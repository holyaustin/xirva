[{"id": "1706.00085", "submitter": "Kayhan Ozcimder", "authors": "Kayhan Ozcimder, Biswadip Dey, Sebastian Musslick, Giovanni Petri,\n  Nesreen K. Ahmed, Theodore L. Willke, Jonathan D. Cohen", "title": "A Formal Approach to Modeling the Cost of Cognitive Control", "comments": "6 pages, 3 figures, Conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a formal method to model the level of demand on control\nwhen executing cognitive processes. The cost of cognitive control is parsed\ninto an intensity cost which encapsulates how much additional input information\nis required so as to get the specified response, and an interaction cost which\nencapsulates the level of interference between individual processes in a\nnetwork. We develop a formal relationship between the probability of successful\nexecution of desired processes and the control signals (additive control\nbiases). This relationship is also used to specify optimal control policies to\nachieve a desired probability of activation for processes. We observe that\nthere are boundary cases when finding such control policies which leads us to\nintroduce the interaction cost. We show that the interaction cost is influenced\nby the relative strengths of individual processes, as well as the\ndirectionality of the underlying competition between processes.\n", "versions": [{"version": "v1", "created": "Wed, 31 May 2017 20:58:20 GMT"}], "update_date": "2017-06-02", "authors_parsed": [["Ozcimder", "Kayhan", ""], ["Dey", "Biswadip", ""], ["Musslick", "Sebastian", ""], ["Petri", "Giovanni", ""], ["Ahmed", "Nesreen K.", ""], ["Willke", "Theodore L.", ""], ["Cohen", "Jonathan D.", ""]]}, {"id": "1706.00133", "submitter": "Zoe Tosi", "authors": "Zoe Tosi, John Beggs", "title": "Cortical Circuits from Scratch: A Metaplastic Architecture for the\n  Emergence of Lognormal Firing Rates and Realistic Topology", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our current understanding of neuroplasticity paints a picture of a complex\ninterconnected system of dependent processes which shape cortical structure so\nas to produce an efficient information processing system. Indeed, the\ncooperation of these processes is associated with robust, stable, adaptable\nnetworks with characteristic features of activity and synaptic topology.\nHowever, combining the actions of these mechanisms in models has proven\nexceptionally difficult and to date no model has been able to do so without\nsignificant hand-tuning. Until such a model exists that can successfully\ncombine these mechanisms to form a stable circuit with realistic features, our\nability to study neuroplasticity in the context of (more realistic) dynamic\nnetworks and potentially reap whatever rewards these features and mechanisms\nimbue biological networks with is hindered. We introduce a model which combines\nfive known plasticity mechanisms that act on the network as well as a unique\nmetaplastic mechanism which acts on other plasticity mechanisms, to produce a\nneural circuit model which is both stable and capable of broadly reproducing\nmany characteristic features of cortical networks. The MANA (metaplastic\nartificial neural architecture) represents the first model of its kind in that\nit is able to self-organize realistic, nonrandom features of cortical networks,\nfrom a null initial state (no synaptic connectivity or neuronal\ndifferentiation). In the same vein as models like the SORN (self-organizing\nrecurrent network) MANA represents further progress toward the reverse\nengineering of the brain at the network level.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jun 2017 00:32:02 GMT"}, {"version": "v2", "created": "Fri, 30 Mar 2018 21:34:00 GMT"}], "update_date": "2018-04-03", "authors_parsed": [["Tosi", "Zoe", ""], ["Beggs", "John", ""]]}, {"id": "1706.00382", "submitter": "Cengiz Pehlevan", "authors": "Cengiz Pehlevan, Sreyas Mohan, Dmitri B. Chklovskii", "title": "Blind nonnegative source separation using biological neural networks", "comments": "Accepted for publication in Neural Computation", "journal-ref": null, "doi": "10.1162/neco_a_01007", "report-no": null, "categories": "q-bio.NC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blind source separation, i.e. extraction of independent sources from a\nmixture, is an important problem for both artificial and natural signal\nprocessing. Here, we address a special case of this problem when sources (but\nnot the mixing matrix) are known to be nonnegative, for example, due to the\nphysical nature of the sources. We search for the solution to this problem that\ncan be implemented using biologically plausible neural networks. Specifically,\nwe consider the online setting where the dataset is streamed to a neural\nnetwork. The novelty of our approach is that we formulate blind nonnegative\nsource separation as a similarity matching problem and derive neural networks\nfrom the similarity matching objective. Importantly, synaptic weights in our\nnetworks are updated according to biologically plausible local learning rules.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jun 2017 16:50:09 GMT"}], "update_date": "2017-10-20", "authors_parsed": [["Pehlevan", "Cengiz", ""], ["Mohan", "Sreyas", ""], ["Chklovskii", "Dmitri B.", ""]]}, {"id": "1706.00603", "submitter": "Ahmad Mheich", "authors": "Ahmad Mheich, Mahmoud Hassan, Fabrice Wendling", "title": "Classification of meaningful and meaningless visual objects: a graph\n  similarity approach", "comments": "4 pages, 2 figures, ICABME 2017 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Cognition involves dynamic reconfiguration of functional brain networks at\nsub-second time scale. A precise tracking of these reconfigurations to\ncategorize visual objects remains elusive. Here, we use dense\nelectroencephalography (EEG) data recorded during naming meaningful (tools,\nanimals) and scrambled objects from 20 healthy subjects. We combine technique\nfor identifying functional brain networks and recently developed algorithm for\nestimating networks similarity to discriminate between the two categories.\nFirst, we showed that dynamic networks of both categories can be segmented into\nseveral brain network states (times windows with consistent brain networks)\nreflecting sequential information processing from object representation to\nreaction time. Second, using a network similarity algorithm, results showed\nhigh intra-category and very low inter-category values. An average accuracy of\n76% was obtained at different brain network states.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jun 2017 09:25:28 GMT"}], "update_date": "2017-06-05", "authors_parsed": [["Mheich", "Ahmad", ""], ["Hassan", "Mahmoud", ""], ["Wendling", "Fabrice", ""]]}, {"id": "1706.00780", "submitter": "Yilin Song", "authors": "Yilin Song, Jonathan Viventi, Yao Wang", "title": "Unsupervised Learning of Spike Patterns for Seizure Detection and\n  Wavefront Estimation of High Resolution Micro Electrocorticographic\n  ({\\mu}ECoG) Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For the past few years, we have developed flexible, active, multiplexed\nrecording devices for high resolution recording over large, clinically relevant\nareas in the brain. While this technology has enabled a much higher-resolution\nview of the electrical activity of the brain, the analytical methods to\nprocess, categorize and respond to the huge volumes of seizure data produced by\nthese devices have not yet been developed. In this work we proposed an\nunsupervised learning framework for spike analysis, which by itself reveals\nspike pattern. By applying advanced video processing techniques for separating\na multi-channel recording into individual spike segments, unfolding the spike\nsegments manifold and identifying natural clusters for spike patterns, we are\nable to find the common spike motion patterns. And we further explored using\nthese patterns for more interesting and practical problems as seizure\nprediction and spike wavefront prediction. These methods have been applied to\nin-vivo feline seizure recordings and yielded promising results.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jun 2017 14:45:58 GMT"}], "update_date": "2017-06-06", "authors_parsed": [["Song", "Yilin", ""], ["Viventi", "Jonathan", ""], ["Wang", "Yao", ""]]}, {"id": "1706.00856", "submitter": "Murat Seckin Ayhan", "authors": "Murat Seckin Ayhan and Vijay Raghavan and Alzheimer's disease\n  Neuroimaging Initiative", "title": "Multiple Kernel Learning and Automatic Subspace Relevance Determination\n  for High-dimensional Neuroimaging Data", "comments": "The material presented here is to promote the dissemination of\n  scholarly and technical work in a timely fashion. Data in this article are\n  from ADNI (adni.loni.usc.edu). As such, ADNI provided data but did not\n  participate in writing of this report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Alzheimer's disease is a major cause of dementia. Its diagnosis requires\naccurate biomarkers that are sensitive to disease stages. In this respect, we\nregard probabilistic classification as a method of designing a probabilistic\nbiomarker for disease staging. Probabilistic biomarkers naturally support the\ninterpretation of decisions and evaluation of uncertainty associated with them.\nIn this paper, we obtain probabilistic biomarkers via Gaussian Processes.\nGaussian Processes enable probabilistic kernel machines that offer flexible\nmeans to accomplish Multiple Kernel Learning. Exploiting this flexibility, we\npropose a new variation of Automatic Relevance Determination and tackle the\nchallenges of high dimensionality through multiple kernels. Our research\nresults demonstrate that the Gaussian Process models are competitive with or\nbetter than the well-known Support Vector Machine in terms of classification\nperformance even in the cases of single kernel learning. Extending the basic\nscheme towards the Multiple Kernel Learning, we improve the efficacy of the\nGaussian Process models and their interpretability in terms of the known\nanatomical correlates of the disease. For instance, the disease pathology\nstarts in and around the hippocampus and entorhinal cortex. Through the use of\nGaussian Processes and Multiple Kernel Learning, we have automatically and\nefficiently determined those portions of neuroimaging data. In addition to\ntheir interpretability, our Gaussian Process models are competitive with recent\ndeep learning solutions under similar settings.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jun 2017 21:16:50 GMT"}], "update_date": "2017-06-06", "authors_parsed": [["Ayhan", "Murat Seckin", ""], ["Raghavan", "Vijay", ""], ["Initiative", "Alzheimer's disease Neuroimaging", ""]]}, {"id": "1706.00976", "submitter": "Shivakeshavan Ratnadurai Giridharan", "authors": "Shivakeshavan Ratnadurai-Giridharan, Chung Cheung, Leonid Rubchinsky", "title": "Effects of electrical and optogenetic deep brain stimulation on\n  synchronized oscillatory activity in Parkinsonian basal ganglia", "comments": "IEEE preprint, 8 pages, 9 Figures", "journal-ref": "IEEE Trans Neural Syst Rehabil Eng 25:2188-2195, 2017", "doi": "10.1109/TNSRE.2017.2712418", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional deep brain stimulation (DBS) of basal ganglia uses\nhigh-frequency regular electrical pulses to treat Parkinsonian motor symptoms\nand has a series of limitations. Relatively new and not yet clinically tested\noptogenetic stimulation is an effective experimental stimulation technique to\naffect pathological network dynamics. We compared the effects of electrical and\noptogenetic stimulation of the basal ganglia on the pathological parkinsonian\nrhythmic neural activity. We studied the network response to electrical\nstimulation and excitatory and inhibitory optogenetic stimulations. Different\nstimulations exhibit different interactions with pathological activity in the\nnetwork. We studied these interactions for different network and stimulation\nparameter values. Optogenetic stimulation was found to be more efficient than\nelectrical stimulation in suppressing pathological rhythmicity. Our findings\nindicate that optogenetic control of neural synchrony may be more efficacious\nthan electrical control because of the different ways of how stimulations\ninteract with network dynamics.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jun 2017 16:45:21 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Ratnadurai-Giridharan", "Shivakeshavan", ""], ["Cheung", "Chung", ""], ["Rubchinsky", "Leonid", ""]]}, {"id": "1706.01188", "submitter": "Diederik Aerts", "authors": "Diederik Aerts, Jonito Aerts Argu\\\"elles, Lester Beltran, Suzette\n  Geriente, Massimiliano Sassoli de Bianchi, Sandro Sozzo and Tomas Veloz", "title": "Spin and Wind Directions II: A Bell State Quantum Model", "comments": "This a the second half of a two-part article, the first half being\n  entitled 'Spin and Wind Directions I: Identifying Entanglement in Nature and\n  Cognition' and to be found at arXiv:1508.00434", "journal-ref": "Foundations of Science, 23, pp. 337-365 (2018)", "doi": "10.1007/s10699-017-9530-2", "report-no": null, "categories": "q-bio.NC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the first half of this two-part article, we analyzed a cognitive\npsychology experiment where participants were asked to select pairs of\ndirections that they considered to be the best example of 'Two Different Wind\nDirections', and showed that the data violate the CHSH version of Bell's\ninequality, with same magnitude as in typical Bell-test experiments in physics.\nIn this second part, we complete our analysis by presenting a symmetrized\nversion of the experiment, still violating the CHSH inequality but now also\nobeying the marginal law, for which we provide a full quantum modeling in\nHilbert space, using a singlet state and suitably chosen product measurements.\nWe also address some of the criticisms that have been recently directed at\nexperiments of this kind, according to which they would not highlight the\npresence of genuine forms of entanglement. We explain that these criticisms are\nbased on a view of entanglement that is too restrictive, thus unable to capture\nall possible ways physical and conceptual entities can connect and form systems\nbehaving as a whole. We also provide an example of a mechanical model showing\nthat the violations of the marginal law and Bell inequalities are generally to\nbe associated with different mechanisms.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jun 2017 04:24:31 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Aerts", "Diederik", ""], ["Argu\u00eblles", "Jonito Aerts", ""], ["Beltran", "Lester", ""], ["Geriente", "Suzette", ""], ["de Bianchi", "Massimiliano Sassoli", ""], ["Sozzo", "Sandro", ""], ["Veloz", "Tomas", ""]]}, {"id": "1706.01249", "submitter": "Lior Noy", "authors": "Yuval Hart, Avraham E Mayo, Ruth Mayo, Liron Rozenkrantz, Avichai\n  Tendler, Uri Alon and Lior Noy", "title": "Creative Foraging: A Quantitative Paradigm for Studying Creative\n  Exploration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Creative exploration is central to science, art and cognitive development.\nHowever, research on creative exploration is limited by a lack of\nhigh-resolution automated paradigms. To address this, we present such an\nautomated paradigm, the creative foraging game, in which people search for\nnovel and valuable solutions in a large and well-defined space made of all\npossible shapes made of ten connected squares. Players discovered shape\ncategories such as digits, letters, and airplanes. They exploited each\ncategory, then dropped it to explore once again, and so on. Aligned with a\nprediction of optimal foraging theory (OFT) prediction, during exploration\nphases, people moved along meandering paths that are about three times longer\nthan the minimal paths between shapes, when exploiting a category of related\nshapes, they moved along the minimal paths. The moment of discovery of a new\ncategory was usually done at a nonprototypical and ambiguous shape, which can\nserve as an experimental proxy for creative leaps. People showed individual\ndifferences in their search patterns, along a continuum between two strategies:\na mercurial quick-to-discover/quick-to-drop strategy and a thorough\nslow-to-discover/slow-to-drop strategy. Contrary to optimal foraging theory,\nplayers leave exploitation to explore again far before categories are depleted.\nThis paradigm opens the way for automated high-resolution study of creative\nexploration.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jun 2017 09:26:23 GMT"}], "update_date": "2017-06-06", "authors_parsed": [["Hart", "Yuval", ""], ["Mayo", "Avraham E", ""], ["Mayo", "Ruth", ""], ["Rozenkrantz", "Liron", ""], ["Tendler", "Avichai", ""], ["Alon", "Uri", ""], ["Noy", "Lior", ""]]}, {"id": "1706.01380", "submitter": "Harish RaviPrakash", "authors": "Harish RaviPrakash, Milena Korostenskaja, Eduardo Castillo, Ki Lee,\n  James Baumgartner, Ulas Bagci", "title": "Automatic Response Assessment in Regions of Language Cortex in Epilepsy\n  Patients Using ECoG-based Functional Mapping and Machine Learning", "comments": "This paper will appear in the Proceedings of IEEE International\n  Conference on Systems, Man and Cybernetics (SMC) 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate localization of brain regions responsible for language and cognitive\nfunctions in Epilepsy patients should be carefully determined prior to surgery.\nElectrocorticography (ECoG)-based Real Time Functional Mapping (RTFM) has been\nshown to be a safer alternative to the electrical cortical stimulation mapping\n(ESM), which is currently the clinical/gold standard. Conventional methods for\nanalyzing RTFM signals are based on statistical comparison of signal power at\ncertain frequency bands. Compared to gold standard (ESM), they have limited\naccuracies when assessing channel responses.\n  In this study, we address the accuracy limitation of the current RTFM signal\nestimation methods by analyzing the full frequency spectrum of the signal and\nreplacing signal power estimation methods with machine learning algorithms,\nspecifically random forest (RF), as a proof of concept. We train RF with power\nspectral density of the time-series RTFM signal in supervised learning\nframework where ground truth labels are obtained from the ESM. Results obtained\nfrom RTFM of six adult patients in a strictly controlled experimental setup\nreveal the state of the art detection accuracy of $\\approx 78\\%$ for the\nlanguage comprehension task, an improvement of $23\\%$ over the conventional\nRTFM estimation method. To the best of our knowledge, this is the first study\nexploring the use of machine learning approaches for determining RTFM signal\ncharacteristics, and using the whole-frequency band for better region\nlocalization. Our results demonstrate the feasibility of machine learning based\nRTFM signal analysis method over the full spectrum to be a clinical routine in\nthe near future.\n", "versions": [{"version": "v1", "created": "Fri, 26 May 2017 16:50:04 GMT"}, {"version": "v2", "created": "Sun, 6 Aug 2017 21:05:14 GMT"}], "update_date": "2017-08-08", "authors_parsed": [["RaviPrakash", "Harish", ""], ["Korostenskaja", "Milena", ""], ["Castillo", "Eduardo", ""], ["Lee", "Ki", ""], ["Baumgartner", "James", ""], ["Bagci", "Ulas", ""]]}, {"id": "1706.01382", "submitter": "Cameron Musco", "authors": "Nancy Lynch, Cameron Musco, Merav Parter", "title": "Neuro-RAM Unit with Applications to Similarity Testing and Compression\n  in Spiking Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.DC cs.DS q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study distributed algorithms implemented in a simplified biologically\ninspired model for stochastic spiking neural networks. We focus on tradeoffs\nbetween computation time and network complexity, along with the role of\nrandomness in efficient neural computation.\n  It is widely accepted that neural computation is inherently stochastic. In\nrecent work, we explored how this stochasticity could be leveraged to solve the\n`winner-take-all' leader election task. Here, we focus on using randomness in\nneural algorithms for similarity testing and compression. In the most basic\nsetting, given two $n$-length patterns of firing neurons, we wish to\ndistinguish if the patterns are equal or $\\epsilon$-far from equal.\n  Randomization allows us to solve this task with a very compact network, using\n$O \\left (\\frac{\\sqrt{n}\\log n}{\\epsilon}\\right)$ auxiliary neurons, which is\nsublinear in the input size. At the heart of our solution is the design of a\n$t$-round neural random access memory, or indexing network, which we call a\nneuro-RAM. This module can be implemented with $O(n/t)$ auxiliary neurons and\nis useful in many applications beyond similarity testing.\n  Using a VC dimension-based argument, we show that the tradeoff between\nruntime and network size in our neuro-RAM is nearly optimal. Our result has\nseveral implications -- since our neuro-RAM can be implemented with\ndeterministic threshold gates, it shows that, in contrast to similarity\ntesting, randomness does not provide significant computational advantages for\nthis problem. It also establishes a separation between feedforward networks\nwhose gates spike with sigmoidal probability functions, and well-studied\ndeterministic sigmoidal networks, whose gates output real number sigmoidal\nvalues, and which can implement a neuro-RAM much more efficiently.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jun 2017 15:43:40 GMT"}, {"version": "v2", "created": "Mon, 21 Aug 2017 17:34:32 GMT"}], "update_date": "2017-08-22", "authors_parsed": [["Lynch", "Nancy", ""], ["Musco", "Cameron", ""], ["Parter", "Merav", ""]]}, {"id": "1706.01443", "submitter": "Camilo Miguel Signorelli", "authors": "Camilo Miguel Signorelli", "title": "Types of Cognition and its Implications for future High-Level Cognitive\n  Machines", "comments": "2017 AAAI Spring Symposium Series, Science of Intelligence:\n  Computational Principles of Natural and Artificial Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work summarizes part of current knowledge on High-level Cognitive\nprocess and its relation with biological hardware. Thus, it is possible to\nidentify some paradoxes which could impact the development of future\ntechnologies and artificial intelligence: we may make a High-level Cognitive\nMachine, sacrificing the principal attribute of a machine, its accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jun 2017 17:47:58 GMT"}], "update_date": "2017-06-06", "authors_parsed": [["Signorelli", "Camilo Miguel", ""]]}, {"id": "1706.01521", "submitter": "Nathan Hodas", "authors": "Lyndsey Franklin, Kristina Lerman, Nathan Hodas", "title": "Will Break for Productivity: Generalized Symptoms of Cognitive Depletion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we address the symptoms of cognitive depletion as they relate\nto generalized knowledge workers. We unify previous findings within a single\nanalytical model of cognitive depletion. Our purpose is to develop a model that\nwill help us predict when a person has reached a sufficient state of cognitive\ndepletion such that taking a break or some other restorative action will\nbenefit both his or her own wellbeing and the quality of his or her\nperformance. We provide a definition of each symptom in our model as well as\nthe effect it would have on a knowledge worker's ability to work productively.\nWe discuss methods to detect each symptom that do not require self assessment.\nUnderstanding symptoms of cognitive depletion provides the ability to support\nhuman knowledge workers by reducing the stress involved with cognitive and work\noverload while maintaining or improving the quality of their performance.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jun 2017 20:02:19 GMT"}], "update_date": "2017-06-07", "authors_parsed": [["Franklin", "Lyndsey", ""], ["Lerman", "Kristina", ""], ["Hodas", "Nathan", ""]]}, {"id": "1706.01728", "submitter": "Jelena Mladenovic", "authors": "Jelena Mladenovi\\'c (Potioc), J\\'er\\'emy Frey (Potioc), Manon\n  Bonnet-Save (Potioc), J\\'er\\'emie Mattout, Fabien Lotte (LaBRI, Potioc)", "title": "The Impact of Flow in an EEG-based Brain Computer Interface", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Major issues in Brain Computer Interfaces (BCIs) include low usability and\npoor user performance. This paper tackles them by ensuring the users to be in a\nstate of immersion, control and motivation, called state of flow. Indeed, in\nvarious disciplines, being in the state of flow was shown to improve\nperformances and learning. Hence, we intended to draw BCI users in a flow state\nto improve both their subjective experience and their performances. In a Motor\nImagery BCI game, we manipulated flow in two ways: 1) by adapting the task\ndifficulty and 2) by using background music. Results showed that the difficulty\nadaptation induced a higher flow state, however music had no effect. There was\na positive correlation between subjective flow scores and offline performance,\nalthough the flow factors had no effect (adaptation) or negative effect (music)\non online performance. Overall, favouring the flow state seems a promising\napproach for enhancing users' satisfaction, although its complexity requires\nmore thorough investigations.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jun 2017 12:21:44 GMT"}], "update_date": "2017-06-07", "authors_parsed": [["Mladenovi\u0107", "Jelena", "", "Potioc"], ["Frey", "J\u00e9r\u00e9my", "", "Potioc"], ["Bonnet-Save", "Manon", "", "Potioc"], ["Mattout", "J\u00e9r\u00e9mie", "", "LaBRI, Potioc"], ["Lotte", "Fabien", "", "LaBRI, Potioc"]]}, {"id": "1706.01757", "submitter": "Max Losch", "authors": "H. Steven Scholte, Max M. Losch, Kandan Ramakrishnan, Edward H.F. de\n  Haan, Sander M. Bohte", "title": "Visual pathways from the perspective of cost functions and multi-task\n  deep neural networks", "comments": "16 pages, 5 figures", "journal-ref": null, "doi": "10.1016/j.cortex.2017.09.019", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vision research has been shaped by the seminal insight that we can understand\nthe higher-tier visual cortex from the perspective of multiple functional\npathways with different goals. In this paper, we try to give a computational\naccount of the functional organization of this system by reasoning from the\nperspective of multi-task deep neural networks. Machine learning has shown that\ntasks become easier to solve when they are decomposed into subtasks with their\nown cost function. We hypothesize that the visual system optimizes multiple\ncost functions of unrelated tasks and this causes the emergence of a ventral\npathway dedicated to vision for perception, and a dorsal pathway dedicated to\nvision for action. To evaluate the functional organization in multi-task deep\nneural networks, we propose a method that measures the contribution of a unit\ntowards each task, applying it to two networks that have been trained on either\ntwo related or two unrelated tasks, using an identical stimulus set. Results\nshow that the network trained on the unrelated tasks shows a decreasing degree\nof feature representation sharing towards higher-tier layers while the network\ntrained on related tasks uniformly shows high degree of sharing. We conjecture\nthat the method we propose can be used to analyze the anatomical and functional\norganization of the visual system and beyond. We predict that the degree to\nwhich tasks are related is a good descriptor of the degree to which they share\ndownstream cortical-units.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jun 2017 13:36:31 GMT"}, {"version": "v2", "created": "Sat, 16 Sep 2017 10:37:24 GMT"}], "update_date": "2017-10-16", "authors_parsed": [["Scholte", "H. Steven", ""], ["Losch", "Max M.", ""], ["Ramakrishnan", "Kandan", ""], ["de Haan", "Edward H. F.", ""], ["Bohte", "Sander M.", ""]]}, {"id": "1706.01831", "submitter": "Madhavun Candadai Vasu", "authors": "Madhavun Candadai Vasu, Eduardo Izquierdo", "title": "Information Bottleneck in Control Tasks with Recurrent Spiking Neural\n  Networks", "comments": "Accepted at ICANN'17 to appear in Springer Lecture Notes in Computer\n  Science", "journal-ref": "ICANN 2017. Lecture Notes in Computer Science, vol 10613.\n  Springer, Cham", "doi": "10.1007/978-3-319-68600-4_28", "report-no": null, "categories": "cs.NE cs.IT math.IT q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The nervous system encodes continuous information from the environment in the\nform of discrete spikes, and then decodes these to produce smooth motor\nactions. Understanding how spikes integrate, represent, and process information\nto produce behavior is one of the greatest challenges in neuroscience.\nInformation theory has the potential to help us address this challenge.\nInformational analyses of deep and feed-forward artificial neural networks\nsolving static input-output tasks, have led to the proposal of the\n\\emph{Information Bottleneck} principle, which states that deeper layers encode\nmore relevant yet minimal information about the inputs. Such an analyses on\nnetworks that are recurrent, spiking, and perform control tasks is relatively\nunexplored. Here, we present results from a Mutual Information analysis of a\nrecurrent spiking neural network that was evolved to perform the classic\npole-balancing task. Our results show that these networks deviate from the\n\\emph{Information Bottleneck} principle prescribed for feed-forward networks.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jun 2017 16:08:18 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Vasu", "Madhavun Candadai", ""], ["Izquierdo", "Eduardo", ""]]}, {"id": "1706.02240", "submitter": "Martin Schrimpf", "authors": "Hanlin Tang, Martin Schrimpf, Bill Lotter, Charlotte Moerman, Ana\n  Paredes, Josue Ortega Caro, Walter Hardesty, David Cox, Gabriel Kreiman", "title": "Recurrent computations for visual pattern completion", "comments": null, "journal-ref": null, "doi": "10.1073/pnas.1719397115", "report-no": null, "categories": "q-bio.NC cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Making inferences from partial information constitutes a critical aspect of\ncognition. During visual perception, pattern completion enables recognition of\npoorly visible or occluded objects. We combined psychophysics, physiology and\ncomputational models to test the hypothesis that pattern completion is\nimplemented by recurrent computations and present three pieces of evidence that\nare consistent with this hypothesis. First, subjects robustly recognized\nobjects even when rendered <15% visible, but recognition was largely impaired\nwhen processing was interrupted by backward masking. Second, invasive\nphysiological responses along the human ventral cortex exhibited visually\nselective responses to partially visible objects that were delayed compared to\nwhole objects, suggesting the need for additional computations. These\nphysiological delays were correlated with the effects of backward masking.\nThird, state-of-the-art feed-forward computational architectures were not\nrobust to partial visibility. However, recognition performance was recovered\nwhen the model was augmented with attractor-based recurrent connectivity. These\nresults provide a strong argument of plausibility for the role of recurrent\ncomputations in making visual inferences from partial information.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jun 2017 16:23:28 GMT"}, {"version": "v2", "created": "Fri, 6 Apr 2018 12:29:22 GMT"}], "update_date": "2018-08-15", "authors_parsed": [["Tang", "Hanlin", ""], ["Schrimpf", "Martin", ""], ["Lotter", "Bill", ""], ["Moerman", "Charlotte", ""], ["Paredes", "Ana", ""], ["Caro", "Josue Ortega", ""], ["Hardesty", "Walter", ""], ["Cox", "David", ""], ["Kreiman", "Gabriel", ""]]}, {"id": "1706.02274", "submitter": "Camilo Miguel Signorelli", "authors": "Camilo Miguel Signorelli", "title": "Can Computers overcome Humans? Consciousness interaction and its\n  implications", "comments": "16th IEEE Cognitive Informatics and Cognitive Computing preprint, 8\n  pages; Added references and short discussion for section 6", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Can computers overcome human capabilities? This is a paradoxical and\ncontroversial question, particularly because there are many hidden assumptions.\nThis article focuses on that issue putting on evidence some misconception\nrelated with future generations of machines and the understanding of the brain.\nIt will be discussed to what extent computers might reach human capabilities,\nand how it could be possible only if the computer is a conscious machine.\nHowever, it will be shown that if the computer is conscious, an interference\nprocess due to consciousness would affect the information processing of the\nsystem. Therefore, it might be possible to make conscious machines to overcome\nhuman capabilities, which will have limitations as well as humans. In other\nwords, trying to overcome human capabilities with computers implies the\nparadoxical conclusion that a computer will never overcome human capabilities\nat all, or if the computer does, it should not be considered as a computer\nanymore.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jun 2017 17:34:49 GMT"}, {"version": "v2", "created": "Mon, 26 Jun 2017 06:50:02 GMT"}], "update_date": "2017-06-27", "authors_parsed": [["Signorelli", "Camilo Miguel", ""]]}, {"id": "1706.02444", "submitter": "Jungsik Hwang", "authors": "Jungsik Hwang, Jinhyung Kim, Ahmadreza Ahmadi, Minkyu Choi, Jun Tani", "title": "Predictive Coding-based Deep Dynamic Neural Network for Visuomotor\n  Learning", "comments": "Accepted at the 7th Joint IEEE International Conference of\n  Developmental Learning and Epigenetic Robotics (ICDL-EpiRob 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.RO q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study presents a dynamic neural network model based on the predictive\ncoding framework for perceiving and predicting the dynamic visuo-proprioceptive\npatterns. In our previous study [1], we have shown that the deep dynamic neural\nnetwork model was able to coordinate visual perception and action generation in\na seamless manner. In the current study, we extended the previous model under\nthe predictive coding framework to endow the model with a capability of\nperceiving and predicting dynamic visuo-proprioceptive patterns as well as a\ncapability of inferring intention behind the perceived visuomotor information\nthrough minimizing prediction error. A set of synthetic experiments were\nconducted in which a robot learned to imitate the gestures of another robot in\na simulation environment. The experimental results showed that with given\nintention states, the model was able to mentally simulate the possible incoming\ndynamic visuo-proprioceptive patterns in a top-down process without the inputs\nfrom the external environment. Moreover, the results highlighted the role of\nminimizing prediction error in inferring underlying intention of the perceived\nvisuo-proprioceptive patterns, supporting the predictive coding account of the\nmirror neuron systems. The results also revealed that minimizing prediction\nerror in one modality induced the recall of the corresponding representation of\nanother modality acquired during the consolidative learning of raw-level\nvisuo-proprioceptive patterns.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jun 2017 03:29:39 GMT"}], "update_date": "2017-06-09", "authors_parsed": [["Hwang", "Jungsik", ""], ["Kim", "Jinhyung", ""], ["Ahmadi", "Ahmadreza", ""], ["Choi", "Minkyu", ""], ["Tani", "Jun", ""]]}, {"id": "1706.02451", "submitter": "Wutu Lin", "authors": "Tiger W. Lin, Anup Das, Giri P. Krishnan, Maxim Bazhenov, Terrence J.\n  Sejnowski", "title": "Differential Covariance: A New Class of Methods to Estimate Sparse\n  Connectivity from Neural Recordings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With our ability to record more neurons simultaneously, making sense of these\ndata is a challenge. Functional connectivity is one popular way to study the\nrelationship between multiple neural signals. Correlation-based methods are a\nset of currently well-used techniques for functional connectivity estimation.\nHowever, due to explaining away and unobserved common inputs (Stevenson et al.,\n2008), they produce spurious connections. The general linear model (GLM), which\nmodels spikes trains as Poisson processes (Okatan et al., 2005; Truccolo et\nal., 2005; Pillow et al., 2008), avoids these confounds. We develop here a new\nclass of methods by using differential signals based on simulated intracellular\nvoltage recordings. It is equivalent to a regularized AR(2) model. We also\nexpand the method to simulated local field potential (LFP) recordings and\ncalcium imaging. In all of our simulated data, the differential\ncovariance-based methods achieved better or similar performance to the GLM\nmethod and required fewer data samples. This new class of methods provides\nalternative ways to analyze neural signals.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jun 2017 04:54:27 GMT"}], "update_date": "2017-06-09", "authors_parsed": [["Lin", "Tiger W.", ""], ["Das", "Anup", ""], ["Krishnan", "Giri P.", ""], ["Bazhenov", "Maxim", ""], ["Sejnowski", "Terrence J.", ""]]}, {"id": "1706.02561", "submitter": "PierGianLuca Porta Mana", "authors": "P.G.L. Porta Mana", "title": "Maximum-entropy from the probability calculus: exchangeability,\n  sufficiency", "comments": "22 pages, 2.5 figures. V2: added references, discussion on relation\n  with multinomial distribution, discussion on conditions of number of\n  observations and possible outcomes", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.data-an math.PR q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Maximum-entropy distributions are shown to appear in the probability calculus\nas approximations of a model by exchangeability or a model by sufficiency, the\nformer model being preferable. The implications of this fact are discussed,\ntogether with other questions: Prediction or retrodiction? How good is the\nmaximum-entropy approximation? Is this a \"derivation\" of maximum-entropy?\n", "versions": [{"version": "v1", "created": "Thu, 8 Jun 2017 14:56:13 GMT"}, {"version": "v2", "created": "Mon, 26 Jun 2017 08:27:40 GMT"}], "update_date": "2017-06-27", "authors_parsed": [["Mana", "P. G. L. Porta", ""]]}, {"id": "1706.02609", "submitter": "Yujie Wu", "authors": "Yujie Wu, Lei Deng, Guoqi Li, Jun Zhu, Luping Shi", "title": "Spatio-Temporal Backpropagation for Training High-performance Spiking\n  Neural Networks", "comments": null, "journal-ref": "Frontiers in neuroscience, 2018, 12", "doi": "10.3389/fnins.2018.00331", "report-no": null, "categories": "cs.NE q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compared with artificial neural networks (ANNs), spiking neural networks\n(SNNs) are promising to explore the brain-like behaviors since the spikes could\nencode more spatio-temporal information. Although pre-training from ANN or\ndirect training based on backpropagation (BP) makes the supervised training of\nSNNs possible, these methods only exploit the networks' spatial domain\ninformation which leads to the performance bottleneck and requires many\ncomplicated training skills. Another fundamental issue is that the spike\nactivity is naturally non-differentiable which causes great difficulties in\ntraining SNNs. To this end, we build an iterative LIF model that is more\nfriendly for gradient descent training. By simultaneously considering the\nlayer-by-layer spatial domain (SD) and the timing-dependent temporal domain\n(TD) in the training phase, as well as an approximated derivative for the spike\nactivity, we propose a spatio-temporal backpropagation (STBP) training\nframework without using any complicated technology. We achieve the best\nperformance of multi-layered perceptron (MLP) compared with existing\nstate-of-the-art algorithms over the static MNIST and the dynamic N-MNIST\ndataset as well as a custom object detection dataset. This work provides a new\nperspective to explore the high-performance SNNs for future brain-like\ncomputing paradigm with rich spatio-temporal dynamics.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jun 2017 14:33:55 GMT"}, {"version": "v2", "created": "Thu, 6 Jul 2017 02:40:45 GMT"}, {"version": "v3", "created": "Tue, 12 Sep 2017 10:50:05 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Wu", "Yujie", ""], ["Deng", "Lei", ""], ["Li", "Guoqi", ""], ["Zhu", "Jun", ""], ["Shi", "Luping", ""]]}, {"id": "1706.02764", "submitter": "Ruth Rosenholtz", "authors": "Ruth Rosenholtz", "title": "What modern vision science reveals about the awareness puzzle:\n  Summary-statistic encoding plus decision limits underlie the richness of\n  visual perception and its quirky failures", "comments": "12 pages, 8 figures. This is the \"extended abstract\" for a\n  presentation at the Vision Sciences Society symposium on summary statistics\n  and awareness, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a fundamental puzzle in understanding our awareness of the visual\nworld. On one hand, our subjective experience is one of a rich visual world,\nwhich we perceive effortlessly. However, when we actually test perception,\nobservers know surprisingly little. A number of tasks, from search, through\ninattentional blindness, to change blindness, suggest that there is\nsurprisingly little awareness or perception without attention. Meanwhile,\nanother set of tasks, such as multiple object tracking, dual-task performance,\nand visual working memory tasks suggest that both attention and working memory\nhave low capacity. These two components together - poor perception without\nattention, and greatly limited capacity for attention and memory - imply that\nperception is impoverished.\n  How can we make sense of this awareness puzzle, of the riddle of our rich\nsubjective experience coupled with poor performance on experimental tasks? I\nsuggest that, looked at in the right way, there is in fact no awareness puzzle.\nIn particular, I will argue that the tasks that show limits are inherently\ndifficult tasks, and that there exists a unified explanation for both the rich\nsubjective experience and the apparent limits.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jun 2017 20:41:50 GMT"}], "update_date": "2017-06-12", "authors_parsed": [["Rosenholtz", "Ruth", ""]]}, {"id": "1706.02912", "submitter": "Julia Gallinaro", "authors": "J\\'ulia V Gallinaro and Stefan Rotter", "title": "Associative properties of structural plasticity based on firing rate\n  homeostasis in recurrent neuronal networks", "comments": "19 pages, 4 figures", "journal-ref": null, "doi": "10.1038/s41598-018-22077-3", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Correlation-based Hebbian plasticity is thought to shape neuronal\nconnectivity during development and learning, whereas homeostatic plasticity\nwould stabilize network activity. Here we investigate another, new aspect of\nthis dichotomy: Can Hebbian associative properties also emerge as a network\neffect from a plasticity rule based on homeostatic principles on the neuronal\nlevel? To address this question, we simulated a recurrent network of leaky\nintegrate-and-fire neurons, in which excitatory connections are subject to a\nstructural plasticity rule based on firing rate homeostasis. We show that a\nsubgroup of neurons develop stronger within-group connectivity as a consequence\nof receiving stronger external stimulation. In an experimentally\nwell-documented scenario we show that feature specific connectivity, similar to\nwhat has been observed in rodent visual cortex, can emerge from such a\nplasticity rule. The experience-dependent structural changes triggered by\nstimulation are long-lasting and decay only slowly when the neurons are exposed\nagain to unspecific external inputs.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jun 2017 12:03:23 GMT"}, {"version": "v2", "created": "Wed, 6 Sep 2017 10:59:32 GMT"}, {"version": "v3", "created": "Mon, 22 Jan 2018 14:29:28 GMT"}, {"version": "v4", "created": "Sat, 24 Feb 2018 09:42:39 GMT"}], "update_date": "2018-03-02", "authors_parsed": [["Gallinaro", "J\u00falia V", ""], ["Rotter", "Stefan", ""]]}, {"id": "1706.03296", "submitter": "Eve Armstrong", "authors": "Eve Armstrong", "title": "An optimization method to simultaneously estimate electrophysiology and\n  connectivity in a model central pattern generator", "comments": "This paper has been extensively revised and has now become the new\n  submission: \"An optimization method for estimating functional connectivity\n  and electrophysiology within a biological neuronal network\"\n  [arXiv:1711.03834]. This old version should not be here anymore", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.bio-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Central pattern generators (CPGs) appear to have evolved multiple times\nthroughout the animal kingdom, indicating that their design imparts a\nsignificant evolutionary advantage. Insight into how this design is achieved is\nhindered by the difficulty inherent in examining relationships among\nelectrophysiological properties of the constituent cells of a CPG and their\nfunctional connectivity. That is: experimentally it is challenging to estimate\nthe values of more than two or three of these properties simultaneously. We\nemploy a method of statistical data assimilation (D.A.) to estimate the\nsynaptic weights, synaptic reversal potentials, and maximum conductances of ion\nchannels of the constituent neurons in a multi-modal network model. We then use\nthese estimates to predict the functional mode of activity that the network is\nexpressing. The measurements used are the membrane voltage time series of all\nneurons in the circuit. We find that these measurements provide sufficient\ninformation to yield accurate predictions of the network's associated\nelectrical activity. This experiment can apply directly in a real laboratory\nusing intracellular recordings from a known biological CPG whose structural\nmapping is known, and which can be completely isolated from the animal. The\nsimulated results in this paper suggest that D.A. might provide a tool for\nsimultaneously estimating tens to hundreds of CPG properties, thereby offering\nthe opportunity to seek possible systematic relationships among these\nproperties and the emergent electrical activity.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jun 2017 02:10:43 GMT"}, {"version": "v2", "created": "Sat, 8 Jul 2017 21:27:12 GMT"}, {"version": "v3", "created": "Thu, 9 Nov 2017 18:21:15 GMT"}, {"version": "v4", "created": "Tue, 4 Sep 2018 12:19:11 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Armstrong", "Eve", ""]]}, {"id": "1706.03619", "submitter": "Omid Rezania", "authors": "Omid Rezania", "title": "Physics of the Brain-Schizophrenia", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Schizophrenic patients suffer from hallucination which its causality is not\nyet fully understood. This paper attempts to approach this mystery from the\nperspective of quantum mechanical theories. A novel approach has been adopted\nto demonstrate the hallucination as a time evolution of percepts basis states\nin the Hilbertian consciousness which are desynchronised from the time in real\nworld. The method also extends his approach to predict mind and brain\nmodulation through the correlation and coupling of consciousness and it reaches\na clinically hypothetical outcome of inducing consciousness into a brain which\nis not conscious.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jun 2017 22:20:00 GMT"}], "update_date": "2017-06-13", "authors_parsed": [["Rezania", "Omid", ""]]}, {"id": "1706.03835", "submitter": "Christian Meisel", "authors": "Christian Meisel, Kimberlyn Bailey, Peter Achermann and Dietmar Plenz", "title": "Decline of long-range temporal correlations in the human brain during\n  sustained wakefulness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sleep is crucial for daytime functioning, cognitive performance and general\nwell-being. These aspects of daily life are known to be impaired after extended\nwake, yet, the underlying neuronal correlates have been difficult to identify.\nAccumulating evidence suggests that normal functioning of the brain is\ncharacterized by long-range temporal correlations (LRTCs) in cortex, which are\nsupportive for decision-making and working memory tasks.\n  Here we assess LRTCs in resting state human EEG data during a 40-hour sleep\ndeprivation experiment by evaluating the decay in autocorrelation and the\nscaling exponent of the detrended fluctuation analysis from EEG amplitude\nfluctuations. We find with both measures that LRTCs decline as sleep\ndeprivation progresses. This decline becomes evident when taking changes in\nsignal power into appropriate consideration.\n  Our results demonstrate the importance of sleep to maintain LRTCs in the\nhuman brain. In complex networks, LRTCs naturally emerge in the vicinity of a\ncritical state. The observation of declining LRTCs during wake thus provides\nadditional support for our hypothesis that sleep reorganizes cortical networks\ntowards critical dynamics for optimal functioning.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jun 2017 20:15:43 GMT"}], "update_date": "2017-06-14", "authors_parsed": [["Meisel", "Christian", ""], ["Bailey", "Kimberlyn", ""], ["Achermann", "Peter", ""], ["Plenz", "Dietmar", ""]]}, {"id": "1706.03836", "submitter": "Christian Meisel", "authors": "Christian Meisel, Andreas Klaus, Vladyslav V. Vyazovskiy and Dietmar\n  Plenz", "title": "The interplay between long- and short-range temporal correlations shapes\n  cortex dynamics across vigilance states", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC nlin.AO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Increasing evidence suggests that cortical dynamics during wake exhibits\nlong-range temporal correlations suitable to integrate inputs over extended\nperiods of time to increase the signal-to-noise ratio in decision-making and\nworking memory tasks. Accordingly, sleep has been suggested as a state\ncharacterized by a breakdown of long-range correlations; detailed measurements\nof neuronal timescales that support this view, however, have so far been\nlacking. Here we show that the long timescales measured at the individual\nneuron level in freely-behaving rats during the awake state are abrogated\nduring non-REM (NREM) sleep. We provide evidence for the existence of two\ndistinct states in terms of timescale dynamics in cortex: one which is\ncharacterized by long timescales which dominate during wake and REM sleep, and\na second one characterized by the absence of long-range temporal correlations\nwhich characterizes NREM sleep. We observe that both timescale regimes can\nco-exist and, in combination, lead to an apparent gradual decline of long\ntimescales during extended wake which is restored after sleep. Our results\nprovide a missing link between the observed long timescales in individual\nneuron fluctuations during wake and the reported absence of long-term\ncorrelations during deep sleep in EEG and fMRI studies. They furthermore\nsuggest a network-level function of sleep, to reorganize cortical networks\ntowards states governed by slow cortex dynamics to ensure optimal function for\nthe time awake.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jun 2017 20:16:42 GMT"}], "update_date": "2017-06-14", "authors_parsed": [["Meisel", "Christian", ""], ["Klaus", "Andreas", ""], ["Vyazovskiy", "Vladyslav V.", ""], ["Plenz", "Dietmar", ""]]}, {"id": "1706.03839", "submitter": "Aya Kabbara", "authors": "Aya Kabbara, Mahmoud Hassan, Mohamad Khalil, Wassim El Falou, Hassan\n  Eid", "title": "A scalp-EEG network-based analysis of Alzheimer's disease patients at\n  rest", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most brain disorders including Alzheimer's disease (AD) are related to\nalterations in the normal brain network organization and function. Exploring\nthese network alterations using non-invasive and easy to use technique is a\ntopic of great interest. In this paper, we collected EEG resting-state data\nfrom AD patients and healthy control subjects. Functional connectivity between\nscalp EEG signals was quantified using the phase locking value (PLV) for 6\nfrequency bands. To assess the differences in network properties,\ngraph-theoretical analysis was performed. AD patients showed decrease of mean\nconnectivity, average clustering and global efficiency in the lower alpha band.\nPositive correlation between the cognitive score and the extracted graph\nmeasures was obtained, suggesting that EEG could be a promising technique to\nderive new biomarkers of AD diagnosis.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jun 2017 20:27:48 GMT"}], "update_date": "2017-06-14", "authors_parsed": [["Kabbara", "Aya", ""], ["Hassan", "Mahmoud", ""], ["Khalil", "Mohamad", ""], ["Falou", "Wassim El", ""], ["Eid", "Hassan", ""]]}, {"id": "1706.03999", "submitter": "Raffaella Mulas", "authors": "Raffaella Mulas and Ngoc M Tran", "title": "Minimal Embedding Dimensions of Connected Neural Codes", "comments": "9 pages, 4 figures", "journal-ref": "Algebraic Statistics 11, 1 (2020) 99-106", "doi": "10.2140/astat.2020.11.99", "report-no": null, "categories": "math.CO q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the past few years, the study of receptive field codes has been of large\ninterest to mathematicians. Here we give a complete characterization of\nreceptive field codes realizable by connected receptive fields and we give the\nminimal embedding dimensions of these codes. In particular, we show that all\nconnected codes are realizable in dimension at most 3. To our knowledge, this\nis the first family of receptive field codes for which the exact\ncharacterization and minimal embedding dimension is known.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jun 2017 11:09:11 GMT"}, {"version": "v2", "created": "Sat, 22 Jul 2017 06:59:08 GMT"}, {"version": "v3", "created": "Tue, 28 Nov 2017 16:19:22 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Mulas", "Raffaella", ""], ["Tran", "Ngoc M", ""]]}, {"id": "1706.04192", "submitter": "Catherine Reason", "authors": "Catherine Reason", "title": "A Theoretical Solution of the Mind-Body Problem: An Operationalized\n  Proof that no Purely Physical System Can Exhibit all the Properties of Human\n  Consciousness", "comments": "This latest version is updated to take account of comments by\n  reviewers from the Journal of Consciousness Studies and the Psychological\n  Review", "journal-ref": "Journal of Mind and behavior. 40 (2), 95-120 (2019)", "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article presents an operationalized solution to the mind-body problem\nwhich relies on rigorously defined theoretical reasoning rather than\nphilosophical argument. We identify a specific operation which is a necessary\nproperty of all healthy human conscious individuals -- specifically the\noperation of self-certainty, or the capacity of healthy conscious humans to\n\"know\" with certainty that they are conscious. This operation is shown to be\ninconsistent with the properties possible in any meaningful definition of a\nphysical system. This inconsistency is demonstrated by proving a \"no-go\"\ntheorem for any physical system capable of human logical reasoning, if this\nreasoning is required to be both sound and consistent. The proof of this\ntheorem is both general -- it applies to any function whereby evidence affects\nthe state of some physical system -- and recursive, since any physical process\nsubserving a function of this type is shown to imply another such function.\nThus for at least one aspect of human consciousness, the mind-body problem is\nnow conclusively resolved.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jun 2017 17:01:36 GMT"}, {"version": "v2", "created": "Tue, 18 Jul 2017 14:38:28 GMT"}, {"version": "v3", "created": "Mon, 28 Aug 2017 12:03:30 GMT"}, {"version": "v4", "created": "Tue, 31 Oct 2017 19:05:38 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Reason", "Catherine", ""]]}, {"id": "1706.04254", "submitter": "Roger Gomez Nieto", "authors": "Roger Gomez Nieto, Andres Marino Alvarez Meza, Julian David Echeverry\n  Correa, Alvaro Angel Orozco Gutierrez", "title": "Automatic Localization of Deep Stimulation Electrodes Using\n  Trajectory-based Segmentation Approach", "comments": "13 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parkinson's disease (PD) is a degenerative condition of the nervous system,\nwhich manifests itself primarily as muscle stiffness, hypokinesia,\nbradykinesia, and tremor. In patients suffering from advanced stages of PD,\nDeep Brain Stimulation neurosurgery (DBS) is the best alternative to medical\ntreatment, especially when they become tolerant to the drugs. This surgery\nproduces a neuronal activity, a result from electrical stimulation, whose\nquantification is known as Volume of Tissue Activated (VTA). To locate\ncorrectly the VTA in the cerebral volume space, one should be aware exactly the\nlocation of the tip of the DBS electrodes, as well as their spatial projection.\n  In this paper, we automatically locate DBS electrodes using a threshold-based\nmedical imaging segmentation methodology, determining the optimal value of this\nthreshold adaptively. The proposed methodology allows the localization of DBS\nelectrodes in Computed Tomography (CT) images, with high noise tolerance, using\nautomatic threshold detection methods.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jun 2017 21:06:35 GMT"}], "update_date": "2017-06-15", "authors_parsed": [["Nieto", "Roger Gomez", ""], ["Meza", "Andres Marino Alvarez", ""], ["Correa", "Julian David Echeverry", ""], ["Gutierrez", "Alvaro Angel Orozco", ""]]}, {"id": "1706.04568", "submitter": "Lex Fridman", "authors": "Lex Fridman, Benedikt Jenik, Shaiyan Keshvari, Bryan Reimer, Christoph\n  Zetzsche, Ruth Rosenholtz", "title": "SideEye: A Generative Neural Network Based Simulator of Human Peripheral\n  Vision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Foveal vision makes up less than 1% of the visual field. The other 99% is\nperipheral vision. Precisely what human beings see in the periphery is both\nobvious and mysterious in that we see it with our own eyes but can't visualize\nwhat we see, except in controlled lab experiments. Degradation of information\nin the periphery is far more complex than what might be mimicked with a radial\nblur. Rather, behaviorally-validated models hypothesize that peripheral vision\nmeasures a large number of local texture statistics in pooling regions that\noverlap and grow with eccentricity. In this work, we develop a new method for\nperipheral vision simulation by training a generative neural network on a\nbehaviorally-validated full-field synthesis model. By achieving a 21,000 fold\nreduction in running time, our approach is the first to combine realism and\nspeed of peripheral vision simulation to a degree that provides a whole new way\nto approach visual design: through peripheral visualization.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jun 2017 16:18:20 GMT"}, {"version": "v2", "created": "Mon, 23 Oct 2017 03:40:03 GMT"}], "update_date": "2017-10-24", "authors_parsed": [["Fridman", "Lex", ""], ["Jenik", "Benedikt", ""], ["Keshvari", "Shaiyan", ""], ["Reimer", "Bryan", ""], ["Zetzsche", "Christoph", ""], ["Rosenholtz", "Ruth", ""]]}, {"id": "1706.04698", "submitter": "Dongsung Huh", "authors": "Dongsung Huh, Terrence J. Sejnowski", "title": "Gradient Descent for Spiking Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much of studies on neural computation are based on network models of static\nneurons that produce analog output, despite the fact that information\nprocessing in the brain is predominantly carried out by dynamic neurons that\nproduce discrete pulses called spikes. Research in spike-based computation has\nbeen impeded by the lack of efficient supervised learning algorithm for spiking\nnetworks. Here, we present a gradient descent method for optimizing spiking\nnetwork models by introducing a differentiable formulation of spiking networks\nand deriving the exact gradient calculation. For demonstration, we trained\nrecurrent spiking networks on two dynamic tasks: one that requires optimizing\nfast (~millisecond) spike-based interactions for efficient encoding of\ninformation, and a delayed memory XOR task over extended duration (~second).\nThe results show that our method indeed optimizes the spiking network dynamics\non the time scale of individual spikes as well as behavioral time scales. In\nconclusion, our result offers a general purpose supervised learning algorithm\nfor spiking neural networks, thus advancing further investigations on\nspike-based computation.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jun 2017 23:56:57 GMT"}, {"version": "v2", "created": "Mon, 19 Jun 2017 22:11:20 GMT"}], "update_date": "2017-06-21", "authors_parsed": [["Huh", "Dongsung", ""], ["Sejnowski", "Terrence J.", ""]]}, {"id": "1706.04772", "submitter": "Lior Weizman", "authors": "Lior Weizman, Karla L. Miller, Mark Chiew, Yonina C. Eldar", "title": "PEAR: PEriodic And fixed Rank separation for fast fMRI", "comments": null, "journal-ref": null, "doi": "10.1002/mp.12599", "report-no": null, "categories": "physics.med-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In functional MRI (fMRI), faster acquisition via undersampling of data can\nimprove the spatial-temporal resolution trade-off and increase statistical\nrobustness through increased degrees-of-freedom. High quality reconstruction of\nfMRI data from undersampled measurements requires proper modeling of the data.\nWe present an fMRI reconstruction approach based on modeling the fMRI signal as\na sum of periodic and fixed rank components, for improved reconstruction from\nundersampled measurements. We decompose the fMRI signal into a component which\na has fixed rank and a component consisting of a sum of periodic signals which\nis sparse in the temporal Fourier domain. Data reconstruction is performed by\nsolving a constrained problem that enforces a fixed, moderate rank on one of\nthe components, and a limited number of temporal frequencies on the other. Our\napproach is coined PEAR - PEriodic And fixed Rank separation for fast fMRI.\n  Experimental results include purely synthetic simulation, a simulation with\nreal timecourses and retrospective undersampling of a real fMRI dataset.\nEvaluation was performed both quantitatively and visually versus ground truth,\ncomparing PEAR to two additional recent methods for fMRI reconstruction from\nundersampled measurements. Results demonstrate PEAR's improvement in estimating\nthe timecourses and activation maps versus the methods compared against at\nacceleration ratios of R=8,16 (for simulated data) and R=6.66,10 (for real\ndata). PEAR results in reconstruction with higher fidelity than when using a\nfixed-rank based model or a conventional Low-rank+Sparse algorithm. We have\nshown that splitting the functional information between the components leads to\nbetter modeling of fMRI, over state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jun 2017 08:16:11 GMT"}], "update_date": "2018-02-07", "authors_parsed": [["Weizman", "Lior", ""], ["Miller", "Karla L.", ""], ["Chiew", "Mark", ""], ["Eldar", "Yonina C.", ""]]}, {"id": "1706.04946", "submitter": "Stefano Fusi", "authors": "Stefano Fusi", "title": "Computational models of long term plasticity and memory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Memory is often defined as the mental capacity of retaining information about\nfacts, events, procedures and more generally about any type of previous\nexperience. Memories are remembered as long as they influence our thoughts,\nfeelings, and behavior at the present time. Memory is also one of the\nfundamental components of learning, our ability to acquire any type of\nknowledge or skills. In the brain it is not easy to identify the physical\nsubstrate of memory. Basically, any long-lasting alteration of a biochemical\nprocess can be considered a form of memory, although some of these alterations\nlast only a few milliseconds, and most of them, if taken individually, cannot\ninfluence our behavior. However, if we want to understand memory, we need to\nkeep in mind that memory is not a unitary phenomenon, and it certainly involves\nseveral distinct mechanisms that operate at different spatial and temporal\nlevels. One of the goals of theoretical neuroscience is to try to understand\nhow these processes are orchestrated to store memories rapidly and preserve\nthem over a lifetime. Theorists have mostly focused on synaptic plasticity, as\nit is one of the most studied memory mechanisms in experimental neuroscience\nand it is known to be highly effective in training artificial neural networks\nto perform real world tasks. Some of the synaptic plasticity models are purely\nphenomenological, some others have been designed to solve computational\nproblems. In this article I will review some of these models and I will try to\nidentify computational principles that underlie memory storage and\npreservation.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jun 2017 16:13:24 GMT"}], "update_date": "2017-06-16", "authors_parsed": [["Fusi", "Stefano", ""]]}, {"id": "1706.05395", "submitter": "Zachary Kilpatrick PhD", "authors": "Zachary P Kilpatrick", "title": "Synaptic mechanisms of interference in working memory", "comments": "28 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC math.PR nlin.PS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information from preceding trials of cognitive tasks can bias performance in\nthe current trial, a phenomenon referred to as interference. Subjects\nperforming visual working memory tasks exhibit interference in their\ntrial-to-trial response correlations: the recalled target location in the\ncurrent trial is biased in the direction of the target presented on the\nprevious trial. We present modeling work that (a) develops a probabilistic\ninference model of this history-dependent bias, and (b) links our probabilistic\nmodel to computations of a recurrent network wherein short-term facilitation\naccounts for the dynamics of the observed bias. Network connectivity is\nreshaped dynamically during each trial, providing a mechanism for generating\npredictions from prior trial observations. Applying timescale separation\nmethods, we can obtain a low-dimensional description of the trial-to-trial bias\nbased on the history of target locations. The model has response statistics\nwhose mean is centered at the true target location across many trials, typical\nof such visual working memory tasks. Furthermore, we demonstrate task protocols\nfor which the plastic model performs better than a model with static\nconnectivity: repetitively presented targets are better retained in working\nmemory than targets drawn from uncorrelated sequences.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jun 2017 18:14:17 GMT"}, {"version": "v2", "created": "Mon, 24 Jul 2017 15:02:43 GMT"}], "update_date": "2017-07-25", "authors_parsed": [["Kilpatrick", "Zachary P", ""]]}, {"id": "1706.05656", "submitter": "Stefan Frank", "authors": "Stefan Frank, Jinbiao Yang", "title": "Lexical representation explains cortical entrainment during speech\n  comprehension", "comments": "Submitted for publication", "journal-ref": null, "doi": "10.1371/journal.pone.0197304", "report-no": null, "categories": "q-bio.NC cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Results from a recent neuroimaging study on spoken sentence comprehension\nhave been interpreted as evidence for cortical entrainment to hierarchical\nsyntactic structure. We present a simple computational model that predicts the\npower spectra from this study, even though the model's linguistic knowledge is\nrestricted to the lexical level, and word-level representations are not\ncombined into higher-level units (phrases or sentences). Hence, the cortical\nentrainment results can also be explained from the lexical properties of the\nstimuli, without recourse to hierarchical syntax.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jun 2017 14:04:09 GMT"}, {"version": "v2", "created": "Wed, 12 Jul 2017 07:33:02 GMT"}, {"version": "v3", "created": "Thu, 20 Jul 2017 11:26:48 GMT"}, {"version": "v4", "created": "Mon, 9 Oct 2017 14:24:45 GMT"}, {"version": "v5", "created": "Wed, 3 Jan 2018 13:53:14 GMT"}, {"version": "v6", "created": "Wed, 10 Jan 2018 13:35:26 GMT"}], "update_date": "2018-06-15", "authors_parsed": [["Frank", "Stefan", ""], ["Yang", "Jinbiao", ""]]}, {"id": "1706.05702", "submitter": "Jeyashree Krishnan", "authors": "Jeyashree Krishnan, PierGianLuca Porta Mana, Moritz Helias, Markus\n  Diesmann, Edoardo Di Napoli", "title": "Perfect spike detection via time reversal", "comments": "9 figures, Preliminary results in proceedings of the Bernstein\n  Conference 2016", "journal-ref": null, "doi": "10.3389/fninf.2017.00075", "report-no": null, "categories": "q-bio.NC math.DG physics.bio-ph q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spiking neuronal networks are usually simulated with three main simulation\nschemes: the classical time-driven and event-driven schemes, and the more\nrecent hybrid scheme. All three schemes evolve the state of a neuron through a\nseries of checkpoints: equally spaced in the first scheme and determined\nneuron-wise by spike events in the latter two. The time-driven and the hybrid\nscheme determine whether the membrane potential of a neuron crosses a threshold\nat the end of of the time interval between consecutive checkpoints. Threshold\ncrossing can, however, occur within the interval even if this test is negative.\nSpikes can therefore be missed. The present work derives, implements, and\nbenchmarks a method for perfect retrospective spike detection. This method can\nbe applied to neuron models with affine or linear subthreshold dynamics. The\nidea behind the method is to propagate the threshold with a time-inverted\ndynamics, testing whether the threshold crosses the neuron state to be evolved,\nrather than vice versa. Algebraically this translates into a set of\ninequalities necessary and sufficient for threshold crossing. This test is\nslower than the imperfect one, but faster than an alternative perfect tests\nbased on bisection or root-finding methods. Comparison confirms earlier results\nthat the imperfect test rarely misses spikes (less than a fraction $1/10^8$ of\nmissed spikes) in biologically relevant settings. This study offers an\nalternative geometric point of view on neuronal dynamics.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jun 2017 19:13:26 GMT"}], "update_date": "2018-01-24", "authors_parsed": [["Krishnan", "Jeyashree", ""], ["Mana", "PierGianLuca Porta", ""], ["Helias", "Moritz", ""], ["Diesmann", "Markus", ""], ["Di Napoli", "Edoardo", ""]]}, {"id": "1706.05783", "submitter": "Yiyin Zhou", "authors": "Aurel A. Lazar and Nikul H. Ukani and Yiyin Zhou", "title": "Sparse Functional Identification of Complex Cells from Spike Times and\n  the Decoding of Visual Stimuli", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We investigate the sparse functional identification of complex cells and the\ndecoding of visual stimuli encoded by an ensemble of complex cells. The\nreconstruction algorithm of both temporal and spatio-temporal stimuli is\nformulated as a rank minimization problem that significantly reduces the number\nof sampling measurements (spikes) required for decoding. We also establish the\nduality between sparse decoding and functional identification, and provide\nalgorithms for identification of low-rank dendritic stimulus processors. The\nduality enables us to efficiently evaluate our functional identification\nalgorithms by reconstructing novel stimuli in the input space. Finally, we\ndemonstrate that our identification algorithms substantially outperform the\ngeneralized quadratic model, the non-linear input model and the widely used\nspike-triggered covariance algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jun 2017 04:50:26 GMT"}], "update_date": "2017-06-20", "authors_parsed": [["Lazar", "Aurel A.", ""], ["Ukani", "Nikul H.", ""], ["Zhou", "Yiyin", ""]]}, {"id": "1706.05796", "submitter": "Benoit Perthame", "authors": "Beno\\^it Perthame (MAMBA, LJLL), Delphine Salort (LCQB), Gilles\n  Wainrib (DI-ENS)", "title": "Distributed synaptic weights in a LIF neural network and learning rules", "comments": "Physica D: Nonlinear Phenomena, Elsevier, 2017", "journal-ref": null, "doi": "10.1016/j.physd.2017.05.005", "report-no": null, "categories": "q-bio.NC math.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Leaky integrate-and-fire (LIF) models are mean-field limits, with a large\nnumber of neurons, used to describe neural networks. We consider inhomogeneous\nnetworks structured by a connec-tivity parameter (strengths of the synaptic\nweights) with the effect of processing the input current with different\nintensities. We first study the properties of the network activity depending on\nthe distribution of synaptic weights and in particular its discrimination\ncapacity. Then, we consider simple learning rules and determine the synaptic\nweight distribution it generates. We outline the role of noise as a selection\nprinciple and the capacity to memorized a learned signal.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jun 2017 06:11:17 GMT"}], "update_date": "2017-06-20", "authors_parsed": [["Perthame", "Beno\u00eet", "", "MAMBA, LJLL"], ["Salort", "Delphine", "", "LCQB"], ["Wainrib", "Gilles", "", "DI-ENS"]]}, {"id": "1706.05899", "submitter": "Frederick Pothof", "authors": "F Pothof, L Bonini, M Lanzilotto, A Livi, L Fogassi, G A Orban, O\n  Paul, P Ruther", "title": "Chronic neural probe for simultaneous recording of single-unit,\n  multi-unit, and local field potential activity from multiple brain sites", "comments": null, "journal-ref": "Journal of neural engineering 13.4 (2016): 046006", "doi": "10.1088/1741-2560/13/4/046006", "report-no": null, "categories": "physics.med-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Drug resistant focal epilepsy can be treated by resecting the epileptic focus\nrequiring a precise focus localization using stereoelectroencephalography\n(SEEG) probes. As commercial SEEG probes offer only a limited spatial\nresolution, probes of higher channel count and design freedom enabling the\nincorporation of macro and microelectrodes would help increasing spatial\nresolution and thus open new perspectives for investigating mechanisms\nunderlying focal epilepsy and its treatment. This work describes a new\nfabrication process for SEEG probes with materials and dimensions similar to\nclinical probes enabling recording single neuron activity at high spatial\nresolution. Polyimide is used as a biocompatible flexible substrate into which\nplatinum electrodes and leads are...\n  The resulting probe features match those of clinically approved devices.\nTests in saline solution confirmed the probe stability and functionality.\nProbes were implanted into the brain of one monkey (Macaca mulatta), trained to\nperform different motor tasks. Suitable configurations including up to 128\nelectrode sites allow the recording of task-related neuronal signals. Probes\nwith 32 and 64 electrode sites were implanted in the posterior parietal cortex.\nLocal field potentials and multi-unit activity were recorded as early as one\nhour after implantation. Stable single-unit activity was achieved for up to 26\ndays after implantation of a 64-channel probe. All recorded signals showed\nmodulation during task execution. With the novel probes it is possible to\nrecord stable biologically relevant data over a time span exceeding the usual\ntime needed for epileptic focus localization in human patients. This is the\nfirst time that single units are recorded along cylindrical polyimide probes\nchronically implanted 22 mm deep into the brain of a monkey, which suggests the\npotential usefulness of this probe for human applications.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jun 2017 12:20:19 GMT"}], "update_date": "2017-06-20", "authors_parsed": [["Pothof", "F", ""], ["Bonini", "L", ""], ["Lanzilotto", "M", ""], ["Livi", "A", ""], ["Fogassi", "L", ""], ["Orban", "G A", ""], ["Paul", "O", ""], ["Ruther", "P", ""]]}, {"id": "1706.05932", "submitter": "Alessandro Fontana", "authors": "Alessandro Fontana", "title": "A deep learning-inspired model of the hippocampus as storage device of\n  the brain extended dataset", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The standard model of memory consolidation foresees that memories are\ninitially recorded in the hippocampus, while features that capture higher-level\ngeneralisations of data are created in the cortex, where they are stored for a\npossibly indefinite period of time. Computer scientists have sought inspiration\nfrom nature to build machines that exhibit some of the remarkable properties\npresent in biological systems. One of the results of this effort is represented\nby artificial neural networks, a class of algorithms that represent the state\nof the art in many artificial intelligence applications. In this work, we\nreverse the inspiration flow and use the experience obtained from neural\nnetworks to gain insight into the design of brain architecture and the\nfunctioning of memory. Our starting observation is that neural networks learn\nfrom data and need to be exposed to each data record many times during\nlearning: this requires the storage of the entire dataset in computer memory.\nOur thesis is that the same holds true for the brain and the main role of the\nhippocampus is to store the \"brain dataset\", from which high-level features are\nlearned and encoded in cortical neurons.\n", "versions": [{"version": "v1", "created": "Fri, 26 May 2017 15:21:43 GMT"}], "update_date": "2017-06-20", "authors_parsed": [["Fontana", "Alessandro", ""]]}, {"id": "1706.06031", "submitter": "Dmitry Petrov", "authors": "Dmitry Petrov, Alexander Ivanov, Joshua Faskowitz, Boris Gutman,\n  Daniel Moyer, Julio Villalon, Neda Jahanshad and Paul Thompson", "title": "Evaluating 35 Methods to Generate Structural Connectomes Using Pairwise\n  Classification", "comments": "Accepted for MICCAI 2017, 8 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is no consensus on how to construct structural brain networks from\ndiffusion MRI. How variations in pre-processing steps affect network\nreliability and its ability to distinguish subjects remains opaque. In this\nwork, we address this issue by comparing 35 structural connectome-building\npipelines. We vary diffusion reconstruction models, tractography algorithms and\nparcellations. Next, we classify structural connectome pairs as either\nbelonging to the same individual or not. Connectome weights and eight\ntopological derivative measures form our feature set. For experiments, we use\nthree test-retest datasets from the Consortium for Reliability and\nReproducibility (CoRR) comprised of a total of 105 individuals. We also compare\npairwise classification results to a commonly used parametric test-retest\nmeasure, Intraclass Correlation Coefficient (ICC).\n", "versions": [{"version": "v1", "created": "Mon, 19 Jun 2017 16:05:11 GMT"}], "update_date": "2017-06-20", "authors_parsed": [["Petrov", "Dmitry", ""], ["Ivanov", "Alexander", ""], ["Faskowitz", "Joshua", ""], ["Gutman", "Boris", ""], ["Moyer", "Daniel", ""], ["Villalon", "Julio", ""], ["Jahanshad", "Neda", ""], ["Thompson", "Paul", ""]]}, {"id": "1706.06088", "submitter": "Richard Betzel", "authors": "Richard F. Betzel, John D. Medaglia, Ari E. Kahn, Jonathan Soffer,\n  Daniel R. Schonhaut, Danielle S. Bassett", "title": "Inter-regional ECoG correlations predicted by communication dynamics,\n  geometry, and correlated gene expression", "comments": "36 pages, 4 figures + 2 tables (main text), 14 figures + 7 tables\n  (supplementary materials)", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electrocorticography (ECoG) provides direct measurements of synchronized\npostsynaptic potentials at the exposed cortical surface. Patterns of signal\ncovariance across ECoG sensors have been associated with diverse cognitive\nfunctions and remain a critical marker of seizure onset, progression, and\ntermination. Yet, a systems level understanding of these patterns (or networks)\nhas remained elusive, in part due to variable electrode placement and sparse\ncortical coverage. Here, we address these challenges by constructing\ninter-regional ECoG networks from multi-subject recordings, demonstrate\nsimilarities between these networks and those constructed from\nblood-oxygen-level-dependent signal in functional magnetic resonance imaging,\nand predict network topology from anatomical connectivity, interregional\ndistance, and correlated gene expression patterns. Our models accurately\npredict out-of-sample ECoG networks and perform well even when fit to data from\nindividual subjects, suggesting shared organizing principles across persons. In\naddition, we identify a set of genes whose brain-wide co-expression is highly\ncorrelated with ECoG network organization. Using gene ontology analysis, we\nshow that these same genes are enriched for membrane and ion channel\nmaintenance and function, suggesting a molecular underpinning of ECoG\nconnectivity. Our findings provide fundamental understanding of the factors\nthat influence interregional ECoG networks, and open the possibility for\npredictive modeling of surgical outcomes in disease.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jun 2017 17:58:20 GMT"}], "update_date": "2017-06-20", "authors_parsed": [["Betzel", "Richard F.", ""], ["Medaglia", "John D.", ""], ["Kahn", "Ari E.", ""], ["Soffer", "Jonathan", ""], ["Schonhaut", "Daniel R.", ""], ["Bassett", "Danielle S.", ""]]}, {"id": "1706.06208", "submitter": "William Kindel", "authors": "William F. Kindel, Elijah D. Christensen and Joel Zylberberg", "title": "Using deep learning to reveal the neural code for images in primary\n  visual cortex", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Primary visual cortex (V1) is the first stage of cortical image processing,\nand a major effort in systems neuroscience is devoted to understanding how it\nencodes information about visual stimuli. Within V1, many neurons respond\nselectively to edges of a given preferred orientation: these are known as\nsimple or complex cells, and they are well-studied. Other neurons respond to\nlocalized center-surround image features. Still others respond selectively to\ncertain image stimuli, but the specific features that excite them are unknown.\nMoreover, even for the simple and complex cells-- the best-understood V1\nneurons-- it is challenging to predict how they will respond to natural image\nstimuli. Thus, there are important gaps in our understanding of how V1 encodes\nimages. To fill this gap, we train deep convolutional neural networks to\npredict the firing rates of V1 neurons in response to natural image stimuli,\nand find that 15% of these neurons are within 10% of their theoretical limit of\npredictability. For these well predicted neurons, we invert the predictor\nnetwork to identify the image features (receptive fields) that cause the V1\nneurons to spike. In addition to those with previously-characterized receptive\nfields (Gabor wavelet and center-surround), we identify neurons that respond\npredictably to higher-level textural image features that are not localized to\nany particular region of the image.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jun 2017 23:13:54 GMT"}], "update_date": "2017-06-21", "authors_parsed": [["Kindel", "William F.", ""], ["Christensen", "Elijah D.", ""], ["Zylberberg", "Joel", ""]]}, {"id": "1706.06495", "submitter": "Michael Barros", "authors": "Stefanus A. Wirdatmadja, Michael Taynnan Barros, Yevgeni Koucheryavy,\n  Josep Miquel Jornet, Sasitharan Balasubramaniam", "title": "Wireless Optogenetic Nanonetworks: Device Model and Charging Protocols", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, numerous research efforts have been dedicated towards\ndeveloping efficient implantable devices for brain stimulation. However, there\nare limitations and challenges with the current technologies. Firstly, the\nstimulation of neurons currently is possible through implantable electrodes but\nlimited to a population of neurons. Secondly, a major hurdle lies in developing\nminiature devices that can last for a lifetime in the patient's brain. In\nparallel, Optogenetics has emerged proposing the stimulation of neurons using\nlight by means of optical fibers inserted through the skull. Many challenges\nare thus introduced in terms of suitability to patient's lifestyle and\nbiocompatibility. We have recently proposed the concept of wireless optogenetic\nnanonetworking devices (WiOptND), addressing these long-term deployment\nproblems, and at the same time targeting single neuron stimulation [1]. The\nWiOptND is equipped with a miniature LED that is able to stimulate a\ngenetically engineered neuron while harvesting energy from ultrasonic\nvibrations. This paper investigates how light propagates in the brain tissue,\nand based on the power required to emit sufficient intensity for stimulation,\nan energy harvesting circuitry is designed. A number of charging protocols are\nalso proposed to maximize energy efficiency while ensuring minimum number of\nneural spike misfirings. These protocols include the Charge and Fire, the\nPredictive Sliding Detection Window, and its variant Markov-Chain based\nTime-Delay Patterns. Simulation results show the drop of stimulation ratio for\n25% and more stable trend in its efficiency ratio are exhibited on Markov-Chain\nbased Time-Delay Patterns compared to Change and Fire. The results show the\nfeasibility of utilizing WiOptND for long-term implants, and a new direction\ntowards precise stimulation of neurons in the cortical columns of the brain.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jun 2017 14:48:31 GMT"}], "update_date": "2017-06-21", "authors_parsed": [["Wirdatmadja", "Stefanus A.", ""], ["Barros", "Michael Taynnan", ""], ["Koucheryavy", "Yevgeni", ""], ["Jornet", "Josep Miquel", ""], ["Balasubramaniam", "Sasitharan", ""]]}, {"id": "1706.06699", "submitter": "Amirhossein Tavanaei", "authors": "Amirhossein Tavanaei, Timothee Masquelier, Anthony Maida", "title": "Representation Learning using Event-based STDP", "comments": null, "journal-ref": "Neural Networks, vol. 105, pp. 294-303, 2018", "doi": "10.1016/j.neunet.2018.05.018", "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although representation learning methods developed within the framework of\ntraditional neural networks are relatively mature, developing a spiking\nrepresentation model remains a challenging problem. This paper proposes an\nevent-based method to train a feedforward spiking neural network (SNN) layer\nfor extracting visual features. The method introduces a novel\nspike-timing-dependent plasticity (STDP) learning rule and a threshold\nadjustment rule both derived from a vector quantization-like objective function\nsubject to a sparsity constraint. The STDP rule is obtained by the gradient of\na vector quantization criterion that is converted to spike-based,\nspatio-temporally local update rules in a spiking network of leaky,\nintegrate-and-fire (LIF) neurons. Independence and sparsity of the model are\nachieved by the threshold adjustment rule and by a softmax function\nimplementing inhibition in the representation layer consisting of\nWTA-thresholded spiking neurons. Together, these mechanisms implement a form of\nspike-based, competitive learning. Two sets of experiments are performed on the\nMNIST and natural image datasets. The results demonstrate a sparse spiking\nvisual representation model with low reconstruction loss comparable with\nstate-of-the-art visual coding approaches, yet our rule is local in both time\nand space, thus biologically plausible and hardware friendly.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jun 2017 23:13:31 GMT"}, {"version": "v2", "created": "Thu, 2 Nov 2017 01:26:09 GMT"}, {"version": "v3", "created": "Fri, 9 Mar 2018 17:24:56 GMT"}], "update_date": "2018-06-15", "authors_parsed": [["Tavanaei", "Amirhossein", ""], ["Masquelier", "Timothee", ""], ["Maida", "Anthony", ""]]}, {"id": "1706.06914", "submitter": "Mauro M. Monsalve-Mercado", "authors": "Mauro M. Monsalve-Mercado, Christian Leibold", "title": "Hippocampal Spike-Timing Correlations Lead to Hexagonal Grid Fields", "comments": "Accepted for publication in Physical Review Letters", "journal-ref": null, "doi": "10.1103/PhysRevLett.119.038101", "report-no": null, "categories": "q-bio.NC nlin.AO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Space is represented in the mammalian brain by the activity of hippocampal\nplace cells as well as in their spike-timing correlations. Here we propose a\ntheory how this temporal code is transformed to spatial firing rate patterns\nvia spike-timing-dependent synaptic plasticity. The resulting dynamics of\nsynaptic weights resembles well-known pattern formation models in which a\nlateral inhibition mechanism gives rise to a Turing instability. We identify\nparameter regimes in which hexagonal firing patterns develop as they have been\nfound in medial entorhinal cortex.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jun 2017 14:05:52 GMT"}], "update_date": "2017-08-02", "authors_parsed": [["Monsalve-Mercado", "Mauro M.", ""], ["Leibold", "Christian", ""]]}, {"id": "1706.06969", "submitter": "Robert Geirhos", "authors": "Robert Geirhos, David H. J. Janssen, Heiko H. Sch\\\"utt, Jonas Rauber,\n  Matthias Bethge, Felix A. Wichmann", "title": "Comparing deep neural networks against humans: object recognition when\n  the signal gets weaker", "comments": "updated article with reference to resulting publication (Geirhos et\n  al, NeurIPS 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human visual object recognition is typically rapid and seemingly effortless,\nas well as largely independent of viewpoint and object orientation. Until very\nrecently, animate visual systems were the only ones capable of this remarkable\ncomputational feat. This has changed with the rise of a class of computer\nvision algorithms called deep neural networks (DNNs) that achieve human-level\nclassification performance on object recognition tasks. Furthermore, a growing\nnumber of studies report similarities in the way DNNs and the human visual\nsystem process objects, suggesting that current DNNs may be good models of\nhuman visual object recognition. Yet there clearly exist important\narchitectural and processing differences between state-of-the-art DNNs and the\nprimate visual system. The potential behavioural consequences of these\ndifferences are not well understood. We aim to address this issue by comparing\nhuman and DNN generalisation abilities towards image degradations. We find the\nhuman visual system to be more robust to image manipulations like contrast\nreduction, additive noise or novel eidolon-distortions. In addition, we find\nprogressively diverging classification error-patterns between humans and DNNs\nwhen the signal gets weaker, indicating that there may still be marked\ndifferences in the way humans and current DNNs perform visual object\nrecognition. We envision that our findings as well as our carefully measured\nand freely available behavioural datasets provide a new useful benchmark for\nthe computer vision community to improve the robustness of DNNs and a\nmotivation for neuroscientists to search for mechanisms in the brain that could\nfacilitate this robustness.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jun 2017 15:46:52 GMT"}, {"version": "v2", "created": "Tue, 11 Dec 2018 17:06:24 GMT"}], "update_date": "2018-12-12", "authors_parsed": [["Geirhos", "Robert", ""], ["Janssen", "David H. J.", ""], ["Sch\u00fctt", "Heiko H.", ""], ["Rauber", "Jonas", ""], ["Bethge", "Matthias", ""], ["Wichmann", "Felix A.", ""]]}, {"id": "1706.07147", "submitter": "Kevin Feigelis", "authors": "Kevin T. Feigelis and Daniel L. K. Yamins", "title": "A Useful Motif for Flexible Task Learning in an Embodied Two-Dimensional\n  Visual Environment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Animals (especially humans) have an amazing ability to learn new tasks\nquickly, and switch between them flexibly. How brains support this ability is\nlargely unknown, both neuroscientifically and algorithmically. One reasonable\nsupposition is that modules drawing on an underlying general-purpose sensory\nrepresentation are dynamically allocated on a per-task basis. Recent results\nfrom neuroscience and artificial intelligence suggest the role of the general\npurpose visual representation may be played by a deep convolutional neural\nnetwork, and give some clues how task modules based on such a representation\nmight be discovered and constructed. In this work, we investigate module\narchitectures in an embodied two-dimensional touchscreen environment, in which\nan agent's learning must occur via interactions with an environment that emits\nimages and rewards, and accepts touches as input. This environment is designed\nto capture the physical structure of the task environments that are commonly\ndeployed in visual neuroscience and psychophysics. We show that in this\ncontext, very simple changes in the nonlinear activations used by such a module\ncan significantly influence how fast it is at learning visual tasks and how\nsuitable it is for switching to new tasks.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jun 2017 02:07:14 GMT"}], "update_date": "2017-06-23", "authors_parsed": [["Feigelis", "Kevin T.", ""], ["Yamins", "Daniel L. K.", ""]]}, {"id": "1706.07220", "submitter": "Rembrandt Bakker", "authors": "Paul Tiesinga, Rembrandt Bakker, Sean Hill, and Jan G. Bjaalie", "title": "Feeding the human brain model", "comments": "Figures are reprints from other publications, we are verifying\n  whether we can include them in this submission", "journal-ref": null, "doi": "10.1016/j.conb.2015.02.003", "report-no": null, "categories": "q-bio.QM q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of the Human Brain Project is to develop during the next decade an\ninfrastructure necessary for running a simulation of the entire human brain\nconstrained by current experimental data. One of the key issues is therefore to\nintegrate and make accessible the experimental data necessary to constrain and\nfully specify this model. The required data covers many different spatial\nscales, ranging from the molecular scale to the whole brain and these data are\nobtained using a variety of techniques whose measurements may not be directly\ncomparable. Furthermore, these data are incomplete, and will remain so at least\nfor the coming decade. Here we review new neuroinformatics techniques that need\nto be developed and applied to address these issues.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jun 2017 09:24:41 GMT"}], "update_date": "2017-06-23", "authors_parsed": [["Tiesinga", "Paul", ""], ["Bakker", "Rembrandt", ""], ["Hill", "Sean", ""], ["Bjaalie", "Jan G.", ""]]}, {"id": "1706.07555", "submitter": "Chengxu Zhuang", "authors": "Chengxu Zhuang, Jonas Kubilius, Mitra Hartmann, Daniel Yamins", "title": "Toward Goal-Driven Neural Network Models for the Rodent\n  Whisker-Trigeminal System", "comments": "17 pages including supplementary information, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In large part, rodents see the world through their whiskers, a powerful\ntactile sense enabled by a series of brain areas that form the\nwhisker-trigeminal system. Raw sensory data arrives in the form of mechanical\ninput to the exquisitely sensitive, actively-controllable whisker array, and is\nprocessed through a sequence of neural circuits, eventually arriving in\ncortical regions that communicate with decision-making and memory areas.\nAlthough a long history of experimental studies has characterized many aspects\nof these processing stages, the computational operations of the\nwhisker-trigeminal system remain largely unknown. In the present work, we take\na goal-driven deep neural network (DNN) approach to modeling these\ncomputations. First, we construct a biophysically-realistic model of the rat\nwhisker array. We then generate a large dataset of whisker sweeps across a wide\nvariety of 3D objects in highly-varying poses, angles, and speeds. Next, we\ntrain DNNs from several distinct architectural families to solve a shape\nrecognition task in this dataset. Each architectural family represents a\nstructurally-distinct hypothesis for processing in the whisker-trigeminal\nsystem, corresponding to different ways in which spatial and temporal\ninformation can be integrated. We find that most networks perform poorly on the\nchallenging shape recognition task, but that specific architectures from\nseveral families can achieve reasonable performance levels. Finally, we show\nthat Representational Dissimilarity Matrices (RDMs), a tool for comparing\npopulation codes between neural systems, can separate these higher-performing\nnetworks with data of a type that could plausibly be collected in a\nneurophysiological or imaging experiment. Our results are a proof-of-concept\nthat goal-driven DNN networks of the whisker-trigeminal system are potentially\nwithin reach.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jun 2017 03:34:03 GMT"}], "update_date": "2017-06-27", "authors_parsed": [["Zhuang", "Chengxu", ""], ["Kubilius", "Jonas", ""], ["Hartmann", "Mitra", ""], ["Yamins", "Daniel", ""]]}, {"id": "1706.08041", "submitter": "Pavitra Krishnaswamy", "authors": "Pavitra Krishnaswamy, Gabriel Obregon-Henao, Jyrki Ahveninen, Sheraz\n  Khan, Behtash Babadi, Juan Eugenio Iglesias, Matti S. Hamalainen, Patrick L.\n  Purdon", "title": "Sparsity Enables Estimation of both Subcortical and Cortical Activity\n  from MEG and EEG", "comments": "12 pages with 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM q-bio.NC stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Subcortical structures play a critical role in brain function. However,\noptions for assessing electrophysiological activity in these structures are\nlimited. Electromagnetic fields generated by neuronal activity in subcortical\nstructures can be recorded non-invasively using magnetoencephalography (MEG)\nand electroencephalography (EEG). However, these subcortical signals are much\nweaker than those due to cortical activity. In addition, we show here that it\nis difficult to resolve subcortical sources, because distributed cortical\nactivity can explain the MEG and EEG patterns due to deep sources. We then\ndemonstrate that if the cortical activity can be assumed to be spatially\nsparse, both cortical and subcortical sources can be resolved with M/EEG.\nBuilding on this insight, we develop a novel hierarchical sparse inverse\nsolution for M/EEG. We assess the performance of this algorithm on realistic\nsimulations and auditory evoked response data and show that thalamic and\nbrainstem sources can be correctly estimated in the presence of cortical\nactivity. Our analysis and method suggest new opportunities and offer practical\ntools for characterizing electrophysiological activity in the subcortical\nstructures of the human brain.\n", "versions": [{"version": "v1", "created": "Sun, 25 Jun 2017 06:52:23 GMT"}], "update_date": "2017-06-27", "authors_parsed": [["Krishnaswamy", "Pavitra", ""], ["Obregon-Henao", "Gabriel", ""], ["Ahveninen", "Jyrki", ""], ["Khan", "Sheraz", ""], ["Babadi", "Behtash", ""], ["Iglesias", "Juan Eugenio", ""], ["Hamalainen", "Matti S.", ""], ["Purdon", "Patrick L.", ""]]}, {"id": "1706.08138", "submitter": "Maurizio De Pitt\\`a", "authors": "Valeri Matrosov, Susan Gordleeva, Natalia Boldyreva, Eshel Ben-Jacob,\n  Alexey Semyanov, Victor Kazantsev and Maurizio De Pitt\\`a", "title": "Emergence of regular and complex calcium oscillations by inositol\n  1,4,5-trisphosphate signaling in astrocytes", "comments": "19 pages (24 pages with References), 1 table, 5 figures, book chapter", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use tools of bifurcation theory to characterize dynamics of\nastrocytic~IP$_3$ and~Ca$^{2+}$ for different~IP$_3$ regimes from a\nmathematical point of view. We do so following a bottom-up approach, starting\nfrom a compact, well-stirred astrocyte model to first identify\ncharacteristic~IP$_3$ pathways whereby~Ca$^{2+}$ (and~IP$_3$) dynamics\n\"bifurcate\", namely change from stable (constant) concentration levels, to\noscillatory dynamics. Then we extend our analysis to the elemental case of two\nastrocytes, coupled by~IP$_3$ diffusion mediated by gap junction channels,\nputting emphasis on the mechanisms of emergence of chaotic oscillations.\nFinally, we complete our analysis discussing spatiotemporal~Ca$^{2+}$ dynamics\nin a spatially-extended astrocyte model, gaining insights on the possible\nphysical mechanisms whereby random Ca$^{2+}$~generation could be orchestrated\ninto robust, spatially-confined intracellular~Ca$^{2+}$ oscillations.\n", "versions": [{"version": "v1", "created": "Sun, 25 Jun 2017 16:39:03 GMT"}], "update_date": "2017-06-27", "authors_parsed": [["Matrosov", "Valeri", ""], ["Gordleeva", "Susan", ""], ["Boldyreva", "Natalia", ""], ["Ben-Jacob", "Eshel", ""], ["Semyanov", "Alexey", ""], ["Kazantsev", "Victor", ""], ["De Pitt\u00e0", "Maurizio", ""]]}, {"id": "1706.08202", "submitter": "Arian Ashourvan", "authors": "Arian Ashourvan, S\\'ergio Pequito, Ankit N. Khambhati, Steven N.\n  Baldassano, Kathryn A. Davis, Timothy Lucas, Jean M. Vettel, Brian Litt,\n  George J. Pappas, Danielle S. Bassett", "title": "Parsing spatiotemporal dynamical stability in ECoG during seizure onset,\n  propagation, and termination", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding brain dynamics in epilepsy is critical for establishing\nrigorous control objectives that enable new therapeutic methods to mitigate\nseizure occurrence. In multichannel electrocorticography (ECoG) recordings\nacquired in 21 subjects during a total of 94 seizures, we apply dynamical\nsystems stability analysis to assess the balance versus imbalance of seizure\ndynamics across different timescales and brain regions. Specifically, we\nconsider a sliding time window multivariate autoregressive linear approximation\nof the data captured by the ECoG channels, where eigendecomposition of the\nestimated matrix of coefficients describes the contribution of different\nregions to the spatiotemporal process (eigenvectors) associated with a\nparticular timescale (eigenvalues). Interestingly, we observe a pattern of\neigenvalue evolution and slowly changing (or approximately time-invariant)\neigenvectors across both seizures and subjects. The seizure-onset is marked by\nan increase in high frequency spatial information to which a few regions\ncontribute for a long period. By contrast, the seizure termination is\ncharacterized by a sudden, small time period change in dynamics to which many\nregions contribute. As the seizure terminates, the relatively stable ictal\ndynamics rapidly transition into the post-ictal regime, marked by relatively\nfast-damping oscillations. Our methodology offers a subject-specific\ncharacterization of the spatiotemporal behavior of the seizure, providing new\ninsights into the dynamic patterns and functional interactions between brain\nregions that occur over different timescales. More generally, our approach\ninforms the development of engineering objectives that can be used to deploy\nnew control strategies to prevent seizure evolution or to hasten seizure\ntermination.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jun 2017 01:24:50 GMT"}], "update_date": "2017-06-27", "authors_parsed": [["Ashourvan", "Arian", ""], ["Pequito", "S\u00e9rgio", ""], ["Khambhati", "Ankit N.", ""], ["Baldassano", "Steven N.", ""], ["Davis", "Kathryn A.", ""], ["Lucas", "Timothy", ""], ["Vettel", "Jean M.", ""], ["Litt", "Brian", ""], ["Pappas", "George J.", ""], ["Bassett", "Danielle S.", ""]]}, {"id": "1706.08584", "submitter": "Stephanie Elizabeth Palmer", "authors": "Audrey J. Sederberg, Jason N. MacLean, Stephanie E. Palmer", "title": "Learning to make external sensory stimulus predictions using internal\n  correlations in populations of neurons", "comments": "36 pages, 5 figures, 3 supplemental figures", "journal-ref": "Proc Natl Acad Sci USA January 30, 2018 115 (5) 1105-1110", "doi": "10.1073/pnas.1710779115", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To compensate for sensory processing delays, the visual system must make\npredictions to ensure timely and appropriate behaviors. Recent work has found\npredictive information about the stimulus in neural populations early in vision\nprocessing, starting in the retina. However, to utilize this information, cells\ndownstream must in turn be able to read out the predictive information from the\nspiking activity of retinal ganglion cells. Here we investigate whether a\ndownstream cell could learn efficient encoding of predictive information in its\ninputs in the absence of other instructive signals, from the correlations in\nthe inputs themselves. We simulate learning driven by spiking activity recorded\nin salamander retina. We model a downstream cell as a binary neuron receiving a\nsmall group of weighted inputs and quantify the predictive information between\nactivity in the binary neuron and future input. Input weights change according\nto spike timing-dependent learning rules during a training period. We\ncharacterize the readouts learned under spike timing-dependent learning rules,\nfinding that although the fixed points of learning dynamics are not associated\nwith absolute optimal readouts, they convey nearly all the information conveyed\nby the optimal readout. Moreover, we find that learned perceptrons transmit\nposition and velocity information of a moving bar stimulus nearly as\nefficiently as optimal perceptrons. We conclude that predictive information is,\nin principle, readable from the perspective of downstream neurons in the\nabsence of other inputs, and consequently suggests that bottom-up prediction\nmay play an important role in sensory processing.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jun 2017 20:32:40 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Sederberg", "Audrey J.", ""], ["MacLean", "Jason N.", ""], ["Palmer", "Stephanie E.", ""]]}, {"id": "1706.08884", "submitter": "El Mahdi El Mhamdi", "authors": "El Mahdi El Mhamdi and Rachid Guerraoui", "title": "When Neurons Fail", "comments": "2017 IEEE International Parallel and Distributed Processing\n  Symposium, Orlando, Florida", "journal-ref": null, "doi": "10.1109/IPDPS.2017.66", "report-no": null, "categories": "stat.ML cs.DC cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We view a neural network as a distributed system of which neurons can fail\nindependently, and we evaluate its robustness in the absence of any (recovery)\nlearning phase. We give tight bounds on the number of neurons that can fail\nwithout harming the result of a computation. To determine our bounds, we\nleverage the fact that neural activation functions are Lipschitz-continuous.\nOur bound is on a quantity, we call the \\textit{Forward Error Propagation},\ncapturing how much error is propagated by a neural network when a given number\nof components is failing, computing this quantity only requires looking at the\ntopology of the network, while experimentally assessing the robustness of a\nnetwork requires the costly experiment of looking at all the possible inputs\nand testing all the possible configurations of the network corresponding to\ndifferent failure situations, facing a discouraging combinatorial explosion.\n  We distinguish the case of neurons that can fail and stop their activity\n(crashed neurons) from the case of neurons that can fail by transmitting\narbitrary values (Byzantine neurons). Interestingly, as we show in the paper,\nour bound can easily be extended to the case where synapses can fail.\n  We show how our bound can be leveraged to quantify the effect of memory cost\nreduction on the accuracy of a neural network, to estimate the amount of\ninformation any neuron needs from its preceding layer, enabling thereby a\nboosting scheme that prevents neurons from waiting for unnecessary signals. We\nfinally discuss the trade-off between neural networks robustness and learning\ncost.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jun 2017 14:31:09 GMT"}], "update_date": "2017-06-28", "authors_parsed": [["Mhamdi", "El Mahdi El", ""], ["Guerraoui", "Rachid", ""]]}, {"id": "1706.09089", "submitter": "Jing Jin", "authors": "Jing Jin, Brendan Z. Allison, Yu Zhang, Yan Chen, Sijie Zhou, Yi Dong,\n  Xingyu Wang and Andrzej Chchocki", "title": "Continuous use of ERP-based BCIs with different visual angles in ALS\n  patients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objective: Amyotrophic lateral sclerosis (ALS) is a rare disease, but is also\none of the most common motor neuron diseases, and people of all races and\nethnic backgrounds are affected. There is currently no cure. Brain computer\ninterfaces (BCIs) can establish a communication channel directly between the\nbrain and an external device by recognizing brain activities that reflect user\nintent. Therefore, this technology could help ALS patients in promoting\nfunctional independence through BCI-based speller systems and motor assistive\ndevices. Methods: In this paper, two kinds of ERP-based speller systems were\ntested on 18 ALS patients to: (1) assess performance when they spelled 42\ncharacters online continuously, without a break; and (2) to compare performance\nbetween a matrix-based speller paradigm (MS-P, mean visual angle 6 degree) and\na new speller paradigm that used a larger visual angle called the large visual\nangle speller paradigm (LS-P, mean visual angle 8 degree). Results: Although\nresults showed that there were no significant differences between the two\nparadigms in accuracy trend over continuous use (p>0.05), the fatigue during\nthe LS-P condition was significantly lower than that of MS-P (p<0.05). Results\nalso showed that continuous use slightly reduced the performance of this\nERP-based BCI. Conclusion: 15 subjects obtained higher than 80% feedback\naccuracy (online output accuracy) and 9 subjects obtained higher than 90%\nfeedback accuracy in one of the two paradigms, thus validating the BCI\napproaches in this study. Significance: Most ALS subjects in this study could\nspell effectively after continuous use of an ERP-based BCI. The new LS-P\ndisplay may be easier for subjects to use, resulting in lower fatigue.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jun 2017 00:52:17 GMT"}], "update_date": "2017-06-29", "authors_parsed": [["Jin", "Jing", ""], ["Allison", "Brendan Z.", ""], ["Zhang", "Yu", ""], ["Chen", "Yan", ""], ["Zhou", "Sijie", ""], ["Dong", "Yi", ""], ["Wang", "Xingyu", ""], ["Chchocki", "Andrzej", ""]]}, {"id": "1706.09570", "submitter": "Nithin Nagaraj", "authors": "Suresh Jois and Nithin Nagaraj", "title": "Simulation Study of Two Measures of Integrated Information", "comments": "10 pages, 3 figures. The work reported in this paper, in summary\n  form, was presented as a poster at The Science of Consciousness (TSC)\n  Conference, June 5-10, held at La Jolla, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: Many authors have proposed Quantitative Theories of Consciousness\n(QTC) based on theoretical principles like information theory, Granger\ncausality and complexity. Recently, Virmani and Nagaraj (arXiv:1608.08450v2\n[cs.IT]) noted the similarity between Integrated Information and\nCompression-Complexity, and on this basis, proposed a novel measure of network\ncomplexity called Phi-Compression Complexity (Phi-C or $\\Phi^C$). Their\ncomputer simulations using Boolean networks showed that $\\Phi^C$ compares\nfavorably to Giulio Tononi et al's Integrated Information measure $\\Phi$ 3.0\nand exhibits desirable mathematical and computational characteristics. Methods:\nIn the present work, $\\Phi^C$ was measured for two types of simulated networks:\n(A) Networks representing simple neuronal connectivity motifs (presented in\nFig.9 of Tononi and Sporns, BMC Neuroscience 4(1), 2003); (B) random networks\nderived from Erd\\\"os-R \\'enyi G(N, p)graphs. Code for all simulations was\nwritten in Python 3.6, and the library NetworkX was used to simulate the\ngraphs. Results and discussions summary: In simulations A, for the same set of\nnetworks, $\\Phi^C$ values differ from the values of IIT 1.0 $\\Phi$ in a\ncounter-intuitive manner. It appears that $\\Phi^C$ captures some invariant\naspects of the interplay between information integration, network topology,\ngraph composition and node entropy. While Virmani and Nagaraj\n(arXiv:1608.08450v2 [cs.IT]) sought to highlight the correlations between\n$\\Phi^C$ and IIT $\\Phi$, the results of simulations A highlight the differences\nbetween the two measures in the way they capture the integrated information. In\nsimulations B, the results of simulations A are extended to the more general\ncase of random networks. In the concluding section we outline the novel aspects\nof this paper, and our ongoing and future research.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jun 2017 04:06:01 GMT"}], "update_date": "2017-06-30", "authors_parsed": [["Jois", "Suresh", ""], ["Nagaraj", "Nithin", ""]]}, {"id": "1706.09667", "submitter": "Maxinder S. Kanwal", "authors": "Maxinder S. Kanwal, Joshua A. Grochow, Nihat Ay", "title": "Comparing Information-Theoretic Measures of Complexity in Boltzmann\n  Machines", "comments": "16 pages, 7 figures; Appears in Entropy, Special Issue \"Information\n  Geometry II\"", "journal-ref": "Entropy (2017), 19(7), 310", "doi": "10.3390/e19070310", "report-no": null, "categories": "cs.IT cs.NE math.IT q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the past three decades, many theoretical measures of complexity have been\nproposed to help understand complex systems. In this work, for the first time,\nwe place these measures on a level playing field, to explore the qualitative\nsimilarities and differences between them, and their shortcomings.\nSpecifically, using the Boltzmann machine architecture (a fully connected\nrecurrent neural network) with uniformly distributed weights as our model of\nstudy, we numerically measure how complexity changes as a function of network\ndynamics and network parameters. We apply an extension of one such\ninformation-theoretic measure of complexity to understand incremental Hebbian\nlearning in Hopfield networks, a fully recurrent architecture model of\nautoassociative memory. In the course of Hebbian learning, the total\ninformation flow reflects a natural upward trend in complexity as the network\nattempts to learn more and more patterns.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jun 2017 10:39:15 GMT"}, {"version": "v2", "created": "Sun, 30 Jul 2017 01:01:49 GMT"}], "update_date": "2017-08-01", "authors_parsed": [["Kanwal", "Maxinder S.", ""], ["Grochow", "Joshua A.", ""], ["Ay", "Nihat", ""]]}, {"id": "1706.10058", "submitter": "Patrick Ruther", "authors": "Patrick Ruther, Oliver Paul", "title": "New approaches for CMOS-based devices for large-scale neural recording", "comments": null, "journal-ref": "Current Opinion in Neurobiology, 32, 31-37 (2015)", "doi": "10.1016/j.conb.2014.10.007", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extracellular, large scale in vivo recording of neural activity is mandatory\nfor elucidating the interaction of neurons within large neural networks at the\nlevel of their single unit activity. Technological achievements in MEMS-based\nmultichannel electrode arrays offer electrophysiological recording capabilities\nthat go far beyond those of classical wire electrodes. Despite their impressive\nchannel counts, recording systems with modest interconnection overhead have\nbeen demonstrated thanks to the hybrid integration of CMOS circuitry for signal\npreprocessing and data handling. The number of addressable channels is\nincreased even further by a switch matrix for electrode selection co-integrated\nalong the slender probe shafts. When realized by IC fabrication technologies,\nthese probes offer highest recording site densities along the entire shaft\nlength.\n", "versions": [{"version": "v1", "created": "Fri, 30 Jun 2017 08:28:59 GMT"}], "update_date": "2017-07-03", "authors_parsed": [["Ruther", "Patrick", ""], ["Paul", "Oliver", ""]]}, {"id": "1706.10297", "submitter": "Johnson Keiriz", "authors": "Johnson J.G. Keiriz, Liang Zhan, Morris Chukhman, Olu Ajilore, Alex D.\n  Leow, and Angus G. Forbes", "title": "Exploring the Human Connectome Topology in Group Studies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visually comparing brain networks, or connectomes, is an essential task in\nthe field of neuroscience. Especially relevant to the field of clinical\nneuroscience, group studies that examine differences between populations or\nchanges over time within a population enable neuroscientists to reason about\neffective diagnoses and treatments for a range of neuropsychiatric disorders.\nIn this paper, we specifically explore how visual analytics tools can be used\nto facilitate various clinical neuroscience tasks, in which observation and\nanalysis of meaningful patterns in the connectome can support patient diagnosis\nand treatment. We conduct a survey of visualization tasks that enable clinical\nneuroscience activities, and further explore how existing connectome\nvisualization tools support or fail to support these tasks. Based on our\ninvestigation of these tasks, we introduce a novel visualization tool,\nNeuroCave, to support group studies analyses. We discuss how our design\ndecisions (the use of immersive visualization, the use of hierarchical\nclustering and dimensionality reduction techniques, and the choice of visual\nencodings) are motivated by these tasks. We evaluate NeuroCave through two use\ncases that illustrate the utility of interactive connectome visualization in\nclinical neuroscience contexts. In the first use case, we study sex differences\nusing functional connectomes and discover hidden connectome patterns associated\nwith well-known cognitive differences in spatial and verbal abilities. In the\nsecond use case, we show how the utility of visualizing the brain in different\ntopological space coupled with clustering information can reveal the brain's\nintrinsic structure.\n", "versions": [{"version": "v1", "created": "Fri, 30 Jun 2017 17:59:14 GMT"}], "update_date": "2017-07-03", "authors_parsed": [["Keiriz", "Johnson J. G.", ""], ["Zhan", "Liang", ""], ["Chukhman", "Morris", ""], ["Ajilore", "Olu", ""], ["Leow", "Alex D.", ""], ["Forbes", "Angus G.", ""]]}]