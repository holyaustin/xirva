[{"id": "2101.00065", "submitter": "Alec Helm", "authors": "Alec Helm, Ann S. Blevins, and Danielle S. Bassett", "title": "The growing topology of the C. elegans connectome", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC math.AT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probing the developing neural circuitry in Caenorhabditis elegans has\nenhanced our understanding of nervous systems. The C. elegans connectome, like\nthose of other species, is characterized by a rich club of densely connected\nneurons embedded within a small-world architecture. This organization of\nneuronal connections, captured by quantitative network statistics, provides\ninsight into the system's capacity to perform integrative computations. Yet\nthese network measures are limited in their ability to detect weakly connected\nmotifs, such as topological cavities, that may support the systems capacity to\nperform segregated computations. We address this limitation by using persistent\nhomology to track the evolution of topological cavities in the growing C.\nelegans connectome throughout neural development, and assess the degree to\nwhich the growing connectomes topology is resistant to biological noise. We\nshow that the developing connectome topology is both relatively robust to\nchanges in neuron birth times and not captured by similar growth models.\nAdditionally, we quantify the consequence of a neurons specific birth time and\nask if this metric tracks other biological properties of neurons. Our results\nsuggest that the connectomes growing topology is a robust feature of the\ndeveloping connectome that is distinct from other network properties, and that\nthe growing topology is particularly sensitive to the exact birth times of a\nsmall set of predominantly motor neurons. By utilizing novel measurements that\ntrack biological features, we anticipate that our study will be helpful in the\nconstruction of more accurate models of neuronal development in C. elegans\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 20:41:32 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Helm", "Alec", ""], ["Blevins", "Ann S.", ""], ["Bassett", "Danielle S.", ""]]}, {"id": "2101.00500", "submitter": "Akke Mats Houben", "authors": "Akke Mats Houben", "title": "Signal anticipation and delay in excitable media: group delay of the\n  FitzHugh-Nagumo model", "comments": "9 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC nlin.CD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An expression for the group delay of the FitzHugh-Nagumo model in response to\nlow amplitude input is obtained by linearisation of the cubic term of the\nvoltage equation around its stable fixed-point. It is found that a negative\ngroup delay exists for low frequencies, indicating that the evolution of slowly\nfluctuating signals are anticipated by the voltage dynamics. The effects of the\ngroup delay for different types of signals are shown numerically for the\nnon-linearised FitzHugh-Nagumo model, and some observations on the signal\naspects that are anticipated are stated.\n", "versions": [{"version": "v1", "created": "Sat, 2 Jan 2021 19:14:24 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Houben", "Akke Mats", ""]]}, {"id": "2101.01533", "submitter": "John Tsotsos", "authors": "John K. Tsotsos, Omar Abid, Iuliia Kotseruba, Markus D. Solbach", "title": "On the Control of Attentional Processes in Vision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC cs.CV cs.LG q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The study of attentional processing in vision has a long and deep history.\nRecently, several papers have presented insightful perspectives into how the\ncoordination of multiple attentional functions in the brain might occur. These\nbegin with experimental observations and the authors propose structures,\nprocesses, and computations that might explain those observations. Here, we\nconsider a perspective that past works have not, as a complementary approach to\nthe experimentally-grounded ones. We approach the same problem as past authors\nbut from the other end of the computational spectrum, from the problem nature,\nas Marr's Computational Level would prescribe. What problem must the brain\nsolve when orchestrating attentional processes in order to successfully\ncomplete one of the myriad possible visuospatial tasks at which we as humans\nexcel? The hope, of course, is for the approaches to eventually meet and thus\nform a complete theory, but this is likely not soon. We make the first steps\ntowards this by addressing the necessity of attentional control, examining the\nbreadth and computational difficulty of the visuospatial and attentional tasks\nseen in human behavior, and suggesting a sketch of how attentional control\nmight arise in the brain. The key conclusions of this paper are that an\nexecutive controller is necessary for human attentional function in vision, and\nthat there is a 'first principles' computational approach to its understanding\nthat is complementary to the previous approaches that focus on modelling or\nlearning from experimental observations directly.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jan 2021 14:24:20 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["Tsotsos", "John K.", ""], ["Abid", "Omar", ""], ["Kotseruba", "Iuliia", ""], ["Solbach", "Markus D.", ""]]}, {"id": "2101.01538", "submitter": "Stuart Kauffman", "authors": "Stuart Kauffman, Dean Radin", "title": "Is Brain-Mind Quantum? A theory and supporting evidence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC quant-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a non-substance dualism theory, following Heisenberg: The world\nconsists of both ontologically real possibilities that do not obey Aristotle's\nLaw of the Excluded Middle, and ontologically real Actuals that do o0bey the\nLaw of the Excluded Middle. This quantum approach solves five issues in quantum\nmechanics and numerous puzzles about the mind-brain relationship. It raises the\npossibility that some aspects of mind are non-local, and that mind plays an\nactive role in the physical world. We present supporting evidence.\n", "versions": [{"version": "v1", "created": "Sun, 3 Jan 2021 01:40:07 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["Kauffman", "Stuart", ""], ["Radin", "Dean", ""]]}, {"id": "2101.01699", "submitter": "Zhuo-Cheng Xiao", "authors": "Yuhang Cai, Tianyi Wu, Louis Tao, Zhuo-Cheng Xiao", "title": "Model Reduction Captures Stochastic Gamma Oscillations on\n  Low-Dimensional Manifolds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC q-bio.QM", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Gamma frequency oscillations (25-140 Hz), observed in the neural activities\nwithin many brain regions, have long been regarded as a physiological basis\nunderlying many brain functions, such as memory and attention. Among numerous\ntheoretical and computational modeling studies, gamma oscillations have been\nfound in biologically realistic spiking network models of the primary visual\ncortex. However, due to its high dimensionality and strong nonlinearity, it is\ngenerally difficult to perform detailed theoretical analysis of the emergent\ngamma dynamics. Here we propose a suite of Markovian model reduction methods\nwith varying levels of complexity and applied it to spiking network models\nexhibiting heterogeneous dynamical regimes, ranging from homogeneous firing to\nstrong synchrony in the gamma band. The reduced models not only successfully\nreproduce gamma band oscillations in the full model, but also exhibit the same\ndynamical features as we vary parameters. Most remarkably, the invariant\nmeasure of the coarse-grained Markov process reveals a two-dimensional surface\nin state space upon which the gamma dynamics mainly resides. Our results\nsuggest that the statistical features of gamma oscillations strongly depend on\nthe subthreshold neuronal distributions. Because of the generality of the\nMarkovian assumptions, our dimensional reduction methods offer a powerful\ntoolbox for theoretical examinations of many other complex cortical\nspatio-temporal behaviors observed in both neurophysiological experiments and\nnumerical simulations.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jan 2021 18:44:00 GMT"}, {"version": "v2", "created": "Sat, 23 Jan 2021 03:26:39 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Cai", "Yuhang", ""], ["Wu", "Tianyi", ""], ["Tao", "Louis", ""], ["Xiao", "Zhuo-Cheng", ""]]}, {"id": "2101.01973", "submitter": "Xiaobo Liu", "authors": "Xiaobo Liu, Su Yang", "title": "Weighted Ensemble-model and Network Analysis: A method to predict fluid\n  intelligence via naturalistic functional connectivity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Objectives: Functional connectivity triggered by naturalistic stimulus (e.g.,\nmovies) and machine learning techniques provide a great insight in exploring\nthe brain functions such as fluid intelligence. However, functional\nconnectivity are considered to be multi-layered, while traditional machine\nlearning based on individual models not only are limited in performance, but\nalso fail to extract multi-dimensional and multi-layered information from brain\nnetwork. Methods: In this study, inspired by multi-layer brain network\nstructure, we propose a new method namely Weighted Ensemble-model and Network\nAnalysis, which combines the machine learning and graph theory for improved\nfluid intelligence prediction. Firstly, functional connectivity analysis and\ngraphical theory were jointly employed. The functional connectivity and\ngraphical indices computed using the preprocessed fMRI data were then all fed\ninto auto-encoder parallelly for feature extraction to predict the fluid\nintelligence. In order to improve the performance, tree regression and ridge\nregression model were automatically stacked and fused with weighted values.\nFinally, layers of auto-encoder were visualized to better illustrate the\nconnectome patterns, followed by the evaluation of the performance to justify\nthe mechanism of brain functions. Results: Our proposed methods achieved best\nperformance with 3.85 mean absolute deviation, 0.66 correlation coefficient and\n0.42 R-squared coefficient, outperformed other state-of-the-art methods. It is\nalso worth noting that, the optimization of the biological pattern extraction\nwas automated though the auto-encoder algorithm. Conclusion: The proposed\nmethod not only outperforming the state-of-the-art reports, but also able to\neffectively capturing the biological patterns from functional connectivity\nduring naturalistic movies state for potential clinical explorations.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jan 2021 11:17:49 GMT"}], "update_date": "2021-01-07", "authors_parsed": [["Liu", "Xiaobo", ""], ["Yang", "Su", ""]]}, {"id": "2101.03163", "submitter": "Elham Ghazizadeh Ms", "authors": "Elham Ghazizadeh, ShiNung Ching", "title": "Slow manifolds in recurrent networks encode working memory efficiently\n  and robustly", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Working memory is a cognitive function involving the storage and manipulation\nof latent information over brief intervals of time, thus making it crucial for\ncontext-dependent computation. Here, we use a top-down modeling approach to\nexamine network-level mechanisms of working memory, an enigmatic issue and\ncentral topic of study in neuroscience and machine intelligence. We train\nthousands of recurrent neural networks on a working memory task and then\nperform dynamical systems analysis on the ensuing optimized networks, wherein\nwe find that four distinct dynamical mechanisms can emerge. In particular, we\nshow the prevalence of a mechanism in which memories are encoded along slow\nstable manifolds in the network state space, leading to a phasic neuronal\nactivation profile during memory periods. In contrast to mechanisms in which\nmemories are directly encoded at stable attractors, these networks naturally\nforget stimuli over time. Despite this seeming functional disadvantage, they\nare more efficient in terms of how they leverage their attractor landscape and\nparadoxically, are considerably more robust to noise. Our results provide new\ndynamical hypotheses regarding how working memory function is encoded in both\nnatural and artificial neural networks.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jan 2021 18:47:02 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Ghazizadeh", "Elham", ""], ["Ching", "ShiNung", ""]]}, {"id": "2101.03609", "submitter": "Wlodzislaw Duch", "authors": "W{\\l}odzis{\\l}aw Duch", "title": "Neurocognitive Informatics Manifesto", "comments": "27 pages, Series of Information and Management Sciences, California\n  Polytechnic State University, 8th International Conference on Information and\n  Management Sciences (IMS 2009), Kunming-Banna, Yunan, China, pp. 264-282", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI q-bio.NC", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Informatics studies all aspects of the structure of natural and artificial\ninformation systems. Theoretical and abstract approaches to information have\nmade great advances, but human information processing is still unmatched in\nmany areas, including information management, representation and understanding.\nNeurocognitive informatics is a new, emerging field that should help to improve\nthe matching of artificial and natural systems, and inspire better\ncomputational algorithms to solve problems that are still beyond the reach of\nmachines. In this position paper examples of neurocognitive inspirations and\npromising directions in this area are given.\n", "versions": [{"version": "v1", "created": "Sun, 10 Jan 2021 19:20:15 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Duch", "W\u0142odzis\u0142aw", ""]]}, {"id": "2101.04137", "submitter": "Zied Ben Houidi", "authors": "Zied Ben Houidi", "title": "The backpropagation-based recollection hypothesis: Backpropagated action\n  potentials mediate recall, imagination, language understanding and naming", "comments": "19 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Ever since the advent of the neuron doctrine more than a century ago,\ninformation processing in the brain is widely believed to mainly follow the\nforward pre to post-synaptic neurons direction. In this paper, we emit the\nbackpropagation-based recollection hypothesis as follows: weak and fast fading\nAction Potentials following the (highest weight) post to pre-synaptic backward\npathways, mediate explicit cue-based memory recall. This includes also the\ntasks of imagination, future episodic thinking, language understanding and\nassociating names to various stimuli. These signals originate in highly\ninvariant neurons, which uniquely respond to some specific stimuli (e.g. image\nof a cat). They then travel backwards to reactivate the same populations of\nneurons that uniquely respond to this specific stimuli during perception, thus\nrecreating \"offline\" an experience that is similar. After stating our\nhypothesis in details, we review abundant evidence on the existence of such\nbackpropagating signals as well as other relevant literature that supports our\nclaims. We then leverage simulations based on existing spiking neural network\nmodels with STDP learning to show the computational feasibility of using such a\nmechanism to map the image of an object to its name with the same high accuracy\nas a state of the art machine learning classifier. Although not yet a theory,\nwe believe this hypothesis presents a paradigm shift that is worth further\ninvestigating: it opens the way, among others, to new interpretations of\nlanguage acquisition and understanding, the interplay between memories encoding\nand retrieval, as well as reconciling the apparently opposed views between\nsparse coding and distributed representations.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jan 2021 19:02:35 GMT"}, {"version": "v2", "created": "Thu, 14 Jan 2021 14:44:58 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Houidi", "Zied Ben", ""]]}, {"id": "2101.04408", "submitter": "Daniel Baker", "authors": "Daniel H. Baker", "title": "Statistical analysis of periodic data in neuroscience", "comments": "18 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Many experimental paradigms in neuroscience involve driving the nervous\nsystem with periodic sensory stimuli. Neural signals recorded using a variety\nof techniques will then include phase-locked oscillations at the stimulation\nfrequency. The analysis of such data often involves standard univariate\nstatistics such as T-tests, conducted on the Fourier amplitude components\n(ignoring phase), either to test for the presence of a signal, or to compare\nsignals across different conditions. However, the assumptions of these tests\nwill sometimes be violated because amplitudes are not normally distributed, and\nfurthermore weak signals might be missed if the phase information is discarded.\nAn alternative approach is to conduct multivariate statistical tests using the\nreal and imaginary Fourier components. Here the performance of two multivariate\nextensions of the T-test are compared: Hotelling's $T^2$ and a variant called\n$T^2_{circ}$. A novel test of the assumptions of $T^2_{circ}$ is developed,\nbased on the condition index of the data (the square root of the ratio of\neigenvalues of a bounding ellipse), and a heuristic for excluding outliers\nusing the Mahalanobis distance is proposed. The $T^2_{circ}$ statistic is then\nextended to multi-level designs, resulting in a new statistical test termed\n$ANOVA^2_{circ}$. This has identical assumptions to $T^2_{circ}$, and is shown\nto be more sensitive than MANOVA when these assumptions are met. The use of\nthese tests is demonstrated for two publicly available empirical data sets, and\npractical guidance is suggested for choosing which test to run. Implementations\nof these novel tools are provided as an R package and a Matlab toolbox, in the\nhope that their wider adoption will improve the sensitivity of statistical\ninferences involving periodic data.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jan 2021 11:10:17 GMT"}, {"version": "v2", "created": "Mon, 29 Mar 2021 10:22:09 GMT"}, {"version": "v3", "created": "Tue, 15 Jun 2021 06:00:54 GMT"}, {"version": "v4", "created": "Wed, 7 Jul 2021 13:27:32 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Baker", "Daniel H.", ""]]}, {"id": "2101.04532", "submitter": "Wlodzislaw Duch", "authors": "W{\\l}odzis{\\l}aw Duch", "title": "Experiential Learning Styles and Neurocognitive Phenomics", "comments": "20 pages, extended version of article published in \"Brains and\n  Education: Towards Neurocognitive Phenomics\", proceedings of: Learning while\n  we are connected, Vol. 3, Eds. N. Reynolds, M. Webb, M.M. Sys{\\l}o, V.\n  Dagiene, pp. 12-23. X World Conference on Computers in Education, 2013;\n  Toru\\'n, Poland", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Phenomics is concerned with detailed description of all aspects of organisms,\nfrom their physical foundations at genetic, molecular and cellular level, to\nbehavioural and psychological traits. Neuropsychiatric phenomics, endorsed by\nNIMH, provides such broad perspective to understand mental disorders. It is\nclear that learning sciences also need similar approach that will integrate\nefforts to understand cognitive processes from the perspective of the brain\ndevelopment, in temporal, spatial, psychological and social aspects. The brain\nis a substrate shaped by genetic, epigenetic, cellular and environmental\nfactors including education, individual experiences and personal history,\nculture, social milieu. Learning sciences should thus be based on the\nfoundation of neurocognitive phenomics. A brief review of selected aspects of\nsuch approach is presented, outlining new research directions. Central,\nperipheral and motor processes in the brain are linked to the inventory of the\nlearning styles.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jan 2021 15:10:06 GMT"}], "update_date": "2021-01-13", "authors_parsed": [["Duch", "W\u0142odzis\u0142aw", ""]]}, {"id": "2101.05091", "submitter": "Vasudevan Lakshminarayanan", "authors": "Darwin Castillo, Vasudevan Lakshminarayanan, Maria J.\n  Rodriguez-Alvarez", "title": "MRI Images, Brain Lesions and Deep Learning", "comments": "Submitted to: Computer Programs and Methods in Biomedicine update\n  (2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Medical brain image analysis is a necessary step in Computer Assisted /Aided\nDiagnosis (CAD) systems. Advancements in both hardware and software in the past\nfew years have led to improved segmentation and classification of various\ndiseases. In the present work, we review the published literature on systems\nand algorithms that allow for classification, identification, and detection of\nWhite Matter Hyperintensities (WMHs) of brain MRI images specifically in cases\nof ischemic stroke and demyelinating diseases. For the selection criteria, we\nused the bibliometric networks. Out of a total of 140 documents we selected 38\narticles that deal with the main objectives of this study. Based on the\nanalysis and discussion of the revised documents, there is constant growth in\nthe research and proposal of new models of deep learning to achieve the highest\naccuracy and reliability of the segmentation of ischemic and demyelinating\nlesions. Models with indicators (Dice Score, DSC: 0.99) were found, however\nwith little practical application due to the uses of small datasets and lack of\nreproducibility. Therefore, the main conclusion is to establish\nmultidisciplinary research groups to overcome the gap between CAD developments\nand their complete utilization in the clinical environment.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jan 2021 14:18:48 GMT"}, {"version": "v2", "created": "Thu, 14 Jan 2021 15:30:59 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Castillo", "Darwin", ""], ["Lakshminarayanan", "Vasudevan", ""], ["Rodriguez-Alvarez", "Maria J.", ""]]}, {"id": "2101.05177", "submitter": "Bank Fenyves", "authors": "Bank G. Fenyves (1 and 2), Gabor S. Szilagyi (1), Zsolt Vassy (1),\n  Csaba Soti (1), Peter Csermely (1) ((1) Department of Molecular Biology,\n  Semmelweis University, Budapest, Hungary, (2) Department of Emergency\n  Medicine, Semmelweis University, Budapest, Hungary)", "title": "Synaptic polarity and sign-balance prediction using gene expression data\n  in the Caenorhabditis elegans chemical synapse neuronal connectome network", "comments": "19 pages, 5 figues", "journal-ref": "PLOS Computational Biology, 2020, 16(12): e1007974", "doi": "10.1371/journal.pcbi.1007974", "report-no": null, "categories": "q-bio.MN q-bio.GN q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Graph theoretical analyses of nervous systems usually omit the aspect of\nconnection polarity, due to data insufficiency. The chemical synapse network of\nCaenorhabditis elegans is a well-reconstructed directed network, but the signs\nof its connections are yet to be elucidated. Here, we present the gene\nexpression-based sign prediction of the ionotropic chemical synapse connectome\nof C. elegans (3,638 connections and 20,589 synapses total), incorporating\navailable presynaptic neurotransmitter and postsynaptic receptor gene\nexpression data for three major neurotransmitter systems. We made predictions\nfor more than two-thirds of these chemical synapses and observed an\nexcitatory-inhibitory (E:I) ratio close to 4:1 which was found similar to that\nobserved in many real-world networks. Our open source tool\n(http://EleganSign.linkgroup.hu) is simple but efficient in predicting\npolarities by integrating neuronal connectome and gene expression data.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jan 2021 16:26:53 GMT"}, {"version": "v2", "created": "Fri, 15 Jan 2021 13:42:57 GMT"}], "update_date": "2021-01-18", "authors_parsed": [["Fenyves", "Bank G.", "", "1 and 2"], ["Szilagyi", "Gabor S.", ""], ["Vassy", "Zsolt", ""], ["Soti", "Csaba", ""], ["Csermely", "Peter", ""]]}, {"id": "2101.05247", "submitter": "Enzo Marinari", "authors": "Marco Benedetti, Victor Dotsenko, Giulia Fischetti, Enzo Marinari,\n  Gleb Oshanin", "title": "Recognition Capabilities of a Hopfield Model with Auxiliary Hidden\n  Neurons", "comments": null, "journal-ref": "Phys. Rev. E 103, 060401 (2021)", "doi": "10.1103/PhysRevE.103.L060401", "report-no": null, "categories": "cond-mat.dis-nn cond-mat.stat-mech physics.bio-ph q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We study the recognition capabilities of the Hopfield model with auxiliary\nhidden layers, which emerge naturally upon a Hubbard-Stratonovich\ntransformation. We show that the recognition capabilities of such a model at\nzero-temperature outperform those of the original Hopfield model, due to a\nsubstantial increase of the storage capacity and the lack of a naturally\ndefined basin of attraction. The modified model does not fall abruptly in a\nregime of complete confusion when memory load exceeds a sharp threshold.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jan 2021 18:13:47 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Benedetti", "Marco", ""], ["Dotsenko", "Victor", ""], ["Fischetti", "Giulia", ""], ["Marinari", "Enzo", ""], ["Oshanin", "Gleb", ""]]}, {"id": "2101.05458", "submitter": "Sayan Nag", "authors": "Sayan Nag", "title": "On the stability of equilibria of the physiologically-informed dynamic\n  causal model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC nlin.CD physics.med-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Experimental manipulations perturb the neuronal activity. This phenomenon is\nmanifested in the fMRI response. Dynamic causal model and its variants can\nmodel these neuronal responses along with the BOLD responses [1, 2, 3, 4, 5] .\nPhysiologically-informed DCM (P-DCM) [5] gives state-of-the-art results in this\naspect. But, P-DCM has more parameters compared to the standard DCM model and\nthe stability of this particular model is still unexplored. In this work, we\nwill try to explore the stability of the P-DCM model and find the ranges of the\nmodel parameters which make it stable.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jan 2021 04:33:31 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Nag", "Sayan", ""]]}, {"id": "2101.06057", "submitter": "Richard Gast", "authors": "Richard Gast, Thomas R. Kn\\\"osche, Helmut Schmidt", "title": "Mean-field approximations of networks of spiking neurons with short-term\n  synaptic plasticity", "comments": "15 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Low-dimensional descriptions of neural network dynamics are an effective tool\nfor bridging different scales of organization of brain structure and function.\nRecent advances in deriving mean-field descriptions for networks of coupled\noscillators have sparked the development of a new generation of neural mass\nmodels. Of notable interest are mean-field descriptions of all-to-all coupled\nquadratic integrate-and-fire (QIF) neurons, which have already seen numerous\nextensions and applications. These extensions include different forms of\nshort-term adaptation (STA) considered to play an important role in generating\nand sustaining dynamic regimes of interest in the brain. It is an open\nquestion, however, whether the incorporation of pre-synaptic forms of synaptic\nplasticity driven by single neuron activity would still permit the derivation\nof mean-field equations using the same method. Here, we discuss this problem\nusing an established model of short-term synaptic plasticity at the single\nneuron level, for which we present two different approaches for the derivation\nof the mean-field equations. We compare these models with a recently proposed\nmean-field approximation that assumes stochastic spike timings. In general, the\nlatter fails to accurately reproduce the macroscopic activity in networks of\ndeterministic QIF neurons with distributed parameters. We show that the\nmean-field models we propose provide a more accurate description of the network\ndynamics, although they are mathematically more involved. Using bifurcation\nanalysis, we find that QIF networks with pre-synaptic short-term plasticity can\nexpress regimes of periodic bursting activity as well as bi-stable regimes.\nTogether, we provide novel insight into the macroscopic effects of short-term\nsynaptic plasticity in spiking neural networks, as well as two different\nmean-field descriptions for future investigations of such networks.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jan 2021 10:59:25 GMT"}, {"version": "v2", "created": "Mon, 14 Jun 2021 15:13:27 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Gast", "Richard", ""], ["Kn\u00f6sche", "Thomas R.", ""], ["Schmidt", "Helmut", ""]]}, {"id": "2101.06294", "submitter": "Halim Maaroufi Hal", "authors": "Halim Maaroufi", "title": "Interactions of SARS-CoV-2 spike protein and transient receptor\n  potential (TRP) cation channels could explain smell, taste, and/or\n  chemesthesis disorders", "comments": "46 pages, 2 tables, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  A significant subset of patients infected by SARS-CoV-2 presents olfactory,\ntaste, and/or chemesthesis (OTC) disorders (OTCD). These patients recover\nrapidly, eliminating damage of sensory nerves. Discovering that S protein\ncontains two ankyrin repeat binding motifs (S-ARBMs) and some TRP cation\nchannels, implicated in OTC, have ankyrin repeat domains (TRPs-ARDs), I\nhypothesized that interaction of S-ARBMs and TRPs-ARDs could dysregulate the\nfunction of the latter and thus explains OTCD. Of note, some TRPs-ARDs are\nexpressed in the olfactory epithelium, taste buds, trigeminal neurons in the\noronasal cavity and vagal neurons in the trachea/lungs. Furthermore, this\nhypothesis is supported by studies that have shown: (i) respiratory viruses\ninteract with TRPA1 and TRPV1 on sensory nerves and epithelial cells in the\nairways, (ii) the respiratory pathophysiology in COVID-19 patients is similar\nto lungs injuries produced by the sensitization of TRPV1 and TRPV4, and (iii)\nresolvin D1 and D2 shown to reduce SARS-CoV-2-induced inflammation, directly\ninhibit TRPA1, TRPV1, TRPV3 and TRPV4. Herein, results of blind dockings of\nS-ARBMs, 408-RQIAPG-413 (in RBD but distal from the ACE-2 binding region) and\n905-RFNGIG-910 (in HR1), into TRPA1, TRPV1 and TRPV4 suggest that S-ARBMs\ninteract with ankyrin repeat 6 of TRPA1 near an active site, and ankyrin repeat\n3-4 of TRPV1 near cysteine 258 supposed to be implicated in the formation of\ninter-subunits disulfide bond. These findings suggest that S-ARBMs affect\nTRPA1, TRPV1 and TRPV4 function by interfering with channel assembly and\ntrafficking. After an experimental confirmation of these interactions, among\npossible preventive treatments against COVID-19, the use of pharmacological\nmanipulation (probably inhibition) of TRPs-ARDs to control or mitigate\nsustained pro-inflammatory response.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jan 2021 20:29:30 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Maaroufi", "Halim", ""]]}, {"id": "2101.06627", "submitter": "Zhongqi Tian", "authors": "Zhong-Qi Kyle Tian and Douglas Zhou", "title": "Design Fast Algorithms For Hodgkin-Huxley Neuronal Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The stiffness of the Hodgkin-Huxley (HH) equations during an action potential\n(spike) limits the use of large time steps. We observe that the neurons can be\nevolved independently between spikes, $i.e.,$ different neurons can be evolved\nwith different methods and different time steps. This observation motivates us\nto design fast algorithms to raise efficiency. We present an adaptive method,\nan exponential time differencing (ETD) method and a library-based method to\ndeal with the stiff period. All the methods can use time steps one order of\nmagnitude larger than the regular Runge-Kutta methods to raise efficiency while\nachieving precise statistical properties of the original HH neurons like the\nlargest Lyapunov exponent and mean firing rate. We point out that the ETD and\nlibrary methods can stably achieve maximum 8 and 10 times of speedup,\nrespectively.\n", "versions": [{"version": "v1", "created": "Sun, 17 Jan 2021 09:27:38 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Tian", "Zhong-Qi Kyle", ""], ["Zhou", "Douglas", ""]]}, {"id": "2101.06887", "submitter": "Dmitry Krotov", "authors": "Yuchen Liang, Chaitanya K. Ryali, Benjamin Hoover, Leopold Grinberg,\n  Saket Navlakha, Mohammed J. Zaki, Dmitry Krotov", "title": "Can a Fruit Fly Learn Word Embeddings?", "comments": "Accepted for publication at ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The mushroom body of the fruit fly brain is one of the best studied systems\nin neuroscience. At its core it consists of a population of Kenyon cells, which\nreceive inputs from multiple sensory modalities. These cells are inhibited by\nthe anterior paired lateral neuron, thus creating a sparse high dimensional\nrepresentation of the inputs. In this work we study a mathematical\nformalization of this network motif and apply it to learning the correlational\nstructure between words and their context in a corpus of unstructured text, a\ncommon natural language processing (NLP) task. We show that this network can\nlearn semantic representations of words and can generate both static and\ncontext-dependent word embeddings. Unlike conventional methods (e.g., BERT,\nGloVe) that use dense representations for word embedding, our algorithm encodes\nsemantic meaning of words and their context in the form of sparse binary hash\ncodes. The quality of the learned representations is evaluated on word\nsimilarity analysis, word-sense disambiguation, and document classification. It\nis shown that not only can the fruit fly network motif achieve performance\ncomparable to existing methods in NLP, but, additionally, it uses only a\nfraction of the computational resources (shorter training time and smaller\nmemory footprint).\n", "versions": [{"version": "v1", "created": "Mon, 18 Jan 2021 05:41:50 GMT"}, {"version": "v2", "created": "Sun, 14 Mar 2021 19:50:25 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Liang", "Yuchen", ""], ["Ryali", "Chaitanya K.", ""], ["Hoover", "Benjamin", ""], ["Grinberg", "Leopold", ""], ["Navlakha", "Saket", ""], ["Zaki", "Mohammed J.", ""], ["Krotov", "Dmitry", ""]]}, {"id": "2101.07257", "submitter": "Zhongqi Tian", "authors": "Zhong-Qi Kyle Tian and Douglas Zhou", "title": "Library-based Fast Algorithm for Simulating the Hodgkin-Huxley Neuronal\n  Networks", "comments": "arXiv admin note: text overlap with arXiv:2101.06627", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a modified library-based method for simulating the Hodgkin-Huxley\n(HH) neuronal networks. By pre-computing a high resolution data library during\nthe interval of an action potential (spike), we can avoid evolving the HH\nequations during the spike and can use a large time step to raise efficiency.\nThe library method can stably achieve at most 10 times of speedup compared with\nthe regular Runge-Kutta method while capturing most statistical properties of\nHH neurons like the distribution of spikes which data is widely used in the\nstatistical analysis like transfer entropy and Granger causality. The idea of\nlibrary method can be easily and successfully applied to other HH-type models\nlike the most prominent \\textquotedblleft regular spiking\\textquotedblright ,\n\\textquotedblleft fast spiking\\textquotedblright , \\textquotedblleft\nintrinsically bursting\\textquotedblright{} and \\textquotedblleft low-threshold\nspike\\textquotedblright{} types of HH models.\n", "versions": [{"version": "v1", "created": "Sun, 17 Jan 2021 10:25:09 GMT"}], "update_date": "2021-01-20", "authors_parsed": [["Tian", "Zhong-Qi Kyle", ""], ["Zhou", "Douglas", ""]]}, {"id": "2101.08211", "submitter": "Xinwei Yu", "authors": "Xinwei Yu, Matthew S. Creamer, Francesco Randi, Anuj K. Sharma, Scott\n  W. Linderman, Andrew M. Leifer", "title": "Fast deep learning correspondence for neuron tracking and identification\n  in C.elegans using synthetic training", "comments": "5 figures", "journal-ref": "eLife 2021;10:e66410", "doi": "10.7554/eLife.66410", "report-no": null, "categories": "q-bio.QM cs.CV q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We present an automated method to track and identify neurons in C. elegans,\ncalled \"fast Deep Learning Correspondence\" or fDLC, based on the transformer\nnetwork architecture. The model is trained once on empirically derived\nsynthetic data and then predicts neural correspondence across held-out real\nanimals via transfer learning. The same pre-trained model both tracks neurons\nacross time and identifies corresponding neurons across individuals.\nPerformance is evaluated against hand-annotated datasets, including NeuroPAL\n[1]. Using only position information, the method achieves 80.0% accuracy at\ntracking neurons within an individual and 65.8% accuracy at identifying neurons\nacross individuals. Accuracy is even higher on a published dataset [2].\nAccuracy reaches 76.5% when using color information from NeuroPAL. Unlike\nprevious methods, fDLC does not require straightening or transforming the\nanimal into a canonical coordinate system. The method is fast and predicts\ncorrespondence in 10 ms making it suitable for future real-time applications.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jan 2021 16:46:37 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Yu", "Xinwei", ""], ["Creamer", "Matthew S.", ""], ["Randi", "Francesco", ""], ["Sharma", "Anuj K.", ""], ["Linderman", "Scott W.", ""], ["Leifer", "Andrew M.", ""]]}, {"id": "2101.08532", "submitter": "Svetlana Postnova", "authors": "Dmitry E. Postnov, Ksenia O. Merkulova, Svetlana Postnova", "title": "Desynchrony and synchronisation underpinning sleep-wake cycles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.bio-ph q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  A biophysical model of arousal dynamics is used to study mechanisms of\nsynchronisation and loss of synchrony among the three key oscillators\ncontrolling sleep-wake cycles: the circadian, homeostatic, and light\noscillators. Synchronisation of these rhythms promotes sleep and brain\nclearance and is critical for human health. Conversely, their desynchrony is\nlinked to impaired performance and disease. We find that the default state of\nthe model corresponds to the endogenous homeostatic period that is far from ~24\nh of the circadian and light-dark cycles. Combined action of light and\ncircadian oscillator on the homeostatic rhythm is required to achieve the\ntypical sleep-wake pattern of healthy people. Change of homeostatic clearance\nis found to induce two types of desynchronisation: (i) fast clearance rates\ndesynchronise the homeostatic oscillator from the circadian, while the\ncircadian rhythm remains entrained to light, and (ii) slow clearance maintains\nsynchronisation between the homeostatic and circadian oscillators, but the\nperiod is different from that of the light-dark cycle. Between these regimes,\nall three rhythms are synchronised under the studied conditions. The system is\nhighly sensitive to external inputs to the neuronal populations of the\nsleep-wake switch, which can lead to complete loss of sleep. The model shows\nthat loss of synchronisation can be caused by changes in the homeostatic\nclearance rate or external input to the neuronal populations of the sleep-wake\nswitch. This has implications for understanding individual variability in\nsleep-wake patterns and in mechanisms of sleep and circadian disorders.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jan 2021 10:32:42 GMT"}], "update_date": "2021-01-22", "authors_parsed": [["Postnov", "Dmitry E.", ""], ["Merkulova", "Ksenia O.", ""], ["Postnova", "Svetlana", ""]]}, {"id": "2101.08635", "submitter": "Martin Nwadiugwu", "authors": "Martin C. Nwadiugwu", "title": "Neural Networks, Artificial Intelligence and the Computational Brain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In recent years, several studies have provided insight on the functioning of\nthe brain which consists of neurons and form networks via interconnection among\nthem by synapses. Neural networks are formed by interconnected systems of\nneurons, and are of two types, namely, the Artificial Neural Network (ANNs) and\nBiological Neural Network (interconnected nerve cells). The ANNs are\ncomputationally influenced by human neurons and are used in modelling neural\nsystems. The reasoning foundations of ANNs have been useful in anomaly\ndetection, in areas of medicine such as instant physician, electronic noses,\npattern recognition, and modelling biological systems. Advancing research in\nartificial intelligence using the architecture of the human brain seeks to\nmodel systems by studying the brain rather than looking to technology for brain\nmodels. This study explores the concept of ANNs as a simulator of the\nbiological neuron, and its area of applications. It also explores why\nbrain-like intelligence is needed and how it differs from computational\nframework by comparing neural networks to contemporary computers and their\nmodern day implementation.\n", "versions": [{"version": "v1", "created": "Fri, 25 Dec 2020 05:56:41 GMT"}], "update_date": "2021-01-22", "authors_parsed": [["Nwadiugwu", "Martin C.", ""]]}, {"id": "2101.08651", "submitter": "Vincent Huin", "authors": "Vincent Huin (JPArc, ICM), Mathieu Barbier (ICM), Alexandra Durr\n  (ICM), Isabelle Le Ber (IM2A, ICM)", "title": "Reply: Early-onset phenotype of bi-allelic GRN mutations", "comments": "Brain - A Journal of Neurology , Oxford University Press (OUP), 2020", "journal-ref": null, "doi": "10.1093/brain/awaa415", "report-no": null, "categories": "q-bio.GN q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We would like to reply to Neuray et al. who report a series of five new\npatients from four unrelated families with bi-allelic mutations of GRN. Their\nwork nicely completes the few existing reports of similar cases, and refers to\nour recent publication describing six homozygous GRN pathogenic variant\ncarriers with divergent phenotypes and ages at onset (Huin et al., 2020). In\nsummary, the Letter from Neuray et al., reports valuable findings that lead to\nbetter define CLN11 due to bi-allelic GRN pathogenic variants. Despite the\nsmall sample number that does not allow statistical analysis, the authors\nunderlined the occurrence of cognitive deterioration and epilepsy. Further\nstudy of the CLN11 families with functional brain imaging and\nneuropsychological examinations may be highly informative for the understanding\nand the clinical characterization of this rare disease.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jan 2021 10:37:10 GMT"}], "update_date": "2021-01-22", "authors_parsed": [["Huin", "Vincent", "", "JPArc, ICM"], ["Barbier", "Mathieu", "", "ICM"], ["Durr", "Alexandra", "", "ICM"], ["Ber", "Isabelle Le", "", "IM2A, ICM"]]}, {"id": "2101.08731", "submitter": "Tomas Barta", "authors": "Tomas Barta and Lubomir Kostal", "title": "Regular spiking in high conductance states: the essential role of\n  inhibition", "comments": null, "journal-ref": "Phys. Rev. E 103, 022408 (2021)", "doi": "10.1103/PhysRevE.103.022408", "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Strong inhibitory input to neurons, which occurs in balanced states of neural\nnetworks, increases synaptic current fluctuations. This has led to the\nassumption that inhibition contributes to the high spike-firing irregularity\nobserved in vivo. We used single compartment neuronal models with\ntime-correlated (due to synaptic filtering) and state-dependent (due to\nreversal potentials) input to demonstrate that inhibitory input acts to\ndecrease membrane potential fluctuations, a result that cannot be achieved with\nsimplified neural input models. To clarify the effects on spike-firing\nregularity, we used models with different spike-firing adaptation mechanisms\nand observed that the addition of inhibition increased firing regularity in\nmodels with dynamic firing thresholds and decreased firing regularity if\nspike-firing adaptation was implemented through ionic currents or not at all.\nThis novel fluctuation-stabilization mechanism provides a new perspective on\nthe importance of strong inhibitory inputs observed in balanced states of\nneural networks and highlights the key roles of biologically plausible inputs\nand specific adaptation mechanisms in neuronal modeling.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jan 2021 17:14:25 GMT"}, {"version": "v2", "created": "Thu, 4 Feb 2021 14:50:11 GMT"}, {"version": "v3", "created": "Thu, 18 Feb 2021 16:30:18 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Barta", "Tomas", ""], ["Kostal", "Lubomir", ""]]}, {"id": "2101.08905", "submitter": "Helena Bordini De Lucas", "authors": "Helena B. Lucas, Steven L. Bressler, Fernanda S. Matias and Osvaldo A.\n  Rosso", "title": "A symbolic information approach to characterize response-related\n  differences in cortical activity during a Go/No-Go task", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How the brain processes information from external stimuli in order to\nperceive the world and act on it is one of the greatest questions in\nneuroscience. To address this question different time series analyzes\ntechniques have been employed to characterize the statistical properties of\nbrain signals during cognitive tasks. Typically response-specific processes are\naddressed by comparing the time course of average event-related potentials in\ndifferent trials type. Here we analyze monkey Local Field Potentials data\nduring visual pattern discrimination called Go/No-Go task in the light of\ninformation theory quantifiers. We show that the Bandt-Pompe symbolization\nmethodology to calculate entropy and complexity of data is a useful tool to\ndistinguish response-related differences between Go and No-Go trials. We\npropose to use an asymmetry index to statistically validate trial type\ndifferences. Moreover, by using the multi-scale approach and embedding time\ndelays to downsample the data we can estimate the important time scales in\nwhich the relevant information is been processed.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jan 2021 01:15:06 GMT"}], "update_date": "2021-01-25", "authors_parsed": [["Lucas", "Helena B.", ""], ["Bressler", "Steven L.", ""], ["Matias", "Fernanda S.", ""], ["Rosso", "Osvaldo A.", ""]]}, {"id": "2101.09352", "submitter": "Raphael Huser", "authors": "Matheus B. Guerrero, Rapha\\\"el Huser and Hernando Ombao", "title": "Conex-Connect: Learning Patterns in Extremal Brain Connectivity From\n  Multi-Channel EEG Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Epilepsy is a chronic neurological disorder affecting more than 50 million\npeople globally. An epileptic seizure acts like a temporary shock to the\nneuronal system, disrupting normal electrical activity in the brain. Epilepsy\nis frequently diagnosed with electroencephalograms (EEGs). Current methods\nstudy the time-varying spectra and coherence but do not directly model changes\nin extreme behavior. Thus, we propose a new approach to characterize brain\nconnectivity based on the joint tail behavior of the EEGs. Our proposed method,\nthe conditional extremal dependence for brain connectivity (Conex-Connect), is\na pioneering approach that links the association between extreme values of\nhigher oscillations at a reference channel with the other brain network\nchannels. Using the Conex-Connect method, we discover changes in the extremal\ndependence driven by the activity at the foci of the epileptic seizure. Our\nmodel-based approach reveals that, pre-seizure, the dependence is notably\nstable for all channels when conditioning on extreme values of the focal\nseizure area. Post-seizure, by contrast, the dependence between channels is\nweaker, and dependence patterns are more \"chaotic\". Moreover, in terms of\nspectral decomposition, we find that high values of the high-frequency\nGamma-band are the most relevant features to explain the conditional extremal\ndependence of brain connectivity.\n", "versions": [{"version": "v1", "created": "Sun, 3 Jan 2021 18:53:05 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Guerrero", "Matheus B.", ""], ["Huser", "Rapha\u00ebl", ""], ["Ombao", "Hernando", ""]]}, {"id": "2101.09354", "submitter": "M. Ali Vosoughi", "authors": "Axel Wismuller and M. Ali Vosoughi", "title": "Large-scale Augmented Granger Causality (lsAGC) for Connectivity\n  Analysis in Complex Systems: From Computer Simulations to Functional MRI\n  (fMRI)", "comments": "15 pages, conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce large-scale Augmented Granger Causality (lsAGC) as a method for\nconnectivity analysis in complex systems. The lsAGC algorithm combines\ndimension reduction with source time-series augmentation and uses predictive\ntime-series modeling for estimating directed causal relationships among\ntime-series. This method is a multivariate approach, since it is capable of\nidentifying the influence of each time-series on any other time-series in the\npresence of all other time-series of the underlying dynamic system. We\nquantitatively evaluate the performance of lsAGC on synthetic directional\ntime-series networks with known ground truth. As a reference method, we compare\nour results with cross-correlation, which is typically used as a standard\nmeasure of connectivity in the functional MRI (fMRI) literature. Using\nextensive simulations for a wide range of time-series lengths and two different\nsignal-to-noise ratios of 5 and 15 dB, lsAGC consistently outperforms\ncross-correlation at accurately detecting network connections, using Receiver\nOperator Characteristic Curve (ROC) analysis, across all tested time-series\nlengths and noise levels. In addition, as an outlook to possible clinical\napplication, we perform a preliminary qualitative analysis of connectivity\nmatrices for fMRI data of Autism Spectrum Disorder (ASD) patients and typical\ncontrols, using a subset of 59 subjects of the Autism Brain Imaging Data\nExchange II (ABIDE II) data repository. Our results suggest that lsAGC, by\nextracting sparse connectivity matrices, may be useful for network analysis in\ncomplex systems, and may be applicable to clinical fMRI analysis in future\nresearch, such as targeting disease-related classification or regression tasks\non clinical data.\n", "versions": [{"version": "v1", "created": "Sun, 10 Jan 2021 01:44:48 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Wismuller", "Axel", ""], ["Vosoughi", "M. Ali", ""]]}, {"id": "2101.09453", "submitter": "Linxing Jiang", "authors": "Linxing Preston Jiang, Luciano de la Iglesia", "title": "Improved Training of Sparse Coding Variational Autoencoder via Weight\n  Normalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning a generative model of visual information with sparse and\ncompositional features has been a challenge for both theoretical neuroscience\nand machine learning communities. Sparse coding models have achieved great\nsuccess in explaining the receptive fields of mammalian primary visual cortex\nwith sparsely activated latent representation. In this paper, we focus on a\nrecently proposed model, sparse coding variational autoencoder (SVAE) (Barello\net al., 2018), and show that the end-to-end training scheme of SVAE leads to a\nlarge group of decoding filters not fully optimized with noise-like receptive\nfields. We propose a few heuristics to improve the training of SVAE and show\nthat a unit $L_2$ norm constraint on the decoder is critical to produce sparse\ncoding filters. Such normalization can be considered as local lateral\ninhibition in the cortex. We verify this claim empirically on both natural\nimage patches and MNIST dataset and show that projection of the filters onto\nunit norm drastically increases the number of active filters. Our results\nhighlight the importance of weight normalization for learning sparse\nrepresentation from data and suggest a new way of reducing the number of\ninactive latent components in VAE learning.\n", "versions": [{"version": "v1", "created": "Sat, 23 Jan 2021 08:07:20 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Jiang", "Linxing Preston", ""], ["de la Iglesia", "Luciano", ""]]}, {"id": "2101.09710", "submitter": "Gerrit Ecke", "authors": "Gerrit A. Ecke, Harald M. Papp, Hanspeter A. Mallot", "title": "Exploitation of Image Statistics with Sparse Coding in the Case of\n  Stereo Vision", "comments": "Author's accepted manuscript", "journal-ref": "Neural Networks, Volume 135, 2021, Pages 158-176", "doi": "10.1016/j.neunet.2020.12.016", "report-no": null, "categories": "cs.CV q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The sparse coding algorithm has served as a model for early processing in\nmammalian vision. It has been assumed that the brain uses sparse coding to\nexploit statistical properties of the sensory stream. We hypothesize that\nsparse coding discovers patterns from the data set, which can be used to\nestimate a set of stimulus parameters by simple readout. In this study, we\nchose a model of stereo vision to test our hypothesis. We used the Locally\nCompetitive Algorithm (LCA), followed by a na\\\"ive Bayes classifier, to infer\nstereo disparity. From the results we report three observations. First,\ndisparity inference was successful with this naturalistic processing pipeline.\nSecond, an expanded, highly redundant representation is required to robustly\nidentify the input patterns. Third, the inference error can be predicted from\nthe number of active coefficients in the LCA representation. We conclude that\nsparse coding can generate a suitable general representation for subsequent\ninference tasks. Keywords: Sparse coding; Locally Competitive Algorithm (LCA);\nEfficient coding; Compact code; Probabilistic inference; Stereo vision\n", "versions": [{"version": "v1", "created": "Sun, 24 Jan 2021 12:45:25 GMT"}, {"version": "v2", "created": "Tue, 26 Jan 2021 22:24:16 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Ecke", "Gerrit A.", ""], ["Papp", "Harald M.", ""], ["Mallot", "Hanspeter A.", ""]]}, {"id": "2101.09774", "submitter": "James Tee", "authors": "James Tee, Desmond P. Taylor", "title": "What If Memory Information is Stored Inside the Neuron, Instead of in\n  the Synapse?", "comments": "8 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Memory information in the brain is commonly believed to be stored in the\nsynapse. However, a recent groundbreaking electrophysiology research has raised\nthe possibility that memory information may actually be stored inside the\nneuron itself. Drawing on information theory and communications system\nengineering perspectives, we examine the problem of how memory information\nmight be transmitted reliably between neurons. We identify 2 types of errors\nthat affect neuronal communications (i.e., channel error and source error),\nalong with plausible error mitigation solutions. We confirm the feasibility of\nthese solutions using simulations. Four alternative hypotheses of the synapse's\nfunction are also proposed. We conclude by highlighting some research\ndirections, along with potential areas of application.\n", "versions": [{"version": "v1", "created": "Sun, 24 Jan 2021 18:54:56 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Tee", "James", ""], ["Taylor", "Desmond P.", ""]]}, {"id": "2101.10056", "submitter": "Vitor Manuel Dinis Pereira", "authors": "Vitor Manuel Dinis Pereira", "title": "Occipital and left temporal instantaneous amplitude and frequency\n  oscillations correlated with access and phenomenal consciousness", "comments": "31 pages, 23 figures, according to the Philpapers.org, my manuscript\n  \"Occipital and left temporal instantaneous amplitude and frequency\n  oscillations correlated with access and phenomenal consciousness\" has been\n  downloaded 161 times until today (since 2017-11-30) without any substantial\n  critic, at least any substantial critic that I'am aware", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Given the hard problem of consciousness (Chalmers, 1995) there are no brain\nelectrophysiological correlates of the subjective experience (the felt quality\nof redness or the redness of red, the experience of dark and light, the quality\nof depth in a visual field, the sound of a clarinet, the smell of mothball,\nbodily sensations from pains to orgasms, mental images that are conjured up\ninternally, the felt quality of emotion, the experience of a stream of\nconscious thought or the phenomenology of thought). However, there are brain\noccipital and left temporal electrophysiological correlates of the subjective\nexperience (Pereira, 2015). Notwithstanding, as evoked signal, the change in\nevent-related brain potentials phase (frequency is the change in phase over\ntime) is instantaneous, that is, the frequency will transiently be infinite: a\ntransient peak in frequency (positive or negative), if any, is instantaneous in\nelectroencephalogram averaging or filtering that the event-related brain\npotentials required and the underlying structure of the event-related brain\npotentials in the frequency domain cannot be accounted, for example, by the\nWavelet Transform (WT) or the Fast Fourier Transform (FFT) analysis, because\nthey require that frequency is derived by convolution rather than by\ndifferentiation. However, as I show in the current original research report,\none suitable method for analyse the instantaneous change in event-related brain\npotentials phase and accounted for a transient peak in frequency (positive or\nnegative), if any, in the underlying structure of the event-related brain\npotentials is the Empirical Mode Decomposition with post processing (Xie et\nal., 2014) Ensemble Empirical Mode Decomposition (postEEMD) and Hilbert-Huang\nTransform (HHT).\n", "versions": [{"version": "v1", "created": "Sat, 26 Dec 2020 16:30:40 GMT"}, {"version": "v2", "created": "Fri, 26 Feb 2021 18:23:30 GMT"}, {"version": "v3", "created": "Fri, 5 Mar 2021 18:36:30 GMT"}], "update_date": "2021-03-08", "authors_parsed": [["Pereira", "Vitor Manuel Dinis", ""]]}, {"id": "2101.10215", "submitter": "Yakup Kutlu", "authors": "Enver Kaan Alpturk, Yakup Kutlu", "title": "Analysis of Relation between Motor Activity and Imaginary EEG Records", "comments": "6 pages, 4 figures, Journal of Artificial Intellicence with\n  Application", "journal-ref": "Journal of Artificial Intellicence with Application, 2020", "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Electroencephalography (EEG) signals signals are often used to learn about\nbrain structure and to learn what thinking. EEG signals can be easily affected\nby external factors. For this reason, they should be applied various\npre-process during their analysis. In this study, it is used the EEG signals\nreceived from 109 subjects when opening and closing their right or left fists\nand performing hand and foot movements and imagining the same movements. The\nrelationship between motor activities and imaginary of that motor activities\nwere investigated. Algorithms with high performance rates have been used for\nfeature extraction , selection and classification using the nearest neighbour\nalgorithm.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jan 2021 05:02:05 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Alpturk", "Enver Kaan", ""], ["Kutlu", "Yakup", ""]]}, {"id": "2101.10471", "submitter": "M. Ali Vosoughi", "authors": "Axel Wism\\\"uller and M. Ali Vosoughi", "title": "Classification of Schizophrenia from Functional MRI Using Large-scale\n  Extended Granger Causality", "comments": "The paper is the preprint of the paper accepted at the SPIE 2021\n  conference. The manuscript includes 14 pages with two figures. arXiv admin\n  note: substantial text overlap with arXiv:2101.01832. text overlap with\n  arXiv:2101.09354", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The literature manifests that schizophrenia is associated with alterations in\nbrain network connectivity. We investigate whether large-scale Extended Granger\nCausality (lsXGC) can capture such alterations using resting-state fMRI data.\nOur method utilizes dimension reduction combined with the augmentation of\nsource time-series in a predictive time-series model for estimating directed\ncausal relationships among fMRI time-series. The lsXGC is a multivariate\napproach since it identifies the relationship of the underlying dynamic system\nin the presence of all other time-series. Here lsXGC serves as a biomarker for\nclassifying schizophrenia patients from typical controls using a subset of 62\nsubjects from the Centers of Biomedical Research Excellence (COBRE) data\nrepository. We use brain connections estimated by lsXGC as features for\nclassification. After feature extraction, we perform feature selection by\nKendall's tau rank correlation coefficient followed by classification using a\nsupport vector machine. As a reference method, we compare our results with\ncross-correlation, typically used in the literature as a standard measure of\nfunctional connectivity. We cross-validate 100 different training/test\n(90%/10%) data split to obtain mean accuracy and a mean Area Under the receiver\noperating characteristic Curve (AUC) across all tested numbers of features for\nlsXGC. Our results demonstrate a mean accuracy range of [0.767, 0.940] and a\nmean AUC range of [0.861, 0.983] for lsXGC. The result of lsXGC is\nsignificantly higher than the results obtained with the cross-correlation,\nnamely mean accuracy of [0.721, 0.751] and mean AUC of [0.744, 0.860]. Our\nresults suggest the applicability of lsXGC as a potential biomarker for\nschizophrenia.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jan 2021 20:36:26 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Wism\u00fcller", "Axel", ""], ["Vosoughi", "M. Ali", ""]]}, {"id": "2101.10568", "submitter": "Torin Clark", "authors": "Jamie L. Voros, Sage O. Sherman, Rachel Rise, Alexander Kryuchkov,\n  Ponder Stine, Allison P. Anderson, and Torin K. Clark", "title": "Galvanic vestibular stimulation produces cross-modal improvements in\n  visual thresholds", "comments": "15 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Background: Stochastic resonance (SR) refers to a faint signal being enhanced\nwith the addition of white noise. Previous studies have found that vestibular\nperceptual thresholds are lowered with noisy galvanic vestibular stimulation\n(i.e., \"in-channel\" SR). Auditory white noise has been shown to improve tactile\nand visual thresholds, suggesting \"cross-modal\" SR. Objective: We aimed to\nstudy the cross-modal impact of noisy galvanic vestibular stimulation (nGVS)\n(n=9 subjects) on visual and auditory thresholds. Methods: We measured auditory\nand visual perceptual thresholds of human subjects across a swath of different\nnGVS levels in order to determine if a subject-specific best nGVS level\nelicited a reduction in thresholds as compared the no noise condition (sham).\nResults: We found an 18% improvement in visual thresholds (p = 0.026). Among\nthe 7 of 9 subjects with reduced thresholds, the average improvement was 26%.\nSubjects with higher (worse) visual thresholds with no stimulation (sham)\nimproved more than those with lower thresholds (p = 0.005). Auditory thresholds\nwere unchanged by vestibular stimulation. Conclusions: These results are the\nfirst demonstration of cross-modal improvement with nGVS, indicating galvanic\nvestibular white noise can produce cross-modal improvements in some sensory\nchannels, but not all.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2021 05:32:12 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Voros", "Jamie L.", ""], ["Sherman", "Sage O.", ""], ["Rise", "Rachel", ""], ["Kryuchkov", "Alexander", ""], ["Stine", "Ponder", ""], ["Anderson", "Allison P.", ""], ["Clark", "Torin K.", ""]]}, {"id": "2101.10617", "submitter": "Lingbin Bian", "authors": "Lingbin Bian, Tiangang Cui, B.T. Thomas Yeo, Alex Fornito, Adeel Razi\n  and Jonathan Keith", "title": "Identification of brain states, transitions, and communities using\n  functional MRI", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Brain function relies on a precisely coordinated and dynamic balance between\nthe functional integration and segregation of distinct neural systems.\nCharacterizing the way in which neural systems reconfigure their interactions\nto give rise to distinct but hidden brain states remains an open challenge. In\nthis paper, we propose a Bayesian model-based characterization of latent brain\nstates and showcase a novel method based on posterior predictive discrepancy\nusing the latent block model to detect transitions between latent brain states\nin blood oxygen level-dependent (BOLD) time series. The set of estimated\nparameters in the model includes a latent label vector that assigns network\nnodes to communities, and also block model parameters that reflect the weighted\nconnectivity within and between communities. Besides extensive in-silico model\nevaluation, we also provide empirical validation (and replication) using the\nHuman Connectome Project (HCP) dataset of 100 healthy adults. Our results\nobtained through an analysis of task-fMRI data during working memory\nperformance show appropriate lags between external task demands and\nchange-points between brain states, with distinctive community patterns\ndistinguishing fixation, low-demand and high-demand task conditions.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2021 08:10:00 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Bian", "Lingbin", ""], ["Cui", "Tiangang", ""], ["Yeo", "B. T. Thomas", ""], ["Fornito", "Alex", ""], ["Razi", "Adeel", ""], ["Keith", "Jonathan", ""]]}, {"id": "2101.10629", "submitter": "Gennaro Vessio Dr.", "authors": "Eufemia Lella, Gennaro Vessio", "title": "Ensembling complex network 'perspectives' for mild cognitive impairment\n  detection with artificial neural networks", "comments": null, "journal-ref": "Pattern Recognition Letters, Volume 136, August 2020, Pages\n  168-174", "doi": "10.1016/j.patrec.2020.06.001", "report-no": null, "categories": "cs.CV eess.IV q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In this paper, we propose a novel method for mild cognitive impairment\ndetection based on jointly exploiting the complex network and the neural\nnetwork paradigm. In particular, the method is based on ensembling different\nbrain structural \"perspectives\" with artificial neural networks. On one hand,\nthese perspectives are obtained with complex network measures tailored to\ndescribe the altered brain connectivity. In turn, the brain reconstruction is\nobtained by combining diffusion-weighted imaging (DWI) data to tractography\nalgorithms. On the other hand, artificial neural networks provide a means to\nlearn a mapping from topological properties of the brain to the presence or\nabsence of cognitive decline. The effectiveness of the method is studied on a\nwell-known benchmark data set in order to evaluate if it can provide an\nautomatic tool to support the early disease diagnosis. Also, the effects of\nbalancing issues are investigated to further assess the reliability of the\ncomplex network approach to DWI data.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2021 08:38:11 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Lella", "Eufemia", ""], ["Vessio", "Gennaro", ""]]}, {"id": "2101.10665", "submitter": "Claudius Gros", "authors": "Fabian Schubert, Claudius Gros", "title": "Local homeostatic regulation of the spectral radius of echo-state\n  networks", "comments": "Frontiers In Computational Neuroscience, in press", "journal-ref": "Frontiers In Computational Neuroscience 24, 587721 (2021)", "doi": "10.3389/fncom.2021.587721", "report-no": null, "categories": "q-bio.NC nlin.AO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent cortical networks provide reservoirs of states that are thought to\nplay a crucial role for sequential information processing in the brain.\nHowever, classical reservoir computing requires manual adjustments of global\nnetwork parameters, particularly of the spectral radius of the recurrent\nsynaptic weight matrix. It is hence not clear if the spectral radius is\naccessible to biological neural networks.\n  Using random matrix theory, we show that the spectral radius is related to\nlocal properties of the neuronal dynamics whenever the overall dynamical state\nis only weakly correlated. This result allows us to introduce two local\nhomeostatic synaptic scaling mechanisms, termed flow control and variance\ncontrol, that implicitly drive the spectral radius towards the desired value\nunder working conditions.\n  We demonstrate the effectiveness of the two adaptation mechanisms under\ndifferent external input protocols and the network performance after adaptation\nby training the network to perform a time-delayed XOR operation on binary\nsequences. As our main result, we found that flow control reliably regulates\nthe spectral radius for different types of input statistics. Precise tuning is\nhowever negatively affected when interneural correlations are substantial.\nFurthermore, we found a consistent task performance over a wide range of input\nstrengths/variances. Variance control did however not yield the desired\nspectral radii with the same precision, being less consistent across different\ninput strengths.\n  Given the effectiveness and remarkably simple mathematical form of flow\ncontrol, we conclude that self-consistent local control of the spectral radius\nvia an implicit adaptation scheme is an interesting and biological plausible\nalternative to conventional methods using setpoint homeostatic feedback\ncontrols of neural firing.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2021 09:47:37 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Schubert", "Fabian", ""], ["Gros", "Claudius", ""]]}, {"id": "2101.10953", "submitter": "Wei Zhong Goh", "authors": "Wei Zhong Goh, Varun Ursekar, Marc W. Howard", "title": "Predicting the future with a scale-invariant temporal memory for the\n  past", "comments": "28 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years it has become clear that the brain maintains a temporal\nmemory of recent events stretching far into the past. This paper presents a\nneurally-inspired algorithm to use a scale-invariant temporal representation of\nthe past to predict a scale-invariant future. The result is a scale-invariant\nestimate of future events as a function of the time at which they are expected\nto occur. The algorithm is time-local, with credit assigned to the present\nevent by observing how it affects the prediction of the future. To illustrate\nthe potential utility of this approach, we test the model on simultaneous\nrenewal processes with different time scales. The algorithm scales well on\nthese problems despite the fact that the number of states needed to describe\nthem as a Markov process grows exponentially.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2021 17:22:17 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Goh", "Wei Zhong", ""], ["Ursekar", "Varun", ""], ["Howard", "Marc W.", ""]]}, {"id": "2101.11143", "submitter": "Arthur Prat-Carrabin", "authors": "Arthur Prat-Carrabin, Robert C. Wilson, Jonathan D. Cohen, Rava\n  Azeredo da Silveira", "title": "Human Inference in Changing Environments With Temporal Structure", "comments": "59 pages, 21 figures, and 6 tables", "journal-ref": null, "doi": "10.1037/rev0000276", "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  To make informed decisions in natural environments that change over time,\nhumans must update their beliefs as new observations are gathered. Studies\nexploring human inference as a dynamical process that unfolds in time have\nfocused on situations in which the statistics of observations are\nhistory-independent. Yet temporal structure is everywhere in nature, and yields\nhistory-dependent observations. Do humans modify their inference processes\ndepending on the latent temporal statistics of their observations? We\ninvestigate this question experimentally and theoretically using a change-point\ninference task. We show that humans adapt their inference process to fine\naspects of the temporal structure in the statistics of stimuli. As such, humans\nbehave qualitatively in a Bayesian fashion, but, quantitatively, deviate away\nfrom optimality. Perhaps more importantly, humans behave suboptimally in that\ntheir responses are not deterministic, but variable. We show that this\nvariability itself is modulated by the temporal statistics of stimuli. To\nelucidate the cognitive algorithm that yields this behavior, we investigate a\nbroad array of existing and new models that characterize different sources of\nsuboptimal deviations away from Bayesian inference. While models with 'output\nnoise' that corrupts the response-selection process are natural candidates,\nhuman behavior is best described by sampling-based inference models, in which\nthe main ingredient is a compressed approximation of the posterior, represented\nthrough a modest set of random samples and updated over time. This result comes\nto complement a growing literature on sample-based representation and learning\nin humans.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jan 2021 00:31:46 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Prat-Carrabin", "Arthur", ""], ["Wilson", "Robert C.", ""], ["Cohen", "Jonathan D.", ""], ["da Silveira", "Rava Azeredo", ""]]}, {"id": "2101.11249", "submitter": "Sai Sukruth Bezugam", "authors": "Sai Sukruth Bezugam, Swatilekha Majumdar, Chetan Ralekar and Tapan\n  Kumar Gandhi", "title": "Efficient Video Summarization Framework using EEG and Eye-tracking\n  Signals", "comments": "10 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.HC cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes an efficient video summarization framework that will give\na gist of the entire video in a few key-frames or video skims. Existing video\nsummarization frameworks are based on algorithms that utilize computer vision\nlow-level feature extraction or high-level domain level extraction. However,\nbeing the ultimate user of the summarized video, humans remain the most\nneglected aspect. Therefore, the proposed paper considers human's role in\nsummarization and introduces human visual attention-based summarization\ntechniques. To understand human attention behavior, we have designed and\nperformed experiments with human participants using electroencephalogram (EEG)\nand eye-tracking technology. The EEG and eye-tracking data obtained from the\nexperimentation are processed simultaneously and used to segment frames\ncontaining useful information from a considerable video volume. Thus, the frame\nsegmentation primarily relies on the cognitive judgments of human beings. Using\nour approach, a video is summarized by 96.5% while maintaining higher precision\nand high recall factors. The comparison with the state-of-the-art techniques\ndemonstrates that the proposed approach yields ceiling-level performance with\nreduced computational cost in summarising the videos.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jan 2021 08:13:19 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Bezugam", "Sai Sukruth", ""], ["Majumdar", "Swatilekha", ""], ["Ralekar", "Chetan", ""], ["Gandhi", "Tapan Kumar", ""]]}, {"id": "2101.11679", "submitter": "Denis Goldobin", "authors": "Denis S. Goldobin and Matteo di Volo and Alessandro Torcini", "title": "A reduction methodology for fluctuation driven population dynamics", "comments": "10 pages (with supplementary materials), 3 figures", "journal-ref": "Phys. Rev. Lett. 127, 038301 (2021)", "doi": "10.1103/PhysRevLett.127.038301", "report-no": null, "categories": "cond-mat.stat-mech nlin.AO q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Lorentzian distributions have been largely employed in statistical mechanics\nto obtain exact results for heterogeneous systems. Analytic continuation of\nthese results is impossible even for slightly deformed Lorentzian\ndistributions, due to the divergence of all the moments (cumulants). We have\nsolved this problem by introducing a `pseudo-cumulants' expansion. This allows\nus to develop a reduction methodology for heterogeneous spiking neural networks\nsubject to extrinsinc and endogenous noise sources, thus generalizing the\nmean-field formulation introduced in [E. Montbri\\'o et al., Phys. Rev. X 5,\n021028 (2015)].\n", "versions": [{"version": "v1", "created": "Wed, 27 Jan 2021 20:24:28 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Goldobin", "Denis S.", ""], ["di Volo", "Matteo", ""], ["Torcini", "Alessandro", ""]]}, {"id": "2101.12507", "submitter": "Mathieu Desroches", "authors": "Mathieu Desroches, Piotr Kowalczyk, Serafim Rodrigues", "title": "Spike-adding and reset-induced canard cycles in adaptive integrate and\n  fire models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.DS q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a class of planar integrate and fire (IF) models called adaptive\nintegrate and fire (AIF) models, which possesses an adaptation variable on top\nof membrane potential, and whose subthreshold dynamics is piecewise linear\n(PWL). These AIF models therefore have two reset conditions, which enable\nbursting dynamics to emerge for suitable parameter values. Such models can be\nthought of as hybrid dynamical systems. We consider a particular slow dynamics\nwithin AIF models and prove the existence of bursting cycles with $N$ resets,\nfor any integer $N$. Furthermore, we study the transition between $N$- and\n$(N+1)$-reset cycles upon vanishingly small parameter variations and prove (for\n$N=2$) that such transitions are organised by canard cycles. Finally, using\nnumerical continuation we compute branches of bursting cycles, including\ncanard-explosive branches, in these AIF models, by suitably recasting the\nperiodic problem as a two-point boundary-value problem.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jan 2021 10:26:45 GMT"}], "update_date": "2021-02-01", "authors_parsed": [["Desroches", "Mathieu", ""], ["Kowalczyk", "Piotr", ""], ["Rodrigues", "Serafim", ""]]}, {"id": "2101.12559", "submitter": "Francesca Pitolli", "authors": "D. Calvetti, B. Johnson, A. Pascarella, F. Pitolli, E. Somersalo, B.\n  Vantaggi", "title": "Mining the Mind: Linear Discriminant Analysis of MEG source\n  reconstruction time series supports dynamic changes in deep brain regions\n  during meditation sessions", "comments": "34 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Meditation practices have been claimed to have a positive effect on the\nregulation of mood and emotion for quite some time by practitioners, and in\nrecent times there has been a sustained effort to provide a more precise\ndescription of the changes induced by meditation on human brain. Longitudinal\nstudies have reported morphological changes in cortical thickness and volume in\nselected brain regions due to meditation practice, which is interpreted as\nevidence for effectiveness of it beyond the subjective self reporting. Evidence\nbased on real time monitoring of meditating brain by functional imaging\nmodalities such as MEG or EEG remains a challenge. In this article we consider\nMEG data collected during meditation sessions of experienced Buddhist monks\npracticing focused attention (Samatha) and open monitoring (Vipassana)\nmeditation, contrasted by resting state with eyes closed. The MEG data is first\nmapped to time series of brain activity averaged over brain regions\ncorresponding to a standard Destrieux brain atlas, and further by bootstrapping\nand spectral analysis to data matrices representing a random sample of power\nspectral densities over bandwidths corresponding to $\\alpha$, $\\beta$,\n$\\gamma$, and $\\theta$ bands in the spectral range. We demonstrate using linear\ndiscriminant analysis (LDA) that the samples corresponding to different\nmeditative or resting states contain enough fingerprints of the brain state to\nallow a separation between different states, and we identify the brain regions\nthat appear to contribute to the separation. Our findings suggest that\ncingulate cortex, insular cortex and some of the internal structures, most\nnotably accumbens, caudate and putamen nuclei, thalamus and amygdalae stand out\nas separating regions, which seems to correlate well with earlier findings\nbased on longitudinal studies.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jan 2021 13:22:36 GMT"}], "update_date": "2021-02-01", "authors_parsed": [["Calvetti", "D.", ""], ["Johnson", "B.", ""], ["Pascarella", "A.", ""], ["Pitolli", "F.", ""], ["Somersalo", "E.", ""], ["Vantaggi", "B.", ""]]}]