[{"id": "1810.00045", "submitter": "Ali Farshchian", "authors": "Ali Farshchian, Juan A. Gallego, Joseph P. Cohen, Yoshua Bengio, Lee\n  E. Miller, Sara A. Solla", "title": "Adversarial Domain Adaptation for Stable Brain-Machine Interfaces", "comments": "14 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Brain-Machine Interfaces (BMIs) have recently emerged as a clinically viable\noption to restore voluntary movements after paralysis. These devices are based\non the ability to extract information about movement intent from neural signals\nrecorded using multi-electrode arrays chronically implanted in the motor\ncortices of the brain. However, the inherent loss and turnover of recorded\nneurons requires repeated recalibrations of the interface, which can\npotentially alter the day-to-day user experience. The resulting need for\ncontinued user adaptation interferes with the natural, subconscious use of the\nBMI. Here, we introduce a new computational approach that decodes movement\nintent from a low-dimensional latent representation of the neural data. We\nimplement various domain adaptation methods to stabilize the interface over\nsignificantly long times. This includes Canonical Correlation Analysis used to\nalign the latent variables across days; this method requires prior\npoint-to-point correspondence of the time series across domains. Alternatively,\nwe match the empirical probability distributions of the latent variables across\ndays through the minimization of their Kullback-Leibler divergence. These two\nmethods provide a significant and comparable improvement in the performance of\nthe interface. However, implementation of an Adversarial Domain Adaptation\nNetwork trained to match the empirical probability distribution of the\nresiduals of the reconstructed neural signals outperforms the two methods based\non latent variables, while requiring remarkably few data points to solve the\ndomain adaptation problem.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 18:56:46 GMT"}, {"version": "v2", "created": "Tue, 15 Jan 2019 17:59:26 GMT"}], "update_date": "2019-01-16", "authors_parsed": [["Farshchian", "Ali", ""], ["Gallego", "Juan A.", ""], ["Cohen", "Joseph P.", ""], ["Bengio", "Yoshua", ""], ["Miller", "Lee E.", ""], ["Solla", "Sara A.", ""]]}, {"id": "1810.00701", "submitter": "Krishnendu Pal", "authors": "Krishnendu Pal and Gautam Gangopadhyay", "title": "Effect Of Site Selective Ion Channel Blocking on Action Potential", "comments": "21 pages, 15 figures including supplemental materials, article to be\n  submitted in a journal soon", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.bio-ph q-bio.NC q-bio.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we have theoretically investigated how the action potential\ngeneration and its associated intrinsic properties are affected in presence of\nion channel blockers by adapting Gillepie's stochastic simulation technique on\na very basic neuron of Hodgkin-Huxley type. With a simple extension of the\nHodgkin-Huxley Markov model we have mainly investigated three types of drug\nblocking mechanisms and showed that the major experimental and physiological\nobservations such as ionic currents, spiking frequency trends, change in action\npotential shape and duration, altered gating dynamics etc due to the presence\nof ion channel blockers can be well reproduced. The nature of action potential\ntermination process in presence of sodium and potassium channel blockers are\ndistinct and physiologically very different from each other. Channel blockers\nhave distinct signatures on ionic currents. In presence of only sodium channel\nblockers the frequency of action potential generation falls off exponentially\nwith increasing drug affinity, whereas in contrast, for only potassium channel\nblockers initially an enhanced spiking activity of action potential is found\nfollowed by a gradual decrease of the spiking frequency as the drug affinity\nincreases. In case of dual type blockers with equal sodium and potassium\nchannel binding affinity, the spiking frequency passes through maxima and\nminima due to the competition between channel number fluctuation and overall\nsodium and potassium conductances. We have found that sodium channel blockers\nshorten the duration of action potential while the potassium channel blockers\ndelay it. We have also shown how the ion channel blockers alter the gating\ndynamics. Some experimental results of ion channel blocking in diverse systems\nhave been validated through our site selected binding scheme.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 13:39:25 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Pal", "Krishnendu", ""], ["Gangopadhyay", "Gautam", ""]]}, {"id": "1810.00786", "submitter": "Deirel Paz-Linares", "authors": "Eduardo Gonzalez-Moreira, Deirel Paz-Linares, Ariosky Areces-Gonzalez,\n  Rigel Wang, Jorge Bosch-Bayard, Maria Luisa Bringas-Vega and Pedro A.\n  Valdes-Sosa", "title": "Caulking the Leakage Effect in MEEG Source Connectivity Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simplistic estimation of neural connectivity in MEEG sensor space is\nimpossible due to volume conduction. The only viable alternative is to carry\nout connectivity estimation in source space. Among the neuroscience community\nthis is claimed to be impossible or misleading due to Leakage: linear mixing of\nthe reconstructed sources. To address this problematic we propose a novel\nsolution method that caulks the Leakage in MEEG source activity and\nconnectivity estimates: BC-VARETA. It is based on a joint estimation of source\nactivity and connectivity in the frequency domain representation of MEEG time\nseries. To achieve this, we go beyond current methods that assume a fixed\ngaussian graphical model for source connectivity. In contrast we estimate this\ngraphical model in a Bayesian framework by placing priors on it, which allows\nfor highly optimized computations of the connectivity, via a new procedure\nbased on the local quadratic approximation under quite general prior models. A\nfurther contribution of this paper is the rigorous definition of leakage via\nthe Spatial Dispersion Measure and Earth Movers Distance based on the geodesic\ndistances over the cortical manifold. Both measures are extended for the first\ntime to quantify Connectivity Leakage by defining them on the cartesian product\nof cortical manifolds. Using these measures, we show that BC-VARETA outperforms\nmost state of the art inverse solvers by several orders of magnitude.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 12:19:05 GMT"}, {"version": "v2", "created": "Mon, 2 Dec 2019 00:19:07 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Gonzalez-Moreira", "Eduardo", ""], ["Paz-Linares", "Deirel", ""], ["Areces-Gonzalez", "Ariosky", ""], ["Wang", "Rigel", ""], ["Bosch-Bayard", "Jorge", ""], ["Bringas-Vega", "Maria Luisa", ""], ["Valdes-Sosa", "Pedro A.", ""]]}, {"id": "1810.00816", "submitter": "Trang-Anh Estelle Nghiem", "authors": "Trang-Anh E. Nghiem, N\\'uria Tort-Colet, Tomasz G\\'orski, Ulisse\n  Ferrari, Shayan Moghimyfiroozabad, Jennifer S. Goldman, Bartosz Tele\\'nczuk,\n  Cristiano Capone, Thierry Bal, Matteo di Volo, and Alain Destexhe", "title": "Cholinergic switch between two types of slow waves in cerebral cortex", "comments": "37 pages, 5 main figures, 4 supplementary figures", "journal-ref": "Cerebral Cortex 2019", "doi": "10.1093/cercor/bhz320", "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sleep slow waves are known to participate in memory consolidation, yet slow\nwaves occurring under anesthesia present no positive effects on memory. Here,\nwe shed light onto this paradox, based on a combination of extracellular\nrecordings in vivo, in vitro, and computational models. We find two types of\nslow waves, based on analyzing the temporal patterns of successive slow-wave\nevents. The first type is consistently observed in natural slow-wave sleep,\nwhile the second is shown to be ubiquitous under anesthesia. Network models of\nspiking neurons predict that the two slow wave types emerge due to a different\ngain on inhibitory vs excitatory cells and that different levels of\nspike-frequency adaptation in excitatory cells can account for dynamical\ndistinctions between the two types. This prediction was tested in vitro by\nvarying adaptation strength using an agonist of acetylcholine receptors, which\ndemonstrated a neuromodulatory switch between the two types of slow waves.\nFinally, we show that the first type of slow-wave dynamics is more sensitive to\nexternal stimuli, which can explain how slow waves in sleep and anesthesia\ndifferentially affect memory consolidation, as well as provide a link between\nslow-wave dynamics and memory diseases.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 16:53:56 GMT"}, {"version": "v2", "created": "Wed, 10 Jul 2019 11:45:46 GMT"}, {"version": "v3", "created": "Thu, 28 Nov 2019 10:46:00 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Nghiem", "Trang-Anh E.", ""], ["Tort-Colet", "N\u00faria", ""], ["G\u00f3rski", "Tomasz", ""], ["Ferrari", "Ulisse", ""], ["Moghimyfiroozabad", "Shayan", ""], ["Goldman", "Jennifer S.", ""], ["Tele\u0144czuk", "Bartosz", ""], ["Capone", "Cristiano", ""], ["Bal", "Thierry", ""], ["di Volo", "Matteo", ""], ["Destexhe", "Alain", ""]]}, {"id": "1810.01174", "submitter": "Deirel Paz-Linares", "authors": "Deirel Paz-Linares, Eduardo Gonzalez-Moreira, Jorge Bosch-Bayard,\n  Ariosky Areces-Gonzalez, Maria L. Bringas-Vega and Pedro A. Valdes-Sosa", "title": "Neural Connectivity with Hidden Gaussian Graphical State-Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The noninvasive procedures for neural connectivity are under questioning.\nTheoretical models sustain that the electromagnetic field registered at\nexternal sensors is elicited by currents at neural space. Nevertheless, what we\nobserve at the sensor space is a superposition of projected fields, from the\nwhole gray-matter. This is the reason for a major pitfall of noninvasive\nElectrophysiology methods: distorted reconstruction of neural activity and its\nconnectivity or leakage. It has been proven that current methods produce\nincorrect connectomes. Somewhat related to the incorrect connectivity\nmodelling, they disregard either Systems Theory and Bayesian Information\nTheory. We introduce a new formalism that attains for it, Hidden Gaussian\nGraphical State-Model (HIGGS). A neural Gaussian Graphical Model (GGM) hidden\nby the observation equation of Magneto-encephalographic (MEEG) signals. HIGGS\nis equivalent to a frequency domain Linear State Space Model (LSSM) but with\nsparse connectivity prior. The mathematical contribution here is the theory for\nhigh-dimensional and frequency-domain HIGGS solvers. We demonstrate that HIGGS\ncan attenuate the leakage effect in the most critical case: the distortion EEG\nsignal due to head volume conduction heterogeneities. Its application in EEG is\nillustrated with retrieved connectivity patterns from human Steady State Visual\nEvoked Potentials (SSVEP). We provide for the first time confirmatory evidence\nfor noninvasive procedures of neural connectivity: concurrent EEG and\nElectrocorticography (ECoG) recordings on monkey. Open source packages are\nfreely available online, to reproduce the results presented in this paper and\nto analyze external MEEG databases.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 11:26:54 GMT"}, {"version": "v2", "created": "Mon, 8 Apr 2019 12:02:11 GMT"}, {"version": "v3", "created": "Thu, 2 May 2019 11:15:30 GMT"}], "update_date": "2019-05-03", "authors_parsed": [["Paz-Linares", "Deirel", ""], ["Gonzalez-Moreira", "Eduardo", ""], ["Bosch-Bayard", "Jorge", ""], ["Areces-Gonzalez", "Ariosky", ""], ["Bringas-Vega", "Maria L.", ""], ["Valdes-Sosa", "Pedro A.", ""]]}, {"id": "1810.01485", "submitter": "Patrick Schwab", "authors": "Patrick Schwab, Walter Karlen", "title": "PhoneMD: Learning to Diagnose Parkinson's Disease from Smartphone Data", "comments": "AAAI Conference on Artificial Intelligence 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parkinson's disease is a neurodegenerative disease that can affect a person's\nmovement, speech, dexterity, and cognition. Clinicians primarily diagnose\nParkinson's disease by performing a clinical assessment of symptoms. However,\nmisdiagnoses are common. One factor that contributes to misdiagnoses is that\nthe symptoms of Parkinson's disease may not be prominent at the time the\nclinical assessment is performed. Here, we present a machine-learning approach\ntowards distinguishing between people with and without Parkinson's disease\nusing long-term data from smartphone-based walking, voice, tapping and memory\ntests. We demonstrate that our attentive deep-learning models achieve\nsignificant improvements in predictive performance over strong baselines (area\nunder the receiver operating characteristic curve = 0.85) in data from a cohort\nof 1853 participants. We also show that our models identify meaningful features\nin the input data. Our results confirm that smartphone data collected over\nextended periods of time could in the future potentially be used as a digital\nbiomarker for the diagnosis of Parkinson's disease.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 11:38:18 GMT"}, {"version": "v2", "created": "Wed, 14 Nov 2018 23:53:32 GMT"}], "update_date": "2018-11-16", "authors_parsed": [["Schwab", "Patrick", ""], ["Karlen", "Walter", ""]]}, {"id": "1810.01747", "submitter": "Gard Spreemann", "authors": "Jean-Baptiste Bardin, Gard Spreemann, Kathryn Hess", "title": "Topological exploration of artificial neuronal network dynamics", "comments": null, "journal-ref": null, "doi": "10.1162/netn_a_00080", "report-no": null, "categories": "q-bio.NC math.AT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  One of the paramount challenges in neuroscience is to understand the dynamics\nof individual neurons and how they give rise to network dynamics when\ninterconnected. Historically, researchers have resorted to graph theory,\nstatistics, and statistical mechanics to describe the spatiotemporal structure\nof such network dynamics. Our novel approach employs tools from algebraic\ntopology to characterize the global properties of network structure and\ndynamics.\n  We propose a method based on persistent homology to automatically classify\nnetwork dynamics using topological features of spaces built from various\nspike-train distances. We investigate the efficacy of our method by simulating\nactivity in three small artificial neural networks with different sets of\nparameters, giving rise to dynamics that can be classified into four regimes.\nWe then compute three measures of spike train similarity and use persistent\nhomology to extract topological features that are fundamentally different from\nthose used in traditional methods. Our results show that a machine learning\nclassifier trained on these features can accurately predict the regime of the\nnetwork it was trained on and also generalize to other networks that were not\npresented during training. Moreover, we demonstrate that using features\nextracted from multiple spike-train distances systematically improves the\nperformance of our method.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 14:11:24 GMT"}, {"version": "v2", "created": "Mon, 28 Jan 2019 10:28:30 GMT"}], "update_date": "2019-02-08", "authors_parsed": [["Bardin", "Jean-Baptiste", ""], ["Spreemann", "Gard", ""], ["Hess", "Kathryn", ""]]}, {"id": "1810.01933", "submitter": "Duccio Fanelli", "authors": "Clement Zankoc, Duccio Fanelli, Francesco Ginelli, Roberto Livi", "title": "Desynchronization and pattern formation in a noisy feedforward\n  oscillators network", "comments": null, "journal-ref": "Phys. Rev. E 99, 012303 (2019)", "doi": "10.1103/PhysRevE.99.012303", "report-no": null, "categories": "cond-mat.dis-nn cond-mat.stat-mech nlin.CD nlin.PS q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a one-dimensional directional array of diffusively coupled\noscillators. They are perturbed by the injection of a small additive noise,\ntypically orders of magnitude smaller than the oscillation amplitude, and the\nsystem is studied in a region of the parameters that would yield deterministic\nsynchronization. Non normal directed couplings seed a coherent amplification of\nthe perturbation: this latter manifests as a modulation, transversal to the\nlimit cycle, which gains in potency node after node. If the lattice extends\nlong enough, the initial synchrony gets eventually lost and the system moves\ntoward a non trivial attractor, which can be analytically characterized as an\nasymptotic splay state. The noise assisted instability, ultimately vehiculated\nand amplified by the non normal nature of the imposed couplings, eventually\ndestabilizes also this second attractor. This phenomenon yields spatiotemporal\npatterns, which cannot be anticipated by a conventional linear stability\nanalysis.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 19:50:36 GMT"}], "update_date": "2019-01-09", "authors_parsed": [["Zankoc", "Clement", ""], ["Fanelli", "Duccio", ""], ["Ginelli", "Francesco", ""], ["Livi", "Roberto", ""]]}, {"id": "1810.02107", "submitter": "Aurore Bussalb", "authors": "Aurore Bussalb, Marie Prat, David Ojeda, Quentin Barth\\'elemy, Julien\n  Bonnaud, Louis Mayaud", "title": "A framework for the comparison of different EEG acquisition solutions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The purpose of this work is to propose a framework for the benchmarking of\nEEG amplifiers, headsets, and electrodes providing objective recommendation for\na given application. The framework covers: data collection paradigm, data\nanalysis, and statistical framework. To illustrate, data was collected from 12\ndifferent devices totaling up to 6 subjects per device. Two data acquisition\nprotocols were implemented: a resting-state protocol eyes-open (EO) and\neyes-closed (EC), and an Auditory Evoked Potential (AEP) protocol.\nSignal-to-noise ratio (SNR) on alpha band (EO/EC) and Event Related Potential\n(ERP) were extracted as objective quantification of physiologically meaningful\ninformation. Then, visual representation, univariate statistical analysis, and\nmultivariate model were performed to increase results interpretability.\nObjective criteria show that the spectral SNR in alpha does not provide much\ndiscrimination between systems, suggesting that the acquisition quality might\nnot be of primary importance for spectral and specifically alpha-based\napplications. On the contrary, AEP SNR proved much more variable stressing the\nimportance of the acquisition setting for ERP experiments. The multivariate\nanalysis identified some individuals and some systems as independent\nstatistically significant contributors to the SNR. It highlights the importance\nof inter-individual differences in neurophysiological experiments (sample size)\nand suggests some device might objectively be superior to others when it comes\nto ERP recordings. However, the illustration of the proposed benchmarking\nframework suffers from severe limitations including small sample size and sound\ncard jitter in the auditory stimulations. While these limitations hinders a\ndefinite ranking of the evaluated hardware, we believe the proposed\nbenchmarking framework to be a modest yet valuable contribution to the field.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 09:09:19 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Bussalb", "Aurore", ""], ["Prat", "Marie", ""], ["Ojeda", "David", ""], ["Barth\u00e9lemy", "Quentin", ""], ["Bonnaud", "Julien", ""], ["Mayaud", "Louis", ""]]}, {"id": "1810.02476", "submitter": "Aurelio Cortese", "authors": "Aurelio Cortese, Benedetto De Martino, Mitsuo Kawato", "title": "The neural and cognitive architecture for learning from a small sample", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial intelligence algorithms are capable of fantastic exploits, yet\nthey are still grossly inefficient compared with the brain's ability to learn\nfrom few exemplars or solve problems that have not been explicitly defined.\nWhat is the secret that the evolution of human intelligence has unlocked?\nGeneralization is one answer, but there is more to it. The brain does not\ndirectly solve difficult problems, it is able to recast them into new and more\ntractable problems. Here we propose a model whereby higher cognitive functions\nprofoundly interact with reinforcement learning to drastically reduce the\ndegrees of freedom of the search space, simplifying complex problems and\nfostering more efficient learning.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 00:57:41 GMT"}], "update_date": "2018-10-08", "authors_parsed": [["Cortese", "Aurelio", ""], ["De Martino", "Benedetto", ""], ["Kawato", "Mitsuo", ""]]}, {"id": "1810.02584", "submitter": "Xi Wang", "authors": "Xi Wang, C. Alexis Gkogkidis, Robin T. Schirrmeister, Felix A.\n  Heilmeyer, Mortimer Gierthmuehlen, Fabian Kohler, Martin Schuettler, Thomas\n  Stieglitz, Tonio Ball", "title": "Deep Learning for micro-Electrocorticographic ({\\mu}ECoG) Data", "comments": "6 pages, 7 figures, 2018 IEEE EMBS conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning can extract information from neural recordings, e.g.,\nsurface EEG, ECoG and {\\mu}ECoG, and therefore plays an important role in many\nresearch and clinical applications. Deep learning with artificial neural\nnetworks has recently seen increasing attention as a new approach in brain\nsignal decoding. Here, we apply a deep learning approach using convolutional\nneural networks to {\\mu}ECoG data obtained with a wireless, chronically\nimplanted system in an ovine animal model. Regularized linear discriminant\nanalysis (rLDA), a filter bank component spatial pattern (FBCSP) algorithm and\nconvolutional neural networks (ConvNets) were applied to auditory evoked\nresponses captured by {\\mu}ECoG. We show that compared with rLDA and FBCSP,\nsignificantly higher decoding accuracy can be obtained by ConvNets trained in\nan end-to-end manner, i.e., without any predefined signal features. Deep\nlearning thus proves a promising technique for {\\mu}ECoG-based brain-machine\ninterfacing applications.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 09:44:09 GMT"}], "update_date": "2018-10-08", "authors_parsed": [["Wang", "Xi", ""], ["Gkogkidis", "C. Alexis", ""], ["Schirrmeister", "Robin T.", ""], ["Heilmeyer", "Felix A.", ""], ["Gierthmuehlen", "Mortimer", ""], ["Kohler", "Fabian", ""], ["Schuettler", "Martin", ""], ["Stieglitz", "Thomas", ""], ["Ball", "Tonio", ""]]}, {"id": "1810.02647", "submitter": "Sebastian Stober", "authors": "Andr\\'e Ofner, Sebastian Stober", "title": "Hybrid Active Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a framework of hybrid cognition by formulating a hybrid cognitive\nagent that performs hierarchical active inference across a human and a machine\npart. We suggest that, in addition to enhancing human cognitive functions with\nan intelligent and adaptive interface, integrated cognitive processing could\naccelerate emergent properties within artificial intelligence. To establish\nthis, a machine learning part learns to integrate into human cognition by\nexplaining away multi-modal sensory measurements from the environment and\nphysiology simultaneously with the brain signal. With ongoing training, the\namount of predictable brain signal increases. This lends the agent the ability\nto self-supervise on increasingly high levels of cognitive processing in order\nto further minimize surprise in predicting the brain signal. Furthermore, with\nincreasing level of integration, the access to sensory information about\nenvironment and physiology is substituted with access to their representation\nin the brain. While integrating into a joint embodiment of human and machine,\nhuman action and perception are treated as the machine's own. The framework can\nbe implemented with invasive as well as non-invasive sensors for environment,\nbody and brain interfacing. Online and offline training with different machine\nlearning approaches are thinkable. Building on previous research on shared\nrepresentation learning, we suggest a first implementation leading towards\nhybrid active inference with non-invasive brain interfacing and state of the\nart probabilistic deep learning methods. We further discuss how implementation\nmight have effect on the meta-cognitive abilities of the described agent and\nsuggest that with adequate implementation the machine part can continue to\nexecute and build upon the learned cognitive processes autonomously.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 12:32:55 GMT"}], "update_date": "2018-10-08", "authors_parsed": [["Ofner", "Andr\u00e9", ""], ["Stober", "Sebastian", ""]]}, {"id": "1810.02842", "submitter": "Kuan-Jung Chiang", "authors": "Kuan-Jung Chiang, Chun-Shu Wei, Masaki Nakanishi, and Tzyy-Ping Jung", "title": "Cross-Subject Transfer Learning Improves the Practicality of Real-World\n  Applications of Brain-Computer Interfaces", "comments": "4 pages, 3 figures, 1 table. For NER'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.HC cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Steady-state visual evoked potential (SSVEP)-based brain-computer interfaces\n(BCIs) have shown its robustness in facilitating high-efficiency communication.\nState-of-the-art training-based SSVEP decoding methods such as extended\nCanonical Correlation Analysis (CCA) and Task-Related Component Analysis (TRCA)\nare the major players that elevate the efficiency of the SSVEP-based BCIs\nthrough a calibration process. However, due to notable human variability across\nindividuals and within individuals over time, calibration (training) data\ncollection is non-negligible and often laborious and time-consuming,\ndeteriorating the practicality of SSVEP BCIs in a real-world context. This\nstudy aims to develop a cross-subject transferring approach to reduce the need\nfor collecting training data from a test user with a newly proposed\nleast-squares transformation (LST) method. Study results show the capability of\nthe LST in reducing the number of training templates required for a 40-class\nSSVEP BCI. The LST method may lead to numerous real-world applications using\nnear-zero-training/plug-and-play high-speed SSVEP BCIs.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 18:33:54 GMT"}, {"version": "v2", "created": "Tue, 30 Oct 2018 22:32:08 GMT"}, {"version": "v3", "created": "Sat, 3 Nov 2018 05:16:51 GMT"}, {"version": "v4", "created": "Wed, 13 Mar 2019 21:14:29 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Chiang", "Kuan-Jung", ""], ["Wei", "Chun-Shu", ""], ["Nakanishi", "Masaki", ""], ["Jung", "Tzyy-Ping", ""]]}, {"id": "1810.02923", "submitter": "Baihan Lin", "authors": "Baihan Lin, Nikolaus Kriegeskorte", "title": "Adaptive Geo-Topological Independence Criterion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG math.ST q-bio.NC stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Testing two potentially multivariate variables for statistical dependence on\nthe basis finite samples is a fundamental statistical challenge. Here we\nexplore a family of tests that adapt to the complexity of the relationship\nbetween the variables, promising robust power across scenarios. Building on the\ndistance correlation, we introduce a family of adaptive independence criteria\nbased on nonlinear monotonic transformations of distances. We show that these\ncriteria, like the distance correlation and RKHS-based criteria, provide\ndependence indicators. We propose a class of adaptive (multi-threshold) test\nstatistics, which form the basis for permutation tests. These tests empirically\noutperform some of the established tests in average and worst-case statistical\nsensitivity across a range of univariate and multivariate relationships, offer\nuseful insights to the data and may deserve further exploration.\n", "versions": [{"version": "v1", "created": "Sat, 6 Oct 2018 02:12:21 GMT"}, {"version": "v2", "created": "Wed, 9 Oct 2019 08:21:04 GMT"}, {"version": "v3", "created": "Sun, 7 Jun 2020 07:14:42 GMT"}, {"version": "v4", "created": "Tue, 9 Jun 2020 05:18:55 GMT"}, {"version": "v5", "created": "Thu, 18 Jun 2020 01:30:58 GMT"}, {"version": "v6", "created": "Thu, 22 Oct 2020 03:44:58 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Lin", "Baihan", ""], ["Kriegeskorte", "Nikolaus", ""]]}, {"id": "1810.03199", "submitter": "Blake Bordelon", "authors": "Bryce Bagley, Blake Bordelon, Benjamin Moseley, Ralf Wessel", "title": "Pre-Synaptic Pool Modification (PSPM): A Supervised Learning Procedure\n  for Spiking Neural Networks", "comments": "24 pages, 8 figures, Code and data can be found at\n  https://github.com/blakebordelon/Spiking-Neural-Network-Optimization", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning synaptic weights of spiking neural network (SNN) models that can\nreproduce target spike trains from provided neural firing data is a central\nproblem in computational neuroscience and spike-based computing. The discovery\nof the optimal weight values can be posed as a supervised learning task wherein\nthe weights of the model network are chosen to maximize the similarity between\nthe target spike trains and the model outputs. It is still largely unknown\nwhether optimizing spike train similarity of highly recurrent SNNs produces\nweight matrices similar to those of the ground truth model. To this end, we\npropose flexible heuristic supervised learning rules, termed Pre-Synaptic Pool\nModification (PSPM), that rely on stochastic weight updates in order to produce\nspikes within a short window of the desired times and eliminate spikes outside\nof this window. PSPM improves spike train similarity for all-to-all SNNs and\nmakes no assumption about the post-synaptic potential of the neurons or the\nstructure of the network since no gradients are required. We test whether\noptimizing for spike train similarity entails the discovery of accurate weights\nand explore the relative contributions of local and homeostatic weight updates.\nAlthough PSPM improves similarity between spike trains, the learned weights\noften differ from the weights of the ground truth model, implying that\nconnectome inference from spike data may require additional constraints on\nconnectivity statistics. We also find that spike train similarity is sensitive\nto local updates, but other measures of network activity such as avalanche\ndistributions, can be learned through synaptic homeostasis.\n", "versions": [{"version": "v1", "created": "Sun, 7 Oct 2018 19:43:09 GMT"}, {"version": "v2", "created": "Wed, 10 Oct 2018 13:18:06 GMT"}, {"version": "v3", "created": "Tue, 8 Oct 2019 23:38:08 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Bagley", "Bryce", ""], ["Bordelon", "Blake", ""], ["Moseley", "Benjamin", ""], ["Wessel", "Ralf", ""]]}, {"id": "1810.03262", "submitter": "Yiwei Zhang", "authors": "Congping Lin, Yuanfei Huang, Tingwei Quan and Yiwei Zhang", "title": "Modelling brain-wide neuronal morphology via rooted Cayley trees", "comments": "11 pages, 8 figures, Accepted to Scientific reports 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.DS math.ST q-bio.NC stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neuronal morphology is an essential element for brain activity and function.\nWe take advantage of current availability of brain-wide neuron digital\nreconstructions of the Pyramidal cells from a mouse brain, and analyze several\nemergent features of brain-wide neuronal morphology. We observe that axonal\ntrees are self-affine while dendritic trees are self-similar. We also show that\ntree size appear to be random, independent of the number of dendrites within\nsingle neurons. Moreover, we consider inhomogeneous branching model which\nstochastically generates rooted 3-Cayley trees for the brain-wide neuron\ntopology. Based on estimated order-dependent branching probability from actual\naxonal and dendritic trees, our inhomogeneous model quantitatively captures a\nnumber of topological features including size and shape of both axons and\ndendrites. This sheds lights on a universal mechanism behind the topological\nformation of brain-wide axonal and dendritic trees.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 03:52:11 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Lin", "Congping", ""], ["Huang", "Yuanfei", ""], ["Quan", "Tingwei", ""], ["Zhang", "Yiwei", ""]]}, {"id": "1810.03428", "submitter": "Federica Turi", "authors": "Federica Turi (ATHENA, UCA), Nathalie Gayraud (ATHENA, UCA), Maureen\n  Clerc (ATHENA, UCA)", "title": "Zero-calibration cVEP BCI using word prediction: a proof of concept", "comments": "BCI 2018 - 7th International BCI Meeting, May 2018, Pacific Grove,\n  California, United States", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Brain Computer Interfaces (BCIs) based on visual evoked potentials (VEP)\nallow for spelling from a keyboard of flashing characters. Among VEP BCIs,\ncode-modulated visual evoked potentials (c-VEPs) are designed for high-speed\ncommunication . In c-VEPs, all characters flash simultaneously. In particular,\neach character flashes according to a predefined 63-bit binary sequence\n(m-sequence), circular-shifted by a different time lag. For a given character,\nthe m-sequence evokes a VEP in the electroencephalogram (EEG) of the subject,\nwhich can be used as a template. This template is obtained during a calibration\nphase at the beginning of each session. Then, the system outputs the desired\ncharacter after a predefined number of repetitions by estimating its time lag\nwith respect to the template. Our work avoids the calibration phase, by\nextracting from the VEP relative lags between successive characters, and\npredicting the full word using a dictionary.\n", "versions": [{"version": "v1", "created": "Fri, 21 Sep 2018 06:25:56 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Turi", "Federica", "", "ATHENA, UCA"], ["Gayraud", "Nathalie", "", "ATHENA, UCA"], ["Clerc", "Maureen", "", "ATHENA, UCA"]]}, {"id": "1810.03661", "submitter": "Bartosz Jura", "authors": "Bartosz Jura", "title": "A mechanism of synaptic clock underlying subjective time perception", "comments": "21 pages, 4 figures", "journal-ref": "Frontiers in Neuroscience 13: 716 (2019)", "doi": "10.3389/fnins.2019.00716", "report-no": null, "categories": "q-bio.NC q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Temporal resolution of visual information processing is thought to be an\nimportant factor in predator-prey interactions, shaped in the course of\nevolution by animals' ecology. Here I show that light can be considered to have\na dual role of a source of information, which guides motor actions, and an\nenvironmental feedback for those actions. I consequently show how temporal\nperception might depend on behavioral adaptations realized by the nervous\nsystem. I propose an underlying mechanism of synaptic clock, with every synapse\nhaving its characteristic time unit, determined by the persistence of memory\ntraces of synaptic inputs, which is used by the synapse to tell time. The\npresent theory offers a testable framework, which may account for numerous\nexperimental findings, including the interspecies variation in temporal\nresolution and the properties of subjective time perception, specifically the\nvariable speed of perceived time passage, depending on emotional and\nattentional states or tasks performed.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 19:05:40 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Jura", "Bartosz", ""]]}, {"id": "1810.03855", "submitter": "Ivan Lazarevich", "authors": "Ivan Lazarevich, Ilya Prokin, and Boris Gutkin", "title": "Neural activity classification with machine learning models trained on\n  interspike interval series data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The flow of information through the brain is reflected by the activity\npatterns of neural cells. Indeed, these firing patterns are widely used as\ninput data to predictive models that relate stimuli and animal behavior to the\nactivity of a population of neurons. However, relatively little attention was\npaid to single neuron spike trains as predictors of cell or network properties\nin the brain. In this work, we introduce an approach to neuronal spike train\ndata mining which enables effective classification and clustering of neuron\ntypes and network activity states based on single-cell spiking patterns. This\napproach is centered around applying state-of-the-art time series\nclassification/clustering methods to sequences of interspike intervals recorded\nfrom single neurons. We demonstrate good performance of these methods in tasks\ninvolving classification of neuron type (e.g. excitatory vs. inhibitory cells)\nand/or neural circuit activity state (e.g. awake vs. REM sleep vs. nonREM sleep\nstates) on an open-access cortical spiking activity dataset.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 08:35:47 GMT"}, {"version": "v2", "created": "Sat, 11 Jan 2020 15:00:52 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Lazarevich", "Ivan", ""], ["Prokin", "Ilya", ""], ["Gutkin", "Boris", ""]]}, {"id": "1810.03856", "submitter": "Rufin VanRullen", "authors": "Rufin VanRullen and Leila Reddy", "title": "Reconstructing Faces from fMRI Patterns using Deep Generative Neural\n  Networks", "comments": null, "journal-ref": "Commun Biol 2, 193 (2019)", "doi": "10.1038/s42003-019-0438-y", "report-no": null, "categories": "cs.HC q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While objects from different categories can be reliably decoded from fMRI\nbrain response patterns, it has proved more difficult to distinguish visually\nsimilar inputs, such as different instances of the same category. Here, we\napply a recently developed deep learning system to the reconstruction of face\nimages from human fMRI patterns. We trained a variational auto-encoder (VAE)\nneural network using a GAN (Generative Adversarial Network) unsupervised\ntraining procedure over a large dataset of celebrity faces. The auto-encoder\nlatent space provides a meaningful, topologically organized 1024-dimensional\ndescription of each image. We then presented several thousand face images to\nhuman subjects, and learned a simple linear mapping between the multi-voxel\nfMRI activation patterns and the 1024 latent dimensions. Finally, we applied\nthis mapping to novel test images, turning the obtained fMRI patterns into VAE\nlatent codes, and ultimately the codes into face reconstructions. Qualitative\nand quantitative evaluation of the reconstructions revealed robust pairwise\ndecoding (>95% correct), and a strong improvement relative to a baseline model\n(PCA decomposition). Furthermore, this brain decoding model can readily be\nrecycled to probe human face perception along many dimensions of interest; for\nexample, the technique allowed for accurate gender classification, and even to\ndecode which face was imagined, rather than seen by the subject. We hypothesize\nthat the latent space of modern deep learning generative models could serve as\na valid approximation for human brain representations.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 08:40:53 GMT"}, {"version": "v2", "created": "Sun, 17 Feb 2019 22:37:44 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["VanRullen", "Rufin", ""], ["Reddy", "Leila", ""]]}, {"id": "1810.04026", "submitter": "Keith Dillon", "authors": "Keith Dillon and Yu-Ping Wang", "title": "Spectral Resolution Clustering for Brain Parcellation", "comments": null, "journal-ref": "Journal of Neuroscience Methods, Volume 335, 2020, 108628", "doi": null, "report-no": null, "categories": "q-bio.NC cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We take an image science perspective on the problem of determining brain\nnetwork connectivity given functional activity. But adapting the concept of\nimage resolution to this problem, we provide a new perspective on network\npartitioning for individual brain parcellation. The typical goal here is to\ndetermine densely-interconnected subnetworks within a larger network by\nchoosing the best edges to cut. We instead define these subnetworks as\nresolution cells, where highly-correlated activity within the cells makes edge\nweights difficult to determine from the data. Subdividing the resolution\nestimates into disjoint resolution cells via clustering yields a new variation,\nand new perspective, on spectral clustering. This provides insight and\nstrategies for open questions such as the selection of model order and the\noptimal choice of preprocessing steps for functional imaging data. The approach\nis demonstrated using functional imaging data, where we find the proposed\napproach produces parcellations which are more predictive across multiple scans\nversus conventional methods, as well as versus alternative forms of spectral\nclustering.\n", "versions": [{"version": "v1", "created": "Sun, 7 Oct 2018 03:40:58 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Dillon", "Keith", ""], ["Wang", "Yu-Ping", ""]]}, {"id": "1810.04191", "submitter": "Maria Lombardi", "authors": "Maria Lombardi, Davide Liuzza, Mario di Bernardo", "title": "Using learning to control artificial avatars in human motor coordination\n  tasks", "comments": "16 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing artificial cyber-agents able to interact with human safely, smartly\nand in a natural way is a current open problem in control. Solving such an\nissue will allow the design of cyber-agents capable of co-operatively\ninteracting with people in order to fulfil common joint tasks in a multitude of\ndifferent applications. This is particularly relevant in the context of\nhealthcare applications. Indeed, the use has been proposed of artificial agents\ninteracting and coordinating their movements with those of a patient suffering\nfrom social or motor disorders. Specifically, it has been shown that an\nartificial agent exhibiting certain kinematic properties could provide\ninnovative and efficient rehabilitation strategies for these patients.\nMoreover, it has also been shown that the level of motor coordination is\nenhanced if these kinematic properties are similar to those of the individual\nit is interacting with. In this paper we discuss, first, a new method based on\nMarkov Chains to confer \"human motor characteristics\" on a virtual agent, so as\nthat it can coordinate its motion with that of a target individual while\nexhibiting specific kinematic properties. Then, we embed such synthetic model\nin a control architecture based on reinforcement learning to synthesize a\ncyber-agent able to mimic the behaviour of a specific human performing a joint\nmotor task with one or more individuals.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 18:05:39 GMT"}, {"version": "v2", "created": "Wed, 17 Jun 2020 08:41:17 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Lombardi", "Maria", ""], ["Liuzza", "Davide", ""], ["di Bernardo", "Mario", ""]]}, {"id": "1810.04280", "submitter": "Bo Deng", "authors": "Bo Deng", "title": "Is Neuron Made from Mathematics?", "comments": "8 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is to derive a mathematical model for neuron by imposing only a\nprinciple of symmetry that two modelers must come up with the same model when\none is approaching the problem by modeling the conductances of ion channels and\nthe other by the channel resistances.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 22:16:42 GMT"}], "update_date": "2018-10-11", "authors_parsed": [["Deng", "Bo", ""]]}, {"id": "1810.04381", "submitter": "Krishnendu Pal", "authors": "Krishnendu Pal and Gautam Gangopadhyay", "title": "Effect of Channel Noise in Synchronization and Metabolic Energy\n  Consumption in Unidirectionally Coupled Neurons: Drug Blocking of Sodium and\n  Potassium Channels", "comments": "To be submitted soon in a journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.bio-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work the stochastic generalization of single Hodgkin-Huxley neuron is\nfurther extended to unidirectionally coupled neurons. Our main focus is to\nelucidate the role of channel noise in the kinetics and energetics of spiking\nof action potential and the synchronization between two coupled neurons. We\nhave found that the size of the patch is playing the pivotal role in\nsynchronization and metabolic energy consumption. For example, there exists\nthree different patch size ranges in which coupled neuron system behaves in a\ndifferent manner from noise enhanced phase to dead range state before reaching\nthe deterministic limit. We have also found that the sodium and potassium\nchannel blockers have characteristic kinetic and energetic effects on\nsynchronization process and metabolic energy consumption rate which has been\nvalidated with the simulated data.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 06:20:06 GMT"}], "update_date": "2018-10-11", "authors_parsed": [["Pal", "Krishnendu", ""], ["Gangopadhyay", "Gautam", ""]]}, {"id": "1810.05077", "submitter": "Abdullah Alchihabi", "authors": "Abdullah Alchihabi, Omer Ekmekci, Baran B. Kivilcim, Sharlene D.\n  Newman, Fatos T. Yarman Vural", "title": "On the Brain Networks of Complex Problem Solving", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complex problem solving is a high level cognitive process which has been\nthoroughly studied over the last decade. The Tower of London (TOL) is a task\nthat has been widely used to study problem-solving. In this study, we aim to\nexplore the underlying cognitive network dynamics among anatomical regions of\ncomplex problem solving and its sub-phases, namely planning and execution. A\nnew brain network construction model establishing dynamic functional brain\nnetworks using fMRI is proposed. The first step of the model is a preprocessing\npipeline that manages to decrease the spatial redundancy while increasing the\ntemporal resolution of the fMRI recordings. Then, dynamic brain networks are\nestimated using artificial neural networks. The network properties of the\nestimated brain networks are studied in order to identify regions of interest,\nsuch as hubs and subgroups of densely connected brain regions. The major\nsimilarities and dissimilarities of the network structure of planning and\nexecution phases are highlighted. Our findings show the hubs and clusters of\ndensely interconnected regions during both subtasks. It is observed that there\nare more hubs during the planning phase compared to the execution phase, and\nthe clusters are more strongly connected during planning compared to execution.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 09:22:21 GMT"}], "update_date": "2018-10-12", "authors_parsed": [["Alchihabi", "Abdullah", ""], ["Ekmekci", "Omer", ""], ["Kivilcim", "Baran B.", ""], ["Newman", "Sharlene D.", ""], ["Vural", "Fatos T. Yarman", ""]]}, {"id": "1810.05558", "submitter": "Luigi Acerbi", "authors": "Luigi Acerbi", "title": "Variational Bayesian Monte Carlo", "comments": "In Advances in Neural Information Processing Systems 31 (NeurIPS\n  2018), pp. 8222-8232. (25 pages, 9 figures)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.NC q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many probabilistic models of interest in scientific computing and machine\nlearning have expensive, black-box likelihoods that prevent the application of\nstandard techniques for Bayesian inference, such as MCMC, which would require\naccess to the gradient or a large number of likelihood evaluations. We\nintroduce here a novel sample-efficient inference framework, Variational\nBayesian Monte Carlo (VBMC). VBMC combines variational inference with\nGaussian-process based, active-sampling Bayesian quadrature, using the latter\nto efficiently approximate the intractable integral in the variational\nobjective. Our method produces both a nonparametric approximation of the\nposterior distribution and an approximate lower bound of the model evidence,\nuseful for model selection. We demonstrate VBMC both on several synthetic\nlikelihoods and on a neuronal model with data from real neurons. Across all\ntested problems and dimensions (up to $D = 10$), VBMC performs consistently\nwell in reconstructing the posterior and the model evidence with a limited\nbudget of likelihood evaluations, unlike other methods that work only in very\nlow dimensions. Our framework shows great promise as a novel tool for posterior\nand model inference with expensive, black-box likelihoods.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 14:50:13 GMT"}, {"version": "v2", "created": "Thu, 29 Nov 2018 12:47:30 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["Acerbi", "Luigi", ""]]}, {"id": "1810.05909", "submitter": "Bhargav Karamched", "authors": "Bhargav Karamched and Simon Stolarczyk and Zachary Kilpatrick and\n  Kre\\v{s}imir Josi\\'c", "title": "Bayesian Evidence Accumulation on Social Networks", "comments": "decision-making; probabilistic inference; social networks", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.SI q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To make decisions we are guided by the evidence we collect, as well as the\nopinions of friends and neighbors. How do we integrate our private beliefs with\ninformation we obtain from our social network? To understand the strategies\nhumans use to do so it is useful to compare them to observers that optimally\nintegrate all evidence. Here we derive network models of rational (Bayes\noptimal) agents who accumulate private measurements and observe decisions of\ntheir neighbors to make an irreversible choice between two options. The\nresulting information exchange dynamics has interesting properties: When one\noption is preferred, the absence of a decision can be increasingly informative\nover time. In recurrent networks an absence of a decision can lead to a\nsequence of belief updates akin to those in the literature on common knowledge.\nInformation obtained from observing repeated non-decisions is independent of\nrealization, unless the private information of agents is redundant. On the\nother hand, in larger networks a single decision can trigger a cascade of\nagreements and disagreements that depend on the private information agents have\ngathered. Our approach provides a bridge between social decision making models\nin the economics literature, which largely ignore the temporal dynamics of\ndecisions, and the single-observer evidence accumulator models used widely in\nneuroscience and psychology.\n", "versions": [{"version": "v1", "created": "Sat, 13 Oct 2018 18:30:19 GMT"}, {"version": "v2", "created": "Wed, 20 Mar 2019 20:31:17 GMT"}, {"version": "v3", "created": "Mon, 2 Mar 2020 22:26:28 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Karamched", "Bhargav", ""], ["Stolarczyk", "Simon", ""], ["Kilpatrick", "Zachary", ""], ["Josi\u0107", "Kre\u0161imir", ""]]}, {"id": "1810.06710", "submitter": "Ardavan Salehi Nobandegani", "authors": "Ardavan S. Nobandegani, William Campoli, Thomas R. Shultz", "title": "Bringing Order to the Cognitive Fallacy Zoo", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the eyes of a rationalist like Descartes or Spinoza, human reasoning is\nflawless, marching toward uncovering ultimate truth. A few centuries later,\nhowever, culminating in the work of Kahneman and Tversky, human reasoning was\nportrayed as anything but flawless, filled with numerous misjudgments, biases,\nand cognitive fallacies. With further investigations, new cognitive fallacies\ncontinually emerged, leading to a state of affairs which can fairly be\ncharacterized as the cognitive fallacy zoo! In this largely methodological\nwork, we formally present a principled way to bring order to this zoo. We\nintroduce the idea of establishing implication relationships (IRs) between\ncognitive fallacies, formally characterizing how one fallacy implies another.\nIR is analogous to, and partly inspired by, the fundamental concept of\nreduction in computational complexity theory. We present several examples of\nIRs involving experimentally well-documented cognitive fallacies: base-rate\nneglect, availability bias, conjunction fallacy, decoy effect, framing effect,\nand Allais paradox. We conclude by discussing how our work: (i) allows for\nidentifying those pivotal cognitive fallacies whose investigation would be the\nmost rewarding research agenda, and importantly (ii) permits a systematized,\nguided research program on cognitive fallacies, motivating influential\ntheoretical as well as experimental avenues of future research.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 21:37:38 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Nobandegani", "Ardavan S.", ""], ["Campoli", "William", ""], ["Shultz", "Thomas R.", ""]]}, {"id": "1810.06748", "submitter": "German I. Parisi", "authors": "Di Fu, Pablo Barros, German I. Parisi, Haiyan Wu, Sven Magg, Xun Liu,\n  Stefan Wermter", "title": "Assessing the Contribution of Semantic Congruency to Multisensory\n  Integration and Conflict Resolution", "comments": "Workshop on Crossmodal Learning for Intelligent Robotics at IROS'18,\n  Madrid, Spain", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The efficient integration of multisensory observations is a key property of\nthe brain that yields the robust interaction with the environment. However,\nartificial multisensory perception remains an open issue especially in\nsituations of sensory uncertainty and conflicts. In this work, we extend\nprevious studies on audio-visual (AV) conflict resolution in complex\nenvironments. In particular, we focus on quantitatively assessing the\ncontribution of semantic congruency during an AV spatial localization task. In\naddition to conflicts in the spatial domain (i.e. spatially misaligned\nstimuli), we consider gender-specific conflicts with male and female avatars.\nOur results suggest that while semantically related stimuli affect the\nmagnitude of the visual bias (perceptually shifting the location of the sound\ntowards a semantically congruent visual cue), humans still strongly rely on\nenvironmental statistics to solve AV conflicts. Together with previously\nreported results, this work contributes to a better understanding of how\nmultisensory integration and conflict resolution can be modelled in artificial\nagents and robots operating in real-world environments.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 23:22:10 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Fu", "Di", ""], ["Barros", "Pablo", ""], ["Parisi", "German I.", ""], ["Wu", "Haiyan", ""], ["Magg", "Sven", ""], ["Liu", "Xun", ""], ["Wermter", "Stefan", ""]]}, {"id": "1810.06966", "submitter": "Victor Minden", "authors": "Victor Minden, Cengiz Pehlevan, Dmitri B. Chklovskii", "title": "Biologically Plausible Online Principal Component Analysis Without\n  Recurrent Neural Dynamics", "comments": "8 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO math.DS q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial neural networks that learn to perform Principal Component Analysis\n(PCA) and related tasks using strictly local learning rules have been\npreviously derived based on the principle of similarity matching: similar pairs\nof inputs should map to similar pairs of outputs. However, the operation of\nthese networks (and of similar networks) requires a fixed-point iteration to\ndetermine the output corresponding to a given input, which means that dynamics\nmust operate on a faster time scale than the variation of the input. Further,\nduring these fast dynamics such networks typically \"disable\" learning, updating\nsynaptic weights only once the fixed-point iteration has been resolved. Here,\nwe derive a network for PCA-based dimensionality reduction that avoids this\nfast fixed-point iteration. The key novelty of our approach is a modification\nof the similarity matching objective to encourage near-diagonality of a\nsynaptic weight matrix. We then approximately invert this matrix using a Taylor\nseries approximation, replacing the previous fast iterations. In the offline\nsetting, our algorithm corresponds to a dynamical system, the stability of\nwhich we rigorously analyze. In the online setting (i.e., with stochastic\ngradients), we map our algorithm to a familiar neural network architecture and\ngive numerical results showing that our method converges at a competitive rate.\nThe computational complexity per iteration of our online algorithm is linear in\nthe total degrees of freedom, which is in some sense optimal.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 13:06:38 GMT"}, {"version": "v2", "created": "Sat, 3 Nov 2018 02:28:03 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Minden", "Victor", ""], ["Pehlevan", "Cengiz", ""], ["Chklovskii", "Dmitri B.", ""]]}, {"id": "1810.07215", "submitter": "Elizabeth Hobson", "authors": "Elizabeth A. Hobson, Dan M{\\o}nster, Simon DeDeo", "title": "Aggression heuristics underlie animal dominance hierarchies and provide\n  evidence of group-level social information", "comments": "Comments welcome", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE nlin.AO physics.soc-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Members of a social species need to make appropriate decisions about who,\nhow, and when to interact with others in their group. However, it has been\ndifficult for researchers to detect the inputs to these decisions and, in\nparticular, how much information individuals actually have about their social\ncontext. We present a new method that can serve as a social assay to quantify\nhow patterns of aggression depend upon information about the ranks of\nindividuals within social dominance hierarchies. Applied to existing data on\naggression in 172 social groups across 85 species in 23 orders, it reveals\nthree main patterns of rank-dependent social dominance: the downward heuristic\n(aggress uniformly against lower-ranked opponents), close competitors (aggress\nagainst opponents ranked slightly below self), and bullying (aggress against\nopponents ranked much lower than self). The majority of the groups (133 groups,\n77%) follow a downward heuristic, but a significant minority (38 groups, 22%)\nshow more complex social dominance patterns (close competitors or bullying)\nconsistent with higher levels of social information use. These patterns are not\nphylogenetically constrained and different groups within the same species can\nuse different patterns, suggesting that heuristics use may depend on context\nand the structuring of aggression by social information should not be\nconsidered a fixed characteristic of a species. Our approach provides new\nopportunities to study the use of social information within and across species\nand the evolution of social complexity and cognition.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 18:18:44 GMT"}, {"version": "v2", "created": "Fri, 22 Mar 2019 19:15:31 GMT"}, {"version": "v3", "created": "Thu, 12 Nov 2020 15:09:12 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Hobson", "Elizabeth A.", ""], ["M\u00f8nster", "Dan", ""], ["DeDeo", "Simon", ""]]}, {"id": "1810.07253", "submitter": "Cristian Zanoci", "authors": "Cristian Zanoci (MIT), Nima Dehghani (MIT), Max Tegmark (MIT)", "title": "Ensemble Inhibition and Excitation in the Human Cortex: an Ising Model\n  Analysis with Uncertainties", "comments": "17 pages, 8 figures", "journal-ref": "Phys. Rev. E 99, 032408 (2019)", "doi": "10.1103/PhysRevE.99.032408", "report-no": null, "categories": "cond-mat.dis-nn q-bio.NC q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The pairwise maximum entropy model, also known as the Ising model, has been\nwidely used to analyze the collective activity of neurons. However, controversy\npersists in the literature about seemingly inconsistent findings, whose\nsignificance is unclear due to lack of reliable error estimates. We therefore\ndevelop a method for accurately estimating parameter uncertainty based on\nrandom walks in parameter space using adaptive Markov Chain Monte Carlo after\nthe convergence of the main optimization algorithm. We apply our method to the\nspiking patterns of excitatory and inhibitory neurons recorded with\nmultielectrode arrays in the human temporal cortex during the wake-sleep cycle.\nOur analysis shows that the Ising model captures neuronal collective behavior\nmuch better than the independent model during wakefulness, light sleep, and\ndeep sleep when both excitatory (E) and inhibitory (I) neurons are modeled;\nignoring the inhibitory effects of I-neurons dramatically overestimates\nsynchrony among E-neurons. Furthermore, information-theoretic measures reveal\nthat the Ising model explains about 80%-95% of the correlations, depending on\nsleep state and neuron type. Thermodynamic measures show signatures of\ncriticality, although we take this with a grain of salt as it may be merely a\nreflection of long-range neural correlations.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 20:01:32 GMT"}], "update_date": "2019-03-13", "authors_parsed": [["Zanoci", "Cristian", "", "MIT"], ["Dehghani", "Nima", "", "MIT"], ["Tegmark", "Max", "", "MIT"]]}, {"id": "1810.07429", "submitter": "Jochen Kerdels", "authors": "Jochen Kerdels and Gabriele Peters", "title": "A Survey of Entorhinal Grid Cell Properties", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  About a decade ago grid cells were discovered in the medial entorhinal cortex\nof rat. Their peculiar firing patterns, which correlate with periodic locations\nin the environment, led to early hypothesis that grid cells may provide some\nform of metric for space. Subsequent research has since uncovered a wealth of\nnew insights into the characteristics of grid cells and their neural\nneighborhood, the parahippocampal-hippocampal region, calling for a revision\nand refinement of earlier grid cell models. This survey paper aims to provide a\ncomprehensive summary of grid cell research published in the past decade. It\nfocuses on the functional characteristics of grid cells such as the influence\nof external cues or the alignment to environmental geometry, but also provides\na basic overview of the underlying neural substrate.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 08:36:07 GMT"}], "update_date": "2018-10-18", "authors_parsed": [["Kerdels", "Jochen", ""], ["Peters", "Gabriele", ""]]}, {"id": "1810.07623", "submitter": "Xiaowen Chen", "authors": "Xiaowen Chen, Francesco Randi, Andrew M. Leifer, and William Bialek", "title": "Searching for collective behavior in a small brain", "comments": "14 pages, 12 figures", "journal-ref": "Phys. Rev. E 99, 052418 (2019)", "doi": "10.1103/PhysRevE.99.052418", "report-no": null, "categories": "physics.bio-ph cond-mat.dis-nn q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In large neuronal networks, it is believed that functions emerge through the\ncollective behavior of many interconnected neurons. Recently, the development\nof experimental techniques that allow simultaneous recording of calcium\nconcentration from a large fraction of all neurons in Caenorhabditis elegans -\na nematode with 302 neurons - creates the opportunity to ask if such emergence\nis universal, reaching down to even the smallest brains. Here, we measure the\nactivity of 50+ neurons in C. elegans, and analyze the data by building the\nmaximum entropy model that matches the mean activity and pairwise correlations\namong these neurons. To capture the graded nature of the cells' responses, we\nassign each cell multiple states. These models, which are equivalent to a\nfamily of Potts glasses, successfully predict higher statistical structure in\nthe network. In addition, these models exhibit signatures of collective\nbehavior: the state of single cells can be predicted from the state of the rest\nof the network; the network, despite being sparse in a way similar to the\nstructural connectome, distributes its response globally when locally\nperturbed; the distribution over network states has multiple local maxima, as\nin models for memory; and the parameters that describe the real network are\nclose to a critical surface in this family of models.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 15:38:01 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Chen", "Xiaowen", ""], ["Randi", "Francesco", ""], ["Leifer", "Andrew M.", ""], ["Bialek", "William", ""]]}, {"id": "1810.07809", "submitter": "Juntang Zhuang", "authors": "Juntang Zhuang, Nicha C. Dvornek, Qingyu Zhao, Xiaoxiao Li, Pamela\n  Ventola, James S. Duncan", "title": "Prediction of treatment outcome for autism from structure of the brain\n  based on sure independence screening", "comments": null, "journal-ref": "2019 IEEE 16th International Symposium on Biomedical Imaging (ISBI\n  2019) 2019 Apr 8 (pp. 404-408). IEEE", "doi": null, "report-no": null, "categories": "q-bio.NC stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autism spectrum disorder (ASD) is a complex neurodevelopmental disorder, and\nbehavioral treatment interventions have shown promise for young children with\nASD. However, there is limited progress in understanding the effect of each\ntype of treatment. In this project, we aim to detect structural changes in the\nbrain after treatment and select structural features associated with treatment\noutcomes. The difficulty in building large databases of patients who have\nreceived specific treatments and the high dimensionality of medical image\nanalysis problems are the challenges in this work. To select predictive\nfeatures and build accurate models, we use the sure independence screening\n(SIS) method. SIS is a theoretically and empirically validated method for\nultra-high dimensional general linear models, and it achieves both predictive\naccuracy and correct feature selection by iterative feature selection. Compared\nwith step-wise feature selection methods, SIS removes multiple features in each\niteration and is computationally efficient. Compared with other linear models\nsuch as elastic-net regression, support vector regression (SVR) and partial\nleast squares regression (PSLR), SIS achieves higher accuracy. We validated the\nsuperior performance of SIS in various experiments: First, we extract brain\nstructural features from FreeSurfer, including cortical thickness, surface\narea, mean curvature and cortical volume. Next, we predict different measures\nof treatment outcomes based on structural features. We show that SIS achieves\nthe highest correlation between prediction and measurements in all tasks.\nFurthermore, we report regions selected by SIS as biomarkers for ASD.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 21:19:46 GMT"}, {"version": "v2", "created": "Tue, 26 Feb 2019 04:24:53 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Zhuang", "Juntang", ""], ["Dvornek", "Nicha C.", ""], ["Zhao", "Qingyu", ""], ["Li", "Xiaoxiao", ""], ["Ventola", "Pamela", ""], ["Duncan", "James S.", ""]]}, {"id": "1810.08056", "submitter": "Alexandra Pinto", "authors": "Alexandra Pinto Castellanos", "title": "Wave to pulse generation. From oscillatory synapse to train of action\n  potentials", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.bio-ph nlin.AO q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Neurons have the capability of transforming information from a digital signal\nat the dendrites of the presynaptic termi- nal to an analogous wave at the\nsynaptic cleft and back to a digital pulse when they achieve the required\nvoltage for the generation of an action potential at the postsynaptic neuron.\nThe main question of this research is what processes are generating the\noscillatory wave signal at the synaptic cleft and what is the best model for\nthis phenomenon. Here, it is proposed a model of the synapse as an oscillatory\nsystem capable of synchronization taking into account conservation of\ninformation and consequently of frequency at the interior of the synaptic\ncleft. Trains of action potentials certainly encode and transmit information\nalong the nervous system but most of the time neurons are not transmitting\naction potentials, 99 percent of their time neurons are in the sub threshold\nregime were only small signals without the energy to emanate an action\npotential are carrying the majority of information. The proposed model for a\nsynapse, smooths the train of action potential and keeps its frequency.\nSynapses are presented here as a system composed of an input wave that is\ntransformed through interferometry. The collective synaptic interference\npattern of waves will reflect the points of maximum amplitude for the density\nwave synaptic function were the location of the \"particle\" in our case action\npotential, has its highest probability.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 13:51:38 GMT"}], "update_date": "2018-10-19", "authors_parsed": [["Castellanos", "Alexandra Pinto", ""]]}, {"id": "1810.08488", "submitter": "Afshin Montakhab", "authors": "Mahsa Khoshkhou and Afshin Montakhab", "title": "Beta-rhythm oscillations and synchronization transition in network\n  models of Izhikevich neurons: effect of topology and synaptic type", "comments": "7 figures, 1 table", "journal-ref": "Frontiers in Computational Neuroscience, 12:59 (2018)", "doi": "10.3389/fncom.2018.00059", "report-no": null, "categories": "nlin.AO cond-mat.dis-nn q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite their significant functional roles, beta-band oscillations are least\nunderstood. Synchronization in neuronal networks have attracted much attention\nin recent years with the main focus on transition type. Whether one obtains\nexplosive transition or a continuous transition is an important feature of the\nneuronal network which can depend on network structure as well as synaptic\ntypes. In this study we consider the effect of synaptic interaction (electrical\nand chemical) as well as structural connectivity on synchronization transition\nin network models of Izhikevich neurons which spike regularly with beta\nrhythms. We find a wide range of behavior including continuous transition,\nexplosive transition, as well as lack of global order. The stronger electrical\nsynapses are more conducive to synchronization and can even lead to explosive\nsynchronization. The key network element which determines the order of\ntransition is found to be the clustering coefficient and not the small world\neffect, or the existence of hubs in a network. These results are in contrast to\nprevious results which use phase oscillator models such as the Kuramoto model.\nFurthermore, we show that the patterns of synchronization changes when one goes\nto the gamma band. We attribute such a change to the change in the refractory\nperiod of Izhikevich neurons which changes significantly with frequency.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 13:25:29 GMT"}], "update_date": "2018-10-22", "authors_parsed": [["Khoshkhou", "Mahsa", ""], ["Montakhab", "Afshin", ""]]}, {"id": "1810.08553", "submitter": "Santiago Silva", "authors": "Santiago Silva, Boris Gutman, Eduardo Romero, Paul M Thompson, Andre\n  Altmann, Marco Lorenzi", "title": "Federated Learning in Distributed Medical Databases: Meta-Analysis of\n  Large-Scale Subcortical Brain Data", "comments": "Federated learning, distributed databases, PCA, SVD, meta-analysis,\n  brain disease", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.NC q-bio.QM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  At this moment, databanks worldwide contain brain images of previously\nunimaginable numbers. Combined with developments in data science, these massive\ndata provide the potential to better understand the genetic underpinnings of\nbrain diseases. However, different datasets, which are stored at different\ninstitutions, cannot always be shared directly due to privacy and legal\nconcerns, thus limiting the full exploitation of big data in the study of brain\ndisorders. Here we propose a federated learning framework for securely\naccessing and meta-analyzing any biomedical data without sharing individual\ninformation. We illustrate our framework by investigating brain structural\nrelationships across diseases and clinical cohorts. The framework is first\ntested on synthetic data and then applied to multi-centric, multi-database\nstudies including ADNI, PPMI, MIRIAD and UK Biobank, showing the potential of\nthe approach for further applications in distributed analysis of multi-centric\ncohorts\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 15:36:35 GMT"}, {"version": "v2", "created": "Mon, 22 Oct 2018 08:40:43 GMT"}, {"version": "v3", "created": "Thu, 14 Mar 2019 16:13:30 GMT"}], "update_date": "2019-03-15", "authors_parsed": [["Silva", "Santiago", ""], ["Gutman", "Boris", ""], ["Romero", "Eduardo", ""], ["Thompson", "Paul M", ""], ["Altmann", "Andre", ""], ["Lorenzi", "Marco", ""]]}, {"id": "1810.08725", "submitter": "Sergei Gepshtein", "authors": "Sergei Gepshtein, Ambarish S. Pawar, Sergey Saveliev, Thomas D.\n  Albright", "title": "Neural wave interference and intrinsic tuning in distributed\n  excitatory-inhibitory networks", "comments": "15 pages, 5 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We developed a model of cortical computation that implements key features of\ncortical circuitry and is capable of describing propagation of neural signals\nbetween cortical locations in response to spatially distributed stimuli. The\nmodel is based on the canonical neural circuit that consists of excitatory and\ninhibitory cells interacting through reciprocal connections, with recurrent\nfeedback. The canonical circuit is used as a node in a distributed network with\nnearest neighbor coupling between the nodes. We find that this system is\ncharacterized by intrinsic preference for spatial frequency. The value of\npreferred frequency depends on the relative weights of excitatory and\ninhibitory connections between cells. This balance of excitation and inhibition\nchanges as stimulus contrast increases, which is why intrinsic spatial\nfrequency is predicted to change with contrast in a manner determined by\nstimulus temporal frequency. The dynamics of network preference is consistent\nwith properties of the cortical area MT in alert macaque monkeys.\n", "versions": [{"version": "v1", "created": "Sat, 20 Oct 2018 01:20:12 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Gepshtein", "Sergei", ""], ["Pawar", "Ambarish S.", ""], ["Saveliev", "Sergey", ""], ["Albright", "Thomas D.", ""]]}, {"id": "1810.08840", "submitter": "Maxwell Bertolero Dr", "authors": "Maxwell A Bertolero, Azeez Adebimpe, Ankit N. Khambhati, Marcelo G.\n  Mattar, Daniel Romer, Sharon L. Thompson-Schill, Danielle S. Bassett", "title": "Learning differentially reorganizes brain activity and connectivity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human learning is a complex process in which future behavior is altered via\nthe reorganization of brain activity and connectivity. It remains unknown\nwhether activity and connectivity differentially reorganize during learning,\nand, if so, how that differential reorganization tracks stages of learning\nacross distinct brain areas. Here, we address this gap in knowledge by\nmeasuring brain activity and functional connectivity in a longitudinal fMRI\nexperiment in which healthy adult human participants learn the values of novel\nobjects over the course of four days. An increasing similarity in activity or\nfunctional connectivity across subjects during learning reflects reorganization\ntoward a common functional architecture. We assessed the presence of\nreorganization in activity and connectivity both during value learning and\nduring the resting-state, allowing us to differentiate common elicited\nprocesses from intrinsic processes. We found a complex and dynamic\nreorganization of brain connectivity and activity--as a function of time,\nspace, and performance--that occurs while subjects learn. Spatially localized\nbrain activity reorganizes across the brain to a common functional architecture\nearly in learning, and this reorganization tracks early learning performance.\nIn contrast, spatially distributed connectivity reorganizes across the brain to\na common functional architecture as training progresses, and this\nreorganization tracks later learning performance. Particularly good performance\nis associated with a sticky connectivity, that persists into the resting state.\nBroadly, our work uncovers distinct principles of reorganization in activity\nand connectivity at different phases of value learning, which inform the\nongoing study of learning processes more generally.\n", "versions": [{"version": "v1", "created": "Sat, 20 Oct 2018 18:40:07 GMT"}, {"version": "v2", "created": "Sun, 23 Feb 2020 15:55:25 GMT"}, {"version": "v3", "created": "Thu, 10 Sep 2020 11:04:02 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Bertolero", "Maxwell A", ""], ["Adebimpe", "Azeez", ""], ["Khambhati", "Ankit N.", ""], ["Mattar", "Marcelo G.", ""], ["Romer", "Daniel", ""], ["Thompson-Schill", "Sharon L.", ""], ["Bassett", "Danielle S.", ""]]}, {"id": "1810.09391", "submitter": "Constantine Dovrolis", "authors": "Constantine Dovrolis", "title": "A neuro-inspired architecture for unsupervised continual learning based\n  on online clustering and hierarchical predictive coding", "comments": "Under peer-review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI q-bio.NC stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We propose that the Continual Learning desiderata can be achieved through a\nneuro-inspired architecture, grounded on Mountcastle's cortical column\nhypothesis. The proposed architecture involves a single module, called\nSelf-Taught Associative Memory (STAM), which models the function of a cortical\ncolumn. STAMs are repeated in multi-level hierarchies involving feedforward,\nlateral and feedback connections. STAM networks learn in an unsupervised\nmanner, based on a combination of online clustering and hierarchical predictive\ncoding. This short paper only presents the architecture and its connections\nwith neuroscience. A mathematical formulation and experimental results will be\npresented in an extended version of this paper.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 16:27:21 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Dovrolis", "Constantine", ""]]}, {"id": "1810.09520", "submitter": "Matthieu Gilson", "authors": "Matthieu Gilson and Jean-Pascal Pfister", "title": "Propagation of spiking moments in linear Hawkes networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The present paper provides exact mathematical expressions for the high-order\nmoments of spiking activity in a recurrently-connected network of linear Hawkes\nprocesses. It extends previous studies that have explored the case of a\n(linear) Hawkes network driven by deterministic intensity functions to the case\nof a stimulation by external inputs (rate functions or spike trains) with\narbitrary correlation structure. Our approach describes the spatio-temporal\nfiltering induced by the afferent and recurrent connectivities (with arbitrary\nsynaptic response kernels) using operators acting on the input moments. This\nalgebraic viewpoint provides intuition about how the network ingredients shape\nthe input-output mapping for moments, as well as cumulants. We also show using\nnumerical simulation that our results hold for neurons with refractoriness\nimplemented by self-inhibition, provided the corresponding negative feedback\nfor each neuron only mildly alters its mean firing probability.\n", "versions": [{"version": "v1", "created": "Tue, 18 Sep 2018 17:03:49 GMT"}, {"version": "v2", "created": "Thu, 12 Sep 2019 14:57:48 GMT"}, {"version": "v3", "created": "Mon, 16 Dec 2019 16:12:09 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Gilson", "Matthieu", ""], ["Pfister", "Jean-Pascal", ""]]}, {"id": "1810.09879", "submitter": "Sebastian Kahl", "authors": "Sebastian Kahl, Stefan Kopp", "title": "A predictive processing model of perception and action for self-other\n  distinction", "comments": "Main text including supplementary materials. This manuscript ist\n  currently under review at Frontiers in Psychology Cognitive Science", "journal-ref": null, "doi": "10.3389/fpsyg.2018.02421", "report-no": null, "categories": "q-bio.NC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During interaction with others, we perceive and produce social actions in\nclose temporal distance or even simultaneously. It has been argued that the\nmotor system is involved in perception and action, playing a fundamental role\nin the handling of actions produced by oneself and by others. But how does it\ndistinguish in this processing between self and other, thus contributing to\nself-other distinction? In this paper we propose a hierarchical model of\nsensorimotor coordination based on principles of perception-action coupling and\npredictive processing in which self-other distinction arises during action and\nperception. For this we draw on mechanisms assumed for the integration of cues\nfor a sense of agency, i.e., the sense that an action is self-generated. We\nreport results from simulations of different scenarios, showing that the model\nis not only able to minimize free energy during perception and action, but also\nshowing that the model can correctly attribute sense of agency to own actions.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 14:27:30 GMT"}, {"version": "v2", "created": "Wed, 24 Oct 2018 11:44:00 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Kahl", "Sebastian", ""], ["Kopp", "Stefan", ""]]}, {"id": "1810.09920", "submitter": "Alexander Lin", "authors": "Alexander Lin, Yingzhuo Zhang, Jeremy Heng, Stephen A. Allsop, Kay M.\n  Tye, Pierre E. Jacob, and Demba Ba", "title": "Clustering Time Series with Nonlinear Dynamics: A Bayesian\n  Non-Parametric and Particle-Based Approach", "comments": null, "journal-ref": "International Conference on Artificial Intelligence and Statistics\n  (AISTATS 2019)", "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.NC stat.CO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a general statistical framework for clustering multiple time\nseries that exhibit nonlinear dynamics into an a-priori-unknown number of\nsub-groups. Our motivation comes from neuroscience, where an important problem\nis to identify, within a large assembly of neurons, subsets that respond\nsimilarly to a stimulus or contingency. Upon modeling the multiple time series\nas the output of a Dirichlet process mixture of nonlinear state-space models,\nwe derive a Metropolis-within-Gibbs algorithm for full Bayesian inference that\nalternates between sampling cluster assignments and sampling parameter values\nthat form the basis of the clustering. The Metropolis step employs recent\ninnovations in particle-based methods. We apply the framework to clustering\ntime series acquired from the prefrontal cortex of mice in an experiment\ndesigned to characterize the neural underpinnings of fear.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 15:40:25 GMT"}, {"version": "v2", "created": "Wed, 24 Oct 2018 18:44:19 GMT"}, {"version": "v3", "created": "Tue, 26 Feb 2019 21:28:11 GMT"}, {"version": "v4", "created": "Mon, 4 Mar 2019 18:40:29 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Lin", "Alexander", ""], ["Zhang", "Yingzhuo", ""], ["Heng", "Jeremy", ""], ["Allsop", "Stephen A.", ""], ["Tye", "Kay M.", ""], ["Jacob", "Pierre E.", ""], ["Ba", "Demba", ""]]}, {"id": "1810.09935", "submitter": "Markus D Schirmer", "authors": "Markus D. Schirmer and Ai Wern Chung and P. Ellen Grant and Natalia S.\n  Rost", "title": "Network Structural Dependency in the Human Connectome Across the\n  Life-Span", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Principles of network topology have been widely studied in the human\nconnectome. Of particular interest is the modularity of the human brain, where\nthe connectome is divided into subnetworks and subsequently changes with\ndevelopment, aging or disease are investigated. We present a weighted network\nmeasure, the Network Dependency Index (NDI), to identify an individual region's\nimportance to the global functioning of the network. Importantly, we utilize\nNDI to differentiate four subnetworks (Tiers) in the human connectome following\nGaussian Mixture Model fitting. We analyze the topological aspects of each\nsubnetwork with respect to age and compare it to rich-club based subnetworks\n(rich-club, feeder and seeder). Our results first demonstrate the efficacy of\nNDI to identify more consistent, central nodes of the connectome across\nage-groups, when compared to the rich-club framework. Stratifying the\nconnectome by NDI led to consistent subnetworks across the life-span revealing\ndistinct patterns associated with age where, e.g., the key relay nuclei and\ncortical regions are contained in a subnetwork with highest NDI. The divisions\nof the human connectome derived from our data-driven NDI framework have the\npotential to reveal topological alterations described by network measures\nthrough the life-span.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 16:01:23 GMT"}, {"version": "v2", "created": "Fri, 26 Oct 2018 17:44:37 GMT"}, {"version": "v3", "created": "Sat, 19 Jan 2019 01:40:14 GMT"}, {"version": "v4", "created": "Sat, 2 Feb 2019 20:38:24 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Schirmer", "Markus D.", ""], ["Chung", "Ai Wern", ""], ["Grant", "P. Ellen", ""], ["Rost", "Natalia S.", ""]]}, {"id": "1810.09945", "submitter": "Wojciech Samek", "authors": "Armin W. Thomas, Hauke R. Heekeren, Klaus-Robert M\\\"uller, Wojciech\n  Samek", "title": "Analyzing Neuroimaging Data Through Recurrent Deep Learning Models", "comments": "36 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The application of deep learning (DL) models to neuroimaging data poses\nseveral challenges, due to the high dimensionality, low sample size and complex\ntemporo-spatial dependency structure of these datasets. Even further, DL models\nact as as black-box models, impeding insight into the association of cognitive\nstate and brain activity. To approach these challenges, we introduce the\nDeepLight framework, which utilizes long short-term memory (LSTM) based DL\nmodels to analyze whole-brain functional Magnetic Resonance Imaging (fMRI)\ndata. To decode a cognitive state (e.g., seeing the image of a house),\nDeepLight separates the fMRI volume into a sequence of axial brain slices,\nwhich is then sequentially processed by an LSTM. To maintain interpretability,\nDeepLight adapts the layer-wise relevance propagation (LRP) technique. Thereby,\ndecomposing its decoding decision into the contributions of the single input\nvoxels to this decision. Importantly, the decomposition is performed on the\nlevel of single fMRI volumes, enabling DeepLight to study the associations\nbetween cognitive state and brain activity on several levels of data\ngranularity, from the level of the group down to the level of single time\npoints. To demonstrate the versatility of DeepLight, we apply it to a large\nfMRI dataset of the Human Connectome Project. We show that DeepLight\noutperforms conventional approaches of uni- and multivariate fMRI analysis in\ndecoding the cognitive states and in identifying the physiologically\nappropriate brain regions associated with these states. We further demonstrate\nDeepLight's ability to study the fine-grained temporo-spatial variability of\nbrain activity over sequences of single fMRI samples.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 16:23:27 GMT"}, {"version": "v2", "created": "Fri, 5 Apr 2019 07:31:32 GMT"}], "update_date": "2019-04-08", "authors_parsed": [["Thomas", "Armin W.", ""], ["Heekeren", "Hauke R.", ""], ["M\u00fcller", "Klaus-Robert", ""], ["Samek", "Wojciech", ""]]}, {"id": "1810.10065", "submitter": "Jonathan Kadmon", "authors": "Jonathan Kadmon and Surya Ganguli", "title": "Statistical mechanics of low-rank tensor decomposition", "comments": "27 pages, 3 figures", "journal-ref": null, "doi": "10.1088/1742-5468/ab3216", "report-no": null, "categories": "stat.ML cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Often, large, high dimensional datasets collected across multiple modalities\ncan be organized as a higher order tensor. Low-rank tensor decomposition then\narises as a powerful and widely used tool to discover simple low dimensional\nstructures underlying such data. However, we currently lack a theoretical\nunderstanding of the algorithmic behavior of low-rank tensor decompositions. We\nderive Bayesian approximate message passing (AMP) algorithms for recovering\narbitrarily shaped low-rank tensors buried within noise, and we employ dynamic\nmean field theory to precisely characterize their performance. Our theory\nreveals the existence of phase transitions between easy, hard and impossible\ninference regimes, and displays an excellent match with simulations. Moreover,\nit reveals several qualitative surprises compared to the behavior of symmetric,\ncubic tensor decomposition. Finally, we compare our AMP algorithm to the most\ncommonly used algorithm, alternating least squares (ALS), and demonstrate that\nAMP significantly outperforms ALS in the presence of noise.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 19:36:28 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Kadmon", "Jonathan", ""], ["Ganguli", "Surya", ""]]}, {"id": "1810.10142", "submitter": "Paulo Protachevicz", "authors": "P. R. Protachevicz, F. S. Borges, E. L. Lameu, P. Ji, K. C. Iarosz, A.\n  H. Kihara, I. L. Caldas, J. D. Szezech Jr., M. S. Baptista, E. E. N. Macau,\n  C. G. Antonopoulos, A. M. Batista, J. Kurths", "title": "Bistable firing pattern in a neural network model", "comments": null, "journal-ref": "Frontiers in Computational Neuroscience - 2019", "doi": null, "report-no": null, "categories": "physics.bio-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Excessively high, neural synchronisation has been associated with epileptic\nseizures, one of the most common brain diseases worldwide. A better\nunderstanding of neural synchronisation mechanisms can thus help control or\neven treat epilepsy. In this paper, we study neural synchronisation in a random\nnetwork where nodes are neurons with excitatory and inhibitory synapses, and\nneural activity for each node is provided by the adaptive exponential\nintegrate-and-fire model. In this framework, we verify that the decrease in the\ninfluence of inhibition can generate synchronisation originating from a pattern\nof desynchronised spikes. The transition from desynchronous spikes to\nsynchronous bursts of activity, induced by varying the synaptic coupling,\nemerges in a hysteresis loop due to bistability where abnormal (excessively\nhigh synchronous) regimes exist. We verify that, for parameters in the\nbistability regime, a square current pulse can trigger excessively high\n(abnormal) synchronisation, a process that can reproduce features of epileptic\nseizures. Then, we show that it is possible to suppress such abnormal\nsynchronisation by applying a small-amplitude external current on less than 10%\nof the neurons in the network. Our results demonstrate that external electrical\nstimulation not only can trigger synchronous behaviour, but more importantly,\nit can be used as a means to reduce abnormal synchronisation and thus, control\nor treat effectively epileptic seizures.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 00:49:49 GMT"}, {"version": "v2", "created": "Thu, 25 Oct 2018 14:36:50 GMT"}, {"version": "v3", "created": "Mon, 29 Oct 2018 15:05:10 GMT"}, {"version": "v4", "created": "Mon, 18 Mar 2019 17:25:57 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Protachevicz", "P. R.", ""], ["Borges", "F. S.", ""], ["Lameu", "E. L.", ""], ["Ji", "P.", ""], ["Iarosz", "K. C.", ""], ["Kihara", "A. H.", ""], ["Caldas", "I. L.", ""], ["Szezech", "J. D.", "Jr."], ["Baptista", "M. S.", ""], ["Macau", "E. E. N.", ""], ["Antonopoulos", "C. G.", ""], ["Batista", "A. M.", ""], ["Kurths", "J.", ""]]}, {"id": "1810.10339", "submitter": "Hamid Behjat", "authors": "Sevil Maghsadhagh, Mousa Shamsi, Anders Eklund, Hamid Behjat", "title": "Characterization of Brain Cortical Morphology Using Localized\n  Topology-Encoding Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The human brain cortical layer has a convoluted morphology that is unique to\neach individual. Characterization of the cortical morphology is necessary in\nlongitudinal studies of structural brain change, as well as in discriminating\nindividuals in health and disease. A method for encoding the cortical\nmorphology in the form of a graph is presented. The design of graphs that\nencode the global cerebral hemisphere cortices as well as localized cortical\nregions is proposed. Spectral features of these graphs are then studied and\nproposed as descriptors of cortical morphology. As proof-of-concept of their\napplicability in characterizing cortical morphology, the descriptors are\nstudied in the context of discriminating individuals based on their sex.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 11:45:09 GMT"}], "update_date": "2018-10-25", "authors_parsed": [["Maghsadhagh", "Sevil", ""], ["Shamsi", "Mousa", ""], ["Eklund", "Anders", ""], ["Behjat", "Hamid", ""]]}, {"id": "1810.10440", "submitter": "Mattia Bramini", "authors": "Martina Chiacchiaretta, Mattia Bramini, Anna Rocchi, Andrea Armirotti,\n  Emanuele Giordano, Ester V\\'azquez, Tiziano Bandiera, Stefano Ferroni,\n  Fabrizia Cesca and Fabio Benfenati", "title": "Graphene oxide upregulates the homeostatic functions of primary\n  astrocytes and modulates astrocyte-to-neuron communication", "comments": "This document is the unedited Author's version of a Submitted Work\n  that was subsequently accepted for publication in Nano Letters. To access the\n  final edited and published work see\n  https://pubs.acs.org/articlesonrequest/AOR-wvjrggcBp7kC8NwEImXr", "journal-ref": "Nano Lett. 2018, 18, 9, 5827-5838", "doi": "10.1021/acs.nanolett.8b02487", "report-no": null, "categories": "q-bio.NC q-bio.CB", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Graphene-based materials are the focus of intense research efforts to devise\nnovel theranostic strategies for targeting the central nervous system. In this\nwork, we have investigated the consequences of long-term exposure of primary\nrat astrocytes to pristine graphene (GR) and graphene oxide (GO) flakes. We\ndemonstrate that GR/GO interfere with a variety of intracellular processes as a\nresult of their internalization through the endo-lysosomal pathway.\nGraphene-exposed astrocytes acquire a more differentiated morphological\nphenotype associated with extensive cytoskeletal rearrangements. Profound\nfunctional alterations are induced by GO internalization, including the\nupregulation of inward-rectifying K+ channels and of Na+-dependent glutamate\nuptake, which are linked to the astrocyte capacity to control the extracellular\nhomeostasis. Interestingly, GO-pretreated astrocytes promote the functional\nmaturation of co-cultured primary neurons by inducing an increase in intrinsic\nexcitability and in the density of GABAergic synapses. The results indicate\nthat graphene nanomaterials profoundly affect astrocyte physiology in vitro,\nwith consequences for neuronal network activity. This work supports the view\nthat GO-based materials could be of great interest to address pathologies of\nthe central nervous system associated to astrocyte dysfunctions.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 15:09:15 GMT"}], "update_date": "2018-10-25", "authors_parsed": [["Chiacchiaretta", "Martina", ""], ["Bramini", "Mattia", ""], ["Rocchi", "Anna", ""], ["Armirotti", "Andrea", ""], ["Giordano", "Emanuele", ""], ["V\u00e1zquez", "Ester", ""], ["Bandiera", "Tiziano", ""], ["Ferroni", "Stefano", ""], ["Cesca", "Fabrizia", ""], ["Benfenati", "Fabio", ""]]}, {"id": "1810.10498", "submitter": "Elena Pastorelli", "authors": "Cristiano Capone and Elena Pastorelli and Bruno Golosio and Pier\n  Stanislao Paolucci", "title": "Sleep-like slow oscillations improve visual classification through\n  synaptic homeostasis and memory association in a thalamo-cortical model", "comments": "11 pages, 5 figures, v5 is the final version published on Scientific\n  Reports journal", "journal-ref": "Sci Rep 9, 8990 (2019)", "doi": "10.1038/s41598-019-45525-0", "report-no": null, "categories": "q-bio.NC cs.AI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The occurrence of sleep passed through the evolutionary sieve and is\nwidespread in animal species. Sleep is known to be beneficial to cognitive and\nmnemonic tasks, while chronic sleep deprivation is detrimental. Despite the\nimportance of the phenomenon, a complete understanding of its functions and\nunderlying mechanisms is still lacking. In this paper, we show interesting\neffects of deep-sleep-like slow oscillation activity on a simplified\nthalamo-cortical model which is trained to encode, retrieve and classify images\nof handwritten digits. During slow oscillations,\nspike-timing-dependent-plasticity (STDP) produces a differential homeostatic\nprocess. It is characterized by both a specific unsupervised enhancement of\nconnections among groups of neurons associated to instances of the same class\n(digit) and a simultaneous down-regulation of stronger synapses created by the\ntraining. This hierarchical organization of post-sleep internal representations\nfavours higher performances in retrieval and classification tasks. The\nmechanism is based on the interaction between top-down cortico-thalamic\npredictions and bottom-up thalamo-cortical projections during deep-sleep-like\nslow oscillations. Indeed, when learned patterns are replayed during sleep,\ncortico-thalamo-cortical connections favour the activation of other neurons\ncoding for similar thalamic inputs, promoting their association. Such mechanism\nhints at possible applications to artificial learning systems.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 17:06:00 GMT"}, {"version": "v2", "created": "Wed, 14 Nov 2018 15:38:12 GMT"}, {"version": "v3", "created": "Mon, 3 Dec 2018 15:24:40 GMT"}, {"version": "v4", "created": "Mon, 21 Jan 2019 15:51:14 GMT"}, {"version": "v5", "created": "Mon, 18 Nov 2019 13:01:01 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Capone", "Cristiano", ""], ["Pastorelli", "Elena", ""], ["Golosio", "Bruno", ""], ["Paolucci", "Pier Stanislao", ""]]}, {"id": "1810.10531", "submitter": "Andrew Saxe", "authors": "Andrew M. Saxe, James L. McClelland, and Surya Ganguli", "title": "A mathematical theory of semantic development in deep neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An extensive body of empirical research has revealed remarkable regularities\nin the acquisition, organization, deployment, and neural representation of\nhuman semantic knowledge, thereby raising a fundamental conceptual question:\nwhat are the theoretical principles governing the ability of neural networks to\nacquire, organize, and deploy abstract knowledge by integrating across many\nindividual experiences? We address this question by mathematically analyzing\nthe nonlinear dynamics of learning in deep linear networks. We find exact\nsolutions to this learning dynamics that yield a conceptual explanation for the\nprevalence of many disparate phenomena in semantic cognition, including the\nhierarchical differentiation of concepts through rapid developmental\ntransitions, the ubiquity of semantic illusions between such transitions, the\nemergence of item typicality and category coherence as factors controlling the\nspeed of semantic processing, changing patterns of inductive projection over\ndevelopment, and the conservation of semantic similarity in neural\nrepresentations across species. Thus, surprisingly, our simple neural model\nqualitatively recapitulates many diverse regularities underlying semantic\ndevelopment, while providing analytic insight into how the statistical\nstructure of an environment can interact with nonlinear deep learning dynamics\nto give rise to these regularities.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 22:20:27 GMT"}], "update_date": "2018-10-26", "authors_parsed": [["Saxe", "Andrew M.", ""], ["McClelland", "James L.", ""], ["Ganguli", "Surya", ""]]}, {"id": "1810.10893", "submitter": "Juergen Reingruber", "authors": "Johannes Reisert, J\\\"urgen Reingruber", "title": "The $Ca^{2+}$-activated $Cl^-$ current ensures robust and reliable\n  signal amplification in vertebrate olfactory receptor neurons", "comments": "31 pages, 10 figures (including SI)", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC q-bio.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Activation of most primary sensory neurons results in transduction currents\nthat are carried by cations. One notable exception is the vertebrate olfactory\nreceptor neuron (ORN), where the transduction current is carried largely by the\nanion $Cl^-$. However, it remains unclear why ORNs use an anionic current for\nsignal amplification. We have sought to provide clarification on this topic by\nstudying the so far neglected dynamics of $Na^+$, $Ca^{2+}$, $K^+$ and $Cl^-$\nin the small space of olfactory cilia during an odorant response. Using\ncomputational modeling and simulations we compared the outcomes of signal\namplification based on either $Cl^-$ or $Na^+$ currents. We found that\namplification produced by $Na^+$ influx instead of a $Cl^-$ efflux is\nproblematic due to several reasons: First, the $Na^+$ current amplitude varies\ngreatly depending on mucosal ion concentration changes. Second, a $Na^+$\ncurrent leads to a large increase in the ciliary $Na^+$ concentration during an\nodorant response. This increase inhibits and even reverses $Ca^{2+}$ clearance\nby $Na^+/Ca^{2+}/K^+$ exchange, which is essential for response termination.\nFinally, a $Na^+$ current increases the ciliary osmotic pressure, which could\ncause swelling to damage the cilia. By contrast, a transduction pathway based\non $Cl^-$ efflux circumvents these problems and renders the odorant response\nrobust and reliable.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 14:26:17 GMT"}], "update_date": "2018-10-26", "authors_parsed": [["Reisert", "Johannes", ""], ["Reingruber", "J\u00fcrgen", ""]]}, {"id": "1810.10894", "submitter": "Panteleimon Vafeidis", "authors": "Panteleimon Vafeidis, Vasilios K. Kimiskidis, Dimitris Kugiumtzis", "title": "Evaluation of algorithms for correction of transcranial magnetic\n  stimulation induced artifacts in electroencephalograms", "comments": "18 pages, 7 figures, 2 tables. Med Biol Eng Comput (2019)", "journal-ref": null, "doi": "10.1007/s11517-019-02053-3", "report-no": null, "categories": "q-bio.QM q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transcranial magnetic stimulation combined with electroencephalography\n(TMS-EEG) is widely used to study the reactivity and connectivity of brain\nregions for clinical or research purposes. The electromagnetic pulse of the TMS\ndevice generates at the instant of administration an artifact of large\namplitude and a duration up to tens of milliseconds that overlaps with brain\nactivity. Methods for TMS artifact correction have been developed to remove the\nartifact and recover the underlying, immediate response of the cerebral cortex\nto the magnetic stimulus. In this study, three such algorithms are evaluated.\nSince there is no ground truth for the masked brain activity, pilot data formed\nfrom the superposition of the isolated TMS artifact on the EEG brain activity\nare used to evaluate the performance of the algorithms. Different scenarios of\nTMS-EEG experiments are considered for the evaluation: TMS at resting state,\nTMS inducing epileptiform discharges and TMS administered during epileptiform\ndischarges. We show that a proposed gap filling method is able to reproduce\nqualitative characteristics and in many cases closely resemble the hidden EEG\nsignal. Finally, shortcomings of the TMS correction algorithms as well as the\npilot data approach are discussed.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 14:27:26 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Vafeidis", "Panteleimon", ""], ["Kimiskidis", "Vasilios K.", ""], ["Kugiumtzis", "Dimitris", ""]]}, {"id": "1810.10941", "submitter": "Juan Manuel Fernandez Montenegro JMFMontenegro", "authors": "Juan Manuel Fern\\'andez Montenegro", "title": "Alzheimer's Disease Diagnosis Based on Cognitive Methods in Virtual\n  Environments and Emotions Analysis", "comments": "PhD Thesis 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Dementia is a syndrome characterised by the decline of different cognitive\nabilities. Alzheimer's Disease (AD) is the most common dementia affecting\ncognitive domains such as memory and learning, perceptual-motion or executive\nfunction. High rate of deaths and high cost for detection, treatments and\npatient's care count amongst its consequences. Early detection of AD is\nconsidered of high importance for improving the quality of life of patients and\ntheir families. The aim of this thesis is to introduce novel non-invasive early\ndiagnosis methods in order to speed the diagnosis, reduce the associated costs\nand make them widely accessible. Novel AD's screening tests based on virtual\nenvironments using new immersive technologies combined with advanced Human\nComputer Interaction (HCI) systems are introduced. Four tests demonstrate the\nwide range of screening mechanisms based on cognitive domain impairments that\ncan be designed using virtual environments. The use of emotion recognition to\nanalyse AD symptoms has been also proposed. A novel multimodal dataset was\nspecifically created to remark the autobiographical memory deficits of AD\npatients. Data from this dataset is used to introduce novel descriptors for\nElectroencephalogram (EEG) and facial images data. EEG features are based on\nquaternions in order to keep the correlation information between sensors,\nwhereas, for facial expression recognition, a preprocessing method for motion\nmagnification and descriptors based on origami crease pattern algorithm are\nproposed to enhance facial micro-expressions. These features have been proved\non classifiers such as SVM and Adaboost for the classification of reactions to\nautobiographical stimuli such as long and short term memories.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 15:56:51 GMT"}], "update_date": "2018-10-26", "authors_parsed": [["Montenegro", "Juan Manuel Fern\u00e1ndez", ""]]}, {"id": "1810.10974", "submitter": "Isaak Kavasidis", "authors": "Simone Palazzo, Concetto Spampinato, Isaak Kavasidis, Daniela\n  Giordano, Joseph Schmidt, Mubarak Shah", "title": "Decoding Brain Representations by Multimodal Learning of Neural Activity\n  and Visual Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents a novel method of exploring human brain-visual\nrepresentations, with a view towards replicating these processes in machines.\nThe core idea is to learn plausible computational and biological\nrepresentations by correlating human neural activity and natural images. Thus,\nwe first propose a model, EEG-ChannelNet, to learn a brain manifold for EEG\nclassification. After verifying that visual information can be extracted from\nEEG data, we introduce a multimodal approach that uses deep image and EEG\nencoders, trained in a siamese configuration, for learning a joint manifold\nthat maximizes a compatibility measure between visual features and brain\nrepresentations. We then carry out image classification and saliency detection\non the learned manifold. Performance analyses show that our approach\nsatisfactorily decodes visual information from neural signals. This, in turn,\ncan be used to effectively supervise the training of deep learning models, as\ndemonstrated by the high performance of image classification and saliency\ndetection on out-of-training classes. The obtained results show that the\nlearned brain-visual features lead to improved performance and simultaneously\nbring deep models more in line with cognitive neuroscience work related to\nvisual perception and attention.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 16:52:20 GMT"}, {"version": "v2", "created": "Sat, 18 Apr 2020 17:49:41 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Palazzo", "Simone", ""], ["Spampinato", "Concetto", ""], ["Kavasidis", "Isaak", ""], ["Giordano", "Daniela", ""], ["Schmidt", "Joseph", ""], ["Shah", "Mubarak", ""]]}, {"id": "1810.11212", "submitter": "Deirel Paz-Linares", "authors": "Eduardo Gonzalez-Moreira, Deirel Paz-Linares, Ariosky Areces-Gonzalez,\n  Rigel Wang and Pedro A. Valdes-Sosa", "title": "Third Generation MEEG Source Connectivity Analysis Toolbox (BC-VARETA\n  1.0) and Validation Benchmark", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new toolbox for MEEG source activity and connectivity\nestimation: Brain Connectivity Variable Resolution Tomographic Analysis version\n1.0 (BC-VARETA 1.0). It relies on the third generation of nonlinear methods for\nthe analysis of resting state MEEG Time Series. Into the state of the art of\nMEEG analysis, the methodology underlying our tool (BC-VARETA) brings out\nseveral assets. First: Constitutes a Bayesian Identification approach of Linear\nDynamical Systems in the Frequency Domain, grounded in more consistent models\n(third generation). Second: Achieves Super-Resolution, through the iterative\nsolution of a Sparse Hermitian Source Graphical Model. Third: Tackles\nefficiently in High Dimensional and Complex set up the estimation of\nconnectivity. Fourth: Incorporates priors at the connectivity level by\npenalizing the groups of variables, corresponding to the Gray Matter anatomical\nsegmentation, and including a probability mask of the anatomically plausible\nconnections. Along with the implementation of our method, we include in this\ntoolbox a benchmark for the validation of MEEG source analysis methods, that\nwould serve for the evaluation of sophisticated methodologies (third\ngeneration). It incorporates two elements. First: A realistic simulation\nframework, for the generation of MEEG synthetic data, given an underlying\nsource connectivity structure. Second: Sensitive quality measures that allow\nfor a reliable evaluation of the source activity and connectivity\nreconstruction performance, based on the Spatial Dispersion and Earth Movers\nDistance, in both source and connectivity space.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 07:47:04 GMT"}, {"version": "v2", "created": "Sun, 1 Dec 2019 06:35:05 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Gonzalez-Moreira", "Eduardo", ""], ["Paz-Linares", "Deirel", ""], ["Areces-Gonzalez", "Ariosky", ""], ["Wang", "Rigel", ""], ["Valdes-Sosa", "Pedro A.", ""]]}, {"id": "1810.11248", "submitter": "Maryam Tohidi-Moghaddam", "authors": "Maryam Tohidi-Moghaddam, Sajjad Zabbah, Farzaneh Olianezhad, Reza\n  Ebrahimpour", "title": "Sequence-dependent sensitivity explains the accuracy of decisions when\n  cues are separated with a gap", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most decisions require information gathering from a stimulus presented with\ndifferent gaps. Indeed, the brain process of this integration is rarely\nambiguous. Recently, it has been claimed that humans can optimally integrate\nthe information of two discrete pulses independent of the temporal gap between\nthem. Interestingly, subjects' performance on such a task, with two discrete\npulses, is superior to what a perfect accumulator can predict. Although\nnumerous neuronal and descriptive models have been proposed to explain the\nmechanism of perceptual decision-making, none can explain human behavior in\nthis two-pulse task. In order to investigate the mechanism of decision-making\non the noted tasks, a set of modified drift-diffusion models based on different\nhypotheses were used. Model comparisons clarified that, in a sequence of\ninformation arriving at different times, the accumulated information of earlier\nevidence affects the process of information accumulation of later evidence. It\nwas shown that the rate of information extraction depends on whether the pulse\nis the first or the second one. The proposed model can also explain the\nstronger effect of the second pulse as shown by Kiani et al. 2013.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 10:22:09 GMT"}], "update_date": "2018-10-29", "authors_parsed": [["Tohidi-Moghaddam", "Maryam", ""], ["Zabbah", "Sajjad", ""], ["Olianezhad", "Farzaneh", ""], ["Ebrahimpour", "Reza", ""]]}, {"id": "1810.11362", "submitter": "Eslam Abbas", "authors": "Eslam Abbas", "title": "On The Ignition, Propagation and Termination Of The Neuronal Bursting\n  Activity During Ictogenesis In Epileptic Patients", "comments": "9 pages; 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Epilepsy creates a persistent increase in the probability of spontaneous\nseizures. An ictal episode evolves due to acute disturbance of the fine-tuned\nbalance between excitatory vs. inhibitory inputs within a neural network in\nfavor of excitation. The current literature that proposes the\nactivity-dependent disinhibition as a valid mechanism of chronic epilepsy, does\nnot provide clues on why this mechanism emerges only in epileptic patients and\nhow the vicious circle resulting of an activity-dependent disinhibition in\nover-active ictogenic network would end. A new model, which presents chronic\nepilepsy as a disease of faulty architecture of the neural circuit, is\ndiscussed. Wherein; variable genetic or acquired predisposing factors drive\nabnormalities in the construction of multiple neural circuits resulting in an\nactivity-dependent positive feedback excitatory loops which transform normal\nneural circuits into ictal foci. Such new mechanism, for igniting an\nactivity-dependent unstable excitation with subsequent relatively stable\ndisinhibition, leads to an ictal escape rhythm. The propagation of such\nbursting activity occurs either electrochemically via synaptic communication to\nremote susceptible circuits, or chemically via a trigger wave which recruits\nthe non-connected proximal neurons. Termination occurs abruptly when the\ninhibitory interneurons functionally recover and reimpose their inhibitory\neffect on the ictogenic circuit to transform the escape rhythm into a normal,\nunder-control output. The proposed model elucidates various enigmatic features\nof the disease; and illustrates both the end-result ictogenic mechanism arising\nfrom the wide variety of etiologies of human spontaneous and acquired epilepsy,\nand the timing of episodic transitions from normal activity to seizures.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 21:03:48 GMT"}], "update_date": "2018-10-29", "authors_parsed": [["Abbas", "Eslam", ""]]}, {"id": "1810.11393", "submitter": "Jo\\~ao Sacramento", "authors": "Jo\\~ao Sacramento, Rui Ponte Costa, Yoshua Bengio, Walter Senn", "title": "Dendritic cortical microcircuits approximate the backpropagation\n  algorithm", "comments": "To appear in Advances in Neural Information Processing Systems 31\n  (NIPS 2018). 12 pages, 3 figures, 9 pages of supplementary material (2\n  supplementary figures)", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has seen remarkable developments over the last years, many of\nthem inspired by neuroscience. However, the main learning mechanism behind\nthese advances - error backpropagation - appears to be at odds with\nneurobiology. Here, we introduce a multilayer neuronal network model with\nsimplified dendritic compartments in which error-driven synaptic plasticity\nadapts the network towards a global desired output. In contrast to previous\nwork our model does not require separate phases and synaptic learning is driven\nby local dendritic prediction errors continuously in time. Such errors\noriginate at apical dendrites and occur due to a mismatch between predictive\ninput from lateral interneurons and activity from actual top-down feedback.\nThrough the use of simple dendritic compartments and different cell-types our\nmodel can represent both error and normal activity within a pyramidal neuron.\nWe demonstrate the learning capabilities of the model in regression and\nclassification tasks, and show analytically that it approximates the error\nbackpropagation algorithm. Moreover, our framework is consistent with recent\nobservations of learning between brain areas and the architecture of cortical\nmicrocircuits. Overall, we introduce a novel view of learning on dendritic\ncortical circuits and on how the brain may solve the long-standing synaptic\ncredit assignment problem.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 15:40:58 GMT"}], "update_date": "2018-10-29", "authors_parsed": [["Sacramento", "Jo\u00e3o", ""], ["Costa", "Rui Ponte", ""], ["Bengio", "Yoshua", ""], ["Senn", "Walter", ""]]}, {"id": "1810.11594", "submitter": "Brian Hu", "authors": "Brian Hu and Stefan Mihalas", "title": "Convolutional neural networks with extra-classical receptive fields", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks (CNNs) have had great success in many\nreal-world applications and have also been used to model visual processing in\nthe brain. However, these networks are quite brittle - small changes in the\ninput image can dramatically change a network's output prediction. In contrast\nto what is known from biology, these networks largely rely on feedforward\nconnections, ignoring the influence of recurrent connections. They also focus\non supervised rather than unsupervised learning. To address these issues, we\ncombine traditional supervised learning via backpropagation with a specialized\nunsupervised learning rule to learn lateral connections between neurons within\na convolutional neural network. These connections have been shown to optimally\nintegrate information from the surround, generating extra-classical receptive\nfields for the neurons in our new proposed model (CNNEx). Models with optimal\nlateral connections are more robust to noise and achieve better performance on\nnoisy versions of the MNIST and CIFAR-10 datasets. Resistance to noise can be\nfurther improved by combining our model with additional regularization\ntechniques such as dropout and weight decay. Although the image statistics of\nMNIST and CIFAR-10 differ greatly, the same unsupervised learning rule\ngeneralized to both datasets. Our results demonstrate the potential usefulness\nof combining supervised and unsupervised learning techniques and suggest that\nthe integration of lateral connections into convolutional neural networks is an\nimportant area of future research.\n", "versions": [{"version": "v1", "created": "Sat, 27 Oct 2018 04:15:50 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Hu", "Brian", ""], ["Mihalas", "Stefan", ""]]}, {"id": "1810.11654", "submitter": "Andriy Myronenko", "authors": "Andriy Myronenko", "title": "3D MRI brain tumor segmentation using autoencoder regularization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated segmentation of brain tumors from 3D magnetic resonance images\n(MRIs) is necessary for the diagnosis, monitoring, and treatment planning of\nthe disease. Manual delineation practices require anatomical knowledge, are\nexpensive, time consuming and can be inaccurate due to human error. Here, we\ndescribe a semantic segmentation network for tumor subregion segmentation from\n3D MRIs based on encoder-decoder architecture. Due to a limited training\ndataset size, a variational auto-encoder branch is added to reconstruct the\ninput image itself in order to regularize the shared decoder and impose\nadditional constraints on its layers. The current approach won 1st place in the\nBraTS 2018 challenge.\n", "versions": [{"version": "v1", "created": "Sat, 27 Oct 2018 14:42:13 GMT"}, {"version": "v2", "created": "Tue, 30 Oct 2018 22:59:52 GMT"}, {"version": "v3", "created": "Mon, 19 Nov 2018 17:04:58 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Myronenko", "Andriy", ""]]}, {"id": "1810.11769", "submitter": "Yuri A. Dabaghian", "authors": "Y. Dabaghian", "title": "Through synapses to spatial memory maps: a topological model", "comments": "18 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Various neurophysiological and cognitive functions are based on transferring\ninformation between spiking neurons via a complex system of synaptic\nconnections. In particular, the capacity of presynaptic inputs to influence the\npostsynaptic outputs---the efficacy of the synapses---plays a principal role in\nall aspects of hippocampal neurophysiology. However, a direct link between the\ninformation processed at the level of individual synapses and the animal's\nability to form memories at the organismal level has not yet been fully\nunderstood. Here, we investigate the effect of synaptic transmission\nprobabilities on the ability of the hippocampal place cell ensembles to produce\na cognitive map of the environment. Using methods from algebraic topology, we\nfind that weakening synaptic connections increase spatial learning times,\nproduce topological defects in the large-scale representation of the ambient\nspace and restrict the range of parameters for which place cell ensembles are\ncapable of producing a map with correct topological structure. On the other\nhand, the results indicate a possibility of compensatory phenomena, namely that\nspatial learning deficiencies may be mitigated through enhancement of neuronal\nactivity.\n", "versions": [{"version": "v1", "created": "Sun, 28 Oct 2018 07:05:16 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Dabaghian", "Y.", ""]]}, {"id": "1810.11891", "submitter": "Juntang Zhuang", "authors": "Juntang Zhuang, Nicha C. Dvornek, Xiaoxiao Li, Pamela Ventola, James\n  S. Duncan", "title": "Prediction of severity and treatment outcome for ASD from fMRI", "comments": null, "journal-ref": "International Workshop on Predictive Intelligence In Medicine, pp\n  9-17, 2018, Springer", "doi": "10.1007/978-3-030-00320-3_2", "report-no": null, "categories": "q-bio.NC stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autism spectrum disorder (ASD) is a complex neurodevelopmental syndrome.\nEarly diagnosis and precise treatment are essential for ASD patients. Although\nresearchers have built many analytical models, there has been limited progress\nin accurate predictive models for early diagnosis. In this project, we aim to\nbuild an accurate model to predict treatment outcome and ASD severity from\nearly stage functional magnetic resonance imaging (fMRI) scans. The difficulty\nin building large databases of patients who have received specific treatments\nand the high dimensionality of medical image analysis problems are challenges\nin this work. We propose a generic and accurate two-level approach for\nhigh-dimensional regression problems in medical image analysis. First, we\nperform region-level feature selection using a predefined brain parcellation.\nBased on the assumption that voxels within one region in the brain have similar\nvalues, for each region we use the bootstrapped mean of voxels within it as a\nfeature. In this way, the dimension of data is reduced from number of voxels to\nnumber of regions. Then we detect predictive regions by various feature\nselection methods. Second, we extract voxels within selected regions, and\nperform voxel-level feature selection. To use this model in both linear and\nnon-linear cases with limited training examples, we apply two-level elastic net\nregression and random forest (RF) models respectively. To validate accuracy and\nrobustness of this approach, we perform experiments on both task-fMRI and\nresting state fMRI datasets. Furthermore, we visualize the influence of each\nregion, and show that the results match well with other findings.\n", "versions": [{"version": "v1", "created": "Sun, 28 Oct 2018 21:48:21 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Zhuang", "Juntang", ""], ["Dvornek", "Nicha C.", ""], ["Li", "Xiaoxiao", ""], ["Ventola", "Pamela", ""], ["Duncan", "James S.", ""]]}, {"id": "1810.12016", "submitter": "Mattia Bramini", "authors": "Mattia Bramini, Silvio Sacchetti, Andrea Armirotti, Anna Rocchi, Ester\n  V\\'azquez, Ver\\'onica Le\\'on Castellanos, Tiziano Bandiera, Fabrizia Cesca\n  and Fabio Benfenati", "title": "Graphene oxide nanosheets disrupt lipid composition, Ca2+ homeostasis\n  and synaptic transmission in primary cortical neurons", "comments": "This document is the unedited Author's version of a Submitted Work\n  that was subsequently accepted for publication in ACS Nano. To access the\n  final edited and published work see\n  https://pubs.acs.org/articlesonrequest/AOR-MGXEfuAxY43fnrHfBEuQ", "journal-ref": "ACS Nano 2016, 10, 7, 7154-7171", "doi": "10.1021/acsnano.6b03438", "report-no": null, "categories": "q-bio.NC physics.bio-ph", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Graphene has the potential to make a very significant impact on society, with\nimportant applications in the biomedical field. The possibility to engineer\ngraphene-based medical devices at the neuronal interface is of particular\ninterest, making it imperative to determine the biocompatibility of graphene\nmaterials with neuronal cells. Here we conducted a comprehensive analysis of\nthe effects of chronic and acute exposure of rat primary cortical neurons to\nfew-layers pristine graphene (GR) and monolayer graphene oxide (GO) flakes. By\ncombining a range of cell biology, microscopy, electrophysiology and omics\napproaches we characterized the graphene neuron interaction from the first\nsteps of membrane contact and internalization to the long-term effects on cell\nviability, synaptic transmission and cell metabolism. GR/GO flakes are found in\ncontact with the neuronal membrane, free in the cytoplasm and internalized\nthrough the endolysosomal pathway, with no significant impact on neuron\nviability. However, GO exposure selectively caused the inhibition of excitatory\ntransmission, paralleled by a reduction in the number of excitatory synaptic\ncontacts, and a concomitant enhancement of the inhibitory activity. This was\naccompanied by induction of autophagy, altered Ca2+ dynamics and by a\ndownregulation of some of the main players in the regulation of Ca2+\nhomeostasis in both excitatory and inhibitory neurons. Our results show that,\nalthough graphene exposure does not impact on neuron viability, it does\nnevertheless have important effects on neuronal transmission and network\nfunctionality, thus warranting caution when planning to employ this material\nfor neuro-biological applications.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 09:23:01 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Bramini", "Mattia", ""], ["Sacchetti", "Silvio", ""], ["Armirotti", "Andrea", ""], ["Rocchi", "Anna", ""], ["V\u00e1zquez", "Ester", ""], ["Castellanos", "Ver\u00f3nica Le\u00f3n", ""], ["Bandiera", "Tiziano", ""], ["Cesca", "Fabrizia", ""], ["Benfenati", "Fabio", ""]]}, {"id": "1810.12441", "submitter": "Gustav Markkula", "authors": "Gustav Markkula, Richard Romano, Rachel Waldram, Oscar Giles, Callum\n  Mole, Richard Wilkie", "title": "Modelling visual-vestibular integration and behavioural adaptation in\n  the driving simulator", "comments": "Changes in v2: Minor language improvements to Abstract and\n  Conclusion; Changes in v3: Added acknowledgments and data statement", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.CE cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well established that not only vision but also other sensory modalities\naffect drivers' control of their vehicles, and that drivers adapt over time to\npersistent changes in sensory cues (for example in driving simulators), but the\nmechanisms underlying these behavioural phenomena are poorly understood. Here,\nwe consider the existing literature on how driver steering in slalom tasks is\naffected by the down-scaling of vestibular cues, and propose a driver model\nthat can explain the empirically observed effects, namely: decreased task\nperformance and increased steering effort during initial exposure, followed by\na partial reversal of these effects as task exposure is prolonged.\nUnexpectedly, the model also reproduced another empirical finding: a local\noptimum for motion down-scaling, where path-tracking is better than when\none-to-one motion cues are available. Overall, the results imply that: (1)\ndrivers make direct use of vestibular information as part of determining\nappropriate steering, and (2) motion down-scaling causes a yaw rate\nunderestimation phenomenon, where drivers behave as if the simulated vehicle is\nrotating more slowly than it is. However, (3) in the slalom task, a certain\ndegree of such yaw rate underestimation is beneficial to path tracking\nperformance. Furthermore, (4) behavioural adaptation, as empirically observed\nin slalom tasks, may occur due to (a) down-weighting of vestibular cues, and/or\n(b) increased sensitivity to control errors, in determining when to adjust\nsteering and by how much, but (c) seemingly not in the form of a full\ncompensatory rescaling of the received vestibular input. The analyses presented\nhere provide new insights and hypotheses about simulator driving, and the\ndeveloped models can be used to support research on multisensory integration\nand behavioural adaptation in both driving and other task domains.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 22:30:06 GMT"}, {"version": "v2", "created": "Mon, 5 Nov 2018 16:58:36 GMT"}, {"version": "v3", "created": "Wed, 7 Nov 2018 09:14:46 GMT"}], "update_date": "2018-11-08", "authors_parsed": [["Markkula", "Gustav", ""], ["Romano", "Richard", ""], ["Waldram", "Rachel", ""], ["Giles", "Oscar", ""], ["Mole", "Callum", ""], ["Wilkie", "Richard", ""]]}, {"id": "1810.12898", "submitter": "Anna Song", "authors": "Anna Song, Olivier Faugeras and Romain Veltz", "title": "A neural field model for color perception unifying assimilation and\n  contrast", "comments": "28 pages, 14 figures, 6 supplementary files (to be found on PLOS'\n  website)", "journal-ref": null, "doi": "10.1371/journal.pcbi.1007050", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the question of color-space interactions in the brain, by\nproposing a neural field model of color perception with spatial context for the\nvisual area V1 of the cortex. Our framework reconciles two opposing perceptual\nphenomena, known as simultaneous contrast and chromatic assimilation. They have\nbeen previously shown to act synergistically, so that at some point in an\nimage, the color seems perceptually more similar to that of adjacent neighbors,\nwhile being more dissimilar from that of remote ones. Thus, their combined\neffects are enhanced in the presence of a spatial pattern, and can be measured\nas larger shifts in color matching experiments. Our model supposes a\nhypercolumnar structure coding for colors in V1, and relies on the notion of\ncolor opponency introduced by Hering. The connectivity kernel of the neural\nfield exploits the balance between attraction and repulsion in color and\nphysical spaces, so as to reproduce the sign reversal in the influence of\nneighboring points. The color sensation at a point, defined from a steady state\nof the neural activities, is then extracted as a nonlinear percept conveyed by\nan assembly of neurons. It connects the cortical and perceptual levels, because\nwe describe the search for a color match in asymmetric matching experiments as\na mathematical projection on color sensations. We validate our color neural\nfield alongside this color matching framework, by performing a multi-parameter\nregression to data produced by psychophysicists and ourselves. All the results\nshow that we are able to explain the nonlinear behavior of shifts observed\nalong one or two dimensions in color space, which cannot be done using a simple\nlinear model.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 17:50:29 GMT"}, {"version": "v2", "created": "Fri, 28 Jun 2019 12:29:41 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Song", "Anna", ""], ["Faugeras", "Olivier", ""], ["Veltz", "Romain", ""]]}, {"id": "1810.12954", "submitter": "Li Xiao", "authors": "Li Xiao, Julia M. Stephen, Tony W. Wilson, Vince D. Calhoun, and\n  Yu-Ping Wang", "title": "Alternating Diffusion Map Based Fusion of Multimodal Brain Connectivity\n  Networks for IQ Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To explain individual differences in development, behavior, and cognition,\nmost previous studies focused on projecting resting-state functional MRI (fMRI)\nbased functional connectivity (FC) data into a low-dimensional space via linear\ndimensionality reduction techniques, followed by executing analysis operations.\nHowever, linear dimensionality analysis techniques may fail to capture\nnonlinearity of brain neuroactivity. Moreover, besides resting-state FC, FC\nbased on task fMRI can be expected to provide complementary information.\nMotivated by these considerations, we nonlinearly fuse resting-state and\ntask-based FC networks (FCNs) to seek a better representation in this paper. We\npropose a framework based on alternating diffusion map (ADM), which extracts\ngeometry-preserving low-dimensional embeddings that successfully parameterize\nthe intrinsic variables driving the phenomenon of interest. Specifically, we\nfirst separately build resting-state and task-based FCNs by symmetric positive\ndefinite matrices using sparse inverse covariance estimation for each subject,\nand then utilize the ADM to fuse them in order to extract significant\nlow-dimensional embeddings, which are used as fingerprints to identify\nindividuals. The proposed framework is validated on the Philadelphia\nNeurodevelopmental Cohort data, where we conduct extensive experimental study\non resting-state and fractal $n$-back task fMRI for the classification of\nintelligence quotient (IQ). The fusion of resting-state and $n$-back task fMRI\nby the proposed framework achieves better classification accuracy than any\nsingle fMRI, and the proposed framework is shown to outperform several other\ndata fusion methods. To our knowledge, this paper is the first to demonstrate a\nsuccessful extension of the ADM to fuse resting-state and task-based fMRI data\nfor accurate prediction of IQ.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 18:29:50 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Xiao", "Li", ""], ["Stephen", "Julia M.", ""], ["Wilson", "Tony W.", ""], ["Calhoun", "Vince D.", ""], ["Wang", "Yu-Ping", ""]]}, {"id": "1810.13034", "submitter": "Joaquin Torres", "authors": "Joaqu\\'in J. Torres and Muhammet Uzuntarla and J. Marro", "title": "Theory for Inverse Stochastic Resonance in Nature", "comments": "7 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.stat-mech cond-mat.dis-nn q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The inverse stochastic resonance (ISR) phenomenon consists in an unexpected\ndepression in the response of a system under external noise, e.g., as observed\nin the behavior of the mean-firing rate in some pacemaker neurons in the\npresence of moderate values of noise. A possible requirement for such behavior\nis the existence of a bistable regime in the behavior of these neurons. We here\nexplore theoretically the possible emergence of this behavior in a general\nbistable system, and conclude on conditions the potential function which drives\nthe dynamics must accomplish. We show that such an intriguing, and apparently\nwidely observed, phenomenon ensues in the case of an asymmetric potential\nfunction when the high activity minimum state of the system is metastable with\nthe largest basin of attraction and the low activity state is the global\nminimum with a smaller basin of attraction. We discuss on the relevance of such\na picture to understand the ISR features and to predict its general appearance\nin other natural systems that share the requirements described here. Finally,\nwe report another intriguing non-standard stochastic resonance in our system,\nwhich occurs in the absence of any weak signal input into the system and whose\nemergence can be explained, with the ISR, within our theoretical framework in\nthis paper in terms of the shape of the potential function.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 23:36:20 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Torres", "Joaqu\u00edn J.", ""], ["Uzuntarla", "Muhammet", ""], ["Marro", "J.", ""]]}, {"id": "1810.13302", "submitter": "Nicole Voges", "authors": "Jeyathevy Sukiban, Nicole Voges, Till A. Dembek, Robin Pauli, Michael\n  Denker, Immo Weber, Lars Timmermann, Sonja Gr\\\"un", "title": "Evaluation of spike sorting algorithms: Simulations and application to\n  human Subthalamic Nucleus recordings", "comments": "9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important prerequisite for the analysis of spike synchrony in\nextracellular recordings is the extraction of single unit activity from the\nrecorded multi unit signal. To identify single units (SUs), potential spikes\nare detected and separated with respect to their potential neuronal origins\n('spike sorting'). However, different sorting algorithms yield inconsistent\nunit assignments which seriously influences the subsequent analyses of the\nspiking activity. To evaluate the quality of spike sortings performed with\ndifferent prevalent algorithms offered by the 'Plexon Offline Sorter' we first\napply these algorithms to experimental data (ED), namely recordings in the\nSubthalamic Nucleus of patients with Parkinson's disease, obtained during Deep\nBrain Stimulation surgery. Since this procedure leaves us unsure about the best\nsorting result we then apply all methods again to artificial data (AD) with\nknown ground truth (GT). AD consists of pairs of SUs with different shape\nsimilarity embedded in the background noise of the ED. The sorting evaluation\nis based on the influence of the respective methods on the SU assignments and\nits effect on the resulting firing characteristics. We find a high variability\nin the sorting results obtained by different algorithms that increases with SU\nshape similarity. We also find significant differences in the resulting firing\ncharacteristics of the ED. We conclude that Valley-Seeking produces the most\naccurate results if the exclusion of artifacts as unsorted events is important.\nIf the latter is less important ('clean' data) K-Means is a better option. Our\nresults strongly argue for the need of standardized validation procedures for\nspike sorting based on GT data. The recipe suggested here is simple enough to\nbecome a standard procedure.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 14:32:45 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Sukiban", "Jeyathevy", ""], ["Voges", "Nicole", ""], ["Dembek", "Till A.", ""], ["Pauli", "Robin", ""], ["Denker", "Michael", ""], ["Weber", "Immo", ""], ["Timmermann", "Lars", ""], ["Gr\u00fcn", "Sonja", ""]]}, {"id": "1810.13342", "submitter": "Diederik Aerts", "authors": "Diederik Aerts, Lester Beltran, Suzette Geriente, Massimiliano Sassoli\n  de Bianchi, Sandro Sozzo, Rembrandt Van Sprundel and Tomas Veloz", "title": "Quantum Theory Methods as a Possible Alternative for the Double-Blind\n  Gold Standard of Evidence-Based Medicine: Outlining a New Research Program", "comments": "9 pages, no figures", "journal-ref": null, "doi": "10.1007/s10699-018-9572-0", "report-no": null, "categories": "q-bio.NC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We motivate the possibility of using notions and methods derived from quantum\nphysics, and more specifically from the research field known as 'quantum\ncognition', to optimally model different situations in the field of medicine,\nits decision-making processes and ensuing practices, particularly in relation\nto chronic and rare diseases. This also as a way to devise alternative\napproaches to the generally adopted double-blind gold standard.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 15:33:24 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Aerts", "Diederik", ""], ["Beltran", "Lester", ""], ["Geriente", "Suzette", ""], ["de Bianchi", "Massimiliano Sassoli", ""], ["Sozzo", "Sandro", ""], ["Van Sprundel", "Rembrandt", ""], ["Veloz", "Tomas", ""]]}, {"id": "1810.13373", "submitter": "David Barrett", "authors": "David G.T. Barrett, Ari S. Morcos and Jakob H. Macke", "title": "Analyzing biological and artificial neural networks: challenges with\n  opportunities for synergy?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) transform stimuli across multiple processing\nstages to produce representations that can be used to solve complex tasks, such\nas object recognition in images. However, a full understanding of how they\nachieve this remains elusive. The complexity of biological neural networks\nsubstantially exceeds the complexity of DNNs, making it even more challenging\nto understand the representations that they learn. Thus, both machine learning\nand computational neuroscience are faced with a shared challenge: how can we\nanalyze their representations in order to understand how they solve complex\ntasks?\n  We review how data-analysis concepts and techniques developed by\ncomputational neuroscientists can be useful for analyzing representations in\nDNNs, and in turn, how recently developed techniques for analysis of DNNs can\nbe useful for understanding representations in biological neural networks. We\nexplore opportunities for synergy between the two fields, such as the use of\nDNNs as in-silico model systems for neuroscience, and how this synergy can lead\nto new hypotheses about the operating principles of biological neural networks.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 16:09:44 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Barrett", "David G. T.", ""], ["Morcos", "Ari S.", ""], ["Macke", "Jakob H.", ""]]}]