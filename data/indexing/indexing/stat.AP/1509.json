[{"id": "1509.00051", "submitter": "Laura Tupper", "authors": "Laura L. Tupper, David S. Matteson, C. Lindsay Anderson", "title": "Band Depth Clustering for Nonstationary Time Series and Wind Speed\n  Behavior", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the behavior of wind speed over time, using the Eastern Wind\nDataset published by the National Renewable Energy Laboratory. This dataset\ngives wind speeds over three years at hundreds of potential wind farm sites.\nWind speed analysis is necessary to the integration of wind energy into the\npower grid; short-term variability in wind speed affects decisions about usage\nof other power sources, so that the shape of the wind speed curve becomes as\nimportant as the overall level. To assess differences in intra-day time series,\nwe propose a functional distance measure, the band distance, which extends the\nband depth of Lopez-Pintado and Romo (2009). This measure emphasizes the shape\nof time series or functional observations relative to other members of a\ndataset, and allows clustering of observations without reliance on pointwise\nEuclidean distance. To emphasize short-term variability, we examine the\nshort-time Fourier transform of the nonstationary speed time series; we can\nalso adjust for seasonal effects, and use these standardizations as input for\nthe band distance. We show that these approaches to characterizing the data go\nbeyond mean-dependent standard clustering methods, such as k-means, to provide\nmore shape-influenced cluster representatives useful for power grid decisions.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2015 20:28:25 GMT"}], "update_date": "2015-09-02", "authors_parsed": [["Tupper", "Laura L.", ""], ["Matteson", "David S.", ""], ["Anderson", "C. Lindsay", ""]]}, {"id": "1509.00095", "submitter": "Li Chen", "authors": "Li Chen, Pooja Jain, Kingsum Chow, Emad Guirguis, Tony Wu", "title": "Brewing Analytics Quality for Cloud Performance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.DC stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud computing has become increasingly popular. Many options of cloud\ndeployments are available. Testing cloud performance would enable us to choose\na cloud deployment based on the requirements. In this paper, we present an\ninnovative process, implemented in software, to allow us to assess the quality\nof the cloud performance data. The process combines performance data from\nmultiple machines, spanning across user experience data, workload performance\nmetrics, and readily available system performance data. Furthermore, we discuss\nthe major challenges of bringing raw data into tidy data formats in order to\nenable subsequent analysis, and describe how our process has several layers of\nassessment to validate the quality of the data processing procedure. We present\na case study to demonstrate the effectiveness of our proposed process, and\nconclude our paper with several future research directions worth investigating.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2015 23:55:54 GMT"}], "update_date": "2015-09-03", "authors_parsed": [["Chen", "Li", ""], ["Jain", "Pooja", ""], ["Chow", "Kingsum", ""], ["Guirguis", "Emad", ""], ["Wu", "Tony", ""]]}, {"id": "1509.00110", "submitter": "Kai Fan", "authors": "Kai Fan, Allison E. Aiello, Katherine A. Heller", "title": "Bayesian Models for Heterogeneous Personalized Health Data", "comments": "35 pages; Heterogeneous Flu Diffusion, Social Networks, Dynamic\n  Bayesian Modeling", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The purpose of this study is to leverage modern technology (such as mobile or\nweb apps in Beckman et al. (2014)) to enrich epidemiology data and infer the\ntransmission of disease. Homogeneity related research on population level has\nbeen intensively studied in previous work. In contrast, we develop hierarchical\nGraph-Coupled Hidden Markov Models (hGCHMMs) to simultaneously track the spread\nof infection in a small cell phone community and capture person-specific\ninfection parameters by leveraging a link prior that incorporates additional\ncovariates. We also reexamine the model evolution of the hGCHMM from simple\nHMMs and LDA, elucidating additional flexibility and interpretability. Due to\nthe non-conjugacy of sparsely coupled HMMs, we design a new approximate\ndistribution, allowing our approach to be more applicable to other application\nareas. Additionally, we investigate two common link functions, the\nbeta-exponential prior and sigmoid function, both of which allow the\ndevelopment of a principled Bayesian hierarchical framework for disease\ntransmission. The results of our model allow us to predict the probability of\ninfection for each person on each day, and also to infer personal physical\nvulnerability and the relevant association with covariates. We demonstrate our\napproach experimentally on both simulation data and real epidemiological\nrecords.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2015 01:32:51 GMT"}], "update_date": "2015-09-02", "authors_parsed": [["Fan", "Kai", ""], ["Aiello", "Allison E.", ""], ["Heller", "Katherine A.", ""]]}, {"id": "1509.00533", "submitter": "Scott Wisdom", "authors": "Scott Wisdom, Thomas Powers, Les Atlas, and James Pitton", "title": "Enhancement and Recognition of Reverberant and Noisy Speech by Extending\n  Its Coherence", "comments": "22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most speech enhancement algorithms make use of the short-time Fourier\ntransform (STFT), which is a simple and flexible time-frequency decomposition\nthat estimates the short-time spectrum of a signal. However, the duration of\nshort STFT frames are inherently limited by the nonstationarity of speech\nsignals. The main contribution of this paper is a demonstration of speech\nenhancement and automatic speech recognition in the presence of reverberation\nand noise by extending the length of analysis windows. We accomplish this\nextension by performing enhancement in the short-time fan-chirp transform\n(STFChT) domain, an overcomplete time-frequency representation that is coherent\nwith speech signals over longer analysis window durations than the STFT. This\nextended coherence is gained by using a linear model of fundamental frequency\nvariation of voiced speech signals. Our approach centers around using a\nsingle-channel minimum mean-square error log-spectral amplitude (MMSE-LSA)\nestimator proposed by Habets, which scales coefficients in a time-frequency\ndomain to suppress noise and reverberation. In the case of multiple\nmicrophones, we preprocess the data with either a minimum variance\ndistortionless response (MVDR) beamformer, or a delay-and-sum beamformer (DSB).\nWe evaluate our algorithm on both speech enhancement and recognition tasks for\nthe REVERB challenge dataset. Compared to the same processing done in the STFT\ndomain, our approach achieves significant improvement in terms of objective\nenhancement metrics (including PESQ---the ITU-T standard measurement for speech\nquality). In terms of automatic speech recognition (ASR) performance as\nmeasured by word error rate (WER), our experiments indicate that the STFT with\na long window is more effective for ASR.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2015 00:31:40 GMT"}], "update_date": "2015-09-03", "authors_parsed": [["Wisdom", "Scott", ""], ["Powers", "Thomas", ""], ["Atlas", "Les", ""], ["Pitton", "James", ""]]}, {"id": "1509.00549", "submitter": "Srinath Sampath", "authors": "Srinath Sampath, Adriano Caloiaro, Wayne Johnson, Joseph S. Verducci", "title": "The Top-K Tau-Path Screen for Monotone Association", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A pair of variables that tend to rise and fall either together or in\nopposition are said to be monotonically associated. For certain phenomena, this\ntendency is causally restricted to a subpopulation, as, for example, an\nallergic reaction to an irritant. Previously, Yu et al. (2011) devised a method\nof rearranging observations to test paired data to see if such an association\nmight be present in a subpopulation. However, the computational intensity of\nthe method limited its application to relatively small samples of data, and the\ntest itself only judges if association is present in some subpopulation; it\ndoes not clearly identify the subsample that came from this subpopulation,\nespecially when the whole sample tests positive. The present paper adds a\n\"top-K\" feature (Sampath and Verducci (2013)) based on a multistage ranking\nmodel, that identifies a concise subsample that is likely to contain a high\nproportion of observations from the subpopulation in which the association is\nsupported. Computational improvements incorporated into this top-K tau-path\n(TKTP) algorithm now allow the method to be extended to thousands of pairs of\nvariables measured on sample sizes in the thousands. A description of the new\nalgorithm along with measures of computational complexity and practical\nefficiency help to gauge its potential use in different settings. Simulation\nstudies catalog its accuracy in various settings, and an example from finance\nillustrates its step-by-step use.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2015 02:59:38 GMT"}], "update_date": "2015-09-03", "authors_parsed": [["Sampath", "Srinath", ""], ["Caloiaro", "Adriano", ""], ["Johnson", "Wayne", ""], ["Verducci", "Joseph S.", ""]]}, {"id": "1509.00571", "submitter": "Michael Vaillant", "authors": "Thibault Laurent (GREMAQ), Christine Thomas-Agnan (GREMAQ), Micha\\\"el\n  Vaillant", "title": "Spatial Point Pattern Analysis of the Unidentified Aerial Phenomena in\n  France", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We model the unidentified aerial phenomena observed in France during the last\n60 years as a spatial point pattern. We use some public information such as\npopulation density, rate of moisture or presence of airports to model the\nintensity of the unidentified aerial phenomena. Spatial exploratory data\nanalysis is a first approach to appreciate the link between the intensity of\nthe unidentified aerial phenomena and the covariates. We then fit an\ninhomogeneous spatial Poisson process model with covariates. We find that the\nsignificant variables are the population density, the presence of the factories\nwith a nuclear risk and contaminated land, and the rate of moisture. The\nanalysis of the residuals shows that some parts of France (the Belgian border,\nthe tip of Britany, some parts in the SouthEast , the Picardie and\nHaute-Normandie regions, the Loiret and Corr eze departments) present a high\nvalue of local intensity which are not explained by our model.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2015 06:42:07 GMT"}], "update_date": "2015-09-03", "authors_parsed": [["Laurent", "Thibault", "", "GREMAQ"], ["Thomas-Agnan", "Christine", "", "GREMAQ"], ["Vaillant", "Micha\u00ebl", ""]]}, {"id": "1509.00915", "submitter": "Andrew Zammit-Mangion", "authors": "Andrew Zammit-Mangion and Noel Cressie and Anita L. Ganesan and Simon\n  O' Doherty and Alistair J. Manning", "title": "Spatio-temporal bivariate statistical models for atmospheric trace-gas\n  inversion", "comments": "39 pages, 8 figures", "journal-ref": "Chemometrics and Intelligent Laboratory Systems, Vol. 149,\n  15.12.2015, p. 227-241", "doi": "10.1016/j.chemolab.2015.09.006", "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Atmospheric trace-gas inversion refers to any technique used to predict\nspatial and temporal fluxes using mole-fraction measurements and atmospheric\nsimulations obtained from computer models. Studies to date are most often of a\ndata-assimilation flavour, which implicitly consider univariate statistical\nmodels with the flux as the variate of interest. This univariate approach\ntypically assumes that the flux field is either a spatially correlated Gaussian\nprocess or a spatially uncorrelated non-Gaussian process with prior expectation\nfixed using flux inventories (e.g., NAEI or EDGAR in Europe). Here, we extend\nthis approach in three ways. First, we develop a bivariate model for the\nmole-fraction field and the flux field. The bivariate approach allows optimal\nprediction of both the flux field and the mole-fraction field, and it leads to\nsignificant computational savings over the univariate approach. Second, we\nemploy a lognormal spatial process for the flux field that captures both the\nlognormal characteristics of the flux field (when appropriate) and its spatial\ndependence. Third, we propose a new, geostatistical approach to incorporate the\nflux inventories in our updates, such that the posterior spatial distribution\nof the flux field is predominantly data-driven. The approach is illustrated on\na case study of methane (CH$_4$) emissions in the United Kingdom and Ireland.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2015 01:53:58 GMT"}, {"version": "v2", "created": "Mon, 19 Oct 2015 04:04:58 GMT"}], "update_date": "2016-09-29", "authors_parsed": [["Zammit-Mangion", "Andrew", ""], ["Cressie", "Noel", ""], ["Ganesan", "Anita L.", ""], ["Doherty", "Simon O'", ""], ["Manning", "Alistair J.", ""]]}, {"id": "1509.00976", "submitter": "Ahmad AlAmmouri", "authors": "Ahmad AlAmmouri, Hesham ElSawy, Osama Amin, Mohamed-Slim Alouini", "title": "In-Band $\\alpha$-Duplex Scheme for Cellular Networks: A Stochastic\n  Geometry Approach", "comments": "IEEE TWC", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In-band full-duplex (FD) communications have been optimistically promoted to\nimprove the spectrum utilization and efficiency. However, the penetration of FD\ncommunications to the cellular networks domain is challenging due to the\nimposed uplink/downlink interference. This paper presents a tractable\nframework, based on stochastic geometry, to study FD communications in cellular\nnetworks. Particularly, we assess the FD communications effect on the network\nperformance and quantify the associated gains. The study proves the\nvulnerability of the uplink to the downlink interference and shows that the\nimproved FD rate gains harvested in the downlink (up to $97\\%$) comes at the\nexpense of a significant degradation in the uplink rate (up to $94\\%$).\nTherefore, we propose a novel fine-grained duplexing scheme, denoted as\n$\\alpha$-duplex scheme, which allows a partial overlap between the uplink and\nthe downlink frequency bands. We derive the required conditions to harvest rate\ngains from the $\\alpha$-duplex scheme and show its superiority to both the FD\nand half-duplex (HD) schemes. In particular, we show that the $\\alpha$-duplex\nscheme provides a simultaneous improvement of $28\\%$ for the downlink rate and\n$56\\%$ for the uplink rate. Finally, we show that the amount of the overlap can\nbe optimized based on the network design objective.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2015 08:14:47 GMT"}, {"version": "v2", "created": "Wed, 10 Feb 2016 19:41:17 GMT"}, {"version": "v3", "created": "Mon, 11 Jul 2016 18:19:08 GMT"}], "update_date": "2016-07-12", "authors_parsed": [["AlAmmouri", "Ahmad", ""], ["ElSawy", "Hesham", ""], ["Amin", "Osama", ""], ["Alouini", "Mohamed-Slim", ""]]}, {"id": "1509.01051", "submitter": "Gianluca Rosso", "authors": "Gianluca Rosso", "title": "Extreme Value Theory for Time Series using Peak-Over-Threshold method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This brief paper summarize the chances offered by the Peak-Over-Threshold\nmethod, related with analysis of extremes. Identification of appropriate Value\nat Risk can be solved by fitting data with a Generalized Pareto Distribution.\nAlso an estimation of value for the Expected Shortfall can be useful, and the\napplication of these few concepts are valid for the most wide range of risk\nanalysis, from the financial application to the operational risk assessment,\nthrough the analysis for climate time series; resolving the problem of\nborderline data.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2015 12:12:46 GMT"}], "update_date": "2015-09-04", "authors_parsed": [["Rosso", "Gianluca", ""]]}, {"id": "1509.01199", "submitter": "Erika Fille Legara", "authors": "Erika Fille Legara and Christopher Monterola", "title": "Inferring Passenger Type from Commuter Eigentravel Matrices", "comments": "14 pages, 7 figures. Preprint submitted to Elsevier and is currently\n  under review. An earlier version of this work (contributed as an extended\n  abstract) has been accepted for presentation at the 2015 Conference on\n  Complex Systems in Phoenix, Arizona, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.CY physics.data-an stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A sufficient knowledge of the demographics of a commuting public is essential\nin formulating and implementing more targeted transportation policies, as\ncommuters exhibit different ways of traveling. With the advent of the Automated\nFare Collection system (AFC), probing the travel patterns of commuters has\nbecome less invasive and more accessible. Consequently, numerous transport\nstudies related to human mobility have shown that these observed patterns allow\none to pair individuals with locations and/or activities at certain times of\nthe day. However, classifying commuters using their travel signatures is yet to\nbe thoroughly examined.\n  Here, we contribute to the literature by demonstrating a procedure to\ncharacterize passenger types (Adult, Child/Student, and Senior Citizen) based\non their three-month travel patterns taken from a smart fare card system. We\nfirst establish a method to construct distinct commuter matrices, which we\nrefer to as eigentravel matrices, that capture the characteristic travel\nroutines of individuals. From the eigentravel matrices, we build classification\nmodels that predict the type of passengers traveling. Among the models\nexplored, the gradient boosting method (GBM) gives the best prediction accuracy\nat 76%, which is 84% better than the minimum model accuracy (41%) required\nvis-\\`a-vis the proportional chance criterion. In addition, we find that travel\nfeatures generated during weekdays have greater predictive power than those on\nweekends. This work should not only be useful for transport planners, but for\nmarket researchers as well. With the awareness of which commuter types are\ntraveling, ads, service announcements, and surveys, among others, can be made\nmore targeted spatiotemporally. Finally, our framework should be effective in\ncreating synthetic populations for use in real-world simulations that involve a\nmetropolitan's public transport system.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2015 16:10:08 GMT"}], "update_date": "2015-09-04", "authors_parsed": [["Legara", "Erika Fille", ""], ["Monterola", "Christopher", ""]]}, {"id": "1509.01275", "submitter": "Yolanda Hagar", "authors": "Yolanda Hagar, James J. Dignam, and Vanja Dukic", "title": "Modeling Long-term Outcomes and Treatment Effects After Androgen\n  Deprivation Therapy for Prostate Cancer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analyzing outcomes in long-term cancer survivor studies can be complex. The\neffects of predictors on the failure process may be difficult to assess over\nlonger periods of time, as the commonly used assumption of proportionality of\nhazards holding over an extended period is often questionable. In this\nmanuscript, we compare seven different survival models that estimate the hazard\nrate and the effects of proportional and non-proportional covariates. In\nparticular, we focus on an extension of the the multi-resolution hazard (MRH)\nestimator, combining a non-proportional hierarchical MRH approach with a\ndata-driven pruning algorithm that allows for computational efficiency and\nproduces robust estimates even in times of few observed failures. Using data\nfrom a large-scale randomized prostate cancer clinical trial, we examine\npatterns of biochemical failure and estimate the time-varying effects of\nandrogen deprivation therapy treatment and other covariates. We compare the\nimpact of different modeling strategies and smoothness assumptions on the\nestimated treatment effect. Our results show that the benefits of treatment\ndiminish over time, possibly with implications for future treatment protocols.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2015 20:43:02 GMT"}], "update_date": "2015-09-07", "authors_parsed": [["Hagar", "Yolanda", ""], ["Dignam", "James J.", ""], ["Dukic", "Vanja", ""]]}, {"id": "1509.01570", "submitter": "Aleksey Polunchenko", "authors": "Andrey Pepelyshev and Aleksey S. Polunchenko", "title": "Real-time financial surveillance via quickest change-point detection\n  methods", "comments": "14 pages, 10 figures; to appear in Statistic and Its Interface", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of efficient financial surveillance aimed at\n\"on-the-go\" detection of structural breaks (anomalies) in \"live\"-monitored\nfinancial time series. With the problem approached statistically, viz. as that\nof multi-cyclic sequential (quickest) change-point detection, we propose a\nsemi-parametric multi-cyclic change-point detection procedure to promptly spot\nanomalies as they occur in the time series under surveillance. The proposed\nprocedure is a derivative of the likelihood ratio-based Shiryaev-Roberts (SR)\nprocedure; the latter is a quasi-Bayesian surveillance method known to deliver\nthe fastest (in the multi-cyclic sense) speed of detection, whatever be the\nfalse alarm frequency. We offer a case study where we first carry out, step by\nstep, statistical analysis of a set of real-world financial data, and then set\nup and devise (a) the proposed SR-based anomaly-detection procedure and (b) the\ncelebrated Cumulative Sum (CUSUM) chart to detect structural breaks in the\ndata. While both procedures performed well, the proposed SR-derivative,\nconforming to the intuition, seemed slightly better.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2015 19:28:50 GMT"}, {"version": "v2", "created": "Thu, 3 Dec 2015 18:09:58 GMT"}], "update_date": "2015-12-04", "authors_parsed": [["Pepelyshev", "Andrey", ""], ["Polunchenko", "Aleksey S.", ""]]}, {"id": "1509.01804", "submitter": "Alexander Petersen", "authors": "Alexander Michael Petersen", "title": "Quantifying the impact of weak, strong, and super ties in scientific\n  careers", "comments": "13 pages, 5 figures, 1 Table", "journal-ref": "Proceedings of the National Academy of Sciences 112, E4671-E4680\n  (2015)", "doi": "10.1073/pnas.1501444112", "report-no": null, "categories": "physics.soc-ph cs.DL physics.data-an stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scientists are frequently faced with the important decision to start or\nterminate a creative partnership. This process can be influenced by strategic\nmotivations, as early career researchers are pursuers, whereas senior\nresearchers are typically attractors, of new collaborative opportunities.\nFocusing on the longitudinal aspects of scientific collaboration, we analyzed\n473 collaboration profiles using an ego-centric perspective which accounts for\nresearcher-specific characteristics and provides insight into a range of\ntopics, from career achievement and sustainability to team dynamics and\nefficiency. From more than 166,000 collaboration records, we quantify the\nfrequency distributions of collaboration duration and tie-strength, showing\nthat collaboration networks are dominated by weak ties characterized by high\nturnover rates. We use analytic extreme-value thresholds to identify a new\nclass of indispensable `super ties', the strongest of which commonly exhibit\n>50% publication overlap with the central scientist. The prevalence of super\nties suggests that they arise from career strategies based upon cost, risk, and\nreward sharing and complementary skill matching. We then use a combination of\ndescriptive and panel regression methods to compare the subset of publications\ncoauthored with a super tie to the subset without one, controlling for\npertinent features such as career age, prestige, team size, and prior group\nexperience. We find that super ties contribute to above-average productivity\nand a 17% citation increase per publication, thus identifying these\npartnerships - the analog of life partners - as a major factor in science\ncareer development.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2015 12:58:28 GMT"}], "update_date": "2015-09-08", "authors_parsed": [["Petersen", "Alexander Michael", ""]]}, {"id": "1509.01815", "submitter": "Valery Vilisov", "authors": "Valery Vilisov", "title": "Research: Analysis of Transport Model that Approximates Decision Taker's\n  Preferences", "comments": null, "journal-ref": null, "doi": "10.13140/RG.2.1.5085.6166", "report-no": null, "categories": "cs.LG cs.AI math.OC stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Paper provides a method for solving the reverse Monge-Kantorovich transport\nproblem (TP). It allows to accumulate positive decision-taking experience made\nby decision-taker in situations that can be presented in the form of TP. The\ninitial data for the solution of the inverse TP is the information on orders,\ninventories and effective decisions take by decision-taker. The result of\nsolving the inverse TP contains evaluations of the TPs payoff matrix elements.\nIt can be used in new situations to select the solution corresponding to the\npreferences of the decision-taker. The method allows to gain decision-taker\nexperience, so it can be used by others. The method allows to build the model\nof decision-taker preferences in a specific application area. The model can be\nupdated regularly to ensure its relevance and adequacy to the decision-taker\nsystem of preferences. This model is adaptive to the current preferences of the\ndecision taker.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2015 14:25:45 GMT"}], "update_date": "2015-09-08", "authors_parsed": [["Vilisov", "Valery", ""]]}, {"id": "1509.02124", "submitter": "Yajuan  Si", "authors": "Yajuan Si, Jerome P. Reiter and D. Sunshine Hillygus", "title": "Bayesian Latent Pattern Mixture Models for Handling Attrition in Panel\n  Studies With Refreshment Samples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many panel studies collect refreshment samples---new, randomly sampled\nrespondents who complete the questionnaire at the same time as a subsequent\nwave of the panel. With appropriate modeling, these samples can be leveraged to\ncorrect inferences for biases caused by non-ignorable attrition. We present\nsuch a model when the panel includes many categorical survey variables. The\nmodel relies on a Bayesian latent pattern mixture model, in which an indicator\nfor attrition and the survey variables are modeled jointly via a latent class\nmodel. We allow the multinomial probabilities within classes to depend on the\nattrition indicator, which offers additional flexibility over standard\napplications of latent class models. We present results of simulation studies\nthat illustrate the benefits of this flexibility. We apply the model to correct\nattrition bias in an analysis of data from the 2007-2008 Associated Press/Yahoo\nNews election panel study.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2015 17:06:06 GMT"}], "update_date": "2015-09-08", "authors_parsed": [["Si", "Yajuan", ""], ["Reiter", "Jerome P.", ""], ["Hillygus", "D. Sunshine", ""]]}, {"id": "1509.02261", "submitter": "Willem Kruijer", "authors": "Willem Kruijer", "title": "Misspecification in mixed-model based association analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Additive genetic variance in natural populations is commonly estimated using\nmixed models, in which the covariance of the genetic effects is modeled by a\ngenetic similarity matrix derived from a dense set of markers. An important but\nusually implicit assumption is that the presence of any non-additive genetic\neffect only increases the residual variance, and does not affect estimates of\nadditive genetic variance. Here we show that this is only true for panels of\nunrelated individuals. In case there is genetic relatedness, the combination of\npopulation structure and epistatic interactions can lead to inflated estimates\nof additive genetic variance.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2015 06:55:03 GMT"}], "update_date": "2015-09-09", "authors_parsed": [["Kruijer", "Willem", ""]]}, {"id": "1509.03055", "submitter": "Michela Gnaldi", "authors": "Michela Gnaldi, Venera Tomaselli, Antonio Forcina", "title": "Ecological fallacy and covariates: new insights based on multilevel\n  modelling of individual data", "comments": "arXiv admin note: substantial text overlap with arXiv:1411.4411.\n  substantial text overlap with arXiv:1411.4411", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with the issue of ecological bias in ecological inference.\nWe provide an explicit formulation of the conditions required for the ordinary\necological regression to produce unbiased estimates and argue that, when these\nconditions are violated, any method of ecological inference is going to produce\nbiased estimates. These findings are clarified and supported by empirical\nevidence provided by comparing the results of three main ecological inference\nmethods with those of multilevel logistic regression applied to a unique set of\nindividual data on voting behaviour. The main findings of our study have two\nimportant implications that apply to all situations where the conditions for no\necological bias are violated: (i) only ecological inference methods that allow\nto model the effect of covariates have a chance to produce unbiased estimates;\n(ii) the set of covariates to be included in the model to remove bias is\nlimited to the marginal proportions. Finally, our results suggest that, when\nthe association between two ecological variables is very weak, it is not\npossible to obtain unbiased estimates even by an appropriate model that\naccounts for the effect of relevant covariates.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2015 09:04:49 GMT"}], "update_date": "2015-09-11", "authors_parsed": [["Gnaldi", "Michela", ""], ["Tomaselli", "Venera", ""], ["Forcina", "Antonio", ""]]}, {"id": "1509.03116", "submitter": "Daniel Ambach", "authors": "Daniel Ambach", "title": "Short-Term Wind Speed Forecasting in Germany", "comments": "Accepted: 14 Jun 2015; Published online: 09 Aug 2015. in Journal of\n  Applied Statistics 2015", "journal-ref": null, "doi": "10.1080/02664763.2015.1063113", "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The importance of renewable power production is a set goal in terms of the\nenergy turnaround. Developing short-term wind speed forecasting improvements\nmight increase the profitability of wind power. This article compares two novel\napproaches to model and predict wind speed. Both approaches incorporate\nperiodic interactions, whereas the first model uses Fourier series to model the\nperiodicity. The second model takes $l_{2,p}$ generalised trigonometric\nfunctions into consideration. The aforementioned Fourier series are special\ntypes of the p-generalised trigonometrical function and therefore model 1 is\nnested in model 2. The two models use an ARFIMA-APARCH process to cover the\nautocorrelation and the heteroscedasticity. A data set which consist of 10\nminute data collected at four stations at the German-Polish border from August\n2007 to December 2012 is analysed. The most important finding is an enhancement\nof the forecasting accuracy up to three hours that is directly related to our\nnew short-term forecasting model.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2015 11:53:46 GMT"}], "update_date": "2015-09-11", "authors_parsed": [["Ambach", "Daniel", ""]]}, {"id": "1509.03397", "submitter": "Alice Xiang", "authors": "Alice Xiang, Donald B. Rubin", "title": "Assessing the Potential Impact of a Nationwide Class-Based Affirmative\n  Action System", "comments": "Published at http://dx.doi.org/10.1214/15-STS514 in the Statistical\n  Science (http://www.imstat.org/sts/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Statistical Science 2015, Vol. 30, No. 3, 297-327", "doi": "10.1214/15-STS514", "report-no": "IMS-STS-STS514", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine the possible consequences of a change in law school admissions in\nthe United States from an affirmative action system based on race to one based\non socioeconomic class. Using data from the 1991-1996 Law School Admission\nCouncil Bar Passage Study, students were reassigned attendance by simulation to\nlaw school tiers by transferring the affirmative action advantage for black\nstudents to students from low socioeconomic backgrounds. The hypothetical\nacademic outcomes for the students were then multiply-imputed to quantify the\nuncertainty of the resulting estimates. The analysis predicts dramatic\ndecreases in the numbers of black students in top law school tiers, suggesting\nthat class-based affirmative action is insufficient to maintain racial\ndiversity in prestigious law schools. Furthermore, there appear to be no\nstatistically significant changes in the graduation and bar passage rates of\nstudents in any demographic group. The results thus provide evidence that,\nother than increasing their representation in upper tiers, current affirmative\naction policies relative to a socioeconomic-based system neither substantially\nhelp nor harm minority academic outcomes, contradicting the predictions of the\n\"mismatch\" hypothesis, which asserts otherwise.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2015 06:49:00 GMT"}], "update_date": "2015-09-14", "authors_parsed": [["Xiang", "Alice", ""], ["Rubin", "Donald B.", ""]]}, {"id": "1509.03410", "submitter": "Gustavo da Silva Ferreira", "authors": "Gustavo da Silva Ferreira, Dani Gamerman", "title": "Optimal Design in Geostatistics under Preferential Sampling", "comments": "Published at http://dx.doi.org/10.1214/15-BA944 in the Bayesian\n  Analysis (http://projecteuclid.org/euclid.ba) by the International Society of\n  Bayesian Analysis (http://bayesian.org/)", "journal-ref": "Bayesian Analysis 2015, Vol. 10, No. 3, 711-735", "doi": "10.1214/15-BA944", "report-no": "VTeX-BA-BA944", "categories": "math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper analyses the effect of preferential sampling in Geostatistics when\nthe choice of new sampling locations is the main interest of the researcher. A\nBayesian criterion based on maximizing utility functions is used. Simulated\nstudies are presented and highlight the strong influence of preferential\nsampling in the decisions. The computational complexity is faced by treating\nthe new local sampling locations as a model parameter and the optimal choice is\nthen made by analysing its posterior distribution. Finally, an application is\npresented using rainfall data collected during spring in Rio de Janeiro. The\nresults showed that the optimal design is substantially changed under\npreferential sampling effects. Furthermore, it was possible to identify other\ninteresting aspects related to preferential sampling effects in estimation and\nprediction in Geostatistics. With the Rejoinder to Comments [arXiv:1509.04817],\n[arXiv:1509.04819], [arXiv:1509.04821].\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2015 08:09:02 GMT"}, {"version": "v2", "created": "Tue, 22 Sep 2015 10:55:02 GMT"}], "update_date": "2015-09-23", "authors_parsed": [["Ferreira", "Gustavo da Silva", ""], ["Gamerman", "Dani", ""]]}, {"id": "1509.03521", "submitter": "Sebastian Lerch", "authors": "Sebastian Lerch, Sandor Baran", "title": "Similarity-based semi-local estimation of EMOS models", "comments": null, "journal-ref": "Journal of the Royal Statistical Society, Series C (Applied\n  Statistics) 2017, 66(1): 29-51", "doi": "10.1111/rssc.12153", "report-no": null, "categories": "stat.AP physics.ao-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Weather forecasts are typically given in the form of forecast ensembles\nobtained from multiple runs of numerical weather prediction models with varying\ninitial conditions and physics parameterizations. Such ensemble predictions\ntend to be biased and underdispersive and thus require statistical\npostprocessing. In the ensemble model output statistics (EMOS) approach, a\nprobabilistic forecast is given by a single parametric distribution with\nparameters depending on the ensemble members. This article proposes two\nsemi-local methods for estimating the EMOS coefficients where the training data\nfor a specific observation station are augmented with corresponding forecast\ncases from stations with similar characteristics. Similarities between stations\nare determined using either distance functions or clustering based on various\nfeatures of the climatology, forecast errors, ensemble predictions and\nlocations of the observation stations. In a case study on wind speed over\nEurope with forecasts from the Grand Limited Area Model Ensemble Prediction\nSystem, the proposed similarity-based semi-local models show significant\nimprovement in predictive performance compared to standard regional and local\nestimation methods. They further allow for estimating complex models without\nnumerical stability issues and are computationally more efficient than local\nparameter estimation.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2015 14:03:44 GMT"}], "update_date": "2017-01-13", "authors_parsed": [["Lerch", "Sebastian", ""], ["Baran", "Sandor", ""]]}, {"id": "1509.03730", "submitter": "Yi Yu", "authors": "Ivor Cribben and Yi Yu", "title": "Estimating whole brain dynamics using spectral clustering", "comments": "24 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The estimation of time-varying networks for functional Magnetic Resonance\nImaging (fMRI) data sets is of increasing importance and interest. In this\nwork, we formulate the problem in a high-dimensional time series framework and\nintroduce a data-driven method, namely Network Change Points Detection (NCPD),\nwhich detects change points in the network structure of a multivariate time\nseries, with each component of the time series represented by a node in the\nnetwork. NCPD is applied to various simulated data and a resting-state fMRI\ndata set. This new methodology also allows us to identify common functional\nstates within and across subjects. Finally, NCPD promises to offer a deep\ninsight into the large-scale characterisations and dynamics of the brain\n", "versions": [{"version": "v1", "created": "Sat, 12 Sep 2015 11:35:04 GMT"}, {"version": "v2", "created": "Thu, 23 Jun 2016 16:55:51 GMT"}], "update_date": "2016-06-24", "authors_parsed": [["Cribben", "Ivor", ""], ["Yu", "Yi", ""]]}, {"id": "1509.03770", "submitter": "Christopher E. Granade", "authors": "Christopher Granade, Joshua Combes, D. G. Cory", "title": "Practical Bayesian Tomography", "comments": "25 pages, quite a lot of figures, two videos, a tutorial, and a\n  partridge in a pear tree", "journal-ref": "New J. Phys. 18, 033024 (2016)", "doi": "10.1088/1367-2630/18/3/033024", "report-no": null, "categories": "quant-ph physics.data-an stat.AP", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In recent years, Bayesian methods have been proposed as a solution to a wide\nrange of issues in quantum state and process tomography. State-of-the-art\nBayesian tomography solutions suffer from three problems: numerical\nintractability, a lack of informative prior distributions, and an inability to\ntrack time-dependent processes. Here, we address all three problems. First, we\nuse modern statistical methods, as pioneered by Husz\\'ar and Houlsby and by\nFerrie, to make Bayesian tomography numerically tractable. Our approach allows\nfor practical computation of Bayesian point and region estimators for quantum\nstates and channels. Second, we propose the first priors on quantum states and\nchannels that allow for including useful experimental insight. Finally, we\ndevelop a method that allows tracking of time-dependent states and estimates\nthe drift and diffusion processes affecting a state. We provide source code and\nanimated visual examples for our methods.\n", "versions": [{"version": "v1", "created": "Sat, 12 Sep 2015 19:34:31 GMT"}, {"version": "v2", "created": "Wed, 11 May 2016 05:52:08 GMT"}], "update_date": "2016-05-12", "authors_parsed": [["Granade", "Christopher", ""], ["Combes", "Joshua", ""], ["Cory", "D. G.", ""]]}, {"id": "1509.03860", "submitter": "Peng Ding", "authors": "Wang Miao, Peng Ding, and Zhi Geng", "title": "Identifiability of Normal and Normal Mixture Models With Nonignorable\n  Missing Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Missing data problems arise in many applied research studies. They may\njeopardize statistical inference of the model of interest, if the missing\nmechanism is nonignorable, that is, the missing mechanism depends on the\nmissing values themselves even conditional on the observed data. With a\nnonignorable missing mechanism, the model of interest is often not identifiable\nwithout imposing further assumptions. We find that even if the missing\nmechanism has a known parametric form, the model is not identifiable without\nspecifying a parametric outcome distribution. Although it is fundamental for\nvalid statistical inference, identifiability under nonignorable missing\nmechanisms is not established for many commonly-used models. In this paper, we\nfirst demonstrate identifiability of the normal distribution under monotone\nmissing mechanisms. We then extend it to the normal mixture and $t$ mixture\nmodels with non-monotone missing mechanisms. We discover that models under the\nLogistic missing mechanism are less identifiable than those under the Probit\nmissing mechanism. We give necessary and sufficient conditions for\nidentifiability of models under the Logistic missing mechanism, which sometimes\ncan be checked in real data analysis. We illustrate our methods using a series\nof simulations, and apply them to a real-life dataset.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2015 15:34:26 GMT"}], "update_date": "2015-09-15", "authors_parsed": [["Miao", "Wang", ""], ["Ding", "Peng", ""], ["Geng", "Zhi", ""]]}, {"id": "1509.03938", "submitter": "Yiyuan She", "authors": "Yiyuan She and Kun Chen", "title": "Robust Reduced Rank Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.AP stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In high-dimensional multivariate regression problems, enforcing low rank in\nthe coefficient matrix offers effective dimension reduction, which greatly\nfacilitates parameter estimation and model interpretation. However,\ncommonly-used reduced-rank methods are sensitive to data corruption, as the\nlow-rank dependence structure between response variables and predictors is\neasily distorted by outliers. We propose a robust reduced-rank regression\napproach for joint modeling and outlier detection. The problem is formulated as\na regularized multivariate regression with a sparse mean-shift parametrization,\nwhich generalizes and unifies some popular robust multivariate methods. An\nefficient thresholding-based iterative procedure is developed for optimization.\nWe show that the algorithm is guaranteed to converge, and the coordinatewise\nminimum point produced is statistically accurate under regularity conditions.\nOur theoretical investigations focus on nonasymptotic robust analysis, which\ndemonstrates that joint rank reduction and outlier detection leads to improved\nprediction accuracy. In particular, we show that redescending $\\psi$-functions\ncan essentially attain the minimax optimal error rate, and in some less\nchallenging problems convex regularization guarantees the same low error rate.\nThe performance of the proposed method is examined by simulation studies and\nreal data examples.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2015 03:09:04 GMT"}, {"version": "v2", "created": "Sat, 19 Nov 2016 04:35:58 GMT"}, {"version": "v3", "created": "Sat, 1 Apr 2017 20:06:39 GMT"}, {"version": "v4", "created": "Thu, 13 Apr 2017 16:54:31 GMT"}, {"version": "v5", "created": "Sat, 15 Jul 2017 09:52:38 GMT"}], "update_date": "2017-07-18", "authors_parsed": [["She", "Yiyuan", ""], ["Chen", "Kun", ""]]}, {"id": "1509.03940", "submitter": "Matt Taddy", "authors": "Vadim von Brzeski, Matt Taddy, David Draper", "title": "Causal Inference in Repeated Observational Studies: A Case Study of eBay\n  Product Releases", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal inference in observational studies is notoriously difficult, due to\nthe fact that the experimenter is not in charge of the treatment assignment\nmechanism. Many potential con- founding factors (PCFs) exist in such a\nscenario, and if one seeks to estimate the causal effect of the treatment on a\nresponse, one needs to control for such factors. Identifying all relevant PCFs\nmay be difficult (or impossible) given a single observational study. Instead,\nwe argue that if one can observe a sequence of similar treatments over the\ncourse of a lengthy time period, one can identify patterns of behavior in the\nexperimental subjects that are correlated with the response of interest and\ncontrol for those patterns directly. Specifically, in our case-study we find\nand control for an early-adopter effect: the scenario in which the magnitude of\nthe response is highly correlated with how quickly one adopts a treatment after\nits release.\n  We provide a flexible hierarchical Bayesian framework that controls for such\nearly-adopter effects in the analysis of the effects of multiple sequential\ntreatments. The methods are presented and evaluated in the context of a\ndetailed case-study involving product updates (newer versions of the same\nproduct) from eBay, Inc. The users in our study upgrade (or not) to a new\nversion of the product at their own volition and timing. Our response variable\nis a measure of user actions, and we study the behavior of a large set of users\n(n = 10.5 million) in a targeted subset of eBay categories over a period of one\nyear. We find that (a) naive causal estimates are hugely misleading and (b) our\nmethod, which is relatively insensitive to modeling assumptions and exhibits\ngood out-of-sample predictive validation, yields sensible causal estimates that\noffer eBay a stable basis for decision-making.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2015 03:11:40 GMT"}], "update_date": "2015-09-15", "authors_parsed": [["von Brzeski", "Vadim", ""], ["Taddy", "Matt", ""], ["Draper", "David", ""]]}, {"id": "1509.04017", "submitter": "Jiahan Li", "authors": "Jiahan Li, Zhong Wang, Runze Li, Rongling Wu", "title": "Bayesian group Lasso for nonparametric varying-coefficient models with\n  application to functional genome-wide association studies", "comments": "Published at http://dx.doi.org/10.1214/15-AOAS808 in the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2015, Vol. 9, No. 2, 640-664", "doi": "10.1214/15-AOAS808", "report-no": "IMS-AOAS-AOAS808", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although genome-wide association studies (GWAS) have proven powerful for\ncomprehending the genetic architecture of complex traits, they are challenged\nby a high dimension of single-nucleotide polymorphisms (SNPs) as predictors,\nthe presence of complex environmental factors, and longitudinal or functional\nnatures of many complex traits or diseases. To address these challenges, we\npropose a high-dimensional varying-coefficient model for incorporating\nfunctional aspects of phenotypic traits into GWAS to formulate a so-called\nfunctional GWAS or fGWAS. The Bayesian group lasso and the associated MCMC\nalgorithms are developed to identify significant SNPs and estimate how they\naffect longitudinal traits through time-varying genetic actions. The model is\ngeneralized to analyze the genetic control of complex traits using\nsubject-specific sparse longitudinal data. The statistical properties of the\nnew model are investigated through simulation studies. We use the new model to\nanalyze a real GWAS data set from the Framingham Heart Study, leading to the\nidentification of several significant SNPs associated with age-specific changes\nof body mass index. The fGWAS model, equipped with the Bayesian group lasso,\nwill provide a useful tool for genetic and developmental analysis of complex\ntraits or diseases.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2015 10:19:04 GMT"}], "update_date": "2015-09-15", "authors_parsed": [["Li", "Jiahan", ""], ["Wang", "Zhong", ""], ["Li", "Runze", ""], ["Wu", "Rongling", ""]]}, {"id": "1509.04026", "submitter": "Peter M\\\"{u}ller", "authors": "Juhee Lee, Peter M\\\"uller, Kamalakar Gulukota, Yuan Ji", "title": "A Bayesian feature allocation model for tumor heterogeneity", "comments": "Published at http://dx.doi.org/10.1214/15-AOAS817 in the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2015, Vol. 9, No. 2, 621-639", "doi": "10.1214/15-AOAS817", "report-no": "IMS-AOAS-AOAS817", "categories": "stat.AP q-bio.GN q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a feature allocation model for inference on genetic tumor\nvariation using next-generation sequencing data. Specifically, we record single\nnucleotide variants (SNVs) based on short reads mapped to human reference\ngenome and characterize tumor heterogeneity by latent haplotypes defined as a\nscaffold of SNVs on the same homologous genome. For multiple samples from a\nsingle tumor, assuming that each sample is composed of some sample-specific\nproportions of these haplotypes, we then fit the observed variant allele\nfractions of SNVs for each sample and estimate the proportions of haplotypes.\nVarying proportions of haplotypes across samples is evidence of tumor\nheterogeneity since it implies varying composition of cell subpopulations.\nTaking a Bayesian perspective, we proceed with a prior probability model for\nall relevant unknown quantities, including, in particular, a prior probability\nmodel on the binary indicators that characterize the latent haplotypes. Such\nprior models are known as feature allocation models. Specifically, we define a\nsimplified version of the Indian buffet process, one of the most traditional\nfeature allocation models. The proposed model allows overlapping clustering of\nSNVs in defining latent haplotypes, which reflects the evolutionary process of\nsubclonal expansion in tumor samples.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2015 10:36:09 GMT"}], "update_date": "2015-09-15", "authors_parsed": [["Lee", "Juhee", ""], ["M\u00fcller", "Peter", ""], ["Gulukota", "Kamalakar", ""], ["Ji", "Yuan", ""]]}, {"id": "1509.04069", "submitter": "Fan Li", "authors": "Fan Li, Tingting Zhang, Quanli Wang, Marlen Z. Gonzalez, Erin L.\n  Maresh, James A. Coan", "title": "Spatial Bayesian variable selection and grouping for high-dimensional\n  scalar-on-image regression", "comments": "Published at http://dx.doi.org/10.1214/15-AOAS818 in the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2015, Vol. 9, No. 2, 687-713", "doi": "10.1214/15-AOAS818", "report-no": "IMS-AOAS-AOAS818", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-subject functional magnetic resonance imaging (fMRI) data has been\nincreasingly used to study the population-wide relationship between human brain\nactivity and individual biological or behavioral traits. A common method is to\nregress the scalar individual response on imaging predictors, known as a\nscalar-on-image (SI) regression. Analysis and computation of such massive and\nnoisy data with complex spatio-temporal correlation structure is challenging.\nIn this article, motivated by a psychological study on human affective feelings\nusing fMRI, we propose a joint Ising and Dirichlet Process (Ising-DP) prior\nwithin the framework of Bayesian stochastic search variable selection for\nselecting brain voxels in high-dimensional SI regressions. The Ising component\nof the prior makes use of the spatial information between voxels, and the DP\ncomponent groups the coefficients of the large number of voxels to a small set\nof values and thus greatly reduces the posterior computational burden. To\naddress the phase transition phenomenon of the Ising prior, we propose a new\nanalytic approach to derive bounds for the hyperparameters, illustrated on 2-\nand 3-dimensional lattices. The proposed method is compared with several\nalternative methods via simulations, and is applied to the fMRI data collected\nfrom the KLIFF hand-holding experiment.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2015 12:56:23 GMT"}], "update_date": "2015-09-15", "authors_parsed": [["Li", "Fan", ""], ["Zhang", "Tingting", ""], ["Wang", "Quanli", ""], ["Gonzalez", "Marlen Z.", ""], ["Maresh", "Erin L.", ""], ["Coan", "James A.", ""]]}, {"id": "1509.04080", "submitter": "Xiangdong Gu", "authors": "Xiangdong Gu, Yunsheng Ma, Raji Balasubramanian", "title": "Semiparametric time to event models in the presence of error-prone,\n  self-reported outcomes - With application to the women's health initiative", "comments": "Published at http://dx.doi.org/10.1214/15-AOAS810 in the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2015, Vol. 9, No. 2, 714-730", "doi": "10.1214/15-AOAS810", "report-no": "IMS-AOAS-AOAS810", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The onset of several silent, chronic diseases such as diabetes can be\ndetected only through diagnostic tests. Due to cost considerations,\nself-reported outcomes are routinely collected in lieu of expensive diagnostic\ntests in large-scale prospective investigations such as the Women's Health\nInitiative. However, self-reported outcomes are subject to imperfect\nsensitivity and specificity. Using a semiparametric likelihood-based approach,\nwe present time to event models to estimate the association of one or more\ncovariates with a error-prone, self-reported outcome. We present simulation\nstudies to assess the effect of error in self-reported outcomes with regard to\nbias in the estimation of the regression parameter of interest. We apply the\nproposed methods to prospective data from 152,830 women enrolled in the Women's\nHealth Initiative to evaluate the effect of statin use with the risk of\nincident diabetes mellitus among postmenopausal women. The current analysis is\nbased on follow-up through 2010, with a median duration of follow-up of 12.1\nyears. The methods proposed in this paper are readily implemented using our\nfreely available R software package icensmis, which is available at the\nComprehensive R Archive Network (CRAN) website.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2015 13:17:37 GMT"}], "update_date": "2015-09-15", "authors_parsed": [["Gu", "Xiangdong", ""], ["Ma", "Yunsheng", ""], ["Balasubramanian", "Raji", ""]]}, {"id": "1509.04486", "submitter": "Isabel Moreno-S\\'anchez", "authors": "Isabel Moreno-S\\'anchez, Francesc Font-Clos, \\'Alvaro Corral", "title": "Large-scale analysis of Zipf's law in English texts", "comments": null, "journal-ref": null, "doi": "10.1371/journal.pone.0147073", "report-no": null, "categories": "stat.AP physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite being a paradigm of quantitative linguistics, Zipf's law for words\nsuffers from three main problems: its formulation is ambiguous, its validity\nhas not been tested rigorously from a statistical point of view, and it has not\nbeen confronted to a representatively large number of texts. So, we can\nsummarize the current support of Zipf's law in texts as anecdotic.\n  We try to solve these issues by studying three different versions of Zipf's\nlaw and fitting them to all available English texts in the Project Gutenberg\ndatabase (consisting of more than 30000 texts). To do so we use state-of-the\nart tools in fitting and goodness-of-fit tests, carefully tailored to the\npeculiarities of text statistics. Remarkably, one of the three versions of\nZipf's law, consisting of a pure power-law form in the complementary cumulative\ndistribution function of word frequencies, is able to fit more than 40% of the\ntexts in the database (at the 0.05 significance level), for the whole domain of\nfrequencies (from 1 to the maximum value) and with only one free parameter (the\nexponent).\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2015 10:41:03 GMT"}], "update_date": "2016-02-17", "authors_parsed": [["Moreno-S\u00e1nchez", "Isabel", ""], ["Font-Clos", "Francesc", ""], ["Corral", "\u00c1lvaro", ""]]}, {"id": "1509.04602", "submitter": "Aristides Moustakas", "authors": "Aristides Moustakas and Matthew R. Evans", "title": "Regional and temporal characteristics of bovine tuberculosis of cattle\n  in Great Britain", "comments": "(in press) Stochastic Environmental Research and Risk Assessment\n  (2015)", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bovine tuberculosis (TB) is a chronic disease in cattle that causes a serious\nfood security challenge to the agricultural industry in terms of dairy and meat\nproduction. In GB, Scotland has had a risk based surveillance testing policy\nunder which high risk herds are tested frequently, and in Sept 2009 was\nofficially declared as TB free. Wales have had an annual or more frequent\ntesting policy for all cattle herds since Jan 2010, while in England several\nherds are still tested every 4 years except some high TB prevalence areas where\nannual testing is applied. Time series analysis using publicly available data\nfor total tests on herds, total cattle slaughtered, new herd incidents, and\nherds not TB free, were analysed globally for GB and locally for the\nconstituent regions of Wales, Scotland, West, North, and East England. After\ndetecting trends over time, underlying regional differences were compared with\nthe testing policies in the region. Total cattle slaughtered are decreasing in\nWales, Scotland and West England, but increasing in the North and East English\nregions. New herd incidents, i.e., disease incidence, are decreasing in Wales,\nScotland, West English region, but increasing in North and East English\nregions. Herds not TB free, are increasing in West, North, and East English\nregions, while they are decreasing in Wales and Scotland. Total cattle\nslaughtered were positively correlated with total tests in the West, North, and\nEast English regions, with high slopes of regression. There was no correlation\nbetween total cattle slaughtered and total tests on herds in Wales indicating\nthat herds are tested frequent enough in order to detect all likely cases and\nso control TB. The main conclusion of the analysis conducted here is that more\nfrequent testing is leading to lower TB infections in cattle both in terms of\nTB prevalence as well as TB incidence.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2015 15:29:41 GMT"}], "update_date": "2015-09-16", "authors_parsed": [["Moustakas", "Aristides", ""], ["Evans", "Matthew R.", ""]]}, {"id": "1509.04824", "submitter": "Jonathan S. Schildcrout", "authors": "Jonathan S. Schildcrout, Paul J. Rathouz, Leila R. Zelnick, Shawn P.\n  Garbett, Patrick J. Heagerty", "title": "Biased sampling designs to improve research efficiency: Factors\n  influencing pulmonary function over time in children with asthma", "comments": "Published at http://dx.doi.org/10.1214/15-AOAS826 in the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2015, Vol. 9, No. 2, 731-753", "doi": "10.1214/15-AOAS826", "report-no": "IMS-AOAS-AOAS826", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Substudies of the Childhood Asthma Management Program [Control. Clin. Trials\n20 (1999) 91-120; N. Engl. J. Med. 343 (2000) 1054-1063] seek to identify\npatient characteristics associated with asthma symptoms and lung function. To\ndetermine if genetic measures are associated with trajectories of lung function\nas measured by forced vital capacity (FVC), children in the primary cohort\nstudy retrospectively had candidate loci evaluated. Given participant burden\nand constraints on financial resources, it is often desirable to target a\nsubsample for ascertainment of costly measures. Methods that can leverage the\nlongitudinal outcome on the full cohort to selectively measure informative\nindividuals have been promising, but have been restricted in their use to\nanalysis of the targeted subsample. In this paper we detail two multiple\nimputation analysis strategies that exploit outcome and partially observed\ncovariate data on the nonsampled subjects, and we characterize alternative\ndesign and analysis combinations that could be used for future studies of\npulmonary function and other outcomes. Candidate predictor (e.g., IL10 cytokine\npolymorphisms) associations obtained from targeted sampling designs can be\nestimated with very high efficiency compared to standard designs. Further, even\nthough multiple imputation can dramatically improve estimation efficiency for\ncovariates available on all subjects (e.g., gender and baseline age),\nrelatively modest efficiency gains were observed in parameters associated with\npredictors that are exclusive to the targeted sample. Our results suggest that\nfuture studies of longitudinal trajectories can be efficiently conducted by use\nof outcome-dependent designs and associated full cohort analysis.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2015 06:44:18 GMT"}], "update_date": "2015-09-17", "authors_parsed": [["Schildcrout", "Jonathan S.", ""], ["Rathouz", "Paul J.", ""], ["Zelnick", "Leila R.", ""], ["Garbett", "Shawn P.", ""], ["Heagerty", "Patrick J.", ""]]}, {"id": "1509.04828", "submitter": "Jian Guo", "authors": "Jian Guo, Jie Cheng, Elizaveta Levina, George Michailidis, Ji Zhu", "title": "Estimating heterogeneous graphical models for discrete data with an\n  application to roll call voting", "comments": "Published at http://dx.doi.org/10.1214/13-AOAS700 in the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2015, Vol. 9, No. 2, 821-848", "doi": "10.1214/13-AOAS700", "report-no": "IMS-AOAS-AOAS700", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of jointly estimating a collection of graphical\nmodels for discrete data, corresponding to several categories that share some\ncommon structure. An example for such a setting is voting records of\nlegislators on different issues, such as defense, energy, and healthcare. We\ndevelop a Markov graphical model to characterize the heterogeneous dependence\nstructures arising from such data. The model is fitted via a joint estimation\nmethod that preserves the underlying common graph structure, but also allows\nfor differences between the networks. The method employs a group penalty that\ntargets the common zero interaction effects across all the networks. We apply\nthe method to describe the internal networks of the U.S. Senate on several\nimportant issues. Our analysis reveals individual structure for each issue,\ndistinct from the underlying well-known bipartisan structure common to all\ncategories which we are able to extract separately. We also establish\nconsistency of the proposed method both for parameter estimation and model\nselection, and evaluate its numerical performance on a number of simulated\nexamples.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2015 07:02:07 GMT"}], "update_date": "2015-09-17", "authors_parsed": [["Guo", "Jian", ""], ["Cheng", "Jie", ""], ["Levina", "Elizaveta", ""], ["Michailidis", "George", ""], ["Zhu", "Ji", ""]]}, {"id": "1509.04831", "submitter": "John C. Jackson", "authors": "John C. Jackson, Paul S. Albert, Zhiwei Zhang", "title": "A two-state mixed hidden Markov model for risky teenage driving behavior", "comments": "Published at http://dx.doi.org/10.1214/14-AOAS765 in the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2015, Vol. 9, No. 2, 849-865", "doi": "10.1214/14-AOAS765", "report-no": "IMS-AOAS-AOAS765", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a joint model for longitudinal binary and count outcomes.\nWe apply the model to a unique longitudinal study of teen driving where risky\ndriving behavior and the occurrence of crashes or near crashes are measured\nprospectively over the first 18 months of licensure. Of scientific interest is\nrelating the two processes and predicting crash and near crash outcomes. We\npropose a two-state mixed hidden Markov model whereby the hidden state\ncharacterizes the mean for the joint longitudinal crash/near crash outcomes and\nelevated g-force events which are a proxy for risky driving. Heterogeneity is\nintroduced in both the conditional model for the count outcomes and the hidden\nprocess using a shared random effect. An estimation procedure is presented\nusing the forward-backward algorithm along with adaptive Gaussian quadrature to\nperform numerical integration. The estimation procedure readily yields hidden\nstate probabilities as well as providing for a broad class of predictors.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2015 07:11:13 GMT"}], "update_date": "2015-09-17", "authors_parsed": [["Jackson", "John C.", ""], ["Albert", "Paul S.", ""], ["Zhang", "Zhiwei", ""]]}, {"id": "1509.04834", "submitter": "Francis K. C. Hui", "authors": "Francis K. C. Hui, David I. Warton, Scott D. Foster", "title": "Multi-species distribution modeling using penalized mixture of\n  regressions", "comments": "Published at http://dx.doi.org/10.1214/15-AOAS813 in the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2015, Vol. 9, No. 2, 866-882", "doi": "10.1214/15-AOAS813", "report-no": "IMS-AOAS-AOAS813", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-species distribution modeling, which relates the occurrence of multiple\nspecies to environmental variables, is an important tool used by ecologists for\nboth predicting the distribution of species in a community and identifying the\nimportant variables driving species co-occurrences. Recently, Dunstan, Foster\nand Darnell [Ecol. Model. 222 (2011) 955-963] proposed using finite mixture of\nregression (FMR) models for multi-species distribution modeling, where species\nare clustered based on their environmental response to form a small number of\n\"archetypal responses.\" As an illustrative example, they applied their mixture\nmodel approach to a presence-absence data set of 200 marine organisms,\ncollected along the Great Barrier Reef in Australia. Little attention, however,\nwas given to the problem of model selection - since the archetypes (mixture\ncomponents) may depend on different but likely overlapping sets of covariates,\na method is needed for performing variable selection on all components\nsimultaneously. In this article, we consider using penalized likelihood\nfunctions for variable selection in FMR models. We propose two penalties which\nexploit the grouped structure of the covariates, that is, each covariate is\nrepresented by a group of coefficients, one for each component. This leads to\nan attractive form of shrinkage that allows a covariate to be removed from all\ncomponents simultaneously. Both penalties are shown to possess specific forms\nof variable selection consistency, with simulations indicating they outperform\nother methods which do not take into account the grouped structure. When\napplied to the Great Barrier Reef data set, penalized FMR models offer more\ninsight into the important variables driving species co-occurrence in the\nmarine community (compared to previous results where no model selection was\nconducted), while offering a computationally stable method of modeling complex\nspecies-environment relationships (through regularization).\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2015 07:18:01 GMT"}], "update_date": "2015-09-17", "authors_parsed": [["Hui", "Francis K. C.", ""], ["Warton", "David I.", ""], ["Foster", "Scott D.", ""]]}, {"id": "1509.04836", "submitter": "Yicheng Kang", "authors": "Yicheng Kang, Xiaodong Gong, Jiti Gao, Peihua Qiu", "title": "Jump detection in generalized error-in-variables regression with an\n  application to Australian health tax policies", "comments": "Published at http://dx.doi.org/10.1214/15-AOAS814 in the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2015, Vol. 9, No. 2, 883-900", "doi": "10.1214/15-AOAS814", "report-no": "IMS-AOAS-AOAS814", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Without measurement errors in predictors, discontinuity of a nonparametric\nregression function at unknown locations could be estimated using a number of\nexisting approaches. However, it becomes a challenging problem when the\npredictors contain measurement errors. In this paper, an error-in-variables\njump point estimator is suggested for a nonparametric generalized\nerror-in-variables regression model. A major feature of our method is that it\ndoes not impose any parametric distribution on the measurement error. Its\nperformance is evaluated by both numerical studies and theoretical\njustifications. The method is applied to studying the impact of Medicare Levy\nSurcharge on the private health insurance take-up rate in Australia.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2015 07:25:07 GMT"}], "update_date": "2015-09-17", "authors_parsed": [["Kang", "Yicheng", ""], ["Gong", "Xiaodong", ""], ["Gao", "Jiti", ""], ["Qiu", "Peihua", ""]]}, {"id": "1509.04838", "submitter": "Shiqi Cui", "authors": "Shiqi Cui, Subharup Guha, Marco A. R. Ferreira, Allison N. Tegge", "title": "hmmSeq: A hidden Markov model for detecting differentially expressed\n  genes from RNA-seq data", "comments": "Published at http://dx.doi.org/10.1214/15-AOAS815 in the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2015, Vol. 9, No. 2, 901-925", "doi": "10.1214/15-AOAS815", "report-no": "IMS-AOAS-AOAS815", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce hmmSeq, a model-based hierarchical Bayesian technique for\ndetecting differentially expressed genes from RNA-seq data. Our novel hmmSeq\nmethodology uses hidden Markov models to account for potential co-expression of\nneighboring genes. In addition, hmmSeq employs an integrated approach to\nstudies with technical or biological replicates, automatically adjusting for\nany extra-Poisson variability. Moreover, for cases when paired data are\navailable, hmmSeq includes a paired structure between treatments that\nincoporates subject-specific effects. To perform parameter estimation for the\nhmmSeq model, we develop an efficient Markov chain Monte Carlo algorithm.\nFurther, we develop a procedure for detection of differentially expressed genes\nthat automatically controls false discovery rate. A simulation study shows that\nthe hmmSeq methodology performs better than competitors in terms of receiver\noperating characteristic curves. Finally, the analyses of three publicly\navailable RNA-seq data sets demonstrate the power and flexibility of the hmmSeq\nmethodology. An R package implementing the hmmSeq framework will be submitted\nto CRAN upon publication of the manuscript.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2015 07:30:55 GMT"}], "update_date": "2015-09-17", "authors_parsed": [["Cui", "Shiqi", ""], ["Guha", "Subharup", ""], ["Ferreira", "Marco A. R.", ""], ["Tegge", "Allison N.", ""]]}, {"id": "1509.04841", "submitter": "Vasileios Maroulas", "authors": "Vasileios Maroulas, Andreas Nebenf\\\"uhr", "title": "Tracking rapid intracellular movements: A Bayesian random set approach", "comments": "Published at http://dx.doi.org/10.1214/15-AOAS819 in the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2015, Vol. 9, No. 2, 926-949", "doi": "10.1214/15-AOAS819", "report-no": "IMS-AOAS-AOAS819", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We focus on the biological problem of tracking organelles as they move\nthrough cells. In the past, most intracellular movements were recorded\nmanually, however, the results are too incomplete to capture the full\ncomplexity of organelle motions. An automated tracking algorithm promises to\nprovide a complete analysis of noisy microscopy data. In this paper, we adopt\nstatistical techniques from a Bayesian random set point of view. Instead of\nconsidering each individual organelle, we examine a random set whose members\nare the organelle states and we establish a Bayesian filtering algorithm\ninvolving such set states. The propagated multi-object densities are\napproximated using a Gaussian mixture scheme. Our algorithm is applied to\nsynthetic and experimental data.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2015 07:40:43 GMT"}], "update_date": "2015-09-17", "authors_parsed": [["Maroulas", "Vasileios", ""], ["Nebenf\u00fchr", "Andreas", ""]]}, {"id": "1509.04857", "submitter": "Bal\\'azs Gerencs\\'er", "authors": "Corentin Vande Kerckhove, Bal\\'azs Gerencs\\'er, Julien M. Hendrickx,\n  Vincent D. Blondel", "title": "Markov modeling of online inter-arrival times", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.SI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the arising communication patterns on social\nmedia, and in particular the series of events happening for a single user.\nWhile the distribution of inter-event times is often assimilated to power-law\ndensity functions, a debate persists on the nature of an underlying model that\nexplains the observed distribution. In the present, we propose an intuitive\nexplanation to understand the observed dependence of subsequent waiting times.\nOur contribution is twofold. The first idea consists of separating the short\nwaiting times -- out of scope for power-law distributions -- from the long\nones. The model is further enhanced by introducing a two-state Markovian\nprocess to incorporate memory.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2015 09:16:20 GMT"}, {"version": "v2", "created": "Tue, 16 May 2017 17:21:07 GMT"}, {"version": "v3", "created": "Fri, 7 Dec 2018 16:07:14 GMT"}], "update_date": "2018-12-10", "authors_parsed": [["Kerckhove", "Corentin Vande", ""], ["Gerencs\u00e9r", "Bal\u00e1zs", ""], ["Hendrickx", "Julien M.", ""], ["Blondel", "Vincent D.", ""]]}, {"id": "1509.04872", "submitter": "Jie Hu", "authors": "Jie Hu, Zhongying Zhao, Hari Krishna Yalamanchili, Junwen Wang, Kenny\n  Ye, Xiaodan Fan", "title": "Bayesian detection of embryonic gene expression onset in C. elegans", "comments": "Published at http://dx.doi.org/10.1214/15-AOAS820 in the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2015, Vol. 9, No. 2, 950-968", "doi": "10.1214/15-AOAS820", "report-no": "IMS-AOAS-AOAS820", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To study how a zygote develops into an embryo with different tissues,\nlarge-scale 4D confocal movies of C. elegans embryos have been produced\nrecently by experimental biologists. However, the lack of principled\nstatistical methods for the highly noisy data has hindered the comprehensive\nanalysis of these data sets. We introduced a probabilistic change point model\non the cell lineage tree to estimate the embryonic gene expression onset time.\nA Bayesian approach is used to fit the 4D confocal movies data to the model.\nSubsequent classification methods are used to decide a model selection\nthreshold and further refine the expression onset time from the branch level to\nthe specific cell time level. Extensive simulations have shown the high\naccuracy of our method. Its application on real data yields both previously\nknown results and new findings.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2015 10:18:31 GMT"}], "update_date": "2015-09-17", "authors_parsed": [["Hu", "Jie", ""], ["Zhao", "Zhongying", ""], ["Yalamanchili", "Hari Krishna", ""], ["Wang", "Junwen", ""], ["Ye", "Kenny", ""], ["Fan", "Xiaodan", ""]]}, {"id": "1509.04889", "submitter": "Makram Talih", "authors": "Makram Talih", "title": "Examining socioeconomic health disparities using a rank-dependent\n  R\\'{e}nyi index", "comments": "Published at http://dx.doi.org/10.1214/15-AOAS822 in the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2015, Vol. 9, No. 2, 992-1023", "doi": "10.1214/15-AOAS822", "report-no": "IMS-AOAS-AOAS822", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The R\\'{e}nyi index (RI) is a one-parameter class of indices that summarize\nhealth disparities among population groups by measuring divergence between the\ndistributions of disease burden and population shares of these groups. The\nrank-dependent RI introduced in this paper is a two-parameter class of health\ndisparity indices that also accounts for the association between socioeconomic\nrank and health; it may be derived from a rank-dependent social welfare\nfunction. Two competing classes are discussed and the rank-dependent RI is\nshown to be more robust to changes in the distribution of either socioeconomic\nrank or health. The standard error and sampling distribution of the\nrank-dependent RI are evaluated using linearization and resampling techniques,\nand the methodology is illustrated using health survey data from the U.S.\nNational Health and Nutrition Examination Survey and registry data from the\nU.S. Surveillance, Epidemiology and End Results Program. Such data underlie\nmany population-based objectives within the U.S. Healthy People 2020\ninitiative. The rank-dependent RI provides a unified mathematical framework for\neliciting various societal positions with regards to the policies that are tied\nto such wide-reaching public health initiatives. For example, if population\ngroups with lower socioeconomic position were ascertained to be more likely to\nutilize costly public programs, then the parameters of the RI could be selected\nto reflect prioritizing those population groups for intervention or treatment.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2015 11:25:35 GMT"}], "update_date": "2015-09-17", "authors_parsed": [["Talih", "Makram", ""]]}, {"id": "1509.04897", "submitter": "Kevin K. Dobbin", "authors": "Sandra Safo, Xiao Song, Kevin K. Dobbin", "title": "Sample size determination for training cancer classifiers from\n  microarray and RNA-seq data", "comments": "Published at http://dx.doi.org/10.1214/15-AOAS825 in the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2015, Vol. 9, No. 2, 1053-1075", "doi": "10.1214/15-AOAS825", "report-no": "IMS-AOAS-AOAS825", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The objective of many high-dimensional microarray and RNA-seq studies is to\ndevelop a classifier of cancer patients based on characteristics of their\ndisease. The germinal center B-cell (GCB) classifier study in lymphoma and the\nNational Cancer Institute's Director's Challenge lung (DC-lung) study are two\nexamples. In recent years, such classifiers are often developed using\nregularized regression, such as the lasso. A critical question is whether a\nbetter classifier can be developed from a larger training set size and, if so,\nhow large the training set should be. This paper examines these two questions\nusing an existing sample size method and a novel sample size method developed\nhere specifically for lasso logistic regression. Both methods are based on\npilot data. We reexamine the lymphoma and lung cancer data sets to evaluate the\nsample sizes, and use resampling to assess the estimation methods. We also\nstudy application to an RNA-seq data set. We find that it is feasible to\nestimate sample size for regularized logistic regression if an adequate pilot\ndata set exists. The GCB and the DC-lung data sets appear adequate, under\nspecific assumptions. Existing human RNA-seq data sets are by and large\ninadequate, and cannot be used as pilot data. Pilot RNA-seq data can be\nsimulated, and the methods in this paper can be used for sample size\nestimation. A MATLAB program is made available.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2015 12:10:11 GMT"}], "update_date": "2015-09-17", "authors_parsed": [["Safo", "Sandra", ""], ["Song", "Xiao", ""], ["Dobbin", "Kevin K.", ""]]}, {"id": "1509.04903", "submitter": "Philip T. Reiss", "authors": "Philip T. Reiss, Lan Huo, Yihong Zhao, Clare Kelly, R. Todd Ogden", "title": "Wavelet-domain regression and predictive inference in psychiatric\n  neuroimaging", "comments": "Published at http://dx.doi.org/10.1214/15-AOAS829 in the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2015, Vol. 9, No. 2, 1076-1101", "doi": "10.1214/15-AOAS829", "report-no": "IMS-AOAS-AOAS829", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An increasingly important goal of psychiatry is the use of brain imaging data\nto develop predictive models. Here we present two contributions to statistical\nmethodology for this purpose. First, we propose and compare a set of\nwavelet-domain procedures for fitting generalized linear models with scalar\nresponses and image predictors: sparse variants of principal component\nregression and of partial least squares, and the elastic net. Second, we\nconsider assessing the contribution of image predictors over and above\navailable scalar predictors, in particular, via permutation tests and an\nextension of the idea of confounding to the case of functional or image\npredictors. Using the proposed methods, we assess whether maps of a spontaneous\nbrain activity measure, derived from functional magnetic resonance imaging, can\nmeaningfully predict presence or absence of attention deficit/hyperactivity\ndisorder (ADHD). Our results shed light on the role of confounding in the\nsurprising outcome of the recent ADHD-200 Global Competition, which challenged\nresearchers to develop algorithms for automated image-based diagnosis of the\ndisorder.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2015 12:36:43 GMT"}], "update_date": "2015-09-17", "authors_parsed": [["Reiss", "Philip T.", ""], ["Huo", "Lan", ""], ["Zhao", "Yihong", ""], ["Kelly", "Clare", ""], ["Ogden", "R. Todd", ""]]}, {"id": "1509.04984", "submitter": "Edmilson Rodrigues Pinto Dr.", "authors": "Edmilson Rodrigues Pinto, Leandro Alves Pereira and Aur\\'elia\n  Aparecida de Ara\\'ujo Rodrigues", "title": "On modeling of variability in mixture experiments with noise variables", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In mixture experiments with noise variables or process variables that can not\nbe controlled, investigate and try to control the variability of the response\nvariable is very important for quality improvement in industrial processes.\nThus, modeling the variability in mixture experiments with noise variables\nbecomes necessary and has been considered in literature with approaches that\nrequire the choice of a quadratic loss function or by using the delta method.\nIn this paper, we make use of the delta method and also propose an alternative\napproach, which is based on the Joint Modeling of Mean and Dispersion (JMMD).\nWe consider a mixture experiment involving noise variables and we use the\ntechniques of JMMD and of the delta method to get models for both mean and\nvariance of the response variable. Following the Taguchi's ideas about robust\nparameter design we build and solve an optimization problem for minimizing the\nvariance while holding the mean on the target. At the end we provide a\ndiscussion about the two methodologies considered.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2015 17:51:06 GMT"}], "update_date": "2015-09-17", "authors_parsed": [["Pinto", "Edmilson Rodrigues", ""], ["Pereira", "Leandro Alves", ""], ["Rodrigues", "Aur\u00e9lia Aparecida de Ara\u00fajo", ""]]}, {"id": "1509.05024", "submitter": "Valery Vilisov", "authors": "Valery Vilisov", "title": "Modeling Concordances of Company's Investment Directions With Its Market\n  Attraction", "comments": null, "journal-ref": null, "doi": "10.13140/RG.2.1.1707.8248", "report-no": null, "categories": "q-fin.PM cs.CY stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work models the interconnection of company's investment managers'\nrepresentations and the market attraction of its shares. The models that\nreflect the connection of the company's market effectiveness indices and\nparameters of its economic activity are created on the basis of the\nMean-Variance Analysis and Regression Analysis. On another side, expert\nevaluation methods also clarified the same influence parameters, but it was\nmade according to the opinion of company managers. These two evaluation rows\nare used when making managerial decisions.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2015 16:55:45 GMT"}], "update_date": "2015-09-17", "authors_parsed": [["Vilisov", "Valery", ""]]}, {"id": "1509.05121", "submitter": "Irineo Cabreros", "authors": "Irineo Cabreros, Emmanuel Abbe and Aristotelis Tsirigos", "title": "Detecting Community Structures in Hi-C Genomic Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.SI stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Community detection (CD) algorithms are applied to Hi-C data to discover new\ncommunities of loci in the 3D conformation of human and mouse DNA. We find that\nCD has some distinct advantages over pre-existing methods: (1) it is capable of\nfinding a variable number of communities, (2) it can detect communities of DNA\nloci either adjacent or distant in the 1D sequence, and (3) it allows us to\nobtain a principled value of k, the number of communities present. Forcing k =\n2, our method recovers earlier findings of Lieberman-Aiden, et al. (2009), but\nletting k be a parameter, our method obtains as optimal value k = 6,\ndiscovering new candidate communities. In addition to discovering large\ncommunities that partition entire chromosomes, we also show that CD can detect\nsmall-scale topologically associating domains (TADs) such as those found in\nDixon, et al. (2012). CD thus provides a natural and flexible statistical\nframework for understanding the folding structure of DNA at multiple scales in\nHi-C data.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2015 04:23:55 GMT"}], "update_date": "2015-09-18", "authors_parsed": [["Cabreros", "Irineo", ""], ["Abbe", "Emmanuel", ""], ["Tsirigos", "Aristotelis", ""]]}, {"id": "1509.05224", "submitter": "Wenfei Zhang", "authors": "Wenfei Zhang, Ying Wei", "title": "Regression based principal component analysis for sparse functional data\n  with applications to screening growth paths", "comments": "Published at http://dx.doi.org/10.1214/15-AOAS811 in the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2015, Vol. 9, No. 2, 597-620", "doi": "10.1214/15-AOAS811", "report-no": "IMS-AOAS-AOAS811", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Growth charts are widely used in pediatric care for assessing childhood body\nsize measurements (e.g., height or weight). The existing growth charts screen\none body size at a single given age. However, when a child has multiple\nmeasures over time and exhibits a growth path, how to assess those measures\njointly in a rigorous and quantitative way remains largely undeveloped in the\nliterature. In this paper, we develop a new method to construct growth charts\nfor growth paths. A new estimation algorithm using alternating regressions is\ndeveloped to obtain principal component representations of growth paths (sparse\nfunctional data). The new algorithm does not rely on strong distribution\nassumptions and is computationally robust and easily incorporates subject level\ncovariates, such as parental information. Simulation studies are conducted to\ninvestigate the performance of our proposed method, including comparisons to\nexisting methods. When the proposed method is applied to monitor the puberty\ngrowth among a group of Finnish teens, it yields interesting insights.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2015 12:04:55 GMT"}], "update_date": "2015-09-18", "authors_parsed": [["Zhang", "Wenfei", ""], ["Wei", "Ying", ""]]}, {"id": "1509.05226", "submitter": "Beno\\^ite de Saporta", "authors": "Bernard Delyon, Beno\\^ite de Saporta, Nathalie Krell, Lydia Robert", "title": "Investigation of asymmetry in E. coli growth rate", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The data we analyze derives from the observation of numerous cells of the\nbacterium Escherichia coli (E. coli) growing and dividing. Single cells grow\nand divide to give birth to two daughter cells, that in turn grow and divide.\nThus, a colony of cells from a single ancestor is structured as a binary\ngenealogical tree. At each node the measured data is the growth rate of the\nbacterium. In this paper, we study two different data sets. One set corresponds\nto small complete trees, whereas the other one corresponds to long specific\nsub-trees. Our aim is to compare both sets. This paper is accessible to post\ngraduate students and readers with advanced knowledge in statistics.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2015 12:05:31 GMT"}], "update_date": "2015-09-18", "authors_parsed": [["Delyon", "Bernard", ""], ["de Saporta", "Beno\u00eete", ""], ["Krell", "Nathalie", ""], ["Robert", "Lydia", ""]]}, {"id": "1509.05230", "submitter": "Nadja Klein", "authors": "Nadja Klein, Thomas Kneib, Stefan Lang, Alexander Sohn", "title": "Bayesian structured additive distributional regression with an\n  application to regional income inequality in Germany", "comments": "Published at http://dx.doi.org/10.1214/15-AOAS823 in the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2015, Vol. 9, No. 2, 1024-1052", "doi": "10.1214/15-AOAS823", "report-no": "IMS-AOAS-AOAS823", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a generic Bayesian framework for inference in distributional\nregression models in which each parameter of a potentially complex response\ndistribution and not only the mean is related to a structured additive\npredictor. The latter is composed additively of a variety of different\nfunctional effect types such as nonlinear effects, spatial effects, random\ncoefficients, interaction surfaces or other (possibly nonstandard) basis\nfunction representations. To enforce specific properties of the functional\neffects such as smoothness, informative multivariate Gaussian priors are\nassigned to the basis function coefficients. Inference can then be based on\ncomputationally efficient Markov chain Monte Carlo simulation techniques where\na generic procedure makes use of distribution-specific iteratively weighted\nleast squares approximations to the full conditionals. The framework of\ndistributional regression encompasses many special cases relevant for treating\nnonstandard response structures such as highly skewed nonnegative responses,\noverdispersed and zero-inflated counts or shares including the possibility for\nzero- and one-inflation. We discuss distributional regression along a study on\ndeterminants of labour incomes for full-time working males in Germany with a\nparticular focus on regional differences after the German reunification.\nControlling for age, education, work experience and local disparities, we\nestimate full conditional income distributions allowing us to study various\ndistributional quantities such as moments, quantiles or inequality measures in\na consistent manner in one joint model. Detailed guidance on practical aspects\nof model choice including the selection of several competing distributions for\nlabour incomes and the consideration of different covariate effects on the\nincome distribution complete the distributional regression analysis. We find\nthat next to a lower expected income, full-time working men in East Germany\nalso face a more unequal income distribution than men in the West, ceteris\nparibus.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2015 12:24:30 GMT"}], "update_date": "2015-09-18", "authors_parsed": [["Klein", "Nadja", ""], ["Kneib", "Thomas", ""], ["Lang", "Stefan", ""], ["Sohn", "Alexander", ""]]}, {"id": "1509.05326", "submitter": "Adria Caballe", "authors": "Adria Caballe, Natalia Bochkina, Claus Mayer", "title": "Selection of the Regularization Parameter in Graphical Models using\n  Network Characteristics", "comments": "32 pages, 6 figures, 16 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian graphical models represent the underlying graph structure of\nconditional dependence between random variables which can be determined using\ntheir partial correlation or precision matrix. In a high-dimensional setting,\nthe precision matrix is estimated using penalized likelihood by adding a\npenalization term which controls the amount of sparsity in the precision matrix\nand totally characterizes the complexity and structure of the graph. The most\ncommonly used penalization term is the L1 norm of the precision matrix scaled\nby the regularization parameter which determines the trade-off between sparsity\nof the graph and fit to the data. In this paper we propose several procedures\nto select the regularization parameter in the estimation of graphical models\nthat focus on recovering reliably the appropriate network structure of the\ngraph. We conduct an extensive simulation study to show that the proposed\nmethods produce useful results for different network topologies. The approaches\nare also applied in a high-dimensional real case study of gene expression data\nwith the aim to discover the genes relevant to colon cancer. Using this data,\nwe find graph structures which are verified to display significant biological\ngene associations.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2015 16:44:08 GMT"}, {"version": "v2", "created": "Mon, 23 May 2016 09:27:15 GMT"}], "update_date": "2016-05-24", "authors_parsed": [["Caballe", "Adria", ""], ["Bochkina", "Natalia", ""], ["Mayer", "Claus", ""]]}, {"id": "1509.05570", "submitter": "Sarah Friedrich", "authors": "Sarah Friedrich and Edgar Brunner and Markus Pauly", "title": "Permuting longitudinal data despite all the dependencies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For general repeated measures designs the Wald-type statistic (WTS) is an\nasymptotically valid procedure allowing for unequal covariance matrices and\npossibly non-normal multivariate observations. The drawback of this procedure\nis the poor performance for small to moderate samples, i.e. decisions based on\nthe WTS may become quite liberal. It is the aim of the present paper to improve\nits small sample behavior by means of a novel permutation procedure. In\nparticular, it is shown that a permutation version of the WTS inherits its good\nlarge sample properties while yielding a very accurate finite sample control of\nthe type-I error as shown in extensive simulations. Moreover, the new\npermutation method is motivated by a practical data set of a split plot design\nwith a factorial structure on the repeated measures.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2015 10:13:49 GMT"}, {"version": "v2", "created": "Thu, 23 Jun 2016 08:02:57 GMT"}], "update_date": "2016-06-24", "authors_parsed": [["Friedrich", "Sarah", ""], ["Brunner", "Edgar", ""], ["Pauly", "Markus", ""]]}, {"id": "1509.05946", "submitter": "Prasun Kundu", "authors": "Prasun K. Kundu and Ravi K. Siddani", "title": "A New Class of Probability Distributions for Describing the Spatial\n  Statistics of Area-averaged Rainfall", "comments": "37 pages, 6 figures. doi:10/1029/2006JD008042", "journal-ref": "J. Geophys. Res. Atmospheres, 112, D18113, 2007", "doi": "10.1029/2006JD008042", "report-no": null, "categories": "physics.ao-ph stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rainfall exhibits extreme variability at many space and time scales and calls\nfor a statistical description. Based on an analysis of radar measurements of\nprecipitation over the tropical oceans, we introduce a new probability law for\nthe area-averaged rain rate constructed from the class of log-infinitely\ndivisible distributions that accurately describes the frequency of the most\nintense rain events. The dependence of its parameters on the spatial averaging\nlength L allows one to relate spatial statistics at different scales. In\nparticular, it enables us to explain the observed power law scaling of the\nmoments of the data and successfully predicts the continuous spectrum of\nscaling exponents expressing multiscaling characteristics of the rain intensity\nfield.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2015 23:09:35 GMT"}], "update_date": "2015-09-30", "authors_parsed": [["Kundu", "Prasun K.", ""], ["Siddani", "Ravi K.", ""]]}, {"id": "1509.05954", "submitter": "Marco Cuturi", "authors": "Marco Cuturi, Alexandre d'Aspremont", "title": "Mean-Reverting Portfolios: Tradeoffs Between Sparsity and Volatility", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mean-reverting assets are one of the holy grails of financial markets: if\nsuch assets existed, they would provide trivially profitable investment\nstrategies for any investor able to trade them, thanks to the knowledge that\nsuch assets oscillate predictably around their long term mean. The modus\noperandi of cointegration-based trading strategies [Tsay, 2005, {\\S}8] is to\ncreate first a portfolio of assets whose aggregate value mean-reverts, to\nexploit that knowledge by selling short or buying that portfolio when its value\ndeviates from its long-term mean. Such portfolios are typically selected using\ntools from cointegration theory [Engle and Granger, 1987, Johansen, 1991],\nwhose aim is to detect combinations of assets that are stationary, and\ntherefore mean-reverting. We argue in this work that focusing on stationarity\nonly may not suffice to ensure profitability of cointegration-based strategies.\nWhile it might be possible to create syn- thetically, using a large array of\nfinancial assets, a portfolio whose aggre- gate value is stationary and\ntherefore mean-reverting, trading such a large portfolio incurs in practice\nimportant trade or borrow costs. Looking for stationary portfolios formed by\nmany assets may also result in portfolios that have a very small volatility and\nwhich require significant leverage to be profitable. We study in this work\nalgorithmic approaches that can take mitigate these effects by searching for\nmaximally mean-reverting portfo- lios which are sufficiently sparse and/or\nvolatile.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2015 02:04:14 GMT"}], "update_date": "2015-09-22", "authors_parsed": [["Cuturi", "Marco", ""], ["d'Aspremont", "Alexandre", ""]]}, {"id": "1509.06075", "submitter": "Claudia Solis-Lemus", "authors": "Claudia Sol\\'is-Lemus and C\\'ecile An\\'e", "title": "Inferring phylogenetic networks with maximum pseudolikelihood under\n  incomplete lineage sorting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE math.ST stat.AP stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Phylogenetic networks are necessary to represent the tree of life expanded by\nedges to represent events such as horizontal gene transfers, hybridizations or\ngene flow. Not all species follow the paradigm of vertical inheritance of their\ngenetic material. While a great deal of research has flourished into the\ninference of phylogenetic trees, statistical methods to infer phylogenetic\nnetworks are still limited and under development. The main disadvantage of\nexisting methods is a lack of scalability. Here, we present a statistical\nmethod to infer phylogenetic networks from multi-locus genetic data in a\npseudolikelihood framework. Our model accounts for incomplete lineage sorting\nthrough the coalescent model, and for horizontal inheritance of genes through\nreticulation nodes in the network. Computation of the pseudolikelihood is fast\nand simple, and it avoids the burdensome calculation of the full likelihood\nwhich can be intractable with many species. Moreover, estimation at the\nquartet-level has the added computational benefit that it is easily\nparallelizable. Simulation studies comparing our method to a full likelihood\napproach show that our pseudolikelihood approach is much faster without\ncompromising accuracy. We applied our method to reconstruct the evolutionary\nrelationships among swordtails and platyfishes ($Xiphophorus$: Poeciliidae),\nwhich is characterized by widespread hybridizations.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2015 23:41:03 GMT"}, {"version": "v2", "created": "Fri, 8 Jan 2016 20:48:47 GMT"}, {"version": "v3", "created": "Fri, 12 Feb 2016 19:23:35 GMT"}], "update_date": "2016-02-15", "authors_parsed": [["Sol\u00eds-Lemus", "Claudia", ""], ["An\u00e9", "C\u00e9cile", ""]]}, {"id": "1509.06253", "submitter": "Xin Yuan", "authors": "Xin Yuan, Hong Jiang, Paul Wilford", "title": "Convergence of the Generalized Alternating Projection Algorithm for\n  Compressive Sensing", "comments": "12 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The convergence of the generalized alternating projection (GAP) algorithm is\nstudied in this paper to solve the compressive sensing problem $\\yv = \\Amat \\xv\n+ \\epsilonv$. By assuming that $\\Amat\\Amat\\ts$ is invertible, we prove that GAP\nconverges linearly within a certain range of step-size when the sensing matrix\n$\\Amat$ satisfies restricted isometry property (RIP) condition of\n$\\delta_{2K}$, where $K$ is the sparsity of $\\xv$. The theoretical analysis is\nextended to the adaptively iterative thresholding (AIT) algorithms, for which\nthe convergence rate is also derived based on $\\delta_{2K}$ of the sensing\nmatrix. We further prove that, under the same conditions, the convergence rate\nof GAP is faster than that of AIT. Extensive simulation results confirm the\ntheoretical assertions.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2015 21:15:44 GMT"}], "update_date": "2015-09-22", "authors_parsed": [["Yuan", "Xin", ""], ["Jiang", "Hong", ""], ["Wilford", "Paul", ""]]}, {"id": "1509.06376", "submitter": "Yen-Chi Chen", "authors": "Yen-Chi Chen, Shirley Ho, Rachel Mandelbaum, Neta A. Bahcall, Joel R.\n  Brownstein, Peter E. Freeman, Christopher R. Genovese, Donald P. Schneider,\n  Larry Wasserman", "title": "Detecting Effects of Filaments on Galaxy Properties in the Sloan Digital\n  Sky Survey III", "comments": "To appear in MNRAS", "journal-ref": null, "doi": "10.1093/mnras/stw3127", "report-no": null, "categories": "astro-ph.GA astro-ph.CO stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the effects of filaments on galaxy properties in the Sloan Digital\nSky Survey (SDSS) Data Release 12 using filaments from the `Cosmic Web\nReconstruction' catalogue (Chen et al. 2016), a publicly available filament\ncatalogue for SDSS. Since filaments are tracers of medium-to-high density\nregions, we expect that galaxy properties associated with the environment are\ndependent on the distance to the nearest filament. Our analysis demonstrates\nthat a red galaxy or a high-mass galaxy tend to reside closer to filaments than\na blue or low-mass galaxy. After adjusting the effect from stellar mass, on\naverage, early-forming galaxies or large galaxies have a shorter distance to\nfilaments than late-forming galaxies or small galaxies. For the Main galaxy\nsample (MGS), all signals are very significant ($>6\\sigma$). For the LOWZ and\nCMASS sample, the stellar mass and size are significant ($>2 \\sigma$). The\nfilament effects we observe persist until $z = 0.7$ (the edge of the CMASS\nsample). Comparing our results to those using the galaxy distances from\nredMaPPer galaxy clusters as a reference, we find a similar result between\nfilaments and clusters. Moreover, we find that the effect of clusters on the\nstellar mass of nearby galaxies depends on the galaxy's filamentary\nenvironment. Our findings illustrate the strong correlation of galaxy\nproperties with proximity to density ridges, strongly supporting the claim that\ndensity ridges are good tracers of filaments.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2015 20:10:18 GMT"}, {"version": "v2", "created": "Thu, 12 Jan 2017 23:04:11 GMT"}], "update_date": "2017-01-16", "authors_parsed": [["Chen", "Yen-Chi", ""], ["Ho", "Shirley", ""], ["Mandelbaum", "Rachel", ""], ["Bahcall", "Neta A.", ""], ["Brownstein", "Joel R.", ""], ["Freeman", "Peter E.", ""], ["Genovese", "Christopher R.", ""], ["Schneider", "Donald P.", ""], ["Wasserman", "Larry", ""]]}, {"id": "1509.06443", "submitter": "Yen-Chi Chen", "authors": "Yen-Chi Chen, Shirley Ho, Jon Brinkmann, Peter E. Freeman, Christopher\n  R. Genovese, Donald P. Schneider, Larry Wasserman", "title": "Cosmic Web Reconstruction through Density Ridges: Catalogue", "comments": "14 pages, 12 figures, 4 tables", "journal-ref": null, "doi": "10.1093/mnras/stw1554", "report-no": null, "categories": "astro-ph.CO stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We construct a catalogue for filaments using a novel approach called SCMS\n(subspace constrained mean shift; Ozertem & Erdogmus 2011; Chen et al. 2015).\nSCMS is a gradient-based method that detects filaments through density ridges\n(smooth curves tracing high-density regions). A great advantage of SCMS is its\nuncertainty measure, which allows an evaluation of the errors for the detected\nfilaments. To detect filaments, we use data from the Sloan Digital Sky Survey,\nwhich consist of three galaxy samples: the NYU main galaxy sample (MGS), the\nLOWZ sample and the CMASS sample. Each of the three dataset covers different\nredshift regions so that the combined sample allows detection of filaments up\nto z = 0.7. Our filament catalogue consists of a sequence of two-dimensional\nfilament maps at different redshifts that provide several useful statistics on\nthe evolution cosmic web. To construct the maps, we select spectroscopically\nconfirmed galaxies within 0.050 < z < 0.700 and partition them into 130 bins.\nFor each bin, we ignore the redshift, treating the galaxy observations as a 2-D\ndata and detect filaments using SCMS. The filament catalogue consists of 130\nindividual 2-D filament maps, and each map comprises points on the detected\nfilaments that describe the filamentary structures at a particular redshift. We\nalso apply our filament catalogue to investigate galaxy luminosity and its\nrelation with distance to filament. Using a volume-limited sample, we find\nstrong evidence (6.1$\\sigma$ - 12.3$\\sigma$) that galaxies close to filaments\nare generally brighter than those at significant distance from filaments.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2015 01:48:57 GMT"}], "update_date": "2016-08-03", "authors_parsed": [["Chen", "Yen-Chi", ""], ["Ho", "Shirley", ""], ["Brinkmann", "Jon", ""], ["Freeman", "Peter E.", ""], ["Genovese", "Christopher R.", ""], ["Schneider", "Donald P.", ""], ["Wasserman", "Larry", ""]]}, {"id": "1509.06494", "submitter": "John-Olof Nilsson", "authors": "Isaac Skog, John-Olof Nilsson, Peter H\\\"andel, and Arye Nehorai", "title": "Inertial Sensor Arrays, Maximum Likelihood, and Cram\\'er-Rao Bound", "comments": "In review", "journal-ref": null, "doi": "10.1109/TSP.2016.2560136", "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A maximum likelihood estimator for fusing the measurements in an inertial\nsensor array is presented. The maximum likelihood estimator is concentrated and\nan iterative solution method is presented for the resulting low-dimensional\noptimization problem. The Cram\\'er-Rao bound for the corresponding measurement\nfusion problem is derived and used to assess the performance of the proposed\nmethod, as well as to analyze how the geometry of the array and sensor errors\naffect the accuracy of the measurement fusion. The angular velocity information\ngained from the accelerometers in the array is shown to be proportional to the\nsquare of the array dimension and to the square of the angular speed. In our\nsimulations the proposed fusion method attains the Cram\\'er-Rao bound and\noutperforms the current state-of-the-art method for measurement fusion in\naccelerometer arrays. Further, in contrast to the state-of-the-art method that\nrequires a 3D array to work, the proposed method also works for 2D arrays. The\ntheoretical findings are compared to results from real-world experiments with\nan in-house developed array that consists of 192 sensing elements.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2015 08:09:52 GMT"}, {"version": "v2", "created": "Tue, 19 Apr 2016 14:28:16 GMT"}], "update_date": "2016-08-24", "authors_parsed": [["Skog", "Isaac", ""], ["Nilsson", "John-Olof", ""], ["H\u00e4ndel", "Peter", ""], ["Nehorai", "Arye", ""]]}, {"id": "1509.06721", "submitter": "Liwen Ouyang", "authors": "Liwen Ouyang, Daniel W. Apley, Sanjay Mehrotra", "title": "Designed Sampling from Large Databases for Controlled Trials", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.AP stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing prevalence of rich sources of data and the availability of\nelectronic medical record databases and electronic registries opens tremendous\nopportunities for enhancing medical research. For example, controlled trials\nare ubiquitously used to investigate the effect of a medical treatment, perhaps\ndependent on a set of patient covariates, and traditional approaches have\nrelied primarily on randomized patient sampling and allocation to treatment and\ncontrol group. However, when covariate data for a large cohort group of\npatients have already been collected and are available in a database, one can\npotentially design a treatment/control sample and allocation that provides far\nbetter estimates of the covariate-dependent effects of the treatment. In this\npaper, we develop a new approach that uses optimal design of experiments (DOE)\nconcepts to accomplish this objective. The approach selects the patients for\nthe treatment and control samples upfront, based on their covariate values, in\na manner that optimizes the information content in the data. For the optimal\nsample selection, we develop simple guidelines and an optimization algorithm\nthat provides solutions that are substantially better than random sampling.\nMoreover, our approach causes no sampling bias in the estimated effects, for\nthe same reason that DOE principles do not bias estimated effects. We test our\nmethod with a simulation study based on a testbed data set containing\ninformation on the effect of statins on low-density lipoprotein (LDL)\ncholesterol.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2015 18:41:43 GMT"}], "update_date": "2015-09-23", "authors_parsed": [["Ouyang", "Liwen", ""], ["Apley", "Daniel W.", ""], ["Mehrotra", "Sanjay", ""]]}, {"id": "1509.06808", "submitter": "Karthik Gangavarapu", "authors": "Karthik Gangavarapu, Vyshakh Babji, Tobias Mei{\\ss}ner, Andrew I. Su,\n  and Benjamin M. Good", "title": "Branch: An interactive, web-based tool for testing hypotheses and\n  developing predictive models", "comments": null, "journal-ref": null, "doi": "10.1093/bioinformatics/btw117", "report-no": null, "categories": "stat.AP cs.CY cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Branch is a web application that provides users with no programming with the\nability to interact directly with large biomedical datasets. The interaction is\nmediated through a collaborative graphical user interface for building and\nevaluating decision trees. These trees can be used to compose and test\nsophisticated hypotheses and to develop predictive models. Decision trees are\nevaluated based on a library of imported datasets and can be stored in a\ncollective area for sharing and re-use. Branch is hosted at\nhttp://biobranch.org/ and the open source code is available at\nhttp://bitbucket.org/sulab/biobranch/.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2015 23:15:57 GMT"}, {"version": "v2", "created": "Wed, 30 Sep 2015 20:55:14 GMT"}], "update_date": "2016-05-04", "authors_parsed": [["Gangavarapu", "Karthik", ""], ["Babji", "Vyshakh", ""], ["Mei\u00dfner", "Tobias", ""], ["Su", "Andrew I.", ""], ["Good", "Benjamin M.", ""]]}, {"id": "1509.07102", "submitter": "Stefan Siegert", "authors": "Stefan Siegert, Philip G. Sansom, Robin Williams", "title": "Parameter uncertainty in forecast recalibration", "comments": "22 pages, 9 figures", "journal-ref": null, "doi": "10.1002/qj.2716", "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensemble forecasts of weather and climate are subject to systematic biases in\nthe ensemble mean and variance, leading to inaccurate estimates of the forecast\nmean and variance. To address these biases, ensemble forecasts are\npost-processed using statistical recalibration frameworks. These frameworks\noften specify parametric probability distributions for the verifying\nobservations. A common choice is the Normal distribution with mean and variance\nspecified by linear functions of the ensemble mean and variance. The parameters\nof the recalibration framework are estimated from historical archives of\nforecasts and verifying observations. Often there are relatively few forecasts\nand observations available for parameter estimation, and so the fitted\nparameters are also subject to uncertainty. This artefact is usually ignored.\nThis study reviews analytic results that account for parameter uncertainty in\nthe widely used Model Output Statistics recalibration framework. The predictive\nbootstrap is used to approximate the parameter uncertainty by resampling in\nmore general frameworks such as Non-homogeneous Gaussian Regression. Forecasts\non daily, seasonal and annual time scales are used to demonstrate that\naccounting for parameter uncertainty in the recalibrated predictive\ndistributions leads to probability forecasts that are more skilful and reliable\nthan those in which parameter uncertainty is ignored. The improvements are\nattributed to more reliable tail probabilities of the recalibrated forecast\ndistributions.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2015 19:26:07 GMT"}, {"version": "v2", "created": "Mon, 23 Nov 2015 14:01:49 GMT"}], "update_date": "2016-05-25", "authors_parsed": [["Siegert", "Stefan", ""], ["Sansom", "Philip G.", ""], ["Williams", "Robin", ""]]}, {"id": "1509.07138", "submitter": "Peng Ding", "authors": "Xinran Li, Peng Ding", "title": "Exact confidence intervals for the average causal effect on a binary\n  outcome", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Based on the physical randomization of completely randomized experiments,\nRigdon and Hudgens (2015) propose two approaches to obtaining exact confidence\nintervals for the average causal effect on a binary outcome. They construct the\nfirst confidence interval by combining, with the Bonferroni adjustment, the\nprediction sets for treatment effects among treatment and control groups, and\nthe second one by inverting a series of randomization tests. With sample size\n$n$, their second approach requires performing $O(n^4)$ randomization tests. We\ndemonstrate that the physical randomization also justifies other ways to\nconstructing exact confidence intervals that are more computationally\nefficient. By exploiting recent advances in hypergeometric confidence intervals\nand the stochastic order information of randomization tests, we propose\napproaches that either do not need to invoke Monte Carlo, or require performing\nat most $O(n^2)$ randomization tests. We provide technical details and R code\nin the Supplementary Material.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2015 20:15:35 GMT"}], "update_date": "2015-09-25", "authors_parsed": [["Li", "Xinran", ""], ["Ding", "Peng", ""]]}, {"id": "1509.07238", "submitter": "David Pritchard", "authors": "David Pritchard", "title": "Frequency Distribution of Error Messages", "comments": "To appear at PLATEAU 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CY cs.PL stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Which programming error messages are the most common? We investigate this\nquestion, motivated by writing error explanations for novices. We consider\nlarge data sets in Python and Java that include both syntax and run-time\nerrors. In both data sets, after grouping essentially identical messages, the\nerror message frequencies empirically resemble Zipf-Mandelbrot distributions.\nWe use a maximum-likelihood approach to fit the distribution parameters. This\ngives one possible way to contrast languages or compilers quantitatively.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2015 05:22:59 GMT"}], "update_date": "2015-09-25", "authors_parsed": [["Pritchard", "David", ""]]}, {"id": "1509.07304", "submitter": "Daniele Ramazzotti", "authors": "Luca De Sano, Giulio Caravagna, Daniele Ramazzotti, Alex Graudenzi,\n  Giancarlo Mauri, Bud Mishra, Marco Antoniotti", "title": "TRONCO: an R package for the inference of cancer progression models from\n  heterogeneous genomic data", "comments": null, "journal-ref": null, "doi": "10.1093/bioinformatics/btw035", "report-no": null, "categories": "q-bio.QM q-bio.GN stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivation: We introduce TRONCO (TRanslational ONCOlogy), an open-source R\npackage that implements the state-of-the-art algorithms for the inference of\ncancer progression models from (epi)genomic mutational profiles. TRONCO can be\nused to extract population-level models describing the trends of accumulation\nof alterations in a cohort of cross-sectional samples, e.g., retrieved from\npublicly available databases, and individual-level models that reveal the\nclonal evolutionary history in single cancer patients, when multiple samples,\ne.g., multiple biopsies or single-cell sequencing data, are available. The\nresulting models can provide key hints in uncovering the evolutionary\ntrajectories of cancer, especially for precision medicine or personalized\ntherapy.\n  Availability: TRONCO is released under the GPL license, it is hosted in the\nSoftware section at http://bimib.disco.unimib.it/ and archived also at\nbioconductor.org.\n  Contact: tronco@disco.unimib.it\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2015 10:34:30 GMT"}, {"version": "v2", "created": "Tue, 13 Oct 2015 15:04:33 GMT"}, {"version": "v3", "created": "Tue, 22 Dec 2015 16:16:20 GMT"}, {"version": "v4", "created": "Wed, 23 Dec 2015 09:33:47 GMT"}, {"version": "v5", "created": "Tue, 26 Jan 2016 18:23:40 GMT"}, {"version": "v6", "created": "Wed, 10 Feb 2016 16:02:54 GMT"}], "update_date": "2016-02-11", "authors_parsed": [["De Sano", "Luca", ""], ["Caravagna", "Giulio", ""], ["Ramazzotti", "Daniele", ""], ["Graudenzi", "Alex", ""], ["Mauri", "Giancarlo", ""], ["Mishra", "Bud", ""], ["Antoniotti", "Marco", ""]]}, {"id": "1509.07510", "submitter": "James M. Flegal", "authors": "Lei Gong, James M. Flegal, Stephen R. Spindler, and Patricia L. Mote", "title": "Bayesian model selection on linear mixed-effects models for comparisons\n  between multiple treatments and a control", "comments": "22 pages, 3 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel Bayesian model selection technique on linear mixed-effects\nmodels to compare multiple treatments with a control. A fully Bayesian approach\nis implemented to estimate the marginal inclusion probabilities that provide a\ndirect measure of the difference between treatments and the control, along with\nthe model-averaged posterior distributions. Default priors are proposed for\nmodel selection incorporating domain knowledge and a component-wise Gibbs\nsampler is developed for efficient posterior computation. We demonstrate the\nproposed method based on simulated data and an experimental dataset from a\nlongitudinal study of mouse lifespan and weight trajectories.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2015 20:07:51 GMT"}], "update_date": "2015-09-28", "authors_parsed": [["Gong", "Lei", ""], ["Flegal", "James M.", ""], ["Spindler", "Stephen R.", ""], ["Mote", "Patricia L.", ""]]}, {"id": "1509.07535", "submitter": "Sayantan Banerjee", "authors": "Sayantan Banerjee, Rehan Akbani and Veerabhadran Baladandayuthapani", "title": "Bayesian Nonparametric Graph Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present clustering methods for multivariate data exploiting the underlying\ngeometry of the graphical structure between variables. As opposed to standard\napproaches that assume known graph structures, we first estimate the edge\nstructure of the unknown graph using Bayesian neighborhood selection\napproaches, wherein we account for the uncertainty of graphical structure\nlearning through model-averaged estimates of the suitable parameters.\nSubsequently, we develop a nonparametric graph clustering model on the lower\ndimensional projections of the graph based on Laplacian embeddings using\nDirichlet process mixture models. In contrast to standard algorithmic\napproaches, this fully probabilistic approach allows incorporation of\nuncertainty in estimation and inference for both graph structure learning and\nclustering. More importantly, we formalize the arguments for Laplacian\nembeddings as suitable projections for graph clustering by providing\ntheoretical support for the consistency of the eigenspace of the estimated\ngraph Laplacians. We develop fast computational algorithms that allow our\nmethods to scale to large number of nodes. Through extensive simulations we\ncompare our clustering performance with standard clustering methods. We apply\nour methods to a novel pan-cancer proteomic data set, and evaluate protein\nnetworks and clusters across multiple different cancer types.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2015 20:52:05 GMT"}], "update_date": "2015-09-28", "authors_parsed": [["Banerjee", "Sayantan", ""], ["Akbani", "Rehan", ""], ["Baladandayuthapani", "Veerabhadran", ""]]}, {"id": "1509.08210", "submitter": "Bin Liu", "authors": "Bin Liu", "title": "Mixture Modeling based Probabilistic Situation Awareness", "comments": "14 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of situational awareness (SAW) is investigated from the\nprobabilistic modeling point of view. Taking the situation as a hidden\nvariable, we introduce a hidden Markov model (HMM) and an extended state space\nmodel (ESSM) to mathematically express the dynamic evolution law of the\nsituation and the relationships between the situation and the observable\nquantities. We use the Gaussian mixture model (GMM) to formulate expert\nknowledge, which is needed in building the HMM and ESSM. We show that the ESSM\nmodel is preferable as compared with HMM, since using ESSM, we can also get a\nreal time estimate of the pivot variable that connects the situation with the\nobservable quantities. The effectiveness and efficiency of both models are\ntested through a simulated experiment about threat surveillance.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2015 06:35:12 GMT"}, {"version": "v2", "created": "Wed, 7 Oct 2015 02:44:38 GMT"}], "update_date": "2015-10-08", "authors_parsed": [["Liu", "Bin", ""]]}, {"id": "1509.08359", "submitter": "Elizabeth Sweeney", "authors": "Elizabeth M. Sweeney, Russell T. Shinohara, Blake E. Dewey, Matthew K.\n  Schindler, John Muschelli, Daniel S. Reich, Ciprian M. Crainiceanu and Ani\n  Eloyan", "title": "Relating multi-sequence longitudinal intensity profiles and clinical\n  covariates in new multiple sclerosis lesions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Structural magnetic resonance imaging (MRI) can be used to detect lesions in\nthe brains of multiple sclerosis (MS) patients. The formation of these lesions\nis a complex process involving inflammation, tissue damage, and tissue repair,\nall of which are visible on MRI. Here we characterize the lesion formation\nprocess on longitudinal, multi-sequence structural MRI from 34 MS patients and\nrelate the longitudinal changes we observe within lesions to therapeutic\ninterventions. In this article, we first outline a pipeline to extract voxel\nlevel, multi-sequence longitudinal profiles from four MRI sequences within\nlesion tissue. We then propose two models to relate clinical covariates to the\nlongitudinal profiles. The first model is a principal component analysis (PCA)\nregression model, which collapses the information from all four profiles into a\nscalar value. We find that the score on the first PC identifies areas of slow,\nlong-term intensity changes within the lesion at a voxel level, as validated by\ntwo experienced clinicians, a neuroradiologist and a neurologist. On a quality\nscale of 1 to 4 (4 being the highest) the neuroradiologist gave the score on\nthe first PC a median rating of 4 (95% CI: [4,4]), and the neurologist gave it\na median rating of 3 (95% CI: [3,3]). In the PCA regression model, we find that\ntreatment with disease modifying therapies (p-value < 0.01), steroids (p-value\n< 0.01), and being closer to the boundary of abnormal signal intensity (p-value\n< 0.01) are associated with a return of a voxel to intensity values closer to\nthat of normal-appearing tissue. The second model is a function-on-scalar\nregression, which allows for assessment of the individual time points at which\nthe covariates are associated with the profiles. In the function-on-scalar\nregression both age and distance to the boundary were found to have a\nstatistically significant association with the profiles.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2015 15:31:16 GMT"}], "update_date": "2015-09-29", "authors_parsed": [["Sweeney", "Elizabeth M.", ""], ["Shinohara", "Russell T.", ""], ["Dewey", "Blake E.", ""], ["Schindler", "Matthew K.", ""], ["Muschelli", "John", ""], ["Reich", "Daniel S.", ""], ["Crainiceanu", "Ciprian M.", ""], ["Eloyan", "Ani", ""]]}, {"id": "1509.08361", "submitter": "Robert Cowell", "authors": "Robert Cowell", "title": "Combining allele frequency uncertainty and population substructure\n  corrections in forensic DNA calculations", "comments": "20 pages, 3 figures. Corrected values in Tables, added new section", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In forensic DNA calculations of relatedness of individuals and in DNA mixture\nanalyses, two sources of uncertainty are present concerning the allele\nfrequencies used for evaluating genotype probabilities when evaluating\nlikelihoods. They are: (i) imprecision in the estimates of the allele\nfrequencies in the population by using an inevitably finite database of DNA\nprofiles to estimate them; and (ii) the existence of population substructure.\nGreen and Mortera (2009) showed that these effects may be taken into account\nindividually using a common Dirichlet model within a Bayesian network\nformulation, but that when taken in combination this is not the case; however\nthey suggested an approximation that could be used. Here we develop a slightly\ndifferent approximation that is shown to be exact in the case of a single\nindividual. We demonstrate the closeness of the approximation numerically using\na published database of allele counts, and illustrate the effect of\nincorporating the approximation into calculations of a recently published\nstatistical model of DNA mixtures.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2015 15:32:36 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2015 14:36:52 GMT"}], "update_date": "2015-10-07", "authors_parsed": [["Cowell", "Robert", ""]]}, {"id": "1509.08442", "submitter": "Melissa Turcotte", "authors": "Melissa J. M. Turcotte, Nicholas A. Heard", "title": "Adaptive sequential Monte Carlo for multiple changepoint analysis", "comments": "23 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Process monitoring and control requires detection of structural changes in a\ndata stream in real time. This article introduces an efficient sequential Monte\nCarlo algorithm designed for learning unknown changepoints in continuous time.\nThe method is intuitively simple: new changepoints for the latest window of\ndata are proposed by conditioning only on data observed since the most recent\nestimated changepoint, as these carry most of the information about the state\nof the process prior to the update. The proposed method shows improved\nperformance over the current state of the art. Another advantage of the\nproposed algorithm is that it can be made adaptive, varying the number of\nparticles according to the apparent local complexity of the target changepoint\nprobability distribution. This saves valuable computing time when changes in\nthe change- point distribution are negligible, and enables re-balancing of the\nimportance weights of ex- isting particles when a significant change in the\ntarget distribution is encountered. The plain and adaptive versions of the\nmethod are illustrated using the canonical con- tinuous time changepoint\nproblem of inferring the intensity of an inhomogeneous Poisson process.\nPerformance is demonstrated using both conjugate and non-conjugate Bayesian\nmodels for the intensity.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2015 19:29:06 GMT"}], "update_date": "2015-09-29", "authors_parsed": [["Turcotte", "Melissa J. M.", ""], ["Heard", "Nicholas A.", ""]]}, {"id": "1509.08666", "submitter": "Ricardo Ehlers", "authors": "Marinho G. Andrade, Ricardo S. Ehlers, Breno S. Andrade", "title": "Bayesian GARMA Models for Count Data", "comments": null, "journal-ref": "Communications in Statistics: Case Studies, Data Analysis and\n  Applications, 1 (2016) 192-205", "doi": "10.1080/23737484.2016.1190307", "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generalized autoregressive moving average (GARMA) models are a class of\nmodels that was developed for extending the univariate Gaussian ARMA time\nseries model to a flexible observation-driven model for non-Gaussian time\nseries data. This work presents Bayesian approach for GARMA models with\nPoisson, binomial and negative binomial distributions. A simulation study was\ncarried out to investigate the performance of Bayesian estimation and Bayesian\nmodel selection criteria. Also three real datasets were analysed using the\nBayesian approach on GARMA models.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2015 09:50:38 GMT"}], "update_date": "2017-02-07", "authors_parsed": [["Andrade", "Marinho G.", ""], ["Ehlers", "Ricardo S.", ""], ["Andrade", "Breno S.", ""]]}, {"id": "1509.08774", "submitter": "Paul Blomstedt PhD", "authors": "Paul Blomstedt, Jarno Vanhatalo, Mats Ulmestrand, Anna G{\\aa}rdmark,\n  Samu M\\\"antyniemi", "title": "A Bayesian length-based population dynamics model for northern shrimp\n  (Pandalus Borealis)", "comments": "Deliverable for the EU FP7 project ECOKNOWS", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a fully length-based Bayesian model for the population dynamics\nof northern shrimp (Pandalus Borealis). This has the advantage of structuring\nthe population in terms of a directly observable quantity, requiring no\nindirect estimation of age distributions from measurements of size. The\nintroduced model is intended as a simplistic prototype around which further\ndevelopments and refinements can be built. As a case study, we use the model to\nanalyze the population of Skagerrak and the Norwegian Deep in the years\n1988-2012.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2015 14:31:15 GMT"}], "update_date": "2015-09-30", "authors_parsed": [["Blomstedt", "Paul", ""], ["Vanhatalo", "Jarno", ""], ["Ulmestrand", "Mats", ""], ["G\u00e5rdmark", "Anna", ""], ["M\u00e4ntyniemi", "Samu", ""]]}, {"id": "1509.08864", "submitter": "Tiago Fragoso", "authors": "Tiago M. Fragoso and Francisco Louzada Neto", "title": "Bayesian model averaging: A systematic review and conceptual\n  classification", "comments": null, "journal-ref": null, "doi": "10.1111/insr.12243", "report-no": null, "categories": "stat.ME stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian Model Averaging (BMA) is an application of Bayesian inference to the\nproblems of model selection, combined estimation and prediction that produces a\nstraightforward model choice criteria and less risky predictions. However, the\napplication of BMA is not always straightforward, leading to diverse\nassumptions and situational choices on its different aspects. Despite the\nwidespread application of BMA in the literature, there were not many accounts\nof these differences and trends besides a few landmark revisions in the late\n1990s and early 2000s, therefore not taking into account any advancements made\nin the last 15 years. In this work, we present an account of these developments\nthrough a careful content analysis of 587 articles in BMA published between\n1996 and 2014. We also develop a conceptual classification scheme to better\ndescribe this vast literature, understand its trends and future directions and\nprovide guidance for the researcher interested in both the application and\ndevelopment of the methodology. The results of the classification scheme and\ncontent review are then used to discuss the present and future of the BMA\nliterature.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2015 17:34:48 GMT"}], "update_date": "2017-11-08", "authors_parsed": [["Fragoso", "Tiago M.", ""], ["Neto", "Francisco Louzada", ""]]}, {"id": "1509.08968", "submitter": "Jeffrey Leek", "authors": "Jeffrey T. Leek, Prasad Patil and Roger D. Peng", "title": "A glass half full interpretation of the replicability of psychological\n  science", "comments": "6 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A recent study of the replicability of key psychological findings is a major\ncontribution toward understanding the human side of the scientific process.\nDespite the careful and nuanced analysis reported in the paper, mass and social\nmedia adhered to the simple narrative that only 36% of the studies replicated\ntheir original results. Here we show that 77% of the replication effect sizes\nreported were within a prediction interval based on the original effect size.\nIn this light, the results of Reproducibility Project: Psychology can be viewed\nas a positive result for the scientific process.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2015 22:31:57 GMT"}], "update_date": "2015-10-01", "authors_parsed": [["Leek", "Jeffrey T.", ""], ["Patil", "Prasad", ""], ["Peng", "Roger D.", ""]]}, {"id": "1509.09103", "submitter": "Sylvain Le", "authors": "Pierre Gloaguen (IFREMER), Marie-Pierre Etienne (MIA-Paris), Sylvain\n  Le Corff", "title": "Stochastic differential equation based on a multimodal potential to\n  model movement data in ecology", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a new model for individuals movement in ecology. The\nmovement process is defined as a solution to a stochastic differential equation\nwhose drift is the gradient of a multimodal potential surface. This offers a\nnew flexible approach among the popular potential based movement models in\necology. To perform parameter inference, the widely used Euler method is\ncompared with two other pseudo-likelihood procedures and with a Monte Carlo\nExpectation Maximization approach based on exact simulation of diffusions.\nPerformances of all methods are assessed with simulated data and with a data\nset of fishing vessels trajectories. We show that the usual Euler method\nperforms worse than the other procedures for all sampling schemes.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2015 09:53:32 GMT"}, {"version": "v2", "created": "Fri, 18 Nov 2016 15:37:22 GMT"}, {"version": "v3", "created": "Thu, 21 Sep 2017 07:39:20 GMT"}], "update_date": "2017-09-22", "authors_parsed": [["Gloaguen", "Pierre", "", "IFREMER"], ["Etienne", "Marie-Pierre", "", "MIA-Paris"], ["Corff", "Sylvain Le", ""]]}]