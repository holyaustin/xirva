[{"id": "0712.0189", "submitter": "Jeffrey Picka", "authors": "Jeffrey Picka and Mingxia Deng", "title": "Summarization and Classification of Non-Poisson Point Processes", "comments": "14 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.AP stat.ML", "license": null, "abstract": "  Fitting models for non-Poisson point processes is complicated by the lack of\ntractable models for much of the data. By using large samples of independent\nand identically distributed realizations and statistical learning, it is\npossible to identify absence of fit through finding a classification rule that\ncan efficiently identify single realizations of each type. The method requires\na much wider range of descriptive statistics than are currently in use, and a\nnew concept of model fitting which is derive from how physical laws are judged\nto fit data.\n", "versions": [{"version": "v1", "created": "Sun, 2 Dec 2007 21:48:10 GMT"}], "update_date": "2007-12-04", "authors_parsed": [["Picka", "Jeffrey", ""], ["Deng", "Mingxia", ""]]}, {"id": "0712.0660", "submitter": "Oliver Bembom", "authors": "Oliver Bembom, Mark J. van der Laan", "title": "A practical illustration of the importance of realistic individualized\n  treatment rules in causal inference", "comments": "Published in at http://dx.doi.org/10.1214/07-EJS105 the Electronic\n  Journal of Statistics (http://www.i-journals.org/ejs/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Electronic Journal of Statistics 2007, Vol. 1, 574-596", "doi": "10.1214/07-EJS105", "report-no": "IMS-EJS-EJS_2007_105", "categories": "stat.AP", "license": null, "abstract": "  The effect of vigorous physical activity on mortality in the elderly is\ndifficult to estimate using conventional approaches to causal inference that\ndefine this effect by comparing the mortality risks corresponding to\nhypothetical scenarios in which all subjects in the target population engage in\na given level of vigorous physical activity. A causal effect defined on the\nbasis of such a static treatment intervention can only be identified from\nobserved data if all subjects in the target population have a positive\nprobability of selecting each of the candidate treatment options, an assumption\nthat is highly unrealistic in this case since subjects with serious health\nproblems will not be able to engage in higher levels of vigorous physical\nactivity. This problem can be addressed by focusing instead on causal effects\nthat are defined on the basis of realistic individualized treatment rules and\nintention-to-treat rules that explicitly take into account the set of treatment\noptions that are available to each subject. We present a data analysis to\nillustrate that estimators of static causal effects in fact tend to\noverestimate the beneficial impact of high levels of vigorous physical activity\nwhile corresponding estimators based on realistic individualized treatment\nrules and intention-to-treat rules can yield unbiased estimates. We emphasize\nthat the problems encountered in estimating static causal effects are not\nrestricted to the IPTW estimator, but are also observed with the\n$G$-computation estimator, the DR-IPTW estimator, and the targeted MLE. Our\nanalyses based on realistic individualized treatment rules and\nintention-to-treat rules suggest that high levels of vigorous physical activity\nmay confer reductions in mortality risk on the order of 15-30%, although in\nmost cases the evidence for such an effect does not quite reach the 0.05 level\nof significance.\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2007 07:18:54 GMT"}], "update_date": "2007-12-18", "authors_parsed": [["Bembom", "Oliver", ""], ["van der Laan", "Mark J.", ""]]}, {"id": "0712.0974", "submitter": "Stephen E. Fienberg", "authors": "Stephen E. Fienberg", "title": "Editorial: Statistics and forensic science", "comments": "Published in at http://dx.doi.org/10.1214/07-AOAS140 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2007, Vol. 1, No. 2, 285-286", "doi": "10.1214/07-AOAS140", "report-no": "IMS-AOAS-AOAS140", "categories": "stat.AP", "license": null, "abstract": "  Forensic science is usually taken to mean the application of a broad spectrum\nof scientific tools to answer questions of interest to the legal system.\nDespite such popular television series as CSI: Crime Scene Investigation and\nits spinoffs--CSI: Miami and CSI: New York--on which the forensic scientists\nuse the latest high-tech scientific tools to identify the perpetrator of a\ncrime and always in under an hour, forensic science is under assault, in the\npublic media, popular magazines [Talbot (2007), Toobin (2007)] and in the\nscientific literature [Kennedy (2003), Saks and Koehler (2005)]. Ironically,\nthis growing controversy over forensic science has occurred precisely at the\ntime that DNA evidence has become the ``gold standard'' in the courts, leading\nto the overturning of hundreds of convictions many of which were based on\nclearly less credible forensic evidence, including eyewitness testimony [Berger\n(2006)].\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2007 15:42:37 GMT"}], "update_date": "2009-09-29", "authors_parsed": [["Fienberg", "Stephen E.", ""]]}, {"id": "0712.1099", "submitter": "Bruce S. Weir", "authors": "Bruce S. Weir", "title": "The rarity of DNA profiles", "comments": "Published in at http://dx.doi.org/10.1214/07-AOAS128 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2007, Vol. 1, No. 2, 358-370", "doi": "10.1214/07-AOAS128", "report-no": "IMS-AOAS-AOAS128", "categories": "stat.AP", "license": null, "abstract": "  It is now widely accepted that forensic DNA profiles are rare, so it was a\nsurprise to some people that different people represented in offender databases\nare being found to have the same profile. In the first place this is just an\nillustration of the birthday problem, but a deeper analysis must take into\naccount dependencies among profiles caused by family or population membership.\n", "versions": [{"version": "v1", "created": "Fri, 7 Dec 2007 09:42:10 GMT"}], "update_date": "2007-12-18", "authors_parsed": [["Weir", "Bruce S.", ""]]}, {"id": "0712.1106", "submitter": "Amy Berrington de Gonz\\'{a}lez", "authors": "Amy Berrington de Gonz\\'alez, D. R. Cox", "title": "Interpretation of interaction: A review", "comments": "Published in at http://dx.doi.org/10.1214/07-AOAS124 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2007, Vol. 1, No. 2, 371-385", "doi": "10.1214/07-AOAS124", "report-no": "IMS-AOAS-AOAS124", "categories": "stat.AP", "license": null, "abstract": "  Several different types of statistical interaction are defined and\ndistinguished, primarily on the basis of the nature of the factors defining the\ninteraction. Illustrative examples, mostly epidemiological, are given. The\nemphasis is primarily on interpretation rather than on methods for detecting\ninteractions.\n", "versions": [{"version": "v1", "created": "Fri, 7 Dec 2007 10:16:48 GMT"}], "update_date": "2009-09-29", "authors_parsed": [["de Gonz\u00e1lez", "Amy Berrington", ""], ["Cox", "D. R.", ""]]}, {"id": "0712.1111", "submitter": "Art B. Owen", "authors": "Art B. Owen", "title": "The pigeonhole bootstrap", "comments": "Published in at http://dx.doi.org/10.1214/07-AOAS122 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2007, Vol. 1, No. 2, 386-411", "doi": "10.1214/07-AOAS122", "report-no": "IMS-AOAS-AOAS122", "categories": "stat.AP", "license": null, "abstract": "  Recently there has been much interest in data that, in statistical language,\nmay be described as having a large crossed and severely unbalanced random\neffects structure. Such data sets arise for recommender engines and information\nretrieval problems. Many large bipartite weighted graphs have this structure\ntoo. We would like to assess the stability of algorithms fit to such data. Even\nfor linear statistics, a naive form of bootstrap sampling can be seriously\nmisleading and McCullagh [Bernoulli 6 (2000) 285--301] has shown that no\nbootstrap method is exact. We show that an alternative bootstrap separately\nresampling rows and columns of the data matrix satisfies a mean consistency\nproperty even in heteroscedastic crossed unbalanced random effects models. This\nalternative does not require the user to fit a crossed random effects model to\nthe data.\n", "versions": [{"version": "v1", "created": "Fri, 7 Dec 2007 10:45:24 GMT"}], "update_date": "2007-12-18", "authors_parsed": [["Owen", "Art B.", ""]]}, {"id": "0712.1124", "submitter": "Haiyan Wu", "authors": "Haiyan Wu, Ming Yuan, Susan M. Kaech, M. Elizabeth Halloran", "title": "A statistical analysis of memory CD8 T cell differentiation: An\n  application of a hierarchical state space model to a short time course\n  microarray experiment", "comments": "Published in at http://dx.doi.org/10.1214/07-AOAS118 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2007, Vol. 1, No. 2, 442-458", "doi": "10.1214/07-AOAS118", "report-no": "IMS-AOAS-AOAS118", "categories": "stat.AP", "license": null, "abstract": "  CD8 T cells are specialized immune cells that play an important role in the\nregulation of antiviral immune response and the generation of protective\nimmunity. In this paper we investigate the differentiation of memory CD8 T\ncells in the immune response using a short time course microarray experiment.\nStructurally, this experiment is similar to many in that it involves\nmeasurements taken on independent samples, in one biological group, at a small\nnumber of irregularly spaced time points, and exhibiting patterns of temporal\nnonstationarity. To analyze this CD8 T-cell experiment, we develop a\nhierarchical state space model so that we can: (1) detect temporally\ndifferentially expressed genes, (2) identify the direction of successive\nchanges over time, and (3) assess the magnitude of successive changes over\ntime. We incorporate hidden Markov models into our model to utilize the\ninformation embedded in the time series and set up the proposed hierarchical\nstate space model in an empirical Bayes framework to utilize the population\ninformation from the large-scale data. Analysis of the CD8 T-cell experiment\nusing the proposed model results in biologically meaningful findings. Temporal\npatterns involved in the differentiation of memory CD8 T cells are summarized\nseparately and performance of the proposed model is illustrated in a simulation\nstudy.\n", "versions": [{"version": "v1", "created": "Fri, 7 Dec 2007 12:25:08 GMT"}], "update_date": "2009-09-29", "authors_parsed": [["Wu", "Haiyan", ""], ["Yuan", "Ming", ""], ["Kaech", "Susan M.", ""], ["Halloran", "M. Elizabeth", ""]]}, {"id": "0712.1425", "submitter": "Gareth M. James", "authors": "Gareth M. James", "title": "Curve alignment by moments", "comments": "Published in at http://dx.doi.org/10.1214/07-AOAS127 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2007, Vol. 1, No. 2, 480-501", "doi": "10.1214/07-AOAS127", "report-no": "IMS-AOAS-AOAS127", "categories": "stat.AP", "license": null, "abstract": "  A significant problem with most functional data analyses is that of\nmisaligned curves. Without adjustment, even an analysis as simple as estimation\nof the mean will fail. One common method to synchronize a set of curves\ninvolves equating ``landmarks'' such as peaks or troughs. The landmarks method\ncan work well but will fail if marker events can not be identified or are\nmissing from some curves. An alternative approach, the ``continuous monotone\nregistration'' method, works by transforming the curves so that they are as\nclose as possible to a target function. This method can also perform well but\nis highly dependent on identifying an accurate target function. We develop an\nalignment method based on equating the ``moments'' of a given set of curves.\nThese moments are intended to capture the locations of important features which\nmay represent local behavior, such as maximums and minimums, or more global\ncharacteristics, such as the slope of the curve averaged over time. Our method\nworks by equating the moments of the curves while also shrinking toward a\ncommon shape. This allows us to capture the advantages of both the landmark and\ncontinuous monotone registration approaches. The method is illustrated on\nseveral data sets and a simulation study is performed.\n", "versions": [{"version": "v1", "created": "Mon, 10 Dec 2007 10:37:58 GMT"}], "update_date": "2007-12-18", "authors_parsed": [["James", "Gareth M.", ""]]}, {"id": "0712.1458", "submitter": "Ji Meng Loh", "authors": "Ji Meng Loh, Zhengyuan Zhu", "title": "Accounting for spatial correlation in the scan statistic", "comments": "Published in at http://dx.doi.org/10.1214/07-AOAS129 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2007, Vol. 1, No. 2, 560-584", "doi": "10.1214/07-AOAS129", "report-no": "IMS-AOAS-AOAS129", "categories": "stat.AP", "license": null, "abstract": "  The spatial scan statistic is widely used in epidemiology and medical studies\nas a tool to identify hotspots of diseases. The classical spatial scan\nstatistic assumes the number of disease cases in different locations have\nindependent Poisson distributions, while in practice the data may exhibit\noverdispersion and spatial correlation. In this work, we examine the behavior\nof the spatial scan statistic when overdispersion and spatial correlation are\npresent, and propose a modified spatial scan statistic to account for that.\nSome theoretical results are provided to demonstrate that ignoring the\noverdispersion and spatial correlation leads to an increased rate of false\npositives, which is verified through a simulation study. Simulation studies\nalso show that our modified procedure can substantially reduce the rate of\nfalse alarms. Two data examples involving brain cancer cases in New Mexico and\nchickenpox incidence data in France are used to illustrate the practical\nrelevance of the modified procedure.\n", "versions": [{"version": "v1", "created": "Mon, 10 Dec 2007 12:30:09 GMT"}], "update_date": "2009-09-29", "authors_parsed": [["Loh", "Ji Meng", ""], ["Zhu", "Zhengyuan", ""]]}, {"id": "0712.1477", "submitter": "Marc Artzrouni", "authors": "Marc Artzrouni (LMA - Pau)", "title": "Crossing paths in 2D Random Walks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": null, "abstract": "  We investigate crossing path probabilities for two agents that move randomly\nin a bounded region of the plane or on a sphere (denoted $R$). At each discrete\ntime-step the agents move, independently, fixed distances $d_1$ and $d_2$ at\nangles that are uniformly distributed in $(0,2\\pi)$. If $R$ is large enough and\nthe initial positions of the agents are uniformly distributed in $R$, then the\nprobability of paths crossing at the first time-step is close to $ 2d_1d_2/(\\pi\nA[R])$, where $A[R]$ is the area of $R$. Simulations suggest that the long-run\nrate at which paths cross is also close to $2d_1d_2/(\\pi A[R])$ (despite marked\ndepartures from uniformity and independence conditions needed for such a\nconclusion).\n", "versions": [{"version": "v1", "created": "Mon, 10 Dec 2007 13:55:15 GMT"}], "update_date": "2009-09-29", "authors_parsed": [["Artzrouni", "Marc", "", "LMA - Pau"]]}, {"id": "0712.1486", "submitter": "David M. Blei", "authors": "David M. Blei, John D. Lafferty", "title": "Correction: A correlated topic model of Science", "comments": "Published in at http://dx.doi.org/10.1214/07-AOAS136 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2007, Vol. 1, No. 2, 634-634", "doi": "10.1214/07-AOAS136", "report-no": "IMS-AOAS-AOAS136", "categories": "stat.AP", "license": null, "abstract": "  Correction to Annals of Applied Statistics 1 (2007) 17--35\n[doi:10.1214/07-AOAS114]\n", "versions": [{"version": "v1", "created": "Mon, 10 Dec 2007 14:16:00 GMT"}], "update_date": "2009-09-29", "authors_parsed": [["Blei", "David M.", ""], ["Lafferty", "John D.", ""]]}, {"id": "0712.1663", "submitter": "Nicolai Meinshausen", "authors": "Nicolai Meinshausen, Peter Bickel, John Rice", "title": "Efficient blind search: Optimal power of detection under computational\n  cost constraints", "comments": "Published in at http://dx.doi.org/10.1214/08-AOAS180 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2009, Vol. 3, No. 1, 38-60", "doi": "10.1214/08-AOAS180", "report-no": "IMS-AOAS-AOAS180", "categories": "stat.ME stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Some astronomy projects require a blind search through a vast number of\nhypotheses to detect objects of interest. The number of hypotheses to test can\nbe in the billions. A naive blind search over every single hypothesis would be\nfar too costly computationally. We propose a hierarchical scheme for blind\nsearch, using various \"resolution\" levels. At lower resolution levels,\n\"regions\" of interest in the search space are singled out with a low\ncomputational cost. These regions are refined at intermediate resolution levels\nand only the most promising candidates are finally tested at the original fine\nresolution. The optimal search strategy is found by dynamic programming. We\ndemonstrate the procedure for pulsar search from satellite gamma-ray\nobservations and show that the power of the naive blind search can almost be\nmatched with the hierarchical scheme while reducing the computational burden by\nmore than three orders of magnitude.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2007 09:04:06 GMT"}, {"version": "v2", "created": "Tue, 12 Feb 2008 15:21:17 GMT"}, {"version": "v3", "created": "Sun, 1 Jun 2008 12:41:21 GMT"}, {"version": "v4", "created": "Fri, 15 May 2009 09:48:10 GMT"}], "update_date": "2009-05-15", "authors_parsed": [["Meinshausen", "Nicolai", ""], ["Bickel", "Peter", ""], ["Rice", "John", ""]]}, {"id": "0712.1943", "submitter": "Hua Tang", "authors": "Marc Coram, Hua Tang", "title": "Improving population-specific allele frequency estimates by adapting\n  supplemental data: an empirical Bayes approach", "comments": "Published in at http://dx.doi.org/10.1214/07-AOAS121 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2007, Vol. 1, No. 2, 459-479", "doi": "10.1214/07-AOAS121", "report-no": "IMS-AOAS-AOAS121", "categories": "stat.AP", "license": null, "abstract": "  Estimation of the allele frequency at genetic markers is a key ingredient in\nbiological and biomedical research, such as studies of human genetic variation\nor of the genetic etiology of heritable traits. As genetic data becomes\nincreasingly available, investigators face a dilemma: when should data from\nother studies and population subgroups be pooled with the primary data? Pooling\nadditional samples will generally reduce the variance of the frequency\nestimates; however, used inappropriately, pooled estimates can be severely\nbiased due to population stratification. Because of this potential bias, most\ninvestigators avoid pooling, even for samples with the same ethnic background\nand residing on the same continent. Here, we propose an empirical Bayes\napproach for estimating allele frequencies of single nucleotide polymorphisms.\nThis procedure adaptively incorporates genotypes from related samples, so that\nmore similar samples have a greater influence on the estimates. In every\nexample we have considered, our estimator achieves a mean squared error (MSE)\nthat is smaller than either pooling or not, and sometimes substantially\nimproves over both extremes. The bias introduced is small, as is shown by a\nsimulation study that is carefully matched to a real data example. Our method\nis particularly useful when small groups of individuals are genotyped at a\nlarge number of markers, a situation we are likely to encounter in a\ngenome-wide association study.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2007 14:22:44 GMT"}], "update_date": "2007-12-18", "authors_parsed": [["Coram", "Marc", ""], ["Tang", "Hua", ""]]}, {"id": "0712.1962", "submitter": "Galit Shmueli", "authors": "Galit Shmueli, Ralph P. Russo, Wolfgang Jank", "title": "The BARISTA: A model for bid arrivals in online auctions", "comments": "Published in at http://dx.doi.org/10.1214/07-AOAS117 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2007, Vol. 1, No. 2, 412-441", "doi": "10.1214/07-AOAS117", "report-no": "IMS-AOAS-AOAS117", "categories": "stat.AP", "license": null, "abstract": "  The arrival process of bidders and bids in online auctions is important for\nstudying and modeling supply and demand in the online marketplace. A popular\nassumption in the online auction literature is that a Poisson bidder arrival\nprocess is a reasonable approximation. This approximation underlies theoretical\nderivations, statistical models and simulations used in field studies. However,\nwhen it comes to the bid arrivals, empirical research has shown that the\nprocess is far from Poisson, with early bidding and last-moment bids taking\nplace. An additional feature that has been reported by various authors is an\napparent self-similarity in the bid arrival process. Despite the wide evidence\nfor the changing bidding intensities and the self-similarity, there has been no\nrigorous attempt at developing a model that adequately approximates bid\narrivals and accounts for these features. The goal of this paper is to\nintroduce a family of distributions that well-approximate the bid time\ndistribution in hard-close auctions. We call this the BARISTA process (Bid\nARrivals In STAges) because of its ability to generate different intensities at\ndifferent stages. We describe the properties of this model, show how to\nsimulate bid arrivals from it, and how to use it for estimation and inference.\nWe illustrate its power and usefulness by fitting simulated and real data from\neBay.com. Finally, we show how a Poisson bidder arrival process relates to a\nBARISTA bid arrival process.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2007 15:58:46 GMT"}], "update_date": "2007-12-18", "authors_parsed": [["Shmueli", "Galit", ""], ["Russo", "Ralph P.", ""], ["Jank", "Wolfgang", ""]]}, {"id": "0712.2088", "submitter": "Byron Bell", "authors": "Byron E. Bell", "title": "Financial Variables Effect on the U.S. Gross Private Domestic Investment\n  (GPDI) 1959-2001", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.GN stat.AP", "license": null, "abstract": "  I studied what role the US stock markets and money markets have possibly\nplayed in the Gross Private Domestic Investment (GPDI) of the United States\nfrom the year 1959 to the year 2001, Gross Private Domestic Investment refers\nto the total amount of investment spending by businesses and firms located\nwithin the borders of a nation. It includes both the values of the purchases of\nnon-residential fixed investment, which include capital goods used for\nproduction, and the values of the purchases of residential fixed investment,\nwhich include construction spending for factories or offices. And I created a\nMultiple Linear Regression Model of the GDPI. To see if companies and private\ncitizens use the stock market and money markets as a way of financing capital\nprojects (business ventures, buying commercial and noncommercial property,\netc).\n  Keywords: Gross Private Domestic Investment, Pearson Correlation, SP 500, TB3\n", "versions": [{"version": "v1", "created": "Thu, 13 Dec 2007 04:05:17 GMT"}], "update_date": "2008-12-02", "authors_parsed": [["Bell", "Byron E.", ""]]}, {"id": "0712.2115", "submitter": "Zhijin Wu", "authors": "Zhijin Wu, Rafael A. Irizarry", "title": "A statistical framework for the analysis of microarray probe-level data", "comments": "Published in at http://dx.doi.org/10.1214/07-AOAS116 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2007, Vol. 1, No. 2, 333-357", "doi": "10.1214/07-AOAS116", "report-no": "IMS-AOAS-AOAS116", "categories": "stat.AP", "license": null, "abstract": "  In microarray technology, a number of critical steps are required to convert\nthe raw measurements into the data relied upon by biologists and clinicians.\nThese data manipulations, referred to as preprocessing, influence the quality\nof the ultimate measurements and studies that rely upon them. Standard\noperating procedure for microarray researchers is to use preprocessed data as\nthe starting point for the statistical analyses that produce reported results.\nThis has prevented many researchers from carefully considering their choice of\npreprocessing methodology. Furthermore, the fact that the preprocessing step\naffects the stochastic properties of the final statistical summaries is often\nignored. In this paper we propose a statistical framework that permits the\nintegration of preprocessing into the standard statistical analysis flow of\nmicroarray data. This general framework is relevant in many microarray\nplatforms and motivates targeted analysis methods for specific applications. We\ndemonstrate its usefulness by applying the idea in three different applications\nof the technology.\n", "versions": [{"version": "v1", "created": "Thu, 13 Dec 2007 09:57:57 GMT"}], "update_date": "2009-09-29", "authors_parsed": [["Wu", "Zhijin", ""], ["Irizarry", "Rafael A.", ""]]}, {"id": "0712.2124", "submitter": "Elena A. Erosheva", "authors": "Elena A. Erosheva, Stephen E. Fienberg, Cyrille Joutard", "title": "Describing disability through individual-level mixture models for\n  multivariate binary data", "comments": "Published in at http://dx.doi.org/10.1214/07-AOAS126 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2007, Vol. 1, No. 2, 502-537", "doi": "10.1214/07-AOAS126", "report-no": "IMS-AOAS-AOAS126", "categories": "stat.AP", "license": null, "abstract": "  Data on functional disability are of widespread policy interest in the United\nStates, especially with respect to planning for Medicare and Social Security\nfor a growing population of elderly adults. We consider an extract of\nfunctional disability data from the National Long Term Care Survey (NLTCS) and\nattempt to develop disability profiles using variations of the Grade of\nMembership (GoM) model. We first describe GoM as an individual-level mixture\nmodel that allows individuals to have partial membership in several mixture\ncomponents simultaneously. We then prove the equivalence between\nindividual-level and population-level mixture models, and use this property to\ndevelop a Markov Chain Monte Carlo algorithm for Bayesian estimation of the\nmodel. We use our approach to analyze functional disability data from the\nNLTCS.\n", "versions": [{"version": "v1", "created": "Thu, 13 Dec 2007 10:38:24 GMT"}], "update_date": "2009-09-29", "authors_parsed": [["Erosheva", "Elena A.", ""], ["Fienberg", "Stephen E.", ""], ["Joutard", "Cyrille", ""]]}, {"id": "0712.2130", "submitter": "Andrei Yakovlev", "authors": "Lev Klebanov, Andrei Yakovlev", "title": "Diverse correlation structures in gene expression data and their utility\n  in improving statistical inference", "comments": "Published in at http://dx.doi.org/10.1214/07-AOAS120 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2007, Vol. 1, No. 2, 538-559", "doi": "10.1214/07-AOAS120", "report-no": "IMS-AOAS-AOAS120", "categories": "stat.AP", "license": null, "abstract": "  It is well known that correlations in microarray data represent a serious\nnuisance deteriorating the performance of gene selection procedures. This paper\nis intended to demonstrate that the correlation structure of microarray data\nprovides a rich source of useful information. We discuss distinct correlation\nsubstructures revealed in microarray gene expression data by an appropriate\nordering of genes. These substructures include stochastic proportionality of\nexpression signals in a large percentage of all gene pairs, negative\ncorrelations hidden in ordered gene triples, and a long sequence of weakly\ndependent random variables associated with ordered pairs of genes. The reported\nstriking regularities are of general biological interest and they also have\nfar-reaching implications for theory and practice of statistical methods of\nmicroarray data analysis. We illustrate the latter point with a method for\ntesting differential expression of nonoverlapping gene pairs. While designed\nfor testing a different null hypothesis, this method provides an order of\nmagnitude more accurate control of type 1 error rate compared to conventional\nmethods of individual gene expression profiling. In addition, this method is\nrobust to the technical noise. Quantitative inference of the correlation\nstructure has the potential to extend the analysis of microarray data far\nbeyond currently practiced methods.\n", "versions": [{"version": "v1", "created": "Thu, 13 Dec 2007 11:15:49 GMT"}], "update_date": "2007-12-18", "authors_parsed": [["Klebanov", "Lev", ""], ["Yakovlev", "Andrei", ""]]}, {"id": "0712.2150", "submitter": "Cliff Spiegelman", "authors": "Cliff Spiegelman, William A. Tobin, William D. James, Simon J.\n  Sheather, Stuart Wexler, D. Max Roundhill", "title": "Chemical and forensic analysis of JFK assassination bullet lots: Is a\n  second shooter possible?", "comments": "Published in at http://dx.doi.org/10.1214/07-AOAS119 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2007, Vol. 1, No. 2, 287-301", "doi": "10.1214/07-AOAS119", "report-no": "IMS-AOAS-AOAS119", "categories": "stat.AP", "license": null, "abstract": "  The assassination of President John Fitzgerald Kennedy (JFK) traumatized the\nnation. In this paper we show that evidence used to rule out a second assassin\nis fundamentally flawed. This paper discusses new compositional analyses of\nbullets reportedly to have been derived from the same batch as those used in\nthe assassination. The new analyses show that the bullet fragments involved in\nthe assassination are not nearly as rare as previously reported. In particular,\nthe new test results are compared to key bullet composition testimony presented\nbefore the House Select Committee on Assassinations (HSCA). Matches of bullets\nwithin the same box of bullets are shown to be much more likely than indicated\nin the House Select Committee on Assassinations' testimony. Additionally, we\nshow that one of the ten test bullets is considered a match to one or more\nassassination fragments. This finding means that the bullet fragments from the\nassassination that match could have come from three or more separate bullets.\nFinally, this paper presents a case for reanalyzing the assassination bullet\nfragments and conducting the necessary supporting scientific studies. These\nanalyses will shed light on whether the five bullet fragments constitute three\nor more separate bullets. If the assassination fragments are derived from three\nor more separate bullets, then a second assassin is likely, as the additional\nbullet would not easily be attributable to the main suspect, Mr. Oswald, under\nwidely accepted shooting scenarios [see Posner (1993), Case Closed, Bantam, New\nYork].\n", "versions": [{"version": "v1", "created": "Thu, 13 Dec 2007 13:29:54 GMT"}], "update_date": "2009-09-29", "authors_parsed": [["Spiegelman", "Cliff", ""], ["Tobin", "William A.", ""], ["James", "William D.", ""], ["Sheather", "Simon J.", ""], ["Wexler", "Stuart", ""], ["Roundhill", "D. Max", ""]]}, {"id": "0712.2352", "submitter": "Guido Nolte", "authors": "Guido Nolte, Andreas Ziehe, Vadim V. Nikulin, Alois Schl\\\"ogl, Nicole\n  Kr\\\"amer, Tom Brismar, Klaus-Robert M\\\"uller", "title": "Robustly estimating the flow direction of information in complex\n  physical systems", "comments": "5 pages, 4 figures", "journal-ref": null, "doi": "10.1103/PhysRevLett.100.234101", "report-no": null, "categories": "stat.ME stat.AP", "license": null, "abstract": "  We propose a new measure to estimate the direction of information flux in\nmultivariate time series from complex systems. This measure, based on the slope\nof the phase spectrum (Phase Slope Index) has invariance properties that are\nimportant for applications in real physical or biological systems: (a) it is\nstrictly insensitive to mixtures of arbitrary independent sources, (b) it gives\nmeaningful results even if the phase spectrum is not linear, and (c) it\nproperly weights contributions from different frequencies. Simulations of a\nclass of coupled multivariate random data show that for truly unidirectional\ninformation flow without additional noise contamination our measure detects the\ncorrect direction as good as the standard Granger causality. For random\nmixtures of independent sources Granger Causality erroneously yields highly\nsignificant results whereas our measure correctly becomes non-significant. An\napplication of our novel method to EEG data (88 subjects in eyes-closed\ncondition) reveals a strikingly clear front-to-back information flow in the\nvast majority of subjects and thus contributes to a better understanding of\ninformation processing in the brain.\n", "versions": [{"version": "v1", "created": "Fri, 14 Dec 2007 16:10:07 GMT"}], "update_date": "2009-11-13", "authors_parsed": [["Nolte", "Guido", ""], ["Ziehe", "Andreas", ""], ["Nikulin", "Vadim V.", ""], ["Schl\u00f6gl", "Alois", ""], ["Kr\u00e4mer", "Nicole", ""], ["Brismar", "Tom", ""], ["M\u00fcller", "Klaus-Robert", ""]]}, {"id": "0712.2708", "submitter": "A. C. Davison", "authors": "A. C. Davison, N. Sartori", "title": "The Banff Challenge: Statistical Detection of a Noisy Signal", "comments": "Published in at http://dx.doi.org/10.1214/08-STS260 the Statistical\n  Science (http://www.imstat.org/sts/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Statistical Science 2008, Vol. 23, No. 3, 354-364", "doi": "10.1214/08-STS260", "report-no": "IMS-STS-STS260", "categories": "stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Particle physics experiments such as those run in the Large Hadron Collider\nresult in huge quantities of data, which are boiled down to a few numbers from\nwhich it is hoped that a signal will be detected. We discuss a simple\nprobability model for this and derive frequentist and noninformative Bayesian\nprocedures for inference about the signal. Both are highly accurate in\nrealistic cases, with the frequentist procedure having the edge for interval\nestimation, and the Bayesian procedure yielding slightly better point\nestimates. We also argue that the significance, or $p$-value, function based on\nthe modified likelihood root provides a comprehensive presentation of the\ninformation in the data and should be used for inference.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2007 12:49:56 GMT"}, {"version": "v2", "created": "Thu, 17 Feb 2011 14:06:16 GMT"}], "update_date": "2011-02-18", "authors_parsed": [["Davison", "A. C.", ""], ["Sartori", "N.", ""]]}, {"id": "0712.3618", "submitter": "Aiyou Chen", "authors": "Aiyou Chen, Jin Cao, and Tian Bu", "title": "Network Tomography: Identifiability and Fourier Domain Estimation", "comments": "21 pages", "journal-ref": "IEEE INFOCOM 2007, p.1875-1883", "doi": "10.1109/INFCOM.2007.218", "report-no": null, "categories": "stat.ME math.ST stat.AP stat.CO stat.TH", "license": null, "abstract": "  The statistical problem for network tomography is to infer the distribution\nof $\\mathbf{X}$, with mutually independent components, from a measurement model\n$\\mathbf{Y}=A\\mathbf{X}$, where $A$ is a given binary matrix representing the\nrouting topology of a network under consideration. The challenge is that the\ndimension of $\\mathbf{X}$ is much larger than that of $\\mathbf{Y}$ and thus the\nproblem is often called ill-posed. This paper studies some statistical aspects\nof network tomography. We first address the identifiability issue and prove\nthat the $\\mathbf{X}$ distribution is identifiable up to a shift parameter\nunder mild conditions. We then use a mixture model of characteristic functions\nto derive a fast algorithm for estimating the distribution of $\\mathbf{X}$\nbased on the General method of Moments. Through extensive model simulation and\nreal Internet trace driven simulation, the proposed approach is shown to be\nfavorable comparing to previous methods using simple discretization for\ninferring link delays in a heterogeneous network.\n", "versions": [{"version": "v1", "created": "Fri, 21 Dec 2007 03:47:28 GMT"}], "update_date": "2007-12-24", "authors_parsed": [["Chen", "Aiyou", ""], ["Cao", "Jin", ""], ["Bu", "Tian", ""]]}, {"id": "0712.4161", "submitter": "Mateusz Pipie\\'n", "authors": "Mateusz Pipien", "title": "On the Empirical Importance of the Conditional Skewness Assumption in\n  Modelling the Relationship Between Risk and Return", "comments": "Presented at 3-rd Symposium on Socio- and Econophysics, FENS2007,\n  Wroclaw 22-24 November 2007", "journal-ref": "Acta Physica Polonica A, 114 (3), 2008, pp. 517 - 524", "doi": null, "report-no": null, "categories": "stat.AP", "license": null, "abstract": "  The main goal of this paper is an application of Bayesian inference in\ntesting the relation between risk and return on the financial instruments. On\nthe basis of the Intertemporal CAPM model we built a general sampling model\nsuitable in analysing such a relationship. The most important feature of our\nassumptions is that the skewness of the conditional distribution of returns is\nused as an alternative source of relation between risk and return. This general\nspecification relates to GARCH-In-Mean model. In order to make conditional\ndistribution of financial returns skewed we considered a constructive approach\nbased on the inverse probability integral transformation. In particular, we\napply the hidden truncation mechanism, two equivalent approaches of the inverse\nscale factors, order statistics concept, Beta and Bernstein distribution\ntransformations, and also the constructive method. Based on the daily excess\nreturns on the Warsaw Stock Exchange Index we checked the empirical importance\nof the conditional skewness assumption on the relation between risk and return\non the Warsaw Stock Market. We present posterior probabilities of all competing\nspecifications as well as the posterior analysis of positive sign of the tested\nrelationship.\n", "versions": [{"version": "v1", "created": "Wed, 26 Dec 2007 23:41:36 GMT"}, {"version": "v2", "created": "Mon, 5 May 2008 17:53:41 GMT"}, {"version": "v3", "created": "Tue, 6 May 2008 15:28:39 GMT"}], "update_date": "2008-10-06", "authors_parsed": [["Pipien", "Mateusz", ""]]}, {"id": "0712.4290", "submitter": "Adom Giffin", "authors": "Adom Giffin", "title": "Updating Probabilities: A Complex Agent Based Example", "comments": "Presented at the 7th International Conference on Complex Systems,\n  Boston, 2007. 9 pages, 1 figure", "journal-ref": "InterJournal of Complex Systems, 2273 (2008)", "doi": null, "report-no": null, "categories": "stat.ME cond-mat.stat-mech nlin.AO physics.bio-ph physics.data-an q-bio.MN stat.AP", "license": null, "abstract": "  It has been shown that one can accommodate data (Bayes) and constraints\n(MaxEnt) in one method, the method of Maximum (relative) Entropy (ME) (Giffin\n2007). In this paper we show a complex agent based example of inference with\ntwo different forms of information; moments and data. In this example, several\nagents each receive partial information about a system in the form of data. In\naddition, each agent agrees or is informed that there are certain global\nconstraints on the system that are always true. The agents are then asked to\nmake inferences about the entire system. The system becomes more complex as we\nadd agents and allow them to share information. This system can have a\ngeometrical form, such as a crystal structure. The shape may dictate how the\nagents are able to share information, such as sharing with nearest neighbors.\nThis method can be used to model many systems where the agents or cells have\nlocal or partial information but must adhere to some global rules. This could\nalso illustrate how the agents evolve and could illuminate emergent behavior of\nthe system.\n", "versions": [{"version": "v1", "created": "Thu, 27 Dec 2007 22:15:49 GMT"}], "update_date": "2016-09-08", "authors_parsed": [["Giffin", "Adom", ""]]}]