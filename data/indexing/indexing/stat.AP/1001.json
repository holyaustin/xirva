[{"id": "1001.0279", "submitter": "Raghunandan Hulikal Keshavan", "authors": "Raghunandan H. Keshavan, Andrea Montanari", "title": "Regularization for Matrix Completion", "comments": "5 pages, 3 figures, Conference Version", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of reconstructing a low rank matrix from noisy\nobservations of a subset of its entries. This task has applications in\nstatistical learning, computer vision, and signal processing. In these\ncontexts, \"noise\" generically refers to any contribution to the data that is\nnot captured by the low-rank model. In most applications, the noise level is\nlarge compared to the underlying signal and it is important to avoid\noverfitting. In order to tackle this problem, we define a regularized cost\nfunction well suited for spectral reconstruction methods. Within a random noise\nmodel, and in the large system limit, we prove that the resulting accuracy\nundergoes a phase transition depending on the noise level and on the fraction\nof observed entries. The cost function can be minimized using OPTSPACE (a\nmanifold gradient descent algorithm). Numerical simulations show that this\napproach is competitive with state-of-the-art alternatives.\n", "versions": [{"version": "v1", "created": "Sat, 2 Jan 2010 04:14:50 GMT"}], "update_date": "2010-01-05", "authors_parsed": [["Keshavan", "Raghunandan H.", ""], ["Montanari", "Andrea", ""]]}, {"id": "1001.0341", "submitter": "Qing Zhou", "authors": "Qing Zhou", "title": "On Weight Matrix and Free Energy Models for Sequence Motif Detection", "comments": "23 pages, 1 figure and 4 tables", "journal-ref": "Journal of Computational Biology, 17 (2010): 1621-1638", "doi": "10.1089/cmb.2009.0142", "report-no": null, "categories": "q-bio.GN stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of motif detection can be formulated as the construction of a\ndiscriminant function to separate sequences of a specific pattern from\nbackground. In computational biology, motif detection is used to predict DNA\nbinding sites of a transcription factor (TF), mostly based on the weight matrix\n(WM) model or the Gibbs free energy (FE) model. However, despite the wide\napplications, theoretical analysis of these two models and their predictions is\nstill lacking. We derive asymptotic error rates of prediction procedures based\non these models under different data generation assumptions. This allows a\ntheoretical comparison between the WM-based and the FE-based predictions in\nterms of asymptotic efficiency. Applications of the theoretical results are\ndemonstrated with empirical studies on ChIP-seq data and protein binding\nmicroarray data. We find that, irrespective of underlying data generation\nmechanisms, the FE approach shows higher or comparable predictive power\nrelative to the WM approach when the number of observed binding sites used for\nconstructing a discriminant decision is not too small.\n", "versions": [{"version": "v1", "created": "Sun, 3 Jan 2010 00:27:13 GMT"}, {"version": "v2", "created": "Sat, 16 Oct 2010 00:19:20 GMT"}], "update_date": "2010-12-10", "authors_parsed": [["Zhou", "Qing", ""]]}, {"id": "1001.0951", "submitter": "Burcu Aydin", "authors": "Burcu Aydin, Gabor Pataki, Haonan Wang, Alim Ladha, Elizabeth Bullitt,\n  J.S. Marron", "title": "Visualizing the Structure of Large Trees", "comments": "17 pages, 8 figures", "journal-ref": "Electronic Journal of Statistics 2011, Vol. 5, 405-420", "doi": "10.1214/11-EJS612", "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study introduces a new method of visualizing complex tree structured\nobjects. The usefulness of this method is illustrated in the context of\ndetecting unexpected features in a data set of very large trees. The major\ncontribution is a novel two-dimensional graphical representation of each tree,\nwith a covariate coded by color. The motivating data set contains three\ndimensional representations of brain artery systems of 105 subjects. Due to\ninaccuracies inherent in the medical imaging techniques, issues with the\nreconstruction algo- rithms and inconsistencies introduced by manual\nadjustment, various discrepancies are present in the data. The proposed\nrepresentation enables quick visual detection of the most common discrepancies.\nFor our driving example, this tool led to the modification of 10% of the artery\ntrees and deletion of 6.7%. The benefits of our cleaning method are\ndemonstrated through a statistical hypothesis test on the effects of aging on\nvessel structure. The data cleaning resulted in improved significance levels.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jan 2010 19:19:49 GMT"}, {"version": "v2", "created": "Mon, 11 Jan 2010 19:53:43 GMT"}], "update_date": "2012-02-14", "authors_parsed": [["Aydin", "Burcu", ""], ["Pataki", "Gabor", ""], ["Wang", "Haonan", ""], ["Ladha", "Alim", ""], ["Bullitt", "Elizabeth", ""], ["Marron", "J. S.", ""]]}, {"id": "1001.1049", "submitter": "Bertrand Iooss", "authors": "Bertrand Iooss (M\\'ethodes d'Analyse Stochastique des Codes et\n  Traitements Num\\'eriques), Lo\\\"ic Boussouf, Vincent Feuillard, Amandine\n  Marrel (IFP)", "title": "Numerical studies of the metamodel fitting and validation processes", "comments": null, "journal-ref": "International Journal of Advances in Systems and Measurements 3\n  (2010) 11-21", "doi": null, "report-no": null, "categories": "math.NA math.ST stat.AP stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complex computer codes, for instance simulating physical phenomena, are often\ntoo time expensive to be directly used to perform uncertainty, sensitivity,\noptimization and robustness analyses. A widely accepted method to circumvent\nthis problem consists in replacing cpu time expensive computer models by cpu\ninexpensive mathematical functions, called metamodels. In this paper, we focus\non the Gaussian process metamodel and two essential steps of its definition\nphase. First, the initial design of the computer code input variables (which\nallows to fit the metamodel) has to honor adequate space filling properties. We\nadopt a numerical approach to compare the performance of different types of\nspace filling designs, in the class of the optimal Latin hypercube samples, in\nterms of the predictivity of the subsequent fitted metamodel. We conclude that\nsuch samples with minimal wrap-around discrepancy are particularly well-suited\nfor the Gaussian process metamodel fitting. Second, the metamodel validation\nprocess consists in evaluating the metamodel predictivity with respect to the\ninitial computer code. We propose and test an algorithm which optimizes the\ndistance between the validation points and the metamodel learning points in\norder to estimate the true metamodel predictivity with a minimum number of\nvalidation points. Comparisons with classical validation algorithms and\napplication to a nuclear safety computer code show the relevance of this new\nsequential validation design.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jan 2010 10:43:51 GMT"}, {"version": "v2", "created": "Thu, 23 Sep 2010 11:51:41 GMT"}], "update_date": "2011-04-22", "authors_parsed": [["Iooss", "Bertrand", "", "M\u00e9thodes d'Analyse Stochastique des Codes et\n  Traitements Num\u00e9riques"], ["Boussouf", "Lo\u00efc", "", "IFP"], ["Feuillard", "Vincent", "", "IFP"], ["Marrel", "Amandine", "", "IFP"]]}, {"id": "1001.1831", "submitter": "Ansgar Steland", "authors": "Ansgar Steland", "title": "Monitoring Procedures to Detect Unit Roots and Stationarity", "comments": null, "journal-ref": "Econometric Theory 2007, 23 (6), 1108-1135", "doi": null, "report-no": null, "categories": "math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When analysing time series an important issue is to decide whether the time\nseries is stationary or a random walk. Relaxing these notions, we consider the\nproblem to decide in favor of the I(0)- or I(1)-property. Fixed-sample\nstatistical tests for that problem are well studied in the literature. In this\npaper we provide first results for the problem to monitor sequentially a time\nseries. Our stopping times are based on a sequential version of a\nkernel-weighted variance-ratio statistic. The asymptotic distributions are\nestablished for I(1) processes, a rich class of stationary processes, possibly\naffected by local nonpara- metric alternatives, and the local-to-unity model.\nFurther, we consider the two interesting change-point models where the time\nseries changes its behaviour after a certain fraction of the observations and\nderive the associated limiting laws. Our Monte-Carlo studies show that the\nproposed detection procedures have high power when interpreted as a hypothesis\ntest, and that the decision can often be made very early.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jan 2010 09:45:20 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Steland", "Ansgar", ""]]}, {"id": "1001.1841", "submitter": "Ansgar Steland", "authors": "Ansgar Steland, Ewaryst Rafalowicz", "title": "A Binary Control Chart to Detect Small Jumps", "comments": null, "journal-ref": "Statistics 2009, 43 (3), 295-311", "doi": null, "report-no": null, "categories": "stat.ME stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The classic N p chart gives a signal if the number of successes in a sequence\nof inde- pendent binary variables exceeds a control limit. Motivated by\nengineering applications in industrial image processing and, to some extent,\nfinancial statistics, we study a simple modification of this chart, which uses\nonly the most recent observations. Our aim is to construct a control chart for\ndetecting a shift of an unknown size, allowing for an unknown distribution of\nthe error terms. Simulation studies indicate that the proposed chart is su-\nperior in terms of out-of-control average run length, when one is interest in\nthe detection of very small shifts. We provide a (functional) central limit\ntheorem under a change-point model with local alternatives which explains that\nunexpected and interesting behavior. Since real observations are often not\nindependent, the question arises whether these re- sults still hold true for\nthe dependent case. Indeed, our asymptotic results work under the fairly\ngeneral condition that the observations form a martingale difference array.\nThis enlarges the applicability of our results considerably, firstly, to a\nlarge class time series models, and, secondly, to locally dependent image data,\nas we demonstrate by an example.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jan 2010 10:43:50 GMT"}], "update_date": "2010-01-13", "authors_parsed": [["Steland", "Ansgar", ""], ["Rafalowicz", "Ewaryst", ""]]}, {"id": "1001.2136", "submitter": "Serena Arima", "authors": "Serena Arima and Luca Tardella", "title": "An alternative marginal likelihood estimator for phylogenetic models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO q-bio.QM stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian phylogenetic methods are generating noticeable enthusiasm in the\nfield of molecular systematics. Many phylogenetic models are often at stake and\ndifferent approaches are used to compare them within a Bayesian framework. The\nBayes factor, defined as the ratio of the marginal likelihoods of two competing\nmodels, plays a key role in Bayesian model selection. We focus on an\nalternative estimator of the marginal likelihood whose computation is still a\nchallenging problem. Several computational solutions have been proposed none of\nwhich can be considered outperforming the others simultaneously in terms of\nsimplicity of implementation, computational burden and precision of the\nestimates. Practitioners and researchers, often led by available software, have\nprivileged so far the simplicity of the harmonic mean estimator (HM) and the\narithmetic mean estimator (AM). However it is known that the resulting\nestimates of the Bayesian evidence in favor of one model are biased and often\ninaccurate up to having an infinite variance so that the reliability of the\ncorresponding conclusions is doubtful. Our new implementation of the\ngeneralized harmonic mean (GHM) idea recycles MCMC simulations from the\nposterior, shares the computational simplicity of the original HM estimator,\nbut, unlike it, overcomes the infinite variance issue. The alternative\nestimator is applied to simulated phylogenetic data and produces fully\nsatisfactory results outperforming those simple estimators currently provided\nby most of the publicly available software.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jan 2010 12:06:44 GMT"}, {"version": "v2", "created": "Sun, 20 Jun 2010 13:18:50 GMT"}], "update_date": "2010-06-22", "authors_parsed": [["Arima", "Serena", ""], ["Tardella", "Luca", ""]]}, {"id": "1001.2615", "submitter": "Ryota Tomioka", "authors": "Ryota Tomioka, Taiji Suzuki", "title": "Sparsity-accuracy trade-off in MKL", "comments": "8pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We empirically investigate the best trade-off between sparse and\nuniformly-weighted multiple kernel learning (MKL) using the elastic-net\nregularization on real and simulated datasets. We find that the best trade-off\nparameter depends not only on the sparsity of the true kernel-weight spectrum\nbut also on the linear dependence among kernels and the number of samples.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jan 2010 05:53:23 GMT"}], "update_date": "2010-01-18", "authors_parsed": [["Tomioka", "Ryota", ""], ["Suzuki", "Taiji", ""]]}, {"id": "1001.3006", "submitter": "Markus Rei{\\ss}", "authors": "Markus Rei\\ss", "title": "Asymptotic equivalence and sufficiency for volatility estimation under\n  microstructure noise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR q-fin.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The basic model for high-frequency data in finance is considered, where an\nefficient price process is observed under microstructure noise. It is shown\nthat this nonparametric model is in Le Cam's sense asymptotically equivalent to\na Gaussian shift experiment in terms of the square root of the volatility\nfunction $\\sigma$. As an application, simple rate-optimal estimators of the\nvolatility and efficient estimators of the integrated volatility are\nconstructed.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jan 2010 10:17:42 GMT"}], "update_date": "2010-01-25", "authors_parsed": [["Rei\u00df", "Markus", ""]]}, {"id": "1001.3109", "submitter": "Anne-Claire Haury", "authors": "Anne-Claire Haury (CBIO), Laurent Jacob (CBIO), Jean-Philippe Vert\n  (CBIO)", "title": "Increasing stability and interpretability of gene expression signatures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML q-bio.GN q-bio.QM stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivation : Molecular signatures for diagnosis or prognosis estimated from\nlarge-scale gene expression data often lack robustness and stability, rendering\ntheir biological interpretation challenging. Increasing the signature's\ninterpretability and stability across perturbations of a given dataset and, if\npossible, across datasets, is urgently needed to ease the discovery of\nimportant biological processes and, eventually, new drug targets. Results : We\npropose a new method to construct signatures with increased stability and\neasier interpretability. The method uses a gene network as side interpretation\nand enforces a large connectivity among the genes in the signature, leading to\nsignatures typically made of genes clustered in a few subnetworks. It combines\nthe recently proposed graph Lasso procedure with a stability selection\nprocedure. We evaluate its relevance for the estimation of a prognostic\nsignature in breast cancer, and highlight in particular the increase in\ninterpretability and stability of the signature.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jan 2010 19:41:43 GMT"}], "update_date": "2010-01-19", "authors_parsed": [["Haury", "Anne-Claire", "", "CBIO"], ["Jacob", "Laurent", "", "CBIO"], ["Vert", "Jean-Philippe", "", "CBIO"]]}, {"id": "1001.3355", "submitter": "Charles Sutton", "authors": "Charles Sutton, Michael I. Jordan", "title": "Bayesian inference for queueing networks and modeling of internet\n  services", "comments": "Published in at http://dx.doi.org/10.1214/10-AOAS392 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2011, Vol. 5, No. 1, 254-282", "doi": "10.1214/10-AOAS392", "report-no": "IMS-AOAS-AOAS392", "categories": "stat.ML cs.NI cs.PF stat.AP stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern Internet services, such as those at Google, Yahoo!, and Amazon, handle\nbillions of requests per day on clusters of thousands of computers. Because\nthese services operate under strict performance requirements, a statistical\nunderstanding of their performance is of great practical interest. Such\nservices are modeled by networks of queues, where each queue models one of the\ncomputers in the system. A key challenge is that the data are incomplete,\nbecause recording detailed information about every request to a heavily used\nsystem can require unacceptable overhead. In this paper we develop a Bayesian\nperspective on queueing models in which the arrival and departure times that\nare not observed are treated as latent variables. Underlying this viewpoint is\nthe observation that a queueing model defines a deterministic transformation\nbetween the data and a set of independent variables called the service times.\nWith this viewpoint in hand, we sample from the posterior distribution over\nmissing data and model parameters using Markov chain Monte Carlo. We evaluate\nour framework on data from a benchmark Web application. We also present a\nsimple technique for selection among nested queueing models. We are unaware of\nany previous work that considers inference in networks of queues in the\npresence of missing data.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jan 2010 16:27:13 GMT"}, {"version": "v2", "created": "Wed, 4 Aug 2010 15:34:17 GMT"}, {"version": "v3", "created": "Fri, 15 Apr 2011 06:03:52 GMT"}], "update_date": "2011-04-18", "authors_parsed": [["Sutton", "Charles", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1001.3895", "submitter": "Lei Qi", "authors": "Lei Qi, Dacheng Xiu and Jianqing Fan", "title": "Non-Gaussian Quasi Maximum Likelihood Estimation of GARCH Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The non-Gaussian quasi maximum likelihood estimator is frequently used in\nGARCH models with intension to improve the efficiency of the GARCH parameters.\nHowever, unless the quasi-likelihood happens to be the true one, non-Gaussian\nQMLE methods suffers inconsistency even if shape parameters in the\nquasi-likelihood are estimated. To correct this bias, we identify an unknown\nscale parameter that is critical to the consistent estimation of non-Gaussian\nQMLE, and propose a two-step non-Gaussian QMLE (2SNG-QMLE) for estimation of\nthe scale parameter and GARCH parameters. This novel approach is consistent and\nasymptotically normal. Moreover, it has higher efficiency than the Gaussian\nQMLE, particularly when the innovation error has heavy tails. Two extensions\nare proposed to further improve the efficiency of 2SNG-QMLE. The impact of\nrelative heaviness of tails of the innovation and quasi-likelihood\ndistributions on the asymptotic efficiency has been thoroughly investigated.\nMonte Carlo simulations and an empirical study confirm the advantages of the\nproposed approach.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jan 2010 22:24:44 GMT"}, {"version": "v2", "created": "Mon, 14 Jun 2010 00:56:37 GMT"}], "update_date": "2010-06-15", "authors_parsed": [["Qi", "Lei", ""], ["Xiu", "Dacheng", ""], ["Fan", "Jianqing", ""]]}, {"id": "1001.3907", "submitter": "Aleksandr Aravkin", "authors": "Aleksandr Y. Aravkin, James V. Burke, Gianluigi Pillonetto", "title": "Robust and Trend-following Kalman Smoothers using Student's t", "comments": "7 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO math.OC stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose two nonlinear Kalman smoothers that rely on Student's t\ndistributions. The T-Robust smoother finds the maximum a posteriori likelihood\n(MAP) solution for Gaussian process noise and Student's t observation noise,\nand is extremely robust against outliers, outperforming the recently proposed\nl1-Laplace smoother in extreme situations (e.g. 50% or more outliers). The\nsecond estimator, which we call the T-Trend smoother, is able to follow sudden\nchanges in the process model, and is derived as a MAP solver for a model with\nStudent's t-process noise and Gaussian observation noise. We design specialized\nmethods to solve both problems which exploit the special structure of the\nStudent's t-distribution, and provide a convergence theory. Both smoothers can\nbe implemented with only minor modifications to an existing L2 smoother\nimplementation. Numerical results for linear and nonlinear models illustrating\nboth robust and fast tracking applications are presented.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jan 2010 02:48:12 GMT"}, {"version": "v2", "created": "Sat, 5 Jun 2010 08:56:39 GMT"}, {"version": "v3", "created": "Fri, 11 Nov 2011 12:43:55 GMT"}], "update_date": "2011-11-14", "authors_parsed": [["Aravkin", "Aleksandr Y.", ""], ["Burke", "James V.", ""], ["Pillonetto", "Gianluigi", ""]]}, {"id": "1001.4208", "submitter": "Abel Rodriguez", "authors": "Abel Rodriguez, Alex Lenkoski and Adrian Dobra", "title": "Sparse covariance estimation in heterogeneous samples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.AP stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard Gaussian graphical models (GGMs) implicitly assume that the\nconditional independence among variables is common to all observations in the\nsample. However, in practice, observations are usually collected form\nheterogeneous populations where such assumption is not satisfied, leading in\nturn to nonlinear relationships among variables. To tackle these problems we\nexplore mixtures of GGMs; in particular, we consider both infinite mixture\nmodels of GGMs and infinite hidden Markov models with GGM emission\ndistributions. Such models allow us to divide a heterogeneous population into\nhomogenous groups, with each cluster having its own conditional independence\nstructure. The main advantage of considering infinite mixtures is that they\nallow us easily to estimate the number of number of subpopulations in the\nsample. As an illustration, we study the trends in exchange rate fluctuations\nin the pre-Euro era. This example demonstrates that the models are very\nflexible while providing extremely interesting interesting insights into\nreal-life applications.\n", "versions": [{"version": "v1", "created": "Sat, 23 Jan 2010 21:49:00 GMT"}], "update_date": "2010-01-26", "authors_parsed": [["Rodriguez", "Abel", ""], ["Lenkoski", "Alex", ""], ["Dobra", "Adrian", ""]]}, {"id": "1001.4639", "submitter": "Stefano Andreon", "authors": "S. Andreon (1), M. A. Hurn (2) ((1) INAF-OA Brera, (2) Bath Univ.,\n  Math Dept.)", "title": "The scaling relation between richness and mass of galaxy clusters: a\n  Bayesian approach", "comments": "MNRAS, in press", "journal-ref": null, "doi": "10.1111/j.1365-2966.2010.16406.x", "report-no": null, "categories": "astro-ph.CO astro-ph.IM stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use a sample of 53 galaxy clusters at 0.03 < z < 0.1 with available masses\nderived from the caustic technique and with velocity dispersions computed using\n208 galaxies on average per cluster, in order to investigate the scaling\nbetween richness, mass and velocity dispersion. A tight scaling between\nrichness and mass is found, with an intrinsic scatter of only 0.19 dex in mass\nand with a slope one, i.e. clusters which have twice as many galaxies are twice\nas massive. When richness is measured without any knowledge of the cluster mass\nor linked parameters (such as r200), it can predict mass with an uncertainty of\n0.29+/-0.01 dex. As a mass proxy, richness competes favourably with both direct\nmeasurements of mass given by the caustic method, which has typically 0.14 dex\nerrors (vs 0.29) and X-ray luminosity, which offers a similar 0.30 dex\nuncertainty. The similar performances of X-ray luminosity and richness in\npredicting cluster masses has been confirmed using cluster masses derived from\nvelocity dispersion fixed by numerical simulations. These results suggest that\ncluster masses can be reliably estimated from simple galaxy counts, at least at\nthe redshift and masses explored in this work. This has important applications\nin the estimation of cosmological parameters from optical cluster surveys,\nbecause in current surveys clusters detected in the optical range outnumber, by\nat least one order of magnitude, those detected in X-ray. Our analysis is\nrobust from astrophysical and statistical perspectives. The data and code used\nfor the stochastic computation is distributed with the paper. [Abridged]\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2010 10:23:04 GMT"}], "update_date": "2015-05-18", "authors_parsed": [["Andreon", "S.", ""], ["Hurn", "M. A.", ""]]}, {"id": "1001.4762", "submitter": "Peijie Wang", "authors": "Peijie Wang, Trefor Jones", "title": "A Spectral Analysis of Business Cycle Patterns in UK Sectoral Output", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.GN q-fin.ST stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies business cycle patterns in UK sectoral output. It analyzes\nthe distinction between white noise processes and their non-white noise\ncounterparts in the frequency domain and further examines the associated\nfeatures and patterns for the process where white noise conditions are\nviolated. The characteristics of these sectors, arising from their\ninstitutional features that may influence business cycles behavior and\npatterns, are discussed. The study then investigates the output of UK GDP\nsectors empirically, revealing their similarities and differences in their\nbusiness cycle patterns.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2010 18:20:44 GMT"}], "update_date": "2010-01-27", "authors_parsed": [["Wang", "Peijie", ""], ["Jones", "Trefor", ""]]}]