[{"id": "1101.0122", "submitter": "Martin Ehler", "authors": "Martin Ehler and Jennifer Galanis", "title": "Frame theory in directional statistics", "comments": null, "journal-ref": "Stat. Probabil. Lett., vol. 81, no. 8 (2011), 1046-1051", "doi": "10.1016/j.spl.2011.02.027", "report-no": null, "categories": "stat.AP cond-mat.soft", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distinguishing between uniform and non-uniform sample distributions is a\ncommon problem in directional data analysis; however for many tests,\nnon-uniform distributions exist that fail uniformity rejection. By merging\ndirectional statistics with frame theory, we find that probabilistic tight\nframes yield non-uniform distributions that minimize directional potentials,\nleading to failure of uniformity rejection for the Bingham test. Finally, we\napply our results to model patterns found in granular rod experiments.\n", "versions": [{"version": "v1", "created": "Thu, 30 Dec 2010 18:03:59 GMT"}], "update_date": "2011-08-11", "authors_parsed": [["Ehler", "Martin", ""], ["Galanis", "Jennifer", ""]]}, {"id": "1101.0559", "submitter": "Pierre Andreoletti", "authors": "Pierre Andreoletti (MAPMO), Roland Diel (MAPMO)", "title": "DNA unzipping via stopped birth and death processes with unknown\n  transition probabilities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cond-mat.stat-mech physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we provide an alternative approach to the works of the\nphysicists S. Cocco and R. Monasson about a model of DNA molecules. The aim is\nto predict the sequence of bases by mechanical stimulations. The model\ndescribed by the physicists is a stopped birth and death process with unknown\ntransition probabilities. We consider two models, a discrete in time and a\ncontinuous in time, as general as possible. We show that explicit formula can\nbe obtained for the probability to be wrong for a given estimator, and apply it\nto evaluate the quality of the prediction. Also we add some generalizations\ncomparing to the initial model allowing us to answer some questions asked by\nthe physicists.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jan 2011 16:37:27 GMT"}, {"version": "v2", "created": "Thu, 9 Feb 2012 10:54:41 GMT"}], "update_date": "2012-02-10", "authors_parsed": [["Andreoletti", "Pierre", "", "MAPMO"], ["Diel", "Roland", "", "MAPMO"]]}, {"id": "1101.0632", "submitter": "Doug Speed", "authors": "Doug Speed, Simon Tavar\\'e", "title": "Sparse Partitioning: Nonlinear regression with binary or tertiary\n  predictors, with application to association studies", "comments": "Published in at http://dx.doi.org/10.1214/10-AOAS411 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2011, Vol. 5, No. 2A, 873-893", "doi": "10.1214/10-AOAS411", "report-no": "IMS-AOAS-AOAS411", "categories": "q-bio.QM stat.AP stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents Sparse Partitioning, a Bayesian method for identifying\npredictors that either individually or in combination with others affect a\nresponse variable. The method is designed for regression problems involving\nbinary or tertiary predictors and allows the number of predictors to exceed the\nsize of the sample, two properties which make it well suited for association\nstudies. Sparse Partitioning differs from other regression methods by placing\nno restrictions on how the predictors may influence the response. To compensate\nfor this generality, Sparse Partitioning implements a novel way of exploring\nthe model space. It searches for high posterior probability partitions of the\npredictor set, where each partition defines groups of predictors that jointly\ninfluence the response. The result is a robust method that requires no prior\nknowledge of the true predictor--response relationship. Testing on simulated\ndata suggests Sparse Partitioning will typically match the performance of an\nexisting method on a data set which obeys the existing method's model\nassumptions. When these assumptions are violated, Sparse Partitioning will\ngenerally offer superior performance.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jan 2011 00:43:09 GMT"}, {"version": "v2", "created": "Tue, 30 Aug 2011 06:11:26 GMT"}], "update_date": "2011-08-31", "authors_parsed": [["Speed", "Doug", ""], ["Tavar\u00e9", "Simon", ""]]}, {"id": "1101.0656", "submitter": "Wen-Bo Du", "authors": "Jun Zhang, Xian-Bin Cao, Wen-Bo Du, Kai-Quan Cai", "title": "Evolution of Chinese airport network", "comments": "10 pages, 10 figures, Physica A 389 (2010) 3922-3931", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.SI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid development of economy and the accelerated globalization\nprocess, the aviation industry plays more and more critical role in today's\nworld, in both developed and developing countries. As the infrastructure of\naviation industry, the airport network is one of the most important indicators\nof economic growth. In this paper, we investigate the evolution of Chinese\nairport network (CAN) via complex network theory. It is found that although the\ntopology of CAN remains steady during the past several years, there are many\ndynamic switchings inside the network, which changes the relative relevance of\nairports and airlines. Moreover, we investigate the evolution of traffic flow\n(passengers and cargoes) on CAN. It is found that the traffic keeps growing in\nan exponential form and it has evident seasonal fluctuations. We also found\nthat cargo traffic and passenger traffic are positively related but the\ncorrelations are quite different for different kinds of cities.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jan 2011 05:32:32 GMT"}], "update_date": "2011-01-05", "authors_parsed": [["Zhang", "Jun", ""], ["Cao", "Xian-Bin", ""], ["Du", "Wen-Bo", ""], ["Cai", "Kai-Quan", ""]]}, {"id": "1101.0689", "submitter": "Christine Tuleau-Malot", "authors": "Marie Sauv\\'e and Christine Tuleau-Malot", "title": "Variable selection through CART", "comments": "33 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with variable selection in the regression and binary\nclassification frameworks. It proposes an automatic and exhaustive procedure\nwhich relies on the use of the CART algorithm and on model selection via\npenalization. This work, of theoretical nature, aims at determining adequate\npenalties, i.e. penalties which allow to get oracle type inequalities\njustifying the performance of the proposed procedure. Since the exhaustive\nprocedure can not be executed when the number of variables is too big, a more\npractical procedure is also proposed and still theoretically validated. A\nsimulation study completes the theoretical results.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jan 2011 10:07:55 GMT"}], "update_date": "2011-01-05", "authors_parsed": [["Sauv\u00e9", "Marie", ""], ["Tuleau-Malot", "Christine", ""]]}, {"id": "1101.0788", "submitter": "Andrew C. Thomas", "authors": "Andrew C. Thomas, Joseph K. Blitzstein", "title": "Valued Ties Tell Fewer Lies: Why Not To Dichotomize Network Edges With\n  Thresholds", "comments": "36 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.SI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to conduct analyses of networked systems where connections between\nindividuals take on a range of values - counts, continuous strengths or ordinal\nrankings - a common technique is to dichotomize the data according to their\npositions with respect to a threshold value. However, there are two issues to\nconsider: how the results of the analysis depend on the choice of threshold,\nand what role the presence of noise has on a system with respect to a fixed\nthreshold value. We show that while there are principled criteria of keeping\ninformation from the valued graph in the dichotomized version, they produce\nsuch a wide range of binary graphs that only a fraction of the relevant\ninformation will be kept. Additionally, while dichotomization of predictors in\nlinear models has a known asymptotic efficiency loss, the same process applied\nto network edges in a time series model will lead to an efficiency loss that\ngrows larger as the network increases in size.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jan 2011 18:47:55 GMT"}, {"version": "v2", "created": "Tue, 11 Jan 2011 22:34:41 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Thomas", "Andrew C.", ""], ["Blitzstein", "Joseph K.", ""]]}, {"id": "1101.0917", "submitter": "Adele Cutler", "authors": "Adele Cutler", "title": "Remembering Leo Breiman", "comments": "Published in at http://dx.doi.org/10.1214/10-AOAS427 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2010, Vol. 4, No. 4, 1621-1633", "doi": "10.1214/10-AOAS427", "report-no": "IMS-AOAS-AOAS427", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Leo Breiman was a highly creative, influential researcher with a\ndown-to-earth personal style and an insistence on working on important real\nworld problems and producing useful solutions. This paper is a short review of\nBreiman's extensive contributions to the field of applied statistics.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jan 2011 09:46:38 GMT"}], "update_date": "2011-01-06", "authors_parsed": [["Cutler", "Adele", ""]]}, {"id": "1101.0923", "submitter": "Peter B\\\"{u}hlmann", "authors": "Peter B\\\"uhlmann", "title": "Remembrance of Leo Breiman", "comments": "Published in at http://dx.doi.org/10.1214/10-AOAS381 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2010, Vol. 4, No. 4, 1638-1641", "doi": "10.1214/10-AOAS381", "report-no": "IMS-AOAS-AOAS381", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In 1994, I came to Berkeley and was fortunate to stay there three years,\nfirst as a postdoctoral researcher and then as Neyman Visiting Assistant\nProfessor. For me, this period was a unique opportunity to see other aspects\nand learn many more things about statistics: the Department of Statistics at\nBerkeley was much bigger and hence broader than my home at ETH Z\\\"urich and I\nenjoyed very much that the science was perhaps a bit more speculative. As soon\nas I settled in the department, I tried to get in touch with the local faculty.\nLeo Breiman started a reading group on topics in machine learning and I didn't\nhesitate to participate together with other Ph.D. students. Leo spread a\ntremendous amount of enthusiasm, telling us about the vast opportunity we now\nhad by taking advantage of computational power. Hearing his views and opinions\nand listening to his thoughts and ideas has been very exciting, stimulating and\nentertaining as well. This was my first occasion to get to know Leo. And there\nwas, at least a bit, a vice-versa implication: now, Leo knew my name and who I\nam. Whenever we saw each other on the 4th floor in Evans Hall, I got a very\ngentle smile and \"hello\" from Leo. And in fact, this happened quite often: I\noften walked around while thinking about a problem, and it seemed to me, that\nLeo had a similar habit.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jan 2011 10:13:42 GMT"}], "update_date": "2016-08-14", "authors_parsed": [["B\u00fchlmann", "Peter", ""]]}, {"id": "1101.0929", "submitter": "Michael I. Jordan", "authors": "Michael I. Jordan", "title": "Leo Breiman", "comments": "Published in at http://dx.doi.org/10.1214/10-AOAS387 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2010, Vol. 4, No. 4, 1642-1643", "doi": "10.1214/10-AOAS387", "report-no": "IMS-AOAS-AOAS387", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistics is a uniquely difficult field to convey to the uninitiated. It\nsits astride the abstract and the concrete, the theoretical and the applied. It\nhas a mathematical flavor and yet it is not simply a branch of mathematics. Its\ncore problems blend into those of the disciplines that probe into the nature of\nintelligence and thought, in particular philosophy, psychology and artificial\nintelligence. Debates over foundational issues have waxed and waned, but the\nfield has not yet arrived at a single foundational perspective.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jan 2011 10:23:30 GMT"}], "update_date": "2011-01-06", "authors_parsed": [["Jordan", "Michael I.", ""]]}, {"id": "1101.0934", "submitter": "Jerome H. Friedman", "authors": "Jerome H. Friedman", "title": "Remembering Leo", "comments": "Published in at http://dx.doi.org/10.1214/10-AOAS432 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2010, Vol. 4, No. 4, 1649-1651", "doi": "10.1214/10-AOAS432", "report-no": "IMS-AOAS-AOAS432", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Leo Breiman was a unique character. There will not be another like him. I\nconsider it one of my great fortunes in life to have know and worked with him.\nAlong with John Tukey, Leo had the greatest influence on shaping my approach to\nstatistical problems. I did some of my best work collaborating with Leo, but\nmore importantly, we both had great fun doing it. I look back on those years\nwhen we worked closely together with great fondness and regard them as among\nthe happiest and most fruitful of my professional career.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jan 2011 10:44:43 GMT"}], "update_date": "2011-01-06", "authors_parsed": [["Friedman", "Jerome H.", ""]]}, {"id": "1101.0936", "submitter": "Peter J. Bickel", "authors": "Peter J. Bickel", "title": "Leo Breiman: An important intellectual and personal force in statistics,\n  my life and that of many others", "comments": "Published in at http://dx.doi.org/10.1214/10-AOAS404 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2010, Vol. 4, No. 4, 1634-1637", "doi": "10.1214/10-AOAS404", "report-no": "IMS-AOAS-AOAS404", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  I first met Leo Breiman in 1979 at the beginning of his third career,\nProfessor of Statistics at Berkeley. He obtained his PhD with Lo\\'eve at\nBerkeley in 1957. His first career was as a probabilist in the Mathematics\nDepartment at UCLA. After distinguished research, including the\nShannon--Breiman--MacMillan Theorem and getting tenure, he decided that his\nreal interest was in applied statistics, so he resigned his position at UCLA\nand set up as a consultant. Before doing so he produced two classic texts,\nProbability, now reprinted as a SIAM Classic in Applied Mathematics, and\nStatistics. Both books reflected his strong opinion that intuition and rigor\nmust be combined. He expressed this in his probability book which he viewed as\na combination of his learning the right hand of probability, rigor, from\nLo\\'eve, and the left-hand, intuition, from David Blackwell.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jan 2011 10:51:11 GMT"}], "update_date": "2011-01-06", "authors_parsed": [["Bickel", "Peter J.", ""]]}, {"id": "1101.0941", "submitter": "Charles J. Stone", "authors": "Charles J. Stone", "title": "Selected recollections of my relationship with Leo Breiman", "comments": "Published in at http://dx.doi.org/10.1214/10-AOAS431 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2010, Vol. 4, No. 4, 1652-1655", "doi": "10.1214/10-AOAS431", "report-no": "IMS-AOAS-AOAS431", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During the period 1962--1964, I had a tenure track Assistant Professorship in\nMathematics at Cornell University in Ithaca, New York, where I did research in\nprobability theory, especially on linear diffusion processes. Being somewhat\nlonely there and not liking the cold winter weather, I decided around the\nbeginning of 1964 to try to get a job in the Mathematics Department at UCLA, in\nthe city in which I was born and raised. At that time, Leo Breiman was an\nAssociate Professor in that department. Presumably, he liked my research on\nlinear diffusion processes and other research as well, since the department\noffered me a tenure track Assistant Professorship, which I happily accepted.\nDuring the Summer of 1965, I worked on various projects with Sidney Port, then\nat RAND Corporation, especially on random walks and related material. I was\npromoted to Associate Professor, effective in Fall, 1966, presumably thanks in\npart to Leo. Early in 1966, I~was surprised to be asked by Leo to participate\nin a department meeting called to discuss the possible hiring of Sidney. The\nconclusion was that Sidney was hired as Associate Professor in the department,\nas of Fall, 1966. Leo communicated to me his view that he thought that Sidney\nand I worked well together, which is why he had urged the department to hire\nSidney. Anyhow, Sidney and I had a very fruitful and enjoyable collaboration in\nprobability and, to a much lesser extent, in theoretical statistics, for a\nnumber of years thereafter.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jan 2011 11:48:30 GMT"}], "update_date": "2011-01-06", "authors_parsed": [["Stone", "Charles J.", ""]]}, {"id": "1101.0943", "submitter": "Jacob Feldman", "authors": "Jacob Feldman", "title": "Leo and me", "comments": "Published in at http://dx.doi.org/10.1214/10-AOAS430 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2010, Vol. 4, No. 4, 1656-1656", "doi": "10.1214/10-AOAS430", "report-no": "IMS-AOAS-AOAS430", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  I arrived in Berkeley in 1957, at which time Leo was an Acting Assistant\nProfessor of Mathematics here. He had recently proven the \"individual ergodic\ntheorem of information theory\"---a triumph---and since this was becoming\ncentral to my own interests, it would have been natural for us to work\ntogether. However, Leo's interests shifted to more applied work, specifically\nstatistics, and he soon moved to UCLA. So we never became collaborators, but we\ndid became good friends, especially after 1980 when he returned to Berkeley as\na Professor of Statistics.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jan 2011 11:59:01 GMT"}], "update_date": "2011-01-06", "authors_parsed": [["Feldman", "Jacob", ""]]}, {"id": "1101.0947", "submitter": "Peter J. Bickel", "authors": "Peter J. Bickel, Nathan Boley, James B. Brown, Haiyan Huang, Nancy R.\n  Zhang", "title": "Subsampling Methods for genomic inference", "comments": "Published in at http://dx.doi.org/10.1214/10-AOAS363 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2010, Vol. 4, No. 4, 1660-1697", "doi": "10.1214/10-AOAS363", "report-no": "IMS-AOAS-AOAS363", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale statistical analysis of data sets associated with genome\nsequences plays an important role in modern biology. A key component of such\nstatistical analyses is the computation of $p$-values and confidence bounds for\nstatistics defined on the genome. Currently such computation is commonly\nachieved through ad hoc simulation measures. The method of randomization, which\nis at the heart of these simulation procedures, can significantly affect the\nresulting statistical conclusions. Most simulation schemes introduce a variety\nof hidden assumptions regarding the nature of the randomness in the data,\nresulting in a failure to capture biologically meaningful relationships. To\naddress the need for a method of assessing the significance of observations\nwithin large scale genomic studies, where there often exists a complex\ndependency structure between observations, we propose a unified solution built\nupon a data subsampling approach. We propose a piecewise stationary model for\ngenome sequences and show that the subsampling approach gives correct answers\nunder this model. We illustrate the method on three simulation studies and two\nreal data examples.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jan 2011 12:35:18 GMT"}], "update_date": "2011-01-06", "authors_parsed": [["Bickel", "Peter J.", ""], ["Boley", "Nathan", ""], ["Brown", "James B.", ""], ["Huang", "Haiyan", ""], ["Zhang", "Nancy R.", ""]]}, {"id": "1101.0952", "submitter": "Tong Tong Wu", "authors": "Tong Tong Wu, Kenneth Lange", "title": "Multicategory vertex discriminant analysis for high-dimensional data", "comments": "Published in at http://dx.doi.org/10.1214/10-AOAS345 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2010, Vol. 4, No. 4, 1698-1721", "doi": "10.1214/10-AOAS345", "report-no": "IMS-AOAS-AOAS345", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In response to the challenges of data mining, discriminant analysis continues\nto evolve as a vital branch of statistics. Our recently introduced method of\nvertex discriminant analysis (VDA) is ideally suited to handle multiple\ncategories and an excess of predictors over training cases. The current paper\nexplores an elaboration of VDA that conducts classification and variable\nselection simultaneously. Adding lasso ($\\ell_1$-norm) and Euclidean penalties\nto the VDA loss function eliminates unnecessary predictors. Lasso penalties\napply to each predictor coefficient separately; Euclidean penalties group the\ncollective coefficients of a single predictor. With these penalties in place,\ncyclic coordinate descent accelerates estimation of all coefficients. Our tests\non simulated and benchmark real data demonstrate the virtues of penalized VDA\nin model building and prediction in high-dimensional settings.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jan 2011 12:44:31 GMT"}], "update_date": "2011-01-06", "authors_parsed": [["Wu", "Tong Tong", ""], ["Lange", "Kenneth", ""]]}, {"id": "1101.0959", "submitter": "Jennifer A. Tom", "authors": "Jennifer A. Tom, Janet S. Sinsheimer, Marc A. Suchard", "title": "Reuse, recycle, reweigh: Combating influenza through efficient\n  sequential Bayesian computation for massive data", "comments": "Published in at http://dx.doi.org/10.1214/10-AOAS349 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2010, Vol. 4, No. 4, 1722-1748", "doi": "10.1214/10-AOAS349", "report-no": "IMS-AOAS-AOAS349", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Massive datasets in the gigabyte and terabyte range combined with the\navailability of increasingly sophisticated statistical tools yield analyses at\nthe boundary of what is computationally feasible. Compromising in the face of\nthis computational burden by partitioning the dataset into more tractable sizes\nresults in stratified analyses, removed from the context that justified the\ninitial data collection. In a Bayesian framework, these stratified analyses\ngenerate intermediate realizations, often compared using point estimates that\nfail to account for the variability within and correlation between the\ndistributions these realizations approximate. However, although the initial\nconcession to stratify generally precludes the more sensible analysis using a\nsingle joint hierarchical model, we can circumvent this outcome and capitalize\non the intermediate realizations by extending the dynamic iterative reweighting\nMCMC algorithm. In doing so, we reuse the available realizations by reweighting\nthem with importance weights, recycling them into a now tractable joint\nhierarchical model. We apply this technique to intermediate realizations\ngenerated from stratified analyses of 687 influenza A genomes spanning 13 years\nallowing us to revisit hypotheses regarding the evolutionary history of\ninfluenza within a hierarchical statistical framework.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jan 2011 12:56:49 GMT"}], "update_date": "2011-01-06", "authors_parsed": [["Tom", "Jennifer A.", ""], ["Sinsheimer", "Janet S.", ""], ["Suchard", "Marc A.", ""]]}, {"id": "1101.0961", "submitter": "Richard A. Olshen", "authors": "Richard A. Olshen", "title": "Remembering Leo Breiman", "comments": "Published in at http://dx.doi.org/10.1214/10-AOAS385 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2010, Vol. 4, No. 4, 1644-1648", "doi": "10.1214/10-AOAS385", "report-no": "IMS-AOAS-AOAS385", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  I published an interview of Leo Breiman in Statistical Science [Olshen\n(2001)], and also the solution to a problem concerning almost sure convergence\nof binary tree-structured estimators in regression [Olshen (2007)]. The former\nsummarized much of my thinking about Leo up to five years before his death. I\ndiscussed the latter with Leo and dedicated that paper to his memory.\nTherefore, this note is on other topics. In preparing it I am reminded how much\nI miss this man of so many talents and interests. I miss him not because I\nalways agreed with him, but instead because his comments about statistics in\nparticular and life in general always elicited my substantial reflection.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jan 2011 13:16:59 GMT"}], "update_date": "2011-01-06", "authors_parsed": [["Olshen", "Richard A.", ""]]}, {"id": "1101.0966", "submitter": "Bin Yu", "authors": "Bin Yu", "title": "Remembering Leo", "comments": "Published in at http://dx.doi.org/10.1214/10-AOAS386 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2010, Vol. 4, No. 4, 1657-1659", "doi": "10.1214/10-AOAS386", "report-no": "IMS-AOAS-AOAS386", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  I do not remember when was the first time that I met Leo, but I have a clear\nmemory of going to Leo's office on the 4th floor of Evans Hall to talk to him\nin my second year in Berkeley's Ph.D. program in 1986. The details of the\nconversation are not retained but a visual image of his clean and orderly\noffice remains, in a stark contrast to a high entropy state of the same office\nnow being used by myself.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jan 2011 13:35:03 GMT"}], "update_date": "2011-01-06", "authors_parsed": [["Yu", "Bin", ""]]}, {"id": "1101.0985", "submitter": "D. James Greiner", "authors": "D. James Greiner, Kevin M. Quinn", "title": "Exit polling and racial bloc voting: Combining individual-level and\n  R$\\times$C ecological data", "comments": "Published in at http://dx.doi.org/10.1214/10-AOAS353 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2010, Vol. 4, No. 4, 1774-1796", "doi": "10.1214/10-AOAS353", "report-no": "IMS-AOAS-AOAS353", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite its shortcomings, cross-level or ecological inference remains a\nnecessary part of some areas of quantitative inference, including in United\nStates voting rights litigation. Ecological inference suffers from a lack of\nidentification that, most agree, is best addressed by incorporating\nindividual-level data into the model. In this paper we test the limits of such\nan incorporation by attempting it in the context of drawing inferences about\nracial voting patterns using a combination of an exit poll and precinct-level\necological data; accurate information about racial voting patterns is needed to\nassess triggers in voting rights laws that can determine the composition of\nUnited States legislative bodies. Specifically, we extend and study a hybrid\nmodel that addresses two-way tables of arbitrary dimension. We apply the hybrid\nmodel to an exit poll we administered in the City of Boston in 2008. Using the\nresulting data as well as simulation, we compare the performance of a pure\necological estimator, pure survey estimators using various sampling schemes and\nour hybrid. We conclude that the hybrid estimator offers substantial benefits\nby enabling substantive inferences about voting patterns not practicably\navailable without its use.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jan 2011 14:21:51 GMT"}], "update_date": "2011-01-06", "authors_parsed": [["Greiner", "D. James", ""], ["Quinn", "Kevin M.", ""]]}, {"id": "1101.1154", "submitter": "Alan R. Dabney", "authors": "Yuliya V. Karpievitch, Ashoka D. Polpitiya, Gordon A. Anderson,\n  Richard D. Smith, Alan R. Dabney", "title": "Liquid chromatography mass spectrometry-based proteomics: Biological and\n  technological aspects", "comments": "Published in at http://dx.doi.org/10.1214/10-AOAS341 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2010, Vol. 4, No. 4, 1797-1823", "doi": "10.1214/10-AOAS341", "report-no": "IMS-AOAS-AOAS341", "categories": "stat.AP q-bio.BM q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mass spectrometry-based proteomics has become the tool of choice for\nidentifying and quantifying the proteome of an organism. Though recent years\nhave seen a tremendous improvement in instrument performance and the\ncomputational tools used, significant challenges remain, and there are many\nopportunities for statisticians to make important contributions. In the most\nwidely used \"bottom-up\" approach to proteomics, complex mixtures of proteins\nare first subjected to enzymatic cleavage, the resulting peptide products are\nseparated based on chemical or physical properties and analyzed using a mass\nspectrometer. The two fundamental challenges in the analysis of bottom-up\nMS-based proteomics are as follows: (1) Identifying the proteins that are\npresent in a sample, and (2) Quantifying the abundance levels of the identified\nproteins. Both of these challenges require knowledge of the biological and\ntechnological context that gives rise to observed data, as well as the\napplication of sound statistical principles for estimation and inference. We\npresent an overview of bottom-up proteomics and outline the key statistical\nissues that arise in protein identification and quantification.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jan 2011 07:40:25 GMT"}], "update_date": "2011-01-07", "authors_parsed": [["Karpievitch", "Yuliya V.", ""], ["Polpitiya", "Ashoka D.", ""], ["Anderson", "Gordon A.", ""], ["Smith", "Richard D.", ""], ["Dabney", "Alan R.", ""]]}, {"id": "1101.1163", "submitter": "Dominique-Laurent Couturier", "authors": "Dominique-Laurent Couturier, Maria-Pia Victoria-Feser", "title": "Zero-inflated truncated generalized Pareto distribution for the analysis\n  of radio audience data", "comments": "Published in at http://dx.doi.org/10.1214/10-AOAS358 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2010, Vol. 4, No. 4, 1824-1846", "doi": "10.1214/10-AOAS358", "report-no": "IMS-AOAS-AOAS358", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extreme value data with a high clump-at-zero occur in many domains. Moreover,\nit might happen that the observed data are either truncated below a given\nthreshold and/or might not be reliable enough below that threshold because of\nthe recording devices. These situations occur, in particular, with radio\naudience data measured using personal meters that record environmental noise\nevery minute, that is then matched to one of the several radio programs. There\nare therefore genuine zeros for respondents not listening to the radio, but\nalso zeros corresponding to real listeners for whom the match between the\nrecorded noise and the radio program could not be achieved. Since radio\naudiences are important for radio broadcasters in order, for example, to\ndetermine advertisement price policies, possibly according to the type of\naudience at different time points, it is essential to be able to explain not\nonly the probability of listening to a radio but also the average time spent\nlistening to the radio by means of the characteristics of the listeners. In\nthis paper we propose a generalized linear model for zero-inflated truncated\nPareto distribution (ZITPo) that we use to fit audience radio data. Because it\nis based on the generalized Pareto distribution, the ZITPo model has nice\nproperties such as model invariance to the choice of the threshold and from\nwhich a natural residual measure can be derived to assess the model fit to the\ndata. From a general formulation of the most popular models for zero-inflated\ndata, we derive our model by considering successively the truncated case, the\ngeneralized Pareto distribution and then the inclusion of covariates to explain\nthe nonzero proportion of listeners and their average listening time. By means\nof simulations, we study the performance of the maximum likelihood estimator\n(and derived inference) and use the model to fully analyze the audience data of\na radio station in a certain area of Switzerland.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jan 2011 08:26:39 GMT"}], "update_date": "2011-01-07", "authors_parsed": [["Couturier", "Dominique-Laurent", ""], ["Victoria-Feser", "Maria-Pia", ""]]}, {"id": "1101.1164", "submitter": "J. Drylewicz", "authors": "J. Drylewicz, J. Guedj, D. Commenges, R. Thi\\'ebaut", "title": "Modeling the dynamics of biomarkers during primary HIV infection taking\n  into account the uncertainty of infection date", "comments": "Published in at http://dx.doi.org/10.1214/10-AOAS364 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2010, Vol. 4, No. 4, 1847-1870", "doi": "10.1214/10-AOAS364", "report-no": "IMS-AOAS-AOAS364", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During primary HIV infection, the kinetics of plasma virus concentrations and\nCD4+ cell counts is very complex. Parametric and nonparametric models have been\nsuggested for fitting repeated measurements of these markers. Alternatively,\nmechanistic approaches based on ordinary differential equations have also been\nproposed. These latter models are constructed according to biological knowledge\nand take into account the complex nonlinear interactions between viruses and\ncells. However, estimating the parameters of these models is difficult. A main\ndifficulty in the context of primary HIV infection is that the date of\ninfection is generally unknown. For some patients, the date of last negative\nHIV test is available in addition to the date of first positive HIV test\n(seroconverters). In this paper we propose a likelihood-based method for\nestimating the parameters of dynamical models using a population approach and\ntaking into account the uncertainty of the infection date. We applied this\nmethod to a sample of 761 HIV-infected patients from the Concerted Action on\nSeroConversion to AIDS and Death in Europe (CASCADE).\n", "versions": [{"version": "v1", "created": "Thu, 6 Jan 2011 08:54:35 GMT"}], "update_date": "2011-01-07", "authors_parsed": [["Drylewicz", "J.", ""], ["Guedj", "J.", ""], ["Commenges", "D.", ""], ["Thi\u00e9baut", "R.", ""]]}, {"id": "1101.1203", "submitter": "Mohammed Haddou", "authors": "Mohammed Haddou, Louis-Paul Rivest, Michael Pierrynowski", "title": "A nonlinear mixed effects directional model for the estimation of the\n  rotation axes of the human ankle", "comments": "Published in at http://dx.doi.org/10.1214/10-AOAS342 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2010, Vol. 4, No. 4, 1892-1912", "doi": "10.1214/10-AOAS342", "report-no": "IMS-AOAS-AOAS342", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper suggests a nonlinear mixed effects model for data points in\n$\\mathit{SO}(3)$, the set of $3\\times3$ rotation matrices, collected according\nto a repeated measure design. Each sample individual contributes a sequence of\nrotation matrices giving the relative orientations of the right foot with\nrespect to the right lower leg as its ankle moves. The random effects are the\nfive angles characterizing the orientation of the two rotation axes of a\nsubject's right ankle. The fixed parameters are the average value of these\nangles and their variances within the population. The algorithms to fit\nnonlinear mixed effects models presented in Pinheiro and Bates (2000) are\nadapted to the new directional model. The estimation of the random effects are\nof interest since they give predictions of the rotation axes of an individual\nankle. The performance of these algorithms is investigated in a Monte Carlo\nstudy. The analysis of two data sets is presented. In the biomechanical\nliterature, there is no consensus on an in vivo method to estimate the two\nrotation axes of the ankle. The new model is promising. The estimates obtained\nfrom a sample of volunteers are shown to be in agreement with the clinically\naccepted results of Inman (1976), obtained by manipulating cadavers. The\nrepeated measure directional model presented in this paper is developed for a\nparticular application. The approach is, however, general and might be applied\nto other models provided that the random directional effects are clustered\naround their mean values.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jan 2011 12:58:25 GMT"}], "update_date": "2011-01-07", "authors_parsed": [["Haddou", "Mohammed", ""], ["Rivest", "Louis-Paul", ""], ["Pierrynowski", "Michael", ""]]}, {"id": "1101.1210", "submitter": "Tingting Zhang", "authors": "Tingting Zhang, S. C. Kou", "title": "Nonparametric inference of doubly stochastic Poisson process data via\n  the kernel method", "comments": "Published in at http://dx.doi.org/10.1214/10-AOAS352 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2010, Vol. 4, No. 4, 1913-1941", "doi": "10.1214/10-AOAS352", "report-no": "IMS-AOAS-AOAS352", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Doubly stochastic Poisson processes, also known as the Cox processes,\nfrequently occur in various scientific fields. In this article, motivated\nprimarily by analyzing Cox process data in biophysics, we propose a\nnonparametric kernel-based inference method. We conduct a detailed study,\nincluding an asymptotic analysis, of the proposed method, and provide\nguidelines for its practical use, introducing a fast and stable regression\nmethod for bandwidth selection. We apply our method to real photon arrival data\nfrom recent single-molecule biophysical experiments, investigating proteins'\nconformational dynamics. Our result shows that conformational fluctuation is\nwidely present in protein systems, and that the fluctuation covers a broad\nrange of time scales, highlighting the dynamic and complex nature of proteins'\nstructure.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jan 2011 13:31:59 GMT"}], "update_date": "2011-01-07", "authors_parsed": [["Zhang", "Tingting", ""], ["Kou", "S. C.", ""]]}, {"id": "1101.1264", "submitter": "Garfield Brown", "authors": "Garfield Brown and Steve Brooks", "title": "Bayesian Analysis of Loss Ratios Using the Reversible Jump Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider the problem of model choice for a set of insurance\nloss ratios. We use a reversible jump algorithm for our model discrimination\nand show how the vanilla reversible jump algorithm can be improved on using\nrecent methodological advances in reversible jump computation.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jan 2011 17:40:36 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Brown", "Garfield", ""], ["Brooks", "Steve", ""]]}, {"id": "1101.1365", "submitter": "Samiran Ghosh", "authors": "Samiran Ghosh", "title": "An imputation-based approach for parameter estimation in the presence of\n  ambiguous censoring with application in industrial supply chain", "comments": "Published in at http://dx.doi.org/10.1214/10-AOAS348 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2010, Vol. 4, No. 4, 1976-1999", "doi": "10.1214/10-AOAS348", "report-no": "IMS-AOAS-AOAS348", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a novel approach based on \"proportional imputation\" when\nidentical units produced in a batch have random but independent installation\nand failure times. The current problem is motivated by a real life industrial\nproduction-delivery supply chain where identical units are shipped after\nproduction to a third party warehouse and then sold at a future date for\npossible installation. Due to practical limitations, at any given time point,\nthe exact installation as well as the failure times are known for only those\nunits which have failed within that time frame after the installation. Hence,\nin-house reliability engineers are presented with a very limited, as well as\npartial, data to estimate different model parameters related to installation\nand failure distributions. In reality, other units in the batch are generally\nnot utilized due to lack of proper statistical methodology, leading to gross\nmisspecification. In this paper we have introduced a likelihood based\nparametric and computationally efficient solution to overcome this problem.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jan 2011 07:17:27 GMT"}], "update_date": "2011-01-10", "authors_parsed": [["Ghosh", "Samiran", ""]]}, {"id": "1101.1373", "submitter": "Xia Wang", "authors": "Xia Wang, Dipak K. Dey", "title": "Generalized extreme value regression for binary response data: An\n  application to B2B electronic payments system adoption", "comments": "Published in at http://dx.doi.org/10.1214/10-AOAS354 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2010, Vol. 4, No. 4, 2000-2023", "doi": "10.1214/10-AOAS354", "report-no": "IMS-AOAS-AOAS354", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the information system research, a question of particular interest is to\ninterpret and to predict the probability of a firm to adopt a new technology\nsuch that market promotions are targeted to only those firms that were more\nlikely to adopt the technology. Typically, there exists significant difference\nbetween the observed number of ``adopters'' and ``nonadopters,'' which is\nusually coded as binary response. A critical issue involved in modeling such\nbinary response data is the appropriate choice of link functions in a\nregression model. In this paper we introduce a new flexible skewed link\nfunction for modeling binary response data based on the generalized extreme\nvalue (GEV) distribution. We show how the proposed GEV links provide more\nflexible and improved skewed link regression models than the existing skewed\nlinks, especially when dealing with imbalance between the observed number of\n0's and 1's in a data. The flexibility of the proposed model is illustrated\nthrough simulated data sets and a billing data set of the electronic payments\nsystem adoption from a Fortune 100 company in 2005.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jan 2011 08:06:54 GMT"}], "update_date": "2011-01-10", "authors_parsed": [["Wang", "Xia", ""], ["Dey", "Dipak K.", ""]]}, {"id": "1101.1377", "submitter": "Francesco C. Stingo", "authors": "Francesco C. Stingo, Yian A. Chen, Marina Vannucci, Marianne Barrier,\n  Philip E. Mirkes", "title": "A Bayesian graphical modeling approach to microRNA regulatory network\n  inference", "comments": "Published in at http://dx.doi.org/10.1214/10-AOAS360 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2010, Vol. 4, No. 4, 2024-2048", "doi": "10.1214/10-AOAS360", "report-no": "IMS-AOAS-AOAS360", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been estimated that about 30% of the genes in the human genome are\nregulated by microRNAs (miRNAs). These are short RNA sequences that can\ndown-regulate the levels of mRNAs or proteins in animals and plants. Genes\nregulated by miRNAs are called targets. Typically, methods for target\nprediction are based solely on sequence data and on the structure information.\nIn this paper we propose a Bayesian graphical modeling approach that infers the\nmiRNA regulatory network by integrating expression levels of miRNAs with their\npotential mRNA targets and, via the prior probability model, with their\nsequence/structure information. We use a directed graphical model with a\nparticular structure adapted to our data based on biological considerations. We\nthen achieve network inference using stochastic search methods for variable\nselection that allow us to explore the huge model space via MCMC. A\ntime-dependent coefficients model is also implemented. We consider experimental\ndata from a study on a very well-known developmental toxicant causing neural\ntube defects, hyperthermia. Some of the pairs of target gene and miRNA we\nidentify seem very plausible and warrant future investigation. Our proposed\nmethod is general and can be easily applied to other types of network inference\nby integrating multiple data sources.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jan 2011 08:29:37 GMT"}], "update_date": "2011-01-10", "authors_parsed": [["Stingo", "Francesco C.", ""], ["Chen", "Yian A.", ""], ["Vannucci", "Marina", ""], ["Barrier", "Marianne", ""], ["Mirkes", "Philip E.", ""]]}, {"id": "1101.1398", "submitter": "Luciano I. de Castro", "authors": "Luciano I. de Castro, Harry J. Paarsch", "title": "Testing affiliation in private-values models of first-price auctions\n  using grid distributions", "comments": "Published in at http://dx.doi.org/10.1214/10-AOAS344 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2010, Vol. 4, No. 4, 2073-2098", "doi": "10.1214/10-AOAS344", "report-no": "IMS-AOAS-AOAS344", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Within the private-values paradigm, we construct a tractable empirical model\nof equilibrium behavior at first-price auctions when bidders' valuations are\npotentially dependent, but not necessarily affiliated. We develop a test of\naffiliation and apply our framework to data from low-price, sealed-bid auctions\nheld by the Department of Transportation in the State of Michigan to procure\nroad-resurfacing services: we do not reject the hypothesis of affiliation in\ncost signals.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jan 2011 10:22:17 GMT"}], "update_date": "2011-01-10", "authors_parsed": [["de Castro", "Luciano I.", ""], ["Paarsch", "Harry J.", ""]]}, {"id": "1101.1402", "submitter": "Adam A. Szpiro", "authors": "Adam A. Szpiro, Kenneth M. Rice, Thomas Lumley", "title": "Model-robust regression and a Bayesian ``sandwich'' estimator", "comments": "Published in at http://dx.doi.org/10.1214/10-AOAS362 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2010, Vol. 4, No. 4, 2099-2113", "doi": "10.1214/10-AOAS362", "report-no": "IMS-AOAS-AOAS362", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new Bayesian approach to model-robust linear regression that\nleads to uncertainty estimates with the same robustness properties as the\nHuber--White sandwich estimator. The sandwich estimator is known to provide\nasymptotically correct frequentist inference, even when standard modeling\nassumptions such as linearity and homoscedasticity in the data-generating\nmechanism are violated. Our derivation provides a compelling Bayesian\njustification for using this simple and popular tool, and it also clarifies\nwhat is being estimated when the data-generating mechanism is not linear. We\ndemonstrate the applicability of our approach using a simulation study and\nhealth care cost data from an evaluation of the Washington State Basic Health\nPlan.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jan 2011 10:35:33 GMT"}], "update_date": "2011-01-10", "authors_parsed": [["Szpiro", "Adam A.", ""], ["Rice", "Kenneth M.", ""], ["Lumley", "Thomas", ""]]}, {"id": "1101.1407", "submitter": "Xuming He", "authors": "Xuming He, Ya-Hui Hsu, Mingxiu Hu", "title": "Detection of treatment effects by covariate-adjusted expected shortfall", "comments": "Published in at http://dx.doi.org/10.1214/10-AOAS347 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2010, Vol. 4, No. 4, 2114-2125", "doi": "10.1214/10-AOAS347", "report-no": "IMS-AOAS-AOAS347", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The statistical tests that are commonly used for detecting mean or median\ntreatment effects suffer from low power when the two distribution functions\ndiffer only in the upper (or lower) tail, as in the assessment of the Total\nSharp Score (TSS) under different treatments for rheumatoid arthritis. In this\narticle, we propose a more powerful test that detects treatment effects through\nthe expected shortfalls. We show how the expected shortfall can be adjusted for\ncovariates, and demonstrate that the proposed test can achieve a substantial\nsample size reduction over the conventional tests on the mean effects.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jan 2011 11:23:52 GMT"}], "update_date": "2011-01-10", "authors_parsed": [["He", "Xuming", ""], ["Hsu", "Ya-Hui", ""], ["Hu", "Mingxiu", ""]]}, {"id": "1101.1415", "submitter": "Alejandro Jara", "authors": "Alejandro Jara, Emmanuel Lesaffre, Maria De Iorio, Fernando Quintana", "title": "Bayesian semiparametric inference for multivariate\n  doubly-interval-censored data", "comments": "Published in at http://dx.doi.org/10.1214/10-AOAS368 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2010, Vol. 4, No. 4, 2126-2149", "doi": "10.1214/10-AOAS368", "report-no": "IMS-AOAS-AOAS368", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Based on a data set obtained in a dental longitudinal study, conducted in\nFlanders (Belgium), the joint time to caries distribution of permanent first\nmolars was modeled as a function of covariates. This involves an analysis of\nmultivariate continuous doubly-interval-censored data since: (i) the emergence\ntime of a tooth and the time it experiences caries were recorded yearly, and\n(ii) events on teeth of the same child are dependent. To model the joint\ndistribution of the emergence times and the times to caries, we propose a\ndependent Bayesian semiparametric model. A major feature of the proposed\napproach is that survival curves can be estimated without imposing assumptions\nsuch as proportional hazards, additive hazards, proportional odds or\naccelerated failure time.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jan 2011 12:07:59 GMT"}], "update_date": "2011-01-10", "authors_parsed": [["Jara", "Alejandro", ""], ["Lesaffre", "Emmanuel", ""], ["De Iorio", "Maria", ""], ["Quintana", "Fernando", ""]]}, {"id": "1101.1421", "submitter": "Jan Gertheiss", "authors": "Jan Gertheiss, Gerhard Tutz", "title": "Sparse modeling of categorial explanatory variables", "comments": "Published in at http://dx.doi.org/10.1214/10-AOAS355 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2010, Vol. 4, No. 4, 2150-2180", "doi": "10.1214/10-AOAS355", "report-no": "IMS-AOAS-AOAS355", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Shrinking methods in regression analysis are usually designed for metric\npredictors. In this article, however, shrinkage methods for categorial\npredictors are proposed. As an application we consider data from the Munich\nrent standard, where, for example, urban districts are treated as a categorial\npredictor. If independent variables are categorial, some modifications to usual\nshrinking procedures are necessary. Two $L_1$-penalty based methods for factor\nselection and clustering of categories are presented and investigated. The\nfirst approach is designed for nominal scale levels, the second one for ordinal\npredictors. Besides applying them to the Munich rent standard, methods are\nillustrated and compared in simulation studies.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jan 2011 12:29:48 GMT"}], "update_date": "2011-01-10", "authors_parsed": [["Gertheiss", "Jan", ""], ["Tutz", "Gerhard", ""]]}, {"id": "1101.1425", "submitter": "Brian Francis", "authors": "Brian Francis, Regina Dittrich, Reinhold Hatzinger", "title": "Modeling heterogeneity in ranked responses by nonparametric maximum\n  likelihood: How do Europeans get their scientific knowledge?", "comments": "Published in at http://dx.doi.org/10.1214/10-AOAS366 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2010, Vol. 4, No. 4, 2181-2202", "doi": "10.1214/10-AOAS366", "report-no": "IMS-AOAS-AOAS366", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is motivated by a Eurobarometer survey on science knowledge. As\npart of the survey, respondents were asked to rank sources of science\ninformation in order of importance. The official statistical analysis of these\ndata however failed to use the complete ranking information. We instead propose\na method which treats ranked data as a set of paired comparisons which places\nthe problem in the standard framework of generalized linear models and also\nallows respondent covariates to be incorporated. An extension is proposed to\nallow for heterogeneity in the ranked responses. The resulting model uses a\nnonparametric formulation of the random effects structure, fitted using the EM\nalgorithm. Each mass point is multivalued, with a parameter for each item. The\nresultant model is equivalent to a covariate latent class model, where the\nlatent class profiles are provided by the mass point components and the\ncovariates act on the class profiles. This provides an alternative\ninterpretation of the fitted model. The approach is also suitable for paired\ncomparison data.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jan 2011 12:47:11 GMT"}], "update_date": "2011-01-10", "authors_parsed": [["Francis", "Brian", ""], ["Dittrich", "Regina", ""], ["Hatzinger", "Reinhold", ""]]}, {"id": "1101.1959", "submitter": "Joseph Richards", "authors": "Joseph W. Richards, Dan L. Starr, Nathaniel R. Butler, Joshua S.\n  Bloom, John M. Brewer, Arien Crellin-Quick, Justin Higgins, Rachel Kennedy,\n  Maxime Rischard", "title": "On Machine-Learned Classification of Variable Stars with Sparse and\n  Noisy Time-Series Data", "comments": "23 pages, 9 figures", "journal-ref": "ApJ, 733, 10 (2011)", "doi": "10.1088/0004-637X/733/1/10", "report-no": null, "categories": "astro-ph.IM stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the coming data deluge from synoptic surveys, there is a growing need\nfor frameworks that can quickly and automatically produce calibrated\nclassification probabilities for newly-observed variables based on a small\nnumber of time-series measurements. In this paper, we introduce a methodology\nfor variable-star classification, drawing from modern machine-learning\ntechniques. We describe how to homogenize the information gleaned from light\ncurves by selection and computation of real-numbered metrics (\"feature\"),\ndetail methods to robustly estimate periodic light-curve features, introduce\ntree-ensemble methods for accurate variable star classification, and show how\nto rigorously evaluate the classification results using cross validation. On a\n25-class data set of 1542 well-studied variable stars, we achieve a 22.8%\noverall classification error using the random forest classifier; this\nrepresents a 24% improvement over the best previous classifier on these data.\nThis methodology is effective for identifying samples of specific science\nclasses: for pulsational variables used in Milky Way tomography we obtain a\ndiscovery efficiency of 98.2% and for eclipsing systems we find an efficiency\nof 99.1%, both at 95% purity. We show that the random forest (RF) classifier is\nsuperior to other machine-learned methods in terms of accuracy, speed, and\nrelative immunity to features with no useful class information; the RF\nclassifier can also be used to estimate the importance of each feature in\nclassification. Additionally, we present the first astronomical use of\nhierarchical classification methods to incorporate a known class taxonomy in\nthe classifier, which further reduces the catastrophic error rate to 7.8%.\nExcluding low-amplitude sources, our overall error rate improves to 14%, with a\ncatastrophic error rate of 3.5%.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jan 2011 21:00:16 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Richards", "Joseph W.", ""], ["Starr", "Dan L.", ""], ["Butler", "Nathaniel R.", ""], ["Bloom", "Joshua S.", ""], ["Brewer", "John M.", ""], ["Crellin-Quick", "Arien", ""], ["Higgins", "Justin", ""], ["Kennedy", "Rachel", ""], ["Rischard", "Maxime", ""]]}, {"id": "1101.2157", "submitter": "Nikolai Sinitsyn", "authors": "Soumya Kundu, Nikolai Sinitsyn, Scott Backhaus, and Ian Hiskens", "title": "Modeling and control of thermostatically controlled loads", "comments": null, "journal-ref": null, "doi": null, "report-no": "LA-UR 11-00040", "categories": "cond-mat.stat-mech nlin.AO stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the penetration of intermittent energy sources grows substantially, loads\nwill be required to play an increasingly important role in compensating the\nfast time-scale fluctuations in generated power. Recent numerical modeling of\nthermostatically controlled loads (TCLs) has demonstrated that such load\nfollowing is feasible, but analytical models that satisfactorily quantify the\naggregate power consumption of a group of TCLs are desired to enable controller\ndesign. We develop such a model for the aggregate power response of a\nhomogeneous population of TCLs to uniform variation of all TCL setpoints. A\nlinearized model of the response is derived, and a linear quadratic regulator\n(LQR) has been designed. Using the TCL setpoint as the control input, the LQR\nenables aggregate power to track reference signals that exhibit step, ramp and\nsinusoidal variations. Although much of the work assumes a homogeneous\npopulation of TCLs with deterministic dynamics, we also propose a method for\nprobing the dynamics of systems where load characteristics are not well known.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jan 2011 16:23:31 GMT"}], "update_date": "2012-04-13", "authors_parsed": [["Kundu", "Soumya", ""], ["Sinitsyn", "Nikolai", ""], ["Backhaus", "Scott", ""], ["Hiskens", "Ian", ""]]}, {"id": "1101.2228", "submitter": "Andrew C. Thomas", "authors": "Andrew C. Thomas, Joseph K. Blitzstein", "title": "Valued Ties Tell Fewer Lies, II: Why Not To Dichotomize Network Edges\n  With Bounded Outdegrees", "comments": "15 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.SI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Various methods have been proposed for creating a binary version of a complex\nnetwork with valued ties. Rather than the default method of choosing a single\nthreshold value about which to dichotomize, we consider a method of choosing\nthe highest k outbound arcs from each person and assigning a binary tie, as\nthis has the advantage of minimizing the isolation of nodes that may otherwise\nbe weakly connected. However, simulations and real data sets establish that\nthis method is worse than the default thresholding method and should not be\ngenerally considered to deal with valued networks.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jan 2011 22:25:15 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Thomas", "Andrew C.", ""], ["Blitzstein", "Joseph K.", ""]]}, {"id": "1101.2374", "submitter": "Charles Bouveyron", "authors": "Charles Bouveyron and Camille Brunet", "title": "Simultaneous model-based clustering and visualization in the Fisher\n  discriminative subspace", "comments": null, "journal-ref": "Statistics and Computing, 2011", "doi": "10.1007/s11222-011-9249-9", "report-no": null, "categories": "stat.ME stat.AP stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering in high-dimensional spaces is nowadays a recurrent problem in many\nscientific domains but remains a difficult task from both the clustering\naccuracy and the result understanding points of view. This paper presents a\ndiscriminative latent mixture (DLM) model which fits the data in a latent\northonormal discriminative subspace with an intrinsic dimension lower than the\ndimension of the original space. By constraining model parameters within and\nbetween groups, a family of 12 parsimonious DLM models is exhibited which\nallows to fit onto various situations. An estimation algorithm, called the\nFisher-EM algorithm, is also proposed for estimating both the mixture\nparameters and the discriminative subspace. Experiments on simulated and real\ndatasets show that the proposed approach performs better than existing\nclustering methods while providing a useful representation of the clustered\ndata. The method is as well applied to the clustering of mass spectrometry\ndata.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jan 2011 14:40:06 GMT"}, {"version": "v2", "created": "Tue, 19 Apr 2011 08:21:44 GMT"}], "update_date": "2011-04-20", "authors_parsed": [["Bouveyron", "Charles", ""], ["Brunet", "Camille", ""]]}, {"id": "1101.2592", "submitter": "Sean Simpson", "authors": "Sean L. Simpson, Malaak N. Moussa, Paul J. Laurienti", "title": "An exponential random graph modeling approach to creating group-based\n  representative whole-brain connectivity networks", "comments": null, "journal-ref": "NeuroImage 2012: 60, 1117-1126", "doi": null, "report-no": null, "categories": "stat.AP q-bio.NC q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Group-based brain connectivity networks have great appeal for researchers\ninterested in gaining further insight into complex brain function and how it\nchanges across different mental states and disease conditions. Accurately\nconstructing these networks presents a daunting challenge given the\ndifficulties associated with accounting for inter-subject topological\nvariability. Viable approaches to this task must engender networks that capture\nthe constitutive topological properties of the group of subjects' networks that\nit is aiming to represent. The conventional approach has been to use a mean or\nmedian correlation network (Achard et al., 2006; Song et al., 2009) to embody a\ngroup of networks. However, the degree to which their topological properties\nconform with those of the groups that they are purported to represent has yet\nto be explored. Here we investigate the performance of these mean and median\ncorrelation networks. We also propose an alternative approach based on an\nexponential random graph modeling framework and compare its performance to that\nof the aforementioned conventional approach. Simpson et al. (2010) illustrated\nthe utility of exponential random graph models (ERGMs) for creating brain\nnetworks that capture the topological characteristics of a single subject's\nbrain network. However, their advantageousness in the context of producing a\nbrain network that \"represents\" a group of brain networks has yet to be\nexamined. Here we show that our proposed ERGM approach outperforms the\nconventional mean and median correlation based approaches and provides an\naccurate and flexible method for constructing group-based representative brain\nnetworks.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jan 2011 15:48:05 GMT"}, {"version": "v2", "created": "Wed, 16 Nov 2011 21:17:26 GMT"}], "update_date": "2013-03-05", "authors_parsed": [["Simpson", "Sean L.", ""], ["Moussa", "Malaak N.", ""], ["Laurienti", "Paul J.", ""]]}, {"id": "1101.3231", "submitter": "Sean Simpson", "authors": "Sean L. Simpson", "title": "An Adjusted Likelihood Ratio Test for Separability in Unbalanced\n  Multivariate Repeated Measures Data", "comments": null, "journal-ref": "Statistical Methodology (2010) 7, 511-519", "doi": null, "report-no": null, "categories": "stat.ME stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an adjusted likelihood ratio test of two-factor separability\n(Kronecker product structure) for unbalanced multivariate repeated measures\ndata. Here we address the particular case where the within subject correlation\nis believed to decrease exponentially in both dimensions (e.g., temporal and\nspatial dimensions). However, the test can be easily generalized to factor\nspecific matrices of any structure. A simulation study is conducted to assess\nthe inference accuracy of the proposed test. Longitudinal medical imaging data\nconcerning schizophrenia and caudate morphology illustrates the methodology.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jan 2011 14:45:29 GMT"}, {"version": "v2", "created": "Tue, 1 Feb 2011 15:58:09 GMT"}], "update_date": "2011-02-02", "authors_parsed": [["Simpson", "Sean L.", ""]]}, {"id": "1101.3824", "submitter": "RadhaKrishna Ganti", "authors": "Radha Krishna Ganti, Francois Baccelli and Jeffrey G. Andrews", "title": "Series Expansion for Interference in Wireless Networks", "comments": "Submitted to IEEE Transactions on Information Theory", "journal-ref": null, "doi": "10.1109/TIT.2011.2177067", "report-no": null, "categories": "cs.IT math.IT math.PR stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The spatial correlations in transmitter node locations introduced by common\nmultiple access protocols makes the analysis of interference, outage, and other\nrelated metrics in a wireless network extremely difficult. Most works therefore\nassume that nodes are distributed either as a Poisson point process (PPP) or a\ngrid, and utilize the independence properties of the PPP (or the regular\nstructure of the grid) to analyze interference, outage and other metrics.\nBut,the independence of node locations makes the PPP a dubious model for\nnontrivial MACs which intentionally introduce correlations, e.g. spatial\nseparation, while the grid is too idealized to model real networks. In this\npaper, we introduce a new technique based on the factorial moment expansion of\nfunctionals of point processes to analyze functions of interference, in\nparticular outage probability. We provide a Taylor-series type expansion of\nfunctions of interference, wherein increasing the number of terms in the series\nprovides a better approximation at the cost of increased complexity of\ncomputation. Various examples illustrate how this new approach can be used to\nfind outage probability in both Poisson and non-Poisson wireless networks.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jan 2011 05:37:53 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Ganti", "Radha Krishna", ""], ["Baccelli", "Francois", ""], ["Andrews", "Jeffrey G.", ""]]}, {"id": "1101.4331", "submitter": "Robert Strawderman", "authors": "Karen Lostritto, Robert Strawderman, Annette Molinaro", "title": "A Partitioning Deletion/Substitution/Addition Algorithm for Creating\n  Survival Risk Groups", "comments": "A revision of this paper has been accepted for publication in\n  Biometrics", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurately assessing a patient's risk of a given event is essential in making\ninformed treatment decisions. One approach is to stratify patients into two or\nmore distinct risk groups with respect to a specific outcome using both\nclinical and demographic variables. Outcomes may be categorical or continuous\nin nature; important examples in cancer studies might include level of toxicity\nor time to recurrence. Recursive partitioning methods are ideal for building\nsuch risk groups. Two such methods are Classification and Regression Trees\n(CART) and a more recent competitor known as the partitioning\nDeletion/Substitution/Addition (partDSA) algorithm, both which also utilize\nloss functions (e.g. squared error for a continuous outcome) as the basis for\nbuilding, selecting and assessing predictors but differ in the manner by which\nregression trees are constructed.\n  Recently, we have shown that partDSA often outperforms CART in so-called\n\"full data\" (e.g., uncensored) settings. However, when confronted with censored\noutcome data, the loss functions used by both procedures must be modified.\nThere have been several attempts to adapt CART for right-censored data. This\narticle describes two such extensions for \\emph{partDSA} that make use of\nobserved data (i.e. possibly censored) loss functions. These observed data loss\nfunctions, constructed using inverse probability of censoring weights, are\nconsistent estimates of their uncensored counterparts provided that the\ncorresponding censoring model is correctly specified. The relative performance\nof these new methods is evaluated via simulation studies and illustrated\nthrough an analysis of clinical trial data on brain cancer patients.\n", "versions": [{"version": "v1", "created": "Sat, 22 Jan 2011 23:02:00 GMT"}, {"version": "v2", "created": "Tue, 14 Feb 2012 22:44:17 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Lostritto", "Karen", ""], ["Strawderman", "Robert", ""], ["Molinaro", "Annette", ""]]}, {"id": "1101.4373", "submitter": "Klaus Frick", "authors": "Klaus Frick, Philipp Marnitz, Axel Munk", "title": "Statistical Multiresolution Dantzig Estimation in Imaging: Fundamental\n  Concepts and Algorithmic Framework", "comments": null, "journal-ref": "Electron. J. Stat. 6 (2012) 231-268", "doi": "10.1214/12-EJS671", "report-no": null, "categories": "stat.AP cs.CV cs.SY math.OC stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we are concerned with fully automatic and locally adaptive\nestimation of functions in a \"signal + noise\"-model where the regression\nfunction may additionally be blurred by a linear operator, e.g. by a\nconvolution. To this end, we introduce a general class of statistical\nmultiresolution estimators and develop an algorithmic framework for computing\nthose. By this we mean estimators that are defined as solutions of convex\noptimization problems with supremum-type constraints. We employ a combination\nof the alternating direction method of multipliers with Dykstra's algorithm for\ncomputing orthogonal projections onto intersections of convex sets and prove\nnumerical convergence. The capability of the proposed method is illustrated by\nvarious examples from imaging and signal detection.\n", "versions": [{"version": "v1", "created": "Sun, 23 Jan 2011 13:46:43 GMT"}, {"version": "v2", "created": "Fri, 22 Jul 2011 00:24:44 GMT"}, {"version": "v3", "created": "Wed, 1 Feb 2012 09:25:47 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Frick", "Klaus", ""], ["Marnitz", "Philipp", ""], ["Munk", "Axel", ""]]}, {"id": "1101.4577", "submitter": "Meili Baragatti", "authors": "Meili Baragatti (IML)", "title": "Bayesian Variable Selection for Probit Mixed Models Applied to Gene\n  Selection", "comments": null, "journal-ref": "Bayesian Analysis 6, 2 (2011) 209-230", "doi": "10.1214/11-BA607", "report-no": null, "categories": "stat.ME q-bio.QM stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In computational biology, gene expression datasets are characterized by very\nfew individual samples compared to a large number of measurements per sample.\nThus, it is appealing to merge these datasets in order to increase the number\nof observations and diversify the data, allowing a more reliable selection of\ngenes relevant to the biological problem. Besides, the increased size of a\nmerged dataset facilitates its re-splitting into training and validation sets.\nThis necessitates the introduction of the dataset as a random effect. In this\ncontext, extending a work of Lee et al. (2003), a method is proposed to select\nrelevant variables among tens of thousands in a probit mixed regression model,\nconsidered as part of a larger hierarchical Bayesian model. Latent variables\nare used to identify subsets of selected variables and the grouping (or\nblocking) technique of Liu (1994) is combined with a Metropolis-within-Gibbs\nalgorithm (Robert and Casella 2004). The method is applied to a merged dataset\nmade of three individual gene expression datasets, in which tens of thousands\nof measurements are available for each of several hundred human breast cancer\nsamples. Even for this large dataset comprised of around 20000 predictors, the\nmethod is shown to be efficient and feasible. As an illustration, it is used to\nselect the most important genes that characterize the estrogen receptor status\nof patients with breast cancer.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jan 2011 16:08:54 GMT"}, {"version": "v2", "created": "Wed, 23 Feb 2011 06:12:55 GMT"}], "update_date": "2011-08-18", "authors_parsed": [["Baragatti", "Meili", "", "IML"]]}, {"id": "1101.4744", "submitter": "Jairo Cugliari", "authors": "Anestis Antoniadis (UJF), Xavier Brossat, Jairo Cugliari (LM-Orsay),\n  Jean-Michel Poggi (LM-Orsay)", "title": "Clustering functional data using wavelets", "comments": null, "journal-ref": null, "doi": "10.1142/S0219691313500033", "report-no": "RR-7515", "categories": "stat.ME stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present two methods for detecting patterns and clusters in high\ndimensional time-dependent functional data. Our methods are based on\nwavelet-based similarity measures, since wavelets are well suited for\nidentifying highly discriminant local time and scale features. The\nmultiresolution aspect of the wavelet transform provides a time-scale\ndecomposition of the signals allowing to visualize and to cluster the\nfunctional data into homogeneous groups. For each input function, through its\nempirical orthogonal wavelet transform the first method uses the distribution\nof energy across scales generate a handy number of features that can be\nsufficient to still make the signals well distinguishable. Our new similarity\nmeasure combined with an efficient feature selection technique in the wavelet\ndomain is then used within more or less classical clustering algorithms to\neffectively differentiate among high dimensional populations. The second method\nuses dissimilarity measures between the whole time-scale representations and\nare based on wavelet-coherence tools. The clustering is then performed using a\nk-centroid algorithm starting from these dissimilarities. Practical performance\nof these methods that jointly designs both the feature selection in the wavelet\ndomain and the classification distance is demonstrated through simulations as\nwell as daily profiles of the French electricity power demand.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jan 2011 08:13:18 GMT"}, {"version": "v2", "created": "Tue, 31 May 2011 12:46:40 GMT"}], "update_date": "2013-02-15", "authors_parsed": [["Antoniadis", "Anestis", "", "UJF"], ["Brossat", "Xavier", "", "LM-Orsay"], ["Cugliari", "Jairo", "", "LM-Orsay"], ["Poggi", "Jean-Michel", "", "LM-Orsay"]]}, {"id": "1101.5008", "submitter": "Anne-Claire Haury", "authors": "Anne-Claire Haury (CBIO), Pierre Gestraud, Jean-Philippe Vert (CBIO)", "title": "The influence of feature selection methods on accuracy, stability and\n  interpretability of molecular signatures", "comments": null, "journal-ref": "PLoS ONE (2011) 6(12): e28210", "doi": "10.1371/journal.pone.0028210", "report-no": null, "categories": "q-bio.QM stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivation: Biomarker discovery from high-dimensional data is a crucial\nproblem with enormous applications in biology and medicine. It is also\nextremely challenging from a statistical viewpoint, but surprisingly few\nstudies have investigated the relative strengths and weaknesses of the plethora\nof existing feature selection methods. Methods: We compare 32 feature selection\nmethods on 4 public gene expression datasets for breast cancer prognosis, in\nterms of predictive performance, stability and functional interpretability of\nthe signatures they produce. Results: We observe that the feature selection\nmethod has a significant influence on the accuracy, stability and\ninterpretability of signatures. Simple filter methods generally outperform more\ncomplex embedded or wrapper methods, and ensemble feature selection has\ngenerally no positive effect. Overall a simple Student's t-test seems to\nprovide the best results. Availability: Code and data are publicly available at\nhttp://cbio.ensmp.fr/~ahaury/.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jan 2011 09:04:05 GMT"}, {"version": "v2", "created": "Thu, 23 Jun 2011 07:17:10 GMT"}], "update_date": "2012-09-17", "authors_parsed": [["Haury", "Anne-Claire", "", "CBIO"], ["Gestraud", "Pierre", "", "CBIO"], ["Vert", "Jean-Philippe", "", "CBIO"]]}, {"id": "1101.5084", "submitter": "George Moustakides", "authors": "George V. Moustakides, Guido H. Jajamovich, Ali Tajer and Xiaodong\n  Wang", "title": "Joint Detection and Estimation: Optimum Tests and Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a well defined joint detection and parameter estimation problem.\nBy combining the Baysian formulation of the estimation subproblem with suitable\nconstraints on the detection subproblem we develop optimum one- and two-step\ntest for the joint detection/estimation case. The proposed combined strategies\nhave the very desirable characteristic to allow for the trade-off between\ndetection power and estimation efficiency. Our theoretical developments are\nthen applied to the problems of retrospective changepoint detection and MIMO\nradar. In the former case we are interested in detecting a change in the\nstatistics of a set of available data and provide an estimate for the time of\nchange, while in the latter in detecting a target and estimating its location.\nIntense simulations demonstrate that by using the jointly optimum schemes, we\ncan experience significant improvement in estimation quality with small\nsacrifice in detection power.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jan 2011 15:32:29 GMT"}], "update_date": "2011-01-27", "authors_parsed": [["Moustakides", "George V.", ""], ["Jajamovich", "Guido H.", ""], ["Tajer", "Ali", ""], ["Wang", "Xiaodong", ""]]}, {"id": "1101.5091", "submitter": "Christian P. Robert", "authors": "Christian Robert (Universite Paris Dauphine), Jean-Michel Marin\n  (Universite de Montpellier 2) and Natesh S. Pillai (Harvard University)", "title": "Why approximate Bayesian computational (ABC) methods cannot handle model\n  choice problems", "comments": "22 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO q-bio.QM stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Approximate Bayesian computation (ABC), also known as likelihood-free\nmethods, have become a favourite tool for the analysis of complex stochastic\nmodels, primarily in population genetics but also in financial analyses. We\nadvocated in Grelaud et al. (2009) the use of ABC for Bayesian model choice in\nthe specific case of Gibbs random fields (GRF), relying on a sufficiency\nproperty mainly enjoyed by GRFs to show that the approach was legitimate.\nDespite having previously suggested the use of ABC for model choice in a wider\nrange of models in the DIY ABC software (Cornuet et al., 2008), we present\ntheoretical evidence that the general use of ABC for model choice is fraught\nwith danger in the sense that no amount of computation, however large, can\nguarantee a proper approximation of the posterior probabilities of the models\nunder comparison.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jan 2011 15:51:55 GMT"}, {"version": "v2", "created": "Thu, 27 Jan 2011 06:32:36 GMT"}], "update_date": "2015-03-18", "authors_parsed": [["Robert", "Christian", "", "Universite Paris Dauphine"], ["Marin", "Jean-Michel", "", "Universite de Montpellier 2"], ["Pillai", "Natesh S.", "", "Harvard University"]]}, {"id": "1101.5263", "submitter": "Lukas Jelinek", "authors": "J. Hert, L. Jelinek, L. Pekarek, A. Pavlicek", "title": "No alignment of cattle along geomagnetic field lines found", "comments": "Added electronic supplement with source data", "journal-ref": "Journal of Comparative Physiology A 197, pp 677-682, 2011", "doi": "10.1007/s00359-011-0628-7", "report-no": null, "categories": "stat.AP physics.bio-ph q-bio.TO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a study of the body orientation of domestic cattle on\nfree pastures in several European states, based on Google satellite\nphotographs. In sum, 232 herds with 3412 individuals were evaluated. Two\nindependent groups participated in our study and came to the same conclusion\nthat, in contradiction to the recent findings of other researchers, no\nalignment of the animals and of their herds along geomagnetic field lines could\nbe found. Several possible reasons for this discrepancy should be taken into\naccount: poor quality of Google satellite photographs, difficulties in\ndetermining the body axis, selection of herds or animals within herds, lack of\nblinding in the evaluation, possible subconscious bias, and, most importantly,\nhigh sensitivity of the calculated main directions of the Rayleigh vectors to\nsome kind of bias or to some overlooked or ignored confounder. This factor\ncould easily have led to an unsubstantiated positive conclusion about the\nexistence of magnetoreception.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jan 2011 12:10:36 GMT"}, {"version": "v2", "created": "Tue, 1 Feb 2011 08:56:51 GMT"}], "update_date": "2014-09-10", "authors_parsed": [["Hert", "J.", ""], ["Jelinek", "L.", ""], ["Pekarek", "L.", ""], ["Pavlicek", "A.", ""]]}, {"id": "1101.5926", "submitter": "Marianna Bolla CSc", "authors": "Marianna Bolla", "title": "Beyond the Expanders", "comments": "Replacement is because of revised argument in Section 3 and adding\n  new Section 4", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Expander graphs are widely used in communication problems and construction of\nerror correcting codes. In such graphs, information gets through very quickly.\nTypically, it is not true for social or biological networks, though we may find\na partition of the vertices such that the induced subgraphs on them and the\nbipartite subgraphs between any pair of them exhibit regular behavior of\ninformation flow within or between the subsets. Implications between spectral\nand regularity properties are discussed.\n", "versions": [{"version": "v1", "created": "Mon, 31 Jan 2011 11:54:54 GMT"}, {"version": "v2", "created": "Thu, 3 Mar 2011 17:41:26 GMT"}], "update_date": "2011-03-04", "authors_parsed": [["Bolla", "Marianna", ""]]}, {"id": "1101.6063", "submitter": "Diego  Guarin  Mr.", "authors": "Diego Guarin, Edilson Delgado, Alvaro Orozco", "title": "Band-phase-randomized Surrogates to assess nonlinearity in\n  non-stationary time series", "comments": "submitted to IEEE Transactions on Biomedical Engineering", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Testing for nonlinearity is one of the most important preprocessing steps in\nnonlinear time series analysis. Typically, this is done by means of the linear\nsurrogate data methods. But it is a known fact that the validity of the results\nheavily depends on the stationarity of the time series. Since most\nphysiological signals are non-stationary, it is easy to falsely detect\nnonlinearity using the linear surrogate data methods. In this document, we\npropose a methodology to extend the procedure for generating constrained\nsurrogate time series in order to assess nonlinearity in non-stationary data.\nThe method is based on the band-phase-randomized surrogates, which consists\n(contrary to the linear surrogate data methods) in randomizing only a portion\nof the Fourier phases in the high frequency band. Analysis of simulated time\nseries showed that in comparison to the linear surrogate data method, our\nmethod is able to discriminate between linear stationarity, linear\nnon-stationary and nonlinear time series. When applying our methodology to\nheart rate variability (HRV) time series that present spikes and other kinds of\nnonstationarities, we where able to obtain surrogate time series that look like\nthe data and preserves linear correlations, something that is not possible to\ndo with the existing surrogate data methods.\n", "versions": [{"version": "v1", "created": "Mon, 31 Jan 2011 20:13:01 GMT"}], "update_date": "2011-02-01", "authors_parsed": [["Guarin", "Diego", ""], ["Delgado", "Edilson", ""], ["Orozco", "Alvaro", ""]]}]