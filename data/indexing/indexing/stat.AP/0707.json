[{"id": "0707.0284", "submitter": "Xinjia Chen", "authors": "Xinjia Chen, Guoxiang Gu and Kemin Zhou", "title": "A statistical theory for the measurement and estimation of Rayleigh\n  fading channel", "comments": "25 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.AP stat.TH", "license": null, "abstract": "  In this paper, we propose a statistical theory on measurement and estimation\nof Rayleigh fading channels in wireless communications and provide complete\nsolutions to the fundamental problems: What is the optimum estimator for the\nstatistical parameters associated with the Rayleigh fading channel, and how\nmany measurements are sufficient to estimate these parameters with the\nprescribed margin of error and confidence level? Our proposed statistical\ntheory suggests that two testing signals of different strength be used. The\nmaximum likelihood (ML) estimator is obtained for estimation of the statistical\nparameters of the Rayleigh fading channel that is both sufficient and complete\nstatistic. Moreover, the ML estimator is the minimum variance (MV) estimator\nthat in fact achieves the Cramer-Rao lower bound.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2007 18:04:35 GMT"}], "update_date": "2007-07-03", "authors_parsed": [["Chen", "Xinjia", ""], ["Gu", "Guoxiang", ""], ["Zhou", "Kemin", ""]]}, {"id": "0707.0462", "submitter": "Jason A. Osborne", "authors": "Jason A. Osborne and Tony E. Grift", "title": "M-estimation of Boolean models for particle flow experiments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": null, "abstract": "  Probability models are proposed for passage time data collected in\nexperiments with a device designed to measure particle flow during aerial\napplication of fertilizer. Maximum likelihood estimation of flow intensity is\nreviewed for the simple linear Boolean model, which arises with the assumption\nthat each particle requires the same known passage time. M-estimation is\ndeveloped for a generalization of the model in which passage times behave as a\nrandom sample from a distribution with a known mean. The generalized model\nimproves fit in these experiments. An estimator of total particle flow is\nconstructed by conditioning on lengths of multi-particle clumps.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2007 16:55:01 GMT"}], "update_date": "2007-07-04", "authors_parsed": [["Osborne", "Jason A.", ""], ["Grift", "Tony E.", ""]]}, {"id": "0707.0600", "submitter": "Marc Artzrouni", "authors": "Marc Artzrouni (LMA - PAU), Vivient Kamla (LMA - PAU)", "title": "Does heterosexual transmission drive the HIV/AIDS epidemic in\n  Sub-Saharan Africa (or elsewhere)?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": null, "abstract": "  A two-sex Basic Reproduction Number (BRN) is used to investigate the\nconditions under which the Human Immunodeficiency Virus (HIV) may spread\nthrough heterosexual contacts in Sub-Saharan Africa. (The BRN is the expected\nnumber of new infections generated by one infected individual; the disease\nspreads if the BRN is larger than 1). A simple analytical expression for the\nBRN is derived on the basis of recent data on survival rates, transmission\nprobabilities, and levels of sexual activity. Baseline results show that in the\npopulation at large (characterized by equal numbers of men and women) the BRN\nis larger than 1 if every year each person has 82 sexual contacts with\ndifferent partners. the BRN is also larger than 1 for commercial sex workers\n(CSWs) and their clients (two populations of different sizes) if each CSW has\nabout 256 clients per year and each client visits one CSW every two weeks. A\nsensitivity analysis explores the effect on the BRN of a doubling (or a\nhalving) of the transmission probabilities. Implications and extensions are\ndiscussed.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2007 12:48:46 GMT"}], "update_date": "2007-07-05", "authors_parsed": [["Artzrouni", "Marc", "", "LMA - PAU"], ["Kamla", "Vivient", "", "LMA - PAU"]]}, {"id": "0707.0805", "submitter": "Xinjia Chen", "authors": "Xinjia Chen", "title": "A New Generalization of Chebyshev Inequality for Random Vectors", "comments": "7 pages, 1 figure; added some references", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG math.PR stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we derive a new generalization of Chebyshev inequality for\nrandom vectors. We demonstrate that the new generalization is much less\nconservative than the classical generalization.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jul 2007 15:28:05 GMT"}, {"version": "v2", "created": "Fri, 24 Jun 2011 15:08:17 GMT"}], "update_date": "2013-11-05", "authors_parsed": [["Chen", "Xinjia", ""]]}, {"id": "0707.0823", "submitter": "Xinjia Chen", "authors": "Xinjia Chen, Kemin Zhou and Jorge L. Aravena", "title": "A Statistical Theory for the Analysis of Uncertain Systems", "comments": "32 pages, 15 figures", "journal-ref": "Proceeding of Joint Meeting of Statistics, pp. 1656--1663, Salt\n  Lake City, 2007", "doi": null, "report-no": null, "categories": "stat.AP math.DS", "license": null, "abstract": "  This paper addresses the issues of conservativeness and computational\ncomplexity of probabilistic robustness analysis. We solve both issues by\ndefining a new sampling strategy and robustness measure. The new measure is\nshown to be much less conservative than the existing one. The new sampling\nstrategy enables the definition of efficient hierarchical sample reuse\nalgorithms that reduce significantly the computational complexity and make it\nindependent of the dimension of the uncertainty space. Moreover, we show that\nthere exists a one to one correspondence between the new and the existing\nrobustness measures and provide a computationally simple algorithm to derive\none from the other.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jul 2007 16:12:32 GMT"}], "update_date": "2008-05-12", "authors_parsed": [["Chen", "Xinjia", ""], ["Zhou", "Kemin", ""], ["Aravena", "Jorge L.", ""]]}, {"id": "0707.0828", "submitter": "Xinjia Chen", "authors": "Xinjia Chen, Kemin Zhou and Jorge L. Aravena", "title": "Probabilistic Robustness Analysis -- Risks, Complexity and Algorithms", "comments": "28 pages, 5 figures", "journal-ref": "Published in SIAM Journal on Control and Optimization, vol. 47,\n  pp. 2693--2723, 2008", "doi": null, "report-no": null, "categories": "stat.AP math.ST stat.TH", "license": null, "abstract": "  It is becoming increasingly apparent that probabilistic approaches can\novercome conservatism and computational complexity of the classical worst-case\ndeterministic framework and may lead to designs that are actually safer. In\nthis paper we argue that a comprehensive probabilistic robustness analysis\nrequires a detailed evaluation of the robustness function and we show that such\nevaluation can be performed with essentially any desired accuracy and\nconfidence using algorithms with complexity linear in the dimension of the\nuncertainty space. Moreover, we show that the average memory requirements of\nsuch algorithms are absolutely bounded and well within the capabilities of\ntoday's computers.\n  In addition to efficiency, our approach permits control over statistical\nsampling error and the error due to discretization of the uncertainty radius.\nFor a specific level of tolerance of the discretization error, our techniques\nprovide an efficiency improvement upon conventional methods which is inversely\nproportional to the accuracy level; i.e., our algorithms get better as the\ndemands for accuracy increase.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jul 2007 16:42:21 GMT"}], "update_date": "2008-11-01", "authors_parsed": [["Chen", "Xinjia", ""], ["Zhou", "Kemin", ""], ["Aravena", "Jorge L.", ""]]}, {"id": "0707.0861", "submitter": "Mikhail Langovoy", "authors": "Mikhail Langovoy", "title": "Data-driven efficient score tests for deconvolution problems", "comments": null, "journal-ref": "Inverse Problems 24 (2008) 025028 17pp", "doi": "10.1088/0266-5611/24/2/025028", "report-no": null, "categories": "math.ST stat.AP stat.TH", "license": null, "abstract": "  We consider testing statistical hypotheses about densities of signals in\ndeconvolution models. A new approach to this problem is proposed. We\nconstructed score tests for the deconvolution with the known noise density and\nefficient score tests for the case of unknown density. The tests are\nincorporated with model selection rules to choose reasonable model dimensions\nautomatically by the data. Consistency of the tests is proved.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jul 2007 19:41:36 GMT"}], "update_date": "2013-12-02", "authors_parsed": [["Langovoy", "Mikhail", ""]]}, {"id": "0707.1384", "submitter": "Dmitry Ivanenko Alexandrovich", "authors": "Dmytro Ivanenko", "title": "Asymptotically Optimal Estimator of the Parameter of Semi-Linear\n  Autoregression", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.DS stat.AP stat.TH", "license": null, "abstract": "  The difference equations $\\xi_{k}=af(\\xi_{k-1})+\\epsilon_{k}$, where\n$(\\epsilon_k)$ is a square integrable difference martingale, and the\ndifferential equation ${\\rm d}\\xi=-af(\\xi){\\rm d}t+{\\rm d}\\eta$, where $\\eta$\nis a square integrable martingale, are considered. A family of estimators\ndepending, besides the sample size $n$ (or the observation period, if time is\ncontinuous) on some random Lipschitz functions is constructed. Asymptotic\noptimality of this estimators is investigated.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2007 08:48:06 GMT"}], "update_date": "2007-07-11", "authors_parsed": [["Ivanenko", "Dmytro", ""]]}, {"id": "0707.3013", "submitter": "Frederic Dambreville", "authors": "Alois Kirchner, Frederic Dambreville (DGA/CTA/DT/GIP), Francis Celeste\n  (DGA/CTA/DT/GIP), Jean Dezert, Florentin Smarandache", "title": "Application of probabilistic PCR5 Fusion Rule for Multisensor Target\n  Tracking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": null, "abstract": "  This paper defines and implements a non-Bayesian fusion rule for combining\ndensities of probabilities estimated by local (non-linear) filters for tracking\na moving target by passive sensors. This rule is the restriction to a strict\nprobabilistic paradigm of the recent and efficient Proportional Conflict\nRedistribution rule no 5 (PCR5) developed in the DSmT framework for fusing\nbasic belief assignments. A sampling method for probabilistic PCR5 (p-PCR5) is\ndefined. It is shown that p-PCR5 is more robust to an erroneous modeling and\nallows to keep the modes of local densities and preserve as much as possible\nthe whole information inherent to each densities to combine. In particular,\np-PCR5 is able of maintaining multiple hypotheses/modes after fusion, when the\nhypotheses are too distant in regards to their deviations. This new p-PCR5 rule\nhas been tested on a simple example of distributed non-linear filtering\napplication to show the interest of such approach for future developments. The\nnon-linear distributed filter is implemented through a basic particles\nfiltering technique. The results obtained in our simulations show the ability\nof this p-PCR5-based filter to track the target even when the models are not\nwell consistent in regards to the initialization and real cinematic.\n", "versions": [{"version": "v1", "created": "Fri, 20 Jul 2007 08:23:41 GMT"}], "update_date": "2007-07-24", "authors_parsed": [["Kirchner", "Alois", "", "DGA/CTA/DT/GIP"], ["Dambreville", "Frederic", "", "DGA/CTA/DT/GIP"], ["Celeste", "Francis", "", "DGA/CTA/DT/GIP"], ["Dezert", "Jean", ""], ["Smarandache", "Florentin", ""]]}, {"id": "0707.3482", "submitter": "Kenton K. Yee", "authors": "Kenton K. Yee", "title": "A Bayesian Framework for Combining Valuation Estimates", "comments": "Citations at\n  http://papers.ssrn.com/sol3/cf_dev/AbsByAuth.cfm?per_id=240309 Review of\n  Quantitative Finance and Accounting, 30.3 (2008) forthcoming", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.CE nlin.AO nlin.CD nlin.SI physics.pop-ph physics.soc-ph stat.AP", "license": null, "abstract": "  Obtaining more accurate equity value estimates is the starting point for\nstock selection, value-based indexing in a noisy market, and beating benchmark\nindices through tactical style rotation. Unfortunately, discounted cash flow,\nmethod of comparables, and fundamental analysis typically yield discrepant\nvaluation estimates. Moreover, the valuation estimates typically disagree with\nmarket price. Can one form a superior valuation estimate by averaging over the\nindividual estimates, including market price? This article suggests a Bayesian\nframework for combining two or more estimates into a superior valuation\nestimate. The framework justifies the common practice of averaging over several\nestimates to arrive at a final point estimate.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jul 2007 05:04:53 GMT"}], "update_date": "2008-12-02", "authors_parsed": [["Yee", "Kenton K.", ""]]}, {"id": "0707.4242", "submitter": "Robert B. Gramacy", "authors": "Robert B. Gramacy, Richard J. Samworth, Ruth King", "title": "Importance Tempering", "comments": "16 pages, 2 tables, significantly shortened from version 4 in\n  response to referee comments, to appear in Statistics and Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simulated tempering (ST) is an established Markov chain Monte Carlo (MCMC)\nmethod for sampling from a multimodal density $\\pi(\\theta)$. Typically, ST\ninvolves introducing an auxiliary variable $k$ taking values in a finite subset\nof $[0,1]$ and indexing a set of tempered distributions, say $\\pi_k(\\theta)\n\\propto \\pi(\\theta)^k$. In this case, small values of $k$ encourage better\nmixing, but samples from $\\pi$ are only obtained when the joint chain for\n$(\\theta,k)$ reaches $k=1$. However, the entire chain can be used to estimate\nexpectations under $\\pi$ of functions of interest, provided that importance\nsampling (IS) weights are calculated. Unfortunately this method, which we call\nimportance tempering (IT), can disappoint. This is partly because the most\nimmediately obvious implementation is na\\\"ive and can lead to high variance\nestimators. We derive a new optimal method for combining multiple IS estimators\nand prove that the resulting estimator has a highly desirable property related\nto the notion of effective sample size. We briefly report on the success of the\noptimal combination in two modelling scenarios requiring reversible-jump MCMC,\nwhere the na\\\"ive approach fails.\n", "versions": [{"version": "v1", "created": "Sat, 28 Jul 2007 15:04:57 GMT"}, {"version": "v2", "created": "Thu, 9 Aug 2007 19:26:59 GMT"}, {"version": "v3", "created": "Thu, 16 Aug 2007 15:35:12 GMT"}, {"version": "v4", "created": "Mon, 17 Sep 2007 16:21:18 GMT"}, {"version": "v5", "created": "Mon, 8 Sep 2008 15:10:25 GMT"}, {"version": "v6", "created": "Mon, 3 Nov 2008 18:12:25 GMT"}], "update_date": "2008-11-03", "authors_parsed": [["Gramacy", "Robert B.", ""], ["Samworth", "Richard J.", ""], ["King", "Ruth", ""]]}]