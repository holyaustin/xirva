[{"id": "1501.00019", "submitter": "Peter Waddell", "authors": "Peter J. Waddell", "title": "Extended Distance-based Phylogenetic Analyses Applied to 3D Homo Fossil\n  Skull Evolution", "comments": "42 pages, 18 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE q-bio.QM stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article shows how 3D geometric morphometric data can be analyzed using\nnewly developed distance-based evolutionary tree inference methods, with\nextensions to planar graphs. Application of these methods to 3D representations\nof the skullcap (calvaria) of 13 diverse skulls in the genus Homo, ranging from\nHomo erectus (ergaster) at about 1.6 mya, all the way forward to modern humans,\nyields a remarkably clear phylogenetic tree. Various evolutionary hypotheses\nare tested. Results of these tests include rejection of the monophyly of Homo\nheidelbergensis, the Multi-Regional hypothesis, and the hypothesis that the\nunusual 12,000 year old (12kya) Iwo Eleru skull represents a modern human.\nRather, by quantitative phylogenetic analyses the latter is seen to be an old\n(200-400kya) lineage that probably represents a novel African species, Homo\niwoelerueensis. It diverged after the lineage leading to Neanderthals, and may\nhave been driven to extinction in the last 10kya by modern humans, Homo\nsapiens, another African species of Homo that appeared about 100kya. Another\nenigmatic skull, Qafzeh 6 from the Middle East about 90kya, appears to be a\nhybrid of two thirds near, but not, anatomically modern human and one third of\nan archaic lineage diverging close to classic European Neanderthals. Overall,\nthe tree clearly implies an accelerating rate of skullcap shape change, and by\nextension, change of the underlying brain, over the last 400kya in Africa. This\nacceleration may have extended right up to the origin of modern humans. Methods\nof distance-based evolutionary tree inference are refined and extended, with\nparticular attention to diagnosing the model and achieving a better fit. This\nincludes power transformations of the input data which favor root Procrustes\ndistances.\n", "versions": [{"version": "v1", "created": "Tue, 30 Dec 2014 21:05:27 GMT"}], "update_date": "2015-01-05", "authors_parsed": [["Waddell", "Peter J.", ""]]}, {"id": "1501.00230", "submitter": "Bronwyn Woods", "authors": "Bronwyn Woods", "title": "Spatio-temporal patterns in multi-electrode array local field potential\n  recordings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a method for the detection of traveling waves of activity\nin neural recordings from multi-electrode arrays. The method converts local\nfield potential measurements into the phase domain and fits a series of linear\nmodels to find planar traveling waves of activity. Here I present the new\napproach in the context of the previous work it extends, apply the approach to\ndata from neural recordings from a single animal, and verify the success of the\nmethod on simulated data.\n  This paper was written in 2011, though it was uploaded to arXiv in 2014.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jan 2015 01:33:13 GMT"}], "update_date": "2015-01-05", "authors_parsed": [["Woods", "Bronwyn", ""]]}, {"id": "1501.00372", "submitter": "Manuel Oviedo de la Fuente", "authors": "Juan A. Cuesta-Albertos, Manuel Febrero-Bande, Manuel Oviedo de la\n  Fuente", "title": "The DD$^G$-classifier in the functional setting", "comments": "29 pages, 6 figures, 6 tables, Supplemental R Code and Data", "journal-ref": "Cuesta-Albertos, J. A., Febrero-Bande, M., & de la Fuente, M. O.\n  (2017). The\\hbox {DD}^ G-classifier in the functional setting. Test, 26(1),\n  119-142", "doi": "10.1007/s11749-016-0502-6", "report-no": null, "categories": "stat.ME stat.AP", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The Maximum Depth was the first attempt to use data depths instead of\nmultivariate raw data to construct a classification rule. Recently, the\nDD-classifier has solved several serious limitations of the Maximum Depth\nclassifier but some issues still remain. This paper is devoted to extending the\nDD-classifier in the following ways: first, to surpass the limitation of the\nDD-classifier when more than two groups are involved. Second to apply regular\nclassification methods (like $k$NN, linear or quadratic classifiers, recursive\npartitioning,...) to DD-plots to obtain useful insights through the diagnostics\nof these methods. And third, to integrate different sources of information\n(data depths or multivariate functional data) in a unified way in the\nclassification procedure. Besides, as the DD-classifier trick is especially\nuseful in the functional framework, an enhanced revision of several functional\ndata depths is done in the paper. A simulation study and applications to some\nclassical real datasets are also provided showing the power of the new\nproposal.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jan 2015 09:32:18 GMT"}, {"version": "v2", "created": "Wed, 18 Feb 2015 15:27:33 GMT"}, {"version": "v3", "created": "Mon, 2 May 2016 14:55:44 GMT"}], "update_date": "2018-01-04", "authors_parsed": [["Cuesta-Albertos", "Juan A.", ""], ["Febrero-Bande", "Manuel", ""], ["de la Fuente", "Manuel Oviedo", ""]]}, {"id": "1501.00450", "submitter": "Alex Deng", "authors": "Yu Guo and Alex Deng", "title": "Flexible Online Repeated Measures Experiment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online controlled experiments, now commonly known as A/B testing, are crucial\nto causal inference and data driven decision making in many internet based\nbusinesses. While a simple comparison between a treatment (the feature under\ntest) and a control (often the current standard), provides a starting point to\nidentify the cause of change in Key Performance Indicator (KPI), it is often\ninsufficient, as the change we wish to detect may be small, and inherent\nvariation contained in data may obscure movements in KPI. To have sufficient\npower to detect statistically significant changes in KPI, an experiment needs\nto engage a sufficiently large proportion of traffic to the site, and also last\nfor a sufficiently long duration. This limits the number of candidate\nvariations to be evaluated, and the speed new feature iterations. We introduce\nmore sophisticated experimental designs, specifically the repeated measures\ndesign, including the crossover design and related variants, to increase KPI\nsensitivity with the same traffic size and duration of experiment. In this\npaper we present FORME (Flexible Online Repeated Measures Experiment), a\nflexible and scalable framework for these designs. We evaluate the theoretic\nbasis, design considerations, practical guidelines and big data implementation.\nWe compare FORME to an existing methodology called mixed effect model and\ndemonstrate why FORME is more flexible and scalable. We present empirical\nresults based on both simulation and real data. Our method is widely applicable\nto online experimentation to improve sensitivity in detecting movements in KPI,\nand increase experimentation capability.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jan 2015 18:03:38 GMT"}], "update_date": "2015-01-05", "authors_parsed": [["Guo", "Yu", ""], ["Deng", "Alex", ""]]}, {"id": "1501.00537", "submitter": "He Kun", "authors": "Kun He, Yan Fu, Wen-Feng Zeng, Lan Luo, Hao Chi, Chao Liu, Lai-Yun\n  Qing, Rui-Xiang Sun, and Si-Min He", "title": "A theoretical foundation of the target-decoy search strategy for false\n  discovery rate control in proteomics", "comments": "7 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivation: Target-decoy search (TDS) is currently the most popular strategy\nfor estimating and controlling the false discovery rate (FDR) of peptide\nidentifications in mass spectrometry-based shotgun proteomics. While this\nstrategy is very useful in practice and has been intensively studied\nempirically, its theoretical foundation has not yet been well established.\nResult: In this work, we systematically analyze the TDS strategy in a rigorous\nstatistical sense. We prove that the commonly used concatenated TDS provides a\nconservative estimate of the FDR for any given score threshold, but it cannot\nrigorously control the FDR. We prove that with a slight modification to the\ncommonly used formula for FDR estimation, the peptide-level FDR can be\nrigorously controlled based on the concatenated TDS. We show that the\nspectrum-level FDR control is difficult. We verify the theoretical conclusions\nwith real mass spectrometry data.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jan 2015 07:20:05 GMT"}], "update_date": "2015-01-06", "authors_parsed": [["He", "Kun", ""], ["Fu", "Yan", ""], ["Zeng", "Wen-Feng", ""], ["Luo", "Lan", ""], ["Chi", "Hao", ""], ["Liu", "Chao", ""], ["Qing", "Lai-Yun", ""], ["Sun", "Rui-Xiang", ""], ["He", "Si-Min", ""]]}, {"id": "1501.00592", "submitter": "Necla Gunduz", "authors": "Necla Gunduz and Ernest Fokoue", "title": "Robust Classification of High Dimension Low Sample Size Data", "comments": "17 pages, 29 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The robustification of pattern recognition techniques has been the subject of\nintense research in recent years. Despite the multiplicity of papers on the\nsubject, very few articles have deeply explored the topic of robust\nclassification in the high dimension low sample size context. In this work, we\nexplore and compare the predictive performances of robust classification\ntechniques with a special concentration on robust discriminant analysis and\nrobust PCA applied to a wide variety of large $p$ small $n$ data sets. We also\nexplore the performance of random forest by way of comparing and contrasting\nthe differences single model methods and ensemble methods in this context. Our\nwork reveals that Random Forest, although not inherently designed to be robust\nto outliers, substantially outperforms the existing techniques specifically\ndesigned to achieve robustness. Indeed, random forest emerges as the best\npredictively on both real life and simulated data.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jan 2015 18:50:19 GMT"}], "update_date": "2015-01-06", "authors_parsed": [["Gunduz", "Necla", ""], ["Fokoue", "Ernest", ""]]}, {"id": "1501.00738", "submitter": "Henry Lin Mr.", "authors": "Henry W. Lin and Abraham Loeb", "title": "Zipf's Law from Scale-free Geometry", "comments": "7 pages, 2 figures, accepted for publication in Physical Review E", "journal-ref": "Phys. Rev. E 93, 032306 (2016)", "doi": "10.1103/PhysRevE.93.032306", "report-no": null, "categories": "physics.soc-ph astro-ph.CO cond-mat.stat-mech cs.SI stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The spatial distribution of people exhibits clustering across a wide range of\nscales, from household ($\\sim 10^{-2}$ km) to continental ($\\sim 10^4$ km)\nscales. Empirical data indicates simple power-law scalings for the size\ndistribution of cities (known as Zipf's law) and the population density\nfluctuations as a function of scale. Using techniques from random field theory\nand statistical physics, we show that these power laws are fundamentally a\nconsequence of the scale-free spatial clustering of human populations and the\nfact that humans inhabit a two-dimensional surface. In this sense, the\nsymmetries of scale invariance in two spatial dimensions are intimately\nconnected to urban sociology. We test our theory by empirically measuring the\npower spectrum of population density fluctuations and show that the logarithmic\nslope $\\alpha = 2.04 \\pm 0.09$, in excellent agreement with our theoretical\nprediction $\\alpha = 2$. The model enables the analytic computation of many new\npredictions by importing the mathematical formalism of random fields.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jan 2015 00:33:58 GMT"}, {"version": "v2", "created": "Sun, 19 Apr 2015 18:10:28 GMT"}, {"version": "v3", "created": "Mon, 15 Feb 2016 00:40:33 GMT"}], "update_date": "2016-03-23", "authors_parsed": [["Lin", "Henry W.", ""], ["Loeb", "Abraham", ""]]}, {"id": "1501.00818", "submitter": "Rick Steinert", "authors": "Florian Ziel, Rick Steinert, Sven Husmann", "title": "Forecasting day ahead electricity spot prices: The impact of the EXAA to\n  other European electricity markets", "comments": null, "journal-ref": "Energy Economics, 51 (2015) 430-444", "doi": "10.1016/j.eneco.2015.08.005", "report-no": null, "categories": "q-fin.TR econ.EM q-fin.ST stat.AP stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In our paper we analyze the relationship between the day-ahead electricity\nprice of the Energy Exchange Austria (EXAA) and other day-ahead electricity\nprices in Europe. We focus on markets, which settle their prices after the\nEXAA, which enables traders to include the EXAA price into their calculations.\nFor each market we employ econometric models to incorporate the EXAA price and\ncompare them with their counterparts without the price of the Austrian\nexchange. By employing a forecasting study, we find that electricity price\nmodels can be improved when EXAA prices are considered.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jan 2015 11:07:11 GMT"}, {"version": "v2", "created": "Tue, 1 Dec 2015 12:27:49 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Ziel", "Florian", ""], ["Steinert", "Rick", ""], ["Husmann", "Sven", ""]]}, {"id": "1501.00960", "submitter": "Peter Sheridan Dodds", "authors": "Eitan Adam Pechenick, Christopher M. Danforth, Peter Sheridan Dodds", "title": "Characterizing the Google Books corpus: Strong limits to inferences of\n  socio-cultural and linguistic evolution", "comments": "13 pages, 16 figures", "journal-ref": "PLoS ONE, 10, e0137041, 2015", "doi": "10.1371/journal.pone.0137041", "report-no": null, "categories": "physics.soc-ph cond-mat.stat-mech cs.CL stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is tempting to treat frequency trends from the Google Books data sets as\nindicators of the \"true\" popularity of various words and phrases. Doing so\nallows us to draw quantitatively strong conclusions about the evolution of\ncultural perception of a given topic, such as time or gender. However, the\nGoogle Books corpus suffers from a number of limitations which make it an\nobscure mask of cultural popularity. A primary issue is that the corpus is in\neffect a library, containing one of each book. A single, prolific author is\nthereby able to noticeably insert new phrases into the Google Books lexicon,\nwhether the author is widely read or not. With this understood, the Google\nBooks corpus remains an important data set to be considered more lexicon-like\nthan text-like. Here, we show that a distinct problematic feature arises from\nthe inclusion of scientific texts, which have become an increasingly\nsubstantive portion of the corpus throughout the 1900s. The result is a surge\nof phrases typical to academic articles but less common in general, such as\nreferences to time in the form of citations. We highlight these dynamics by\nexamining and comparing major contributions to the statistical divergence of\nEnglish data sets between decades in the period 1800--2000. We find that only\nthe English Fiction data set from the second version of the corpus is not\nheavily affected by professional texts, in clear contrast to the first version\nof the fiction data set and both unfiltered English data sets. Our findings\nemphasize the need to fully characterize the dynamics of the Google Books\ncorpus before using these data sets to draw broad conclusions about cultural\nand linguistic evolution.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jan 2015 20:09:59 GMT"}, {"version": "v2", "created": "Thu, 7 May 2015 10:11:46 GMT"}, {"version": "v3", "created": "Fri, 24 Mar 2017 11:46:25 GMT"}, {"version": "v4", "created": "Wed, 27 May 2020 13:37:06 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Pechenick", "Eitan Adam", ""], ["Danforth", "Christopher M.", ""], ["Dodds", "Peter Sheridan", ""]]}, {"id": "1501.01121", "submitter": "Aina Frau-Pascual", "authors": "Aina Frau-Pascual (INRIA Grenoble Rh\\^one-Alpes / LJK Laboratoire Jean\n  Kuntzmann, INRIA Saclay - Ile de France), Thomas Vincent (INRIA Grenoble\n  Rh\\^one-Alpes / LJK Laboratoire Jean Kuntzmann), Florence Forbes (INRIA\n  Grenoble Rh\\^one-Alpes / LJK Laboratoire Jean Kuntzmann), Philippe Ciuciu\n  (CEA, INRIA Saclay - Ile de France)", "title": "Hemodynamically informed parcellation of cerebral FMRI data", "comments": null, "journal-ref": "Acoustics, Speech and Signal Processing (ICASSP), 2014 IEEE\n  International Conference on, May 2014, Florence, Italy. pp.2079 - 2083", "doi": "10.1109/ICASSP.2014.6853965", "report-no": null, "categories": "stat.AP q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard detection of evoked brain activity in functional MRI (fMRI) relies\non a fixed and known shape of the impulse response of the neurovascular\ncoupling, namely the hemodynamic response function (HRF). To cope with this\nissue, the joint detection-estimation (JDE) framework has been proposed. This\nformalism enables to estimate a HRF per region but for doing so, it assumes a\nprior brain partition (or parcellation) regarding hemodynamic territories. This\npartition has to be accurate enough to recover accurate HRF shapes but has also\nto overcome the detection-estimation issue: the lack of hemodynamics\ninformation in the non-active positions. An hemodynamically-based parcellation\nmethod is proposed, consisting first of a feature extraction step, followed by\na Gaussian Mixture-based parcellation, which considers the injection of the\nactivation levels in the parcellation process, in order to overcome the\ndetection-estimation issue and find the underlying hemodynamics.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jan 2015 09:36:29 GMT"}], "update_date": "2015-01-07", "authors_parsed": [["Frau-Pascual", "Aina", "", "INRIA Grenoble Rh\u00f4ne-Alpes / LJK Laboratoire Jean\n  Kuntzmann, INRIA Saclay - Ile de France"], ["Vincent", "Thomas", "", "INRIA Grenoble\n  Rh\u00f4ne-Alpes / LJK Laboratoire Jean Kuntzmann"], ["Forbes", "Florence", "", "INRIA\n  Grenoble Rh\u00f4ne-Alpes / LJK Laboratoire Jean Kuntzmann"], ["Ciuciu", "Philippe", "", "CEA, INRIA Saclay - Ile de France"]]}, {"id": "1501.01133", "submitter": "Aina Frau-Pascual", "authors": "Aina Frau-Pascual (INRIA Grenoble Rh\\^one-Alpes / LJK Laboratoire Jean\n  Kuntzmann, INRIA Saclay - Ile de France), Thomas Vincent (INRIA Grenoble\n  Rh\\^one-Alpes / LJK Laboratoire Jean Kuntzmann), Jennifer Sloboda (INRIA\n  Grenoble Rh\\^one-Alpes / LJK Laboratoire Jean Kuntzmann), Philippe CIUCIU\n  (CEA, INRIA Saclay - Ile de France), Florence Forbes (INRIA Grenoble\n  Rh\\^one-Alpes / LJK Laboratoire Jean Kuntzmann)", "title": "Physiologically Informed Bayesian Analysis of ASL fMRI Data", "comments": null, "journal-ref": "Bayesian and Graphical Models for Biomedical Imaging, Sep 2014,\n  Boston, United States. Springer International Publishing, 8677, pp.37 - 48,\n  Lecture Notes in Computer Science", "doi": "10.1007/978-3-319-12289-2_4", "report-no": null, "categories": "stat.AP q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Arterial Spin Labelling (ASL) functional Magnetic Resonance Imaging (fMRI)\ndata provides a quantitative measure of blood perfusion, that can be correlated\nto neuronal activation. In contrast to BOLD measure, it is a direct measure of\ncerebral blood flow. However, ASL data has a lower SNR and resolution so that\nthe recovery of the perfusion response of interest suffers from the\ncontamination by a stronger hemodynamic component in the ASL signal. In this\nwork we consider a model of both hemodynamic and perfusion components within\nthe ASL signal. A physiological link between these two components is analyzed\nand used for a more accurate estimation of the perfusion response function in\nparticular in the usual ASL low SNR conditions.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jan 2015 10:37:07 GMT"}], "update_date": "2015-01-07", "authors_parsed": [["Frau-Pascual", "Aina", "", "INRIA Grenoble Rh\u00f4ne-Alpes / LJK Laboratoire Jean\n  Kuntzmann, INRIA Saclay - Ile de France"], ["Vincent", "Thomas", "", "INRIA Grenoble\n  Rh\u00f4ne-Alpes / LJK Laboratoire Jean Kuntzmann"], ["Sloboda", "Jennifer", "", "INRIA\n  Grenoble Rh\u00f4ne-Alpes / LJK Laboratoire Jean Kuntzmann"], ["CIUCIU", "Philippe", "", "CEA, INRIA Saclay - Ile de France"], ["Forbes", "Florence", "", "INRIA Grenoble\n  Rh\u00f4ne-Alpes / LJK Laboratoire Jean Kuntzmann"]]}, {"id": "1501.01366", "submitter": "Georgios Fellouris Dr.", "authors": "Shiyu Wang, Georgios Fellouris and Hua-Hua Chang", "title": "Sequential Design for Computerized Adaptive Testing that Allows for\n  Response Revision", "comments": "32 pages,2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.AP stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In computerized adaptive testing (CAT), items (questions) are selected in\nreal time based on the already observed responses, so that the ability of the\nexaminee can be estimated as accurately as possible. This is typically\nformulated as a non-linear, sequential, experimental design problem with binary\nobservations that correspond to the true or false responses. However, most\nitems in practice are multiple-choice and dichotomous models do not make full\nuse of the available data. Moreover, CAT has been heavily criticized for not\nallowing test-takers to review and revise their answers. In this work, we\npropose a novel CAT design that is based on the polytomous nominal response\nmodel and in which test-takers are allowed to revise their responses at any\ntime during the test. We show that as the number of administered items goes to\ninfinity, the proposed estimator is (i) strongly consistent for any item\nselection and revision strategy and (ii) asymptotically normal when the items\nare selected to maximize the Fisher information at the current ability estimate\nand the number of revisions is smaller than the number of items. We also\npresent the findings of a simulation study that supports our asymptotic\nresults.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jan 2015 04:07:02 GMT"}], "update_date": "2015-01-08", "authors_parsed": [["Wang", "Shiyu", ""], ["Fellouris", "Georgios", ""], ["Chang", "Hua-Hua", ""]]}, {"id": "1501.01617", "submitter": "Lucy Xia", "authors": "Jianqing Fan, Yang Feng, Lucy Xia", "title": "A Projection Based Conditional Dependence Measure with Applications to\n  High-dimensional Undirected Graphical Models", "comments": "39 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.AP stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Measuring conditional dependence is an important topic in statistics with\nbroad applications including graphical models. Under a factor model setting, a\nnew conditional dependence measure based on projection is proposed. The\ncorresponding conditional independence test is developed with the asymptotic\nnull distribution unveiled where the number of factors could be\nhigh-dimensional. It is also shown that the new test has control over the\nasymptotic significance level and can be calculated efficiently. A generic\nmethod for building dependency graphs without Gaussian assumption using the new\ntest is elaborated. Numerical results and real data analysis show the\nsuperiority of the new method.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jan 2015 20:43:14 GMT"}, {"version": "v2", "created": "Thu, 8 Jan 2015 20:08:35 GMT"}, {"version": "v3", "created": "Wed, 23 Nov 2016 04:50:55 GMT"}, {"version": "v4", "created": "Tue, 14 Feb 2017 20:33:54 GMT"}, {"version": "v5", "created": "Fri, 11 Jan 2019 07:36:17 GMT"}], "update_date": "2019-01-14", "authors_parsed": [["Fan", "Jianqing", ""], ["Feng", "Yang", ""], ["Xia", "Lucy", ""]]}, {"id": "1501.01814", "submitter": "Stefano Andreon", "authors": "S. Andreon", "title": "Relative distribution of dark matter and stellar mass in three massive\n  galaxy clusters", "comments": "A&A, in press", "journal-ref": "A&A 575, A108 (2015)", "doi": "10.1051/0004-6361/201425122", "report-no": null, "categories": "astro-ph.CO astro-ph.GA astro-ph.IM stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work observationally addresses the relative distribution of total and\noptically luminous matter in galaxy clusters by computing the radial profile of\nthe stellar-to-total mass ratio. We adopt state-of-the-art accurate lensing\nmasses free from assumptions about the mass radial profile and we use extremely\ndeep multicolor wide--field optical images to distinguish star formation from\nstellar mass, to properly calculate the mass in galaxies of low mass, those\noutside the red sequence, and to allow a contribution from galaxies of low mass\nthat is clustercentric dependent. We pay special attention to issues and\ncontributions that are usually underrated, yet are major sources of\nuncertainty, and we present an approach that allows us to account for all of\nthem. Here we present the results for three very massive clusters at\n$z\\sim0.45$, MACSJ1206.2-0847, MACSJ0329.6-0211, and RXJ1347.5-1145. We find\nthat stellar mass and total matter are closely distributed on scales from about\n150 kpc to 2.5 Mpc: the stellar-to-total mass ratio is radially constant. We\nfind that the characteristic mass stays constant across clustercentric radii\nand clusters, but that the less-massive end of the galaxy mass function is\ndependent on the environment.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jan 2015 12:18:31 GMT"}], "update_date": "2015-03-11", "authors_parsed": [["Andreon", "S.", ""]]}, {"id": "1501.01898", "submitter": "Jia  Liu", "authors": "Jia Liu, Dario Gasbarra, Juha Railavo", "title": "Fast Estimation of Diffusion Tensors under Rician noise by the EM\n  algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a fast computational method, the Expectation Maximization\nalgorithm, for Maximum Likelihood (ML) estimation in diffusion tensor imaging\nunder the Rice noise model. We further extend the ML framework to the maximum a\nposterior (MAP) estimation and describe the numerical similarities of both ML\nand MAP estimators. This novel method is implemented and applied using both\nsynthetic and real data in a wide range of b amplitudes. The comparison with\nother popular methods are made in accuracy, methodology and computation.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jan 2015 16:29:16 GMT"}], "update_date": "2015-01-09", "authors_parsed": [["Liu", "Jia", ""], ["Gasbarra", "Dario", ""], ["Railavo", "Juha", ""]]}, {"id": "1501.01937", "submitter": "Won Chang", "authors": "Won Chang, Murali Haran, Patrick Applegate, David Pollard", "title": "Calibrating an ice sheet model using high-dimensional binary spatial\n  data", "comments": null, "journal-ref": "Journal of the American Statistical Association (2016), Volume\n  111, Issue 513, 57-72", "doi": "10.1080/01621459.2015.1108199", "report-no": null, "categories": "stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rapid retreat of ice in the Amundsen Sea sector of West Antarctica may cause\ndrastic sea level rise, posing significant risks to populations in low-lying\ncoastal regions. Calibration of computer models representing the behavior of\nthe West Antarctic Ice Sheet is key for informative projections of future sea\nlevel rise. However, both the relevant observations and the model output are\nhigh-dimensional binary spatial data; existing computer model calibration\nmethods are unable to handle such data. Here we present a novel calibration\nmethod for computer models whose output is in the form of binary spatial data.\nTo mitigate the computational and inferential challenges posed by our approach,\nwe apply a generalized principal component based dimension reduction method. To\ndemonstrate the utility of our method, we calibrate the PSU3D-ICE model by\ncomparing the output from a 499-member perturbed-parameter ensemble with\nobservations from the Amundsen Sea sector of the ice sheet. Our methods help\nrigorously characterize the parameter uncertainty even in the presence of\nsystematic data-model discrepancies and dependence in the errors. Our method\nalso helps inform environmental risk analyses by contributing to improved\nprojections of sea level rise from the ice sheets.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jan 2015 19:45:00 GMT"}, {"version": "v2", "created": "Fri, 9 Jan 2015 03:49:32 GMT"}, {"version": "v3", "created": "Tue, 5 May 2015 21:43:12 GMT"}, {"version": "v4", "created": "Thu, 2 Jul 2015 22:50:38 GMT"}, {"version": "v5", "created": "Thu, 3 Sep 2015 03:25:39 GMT"}, {"version": "v6", "created": "Fri, 20 May 2016 04:38:32 GMT"}], "update_date": "2016-05-23", "authors_parsed": [["Chang", "Won", ""], ["Haran", "Murali", ""], ["Applegate", "Patrick", ""], ["Pollard", "David", ""]]}, {"id": "1501.02108", "submitter": "Maciej A. Nowak", "authors": "Zbigniew Drogosz, Jerzy Jurkiewicz, Grzegorz {\\L}ukaszewski, Maciej A.\n  Nowak", "title": "Signal from noise retrieval from one and two-point Green's function -\n  comparison", "comments": "14 pages, 8 figures, 3 tables", "journal-ref": "Phys. Rev. E 92, 022111 (2015)", "doi": "10.1103/PhysRevE.92.022111", "report-no": null, "categories": "stat.AP math-ph math.MP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We compare two methods of eigen-inference from large sets of data, based on\nthe analysis of one-point and two-point Green's functions, respectively. Our\nanalysis points at the superiority of eigen-inference based on one-point\nGreen's function. First, the applied by us method based on Pad?e approximants\nis orders of magnitude faster comparing to the eigen-inference based on\nuctuations (two-point Green's functions). Second, we have identified the source\nof potential instability of the two-point Green's function method, as arising\nfrom the spurious zero and negative modes of the estimator for a variance\noperator of the certain multidimensional Gaussian distribution, inherent for\nthe two-point Green's function eigen-inference method. Third, we have presented\nthe cases of eigen-inference based on negative spectral moments, for strictly\npositive spectra. Finally, we have compared the cases of eigen-inference of\nreal-valued and complex-valued correlated Wishart distributions, reinforcing\nour conclusions on an advantage of the one-point Green's function method.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jan 2015 11:39:57 GMT"}], "update_date": "2016-10-31", "authors_parsed": [["Drogosz", "Zbigniew", ""], ["Jurkiewicz", "Jerzy", ""], ["\u0141ukaszewski", "Grzegorz", ""], ["Nowak", "Maciej A.", ""]]}, {"id": "1501.02185", "submitter": "Paolo D'Alberto", "authors": "Paolo D'Alberto", "title": "Multiple-Campaign Ad-Targeting Deployment: Parallel Response Modeling,\n  Calibration and Scoring Without Personal User Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.OH", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  We present a vertical introduction to campaign optimization; that is, the\nability to predict the user response to an ad campaign without any users'\nprofiles on average and for each exposed ad. In practice, we present an\napproach to build a polytomous model, multi response, composed by several\nhundred binary models using generalized linear models. The theory has been\nintroduced twenty years ago and it has been applied in different fields since\nthen. Here, we show how we optimize hundreds campaigns and how this large\nnumber of campaigns may overcome a few characteristic caveats of single\ncampaign optimization. We discuss the problem and solution of training and\ncalibration at scale. We present statistical performance as {\\em coverage},\n{\\em precision} and {\\em recall} used in classification. We present also a\ndiscussion about the potential performance as throughput: how many decisions\ncan be done per second streaming the bid auctions also by using dedicated\nhardware.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jan 2015 18:02:52 GMT"}, {"version": "v2", "created": "Mon, 11 May 2015 00:30:00 GMT"}], "update_date": "2015-05-12", "authors_parsed": [["D'Alberto", "Paolo", ""]]}, {"id": "1501.02226", "submitter": "Shirin Golchi", "authors": "Shirin Golchi, Richard Lockhart", "title": "A Bayesian Search for the Higgs Particle", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The statistical procedure used in the search for the Higgs boson is\ninvestigated in this paper. A Bayesian hierarchical model is proposed that uses\nthe information provided by the theory in the analysis of the data generated by\nthe particle detectors. In addition, we develop a Bayesian decision making\nprocedure that combines the two steps of the current method (discovery and\nexclusion) into one and can be calibrated to satisfy frequency theory error\nrate requirements. .\n", "versions": [{"version": "v1", "created": "Fri, 9 Jan 2015 18:45:57 GMT"}, {"version": "v2", "created": "Mon, 9 May 2016 18:06:02 GMT"}], "update_date": "2016-05-10", "authors_parsed": [["Golchi", "Shirin", ""], ["Lockhart", "Richard", ""]]}, {"id": "1501.02263", "submitter": "Necla Gunduz", "authors": "Necla Gunduz and Ernest Fokoue", "title": "Pattern Discovery in Students' Evaluations of Professors: A Statistical\n  Data Mining Approach", "comments": "20 pages, 5 figures, 11 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The evaluation of instructors by their students has been practiced at most\nuniversities for many decades, and there has always been a great interest in a\nvariety of aspects of the evaluations. Are students matured and knowledgeable\nenough to provide useful and dependable feedback for the improvement of their\ninstructors' teaching skills/abilities? Does the level of difficulty of the\ncourse have a strong relationship with the rating the student give an\ninstructor? In this paper, we attempt to answer questions such as these using\nsome state of the art statistical data mining techniques such support vector\nmachines, classification and regression trees, boosting, random forest, factor\nanalysis, kMeans clustering. hierarchical clustering. We explore various\naspects of the data from both the supervised and unsupervised learning\nperspective. The data set analyzed in this paper was collected from a\nuniversity in Turkey. The application of our techniques to this data reveals\nsome very interesting patterns in the evaluations, like the strong association\nbetween the student's seriousness and dedication (measured by attendance) and\nthe kind of scores they tend to assign to their instructors.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jan 2015 20:55:10 GMT"}], "update_date": "2015-01-12", "authors_parsed": [["Gunduz", "Necla", ""], ["Fokoue", "Ernest", ""]]}, {"id": "1501.02366", "submitter": "Ehtibar Dzhafarov", "authors": "Ru Zhang and Ehtibar N. Dzhafarov", "title": "Noncontextuality with Marginal Selectivity in Reconstructing Mental\n  Architectures", "comments": "published in Frontiers in Psychology: Cognition 1:12 doi:\n  10.3389/fpsyg.2015.00735 (special issue \"Quantum Structures in Cognitive and\n  Social Science\")", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a general theory of series-parallel mental architectures with\nselectively influenced stochastically non-independent components. A mental\narchitecture is a hypothetical network of processes aimed at performing a task,\nof which we only observe the overall time it takes under variable parameters of\nthe task. It is usually assumed that the network contains several processes\nselectively influenced by different experimental factors, and then the question\nis asked as to how these processes are arranged within the network, e.g.,\nwhether they are concurrent or sequential. One way of doing this is to consider\nthe distribution functions for the overall processing time and compute certain\nlinear combinations thereof (interaction contrasts). The theory of selective\ninfluences in psychology can be viewed as a special application of the\ninterdisciplinary theory of (non)contextuality having its origins and main\napplications in quantum theory. In particular, lack of contextuality is\nequivalent to the existence of a \"hidden\" random entity of which all the random\nvariables in play are functions. Consequently, for any given value of this\ncommon random entity, the processing times and their compositions (minima,\nmaxima, or sums) become deterministic quantities. These quantities, in turn,\ncan be treated as random variables with (shifted) Heaviside distribution\nfunctions, for which one can easily compute various linear combinations across\ndifferent treatments, including interaction contrasts. This mathematical fact\nleads to a simple method, more general than the previously used ones, to\ninvestigate and characterize the interaction contrast for different types of\nseries-parallel architectures.\n", "versions": [{"version": "v1", "created": "Sat, 10 Jan 2015 16:23:21 GMT"}, {"version": "v2", "created": "Thu, 2 Apr 2015 12:45:54 GMT"}, {"version": "v3", "created": "Sun, 17 May 2015 17:54:33 GMT"}, {"version": "v4", "created": "Fri, 19 Jun 2015 02:53:17 GMT"}], "update_date": "2015-06-22", "authors_parsed": [["Zhang", "Ru", ""], ["Dzhafarov", "Ehtibar N.", ""]]}, {"id": "1501.02467", "submitter": "Justin Yang Mr.", "authors": "Justin J. Yang, Xufei Wang, Pavlos Protopapas, Luke Bornn", "title": "Fast and optimal nonparametric sequential design for astronomical\n  observations", "comments": "22 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The spectral energy distribution (SED) is a relatively easy way for\nastronomers to distinguish between different astronomical objects such as\ngalaxies, black holes, and stellar objects. By comparing the observations from\na source at different frequencies with template models, astronomers are able to\ninfer the type of this observed object. In this paper, we take a Bayesian model\naveraging perspective to learn astronomical objects, employing a Bayesian\nnonparametric approach to accommodate the deviation from convex combinations of\nknown log-SEDs. To effectively use telescope time for observations, we then\nstudy Bayesian nonparametric sequential experimental design without conjugacy,\nin which we use sequential Monte Carlo as an efficient tool to maximize the\nvolume of information stored in the posterior distribution of the parameters of\ninterest. A new technique for performing inferences in log-Gaussian Cox\nprocesses called the Poisson log-normal approximation is also proposed.\nSimulations show the speed, accuracy, and usefulness of our method. While the\nstrategy we propose in this paper is brand new in the astronomy literature, the\ninferential techniques developed apply to more general nonparametric sequential\nexperimental design problems.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jan 2015 15:50:09 GMT"}], "update_date": "2015-01-13", "authors_parsed": [["Yang", "Justin J.", ""], ["Wang", "Xufei", ""], ["Protopapas", "Pavlos", ""], ["Bornn", "Luke", ""]]}, {"id": "1501.02514", "submitter": "Martin L. Hazelton", "authors": "Martin L. Hazelton", "title": "Network tomography for integer-valued traffic", "comments": "Published at http://dx.doi.org/10.1214/15-AOAS805 in the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2015, Vol. 9, No. 1, 474-506", "doi": "10.1214/15-AOAS805", "report-no": "IMS-AOAS-AOAS805", "categories": "stat.ME stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A classic network tomography problem is estimation of properties of the\ndistribution of route traffic volumes based on counts taken on the network\nlinks. We consider inference for a general class of models for integer-valued\ntraffic. Model identifiability is examined. We investigate both maximum\nlikelihood and Bayesian methods of estimation. In practice, these must be\nimplemented using stochastic EM and MCMC approaches. This requires a\nmethodology for sampling latent route flows conditional on the observed link\ncounts. We show that existing algorithms for doing so can fail entirely,\nbecause inflexibility in the choice of sampling directions can leave the\nsampler trapped at a vertex of the convex polytope that describes the feasible\nset of route flows. We prove that so long as the network's link-path incidence\nmatrix is totally unimodular, it is always possible to select a coordinate\nsystem representation of the polytope for which sampling parallel to the axes\nis adequate. This motivates a modified sampler in which the representation of\nthe polytope adapts to provide good mixing behavior. This methodology is\napplied to three road traffic data sets. We conclude with a discussion of the\nramifications of the unimodularity requirements for the routing matrix.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jan 2015 01:03:07 GMT"}, {"version": "v2", "created": "Tue, 2 Jun 2015 07:16:29 GMT"}], "update_date": "2015-06-03", "authors_parsed": [["Hazelton", "Martin L.", ""]]}, {"id": "1501.03185", "submitter": "Victor Chernozhukov", "authors": "Victor Chernozhukov, Christian Hansen, Martin Spindler", "title": "Post-Selection and Post-Regularization Inference in Linear Models with\n  Many Controls and Instruments", "comments": "American Economic Review 2015, Papers and Proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP econ.EM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this note, we offer an approach to estimating causal/structural parameters\nin the presence of many instruments and controls based on methods for\nestimating sparse high-dimensional models. We use these high-dimensional\nmethods to select both which instruments and which control variables to use.\nThe approach we take extends BCCH2012, which covers selection of instruments\nfor IV models with a small number of controls, and extends BCH2014, which\ncovers selection of controls in models where the variable of interest is\nexogenous conditional on observables, to accommodate both a large number of\ncontrols and a large number of instruments. We illustrate the approach with a\nsimulation and an empirical example. Technical supporting material is available\nin a supplementary online appendix.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jan 2015 21:48:46 GMT"}], "update_date": "2017-10-03", "authors_parsed": [["Chernozhukov", "Victor", ""], ["Hansen", "Christian", ""], ["Spindler", "Martin", ""]]}, {"id": "1501.03214", "submitter": "Roger Bilisoly", "authors": "Roger Bilisoly", "title": "Quantifying Prosodic Variability in Middle English Alliterative Poetry", "comments": "12 pages, 8 figures. Based on a presentation given at the Joint\n  Statistical Meetings, Section on Statistical Learning and Data Mining, which\n  took place August, 2014, in Boston, Massachusetts, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interest in the mathematical structure of poetry dates back to at least the\n19th century: after retiring from his mathematics position, J. J. Sylvester\nwrote a book on prosody called $\\textit{The Laws of Verse}$. Today there is\ninterest in the computer analysis of poems, and this paper discusses how a\nstatistical approach can be applied to this task. Starting with the definition\nof what Middle English alliteration is, $\\textit{Sir Gawain and the Green\nKnight}$ and William Langland's $\\textit{Piers Plowman}$ are used to illustrate\nthe methodology. Theory first developed for analyzing data from a Riemannian\nmanifold turns out to be applicable to strings allowing one to compute a\ngeneralized mean and variance for textual data, which is applied to the poems\nabove. The ratio of these two variances produces the analogue of the F test,\nand resampling allows p-values to be estimated. Consequently, this methodology\nprovides a way to compare prosodic variability between two texts.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jan 2015 00:06:15 GMT"}], "update_date": "2015-01-15", "authors_parsed": [["Bilisoly", "Roger", ""]]}, {"id": "1501.03409", "submitter": "Rom\\'an Salmer\\'on", "authors": "Rom\\'an Salmer\\'on-G\\'omez and Samuel G\\'omez-Haro", "title": "Ampliando horizontes sobre medici\\'on del desempe\\~no y el concepto de\n  regularidad en el baloncesto profesional", "comments": "in Spanish, 20 p\\'aginas, 10 tablas", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The present work aims to improve the existing analysis on the performance of\nprofessional basketball players presenting a methodology to measure its\nperformance and regularity.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jan 2015 17:01:17 GMT"}], "update_date": "2015-01-15", "authors_parsed": [["Salmer\u00f3n-G\u00f3mez", "Rom\u00e1n", ""], ["G\u00f3mez-Haro", "Samuel", ""]]}, {"id": "1501.03529", "submitter": "Mohammad Reza Gholami", "authors": "Mohammad Reza Gholami, Satyam Dwivedi, Magnus Jansson, and Peter\n  H\\\"andel", "title": "Ranging without time stamps exchanging", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the range estimate between two wireless nodes without time\nstamps exchanging. Considering practical aspects of oscillator clocks, we\npropose a new model for ranging in which the measurement errors include the sum\nof two distributions, namely, uniform and Gaussian. We then derive an\napproximate maximum likelihood estimator (AMLE), which poses a difficult global\noptimization problem. To avoid the difficulty in solving the complex AMLE, we\npropose a simple estimator based on the method of moments. Numerical results\nshow a promising performance for the proposed technique.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jan 2015 22:20:01 GMT"}], "update_date": "2015-01-16", "authors_parsed": [["Gholami", "Mohammad Reza", ""], ["Dwivedi", "Satyam", ""], ["Jansson", "Magnus", ""], ["H\u00e4ndel", "Peter", ""]]}, {"id": "1501.03537", "submitter": "William Barcella", "authors": "William Barcella, Maria De Iorio, Gianluca Baio and James Malone-Lee", "title": "Variable Selection in Covariate Dependent Random Partition Models: an\n  Application to Urinary Tract Infection", "comments": "Revised version. 24 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lower urinary tract symptoms (LUTS) can indicate the presence of urinary\ntract infection (UTI), a condition that if it becomes chronic requires\nexpensive and time consuming care as well as leading to reduced quality of\nlife. Detecting the presence and gravity of an infection from the earliest\nsymptoms is then highly valuable. Typically, white blood cell count (WBC)\nmeasured in a sample of urine is used to assess UTI. We consider clinical data\nfrom 1341 patients at their first visit in which UTI (i.e. WBC$\\geq 1$) is\ndiagnosed. In addition, for each patient, a clinical profile of 34 symptoms was\nrecorded. In this paper we propose a Bayesian nonparametric regression model\nbased on the Dirichlet Process (DP) prior aimed at providing the clinicians\nwith a meaningful clustering of the patients based on both the WBC (response\nvariable) and possible patterns within the symptoms profiles (covariates). This\nis achieved by assuming a probability model for the symptoms as well as for the\nresponse variable. To identify the symptoms most associated to UTI, we specify\na spike and slab base measure for the regression coefficients: this induces\ndependence of symptoms selection on cluster assignment. Posterior inference is\nperformed through Markov Chain Monte Carlo methods.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jan 2015 23:47:46 GMT"}, {"version": "v2", "created": "Fri, 10 Jul 2015 09:43:31 GMT"}], "update_date": "2015-07-13", "authors_parsed": [["Barcella", "William", ""], ["De Iorio", "Maria", ""], ["Baio", "Gianluca", ""], ["Malone-Lee", "James", ""]]}, {"id": "1501.03571", "submitter": "Qingyuan Zhao", "authors": "Qingyuan Zhao and Daniel Percival", "title": "Entropy balancing is doubly robust", "comments": "23 pages, 6 figures, Journal of Causal Inference 2016", "journal-ref": null, "doi": "10.1515/jci-2016-0010", "report-no": null, "categories": "stat.ME stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Covariate balance is a conventional key diagnostic for methods used\nestimating causal effects from observational studies. Recently, there is an\nemerging interest in directly incorporating covariate balance in the\nestimation. We study a recently proposed entropy maximization method called\nEntropy Balancing (EB), which exactly matches the covariate moments for the\ndifferent experimental groups in its optimization problem. We show EB is doubly\nrobust with respect to linear outcome regression and logistic propensity score\nregression, and it reaches the asymptotic semiparametric variance bound when\nboth regressions are correctly specified. This is surprising to us because\nthere is no attempt to model the outcome or the treatment assignment in the\noriginal proposal of EB. Our theoretical results and simulations suggest that\nEB is a very appealing alternative to the conventional weighting estimators\nthat estimate the propensity score by maximum likelihood.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jan 2015 04:49:54 GMT"}, {"version": "v2", "created": "Tue, 4 Aug 2015 04:46:32 GMT"}, {"version": "v3", "created": "Sat, 11 Feb 2017 17:27:37 GMT"}], "update_date": "2017-02-14", "authors_parsed": [["Zhao", "Qingyuan", ""], ["Percival", "Daniel", ""]]}, {"id": "1501.03626", "submitter": "Mallory Nobles", "authors": "Mallory Nobles, Nicoleta Serban, Julie Swann", "title": "Spatial accessibility of pediatric primary healthcare: Measurement and\n  inference", "comments": "Published in at http://dx.doi.org/10.1214/14-AOAS728 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2014, Vol. 8, No. 4, 1922-1946", "doi": "10.1214/14-AOAS728", "report-no": "IMS-AOAS-AOAS728", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although improving financial access is in the spotlight of the current U.S.\nhealth policy agenda, this alone does not address universal and comprehensive\nhealthcare. Affordability is one barrier to healthcare, but others such as\navailability and accessibility, together defined as spatial accessibility, are\nequally important. In this paper, we develop a measurement and modeling\nframework that can be used to infer the impact of policy changes on disparities\nin spatial accessibility within and across different population groups. The\nunderlying model for measuring spatial accessibility is optimization-based and\naccounts for constraints in the healthcare delivery system. The measurement\nmethod is complemented by statistical modeling and inference on the impact of\nvarious potential contributing factors to disparities in spatial accessibility.\nThe emphasis of this study is on children's accessibility to primary care\npediatricians, piloted for the state of Georgia. We focus on disparities in\naccessibility between and within two populations: children insured by Medicaid\nand other children. We find that disparities in spatial accessibility to\npediatric primary care in Georgia are significant, and resistant to many policy\ninterventions, suggesting the need for major changes to the structure of\nGeorgia's pediatric healthcare provider network.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jan 2015 10:47:22 GMT"}], "update_date": "2015-01-16", "authors_parsed": [["Nobles", "Mallory", ""], ["Serban", "Nicoleta", ""], ["Swann", "Julie", ""]]}, {"id": "1501.03883", "submitter": "Laura A. Hatfield", "authors": "Laura A. Hatfield", "title": "Discussion of \"Spatial accessibility of pediatric primary healthcare:\n  Measurement and inference\"", "comments": "Published in at http://dx.doi.org/10.1214/14-AOAS728A the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2014, Vol. 8, No. 4, 1947-1951", "doi": "10.1214/14-AOAS728A", "report-no": "IMS-AOAS-AOAS728A", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discussion of \"Spatial accessibility of pediatric primary healthcare:\nMeasurement and inference\" by Mallory Nobles, Nicoleta Serban and Julie Swann\n[arXiv:1501.03626].\n", "versions": [{"version": "v1", "created": "Fri, 16 Jan 2015 06:05:12 GMT"}], "update_date": "2015-01-19", "authors_parsed": [["Hatfield", "Laura A.", ""]]}, {"id": "1501.03884", "submitter": "Amelia M. Haviland", "authors": "Amelia M. Haviland", "title": "Discussion of \"Spatial accessibility of pediatric primary healthcare:\n  Measurement and inference\"", "comments": "Published in at http://dx.doi.org/10.1214/14-AOAS728B the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2014, Vol. 8, No. 4, 1952-1955", "doi": "10.1214/14-AOAS728B", "report-no": "IMS-AOAS-AOAS728B", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discussion of \"Spatial accessibility of pediatric primary healthcare:\nMeasurement and inference\" by Mallory Nobles, Nicoleta Serban and Julie Swann\n[arXiv:1501.03626].\n", "versions": [{"version": "v1", "created": "Fri, 16 Jan 2015 06:07:45 GMT"}], "update_date": "2015-01-19", "authors_parsed": [["Haviland", "Amelia M.", ""]]}, {"id": "1501.03885", "submitter": "Lance A. Waller", "authors": "Lance A. Waller", "title": "Discussion of \"Spatial accessibility of pediatric primary healthcare:\n  Measurement and inference\"", "comments": "Published in at http://dx.doi.org/10.1214/14-AOAS728C the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2014, Vol. 8, No. 4, 1956-1960", "doi": "10.1214/14-AOAS728C", "report-no": "IMS-AOAS-AOAS728C", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discussion of \"Spatial accessibility of pediatric primary healthcare:\nMeasurement and inference\" by Mallory Nobles, Nicoleta Serban and Julie Swann\n[arXiv:1501.03626].\n", "versions": [{"version": "v1", "created": "Fri, 16 Jan 2015 06:10:21 GMT"}], "update_date": "2015-01-19", "authors_parsed": [["Waller", "Lance A.", ""]]}, {"id": "1501.03886", "submitter": "Mallory Nobles", "authors": "Mallory Nobles, Nicoleta Serban, Julie Swann", "title": "Rejoinder: \"Spatial accessibility of pediatric primary healthcare:\n  Measurement and inference\"", "comments": "Published in at http://dx.doi.org/10.1214/14-AOAS728R the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2014, Vol. 8, No. 4, 1961-1965", "doi": "10.1214/14-AOAS728R", "report-no": "IMS-AOAS-AOAS728R", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rejoinder of \"Spatial accessibility of pediatric primary healthcare:\nMeasurement and inference\" by Mallory Nobles, Nicoleta Serban and Julie Swann\n[arXiv:1501.03626].\n", "versions": [{"version": "v1", "created": "Fri, 16 Jan 2015 06:12:30 GMT"}], "update_date": "2015-01-19", "authors_parsed": [["Nobles", "Mallory", ""], ["Serban", "Nicoleta", ""], ["Swann", "Julie", ""]]}, {"id": "1501.03887", "submitter": "Susan M. Paddock", "authors": "Susan M. Paddock", "title": "Editorial: Spatial accessibility of pediatric primary healthcare:\n  Measurement and inference", "comments": "Published in at http://dx.doi.org/10.1214/14-AOAS728ED the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2014, Vol. 8, No. 4, 1921-1921", "doi": "10.1214/14-AOAS728ED", "report-no": "IMS-AOAS-AOAS728ED", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Improving access to health care has long been at the forefront of policy\ndebates in the U.S. There are multiple determinants of healthcare utilization:\npredisposing characteristics that explain individuals' propensities to use\nhealthcare; enabling characteristics that describe the resources individuals\nhave to use healthcare; and perceived or actual need for healthcare [Aday and\nAndersen (1974)]. Nobles, Serban and Swann (2014) illustrate the complexity\ninvolved with developing an understanding of one determinant of healthcare\nutilization. They examine spatial accessibility - an enabling characteristic\nunder the aforementioned framework - to primary care pediatricians in Georgia.\nThe authors encounter challenges that arise in many public policy applications,\nnamely, the limitations of the available data, the need to conduct analyses\nthat reflect system constraints, model selection and uncertainty\nquantification. The Area Editors featured this paper, along with contributions\nfrom three discussants, in an AoAS invited session at the 2014 Joint\nStatistical Meetings and are including the paper and those discussions in this\nissue because the paper showcases the type of research AoAS aims to publish:\nanalyses requiring innovative statistical thinking to address questions of\npractical importance.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jan 2015 06:26:31 GMT"}], "update_date": "2015-01-19", "authors_parsed": [["Paddock", "Susan M.", ""]]}, {"id": "1501.03956", "submitter": "Bruno Sudret", "authors": "Bruno Sudret, Hung Xuan Dang, Marc Berveiller, Asmahana Zeghadi,\n  Thierry Yalamas", "title": "Characterization of random stress fields obtained from polycrystalline\n  aggregate calculations using multi-scale stochastic finite elements", "comments": null, "journal-ref": null, "doi": null, "report-no": "RSUQ-2015-001", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The spatial variability of stress fields resulting from polycrystalline\naggregate calculations involving random grain geometry and crystal orientations\nis investigated. A periodogram-based method is proposed to identify the\nproperties of homogeneous Gaussian random fields (power spectral density and\nrelated covariance structure). Based on a set of finite element polycrystalline\naggregate calculations the properties of the maximal principal stress field are\nidentified. Two cases are considered, using either a fixed or random grain\ngeometry. The stability of the method w.r.t the number of samples and the load\nlevel (up to 3.5 % macroscopic deformation) is investigated.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jan 2015 11:42:00 GMT"}], "update_date": "2015-01-19", "authors_parsed": [["Sudret", "Bruno", ""], ["Dang", "Hung Xuan", ""], ["Berveiller", "Marc", ""], ["Zeghadi", "Asmahana", ""], ["Yalamas", "Thierry", ""]]}, {"id": "1501.03971", "submitter": "Abel Rodriguez", "authors": "Abel Rodriguez, Scott C. Schmidler", "title": "Bayesian protein structure alignment", "comments": "Published in at http://dx.doi.org/10.1214/14-AOAS780 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2014, Vol. 8, No. 4, 2068-2095", "doi": "10.1214/14-AOAS780", "report-no": "IMS-AOAS-AOAS780", "categories": "stat.AP q-bio.BM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The analysis of the three-dimensional structure of proteins is an important\ntopic in molecular biochemistry. Structure plays a critical role in defining\nthe function of proteins and is more strongly conserved than amino acid\nsequence over evolutionary timescales. A key challenge is the identification\nand evaluation of structural similarity between proteins; such analysis can aid\nin understanding the role of newly discovered proteins and help elucidate\nevolutionary relationships between organisms. Computational biologists have\ndeveloped many clever algorithmic techniques for comparing protein structures,\nhowever, all are based on heuristic optimization criteria, making statistical\ninterpretation somewhat difficult. Here we present a fully probabilistic\nframework for pairwise structural alignment of proteins. Our approach has\nseveral advantages, including the ability to capture alignment uncertainty and\nto estimate key \"gap\" parameters which critically affect the quality of the\nalignment. We show that several existing alignment methods arise as maximum a\nposteriori estimates under specific choices of prior distributions and error\nmodels. Our probabilistic framework is also easily extended to incorporate\nadditional information, which we demonstrate by including primary sequence\ninformation to generate simultaneous sequence-structure alignments that can\nresolve ambiguities obtained using structure alone. This combined model also\nprovides a natural approach for the difficult task of estimating evolutionary\ndistance based on structural alignments. The model is illustrated by comparison\nwith well-established methods on several challenging protein alignment\nexamples.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jan 2015 13:15:39 GMT"}], "update_date": "2015-01-19", "authors_parsed": [["Rodriguez", "Abel", ""], ["Schmidler", "Scott C.", ""]]}, {"id": "1501.04229", "submitter": "Gabriell M\\'at\\'e", "authors": "Gabriell M\\'at\\'e", "title": "A Potts Model for Night Light and Human Population", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph physics.data-an stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Potts model was one of the most popular physics models of the twentieth\ncentury in an interdisciplinary context. It has been applied to a large variety\nof problems. Many generalizations exists and a whole range of models were\ninspired by this statistical physics tool. Here we present how a generic Potts\nmodel can be used to study complex data. As a demonstration, we engage our\nmodel in the analysis of night light patterns of human settlements observed on\nspace photographs.\n", "versions": [{"version": "v1", "created": "Sat, 17 Jan 2015 21:09:41 GMT"}], "update_date": "2015-01-20", "authors_parsed": [["M\u00e1t\u00e9", "Gabriell", ""]]}, {"id": "1501.04308", "submitter": "Enea Giuseppe Bongiorno", "authors": "Enea Bongiorno and Aldo Goia", "title": "Some Insights About the Small Ball Probability Factorization for Hilbert\n  Random Elements", "comments": "27 pages, 1 figure, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.AP stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Asymptotic factorizations for the small-ball probability (SmBP) of a Hilbert\nvalued random element $X$ are rigorously established and discussed. In\nparticular, given the first $d$ principal components (PCs) and as the radius\n$\\varepsilon$ of the ball tends to zero, the SmBP is asymptotically\nproportional to (a) the joint density of the first $d$ PCs, (b) the volume of\nthe $d$-dimensional ball with radius $\\varepsilon$, and (c) a correction factor\nweighting the use of a truncated version of the process expansion. Moreover,\nunder suitable assumptions on the spectrum of the covariance operator of $X$\nand as $d$ diverges to infinity when $\\varepsilon$ vanishes, some\nsimplifications occur. In particular, the SmBP factorizes asymptotically as the\nproduct of the joint density of the first $d$ PCs and a pure volume parameter.\nAll the provided factorizations allow to define a surrogate intensity of the\nSmBP that, in some cases, leads to a genuine intensity. To operationalize the\nstated results, a non-parametric estimator for the surrogate intensity is\nintroduced and it is proved that the use of estimated PCs, instead of the true\nones, does not affect the rate of convergence. Finally, as an illustration,\nsimulations in controlled frameworks are provided.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jan 2015 14:48:30 GMT"}, {"version": "v2", "created": "Tue, 29 Mar 2016 08:31:19 GMT"}], "update_date": "2016-03-30", "authors_parsed": [["Bongiorno", "Enea", ""], ["Goia", "Aldo", ""]]}, {"id": "1501.04392", "submitter": "Jos\\'{e} R. Zubizarreta", "authors": "Jos\\'e R. Zubizarreta, Dylan S. Small, Paul R. Rosenbaum", "title": "Isolation in the construction of natural experiments", "comments": "Published in at http://dx.doi.org/10.1214/14-AOAS770 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2014, Vol. 8, No. 4, 2096-2121", "doi": "10.1214/14-AOAS770", "report-no": "IMS-AOAS-AOAS770", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A natural experiment is a type of observational study in which treatment\nassignment, though not randomized by the investigator, is plausibly close to\nrandom. A process that assigns treatments in a highly nonrandom, inequitable\nmanner may, in rare and brief moments, assign aspects of treatments at random\nor nearly so. Isolating those moments and aspects may extract a natural\nexperiment from a setting in which treatment assignment is otherwise quite\nbiased, far from random. Isolation is a tool that focuses on those rare, brief\ninstances, extracting a small natural experiment from otherwise useless data.\nWe discuss the theory behind isolation and illustrate its use in a reanalysis\nof a well-known study of the effects of fertility on workforce participation.\nWhether a woman becomes pregnant at a certain moment in her life and whether\nshe brings that pregnancy to term may reflect her aspirations for family,\neducation and career, the degree of control she exerts over her fertility, and\nthe quality of her relationship with the father; moreover, these aspirations\nand relationships are unlikely to be recorded with precision in surveys and\ncensuses, and they may confound studies of workforce participation. However,\ngiven that a women is pregnant and will bring the pregnancy to term, whether\nshe will have twins or a single child is, to a large extent, simply luck. Given\nthat a woman is pregnant at a certain moment, the differential comparison of\ntwo types of pregnancies on workforce participation, twins or a single child,\nmay be close to randomized, not biased by unmeasured aspirations. In this\ncomparison, we find in our case study that mothers of twins had more children\nbut only slightly reduced workforce participation, approximately 5% less time\nat work for an additional child.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jan 2015 05:52:50 GMT"}], "update_date": "2015-01-20", "authors_parsed": [["Zubizarreta", "Jos\u00e9 R.", ""], ["Small", "Dylan S.", ""], ["Rosenbaum", "Paul R.", ""]]}, {"id": "1501.04415", "submitter": "Shaowu Tang", "authors": "Shaowu Tang, Ying Ding, Etienne Sibille, Jeffrey S. Mogil, William R.\n  Lariviere, George C. Tseng", "title": "Imputation of truncated p-values for meta-analysis methods and its\n  genomic application", "comments": "Published in at http://dx.doi.org/10.1214/14-AOAS747 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2014, Vol. 8, No. 4, 2150-2174", "doi": "10.1214/14-AOAS747", "report-no": "IMS-AOAS-AOAS747", "categories": "stat.AP q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Microarray analysis to monitor expression activities in thousands of genes\nsimultaneously has become routine in biomedical research during the past\ndecade. A tremendous amount of expression profiles are generated and stored in\nthe public domain and information integration by meta-analysis to detect\ndifferentially expressed (DE) genes has become popular to obtain increased\nstatistical power and validated findings. Methods that aggregate transformed\n$p$-value evidence have been widely used in genomic settings, among which\nFisher's and Stouffer's methods are the most popular ones. In practice, raw\ndata and $p$-values of DE evidence are often not available in genomic studies\nthat are to be combined. Instead, only the detected DE gene lists under a\ncertain $p$-value threshold (e.g., DE genes with $p$-value${}<0.001$) are\nreported in journal publications. The truncated $p$-value information makes the\naforementioned meta-analysis methods inapplicable and researchers are forced to\napply a less efficient vote counting method or na\\\"{i}vely drop the studies\nwith incomplete information. The purpose of this paper is to develop effective\nmeta-analysis methods for such situations with partially censored $p$-values.\nWe developed and compared three imputation methods - mean imputation, single\nrandom imputation and multiple imputation - for a general class of evidence\naggregation methods of which Fisher's and Stouffer's methods are special\nexamples. The null distribution of each method was analytically derived and\nsubsequent inference and genomic analysis frameworks were established.\nSimulations were performed to investigate the type I error, power and the\ncontrol of false discovery rate (FDR) for (correlated) gene expression data.\nThe proposed methods were applied to several genomic applications in colorectal\ncancer, pain and liquid association analysis of major depressive disorder\n(MDD). The results showed that imputation methods outperformed existing\nna\\\"{i}ve approaches. Mean imputation and multiple imputation methods performed\nthe best and are recommended for future applications.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jan 2015 08:12:02 GMT"}], "update_date": "2015-01-20", "authors_parsed": [["Tang", "Shaowu", ""], ["Ding", "Ying", ""], ["Sibille", "Etienne", ""], ["Mogil", "Jeffrey S.", ""], ["Lariviere", "William R.", ""], ["Tseng", "George C.", ""]]}, {"id": "1501.04420", "submitter": "Vadim Zipunnikov", "authors": "Vadim Zipunnikov, Sonja Greven, Haochang Shou, Brian S. Caffo, Daniel\n  S. Reich, Ciprian M. Crainiceanu", "title": "Longitudinal high-dimensional principal components analysis with\n  application to diffusion tensor imaging of multiple sclerosis", "comments": "Published in at http://dx.doi.org/10.1214/14-AOAS748 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2014, Vol. 8, No. 4, 2175-2202", "doi": "10.1214/14-AOAS748", "report-no": "IMS-AOAS-AOAS748", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a flexible framework for modeling high-dimensional imaging data\nobserved longitudinally. The approach decomposes the observed variability of\nrepeatedly measured high-dimensional observations into three additive\ncomponents: a subject-specific imaging random intercept that quantifies the\ncross-sectional variability, a subject-specific imaging slope that quantifies\nthe dynamic irreversible deformation over multiple realizations, and a\nsubject-visit-specific imaging deviation that quantifies exchangeable effects\nbetween visits. The proposed method is very fast, scalable to studies including\nultrahigh-dimensional data, and can easily be adapted to and executed on modest\ncomputing infrastructures. The method is applied to the longitudinal analysis\nof diffusion tensor imaging (DTI) data of the corpus callosum of multiple\nsclerosis (MS) subjects. The study includes $176$ subjects observed at $466$\nvisits. For each subject and visit the study contains a registered DTI scan of\nthe corpus callosum at roughly 30,000 voxels.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jan 2015 08:48:45 GMT"}], "update_date": "2015-01-20", "authors_parsed": [["Zipunnikov", "Vadim", ""], ["Greven", "Sonja", ""], ["Shou", "Haochang", ""], ["Caffo", "Brian S.", ""], ["Reich", "Daniel S.", ""], ["Crainiceanu", "Ciprian M.", ""]]}, {"id": "1501.04671", "submitter": "Jeremie Houssineau", "authors": "Emmanuel Delande, Jeremie Houssineau, Daniel E. Clark", "title": "Multi-object filtering with stochastic populations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While the design of automated knowledge-based sensor scheduling is relevant\nto many multi-target detection and tracking problems, tracking algorithms are\nrarely built for this purpose and their outputs provide little flexibility for\nthe design of sensor policies. In this paper, we present an estimation\nframework for stochastic populations in the context of multi-target estimation\nproblems. Fully probabilistic in nature, it allows for the evaluation of the\npopulation of targets through statistical moments, as well as the assessment of\nsensor observations through information-theoretical gain functions. We present\na principled solution derived from this framework addressing challenging\nmulti-target scenarios involving missed detections and false alarms, the filter\nfor Distinguishable and Independent Stochastic Populations, which propagates\ninformation on previously-detected targets as well as yet-to-be-detected\ntargets while maintaining track continuity.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jan 2015 23:24:41 GMT"}, {"version": "v2", "created": "Tue, 12 Jul 2016 13:20:27 GMT"}], "update_date": "2016-07-13", "authors_parsed": [["Delande", "Emmanuel", ""], ["Houssineau", "Jeremie", ""], ["Clark", "Daniel E.", ""]]}, {"id": "1501.04830", "submitter": "Patr\\'icia Leone Espinheira", "authors": "Patr\\'icia L. Espinheira, Luana Cec\\'ilia Meireles da Silva, Alisson\n  de Oliveira Silva", "title": "Prediction Measures in Beta Regression Models", "comments": "15 pag. 1 Fig", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the issue of constructing PRESS statistics and coefficients of\nprediction for a class of beta regression models. We aim at displaying measures\nof predictive power of the model regardless goodness-of-fit. Monte Carlo\nsimulation results on the finite sample behavior of such measures are\nprovided.We also present an application that relates to the distribution of\nnatural gas for home usage in S\\~ao Paulo, Brazil. Faced with the economic risk\nof to overestimate or to underestimate the distribution of gas was necessary to\nconstruct prediction limits using beta regression models (Espinheira et al.,\n2014). Thus, it arises the aim of this work, the selection of best predictive\nmodel to construct best prediction limits.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jan 2015 14:53:17 GMT"}], "update_date": "2015-01-21", "authors_parsed": [["Espinheira", "Patr\u00edcia L.", ""], ["da Silva", "Luana Cec\u00edlia Meireles", ""], ["Silva", "Alisson de Oliveira", ""]]}, {"id": "1501.04849", "submitter": "Abdolreza Mohammadi", "authors": "Abdolreza Mohammadi, Fentaw Abegaz, Edwin van den Heuvel, and Ernst C.\n  Wit", "title": "Bayesian Gaussian Copula Graphical Modeling for Dupuytren Disease", "comments": null, "journal-ref": null, "doi": "10.1111/rssc.12171", "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dupuytren disease is a fibroproliferative disorder with unknown etiology that\noften progresses and eventually can cause permanent contractures of the\naffected fingers. In this paper, we provide a computationally efficient\nBayesian framework to discover potential risk factors and investigate which\nfingers are jointly affected. Our Bayesian approach is based on Gaussian copula\ngraphical models, which are one potential way to discover the underlying\nconditional independence structure of variables in multivariate mixed data. In\nparticular, we combine the semiparametric Gaussian copula with extended rank\nlikelihood which is appropriate to analyse multivariate mixed data with\narbitrary marginal distributions. For the graph structure learning, we\nconstruct a computationally efficient search algorithm which is a\ntrans-dimensional MCMC algorithm based on a birth-death process. In addition,\nto make our statistical method easily accessible to other researchers, we have\nimplemented our method in C++ and interfaced with R software as an R package\nBDgraph which is available online.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jan 2015 15:39:07 GMT"}, {"version": "v2", "created": "Tue, 3 Feb 2015 14:13:16 GMT"}, {"version": "v3", "created": "Wed, 15 Apr 2015 12:52:43 GMT"}, {"version": "v4", "created": "Tue, 15 Sep 2015 13:49:18 GMT"}], "update_date": "2017-12-08", "authors_parsed": [["Mohammadi", "Abdolreza", ""], ["Abegaz", "Fentaw", ""], ["Heuvel", "Edwin van den", ""], ["Wit", "Ernst C.", ""]]}, {"id": "1501.05035", "submitter": "Cristian Tomasetti", "authors": "Cristian Tomasetti and Bert Vogelstein", "title": "Musings on the theory that variation in cancer risk among tissues can be\n  explained by the number of divisions of normal stem cells", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP q-bio.GN q-bio.TO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This manuscript has been written to address questions related to our recent\npublication (Science 347:78-81, 2015). We appreciate the many reactions to this\npaper that have been communicated to us, either privately or publicly. The\nfollowing addresses several of the most important statistical and technical\nissues related to our analysis and conclusions. Our responses to non-technical\nquestions are available at\nhttp://www.hopkinsmedicine.org/news/media/releases/bad_luck_of_random_mutations_plays_predominant_role_in_cancer_study_shows\n", "versions": [{"version": "v1", "created": "Wed, 21 Jan 2015 02:15:43 GMT"}, {"version": "v2", "created": "Wed, 4 Feb 2015 14:34:41 GMT"}, {"version": "v3", "created": "Wed, 16 Dec 2015 04:04:07 GMT"}, {"version": "v4", "created": "Wed, 17 Feb 2016 14:05:09 GMT"}], "update_date": "2016-02-18", "authors_parsed": [["Tomasetti", "Cristian", ""], ["Vogelstein", "Bert", ""]]}, {"id": "1501.05072", "submitter": "Sudhansu Sekhar Maiti", "authors": "Sudhansu S. Maiti, Sudhir Murmu and G. Chattopadhyay", "title": "Estimation of Reliability in the Two-Parameter Geometric Distribution", "comments": "31 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, the reliabilities $R(t)=P(X\\geq t)$, when $X$ follows\ntwo-parameter geometric distribution and $R=P(X\\leq Y)$, arises under\nstress-strength setup, when X and Y assumed to follow two-parameter geometric\nindependently have been found out. Maximum Likelihood Estimator (MLE) and an\nUnbiased Estimator (UE) of these have been derived. MLE and UE of the\nreliability of k-out-of-m system have also been derived. The estimators have\nbeen compared through simulation study.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jan 2015 06:49:52 GMT"}], "update_date": "2015-01-22", "authors_parsed": [["Maiti", "Sudhansu S.", ""], ["Murmu", "Sudhir", ""], ["Chattopadhyay", "G.", ""]]}, {"id": "1501.05119", "submitter": "Li Yin", "authors": "Xiaoqin Wang, Weimin Ye and Li Yin", "title": "Measuring and estimating interaction between exposures on dichotomous\n  outcome of a population", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In observational studies for the interaction between exposures on dichotomous\noutcome of a population, one usually uses one parameter of a regression model\nto describe the interaction, leading to one measure of the interaction. In this\narticle, we use the conditional risk of outcome given exposures and covariates\nto describe the interaction and obtain five different measures for the\ninteraction in observational studies, i.e. difference between the marginal risk\ndifferences, ratio of the marginal risk ratios, ratio of the marginal odds\nratios, ratio of the conditional risk ratios, and ratio of the conditional odds\nratios. By using only one regression model for the conditional risk of outcome\ngiven exposures and covariates, we obtain the maximum-likelihood estimates of\nall these measures. By generating approximate distributions of the\nmaximum-likelihood estimates of these measures, we obtain interval estimates of\nthese measures. The method is presented by studying the interaction between a\ntherapy and the environment on eradication of Helicobacter pylori among\nVietnamese children.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jan 2015 10:45:44 GMT"}], "update_date": "2015-01-22", "authors_parsed": [["Wang", "Xiaoqin", ""], ["Ye", "Weimin", ""], ["Yin", "Li", ""]]}, {"id": "1501.05230", "submitter": "Guillaume Kon Kam King", "authors": "Guillaume Kon Kam King, Floriane Larras, Sandrine Charles, Marie Laure\n  Delignette-Muller", "title": "Hierarchical modelling of species sensitivity distribution: development\n  and application to the case of diatoms exposed to several herbicides", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Species Sensitivity Distribution (SSD) is a key tool to assess the\necotoxicological threat of contaminant to biodiversity. It predicts safe\nconcentrations for a contaminant in a community. Widely used, this approach\nsuffers from several drawbacks: i)summarizing the sensitivity of each species\nby a single value entails a loss of valuable information about the other\nparameters characterizing the concentration-effect curves; ii)it does not\npropagate the uncertainty on the critical effect concentration into the SSD;\niii)the hazardous concentration estimated with SSD only indicates the threat to\nbiodiversity, without any insight about a global response of the community\nrelated to the measured endpoint. We revisited the current SSD approach to\naccount for all the sources of variability and uncertainty into the prediction\nand to assess a global response for the community. For this purpose, we built a\nglobal hierarchical model including the concentration-response model together\nwith the distribution law for the SSD. Working within a Bayesian framework, we\nwere able to compute an SSD taking into account all the uncertainty from the\noriginal raw data. From model simulations, it is also possible to extract a\nquantitative indicator of a global response of the community to the\ncontaminant. We applied this methodology to study the toxicity of 6 herbicides\nto benthic diatoms from Lake Geneva, measured from biomass reduction.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jan 2015 17:04:30 GMT"}], "update_date": "2015-01-22", "authors_parsed": [["King", "Guillaume Kon Kam", ""], ["Larras", "Floriane", ""], ["Charles", "Sandrine", ""], ["Delignette-Muller", "Marie Laure", ""]]}, {"id": "1501.05297", "submitter": "Sandeep Vanga", "authors": "Sandeep Vanga and Sachin Jaganade", "title": "Multi Stage based Time Series Analysis of User Activity on Touch\n  Sensitive Surfaces in Highly Noise Susceptible Environments", "comments": "9 pages (including 9 figures and 3 tables); International Journal of\n  Computer Applications (published)", "journal-ref": "International Journal of Computer Applications 105(16):23-31,\n  November 2014", "doi": "10.5120/18462-9822 10.5120/18462-9822 10.5120/18462-9822", "report-no": null, "categories": "cs.HC stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article proposes a multistage framework for time series analysis of user\nactivity on touch sensitive surfaces in noisy environments. Here multiple\nmethods are put together in multi stage framework; including moving average,\nmoving median, linear regression, kernel density estimation, partial\ndifferential equations and Kalman filter. The proposed three stage filter\nconsisting of partial differential equation based denoising, Kalman filter and\nmoving average method provides ~25% better noise reduction than other methods\naccording to Mean Squared Error (MSE) criterion in highly noise susceptible\nenvironments. Apart from synthetic data, we also obtained real world data like\nhand writing, finger/stylus drags etc. on touch screens in the presence of high\nnoise such as unauthorized charger noise or display noise and validated our\nalgorithms. Furthermore, the proposed algorithm performs qualitatively better\nthan the existing solutions for touch panels of the high end hand held devices\navailable in the consumer electronics market qualitatively.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jan 2015 05:24:41 GMT"}], "update_date": "2015-01-23", "authors_parsed": [["Vanga", "Sandeep", ""], ["Jaganade", "Sachin", ""]]}, {"id": "1501.05303", "submitter": "Yen-Chi Chen", "authors": "Yen-Chi Chen, Shirley Ho, Peter E. Freeman, Christopher R. Genovese,\n  Larry Wasserman", "title": "Cosmic Web Reconstruction through Density Ridges: Method and Algorithm", "comments": "To appear in MNRAS. 18 pages, 19 figures, 1 table", "journal-ref": null, "doi": "10.1093/mnras/stv1996", "report-no": null, "categories": "astro-ph.CO stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The detection and characterization of filamentary structures in the cosmic\nweb allows cosmologists to constrain parameters that dictates the evolution of\nthe Universe. While many filament estimators have been proposed, they generally\nlack estimates of uncertainty, reducing their inferential power. In this paper,\nwe demonstrate how one may apply the Subspace Constrained Mean Shift (SCMS)\nalgorithm (Ozertem and Erdogmus (2011); Genovese et al. (2012)) to uncover\nfilamentary structure in galaxy data. The SCMS algorithm is a gradient ascent\nmethod that models filaments as density ridges, one-dimensional smooth curves\nthat trace high-density regions within the point cloud. We also demonstrate how\naugmenting the SCMS algorithm with bootstrap-based methods of uncertainty\nestimation allows one to place uncertainty bands around putative filaments. We\napply the SCMS method to datasets sampled from the P3M N-body simulation, with\ngalaxy number densities consistent with SDSS and WFIRST-AFTA and to LOWZ and\nCMASS data from the Baryon Oscillation Spectroscopic Survey (BOSS). To further\nassess the efficacy of SCMS, we compare the relative locations of BOSS\nfilaments with galaxy clusters in the redMaPPer catalog, and find that\nredMaPPer clusters are significantly closer (with p-values $< 10^{-9}$) to\nSCMS-detected filaments than to randomly selected galaxies.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jan 2015 21:00:09 GMT"}, {"version": "v2", "created": "Wed, 1 Apr 2015 21:30:47 GMT"}, {"version": "v3", "created": "Fri, 28 Aug 2015 00:51:54 GMT"}], "update_date": "2015-10-07", "authors_parsed": [["Chen", "Yen-Chi", ""], ["Ho", "Shirley", ""], ["Freeman", "Peter E.", ""], ["Genovese", "Christopher R.", ""], ["Wasserman", "Larry", ""]]}, {"id": "1501.05349", "submitter": "Yan Shang", "authors": "Yan Shang, David B. Dunson, Jing-Sheng Song", "title": "Exploiting Big Data in Logistics Risk Assessment via Bayesian\n  Nonparametrics", "comments": "35 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In cargo logistics, a key performance measure is transport risk, defined as\nthe deviation of the actual arrival time from the planned arrival time. Neither\nearliness nor tardiness is desirable for customer and freight forwarders. In\nthis paper, we investigate ways to assess and forecast transport risks using a\nhalf-year of air cargo data, provided by a leading forwarder on 1336 routes\nserved by 20 airlines. Interestingly, our preliminary data analysis shows a\nstrong multimodal feature in the transport risks, driven by unobserved events,\nsuch as cargo missing flights. To accommodate this feature, we introduce a\nBayesian nonparametric model -- the probit stick-breaking process (PSBP)\nmixture model -- for flexible estimation of the conditional (i.e.,\nstate-dependent) density function of transport risk. We demonstrate that using\nsimpler methods, such as OLS linear regression, can lead to misleading\ninferences. Our model provides a tool for the forwarder to offer customized\nprice and service quotes. It can also generate baseline airline performance to\nenable fair supplier evaluation. Furthermore, the method allows us to separate\nrecurrent risks from disruption risks. This is important, because hedging\nstrategies for these two kinds of risks are often drastically different.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jan 2015 23:22:22 GMT"}, {"version": "v2", "created": "Thu, 21 Jul 2016 04:31:38 GMT"}], "update_date": "2016-07-22", "authors_parsed": [["Shang", "Yan", ""], ["Dunson", "David B.", ""], ["Song", "Jing-Sheng", ""]]}, {"id": "1501.05552", "submitter": "Abderrahim Halimi", "authors": "A. Halimi and P. Honeine and M. Kharouf and C. Richard and J.-Y.\n  Tourneret", "title": "Estimating the Intrinsic Dimension of Hyperspectral Images Using an\n  Eigen-Gap Approach", "comments": "21 pages, 4 figures and 4 tables", "journal-ref": null, "doi": "10.1109/TGRS.2016.2528298", "report-no": null, "categories": "stat.AP cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linear mixture models are commonly used to represent hyperspectral datacube\nas a linear combinations of endmember spectra. However, determining of the\nnumber of endmembers for images embedded in noise is a crucial task. This paper\nproposes a fully automatic approach for estimating the number of endmembers in\nhyperspectral images. The estimation is based on recent results of random\nmatrix theory related to the so-called spiked population model. More precisely,\nwe study the gap between successive eigenvalues of the sample covariance matrix\nconstructed from high dimensional noisy samples. The resulting estimation\nstrategy is unsupervised and robust to correlated noise. This strategy is\nvalidated on both synthetic and real images. The experimental results are very\npromising and show the accuracy of this algorithm with respect to\nstate-of-the-art algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jan 2015 16:18:35 GMT"}], "update_date": "2016-06-29", "authors_parsed": [["Halimi", "A.", ""], ["Honeine", "P.", ""], ["Kharouf", "M.", ""], ["Richard", "C.", ""], ["Tourneret", "J. -Y.", ""]]}, {"id": "1501.05763", "submitter": "Ian Dryden", "authors": "Christopher J. Brignell, William J. Browne, Ian L. Dryden and Susan T.\n  Francis", "title": "Mixed Effect Modelling of Single Trial Variability in Ultra-High Field\n  fMRI", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neuronal brain activity in response to repeated stimuli can be perceived\nusing functional magnetic resonance imaging (fMRI). In this paper, we develop a\nstatistical model for fMRI data that estimates both the associated haemodynamic\nresponse function and the within and between trial variability through maximum\nlikelihood estimation. We discuss our results in the context of other\nmodel-driven approaches, extending models already popular in the literature,\nwhile removing the need for some of their assumptions. We consider an\napplication to the motor cortex activity caused by a subject pressing a button\nand observe that the response changes significantly with task and through time.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jan 2015 10:36:41 GMT"}], "update_date": "2015-01-26", "authors_parsed": [["Brignell", "Christopher J.", ""], ["Browne", "William J.", ""], ["Dryden", "Ian L.", ""], ["Francis", "Susan T.", ""]]}, {"id": "1501.05831", "submitter": "Jean-Louis Foulley JLF", "authors": "Jean-Louis Foulley", "title": "A simple Bayesian procedure for forecasting the outcomes of the UEFA\n  Champions League matches", "comments": "14 pages, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article presents a Bayesian implementation of a cumulative probit model\nto forecast the outcomes of the UEFA Champions League matches. The argument of\nthe normal CDF involves a cut-off point, a home vs away playing effect and the\ndifference in strength of the two competing teams. Team strength is assumed to\nfollow a Gaussian distribution the expectation of which is expressed as a\nlinear regression on an external rating of the team from eg the UEFA Club\nRanking (UEFACR) or the Football Club World Ranking (FCWR). Priors on these\nparameters are updated at the beginning of each season from their posterior\ndistributions obtained at the end of the previous one. This allows making\npredictions of match results for each phase of the competition: group stage and\nknock-out. An application is presented for the 2013-2014 season. Adjustment\nbased on the FCWR performs better than on UEFACR.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jan 2015 15:30:32 GMT"}, {"version": "v2", "created": "Fri, 13 Feb 2015 11:26:26 GMT"}], "update_date": "2015-02-16", "authors_parsed": [["Foulley", "Jean-Louis", ""]]}, {"id": "1501.05930", "submitter": "Aslan Tchamkerten", "authors": "Venkat Chandar and Aslan Tchamkerten", "title": "Sampling Constrained Asynchronous Communication: How to Sleep\n  Efficiently", "comments": "Accepted for publication in the IEEE Transactions on Information\n  Theory", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The minimum energy, and, more generally, the minimum cost, to transmit one\nbit of information has been recently derived for bursty communication when\ninformation is available infrequently at random times at the transmitter.\nFurthermore, it has been shown that even if the receiver is constrained to\nsample only a fraction $\\rho\\in (0,1]$ of the channel outputs, there is no\ncapacity penalty. That is, for any strictly positive sampling rate $\\rho>0$,\nthe asynchronous capacity per unit cost is the same as under full sampling,\ni.e., when $\\rho=1$. Moreover, there is no penalty in terms of decoding delay.\n  The above results are asymptotic in nature, considering the limit as the\nnumber $B$ of bits to be transmitted tends to infinity, while the sampling rate\n$\\rho$ remains fixed. A natural question is then whether the sampling rate\n$\\rho(B)$ can drop to zero without introducing a capacity (or delay) penalty\ncompared to full sampling. We answer this question affirmatively. The main\nresult of this paper is an essentially tight characterization of the minimum\nsampling rate. We show that any sampling rate that grows at least as fast as\n$\\omega(1/B)$ is achievable, while any sampling rate smaller than $o(1/B)$\nyields unreliable communication. The key ingredient in our improved\nachievability result is a new, multi-phase adaptive sampling scheme for\nlocating transient changes, which we believe may be of independent interest for\ncertain change-point detection problems.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jan 2015 19:56:13 GMT"}, {"version": "v2", "created": "Tue, 27 Jan 2015 17:30:29 GMT"}, {"version": "v3", "created": "Wed, 2 Mar 2016 13:16:22 GMT"}, {"version": "v4", "created": "Fri, 30 Jun 2017 19:52:52 GMT"}, {"version": "v5", "created": "Tue, 24 Oct 2017 16:19:40 GMT"}], "update_date": "2017-10-25", "authors_parsed": [["Chandar", "Venkat", ""], ["Tchamkerten", "Aslan", ""]]}, {"id": "1501.05961", "submitter": "Nicholas Henderson", "authors": "Nicholas C. Henderson and Paul J. Rathouz", "title": "AR(1) Latent Class Models for Longitudinal Count Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a variety of applications involving longitudinal or repeated-measurements\ndata, it is desired to uncover natural groupings or clusters which exist among\nstudy subjects. Motivated by the need to recover longitudinal trajectories of\nconduct problems in the field of developmental psychopathology, we propose a\nmethod to address this goal when the data in question are counts. We assume\nthat the subject-specific observations are generated from a first-order\nautoregressive process which is appropriate for counts. A key advantage of our\napproach is that the marginal distribution of the response can be expressed in\nclosed form, circumventing common computational issues associated with random\neffects models. To further improve computational efficiency, we propose a\nquasi-EM procedure for estimating the model parameters where, within each EM\niteration, the maximization step is approximated by solving an appropriately\nchosen set of estimating equations. Additionally, we introduce a novel method\nto express the degree to which both the underlying data and the fitted model\nare able to correctly assign subjects to their (unknown) latent classes. We\nexplore the effectiveness of our procedures through simulations based on a\nfour-class model, placing a special emphasis on posterior classification.\nFinally, we analyze data and recover trajectories of conduct problems in an\nimportant nationally representative sample.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jan 2015 21:23:31 GMT"}], "update_date": "2015-01-27", "authors_parsed": [["Henderson", "Nicholas C.", ""], ["Rathouz", "Paul J.", ""]]}, {"id": "1501.06031", "submitter": "Giacomo Aletti", "authors": "Giacomo Aletti, Davide Lonardoni, Giovanni Naldi and Thierry Nieus", "title": "From dynamics to links: a sparse reconstruction of the topology of a\n  neural network", "comments": null, "journal-ref": null, "doi": "10.2478/caim-2019-0002", "report-no": null, "categories": "stat.AP math.NA q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One major challenge in neuroscience is the identification of interrelations\nbetween signals reflecting neural activity and how information processing\noccurs in the neural circuits. At the cellular and molecular level, mechanisms\nof signal transduction have been studied intensively and a better knowledge and\nunderstanding of some basic processes of information handling by neurons has\nbeen achieved. In contrast, little is known about the organization and function\nof complex neuronal networks. Experimental methods are now available to\nsimultaneously monitor electrical activity of a large number of neurons in real\ntime. Then, the qualitative and quantitative analysis of the spiking activity\nof individual neurons is a very valuable tool for the study of the dynamics and\narchitecture of the neural networks. Such activity is not due to the sole\nintrinsic properties of the individual neural cells but it is mostly\nconsequence of the direct influence of other neurons. The deduction of the\neffective connectivity between neurons, whose experimental spike trains are\nobserved, is of crucial importance in neuroscience: first for the correct\ninterpretation of the electro-physiological activity of the involved neurons\nand neural networks, and, for correctly relating the electrophysiological\nactivity to the functional tasks accomplished by the network. In this work we\npropose a novel method for the identification of connectivity of neural\nnetworks using recorded voltages. Our approach is based on the assumption that\nthe network has a topology with sparse connections. After a brief description\nof our method we will report the performances and compare it to the\ncross-correlation computed on the spike trains, that represents a gold standard\nmethod in the field.\n", "versions": [{"version": "v1", "created": "Sat, 24 Jan 2015 12:16:10 GMT"}, {"version": "v2", "created": "Tue, 29 Nov 2016 14:08:39 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Aletti", "Giacomo", ""], ["Lonardoni", "Davide", ""], ["Naldi", "Giovanni", ""], ["Nieus", "Thierry", ""]]}, {"id": "1501.06149", "submitter": "Iain Johnston", "authors": "Iain G. Johnston and Nick S. Jones", "title": "Closed-form stochastic solutions for non-equilibrium dynamics and\n  inheritance of cellular components over many cell divisions", "comments": null, "journal-ref": null, "doi": "10.1098/rspa.2015.0050", "report-no": null, "categories": "q-bio.QM stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic dynamics govern many important processes in cellular biology, and\nan underlying theoretical approach describing these dynamics is desirable to\naddress a wealth of questions in biology and medicine. Mathematical tools exist\nfor treating several important examples of these stochastic processes, most\nnotably gene expression, and random partitioning at single cell divisions or\nafter a steady state has been reached. Comparatively little work exists\nexploring different and specific ways that repeated cell divisions can lead to\nstochastic inheritance of unequilibrated cellular populations. Here we\nintroduce a mathematical formalism to describe cellular agents that are subject\nto random creation, replication, and/or degradation, and are inherited\naccording to a range of random dynamics at cell divisions. We obtain\nclosed-form generating functions describing systems at any time after any\nnumber of cell divisions for binomial partitioning and divisions provoking a\ndeterministic or random, subtractive or additive change in copy number, and\nshow that these solutions agree exactly with stochastic simulation. We apply\nthis general formalism to several example problems involving the dynamics of\nmitochondrial DNA (mtDNA) during development and organismal lifetimes.\n", "versions": [{"version": "v1", "created": "Sun, 25 Jan 2015 12:56:04 GMT"}], "update_date": "2016-02-17", "authors_parsed": [["Johnston", "Iain G.", ""], ["Jones", "Nick S.", ""]]}, {"id": "1501.06377", "submitter": "Theodoros Economou", "authors": "Theodoros Economou, David B. Stephenson, Christopher A. T. Ferro", "title": "Spatio-temporal modelling of extreme storms", "comments": "Published in at http://dx.doi.org/10.1214/14-AOAS766 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2014, Vol. 8, No. 4, 2223-2246", "doi": "10.1214/14-AOAS766", "report-no": "IMS-AOAS-AOAS766", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A flexible spatio-temporal model is implemented to analyse extreme\nextra-tropical cyclones objectively identified over the Atlantic and Europe in\n6-hourly re-analyses from 1979-2009. Spatial variation in the extremal\nproperties of the cyclones is captured using a 150 cell spatial regularisation,\nlatitude as a covariate, and spatial random effects. The North Atlantic\nOscillation (NAO) is also used as a covariate and is found to have a\nsignificant effect on intensifying extremal storm behaviour, especially over\nNorthern Europe and the Iberian peninsula. Estimates of lower bounds on minimum\nsea-level pressure are typically 10-50 hPa below the minimum values observed\nfor historical storms with largest differences occurring when the NAO index is\npositive.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jan 2015 13:13:18 GMT"}], "update_date": "2015-01-27", "authors_parsed": [["Economou", "Theodoros", ""], ["Stephenson", "David B.", ""], ["Ferro", "Christopher A. T.", ""]]}, {"id": "1501.06387", "submitter": "Andrew Bray", "authors": "Andrew Bray, Ka Wong, Christopher D. Barr, Frederic Paik Schoenberg", "title": "Voronoi residual analysis of spatial point process models with\n  applications to California earthquake forecasts", "comments": "Published in at http://dx.doi.org/10.1214/14-AOAS767 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2014, Vol. 8, No. 4, 2247-2267", "doi": "10.1214/14-AOAS767", "report-no": "IMS-AOAS-AOAS767", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many point process models have been proposed for describing and forecasting\nearthquake occurrences in seismically active zones such as California, but the\nproblem of how best to compare and evaluate the goodness of fit of such models\nremains open. Existing techniques typically suffer from low power, especially\nwhen used for models with very volatile conditional intensities such as those\nused to describe earthquake clusters. This paper proposes a new residual\nanalysis method for spatial or spatial-temporal point processes involving\ninspecting the differences between the modeled conditional intensity and the\nobserved number of points over the Voronoi cells generated by the observations.\nThe resulting residuals can be used to construct diagnostic methods of greater\nstatistical power than residuals based on rectangular grids. Following an\nevaluation of performance using simulated data, the suggested method is used to\ncompare the Epidemic-Type Aftershock Sequence (ETAS) model to the Hector Mine\nearthquake catalog. The proposed residuals indicate that the ETAS model with\nuniform background rate appears to slightly but systematically underpredict\nseismicity along the fault and to overpredict seismicity in along the periphery\nof the fault.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jan 2015 13:31:06 GMT"}], "update_date": "2015-01-27", "authors_parsed": [["Bray", "Andrew", ""], ["Wong", "Ka", ""], ["Barr", "Christopher D.", ""], ["Schoenberg", "Frederic Paik", ""]]}, {"id": "1501.06406", "submitter": "Daniel Ambach", "authors": "Daniel Ambach and Carsten Croonenbroeck", "title": "Using the lasso method for space-time short-term wind speed predictions", "comments": "20 pages, 9 figures and 3 tables", "journal-ref": null, "doi": null, "report-no": "SMAP-D-14-00286", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate wind power forecasts depend on reliable wind speed forecasts.\nNumerical Weather Predictions (NWPs) utilize huge amounts of computing time,\nbut still have rather low spatial and temporal resolution. However, stochastic\nwind speed forecasts perform well in rather high temporal resolution settings.\nThey consume comparably little computing resources and return reliable\nforecasts, if forecasting horizons are not too long. In the recent literature,\nspatial interdependence is increasingly taken into consideration. In this paper\nwe propose a new and quite flexible multivariate model that accounts for\nneighbouring weather stations' information and as such, exploits spatial data\nat a high resolution. The model is applied to forecasting horizons of up to one\nday and is capable of handling a high resolution temporal structure. We use a\nperiodic vector autoregressive model with seasonal lags to account for the\ninteraction of the explanatory variables. Periodicity is considered and is\nmodelled by cubic B-splines. Due to the model's flexibility, the number of\nexplanatory variables becomes huge. Therefore, we utilize time-saving shrinkage\nmethods like lasso and elastic net for estimation. Particularly, a relatively\nnewly developed iteratively re-weighted lasso and elastic net is applied that\nalso incorporates heteroscedasticity. We compare our model to several\nbenchmarks. The out-of-sample forecasting results show that the exploitation of\nspatial information increases the forecasting accuracy tremendously, in\ncomparison to models in use so far.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jan 2015 14:19:11 GMT"}, {"version": "v2", "created": "Wed, 9 Sep 2015 08:14:21 GMT"}], "update_date": "2015-09-10", "authors_parsed": [["Ambach", "Daniel", ""], ["Croonenbroeck", "Carsten", ""]]}, {"id": "1501.06629", "submitter": "Anna Sikov", "authors": "Anna Sikov", "title": "Bayesian Approach to Handling Informative Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the case of informative sampling the sampling scheme explicitly or\nimplicitly depends on the response variable. As a result, the sample\ndistribution of response variable can- not be used for making inference about\nthe population. In this research I investigate the problem of informative\nsampling from the Bayesian perspective. Application of the Bayesian approach\npermits solving the problems, which arise due to complexity of the models,\nbeing used for handling informative sampling. The main objective of the re-\nsearch is to combine the elements of the classical sampling theory and Bayesian\nanalysis, for identifying and estimating the population model, and the model\ndescribing the sam- pling mechanism. Utilizing the fact that inclusion\nprobabilities are generally known, the population sum of squares of the models\nresiduals can be estimated, implementing the techniques of the sampling theory.\nIn this research I show, how these estimates can be incorporated in the\nBayesian modeling and how the Full Bayesian Significance Test (FBST), which is\nbased on the Bayesian measure of evidence for precise null hypothesis, can be\nutilized as a model identification tool. The results obtained by implementation\nof the proposed approach to estimation and identification of the sample\nselection model seem promising. At this point I am working on methods of\nestimation and identification of the population model. An interesting extension\nof my approach is incorporation of known population characteristics into the\nestimation process. Some other directions for continuation of my research are\nhighlighted in the sections which describe the proposed methodology.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jan 2015 00:29:14 GMT"}], "update_date": "2016-11-18", "authors_parsed": [["Sikov", "Anna", ""]]}, {"id": "1501.06630", "submitter": "Timothy Armstrong", "authors": "Isaiah Andrews and Timothy B. Armstrong", "title": "Unbiased Instrumental Variables Estimation Under Known First-Stage Sign", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive mean-unbiased estimators for the structural parameter in\ninstrumental variables models with a single endogenous regressor where the sign\nof one or more first stage coefficients is known. In the case with a single\ninstrument, there is a unique non-randomized unbiased estimator based on the\nreduced-form and first-stage regression estimates. For cases with multiple\ninstruments we propose a class of unbiased estimators and show that an\nestimator within this class is efficient when the instruments are strong. We\nshow numerically that unbiasedness does not come at a cost of increased\ndispersion in models with a single instrument: in this case the unbiased\nestimator is less dispersed than the 2SLS estimator. Our finite-sample results\napply to normal models with known variance for the reduced-form errors, and\nimply analogous results under weak instrument asymptotics with an unknown error\ndistribution.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jan 2015 00:48:00 GMT"}, {"version": "v2", "created": "Mon, 23 Mar 2015 14:12:05 GMT"}, {"version": "v3", "created": "Mon, 31 Aug 2015 11:52:35 GMT"}, {"version": "v4", "created": "Sat, 10 Oct 2015 12:29:22 GMT"}, {"version": "v5", "created": "Mon, 26 Oct 2015 02:09:32 GMT"}, {"version": "v6", "created": "Sun, 10 Apr 2016 14:23:08 GMT"}, {"version": "v7", "created": "Fri, 2 Dec 2016 14:04:00 GMT"}], "update_date": "2016-12-05", "authors_parsed": [["Andrews", "Isaiah", ""], ["Armstrong", "Timothy B.", ""]]}, {"id": "1501.06643", "submitter": "Xiang Wan", "authors": "Kai Dong, Hongyu Zhao, Xiang Wan, Tiejun Tong", "title": "NBLDA: Negative Binomial Linear Discriminant Analysis for RNA-Seq Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  RNA-sequencing (RNA-Seq) has become a powerful technology to characterize\ngene expression profiles because it is more accurate and comprehensive than\nmicroarrays. Although statistical methods that have been developed for\nmicroarray data can be applied to RNA-Seq data, they are not ideal due to the\ndiscrete nature of RNA-Seq data. The Poisson distribution and negative binomial\ndistribution are commonly used to model count data. Recently, Witten (2011)\nproposed a Poisson linear discriminant analysis for RNA-Seq data. The Poisson\nassumption may not be as appropriate as negative binomial distribution when\nbiological replicates are available and in the presence of overdispersion\n(i.e., when the variance is larger than the mean). However, it is more\ncomplicated to model negative binomial variables because they involve a\ndispersion parameter that needs to be estimated. In this paper, we propose a\nnegative binomial linear discriminant analysis for RNA-Seq data. By Bayes'\nrule, we construct the classifier by fitting a negative binomial model, and\npropose some plug-in rules to estimate the unknown parameters in the\nclassifier. The relationship between the negative binomial classifier and the\nPoisson classifier is explored, with a numerical investigation of the impact of\ndispersion on the discriminant score. Simulation results show the superiority\nof our proposed method. We also analyze four real RNA-Seq data sets to\ndemonstrate the advantage of our method in real-world applications.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jan 2015 02:37:40 GMT"}, {"version": "v2", "created": "Wed, 28 Jan 2015 03:48:59 GMT"}], "update_date": "2015-01-29", "authors_parsed": [["Dong", "Kai", ""], ["Zhao", "Hongyu", ""], ["Wan", "Xiang", ""], ["Tong", "Tiejun", ""]]}, {"id": "1501.06789", "submitter": "Caroline Wagner", "authors": "Caroline S. Wagner, Edwin Horlings, Arindum Dutta", "title": "Can Science and Technology Capacity be Measured?", "comments": "Updates a RAND 2001 report: Science and Technology Collaboration:\n  Building Capacity in Developing Countries? MR-135, Santa Monica, CA", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.DL physics.soc-ph", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  The ability of a nation to participate in the global knowledge economy\ndepends to some extent on its capacities in science and technology. In an\neffort to assess the capacity of different countries in science and technology,\nthis article updates a classification scheme developed by RAND to measure\nscience and technology capacity for 150 countries of the world.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jan 2015 15:19:17 GMT"}], "update_date": "2015-01-28", "authors_parsed": [["Wagner", "Caroline S.", ""], ["Horlings", "Edwin", ""], ["Dutta", "Arindum", ""]]}, {"id": "1501.06835", "submitter": "Konstantin Zuev M", "authors": "Konstantin Zuev, Marian Boguna, Ginestra Bianconi, Dmitri Krioukov", "title": "Emergence of Soft Communities from Geometric Preferential Attachment", "comments": "10 pages, 6 figures", "journal-ref": "Nature Scientific Reports, v.5, p.9421, 2015", "doi": "10.1038/srep09421", "report-no": null, "categories": "physics.soc-ph cs.SI physics.data-an stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  All real networks are different, but many have some structural properties in\ncommon. There seems to be no consensus on what the most common properties are,\nbut scale-free degree distributions, strong clustering, and community structure\nare frequently mentioned without question. Surprisingly, there exists no simple\ngenerative mechanism explaining all the three properties at once in growing\nnetworks. Here we show how latent network geometry coupled with preferential\nattachment of nodes to this geometry fills this gap. We call this mechanism\ngeometric preferential attachment (GPA), and validate it against the Internet.\nGPA gives rise to soft communities that provide a different perspective on the\ncommunity structure in networks. The connections between GPA and cosmological\nmodels, including inflation, are also discussed.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jan 2015 17:34:57 GMT"}], "update_date": "2015-05-01", "authors_parsed": [["Zuev", "Konstantin", ""], ["Boguna", "Marian", ""], ["Bianconi", "Ginestra", ""], ["Krioukov", "Dmitri", ""]]}, {"id": "1501.06845", "submitter": "Yu Chen", "authors": "Yu Chen", "title": "Exact Solution for One Type of Lindley's Equation for Queueing Theory\n  and Network Calculus", "comments": "This paper has been withdrawn by the author due to a crucial sign\n  error in equation 1", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lindley's equation is an important relation in queueing theory and network\ncalculus. In this paper, we develop a new method to solve one type of Lindley's\nequation, i.e., the equation V(s)T(-s)-1=0 only has finite negative real roots.\nV(s) and T(-s) are the Laplace transforms of service time's probability density\nfunction (PDF) and interarrival time's PDF (evaluated at -s). For queueing\ntheory, we use this method to derive the exact M/M/1, M/H2/1 and M/E2/1\nwaiting-time distributions, and for the first time find the exact D/M/1\nwaiting-time distribution. For network calculus, we use two examples to compare\nour method with the effective bandwidth model and its dual, the effective\ncapacity model, respectively. We observe that the distribution function of\nbacklog size in the first example can be obtained exactly by our method and\npartially by the effective bandwidth model; however, such a distribution\nfunction in the second example cannot be obtained by our method but can be\napproximated by the effective capacity model.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jan 2015 11:48:55 GMT"}, {"version": "v2", "created": "Thu, 7 May 2015 14:47:32 GMT"}], "update_date": "2015-05-08", "authors_parsed": [["Chen", "Yu", ""]]}, {"id": "1501.06929", "submitter": "Jesus Fernandez-Bes", "authors": "Jesus Fernandez-Bes, V\\'ictor Elvira, Steven Van Vaerenbergh", "title": "A Probabilistic Least-Mean-Squares Filter", "comments": null, "journal-ref": null, "doi": "10.1109/ICASSP.2015.7178361", "report-no": null, "categories": "stat.ML cs.SY stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a probabilistic approach to the LMS filter. By means of an\nefficient approximation, this approach provides an adaptable step-size LMS\nalgorithm together with a measure of uncertainty about the estimation. In\naddition, the proposed approximation preserves the linear complexity of the\nstandard LMS. Numerical results show the improved performance of the algorithm\nwith respect to standard LMS and state-of-the-art algorithms with similar\ncomplexity. The goal of this work, therefore, is to open the door to bring some\nmore Bayesian machine learning techniques to adaptive filtering.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jan 2015 21:23:22 GMT"}], "update_date": "2016-04-11", "authors_parsed": [["Fernandez-Bes", "Jesus", ""], ["Elvira", "V\u00edctor", ""], ["Van Vaerenbergh", "Steven", ""]]}, {"id": "1501.06952", "submitter": "Brendon Brewer", "authors": "Brendon J. Brewer, Courtney P. Donovan", "title": "Fast Bayesian Inference for Exoplanet Discovery in Radial Velocity Data", "comments": "Accepted for publication in MNRAS. 9 pages, 12 figures. Code at\n  http://www.github.com/eggplantbren/Exoplanet", "journal-ref": null, "doi": "10.1093/mnras/stv199", "report-no": null, "categories": "astro-ph.IM astro-ph.EP physics.data-an stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inferring the number of planets $N$ in an exoplanetary system from radial\nvelocity (RV) data is a challenging task. Recently, it has become clear that RV\ndata can contain periodic signals due to stellar activity, which can be\ndifficult to distinguish from planetary signals. However, even doing the\ninference under a given set of simplifying assumptions (e.g. no stellar\nactivity) can be difficult. It is common for the posterior distribution for the\nplanet parameters, such as orbital periods, to be multimodal and to have other\nawkward features. In addition, when $N$ is unknown, the marginal likelihood (or\nevidence) as a function of $N$ is required. Rather than doing separate runs\nwith different trial values of $N$, we propose an alternative approach using a\ntrans-dimensional Markov Chain Monte Carlo method within Nested Sampling. The\nposterior distribution for $N$ can be obtained with a single run. We apply the\nmethod to $\\nu$ Oph and Gliese 581, finding moderate evidence for additional\nsignals in $\\nu$ Oph with periods of 36.11 $\\pm$ 0.034 days, 75.58 $\\pm$ 0.80\ndays, and 1709 $\\pm$ 183 days; the posterior probability that at least one of\nthese exists is 85%. The results also suggest Gliese 581 hosts many (7-15)\n\"planets\" (or other causes of other periodic signals), but only 4-6 have well\ndetermined periods. The analysis of both of these datasets shows phase\ntransitions exist which are difficult to negotiate without Nested Sampling.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jan 2015 22:54:14 GMT"}], "update_date": "2015-06-23", "authors_parsed": [["Brewer", "Brendon J.", ""], ["Donovan", "Courtney P.", ""]]}, {"id": "1501.07000", "submitter": "Max Sommerfeld", "authors": "Max Sommerfeld, Stephen Sain, Armin Schwartzman", "title": "Confidence regions for excursion sets in asymptotically Gaussian random\n  fields, with an application to climate", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of this paper is to give confidence regions for the excursion set of\na spatial function above a given threshold from repeated noisy observations on\na fine grid of fixed locations. Given an asymptotically Gaussian estimator of\nthe target function, a pair of data-dependent nested excursion sets are\nconstructed that are sub- and super-sets of the true excursion set,\nrespectively, with a desired confidence. Asymptotic coverage probabilities are\ndetermined via a multiplier bootstrap method, not requiring Gaussianity of the\noriginal data nor stationarity or smoothness of the limiting Gaussian field.\nThe method is used to determine regions in North America where the mean summer\nand winter temperatures are expected to increase by mid 21st century by more\nthan 2 degrees Celsius.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jan 2015 06:31:00 GMT"}], "update_date": "2015-01-29", "authors_parsed": [["Sommerfeld", "Max", ""], ["Sain", "Stephen", ""], ["Schwartzman", "Armin", ""]]}, {"id": "1501.07134", "submitter": "Michael Krystek", "authors": "Michael Krystek and Harald Bosse", "title": "A Bayesian approach to the linking of key comparisons", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This contribution presents a Bayesian approach to the issue of linking of the\nresults from key comparison measurements. A mathematical treatment based on\nBayesian statistics for the analysis of the results from two comparisons with\nsome joint participants is described. This robust statistical analysis provides\nexpressions and standard uncertainties for the key comparison reference value\n(KCRV) and the degree of equivalence (DOE) as well as a conformity check\nwithout any assumption on a priority of one of the comparisons. In addition to\nthe derivation of the mathematical formulae to be used for this type of\n\"distributed linking\", we also present one synthetic and one real linking\nexample and discuss possible applications of this new linking procedure.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jan 2015 15:10:21 GMT"}], "update_date": "2015-01-29", "authors_parsed": [["Krystek", "Michael", ""], ["Bosse", "Harald", ""]]}, {"id": "1501.07179", "submitter": "Julian Wolfson", "authors": "Julian Wolfson, Joseph S. Koopmeiners", "title": "Who's good this year? Comparing the Information Content of Games in the\n  Four Major US Sports", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the four major North American professional sports (baseball, basketball,\nfootball, and hockey), the primary purpose of the regular season is to\ndetermine which teams most deserve to advance to the playoffs. Interestingly,\nwhile the ultimate goal of identifying the best teams is the same, the number\nof regular season games played differs dramatically between the sports, ranging\nfrom 16 (football) to 82 (basketball and hockey) to 162 (baseball). Though\nlength of season is partially determined by many factors including travel\nlogistics, rest requirements, playoff structure and television contracts, it is\nhard to reconcile the 10-fold difference in the number of games between, for\nexample, the NFL and MLB unless football games are somehow more \"informative\"\nthan baseball games. In this paper, we aim to quantify the amount of\ninformation games yield about the relative strength of the teams involved. Our\nstrategy is to assess how well simple paired comparison models fitted from $X%$\nof the games within a season predict the outcomes of the remaining $(100-X)%$\nof games, for multiple values of $X$. We compare the resulting predictive\naccuracy curves between seasons within the same sport and across all four\nsports, and find dramatic differences in the amount of information yielded by\nindividual game results in the four major U.S. sports.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jan 2015 16:31:47 GMT"}], "update_date": "2015-01-29", "authors_parsed": [["Wolfson", "Julian", ""], ["Koopmeiners", "Joseph S.", ""]]}, {"id": "1501.07255", "submitter": "Renato J Cintra", "authors": "M. M. S. Lira, H. M. de Oliveira, R. J. Cintra", "title": "Elliptic-cylindrical Wavelets: The Mathieu Wavelets", "comments": "10 pages, 2 figures", "journal-ref": "IEEE Signal Processing Letters, vol. 11, issue 1, pp. 52-55, 2004", "doi": "10.1109/LSP.2003.819341", "report-no": null, "categories": "stat.ME cs.NA math.NA stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This note introduces a new family of wavelets and a multiresolution analysis,\nwhich exploits the relationship between analysing filters and Floquet's\nsolution of Mathieu differential equations. The transfer function of both the\ndetail and the smoothing filter is related to the solution of a Mathieu\nequation of odd characteristic exponent. The number of notches of these filters\ncan be easily designed. Wavelets derived by this method have potential\napplication in the fields of Optics and Electromagnetism.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jan 2015 20:00:17 GMT"}], "update_date": "2015-01-29", "authors_parsed": [["Lira", "M. M. S.", ""], ["de Oliveira", "H. M.", ""], ["Cintra", "R. J.", ""]]}, {"id": "1501.07481", "submitter": "Kristjan Greenewald", "authors": "Kristjan Greenewald and Edmund Zelnio and Alfred O. Hero III", "title": "Kronecker PCA Based Robust SAR STAP", "comments": "Tech report. Shorter version submitted to IEEE AES", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work the detection of moving targets in multiantenna SAR is\nconsidered. As a high resolution radar imaging modality, SAR detects and\nidentifies stationary targets very well, giving it an advantage over classical\nGMTI radars. Moving target detection is more challenging due to the \"burying\"\nof moving targets in the clutter and is often achieved using space-time\nadaptive processing (STAP) (based on learning filters from the spatio-temporal\nclutter covariance) to remove the stationary clutter and enhance the moving\ntargets. In this work, it is noted that in addition to the oft noted low rank\nstructure, the clutter covariance is also naturally in the form of a space vs\ntime Kronecker product with low rank factors. A low-rank KronPCA covariance\nestimation algorithm is proposed to exploit this structure, and a separable\nclutter cancelation filter based on the Kronecker covariance estimate is\nproposed. Together, these provide orders of magnitude reduction in the number\nof training samples required, as well as improved robustness to corruption of\nthe training data, e.g. due to outliers and moving targets. Theoretical\nproperties of the proposed estimation algorithm are derived and the significant\nreductions in training complexity are established under the spherically\ninvariant random vector model (SIRV). Finally, an extension of this approach\nincorporating multipass data (change detection) is presented. Simulation\nresults and experiments using the real Gotcha SAR GMTI challenge dataset are\npresented that confirm the advantages of our approach relative to existing\ntechniques.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jan 2015 15:33:32 GMT"}, {"version": "v2", "created": "Fri, 30 Jan 2015 18:25:44 GMT"}, {"version": "v3", "created": "Thu, 1 Oct 2015 18:46:09 GMT"}], "update_date": "2015-10-02", "authors_parsed": [["Greenewald", "Kristjan", ""], ["Zelnio", "Edmund", ""], ["Hero", "Alfred O.", "III"]]}, {"id": "1501.07504", "submitter": "Helio de Oliveira M.", "authors": "J.E. Wesen, V.VV. Vermehren and H.M. de Oliveira", "title": "Adaptive Filter Design for Stock Market Prediction Using a\n  Correlation-based Criterion", "comments": "Quantitative Finance? 9 pages, 9 figures, 1 table. Conference: XLIII\n  Simposio Brasileiro de Pesquisa Operacional, August 2011, Ubatuba-SP, Brazil", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP q-fin.GN q-fin.MF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel adaptive-filter approach for predicting assets on\nthe stock markets. Concepts are introduced here, which allow understanding this\nmethod and computing of the corresponding forecast. This approach is applied,\nas an example, through the prediction over the actual valuation of the PETR3\nshares (Petrobras ON) traded in the Brazilian Stock Market. The first-rate\nchoices of the window length and the number of filter coefficient are\nevaluated. This is done by observing the correlation between the predictor\nsignal and the actual course performed by the market in terms of both the\nwindow prevision length and filter coefficient values. It is shown that such\nadaptive predictors furnish, on the average, very substantial profit on the\ninvested amount.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jan 2015 16:41:33 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Wesen", "J. E.", ""], ["Vermehren", "V. VV.", ""], ["de Oliveira", "H. M.", ""]]}, {"id": "1501.07518", "submitter": "Fabrizio Lecci", "authors": "Samrachana Adhikari, Fabrizio Lecci, James T. Becker, Brian W. Junker,\n  Lewis H. Kuller, Oscar L. Lopez, Ryan J. Tibshirani", "title": "High-Dimensional Longitudinal Classification with the Multinomial Fused\n  Lasso", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study regularized estimation in high-dimensional longitudinal\nclassification problems, using the lasso and fused lasso regularizers. The\nconstructed coefficient estimates are piecewise constant across the time\ndimension in the longitudinal problem, with adaptively selected change points\n(break points). We present an efficient algorithm for computing such estimates,\nbased on proximal gradient descent. We apply our proposed technique to a\nlongitudinal data set on Alzheimer's disease from the Cardiovascular Health\nStudy Cognition Study, and use this data set to motivate and demonstrate\nseveral practical considerations such as the selection of tuning parameters,\nand the assessment of model stability.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jan 2015 17:16:36 GMT"}], "update_date": "2015-01-30", "authors_parsed": [["Adhikari", "Samrachana", ""], ["Lecci", "Fabrizio", ""], ["Becker", "James T.", ""], ["Junker", "Brian W.", ""], ["Kuller", "Lewis H.", ""], ["Lopez", "Oscar L.", ""], ["Tibshirani", "Ryan J.", ""]]}, {"id": "1501.07621", "submitter": "Chris von Csefalvay FRSA", "authors": "Chris von Csefalvay", "title": "Ecological metrics of diversity in understanding social media", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI physics.soc-ph stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Topical discussion networks (TDNs) are networks centered around a discourse\nconcerning a particular concept, whether in real life or online. This paper\nanalogises the population of such networks to populations encountered in\nmathematical ecology, and seeks to evaluate whether three metrics of diversity\nused in ecology - Shannon's $H'$, Simpson's $\\lambda$ and $E_{var}$ proposed by\nSmith and Wilson - give valuable information about the composition and\ndiversity of TDNs. It concludes that each metric has its particular use, and\nthe choice of metric is best understood in the context of the particular\nresearch question.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jan 2015 21:45:40 GMT"}], "update_date": "2015-02-02", "authors_parsed": [["von Csefalvay", "Chris", ""]]}, {"id": "1501.07788", "submitter": "Maxime Lenormand", "authors": "Maxime Lenormand, Bruno Gon\\c{c}alves, Ant\\`onia Tugores, Jos\\'e J.\n  Ramasco", "title": "Human diffusion and city influence", "comments": "9 pages, 7 figures + appendix", "journal-ref": "J. R. Soc. Interface 12, 20150473 (2015)", "doi": "10.1098/rsif.2015.0473", "report-no": null, "categories": "physics.soc-ph cs.CY cs.SI physics.data-an stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cities are characterized by concentrating population, economic activity and\nservices. However, not all cities are equal and a natural hierarchy at local,\nregional or global scales spontaneously emerges. In this work, we introduce a\nmethod to quantify city influence using geolocated tweets to characterize human\nmobility. Rome and Paris appear consistently as the cities attracting most\ndiverse visitors. The ratio between locals and non-local visitors turns out to\nbe fundamental for a city to truly be global. Focusing only on urban residents'\nmobility flows, a city to city network can be constructed. This network allows\nus to analyze centrality measures at different scales. New York and London play\na predominant role at the global scale, while urban rankings suffer substantial\nchanges if the focus is set at a regional level.\n", "versions": [{"version": "v1", "created": "Fri, 30 Jan 2015 14:39:24 GMT"}, {"version": "v2", "created": "Wed, 15 Jul 2015 10:48:39 GMT"}], "update_date": "2015-07-24", "authors_parsed": [["Lenormand", "Maxime", ""], ["Gon\u00e7alves", "Bruno", ""], ["Tugores", "Ant\u00f2nia", ""], ["Ramasco", "Jos\u00e9 J.", ""]]}, {"id": "1501.07866", "submitter": "Ernest Fokoue", "authors": "Zichen Ma and Ernest Fokoue", "title": "A Comparison of Classifiers in Performing Speaker Accent Recognition\n  Using MFCCs", "comments": "9 pages, 7 figures", "journal-ref": "Open Journal of Statistics, 2014, 4, 258-266", "doi": null, "report-no": null, "categories": "cs.SD stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An algorithm involving Mel-Frequency Cepstral Coefficients (MFCCs) is\nprovided to perform signal feature extraction for the task of speaker accent\nrecognition. Then different classifiers are compared based on the MFCC feature.\nFor each signal, the mean vector of MFCC matrix is used as an input vector for\npattern recognition. A sample of 330 signals, containing 165 US voice and 165\nnon-US voice, is analyzed. By comparison, k-nearest neighbors yield the highest\naverage test accuracy, after using a cross-validation of size 500, and least\ntime being used in the computation\n", "versions": [{"version": "v1", "created": "Wed, 28 Jan 2015 21:58:51 GMT"}], "update_date": "2015-02-02", "authors_parsed": [["Ma", "Zichen", ""], ["Fokoue", "Ernest", ""]]}]