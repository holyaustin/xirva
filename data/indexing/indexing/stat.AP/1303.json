[{"id": "1303.0076", "submitter": "Uri Kartoun", "authors": "Uri Kartoun", "title": "Bio-Signals-based Situation Comparison Approach to Predict Pain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a time-series-based classification approach to identify\nsimilarities between bio-medical-based situations. The proposed approach allows\nclassifying collections of time-series representing bio-medical measurements,\ni.e., situations, regardless of the type, the length and the quantity of the\ntime-series a situation comprised of.\n", "versions": [{"version": "v1", "created": "Fri, 1 Mar 2013 03:49:11 GMT"}, {"version": "v2", "created": "Tue, 19 Mar 2013 21:19:06 GMT"}], "update_date": "2013-05-14", "authors_parsed": [["Kartoun", "Uri", ""]]}, {"id": "1303.0117", "submitter": "Manisha Gahirwal", "authors": "Manisha Gahirwal", "title": "Inter Time Series Sales Forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Combining forecast from different models has shown to perform better than\nsingle forecast in most time series. To improve the quality of forecast we can\ngo for combining forecast. We study the effect of decomposing a series into\nmultiple components and performing forecasts on each component separately...\nThe original series is decomposed into trend, seasonality and an irregular\ncomponent for each series. The statistical methods such as ARIMA, Holt-Winter\nhave been used to forecast these components. In this paper we focus on how the\nbest models of one series can be applied to similar frequency pattern series\nfor forecasting using association mining. The proposed method forecast values\nhas been compared with Holt Winter method and shown that the results are better\nthan Holt Winter method\n", "versions": [{"version": "v1", "created": "Fri, 1 Mar 2013 09:06:03 GMT"}], "update_date": "2013-03-04", "authors_parsed": [["Gahirwal", "Manisha", ""]]}, {"id": "1303.0191", "submitter": "Milan \\v{Z}ukovi\\v{c}", "authors": "Milan \\v{Z}ukovi\\v{c} and Dionissios T. Hristopulos", "title": "A Directional Gradient-Curvature Method for Gap Filling of Gridded\n  Environmental Spatial Data with Potentially Anisotropic Correlations", "comments": "26 pages, 7 figures", "journal-ref": "Atmospheric Environment, 77 (2013) p. 901", "doi": "10.1016/j.atmosenv.2013.05.078", "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the Directional Gradient-Curvature (DGC) method, a novel\napproach for filling gaps in gridded environmental data. DGC is based on an\nobjective function that measures the distance between the directionally\nsegregated normalized squared gradient and curvature energies of the sample and\nentire domain data. DGC employs data-conditioned simulations, which sample the\nlocal minima configuration space of the objective function instead of the full\nconditional probability density function. Anisotropy and non-stationarity can\nbe captured by the local constraints and the direction-dependent global\nconstraints. DGC is computationally efficient and requires minimal user input,\nmaking it suitable for automated processing of large (e.g., remotely sensed)\nspatial data sets. Various effects are investigated on synthetic data. The\ngap-filling performance of DGC is assessed in comparison with established\nclassification and interpolation methods using synthetic and real satellite\ndata, including a skewed distribution of daily column ozone values. It is shown\nthat DGC is competitive in terms of cross validation performance.\n", "versions": [{"version": "v1", "created": "Fri, 1 Mar 2013 15:23:30 GMT"}], "update_date": "2014-01-09", "authors_parsed": [["\u017dukovi\u010d", "Milan", ""], ["Hristopulos", "Dionissios T.", ""]]}, {"id": "1303.0426", "submitter": "Stephanie S Zhang", "authors": "Stephanie S. Zhang, Lawrence T. DeCarlo, and Zhiliang Ying", "title": "Non-identifiability, equivalence classes, and attribute-specific\n  classification in Q-matrix based Cognitive Diagnosis Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been growing interest in recent years in Q-matrix based cognitive\ndiagnosis models. Parameter estimation and respondent classification under\nthese models may suffer due to identifiability issues. Non-identifiability can\nbe described by a partition separating attribute profiles into groups of those\nwith identical likelihoods. Marginal identifiability concerns the\nidentifiability of individual attributes. Maximum likelihood estimation of the\nproportion of respondents within each equivalence class is consistent, making\npossible a new measure of assessment quality reporting the proportion of\nrespondents for whom each individual attribute is marginally identifiable.\nArising from this is a new posterior-based classification method adjusting for\nnon-identifiability.\n", "versions": [{"version": "v1", "created": "Sat, 2 Mar 2013 20:36:16 GMT"}], "update_date": "2013-03-05", "authors_parsed": [["Zhang", "Stephanie S.", ""], ["DeCarlo", "Lawrence T.", ""], ["Ying", "Zhiliang", ""]]}, {"id": "1303.0654", "submitter": "Milan \\v{Z}ukovi\\v{c}", "authors": "M. \\v{Z}ukovi\\v{c} and D. T. Hristopulos", "title": "Environmental Time Series Interpolation Based on Spartan Random\n  Processes", "comments": "23 pages, 7 figures", "journal-ref": "Atmospheric Environment 42 (2008) 7669", "doi": "10.1016/j.atmosenv.2008.05.062", "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many environmental applications, time series are either incomplete or\nirregularly spaced. We investigate the application of the Spartan random\nprocess to missing data prediction. We employ a novel modified method of\nmoments (MMoM) for parameter inference. The CPU time of MMoM is shown to be\nmuch faster than that of maximum likelihood estimation and almost independent\nof the data size. We formulate an explicit Spartan interpolator for estimating\nmissing data. The model validation is performed on both synthetic data and real\ntime series of atmospheric aerosol concentrations. The prediction performance\nis shown to be comparable with that attained by the best linear unbiased\n(Kolmogorov-Wiener) predictor at reduced computational cost.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2013 09:38:58 GMT"}], "update_date": "2013-03-05", "authors_parsed": [["\u017dukovi\u010d", "M.", ""], ["Hristopulos", "D. T.", ""]]}, {"id": "1303.0686", "submitter": "K. P. Unnikrishnan", "authors": "Xiang Zhong, Jingshan Li, Goutham Rao, KP Unnikrishnan", "title": "Growth Patterns of US Children from 1963 to 2012", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anthropometric measurements such as weight, stature (height), and body mass\nindex (BMI) provide reliable indicators of children's growth. The 2000 CDC\ngrowth charts are the national standards in the United States for these\nimportant measures. But these growth charts were generated using data from\n1963-1994. To understand the growth patterns of US children since 1994, we\ngenerate weight-for-age, stature-for-age and BMI-for-age percentile curves for\nboth boys and girls aged 2-20 through the methods used to generate the 2000 CDC\ngrowth charts. Our datasets are from the National Health and Nutrition\nExamination Survey (NHANES) for years 1999-2010 and and from NorthShore\nUniversity HealthSystem's Enterprise Data Warehouse (NS-EDW) for years\n2006-2012. The weight and BMI percentile curves generated from NS-EDW and\nNHANES data differ substantially from the CDC percentile curves, while those\nfor stature do not differ substantially. We conclude that the population weight\nand BMI values of US children in recent years have increased significantly\nsince 2000 and the 2000 CDC growth charts may no longer be applicable to the\ncurrent population of US children. Our charts poignantly reveals the increasing\nobesity of American children.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2013 12:36:04 GMT"}], "update_date": "2013-03-05", "authors_parsed": [["Zhong", "Xiang", ""], ["Li", "Jingshan", ""], ["Rao", "Goutham", ""], ["Unnikrishnan", "KP", ""]]}, {"id": "1303.0810", "submitter": "Rodrigo Labouriau", "authors": "Rafael Pimentel Maia, Per Madsen and Rodrigo Labouriau", "title": "Multivariate Survival Mixed Models for Genetic Analysis of Longevity\n  Traits", "comments": "36 pages, 2 figures, 3 tables", "journal-ref": "Pimentel Maia R, Madsen P, Labouriau R. 2014. Multivariate\n  Survival Mixed Models for Genetic Analysis of Longevity Traits. Journal of\n  Applied Statistics. 41(6):1286-1306", "doi": "10.1080/02664763.2013.868416", "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A class of multivariate mixed survival models for continuous and discrete\ntime with a complex covariance structure is introduced in a context of\nquantitative genetic applications. The methods introduced can be used in many\napplications in quantitative genetics although the discussion presented\nconcentrates on longevity studies. The framework presented allows to combine\nmodels based on continuous time with models based on discrete time in a joint\nanalysis. The continuous time models are approximations of the frailty model in\nwhich the hazard function will be assumed to be piece-wise constant. The\ndiscrete time models used are multivariate variants of the discrete relative\nrisk models. These models allow for regular parametric likelihood-based\ninference by exploring a coincidence of their likelihood functions and the\nlikelihood functions of suitably defined multivariate generalized linear mixed\nmodels. The models include a dispersion parameter, which is essential for\nobtaining a decomposition of the variance of the trait of interest as a sum of\nparcels representing the additive genetic effects, environmental effects and\nunspecified sources of variability; as required in quantitative genetic\napplications. The methods presented are implemented in such a way that large\nand complex quantitative genetic data can be analyzed.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2013 19:59:33 GMT"}, {"version": "v2", "created": "Sun, 4 May 2014 09:46:31 GMT"}], "update_date": "2014-05-06", "authors_parsed": [["Maia", "Rafael Pimentel", ""], ["Madsen", "Per", ""], ["Labouriau", "Rodrigo", ""]]}, {"id": "1303.1170", "submitter": "K. P. Unnikrishnan", "authors": "Joyce C. Ho, Joydeep Ghosh, KP Unnikrishnan", "title": "Risk Prediction of a Multiple Sclerosis Diagnosis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiple sclerosis (MS) is a chronic autoimmune disease that affects the\ncentral nervous system. The progression and severity of MS varies by\nindividual, but it is generally a disabling disease. Although medications have\nbeen developed to slow the disease progression and help manage symptoms, MS\nresearch has yet to result in a cure. Early diagnosis and treatment of the\ndisease have been shown to be effective at slowing the development of\ndisabilities. However, early MS diagnosis is difficult because symptoms are\nintermittent and shared with other diseases. Thus most previous works have\nfocused on uncovering the risk factors associated with MS and predicting the\nprogression of disease after a diagnosis rather than disease prediction. This\npaper investigates the use of data available in electronic medical records\n(EMRs) to create a risk prediction model; thereby helping clinicians perform\nthe difficult task of diagnosing an MS patient. Our results demonstrate that\neven given a limited time window of patient data, one can achieve reasonable\nclassification with an area under the receiver operating characteristic curve\nof 0.724. By restricting our features to common EMR components, the developed\nmodels also generalize to other healthcare systems.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2013 20:44:58 GMT"}], "update_date": "2013-03-06", "authors_parsed": [["Ho", "Joyce C.", ""], ["Ghosh", "Joydeep", ""], ["Unnikrishnan", "KP", ""]]}, {"id": "1303.1382", "submitter": "Won Chang", "authors": "Won Chang, Murali Haran, Roman Olson, Klaus Keller", "title": "Fast dimension-reduced climate model calibration and the effect of data\n  aggregation", "comments": "Published in at http://dx.doi.org/10.1214/14-AOAS733 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2014, Vol. 8, No. 2, 649-673", "doi": "10.1214/14-AOAS733", "report-no": "IMS-AOAS-AOAS733", "categories": "stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How will the climate system respond to anthropogenic forcings? One approach\nto this question relies on climate model projections. Current climate\nprojections are considerably uncertain. Characterizing and, if possible,\nreducing this uncertainty is an area of ongoing research. We consider the\nproblem of making projections of the North Atlantic meridional overturning\ncirculation (AMOC). Uncertainties about climate model parameters play a key\nrole in uncertainties in AMOC projections. When the observational data and the\nclimate model output are high-dimensional spatial data sets, the data are\ntypically aggregated due to computational constraints. The effects of\naggregation are unclear because statistically rigorous approaches for model\nparameter inference have been infeasible for high-resolution data. Here we\ndevelop a flexible and computationally efficient approach using principal\ncomponents and basis expansions to study the effect of spatial data aggregation\non parametric and projection uncertainties. Our Bayesian reduced-dimensional\ncalibration approach allows us to study the effect of complicated error\nstructures and data-model discrepancies on our ability to learn about climate\nmodel parameters from high-dimensional data. Considering high-dimensional\nspatial observations reduces the effect of deep uncertainty associated with\nprior specifications for the data-model discrepancy. Also, using the\nunaggregated data results in sharper projections based on our climate model.\nOur computationally efficient approach may be widely applicable to a variety of\nhigh-dimensional computer model calibration problems.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2013 16:44:40 GMT"}, {"version": "v2", "created": "Wed, 23 Oct 2013 21:36:15 GMT"}, {"version": "v3", "created": "Fri, 7 Feb 2014 00:38:18 GMT"}, {"version": "v4", "created": "Wed, 12 Feb 2014 18:20:12 GMT"}, {"version": "v5", "created": "Thu, 31 Jul 2014 10:45:38 GMT"}], "update_date": "2014-08-01", "authors_parsed": [["Chang", "Won", ""], ["Haran", "Murali", ""], ["Olson", "Roman", ""], ["Keller", "Klaus", ""]]}, {"id": "1303.1610", "submitter": "Matteo Convertino", "authors": "Matteo Convertino, Filippo Simini, Filippo Catani, Igor Linkov,\n  Gregory A. Kiker", "title": "Power-law of Aggregate-size Spectra in Natural Systems", "comments": "ICST Transactions on Complex Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM math-ph math.MP stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Patterns of animate and inanimate systems show remarkable similarities in\ntheir aggregation. One similarity is the double-Pareto distribution of the\naggregate-size of system components. Different models have been developed to\npredict aggregates of system components. However, not many models have been\ndeveloped to describe probabilistically the aggregate-size distribution of any\nsystem regardless of the intrinsic and extrinsic drivers of the aggregation\nprocess. Here we consider natural animate systems, from one of the greatest\nmammals - the African elephant (\\textit{Loxodonta africana}) - to the\n\\textit{Escherichia coli} bacteria, and natural inanimate systems in river\nbasins. Considering aggregates as islands and their perimeter as a curve\nmirroring the sculpting network of the system, the probability of exceedence of\nthe drainage area, and the Hack's law are shown to be the the Kor\\v{c}ak's law\nand the perimeter-area relationship for river basins. The perimeter-area\nrelationship, and the probability of exceedence of the aggregate-size provide a\nmeaningful estimate of the same fractal dimension. Systems aggregate because of\nthe influence exerted by a physical or processes network within the system\ndomain. The aggregate-size distribution is accurately derived using the\nnull-method of box-counting on the occurrences of system components. The\nimportance of the aggregate-size spectrum relies on its ability to reveal\nsystem form, function, and dynamics also as a function of other coupled\nsystems. Variations of the fractal dimension and of the aggregate-size\ndistribution are related to changes of systems that are meaningful to monitor\nbecause potentially critical for these systems.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2013 06:19:06 GMT"}], "update_date": "2013-03-08", "authors_parsed": [["Convertino", "Matteo", ""], ["Simini", "Filippo", ""], ["Catani", "Filippo", ""], ["Linkov", "Igor", ""], ["Kiker", "Gregory A.", ""]]}, {"id": "1303.1788", "submitter": "Hae Kyung Im", "authors": "Heather E. Wheeler, Keston Aquino-Michaels, Eric R. Gamazon, Vassily\n  V. Trubetskoy, M. Eileen Dolan, R. Stephanie Huang, Nancy J. Cox, Hae Kyung\n  Im", "title": "Poly-Omic Prediction of Complex Traits: OmicKriging", "comments": null, "journal-ref": null, "doi": "10.1002/gepi.21808", "report-no": null, "categories": "stat.AP q-bio.GN q-bio.QM stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-confidence prediction of complex traits such as disease risk or drug\nresponse is an ultimate goal of personalized medicine. Although genome-wide\nassociation studies have discovered thousands of well-replicated polymorphisms\nassociated with a broad spectrum of complex traits, the combined predictive\npower of these associations for any given trait is generally too low to be of\nclinical relevance. We propose a novel systems approach to complex trait\nprediction, which leverages and integrates similarity in genetic,\ntranscriptomic or other omics-level data. We translate the omic similarity into\nphenotypic similarity using a method called Kriging, commonly used in\ngeostatistics and machine learning. Our method called OmicKriging emphasizes\nthe use of a wide variety of systems-level data, such as those increasingly\nmade available by comprehensive surveys of the genome, transcriptome and\nepigenome, for complex trait prediction. Furthermore, our OmicKriging framework\nallows easy integration of prior information on the function of subsets of\nomics-level data from heterogeneous sources without the sometimes heavy\ncomputational burden of Bayesian approaches. Using seven disease datasets from\nthe Wellcome Trust Case Control Consortium (WTCCC), we show that OmicKriging\nallows simple integration of sparse and highly polygenic components yielding\ncomparable performance at a fraction of the computing time of a recently\npublished Bayesian sparse linear mixed model method. Using a cellular growth\nphenotype, we show that integrating mRNA and microRNA expression data\nsubstantially increases performance over either dataset alone. We also\nintegrate genotype and expression data to predict change in LDL cholesterol\nlevels after statin treatment and show that OmicKriging performs better than\nthe polygenic score method. We provide an R package to implement OmicKriging.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2013 19:26:33 GMT"}, {"version": "v2", "created": "Thu, 12 Sep 2013 15:42:08 GMT"}], "update_date": "2014-05-21", "authors_parsed": [["Wheeler", "Heather E.", ""], ["Aquino-Michaels", "Keston", ""], ["Gamazon", "Eric R.", ""], ["Trubetskoy", "Vassily V.", ""], ["Dolan", "M. Eileen", ""], ["Huang", "R. Stephanie", ""], ["Cox", "Nancy J.", ""], ["Im", "Hae Kyung", ""]]}, {"id": "1303.1828", "submitter": "Ben Murrell", "authors": "Ben Murrell, Daniel Murrell and Hugh Murrell", "title": "Discovering general multidimensional associations", "comments": "8 pages. 4 figures. Supporting information can be found at\n  http://www.cs.sun.ac.za/~bmurrell/Murrell_Matie_SI.pdf", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When two variables are related by a known function, the coefficient of\ndetermination (denoted $R^2$) measures the proportion of the total variance in\nthe observations that is explained by that function. This quantifies the\nstrength of the relationship between variables by describing what proportion of\nthe variance is signal as opposed to noise. For linear relationships, this is\nequal to the square of the correlation coefficient, $\\rho$. When the parametric\nform of the relationship is unknown, however, it is unclear how to estimate the\nproportion of explained variance equitably - assigning similar values to\nequally noisy relationships. Here we demonstrate how to directly estimate a\ngeneralized $R^2$ when the form of the relationship is unknown, and we question\nthe performance of the Maximal Information Coefficient (MIC) - a recently\nproposed information theoretic measure of dependence. We show that our approach\nbehaves equitably, has more power than MIC to detect association between\nvariables, and converges faster with increasing sample size. Most importantly,\nour approach generalizes to higher dimensions, which allows us to estimate the\nstrength of multivariate relationships ($Y$ against $A,B, ...$) and to measure\nassociation while controlling for covariates ($Y$ against $X$ controlling for\n$C$).\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2013 21:11:02 GMT"}], "update_date": "2013-03-11", "authors_parsed": [["Murrell", "Ben", ""], ["Murrell", "Daniel", ""], ["Murrell", "Hugh", ""]]}, {"id": "1303.1883", "submitter": "Brandon Willard", "authors": "Brandon Willard", "title": "Real-time On and Off Road GPS Tracking", "comments": "16 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  This document describes a GPS-based tracking model for position and velocity\nstates on and off of a road network and it enables parallel, online learning of\nstate-dependent parameters, such as GPS error, acceleration error, and road\ntransition probabilities. More specifically, the conditionally linear tracking\nmodel of Ulmke and Koch (2006) is adapted to the Particle Learning framework of\nH. F. Lopes, et. al. (2011), which provides a foundation for further\nhierarchical Bayesian extensions. The filter is shown to perform well on a real\ncity road network while sufficiently estimating on and off road transition\nprobabilities. The model in this paper is also backed by an open-source Java\nproject.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2013 04:21:37 GMT"}, {"version": "v2", "created": "Sat, 19 Apr 2014 01:35:59 GMT"}], "update_date": "2014-04-22", "authors_parsed": [["Willard", "Brandon", ""]]}, {"id": "1303.2060", "submitter": "Sijia Liu", "authors": "Sijia Liu, Engin Masazade, Xiaojing Shen, Pramod K. Varshney", "title": "Adaptive Non-myopic Quantizer Design for Target Tracking in Wireless\n  Sensor Networks", "comments": "Submitted to 2013 Asilomar Conference on Signals, Systems, and\n  Computers", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the problem of nonmyopic (multi-step ahead)\nquantizer design for target tracking using a wireless sensor network. Adopting\nthe alternative conditional posterior Cramer-Rao lower bound (A-CPCRLB) as the\noptimization metric, we theoretically show that this problem can be temporally\ndecomposed over a certain time window. Based on sequential Monte-Carlo methods\nfor tracking, i.e., particle filters, we design the local quantizer adaptively\nby solving a particlebased non-linear optimization problem which is well suited\nfor the use of interior-point algorithm and easily embedded in the filtering\nprocess. Simulation results are provided to illustrate the effectiveness of our\nproposed approach.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2013 17:27:02 GMT"}, {"version": "v2", "created": "Mon, 6 May 2013 20:16:05 GMT"}], "update_date": "2013-05-08", "authors_parsed": [["Liu", "Sijia", ""], ["Masazade", "Engin", ""], ["Shen", "Xiaojing", ""], ["Varshney", "Pramod K.", ""]]}, {"id": "1303.2108", "submitter": "Alejandro Frery", "authors": "Wagner Barreto da Silva, Corina da Costa Freitas, Sidnei Jo\\~ao\n  Siqueira Sant'Anna and Alejandro C. Frery", "title": "Classification of Segments in PolSAR Imagery by Minimum Stochastic\n  Distances Between Wishart Distributions", "comments": "Accepted for publication on the IEEE Journal of Selected Topics in\n  Applied Earth Observations and Remote Sensing", "journal-ref": null, "doi": "10.1109/JSTARS.2013.2248132", "report-no": null, "categories": "cs.CV stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new classifier for Polarimetric SAR (PolSAR) images is proposed and\nassessed in this paper. Its input consists of segments, and each one is\nassigned the class which minimizes a stochastic distance. Assuming the complex\nWishart model, several stochastic distances are obtained from the h-phi family\nof divergences, and they are employed to derive hypothesis test statistics that\nare also used in the classification process. This article also presents, as a\nnovelty, analytic expressions for the test statistics based on the following\nstochastic distances between complex Wishart models: Kullback-Leibler,\nBhattacharyya, Hellinger, R\\'enyi, and Chi-Square; also, the test statistic\nbased on the Bhattacharyya distance between multivariate Gaussian distributions\nis presented. The classifier performance is evaluated using simulated and real\nPolSAR data. The simulated data are based on the complex Wishart model, aiming\nat the analysis of the proposal well controlled data. The real data refer to\nthe complex L-band image, acquired during the 1994 SIR-C mission. The results\nof the proposed classifier are compared with those obtained by a Wishart\nper-pixel/contextual classifier, and we show the better performance of the\nregion-based classification. The influence of the statistical modeling is\nassessed by comparing the results using the Bhattacharyya distance between\nmultivariate Gaussian distributions for amplitude data. The results with\nsimulated data indicate that the proposed classification method has a very good\nperformance when the data follow the Wishart model. The proposed classifier\nalso performs better than the per-pixel/contextual classifier and the\nBhattacharyya Gaussian distance using SIR-C PolSAR data.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2013 18:39:52 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["da Silva", "Wagner Barreto", ""], ["Freitas", "Corina da Costa", ""], ["Sant'Anna", "Sidnei Jo\u00e3o Siqueira", ""], ["Frery", "Alejandro C.", ""]]}, {"id": "1303.2133", "submitter": "S\\'andor Baran", "authors": "S\\'andor Baran, Andr\\'as Hor\\'anyi, D\\'ora Nemoda", "title": "Probabilistic temperature forecasting with statistical calibration in\n  Hungary", "comments": "arXiv admin note: substantial text overlap with arXiv:1202.4442", "journal-ref": "Meteorology and Atmospheric Physics 124 (2014), no. 3-4, 129-142", "doi": "10.1007/s00703-014-0314-8", "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Weather forecasting is mostly based on the outputs of deterministic numerical\nweather forecasting models. Multiple runs of these models with different\ninitial conditions result in forecast ensembles which is are used for\nestimating the distribution of future atmospheric variables. However, these\nensembles are usually under-dispersive and uncalibrated, so post-processing is\nrequired.\n  In the present work Bayesian Model Averaging (BMA) is applied for calibrating\nensembles of temperature forecasts produced by the operational Limited Area\nModel Ensemble Prediction System of the Hungarian Meteorological Service (HMS).\n  We describe two possible BMA models for temperature data of the HMS and show\nthat BMA post-processing significantly improves calibration and probabilistic\nforecasts although the accuracy of point forecasts is rather unchanged.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2013 21:41:23 GMT"}], "update_date": "2015-07-21", "authors_parsed": [["Baran", "S\u00e1ndor", ""], ["Hor\u00e1nyi", "Andr\u00e1s", ""], ["Nemoda", "D\u00f3ra", ""]]}, {"id": "1303.2309", "submitter": "Francesco Montorsi", "authors": "Francesco Montorsi, Santiago Mazuelas, Giorgio M. Vitetta, Moe Z. Win", "title": "On the Performance Limits of Map-Aware Localization", "comments": "16 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Establishing bounds on the accuracy achievable by localization techniques\nrepresents a fundamental technical issue. Bounds on localization accuracy have\nbeen derived for cases in which the position of an agent is estimated on the\nbasis of a set of observations and, possibly, of some a priori information\nrelated to them (e.g., information about anchor positions and properties of the\ncommunication channel). In this manuscript new bounds are derived under the\nassumption that the localization system is map-aware, i.e., it can benefit not\nonly from the availability of observations, but also from the a priori\nknowledge provided by the map of the environment where it operates. Our results\nshow that: a) map-aware estimation accuracy can be related to some features of\nthe map (e.g., its shape and area) even though, in general, the relation is\ncomplicated; b) maps are really useful in the presence of some combination of\nlow signal-to-noise ratios and specific geometrical features of the map (e.g.,\nthe size of obstructions); c) in most cases, there is no need of refined maps\nsince additional details do not improve estimation accuracy.\n", "versions": [{"version": "v1", "created": "Sun, 10 Mar 2013 11:28:45 GMT"}], "update_date": "2013-03-12", "authors_parsed": [["Montorsi", "Francesco", ""], ["Mazuelas", "Santiago", ""], ["Vitetta", "Giorgio M.", ""], ["Win", "Moe Z.", ""]]}, {"id": "1303.2316", "submitter": "Tsung-I Lin", "authors": "Tsung-I Lin, Paul D. McNicholas and Hsiu J. Ho", "title": "Capturing Patterns via Parsimonious t Mixture Models", "comments": "19 pages, 3 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper exploits a simplified version of the mixture of multivariate\nt-factor analyzers (MtFA) for robust mixture modelling and clustering of\nhigh-dimensional data that frequently contain a number of outliers. Two classes\nof eight parsimonious t mixture models are introduced and computation of\nmaximum likelihood estimates of parameters is achieved using the alternating\nexpectation conditional maximization (AECM) algorithm. The usefulness of the\nmethodology is illustrated through applications of image compression and\ncompact facial representation.\n", "versions": [{"version": "v1", "created": "Sun, 10 Mar 2013 12:08:26 GMT"}], "update_date": "2013-03-12", "authors_parsed": [["Lin", "Tsung-I", ""], ["McNicholas", "Paul D.", ""], ["Ho", "Hsiu J.", ""]]}, {"id": "1303.2739", "submitter": "Maumita Bhattacharya", "authors": "Maumita Bhattacharya", "title": "Machine Learning for Bioclimatic Modelling", "comments": "8 pages", "journal-ref": "(IJACSA) International Journal of Advanced Computer Science and\n  Applications,Vol. 4, No. 2, 2013, pp. 1-8", "doi": null, "report-no": null, "categories": "cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many machine learning (ML) approaches are widely used to generate bioclimatic\nmodels for prediction of geographic range of organism as a function of climate.\nApplications such as prediction of range shift in organism, range of invasive\nspecies influenced by climate change are important parameters in understanding\nthe impact of climate change. However, success of machine learning-based\napproaches depends on a number of factors. While it can be safely said that no\nparticular ML technique can be effective in all applications and success of a\ntechnique is predominantly dependent on the application or the type of the\nproblem, it is useful to understand their behavior to ensure informed choice of\ntechniques. This paper presents a comprehensive review of machine\nlearning-based bioclimatic model generation and analyses the factors\ninfluencing success of such models. Considering the wide use of statistical\ntechniques, in our discussion we also include conventional statistical\ntechniques used in bioclimatic modelling.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2013 01:13:44 GMT"}], "update_date": "2013-03-13", "authors_parsed": [["Bhattacharya", "Maumita", ""]]}, {"id": "1303.2797", "submitter": "Dimitris Rizopoulos", "authors": "Dimitris Rizopoulos, Laura A. Hatfield, Bradley P. Carlin and Johanna\n  J.M. Takkenberg", "title": "Combining Dynamic Predictions from Joint Models for Longitudinal and\n  Time-to-Event Data using Bayesian Model Averaging", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The joint modeling of longitudinal and time-to-event data is an active area\nof statistics research that has received a lot of attention in the recent\nyears. More recently, a new and attractive application of this type of models\nhas been to obtain individualized predictions of survival probabilities and/or\nof future longitudinal responses. The advantageous feature of these predictions\nis that they are dynamically updated as extra longitudinal responses are\ncollected for the subjects of interest, providing real time risk assessment\nusing all recorded information. The aim of this paper is two-fold. First, to\nhighlight the importance of modeling the association structure between the\nlongitudinal and event time responses that can greatly influence the derived\npredictions, and second, to illustrate how we can improve the accuracy of the\nderived predictions by suitably combining joint models with different\nassociation structures. The second goal is achieved using Bayesian model\naveraging, which, in this setting, has the very intriguing feature that the\nmodel weights are not fixed but they are rather subject- and time-dependent,\nimplying that at different follow-up times predictions for the same subject may\nbe based on different models.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2013 07:39:31 GMT"}], "update_date": "2013-03-13", "authors_parsed": [["Rizopoulos", "Dimitris", ""], ["Hatfield", "Laura A.", ""], ["Carlin", "Bradley P.", ""], ["Takkenberg", "Johanna J. M.", ""]]}, {"id": "1303.2803", "submitter": "Christian R\\\"over", "authors": "Simon M. Steinvorth, Christian R\\\"over, Simon Schneider, Richard\n  Nicholas, Sebastian Straube, Tim Friede", "title": "Explaining temporal trends in annualized relapse rates in placebo groups\n  of randomized controlled trials in relapsing multiple sclerosis: systematic\n  review and meta-regression", "comments": "20 pages, 4 figures (main article) + 13 pages (web appendix)", "journal-ref": "Multiple Sclerosis Journal, 19(12):1580-1586, 2013", "doi": "10.1177/1352458513481009", "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: Recent studies have shown a decrease in annualised relapse rates\n(ARRs) in placebo groups of randomised controlled trials (RCTs) in relapsing\nmultiple sclerosis (RMS).\n  Methods: We conducted a systematic literature search of RCTs in RMS. Data on\neligibility criteria and baseline characteristics were extracted and tested for\nsignificant trends over time. A meta-regression was conducted to estimate their\ncontribution to the decrease of trial ARRs over time.\n  Results: We identified 56 studies. Patient age at baseline (p < 0.001), mean\nduration of multiple sclerosis (MS) at baseline (p = 0.048), size of treatment\ngroups (p = 0.003), Oxford Quality Scale scores (p = 0.021), and the number of\neligibility criteria (p<0.001) increased significantly, whereas pre-trial ARR\n(p = 0.001), the time span over which pre-trial ARR was calculated (p < 0.001),\nand the duration of placebo-controlled follow-up (p = 0.006) decreased\nsignificantly over time. In meta-regression of trial placebo ARR, the temporal\ntrend was found to be insignificant, with major factors explaining the\nvariation: pre-trial ARR, the number of years used to calculate pre-trial ARR\nand study duration. Conclusion: The observed decline in trial ARRs may result\nfrom decreasing pre-trial ARRs and a shorter time period over which pre-trial\nARRs were calculated. Increasing patient age and duration of illness may also\ncontribute.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2013 08:31:19 GMT"}, {"version": "v2", "created": "Mon, 17 Mar 2014 08:18:14 GMT"}], "update_date": "2014-03-18", "authors_parsed": [["Steinvorth", "Simon M.", ""], ["R\u00f6ver", "Christian", ""], ["Schneider", "Simon", ""], ["Nicholas", "Richard", ""], ["Straube", "Sebastian", ""], ["Friede", "Tim", ""]]}, {"id": "1303.2915", "submitter": "Pasquale Valentini", "authors": "Pasquale Valentini, Luigi Ippoliti, Lara Fontanella", "title": "Modeling US housing prices by spatial dynamic structural equation models", "comments": "Published in at http://dx.doi.org/10.1214/12-AOAS613 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2013, Vol. 7, No. 2, 763-798", "doi": "10.1214/12-AOAS613", "report-no": "IMS-AOAS-AOAS613", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article proposes a spatial dynamic structural equation model for the\nanalysis of housing prices at the State level in the USA. The study contributes\nto the existing literature by extending the use of dynamic factor models to the\neconometric analysis of multivariate lattice data. One of the main advantages\nof our model formulation is that by modeling the spatial variation via\nspatially structured factor loadings, we entertain the possibility of\nidentifying similarity \"regions\" that share common time series components. The\nfactor loadings are modeled as conditionally independent multivariate Gaussian\nMarkov Random Fields, while the common components are modeled by latent dynamic\nfactors. The general model is proposed in a state-space formulation where both\nstationary and nonstationary autoregressive distributed-lag processes for the\nlatent factors are considered. For the latent factors which exhibit a common\ntrend, and hence are cointegrated, an error correction specification of the\n(vector) autoregressive distributed-lag process is proposed. Full probabilistic\ninference for the model parameters is facilitated by adapting standard Markov\nchain Monte Carlo (MCMC) algorithms for dynamic linear models to our model\nformulation. The fit of the model is discussed for a data set of 48 States for\nwhich we model the relationship between housing prices and the macroeconomy,\nusing State level unemployment and per capita personal income.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2013 15:23:05 GMT"}, {"version": "v2", "created": "Fri, 20 Dec 2013 14:34:33 GMT"}], "update_date": "2013-12-23", "authors_parsed": [["Valentini", "Pasquale", ""], ["Ippoliti", "Luigi", ""], ["Fontanella", "Lara", ""]]}, {"id": "1303.2923", "submitter": "Gundula Behrens", "authors": "Gundula Behrens", "title": "Assessing the public health relevance of a risk factor", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a recent series of high impact public health publications, the c-index was\nused as measure of prediction to assess the public health relevance of a risk\nfactor. I demonstrate that the c-index is an inferior measure as compared to\nthe classical epidemiologic measures most commonly employed for risk prediction\nand public health assessment such as disease incidence, relative risk (RR) and\npopulation-attributable risk (PAR). I recommend using the latter measures when\nassessing the public health relevance of a risk factor.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2013 15:39:35 GMT"}], "update_date": "2013-03-13", "authors_parsed": [["Behrens", "Gundula", ""]]}, {"id": "1303.3079", "submitter": "Jeffrey Regier", "authors": "Jeffrey C. Regier and Philip B. Stark", "title": "Mini-Minimax Uncertainty Quantification for Emulators", "comments": null, "journal-ref": "SIAM/ASA Journal on Uncertainty Quantification. 3-1 (2015), pp.\n  686-708", "doi": "10.1137/130917909", "report-no": null, "categories": "stat.ME stat.AP stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider approximating a \"black box\" function $f$ by an emulator $\\hat{f}$\nbased on $n$ noiseless observations of $f$. Let $w$ be a point in the domain of\n$f$. How big might the error $|\\hat{f}(w) - f(w)|$ be? If $f$ could be\narbitrarily rough, this error could be arbitrarily large: we need some\nconstraint on $f$ besides the data. Suppose $f$ is Lipschitz with known\nconstant. We find a lower bound on the number of observations required to\nensure that for the best emulator $\\hat{f}$ based on the $n$ data, $|\\hat{f}(w)\n- f(w)| \\le \\epsilon$. But in general, we will not know whether $f$ is\nLipschitz, much less know its Lipschitz constant. Assume optimistically that\n$f$ is Lipschitz-continuous with the smallest constant consistent with the $n$\ndata. We find the maximum (over such regular $f$) of $|\\hat{f}(w) - f(w)|$ for\nthe best possible emulator $\\hat{f}$; we call this the \"mini-minimax\nuncertainty\" at $w$. In reality, $f$ might not be Lipschitz or---if it is---it\nmight not attain its Lipschitz constant on the data. Hence, the mini-minimax\nuncertainty at $w$ could be much smaller than $|\\hat{f}(w) - f(w)|$. But if the\nmini-minimax uncertainty is large, then---even if $f$ satisfies the optimistic\nregularity assumption---$|\\hat{f}(w) - f(w)|$ could be large, no matter how\ncleverly we choose $\\hat{f}$. For the Community Atmosphere Model, the maximum\n(over $w$) of the mini-minimax uncertainty based on a set of 1154~observations\nof $f$ is no smaller than it would be for a single observation of $f$ at the\ncentroid of the 21-dimensional parameter space. We also find lower confidence\nbounds for quantiles of the mini-minimax uncertainty and its mean over the\ndomain of $f$. For the Community Atmosphere Model, these lower confidence\nbounds are an appreciable fraction of the maximum.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2013 02:29:37 GMT"}, {"version": "v2", "created": "Wed, 8 May 2013 00:08:50 GMT"}, {"version": "v3", "created": "Sun, 7 Jul 2013 17:25:32 GMT"}, {"version": "v4", "created": "Tue, 8 Apr 2014 20:16:06 GMT"}, {"version": "v5", "created": "Mon, 14 Sep 2015 21:29:54 GMT"}], "update_date": "2015-09-16", "authors_parsed": [["Regier", "Jeffrey C.", ""], ["Stark", "Philip B.", ""]]}, {"id": "1303.3226", "submitter": "Pasha Zusmanovich", "authors": "Pasha Zusmanovich", "title": "On near and the nearest correlation matrix", "comments": "v2: added example; updated references", "journal-ref": "J. Nonlin. Math. Phys. 20 (2013), 431-439", "doi": "10.1080/14029251.2013.855050", "report-no": null, "categories": "stat.AP math.RA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an elementary heuristic reasoning based on Arnold's theory of\nversal deformations in support of a straightforward algorithm for finding a\ncorrelation matrix near a given symmetric one.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2013 17:44:50 GMT"}, {"version": "v2", "created": "Sat, 11 Jan 2014 20:47:51 GMT"}], "update_date": "2014-01-14", "authors_parsed": [["Zusmanovich", "Pasha", ""]]}, {"id": "1303.3384", "submitter": "Sandra Plancade", "authors": "Sandra Plancade, Gregory Nuel and Eiliv Lund", "title": "From GWAS to transcriptomics in prospective cancer design - new\n  statistical challenges", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background. With the increasing interest in post-GWAS research which\nrepresents a transition from genome-wide association discovery to analysis of\nfunctional mechanisms, attention has been lately focused on the potential of\nincluding various biological material in epidemiological studies. In\nparticular, exploration of the carcinogenic process through transcriptional\nanalysis at the epidemiological level opens up new horizons in functional\nanalysis and causal inference, and requires a new design together with adequate\nanalysis procedures.\n  Results. In this article, we present the post-genome design implemented in\nthe NOWAC cohort as an example of a prospective nested case-control study built\nfor transcriptomics use, and discuss analytical strategies to explore the\nchanges occurring in transcriptomics during the carcinogenic process in\nassociation with questionnaire information. We emphasize the inadequacy of\nsurvival analysis models usually considered in GWAS for post-genome design, and\npropose instead to parameterize the gene trajectories during the carcinogenic\nprocess.\n  Conclusions. This novel approach, in which transcriptomics are considered as\npotential intermediate biomarkers of cancer and exposures, offers a flexible\nframework which can include various biological assumptions.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2013 09:46:19 GMT"}], "update_date": "2013-03-15", "authors_parsed": [["Plancade", "Sandra", ""], ["Nuel", "Gregory", ""], ["Lund", "Eiliv", ""]]}, {"id": "1303.3574", "submitter": "Alexandre Janon", "authors": "Fabrice Gamboa (UMR CNRS 5219), Alexandre Janon (INRIA Grenoble\n  Rh\\^one-Alpes / LJK Laboratoire Jean Kuntzmann, - M\\'ethodes d'Analyse\n  Stochastique des Codes et Traitements Num\\'eriques, SAF), Thierry Klein\n  (IMT), Agn\\`es Lagnoux (UMR CNRS 5219)", "title": "Sensitivity indices for multivariate outputs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define and study a generalization of Sobol sensitivity indices for the\ncase of a vector output.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2013 19:50:07 GMT"}, {"version": "v2", "created": "Wed, 17 Apr 2013 15:11:10 GMT"}], "update_date": "2013-04-18", "authors_parsed": [["Gamboa", "Fabrice", "", "UMR CNRS 5219"], ["Janon", "Alexandre", "", "INRIA Grenoble\n  Rh\u00f4ne-Alpes / LJK Laboratoire Jean Kuntzmann, - M\u00e9thodes d'Analyse\n  Stochastique des Codes et Traitements Num\u00e9riques, SAF"], ["Klein", "Thierry", "", "IMT"], ["Lagnoux", "Agn\u00e8s", "", "UMR CNRS 5219"]]}, {"id": "1303.3594", "submitter": "Michael Messer", "authors": "Michael Messer, Marietta Kirchner, Julia Schiemann, Jochen Roeper,\n  Ralph Neininger, Gaby Schneider", "title": "A multiple filter test for the detection of rate changes in renewal\n  processes with varying variance", "comments": "Published in at http://dx.doi.org/10.1214/14-AOAS782 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2014, Vol. 8, No. 4, 2027-2067", "doi": "10.1214/14-AOAS782", "report-no": "IMS-AOAS-AOAS782", "categories": "stat.AP math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonstationarity of the event rate is a persistent problem in modeling time\nseries of events, such as neuronal spike trains. Motivated by a variety of\npatterns in neurophysiological spike train recordings, we define a general\nclass of renewal processes. This class is used to test the null hypothesis of\nstationary rate versus a wide alternative of renewal processes with finitely\nmany rate changes (change points). Our test extends ideas from the filtered\nderivative approach by using multiple moving windows simultaneously. To adjust\nthe rejection threshold of the test, we use a Gaussian process, which emerges\nas the limit of the filtered derivative process. We also develop a multiple\nfilter algorithm, which can be used when the null hypothesis is rejected in\norder to estimate the number and location of change points. We analyze the\nbenefits of multiple filtering and its increased detection probability as\ncompared to a single window approach. Application to spike trains recorded from\ndopamine midbrain neurons in anesthetized mice illustrates the relevance of the\nproposed techniques as preprocessing steps for methods that assume rate\nstationarity. In over 70% of all analyzed spike trains classified as rate\nnonstationary, different change points were detected by different window sizes.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2013 20:31:08 GMT"}, {"version": "v2", "created": "Tue, 2 Apr 2013 18:41:59 GMT"}, {"version": "v3", "created": "Thu, 28 Nov 2013 16:21:43 GMT"}, {"version": "v4", "created": "Mon, 2 Dec 2013 12:39:41 GMT"}, {"version": "v5", "created": "Wed, 6 Aug 2014 12:45:52 GMT"}, {"version": "v6", "created": "Fri, 16 Jan 2015 11:28:46 GMT"}], "update_date": "2015-01-19", "authors_parsed": [["Messer", "Michael", ""], ["Kirchner", "Marietta", ""], ["Schiemann", "Julia", ""], ["Roeper", "Jochen", ""], ["Neininger", "Ralph", ""], ["Schneider", "Gaby", ""]]}, {"id": "1303.4372", "submitter": "Gaelle Chastaing", "authors": "Gaelle Chastaing (- M\\'ethodes d'Analyse Stochastique des Codes et\n  Traitements Num\\'eriques, INRIA Grenoble Rh\\^one-Alpes / LJK Laboratoire Jean\n  Kuntzmann), Cl\\'ementine Prieur (- M\\'ethodes d'Analyse Stochastique des\n  Codes et Traitements Num\\'eriques, INRIA Grenoble Rh\\^one-Alpes / LJK\n  Laboratoire Jean Kuntzmann), Fabrice Gamboa (IMT)", "title": "Generalized Sobol sensitivity indices for dependent variables: numerical\n  methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The hierarchically orthogonal functional decomposition of any measurable\nfunction f of a random vector X=(X_1,...,X_p) consists in decomposing f(X) into\na sum of increasing dimension functions depending only on a subvector of X.\nEven when X_1,..., X_p are assumed to be dependent, this decomposition is\nunique if components are hierarchically orthogonal. That is, two of the\ncomponents are orthogonal whenever all the variables involved in one of the\nsummands are a subset of the variables involved in the other. Setting Y=f(X),\nthis decomposition leads to the definition of generalized sensitivity indices\nable to quantify the uncertainty of Y with respect to the dependent inputs X.\nIn this paper, a numerical method is developed to identify the component\nfunctions of the decomposition using the hierarchical orthogonality property.\nFurthermore, the asymptotic properties of the components estimation is studied,\nas well as the numerical estimation of the generalized sensitivity indices of a\ntoy model. Lastly, the method is applied to a model arising from a real-world\nproblem.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2013 19:39:15 GMT"}, {"version": "v2", "created": "Wed, 21 May 2014 05:29:49 GMT"}], "update_date": "2014-05-22", "authors_parsed": [["Chastaing", "Gaelle", "", "- M\u00e9thodes d'Analyse Stochastique des Codes et\n  Traitements Num\u00e9riques, INRIA Grenoble Rh\u00f4ne-Alpes / LJK Laboratoire Jean\n  Kuntzmann"], ["Prieur", "Cl\u00e9mentine", "", "- M\u00e9thodes d'Analyse Stochastique des\n  Codes et Traitements Num\u00e9riques, INRIA Grenoble Rh\u00f4ne-Alpes / LJK\n  Laboratoire Jean Kuntzmann"], ["Gamboa", "Fabrice", "", "IMT"]]}, {"id": "1303.4767", "submitter": "Xiaosun Lu", "authors": "Xiaosun Lu, J. S. Marron and Perry Haaland", "title": "Object Oriented Data Analysis of Cell-Well Structured Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Object oriented data analysis (OODA) aims at statistically analyzing\npopulations of complicated objects. This paper is motivated by a study of cell\nimages in cell culture biology, which highlights a common critical issue:\nchoice of data objects. Instead of conventionally treating either the\nindividual cells or the wells (a container in which the cells are grown) as\ndata objects, a new type of data object is proposed, that is the union of a\nwell with its corresponding set of cells. This paper contains two parts. The\nfirst part is the image data analysis, which suggests empirically that the\ncell-well unions can be a better choice of data objects than the cells or the\nwells alone. The second part discusses the benefit of choosing cell-well unions\nas data objects using an illustrative example and simulations. This research\nsuggests that OODA is not simply a frame work for understanding the structure\nof the data analysis. It leads to useful interdisciplinary discussion that\ngives better results through more appropriate choice of data objects,\nespecially for complex data analyses.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2013 20:55:31 GMT"}], "update_date": "2013-03-21", "authors_parsed": [["Lu", "Xiaosun", ""], ["Marron", "J. S.", ""], ["Haaland", "Perry", ""]]}, {"id": "1303.4956", "submitter": "Tomasz Piotrowski", "authors": "Tomasz Piotrowski and Isao Yamada", "title": "Performance of the stochastic MV-PURE estimator in highly noisy settings", "comments": "submitted to Journal of the Franklin Institute", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The stochastic MV-PURE estimator has been developed to provide linear\nestimation robust to ill-conditioning, high noise levels, and imperfections in\nmodel knowledge. In this paper, we investigate the theoretical performance of\nthe stochastic MV-PURE estimator under varying level of additive noise. More\nprecisely, we prove that the mean-square-error (MSE) of this estimator in the\nlow signal-to-noise (SNR) region is much smaller than that obtained with its\nfull-rank version, the minimum-variance distortionless estimator, and that the\ngap in performance is the larger the higher the noise level. These results shed\nlight on the excellent performance of the stochastic MV-PURE estimator in\nhighly noisy settings obtained in simulations so far. We extend here previously\nconducted numerical simulations to demonstrate a new insight provided by\nresults of this paper in practical applications.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2013 14:51:54 GMT"}], "update_date": "2013-03-21", "authors_parsed": [["Piotrowski", "Tomasz", ""], ["Yamada", "Isao", ""]]}, {"id": "1303.5195", "submitter": "Vladimir Kulikovskiy", "authors": "Vladimir Kulikovskiy", "title": "Adding a systematic uncertainty to the signal estimation in the\n  on/off-zone measurements", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP astro-ph.HE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The measurements with the background estimation from an off-zone are widely\nused in astrophysics, accelerator physics and other areas. Usually, the\nexpected number of the background events in the off-zone and in the on-zone is\nknown with a limited precision. This fact should be included as a systematic\nuncertainty. In this note an overview of the statistical methods which estimate\nthe range and the significance of the measured signal is done. The method which\nincludes a systematic uncertainty is developed for the on/off-zone measurements\nand compared with other existing methods.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2013 09:00:07 GMT"}, {"version": "v2", "created": "Wed, 1 May 2013 16:56:14 GMT"}], "update_date": "2013-05-02", "authors_parsed": [["Kulikovskiy", "Vladimir", ""]]}, {"id": "1303.5588", "submitter": "Aleksandr Aravkin", "authors": "Aleksandr Y. Aravkin, James V. Burke, and Gianluigi Pillonetto", "title": "Robust and Trend Following Student's t Kalman Smoothers", "comments": "23 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC math.NA stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a Kalman smoothing framework based on modeling errors using the\nheavy tailed Student's t distribution, along with algorithms, convergence\ntheory, open-source general implementation, and several important applications.\nThe computational effort per iteration grows linearly with the length of the\ntime series, and all smoothers allow nonlinear process and measurement models.\n  Robust smoothers form an important subclass of smoothers within this\nframework. These smoothers work in situations where measurements are highly\ncontaminated by noise or include data unexplained by the forward model. Highly\nrobust smoothers are developed by modeling measurement errors using the\nStudent's t distribution, and outperform the recently proposed L1-Laplace\nsmoother in extreme situations with data containing 20% or more outliers.\n  A second special application we consider in detail allows tracking sudden\nchanges in the state. It is developed by modeling process noise using the\nStudent's t distribution, and the resulting smoother can track sudden changes\nin the state.\n  These features can be used separately or in tandem, and we present a general\nsmoother algorithm and open source implementation, together with convergence\nanalysis that covers a wide range of smoothers. A key ingredient of our\napproach is a technique to deal with the non-convexity of the Student's t loss\nfunction. Numerical results for linear and nonlinear models illustrate the\nperformance of the new smoothers for robust and tracking applications, as well\nas for mixed problems that have both types of features.\n", "versions": [{"version": "v1", "created": "Fri, 22 Mar 2013 11:36:19 GMT"}], "update_date": "2013-03-25", "authors_parsed": [["Aravkin", "Aleksandr Y.", ""], ["Burke", "James V.", ""], ["Pillonetto", "Gianluigi", ""]]}, {"id": "1303.5685", "submitter": "Andrew Lan", "authors": "Andrew S. Lan, Andrew E. Waters, Christoph Studer and Richard G.\n  Baraniuk", "title": "Sparse Factor Analysis for Learning and Content Analytics", "comments": null, "journal-ref": "Journal of Machine Learning Research, vol. 15, pp. 1959-2008,\n  June, 2014", "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a new model and algorithms for machine learning-based learning\nanalytics, which estimate a learner's knowledge of the concepts underlying a\ndomain, and content analytics, which estimate the relationships among a\ncollection of questions and those concepts. Our model represents the\nprobability that a learner provides the correct response to a question in terms\nof three factors: their understanding of a set of underlying concepts, the\nconcepts involved in each question, and each question's intrinsic difficulty.\nWe estimate these factors given the graded responses to a collection of\nquestions. The underlying estimation problem is ill-posed in general,\nespecially when only a subset of the questions are answered. The key\nobservation that enables a well-posed solution is the fact that typical\neducational domains of interest involve only a small number of key concepts.\nLeveraging this observation, we develop both a bi-convex maximum-likelihood and\na Bayesian solution to the resulting SPARse Factor Analysis (SPARFA) problem.\nWe also incorporate user-defined tags on questions to facilitate the\ninterpretability of the estimated factors. Experiments with synthetic and\nreal-world data demonstrate the efficacy of our approach. Finally, we make a\nconnection between SPARFA and noisy, binary-valued (1-bit) dictionary learning\nthat is of independent interest.\n", "versions": [{"version": "v1", "created": "Fri, 22 Mar 2013 18:44:56 GMT"}, {"version": "v2", "created": "Fri, 19 Jul 2013 20:33:18 GMT"}], "update_date": "2015-01-20", "authors_parsed": [["Lan", "Andrew S.", ""], ["Waters", "Andrew E.", ""], ["Studer", "Christoph", ""], ["Baraniuk", "Richard G.", ""]]}, {"id": "1303.5707", "submitter": "Carlo Berzuini", "authors": "Carlo Berzuini, David J. Spiegelhalter, Riccardo Bellazzi", "title": "Bayesian Networks Aplied to Therapy Monitoring", "comments": "Appears in Proceedings of the Seventh Conference on Uncertainty in\n  Artificial Intelligence (UAI1991)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1991-PG-35-43", "categories": "cs.AI stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a general Bayesian network model for application in a wide class\nof problems of therapy monitoring. We discuss the use of stochastic simulation\nas a computational approach to inference on the proposed class of models. As an\nillustration we present an application to the monitoring of cytotoxic\nchemotherapy in breast cancer.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2013 15:29:46 GMT"}], "update_date": "2013-03-26", "authors_parsed": [["Berzuini", "Carlo", ""], ["Spiegelhalter", "David J.", ""], ["Bellazzi", "Riccardo", ""]]}, {"id": "1303.5919", "submitter": "Akhil Jabbar Meerja", "authors": "M.Akhil Jabbar, B L Deekshatulu, Priti Chandra", "title": "Heart Disease Prediction System using Associative Classification and\n  Genetic Algorithm", "comments": "International Conference on Emerging Trends in Electrical,\n  Electronics and Communication Technologies-ICECIT, 2012", "journal-ref": "Vol no1 pp 183-192, Elsevier Dec 2012", "doi": null, "report-no": null, "categories": "cs.AI stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Associative classification is a recent and rewarding technique which\nintegrates association rule mining and classification to a model for prediction\nand achieves maximum accuracy. Associative classifiers are especially fit to\napplications where maximum accuracy is desired to a model for prediction. There\nare many domains such as medical where the maximum accuracy of the model is\ndesired. Heart disease is a single largest cause of death in developed\ncountries and one of the main contributors to disease burden in developing\ncountries. Mortality data from the registrar general of India shows that heart\ndisease are a major cause of death in India, and in Andhra Pradesh coronary\nheart disease cause about 30%of deaths in rural areas. Hence there is a need to\ndevelop a decision support system for predicting heart disease of a patient. In\nthis paper we propose efficient associative classification algorithm using\ngenetic approach for heart disease prediction. The main motivation for using\ngenetic algorithm in the discovery of high level prediction rules is that the\ndiscovered rules are highly comprehensible, having high predictive accuracy and\nof high interestingness values. Experimental Results show that most of the\nclassifier rules help in the best prediction of heart disease which even helps\ndoctors in their diagnosis decisions.\n", "versions": [{"version": "v1", "created": "Sun, 24 Mar 2013 07:18:50 GMT"}], "update_date": "2013-03-26", "authors_parsed": [["Jabbar", "M. Akhil", ""], ["Deekshatulu", "B L", ""], ["Chandra", "Priti", ""]]}, {"id": "1303.6042", "submitter": "Alexandre Janon", "authors": "Alexandre Janon (INRIA Grenoble Rh\\^one-Alpes / LJK Laboratoire Jean\n  Kuntzmann, - M\\'ethodes d'Analyse Stochastique des Codes et Traitements\n  Num\\'eriques, SAF)", "title": "Multifidelity variance reduction for pick-freeze Sobol index estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.AP stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many mathematical models involve input parameters, which are not precisely\nknown. Global sensitivity analysis aims to identify the parameters whose\nuncertainty has the largest impact on the variability of a quantity of interest\n(output of the model). One of the statistical tools used to quantify the\ninfluence of each input variable on the output is the Sobol sensitivity index,\nwhich can be estimated using a large sample of evaluations of the output. We\npropose a variance reduction technique, based on the availability of a fast\napproximation of the output, which can enable significant computational savings\nwhen the output is costly to evaluate.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2013 07:50:13 GMT"}], "update_date": "2013-03-26", "authors_parsed": [["Janon", "Alexandre", "", "INRIA Grenoble Rh\u00f4ne-Alpes / LJK Laboratoire Jean\n  Kuntzmann, - M\u00e9thodes d'Analyse Stochastique des Codes et Traitements\n  Num\u00e9riques, SAF"]]}, {"id": "1303.6152", "submitter": "Charles-Alban Deledalle", "authors": "Charles-Alban Deledalle (IMB), Lo\\\"ic Denis (LAHC), Florence Tupin\n  (LTCI)", "title": "Template matching with noisy patches: A contrast-invariant GLR test", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matching patches from a noisy image to atoms in a dictionary of patches is a\nkey ingredient to many techniques in image processing and computer vision. By\nrepresenting with a single atom all patches that are identical up to a\nradiometric transformation, dictionary size can be kept small, thereby\nretaining good computational efficiency. Identification of the atom in best\nmatch with a given noisy patch then requires a contrast-invariant criterion. In\nthe light of detection theory, we propose a new criterion that ensures contrast\ninvariance and robustness to noise. We discuss its theoretical grounding and\nassess its performance under Gaussian, gamma and Poisson noises.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2013 14:58:52 GMT"}], "update_date": "2013-03-26", "authors_parsed": [["Deledalle", "Charles-Alban", "", "IMB"], ["Denis", "Lo\u00efc", "", "LAHC"], ["Tupin", "Florence", "", "LTCI"]]}, {"id": "1303.6169", "submitter": "Tao Liu", "authors": "Tao Liu, Lauri Bazerman, Megan Pinkston, Amy Nunn, Aadia Rana, Curt G.\n  Beckwith", "title": "Co-Occurring HIV Risk Behaviors among Males Entering Jail", "comments": "0 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  This paper examines the pattern of HIV risk behaviors among male jail\ndetainees. From multivariate analyses of baseline data from an HIV intervention\nstudy of ours, we find that: (1) cocaine use, heroin use and multiple sexual\npartners; and (2) heavy drinking and marijuana are often co-occurring among\nthis population. From pairwise analyses, we find that (1) heroin and IDU (2)\nunprotected sexes with main, with non-main, and in last sexual encounter are\nmostly co-occurring. IDU is found to be associated with middle ages (30-40) and\nmultiple prior incarcerations, and multiple sex partners associated young males\nwith age <30, African American race, and low education. Our findings suggest\nthat efficient interventions to reduce HIV infection in this high-risk\npopulation may have to target on these behaviors simultaneously and be\ndemographically adapted.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2013 15:33:52 GMT"}, {"version": "v2", "created": "Thu, 4 Apr 2019 12:17:27 GMT"}], "update_date": "2019-04-05", "authors_parsed": [["Liu", "Tao", ""], ["Bazerman", "Lauri", ""], ["Pinkston", "Megan", ""], ["Nunn", "Amy", ""], ["Rana", "Aadia", ""], ["Beckwith", "Curt G.", ""]]}, {"id": "1303.6170", "submitter": "Brandon Jones", "authors": "Brandon Jones, Mark Campbell, Lang Tong", "title": "Maximum Likelihood Fusion of Stochastic Maps", "comments": "10 pages, 8 figures, submitted to IEEE Transactions on Signal\n  Processing on 24-March-2013", "journal-ref": null, "doi": "10.1109/TSP.2014.2304435", "report-no": null, "categories": "stat.AP cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The fusion of independently obtained stochastic maps by collaborating mobile\nagents is considered. The proposed approach includes two parts: matching of\nstochastic maps and maximum likelihood alignment. In particular, an affine\ninvariant hypergraph is constructed for each stochastic map, and a bipartite\nmatching via a linear program is used to establish landmark correspondence\nbetween stochastic maps. A maximum likelihood alignment procedure is proposed\nto determine rotation and translation between common landmarks in order to\nconstruct a global map within a common frame of reference. A main feature of\nthe proposed approach is its scalability with respect to the number of\nlandmarks: the matching step has polynomial complexity and the maximum\nlikelihood alignment is obtained in closed form. Experimental validation of the\nproposed fusion approach is performed using the Victoria Park benchmark\ndataset.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2013 15:34:26 GMT"}], "update_date": "2015-06-15", "authors_parsed": [["Jones", "Brandon", ""], ["Campbell", "Mark", ""], ["Tong", "Lang", ""]]}, {"id": "1303.6447", "submitter": "Alexandre Janon", "authors": "Fabrice Gamboa (UMR CNRS 5219), Alexandre Janon (INRIA Grenoble\n  Rh\\^one-Alpes / LJK Laboratoire Jean Kuntzmann, - M\\'ethodes d'Analyse\n  Stochastique des Codes et Traitements Num\\'eriques, SAF), Thierry Klein\n  (IMT), Agnes Lagnoux-Renaudie (IMT), Cl\\'ementine Prieur (INRIA Grenoble\n  Rh\\^one-Alpes / LJK Laboratoire Jean Kuntzmann, - M\\'ethodes d'Analyse\n  Stochastique des Codes et Traitements Num\\'eriques), Cl\\'ementine Prieur\n  (INRIA Grenoble Rh\\^one-Alpes / LJK Laboratoire Jean Kuntzmann, - M\\'ethodes\n  d'Analyse Stochastique des Codes et Traitements Num\\'eriques)", "title": "Statistical inference for Sobol pick freeze Monte Carlo method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many mathematical models involve input parameters, which are not precisely\nknown. Global sensitivity analysis aims to identify the parameters whose\nuncertainty has the largest impact on the variability of a quantity of interest\n(output of the model). One of the statistical tools used to quantify the\ninfluence of each input variable on the output is the Sobol sensitivity index.\nWe consider the statistical estimation of this index from a finite sample of\nmodel outputs. We study asymptotic and non-asymptotic properties of two\nestimators of Sobol indices. These properties are applied to significance tests\nand estimation by confidence intervals.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2013 12:03:48 GMT"}], "update_date": "2013-03-27", "authors_parsed": [["Gamboa", "Fabrice", "", "UMR CNRS 5219"], ["Janon", "Alexandre", "", "INRIA Grenoble\n  Rh\u00f4ne-Alpes / LJK Laboratoire Jean Kuntzmann, - M\u00e9thodes d'Analyse\n  Stochastique des Codes et Traitements Num\u00e9riques, SAF"], ["Klein", "Thierry", "", "IMT"], ["Lagnoux-Renaudie", "Agnes", "", "IMT"], ["Prieur", "Cl\u00e9mentine", "", "INRIA Grenoble\n  Rh\u00f4ne-Alpes / LJK Laboratoire Jean Kuntzmann, - M\u00e9thodes d'Analyse\n  Stochastique des Codes et Traitements Num\u00e9riques"], ["Prieur", "Cl\u00e9mentine", "", "INRIA Grenoble\n  Rh\u00f4ne-Alpes / LJK Laboratoire Jean Kuntzmann, - M\u00e9thodes d'Analyse\n  Stochastique des Codes et Traitements Num\u00e9riques"]]}, {"id": "1303.6451", "submitter": "Alexandre Janon", "authors": "Alexandre Janon (INRIA Grenoble Rh\\^one-Alpes / LJK Laboratoire Jean\n  Kuntzmann, - M\\'ethodes d'Analyse Stochastique des Codes et Traitements\n  Num\\'eriques), Thierry Klein (IMT), Agnes Lagnoux-Renaudie (IMT), Ma\\\"elle\n  Nodet (INRIA Grenoble Rh\\^one-Alpes / LJK Laboratoire Jean Kuntzmann),\n  Cl\\'ementine Prieur (INRIA Grenoble Rh\\^one-Alpes / LJK Laboratoire Jean\n  Kuntzmann, - M\\'ethodes d'Analyse Stochastique des Codes et Traitements\n  Num\\'eriques)", "title": "Asymptotic normality and efficiency of two Sobol index estimators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.AP stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many mathematical models involve input parameters, which are not precisely\nknown. Global sensitivity analysis aims to identify the parameters whose\nuncertainty has the largest impact on the variability of a quantity of interest\n(output of the model). One of the statistical tools used to quantify the\ninfluence of each input variable on the output is the Sobol sensitivity index.\nWe consider the statistical estimation of this index from a finite sample of\nmodel outputs: we present two estimators and state a central limit theorem for\neach. We show that one of these estimators has an optimal asymptotic variance.\nWe also generalize our results to the case where the true output is not\nobservable, and is replaced by a noisy version.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2013 12:20:03 GMT"}], "update_date": "2013-03-27", "authors_parsed": [["Janon", "Alexandre", "", "INRIA Grenoble Rh\u00f4ne-Alpes / LJK Laboratoire Jean\n  Kuntzmann, - M\u00e9thodes d'Analyse Stochastique des Codes et Traitements\n  Num\u00e9riques"], ["Klein", "Thierry", "", "IMT"], ["Lagnoux-Renaudie", "Agnes", "", "IMT"], ["Nodet", "Ma\u00eblle", "", "INRIA Grenoble Rh\u00f4ne-Alpes / LJK Laboratoire Jean Kuntzmann"], ["Prieur", "Cl\u00e9mentine", "", "INRIA Grenoble Rh\u00f4ne-Alpes / LJK Laboratoire Jean\n  Kuntzmann, - M\u00e9thodes d'Analyse Stochastique des Codes et Traitements\n  Num\u00e9riques"]]}, {"id": "1303.6525", "submitter": "John Kenneth Baillie", "authors": "David P Hall, Ian JC MacCormick, Alex T Phythian-Adams, Nina M\n  Rzechorzek, David Hope-Jones, Sorrel Cosens, Stewart Jackson, Matthew GD\n  Bates, David J Collier, David A Hume, Thomas Freeman, AA Roger Thompson, and\n  J Kenneth Baillie", "title": "Network analysis reveals distinct clinical syndromes underlying acute\n  mountain sickness", "comments": null, "journal-ref": null, "doi": "10.1371/journal.pone.0081229", "report-no": null, "categories": "q-bio.QM stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Acute mountain sickness (AMS) is a common problem among visitors at high\naltitude, and may progress to life-threatening pulmonary and cerebral oedema in\na minority of cases. International consensus defines AMS as a constellation of\nsubjective, non-specific symptoms. Specifically, headache, sleep disturbance,\nfatigue and dizziness are given equal diagnostic weighting. Different\npathophysiological mechanisms are now thought to underlie headache and sleep\ndisturbance during acute exposure to high altitude. Hence, these symptoms may\nnot belong together as a single syndrome. Using a novel visual analogue scale\n(VAS), we sought to undertake a systematic exploration of the symptomatology of\nAMS using an unbiased, data-driven approach originally designed for analysis of\ngene expression. Symptom scores were collected from 293 subjects during 1110\nsubject-days at altitudes between 3650m and 5200m on Apex expeditions to\nBolivia and Kilimanjaro. Three distinct patterns of symptoms were consistently\nidentified. Although fatigue is a ubiquitous finding, sleep disturbance and\nheadache are each commonly reported without the other. The commonest pattern of\nsymptoms was sleep disturbance and fatigue, with little or no headache. In\nsubjects reporting severe headache, 40% did not report sleep disturbance. Sleep\ndisturbance correlates poorly with other symptoms of AMS (Pearson r = 0.31 vs\nheadache). These results challenge the accepted paradigm that AMS is a single\ndisease process and describe at least two distinct syndromes following acute\nascent to high altitude. This approach to analysing symptom patterns has\npotential utility in other clinical syndromes.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2013 15:21:11 GMT"}], "update_date": "2014-03-05", "authors_parsed": [["Hall", "David P", ""], ["MacCormick", "Ian JC", ""], ["Phythian-Adams", "Alex T", ""], ["Rzechorzek", "Nina M", ""], ["Hope-Jones", "David", ""], ["Cosens", "Sorrel", ""], ["Jackson", "Stewart", ""], ["Bates", "Matthew GD", ""], ["Collier", "David J", ""], ["Hume", "David A", ""], ["Freeman", "Thomas", ""], ["Thompson", "AA Roger", ""], ["Baillie", "J Kenneth", ""]]}, {"id": "1303.6686", "submitter": "Satyam Mukherjee", "authors": "Satyam Mukherjee", "title": "Individual Performance and Leader's Laterality in Interactive Contests", "comments": "3 Figures, 6 Tables and 17 pages, Accepted for Publication in\n  Laterality: Asymmetries of Body, Brain and Cognition", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Left-handedness is known to provide an intrinsic and tactical advantage at\ntop level in many sports involving interactive contests. Again, most of the\nrenowned leaders of the world are known to have been left-handed. Leadership\nplays an important role in politics, sports and mentorship. In this paper we\nshow that Cricket captains who bat left-handed have a strategic advantage over\nthe right-handed captains in One Day International (ODI) and Test matches. The\npresent study involving 46 left-handed captains and 148 right-handed captains\nin ODI matches, reveal a strong relation between leader's laterality and\nteam-member performance, demonstrating the critical importance of\nleft-handedness and successful leadership. The odds for superior batting\nperformance in an ODI match under left-handed captains are 89% higher than the\nodds under right-handed captains. Our study shows that left-handed captains are\nmore successful in extracting superior performance from the batsmen and bowlers\nin ODI and Test matches; perhaps indicating left-handed leaders are better\nmotivators as leaders when compared to right-handed captains.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2013 22:31:58 GMT"}, {"version": "v2", "created": "Fri, 10 Oct 2014 20:49:25 GMT"}, {"version": "v3", "created": "Thu, 9 Jun 2016 10:59:44 GMT"}], "update_date": "2016-06-10", "authors_parsed": [["Mukherjee", "Satyam", ""]]}, {"id": "1303.6700", "submitter": "Tatiana Tatarinova", "authors": "Tatiana Tatarinova, Michael Neely, Jay Bartroff, Michael van Guilder,\n  Walter Yamada, David Bayard, Roger Jelliffe, Robert Leary, Alyona Chubatiuk\n  and Alan Schumitzky", "title": "Two General Methods for Population Pharmacokinetic Modeling:\n  Non-Parametric Adaptive Grid and Non-Parametric Bayesian", "comments": null, "journal-ref": "Tatarinova et al, Journal of Pharmacokinetics and\n  Pharmacodynamics, 2013, vol. 40 no 1", "doi": "10.1007/s10928-013-9302-8", "report-no": null, "categories": "q-bio.QM q-bio.GN stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Population pharmacokinetic (PK) modeling methods can be statistically\nclassified as either parametric or nonparametric (NP). Each classification can\nbe divided into maximum likelihood (ML) or Bayesian (B) approaches. In this\npaper we discuss the nonparametric case using both maximum likelihood and\nBayesian approaches. We present two nonparametric methods for estimating the\nunknown joint population distribution of model parameter values in a\npharmacokinetic/pharmacodynamic (PK/PD) dataset. The first method is the NP\nAdaptive Grid (NPAG). The second is the NP Bayesian (NPB) algorithm with a\nstick-breaking process to construct a Dirichlet prior. Our objective is to\ncompare the performance of these two methods using a simulated PK/PD dataset.\nOur results showed excellent performance of NPAG and NPB in a realistically\nsimulated PK study. This simulation allowed us to have benchmarks in the form\nof the true population parameters to compare with the estimates produced by the\ntwo methods, while incorporating challenges like unbalanced sample times and\nsample numbers as well as the ability to include the covariate of patient\nweight. We conclude that both NPML and NPB can be used in realistic PK/PD\npopulation analysis problems. The advantages of one versus the other are\ndiscussed in the paper. NPAG and NPB are implemented in R and freely available\nfor download within the Pmetrics package from www.lapk.org.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2013 23:04:41 GMT"}], "update_date": "2013-03-29", "authors_parsed": [["Tatarinova", "Tatiana", ""], ["Neely", "Michael", ""], ["Bartroff", "Jay", ""], ["van Guilder", "Michael", ""], ["Yamada", "Walter", ""], ["Bayard", "David", ""], ["Jelliffe", "Roger", ""], ["Leary", "Robert", ""], ["Chubatiuk", "Alyona", ""], ["Schumitzky", "Alan", ""]]}, {"id": "1303.6765", "submitter": "Martin \\v{S}m\\'id", "authors": "Martin \\v{S}m\\'id", "title": "Zero Intelligence Models of the Continuous Double Auction: Econometrics,\n  Empirical Evidence and Generalization", "comments": "This is yet previous version of arXiv:1504.05714", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the paper, a statistical procedure for estimating the parameters of zero\nintelligence models by means of tick-by-tick quote (L1) data is proposed. A\nlarge class of existing zero intelligence models is reviewed. It is shown that\nall those models fail to describe the actual behavior of limit order books\nclose to the ask price. A generalized model, accommodating the discrepancies\nfound, is proposed and shown to give significant results for L1 data from three\nUS electronic markets. It is also demonstrated that the generalized model\npreforms significantly better than the reviewed models.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 08:43:51 GMT"}, {"version": "v2", "created": "Fri, 19 Sep 2014 06:25:41 GMT"}, {"version": "v3", "created": "Mon, 29 May 2017 10:37:04 GMT"}, {"version": "v4", "created": "Wed, 7 Mar 2018 07:20:44 GMT"}], "update_date": "2018-03-08", "authors_parsed": [["\u0160m\u00edd", "Martin", ""]]}, {"id": "1303.6784", "submitter": "Richard Clegg", "authors": "Richard G. Clegg and Raul Landa and Hamed Haddadi and M. Rio", "title": "Measuring the likelihood of models for network evolution", "comments": "Published in INFOCOM NetSciCom Workshop 2009.\n  http://dl.acm.org/citation.cfm?id=1719896", "journal-ref": "INFOCOM NetSciCom Workshop, Pages 272-277 2009", "doi": null, "report-no": null, "categories": "stat.AP cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many researchers have hypothesised models which explain the evolution of the\ntopology of a target network. The framework described in this paper gives the\nlikelihood that the target network arose from the hypothesised model. This\nallows rival hypothesised models to be compared for their ability to explain\nthe target network. A null model (of random evolution) is proposed as a\nbaseline for comparison. The framework also considers models made from linear\ncombinations of model components. A method is given for the automatic\noptimisation of component weights. The framework is tested on simulated\nnetworks with known parameters and also on real data.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 10:51:53 GMT"}], "update_date": "2013-03-28", "authors_parsed": [["Clegg", "Richard G.", ""], ["Landa", "Raul", ""], ["Haddadi", "Hamed", ""], ["Rio", "M.", ""]]}, {"id": "1303.6992", "submitter": "William Kleiber", "authors": "William Kleiber, Stephan R. Sain, Matthew J. Heaton, Michael\n  Wiltberger, C. Shane Reese, Derek Bingham", "title": "Parameter tuning for a multi-fidelity dynamical model of the\n  magnetosphere", "comments": "Published in at http://dx.doi.org/10.1214/13-AOAS651 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2013, Vol. 7, No. 3, 1286-1310", "doi": "10.1214/13-AOAS651", "report-no": "IMS-AOAS-AOAS651", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Geomagnetic storms play a critical role in space weather physics with the\npotential for far reaching economic impacts including power grid outages, air\ntraffic rerouting, satellite damage and GPS disruption. The LFM-MIX is a\nstate-of-the-art coupled magnetospheric-ionospheric model capable of simulating\ngeomagnetic storms. Imbedded in this model are physical equations for turning\nthe magnetohydrodynamic state parameters into energy and flux of electrons\nentering the ionosphere, involving a set of input parameters. The exact values\nof these input parameters in the model are unknown, and we seek to quantify the\nuncertainty about these parameters when model output is compared to\nobservations. The model is available at different fidelities: a lower fidelity\nwhich is faster to run, and a higher fidelity but more computationally intense\nversion. Model output and observational data are large spatiotemporal systems;\nthe traditional design and analysis of computer experiments is unable to cope\nwith such large data sets that involve multiple fidelities of model output. We\ndevelop an approach to this inverse problem for large spatiotemporal data sets\nthat incorporates two different versions of the physical model. After an\ninitial design, we propose a sequential design based on expected improvement.\nFor the LFM-MIX, the additional run suggested by expected improvement\ndiminishes posterior uncertainty by ruling out a posterior mode and shrinking\nthe width of the posterior distribution. We also illustrate our approach using\nthe Lorenz `96 system of equations for a simplified atmosphere, using known\ninput parameters. For the Lorenz `96 system, after performing sequential runs\nbased on expected improvement, the posterior mode converges to the true value\nand the posterior variability is reduced.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 22:09:56 GMT"}, {"version": "v2", "created": "Thu, 5 Dec 2013 09:17:02 GMT"}], "update_date": "2013-12-06", "authors_parsed": [["Kleiber", "William", ""], ["Sain", "Stephan R.", ""], ["Heaton", "Matthew J.", ""], ["Wiltberger", "Michael", ""], ["Reese", "C. Shane", ""], ["Bingham", "Derek", ""]]}, {"id": "1303.7002", "submitter": "Giovanni Montana", "authors": "Christopher Minas, Edward Curry and Giovanni Montana", "title": "A Distance-Based Test of Association Between Paired Heterogeneous\n  Genomic Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to rapid technological advances, a wide range of different measurements\ncan be obtained from a given biological sample including single nucleotide\npolymorphisms, copy number variation, gene expression levels, DNA methylation\nand proteomic profiles. Each of these distinct measurements provides the means\nto characterize a certain aspect of biological diversity, and a fundamental\nproblem of broad interest concerns the discovery of shared patterns of\nvariation across different data types. Such data types are heterogeneous in the\nsense that they represent measurements taken at very different scales or\ndescribed by very different data structures. We propose a distance-based\nstatistical test, the generalized RV (GRV) test, to assess whether there is a\ncommon and non-random pattern of variability between paired biological\nmeasurements obtained from the same random sample. The measurements enter the\ntest through distance measures which can be chosen to capture particular\naspects of the data. An approximate null distribution is proposed to compute\np-values in closed-form and without the need to perform costly Monte Carlo\npermutation procedures. Compared to the classical Mantel test for association\nbetween distance matrices, the GRV test has been found to be more powerful in a\nnumber of simulation settings. We also report on an application of the GRV test\nto detect biological pathways in which genetic variability is associated to\nvariation in gene expression levels in ovarian cancer samples, and present\nresults obtained from two independent cohorts.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 23:00:49 GMT"}], "update_date": "2013-03-29", "authors_parsed": [["Minas", "Christopher", ""], ["Curry", "Edward", ""], ["Montana", "Giovanni", ""]]}, {"id": "1303.7050", "submitter": "Victor Chernozhukov", "authors": "Victor Chernozhukov, Christian Hansen", "title": "Quantile Models with Endogeneity", "comments": "32 pages", "journal-ref": "Annual Review of Economics, vol 5, 2013", "doi": "10.1146/annurev-economics-080511-110952", "report-no": null, "categories": "stat.AP econ.EM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we review quantile models with endogeneity. We focus on\nmodels that achieve identification through the use of instrumental variables\nand discuss conditions under which partial and point identification are\nobtained. We discuss key conditions, which include monotonicity and\nfull-rank-type conditions, in detail. In providing this review, we update the\nidentification results of Chernozhukov and Hansen (2005, Econometrica). We\nillustrate the modeling assumptions through economically motivated examples. We\nalso briefly review the literature on estimation and inference.\n  Key Words: identification, treatment effects, structural models, instrumental\nvariables\n", "versions": [{"version": "v1", "created": "Thu, 28 Mar 2013 06:32:37 GMT"}], "update_date": "2017-10-03", "authors_parsed": [["Chernozhukov", "Victor", ""], ["Hansen", "Christian", ""]]}, {"id": "1303.7408", "submitter": "Guillaume Belanger", "authors": "G. Belanger", "title": "On Detecting Transient Phenomena", "comments": "Typos in published version are corrected", "journal-ref": "2013, ApJ, 733, 66", "doi": "10.1088/0004-637X/773/1/66", "report-no": null, "categories": "astro-ph.IM astro-ph.HE stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transient phenomena are interesting and potentially highly revealing of\ndetails about the processes under observation and study that could otherwise go\nunnoticed. It is therefore important to maximize the sensitivity of the method\nused to identify such events. In this article, we present a general procedure\nbased on the use of the likelihood function for identifying transients which is\nparticularly suited for real-time applications because it requires no grouping\nor pre-processing of the data. The method makes use of all the information that\nis available in the data throughout the statistical decision-making process,\nand is suitable for a wide range of applications. Here we consider those most\ncommon in astrophysics, which involve searching for transient sources, events\nor features in images, time series, energy spectra, and power spectra, and\ndemonstrate the use of the method in the case of a weak X-ray flare in a time\nseries and a short-lived quasi-periodic oscillation in a power spectrum. We\nderive a fit statistic that is ideal for fitting arbitrarily shaped models to a\npower density distribution, which is of general interest in all applications\ninvolving periodogram analysis.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2013 14:32:02 GMT"}, {"version": "v2", "created": "Mon, 3 Jun 2013 20:19:25 GMT"}, {"version": "v3", "created": "Fri, 27 Sep 2013 09:04:49 GMT"}, {"version": "v4", "created": "Sat, 2 Dec 2017 18:13:37 GMT"}], "update_date": "2017-12-05", "authors_parsed": [["Belanger", "G.", ""]]}]