[{"id": "1007.0562", "submitter": "Alhaji Cherif", "authors": "Alhaji Cherif, Kamal Barley", "title": "Cliophysics: Socio-political Reliability Theory, Polity Duration and\n  African Political (In)stabilities", "comments": "4 pages, 3 figures, 1 table", "journal-ref": null, "doi": "10.1371/journal.pone.0015169", "report-no": null, "categories": "physics.soc-ph physics.data-an stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantification of historical sociological processes have recently gained\nattention among theoreticians in the effort of providing a solid theoretical\nunderstanding of the behaviors and regularities present in sociopolitical\ndynamics. Here we present a reliability theory of polity processes with\nemphases on individual political dynamics of African countries. We found that\nthe structural properties of polity failure rates successfully capture the risk\nof political vulnerability and instabilities in which 87.50%, 75%, 71.43%, and\n0% of the countries with monotonically increasing, unimodal, U-shaped and\nmonotonically decreasing polity failure rates, respectively, have high level of\nstate fragility indices. The quasi-U-shape relationship between average polity\nduration and regime types corroborates historical precedents and explains the\nstability of the autocracies and democracies.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jul 2010 15:27:23 GMT"}, {"version": "v2", "created": "Tue, 20 Jul 2010 01:13:46 GMT"}], "update_date": "2015-05-19", "authors_parsed": [["Cherif", "Alhaji", ""], ["Barley", "Kamal", ""]]}, {"id": "1007.1140", "submitter": "Joerg Dubiel", "authors": "Joerg Dubiel", "title": "Promoting target models by potential measures", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Direct marketers use target models in order to minimize the spreading loss of\nsales efforts. The application of target models has become more widespread with\nthe increasing range of sales efforts. Target models are relevant for offline\nmarketers sending printed mails as well as for online marketers who have to\navoid intensity. However business has retained its evaluation since the late\n1960s. Marketing decision-makers still prefer managerial performance measures\nof the economic benefit of a target model. Such benefit measures have merits\nbut are unfavorable in other respects: They constrain leadership by stretched\ntargets since they do not tell us how good a model could be. And they require a\npredisposed decision regarding cut-offs. Since this is based on earlier\noptimizations it virtually means sticking to traditions. Hence it is\nrecommended also to use cut-off invariant and potential oriented performance\nmeasures for the model evaluation. This has three advantages: sustaining\nstretched targets, identifying improvement potential and sup-porting an\nautomated evaluation of many different models. This article introduces a\nconcrete po-tential measure and shows how to calculate it. It is especially\nrecommended for direct marketing businesses churning out many specific target\nmodels at short intervals.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2010 14:13:29 GMT"}], "update_date": "2010-07-08", "authors_parsed": [["Dubiel", "Joerg", ""]]}, {"id": "1007.1410", "submitter": "Etienne Birmel\\'e", "authors": "Etienne Birmele", "title": "Detecting local network motifs", "comments": "25 pages, 4 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP math.PR physics.soc-ph q-bio.MN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Studying the topology of so-called real networks, that is networks obtained\nfrom sociological or biological data for instance, has become a major field of\ninterest in the last decade. One way to deal with it is to consider that\nnetworks are built from small functional units called motifs, which can be\nfound by looking for small subgraphs whose numbers of occurrences in the whole\nnetwork are surprisingly high. In this article, we propose to define motifs\nthrough a local overrepresentation in the network and develop a statistic to\ndetect them without relying on simulations. We then illustrate the performance\nof our procedure on simulated and real data, recovering already known\nbiologically relevant motifs. Moreover, we explain how our method gives some\ninformation about the respective roles of the vertices in a motif.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2010 16:08:13 GMT"}], "update_date": "2010-07-27", "authors_parsed": [["Birmele", "Etienne", ""]]}, {"id": "1007.1880", "submitter": "Chuan Yin", "authors": "August Lau and Chuan Yin", "title": "L0+L1+L2 mixed optimization: a geometric approach to seismic imaging and\n  inversion using concepts in topology and semigroup", "comments": "8 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The mathematical interpretation of L0, L1 and L2 is needed to understand how\nwe should use these norms for optimization problems. The L0 norm is\ncombinatorics which is counting certain properties of an object or an operator.\nThis is the least amplitude dependent norm since it is counted regardless of\nthe magnitude. The L1 norm could be interpreted as minimal geometric\ndescription. It is somewhat sensitive to amplitude information. In geophysics,\nit has been used to edit outliers like spikes in seismic data. This is a good\napplication of L1 norm. The L2 norm could be interpreted as the numerically\nsimplest solution to fitting data with a differential equation. It is very\nsensitive to amplitude information. Previous application includes least square\nmigration. In this paper, we will show how to combine the usage of L0 and L1\nand L2. We will not be optimizing the 3 norms simultaneously but will go from\none norm to the next norm to optimize the data before the final migration.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2010 12:07:37 GMT"}], "update_date": "2010-07-13", "authors_parsed": [["Lau", "August", ""], ["Yin", "Chuan", ""]]}, {"id": "1007.3017", "submitter": "Sherry Towers", "authors": "Sherry Towers, Zhilan Feng, Nathaniel Hupert", "title": "Short-term heterologous immunity after severe influenza A outbreaks", "comments": "9 double spaced pages, 1 figure, and supplementary material\n  (Materials and Methods)", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE q-bio.QM stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional wisdom holds that influenza A and B are such genetically\ndissimilar viruses that infection with one cannot confer cross-immunity to the\nother. However, our examination of the records of the past 25 influenza seasons\nin the U.S. reveals that almost every time there is an early and severe\ninfluenza A outbreak, the annual influenza B epidemic is almost entirely\nsuppressed (and is never suppressed otherwise). Temporary broad-spectrum (aka\n\"heterologous\") immunity in the aftermath of influenza infection is the most\ndirect explanation for this phenomenon. We find a remarkably weak degree of\ntemporary cross-immunity is needed to explain these patterns, and that indeed\ninfluenza B provides an ideal setting for the observation of heterologous\nimmune effects outside of the carefully controlled environment of a laboratory.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jul 2010 16:01:41 GMT"}], "update_date": "2010-07-20", "authors_parsed": [["Towers", "Sherry", ""], ["Feng", "Zhilan", ""], ["Hupert", "Nathaniel", ""]]}, {"id": "1007.3207", "submitter": "Rossi Hassad", "authors": "Rossi A. Hassad", "title": "Reform-Oriented Teaching of Introductory Statistics in the Health,\n  Social and Behavioral Sciences-Historical Context and Rationale", "comments": "Refereed Journal Publication", "journal-ref": "International Journal of Social Sciences v4 n2 p132-137 2009", "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is widespread emphasis on reform in the teaching of introductory\nstatistics at the college level. Underpinning this reform is a consensus among\neducators and practitioners that traditional curricular materials and\npedagogical strategies have not been effective in promoting statistical\nliteracy, a competency that is becoming increasingly necessary for effective\ndecision-making and evidence-based practice. This paper explains the historical\ncontext of, and rationale for reform-oriented teaching of introductory\nstatistics (at the college level) in the health, social and behavioral sciences\n(evidence-based disciplines). A firm understanding and appreciation of the\nbasis for change in pedagogical approach is important, in order to facilitate\ncommitment to reform, consensus building on appropriate strategies, and\nadoption and maintenance of best practices. In essence, reform-oriented\npedagogy, in this context, is a function of the interaction among content,\npedagogy, technology, and assessment. The challenge is to create an appropriate\nbalance among these domains.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2010 16:50:15 GMT"}], "update_date": "2010-07-20", "authors_parsed": [["Hassad", "Rossi A.", ""]]}, {"id": "1007.3219", "submitter": "Rossi Hassad", "authors": "Rossi A. Hassad", "title": "Development and Validation of a Scale for Measuring Instructors'\n  Attitudes toward Concept-Based or Reform-Oriented Teaching of Introductory\n  Statistics in the Health and Behavioral Sciences", "comments": "Doctoral Dissertation (PhD)- 2007;\n  http://gradworks.umi.com/32/81/3281778.html - ProQuest (2007)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite more than a decade of reform efforts, students continue to experience\ndifficulty understanding and applying statistical concepts. The predominant\nfocus of reform has been on content, pedagogy, technology and assessment, with\nlittle attention to instructor characteristics. However, there is strong\ntheoretical and empirical evidence that instructors' attitudes impact the\nquality of teaching and learning. The objective of this study was to develop\nand initially validate a scale to measure instructors' attitudes toward\nreform-oriented (or concept-based) teaching of introductory statistics in the\nhealth and behavioral sciences, at the tertiary level. This scale will be\nreferred to as FATS (Faculty Attitudes Toward Statistics). Data were obtained\nfrom 227 instructors (USA and international), and analyzed using factor\nanalysis, multidimensional scaling and hierarchical cluster analysis. The\noverall scale consists of five sub-scales with a total of 25 items, and an\noverall alpha of 0.89. Construct validity was established. Specifically, the\noverall scale, and subscales (except perceived difficulty) plausibly\ndifferentiated between low-reform and high-reform practice instructors.\nStatistically significant differences in attitude were observed with respect to\nage, but not gender, employment status, membership status in professional\norganizations, ethnicity, highest academic qualification, and degree\nconcentration. This scale can be considered a reliable and valid measure of\ninstructors' attitudes toward reform-oriented (concept-based or constructivist)\nteaching of introductory statistics in the health and behavioral sciences at\nthe tertiary level. These five dimensions influence instructors' attitudes.\nAdditional studies are required to confirm these structural and psychometric\nproperties.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2010 17:33:31 GMT"}], "update_date": "2010-07-20", "authors_parsed": [["Hassad", "Rossi A.", ""]]}, {"id": "1007.3225", "submitter": "Athanasios Rakitzis", "authors": "Demetrios L. Antzoulakos and Athanasios C. Rakitzis", "title": "New Sensitizing Runs Rules for Shewhart type Control Charts with\n  Applications", "comments": "6 pages, 5 Tables, Presented in the 7th Hellenic-European Conference\n  on Computer Mathematics and its Applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The most popular tool used in the industry for monitoring a process is the\nShewhart control chart. The major disadvantage of the Shewhart control chart is\nthat it is not very efficient in detecting small process average shifts. To\nincrease the sensitivity of Shewhart control charts to small shifts additional\nsupplementary runs rules has been suggested. In this paper we introduce and\nstudy the modified r/m control chart which has an improved sensitivity to small\nand moderate process average shifts as compared with the standard Shewhart\nX-bar control chart and corresponding control charts proposed recently in the\nliterature.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2010 18:03:45 GMT"}], "update_date": "2010-07-20", "authors_parsed": [["Antzoulakos", "Demetrios L.", ""], ["Rakitzis", "Athanasios C.", ""]]}, {"id": "1007.3230", "submitter": "Sean Simpson", "authors": "Sean L. Simpson, Satoru Hayasaka, and Paul J. Laurienti", "title": "Exponential Random Graph Modeling for Complex Brain Networks", "comments": null, "journal-ref": "PLoS ONE 2011: 6(5), e20039 (doi:10.1371/journal.pone.0020039)", "doi": "10.1371/journal.pone.0020039", "report-no": null, "categories": "stat.AP q-bio.NC q-bio.QM stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exponential random graph models (ERGMs), also known as p* models, have been\nutilized extensively in the social science literature to study complex networks\nand how their global structure depends on underlying structural components.\nHowever, the literature on their use in biological networks (especially brain\nnetworks) has remained sparse. Descriptive models based on a specific feature\nof the graph (clustering coefficient, degree distribution, etc.) have dominated\nconnectivity research in neuroscience. Corresponding generative models have\nbeen developed to reproduce one of these features. However, the complexity\ninherent in whole-brain network data necessitates the development and use of\ntools that allow the systematic exploration of several features simultaneously\nand how they interact to form the global network architecture. ERGMs provide a\nstatistically principled approach to the assessment of how a set of interacting\nlocal brain network features gives rise to the global structure. We illustrate\nthe utility of ERGMs for modeling, analyzing, and simulating complex\nwhole-brain networks with network data from normal subjects. We also provide a\nfoundation for the selection of important local features through the\nimplementation and assessment of three selection approaches: a traditional\np-value based backward selection approach, an information criterion approach\n(AIC), and a graphical goodness of fit (GOF) approach. The graphical GOF\napproach serves as the best method given the scientific interest in being able\nto capture and reproduce the structure of fitted brain networks.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2010 18:16:26 GMT"}, {"version": "v2", "created": "Wed, 1 Jun 2011 20:31:29 GMT"}], "update_date": "2015-05-19", "authors_parsed": [["Simpson", "Sean L.", ""], ["Hayasaka", "Satoru", ""], ["Laurienti", "Paul J.", ""]]}, {"id": "1007.3424", "submitter": "Or Zuk", "authors": "Amnon Amir and Or Zuk", "title": "Bacterial Community Reconstruction Using A Single Sequencing Reaction", "comments": "28 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.IT math.IT q-bio.QM stat.AP stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bacteria are the unseen majority on our planet, with millions of species and\ncomprising most of the living protoplasm. While current methods enable in-depth\nstudy of a small number of communities, a simple tool for breadth studies of\nbacterial population composition in a large number of samples is lacking. We\npropose a novel approach for reconstruction of the composition of an unknown\nmixture of bacteria using a single Sanger-sequencing reaction of the mixture.\nThis method is based on compressive sensing theory, which deals with\nreconstruction of a sparse signal using a small number of measurements.\nUtilizing the fact that in many cases each bacterial community is comprised of\na small subset of the known bacterial species, we show the feasibility of this\napproach for determining the composition of a bacterial mixture. Using\nsimulations, we show that sequencing a few hundred base-pairs of the 16S rRNA\ngene sequence may provide enough information for reconstruction of mixtures\ncontaining tens of species, out of tens of thousands, even in the presence of\nrealistic measurement noise. Finally, we show initial promising results when\napplying our method for the reconstruction of a toy experimental mixture with\nfive species. Our approach may have a potential for a practical and efficient\nway for identifying bacterial species compositions in biological samples.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2010 13:47:09 GMT"}], "update_date": "2010-07-21", "authors_parsed": [["Amir", "Amnon", ""], ["Zuk", "Or", ""]]}, {"id": "1007.3490", "submitter": "Farzad Farkhooi", "authors": "Farzad Farkhooi and Eilif Muller and Martin P. Nawrot", "title": "Adaptation Reduces Variability of the Neuronal Population Code", "comments": "4 pages, 2 figures", "journal-ref": "Phys. Rev. E 83, 050905 (2011)", "doi": "10.1103/PhysRevE.83.050905", "report-no": null, "categories": "physics.bio-ph math.PR q-bio.NC stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequences of events in noise-driven excitable systems with slow variables\noften show serial correlations among their intervals of events. Here, we employ\na master equation for general non-renewal processes to calculate the interval\nand count statistics of superimposed processes governed by a slow adaptation\nvariable. For an ensemble of spike-frequency adapting neurons this results in\nthe regularization of the population activity and an enhanced post-synaptic\nsignal decoding. We confirm our theoretical results in a population of cortical\nneurons.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2010 19:42:34 GMT"}, {"version": "v2", "created": "Mon, 7 Feb 2011 16:29:14 GMT"}], "update_date": "2011-05-23", "authors_parsed": [["Farkhooi", "Farzad", ""], ["Muller", "Eilif", ""], ["Nawrot", "Martin P.", ""]]}, {"id": "1007.3654", "submitter": "Rossi Hassad", "authors": "Rossi A. Hassad", "title": "Development and Validation of a Teaching Practice Scale (TISS) for\n  Instructors of Introductory Statistics at the College Level", "comments": "8 Pages, Refereed Conference Presentation & Publication", "journal-ref": "International Association for Statistical Education (IASE)\n  Satellite Conference (Durban, South Africa, Aug 14-15, 2009)", "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study examined the teaching practices of 227 college instructors of\nintroductory statistics (from the health and behavioral sciences). Using\nprimarily multidimensional scaling (MDS) techniques, a two-dimensional, 10-item\nteaching practice scale, TISS (Teaching of Introductory Statistics Scale), was\ndeveloped and validated. The two dimensions (subscales) were characterized as\nconstructivist, and behaviorist, and are orthogonal to each other. Criterion\nvalidity of this scale was established in relation to instructors' attitude\ntoward teaching, and acceptable levels of reliability were obtained. A\nsignificantly higher level of behaviorist practice (less reform-oriented) was\nreported by instructors from the USA, and instructors with academic degrees in\nmathematics and engineering. This new scale (TISS) will allow us to empirically\nassess and describe the pedagogical approach (teaching practice) of instructors\nof introductory statistics. Further research is required in order to be\nconclusive about the structural and psychometric properties of this scale.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2010 16:30:36 GMT"}], "update_date": "2010-07-22", "authors_parsed": [["Hassad", "Rossi A.", ""]]}, {"id": "1007.4532", "submitter": "Christopher Yau", "authors": "Christopher Yau, Christopher C. Holmes", "title": "A decision-theoretic approach for segmental classification", "comments": "Published in at http://dx.doi.org/10.1214/13-AOAS657 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2013, Vol. 7, No. 3, 1814-1835", "doi": "10.1214/13-AOAS657", "report-no": "IMS-AOAS-AOAS657", "categories": "stat.ME stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is concerned with statistical methods for the segmental\nclassification of linear sequence data where the task is to segment and\nclassify the data according to an underlying hidden discrete state sequence.\nSuch analysis is commonplace in the empirical sciences including genomics,\nfinance and speech processing. In particular, we are interested in answering\nthe following question: given data $y$ and a statistical model $\\pi(x,y)$ of\nthe hidden states $x$, what should we report as the prediction $\\hat{x}$ under\nthe posterior distribution $\\pi (x|y)$? That is, how should you make a\nprediction of the underlying states? We demonstrate that traditional approaches\nsuch as reporting the most probable state sequence or most probable set of\nmarginal predictions can give undesirable classification artefacts and offer\nlimited control over the properties of the prediction. We propose a decision\ntheoretic approach using a novel class of Markov loss functions and report\n$\\hat{x}$ via the principle of minimum expected loss (maximum expected\nutility). We demonstrate that the sequence of minimum expected loss under the\nMarkov loss function can be enumerated exactly using dynamic programming\nmethods and that it offers flexibility and performance improvements over\nexisting techniques. The result is generic and applicable to any probabilistic\nmodel on a sequence, such as Hidden Markov models, change point or product\npartition models.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2010 19:03:11 GMT"}, {"version": "v2", "created": "Fri, 29 Nov 2013 08:43:45 GMT"}], "update_date": "2015-05-05", "authors_parsed": [["Yau", "Christopher", ""], ["Holmes", "Christopher C.", ""]]}, {"id": "1007.4603", "submitter": "Yanan Fan Dr", "authors": "Gareth W.Peters, Ido Nevat, Scott A. Sisson, Yanan Fan and Jinhong\n  Yuan", "title": "Bayesian Symbol Detection in Wireless Relay Networks via Likelihood-Free\n  Inference", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2010.2052457", "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a general stochastic model developed for a class of\ncooperative wireless relay networks, in which imperfect knowledge of the\nchannel state information at the destination node is assumed. The framework\nincorporates multiple relay nodes operating under general known non-linear\nprocessing functions. When a non-linear relay function is considered, the\nlikelihood function is generally intractable resulting in the maximum\nlikelihood and the maximum a posteriori detectors not admitting closed form\nsolutions. We illustrate our methodology to overcome this intractability under\nthe example of a popular optimal non-linear relay function choice and\ndemonstrate how our algorithms are capable of solving the previously\nintractable detection problem. Overcoming this intractability involves\ndevelopment of specialised Bayesian models. We develop three novel algorithms\nto perform detection for this Bayesian model, these include a Markov chain\nMonte Carlo Approximate Bayesian Computation (MCMC-ABC) approach; an Auxiliary\nVariable MCMC (MCMC-AV) approach; and a Suboptimal Exhaustive Search Zero\nForcing (SES-ZF) approach. Finally, numerical examples comparing the symbol\nerror rate (SER) performance versus signal to noise ratio (SNR) of the three\ndetection algorithms are studied in simulated examples.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2010 01:41:21 GMT"}], "update_date": "2015-05-19", "authors_parsed": [["Peters", "Gareth W.", ""], ["Nevat", "Ido", ""], ["Sisson", "Scott A.", ""], ["Fan", "Yanan", ""], ["Yuan", "Jinhong", ""]]}, {"id": "1007.4740", "submitter": "Nicolas Bousquet", "authors": "Nicolas Bousquet", "title": "Elicitation of Weibull priors", "comments": "21 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Based on expert opinions, informative prior elicitation for the common\nWeibull lifetime distribution usually presents some difficulties since it\nrequires to elicit a two-dimensional joint prior. We consider here a\nreliability framework where the available expert information states directly in\nterms of prior predictive values (lifetimes) and not parameter values, which\nare less intuitive. The novelty of our procedure is to weigh the expert\ninformation by the size m of a virtual sample yielding a similar information,\nthe prior being seen as a reference posterior. Thus, the prior calibration by\nthe Bayesian analyst, who has to moderate the subjective information with\nrespect to the data information, is made simple. A main result is the full\ntractability of the prior under mild conditions, despite the conjugation issues\nencountered with the Weibull distribution. Besides, m is a practical focus\npoint for discussion between analysts and experts, and a helpful parameter for\nleading sensitivity studies and reducing the potential imbalance in posterior\nselection between Bayesian Weibull models, which can be due to favoring\narbitrarily a prior. The calibration of m is discussed and a real example is\ntreated along the paper.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2010 14:46:16 GMT"}, {"version": "v2", "created": "Thu, 29 Jul 2010 08:52:42 GMT"}, {"version": "v3", "created": "Thu, 21 Oct 2010 16:59:47 GMT"}], "update_date": "2010-10-22", "authors_parsed": [["Bousquet", "Nicolas", ""]]}, {"id": "1007.4969", "submitter": "Jose Dias", "authors": "S\\'onia Pelizzari and Jos\\'e M. Bioucas-Dias", "title": "Bayesian Segmentation of Oceanic SAR Images: Application to Oil Spill\n  Detection", "comments": "Submitted to IEEE Transactions in Geoscience and Remote Sensing", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces Bayesian supervised and unsupervised segmentation\nalgorithms aimed at oceanic segmentation of SAR images. The data term,\n\\emph{i.e}., the density of the observed backscattered signal given the region,\nis modeled by a finite mixture of Gamma densities with a given predefined\nnumber of components. To estimate the parameters of the class conditional\ndensities, a new expectation maximization algorithm was developed. The prior is\na multi-level logistic Markov random field enforcing local continuity in a\nstatistical sense. The smoothness parameter controlling the degree of\nhomogeneity imposed on the scene is automatically estimated, by computing the\nevidence with loopy belief propagation; the classical coding and least squares\nfit methods are also considered. The maximum a posteriori segmentation is\ncomputed efficiently by means of recent graph-cut techniques, namely the\n$\\alpha$-Expansion algorithm that extends the methodology to an optional number\nof classes. The effectiveness of the proposed approaches is illustrated with\nsimulated images and real ERS and Envisat scenes containing oil spills.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2010 17:46:47 GMT"}], "update_date": "2010-07-29", "authors_parsed": [["Pelizzari", "S\u00f3nia", ""], ["Bioucas-Dias", "Jos\u00e9 M.", ""]]}, {"id": "1007.5034", "submitter": "Daniel Weller", "authors": "Daniel S. Weller and Vivek K Goyal", "title": "On the Estimation of Nonrandom Signal Coefficients from Jittered Samples", "comments": "11 pages, 8 figures", "journal-ref": "IEEE Trans. on Signal Processing, vol. 59, no. 2, pp. 587-597,\n  February 2011", "doi": "10.1109/TSP.2010.2090347", "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper examines the problem of estimating the parameters of a bandlimited\nsignal from samples corrupted by random jitter (timing noise) and additive iid\nGaussian noise, where the signal lies in the span of a finite basis. For the\npresented classical estimation problem, the Cramer-Rao lower bound (CRB) is\ncomputed, and an Expectation-Maximization (EM) algorithm approximating the\nmaximum likelihood (ML) estimator is developed. Simulations are performed to\nstudy the convergence properties of the EM algorithm and compare the\nperformance both against the CRB and a basic linear estimator. These\nsimulations demonstrate that by post-processing the jittered samples with the\nproposed EM algorithm, greater jitter can be tolerated, potentially reducing\non-chip ADC power consumption substantially.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2010 17:06:47 GMT"}], "update_date": "2015-03-24", "authors_parsed": [["Weller", "Daniel S.", ""], ["Goyal", "Vivek K", ""]]}, {"id": "1007.5098", "submitter": "Daniel Weller", "authors": "Daniel S. Weller and Vivek K Goyal", "title": "Bayesian Post-Processing Methods for Jitter Mitigation in Sampling", "comments": "12 pages, 11 figures", "journal-ref": "IEEE Trans. on Signal Processing, vol. 59, no. 5, pp. 2112-2123,\n  May 2011", "doi": "10.1109/TSP.2011.2108289", "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Minimum mean squared error (MMSE) estimators of signals from samples\ncorrupted by jitter (timing noise) and additive noise are nonlinear, even when\nthe signal prior and additive noise have normal distributions. This paper\ndevelops a stochastic algorithm based on Gibbs sampling and slice sampling to\napproximate the optimal MMSE estimator in this Bayesian formulation.\nSimulations demonstrate that this nonlinear algorithm can improve significantly\nupon the linear MMSE estimator, as well as the EM algorithm approximation to\nthe maximum likelihood (ML) estimator used in classical estimation. Effective\noff-chip post-processing to mitigate jitter enables greater jitter to be\ntolerated, potentially reducing on-chip ADC power consumption.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2010 01:11:49 GMT"}, {"version": "v2", "created": "Fri, 8 Oct 2010 19:35:14 GMT"}], "update_date": "2015-03-24", "authors_parsed": [["Weller", "Daniel S.", ""], ["Goyal", "Vivek K", ""]]}, {"id": "1007.5192", "submitter": "Nial Friel", "authors": "Alberto Caimo and Nial Friel", "title": "Bayesian inference for exponential random graph models", "comments": "29 pages; Accepted to appear in Social Networks", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exponential random graph models are extremely difficult models to handle from\na statistical viewpoint, since their normalising constant, which depends on\nmodel parameters, is available only in very trivial cases. We show how\ninference can be carried out in a Bayesian framework using a MCMC algorithm,\nwhich circumvents the need to calculate the normalising constants. We use a\npopulation MCMC approach which accelerates convergence and improves mixing of\nthe Markov chain. This approach improves performance with respect to the Monte\nCarlo maximum likelihood method of Geyer and Thompson (1992).\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2010 11:52:12 GMT"}, {"version": "v2", "created": "Wed, 29 Sep 2010 11:58:22 GMT"}], "update_date": "2010-09-30", "authors_parsed": [["Caimo", "Alberto", ""], ["Friel", "Nial", ""]]}, {"id": "1007.5516", "submitter": "Korbinian Strimmer", "authors": "Verena Zuber and Korbinian Strimmer", "title": "High-dimensional regression and variable selection using CAR scores", "comments": "25 pages, 3 figures, 9 tables", "journal-ref": "Statistical Applications in Genetics and Molecular Biology 2011,\n  Vol. 10, Iss. 1, Article 34", "doi": "10.2202/1544-6115.1730", "report-no": null, "categories": "stat.ME stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variable selection is a difficult problem that is particularly challenging in\nthe analysis of high-dimensional genomic data. Here, we introduce the CAR\nscore, a novel and highly effective criterion for variable ranking in linear\nregression based on Mahalanobis-decorrelation of the explanatory variables. The\nCAR score provides a canonical ordering that encourages grouping of correlated\npredictors and down-weights antagonistic variables. It decomposes the\nproportion of variance explained and it is an intermediate between marginal\ncorrelation and the standardized regression coefficient. As a population\nquantity, any preferred inference scheme can be applied for its estimation.\nUsing simulations we demonstrate that variable selection by CAR scores is very\neffective and yields prediction errors and true and false positive rates that\ncompare favorably with modern regression techniques such as elastic net and\nboosting. We illustrate our approach by analyzing data concerned with diabetes\nprogression and with the effect of aging on gene expression in the human brain.\nThe R package \"care\" implementing CAR score regression is available from CRAN.\n", "versions": [{"version": "v1", "created": "Fri, 30 Jul 2010 18:47:09 GMT"}, {"version": "v2", "created": "Mon, 9 Aug 2010 23:07:15 GMT"}, {"version": "v3", "created": "Mon, 27 Sep 2010 16:08:30 GMT"}, {"version": "v4", "created": "Fri, 15 Apr 2011 11:59:15 GMT"}, {"version": "v5", "created": "Thu, 7 Jul 2011 09:24:48 GMT"}, {"version": "v6", "created": "Tue, 19 Jul 2011 02:35:53 GMT"}], "update_date": "2011-07-20", "authors_parsed": [["Zuber", "Verena", ""], ["Strimmer", "Korbinian", ""]]}]