[{"id": "1407.0001", "submitter": "Shu Yan", "authors": "Shu Yan, Shaoting Tang, Sen Pei, Shijin Jiang, Zhiming Zheng", "title": "Dynamical Immunization Strategy for Seasonal Epidemics", "comments": "8 pages, 9 figures", "journal-ref": null, "doi": "10.1103/PhysRevE.90.022808", "report-no": null, "categories": "stat.AP physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The topic of finding effective strategy to halt virus in complex network is\nof current interest. We propose an immunization strategy for seasonal epidemics\nthat occur periodically. Based on the local information of the infection status\nfrom the previous epidemic season, the selection of vaccinated nodes is\noptimized gradually. The evolution of vaccinated nodes during iterations\ndemonstrates that the immunization tends to locate in both global hubs and\nlocal hubs. We analyze the epidemic prevalence by a heterogeneous mean-field\nmethod and present numerical simulations of our model. This immunization\nperforms superiorly to some other previously known strategies. Our work points\nout a new direction in immunization of seasonal epidemics.\n", "versions": [{"version": "v1", "created": "Sat, 28 Jun 2014 01:50:24 GMT"}], "update_date": "2015-06-22", "authors_parsed": [["Yan", "Shu", ""], ["Tang", "Shaoting", ""], ["Pei", "Sen", ""], ["Jiang", "Shijin", ""], ["Zheng", "Zhiming", ""]]}, {"id": "1407.0044", "submitter": "Jonathan Huggins", "authors": "Jonathan H. Huggins and Frank Wood", "title": "Infinite Structured Hidden Semi-Markov Models", "comments": "23 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper reviews recent advances in Bayesian nonparametric techniques for\nconstructing and performing inference in infinite hidden Markov models. We\nfocus on variants of Bayesian nonparametric hidden Markov models that enhance a\nposteriori state-persistence in particular. This paper also introduces a new\nBayesian nonparametric framework for generating left-to-right and other\nstructured, explicit-duration infinite hidden Markov models that we call the\ninfinite structured hidden semi-Markov model.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jun 2014 20:18:18 GMT"}], "update_date": "2014-07-02", "authors_parsed": [["Huggins", "Jonathan H.", ""], ["Wood", "Frank", ""]]}, {"id": "1407.0050", "submitter": "Barbara Engelhardt", "authors": "David Mimno and David M Blei and Barbara E Engelhardt", "title": "Posterior predictive checks to quantify lack-of-fit in admixture models\n  of latent population structure", "comments": null, "journal-ref": null, "doi": "10.1073/pnas.1412301112", "report-no": null, "categories": "stat.ME q-bio.GN q-bio.PE stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Admixture models are a ubiquitous approach to capture latent population\nstructure in genetic samples. Despite the widespread application of admixture\nmodels, little thought has been devoted to the quality of the model fit or the\naccuracy of the estimates of parameters of interest for a particular study.\nHere we develop methods for validating admixture models based on posterior\npredictive checks (PPCs), a Bayesian method for assessing the quality of a\nstatistical model. We develop PPCs for five population-level statistics of\ninterest: within-population genetic variation, background linkage\ndisequilibrium, number of ancestral populations, between-population genetic\nvariation, and the downstream use of admixture parameters to correct for\npopulation structure in association studies. Using PPCs, we evaluate the\nquality of the model estimates for four qualitatively different population\ngenetic data sets: the POPRES European individuals, the HapMap phase 3\nindividuals, continental Indians, and African American individuals. We found\nthat the same model fitted to different genomic studies resulted in highly\nstudy-specific results when evaluated using PPCs, illustrating the utility of\nPPCs for model-based analyses in large genomic studies.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jun 2014 20:36:54 GMT"}], "update_date": "2015-11-12", "authors_parsed": [["Mimno", "David", ""], ["Blei", "David M", ""], ["Engelhardt", "Barbara E", ""]]}, {"id": "1407.0058", "submitter": "Thordis Thorarinsdottir", "authors": "Kira Feldmann, Michael Scheuerer and Thordis L. Thorarinsdottir", "title": "Spatial postprocessing of ensemble forecasts for temperature using\n  nonhomogeneous Gaussian regression", "comments": null, "journal-ref": null, "doi": "10.1175/MWR-D-14-00210.1", "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical postprocessing techniques are commonly used to improve the skill\nof ensembles of numerical weather forecasts. This paper considers spatial\nextensions of the well-established nonhomogeneous Gaussian regression (NGR)\npostprocessing technique for surface temperature and a recent modification\nthereof in which the local climatology is included in the regression model for\na locally adaptive postprocessing. In a comparative study employing 21 h\nforecasts from the COSMO-DE ensemble predictive system over Germany, two\napproaches for modeling spatial forecast error correlations are considered: A\nparametric Gaussian random field model and the ensemble copula coupling\napproach which utilizes the spatial rank correlation structure of the raw\nensemble. Additionally, the NGR methods are compared to both univariate and\nspatial versions of the ensemble Bayesian model averaging (BMA) postprocessing\ntechnique.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jun 2014 21:19:37 GMT"}], "update_date": "2015-06-22", "authors_parsed": [["Feldmann", "Kira", ""], ["Scheuerer", "Michael", ""], ["Thorarinsdottir", "Thordis L.", ""]]}, {"id": "1407.1195", "submitter": "Irene Gannaz", "authors": "Ir\\`ene Gannaz (ICJ, GIPSA-lab)", "title": "Classification of EEG recordings in auditory brain activity via a\n  logistic functional linear regression model", "comments": null, "journal-ref": "International Workshop on Functional and Operatorial Statistics,\n  Italy (2014)", "doi": null, "report-no": null, "categories": "stat.AP math.ST q-bio.NC stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We want to analyse EEG recordings in order to investigate the phonemic\ncategorization at a very early stage of auditory processing. This problem can\nbe modelled by a supervised classification of functional data. Discrimination\nis explored via a logistic functional linear model, using a wavelet\nrepresentation of the data. Different procedures are investigated, based on\npenalized likelihood and principal component reduction or partial least squares\nreduction.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jul 2014 11:33:46 GMT"}], "update_date": "2014-07-07", "authors_parsed": [["Gannaz", "Ir\u00e8ne", "", "ICJ, GIPSA-lab"]]}, {"id": "1407.1291", "submitter": "Stoyan Dimitrov", "authors": "Stoyan Dimitrov, Redouane Lguensat", "title": "Reinforcement Learning Based Algorithm for the Maximization of EV\n  Charging Station Revenue", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.LG math.OC stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an online reinforcement learning based application which\nincreases the revenue of one particular electric vehicles (EV) station,\nconnected to a renewable source of energy. Moreover, the proposed application\nadapts to changes in the trends of the station's average number of customers\nand their types. Most of the parameters in the model are simulated\nstochastically and the algorithm used is a Q-learning algorithm. A computer\nsimulation was implemented which demonstrates and confirms the utility of the\nmodel.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jul 2014 18:37:33 GMT"}, {"version": "v2", "created": "Wed, 17 Sep 2014 12:59:13 GMT"}], "update_date": "2014-09-18", "authors_parsed": [["Dimitrov", "Stoyan", ""], ["Lguensat", "Redouane", ""]]}, {"id": "1407.1450", "submitter": "Ning Yang", "authors": "Ning Yang, Xiangnan Kong, Fengjiao Wang, Philip S. Yu", "title": "When and Where: Predicting Human Movements Based on Social\n  Spatial-Temporal Events", "comments": null, "journal-ref": "In Proceedings of 2014 SIAM International Conference on Data\n  Mining (SDM 2014), 2014. 515-523", "doi": null, "report-no": null, "categories": "cs.SI stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting both the time and the location of human movements is valuable but\nchallenging for a variety of applications. To address this problem, we propose\nan approach considering both the periodicity and the sociality of human\nmovements. We first define a new concept, Social Spatial-Temporal Event (SSTE),\nto represent social interactions among people. For the time prediction, we\ncharacterise the temporal dynamics of SSTEs with an ARMA (AutoRegressive Moving\nAverage) model. To dynamically capture the SSTE kinetics, we propose a Kalman\nFilter based learning algorithm to learn and incrementally update the ARMA\nmodel as a new observation becomes available. For the location prediction, we\npropose a ranking model where the periodicity and the sociality of human\nmovements are simultaneously taken into consideration for improving the\nprediction accuracy. Extensive experiments conducted on real data sets validate\nour proposed approach.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jul 2014 01:18:57 GMT"}], "update_date": "2014-07-08", "authors_parsed": [["Yang", "Ning", ""], ["Kong", "Xiangnan", ""], ["Wang", "Fengjiao", ""], ["Yu", "Philip S.", ""]]}, {"id": "1407.1576", "submitter": "Farshad Rassaei", "authors": "Farshad Rassaei, Wee-Seng Soh and Kee-Chaing Chua", "title": "A Statistical Modelling and Analysis of PHEVs' Power Demand in Smart\n  Grids", "comments": "6 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electric vehicles (EVs) and particularly plug-in hybrid electric vehicles\n(PHEVs) are foreseen to become popular in the near future. Not only are they\nmuch more environmentally friendly than conventional internal combustion engine\n(ICE) vehicles, their fuel can also be catered from diverse energy sources and\nresources. However, they add significant load on the power grid as they become\nwidespread. The characteristics of this extra load follow the patterns of\npeople's driving behaviours. In particular, random parameters such as arrival\ntime and driven distance of the vehicles determine their expected demand\nprofile from the power grid. In this paper, we first present a model for\nuncoordinated charging power demand of PHEVs based on a stochastic process and\naccordingly we characterize the EV's expected daily power demand profile. Next,\nwe adopt different distributions for the EV's charging time following some\navailable empirical research data in the literature. Simulation results show\nthat the EV's expected daily power demand profiles obtained under the uniform,\nGaussian with positive support and Rician distributions for charging time are\nidentical when the first and second order statistics of these distributions are\nthe same. This gives us useful insights into the long-term planning for\nupgrading power systems' infrastructure to accommodate PHEVs. In addition, the\nresults from this modelling can be incorporated into designing demand response\n(DR) algorithms and evaluating the available DR techniques more accurately.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jul 2014 04:12:47 GMT"}], "update_date": "2014-07-08", "authors_parsed": [["Rassaei", "Farshad", ""], ["Soh", "Wee-Seng", ""], ["Chua", "Kee-Chaing", ""]]}, {"id": "1407.1751", "submitter": "Marco Enea", "authors": "Marco Enea and Gianfranco Lovison", "title": "A penalized approach to the bivariate logistic regression model for the\n  association between ordinal responses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.AP stat.CO stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bivariate ordered logistic models (BOLMs) are appealing to jointly model the\nmarginal distribution of two ordered responses and their association, given a\nset of covariates. When the number of categories of the responses increases,\nthe number of global odds ratios (or their re-parametrizations) to be estimated\nalso increases and estimating the association structure becomes crucial for\nthis type of data. In fact, such data could be too \"rich\" to be fully modelled\nwith an ordinary BOLM while, sometimes, the well-known Dale's model could be\ntoo parsimonious to provide a good fit. In addition, when the cross-tabulation\nof the responses contains some zeros, for a number of model configurations,\nincluding the bivariate version of the partial proportional odds model (PPOM),\nestimation of a BOLM by the Fisher-scoring algorithm may either fail or\nestimate a too \"irregular\" association structure. In this work, we propose to\nuse a nonparametric approach for the maximum likelihood estimation of a BOLM.\nWe apply penalties to the differences between adjacent row and column effects.\nAs a result, estimation is less demanding than an ordinary BOLM, permitting the\nfit of PPOMs and/or the smoothing of the marginal and association parameters by\npolynomial curves and surfaces, with scores chosen by the data. Model selection\nis based on the penalized log-likelihood ratio, whose limiting distribution has\nbeen studied through simulations, and AIC. Our proposal is compared to the\nGoodman's model and the Dale's model, in terms of goodness-of-fit and\nparsimony, on a literature data set. Finally, an application on an original\ndata set of liver disease patients is proposed.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jul 2014 15:52:29 GMT"}], "update_date": "2014-07-08", "authors_parsed": [["Enea", "Marco", ""], ["Lovison", "Gianfranco", ""]]}, {"id": "1407.1778", "submitter": "Abhik Ghosh", "authors": "Abhik Ghosh", "title": "Robust Estimation of Bivariate Tail Dependence Coefficient", "comments": "Pre-Print, 20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of estimating the coefficient of bivariate tail dependence is\nconsidered here from the robustness point of view; it combines two apparently\ncontradictory theories of robust statistics and extreme value statistics. The\nusual maximum likelihood based or the moment type estimators of tail dependence\ncoefficient are highly sensitive to the presence of outlying observations in\ndata. This paper proposes some alternative robust estimators obtained by\nminimizing the density power divergence with suitable model assumptions; their\nrobustness properties are examined through the classical influence function\nanalysis. The performance of the proposed estimators is illustrated through an\nextensive empirical study considering several important bivariate extreme value\ndistributions.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jul 2014 17:20:51 GMT"}], "update_date": "2014-07-08", "authors_parsed": [["Ghosh", "Abhik", ""]]}, {"id": "1407.1886", "submitter": "Marcel Ausloos", "authors": "Marcel Ausloos", "title": "Intrinsic Classes in the Union of European Football Associations Soccer\n  Team Ranking", "comments": "13 pages, 4 figures, 3 Tables, 41 references, prepared for Central\n  European Journal of Physics", "journal-ref": "Cent. Eur. J. Phys. 12(11) (2014) 773-779", "doi": "10.2478/s11534-014-0423-5", "report-no": null, "categories": "stat.AP physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A strong structural regularity of classes is found in soccer teams ranked by\nthe Union of European Football Associations (UEFA) for the time interval\n2009-2014. It concerns 424 to 453 teams according to the 5 competition seasons.\nThe analysis is based on the rank-size theory considerations, the size being\nthe UEFA coefficient at the end of a season. Three classes emerge: (i) the few\n\"top\" teams, (ii) 300 teams, (iii) the rest of the involved teams (about 150)\nin the tail of the distribution. There are marked empirical laws describing\neach class. A 3-parameter Lavalette function is used to describe the concave\ncurving as the rank increases, and to distinguish the the tail from the central\nbehavior.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jul 2014 20:59:02 GMT"}], "update_date": "2018-02-14", "authors_parsed": [["Ausloos", "Marcel", ""]]}, {"id": "1407.2239", "submitter": "Benjamin Goldstein", "authors": "Benjamin A Goldstein, Themistocles Assimes, Wolfgang C. Winkelmayer,\n  and Trevor Hastoe", "title": "Detecting clinically meaningful biomarkers with repeated measurements in\n  an Electronic Health Record", "comments": "23 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electronic health record (EHR) data are becoming an increasingly common data\nsource for understanding clinical risk of acute events. While their\nlongitudinal nature presents opportunities to observe changing risk over time,\nthese analyses are complicated by the sparse and irregular measurements of many\nof the clinical metrics making typical statistical methods unsuitable for these\ndata. In this paper, we present an analytic procedure to both sample from an\nEHR and analyze the data to detect clinically meaningful markers of acute\nmyocardial infarction (MI). Using an EHR from a large national dialysis\norganization we abstracted the records of 64,318 individuals and identified\n5,314 people that had an MI during the study period. We describe a nested\ncase-control design to sample appropriate controls and an analytic approach\nusing regression splines. Fitting a mixed-model with truncated power splines we\nperform a series of goodness-of-fit tests to determine whether any of 11\nregularly collected laboratory markers are useful clinical predictors. We test\nthe clinical utility of each marker using an independent test set. The results\nsuggest that EHR data can be easily used to detect markers of clinically acute\nevents. Special software or analytic tools are not needed, even with irregular\nEHR data.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jul 2014 19:54:47 GMT"}], "update_date": "2014-07-09", "authors_parsed": [["Goldstein", "Benjamin A", ""], ["Assimes", "Themistocles", ""], ["Winkelmayer", "Wolfgang C.", ""], ["Hastoe", "Trevor", ""]]}, {"id": "1407.2432", "submitter": "Christophe Giraud", "authors": "Christophe Giraud (CMAP, LM-Orsay), Cl\\'ement Calenge, Camille Coron\n  (LM-Orsay), Romain Julliard (MNHN)", "title": "Capitalising on Opportunistic Data for Monitoring Species Relative\n  Abundances", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the internet, a massive amount of information on species abundance can\nbe collected under citizen science programs. However, these data are often\ndifficult to use directly in statistical inference, as their collection is\ngenerally opportunistic, and the distribution of the sampling effort is often\nnot known. In this paper, we develop a general statistical framework to combine\nsuch \"opportunistic data\" with data collected using schemes characterized by a\nknown sampling effort. Under some structural assumptions regarding the sampling\neffort and detectability, our approach allows to estimate the relative\nabundance of several species in different sites. It can be implemented through\na simple generalized linear model. We illustrate the framework with typical\nbird datasets from the Aquitaine region, south-western France. We show that,\nunder some assumptions, our approach provides estimates that are more precise\nthan the ones obtained from the dataset with a known sampling effort alone.\nWhen the opportunistic data are abundant, the gain in precision may be\nconsiderable, especially for the rare species. We also show that estimates can\nbe obtained even for species recorded only in the opportunistic scheme.\nOpportunistic data combined with a relatively small amount of data collected\nwith a known effort may thus provide access to accurate and precise estimates\nof quantitative changes in relative abundance over space and/or time.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jul 2014 11:00:37 GMT"}, {"version": "v2", "created": "Thu, 26 Feb 2015 19:43:48 GMT"}], "update_date": "2015-02-27", "authors_parsed": [["Giraud", "Christophe", "", "CMAP, LM-Orsay"], ["Calenge", "Cl\u00e9ment", "", "LM-Orsay"], ["Coron", "Camille", "", "LM-Orsay"], ["Julliard", "Romain", "", "MNHN"]]}, {"id": "1407.2677", "submitter": "Shantha Herath Dr.", "authors": "H.M.S.P. Herath, Cao Liang, Chen Yongbing", "title": "Impacts of Regional Trade Agreements(RTAs) on Food Security: A Case of\n  ASEAN Free Trade Agreement", "comments": null, "journal-ref": "International Journal of Social Science & Interdisciplinary\n  Research, Vol.3(3) 2014, ISSN:2277-3630", "doi": null, "report-no": null, "categories": "q-fin.GN stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discriminatory trade liberalization policies are becoming more popular among\nworld economies. Countries are motivated to enter for regional trade agreements\nto capture faster economic growth for alleviating poverty. In developing\neconomies like most of the member countries of the Association of South East\nAsian Nations (ASEAN), a sizeable portion of people are suffering from poverty\nby exposing them to food insecurity. Low level of income and low productivity\nof agricultural sector have augmented the severity of food insecurity of those\npeople. Discriminatory trade liberalization policies are expected to reduce\npoverty and strengthen the food security. The objective of this paper is to\nexamine the effect of ASEAN Free Trade Agreement (AFTA) on food security of its\nmember countries. The multiple regression analysis in panel data was employed\nto disentangle the impacts of trade liberalization on food securit y with use\nof regional trade agreement dummy variable. The finding of the study supports\nthat AFTA has influenced positively on food security of its member nations.\nAfter the formation of AFTA, the level of per-capita daily dietary energy\nsupply of the member countries has been increased moderately over time.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jul 2014 02:43:56 GMT"}], "update_date": "2014-07-11", "authors_parsed": [["Herath", "H. M. S. P.", ""], ["Liang", "Cao", ""], ["Yongbing", "Chen", ""]]}, {"id": "1407.2731", "submitter": "Richard D. Gill", "authors": "Richard D. Gill", "title": "Rarity of Respiratory Arrest in ED?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical analysis of monthly rates of events in around 20 hospitals and\nover a period of about 10 years shows that respiratory arrest, though about\nfive times less frequent than cardio-respiratory arrest, is a common occurrence\nin the Emergency Department of a typical smaller UK hospital. This report has\nbeen prepared at the request of lawyers working in the London Innocence Project\nand is intended to form part of an application to the CCRC for a reopening of\nthe case of Ben Geen: a UK nurse sentenced to 30 years in jail following an\napparent cluster of cases always when he was on duty at the Horton General\nHospital.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jul 2014 09:11:56 GMT"}], "update_date": "2014-07-11", "authors_parsed": [["Gill", "Richard D.", ""]]}, {"id": "1407.2754", "submitter": "Mikkel Bennedsen", "authors": "Mikkel Bennedsen, Asger Lunde and Mikko S. Pakkanen", "title": "Discretization of L\\'evy semistationary processes with application to\n  estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the construction of the It\\^o stochastic integral, we consider a\nstep function method to discretize and simulate volatility modulated L\\'evy\nsemistationary processes. Moreover, we assess the accuracy of the method with a\nparticular focus on integrating kernels with a singularity at the origin. Using\nthe simulation method, we study the finite sample properties of some recently\ndeveloped estimators of realized volatility and associated parametric\nestimators for Brownian semistationary processes. Although the theoretical\nproperties of these estimators have been established under high frequency\nasymptotics, it turns out that the estimators perform well also in a low\nfrequency setting.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jul 2014 11:11:09 GMT"}], "update_date": "2014-07-11", "authors_parsed": [["Bennedsen", "Mikkel", ""], ["Lunde", "Asger", ""], ["Pakkanen", "Mikko S.", ""]]}, {"id": "1407.3191", "submitter": "Rebecca Steorts", "authors": "Rebecca C. Steorts, Samuel L. Ventura, Mauricio Sadinle, Stephen E.\n  Fienberg", "title": "A Comparison of Blocking Methods for Record Linkage", "comments": "22 pages, 2 tables, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Record linkage seeks to merge databases and to remove duplicates when unique\nidentifiers are not available. Most approaches use blocking techniques to\nreduce the computational complexity associated with record linkage. We review\ntraditional blocking techniques, which typically partition the records\naccording to a set of field attributes, and consider two variants of a method\nknown as locality sensitive hashing, sometimes referred to as \"private\nblocking.\" We compare these approaches in terms of their recall, reduction\nratio, and computational complexity. We evaluate these methods using different\nsynthetic datafiles and conclude with a discussion of privacy-related issues.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jul 2014 15:06:03 GMT"}], "update_date": "2014-07-14", "authors_parsed": [["Steorts", "Rebecca C.", ""], ["Ventura", "Samuel L.", ""], ["Sadinle", "Mauricio", ""], ["Fienberg", "Stephen E.", ""]]}, {"id": "1407.3322", "submitter": "Raffi Sevlian", "authors": "Raffi Sevlian and Siddarth Patel and Ram Rajagopal", "title": "Distribution System Load and Forecast Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This short document provides experimental evidence for the set of assumptions\non the mean load and forecast errors made in \\cite{Sevlian2014A_Outage} and\n\\cite{Sevlian2014B_Outage}. We show that the mean load at any given node is\ndistributed normally, where we compute the mean and variance. We then present\nan aggregation-error curve for a single day ahead forecaster. Residual analysis\nshows that beyond 500 customers, gaussian residuals is a reasonable model. We\nthen show the forecaster has uncorrelated errors.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jul 2014 23:28:38 GMT"}], "update_date": "2014-07-15", "authors_parsed": [["Sevlian", "Raffi", ""], ["Patel", "Siddarth", ""], ["Rajagopal", "Ram", ""]]}, {"id": "1407.3912", "submitter": "Silvia Pandolfi Dr", "authors": "Francesco Bartolucci, Giorgio E. Montanari, Silvia Pandolfi", "title": "Item selection by Latent Class-based methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The evaluation of nursing homes is usually based on the administration of\nquestionnaires made of a large number of polytomous items. In such a context,\nthe Latent Class (LC) model represents a useful tool for clustering subjects in\nhomogenous groups corresponding to different degrees of impairment of the\nhealth conditions. It is known that the performance of model-based clustering\nand the accuracy of the choice of the number of latent classes may be affected\nby the presence of irrelevant or noise variables. In this paper, we show the\napplication of an item selection algorithm to real data collected within a\nproject, named ULISSE, on the quality-of-life of elderly patients hosted in\nitalian nursing homes. This algorithm, which is closely related to that\nproposed by Dean and Raftery in 2010, is aimed at finding the subset of items\nwhich provides the best clustering according to the Bayesian Information\nCriterion. At the same time, it allows us to select the optimal number of\nlatent classes. Given the complexity of the ULISSE study, we perform a\nvalidation of the results by means of a sensitivity analysis to different\nspecifications of the initial subset of items and of a resampling procedure.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jul 2014 08:46:27 GMT"}], "update_date": "2014-07-16", "authors_parsed": [["Bartolucci", "Francesco", ""], ["Montanari", "Giorgio E.", ""], ["Pandolfi", "Silvia", ""]]}, {"id": "1407.3961", "submitter": "Abhik Ghosh", "authors": "Avijit Maji, Abhik Ghosh, Ayanendranath Basu", "title": "The Logarithmic Super Divergence and its use in Statistical Inference", "comments": "Pre-print, under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a new superfamily of divergences that is similar in\nspirit to the S-divergence family introduced by Ghosh et al. (2013). This new\nfamily serves as an umbrella that contains the logarithmic power divergence\nfamily (Renyi, 1961; Maji, Chakraborty and Basu 2014) and the logarithmic\ndensity power divergence family (Jones et al., 2001) as special cases. Various\nproperties of this new family and the corresponding minimum distance procedures\nare discussed with particular emphasis on the robustness issue; these\nproperties are demonstrated through simulation studies. In particular the\nmethod demonstrates the limitation of the first order influence function in\nassessing the robustness of the corresponding minimum distance procedures.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jul 2014 12:33:27 GMT"}], "update_date": "2014-07-16", "authors_parsed": [["Maji", "Avijit", ""], ["Ghosh", "Abhik", ""], ["Basu", "Ayanendranath", ""]]}, {"id": "1407.4240", "submitter": "Ulrike von Luxburg", "authors": "Volker H. Franz and Ulrike von Luxburg", "title": "Unconscious lie detection as an example of a widespread fallacy in the\n  Neurosciences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neuroscientists frequently use a certain statistical reasoning to establish\nthe existence of distinct neuronal processes in the brain. We show that this\nreasoning is flawed and that the large corresponding literature needs\nreconsideration. We illustrate the fallacy with a recent study that received an\nenormous press coverage because it concluded that humans detect deceit better\nif they use unconscious processes instead of conscious deliberations. The study\nwas published under a new open-data policy that enabled us to reanalyze the\ndata with more appropriate methods. We found that unconscious performance was\nclose to chance - just as the conscious performance. This illustrates the flaws\nof this widely used statistical reasoning, the benefits of open-data practices,\nand the need for careful reconsideration of studies using the same rationale.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jul 2014 09:13:26 GMT"}], "update_date": "2014-07-17", "authors_parsed": [["Franz", "Volker H.", ""], ["von Luxburg", "Ulrike", ""]]}, {"id": "1407.4430", "submitter": "Zhaoyi Kang", "authors": "Zhaoyi Kang and Costas J. Spanos", "title": "Sequential Logistic Principal Component Analysis (SLPCA): Dimensional\n  Reduction in Streaming Multivariate Binary-State System", "comments": "6 pages, 4 figures, conference submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Sequential or online dimensional reduction is of interests due to the\nexplosion of streaming data based applications and the requirement of adaptive\nstatistical modeling, in many emerging fields, such as the modeling of energy\nend-use profile. Principal Component Analysis (PCA), is the classical way of\ndimensional reduction. However, traditional Singular Value Decomposition (SVD)\nbased PCA fails to model data which largely deviates from Gaussian\ndistribution. The Bregman Divergence was recently introduced to achieve a\ngeneralized PCA framework. If the random variable under dimensional reduction\nfollows Bernoulli distribution, which occurs in many emerging fields, the\ngeneralized PCA is called Logistic PCA (LPCA). In this paper, we extend the\nbatch LPCA to a sequential version (i.e. SLPCA), based on the sequential convex\noptimization theory. The convergence property of this algorithm is discussed\ncompared to the batch version of LPCA (i.e. BLPCA), as well as its performance\nin reducing the dimension for multivariate binary-state systems. Its\napplication in building energy end-use profile modeling is also investigated.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jul 2014 19:05:55 GMT"}], "update_date": "2014-07-17", "authors_parsed": [["Kang", "Zhaoyi", ""], ["Spanos", "Costas J.", ""]]}, {"id": "1407.4658", "submitter": "Florian Markowetz", "authors": "Alex J. Cornish and Florian Markowetz", "title": "SANTA: quantifying the functional content of molecular networks", "comments": "Accepted at PLoS Comp Bio", "journal-ref": null, "doi": "10.1371/journal.pcbi.1003808", "report-no": null, "categories": "q-bio.MN q-bio.QM stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linking networks of molecular interactions to cellular functions and\nphenotypes is a key goal in systems biology. Here, we adapt concepts of spatial\nstatistics to assess the functional content of molecular networks. Based on the\nguilt-by-association principle, our approach (called SANTA) quantifies the\nstrength of association between a gene set and a network, and functionally\nannotates molecular networks like other enrichment methods annotate lists of\ngenes. As a general association measure, SANTA can (i) functionally annotate\nexperimentally derived networks using a collection of curated gene sets, and\n(ii) annotate experimentally derived gene sets using a collection of curated\nnetworks, as well as (iii) prioritize genes for follow-up analyses. We\nexemplify the efficacy of SANTA in several case studies using the \\emph{S.\ncerevisiae} genetic interaction network and genome-wide RNAi screens in cancer\ncell lines. Our theory, simulations and applications show that SANTA provides a\nprincipled statistical way to quantify the association between molecular\nnetworks and cellular functions and phenotypes. SANTA is available from\nhttp://bioconductor.org/packages/release/bioc/html/SANTA.html.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jul 2014 12:59:42 GMT"}], "update_date": "2015-06-22", "authors_parsed": [["Cornish", "Alex J.", ""], ["Markowetz", "Florian", ""]]}, {"id": "1407.4718", "submitter": "Riccardo Di Clemente", "authors": "Alessandro Belmonte, Riccardo Di Clemente and Sergey V. Buldyrev", "title": "The Italian primary school-size distribution and the city-size: a\n  complex nexus", "comments": "16 pages, 10 figures", "journal-ref": "Sci. Rep. 4, 5301 (2014)", "doi": "10.1038/srep05301", "report-no": null, "categories": "physics.soc-ph physics.data-an stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We characterize the statistical law according to which Italian primary\nschool-size distributes. We find that the school-size can be approximated by a\nlog-normal distribution, with a fat lower tail that collects a large number of\nvery small schools. The upper tail of the school-size distribution decreases\nexponentially and the growth rates are distributed with a Laplace PDF. These\ndistributions are similar to those observed for firms and are consistent with a\nBose-Einstein preferential attachment process. The body of the distribution\nfeatures a bimodal shape suggesting some source of heterogeneity in the school\norganization that we uncover by an in-depth analysis of the relation between\nschools-size and city-size. We propose a novel cluster methodology and a new\nspatial interaction approach among schools which outline the variety of\npolicies implemented in Italy. Different regional policies are also discussed\nshedding lights on the relation between policy and geographical features.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jul 2014 16:10:24 GMT"}], "update_date": "2014-07-18", "authors_parsed": [["Belmonte", "Alessandro", ""], ["Di Clemente", "Riccardo", ""], ["Buldyrev", "Sergey V.", ""]]}, {"id": "1407.5017", "submitter": "Pablo G. Moreno", "authors": "Pablo G. Moreno and Yee Whye Teh and Fernando Perez-Cruz and Antonio\n  Art\\'es-Rodr\\'iguez", "title": "Bayesian Nonparametric Crowdsourcing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Crowdsourcing has been proven to be an effective and efficient tool to\nannotate large datasets. User annotations are often noisy, so methods to\ncombine the annotations to produce reliable estimates of the ground truth are\nnecessary. We claim that considering the existence of clusters of users in this\ncombination step can improve the performance. This is especially important in\nearly stages of crowdsourcing implementations, where the number of annotations\nis low. At this stage there is not enough information to accurately estimate\nthe bias introduced by each annotator separately, so we have to resort to\nmodels that consider the statistical links among them. In addition, finding\nthese clusters is interesting in itself as knowing the behavior of the pool of\nannotators allows implementing efficient active learning strategies. Based on\nthis, we propose in this paper two new fully unsupervised models based on a\nChinese Restaurant Process (CRP) prior and a hierarchical structure that allows\ninferring these groups jointly with the ground truth and the properties of the\nusers. Efficient inference algorithms based on Gibbs sampling with auxiliary\nvariables are proposed. Finally, we perform experiments, both on synthetic and\nreal databases, to show the advantages of our models over state-of-the-art\nalgorithms.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jul 2014 14:51:34 GMT"}], "update_date": "2014-07-21", "authors_parsed": [["Moreno", "Pablo G.", ""], ["Teh", "Yee Whye", ""], ["Perez-Cruz", "Fernando", ""], ["Art\u00e9s-Rodr\u00edguez", "Antonio", ""]]}, {"id": "1407.5079", "submitter": "Colin B. Fogarty", "authors": "Colin B. Fogarty, Dylan S. Small", "title": "Equivalence testing for functional data with an application to comparing\n  pulmonary function devices", "comments": "Published in at http://dx.doi.org/10.1214/14-AOAS763 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2014, Vol. 8, No. 4, 2002-2026", "doi": "10.1214/14-AOAS763", "report-no": "IMS-AOAS-AOAS763", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Equivalence testing for scalar data has been well addressed in the\nliterature, however, the same cannot be said for functional data. The resultant\ncomplexity from maintaining the functional structure of the data, rather than\nusing a scalar transformation to reduce dimensionality, renders the existing\nliterature on equivalence testing inadequate for the desired inference. We\npropose a framework for equivalence testing for functional data within both the\nfrequentist and Bayesian paradigms. This framework combines extensions of\nscalar methodologies with new methodology for functional data. Our frequentist\nhypothesis test extends the Two One-Sided Testing (TOST) procedure for\nequivalence testing to the functional regime. We conduct this TOST procedure\nthrough the use of the nonparametric bootstrap. Our Bayesian methodology\nemploys a functional analysis of variance model, and uses a flexible class of\nGaussian Processes for both modeling our data and as prior distributions.\nThrough our analysis, we introduce a model for heteroscedastic variances within\na Gaussian Process by modeling variance curves via Log-Gaussian Process priors.\nWe stress the importance of choosing prior distributions that are commensurate\nwith the prior state of knowledge and evidence regarding practical equivalence.\nWe illustrate these testing methods through data from an ongoing method\ncomparison study between two devices for pulmonary function testing. In so\ndoing, we provide not only concrete motivation for equivalence testing for\nfunctional data, but also a blueprint for researchers who hope to conduct\nsimilar inference.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jul 2014 18:42:11 GMT"}, {"version": "v2", "created": "Wed, 4 Mar 2015 13:48:28 GMT"}], "update_date": "2015-03-05", "authors_parsed": [["Fogarty", "Colin B.", ""], ["Small", "Dylan S.", ""]]}, {"id": "1407.5141", "submitter": "Gabriel Terejanu", "authors": "Xiao Lin and Gabriel Terejanu", "title": "Model-Driven Data Collection for Biological Systems", "comments": "2014 American Control Conference, Portland, OR, June 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For biological experiments aiming at calibrating models with unknown\nparameters, a good experimental design is crucial, especially for those subject\nto various constraints, such as financial limitations, time consumption and\nphysical practicability. In this paper, we discuss a sequential experimental\ndesign based on information theory for parameter estimation and apply it to two\nbiological systems. Two specific issues are addressed in the proposed\napplications, namely the determination of the optimal sampling time and the\noptimal choice of observable. The optimal design, either sampling time or\nobservable, is achieved by an information-theoretic sensitivity analysis. It is\nshown that this is equivalent with maximizing the mutual information and\ncontrasted with non-adaptive designs, this information theoretic strategy\nprovides the fastest reduction of uncertainty.\n", "versions": [{"version": "v1", "created": "Sat, 19 Jul 2014 02:14:29 GMT"}], "update_date": "2014-07-22", "authors_parsed": [["Lin", "Xiao", ""], ["Terejanu", "Gabriel", ""]]}, {"id": "1407.5185", "submitter": "Pavlo Mozharovskyi", "authors": "Pavlo Mozharovskyi, Karl Mosler, Tatjana Lange", "title": "Classifying real-world data with the $DD\\alpha$-procedure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.ME", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The $DD\\alpha$-classifier, a nonparametric fast and very robust procedure, is\ndescribed and applied to fifty classification problems regarding a broad\nspectrum of real-world data. The procedure first transforms the data from their\noriginal property space into a depth space, which is a low-dimensional unit\ncube, and then separates them by a projective invariant procedure, called\n$\\alpha$-procedure. To each data point the transformation assigns its depth\nvalues with respect to the given classes. Several alternative depth notions\n(spatial depth, Mahalanobis depth, projection depth, and Tukey depth, the\nlatter two being approximated by univariate projections) are used in the\nprocedure, and compared regarding their average error rates. With the Tukey\ndepth, which fits the distributions' shape best and is most robust,\n`outsiders', that is data points having zero depth in all classes, need an\nadditional treatment for classification. Evidence is also given about the\ndimension of the extended feature space needed for linear separation. The\n$DD\\alpha$-procedure is available as an R-package.\n", "versions": [{"version": "v1", "created": "Sat, 19 Jul 2014 13:55:47 GMT"}, {"version": "v2", "created": "Wed, 28 Oct 2015 15:20:39 GMT"}], "update_date": "2015-10-29", "authors_parsed": [["Mozharovskyi", "Pavlo", ""], ["Mosler", "Karl", ""], ["Lange", "Tatjana", ""]]}, {"id": "1407.5296", "submitter": "David Colquhoun FRS", "authors": "David Colquhoun", "title": "An investigation of the false discovery rate and the misinterpretation\n  of P values", "comments": "Small typo fixed again, at top of page 7 20 Nov", "journal-ref": "R. Soc. open sci. (2014) 1: 140216", "doi": "10.1098/rsos.140216", "report-no": null, "categories": "stat.AP physics.data-an q-bio.QM", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  The following proposition is justified from several different points of view.\nIf you use P = 0.05 to suggest that you have made a discovery, you will be\nwrong at least 30 percent of the time. If, as is often the case, experiments\nare under-powered, you will be wrong most of the time. It is concluded that if\nyou wish to keep your false discovery rate below 5 percent, you need to use a\n3-sigma rule, or to insist on P value below 0.001. And never use the word\n\"significant\".\n", "versions": [{"version": "v1", "created": "Sun, 20 Jul 2014 14:35:09 GMT"}, {"version": "v2", "created": "Mon, 11 Aug 2014 08:27:09 GMT"}, {"version": "v3", "created": "Thu, 20 Nov 2014 09:23:37 GMT"}], "update_date": "2014-11-21", "authors_parsed": [["Colquhoun", "David", ""]]}, {"id": "1407.5368", "submitter": "Liang Wu", "authors": "Liang Wu, Xuezhen Chen, Chunyan Zhao", "title": "Taylor's Law and the Spatial Distribution of Urban Facilities", "comments": "30 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Taylor's law is the footprint of ecosystems, which admits a power function\nrelationship $S^{2}=am^{b}$ between the variance $S^{2}$ and mean number $m$ of\norganisms in an area. We examine the distribution of spatial coordinate data of\nseven urban facilities (beauty salons, banks, stadiums, schools, pharmacy,\nconvenient stores and restaurants) in 37 major cities in China, and find that\nTaylor's law is validated among all 7 considered facilities, in the fashion\nthat either all cities are combined together or each city is considered\nseparately. Moreover, we find that the exponent $b$ falls between 1 and 2,\nwhich reveals that the distribution of urban facilities resembles that of the\norganisms in ecosystems. Furthermore, through decomposing the inverse of\nexponent $b$, we examine two different factors affecting\\emph{ }the numbers of\nfacilities in an area of a city respectively, which are the city-specific\nfactor and the facility-specific factor. The city-specific factor reflects the\noverall density of all the facilities in a city, while the facility-specific\nfactor indicates the overall aggregation level of each type of facility in all\nthe cities. For example, Beijing ranks the first in the overall density, while\nrestaurant tops the overall aggregation level.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jul 2014 03:58:05 GMT"}], "update_date": "2014-07-22", "authors_parsed": [["Wu", "Liang", ""], ["Chen", "Xuezhen", ""], ["Zhao", "Chunyan", ""]]}, {"id": "1407.5412", "submitter": "Rahul Biswas", "authors": "Rahul Biswas, Koulik Khamaru, Kaushik Majumdar", "title": "A Peak Synchronization Measure for Multiple Signals", "comments": null, "journal-ref": "IEEE Transactions on Signal Processing, vol.62, no.17,\n  pp.4390-4398, Sept.1, 2014", "doi": "10.1109/TSP.2014.2333568", "report-no": null, "categories": "stat.ME stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Peaks signify important events in a signal. In a pair of signals how peaks\nare occurring with mutual correspondence may offer us significant insights into\nthe mutual interdependence between the two signals based on important events.\nIn this work we proposed a novel synchronization measure between two signals,\ncalled peak synchronization, which measures the simultaneity of occurrence of\npeaks in the signals. We subsequently generalized it to more than two signals.\nWe showed that our measure of synchronization is largely independent of the\nunderlying parameter values. A time complexity analysis of the algorithm has\nalso been presented. We applied the measure on intracranial EEG signals of\nepileptic patients and found that the enhanced synchronization during an\nepileptic seizure can be modeled better by the new peak synchronization measure\nthan the classical amplitude correlation method.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jul 2014 08:34:17 GMT"}, {"version": "v2", "created": "Wed, 14 Jan 2015 20:17:06 GMT"}], "update_date": "2015-01-15", "authors_parsed": [["Biswas", "Rahul", ""], ["Khamaru", "Koulik", ""], ["Majumdar", "Kaushik", ""]]}, {"id": "1407.5525", "submitter": "Cedric Ginestet", "authors": "Cedric E. Ginestet, Jun Li, Prakash Balachandran, Steven Rosenberg and\n  Eric D. Kolaczyk", "title": "Hypothesis Testing For Network Data in Functional Neuroimaging", "comments": "34 pages. 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP q-bio.NC stat.ME", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In recent years, it has become common practice in neuroscience to use\nnetworks to summarize relational information in a set of measurements,\ntypically assumed to be reflective of either functional or structural\nrelationships between regions of interest in the brain. One of the most basic\ntasks of interest in the analysis of such data is the testing of hypotheses, in\nanswer to questions such as \"Is there a difference between the networks of\nthese two groups of subjects?\" In the classical setting, where the unit of\ninterest is a scalar or a vector, such questions are answered through the use\nof familiar two-sample testing strategies. Networks, however, are not Euclidean\nobjects, and hence classical methods do not directly apply. We address this\nchallenge by drawing on concepts and techniques from geometry, and\nhigh-dimensional statistical inference. Our work is based on a precise\ngeometric characterization of the space of graph Laplacian matrices and a\nnonparametric notion of averaging due to Fr\\'echet. We motivate and illustrate\nour resulting methodologies for testing in the context of networks derived from\nfunctional neuroimaging data on human subjects from the 1000 Functional\nConnectomes Project. In particular, we show that this global test is more\nstatistical powerful, than a mass-univariate approach. In addition, we have\nalso provided a method for visualizing the individual contribution of each edge\nto the overall test statistic.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jul 2014 15:20:34 GMT"}, {"version": "v2", "created": "Mon, 28 Jul 2014 16:40:50 GMT"}, {"version": "v3", "created": "Fri, 2 Sep 2016 15:15:47 GMT"}, {"version": "v4", "created": "Thu, 2 Feb 2017 15:49:34 GMT"}, {"version": "v5", "created": "Fri, 3 Feb 2017 10:53:01 GMT"}, {"version": "v6", "created": "Fri, 17 Mar 2017 16:41:13 GMT"}], "update_date": "2017-03-20", "authors_parsed": [["Ginestet", "Cedric E.", ""], ["Li", "Jun", ""], ["Balachandran", "Prakash", ""], ["Rosenberg", "Steven", ""], ["Kolaczyk", "Eric D.", ""]]}, {"id": "1407.5616", "submitter": "Mohammad Reza Gholami", "authors": "Mohammad Reza Gholami, Sinan Gezici, Erik G. Str\\\"om", "title": "TW-TOA Based Positioning in the Presence of Clock Imperfections", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the positioning problem based on two-way time-of-arrival\n(TW-TOA) measurements in asynchronous wireless sensor networks. Since the\noptimal estimator for this problem involves difficult nonconvex optimization,\nwe propose two suboptimal estimators based on squared-range least squares and\nleast absolute mean of residual errors. The former approach is formulated as a\ngeneral trust region subproblem which can be solved exactly under mild\nconditions. The latter approach is formulated as a difference of convex\nfunctions programming (DCP), which can be solved using a concave-convex\nprocedure. Simulation results illustrate the high performance of the proposed\ntechniques, especially for the DCP approach.\n", "versions": [{"version": "v1", "created": "Sat, 19 Jul 2014 12:13:45 GMT"}], "update_date": "2014-07-23", "authors_parsed": [["Gholami", "Mohammad Reza", ""], ["Gezici", "Sinan", ""], ["Str\u00f6m", "Erik G.", ""]]}, {"id": "1407.5764", "submitter": "Truyen Tran", "authors": "Tran The Truyen, Dinh Q. Phung and Svetha Venkatesh", "title": "Preference Networks: Probabilistic Models for Recommendation Systems", "comments": "In Proc. of 6th Australasian Data Mining Conference (AusDM), Gold\n  Coast, Australia, pages 195--202, 2007", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.SI stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems are important to help users select relevant and\npersonalised information over massive amounts of data available. We propose an\nunified framework called Preference Network (PN) that jointly models various\ntypes of domain knowledge for the task of recommendation. The PN is a\nprobabilistic model that systematically combines both content-based filtering\nand collaborative filtering into a single conditional Markov random field. Once\nestimated, it serves as a probabilistic database that supports various useful\nqueries such as rating prediction and top-$N$ recommendation. To handle the\nchallenging problem of learning large networks of users and items, we employ a\nsimple but effective pseudo-likelihood with regularisation. Experiments on the\nmovie rating data demonstrate the merits of the PN.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jul 2014 07:17:48 GMT"}], "update_date": "2014-07-23", "authors_parsed": [["Truyen", "Tran The", ""], ["Phung", "Dinh Q.", ""], ["Venkatesh", "Svetha", ""]]}, {"id": "1407.5809", "submitter": "Steffen Lauritzen", "authors": "Peter G. M. Forbes and Steffen Lauritzen and Jesper M{\\o}ller", "title": "Fingerprint Analysis with Marked Point Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a framework for fingerprint matching based on marked point process\nmodels. An efficient Monte Carlo algorithm is developed to calculate the\nmarginal likelihood ratio for the hypothesis that two observed prints originate\nfrom the same finger against the hypothesis that they originate from different\nfingers. Our model achieves good performance on an NIST-FBI fingerprint\ndatabase of 258 matched fingerprint pairs.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jul 2014 10:19:00 GMT"}], "update_date": "2014-07-23", "authors_parsed": [["Forbes", "Peter G. M.", ""], ["Lauritzen", "Steffen", ""], ["M\u00f8ller", "Jesper", ""]]}, {"id": "1407.5962", "submitter": "Martin Lysy", "authors": "Martin Lysy, Natesh S. Pillai, David B. Hill, M. Gregory Forest, John\n  Mellnik, Paula Vasquez, Scott A. McKinley", "title": "Model comparison and assessment for single particle tracking in\n  biological fluids", "comments": "24 pages, 10 figures + supplementary material", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art techniques in passive particle-tracking microscopy provide\nhigh-resolution path trajectories of diverse foreign particles in biological\nfluids. For particles on the order of 1 micron diameter, these paths are\ngenerally inconsistent with simple Brownian motion. Yet, despite an abundance\nof data confirming these findings and their wide-ranging scientific\nimplications, stochastic modeling of the complex particle motion has received\ncomparatively little attention. Even among posited models, there is virtually\nno literature on likelihood-based inference, model comparisons, and other\nquantitative assessments. In this article, we develop a rigorous and\ncomputationally efficient Bayesian methodology to address this gap. We analyze\ntwo of the most prevalent candidate models for 30 second paths of 1 micron\ndiameter tracer particles in human lung mucus: fractional Brownian motion (fBM)\nand a Generalized Langevin Equation (GLE) consistent with viscoelastic theory.\nOur model comparisons distinctly favor GLE over fBM, with the former describing\nthe data remarkably well up to the timescales for which we have reliable\ninformation.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jul 2014 17:58:55 GMT"}, {"version": "v2", "created": "Sun, 29 Nov 2015 10:11:36 GMT"}], "update_date": "2015-12-01", "authors_parsed": [["Lysy", "Martin", ""], ["Pillai", "Natesh S.", ""], ["Hill", "David B.", ""], ["Forest", "M. Gregory", ""], ["Mellnik", "John", ""], ["Vasquez", "Paula", ""], ["McKinley", "Scott A.", ""]]}, {"id": "1407.6084", "submitter": "Truyen Tran", "authors": "Truyen Tran, Dinh Phung, Wei Luo, Svetha Venkatesh", "title": "Stabilized Sparse Ordinal Regression for Medical Risk Stratification", "comments": null, "journal-ref": null, "doi": "10.1007/s10115-014-0740-4", "report-no": null, "categories": "stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent wide adoption of Electronic Medical Records (EMR) presents great\nopportunities and challenges for data mining. The EMR data is largely temporal,\noften noisy, irregular and high dimensional. This paper constructs a novel\nordinal regression framework for predicting medical risk stratification from\nEMR. First, a conceptual view of EMR as a temporal image is constructed to\nextract a diverse set of features. Second, ordinal modeling is applied for\npredicting cumulative or progressive risk. The challenges are building a\ntransparent predictive model that works with a large number of weakly\npredictive features, and at the same time, is stable against resampling\nvariations. Our solution employs sparsity methods that are stabilized through\ndomain-specific feature interaction networks. We introduces two indices that\nmeasure the model stability against data resampling. Feature networks are used\nto generate two multivariate Gaussian priors with sparse precision matrices\n(the Laplacian and Random Walk). We apply the framework on a large short-term\nsuicide risk prediction problem and demonstrate that our methods outperform\nclinicians to a large-margin, discover suicide risk factors that conform with\nmental health knowledge, and produce models with enhanced stability.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jul 2014 01:19:47 GMT"}], "update_date": "2014-07-24", "authors_parsed": [["Tran", "Truyen", ""], ["Phung", "Dinh", ""], ["Luo", "Wei", ""], ["Venkatesh", "Svetha", ""]]}, {"id": "1407.6242", "submitter": "Andrew Parnell", "authors": "Andrew C. Parnell, Norman Graham, Andrew L. Jackson, Mafalda Viana", "title": "Frequency behaviour for multinomial counts of fisheries discards via a\n  nested wavelet zero and N inflated binomial model", "comments": "24 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we identify the changing frequency behaviour of multinomial\ncounts of fish species discarded by vessels in the Irish Sea. We use a Bayesian\nhierarchical model which captures dynamic frequency changes via a shrinkage\nmodel applied to wavelet basis functions. Wavelets are known for capturing data\nfeatures at different temporal scales; we use a recently-proposed shrinkage\nprior from the factor analysis literature so that features at the finest levels\nof detail exhibit the greatest shrinkage. Rather than using a multinomial\ndistribution for monitoring the changes in discards over time, which can be\nslow to fit and inflexible, we use a nested zero-and-N inflated (ZaNI) binomial\ndistribution which enables much faster computation with no obvious\ndeterioration in model flexibility. Our results show that seasonal behaviour in\nthese data are not regular and occur at different frequencies. We also show\nthat the nested ZaNI binomial distribution is a good fit to multinomial count\ndata of this sort when an informative nested structure is applied.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jul 2014 14:40:31 GMT"}], "update_date": "2014-07-24", "authors_parsed": [["Parnell", "Andrew C.", ""], ["Graham", "Norman", ""], ["Jackson", "Andrew L.", ""], ["Viana", "Mafalda", ""]]}, {"id": "1407.6390", "submitter": "Rajesh Singh", "authors": "Sachin Malik, Viplav Kumar Singh, Rajesh Singh", "title": "An improved estimator for population mean using auxiliary information in\n  stratified random sampling", "comments": "10 pages, 2 tables", "journal-ref": "SIT_ns, 15(1), 59-66, 2014", "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the present study, we propose a new estimator for population mean of the\nstudy variable y in the case of stratified random sampling using the\ninformation based on auxiliary variable x. Expression for the mean squared\nerror (MSE) of the proposed estimators is derived up to the first order of\napproximation. The theoretical conditions have also been verified by a\nnumerical example. An empirical study is carried out to show the efficiency of\nthe suggested estimator over sample mean estimator, usual separate ratio,\nseparate product estimator and other proposed estimators.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jul 2014 05:10:22 GMT"}], "update_date": "2014-07-25", "authors_parsed": [["Malik", "Sachin", ""], ["Singh", "Viplav Kumar", ""], ["Singh", "Rajesh", ""]]}, {"id": "1407.6514", "submitter": "Fumiya Akashi", "authors": "Fumiya Akashi, Yan Liu, Masanobu Taniguchi", "title": "An empirical likelihood approach for symmetric $\\alpha$-stable processes", "comments": "Published at http://dx.doi.org/10.3150/14-BEJ636 in the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2015, Vol. 21, No. 4, 2093-2119", "doi": "10.3150/14-BEJ636", "report-no": "IMS-BEJ-BEJ636", "categories": "math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Empirical likelihood approach is one of non-parametric statistical methods,\nwhich is applied to the hypothesis testing or construction of confidence\nregions for pivotal unknown quantities. This method has been applied to the\ncase of independent identically distributed random variables and second order\nstationary processes. In recent years, we observe heavy-tailed data in many\nfields. To model such data suitably, we consider symmetric scalar and\nmultivariate $\\alpha$-stable linear processes generated by infinite variance\ninnovation sequence. We use a Whittle likelihood type estimating function in\nthe empirical likelihood ratio function and derive the asymptotic distribution\nof the empirical likelihood ratio statistic for $\\alpha$-stable linear\nprocesses. With the empirical likelihood statistic approach, the theory of\nestimation and testing for second order stationary processes is nicely extended\nto heavy-tailed data analyses, not straightforward, and applicable to a lot of\nfinancial statistical analyses.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jul 2014 10:08:42 GMT"}, {"version": "v2", "created": "Fri, 18 Sep 2015 07:31:01 GMT"}], "update_date": "2015-09-21", "authors_parsed": [["Akashi", "Fumiya", ""], ["Liu", "Yan", ""], ["Taniguchi", "Masanobu", ""]]}, {"id": "1407.6519", "submitter": "Darren Wilkinson", "authors": "Howsun Jow, Richard J. Boys and Darren J. Wilkinson", "title": "Bayesian identification of protein differential expression in\n  multi-group isobaric labelled mass spectrometry data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we develop a Bayesian statistical inference approach to the\nunified analysis of isobaric labelled MS/MS proteomic data across multiple\nexperiments. An explicit probabilistic model of the log-intensity of the\nisobaric labels' reporter ions across multiple pre-defined groups and\nexperiments is developed. This is then used to develop a full Bayesian\nstatistical methodology for the identification of differentially expressed\nproteins, with respect to a control group, across multiple groups and\nexperiments. This methodology is implemented and then evaluated on simulated\ndata and on two model experimental datasets (for which the differentially\nexpressed proteins are known) that use a TMT labelling protocol.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jul 2014 10:34:37 GMT"}], "update_date": "2014-07-25", "authors_parsed": [["Jow", "Howsun", ""], ["Boys", "Richard J.", ""], ["Wilkinson", "Darren J.", ""]]}, {"id": "1407.6895", "submitter": "Stephanie Thiemichen", "authors": "Stephanie Thiemichen, Nial Friel, Alberto Caimo, G\\\"oran Kauermann", "title": "Bayesian Exponential Random Graph Models with Nodal Random Effects", "comments": "23 pages, 9 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend the well-known and widely used Exponential Random Graph Model\n(ERGM) by including nodal random effects to compensate for heterogeneity in the\nnodes of a network. The Bayesian framework for ERGMs proposed by Caimo and\nFriel (2011) yields the basis of our modelling algorithm. A central question in\nnetwork models is the question of model selection and following the Bayesian\nparadigm we focus on estimating Bayes factors. To do so we develop an\napproximate but feasible calculation of the Bayes factor which allows one to\npursue model selection. Two data examples and a small simulation study\nillustrate our mixed model approach and the corresponding model selection.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jul 2014 13:53:07 GMT"}, {"version": "v2", "created": "Mon, 12 Jan 2015 14:30:28 GMT"}], "update_date": "2015-01-13", "authors_parsed": [["Thiemichen", "Stephanie", ""], ["Friel", "Nial", ""], ["Caimo", "Alberto", ""], ["Kauermann", "G\u00f6ran", ""]]}, {"id": "1407.7118", "submitter": "Vladimir Filimonov", "authors": "Spencer Wheatley, Vladimir Filimonov, Didier Sornette", "title": "Estimation of the Hawkes Process With Renewal Immigration Using the EM\n  Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the Hawkes process with renewal immigration and make its\nstatistical estimation possible with two Expectation Maximization (EM)\nalgorithms. The standard Hawkes process introduces immigrant points via a\nPoisson process, and each immigrant has a subsequent cluster of associated\noffspring of multiple generations. We generalize the immigration to come from a\nRenewal process; introducing dependence between neighbouring clusters, and\nallowing for over/under dispersion in cluster locations. This complicates\nevaluation of the likelihood since one needs to know which subset of the\nobserved points are immigrants. Two EM algorithms enable estimation here: The\nfirst is an extension of an existing algorithm that treats the entire branching\nstructure - which points are immigrants, and which point is the parent of each\noffspring - as missing data. The second considers only if a point is an\nimmigrant or not as missing data and can be implemented with linear time\ncomplexity. Both algorithms are found to be consistent in simulation studies.\nFurther, we show that misspecifying the immigration process introduces\nsignficant bias into model estimation-- especially the branching ratio, which\nquantifies the strength of self excitation. Thus, this extended model provides\na valuable alternative model in practice.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jul 2014 10:22:06 GMT"}], "update_date": "2014-07-29", "authors_parsed": [["Wheatley", "Spencer", ""], ["Filimonov", "Vladimir", ""], ["Sornette", "Didier", ""]]}, {"id": "1407.7150", "submitter": "Aditya Vempaty", "authors": "Bhavya Kailkhura, Aditya Vempaty, and Pramod K. Varshney", "title": "Distributed Inference in Tree Networks using Coding Theory", "comments": "16 pages, 7 figures, submitted to IEEE Transactions on Signal\n  Processing", "journal-ref": null, "doi": "10.1109/TSP.2015.2434326", "report-no": null, "categories": "cs.IT math.IT stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the problem of distributed inference in tree based\nnetworks. In the framework considered in this paper, distributed nodes make a\n1-bit local decision regarding a phenomenon before sending it to the fusion\ncenter (FC) via intermediate nodes. We propose the use of coding theory based\ntechniques to solve this distributed inference problem in such structures. Data\nis progressively compressed as it moves towards the FC. The FC makes the global\ninference after receiving data from intermediate nodes. Data fusion at nodes as\nwell as at the FC is implemented via error correcting codes. In this context,\nwe analyze the performance for a given code matrix and also design the optimal\ncode matrices at every level of the tree. We address the problems of\ndistributed classification and distributed estimation separately and develop\nschemes to perform these tasks in tree networks. The proposed schemes are of\npractical significance due to their simple structure. We study the asymptotic\ninference performance of our schemes for two different classes of tree\nnetworks: fixed height tree networks, and fixed degree tree networks. We show\nthat the proposed schemes are asymptotically optimal under certain conditions.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jul 2014 19:32:31 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Kailkhura", "Bhavya", ""], ["Vempaty", "Aditya", ""], ["Varshney", "Pramod K.", ""]]}, {"id": "1407.7619", "submitter": "Thurston Dang", "authors": "Thurston H. Y. Dang and Elchanan Mossel", "title": "A Statistical Test for Clades in Phylogenies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP q-bio.PE", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  We investigated testing the likelihood of a phylogenetic tree by comparison\nto its subtree pruning and regrafting (SPR) neighbors, with or without\nre-optimizing branch lengths. This is inspired by aspects of Bayesian\nsignificance tests, and the use of SPRs for heuristically finding maximum\nlikelihood trees. Through a number of simulations with the Jukes-Cantor model\non various topologies, it is observed that the SPR tests are informative, and\nreasonably fast compared to searching for the maximum likelihood tree. This\nsuggests that the SPR tests would be a useful addition to the suite of existing\nstatistical tests, for identifying potential inaccuracies of inferred\ntopologies.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jul 2014 02:39:40 GMT"}], "update_date": "2014-07-30", "authors_parsed": [["Dang", "Thurston H. Y.", ""], ["Mossel", "Elchanan", ""]]}, {"id": "1407.8067", "submitter": "Fei Yu", "authors": "Fei Yu, Michal Rybar, Caroline Uhler, Stephen E. Fienberg", "title": "Differentially-Private Logistic Regression for Detecting Multiple-SNP\n  Association in GWAS Databases", "comments": "To appear in Proceedings of the 2014 International Conference on\n  Privacy in Statistical Databases", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Following the publication of an attack on genome-wide association studies\n(GWAS) data proposed by Homer et al., considerable attention has been given to\ndeveloping methods for releasing GWAS data in a privacy-preserving way. Here,\nwe develop an end-to-end differentially private method for solving regression\nproblems with convex penalty functions and selecting the penalty parameters by\ncross-validation. In particular, we focus on penalized logistic regression with\nelastic-net regularization, a method widely used to in GWAS analyses to\nidentify disease-causing genes. We show how a differentially private procedure\nfor penalized logistic regression with elastic-net regularization can be\napplied to the analysis of GWAS data and evaluate our method's performance.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jul 2014 14:51:19 GMT"}], "update_date": "2014-07-31", "authors_parsed": [["Yu", "Fei", ""], ["Rybar", "Michal", ""], ["Uhler", "Caroline", ""], ["Fienberg", "Stephen E.", ""]]}, {"id": "1407.8219", "submitter": "Mauricio Sadinle", "authors": "Mauricio Sadinle", "title": "Detecting duplicates in a homicide registry using a Bayesian\n  partitioning approach", "comments": "Published in at http://dx.doi.org/10.1214/14-AOAS779 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2014, Vol. 8, No. 4, 2404-2434", "doi": "10.1214/14-AOAS779", "report-no": "IMS-AOAS-AOAS779", "categories": "stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding duplicates in homicide registries is an important step in keeping an\naccurate account of lethal violence. This task is not trivial when unique\nidentifiers of the individuals are not available, and it is especially\nchallenging when records are subject to errors and missing values. Traditional\napproaches to duplicate detection output independent decisions on the\ncoreference status of each pair of records, which often leads to nontransitive\ndecisions that have to be reconciled in some ad-hoc fashion. The task of\nfinding duplicate records in a data file can be alternatively posed as\npartitioning the data file into groups of coreferent records. We present an\napproach that targets this partition of the file as the parameter of interest,\nthereby ensuring transitive decisions. Our Bayesian implementation allows us to\nincorporate prior information on the reliability of the fields in the data\nfile, which is especially useful when no training data are available, and it\nalso provides a proper account of the uncertainty in the duplicate detection\ndecisions. We present a study to detect killings that were reported multiple\ntimes to the United Nations Truth Commission for El Salvador.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jul 2014 21:21:50 GMT"}, {"version": "v2", "created": "Tue, 3 Feb 2015 10:47:56 GMT"}], "update_date": "2015-02-04", "authors_parsed": [["Sadinle", "Mauricio", ""]]}, {"id": "1407.8253", "submitter": "Hua Zhou", "authors": "Hua Zhou and John Blangero and Thomas D. Dyer and Kei-hang K. Chan and\n  Kenneth Lange and Eric M. Sobel", "title": "Fast Genome-Wide QTL Association Mapping on Pedigree and Population Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP q-bio.GN q-bio.PE stat.CO", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Since most analysis software for genome-wide association studies (GWAS)\ncurrently exploit only unrelated individuals, there is a need for efficient\napplications that can handle general pedigree data or mixtures of both\npopulation and pedigree data. Even data sets thought to consist of only\nunrelated individuals may include cryptic relationships that can lead to false\npositives if not discovered and controlled for. In addition, family designs\npossess compelling advantages. They are better equipped to detect rare\nvariants, control for population stratification, and facilitate the study of\nparent-of-origin effects. Pedigrees selected for extreme trait values often\nsegregate a single gene with strong effect. Finally, many pedigrees are\navailable as an important legacy from the era of linkage analysis.\nUnfortunately, pedigree likelihoods are notoriously hard to compute. In this\npaper we re-examine the computational bottlenecks and implement ultra-fast\npedigree-based GWAS analysis. Kinship coefficients can either be based on\nexplicitly provided pedigrees or automatically estimated from dense markers.\nOur strategy (a) works for random sample data, pedigree data, or a mix of both;\n(b) entails no loss of power; (c) allows for any number of covariate\nadjustments, including correction for population stratification; (d) allows for\ntesting SNPs under additive, dominant, and recessive models; and (e)\naccommodates both univariate and multivariate quantitative traits. On a typical\npersonal computer (6 CPU cores at 2.67 GHz), analyzing a univariate HDL\n(high-density lipoprotein) trait from the San Antonio Family Heart Study\n(935,392 SNPs on 1357 individuals in 124 pedigrees) takes less than 2 minutes\nand 1.5 GB of memory. Complete multivariate QTL analysis of the three\ntime-points of the longitudinal HDL multivariate trait takes less than 5\nminutes and 1.5 GB of memory.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jul 2014 01:42:21 GMT"}, {"version": "v2", "created": "Sat, 20 Dec 2014 03:31:15 GMT"}], "update_date": "2014-12-23", "authors_parsed": [["Zhou", "Hua", ""], ["Blangero", "John", ""], ["Dyer", "Thomas D.", ""], ["Chan", "Kei-hang K.", ""], ["Lange", "Kenneth", ""], ["Sobel", "Eric M.", ""]]}, {"id": "1407.8259", "submitter": "Hua Zhou", "authors": "Hua Zhou and Jin Zhou and Tao Hu and Eric M Sobel and Kenneth Lange", "title": "Fast Genome-Wide QTL Analysis Using Mendel", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP q-bio.GN q-bio.PE", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Pedigree GWAS (Option 29) in the current version of the Mendel software is an\noptimized subroutine for performing large scale genome-wide QTL analysis. This\nanalysis (a) works for random sample data, pedigree data, or a mix of both, (b)\nis highly efficient in both run time and memory requirement, (c) accommodates\nboth univariate and multivariate traits, (d) works for autosomal and x-linked\nloci, (e) correctly deals with missing data in traits, covariates, and\ngenotypes, (f) allows for covariate adjustment and constraints among\nparameters, (g) uses either theoretical or SNP-based empirical kinship matrix\nfor additive polygenic effects, (h) allows extra variance components such as\ndominant polygenic effects and household effects, (i) detects and reports\noutlier individuals and pedigrees, and (j) allows for robust estimation via the\n$t$-distribution. The current paper assesses these capabilities on the genetics\nanalysis workshop 19 (GAW19) sequencing data. We analyzed simulated and real\nphenotypes for both family and random sample data sets. For instance, when\njointly testing the 8 longitudinally measured systolic blood pressure (SBP) and\ndiastolic blood pressure (DBP) traits, it takes Mendel 78 minutes on a standard\nlaptop computer to read, quality check, and analyze a data set with 849\nindividuals and 8.3 million SNPs. Genome-wide eQTL analysis of 20,643\nexpression traits on 641 individuals with 8.3 million SNPs takes 30 hours using\n20 parallel runs on a cluster. Mendel is freely available at\n\\url{http://www.genetics.ucla.edu/software}.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jul 2014 02:00:17 GMT"}], "update_date": "2014-08-01", "authors_parsed": [["Zhou", "Hua", ""], ["Zhou", "Jin", ""], ["Hu", "Tao", ""], ["Sobel", "Eric M", ""], ["Lange", "Kenneth", ""]]}, {"id": "1407.8371", "submitter": "Mireille E. Schnitzer", "authors": "Mireille E. Schnitzer, Mark J. van der Laan, Erica E. M. Moodie,\n  Robert W. Platt", "title": "Effect of breastfeeding on gastrointestinal infection in infants: A\n  targeted maximum likelihood approach for clustered longitudinal data", "comments": "Published in at http://dx.doi.org/10.1214/14-AOAS727 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2014, Vol. 8, No. 2, 703-725", "doi": "10.1214/14-AOAS727", "report-no": "IMS-AOAS-AOAS727", "categories": "stat.AP q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The PROmotion of Breastfeeding Intervention Trial (PROBIT) cluster-randomized\na program encouraging breastfeeding to new mothers in hospital centers. The\noriginal studies indicated that this intervention successfully increased\nduration of breastfeeding and lowered rates of gastrointestinal tract\ninfections in newborns. Additional scientific and popular interest lies in\ndetermining the causal effect of longer breastfeeding on gastrointestinal\ninfection. In this study, we estimate the expected infection count under\nvarious lengths of breastfeeding in order to estimate the effect of\nbreastfeeding duration on infection. Due to the presence of baseline and\ntime-dependent confounding, specialized \"causal\" estimation methods are\nrequired. We demonstrate the double-robust method of Targeted Maximum\nLikelihood Estimation (TMLE) in the context of this application and review some\nrelated methods and the adjustments required to account for clustering. We\ncompare TMLE (implemented both parametrically and using a data-adaptive\nalgorithm) to other causal methods for this example. In addition, we conduct a\nsimulation study to determine (1) the effectiveness of controlling for\nclustering indicators when cluster-specific confounders are unmeasured and (2)\nthe importance of using data-adaptive TMLE.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jul 2014 12:07:45 GMT"}], "update_date": "2014-08-01", "authors_parsed": [["Schnitzer", "Mireille E.", ""], ["van der Laan", "Mark J.", ""], ["Moodie", "Erica E. M.", ""], ["Platt", "Robert W.", ""]]}, {"id": "1407.8374", "submitter": "Brian D. M. Tom", "authors": "Brian D. M. Tom, Vernon T. Farewell, Sheila M. Bird", "title": "Maximum likelihood and pseudo score approaches for parametric\n  time-to-event analysis with informative entry times", "comments": "Published in at http://dx.doi.org/10.1214/14-AOAS725 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2014, Vol. 8, No. 2, 726-746", "doi": "10.1214/14-AOAS725", "report-no": "IMS-AOAS-AOAS725", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a maximum likelihood estimating approach for time-to-event Weibull\nregression models with outcome-dependent sampling, where sampling of subjects\nis dependent on the residual fraction of the time left to developing the event\nof interest. Additionally, we propose a two-stage approach which proceeds by\niteratively estimating, through a pseudo score, the Weibull parameters of\ninterest (i.e., the regression parameters) conditional on the inverse\nprobability of sampling weights; and then re-estimating these weights (given\nthe updated Weibull parameter estimates) through the profiled full likelihood.\nWith these two new methods, both the estimated sampling mechanism parameters\nand the Weibull parameters are consistently estimated under correct\nspecification of the conditional referral distribution. Standard errors for the\nregression parameters are obtained directly from inverting the observed\ninformation matrix in the full likelihood specification and by either\ncalculating bootstrap or robust standard errors for the hybrid pseudo\nscore/profiled likelihood approach. Loss of efficiency with the latter approach\nis considered. Robustness of the proposed methods to misspecification of the\nreferral mechanism and the time-to-event distribution is also briefly examined.\nFurther, we show how to extend our methods to the family of parametric\ntime-to-event distributions characterized by the generalized gamma\ndistribution. The motivation for these two approaches came from data on time to\ncirrhosis from hepatitis C viral infection in patients referred to the\nEdinburgh liver clinic. We analyze these data here.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jul 2014 12:14:10 GMT"}], "update_date": "2014-08-01", "authors_parsed": [["Tom", "Brian D. M.", ""], ["Farewell", "Vernon T.", ""], ["Bird", "Sheila M.", ""]]}, {"id": "1407.8376", "submitter": "Chi Song", "authors": "Chi Song, George C. Tseng", "title": "Hypothesis setting and order statistic for robust genomic meta-analysis", "comments": "Published in at http://dx.doi.org/10.1214/13-AOAS683 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2014, Vol. 8, No. 2, 777-800", "doi": "10.1214/13-AOAS683", "report-no": "IMS-AOAS-AOAS683", "categories": "stat.AP q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Meta-analysis techniques have been widely developed and applied in genomic\napplications, especially for combining multiple transcriptomic studies. In this\npaper we propose an order statistic of $p$-values ($r$th ordered $p$-value,\nrOP) across combined studies as the test statistic. We illustrate different\nhypothesis settings that detect gene markers differentially expressed (DE) 'in\nall studies,\" \"in the majority of studies\"' or \"in one or more studies,\" and\nspecify rOP as a suitable method for detecting DE genes \"in the majority of\nstudies.\" We develop methods to estimate the parameter $r$ in rOP for real\napplications. Statistical properties such as its asymptotic behavior and a\none-sided testing correction for detecting markers of concordant expression\nchanges are explored. Power calculation and simulation show better performance\nof rOP compared to classical Fisher's method, Stouffer's method, minimum\n$p$-value method and maximum $p$-value method under the focused hypothesis\nsetting. Theoretically, rOP is found connected to the na\\\"{i}ve vote counting\nmethod and can be viewed as a generalized form of vote counting with better\nstatistical properties. The method is applied to three microarray meta-analysis\nexamples including major depressive disorder, brain cancer and diabetes. The\nresults demonstrate rOP as a more generalizable, robust and sensitive\nstatistical framework to detect disease-related markers.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jul 2014 12:27:22 GMT"}], "update_date": "2014-08-01", "authors_parsed": [["Song", "Chi", ""], ["Tseng", "George C.", ""]]}, {"id": "1407.8382", "submitter": "Zheyang Wu", "authors": "Zheyang Wu, Yiming Sun, Shiquan He, Judy Cho, Hongyu Zhao, Jiashun Jin", "title": "Detection boundary and Higher Criticism approach for rare and weak\n  genetic effects", "comments": "Published in at http://dx.doi.org/10.1214/14-AOAS724 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2014, Vol. 8, No. 2, 824-851", "doi": "10.1214/14-AOAS724", "report-no": "IMS-AOAS-AOAS724", "categories": "stat.AP q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Genome-wide association studies (GWAS) have identified many genetic factors\nunderlying complex human traits. However, these factors have explained only a\nsmall fraction of these traits' genetic heritability. It is argued that many\nmore genetic factors remain undiscovered. These genetic factors likely are\nweakly associated at the population level and sparsely distributed across the\ngenome. In this paper, we adapt the recent innovations on Tukey's Higher\nCriticism (Tukey [The Higher Criticism (1976) Princeton Univ.]; Donoho and Jin\n[Ann. Statist. 32 (2004) 962-994]) to SNP-set analysis of GWAS, and develop a\nnew theoretical framework in large-scale inference to assess the joint\nsignificance of such rare and weak effects for a quantitative trait. In the\ncore of our theory is the so-called detection boundary, a curve in the\ntwo-dimensional phase space that quantifies the rarity and strength of genetic\neffects. Above the detection boundary, the overall effects of genetic factors\nare strong enough for reliable detection. Below the detection boundary, the\ngenetic factors are simply too rare and too weak for reliable detection. We\nshow that the HC-type methods are optimal in that they reliably yield detection\nonce the parameters of the genetic effects fall above the detection boundary\nand that many commonly used SNP-set methods are suboptimal. The superior\nperformance of the HC-type approach is demonstrated through simulations and the\nanalysis of a GWAS data set of Crohn's disease.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jul 2014 12:37:42 GMT"}], "update_date": "2014-08-01", "authors_parsed": [["Wu", "Zheyang", ""], ["Sun", "Yiming", ""], ["He", "Shiquan", ""], ["Cho", "Judy", ""], ["Zhao", "Hongyu", ""], ["Jin", "Jiashun", ""]]}, {"id": "1407.8384", "submitter": "Isabel Molina", "authors": "Isabel Molina, Balgobin Nandram, J. N. K. Rao", "title": "Small area estimation of general parameters with application to poverty\n  indicators: A hierarchical Bayes approach", "comments": "Published in at http://dx.doi.org/10.1214/13-AOAS702 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2014, Vol. 8, No. 2, 852-885", "doi": "10.1214/13-AOAS702", "report-no": "IMS-AOAS-AOAS702", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Poverty maps are used to aid important political decisions such as allocation\nof development funds by governments and international organizations. Those\ndecisions should be based on the most accurate poverty figures. However, often\nreliable poverty figures are not available at fine geographical levels or for\nparticular risk population subgroups due to the sample size limitation of\ncurrent national surveys. These surveys cannot cover adequately all the desired\nareas or population subgroups and, therefore, models relating the different\nareas are needed to 'borrow strength\" from area to area. In particular, the\nSpanish Survey on Income and Living Conditions (SILC) produces national poverty\nestimates but cannot provide poverty estimates by Spanish provinces due to the\npoor precision of direct estimates, which use only the province specific data.\nIt also raises the ethical question of whether poverty is more severe for women\nthan for men in a given province. We develop a hierarchical Bayes (HB) approach\nfor poverty mapping in Spanish provinces by gender that overcomes the small\nprovince sample size problem of the SILC. The proposed approach has a wide\nscope of application because it can be used to estimate general nonlinear\nparameters. We use a Bayesian version of the nested error regression model in\nwhich Markov chain Monte Carlo procedures and the convergence monitoring\ntherein are avoided. A simulation study reveals good frequentist properties of\nthe HB approach. The resulting poverty maps indicate that poverty, both in\nfrequency and intensity, is localized mostly in the southern and western\nprovinces and it is more acute for women than for men in most of the provinces.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jul 2014 12:42:00 GMT"}], "update_date": "2014-08-01", "authors_parsed": [["Molina", "Isabel", ""], ["Nandram", "Balgobin", ""], ["Rao", "J. N. K.", ""]]}, {"id": "1407.8386", "submitter": "Inna Chervoneva", "authors": "Inna Chervoneva, Boris Freydin, Brian Hipszer, Tatiyana V.\n  Apanasovich, Jeffrey I. Joseph", "title": "Estimation of nonlinear differential equation model for glucose-insulin\n  dynamics in type I diabetic patients using generalized smoothing", "comments": "Published in at http://dx.doi.org/10.1214/13-AOAS706 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2014, Vol. 8, No. 2, 886-904", "doi": "10.1214/13-AOAS706", "report-no": "IMS-AOAS-AOAS706", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we develop an ordinary differential equations (ODE) model of\nphysiological regulation of glycemia in type 1 diabetes mellitus (T1DM)\npatients in response to meals and intravenous insulin infusion. Unlike for the\nmajority of existing mathematical models of glucose-insulin dynamics,\nparameters in our model are estimable from a relatively small number of noisy\nobservations of plasma glucose and insulin concentrations. For estimation, we\nadopt the generalized smoothing estimation of nonlinear dynamic systems of\nRamsay et al. [J. R. Stat. Soc. Ser. B Stat. Methodol. 69 (2007) 741-796]. In\nthis framework, the ODE solution is approximated with a penalized spline, where\nthe ODE model is incorporated in the penalty. We propose to optimize the\ngeneralized smoothing by using penalty weights that minimize the covariance\npenalties criterion (Efron [J. Amer. Statist. Assoc. 99 (2004) 619-642]). The\ncovariance penalties criterion provides an estimate of the prediction error for\nnonlinear estimation rules resulting from nonlinear and/or nonhomogeneous ODE\nmodels, such as our model of glucose-insulin dynamics. We also propose to\nselect the optimal number and location of knots for B-spline bases used to\nrepresent the ODE solution. The results of the small simulation study\ndemonstrate advantages of optimized generalized smoothing in terms of smaller\nestimation errors for ODE parameters and smaller prediction errors for\nsolutions of differential equations. Using the proposed approach to analyze the\nglucose and insulin concentration data in T1DM patients, we obtained good\napproximation of global glucose-insulin dynamics and physiologically meaningful\nparameter estimates.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jul 2014 12:43:53 GMT"}], "update_date": "2014-08-01", "authors_parsed": [["Chervoneva", "Inna", ""], ["Freydin", "Boris", ""], ["Hipszer", "Brian", ""], ["Apanasovich", "Tatiyana V.", ""], ["Joseph", "Jeffrey I.", ""]]}, {"id": "1407.8388", "submitter": "Olga Vsevolozhskaya", "authors": "Olga Vsevolozhskaya, Mark Greenwood, Dmitri Holodov", "title": "Pairwise comparison of treatment levels in functional analysis of\n  variance with application to erythrocyte hemolysis", "comments": "Published in at http://dx.doi.org/10.1214/14-AOAS723 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2014, Vol. 8, No. 2, 905-925", "doi": "10.1214/14-AOAS723", "report-no": "IMS-AOAS-AOAS723", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by a practical need for the comparison of hemolysis curves at\nvarious treatment levels, we propose a novel method for pairwise comparison of\nmean functional responses. The hemolysis curves - the percent hemolysis as a\nfunction of time - of mice erythrocytes (red blood cells) by hydrochloric acid\nhave been measured among different treatment levels. This data set fits well\nwithin the functional data analysis paradigm, in which a time series is\nconsidered as a realization of the underlying stochastic process or a smooth\ncurve. Previous research has only provided methods for identifying some\ndifferences in mean curves at different times. We propose a two-level follow-up\ntesting framework to allow comparisons of pairs of treatments within regions of\ntime where some difference among curves is identified. The closure multiplicity\nadjustment method is used to control the family-wise error rate of the proposed\nprocedure.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jul 2014 12:45:45 GMT"}], "update_date": "2014-08-01", "authors_parsed": [["Vsevolozhskaya", "Olga", ""], ["Greenwood", "Mark", ""], ["Holodov", "Dmitri", ""]]}, {"id": "1407.8392", "submitter": "Gagan Sidhu", "authors": "Gagan Sidhu, Brian Caffo", "title": "MONEYBaRL: Exploiting pitcher decision-making using Reinforcement\n  Learning", "comments": "Published in at http://dx.doi.org/10.1214/13-AOAS712 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2014, Vol. 8, No. 2, 926-955", "doi": "10.1214/13-AOAS712", "report-no": "IMS-AOAS-AOAS712", "categories": "cs.AI stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This manuscript uses machine learning techniques to exploit baseball\npitchers' decision making, so-called \"Baseball IQ,\" by modeling the at-bat\ninformation, pitch selection and counts, as a Markov Decision Process (MDP).\nEach state of the MDP models the pitcher's current pitch selection in a\nMarkovian fashion, conditional on the information immediately prior to making\nthe current pitch. This includes the count prior to the previous pitch, his\nensuing pitch selection, the batter's ensuing action and the result of the\npitch.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jul 2014 12:49:52 GMT"}], "update_date": "2014-08-01", "authors_parsed": [["Sidhu", "Gagan", ""], ["Caffo", "Brian", ""]]}, {"id": "1407.8398", "submitter": "Joshua N. Sampson", "authors": "Joshua N. Sampson, Bill Wheeler, Peng Li, Jianxin Shi", "title": "Leveraging local identity-by-descent increases the power of case/control\n  GWAS with related individuals", "comments": "Published in at http://dx.doi.org/10.1214/14-AOAS715 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2014, Vol. 8, No. 2, 974-998", "doi": "10.1214/14-AOAS715", "report-no": "IMS-AOAS-AOAS715", "categories": "stat.AP q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large case/control Genome-Wide Association Studies (GWAS) often include\ngroups of related individuals with known relationships. When testing for\nassociations at a given locus, current methods incorporate only the familial\nrelationships between individuals. Here, we introduce the chromosome-based\nQuasi Likelihood Score (cQLS) statistic that incorporates local\nIdentity-By-Descent (IBD) to increase the power to detect associations. In\nstudies robust to population stratification, such as those with case/control\nsibling pairs, simulations show that the study power can be increased by over\n50%. In our example, a GWAS examining late-onset Alzheimer's disease, the\n$p$-values among the most strongly associated SNPs in the APOE gene tend to\ndecrease, with the smallest $p$-value decreasing from $1.23\\times10^{-8}$ to\n$7.70\\times 10^{-9}$. Furthermore, as a part of our simulations, we reevaluate\nour expectations about the use of families in GWAS. We show that, although\nadding only half as many unique chromosomes, genotyping affected siblings is\nmore efficient than genotyping randomly ascertained cases. We also show that\ngenotyping cases with a family history of disease will be less beneficial when\nsearching for SNPs with smaller effect sizes.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jul 2014 13:02:37 GMT"}], "update_date": "2014-08-01", "authors_parsed": [["Sampson", "Joshua N.", ""], ["Wheeler", "Bill", ""], ["Li", "Peng", ""], ["Shi", "Jianxin", ""]]}, {"id": "1407.8399", "submitter": "Yize Zhao", "authors": "Yize Zhao, Jian Kang, Tianwei Yu", "title": "A Bayesian nonparametric mixture model for selecting genes and gene\n  subnetworks", "comments": "Published in at http://dx.doi.org/10.1214/14-AOAS719 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2014, Vol. 8, No. 2, 999-1021", "doi": "10.1214/14-AOAS719", "report-no": "IMS-AOAS-AOAS719", "categories": "stat.AP q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is very challenging to select informative features from tens of thousands\nof measured features in high-throughput data analysis. Recently, several\nparametric/regression models have been developed utilizing the gene network\ninformation to select genes or pathways strongly associated with a\nclinical/biological outcome. Alternatively, in this paper, we propose a\nnonparametric Bayesian model for gene selection incorporating network\ninformation. In addition to identifying genes that have a strong association\nwith a clinical outcome, our model can select genes with particular\nexpressional behavior, in which case the regression models are not directly\napplicable. We show that our proposed model is equivalent to an infinity\nmixture model for which we develop a posterior computation algorithm based on\nMarkov chain Monte Carlo (MCMC) methods. We also propose two fast computing\nalgorithms that approximate the posterior simulation with good accuracy but\nrelatively low computational cost. We illustrate our methods on simulation\nstudies and the analysis of Spellman yeast cell cycle microarray data.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jul 2014 13:05:38 GMT"}], "update_date": "2014-08-01", "authors_parsed": [["Zhao", "Yize", ""], ["Kang", "Jian", ""], ["Yu", "Tianwei", ""]]}, {"id": "1407.8401", "submitter": "Xuejing Wang", "authors": "Xuejing Wang, Bin Nan, Ji Zhu, Robert Koeppe", "title": "Regularized 3D functional regression for brain image data via Haar\n  wavelets", "comments": "Published in at http://dx.doi.org/10.1214/14-AOAS736 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2014, Vol. 8, No. 2, 1045-1064", "doi": "10.1214/14-AOAS736", "report-no": "IMS-AOAS-AOAS736", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The primary motivation and application in this article come from brain\nimaging studies on cognitive impairment in elderly subjects with brain\ndisorders. We propose a regularized Haar wavelet-based approach for the\nanalysis of three-dimensional brain image data in the framework of functional\ndata analysis, which automatically takes into account the spatial information\namong neighboring voxels. We conduct extensive simulation studies to evaluate\nthe prediction performance of the proposed approach and its ability to identify\nrelated regions to the outcome of interest, with the underlying assumption that\nonly few relatively small subregions are truly predictive of the outcome of\ninterest. We then apply the proposed approach to searching for brain subregions\nthat are associated with cognition using PET images of patients with\nAlzheimer's disease, patients with mild cognitive impairment and normal\ncontrols.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jul 2014 13:14:55 GMT"}, {"version": "v2", "created": "Fri, 8 Aug 2014 05:32:55 GMT"}], "update_date": "2014-08-11", "authors_parsed": [["Wang", "Xuejing", ""], ["Nan", "Bin", ""], ["Zhu", "Ji", ""], ["Koeppe", "Robert", ""]]}, {"id": "1407.8402", "submitter": "Finbarr O'Sullivan", "authors": "Finbarr O'Sullivan, Mark Muzi, David A. Mankoff, Janet F. Eary,\n  Alexander M. Spence, Kenneth A. Krohn", "title": "Voxel-level mapping of tracer kinetics in PET studies: A statistical\n  approach emphasizing tissue life tables", "comments": "Published in at http://dx.doi.org/10.1214/14-AOAS732 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2014, Vol. 8, No. 2, 1065-1094", "doi": "10.1214/14-AOAS732", "report-no": "IMS-AOAS-AOAS732", "categories": "stat.AP q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most radiotracers used in dynamic positron emission tomography (PET) scanning\nact in a linear time-invariant fashion so that the measured time-course data\nare a convolution between the time course of the tracer in the arterial supply\nand the local tissue impulse response, known as the tissue residue function. In\nstatistical terms the residue is a life table for the transit time of injected\nradiotracer atoms. The residue provides a description of the tracer kinetic\ninformation measurable by a dynamic PET scan. Decomposition of the residue\nfunction allows separation of rapid vascular kinetics from slower blood-tissue\nexchanges and tissue retention. For voxel-level analysis, we propose that\nresidues be modeled by mixtures of nonparametrically derived basis residues\nobtained by segmentation of the full data volume. Spatial and temporal aspects\nof diagnostics associated with voxel-level model fitting are emphasized.\nIllustrative examples, some involving cancer imaging studies, are presented.\nData from cerebral PET scanning with $^{18}$F fluoro-deoxyglucose (FDG) and\n$^{15}$O water (H2O) in normal subjects is used to evaluate the approach.\nCross-validation is used to make regional comparisons between residues\nestimated using adaptive mixture models with more conventional compartmental\nmodeling techniques. Simulations studies are used to theoretically examine mean\nsquare error performance and to explore the benefit of voxel-level analysis\nwhen the primary interest is a statistical summary of regional kinetics. The\nwork highlights the contribution that multivariate analysis tools and\nlife-table concepts can make in the recovery of local metabolic information\nfrom dynamic PET studies, particularly ones in which the assumptions of\ncompartmental-like models, with residues that are sums of exponentials, might\nnot be certain.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jul 2014 13:17:08 GMT"}], "update_date": "2014-08-01", "authors_parsed": [["O'Sullivan", "Finbarr", ""], ["Muzi", "Mark", ""], ["Mankoff", "David A.", ""], ["Eary", "Janet F.", ""], ["Spence", "Alexander M.", ""], ["Krohn", "Kenneth A.", ""]]}, {"id": "1407.8406", "submitter": "Tian Ge", "authors": "Tian Ge, Nicole M\\\"uller-Lenke, Kerstin Bendfeldt, Thomas E. Nichols,\n  Timothy D. Johnson", "title": "Analysis of multiple sclerosis lesions via spatially varying\n  coefficients", "comments": "Published in at http://dx.doi.org/10.1214/14-AOAS718 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2014, Vol. 8, No. 2, 1095-1118", "doi": "10.1214/14-AOAS718", "report-no": "IMS-AOAS-AOAS718", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Magnetic resonance imaging (MRI) plays a vital role in the scientific\ninvestigation and clinical management of multiple sclerosis. Analyses of binary\nmultiple sclerosis lesion maps are typically \"mass univariate\" and conducted\nwith standard linear models that are ill suited to the binary nature of the\ndata and ignore the spatial dependence between nearby voxels (volume elements).\nSmoothing the lesion maps does not entirely eliminate the non-Gaussian nature\nof the data and requires an arbitrary choice of the smoothing parameter. Here\nwe present a Bayesian spatial model to accurately model binary lesion maps and\nto determine if there is spatial dependence between lesion location and subject\nspecific covariates such as MS subtype, age, gender, disease duration and\ndisease severity measures. We apply our model to binary lesion maps derived\nfrom $T_2$-weighted MRI images from 250 multiple sclerosis patients classified\ninto five clinical subtypes, and demonstrate unique modeling and predictive\ncapabilities over existing methods.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jul 2014 13:33:30 GMT"}], "update_date": "2016-08-10", "authors_parsed": [["Ge", "Tian", ""], ["M\u00fcller-Lenke", "Nicole", ""], ["Bendfeldt", "Kerstin", ""], ["Nichols", "Thomas E.", ""], ["Johnson", "Timothy D.", ""]]}, {"id": "1407.8412", "submitter": "Jing Qin", "authors": "Jing Qin, Tanya P. Garcia, Yanyuan Ma, Ming-Xin Tang, Karen Marder,\n  Yuanjia Wang", "title": "Combining isotonic regression and EM algorithm to predict genetic risk\n  under monotonicity constraint", "comments": "Published in at http://dx.doi.org/10.1214/14-AOAS730 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2014, Vol. 8, No. 2, 1182-1208", "doi": "10.1214/14-AOAS730", "report-no": "IMS-AOAS-AOAS730", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In certain genetic studies, clinicians and genetic counselors are interested\nin estimating the cumulative risk of a disease for individuals with and without\na rare deleterious mutation. Estimating the cumulative risk is difficult,\nhowever, when the estimates are based on family history data. Often, the\ngenetic mutation status in many family members is unknown; instead, only\nestimated probabilities of a patient having a certain mutation status are\navailable. Also, ages of disease-onset are subject to right censoring. Existing\nmethods to estimate the cumulative risk using such family-based data only\nprovide estimation at individual time points, and are not guaranteed to be\nmonotonic or nonnegative. In this paper, we develop a novel method that\ncombines Expectation-Maximization and isotonic regression to estimate the\ncumulative risk across the entire support. Our estimator is monotonic,\nsatisfies self-consistent estimating equations and has high power in detecting\ndifferences between the cumulative risks of different populations. Application\nof our estimator to a Parkinson's disease (PD) study provides the age-at-onset\ndistribution of PD in PARK2 mutation carriers and noncarriers, and reveals a\nsignificant difference between the distribution in compound heterozygous\ncarriers compared to noncarriers, but not between heterozygous carriers and\nnoncarriers.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jul 2014 13:48:00 GMT"}], "update_date": "2014-08-01", "authors_parsed": [["Qin", "Jing", ""], ["Garcia", "Tanya P.", ""], ["Ma", "Yanyuan", ""], ["Tang", "Ming-Xin", ""], ["Marder", "Karen", ""], ["Wang", "Yuanjia", ""]]}]