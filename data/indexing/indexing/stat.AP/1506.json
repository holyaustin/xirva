[{"id": "1506.00185", "submitter": "Matthew Charles Edwards", "authors": "Matthew C. Edwards, Renate Meyer, Nelson Christensen", "title": "Bayesian semiparametric power spectral density estimation with\n  applications in gravitational wave data analysis", "comments": "15 pages, 15 figures", "journal-ref": "Phys. Rev. D 92, 064011 (2015)", "doi": "10.1103/PhysRevD.92.064011", "report-no": null, "categories": "gr-qc physics.data-an stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The standard noise model in gravitational wave (GW) data analysis assumes\ndetector noise is stationary and Gaussian distributed, with a known power\nspectral density (PSD) that is usually estimated using clean off-source data.\nReal GW data often depart from these assumptions, and misspecified parametric\nmodels of the PSD could result in misleading inferences. We propose a Bayesian\nsemiparametric approach to improve this. We use a nonparametric Bernstein\npolynomial prior on the PSD, with weights attained via a Dirichlet process\ndistribution, and update this using the Whittle likelihood. Posterior samples\nare obtained using a blocked Metropolis-within-Gibbs sampler. We simultaneously\nestimate the reconstruction parameters of a rotating core collapse supernova GW\nburst that has been embedded in simulated Advanced LIGO noise. We also discuss\nan approach to deal with non-stationary data by breaking longer data streams\ninto smaller and locally stationary components.\n", "versions": [{"version": "v1", "created": "Sun, 31 May 2015 02:17:35 GMT"}, {"version": "v2", "created": "Tue, 18 Aug 2015 11:37:35 GMT"}], "update_date": "2015-09-16", "authors_parsed": [["Edwards", "Matthew C.", ""], ["Meyer", "Renate", ""], ["Christensen", "Nelson", ""]]}, {"id": "1506.00219", "submitter": "Nikolai Slavov", "authors": "Alexander Franks, Edoardo Airoldi, Nikolai Slavov", "title": "Post-transcriptional regulation across human tissues", "comments": "30 pages, 4 figures", "journal-ref": "PLoS Comput Biol 13(5): e1005535 (2017)", "doi": "10.1371/journal.pcbi.1005535", "report-no": null, "categories": "q-bio.GN q-bio.QM q-bio.TO stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transcriptional and post-transcriptional regulation shape\ntissue-type-specific proteomes, but their relative contributions remain\ncontested. Estimates of the factors determining protein levels in human tissues\ndo not distinguish between (i) the factors determining the variability between\nthe abundances of different proteins, i.e., mean-level-variability and, (ii)\nthe factors determining the physiological variability of the same protein\nacross different tissue types, i.e., across-tissues variability. We sought to\nestimate the contribution of transcript levels to these two orthogonal sources\nof variability, and found that scaled mRNA levels can account for most of the\nmean-level-variability but not necessarily for across-tissues variability. The\nreliable quantification of the latter estimate is limited by substantial\nmeasurement noise. However, protein-to-mRNA ratios exhibit substantial\nacross-tissues variability that is functionally concerted and reproducible\nacross different datasets, suggesting extensive post-transcriptional\nregulation. These results caution against estimating protein fold-changes from\nmRNA fold-changes between different cell-types, and highlight the contribution\nof post-transcriptional regulation to shaping tissue-type-specific proteomes.\n", "versions": [{"version": "v1", "created": "Sun, 31 May 2015 11:52:05 GMT"}, {"version": "v2", "created": "Tue, 2 May 2017 15:38:55 GMT"}], "update_date": "2017-05-15", "authors_parsed": [["Franks", "Alexander", ""], ["Airoldi", "Edoardo", ""], ["Slavov", "Nikolai", ""]]}, {"id": "1506.00238", "submitter": "Bhavya Kailkhura", "authors": "Bhavya Kailkhura and Sijia Liu and Thakshila Wimalajeewa and Pramod K.\n  Varshney", "title": "Measurement Matrix Design for Compressive Detection with Secrecy\n  Guarantees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this letter, we consider the problem of detecting a high dimensional\nsignal based on compressed measurements with physical layer secrecy guarantees.\nWe assume that the network operates in the presence of an eavesdropper who\nintends to discover the state of the nature being monitored by the system. We\ndesign measurement matrices which maximize the detection performance of the\nnetwork while guaranteeing a certain level of secrecy. We solve the measurement\nmatrix design problem under three different scenarios: $a)$ signal is known,\n$b)$ signal lies in a low dimensional subspace, and $c)$ signal is sparse. It\nis shown that the security performance of the system can be improved by using\noptimized measurement matrices along with artificial noise injection based\ntechniques.\n", "versions": [{"version": "v1", "created": "Sun, 31 May 2015 14:31:43 GMT"}], "update_date": "2015-06-02", "authors_parsed": [["Kailkhura", "Bhavya", ""], ["Liu", "Sijia", ""], ["Wimalajeewa", "Thakshila", ""], ["Varshney", "Pramod K.", ""]]}, {"id": "1506.00356", "submitter": "Kay H. Brodersen", "authors": "Kay H. Brodersen, Fabian Gallusser, Jim Koehler, Nicolas Remy, Steven\n  L. Scott", "title": "Inferring causal impact using Bayesian structural time-series models", "comments": "Published at http://dx.doi.org/10.1214/14-AOAS788 in the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2015, Vol. 9, No. 1, 247-274", "doi": "10.1214/14-AOAS788", "report-no": "IMS-AOAS-AOAS788", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important problem in econometrics and marketing is to infer the causal\nimpact that a designed market intervention has exerted on an outcome metric\nover time. This paper proposes to infer causal impact on the basis of a\ndiffusion-regression state-space model that predicts the counterfactual market\nresponse in a synthetic control that would have occurred had no intervention\ntaken place. In contrast to classical difference-in-differences schemes,\nstate-space models make it possible to (i) infer the temporal evolution of\nattributable impact, (ii) incorporate empirical priors on the parameters in a\nfully Bayesian treatment, and (iii) flexibly accommodate multiple sources of\nvariation, including local trends, seasonality and the time-varying influence\nof contemporaneous covariates. Using a Markov chain Monte Carlo algorithm for\nposterior inference, we illustrate the statistical properties of our approach\non simulated data. We then demonstrate its practical utility by estimating the\ncausal effect of an online advertising campaign on search-related site visits.\nWe discuss the strengths and limitations of state-space models in enabling\ncausal attribution in those settings where a randomised experiment is\nunavailable. The CausalImpact R package provides an implementation of our\napproach.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2015 05:55:13 GMT"}], "update_date": "2015-06-02", "authors_parsed": [["Brodersen", "Kay H.", ""], ["Gallusser", "Fabian", ""], ["Koehler", "Jim", ""], ["Remy", "Nicolas", ""], ["Scott", "Steven L.", ""]]}, {"id": "1506.00360", "submitter": "Danping Liu", "authors": "Kara A. Fulton, Danping Liu, Denise L. Haynie, Paul S. Albert", "title": "Mixed model and estimating equation approaches for zero inflation in\n  clustered binary response data with application to a dating violence study", "comments": "Published at http://dx.doi.org/10.1214/14-AOAS791 in the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2015, Vol. 9, No. 1, 275-299", "doi": "10.1214/14-AOAS791", "report-no": "IMS-AOAS-AOAS791", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The NEXT Generation Health study investigates the dating violence of\nadolescents using a survey questionnaire. Each student is asked to affirm or\ndeny multiple instances of violence in his/her dating relationship. There is,\nhowever, evidence suggesting that students not in a relationship responded to\nthe survey, resulting in excessive zeros in the responses. This paper proposes\nlikelihood-based and estimating equation approaches to analyze the\nzero-inflated clustered binary response data. We adopt a mixed model method to\naccount for the cluster effect, and the model parameters are estimated using a\nmaximum-likelihood (ML) approach that requires a Gaussian-Hermite quadrature\n(GHQ) approximation for implementation. Since an incorrect assumption on the\nrandom effects distribution may bias the results, we construct generalized\nestimating equations (GEE) that do not require the correct specification of\nwithin-cluster correlation. In a series of simulation studies, we examine the\nperformance of ML and GEE methods in terms of their bias, efficiency and\nrobustness. We illustrate the importance of properly accounting for this zero\ninflation by reanalyzing the NEXT data where this issue has previously been\nignored.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2015 06:46:47 GMT"}], "update_date": "2015-06-02", "authors_parsed": [["Fulton", "Kara A.", ""], ["Liu", "Danping", ""], ["Haynie", "Denise L.", ""], ["Albert", "Paul S.", ""]]}, {"id": "1506.00403", "submitter": "Cecile Low-Kam", "authors": "Cecile Low-Kam, Donatello Telesca, Zhaoxia Ji, Haiyuan Zhang, Tian\n  Xia, Jeffrey I. Zink, Andre E. Nel", "title": "A Bayesian regression tree approach to identify the effect of\n  nanoparticles' properties on toxicity profiles", "comments": "Published at http://dx.doi.org/10.1214/14-AOAS797 in the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2015, Vol. 9, No. 1, 383-401", "doi": "10.1214/14-AOAS797", "report-no": "IMS-AOAS-AOAS797", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a Bayesian multiple regression tree model to characterize\nrelationships between physico-chemical properties of nanoparticles and their\nin-vitro toxicity over multiple doses and times of exposure. Unlike\nconventional models that rely on data summaries, our model solves the low\nsample size issue and avoids arbitrary loss of information by combining all\nmeasurements from a general exposure experiment across doses, times of\nexposure, and replicates. The proposed technique integrates Bayesian trees for\nmodeling threshold effects and interactions, and penalized B-splines for dose-\nand time-response surface smoothing. The resulting posterior distribution is\nsampled by Markov Chain Monte Carlo. This method allows for inference on a\nnumber of quantities of potential interest to substantive nanotoxicology, such\nas the importance of physico-chemical properties and their marginal effect on\ntoxicity. We illustrate the application of our method to the analysis of a\nlibrary of 24 nano metal oxides.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2015 09:33:08 GMT"}], "update_date": "2015-06-02", "authors_parsed": [["Low-Kam", "Cecile", ""], ["Telesca", "Donatello", ""], ["Ji", "Zhaoxia", ""], ["Zhang", "Haiyuan", ""], ["Xia", "Tian", ""], ["Zink", "Jeffrey I.", ""], ["Nel", "Andre E.", ""]]}, {"id": "1506.00429", "submitter": "Sai Xiao", "authors": "Sai Xiao, Athanasios Kottas, Bruno Sans\\'o", "title": "Modeling for seasonal marked point processes: An analysis of evolving\n  hurricane occurrences", "comments": "Published at http://dx.doi.org/10.1214/14-AOAS796 in the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2015, Vol. 9, No. 1, 353-382", "doi": "10.1214/14-AOAS796", "report-no": "IMS-AOAS-AOAS796", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Seasonal point processes refer to stochastic models for random events which\nare only observed in a given season. We develop nonparametric Bayesian\nmethodology to study the dynamic evolution of a seasonal marked point process\nintensity. We assume the point process is a nonhomogeneous Poisson process and\npropose a nonparametric mixture of beta densities to model dynamically evolving\ntemporal Poisson process intensities. Dependence structure is built through a\ndependent Dirichlet process prior for the seasonally-varying mixing\ndistributions. We extend the nonparametric model to incorporate time-varying\nmarks, resulting in flexible inference for both the seasonal point process\nintensity and for the conditional mark distribution. The motivating application\ninvolves the analysis of hurricane landfalls with reported damages along the\nU.S. Gulf and Atlantic coasts from 1900 to 2010. We focus on studying the\nevolution of the intensity of the process of hurricane landfall occurrences,\nand the respective maximum wind speed and associated damages. Our results\nindicate an increase in the number of hurricane landfall occurrences and a\ndecrease in the median maximum wind speed at the peak of the season.\nIntroducing standardized damage as a mark, such that reported damages are\ncomparable both in time and space, we find that there is no significant rising\ntrend in hurricane damages over time.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2015 10:30:00 GMT"}], "update_date": "2016-08-08", "authors_parsed": [["Xiao", "Sai", ""], ["Kottas", "Athanasios", ""], ["Sans\u00f3", "Bruno", ""]]}, {"id": "1506.00474", "submitter": "Lorenzo Trippa", "authors": "Lorenzo Trippa, Levi Waldron, Curtis Huttenhower, Giovanni Parmigiani", "title": "Bayesian nonparametric cross-study validation of prediction methods", "comments": "Published at http://dx.doi.org/10.1214/14-AOAS798 in the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2015, Vol. 9, No. 1, 402-428", "doi": "10.1214/14-AOAS798", "report-no": "IMS-AOAS-AOAS798", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider comparisons of statistical learning algorithms using multiple\ndata sets, via leave-one-in cross-study validation: each of the algorithms is\ntrained on one data set; the resulting model is then validated on each\nremaining data set. This poses two statistical challenges that need to be\naddressed simultaneously. The first is the assessment of study heterogeneity,\nwith the aim of identifying a subset of studies within which algorithm\ncomparisons can be reliably carried out. The second is the comparison of\nalgorithms using the ensemble of data sets. We address both problems by\nintegrating clustering and model comparison. We formulate a Bayesian model for\nthe array of cross-study validation statistics, which defines clusters of\nstudies with similar properties and provides the basis for meaningful algorithm\ncomparison in the presence of study heterogeneity. We illustrate our approach\nthrough simulations involving studies with varying severity of systematic\nerrors, and in the context of medical prognosis for patients diagnosed with\ncancer, using high-throughput measurements of the transcriptional activity of\nthe tumor's genes.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2015 12:36:12 GMT"}], "update_date": "2015-06-02", "authors_parsed": [["Trippa", "Lorenzo", ""], ["Waldron", "Levi", ""], ["Huttenhower", "Curtis", ""], ["Parmigiani", "Giovanni", ""]]}, {"id": "1506.00480", "submitter": "Zhixiang Lin", "authors": "Zhixiang Lin, Stephan J. Sanders, Mingfeng Li, Nenad Sestan, Matthew\n  W. State, Hongyu Zhao", "title": "A Markov random field-based approach to characterizing human brain\n  development using spatial-temporal transcriptome data", "comments": "Published at http://dx.doi.org/10.1214/14-AOAS802 in the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2015, Vol. 9, No. 1, 429-451", "doi": "10.1214/14-AOAS802", "report-no": "IMS-AOAS-AOAS802", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human neurodevelopment is a highly regulated biological process. In this\narticle, we study the dynamic changes of neurodevelopment through the analysis\nof human brain microarray data, sampled from 16 brain regions in 15 time\nperiods of neurodevelopment. We develop a two-step inferential procedure to\nidentify expressed and unexpressed genes and to detect differentially expressed\ngenes between adjacent time periods. Markov Random Field (MRF) models are used\nto efficiently utilize the information embedded in brain region similarity and\ntemporal dependency in our approach. We develop and implement a Monte Carlo\nexpectation-maximization (MCEM) algorithm to estimate the model parameters.\nSimulation studies suggest that our approach achieves lower misclassification\nerror and potential gain in power compared with models not incorporating\nspatial similarity and temporal dependency.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2015 12:56:00 GMT"}], "update_date": "2015-06-02", "authors_parsed": [["Lin", "Zhixiang", ""], ["Sanders", "Stephan J.", ""], ["Li", "Mingfeng", ""], ["Sestan", "Nenad", ""], ["State", "Matthew W.", ""], ["Zhao", "Hongyu", ""]]}, {"id": "1506.00728", "submitter": "Li Liu", "authors": "Li Liu, Jing Lei, Kathryn Roeder", "title": "Network assisted analysis to reveal the genetic basis of autism", "comments": "Published at http://dx.doi.org/10.1214/15-AOAS844 in the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2015, Vol. 9, No. 3, 1571-1600", "doi": "10.1214/15-AOAS844", "report-no": "IMS-AOAS-AOAS844", "categories": "stat.ME stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While studies show that autism is highly heritable, the nature of the genetic\nbasis of this disorder remains illusive. Based on the idea that highly\ncorrelated genes are functionally interrelated and more likely to affect risk,\nwe develop a novel statistical tool to find more potentially autism risk genes\nby combining the genetic association scores with gene co-expression in specific\nbrain regions and periods of development. The gene dependence network is\nestimated using a novel partial neighborhood selection (PNS) algorithm, where\nnode specific properties are incorporated into network estimation for improved\nstatistical and computational efficiency. Then we adopt a hidden Markov random\nfield (HMRF) model to combine the estimated network and the genetic association\nscores in a systematic manner. The proposed modeling framework can be naturally\nextended to incorporate additional structural information concerning the\ndependence between genes. Using currently available genetic association data\nfrom whole exome sequencing studies and brain gene expression levels, the\nproposed algorithm successfully identified 333 genes that plausibly affect\nautism risk.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2015 02:21:49 GMT"}, {"version": "v2", "created": "Thu, 18 Jun 2015 03:37:51 GMT"}, {"version": "v3", "created": "Tue, 17 Nov 2015 12:58:52 GMT"}], "update_date": "2015-11-18", "authors_parsed": [["Liu", "Li", ""], ["Lei", "Jing", ""], ["Roeder", "Kathryn", ""]]}, {"id": "1506.00947", "submitter": "Mahamat Ali Issaka", "authors": "Mahamat Ali Issaka, Ali S. Dabye, Lamine Gueye", "title": "Localization of epileptic seizure with an approach based on the PSD with\n  an autoregressive model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  In this study, we present a criterion based on the analysis of EEG signals\nthrough the mean of the conventional power spectral density (PSD) in the aim to\nlocalize and detect the epileptic area of the brain. Firstly, as the EEG\nsignals are commonly non stationary in practice, we processed the data with\ntechnique of differentiation in order to have the stationary which is\nconvenient to model with autoregressive model (AR). For this, we have used many\ntechniques for to determine the order which model better the data in this work.\nTherefore, we can characterize normal and abnormal activity which correspond to\nepileptic discharge for the patient. Our contribution in this work is the\nautomatic detection of epilepsy seizure with the PSD novel approach by a better\nresolution in the frequency domain as the examination of EEG signals is often\ndone with visual inspection of the rhythm (delta, theta, alpha, beta, gamma) by\nneurologists practitioners. The accuracy of the detection is estimated to 70%\nwith the sensitivity of 80.55% compared with the interpretation of neurologist.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2015 16:29:40 GMT"}], "update_date": "2016-10-31", "authors_parsed": [["Issaka", "Mahamat Ali", ""], ["Dabye", "Ali S.", ""], ["Gueye", "Lamine", ""]]}, {"id": "1506.01281", "submitter": "Andrea Mercatanti", "authors": "Andrea Mercatanti, Fan Li", "title": "Do debit cards decrease cash demand? Evidence from a causal analysis\n  using Principal Stratification", "comments": "29 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been argued that innovation in transaction technology may modify the\ncash holding behaviour of agents, as debit card holders may either withdraw\ncash from ATMs or purchase items using POS devices at retailers. In this paper,\nwithin the Rubin Causal Model, we investigate the causal effects of the use of\ndebit cards on the cash inventories held by households using data from the\nItaly Survey of Household Income and Wealth (SHIW). We adopt the principal\nstratification approach to incorporate the share of debit card holders who do\nnot use this payment instrument. We use a regression model with the propensity\nscore as the single predictor to adjust for the imbalance in observed\ncovariates. We further develop a sensitivity analysis approach to assess the\nsensitivity of the proposed model to violation to the key unconfoundedness\nassumption. Our empirical results suggest statistically significant negative\neffects of debit cards on the household cash level in Italy.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jun 2015 15:35:25 GMT"}], "update_date": "2015-06-04", "authors_parsed": [["Mercatanti", "Andrea", ""], ["Li", "Fan", ""]]}, {"id": "1506.01388", "submitter": "Ioannis Kosmidis", "authors": "Ioannis Kosmidis and Louis Passfield", "title": "Linking the performance of endurance runners to training and\n  physiological effects via multi-resolution elastic net", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A multiplicative effects model is introduced for the identification of the\nfactors that are influential to the performance of highly-trained endurance\nrunners. The model extends the established power-law relationship between\nperformance times and distances by taking into account the effect of the\nphysiological status of the runners, and training effects extracted from GPS\nrecords collected over the course of a year. In order to incorporate\ninformation on the runners' training into the model, the concept of the\ntraining distribution profile is introduced and its ability to capture the\ncharacteristics of the training session is discussed. The covariates that are\nrelevant to runner performance as response are identified using a procedure\ntermed multi-resolution elastic net. Multi-resolution elastic net allows the\nsimultaneous identification of scalar covariates and of intervals on the domain\nof one or more functional covariates that are most influential for the\nresponse. The results identify a contiguous group of speed intervals between\n5.3 to 5.7 m$\\cdot$s$^{-1}$ as influential for the improvement of running\nperformance and extend established relationships between physiological status\nand runner performance. Another outcome of multi-resolution elastic net is a\npredictive equation for performance based on the minimization of the mean\nsquared prediction error on a test data set across resolutions.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jun 2015 20:14:15 GMT"}, {"version": "v2", "created": "Wed, 1 Jul 2015 13:30:58 GMT"}], "update_date": "2015-07-02", "authors_parsed": [["Kosmidis", "Ioannis", ""], ["Passfield", "Louis", ""]]}, {"id": "1506.01589", "submitter": "Ines Wilms", "authors": "Sarah Gelper, Ines Wilms, Christophe Croux", "title": "Identifying Demand Effects in a Large Network of Product Categories", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Planning marketing mix strategies requires retailers to understand within- as\nwell as cross-category demand effects. Most retailers carry products in a large\nvariety of categories, leading to a high number of such demand effects to be\nestimated. At the same time, we do not expect cross-category effects between\nall categories. This paper outlines a methodology to estimate a parsimonious\nproduct category network without prior constraints on its structure. To do so,\nsparse estimation of the Vector AutoRegressive Market Response Model is\npresented. We find that cross-category effects go beyond substitutes and\ncomplements, and that categories have asymmetric roles in the product category\nnetwork. Destination categories are most influential for other product\ncategories, while convenience and occasional categories are most responsive.\nRoutine categories are moderately influential and moderately responsive.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2015 13:43:26 GMT"}], "update_date": "2015-06-05", "authors_parsed": [["Gelper", "Sarah", ""], ["Wilms", "Ines", ""], ["Croux", "Christophe", ""]]}, {"id": "1506.01976", "submitter": "Jeffrey Peters", "authors": "Jeffrey R. Peters, Amit Surana, Luca Bertuccelli", "title": "Eye-Tracking Metrics for Task-Based Supervisory Control", "comments": "6 pages, 4 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Task-based, rather than vehicle-based, control architectures have been shown\nto provide superior performance in certain human supervisory control missions.\nThese results motivate the need for the development of robust, reliable\nusability metrics to aid in creating interfaces for use in this domain. To this\nend, we conduct a pilot usability study of a particular task-based supervisory\ncontrol interface called the Research Environment for Supervisory Control of\nHeterogenous Unmanned Vehicles (RESCHU). In particular, we explore the use of\neye-tracking metrics as an objective means of evaluating the RESCHU interface\nand providing guidance in improving usability. Our main goals for this study\nare to 1) better understand how eye-tracking can augment standard usability\nmetrics, 2) formulate initial models of operator behavior, and 3) identify\ninteresting areas of future research.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2015 17:08:28 GMT"}], "update_date": "2015-06-08", "authors_parsed": [["Peters", "Jeffrey R.", ""], ["Surana", "Amit", ""], ["Bertuccelli", "Luca", ""]]}, {"id": "1506.02169", "submitter": "Kyle S. Cranmer", "authors": "Kyle Cranmer, Juan Pavez, Gilles Louppe", "title": "Approximating Likelihood Ratios with Calibrated Discriminative\n  Classifiers", "comments": "35 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many fields of science, generalized likelihood ratio tests are established\ntools for statistical inference. At the same time, it has become increasingly\ncommon that a simulator (or generative model) is used to describe complex\nprocesses that tie parameters $\\theta$ of an underlying theory and measurement\napparatus to high-dimensional observations $\\mathbf{x}\\in \\mathbb{R}^p$.\nHowever, simulator often do not provide a way to evaluate the likelihood\nfunction for a given observation $\\mathbf{x}$, which motivates a new class of\nlikelihood-free inference algorithms. In this paper, we show that likelihood\nratios are invariant under a specific class of dimensionality reduction maps\n$\\mathbb{R}^p \\mapsto \\mathbb{R}$. As a direct consequence, we show that\ndiscriminative classifiers can be used to approximate the generalized\nlikelihood ratio statistic when only a generative model for the data is\navailable. This leads to a new machine learning-based approach to\nlikelihood-free inference that is complementary to Approximate Bayesian\nComputation, and which does not require a prior on the model parameters.\nExperimental results on artificial problems with known exact likelihoods\nillustrate the potential of the proposed method.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jun 2015 16:59:23 GMT"}, {"version": "v2", "created": "Fri, 18 Mar 2016 16:47:11 GMT"}], "update_date": "2016-03-21", "authors_parsed": [["Cranmer", "Kyle", ""], ["Pavez", "Juan", ""], ["Louppe", "Gilles", ""]]}, {"id": "1506.02276", "submitter": "Edmondo Di Giuseppe", "authors": "Edmondo Di Giuseppe, Giovanna Jona Lasinio, Massimiliano Pasqui,\n  Stanislao Esposito", "title": "Tools for predicting rainfall from lightning records: events\n  identification and rain prediction using a Bayesian hierarchical model", "comments": "37 pages, 10 figures, 15 tables; Corrected typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new statistical protocol for the estimation of precipitation\nusing lightning data. We first identify rainy events using a scan statistics,\nthen we estimate Rainfall Lighting Ratio (RLR) to convert lightning number into\nrain volume given the storm intensity. Then we build a hierarchical Bayesian\nmodel aiming at the prediction of 15- and 30-minutes cumulated precipitation at\nunobserved locations and time using information on lightning in the same area.\nMore specifically, we build a Bayesian hierarchical model in which\nprecipitation is modeled as function of lightning count and space time\nvariation is handled using specific structured (random) effects. The mean\ncomponent of the model relates precipitation and lightning assuming that the\nnumber of lightning recorded on a regular grid depends on the number of\nlightning occurring in neighboring cells. We analyze several model formulations\nwhere storms propagation speed, spatial dependence and time variation\nincorporates different descriptions of the phenomena at hand. The space-time\nvariation is assumed separable. The study area is located in Central Italy,\nwhere two storms, that differ for duration and intensity, are presented.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jun 2015 15:35:48 GMT"}, {"version": "v2", "created": "Sun, 14 Jun 2015 14:51:44 GMT"}], "update_date": "2015-06-16", "authors_parsed": [["Di Giuseppe", "Edmondo", ""], ["Lasinio", "Giovanna Jona", ""], ["Pasqui", "Massimiliano", ""], ["Esposito", "Stanislao", ""]]}, {"id": "1506.02570", "submitter": "M. R. Danaee", "authors": "Meysam R. Danaee", "title": "Unscented Auxiliary Particle Filter Implementation of the Cardinalized\n  Probability Hypothesis Density Filter", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The probability hypothesis density (PHD) filter alleviates the computational\nexpense of the optimal Bayesian multi-target filtering by approximating the\nintensity function of the random finite set (RFS) of targets in time. However,\nas a powerful decluttering algorithm, it suffers from lack of the precise\nestimation of the expected number of targets. The cardinalized PHD (CPHD)\nrecursion, as a generalization of the PHD recursion, is to remedy this flaw,\nwhich jointly propagates the intensity function and the posterior cardinality\ndistribution. While there are a few new approaches to enhance the Sequential\nMonte Carlo (SMC) implementation of the PHD filter, current SMC implementation\nfor the CPHD filter suffers from poor performance in terms of accuracy of\nestimate. In this paper, based on the unscented transform (UT), we propose an\nauxiliary implementation of the CPHD filter for highly nonlinear systems. To\nthat end, we approximate the elementary symmetric functions both with the\npredicted and with the update estimate of the linear functional. We\nsubsequently demonstrate via numerical simulations that our algorithms\nsignificantly out performs both the SMC-CPHD filter and the auxiliary particle\nimplementation of the PHD filter in difficult situations with high clutter. We\nalso compare our proposed algorithm with its counterparts in terms of other\nmetrics, such as run times and sensitivity to new target appearance.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2015 16:19:22 GMT"}], "update_date": "2015-06-09", "authors_parsed": [["Danaee", "Meysam R.", ""]]}, {"id": "1506.02594", "submitter": "Qingyuan Zhao", "authors": "Qingyuan Zhao, Murat A. Erdogdu, Hera Y. He, Anand Rajaraman, Jure\n  Leskovec", "title": "SEISMIC: A Self-Exciting Point Process Model for Predicting Tweet\n  Popularity", "comments": "10 pages, published in KDD 2015", "journal-ref": "KDD '15, Proceedings of the 21th ACM SIGKDD International\n  Conference on Knowledge Discovery and Data Mining (2015), Pages 1513-1522", "doi": "10.1145/2783258.2783401", "report-no": null, "categories": "cs.SI physics.soc-ph stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social networking websites allow users to create and share content. Big\ninformation cascades of post resharing can form as users of these sites reshare\nothers' posts with their friends and followers. One of the central challenges\nin understanding such cascading behaviors is in forecasting information\noutbreaks, where a single post becomes widely popular by being reshared by many\nusers. In this paper, we focus on predicting the final number of reshares of a\ngiven post. We build on the theory of self-exciting point processes to develop\na statistical model that allows us to make accurate predictions. Our model\nrequires no training or expensive feature engineering. It results in a simple\nand efficiently computable formula that allows us to answer questions, in\nreal-time, such as: Given a post's resharing history so far, what is our\ncurrent estimate of its final number of reshares? Is the post resharing cascade\npast the initial stage of explosive growth? And, which posts will be the most\nreshared in the future? We validate our model using one month of complete\nTwitter data and demonstrate a strong improvement in predictive accuracy over\nexisting approaches. Our model gives only 15% relative error in predicting\nfinal size of an average information cascade after observing it for just one\nhour.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2015 17:41:53 GMT"}], "update_date": "2016-01-28", "authors_parsed": [["Zhao", "Qingyuan", ""], ["Erdogdu", "Murat A.", ""], ["He", "Hera Y.", ""], ["Rajaraman", "Anand", ""], ["Leskovec", "Jure", ""]]}, {"id": "1506.02735", "submitter": "Luis Enrique Correa Rocha Dr", "authors": "Luis E. C. Rocha and Anna E. Thorson and Renaud Lambiotte", "title": "The non-linear health consequences of living in larger cities", "comments": "12 pages", "journal-ref": "Journal of Urban Health 92, 785 (2015)", "doi": "10.1007/s11524-015-9976-x", "report-no": null, "categories": "physics.soc-ph stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Urbanization promotes economy, mobility, access and availability of\nresources, but on the other hand, generates higher levels of pollution,\nviolence, crime, and mental distress. The health consequences of the\nagglomeration of people living close together are not fully understood.\nParticularly, it remains unclear how variations in the population size across\ncities impact the health of the population. We analyze the deviations from\nlinearity of the scaling of several health-related quantities, such as the\nincidence and mortality of diseases, external causes of death, wellbeing, and\nhealth-care availability, in respect to the population size of cities in\nBrazil, Sweden and the USA. We find that deaths by non-communicable diseases\ntend to be relatively less common in larger cities, whereas the per-capita\nincidence of infectious diseases is relatively larger for increasing population\nsize. Healthier life style and availability of medical support are\ndisproportionally higher in larger cities. The results are connected with the\noptimization of human and physical resources, and with the non-linear effects\nof social networks in larger populations. An urban advantage in terms of health\nis not evident and using rates as indicators to compare cities with different\npopulation sizes may be insufficient.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2015 00:42:49 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Rocha", "Luis E. C.", ""], ["Thorson", "Anna E.", ""], ["Lambiotte", "Renaud", ""]]}, {"id": "1506.02927", "submitter": "Juliette Spinnato", "authors": "Juliette Spinnato (LNC, I2M), Marie-Christine Roubaud (I2M), Margaux\n  Perrin, Emmanuel Maby, Jeremie Mattout, Boris Burle (LNC), Bruno Torr\\'esani\n  (I2M)", "title": "Analyse discriminante matricielle descriptive. Application a l'\\'etude\n  de signaux EEG", "comments": "in French, Journ{\\'e}es de statistique de la SFDS, Jun 2015, Lille,\n  France", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We focus on the descriptive approach to linear discriminant analysis for\nmatrix-variate data in the binary case. Under a separability assumption on row\nand column variability, the most discriminant linear combinations of rows and\ncolumns are determined by the singular value decomposition of the difference of\nthe class-averages with the Mahalanobis metric in the row and column spaces.\nThis approach provides data representations of data in two-dimensional or\nthree-dimensional plots and singles out discriminant components. An application\nto electroencephalographic multi-sensor signals illustrates the relevance of\nthe method.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2015 14:24:17 GMT"}], "update_date": "2015-06-10", "authors_parsed": [["Spinnato", "Juliette", "", "LNC, I2M"], ["Roubaud", "Marie-Christine", "", "I2M"], ["Perrin", "Margaux", "", "LNC"], ["Maby", "Emmanuel", "", "LNC"], ["Mattout", "Jeremie", "", "LNC"], ["Burle", "Boris", "", "LNC"], ["Torr\u00e9sani", "Bruno", "", "I2M"]]}, {"id": "1506.02940", "submitter": "Luca Di Persio", "authors": "Luca Di Persio", "title": "Autoregressive approaches to import-export time series I: basic\n  techniques", "comments": "Published at http://dx.doi.org/10.15559/15-VMSTA22 in the Modern\n  Stochastics: Theory and Applications (https://www.i-journals.org/vtxpp/VMSTA)\n  by VTeX (http://www.vtex.lt/)", "journal-ref": "Modern Stochastics: Theory and Applications 2015, Vol. 2, No. 1,\n  51-65", "doi": "10.15559/15-VMSTA22", "report-no": "VTeX-VMSTA-VMSTA22", "categories": "stat.AP math.PR q-fin.ST stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work is the first part of a project dealing with an in-depth study of\neffective techniques used in econometrics in order to make accurate forecasts\nin the concrete framework of one of the major economies of the most productive\nItalian area, namely the province of Verona. In particular, we develop an\napproach mainly based on vector autoregressions, where lagged values of two or\nmore variables are considered, Granger causality, and the stochastic trend\napproach useful to work with the cointegration phenomenon. Latter techniques\nconstitute the core of the present paper, whereas in the second part of the\nproject, we present how these approaches can be applied to economic data at our\ndisposal in order to obtain concrete analysis of import--export behavior for\nthe considered productive area of Verona.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2015 07:23:44 GMT"}], "update_date": "2015-06-10", "authors_parsed": [["Di Persio", "Luca", ""]]}, {"id": "1506.03104", "submitter": "James Peirce Jr.", "authors": "Eric Eager, Megan Eberle and James Peirce", "title": "How Infectious Was #Deflategate?", "comments": "12 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI physics.soc-ph q-bio.PE stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  On Monday January 19, 2015 a story broke that the National Football League\n(NFL) had started an investigation into whether the New England Patriots\ndeliberately deflated the footballs they used during their championship win\nover the Indianapolis Colts. Like an infectious disease, discussion regarding\nDeflategate grew rapidly on social media sites in the hours and days after the\nrelease of the story. However, after the Super Bowl was over, the scandal\nslowly began to dissipate and lost much of the attention it had originally had,\nas interest in the NFL wained at the completion of its season. We construct a\nsimple epidemic model for the infectiousness of the Deflategate news story. We\nthen use data from the social media site Twitter to estimate the parameters of\nthis model using standard techniques from the study of inverse problems. We\nfind that the infectiousness (as measured by the basic reproduction number) of\nDeflategate rivals that of any infectious disease that we are aware of, and is\nactually more infectious than recent news stories of greater importance - both\nin terms of the basic reproduction number and in terms of the average amount of\ntime the average tweeter continued to tweet about the news story.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2015 21:09:53 GMT"}], "update_date": "2015-06-11", "authors_parsed": [["Eager", "Eric", ""], ["Eberle", "Megan", ""], ["Peirce", "James", ""]]}, {"id": "1506.03157", "submitter": "Sergiusz Wesolowski", "authors": "Sergiusz Wesolowski, Robert J. Contreras, Wei Wu", "title": "A new framework for Euclidean summary statistics in the neural spike\n  train space", "comments": "Published at http://dx.doi.org/10.1214/15-AOAS847 in the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2015, Vol. 9, No. 3, 1278-1297", "doi": "10.1214/15-AOAS847", "report-no": "IMS-AOAS-AOAS847", "categories": "q-bio.NC stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical analysis and inference on spike trains is one of the central\ntopics in the neural coding. It is of great interest to understand the\nunderlying structure of given neural data. Based on the metric distances\nbetween spike trains, recent investigations have introduced the notion of an\naverage or prototype spike train to characterize the template pattern in the\nneural activity. However, as those metrics lack certain Euclidean properties,\nthe defined averages are nonunique, and do not share the conventional\nproperties of a mean. In this article, we propose a new framework to define the\nmean spike train where we adopt a Euclidean-like metric from an $L^p$ family.\nWe demonstrate that this new mean spike train properly represents the average\npattern in the conventional fashion, and can be effectively computed using a\ntheoretically-proven convergent procedure. We compare this mean with other\nspike train averages and demonstrate its superiority. Furthermore, we apply the\nnew framework in a recording from rodent geniculate ganglion, where background\nfiring activity is a common issue for neural coding. We show that the proposed\nmean spike train can be utilized to remove the background noise and improve\ndecoding performance.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2015 03:57:32 GMT"}, {"version": "v2", "created": "Thu, 5 Nov 2015 14:15:51 GMT"}], "update_date": "2015-11-06", "authors_parsed": [["Wesolowski", "Sergiusz", ""], ["Contreras", "Robert J.", ""], ["Wu", "Wei", ""]]}, {"id": "1506.03493", "submitter": "Aaron Schein", "authors": "Aaron Schein, John Paisley, David M. Blei, Hanna Wallach", "title": "Bayesian Poisson Tensor Factorization for Inferring Multilateral\n  Relations from Sparse Dyadic Event Counts", "comments": "To appear in Proceedings of the 21st ACM SIGKDD Conference of\n  Knowledge Discovery and Data Mining (KDD 2015)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG cs.SI stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a Bayesian tensor factorization model for inferring latent group\nstructures from dynamic pairwise interaction patterns. For decades, political\nscientists have collected and analyzed records of the form \"country $i$ took\naction $a$ toward country $j$ at time $t$\"---known as dyadic events---in order\nto form and test theories of international relations. We represent these event\ndata as a tensor of counts and develop Bayesian Poisson tensor factorization to\ninfer a low-dimensional, interpretable representation of their salient\npatterns. We demonstrate that our model's predictive performance is better than\nthat of standard non-negative tensor factorization methods. We also provide a\ncomparison of our variational updates to their maximum likelihood counterparts.\nIn doing so, we identify a better way to form point estimates of the latent\nfactors than that typically used in Bayesian Poisson matrix factorization.\nFinally, we showcase our model as an exploratory analysis tool for political\nscientists. We show that the inferred latent factor matrices capture\ninterpretable multilateral relations that both conform to and inform our\nknowledge of international affairs.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2015 21:49:31 GMT"}], "update_date": "2015-06-12", "authors_parsed": [["Schein", "Aaron", ""], ["Paisley", "John", ""], ["Blei", "David M.", ""], ["Wallach", "Hanna", ""]]}, {"id": "1506.03571", "submitter": "Enea Giuseppe Bongiorno", "authors": "Enea G. Bongiorno and Aldo Goia", "title": "Classification methods for Hilbert data based on surrogate density", "comments": "33 pages, 11 figures, 6 tables", "journal-ref": "Computational Statistics & Data Analysis, 99 (2016) pp. 204-222", "doi": "10.1016/j.csda.2016.01.019", "report-no": null, "categories": "stat.ME stat.AP stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An unsupervised and a supervised classification approaches for Hilbert random\ncurves are studied. Both rest on the use of a surrogate of the probability\ndensity which is defined, in a distribution-free mixture context, from an\nasymptotic factorization of the small-ball probability. That surrogate density\nis estimated by a kernel approach from the principal components of the data.\nThe focus is on the illustration of the classification algorithms and the\ncomputational implications, with particular attention to the tuning of the\nparameters involved. Some asymptotic results are sketched. Applications on\nsimulated and real datasets show how the proposed methods work.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2015 07:31:45 GMT"}, {"version": "v2", "created": "Tue, 29 Mar 2016 08:57:16 GMT"}], "update_date": "2016-03-30", "authors_parsed": [["Bongiorno", "Enea G.", ""], ["Goia", "Aldo", ""]]}, {"id": "1506.03920", "submitter": "Aristidis K. Nikoloulopoulos", "authors": "Aristidis K. Nikoloulopoulos", "title": "A vine copula mixed effect model for trivariate meta-analysis of\n  diagnostic test accuracy studies accounting for disease prevalence", "comments": "arXiv admin note: substantial text overlap with arXiv:1502.07505", "journal-ref": "Statistical Methods in Medical Research, 2017, 26(5):2270--2286", "doi": "10.1177/0962280215596769", "report-no": null, "categories": "stat.ME stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A bivariate copula mixed model has been recently proposed to synthesize\ndiagnostic test accuracy studies and it has been shown that is superior to the\nstandard generalized linear mixed model (GLMM) in this context. Here we call\ntrivariate vine copulas to extend the bivariate meta-analysis of diagnostic\ntest accuracy studies by accounting for disease prevalence. Our vine copula\nmixed model includes the trivariate GLMM as a special case and can also operate\non the original scale of sensitivity, specificity, and disease prevalence. Our\ngeneral methodology is illustrated by re-analysing the data of two published\nmeta-analyses. Our study suggests that there can be an improvement on\ntrivariate GLMM in fit to data and makes the argument for moving to vine copula\nrandom effects models especially because of their richness including reflection\nasymmetric tail dependence, and, computational feasibility despite their\nthree-dimensionality.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2015 07:50:24 GMT"}], "update_date": "2017-11-09", "authors_parsed": [["Nikoloulopoulos", "Aristidis K.", ""]]}, {"id": "1506.04125", "submitter": "Khalil Said", "authors": "V\\'eronique Maume-Deschamps (ICJ), Didier Rulli\\`ere (SAF), Khalil\n  Said (SAF)", "title": "A risk management approach to capital allocation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM math.PR stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The European insurance sector will soon be faced with the application of\nSolvency 2 regulation norms. It will create a real change in risk management\npractices. The ORSA approach of the second pillar makes the capital allocation\nan important exercise for all insurers and specially for groups. Considering\nmulti-branches firms, capital allocation has to be based on a multivariate risk\nmodeling. Several allocation methods are present in the literature and insurers\npractices. In this paper, we present a new risk allocation method, we study its\ncoherence using an axiomatic approach, and we try to define what the best\nallocation choice for an insurance group is.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2015 19:42:30 GMT"}], "update_date": "2015-06-15", "authors_parsed": [["Maume-Deschamps", "V\u00e9ronique", "", "ICJ"], ["Rulli\u00e8re", "Didier", "", "SAF"], ["Said", "Khalil", "", "SAF"]]}, {"id": "1506.04131", "submitter": "Igor Korkin", "authors": "Igor Korkin", "title": "Two Challenges of Stealthy Hypervisors Detection: Time Cheating and Data\n  Fluctuations", "comments": "25 pages, 7 figures, 8 tables. Paper presented at the Proceedings of\n  the 10th Annual Conference on Digital Forensics, Security and Law (CDFSL),\n  33-57, Daytona Beach, Florida, USA (2015, May 18-21)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR stat.AP stat.CO stat.OT", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Hardware virtualization technologies play a significant role in cyber\nsecurity. On the one hand these technologies enhance security levels, by\ndesigning a trusted operating system. On the other hand these technologies can\nbe taken up into modern malware which is rather hard to detect. None of the\nexisting methods is able to efficiently detect a hypervisor in the face of\ncountermeasures such as time cheating, temporary self uninstalling, memory\nhiding etc. New hypervisor detection methods which will be described in this\npaper can detect a hypervisor under these countermeasures and even count\nseveral nested ones. These novel approaches rely on the new statistical\nanalysis of time discrepancies by examination of a set of instructions, which\nare unconditionally intercepted by a hypervisor. Reliability was achieved\nthrough the comprehensive analysis of the collected data despite its\nfluctuation. These offered methods were comprehensively assessed in both Intel\nand AMD CPUs.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2015 19:50:33 GMT"}], "update_date": "2015-06-15", "authors_parsed": [["Korkin", "Igor", ""]]}, {"id": "1506.04493", "submitter": "Julien Bect", "authors": "H\\'elo\\\"ise Dutrieux (EDF R\\&D, L2EP), Ivana Aleksovska (L2S), Julien\n  Bect (L2S,(M\\'ethodes d'Analyse Stochastique des Codes et Traitements\n  Num\\'eriques)), Emmanuel Vazquez (L2S,(M\\'ethodes d'Analyse Stochastique des\n  Codes et Traitements Num\\'eriques)), Delille Gauthier (EDF R\\&D), Bruno\n  Fran\\c{c}ois (L2EP)", "title": "The Informational Approach to Global Optimization in presence of very\n  noisy evaluation results. Application to the optimization of renewable energy\n  integration strategies", "comments": null, "journal-ref": "47\\`emes Journ\\'ees de Statistique de la SFdS (JdS 2015), Jun\n  2015, Lille, France", "doi": null, "report-no": null, "categories": "stat.CO math.OC stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of global optimization of a function f from very\nnoisy evaluations. We adopt a Bayesian sequential approach: evaluation points\nare chosen so as to reduce the uncertainty about the position of the global\noptimum of f, as measured by the entropy of the corresponding random variable\n(Informational Approach to Global Optimization, Villemonteix et al., 2009).\nWhen evaluations are very noisy, the error coming from the estimation of the\nentropy using conditional simulations becomes non negligible compared to its\nvariations on the input domain. We propose a solution to this problem by\nchoosing evaluation points as if several evaluations were going to be made at\nthese points. The method is applied to the optimization of a strategy for the\nintegration of renewable energies into an electrical distribution network.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2015 07:25:16 GMT"}], "update_date": "2015-06-16", "authors_parsed": [["Dutrieux", "H\u00e9lo\u00efse", "", "EDF R\\&D, L2EP"], ["Aleksovska", "Ivana", "", "L2S"], ["Bect", "Julien", "", "L2S,"], ["Vazquez", "Emmanuel", "", "L2S,"], ["Gauthier", "Delille", "", "EDF R\\&D"], ["Fran\u00e7ois", "Bruno", "", "L2EP"]]}, {"id": "1506.04792", "submitter": "Rafael de Souza", "authors": "R.S. de Souza, J.M. Hilbe, B. Buelens, J.D. Riggs, E. Cameron, E.E.O.\n  Ishida, A.L. Chies-Santos, M. Killedar (for the COIN collaboration)", "title": "The Overlooked Potential of Generalized Linear Models in Astronomy-III:\n  Bayesian Negative Binomial Regression and Globular Cluster Populations", "comments": "14 pages, 12 figures. Accepted for publication in MNRAS", "journal-ref": null, "doi": "10.1093/mnras/stv1825", "report-no": null, "categories": "astro-ph.IM astro-ph.CO astro-ph.GA stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the third in a series illustrating the power of generalized\nlinear models (GLMs) for the astronomical community, we elucidate the potential\nof the class of GLMs which handles count data. The size of a galaxy's globular\ncluster population $N_{\\rm GC}$ is a prolonged puzzle in the astronomical\nliterature. It falls in the category of count data analysis, yet it is usually\nmodelled as if it were a continuous response variable. We have developed a\nBayesian negative binomial regression model to study the connection between\n$N_{\\rm GC}$ and the following galaxy properties: central black hole mass,\ndynamical bulge mass, bulge velocity dispersion, and absolute visual magnitude.\nThe methodology introduced herein naturally accounts for heteroscedasticity,\nintrinsic scatter, errors in measurements in both axes (either discrete or\ncontinuous), and allows modelling the population of globular clusters on their\nnatural scale as a non-negative integer variable. Prediction intervals of 99%\naround the trend for expected $N_{\\rm GC}$comfortably envelope the data,\nnotably including the Milky Way, which has hitherto been considered a\nproblematic outlier. Finally, we demonstrate how random intercept models can\nincorporate information of each particular galaxy morphological type. Bayesian\nvariable selection methodology allows for automatically identifying galaxy\ntypes with different productions of GCs, suggesting that on average S0 galaxies\nhave a GC population 35% smaller than other types with similar brightness.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2015 22:43:37 GMT"}, {"version": "v2", "created": "Thu, 13 Aug 2015 07:56:58 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["de Souza", "R. S.", "", "for the COIN collaboration"], ["Hilbe", "J. M.", "", "for the COIN collaboration"], ["Buelens", "B.", "", "for the COIN collaboration"], ["Riggs", "J. D.", "", "for the COIN collaboration"], ["Cameron", "E.", "", "for the COIN collaboration"], ["Ishida", "E. E. O.", "", "for the COIN collaboration"], ["Chies-Santos", "A. L.", "", "for the COIN collaboration"], ["Killedar", "M.", "", "for the COIN collaboration"]]}, {"id": "1506.04842", "submitter": "Giovanni Montana", "authors": "Da Ruan, Alastair Young and Giovanni Montana", "title": "Differential analysis of biological networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In cancer research, the comparison of gene expression or DNA methylation\nnetworks inferred from healthy controls and patients can lead to the discovery\nof biological pathways associated to the disease. As a cancer progresses, its\nsignalling and control networks are subject to some degree of localised\nre-wiring. Being able to detect disrupted interaction patterns induced by the\npresence or progression of the disease can lead to the discovery of novel\nmolecular diagnostic and prognostic signatures. Currently there is a lack of\nscalable statistical procedures for two-network comparisons aimed at detecting\nlocalised topological differences. We propose the dGHD algorithm, a methodology\nfor detecting differential interaction patterns in two-network comparisons. The\nalgorithm relies on a statistic, the Generalised Hamming Distance (GHD), for\nassessing the degree of topological difference between networks and evaluating\nits statistical significance. dGHD builds on a non-parametric permutation\ntesting framework but achieves computationally efficiency through an asymptotic\nnormal approximation. We show that the GHD is able to detect more subtle\ntopological differences compared to a standard Hamming distance between\nnetworks. This results in the dGHD algorithm achieving high performance in\nsimulation studies as measured by sensitivity and specificity. An application\nto the problem of detecting differential DNA co-methylation subnetworks\nassociated to ovarian cancer demonstrates the potential benefits of the\nproposed methodology for discovering network-derived biomarkers associated with\na trait of interest.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2015 06:03:20 GMT"}], "update_date": "2015-06-17", "authors_parsed": [["Ruan", "Da", ""], ["Young", "Alastair", ""], ["Montana", "Giovanni", ""]]}, {"id": "1506.04928", "submitter": "Thomas E Bartlett", "authors": "Thomas E. Bartlett", "title": "Network inference and community detection, based on covariance matrices,\n  correlations and test statistics from arbitrary distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose methodology for inference of binary-valued adjacency\nmatrices from various measures of the strength of association between pairs of\nnetwork nodes, or more generally pairs of variables. This strength of\nassociation can be quantified by sample covariance and correlation matrices,\nand more generally by test-statistics and hypothesis test p-values from\narbitrary distributions. Community detection methods such as block modelling\ntypically require binary-valued adjacency matrices as a starting point. Hence,\na main motivation for the methodology we propose is to obtain binary-valued\nadjacency matrices from such pairwise measures of strength of association\nbetween variables. The proposed methodology is applicable to large\nhigh-dimensional data-sets and is based on computationally efficient\nalgorithms. We illustrate its utility in a range of contexts and data-sets.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2015 11:48:57 GMT"}, {"version": "v2", "created": "Wed, 17 Jun 2015 08:55:22 GMT"}, {"version": "v3", "created": "Wed, 29 Jul 2015 17:40:51 GMT"}, {"version": "v4", "created": "Fri, 13 May 2016 09:58:13 GMT"}], "update_date": "2016-05-16", "authors_parsed": [["Bartlett", "Thomas E.", ""]]}, {"id": "1506.05215", "submitter": "Ying Sun", "authors": "Ying Sun, Prabhu Babu, and Daniel P. Palomar", "title": "Robust Estimation of Structured Covariance Matrix for Heavy-Tailed\n  Elliptical Distributions", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2016.2546222", "report-no": null, "categories": "stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the problem of robustly estimating a structured\ncovariance matrix with an elliptical underlying distribution with known mean.\nIn applications where the covariance matrix naturally possesses a certain\nstructure, taking the prior structure information into account in the\nestimation procedure is beneficial to improve the estimation accuracy. We\npropose incorporating the prior structure information into Tyler's M-estimator\nand formulate the problem as minimizing the cost function of Tyler's estimator\nunder the prior structural constraint. First, the estimation under a general\nconvex structural constraint is introduced with an efficient algorithm for\nfinding the estimator derived based on the majorization minimization (MM)\nalgorithm framework. Then, the algorithm is tailored to several special\nstructures that enjoy a wide range of applications in signal processing related\nfields, namely, sum of rank-one matrices, Toeplitz, and banded Toeplitz\nstructure. In addition, two types of non-convex structures, i.e., the Kronecker\nstructure and the spiked covariance structure, are also discussed, where it is\nshown that simple algorithms can be derived under the guidelines of MM.\nNumerical results show that the proposed estimator achieves a smaller\nestimation error than the benchmark estimators at a lower computational cost.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2015 06:17:26 GMT"}], "update_date": "2016-06-29", "authors_parsed": [["Sun", "Ying", ""], ["Babu", "Prabhu", ""], ["Palomar", "Daniel P.", ""]]}, {"id": "1506.05219", "submitter": "Ricardo Pio Monti", "authors": "Ricardo Pio Monti, Romy Lorenz, Peter Hellyer, Robert Leech,\n  Christoforos Anagnostopoulos, Giovanni Montana", "title": "Graph embeddings of dynamic functional connectivity reveal\n  discriminative patterns of task engagement in HCP data", "comments": "4 pages, 1 figure, 5th International Workshop on Pattern Recognition\n  in Neuroimaging, Stanford University, 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is increasing evidence to suggest functional connectivity networks are\nnon-stationary. This has lead to the development of novel methodologies with\nwhich to accurately estimate time-varying functional connectivity networks.\nMany of these methods provide unprecedented temporal granularity by estimating\na functional connectivity network at each point in time; resulting in\nhigh-dimensional output which can be studied in a variety of ways. One possible\nmethod is to employ graph embedding algorithms. Such algorithms effectively map\nestimated networks from high-dimensional spaces down to a low dimensional\nvector space; thus facilitating visualization, interpretation and\nclassification. In this work, the dynamic properties of functional connectivity\nare studied using working memory task data from the Human Connectome Project. A\nrecently proposed method is employed to estimate dynamic functional\nconnectivity networks. The results are subsequently analyzed using two graph\nembedding methods based on linear projections. These methods are shown to\nprovide informative embeddings that can be directly interpreted as functional\nconnectivity networks.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2015 06:49:42 GMT"}], "update_date": "2015-06-18", "authors_parsed": [["Monti", "Ricardo Pio", ""], ["Lorenz", "Romy", ""], ["Hellyer", "Peter", ""], ["Leech", "Robert", ""], ["Anagnostopoulos", "Christoforos", ""], ["Montana", "Giovanni", ""]]}, {"id": "1506.05244", "submitter": "Thomas E Bartlett", "authors": "Thomas E. Bartlett and Alexey Zaikin", "title": "Detection of Epigenomic Network Community Oncomarkers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP q-bio.GN q-bio.MN stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose network methodology to infer prognostic cancer\nbiomarkers based on the epigenetic pattern DNA methylation. Epigenetic\nprocesses such as DNA methylation reflect environmental risk factors, and are\nincreasingly recognised for their fundamental role in diseases such as cancer.\nDNA methylation is a gene-regulatory pattern, and hence provides a means by\nwhich to assess genomic regulatory interactions. Network models are a natural\nway to represent and analyse groups of such interactions. The utility of\nnetwork models also increases as the quantity of data and number of variables\nincrease, making them increasingly relevant to large-scale genomic studies. We\npropose methodology to infer prognostic genomic networks from a DNA\nmethylation-based measure of genomic interaction and association. We then show\nhow to identify prognostic biomarkers from such networks, which we term\n`network community oncomarkers'. We illustrate the power of our proposed\nmethodology in the context of a large publicly available breast cancer dataset.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2015 08:48:27 GMT"}, {"version": "v2", "created": "Tue, 28 Jul 2015 11:23:58 GMT"}, {"version": "v3", "created": "Mon, 1 Aug 2016 18:10:17 GMT"}], "update_date": "2016-08-02", "authors_parsed": [["Bartlett", "Thomas E.", ""], ["Zaikin", "Alexey", ""]]}, {"id": "1506.05661", "submitter": "Gergely Palla", "authors": "Gergely Palla, Gergely Tib\\'ely, Enys Mones, P\\'eter Pollner and\n  Tam\\'as Vicsek", "title": "Hierarchical networks of scientific journals", "comments": null, "journal-ref": "Palgrave Communications 1, 15016 (2015)", "doi": "10.1057/palcomms.2015.16", "report-no": null, "categories": "physics.soc-ph cs.DL stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scientific journals are the repositories of the gradually accumulating\nknowledge of mankind about the world surrounding us. Just as our knowledge is\norganised into classes ranging from major disciplines, subjects and fields to\nincreasingly specific topics, journals can also be categorised into groups\nusing various metrics. In addition to the set of topics characteristic for a\njournal, they can also be ranked regarding their relevance from the point of\noverall influence. One widespread measure is impact factor, but in the present\npaper we intend to reconstruct a much more detailed description by studying the\nhierarchical relations between the journals based on citation data. We use a\nmeasure related to the notion of m-reaching centrality and find a network which\nshows the level of influence of a journal from the point of the direction and\nefficiency with which information spreads through the network. We can also\nobtain an alternative network using a suitably modified nested hierarchy\nextraction method applied to the same data. The results are weakly\nmethodology-dependent and reveal non-trivial relations among journals. The two\nalternative hierarchies show large similarity with some striking differences,\nproviding together a complex picture of the intricate relations between\nscientific journals.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2015 12:58:38 GMT"}, {"version": "v2", "created": "Wed, 12 Aug 2015 11:24:32 GMT"}], "update_date": "2015-08-13", "authors_parsed": [["Palla", "Gergely", ""], ["Tib\u00e9ly", "Gergely", ""], ["Mones", "Enys", ""], ["Pollner", "P\u00e9ter", ""], ["Vicsek", "Tam\u00e1s", ""]]}, {"id": "1506.05709", "submitter": "Kangrui Wang", "authors": "Kangrui Wang and Dalia Chakrabarty", "title": "Bayesian Covariance Modelling of Large Tensor-Variate Data Sets $\\&$\n  Inverse Non-parametric Learning of the Unknown Model Parameter Vector", "comments": "5 pages. Extended abstract for 24th International Workshop on\n  Matrices and Statistics,2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tensor-valued data are being encountered increasingly more commonly, in the\nbiological, natural as well as the social sciences. The learning of the unknown\nmodel parameter vector given such data, involves covariance modelling of such\ndata, though this can be difficult owing to the high-dimensional nature of the\ndata, where the numerical challenge of such modelling can only be compounded by\nthe largeness of the available data set. Assuming such data to be modelled\nusing a correspondingly high-dimensional Gaussian Process (${\\cal\n  GP}$), the joint density of a finite set of such data sets is then a tensor\nnormal distribution, with density parametrised by a mean tensor\n$\\boldsymbol{M}$ (that is of the same dimensionality as the $k$-tensor valued\nobservable), and the $k$ covariance matrices\n$\\boldsymbol{\\Sigma}_1,...,\\boldsymbol{\\Sigma}_k$. When aiming to model the\ncovariance structure of the data, we need to estimate/learn\n$\\{\\boldsymbol{\\Sigma}_1,...,\\boldsymbol{\\Sigma}_k \\}$ and $\\boldsymbol{M}$,\ngiven tha data. We present a new method in which we perform such covariance\nmodelling by first expressing the probability density of the available data\nsets as tensor-normal. We then invoke appropriate priors on these unknown\nparameters and express the posterior of the unknowns given the data. We sample\nfrom this posterior using an appropriate variant of Metropolis Hastings. Since\nthe classical MCMC is time and resource intensive in high-dimensional state\nspaces, we use an efficient variant of the Metropolis-Hastings\nalgorithm--Transformation based MCMC--employed to perform efficient sampling\nfrom a high-dimensional state space. Once we perform the covariance modelling\nof such a data set, we will learn the unknown model parameter vector at which a\nmeasured (or test) data set has been obtained, given the already modelled data\n(training data), augmented by the test data.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2015 15:13:20 GMT"}], "update_date": "2015-06-19", "authors_parsed": [["Wang", "Kangrui", ""], ["Chakrabarty", "Dalia", ""]]}, {"id": "1506.05772", "submitter": "Carlos P. Roca", "authors": "Carlos P. Roca, Susana I. L. Gomes, M\\'onica J. B. Amorim, Janeck J.\n  Scott-Fordsmand", "title": "Variation-preserving normalization unveils blind spots in gene\n  expression profiling", "comments": "92 pages, 15 figures, 2 tables, includes supplementary materials", "journal-ref": "Scientific Reports 7, 42460 (2017)", "doi": "10.1038/srep42460", "report-no": null, "categories": "q-bio.PE q-bio.QM stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  RNA-Seq and gene expression microarrays provide comprehensive profiles of\ngene activity, but lack of reproducibility has hindered their application. A\nkey challenge in the data analysis is the normalization of gene expression\nlevels, which is currently performed following the implicit assumption that\nmost genes are not differentially expressed. Here, we present a mathematical\napproach to normalization that makes no assumption of this sort. We have found\nthat variation in gene expression is much larger than currently believed, and\nthat it can be measured with available assays. Our results also explain, at\nleast partially, the reproducibility problems encountered in transcriptomics\nstudies. We expect that this improvement in detection will help efforts to\nrealize the full potential of gene expression profiling, especially in analyses\nof cellular processes involving complex modulations of gene expression.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2015 18:54:28 GMT"}, {"version": "v2", "created": "Wed, 22 Jul 2015 12:32:52 GMT"}, {"version": "v3", "created": "Thu, 9 Mar 2017 18:00:22 GMT"}], "update_date": "2017-03-10", "authors_parsed": [["Roca", "Carlos P.", ""], ["Gomes", "Susana I. L.", ""], ["Amorim", "M\u00f3nica J. B.", ""], ["Scott-Fordsmand", "Janeck J.", ""]]}, {"id": "1506.05830", "submitter": "Maryam Sohrabi Dr", "authors": "Maryam Sohrabi and Mahmoud Zarepour", "title": "Asymptotic Theory for M-Estimates in Unstable AR(p) Processes with\n  Infinite Variance Innovations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present the asymptotic distribution of M-estimators for\nparameters in non-stationary AR(p) processes. The innovations are assumed to be\nin the domain of attraction of a stable law with index $0<\\alpha\\le2$. In\nparticular, when the model involves repeated unit roots or conjugate complex\nunit roots, M-estimators have a higher asymptotic rate of convergence compared\nto the least square estimators and the asymptotic results can be written as\nIt\\^{o} stochastic integrals.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2015 21:46:26 GMT"}, {"version": "v2", "created": "Mon, 12 Dec 2016 17:59:12 GMT"}], "update_date": "2016-12-13", "authors_parsed": [["Sohrabi", "Maryam", ""], ["Zarepour", "Mahmoud", ""]]}, {"id": "1506.06040", "submitter": "Esin Karahan", "authors": "Esin Karahan, Pedro A. Rojas-Lopez, Maria L. Bringas-Vega, Pedro A.\n  Valdes-Hernandez, Pedro A. Valdes-Sosa", "title": "Tensor Analysis and Fusion of Multimodal Brain Images", "comments": "23 pages, 15 figures, submitted to Proceedings of the IEEE", "journal-ref": null, "doi": "10.1109/JPROC.2015.2455028", "report-no": null, "categories": "stat.ME cs.NA stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current high-throughput data acquisition technologies probe dynamical systems\nwith different imaging modalities, generating massive data sets at different\nspatial and temporal resolutions posing challenging problems in multimodal data\nfusion. A case in point is the attempt to parse out the brain structures and\nnetworks that underpin human cognitive processes by analysis of different\nneuroimaging modalities (functional MRI, EEG, NIRS etc.). We emphasize that the\nmultimodal, multi-scale nature of neuroimaging data is well reflected by a\nmulti-way (tensor) structure where the underlying processes can be summarized\nby a relatively small number of components or \"atoms\". We introduce\nMarkov-Penrose diagrams - an integration of Bayesian DAG and tensor network\nnotation in order to analyze these models. These diagrams not only clarify\nmatrix and tensor EEG and fMRI time/frequency analysis and inverse problems,\nbut also help understand multimodal fusion via Multiway Partial Least Squares\nand Coupled Matrix-Tensor Factorization. We show here, for the first time, that\nGranger causal analysis of brain networks is a tensor regression problem, thus\nallowing the atomic decomposition of brain networks. Analysis of EEG and fMRI\nrecordings shows the potential of the methods and suggests their use in other\nscientific domains.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2015 15:03:22 GMT"}], "update_date": "2016-11-18", "authors_parsed": [["Karahan", "Esin", ""], ["Rojas-Lopez", "Pedro A.", ""], ["Bringas-Vega", "Maria L.", ""], ["Valdes-Hernandez", "Pedro A.", ""], ["Valdes-Sosa", "Pedro A.", ""]]}, {"id": "1506.06169", "submitter": "Patrick McDermott", "authors": "Patrick L. McDermott and Christopher K. Wikle", "title": "A Model-Based Approach for Analog Spatio-Temporal Dynamic Forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analog forecasting has been applied in a variety of fields for predicting\nfuture states of complex nonlinear systems that require flexible forecasting\nmethods. Past analog methods have almost exclu- sively been used in an\nempirical framework without the structure of a model-based approach. We propose\na Bayesian model framework for analog forecasting, building upon previous\nanalog methods but accounting for parameter uncertainty. Thus, unlike\ntraditional analog forecasting methods, the use of Bayesian modeling allows one\nto rigorously quantify uncertainty to obtain realistic posterior predictive\ndistributions. The model is applied to the long-lead time forecasting of\nmid-May averaged soil moisture anomalies in Iowa over a high-resolution grid of\nspatial locations. Sea Surface Tem- perature (SST) is used to find past time\nperiods with similar trajectories to the current pre-forecast period. The\nanalog model is developed on projection coefficients from a basis expansion of\nthe soil moisture and SST fields. Separate models are constructed for locations\nfalling in each Iowa Crop Reporting District (CRD) and the forecasting ability\nof the proposed model is compared against a variety of alternative methods and\nmetrics.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2015 22:16:06 GMT"}, {"version": "v2", "created": "Fri, 12 Feb 2016 23:04:13 GMT"}], "update_date": "2016-02-16", "authors_parsed": [["McDermott", "Patrick L.", ""], ["Wikle", "Christopher K.", ""]]}, {"id": "1506.06297", "submitter": "Alexander Gorban", "authors": "E. Fehrman, A.K. Muhammad, E.M. Mirkes, V. Egan, A.N. Gorban", "title": "The Five Factor Model of personality and evaluation of drug consumption\n  risk", "comments": "Significantly extended report with 67 pages, 27 tables, 21 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The problem of evaluating an individual's risk of drug consumption and misuse\nis highly important. An online survey methodology was employed to collect data\nincluding Big Five personality traits (NEO-FFI-R), impulsivity (BIS-11),\nsensation seeking (ImpSS), and demographic information. The data set contained\ninformation on the consumption of 18 central nervous system psychoactive drugs.\nCorrelation analysis demonstrated the existence of groups of drugs with\nstrongly correlated consumption patterns. Three correlation pleiades were\nidentified, named by the central drug in the pleiade: ecstasy, heroin, and\nbenzodiazepines pleiades. An exhaustive search was performed to select the most\neffective subset of input features and data mining methods to classify users\nand non-users for each drug and pleiad. A number of classification methods were\nemployed (decision tree, random forest, $k$-nearest neighbors, linear\ndiscriminant analysis, Gaussian mixture, probability density function\nestimation, logistic regression and na{\\\"i}ve Bayes) and the most effective\nclassifier was selected for each drug. The quality of classification was\nsurprisingly high with sensitivity and specificity (evaluated by leave-one-out\ncross-validation) being greater than 70\\% for almost all classification tasks.\nThe best results with sensitivity and specificity being greater than 75\\% were\nachieved for cannabis, crack, ecstasy, legal highs, LSD, and volatile substance\nabuse (VSA).\n", "versions": [{"version": "v1", "created": "Sat, 20 Jun 2015 21:38:44 GMT"}, {"version": "v2", "created": "Sun, 15 Jan 2017 14:46:56 GMT"}], "update_date": "2017-01-17", "authors_parsed": [["Fehrman", "E.", ""], ["Muhammad", "A. K.", ""], ["Mirkes", "E. M.", ""], ["Egan", "V.", ""], ["Gorban", "A. N.", ""]]}, {"id": "1506.06669", "submitter": "Rachael Meager", "authors": "Rachael Meager", "title": "Understanding the Impact of Microcredit Expansions: A Bayesian\n  Hierarchical Analysis of 7 Randomised Experiments", "comments": "This draft is preliminary and incomplete; future versions of this\n  paper will contain substantive additional results", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.EC stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian hierarchical models are a methodology for aggregation and synthesis\nof data from heterogeneous settings, used widely in statistics and other\ndisciplines. I apply this framework to the evidence from 7 randomized\nexperiments of expanding access to microcredit to assess the general impact of\nthe intervention on household outcomes and the heterogeneity in this impact\nacross sites. The results suggest that the effect of microcredit is likely to\nbe positive but small relative to control group average levels, and the\npossibility of a negative impact cannot be ruled out. By contrast, common\nmeta-analytic methods that pool all the data without assessing the\nheterogeneity misleadingly produce \"statistically significant\" results in 2 of\nthe 6 household outcomes. Standard pooling metrics for the studies indicate on\naverage 60% pooling on the treatment effects, suggesting that the site-specific\neffects are reasonably externally valid, and thus informative for each other\nand for the general case. The cross-study heterogeneity is almost entirely\ngenerated by heterogeneous effects for the 27% households who previously\noperated businesses before microcredit expansion, although this group is likely\nto see much larger impacts overall. A Ridge regression procedure to assess the\ncorrelations between site-specific covariates and treatment effects indicates\nthat the remaining heterogeneity is strongly correlated with differences in\neconomic variables, but not with differences in study design protocols. The\naverage interest rate and the average loan size have the strongest correlation\nwith the treatment effects, and both are negative.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2015 16:23:51 GMT"}, {"version": "v2", "created": "Tue, 8 Sep 2015 14:31:38 GMT"}, {"version": "v3", "created": "Tue, 12 Jul 2016 20:28:38 GMT"}], "update_date": "2016-07-14", "authors_parsed": [["Meager", "Rachael", ""]]}, {"id": "1506.06831", "submitter": "Paul Northrop", "authors": "Paul J. Northrop", "title": "An efficient semiparametric maxima estimator of the extremal index", "comments": "17 pages, 7 figures. Minor edits made to version 1 prior to journal\n  publication. The final publication is available at Springer via\n  http://dx.doi.org/10.1007/s10687-015-0221-5", "journal-ref": "Extremes 18 (2015) 585-603", "doi": "10.1007/s10687-015-0221-5", "report-no": null, "categories": "stat.ME stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The extremal index $\\theta$, a measure of the degree of local dependence in\nthe extremes of a stationary process, plays an important role in extreme value\nanalyses. We estimate $\\theta$ semiparametrically, using the relationship\nbetween the distribution of block maxima and the marginal distribution of a\nprocess to define a semiparametric model. We show that these semiparametric\nestimators are simpler and substantially more efficient than their parametric\ncounterparts. We seek to improve efficiency further using maxima over sliding\nblocks. A simulation study shows that the semiparametric estimators are\ncompetitive with the leading estimators. An application to sea-surge heights\ncombines inferences about $\\theta$ with a standard extreme value analysis of\nblock maxima to estimate marginal quantiles.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2015 00:27:44 GMT"}, {"version": "v2", "created": "Mon, 13 Jul 2015 14:29:17 GMT"}, {"version": "v3", "created": "Sun, 2 Aug 2015 22:23:39 GMT"}], "update_date": "2016-06-02", "authors_parsed": [["Northrop", "Paul J.", ""]]}, {"id": "1506.06972", "submitter": "Gergo Barta", "authors": "Gergo Barta, Gyula Borbely, Gabor Nagy, Sandor Kazi, Tamas Henk", "title": "GEFCOM 2014 - Probabilistic Electricity Price Forecasting", "comments": "10 pages, 5 figures, KES-IDT 2015 conference. The final publication\n  is available at Springer via http://dx.doi.org/10.1007/978-3-319-19857-6_7", "journal-ref": null, "doi": "10.1007/978-3-319-19857-6_7", "report-no": null, "categories": "stat.ML cs.CE cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Energy price forecasting is a relevant yet hard task in the field of\nmulti-step time series forecasting. In this paper we compare a well-known and\nestablished method, ARMA with exogenous variables with a relatively new\ntechnique Gradient Boosting Regression. The method was tested on data from\nGlobal Energy Forecasting Competition 2014 with a year long rolling window\nforecast. The results from the experiment reveal that a multi-model approach is\nsignificantly better performing in terms of error metrics. Gradient Boosting\ncan deal with seasonality and auto-correlation out-of-the box and achieve lower\nrate of normalized mean absolute error on real-world data.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2015 12:27:50 GMT"}], "update_date": "2015-06-24", "authors_parsed": [["Barta", "Gergo", ""], ["Borbely", "Gyula", ""], ["Nagy", "Gabor", ""], ["Kazi", "Sandor", ""], ["Henk", "Tamas", ""]]}, {"id": "1506.07368", "submitter": "Stefan Rass", "authors": "Stefan Rass", "title": "On Game-Theoretic Risk Management (Part One) -- Towards a Theory of\n  Games with Payoffs that are Probability-Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.GN math.ST q-fin.EC stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimal behavior in (competitive) situation is traditionally determined with\nthe help of utility functions that measure the payoff of different actions.\nGiven an ordering on the space of revenues (payoffs), the classical axiomatic\napproach of von Neumann and Morgenstern establishes the existence of suitable\nutility functions, and yields to game-theory as the most prominent\nmaterialization of a theory to determine optimal behavior. Although this\nappears to be a most natural approach to risk management too, applications in\ncritical infrastructures often violate the implicit assumption of actions\nleading to deterministic consequences. In that sense, the gameplay in a\ncritical infrastructure risk control competition is intrinsically random in the\nsense of actions having uncertain consequences. Mathematically, this takes us\nto utility functions that are probability-distribution-valued, in which case we\nloose the canonic (in fact every possible) ordering on the space of payoffs,\nand the original techniques of von Neumann and Morgenstern no longer apply.\n  This work introduces a new kind of game in which uncertainty applies to the\npayoff functions rather than the player's actions (a setting that has been\nwidely studied in the literature, yielding to celebrated notions like the\ntrembling hands equilibrium or the purification theorem). In detail, we show\nhow to fix the non-existence of a (canonic) ordering on the space of\nprobability distributions by only mildly restricting the full set to a subset\nthat can be totally ordered. Our vehicle to define the ordering and establish\nbasic game-theory is non-standard analysis and hyperreal numbers.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2015 14:00:41 GMT"}, {"version": "v2", "created": "Fri, 26 Jun 2015 10:34:15 GMT"}, {"version": "v3", "created": "Thu, 13 Aug 2015 10:46:49 GMT"}, {"version": "v4", "created": "Thu, 17 Sep 2015 11:58:18 GMT"}, {"version": "v5", "created": "Fri, 24 Apr 2020 11:02:52 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Rass", "Stefan", ""]]}, {"id": "1506.07450", "submitter": "Joanna Polanska", "authors": "Andrzej Polanski, Michal Marczyk, Monika Pietrowska, Piotr Widlak,\n  Joanna Polanska", "title": "Initializing EM algorithm for univariate Gaussian, multi-component,\n  heteroscedastic mixture models by dynamic programming partitions", "comments": "21 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Setting initial values of parameters of mixture distributions estimated by\nusing the EM recursive algorithm is very important to the overall quality of\nestimation. None of the existing methods is suitable for mixtures with large\nnumber of components. We present a relevant methodology of estimating initial\nvalues of parameters of univariate, heteroscedastic Gaussian mixtures, on the\nbasis of the dynamic programming algorithm for partitioning the range of\nobservations into bins. We evaluate variants of dynamic programming method\ncorresponding to different scoring functions for partitioning. For simulated\nand real datasets we demonstrate superior efficiency of the proposed method\ncompared to existing techniques.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2015 16:18:00 GMT"}, {"version": "v2", "created": "Sun, 2 Aug 2015 11:22:34 GMT"}], "update_date": "2015-08-04", "authors_parsed": [["Polanski", "Andrzej", ""], ["Marczyk", "Michal", ""], ["Pietrowska", "Monika", ""], ["Widlak", "Piotr", ""], ["Polanska", "Joanna", ""]]}, {"id": "1506.07496", "submitter": "Lo\\\"ic Ferrer", "authors": "Lo\\\"ic Ferrer, Virginie Rondeau, James J. Dignam, Tom Pickles,\n  H\\'el\\`ene Jacqmin-Gadda and C\\'ecile Proust-Lima", "title": "Joint modelling of longitudinal and multi-state processes: application\n  to clinical progressions in prostate cancer", "comments": "Added appendix", "journal-ref": null, "doi": "10.1002/sim.6972", "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Joint modelling of longitudinal and survival data is increasingly used in\nclinical trials on cancer. In prostate cancer for example, these models permit\nto account for the link between longitudinal measures of prostate-specific\nantigen (PSA) and the time of clinical recurrence when studying the risk of\nrelapse. In practice, multiple types of relapse may occur successively.\nDistinguishing these transitions between health states would allow to evaluate,\nfor example, how PSA trajectory and classical covariates impact the risk of\ndying after a distant recurrence post-radiotherapy, or to predict the risk of\none specific type of clinical recurrence post-radiotherapy, from the PSA\nhistory. In this context, we present a joint model for a longitudinal process\nand a multi-state process which is divided into two sub-models: a linear mixed\nsub-model for longitudinal data, and a multi-state sub-model with proportional\nhazards for transition times, both linked by shared random effects. Parameters\nof this joint multi-state model are estimated within the maximum likelihood\nframework using an EM algorithm coupled to a quasi-Newton algorithm in case of\nslow convergence. It is implemented under R, by combining and extending the\nmstate and JM packages. The estimation program is validated by simulations and\napplied on pooled data from two cohorts of men with localized prostate cancer\nand treated by radiotherapy. Thanks to the classical covariates available at\nbaseline and the PSA measurements collected repeatedly during the follow-up, we\nare able to assess the biomarker's trajectory, define the risks of transitions\nbetween health states, and quantify the impact of the PSA dynamics on each\ntransition intensity.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2015 18:51:19 GMT"}, {"version": "v2", "created": "Fri, 26 Jun 2015 14:45:29 GMT"}, {"version": "v3", "created": "Mon, 29 Jun 2015 14:39:30 GMT"}], "update_date": "2017-11-10", "authors_parsed": [["Ferrer", "Lo\u00efc", ""], ["Rondeau", "Virginie", ""], ["Dignam", "James J.", ""], ["Pickles", "Tom", ""], ["Jacqmin-Gadda", "H\u00e9l\u00e8ne", ""], ["Proust-Lima", "C\u00e9cile", ""]]}, {"id": "1506.07504", "submitter": "Maja Rudolph", "authors": "Maja R. Rudolph, Joseph G. Ellis, and David M. Blei", "title": "Objective Variables for Probabilistic Revenue Maximization in\n  Second-Price Auctions with Reserve", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.GT cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many online companies sell advertisement space in second-price auctions with\nreserve. In this paper, we develop a probabilistic method to learn a profitable\nstrategy to set the reserve price. We use historical auction data with features\nto fit a predictor of the best reserve price. This problem is delicate - the\nstructure of the auction is such that a reserve price set too high is much\nworse than a reserve price set too low. To address this we develop objective\nvariables, a new framework for combining probabilistic modeling with optimal\ndecision-making. Objective variables are \"hallucinated observations\" that\ntransform the revenue maximization task into a regularized maximum likelihood\nestimation problem, which we solve with an EM algorithm. This framework enables\na variety of prediction mechanisms to set the reserve price. As examples, we\nstudy objective variable methods with regression, kernelized regression, and\nneural networks on simulated and real data. Our methods outperform previous\napproaches both in terms of scalability and profit.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2015 19:20:18 GMT"}], "update_date": "2015-06-25", "authors_parsed": [["Rudolph", "Maja R.", ""], ["Ellis", "Joseph G.", ""], ["Blei", "David M.", ""]]}, {"id": "1506.07687", "submitter": "Yanxun Xu", "authors": "Yanxun Xu and Peter F. Thall and Peter Mueller and Mehran J. Reza", "title": "A Decision-Theoretic Comparison of Treatments to Resolve Air Leaks After\n  Lung Surgery Based on Nonparametric Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a Bayesian nonparametric utility-based group sequential design for\na randomized clinical trial to compare a gel sealant to standard care for\nresolving air leaks after pulmonary resection. Clinically, resolving air leaks\nin the days soon after surgery is highly important, since longer resolution\ntime produces undesirable complications that require extended hospitalization.\nThe problem of comparing treatments is complicated by the fact that the\nresolution time distributions are skewed and multi-modal, so using means is\nmisleading. We address these challenges by assuming Bayesian nonparametric\nprobability models for the resolution time distributions and basing the\ncomparative test on weighted means. The weights are elicited as clinical\nutilities of the resolution times. The proposed design uses posterior expected\nutilities as group sequential test criteria. The procedure's frequentist\nproperties are studied by extensive simulations.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2015 10:13:01 GMT"}, {"version": "v2", "created": "Mon, 18 Jul 2016 19:27:28 GMT"}], "update_date": "2017-02-28", "authors_parsed": [["Xu", "Yanxun", ""], ["Thall", "Peter F.", ""], ["Mueller", "Peter", ""], ["Reza", "Mehran J.", ""]]}, {"id": "1506.07727", "submitter": "Florian Wickelmaier", "authors": "Florian Wickelmaier", "title": "On not testing the foreign-language effect: A comment on Costa, Foucart,\n  Arnon, Aparici, and Apesteguia (2014)", "comments": "3 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In their first five studies, Costa, Foucart, Arnon, Aparici, and Apesteguia\n(2014) fail to provide a statistical test of the foreign-language effect.\nInstead, the authors employ a procedure in which they test the framing effects\nseparately for the native and the foreign language conditions. Such a\nprocedure, however, is inappropriate when comparing two effects; rather, a test\nof their difference is required. Using the original data, it is shown that in\nfour out of the five studies the authors' conclusions about the existence of a\nforeign-language effect are invalid.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2015 12:39:35 GMT"}], "update_date": "2015-06-26", "authors_parsed": [["Wickelmaier", "Florian", ""]]}, {"id": "1506.07836", "submitter": "Emeric Thibaud", "authors": "Emeric Thibaud, Juha Aalto, Daniel S. Cooley, Anthony C. Davison, Juha\n  Heikkinen", "title": "Bayesian inference for the Brown-Resnick process, with an application to\n  extreme low temperatures", "comments": null, "journal-ref": "The Annals of Applied Statistics, 2016, Vol. 10, No. 4, 2303-2324", "doi": "10.1214/16-AOAS980", "report-no": null, "categories": "stat.ME stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Brown-Resnick max-stable process has proven to be well-suited for\nmodeling extremes of complex environmental processes, but in many applications\nits likelihood function is intractable and inference must be based on a\ncomposite likelihood, thereby preventing the use of classical Bayesian\ntechniques. In this paper we exploit a case in which the full likelihood of a\nBrown-Resnick process can be calculated, using componentwise maxima and their\npartitions in terms of individual events, and we propose two new approaches to\ninference. The first estimates the partitions using declustering, while the\nsecond uses random partitions in a Markov chain Monte Carlo algorithm. We use\nthese approaches to construct a Bayesian hierarchical model for extreme low\ntemperatures in northern Fennoscandia.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2015 18:04:02 GMT"}, {"version": "v2", "created": "Mon, 17 Oct 2016 20:53:14 GMT"}], "update_date": "2017-01-16", "authors_parsed": [["Thibaud", "Emeric", ""], ["Aalto", "Juha", ""], ["Cooley", "Daniel S.", ""], ["Davison", "Anthony C.", ""], ["Heikkinen", "Juha", ""]]}, {"id": "1506.07939", "submitter": "Michael Lopez", "authors": "Qi Ge, Michael J. Lopez", "title": "Labor Disputes and Worker Productivity", "comments": "4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We implement a propensity score matching technique to present the first\nevidence on the impact of labor supply decisions during labor disputes on\nworker productivity in the context of professional sports. In particular, we\nutilize a unique natural experiment from the 2012-13 National Hockey League\n(NHL) lockout, during which approximately 200 players decided to play overseas\nwhile the rest stayed in North America. We separate the players based on their\nnationality and investigate the effect of playing abroad on post-lockout player\nperformance. We find limited evidence of enhanced productivity among European\nplayers, and no evidence of a benefit or drawback for North American players.\nThe lack of consistent productivity impact is in line with literature in\nindustries with large labor rents, and we propose several additional\nexplanations within the context of professional hockey. Our study contributes\nto the general understanding of the impact of employer-initiated work stoppage\non labor productivity.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jun 2015 02:07:35 GMT"}], "update_date": "2015-06-29", "authors_parsed": [["Ge", "Qi", ""], ["Lopez", "Michael J.", ""]]}, {"id": "1506.08047", "submitter": "Paul Ilhe", "authors": "Paul Ilhe (LTCI, LIST), Eric Moulines (LTCI), Fran\\c{c}ois Roueff\n  (LTCI), Antoine Souloumiac (LIST)", "title": "Nonparametric estimation of mark's distribution of an exponential\n  Shot-noise process", "comments": "Electronic Journal of Statistics, Institute of Mathematical\n  Statistics and Bernoulli Society, 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider a nonlinear inverse problem occurring in nuclear\nscience. Gamma rays randomly hit a semiconductor detector which produces an\nimpulse response of electric current. Because the sampling period of the\nmeasured current is larger than the mean inter arrival time of photons, the\nimpulse responses associated to different gamma rays can overlap: this\nphenomenon is known as pileup. In this work, it is assumed that the impulse\nresponse is an exponentially decaying function. We propose a novel method to\ninfer the distribution of gamma photon energies from the indirect measurements\nobtained from the detector. This technique is based on a formula linking the\ncharacteristic function of the photon density to a function involving the\ncharacteristic function and its derivative of the observations. We establish\nthat our estimator converges to the mark density in uniform norm at a\nlogarithmic rate. A limited Monte-Carlo experiment is provided to support our\nfindings.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jun 2015 12:57:35 GMT"}, {"version": "v2", "created": "Tue, 26 Jan 2016 13:15:21 GMT"}], "update_date": "2016-01-27", "authors_parsed": [["Ilhe", "Paul", "", "LTCI, LIST"], ["Moulines", "Eric", "", "LTCI"], ["Roueff", "Fran\u00e7ois", "", "LTCI"], ["Souloumiac", "Antoine", "", "LIST"]]}, {"id": "1506.08159", "submitter": "Sohail Bahmani", "authors": "Sohail Bahmani and Justin Romberg", "title": "Near-Optimal Estimation of Simultaneously Sparse and Low-Rank Matrices\n  from Nested Linear Measurements", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT math.IT math.OC stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider the problem of estimating simultaneously low-rank\nand row-wise sparse matrices from nested linear measurements where the linear\noperator consists of the product of a linear operator $\\mathcal{W}$ and a\nmatrix $\\mathbf{\\varPsi}$. Leveraging the nested structure of the measurement\noperator, we propose a computationally efficient two-stage algorithm for\nestimating the simultaneously structured target matrix. Assuming that\n$\\mathcal{W}$ is a restricted isometry for low-rank matrices and\n$\\mathbf{\\varPsi}$ is a restricted isometry for row-wise sparse matrices, we\nestablish an accuracy guarantee that holds uniformly for all sufficiently\nlow-rank and row-wise sparse matrices with high probability. Furthermore, using\nstandard tools from information theory, we establish a minimax lower bound for\nestimation of simultaneously low-rank and row-wise sparse matrices from linear\nmeasurements that need not be nested. The accuracy bounds established for the\nalgorithm, that also serve as a minimax upper bound, differ from the derived\nminimax lower bound merely by a polylogarithmic factor of the dimensions.\nTherefore, the proposed algorithm is nearly minimax optimal. We also discuss\nsome applications of the proposed observation model and evaluate our algorithm\nthrough numerical simulation.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jun 2015 17:07:01 GMT"}, {"version": "v2", "created": "Mon, 21 Mar 2016 12:40:24 GMT"}], "update_date": "2016-03-22", "authors_parsed": [["Bahmani", "Sohail", ""], ["Romberg", "Justin", ""]]}, {"id": "1506.08180", "submitter": "Amar Shah", "authors": "Amar Shah and David A. Knowles and Zoubin Ghahramani", "title": "An Empirical Study of Stochastic Variational Algorithms for the Beta\n  Bernoulli Process", "comments": "ICML, 12 pages. Volume 37: Proceedings of The 32nd International\n  Conference on Machine Learning, 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic variational inference (SVI) is emerging as the most promising\ncandidate for scaling inference in Bayesian probabilistic models to large\ndatasets. However, the performance of these methods has been assessed primarily\nin the context of Bayesian topic models, particularly latent Dirichlet\nallocation (LDA). Deriving several new algorithms, and using synthetic, image\nand genomic datasets, we investigate whether the understanding gleaned from LDA\napplies in the setting of sparse latent factor models, specifically beta\nprocess factor analysis (BPFA). We demonstrate that the big picture is\nconsistent: using Gibbs sampling within SVI to maintain certain posterior\ndependencies is extremely effective. However, we find that different posterior\ndependencies are important in BPFA relative to LDA. Particularly,\napproximations able to model intra-local variable dependence perform best.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jun 2015 18:55:11 GMT"}], "update_date": "2015-06-29", "authors_parsed": [["Shah", "Amar", ""], ["Knowles", "David A.", ""], ["Ghahramani", "Zoubin", ""]]}, {"id": "1506.08253", "submitter": "Yanxun Xu", "authors": "Yanxun Xu and Peter Mueller and Donatello Telesca", "title": "Bayesian Inference for Latent Biologic Structure with Determinantal\n  Point Processes (DPP)", "comments": null, "journal-ref": null, "doi": "10.1111/biom.12482", "report-no": null, "categories": "stat.ME stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss the use of the determinantal point process (DPP) as a prior for\nlatent structure in biomedical applications, where inference often centers on\nthe interpretation of latent features as biologically or clinically meaningful\nstructure. Typical examples include mixture models, when the terms of the\nmixture are meant to represent clinically meaningful subpopulations (of\npatients, genes, etc.). Another class of examples are feature allocation\nmodels. We propose the DPP prior as a repulsive prior on latent mixture\ncomponents in the first example, and as prior on feature-specific parameters in\nthe second case. We argue that the DPP is in general an attractive prior model\nfor latent structure when biologically relevant interpretation of such\nstructure is desired. We illustrate the advantages of DPP prior in three case\nstudies, including inference in mixture models for magnetic resonance images\n(MRI) and for protein expression, and a feature allocation model for gene\nexpression using data from The Cancer Genome Atlas. An important part of our\nargument are efficient and straightforward posterior simulation methods. We\nimplement a variation of reversible jump Markov chain Monte Carlo simulation\nfor inference under the DPP prior, using a density with respect to the unit\nrate Poisson process.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jun 2015 03:56:25 GMT"}, {"version": "v2", "created": "Mon, 16 Nov 2015 22:27:13 GMT"}], "update_date": "2017-02-28", "authors_parsed": [["Xu", "Yanxun", ""], ["Mueller", "Peter", ""], ["Telesca", "Donatello", ""]]}, {"id": "1506.08256", "submitter": "Daniel Cervone", "authors": "Daniel Cervone and Natesh S. Pillai", "title": "Gaussian Process Regression with Location Errors", "comments": "28 pages, 17 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate Gaussian process regression models where inputs\nare subject to measurement error. In spatial statistics, input measurement\nerrors occur when the geographical locations of observed data are not known\nexactly. Such sources of error are not special cases of \"nugget\" or microscale\nvariation, and require alternative methods for both interpolation and parameter\nestimation. Gaussian process models do not straightforwardly extend to\nincorporate input measurement error, and simply ignoring noise in the input\nspace can lead to poor performance for both prediction and parameter inference.\nWe review and extend existing theory on prediction and estimation in the\npresence of location errors, and show that ignoring location errors may lead to\nKriging that is not \"self-efficient\". We also introduce a Markov Chain Monte\nCarlo (MCMC) approach using the Hybrid Monte Carlo algorithm that obtains\noptimal (minimum MSE) predictions, and discuss situations that lead to\nmultimodality of the target distribution and/or poor chain mixing. Through\nsimulation study and analysis of global air temperature data, we show that\nappropriate methods for incorporating location measurement error are essential\nto valid inference in this regime.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jun 2015 04:24:10 GMT"}], "update_date": "2015-06-30", "authors_parsed": [["Cervone", "Daniel", ""], ["Pillai", "Natesh S.", ""]]}, {"id": "1506.08334", "submitter": "Senthil Balaji Girimurugan", "authors": "S.B. Girimurugan, Jonathan Dennis, and Jinfeng Zhang", "title": "iSeg: an algorithm for segmentation of genomic data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Identification of functional elements of a genome often requires dividing a\nsequence of measurements along a genome into segments differing from adjacent\nsegments. In many applications, the mean of the measured values at multiple\ngenomic locations in a segment is used to make inference of the property of\ninterest. The segments with non-zero means often correspond to genomic regions\nwith certain biological events, such as changes between two conditions. This\nproblem is often called the segmentation problem in the field of genomics, and\nthe change-point problem in other scientific disciplines. We designed an\nefficient algorithm, called iSeg, for segmentation of high-throughput genomic\nprofiles. iSeg first utilizes dynamic programming to compute the significance\nfor a large number of candidate segments. It then uses tree-based data\nstructures to detect overlapping significant regions and update them\nsimultaneously. Refinement and merging of significant segments are performed at\nthe end to generate the final segmentation. We evaluate iSeg using both\nsimulated and experimental datasets and show that it performs quite well when\ncompared with existing methods.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jun 2015 22:05:14 GMT"}], "update_date": "2015-06-30", "authors_parsed": [["Girimurugan", "S. B.", ""], ["Dennis", "Jonathan", ""], ["Zhang", "Jinfeng", ""]]}, {"id": "1506.08339", "submitter": "Sen Zhao", "authors": "Sen Zhao and Ali Shojaie", "title": "A Significance Test for Graph-Constrained Estimation", "comments": "42 pages, 3 tables, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph-constrained estimation methods encourage similarities among neighboring\ncovariates presented as nodes on a graph, which can result in more accurate\nestimations, especially in high dimensional settings. Variable selection\napproaches can then be utilized to select a subset of variables that are\nassociated with the response. However, existing procedures do not provide\nmeasures of uncertainty of the estimates. Moreover, the vast majority of\nexisting approaches assume that available graphs accurately capture the\nassociation among covariates; violating this assumption could severely hurt the\nreliability of the resulting estimates. In this paper, we present an inference\nframework, called the Grace test, which simultaneously produces coefficient\nestimates and corresponding $p$-values while incorporating the external graph\ninformation. We show, both theoretically and via numerical studies, that the\nproposed method asymptotically controls the type-I error rate regardless of the\nchoice of the graph. When the underlying graph is informative, the Grace test\nis asymptotically more powerful than similar tests that ignore external\ninformation. We further propose a more general Grace-ridge test that results in\na higher power than the Grace test when the choice of the graph is not fully\ninformative. Our numerical studies show that as long as the graph is reasonably\ninformative, the proposed testing methods deliver improved statistical power\nover existing inference procedures that ignore external information.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jun 2015 00:03:58 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Zhao", "Sen", ""], ["Shojaie", "Ali", ""]]}, {"id": "1506.08444", "submitter": "Giulia  Cereda", "authors": "Giulia Cereda", "title": "Non parametric Bayesian approach to LR assessment in case of rare\n  haplotype match", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The evaluation of a match between the DNA profile of a stain found on a crime\nscene and that of a suspect (previously identified) involves the use of the\nunknown parameter $p=(p_1, p_2, ...)$, (the ordered vector which represents the\nproportions of the different DNA profiles in the population of potential\ndonors) and the names of the different DNA types. We propose a Bayesian non\nparametric method which considers $P$ as a random variable distributed\naccording to the two-parameter Poisson Dirichlet distribution, and discard\ninformation about names of DNA types. The ultimate goal of this model is to\nevaluate DNA matches in the rare type case, that is the situation in which the\nsuspect's profile, matching the crime stain profile, is not one of those in the\ndatabase of reference.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jun 2015 20:04:55 GMT"}, {"version": "v2", "created": "Wed, 1 Jul 2015 12:23:13 GMT"}, {"version": "v3", "created": "Fri, 18 Sep 2015 14:25:57 GMT"}], "update_date": "2015-09-21", "authors_parsed": [["Cereda", "Giulia", ""]]}, {"id": "1506.08535", "submitter": "Marcel Ausloos", "authors": "Nikolay K. Vitanov and Marcel Ausloos", "title": "Test of two hypotheses explaining the size of populations in a system of\n  cities", "comments": "13 pages; 4 figures, 1 Table; 25 references; prepared for Journal of\n  Applied Statistics", "journal-ref": "J. Appl. Stat. 42 (12) 2686-2693, 2015", "doi": "10.1080/02664763.2015.1047744", "report-no": null, "categories": "physics.soc-ph cs.SI stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two classical hypotheses are examined about the population growth in a system\nof cities: Hypothesis 1 pertains to Gibrat's and Zipf's theory which states\nthat the city growth-decay process is size independent; Hypothesis 2 pertains\nto the so called Yule process which states that the growth of populations in\ncities happens when (i) the distribution of the city population initial size\nobeys a log-normal function, (ii) the growth of the settlements follows a\nstochastic process. The basis for the test is some official data on Bulgarian\ncities at various times. This system was chosen because (i) Bulgaria is a\ncountry for which one does not expect biased theoretical conditions; (ii) the\ncity populations were determined rather precisely. The present results show\nthat: (i) the population size growth of the Bulgarian cities is size dependent,\nwhence Hypothesis 1 is not confirmed for Bulgaria; (ii) the population size\ngrowth of Bulgarian cities can be described by a double Pareto log-normal\ndistribution, whence Hypothesis 2 is valid for the Bulgarian city system. It is\nexpected that this fine study brings some information and light on other,\nusually considered to be more pertinent, city systems in various countries.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2015 08:08:50 GMT"}], "update_date": "2015-12-15", "authors_parsed": [["Vitanov", "Nikolay K.", ""], ["Ausloos", "Marcel", ""]]}, {"id": "1506.08842", "submitter": "Wassim Suleiman", "authors": "W. Suleiman, M. Pesavento and A. M. Zoubir", "title": "Performance Analysis of the Decentralized Eigendecomposition and ESPRIT\n  Algorithm", "comments": "18 pages, 5 figures, submitted for publication in IEEE Transactions\n  on Signal Processing", "journal-ref": null, "doi": "10.1109/TSP.2016.2523448", "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider performance analysis of the decentralized power\nmethod for the eigendecomposition of the sample covariance matrix based on the\naveraging consensus protocol. An analytical expression of the second order\nstatistics of the eigenvectors obtained from the decentralized power method\nwhich is required for computing the mean square error (MSE) of subspace-based\nestimators is presented. We show that the decentralized power method is not an\nasymptotically consistent estimator of the eigenvectors of the true measurement\ncovariance matrix unless the averaging consensus protocol is carried out over\nan infinitely large number of iterations. Moreover, we introduce the\ndecentralized ESPRIT algorithm which yields fully decentralized\ndirection-of-arrival (DOA) estimates. Based on the performance analysis of the\ndecentralized power method, we derive an analytical expression of the MSE of\nDOA estimators using the decentralized ESPRIT algorithm. The validity of our\nasymptotic results is demonstrated by simulations.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2015 20:11:21 GMT"}, {"version": "v2", "created": "Mon, 7 Dec 2015 08:51:36 GMT"}], "update_date": "2016-05-04", "authors_parsed": [["Suleiman", "W.", ""], ["Pesavento", "M.", ""], ["Zoubir", "A. M.", ""]]}, {"id": "1506.09060", "submitter": "Anum Ali", "authors": "Ebrahim B. Al-Safadi, Tareq Y. Al-Naffouri, Mudassir Masood, Anum Ali", "title": "Nonlinear Distortion Reduction in OFDM from Reliable Perturbations in\n  Data Carriers", "comments": "27 pages, 11 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel method for correcting the effect of nonlinear distortion in\northogonal frequency division multiplexing signals is proposed. The method\ndepends on adaptively selecting the distortion over a subset of the data\ncarriers, and then using tools from compressed sensing and sparse Bayesian\nrecovery to estimate the distortion over the other carriers. Central to this\nmethod is the fact that carriers (or tones) are decoded with different levels\nof confidence, depending on a coupled function of the magnitude and phase of\nthe distortion over each carrier, in addition to the respective channel\nstrength. Moreover, as no pilots are required by this method, a significant\nimprovement in terms of achievable rate can be achieved relative to previous\nwork.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2015 12:34:11 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Al-Safadi", "Ebrahim B.", ""], ["Al-Naffouri", "Tareq Y.", ""], ["Masood", "Mudassir", ""], ["Ali", "Anum", ""]]}]