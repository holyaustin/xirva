[{"id": "1107.0076", "submitter": "Patrick J. Wolfe", "authors": "Daryush D. Mehta, Daniel Rudoy, Patrick J. Wolfe", "title": "KARMA: Kalman-based autoregressive moving average modeling and inference\n  for formant and antiformant tracking", "comments": "13 pages, 7 figures; submitted for publication", "journal-ref": "Journal of the Acoustical Society of America, vol. 132, pp.\n  1732-1746, 2012", "doi": "10.1121/1.4739462", "report-no": null, "categories": "stat.AP cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vocal tract resonance characteristics in acoustic speech signals are\nclassically tracked using frame-by-frame point estimates of formant frequencies\nfollowed by candidate selection and smoothing using dynamic programming methods\nthat minimize ad hoc cost functions. The goal of the current work is to provide\nboth point estimates and associated uncertainties of center frequencies and\nbandwidths in a statistically principled state-space framework. Extended Kalman\n(K) algorithms take advantage of a linearized mapping to infer formant and\nantiformant parameters from frame-based estimates of autoregressive moving\naverage (ARMA) cepstral coefficients. Error analysis of KARMA, WaveSurfer, and\nPraat is accomplished in the all-pole case using a manually marked formant\ndatabase and synthesized speech waveforms. KARMA formant tracks exhibit lower\noverall root-mean-square error relative to the two benchmark algorithms, with\nthird formant tracking more challenging. Antiformant tracking performance of\nKARMA is illustrated using synthesized and spoken nasal phonemes. The\nsimultaneous tracking of uncertainty levels enables practitioners to recognize\ntime-varying confidence in parameters of interest and adjust algorithmic\nsettings accordingly.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jun 2011 22:15:07 GMT"}], "update_date": "2012-10-15", "authors_parsed": [["Mehta", "Daryush D.", ""], ["Rudoy", "Daniel", ""], ["Wolfe", "Patrick J.", ""]]}, {"id": "1107.0516", "submitter": "Mihir Arjunwadkar", "authors": "Amir Aghamousa (CMS-UoP, India), Mihir Arjunwadkar (CMS-UoP and NCRA,\n  India) and Tarun Souradeep (IUCAA, India)", "title": "Evolution of the CMB Power Spectrum Across WMAP Data Releases: A\n  Nonparametric Analysis", "comments": null, "journal-ref": "ApJ, 745, 114 (2012)", "doi": "10.1088/0004-637X/745/2/114", "report-no": "CMS-TR-20110704", "categories": "astro-ph.CO stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using a nonparametric function estimation methodology, we present a\ncomparative analysis of the WMAP 1-, 3-, 5-, and 7-year data releases for the\nCMB angular power spectrum with respect to the following key questions: (a) How\nwell is the power spectrum determined by the data alone? (b) How well is the\n$\\Lambda$CDM model supported by a model-independent, data-driven analysis? (c)\nWhat are the realistic uncertainties on peak/dip locations and heights? Our\nresults show that the height of the power spectrum is well determined by data\nalone for multipole l approximately less than 546 (1-year), 667 (3-year), 804\n(5-year), and 842 (7-year data). We show that parametric fits based on the\n$\\Lambda$CDM model are remarkably close to our nonparametric fits in\n$l$-regions where data are sufficiently precise. In contrast, the power\nspectrum for an H$\\Lambda$CDM model gets progressively pushed away from our\nnonparametric fit as data quality improves with successive data realizations,\nsuggesting incompatibility of this particular cosmological model with respect\nto the WMAP data sets. We present uncertainties on peak/dip locations and\nheights at the 95% ($2 \\sigma$) level of confidence, and show how these\nuncertainties translate into hyperbolic \"bands\" on the acoustic scale ($l_A$)\nand peak shift ($\\phi_m$) parameters. Based on the confidence set for the\n7-year data, we argue that the low-l up-turn in the CMB power spectrum cannot\nbe ruled out at any confidence level in excess of about 10% ($\\approx 0.12\n\\sigma$). Additional outcomes of this work are a numerical formulation for\nminimization of a noise-weighted risk function subject to monotonicity\nconstraints, a prescription for obtaining nonparametric fits that are closer to\ncosmological expectations on smoothness, and a method for sampling\ncosmologically meaningful power spectrum variations from the confidence set of\na nonparametric fit.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jul 2011 02:24:57 GMT"}, {"version": "v2", "created": "Tue, 25 Oct 2011 06:41:54 GMT"}], "update_date": "2012-01-10", "authors_parsed": [["Aghamousa", "Amir", "", "CMS-UoP, India"], ["Arjunwadkar", "Mihir", "", "CMS-UoP and NCRA,\n  India"], ["Souradeep", "Tarun", "", "IUCAA, India"]]}, {"id": "1107.0662", "submitter": "Arijit Das", "authors": "Arijit Das and Anthony Quinn", "title": "A Variational Bayes Approach to Decoding in a Phase-Uncertain Digital\n  Receiver", "comments": "6 pages, 3 figures, Accepted at the Irish Signals and Systems\n  Conference 23-24 June 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a Bayesian approach to symbol and phase inference in a\nphase-unsynchronized digital receiver. It primarily extends [Quinn 2011] to the\nmulti-symbol case, using the variational Bayes (VB) approximation to deal with\nthe combinatorial complexity of the phase inference in this case. The work\nprovides a fully Bayesian extension of the EM-based framework underlying\ncurrent turbo-synchronization methods, since it induces a von Mises prior on\nthe time-invariant phase parmeter. As a result, we achieve tractable iterative\nalgorithms with improved robustness in low SNR regimes, compared to the current\nEM-based approaches. As a corollary to our analysis we also discover the\nimportance of prior regularization in elegantly tackling the significant\nproblem of phase ambiguity.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jul 2011 15:37:19 GMT"}], "update_date": "2015-03-13", "authors_parsed": [["Das", "Arijit", ""], ["Quinn", "Anthony", ""]]}, {"id": "1107.0749", "submitter": "Cari G. Kaufman", "authors": "Cari G. Kaufman, Derek Bingham, Salman Habib, Katrin Heitmann, Joshua\n  A. Frieman", "title": "Efficient emulators of computer experiments using compactly supported\n  correlation functions, with an application to cosmology", "comments": "Published in at http://dx.doi.org/10.1214/11-AOAS489 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2011, Vol. 5, No. 4, 2470-2492", "doi": "10.1214/11-AOAS489", "report-no": "IMS-AOAS-AOAS489", "categories": "stat.ME stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical emulators of computer simulators have proven to be useful in a\nvariety of applications. The widely adopted model for emulator building, using\na Gaussian process model with strictly positive correlation function, is\ncomputationally intractable when the number of simulator evaluations is large.\nWe propose a new model that uses a combination of low-order regression terms\nand compactly supported correlation functions to recreate the desired\npredictive behavior of the emulator at a fraction of the computational cost.\nFollowing the usual approach of taking the correlation to be a product of\ncorrelations in each input dimension, we show how to impose restrictions on the\nranges of the correlations, giving sparsity, while also allowing the ranges to\ntrade off against one another, thereby giving good predictive performance. We\nillustrate the method using data from a computer simulator of photometric\nredshift with 20,000 simulator evaluations and 80,000 predictions.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jul 2011 22:14:49 GMT"}, {"version": "v2", "created": "Tue, 28 Feb 2012 12:05:07 GMT"}], "update_date": "2012-02-29", "authors_parsed": [["Kaufman", "Cari G.", ""], ["Bingham", "Derek", ""], ["Habib", "Salman", ""], ["Heitmann", "Katrin", ""], ["Frieman", "Joshua A.", ""]]}, {"id": "1107.0885", "submitter": "Akhila Raman", "authors": "Akhila Raman", "title": "On Daryl Bem's Feeling the Future Paper", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been argued by Daryl Bem in his 2011 paper that 8 out of 9 experiments\nyielded statistically significant results in favour of the psi effect. It is\npointed out in this short communication that many of the results in the above\nmentioned paper could be explained by using well known concepts in statistics\nsuch as Confidence Level and Standard Error of the Sample Mean. This short\ncommunication also discusses implied confidence level and confidence intervals\nin polling results.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jul 2011 14:36:25 GMT"}], "update_date": "2011-07-06", "authors_parsed": [["Raman", "Akhila", ""]]}, {"id": "1107.0895", "submitter": "Ferenc Husz\\'ar", "authors": "Ferenc Husz\\'ar and Neil M. T. Houlsby", "title": "Adaptive Bayesian Quantum Tomography", "comments": "4 pages, 3 figures, updated references, clarified exposition", "journal-ref": null, "doi": "10.1103/PhysRevA.85.052120", "report-no": null, "categories": "quant-ph stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this letter we revisit the problem of optimal design of quantum\ntomographic experiments. In contrast to previous approaches where an optimal\nset of measurements is decided in advance of the experiment, we allow for\nmeasurements to be adaptively and efficiently re-optimised depending on data\ncollected so far. We develop an adaptive statistical framework based on\nBayesian inference and Shannon's information, and demonstrate a ten-fold\nreduction in the total number of measurements required as compared to\nnon-adaptive methods, including mutually unbiased bases.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jul 2011 15:05:53 GMT"}, {"version": "v2", "created": "Wed, 5 Oct 2011 09:16:34 GMT"}], "update_date": "2017-02-28", "authors_parsed": [["Husz\u00e1r", "Ferenc", ""], ["Houlsby", "Neil M. T.", ""]]}, {"id": "1107.0927", "submitter": "Gabriel Terejanu", "authors": "Gabriel Terejanu, Todd Oliver, Chris Simmons", "title": "Application of Predictive Model Selection to Coupled Models", "comments": "Submitted to International Conference on Modeling, Simulation and\n  Control 2011 (ICMSC'11), San Francisco, USA, 19-21 October, 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.IT math.IT physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A predictive Bayesian model selection approach is presented to discriminate\ncoupled models used to predict an unobserved quantity of interest (QoI). The\nneed for accurate predictions arises in a variety of critical applications such\nas climate, aerospace and defense. A model problem is introduced to study the\nprediction yielded by the coupling of two physics/sub-components. For each\nsingle physics domain, a set of model classes and a set of sensor observations\nare available. A goal-oriented algorithm using a predictive approach to\nBayesian model selection is then used to select the combination of single\nphysics models that best predict the QoI. It is shown that the best coupled\nmodel for prediction is the one that provides the most robust predictive\ndistribution for the QoI.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jul 2011 17:26:52 GMT"}], "update_date": "2011-07-06", "authors_parsed": [["Terejanu", "Gabriel", ""], ["Oliver", "Todd", ""], ["Simmons", "Chris", ""]]}, {"id": "1107.1229", "submitter": "Daniel Rockmore", "authors": "Sean Brocklebank, Scott Pauls, Daniel Rockmore, Timothy C. Bates", "title": "Characteristic Characteristics", "comments": "23 pages, 5 Figures, 3 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.IR physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While five-factor models of personality are widespread, there is still not\nuniversal agreement on this as a structural framework. Part of the reason for\nthe lingering debate is its dependence on factor analysis. In particular,\nderivation or refutation of the model via other statistical means is a\nworthwhile project. In this paper we use the methodology of spectral clustering\nto articulate the structure in the dataset of responses of 20,993 subjects on a\n300-item item version of the IPIP NEO personality questionnaire, and we compare\nour results to those obtained from a factor analytic solution. We found support\nfor five- and six-cluster solutions. The five-cluster solution was similar to a\nconventional five-factor solution, but the six-cluster and six-factor solutions\ndiffered significantly, and only the six-cluster solution was readily\ninterpretable: it gave a model similar to the HEXACO model. We suggest that\nspectral clustering provides a robust alternative view of personality data.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jul 2011 19:45:14 GMT"}], "update_date": "2011-07-07", "authors_parsed": [["Brocklebank", "Sean", ""], ["Pauls", "Scott", ""], ["Rockmore", "Daniel", ""], ["Bates", "Timothy C.", ""]]}, {"id": "1107.1445", "submitter": "Gabriel Terejanu", "authors": "Gabriel Terejanu, Rochan R. Upadhyay, Kenji Miki", "title": "Bayesian experimental design for the active nitridation of graphite by\n  atomic nitrogen", "comments": "Preprint submitted to Experimental Thermal and Fluid Science,\n  February 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.data-an cs.IT math.IT stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of optimal data collection to efficiently learn the model\nparameters of a graphite nitridation experiment is studied in the context of\nBayesian analysis using both synthetic and real experimental data. The paper\nemphasizes that the optimal design can be obtained as a result of an\ninformation theoretic sensitivity analysis. Thus, the preferred design is where\nthe statistical dependence between the model parameters and observables is the\nhighest possible. In this paper, the statistical dependence between random\nvariables is quantified by mutual information and estimated using a k-nearest\nneighbor based approximation. It is shown, that by monitoring the inference\nprocess via measures such as entropy or Kullback-Leibler divergence, one can\ndetermine when to stop the data collection process. The methodology is applied\nto select the most informative designs on both a simulated data set and on an\nexperimental data set, previously published in the literature. It is also shown\nthat the sequential Bayesian analysis used in the experimental design can also\nbe useful in detecting conflicting information between measurements and model\npredictions.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jul 2011 16:46:43 GMT"}], "update_date": "2011-07-08", "authors_parsed": [["Terejanu", "Gabriel", ""], ["Upadhyay", "Rochan R.", ""], ["Miki", "Kenji", ""]]}, {"id": "1107.1545", "submitter": "Gabriel Terejanu", "authors": "Gabriel Terejanu, Yang Cheng, Tarunraj Singh, Peter D. Scott", "title": "Comparison of SCIPUFF Plume Prediction with Particle Filter Assimilated\n  Prediction for Dipole Pride 26 Data", "comments": "The Chemical and Biological Defense Physical Science and Technology\n  Conference, New Orleans, November 2008", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.DC physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the application of a particle filter for data\nassimilation in the context of puff-based dispersion models. Particle filters\nprovide estimates of the higher moments, and are well suited for strongly\nnonlinear and/or non-Gaussian models. The Gaussian puff model SCIPUFF, is used\nin predicting the chemical concentration field after a chemical incident. This\nmodel is highly nonlinear and evolves with variable state dimension and, after\nsufficient time, high dimensionality. While the particle filter formalism\nnaturally supports variable state dimensionality high dimensionality represents\na challenge in selecting an adequate number of particles, especially for the\nBootstrap version. We present an implementation of the Bootstrap particle\nfilter and compare its performance with the SCIPUFF predictions. Both the model\nand the Particle Filter are evaluated on the Dipole Pride 26 experimental data.\nSince there is no available ground truth, the data has been divided in two\nsets: training and testing. We show that even with a modest number of\nparticles, the Bootstrap particle filter provides better estimates of the\nconcentration field compared with the process model, without excessive increase\nin computational complexity.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jul 2011 01:59:45 GMT"}], "update_date": "2011-07-11", "authors_parsed": [["Terejanu", "Gabriel", ""], ["Cheng", "Yang", ""], ["Singh", "Tarunraj", ""], ["Scott", "Peter D.", ""]]}, {"id": "1107.1900", "submitter": "An Zeng", "authors": "Cheng-Jun Zhang, An Zeng", "title": "Behavior patterns of online users and the effect on information\n  filtering", "comments": "8 pages, 6 figures", "journal-ref": "Physica A 391, 1822 (2012)", "doi": "10.1016/j.physa.2011.09.038", "report-no": null, "categories": "physics.soc-ph cs.SI physics.data-an stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the structure and evolution of web-based user-object bipartite\nnetworks is an important task since they play a fundamental role in online\ninformation filtering. In this paper, we focus on investigating the patterns of\nonline users' behavior and the effect on recommendation process. Empirical\nanalysis on the e-commercial systems show that users have significant taste\ndiversity and their interests for niche items highly overlap. Additionally,\nrecommendation process are investigated on both the real networks and the\nreshuffled networks in which real users' behavior patterns can be gradually\ndestroyed. Our results shows that the performance of personalized\nrecommendation methods is strongly related to the real network structure.\nDetail study on each item shows that recommendation accuracy for hot items is\nalmost maximum and quite robust to the reshuffling process. However, niche\nitems cannot be accurately recommended after removing users' behavior patterns.\nOur work also is meaningful in practical sense since it reveals an effective\ndirection to improve the accuracy and the robustness of the existing\nrecommender systems.\n", "versions": [{"version": "v1", "created": "Sun, 10 Jul 2011 21:18:52 GMT"}], "update_date": "2015-05-28", "authors_parsed": [["Zhang", "Cheng-Jun", ""], ["Zeng", "An", ""]]}, {"id": "1107.2456", "submitter": "Andrew C. Thomas", "authors": "Andrew C. Thomas", "title": "Variance Decomposition and Replication In Scrabble: When You Can Blame\n  Your Tiles?", "comments": "16 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the game of Scrabble, letter tiles are drawn uniformly at random from a\nbag. The variability of possible draws as the game progresses is a source of\nvariation that makes it more likely for an inferior player to win a\nhead-to-head match against a superior player, and more difficult to determine\nthe true ability of a player in a tournament or contest. I propose a new format\nfor drawing tiles in a two-player game that allows for the same tile pattern\n(though not the same board) to be replicated over multiple matches, so that a\nplayer's result can be better compared against others, yet is indistinguishable\nfrom the bag-based draw within a game. A large number of simulations conducted\nwith Scrabble software shows that the variance from the tile order in this\nscheme accounts for as much variance as the different patterns of letters on\nthe board as the game progresses. I use these simulations as well as the\nexperimental design to show how much various tiles are able to affect player\nscores depending on their placement in the tile seeding.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jul 2011 03:12:03 GMT"}, {"version": "v2", "created": "Wed, 19 Oct 2011 17:18:49 GMT"}, {"version": "v3", "created": "Tue, 1 Nov 2011 15:53:08 GMT"}], "update_date": "2011-11-02", "authors_parsed": [["Thomas", "Andrew C.", ""]]}, {"id": "1107.2464", "submitter": "Faryad Darabi Sahneh", "authors": "Faryad Darabi Sahneh and Caterina Scoglio", "title": "Epidemic Spread in Human Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.SY math.DS stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the popular dynamics on complex networks is the epidemic spreading. An\nepidemic model describes how infections spread throughout a network. Among the\ncompartmental models used to describe epidemics, the\nSusceptible-Infected-Susceptible (SIS) model has been widely used. In the SIS\nmodel, each node can be susceptible, become infected with a given infection\nrate, and become again susceptible with a given curing rate. In this paper, we\nadd a new compartment to the classic SIS model to account for human response to\nepidemic spread. Each individual can be infected, susceptible, or alert.\nSusceptible individuals can become alert with an alerting rate if infected\nindividuals exist in their neighborhood. An individual in the alert state is\nless probable to become infected than an individual in the susceptible state;\ndue to a newly adopted cautious behavior. The problem is formulated as a\ncontinuous-time Markov process on a general static graph and then modeled into\na set of ordinary differential equations using mean field approximation method\nand the corresponding Kolmogorov forward equations. The model is then studied\nusing results from algebraic graph theory and center manifold theorem. We\nanalytically show that our model exhibits two distinct thresholds in the\ndynamics of epidemic spread. Below the first threshold, infection dies out\nexponentially. Beyond the second threshold, infection persists in the steady\nstate. Between the two thresholds, the infection spreads at the first stage but\nthen dies out asymptotically as the result of increased alertness in the\nnetwork. Finally, simulations are provided to support our findings. Our results\nsuggest that alertness can be considered as a strategy of controlling the\nepidemics which propose multiple potential areas of applications, from\ninfectious diseases mitigations to malware impact reduction.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jul 2011 04:58:25 GMT"}], "update_date": "2011-07-14", "authors_parsed": [["Sahneh", "Faryad Darabi", ""], ["Scoglio", "Caterina", ""]]}, {"id": "1107.3104", "submitter": "Anand Ramalingam", "authors": "Anand Ramalingam", "title": "Bernoulli Runs: Using \"Book Cricket\" to Evaluate Cricketers", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a simple method to evaluate batsmen and bowlers in\ncricket. The idea in this paper refines \"book cricket\" and evaluates a batsman\nby answering the question: How many runs a team consisting of same player\nreplicated eleven times will score?\n", "versions": [{"version": "v1", "created": "Fri, 15 Jul 2011 16:43:14 GMT"}], "update_date": "2011-07-18", "authors_parsed": [["Ramalingam", "Anand", ""]]}, {"id": "1107.3351", "submitter": "Yueqing Wang nancy", "authors": "Yueqing Wang, Xin Jiang, Bin Yu, and Ming Jiang", "title": "A Hierarchical Bayesian Approach for Aerosol Retrieval Using MISR Data", "comments": "39 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Atmospheric aerosols can cause serious damage to human health and life\nexpectancy. Using the radiances observed by NASA's Multi-angle Imaging\nSpectroRadiometer (MISR), the current MISR operational algorithm retrieves\nAerosol Optical Depth (AOD) at a spatial resolution of 17.6 km x 17.6 km. A\nsystematic study of aerosols and their impact on public health, especially in\nhighly-populated urban areas, requires a finer-resolution estimate of the\nspatial distribution of AOD values.\n  We embed MISR's operational weighted least squares criterion and its forward\nsimulations for AOD retrieval in a likelihood framework and further expand it\ninto a Bayesian hierarchical model to adapt to a finer spatial scale of 4.4 km\nx 4.4 km. To take advantage of AOD's spatial smoothness, our method borrows\nstrength from data at neighboring pixels by postulating a Gaussian Markov\nRandom Field prior for AOD. Our model considers both AOD and aerosol mixing\nvectors as continuous variables. The inference of AOD and mixing vectors is\ncarried out using Metropolis-within-Gibbs sampling methods. Retrieval\nuncertainties are quantified by posterior variabilities. We also implement a\nparallel MCMC algorithm to reduce computational cost. We assess our retrievals\nperformance using ground-based measurements from the AErosol RObotic NETwork\n(AERONET), a hand-held sunphotometer and satellite images from Google Earth.\n  Based on case studies in the greater Beijing area, China, we show that a 4.4\nkm resolution can improve the accuracy and coverage of remotely-sensed aerosol\nretrievals, as well as our understanding of the spatial and seasonal behaviors\nof aerosols. This improvement is particularly important during high-AOD events,\nwhich often indicate severe air pollution.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jul 2011 03:29:42 GMT"}, {"version": "v2", "created": "Thu, 26 Jul 2012 20:22:29 GMT"}], "update_date": "2012-07-30", "authors_parsed": [["Wang", "Yueqing", ""], ["Jiang", "Xin", ""], ["Yu", "Bin", ""], ["Jiang", "Ming", ""]]}, {"id": "1107.3382", "submitter": "Karen Kafadar", "authors": "Karen Kafadar", "title": "Special section on statistics in neuroscience", "comments": "Published in at http://dx.doi.org/10.1214/11-AOAS485 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2011, Vol. 5, No. 2B, 1127-1131", "doi": "10.1214/11-AOAS485", "report-no": "IMS-AOAS-AOAS485", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article provides a brief introduction to seven papers that are included\nin this special section on Statistics in Neuroscience: (1) Xiaoyan Shi, Joseph\nG. Ibrahim, Jeffrey Lieberman, Martin Styner, Yimei Li and Hongtu Zhu:\nTwo-state empirical likelihood for longitudinal neuroimaging data (2) Vincent\nQ. Vu, Pradeep Ravikumar, Thomas Naselaris, Kendrick N. Kay, Jack L. Gallant\nand Bin Yu: Encoding and decoding V1 fMRI responses to natural images with\nsparse nonparametric models (3) Sourabh Bhattacharya and Ranjan Maitra: A\nnonstationary nonparametric Bayesian approach to dynamically modeling effective\nconnectivity in functional magnetic resonance imaging experiments (4)\nChristopher J. Long, Patrick L. Purdon, Simona Temereanca, Neil U. Desai, Matti\nS. H\\\"{a}m\\\"{a}l\\\"{a}inen and Emery Neal Brown: State-space solutions to the\ndynamic magnetoencephalography inverse problem using high performance computing\n(5) Yuriy Mishchencko, Joshua T. Vogelstein and Liam Paninski: A Bayesian\napproach for inferring neuronal connectivity from calcium fluorescent imaging\ndata (6) Robert E. Kass, Ryan C. Kelly and Wei-Liem Loh: Assessment of\nsynchrony in multiple neural spike trains using loglinear point process models\n(7) Sofia Olhede and Brandon Whitcher: Nonparametric tests of structure for\nhigh angular resolution diffusion imaging in Q-space\n", "versions": [{"version": "v1", "created": "Mon, 18 Jul 2011 08:49:12 GMT"}], "update_date": "2011-07-19", "authors_parsed": [["Kafadar", "Karen", ""]]}, {"id": "1107.3681", "submitter": "Jo\\~ao P Rodrigues", "authors": "Mthokozisi Masuku and Jo\\~ao P. Rodrigues", "title": "How universal is the Wigner distribution?", "comments": "16 pages; references added", "journal-ref": null, "doi": "10.1088/1751-8113/45/8/085201", "report-no": "WITS-CTP-077", "categories": "hep-th cond-mat.stat-mech math.PR physics.data-an stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider Gaussian ensembles of m N x N complex matrices. We identify an\nenhanced symmetry in the system and the resultant closed subsector, which is\nnaturally associated with the radial sector of the theory. The density of\nradial eigenvalues is obtained in the large N limit. It is of the Wigner form\nonly for m=1. For m \\ge 2, the new form of the density is obtained.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jul 2011 10:50:34 GMT"}, {"version": "v2", "created": "Tue, 23 Aug 2011 15:51:32 GMT"}], "update_date": "2015-05-28", "authors_parsed": [["Masuku", "Mthokozisi", ""], ["Rodrigues", "Jo\u00e3o P.", ""]]}, {"id": "1107.4016", "submitter": "Andriy Miranskyy", "authors": "Andriy V. Miranskyy and Matthew Davison and Mark Reesor", "title": "Metrics of Risk Associated with Defects Rediscovery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software defects rediscovered by a large number of customers affect various\nstakeholders and may: 1) hint at gaps in a software manufacturer's Quality\nAssurance (QA) processes, 2) lead to an over-load of a software manufacturer's\nsupport and maintenance teams, and 3) consume customers' resources, leading to\na loss of reputation and a decrease in sales.\n  Quantifying risk associated with the rediscovery of defects can help all of\nthese stake-holders. In this chapter we present a set of metrics needed to\nquantify the risks. The metrics are designed to help: 1) the QA team to assess\ntheir processes; 2) the support and maintenance teams to allocate their\nresources; and 3) the customers to assess the risk associated with using the\nsoftware product. The paper includes a validation case study which applies the\nrisk metrics to industrial data. To calculate the metrics we use mathematical\ninstruments like the heavy-tailed Kappa distribution and the G/M/k queuing\nmodel.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jul 2011 16:01:00 GMT"}], "update_date": "2011-07-21", "authors_parsed": [["Miranskyy", "Andriy V.", ""], ["Davison", "Matthew", ""], ["Reesor", "Mark", ""]]}, {"id": "1107.4047", "submitter": "Eric Ford", "authors": "Eric B. Ford (UF), Althea V. Moorhead (UF), Dimitri Veras (UF, IoA)", "title": "A Bayesian Surrogate Model for Rapid Time Series Analysis and\n  Application to Exoplanet Observations", "comments": "25 pages, 4 figures, accepted to Bayesian Analysis\n  <http://ba.stat.cmu.edu>, special issue for Ninth Valencia International\n  Conference on Bayesian Statistics", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME astro-ph.EP astro-ph.IM stat.AP stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a Bayesian surrogate model for the analysis of periodic or\nquasi-periodic time series data. We describe a computationally efficient\nimplementation that enables Bayesian model comparison. We apply this model to\nsimulated and real exoplanet observations. We discuss the results and\ndemonstrate some of the challenges for applying our surrogate model to\nrealistic exoplanet data sets. In particular, we find that analyses of real\nworld data should pay careful attention to the effects of uneven spacing of\nobservations and the choice of prior for the \"jitter\" parameter.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jul 2011 17:47:43 GMT"}], "update_date": "2011-07-21", "authors_parsed": [["Ford", "Eric B.", "", "UF"], ["Moorhead", "Althea V.", "", "UF"], ["Veras", "Dimitri", "", "UF, IoA"]]}, {"id": "1107.4181", "submitter": "Sourabh Bhattacharya", "authors": "Sourabh Bhattacharya, Ranjan Maitra", "title": "A nonstationary nonparametric Bayesian approach to dynamically modeling\n  effective connectivity in functional magnetic resonance imaging experiments", "comments": "Published in at http://dx.doi.org/10.1214/11-AOAS470 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2011, Vol. 5, No. 2B, 1183-1206", "doi": "10.1214/11-AOAS470", "report-no": "IMS-AOAS-AOAS470", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effective connectivity analysis provides an understanding of the functional\norganization of the brain by studying how activated regions influence one\nother. We propose a nonparametric Bayesian approach to model effective\nconnectivity assuming a dynamic nonstationary neuronal system. Our approach\nuses the Dirichlet process to specify an appropriate (most plausible according\nto our prior beliefs) dynamic model as the \"expectation\" of a set of plausible\nmodels upon which we assign a probability distribution. This addresses model\nuncertainty associated with dynamic effective connectivity. We derive a Gibbs\nsampling approach to sample from the joint (and marginal) posterior\ndistributions of the unknowns. Results on simulation experiments demonstrate\nour model to be flexible and a better candidate in many situations. We also\nused our approach to analyzing functional Magnetic Resonance Imaging (fMRI)\ndata on a Stroop task: our analysis provided new insight into the mechanism by\nwhich an individual brain distinguishes and learns about shapes of objects.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jul 2011 06:56:34 GMT"}], "update_date": "2011-07-22", "authors_parsed": [["Bhattacharya", "Sourabh", ""], ["Maitra", "Ranjan", ""]]}, {"id": "1107.4192", "submitter": "Christopher J. Long", "authors": "Christopher J. Long, Patrick L. Purdon, Simona Temereanca, Neil U.\n  Desai, Matti S. H\\\"am\\\"al\\\"ainen, Emery N. Brown", "title": "State-space solutions to the dynamic magnetoencephalography inverse\n  problem using high performance computing", "comments": "Published in at http://dx.doi.org/10.1214/11-AOAS483 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2011, Vol. 5, No. 2B, 1207-1228", "doi": "10.1214/11-AOAS483", "report-no": "IMS-AOAS-AOAS483", "categories": "stat.AP physics.med-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Determining the magnitude and location of neural sources within the brain\nthat are responsible for generating magnetoencephalography (MEG) signals\nmeasured on the surface of the head is a challenging problem in functional\nneuroimaging. The number of potential sources within the brain exceeds by an\norder of magnitude the number of recording sites. As a consequence, the\nestimates for the magnitude and location of the neural sources will be\nill-conditioned because of the underdetermined nature of the problem. One\nwell-known technique designed to address this imbalance is the minimum norm\nestimator (MNE). This approach imposes an $L^2$ regularization constraint that\nserves to stabilize and condition the source parameter estimates. However,\nthese classes of regularizer are static in time and do not consider the\ntemporal constraints inherent to the biophysics of the MEG experiment. In this\npaper we propose a dynamic state-space model that accounts for both spatial and\ntemporal correlations within and across candidate intracortical sources. In our\nmodel, the observation model is derived from the steady-state solution to\nMaxwell's equations while the latent model representing neural dynamics is\ngiven by a random walk process.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jul 2011 08:02:29 GMT"}], "update_date": "2011-07-22", "authors_parsed": [["Long", "Christopher J.", ""], ["Purdon", "Patrick L.", ""], ["Temereanca", "Simona", ""], ["Desai", "Neil U.", ""], ["H\u00e4m\u00e4l\u00e4inen", "Matti S.", ""], ["Brown", "Emery N.", ""]]}, {"id": "1107.4228", "submitter": "Yuriy Mishchencko", "authors": "Yuriy Mishchencko, Joshua T. Vogelstein, Liam Paninski", "title": "A Bayesian approach for inferring neuronal connectivity from calcium\n  fluorescent imaging data", "comments": "Published in at http://dx.doi.org/10.1214/09-AOAS303 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2011, Vol. 5, No. 2B, 1229-1261", "doi": "10.1214/09-AOAS303", "report-no": "IMS-AOAS-AOAS303", "categories": "stat.AP q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deducing the structure of neural circuits is one of the central problems of\nmodern neuroscience. Recently-introduced calcium fluorescent imaging methods\npermit experimentalists to observe network activity in large populations of\nneurons, but these techniques provide only indirect observations of neural\nspike trains, with limited time resolution and signal quality. In this work we\npresent a Bayesian approach for inferring neural circuitry given this type of\nimaging data. We model the network activity in terms of a collection of coupled\nhidden Markov chains, with each chain corresponding to a single neuron in the\nnetwork and the coupling between the chains reflecting the network's\nconnectivity matrix. We derive a Monte Carlo Expectation--Maximization\nalgorithm for fitting the model parameters; to obtain the sufficient statistics\nin a computationally-efficient manner, we introduce a specialized\nblockwise-Gibbs algorithm for sampling from the joint activity of all observed\nneurons given the observed fluorescence data. We perform large-scale\nsimulations of randomly connected neuronal networks with biophysically\nrealistic parameters and find that the proposed methods can accurately infer\nthe connectivity in these networks given reasonable experimental and\ncomputational constraints. In addition, the estimation accuracy may be improved\nsignificantly by incorporating prior knowledge about the sparseness of\nconnectivity in the network, via standard L$_1$ penalization methods.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jul 2011 10:33:59 GMT"}], "update_date": "2011-07-22", "authors_parsed": [["Mishchencko", "Yuriy", ""], ["Vogelstein", "Joshua T.", ""], ["Paninski", "Liam", ""]]}, {"id": "1107.4799", "submitter": "Mikhail Simkin", "authors": "M. V. Simkin", "title": "Scientific comparison of Mozart and Salieri", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  I report the results of the internet quiz, where the takers had to tell the\nmusic of Mozart from that of Salieri. The average score earned by over eleven\nthousand quiz-takers is 61%. This suggests that the music of Mozart is of about\nthe same quality as the music of Salieri.\n", "versions": [{"version": "v1", "created": "Sun, 24 Jul 2011 20:59:28 GMT"}], "update_date": "2011-07-26", "authors_parsed": [["Simkin", "M. V.", ""]]}, {"id": "1107.4843", "submitter": "Lorenzo Trippa", "authors": "Lorenzo Trippa, Giovanni Parmigiani", "title": "False discovery rates in somatic mutation studies of cancer", "comments": "Published in at http://dx.doi.org/10.1214/10-AOAS438 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2011, Vol. 5, No. 2B, 1360-1378", "doi": "10.1214/10-AOAS438", "report-no": "IMS-AOAS-AOAS438", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The purpose of cancer genome sequencing studies is to determine the nature\nand types of alterations present in a typical cancer and to discover genes\nmutated at high frequencies. In this article we discuss statistical methods for\nthe analysis of somatic mutation frequency data generated in these studies. We\nplace special emphasis on a two-stage study design introduced by Sj\\\"{o}blom et\nal. [Science 314 (2006) 268--274]. In this context, we describe and compare\nstatistical methods for constructing scores that can be used to prioritize\ncandidate genes for further investigation and to assess the statistical\nsignificance of the candidates thus identified. Controversy has surrounded the\nreliability of the false discovery rates estimates provided by the\napproximations used in early cancer genome studies. To address these, we\ndevelop a semiparametric Bayesian model that provides an accurate fit to the\ndata. We use this model to generate a large collection of realistic scenarios,\nand evaluate alternative approaches on this collection. Our assessment is\nimpartial in that the model used for generating data is not used by any of the\napproaches compared. And is objective, in that the scenarios are generated by a\nmodel that fits data. Our results quantify the conservative control of the\nfalse discovery rate with the Benjamini and Hockberg method compared to the\nempirical Bayes approach and the multiple testing method proposed in Storey [J.\nR. Stat. Soc. Ser. B Stat. Methodol. 64 (2002) 479--498]. Simulation results\nalso show a negligible departure from the target false discovery rate for the\nmethodology used in Sj\\\"{o}blom et al. [Science 314 (2006) 268--274].\n", "versions": [{"version": "v1", "created": "Mon, 25 Jul 2011 05:37:12 GMT"}], "update_date": "2011-07-26", "authors_parsed": [["Trippa", "Lorenzo", ""], ["Parmigiani", "Giovanni", ""]]}, {"id": "1107.4852", "submitter": "Nozer D. Singpurwalla", "authors": "Nozer D. Singpurwalla", "title": "Network routing in a dynamic environment", "comments": "Published in at http://dx.doi.org/10.1214/10-AOAS453 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2011, Vol. 5, No. 2B, 1407-1424", "doi": "10.1214/10-AOAS453", "report-no": "IMS-AOAS-AOAS453", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, there has been an explosion of work on network routing in hostile\nenvironments. Hostile environments tend to be dynamic, and the motivation for\nthis work stems from the scenario of IED placements by insurgents in a\nlogistical network. For discussion, we consider here a sub-network abstracted\nfrom a real network, and propose a framework for route selection. What\ndistinguishes our work from related work is its decision theoretic foundation,\nand statistical considerations pertaining to probability assessments. The\nlatter entails the fusion of data from diverse sources, modeling the\nsocio-psychological behavior of adversaries, and likelihood functions that are\ninduced by simulation. This paper demonstrates the role of statistical\ninference and data analysis on problems that have traditionally belonged in the\ndomain of computer science, communications, transportation science, and\noperations research.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jul 2011 06:44:07 GMT"}], "update_date": "2011-07-26", "authors_parsed": [["Singpurwalla", "Nozer D.", ""]]}, {"id": "1107.4855", "submitter": "Vishesh Karwa", "authors": "Vishesh Karwa, Aleksandra B. Slavkovi\\'c, Eric T. Donnell", "title": "Causal inference in transportation safety studies: Comparison of\n  potential outcomes and causal diagrams", "comments": "Published in at http://dx.doi.org/10.1214/10-AOAS440 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2011, Vol. 5, No. 2B, 1428-1455", "doi": "10.1214/10-AOAS440", "report-no": "IMS-AOAS-AOAS440", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The research questions that motivate transportation safety studies are causal\nin nature. Safety researchers typically use observational data to answer such\nquestions, but often without appropriate causal inference methodology. The\nfield of causal inference presents several modeling frameworks for probing\nempirical data to assess causal relations. This paper focuses on exploring the\napplicability of two such modeling frameworks---Causal Diagrams and Potential\nOutcomes---for a specific transportation safety problem. The causal effects of\npavement marking retroreflectivity on safety of a road segment were estimated.\nMore specifically, the results based on three different implementations of\nthese frameworks on a real data set were compared: Inverse Propensity Score\nWeighting with regression adjustment and Propensity Score Matching with\nregression adjustment versus Causal Bayesian Network. The effect of increased\npavement marking retroreflectivity was generally found to reduce the\nprobability of target nighttime crashes. However, we found that the magnitude\nof the causal effects estimated are sensitive to the method used and to the\nassumptions being violated.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jul 2011 07:36:41 GMT"}], "update_date": "2011-07-26", "authors_parsed": [["Karwa", "Vishesh", ""], ["Slavkovi\u0107", "Aleksandra B.", ""], ["Donnell", "Eric T.", ""]]}, {"id": "1107.4868", "submitter": "Saijuan Zhang", "authors": "Saijuan Zhang, Raymond J. Carroll, Douglas Midthune, Patricia M.\n  Guenther, Susan M. Krebs-Smith, Victor Kipnis, Kevin W. Dodd, Dennis W.\n  Buckman, Janet A. Tooze, Laurence Freedman", "title": "A new multivariate measurement error model with zero-inflated dietary\n  data, and its application to dietary assessment", "comments": "Published in at http://dx.doi.org/10.1214/10-AOAS446 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2011, Vol. 5, No. 2B, 1456-1487", "doi": "10.1214/10-AOAS446", "report-no": "IMS-AOAS-AOAS446", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the United States the preferred method of obtaining dietary intake data is\nthe 24-hour dietary recall, yet the measure of most interest is usual or\nlong-term average daily intake, which is impossible to measure. Thus, usual\ndietary intake is assessed with considerable measurement error. Also, diet\nrepresents numerous foods, nutrients and other components, each of which have\ndistinctive attributes. Sometimes, it is useful to examine intake of these\ncomponents separately, but increasingly nutritionists are interested in\nexploring them collectively to capture overall dietary patterns. Consumption of\nthese components varies widely: some are consumed daily by almost everyone on\nevery day, while others are episodically consumed so that 24-hour recall data\nare zero-inflated. In addition, they are often correlated with each other.\nFinally, it is often preferable to analyze the amount of a dietary component\nrelative to the amount of energy (calories) in a diet because dietary\nrecommendations often vary with energy level. The quest to understand overall\ndietary patterns of usual intake has to this point reached a standstill. There\nare no statistical methods or models available to model such complex\nmultivariate data with its measurement error and zero inflation. This paper\nproposes the first such model, and it proposes the first workable solution to\nfit such a model. After describing the model, we use survey-weighted MCMC\ncomputations to fit the model, with uncertainty estimation coming from balanced\nrepeated replication.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jul 2011 09:08:23 GMT"}], "update_date": "2011-07-26", "authors_parsed": [["Zhang", "Saijuan", ""], ["Carroll", "Raymond J.", ""], ["Midthune", "Douglas", ""], ["Guenther", "Patricia M.", ""], ["Krebs-Smith", "Susan M.", ""], ["Kipnis", "Victor", ""], ["Dodd", "Kevin W.", ""], ["Buckman", "Dennis W.", ""], ["Tooze", "Janet A.", ""], ["Freedman", "Laurence", ""]]}, {"id": "1107.4905", "submitter": "Jenn\\'{y} Brynjarsd\\'{o}ttir", "authors": "Jenn\\'y Brynjarsd\\'ottir, L. Mark Berliner", "title": "Bayesian hierarchical modeling for temperature reconstruction from\n  geothermal data", "comments": "Published in at http://dx.doi.org/10.1214/10-AOAS452 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2011, Vol. 5, No. 2B, 1328-1359", "doi": "10.1214/10-AOAS452", "report-no": "IMS-AOAS-AOAS452", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a Bayesian hierarchical modeling approach to paleoclimate\nreconstruction using borehole temperature profiles. The approach relies on\nmodeling heat conduction in solids via the heat equation with step function,\nsurface boundary conditions. Our analysis includes model error and assumes that\nthe boundary conditions are random processes. The formulation also enables\nseparation of measurement error and model error. We apply the analysis to data\nfrom nine borehole temperature records from the San Rafael region in Utah. We\nproduce ground surface temperature histories with uncertainty estimates for the\npast 400 years. We pay special attention to use of prior parameter models that\nillustrate borrowing strength in a combined analysis for all nine boreholes. In\naddition, we review selected sensitivity analyses.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jul 2011 11:42:58 GMT"}], "update_date": "2011-07-26", "authors_parsed": [["Brynjarsd\u00f3ttir", "Jenn\u00fd", ""], ["Berliner", "L. Mark", ""]]}, {"id": "1107.4919", "submitter": "David S. Matteson", "authors": "David S. Matteson, Mathew W. McLean, Dawn B. Woodard, Shane G.\n  Henderson", "title": "Forecasting emergency medical service call arrival rates", "comments": "Published in at http://dx.doi.org/10.1214/10-AOAS442 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2011, Vol. 5, No. 2B, 1379-1406", "doi": "10.1214/10-AOAS442", "report-no": "IMS-AOAS-AOAS442", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new method for forecasting emergency call arrival rates that\ncombines integer-valued time series models with a dynamic latent factor\nstructure. Covariate information is captured via simple constraints on the\nfactor loadings. We directly model the count-valued arrivals per hour, rather\nthan using an artificial assumption of normality. This is crucial for the\nemergency medical service context, in which the volume of calls may be very\nlow. Smoothing splines are used in estimating the factor levels and loadings to\nimprove long-term forecasts. We impose time series structure at the hourly\nlevel, rather than at the daily level, capturing the fine-scale dependence in\naddition to the long-term structure. Our analysis considers all emergency\npriority calls received by Toronto EMS between January 2007 and December 2008\nfor which an ambulance was dispatched. Empirical results demonstrate\nsignificantly reduced error in forecasting call arrival volume. To quantify the\nimpact of reduced forecast errors, we design a queueing model simulation that\napproximates the dynamics of an ambulance system. The results show better\nperformance as the forecasting method improves. This notion of quantifying the\noperational impact of improved statistical procedures may be of independent\ninterest.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jul 2011 12:30:57 GMT"}], "update_date": "2011-07-26", "authors_parsed": [["Matteson", "David S.", ""], ["McLean", "Mathew W.", ""], ["Woodard", "Dawn B.", ""], ["Henderson", "Shane G.", ""]]}, {"id": "1107.5121", "submitter": "Andrew C. Thomas", "authors": "Andrew C. Thomas, Stephen E. Fienberg", "title": "Discussion of \"Network routing in a dynamic environment\"", "comments": "Published in at http://dx.doi.org/10.1214/11-AOAS453A the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2011, Vol. 5, No. 2B, 1425-1427", "doi": "10.1214/11-AOAS453A", "report-no": "IMS-AOAS-AOAS453A", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discussion of \"Network routing in a dynamic environment\" by N.D. Singpurwalla\n[arXiv:1107.4852]\n", "versions": [{"version": "v1", "created": "Tue, 26 Jul 2011 05:47:51 GMT"}], "update_date": "2011-07-27", "authors_parsed": [["Thomas", "Andrew C.", ""], ["Fienberg", "Stephen E.", ""]]}, {"id": "1107.5338", "submitter": "Elisa Loza-Reyes Dr", "authors": "Elisa Loza-Reyes, Merrilee Hurn and Tony Robinson", "title": "Classification of molecular sequence data using Bayesian phylogenetic\n  mixture models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rate variation among the sites of a molecular sequence is commonly found in\napplications of phylogenetic inference. Several approaches exist to account for\nthis feature but they do not usually enable the investigator to pinpoint the\nsites that evolve under one or another rate of evolution in a straightforward\nmanner. The focus is on Bayesian phylogenetic mixture models, augmented with\nallocation variables, as tools for site classification and quantification of\nclassification uncertainty. The method does not rely on prior knowledge of site\nmembership to classes or even the number of classes. Furthermore, it does not\nrequire correlated sites to be next to one another in the sequence alignment,\nunlike some phylogenetic hidden Markov or change-point models. In the approach\npresented, model selection on the number and type of mixture components is\nconducted ahead of both model estimation and site classification; the\nsteppingstone sampler (SS) is used to select amongst competing mixture models.\nExample applications of simulated data and mitochondrial DNA of primates\nillustrate site classification via 'augmented' Bayesian phylogenetic mixtures.\nIn both examples, all mixtures outperform commonly-used models of among-site\nrate variation and models that do not account for rate heterogeneity. The\nexamples further demonstrate how site classification is readily available from\nthe analysis output. The method is directly relevant to the choice of\npartitions in Bayesian phylogenetics, and its application may lead to the\ndiscovery of structure not otherwise recognised in a molecular sequence\nalignment. Computational aspects of Bayesian phylogenetic model estimation are\ndiscussed, including the use of simple Markov chain Monte Carlo (MCMC) moves\nthat mix efficiently without tempering the chains.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jul 2011 21:24:16 GMT"}, {"version": "v2", "created": "Tue, 28 Aug 2012 17:29:49 GMT"}, {"version": "v3", "created": "Mon, 8 Apr 2013 10:51:23 GMT"}, {"version": "v4", "created": "Tue, 9 Apr 2013 07:40:36 GMT"}, {"version": "v5", "created": "Wed, 22 May 2013 19:41:25 GMT"}], "update_date": "2013-05-23", "authors_parsed": [["Loza-Reyes", "Elisa", ""], ["Hurn", "Merrilee", ""], ["Robinson", "Tony", ""]]}, {"id": "1107.5407", "submitter": "Leanna L. House", "authors": "Leanna L. House, Merlise A. Clyde, Robert L. Wolpert", "title": "Bayesian nonparametric models for peak identification in MALDI-TOF mass\n  spectroscopy", "comments": "Published in at http://dx.doi.org/10.1214/10-AOAS450 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2011, Vol. 5, No. 2B, 1488-1511", "doi": "10.1214/10-AOAS450", "report-no": "IMS-AOAS-AOAS450", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel nonparametric Bayesian approach based on L\\'{e}vy Adaptive\nRegression Kernels (LARK) to model spectral data arising from MALDI-TOF (Matrix\nAssisted Laser Desorption Ionization Time-of-Flight) mass spectrometry. This\nmodel-based approach provides identification and quantification of proteins\nthrough model parameters that are directly interpretable as the number of\nproteins, mass and abundance of proteins and peak resolution, while having the\nability to adapt to unknown smoothness as in wavelet based methods. Informative\nprior distributions on resolution are key to distinguishing true peaks from\nbackground noise and resolving broad peaks into individual peaks for multiple\nprotein species. Posterior distributions are obtained using a reversible jump\nMarkov chain Monte Carlo algorithm and provide inference about the number of\npeaks (proteins), their masses and abundance. We show through simulation\nstudies that the procedure has desirable true-positive and false-discovery\nrates. Finally, we illustrate the method on five example spectra: a blank\nspectrum, a spectrum with only the matrix of a low-molecular-weight substance\nused to embed target proteins, a spectrum with known proteins, and a single\nspectrum and average of ten spectra from an individual lung cancer patient.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jul 2011 08:18:43 GMT"}], "update_date": "2011-07-28", "authors_parsed": [["House", "Leanna L.", ""], ["Clyde", "Merlise A.", ""], ["Wolpert", "Robert L.", ""]]}, {"id": "1107.5423", "submitter": "Irene Rocchetti", "authors": "Irene Rocchetti, John Bunge, Dankmar B\\\"ohning", "title": "Population size estimation based upon ratios of recapture probabilities", "comments": "Published in at http://dx.doi.org/10.1214/10-AOAS436 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2011, Vol. 5, No. 2B, 1512-1533", "doi": "10.1214/10-AOAS436", "report-no": "IMS-AOAS-AOAS436", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating the size of an elusive target population is of prominent interest\nin many areas in the life and social sciences. Our aim is to provide an\nefficient and workable method to estimate the unknown population size, given\nthe frequency distribution of counts of repeated identifications of units of\nthe population of interest. This counting variable is necessarily\nzero-truncated, since units that have never been identified are not in the\nsample. We consider several applications: clinical medicine, where interest is\nin estimating patients with adenomatous polyps which have been overlooked by\nthe diagnostic procedure; drug user studies, where interest is in estimating\nthe number of hidden drug users which are not identified; veterinary\nsurveillance of scrapie in the UK, where interest is in estimating the hidden\namount of scrapie; and entomology and microbial ecology, where interest is in\nestimating the number of unobserved species of organisms. In all these\nexamples, simple models such as the homogenous Poisson are not appropriate\nsince they do not account for present and latent heterogeneity. The\nPoisson-Gamma (negative binomial) model provides a flexible alternative and\noften leads to well-fitting models. It has a long history and was recently used\nin the development of the Chao-Bunge estimator. Here we use a different\nproperty of the Poisson-Gamma model: if we consider ratios of neighboring\nPoisson-Gamma probabilities, then these are linearly related to the counts of\nrepeated identifications.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jul 2011 09:43:21 GMT"}], "update_date": "2011-07-28", "authors_parsed": [["Rocchetti", "Irene", ""], ["Bunge", "John", ""], ["B\u00f6hning", "Dankmar", ""]]}, {"id": "1107.5517", "submitter": "Matthew Sperrin", "authors": "Matthew Sperrin and Thomas Jaki", "title": "Recovering Direct Effects in Genetics: A Comparison", "comments": "19 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In genetics it is often of interest to discover single nucleotide\npolymorphisms (SNPs) that are directly related to a disease, rather than just\nbeing associated with it. Few methods exist, however, addressing this so-called\n`true sparsity recovery' issue. In a thorough simulation study, we show that\nfor moderate or low correlation between predictors, lasso-based methods perform\nwell at true sparsity recovery, despite not being specifically designed for\nthis purpose. For large correlations, however, more specialised methods are\nneeded. Stability selection and direct effect testing perform well in all\nsituations, including when the correlation is large.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jul 2011 16:11:35 GMT"}], "update_date": "2011-07-28", "authors_parsed": [["Sperrin", "Matthew", ""], ["Jaki", "Thomas", ""]]}, {"id": "1107.5658", "submitter": "Gilles Fa\\\"{y}", "authors": "Gilles Fa\\\"y, Jacques Delabrouille, G\\'erard Kerkyacharian, Dominique\n  Picard", "title": "Testing the isotropy of high energy cosmic rays using spherical needlets", "comments": "Published in at http://dx.doi.org/10.1214/12-AOAS619 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2013, Vol. 7, No. 2, 1040-1073", "doi": "10.1214/12-AOAS619", "report-no": "IMS-AOAS-AOAS619", "categories": "stat.AP astro-ph.HE stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For many decades, ultrahigh energy charged particles of unknown origin that\ncan be observed from the ground have been a puzzle for particle physicists and\nastrophysicists. As an attempt to discriminate among several possible\nproduction scenarios, astrophysicists try to test the statistical isotropy of\nthe directions of arrival of these cosmic rays. At the highest energies, they\nare supposed to point toward their sources with good accuracy. However, the\nobservations are so rare that testing the distribution of such samples of\ndirectional data on the sphere is nontrivial. In this paper, we choose a\nnonparametric framework that makes weak hypotheses on the alternative\ndistributions and allows in turn to detect various and possibly unexpected\nforms of anisotropy. We explore two particular procedures. Both are derived\nfrom fitting the empirical distribution with wavelet expansions of densities.\nWe use the wavelet frame introduced by [SIAM J. Math. Anal. 38 (2006b) 574-594\n(electronic)], the so-called needlets. The expansions are truncated at scale\nindices no larger than some ${J^{\\star}}$, and the $L^p$ distances between\nthose estimates and the null density are computed. One family of tests (called\nMultiple) is based on the idea of testing the distance from the null for each\nchoice of $J=1,\\ldots,{J^{\\star}}$, whereas the so-called PlugIn approach is\nbased on the single full ${J^{\\star}}$ expansion, but with thresholded wavelet\ncoefficients. We describe the practical implementation of these two procedures\nand compare them to other methods in the literature. As alternatives to\nisotropy, we consider both very simple toy models and more realistic\nnonisotropic models based on Physics-inspired simulations. The Monte Carlo\nstudy shows good performance of the Multiple test, even at moderate sample\nsize, for a wide sample of alternative hypotheses and for different choices of\nthe parameter ${J^{\\star}}$. On the 69 most energetic events published by the\nPierre Auger Collaboration, the needlet-based procedures suggest statistical\nevidence for anisotropy. Using several values for the parameters of the\nmethods, our procedures yield $p$-values below 1%, but with uncontrolled\nmultiplicity issues. The flexibility of this method and the possibility to\nmodify it to take into account a large variety of extensions of the problem\nmake it an interesting option for future investigation of the origin of\nultrahigh energy cosmic rays.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jul 2011 09:33:46 GMT"}, {"version": "v2", "created": "Sat, 23 Jun 2012 00:02:22 GMT"}, {"version": "v3", "created": "Fri, 6 Dec 2013 13:24:00 GMT"}], "update_date": "2013-12-09", "authors_parsed": [["Fa\u00ff", "Gilles", ""], ["Delabrouille", "Jacques", ""], ["Kerkyacharian", "G\u00e9rard", ""], ["Picard", "Dominique", ""]]}, {"id": "1107.5712", "submitter": "Rensheng R. Zhou", "authors": "Rensheng R. Zhou, Nicoleta Serban, Nagi Gebraeel", "title": "Degradation modeling applied to residual lifetime prediction using\n  functional data analysis", "comments": "Published in at http://dx.doi.org/10.1214/10-AOAS448 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2011, Vol. 5, No. 2B, 1586-1610", "doi": "10.1214/10-AOAS448", "report-no": "IMS-AOAS-AOAS448", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sensor-based degradation signals measure the accumulation of damage of an\nengineering system using sensor technology. Degradation signals can be used to\nestimate, for example, the distribution of the remaining life of partially\ndegraded systems and/or their components. In this paper we present a\nnonparametric degradation modeling framework for making inference on the\nevolution of degradation signals that are observed sparsely or over short\nintervals of times. Furthermore, an empirical Bayes approach is used to update\nthe stochastic parameters of the degradation model in real-time using training\ndegradation signals for online monitoring of components operating in the field.\nThe primary application of this Bayesian framework is updating the residual\nlifetime up to a degradation threshold of partially degraded components. We\nvalidate our degradation modeling approach using a real-world crack growth data\nset as well as a case study of simulated degradation signals.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jul 2011 13:26:29 GMT"}], "update_date": "2011-07-29", "authors_parsed": [["Zhou", "Rensheng R.", ""], ["Serban", "Nicoleta", ""], ["Gebraeel", "Nagi", ""]]}, {"id": "1107.5805", "submitter": "Tom Loredo", "authors": "Thomas J. Loredo", "title": "Rotating Stars and Revolving Planets: Bayesian Exploration of the\n  Pulsating Sky", "comments": "28 pages, 6 figures. Invited discussion paper for the Ninth Valencia\n  International Conference on Bayesian Statistics (discussant was Peter\n  Mueller); to appear in \"Bayesian Statistics 9,\" ed. by Jos\\'e M. Bernardo et\n  al., Oxford University Press (2011); see\n  http://ukcatalogue.oup.com/product/9780199694587.do", "journal-ref": null, "doi": "10.1093/acprof:oso/9780199694587.001.0001", "report-no": null, "categories": "astro-ph.IM astro-ph.EP astro-ph.HE stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  I describe ongoing work on development of Bayesian methods for exploring\nperiodically varying phenomena in astronomy, addressing two classes of sources:\npulsars, and extrasolar planets (exoplanets). For pulsars, the methods aim to\ndetect and measure periodically varying signals in data consisting of photon\narrival times, modeled as non-homogeneous Poisson point processes. For\nexoplanets, the methods address detection and estimation of planetary orbits\nusing observations of the reflex motion \"wobble\" of a host star, including\nadaptive scheduling of observations to optimize inferences.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jul 2011 19:51:53 GMT"}], "update_date": "2012-04-27", "authors_parsed": [["Loredo", "Thomas J.", ""]]}, {"id": "1107.5838", "submitter": "Jen-Hao Yeh", "authors": "Jen-Hao Yeh, Thomas M. Antonsen, Edward Ott, Steven M. Anlage", "title": "A first-principles model of time-dependent variations in transmission\n  through a fluctuating scattering environment", "comments": "4 pages, 2 figures", "journal-ref": "Phys. Rev. E 85, 015202(R) (2012)", "doi": "10.1103/PhysRevE.85.015202", "report-no": null, "categories": "nlin.CD cond-mat.stat-mech stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fading is the time-dependent variation in transmitted signal strength through\na complex medium, due to interference or temporally evolving multipath\nscattering. In this paper we use random matrix theory (RMT) to establish a\nfirst-principles model for fading, including both universal and non-universal\neffects. This model provides a more general understanding of the most common\nstatistical models (Rayleigh fading and Rice fading) and provides a detailed\nphysical basis for their parameters. We also report experimental tests on two\nray-chaotic microwave cavities. The results show that our RMT model agrees with\nthe Rayleigh/Rice models in the high loss regime, but there are strong\ndeviations in low-loss systems where the RMT approach describes the data well.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jul 2011 22:08:45 GMT"}, {"version": "v2", "created": "Mon, 5 Dec 2011 23:04:41 GMT"}], "update_date": "2012-01-30", "authors_parsed": [["Yeh", "Jen-Hao", ""], ["Antonsen", "Thomas M.", ""], ["Ott", "Edward", ""], ["Anlage", "Steven M.", ""]]}, {"id": "1107.5872", "submitter": "Robert E. Kass", "authors": "Robert E. Kass, Ryan C. Kelly, Wei-Liem Loh", "title": "Assessment of synchrony in multiple neural spike trains using loglinear\n  point process models", "comments": "Published in at http://dx.doi.org/10.1214/10-AOAS429 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2011, Vol. 5, No. 2B, 1262-1292", "doi": "10.1214/10-AOAS429", "report-no": "IMS-AOAS-AOAS429", "categories": "stat.AP q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural spike trains, which are sequences of very brief jumps in voltage\nacross the cell membrane, were one of the motivating applications for the\ndevelopment of point process methodology. Early work required the assumption of\nstationarity, but contemporary experiments often use time-varying stimuli and\nproduce time-varying neural responses. More recently, many statistical methods\nhave been developed for nonstationary neural point process data. There has also\nbeen much interest in identifying synchrony, meaning events across two or more\nneurons that are nearly simultaneous at the time scale of the recordings. A\nnatural statistical approach is to discretize time, using short time bins, and\nto introduce loglinear models for dependency among neurons, but previous use of\nloglinear modeling technology has assumed stationarity. We introduce a succinct\nyet powerful class of time-varying loglinear models by (a) allowing\nindividual-neuron effects (main effects) to involve time-varying intensities;\n(b) also allowing the individual-neuron effects to involve autocovariation\neffects (history effects) due to past spiking, (c) assuming excess synchrony\neffects (interaction effects) do not depend on history, and (d) assuming all\neffects vary smoothly across time.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jul 2011 05:18:38 GMT"}], "update_date": "2011-08-01", "authors_parsed": [["Kass", "Robert E.", ""], ["Kelly", "Ryan C.", ""], ["Loh", "Wei-Liem", ""]]}, {"id": "1107.5883", "submitter": "Bj\\\"{o}rn Bornkamp", "authors": "Bj\\\"orn Bornkamp, Frank Bretz, Holger Dette, Jos\\'e Pinheiro", "title": "Response-adaptive dose-finding under model uncertainty", "comments": "Published in at http://dx.doi.org/10.1214/10-AOAS445 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2011, Vol. 5, No. 2B, 1611-1631", "doi": "10.1214/10-AOAS445", "report-no": "IMS-AOAS-AOAS445", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dose-finding studies are frequently conducted to evaluate the effect of\ndifferent doses or concentration levels of a compound on a response of\ninterest. Applications include the investigation of a new medicinal drug, a\nherbicide or fertilizer, a molecular entity, an environmental toxin, or an\nindustrial chemical. In pharmaceutical drug development, dose-finding studies\nare of critical importance because of regulatory requirements that marketed\ndoses are safe and provide clinically relevant efficacy. Motivated by a\ndose-finding study in moderate persistent asthma, we propose response-adaptive\ndesigns addressing two major challenges in dose-finding studies: uncertainty\nabout the dose-response models and large variability in parameter estimates. To\nallocate new cohorts of patients in an ongoing study, we use optimal designs\nthat are robust under model uncertainty. In addition, we use a Bayesian\nshrinkage approach to stabilize the parameter estimates over the successive\ninterim analyses used in the adaptations. This approach allows us to calculate\nupdated parameter estimates and model probabilities that can then be used to\ncalculate the optimal design for subsequent cohorts. The resulting designs are\nhence robust with respect to model misspecification and additionally can\nefficiently adapt to the information accrued in an ongoing study. We focus on\nadaptive designs for estimating the minimum effective dose, although\nalternative optimality criteria or mixtures thereof could be used, enabling the\ndesign to address multiple objectives.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jul 2011 07:10:56 GMT"}], "update_date": "2011-08-01", "authors_parsed": [["Bornkamp", "Bj\u00f6rn", ""], ["Bretz", "Frank", ""], ["Dette", "Holger", ""], ["Pinheiro", "Jos\u00e9", ""]]}, {"id": "1107.5899", "submitter": "Eric Gautier", "authors": "Eric Gautier", "title": "Hierarchical Bayesian estimation of inequality measures with\n  nonrectangular censored survey data with an application to wealth\n  distribution of French households", "comments": "Published in at http://dx.doi.org/10.1214/10-AOAS443 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2011, Vol. 5, No. 2B, 1632-1656", "doi": "10.1214/10-AOAS443", "report-no": "IMS-AOAS-AOAS443", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the estimation of wealth inequality measures with their\nconfidence interval, based on survey data with interval censoring. We rely on a\nBayesian hierarchical model. It consists of a model where, due to survey\nsampling and unit nonresponse, the summaries of the wealth distribution of\nhouseholds are observed with error; a mixture of multivariate models for the\nwealth components where groups correspond to portfolios of assets; and a prior\non the parameters. A Gibbs sampler is used for numerical purposes to do the\ninference. We apply this strategy to the French 2004 Wealth Survey. In order to\nalleviate the nonresponse, the amounts were systematically collected in the\nform of brackets. Matched administrative data on the liability of the\nrespondents for wealth tax and response to overview questions are used to\nbetter localize the wealth components. It implies nonrectangular\nmultidimensional censoring. The variance of the error term in the model for the\npopulation inequality measures is obtained using linearization and taking into\naccount the complex sampling design and the various weight adjustments.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jul 2011 08:56:00 GMT"}], "update_date": "2011-08-01", "authors_parsed": [["Gautier", "Eric", ""]]}, {"id": "1107.5935", "submitter": "Qingzhao Yu", "authors": "Qingzhao Yu, Steven N. MacEachern, Mario Peruggia", "title": "Bayesian Synthesis: Combining subjective analyses, with an application\n  to ozone data", "comments": "Published in at http://dx.doi.org/10.1214/10-AOAS444 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2011, Vol. 5, No. 2B, 1678-1698", "doi": "10.1214/10-AOAS444", "report-no": "IMS-AOAS-AOAS444", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian model averaging enables one to combine the disparate predictions of\na number of models in a coherent fashion, leading to superior predictive\nperformance. The improvement in performance arises from averaging models that\nmake different predictions. In this work, we tap into perhaps the biggest\ndriver of different predictions---different analysts---in order to gain the\nfull benefits of model averaging. In a standard implementation of our method,\nseveral data analysts work independently on portions of a data set, eliciting\nseparate models which are eventually updated and combined through a specific\nweighting method. We call this modeling procedure Bayesian Synthesis. The\nmethodology helps to alleviate concerns about the sizable gap between the\nfoundational underpinnings of the Bayesian paradigm and the practice of\nBayesian statistics. In experimental work we show that human modeling has\npredictive performance superior to that of many automatic modeling techniques,\nincluding AIC, BIC, Smoothing Splines, CART, Bagged CART, Bayes CART, BMA and\nLARS, and only slightly inferior to that of BART. We also show that Bayesian\nSynthesis further improves predictive performance. Additionally, we examine the\npredictive performance of a simple average across analysts, which we dub Convex\nSynthesis, and find that it also produces an improvement.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jul 2011 11:18:08 GMT"}], "update_date": "2011-08-01", "authors_parsed": [["Yu", "Qingzhao", ""], ["MacEachern", "Steven N.", ""], ["Peruggia", "Mario", ""]]}, {"id": "1107.6043", "submitter": "Zhijian Wang Dr.", "authors": "Bin Xu, Zhijian Wang", "title": "Measurement and Application of Entropy Production Rate in Human Subject\n  Social Interaction Systems", "comments": "4 pages, 4 figures, Keyword: entropy production rate, experimental\n  economics, experimental social dynamics, Edgeworth price cycle, mixed\n  strategy Nash equilibrium, velocity, minimax randomization, JEL: C91, C70", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME nlin.AO stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper illustrates the measurement and the applications of the\nobservable, entropy production rate (EPR), in human subject social interaction\nsystems. To this end, we show (1) how to test the minimax randomization model\nwith experimental economics' 2$\\times$2 games data and with the Wimbledon\nTennis data; (2) how to identify the Edgeworth price cycle in experimental\nmarket data; and (3) the relationship within EPR and motion in data. As a\nresult, in human subject social interaction systems, EPR can be measured\npractically and can be employed to test models and to search for facts\nefficiently.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jul 2011 19:30:00 GMT"}], "update_date": "2011-08-01", "authors_parsed": [["Xu", "Bin", ""], ["Wang", "Zhijian", ""]]}]