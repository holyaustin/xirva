[{"id": "1308.0072", "submitter": "Xin Yuan", "authors": "Xin Yuan", "title": "Joint DOA and Polarization Estimation with Sparsely Distributed and\n  Spatially Non-Collocating Dipole/Loop Triads", "comments": "17 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces an ESPRIT-based algorithm to estimate the\ndirections-of-arrival and polarizations for multiple sources. The investigated\nalgorithm is based on new sparse array geometries, which are composed of three\nnon-collocating dipole triads or three non-collocating loop triads. Both the\ninter-triad spacings and the inter-sensor spacings in the same triad can be far\nlarger than a half-wavelength of the incident sources. By adopting the ESPRIT\nalgorithm, the eigenvalues of the data-correlation matrix offer the fine but\nambiguous estimates of the direction-cosines for each source, and the\neigenvectors provide the estimates of each source's steering vector. Based on\nthe constrained array geometries, the fine and unambiguous estimates of\ndirections-of-arrival and polarizations are obtained. Simulation results verify\nthe efficacy of the investigated approach and also verify the aperture\nextension property of the proposed array geometries.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2013 00:50:22 GMT"}], "update_date": "2013-08-02", "authors_parsed": [["Yuan", "Xin", ""]]}, {"id": "1308.0075", "submitter": "Xin Yuan", "authors": "Xin Yuan", "title": "Polynomial-Phase Signal Direction-Finding & Source-Tracking with an\n  Acoustic Vector Sensor", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new ESPRIT-based algorithm is proposed to estimate the direction-of-arrival\nof an arbitrary degree polynomial-phase signal with a single acoustic vector\nsensor. The proposed approach requires neither a priori knowledge of the\npolynomial-phase signal's coefficients nor a priori knowledge of the\npolynomial-phase signal's frequency-spectrum. A pre-processing technique is\nalso proposed to incorporate the single-forgetting-factor algorithm and\nmultiple-forgetting-factor adaptive tracking algorithm to track a\npolynomial-phase signal using one acoustic vector sensor. Simulation results\nverify the efficacy of the proposed direction finding and source tracking\nalgorithms.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2013 01:06:17 GMT"}, {"version": "v2", "created": "Mon, 5 Aug 2013 13:08:12 GMT"}], "update_date": "2013-08-06", "authors_parsed": [["Yuan", "Xin", ""]]}, {"id": "1308.0384", "submitter": "Masaaki Nagahara", "authors": "Masaaki Nagahara and Clyde F. Martin", "title": "L1-Optimal Splines for Outlier Rejection", "comments": "Submitted to the 59th World Statistics Congress (WSC), Aug. 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.IT math.IT math.OC stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we consider control theoretic splines with L1 optimization\nfor rejecting outliers in data. Control theoretic splines are either\ninterpolating or smoothing splines, depending on a cost function with a\nconstraint defined by linear differential equations. Control theoretic splines\nare effective for Gaussian noise in data since the estimation is based on L2\noptimization. However, in practice, there may be outliers in data, which may\noccur with vanishingly small probability under the Gaussian assumption of\nnoise, to which L2-optimized spline regression may be very sensitive. To\nachieve robustness against outliers, we propose to use L1 optimality, which is\nalso used in support vector regression. A numerical example shows the\neffectiveness of the proposed method.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2013 01:13:25 GMT"}], "update_date": "2013-08-05", "authors_parsed": [["Nagahara", "Masaaki", ""], ["Martin", "Clyde F.", ""]]}, {"id": "1308.0469", "submitter": "Alex Lenkoski", "authors": "Fabian E. Bachl, Alex Lenkoski, Thordis L. Thorarinsdottir and\n  Christoph S. Garbe", "title": "Bayesian Motion Estimation for Dust Aerosols", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dust storms in the earth's major desert regions significantly influence\nmicrophysical weather processes, the CO$_2$-cycle and the global climate in\ngeneral. Recent increases in the spatio-temporal resolution of remote sensing\ninstruments have created new opportunities to understand these phenomena.\nHowever, the scale of the data collected and the inherent stochasticity of the\nunderlying process pose significant challenges, requiring a careful combination\nof image processing and statistical techniques. In particular, using satellite\nimagery data, we develop a statistical model of atmospheric transport that\nrelies on a latent Gaussian Markov random field (GMRF) for inference. In doing\nso, we make a link between the optical flow method of Horn and Schunck and the\nformulation of the transport process as a latent field in a generalized linear\nmodel, which enables the use of the integrated nested Laplace approximation for\ninference. This framework is specified such that it satisfies the so-called\nintegrated continuity equation, thereby intrinsically expressing the divergence\nof the field as a multiplicative factor covering air compressibility and\nsatellite column projection. The importance of this step -- as well as treating\nthe problem in a fully statistical manner -- is emphasized by a simulation\nstudy where inference based on this latent GMRF clearly reduces errors of the\nestimated flow field. We conclude with a study of the dynamics of dust storms\nformed over Saharan Africa and show that our methodology is able to accurately\nand coherently track the storm movement, a critical problem in this field.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2013 11:27:46 GMT"}, {"version": "v2", "created": "Mon, 5 Aug 2013 09:43:40 GMT"}], "update_date": "2013-08-06", "authors_parsed": [["Bachl", "Fabian E.", ""], ["Lenkoski", "Alex", ""], ["Thorarinsdottir", "Thordis L.", ""], ["Garbe", "Christoph S.", ""]]}, {"id": "1308.0642", "submitter": "Subhadeep Mukhopadhyay", "authors": "Subhadeep Mukhopadhyay and Emanuel Parzen", "title": "Nonlinear Time Series Modeling: A Unified Perspective, Algorithm, and\n  Application", "comments": "Major restructuring has been done", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.AP stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new comprehensive approach to nonlinear time series analysis and modeling\nis developed in the present paper. We introduce novel data-specific\nmid-distribution based Legendre Polynomial (LP) like nonlinear transformations\nof the original time series Y(t) that enables us to adapt all the existing\nstationary linear Gaussian time series modeling strategy and made it applicable\nfor non-Gaussian and nonlinear processes in a robust fashion. The emphasis of\nthe present paper is on empirical time series modeling via the algorithm\nLPTime. We demonstrate the effectiveness of our theoretical framework using\ndaily S&P 500 return data between Jan/2/1963 - Dec/31/2009. Our proposed LPTime\nalgorithm systematically discovers all the `stylized facts' of the financial\ntime series automatically all at once, which were previously noted by many\nresearchers one at a time.\n", "versions": [{"version": "v1", "created": "Sat, 3 Aug 2013 00:04:00 GMT"}, {"version": "v2", "created": "Tue, 3 Sep 2013 18:59:35 GMT"}, {"version": "v3", "created": "Wed, 26 Apr 2017 23:03:40 GMT"}, {"version": "v4", "created": "Sun, 24 Dec 2017 01:40:19 GMT"}], "update_date": "2017-12-27", "authors_parsed": [["Mukhopadhyay", "Subhadeep", ""], ["Parzen", "Emanuel", ""]]}, {"id": "1308.0868", "submitter": "John Aston", "authors": "Pantelis Z. Hadjipantelis, John A. D. Aston, Hans-Georg M\\\"uller and\n  Jonathan P. Evans", "title": "Unifying Amplitude and Phase Analysis: A Compositional Data Approach to\n  Functional Multivariate Mixed-Effects Modeling of Mandarin Chinese", "comments": "49 pages, 13 figures, small changes to discussion", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mandarin Chinese is characterized by being a tonal language; the pitch (or\n$F_0$) of its utterances carries considerable linguistic information. However,\nspeech samples from different individuals are subject to changes in amplitude\nand phase which must be accounted for in any analysis which attempts to provide\na linguistically meaningful description of the language. A joint model for\namplitude, phase and duration is presented which combines elements from\nFunctional Data Analysis, Compositional Data Analysis and Linear Mixed Effects\nModels. By decomposing functions via a functional principal component analysis,\nand connecting registration functions to compositional data analysis, a joint\nmultivariate mixed effect model can be formulated which gives insights into the\nrelationship between the different modes of variation as well as their\ndependence on linguistic and non-linguistic covariates. The model is applied to\nthe COSPRO-1 data set, a comprehensive database of spoken Taiwanese Mandarin,\ncontaining approximately 50 thousand phonetically diverse sample $F_0$ contours\n(syllables), and reveals that phonetic information is jointly carried by both\namplitude and phase variation.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2013 01:35:13 GMT"}, {"version": "v2", "created": "Mon, 21 Oct 2013 13:05:09 GMT"}, {"version": "v3", "created": "Wed, 24 Sep 2014 05:31:28 GMT"}, {"version": "v4", "created": "Sun, 28 Dec 2014 09:24:47 GMT"}], "update_date": "2014-12-30", "authors_parsed": [["Hadjipantelis", "Pantelis Z.", ""], ["Aston", "John A. D.", ""], ["M\u00fcller", "Hans-Georg", ""], ["Evans", "Jonathan P.", ""]]}, {"id": "1308.1066", "submitter": "Jeff Shrager", "authors": "Jeff Shrager", "title": "Theoretical Issues for Global Cumulative Treatment Analysis (GCTA)", "comments": "15 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adaptive trials are now mainstream science. Recently, researchers have taken\nthe adaptive trial concept to its natural conclusion, proposing what we call\n\"Global Cumulative Treatment Analysis\" (GCTA). Similar to the adaptive trial,\ndecision making and data collection and analysis in the GCTA are continuous and\nintegrated, and treatments are ranked in accord with the statistics of this\ninformation, combined with what offers the most information gain. Where GCTA\ndiffers from an adaptive trial, or, for that matter, from any trial design, is\nthat all patients are implicitly participants in the GCTA process, regardless\nof whether they are formally enrolled in a trial. This paper discusses some of\nthe theoretical and practical issues that arise in the design of a GCTA, along\nwith some preliminary thoughts on how they might be approached.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2013 18:44:17 GMT"}], "update_date": "2013-08-06", "authors_parsed": [["Shrager", "Jeff", ""]]}, {"id": "1308.1509", "submitter": "Masaaki Nagahara", "authors": "Masaaki Nagahara and Clyde F. Martin", "title": "Monotone Smoothing Splines Using General Linear Systems", "comments": null, "journal-ref": "Asian Journal of Control, Vol. 5, No. 2, pp. 461-468, Mar. 2013", "doi": "10.1002/asjc.557", "report-no": null, "categories": "cs.SY cs.IT math.IT math.OC stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a method is proposed to solve the problem of monotone\nsmoothing splines using general linear systems. This problem, also called\nmonotone control theoretic splines, has been solved only when the curve\ngenerator is modeled by the second-order integrator, but not for other cases.\nThe difficulty in the problem is that the monotonicity constraint should be\nsatisfied over an interval which has the cardinality of the continuum. To solve\nthis problem, we first formulate the problem as a semi-infinite quadratic\nprogramming, and then we adopt a discretization technique to obtain a\nfinite-dimensional quadratic programming problem. It is shown that the solution\nof the finite-dimensional problem always satisfies the infinite-dimensional\nmonotonicity constraint. It is also proved that the approximated solution\nconverges to the exact solution as the discretization grid-size tends to zero.\nAn example is presented to show the effectiveness of the proposed method.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2013 09:13:21 GMT"}], "update_date": "2013-08-08", "authors_parsed": [["Nagahara", "Masaaki", ""], ["Martin", "Clyde F.", ""]]}, {"id": "1308.1554", "submitter": "Lutz Bornmann Dr.", "authors": "Lutz Bornmann, Werner Marx", "title": "The Wisdom of Citing Scientists", "comments": "Accepted for publication in the Journal of the American Society for\n  Information Science and Technology", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL physics.soc-ph stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This Brief Communication discusses the benefits of citation analysis in\nresearch evaluation based on Galton's \"Wisdom of Crowds\" (1907). Citations are\nbased on the assessment of many which is why they can be ascribed a certain\namount of accuracy. However, we show that citations are incomplete assessments\nand that one cannot assume that a high number of citations correlate with a\nhigh level of usefulness. Only when one knows that a rarely cited paper has\nbeen widely read is it possible to say (strictly speaking) that it was\nobviously of little use for further research. Using a comparison with 'like'\ndata, we try to determine that cited reference analysis allows a more\nmeaningful analysis of bibliometric data than times-cited analysis.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2013 12:50:10 GMT"}], "update_date": "2013-08-08", "authors_parsed": [["Bornmann", "Lutz", ""], ["Marx", "Werner", ""]]}, {"id": "1308.1624", "submitter": "Qixin Wang", "authors": "Menghui Li, Dasheng Luo, Chenghua Cao, Xiaochuan Pan, Qixin Wang", "title": "Poisson-type Multivariate Transfer Function Model Reveals Short-term\n  Effects of Ambient Air Pollutants on Hospital Emergency room Visits for\n  Cerebro-cardiovascular Diseases", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Laboratory experiments have shown that cardiovascular diseases are positively\ncorrelated to the concentration of ambient air pollutants, such as SO2, NO2,\nPM10, etc. It has also been repeatedly reported in many countries that\nincreased concentration of ambient air pollutants leads to rise in hospital\nemergency room visitss for these diseases. These studies mainly adopt either\nregression analysis or preliminary models in time series analysis, while the\nmultivariable transfer function model, a relatively newly developed model, has\nmultiple advantages over the conventional linear regression on analyzing time\nseries. This study attempts to quantify the association between concentrations\nambient air pollutants and hospital emergency room visitss for\ncerebro-cardiovascular diseases in Beijing using a Poisson-type multivariate\ntransfer function model. The results show that the RR values of SO2, NO2 and\nPM10 for a 50 g/m3 increase are 1.129, 1.092 and 1.069 respectively. The lags\nfor the three pollutants are estimated to be 2 days, 1 day and 1 day\nrespectively. Compared with the ambient pollutants, daily average temperature\nand relative humidity do not influence the daily count of hospital emergency\nroom visits significantly.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2013 16:19:47 GMT"}], "update_date": "2013-08-08", "authors_parsed": [["Li", "Menghui", ""], ["Luo", "Dasheng", ""], ["Cao", "Chenghua", ""], ["Pan", "Xiaochuan", ""], ["Wang", "Qixin", ""]]}, {"id": "1308.2403", "submitter": "Subhadeep Mukhopadhyay", "authors": "Subhadeep Mukhopadhyay", "title": "CDfdr: A Comparison Density Approach to Local False Discovery Rate\n  Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.AP stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efron et al. (2001) proposed empirical Bayes formulation of the frequentist\nBenjamini and Hochbergs False Discovery Rate method (Benjamini and\nHochberg,1995). This article attempts to unify the `two cultures' using\nconcepts of comparison density and distribution function. We have also shown\nhow almost all of the existing local fdr methods can be viewed as proposing\nvarious model specification for comparison density - unifies the vast\nliterature of false discovery methods under one concept and notation.\n", "versions": [{"version": "v1", "created": "Sun, 11 Aug 2013 15:46:36 GMT"}], "update_date": "2013-08-13", "authors_parsed": [["Mukhopadhyay", "Subhadeep", ""]]}, {"id": "1308.2430", "submitter": "Trevor Hefley", "authors": "Trevor Hefley, Andrew Tyre, David Baasch, Erin Blankenship", "title": "Nondetection sampling bias in marked presence-only data", "comments": "Published in Ecology and Evolution", "journal-ref": null, "doi": "10.1002/ece3.887", "report-no": null, "categories": "q-bio.PE stat.AP", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  1. Species distribution models (SDM) are tools used to determine\nenvironmental features that influence the geographic distribution of species'\nabundance and have been used to analyze presence-only records. Analysis of\npresence-only records may require correction for nondetection sampling bias to\nyield reliable conclusions. In addition, individuals of some species of animals\nmay be highly aggregated and standard SDMs ignore environmental features that\nmay influence aggregation behavior. 2. We contend that nondetection sampling\nbias can be treated as missing data. Statistical theory and corrective methods\nare well developed for missing data, but have been ignored in the literature on\nSDMs. We developed a marked inhomogeneous Poisson point process model that\naccounted for nondetection and aggregation behavior in animals and tested our\nmethods on simulated data. 3. Correcting for nondetection sampling bias\nrequires estimates of the probability of detection which must be obtained from\nauxiliary data, as presence-only data do not contain information about the\ndetection mechanism. Weighted likelihood methods can be used to correct for\nnondetection if estimates of the probability of detection are available. We\nused an inhomogeneous Poisson point process model to model group abundance, a\nzero-truncated generalized linear model to model group size, and combined these\ntwo models to describe the distribution of abundance. Our methods performed\nwell on simulated data when nondetection was accounted for and poorly when\ndetection was ignored. 4. We recommend researchers consider the effects of\nnondetection sampling bias when modeling species distributions using\npresence-only data. If information about the detection process is available, we\nrecommend researchers explore the effects of nondetection and, when warranted,\ncorrect the bias using our methods.\n", "versions": [{"version": "v1", "created": "Sun, 11 Aug 2013 21:26:35 GMT"}, {"version": "v2", "created": "Wed, 4 Dec 2013 05:51:20 GMT"}], "update_date": "2013-12-05", "authors_parsed": [["Hefley", "Trevor", ""], ["Tyre", "Andrew", ""], ["Baasch", "David", ""], ["Blankenship", "Erin", ""]]}, {"id": "1308.2577", "submitter": "Cedric Ginestet", "authors": "Cedric E. Ginestet, Arnaud P. Fournel and Andrew Simmons", "title": "Statistical Network Analysis for Functional MRI: Summary Networks and\n  Group Comparisons", "comments": "16 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Comparing weighted networks in neuroscience is hard, because the topological\nproperties of a given network are necessarily dependent on the number of edges\nof that network. This problem arises in the analysis of both weighted and\nunweighted networks. The term density is often used in this context, in order\nto refer to the mean edge weight of a weighted network, or to the number of\nedges in an unweighted one. Comparing families of networks is therefore\nstatistically difficult because differences in topology are necessarily\nassociated with differences in density. In this review paper, we consider this\nproblem from two different perspectives, which include (i) the construction of\nsummary networks, such as how to compute and visualize the mean network from a\nsample of network-valued data points; and (ii) how to test for topological\ndifferences, when two families of networks also exhibit significant differences\nin density. In the first instance, we show that the issue of summarizing a\nfamily of networks can be conducted by adopting a mass-univariate approach,\nwhich produces a statistical parametric network (SPN). In the second part of\nthis review, we then highlight the inherent problems associated with the\ncomparison of topological functions of families of networks that differ in\ndensity. In particular, we show that a wide range of topological summaries,\nsuch as global efficiency and network modularity are highly sensitive to\ndifferences in density. Moreover, these problems are not restricted to\nunweighted metrics, as we demonstrate that the same issues remain present when\nconsidering the weighted versions of these metrics. We conclude by encouraging\ncaution, when reporting such statistical comparisons, and by emphasizing the\nimportance of constructing summary networks.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2013 14:26:38 GMT"}, {"version": "v2", "created": "Thu, 27 Mar 2014 06:09:45 GMT"}], "update_date": "2014-03-28", "authors_parsed": [["Ginestet", "Cedric E.", ""], ["Fournel", "Arnaud P.", ""], ["Simmons", "Andrew", ""]]}, {"id": "1308.2735", "submitter": "Ugo Marzolino", "authors": "Ugo Marzolino, Daniel Braun", "title": "Precision Measurements of Temperature and Chemical Potential of Quantum\n  Gases", "comments": null, "journal-ref": "Phys. Rev. A 88, 063609 (2013)", "doi": "10.1103/PhysRevA.88.063609", "report-no": null, "categories": "quant-ph cond-mat.quant-gas stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the sensitivity with which the temperature and the chemical\npotential characterizing quantum gases can be measured. We calculate the\ncorresponding quantum Fisher information matrices for both fermionic and\nbosonic gases. For the latter, particular attention is devoted to the situation\nclose to the Bose-Einstein condensation transition, which we examine not only\nfor the standard scenario in three dimensions, but also for generalized\ncondensation in lower dimensions, where the bosons condense in a subspace of\nHilbert space instead of a unique ground state, as well as condensation at\nfixed volume or fixed pressure. We show that Bose Einstein condensation can\nlead to sub-shot noise sensitivity for the measurement of the chemical\npotential. We also examine the influence of interactions on the sensitivity in\nthree different models, and show that mean-field and contact interactions\ndeteriorate the sensitivity but only slightly for experimentally accessible\nweak interactions.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2013 01:56:25 GMT"}, {"version": "v2", "created": "Sun, 24 Nov 2013 05:40:36 GMT"}], "update_date": "2016-02-01", "authors_parsed": [["Marzolino", "Ugo", ""], ["Braun", "Daniel", ""]]}, {"id": "1308.2790", "submitter": "Emanuele  Giorgi", "authors": "Emanuele Giorgi, Sanie S. S. Sesay, Dianne J. Terlouw and Peter J.\n  Diggle", "title": "Combining data from multiple spatially referenced prevalence surveys\n  using generalized linear geostatistical models", "comments": "Edited version after a first revision", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data from multiple prevalence surveys can provide information on common\nparameters of interest, which can therefore be estimated more precisely in a\njoint analysis than by separate analyses of the data from each survey. However,\nfitting a single model to the combined data from multiple surveys is\ninadvisable without testing the implicit assumption that all of the surveys are\ndirected at the same inferential target. In this paper we propose a\nmultivariate generalized linear geostatistical model that accommodates two\nsources of heterogeneity across surveys so as to correct for spatially\nstructured bias in non-randomised surveys and to allow for temporal variation\nin the underlying prevalence surface between consecutive survey-periods. We\ndescribe a Monte Carlo maximum likelihood procedure for parameter estimation,\nand show through simulation experiments how accounting for the different\nsources of heterogeneity among surveys in a joint model leads to more precise\ninferences. We describe an application to multiple surveys of malaria\nprevalence conducted in Chikhwawa District, Southern Malawi, and discuss how\nthis approach could inform hybrid sampling strategies that combine data from\nrandomised and non-randomised surveys so as to make the most efficient use of\nall available data.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2013 09:07:35 GMT"}, {"version": "v2", "created": "Wed, 14 Aug 2013 06:43:00 GMT"}, {"version": "v3", "created": "Fri, 20 Dec 2013 10:16:29 GMT"}], "update_date": "2013-12-23", "authors_parsed": [["Giorgi", "Emanuele", ""], ["Sesay", "Sanie S. S.", ""], ["Terlouw", "Dianne J.", ""], ["Diggle", "Peter J.", ""]]}, {"id": "1308.3568", "submitter": "Camille Charbonnier", "authors": "Camille Charbonnier, Nicolas Verzelen (MISTEA), Fanny Villers (LPMA)", "title": "A Global Homogeneity Test for High-Dimensional Linear Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.AP stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is motivated by the comparison of genetic networks based on\nmicroarray samples. The aim is to test whether the differences observed between\ntwo inferred Gaussian graphical models come from real differences or arise from\nestimation uncertainties. Adopting a neighborhood approach, we consider a\ntwo-sample linear regression model with random design and propose a procedure\nto test whether these two regressions are the same. Relying on multiple testing\nand variable selection strategies, we develop a testing procedure that applies\nto high-dimensional settings where the number of covariates $p$ is larger than\nthe number of observations $n_1$ and $n_2$ of the two samples. Both type I and\ntype II errors are explicitely controlled from a non-asymptotic perspective and\nthe test is proved to be minimax adaptive to the sparsity. The performances of\nthe test are evaluated on simulated data. Moreover, we illustrate how this\nprocedure can be used to compare genetic networks on Hess \\emph{et al} breast\ncancer microarray dataset.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2013 07:39:52 GMT"}, {"version": "v2", "created": "Thu, 19 Jun 2014 19:10:35 GMT"}], "update_date": "2014-06-20", "authors_parsed": [["Charbonnier", "Camille", "", "MISTEA"], ["Verzelen", "Nicolas", "", "MISTEA"], ["Villers", "Fanny", "", "LPMA"]]}, {"id": "1308.3590", "submitter": "Ananl Lotsi", "authors": "Anani Lotsi and Ernst Wit", "title": "State-space modeling of dynamic genetic networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The genomic reality is a highly complex and dynamic system. The recent\ndevelopment of high-throughput technologies has enabled researchers to measure\nthe abundance of many genes (in the order of thousands) simultaneously. The\nchallenge is to unravel from such measurements, gene/protein or gene/gene or\nprotein/ protein interactions and key biological features of cellular systems.\nOur goal is to devise a method for inferring transcriptional or gene regulatory\nnetworks from high-throughput data sources such as gene expression microarrays\nwith potentially hidden states, such as unmeasured transcription factors (TFs),\nwhich satisfies certain Markov properties. We propose a dynamic state space\nrepresentation. Our method is based on an EM algorithm with an incorporated\nKalman smoothing algorithm in the E-step, a bootstrap for confidence intervals\nto infer the networks and the AIC for model selection. The state space model is\nan approach with proven effectiveness to reverse engineer transcriptional\nnetworks. The proposed method is applied to time course microarray data\nobtained from well established T-cell. When we applied the method to the T-cell\ndata, we obtained 4, as the optimum number of hidden states. Our results\nsupport interesting biological properties in the family of Jun genes. The\nfollowing genes were mostly seen as regulatory genes. These genes includes FYB,\nCCNA2, AKT1, TRAF5, CASP4, and CTNNB1. We found interaction between Jun-B and\nSMN1, and CDC2 activates Jun-D. We found few significant interactions or\none-to-one correspondence among the 4 putative transcription factors. Among the\nimportant key genes in terms of outward-directed edges, we found genes such as\nCCNA2, JUNB, CDC2, CASP4, JUND to have a high degree of connectivity. R\nComputer source code is made available at our website at\nhttp://www.math.rug.nl/stat/Main/Software.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2013 10:09:55 GMT"}, {"version": "v2", "created": "Thu, 29 Aug 2013 14:57:07 GMT"}, {"version": "v3", "created": "Sat, 5 Oct 2013 13:42:29 GMT"}], "update_date": "2013-10-08", "authors_parsed": [["Lotsi", "Anani", ""], ["Wit", "Ernst", ""]]}, {"id": "1308.3740", "submitter": "Paul McNicholas", "authors": "Mateen Shaikh, Paul D. McNicholas, M. Luiza Antonie and T. Brendan\n  Murphy", "title": "Standardizing Interestingness Measures for Association Rules", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interestingness measures provide information that can be used to prune or\nselect association rules. A given value of an interestingness measure is often\ninterpreted relative to the overall range of the values that the\ninterestingness measure can take. However, properties of individual association\nrules restrict the values an interestingness measure can achieve. An\ninteresting measure can be standardized to take this into account, but this has\nonly been done for one interestingness measure to date, i.e., the lift.\nStandardization provides greater insight than the raw value and may even alter\nresearchers' perception of the data. We derive standardized analogues of three\ninterestingness measures and use real and simulated data to compare them to\ntheir raw versions, each other, and the standardized lift.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2013 23:42:05 GMT"}], "update_date": "2013-08-20", "authors_parsed": [["Shaikh", "Mateen", ""], ["McNicholas", "Paul D.", ""], ["Antonie", "M. Luiza", ""], ["Murphy", "T. Brendan", ""]]}, {"id": "1308.3849", "submitter": "Kyeong Soo (Joseph) Kim", "authors": "Kyeong Soo Kim", "title": "The Effect of ISP Traffic Shaping on User-Perceived Performances in\n  Broadband Shared Access Networks", "comments": "39 pages, 12 figures, accepted for publication in the Computer\n  Networks, Jun. 1, 2014", "journal-ref": "Computer Networks, vol. 70, pp. 192-209, Sep. 2014", "doi": "10.1016/j.comnet.2014.06.001", "report-no": null, "categories": "cs.NI stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies on the practice of shaping subscribers' traffic by ISPs give a\nnew insight into the actual performance of broadband access networks at a\npacket level. Unlike metro and backbone networks, however, access networks\ndirectly interface with end-users, so it is important to base the study and\ndesign of access networks on the behaviors of and the actual performance\nperceived by end-users. In this paper we study the effect of ISP traffic\nshaping using traffic models based on user behaviors and\napplication/session-layer metrics providing quantifiable measures of\nuser-perceived performance for HTTP, FTP, and streaming video traffic. To\ncompare the user-perceived performance of shaped traffic flows with those of\nunshaped ones in an integrated way, we use a multivariate non-inferiority\ntesting procedure. We first investigate the effect of the token generation rate\nand the token bucket size of a token bucket filter on user-perceived\nperformance at a subscriber level with a single subscriber. Then we investigate\ntheir effect at an access level where shaped traffic flows from multiple\nsubscribers interact with one another in a common shared access network. The\nsimulation results show that for a given token generation rate, a larger token\nbucket provides better user-perceived performance at both subscriber and access\nlevels. It is also shown that the loose burst control resulting from the large\ntoken bucket --- up to 100 MB for access line rate of 100 Mbit/s --- does not\nnegatively affect user-perceived performance with multiple subscribers even in\nthe presence of non-conformant subscribers; with a much larger token bucket,\nhowever, the negative effect of non-conformant subscribers on the\nuser-perceived performance of conformant subscribers becomes clearly visible\nbecause the impact of token bucket size and that of token generation rate are\nvirtually indistinguishable in this case.\n", "versions": [{"version": "v1", "created": "Sun, 18 Aug 2013 10:17:17 GMT"}, {"version": "v2", "created": "Tue, 3 Jun 2014 15:26:27 GMT"}], "update_date": "2015-06-02", "authors_parsed": [["Kim", "Kyeong Soo", ""]]}, {"id": "1308.3925", "submitter": "Mercedes Richards", "authors": "Elizabeth Martinez-Gomez, Mercedes T. Richards, Donald St. P. Richards", "title": "Distance Correlation Methods for Discovering Associations in Large\n  Astrophysical Databases", "comments": "11 pages, 6 figures, 4 tables; Astrophysical Journal, accepted, in\n  press", "journal-ref": null, "doi": "10.1088/0004-637X/781/1/39", "report-no": null, "categories": "astro-ph.CO math.ST stat.AP stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-dimensional, large-sample astrophysical databases of galaxy clusters,\nsuch as the Chandra Deep Field South COMBO-17 database, provide measurements on\nmany variables for thousands of galaxies and a range of redshifts. Current\nunderstanding of galaxy formation and evolution rests sensitively on\nrelationships between different astrophysical variables; hence an ability to\ndetect and verify associations or correlations between variables is important\nin astrophysical research. In this paper, we apply a recently defined\nstatistical measure called the distance correlation coefficient which can be\nused to identify new associations and correlations between astrophysical\nvariables. The distance correlation coefficient applies to variables of any\ndimension; it can be used to determine smaller sets of variables that provide\nequivalent astrophysical information; it is zero only when variables are\nindependent; and it is capable of detecting nonlinear associations that are\nundetectable by the classical Pearson correlation coefficient. Hence, the\ndistance correlation coefficient provides more information than the Pearson\ncoefficient. We analyze numerous pairs of variables in the COMBO-17 database\nwith the distance correlation method and with the maximal information\ncoefficient. We show that the Pearson coefficient can be estimated with higher\naccuracy from the corresponding distance correlation coefficient than from the\nmaximal information coefficient. For given values of the Pearson coefficient,\nthe distance correlation method has a greater ability than the maximal\ninformation coefficient to resolve astrophysical data into highly concentrated\nV-shapes, which enhances classification and pattern identification. These\nresults are observed over a range of redshifts beyond the local universe and\nfor galaxies from elliptical to spiral.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2013 05:27:09 GMT"}, {"version": "v2", "created": "Tue, 3 Dec 2013 20:47:20 GMT"}], "update_date": "2015-06-16", "authors_parsed": [["Martinez-Gomez", "Elizabeth", ""], ["Richards", "Mercedes T.", ""], ["Richards", "Donald St. P.", ""]]}, {"id": "1308.4079", "submitter": "Ananl Lotsi", "authors": "Anani Lotsi and Ernst Wit", "title": "Network estimation in State Space Model with L1-regularization\n  constraint", "comments": "arXiv admin note: substantial text overlap with arXiv:1308.3590", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Biological networks have arisen as an attractive paradigm of genomic science\never since the introduction of large scale genomic technologies which carried\nthe promise of elucidating the relationship in functional genomics. Microarray\ntechnologies coupled with appropriate mathematical or statistical models have\nmade it possible to identify dynamic regulatory networks or to measure time\ncourse of the expression level of many genes simultaneously. However one of the\nfew limitations fall on the high-dimensional nature of such data coupled with\nthe fact that these gene expression data are known to include some hidden\nprocess. In that regards, we are concerned with deriving a method for inferring\na sparse dynamic network in a high dimensional data setting. We assume that the\nobservations are noisy measurements of gene expression in the form of mRNAs,\nwhose dynamics can be described by some unknown or hidden process. We build an\ninput-dependent linear state space model from these hidden states and\ndemonstrate how an incorporated $L_{1}$ regularization constraint in an\nExpectation-Maximization (EM) algorithm can be used to reverse engineer\ntranscriptional networks from gene expression profiling data. This corresponds\nto estimating the model interaction parameters. The proposed method is\nillustrated on time-course microarray data obtained from a well established\nT-cell data. At the optimum tuning parameters we found genes TRAF5, JUND, CDK4,\nCASP4, CD69, and C3X1 to have higher number of inwards directed connections and\nFYB, CCNA2, AKT1 and CASP8 to be genes with higher number of outwards directed\nconnections. We recommend these genes to be object for further investigation.\nCaspase 4 is also found to activate the expression of JunD which in turn\nrepresses the cell cycle regulator CDC2.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2013 17:25:13 GMT"}], "update_date": "2013-08-20", "authors_parsed": [["Lotsi", "Anani", ""], ["Wit", "Ernst", ""]]}, {"id": "1308.4178", "submitter": "Andr\\'e Beauducel", "authors": "Andre Beauducel", "title": "The factor paradox: Common factors can be correlated with the variance\n  not accounted for by the common factors!", "comments": "11 pages, 2 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The case that the factor model does not account for all the covariances of\nthe observed variables is considered. This is a quite realistic condition\nbecause some model error as well as some sampling error should usually occur\nwith empirical data. It is shown that principal components representing\ncovariances not accounted for by the factors of the model can have a non-zero\ncorrelation with the common factors of the factor model. Non-zero correlations\nof components representing variance not accounted for by the factor model with\ncommon factors were also found in a simulation study. Based on these results it\nshould be concluded that common factors can be correlated with variance\ncomponents representing model error as well as sampling error. In consequence,\neven when researchers decide not to represent some small or trivial variance by\nmeans of a common factor, these excluded variances can still be part of the\nmodel.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2013 21:29:55 GMT"}], "update_date": "2015-12-18", "authors_parsed": [["Beauducel", "Andre", ""]]}, {"id": "1308.4338", "submitter": "Leonardo Torres", "authors": "Leonardo Torres and Alejandro C. Frery", "title": "SAR Image Despeckling Algorithms using Stochastic Distances and Nonlocal\n  Means", "comments": "Accepted for publication in Workshop of Theses and Dissertations\n  (WTD) in Conference on Graphics, Patterns, and Images (SIBGRAPI 2013). This\n  paper received the first best work award in the Dissertation category at the\n  WTD-SIBGRAPI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CV cs.GR math.IT stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents two approaches for filter design based on stochastic\ndistances for intensity speckle reduction. A window is defined around each\npixel, overlapping samples are compared and only those which pass a\ngoodness-of-fit test are used to compute the filtered value. The tests stem\nfrom stochastic divergences within the Information Theory framework. The\ntechnique is applied to intensity Synthetic Aperture Radar (SAR) data with\nhomogeneous regions using the Gamma model. The first approach uses a\nNagao-Matsuyama-type procedure for setting the overlapping samples, and the\nsecond uses the nonlocal method. The proposals are compared with the Improved\nSigma filter and with anisotropic diffusion for speckled data (SRAD) using a\nprotocol based on Monte Carlo simulation. Among the criteria used to quantify\nthe quality of filters, we employ the equivalent number of looks, and line and\nedge preservation. Moreover, we also assessed the filters by the Universal\nImage Quality Index and by the Pearson correlation between edges. Applications\nto real images are also discussed. The proposed methods show good results.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2013 15:58:19 GMT"}], "update_date": "2013-08-21", "authors_parsed": [["Torres", "Leonardo", ""], ["Frery", "Alejandro C.", ""]]}, {"id": "1308.4589", "submitter": "Marta Sarzynska", "authors": "Marta Sarzynska, Oyita Udiani, Na Zhang", "title": "A study of gravity-linked metapopulation models for the spatial spread\n  of dengue fever", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Metapopulation (multipatch) models are widely used to study the patterns of\nspatial spread of epidemics. In this paper we study the impact of inter-patch\nconnection weights on the predictions of these models. We contrast arbitrary,\nuniform link weights with link weights predicted using a gravity model based on\npatch populations and distance. In a synthetic system with one large driver\ncity and many small follower cities, we show that under uniform link weights,\nepidemics in the follower regions are perfectly synchronized. In contrast,\ngravity-based links allow a more realistic, less synchronized distribution of\nepidemic peaks in the follower regions. We then fit a three-patch\nmetapopulation model to regional dengue fever data from Peru -- a country\nexperiencing yearly, spatially defined epidemics. We use data for 2002-2008\n(studying the seasonal disease patterns in the country and the yearly\nreinfection patterns from jungle to the coast) and 2000-2001 (one large\nepidemic of a new disease strain across the country). We present numerical\nresults.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2013 10:46:35 GMT"}, {"version": "v2", "created": "Fri, 23 Aug 2013 13:59:01 GMT"}], "update_date": "2013-08-26", "authors_parsed": [["Sarzynska", "Marta", ""], ["Udiani", "Oyita", ""], ["Zhang", "Na", ""]]}, {"id": "1308.4690", "submitter": "Longhai Li", "authors": "Longhai Li and Weixin Yao", "title": "High-dimensional Feature Selection Using Hierarchical Bayesian Logistic\n  Regression with Heavy-tailed Priors", "comments": "This is an earlier version of the paper arXiv:1405.3319. We do not\n  want to cause confusion to readers", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of selecting the most useful features from a great many (eg,\nthousands) of candidates arises in many areas of modern sciences. An\ninteresting problem from genomic research is that, from thousands of genes that\nare active (expressed) in certain tissue cells, we want to find the genes that\ncan be used to separate tissues of different classes (eg. cancer and normal).\nIn this paper, we report our empirical experiences of using Bayesian logistic\nregression based on heavy-tailed priors with moderately small degree freedom\n(such as 1) and very small scale, and using Hamiltonian Monte Carlo to do\ncomputation. We discuss the advantages and limitations of this method, and\nillustrate the difficulties that remain unsolved. The method is applied to a\nreal microarray data set related to prostate cancer. The method identifies only\n3 non-redundant genes out of 6033 candidates but achieves better leave-one-out\ncross-validated prediction accuracy than many other methods.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2013 20:04:34 GMT"}, {"version": "v2", "created": "Sat, 12 May 2018 03:12:27 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Li", "Longhai", ""], ["Yao", "Weixin", ""]]}, {"id": "1308.4826", "submitter": "Kyeong Soo (Joseph) Kim", "authors": "Kyeong Soo Kim", "title": "A Research Framework for the Clean-Slate Design of Next-Generation\n  Optical Access", "comments": "8 pages, 10 figures", "journal-ref": "Fiber and Integrated Optics Special Issue on Second Fiber Optics\n  in Access Networks (FOAN), vol. 31, issue 2, pp. 90-110, Apr. 2012", "doi": "10.1080/01468030.2012.654597", "report-no": null, "categories": "cs.NI stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A comprehensive research framework for a comparative analysis of candidate\nnetwork architectures and protocols in the clean-slate design of\nnext-generation optical access is proposed. The proposed research framework\nconsists of a comparative analysis framework based on multivariate\nnon-inferiority testing and a notion of equivalent circuit rate taking into\naccount user-perceived performances, and a virtual test bed providing a\ncomplete experimental platform for the comparative analysis. The capability of\nthe research framework is demonstrated through numerical results from the study\nof the elasticity of hybrid TDM/WDM-PON based on tunable transceivers.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2013 11:31:54 GMT"}], "update_date": "2014-03-25", "authors_parsed": [["Kim", "Kyeong Soo", ""]]}, {"id": "1308.4827", "submitter": "Christian R\\\"over", "authors": "Christian R\\\"over, Richard Nicholas, Sebastian Straube, Tim Friede", "title": "Changing EDSS progression in placebo cohorts in relapsing MS: A\n  systematic review and meta-regression", "comments": "17 pages, 2 figures", "journal-ref": "PLoS ONE, 10(9):e0137052, 2015", "doi": "10.1371/journal.pone.0137052", "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: Recent systematic reviews of randomised controlled trials (RCTs)\nin relapsing multiple sclerosis (RMS) revealed a decrease in placebo annualized\nrelapse rates (ARR) over the past two decades. Furthermore, regression to the\nmean effects were observed in ARR and MRI lesion counts. It is unclear whether\ndisease progression measured by the expanded disability status scale (EDSS)\nexhibits similar features.\n  Methods: A systematic review of RCTs in RMS was conducted extracting data on\nEDSS and baseline characteristics. The logarithmic odds of disease progression\nwere modelled to investigate time trends. Random-effects models were used to\naccount for between-study variability; all investigated models included trial\nduration as a predictor to correct for unequal study durations.\nMeta-regressions were conducted to assess the prognostic value of a number of\nbaseline variables.\n  Results: The systematic literature search identified 39 studies, including a\ntotal of 19,714 patients. The proportion of patients in placebo controls\nexperiencing a disease progression decreased over the years (p<0.001). Meta\nregression identified associated covariates including the size of the study and\nits duration that in part explained the time trend. Progression probabilities\ntended to be lower in the second year compared to the first year with a\nreduction of 24% in progression probability from year 1 to year 2 (p=0.014).\n  Conclusion: EDSS disease progression exhibits similar behaviour over time as\nthe ARR and point to changes in trial characteristics over the years,\nquestioning comparisons between historical and recent trials.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2013 11:36:33 GMT"}, {"version": "v2", "created": "Mon, 9 Dec 2013 15:55:23 GMT"}, {"version": "v3", "created": "Wed, 13 May 2015 11:29:29 GMT"}], "update_date": "2015-09-03", "authors_parsed": [["R\u00f6ver", "Christian", ""], ["Nicholas", "Richard", ""], ["Straube", "Sebastian", ""], ["Friede", "Tim", ""]]}, {"id": "1308.5115", "submitter": "Sebastian Meyer", "authors": "Sebastian Meyer, Leonhard Held", "title": "Power-law models for infectious disease spread", "comments": "Published in at http://dx.doi.org/10.1214/14-AOAS743 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2014, Vol. 8, No. 3, 1612-1639", "doi": "10.1214/14-AOAS743", "report-no": "IMS-AOAS-AOAS743", "categories": "stat.ME physics.data-an physics.soc-ph stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Short-time human travel behaviour can be described by a power law with\nrespect to distance. We incorporate this information in space-time models for\ninfectious disease surveillance data to better capture the dynamics of disease\nspread. Two previously established model classes are extended, which both\ndecompose disease risk additively into endemic and epidemic components: a\nspatio-temporal point process model for individual-level data and a\nmultivariate time-series model for aggregated count data. In both frameworks, a\npower-law decay of spatial interaction is embedded into the epidemic component\nand estimated jointly with all other unknown parameters using (penalised)\nlikelihood inference. Whereas the power law can be based on Euclidean distance\nin the point process model, a novel formulation is proposed for count data\nwhere the power law depends on the order of the neighbourhood of discrete\nspatial units. The performance of the new approach is investigated by a\nreanalysis of individual cases of invasive meningococcal disease in Germany\n(2002-2008) and count data on influenza in 140 administrative districts of\nSouthern Germany (2001-2008). In both applications, the power law substantially\nimproves model fit and predictions, and is reasonably close to alternative\nqualitative formulations, where distance and order of neighbourhood,\nrespectively, are treated as a factor. Implementation in the R package\nsurveillance allows the approach to be applied in other settings.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2013 12:45:25 GMT"}, {"version": "v2", "created": "Fri, 7 Feb 2014 15:30:09 GMT"}, {"version": "v3", "created": "Mon, 24 Nov 2014 07:52:37 GMT"}], "update_date": "2014-11-25", "authors_parsed": [["Meyer", "Sebastian", ""], ["Held", "Leonhard", ""]]}, {"id": "1308.5140", "submitter": "Denise K\\\"uhnert", "authors": "Denise K\\\"uhnert, Tanja Stadler, Timothy G. Vaughan, Alexei J.\n  Drummond", "title": "Simultaneous reconstruction of evolutionary history and epidemiological\n  dynamics from viral sequences with the birth-death SIR model", "comments": "Journal link:\n  http://rsif.royalsocietypublishing.org/content/11/94/20131106.full", "journal-ref": "J. R. Soc. Interface 2014 11, 20131106, published 26 February 2014", "doi": "10.1098/rsif.2013.1106", "report-no": null, "categories": "q-bio.PE math.PR stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The evolution of RNA viruses such as HIV, Hepatitis C and Influenza virus\noccurs so rapidly that the viruses' genomes contain information on past\necological dynamics. Hence, we develop a phylodynamic method that enables the\njoint estimation of epidemiological parameters and phylogenetic history. Based\non a compartmental susceptible-infected-removed (SIR) model, this method\nprovides separate information on incidence and prevalence of infections.\nDetailed information on the interaction of host population dynamics and\nevolutionary history can inform decisions on how to contain or entirely avoid\ndisease outbreaks.\n  We apply our Birth-Death SIR method (BDSIR) to two viral data sets. First,\nfive human immunodeficiency virus type 1 clusters sampled in the United Kingdom\nbetween 1999 and 2003 are analyzed. The estimated basic reproduction ratios\nrange from 1.9 to 3.2 among the clusters. All clusters show a decline in the\ngrowth rate of the local epidemic in the middle or end of the 90's.\n  The analysis of a hepatitis C virus (HCV) genotype 2c data set shows that the\nlocal epidemic in the C\\'ordoban city Cruz del Eje originated around 1906\n(median), coinciding with an immigration wave from Europe to central Argentina\nthat dates from 1880--1920. The estimated time of epidemic peak is around 1970.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2013 14:41:24 GMT"}, {"version": "v2", "created": "Fri, 21 Mar 2014 13:27:15 GMT"}], "update_date": "2014-03-24", "authors_parsed": [["K\u00fchnert", "Denise", ""], ["Stadler", "Tanja", ""], ["Vaughan", "Timothy G.", ""], ["Drummond", "Alexei J.", ""]]}, {"id": "1308.5146", "submitter": "Ali Ahmed", "authors": "Ali Ahmed and Justin Romberg", "title": "Compressive Multiplexing of Correlated Signals", "comments": "38 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a general architecture for the acquisition of ensembles of\ncorrelated signals. The signals are multiplexed onto a single line by mixing\neach one against a different code and then adding them together, and the\nresulting signal is sampled at a high rate. We show that if the $M$ signals,\neach bandlimited to $W/2$ Hz, can be approximated by a superposition of $R < M$\nunderlying signals, then the ensemble can be recovered by sampling at a rate\nwithin a logarithmic factor of $RW$ (as compared to the Nyquist rate of $MW$).\nThis sampling theorem shows that the correlation structure of the signal\nensemble can be exploited in the acquisition process even though it is unknown\na priori.\n  The reconstruction of the ensemble is recast as a low-rank matrix recovery\nproblem from linear measurements. The architectures we are considering impose a\ncertain type of structure on the linear operators. Although our results depend\non the mixing forms being random, this imposed structure results in a very\ndifferent type of random projection than those analyzed in the low-rank\nrecovery literature to date.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2013 14:52:02 GMT"}, {"version": "v2", "created": "Sat, 25 Oct 2014 01:59:15 GMT"}, {"version": "v3", "created": "Fri, 15 Dec 2017 17:25:35 GMT"}, {"version": "v4", "created": "Tue, 12 Jun 2018 09:02:11 GMT"}], "update_date": "2018-06-13", "authors_parsed": [["Ahmed", "Ali", ""], ["Romberg", "Justin", ""]]}, {"id": "1308.5623", "submitter": "Matt Taddy", "authors": "Matt Taddy", "title": "One-step estimator paths for concave regularization", "comments": "Data and code are in the gamlr package for R. Supplemental appendix\n  is at https://github.com/TaddyLab/pose/raw/master/paper/supplemental.pdf", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The statistics literature of the past 15 years has established many favorable\nproperties for sparse diminishing-bias regularization: techniques which can\nroughly be understood as providing estimation under penalty functions spanning\nthe range of concavity between $L_0$ and $L_1$ norms. However, lasso\n$L_1$-regularized estimation remains the standard tool for industrial `Big\nData' applications because of its minimal computational cost and the presence\nof easy-to-apply rules for penalty selection. In response, this article\nproposes a simple new algorithm framework that requires no more computation\nthan a lasso path: the path of one-step estimators (POSE) does $L_1$ penalized\nregression estimation on a grid of decreasing penalties, but adapts\ncoefficient-specific weights to decrease as a function of the coefficient\nestimated in the previous path step. This provides sparse diminishing-bias\nregularization at no extra cost over the fastest lasso algorithms. Moreover,\nour `gamma lasso' implementation of POSE is accompanied by a reliable heuristic\nfor the fit degrees of freedom, so that standard information criteria can be\napplied in penalty selection. We also provide novel results on the distance\nbetween weighted-$L_1$ and $L_0$ penalized predictors; this allows us to build\nintuition about POSE and other diminishing-bias regularization schemes. The\nmethods and results are illustrated in extensive simulations and in application\nof logistic regression to evaluating the performance of hockey players.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2013 16:11:49 GMT"}, {"version": "v2", "created": "Mon, 2 Sep 2013 18:36:22 GMT"}, {"version": "v3", "created": "Sun, 6 Oct 2013 19:06:48 GMT"}, {"version": "v4", "created": "Tue, 26 Nov 2013 22:11:25 GMT"}, {"version": "v5", "created": "Sat, 20 Sep 2014 05:25:15 GMT"}, {"version": "v6", "created": "Sun, 8 Feb 2015 22:36:26 GMT"}, {"version": "v7", "created": "Mon, 19 Oct 2015 15:24:18 GMT"}, {"version": "v8", "created": "Sun, 1 May 2016 20:35:16 GMT"}], "update_date": "2016-05-03", "authors_parsed": [["Taddy", "Matt", ""]]}, {"id": "1308.5767", "submitter": "Tewfik Lounis", "authors": "Tewfik Lounis (LMNO)", "title": "Optimal tests in AR(m) time series model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A method for an evaluation of the error between an unknown parameter and its\nestimator is developed. Its application enables us to preserve the asymptotic\npower of a constructed test. Testing problems in AR(1) and ARCH models are\nstudied with a derivation of the asymptotic power function. Also the results\nare extended to AR(m) time series model.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2013 06:48:42 GMT"}], "update_date": "2013-08-28", "authors_parsed": [["Lounis", "Tewfik", "", "LMNO"]]}, {"id": "1308.5830", "submitter": "Anthony Cousien", "authors": "St\\'ephan Cl\\'emen\\c{c}on (LTCI), Anthony Cousien (ATIP-Avenir\n  Inserm), Miraine D\\'avila Felipe (LTCI, CIRB), Viet Chi Tran (LPP)", "title": "On Computer-Intensive Simulation and Estimation Methods for Rare Event\n  Analysis in Epidemic Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article focuses, in the context of epidemic models, on rare events that\nmay possibly correspond to crisis situations from the perspective of Public\nHealth. In general, no close analytic form for their occurrence probabilities\nis available and crude Monte-Carlo procedures fail. We show how recent\nintensive computer simulation techniques, such as interacting branching\nparticle methods, can be used for estimation purposes, as well as for\ngenerating model paths that correspond to realizations of such events.\nApplications of these simulation-based methods to several epidemic models are\nalso considered and discussed thoroughly.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2013 11:42:04 GMT"}], "update_date": "2013-08-28", "authors_parsed": [["Cl\u00e9men\u00e7on", "St\u00e9phan", "", "LTCI"], ["Cousien", "Anthony", "", "ATIP-Avenir\n  Inserm"], ["Felipe", "Miraine D\u00e1vila", "", "LTCI, CIRB"], ["Tran", "Viet Chi", "", "LPP"]]}, {"id": "1308.5842", "submitter": "Hanno Gottschalk", "authors": "Sebastian Schmitz, Thomas Seibel, Tilman Beck, Georg Rollmann, Rolf\n  Krause, Hanno Gottschalk", "title": "A Probabilistic Model for LCF", "comments": "20 pages, 6 figures", "journal-ref": "Computational Materials Science 79 (2013), 584-590", "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fatigue life of components or test specimens often exhibit a significant\nscatter. Furthermore, size effects have a non-negligible influence on fatigue\nlife of parts with different geometries. We present a new probabilistic model\nfor low-cycle fatigue (LCF) in the context of polycrystalline metal. The model\ntakes size effects and inhomogeneous strain fields into account by means of the\nPoisson point process (PPP). This approach is based on the assumption of\nindependently occurring LCF cracks and the Coffin-Manson-Basquin (CMB)\nequation. Within the probabilistic model, we give a new and more physical\ninterpretation of the CMB parameters which are in the original approach no\nmaterial parameters in a strict sense, as they depend on the specimen geometry.\nCalibration and validation of the proposed model is performed using results of\nstrain controlled LCF tests of specimens with different surface areas. The test\nspecimens are made of the nickel base superalloy RENE 80.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2013 12:43:10 GMT"}], "update_date": "2013-08-28", "authors_parsed": [["Schmitz", "Sebastian", ""], ["Seibel", "Thomas", ""], ["Beck", "Tilman", ""], ["Rollmann", "Georg", ""], ["Krause", "Rolf", ""], ["Gottschalk", "Hanno", ""]]}, {"id": "1308.5850", "submitter": "Roland Langrock", "authors": "Roland Langrock, J. Grant C. Hopcraft, Paul G. Blackwell, Victoria\n  Goodall, Ruth King, Mu Niu, Toby A. Patterson, Martin W. Pedersen, Anna\n  Skarin, Robert S. Schick", "title": "Modelling group dynamic animal movement", "comments": null, "journal-ref": "Methods in Ecology and Evolution, 2014, Vol. 5, Issue 2, pages\n  190-199", "doi": "10.1111/2041-210X.12155", "report-no": null, "categories": "q-bio.QM stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Group dynamic movement is a fundamental aspect of many species' movements.\nThe need to adequately model individuals' interactions with other group members\nhas been recognised, particularly in order to differentiate the role of social\nforces in individual movement from environmental factors. However, to date,\npractical statistical methods which can include group dynamics in animal\nmovement models have been lacking. We consider a flexible modelling framework\nthat distinguishes a group-level model, describing the movement of the group's\ncentre, and an individual-level model, such that each individual makes its\nmovement decisions relative to the group centroid. The basic idea is framed\nwithin the flexible class of hidden Markov models, extending previous work on\nmodelling animal movement by means of multi-state random walks. While in\nsimulation experiments parameter estimators exhibit some bias in non-ideal\nscenarios, we show that generally the estimation of models of this type is both\nfeasible and ecologically informative. We illustrate the approach using real\nmovement data from 11 reindeer (Rangifer tarandus). Results indicate a\ndirectional bias towards a group centroid for reindeer in an encamped state.\nThough the attraction to the group centroid is relatively weak, our model\nsuccessfully captures group-influenced movement dynamics. Specifically, as\ncompared to a regular mixture of correlated random walks, the group dynamic\nmodel more accurately predicts the non-diffusive behaviour of a cohesive mobile\ngroup.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2013 12:52:33 GMT"}], "update_date": "2015-05-21", "authors_parsed": [["Langrock", "Roland", ""], ["Hopcraft", "J. Grant C.", ""], ["Blackwell", "Paul G.", ""], ["Goodall", "Victoria", ""], ["King", "Ruth", ""], ["Niu", "Mu", ""], ["Patterson", "Toby A.", ""], ["Pedersen", "Martin W.", ""], ["Skarin", "Anna", ""], ["Schick", "Robert S.", ""]]}, {"id": "1308.5953", "submitter": "James Hensman", "authors": "James Hensman, Peter Glaus, Antti Honkela, Magnus Rattray", "title": "Fast Approximate Inference of Transcript Expression Levels from RNA-seq\n  Data", "comments": "This paper has been withdrawn by the authors. Please see much revised\n  edition arXiv:1412.5995", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN stat.AP stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivation: The mapping of RNA-seq reads to their transcripts of origin is a\nfundamental task in transcript expression estimation and differential\nexpression scoring. Where ambiguities in mapping exist due to transcripts\nsharing sequence, e.g. alternative isoforms or alleles, the problem becomes an\ninstance of non-trivial probabilistic inference. Bayesian inference in such a\nproblem is intractable and approximate methods must be used such as Markov\nchain Monte Carlo (MCMC) and Variational Bayes. Standard implementations of\nthese methods can be prohibitively slow for large datasets and complex gene\nmodels.\n  Results: We propose an approximate inference scheme based on Variational\nBayes applied to an existing model of transcript expression inference from\nRNA-seq data. We apply recent advances in Variational Bayes algorithmics to\nimprove the convergence of the algorithm beyond the standard variational\nexpectation-maximisation approach. We apply our algorithm to simulated and\nbiological datasets, demonstrating that the increase in speed requires only a\nsmall trade-off in accuracy of expression level estimation.\n  Availability: The methods were implemented in R and C++, and are available as\npart of the BitSeq project at https://code.google.com/p/bitseq/. The methods\nwill be made available through the BitSeq Bioconductor package at the next\nstable release.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2013 19:16:40 GMT"}, {"version": "v2", "created": "Tue, 27 Jan 2015 10:35:01 GMT"}], "update_date": "2015-01-28", "authors_parsed": [["Hensman", "James", ""], ["Glaus", "Peter", ""], ["Honkela", "Antti", ""], ["Rattray", "Magnus", ""]]}, {"id": "1308.6013", "submitter": "John Storey", "authors": "Neo Christopher Chung and John D. Storey", "title": "Statistical significance of variables driving systematic variation", "comments": "35 pages, 1 table, 6 main figures, 7 supplementary figures", "journal-ref": "Bioinformatics (2015) 31 (4): 545-554", "doi": "10.1093/bioinformatics/btu674", "report-no": null, "categories": "stat.ME q-bio.QM stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are a number of well-established methods such as principal components\nanalysis (PCA) for automatically capturing systematic variation due to latent\nvariables in large-scale genomic data. PCA and related methods may directly\nprovide a quantitative characterization of a complex biological variable that\nis otherwise difficult to precisely define or model. An unsolved problem in\nthis context is how to systematically identify the genomic variables that are\ndrivers of systematic variation captured by PCA. Principal components (and\nother estimates of systematic variation) are directly constructed from the\ngenomic variables themselves, making measures of statistical significance\nartificially inflated when using conventional methods due to over-fitting. We\nintroduce a new approach called the jackstraw that allows one to accurately\nidentify genomic variables that are statistically significantly associated with\nany subset or linear combination of principal components (PCs). The proposed\nmethod can greatly simplify complex significance testing problems encountered\nin genomics and can be utilized to identify the genomic variables significantly\nassociated with latent variables. Using simulation, we demonstrate that our\nmethod attains accurate measures of statistical significance over a range of\nrelevant scenarios. We consider yeast cell-cycle gene expression data, and show\nthat the proposed method can be used to straightforwardly identify\nstatistically significant genes that are cell-cycle regulated. We also analyze\ngene expression data from post-trauma patients, allowing the gene expression\ndata to provide a molecularly-driven phenotype. We find a greater enrichment\nfor inflammatory-related gene sets compared to using a clinically defined\nphenotype. The proposed method provides a useful bridge between large-scale\nquantifications of systematic variation and gene-level significance analyses.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2013 23:37:11 GMT"}], "update_date": "2015-03-05", "authors_parsed": [["Chung", "Neo Christopher", ""], ["Storey", "John D.", ""]]}, {"id": "1308.6210", "submitter": "Ron Nielsen", "authors": "Ron W. Nielsen aka Jan Nurzynski", "title": "Hyperbolic Illusion of the Mid-Holocene Turning Point", "comments": "13 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using the growth of population in Australia in the past 10,000 years it is\nillustrated here how an illusion created by hyperbolic distributions may lead\neasily to incorrect conclusions. Contrary to the published claim, there was no\nchange in the mechanism of growth of the ancient human population in Australia\naround 5000 years before present (BP). Data for the number of rock-shelter\nsites, interpreted as reflecting the growth of human population, are analysed.\nThey are shown to be monotonically increasing with time without any sign of\nintensification in the past 10,000 years. The growth of human population in\nAustralia is in excellent agreement with the similar pattern describing the\ngrowth of the world population.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2013 09:12:51 GMT"}, {"version": "v2", "created": "Thu, 17 Oct 2013 01:56:25 GMT"}, {"version": "v3", "created": "Fri, 25 Oct 2013 02:13:08 GMT"}], "update_date": "2013-10-28", "authors_parsed": [["Nurzynski", "Ron W. Nielsen aka Jan", ""]]}, {"id": "1308.6245", "submitter": "Wentian Li", "authors": "Wentian Li, Jan Freudenberg, Young Ju Suh, Yaning Yang", "title": "Using Volcano Plots and Regularized-Chi Statistics in Genetic\n  Association Studies", "comments": "5 figures", "journal-ref": "Computational Biology and Chemistry, 48: 77-83 (2014)", "doi": "10.1016/j.compbiolchem.2013.02.003", "report-no": null, "categories": "q-bio.QM stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Labor intensive experiments are typically required to identify the causal\ndisease variants from a list of disease associated variants in the genome. For\ndesigning such experiments, candidate variants are ranked by their strength of\ngenetic association with the disease. However, the two commonly used measures\nof genetic association, the odds-ratio (OR) and p-value, may rank variants in\ndifferent order. To integrate these two measures into a single analysis, here\nwe transfer the volcano plot methodology from gene expression analysis to\ngenetic association studies. In its original setting, volcano plots are scatter\nplots of fold-change and t-test statistic (or -log of the p-value), with the\nlatter being more sensitive to sample size. In genetic association studies, the\nOR and Pearson's chi-square statistic (or equivalently its square root, chi; or\nthe standardized log(OR)) can be analogously used in a volcano plot, allowing\nfor their visual inspection. Moreover, the geometric interpretation of these\nplots leads to an intuitive method for filtering results by a combination of\nboth OR and chi-square statistic, which we term \"regularized-chi\". This method\nselects associated markers by a smooth curve in the volcano plot instead of the\nright-angled lines which corresponds to independent cutoffs for OR and\nchi-square statistic. The regularized-chi incorporates relatively more signals\nfrom variants with lower minor-allele-frequencies than chi-square test\nstatistic. As rare variants tend to have stronger functional effects,\nregularized-chi is better suited to the task of prioritization of candidate\ngenes.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2013 18:40:58 GMT"}], "update_date": "2017-03-03", "authors_parsed": [["Li", "Wentian", ""], ["Freudenberg", "Jan", ""], ["Suh", "Young Ju", ""], ["Yang", "Yaning", ""]]}, {"id": "1308.6312", "submitter": "Gianluca Baio", "authors": "Marta Blangiardo, Gianluca Baio", "title": "Evidence of bias in the Eurovision song contest: modelling the votes\n  using Bayesian hierarchical models", "comments": "16 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Eurovision Song Contest is an annual musical competition held among\nactive members of the European Broadcasting Union since 1956. The event is\ntelevised live across Europe. Each participating country presents a song and\nreceive a vote based on a combination of tele-voting and jury. Over the years,\nthis has led to speculations of tactical voting, discriminating against some\nparticipants and thus inducing bias in the final results. In this paper we\ninvestigate the presence of positive or negative bias (which may roughly\nindicate favouritisms or discrimination) in the votes based on geographical\nproximity, migration and cultural characteristics of the participating\ncountries through a Bayesian hierarchical model. Our analysis found no evidence\nof negative bias, although mild positive bias does seem to emerge\nsystematically, linking voters to performers.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2013 21:12:15 GMT"}], "update_date": "2013-08-30", "authors_parsed": [["Blangiardo", "Marta", ""], ["Baio", "Gianluca", ""]]}, {"id": "1308.6356", "submitter": "Christopher Homan", "authors": "Christopher M. Homan, Vincent Silenzio, and Randall Sell", "title": "Respondent-Driven Sampling in Online Social Networks", "comments": null, "journal-ref": "Social Computing, Behavioral-Cultural Modeling and Prediction\n  Lecture Notes in Computer Science Volume 7812, 2013, pp 403-411", "doi": null, "report-no": null, "categories": "cs.SI stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Respondent-driven sampling (RDS) is a commonly used method for acquiring data\non hidden communities, i.e., those that lack unbiased sampling frames or face\nsocial stigmas that make their mem- bers unwilling to identify themselves.\nObtaining accurate statistical data about such communities is important\nbecause, for instance, they often have different health burdens from the\ngreater population, and without good statistics it is hard and expensive to\neffectively reach them for pre- vention or treatment interventions. Online\nsocial networks (OSN) have the potential to transform RDS for the better. We\npresent a new RDS recruitment protocol for (OSNs) and show via simulation that\nit out- performs the standard RDS protocol in terms of sampling accuracy and\napproaches the accuracy of Markov chain Monte Carlo random walks.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2013 03:42:27 GMT"}], "update_date": "2013-08-30", "authors_parsed": [["Homan", "Christopher M.", ""], ["Silenzio", "Vincent", ""], ["Sell", "Randall", ""]]}, {"id": "1308.6487", "submitter": "Leonardo Torres", "authors": "Leonardo Torres and Tamer Cavalcante and Alejandro C. Frery", "title": "A New Algorithm of Speckle Filtering using Stochastic Distances", "comments": "Accepted for publication on the proceedings of the IEEE Geoscience\n  and Remote Sensing Symposium (IGARSS 2012), to be published in IEEE Press.\n  Available: http://www.igarss2012.org/Papers/viewpapers.asp?papernum=4877", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CV cs.GR math.IT stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new approach for filter design based on stochastic\ndistances and tests between distributions. A window is defined around each\npixel, overlapping samples are compared and only those which pass a\ngoodness-of-fit test are used to compute the filtered value. The technique is\napplied to intensity SAR data with homogeneous regions using the Gamma model.\nThe proposal is compared with the Lee's filter using a protocol based on Monte\nCarlo. Among the criteria used to quantify the quality of filters, we employ\nthe equivalent number of looks, line and edge preservation. Moreover, we also\nassessed the filters by the Universal Image Quality Index and the Pearson's\ncorrelation on edges regions.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2013 14:56:01 GMT"}], "update_date": "2013-08-30", "authors_parsed": [["Torres", "Leonardo", ""], ["Cavalcante", "Tamer", ""], ["Frery", "Alejandro C.", ""]]}]