[{"id": "0806.0539", "submitter": "Jan Christoph Neddermeyer", "authors": "Jan C. Neddermeyer", "title": "Nonparametric Partial Importance Sampling for Financial Derivative\n  Pricing", "comments": "26 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Importance sampling is a promising variance reduction technique for Monte\nCarlo simulation based derivative pricing. Existing importance sampling methods\nare based on a parametric choice of the proposal. This article proposes an\nalgorithm that estimates the optimal proposal nonparametrically using a\nmultivariate frequency polygon estimator. In contrast to parametric methods,\nnonparametric estimation allows for close approximation of the optimal\nproposal. Standard nonparametric importance sampling is inefficient for\nhigh-dimensional problems. We solve this issue by applying the procedure to a\nlow-dimensional subspace, which is identified through principal component\nanalysis and the concept of the effective dimension. The mean square error\nproperties of the algorithm are investigated and its asymptotic optimality is\nshown. Quasi-Monte Carlo is used for further improvement of the method. It is\neasy to implement, particularly it does not require any analytical computation,\nand it is computationally very efficient. We demonstrate through path-dependent\nand multi-asset option pricing problems that the algorithm leads to significant\nefficiency gains compared to other algorithms in the literature.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jun 2008 13:39:45 GMT"}, {"version": "v2", "created": "Tue, 14 Apr 2009 08:57:26 GMT"}], "update_date": "2009-04-14", "authors_parsed": [["Neddermeyer", "Jan C.", ""]]}, {"id": "0806.1354", "submitter": "Nataliya Malyshkina", "authors": "Nataliya V. Malyshkina, Fred L. Mannering", "title": "Analysis of the Effect of Speed Limit Increases on Accident-Injury\n  Severities", "comments": "14 pages, 2 tables, accepted for publication in Transportation\n  Research Record", "journal-ref": "Transportation Research Record, 2008, Issue 2083, pages 122-127", "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The influence of speed limits on roadway safety has been a subject of\ncontinuous debate in the State of Indiana and nationwide. In Indiana,\nhighway-related accidents result in about 900 fatalities and forty thousand\ninjuries annually and place an incredible social and economic burden on the\nstate. Still, speed limits posted on highways and other roads are routinely\nexceeded as individual drivers try to balance safety, mobility (speed), and the\nrisks and penalties associated with law enforcement efforts. The\nspeed-limit/safety issue has been a matter of considerable concern in Indiana\nsince the state raised its speed limits on rural interstates and selected\nmultilane highways on July 1, 2005. In this paper, the influence of the posted\nspeed limit on the severity of vehicle accidents is studied using Indiana\naccident data from 2004 (the year before speed limits were raised) and 2006\n(the year after speed limits were raised on rural interstates and some\nmulti-lane non-interstate routes). Statistical models of the injury severity of\ndifferent types of accidents on various roadway classes were estimated. The\nresults of the model estimations showed that, for the speed limit ranges\ncurrently used, speed limits did not have a statistically significant effect on\nthe severity of accidents on interstate highways. However, for some\nnon-interstate highways, higher speed limits were found to be associated with\nhigher accident severities - suggesting that future speed limit changes, on\nnon-interstate highways in particular, need to be carefully assessed on a\ncase-by-case basis.\n", "versions": [{"version": "v1", "created": "Sun, 8 Jun 2008 20:00:01 GMT"}], "update_date": "2009-08-02", "authors_parsed": [["Malyshkina", "Nataliya V.", ""], ["Mannering", "Fred L.", ""]]}, {"id": "0806.1473", "submitter": "Elvan Ceyhan", "authors": "Elvan Ceyhan, Can Ceritoglu, M. Faisal Beg, Lei Wang, John C. Morris,\n  John G. Csernansky, Michael I. Miller, John Tilak Ratnanather", "title": "Analysis of Metric Distances and Volumes of Hippocampi Indicates\n  Different Morphometric Changes over Time in Dementia of Alzheimer Type and\n  Nondemented Subjects", "comments": null, "journal-ref": null, "doi": null, "report-no": "KU-EC-08-3", "categories": "stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we analyze the morphometry of hippocampus in subjects with\nvery mild dementia of Alzheimer's type (DAT) and nondemented controls and how\nit changes over a two-year period. Morphometric differences with respect to a\ntemplate hippocampus were measured by the metric distance obtained from the\nLarge Deformation Diffeomorphic Metric Mapping (LDDMM) algorithm which was\npreviously used to calculate dense one-to-one correspondence vector fields\nbetween the shapes. LDDMM assigns metric distances on the space of anatomical\nimages thereby allowing for the direct comparison and quantization of\nmorphometric changes. We use various statistical methods to compare the metric\ndistances in a cross-sectional and longitudinal manner. At baseline, the metric\ndistances for demented subjects are found not to be significantly different\nfrom those for nondemented subjects. At follow-up, the metric distances for\ndemented subjects were significantly larger compared to nondemented subjects.\nThe metric distances for demented subjects increased significantly from\nbaseline to follow-up but not for nondemented subjects. We also use the metric\ndistances in logistic regression for diagnostic discrimination of subjects. We\ncompare metric distances with the volumes and obtain similar results. In\nclassification, the model that uses volume, metric distance, and volume loss\nover time together performs better in detecting DAT. Thus, metric distances\nwith respect to a template computed via LDDMM can be a powerful tool in\ndetecting differences in shape in cross-sectional as well as longitudinal\nstudies.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jun 2008 15:09:39 GMT"}, {"version": "v2", "created": "Thu, 14 Aug 2008 18:14:26 GMT"}], "update_date": "2008-08-14", "authors_parsed": [["Ceyhan", "Elvan", ""], ["Ceritoglu", "Can", ""], ["Beg", "M. Faisal", ""], ["Wang", "Lei", ""], ["Morris", "John C.", ""], ["Csernansky", "John G.", ""], ["Miller", "Michael I.", ""], ["Ratnanather", "John Tilak", ""]]}, {"id": "0806.1631", "submitter": "Maria Elena De Giuli professor", "authors": "Maria Elena De Giuli (1), Mario Alessandro Maggi (1), Claudia\n  Tarantola (2) ((1)Department of Business Research, University of Pavia, (2)\n  Department of Economics and Quantitative Methods, University of Pavia, Italy)", "title": "Bayesian outlier detection in Capital Asset Pricing Model", "comments": null, "journal-ref": "statistical Modelling ,2010, 10, 379--390", "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel Bayesian optimisation procedure for outlier detection in\nthe Capital Asset Pricing Model. We use a parametric product partition model to\nrobustly estimate the systematic risk of an asset. We assume that the returns\nfollow independent normal distributions and we impose a partition structure on\nthe parameters of interest. The partition structure imposed on the parameters\ninduces a corresponding clustering of the returns. We identify via an\noptimisation procedure the partition that best separates standard observations\nfrom the atypical ones. The methodology is illustrated with reference to a real\ndata set, for which we also provide a microeconomic interpretation of the\ndetected outliers.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jun 2008 10:50:54 GMT"}, {"version": "v2", "created": "Thu, 23 Apr 2009 09:52:48 GMT"}], "update_date": "2011-11-18", "authors_parsed": [["De Giuli", "Maria Elena", ""], ["Maggi", "Mario Alessandro", ""], ["Tarantola", "Claudia", ""]]}, {"id": "0806.1894", "submitter": "Jerome  Percus", "authors": "O.E. Percus and J.K. Percus", "title": "Extrapolation of Threshold-Limited Null Measurement Frequencies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The total measurable level of a pathogen is due to many sources, which\nproduce a variety of pulses, overlapping in time, that rise suddenly and then\ndecay. What is measured is the level of the total contribution of the sources\nat a given time. But since we are only capable of measuring the total level\nabove some threshold $x_0$, we would like to predict the distribution below\nthis level. Our principal model assumption is that of the asymptotic\nexponential decay of all pulses. We show that this implies a power law\ndistribution for the frequencies of low amplitude observations. As a\nconsequence, there is a simple extrapolation procedure for carrying the data to\nthe region below $x_0$.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jun 2008 19:25:25 GMT"}], "update_date": "2008-11-23", "authors_parsed": [["Percus", "O. E.", ""], ["Percus", "J. K.", ""]]}, {"id": "0806.2305", "submitter": "Jan Lorenz", "authors": "Jan Lorenz", "title": "Universality in movie rating distributions", "comments": "8 pages, 5 figures, accepted for publication", "journal-ref": "European Physical Journal B (2009), 71, 251-258", "doi": "10.1140/epjb/e2009-00283-3", "report-no": null, "categories": "physics.soc-ph physics.data-an stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper histograms of user ratings for movies (1,...,10) are analysed.\nThe evolving stabilised shapes of histograms follow the rule that all are\neither double- or triple-peaked. Moreover, at most one peak can be on the\ncentral bins 2,...,9 and the distribution in these bins looks smooth\n`Gaussian-like' while changes at the extremes (1 and 10) often look abrupt. It\nis shown that this is well approximated under the assumption that histograms\nare confined and discretised probability density functions of L\\'evy skew\nalpha-stable distributions. These distributions are the only stable\ndistributions which could emerge due to a generalized central limit theorem\nfrom averaging of various independent random avriables as which one can see the\ninitial opinions of users. Averaging is also an appropriate assumption about\nthe social process which underlies the process of continuous opinion formation.\nSurprisingly, not the normal distribution achieves the best fit over histograms\nobseved on the web, but distributions with fat tails which decay as power-laws\nwith exponent -(1+alpha) (alpha=4/3). The scale and skewness parameters of the\nLevy skew alpha-stable distributions seem to depend on the deviation from an\naverage movie (with mean about 7.6). The histogram of such an average movie has\nno skewness and is the most narrow one. If a movie deviates from average the\ndistribution gets broader and skew. The skewness pronounces the deviation. This\nis used to construct a one parameter fit which gives some evidence of\nuniversality in processes of continuous opinion dynamics about taste.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jun 2008 18:19:34 GMT"}, {"version": "v2", "created": "Mon, 4 May 2009 10:04:56 GMT"}, {"version": "v3", "created": "Fri, 10 Jul 2009 14:04:57 GMT"}], "update_date": "2010-12-07", "authors_parsed": [["Lorenz", "Jan", ""]]}, {"id": "0806.3286", "submitter": "Hugh A. Chipman", "authors": "Hugh A. Chipman, Edward I. George, Robert E. McCulloch", "title": "BART: Bayesian additive regression trees", "comments": "Published in at http://dx.doi.org/10.1214/09-AOAS285 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2010, Vol. 4, No. 1, 266-298", "doi": "10.1214/09-AOAS285", "report-no": "IMS-AOAS-AOAS285", "categories": "stat.ME stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a Bayesian \"sum-of-trees\" model where each tree is constrained by\na regularization prior to be a weak learner, and fitting and inference are\naccomplished via an iterative Bayesian backfitting MCMC algorithm that\ngenerates samples from a posterior. Effectively, BART is a nonparametric\nBayesian regression approach which uses dimensionally adaptive random basis\nelements. Motivated by ensemble methods in general, and boosting algorithms in\nparticular, BART is defined by a statistical model: a prior and a likelihood.\nThis approach enables full posterior inference including point and interval\nestimates of the unknown regression function as well as the marginal effects of\npotential predictors. By keeping track of predictor inclusion frequencies, BART\ncan also be used for model-free variable selection. BART's many features are\nillustrated with a bake-off against competing methods on 42 different data\nsets, with a simulation experiment and on a drug discovery classification\nproblem.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jun 2008 21:00:03 GMT"}, {"version": "v2", "created": "Thu, 7 Oct 2010 09:21:37 GMT"}], "update_date": "2010-10-08", "authors_parsed": [["Chipman", "Hugh A.", ""], ["George", "Edward I.", ""], ["McCulloch", "Robert E.", ""]]}, {"id": "0806.3301", "submitter": "Ryan Tibshirani", "authors": "Ryan J. Tibshirani", "title": "Fast computation of the median by successive binning", "comments": "14 pages, 1 Postscript figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.DS stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a new median algorithm and a median approximation\nalgorithm. The former has O(n) average running time and the latter has O(n)\nworst-case running time. These algorithms are highly competitive with the\nstandard algorithm when computing the median of a single data set, but are\nsignificantly faster in updating the median when more data is added.\n", "versions": [{"version": "v1", "created": "Fri, 20 Jun 2008 00:44:53 GMT"}, {"version": "v2", "created": "Tue, 12 May 2009 04:46:56 GMT"}], "update_date": "2009-05-12", "authors_parsed": [["Tibshirani", "Ryan J.", ""]]}, {"id": "0806.3684", "submitter": "- Departement Mathematiques Orsay", "authors": "Gregory Benmenzer (LJK), Didier Dacunha-Castelle (LM-Orsay), T.T.Huong\n  Hoang (LM-Orsay)", "title": "Estimation of a diffusion model with trends taking in account the\n  extremes. Application to temperature in France", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We built a model of the daily temperature based on a diffusion process and\naddress to extreme values not taken into account in the literature on this kind\nof models. We first study, using non parametric tools, the trends on mean and\nvariance. In a second step we estimate a stationary model first non\nparametrically and then using likelihood methods. Extreme values are taken into\naccount in the estimation of model and to obtain a definitive estimation we use\nin a specific framework extreme theory for diffusions. A test of suitable model\nby simulation is done.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jun 2008 14:02:59 GMT"}], "update_date": "2008-12-18", "authors_parsed": [["Benmenzer", "Gregory", "", "LJK"], ["Dacunha-Castelle", "Didier", "", "LM-Orsay"], ["Hoang", "T. T. Huong", "", "LM-Orsay"]]}, {"id": "0806.4168", "submitter": "Paul Slater", "authors": "Paul B. Slater", "title": "Established Clustering Procedures for Network Analysis", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.SI physics.data-an stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In light of the burgeoning interest in network analysis in the new millenium,\nwe bring to the attention of contemporary network theorists, a two-stage\ndouble-standarization and hierarchical clustering (single-linkage-like)\nprocedure devised in 1974. In its many applications over the next\ndecade--primarily to the migration flows between geographic subdivisions within\nnations--the presence was often revealed of ``hubs''. These are, typically,\n``cosmopolitan/non-provincial'' areas--such as the French capital, Paris--which\nsend and receive people relatively broadly across their respective nations.\nAdditionally, this two-stage procedure--which ``might very well be the most\nsuccessful application of cluster analysis'' (R. C. Dubes)--has detected many\n(physically or socially) isolated groups (regions) of areas, such as those\nforming the southern islands, Shikoku and Kyushu, of Japan, the Italian islands\nof Sardinia and Sicily, and the New England region of the United States.\nFurther, we discuss a (complementary) approach developed in 1976, involving the\napplication of the max-flow/min-cut theorem to raw/non-standardized flows.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jun 2008 18:20:57 GMT"}], "update_date": "2012-07-03", "authors_parsed": [["Slater", "Paul B.", ""]]}, {"id": "0806.4441", "submitter": "Deborah Nolan", "authors": "Deborah Nolan, Terry Speed", "title": "Probability and Statistics: Essays in Honor of David A. Freedman", "comments": "Published in the IMS Collections\n  (http://www.imstat.org/publications/imscollections.htm) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "IMS Collections 2008, Vol. 2, i-vii", "doi": null, "report-no": null, "categories": "math.PR stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume is our tribute to David A. Freedman, whom we regard as one of the\ngreat statisticians of our time. He received his B.Sc. degree from McGill\nUniversity and his Ph.D. from Princeton, and joined the Department of\nStatistics of the University of California, Berkeley, in 1962, where, apart\nfrom sabbaticals, he has been ever since. In a career of over 45 years, David\nhas made many fine contributions to probability and statistical theory, and to\nthe application of statistics. His early research was on Markov chains and\nmartingales, and two topics with which he has had a lifelong fascination:\nexchangeability and De Finetti's theorem, and the consistency of Bayes\nestimates. His asymptotic theory for the bootstrap was also highly influential.\nDavid was elected to the American Academy of Arts and Sciences in 1991, and in\n2003 he received the John J. Carty Award for the Advancement of Science from\nthe U.S. National Academy of Sciences. In addition to his purely academic\nresearch, David has extensive experience as a consultant, including working for\nthe Carnegie Commission, the City of San Francisco, and the Federal Reserve, as\nwell as several Departments of the U.S. Government--Energy, Treasury, Justice,\nand Commerce. He has testified as an expert witness on statistics in a number\nof law cases, including Piva v. Xerox (employment discrimination), Garza v.\nCounty of Los Angeles (voting rights), and New York v. Department of Commerce\n(census adjustment). Lastly, he is an exceptionally good writer and teacher,\nand his many books and review articles are arguably his most important\ncontribution to our subject.\n", "versions": [{"version": "v1", "created": "Fri, 27 Jun 2008 08:25:01 GMT"}], "update_date": "2008-06-30", "authors_parsed": [["Nolan", "Deborah", ""], ["Speed", "Terry", ""]]}, {"id": "0806.4642", "submitter": "Amy Gansell", "authors": "Amy Rebecca Gansell, Irene K.Tamaru, Aleks Jakulin, and Chris H.\n  Wiggins", "title": "Predicting Regional Classification of Levantine Ivory Sculptures: A\n  Machine Learning Approach", "comments": "presented at 34th Computer Applications & Quantitative Methods in\n  Archaeology Conference, Fargo, North Dakota, April 2006. appears in Digital\n  Discovery: Exploring New Frontiers in Human Heritage; CAA 2006. ISBN\n  978-963-8046-90-1. pp 483-492 (2007)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Art historians and archaeologists have long grappled with the regional\nclassification of ancient Near Eastern ivory carvings. Based on the visual\nsimilarity of sculptures, individuals within these fields have proposed object\nassemblages linked to hypothesized regional production centers. Using\nquantitative rather than visual methods, we here approach this classification\ntask by exploiting computational methods from machine learning currently used\nwith success in a variety of statistical problems in science and engineering.\nWe first construct a prediction function using 66 categorical features as\ninputs and regional style as output. The model assigns regional style group\n(RSG), with 98 percent prediction accuracy. We then rank these features by\ntheir mutual information with RSG, quantifying single-feature predictive power.\nUsing the highest- ranking features in combination with nomographic\nvisualization, we have found previously unknown relationships that may aid in\nthe regional classification of these ivories and their interpretation in art\nhistorical context.\n", "versions": [{"version": "v1", "created": "Sat, 28 Jun 2008 01:59:38 GMT"}], "update_date": "2008-07-01", "authors_parsed": [["Gansell", "Amy Rebecca", ""], ["Tamaru", "Irene K.", ""], ["Jakulin", "Aleks", ""], ["Wiggins", "Chris H.", ""]]}]