[{"id": "0801.0207", "submitter": "Myriam Maumy", "authors": "Myriam Maumy (IRMA), B. Boulanger, W. Dewe, A. Gilbert, B. Govaerts", "title": "Risk management for analytical methods: conciliating objectives of\n  methods, validation phase and routine decision rules", "comments": null, "journal-ref": "Dans Actes du congr\\`es de Chimiom\\'etrie 2005 - Risk management\n  for analytical methods: conciliating objectives of methods, validation phase\n  and routine decision rules., France (2005)", "doi": null, "report-no": null, "categories": "stat.AP math.ST stat.TH", "license": null, "abstract": "  In the industries that involved either chemistry or biology, such as\npharmaceutical industries, chemical industries or food industry, the analytical\nmethods are the necessary eyes and hear of all the material produced or used.\nIf the quality of an analytical method is doubtful, then the whole set of\ndecision that will be based on those measures is questionable. For those\nreasons, being able to assess the quality of an analytical method is far more\nthan a statistical challenge; it's a matter of ethic and good business\npractices. Many regulatory documents have been releases, primarily ICH and FDA\ndocuments in the pharmaceutical industry (FDA, 1995, 1997, 2001) to address\nthat issue.\n", "versions": [{"version": "v1", "created": "Mon, 31 Dec 2007 14:05:52 GMT"}], "update_date": "2008-01-03", "authors_parsed": [["Maumy", "Myriam", "", "IRMA"], ["Boulanger", "B.", ""], ["Dewe", "W.", ""], ["Gilbert", "A.", ""], ["Govaerts", "B.", ""]]}, {"id": "0801.0254", "submitter": "Reinhard Laubenbacher", "authors": "Reinhard Laubenbacher and Brandilyn Stigler", "title": "Design of experiments and biochemical network inference", "comments": "To appear in \"Algebraic and geometric methods in statistics,\" P.\n  Gibilisco, E. Riccomagno, M.-P. Rogantin, H. P. Wynn, eds., Cambridge\n  University Press, 2008", "journal-ref": "Algebraic and Geometric Methods in Statistics. Eds: Gibilisco,\n  Riccomagno, Rogantin, Wynn, Cambridge University Press (2008)", "doi": null, "report-no": null, "categories": "q-bio.MN stat.AP", "license": null, "abstract": "  Design of experiments is a branch of statistics that aims to identify\nefficient procedures for planning experiments in order to optimize knowledge\ndiscovery. Network inference is a subfield of systems biology devoted to the\nidentification of biochemical networks from experimental data. Common to both\nareas of research is their focus on the maximization of information gathered\nfrom experimentation. The goal of this paper is to establish a connection\nbetween these two areas coming from the common use of polynomial models and\ntechniques from computational algebra.\n", "versions": [{"version": "v1", "created": "Mon, 31 Dec 2007 23:52:47 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Laubenbacher", "Reinhard", ""], ["Stigler", "Brandilyn", ""]]}, {"id": "0801.0275", "submitter": "Vincent Tan", "authors": "Vincent Y. F. Tan, Vivek K. Goyal", "title": "Estimating Signals with Finite Rate of Innovation from Noisy Samples: A\n  Stochastic Algorithm", "comments": "Submitted to IEEE Transactions on Signal Processing", "journal-ref": "IEEE Trans. on Signal Processing, vol. 56, no. 10, pp. 5135-5146,\n  October 2008", "doi": "10.1109/TSP.2008.928510", "report-no": null, "categories": "stat.AP cs.IT math.IT", "license": null, "abstract": "  As an example of the recently-introduced concept of rate of innovation,\nsignals that are linear combinations of a finite number of Diracs per unit time\ncan be acquired by linear filtering followed by uniform sampling. However, in\nreality, samples are rarely noiseless. In this paper, we introduce a novel\nstochastic algorithm to reconstruct a signal with finite rate of innovation\nfrom its noisy samples. Even though variants of this problem has been\napproached previously, satisfactory solutions are only available for certain\nclasses of sampling kernels, for example kernels which satisfy the Strang-Fix\ncondition. In this paper, we consider the infinite-support Gaussian kernel,\nwhich does not satisfy the Strang-Fix condition. Other classes of kernels can\nbe employed. Our algorithm is based on Gibbs sampling, a Markov chain Monte\nCarlo (MCMC) method. Extensive numerical simulations demonstrate the accuracy\nand robustness of our algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jan 2008 05:19:35 GMT"}, {"version": "v2", "created": "Thu, 3 Jan 2008 01:09:41 GMT"}], "update_date": "2009-03-09", "authors_parsed": [["Tan", "Vincent Y. F.", ""], ["Goyal", "Vivek K.", ""]]}, {"id": "0801.0848", "submitter": "Nathalie Villa", "authors": "Romain Boulet (IMT), Bertrand Jouve (IMT), Fabrice Rossi (INRIA\n  Rocquencourt / INRIA Sophia Antipolis), Nathalie Villa (IMT)", "title": "Batch kernel SOM and related Laplacian methods for social network\n  analysis", "comments": null, "journal-ref": "Neurocomputing / EEG Neurocomputing (2008) A para\\^itre", "doi": null, "report-no": null, "categories": "stat.AP math.ST stat.ME stat.ML stat.TH", "license": null, "abstract": "  Large graphs are natural mathematical models for describing the structure of\nthe data in a wide variety of fields, such as web mining, social networks,\ninformation retrieval, biological networks, etc. For all these applications,\nautomatic tools are required to get a synthetic view of the graph and to reach\na good understanding of the underlying problem. In particular, discovering\ngroups of tightly connected vertices and understanding the relations between\nthose groups is very important in practice. This paper shows how a kernel\nversion of the batch Self Organizing Map can be used to achieve these goals via\nkernels derived from the Laplacian matrix of the graph, especially when it is\nused in conjunction with more classical methods based on the spectral analysis\nof the graph. The proposed method is used to explore the structure of a\nmedieval social network modeled through a weighted graph that has been directly\nbuilt from a large corpus of agrarian contracts.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jan 2008 08:28:15 GMT"}], "update_date": "2008-01-08", "authors_parsed": [["Boulet", "Romain", "", "IMT"], ["Jouve", "Bertrand", "", "IMT"], ["Rossi", "Fabrice", "", "INRIA\n  Rocquencourt / INRIA Sophia Antipolis"], ["Villa", "Nathalie", "", "IMT"]]}, {"id": "0801.1724", "submitter": "M. Khalilian", "authors": "S. Alimoradi, M. Khalilian", "title": "Bilinear Mixed Effects Models For Relations Between Universities", "comments": "Submitted to the Electronic Journal of Statistics\n  (http://www.i-journals.org/ejs/) by the Institute of Mathematical Statistics\n  (http://www.imstat.org)", "journal-ref": null, "doi": null, "report-no": "IMS-EJS-EJS_2008_167", "categories": "stat.AP", "license": null, "abstract": "  this article illustrates the use of linear and bilinear random effects models\nto represent statistical dependencies that often characterize dyadic data such\nas international relations. In particular, we show how to estimate models for\ndyadic data that simultaneously take into account: regressor variables and\nthird-order dependencies, such as transitivity, clustering, and balance. We\napply this new approach to the relations among ph.d. of university in Iran over\nthe period from 1991-2005, illustrating the presence and strength of second and\nthird-order statistical dependencies in these data.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jan 2008 06:54:47 GMT"}], "update_date": "2008-01-14", "authors_parsed": [["Alimoradi", "S.", ""], ["Khalilian", "M.", ""]]}, {"id": "0801.1864", "submitter": "Robert Kohn", "authors": "P. Giordani and R. Kohn", "title": "Adaptive Independent Metropolis-Hastings by Fast Estimation of Mixtures\n  of Normals", "comments": "35 pages and 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.AP stat.ME", "license": null, "abstract": "  We construct an adaptive independent Metropolis-Hastings sampler that uses a\nmixture of normals as a proposal distribution. To take full advantage of the\npotential of adaptive sampling our algorithm updates the mixture of normals\nfrequently, starting early in the chain. The algorithm is built for speed and\nreliability and its sampling performance is evaluated with real and simulated\nexamples. Our article outlines conditions for adaptive sampling to hold and\ngives a readily accessible proof that under these conditions the sampling\nscheme generates iterates that converge to the target distribution.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jan 2008 22:53:12 GMT"}], "update_date": "2008-01-15", "authors_parsed": [["Giordani", "P.", ""], ["Kohn", "R.", ""]]}, {"id": "0801.2800", "submitter": "Paul Sheridan", "authors": "Paul Sheridan, Yuichi Yagahara and Hidetoshi Shimodaira", "title": "A preferential attachment model with Poisson growth for scale-free\n  networks", "comments": "18 pages with 2 figures; correction to a proof in the appendix", "journal-ref": "Annals of the Institute of Statistical Mathematics 2008, Vol. 60,\n  pp. 747-761", "doi": "10.1007/s10463-008-0181-5", "report-no": null, "categories": "stat.AP", "license": null, "abstract": "  We propose a scale-free network model with a tunable power-law exponent. The\nPoisson growth model, as we call it, is an offshoot of the celebrated model of\nBarab\\'{a}si and Albert where a network is generated iteratively from a small\nseed network; at each step a node is added together with a number of incident\nedges preferentially attached to nodes already in the network. A key feature of\nour model is that the number of edges added at each step is a random variable\nwith Poisson distribution, and, unlike the Barab\\'{a}si-Albert model where this\nquantity is fixed, it can generate any network. Our model is motivated by an\napplication in Bayesian inference implemented as Markov chain Monte Carlo to\nestimate a network; for this purpose, we also give a formula for the\nprobability of a network under our model.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jan 2008 01:23:45 GMT"}, {"version": "v2", "created": "Thu, 31 Jan 2008 01:20:26 GMT"}], "update_date": "2013-12-24", "authors_parsed": [["Sheridan", "Paul", ""], ["Yagahara", "Yuichi", ""], ["Shimodaira", "Hidetoshi", ""]]}, {"id": "0801.3053", "submitter": "Nikitas Papasimakis", "authors": "Fotini Pallikari and Nikitas Papasimakis", "title": "Markovian Memory Embedded in Two-State Natural Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": null, "abstract": "  Markovian memory embedded in a binary system is shaping its evolution on the\nbasis of its current state and introduces either clustering or dispersion of\nbinary states. The consequence is directly observed in the lengthening or\nshortening of the runs of the same binary state and also in the way the\nproportion of a state within a sequence of state measurements scatters about\nits true average, which is quantifiable through the Markovian self-transition\nprobabilities. It is shown that the Markovian memory can even imitate the\nevolution of a random process, regarding the long-term behavior of the\nfrequencies of its binary states. This situation occurs when the associated\nbinary state self-transition probabilities are balanced. To exemplify the\nbehavior of Markovian memory, two natural processes are selected. The first\nexample is studying the preferences of nonhuman troglodytes regarding\nhandedness. The Markovian model in this case assesses the extent of influence\ntwo contiguous individuals may have on each other. The other example studies\nthe hindering of the quantum state transitions that rapid state measurements\nintroduce, known as the Quantum Zeno effect (QZE). Based on the current\nmethodology, simulations of the experimentally observed clustering of states\nallowed for the estimation of the two self-transition probabilities in this\nquantum system. Through these, one can appreciate how the particular hindering\nof the evolution of a quantum state may have originated. The aim of this work\nis to illustrate as merits of the current mathematical approach, its wide range\napplicability and its potential to provide a variety of information regarding\nthe dynamics of the studied process.\n", "versions": [{"version": "v1", "created": "Sat, 19 Jan 2008 23:48:24 GMT"}, {"version": "v2", "created": "Mon, 18 Feb 2008 18:50:07 GMT"}], "update_date": "2008-02-18", "authors_parsed": [["Pallikari", "Fotini", ""], ["Papasimakis", "Nikitas", ""]]}, {"id": "0801.3442", "submitter": "Qingzhao Yu", "authors": "Qingzhao Yu, Elizabeth A. Stasny, Bin Li", "title": "Bayesian models to adjust for response bias in survey data for\n  estimating rape and domestic violence rates from the NCVS", "comments": "Published in at http://dx.doi.org/10.1214/08-AOAS160 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2008, Vol. 2, No. 2, 665-686", "doi": "10.1214/08-AOAS160", "report-no": "IMS-AOAS-AOAS160", "categories": "stat.ME stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is difficult to accurately estimate the rates of rape and domestic\nviolence due to the sensitive nature of these crimes. There is evidence that\nbias in estimating the crime rates from survey data may arise because some\nwomen respondents are \"gagged\" in reporting some types of crimes by the use of\na telephone rather than a personal interview, and by the presence of a spouse\nduring the interview. On the other hand, as data on these crimes are collected\nevery year, it would be more efficient in data analysis if we could identify\nand make use of information from previous data. In this paper we propose a\nmodel to adjust the estimates of the rates of rape and domestic violence to\naccount for the response bias due to the \"gag\" factors. To estimate parameters\nin the model, we identify the information that is not sensitive to time and\nincorporate this into prior distributions. The strength of Bayesian estimators\nis their ability to combine information from long observational records in a\nsensible way. Within a Bayesian framework, we develop an\nExpectation-Maximization-Bayesian (EMB) algorithm for computation in analyzing\ncontingency table and we apply the jackknife to estimate the accuracy of the\nestimates. Our approach is illustrated using the yearly crime data from the\nNational Crime Victimization Survey. The illustration shows that compared with\nthe classical method, our model leads to more efficient estimation but does not\nrequire more complicated computation.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2008 18:51:56 GMT"}, {"version": "v2", "created": "Mon, 28 Jul 2008 15:15:54 GMT"}], "update_date": "2008-07-28", "authors_parsed": [["Yu", "Qingzhao", ""], ["Stasny", "Elizabeth A.", ""], ["Li", "Bin", ""]]}, {"id": "0801.4065", "submitter": "Brandon Whitcher", "authors": "Volker J. Schmid, Brandon Whitcher, Anwar R. Padhani, Guang-Zhong Yang", "title": "A Semi-parametric Technique for the Quantitative Analysis of Dynamic\n  Contrast-enhanced MR Images Based on Bayesian P-splines", "comments": null, "journal-ref": "IEEE Transactions on Medical Imaging ( Volume: 28 , Issue: 6 ,\n  June 2009 ). Page(s): 789 - 798", "doi": "10.1109/TMI.2008.2007326", "report-no": null, "categories": "stat.AP physics.med-ph stat.ME", "license": null, "abstract": "  Dynamic Contrast-enhanced Magnetic Resonance Imaging (DCE-MRI) is an\nimportant tool for detecting subtle kinetic changes in cancerous tissue.\nQuantitative analysis of DCE-MRI typically involves the convolution of an\narterial input function (AIF) with a nonlinear pharmacokinetic model of the\ncontrast agent concentration. Parameters of the kinetic model are biologically\nmeaningful, but the optimization of the non-linear model has significant\ncomputational issues. In practice, convergence of the optimization algorithm is\nnot guaranteed and the accuracy of the model fitting may be compromised. To\novercome this problems, this paper proposes a semi-parametric penalized spline\nsmoothing approach, with which the AIF is convolved with a set of B-splines to\nproduce a design matrix using locally adaptive smoothing parameters based on\nBayesian penalized spline models (P-splines). It has been shown that kinetic\nparameter estimation can be obtained from the resulting deconvolved response\nfunction, which also includes the onset of contrast enhancement. Detailed\nvalidation of the method, both with simulated and in vivo data, is provided.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jan 2008 08:59:24 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Schmid", "Volker J.", ""], ["Whitcher", "Brandon", ""], ["Padhani", "Anwar R.", ""], ["Yang", "Guang-Zhong", ""]]}, {"id": "0801.4172", "submitter": "Piero Barone", "authors": "Piero Barone", "title": "Computational aspects and applications of a new transform for solving\n  the complex exponentials approximation problem", "comments": "28 pages, 20 figures", "journal-ref": "Digital Signal processing 20 (2010) 724-735", "doi": "10.1016/j.dsp.2009.10.003", "report-no": null, "categories": "math.NA stat.AP stat.CO", "license": null, "abstract": "  Many real life problems can be reduced to the solution of a complex\nexponentials approximation problem which is usually ill posed. Recently a new\ntransform for solving this problem, formulated as a specific moments problem in\nthe plane, has been proposed in a theoretical framework. In this work some\ncomputational issues are addressed to make this new tool useful in practice. An\nalgorithm is developed and used to solve a Nuclear Magnetic Resonance\nspectrometry problem, two time series interpolation and extrapolation problems\nand a shape from moments problem.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2008 16:37:16 GMT"}], "update_date": "2012-05-03", "authors_parsed": [["Barone", "Piero", ""]]}, {"id": "0801.4408", "submitter": "Brendon Brewer", "authors": "Brendon J. Brewer", "title": "Getting Your Eye In: A Bayesian Analysis of Early Dismissals in Cricket", "comments": "Submitted. Latest version includes more quantitative results.\n  Software available from http://web.maths.unsw.edu.au/~brewer/", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP physics.data-an", "license": null, "abstract": "  A Bayesian Survival Analysis method is motivated and developed for analysing\nsequences of scores made by a batsman in test or first class cricket. In\nparticular, we expect the presence of an effect whereby the distribution of\nscores has more probability near zero than a geometric distribution, due to the\nfact that batting is more difficult when the batsman is new at the crease. A\nMetropolis-Hastings algorithm is found to be efficient at estimating the\nproposed parameters, allowing us to quantify exactly how large this\nearly-innings effect is, and how long a batsman needs to be at the crease in\norder to ``get their eye in''. Applying this model to several modern players\nshows that a batsman is typically only playing at about half of their potential\nability when they first arrive at the crease, and gets their eye in\nsurprisingly quickly. Additionally, some players are more ``robust'' (have a\nsmaller early-innings effect) than others, which may have implications for\nselection policy.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2008 01:12:58 GMT"}, {"version": "v2", "created": "Mon, 26 May 2008 06:30:54 GMT"}], "update_date": "2008-05-26", "authors_parsed": [["Brewer", "Brendon J.", ""]]}, {"id": "0801.4522", "submitter": "Jerome  Percus", "authors": "Ora E. Percus and Jerome K. Percus", "title": "The Inverse Simpson Paradox (How To Win Without Overtly Cheating)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": null, "abstract": "  Given two sets of data which lead to a similar statistical conclusion, the\nSimpson Paradox describes the tactic of combining these two sets and achieving\nthe opposite conclusion. Depending upon the given data, this may or may not\nsucceed. Inverse Simpson is a method of decomposing a given set of comparison\ndata into two disjoint sets and achieving the opposite conclusion for each one.\nThis is always possible; however, the statistical significance of the\nconclusions does depend upon the details of the given data.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2008 15:45:22 GMT"}], "update_date": "2008-01-30", "authors_parsed": [["Percus", "Ora E.", ""], ["Percus", "Jerome K.", ""]]}, {"id": "0801.4726", "submitter": "Sergey Nikitin", "authors": "S. Nikitin", "title": "Stochastic extrema as stationary phases of characteristic functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.AP stat.TH", "license": null, "abstract": "  The paper is dealing with semi-classical asymptotics of a characteristic\nfunction for a stochastic process. The main technical tool is provided by the\nstationary phase method. The extremal range for a stochastic process is defined\nby limit values of the complex logarithm of the characteristic function. The\npaper also outlines a numerical method for calculating stochastic extrema.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2008 17:35:40 GMT"}], "update_date": "2008-01-31", "authors_parsed": [["Nikitin", "S.", ""]]}]