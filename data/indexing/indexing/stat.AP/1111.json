[{"id": "1111.0317", "submitter": "Jared Murray", "authors": "Jared S. Murray, David B. Dunson, Lawrence Carin and Joseph E. Lucas", "title": "Bayesian Gaussian Copula Factor Models for Mixed Data", "comments": "To appear in JASA Theory & Methods. This revision corrects the\n  simulation study in the previous version (and adds another), adds new figures\n  and edits some of the previous figures, corrects some typographical errors\n  and has been edited for style and length", "journal-ref": null, "doi": "10.1080/01621459.2012.762328", "report-no": null, "categories": "stat.ME stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian factor models have proven widely useful for parsimoniously\ncharacterizing dependence in multivariate data. There is a rich literature on\ntheir extension to mixed categorical and continuous variables, using latent\nGaussian variables or through generalized latent trait models acommodating\nmeasurements in the exponential family. However, when generalizing to\nnon-Gaussian measured variables the latent variables typically influence both\nthe dependence structure and the form of the marginal distributions,\ncomplicating interpretation and introducing artifacts. To address this problem\nwe propose a novel class of Bayesian Gaussian copula factor models which\ndecouple the latent factors from the marginal distributions. A semiparametric\nspecification for the marginals based on the extended rank likelihood yields\nstraightforward implementation and substantial computational gains, critical\nfor scaling to high-dimensional applications. We provide new theoretical and\nempirical justifications for using this likelihood in Bayesian inference. We\npropose new default priors for the factor loadings and develop efficient\nparameter-expanded Gibbs sampling for posterior computation. The methods are\nevaluated through simulations and applied to a dataset in political science.\nThe methods in this paper are implemented in the R package bfa.\n", "versions": [{"version": "v1", "created": "Tue, 1 Nov 2011 21:06:48 GMT"}, {"version": "v2", "created": "Mon, 7 Jan 2013 18:45:49 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Murray", "Jared S.", ""], ["Dunson", "David B.", ""], ["Carin", "Lawrence", ""], ["Lucas", "Joseph E.", ""]]}, {"id": "1111.0349", "submitter": "Gail Potter", "authors": "Gail E. Potter and Niel Hens", "title": "A penalized likelihood approach to estimate within-household contact\n  networks from egocentric data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Acute infectious diseases are transmitted over networks of social contacts.\nEpidemic models are used to predict the spread of emergent pathogens and\ncompare intervention strategies. Many of these models assume equal probability\nof contact within mixing groups (homes, schools, etc.), but little work has\ninferred the actual contact network, which may influence epidemic estimates. We\ndevelop a penalized likelihood method to infer contact networks within\nhouseholds, a key area for disease transmission. Using egocentric surveys of\ncontact behavior in Belgium, we estimate within-household contact networks for\nsix different age compositions. Our estimates show dependency in contact\nbehavior and vary substantively by age composition, with fewer contacts\noccurring in older households. Our results are relevant for epidemic models\nused to make policy recommendations.\n", "versions": [{"version": "v1", "created": "Tue, 1 Nov 2011 23:54:35 GMT"}], "update_date": "2016-11-25", "authors_parsed": [["Potter", "Gail E.", ""], ["Hens", "Niel", ""]]}, {"id": "1111.0416", "submitter": "Deepak Agarwal", "authors": "Deepak Agarwal, Liang Zhang, Rahul Mazumder", "title": "Modeling item--item similarities for personalized recommendations on\n  Yahoo! front page", "comments": "Published in at http://dx.doi.org/10.1214/11-AOAS475 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2011, Vol. 5, No. 3, 1839-1875", "doi": "10.1214/11-AOAS475", "report-no": "IMS-AOAS-AOAS475", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of algorithmically recommending items to users on a\nYahoo! front page module. Our approach is based on a novel multilevel\nhierarchical model that we refer to as a User Profile Model with Graphical\nLasso (UPG). The UPG provides a personalized recommendation to users by\nsimultaneously incorporating both user covariates and historical user\ninteractions with items in a model based way. In fact, we build a per-item\nregression model based on a rich set of user covariates and estimate individual\nuser affinity to items by introducing a latent random vector for each user. The\nvector random effects are assumed to be drawn from a prior with a precision\nmatrix that measures residual partial associations among items. To ensure\nbetter estimates of a precision matrix in high-dimensions, the matrix elements\nare constrained through a Lasso penalty. Our model is fitted through a\npenalized-quasi likelihood procedure coupled with a scalable EM algorithm. We\nemploy several computational strategies like multi-threading, conjugate\ngradients and heavily exploit problem structure to scale our computations in\nthe E-step. For the M-step we take recourse to a scalable variant of the\nGraphical Lasso algorithm for covariance selection. Through extensive\nexperiments on a new data set obtained from Yahoo! front page and a benchmark\ndata set from a movie recommender application, we show that our UPG model\nsignificantly improves performance compared to several state-of-the-art methods\nin the literature, especially those based on a bilinear random effects model\n(BIRE). In particular, we show that the gains of UPG are significant compared\nto BIRE when the number of users is large and the number of items to select\nfrom is small. For large item sets and relatively small user sets the results\nof UPG and BIRE are comparable. The UPG leads to faster model building and\nproduces outputs which are interpretable.\n", "versions": [{"version": "v1", "created": "Wed, 2 Nov 2011 08:13:43 GMT"}], "update_date": "2011-11-03", "authors_parsed": [["Agarwal", "Deepak", ""], ["Zhang", "Liang", ""], ["Mazumder", "Rahul", ""]]}, {"id": "1111.0617", "submitter": "James Scott", "authors": "Zesong Liu and Jesse Windle and James G. Scott", "title": "The partition problem: case studies in Bayesian screening for\n  time-varying model structure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents two case studies of data sets where the main inferential\ngoal is to characterize time-varying patterns in model structure. Both of these\nexamples are seen to be general cases of the so-called \"partition problem,\"\nwhere auxiliary information (in this case, time) defines a partition over\nsample space, and where different models hold for each element of the\npartition. In the first case study, we identify time-varying graphical\nstructure in the covariance matrix of asset returns from major European equity\nindices from 2006--2010. This structure has important implications for\nquantifying the notion of financial contagion, a term often mentioned in the\ncontext of the European sovereign debt crisis of this period. In the second\ncase study, we screen a large database of historical corporate performance in\norder to identify specific firms with impressively good (or bad) streaks of\nperformance.\n", "versions": [{"version": "v1", "created": "Wed, 2 Nov 2011 19:28:51 GMT"}], "update_date": "2011-11-03", "authors_parsed": [["Liu", "Zesong", ""], ["Windle", "Jesse", ""], ["Scott", "James G.", ""]]}, {"id": "1111.0641", "submitter": "Daniel Simpson", "authors": "Daniel Simpson, Janine Illian, Finn Lindgren, Sigrunn S{\\o}rbye and\n  H{\\aa}vard Rue", "title": "Going off grid: Computationally efficient inference for log-Gaussian Cox\n  processes", "comments": "22 Pages, 8 figures", "journal-ref": null, "doi": null, "report-no": "NTNU Department of Mathematics Statistics Technical Report 9/2011", "categories": "stat.CO math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a new method for performing computational inference on\nlog-Gaussian Cox processes. The likelihood is approximated directly by making\nnovel use of a continuously specified Gaussian random field. We show that for\nsufficiently smooth Gaussian random field prior distributions, the\napproximation can converge with arbitrarily high order, while an approximation\nbased on a counting process on a partition of the domain only achieves\nfirst-order convergence. The given results improve on the general theory of\nconvergence of the stochastic partial differential equation models, introduced\nby Lindgren et al. (2011). The new method is demonstrated on a standard point\npattern data set and two interesting extensions to the classical log-Gaussian\nCox process framework are discussed. The first extension considers variable\nsampling effort throughout the observation window and implements the method of\nChakraborty et al. (2011). The second extension constructs a log-Gaussian Cox\nprocess on the world's oceans. The analysis is performed using integrated\nnested Laplace approximation for fast approximate inference.\n", "versions": [{"version": "v1", "created": "Tue, 1 Nov 2011 17:56:10 GMT"}, {"version": "v2", "created": "Mon, 2 Dec 2013 08:53:15 GMT"}, {"version": "v3", "created": "Fri, 30 Oct 2015 18:46:25 GMT"}], "update_date": "2015-11-02", "authors_parsed": [["Simpson", "Daniel", ""], ["Illian", "Janine", ""], ["Lindgren", "Finn", ""], ["S\u00f8rbye", "Sigrunn", ""], ["Rue", "H\u00e5vard", ""]]}, {"id": "1111.0911", "submitter": "Ann Lee", "authors": "Ann B. Lee and Peter E. Freeman", "title": "Exploiting Non-Linear Structure in Astronomical Data for Improved\n  Statistical Inference", "comments": "Invited talk at SCMA V, Penn State University, June 2011, PA. To\n  appear in the Proceedings of \"Statistical Challenges in Modern Astronomy V\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP astro-ph.IM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many estimation problems in astrophysics are highly complex, with\nhigh-dimensional, non-standard data objects (e.g., images, spectra, entire\ndistributions, etc.) that are not amenable to formal statistical analysis. To\nutilize such data and make accurate inferences, it is crucial to transform the\ndata into a simpler, reduced form. Spectral kernel methods are non-linear data\ntransformation methods that efficiently reveal the underlying geometry of\nobservable data. Here we focus on one particular technique: diffusion maps or\nmore generally spectral connectivity analysis (SCA). We give examples of\napplications in astronomy; e.g., photometric redshift estimation, prototype\nselection for estimation of star formation history, and supernova light curve\nclassification. We outline some computational and statistical challenges that\nremain, and we discuss some promising future directions for astronomy and data\nmining.\n", "versions": [{"version": "v1", "created": "Thu, 3 Nov 2011 16:52:52 GMT"}], "update_date": "2011-11-04", "authors_parsed": [["Lee", "Ann B.", ""], ["Freeman", "Peter E.", ""]]}, {"id": "1111.1210", "submitter": "Xiaoquan Wen", "authors": "Xiaoquan Wen, Matthew Stephens", "title": "Bayesian methods for genetic association analysis with heterogeneous\n  subgroups: From meta-analyses to gene-environment interactions", "comments": "Published in at http://dx.doi.org/10.1214/13-AOAS695 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2014, Vol. 8, No. 1, 176-203", "doi": "10.1214/13-AOAS695", "report-no": "IMS-AOAS-AOAS695", "categories": "stat.ME stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Genetic association analyses often involve data from multiple\npotentially-heterogeneous subgroups. The expected amount of heterogeneity can\nvary from modest (e.g., a typical meta-analysis) to large (e.g., a strong\ngene--environment interaction). However, existing statistical tools are limited\nin their ability to address such heterogeneity. Indeed, most genetic\nassociation meta-analyses use a \"fixed effects\" analysis, which assumes no\nheterogeneity. Here we develop and apply Bayesian association methods to\naddress this problem. These methods are easy to apply (in the simplest case,\nrequiring only a point estimate for the genetic effect and its standard error,\nfrom each subgroup) and effectively include standard frequentist meta-analysis\nmethods, including the usual \"fixed effects\" analysis, as special cases. We\napply these tools to two large genetic association studies: one a meta-analysis\nof genome-wide association studies from the Global Lipids consortium, and the\nsecond a cross-population analysis for expression quantitative trait loci\n(eQTLs). In the Global Lipids data we find, perhaps surprisingly, that effects\nare generally quite homogeneous across studies. In the eQTL study we find that\neQTLs are generally shared among different continental groups, and discuss\nconsequences of this for study design.\n", "versions": [{"version": "v1", "created": "Fri, 4 Nov 2011 18:48:43 GMT"}, {"version": "v2", "created": "Tue, 8 Nov 2011 13:22:28 GMT"}, {"version": "v3", "created": "Mon, 14 Apr 2014 13:42:20 GMT"}], "update_date": "2014-04-15", "authors_parsed": [["Wen", "Xiaoquan", ""], ["Stephens", "Matthew", ""]]}, {"id": "1111.1509", "submitter": "Corwin M. Zigler", "authors": "Corwin M. Zigler, Thomas R. Belin", "title": "The potential for bias in principal causal effect estimation when\n  treatment received depends on a key covariate", "comments": "Published in at http://dx.doi.org/10.1214/11-AOAS477 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2011, Vol. 5, No. 3, 1876-1892", "doi": "10.1214/11-AOAS477", "report-no": "IMS-AOAS-AOAS477", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by a potential-outcomes perspective, the idea of principal\nstratification has been widely recognized for its relevance in settings\nsusceptible to posttreatment selection bias such as randomized clinical trials\nwhere treatment received can differ from treatment assigned. In one such\nsetting, we address subtleties involved in inference for causal effects when\nusing a key covariate to predict membership in latent principal strata. We show\nthat when treatment received can differ from treatment assigned in both study\narms, incorporating a stratum-predictive covariate can make estimates of the\n\"complier average causal effect\" (CACE) derive from observations in the two\ntreatment arms with different covariate distributions. Adopting a Bayesian\nperspective and using Markov chain Monte Carlo for computation, we develop\nposterior checks that characterize the extent to which incorporating the\npretreatment covariate endangers estimation of the CACE. We apply the method to\nanalyze a clinical trial comparing two treatments for jaw fractures in which\nthe study protocol allowed surgeons to overrule both possible randomized\ntreatment assignments based on their clinical judgment and the data contained a\nkey covariate (injury severity) predictive of treatment received.\n", "versions": [{"version": "v1", "created": "Mon, 7 Nov 2011 09:04:51 GMT"}], "update_date": "2011-11-08", "authors_parsed": [["Zigler", "Corwin M.", ""], ["Belin", "Thomas R.", ""]]}, {"id": "1111.1714", "submitter": "Yakir Berchenko", "authors": "Yakir Berchenko, Richard G. White, Cyprian Wejnert, Simon D.W. Frost", "title": "Analysis of a capture-recapture estimator for the size of populations\n  with heterogenous catchability, and its evaluation on RDS data from rural\n  Uganda", "comments": "22 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP q-bio.QM stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider capture-recapture experiments with heterogenous\ncatchability. In the setting we consider, the widespread Huggins-Alho estimator\nis not very suitable and we introduce and study a new generalized\nHorvitz-Thompson estimator. Our motivation is Respondent Driven Sampling (RDS),\na prime example for such a setting where the capture probability is dependent\non both the unknown population size as well as on an observable covariate, the\nnetwork degree of an individual, due to peer recruitment. After discussing the\ntheoretical properties of the new estimator, with full details given in the\nappendix, we evaluate it on various empirical and simulated data-sets, focusing\non an RDS survey in a population in rural Uganda in which the population size\nis known a priori. The results thus obtained demonstrate that the adjusted\nestimator is less biased than the naive Lincoln-Petersen estimator.\n", "versions": [{"version": "v1", "created": "Mon, 7 Nov 2011 20:51:18 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Berchenko", "Yakir", ""], ["White", "Richard G.", ""], ["Wejnert", "Cyprian", ""], ["Frost", "Simon D. W.", ""]]}, {"id": "1111.1786", "submitter": "Alexis Akira Toda", "authors": "Alexis Akira Toda", "title": "Weak Limit of the Geometric Sum of Independent But Not Identically\n  Distributed Random Variables", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that when $\\set{X_j}$ is a sequence of independent (but not\nnecessarily identically distributed) random variables which satisfies a\ncondition similar to the Lindeberg condition, the properly normalized geometric\nsum $\\sum_{j=1}^{\\nu_p}X_j$ (where $\\nu_p$ is a geometric random variable with\nmean $1/p$) converges in distribution to a Laplace distribution as $p\\to 0$.\nThe same conclusion holds for the multivariate case. This theorem provides a\nreason for the ubiquity of the double power law in economic and financial data.\n", "versions": [{"version": "v1", "created": "Tue, 8 Nov 2011 03:11:49 GMT"}, {"version": "v2", "created": "Fri, 20 Jan 2012 18:52:43 GMT"}], "update_date": "2012-01-23", "authors_parsed": [["Toda", "Alexis Akira", ""]]}, {"id": "1111.1855", "submitter": "Jeremie Bigot", "authors": "J\\'er\\'emie Bigot (IMT)", "title": "Fr\\'echet means of curves for signal averaging and application to ECG\n  data analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Signal averaging is the process that consists in computing a mean shape from\na set of noisy signals. In the presence of geometric variability in time in the\ndata, the usual Euclidean mean of the raw data yields a mean pattern that does\nnot reflect the typical shape of the observed signals. In this setting, it is\nnecessary to use alignment techniques for a precise synchronization of the\nsignals, and then to average the aligned data to obtain a consistent mean\nshape. In this paper, we study the numerical performances of Fr\\'echet means of\ncurves which are extensions of the usual Euclidean mean to spaces endowed with\nnon-Euclidean metrics. This yields a new algorithm for signal averaging without\na reference template. We apply this approach to the estimation of a mean heart\ncycle from ECG records.\n", "versions": [{"version": "v1", "created": "Tue, 8 Nov 2011 10:23:15 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Bigot", "J\u00e9r\u00e9mie", "", "IMT"]]}, {"id": "1111.2260", "submitter": "Andres Christen", "authors": "Marcos A. Capistr\\'an and J. Andr\\'es Christen and Jorge X.\n  Velasco-Hern\\'andez", "title": "Towards Uncertainty Quantification and Inference in the stochastic SIR\n  Epidemic Model", "comments": "30 pages, 5 figures, submitted for peer review", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  In this paper we introduce a novel method to conduct inference with models\ndefined through a continuous-time Markov process, and we apply these results to\na classical stochastic SIR model as a case study. Using the inverse-size\nexpansion of van Kampen we obtain approximations for first and second moments\nfor the state variables. These approximate moments are in turn matched to the\nmoments of an inputed generic discrete distribution aimed at generating an\napproximate likelihood that is valid both for low count or high count data. We\nconduct a full Bayesian inference to estimate epidemic parameters using\ninformative priors. Excellent estimations and predictions are obtained both in\na synthetic data scenario and in two Dengue fever case studies.\n", "versions": [{"version": "v1", "created": "Wed, 9 Nov 2011 16:27:18 GMT"}], "update_date": "2011-11-10", "authors_parsed": [["Capistr\u00e1n", "Marcos A.", ""], ["Christen", "J. Andr\u00e9s", ""], ["Velasco-Hern\u00e1ndez", "Jorge X.", ""]]}, {"id": "1111.2411", "submitter": "Vasiliy Leonenko Mr", "authors": "Vasiliy Leonenko", "title": "An individual-based model of infection spread in an urban environment", "comments": "in Russian, 6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An individual-based model of the infectious disease spread among the urban\npopulation is considered. A system of stochastic equations, which describes\nchanges in quantities of four population groups, susceptible, exposed, infected\nindividuals and individuals in the state of remission, is built. The system of\nequations of the model is supplemented with correlations, which consider\ndisease heaviness and duration for every infected individual. An algorithm and\na modelling program based on Monte-Carlo methods which allows to investigate\nthe group number dynamics is developed.\n", "versions": [{"version": "v1", "created": "Thu, 10 Nov 2011 08:05:15 GMT"}], "update_date": "2011-11-11", "authors_parsed": [["Leonenko", "Vasiliy", ""]]}, {"id": "1111.2730", "submitter": "Aleksandr Aravkin", "authors": "Aleksandr Y. Aravkin, James V. Burke, Gianluigi Pillonetto", "title": "A statistical and computational theory for robust and sparse Kalman\n  smoothing", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC math.ST stat.AP stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kalman smoothers reconstruct the state of a dynamical system starting from\nnoisy output samples. While the classical estimator relies on quadratic\npenalization of process deviations and measurement errors, extensions that\nexploit Piecewise Linear Quadratic (PLQ) penalties have been recently proposed\nin the literature. These new formulations include smoothers robust with respect\nto outliers in the data, and smoothers that keep better track of fast system\ndynamics, e.g. jumps in the state values. In addition to L2, well known\nexamples of PLQ penalties include the L1, Huber and Vapnik losses. In this\npaper, we use a dual representation for PLQ penalties to build a statistical\nmodeling framework and a computational theory for Kalman smoothing.\n  We develop a statistical framework by establishing conditions required to\ninterpret PLQ penalties as negative logs of true probability densities. Then,\nwe present a computational framework, based on interior-point methods, that\nsolves the Kalman smoothing problem with PLQ penalties and maintains the linear\ncomplexity in the size of the time series, just as in the L2 case. The\nframework presented extends the computational efficiency of the Mayne-Fraser\nand Rauch-Tung-Striebel algorithms to a much broader non-smooth setting, and\nincludes many known robust and sparse smoothers as special cases.\n", "versions": [{"version": "v1", "created": "Fri, 11 Nov 2011 13:06:55 GMT"}], "update_date": "2011-11-14", "authors_parsed": [["Aravkin", "Aleksandr Y.", ""], ["Burke", "James V.", ""], ["Pillonetto", "Gianluigi", ""]]}, {"id": "1111.3149", "submitter": "Jerome Bobin", "authors": "J. Bobin, J.-L. Starck, F. Sureau, J. Fadili", "title": "CMB map restoration", "comments": null, "journal-ref": null, "doi": "10.1155/2012/703217", "report-no": null, "categories": "astro-ph.CO stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating the cosmological microwave background is of utmost importance for\ncosmology. However, its estimation from full-sky surveys such as WMAP or more\nrecently Planck is challenging: CMB maps are generally estimated via the\napplication of some source separation techniques which never prevent the final\nmap from being contaminated with noise and foreground residuals. These spurious\ncontaminations whether noise or foreground residuals are well-known to be a\nplague for most cosmologically relevant tests or evaluations; this includes CMB\nlensing reconstruction or non-Gaussian signatures search. Noise reduction is\ngenerally performed by applying a simple Wiener filter in spherical harmonics;\nhowever this does not account for the non-stationarity of the noise. Foreground\ncontamination is usually tackled by masking the most intense residuals detected\nin the map, which makes CMB evaluation harder to perform. In this paper, we\nintroduce a novel noise reduction framework coined LIW-Filtering for Linear\nIterative Wavelet Filtering which is able to account for the noise spatial\nvariability thanks to a wavelet-based modeling while keeping the highly desired\nlinearity of the Wiener filter. We further show that the same filtering\ntechnique can effectively perform foreground contamination reduction thus\nproviding a globally cleaner CMB map. Numerical results on simulated but\nrealistic Planck data are provided.\n", "versions": [{"version": "v1", "created": "Mon, 14 Nov 2011 09:25:44 GMT"}], "update_date": "2015-06-03", "authors_parsed": [["Bobin", "J.", ""], ["Starck", "J. -L.", ""], ["Sureau", "F.", ""], ["Fadili", "J.", ""]]}, {"id": "1111.3387", "submitter": "Andr\\'as L\\'aszl\\'o", "authors": "Andras Laszlo", "title": "A Linear Iterative Unfolding Method", "comments": "Proceedings of ACAT-2011 conference (Uxbridge, United Kingdom), 9\n  pages, 5 figures, changes of corrigendum included", "journal-ref": "JPCS 368 (2012) 012043", "doi": "10.1088/1742-6596/368/1/012043", "report-no": null, "categories": "math.ST physics.data-an stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A frequently faced task in experimental physics is to measure the probability\ndistribution of some quantity. Often this quantity to be measured is smeared by\na non-ideal detector response or by some physical process. The procedure of\nremoving this smearing effect from the measured distribution is called\nunfolding, and is a delicate problem in signal processing, due to the\nwell-known numerical ill behavior of this task. Various methods were invented\nwhich, given some assumptions on the initial probability distribution, try to\nregularize the unfolding problem. Most of these methods definitely introduce\nbias into the estimate of the initial probability distribution. We propose a\nlinear iterative method, which has the advantage that no assumptions on the\ninitial probability distribution is needed, and the only regularization\nparameter is the stopping order of the iteration, which can be used to choose\nthe best compromise between the introduced bias and the propagated statistical\nand systematic errors. The method is consistent: \"binwise\" convergence to the\ninitial probability distribution is proved in absence of measurement errors\nunder a quite general condition on the response function. This condition holds\nfor practical applications such as convolutions, calorimeter response\nfunctions, momentum reconstruction response functions based on tracking in\nmagnetic field etc. In presence of measurement errors, explicit formulae for\nthe propagation of the three important error terms is provided: bias error,\nstatistical error, and systematic error. A trade-off between these three error\nterms can be used to define an optimal iteration stopping criterion, and the\nerrors can be estimated there. We provide a numerical C library for the\nimplementation of the method, which incorporates automatic statistical error\npropagation as well.\n", "versions": [{"version": "v1", "created": "Mon, 14 Nov 2011 23:04:19 GMT"}, {"version": "v2", "created": "Wed, 4 Jul 2012 19:55:44 GMT"}, {"version": "v3", "created": "Sun, 6 Apr 2014 19:57:12 GMT"}], "update_date": "2014-04-11", "authors_parsed": [["Laszlo", "Andras", ""]]}, {"id": "1111.4100", "submitter": "Kyle Johnston", "authors": "Kyle B. Johnston, Terry D. Oswalt, and David Valls-Gabaud", "title": "Orbital Separation Amplification in Fragile Binaries with Evolved\n  Components", "comments": "37 pages, 13 figures", "journal-ref": "New Astro. 17 (2011) 458-468", "doi": "10.1016/j.newast.2011.11.004", "report-no": null, "categories": "astro-ph.SR stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The secular stellar mass-loss causes an amplification of the orbital\nseparation in fragile, common proper motion, binary systems with separations of\nthe order of 1000 A.U. In these systems, companions evolve as two independent\ncoeval stars as they experience negligible mutual tidal interactions or mass\ntransfer. We present models for how post-main sequence mass-loss statistically\ndistorts the frequency distribution of separations in fragile binaries. These\nmodels demonstrate the expected increase in orbital seapration resulting from\nstellar mass-loss, as well as a perturbation of associated orbital parameters.\nComparisons between our models and observations resulting from the Luyten\nsurvey of wide visual binaries, specifically those containing MS and\nwhite-dwarf pairs, demonstrate a good agreement between the calculated and the\nobserved angular separation distribution functions.\n", "versions": [{"version": "v1", "created": "Thu, 17 Nov 2011 14:06:34 GMT"}, {"version": "v2", "created": "Tue, 22 Nov 2011 19:09:52 GMT"}], "update_date": "2012-03-26", "authors_parsed": [["Johnston", "Kyle B.", ""], ["Oswalt", "Terry D.", ""], ["Valls-Gabaud", "David", ""]]}, {"id": "1111.4157", "submitter": "Tuhin Sahai", "authors": "Tuhin Sahai and Jose Miguel Pasini", "title": "Uncertainty Quantification in Hybrid Dynamical Systems", "comments": null, "journal-ref": "Journal of Computational Physics, vol. 237, pp. 411-427 (2013)", "doi": "10.1016/j.jcp.2012.10.030", "report-no": null, "categories": "stat.CO math.DS stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uncertainty quantification (UQ) techniques are frequently used to ascertain\noutput variability in systems with parametric uncertainty. Traditional\nalgorithms for UQ are either system-agnostic and slow (such as Monte Carlo) or\nfast with stringent assumptions on smoothness (such as polynomial chaos and\nQuasi-Monte Carlo). In this work, we develop a fast UQ approach for hybrid\ndynamical systems by extending the polynomial chaos methodology to these\nsystems. To capture discontinuities, we use a wavelet-based Wiener-Haar\nexpansion. We develop a boundary layer approach to propagate uncertainty\nthrough separable reset conditions. We also introduce a transport theory based\napproach for propagating uncertainty through hybrid dynamical systems. Here the\nexpansion yields a set of hyperbolic equations that are solved by integrating\nalong characteristics. The solution of the partial differential equation along\nthe characteristics allows one to quantify uncertainty in hybrid or switching\ndynamical systems. The above methods are demonstrated on example problems.\n", "versions": [{"version": "v1", "created": "Thu, 17 Nov 2011 17:20:29 GMT"}, {"version": "v2", "created": "Sun, 7 Oct 2012 17:14:50 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Sahai", "Tuhin", ""], ["Pasini", "Jose Miguel", ""]]}, {"id": "1111.4639", "submitter": "Leo Lahti", "authors": "Leo Lahti, Martin Sch\\\"afer, Hans-Ulrich Klein, Silvio Bicciato, and\n  Martin Dugas", "title": "Cancer gene prioritization by integrative analysis of mRNA expression\n  and DNA copy number data: a comparative review", "comments": "PDF file including supplementary material. 9 pages. Preprint", "journal-ref": null, "doi": "10.1093/bib/bbs005", "report-no": null, "categories": "cs.CE q-bio.GN stat.AP stat.ME", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  A variety of genome-wide profiling techniques are available to probe\ncomplementary aspects of genome structure and function. Integrative analysis of\nheterogeneous data sources can reveal higher-level interactions that cannot be\ndetected based on individual observations. A standard integration task in\ncancer studies is to identify altered genomic regions that induce changes in\nthe expression of the associated genes based on joint analysis of genome-wide\ngene expression and copy number profiling measurements. In this review, we\nprovide a comparison among various modeling procedures for integrating\ngenome-wide profiling data of gene copy number and transcriptional alterations\nand highlight common approaches to genomic data integration. A transparent\nbenchmarking procedure is introduced to quantitatively compare the cancer gene\nprioritization performance of the alternative methods. The benchmarking\nalgorithms and data sets are available at http://intcomp.r-forge.r-project.org\n", "versions": [{"version": "v1", "created": "Sun, 20 Nov 2011 15:23:09 GMT"}], "update_date": "2012-03-23", "authors_parsed": [["Lahti", "Leo", ""], ["Sch\u00e4fer", "Martin", ""], ["Klein", "Hans-Ulrich", ""], ["Bicciato", "Silvio", ""], ["Dugas", "Martin", ""]]}, {"id": "1111.4721", "submitter": "Timothy Randolph", "authors": "Thomas I. Milac, Timothy W. Randolph, Pei Wang", "title": "Analyzing LC-MS/MS data by spectral count and ion abundance: two case\n  studies", "comments": "12 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In comparative proteomics studies, LC-MS/MS data is generally quantified\nusing one or both of two measures: the spectral count, derived from the\nidentification of MS/MS spectra, or some measure of ion abundance derived from\nthe LC-MS data. Here we contrast the performance of these measures and show\nthat ion abundance is the more sensitive. We also examine how the conclusions\nof a comparative analysis are influenced by the manner in which the LC-MS/MS\ndata is `rolled up' to the protein level, and show that divergent conclusions\nobtained using different rollups can be informative. Our analysis is based on\ntwo publicly available reference data sets, BIATECH-54 and CPTAC, which were\ndeveloped for the purpose of assessing methods used in label-free differential\nproteomic studies. We find that the use of the ion abundance measure reveals\nproperties of both data sets not readily apparent using the spectral count.\n", "versions": [{"version": "v1", "created": "Mon, 21 Nov 2011 03:04:51 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Milac", "Thomas I.", ""], ["Randolph", "Timothy W.", ""], ["Wang", "Pei", ""]]}, {"id": "1111.4787", "submitter": "Martin Rypdal", "authors": "Martin Rypdal and Kristoffer Rypdal", "title": "Is there long-range memory in solar activity on time scales shorter than\n  the sunspot period?", "comments": "23 pages, 12 figures", "journal-ref": null, "doi": "10.1029/2011JA017283", "report-no": null, "categories": "physics.space-ph astro-ph.SR stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The sunspot number (SSN), the total solar irradiance (TSI), a TSI\nreconstruction, and the solar flare index (SFI), are analyzed for long-range\npersistence (LRP). Standard Hurst analysis yields $H \\approx 0.9$, which\nsuggests strong LRP. However, solar activity time series are non-stationary due\nto the almost periodic 11 year smooth component, and the analysis does not give\nthe correct $H$ for the stochastic component. Better estimates are obtained by\ndetrended fluctuations analysis (DFA), but estimates are biased and errors are\nlarge due to the short time records. These time series can be modeled as a\nstochastic process of the form $x(t)=y(t)+\\sigma \\sqrt{y(t)}\\, w_H(t)$, where\n$y(t)$ is the smooth component, and $w_H(t) $ is a stationary fractional noise\nwith Hurst exponent $H$. From ensembles of numerical solutions to the\nstochastic model, and application of Bayes' theorem, we can obtain bias and\nerror bars on $H$ and also a test of the hypothesis that a process is\nuncorrelated ($H=1/2$). The conclusions from the present data sets are that\nSSN, TSI and TSI reconstruction almost certainly are long-range persistent, but\nwith most probable value $H\\approx 0.7$. The SFI process, however, is either\nvery weakly persistent ($H<0.6$) or completely uncorrelated. Some differences\nbetween stochastic properties of the TSI and its reconstruction indicate some\nerror in the reconstruction scheme.\n", "versions": [{"version": "v1", "created": "Mon, 21 Nov 2011 08:40:23 GMT"}], "update_date": "2015-06-03", "authors_parsed": [["Rypdal", "Martin", ""], ["Rypdal", "Kristoffer", ""]]}, {"id": "1111.4942", "submitter": "Luca Martino", "authors": "Luca Martino and Joaqu\\'in M\\'iguez", "title": "Two adaptive rejection sampling schemes for probability density\n  functions log-convex tails", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monte Carlo methods are often necessary for the implementation of optimal\nBayesian estimators. A fundamental technique that can be used to generate\nsamples from virtually any target probability distribution is the so-called\nrejection sampling method, which generates candidate samples from a proposal\ndistribution and then accepts them or not by testing the ratio of the target\nand proposal densities. The class of adaptive rejection sampling (ARS)\nalgorithms is particularly interesting because they can achieve high acceptance\nrates. However, the standard ARS method can only be used with log-concave\ntarget densities. For this reason, many generalizations have been proposed.\n  In this work, we investigate two different adaptive schemes that can be used\nto draw exactly from a large family of univariate probability density functions\n(pdf's), not necessarily log-concave, possibly multimodal and with tails of\narbitrary concavity. These techniques are adaptive in the sense that every time\na candidate sample is rejected, the acceptance rate is improved. The two\nproposed algorithms can work properly when the target pdf is multimodal, with\nfirst and second derivatives analytically intractable, and when the tails are\nlog-convex in a infinite domain. Therefore, they can be applied in a number of\nscenarios in which the other generalizations of the standard ARS fail. Two\nillustrative numerical examples are shown.\n", "versions": [{"version": "v1", "created": "Mon, 21 Nov 2011 17:24:21 GMT"}], "update_date": "2011-11-22", "authors_parsed": [["Martino", "Luca", ""], ["M\u00edguez", "Joaqu\u00edn", ""]]}, {"id": "1111.5028", "submitter": "Shuang Li", "authors": "Shuang Li, Li Hsu, Jie Peng, Pei Wang", "title": "Bootstrap inference for network construction with an application to a\n  breast cancer microarray study", "comments": "Published in at http://dx.doi.org/10.1214/12-AOAS589 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2013, Vol. 7, No. 1, 391-417", "doi": "10.1214/12-AOAS589", "report-no": "IMS-AOAS-AOAS589", "categories": "stat.ME stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian Graphical Models (GGMs) have been used to construct genetic\nregulatory networks where regularization techniques are widely used since the\nnetwork inference usually falls into a high-dimension-low-sample-size scenario.\nYet, finding the right amount of regularization can be challenging, especially\nin an unsupervised setting where traditional methods such as BIC or\ncross-validation often do not work well. In this paper, we propose a new method\n- Bootstrap Inference for Network COnstruction (BINCO) - to infer networks by\ndirectly controlling the false discovery rates (FDRs) of the selected edges.\nThis method fits a mixture model for the distribution of edge selection\nfrequencies to estimate the FDRs, where the selection frequencies are\ncalculated via model aggregation. This method is applicable to a wide range of\napplications beyond network construction. When we applied our proposed method\nto building a gene regulatory network with microarray expression breast cancer\ndata, we were able to identify high-confidence edges and well-connected hub\ngenes that could potentially play important roles in understanding the\nunderlying biological processes of breast cancer.\n", "versions": [{"version": "v1", "created": "Mon, 21 Nov 2011 21:11:21 GMT"}, {"version": "v2", "created": "Tue, 23 Apr 2013 12:34:50 GMT"}], "update_date": "2013-04-24", "authors_parsed": [["Li", "Shuang", ""], ["Hsu", "Li", ""], ["Peng", "Jie", ""], ["Wang", "Pei", ""]]}, {"id": "1111.5046", "submitter": "Yasin Yilmaz", "authors": "Yasin Yilmaz, George Moustakides, Xiaodong Wang", "title": "Cooperative Sequential Spectrum Sensing Based on Level-triggered\n  Sampling", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2012.2202657", "report-no": null, "categories": "stat.AP cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new framework for cooperative spectrum sensing in cognitive\nradio networks, that is based on a novel class of non-uniform samplers, called\nthe event-triggered samplers, and sequential detection. In the proposed scheme,\neach secondary user computes its local sensing decision statistic based on its\nown channel output; and whenever such decision statistic crosses certain\npredefined threshold values, the secondary user will send one (or several) bit\nof information to the fusion center. The fusion center asynchronously receives\nthe bits from different secondary users and updates the global sensing decision\nstatistic to perform a sequential probability ratio test (SPRT), to reach a\nsensing decision. We provide an asymptotic analysis for the above scheme, and\nunder different conditions, we compare it against the cooperative sensing\nscheme that is based on traditional uniform sampling and sequential detection.\nSimulation results show that the proposed scheme, using even 1 bit, can\noutperform its uniform sampling counterpart that uses infinite number of bits\nunder changing target error probabilities, SNR values, and number of SUs.\n", "versions": [{"version": "v1", "created": "Mon, 21 Nov 2011 22:11:51 GMT"}, {"version": "v2", "created": "Mon, 5 Mar 2012 02:49:30 GMT"}, {"version": "v3", "created": "Wed, 16 May 2012 15:34:31 GMT"}], "update_date": "2015-06-03", "authors_parsed": [["Yilmaz", "Yasin", ""], ["Moustakides", "George", ""], ["Wang", "Xiaodong", ""]]}, {"id": "1111.5110", "submitter": "Ting Yan", "authors": "Ting Yan, Jinfeng Xu and Yaning Yang", "title": "Grouped sparse paired comparisons in the Bradley-Terry model", "comments": "This paper has been withdrawn by the author due to that it needs to\n  be revised greatly", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.OT math.ST stat.AP stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a wide class of paired comparisons, especially in the sports games, in\nwhich all subjects are divided into several groups, the intragroup comparisons\nare dense and the intergroup comparisons are sparse. Typical examples include\nthe NFL regular season. Motivated by these situations, we propose group\nsparsity for paired comparisons and show the consistency and asymptotical\nnormality of the maximum likelihood estimate in the Bradley-Terry model when\nthe number of parameters goes to infinity in this paper. Simulations are\ncarried out to illustrate the group sparsity and asymptotical results.\n", "versions": [{"version": "v1", "created": "Tue, 22 Nov 2011 06:12:16 GMT"}, {"version": "v2", "created": "Wed, 16 May 2012 08:30:16 GMT"}, {"version": "v3", "created": "Fri, 8 Jun 2012 10:46:55 GMT"}], "update_date": "2012-06-11", "authors_parsed": [["Yan", "Ting", ""], ["Xu", "Jinfeng", ""], ["Yang", "Yaning", ""]]}, {"id": "1111.5145", "submitter": "O. Stenzel", "authors": "O. Stenzel, V. Schmidt, H. Hassfeld, R. Thiedmann, L. J. A. Koster, S.\n  D. Oosterhout, S. S. van Bavel, M. M. Wienk, J. Loos, R. A. J. Janssen", "title": "Spatial modeling of the 3D morphology of hybrid polymer-ZnO solar cells,\n  based on electron tomography data", "comments": "Published in at http://dx.doi.org/10.1214/11-AOAS468 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2011, Vol. 5, No. 3, 1920-1947", "doi": "10.1214/11-AOAS468", "report-no": "IMS-AOAS-AOAS468", "categories": "stat.AP cond-mat.mtrl-sci cond-mat.soft", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A spatial stochastic model is developed which describes the 3D nanomorphology\nof composite materials, being blends of two different (organic and inorganic)\nsolid phases. Such materials are used, for example, in photoactive layers of\nhybrid polymer zinc oxide solar cells. The model is based on ideas from\nstochastic geometry and spatial statistics. Its parameters are fitted to image\ndata gained by electron tomography (ET), where adaptive thresholding and\nstochastic segmentation have been used to represent morphological features of\nthe considered ET data by unions of overlapping spheres. Their midpoints are\nmodeled by a stack of 2D point processes with a suitably chosen correlation\nstructure, whereas a moving-average procedure is used to add the radii of\nspheres. The model is validated by comparing physically relevant\ncharacteristics of real and simulated data, like the efficiency of exciton\nquenching, which is important for the generation of charges and their transport\ntoward the electrodes.\n", "versions": [{"version": "v1", "created": "Tue, 22 Nov 2011 10:12:47 GMT"}], "update_date": "2011-11-23", "authors_parsed": [["Stenzel", "O.", ""], ["Schmidt", "V.", ""], ["Hassfeld", "H.", ""], ["Thiedmann", "R.", ""], ["Koster", "L. J. A.", ""], ["Oosterhout", "S. D.", ""], ["van Bavel", "S. S.", ""], ["Wienk", "M. M.", ""], ["Loos", "J.", ""], ["Janssen", "R. A. J.", ""]]}, {"id": "1111.5419", "submitter": "Francesco C. Stingo", "authors": "Francesco C. Stingo, Yian A. Chen, Mahlet G. Tadesse, Marina Vannucci", "title": "Incorporating biological information into linear models: A Bayesian\n  approach to the selection of pathways and genes", "comments": "Published in at http://dx.doi.org/10.1214/11-AOAS463 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2011, Vol. 5, No. 3, 1978-2002", "doi": "10.1214/11-AOAS463", "report-no": "IMS-AOAS-AOAS463", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The vast amount of biological knowledge accumulated over the years has\nallowed researchers to identify various biochemical interactions and define\ndifferent families of pathways. There is an increased interest in identifying\npathways and pathway elements involved in particular biological processes. Drug\ndiscovery efforts, for example, are focused on identifying biomarkers as well\nas pathways related to a disease. We propose a Bayesian model that addresses\nthis question by incorporating information on pathways and gene networks in the\nanalysis of DNA microarray data. Such information is used to define pathway\nsummaries, specify prior distributions, and structure the MCMC moves to fit the\nmodel. We illustrate the method with an application to gene expression data\nwith censored survival outcomes. In addition to identifying markers that would\nhave been missed otherwise and improving prediction accuracy, the integration\nof existing biological knowledge into the analysis provides a better\nunderstanding of underlying molecular processes.\n", "versions": [{"version": "v1", "created": "Wed, 23 Nov 2011 07:12:46 GMT"}], "update_date": "2011-11-24", "authors_parsed": [["Stingo", "Francesco C.", ""], ["Chen", "Yian A.", ""], ["Tadesse", "Mahlet G.", ""], ["Vannucci", "Marina", ""]]}, {"id": "1111.5429", "submitter": "Qi Long", "authors": "Qi Long, Matthias Chung, Carlos S. Moreno, Brent A. Johnson", "title": "Risk prediction for prostate cancer recurrence through regularized\n  estimation with simultaneous adjustment for nonlinear clinical effects", "comments": "Published in at http://dx.doi.org/10.1214/11-AOAS458 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2011, Vol. 5, No. 3, 2003-2023", "doi": "10.1214/11-AOAS458", "report-no": "IMS-AOAS-AOAS458", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In biomedical studies it is of substantial interest to develop risk\nprediction scores using high-dimensional data such as gene expression data for\nclinical endpoints that are subject to censoring. In the presence of\nwell-established clinical risk factors, investigators often prefer a procedure\nthat also adjusts for these clinical variables. While accelerated failure time\n(AFT) models are a useful tool for the analysis of censored outcome data, it\nassumes that covariate effects on the logarithm of time-to-event are linear,\nwhich is often unrealistic in practice. We propose to build risk prediction\nscores through regularized rank estimation in partly linear AFT models, where\nhigh-dimensional data such as gene expression data are modeled linearly and\nimportant clinical variables are modeled nonlinearly using penalized regression\nsplines. We show through simulation studies that our model has better operating\ncharacteristics compared to several existing models. In particular, we show\nthat there is a nonnegligible effect on prediction as well as feature selection\nwhen nonlinear clinical effects are misspecified as linear. This work is\nmotivated by a recent prostate cancer study, where investigators collected gene\nexpression data along with established prognostic clinical variables and the\nprimary endpoint is time to prostate cancer recurrence.\n", "versions": [{"version": "v1", "created": "Wed, 23 Nov 2011 08:42:59 GMT"}], "update_date": "2011-11-24", "authors_parsed": [["Long", "Qi", ""], ["Chung", "Matthias", ""], ["Moreno", "Carlos S.", ""], ["Johnson", "Brent A.", ""]]}, {"id": "1111.5487", "submitter": "Zeny Feng", "authors": "Zeny Feng, William W. L. Wong, Xin Gao, Flavio Schenkel", "title": "Generalized genetic association study with samples of related\n  individuals", "comments": "Published in at http://dx.doi.org/10.1214/11-AOAS465 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2011, Vol. 5, No. 3, 2109-2130", "doi": "10.1214/11-AOAS465", "report-no": "IMS-AOAS-AOAS465", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Genetic association study is an essential step to discover genetic factors\nthat are associated with a complex trait of interest. In this paper we present\na novel generalized quasi-likelihood score (GQLS) test that is suitable for a\nstudy with either a quantitative trait or a binary trait. We use a logistic\nregression model to link the phenotypic value of the trait to the distribution\nof allelic frequencies. In our model, the allele frequencies are treated as a\nresponse and the trait is treated as a covariate that allows us to leave the\ndistribution of the trait values unspecified. Simulation studies indicate that\nour method is generally more powerful in comparison with the family-based\nassociation test (FBAT) and controls the type I error at the desired levels. We\napply our method to analyze data on Holstein cattle for an estimated breeding\nvalue phenotype, and to analyze data from the Collaborative Study of the\nGenetics of Alcoholism for alcohol dependence. The results show a good portion\nof significant SNPs and regions consistent with previous reports in the\nliterature, and also reveal new significant SNPs and regions that are\nassociated with the complex trait of interest.\n", "versions": [{"version": "v1", "created": "Wed, 23 Nov 2011 13:31:39 GMT"}], "update_date": "2011-11-24", "authors_parsed": [["Feng", "Zeny", ""], ["Wong", "William W. L.", ""], ["Gao", "Xin", ""], ["Schenkel", "Flavio", ""]]}, {"id": "1111.5551", "submitter": "Bin Zhu", "authors": "Bin Zhu, Allison E. Ashley-Koch, and David B. Dunson", "title": "Generalized Admixture Mapping for Complex Traits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Admixture mapping is a popular tool to identify regions of the genome\nassociated with traits in a recently admixed population. Existing methods have\nbeen developed primarily for identification of a single locus influencing a\ndichotomous trait within a case-control study design. We propose a generalized\nadmixture mapping (GLEAM) approach, a flexible and powerful regression method\nfor both quantitative and qualitative traits, which is able to test for\nassociation between the trait and local ancestries in multiple loci\nsimultaneously and adjust for covariates. The new method is based on the\ngeneralized linear model and utilizes a quadratic normal moment prior to\nincorporate admixture prior information. Through simulation, we demonstrate\nthat GLEAM achieves lower type I error rate and higher power than existing\nmethods both for qualitative traits and more significantly for quantitative\ntraits. We applied GLEAM to genome-wide SNP data from the Illumina African\nAmerican panel derived from a cohort of black woman participating in the\nHealthy Pregnancy, Healthy Baby study and identified a locus on chromosome 2\nassociated with the averaged maternal mean arterial pressure during 24 to 28\nweeks of pregnancy.\n", "versions": [{"version": "v1", "created": "Wed, 23 Nov 2011 16:55:53 GMT"}], "update_date": "2011-11-24", "authors_parsed": [["Zhu", "Bin", ""], ["Ashley-Koch", "Allison E.", ""], ["Dunson", "David B.", ""]]}, {"id": "1111.5563", "submitter": "Bin Zhu", "authors": "Bin Zhu, David B. Dunson, Allison E. Ashley-Koch", "title": "Adverse Subpopulation Regression for Multivariate Outcomes with\n  High-Dimensional Predictors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Biomedical studies have a common interest in assessing relationships between\nmultiple related health outcomes and high-dimensional predictors. For example,\nin reproductive epidemiology, one may collect pregnancy outcomes such as length\nof gestation and birth weight and predictors such as single nucleotide\npolymorphisms in multiple candidate genes and environmental exposures. In such\nsettings, there is a need for simple yet flexible methods for selecting true\npredictors of adverse health responses from a high-dimensional set of candidate\npredictors. To address this problem, one may either consider linear regression\nmodels for the continuous outcomes or convert these outcomes into binary\nindicators of adverse responses using pre-defined cutoffs. The former strategy\nhas the disadvantage of often leading to a poorly fitting model that does not\npredict risk well, while the latter approach can be very sensitive to the\ncutoff choice. As a simple yet flexible alternative, we propose a method for\nadverse subpopulation regression (ASPR), which relies on a two component latent\nclass model, with the dominant component corresponding to (presumed) healthy\nindividuals and the risk of falling in the minority component characterized via\na logistic regression. The logistic regression model is designed to accommodate\nhigh-dimensional predictors, as occur in studies with a large number of gene by\nenvironment interactions, through use of a flexible nonparametric multiple\nshrinkage approach. The Gibbs sampler is developed for posterior computation.\nThe methods are evaluated using simulation studies and applied to a genetic\nepidemiology study of pregnancy outcomes.\n", "versions": [{"version": "v1", "created": "Wed, 23 Nov 2011 17:30:34 GMT"}], "update_date": "2011-11-24", "authors_parsed": [["Zhu", "Bin", ""], ["Dunson", "David B.", ""], ["Ashley-Koch", "Allison E.", ""]]}, {"id": "1111.5972", "submitter": "Yu Zhang", "authors": "Yu Zhang, Jing Zhang, Jun S. Liu", "title": "Block-based Bayesian epistasis association mapping with application to\n  WTCCC type 1 diabetes data", "comments": "Published in at http://dx.doi.org/10.1214/11-AOAS469 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2011, Vol. 5, No. 3, 2052-2077", "doi": "10.1214/11-AOAS469", "report-no": "IMS-AOAS-AOAS469", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interactions among multiple genes across the genome may contribute to the\nrisks of many complex human diseases. Whole-genome single nucleotide\npolymorphisms (SNPs) data collected for many thousands of SNP markers from\nthousands of individuals under the case--control design promise to shed light\non our understanding of such interactions. However, nearby SNPs are highly\ncorrelated due to linkage disequilibrium (LD) and the number of possible\ninteractions is too large for exhaustive evaluation. We propose a novel\nBayesian method for simultaneously partitioning SNPs into LD-blocks and\nselecting SNPs within blocks that are associated with the disease, either\nindividually or interactively with other SNPs. When applied to homogeneous\npopulation data, the method gives posterior probabilities for LD-block\nboundaries, which not only result in accurate block partitions of SNPs, but\nalso provide measures of partition uncertainty. When applied to case--control\ndata for association mapping, the method implicitly filters out SNP\nassociations created merely by LD with disease loci within the same blocks.\nSimulation study showed that this approach is more powerful in detecting\nmulti-locus associations than other methods we tested, including one of ours.\nWhen applied to the WTCCC type 1 diabetes data, the method identified many\npreviously known T1D associated genes, including PTPN22, CTLA4, MHC, and IL2RA.\n", "versions": [{"version": "v1", "created": "Fri, 25 Nov 2011 13:00:28 GMT"}], "update_date": "2011-11-28", "authors_parsed": [["Zhang", "Yu", ""], ["Zhang", "Jing", ""], ["Liu", "Jun S.", ""]]}, {"id": "1111.5993", "submitter": "Gail E. Potter", "authors": "Gail E. Potter, Mark S. Handcock, Ira M. Longini, Jr., M. Elizabeth\n  Halloran", "title": "Estimating within-household contact networks from egocentric data", "comments": "Published in at http://dx.doi.org/10.1214/11-AOAS474 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2011, Vol. 5, No. 3, 1816-1838", "doi": "10.1214/11-AOAS474", "report-no": "IMS-AOAS-AOAS474", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Acute respiratory diseases are transmitted over networks of social contacts.\nLarge-scale simulation models are used to predict epidemic dynamics and\nevaluate the impact of various interventions, but the contact behavior in these\nmodels is based on simplistic and strong assumptions which are not informed by\nsurvey data. These assumptions are also used for estimating transmission\nmeasures such as the basic reproductive number and secondary attack rates.\nDevelopment of methodology to infer contact networks from survey data could\nimprove these models and estimation methods. We contribute to this area by\ndeveloping a model of within-household social contacts and using it to analyze\nthe Belgian POLYMOD data set, which contains detailed diaries of social\ncontacts in a 24-hour period. We model dependency in contact behavior through a\nlatent variable indicating which household members are at home. We estimate\nage-specific probabilities of being at home and age-specific probabilities of\ncontact conditional on two members being at home. Our results differ from the\nstandard random mixing assumption. In addition, we find that the probability\nthat all members contact each other on a given day is fairly low: 0.49 for\nhouseholds with two 0--5 year olds and two 19--35 year olds, and 0.36 for\nhouseholds with two 12--18 year olds and two 36+ year olds. We find higher\ncontact rates in households with 2--3 members, helping explain the higher\ninfluenza secondary attack rates found in households of this size.\n", "versions": [{"version": "v1", "created": "Fri, 25 Nov 2011 14:15:05 GMT"}], "update_date": "2012-08-27", "authors_parsed": [["Potter", "Gail E.", ""], ["Handcock", "Mark S.", ""], ["Longini,", "Ira M.", "Jr."], ["Halloran", "M. Elizabeth", ""]]}, {"id": "1111.6283", "submitter": "Charles Zheng", "authors": "Charles Zheng, Scott Schwartz, Robert Chapkin, Raymond Carroll, Ivan\n  Ivanov", "title": "Feature selection for high-dimensional integrated data", "comments": "Submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the problem of identifying correlations between genes or\nfeatures of two related biological systems, we propose a model of \\emph{feature\nselection} in which only a subset of the predictors $X_t$ are dependent on the\nmultidimensional variate $Y$, and the remainder of the predictors constitute a\n\"noise set\" $X_u$ independent of $Y$. Using Monte Carlo simulations, we\ninvestigated the relative performance of two methods: thresholding and\nsingular-value decomposition, in combination with stochastic optimization to\ndetermine \"empirical bounds\" on the small-sample accuracy of an asymptotic\napproximation. We demonstrate utility of the thresholding and SVD feature\nselection methods to with respect to a recent infant intestinal gene expression\nand metagenomics dataset.\n", "versions": [{"version": "v1", "created": "Sun, 27 Nov 2011 17:53:35 GMT"}], "update_date": "2011-11-29", "authors_parsed": [["Zheng", "Charles", ""], ["Schwartz", "Scott", ""], ["Chapkin", "Robert", ""], ["Carroll", "Raymond", ""], ["Ivanov", "Ivan", ""]]}, {"id": "1111.6285", "submitter": "Fionn Murtagh", "authors": "Fionn Murtagh and Pierre Legendre", "title": "Ward's Hierarchical Clustering Method: Clustering Criterion and\n  Agglomerative Algorithm", "comments": "20 pages, 21 citations, 4 figures", "journal-ref": "Journal of Classification, 31 (3), 274-295, 2014", "doi": "10.1007/s00357-014-9161-z", "report-no": null, "categories": "stat.ML cs.CV stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Ward error sum of squares hierarchical clustering method has been very\nwidely used since its first description by Ward in a 1963 publication. It has\nalso been generalized in various ways. However there are different\ninterpretations in the literature and there are different implementations of\nthe Ward agglomerative algorithm in commonly used software systems, including\ndiffering expressions of the agglomerative criterion. Our survey work and case\nstudies will be useful for all those involved in developing software for data\nanalysis using Ward's hierarchical clustering method.\n", "versions": [{"version": "v1", "created": "Sun, 27 Nov 2011 18:39:14 GMT"}, {"version": "v2", "created": "Sun, 11 Dec 2011 23:58:45 GMT"}], "update_date": "2016-09-20", "authors_parsed": [["Murtagh", "Fionn", ""], ["Legendre", "Pierre", ""]]}, {"id": "1111.6345", "submitter": "Dabuxilatu Wang", "authors": "Dabuxilatu Wang", "title": "Modelling comonotonic group-life under dependent decrement causes", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Comonotonicity had been a extreme case of dependency between random\nvariables. This article consider an extension of single life model under\nmultiple dependent decrement causes to the case of comonotonic group-life.\n", "versions": [{"version": "v1", "created": "Mon, 28 Nov 2011 05:11:24 GMT"}], "update_date": "2011-11-29", "authors_parsed": [["Wang", "Dabuxilatu", ""]]}, {"id": "1111.6828", "submitter": "Paolo Banelli Paolo Banelli", "authors": "Paolo Banelli", "title": "Bayesian Estimation of a Gaussian source in Middleton's Class-A\n  Impulsive Noise", "comments": "30 pages, 13 figures, part of this work has been submitted to IEEE\n  Signal Processing Letters", "journal-ref": null, "doi": "10.1109/LSP.2013.2274774", "report-no": null, "categories": "cs.IT math.IT stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper focuses on minimum mean square error (MMSE) Bayesian estimation for\na Gaussian source impaired by additive Middleton's Class-A impulsive noise. In\naddition to the optimal Bayesian estimator, the paper considers also the\nsoft-limiter and the blanker, which are two popular suboptimal estimators\ncharacterized by very low complexity. The MMSE-optimum thresholds for such\nsuboptimal estimators are obtained by practical iterative algorithms with fast\nconvergence. The paper derives also the optimal thresholds according to a\nmaximum-SNR (MSNR) criterion, and establishes connections with the MMSE\ncriterion. Furthermore, closed form analytic expressions are derived for the\nMSE and the SNR of all the suboptimal estimators, which perfectly match\nsimulation results. Noteworthy, these results can be applied to characterize\nthe receiving performance of any multicarrier system impaired by a\nGaussian-mixture noise, such as asymmetric digital subscriber lines (ADSL) and\npower-line communications (PLC).\n", "versions": [{"version": "v1", "created": "Tue, 29 Nov 2011 14:48:27 GMT"}, {"version": "v2", "created": "Tue, 11 Dec 2012 12:02:43 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Banelli", "Paolo", ""]]}, {"id": "1111.6857", "submitter": "Nicholas Timme", "authors": "Nicholas Timme, Wesley Alford, Benjamin Flecker, and John M. Beggs", "title": "Multivariate information measures: an experimentalist's perspective", "comments": "Manuscript (15 pages, 3 figures, 8 tables)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT physics.data-an stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information theory is widely accepted as a powerful tool for analyzing\ncomplex systems and it has been applied in many disciplines. Recently, some\ncentral components of information theory - multivariate information measures -\nhave found expanded use in the study of several phenomena. These information\nmeasures differ in subtle yet significant ways. Here, we will review the\ninformation theory behind each measure, as well as examine the differences\nbetween these measures by applying them to several simple model systems. In\naddition to these systems, we will illustrate the usefulness of the information\nmeasures by analyzing neural spiking data from a dissociated culture through\nearly stages of its development. We hope that this work will aid other\nresearchers as they seek the best multivariate information measure for their\nspecific research goals and system. Finally, we have made software available\nonline which allows the user to calculate all of the information measures\ndiscussed within this paper.\n", "versions": [{"version": "v1", "created": "Mon, 28 Nov 2011 18:03:04 GMT"}, {"version": "v2", "created": "Tue, 6 Dec 2011 16:08:00 GMT"}, {"version": "v3", "created": "Thu, 31 May 2012 17:18:58 GMT"}, {"version": "v4", "created": "Wed, 25 Jul 2012 13:57:00 GMT"}, {"version": "v5", "created": "Wed, 29 Aug 2012 15:23:09 GMT"}], "update_date": "2012-08-30", "authors_parsed": [["Timme", "Nicholas", ""], ["Alford", "Wesley", ""], ["Flecker", "Benjamin", ""], ["Beggs", "John M.", ""]]}, {"id": "1111.6899", "submitter": "Ioannis Papastathopoulos", "authors": "Ioannis Papastathopoulos and Jonathan A. Tawn", "title": "Extended Generalised Pareto Models for Tail Estimation", "comments": "18 pages, 7 figures", "journal-ref": "J. Statist. Plann. and Inf., (2013), 143", "doi": "10.1016/j.jspi.2012.07.001", "report-no": null, "categories": "stat.ME stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The most popular approach in extreme value statistics is the modelling of\nthreshold exceedances using the asymptotically motivated generalised Pareto\ndistribution. This approach involves the selection of a high threshold above\nwhich the model fits the data well. Sometimes, few observations of a\nmeasurement process might be recorded in applications and so selecting a high\nquantile of the sample as the threshold leads to almost no exceedances. In this\npaper we propose extensions of the generalised Pareto distribution that\nincorporate an additional shape parameter while keeping the tail behaviour\nunaffected. The inclusion of this parameter offers additional structure for the\nmain body of the distribution, improves the stability of the modified scale,\ntail index and return level estimates to threshold choice and allows a lower\nthreshold to be selected. We illustrate the benefits of the proposed models\nwith a simulation study and two case studies.\n", "versions": [{"version": "v1", "created": "Tue, 29 Nov 2011 17:04:26 GMT"}], "update_date": "2014-05-27", "authors_parsed": [["Papastathopoulos", "Ioannis", ""], ["Tawn", "Jonathan A.", ""]]}, {"id": "1111.6923", "submitter": "Akshay Soni", "authors": "Akshay Soni and Jarvis Haupt", "title": "Efficient Adaptive Compressive Sensing Using Sparse Hierarchical Learned\n  Dictionaries", "comments": "5 pages, 6 figures, conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.IT math.IT math.PR stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent breakthrough results in compressed sensing (CS) have established that\nmany high dimensional objects can be accurately recovered from a relatively\nsmall number of non- adaptive linear projection observations, provided that the\nobjects possess a sparse representation in some basis. Subsequent efforts have\nshown that the performance of CS can be improved by exploiting the structure in\nthe location of the non-zero signal coefficients (structured sparsity) or using\nsome form of online measurement focusing (adaptivity) in the sensing process.\nIn this paper we examine a powerful hybrid of these two techniques. First, we\ndescribe a simple adaptive sensing procedure and show that it is a provably\neffective method for acquiring sparse signals that exhibit structured sparsity\ncharacterized by tree-based coefficient dependencies. Next, employing\ntechniques from sparse hierarchical dictionary learning, we show that\nrepresentations exhibiting the appropriate form of structured sparsity can be\nlearned from collections of training data. The combination of these techniques\nresults in an effective and efficient adaptive compressive acquisition\nprocedure.\n", "versions": [{"version": "v1", "created": "Tue, 29 Nov 2011 18:31:54 GMT"}], "update_date": "2011-11-30", "authors_parsed": [["Soni", "Akshay", ""], ["Haupt", "Jarvis", ""]]}, {"id": "1111.6926", "submitter": "Nicholas Arcolano", "authors": "Nicholas Arcolano and Patrick J. Wolfe", "title": "Estimating principal components of covariance matrices using the\n  Nystr\\\"{o}m method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Covariance matrix estimates are an essential part of many signal processing\nalgorithms, and are often used to determine a low-dimensional principal\nsubspace via their spectral decomposition. However, exact eigenanalysis is\ncomputationally intractable for sufficiently high-dimensional matrices, and in\nthe case of small sample sizes, sample eigenvalues and eigenvectors are known\nto be poor estimators of their population counterparts. To address these\nissues, we propose a covariance estimator that is computationally efficient\nwhile also performing shrinkage on the sample eigenvalues. Our approach is\nbased on the Nystr\\\"{o}m method, which uses a data-dependent orthogonal\nprojection to obtain a fast low-rank approximation of a large positive\nsemidefinite matrix. We provide a theoretical analysis of the error properties\nof our estimator as well as empirical results, including examples of its\napplication to adaptive beamforming and image denoising.\n", "versions": [{"version": "v1", "created": "Tue, 29 Nov 2011 18:36:44 GMT"}, {"version": "v2", "created": "Wed, 30 Nov 2011 17:40:30 GMT"}], "update_date": "2011-12-01", "authors_parsed": [["Arcolano", "Nicholas", ""], ["Wolfe", "Patrick J.", ""]]}, {"id": "1111.7089", "submitter": "Debashis Paul", "authors": "Debashis Paul, Jie Peng, Prabir Burman", "title": "Semiparametric modeling of autonomous nonlinear dynamical systems with\n  application to plant growth", "comments": "Published in at http://dx.doi.org/10.1214/11-AOAS459 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org). arXiv admin note:\n  substantial text overlap with arXiv:0906.3501", "journal-ref": "Annals of Applied Statistics 2011, Vol. 5, No. 3, 2078-2108", "doi": "10.1214/11-AOAS459", "report-no": "IMS-AOAS-AOAS459", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a semiparametric model for autonomous nonlinear dynamical systems\nand devise an estimation procedure for model fitting. This model incorporates\nsubject-specific effects and can be viewed as a nonlinear semiparametric mixed\neffects model. We also propose a computationally efficient model selection\nprocedure. We show by simulation studies that the proposed estimation as well\nas model selection procedures can efficiently handle sparse and noisy\nmeasurements. Finally, we apply the proposed method to a plant growth data used\nto study growth displacement rates within meristems of maize roots under two\ndifferent experimental conditions.\n", "versions": [{"version": "v1", "created": "Wed, 30 Nov 2011 09:17:21 GMT"}], "update_date": "2011-12-01", "authors_parsed": [["Paul", "Debashis", ""], ["Peng", "Jie", ""], ["Burman", "Prabir", ""]]}, {"id": "1111.7091", "submitter": "Juliette Blanchet", "authors": "Juliette Blanchet, Anthony C. Davison", "title": "Spatial modeling of extreme snow depth", "comments": "Published in at http://dx.doi.org/10.1214/11-AOAS464 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2011, Vol. 5, No. 3, 1699-1725", "doi": "10.1214/11-AOAS464", "report-no": "IMS-AOAS-AOAS464", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The spatial modeling of extreme snow is important for adequate risk\nmanagement in Alpine and high altitude countries. A natural approach to such\nmodeling is through the theory of max-stable processes, an infinite-dimensional\nextension of multivariate extreme value theory. In this paper we describe the\napplication of such processes in modeling the spatial dependence of extreme\nsnow depth in Switzerland, based on data for the winters 1966--2008 at 101\nstations. The models we propose rely on a climate transformation that allows us\nto account for the presence of climate regions and for directional effects,\nresulting from synoptic weather patterns. Estimation is performed through\npairwise likelihood inference and the models are compared using penalized\nlikelihood criteria. The max-stable models provide a much better fit to the\njoint behavior of the extremes than do independence or full dependence models.\n", "versions": [{"version": "v1", "created": "Wed, 30 Nov 2011 09:28:39 GMT"}], "update_date": "2011-12-01", "authors_parsed": [["Blanchet", "Juliette", ""], ["Davison", "Anthony C.", ""]]}, {"id": "1111.7098", "submitter": "Liam Paninski", "authors": "Yuriy Mishchenko, Liam Paninski", "title": "Efficient methods for sampling spike trains in networks of coupled\n  neurons", "comments": "Published in at http://dx.doi.org/10.1214/11-AOAS467 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2011, Vol. 5, No. 3, 1893-1919", "doi": "10.1214/11-AOAS467", "report-no": "IMS-AOAS-AOAS467", "categories": "stat.AP q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monte Carlo approaches have recently been proposed to quantify connectivity\nin neuronal networks. The key problem is to sample from the conditional\ndistribution of a single neuronal spike train, given the activity of the other\nneurons in the network. Dependencies between neurons are usually relatively\nweak; however, temporal dependencies within the spike train of a single neuron\nare typically strong. In this paper we develop several specialized\nMetropolis--Hastings samplers which take advantage of this dependency\nstructure. These samplers are based on two ideas: (1) an adaptation of fast\nforward--backward algorithms from the theory of hidden Markov models to take\nadvantage of the local dependencies inherent in spike trains, and (2) a\nfirst-order expansion of the conditional likelihood which allows for efficient\nexact sampling in the limit of weak coupling between neurons. We also\ndemonstrate that these samplers can effectively incorporate side information,\nin particular, noisy fluorescence observations in the context of\ncalcium-sensitive imaging experiments. We quantify the efficiency of these\nsamplers in a variety of simulated experiments in which the network parameters\nare closely matched to data measured in real cortical networks, and also\ndemonstrate the sampler applied to real calcium imaging data.\n", "versions": [{"version": "v1", "created": "Wed, 30 Nov 2011 09:44:48 GMT"}], "update_date": "2011-12-01", "authors_parsed": [["Mishchenko", "Yuriy", ""], ["Paninski", "Liam", ""]]}, {"id": "1111.7105", "submitter": "Sabyasachi Mukhopadhyay", "authors": "Sabyasachi Mukhopadhyay, Sourabh Bhattacharya, Kajal Dihidar", "title": "On Bayesian \"central clustering\": Application to landscape\n  classification of Western Ghats", "comments": "Published in at http://dx.doi.org/10.1214/11-AOAS454 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2011, Vol. 5, No. 3, 1948-1977", "doi": "10.1214/11-AOAS454", "report-no": "IMS-AOAS-AOAS454", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Landscape classification of the well-known biodiversity hotspot, Western\nGhats (mountains), on the west coast of India, is an important part of a\nworld-wide program of monitoring biodiversity. To this end, a massive\nvegetation data set, consisting of 51,834 4-variate observations has been\nclustered into different landscapes by Nagendra and Gadgil [Current Sci. 75\n(1998) 264--271]. But a study of such importance may be affected by\nnonuniqueness of cluster analysis and the lack of methods for quantifying\nuncertainty of the clusterings obtained. Motivated by this applied problem of\nmuch scientific importance, we propose a new methodology for obtaining the\nglobal, as well as the local modes of the posterior distribution of clustering,\nalong with the desired credible and \"highest posterior density\" regions in a\nnonparametric Bayesian framework. To meet the need of an appropriate metric for\ncomputing the distance between any two clusterings, we adopt and provide a much\nsimpler, but accurate modification of the metric proposed in [In Felicitation\nVolume in Honour of Prof. B. K. Kale (2009) MacMillan]. A very fast and\nefficient Bayesian methodology, based on [Sankhy\\={a} Ser. B 70 (2008)\n133--155], has been utilized to solve the computational problems associated\nwith the massive data and to obtain samples from the posterior distribution of\nclustering on which our proposed methods of summarization are illustrated.\n", "versions": [{"version": "v1", "created": "Wed, 30 Nov 2011 10:09:55 GMT"}], "update_date": "2011-12-01", "authors_parsed": [["Mukhopadhyay", "Sabyasachi", ""], ["Bhattacharya", "Sourabh", ""], ["Dihidar", "Kajal", ""]]}, {"id": "1111.7120", "submitter": "Nicoleta Serban", "authors": "Nicoleta Serban", "title": "A space--time varying coefficient model: The equity of service\n  accessibility", "comments": "Published in at http://dx.doi.org/10.1214/11-AOAS473 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2011, Vol. 5, No. 3, 2024-2051", "doi": "10.1214/11-AOAS473", "report-no": "IMS-AOAS-AOAS473", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research in examining the equity of service accessibility has emerged as\neconomic and social equity advocates recognized that where people live\ninfluences their opportunities for economic development, access to quality\nhealth care and political participation. In this research paper service\naccessibility equity is concerned with where and when services have been and\nare accessed by different groups of people, identified by location or\nunderlying socioeconomic variables. Using new statistical methods for modeling\nspatial-temporal data, this paper estimates demographic association patterns to\nfinancial service accessibility varying over a large geographic area (Georgia)\nand over a period of 13 years. The underlying model is a space--time varying\ncoefficient model including both separable space and time varying coefficients\nand space--time interaction terms. The model is extended to a multilevel\nresponse where the varying coefficients account for both the within- and\nbetween-variability. We introduce an inference procedure for assessing the\nshape of the varying regression coefficients using confidence bands.\n", "versions": [{"version": "v1", "created": "Wed, 30 Nov 2011 10:58:37 GMT"}], "update_date": "2011-12-01", "authors_parsed": [["Serban", "Nicoleta", ""]]}, {"id": "1111.7125", "submitter": "Charlotte Soneson", "authors": "Charlotte Soneson, Magnus Fontes", "title": "A method for visual identification of small sample subgroups and\n  potential biomarkers", "comments": "Published in at http://dx.doi.org/10.1214/11-AOAS460 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2011, Vol. 5, No. 3, 2131-2149", "doi": "10.1214/11-AOAS460", "report-no": "IMS-AOAS-AOAS460", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to find previously unknown subgroups in biomedical data and generate\ntestable hypotheses, visually guided exploratory analysis can be of tremendous\nimportance. In this paper we propose a new dissimilarity measure that can be\nused within the Multidimensional Scaling framework to obtain a joint\nlow-dimensional representation of both the samples and variables of a\nmultivariate data set, thereby providing an alternative to conventional\nbiplots. In comparison with biplots, the representations obtained by our\napproach are particularly useful for exploratory analysis of data sets where\nthere are small groups of variables sharing unusually high or low values for a\nsmall group of samples.\n", "versions": [{"version": "v1", "created": "Wed, 30 Nov 2011 11:12:18 GMT"}], "update_date": "2011-12-01", "authors_parsed": [["Soneson", "Charlotte", ""], ["Fontes", "Magnus", ""]]}, {"id": "1111.7247", "submitter": "Zachary Harmany", "authors": "Zachary T. Harmany, Roummel F. Marcia, Rebecca M. Willett", "title": "Spatio-temporal Compressed Sensing with Coded Apertures and Keyed\n  Exposures", "comments": "15 pages, 4 figures, 2 tables, submitted to IEEE Transactions on\n  Image Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP math.OC math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optical systems which measure independent random projections of a scene\naccording to compressed sensing (CS) theory face a myriad of practical\nchallenges related to the size of the physical platform, photon efficiency, the\nneed for high temporal resolution, and fast reconstruction in video settings.\nThis paper describes a coded aperture and keyed exposure approach to\ncompressive measurement in optical systems. The proposed projections satisfy\nthe Restricted Isometry Property for sufficiently sparse scenes, and hence are\ncompatible with theoretical guarantees on the video reconstruction quality.\nThese concepts can be implemented in both space and time via either amplitude\nmodulation or phase shifting, and this paper describes the relative merits of\nthe two approaches in terms of theoretical performance, noise and hardware\nconsiderations, and experimental results. Fast numerical algorithms which\naccount for the nonnegativity of the projections and temporal correlations in a\nvideo sequence are developed and applied to microscopy and short-wave infrared\ndata.\n", "versions": [{"version": "v1", "created": "Wed, 30 Nov 2011 17:38:53 GMT"}, {"version": "v2", "created": "Fri, 6 Jan 2012 19:51:26 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Harmany", "Zachary T.", ""], ["Marcia", "Roummel F.", ""], ["Willett", "Rebecca M.", ""]]}]