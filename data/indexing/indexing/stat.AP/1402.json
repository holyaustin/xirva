[{"id": "1402.0045", "submitter": "Tadilo E Bogale", "authors": "Tadilo Endeshaw Bogale and Long Bao Le", "title": "Pilot Optimization and Channel Estimation for Multiuser Massive MIMO\n  Systems", "comments": "Accepted in CISS 2014 Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes novel pilot optimization and channel estimation algorithm\nfor the downlink multiuser massive multiple input multiple output (MIMO) system\nwith $K$ decentralized single antenna mobile stations (MSs), and time division\nduplex (TDD) channel estimation which is performed by utilizing $N$ pilot\nsymbols. The proposed algorithm is explained as follows. First, we formulate\nthe channel estimation problem as a weighted sum mean square error (WSMSE)\nminimization problem containing pilot symbols and introduced variables. Second,\nfor fixed pilot symbols, the introduced variables are optimized using minimum\nmean square error (MMSE) and generalized Rayleigh quotient methods. Finally,\nfor $N=1$ and $N=K$ settings, the pilot symbols of all MSs are optimized using\nsemi definite programming (SDP) convex optimization approach, and for the other\nsettings of $N$ and $K$, the pilot symbols of all MSs are optimized by applying\nsimple iterative algorithm. When $N=K$, it is shown that the latter iterative\nalgorithm gives the optimal pilot symbols achieved by the SDP method.\nSimulation results confirm that the proposed algorithm achieves less WSMSE\ncompared to that of the conventional semi-orthogonal pilot symbol and MMSE\nchannel estimation algorithm which creates pilot contamination.\n", "versions": [{"version": "v1", "created": "Sat, 1 Feb 2014 02:46:52 GMT"}, {"version": "v2", "created": "Thu, 6 Feb 2014 02:07:39 GMT"}], "update_date": "2014-02-07", "authors_parsed": [["Bogale", "Tadilo Endeshaw", ""], ["Le", "Long Bao", ""]]}, {"id": "1402.0136", "submitter": "Wei Sun", "authors": "Wei Sun, Yufeng Liu, James J. Crowley, Ting-Huei Chen, Hua Zhou,\n  Haitao Chu, Shunping Huang, Pei-Fen Kuan, Yuan Li, Darla Miller, Ginger Shaw,\n  Yichao Wu, Vasyl Zhabotynsky, Leonard McMillan, Fei Zou, Patrick F. Sullivan,\n  Fernando Pardo-Manuel de Villena", "title": "IsoDOT Detects Differential RNA-isoform Expression/Usage with respect to\n  a Categorical or Continuous Covariate with High Sensitivity and Specificity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP q-bio.QM stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We have developed a statistical method named IsoDOT to assess differential\nisoform expression (DIE) and differential isoform usage (DIU) using RNA-seq\ndata. Here isoform usage refers to relative isoform expression given the total\nexpression of the corresponding gene. IsoDOT performs two tasks that cannot be\naccomplished by existing methods: to test DIE/DIU with respect to a continuous\ncovariate, and to test DIE/DIU for one case versus one control. The latter task\nis not an uncommon situation in practice, e.g., comparing paternal and maternal\nallele of one individual or comparing tumor and normal sample of one cancer\npatient. Simulation studies demonstrate the high sensitivity and specificity of\nIsoDOT. We apply IsoDOT to study the effects of haloperidol treatment on mouse\ntranscriptome and identify a group of genes whose isoform usages respond to\nhaloperidol treatment.\n", "versions": [{"version": "v1", "created": "Sat, 1 Feb 2014 23:21:17 GMT"}, {"version": "v2", "created": "Wed, 29 Oct 2014 14:09:32 GMT"}], "update_date": "2014-10-30", "authors_parsed": [["Sun", "Wei", ""], ["Liu", "Yufeng", ""], ["Crowley", "James J.", ""], ["Chen", "Ting-Huei", ""], ["Zhou", "Hua", ""], ["Chu", "Haitao", ""], ["Huang", "Shunping", ""], ["Kuan", "Pei-Fen", ""], ["Li", "Yuan", ""], ["Miller", "Darla", ""], ["Shaw", "Ginger", ""], ["Wu", "Yichao", ""], ["Zhabotynsky", "Vasyl", ""], ["McMillan", "Leonard", ""], ["Zou", "Fei", ""], ["Sullivan", "Patrick F.", ""], ["de Villena", "Fernando Pardo-Manuel", ""]]}, {"id": "1402.0172", "submitter": "Yuval Nov", "authors": "Yair Goldberg and Yuval Nov", "title": "Modeling and Optimization of Genetic Screens via RNA Interference and\n  FACS", "comments": null, "journal-ref": "Prob. Eng. Inf. Sci. 29 (2015) 131-145", "doi": "10.1017/S0269964814000254", "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study mathematically a method for discovering which gene is related to a\ncell phenotype of interest. The method is based on RNA interference -- a\nmolecular process for gene deactivation -- and on coupling the phenotype with\nfluorescence in a FACS machine. A small number of candidate genes are thus\nisolated, and then tested individually. We model probabilistically this\nprocess, prove a limit theorem for its outcome, and derive operational\nguidelines for maximizing the probability of successful gene discovery.\n", "versions": [{"version": "v1", "created": "Sun, 2 Feb 2014 10:45:15 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Goldberg", "Yair", ""], ["Nov", "Yuval", ""]]}, {"id": "1402.0346", "submitter": "Audrone Virbickaite", "authors": "Audron\\.e Virbickait\\.e, M. Concepci\\'on Aus\\'in, Pedro Galeano", "title": "Bayesian Inference Methods for Univariate and Multivariate GARCH Models:\n  a Survey", "comments": "28 pages, 3 figures", "journal-ref": null, "doi": "10.1111/joes.12046", "report-no": null, "categories": "math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This survey reviews the existing literature on the most relevant Bayesian\ninference methods for univariate and multivariate GARCH models. The advantages\nand drawbacks of each procedure are outlined as well as the advantages of the\nBayesian approach versus classical procedures. The paper makes emphasis on\nrecent Bayesian non-parametric approaches for GARCH models that avoid imposing\narbitrary parametric distributional assumptions. These novel approaches\nimplicitly assume infinite mixture of Gaussian distributions on the\nstandardized returns which have been shown to be more flexible and describe\nbetter the uncertainty about future volatilities. Finally, the survey presents\nan illustration using real data to show the flexibility and usefulness of the\nnon-parametric approach.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2014 11:32:05 GMT"}], "update_date": "2014-02-04", "authors_parsed": [["Virbickait\u0117", "Audron\u0117", ""], ["Aus\u00edn", "M. Concepci\u00f3n", ""], ["Galeano", "Pedro", ""]]}, {"id": "1402.0536", "submitter": "Vladimir Minin", "authors": "Amanda A. Koepke, Ira M. Longini Jr., M. Elizabeth Halloran, Jon\n  Wakefield, Vladimir N. Minin", "title": "Predictive Modeling of Cholera Outbreaks in Bangladesh", "comments": "43 pages, including appendices, 5 figures, 1 table in the main text", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite seasonal cholera outbreaks in Bangladesh, little is known about the\nrelationship between environmental conditions and cholera cases. We seek to\ndevelop a predictive model for cholera outbreaks in Bangladesh based on\nenvironmental predictors. To do this, we estimate the contribution of\nenvironmental variables, such as water depth and water temperature, to cholera\noutbreaks in the context of a disease transmission model. We implement a method\nwhich simultaneously accounts for disease dynamics and environmental variables\nin a Susceptible-Infected-Recovered-Susceptible (SIRS) model. The entire system\nis treated as a continuous-time hidden Markov model, where the hidden Markov\nstates are the numbers of people who are susceptible, infected, or recovered at\neach time point, and the observed states are the numbers of cholera cases\nreported. We use a Bayesian framework to fit this hidden SIRS model,\nimplementing particle Markov chain Monte Carlo methods to sample from the\nposterior distribution of the environmental and transmission parameters given\nthe observed data. We test this method using both simulation and data from\nMathbaria, Bangladesh. Parameter estimates are used to make short-term\npredictions that capture the formation and decline of epidemic peaks. We\ndemonstrate that our model can successfully predict an increase in the number\nof infected individuals in the population weeks before the observed number of\ncholera cases increases, which could allow for early notification of an\nepidemic and timely allocation of resources.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2014 22:32:52 GMT"}, {"version": "v2", "created": "Sun, 11 Jan 2015 23:17:34 GMT"}], "update_date": "2015-01-13", "authors_parsed": [["Koepke", "Amanda A.", ""], ["Longini", "Ira M.", "Jr."], ["Halloran", "M. Elizabeth", ""], ["Wakefield", "Jon", ""], ["Minin", "Vladimir N.", ""]]}, {"id": "1402.0944", "submitter": "Ali Saeb Dr.", "authors": "Ali Saeb", "title": "General extreme value modeling and application of bootstrap on rainfall\n  data - A case study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extreme value theory is concerned with probabilistic and statistical\nquestions related to very high or very low values in sequences of random\nvariables and in stochastic processes. The subject has a rich mathematical\ntheory and also a long tradition of applications in a variety of areas. Among\nmany excellent books on the subject, Coles [2] while the book by concentrates\non data analysis and statistical inference for extremes. In this article, we\npresent a case study wherein we model annual maximum yearly rainfall data using\nthe generalized extreme value distribution. Also, we use R software for data\nanalysis and give the R codes in the appendix.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2014 06:04:10 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2014 15:00:14 GMT"}, {"version": "v3", "created": "Fri, 28 Mar 2014 19:13:27 GMT"}], "update_date": "2014-03-31", "authors_parsed": [["Saeb", "Ali", ""]]}, {"id": "1402.1054", "submitter": "Charanpal Dhanjal", "authors": "Charanpal Dhanjal (LTCI), St\\'ephan Cl\\'emen\\c{c}on (LTCI)", "title": "On Recent Advances in Supervised Ranking for Metabolite Profiling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on data arising from the field of metabolomics, a rapidly\ndeveloping area concerned by the analysis of the chemical fingerprints (i.e.\nthe metabolite profile). The metabolite profile is left by specific chemical\nprocesses occurring in biological cells, tissues or organs. It is the main\npurpose of this article to develop and implement scoring techniques so as to\nrank all possible metabolic profiles by increasing order of magnitude of the\nconditional probability that a given metabolite is present at high levels in a\ncertain biological fluid. After a detailed description of the (functional) data\nfrom which decision rules must be learnt, several approaches to this predictive\nproblem, based on recent advances in K-partite ranking are described at length.\nTheir performance on several real datasets are next thoroughly investigated.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2014 14:31:19 GMT"}], "update_date": "2014-02-06", "authors_parsed": [["Dhanjal", "Charanpal", "", "LTCI"], ["Cl\u00e9men\u00e7on", "St\u00e9phan", "", "LTCI"]]}, {"id": "1402.1213", "submitter": "Adrien Ickowicz", "authors": "Adrien Ickowicz", "title": "A Statistical Modelling Approach to Detecting Community in Networks", "comments": "23 pages, 4 figures. arXiv admin note: text overlap with\n  arXiv:physics/0512106, arXiv:1207.0865 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been considerable recent interest in algorithms for finding\ncommunities in networks - groups of vertex within which connections are dense\n(frequent), but between which connections are sparser (rare). Most of the\ncurrent literature advocates an heuristic approach to the removal of the edges\n(i.e., removing the links that are less significant using a well-designed\nfunction). In this article, we will investigate a technique for uncovering\nlatent communities using a new modelling approach, based on how information\nspread within a network. It will prove to be easy to use, robust and scalable.\nIt makes supplementary information related to the network/community structure\n(different communications, consecutive observations) easier to integrate. We\nwill demonstrate the efficiency of our approach by providing some illustrating\nreal-world applications, like the famous Zachary karate club, or the Amazon\npolitical books buyers network.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2014 23:14:43 GMT"}], "update_date": "2014-02-07", "authors_parsed": [["Ickowicz", "Adrien", ""]]}, {"id": "1402.1694", "submitter": "Patrick Conrad", "authors": "Patrick R. Conrad, Youssef M. Marzouk, Natesh S. Pillai, Aaron Smith", "title": "Accelerating Asymptotically Exact MCMC for Computationally Intensive\n  Models via Local Approximations", "comments": "A major update of the theory and examples", "journal-ref": "Journal of the American Statistical Association, volume 111, issue\n  516, 1591--1607 (2016)", "doi": "10.1080/01621459.2015.1096787", "report-no": null, "categories": "stat.ME stat.AP stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We construct a new framework for accelerating Markov chain Monte Carlo in\nposterior sampling problems where standard methods are limited by the\ncomputational cost of the likelihood, or of numerical models embedded therein.\nOur approach introduces local approximations of these models into the\nMetropolis-Hastings kernel, borrowing ideas from deterministic approximation\ntheory, optimization, and experimental design. Previous efforts at integrating\napproximate models into inference typically sacrifice either the sampler's\nexactness or efficiency; our work seeks to address these limitations by\nexploiting useful convergence characteristics of local approximations. We prove\nthe ergodicity of our approximate Markov chain, showing that it samples\nasymptotically from the \\emph{exact} posterior distribution of interest. We\ndescribe variations of the algorithm that employ either local polynomial\napproximations or local Gaussian process regressors. Our theoretical results\nreinforce the key observation underlying this paper: when the likelihood has\nsome \\emph{local} regularity, the number of model evaluations per MCMC step can\nbe greatly reduced without biasing the Monte Carlo average. Numerical\nexperiments demonstrate multiple order-of-magnitude reductions in the number of\nforward model evaluations used in representative ODE and PDE inference\nproblems, with both synthetic and real data.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2014 16:59:31 GMT"}, {"version": "v2", "created": "Mon, 8 Sep 2014 20:53:57 GMT"}, {"version": "v3", "created": "Wed, 5 Nov 2014 15:20:21 GMT"}, {"version": "v4", "created": "Tue, 15 Sep 2015 15:45:09 GMT"}], "update_date": "2017-01-06", "authors_parsed": [["Conrad", "Patrick R.", ""], ["Marzouk", "Youssef M.", ""], ["Pillai", "Natesh S.", ""], ["Smith", "Aaron", ""]]}, {"id": "1402.1734", "submitter": "Ana Georgina Flesia MS", "authors": "J. Gimenez and A.C. Frery and Ana Georgina Flesia", "title": "When Data do not Bring Information: A Case Study in Markov Random Fields\n  Estimation", "comments": "To appear at IEEE Journal Of Selected Topics In Applied Earth\n  Observations And Remote Sensing", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Potts model is frequently used to describe the behavior of image classes,\nsince it allows to incorporate contextual information linking neighboring\npixels in a simple way. Its isotropic version has only one real parameter beta,\nknown as smoothness parameter or inverse temperature, which regulates the\nclasses map homogeneity. The classes are unavailable, and estimating them is\ncentral in important image processing procedures as, for instance, image\nclassification. Methods for estimating the classes which stem from a Bayesian\napproach under the Potts model require to adequately specify a value for beta.\nThe estimation of such parameter can be efficiently made solving the Pseudo\nMaximum likelihood (PML) equations in two different schemes, using the prior or\nthe posterior model. Having only radiometric data available, the first scheme\nneeds the computation of an initial segmentation, while the second uses both\nthe segmentation and the radiometric data to make the estimation. In this\npaper, we compare these two PML estimators by computing the mean square error\n(MSE), bias, and sensitivity to deviations from the hypothesis of the model. We\nconclude that the use of extra data does not improve the accuracy of the PML,\nmoreover, under gross deviations from the model, this extra information\nintroduces unpredictable distortions and bias.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2014 19:07:15 GMT"}, {"version": "v2", "created": "Wed, 7 May 2014 17:17:46 GMT"}], "update_date": "2014-05-08", "authors_parsed": [["Gimenez", "J.", ""], ["Frery", "A. C.", ""], ["Flesia", "Ana Georgina", ""]]}, {"id": "1402.1740", "submitter": "Camila Pedroso Estevam de Souza", "authors": "Amanda Lenzi, Camila P. E. de Souza, Ronaldo Dias, Nancy Garcia and\n  Nancy E. Heckman", "title": "Analysis of Aggregated Functional Data from Mixed Populations with\n  Application to Energy Consumption", "comments": "31 pages, 9 figures and 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the energy consumption patterns of different types of consumers\nis essential in any planning of energy distribution. However, obtaining\nconsumption information for single individuals is often either not possible or\ntoo expensive. Therefore, we consider data from aggregations of energy use,\nthat is, from sums of individuals' energy use, where each individual falls into\none of C consumer classes. Unfortunately, the exact number of individuals of\neach class may be unknown: consumers do not always report the appropriate\nclass, due to various factors including differential energy rates for different\nconsumer classes. We develop a methodology to estimate the expected energy use\nof each class as a function of time and the true number of consumers in each\nclass. We also provide some measure of uncertainty of the resulting estimates.\nTo accomplish this, we assume that the expected consumption is a function of\ntime that can be well approximated by a linear combination of B-splines.\nIndividual consumer perturbations from this baseline are modeled as B-splines\nwith random coefficients. We treat the reported numbers of consumers in each\ncategory as random variables with distribution depending on the true number of\nconsumers in each class and on the probabilities of a consumer in one class\nreporting as another class. We obtain maximum likelihood estimates of all\nparameters via a maximization algorithm. We introduce a special numerical trick\nfor calculating the maximum likelihood estimates of the true number of\nconsumers in each class. We apply our method to a data set and study our method\nvia simulation.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2014 19:28:07 GMT"}], "update_date": "2014-02-10", "authors_parsed": [["Lenzi", "Amanda", ""], ["de Souza", "Camila P. E.", ""], ["Dias", "Ronaldo", ""], ["Garcia", "Nancy", ""], ["Heckman", "Nancy E.", ""]]}, {"id": "1402.1801", "submitter": "Sayedmasoud Hashemi Amroabadi", "authors": "SayedMasoud Hashemi, Soosan Beheshti, Patrick R. Gill, Narinder S.\n  Paul, Richard S.C. Cobbold", "title": "Efficient Low Dose X-ray CT Reconstruction through Sparsity-Based MAP\n  Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ultra low radiation dose in X-ray Computed Tomography (CT) is an important\nclinical objective in order to minimize the risk of carcinogenesis. Compressed\nSensing (CS) enables significant reductions in radiation dose to be achieved by\nproducing diagnostic images from a limited number of CT projections. However,\nthe excessive computation time that conventional CS-based CT reconstruction\ntypically requires has limited clinical implementation. In this paper, we first\ndemonstrate that a thorough analysis of CT reconstruction through a Maximum a\nPosteriori objective function results in a weighted compressive sensing\nproblem. This analysis enables us to formulate a low dose fan beam and helical\ncone beam CT reconstruction. Subsequently, we provide an efficient solution to\nthe formulated CS problem based on a Fast Composite Splitting Algorithm-Latent\nExpected Maximization (FCSA-LEM) algorithm. In the proposed method we use\npseudo polar Fourier transform as the measurement matrix in order to decrease\nthe computational complexity; and rebinning of the projections to parallel rays\nin order to extend its application to fan beam and helical cone beam scans. The\nweight involved in the proposed weighted CS model, denoted by Error Adaptation\nWeight (EAW), is calculated based on the statistical characteristics of CT\nreconstruction and is a function of Poisson measurement noise and rebinning\ninterpolation error. Simulation results show that low computational complexity\nof the proposed method made the fast recovery of the CT images possible and\nusing EAW reduces the reconstruction error by one order of magnitude. Recovery\nof a high quality 512$\\times$ 512 image was achieved in less than 20 sec on a\ndesktop computer without numerical optimizations.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2014 00:18:46 GMT"}], "update_date": "2014-02-11", "authors_parsed": [["Hashemi", "SayedMasoud", ""], ["Beheshti", "Soosan", ""], ["Gill", "Patrick R.", ""], ["Paul", "Narinder S.", ""], ["Cobbold", "Richard S. C.", ""]]}, {"id": "1402.1835", "submitter": "Tu Xu", "authors": "Tu Xu, Junhui Wang and Yixin Fang", "title": "A model-free estimation for the covariate-adjusted Youden index and its\n  associated cut-point", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In medical research, continuous markers are widely employed in diagnostic\ntests to distinguish diseased and non-diseased subjects. The accuracy of such\ndiagnostic tests is commonly assessed using the receiver operating\ncharacteristic (ROC) curve. To summarize an ROC curve and determine its optimal\ncut-point, the Youden index is popularly used. In literature, estimation of the\nYouden index has been widely studied via various statistical modeling\nstrategies on the conditional density. This paper proposes a new model-free\nestimation method, which directly estimates the covariate-adjusted cut-point\nwithout estimating the conditional density. Consequently, covariate-adjusted\nYouden index can be estimated based on the estimated cutpoint. The proposed\nmethod formulates the estimation problem in a large margin classification\nframework, which allows flexible modeling of the covariate-adjusted Youden\nindex through kernel machines. The advantage of the proposed method is\ndemonstrated in a variety of simulated experiments as well as a real\napplication to Pima Indians diabetes study.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2014 08:56:46 GMT"}], "update_date": "2014-02-11", "authors_parsed": [["Xu", "Tu", ""], ["Wang", "Junhui", ""], ["Fang", "Yixin", ""]]}, {"id": "1402.1937", "submitter": "Heejoon Han", "authors": "Heejoon Han, Oliver Linton, Tatsushi Oka, Yoon-Jae Whang", "title": "The Cross-Quantilogram: Measuring Quantile Dependence and Testing\n  Directional Predictability between Time Series", "comments": null, "journal-ref": "Journal of Econometrics, 2016, 193, 251-270", "doi": null, "report-no": null, "categories": "math.ST stat.AP stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes the cross-quantilogram to measure the quantile dependence\nbetween two time series. We apply it to test the hypothesis that one time\nseries has no directional predictability to another time series. We establish\nthe asymptotic distribution of the cross quantilogram and the corresponding\ntest statistic. The limiting distributions depend on nuisance parameters. To\nconstruct consistent confidence intervals we employ the stationary bootstrap\nprocedure; we show the consistency of this bootstrap. Also, we consider the\nself-normalized approach, which is shown to be asymptotically pivotal under the\nnull hypothesis of no predictability. We provide simulation studies and two\nempirical applications. First, we use the cross-quantilogram to detect\npredictability from stock variance to excess stock return. Compared to existing\ntools used in the literature of stock return predictability, our method\nprovides a more complete relationship between a predictor and stock return.\nSecond, we investigate the systemic risk of individual financial institutions,\nsuch as JP Morgan Chase, Goldman Sachs and AIG. This article has supplementary\nmaterials online.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2014 11:30:20 GMT"}, {"version": "v2", "created": "Sun, 21 Jan 2018 04:46:31 GMT"}], "update_date": "2018-01-23", "authors_parsed": [["Han", "Heejoon", ""], ["Linton", "Oliver", ""], ["Oka", "Tatsushi", ""], ["Whang", "Yoon-Jae", ""]]}, {"id": "1402.2026", "submitter": "Deniz Akdemir", "authors": "Deniz Akdemir", "title": "Genomic Prediction of Quantitative Traits using Sparse and Locally\n  Epistatic Models", "comments": "arXiv admin note: substantial text overlap with arXiv:1302.3463", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In plant and animal breeding studies a distinction is made between the\ngenetic value (additive + epistatic genetic effects) and the breeding value\n(additive genetic effects) of an individual since it is expected that some of\nthe epistatic genetic effects will be lost due to recombination. In this paper,\nwe argue that the breeder can take advantage of some of the epistatic marker\neffects in regions of low recombination. The models introduced here aim to\nestimate local epistatic line heritability by using the genetic map information\nand combine the local additive and epistatic effects. To this end, we have used\nsemi-parametric mixed models with multiple local genomic relationship matrices\nwith hierarchical designs and lasso post-processing for sparsity in the final\nmodel. Our models produce good predictive performance along with good\nexplanatory information.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2014 03:30:17 GMT"}], "update_date": "2014-02-11", "authors_parsed": [["Akdemir", "Deniz", ""]]}, {"id": "1402.2169", "submitter": "Nabin Malakar", "authors": "N. K. Malakar, A. J. Mesiti, K. H. Knuth", "title": "The Spatial Sensitivity Function of a Light Sensor", "comments": "Published in MaxEnt 2009", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.IM physics.data-an stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Spatial Sensitivity Function (SSF) is used to quantify a detector's\nsensitivity to a spatially-distributed input signal. By weighting the incoming\nsignal with the SSF and integrating, the overall scalar response of the\ndetector can be estimated. This project focuses on estimating the SSF of a\nlight intensity sensor consisting of a photodiode. This light sensor has been\nused previously in the Knuth Cyberphysics Laboratory on a robotic arm that\nperforms its own experiments to locate a white circle in a dark field (Knuth et\nal., 2007). To use the light sensor to learn about its surroundings, the\nrobot's inference software must be able to model and predict the light sensor's\nresponse to a hypothesized stimulus. Previous models of the light sensor\ntreated it as a point sensor and ignored its spatial characteristics. Here we\npropose a parametric approach where the SSF is described by a mixture of\nGaussians (MOG). By performing controlled calibration experiments with known\nstimulus inputs, we used nested sampling to estimate the SSF of the light\nsensor using an MOG model with the number of Gaussians ranging from one to\nfive. By comparing the evidence computed for each MOG model, we found that one\nGaussian is sufficient to describe the SSF to the accuracy we require. Future\nwork will involve incorporating this more accurate SSF into the Bayesian\nmachine learning software for the robotic system and studying how this detailed\ninformation about the properties of the light sensor will improve robot's\nability to learn.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2014 14:49:22 GMT"}], "update_date": "2014-02-11", "authors_parsed": [["Malakar", "N. K.", ""], ["Mesiti", "A. J.", ""], ["Knuth", "K. H.", ""]]}, {"id": "1402.2255", "submitter": "Youssef  Mroueh", "authors": "Youssef Mroueh", "title": "Robust Phase Retrieval and Super-Resolution from One Bit Coded\n  Diffraction Patterns", "comments": "fixed notations", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study a realistic setup for phase retrieval, where the\nsignal of interest is modulated or masked and then for each modulation or mask\na diffraction pattern is collected, producing a coded diffraction pattern (CDP)\n[CLM13]. We are interested in the setup where the resolution of the collected\nCDP is limited by the Fraunhofer diffraction limit of the imaging system.\n  We investigate a novel approach based on a geometric quantization scheme of\nphase-less linear measurements into (one-bit) coded diffraction patterns, and a\ncorresponding recovery scheme. The key novelty in this approach consists in\ncomparing pairs of coded diffractions patterns across frequencies: the one bit\nmeasurements obtained rely on the order statistics of the un-quantized\nmeasurements rather than their values . This results in a robust phase\nrecovery, and unlike currently available methods, allows to efficiently perform\nphase recovery from measurements affected by severe (possibly unknown) non\nlinear, rank preserving perturbations, such as distortions. Another important\nfeature of this approach consists in the fact that it enables also\nsuper-resolution and blind-deconvolution, beyond the diffraction limit of a\ngiven imaging system.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2014 20:19:53 GMT"}, {"version": "v2", "created": "Mon, 24 Mar 2014 13:11:16 GMT"}], "update_date": "2014-03-25", "authors_parsed": [["Mroueh", "Youssef", ""]]}, {"id": "1402.2468", "submitter": "Ansgar Steland", "authors": "Ansgar Steland", "title": "Sampling Plans for Control-Inspection Schemes Under Independent and\n  Dependent Sampling Designs With Applications to Photovoltaics", "comments": null, "journal-ref": "Frontiers in Statistical Quality Control 11 - 2015, pp 287-317", "doi": "10.1007/978-3-319-12355-4_18", "report-no": null, "categories": "math.ST stat.AP stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The evaluation of produced items at the time of delivery is, in practice,\nusually amended by at least one inspection at later time points. We extend the\nmethodology of acceptance sampling for variables for arbitrary unknown\ndistributions when additional sampling infor- mation is available to such\nsettings. Based on appropriate approximations of the operating characteristic,\nwe derive new acceptance sampling plans that control the overall operating\ncharacteristic. The results cover the case of independent sampling as well as\nthe case of dependent sampling. In particular, we study a modified panel\nsampling design and the case of spatial batch sampling. The latter is advisable\nin photovoltaic field monitoring studies, since it allows to detect and analyze\nlocal clusters of degraded or damaged modules. Some finite sample properties\nare examined by a simulation study, focusing on the accuracy of estimation.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2014 12:17:50 GMT"}], "update_date": "2018-03-20", "authors_parsed": [["Steland", "Ansgar", ""]]}, {"id": "1402.2492", "submitter": "Gareth Peters Dr", "authors": "Alice X.D. Dong, Jennifer S.K. Chan, Gareth W. Peters", "title": "Risk Margin Quantile Function Via Parametric and Non-Parametric Bayesian\n  Quantile Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM stat.AP stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop quantile regression models in order to derive risk margin and to\nevaluate capital in non-life insurance applications. By utilizing the entire\nrange of conditional quantile functions, especially higher quantile levels, we\ndetail how quantile regression is capable of providing an accurate estimation\nof risk margin and an overview of implied capital based on the historical\nvolatility of a general insurers loss portfolio. Two modelling frameworks are\nconsidered based around parametric and nonparametric quantile regression models\nwhich we develop specifically in this insurance setting.\n  In the parametric quantile regression framework, several models including the\nflexible generalized beta distribution family, asymmetric Laplace (AL)\ndistribution and power Pareto distribution are considered under a Bayesian\nregression framework. The Bayesian posterior quantile regression models in each\ncase are studied via Markov chain Monte Carlo (MCMC) sampling strategies.\n  In the nonparametric quantile regression framework, that we contrast to the\nparametric Bayesian models, we adopted an AL distribution as a proxy and\ntogether with the parametric AL model, we expressed the solution as a scale\nmixture of uniform distributions to facilitate implementation. The models are\nextended to adopt dynamic mean, variance and skewness and applied to analyze\ntwo real loss reserve data sets to perform inference and discuss interesting\nfeatures of quantile regression for risk margin calculations.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2014 14:13:17 GMT"}], "update_date": "2014-02-12", "authors_parsed": [["Dong", "Alice X. D.", ""], ["Chan", "Jennifer S. K.", ""], ["Peters", "Gareth W.", ""]]}, {"id": "1402.2510", "submitter": "Hygor Piaget Melo M.Sc.", "authors": "Hygor Piaget M. Melo, Andr\\'e A. Moreira, Hern\\'an A. Makse, Jos\\'e S.\n  Andrade Jr", "title": "Statistical Signs of Social Influence on Suicides", "comments": "7 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Certain currents in sociology consider society as being composed of\nautonomous individuals with independent psychologies. Others, however, deem our\nactions as strongly influenced by the accepted standards of social behavior.\nThe later view was central to the positivist conception of society when in 1887\n\\'Emile Durkheim published his monograph Suicide (Durkheim, 1897). By treating\nthe suicide as a social fact, Durkheim envisaged that suicide rates should be\ndetermined by the connections (or the lack of them) between people and society.\nUnder the same framework, Durkheim considered that crime is bound up with the\nfundamental conditions of all social life and serves a social function. In this\nsense, and regardless of its extremely deviant nature, crime events are somehow\ncapable to release certain social tensions and so have a purging effect in\nsociety. The social effect on the occurrence of homicides has been previously\nsubstantiated (Bettencourt et al., 2007; Alves et al., 2013), and confirmed\nhere, in terms of a superlinear scaling relation: by doubling the population of\na Brazilian city results in an average increment of 135 % in the number of\nhomicides, rather than the expected isometric increase of 100 %, as found, for\nexample, for the mortality due to car crashes. Here we present statistical\nsigns of the social influence on the suicide occurrence in cities. Differently\nfrom homicides (superlinear) and fatal events in car crashes (isometric), we\nfind sublinear scaling behavior between the number of suicides and city\npopulation, with allometric power-law exponents, $\\beta = 0.836 \\pm 0.009$ and\n$0.870 \\pm 0.002$, for all cities in Brazil and US, respectively. The fact that\nthe frequency of suicides is disproportionately small for larger cities reveals\na surprisingly beneficial aspect of living and interacting in larger and more\ncomplex social networks.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2014 14:53:21 GMT"}], "update_date": "2014-02-12", "authors_parsed": [["Melo", "Hygor Piaget M.", ""], ["Moreira", "Andr\u00e9 A.", ""], ["Makse", "Hern\u00e1n A.", ""], ["Andrade", "Jos\u00e9 S.", "Jr"]]}, {"id": "1402.2550", "submitter": "Jay Bartroff", "authors": "Jay Bartroff and Tze Leung Lai and Balasubramanian Narasimhan", "title": "A New Approach to Designing Phase I-II Cancer Trials for Cytotoxic\n  Chemotherapies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently there has been much work on early phase cancer designs that\nincorporate both toxicity and efficacy data, called Phase I-II designs because\nthey combine elements of both phases. However, they do not explicitly address\nthe Phase II hypothesis test of $H_0: p\\le p_0$, where $p$ is the probability\nof efficacy at the estimated maximum tolerated dose (MTD) $\\widehat{\\eta}$ from\nPhase I and $p_0$ is the baseline efficacy rate. Standard practice for Phase II\nremains to treat $p$ as a fixed, unknown parameter and to use Simon's 2-stage\ndesign with all patients dosed at $\\widehat{\\eta}$. We propose a Phase I-II\ndesign that addresses the uncertainty in the estimate $p=p(\\widehat{\\eta})$ in\n$H_0$ by using sequential generalized likelihood theory. Combining this with a\nPhase I design that incorporates efficacy data, the Phase I-II design provides\na common framework that can be used all the way from the first dose of Phase I\nthrough the final accept/reject decision about $H_0$ at the end of Phase II,\nutilizing both toxicity and efficacy data throughout. Efficient group\nsequential testing is used in Phase II that allows for early stopping to show\ntreatment effect or futility. The proposed Phase I-II design thus removes the\nartificial barrier between Phase I and Phase II, and fulfills the objectives of\nsearching for the MTD and testing if the treatment has an acceptable response\nrate to enter into a Phase III trial.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2014 16:27:30 GMT"}], "update_date": "2014-02-12", "authors_parsed": [["Bartroff", "Jay", ""], ["Lai", "Tze Leung", ""], ["Narasimhan", "Balasubramanian", ""]]}, {"id": "1402.2633", "submitter": "Karl Broman", "authors": "Karl W. Broman, Mark P. Keller, Aimee Teo Broman, Christina\n  Kendziorski, Brian S. Yandell, Saunak Sen, Alan D. Attie", "title": "Identification and correction of sample mix-ups in expression genetic\n  data: A case study", "comments": "63 pages, 9 figures, 20 supplemental figures, and 5 supplemental\n  tables. In version 2: added two supplemental figures in response to\n  reviewers' comments, and corrected a problem in Figure S13 (points at the\n  boundary between genotype groups were inadvertently omitted, which gave the\n  false impression of clear separation between the groups). In version 3: fixed\n  a few typos", "journal-ref": null, "doi": "10.1534/g3.115.019778", "report-no": null, "categories": "stat.AP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In a mouse intercross with more than 500 animals and genome-wide gene\nexpression data on six tissues, we identified a high proportion (18%) of sample\nmix-ups in the genotype data. Local expression quantitative trait loci (eQTL;\ngenetic loci influencing gene expression) with extremely large effect were used\nto form a classifier to predict an individual's eQTL genotype based on\nexpression data alone. By considering multiple eQTL and their related\ntranscripts, we identified numerous individuals whose predicted eQTL genotypes\n(based on their expression data) did not match their observed genotypes, and\nthen went on to identify other individuals whose genotypes did match the\npredicted eQTL genotypes. The concordance of predictions across six tissues\nindicated that the problem was due to mix-ups in the genotypes (though we\nfurther identified a small number of sample mix-ups in each of the six panels\nof gene expression microarrays). Consideration of the plate positions of the\nDNA samples indicated a number of off-by-one and off-by-two errors, likely the\nresult of pipetting errors. Such sample mix-ups can be a problem in any genetic\nstudy, but eQTL data allow us to identify, and even correct, such problems. Our\nmethods have been implemented in an R package, R/lineup.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2014 20:25:43 GMT"}, {"version": "v2", "created": "Tue, 18 Aug 2015 21:08:44 GMT"}, {"version": "v3", "created": "Fri, 21 Aug 2015 03:28:45 GMT"}], "update_date": "2015-10-15", "authors_parsed": [["Broman", "Karl W.", ""], ["Keller", "Mark P.", ""], ["Broman", "Aimee Teo", ""], ["Kendziorski", "Christina", ""], ["Yandell", "Brian S.", ""], ["Sen", "Saunak", ""], ["Attie", "Alan D.", ""]]}, {"id": "1402.2643", "submitter": "Christian R\\\"over", "authors": "Nicola D. Crins, Christian R\\\"over, Armin D. Goralczyk, Tim Friede", "title": "Interleukin-2 receptor antagonists for pediatric liver transplant\n  recipients: A systematic review and meta-analysis of controlled studies", "comments": "18 pages, 3 tables, 3 figures", "journal-ref": "Pediatric Transplantation, 18(8):839-850, 2014", "doi": "10.1111/petr.12362", "report-no": null, "categories": "q-bio.QM stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interleukin-2 receptor antagonists (IL-2RA) are frequently used as induction\ntherapy in liver transplant recipients to decrease the risk of acute rejection\nwhile allowing the reduction of concomitant immunosuppression. The exact\nassociation with the use of IL-2RA however is uncertain. We performed a\nsystematic literature search for relevant studies. Random effects models were\nused to assess the incidence of acute rejection, steroid-resistant rejection,\ngraft loss, patient death, and adverse drug reaction, with or without IL-2RA.\nSix studies (2 randomized and 4 nonrandomized) met the elegibility criteria.\nAcute rejection at 6 months or later favored the use of IL-2RA significantly\n(relative risk (RR) 0.38; 95% confidence interval (CI) 0.22-0.66, p = 0.0005).\nAlthough not statistically significant, IL-2RA showed a substantial reduction\nof the risk of steroid-resistant rejection (RR 0.32; CI 0.19-1.03, p = 0.0594).\nGraft loss and patient death showed a reductive tendency through the use of\nIL-2RA. The use of IL-2RA is safe and is associated with a statistically\nsignificantly lower incidence of acute rejection after transplantation and\nsubstantial reduction of steroid-resistant rejection, graft loss and patient\ndeath.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2014 17:16:51 GMT"}, {"version": "v2", "created": "Wed, 12 Nov 2014 10:08:05 GMT"}], "update_date": "2016-02-22", "authors_parsed": [["Crins", "Nicola D.", ""], ["R\u00f6ver", "Christian", ""], ["Goralczyk", "Armin D.", ""], ["Friede", "Tim", ""]]}, {"id": "1402.2678", "submitter": "Wen-Yu Hua", "authors": "Wen-Yu Hua and Thomas E. Nichols and Debashis Ghosh and the\n  Alzheimer's Disease Neuroimaging Initiative", "title": "Multiple Comparison Procedures for Neuroimaging Genomewide Association\n  Studies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research in neuroimaging has focused on assessing associations between\ngenetic variants that are measured on a genomewide scale and brain imaging\nphenotypes. A large number of works in the area apply massively univariate\nanalyses on a genomewide basis to find single nucleotide polymorphisms that\ninfluence brain structure. In this paper, we propose using various\ndimensionality reduction methods on both brain structural MRI scans and genomic\ndata, motivated by the Alzheimer's Disease Neuroimaging Initiative (ADNI)\nstudy. We also consider a new multiple testing adjustment method and compare it\nwith two existing false discovery rate (FDR) adjustment methods. The simulation\nresults suggest an increase in power for the proposed method. The real data\nanalysis suggests that the proposed procedure is able to find associations\nbetween genetic variants and brain volume differences that offer potentially\nnew biological insights.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2014 21:51:25 GMT"}, {"version": "v2", "created": "Wed, 12 Mar 2014 20:50:44 GMT"}, {"version": "v3", "created": "Sat, 22 Mar 2014 20:01:19 GMT"}], "update_date": "2014-03-25", "authors_parsed": [["Hua", "Wen-Yu", ""], ["Nichols", "Thomas E.", ""], ["Ghosh", "Debashis", ""], ["Initiative", "the Alzheimer's Disease Neuroimaging", ""]]}, {"id": "1402.2706", "submitter": "Georg Hahn", "authors": "Axel Gandy, Georg Hahn", "title": "QuickMMCTest - Quick Multiple Monte Carlo Testing", "comments": null, "journal-ref": "Stat Comput (2017), 27(3):823--832", "doi": "10.1007/s11222-016-9656-z", "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiple hypothesis testing is widely used to evaluate scientific studies\ninvolving statistical tests. However, for many of these tests, p-values are not\navailable and are thus often approximated using Monte Carlo tests such as\npermutation tests or bootstrap tests. This article presents a simple algorithm\nbased on Thompson Sampling to test multiple hypotheses. It works with arbitrary\nmultiple testing procedures, in particular with step-up and step-down\nprocedures. Its main feature is to sequentially allocate Monte Carlo effort,\ngenerating more Monte Carlo samples for tests whose decisions are so far less\ncertain. A simulation study demonstrates that for a low computational effort,\nthe new approach yields a higher power and a higher degree of reproducibility\nof its results than previously suggested methods.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2014 00:32:23 GMT"}, {"version": "v2", "created": "Thu, 26 Feb 2015 18:20:59 GMT"}, {"version": "v3", "created": "Mon, 2 Mar 2015 11:15:24 GMT"}, {"version": "v4", "created": "Thu, 7 May 2015 15:36:27 GMT"}, {"version": "v5", "created": "Tue, 2 Jun 2015 02:54:00 GMT"}, {"version": "v6", "created": "Mon, 14 Dec 2015 23:57:56 GMT"}, {"version": "v7", "created": "Tue, 5 Apr 2016 22:39:39 GMT"}, {"version": "v8", "created": "Wed, 31 Jan 2018 17:14:10 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Gandy", "Axel", ""], ["Hahn", "Georg", ""]]}, {"id": "1402.3014", "submitter": "Thinh Doan", "authors": "Thinh K. Doan, Andrew C. Parnell, John Haslett", "title": "Joint Inference of Misaligned Irregular Time Series with Application to\n  Greenland Ice Core Data", "comments": "14 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ice cores provide insight into the past climate over many millennia. Due to\nice compaction, the raw data for any single core are irregular in time.\nMultiple cores have different irregularities; jointly these series are\nmisaligned. After processing, such data are made available to researchers as\nregular time series: a data product. Typically, these cores are independently\nprocessed. In this paper, we consider a fast Bayesian method for the joint\nprocessing of multiple irregular series. This is shown to be more efficient.\nFurther, our approach permits a realistic modelling of the impact of the\nmultiple sources of uncertainty. The methodology is illustrated with the\nanalysis of a pair of ice cores (GISP2 and GRIP). Our data products, in the\nform of marginal posterior distributions on an arbitrary temporal grid, are\nfinite Gaussian mixtures. We can also produce sample paths from the joint\nposterior distribution to study non-linear functionals of interest. More\ngenerally, the concept of joint analysis via hierarchical Gaussian process\nmodel can be widely extended as the models used can be viewed within the larger\ncontext of continuous space-time processes.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2014 00:47:17 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2014 10:58:59 GMT"}, {"version": "v3", "created": "Mon, 22 Sep 2014 14:29:37 GMT"}], "update_date": "2014-09-23", "authors_parsed": [["Doan", "Thinh K.", ""], ["Parnell", "Andrew C.", ""], ["Haslett", "John", ""]]}, {"id": "1402.3410", "submitter": "Jean-Benoist Leger", "authors": "Jean-Benoist Leger", "title": "Wmixnet: Software for Clustering the Nodes of Binary and Valued Graphs\n  using the Stochastic Block Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering the nodes of a graph allows the analysis of the topology of a\nnetwork.\n  The stochastic block model is a clustering method based on a probabilistic\nmodel. Initially developed for binary networks it has recently been extended to\nvalued networks possibly with covariates on the edges.\n  We present an implementation of a variational EM algorithm. It is written\nusing C++, parallelized, available under a GNU General Public License (version\n3), and can select the optimal number of clusters using the ICL criteria. It\nallows us to analyze networks with ten thousand nodes in a reasonable amount of\ntime.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2014 09:43:04 GMT"}], "update_date": "2014-02-17", "authors_parsed": [["Leger", "Jean-Benoist", ""]]}, {"id": "1402.3514", "submitter": "Kaveh Vakili", "authors": "E. Schmitt and K. Vakili", "title": "Robust PCA with FastHCS", "comments": "14 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.AP stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Principal component analysis (PCA) is widely used to analyze high-dimensional\ndata, but it is very sensitive to outliers. Robust PCA methods seek fits that\nare unaffected by the outliers and can therefore be trusted to reveal them.\nFastHCS (High-dimensional Congruent Subsets) is a robust PCA algorithm suitable\nfor high-dimensional applications, including cases where the number of\nvariables exceeds the number of observations. After detailing the FastHCS\nalgorithm, we carry out an extensive simulation study and three real data\napplications, the results of which show that FastHCS is systematically more\nrobust to outliers than state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2014 16:13:21 GMT"}, {"version": "v2", "created": "Wed, 19 Feb 2014 09:51:42 GMT"}, {"version": "v3", "created": "Tue, 15 Jul 2014 06:20:07 GMT"}, {"version": "v4", "created": "Tue, 16 Dec 2014 20:28:59 GMT"}, {"version": "v5", "created": "Fri, 19 Dec 2014 04:23:59 GMT"}, {"version": "v6", "created": "Mon, 18 May 2015 09:48:48 GMT"}, {"version": "v7", "created": "Thu, 24 Sep 2015 11:24:08 GMT"}], "update_date": "2015-09-25", "authors_parsed": [["Schmitt", "E.", ""], ["Vakili", "K.", ""]]}, {"id": "1402.3580", "submitter": "Andrew Wilson", "authors": "Andrew Gordon Wilson, Yuting Wu, Daniel J. Holland, Sebastian Nowozin,\n  Mick D. Mantle, Lynn F. Gladden, Andrew Blake", "title": "Bayesian Inference for NMR Spectroscopy with Applications to Chemical\n  Quantification", "comments": "26 pages, 13 figures, 1 table. Submitted for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nuclear magnetic resonance (NMR) spectroscopy exploits the magnetic\nproperties of atomic nuclei to discover the structure, reaction state and\nchemical environment of molecules. We propose a probabilistic generative model\nand inference procedures for NMR spectroscopy. Specifically, we use a weighted\nsum of trigonometric functions undergoing exponential decay to model free\ninduction decay (FID) signals. We discuss the challenges in estimating the\ncomponents of this general model -- amplitudes, phase shifts, frequencies,\ndecay rates, and noise variances -- and offer practical solutions. We compare\nwith conventional Fourier transform spectroscopy for estimating the relative\nconcentrations of chemicals in a mixture, using synthetic and experimentally\nacquired FID signals. We find the proposed model is particularly robust to low\nsignal to noise ratios (SNR), and overlapping peaks in the Fourier transform of\nthe FID, enabling accurate predictions (e.g., 1% sensitivity at low SNR) which\nare not possible with conventional spectroscopy (5% sensitivity).\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2014 20:47:58 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2014 02:24:00 GMT"}], "update_date": "2014-02-25", "authors_parsed": [["Wilson", "Andrew Gordon", ""], ["Wu", "Yuting", ""], ["Holland", "Daniel J.", ""], ["Nowozin", "Sebastian", ""], ["Mantle", "Mick D.", ""], ["Gladden", "Lynn F.", ""], ["Blake", "Andrew", ""]]}, {"id": "1402.3646", "submitter": "Peter Visscher", "authors": "Peter M. Visscher", "title": "Statistical analysis of the price and subjective quality ratings on\n  Australian wines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consumers have a wide choice regarding the purchase of wine. Wines vary\nacross varieties, regions, years of vintage, alcohol content, price and expert\nratings. In this study we explored the relationship between those variables and\nwhether a combination of explanatory variables can predict outcome variables\nusing data on selected 2710 Australian wines rates by the latest book of James\nHalliday1. We analysed two dependent (outcome) variables, namely the rating and\nthe price, and their (non-linear) relationship between explanatory variables\nand each other. We observe that the rating scale is not linear, as consumers\nmay believe, and that a narrow range of rating scores is used for the\nascertained wines. Across all wines, approximately 20% of variation in\nlog(Price) can be explained by the explanatory factors state, variety, vintage\nand alcohol percentage. If the residuals from the model for rating is also\ntaken as an explanatory variable for price, then a total of 53% of variation in\nlog(Price) is explained by the model. For those wines ascertained to be in\nHalliday1, there is more variability between white wines than between red wines\nthat is explained by explanatory variables such as State and variety. In\ncomparison with hedonic pricing analyses in previous studies on French and\nAustralian wines, a smaller proportion of variation in price and rating was\nexplained in Australian wines that were in the 2014 edition of Halliday.\n", "versions": [{"version": "v1", "created": "Sat, 15 Feb 2014 05:07:56 GMT"}], "update_date": "2014-02-18", "authors_parsed": [["Visscher", "Peter M.", ""]]}, {"id": "1402.3647", "submitter": "Vyacheslav Lyubchich", "authors": "Mary E. Thompson, Lilia Leticia Ramirez Ramirez, Vyacheslav Lyubchich\n  and Yulia R. Gel", "title": "Using bootstrap for statistical inference on random graphs", "comments": "The paper has been withdrawn by the authors: a general revision of\n  methodology is needed", "journal-ref": null, "doi": "10.1002/cjs.11271", "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose new nonparametric approach to network inference\nthat may be viewed as a fusion of block sampling procedures for temporally and\nspatially dependent processes with the classical network methodology. We\ndevelop estimation and uncertainty quantification procedures for network mean\ndegree using a \"patchwork\" sample and nonparametric bootstrap, under the\nassumption of unknown degree distribution. We investigate asymptotic properties\nof the proposed patchwork bootstrap procedure and present cross-validation\nmethodology for selecting an optimal patch size. We validate the new patchwork\nbootstrap on simulated networks with short and long tailed mean degree\ndistributions, and revisit the Erd\u007fos collaboration data to illustrate the\nproposed methodology.\n", "versions": [{"version": "v1", "created": "Sat, 15 Feb 2014 05:09:59 GMT"}, {"version": "v2", "created": "Wed, 12 Mar 2014 00:12:51 GMT"}, {"version": "v3", "created": "Sun, 18 Jan 2015 22:18:40 GMT"}], "update_date": "2016-02-11", "authors_parsed": [["Thompson", "Mary E.", ""], ["Ramirez", "Lilia Leticia Ramirez", ""], ["Lyubchich", "Vyacheslav", ""], ["Gel", "Yulia R.", ""]]}, {"id": "1402.3783", "submitter": "Francesco Montorsi Dr.", "authors": "Francesco Montorsi, Fabrizio Pancaldi, Giorgio M. Vitetta", "title": "Map-Aware Models for Indoor Wireless Localization Systems: An\n  Experimental Study", "comments": "13 pages, 11 figures, 1 table. IEEE Transactions on Wireless\n  Communications, 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The accuracy of indoor wireless localization systems can be substantially\nenhanced by map-awareness, i.e., by the knowledge of the map of the environment\nin which localization signals are acquired. In fact, this knowledge can be\nexploited to cancel out, at least to some extent, the signal degradation due to\npropagation through physical obstructions, i.e., to the so called\nnon-line-of-sight bias. This result can be achieved by developing novel\nlocalization techniques that rely on proper map-aware statistical modelling of\nthe measurements they process. In this manuscript a unified statistical model\nfor the measurements acquired in map-aware localization systems based on\ntime-of-arrival and received signal strength techniques is developed and its\nexperimental validation is illustrated. Finally, the accuracy of the proposed\nmap-aware model is assessed and compared with that offered by its map-unaware\ncounterparts. Our numerical results show that, when the quality of acquired\nmeasurements is poor, map-aware modelling can enhance localization accuracy by\nup to 110% in certain scenarios.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2014 10:50:01 GMT"}], "update_date": "2014-02-18", "authors_parsed": [["Montorsi", "Francesco", ""], ["Pancaldi", "Fabrizio", ""], ["Vitetta", "Giorgio M.", ""]]}, {"id": "1402.3890", "submitter": "Michal Brzezinski", "authors": "Michal Brzezinski", "title": "Power laws in citation distributions: Evidence from Scopus", "comments": "18 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL physics.soc-ph stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling distributions of citations to scientific papers is crucial for\nunderstanding how science develops. However, there is a considerable empirical\ncontroversy on which statistical model fits the citation distributions best.\nThis paper is concerned with rigorous empirical detection of power-law\nbehaviour in the distribution of citations received by the most highly cited\nscientific papers. We have used a large, novel data set on citations to\nscientific papers published between 1998 and 2002 drawn from Scopus. The\npower-law model is compared with a number of alternative models using a\nlikelihood ratio test. We have found that the power-law hypothesis is rejected\nfor around half of the Scopus fields of science. For these fields of science,\nthe Yule, power-law with exponential cut-off and log-normal distributions seem\nto fit the data better than the pure power-law model. On the other hand, when\nthe power-law hypothesis is not rejected, it is usually empirically\nindistinguishable from most of the alternative models. The pure power-law model\nseems to be the best model only for the most highly cited papers in \"Physics\nand Astronomy\". Overall, our results seem to support theories implying that the\nmost highly cited scientific papers follow the Yule, power-law with exponential\ncut-off or log-normal distribution. Our findings suggest also that power laws\nin citation distributions, when present, account only for a very small fraction\nof the published papers (less than 1% for most of science fields) and that the\npower-law scaling parameter (exponent) is substantially higher (from around 3.2\nto around 4.7) than found in the older literature.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2014 05:17:29 GMT"}], "update_date": "2014-02-18", "authors_parsed": [["Brzezinski", "Michal", ""]]}, {"id": "1402.4109", "submitter": "Sanket Kalamkar", "authors": "Sanket S. Kalamkar, Praveen Kumar Singh and Adrish Banerjee", "title": "Block Outlier Methods for Malicious User Detection in Cooperative\n  Spectrum Sensing", "comments": "Accepted in Proceedings of 79th IEEE Vehicular Technology\n  Conference-Spring (VTC-Spring), May 2014, Seoul, South Korea", "journal-ref": null, "doi": "10.1109/VTCSpring.2014.7022848", "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Block outlier detection methods, based on Tietjen-Moore (TM) and Shapiro-Wilk\n(SW) tests, are proposed to detect and suppress spectrum sensing data\nfalsification (SSDF) attacks by malicious users in cooperative spectrum\nsensing. First, we consider basic and statistical SSDF attacks, where the\nmalicious users attack independently. Then we propose a new SSDF attack, which\ninvolves cooperation among malicious users by masking. In practice, the number\nof malicious users is unknown. Thus, it is necessary to estimate the number of\nmalicious users, which is found using clustering and largest gap method.\nHowever, we show using Monte Carlo simulations that, these methods fail to\nestimate the exact number of malicious users when they cooperate. To overcome\nthis, we propose a modified largest gap method.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2014 20:16:08 GMT"}], "update_date": "2016-11-18", "authors_parsed": [["Kalamkar", "Sanket S.", ""], ["Singh", "Praveen Kumar", ""], ["Banerjee", "Adrish", ""]]}, {"id": "1402.4239", "submitter": "Ran Shi", "authors": "Ran Shi, Ying Guo", "title": "Modeling Covariate Effects in Group Independent Component Analysis with\n  Applications to Functional Magnetic Resonance Imaging", "comments": "36 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Independent component analysis (ICA) is a powerful computational tool for\nseparating independent source signals from their linear mixtures. ICA has been\nwidely applied in neuroimaging studies to identify and characterize underlying\nbrain functional networks. An important goal in such studies is to assess the\neffects of subjects' clinical and demographic covariates on the spatial\ndistributions of the functional networks. Currently, covariate effects are not\nincorporated in existing group ICA decomposition methods. Hence, they can only\nbe evaluated through ad-hoc approaches which may not be accurate in many cases.\nIn this paper, we propose a hierarchical covariate ICA model that provides a\nformal statistical framework for estimating and testing covariate effects in\nICA decomposition. A maximum likelihood method is proposed for estimating the\ncovariate ICA model. We develop two expectation-maximization (EM) algorithms to\nobtain maximum likelihood estimates. The first is an exact EM algorithm, which\nhas analytically tractable E-step and M-step. Additionally, we propose a\nsubspace-based approximate EM, which can significantly reduce computational\ntime while still retain high model-fitting accuracy. Furthermore, to test\ncovariate effects on the functional networks, we develop a voxel-wise\napproximate inference procedure which eliminates the needs of computationally\nexpensive covariance estimation. The performance of the proposed methods is\nevaluated via simulation studies. The application is illustrated through an\nfMRI study of Zen meditation.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2014 07:23:00 GMT"}, {"version": "v2", "created": "Mon, 16 Jun 2014 07:04:40 GMT"}, {"version": "v3", "created": "Thu, 30 Apr 2015 00:09:35 GMT"}], "update_date": "2015-05-01", "authors_parsed": [["Shi", "Ran", ""], ["Guo", "Ying", ""]]}, {"id": "1402.4426", "submitter": "Massimo Ostilli", "authors": "Massimo Ostilli", "title": "Fluctuations analysis in complex networks modeled by hidden variable\n  models. Necessity of a large cut-off in hidden-variable models", "comments": "19 pages, 16 figures. arXiv admin note: text overlap with\n  arXiv:1306.5565", "journal-ref": "Phys. Rev. E 89, 022807 (2014)", "doi": "10.1103/PhysRevE.89.022807", "report-no": null, "categories": "cond-mat.dis-nn cond-mat.stat-mech stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is becoming more and more clear that complex networks present remarkable\nlarge fluctuations. These fluctuations may manifest differently according to\nthe given model. In this paper we re-consider hidden variable models which turn\nout to be more analytically treatable and for which we have recently shown\nclear evidence of non-self averaging; the density of a motif being subject to\npossible uncontrollable fluctuations in the infinite size limit. Here we\nprovide full detailed calculations and we show that large fluctuations are only\ndue to the node hidden variables variability while, in ensembles where these\nare frozen, fluctuations are negligible in the thermodynamic limit, and equal\nthe fluctuations of classical random graphs. A special attention is paid to the\nchoice of the cut-off: we show that in hidden-variable models, only a cut-off\ngrowing as $N^\\lambda$ with $\\lambda\\geq 1$ can reproduce the scaling of a\npower-law degree distribution. In turn, it is this large cut-off that generates\nnon-self-averaging.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2014 18:23:53 GMT"}], "update_date": "2014-02-19", "authors_parsed": [["Ostilli", "Massimo", ""]]}, {"id": "1402.4547", "submitter": "Robert Castelo", "authors": "Inma Tur, Alberto Roverato and Robert Castelo", "title": "Mapping eQTL networks with mixed graphical Markov models", "comments": "48 pages, 8 figures, 2 supplementary figures; fixed problems with\n  embedded fonts; figure 7 sideways for improving display; minor fixes; major\n  revision of the paper after journal review; fixed missing .bbl file; 36\n  pages, 6 figures, 2 tables", "journal-ref": "Genetics, 198:1377-1393 (2014)", "doi": "10.1534/genetics.114.169573", "report-no": null, "categories": "q-bio.QM q-bio.GN q-bio.MN stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Expression quantitative trait loci (eQTL) mapping constitutes a challenging\nproblem due to, among other reasons, the high-dimensional multivariate nature\nof gene-expression traits. Next to the expression heterogeneity produced by\nconfounding factors and other sources of unwanted variation, indirect effects\nspread throughout genes as a result of genetic, molecular and environmental\nperturbations. From a multivariate perspective one would like to adjust for the\neffect of all of these factors to end up with a network of direct associations\nconnecting the path from genotype to phenotype. In this paper we approach this\nchallenge with mixed graphical Markov models, higher-order conditional\nindependences and q-order correlation graphs. These models show that additive\ngenetic effects propagate through the network as function of gene-gene\ncorrelations. Our estimation of the eQTL network underlying a well-studied\nyeast data set leads to a sparse structure with more direct genetic and\nregulatory associations that enable a straightforward comparison of the genetic\ncontrol of gene expression across chromosomes. Interestingly, it also reveals\nthat eQTLs explain most of the expression variability of network hub genes.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2014 02:22:38 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2014 14:12:27 GMT"}, {"version": "v3", "created": "Wed, 1 Oct 2014 13:14:44 GMT"}, {"version": "v4", "created": "Thu, 2 Oct 2014 10:12:46 GMT"}, {"version": "v5", "created": "Wed, 29 Oct 2014 13:26:03 GMT"}], "update_date": "2014-12-10", "authors_parsed": [["Tur", "Inma", ""], ["Roverato", "Alberto", ""], ["Castelo", "Robert", ""]]}, {"id": "1402.4578", "submitter": "Lutz Bornmann Dr.", "authors": "Lutz Bornmann, Ruediger Mutz", "title": "Growth rates of modern science: A bibliometric analysis based on the\n  number of publications and cited references", "comments": "Accepted for publication in the Journal of the Association for\n  Information Science and Technology", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL physics.soc-ph stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many studies in information science have looked at the growth of science. In\nthis study, we re-examine the question of the growth of science. To do this we\n(i) use current data up to publication year 2012 and (ii) analyse it across all\ndisciplines and also separately for the natural sciences and for the medical\nand health sciences. Furthermore, the data are analysed with an advanced\nstatistical technique - segmented regression analysis - which can identify\nspecific segments with similar growth rates in the history of science. The\nstudy is based on two different sets of bibliometric data: (1) The number of\npublications held as source items in the Web of Science (WoS, Thomson Reuters)\nper publication year and (2) the number of cited references in the publications\nof the source items per cited reference year. We have looked at the rate at\nwhich science has grown since the mid-1600s. In our analysis of cited\nreferences we identified three growth phases in the development of science,\nwhich each led to growth rates tripling in comparison with the previous phase:\nfrom less than 1% up to the middle of the 18th century, to 2 to 3% up to the\nperiod between the two world wars and 8 to 9% to 2012.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2014 08:00:26 GMT"}, {"version": "v2", "created": "Wed, 30 Apr 2014 13:43:25 GMT"}, {"version": "v3", "created": "Thu, 8 May 2014 07:38:15 GMT"}], "update_date": "2014-05-09", "authors_parsed": [["Bornmann", "Lutz", ""], ["Mutz", "Ruediger", ""]]}, {"id": "1402.4732", "submitter": "Thomas Lasko", "authors": "Thomas A. Lasko", "title": "Efficient Inference of Gaussian Process Modulated Renewal Processes with\n  Application to Medical Event Data", "comments": "8 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": "VU-DBMI-2014-01-001", "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The episodic, irregular and asynchronous nature of medical data render them\ndifficult substrates for standard machine learning algorithms. We would like to\nabstract away this difficulty for the class of time-stamped categorical\nvariables (or events) by modeling them as a renewal process and inferring a\nprobability density over continuous, longitudinal, nonparametric intensity\nfunctions modulating that process. Several methods exist for inferring such a\ndensity over intensity functions, but either their constraints and assumptions\nprevent their use with our potentially bursty event streams, or their time\ncomplexity renders their use intractable on our long-duration observations of\nhigh-resolution events, or both. In this paper we present a new and efficient\nmethod for inferring a distribution over intensity functions that uses direct\nnumeric integration and smooth interpolation over Gaussian processes. We\ndemonstrate that our direct method is up to twice as accurate and two orders of\nmagnitude more efficient than the best existing method (thinning). Importantly,\nthe direct method can infer intensity functions over the full range of bursty\nto memoryless to regular events, which thinning and many other methods cannot.\nFinally, we apply the method to clinical event data and demonstrate the\nface-validity of the abstraction, which is now amenable to standard learning\nalgorithms.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2014 17:09:14 GMT"}], "update_date": "2014-02-20", "authors_parsed": [["Lasko", "Thomas A.", ""]]}, {"id": "1402.5257", "submitter": "Minho Park", "authors": "M. Park and K. A. Cliffe", "title": "Conditional Multilevel Monte Carlo Simulation of Groundwater Flow in the\n  Culebra Dolomite at the Waste Isolation Pilot Plant (WIPP) Site", "comments": "16 pages, 13 figures, and 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extended the multilevel Monte of Carlo (MLMC) approach to simulation of\ngroundwater flow in porous media by incorporating direct measurements of medium\nproperties. Numerical simulations of Waste Isolation Pilot Plant (WIPP)\nrepository in southeastern New Mexico are performed to test the performance of\nthe conditional MLMC technique. The log-transmissivity of WIPP site is modeled\nas the conditional random fields which honor exact field values at a few\nlocations. The conditional random fields are generated through the modified\ncirculant embedding methods in (Dietrich and Newsam, 1996). We also study\neffects of a combination of the conditional MLMC accompanied by antithetic\nvariates. The main quantity of interest is the time of radionuclides travelling\nfrom the center of repository to the site boundary. Numerical examples are\npresented to demonstrate the cost-effectiveness of the multilevel approach in\ncomparison to the standard Monte Carlo (MC) simulation.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2014 11:20:42 GMT"}], "update_date": "2014-02-24", "authors_parsed": [["Park", "M.", ""], ["Cliffe", "K. A.", ""]]}, {"id": "1402.5319", "submitter": "Vincent Miele", "authors": "Vincent Miele and Franck Picard and St\\'ephane Dray", "title": "Spatially-constrained clustering of ecological networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spatial ecological networks are widely used to model interactions between\ngeoreferenced biological entities (e.g., populations or communities). The\nanalysis of such data often leads to a two-step approach where groups\ncontaining similar biological entities are firstly identified and the spatial\ninformation is used afterwards to improve the ecological interpretation. We\ndevelop an integrative approach to retrieve groups of nodes that are\ngeographically close and ecologically similar. Our model-based\nspatially-constrained method embeds the geographical information within a\nregularization framework by adding some constraints to the maximum likelihood\nestimation of parameters. A simulation study and the analysis of real data\ndemonstrate that our approach is able to detect complex spatial patterns that\nare ecologically meaningful. The model-based framework allows us to consider\nexternal information (e.g., geographic proximities, covariates) in the analysis\nof ecological networks and appears to be an appealing alternative to consider\nsuch data.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2014 15:06:57 GMT"}], "update_date": "2014-02-24", "authors_parsed": [["Miele", "Vincent", ""], ["Picard", "Franck", ""], ["Dray", "St\u00e9phane", ""]]}, {"id": "1402.5321", "submitter": "Michael GB Blum", "authors": "N. Duforet-Frebourg, E. Bazin, M.G.B. Blum", "title": "Genome scans for detecting footprints of local adaptation using a\n  Bayesian factor model", "comments": "This work has been partially supported by the LabEx PERSYVAL-Lab\n  (ANR-11-LABX-0025-01),Molecular Biology and Evolution 2014", "journal-ref": null, "doi": "10.1093/molbev/msu182", "report-no": null, "categories": "q-bio.PE stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A central part of population genomics consists of finding genomic regions\nimplicated in local adaptation. Population genomic analyses are based on\ngenotyping numerous molecular markers and looking for outlier loci in terms of\npatterns of genetic differentiation. One of the most common approach for\nselection scan is based on statistics that measure population differentiation\nsuch as $F_{ST}$. However they are important caveats with approaches related to\n$F_{ST}$ because they require grouping individuals into populations and they\nadditionally assume a particular model of population structure. Here we\nimplement a more flexible individual-based approach based on Bayesian factor\nmodels. Factor models capture population structure with latent variables called\nfactors, which can describe clustering of individuals into populations or\nisolation-by-distance patterns. Using hierarchical Bayesian modeling, we both\ninfer population structure and identify outlier loci that are candidates for\nlocal adaptation. As outlier loci, the hierarchical factor model searches for\nloci that are atypically related to population structure as measured by the\nlatent factors. In a model of population divergence, we show that the factor\nmodel can achieve a 2-fold or more reduction of false discovery rate compared\nto the software BayeScan or compared to a $F_{ST}$ approach. We analyze the\ndata of the Human Genome Diversity Panel to provide an example of how factor\nmodels can be used to detect local adaptation with a large number of SNPs. The\nBayesian factor model is implemented in the open-source PCAdapt software.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2014 15:09:06 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2014 20:02:22 GMT"}, {"version": "v3", "created": "Sun, 23 Mar 2014 10:55:28 GMT"}, {"version": "v4", "created": "Tue, 29 Jul 2014 11:40:36 GMT"}], "update_date": "2014-07-30", "authors_parsed": [["Duforet-Frebourg", "N.", ""], ["Bazin", "E.", ""], ["Blum", "M. G. B.", ""]]}, {"id": "1402.5360", "submitter": "Chanabasayya Vastrad M", "authors": "Doreswamy, Chanabasayya M. Vastrad", "title": "Important Molecular Descriptors Selection Using Self Tuned Reweighted\n  Sampling Method for Prediction of Antituberculosis Activity", "comments": "published 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.AP stat.ML", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  In this paper, a new descriptor selection method for selecting an optimal\ncombination of important descriptors of sulfonamide derivatives data, named\nself tuned reweighted sampling (STRS), is developed. descriptors are defined as\nthe descriptors with large absolute coefficients in a multivariate linear\nregression model such as partial least squares(PLS). In this study, the\nabsolute values of regression coefficients of PLS model are used as an index\nfor evaluating the importance of each descriptor Then, based on the importance\nlevel of each descriptor, STRS sequentially selects N subsets of descriptors\nfrom N Monte Carlo (MC) sampling runs in an iterative and competitive manner.\nIn each sampling run, a fixed ratio (e.g. 80%) of samples is first randomly\nselected to establish a regresson model. Next, based on the regression\ncoefficients, a two-step procedure including rapidly decreasing function (RDF)\nbased enforced descriptor selection and self tuned sampling (STS) based\ncompetitive descriptor selection is adopted to select the important\ndescriptorss. After running the loops, a number of subsets of descriptors are\nobtained and root mean squared error of cross validation (RMSECV) of PLS models\nestablished with subsets of descriptors is computed. The subset of descriptors\nwith the lowest RMSECV is considered as the optimal descriptor subset. The\nperformance of the proposed algorithm is evaluated by sulfanomide derivative\ndataset. The results reveal an good characteristic of STRS that it can usually\nlocate an optimal combination of some important descriptors which are\ninterpretable to the biologically of interest. Additionally, our study shows\nthat better prediction is obtained by STRS when compared to full descriptor set\nPLS modeling, Monte Carlo uninformative variable elimination (MC-UVE).\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2014 17:24:53 GMT"}], "update_date": "2014-02-24", "authors_parsed": [["Doreswamy", "", ""], ["Vastrad", "Chanabasayya M.", ""]]}, {"id": "1402.5383", "submitter": "Sergii Koliada", "authors": "Sergii Koliada", "title": "Statistical tests for a sequence of random numbers by using the\n  distribution function of random distance in three dimensions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The distribution function of a random distance in three dimensions is given\nand some new three-dimensional d2-tests of randomness are suggested. We show\nthat our test statistics are not correlated with the usual test statistics and\nare therefore an other promising way to determine the quality of generated\nrandom numbers.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2014 18:59:59 GMT"}], "update_date": "2014-02-24", "authors_parsed": [["Koliada", "Sergii", ""]]}, {"id": "1402.5447", "submitter": "Nicol\\'o  Fusi", "authors": "Nicolo Fusi, Christoph Lippert, Neil D. Lawrence and Oliver Stegle", "title": "Genetic Analysis of Transformed Phenotypes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linear mixed models (LMMs) are a powerful and established tool for studying\ngenotype-phenotype relationships. A limiting assumption of LMMs is that the\nresiduals are Gaussian distributed, a requirement that rarely holds in\npractice. Violations of this assumption can lead to false conclusions and\nlosses in power, and hence it is common practice to pre-process the phenotypic\nvalues to make them Gaussian, for instance by applying logarithmic or other\nnon-linear transformations. Unfortunately, different phenotypes require\ndifferent specific transformations, and choosing a \"good\" transformation is in\ngeneral challenging and subjective. Here, we present an extension of the LMM\nthat estimates an optimal transformation from the observed data. In extensive\nsimulations and applications to real data from human, mouse and yeast we show\nthat using such optimal transformations lead to increased power in genome-wide\nassociation studies and higher accuracy in heritability estimates and phenotype\npredictions.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2014 23:28:52 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2014 03:26:22 GMT"}], "update_date": "2014-08-10", "authors_parsed": [["Fusi", "Nicolo", ""], ["Lippert", "Christoph", ""], ["Lawrence", "Neil D.", ""], ["Stegle", "Oliver", ""]]}, {"id": "1402.5581", "submitter": "Ilya Soloveychik", "authors": "Ilya Soloveychik", "title": "Error Bound for Compound Wishart Matrices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider non-asymptotic behavior of the real compound\nWishart matrices that generalize the classical real Wishart distribution. In\nparticular, we consider matrices of the form 1/nXBX', where X consists of real\ncentered Gaussian elements and B is an arbitrary real matrix and sequences of\nsuch matrices for varying n. We show how the expectation of deviations from the\nmean can be bounded for compound Wishart matrices.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2014 06:30:17 GMT"}, {"version": "v2", "created": "Wed, 12 Mar 2014 18:37:50 GMT"}], "update_date": "2014-03-13", "authors_parsed": [["Soloveychik", "Ilya", ""]]}, {"id": "1402.5607", "submitter": "Enkelejd Hashorva", "authors": "Enkelejd Hashorva, Liang Peng, Zhichao Weng", "title": "Maxima of a triangular array of multivariate Gaussian sequence", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is known that the normalized maxima of a sequence of independent and\nidentically distributed bivariate normal random vectors with correlation\ncoefficient $\\rho \\in (-1,1)$ is asymptotically independent, which may\nseriously underestimate extreme probabilities in practice. By letting $\\rho$\ndepend on the sample size and go to one with certain rate, H\\\"usler and Reiss\n(1989) showed that the normalized maxima can become asymptotically dependent.\nIn this paper, we extend such a study to a triangular array of multivariate\nGaussian sequence, which further generalizes the results in Hsing, H\\\"usler and\nReiss (1996) and Hashorva and Weng (2013).\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2014 13:46:14 GMT"}], "update_date": "2014-02-25", "authors_parsed": [["Hashorva", "Enkelejd", ""], ["Peng", "Liang", ""], ["Weng", "Zhichao", ""]]}, {"id": "1402.5608", "submitter": "Enkelejd Hashorva", "authors": "E. Hashorva, Z. Peng, Z. Weng", "title": "Higher-order expansions of distributions of maxima in a H\\\"{u}sler-Reiss\n  model", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The max-stable H\\\"usler-Reiss distribution which arises as the limit\ndistribution of maxima of bivariate Gaussian triangular arrays has been shown\nto be useful in various extreme value models. For such triangular arrays, this\npaper establishes higher-order asymptotic expansions of the joint distribution\nof maxima under refined H\\\"{u}sler-Reiss conditions. In particular, the rate of\nconvergence of normalized maxima to the H\\\"usler-Reiss distribution is\nexplicitly calculated.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2014 14:04:10 GMT"}], "update_date": "2014-02-25", "authors_parsed": [["Hashorva", "E.", ""], ["Peng", "Z.", ""], ["Weng", "Z.", ""]]}, {"id": "1402.5991", "submitter": "Issac Shams", "authors": "Issac Shams, Saeede Ajorlou, Kai Yang", "title": "A predictive analytics approach to reducing avoidable hospital\n  readmission", "comments": "30 pages, 4 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hospital readmission has become a critical metric of quality and cost of\nhealthcare. Medicare anticipates that nearly $17 billion is paid out on the 20%\nof patients who are readmitted within 30 days of discharge. Although several\ninterventions such as transition care management and discharge reengineering\nhave been practiced in recent years, the effectiveness and sustainability\ndepends on how well they can identify and target patients at high risk of\nrehospitalization. Based on the literature, most current risk prediction models\nfail to reach an acceptable accuracy level; none of them considers patient's\nhistory of readmission and impacts of patient attribute changes over time; and\nthey often do not discriminate between planned and unnecessary readmissions.\nTackling such drawbacks, we develop a new readmission metric based on\nadministrative data that can identify potentially avoidable readmissions from\nall other types of readmission. We further propose a tree based classification\nmethod to estimate the predicted probability of readmission that can directly\nincorporate patient's history of readmission and risk factors changes over\ntime. The proposed methods are validated with 2011-12 Veterans Health\nAdministration data from inpatients hospitalized for heart failure, acute\nmyocardial infarction, pneumonia, or chronic obstructive pulmonary disease in\nthe State of Michigan. Results shows improved discrimination power compared to\nthe literature (c-statistics>80%) and good calibration.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2014 21:37:25 GMT"}, {"version": "v2", "created": "Wed, 12 Mar 2014 23:42:51 GMT"}], "update_date": "2014-03-14", "authors_parsed": [["Shams", "Issac", ""], ["Ajorlou", "Saeede", ""], ["Yang", "Kai", ""]]}, {"id": "1402.6089", "submitter": "David Degras", "authors": "David Degras and Martin A. Lindquist", "title": "A hierarchical model for simultaneous detection and estimation in\n  multi-subject fMRI Studies", "comments": null, "journal-ref": "NeuroImage 98, 2014, p. 61-72", "doi": "10.1016/j.neuroimage.2014.04.052", "report-no": null, "categories": "stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce a new hierarchical model for the simultaneous\ndetection of brain activation and estimation of the shape of the hemodynamic\nresponse in multi-subject fMRI studies. The proposed approach circumvents a\nmajor stumbling block in standard multi-subject fMRI data analysis, in that it\nboth allows the shape of the hemodynamic response function to vary across\nregion and subjects, while still providing a straightforward way to estimate\npopulation-level activation. An efficient estimation algorithm is presented, as\nis an inferential framework that not only allows for tests of activation, but\nalso for tests for deviations from some canonical shape. The model is validated\nthrough simulations and application to a multi-subject fMRI study of thermal\npain.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2014 08:35:14 GMT"}, {"version": "v2", "created": "Sat, 29 Mar 2014 20:56:11 GMT"}], "update_date": "2015-11-13", "authors_parsed": [["Degras", "David", ""], ["Lindquist", "Martin A.", ""]]}, {"id": "1402.6151", "submitter": "Oscar Sotolongo-Grau", "authors": "Jos\\'e Santiago Garc\\'ia-Cremades, Angel del R\\'io, Jos\\'e A.\n  Garc\\'ia, Javier Gay\\'an, Antonio Gonz\\'alez-P\\'erez, Agust\\'in Ruiz, O.\n  Sotolongo-Grau and Manuel Ruiz-Mar\\'in", "title": "Approaching allelic probabilities and Genome-Wide Association Studies\n  from beta distributions", "comments": "24 pages, 16 figures, to be submitted to publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN q-bio.PE stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we have proposed a model for the distribution of allelic\nprobabilities for generating populations as reliably as possible. Our objective\nwas to develop such a model which would allow simulating allelic probabilities\nwith different observed truncation and de- gree of noise. In addition, we have\nalso introduced here a complete new approach to analyze a genome-wide\nassociation study (GWAS) dataset, starting from a new test of association with\na statistical distribution and two effect sizes of each genotype. The new\nmethodologi- cal approach was applied to a real data set together with a Monte\nCarlo experiment which showed the power performance of our new method. Finally,\nwe compared the new method based on beta distribution with the conventional\nmethod (based on Chi-Squared distribu- tion) using the agreement Kappa index\nand a principal component analysis (PCA). Both the analyses show found\ndifferences existed between both the approaches while selecting the single\nnucleotide polymorphisms (SNPs) in association.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2014 12:33:58 GMT"}], "update_date": "2014-02-26", "authors_parsed": [["Garc\u00eda-Cremades", "Jos\u00e9 Santiago", ""], ["del R\u00edo", "Angel", ""], ["Garc\u00eda", "Jos\u00e9 A.", ""], ["Gay\u00e1n", "Javier", ""], ["Gonz\u00e1lez-P\u00e9rez", "Antonio", ""], ["Ruiz", "Agust\u00edn", ""], ["Sotolongo-Grau", "O.", ""], ["Ruiz-Mar\u00edn", "Manuel", ""]]}, {"id": "1402.6302", "submitter": "Enkelejd Hashorva", "authors": "E. Hashorva, C. Ling, Z. Peng", "title": "Tail Asymptotic Expansions for L-Statistics", "comments": null, "journal-ref": "Science China Mathematics, 57(10), 1993-2012", "doi": "10.1007/s11425-014-4841-z", "report-no": null, "categories": "math.PR stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we derive higher-order expansions of $L$-statistics of\nindependent risks $X_1, \\ldots, X_n$ under conditions on the underlying\ndistribution function $F$. The new results are applied to derive the asymptotic\nexpansions of ratios of two kinds of risk measures, stop-loss premium and\nexcess return on capital, respectively.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2014 20:28:22 GMT"}], "update_date": "2014-10-08", "authors_parsed": [["Hashorva", "E.", ""], ["Ling", "C.", ""], ["Peng", "Z.", ""]]}, {"id": "1402.6666", "submitter": "Saeede Ajorlou", "authors": "Saeede Ajorlou, Issac Shams, Kai Yang", "title": "An analytics approach to designing patient centered medical homes", "comments": "36 pages, 6 figures, 8 tables, submitted to health care management\n  science", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently the patient-centered medical home (PCMH) model has become a popular\nteam-based approach focused on delivering more streamlined care to patients. In\ncurrent practices of medical homes, a clinical-based prediction frame is\nrecommended because it can help match the portfolio capacity of PCMH teams with\nthe actual load generated by a set of patients. Without such balances in\nclinical supply and demand, issues such as excessive under and over utilization\nof physicians, long waiting time for receiving the appropriate treatment, and\nnon-continuity of care will eliminate many advantages of the medical home\nstrategy. In this paper, by extending the hierarchical generalized linear model\nto include multivariate responses, we develop a clinical workload prediction\nmodel for care portfolio demands in a Bayesian framework. The model allows for\nheterogeneous variances and unstructured covariance matrices for nested random\neffects that arise through complex hierarchical care systems. We show that\nusing a multivariate approach substantially enhances the precision of workload\npredictions at both primary and non-primary care levels. We also demonstrate\nthat care demands depend not only on patient demographics but also on other\nutilization factors, such as length of stay. Our analyses of a recent data from\nVeteran Health Administration further indicate that risk adjustment for patient\nhealth conditions can considerably improve the prediction power of the model.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2014 20:14:20 GMT"}], "update_date": "2014-02-27", "authors_parsed": [["Ajorlou", "Saeede", ""], ["Shams", "Issac", ""], ["Yang", "Kai", ""]]}, {"id": "1402.6720", "submitter": "Edgar Merkle", "authors": "Edgar C. Merkle, Dongjun You, Kristopher J. Preacher", "title": "Testing non-nested structural equation models", "comments": "24 pages, 6 figures", "journal-ref": "Psychological Methods 21 (2016) 151-163", "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we apply Vuong's (1989) likelihood ratio tests of non-nested\nmodels to the comparison of non-nested structural equation models. Similar\ntests have been previously applied in SEM contexts (especially to mixture\nmodels), though the non-standard output required to conduct the tests has\nlimited their previous use and study. We review the theory underlying the tests\nand show how they can be used to construct interval estimates for differences\nin non-nested information criteria. Through both simulation and application, we\nthen study the tests' performance in non-mixture SEMs and describe their\ngeneral implementation via free R packages. The tests offer researchers a\nuseful tool for non-nested SEM comparison, with barriers to test implementation\nnow removed.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2014 21:46:01 GMT"}, {"version": "v2", "created": "Wed, 8 Oct 2014 21:20:23 GMT"}, {"version": "v3", "created": "Tue, 12 May 2015 20:20:42 GMT"}], "update_date": "2016-11-18", "authors_parsed": [["Merkle", "Edgar C.", ""], ["You", "Dongjun", ""], ["Preacher", "Kristopher J.", ""]]}, {"id": "1402.6951", "submitter": "Drausin Wulsin", "authors": "Drausin F. Wulsin, Emily B. Fox, Brian Litt", "title": "Modeling the Complex Dynamics and Changing Correlations of Epileptic\n  Events", "comments": null, "journal-ref": null, "doi": "10.1016/j.artint.2014.05.006", "report-no": null, "categories": "stat.ML q-bio.NC stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Patients with epilepsy can manifest short, sub-clinical epileptic \"bursts\" in\naddition to full-blown clinical seizures. We believe the relationship between\nthese two classes of events---something not previously studied\nquantitatively---could yield important insights into the nature and intrinsic\ndynamics of seizures. A goal of our work is to parse these complex epileptic\nevents into distinct dynamic regimes. A challenge posed by the intracranial EEG\n(iEEG) data we study is the fact that the number and placement of electrodes\ncan vary between patients. We develop a Bayesian nonparametric Markov switching\nprocess that allows for (i) shared dynamic regimes between a variable number of\nchannels, (ii) asynchronous regime-switching, and (iii) an unknown dictionary\nof dynamic regimes. We encode a sparse and changing set of dependencies between\nthe channels using a Markov-switching Gaussian graphical model for the\ninnovations process driving the channel dynamics and demonstrate the importance\nof this model in parsing and out-of-sample predictions of iEEG data. We show\nthat our model produces intuitive state assignments that can help automate\nclinical analysis of seizures and enable the comparison of sub-clinical bursts\nand full clinical seizures.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2014 16:09:09 GMT"}, {"version": "v2", "created": "Mon, 14 Jul 2014 01:37:35 GMT"}], "update_date": "2014-07-29", "authors_parsed": [["Wulsin", "Drausin F.", ""], ["Fox", "Emily B.", ""], ["Litt", "Brian", ""]]}, {"id": "1402.6962", "submitter": "Yanxun Xu", "authors": "Yanxun Xu, Lorenzo Trippa, Peter M\\\"uller, Yuan Ji", "title": "Subgroup-Based Adaptive (SUBA) Designs for Multi-Arm Biomarker Trials", "comments": null, "journal-ref": null, "doi": "10.1007/s12561-014-9117-1", "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Targeted therapies based on biomarker profiling are becoming a mainstream\ndirection of cancer research and treatment. Depending on the expression of\nspecific prognostic biomarkers, targeted therapies assign different cancer\ndrugs to subgroups of patients even if they are diagnosed with the same type of\ncancer by traditional means, such as tumor location. For example, Herceptin is\nonly indicated for the subgroup of patients with HER2+ breast cancer, but not\nother types of breast cancer. However, subgroups like HER2+ breast cancer with\neffective targeted therapies are rare and most cancer drugs are still being\napplied to large patient populations that include many patients who might not\nrespond or benefit. Also, the response to targeted agents in human is usually\nunpredictable. To address these issues, we propose SUBA, subgroup-based\nadaptive designs that simultaneously search for prognostic subgroups and\nallocate patients adaptively to the best subgroup-specific treatments\nthroughout the course of the trial. The main features of SUBA include the\ncontinuous reclassification of patient subgroups based on a random partition\nmodel and the adaptive allocation of patients to the best treatment arm based\non posterior predictive probabilities. We compare the SUBA design with three\nalternative designs including equal randomization, outcome-adaptive\nrandomization and a design based on a probit regression. In simulation studies\nwe find that SUBA compares favorably against the alternatives.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2014 16:38:23 GMT"}], "update_date": "2015-03-24", "authors_parsed": [["Xu", "Yanxun", ""], ["Trippa", "Lorenzo", ""], ["M\u00fcller", "Peter", ""], ["Ji", "Yuan", ""]]}, {"id": "1402.7027", "submitter": "Rick Steinert", "authors": "Florian Ziel, Rick Steinert and Sven Husmann", "title": "Efficient Modeling and Forecasting of the Electricity Spot Price", "comments": null, "journal-ref": "Energy Economics, 47 (2015) 98-111", "doi": "10.1016/j.eneco.2014.10.012", "report-no": null, "categories": "stat.AP econ.EM q-fin.ST q-fin.TR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing importance of renewable energy, especially solar and wind\npower, has led to new forces in the formation of electricity prices. Hence,\nthis paper introduces an econometric model for the hourly time series of\nelectricity prices of the European Power Exchange (EPEX) which incorporates\nspecific features like renewable energy. The model consists of several\nsophisticated and established approaches and can be regarded as a periodic\nVAR-TARCH with wind power, solar power, and load as influences on the time\nseries. It is able to map the distinct and well-known features of electricity\nprices in Germany. An efficient iteratively reweighted lasso approach is used\nfor the estimation. Moreover, it is shown that several existing models are\noutperformed by the procedure developed in this paper.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2014 19:18:21 GMT"}, {"version": "v2", "created": "Tue, 26 Aug 2014 11:45:13 GMT"}, {"version": "v3", "created": "Mon, 8 Sep 2014 10:33:59 GMT"}, {"version": "v4", "created": "Mon, 13 Oct 2014 09:46:09 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Ziel", "Florian", ""], ["Steinert", "Rick", ""], ["Husmann", "Sven", ""]]}, {"id": "1402.7079", "submitter": "Kaisey Mandel", "authors": "Kaisey S. Mandel, Ryan J. Foley, Robert P. Kirshner", "title": "Type Ia Supernova Colors and Ejecta Velocities: Hierarchical Bayesian\n  Regression with Non-Gaussian Distributions", "comments": "accepted for publication in ApJ; expanded analysis & discussion,\n  results unchanged", "journal-ref": "Astrophys.J.797,75,2014", "doi": "10.1088/0004-637X/797/2/75", "report-no": null, "categories": "astro-ph.CO stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the statistical dependence of the peak intrinsic colors of\nType Ia supernovae (SN Ia) on their expansion velocities at maximum light,\nmeasured from the Si II 6355 spectral feature. We construct a new hierarchical\nBayesian regression model, accounting for the random effects of intrinsic\nscatter, measurement error, and reddening by host galaxy dust, and implement a\nGibbs sampler and deviance information criteria to estimate the correlation.\nThe method is applied to the apparent colors from BVRI light curves and Si II\nvelocity data for 79 nearby SNe Ia. The apparent color distributions of high\n(HV) and normal velocity (NV) supernovae exhibit significant discrepancies for\nB-V and B-R, but not other colors. Hence, they are likely due to intrinsic\ncolor differences originating in the B-band, rather than dust reddening. The\nmean intrinsic B-V and B-R color differences between HV and NV groups are 0.06\n+/- 0.02 and 0.09 +/- 0.02 mag, respectively. A linear model finds significant\nslopes of -0.021 +/- 0.006 and -0.030 +/- 0.009 mag/(1000 km/s) for intrinsic\nB-V and B-R colors versus velocity, respectively. Since the ejecta velocity\ndistribution is skewed towards high velocities, these effects imply\nnon-Gaussian intrinsic color distributions with skewness up to +0.3. Accounting\nfor the intrinsic color-velocity correlation results in corrections to A_V\nextinction estimates as large as -0.12 mag for HV SNe Ia and +0.06 mag for NV\nevents. Velocity measurements from SN Ia spectra have potential to diminish\nsystematic errors from the confounding of intrinsic colors and dust reddening\naffecting supernova distances.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2014 21:00:22 GMT"}, {"version": "v2", "created": "Wed, 5 Mar 2014 07:00:30 GMT"}, {"version": "v3", "created": "Thu, 27 Nov 2014 07:26:12 GMT"}], "update_date": "2014-12-01", "authors_parsed": [["Mandel", "Kaisey S.", ""], ["Foley", "Ryan J.", ""], ["Kirshner", "Robert P.", ""]]}, {"id": "1402.7112", "submitter": "Issac Shams", "authors": "Issac Shams, Saeede Ajorlou, Kai Yang", "title": "On modeling nonhomogeneous Poisson process for stochastic simulation\n  input analysis", "comments": "This paper has been withdrawn by the author due to an error in table\n  1", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A validated simulation model primarily requires performing an appropriate\ninput analysis mainly by determining the behavior of real-world processes using\nprobability distributions. In many practical cases, probability distributions\nof the random inputs vary over time in such a way that the functional forms of\nthe distributions and/or their parameters depend on time. This paper answers\nthe question whether a sequence of observations from a process follows the same\nstatistical distribution, and if not, where the exact change points are. We\npropose a Likelihood Ratio Test (LRT) based method to detect multiple change\npoints when observations follow non-stationary Poisson process with diverse\noccurrence rates over time. Results from a comprehensive Monte Carlo study\nindicate satisfactory performance for the proposed method.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2014 00:40:42 GMT"}, {"version": "v2", "created": "Fri, 29 Aug 2014 02:50:16 GMT"}], "update_date": "2014-09-01", "authors_parsed": [["Shams", "Issac", ""], ["Ajorlou", "Saeede", ""], ["Yang", "Kai", ""]]}, {"id": "1402.7141", "submitter": "Bertrand Iooss", "authors": "Anne-Laure Popelin, Bertrand Iooss (- M\\'ethodes d'Analyse\n  Stochastique des Codes et Traitements Num\\'eriques, IMT)", "title": "Visualization tools for uncertainty and sensitivity analyses on\n  thermal-hydraulic transients", "comments": null, "journal-ref": "Joint International Conference on Supercomputing in Nuclear\n  Applications and Monte Carlo 2013 (SNA + MC 2013), Paris : France (2013)", "doi": "10.1051/snamc/201403403", "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In nuclear engineering studies, uncertainty and sensitivity analyses of\nsimulation computer codes can be faced to the complexity of the input and/or\nthe output variables. If these variables represent a transient or a spatial\nphenomenon, the difficulty is to provide tool adapted to their functional\nnature. In this paper, we describe useful visualization tools in the context of\nuncertainty analysis of model transient outputs. Our application involves\nthermal-hydraulic computations for safety studies of nuclear pressurized water\nreactors.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2014 06:11:33 GMT"}], "update_date": "2015-06-18", "authors_parsed": [["Popelin", "Anne-Laure", "", "- M\u00e9thodes d'Analyse\n  Stochastique des Codes et Traitements Num\u00e9riques, IMT"], ["Iooss", "Bertrand", "", "- M\u00e9thodes d'Analyse\n  Stochastique des Codes et Traitements Num\u00e9riques, IMT"]]}, {"id": "1402.7160", "submitter": "Ryosuke Yano", "authors": "Ryosuke Yano, Arnaud Martin", "title": "Opinion formation with upper and lower bounds", "comments": "We revised in April 2014", "journal-ref": null, "doi": "10.1140/epjb/e2015-60575-5", "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the opinion formation with upper and lower bounds. We\nformulate the binary exchange of opinions between two individuals, and effects\nof the self-thinking and political party using the relativistic\nBoltzmann-Vlasov type equation with the randomly perturbed motion. The\nconvergent form of the distribution function is determined by the balance\nbetween the cooling rate via the binary exchange of opinions between two\nindividuals and the concentration of opinions by the political party, and\nheating rate via the self-thinking.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2014 08:13:10 GMT"}, {"version": "v2", "created": "Sat, 26 Apr 2014 07:50:37 GMT"}, {"version": "v3", "created": "Mon, 23 Nov 2015 09:46:50 GMT"}], "update_date": "2016-01-20", "authors_parsed": [["Yano", "Ryosuke", ""], ["Martin", "Arnaud", ""]]}, {"id": "1402.7203", "submitter": "Morgane Pierre-Jean", "authors": "Morgane Pierre-Jean (LaMME), Guillem Rigaill (URGV), Pierre Neuvial\n  (LaMME)", "title": "Performance evaluation of DNA copy number segmentation methods", "comments": null, "journal-ref": "Briefings in Bioinformatics, Oxford University Press (OUP), 2015,\n  16 (4)", "doi": "10.1093/bib/bbu026", "report-no": null, "categories": "q-bio.QM stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A number of bioinformatic or biostatistical methods are available for\nanalyzing DNA copy number profiles measured from microarray or sequencing\ntechnologies. In the absence of rich enough gold standard data sets, the\nperformance of these methods is generally assessed using unrealistic simulation\nstudies, or based on small real data analyses. We have designed and implemented\na framework to generate realistic DNA copy number profiles of cancer samples\nwith known truth. These profiles are generated by resampling real SNP\nmicroarray data from genomic regions with known copy-number state. The original\nreal data have been extracted from dilutions series of tumor cell lines with\nmatched blood samples at several concentrations. Therefore, the signal-to-noise\nratio of the generated profiles can be controlled through the (known)\npercentage of tumor cells in the sample. In this paper, we describe this\nframework and illustrate some of the benefits of the proposed data generation\napproach on a practical use case: a comparison study between methods for\nsegmenting DNA copy number profiles from SNP microarrays. This study indicates\nthat no single method is uniformly better than all others. It also helps\nidentifying pros and cons for the compared methods as a function of\nbiologically informative parameters, such as the fraction of tumor cells in the\nsample and the proportion of heterozygous markers. Availability: R package\njointSeg: http://r-forge.r-project.org/R/?group\\_id=1562\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2014 11:11:24 GMT"}, {"version": "v2", "created": "Thu, 5 Nov 2015 15:34:46 GMT"}], "update_date": "2015-11-06", "authors_parsed": [["Pierre-Jean", "Morgane", "", "LaMME"], ["Rigaill", "Guillem", "", "URGV"], ["Neuvial", "Pierre", "", "LaMME"]]}]