[{"id": "1207.0187", "submitter": "Ruth Heller", "authors": "Marina Bogomolov and Ruth Heller", "title": "Discovering findings that replicate from a primary study of high\n  dimension to a follow-up study", "comments": null, "journal-ref": "Journal of the American Statistical Association Volume 108, Issue\n  504, 2013", "doi": "10.1080/01621459.2013.829002", "report-no": "arXiv:1207.0187v3", "categories": "stat.ME math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of identifying whether findings replicate from one\nstudy of high dimension to another, when the primary study guides the selection\nof hypotheses to be examined in the follow-up study as well as when there is no\ndivision of roles into the primary and the follow-up study. We show that\nexisting meta-analysis methods are not appropriate for this problem, and\nsuggest novel methods instead. We prove that our multiple testing procedures\ncontrol for appropriate error-rates. The suggested FWER controlling procedure\nis valid for arbitrary dependence among the test statistics within each study.\nA more powerful procedure is suggested for FDR control. We prove that this\nprocedure controls the FDR if the test statistics are independent within the\nprimary study, and independent or have dependence of type PRDS in the follow-up\nstudy. For arbitrary dependence within the primary study, and either arbitrary\ndependence or dependence of type PRDS in the follow-up study, simple\nconservative modifications of the procedure control the FDR. We demonstrate the\nusefulness of these procedures via simulations and real data examples.\n", "versions": [{"version": "v1", "created": "Sun, 1 Jul 2012 07:02:29 GMT"}, {"version": "v2", "created": "Wed, 26 Dec 2012 14:49:35 GMT"}, {"version": "v3", "created": "Fri, 24 May 2013 05:49:51 GMT"}], "update_date": "2014-01-28", "authors_parsed": [["Bogomolov", "Marina", ""], ["Heller", "Ruth", ""]]}, {"id": "1207.0188", "submitter": "Duy Q. Vu", "authors": "Duy Q. Vu, David R. Hunter, Michael Schweinberger", "title": "Model-based clustering of large networks", "comments": "Published in at http://dx.doi.org/10.1214/12-AOAS617 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2013, Vol. 7, No. 2, 1010-1039", "doi": "10.1214/12-AOAS617", "report-no": "IMS-AOAS-AOAS617", "categories": "stat.CO cs.SI physics.soc-ph stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a network clustering framework, based on finite mixture models,\nthat can be applied to discrete-valued networks with hundreds of thousands of\nnodes and billions of edge variables. Relative to other recent model-based\nclustering work for networks, we introduce a more flexible modeling framework,\nimprove the variational-approximation estimation algorithm, discuss and\nimplement standard error estimation via a parametric bootstrap approach, and\napply these methods to much larger data sets than those seen elsewhere in the\nliterature. The more flexible framework is achieved through introducing novel\nparameterizations of the model, giving varying degrees of parsimony, using\nexponential family models whose structure may be exploited in various\ntheoretical and algorithmic ways. The algorithms are based on variational\ngeneralized EM algorithms, where the E-steps are augmented by a\nminorization-maximization (MM) idea. The bootstrapped standard error estimates\nare based on an efficient Monte Carlo network simulation idea. Last, we\ndemonstrate the usefulness of the model-based clustering framework by applying\nit to a discrete-valued network with more than 131,000 nodes and 17 billion\nedge variables.\n", "versions": [{"version": "v1", "created": "Sun, 1 Jul 2012 08:06:40 GMT"}, {"version": "v2", "created": "Sun, 18 Nov 2012 21:15:28 GMT"}, {"version": "v3", "created": "Tue, 10 Dec 2013 06:46:57 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Vu", "Duy Q.", ""], ["Hunter", "David R.", ""], ["Schweinberger", "Michael", ""]]}, {"id": "1207.0280", "submitter": "George Casella", "authors": "Zhen Li, Vikneswaran Gopal, Xiaobo Li, John M. Davis, George Casella", "title": "Simultaneous SNP identification in association studies with missing data", "comments": "Published in at http://dx.doi.org/10.1214/11-AOAS516 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2012, Vol. 6, No. 2, 432-456", "doi": "10.1214/11-AOAS516", "report-no": "IMS-AOAS-AOAS516", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Association testing aims to discover the underlying relationship between\ngenotypes (usually Single Nucleotide Polymorphisms, or SNPs) and phenotypes\n(attributes, or traits). The typically large data sets used in association\ntesting often contain missing values. Standard statistical methods either\nimpute the missing values using relatively simple assumptions, or delete them,\nor both, which can generate biased results. Here we describe the Bayesian\nhierarchical model BAMD (Bayesian Association with Missing Data). BAMD is a\nGibbs sampler, in which missing values are multiply imputed based upon all of\nthe available information in the data set. We estimate the parameters and prove\nthat updating one SNP at each iteration preserves the ergodic property of the\nMarkov chain, and at the same time improves computational speed. We also\nimplement a model selection option in BAMD, which enables potential detection\nof SNP interactions. Simulations show that unbiased estimates of SNP effects\nare recovered with missing genotype data. Also, we validate associations\nbetween SNPs and a carbon isotope discrimination phenotype that were previously\nreported using a family based method, and discover an additional SNP associated\nwith the trait. BAMD is available as an R-package from\nhttp://cran.r-project.org/package=BAMD\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2012 05:24:50 GMT"}, {"version": "v2", "created": "Tue, 3 Jul 2012 06:46:04 GMT"}], "update_date": "2012-07-04", "authors_parsed": [["Li", "Zhen", ""], ["Gopal", "Vikneswaran", ""], ["Li", "Xiaobo", ""], ["Davis", "John M.", ""], ["Casella", "George", ""]]}, {"id": "1207.0360", "submitter": "Fr\\'ed\\'eric Proia", "authors": "Sophie Bercu and Fr\\'ed\\'eric Pro\\\"ia", "title": "A SARIMAX coupled modelling applied to individual load curves intraday\n  forecasting", "comments": "17 pages, 18 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A dynamic coupled modelling is investigated to take temperature into account\nin the individual energy consumption forecasting. The objective is both to\navoid the inherent complexity of exhaustive SARIMAX models and to take\nadvantage of the usual linear relation between energy consumption and\ntemperature for thermosensitive customers. We first recall some issues related\nto individual load curves forecasting. Then, we propose and study the\nproperties of a dynamic coupled modelling taking temperature into account as an\nexogenous contribution and its application to the intraday prediction of energy\nconsumption. Finally, these theoretical results are illustrated on a real\nindividual load curve. The authors discuss the relevance of such an approach\nand anticipate that it could form a substantial alternative to the commonly\nused methods for energy consumption forecasting of individual customers.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2012 12:36:58 GMT"}], "update_date": "2012-07-03", "authors_parsed": [["Bercu", "Sophie", ""], ["Pro\u00efa", "Fr\u00e9d\u00e9ric", ""]]}, {"id": "1207.0437", "submitter": "Paul Slater", "authors": "Paul B. Slater", "title": "Ordinal and Cardinal Dendrograms Depicting Migration-Based\n  Regionalization of 3,000 + U. S. Counties", "comments": "83 pages, cardinal-scale dendrogram now appended--in addition to\n  originally posted ordinal-scale dendrogram", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.SI stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We have obtained a \"hierarchical regionalization\" of 3,107 county-level units\nof the United States based upon census-recorded 1995-2000 intercounty migration\nflows. The methodology employed was the two-stage (double-standardization and\nstrong component [directed graph] hierarchical clustering) algorithm described\nin the 2009 PNAS (106 [26], E66) letter (arXiv:0904.4863). Various features (e.\ng., cosmopolitan vs. provincial aspects, and indices of isolation) of the\nregionalization have been previously discussed in arXiv:0907.2393,\narXiv:0903.3623 and arXiv:0809.2768. However, due to the lengthy (38-page)\nnature of the associated dendrogram, the detailed tree structure itself was not\nreadily available for inspection. Here, we do present this (county-searchable)\ndendrogram--and invite readers to explore it, based on their particular\ninterests/locations. An ordinal scale--rather than the originally-derived\ncardinal scale of the doubly-standardized values--in which groupings/features\nwere more immediately apparent, was originally presented. Now, we append the\ncardinal-scale dendrogram.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2012 16:22:51 GMT"}, {"version": "v2", "created": "Fri, 27 Jul 2012 18:19:34 GMT"}, {"version": "v3", "created": "Thu, 9 Aug 2012 15:32:46 GMT"}, {"version": "v4", "created": "Wed, 22 Nov 2017 13:22:41 GMT"}, {"version": "v5", "created": "Fri, 5 Apr 2019 20:26:29 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Slater", "Paul B.", ""]]}, {"id": "1207.0520", "submitter": "Pengfei Zang", "authors": "Richard A. Davis, Pengfei Zang, Tian Zheng", "title": "Sparse Vector Autoregressive Modeling", "comments": "39 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The vector autoregressive (VAR) model has been widely used for modeling\ntemporal dependence in a multivariate time series. For large (and even\nmoderate) dimensions, the number of AR coefficients can be prohibitively large,\nresulting in noisy estimates, unstable predictions and difficult-to-interpret\ntemporal dependence. To overcome such drawbacks, we propose a 2-stage approach\nfor fitting sparse VAR (sVAR) models in which many of the AR coefficients are\nzero. The first stage selects non-zero AR coefficients based on an estimate of\nthe partial spectral coherence (PSC) together with the use of BIC. The PSC is\nuseful for quantifying the conditional relationship between marginal series in\na multivariate process. A refinement second stage is then applied to further\nreduce the number of parameters. The performance of this 2-stage approach is\nillustrated with simulation results. The 2-stage approach is also applied to\ntwo real data examples: the first is the Google Flu Trends data and the second\nis a time series of concentration levels of air pollutants.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2012 20:36:13 GMT"}], "update_date": "2013-10-21", "authors_parsed": [["Davis", "Richard A.", ""], ["Zang", "Pengfei", ""], ["Zheng", "Tian", ""]]}, {"id": "1207.0532", "submitter": "Jim Gaffney", "authors": "J. A. Gaffney, D. Clark, V. Sonnad, S. B. Libby", "title": "Bayesian Analysis of Inertial Confinement Fusion Experiments at the\n  National Ignition Facility", "comments": null, "journal-ref": null, "doi": null, "report-no": "LLNL-JRNL-562314-DRAFT", "categories": "physics.plasm-ph physics.data-an stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a Bayesian inference method that allows the efficient\ndetermination of several interesting parameters from complicated\nhigh-energy-density experiments performed on the National Ignition Facility\n(NIF). The model is based on an exploration of phase space using the\nhydrodynamic code HYDRA. A linear model is used to describe the effect of\nnuisance parameters on the analysis, allowing an analytic likelihood to be\nderived that can be determined from a small number of HYDRA runs and then used\nin existing advanced statistical analysis methods. This approach is applied to\na recent experiment in order to determine the carbon opacity and X-ray drive;\nit is found that the inclusion of prior expert knowledge and fluctuations in\ncapsule dimensions and chemical composition significantly improve the agreement\nbetween experiment and theoretical opacity calculations. A parameterisation of\nHYDRA results is used to test the application of both Markov chain Monte Carlo\n(MCMC) and genetic algorithm (GA) techniques to explore the posterior. These\napproaches have distinct advantages and we show that both can allow the\nefficient analysis of high energy density experiments.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2012 22:09:56 GMT"}], "update_date": "2012-07-04", "authors_parsed": [["Gaffney", "J. A.", ""], ["Clark", "D.", ""], ["Sonnad", "V.", ""], ["Libby", "S. B.", ""]]}, {"id": "1207.0558", "submitter": "Sam Clifford", "authors": "Sam Clifford, Bjarke M{\\o}lgaard, Sama Low Choy, Jukka Corander,\n  Kaarle H\\\"ameri, Kerrie Mengersen and Tareq Hussein", "title": "Bayesian semi-parametric forecasting of ultrafine particle number\n  concentration with penalised splines and autoregressive errors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP physics.ao-ph physics.data-an stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Observational time series data often exhibit both cyclic temporal trends and\nautocorrelation and may also depend on covariates. As such, there is a need for\nflexible regression models that are able to capture these trends and model any\nresidual autocorrelation simultaneously. Modelling the autocorrelation in the\nresiduals leads to more realistic forecasts than an assumption of independence.\nIn this paper we propose a method which combines spline-based semi-parametric\nregression modelling with the modelling of auto-regressive errors.\n  The method is applied to a simulated data set in order to show its efficacy\nand to ultrafine particle number concentration in Helsinki, Finland, to show\nits use in real world problems.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2012 01:24:26 GMT"}, {"version": "v2", "created": "Fri, 6 Jul 2012 00:12:37 GMT"}, {"version": "v3", "created": "Wed, 8 Aug 2012 01:12:22 GMT"}, {"version": "v4", "created": "Tue, 25 Sep 2012 06:46:13 GMT"}], "update_date": "2012-09-26", "authors_parsed": [["Clifford", "Sam", ""], ["M\u00f8lgaard", "Bjarke", ""], ["Choy", "Sama Low", ""], ["Corander", "Jukka", ""], ["H\u00e4meri", "Kaarle", ""], ["Mengersen", "Kerrie", ""], ["Hussein", "Tareq", ""]]}, {"id": "1207.0700", "submitter": "Jens Smiatek", "authors": "Jens Smiatek and Andreas Heuer", "title": "A statistical view on team handball results: home advantage, team\n  fitness and prediction of match outcomes", "comments": "8 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.OT physics.data-an physics.soc-ph stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the results of the German Team Handball Bundesliga for ten seasons\nin a model-free statistical time series approach. We will show that the home\nadvantage is nearly negligible compared to the total sum of goals. Specific\ninterest has been spent on the time evolution of the team fitness expressed in\nterms of the goal difference. In contrast to soccer, our results indicate a\ndecay of the team fitness values over a season while the long time correlation\nbehavior over years is nearly comparable. We are able to explain the dominance\nof a few teams by the large value for the total number of goals in a match. A\nmethod for the prediction of match winners is presented in good accuracy with\nthe real results. We analyze the properties of promoted teams and indicate\ndrastic level changes between the Bundesliga and the second league. Our\nfindings reflect in good agreement recent discussions on modern successful\nattack strategies.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2012 14:39:42 GMT"}], "update_date": "2012-07-04", "authors_parsed": [["Smiatek", "Jens", ""], ["Heuer", "Andreas", ""]]}, {"id": "1207.0704", "submitter": "Alejandro Frery", "authors": "Leonardo Torres, Tamer Cavalcante and Alejandro C. Frery", "title": "Speckle Reduction using Stochastic Distances", "comments": "Accepted for publication on the proceedings of the 17th Iberoamerican\n  Congress on Patter Recognition (CIARP), to be published in the Lecture Notes\n  in Computer Science series", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CV cs.GR math.IT stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new approach for filter design based on stochastic\ndistances and tests between distributions. A window is defined around each\npixel, samples are compared and only those which pass a goodness-of-fit test\nare used to compute the filtered value. The technique is applied to intensity\nSynthetic Aperture Radar (SAR) data, using the Gamma model with varying number\nof looks allowing, thus, changes in heterogeneity. Modified Nagao-Matsuyama\nwindows are used to define the samples. The proposal is compared with the Lee's\nfilter which is considered a standard, using a protocol based on simulation.\nAmong the criteria used to quantify the quality of filters, we employ the\nequivalent number of looks (related to the signal-to-noise ratio), line\ncontrast, and edge preservation. Moreover, we also assessed the filters by the\nUniversal Image Quality Index and the Pearson's correlation between edges.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2012 14:57:44 GMT"}], "update_date": "2012-07-04", "authors_parsed": [["Torres", "Leonardo", ""], ["Cavalcante", "Tamer", ""], ["Frery", "Alejandro C.", ""]]}, {"id": "1207.0752", "submitter": "Zhijian Wang Dr.", "authors": "Bin Xu, Zhijian Wang", "title": "Test MaxEnt in Social Strategy Transitions with Experimental Two-Person\n  Constant Sum 2$\\times$2 Games", "comments": "Keyward: game theory, experimental economics, MaxEnt, mixed strategy\n  Nash Equilibrium, social dynamics, evolution, social state transition,\n  evolutionary game theory, cycles; Result in Physics 2012", "journal-ref": null, "doi": "10.1016/j.rinp.2012.09.002", "report-no": null, "categories": "stat.ME nlin.CD physics.soc-ph stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By using laboratory experimental data, we test the uncertainty of social\nstrategy transitions in various competing environments of fixed paired\ntwo-person constant sum $2 \\times 2$ games. It firstly shows that, the\ndistributions of social strategy transitions are not erratic but obey the\nprinciple of the maximum entropy (MaxEnt). This finding indicates that human\nsubject social systems and natural systems could have wider common backgrounds.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2012 17:11:07 GMT"}, {"version": "v2", "created": "Fri, 7 Sep 2012 16:02:08 GMT"}], "update_date": "2012-09-10", "authors_parsed": [["Xu", "Bin", ""], ["Wang", "Zhijian", ""]]}, {"id": "1207.0757", "submitter": "Alejandro Frery", "authors": "Eliana S. de Almeida, Antonio Carlos de Medeiros, Osvaldo A. Rosso and\n  Alejandro C. Frery", "title": "Generalized Statistical Complexity of SAR Imagery", "comments": "Article accepted for publication in the proceedings of the 17\n  Iberoamerican Conference on Pattern Recognition (CIARP), to be published in\n  the Lecture Notes in Computer Science", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.GR math.IT stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new generalized Statistical Complexity Measure (SCM) was proposed by Rosso\net al in 2010. It is a functional that captures the notions of order/disorder\nand of distance to an equilibrium distribution. The former is computed by a\nmeasure of entropy, while the latter depends on the definition of a stochastic\ndivergence. When the scene is illuminated by coherent radiation, image data is\ncorrupted by speckle noise, as is the case of ultrasound-B, sonar, laser and\nSynthetic Aperture Radar (SAR) sensors. In the amplitude and intensity formats,\nthis noise is multiplicative and non-Gaussian requiring, thus, specialized\ntechniques for image processing and understanding. One of the most successful\nfamily of models for describing these images is the Multiplicative Model which\nleads, among other probability distributions, to the G0 law. This distribution\nhas been validated in the literature as an expressive and tractable model,\ndeserving the \"universal\" denomination for its ability to describe most types\nof targets. In order to compute the statistical complexity of a site in an\nimage corrupted by speckle noise, we assume that the equilibrium distribution\nis that of fully developed speckle, namely the Gamma law in intensity format,\nwhich appears in areas with little or no texture. We use the Shannon entropy\nalong with the Hellinger distance to measure the statistical complexity of\nintensity SAR images, and we show that it is an expressive feature capable of\nidentifying many types of targets.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2012 17:25:18 GMT"}], "update_date": "2012-07-04", "authors_parsed": [["de Almeida", "Eliana S.", ""], ["de Medeiros", "Antonio Carlos", ""], ["Rosso", "Osvaldo A.", ""], ["Frery", "Alejandro C.", ""]]}, {"id": "1207.0771", "submitter": "Alejandro Frery", "authors": "Leonardo Torres, Antonio C. Medeiros and Alejandro C. Frery", "title": "Polarimetric SAR Image Smoothing with Stochastic Distances", "comments": "Accepted for publication in the proceedings of the 17th Iberoamerican\n  Conference on Pattern Recognition, to be published in the Lecture Notes in\n  Computer Science series", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CV cs.GR math.IT stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Polarimetric Synthetic Aperture Radar (PolSAR) images are establishing as an\nimportant source of information in remote sensing applications. The most\ncomplete format this type of imaging produces consists of complex-valued\nHermitian matrices in every image coordinate and, as such, their visualization\nis challenging. They also suffer from speckle noise which reduces the\nsignal-to-noise ratio. Smoothing techniques have been proposed in the\nliterature aiming at preserving different features and, analogously,\nprojections from the cone of Hermitian positive matrices to different color\nrepresentation spaces are used for enhancing certain characteristics. In this\nwork we propose the use of stochastic distances between models that describe\nthis type of data in a Nagao-Matsuyama-type of smoothing technique. The\nresulting images are shown to present good visualization properties (noise\nreduction with preservation of fine details) in all the considered\nvisualization spaces.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2012 18:11:46 GMT"}], "update_date": "2012-07-04", "authors_parsed": [["Torres", "Leonardo", ""], ["Medeiros", "Antonio C.", ""], ["Frery", "Alejandro C.", ""]]}, {"id": "1207.1134", "submitter": "Radu Balan", "authors": "Radu Balan", "title": "Reconstruction of Signals from Magnitudes of Redundant Representations", "comments": "20 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.FA cs.IT math.IT stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is concerned with the question of reconstructing a vector in a\nfinite-dimensional real or complex Hilbert space when only the magnitudes of\nthe coefficients of the vector under a redundant linear map are known. We\npresent new invertibility results as well an iterative algorithm that finds the\nleast-square solution and is robust in the presence of noise. We analyze its\nnumerical performance by comparing it to two versions of the Cramer-Rao lower\nbound.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2012 22:16:19 GMT"}], "update_date": "2012-07-06", "authors_parsed": [["Balan", "Radu", ""]]}, {"id": "1207.1463", "submitter": "Jessika Trancik", "authors": "Bela Nagy, J. Doyne Farmer, Quan M. Bui, Jessika E. Trancik", "title": "Statistical Basis for Predicting Technological Progress", "comments": null, "journal-ref": null, "doi": "10.1371/journal.pone.0052669", "report-no": null, "categories": "physics.soc-ph q-fin.GN stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Forecasting technological progress is of great interest to engineers, policy\nmakers, and private investors. Several models have been proposed for predicting\ntechnological improvement, but how well do these models perform? An early\nhypothesis made by Theodore Wright in 1936 is that cost decreases as a power\nlaw of cumulative production. An alternative hypothesis is Moore's law, which\ncan be generalized to say that technologies improve exponentially with time.\nOther alternatives were proposed by Goddard, Sinclair et al., and Nordhaus.\nThese hypotheses have not previously been rigorously tested. Using a new\ndatabase on the cost and production of 62 different technologies, which is the\nmost expansive of its kind, we test the ability of six different postulated\nlaws to predict future costs. Our approach involves hindcasting and developing\na statistical model to rank the performance of the postulated laws. Wright's\nlaw produces the best forecasts, but Moore's law is not far behind. We discover\na previously unobserved regularity that production tends to increase\nexponentially. A combination of an exponential decrease in cost and an\nexponential increase in production would make Moore's law and Wright's law\nindistinguishable, as originally pointed out by Sahal. We show for the first\ntime that these regularities are observed in data to such a degree that the\nperformance of these two laws is nearly tied. Our results show that\ntechnological progress is forecastable, with the square root of the logarithmic\nerror growing linearly with the forecasting horizon at a typical rate of 2.5%\nper year. These results have implications for theories of technological change,\nand assessments of candidate technologies and policies for climate change\nmitigation.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jul 2012 21:12:19 GMT"}], "update_date": "2015-06-05", "authors_parsed": [["Nagy", "Bela", ""], ["Farmer", "J. Doyne", ""], ["Bui", "Quan M.", ""], ["Trancik", "Jessika E.", ""]]}, {"id": "1207.1497", "submitter": "Vasanthan Raghavan", "authors": "Vasanthan Raghavan, Aram Galstyan, Alexander G. Tartakovsky", "title": "Hidden Markov models for the activity profile of terrorist groups", "comments": "Published in at http://dx.doi.org/10.1214/13-AOAS682 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2013, Vol. 7, No. 4, 2402-2430", "doi": "10.1214/13-AOAS682", "report-no": "IMS-AOAS-AOAS682", "categories": "stat.AP cs.SI physics.data-an physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main focus of this work is on developing models for the activity profile\nof a terrorist group, detecting sudden spurts and downfalls in this profile,\nand, in general, tracking it over a period of time. Toward this goal, a\n$d$-state hidden Markov model (HMM) that captures the latent states underlying\nthe dynamics of the group and thus its activity profile is developed. The\nsimplest setting of $d=2$ corresponds to the case where the dynamics are\ncoarsely quantized as Active and Inactive, respectively. A state estimation\nstrategy that exploits the underlying HMM structure is then developed for spurt\ndetection and tracking. This strategy is shown to track even nonpersistent\nchanges that last only for a short duration at the cost of learning the\nunderlying model. Case studies with real terrorism data from open-source\ndatabases are provided to illustrate the performance of the proposed\nmethodology.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jul 2012 00:40:49 GMT"}, {"version": "v2", "created": "Thu, 26 Jul 2012 21:08:01 GMT"}, {"version": "v3", "created": "Wed, 15 Jan 2014 14:19:19 GMT"}], "update_date": "2014-01-16", "authors_parsed": [["Raghavan", "Vasanthan", ""], ["Galstyan", "Aram", ""], ["Tartakovsky", "Alexander G.", ""]]}, {"id": "1207.1531", "submitter": "Ido Nevat Ido Nevat", "authors": "Gareth W. Peters, Ido Nevat, Francois Septier, Laurent Clavier", "title": "Generalized Interference Models in Doubly Stochastic Poisson Random\n  Fields for Wideband Communications: the PNSC(alpha) model", "comments": "40 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A general stochastic model is developed for the total interference in\nwideband systems, denoted as the PNSC(alpha) Interference Model. It allows one\nto obtain, analytic representations in situations where (a) interferers are\ndistributed according to either a homogeneous or an inhomogeneous in time or\nspace Cox point process and (b) when the frequency bands occupied by each of\nthe unknown number of interferers is also a random variable in the allowable\nbandwidth. The analytic representations obtained are generalizations of Cox\nprocesses to the family of sub-exponential models characterized by\ndistributions from the alpha-stable family. We develop general parametric\ndensity representations for the interference models via doubly stochastic\nPoisson mixture representations of Scaled Mixture of Normal's via the\nNormal-Stable variance mixture. To illustrate members of this class of\ninterference model we also develop two special cases for a moderately impulsive\ninterference (alpha=3/2) and a highly impulsive interference (alpha=2/3) where\nclosed form representations can be obtained either by the SMiN representation\nor via function expansions based on the Holtsmark distribution or Whittaker\nfunctions. To illustrate the paper we propose expressions for the Capacity of a\nBPSK system under a PNSC(alpha) interference, via analytic expressions for the\nLikelihood Ratio Test statistic.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jul 2012 06:32:47 GMT"}], "update_date": "2012-07-09", "authors_parsed": [["Peters", "Gareth W.", ""], ["Nevat", "Ido", ""], ["Septier", "Francois", ""], ["Clavier", "Laurent", ""]]}, {"id": "1207.1758", "submitter": "A.C. Thomas", "authors": "A.C. Thomas", "title": "The Social Contagion Hypothesis: Comment on \"Social Contagion Theory:\n  Examining Dynamic Social Networks and Human Behavior\"", "comments": null, "journal-ref": "Statistics in Medicine, 2013", "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  I reflect on the statistical methods of the Christakis-Fowler studies on\nnetwork-based contagion of traits by checking the sensitivity of these kinds of\nresults to various alternate specifications and generative mechanisms. Despite\nthe honest efforts of all involved, I remain pessimistic about establishing\nwhether binary health outcomes or product adoptions are contagious if the\nevidence comes from simultaneously observed data.\n", "versions": [{"version": "v1", "created": "Sat, 7 Jul 2012 04:29:43 GMT"}, {"version": "v2", "created": "Tue, 10 Jul 2012 19:51:02 GMT"}, {"version": "v3", "created": "Fri, 8 Feb 2013 18:53:45 GMT"}], "update_date": "2013-02-11", "authors_parsed": [["Thomas", "A. C.", ""]]}, {"id": "1207.1865", "submitter": "Susanne Ditlevsen", "authors": "Susanne Ditlevsen, Adeline Samson", "title": "Estimation in the partially observed stochastic Morris-Lecar neuronal\n  model with particle filter and stochastic approximation methods", "comments": "Published in at http://dx.doi.org/10.1214/14-AOAS729 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2014, Vol. 8, No. 2, 674-702", "doi": "10.1214/14-AOAS729", "report-no": "IMS-AOAS-AOAS729", "categories": "stat.ME stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parameter estimation in multidimensional diffusion models with only one\ncoordinate observed is highly relevant in many biological applications, but a\nstatistically difficult problem. In neuroscience, the membrane potential\nevolution in single neurons can be measured at high frequency, but biophysical\nrealistic models have to include the unobserved dynamics of ion channels. One\nsuch model is the stochastic Morris-Lecar model, defined by a nonlinear\ntwo-dimensional stochastic differential equation. The coordinates are coupled,\nthat is, the unobserved coordinate is nonautonomous, the model exhibits\noscillations to mimic the spiking behavior, which means it is not of\ngradient-type, and the measurement noise from intracellular recordings is\ntypically negligible. Therefore, the hidden Markov model framework is\ndegenerate, and available methods break down. The main contributions of this\npaper are an approach to estimate in this ill-posed situation and nonasymptotic\nconvergence results for the method. Specifically, we propose a sequential Monte\nCarlo particle filter algorithm to impute the unobserved coordinate, and then\nestimate parameters maximizing a pseudo-likelihood through a stochastic version\nof the Expectation-Maximization algorithm. It turns out that even the rate\nscaling parameter governing the opening and closing of ion channels of the\nunobserved coordinate can be reasonably estimated. An experimental data set of\nintracellular recordings of the membrane potential of a spinal motoneuron of a\nred-eared turtle is analyzed, and the performance is further evaluated in a\nsimulation study.\n", "versions": [{"version": "v1", "created": "Sun, 8 Jul 2012 12:18:07 GMT"}, {"version": "v2", "created": "Sun, 2 Feb 2014 21:01:26 GMT"}, {"version": "v3", "created": "Thu, 31 Jul 2014 12:03:26 GMT"}], "update_date": "2014-08-01", "authors_parsed": [["Ditlevsen", "Susanne", ""], ["Samson", "Adeline", ""]]}, {"id": "1207.1888", "submitter": "David  Biagioni", "authors": "David J. Biagioni and Ryan Elmore and Wesley Jones", "title": "Keeping greed good: sparse regression under design uncertainty with\n  application to biomass characterization", "comments": "22 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.CO stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the classic measurement error regression scenario\nin which our independent, or design, variables are observed with several\nsources of additive noise. We will show that our motivating example's\nreplicated measurements on both the design and dependent variables may be\nleveraged to enhance a sparse regression algorithm. Specifically, we estimate\nthe variance and use it to scale our design variables. We demonstrate the\nefficacy of scaling from several points of view and validate it empirically\nwith a biomass characterization data set using two of the most widely used\nsparse algorithms: least angle regression (LARS) and the Dantzig selector (DS).\n", "versions": [{"version": "v1", "created": "Sun, 8 Jul 2012 17:15:59 GMT"}], "update_date": "2012-07-10", "authors_parsed": [["Biagioni", "David J.", ""], ["Elmore", "Ryan", ""], ["Jones", "Wesley", ""]]}, {"id": "1207.1915", "submitter": "Alejandro Frery", "authors": "Edwin Gir\\'on, Alejandro C. Frery and Francisco Cribari-Neto", "title": "Nonparametric Edge Detection in Speckled Imagery", "comments": "Accepted for publication in Mathematics and Computers in Simulation", "journal-ref": "Mathematics and Computers in Simulation, vol. 82, pages 2182-2198,\n  2012", "doi": "10.1016/j.matcom.2012.04.013", "report-no": null, "categories": "stat.AP cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the issue of edge detection in Synthetic Aperture Radar imagery.\nIn particular, we propose nonparametric methods for edge detection, and\nnumerically compare them to an alternative method that has been recently\nproposed in the literature. Our results show that some of the proposed methods\ndisplay superior results and are computationally simpler than the existing\nmethod. An application to real (not simulated) data is presented and discussed.\n", "versions": [{"version": "v1", "created": "Sun, 8 Jul 2012 21:45:43 GMT"}], "update_date": "2012-08-30", "authors_parsed": [["Gir\u00f3n", "Edwin", ""], ["Frery", "Alejandro C.", ""], ["Cribari-Neto", "Francisco", ""]]}, {"id": "1207.1965", "submitter": "Gilles Stoltz", "authors": "Marie Devaine (DMA), Pierre Gaillard (DMA, INRIA Paris -\n  Rocquencourt), Yannig Goude, Gilles Stoltz (DMA, INRIA Paris - Rocquencourt,\n  GREGH)", "title": "Forecasting electricity consumption by aggregating specialized experts", "comments": "33 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the setting of sequential prediction of arbitrary sequences based\non specialized experts. We first provide a review of the relevant literature\nand present two theoretical contributions: a general analysis of the specialist\naggregation rule of Freund et al. (1997) and an adaptation of fixed-share rules\nof Herbster and Warmuth (1998) in this setting. We then apply these rules to\nthe sequential short-term (one-day-ahead) forecasting of electricity\nconsumption; to do so, we consider two data sets, a Slovakian one and a French\none, respectively concerned with hourly and half-hourly predictions. We follow\na general methodology to perform the stated empirical studies and detail in\nparticular tuning issues of the learning parameters. The introduced aggregation\nrules demonstrate an improved accuracy on the data sets at hand; the\nimprovements lie in a reduced mean squared error but also in a more robust\nbehavior with respect to large occasional errors.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jul 2012 06:47:39 GMT"}], "update_date": "2012-07-10", "authors_parsed": [["Devaine", "Marie", "", "DMA"], ["Gaillard", "Pierre", "", "DMA, INRIA Paris -\n  Rocquencourt"], ["Goude", "Yannig", "", "DMA, INRIA Paris - Rocquencourt,\n  GREGH"], ["Stoltz", "Gilles", "", "DMA, INRIA Paris - Rocquencourt,\n  GREGH"]]}, {"id": "1207.2296", "submitter": "Thomas Opitz", "authors": "Thomas Opitz", "title": "Extremal t processes: Elliptical domain of attraction and a spectral\n  representation", "comments": null, "journal-ref": null, "doi": "10.1016/j.jmva.2013.08.008", "report-no": null, "categories": "stat.ME stat.AP stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The extremal t process was proposed in the literature for modeling spatial\nextremes within a copula framework based on the extreme value limit of\nelliptical t distributions (Davison, Padoan and Ribatet (2012)). A major\ndrawback of this max-stable model was the lack of a spectral representation\nsuch that for instance direct simulation was infeasible. The main contribution\nof this note is to propose such a spectral construction for the extremal t\nprocess. Interestingly, the extremal Gaussian process introduced by Schlather\n(2002) appears as a special case. We further highlight the role of the extremal\nt process as the maximum attractor for processes with finite-dimensional\nelliptical distributions. All results naturally also hold within the\nmultivariate domain.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2012 10:25:00 GMT"}, {"version": "v2", "created": "Tue, 7 Aug 2012 15:09:51 GMT"}, {"version": "v3", "created": "Thu, 9 Aug 2012 12:08:03 GMT"}, {"version": "v4", "created": "Wed, 29 Aug 2012 15:56:17 GMT"}, {"version": "v5", "created": "Tue, 18 Sep 2012 08:52:11 GMT"}, {"version": "v6", "created": "Mon, 25 Mar 2013 10:47:41 GMT"}], "update_date": "2013-08-23", "authors_parsed": [["Opitz", "Thomas", ""]]}, {"id": "1207.2370", "submitter": "Simon Barthelm\\'e", "authors": "Simon Barthelm\\'e, Hans Trukenbrod, Ralf Engbert, Felix Wichmann", "title": "Modelling fixation locations using spatial point processes", "comments": "Revised following peer review", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Whenever eye movements are measured, a central part of the analysis has to do\nwith where subjects fixate, and why they fixated where they fixated. To a first\napproximation, a set of fixations can be viewed as a set of points in space:\nthis implies that fixations are spatial data and that the analysis of fixation\nlocations can be beneficially thought of as a spatial statistics problem. We\nargue that thinking of fixation locations as arising from point processes is a\nvery fruitful framework for eye movement data, helping turn qualitative\nquestions into quantitative ones.\n  We provide a tutorial introduction to some of the main ideas of the field of\nspatial statistics, focusing especially on spatial Poisson processes. We show\nhow point processes help relate image properties to fixation locations. In\nparticular we show how point processes naturally express the idea that image\nfeatures' predictability for fixations may vary from one image to another. We\nreview other methods of analysis used in the literature, show how they relate\nto point process theory, and argue that thinking in terms of point processes\nsubstantially extends the range of analyses that can be performed and clarify\ntheir interpretation.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2012 14:32:47 GMT"}, {"version": "v2", "created": "Fri, 15 Feb 2013 09:13:44 GMT"}, {"version": "v3", "created": "Wed, 22 May 2013 15:53:49 GMT"}], "update_date": "2013-05-23", "authors_parsed": [["Barthelm\u00e9", "Simon", ""], ["Trukenbrod", "Hans", ""], ["Engbert", "Ralf", ""], ["Wichmann", "Felix", ""]]}, {"id": "1207.2674", "submitter": "R\\'emi Cogranne", "authors": "R\\'emi Cogranne, Cathel Zitzmann, Florent Retraint, Igor Nikiforov,\n  Lionel Fillatre and Philippe Cornu", "title": "Statistical Detection of LSB Matching Using Hypothesis Testing Theory", "comments": null, "journal-ref": "Information Hiding Conference, 15-18 May 2012, Berkeley, CA USA", "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the detection of information hidden by the Least\nSignificant Bit (LSB) matching scheme. In a theoretical context of known image\nmedia parameters, two important results are presented. First, the use of\nhypothesis testing theory allows us to design the Most Powerful (MP) test.\nSecond, a study of the MP test gives us the opportunity to analytically\ncalculate its statistical performance in order to warrant a given probability\nof false-alarm. In practice when detecting LSB matching, the unknown image\nparameters have to be estimated. Based on the local estimator used in the\nWeighted Stego-image (WS) detector, a practical test is presented. A numerical\ncomparison with state-of-the-art detectors shows the good performance of the\nproposed tests and highlights the relevance of the proposed methodology.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2012 15:21:30 GMT"}], "update_date": "2012-07-12", "authors_parsed": [["Cogranne", "R\u00e9mi", ""], ["Zitzmann", "Cathel", ""], ["Retraint", "Florent", ""], ["Nikiforov", "Igor", ""], ["Fillatre", "Lionel", ""], ["Cornu", "Philippe", ""]]}, {"id": "1207.2883", "submitter": "Petr Simecek", "authors": "Petr Simecek, Marie Simeckova", "title": "Modification of Tukey's Additivity Test", "comments": "Accepted to Journal of Statistical Planning and Inference", "journal-ref": null, "doi": "10.1016/j.jspi.2012.07.002", "report-no": null, "categories": "math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we discuss testing for an interaction in the two-way ANOVA with\njust one observation per cell. The known results are reviewed and a simulation\nstudy is performed to evaluate type I and type II risks of the tests. It is\nshown that the Tukey and Mandel additivity tests have very low power in case of\nmore general interaction scheme. A modification of Tukey's test is developed to\nresolve this issue. All tests mentioned in the paper have been implemented in R\npackage AdditivityTests.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2012 09:20:16 GMT"}], "update_date": "2012-07-13", "authors_parsed": [["Simecek", "Petr", ""], ["Simeckova", "Marie", ""]]}, {"id": "1207.2941", "submitter": "Andrzej Jarynowski", "authors": "Andrzej Jarynowski, Marta Klis", "title": "Socio-economic models of divorces in different societies", "comments": "Proceedings of 18th National Conference", "journal-ref": "Applications of mathematics in biology and medicine, Krynica\n  Morska, 23-27.09.2012", "doi": null, "report-no": null, "categories": "nlin.AO physics.data-an physics.soc-ph stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Population dynamic of getting divorced depends on many global factors,\nincluding social norms, economy, law or demographics as well as individual\nfactors like the level of interpersonal or problem-solving skills of the\nspouses. We sought to find such a relationship incorporating only quantitative\nvariables and test theoretical model considering phase transition between\ncoupling (pairs) and free (single) preferential states as a function of social\nand economic. The analyzed data has been collected by UN across almost all the\ncountries since 1948. Our first approach is followed by Bouchaud's model of\nsocial network of opinions, which works well with dynamics of fertility rates\nin postwar Europe. Unfortunately, we postulate that this pure sociological and\npure economic approach fail in general. Thus, we did some observation about why\nit went wrong and where economy (e. g. Poland) or law (e. g. Portugal) has\nbigger impact on getting divorce than social pressure.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2012 12:38:28 GMT"}], "update_date": "2012-10-02", "authors_parsed": [["Jarynowski", "Andrzej", ""], ["Klis", "Marta", ""]]}, {"id": "1207.2961", "submitter": "Alejandro Frery", "authors": "A. C. Frery, L. Rivarola-Duarte, V. Carrilho Le\\~ao Ramos, A. Soares\n  Ramos Junior, W. W. Matos Lira", "title": "Stochastic particle packing with specified granulometry and porosity", "comments": null, "journal-ref": "Granular Matter, v. 14, p. 27--36, 2012", "doi": "10.1007/s10035-011-0300-5", "report-no": null, "categories": "stat.CO stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents a technique for particle size generation and placement in\narbitrary closed domains. Its main application is the simulation of granular\nmedia described by disks. Particle size generation is based on the statistical\nanalysis of granulometric curves which are used as empirical cumulative\ndistribution functions to sample from mixtures of uniform distributions. The\ndesired porosity is attained by selecting a certain number of particles, and\ntheir placement is performed by a stochastic point process. We present an\napplication analyzing different types of sand and clay, where we model the\ngrain size with the gamma, lognormal, Weibull and hyperbolic distributions. The\nparameters from the resulting best fit are used to generate samples from the\ntheoretical distribution, which are used for filling a finite-size area with\nnon-overlapping disks deployed by a Simple Sequential Inhibition stochastic\npoint process. Such filled areas are relevant as plausible inputs for assessing\nDiscrete Element Method and similar techniques.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2012 13:46:29 GMT"}], "update_date": "2012-07-13", "authors_parsed": [["Frery", "A. C.", ""], ["Rivarola-Duarte", "L.", ""], ["Ramos", "V. Carrilho Le\u00e3o", ""], ["Junior", "A. Soares Ramos", ""], ["Lira", "W. W. Matos", ""]]}, {"id": "1207.3137", "submitter": "Arwen Bradley", "authors": "Arwen Vanice Bradley (Meister), Ye Henry Li, Bokyung Choi, Wing Hung\n  Wong", "title": "Learning a nonlinear dynamical system model of gene regulation: A\n  perturbed steady-state approach", "comments": "Published in at http://dx.doi.org/10.1214/13-AOAS645 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2013, Vol. 7, No. 3, 1311-1333", "doi": "10.1214/13-AOAS645", "report-no": "IMS-AOAS-AOAS645", "categories": "q-bio.MN stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Biological structure and function depend on complex regulatory interactions\nbetween many genes. A wealth of gene expression data is available from\nhigh-throughput genome-wide measurement technologies, but effective gene\nregulatory network inference methods are still needed. Model-based methods\nfounded on quantitative descriptions of gene regulation are among the most\npromising, but many such methods rely on simple, local models or on ad hoc\ninference approaches lacking experimental interpretability. We propose an\nexperimental design and develop an associated statistical method for inferring\na gene network by learning a standard quantitative, interpretable, predictive,\nbiophysics-based ordinary differential equation model of gene regulation. We\nfit the model parameters using gene expression measurements from perturbed\nsteady-states of the system, like those following overexpression or knockdown\nexperiments. Although the original model is nonlinear, our design allows us to\ntransform it into a convex optimization problem by restricting attention to\nsteady-states and using the lasso for parameter selection. Here, we describe\nthe model and inference algorithm and apply them to a synthetic six-gene\nsystem, demonstrating that the model is detailed and flexible enough to account\nfor activation and repression as well as synergistic and self-regulation, and\nthe algorithm can efficiently and accurately recover the parameters used to\ngenerate the data.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jul 2012 03:13:03 GMT"}, {"version": "v2", "created": "Fri, 12 Apr 2013 18:10:00 GMT"}, {"version": "v3", "created": "Thu, 28 Nov 2013 08:14:14 GMT"}, {"version": "v4", "created": "Fri, 25 Mar 2016 17:50:21 GMT"}], "update_date": "2016-03-28", "authors_parsed": [["Bradley", "Arwen Vanice", "", "Meister"], ["Li", "Ye Henry", ""], ["Choi", "Bokyung", ""], ["Wong", "Wing Hung", ""]]}, {"id": "1207.3246", "submitter": "Quentin Giai Gianetto", "authors": "Quentin Giai Gianetto and Hamdi Raissi", "title": "Testing instantaneous causality in presence of non constant\n  unconditional variance", "comments": "Keywords : VAR model, Unconditionally heteroscedastic errors,\n  instantaneous causality", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of testing instantaneous causality between variables with\ntime-varying unconditional variance is investigated. It is shown that the\nclassical tests based on the assumption of stationary processes must be avoided\nin our non standard framework. More precisely we underline that the standard\ntest does not control the type I errors, while the tests with White (1980) and\nHeteroscedastic Autocorrelation Consistent (HAC) corrections can suffer from a\nsevere loss of power when the variance is not constant. Consequently a modified\ntest based on a bootstrap procedure is proposed. The relevance of the modified\ntest is underlined through a simulation study. The tests considered in this\npaper are also compared by investigating the instantaneous causality relations\nbetween US macroeconomic variables.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jul 2012 13:57:42 GMT"}, {"version": "v2", "created": "Fri, 11 Apr 2014 11:42:49 GMT"}], "update_date": "2014-04-14", "authors_parsed": [["Gianetto", "Quentin Giai", ""], ["Raissi", "Hamdi", ""]]}, {"id": "1207.3288", "submitter": "Andy  Royle", "authors": "J. Andrew Royle and Richard B. Chandler", "title": "Integrating Resource Selection Information with Spatial\n  Capture-Recapture", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM stat.AP", "license": "http://creativecommons.org/licenses/publicdomain/", "abstract": "  Understanding space usage and resource selection is a primary focus of many\nstudies of animal populations. Usually, such studies are based on location data\nobtained from telemetry, and resource selection functions (RSF) are used for\ninference. Another important focus of wildlife research is estimation and\nmodeling population size and density. Recently developed spatial\ncapture-recapture (SCR) models accomplish this objective using individual\nencounter history data with auxiliary spatial information on location of\ncapture. SCR models include encounter probability functions that are\nintuitively related to RSFs, but to date, no one has extended SCR models to\nallow for explicit inference about space usage and resource selection. We\ndevelop a statistical framework for jointly modeling space usage, resource\nselection, and population density by integrating SCR data, such as from camera\ntraps, mist-nets, or conventional catch-traps, with resource selection data\nfrom telemetered individuals. We provide a framework for estimation based on\nmarginal likelihood, wherein we estimate simultaneously the parameters of the\nSCR and RSF models.\n  Our method leads to increases in precision for estimating population density\nand parameters of ordinary SCR models. Importantly, we also find that SCR\nmodels alone can estimate parameters of resource selection functions and, as\nsuch, SCR methods can be used as the sole source for studying space-usage;\nhowever, precision will be higher when telemetry data are available. Finally,\nwe find that SCR models using standard symmetric and stationary encounter\nprobability models produce biased estimates of density when animal space usage\nis related to a landscape covariate. Therefore, it is important that space\nusage be taken into consideration, if possible, in studies focused on\nestimating density using capture-recapture methods.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jul 2012 16:05:40 GMT"}], "update_date": "2012-07-16", "authors_parsed": [["Royle", "J. Andrew", ""], ["Chandler", "Richard B.", ""]]}, {"id": "1207.3413", "submitter": "Philip Stark", "authors": "Jorge H. Banuelos and Philip B. Stark", "title": "Limiting Risk by Turning Manifest Phantoms into Evil Zombies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Drawing a random sample of ballots to conduct a risk-limiting audit generally\nrequires knowing how the ballots cast in an election are organized into groups,\nfor instance, how many containers of ballots there are in all and how many\nballots are in each container. A list of the ballot group identifiers along\nwith number of ballots in each group is called a ballot manifest. What if the\nballot manifest is not accurate? Surprisingly, even if ballots are known to be\nmissing from the manifest, it is not necessary to make worst-case assumptions\nabout those ballots--for instance, to adjust the margin by the number of\nmissing ballots--to ensure that the audit remains conservative. Rather, it\nsuffices to make worst-case assumptions about the individual randomly selected\nballots that the audit cannot find. This observation provides a simple\nmodification to some risk-limiting audit procedures that makes them\nautomatically become more conservative if the ballot manifest has errors. The\nmodification--phantoms to evil zombies (~2EZ)--requires only an upper bound on\nthe total number of ballots cast. ~2EZ makes the audit P-value stochastically\nlarger than it would be had the manifest been accurate, automatically requiring\nmore than enough ballots to be audited to offset the manifest errors. This\nensures that the true risk limit remains smaller than the nominal risk limit.\nOn the other hand, if the manifest is in fact accurate and the upper bound on\nthe total number of ballots equals the total according to the manifest, ~2EZ\nhas no effect at all on the number of ballots audited nor on the true risk\nlimit.\n", "versions": [{"version": "v1", "created": "Sat, 14 Jul 2012 11:26:02 GMT"}], "update_date": "2012-07-17", "authors_parsed": [["Banuelos", "Jorge H.", ""], ["Stark", "Philip B.", ""]]}, {"id": "1207.4085", "submitter": "Xi Luo", "authors": "Xi Luo, Steven Gee, Vikaas S. Sohal, Dylan S. Small", "title": "A Point-process Response Model for Spike Trains from Single Neurons in\n  Neural Circuits under Optogenetic Stimulation", "comments": "24 pages, 7 figures. R package pro implementing the proposed method\n  is available on CRAN at https://CRAN.R-project.org/package=pro . Published by\n  Statistics in Medicine at\n  http://onlinelibrary.wiley.com/doi/10.1002/sim.6742/full", "journal-ref": "Stat Med. 2016; 35(3): 455-74", "doi": "10.1002/sim.6742", "report-no": null, "categories": "stat.ME q-bio.NC stat.AP stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optogenetics is a new tool to study neuronal circuits that have been\ngenetically modified to allow stimulation by flashes of light. We study\nrecordings from single neurons within neural circuits under optogenetic\nstimulation. The data from these experiments present a statistical challenge of\nmodeling a high frequency point process (neuronal spikes) while the input is\nanother high frequency point process (light flashes). We further develop a\ngeneralized linear model approach to model the relationships between two point\nprocesses, employing additive point-process response functions. The resulting\nmodel, Point-process Responses for Optogenetics (PRO), provides explicit\nnonlinear transformations to link the input point process with the output one.\nSuch response functions may provide important and interpretable scientific\ninsights into the properties of the biophysical process that governs neural\nspiking in response to optogenetic stimulation. We validate and compare the PRO\nmodel using a real dataset and simulations, and our model yields a superior\narea-under-the- curve value as high as 93% for predicting every future spike.\nFor our experiment on the recurrent layer V circuit in the prefrontal cortex,\nthe PRO model provides evidence that neurons integrate their inputs in a\nsophisticated manner. Another use of the model is that it enables understanding\nhow neural circuits are altered under various disease conditions and/or\nexperimental conditions by comparing the PRO parameters.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2012 18:51:17 GMT"}, {"version": "v2", "created": "Thu, 22 Dec 2016 03:48:50 GMT"}], "update_date": "2016-12-23", "authors_parsed": [["Luo", "Xi", ""], ["Gee", "Steven", ""], ["Sohal", "Vikaas S.", ""], ["Small", "Dylan S.", ""]]}, {"id": "1207.4122", "submitter": "Gregory F. Cooper", "authors": "Gregory F. Cooper, Denver Dash, John Levander, Weng-Keen Wong, William\n  Hogan, Michael Wagner", "title": "Bayesian Biosurveillance of Disease Outbreaks", "comments": "Appears in Proceedings of the Twentieth Conference on Uncertainty in\n  Artificial Intelligence (UAI2004)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2004-PG-94-103", "categories": "stat.AP cs.AI cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Early, reliable detection of disease outbreaks is a critical problem today.\nThis paper reports an investigation of the use of causal Bayesian networks to\nmodel spatio-temporal patterns of a non-contagious disease (respiratory anthrax\ninfection) in a population of people. The number of parameters in such a\nnetwork can become enormous, if not carefully managed. Also, inference needs to\nbe performed in real time as population data stream in. We describe techniques\nwe have applied to address both the modeling and inference challenges. A key\ncontribution of this paper is the explication of assumptions and techniques\nthat are sufficient to allow the scaling of Bayesian network modeling and\ninference to millions of nodes for real-time surveillance applications. The\nresults reported here provide a proof-of-concept that Bayesian networks can\nserve as the foundation of a system that effectively performs Bayesian\nbiosurveillance of disease outbreaks.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2012 14:45:54 GMT"}], "update_date": "2012-07-19", "authors_parsed": [["Cooper", "Gregory F.", ""], ["Dash", "Denver", ""], ["Levander", "John", ""], ["Wong", "Weng-Keen", ""], ["Hogan", "William", ""], ["Wagner", "Michael", ""]]}, {"id": "1207.4140", "submitter": "Manabu Kuroki", "authors": "Manabu Kuroki, Zhihong Cai", "title": "Selection of Identifiability Criteria for Total Effects by using Path\n  Diagrams", "comments": "Appears in Proceedings of the Twentieth Conference on Uncertainty in\n  Artificial Intelligence (UAI2004)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2004-PG-333-340", "categories": "stat.ME cs.AI stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pearl has provided the back door criterion, the front door criterion and the\nconditional instrumental variable (IV) method as identifiability criteria for\ntotal effects. In some situations, these three criteria can be applied to\nidentifying total effects simultaneously. For the purpose of increasing\nestimating accuracy, this paper compares the three ways of identifying total\neffects in terms of the asymptotic variance, and concludes that in some\nsituations the superior of them can be recognized directly from the graph\nstructure.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2012 14:53:48 GMT"}], "update_date": "2012-07-19", "authors_parsed": [["Kuroki", "Manabu", ""], ["Cai", "Zhihong", ""]]}, {"id": "1207.4143", "submitter": "Seyoung Kim", "authors": "Seyoung Kim, Padhraic Smyth, Stefan Luther", "title": "Modeling Waveform Shapes with Random Eects Segmental Hidden Markov\n  Models", "comments": "Appears in Proceedings of the Twentieth Conference on Uncertainty in\n  Artificial Intelligence (UAI2004)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2004-PG-309-316", "categories": "stat.AP cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we describe a general probabilistic framework for modeling\nwaveforms such as heartbeats from ECG data. The model is based on segmental\nhidden Markov models (as used in speech recognition) with the addition of\nrandom effects to the generative model. The random effects component of the\nmodel handles shape variability across different waveforms within a general\nclass of waveforms of similar shape. We show that this probabilistic model\nprovides a unified framework for learning these models from sets of waveform\ndata as well as parsing, classification, and prediction of new waveforms. We\nderive a computationally efficient EM algorithm to fit the model on multiple\nwaveforms, and introduce a scoring method that evaluates a test waveform based\non its shape. Results on two real-world data sets demonstrate that the random\neffects methodology leads to improved accuracy (compared to alternative\napproaches) on classification and segmentation of real-world waveforms.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2012 14:54:41 GMT"}], "update_date": "2012-07-19", "authors_parsed": [["Kim", "Seyoung", ""], ["Smyth", "Padhraic", ""], ["Luther", "Stefan", ""]]}, {"id": "1207.4162", "submitter": "Bo Thiesson", "authors": "Bo Thiesson, David Maxwell Chickering, David Heckerman, Christopher\n  Meek", "title": "ARMA Time-Series Modeling with Graphical Models", "comments": "Appears in Proceedings of the Twentieth Conference on Uncertainty in\n  Artificial Intelligence (UAI2004)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2004-PG-552-560", "categories": "stat.AP cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We express the classic ARMA time-series model as a directed graphical model.\nIn doing so, we find that the deterministic relationships in the model make it\neffectively impossible to use the EM algorithm for learning model parameters.\nTo remedy this problem, we replace the deterministic relationships with\nGaussian distributions having a small variance, yielding the stochastic ARMA\n(ARMA) model. This modification allows us to use the EM algorithm to learn\nparmeters and to forecast,even in situations where some data is missing. This\nmodification, in conjunction with the graphicalmodel approach, also allows us\nto include cross predictors in situations where there are multiple times series\nand/or additional nontemporal covariates. More surprising,experiments suggest\nthat the move to stochastic ARMA yields improved accuracy through better\nsmoothing. We demonstrate improvements afforded by cross prediction and better\nsmoothing on real data.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2012 15:03:00 GMT"}, {"version": "v2", "created": "Wed, 8 Aug 2012 20:45:28 GMT"}], "update_date": "2012-08-10", "authors_parsed": [["Thiesson", "Bo", ""], ["Chickering", "David Maxwell", ""], ["Heckerman", "David", ""], ["Meek", "Christopher", ""]]}, {"id": "1207.4836", "submitter": "Yan Kagan", "authors": "Yan. Y. Kagan, David D. Jackson, and Robert J. Geller", "title": "Characteristic earthquake model, 1884 -- 2011, R.I.P", "comments": "7 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.geo-ph stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unfortunately, working scientists sometimes reflexively continue to use \"buzz\nphrases\" grounded in once prevalent paradigms that have been subsequently\nrefuted. This can impede both earthquake research and hazard mitigation.\nWell-worn seismological buzz phrases include \"earthquake cycle,\" \"seismic\ncycle,\" \"seismic gap,\" and \"characteristic earthquake.\" They all assume that\nthere are sequences of earthquakes that are nearly identical except for the\ntimes of their occurrence. If so, the complex process of earthquake occurrence\ncould be reduced to a description of one \"characteristic\" earthquake plus the\ntimes of the others in the sequence. A common additional assumption is that\ncharacteristic earthquakes dominate the displacement on fault or plate boundary\n\"segments.\" The \"seismic gap\" (or the effectively equivalent \"seismic cycle\")\nmodel depends entirely on the \"characteristic\" assumption, with the added\nassumption that characteristic earthquakes are quasi-periodic. However, since\nthe 1990s numerous statistical tests have failed to support characteristic\nearthquake and seismic gap models, and the 2004 Sumatra earthquake and 2011\nTohoku earthquake both ripped through several supposed segment boundaries.\nEarthquake scientists should scrap ideas that have been rejected by objective\ntesting or are too vague to be testable.\n", "versions": [{"version": "v1", "created": "Fri, 20 Jul 2012 01:32:42 GMT"}], "update_date": "2012-07-23", "authors_parsed": [["Kagan", "Yan. Y.", ""], ["Jackson", "David D.", ""], ["Geller", "Robert J.", ""]]}, {"id": "1207.4886", "submitter": "Matti Pirinen", "authors": "Matti Pirinen, Peter Donnelly, Chris C. A. Spencer", "title": "Efficient computation with a linear mixed model on large-scale data sets\n  with applications to genetic studies", "comments": "Published in at http://dx.doi.org/10.1214/12-AOAS586 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2013, Vol. 7, No. 1, 369-390", "doi": "10.1214/12-AOAS586", "report-no": "IMS-AOAS-AOAS586", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by genome-wide association studies, we consider a standard linear\nmodel with one additional random effect in situations where many predictors\nhave been collected on the same subjects and each predictor is analyzed\nseparately. Three novel contributions are (1) a transformation between the\nlinear and log-odds scales which is accurate for the important genetic case of\nsmall effect sizes; (2) a likelihood-maximization algorithm that is an order of\nmagnitude faster than the previously published approaches; and (3) efficient\nmethods for computing marginal likelihoods which allow Bayesian model\ncomparison. The methodology has been successfully applied to a large-scale\nassociation study of multiple sclerosis including over 20,000 individuals and\n500,000 genetic variants.\n", "versions": [{"version": "v1", "created": "Fri, 20 Jul 2012 09:21:54 GMT"}, {"version": "v2", "created": "Tue, 23 Apr 2013 10:04:33 GMT"}], "update_date": "2013-04-24", "authors_parsed": [["Pirinen", "Matti", ""], ["Donnelly", "Peter", ""], ["Spencer", "Chris C. A.", ""]]}, {"id": "1207.4913", "submitter": "Richard D. Gill", "authors": "James M. Robins, Tyler J. VanderWeele, and Richard D. Gill", "title": "A proof of Bell's inequality in quantum mechanics using causal\n  interactions", "comments": "http://biostats.bepress.com/cobra/art83", "journal-ref": "Scandinavian Journal of Statistics Volume 42, Issue 2, pages\n  329-335, June 2015", "doi": "10.1111/sjos.12089", "report-no": "COBRA Preprint Series, Working Paper 83", "categories": "stat.AP physics.hist-ph quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a simple proof of Bell's inequality in quantum mechanics which, in\nconjunction with experiments, demonstrates that the local hidden variables\nassumption is false. The proof sheds light on relationships between the notion\nof causal interaction and interference between particles.\n", "versions": [{"version": "v1", "created": "Fri, 20 Jul 2012 11:03:19 GMT"}], "update_date": "2015-09-17", "authors_parsed": [["Robins", "James M.", ""], ["VanderWeele", "Tyler J.", ""], ["Gill", "Richard D.", ""]]}, {"id": "1207.4941", "submitter": "Mindaugas Bloznelis", "authors": "Mindaugas Bloznelis and Valentas Kurauskas", "title": "Clustering function: a measure of social influence", "comments": "Revised argument in section 5. Correction: factor 0.5 has been\n  removed from denominator in (12), (13)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.SI math.CO math.PR physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A commonly used characteristic of statistical dependence of adjacency\nrelations in real networks, the clustering coefficient, evaluates chances that\ntwo neighbours of a given vertex are adjacent. An extension is obtained by\nconsidering conditional probabilities that two randomly chosen vertices are\nadjacent given that they have r common neighbours. We denote such probabilities\ncl(r) and call r-> cl(r) the clustering function.\n  We compare clustering functions of several networks having non-negligible\nclustering coefficient. They show similar patterns and surprising regularity.\nWe establish a first order asymptotic (as the number of vertices tends to\ninfinity) of the clustering function of related random intersection graph\nmodels admitting nonvanishing clustering coefficient and asymptotic degree\ndistribution having a finite second moment.\n", "versions": [{"version": "v1", "created": "Fri, 20 Jul 2012 12:45:36 GMT"}, {"version": "v2", "created": "Fri, 26 Apr 2013 08:41:18 GMT"}], "update_date": "2013-04-29", "authors_parsed": [["Bloznelis", "Mindaugas", ""], ["Kurauskas", "Valentas", ""]]}, {"id": "1207.5079", "submitter": "Yan Kagan", "authors": "Yan Y. Kagan", "title": "Double-Couple Earthquake Source: Symmetry and Rotation", "comments": "40 pages, 14 figures, 1 table", "journal-ref": null, "doi": "10.1093/gji/ggt156", "report-no": null, "categories": "physics.geo-ph math-ph math.MP stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider statistical analysis of double couple (DC) earthquake focal\nmechanism orientation. The symmetry of DC changes with its geometrical\nproperties, and the number of 3-D rotations one DC source can be transformed\ninto another depends on its symmetry. Four rotations exist in a general case of\nDC with the nodal-plane ambiguity, two transformations if the fault plane is\nknown, and one rotation if the sides of the fault plane are known. The symmetry\nof rotated objects is extensively analyzed in statistical material texture\nstudies, and we apply their results to analyzing DC orientation. We consider\ntheoretical probability distributions which can be used to approximate\nobservational patterns of focal mechanisms. Uniform random rotation\ndistributions for various DC sources are discussed, as well as two non-uniform\ndistributions: the rotational Cauchy and von Mises-Fisher. We discuss how\nparameters of these rotations can be estimated by a statistical analysis of\nearthquake source properties in global seismicity. We also show how earthquake\nfocal mechanism orientations can be displayed on the Rodrigues vector space.\n", "versions": [{"version": "v1", "created": "Fri, 20 Jul 2012 23:55:43 GMT"}], "update_date": "2015-06-05", "authors_parsed": [["Kagan", "Yan Y.", ""]]}, {"id": "1207.5103", "submitter": "Richard D. Gill", "authors": "Richard D. Gill", "title": "Statistics, Causality and Bell's Theorem", "comments": "Published in at http://dx.doi.org/10.1214/14-STS490 the Statistical\n  Science (http://www.imstat.org/sts/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Statistical Science 2014, Vol. 29, No. 4, 512-528", "doi": "10.1214/14-STS490", "report-no": "IMS-STS-STS490", "categories": "stat.AP physics.hist-ph quant-ph stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bell's [Physics 1 (1964) 195-200] theorem is popularly supposed to establish\nthe nonlocality of quantum physics. Violation of Bell's inequality in\nexperiments such as that of Aspect, Dalibard and Roger [Phys. Rev. Lett. 49\n(1982) 1804-1807] provides empirical proof of nonlocality in the real world.\nThis paper reviews recent work on Bell's theorem, linking it to issues in\ncausality as understood by statisticians. The paper starts with a proof of a\nstrong, finite sample, version of Bell's inequality and thereby also of Bell's\ntheorem, which states that quantum theory is incompatible with the conjunction\nof three formerly uncontroversial physical principles, here referred to as\nlocality, realism and freedom. Locality is the principle that the direction of\ncausality matches the direction of time, and that causal influences need time\nto propagate spatially. Realism and freedom are directly connected to\nstatistical thinking on causality: they relate to counterfactual reasoning, and\nto randomisation, respectively. Experimental loopholes in state-of-the-art Bell\ntype experiments are related to statistical issues of post-selection in\nobservational studies, and the missing at random assumption. They can be\navoided by properly matching the statistical analysis to the actual\nexperimental design, instead of by making untestable assumptions of\nindependence between observed and unobserved variables. Methodological and\nstatistical issues in the design of quantum Randi challenges (QRC) are\ndiscussed. The paper argues that Bell's theorem (and its experimental\nconfirmation) should lead us to relinquish not locality, but realism.\n", "versions": [{"version": "v1", "created": "Sat, 21 Jul 2012 05:24:44 GMT"}, {"version": "v2", "created": "Mon, 19 Aug 2013 00:26:31 GMT"}, {"version": "v3", "created": "Sat, 22 Mar 2014 15:20:10 GMT"}, {"version": "v4", "created": "Fri, 4 Apr 2014 22:46:52 GMT"}, {"version": "v5", "created": "Mon, 5 May 2014 15:55:13 GMT"}, {"version": "v6", "created": "Fri, 30 Jan 2015 10:55:43 GMT"}], "update_date": "2015-02-02", "authors_parsed": [["Gill", "Richard D.", ""]]}, {"id": "1207.5451", "submitter": "Nicolas Dobigeon", "authors": "Yoann Altmann and Nicolas Dobigeon and Steve McLaughlin and Jean-Yves\n  Tourneret", "title": "Nonlinear spectral unmixing of hyperspectral images using Gaussian\n  processes", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2013.2245127", "report-no": null, "categories": "stat.ML physics.data-an stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an unsupervised algorithm for nonlinear unmixing of\nhyperspectral images. The proposed model assumes that the pixel reflectances\nresult from a nonlinear function of the abundance vectors associated with the\npure spectral components. We assume that the spectral signatures of the pure\ncomponents and the nonlinear function are unknown. The first step of the\nproposed method consists of the Bayesian estimation of the abundance vectors\nfor all the image pixels and the nonlinear function relating the abundance\nvectors to the observations. The endmembers are subsequently estimated using\nGaussian process regression. The performance of the unmixing strategy is\nevaluated with simulations conducted on synthetic and real data.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jul 2012 16:51:10 GMT"}], "update_date": "2015-06-05", "authors_parsed": [["Altmann", "Yoann", ""], ["Dobigeon", "Nicolas", ""], ["McLaughlin", "Steve", ""], ["Tourneret", "Jean-Yves", ""]]}, {"id": "1207.5659", "submitter": "Philip Preu{\\ss}", "authors": "Philip Preu{\\ss}, Thimo Hildebrandt", "title": "Comparing spectral densities of stationary time series with unequal\n  sample sizes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with the comparison of several stationary processes with\nunequal sample sizes. We provide a detailed theoretical framework on the\ntesting problem for equality of spectral densities in the bivariate case, after\nwhich the generalization of our approach to the m dimensional case and to other\nstatistical applications (like testing for zero correlation or clustering of\ntime series data with different length) is straightforward. We prove asymptotic\nnormality of an appropriately standardized version of the test statistic both\nunder the null and the alternative and investigate the finite sample properties\nof our method in a simulation study. Furthermore we apply our approach to\ncluster financial time series data with different sample length.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jul 2012 11:09:14 GMT"}], "update_date": "2012-07-25", "authors_parsed": [["Preu\u00df", "Philip", ""], ["Hildebrandt", "Thimo", ""]]}, {"id": "1207.5947", "submitter": "Fabian Scheipl", "authors": "Fabian Scheipl, Ana-Maria Staicu, Sonja Greven", "title": "Functional Additive Mixed Models", "comments": "26 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an extensive framework for additive regression models for\ncorrelated functional responses, allowing for multiple partially nested or\ncrossed functional random effects with flexible correlation structures for,\ne.g., spatial, temporal, or longitudinal functional data. Additionally, our\nframework includes linear and nonlinear effects of functional and scalar\ncovariates that may vary smoothly over the index of the functional response. It\naccommodates densely or sparsely observed functional responses and predictors\nwhich may be observed with additional error and includes both spline-based and\nfunctional principal component-based terms. Estimation and inference in this\nframework is based on standard additive mixed models, allowing us to take\nadvantage of established methods and robust, flexible algorithms. We provide\neasy-to-use open source software in the pffr() function for the R-package\nrefund. Simulations show that the proposed method recovers relevant effects\nreliably, handles small sample sizes well and also scales to larger data sets.\nApplications with spatially and longitudinally observed functional data\ndemonstrate the flexibility in modeling and interpretability of results of our\napproach.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jul 2012 10:29:36 GMT"}, {"version": "v2", "created": "Mon, 15 Jul 2013 13:01:33 GMT"}, {"version": "v3", "created": "Mon, 22 Jul 2013 08:18:05 GMT"}, {"version": "v4", "created": "Wed, 24 Jul 2013 09:01:47 GMT"}, {"version": "v5", "created": "Mon, 25 Nov 2013 14:00:52 GMT"}], "update_date": "2013-11-26", "authors_parsed": [["Scheipl", "Fabian", ""], ["Staicu", "Ana-Maria", ""], ["Greven", "Sonja", ""]]}, {"id": "1207.6059", "submitter": "Aliakbar Gorji Daronkolaei", "authors": "A.A. Gorji, R. Tharmarasa, W.D. Blair and T. Kirubarajan", "title": "Optimal Antenna Allocation in MIMO Radars with Collocated Antennas", "comments": "Submitted to IEEE Transactions on Aerospace and Electronic Systems", "journal-ref": null, "doi": "10.1109/TAES.2013.120384", "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper concerns with the sensor management problem in collocated\nMultiple-Input Multiple-Output (MIMO) radars. After deriving the Cramer-Rao\nLower Bound (CRLB) as a performance measure, the antenna allocation problem is\nformulated as a standard Semi-definite Programming (SDP) for the single-target\ncase. In addition, for multiple unresolved target scenarios, a sampling-based\nalgorithm is proposed to deal with the non-convexity of the cost function.\nSimulations confirm the superiority of the localization results under the\noptimal structure.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jul 2012 17:07:04 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Gorji", "A. A.", ""], ["Tharmarasa", "R.", ""], ["Blair", "W. D.", ""], ["Kirubarajan", "T.", ""]]}, {"id": "1207.6133", "submitter": "Adam Zarn", "authors": "Elliott Hollifield, Victoria Trevino, and Adam Zarn", "title": "A Survival Analysis of the Duration of Olympic Records", "comments": "16 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use recurrent-events survival analysis techniques and methods to analyze\nthe duration of Olympic records. The Kaplan-Meier estimator is used to perform\npreliminary tests and recurrent event survivor function estimators proposed by\nWang & Chang (1999) and Pena et al. (2001) are used to estimate survival\ncurves. Extensions of the Cox Proportional Hazards model are employed as well\nas a discrete-time logistic model for repeated events to estimate models and\nquantify parameter significance. The logistic model was the best fit to the\ndata according to the Akaike Information Criterion (AIC). We discuss, in\ndetail, covariate significance for this model and make predictions of how many\nrecords will be set at the 2012 Olympic Games in London.\n  Keywords: survival analysis, recurrent events, Kaplan-Meier estimator, Cox\nproportional hazards model, Olympics.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jul 2012 21:20:05 GMT"}], "update_date": "2012-07-27", "authors_parsed": [["Hollifield", "Elliott", ""], ["Trevino", "Victoria", ""], ["Zarn", "Adam", ""]]}, {"id": "1207.6327", "submitter": "Alexandre Bouchard-C\\^ot\\'e", "authors": "Alexandre Bouchard-C\\^ot\\'e and Michael I. Jordan", "title": "Evolutionary Inference via the Poisson Indel Process", "comments": "33 pages, 6 figures", "journal-ref": null, "doi": "10.1073/pnas.1220450110", "report-no": null, "categories": "q-bio.PE stat.AP stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of the joint statistical inference of phylogenetic\ntrees and multiple sequence alignments from unaligned molecular sequences. This\nproblem is generally formulated in terms of string-valued evolutionary\nprocesses along the branches of a phylogenetic tree. The classical evolutionary\nprocess, the TKF91 model, is a continuous-time Markov chain model comprised of\ninsertion, deletion and substitution events. Unfortunately this model gives\nrise to an intractable computational problem---the computation of the marginal\nlikelihood under the TKF91 model is exponential in the number of taxa. In this\nwork, we present a new stochastic process, the Poisson Indel Process (PIP), in\nwhich the complexity of this computation is reduced to linear. The new model is\nclosely related to the TKF91 model, differing only in its treatment of\ninsertions, but the new model has a global characterization as a Poisson\nprocess on the phylogeny. Standard results for Poisson processes allow key\ncomputations to be decoupled, which yields the favorable computational profile\nof inference under the PIP model. We present illustrative experiments in which\nBayesian inference under the PIP model is compared to separate inference of\nphylogenies and alignments.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jul 2012 16:52:10 GMT"}, {"version": "v2", "created": "Fri, 18 Jan 2013 16:32:03 GMT"}], "update_date": "2015-06-05", "authors_parsed": [["Bouchard-C\u00f4t\u00e9", "Alexandre", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1207.6430", "submitter": "Christoph Brune", "authors": "Braxton Osting and Christoph Brune and Stanley J. Osher", "title": "Optimal Data Collection For Informative Rankings Expose Well-Connected\n  Graphs", "comments": "31 pages, 10 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": "UCLA CAM report 12-32", "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a graph where vertices represent alternatives and arcs represent\npairwise comparison data, the statistical ranking problem is to find a\npotential function, defined on the vertices, such that the gradient of the\npotential function agrees with the pairwise comparisons. Our goal in this paper\nis to develop a method for collecting data for which the least squares\nestimator for the ranking problem has maximal Fisher information. Our approach,\nbased on experimental design, is to view data collection as a bi-level\noptimization problem where the inner problem is the ranking problem and the\nouter problem is to identify data which maximizes the informativeness of the\nranking. Under certain assumptions, the data collection problem decouples,\nreducing to a problem of finding multigraphs with large algebraic connectivity.\nThis reduction of the data collection problem to graph-theoretic questions is\none of the primary contributions of this work. As an application, we study the\nYahoo! Movie user rating dataset and demonstrate that the addition of a small\nnumber of well-chosen pairwise comparisons can significantly increase the\nFisher informativeness of the ranking. As another application, we study the\n2011-12 NCAA football schedule and propose schedules with the same number of\ngames which are significantly more informative. Using spectral clustering\nmethods to identify highly-connected communities within the division, we argue\nthat the NCAA could improve its notoriously poor rankings by simply scheduling\nmore out-of-conference games.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jul 2012 23:14:34 GMT"}, {"version": "v2", "created": "Wed, 4 Jun 2014 08:31:57 GMT"}], "update_date": "2014-06-05", "authors_parsed": [["Osting", "Braxton", ""], ["Brune", "Christoph", ""], ["Osher", "Stanley J.", ""]]}, {"id": "1207.6488", "submitter": "Krzysztof Bartoszek", "authors": "Krzysztof Bartoszek and Serik Sagitov", "title": "Phylogenetic confidence intervals for the optimal trait value", "comments": null, "journal-ref": "Journal of Applied Probability 52(4):1115-1132, 2015", "doi": "10.1239/jap/1450802756", "report-no": null, "categories": "q-bio.PE stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a stochastic evolutionary model for a phenotype developing\namongst n related species with unknown phylogeny. The unknown tree is modelled\nby a Yule process conditioned on n contemporary nodes. The trait value is\nassumed to evolve along lineages as an Ornstein-Uhlenbeck process. As a result,\nthe trait values of the n species form a sample with dependent observations. We\nestablish three limit theorems for the sample mean corresponding to three\ndomains for the adaptation rate. In the case of fast adaptation, we show that\nfor large $n$ the normalized sample mean is approximately normally distributed.\nUsing these limit theorems, we develop novel confidence interval formulae for\nthe optimal trait value.\n", "versions": [{"version": "v1", "created": "Fri, 27 Jul 2012 08:33:03 GMT"}, {"version": "v2", "created": "Fri, 21 Dec 2012 12:08:20 GMT"}, {"version": "v3", "created": "Fri, 5 Jul 2013 10:15:24 GMT"}, {"version": "v4", "created": "Mon, 19 May 2014 10:59:54 GMT"}, {"version": "v5", "created": "Fri, 7 Nov 2014 22:28:30 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Bartoszek", "Krzysztof", ""], ["Sagitov", "Serik", ""]]}, {"id": "1207.6504", "submitter": "Alberto Hernando", "authors": "A. Hernando, A. Plastino", "title": "Space-time correlations in urban population flows", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP physics.soc-ph", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Evidences are presented concerning tantalizing regularities in cities'\npopulation-flows in what regards to space and time correlations. The former\nexhibit a distance-behavior (for large distances) compatible with the inverse\nsquare law, following an overall Lorentzian dependence with an scale-parameter\nof $74\\pm6$ km. The later decay exponentially with a characteristic time of\n$17.2\\pm1.3$ years. These features can be explained by a dynamical model for\ncities' population-growth of a Lagevinian nature. Numerical simulations based\non the model confirm its applicability. The model also allows for the\nidentification of collective normal modes of city-growth dynamics that can be\nempirically identified.\n", "versions": [{"version": "v1", "created": "Fri, 27 Jul 2012 09:43:21 GMT"}], "update_date": "2012-07-30", "authors_parsed": [["Hernando", "A.", ""], ["Plastino", "A.", ""]]}, {"id": "1207.6796", "submitter": "Ya'acov Ritov", "authors": "Daniel Nevo and Ya'acov Ritov", "title": "Around the goal: Examining the effect of the first goal on the second\n  goal in soccer using survival analysis methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we apply survival techniques to soccer data, treating a goal\nscoring as the event of interest. It specifically concerns the relationship\nbetween the time of the first goal in the game and the time of the second goal.\nIn order to do so, the relevant survival analysis concepts are readjusted to\nfit the problem and a Cox model is developed for the hazard function.\nAttributes such as time dependent covariates and a frailty term are also being\nconsidered. We also use a reliable propensity score to summarize the pre-game\ncovariates. The conclusions derived from the results are that a first goal\noccurrence could either expedite or impede the next goal scoring, depending on\nthe time it was scored. Moreover, once a goal is scored, another goal scoring\nbecome more and more likely as the game progresses. Furthermore, the first goal\neffect is the same whether the goal was scored or conceded.\n", "versions": [{"version": "v1", "created": "Sun, 29 Jul 2012 19:36:50 GMT"}], "update_date": "2012-07-31", "authors_parsed": [["Nevo", "Daniel", ""], ["Ritov", "Ya'acov", ""]]}, {"id": "1207.6950", "submitter": "William Fithian", "authors": "William Fithian, Trevor Hastie", "title": "Finite-sample equivalence in statistical models for presence-only data", "comments": "Published in at http://dx.doi.org/10.1214/13-AOAS667 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2013, Vol. 7, No. 4, 1917-1939", "doi": "10.1214/13-AOAS667", "report-no": "IMS-AOAS-AOAS667", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical modeling of presence-only data has attracted much recent\nattention in the ecological literature, leading to a proliferation of methods,\nincluding the inhomogeneous Poisson process (IPP) model, maximum entropy\n(Maxent) modeling of species distributions and logistic regression models.\nSeveral recent articles have shown the close relationships between these\nmethods. We explain why the IPP intensity function is a more natural object of\ninference in presence-only studies than occurrence probability (which is only\ndefined with reference to quadrat size), and why presence-only data only allows\nestimation of relative, and not absolute intensity of species occurrence. All\nthree of the above techniques amount to parametric density estimation under the\nsame exponential family model (in the case of the IPP, the fitted density is\nmultiplied by the number of presence records to obtain a fitted intensity). We\nshow that IPP and Maxent give the exact same estimate for this density, but\nlogistic regression in general yields a different estimate in finite samples.\nWhen the model is misspecified - as it practically always is - logistic\nregression and the IPP may have substantially different asymptotic limits with\nlarge data sets. We propose ``infinitely weighted logistic regression,'' which\nis exactly equivalent to the IPP in finite samples. Consequently, many\nalready-implemented methods extending logistic regression can also extend the\nMaxent and IPP models in directly analogous ways using this technique.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jul 2012 14:38:53 GMT"}, {"version": "v2", "created": "Mon, 15 Oct 2012 21:52:27 GMT"}, {"version": "v3", "created": "Wed, 8 Jan 2014 09:09:02 GMT"}], "update_date": "2014-01-09", "authors_parsed": [["Fithian", "William", ""], ["Hastie", "Trevor", ""]]}, {"id": "1207.7218", "submitter": "Francesco Finazzi", "authors": "Francesco Finazzi", "title": "Geostatistical modeling in the presence of interaction between the\n  measuring instruments, with an application to the estimation of spatial\n  market potentials", "comments": "Published in at http://dx.doi.org/10.1214/12-AOAS588 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2013, Vol. 7, No. 1, 81-101", "doi": "10.1214/12-AOAS588", "report-no": "IMS-AOAS-AOAS588", "categories": "stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the problem of recovering the spatial market potential\nof a retail product from spatially distributed sales data. In order to tackle\nthe problem in a general way, the concept of spatial potential is introduced.\nThe potential is concurrently measured at different spatial locations and the\nmeasurements are analyzed in order to recover the spatial potential. The\nmeasuring instruments used to collect the data interact with each other, that\nis, the measurement at a given spatial location is affected by the concurrent\nmeasurements at other locations. An approach based on a novel geostatistical\nmodel is developed. In particular, the model is able to handle both the\nmeasuring instrument interaction and the missing data. A model estimation\nprocedure based on the expectation-maximization algorithm is provided as well\nas standard inferential tools. The model is applied to the estimation of the\nspatial market potential of a newspaper for the city of Bergamo, Italy. The\nestimated spatial market potential is eventually analyzed in order to identify\nthe areas with the highest potential, to identify the areas where it is\nprofitable to open additional newsstands and to evaluate the newspaper total\nmarket volume of the city.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jul 2012 12:14:42 GMT"}, {"version": "v2", "created": "Mon, 15 Apr 2013 12:39:25 GMT"}], "update_date": "2015-03-13", "authors_parsed": [["Finazzi", "Francesco", ""]]}, {"id": "1207.7308", "submitter": "Remy Chicheportiche", "authors": "R\\'emy Chicheportiche and Jean-Philippe Bouchaud", "title": "Weighted Kolmogorov-Smirnov test: Accounting for the tails", "comments": "7 pages, 4 figures", "journal-ref": "Phys. Rev. E 86 (4):1115 (2012)", "doi": "10.1103/PhysRevE.86.041115", "report-no": null, "categories": "stat.AP cond-mat.stat-mech q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate goodness-of-fit tests for the extreme tails of empirical\ndistributions is a very important issue, relevant in many contexts, including\ngeophysics, insurance, and finance. We have derived exact asymptotic results\nfor a generalization of the large-sample Kolmogorov-Smirnov test, well suited\nto testing these extreme tails. In passing, we have rederived and made more\nprecise the approximate limit solutions found originally in unrelated fields,\nfirst in [L. Turban, J. Phys. A 25, 127 (1992)] and later in [P. L. Krapivsky\nand S. Redner, Am. J. Phys. 64, 546 (1996)].\n", "versions": [{"version": "v1", "created": "Tue, 31 Jul 2012 16:34:55 GMT"}, {"version": "v2", "created": "Wed, 10 Oct 2012 21:34:14 GMT"}], "update_date": "2012-10-12", "authors_parsed": [["Chicheportiche", "R\u00e9my", ""], ["Bouchaud", "Jean-Philippe", ""]]}]