[{"id": "1106.0114", "submitter": "Vincenzo Carbone", "authors": "Vincenzo Carbone", "title": "Fractional counting of authorship to quantify scientific research output", "comments": "Submitted to Europhysics Letters", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.DL stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the problem of counting co-authorhip in order to quantify the\nimpact and relevance of scientific research output through normalized\n\\textit{h-index} and \\textit{g-index}. We use the papers whose authors belong\nto a subset of full professors of the Italian Settore Scientifico Disciplinare\n(SSD) FIS01 - Experimental Physics. In this SSD two populations, characterized\nby the number of co-authors of each paper, are roughly present. The total\nnumber of citations for each individuals, as well as their h-index and g-index,\nstrongly depends on the average number of co-authors. We show that, in order to\nremove the dependence of the various indices on the two populations, the best\nway to define a fractional counting of autorship is to divide the number of\ncitations received by each paper by the square root of the number of\nco-authors. This allows us to obtain some information which can be used for a\nbetter understanding of the scientific knowledge made through the process of\nwriting and publishing papers.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jun 2011 08:09:37 GMT"}], "update_date": "2011-06-02", "authors_parsed": [["Carbone", "Vincenzo", ""]]}, {"id": "1106.0322", "submitter": "Anthony Lee", "authors": "Anthony Lee, Francois Caron, Arnaud Doucet, Chris Holmes", "title": "Bayesian Sparsity-Path-Analysis of Genetic Association Signal using\n  Generalized t Priors", "comments": null, "journal-ref": "Statistical Applications in Genetics and Molecular Biology. 11(2)\n  (2012)", "doi": null, "report-no": null, "categories": "stat.AP stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the use of generalized t priors on regression coefficients to help\nunderstand the nature of association signal within \"hit regions\" of genome-wide\nassociation studies. The particular generalized t distribution we adopt is a\nStudent distribution on the absolute value of its argument. For low degrees of\nfreedom we show that the generalized t exhibits 'sparsity-prior' properties\nwith some attractive features over other common forms of sparse priors and\nincludes the well known double-exponential distribution as the degrees of\nfreedom tends to infinity. We pay particular attention to graphical\nrepresentations of posterior statistics obtained from sparsity-path-analysis\n(SPA) where we sweep over the setting of the scale (shrinkage / precision)\nparameter in the prior to explore the space of posterior models obtained over a\nrange of complexities, from very sparse models with all coefficient\ndistributions heavily concentrated around zero, to models with diffuse priors\nand coefficients distributed around their maximum likelihood estimates. The SPA\nplots are akin to LASSO plots of maximum a posteriori (MAP) estimates but they\ncharacterise the complete marginal posterior distributions of the coefficients\nplotted as a function of the precision of the prior. Generating posterior\ndistributions over a range of prior precisions is computationally challenging\nbut naturally amenable to sequential Monte Carlo (SMC) algorithms indexed on\nthe scale parameter. We show how SMC simulation on graphic-processing-units\n(GPUs) provides very efficient inference for SPA. We also present a\nscale-mixture representation of the generalized t prior that leads to an EM\nalgorithm to obtain MAP estimates should only these be required.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jun 2011 21:06:50 GMT"}], "update_date": "2012-10-26", "authors_parsed": [["Lee", "Anthony", ""], ["Caron", "Francois", ""], ["Doucet", "Arnaud", ""], ["Holmes", "Chris", ""]]}, {"id": "1106.0330", "submitter": "An Zeng", "authors": "An Zeng, Chi Ho Yeung, Mingsheng Shang, Yi-Cheng Zhang", "title": "The reinforcing influence of recommendations on global diversification", "comments": "6 pages, 6 figures", "journal-ref": "Europhysics Letter 97, 18005 (2012)", "doi": "10.1209/0295-5075/97/18005", "report-no": null, "categories": "physics.soc-ph physics.data-an stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems are promising ways to filter the overabundant information\nin modern society. Their algorithms help individuals to explore decent items,\nbut it is unclear how they allocate popularity among items. In this paper, we\nsimulate successive recommendations and measure their influence on the\ndispersion of item popularity by Gini coefficient. Our result indicates that\nlocal diffusion and collaborative filtering reinforce the popularity of hot\nitems, widening the popularity dispersion. On the other hand, the heat\nconduction algorithm increases the popularity of the niche items and generates\nsmaller dispersion of item popularity. Simulations are compared to mean-field\npredictions. Our results suggest that recommender systems have reinforcing\ninfluence on global diversification.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jun 2011 22:05:22 GMT"}], "update_date": "2015-05-28", "authors_parsed": [["Zeng", "An", ""], ["Yeung", "Chi Ho", ""], ["Shang", "Mingsheng", ""], ["Zhang", "Yi-Cheng", ""]]}, {"id": "1106.0545", "submitter": "Rafael Izbicki Rafael Izbicki", "authors": "Rafael Izbicki, Ann B. Lee and Ender A. Finol", "title": "Assessment of Aortic Aneurysm Rupture Risk", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rupture of an abdominal aortic aneurysm (AAA) is associated with a high\nmortality. When an AAA ruptures, 50% of the patients die before reaching the\nhospital. Of the patients that are able to reach the operating room, only 50%\nhave it successfully repaired (Fillinger et al, 2003). Therefore, it is\nimportant to find good predictors for immediate risk of rupture. Clinically,\nthe size of the aneurysm is the variable vascular surgeons usually use to\nevaluate this risk. Patients with large aneurysms are often sent to surgery.\nHowever, many studies have shown that even small aneurysms can rupture and\ndeserve attention as well. It is important to find good predictors of rupture\nthat also avoid unnecessary surgery as all surgeries are associated with\npossible complications. Here, we use data obtained from 144 computed\ntomographies of patients from the Western Pennsylvania Allegheny Health System\nto predict the high risk of rupture of an aneurysm and also to examine which\nfeatures are important for this goal.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jun 2011 01:24:15 GMT"}, {"version": "v2", "created": "Tue, 7 Jun 2011 16:54:54 GMT"}, {"version": "v3", "created": "Wed, 19 Aug 2015 22:41:16 GMT"}], "update_date": "2015-08-21", "authors_parsed": [["Izbicki", "Rafael", ""], ["Lee", "Ann B.", ""], ["Finol", "Ender A.", ""]]}, {"id": "1106.0599", "submitter": "Jin-Li Guo", "authors": "Chao Fan, Jin-Li Guo", "title": "Research on the visitor flow pattern of Expo 2010", "comments": "12 pages", "journal-ref": "Chin. Phys. B 2012 21(7) 070209", "doi": null, "report-no": null, "categories": "physics.soc-ph cs.SI stat.AP", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Expo 2010 Shanghai China was a successful, splendid and unforgettable event,\nremaining us with valuable experiences. The visitor flow pattern of Expo is\ninvestigated in this paper. The Hurst exponent, mean value and standard\ndeviation of visitor volume prove that the visitor flow is fractal with\nlong-term stability and correlation as well as obvious fluctuation in short\nperiod. Then the time series of visitor volume is converted to complex network\nby visibility algorithm. It can be inferred from the topological properties of\nthe visibility graph that the network is scale-free, small-world and\nhierarchically constructed, conforming that the time series are fractal and\nclose relationship exit between the visitor volume on different days.\nFurthermore, it is inevitable to show some extreme visitor volume in the\noriginal visitor flow, and these extreme points may appear in group to a great\nextent.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jun 2011 09:54:33 GMT"}, {"version": "v2", "created": "Fri, 17 Jun 2011 13:53:04 GMT"}], "update_date": "2014-12-04", "authors_parsed": [["Fan", "Chao", ""], ["Guo", "Jin-Li", ""]]}, {"id": "1106.1915", "submitter": "Mikhail Simkin", "authors": "M.V. Simkin", "title": "Abstract art grandmasters score like class D amateurs", "comments": null, "journal-ref": "Significance, Web exclusive articles, June 29, 2011", "doi": null, "report-no": null, "categories": "physics.pop-ph stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hawley-Dolan and Winner had asked the art students to compare paintings by\nabstract artists with paintings made by a child or by an animal. In 67% of the\ncases, art students said that the painting by a renowned artist is better. I\ncompare this with the winning probability of the chessplayers of different\nratings. I conclude that the great artists score on the level of class D\namateurs.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jun 2011 20:48:42 GMT"}, {"version": "v2", "created": "Fri, 18 Nov 2011 18:16:24 GMT"}], "update_date": "2011-11-21", "authors_parsed": [["Simkin", "M. V.", ""]]}, {"id": "1106.1993", "submitter": "Sorana D. Bolboaca", "authors": "Lorentz J\\\"antschi, Sorana D. Bolboac{\\ba}, Mugur C. B{\\ba}lan and\n  Radu E. Sestra\\c{s}", "title": "Distribution fitting 13. Analysis of independent, multiplicative effect\n  of factors. Application to effect of essential oils extracts from plant\n  species on bacterial species. Application to factors of antibacterial\n  activity of plant species", "comments": "8 pages, 1 figure, 8 tables, research to be presented at Prospects\n  for the 3rd Millennium Agriculture, Biotechnology section", "journal-ref": null, "doi": null, "report-no": "DistFit13", "categories": "stat.ME stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A factor effect study was conducted on a set of observations at the\ncontingency of a series of plant species and bacteria species regarding the\nantibacterial activity of essential oil extracts. The study reveals a very good\nagreement between the observations and the hypothesis of independent and\nmultiplicative effect of plant and bacteria species factors on the\nantibacterial activity. Shaping of the observable to a Negative Binomial\ndistribution allowed the separation of two convoluted Gamma distributions in\nthe observable further assigned to the distribution of factors. Statistics of\nthe Gamma distribution allowed estimating the ratio between diversity of plants\nfactors and bacteria factors in the antibacterial activity of essential oils\nextracts.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jun 2011 09:50:45 GMT"}], "update_date": "2011-06-13", "authors_parsed": [["J\u00e4ntschi", "Lorentz", ""], ["Bolboac{\\ba}", "Sorana D.", ""], ["B{\\ba}lan", "Mugur C.", ""], ["Sestra\u015f", "Radu E.", ""]]}, {"id": "1106.2014", "submitter": "Emmanuel Guerre", "authors": "Alain Guay, Emmanuel Guerre and Stepana Lazarova", "title": "Robust Adaptive Rate-Optimal Testing for the White Noise Hypothesis", "comments": "Article plus Supplementary Material document which groups proofs", "journal-ref": "Journal of Econometrics Volume 176, Issue 2, October 2013, Pages\n  134-145", "doi": "10.1016/j.jeconom.2013.05.001", "report-no": null, "categories": "math.ST stat.AP stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new test is proposed for the weak white noise null hypothesis. The test is\nbased on a new automatic choice of the order for a Box-Pierce or Hong test\nstatistic. The test uses Lobato (2001) or Kuan and Lee (2006) HAC critical\nvalues. The data-driven order choice is tailored to detect a new class of\nalternatives with autocorrelation coefficients which can be $o(n^{-1/2})$\nprovided there are enough of them. A simulation experiment illustrates the good\nbehavior of the test both under the weak white noise null and the alternative.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jun 2011 10:58:35 GMT"}, {"version": "v2", "created": "Fri, 7 Oct 2011 10:54:54 GMT"}, {"version": "v3", "created": "Fri, 2 Nov 2012 17:03:49 GMT"}], "update_date": "2019-08-16", "authors_parsed": [["Guay", "Alain", ""], ["Guerre", "Emmanuel", ""], ["Lazarova", "Stepana", ""]]}, {"id": "1106.2025", "submitter": "Sina Maleki", "authors": "Sina Maleki and Geert Leus", "title": "Censored Truncated Sequential Spectrum Sensing for Cognitive Radio\n  Networks", "comments": "http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=6464630&isnumber=6464503", "journal-ref": "IEEE Journal on Selected Areas in Communications, Vol.31, No.3,\n  pp. 364, 378, March 2013", "doi": "10.1109/JSAC.2013.130304", "report-no": null, "categories": "cs.SY cs.IT math.IT stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reliable spectrum sensing is a key functionality of a cognitive radio\nnetwork. Cooperative spectrum sensing improves the detection reliability of a\ncognitive radio system but also increases the system energy consumption which\nis a critical factor particularly for low-power wireless technologies. A\ncensored truncated sequential spectrum sensing technique is considered as an\nenergy-saving approach. To design the underlying sensing parameters, the\nmaximum energy consumption per sensor is minimized subject to a lower bounded\nglobal probability of detection and an upper bounded false alarm rate. This way\nboth the interference to the primary user due to miss detection and the network\nthroughput as a result of a low false alarm rate is controlled. We compare the\nperformance of the proposed scheme with a fixed sample size censoring scheme\nunder different scenarios. It is shown that as the sensing cost of the\ncognitive radios increases, the energy efficiency of the censored truncated\nsequential approach grows significantly.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jun 2011 12:04:53 GMT"}, {"version": "v2", "created": "Thu, 14 Mar 2013 11:14:10 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Maleki", "Sina", ""], ["Leus", "Geert", ""]]}, {"id": "1106.2124", "submitter": "Ge Wang", "authors": "Ge Wang, Jie Zhang, Hao Gao, Victor Weir, Hengyong Yu, Wenxiang Cong,\n  Xiaochen Xu, Haiou Shen, James Bennett, Yue Wang, Michael Vannier", "title": "Omni-tomography/Multi-tomography -- Integrating Multiple Modalities for\n  Simultaneous Imaging", "comments": "43 pages, 15 figures, 99 references, provisional patent applications\n  filed by Virginia Tech", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.med-ph cs.CV math.NA stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current tomographic imaging systems need major improvements, especially when\nmulti-dimensional, multi-scale, multi-temporal and multi-parametric phenomena\nare under investigation. Both preclinical and clinical imaging now depend on in\nvivo tomography, often requiring separate evaluations by different imaging\nmodalities to define morphologic details, delineate interval changes due to\ndisease or interventions, and study physiological functions that have\ninterconnected aspects. Over the past decade, fusion of multimodality images\nhas emerged with two different approaches: post-hoc image registration and\ncombined acquisition on PET-CT, PET-MRI and other hybrid scanners. There are\nintrinsic limitations for both the post-hoc image analysis and dual/triple\nmodality approaches defined by registration errors and physical constraints in\nthe acquisition chain. We envision that tomography will evolve beyond current\nmodality fusion and towards grand fusion, a large scale fusion of all or many\nimaging modalities, which may be referred to as omni-tomography or\nmulti-tomography. Unlike modality fusion, grand fusion is here proposed for\ntruly simultaneous but often localized reconstruction in terms of all or many\nrelevant imaging mechanisms such as CT, MRI, PET, SPECT, US, optical, and\npossibly more. In this paper, the technical basis for omni-tomography is\nintroduced and illustrated with a top-level design of a next generation\nscanner, interior tomographic reconstructions of representative modalities, and\nanticipated applications of omni-tomography.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jun 2011 17:19:15 GMT"}], "update_date": "2011-06-13", "authors_parsed": [["Wang", "Ge", ""], ["Zhang", "Jie", ""], ["Gao", "Hao", ""], ["Weir", "Victor", ""], ["Yu", "Hengyong", ""], ["Cong", "Wenxiang", ""], ["Xu", "Xiaochen", ""], ["Shen", "Haiou", ""], ["Bennett", "James", ""], ["Wang", "Yue", ""], ["Vannier", "Michael", ""]]}, {"id": "1106.2125", "submitter": "Art B. Owen", "authors": "Art B. Owen, Dean Eckles", "title": "Bootstrapping data arrays of arbitrary order", "comments": "Published in at http://dx.doi.org/10.1214/12-AOAS547 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2012, Vol. 6, No. 3, 895-927", "doi": "10.1214/12-AOAS547", "report-no": "IMS-AOAS-AOAS547", "categories": "stat.ME stat.AP stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study a bootstrap strategy for estimating the variance of a\nmean taken over large multifactor crossed random effects data sets. We apply\nbootstrap reweighting independently to the levels of each factor, giving each\nobservation the product of independently sampled factor weights. No exact\nbootstrap exists for this problem [McCullagh (2000) Bernoulli 6 285-301]. We\nshow that the proposed bootstrap is mildly conservative, meaning biased toward\noverestimating the variance, under sufficient conditions that allow very\nunbalanced and heteroscedastic inputs. Earlier results for a resampling\nbootstrap only apply to two factors and use multinomial weights that are poorly\nsuited to online computation. The proposed reweighting approach can be\nimplemented in parallel and online settings. The results for this method apply\nto any number of factors. The method is illustrated using a 3 factor data set\nof comment lengths from Facebook.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jun 2011 17:26:33 GMT"}, {"version": "v2", "created": "Wed, 25 Jan 2012 01:28:14 GMT"}, {"version": "v3", "created": "Thu, 27 Sep 2012 11:07:10 GMT"}], "update_date": "2012-09-28", "authors_parsed": [["Owen", "Art B.", ""], ["Eckles", "Dean", ""]]}, {"id": "1106.2229", "submitter": "Fionn Murtagh", "authors": "Pedro Contreras and Fionn Murtagh", "title": "Fast, Linear Time Hierarchical Clustering using the Baire Metric", "comments": "27 pages, 6 tables, 10 figures", "journal-ref": "Journal of Classification, July 2012, Volume 29, Issue 2, pp\n  118-143", "doi": "10.1007/s00357-012-9106-3", "report-no": null, "categories": "stat.ML cs.IR stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Baire metric induces an ultrametric on a dataset and is of linear\ncomputational complexity, contrasted with the standard quadratic time\nagglomerative hierarchical clustering algorithm. In this work we evaluate\nempirically this new approach to hierarchical clustering. We compare\nhierarchical clustering based on the Baire metric with (i) agglomerative\nhierarchical clustering, in terms of algorithm properties; (ii) generalized\nultrametrics, in terms of definition; and (iii) fast clustering through k-means\npartititioning, in terms of quality of results. For the latter, we carry out an\nin depth astronomical study. We apply the Baire distance to spectrometric and\nphotometric redshifts from the Sloan Digital Sky Survey using, in this work,\nabout half a million astronomical objects. We want to know how well the (more\ncostly to determine) spectrometric redshifts can predict the (more easily\nobtained) photometric redshifts, i.e. we seek to regress the spectrometric on\nthe photometric redshifts, and we use clusterwise regression for this.\n", "versions": [{"version": "v1", "created": "Sat, 11 Jun 2011 12:05:43 GMT"}], "update_date": "2014-06-24", "authors_parsed": [["Contreras", "Pedro", ""], ["Murtagh", "Fionn", ""]]}, {"id": "1106.2508", "submitter": "Andrew C. Thomas", "authors": "A.C. Thomas and Jose H. Blanchet", "title": "A Practical Implementation of the Bernoulli Factory", "comments": "23 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Bernoulli Factory is an algorithm that takes as input a series of i.i.d.\nBernoulli random variables with an unknown but fixed success probability $p$,\nand outputs a corresponding series of Bernoulli random variables with success\nprobability $f(p)$, where the function $f$ is known and defined on the interval\n$[0,1]$. While several practical uses of the method have been proposed in Monte\nCarlo applications, these require an implementation framework that is flexible,\ngeneral and efficient. We present such a framework for functions that are\neither strictly linear, concave, or convex on the unit interval using a series\nof envelope functions defined through a cascade, and show that this method not\nonly greatly reduces the number of input bits needed in practice compared to\nother currently proposed solutions for more specific problems, and is easy to\nspecify for simple forms, but can easily be coupled to asymptotically efficient\nmethods to allow for theoretically strong results.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jun 2011 18:21:33 GMT"}, {"version": "v2", "created": "Wed, 24 Aug 2011 01:10:17 GMT"}, {"version": "v3", "created": "Tue, 17 Apr 2012 18:01:50 GMT"}], "update_date": "2012-04-18", "authors_parsed": [["Thomas", "A. C.", ""], ["Blanchet", "Jose H.", ""]]}, {"id": "1106.2793", "submitter": "Olivier Francois", "authors": "Katalin Csill\\'ery, Olivier Fran\\c{c}ois, Michael GB Blum", "title": "abc: an R package for Approximate Bayesian Computation (ABC)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE physics.data-an stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many recent statistical applications involve inference under complex models,\nwhere it is computationally prohibitive to calculate likelihoods but possible\nto simulate data. Approximate Bayesian Computation (ABC) is devoted to these\ncomplex models because it bypasses evaluations of the likelihood function using\ncomparisons between observed and simulated summary statistics. We introduce the\nR abc package that implements several ABC algorithms for performing parameter\nestimation and model selection. In particular, the recently developed\nnon-linear heteroscedastic regression methods for ABC are implemented. The abc\npackage also includes a cross-validation tool for measuring the accuracy of ABC\nestimates, and to calculate the misclassification probabilities when performing\nmodel selection. The main functions are accompanied by appropriate summary and\nplotting tools. Considering an example of demographic inference with population\ngenetics data, we show the potential of the R package.\n  R is already widely used in bioinformatics and several fields of biology. The\nR abc package will make the ABC algorithms available to the large number of R\nusers. abc is a freely available R package under the GPL license, and it can be\ndownloaded at http://cran.r-project.org/web/packages/abc/index.html.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jun 2011 19:23:07 GMT"}], "update_date": "2011-06-15", "authors_parsed": [["Csill\u00e9ry", "Katalin", ""], ["Fran\u00e7ois", "Olivier", ""], ["Blum", "Michael GB", ""]]}, {"id": "1106.2832", "submitter": "Joseph Richards", "authors": "Joseph W. Richards, Dan L. Starr, Henrik Brink, Adam A. Miller, Joshua\n  S. Bloom, Nathaniel R. Butler, J. Berian James, James P. Long and John Rice", "title": "Active Learning to Overcome Sample Selection Bias: Application to\n  Photometric Variable Star Classification", "comments": "43 pages, 11 figures, submitted to ApJ", "journal-ref": null, "doi": "10.1088/0004-637X/744/2/192", "report-no": null, "categories": "astro-ph.IM stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the great promise of machine-learning algorithms to classify and\npredict astrophysical parameters for the vast numbers of astrophysical sources\nand transients observed in large-scale surveys, the peculiarities of the\ntraining data often manifest as strongly biased predictions on the data of\ninterest. Typically, training sets are derived from historical surveys of\nbrighter, more nearby objects than those from more extensive, deeper surveys\n(testing data). This sample selection bias can cause catastrophic errors in\npredictions on the testing data because a) standard assumptions for\nmachine-learned model selection procedures break down and b) dense regions of\ntesting space might be completely devoid of training data. We explore possible\nremedies to sample selection bias, including importance weighting (IW),\nco-training (CT), and active learning (AL). We argue that AL---where the data\nwhose inclusion in the training set would most improve predictions on the\ntesting set are queried for manual follow-up---is an effective approach and is\nappropriate for many astronomical applications. For a variable star\nclassification problem on a well-studied set of stars from Hipparcos and OGLE,\nAL is the optimal method in terms of error rate on the testing data, beating\nthe off-the-shelf classifier by 3.4% and the other proposed methods by at least\n3.0%. To aid with manual labeling of variable stars, we developed a web\ninterface which allows for easy light curve visualization and querying of\nexternal databases. Finally, we apply active learning to classify variable\nstars in the ASAS survey, finding dramatic improvement in our agreement with\nthe ACVS catalog, from 65.5% to 79.5%, and a significant increase in the\nclassifier's average confidence for the testing set, from 14.6% to 42.9%, after\na few AL iterations.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jun 2011 22:05:00 GMT"}, {"version": "v2", "created": "Sat, 18 Jun 2011 03:17:09 GMT"}], "update_date": "2015-05-28", "authors_parsed": [["Richards", "Joseph W.", ""], ["Starr", "Dan L.", ""], ["Brink", "Henrik", ""], ["Miller", "Adam A.", ""], ["Bloom", "Joshua S.", ""], ["Butler", "Nathaniel R.", ""], ["James", "J. Berian", ""], ["Long", "James P.", ""], ["Rice", "John", ""]]}, {"id": "1106.2848", "submitter": "Patrick J. Wolfe", "authors": "Florian Luisier, Thierry Blu, Patrick J. Wolfe", "title": "A CURE for noisy magnetic resonance images: Chi-square unbiased risk\n  estimation", "comments": "30 double-spaced pages, 11 figures; submitted for publication", "journal-ref": "IEEE Transactions on Image Processing, vol. 21, pp. 3454-3466,\n  2012", "doi": "10.1109/TIP.2012.2191565", "report-no": null, "categories": "stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we derive an unbiased expression for the expected\nmean-squared error associated with continuously differentiable estimators of\nthe noncentrality parameter of a chi-square random variable. We then consider\nthe task of denoising squared-magnitude magnetic resonance image data, which\nare well modeled as independent noncentral chi-square random variables on two\ndegrees of freedom. We consider two broad classes of linearly parameterized\nshrinkage estimators that can be optimized using our risk estimate, one in the\ngeneral context of undecimated filterbank transforms, and another in the\nspecific case of the unnormalized Haar wavelet transform. The resultant\nalgorithms are computationally tractable and improve upon state-of-the-art\nmethods for both simulated and actual magnetic resonance image data.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jun 2011 00:56:10 GMT"}], "update_date": "2012-10-15", "authors_parsed": [["Luisier", "Florian", ""], ["Blu", "Thierry", ""], ["Wolfe", "Patrick J.", ""]]}, {"id": "1106.3016", "submitter": "Remy Chicheportiche", "authors": "Remy Chicheportiche and Jean-Philippe Bouchaud", "title": "Goodness-of-Fit tests with Dependent Observations", "comments": "26 pages", "journal-ref": "J. Stat. Mech. (2011) P09003", "doi": "10.1088/1742-5468/2011/09/P09003", "report-no": null, "categories": "q-fin.ST cond-mat.stat-mech stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the Kolmogorov-Smirnov and Cram\\'er-von Mises goodness-of-fit\n(GoF) tests and propose a generalisation to identically distributed, but\ndependent univariate random variables. We show that the dependence leads to a\nreduction of the \"effective\" number of independent observations. The\ngeneralised GoF tests are not distribution-free but rather depend on all the\nlagged bivariate copulas. These objects, that we call \"self-copulas\", encode\nall the non-linear temporal dependences. We introduce a specific, log-normal\nmodel for these self-copulas, for which a number of analytical results are\nderived. An application to financial time series is provided. As is well known,\nthe dependence is to be long-ranged in this case, a finding that we confirm\nusing self-copulas. As a consequence, the acceptance rates for GoF tests are\nsubstantially higher than if the returns were iid random variables.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jun 2011 16:22:48 GMT"}, {"version": "v2", "created": "Wed, 3 Aug 2011 08:24:50 GMT"}], "update_date": "2011-09-06", "authors_parsed": [["Chicheportiche", "Remy", ""], ["Bouchaud", "Jean-Philippe", ""]]}, {"id": "1106.3409", "submitter": "Ido Nevat Ido Nevat", "authors": "Gareth W. Peters, Ido Nevat, Jinhong Yuan and Ian B. Collings", "title": "System Identification in Wireless Relay Networks via Gaussian Process", "comments": "28 pages, 9 figures, one table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a flexible stochastic model for a class of cooperative wireless\nrelay networks, in which the relay processing functionality is not known at the\ndestination. In addressing this problem we develop efficient algorithms to\nperform relay identification in a wireless relay network. We first construct a\nstatistical model based on a representation of the system using Gaussian\nProcesses in a non-standard manner due to the way we treat the imperfect\nchannel state information. We then formulate the estimation problem to perform\nsystem identification, taking into account complexity and computational\nefficiency. Next we develop a set of three algorithms to solve the\nidentification problem each of decreasing complexity, trading-off the\nestimation bias for computational efficiency. The joint optimisation problem is\ntackled via a Bayesian framework using the Iterated Conditioning on the Modes\nmethodology. We develop a lower bound and several sub-optimal computationally\nefficient solutions to the identification problem, for comparison. We\nillustrate the estimation performance of our methodology for a range of widely\nused relay functionalities. The relative total error attained by our algorithm\nwhen compared to the lower bound is found to be at worst 9% for low SNR values\nunder all functions considered. The effect of the relay functional estimation\nerror is also studied via BER simulations and is shown to be less than 2dB\nworse than the lower bound.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jun 2011 08:13:03 GMT"}, {"version": "v2", "created": "Fri, 16 Sep 2011 01:17:44 GMT"}, {"version": "v3", "created": "Tue, 17 Jan 2012 06:41:45 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Peters", "Gareth W.", ""], ["Nevat", "Ido", ""], ["Yuan", "Jinhong", ""], ["Collings", "Ian B.", ""]]}, {"id": "1106.3709", "submitter": "Didier Fraix-Burnet", "authors": "Didier Fraix-Burnet (IPAG)", "title": "Multivariate Evolutionary Analyses in Astrophysics", "comments": null, "journal-ref": "Astronomical Data Analysis, 6th conference, Monastir : Tunisia\n  (2010)", "doi": null, "report-no": null, "categories": "astro-ph.CO stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The large amount of data on galaxies, up to higher and higher redshifts, asks\nfor sophisticated statistical approaches to build adequate classifications.\nMultivariate cluster analyses, that compare objects for their global\nsimilarities, are still confidential in astrophysics, probably because their\nresults are somewhat difficult to interpret. We believe that the missing key is\nthe unavoidable characteristics in our Universe: evolution. Our approach, known\nas Astrocladistics, is based on the evolutionary nature of both galaxies and\ntheir properties. It gathers objects according to their \"histories\" and\nestablishes an evolutionary scenario among groups of objects. In this\npresentation, I show two recent results on globular clusters and earlytype\ngalaxies to illustrate how the evolutionary concepts of Astrocladistics can\nalso be useful for multivariate analyses such as K-means Cluster Analysis.\n", "versions": [{"version": "v1", "created": "Sun, 19 Jun 2011 06:23:20 GMT"}], "update_date": "2011-06-22", "authors_parsed": [["Fraix-Burnet", "Didier", "", "IPAG"]]}, {"id": "1106.3814", "submitter": "Eunsik Park Prof", "authors": "Yuan-chin Ivan Chang, Eunsik Park", "title": "Sequential estimation for covariate-adjusted response-adaptive designs", "comments": "26 pages including title page, abstract, 1 figure, and 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In clinical trials, a covariate-adjusted response-adaptive (CARA) design\nallows a subject newly entering a trial a better chance of being allocated to a\nsuperior treatment regimen based on cumulative information from previous\nsubjects, and adjusts the allocation according to individual covariate\ninformation.\n  Since this design allocates subjects sequentially, it is natural to apply a\nsequential method for estimating the treatment effect in order to make the data\nanalysis more efficient.\n  In this paper, we study the sequential estimation of treatment effect for a\ngeneral CARA design. A stopping criterion is proposed such that the estimates\nsatisfy a prescribed precision when the sampling is stopped. The properties of\nestimates and stopping time} are obtained under the proposed stopping rule. In\naddition, we show that the asymptotic properties of the allocation function,\nunder the proposed stopping rule, are the same as those obtained in the\nnon-sequential/fixed sample size counterpart.\n  We then illustrate the performance of the proposed procedure with some\nsimulation results using logistic models. The properties, such as the coverage\nprobability of treatment effect, correct allocation proportion and average\nsample size, for diverse combinations of initial sample sizes and tuning\nparameters in the utility function are discussed.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jun 2011 06:04:29 GMT"}], "update_date": "2011-06-21", "authors_parsed": [["Chang", "Yuan-chin Ivan", ""], ["Park", "Eunsik", ""]]}, {"id": "1106.4500", "submitter": "Ya'acov Ritov", "authors": "E. Greenshtein and Y. Ritov", "title": "Re-calibration of sample means", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of calibration and the GREG method as suggested and\nstudied in Deville and Sarndal (1992). We show that a GREG type estimator is\ntypically not minimal variance unbiased estimator even asymptotically. We\nsuggest a similar estimator which is unbiased but is asymptotically with a\nminimal variance.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jun 2011 16:49:27 GMT"}], "update_date": "2011-06-23", "authors_parsed": [["Greenshtein", "E.", ""], ["Ritov", "Y.", ""]]}, {"id": "1106.4513", "submitter": "Murphy Choy", "authors": "Choy and Ma", "title": "A Markov Chain approach to determine the optimal performance period and\n  bad definition for credit scorecard", "comments": "7 Pages", "journal-ref": "Research Journal of Social Science and Management,Vol 1, No. 6\n  (2011) 227-234", "doi": null, "report-no": null, "categories": "stat.AP stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Performance period determination and bad definition for credit scorecard has\nbeen a mix of fortune for the typical data modeler. The lack of literature on\nthese matters led to a proliferation of approaches and techniques to solve the\nproblems. However, the most commonly accepted approach involves subjective\ninterpretations of the performance period and bad definition as well as being\nchicken and egg problem. These complications result in poorly developed credit\nscorecard with minimal benefits to the banks. In this paper, we will be\nrecommending a simple and effective approach to resolve these issues.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jun 2011 17:21:48 GMT"}, {"version": "v2", "created": "Mon, 3 Oct 2011 13:55:40 GMT"}], "update_date": "2011-10-04", "authors_parsed": [["Choy", "", ""], ["Ma", "", ""]]}, {"id": "1106.4954", "submitter": "Lorentz Jantschi", "authors": "Lorentz J\\\"antschi, Sorana D. Bolboac\\u{a}, Radu E. Sestra\\c{s}", "title": "Distribution fitting 12. Sampling distribution of compounds abundance\n  from plant species measured by instrumentation. Application to plants\n  metabolism classification", "comments": "8 pages, 3 tables, 3 figures; lognormal distribution, combining\n  independent tests of significance, plants classification systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A series of ten plant species belonging to Magnoliopsida - Dicotyledons class\nwere analyzed in terms of chemical compounds distribution of abundance,\nstarting from the assumption that these distributions should give a picture of\nsimilarities and differences between plants metabolism. From a pool of\ntheoretical distributions, log-normal distribution was selected giving the best\naccuracy with the modeled phenomena and agreement with the observed data. From\nobtained lognormal distributions statistics a classification were constructed\nand were compared with the classification based on phylogeny.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jun 2011 12:41:20 GMT"}, {"version": "v2", "created": "Mon, 27 Jun 2011 06:01:32 GMT"}], "update_date": "2011-06-28", "authors_parsed": [["J\u00e4ntschi", "Lorentz", ""], ["Bolboac\u0103", "Sorana D.", ""], ["Sestra\u015f", "Radu E.", ""]]}, {"id": "1106.4989", "submitter": "Alexander Bulinski", "authors": "Alexander Bulinski (LPMA), Oleg Butkovsky, Alexey Shashkin, Pavel\n  Yaskov (MIRAS)", "title": "Statistical methods of SNP data analysis with applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Various statistical methods important for genetic analysis are considered and\ndeveloped. Namely, we concentrate on the multifactor dimensionality reduction,\nlogic regression, random forests and stochastic gradient boosting. These\nmethods and their new modifications, e.g., the MDR method with \"independent\nrule\", are used to study the risk of complex diseases such as cardiovascular\nones. The roles of certain combinations of single nucleotide polymorphisms and\nexternal risk factors are examined. To perform the data analysis concerning the\nischemic heart disease and myocardial infarction the supercomputer SKIF\n\"Chebyshev\" of the Lomonosov Moscow State University was employed.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jun 2011 15:05:57 GMT"}], "update_date": "2011-06-29", "authors_parsed": [["Bulinski", "Alexander", "", "LPMA"], ["Butkovsky", "Oleg", "", "MIRAS"], ["Shashkin", "Alexey", "", "MIRAS"], ["Yaskov", "Pavel", "", "MIRAS"]]}, {"id": "1106.5061", "submitter": "Sharon Aviran", "authors": "Sharon Aviran, Julius B. Lucks, and Lior Pachter", "title": "RNA structure characterization from chemical mapping experiments", "comments": "8 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite great interest in solving RNA secondary structures due to their\nimpact on function, it remains an open problem to determine structure from\nsequence. Among experimental approaches, a promising candidate is the \"chemical\nmodification strategy\", which involves application of chemicals to RNA that are\nsensitive to structure and that result in modifications that can be assayed via\nsequencing technologies. One approach that can reveal paired nucleotides via\nchemical modification followed by sequencing is SHAPE, and it has been used in\nconjunction with capillary electrophoresis (SHAPE-CE) and high-throughput\nsequencing (SHAPE-Seq). The solution of mathematical inverse problems is needed\nto relate the sequence data to the modified sites, and a number of approaches\nhave been previously suggested for SHAPE-CE, and separately for SHAPE-Seq\nanalysis. Here we introduce a new model for inference of chemical modification\nexperiments, whose formulation results in closed-form maximum likelihood\nestimates that can be easily applied to data. The model can be specialized to\nboth SHAPE-CE and SHAPE-Seq, and therefore allows for a direct comparison of\nthe two technologies. We then show that the extra information obtained with\nSHAPE-Seq but not with SHAPE-CE is valuable with respect to ML estimation.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jun 2011 20:29:06 GMT"}, {"version": "v2", "created": "Wed, 29 Jun 2011 16:49:19 GMT"}], "update_date": "2011-06-30", "authors_parsed": [["Aviran", "Sharon", ""], ["Lucks", "Julius B.", ""], ["Pachter", "Lior", ""]]}, {"id": "1106.5242", "submitter": "Alexandre Belloni", "authors": "Alexandre Belloni and Victor Chernozhukov", "title": "High Dimensional Sparse Econometric Models: An Introduction", "comments": null, "journal-ref": "Inverse Problems and High-Dimensional Estimation, Lecture Notes in\n  Statistics, Vol. 203, 2011, pp. 121-156", "doi": null, "report-no": null, "categories": "stat.AP econ.EM stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this chapter we discuss conceptually high dimensional sparse econometric\nmodels as well as estimation of these models using L1-penalization and\npost-L1-penalization methods. Focusing on linear and nonparametric regression\nframeworks, we discuss various econometric examples, present basic theoretical\nresults, and illustrate the concepts and methods with Monte Carlo simulations\nand an empirical application. In the application, we examine and confirm the\nempirical validity of the Solow-Swan model for international economic growth.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jun 2011 18:21:14 GMT"}, {"version": "v2", "created": "Fri, 2 Sep 2011 02:20:42 GMT"}], "update_date": "2017-10-05", "authors_parsed": [["Belloni", "Alexandre", ""], ["Chernozhukov", "Victor", ""]]}, {"id": "1106.5833", "submitter": "Yoshiaki Itoh", "authors": "Miyako Fujiwara, Yoshiaki Itoh, Takeo Matsumoto, Hiroshi Takeda", "title": "Statistical Distribution of Crystallographic Groups for Inorganic\n  Crystal Structure Database", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a method that defines the species (representatives) of inorganic\ncompounds, and studied the statistical distribution of the defined species\namong space groups (distribution of space groups), by using ICSD (Inorganic\nCrystal Structure Database). Here we show that the number of formula units in a\nunit cell gives a natural classification to understand the statistical\ndistribution of crystallographic groups.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jun 2011 02:22:19 GMT"}], "update_date": "2011-06-30", "authors_parsed": [["Fujiwara", "Miyako", ""], ["Itoh", "Yoshiaki", ""], ["Matsumoto", "Takeo", ""], ["Takeda", "Hiroshi", ""]]}, {"id": "1106.5834", "submitter": "Johanna Hardin", "authors": "Johanna Hardin, Stephan Ramon Garcia, David Golan", "title": "A method for generating realistic correlation matrices", "comments": "Published in at http://dx.doi.org/10.1214/13-AOAS638 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2013, Vol. 7, No. 3, 1733-1762", "doi": "10.1214/13-AOAS638", "report-no": "IMS-AOAS-AOAS638", "categories": "math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simulating sample correlation matrices is important in many areas of\nstatistics. Approaches such as generating Gaussian data and finding their\nsample correlation matrix or generating random uniform $[-1,1]$ deviates as\npairwise correlations both have drawbacks. We develop an algorithm for adding\nnoise, in a highly controlled manner, to general correlation matrices. In many\ninstances, our method yields results which are superior to those obtained by\nsimply simulating Gaussian data. Moreover, we demonstrate how our general\nalgorithm can be tailored to a number of different correlation models. Using\nour results with a few different applications, we show that simulating\ncorrelation matrices can help assess statistical methodology.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jun 2011 02:26:57 GMT"}, {"version": "v2", "created": "Thu, 2 Aug 2012 13:14:39 GMT"}, {"version": "v3", "created": "Mon, 28 Jan 2013 14:26:29 GMT"}, {"version": "v4", "created": "Fri, 6 Dec 2013 09:51:00 GMT"}], "update_date": "2013-12-09", "authors_parsed": [["Hardin", "Johanna", ""], ["Garcia", "Stephan Ramon", ""], ["Golan", "David", ""]]}, {"id": "1106.5919", "submitter": "Oliver Ratmann", "authors": "Oliver Ratmann, Pierre Pudlo, Sylvia Richardson, Christian Robert", "title": "Monte Carlo algorithms for model assessment via conflicting summaries", "comments": "Under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The development of statistical methods and numerical algorithms for model\nchoice is vital to many real-world applications. In practice, the ABC approach\ncan be instrumental for sequential model design; however, the theoretical basis\nof its use has been questioned. We present a measure-theoretic framework for\nusing the ABC error towards model choice and describe how easily existing\nrejection, Metropolis-Hastings and sequential importance sampling ABC\nalgorithms are extended for the purpose of model checking. Considering a panel\nof applications from evolutionary biology to dynamic systems, we discuss the\nchoice of summaries which differs from standard ABC approaches. The methods and\nalgorithms presented here may provide the workhorse machinery for an\nexploratory approach to ABC model choice, particularly as the application of\nstandard Bayesian tools can prove impossible.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jun 2011 12:18:45 GMT"}], "update_date": "2011-06-30", "authors_parsed": [["Ratmann", "Oliver", ""], ["Pudlo", "Pierre", ""], ["Richardson", "Sylvia", ""], ["Robert", "Christian", ""]]}]