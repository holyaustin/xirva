[{"id": "1005.0714", "submitter": "Srdjan Verbi\\'c", "authors": "Srdjan Verbic", "title": "Does it matter if you answer slowly?", "comments": "11 pages, 3 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.ed-ph stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we have analyzed item response times measured at a large scale\nunspeeded low stakes test for primary-school students. We have demonstrated the\nexistence of significant difference in the response time for boys and girls as\nwell as difference in response time of correct and incorrect answers on this\ntest. We have also demonstrated existence of the warm up effect for this test.\nThe results show that responses given by girls exhibit much greater warm up\neffect and that difference appears to be the most important cause of the\ndifference on the test level.\n", "versions": [{"version": "v1", "created": "Wed, 5 May 2010 10:15:12 GMT"}, {"version": "v2", "created": "Sun, 28 Dec 2014 22:34:07 GMT"}], "update_date": "2014-12-30", "authors_parsed": [["Verbic", "Srdjan", ""]]}, {"id": "1005.0892", "submitter": "Marie-Pierre Etienne", "authors": "Marie-Pierre Etienne (AgroParisTech), Shannon Obradovich (FC-UBC),\n  Lynne Yamanaka (PBS), Murdoch Mcallister (FC-UBC)", "title": "Extracting abundance indices from longline surveys : method to account\n  for hook competition and unbaited hooks", "comments": "submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The most commonly used relative abundance index in stock assessments of\nlongline fisheries is catch per unit effort (CPUE), here defined as the number\nof fish of the targeted species caught per hook and minute of soak time.\nLongline CPUE can be affected by interspecific competition and the retrieval of\nunbaited or empty hooks, and interannual variation in these can lead to biases\nin the apparent abundance trends in the CPUE. Interspecific competition on\nlonglines has been previously studied but the return of empty hooks is ignored\nin all current treatments of longline CPUE. In this work we propose some\ndifferent methods to build indices to address the interspecific competition\nthat relates to empty hooks. We show that in the absence of information about\nempty hooks, the relative abundance estimates have constant biases with respect\nto fish density and this is typically not problematic for stock assessment. The\nsimple CPUE index behaves poorly in every scenario. Understanding the reasons\nfor empty hooks allows selection of the appropriate index. A scientific\nlongline survey is conducted every two years in the Strait of Georgia, British\nColumbia by Fisheries and Oceans Canada. The above methods are applied to build\nthe time-series of indices from 2003 to 2009 for quillback rockfish (Sebastes\nmaliger). Due to variation in the incidence of non-target species, the index\ntrend obtained is moderately sensitive to the choice of the estimator.\n", "versions": [{"version": "v1", "created": "Thu, 6 May 2010 06:24:10 GMT"}, {"version": "v2", "created": "Thu, 17 Jun 2010 15:12:45 GMT"}, {"version": "v3", "created": "Tue, 30 Apr 2013 11:50:42 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Etienne", "Marie-Pierre", "", "AgroParisTech"], ["Obradovich", "Shannon", "", "FC-UBC"], ["Yamanaka", "Lynne", "", "PBS"], ["Mcallister", "Murdoch", "", "FC-UBC"]]}, {"id": "1005.1480", "submitter": "Nataliya  Horbenko", "authors": "Peter Ruckdeschel, Nataliya Horbenko (Fraunhofer ITWM, Department of\n  Financial Mathematics, Dept. of Mathematics, Univerisity of Kaiserslautern)", "title": "Yet another breakdown point notion: EFSBP - illustrated at scale-shape\n  models", "comments": "21 pages, 4 figures", "journal-ref": "Metrika 75 (8), 2012, pp.1025-1047", "doi": "10.1007/s00184-011-0366-4", "report-no": null, "categories": "stat.ME stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The breakdown point in its different variants is one of the central notions\nto quantify the global robustness of a procedure. We propose a simple\nsupplementary variant which is useful in situations where we have no obvious or\nonly partial equivariance: Extending the Donoho and Huber(1983) Finite Sample\nBreakdown Point, we propose the Expected Finite Sample Breakdown Point to\nproduce less configuration-dependent values while still preserving the finite\nsample aspect of the former definition. We apply this notion for joint\nestimation of scale and shape (with only scale-equivariance available),\nexemplified for generalized Pareto, generalized extreme value, Weibull, and\nGamma distributions. In these settings, we are interested in highly-robust,\neasy-to-compute initial estimators; to this end we study Pickands-type and\nLocation-Dispersion-type estimators and compute their respective breakdown\npoints.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2010 09:25:04 GMT"}, {"version": "v2", "created": "Tue, 1 Feb 2011 17:50:37 GMT"}, {"version": "v3", "created": "Fri, 10 Jun 2011 12:38:24 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Ruckdeschel", "Peter", "", "Fraunhofer ITWM, Department of\n  Financial Mathematics, Dept. of Mathematics, Univerisity of Kaiserslautern"], ["Horbenko", "Nataliya", "", "Fraunhofer ITWM, Department of\n  Financial Mathematics, Dept. of Mathematics, Univerisity of Kaiserslautern"]]}, {"id": "1005.1863", "submitter": "Yair Goldberg", "authors": "Yair Goldberg and Ya'acov Ritov and Avishai Mandelbaum", "title": "The Best Linear Unbiased Estimator for Continuation of a Function", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how to construct the best linear unbiased predictor (BLUP) for the\ncontinuation of a curve in a spline-function model. We assume that the entire\ncurve is drawn from some smooth random process and that the curve is given up\nto some cut point. We demonstrate how to compute the BLUP efficiently.\nConfidence bands for the BLUP are discussed. Finally, we apply the proposed\nBLUP to real-world call center data. Specifically, we forecast the continuation\nof both the call arrival counts and the workload process at the call center of\na commercial bank.\n", "versions": [{"version": "v1", "created": "Tue, 11 May 2010 15:35:05 GMT"}], "update_date": "2010-05-12", "authors_parsed": [["Goldberg", "Yair", ""], ["Ritov", "Ya'acov", ""], ["Mandelbaum", "Avishai", ""]]}, {"id": "1005.2238", "submitter": "Gareth Peters Dr", "authors": "Gareth W. Peters, Geoff R. Hosack, Keith R. Hayes", "title": "Ecological non-linear state space model selection via adaptive particle\n  Markov chain Monte Carlo (AdPMCMC)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.AP stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a novel advanced Particle Markov chain Monte Carlo algorithm that\nis capable of sampling from the posterior distribution of non-linear state\nspace models for both the unobserved latent states and the unknown model\nparameters. We apply this novel methodology to five population growth models,\nincluding models with strong and weak Allee effects, and test if it can\nefficiently sample from the complex likelihood surface that is often associated\nwith these models. Utilising real and also synthetically generated data sets we\nexamine the extent to which observation noise and process error may frustrate\nefforts to choose between these models. Our novel algorithm involves an\nAdaptive Metropolis proposal combined with an SIR Particle MCMC algorithm\n(AdPMCMC). We show that the AdPMCMC algorithm samples complex, high-dimensional\nspaces efficiently, and is therefore superior to standard Gibbs or Metropolis\nHastings algorithms that are known to converge very slowly when applied to the\nnon-linear state space ecological models considered in this paper.\nAdditionally, we show how the AdPMCMC algorithm can be used to recursively\nestimate the Bayesian Cram\\'er-Rao Lower Bound of Tichavsk\\'y (1998). We derive\nexpressions for these Cram\\'er-Rao Bounds and estimate them for the models\nconsidered. Our results demonstrate a number of important features of common\npopulation growth models, most notably their multi-modal posterior surfaces and\ndependence between the static and dynamic parameters. We conclude by sampling\nfrom the posterior distribution of each of the models, and use Bayes factors to\nhighlight how observation noise significantly diminishes our ability to select\namong some of the models, particularly those that are designed to reproduce an\nAllee effect.\n", "versions": [{"version": "v1", "created": "Thu, 13 May 2010 01:28:10 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Peters", "Gareth W.", ""], ["Hosack", "Geoff R.", ""], ["Hayes", "Keith R.", ""]]}, {"id": "1005.2968", "submitter": "Bastiaan Geelhoed", "authors": "B. Geelhoed", "title": "The construction of variance estimators for particulate material\n  sampling", "comments": "This work was presented at the ISBIS-2008 conference in Prague", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The variance of the concentration in a sample can be estimated using\nknowledge of the particle masses, concentrations and the parameter for the\ndependent selection of particles. A number of variance estimators are\nconstructed including a class of hybrid estimators.\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2010 16:37:09 GMT"}], "update_date": "2010-05-18", "authors_parsed": [["Geelhoed", "B.", ""]]}, {"id": "1005.3225", "submitter": "Merlin Keller", "authors": "Merlin Keller and Alexis Roche and Marc Lavielle", "title": "Selection of a Model of Cerebral Activity for fMRI Group Data Analysis", "comments": "PhD Thesis, 208 pages, Applied Statistics and Neuroimaging,\n  University of Orsay, France", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This thesis is dedicated to the statistical analysis of multi-sub ject fMRI\ndata, with the purpose of identifying bain structures involved in certain\ncognitive or sensori-motor tasks, in a reproducible way across sub jects. To\novercome certain limitations of standard voxel-based testing methods, as\nimplemented in the Statistical Parametric Mapping (SPM) software, we introduce\na Bayesian model selection approach to this problem, meaning that the most\nprobable model of cerebral activity given the data is selected from a\npre-defined collection of possible models. Based on a parcellation of the brain\nvolume into functionally homogeneous regions, each model corresponds to a\npartition of the regions into those involved in the task under study and those\ninactive. This allows to incorporate prior information, and avoids the\ndependence of the SPM-like approach on an arbitrary threshold, called the\ncluster- forming threshold, to define active regions. By controlling a Bayesian\nrisk, our approach balances false positive and false negative risk control.\nFurthermore, it is based on a generative model that accounts for the spatial\nuncertainty on the localization of individual effects, due to spatial\nnormalization errors. On both simulated and real fMRI datasets, we show that\nthis new paradigm corrects several biases of the SPM-like approach, which\neither swells or misses the different active regions, depending on the choice\nof a cluster-forming threshold.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2010 15:11:49 GMT"}], "update_date": "2010-05-19", "authors_parsed": [["Keller", "Merlin", ""], ["Roche", "Alexis", ""], ["Lavielle", "Marc", ""]]}, {"id": "1005.3573", "submitter": "Joaquin Ortega", "authors": "A. Bol\\'ivar, E. D\\'iaz-Franc\\'es, J. Ortega, and E. Vilchis", "title": "Profile Likelihood Intervals for Quantiles in Extreme Value\n  Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Profile likelihood intervals of large quantiles in Extreme Value\ndistributions provide a good way to estimate these parameters of interest since\nthey take into account the asymmetry of the likelihood surface in the case of\nsmall and moderate sample sizes; however they are seldom used in practice. In\ncontrast, maximum likelihood asymptotic (mla) intervals are commonly used\nwithout respect to sample size. It is shown here that profile likelihood\nintervals actually are a good alternative for the estimation of quantiles for\nsample sizes $25 \\leq n\\leq 100$ of block maxima, since they presented adequate\ncoverage frequencies in contrast to the poor coverage frequencies of mla\nintervals for these sample sizes, which also tended to underestimate the\nquantile and therefore might be a dangerous statistical practice.\n  In addition, maximum likelihood estimation can present problems when Weibull\nmodels are considered for moderate or small sample sizes due to singularities\nof the corresponding density function when the shape parameter is smaller than\none. These estimation problems can be traced to the commonly used continuous\napproximation to the likelihood function and could be avoided by using the\nexact or correct likelihood function, at least for the settings considered\nhere. A rainfall data example is presented to exemplify the suggested\ninferential procedure based on the analyses of profile likelihoods.\n", "versions": [{"version": "v1", "created": "Wed, 19 May 2010 23:57:22 GMT"}], "update_date": "2010-05-21", "authors_parsed": [["Bol\u00edvar", "A.", ""], ["D\u00edaz-Franc\u00e9s", "E.", ""], ["Ortega", "J.", ""], ["Vilchis", "E.", ""]]}, {"id": "1005.3737", "submitter": "Vasileios Maroulas", "authors": "Vasileios Maroulas and Demosthenes B. Panagiotakos", "title": "Sensitivity of health-related scales is a non-decreasing function of\n  their classes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In biomedical research the use of discrete scales which describe\ncharacteristics of individuals are widely applied for the evaluation of\nclinical conditions. However, the number of classes (partitions) used in a\ndiscrete scale has never been mathematically evaluated against the accuracy of\na scale to predict the true cases. This work, using as accuracy markers the\nsensitivity and specificity, revealed that the number of classes of a discrete\nscale affects its estimating ability of correctly classifying the true\ndiseased. In particular, it was proved that the sensitivity of scales is a\nnon-decreasing function of the number of their classes. This result has\nparticular interest in clinical research providing a methodology for developing\nmore accurate tools for disease diagnosis.\n", "versions": [{"version": "v1", "created": "Thu, 20 May 2010 15:30:27 GMT"}], "update_date": "2010-05-21", "authors_parsed": [["Maroulas", "Vasileios", ""], ["Panagiotakos", "Demosthenes B.", ""]]}, {"id": "1005.3920", "submitter": "Ryszarda Getko", "authors": "R. Getko", "title": "The 10-rotation Periodicity in Sunspot Areas", "comments": "7 pages, 3 figures, submitted in Solar Physics", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP physics.space-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  I study the sunspot area fluctuations over the epoch of 12 solar cycles\n(12-23). Lately, I found three significant quasi-periodicities at 10, 17 and 23\nsolar rotations, but two longer periods could be treated as subharmonics of the\n10-rotation period. Thus, I search this period during the low- and the\nhigh-activity periods of each solar cycles. Because of the N-S asymmetry I\nconsider each solar hemisphere separately. The skewness of each fluctuation\nprobability distribution suggests that the positive and the negative\nfluctuations could be are examined separately. To avoid the problem when a few\nstrong fluctuations could create an auto-correlation or a wavelet peak, I also\nanalyse the transformations of fluctuations for which the amplitudes at the\nhigh- and the low-activity periods are almost the same. The auto-correlation\nand the wavelet analyses show that the 10-rotation period is mainly detected\nduring the high-activity periods, but it also exists during a few low-activity\nperiods.\n", "versions": [{"version": "v1", "created": "Fri, 21 May 2010 09:53:27 GMT"}], "update_date": "2010-05-24", "authors_parsed": [["Getko", "R.", ""]]}, {"id": "1005.3939", "submitter": "Ryszarda Getko", "authors": "R. Getko", "title": "The mid-term periodicities in sunspot areas", "comments": "4 pages, 2 figures", "journal-ref": "Universal Heliophysical Processes, Proceedings IAU Symposium No.\n  257, 2008, p.169-172", "doi": "10.1017/S174392130902924X", "report-no": null, "categories": "stat.AP physics.space-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The sunspot area fluctuations for the northern and the southern hemispheres\nof the Sun over the epoch of 12 cycles (12-23) are investigated. Because of the\nasymmetry of their probability distributions, the positive and the negative\nfluctuations are considered separately. The auto-correlation analysis of them\nshows three quasi-periodicities at 10, 17 and 23 solar rotations. The wavelets\ngives the 10-rotation quasi-periodicity. For the original and the negative\nfluctuations the correlation coefficient between the wavelet and the\nauto-correlation results is about 0.9 for 90% of the auto-correlation peaks.\nFor the positive fluctuations it is also 0.9 for 70% of the peaks. For 90% of\ncycles in both hemispheres the auto-correlation analysis of negative\nfluctuations shows that two longer periods can be represented as the multiple\nof the shortest period. For positive fluctuations such dependences are found\nfor more than 50% of cases.\n", "versions": [{"version": "v1", "created": "Fri, 21 May 2010 11:29:15 GMT"}], "update_date": "2015-05-19", "authors_parsed": [["Getko", "R.", ""]]}, {"id": "1005.4274", "submitter": "Zachary Harmany", "authors": "Zachary T. Harmany, Roummel F. Marcia, Rebecca M. Willett", "title": "This is SPIRAL-TAP: Sparse Poisson Intensity Reconstruction ALgorithms -\n  Theory and Practice", "comments": "11 pages, 7 figures, IEEE Transactions on Image Processing (2011), in\n  press", "journal-ref": null, "doi": "10.1109/TIP.2011.2168410", "report-no": null, "categories": "math.OC stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The observations in many applications consist of counts of discrete events,\nsuch as photons hitting a detector, which cannot be effectively modeled using\nan additive bounded or Gaussian noise model, and instead require a Poisson\nnoise model. As a result, accurate reconstruction of a spatially or temporally\ndistributed phenomenon (f*) from Poisson data (y) cannot be effectively\naccomplished by minimizing a conventional penalized least-squares objective\nfunction. The problem addressed in this paper is the estimation of f* from y in\nan inverse problem setting, where (a) the number of unknowns may potentially be\nlarger than the number of observations and (b) f* admits a sparse\napproximation. The optimization formulation considered in this paper uses a\npenalized negative Poisson log-likelihood objective function with nonnegativity\nconstraints (since Poisson intensities are naturally nonnegative). In\nparticular, the proposed approach incorporates key ideas of using separable\nquadratic approximations to the objective function at each iteration and\npenalization terms related to l1 norms of coefficient vectors, total variation\nseminorms, and partition-based multiscale estimation methods.\n", "versions": [{"version": "v1", "created": "Mon, 24 May 2010 08:20:03 GMT"}, {"version": "v2", "created": "Tue, 11 Oct 2011 17:50:03 GMT"}, {"version": "v3", "created": "Wed, 12 Oct 2011 14:42:24 GMT"}], "update_date": "2011-10-13", "authors_parsed": [["Harmany", "Zachary T.", ""], ["Marcia", "Roummel F.", ""], ["Willett", "Rebecca M.", ""]]}, {"id": "1005.4641", "submitter": "Stilian Stoev", "authors": "Joel Vaughan, Stilian A. Stoev and George Michailidis", "title": "Network-wide Statistical Modeling and Prediction of Computer Traffic", "comments": null, "journal-ref": null, "doi": null, "report-no": "Department of Statistics, the University of Michigan, Technical\n  Report 501", "categories": "stat.AP math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to maintain consistent quality of service, computer network\nengineers face the task of monitoring the traffic fluctuations on the\nindividual links making up the network. However, due to resource constraints\nand limited access, it is not possible to directly measure all the links.\nStarting with a physically interpretable probabilistic model of network-wide\ntraffic, we demonstrate how an expensively obtained set of measurements may be\nused to develop a network-specific model of the traffic across the network.\nThis model may then be used in conjunction with easily obtainable measurements\nto provide more accurate prediction than is possible with only the inexpensive\nmeasurements. We show that the model, once learned may be used for the same\nnetwork for many different periods of traffic. Finally, we show an application\nof the prediction technique to create relevant control charts for detection and\nisolation of shifts in network traffic.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2010 17:36:22 GMT"}], "update_date": "2010-05-26", "authors_parsed": [["Vaughan", "Joel", ""], ["Stoev", "Stilian A.", ""], ["Michailidis", "George", ""]]}, {"id": "1005.4717", "submitter": "Xi Chen", "authors": "Xi Chen, Qihang Lin, Seyoung Kim, Jaime G. Carbonell, Eric P. Xing", "title": "Smoothing proximal gradient method for general structured sparse\n  regression", "comments": "Published in at http://dx.doi.org/10.1214/11-AOAS514 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2012, Vol. 6, No. 2, 719-752", "doi": "10.1214/11-AOAS514", "report-no": "IMS-AOAS-AOAS514", "categories": "stat.ML cs.LG math.OC stat.AP stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of estimating high-dimensional regression models\nregularized by a structured sparsity-inducing penalty that encodes prior\nstructural information on either the input or output variables. We consider two\nwidely adopted types of penalties of this kind as motivating examples: (1) the\ngeneral overlapping-group-lasso penalty, generalized from the group-lasso\npenalty; and (2) the graph-guided-fused-lasso penalty, generalized from the\nfused-lasso penalty. For both types of penalties, due to their nonseparability\nand nonsmoothness, developing an efficient optimization method remains a\nchallenging problem. In this paper we propose a general optimization approach,\nthe smoothing proximal gradient (SPG) method, which can solve structured sparse\nregression problems with any smooth convex loss under a wide spectrum of\nstructured sparsity-inducing penalties. Our approach combines a smoothing\ntechnique with an effective proximal gradient method. It achieves a convergence\nrate significantly faster than the standard first-order methods, subgradient\nmethods, and is much more scalable than the most widely used interior-point\nmethods. The efficiency and scalability of our method are demonstrated on both\nsimulation experiments and real genetic data sets.\n", "versions": [{"version": "v1", "created": "Wed, 26 May 2010 00:50:17 GMT"}, {"version": "v2", "created": "Sun, 21 Nov 2010 21:24:00 GMT"}, {"version": "v3", "created": "Sat, 26 Mar 2011 01:17:05 GMT"}, {"version": "v4", "created": "Fri, 29 Jun 2012 05:53:50 GMT"}], "update_date": "2012-07-02", "authors_parsed": [["Chen", "Xi", ""], ["Lin", "Qihang", ""], ["Kim", "Seyoung", ""], ["Carbonell", "Jaime G.", ""], ["Xing", "Eric P.", ""]]}, {"id": "1005.5081", "submitter": "Luke Bornn", "authors": "Luke Bornn, Fran\\c{c}ois Caron", "title": "Bayesian clustering in decomposable graphs", "comments": "3 figures, 1 table", "journal-ref": "Bornn, L., Caron, F. (2011) Bayesian Clustering in Decomposable\n  Graphs. Bayesian Analysis Vol. 6, No. 4, 829-846", "doi": null, "report-no": null, "categories": "stat.ME stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a class of prior distributions on decomposable\ngraphs, allowing for improved modeling flexibility. While existing methods\nsolely penalize the number of edges, the proposed work empowers practitioners\nto control clustering, level of separation, and other features of the graph.\nEmphasis is placed on a particular prior distribution which derives its\nmotivation from the class of product partition models; the properties of this\nprior relative to existing priors is examined through theory and simulation. We\nthen demonstrate the use of graphical models in the field of agriculture,\nshowing how the proposed prior distribution alleviates the inflexibility of\nprevious approaches in properly modeling the interactions between the yield of\ndifferent crop varieties.\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2010 14:41:10 GMT"}, {"version": "v2", "created": "Thu, 3 May 2012 06:27:01 GMT"}], "update_date": "2013-01-22", "authors_parsed": [["Bornn", "Luke", ""], ["Caron", "Fran\u00e7ois", ""]]}, {"id": "1005.5082", "submitter": "Yu-Min Yen", "authors": "Yu-Min Yen", "title": "A Note on Sparse Minimum Variance Portfolios and Coordinate-Wise Descent\n  Algorithms", "comments": "This paper has been withdrawn by the author due to a crucial sign\n  error in equation 1", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PM q-fin.ST stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this short report, we discuss how coordinate-wise descent algorithms can\nbe used to solve minimum variance portfolio (MVP) problems in which the\nportfolio weights are constrained by $l_{q}$ norms, where $1\\leq q \\leq 2$. A\nportfolio which weights are regularised by such norms is called a sparse\nportfolio (Brodie et al.), since these constraints facilitate sparsity (zero\ncomponents) of the weight vector. We first consider a case when the portfolio\nweights are regularised by a weighted $l_{1}$ and squared $l_{2}$ norm. Then\ntwo benchmark data sets (Fama and French 48 industries and 100 size and BM\nratio portfolios) are used to examine performances of the sparse portfolios.\nWhen the sample size is not relatively large to the number of assets, sparse\nportfolios tend to have lower out-of-sample portfolio variances, turnover\nrates, active assets, short-sale positions, but higher Sharpe ratios than the\nunregularised MVP. We then show some possible extensions; particularly we\nderive an efficient algorithm for solving an MVP problem in which assets are\nallowed to be chosen grouply.\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2010 14:42:36 GMT"}, {"version": "v2", "created": "Fri, 28 May 2010 15:59:38 GMT"}, {"version": "v3", "created": "Mon, 16 Sep 2013 10:32:53 GMT"}], "update_date": "2013-09-17", "authors_parsed": [["Yen", "Yu-Min", ""]]}, {"id": "1005.5348", "submitter": "Ming Lei Dr.", "authors": "Ming Lei, Pierre Del Moral, Christophe Baehr", "title": "Error Analysis of Approximated PCRLBs for Nonlinear Dynamics", "comments": "5 pages, 4 figures;", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.IT math.IT math.NA", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  In practical nonlinear filtering, the assessment of achievable filtering\nperformance is important. In this paper, we focus on the problem of efficiently\napproximate the posterior Cramer-Rao lower bound (CRLB) in a recursive manner.\nBy using Gaussian assumptions, two types of approximations for calculating the\nCRLB are proposed: An exact model using the state estimate as well as a\nTaylor-series-expanded model using both of the state estimate and its error\ncovariance, are derived. Moreover, the difference between the two approximated\nCRLBs is also formulated analytically. By employing the particle filter (PF)\nand the unscented Kalman filter (UKF) to compute, simulation results reveal\nthat the approximated CRLB using mean-covariance-based model outperforms that\nusing the mean-based exact model. It is also shown that the theoretical\ndifference between the estimated CRLBs can be improved through an improved\nfiltering method.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2010 18:03:03 GMT"}], "update_date": "2010-05-31", "authors_parsed": [["Lei", "Ming", ""], ["Del Moral", "Pierre", ""], ["Baehr", "Christophe", ""]]}, {"id": "1005.5494", "submitter": "Anastasia Voulgaraki", "authors": "Anastasia Voulgaraki, Benjamin Kedem, Barry I. Graubard", "title": "Semiparametric regression in testicular germ cell data", "comments": "Published in at http://dx.doi.org/10.1214/12-AOAS552 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2012, Vol. 6, No. 3, 1185-1208", "doi": "10.1214/12-AOAS552", "report-no": "IMS-AOAS-AOAS552", "categories": "stat.ME stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is possible to approach regression analysis with random covariates from a\nsemiparametric perspective where information is combined from multiple\nmultivariate sources. The approach assumes a semiparametric density ratio model\nwhere multivariate distributions are \"regressed\" on a reference distribution. A\nkernel density estimator can be constructed from many data sources in\nconjunction with the semiparametric model. The estimator is shown to be more\nefficient than the traditional single-sample kernel density estimator, and its\noptimal bandwidth is discussed in some detail. Each multivariate distribution\nand the corresponding conditional expectation (regression) of interest are\nestimated from the combined data using all sources. Graphical and quantitative\ndiagnostic tools are suggested to assess model validity. The method is applied\nin quantifying the effect of height and age on weight of germ cell testicular\ncancer patients. Comparisons are made with multiple regression, generalized\nadditive models (GAM) and nonparametric kernel regression.\n", "versions": [{"version": "v1", "created": "Sun, 30 May 2010 02:03:28 GMT"}, {"version": "v2", "created": "Mon, 1 Oct 2012 06:19:14 GMT"}], "update_date": "2012-10-02", "authors_parsed": [["Voulgaraki", "Anastasia", ""], ["Kedem", "Benjamin", ""], ["Graubard", "Barry I.", ""]]}]