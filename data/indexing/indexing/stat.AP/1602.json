[{"id": "1602.00202", "submitter": "Georgi Dinolov", "authors": "Georgi Dinolov, Abel Rodriguez, and Hongyun Wang", "title": "Bayesian stochastic volatility models for high-frequency data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We formulate a discrete-time Bayesian stochastic volatility model for\nhigh-frequency stock-market data that directly accounts for microstructure\nnoise, and outline a Markov chain Monte Carlo algorithm for parameter\nestimation. The methods described in this paper are designed to be coherent\nacross all sampling timescales, with the goal of estimating the latent\nlog-volatility signal from data collected at arbitrarily short sampling\nperiods. In keeping with this goal, we carefully develop a method for eliciting\npriors. The empirical results derived from both simulated and real data show\nthat directly accounting for microstructure in a state-space formulation allows\nfor well-calibrated estimates of the log-volatility process driving prices.\n", "versions": [{"version": "v1", "created": "Sun, 31 Jan 2016 06:07:54 GMT"}], "update_date": "2016-02-02", "authors_parsed": [["Dinolov", "Georgi", ""], ["Rodriguez", "Abel", ""], ["Wang", "Hongyun", ""]]}, {"id": "1602.00245", "submitter": "Shravan Vasishth", "authors": "Bruno Nicenboim and Shravan Vasishth", "title": "Statistical methods for linguistic research: Foundational Ideas - Part\n  II", "comments": "30 pages, 5 figures, 4 tables. Submitted to Language and Linguistics\n  Compass. Comments and suggestions for improvement most welcome", "journal-ref": "Language and Linguistics Compass 2016", "doi": "10.1111/lnc3.12207", "report-no": null, "categories": "stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide an introductory review of Bayesian data analytical methods, with a\nfocus on applications for linguistics, psychology, psycholinguistics, and\ncognitive science. The empirically oriented researcher will benefit from making\nBayesian methods part of their statistical toolkit due to the many advantages\nof this framework, among them easier interpretation of results relative to\nresearch hypotheses, and flexible model specification. We present an informal\nintroduction to the foundational ideas behind Bayesian data analysis, using, as\nan example, a linear mixed models analysis of data from a typical\npsycholinguistics experiment. We discuss hypothesis testing using the Bayes\nfactor, and model selection using cross-validation. We close with some examples\nillustrating the flexibility of model specification in the Bayesian framework.\nSuggestions for further reading are also provided.\n", "versions": [{"version": "v1", "created": "Sun, 31 Jan 2016 13:36:20 GMT"}], "update_date": "2016-12-14", "authors_parsed": [["Nicenboim", "Bruno", ""], ["Vasishth", "Shravan", ""]]}, {"id": "1602.00256", "submitter": "Lev B Klebanov", "authors": "Lev B. Klebanov, Greg Temnov, Ashot V. Kakosyan", "title": "Some Contra-Arguments for the Use of Stable Distributions in Financial\n  Modeling", "comments": "keywords:outliers, financial indexes, heavy tails, stable\n  distributions", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP q-fin.MF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the present paper, we discuss contra-arguments concerning the use of\nPareto-Lev\\'y distributions for modeling in Finance. It appears that such\nprobability laws do not provide sufficient number of outliers observed in real\ndata. Connection with the classical limit theorem for heavy-tailed\ndistributions with such type of models is also questionable. The idea of\nalternative modeling is given.\n", "versions": [{"version": "v1", "created": "Sun, 31 Jan 2016 14:46:06 GMT"}], "update_date": "2016-02-02", "authors_parsed": [["Klebanov", "Lev B.", ""], ["Temnov", "Greg", ""], ["Kakosyan", "Ashot V.", ""]]}, {"id": "1602.00366", "submitter": "Tan Le Thanh", "authors": "Tan Le Thanh, Long Bao Le", "title": "Multi-Channel MAC Protocol for Full-Duplex Cognitive Radio Networks with\n  Optimized Access Control and Load Balancing", "comments": "To appear in 2016 IEEE International Conference on Communications\n  (IEEE ICC 2016). arXiv admin note: text overlap with arXiv:1512.03839", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DC cs.NI math.IT math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a multi-channel full-duplex Medium Access Control\n(MAC) protocol for cognitive radio networks (MFDC-MAC). Our design exploits the\nfact that full-duplex (FD) secondary users (SUs) can perform spectrum sensing\nand access simultaneously, and we employ the randomized dynamic channel\nselection for load balancing among channels and the standard backoff mechanism\nfor contention resolution on each available channel. Then, we develop a\nmathematical model to analyze the throughput performance of the proposed\nMFDC-MAC protocol. Furthermore, we study the protocol configuration\noptimization to maximize the network throughput where we show that this\noptimization can be performed in two steps, namely optimization of access and\ntransmission parameters on each channel and optimization of channel selection\nprobabilities of the users. Such optimization aims at achieving efficient\nself-interference management for FD transceivers, sensing overhead control, and\nload balancing among the channels. Numerical results demonstrate the impacts of\ndifferent protocol parameters and the importance of parameter optimization on\nthe throughput performance as well as the significant performance gain of the\nproposed design compared to traditional design.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2016 02:50:13 GMT"}], "update_date": "2016-02-02", "authors_parsed": [["Thanh", "Tan Le", ""], ["Le", "Long Bao", ""]]}, {"id": "1602.00564", "submitter": "Frank Miller", "authors": "Per Broberg and Frank Miller", "title": "Conditional Estimation in Two-stage Adaptive Designs", "comments": null, "journal-ref": "Broberg P, Miller F (2017). Conditional estimation in two-stage\n  adaptive designs. Biometrics, 73, 895-904", "doi": "10.1111/biom.12642", "report-no": null, "categories": "stat.ME stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider conditional estimation in two-stage sample size adjustable\ndesigns and the following bias. More specifically, we consider a design which\npermits raising the sample size when interim results look rather promising,\nand, which keeps the originally planned sample size when results look very\npromising. The estimation procedures reported comprise the unconditional\nmaximum likelihood, the conditionally unbiased Rao-Blackwell estimator, the\nconditional median unbiased estimator, and the conditional maximum likelihood\nwith and without bias correction. We compare these estimators based on\nanalytical results and by a simulation study. We show in a real clinical trial\nsetting how they can be applied.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2016 15:32:30 GMT"}, {"version": "v2", "created": "Fri, 24 Aug 2018 13:35:09 GMT"}], "update_date": "2018-08-27", "authors_parsed": [["Broberg", "Per", ""], ["Miller", "Frank", ""]]}, {"id": "1602.00724", "submitter": "Yen-Huan  Li", "authors": "Gergely Odor and Yen-Huan Li and Alp Yurtsever and Ya-Ping Hsieh and\n  Quoc Tran-Dinh and Marwa El Halabi and Volkan Cevher", "title": "Frank-Wolfe Works for Non-Lipschitz Continuous Gradient Objectives:\n  Scalable Poisson Phase Retrieval", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a phase retrieval problem in the Poisson noise model. Motivated by\nthe PhaseLift approach, we approximate the maximum-likelihood estimator by\nsolving a convex program with a nuclear norm constraint. While the Frank-Wolfe\nalgorithm, together with the Lanczos method, can efficiently deal with nuclear\nnorm constraints, our objective function does not have a Lipschitz continuous\ngradient, and hence existing convergence guarantees for the Frank-Wolfe\nalgorithm do not apply. In this paper, we show that the Frank-Wolfe algorithm\nworks for the Poisson phase retrieval problem, and has a global convergence\nrate of O(1/t), where t is the iteration counter. We provide rigorous\ntheoretical guarantee and illustrating numerical results.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2016 21:59:15 GMT"}], "update_date": "2016-02-03", "authors_parsed": [["Odor", "Gergely", ""], ["Li", "Yen-Huan", ""], ["Yurtsever", "Alp", ""], ["Hsieh", "Ya-Ping", ""], ["Tran-Dinh", "Quoc", ""], ["Halabi", "Marwa El", ""], ["Cevher", "Volkan", ""]]}, {"id": "1602.00795", "submitter": "Samuel Way", "authors": "Samuel F. Way, Daniel B. Larremore, Aaron Clauset", "title": "Gender, Productivity, and Prestige in Computer Science Faculty Hiring\n  Networks", "comments": "11 pages, 7 figures, 5 tables", "journal-ref": "Proc. 2016 World Wide Web Conference (WWW), 1169-1179 (2016)", "doi": null, "report-no": null, "categories": "cs.SI cs.CY physics.soc-ph stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Women are dramatically underrepresented in computer science at all levels in\nacademia and account for just 15% of tenure-track faculty. Understanding the\ncauses of this gender imbalance would inform both policies intended to rectify\nit and employment decisions by departments and individuals. Progress in this\ndirection, however, is complicated by the complexity and decentralized nature\nof faculty hiring and the non-independence of hires. Using comprehensive data\non both hiring outcomes and scholarly productivity for 2659 tenure-track\nfaculty across 205 Ph.D.-granting departments in North America, we investigate\nthe multi-dimensional nature of gender inequality in computer science faculty\nhiring through a network model of the hiring process. Overall, we find that\nhiring outcomes are most directly affected by (i) the relative prestige between\nhiring and placing institutions and (ii) the scholarly productivity of the\ncandidates. After including these, and other features, the addition of gender\ndid not significantly reduce modeling error. However, gender differences do\nexist, e.g., in scholarly productivity, postdoctoral training rates, and in\ncareer movements up the rankings of universities, suggesting that the effects\nof gender are indirectly incorporated into hiring decisions through gender's\ncovariates. Furthermore, we find evidence that more highly ranked departments\nrecruit female faculty at higher than expected rates, which appears to inhibit\nsimilar efforts by lower ranked departments. These findings illustrate the\nsubtle nature of gender inequality in faculty hiring networks and provide new\ninsights to the underrepresentation of women in computer science.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2016 05:40:17 GMT"}], "update_date": "2016-06-17", "authors_parsed": [["Way", "Samuel F.", ""], ["Larremore", "Daniel B.", ""], ["Clauset", "Aaron", ""]]}, {"id": "1602.00924", "submitter": "Beno\\^it Descamps", "authors": "Beno\\^it Descamps", "title": "(Quantum) Fractional Brownian Motion and Multifractal Processes under\n  the Loop of a Tensor Networks", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph physics.comp-ph stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive fractional Brownian motion and stochastic processes with\nmultifractal properties using a framework of network of Gaussian conditional\nprobabilities. This leads to the derivation of new representations of\nfractional Brownian motion. These constructions are inspired from\nrenormalization. The main result of this paper consists of constructing each\nincrement of the process from two-dimensional gaussian noise inside the\nlight-cone of each seperate increment. Not only does this allows us to derive\nfractional Brownian motion, we can introduce extensions with multifractal\nflavour. In another part of this paper, we discuss the use of the multi-scale\nentanglement renormalization ansatz (MERA), introduced in the study critical\nsystems in quantum spin lattices, as a method for sampling integrals with\nrespect to such multifractal processes. After proper calibration, a MERA\npromises the generation of a sample of size $N$ of a multifractal process in\nthe order of $O(N\\log(N))$, an improvement over the known methods, such as the\nCholesky decomposition and the circulant methods, which scale between $O(N^2)$\nand $O(N^3)$.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2016 13:53:18 GMT"}], "update_date": "2016-02-03", "authors_parsed": [["Descamps", "Beno\u00eet", ""]]}, {"id": "1602.00933", "submitter": "Sean Simpson", "authors": "Sean L. Simpson and Paul J. Laurienti", "title": "Disentangling Brain Graphs: A Note on the Conflation of Network and\n  Connectivity Analyses", "comments": "In Press, Brain Connectivity 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM q-bio.NC stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the human brain remains the Holy Grail in biomedical science,\nand arguably in all of the sciences. Our brains represent the most complex\nsystems in the world (and some contend the universe) comprising nearly one\nhundred billion neurons with septillions of possible connections between them.\nThe structure of these connections engenders an efficient hierarchical system\ncapable of consciousness, as well as complex thoughts, feelings, and behaviors.\nBrain connectivity and network analyses have exploded over the last decade due\nto their potential in helping us understand both normal and abnormal brain\nfunction. Functional connectivity (FC) analysis examines functional\nassociations between time series pairs in specified brain voxels or regions.\nBrain network analysis serves as a distinct subfield of connectivity analysis\nin which associations are quantified for all time series pairs to create an\ninterconnected representation of the brain (a brain network), which allows\nstudying its systemic properties. While connectivity analyses underlie network\nanalyses, the subtle distinction between the two research areas has generally\nbeen overlooked in the literature, with them often being referred to\nsynonymously. However, developing more useful analytic methods and allowing for\nmore precise biological interpretations requires distinguishing these two\ncomplementary domains.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2016 14:11:40 GMT"}], "update_date": "2016-02-03", "authors_parsed": [["Simpson", "Sean L.", ""], ["Laurienti", "Paul J.", ""]]}, {"id": "1602.00989", "submitter": "Stephen Collins-Elliott", "authors": "Stephen A. Collins-Elliott", "title": "Quantifying Artifacts over Time: Interval Estimation of a Poisson\n  Distribution using the Jeffreys Prior", "comments": null, "journal-ref": null, "doi": "10.1111/arcm.12481", "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article presents a new method for estimating the amount of an artifact\nclass in use at a given moment in the past from a random assemblage of\narchaeological finds. This method is based on the use of simulation, since an\nanalytical solution is computationally impractical. Estimating the number of\nartifacts in use at any time $t$ is shown to follow a Poisson distribution,\nwhich allows for credible intervals to be established using the Jeffreys prior.\nThis estimator works from minimal assumptions about the dating and duration of\nfinds, as well as the intensity of collection, and is applied to coinage from\nfour Roman-period sites excavated by the Roman Peasant Project (2009-2014). The\nresult provides for an estimation of the abundance of material according to an\ninterval of certainty.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2016 16:03:29 GMT"}, {"version": "v2", "created": "Thu, 3 May 2018 12:37:49 GMT"}, {"version": "v3", "created": "Mon, 25 Jun 2018 03:20:17 GMT"}, {"version": "v4", "created": "Tue, 12 Mar 2019 21:32:23 GMT"}, {"version": "v5", "created": "Wed, 1 May 2019 20:58:47 GMT"}], "update_date": "2019-08-01", "authors_parsed": [["Collins-Elliott", "Stephen A.", ""]]}, {"id": "1602.01052", "submitter": "Eric Schulz", "authors": "Eric Schulz, Quentin J. M. Huys, Dominik R. Bach, Maarten\n  Speekenbrink, Andreas Krause", "title": "Better safe than sorry: Risky function exploitation through safe\n  optimization", "comments": "6 pages, submitted to Cognitive Science Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exploration-exploitation of functions, that is learning and optimizing a\nmapping between inputs and expected outputs, is ubiquitous to many real world\nsituations. These situations sometimes require us to avoid certain outcomes at\nall cost, for example because they are poisonous, harmful, or otherwise\ndangerous. We test participants' behavior in scenarios in which they have to\nfind the optimum of a function while at the same time avoid outputs below a\ncertain threshold. In two experiments, we find that Safe-Optimization, a\nGaussian Process-based exploration-exploitation algorithm, describes\nparticipants' behavior well and that participants seem to care firstly whether\na point is safe and then try to pick the optimal point from all such safe\npoints. This means that their trade-off between exploration and exploitation\ncan be seen as an intelligent, approximate, and homeostasis-driven strategy.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2016 19:27:54 GMT"}, {"version": "v2", "created": "Sat, 14 May 2016 15:42:05 GMT"}], "update_date": "2016-05-17", "authors_parsed": [["Schulz", "Eric", ""], ["Huys", "Quentin J. M.", ""], ["Bach", "Dominik R.", ""], ["Speekenbrink", "Maarten", ""], ["Krause", "Andreas", ""]]}, {"id": "1602.01206", "submitter": "Julie Josse", "authors": "Julie Josse, Sylvain Sardy, Stefan Wager", "title": "denoiseR: A Package for Low Rank Matrix Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce denoiseR, an R package that provides a unified implementation of\nseveral state-of-the-art proposals for regularized low rank matrix estimation,\nalong with automatic selection of the regularization parameters. We also extend\nthese methods to allow for missing values. The regularization schemes discussed\nin this paper are built around singular-value shrinkage and bootstrap-based\nstability arguments. We illustrate how to use out package by applying it to\nseveral real and simulated datasets, and highlight strengths and weaknesses of\nthe different implemented methods.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2016 06:53:51 GMT"}, {"version": "v2", "created": "Wed, 8 Aug 2018 06:27:50 GMT"}], "update_date": "2018-08-09", "authors_parsed": [["Josse", "Julie", ""], ["Sardy", "Sylvain", ""], ["Wager", "Stefan", ""]]}, {"id": "1602.01370", "submitter": "Igor Barahona Dr", "authors": "Edis Mauricio Sanmiguel JaimesRelated, Igor Barahona Torres and\n  H\\'ector Hugo P\\'erez-Villarreal", "title": "Sensory evaluation of commercial coffee brands in Colombia", "comments": "This paper is a revised and expanded version of a paper entitled.\n  Evaluacion sensorial de marcas comerciales de cafe en Colombia. Presented at\n  the Sexto Coloquio Interdisciplinario de Doctorado. Universidad Popular\n  Autonoma del Estado de Puebla, Puebla City, Mexico, 25 June 2014", "journal-ref": "International Journal of Business and Systems Research (2015)", "doi": "10.1504/IJBSR.2015.071831", "report-no": null, "categories": "stat.AP stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Colombian coffee farmers have traditionally focused their efforts on\nactivities including seeding, planting and drying. Strategic issues to\nsuccessfully compete in the industry, such as branding, marketing and consumer\nresearch, have been neglected. In this research, we apply a type of sensory\nanalysis, based on several statistical techniques used to investigate the key\nfeatures of ten different brands of Colombian coffee. A panel composed of 32\njudges investigated nine different attributes related to flavour, fragrance,\nsweetness and acidity, among others. The last section presents the conclusions\nreached regarding customer preference and brands profiles.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2016 17:19:13 GMT"}], "update_date": "2016-02-08", "authors_parsed": [["JaimesRelated", "Edis Mauricio Sanmiguel", ""], ["Torres", "Igor Barahona", ""], ["P\u00e9rez-Villarreal", "H\u00e9ctor Hugo", ""]]}, {"id": "1602.01462", "submitter": "Hyungsuk Tak", "authors": "Hyungsuk Tak, Kaisey Mandel, David A. van Dyk, Vinay L. Kashyap,\n  Xiao-Li Meng, Aneta Siemiginowska", "title": "Bayesian Estimates of Astronomical Time Delays between Gravitationally\n  Lensed Stochastic Light Curves", "comments": "Accepted for publication in the Annals of Applied Statistics", "journal-ref": "The Annals of Applied Statistics, 2017, 11 (3), 1309-1348", "doi": "10.1214/17-AOAS1027", "report-no": null, "categories": "astro-ph.IM astro-ph.CO stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The gravitational field of a galaxy can act as a lens and deflect the light\nemitted by a more distant object such as a quasar. Strong gravitational lensing\ncauses multiple images of the same quasar to appear in the sky. Since the light\nin each gravitationally lensed image traverses a different path length from the\nquasar to the Earth, fluctuations in the source brightness are observed in the\nseveral images at different times. The time delay between these fluctuations\ncan be used to constrain cosmological parameters and can be inferred from the\ntime series of brightness data or light curves of each image. To estimate the\ntime delay, we construct a model based on a state-space representation for\nirregularly observed time series generated by a latent continuous-time\nOrnstein-Uhlenbeck process. We account for microlensing, an additional source\nof independent long-term extrinsic variability, via a polynomial regression.\nOur Bayesian strategy adopts a Metropolis-Hastings within Gibbs sampler. We\nimprove the sampler by using an ancillarity-sufficiency interweaving strategy\nand adaptive Markov chain Monte Carlo. We introduce a profile likelihood of the\ntime delay as an approximation of its marginal posterior distribution. The\nBayesian and profile likelihood approaches complement each other, producing\nalmost identical results; the Bayesian method is more principled but the\nprofile likelihood is simpler to implement. We demonstrate our estimation\nstrategy using simulated data of doubly- and quadruply-lensed quasars, and\nobserved data from quasars Q0957+561 and J1029+2623.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2016 02:47:34 GMT"}, {"version": "v2", "created": "Thu, 8 Dec 2016 17:21:55 GMT"}, {"version": "v3", "created": "Mon, 30 Jan 2017 22:35:04 GMT"}], "update_date": "2017-10-06", "authors_parsed": [["Tak", "Hyungsuk", ""], ["Mandel", "Kaisey", ""], ["van Dyk", "David A.", ""], ["Kashyap", "Vinay L.", ""], ["Meng", "Xiao-Li", ""], ["Siemiginowska", "Aneta", ""]]}, {"id": "1602.01672", "submitter": "Rui J. Costa", "authors": "Rui J. Costa and Hilde Wilkinson-Herbots", "title": "The Generalised Isolation-With-Migration Model: a Maximum-Likelihood\n  Implementation for Multilocus Data Sets", "comments": "Code in R to fit the GIM model is currently under development", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical inference about the speciation process has often been based on\nthe isolation-with-migration (IM) model, especially when the research aim is to\nlearn about the presence or absence of gene flow during divergence. The\ngeneralised IM model introduced in this paper extends both the standard\ntwo-population IM model and the isolation-with-initial-migration (IIM) model,\nand encompasses both these models as special cases. It can be described as a\ntwo-population IM model in which migration rates and population sizes are\nallowed to change at some point in the past. By developing a maximum-likelihood\nimplementation of this GIM model, we enable inference on both historical and\ncontemporary rates of gene flow between two closely related species. Our method\nrelies on the spectral decomposition of the coalescent generator matrix and is\napplicable to data sets consisting of the numbers of nucleotide differences\nbetween one pair of DNA sequences at each of a large number of independent\nloci.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2016 13:43:51 GMT"}], "update_date": "2016-02-05", "authors_parsed": [["Costa", "Rui J.", ""], ["Wilkinson-Herbots", "Hilde", ""]]}, {"id": "1602.01915", "submitter": "Zo\\'e van Havre", "authors": "Zo\\'e van Havre, Nicole White, Judith Rousseau, and Kerrie Mengersen", "title": "Clustering action potential spikes: Insights on the use of overfitted\n  finite mixture models and Dirichlet process mixture models", "comments": "Submitted to Australian & New Zealand Journal of Statistics on\n  31-Aug-2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The modelling of action potentials from extracellular recordings, or spike\nsorting, is a rich area of neuroscience research in which latent variable\nmodels are often used. Two such models, Overfitted Finite Mixture models (OFMs)\nand Dirichlet Process Mixture models (DPMs) are considered to provide insights\nfor unsupervised clustering of complex, multivariate medical data when the\nnumber of clusters is unknown. OFM and DPM are structured in a similar\nhierarchical fashion but they are based on different philosophies with\ndifferent underlying assumptions. This study investigates how these differences\nimpact on a real study of spike sorting, for the estimation of multivariate\nGaussian location-scale mixture models in the presence of common difficulties\narising from complex medical data. The results provide insights allowing the\nfuture analyst to choose an approach suited to the situation and goal of the\nresearch problem at hand.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2016 03:36:43 GMT"}], "update_date": "2016-02-08", "authors_parsed": [["van Havre", "Zo\u00e9", ""], ["White", "Nicole", ""], ["Rousseau", "Judith", ""], ["Mengersen", "Kerrie", ""]]}, {"id": "1602.02055", "submitter": "Sebastian Weber", "authors": "Sebastian Weber, Andrew Gelman, Daniel Lee, Michael Betancourt, Aki\n  Vehtari, Amy Racine", "title": "Bayesian aggregation of average data: An application in drug development", "comments": "Code is available at https://github.com/wds15/baad and as\n  supplementary material at the publisher site", "journal-ref": "Ann. Appl. Stat., Volume 12, Number 3 (2018), 1583-1604", "doi": "10.1214/17-AOAS1122", "report-no": null, "categories": "stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Throughout the different phases of a drug development program, randomized\ntrials are used to establish the tolerability, safety, and efficacy of a\ncandidate drug. At each stage one aims to optimize the design of future studies\nby extrapolation from the available evidence at the time. This includes\ncollected trial data and relevant external data. However, relevant external\ndata are typically available as averages only, for example from trials on\nalternative treatments reported in the literature. Here we report on such an\nexample from a drug development for wet age-related macular degeneration. This\ndisease is the leading cause of severe vision loss in the elderly. While\ncurrent treatment options are efficacious, they are also a substantial burden\nfor the patient. Hence, new treatments are under development which need to be\ncompared against existing treatments. The general statistical problem this\nleads to is meta-analysis, which addresses the question of how we can combine\ndatasets collected under different conditions. Bayesian methods have long been\nused to achieve partial pooling. Here we consider the challenge when the model\nof interest is complex (hierarchical and nonlinear) and one dataset is given as\nraw data while the second dataset is given as averages only. In such a\nsituation, common meta-analytic methods can only be applied when the model is\nsufficiently simple for analytic approaches. When the model is too complex, for\nexample nonlinear, an analytic approach is not possible. We provide a Bayesian\nsolution by using simulation to approximately reconstruct the likelihood of the\nexternal summary and allowing the parameters in the model to vary under the\ndifferent conditions. We first evaluate our approach using fake-data\nsimulations and then report results for the drug development program that\nmotivated this research.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2016 15:12:33 GMT"}, {"version": "v2", "created": "Wed, 13 May 2020 12:28:50 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Weber", "Sebastian", ""], ["Gelman", "Andrew", ""], ["Lee", "Daniel", ""], ["Betancourt", "Michael", ""], ["Vehtari", "Aki", ""], ["Racine", "Amy", ""]]}, {"id": "1602.02137", "submitter": "Anderson Ara", "authors": "Francisco Louzada and Anderson Ara and Guilherme B. Fernandes", "title": "Classification methods applied to credit scoring: A systematic review\n  and overall comparison", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The need for controlling and effectively managing credit risk has led\nfinancial institutions to excel in improving techniques designed for this\npurpose, resulting in the development of various quantitative models by\nfinancial institutions and consulting companies. Hence, the growing number of\nacademic studies about credit scoring shows a variety of classification methods\napplied to discriminate good and bad borrowers. This paper, therefore, aims to\npresent a systematic literature review relating theory and application of\nbinary classification techniques for credit scoring financial analysis. The\ngeneral results show the use and importance of the main techniques for credit\nrating, as well as some of the scientific paradigm changes throughout the\nyears.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2016 19:52:06 GMT"}], "update_date": "2016-02-08", "authors_parsed": [["Louzada", "Francisco", ""], ["Ara", "Anderson", ""], ["Fernandes", "Guilherme B.", ""]]}, {"id": "1602.02187", "submitter": "Abhyuday Mandal", "authors": "Joshua Lukemire, Abhyuday Mandal, Weng Kee Wong", "title": "Using particle swarm optimization to search for locally $D$-optimal\n  designs for mixed factor experiments with binary response", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying optimal designs for generalized linear models with a binary\nresponse can be a challenging task, especially when there are both continuous\nand discrete independent factors in the model. Theoretical results rarely exist\nfor such models, and the handful that do exist come with restrictive\nassumptions. This paper investigates the use of particle swarm optimization\n(PSO) to search for locally $D$-optimal designs for generalized linear models\nwith discrete and continuous factors and a binary outcome and demonstrates that\nPSO can be an effective method. We provide two real applications using PSO to\nidentify designs for experiments with mixed factors: one to redesign an odor\nremoval study and the second to find an optimal design for an electrostatic\ndischarge study. In both cases we show that the $D$-efficiencies of the designs\nfound by PSO are much better than the implemented designs. In addition, we show\nPSO can efficiently find $D$-optimal designs on a prototype or an irregularly\nshaped design space, provide insights on the existence of minimally supported\noptimal designs, and evaluate sensitivity of the $D$-optimal design to\nmis-specifications in the link function.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2016 23:13:01 GMT"}], "update_date": "2016-02-09", "authors_parsed": [["Lukemire", "Joshua", ""], ["Mandal", "Abhyuday", ""], ["Wong", "Weng Kee", ""]]}, {"id": "1602.02198", "submitter": "Garrett Waycaster", "authors": "Garrett Waycaster, Christian Bes, Volodymyr Bilotkach, Christian Gogu,\n  Raphael Haftka, Nam-Ho Kim", "title": "Robustness Metric for Quantifying Causal Model Confidence and Parameter\n  Uncertainty", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many methods of estimating causal models do not provide estimates of\nconfidence in the resulting model. In this work, a metric is proposed for\nvalidating the output of a causal model fit; the robustness of the model\nstructure with resampled data. The metric is developed for time series causal\nmodels, but is also applicable to non-time series data. The proposed metric may\nbe utilized regardless of the method selected for fitting the causal model. We\nfind that with synthetically generated data, this metric is able to\nsuccessfully identify the true data generating model in most cases.\nAdditionally, the metric provides both a qualitative measure of model\nconfidence represented by the robustness level as well as accurate estimates of\nuncertainty in model coefficients which are important in interpreting model\nresults. The use of this metric is demonstrated on both numerically simulated\ndata and a case study from existing causal model literature.\n", "versions": [{"version": "v1", "created": "Sat, 6 Feb 2016 01:30:28 GMT"}], "update_date": "2016-02-09", "authors_parsed": [["Waycaster", "Garrett", ""], ["Bes", "Christian", ""], ["Bilotkach", "Volodymyr", ""], ["Gogu", "Christian", ""], ["Haftka", "Raphael", ""], ["Kim", "Nam-Ho", ""]]}, {"id": "1602.02435", "submitter": "Stefano Castruccio", "authors": "Stefano Castruccio and Hernando Ombao and Marc G. Genton", "title": "A Multi-Resolution Spatio-Temporal Model for Brain Activation and\n  Connectivity in fMRI Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Functional Magnetic Resonance Imaging (fMRI) is a primary modality for\nstudying brain activity. Modeling spatial dependence of imaging data at\ndifferent scales is one of the main challenges of contemporary neuroimaging,\nand it could allow for accurate testing for significance in neural activity.\nThe high dimensionality of this type of data (on the order of hundreds of\nthousands of voxels) poses serious modeling challenges and considerable\ncomputational constraints. For the sake of feasibility, standard models\ntypically reduce dimensionality by modeling covariance among regions of\ninterest (ROIs) -- coarser or larger spatial units -- rather than among voxels.\nHowever, ignoring spatial dependence at different scales could drastically\nreduce our ability to detect activation patterns in the brain and hence produce\nmisleading results. To overcome these problems, we introduce a multi-resolution\nspatio-temporal model and a computationally efficient methodology to estimate\ncognitive control related activation and whole-brain connectivity. The proposed\nmodel allows for testing voxel-specific activation while accounting for\nnon-stationary local spatial dependence within anatomically defined ROIs, as\nwell as regional dependence (between-ROIs). Furthermore, the model allows for\ndetection of interpretable connectivity patterns among ROIs using the graphical\nLeast Absolute Shrinkage Selection Operator (LASSO). The model is used in a\nmotor-task fMRI study to investigate brain activation and connectivity patterns\naimed at identifying associations between these patterns and regaining motor\nfunctionality following a stroke.\n", "versions": [{"version": "v1", "created": "Sun, 7 Feb 2016 22:18:45 GMT"}, {"version": "v2", "created": "Tue, 9 Feb 2016 08:03:54 GMT"}, {"version": "v3", "created": "Wed, 15 Jun 2016 13:51:32 GMT"}], "update_date": "2016-06-16", "authors_parsed": [["Castruccio", "Stefano", ""], ["Ombao", "Hernando", ""], ["Genton", "Marc G.", ""]]}, {"id": "1602.02542", "submitter": "Leopoldo Catania", "authors": "Leopoldo Catania and Anna Gloria Bill\\'e", "title": "Dynamic Spatial Autoregressive Models with Autoregressive and\n  Heteroskedastic Disturbances", "comments": "33 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME q-fin.PM stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new class of models specifically tailored for spatio-temporal\ndata analysis. To this end, we generalize the spatial autoregressive model with\nautoregressive and heteroskedastic disturbances, i.e. SARAR(1,1), by exploiting\nthe recent advancements in Score Driven (SD) models typically used in time\nseries econometrics. In particular, we allow for time-varying spatial\nautoregressive coefficients as well as time-varying regressor coefficients and\ncross-sectional standard deviations. We report an extensive Monte Carlo\nsimulation study in order to investigate the finite sample properties of the\nMaximum Likelihood estimator for the new class of models as well as its\nflexibility in explaining several dynamic spatial dependence processes. The new\nproposed class of models are found to be economically preferred by rational\ninvestors through an application in portfolio optimization.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2016 12:25:56 GMT"}, {"version": "v2", "created": "Wed, 10 Feb 2016 08:49:36 GMT"}, {"version": "v3", "created": "Sun, 13 Nov 2016 16:36:43 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Catania", "Leopoldo", ""], ["Bill\u00e9", "Anna Gloria", ""]]}, {"id": "1602.02891", "submitter": "Daniel Scharfstein", "authors": "Daniel Scharfstein, Andrea Rotnitzky, Maria Abraham, Aidan McDermott,\n  Richard Chaisson, Lawrence Geiter", "title": "On the analysis of tuberculosis studies with intermittent missing sputum\n  data", "comments": "Published at http://dx.doi.org/10.1214/15-AOAS860 in the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2015, Vol. 9, No. 4, 2215-2236", "doi": "10.1214/15-AOAS860", "report-no": "IMS-AOAS-AOAS860", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In randomized studies evaluating treatments for tuberculosis (TB),\nindividuals are scheduled to be routinely evaluated for the presence of TB\nusing sputum cultures. One important endpoint in such studies is the time of\nculture conversion, the first visit at which a patient's sputum culture is\nnegative and remains negative. This article addresses how to draw inference\nabout treatment effects when sputum cultures are intermittently missing on some\npatients. We discuss inference under a novel benchmark assumption and under a\nclass of assumptions indexed by a treatment-specific sensitivity parameter that\nquantify departures from the benchmark assumption. We motivate and illustrate\nour approach using data from a randomized trial comparing the effectiveness of\ntwo treatments for adult TB patients in Brazil.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2016 08:24:14 GMT"}], "update_date": "2016-02-10", "authors_parsed": [["Scharfstein", "Daniel", ""], ["Rotnitzky", "Andrea", ""], ["Abraham", "Maria", ""], ["McDermott", "Aidan", ""], ["Chaisson", "Richard", ""], ["Geiter", "Lawrence", ""]]}, {"id": "1602.02895", "submitter": "Shengtong Han", "authors": "Shengtong Han, Hongmei Zhang, Gabrielle A. Lockett, Nandini Mukherjee,\n  John W. Holloway, Wilfried Karmaus", "title": "Identifying heterogeneous transgenerational DNA methylation sites via\n  clustering in beta regression", "comments": "Published at http://dx.doi.org/10.1214/15-AOAS865 in the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2015, Vol. 9, No. 4, 2052-2072", "doi": "10.1214/15-AOAS865", "report-no": "IMS-AOAS-AOAS865", "categories": "stat.AP q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores the transgenerational DNA methylation pattern (DNA\nmethylation transmitted from one generation to the next) via a clustering\napproach. Beta regression is employed to model the transmission pattern from\nparents to their offsprings at the population level. To facilitate this goal,\nan expectation maximization algorithm for parameter estimation along with a BIC\ncriterion to determine the number of clusters is proposed. Applying our method\nto the DNA methylation data composed of 4063 CpG sites of 41\nmother-father-infant triads, we identified a set of CpG sites in which DNA\nmethylation transmission is dominated by fathers, while at a large number of\nCpG sites, DNA methylation is mainly maternally transmitted to the offspring.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2016 08:28:53 GMT"}], "update_date": "2016-02-10", "authors_parsed": [["Han", "Shengtong", ""], ["Zhang", "Hongmei", ""], ["Lockett", "Gabrielle A.", ""], ["Mukherjee", "Nandini", ""], ["Holloway", "John W.", ""], ["Karmaus", "Wilfried", ""]]}, {"id": "1602.02898", "submitter": "Renato Guseo", "authors": "Renato Guseo, Cinzia Mortarino", "title": "Modeling competition between two pharmaceutical drugs using innovation\n  diffusion models", "comments": "Published at http://dx.doi.org/10.1214/15-AOAS868 in the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2015, Vol. 9, No. 4, 2073-2089", "doi": "10.1214/15-AOAS868", "report-no": "IMS-AOAS-AOAS868", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study of competition among brands in a common category is an interesting\nstrategic issue for involved firms. Sales monitoring and prediction of\ncompetitors' performance represent relevant tools for management. In the\npharmaceutical market, the diffusion of product knowledge plays a special role,\ndifferent from the role it plays in other competing fields. This latent feature\nnaturally affects the evolution of drugs' performances in terms of the number\nof packages sold. In this paper, we propose an innovation diffusion model that\ntakes the spread of knowledge into account. We are motivated by the need of\nmodeling competition of two antidiabetic drugs in the Italian market.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2016 08:36:02 GMT"}], "update_date": "2016-02-10", "authors_parsed": [["Guseo", "Renato", ""], ["Mortarino", "Cinzia", ""]]}, {"id": "1602.02900", "submitter": "Jie Xiong", "authors": "Jie Xiong, D. P. Dittmer, J. S. Marron", "title": "\"Virus hunting\" using radial distance weighted discrimination", "comments": "Published at http://dx.doi.org/10.1214/15-AOAS869 in the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2015, Vol. 9, No. 4, 2090-2109", "doi": "10.1214/15-AOAS869", "report-no": "IMS-AOAS-AOAS869", "categories": "stat.AP q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the challenge of using DNA-seq data to identify viruses in human\nblood samples, we propose a novel classification algorithm called \"Radial\nDistance Weighted Discrimination\" (or Radial DWD). This classifier is designed\nfor binary classification, assuming one class is surrounded by the other class\nin very diverse radial directions, which is seen to be typical for our virus\ndetection data. This separation of the 2 classes in multiple radial directions\nnaturally motivates the development of Radial DWD. While classical machine\nlearning methods such as the Support Vector Machine and linear Distance\nWeighted Discrimination can sometimes give reasonable answers for a given data\nset, their generalizability is severely compromised because of the linear\nseparating boundary. Radial DWD addresses this challenge by using a more\nappropriate (in this particular case) spherical separating boundary.\nSimulations show that for appropriate radial contexts, this gives much better\ngeneralizability than linear methods, and also much better than conventional\nkernel based (nonlinear) Support Vector Machines, because the latter methods\nessentially use much of the information in the data for determining the shape\nof the separating boundary. The effectiveness of Radial DWD is demonstrated for\nreal virus detection.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2016 08:39:34 GMT"}], "update_date": "2016-02-10", "authors_parsed": [["Xiong", "Jie", ""], ["Dittmer", "D. P.", ""], ["Marron", "J. S.", ""]]}, {"id": "1602.02902", "submitter": "Ying Sun", "authors": "Ying Sun, Michael L. Stein", "title": "A stochastic space-time model for intermittent precipitation occurrences", "comments": "Published at http://dx.doi.org/10.1214/15-AOAS875 in the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2015, Vol. 9, No. 4, 2110-2132", "doi": "10.1214/15-AOAS875", "report-no": "IMS-AOAS-AOAS875", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling a precipitation field is challenging due to its intermittent and\nhighly scale-dependent nature. Motivated by the features of high-frequency\nprecipitation data from a network of rain gauges, we propose a threshold\nspace-time $t$ random field (tRF) model for 15-minute precipitation\noccurrences. This model is constructed through a space-time Gaussian random\nfield (GRF) with random scaling varying along time or space and time. It can be\nviewed as a generalization of the purely spatial tRF, and has a hierarchical\nrepresentation that allows for Bayesian interpretation. Developing appropriate\ntools for evaluating precipitation models is a crucial part of the\nmodel-building process, and we focus on evaluating whether models can produce\nthe observed conditional dry and rain probabilities given that some set of\nneighboring sites all have rain or all have no rain. These conditional\nprobabilities show that the proposed space-time model has noticeable\nimprovements in some characteristics of joint rainfall occurrences for the data\nwe have considered.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2016 08:43:16 GMT"}], "update_date": "2016-02-10", "authors_parsed": [["Sun", "Ying", ""], ["Stein", "Michael L.", ""]]}, {"id": "1602.02908", "submitter": "Alexia Kakourou", "authors": "Alexia Kakourou, Werner Vach, Simone Nicolardi, Yuri van der Burgt and\n  Bart Mertens", "title": "Statistical development and assessment of summary measures to account\n  for isotopic clustering of Fourier transform mass spectrometry data in\n  clinical diagnostic studies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mass spectrometry based clinical proteomics has emerged as a powerful tool\nfor highthroughput protein profiling and biomarker discovery. Recent\nimprovements in mass spectrometry technology have boosted the potential of\nproteomic studies in biomedical research. However, the complexity of the\nproteomic expression introduces new statistical challenges in summarizing and\nanalyzing the acquired data. Statistical methods for optimally processing\nproteomic data are currently a growing field of research. In this paper we\npresent simple, yet appropriate methods to preprocess, summarize and analyze\nhigh-throughput MALDI-FTICR mass spectrometry data, collected in a case-control\nfashion, while dealing with the statistical challenges that accompany such\ndata. The known statistical properties of the isotopic distribution of the\npeptide molecules are used to preprocess the spectra and translate the\nproteomic expression into a condensed data set. Information on either the\nintensity level or the shape of the identified isotopic clusters is used to\nderive summary measures on which diagnostic rules for disease status allocation\nwill be based. Results indicate that both the shape of the identified isotopic\nclusters and the overall intensity level carry information on the class outcome\nand can be used to predict the presence or absence of the disease.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2016 09:07:54 GMT"}], "update_date": "2016-02-10", "authors_parsed": [["Kakourou", "Alexia", ""], ["Vach", "Werner", ""], ["Nicolardi", "Simone", ""], ["van der Burgt", "Yuri", ""], ["Mertens", "Bart", ""]]}, {"id": "1602.02912", "submitter": "Xiaojun Zhang", "authors": "Xiaojun Zhang, Huilan Yang", "title": "The Degree Distribution of Random Birth-and-Death Network with Network\n  Size Decline", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph physics.data-an stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we provide a general method to obtain the exact solutions of\nthe degree distributions for RBDN with network size decline. First by\nstochastic process rules, the steady state transformation equations and steady\nstate degree distribution equations are given in the case of m>2, 0<p<1/2 ,\nthen the average degree of network with n nodes is introduced to calculate the\ndegree distribution. Especially, taking m=3 as an example, we explain the\ndetailed solving process, in which computer simulation is used to verify our\ndegree distribution solutions. In addition, the tail characteristics of the\ndegree distribution are discussed. Our findings suggest that the degree\ndistributions will exhibit Poisson tail property for the declining RBDN.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2016 09:33:58 GMT"}], "update_date": "2016-02-10", "authors_parsed": [["Zhang", "Xiaojun", ""], ["Yang", "Huilan", ""]]}, {"id": "1602.02945", "submitter": "Adeel Razi", "authors": "Adeel Razi and Karl Friston", "title": "The connected brain: Causality, models and intrinsic dynamics", "comments": "52 pages, Feature Article, Accepted, IEEE Signal Processing Magazine", "journal-ref": null, "doi": "10.1109/MSP.2015.2482121", "report-no": null, "categories": "q-bio.NC math.DS stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, there have been several concerted international efforts - the BRAIN\ninitiative, European Human Brain Project and the Human Connectome Project, to\nname a few - that hope to revolutionize our understanding of the connected\nbrain. Over the past two decades, functional neuroimaging has emerged as the\npredominant technique in systems neuroscience. This is foreshadowed by an ever\nincreasing number of publications on functional connectivity, causal modeling,\nconnectomics, and multivariate analyses of distributed patterns of brain\nresponses. In this article, we summarize pedagogically the (deep) history of\nbrain mapping. We will highlight the theoretical advances made in the (dynamic)\ncausal modelling of brain function - that may have escaped the wider audience\nof this article - and provide a brief overview of recent developments and\ninteresting clinical applications. We hope that this article will engage the\nsignal processing community by showcasing the inherently multidisciplinary\nnature of this important topic and the intriguing questions that are being\naddressed.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2016 11:54:38 GMT"}], "update_date": "2016-02-10", "authors_parsed": [["Razi", "Adeel", ""], ["Friston", "Karl", ""]]}, {"id": "1602.03131", "submitter": "Kinjal Basu", "authors": "Kinjal Basu, Ankan Saha, Shaunak Chatterjee", "title": "Large scale multi-objective optimization: Theoretical and practical\n  challenges", "comments": "10 pages, 2 figures, KDD'16 Submitted Version", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-objective optimization (MOO) is a well-studied problem for several\nimportant recommendation problems. While multiple approaches have been\nproposed, in this work, we focus on using constrained optimization formulations\n(e.g., quadratic and linear programs) to formulate and solve MOO problems. This\napproach can be used to pick desired operating points on the trade-off curve\nbetween multiple objectives. It also works well for internet applications which\nserve large volumes of online traffic, by working with Lagrangian duality\nformulation to connect dual solutions (computed offline) with the primal\nsolutions (computed online).\n  We identify some key limitations of this approach -- namely the inability to\nhandle user and item level constraints, scalability considerations and variance\nof dual estimates introduced by sampling processes. We propose solutions for\neach of the problems and demonstrate how through these solutions we\nsignificantly advance the state-of-the-art in this realm. Our proposed methods\ncan exactly handle user and item (and other such local) constraints, achieve a\n$100\\times$ scalability boost over existing packages in R and reduce variance\nof dual estimates by two orders of magnitude.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2016 19:43:45 GMT"}, {"version": "v2", "created": "Sat, 13 Feb 2016 08:42:01 GMT"}], "update_date": "2016-02-16", "authors_parsed": [["Basu", "Kinjal", ""], ["Saha", "Ankan", ""], ["Chatterjee", "Shaunak", ""]]}, {"id": "1602.03244", "submitter": "Dibya Ghosh", "authors": "Dibya Jyoti Ghosh", "title": "Development of a Computationally Optimized Model of Cancer-induced\n  Angiogenesis through Specialized Cellular Mechanics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.CB stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Angiogenesis, the development of new vasculature, is a critical process in\nthe growth of new tumors. Driven by a goal to understand this aspect of cancer\nproliferation, I develop a discrete computationally optimized mathematical\nmodel of angiogenesis that specializes in intercellular interactions. I model\nvascular endothelial growth factor spread and dynamics of endothelial cell\nmovement in a competitive environment, with parameters specific to our model\ncalculated through Dependent Variable Sensitivity Analysis (DVSA) and\nexperimentally observed data. Through simulation testing, we find the critical\nlimits of angiogenesis to be 102 m and 153 m respectively, beyond which\nangiogenesis will not successfully occur. Cell density in the surrounding\nregion and the concentration of extracellular matrix fibers are also found to\ndirectly inhibit angiogenesis. Through these three factors, we postulate a\nmethod for establishing criticality of a tumor based upon the likelihood of\nangiogenesis completing. This research expands on other work by choosing\nfactors that are patient-dependent through our specialized Cellular Potts mode,\nwhich serves to optimize and increase accuracy of the model. By doing such, I\nestablish a theoretical framework for analyzing lesions using angiogenetic\nproperties, with the ability to potentially compute the criticality of tumors\nwith the aid of medical imaging technology.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2016 02:36:27 GMT"}], "update_date": "2016-02-11", "authors_parsed": [["Ghosh", "Dibya Jyoti", ""]]}, {"id": "1602.03386", "submitter": "Nevine Demitri", "authors": "Nevine Demitri, Abdelhak M. Zoubir", "title": "Measuring Blood Glucose Concentrations in Photometric Glucometers\n  Requiring Very Small Sample Volumes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Glucometers present an important self-monitoring tool for diabetes patients\nand therefore must exhibit high accu- racy as well as good usability features.\nBased on an invasive, photometric measurement principle that drastically\nreduces the volume of the blood sample needed from the patient, we present a\nframework that is capable of dealing with small blood samples, while\nmaintaining the required accuracy. The framework consists of two major parts:\n1) image segmentation; and 2) convergence detection. Step 1) is based on\niterative mode-seeking methods to estimate the intensity value of the region of\ninterest. We present several variations of these methods and give theoretical\nproofs of their convergence. Our approach is able to deal with changes in the\nnumber and position of clusters without any prior knowledge. Furthermore, we\npropose a method based on sparse approximation to decrease the computational\nload, while maintaining accuracy. Step 2) is achieved by employing temporal\ntracking and prediction, herewith decreasing the measurement time, and, thus,\nimproving usability. Our framework is validated on several real data sets with\ndifferent characteristics. We show that we are able to estimate the underlying\nglucose concentration from much smaller blood samples than is currently\nstate-of-the- art with sufficient accuracy according to the most recent ISO\nstandards and reduce measurement time significantly compared to\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2016 14:39:58 GMT"}], "update_date": "2016-02-11", "authors_parsed": [["Demitri", "Nevine", ""], ["Zoubir", "Abdelhak M.", ""]]}, {"id": "1602.03423", "submitter": "Quentin Frederik Gronau", "authors": "Quentin F. Gronau and Eric-Jan Wagenmakers", "title": "Bayesian Evidence Accumulation in Experimental Mathematics: A Case Study\n  of Four Irrational Numbers", "comments": "17 pages (including references), 7 figures, revised version", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many questions in experimental mathematics are fundamentally inductive in\nnature. Here we demonstrate how Bayesian inference --the logic of partial\nbeliefs-- can be used to quantify the evidence that finite data provide in\nfavor of a general law. As a concrete example we focus on the general law which\nposits that certain fundamental constants (i.e., the irrational numbers $\\pi$,\n$e$, $\\sqrt2$, and $\\ln{2}$) are normal; specifically, we consider the more\nrestricted hypothesis that each digit in the constant's decimal expansion\noccurs equally often. Our analysis indicates that for each of the four\nconstants, the evidence in favor of the general law is overwhelming. We argue\nthat the Bayesian paradigm is particularly apt for applications in experimental\nmathematics, a field in which the plausibility of a general law is in need of\nconstant revision in light of data sets whose size is increasing continually\nand indefinitely.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2016 15:58:52 GMT"}, {"version": "v2", "created": "Fri, 12 Feb 2016 10:54:47 GMT"}, {"version": "v3", "created": "Mon, 19 Jun 2017 08:16:57 GMT"}], "update_date": "2017-06-20", "authors_parsed": [["Gronau", "Quentin F.", ""], ["Wagenmakers", "Eric-Jan", ""]]}, {"id": "1602.03429", "submitter": "Roberto Fontana", "authors": "Cristina Coscia, Roberto Fontana and Patrizia Semeraro", "title": "Graphical models for studying museum networks: the Abbonamento Musei\n  Torino Piemonte", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic graphical models are a powerful tool to represent real-word\nphenomena and to learn network structures starting from data. This paper\napplies graphical models in a new framework to study association rules driven\nby consumer choices in a network of museums. The network consists of the\nmuseums participating in the program of Abbonamento Musei Torino Piemonte,\nwhich is a yearly subscription managed by the Associazione Torino Citt\\`a\nCapitale Europea. Consumers are card-holders, who are allowed to entry to all\nthe museums in the network for one year. We employ graphical models to\nhighlight associations among the museums driven by card-holder visiting\nbehaviour. We use both undirected graphs to investigate the strength of the\nnetwork and directed graphs to highlight asimmetry in the association rules.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2016 16:18:00 GMT"}], "update_date": "2016-02-11", "authors_parsed": [["Coscia", "Cristina", ""], ["Fontana", "Roberto", ""], ["Semeraro", "Patrizia", ""]]}, {"id": "1602.03551", "submitter": "Stephanie L. Hyland", "authors": "Stephanie L. Hyland, Theofanis Karaletsos, Gunnar R\\\"atsch", "title": "Knowledge Transfer with Medical Language Embeddings", "comments": "6 pages, 2 figures, to appear at SDM-DMMH 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying relationships between concepts is a key aspect of scientific\nknowledge synthesis. Finding these links often requires a researcher to\nlaboriously search through scien- tific papers and databases, as the size of\nthese resources grows ever larger. In this paper we describe how distributional\nsemantics can be used to unify structured knowledge graphs with unstructured\ntext to predict new relationships between medical concepts, using a\nprobabilistic generative model. Our approach is also designed to ameliorate\ndata sparsity and scarcity issues in the medical domain, which make language\nmodelling more challenging. Specifically, we integrate the medical relational\ndatabase (SemMedDB) with text from electronic health records (EHRs) to perform\nknowledge graph completion. We further demonstrate the ability of our model to\npredict relationships between tokens not appearing in the relational database.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2016 22:02:29 GMT"}], "update_date": "2016-02-12", "authors_parsed": [["Hyland", "Stephanie L.", ""], ["Karaletsos", "Theofanis", ""], ["R\u00e4tsch", "Gunnar", ""]]}, {"id": "1602.03649", "submitter": "Abderrahim Halimi", "authors": "Abderrahim Halimi and Gerald S. Buller and Steve McLaughlin and Paul\n  Honeine", "title": "Bayesian Filtering of Smooth Signals: Application to Altimetry", "comments": "7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel Bayesian strategy for the estimation of smooth\nsignals corrupted by Gaussian noise. The method assumes a smooth evolution of a\nsuccession of continuous signals that can have a numerical or an analytical\nexpression with respect to some parameters. The Bayesian model proposed takes\ninto account the Gaussian properties of the noise and the smooth evolution of\nthe successive signals. In addition, a gamma Markov random field prior is\nassigned to the signal energies and to the noise variances to account for their\nknown properties. The resulting posterior distribution is maximized using a\nfast coordinate descent algorithm whose parameters are updated by analytical\nexpressions. The proposed algorithm is tested on satellite altimetric data\ndemonstrating good denoising results on both synthetic and real signals. The\nproposed algorithm is also shown to improve the quality of the altimetric\nparameters when combined with a parameter estimation strategy.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2016 09:30:04 GMT"}], "update_date": "2016-02-12", "authors_parsed": [["Halimi", "Abderrahim", ""], ["Buller", "Gerald S.", ""], ["McLaughlin", "Steve", ""], ["Honeine", "Paul", ""]]}, {"id": "1602.03855", "submitter": "Ying Lu", "authors": "Ying Lu, Marc Scott and Preeti Raghavan", "title": "A Statistical Framework for Single Subject Design with an Application in\n  Post-stroke Rehabilitation", "comments": "31 pages, 3 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a practical yet novel solution to a longstanding\nstatistical testing problem regarding single subject design. In particular, we\naim to resolve an important clinical question: does a new patient behave the\nsame as one from a healthy population? This question cannot be answered using\nthe traditional single subject design when only test subject information is\nused, nor can it be satisfactorily resolved by comparing a single-subject's\ndata with the mean value of a healthy population without proper assessment of\nthe impact of between and within subject variability. Here, we use Bayesian\nposterior predictive draws based on a training set of healthy subjects to\ngenerate a template null distribution of the statistic of interest to test\nwhether the test subject belongs to the healthy population. This method also\nprovides an estimate of the error rate associated with the decision and\nprovides a confidence interval for the point estimate of interest. Taken\ntogether, this information will enable clinicians to conduct evidence-based\nclinical decision making by directly comparing the observed measures with a\nprecalculated null distribution for such measures. Simulation studies show that\nthe proposed test performs satisfactorily under controlled conditions.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2016 19:47:24 GMT"}], "update_date": "2016-02-12", "authors_parsed": [["Lu", "Ying", ""], ["Scott", "Marc", ""], ["Raghavan", "Preeti", ""]]}, {"id": "1602.03926", "submitter": "Igor Barahona Dr", "authors": "Igor Barahona, Judith Cavazos, and Jian-Bo Yang", "title": "Modelling the level of adoption of analytical tools; An implementation\n  of multi-criteria evidential reasoning", "comments": "Keywords: MCDA methods; evidential reasoning; analytical tools;\n  multiple source data", "journal-ref": "International Journal of Supply and Operations Management. (2014)\n  Vol.1, Issue 2, pp 129-151", "doi": null, "report-no": null, "categories": "stat.AP cs.CY stat.OT", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In the future, competitive advantages will be given to organisations that can\nextract valuable information from massive data and make better decisions. In\nmost cases, this data comes from multiple sources. Therefore, the challenge is\nto aggregate them into a common framework in order to make them meaningful and\nuseful. This paper will first review the most important multi-criteria decision\nanalysis methods (MCDA) existing in current literature. We will offer a novel,\npractical and consistent methodology based on a type of MCDA, to aggregate data\nfrom two different sources into a common framework. Two datasets that are\ndifferent in nature but related to the same topic are aggregated to a common\nscale by implementing a set of transformation rules. This allows us to generate\nappropriate evidence for assessing and finally prioritising the level of\nadoption of analytical tools in four types of companies. A numerical example is\nprovided to clarify the form for implementing this methodology. A six-step\nprocess is offered as a guideline to assist engineers, researchers or\npractitioners interested in replicating this methodology in any situation where\nthere is a need to aggregate and transform multiple source data.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2016 23:02:10 GMT"}], "update_date": "2016-05-11", "authors_parsed": [["Barahona", "Igor", ""], ["Cavazos", "Judith", ""], ["Yang", "Jian-Bo", ""]]}, {"id": "1602.03940", "submitter": "Simon Mak", "authors": "Simon Mak, Derek Bingham, Yi Lu", "title": "A regional compound Poisson process for hurricane and tropical storm\n  damage", "comments": "Accepted to Journal of the Royal Statistical Society, Series C on\n  January 25th (2016). Pending publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In light of intense hurricane activity along the U.S. Atlantic coast,\nattention has turned to understanding both the economic impact and behaviour of\nthese storms. The compound Poisson-lognormal process has been proposed as a\nmodel for aggregate storm damage, but does not shed light on regional analysis\nsince storm path data are not used. In this paper, we propose a fully Bayesian\nregional prediction model which uses conditional autoregressive (CAR) models to\naccount for both storm paths and spatial patterns for storm damage. When fitted\nto historical data, the analysis from our model both confirms previous findings\nand reveals new insights on regional storm tendencies. Posterior predictive\nsamples can also be used for pricing regional insurance premiums, which we\nillustrate using three different risk measures.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2016 01:14:57 GMT"}], "update_date": "2016-02-15", "authors_parsed": [["Mak", "Simon", ""], ["Bingham", "Derek", ""], ["Lu", "Yi", ""]]}, {"id": "1602.03992", "submitter": "Konstantinos Benidis", "authors": "Konstantinos Benidis, Ying Sun, Prabhu Babu, and Daniel P. Palomar", "title": "Orthogonal Sparse PCA and Covariance Estimation via Procrustes\n  Reformulation", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2016.2605073", "report-no": null, "categories": "stat.ML cs.LG math.OC stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of estimating sparse eigenvectors of a symmetric matrix attracts\na lot of attention in many applications, especially those with high dimensional\ndata set. While classical eigenvectors can be obtained as the solution of a\nmaximization problem, existing approaches formulate this problem by adding a\npenalty term into the objective function that encourages a sparse solution.\nHowever, the resulting methods achieve sparsity at the expense of sacrificing\nthe orthogonality property. In this paper, we develop a new method to estimate\ndominant sparse eigenvectors without trading off their orthogonality. The\nproblem is highly non-convex and hard to handle. We apply the MM framework\nwhere we iteratively maximize a tight lower bound (surrogate function) of the\nobjective function over the Stiefel manifold. The inner maximization problem\nturns out to be a rectangular Procrustes problem, which has a closed form\nsolution. In addition, we propose a method to improve the covariance estimation\nproblem when its underlying eigenvectors are known to be sparse. We use the\neigenvalue decomposition of the covariance matrix to formulate an optimization\nproblem where we impose sparsity on the corresponding eigenvectors. Numerical\nexperiments show that the proposed eigenvector extraction algorithm matches or\noutperforms existing algorithms in terms of support recovery and explained\nvariance, while the covariance estimation algorithms improve significantly the\nsample covariance estimator.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2016 09:48:22 GMT"}], "update_date": "2016-11-03", "authors_parsed": [["Benidis", "Konstantinos", ""], ["Sun", "Ying", ""], ["Babu", "Prabhu", ""], ["Palomar", "Daniel P.", ""]]}, {"id": "1602.04003", "submitter": "Alberto Sorrentino", "authors": "Valentina Vivaldi and Alberto Sorrentino", "title": "Bayesian smoothing of dipoles in Magneto-/Electro-encephalography", "comments": "16 pages, 5 figures", "journal-ref": "Inverse Problems 32 (2016) 045007", "doi": "10.1088/0266-5611/32/4/045007", "report-no": null, "categories": "math.NA stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a novel method for dynamic estimation of multi-dipole states from\nMagneto/Electro-encephalography (M/EEG) time series. The new approach builds on\nthe recent development of particle filters for M/EEG; these algorithms\napproximate, with samples and weights, the posterior distribution of the neural\nsources at time t given the data up to time t. However, for off-line inference\npurposes it is preferable to work with the smoothing distribution, i.e. the\ndistribution for the neural sources at time t conditioned on the whole time\nseries. In this study, we use a Monte Carlo algorithm to approximate the\nsmoothing distribution for a time-varying set of current dipoles. We show,\nusing numerical simulations, that the estimates provided by the smoothing\ndistribution are more accurate than those provided by the filtering\ndistribution, particularly at the appearance of the source. We validate the\nproposed algorithm using an experimental dataset recorded from an epileptic\npatient. Improved localization of the source onset can be particularly relevant\nin source modeling of epileptic patients, where the source onset brings\ninformation on the epileptogenic zone.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2016 10:30:27 GMT"}], "update_date": "2016-03-18", "authors_parsed": [["Vivaldi", "Valentina", ""], ["Sorrentino", "Alberto", ""]]}, {"id": "1602.04379", "submitter": "Gustavo Amaral Mr", "authors": "Jean Pierre von der Weid, Mario H. Souto, Joaquim D. Garcia, and\n  Gustavo C. Amaral", "title": "Adaptive Filter for Automatic Identification of Multiple Faults in a\n  Noisy OTDR Profile", "comments": "15 pages, 4 figures", "journal-ref": null, "doi": "10.1109/JLT.2016.2570302", "report-no": null, "categories": "stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel methodology able to distinguish meaningful level shifts\nfrom typical signal fluctuations. A two-stage regularization filtering can\naccurately identify the location of the significant level-shifts with an\nefficient parameter-free algorithm. The developed methodology demands low\ncomputational effort and can easily be embedded in a dedicated processing unit.\nOur case studies compare the new methodology with current available ones and\nshow that it is the most adequate technique for fast detection of multiple\nunknown level-shifts in a noisy OTDR profile.\n", "versions": [{"version": "v1", "created": "Sat, 13 Feb 2016 21:03:13 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["von der Weid", "Jean Pierre", ""], ["Souto", "Mario H.", ""], ["Garcia", "Joaquim D.", ""], ["Amaral", "Gustavo C.", ""]]}, {"id": "1602.04391", "submitter": "Kinjal Basu", "authors": "Kinjal Basu, Shaunak Chatterjee, Ankan Saha", "title": "Constrained Multi-Slot Optimization for Ranking Recommendations", "comments": "12 Pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML math.OC stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ranking items to be recommended to users is one of the main problems in large\nscale social media applications. This problem can be set up as a\nmulti-objective optimization problem to allow for trading off multiple,\npotentially conflicting objectives (that are driven by those items) against\neach other. Most previous approaches to this problem optimize for a single slot\nwithout considering the interaction effect of these items on one another.\n  In this paper, we develop a constrained multi-slot optimization formulation,\nwhich allows for modeling interactions among the items on the different slots.\nWe characterize the solution in terms of problem parameters and identify\nconditions under which an efficient solution is possible. The problem\nformulation results in a quadratically constrained quadratic program (QCQP). We\nprovide an algorithm that gives us an efficient solution by relaxing the\nconstraints of the QCQP minimally. Through simulated experiments, we show the\nbenefits of modeling interactions in a multi-slot ranking context, and the\nspeed and accuracy of our QCQP approximate solver against other state of the\nart methods.\n", "versions": [{"version": "v1", "created": "Sat, 13 Feb 2016 22:22:54 GMT"}, {"version": "v2", "created": "Tue, 16 May 2017 06:30:42 GMT"}], "update_date": "2017-05-17", "authors_parsed": [["Basu", "Kinjal", ""], ["Chatterjee", "Shaunak", ""], ["Saha", "Ankan", ""]]}, {"id": "1602.04528", "submitter": "Harrison Quick", "authors": "Harrison Quick, Lance A. Waller, and Michele Casper", "title": "Hierarchical multivariate space-time methods for modeling counts with an\n  application to stroke mortality data", "comments": null, "journal-ref": "Annals of Applied Statistics, 11 (2017) 2170-2182", "doi": "10.1214/17-AOAS1068", "report-no": null, "categories": "stat.ME stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Geographic patterns in stroke mortality have been studied as far back as the\n1960s, when a region of the southeastern United States became known as the\n\"stroke belt\" due to its unusually high rates of stroke mortality. While stroke\nmortality rates are known to increase exponentially with age, an investigation\nof spatiotemporal trends by age group at the county-level is daunting due to\nthe preponderance of small population sizes and/or few stroke events by age\ngroup. Here, we harness the power of a complex, nonseparable multivariate\nspace-time model which borrows strength across space, time, and age group to\nobtain reliable estimates of yearly county-level mortality rates from US\ncounties between 1973 and 2013 for those aged 65+. Furthermore, we propose an\nalternative metric for measuring changes in event rates over time which\naccounts for the full trajectory of a county's event rates, as opposed to\nsimply comparing the rates at the beginning and end of the study period. In our\nanalysis of the stroke data, we identify differing spatiotemporal trends in\nmortality rates across age groups, shed light on the gains achieved in the Deep\nSouth, and provide evidence that a separable model is inappropriate for these\ndata.\n", "versions": [{"version": "v1", "created": "Sun, 14 Feb 2016 23:51:23 GMT"}], "update_date": "2018-01-23", "authors_parsed": [["Quick", "Harrison", ""], ["Waller", "Lance A.", ""], ["Casper", "Michele", ""]]}, {"id": "1602.04706", "submitter": "Kyeong Soo (Joseph) Kim", "authors": "Kyeong Soo Kim, Sanghyuk Lee, Eng Gee Lim", "title": "Energy-Efficient Time Synchronization Based on Asynchronous Source Clock\n  Frequency Recovery and Reverse Two-Way Message Exchanges in Wireless Sensor\n  Networks", "comments": "11 pages, 8 figures, submitted to IEEE Transactions on Communications", "journal-ref": "IEEE Transactions on Communications, Nov. 2016", "doi": "10.1109/TCOMM.2016.2626281", "report-no": null, "categories": "cs.NI stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider energy-efficient time synchronization in a wireless sensor\nnetwork where a head node (i.e., a gateway between wired and wireless networks\nand a center of data fusion) is equipped with a powerful processor and supplied\npower from outlet, and sensor nodes (i.e., nodes measuring data and connected\nonly through wireless channels) are limited in processing and battery-powered.\nIt is this asymmetry that our study focuses on; unlike most existing schemes to\nsave the power of all network nodes, we concentrate on battery-powered sensor\nnodes in minimizing energy consumption for time synchronization. We present a\ntime synchronization scheme based on asynchronous source clock frequency\nrecovery and reverse two-way message exchanges combined with measurement data\nreport messages, where we minimize the number of message transmissions from\nsensor nodes, and carry out the performance analysis of the estimation of both\nmeasurement time and clock frequency with lower bounds for the latter.\nSimulation results verify that the proposed scheme outperforms the schemes\nbased on conventional two-way message exchanges with and without clock\nfrequency recovery in terms of the accuracy of measurement time estimation and\nthe number of message transmissions and receptions at sensor nodes as an\nindirect measure of energy efficiency.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2016 15:12:07 GMT"}], "update_date": "2016-11-10", "authors_parsed": [["Kim", "Kyeong Soo", ""], ["Lee", "Sanghyuk", ""], ["Lim", "Eng Gee", ""]]}, {"id": "1602.04721", "submitter": "Philip O'Neill", "authors": "Yinghui Wei, Theodore Kypraios, Philip D. O'Neill, Susan S. Huang,\n  Sheryl L. Rifas-Shiman and Ben S. Cooper", "title": "Evaluating hospital infection control measures for\n  antimicrobial-resistant pathogens using stochastic transmission models:\n  application to Vancomycin-Resistant Enterococci in intensive care units", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nosocomial pathogens such as Methicillin-Resistant {\\em Staphylococcus\naureus} (MRSA) and Vancomycin-resistant {\\em Enterococci} (VRE) are the cause\nof significant morbidity and mortality among hospital patients. It is important\nto be able to assess the efficacy of control measures using data on patient\noutcomes. In this paper we describe methods for analysing such data using\npatient-level stochastic models which seek to describe the underlying\nunobserved process of transmission. The methods are applied to detailed\nlongitudinal patient-level data on VRE from a study in a US hospital with eight\nintensive care units (ICUs). The data comprise admission and discharge dates,\ndates and results of screening tests, and dates during which precautionary\nmeasures were in place for each patient during the study period. Results\ninclude estimates of the efficacy of the control measures, the proportion of\nunobserved patients colonized with VRE and the proportion of patients colonized\non admission.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2016 16:14:25 GMT"}], "update_date": "2016-02-20", "authors_parsed": [["Wei", "Yinghui", ""], ["Kypraios", "Theodore", ""], ["O'Neill", "Philip D.", ""], ["Huang", "Susan S.", ""], ["Rifas-Shiman", "Sheryl L.", ""], ["Cooper", "Ben S.", ""]]}, {"id": "1602.05048", "submitter": "James Miller", "authors": "Kyle Miller, Emily Kennedy, Artur Dubrawski", "title": "Do Public Events Affect Sex Trafficking Activity?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For several years the pervasive belief that the Super Bowl is the single\nbiggest day for human trafficking in the United States each year has been\nperpetuated in popular press despite a lack of evidentiary support. The\npractice of relying on hearsay and popular belief for decision-making may\nresult in misappropriation of resources in anti-trafficking efforts. We propose\na data-driven approach to analyzing sex trafficking, especially as it is\ncarried on during--and perhaps in response to--large public events such as the\nSuper Bowl. We examine 33 public events, chosen for attendance numbers\ncomparable to the Super Bowl from a diversity of types, and use the volume of\nescort advertisements posted online as an accessible and reasonable proxy\nmeasure for the actual levels of activity of sex-workers as well as trafficking\nvictims. Our analysis puts the impact of local public events on sex\nadvertisement activity into perspective. We find that many of the events we\nconsidered are not correlated with statistically significant impact on\nsex-worker advertising, though some are. Additionally, we demonstrate how our\nmethod can uncover evidence of other events, not included in our initial list,\nthat are correlated with more significant increases in ad activity. Reliance on\nquantitative evidence accessible through data-driven analysis can inform wise\nresource allocation, guide good policies, and foster the most meaningful\nimpact.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2016 15:10:13 GMT"}], "update_date": "2016-02-17", "authors_parsed": [["Miller", "Kyle", ""], ["Kennedy", "Emily", ""], ["Dubrawski", "Artur", ""]]}, {"id": "1602.05069", "submitter": "Bosung Kang", "authors": "Bosung Kang", "title": "Robust Covariance Matrix Estimation for Radar Space-Time Adaptive\n  Processing (STAP)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating the disturbance or clutter covariance is a centrally important\nproblem in radar space time adaptive processing (STAP). The disturbance\ncovariance matrix should be inferred from training sample observations in\npractice. Large number of homogeneous training samples are generally not\navailable because of difficulty of guaranteeing target free disturbance\nobservation, practical limitations imposed by the spatio-temporal\nnonstationarity, and system considerations. In this dissertation, we look to\naddress the aforementioned challenges by exploiting physically inspired\nconstraints into ML estimation. While adding constraints is beneficial to\nachieve satisfactory performance in the practical regime of limited training,\nit leads to a challenging problem. We focus on breaking this classical\ntrade-off between computational tractability and desirable performance\nmeasures, particularly in training starved regimes. In particular, we exploit\nboth the structure of the disturbance covariance and importantly the knowledge\nof the clutter rank to yield a new rank constrained maximum likelihood (RCML)\nestimator. In addition, we derive a new covariance estimator for STAP that\njointly considers a Toeplitz structure and a rank constraint on the clutter\ncomponent.\n  Finally, we address the problem of working with inexact physical radar\nparameters under a practical radar environment. We propose a robust covariance\nestimation method via an expected likelihood (EL) approach. We analyze\ncovariance estimation algorithms under three different cases of imperfect\nconstraints: 1) only rank constraint, 2) both rank and noise power constraint,\nand 3) condition number constraint. For each case, we formulate estimation of\nthe constraint as an optimization problem with the EL criterion and formally\nderive and prove a significant analytical result such as uniqueness of the\nsolution.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2016 16:09:35 GMT"}], "update_date": "2016-02-22", "authors_parsed": [["Kang", "Bosung", ""]]}, {"id": "1602.05257", "submitter": "Deovrat Kakde", "authors": "Deovrat Kakde, Arin Chaudhuri, Seunghyun Kong, Maria Jahja, Hansi\n  Jiang, Jorge Silva", "title": "Peak Criterion for Choosing Gaussian Kernel Bandwidth in Support Vector\n  Data Description", "comments": null, "journal-ref": null, "doi": "10.1109/ICPHM.2017.7998302", "report-no": null, "categories": "cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Support Vector Data Description (SVDD) is a machine-learning technique used\nfor single class classification and outlier detection. SVDD formulation with\nkernel function provides a flexible boundary around data. The value of kernel\nfunction parameters affects the nature of the data boundary. For example, it is\nobserved that with a Gaussian kernel, as the value of kernel bandwidth is\nlowered, the data boundary changes from spherical to wiggly. The spherical data\nboundary leads to underfitting, and an extremely wiggly data boundary leads to\noverfitting. In this paper, we propose empirical criterion to obtain good\nvalues of the Gaussian kernel bandwidth parameter. This criterion provides a\nsmooth boundary that captures the essential geometric features of the data.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2016 00:51:18 GMT"}, {"version": "v2", "created": "Wed, 11 May 2016 21:39:53 GMT"}, {"version": "v3", "created": "Tue, 8 Aug 2017 18:00:45 GMT"}], "update_date": "2017-09-06", "authors_parsed": [["Kakde", "Deovrat", ""], ["Chaudhuri", "Arin", ""], ["Kong", "Seunghyun", ""], ["Jahja", "Maria", ""], ["Jiang", "Hansi", ""], ["Silva", "Jorge", ""]]}, {"id": "1602.05264", "submitter": "Puneet Chhabra", "authors": "Puneet S Chhabra, Andrew M Wallace and James R Hopgood", "title": "Anomaly Detection in Clutter using Spectrally Enhanced Ladar", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.optics cs.LG physics.ins-det stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discrete return (DR) Laser Detection and Ranging (Ladar) systems provide a\nseries of echoes that reflect from objects in a scene. These can be first, last\nor multi-echo returns. In contrast, Full-Waveform (FW)-Ladar systems measure\nthe intensity of light reflected from objects continuously over a period of\ntime. In a camouflaged scenario, e.g., objects hidden behind dense foliage, a\nFW-Ladar penetrates such foliage and returns a sequence of echoes including\nburied faint echoes. The aim of this paper is to learn local-patterns of\nco-occurring echoes characterised by their measured spectra. A deviation from\nsuch patterns defines an abnormal event in a forest/tree depth profile. As far\nas the authors know, neither DR or FW-Ladar, along with several spectral\nmeasurements, has not been applied to anomaly detection. This work presents an\nalgorithm that allows detection of spectral and temporal anomalies in FW-Multi\nSpectral Ladar (FW-MSL) data samples. An anomaly is defined as a full waveform\ntemporal and spectral signature that does not conform to a prior expectation,\nrepresented using a learnt subspace (dictionary) and set of coefficients that\ncapture co-occurring local-patterns using an overlapping temporal window. A\nmodified optimization scheme is proposed for subspace learning based on\nstochastic approximations. The objective function is augmented with a\ndiscriminative term that represents the subspace's separability properties and\nsupports anomaly characterisation. The algorithm detects several man-made\nobjects and anomalous spectra hidden in a dense clutter of vegetation and also\nallows tree species classification.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2016 01:39:29 GMT"}], "update_date": "2016-02-18", "authors_parsed": [["Chhabra", "Puneet S", ""], ["Wallace", "Andrew M", ""], ["Hopgood", "James R", ""]]}, {"id": "1602.05280", "submitter": "Zu-Guo Yu", "authors": "Zu-Guo Yu, Huan Zhang, Da-Wen Huang, Yong Lin and Vo Anh", "title": "Multifractality and Laplace spectrum of horizontal visibility graphs\n  constructed from fractional Brownian motions", "comments": "14 pages, 5 figures, 1 table; accepted for publication by J. Stat.\n  Mech.: Theor. Exp", "journal-ref": null, "doi": "10.1088/1742-5468/2016/03/033206", "report-no": null, "categories": "cond-mat.stat-mech nlin.CD stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many studies have shown that additional information can be gained on time\nseries by investigating their associated complex networks. In this work, we\ninvestigate the multifractal property and Laplace spectrum of the horizontal\nvisibility graphs (HVGs) constructed from fractional Brownian motions. We aim\nto identify via simulation and curve fitting the form of these properties in\nterms of the Hurst index $H$. First, we use the sandbox algorithm to study the\nmultifractality of these HVGs. It is found that multifractality exists in these\nHVGs. We find that the average fractal dimension $\\langle D(0)\\rangle$ of HVGs\napproximately satisfies the prominent linear formula $\\langle D(0)\\rangle = 2 -\nH$; while the average information dimension $\\langle D(1)\\rangle$ and average\ncorrelation dimension $\\langle D(2)\\rangle$ are all approximately bi-linear\nfunctions of $H$ when $H\\ge 0.15$. Then, we calculate the spectrum and energy\nfor the general Laplacian operator and normalized Laplacian operator of these\nHVGs. We find that, for the general Laplacian operator, the average logarithm\nof second-smallest eigenvalue $\\langle \\ln (u_2) \\rangle$, the average\nlogarithm of third-smallest eigenvalue $\\langle \\ln (u_3) \\rangle$, and the\naverage logarithm of maximum eigenvalue $\\langle \\ln (u_n) \\rangle$ of these\nHVGs are approximately linear functions of $H$; while the average Laplacian\nenergy $\\langle E_{nL} \\rangle$ is approximately a quadratic polynomial\nfunction of $H$. For the normalized Laplacian operator, $\\langle \\ln (u_2)\n\\rangle$ and $\\langle \\ln (u_3) \\rangle$ of these HVGs approximately satisfy\nlinear functions of $H$; while $\\langle \\ln (u_n) \\rangle$ and $\\langle E_{nL}\n\\rangle$ are approximately a 4th and cubic polynomial function of $H$\nrespectively.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2016 02:56:37 GMT"}], "update_date": "2016-04-20", "authors_parsed": [["Yu", "Zu-Guo", ""], ["Zhang", "Huan", ""], ["Huang", "Da-Wen", ""], ["Lin", "Yong", ""], ["Anh", "Vo", ""]]}, {"id": "1602.05305", "submitter": "Kyeong Soo (Joseph) Kim", "authors": "Kyeong Soo Kim, Sanghyuk Lee, Eng Gee Lim", "title": "Simulation Study of an Energy-Efficient Time Synchronization Scheme\n  based on Source Clock Frequency Recovery in Asymmetric Wireless Sensor\n  Networks", "comments": "4 pages, 2 figures, 6th International Symposium on Advanced\n  Engineering (ISAE 2015), Pukyong National University, Busan, Korea, 22-24\n  Oct. 2015. arXiv admin note: substantial text overlap with arXiv:1508.02708", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we report preliminary results of a simulation study on an\nenergy-efficient time synchronization scheme based on source clock frequency\nrecovery (SCFR) at sensor nodes in asymmetric wireless sensor networks (WSNs),\nwhere a head node --- serving as a gateway between wired and wireless networks\n--- is equipped with a powerful processor and supplied power from outlet, and\nsensor nodes --- connected only through wireless channels --- are limited in\nprocessing and battery-powered. In the SCFR-based WSN time synchronization\nscheme, we concentrate on battery-powered sensor nodes and reduce their energy\nconsumption by minimizing the number of message transmissions from sensor nodes\nto the head node. Through simulation experiments we analyze the performance of\nthe SCFR-based WSN time synchronization scheme, including the impact of SCFR on\ntime synchronization based on two-way message exchange, and demonstrate the\nfeasibility of the proposed time synchronization scheme.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2016 05:19:56 GMT"}], "update_date": "2016-02-18", "authors_parsed": [["Kim", "Kyeong Soo", ""], ["Lee", "Sanghyuk", ""], ["Lim", "Eng Gee", ""]]}, {"id": "1602.05349", "submitter": "Halis Sak", "authors": "Halis Sak, Guanyu Yang, Bailiang Li, and Weifeng Li", "title": "Modeling Dependence Dynamics of Air Pollution: Pollution Risk Simulation\n  and Prediction of PM$_{2.5}$ Levels", "comments": "20 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The first part of this paper introduces a portfolio approach for quantifying\nthe risk measures of pollution risk in the presence of dependence of PM$_{2.5}$\nconcentration of cities. The model is based on a copula dependence structure.\nFor assessing model parameters, we analyze a limited data set of PM$_{2.5}$\nlevels of Beijing, Tianjin, Chengde, Hengshui, and Xingtai. This process\nreveals a better fit for the t-copula dependence structure with generalized\nhyperbolic marginal distributions for the PM$_{2.5}$ log-ratios of the cities.\nFurthermore, we show how to efficiently simulate risk measures\nclean-air-at-risk and conditional clean-air-at-risk using importance sampling\nand stratified importance sampling. Our numerical results show that\nclean-air-at-risk at 0.01 probability level reaches up to 352 {\\mu}gm-3\n(initial PM$_{2.5}$ concentrations of cities are assumed to be 100 {\\mu}gm-3)\nfor the constructed sample portfolio, and proposed methods are much more\nefficient than a naive simulation for computing the exceeding probabilities and\nconditional excesses.\n  In the second part, we predict PM$_{2.5}$ levels of the next three-hour\nperiod of four Chinese cities, Beijing, Chengde, Xingtai, and Zhangjiakou. For\nthis purpose, we use the pollution and weather data collected from the stations\nlocated in these four cities. Instead of coding the machine learning\nalgorithms, we employ a state-of-the-art machine learning library, Torch7. This\nallows us to try out the state-of-the-art machine learning methods like long\nshort-term memory (LSTM). Unfortunately, due to small data size and lots of\nmissing values (when we combined the features of the cities) in the data, LSTM\ndoes not perform better than a multilayer perceptron. However, we get a\nclassification accuracy above 0.72 on the test data.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2016 09:35:00 GMT"}], "update_date": "2016-02-18", "authors_parsed": [["Sak", "Halis", ""], ["Yang", "Guanyu", ""], ["Li", "Bailiang", ""], ["Li", "Weifeng", ""]]}, {"id": "1602.05399", "submitter": "Ana Jarne", "authors": "Ana Jarne, Daniel Commenges, M\\'elanie Prague, Yves Levy, Rodolphe\n  Thi\\'ebaut", "title": "Modeling CD4+ T cells dynamics in HIV-infected patients receiving\n  repeated cycles of exogenous Interleukin 7", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Combination Antiretroviral Therapy (cART) succeeds to control viral\nreplication in most HIV infected patients. This is normally followed by a\nreconstitution of the CD4$^+$ T cells pool; however, this does not happen for a\nsubstantial proportion of patients. For these patients, an immunotherapy based\non injections of Interleukin 7 (IL-7) has been recently proposed as a\nco-adjutant treatment in the hope of obtaining long-term reconstitution of the\nT cells pool. Several questions arise as to the long-term efficiency of this\ntreatment and the best protocol to apply.\n  We develop a model based on a system of ordinary differential equations and a\nstatistical model of variability and measurement. We can estimate key\nparameters of this model using the data from INSPIRE, INSPIRE 2 $\\&$ INSPIRE 3\ntrials. In all three studies, cycles of three injections have been\nadministered; in the last two studies, for the first time, repeated cycles of\nexogenous IL-7 have been administered. Our aim was to estimate the possible\ndifferent effects of successive injections in a cycle, to estimate the effect\nof repeated cycles and to assess different protocols.\n  The use of dynamical models together with our complex statistical approach\nallow us to analyze major biological questions. We found a strong effect of\nIL-7 injections on the proliferation rate; however, the effect of the third\ninjection of the cycle appears to be much weaker than the first ones. Also,\ndespite a slightly weaker effect of repeated cycles with respect to the initial\none, our simulations show the ability of this treatment of maintaining adequate\nCD4$^+$ T cells count for years. We were also able to compare different\nprotocols, showing that cycles of two injections should be sufficient in most\ncases. %Finally, we also explore the possibility of adaptive protocols.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2016 13:15:55 GMT"}], "update_date": "2016-02-18", "authors_parsed": [["Jarne", "Ana", ""], ["Commenges", "Daniel", ""], ["Prague", "M\u00e9lanie", ""], ["Levy", "Yves", ""], ["Thi\u00e9baut", "Rodolphe", ""]]}, {"id": "1602.05453", "submitter": "Nil Kamal Hazra", "authors": "Maxim Finkelstein, Nil Kamal Hazra", "title": "On Stochastic Comparisons for Load-Sharing Series and Parallel Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the allocation strategies for redundant components in the\nload-sharing series/parallel systems. We show that under the specified\nassumptions, the allocation of a redundant component to the stochastically\nweakest (strongest) component of a series (parallel) system is the best\nstrategy to achieve its maximal reliability. The results have been studied\nunder cumulative exposure model and for a general scenario as well. They have a\nclear intuitive meaning, however, the corresponding additional assumptions are\nnot obvious, which can be seem from the proofs of our theorems\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2016 15:35:28 GMT"}], "update_date": "2016-02-18", "authors_parsed": [["Finkelstein", "Maxim", ""], ["Hazra", "Nil Kamal", ""]]}, {"id": "1602.05523", "submitter": "Virginie Stanislas", "authors": "Virginie Stanislas (LaMME), Cyril Dalmasso (LaMME), Christophe\n  Ambroise (LaMME)", "title": "Eigen-Epistasis for detecting Gene-Gene interactions", "comments": null, "journal-ref": "BMC Bioinformatics, BioMed Central, 2017, 18, pp.54", "doi": null, "report-no": null, "categories": "stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A large amount of research has been devoted to the detection and\ninvestigation of epistatic interactions in genome-wide association studies\n(GWASs). Most of the literature focuses on low-order interactions between\nsingle-nucleotide polymorphisms (SNPs) with significant main effects.In this\npaper we propose an original approach for detecting epistasis at the gene\nlevel, without systematically filtering on significant genes. We first compute\ninteraction variables for each gene pair by finding its Eigen-Epistasis\ncomponent, defined as the linear combination of Gene SNPs having the highest\ncorrelation with the phenotype. The selection of significant effects is done\nusing a penalized regression method based on Group Lasso controlling the False\nDiscovery Rate.The method is tested against two recent alternative proposals\nfrom the literature using synthetic data, and shows good performances in\ndifferent settings. We demonstrate the power of our approach by detecting new\ngene-gene interactions on three genome-wide association studies.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2016 18:34:55 GMT"}, {"version": "v2", "created": "Mon, 22 Feb 2016 10:45:48 GMT"}, {"version": "v3", "created": "Fri, 13 May 2016 08:16:44 GMT"}, {"version": "v4", "created": "Mon, 20 Jun 2016 08:44:27 GMT"}, {"version": "v5", "created": "Fri, 18 Nov 2016 14:41:33 GMT"}, {"version": "v6", "created": "Thu, 16 Feb 2017 14:00:20 GMT"}], "update_date": "2017-02-17", "authors_parsed": [["Stanislas", "Virginie", "", "LaMME"], ["Dalmasso", "Cyril", "", "LaMME"], ["Ambroise", "Christophe", "", "LaMME"]]}, {"id": "1602.05549", "submitter": "Alex Deng", "authors": "Alex Deng and Jiannan Lu and Shouyuan Chen", "title": "Continuous Monitoring of A/B Tests without Pain: Optional Stopping in\n  Bayesian Testing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A/B testing is one of the most successful applications of statistical theory\nin modern Internet age. One problem of Null Hypothesis Statistical Testing\n(NHST), the backbone of A/B testing methodology, is that experimenters are not\nallowed to continuously monitor the result and make decision in real time. Many\npeople see this restriction as a setback against the trend in the technology\ntoward real time data analytics. Recently, Bayesian Hypothesis Testing, which\nintuitively is more suitable for real time decision making, attracted growing\ninterest as an alternative to NHST. While corrections of NHST for the\ncontinuous monitoring setting are well established in the existing literature\nand known in A/B testing community, the debate over the issue of whether\ncontinuous monitoring is a proper practice in Bayesian testing exists among\nboth academic researchers and general practitioners. In this paper, we formally\nprove the validity of Bayesian testing with continuous monitoring when proper\nstopping rules are used, and illustrate the theoretical results with concrete\nsimulation illustrations. We point out common bad practices where stopping\nrules are not proper and also compare our methodology to NHST corrections.\nGeneral guidelines for researchers and practitioners are also provided.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2016 19:51:34 GMT"}], "update_date": "2016-02-18", "authors_parsed": [["Deng", "Alex", ""], ["Lu", "Jiannan", ""], ["Chen", "Shouyuan", ""]]}, {"id": "1602.05642", "submitter": "Abisheva Adiya", "authors": "Adiya Abisheva, David Garcia, Frank Schweitzer", "title": "When the Filter Bubble Bursts: Collective Evaluation Dynamics in Online\n  Communities", "comments": "20 pages, 4 figures, Submitted to the 8th International ACM Web\n  Science Conference 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI physics.data-an physics.soc-ph stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze online collective evaluation processes through positive and\nnegative votes in various social media. We find two modes of collective\nevaluations that stem from the existence of filter bubbles. Above a threshold\nof collective attention, negativity grows faster with positivity, as a sign of\nthe burst of a filter bubble when information reaches beyond the local social\ncontext of a user. We analyze how collectively evaluated content can reach\nlarge social contexts and create polarization, showing that emotions expressed\nthrough text play a key role in collective evaluation processes.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2016 01:02:15 GMT"}], "update_date": "2016-02-19", "authors_parsed": [["Abisheva", "Adiya", ""], ["Garcia", "David", ""], ["Schweitzer", "Frank", ""]]}, {"id": "1602.05723", "submitter": "Aristides Moustakas", "authors": "Aristides Moustakas", "title": "The effects of marine protected areas over time and species dispersal\n  potential: A quantitative conservation conflict attempt", "comments": "to appear in the journal: Web Ecology", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE cs.MA q-bio.QM stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Protected areas are an important conservation measure. However, there are\ncontroversial findings regarding whether closed areas are beneficial for\nspecies and habitat conservation as well as landings. Species dispersal is\nacknowledged as a key factor for the design and impacts of closed areas. A\nseries of agent based models using random diffusion to model fish dispersal\nwere run before and after habitat protection. All results were normalised\nwithout the protected habitat in each scenario to detect the relative\ndifference after closing an area, all else being equal. Results show that\nlandings of species with short dispersal ranges will take longer to reach the\nlevels of pre Marine Protected Areas (MPAs) establishment than landings of\nspecies with long dispersal ranges. Further the establishment of an MPA\ngenerates a higher relative population source within the MPA for species with\nlow dispersal abilities than for species with high dispersal abilities. Results\nderived here show that there exists a win-win feasible scenario that maximises\nboth fish biomass as well as fish catches.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2016 09:02:38 GMT"}, {"version": "v2", "created": "Thu, 28 Jul 2016 08:35:31 GMT"}], "update_date": "2016-07-29", "authors_parsed": [["Moustakas", "Aristides", ""]]}, {"id": "1602.05731", "submitter": "Vladislav Moltchanov", "authors": "Vladislav Moltchanov", "title": "Dynamic Modelling of Health and its application to the large scale\n  analysis of Body Mass Index, using data from consecutive set of surveys", "comments": "arXiv admin note: substantial text overlap with arXiv:1211.1310", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The methods used so far for the analysis of time changes in population health\nsuffer from the lack of causality in their design. This results in problems\nwith their implementation and interpretation. Here the method is presented with\ncausality directly implemented in the design. This is done by, first, building\nup a dynamic model of population, postulating existence of Driving Force acting\nat subjects, while they move along their cohort lines, causing the changes of\ntheir substantial health indicators , State Variables, at rate proportional to\nthis Force. The correspondent rates , named Cohort Trends, or C-trends,\ndescribe health history in each birth cohort. Having initial value and C-trends\n, the model allows to calculate health level (the means of State Variables) in\neach birth cohort, and thus, in the whole population. The task for statistical\nmethod is to identify the dynamic model (evaluate C-trends and Initial values)\nusing data from a set of consecutive independent cross-sectional surveys. This\nis done by an iterative algorithm, running multiple regression procedure at\neach step, until the specified smoothing conditions are fulfilled. The\nalgorithm can operate with surveys having different age ranges. The\nillustrative example shows the results of analysis of Body Mass Index for men ,\nusing 7 surveys in period 1972-2002 with age ranges 25-64 and 25-74. Since\nC-Trend is proxy for Driving Force, the year - age pattern of C-Trends provides\nunbiased information for health authorities on efficiency of health promotion\nactions or negative effects of uncontrolled harmful factors.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2016 09:43:35 GMT"}], "update_date": "2016-02-19", "authors_parsed": [["Moltchanov", "Vladislav", ""]]}, {"id": "1602.05741", "submitter": "Alexis Decurninge", "authors": "Alexis Decurninge and Maxime Guillaud and Dirk Slock", "title": "Channel Covariance Estimation in Massive MIMO Frequency Division Duplex\n  Systems", "comments": "6 pages in Globecom, \"From theory to practice\" workshop, December\n  2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Channel covariance is emerging as a critical ingredient of the acquisition of\ninstantaneous channel state information (CSI) in multi-user Massive MIMO\nsystems operating in frequency division duplex (FDD) mode. In this context,\nchannel reciprocity does not hold, and it is generally expected that covariance\ninformation about the downlink channel must be estimated and fed back by the\nuser equipment (UE). As an alternative CSI acquisition technique, we propose to\ninfer the downlink covariance based on the observed uplink covariance. This\ninference process relies on a dictionary of uplink/downlink covariance\nmatrices, and on interpolation in the corresponding Riemannian space; once the\ndictionary is known, the estimation does not rely on any form of feedback from\nthe UE. In this article, we present several variants of the interpolation\nmethod, and benchmark them through simulations.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2016 10:15:14 GMT"}], "update_date": "2016-02-19", "authors_parsed": [["Decurninge", "Alexis", ""], ["Guillaud", "Maxime", ""], ["Slock", "Dirk", ""]]}, {"id": "1602.05757", "submitter": "Anna Gloria Bill\\'e Ph.D.", "authors": "Anna Gloria Bill\\'e, Roberto Benedetti, Paolo Postiglione", "title": "A two-step approach to account for unobserved spatial heterogeneity", "comments": null, "journal-ref": "Spatial Economic Analysis 2017", "doi": "10.1080/17421772.2017.1286373", "report-no": null, "categories": "stat.ME stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Empirical analysis in economics often faces the difficulty that the data is\ncorrelated and heterogeneous in some unknown form. Spatial parametric\napproaches have been widely used to account for dependence structures, but the\nproblem of directly deal with spatially varying parameters has been largely\nunexplored. The problem can be serious in all those cases in which we have no\nprior information justified by the economic theory. In this paper we propose an\nalgorithm-based procedure which is able to endogenously identify structural\nbreaks in space. The proposed algorithm is illustrated by using two well known\nhouse price data sets.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2016 11:18:14 GMT"}, {"version": "v2", "created": "Fri, 25 Nov 2016 12:04:34 GMT"}], "update_date": "2017-02-09", "authors_parsed": [["Bill\u00e9", "Anna Gloria", ""], ["Benedetti", "Roberto", ""], ["Postiglione", "Paolo", ""]]}, {"id": "1602.05762", "submitter": "Anna Gloria Bill\\'e Ph.D.", "authors": "Anna Gloria Bill\\'e, Cristina Salvioni, Roberto Benedetti", "title": "Modelling Spatial Regimes in Farms Technologies", "comments": null, "journal-ref": "Journal of Productivity Analysis 2018", "doi": "10.1007/s11123-018-0529-7", "report-no": null, "categories": "stat.AP stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We exploit the information derived from geographical coordinates to\nendogenously identify spatial regimes in technologies that are the result of a\nvariety of complex, dynamic interactions among site-specific environmental\nvariables and farmer decision making about technology, which are often not\nobserved at the farm level. Controlling for unobserved heterogeneity is a\nfundamental challenge in empirical research, as failing to do so can produce\nmodel misspecification and preclude causal inference. In this article, we adopt\na two-step procedure to deal with unobserved spatial heterogeneity, while\naccounting for spatial dependence in a cross-sectional setting. The first step\nof the procedure takes explicitly unobserved spatial heterogeneity into account\nto endogenously identify subsets of farms that follow a similar local\nproduction econometric model, i.e. spatial production regimes. The second step\nconsists in the specification of a spatial autoregressive model with\nautoregressive disturbances and spatial regimes. The method is applied to two\nregional samples of olive growing farms in Italy. The main finding is that the\nidentification of spatial regimes can help drawing a more detailed picture of\nthe production environment and provide more accurate information to guide\nextension services and policy makers.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2016 11:33:57 GMT"}, {"version": "v2", "created": "Wed, 7 Dec 2016 16:56:08 GMT"}, {"version": "v3", "created": "Thu, 14 Dec 2017 09:47:31 GMT"}], "update_date": "2019-08-02", "authors_parsed": [["Bill\u00e9", "Anna Gloria", ""], ["Salvioni", "Cristina", ""], ["Benedetti", "Roberto", ""]]}, {"id": "1602.05795", "submitter": "Matthias Killiches", "authors": "Matthias Killiches, Daniel Kraus and Claudia Czado", "title": "Examination and visualisation of the simplifying assumption for vine\n  copulas in three dimensions", "comments": "26 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vine copulas are a highly flexible class of dependence models, which are\nbased on the decomposition of the density into bivariate building blocks. For\napplications one usually makes the simplifying assumption that copulas of\nconditional distributions are independent of the variables on which they are\nconditioned. However this assumption has been criticised for being too\nrestrictive. We examine both simplified and non-simplified vine copulas in\nthree dimensions and investigate conceptual differences. We show and compare\ncontour surfaces of three-dimensional vine copula models, which prove to be\nmuch more informative than the contour lines of the bivariate marginals. Our\ninvestigation shows that non-simplified vine copulas can exhibit arbitrarily\nirregular shapes, whereas simplified vine copulas appear to be smooth\nextrapolations of their bivariate margins to three dimensions. In addition to a\nvariety of constructed examples, we also investigate a three-dimensional subset\nof the well-known uranium data set and visually detect that a non-simplified\nvine copula is necessary to capture its complex dependence structure.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2016 13:38:23 GMT"}, {"version": "v2", "created": "Fri, 28 Oct 2016 12:56:34 GMT"}], "update_date": "2016-10-31", "authors_parsed": [["Killiches", "Matthias", ""], ["Kraus", "Daniel", ""], ["Czado", "Claudia", ""]]}, {"id": "1602.05834", "submitter": "Nikolai Gagunashvili", "authors": "Nikolai Gagunashvili", "title": "Unfolding problem clarification and solution validation", "comments": "9 pages,4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.data-an astro-ph.IM hep-ex nucl-ex stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The unfolding problem formulation for correcting experimental data\ndistortions due to finite resolution and limited detector acceptance is\ndiscussed. A novel validation of the problem solution is proposed. Attention is\ndrawn to fact that different unfolded distributions may satisfy the validation\ncriteria, in which case a conservative approach using entropy is suggested. The\nimportance of analysis of residuals is demonstrated.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2016 15:18:23 GMT"}, {"version": "v2", "created": "Thu, 7 Apr 2016 19:53:10 GMT"}], "update_date": "2016-04-08", "authors_parsed": [["Gagunashvili", "Nikolai", ""]]}, {"id": "1602.05885", "submitter": "Jiwoong Kim", "authors": "Jiwoong Kim", "title": "Goodness-of-Fit Test: Khmaladze Transformation vs Empirical Likelihood", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper compares two asymptotic distribution free methods for\ngoodness-of-fit test of one sample of location-scale family: Khmaladze\ntransformation and empirical likelihood methods. The comparison is made from\nthe perspective of empirical level and power obtained from simulations. When\ntesting for normal and logistic null distributions, we try various alternative\ndistributions and find that Khmaladze transformation method has better power in\nmost cases. R-package which was used for the simulation is available online.\nSee section 5 for the detail.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2016 17:39:22 GMT"}, {"version": "v2", "created": "Fri, 22 Apr 2016 05:05:07 GMT"}], "update_date": "2016-04-25", "authors_parsed": [["Kim", "Jiwoong", ""]]}, {"id": "1602.05907", "submitter": "Camillo Cammarota", "authors": "Camillo Cammarota and Mario Curione", "title": "Trend extraction in functional data of R and T waves amplitudes of\n  exercise electrocardiogram", "comments": null, "journal-ref": null, "doi": null, "report-no": "Roma01.Math.MP", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The R and T waves amplitudes of the electrocardiogram recorded during the\nexercise test undergo strong modifications in response to stress. We analyze\nthe time series of these amplitudes in a group of normal subjects in the\nframework of functional data, performing reduction of dimensionality, smoothing\nand principal component analysis. These methods show that the R and T\namplitudes have opposite responses to stress, consisting respectively in a bump\nand a dip at the early recovery stage. We test these features computing a\nconfidence band for the trend of the population mean and analyzing the zero\ncrossing of its derivative.\n  Our findings support the existence of a relationship between R and T wave\namplitudes and respectively diastolic and systolic ventricular volumes.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2016 15:56:45 GMT"}], "update_date": "2016-02-19", "authors_parsed": [["Cammarota", "Camillo", ""], ["Curione", "Mario", ""]]}, {"id": "1602.06230", "submitter": "Thakshila Wimalajeewa", "authors": "Thakshila Wimalajeewa and Pramod K. Varshney", "title": "Sparse Signal Detection with Compressive Measurements via Partial\n  Support Set Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the problem of sparse signal detection based on\npartial support set estimation with compressive measurements in a distributed\nnetwork. Multiple nodes in the network are assumed to observe sparse signals\nwhich share a common but unknown support. While in the traditional compressive\nsensing (CS) framework, the goal is to recover the complete sparse signal, in\nsparse signal detection, complete signal recovery may not be necessary to make\na reliable detection decision. In particular, detection can be performed based\non partially or inaccurately estimated signals which requires less\ncomputational burden than that is required for complete signal recovery. To\nthat end, we investigate the problem of sparse signal detection based on\npartially estimated support set. First, we discuss how to determine the minimum\nfraction of the support set to be known so that a desired detection performance\nis achieved in a centralized setting. Second, we develop two distributed\nalgorithms for sparse signal detection when the raw compressed observations are\nnot available at the central fusion center. In these algorithms, the final\ndecision statistic is computed based on locally estimated partial support sets\nvia orthogonal matching pursuit (OMP) at individual nodes. The proposed\ndistributed algorithms with less communication overhead are shown to provide\ncomparable performance (sometimes better) to the centralized approach when the\nsize of the estimated partial support set is very small.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2016 17:27:01 GMT"}, {"version": "v2", "created": "Mon, 7 Mar 2016 19:49:04 GMT"}, {"version": "v3", "created": "Tue, 9 Aug 2016 16:27:58 GMT"}], "update_date": "2016-08-10", "authors_parsed": [["Wimalajeewa", "Thakshila", ""], ["Varshney", "Pramod K.", ""]]}, {"id": "1602.06316", "submitter": "William Chad Young", "authors": "William Chad Young, Ka Yee Yeung and Adrian E. Raftery", "title": "Model-based clustering with data correction for removing artifacts in\n  gene expression data", "comments": "28 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The NIH Library of Integrated Network-based Cellular Signatures (LINCS)\ncontains gene expression data from over a million experiments, using Luminex\nBead technology. Only 500 colors are used to measure the expression levels of\nthe 1,000 landmark genes measured, and the data for the resulting pairs of\ngenes are deconvolved. The raw data are sometimes inadequate for reliable\ndeconvolution leading to artifacts in the final processed data. These include\nthe expression levels of paired genes being flipped or given the same value,\nand clusters of values that are not at the true expression level. We propose a\nnew method called model-based clustering with data correction (MCDC) that is\nable to identify and correct these three kinds of artifacts simultaneously. We\nshow that MCDC improves the resulting gene expression data in terms of\nagreement with external baselines, as well as improving results from subsequent\nanalysis.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2016 21:33:58 GMT"}], "update_date": "2016-02-24", "authors_parsed": [["Young", "William Chad", ""], ["Yeung", "Ka Yee", ""], ["Raftery", "Adrian E.", ""]]}, {"id": "1602.06335", "submitter": "John J Nay", "authors": "John J. Nay, Emily Burchfield, Jonathan Gilligan", "title": "A Machine Learning Approach to Forecasting Remotely Sensed Vegetation\n  Health", "comments": "Code available at http://johnjnay.com/forecastVeg/", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.OT stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Drought threatens food and water security around the world, and this threat\nis likely to become more severe under climate change. High resolution\npredictive information can help farmers, water managers, and others to manage\nthe effects of drought. We have created an open source tool to produce\nshort-term forecasts of vegetation health at high spatial resolution, using\ndata that are global in coverage. The tool automates downloading and processing\nModerate Resolution Imaging Spectroradiometer (MODIS) datasets, and training\ngradient-boosted machine models on hundreds of millions of observations to\npredict future values of the Enhanced Vegetation Index. We compared the\npredictive power of different sets of variables (raw spectral MODIS data and\nLevel-3 MODIS products) in two regions with distinct agro-ecological systems,\nclimates, and cloud coverage: Sri Lanka and California. Our tool provides\nconsiderably greater predictive power on held-out datasets than simpler\nbaseline models.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2016 21:47:57 GMT"}, {"version": "v2", "created": "Thu, 2 Jun 2016 23:24:48 GMT"}, {"version": "v3", "created": "Fri, 7 Oct 2016 17:37:42 GMT"}, {"version": "v4", "created": "Fri, 26 May 2017 12:56:42 GMT"}], "update_date": "2017-05-29", "authors_parsed": [["Nay", "John J.", ""], ["Burchfield", "Emily", ""], ["Gilligan", "Jonathan", ""]]}, {"id": "1602.06375", "submitter": "Emrah Akyol", "authors": "Emrah Akyol and Urbashi Mitra", "title": "Power-Distortion Metrics for Path Planning over Gaussian Sensor Networks", "comments": "will appear in Trans. on Communications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.RO math.IT math.OC stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Path planning is an important component of au- tonomous mobile sensing\nsystems. This paper studies upper and lower bounds of communication performance\nover Gaussian sen- sor networks, to drive power-distortion metrics for path\nplanning problems. The Gaussian multiple-access channel is employed as a\nchannel model and two source models are considered. In the first setting, the\nunderlying source is estimated with minimum mean squared error, while in the\nsecond, reconstruction of a random spatial field is considered. For both\nproblem settings, the upper and the lower bounds of sensor power-distortion\ncurve are derived. For both settings, the upper bounds follow from the\namplify-and-forward scheme and the lower bounds admit a unified derivation\nbased on data processing inequality and tensorization property of the maximal\ncorrelation measure. Next, closed-form solutions of the optimal power\nallocation problems are obtained under a weighted sum-power constraint. The gap\nbetween the upper and the lower bounds is analyzed for both weighted sum and\nindividual power constrained settings. Finally, these metrics are used to drive\na path planning algorithm and the effects of power-distortion metrics, network\nparameters, and power optimization on the optimized path selection are\nanalyzed.\n", "versions": [{"version": "v1", "created": "Sat, 20 Feb 2016 07:06:08 GMT"}], "update_date": "2016-02-23", "authors_parsed": [["Akyol", "Emrah", ""], ["Mitra", "Urbashi", ""]]}, {"id": "1602.06429", "submitter": "Jonathan Warrell", "authors": "Jonathan H. Warrell, Anca F. Savulescu, Robyn Brackin, Musa M. Mhlanga", "title": "Generalized Statistical Tests for mRNA and Protein Subcellular Spatial\n  Patterning against Complete Spatial Randomness", "comments": "17 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML q-bio.QM stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive generalized estimators for a number of spatial statistics that have\nbeen used in the analysis of spatially resolved omics data, such as Ripley's K,\nH and L functions, clustering index, and degree of clustering, which allow\nthese statistics to be calculated on data modelled by arbitrary random measures\n(RMs). Our estimators generalize those typically used to calculate these\nstatistics on point process data, allowing them to be calculated on RMs which\nassign continuous values to spatial regions, for instance to model protein\nintensity. The clustering index (H*) compares Ripley's H function calculated\nempirically to its distribution under complete spatial randomness (CSR),\nleading us to consider CSR null hypotheses for RMs which are not\npoint-processes when generalizing this statistic. We thus consider restricted\nclasses of completely random measures which can be simulated directly (Gamma\nprocesses and Marked Poisson Processes), as well as the general class of all\nCSR RMs, for which we derive an exact permutation-based H* estimator. We\nestablish several properties of the estimators, including bounds on the\naccuracy of our general Ripley K estimator, its relationship to a previous\nestimator for the cross-correlation measure, and the relationship of our\ngeneralized H* estimator to previous statistics. To test the ability of our\napproach to identify spatial patterning, we use Fluorescent In Situ\nHybridization (FISH) and Immunofluorescence (IF) data to probe for mRNA and\nprotein subcellular localization patterns respectively in polarizing mouse\nfibroblasts on micropattened cells. We observe correlated patterns of\nclustering over time for corresponding mRNAs and proteins, suggesting a\ndeterministic effect of mRNA localization on protein localization for several\npairs tested, including one case in which spatial patterning at the mRNA level\nhas not been previously demonstrated.\n", "versions": [{"version": "v1", "created": "Sat, 20 Feb 2016 16:31:18 GMT"}, {"version": "v2", "created": "Sun, 28 Feb 2016 12:20:53 GMT"}, {"version": "v3", "created": "Sun, 10 Apr 2016 12:40:27 GMT"}], "update_date": "2016-04-12", "authors_parsed": [["Warrell", "Jonathan H.", ""], ["Savulescu", "Anca F.", ""], ["Brackin", "Robyn", ""], ["Mhlanga", "Musa M.", ""]]}, {"id": "1602.06461", "submitter": "Jordan Yoder", "authors": "Jonathan Mellon, Jordan Yoder, and Daniel Evans", "title": "Undermining and Strengthening Social Networks through Network\n  Modification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI physics.soc-ph stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social networks have well documented effects at the individual and aggregate\nlevel. Consequently it is often useful to understand how an attempt to\ninfluence a network will change its structure and consequently achieve other\ngoals. We develop a framework for network modification that allows for\narbitrary objective functions, types of modification (e.g. edge weight\naddition, edge weight removal, node removal, and covariate value change), and\nrecovery mechanisms (i.e. how a network responds to interventions). The\nframework outlined in this paper helps both to situate the existing work on\nnetwork interventions but also opens up many new possibilities for intervening\nin networks. In particular use two case studies to highlight the potential\nimpact of empirically calibrating the objective function and network recovery\nmechanisms as well as showing how interventions beyond node removal can be\noptimised. First, we simulate an optimal removal of nodes from the Noordin\nterrorist network in order to reduce the expected number of attacks (based on\nempirically predicting the terrorist collaboration network from multiple types\nof network ties). Second, we simulate optimally strengthening ties within\nentrepreneurial ecosystems in six developing countries. In both cases we\nestimate ERGM models to simulate how a network will endogenously evolve after\nintervention.\n", "versions": [{"version": "v1", "created": "Sat, 20 Feb 2016 21:08:40 GMT"}], "update_date": "2016-02-24", "authors_parsed": [["Mellon", "Jonathan", ""], ["Yoder", "Jordan", ""], ["Evans", "Daniel", ""]]}, {"id": "1602.06550", "submitter": "Igor Melnyk", "authors": "Igor Melnyk, Arindam Banerjee, Bryan Matthews, and Nikunj Oza", "title": "Semi-Markov Switching Vector Autoregressive Model-based Anomaly\n  Detection in Aviation Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we consider the problem of anomaly detection in heterogeneous,\nmultivariate, variable-length time series datasets. Our focus is on the\naviation safety domain, where data objects are flights and time series are\nsensor readings and pilot switches. In this context the goal is to detect\nanomalous flight segments, due to mechanical, environmental, or human factors\nin order to identifying operationally significant events and provide insights\ninto the flight operations and highlight otherwise unavailable potential safety\nrisks and precursors to accidents. For this purpose, we propose a framework\nwhich represents each flight using a semi-Markov switching vector\nautoregressive (SMS-VAR) model. Detection of anomalies is then based on\nmeasuring dissimilarities between the model's prediction and data observation.\nThe framework is scalable, due to the inherent parallel nature of most\ncomputations, and can be used to perform online anomaly detection. Extensive\nexperimental results on simulated and real datasets illustrate that the\nframework can detect various types of anomalies along with the key parameters\ninvolved.\n", "versions": [{"version": "v1", "created": "Sun, 21 Feb 2016 16:55:36 GMT"}, {"version": "v2", "created": "Sun, 28 Feb 2016 23:12:31 GMT"}], "update_date": "2016-03-01", "authors_parsed": [["Melnyk", "Igor", ""], ["Banerjee", "Arindam", ""], ["Matthews", "Bryan", ""], ["Oza", "Nikunj", ""]]}, {"id": "1602.06570", "submitter": "Roland Langrock", "authors": "Stacy L DeRuiter, Roland Langrock, Tomas Skirbutas, Jeremy A\n  Goldbogen, John Chalambokidis, Ari S Friedlaender, Brandon L Southall", "title": "A multivariate mixed hidden Markov model to analyze blue whale diving\n  behaviour during controlled sound exposures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Characterization of multivariate time series of behaviour data from\nanimal-borne sensors is challenging. Biologists require methods to objectively\nquantify baseline behaviour, then assess behaviour changes in response to\nenvironmental stimuli. Here, we apply hidden Markov models (HMMs) to\ncharacterize blue whale movement and diving behaviour, identifying latent\nstates corresponding to three main underlying behaviour states: shallow\nfeeding, travelling, and deep feeding. The model formulation accounts for\ninter-whale differences via a computationally efficient discrete random effect,\nand measures potential effects of experimental acoustic disturbance on\nbetween-state transition probabilities. We identify clear differences in blue\nwhale disturbance response depending on the behavioural context during\nexposure, with whales less likely to initiate deep foraging behaviour during\nexposure. Findings are consistent with earlier studies using smaller samples,\nbut the HMM approach provides more nuanced characterization of behaviour\nchanges.\n", "versions": [{"version": "v1", "created": "Sun, 21 Feb 2016 19:43:25 GMT"}], "update_date": "2016-02-24", "authors_parsed": [["DeRuiter", "Stacy L", ""], ["Langrock", "Roland", ""], ["Skirbutas", "Tomas", ""], ["Goldbogen", "Jeremy A", ""], ["Chalambokidis", "John", ""], ["Friedlaender", "Ari S", ""], ["Southall", "Brandon L", ""]]}, {"id": "1602.06579", "submitter": "Pedro Pury", "authors": "Pedro A. Pury", "title": "Analytic queueing model for ambulance services", "comments": "13 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present predictive tools to calculate the number of ambulances needed\naccording to demand of entrance calls and time of service. Our analysis\ndiscriminates between emergency and non-urgent calls. First, we consider the\nnonstationary regime where we apply previous results of first-passage time of\none dimensional random walks. Then, we reconsider the stationary regime with a\ndetailed discussion of the conditional probabilities and we discuss the key\nperformance indicators.\n", "versions": [{"version": "v1", "created": "Sun, 21 Feb 2016 21:08:12 GMT"}], "update_date": "2016-02-23", "authors_parsed": [["Pury", "Pedro A.", ""]]}, {"id": "1602.06604", "submitter": "Andrey Y. Lokhov", "authors": "Andrey Y. Lokhov, Nathan Lemons, Thomas C. McAndrew, Aric Hagberg,\n  Scott Backhaus", "title": "Detection of Cyber-Physical Faults and Intrusions from Physical\n  Correlations", "comments": "10 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.SI physics.data-an physics.soc-ph stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cyber-physical systems are critical infrastructures that are crucial both to\nthe reliable delivery of resources such as energy, and to the stable\nfunctioning of automatic and control architectures. These systems are composed\nof interdependent physical, control and communications networks described by\ndisparate mathematical models creating scientific challenges that go well\nbeyond the modeling and analysis of the individual networks. A key challenge in\ncyber-physical defense is a fast online detection and localization of faults\nand intrusions without prior knowledge of the failure type. We describe a set\nof techniques for the efficient identification of faults from correlations in\nphysical signals, assuming only a minimal amount of available system\ninformation. The performance of our detection method is illustrated on data\ncollected from a large building automation system.\n", "versions": [{"version": "v1", "created": "Sun, 21 Feb 2016 23:42:53 GMT"}, {"version": "v2", "created": "Fri, 1 Jul 2016 05:27:39 GMT"}], "update_date": "2016-07-04", "authors_parsed": [["Lokhov", "Andrey Y.", ""], ["Lemons", "Nathan", ""], ["McAndrew", "Thomas C.", ""], ["Hagberg", "Aric", ""], ["Backhaus", "Scott", ""]]}, {"id": "1602.06717", "submitter": "Moshe Pollak", "authors": "Michal Shauly-Aharonov, Moshe Pollak, Ygal Plakht", "title": "A Method for Detecting Life-Threatening Signals in Serum Potassium Level\n  after Myocardial Infarction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clinical guidelines recommend maintaining serum potassium levels between 4.0\nand 5.0 mEq/L in patients with acute myocardial infarction (MI). These\nguidelines are based on recent studies that found significant associations\nbetween crossing of absolute potassium limits (by in-hospital mean or by\nmin/max values) and mortality. This paper investigates a different approach: we\nhypothesized that a change in the potassium level may be a harbinger of short\nsurvivability, rather than crossing of absolute boundaries. Our objectives\nwere: (1) to examine if a \"change in mean\" indicator has the ability to\ndistinguish between survivors and non-survivors of MI hospitalization, and if\nso, (2) to formulate a framework for detecting life-threatening changes in\npotassium level of patients hospitalized with MI. The study included 195\npatients who were hospitalized for MI from 2002 to 2014, with at least 40\npotassium measurements (i.e., severely ill). In a retrospective analysis we\nfound evidence that the \"change in mean\" criterion significantly discriminated\nbetween survivors and non-survivors. A threshold for raising an alarm was\nspecified by plotting an ROC curve and choosing the value that yields the best\ncombination of sensitivity and specificity. In this case, the method detected\n~80% of the patients that eventually died, while wrongly alerting for only ~40%\nof the survivors. The proposed approach is not intended for replacing the\nabsolute-level protocols but to add valuable knowledge to cardiologists.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2016 10:49:40 GMT"}], "update_date": "2016-02-23", "authors_parsed": [["Shauly-Aharonov", "Michal", ""], ["Pollak", "Moshe", ""], ["Plakht", "Ygal", ""]]}, {"id": "1602.06885", "submitter": "Virginie Ollier", "authors": "Virginie Ollier, Mohammed Nabil El Korso, R\\'emy Boyer, Pascal\n  Larzabal, Marius Pesavento", "title": "Joint ML calibration and DOA estimation with separated arrays", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates parametric direction-of-arrival (DOA) estimation in a\nparticular context: i) each sensor is characterized by an unknown complex gain\nand ii) the array consists of a collection of subarrays which are substantially\nseparated from each other leading to a structured noise covariance matrix. We\npropose two iterative algorithms based on the maximum likelihood (ML)\nestimation method adapted to the context of joint array calibration and DOA\nestimation. Numerical simulations reveal that the two proposed schemes, the\niterative ML (IML) and the modified iterative ML (MIML) algorithms for joint\narray calibration and DOA estimation, outperform the state of the art methods\nand the MIML algorithm reaches the Cram\\'er-Rao bound for a low number of\niterations.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2016 18:32:57 GMT"}, {"version": "v2", "created": "Sat, 27 Feb 2016 10:59:06 GMT"}, {"version": "v3", "created": "Tue, 17 May 2016 09:25:24 GMT"}, {"version": "v4", "created": "Sun, 22 Jan 2017 17:27:57 GMT"}], "update_date": "2017-01-24", "authors_parsed": [["Ollier", "Virginie", ""], ["Korso", "Mohammed Nabil El", ""], ["Boyer", "R\u00e9my", ""], ["Larzabal", "Pascal", ""], ["Pesavento", "Marius", ""]]}, {"id": "1602.06972", "submitter": "Silvia Liverani", "authors": "Silvia Liverani, Aurore Lavigne, Marta Blangiardo", "title": "Modelling collinear and spatially correlated data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we present a statistical approach to distinguish and interpret\nthe complex relationship between several predictors and a response variable at\nthe small area level, in the presence of i) high correlation between the\npredictors and ii) spatial correlation for the response. Covariates which are\nhighly correlated create collinearity problems when used in a standard multiple\nregression model. Many methods have been proposed in the literature to address\nthis issue. A very common approach is to create an index which aggregates all\nthe highly correlated variables of interest. For example, it is well known that\nthere is a relationship between social deprivation measured through the\nMultiple Deprivation Index (IMD) and air pollution; this index is then used as\na confounder in assessing the effect of air pollution on health outcomes (e.g.\nrespiratory hospital admissions or mortality). However it would be more\ninformative to look specifically at each domain of the IMD and at its\nrelationship with air pollution to better understand its role as a confounder\nin the epidemiological analyses. In this paper we illustrate how the complex\nrelationships between the domains of IMD and air pollution can be deconstructed\nand analysed using profile regression, a Bayesian non-parametric model for\nclustering responses and covariates simultaneously. Moreover, we include an\nintrinsic spatial conditional autoregressive (ICAR) term to account for the\nspatial correlation of the response variable.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2016 21:32:41 GMT"}], "update_date": "2016-02-24", "authors_parsed": [["Liverani", "Silvia", ""], ["Lavigne", "Aurore", ""], ["Blangiardo", "Marta", ""]]}, {"id": "1602.07207", "submitter": "Christian R\\\"over", "authors": "Steffen Unkel, Christian R\\\"over, Nigel Stallard, Norbert Benda,\n  Martin Posch, Sarah Zohar, Tim Friede", "title": "Systematic reviews in paediatric multiple sclerosis and\n  Creutzfeldt-Jakob disease exemplify shortcomings in methods used to evaluate\n  therapies in rare conditions", "comments": "11 pages, 2 figures, 3 tables", "journal-ref": "Orphanet Journal of Rare Diseases, 11:16, 2016", "doi": "10.1186/s13023-016-0402-6", "report-no": null, "categories": "q-bio.QM stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  BACKGROUND: Randomized controlled trials (RCTs) are the gold standard design\nof clinical research to assess interventions. However, RCTs cannot always be\napplied for practical or ethical reasons. To investigate the current practices\nin rare diseases, we review evaluations of therapeutic interventions in\npaediatric multiple sclerosis (MS) and Creutzfeldt-Jakob disease (CJD). In\nparticular, we shed light on the endpoints used, the study designs implemented\nand the statistical methodologies applied.\n  METHODS: We conducted literature searches to identify relevant primary\nstudies. Data on study design, objectives, endpoints, patient characteristics,\nrandomization and masking, type of intervention, control, withdrawals and\nstatistical methodology were extracted from the selected studies. The risk of\nbias and the quality of the studies were assessed.\n  RESULTS: Twelve (seven) primary studies on paediatric MS (CJD) were included\nin the qualitative synthesis. No double-blind, randomized placebo-controlled\ntrial for evaluating interventions in paediatric MS has been published yet.\nEvidence from one open-label RCT is available. The observational studies are\nbefore-after studies or controlled studies. Three of the seven selected studies\non CJD are RCTs, of which two received the maximum mark on the Oxford Quality\nScale. Four trials are controlled observational studies.\n  CONCLUSIONS: Evidence from double-blind RCTs on the efficacy of treatments\nappears to be variable between rare diseases. With regard to paediatric\nconditions it remains to be seen what impact regulators will have through e.g.,\npaediatric investigation plans. Overall, there is space for improvement by\nusing innovative trial designs and data analysis techniques.\n", "versions": [{"version": "v1", "created": "Sun, 21 Feb 2016 16:28:58 GMT"}], "update_date": "2016-02-25", "authors_parsed": [["Unkel", "Steffen", ""], ["R\u00f6ver", "Christian", ""], ["Stallard", "Nigel", ""], ["Benda", "Norbert", ""], ["Posch", "Martin", ""], ["Zohar", "Sarah", ""], ["Friede", "Tim", ""]]}, {"id": "1602.07228", "submitter": "Malcolm Itter", "authors": "Malcolm S. Itter, Andrew O. Finley, Anthony W. D'Amato, Jane R.\n  Foster, John B. Bradford", "title": "Variable Effects of Climate on Forest Growth in Relation to Climate\n  Extremes, Disturbance, and Forest Stand Dynamics", "comments": "30 pages, 3 tables, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Changes in the frequency, duration, and severity of climate extremes are\nforecast to occur under global climate change. The impacts of climate extremes\non forest productivity and health are complicated by potential interactions\nwith disturbance events and stand dynamics. The effects of stand dynamics on\nforest responses to climate and disturbance are particularly important given\nforest characteristics driven by stand dynamics can be modified through forest\nmanagement with the goal of increasing forest resistance and resilience to\nclimate change. We develop a hierarchical Bayesian state-space model allowing\nclimate effects on tree growth to vary over time and in relation to climate\nextremes, disturbance events, and stand dynamics. We apply the model to a\ndendrochronology dataset comprising measurements from forest stands of varying\ncomposition, structure, and development stage in northeastern Minnesota.\nResults indicate average forest growth was most sensitive to variables\ndescribing climatic water deficit. Forest growth responses to water deficit\nwere partitioned into responses driven by climatic threshold exceedances and\ninteractions with forest tent caterpillar defoliation. Forest growth was both\nresistant and resilient to climate extremes with the majority of forest growth\nresponses occurring after multiple climatic threshold exceedances or insect\ndefoliation events. Forest growth was most sensitive to water deficit during\nperiods of high stem density following major regeneration events when average\ninter-tree competition was high. Results suggest that forest growth resistance\nand resilience to interactions between climate extremes and insect defoliation\ncan be increased through management steps such as thinning to reduce\ncompetition during early stages of stand development and small-group selection\nharvests to maintain forest structures characteristic of older, mature stands.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2016 16:42:52 GMT"}, {"version": "v2", "created": "Fri, 2 Dec 2016 20:13:50 GMT"}], "update_date": "2016-12-05", "authors_parsed": [["Itter", "Malcolm S.", ""], ["Finley", "Andrew O.", ""], ["D'Amato", "Anthony W.", ""], ["Foster", "Jane R.", ""], ["Bradford", "John B.", ""]]}, {"id": "1602.07280", "submitter": "Vaibhav Rajan", "authors": "Abhishek Sengupta, Vaibhav Rajan, Sakyajit Bhattacharya, G R K Sarma", "title": "A Statistical Model for Stroke Outcome Prediction and Treatment Planning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stroke is a major cause of mortality and long--term disability in the world.\nPredictive outcome models in stroke are valuable for personalized treatment,\nrehabilitation planning and in controlled clinical trials. In this paper we\ndesign a new model to predict outcome in the short-term, the putative\ntherapeutic window for several treatments. Our regression-based model has a\nparametric form that is designed to address many challenges common in medical\ndatasets like highly correlated variables and class imbalance. Empirically our\nmodel outperforms the best--known previous models in predicting short--term\noutcomes and in inferring the most effective treatments that improve outcome.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2016 12:51:39 GMT"}], "update_date": "2016-02-24", "authors_parsed": [["Sengupta", "Abhishek", ""], ["Rajan", "Vaibhav", ""], ["Bhattacharya", "Sakyajit", ""], ["Sarma", "G R K", ""]]}, {"id": "1602.07290", "submitter": "Andr\\'e Beauducel", "authors": "Andre Beauducel, Christopher Harms and Norbert Hilger", "title": "Reliability estimates for three factor score predictors", "comments": "2 figures", "journal-ref": null, "doi": "10.5539/ijsp.v5n6p94", "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimates for the reliability of Thurstone's regression factor score\npredictor, Bartlett's factor score predictor, and McDonald's factor score\npredictor were proposed. As in Kuder-Richardson's formula, the reliability\nestimates are based on a hypothetical set of equivalent items. The reliability\nestimates were compared by means of simulation studies. Overall, the\nreliability estimates were largest for the regression score predictor, so that\nthe reliability estimates for Bartlett's and McDonald's factor score predictor\nshould be compared with the reliability of the regression score predictor,\nwhenever Bartlett's or McDonald's factor score predictor are to be computed. An\nR-script and an SPSS-script for the computation of the respective reliability\nestimates is presented.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2016 20:37:24 GMT"}], "update_date": "2016-11-28", "authors_parsed": [["Beauducel", "Andre", ""], ["Harms", "Christopher", ""], ["Hilger", "Norbert", ""]]}, {"id": "1602.07559", "submitter": "Michael Donohue", "authors": "Michael C. Donohue and Anthony C. Gamst and Robert A. Rissman and Ian\n  Abramson", "title": "Regression of ranked responses when raw responses are censored", "comments": "33 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss semiparametric regression when only the ranks of responses are\nobserved. The model is $Y_i = F (\\mathbf{x}_i'{\\boldsymbol\\beta}_0 +\n\\varepsilon_i)$, where $Y_i$ is the unobserved response, $F$ is a monotone\nincreasing function, $\\mathbf{x}_i$ is a known $p-$vector of covariates,\n${\\boldsymbol\\beta}_0$ is an unknown $p$-vector of interest, and\n$\\varepsilon_i$ is an error term independent of $\\mathbf{x}_i$. We observe\n$\\{(\\mathbf{x}_i,R_n(Y_i)) : i = 1,\\ldots ,n\\}$, where $R_n$ is the ordinal\nrank function. We explore a novel estimator under Gaussian assumptions. We\ndiscuss the literature, apply the method to an Alzheimer's disease biomarker,\nconduct simulation studies, and prove consistency and asymptotic normality.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2016 15:28:33 GMT"}], "update_date": "2016-02-25", "authors_parsed": [["Donohue", "Michael C.", ""], ["Gamst", "Anthony C.", ""], ["Rissman", "Robert A.", ""], ["Abramson", "Ian", ""]]}, {"id": "1602.07754", "submitter": "Kevin Xu", "authors": "Swayambhoo Jain, Urvashi Oswal, Kevin S. Xu, Brian Eriksson, Jarvis\n  Haupt", "title": "A Compressed Sensing Based Decomposition of Electrodermal Activity\n  Signals", "comments": "To appear in IEEE Transactions on Biomedical Engineering", "journal-ref": null, "doi": "10.1109/TBME.2016.2632523", "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The measurement and analysis of Electrodermal Activity (EDA) offers\napplications in diverse areas ranging from market research, to seizure\ndetection, to human stress analysis. Unfortunately, the analysis of EDA signals\nis made difficult by the superposition of numerous components which can obscure\nthe signal information related to a user's response to a stimulus. We show how\nsimple pre-processing followed by a novel compressed sensing based\ndecomposition can mitigate the effects of the undesired noise components and\nhelp reveal the underlying physiological signal. The proposed framework allows\nfor decomposition of EDA signals with provable bounds on the recovery of user\nresponses. We test our procedure on both synthetic and real-world EDA signals\nfrom wearable sensors and demonstrate that our approach allows for more\naccurate recovery of user responses as compared to the existing techniques.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2016 23:52:07 GMT"}, {"version": "v2", "created": "Thu, 26 Jan 2017 21:03:57 GMT"}], "update_date": "2017-02-01", "authors_parsed": [["Jain", "Swayambhoo", ""], ["Oswal", "Urvashi", ""], ["Xu", "Kevin S.", ""], ["Eriksson", "Brian", ""], ["Haupt", "Jarvis", ""]]}, {"id": "1602.07836", "submitter": "Vesa Palonen Dr", "authors": "V. Palonen", "title": "A Bayesian baseline for belief in uncommon events", "comments": "13 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.ML stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The plausibility of uncommon events and miracles based on testimony of such\nan event has been much discussed. When analyzing the probabilities involved, it\nhas mostly been assumed that the common events can be taken as data in the\ncalculations. However, we usually have only testimonies for the common events.\nWhile this difference does not have a significant effect on the inductive part\nof the inference, it has a large influence on how one should view the\nreliability of testimonies. In this work, a full Bayesian solution is given for\nthe more realistic case, where one has a large number of testimonies for a\ncommon event and one testimony for an uncommon event. It is seen that, in order\nfor there to be a large amount of testimonies for a common event, the\ntestimonies will probably be quite reliable. For this reason, because the\ntestimonies are quite reliable based on the testimonies for the common events,\nthe probability for the uncommon event, given a testimony for it, is also\nhigher. Hence, one should be more open-minded when considering the plausibility\nof uncommon events.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2016 07:57:07 GMT"}, {"version": "v2", "created": "Sat, 27 Feb 2016 17:27:49 GMT"}], "update_date": "2016-03-01", "authors_parsed": [["Palonen", "V.", ""]]}, {"id": "1602.08066", "submitter": "Matt Taddy", "authors": "Matt Taddy, Hedibert Freitas Lopes, Matt Gardner", "title": "Scalable semiparametric inference for the means of heavy-tailed\n  distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Heavy tailed distributions present a tough setting for inference. They are\nalso common in industrial applications, particularly with Internet transaction\ndatasets, and machine learners often analyze such data without considering the\nbiases and risks associated with the misuse of standard tools. This paper\noutlines a procedure for inference about the mean of a (possibly conditional)\nheavy tailed distribution that combines nonparametric analysis for the bulk of\nthe support with Bayesian parametric modeling -- motivated from extreme value\ntheory -- for the heavy tail. The procedure is fast and massively scalable. The\nresulting point estimators attain lowest-possible error rates and, unique among\nalternatives, we are able to provide accurate uncertainty quantification for\nthese estimators. The work should find application in settings wherever correct\ninference is important and reward tails are heavy; we illustrate the framework\nin causal inference for A/B experiments involving hundreds of millions of users\nof eBay.com.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2016 20:15:07 GMT"}, {"version": "v2", "created": "Fri, 20 May 2016 18:59:17 GMT"}, {"version": "v3", "created": "Thu, 13 Oct 2016 14:56:08 GMT"}], "update_date": "2016-10-14", "authors_parsed": [["Taddy", "Matt", ""], ["Lopes", "Hedibert Freitas", ""], ["Gardner", "Matt", ""]]}, {"id": "1602.08080", "submitter": "Bamdad Hosseini Mr.", "authors": "Bamdad Hosseini, Charles Mougenot, Samuel Pichardo, Elodie\n  Constanciel, James M. Drake, John M. Stockie", "title": "A Bayesian approach for energy-based estimation of acoustic aberrations\n  in high intensity focused ultrasound treatment", "comments": null, "journal-ref": "Communications in Computational Physics 25(5):1564-1590, 2019", "doi": "10.4208/cicp.OA-2018-0007", "report-no": null, "categories": "physics.med-ph stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High intensity focused ultrasound is a non-invasive method for treatment of\ndiseased tissue that uses a beam of ultrasound to generate heat within a small\nvolume. A common challenge in application of this technique is that\nheterogeneity of the biological medium can defocus the ultrasound beam. Here we\nreduce the problem of refocusing the beam to the inverse problem of estimating\nthe acoustic aberration due to the biological tissue from acoustic radiative\nforce imaging data. We solve this inverse problem using a Bayesian framework\nwith a hierarchical prior and solve the inverse problem using a\nMetropolis-within-Gibbs algorithm. The framework is tested using both synthetic\nand experimental datasets. We demonstrate that our approach has the ability to\nestimate the aberrations using small datasets, as little as 32 sonication\ntests, which can lead to significant speedup in the treatment process.\nFurthermore, our approach is compatible with a wide range of sonication tests\nand can be applied to other energy-based measurement techniques.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2016 16:48:14 GMT"}, {"version": "v2", "created": "Thu, 7 Jun 2018 16:49:51 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Hosseini", "Bamdad", ""], ["Mougenot", "Charles", ""], ["Pichardo", "Samuel", ""], ["Constanciel", "Elodie", ""], ["Drake", "James M.", ""], ["Stockie", "John M.", ""]]}, {"id": "1602.08154", "submitter": "Gregor Kastner", "authors": "Gregor Kastner, Sylvia Fr\\\"uhwirth-Schnatter, Hedibert Freitas Lopes", "title": "Efficient Bayesian Inference for Multivariate Factor Stochastic\n  Volatility Models", "comments": null, "journal-ref": "Journal of Computational and Graphical Statistics 26(4), 905-917\n  (2017)", "doi": "10.1080/10618600.2017.1322091", "report-no": null, "categories": "stat.CO econ.EM stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss efficient Bayesian estimation of dynamic covariance matrices in\nmultivariate time series through a factor stochastic volatility model. In\nparticular, we propose two interweaving strategies (Yu and Meng, Journal of\nComputational and Graphical Statistics, 20(3), 531-570, 2011) to substantially\naccelerate convergence and mixing of standard MCMC approaches. Similar to\nmarginal data augmentation techniques, the proposed acceleration procedures\nexploit non-identifiability issues which frequently arise in factor models. Our\nnew interweaving strategies are easy to implement and come at almost no extra\ncomputational cost; nevertheless, they can boost estimation efficiency by\nseveral orders of magnitude as is shown in extensive simulation studies. To\nconclude, the application of our algorithm to a 26-dimensional exchange rate\ndata set illustrates the superior performance of the new approach for\nreal-world data.\n", "versions": [{"version": "v1", "created": "Fri, 26 Feb 2016 00:01:27 GMT"}, {"version": "v2", "created": "Thu, 16 Mar 2017 15:07:01 GMT"}, {"version": "v3", "created": "Wed, 19 Jul 2017 13:11:14 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Kastner", "Gregor", ""], ["Fr\u00fchwirth-Schnatter", "Sylvia", ""], ["Lopes", "Hedibert Freitas", ""]]}, {"id": "1602.08355", "submitter": "Michel Fliess", "authors": "Hassane Aboua\\\"issa, Michel Fliess, C\\'edric Join", "title": "On short-term traffic flow forecasting and its reliability", "comments": "8th IFAC Conference on Manufacturing Modeling, Management & Control\n  (Troyes, France, June 2016)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.OH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in time series, where deterministic and stochastic modelings\nas well as the storage and analysis of big data are useless, permit a new\napproach to short-term traffic flow forecasting and to its reliability, i.e.,\nto the traffic volatility. Several convincing computer simulations, which\nutilize concrete data, are presented and discussed.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2016 18:24:56 GMT"}], "update_date": "2016-02-29", "authors_parsed": [["Aboua\u00efssa", "Hassane", ""], ["Fliess", "Michel", ""], ["Join", "C\u00e9dric", ""]]}, {"id": "1602.08360", "submitter": "Nicole Augustin H", "authors": "Nicole Augustin, Sung Won Kim, Annemarie Uhlig, Christina Hanser,\n  Michael Henke and Martin Schumacher", "title": "A flexible multivariate random effects proportional odds model with\n  application to adverse effects during radiation therapy", "comments": null, "journal-ref": null, "doi": "10.1002/bimj.201600142", "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Radiation therapy in patients with head and neck cancer has a toxic effect on\nmucosa, the soft tissue in and around the mouth. Hence mucositis is a serious\ncommon side effect and is a condition characterized by pain and inflammation of\nthe surface of the mucosa. Although the mucosa recovers during breaks of and\nfollowing the radiotherapy course the recovery will depend on the type of\ntissue involved and on its location. We present a novel flexible multivariate\nrandom effects proportional odds model which takes account of the longitudinal\ncourse of oral mucositis at different mouth sites and of the radiation dosage\n(in terms of cumulative dose). The model is an extension of the {\\em\nproportional odds model} which is used for ordinal response variables. Our\nmodel includes the ordinal multivariate response of the mucositis score by\nlocation, random intercepts for individuals and includes a non-linear function\nof cumulative radiation dose. The model allows to test whether sensitivity\ndiffers by mouth sites after having adjusted for site specific cumulative\nradiation dose. The model also allows to check whether and how the (non-linear)\neffect of site specific dose differs by site. We fit the model to longitudinal\npatient data from a prospective observation and find that after adjusting for\ncumulative dose, upper, lower lips and mouth floor are associated with the\nlowest mucositis scores and hard and soft palate are associated with the\nhighest mucositis scores. This implies the possibility that tissues at\ndifferent mouth locations differ in their sensitivity to the toxic effect of\nradiation. We also find that cumulative dose followed by mouth site are the\nstrongest predictors of mucositis, and the effects of age and gender are\nnegligible.\n", "versions": [{"version": "v1", "created": "Fri, 26 Feb 2016 15:05:36 GMT"}], "update_date": "2018-05-17", "authors_parsed": [["Augustin", "Nicole", ""], ["Kim", "Sung Won", ""], ["Uhlig", "Annemarie", ""], ["Hanser", "Christina", ""], ["Henke", "Michael", ""], ["Schumacher", "Martin", ""]]}, {"id": "1602.08644", "submitter": "Lorenzo Sabatelli", "authors": "Lorenzo Sabatelli", "title": "Relationship Between the Uncompensated Price-Elasticity and the\n  Income-Elasticity of Demand Under Conditions of Additive Preferences", "comments": "20 pages, 4 figures, original research manuscript", "journal-ref": null, "doi": "10.1371/journal.pone.0151390", "report-no": null, "categories": "stat.AP math.DS math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Income- and price-elasticity of demand quantify the responsiveness of markets\nto changes in income, and in prices, respectively. Under the assumptions of\nutility maximization and preference-independence (additive preferences),\nmathematical relationships between income-elasticity values and uncompensated\nown and cross price-elasticity of demand are here derived for bundle of goods,\nusing the differential approach to demand analysis. Key parameters are: the\nelasticity of the marginal utility of income, and the average budget-share. The\nproposed method can be applied to forecast the direct and indirect impact of\nprice changes, and of financial instruments of policy using available estimates\nof the income elasticity of demand.\n", "versions": [{"version": "v1", "created": "Sat, 27 Feb 2016 22:23:57 GMT"}, {"version": "v2", "created": "Wed, 16 Mar 2016 20:46:44 GMT"}, {"version": "v3", "created": "Mon, 28 Mar 2016 12:12:21 GMT"}], "update_date": "2016-04-27", "authors_parsed": [["Sabatelli", "Lorenzo", ""]]}, {"id": "1602.08678", "submitter": "Gordon Smyth", "authors": "Belinda Phipson, Stanley Lee, Ian J. Majewski, Warren S. Alexander and\n  Gordon K. Smyth", "title": "Robust hyperparameter estimation protects against hypervariable genes\n  and improves power to detect differential expression", "comments": "23 pages, 4 figures", "journal-ref": "Ann. Appl. Stat., Volume 10, Number 2 (2016), 946-963", "doi": "10.1214/16-AOAS920", "report-no": null, "categories": "stat.AP q-bio.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most common analysis tasks in genomic research is to identify\ngenes that are differentially expressed (DE) between experimental conditions.\nEmpirical Bayes (EB) statistical tests using moderated genewise variances have\nbeen very effective for this purpose, especially when the number of biological\nreplicate samples is small. The EB procedures can however be heavily influenced\nby a small number of genes with very large or very small variances. This\narticle improves the differential expression tests by robustifying the\nhyperparameter estimation procedure. The robust procedure has the effect of\ndecreasing the informativeness of the prior distribution for outlier genes\nwhile increasing its informativeness for other genes. This effect has the\ndouble benefit of reducing the chance that hypervariable genes will be\nspuriously identified as DE while increasing statistical power for the main\nbody of genes. The robust EB algorithm is fast and numerically stable. The\nprocedure allows exact small-sample null distributions for the test statistics\nand reduces exactly to the original EB procedure when no outlier genes are\npresent. Simulations show that the robustified tests have similar performance\nto the original tests in the absence of outlier genes but have greater power\nand robustness when outliers are present. The article includes case studies for\nwhich the robust method correctly identifies and downweights genes associated\nwith hidden covariates and detects more genes likely to be scientifically\nrelevant to the experimental conditions. The new procedure is implemented in\nthe limma software package freely available from the Bioconductor repository.\n", "versions": [{"version": "v1", "created": "Sun, 28 Feb 2016 06:43:47 GMT"}, {"version": "v2", "created": "Mon, 4 Apr 2016 00:48:49 GMT"}, {"version": "v3", "created": "Wed, 27 Jul 2016 04:59:37 GMT"}], "update_date": "2016-07-28", "authors_parsed": [["Phipson", "Belinda", ""], ["Lee", "Stanley", ""], ["Majewski", "Ian J.", ""], ["Alexander", "Warren S.", ""], ["Smyth", "Gordon K.", ""]]}, {"id": "1602.08696", "submitter": "Joanna D\\k{e}bicka", "authors": "Joanna D\\c{e}bicka and Beata Zmy\\'slona", "title": "Modelling of lung cancer survival data for critical illness insurances", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive a general multiple state model for critical illness insurances. In\ncontrast to the classical model, we take into account that the probability of\ndeath for a dread disease sufferer may depend on the duration of the disease,\nand the payment of benefits associated with a severe disease depends not only\non the diagnosis but also on the disease stage. We apply the introduced model\nto the analysis of a critical illness insurance against the risk of lung\ncancer. Based on the real data for the Lower Silesian Voivodship in Poland, we\nestimate the transition matrix, related to the discrete-time Markov model. The\nobtained probabilistic structure of the model can be directly used to cost not\nonly critical illness insurances and life insurances with accelerated death\nbenefits option, but also to viatical settlement contracts.\n", "versions": [{"version": "v1", "created": "Sun, 28 Feb 2016 10:32:10 GMT"}], "update_date": "2016-03-01", "authors_parsed": [["D\u0229bicka", "Joanna", ""], ["Zmy\u015blona", "Beata", ""]]}, {"id": "1602.08754", "submitter": "Matthew van Bommel", "authors": "Matthew van Bommel, Luke Bornn", "title": "Adjusting for Scorekeeper Bias in NBA Box Scores", "comments": "16 pages, 7 figures, updated results to 2015-2016 season, added\n  related works section, added model validation and consistency results", "journal-ref": "Data Min Knowl Disc (2017) 31: 1622", "doi": "10.1007/s10618-017-0497-y", "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Box score statistics in the National Basketball Association are used to\nmeasure and evaluate player performance. Some of these statistics are\nsubjective in nature and since box score statistics are recorded by\nscorekeepers hired by the home team for each game, there exists potential for\ninconsistency and bias. These inconsistencies can have far reaching\nconsequences, particularly with the rise in popularity of daily fantasy sports.\nUsing box score data, we estimate models able to quantify both the bias and the\ngenerosity of each scorekeeper for two of the most subjective statistics:\nassists and blocks. We then use optical player tracking data for the 2014-2015\nseason to improve the assist model by including other contextual\nspatio-temporal variables such as time of possession, player locations, and\ndistance traveled. From this model, we present results measuring the impact of\nthe scorekeeper and of the other contextual variables on the probability of a\npass being recorded as an assist. Results for adjusting season assist totals to\nremove scorekeeper influence are also presented.\n", "versions": [{"version": "v1", "created": "Sun, 28 Feb 2016 18:44:08 GMT"}, {"version": "v2", "created": "Sun, 14 Aug 2016 03:11:55 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["van Bommel", "Matthew", ""], ["Bornn", "Luke", ""]]}, {"id": "1602.08773", "submitter": "Arthur Charpentier", "authors": "Arthur Charpentier and Mathieu Pigeon", "title": "Macro vs. Micro Methods in Non-Life Claims Reserving (an Econometric\n  Perspective)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditionally, actuaries have used run-off triangles to estimate reserve\n(\"macro\" models, on agregated data). But it is possible to model payments\nrelated to individual claims. If those models provide similar estimations, we\ninvestigate uncertainty related to reserves, with \"macro\" and \"micro\" models.\nWe study theoretical properties of econometric models (Gaussian, Poisson and\nquasi-Poisson) on individual data, and clustered data. Finally, application on\nclaims reserving are considered.\n", "versions": [{"version": "v1", "created": "Sun, 28 Feb 2016 21:58:59 GMT"}], "update_date": "2016-03-01", "authors_parsed": [["Charpentier", "Arthur", ""], ["Pigeon", "Mathieu", ""]]}, {"id": "1602.08861", "submitter": "B{\\l}a\\.zej Miasojedow", "authors": "Piotr Gwiazda, B{\\l}a\\.zej Miasojedow, Magdalena Rosi\\'nska", "title": "Bayesian inference for age-structured population model of infectious\n  disease with application to varicella in Poland", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamics of the infectious disease transmission is often best understood\ntaking into account the structure of population with respect to specific\nfeatures, in example age or immunity level. Practical utility of such models\ndepends on the appropriate calibration with the observed data. Here, we discuss\nthe Bayesian approach to data assimilation in case of two-state age-structured\nmodel. This kind of models are frequently used to describe the disease dynamics\n(i.e. force of infection) basing on prevalence data collected at several time\npoints. We demonstrate that, in the case when the explicit solution to the\nmodel equation is known, accounting for the data collection process in the\nBayesian framework allows to obtain an unbiased posterior distribution for the\nparameters determining the force of infection. We further show analytically and\nthrough numerical tests that the posterior distribution of these parameters is\nstable with respect to cohort approximation (Escalator Boxcar Train) to the\nsolution. Finally, we apply the technique to calibrate the model based on\nobserved sero-prevalence of varicella in Poland.\n", "versions": [{"version": "v1", "created": "Mon, 29 Feb 2016 08:47:22 GMT"}, {"version": "v2", "created": "Mon, 20 Jun 2016 07:54:51 GMT"}], "update_date": "2016-06-21", "authors_parsed": [["Gwiazda", "Piotr", ""], ["Miasojedow", "B\u0142a\u017cej", ""], ["Rosi\u0144ska", "Magdalena", ""]]}, {"id": "1602.08974", "submitter": "Peter Ruckdeschel", "authors": "Bernhard Spangl, Sascha Desmettre, Peter Ruckdeschel", "title": "Statistical models for dynamics in extreme value processes", "comments": "Appeared as Proceedings of 30th International Workshop on Statistical\n  Modelling, Johannes Kepler University Linz, July 6--10, 2015. Volume 1, H.\n  Friedl, H. Wagner (eds.), pp. 360--366", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study four different approaches to model time-dependent extremal behavior:\ndynamics introduced by (a) a state-space model (SSM), (b) a shot-noise-type\nprocess with GPD marginals, (c) a copula-based autoregressive model with GPD\nmarginals, and (d) a GLM with GPD marginals (and previous extremal events as\nregressors). Each of the models is fit against data, and from the fitted data,\nwe simulate corresponding paths according to the respective fitted models. At\nthis simulated data, the respective dependence structure is analyzed in copula\nplots and judged against its capacity to fit the corresponding inter-arrival\ndistribution.\n", "versions": [{"version": "v1", "created": "Mon, 29 Feb 2016 14:18:40 GMT"}], "update_date": "2016-03-01", "authors_parsed": [["Spangl", "Bernhard", ""], ["Desmettre", "Sascha", ""], ["Ruckdeschel", "Peter", ""]]}, {"id": "1602.09053", "submitter": "Bamdad Hosseini Mr.", "authors": "Bamdad Hosseini and John M. Stockie", "title": "Bayesian estimation of airborne fugitive emissions using a Gaussian\n  plume model", "comments": null, "journal-ref": "Atmospheric Environment, 141:122-138, 2016", "doi": "10.1016/j.atmosenv.2016.06.046", "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new method is proposed for estimating the rate of fugitive emissions of\nparticulate matter from multiple time-dependent sources via measurements of\ndeposition and concentration. We cast this source inversion problem within the\nBayesian framework, and use a forward model based on a Gaussian plume solution.\nWe present three alternate models for constructing the prior distribution on\nthe emission rates as functions of time. Next, we present an industrial case\nstudy in which our framework is applied to estimate the rate of fugitive\nemissions of lead particulates from a smelter in Trail, British Columbia,\nCanada. The Bayesian framework not only provides an approximate solution to the\ninverse problem, but also quantifies the uncertainty in the solution. Using\nthis information we perform an uncertainty propagation study in order to assess\nthe impact of the estimated sources on the area surrounding the industrial\nsite.\n", "versions": [{"version": "v1", "created": "Mon, 29 Feb 2016 17:23:18 GMT"}], "update_date": "2016-11-01", "authors_parsed": [["Hosseini", "Bamdad", ""], ["Stockie", "John M.", ""]]}, {"id": "1602.09082", "submitter": "Sergei Rodionov", "authors": "Sergei Rodionov", "title": "A comparison of two methods for detecting abrupt changes in the variance\n  of climatic time series", "comments": "32 pages, 11 figures", "journal-ref": "Adv. Stat. Clim. Meteorol. Oceanogr., 2, 63-78 (2016)", "doi": "10.5194/ascmo-2-63-2016", "report-no": null, "categories": "stat.AP physics.ao-ph stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two methods for detecting abrupt shifts in the variance, Integrated\nCumulative Sum of Squares (ICSS) and Sequential Regime Shift Detector (SRSD),\nhave been compared on both synthetic and observed time series. In Monte Carlo\nexperiments, SRSD outperformed ICSS in the overwhelming majority of the\nmodelled scenarios with different sequences of variance regimes. The SRSD\nadvantage was particularly apparent in the case of outliers in the series. When\ntested on climatic time series, in most cases both methods detected the same\nchange points in the longer series (252-787 monthly values). The only exception\nwas the Arctic Ocean SST series, when ICSS found one extra change point that\nappeared to be spurious. As for the shorter time series (66-136 yearly values),\nICSS failed to detect any change points even when the variance doubled or\ntripled from one regime to another. For these time series, SRSD is recommended.\nInterestingly, all the climatic time series tested, from the Arctic to the\nTropics, had one thing in common: the last shift detected in each of these\nseries was toward a high-variance regime. This is consistent with other\nfindings of increased climate variability in recent decades.\n", "versions": [{"version": "v1", "created": "Mon, 29 Feb 2016 18:35:22 GMT"}], "update_date": "2016-06-27", "authors_parsed": [["Rodionov", "Sergei", ""]]}]