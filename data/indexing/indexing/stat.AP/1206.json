[{"id": "1206.0133", "submitter": "Abdelaali Chaoub", "authors": "Abdelaali Chaoub and Elhassane Ibn-Elhaj", "title": "Comparison between Poissonian and Markovian Primary Traffics in\n  Cognitive Radio Networks", "comments": "IJCSI International Journal of Computer Science Issues, Vol. 9, Issue\n  2, No 3, March 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cognitive Radio generates a big interest as a key cost-effective solution for\nthe underutilization of frequency spectrum in legacy communication networks.\nThe objective of this work lies in conducting a performance evaluation of the\nend-to-end message delivery under both Markovian and Poissonian primary\ntraffics in lossy Cognitive Radio networks. We aim at inferring the most\nappropriate conditions for an efficient secondary service provision according\nto the Cognitive Radio network characteristics. Meanwhile, we have performed a\ngeneral analysis for many still open issues in Cognitive Radio, but at the end\nonly two critical aspects have been considered, namely, the unforeseen primary\nreclaims in addition to the collided cognitive transmissions due to the\nOpportunistic Spectrum Sharing. Some graphs, in view of the average Spectral\nEfficiency, have been computed and plotted to report some comparative results\nfor a given video transmission under the Markovian and the Poissonian primary\ninterruptions.\n", "versions": [{"version": "v1", "created": "Fri, 1 Jun 2012 09:42:18 GMT"}], "update_date": "2012-06-04", "authors_parsed": [["Chaoub", "Abdelaali", ""], ["Ibn-Elhaj", "Elhassane", ""]]}, {"id": "1206.0710", "submitter": "Marius Kwemou", "authors": "Marius Kwemou (SG, LERSTAD)", "title": "Non-asymptotic Oracle Inequalities for the Lasso and Group Lasso in high\n  dimensional logistic model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of estimating a function $f\\_{0}$ in logistic\nregression model. We propose to estimate this function $f\\_{0}$ by a sparse\napproximation build as a linear combination of elements of a given dictionary\nof $p$ functions. This sparse approximation is selected by the Lasso or Group\nLasso procedure. In this context, we state non asymptotic oracle inequalities\nfor Lasso and Group Lasso under restricted eigenvalues assumption as introduced\nin \\cite{BRT}.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jun 2012 19:22:49 GMT"}, {"version": "v2", "created": "Wed, 3 Oct 2012 12:12:08 GMT"}, {"version": "v3", "created": "Fri, 14 Dec 2012 20:14:54 GMT"}, {"version": "v4", "created": "Wed, 20 May 2015 14:19:54 GMT"}], "update_date": "2015-05-21", "authors_parsed": [["Kwemou", "Marius", "", "SG, LERSTAD"]]}, {"id": "1206.0889", "submitter": "Gilles Guillot", "authors": "Gilles Guillot", "title": "Detection of correlation between genotypes and environmental variables.\n  A fast computational approach for genomewide studies", "comments": "To appear in Spatial Statistics", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Genomic regions (or loci) displaying outstanding correlation with some\nenvironmental variables are likely to be under selection and this is the\nrationale of recent methods of identifying selected loci and retrieving\nfunctional information about them. To be efficient, such methods need to be\nable to disentangle the potential effect of environmental variables from the\nconfounding effect of population history. For the routine analysis of\ngenome-wide datasets, one also needs fast inference and model selection\nalgorithms. We propose a method based on an explicit spatial model which is an\ninstance of spatial generalized linear mixed model (SGLMM). For inference, we\nmake use of the INLA-SPDE theoretical and computational framework developed by\nRue et al. (2009) and Lindgren et al (2011). The method we propose allows one\nto quantify the correlation between genotypes and environmental variables. It\nworks for the most common types of genetic markers, obtained either at the\nindividual or at the population level. Analyzing simulated data produced under\na geostatistical model then under an explicit model of selection, we show that\nthe method is efficient. We also re-analyze a dataset relative to nineteen pine\nweevils (Hylobius abietis}) populations across Europe. The method proposed\nappears also as a statistically sound alternative to the Mantel tests for\ntesting the association between genetic and environmental variables.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jun 2012 11:55:13 GMT"}, {"version": "v2", "created": "Mon, 12 Aug 2013 08:11:53 GMT"}], "update_date": "2013-08-13", "authors_parsed": [["Guillot", "Gilles", ""]]}, {"id": "1206.1268", "submitter": "Hailiang Du", "authors": "Hailiang Du and Leonard A. Smith", "title": "Parameter Estimation Through Ignorance", "comments": "17 pages, 5 figures, Keywords: parameter estimation, Ignorance,\n  Implied Ignorance, Minimum Ignorance, nonlinear dynamical system, skill\n  score, dynamically consistent ensemble, model inadequacy, least squares,\n  information deficit, potential predictability, predictability", "journal-ref": null, "doi": "10.1103/PhysRevE.86.016213", "report-no": null, "categories": "physics.data-an math-ph math.MP stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamical modelling lies at the heart of our understanding of physical\nsystems. Its role in science is deeper than mere operational forecasting, in\nthat it allows us to evaluate the adequacy of the mathematical structure of our\nmodels. Despite the importance of model parameters, there is no general method\nof parameter estimation outside linear systems. A new relatively simple method\nof parameter estimation for nonlinear systems is presented, based on variations\nin the accuracy of probability forecasts. It is illustrated on the Logistic\nMap, the Henon Map and the 12-D Lorenz96 flow, and its ability to outperform\nlinear least squares in these systems is explored at various noise levels and\nsampling rates. As expected, it is more effective when the forecast error\ndistributions are non-Gaussian. The new method selects parameter values by\nminimizing a proper, local skill score for continuous probability forecasts as\na function of the parameter values. This new approach is easier to implement in\npractice than alternative nonlinear methods based on the geometry of attractors\nor the ability of the model to shadow the observations. New direct measures of\ninadequacy in the model, the \"Implied Ignorance\" and the information deficit\nare introduced.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jun 2012 16:23:45 GMT"}], "update_date": "2015-06-05", "authors_parsed": [["Du", "Hailiang", ""], ["Smith", "Leonard A.", ""]]}, {"id": "1206.1309", "submitter": "Massimiliano Vasile", "authors": "Federico Zuiani, Massimiliano Vasile, Alison Gibbings", "title": "Evidence-Based Robust Design of Deflection Actions for Near Earth\n  Objects", "comments": "Celestial Mechanics and Dynamical Astronomy, 2012", "journal-ref": null, "doi": "10.1007/s10569-012-9423-1", "report-no": null, "categories": "cs.CE cs.NE math.OC stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel approach to the robust design of deflection\nactions for Near Earth Objects (NEO). In particular, the case of deflection by\nmeans of Solar-pumped Laser ablation is studied here in detail. The basic idea\nbehind Laser ablation is that of inducing a sublimation of the NEO surface,\nwhich produces a low thrust thereby slowly deviating the asteroid from its\ninitial Earth threatening trajectory. This work investigates the integrated\ndesign of the Space-based Laser system and the deflection action generated by\nlaser ablation under uncertainty. The integrated design is formulated as a\nmulti-objective optimisation problem in which the deviation is maximised and\nthe total system mass is minimised. Both the model for the estimation of the\nthrust produced by surface laser ablation and the spacecraft system model are\nassumed to be affected by epistemic uncertainties (partial or complete lack of\nknowledge). Evidence Theory is used to quantify these uncertainties and\nintroduce them in the optimisation process. The propagation of the trajectory\nof the NEO under the laser-ablation action is performed with a novel approach\nbased on an approximated analytical solution of Gauss' Variational Equations.\nAn example of design of the deflection of asteroid Apophis with a swarm of\nspacecraft is presented.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jun 2012 19:31:17 GMT"}], "update_date": "2012-06-07", "authors_parsed": [["Zuiani", "Federico", ""], ["Vasile", "Massimiliano", ""], ["Gibbings", "Alison", ""]]}, {"id": "1206.1393", "submitter": "Tewfik Lounis", "authors": "Tewfik Lounis (LMNO)", "title": "Local asymptotically optimal test in ARCH model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work is an extension in Arch models of the theorem of S.Y. Hwang and\nI.V. Basawa Hwang and Basawa (2001) which was used before in nonlinear time\nseries contiguous to AR(1) processes. Our results are established under some\ngeneral assumptions and stationarity and ergodicity conditions. Local\nasymptotic normality (LAN) for the log likelihood ratio was established.An\noptimal test was constructed when the parameter is assumed known. Also the\noptimality of our test was proved when the parameter is unspecified. The method\nis based on the introducing of a new estimator.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jun 2012 04:32:13 GMT"}], "update_date": "2012-06-08", "authors_parsed": [["Lounis", "Tewfik", "", "LMNO"]]}, {"id": "1206.1493", "submitter": "Kashif Zaheer Bin", "authors": "Kashif Bin Zaheer, Waseem Ahmed Ansari and Syed Mohammad Murshid Raza", "title": "Effect of Solar-Terrestrial Phenomena on Solar Cell's Efficiency", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is assumed that the solar cell efficiency of PV device is closely related\nto the solar irradiance, considered the solar parameter Global Solar Irradiance\n(G) and the meteorological parameters like daily data of Earth Skin Temperature\n(E), Average Temperature (T), Relative Humidity (H) and Dew Frost Point (D),\nfor the coastal city Karachi and a non-coastal city Jacobabad, K and J is used\nas a subscripts for parameters of Karachi and Jacobabad respectively. All\nvariables used here are dependent on the location (latitude and longitude) of\nour stations except G. To employ ARIMA modeling, the first eighteen years data\nis used for modeling and forecast is done for the last five years data. In most\ncases results show good correlation among monthly actual and monthly forecasted\nvalues of all the predictors. Next, multiple linear regression is employed to\nthe data obtained by ARIMA modeling and models for mean monthly observed G\nvalues are constructed. For each station, two equations are constructed the R2\nvalues are above 93% for each model, showing adequacy of the fit. Our\ncomputations show that Solar cell efficiency can be increased if better\nmodeling for meteorological predictors governs the process.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jun 2012 13:47:03 GMT"}], "update_date": "2012-06-08", "authors_parsed": [["Zaheer", "Kashif Bin", ""], ["Ansari", "Waseem Ahmed", ""], ["Raza", "Syed Mohammad Murshid", ""]]}, {"id": "1206.1557", "submitter": "Jay Gholap", "authors": "Jay Gholap, Anurag Ingole, Jayesh Gohil, Shailesh Gargade and Vahida\n  Attar", "title": "Soil Data Analysis Using Classification Techniques and Soil Attribute\n  Prediction", "comments": "4 pages, published in International Journal of Computer Science\n  Issues, Volume 9, Issue 3", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Agricultural research has been profited by technical advances such as\nautomation, data mining. Today, data mining is used in a vast areas and many\noff-the-shelf data mining system products and domain specific data mining\napplication soft wares are available, but data mining in agricultural soil\ndatasets is a relatively a young research field. The large amounts of data that\nare nowadays virtually harvested along with the crops have to be analyzed and\nshould be used to their full extent. This research aims at analysis of soil\ndataset using data mining techniques. It focuses on classification of soil\nusing various algorithms available. Another important purpose is to predict\nuntested attributes using regression technique, and implementation of automated\nsoil sample classification.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jun 2012 17:28:20 GMT"}], "update_date": "2012-06-08", "authors_parsed": [["Gholap", "Jay", ""], ["Ingole", "Anurag", ""], ["Gohil", "Jayesh", ""], ["Gargade", "Shailesh", ""], ["Attar", "Vahida", ""]]}, {"id": "1206.1660", "submitter": "Cheng Wang", "authors": "Cheng Wang, Longbing Cao and Baiqi Miao", "title": "Optimal feature selection for sparse linear discriminant analysis and\n  its applications in gene expression data", "comments": "20 pages, 3 figures, 5 tables, accepted by Computational Statistics\n  and Data Analysis", "journal-ref": null, "doi": "10.1016/j.csda.2013.04.003", "report-no": null, "categories": "stat.ME stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work studies the theoretical rules of feature selection in linear\ndiscriminant analysis (LDA), and a new feature selection method is proposed for\nsparse linear discriminant analysis. An $l_1$ minimization method is used to\nselect the important features from which the LDA will be constructed. The\nasymptotic results of this proposed two-stage LDA (TLDA) are studied,\ndemonstrating that TLDA is an optimal classification rule whose convergence\nrate is the best compared to existing methods. The experiments on simulated and\nreal datasets are consistent with the theoretical results and show that TLDA\nperforms favorably in comparison with current methods. Overall, TLDA uses a\nlower minimum number of features or genes than other approaches to achieve a\nbetter result with a reduced misclassification rate.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jun 2012 04:47:48 GMT"}, {"version": "v2", "created": "Tue, 3 Jul 2012 05:40:05 GMT"}, {"version": "v3", "created": "Thu, 5 Jul 2012 05:08:53 GMT"}, {"version": "v4", "created": "Mon, 22 Apr 2013 12:06:53 GMT"}], "update_date": "2013-04-23", "authors_parsed": [["Wang", "Cheng", ""], ["Cao", "Longbing", ""], ["Miao", "Baiqi", ""]]}, {"id": "1206.1741", "submitter": "Lutz Bornmann Dr.", "authors": "Lutz Bornmann", "title": "How to analyse percentile impact data meaningfully in bibliometrics: The\n  statistical analysis of distributions, percentile rank classes and top-cited\n  papers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.DL physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  According to current research in bibliometrics, percentiles (or percentile\nrank classes) are the most suitable method for normalising the citation counts\nof individual publications in terms of the subject area, the document type and\nthe publication year. Up to now, bibliometric research has concerned itself\nprimarily with the calculation of percentiles. This study suggests how\npercentiles can be analysed meaningfully for an evaluation study. Publication\nsets from four universities are compared with each other to provide sample\ndata. These suggestions take into account on the one hand the distribution of\npercentiles over the publications in the sets (here: universities) and on the\nother hand concentrate on the range of publications with the highest citation\nimpact - that is, the range which is usually of most interest in the evaluation\nof scientific performance.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jun 2012 12:18:14 GMT"}], "update_date": "2012-06-11", "authors_parsed": [["Bornmann", "Lutz", ""]]}, {"id": "1206.1773", "submitter": "Jerome Bobin", "authors": "J. Bobin and J.-L. Starck and F. Sureau and S. Basak", "title": "Sparse component separation for accurate CMB map estimation", "comments": "submitted to A&A", "journal-ref": null, "doi": "10.1051/0004-6361/201219781", "report-no": null, "categories": "astro-ph.CO astro-ph.IM stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Cosmological Microwave Background (CMB) is of premier importance for the\ncosmologists to study the birth of our universe. Unfortunately, most CMB\nexperiments such as COBE, WMAP or Planck do not provide a direct measure of the\ncosmological signal; CMB is mixed up with galactic foregrounds and point\nsources. For the sake of scientific exploitation, measuring the CMB requires\nextracting several different astrophysical components (CMB, Sunyaev-Zel'dovich\nclusters, galactic dust) form multi-wavelength observations. Mathematically\nspeaking, the problem of disentangling the CMB map from the galactic\nforegrounds amounts to a component or source separation problem. In the field\nof CMB studies, a very large range of source separation methods have been\napplied which all differ from each other in the way they model the data and the\ncriteria they rely on to separate components. Two main difficulties are i) the\ninstrument's beam varies across frequencies and ii) the emission laws of most\nastrophysical components vary across pixels. This paper aims at introducing a\nvery accurate modeling of CMB data, based on sparsity, accounting for beams\nvariability across frequencies as well as spatial variations of the components'\nspectral characteristics. Based on this new sparse modeling of the data, a\nsparsity-based component separation method coined Local-Generalized\nMorphological Component Analysis (L-GMCA) is described. Extensive numerical\nexperiments have been carried out with simulated Planck data. These experiments\nshow the high efficiency of the proposed component separation methods to\nestimate a clean CMB map with a very low foreground contamination, which makes\nL-GMCA of prime interest for CMB studies.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jun 2012 14:20:45 GMT"}], "update_date": "2015-06-05", "authors_parsed": [["Bobin", "J.", ""], ["Starck", "J. -L.", ""], ["Sureau", "F.", ""], ["Basak", "S.", ""]]}, {"id": "1206.1818", "submitter": "Larry Tang", "authors": "Liansheng Larry Tang, Aiyi Liu, Zhen Chen, Enrique F. Schisterman, Bo\n  Zhang, and Zhuang Miao", "title": "Nonparametric ROC Summary Statistics for Correlated Diagnostic Marker\n  Data", "comments": "13 pages, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose efficient nonparametric statistics to compare medical imaging\nmodalities in multi-reader multi-test data and to compare markers in\nlongitudinal ROC data. The proposed methods are based on the weighted area\nunder the ROC curve which includes the area under the curve and the partial\narea under the curve as special cases. The methods maximize the local power for\ndetecting the difference between imaging modalities. The asymptotic results of\nthe proposed methods are developed under a complex correlation structure. Our\nsimulation studies show that the proposed statistics result in much better\npowers than existing statistics. We applied the proposed statistics to an\nendometriosis diagnosis study.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jun 2012 16:54:20 GMT"}], "update_date": "2012-06-11", "authors_parsed": [["Tang", "Liansheng Larry", ""], ["Liu", "Aiyi", ""], ["Chen", "Zhen", ""], ["Schisterman", "Enrique F.", ""], ["Zhang", "Bo", ""], ["Miao", "Zhuang", ""]]}, {"id": "1206.1850", "submitter": "Elvan Ceyhan", "authors": "Elvan Ceyhan", "title": "New Cell-Specific and Overall Tests of Spatial Interaction Based on\n  Nearest Neighbor Contingency Tables", "comments": "39 pages, 25 Figures, 5 Tables. arXiv admin note: substantial text\n  overlap with arXiv:0805.1629", "journal-ref": null, "doi": null, "report-no": "KU-EC-13-1", "categories": "stat.ME stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spatial interaction patterns such as segregation and association can be\ntested using nearest neighbor contingency tables (NNCTs). We introduce new\ncell-specific (or pairwise) and overall segregation tests and determine their\nasymptotic distributions. In particular, we demonstrate that cell-specific\ntests enjoy asymptotic normality, while overall tests have chi-square\ndistributions asymptotically. We also perform an extensive Monte Carlo\nsimulation study to compare the finite sample performance of the tests in terms\nof empirical size and power. In addition to the cell-specific tests as post-hoc\ntests for overall tests, we discuss one-class-versus-rest type of NNCT-tests\nafter an overall test yields significant interaction. We also introduce the\nconcepts of total, strong, and partial segregation/association to label levels\nof these patterns. We compare these new tests with the existing NNCT-tests in\nliterature with simulations as well and illustrate the NNCT-tests on an\necological data set.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jun 2012 19:53:27 GMT"}, {"version": "v2", "created": "Thu, 5 Dec 2013 03:02:38 GMT"}], "update_date": "2013-12-06", "authors_parsed": [["Ceyhan", "Elvan", ""]]}, {"id": "1206.1874", "submitter": "Bin Dai", "authors": "Bin Dai, Shilin Ding, Grace Wahba", "title": "Multivariate Bernoulli distribution", "comments": "Published in at http://dx.doi.org/10.3150/12-BEJSP10 the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2013, Vol. 19, No. 4, 1465-1483", "doi": "10.3150/12-BEJSP10", "report-no": "IMS-BEJ-BEJSP10", "categories": "stat.AP math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the multivariate Bernoulli distribution as a model\nto estimate the structure of graphs with binary nodes. This distribution is\ndiscussed in the framework of the exponential family, and its statistical\nproperties regarding independence of the nodes are demonstrated. Importantly\nthe model can estimate not only the main effects and pairwise interactions\namong the nodes but also is capable of modeling higher order interactions,\nallowing for the existence of complex clique effects. We compare the\nmultivariate Bernoulli model with existing graphical inference models - the\nIsing model and the multivariate Gaussian model, where only the pairwise\ninteractions are considered. On the other hand, the multivariate Bernoulli\ndistribution has an interesting property in that independence and\nuncorrelatedness of the component random variables are equivalent. Both the\nmarginal and conditional distributions of a subset of variables in the\nmultivariate Bernoulli distribution still follow the multivariate Bernoulli\ndistribution. Furthermore, the multivariate Bernoulli logistic model is\ndeveloped under generalized linear model theory by utilizing the canonical link\nfunction in order to include covariate information on the nodes, edges and\ncliques. We also consider variable selection techniques such as LASSO in the\nlogistic model to impose sparsity structure on the graph. Finally, we discuss\nextending the smoothing spline ANOVA approach to the multivariate Bernoulli\nlogistic model to enable estimation of non-linear effects of the predictor\nvariables.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jun 2012 20:49:42 GMT"}, {"version": "v2", "created": "Tue, 12 Nov 2013 11:03:31 GMT"}], "update_date": "2013-11-13", "authors_parsed": [["Dai", "Bin", ""], ["Ding", "Shilin", ""], ["Wahba", "Grace", ""]]}, {"id": "1206.1955", "submitter": "Sofia Olhede Professor", "authors": "Sofia C. Olhede and Hernando Ombao", "title": "Covariance of Replicated Modulated Cyclical Time Series", "comments": "25 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces the novel class of modulated cyclostationary processes,\na class of non-stationary processes exhibiting frequency coupling, and proposes\na method of their estimation from repeated trials. Cyclostationary processes\nalso exhibit frequency correlation but have Loeve spectra whose support lies\nonly on parallel lines in the dual-frequency plane. Such extremely sparse\nstructure does not adequately represent many biological processes. Thus, we\npropose a model that, in the time domain, modulates the covariance of\ncyclostationary processes and consequently broadens their frequency support in\nthe dual-frequency plane. The spectra and the cross-coherence of the proposed\nmodulated cyclostationary process are first estimated using multitaper methods.\nA shrinkage procedure is then applied to each trial-specific estimate to reduce\nthe estimation risk.\n  Multiple trials of each series are observed. When combining information\nacross trials, we carefully take into account the bias that may be introduced\nby phase misalignment and the fact that the Loeve spectra and cross-coherence\nacross replicates may only be \"similar\" - but not necessarily identical -\nacross replicates. The application of the inference methods developed for the\nmodulated cyclostationary model to EEG data also demonstrates that the proposed\nmodel captures statistically significant cross-frequency interactions, that\nought to be further examined by neuroscientists.\n", "versions": [{"version": "v1", "created": "Sat, 9 Jun 2012 16:42:57 GMT"}, {"version": "v2", "created": "Wed, 24 Oct 2012 13:01:44 GMT"}], "update_date": "2012-10-25", "authors_parsed": [["Olhede", "Sofia C.", ""], ["Ombao", "Hernando", ""]]}, {"id": "1206.2425", "submitter": "Alessandro Sarnaglia M.Sc.", "authors": "V. A. Reisen, A. J. Q Sarnaglia, N. C. Reis Jr, C. L\\'evy-Leduc, J. M.\n  Santos", "title": "Modeling and forecasting daily average PM$_{10}$ concentrations by a\n  seasonal ARFIMA model with volatility", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the possibility that the daily average Particulate\nMatter (PM$_{10}$) concentration is a seasonal fractionally integrated process\nwith time-dependent variance (volatility). In this context, one convenient\nextension is to consider the SARFIMA model (Reisen, et al, 2006a,b) with GARCH\ntype innovations. The model is theoretically justified and its usefulness is\ncorroborated with the application to PM$_{10}$ concentration in the city of\nCariacica-ES (Brazil). The model adjusted was able to capture the dynamics in\nthe series. The out-of-sample forecast intervals were improved by considering\nheteroscedastic errors and they were able to identify the periods of more\nvolatility.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jun 2012 02:40:57 GMT"}], "update_date": "2012-06-13", "authors_parsed": [["Reisen", "V. A.", ""], ["Sarnaglia", "A. J. Q", ""], ["Reis", "N. C.", "Jr"], ["L\u00e9vy-Leduc", "C.", ""], ["Santos", "J. M.", ""]]}, {"id": "1206.2662", "submitter": "Godfrey Charles-Cadogan", "authors": "Godfrey Charles-Cadogan", "title": "Alpha Representation For Active Portfolio Management and High Frequency\n  Trading In Seemingly Efficient Markets", "comments": "15 pages, 0 figures", "journal-ref": "In Proceedings of Joint Statistical Meeting (JSM), Business and\n  Economic Statistics Section, Alexandria, VA: American Statistical\n  Association. 673-687, 2011", "doi": null, "report-no": null, "categories": "q-fin.RM math.PR math.ST q-fin.PM stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a trade strategy representation theorem for performance\nmeasurement and portable alpha in high frequency trading, by embedding a robust\ntrading algorithm that describe portfolio manager market timing behavior, in a\ncanonical multifactor asset pricing model. First, we present a spectral test\nfor market timing based on behavioral transformation of the hedge factors\ndesign matrix. Second, we find that the typical trade strategy process is a\nlocal martingale with a background driving Brownian bridge that mimics\nportfolio manager price reversal strategies. Third, we show that equilibrium\nasset pricing models like the CAPM exists on a set with P-measure zero. So that\nexcess returns, i.e. positive alpha, relative to a benchmark index is robust to\nno arbitrage pricing in turbulent capital markets. Fourth, the path properties\nof alpha are such that it is positive between suitably chosen stopping times\nfor trading. Fifth, we demonstrate how, and why, econometric tests of portfolio\nperformance tend to under report positive alpha.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jun 2012 20:27:14 GMT"}], "update_date": "2012-06-21", "authors_parsed": [["Charles-Cadogan", "Godfrey", ""]]}, {"id": "1206.2683", "submitter": "Mark Schilling", "authors": "Michael Neubauer, Mark Schilling, Joel Zeitlin", "title": "Exploring Unpopular Presidential Elections", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There have been several instances in our nation's history in which the\npresidential candidate who received the most popular votes did not win the\npresidency. Using a principal components analysis of recent presidential\nelections, we estimate the likelihood of such an outcome under modern\nconditions to be approximately 5%. We also investigate the effect on this\nestimate of eliminating from the Electoral College the two electors per state\nawarded due to their representation in the Senate, as well as the effect of\nincreasing them. We conclude with an analysis of the likely consequences of The\nNational Popular Vote Bill, which would award the presidency to the candidate\nwith the largest national popular vote total if it took effect.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jun 2012 22:22:54 GMT"}], "update_date": "2012-06-14", "authors_parsed": [["Neubauer", "Michael", ""], ["Schilling", "Mark", ""], ["Zeitlin", "Joel", ""]]}, {"id": "1206.2700", "submitter": "Judson Locke", "authors": "Judson B. Locke and Adrian M. Peter", "title": "Multiwavelet density estimation", "comments": "Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate density estimation methodologies play an integral role in a variety\nof scientific disciplines, with applications including simulation models,\ndecision support tools, and exploratory data analysis. In the past, histograms\nand kernel density estimators have been the predominant tools of choice,\nprimarily due to their ease of use and mathematical simplicity. More recently,\nthe use of wavelets for density estimation has gained in popularity due to\ntheir ability to approximate a large class of functions, including those with\nlocalized, abrupt variations. However, a well-known attribute of wavelet bases\nis that they can not be simultaneously symmetric, orthogonal, and compactly\nsupported. Multiwavelets-a more general, vector-valued, construction of\nwavelets-overcome this disadvantage, making them natural choices for estimating\ndensity functions, many of which exhibit local symmetries around features such\nas a mode. We extend the methodology of wavelet density estimation to use\nmultiwavelet bases and illustrate several empirical results where multiwavelet\nestimators outperform their wavelet counterparts at coarser resolution levels.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2012 02:08:12 GMT"}], "update_date": "2012-06-14", "authors_parsed": [["Locke", "Judson B.", ""], ["Peter", "Adrian M.", ""]]}, {"id": "1206.2742", "submitter": "Finn {\\AA}rup Nielsen", "authors": "Finn {\\AA}rup Nielsen, Matthew J. Kempton, Steven C. R. Williams", "title": "Online open neuroimaging mass meta-analysis", "comments": "5 pages, 4 figures SePublica 2012, ESWC 2012 Workshop, 28 May 2012,\n  Heraklion, Greece", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.AI stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a system for meta-analysis where a wiki stores numerical data in\na simple format and a web service performs the numerical computation.\n  We initially apply the system on multiple meta-analyses of structural\nneuroimaging data results. The described system allows for mass meta-analysis,\ne.g., meta-analysis across multiple brain regions and multiple mental\ndisorders.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2012 08:23:42 GMT"}], "update_date": "2012-06-14", "authors_parsed": [["Nielsen", "Finn \u00c5rup", ""], ["Kempton", "Matthew J.", ""], ["Williams", "Steven C. R.", ""]]}, {"id": "1206.2966", "submitter": "Ivan Fernandez-Val", "authors": "Ivan Fernandez-Val and Joonhwah Lee", "title": "Panel Data Models with Nonadditive Unobserved Heterogeneity: Estimation\n  and Inference", "comments": "51 pages, 4 tables, 1 figure, it includes supplementary appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME econ.EM math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers fixed effects estimation and inference in linear and\nnonlinear panel data models with random coefficients and endogenous regressors.\nThe quantities of interest -- means, variances, and other moments of the random\ncoefficients -- are estimated by cross sectional sample moments of GMM\nestimators applied separately to the time series of each individual. To deal\nwith the incidental parameter problem introduced by the noise of the\nwithin-individual estimators in short panels, we develop bias corrections.\nThese corrections are based on higher-order asymptotic expansions of the GMM\nestimators and produce improved point and interval estimates in moderately long\npanels. Under asymptotic sequences where the cross sectional and time series\ndimensions of the panel pass to infinity at the same rate, the uncorrected\nestimator has an asymptotic bias of the same order as the asymptotic variance.\nThe bias corrections remove the bias without increasing variance. An empirical\nexample on cigarette demand based on Becker, Grossman and Murphy (1994) shows\nsignificant heterogeneity in the price effect across U.S. states.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2012 23:10:58 GMT"}, {"version": "v2", "created": "Fri, 11 Oct 2013 22:03:17 GMT"}], "update_date": "2018-01-16", "authors_parsed": [["Fernandez-Val", "Ivan", ""], ["Lee", "Joonhwah", ""]]}, {"id": "1206.3239", "submitter": "Zhihong Cai", "authors": "Zhihong Cai, Manabu Kuroki", "title": "On Identifying Total Effects in the Presence of Latent Variables and\n  Selection bias", "comments": "Appears in Proceedings of the Twenty-Fourth Conference on Uncertainty\n  in Artificial Intelligence (UAI2008)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2008-PG-62-69", "categories": "stat.ME cs.AI stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Assume that cause-effect relationships between variables can be described as\na directed acyclic graph and the corresponding linear structural equation\nmodel.We consider the identification problem of total effects in the presence\nof latent variables and selection bias between a treatment variable and a\nresponse variable. Pearl and his colleagues provided the back door criterion,\nthe front door criterion (Pearl, 2000) and the conditional instrumental\nvariable method (Brito and Pearl, 2002) as identifiability criteria for total\neffects in the presence of latent variables, but not in the presence of\nselection bias. In order to solve this problem, we propose new graphical\nidentifiability criteria for total effects based on the identifiable factor\nmodels. The results of this paper are useful to identify total effects in\nobservational studies and provide a new viewpoint to the identification\nconditions of factor models.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2012 14:59:34 GMT"}], "update_date": "2012-06-18", "authors_parsed": [["Cai", "Zhihong", ""], ["Kuroki", "Manabu", ""]]}, {"id": "1206.3280", "submitter": "Aleksandr Simma", "authors": "Aleksandr Simma, Moises Goldszmidt, John MacCormick, Paul Barham,\n  Richard Black, Rebecca Isaacs, Richard Mortier", "title": "CT-NOR: Representing and Reasoning About Events in Continuous Time", "comments": "Appears in Proceedings of the Twenty-Fourth Conference on Uncertainty\n  in Artificial Intelligence (UAI2008)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2008-PG-484-493", "categories": "cs.AI stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a generative model for representing and reasoning about the\nrelationships among events in continuous time. We apply the model to the domain\nof networked and distributed computing environments where we fit the parameters\nof the model from timestamp observations, and then use hypothesis testing to\ndiscover dependencies between the events and changes in behavior for monitoring\nand diagnosis. After introducing the model, we present an EM algorithm for\nfitting the parameters and then present the hypothesis testing approach for\nboth dependence discovery and change-point detection. We validate the approach\nfor both tasks using real data from a trace of network events at Microsoft\nResearch Cambridge. Finally, we formalize the relationship between the proposed\nmodel and the noisy-or gate for cases when time can be discretized.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2012 15:43:08 GMT"}], "update_date": "2012-06-18", "authors_parsed": [["Simma", "Aleksandr", ""], ["Goldszmidt", "Moises", ""], ["MacCormick", "John", ""], ["Barham", "Paul", ""], ["Black", "Richard", ""], ["Isaacs", "Rebecca", ""], ["Mortier", "Richard", ""]]}, {"id": "1206.3377", "submitter": "Zhijian Wang Dr.", "authors": "Bin Xu, Zhijian Wang", "title": "Maxent in Experimental 2$\\times$2 Population Games", "comments": "16 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP nlin.AO nlin.CD physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In mixed strategy 2\\times2 population games, the realization of maximum\nentropy (Maxent) is of the theoretical expectation. We evaluate this\ntheoretical prediction in the experimental economics game data. The data\nincludes 12 treatments and 108 experimental sessions in which the random match\nhuman subjects pairs make simultaneous strategy moves repeated 200 rounds. Main\nresults are (1) We confirm that experimental entropy value fit the prediction\nfrom Maxent well; and (2) In small proportion samples, distributions are\ndeviated from Maxent expectations; interesting is that, the deviated patterns\nare significant more concentrated. These experimental findings could enhance\nthe understanding of social game behavior with the natural science rule ---\nMaxent.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jun 2012 06:30:31 GMT"}], "update_date": "2012-06-18", "authors_parsed": [["Xu", "Bin", ""], ["Wang", "Zhijian", ""]]}, {"id": "1206.3493", "submitter": "Zhilin Zhang", "authors": "Zhilin Zhang, Tzyy-Ping Jung, Scott Makeig, Bhaskar D. Rao", "title": "Compressed Sensing of EEG for Wireless Telemonitoring with Low Energy\n  Consumption and Inexpensive Hardware", "comments": "Matlab codes can be downloaded at:\n  http://dsp.ucsd.edu/~zhilin/BSBL.html, or\n  http://sites.google.com/site/researchbyzhang/bsbl", "journal-ref": null, "doi": "10.1109/TBME.2012.2217959", "report-no": null, "categories": "stat.AP cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Telemonitoring of electroencephalogram (EEG) through wireless body-area\nnetworks is an evolving direction in personalized medicine. Among various\nconstraints in designing such a system, three important constraints are energy\nconsumption, data compression, and device cost. Conventional data compression\nmethodologies, although effective in data compression, consumes significant\nenergy and cannot reduce device cost. Compressed sensing (CS), as an emerging\ndata compression methodology, is promising in catering to these constraints.\nHowever, EEG is non-sparse in the time domain and also non-sparse in\ntransformed domains (such as the wavelet domain). Therefore, it is extremely\ndifficult for current CS algorithms to recover EEG with the quality that\nsatisfies the requirements of clinical diagnosis and engineering applications.\nRecently, Block Sparse Bayesian Learning (BSBL) was proposed as a new method to\nthe CS problem. This study introduces the technique to the telemonitoring of\nEEG. Experimental results show that its recovery quality is better than\nstate-of-the-art CS algorithms, and sufficient for practical use. These results\nsuggest that BSBL is very promising for telemonitoring of EEG and other\nnon-sparse physiological signals.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2012 19:47:23 GMT"}, {"version": "v2", "created": "Wed, 5 Sep 2012 12:42:26 GMT"}, {"version": "v3", "created": "Sun, 2 Nov 2014 05:40:56 GMT"}], "update_date": "2014-11-04", "authors_parsed": [["Zhang", "Zhilin", ""], ["Jung", "Tzyy-Ping", ""], ["Makeig", "Scott", ""], ["Rao", "Bhaskar D.", ""]]}, {"id": "1206.3540", "submitter": "Kunlaya Soiaporn", "authors": "Kunlaya Soiaporn, David Chernoff, Thomas Loredo, David Ruppert, Ira\n  Wasserman", "title": "Guilt by Association: Finding Cosmic Ray Sources Using Hierarchical\n  Bayesian Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.HE astro-ph.IM stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Earth is continuously showered by charged cosmic ray particles, naturally\nproduced atomic nuclei moving with velocity close to the speed of light. Among\nthese are ultra high energy cosmic ray particles with energy exceeding 5x10^19\neV, which is ten million times more energetic than the most energetic particles\nproduced at the Large Hadron Collider. Astrophysical questions include: what\nphenomenon accelerates particles to such high energies, and what sort of nuclei\nare energized? Also, the magnetic deflection of the trajectories of the cosmic\nrays makes them potential probes of galactic and intergalactic magnetic fields.\nWe develop a Bayesian hierarchical model that can be used to compare different\nassociation models between the cosmic rays and source population, using Bayes\nfactors. A measurement model with directional uncertainties and accounting for\nnon-uniform sky exposure is incoporated into the model. The methodology allows\nus to learn about astrophysical parameters, such as those governing the source\nluminosity function and the cosmic magnetic field.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jun 2012 18:44:40 GMT"}], "update_date": "2012-06-18", "authors_parsed": [["Soiaporn", "Kunlaya", ""], ["Chernoff", "David", ""], ["Loredo", "Thomas", ""], ["Ruppert", "David", ""], ["Wasserman", "Ira", ""]]}, {"id": "1206.3601", "submitter": "Larry Tang", "authors": "Ting Dong, Liansheng Larry Tang, William F. Rosenberger", "title": "Optimal sampling ratios in comparative diagnostic trials", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we focus on comparative diagnostic trials which are frequently\nemployed to compare two markers with continuous or ordinal results. We derive\nexplicit expressions for the optimal sampling ratio based on a common variance\nstructure shared by existing summary statistics of the receiver operating\ncharacteristic (ROC) curve. Estimating the optimal ratio requires either pilot\ndata or parametric model assumptions; however, pilot data are often unavailable\nat the planning stage of diagnostic trials. In the absence of pilot data, some\ndistributions have to be assumed for carrying out the calculation. An optimal\nratio from an incorrect distributional assumption may lead to an underpowered\nstudy. We propose a two-stage procedure to adaptively estimate the optimal\nratio in comparative diagnostic trials without pilot data or assuming\nparametric distributions. We illustrate the properties of the proposed method\nthrough theoretical proofs and extensive simulation studies. We use an example\nin cancer diagnostic studies to illustrate the application of our method. We\nfind that our method increases the power, or reduces the required overall\nsample size dramatically.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jun 2012 21:16:58 GMT"}], "update_date": "2012-06-19", "authors_parsed": [["Dong", "Ting", ""], ["Tang", "Liansheng Larry", ""], ["Rosenberger", "William F.", ""]]}, {"id": "1206.3720", "submitter": "Daniel Klein", "authors": "Anna Bershteyn, Daniel J. Klein, Edward Wenger, Philip A. Eckhoff", "title": "Description of the EMOD-HIV Model v0.7", "comments": "16 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM q-bio.PE stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The expansion of tools against HIV transmission has brought increased\ninterest in epidemiological models that can predict the impact of these\ninterventions. The EMOD-HIV model was recently compared to eleven other\nindependently developed mathematical models of HIV transmission to determine\nthe extent to which they agree about the potential impact of expanded use of\nantiretroviral therapy in South Africa. Here we describe in detail the modeling\nmethodology used to produce the results in this comparison, which we term\nEMOD-HIV v0.7. We include a discussion of the structure and a full list of\nmodel parameters. We also discuss the architecture of the model, and its\npotential utility in comparing structural assumptions within a single modeling\nframework.\n", "versions": [{"version": "v1", "created": "Sun, 17 Jun 2012 03:36:48 GMT"}], "update_date": "2012-06-19", "authors_parsed": [["Bershteyn", "Anna", ""], ["Klein", "Daniel J.", ""], ["Wenger", "Edward", ""], ["Eckhoff", "Philip A.", ""]]}, {"id": "1206.3776", "submitter": "Matt Taddy", "authors": "Matt Taddy", "title": "Measuring political sentiment on Twitter: factor-optimal design for\n  multinomial inverse regression", "comments": "To appear in Technometrics. Code is available in the textir package\n  for R", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article presents a short case study in text analysis: the scoring of\nTwitter posts for positive, negative, or neutral sentiment directed towards\nparticular US politicians. The study requires selection of a sub-sample of\nrepresentative posts for sentiment scoring, a common and costly aspect of\nsentiment mining. As a general contribution, our application is preceded by a\nproposed algorithm for maximizing sampling efficiency. In particular, we\noutline and illustrate greedy selection of documents to build designs that are\nD-optimal in a topic-factor decomposition of the original text. The strategy is\napplied to our motivating dataset of political posts, and we outline a new\ntechnique for predicting both generic and subject-specific document sentiment\nthrough use of variable interactions in multinomial inverse regression. Results\nare presented for analysis of 2.1 million Twitter posts around February 2012.\n", "versions": [{"version": "v1", "created": "Sun, 17 Jun 2012 17:58:07 GMT"}, {"version": "v2", "created": "Thu, 4 Oct 2012 15:43:40 GMT"}, {"version": "v3", "created": "Tue, 15 Jan 2013 16:20:16 GMT"}, {"version": "v4", "created": "Fri, 25 Jan 2013 21:44:34 GMT"}, {"version": "v5", "created": "Sat, 2 Mar 2013 00:05:48 GMT"}], "update_date": "2013-03-05", "authors_parsed": [["Taddy", "Matt", ""]]}, {"id": "1206.3833", "submitter": "Sam Clifford", "authors": "Sam Clifford, Sama Low Choy, Mandana Mazaheri, Farhad Salimi, Lidia\n  Morawska and Kerrie Mengsersen", "title": "A Bayesian spatio-temporal model of panel design data: airborne particle\n  number concentration in Brisbane, Australia", "comments": "Draft of this paper presented at ISBA 2012 as poster, part of UPTECH\n  project", "journal-ref": null, "doi": "10.1002/env.2597", "report-no": null, "categories": "stat.AP physics.ao-ph physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper outlines a methodology for semi-parametric spatio-temporal\nmodelling of data which is dense in time but sparse in space, obtained from a\nsplit panel design, the most feasible approach to covering space and time with\nlimited equipment. The data are hourly averaged particle number concentration\n(PNC) and were collected, as part of the Ultrafine Particles from Transport\nEmissions and Child Health (UPTECH) project. Two weeks of continuous\nmeasurements were taken at each of a number of government primary schools in\nthe Brisbane Metropolitan Area. The monitoring equipment was taken to each\nschool sequentially. The school data are augmented by data from long term\nmonitoring stations at three locations in Brisbane, Australia.\n  Fitting the model helps describe the spatial and temporal variability at a\nsubset of the UPTECH schools and the long-term monitoring sites. The temporal\nvariation is modelled hierarchically with penalised random walk terms, one\ncommon to all sites and a term accounting for the remaining temporal trend at\neach site. Parameter estimates and their uncertainty are computed in a\ncomputationally efficient approximate Bayesian inference environment, R-INLA.\n  The temporal part of the model explains daily and weekly cycles in PNC at the\nschools, which can be used to estimate the exposure of school children to\nultrafine particles (UFPs) emitted by vehicles. At each school and long-term\nmonitoring site, peaks in PNC can be attributed to the morning and afternoon\nrush hour traffic and new particle formation events. The spatial component of\nthe model describes the school to school variation in mean PNC at each school\nand within each school ground. It is shown how the spatial model can be\nexpanded to identify spatial patterns at the city scale with the inclusion of\nmore spatial locations.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jun 2012 06:03:27 GMT"}, {"version": "v2", "created": "Wed, 6 Feb 2013 23:54:24 GMT"}], "update_date": "2019-08-09", "authors_parsed": [["Clifford", "Sam", ""], ["Choy", "Sama Low", ""], ["Mazaheri", "Mandana", ""], ["Salimi", "Farhad", ""], ["Morawska", "Lidia", ""], ["Mengsersen", "Kerrie", ""]]}, {"id": "1206.3963", "submitter": "Jaroslav Hlinka", "authors": "Jaroslav Hlinka, David Hartman and Milan Palu\\v{s}", "title": "Small-world topology of functional connectivity in randomly connected\n  dynamical systems", "comments": "The following article has been submitted to Chaos: An\n  interdisciplinary journal of nonlinear science. After it is published, it\n  will be found at http://chaos.aip.org/", "journal-ref": "Chaos, (2012), vol. 22, no. 3, pp. 033107", "doi": "10.1063/1.4732541", "report-no": null, "categories": "cs.SI physics.data-an physics.soc-ph q-bio.NC stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Characterization of real-world complex systems increasingly involves the\nstudy of their topological structure using graph theory. Among global network\nproperties, small-world property, consisting in existence of relatively short\npaths together with high clustering of the network, is one of the most\ndiscussed and studied. When dealing with coupled dynamical systems, links among\nunits of the system are commonly quantified by a measure of pairwise\nstatistical dependence of observed time series (functional connectivity). We\nargue that the functional connectivity approach leads to upwardly biased\nestimates of small-world characteristics (with respect to commonly used random\ngraph models) due to partial transitivity of the accepted functional\nconnectivity measures such as the correlation coefficient. In particular, this\nmay lead to observation of small-world characteristics in connectivity graphs\nestimated from generic randomly connected dynamical systems. The ubiquity and\nrobustness of the phenomenon is documented by an extensive parameter study of\nits manifestation in a multivariate linear autoregressive process, with\ndiscussion of the potential relevance for nonlinear processes and measures.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jun 2012 15:23:37 GMT"}], "update_date": "2017-02-28", "authors_parsed": [["Hlinka", "Jaroslav", ""], ["Hartman", "David", ""], ["Palu\u0161", "Milan", ""]]}, {"id": "1206.4032", "submitter": "Madalin Guta", "authors": "Madalin Guta, Theodore Kypraios and Ian Dryden", "title": "Rank-based model selection for multiple ions quantum tomography", "comments": "24 pages, 6 figures, 3 tables", "journal-ref": "New J. Phys. (14) 105002, 2012", "doi": "10.1088/1367-2630/14/10/105002", "report-no": null, "categories": "quant-ph stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The statistical analysis of measurement data has become a key component of\nmany quantum engineering experiments. As standard full state tomography becomes\nunfeasible for large dimensional quantum systems, one needs to exploit prior\ninformation and the \"sparsity\" properties of the experimental state in order to\nreduce the dimensionality of the estimation problem. In this paper we propose\nmodel selection as a general principle for finding the simplest, or most\nparsimonious explanation of the data, by fitting different models and choosing\nthe estimator with the best trade-off between likelihood fit and model\ncomplexity. We apply two well established model selection methods -- the Akaike\ninformation criterion (AIC) and the Bayesian information criterion (BIC) -- to\nmodels consising of states of fixed rank and datasets such as are currently\nproduced in multiple ions experiments. We test the performance of AIC and BIC\non randomly chosen low rank states of 4 ions, and study the dependence of the\nselected rank with the number of measurement repetitions for one ion states. We\nthen apply the methods to real data from a 4 ions experiment aimed at creating\na Smolin state of rank 4. The two methods indicate that the optimal model for\ndescribing the data lies between ranks 6 and 9, and the Pearson $\\chi^{2}$ test\nis applied to validate this conclusion. Additionally we find that the mean\nsquare error of the maximum likelihood estimator for pure states is close to\nthat of the optimal over all possible measurements.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jun 2012 19:41:44 GMT"}], "update_date": "2012-11-27", "authors_parsed": [["Guta", "Madalin", ""], ["Kypraios", "Theodore", ""], ["Dryden", "Ian", ""]]}, {"id": "1206.4189", "submitter": "Yuan-chin Chang yc.ivan.chang", "authors": "Yuan-chin Ivan Chang", "title": "Sequential Estimation in Item Calibration with A Two-Stage Design", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we apply a two-stage sequential design to item calibration\nproblems under a three-parameter logistic model assumption. The measurement\nerrors of the estimates of the latent trait levels of examinees are considered\nin our procedure. Moreover, a sequential procedure is employed to guarantee\nthat the estimates of the parameters reach a prescribed accuracy criterion when\nthe iteration is stopped, which fully takes the advantage of sequential design.\nStatistical properties of both the item parameter estimates and the sequential\nprocedure are discussed. We compare the performance of the proposed method with\nthat of the procedures based on some conventional designs using numerical\nstudies.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jun 2012 12:17:07 GMT"}, {"version": "v2", "created": "Tue, 21 May 2013 23:36:12 GMT"}], "update_date": "2013-05-23", "authors_parsed": [["Chang", "Yuan-chin Ivan", ""]]}, {"id": "1206.4221", "submitter": "Nikolas Kantas", "authors": "Nikolas Kantas, Sumeetpal S. Singh and Arnaud Doucet", "title": "Distributed Maximum Likelihood for Simultaneous Self-localization and\n  Tracking in Sensor Networks", "comments": "shorter version is about to appear in IEEE Transactions of Signal\n  Processing; 22 pages, 15 figures", "journal-ref": null, "doi": "10.1109/TSP.2012.2205923", "report-no": null, "categories": "math.OC cs.DC cs.SY stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the sensor self-localization problem can be cast as a static\nparameter estimation problem for Hidden Markov Models and we implement fully\ndecentralized versions of the Recursive Maximum Likelihood and on-line\nExpectation-Maximization algorithms to localize the sensor network\nsimultaneously with target tracking. For linear Gaussian models, our algorithms\ncan be implemented exactly using a distributed version of the Kalman filter and\na novel message passing algorithm. The latter allows each node to compute the\nlocal derivatives of the likelihood or the sufficient statistics needed for\nExpectation-Maximization. In the non-linear case, a solution based on local\nlinearization in the spirit of the Extended Kalman Filter is proposed. In\nnumerical examples we demonstrate that the developed algorithms are able to\nlearn the localization parameters.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jun 2012 14:28:50 GMT"}], "update_date": "2015-06-05", "authors_parsed": [["Kantas", "Nikolas", ""], ["Singh", "Sumeetpal S.", ""], ["Doucet", "Arnaud", ""]]}, {"id": "1206.4278", "submitter": "Thomas Loredo", "authors": "Thomas J. Loredo", "title": "Commentary on Bayesian coincidence assessment (cross-matching)", "comments": "6 pp, no figures. To appear in \"Statistical Challenges in Modern\n  Astronomy V,\" (Lecture Notes in Statistics, Vol. 209), ed. Eric D. Feigelson\n  and G. Jogesh Babu; publication planned for July 2012; see\n  http://www.springer.com/statistics/book/978-1-4614-3519-8", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.IM stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is an invited commentary on Tamas Budavari's presentation, \"On\nstatistical cross-identification in astronomy,\" for the Statistical Challenges\nin Modern Astronomy V conference held at Pennsylvania State University in June\n2011. I begin with a brief review of previous work on probabilistic (Bayesian)\nassessment of directional and spatio-temporal coincidences in astronomy (e.g.,\ncross-matching or cross-identification of objects across multiple catalogs).\nThen I discuss an open issue in the recent innovative work of Budavari and his\ncolleagues on large-scale probabilistic cross-identification: how to assign\nprior probabilities that play an important role in the analysis. With a simple\ntoy problem, I show how Bayesian multilevel modeling (hierarchical Bayes)\nprovides a principled framework that justifies and generalizes pragmatic rules\nof thumb that have been successfully used by Budavari's team to assign priors.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jun 2012 17:48:53 GMT"}], "update_date": "2012-06-20", "authors_parsed": [["Loredo", "Thomas J.", ""]]}, {"id": "1206.4327", "submitter": "Eytan Bakshy", "authors": "Eytan Bakshy, Dean Eckles, Rong Yan, Itamar Rosenn", "title": "Social Influence in Social Advertising: Evidence from Field Experiments", "comments": "16 pages, 8 figures, ACM EC 2012", "journal-ref": "E. Bakshy, D. Eckles, R. Yan, and I. Rosenn. 2012. Social\n  influence in social advertising: evidence from field experiments. In\n  Proceedings of the 13th ACM Conference on Electronic Commerce (EC '12). ACM,\n  New York, NY, USA, 146-161", "doi": "10.1145/2229012.2229027", "report-no": null, "categories": "cs.SI physics.soc-ph stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social advertising uses information about consumers' peers, including peer\naffiliations with a brand, product, organization, etc., to target ads and\ncontextualize their display. This approach can increase ad efficacy for two\nmain reasons: peers' affiliations reflect unobserved consumer characteristics,\nwhich are correlated along the social network; and the inclusion of social cues\n(i.e., peers' association with a brand) alongside ads affect responses via\nsocial influence processes. For these reasons, responses may be increased when\nmultiple social signals are presented with ads, and when ads are affiliated\nwith peers who are strong, rather than weak, ties.\n  We conduct two very large field experiments that identify the effect of\nsocial cues on consumer responses to ads, measured in terms of ad clicks and\nthe formation of connections with the advertised entity. In the first\nexperiment, we randomize the number of social cues present in word-of-mouth\nadvertising, and measure how responses increase as a function of the number of\ncues. The second experiment examines the effect of augmenting traditional ad\nunits with a minimal social cue (i.e., displaying a peer's affiliation below an\nad in light grey text). On average, this cue causes significant increases in ad\nperformance. Using a measurement of tie strength based on the total amount of\ncommunication between subjects and their peers, we show that these influence\neffects are greatest for strong ties. Our work has implications for ad\noptimization, user interface design, and central questions in social science\nresearch.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jun 2012 20:16:35 GMT"}], "update_date": "2012-06-21", "authors_parsed": [["Bakshy", "Eytan", ""], ["Eckles", "Dean", ""], ["Yan", "Rong", ""], ["Rosenn", "Itamar", ""]]}, {"id": "1206.4569", "submitter": "Kunlaya Soiaporn", "authors": "Kunlaya Soiaporn, David Chernoff, Thomas Loredo, David Ruppert, Ira\n  Wasserman", "title": "Multilevel Bayesian framework for modeling the production, propagation\n  and detection of ultra-high energy cosmic rays", "comments": "Published in at http://dx.doi.org/10.1214/13-AOAS654 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2013, Vol. 7, No. 3, 1249-1285", "doi": "10.1214/13-AOAS654", "report-no": "IMS-AOAS-AOAS654", "categories": "astro-ph.HE astro-ph.IM stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ultra-high energy cosmic rays (UHECRs) are atomic nuclei with energies over\nten million times energies accessible to human-made particle accelerators.\nEvidence suggests that they originate from relatively nearby extragalactic\nsources, but the nature of the sources is unknown. We develop a multilevel\nBayesian framework for assessing association of UHECRs and candidate source\npopulations, and Markov chain Monte Carlo algorithms for estimating model\nparameters and comparing models by computing, via Chib's method, marginal\nlikelihoods and Bayes factors. We demonstrate the framework by analyzing\nmeasurements of 69 UHECRs observed by the Pierre Auger Observatory (PAO) from\n2004-2009, using a volume-complete catalog of 17 local active galactic nuclei\n(AGN) out to 15 megaparsecs as candidate sources. An early portion of the data\n(\"period 1,\" with 14 events) was used by PAO to set an energy cut maximizing\nthe anisotropy in period 1; the 69 measurements include this \"tuned\" subset,\nand subsequent \"untuned\" events with energies above the same cutoff. Also,\nmeasurement errors are approximately summarized. These factors are problematic\nfor independent analyses of PAO data. Within the context of \"standard candle\"\nsource models (i.e., with a common isotropic emission rate), and considering\nonly the 55 untuned events, there is no significant evidence favoring\nassociation of UHECRs with local AGN vs. an isotropic background. The\nhighest-probability associations are with the two nearest, adjacent AGN,\nCentaurus A and NGC 4945. If the association model is adopted, the fraction of\nUHECRs that may be associated is likely nonzero but is well below 50%. Our\nframework enables estimation of the angular scale for deflection of cosmic rays\nby cosmic magnetic fields; relatively modest scales of $\\approx\\!3^{\\circ}$ to\n$30^{\\circ}$ are favored. Models that assign a large fraction of UHECRs to a\nsingle nearby source (e.g., Centaurus A) are ruled out unless very large\ndeflection scales are specified a priori, and even then they are disfavored.\nHowever, including the period 1 data alters the conclusions significantly, and\na simulation study supports the idea that the period 1 data are anomalous,\npresumably due to the tuning. Accurate and optimal analysis of future data will\nlikely require more complete disclosure of the data.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2012 18:13:01 GMT"}, {"version": "v2", "created": "Thu, 28 Nov 2013 07:41:05 GMT"}], "update_date": "2013-12-02", "authors_parsed": [["Soiaporn", "Kunlaya", ""], ["Chernoff", "David", ""], ["Loredo", "Thomas", ""], ["Ruppert", "David", ""], ["Wasserman", "Ira", ""]]}, {"id": "1206.4616", "submitter": "Drausin Wulsin", "authors": "Drausin Wulsin (University of Pennsylvania), Shane Jensen (University\n  of Pennsylvania), Brian Litt (University of Pennsylvania)", "title": "A Hierarchical Dirichlet Process Model with Multiple Levels of\n  Clustering for Human EEG Seizure Modeling", "comments": "ICML2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Driven by the multi-level structure of human intracranial\nelectroencephalogram (iEEG) recordings of epileptic seizures, we introduce a\nnew variant of a hierarchical Dirichlet Process---the multi-level clustering\nhierarchical Dirichlet Process (MLC-HDP)---that simultaneously clusters\ndatasets on multiple levels. Our seizure dataset contains brain activity\nrecorded in typically more than a hundred individual channels for each seizure\nof each patient. The MLC-HDP model clusters over channels-types, seizure-types,\nand patient-types simultaneously. We describe this model and its implementation\nin detail. We also present the results of a simulation study comparing the\nMLC-HDP to a similar model, the Nested Dirichlet Process and finally\ndemonstrate the MLC-HDP's use in modeling seizures across multiple patients. We\nfind the MLC-HDP's clustering to be comparable to independent human physician\nclusterings. To our knowledge, the MLC-HDP model is the first in the epilepsy\nliterature capable of clustering seizures within and between patients.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jun 2012 15:02:12 GMT"}], "update_date": "2012-06-22", "authors_parsed": [["Wulsin", "Drausin", "", "University of Pennsylvania"], ["Jensen", "Shane", "", "University\n  of Pennsylvania"], ["Litt", "Brian", "", "University of Pennsylvania"]]}, {"id": "1206.4685", "submitter": "Yan Liu", "authors": "Yan Liu (USC), Taha Bahadori (USC), Hongfei Li (IBM T.J. Watson\n  Research Center)", "title": "Sparse-GEV: Sparse Latent Space Model for Multivariate Extreme Value\n  Time Serie Modeling", "comments": "ICML2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many applications of time series models, such as climate analysis and\nsocial media analysis, we are often interested in extreme events, such as\nheatwave, wind gust, and burst of topics. These time series data usually\nexhibit a heavy-tailed distribution rather than a Gaussian distribution. This\nposes great challenges to existing approaches due to the significantly\ndifferent assumptions on the data distributions and the lack of sufficient past\ndata on extreme events. In this paper, we propose the Sparse-GEV model, a\nlatent state model based on the theory of extreme value modeling to\nautomatically learn sparse temporal dependence and make predictions. Our model\nis theoretically significant because it is among the first models to learn\nsparse temporal dependencies among multivariate extreme value time series. We\ndemonstrate the superior performance of our algorithm to the state-of-art\nmethods, including Granger causality, copula approach, and transfer entropy, on\none synthetic dataset, one climate dataset and two Twitter datasets.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jun 2012 15:42:15 GMT"}], "update_date": "2012-06-22", "authors_parsed": [["Liu", "Yan", "", "USC"], ["Bahadori", "Taha", "", "USC"], ["Li", "Hongfei", "", "IBM T.J. Watson\n  Research Center"]]}, {"id": "1206.4900", "submitter": "Hao Zhu", "authors": "Hao Zhu and Georgios B. Giannakis", "title": "Robust Power System State Estimation for the Nonlinear AC Flow Model", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important monitoring task for power systems is accurate estimation of the\nsystem operation state. Under the nonlinear AC power flow model, the state\nestimation (SE) problem is inherently nonconvex giving rise to many local\noptima. In addition to nonconvexity, SE is challenged by data integrity and\ncyber-security issues. Unfortunately, existing robust (R-) SE schemes employed\nroutinely in practice rely on iterative solvers, which are sensitive to\ninitialization and cannot ensure global optimality. A novel R-SE approach is\nformulated here by capitalizing on the sparsity of an overcomplete outlier\nvector model. Observability and identifiability issues of this model are\ninvestigated, and neat links are established between R-SE and error control\ncoding. The \\emph{convex} semidefinite relaxation (SDR) technique is further\npursued to render the nonconvex R-SE problem efficiently solvable. The\nresultant algorithm markedly outperforms existing iterative alternatives, as\ncorroborated through numerical tests on the standard IEEE 30-bus system.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jun 2012 14:44:29 GMT"}], "update_date": "2012-06-22", "authors_parsed": [["Zhu", "Hao", ""], ["Giannakis", "Georgios B.", ""]]}, {"id": "1206.4952", "submitter": "Nesreen Ahmed", "authors": "Nesreen K. Ahmed, Jennifer Neville, Ramana Kompella", "title": "Space-Efficient Sampling from Social Activity Streams", "comments": "BigMine 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.DB physics.soc-ph stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to efficiently study the characteristics of network domains and\nsupport development of network systems (e.g. algorithms, protocols that operate\non networks), it is often necessary to sample a representative subgraph from a\nlarge complex network. Although recent subgraph sampling methods have been\nshown to work well, they focus on sampling from memory-resident graphs and\nassume that the sampling algorithm can access the entire graph in order to\ndecide which nodes/edges to select. Many large-scale network datasets, however,\nare too large and/or dynamic to be processed using main memory (e.g., email,\ntweets, wall posts). In this work, we formulate the problem of sampling from\nlarge graph streams. We propose a streaming graph sampling algorithm that\ndynamically maintains a representative sample in a reservoir based setting. We\nevaluate the efficacy of our proposed methods empirically using several\nreal-world data sets. Across all datasets, we found that our method produce\nsamples that preserve better the original graph distributions.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2012 04:55:20 GMT"}], "update_date": "2012-06-22", "authors_parsed": [["Ahmed", "Nesreen K.", ""], ["Neville", "Jennifer", ""], ["Kompella", "Ramana", ""]]}, {"id": "1206.4969", "submitter": "Yves van Gennip", "authors": "Yves van Gennip, Blake Hunter, Raymond Ahn, Peter Elliott, Kyle Luh,\n  Megan Halvorson, Shannon Reid, Matt Valasik, James Wo, George E. Tita, Andrea\n  L. Bertozzi, P. Jeffrey Brantingham", "title": "Community detection using spectral clustering on sparse geosocial data", "comments": "22 pages, 6 figures (with subfigures)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.SI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we identify social communities among gang members in the\nHollenbeck policing district in Los Angeles, based on sparse observations of a\ncombination of social interactions and geographic locations of the individuals.\nThis information, coming from LAPD Field Interview cards, is used to construct\na similarity graph for the individuals. We use spectral clustering to identify\nclusters in the graph, corresponding to communities in Hollenbeck, and compare\nthese with the LAPD's knowledge of the individuals' gang membership. We discuss\ndifferent ways of encoding the geosocial information using a graph structure\nand the influence on the resulting clusterings. Finally we analyze the\nrobustness of this technique with respect to noisy and incomplete data, thereby\nproviding suggestions about the relative importance of quantity versus quality\nof collected data.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jun 2012 18:54:50 GMT"}, {"version": "v2", "created": "Wed, 27 Jun 2012 00:02:44 GMT"}, {"version": "v3", "created": "Thu, 8 Nov 2012 19:55:58 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["van Gennip", "Yves", ""], ["Hunter", "Blake", ""], ["Ahn", "Raymond", ""], ["Elliott", "Peter", ""], ["Luh", "Kyle", ""], ["Halvorson", "Megan", ""], ["Reid", "Shannon", ""], ["Valasik", "Matt", ""], ["Wo", "James", ""], ["Tita", "George E.", ""], ["Bertozzi", "Andrea L.", ""], ["Brantingham", "P. Jeffrey", ""]]}, {"id": "1206.5009", "submitter": "Andrew Parnell", "authors": "Andrew C. Parnell, James Sweeney, Thinh K. Doan, Michael\n  Salter-Townshend, Judy R. M. Allen, Brian Huntley, and John Haslett", "title": "On Bayesian Modelling of the Uncertainties in Palaeoclimate\n  Reconstruction", "comments": "25 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We outline a model and algorithm to perform inference on the palaeoclimate\nand palaeoclimate volatility from pollen proxy data. We use a novel\nmultivariate non-linear non-Gaussian state space model consisting of an\nobservation equation linking climate to proxy data and an evolution equation\ndriving climate change over time. The link from climate to proxy data is\ndefined by a pre-calibrated forward model, as developed in Salter-Townshend and\nHaslett (2012) and Sweeney (2012). Climatic change is represented by a\ntemporally-uncertain Normal-Inverse Gaussian Levy process, being able to\ncapture large jumps in multivariate climate whilst remaining temporally\nconsistent. The pre-calibrated nature of the forward model allows us to cut\nfeedback between the observation and evolution equations and thus integrate out\nthe state variable entirely whilst making minimal simplifying assumptions. A\nkey part of this approach is the creation of mixtures of marginal data\nposteriors representing the information obtained about climate from each\nindividual time point. Our approach allows for an extremely efficient MCMC\nalgorithm, which we demonstrate with a pollen core from Sluggan Bog, County\nAntrim, Northern Ireland.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jun 2012 20:27:19 GMT"}], "update_date": "2012-06-25", "authors_parsed": [["Parnell", "Andrew C.", ""], ["Sweeney", "James", ""], ["Doan", "Thinh K.", ""], ["Salter-Townshend", "Michael", ""], ["Allen", "Judy R. M.", ""], ["Huntley", "Brian", ""], ["Haslett", "John", ""]]}, {"id": "1206.5232", "submitter": "Mehdi Molkaraie", "authors": "Mehdi Molkaraie and Hans-Andrea Loeliger", "title": "Extending Monte Carlo Methods to Factor Graphs with Negative and Complex\n  Factors", "comments": "Proc. IEEE Information Theory Workshop (ITW), Lausanne, Switzerland,\n  Sept. 3-7, 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.IT math.IT stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The partition function of a factor graph can sometimes be accurately\nestimated by Monte Carlo methods. In this paper, such methods are extended to\nfactor graphs with negative and complex factors.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jun 2012 19:28:39 GMT"}, {"version": "v2", "created": "Sun, 7 Oct 2012 21:21:51 GMT"}], "update_date": "2012-10-09", "authors_parsed": [["Molkaraie", "Mehdi", ""], ["Loeliger", "Hans-Andrea", ""]]}, {"id": "1206.5250", "submitter": "Ethan W. Dereszynski", "authors": "Ethan W. Dereszynski, Thomas G. Dietterich", "title": "Probabilistic Models for Anomaly Detection in Remote Sensor Data Streams", "comments": "Appears in Proceedings of the Twenty-Third Conference on Uncertainty\n  in Artificial Intelligence (UAI2007)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2007-PG-75-82", "categories": "cs.AI stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Remote sensors are becoming the standard for observing and recording\necological data in the field. Such sensors can record data at fine temporal\nresolutions, and they can operate under extreme conditions prohibitive to human\naccess. Unfortunately, sensor data streams exhibit many kinds of errors ranging\nfrom corrupt communications to partial or total sensor failures. This means\nthat the raw data stream must be cleaned before it can be used by domain\nscientists. In our application environment|the H.J. Andrews Experimental\nForest|this data cleaning is performed manually. This paper introduces a\nDynamic Bayesian Network model for analyzing sensor observations and\ndistinguishing sensor failures from valid data for the case of air temperature\nmeasured at 15 minute time resolution. The model combines an accurate\ndistribution of long-term and short-term temperature variations with a single\ngeneralized fault model. Experiments with historical data show that the\nprecision and recall of the method is comparable to that of the domain expert.\nThe system is currently being deployed to perform real-time automated data\ncleaning.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2012 14:56:02 GMT"}], "update_date": "2012-06-26", "authors_parsed": [["Dereszynski", "Ethan W.", ""], ["Dietterich", "Thomas G.", ""]]}, {"id": "1206.5256", "submitter": "Joseph Bockhorst", "authors": "Joseph Bockhorst, Nebojsa Jojic", "title": "Discovering Patterns in Biological Sequences by Optimal Segmentation", "comments": "Appears in Proceedings of the Twenty-Third Conference on Uncertainty\n  in Artificial Intelligence (UAI2007)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2007-PG-17-24", "categories": "cs.CE cs.LG q-bio.QM stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational methods for discovering patterns of local correlations in\nsequences are important in computational biology. Here we show how to determine\nthe optimal partitioning of aligned sequences into non-overlapping segments\nsuch that positions in the same segment are strongly correlated while positions\nin different segments are not. Our approach involves discovering the hidden\nvariables of a Bayesian network that interact with observed sequences so as to\nform a set of independent mixture models. We introduce a dynamic program to\nefficiently discover the optimal segmentation, or equivalently the optimal set\nof hidden variables. We evaluate our approach on two computational biology\ntasks. One task is related to the design of vaccines against polymorphic\npathogens and the other task involves analysis of single nucleotide\npolymorphisms (SNPs) in human DNA. We show how common tasks in these problems\nnaturally correspond to inference procedures in the learned models. Error rates\nof our learned models for the prediction of missing SNPs are up to 1/3 less\nthan the error rates of a state-of-the-art SNP prediction method. Source code\nis available at www.uwm.edu/~joebock/segmentation.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2012 14:58:18 GMT"}], "update_date": "2012-06-26", "authors_parsed": [["Bockhorst", "Joseph", ""], ["Jojic", "Nebojsa", ""]]}, {"id": "1206.5269", "submitter": "Jennifer Listgarden", "authors": "Jennifer Listgarden, David Heckerman", "title": "Determining the Number of Non-Spurious Arcs in a Learned DAG Model:\n  Investigation of a Bayesian and a Frequentist Approach", "comments": "Appears in Proceedings of the Twenty-Third Conference on Uncertainty\n  in Artificial Intelligence (UAI2007)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2007-PG-251-258", "categories": "stat.AP cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many application domains, such as computational biology, the goal of\ngraphical model structure learning is to uncover discrete relationships between\nentities. For example, in our problem of interest concerning HIV vaccine\ndesign, we want to infer which HIV peptides interact with which immune system\nmolecules (HLA molecules). For problems of this nature, we are interested in\ndetermining the number of nonspurious arcs in a learned graphical model. We\ndescribe both a Bayesian and frequentist approach to this problem. In the\nBayesian approach, we use the posterior distribution over model structures to\ncompute the expected number of true arcs in a learned model. In the frequentist\napproach, we develop a method based on the concept of the False Discovery Rate.\nOn synthetic data sets generated from models similar to the ones learned, we\nfind that both the Bayesian and frequentist approaches yield accurate estimates\nof the number of non-spurious arcs. In addition, we speculate that the\nfrequentist approach, which is non-parametric, may outperform the parametric\nBayesian approach in situations where the models learned are less\nrepresentative of the data. Finally, we apply the frequentist approach to our\nproblem of HIV vaccine design.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2012 15:04:30 GMT"}], "update_date": "2012-06-26", "authors_parsed": [["Listgarden", "Jennifer", ""], ["Heckerman", "David", ""]]}, {"id": "1206.5280", "submitter": "Or Zuk", "authors": "Or Zuk, Liat Ein-Dor, Eytan Domany", "title": "Ranking Under Uncertainty", "comments": "Appears in Proceedings of the Twenty-Third Conference on Uncertainty\n  in Artificial Intelligence (UAI2007)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2007-PG-466-473", "categories": "cs.AI stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ranking objects is a simple and natural procedure for organizing data. It is\noften performed by assigning a quality score to each object according to its\nrelevance to the problem at hand. Ranking is widely used for object selection,\nwhen resources are limited and it is necessary to select a subset of most\nrelevant objects for further processing. In real world situations, the object's\nscores are often calculated from noisy measurements, casting doubt on the\nranking reliability. We introduce an analytical method for assessing the\ninfluence of noise levels on the ranking reliability. We use two similarity\nmeasures for reliability evaluation, Top-K-List overlap and Kendall's tau\nmeasure, and show that the former is much more sensitive to noise than the\nlatter. We apply our method to gene selection in a series of microarray\nexperiments of several cancer types. The results indicate that the reliability\nof the lists obtained from these experiments is very poor, and that experiment\nsizes which are necessary for attaining reasonably stable Top-K-Lists are much\nlarger than those currently available. Simulations support our analytical\nresults.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2012 15:10:59 GMT"}], "update_date": "2012-06-26", "authors_parsed": [["Zuk", "Or", ""], ["Ein-Dor", "Liat", ""], ["Domany", "Eytan", ""]]}, {"id": "1206.5387", "submitter": "Manjunath B G", "authors": "Manjunath B G and Stefan Wilhelm", "title": "Moments Calculation For the Doubly Truncated Multivariate Normal Density", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the present article we derive an explicit expression for the trun- cated\nmean and variance for the multivariate normal distribution with ar- bitrary\nrectangular double truncation. We use the moment generating ap- proach of\nTallis (1961) and extend it to general {\\mu}, {\\Sigma} and all combinations of\ntruncation. As part of the solution we also give a formula for the bivari- ate\nmarginal density of truncated multinormal variates. We also prove an invariance\nproperty of some elements of the inverse covariance after trunca- tion.\nComputer algorithms for computing the truncated mean, variance and the\nbivariate marginal probabilities for doubly truncated multivariate normal\nvariates have been written in R and are presented along with three examples.\n", "versions": [{"version": "v1", "created": "Sat, 23 Jun 2012 12:37:20 GMT"}], "update_date": "2012-06-26", "authors_parsed": [["G", "Manjunath B", ""], ["Wilhelm", "Stefan", ""]]}, {"id": "1206.5681", "submitter": "Leonardo Bastos", "authors": "Leonardo S. Bastos and Adriana A. Pinho and Claudia Code\\c{c}o and\n  Francisco I. Bastos", "title": "Binary regression analysis with network structure of respondent-driven\n  sampling data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Respondent-driven sampling (RDS) is a procedure to sample from hard-to-reach\npopulations. It has been widely used in several countries, especially in the\nmonitoring of HIV/AIDS and other sexually transmitted infections. Hard-to-reach\npopulations have had a key role in the dynamics of such epidemics and must\ninform evidence-based initiatives aiming to curb their spread. In this paper,\nwe present a simple test for network dependence for a binary response variable.\nWe estimate the prevalence of the response variable. We also propose a binary\nregression model taking into account the RDS structure which is included in the\nmodel through a latent random effect with a correlation structure. The proposed\nmodel is illustrated in a RDS study for HIV and Syphilis in men who have sex\nwith men implemented in Campinas (Brazil).\n", "versions": [{"version": "v1", "created": "Mon, 25 Jun 2012 13:45:20 GMT"}], "update_date": "2012-06-26", "authors_parsed": [["Bastos", "Leonardo S.", ""], ["Pinho", "Adriana A.", ""], ["Code\u00e7o", "Claudia", ""], ["Bastos", "Francisco I.", ""]]}, {"id": "1206.6070", "submitter": "Karla Diaz-Ordaz Ms", "authors": "Karla Diaz-Ordaz, Michael G. Kenward and Richard Grieve", "title": "Handling missing values in cost-effectiveness analyses that use data\n  from cluster randomised trials", "comments": "18 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Public policy-makers use cost-effectiveness analyses (CEA) to decide which\nhealth and social care interventions to provide. Appropriate methods have not\nbeen developed for handling missing data in complex settings, such as for CEA\nthat use data from cluster randomised trials (CRTs). We present a multilevel\nmultiple imputation (MI) approach that recognises when missing data have a\nhierarchical structure, and is compatible with the bivariate multilevel models\nused to report cost-effectiveness. We contrast the multilevel MI approach with\nsingle-level MI and complete case analysis in a CEA alongside a CRT. The paper\nhighlights the importance of adopting a principled approach to handling missing\nvalues in settings with complex data structures.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jun 2012 18:22:58 GMT"}], "update_date": "2012-06-27", "authors_parsed": [["Diaz-Ordaz", "Karla", ""], ["Kenward", "Michael G.", ""], ["Grieve", "Richard", ""]]}, {"id": "1206.6304", "submitter": "Ahmed El Shafie", "authors": "Ahmed El Shafie, Tamer Khattab", "title": "Stationarity of Stochastic Processes In The Fractional Fourier Domains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CV stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the stationarity of stochastic processes in the\nfractional Fourier domains. We study the stationarity of a stochastic process\nafter performing fractional Fourier transform (FRFT), and discrete fractional\nFourier transform (DFRT) on both continuous and discrete stochastic processes,\nrespectively. Also we investigate the stationarity of the fractional Fourier\nseries (FRFS) coefficients of a continuous time stochastic process, and the\nstationarity of the discrete time fractional Fourier transform (DTFRFT) of a\ndiscrete time stochastic process. Closed formulas of the input process\nautocorrelation function and pseudo-autocorrelation function after performing\nthe fractional Fourier transform are derived given that the input is a\nstationary stochastic process. We derive a formula for the output\nautocorrelation as a function of the $a^{th}$ power spectral density of the\ninput stochastic process, also we derived a formula for the input fractional\npower spectral density as a function of the fractional Fourier transform of the\noutput process autocorrelation function. We proved that, the input stochastic\nprocess must be zero mean to satisfy a necessary but not a sufficient condition\nof stationarity in the fractional domains. Closed formulas of the resultant\nstatistics are also shown. It is shown that, in case of real input process, the\noutput process is stationary if and only if the input process is white. On the\nother hand, if the input process is a complex process, it should be proper\nwhite process to obtain a stationary output process.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 15:19:59 GMT"}, {"version": "v2", "created": "Sat, 10 Nov 2012 10:44:17 GMT"}], "update_date": "2012-11-13", "authors_parsed": [["Shafie", "Ahmed El", ""], ["Khattab", "Tamer", ""]]}, {"id": "1206.6391", "submitter": "Alexis Boukouvalas", "authors": "Alexis Boukouvalas (Aston University), Remi Barillec (Aston\n  University), Dan Cornford (Aston University)", "title": "Gaussian Process Quantile Regression using Expectation Propagation", "comments": "Appears in Proceedings of the 29th International Conference on\n  Machine Learning (ICML 2012)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Direct quantile regression involves estimating a given quantile of a response\nvariable as a function of input variables. We present a new framework for\ndirect quantile regression where a Gaussian process model is learned,\nminimising the expected tilted loss function. The integration required in\nlearning is not analytically tractable so to speed up the learning we employ\nthe Expectation Propagation algorithm. We describe how this work relates to\nother quantile regression methods and apply the method on both synthetic and\nreal data sets. The method is shown to be competitive with state of the art\nmethods whilst allowing for the leverage of the full Gaussian process\nprobabilistic framework.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 19:59:59 GMT"}], "update_date": "2012-07-03", "authors_parsed": [["Boukouvalas", "Alexis", "", "Aston University"], ["Barillec", "Remi", "", "Aston\n  University"], ["Cornford", "Dan", "", "Aston University"]]}, {"id": "1206.6439", "submitter": "Hanhuai Shan", "authors": "Hanhuai Shan (University of Minnesota), Jens Kattge (Max Planck\n  Institute for Biogeochemistry), Peter Reich (University of Minnesota),\n  Arindam Banerjee (University of Minnesota), Franziska Schrodt (University of\n  Minnesota), Markus Reichstein (Max Planck Institute for Biogeochemistry)", "title": "Gap Filling in the Plant Kingdom---Trait Prediction Using Hierarchical\n  Probabilistic Matrix Factorization", "comments": "Appears in Proceedings of the 29th International Conference on\n  Machine Learning (ICML 2012)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Plant traits are a key to understanding and predicting the adaptation of\necosystems to environmental changes, which motivates the TRY project aiming at\nconstructing a global database for plant traits and becoming a standard\nresource for the ecological community. Despite its unprecedented coverage, a\nlarge percentage of missing data substantially constrains joint trait analysis.\nMeanwhile, the trait data is characterized by the hierarchical phylogenetic\nstructure of the plant kingdom. While factorization based matrix completion\ntechniques have been widely used to address the missing data problem,\ntraditional matrix factorization methods are unable to leverage the\nphylogenetic structure. We propose hierarchical probabilistic matrix\nfactorization (HPMF), which effectively uses hierarchical phylogenetic\ninformation for trait prediction. We demonstrate HPMF's high accuracy,\neffectiveness of incorporating hierarchical structure and ability to capture\ntrait correlation through experiments.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 19:59:59 GMT"}], "update_date": "2012-07-03", "authors_parsed": [["Shan", "Hanhuai", "", "University of Minnesota"], ["Kattge", "Jens", "", "Max Planck\n  Institute for Biogeochemistry"], ["Reich", "Peter", "", "University of Minnesota"], ["Banerjee", "Arindam", "", "University of Minnesota"], ["Schrodt", "Franziska", "", "University of\n  Minnesota"], ["Reichstein", "Markus", "", "Max Planck Institute for Biogeochemistry"]]}, {"id": "1206.6447", "submitter": "Gael Varoquaux", "authors": "Gael Varoquaux (INRIA), Alexandre Gramfort (INRIA), Bertrand Thirion\n  (INRIA)", "title": "Small-sample Brain Mapping: Sparse Recovery on Spatially Correlated\n  Designs with Randomization and Clustering", "comments": "Appears in Proceedings of the 29th International Conference on\n  Machine Learning (ICML 2012)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Functional neuroimaging can measure the brain?s response to an external\nstimulus. It is used to perform brain mapping: identifying from these\nobservations the brain regions involved. This problem can be cast into a linear\nsupervised learning task where the neuroimaging data are used as predictors for\nthe stimulus. Brain mapping is then seen as a support recovery problem. On\nfunctional MRI (fMRI) data, this problem is particularly challenging as i) the\nnumber of samples is small due to limited acquisition time and ii) the\nvariables are strongly correlated. We propose to overcome these difficulties\nusing sparse regression models over new variables obtained by clustering of the\noriginal variables. The use of randomization techniques, e.g. bootstrap\nsamples, and clustering of the variables improves the recovery properties of\nsparse methods. We demonstrate the benefit of our approach on an extensive\nsimulation study as well as two fMRI datasets.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 19:59:59 GMT"}], "update_date": "2012-07-03", "authors_parsed": [["Varoquaux", "Gael", "", "INRIA"], ["Gramfort", "Alexandre", "", "INRIA"], ["Thirion", "Bertrand", "", "INRIA"]]}, {"id": "1206.6456", "submitter": "Mingyuan Zhou", "authors": "Mingyuan Zhou (Duke University), Lingbo Li (Duke University), David\n  Dunson (Duke University), Lawrence Carin (Duke University)", "title": "Lognormal and Gamma Mixed Negative Binomial Regression", "comments": "Appears in Proceedings of the 29th International Conference on\n  Machine Learning (ICML 2012)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In regression analysis of counts, a lack of simple and efficient algorithms\nfor posterior computation has made Bayesian approaches appear unattractive and\nthus underdeveloped. We propose a lognormal and gamma mixed negative binomial\n(NB) regression model for counts, and present efficient closed-form Bayesian\ninference; unlike conventional Poisson models, the proposed approach has two\nfree parameters to include two different kinds of random effects, and allows\nthe incorporation of prior information, such as sparsity in the regression\ncoefficients. By placing a gamma distribution prior on the NB dispersion\nparameter r, and connecting a lognormal distribution prior with the logit of\nthe NB probability parameter p, efficient Gibbs sampling and variational Bayes\ninference are both developed. The closed-form updates are obtained by\nexploiting conditional conjugacy via both a compound Poisson representation and\na Polya-Gamma distribution based data augmentation approach. The proposed\nBayesian inference can be implemented routinely, while being easily\ngeneralizable to more complex settings involving multivariate dependence\nstructures. The algorithms are illustrated using real examples.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 19:59:59 GMT"}], "update_date": "2012-07-03", "authors_parsed": [["Zhou", "Mingyuan", "", "Duke University"], ["Li", "Lingbo", "", "Duke University"], ["Dunson", "David", "", "Duke University"], ["Carin", "Lawrence", "", "Duke University"]]}, {"id": "1206.6617", "submitter": "Karen Kafadar", "authors": "Karen Kafadar", "title": "Special section: Statistical methods for next-generation gene sequencing\n  data", "comments": "Published in at http://dx.doi.org/10.1214/12-AOAS558 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2012, Vol. 6, No. 2, 429-431", "doi": "10.1214/12-AOAS558", "report-no": "IMS-AOAS-AOAS558", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This issue includes six articles that develop and apply statistical methods\nfor the analysis of gene sequencing data of different types. The methods are\ntailored to the different data types and, in each case, lead to biological\ninsights not readily identified without the use of statistical methods. A\ncommon feature in all articles is the development of methods for analyzing\nsimultaneously data of different types (e.g., genotype, phenotype, pedigree,\netc.); that is, using data of one type to inform the analysis of data from\nanother type.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jun 2012 10:23:40 GMT"}], "update_date": "2012-06-29", "authors_parsed": [["Kafadar", "Karen", ""]]}, {"id": "1206.6624", "submitter": "Alice S. Whittemore", "authors": "Baiyu Zhou, Alice S. Whittemore", "title": "Improving sequence-based genotype calls with linkage disequilibrium and\n  pedigree information", "comments": "Published in at http://dx.doi.org/10.1214/11-AOAS527 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2012, Vol. 6, No. 2, 457-475", "doi": "10.1214/11-AOAS527", "report-no": "IMS-AOAS-AOAS527", "categories": "stat.AP q-bio.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Whole and targeted sequencing of human genomes is a promising, increasingly\nfeasible tool for discovering genetic contributions to risk of complex\ndiseases. A key step is calling an individual's genotype from the multiple\naligned short read sequences of his DNA, each of which is subject to nucleotide\nread error. Current methods are designed to call genotypes separately at each\nlocus from the sequence data of unrelated individuals. Here we propose\nlikelihood-based methods that improve calling accuracy by exploiting two\nfeatures of sequence data. The first is the linkage disequilibrium (LD) between\nnearby SNPs. The second is the Mendelian pedigree information available when\nrelated individuals are sequenced. In both cases the likelihood involves the\nprobabilities of read variant counts given genotypes, summed over the\nunobserved genotypes. Parameters governing the prior genotype distribution and\nthe read error rates can be estimated either from the sequence data itself or\nfrom external reference data. We use simulations and synthetic read data based\non the 1000 Genomes Project to evaluate the performance of the proposed\nmethods. An R-program to apply the methods to small families is freely\navailable at http://med.stanford.edu/epidemiology/PHGC/.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jun 2012 10:46:50 GMT"}], "update_date": "2012-06-29", "authors_parsed": [["Zhou", "Baiyu", ""], ["Whittemore", "Alice S.", ""]]}, {"id": "1206.6627", "submitter": "Jeremy J. Shen", "authors": "Jeremy J. Shen, Nancy R. Zhang", "title": "Change-point model on nonhomogeneous Poisson processes with application\n  in copy number profiling by next-generation DNA sequencing", "comments": "Published in at http://dx.doi.org/10.1214/11-AOAS517 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2012, Vol. 6, No. 2, 476-496", "doi": "10.1214/11-AOAS517", "report-no": "IMS-AOAS-AOAS517", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a flexible change-point model for inhomogeneous Poisson Processes,\nwhich arise naturally from next-generation DNA sequencing, and derive score and\ngeneralized likelihood statistics for shifts in intensity functions. We\nconstruct a modified Bayesian information criterion (mBIC) to guide model\nselection, and point-wise approximate Bayesian confidence intervals for\nassessing the confidence in the segmentation. The model is applied to DNA Copy\nNumber profiling with sequencing data and evaluated on simulated spike-in and\nreal data sets.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jun 2012 10:53:57 GMT"}], "update_date": "2012-06-29", "authors_parsed": [["Shen", "Jeremy J.", ""], ["Zhang", "Nancy R.", ""]]}, {"id": "1206.6636", "submitter": "Karen Messer", "authors": "Loki Natarajan, Minya Pu, Karen Messer", "title": "Statistical tests for the intersection of independent lists of genes:\n  Sensitivity, FDR, and type I error control", "comments": "Published in at http://dx.doi.org/10.1214/11-AOAS510 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2012, Vol. 6, No. 2, 521-541", "doi": "10.1214/11-AOAS510", "report-no": "IMS-AOAS-AOAS510", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Public data repositories have enabled researchers to compare results across\nmultiple genomic studies in order to replicate findings. A common approach is\nto first rank genes according to an hypothesis of interest within each study.\nThen, lists of the top-ranked genes within each study are compared across\nstudies. Genes recaptured as highly ranked (usually above some threshold) in\nmultiple studies are considered to be significant. However, this comparison\nstrategy often remains informal, in that type I error and false discovery rate\n(FDR) are usually uncontrolled. In this paper, we formalize an inferential\nstrategy for this kind of list-intersection discovery test. We show how to\ncompute a $p$-value associated with a \"recaptured\" set of genes, using a\nclosed-form Poisson approximation to the distribution of the size of the\nrecaptured set. We investigate operating characteristics of the test as a\nfunction of the total number of studies considered, the rank threshold within\neach study, and the number of studies within which a gene must be recaptured to\nbe declared significant. We investigate the trade off between FDR control and\nexpected sensitivity (the expected proportion of true-positive genes identified\nas significant). We give practical guidance on how to design a bioinformatic\nlist-intersection study with maximal expected sensitivity and prespecified\ncontrol of type I error (at the set level) and false discovery rate (at the\ngene level). We show how optimal choice of parameters may depend on particular\nalternative hypothesis which might hold. We illustrate our methods using\nprostate cancer gene-expression datasets from the curated Oncomine database,\nand discuss the effects of dependence between genes on the test.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jun 2012 11:05:17 GMT"}], "update_date": "2012-06-29", "authors_parsed": [["Natarajan", "Loki", ""], ["Pu", "Minya", ""], ["Messer", "Karen", ""]]}, {"id": "1206.6647", "submitter": "Brian M. Hartman", "authors": "Brian M. Hartman, Bani K. Mallick, Debabrata Talukdar", "title": "Investigating international new product diffusion speed: A\n  semiparametric approach", "comments": "Published in at http://dx.doi.org/10.1214/11-AOAS519 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2012, Vol. 6, No. 2, 625-651", "doi": "10.1214/11-AOAS519", "report-no": "IMS-AOAS-AOAS519", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Global marketing managers are interested in understanding the speed of the\nnew product diffusion process and how the speed has changed in our ever more\ntechnologically advanced and global marketplace. Understanding the process\nallows firms to forecast the expected rate of return on their new products and\ndevelop effective marketing strategies. The most recent major study on this\ntopic [Marketing Science 21 (2002) 97--114] investigated new product diffusions\nin the United States. We expand upon that study in three important ways. (1)\nVan den Bulte notes that a similar study is needed in the international\ncontext, especially in developing countries. Our study covers four new product\ndiffusions across 31 developed and developing nations from 1980--2004. Our\nsample accounts for about 80% of the global economic output and 60% of the\nglobal population, allowing us to examine more general phenomena. (2) His model\ncontains the implicit assumption that the diffusion speed parameter is constant\nthroughout the diffusion life cycle of a product. Recognizing the likely\neffects on the speed parameter of recent changes in the marketplace, we model\nthe parameter as a semiparametric function, allowing it the flexibility to\nchange over time. (3) We perform a variable selection to determine that the\nnumber of internet users and the consumer price index are strongly associated\nwith the speed of diffusion.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jun 2012 12:07:12 GMT"}], "update_date": "2012-06-29", "authors_parsed": [["Hartman", "Brian M.", ""], ["Mallick", "Bani K.", ""], ["Talukdar", "Debabrata", ""]]}, {"id": "1206.6650", "submitter": "Donatello Telesca", "authors": "Donatello Telesca, Peter M\\\"uller, Giovanni Parmigiani, Ralph S.\n  Freedman", "title": "Modeling dependent gene expression", "comments": "Published in at http://dx.doi.org/10.1214/11-AOAS525 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2012, Vol. 6, No. 2, 542-560", "doi": "10.1214/11-AOAS525", "report-no": "IMS-AOAS-AOAS525", "categories": "stat.AP q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a Bayesian approach for inference about dependence\nof high throughput gene expression. Our goals are to use prior knowledge about\npathways to anchor inference about dependence among genes; to account for this\ndependence while making inferences about differences in mean expression across\nphenotypes; and to explore differences in the dependence itself across\nphenotypes. Useful features of the proposed approach are a model-based\nparsimonious representation of expression as an ordinal outcome, a novel and\nflexible representation of prior information on the nature of dependencies, and\nthe use of a coherent probability model over both the structure and strength of\nthe dependencies of interest. We evaluate our approach through simulations and\nin the analysis of data on expression of genes in the Complement and\nCoagulation Cascade pathway in ovarian cancer.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jun 2012 12:14:09 GMT"}], "update_date": "2012-06-29", "authors_parsed": [["Telesca", "Donatello", ""], ["M\u00fcller", "Peter", ""], ["Parmigiani", "Giovanni", ""], ["Freedman", "Ralph S.", ""]]}, {"id": "1206.6653", "submitter": "Tyler H. McCormick", "authors": "Tyler H. McCormick, Cynthia Rudin, David Madigan", "title": "Bayesian hierarchical rule modeling for predicting medical conditions", "comments": "Published in at http://dx.doi.org/10.1214/11-AOAS522 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2012, Vol. 6, No. 2, 652-668", "doi": "10.1214/11-AOAS522", "report-no": "IMS-AOAS-AOAS522", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a statistical modeling technique, called the Hierarchical\nAssociation Rule Model (HARM), that predicts a patient's possible future\nmedical conditions given the patient's current and past history of reported\nconditions. The core of our technique is a Bayesian hierarchical model for\nselecting predictive association rules (such as \"condition 1 and condition 2\n$\\rightarrow$ condition 3\") from a large set of candidate rules. Because this\nmethod \"borrows strength\" using the conditions of many similar patients, it is\nable to provide predictions specialized to any given patient, even when little\ninformation about the patient's history of conditions is available.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jun 2012 12:18:20 GMT"}], "update_date": "2012-06-29", "authors_parsed": [["McCormick", "Tyler H.", ""], ["Rudin", "Cynthia", ""], ["Madigan", "David", ""]]}, {"id": "1206.6655", "submitter": "Oleksandr Gromenko", "authors": "Oleksandr Gromenko, Piotr Kokoszka, Lie Zhu, Jan Sojka", "title": "Estimation and testing for spatially indexed curves with application to\n  ionospheric and magnetic field trends", "comments": "Published in at http://dx.doi.org/10.1214/11-AOAS524 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2012, Vol. 6, No. 2, 669-696", "doi": "10.1214/11-AOAS524", "report-no": "IMS-AOAS-AOAS524", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop methodology for the estimation of the functional mean and the\nfunctional principal components when the functions form a spatial process. The\ndata consist of curves $X(\\mathbf{s}_k;t),t\\in[0,T],$ observed at spatial\nlocations $\\mathbf{s}_1,\\mathbf{s}_2,...,\\mathbf{s}_N$. We propose several\nmethods, and evaluate them by means of a simulation study. Next, we develop a\nsignificance test for the correlation of two such functional spatial fields.\nAfter validating the finite sample performance of this test by means of a\nsimulation study, we apply it to determine if there is correlation between\nlong-term trends in the so-called critical ionospheric frequency and decadal\nchanges in the direction of the internal magnetic field of the Earth. The test\nprovides conclusive evidence for correlation, thus solving a long-standing\nspace physics conjecture. This conclusion is not apparent if the spatial\ndependence of the curves is neglected.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jun 2012 12:25:15 GMT"}], "update_date": "2012-06-29", "authors_parsed": [["Gromenko", "Oleksandr", ""], ["Kokoszka", "Piotr", ""], ["Zhu", "Lie", ""], ["Sojka", "Jan", ""]]}, {"id": "1206.6664", "submitter": "Guangyu Zhang", "authors": "Guangyu Zhang, Ying Yuan", "title": "Bayesian modeling longitudinal dyadic data with nonignorable dropout,\n  with application to a breast cancer study", "comments": "Published in at http://dx.doi.org/10.1214/11-AOAS515 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2012, Vol. 6, No. 2, 753-771", "doi": "10.1214/11-AOAS515", "report-no": "IMS-AOAS-AOAS515", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dyadic data are common in the social and behavioral sciences, in which\nmembers of dyads are correlated due to the interdependence structure within\ndyads. The analysis of longitudinal dyadic data becomes complex when\nnonignorable dropouts occur. We propose a fully Bayesian selection-model-based\napproach to analyze longitudinal dyadic data with nonignorable dropouts. We\nmodel repeated measures on subjects by a transition model and account for\nwithin-dyad correlations by random effects. In the model, we allow subject's\noutcome to depend on his/her own characteristics and measure history, as well\nas those of the other member in the dyad. We further account for the\nnonignorable missing data mechanism using a selection model in which the\nprobability of dropout depends on the missing outcome. We propose a Gibbs\nsampler algorithm to fit the model. Simulation studies show that the proposed\nmethod effectively addresses the problem of nonignorable dropouts. We\nillustrate our methodology using a longitudinal breast cancer study.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jun 2012 12:44:42 GMT"}], "update_date": "2012-06-29", "authors_parsed": [["Zhang", "Guangyu", ""], ["Yuan", "Ying", ""]]}, {"id": "1206.6666", "submitter": "Polly Phipps", "authors": "Polly Phipps, Daniell Toth", "title": "Analyzing establishment nonresponse using an interpretable regression\n  tree model with linked administrative data", "comments": "Published in at http://dx.doi.org/10.1214/11-AOAS521 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2012, Vol. 6, No. 2, 772-794", "doi": "10.1214/11-AOAS521", "report-no": "IMS-AOAS-AOAS521", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To gain insight into how characteristics of an establishment are associated\nwith nonresponse, a recursive partitioning algorithm is applied to the\nOccupational Employment Statistics May 2006 survey data to build a regression\ntree. The tree models an establishment's propensity to respond to the survey\ngiven certain establishment characteristics. It provides mutually exclusive\ncells based on the characteristics with homogeneous response propensities. This\nmakes it easy to identify interpretable associations between the characteristic\nvariables and an establishment's propensity to respond, something not easily\ndone using a logistic regression propensity model. We test the model obtained\nusing the May data against data from the November 2006 Occupational Employment\nStatistics survey. Testing the model on a disjoint set of establishment data\nwith a very large sample size $(n=179,360)$ offers evidence that the regression\ntree model accurately describes the association between the establishment\ncharacteristics and the response propensity for the OES survey. The accuracy of\nthis modeling approach is compared to that of logistic regression through\nsimulation. This representation is then used along with frame-level\nadministrative wage data linked to sample data to investigate the possibility\nof nonresponse bias. We show that without proper adjustments the nonresponse\ndoes pose a risk of bias and is possibly nonignorable.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jun 2012 12:49:16 GMT"}], "update_date": "2012-06-29", "authors_parsed": [["Phipps", "Polly", ""], ["Toth", "Daniell", ""]]}, {"id": "1206.6674", "submitter": "Yu Ryan Yue", "authors": "Yu Ryan Yue, Martin A. Lindquist, Ji Meng Loh", "title": "Meta-analysis of functional neuroimaging data using Bayesian\n  nonparametric binary regression", "comments": "Published in at http://dx.doi.org/10.1214/11-AOAS523 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2012, Vol. 6, No. 2, 697-718", "doi": "10.1214/11-AOAS523", "report-no": "IMS-AOAS-AOAS523", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we perform a meta-analysis of neuroimaging data, consisting of\nlocations of peak activations identified in 162 separate studies on emotion.\nNeuroimaging meta-analyses are typically performed using kernel-based methods.\nHowever, these methods require the width of the kernel to be set a priori and\nto be constant across the brain. To address these issues, we propose a fully\nBayesian nonparametric binary regression method to perform neuroimaging\nmeta-analyses. In our method, each location (or voxel) has a probability of\nbeing a peak activation, and the corresponding probability function is based on\na spatially adaptive Gaussian Markov random field (GMRF). We also include\nparameters in the model to robustify the procedure against miscoding of the\nvoxel response. Posterior inference is implemented using efficient MCMC\nalgorithms extended from those introduced in Holmes and Held [Bayesian Anal. 1\n(2006) 145--168]. Our method allows the probability function to be locally\nadaptive with respect to the covariates, that is, to be smooth in one region of\nthe covariate space and wiggly or even discontinuous in another. Posterior\nmiscoding probabilities for each of the identified voxels can also be obtained,\nidentifying voxels that may have been falsely classified as being activated.\nSimulation studies and application to the emotion neuroimaging data indicate\nthat our method is superior to standard kernel-based methods.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jun 2012 13:10:38 GMT"}], "update_date": "2012-06-29", "authors_parsed": [["Yue", "Yu Ryan", ""], ["Lindquist", "Martin A.", ""], ["Loh", "Ji Meng", ""]]}, {"id": "1206.6701", "submitter": "Paul T Edlefsen", "authors": "Paul T. Edlefsen", "title": "Evaluating the dependence of a non-leaky intervention's partial efficacy\n  on a categorical mark", "comments": "25 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address discrete-marks survival analysis, also known as categorical sieve\nanalysis, for a setting of a randomized placebo-controlled treatment\nintervention to prevent infection by a pathogen to which multiple exposures are\npossible, with a finite number of types of \"failure\". In particular, we address\nthe case of interventions that are partially efficacious due to a combination\nof failure-type-dependent efficacy and subject-dependent efficacy, for an\nintervention that is \"non-leaky\" (where \"leaky\" interventions are those for\nwhich each exposure event has a chance of resulting in a \"failure\" outcome, so\nmultiple exposures to pathogens of a single type increase the chance of\nfailure). We introduce the notion of some-or-none interventions, which are\ncompletely effective only against some of the failure types, and are completely\nineffective against the others. Under conditions of no intervention-induced\nfailures, we introduce a framework and Bayesian and frequentist methods to\ndetect and quantify the extent to which an intervention's partial efficacy is\nattributable to uneven efficacy across the failure types rather than to\nincomplete \"take\" of the intervention. These new methods provide more power\nthan existing methods to detect sieve effects when the conditions hold. We\ndemonstrate the new framework and methods with simulation results and new\nanalyses of genomic signatures of HIV-1 vaccine effects in the STEP and RV144\nvaccine efficacy trials.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jun 2012 14:28:10 GMT"}, {"version": "v2", "created": "Fri, 3 Jan 2014 19:32:25 GMT"}], "update_date": "2014-01-06", "authors_parsed": [["Edlefsen", "Paul T.", ""]]}, {"id": "1206.6774", "submitter": "Brian Williams Dr", "authors": "Brian G. Williams and Eleanor Gouws", "title": "Affordability, cost and cost-effectiveness of universal anti-retroviral\n  therapy for HIV", "comments": "Several typographical errors have been corrected. Main change is the\n  addition of data on the cost of military spending in each country and a\n  comparison with the cost of universal ART", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.OT stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  If people at risk of HIV infection are tested annually and started on\ntreatment as soon as they are found to be HIV-positive it should be possible to\nreduce the case reproduction number for HIV to less than one, eliminate\ntransmission and end the epidemic. If this is to be done it is essential to\nknow if it would be affordable, and cost effective. Here we show that in all\nbut eleven countries of the world it is affordable by those countries, that in\nthese eleven countries it is affordable for the international community, and in\nall countries it is highly cost-effective.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 07:48:39 GMT"}, {"version": "v2", "created": "Fri, 26 Oct 2012 15:40:51 GMT"}], "update_date": "2012-10-29", "authors_parsed": [["Williams", "Brian G.", ""], ["Gouws", "Eleanor", ""]]}, {"id": "1206.6816", "submitter": "Robert G. Cowell", "authors": "Robert G. Cowell, Steffen L. Lauritzen, Julia Mortera", "title": "MAIES: A Tool for DNA Mixture Analysis", "comments": "Appears in Proceedings of the Twenty-Second Conference on Uncertainty\n  in Artificial Intelligence (UAI2006)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2006-PG-90-97", "categories": "cs.AI cs.CE stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe an expert system, MAIES, developed for analysing forensic\nidentification problems involving DNA mixture traces using quantitative peak\narea information. Peak area information is represented by conditional Gaussian\ndistributions, and inference based on exact junction tree propagation\nascertains whether individuals, whose profiles have been measured, have\ncontributed to the mixture. The system can also be used to predict DNA profiles\nof unknown contributors by separating the mixture into its individual\ncomponents. The use of the system is illustrated with an application to a real\nworld example. The system implements a novel MAP (maximum a posteriori) search\nalgorithm that is described in an appendix.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 15:38:31 GMT"}], "update_date": "2012-07-02", "authors_parsed": [["Cowell", "Robert G.", ""], ["Lauritzen", "Steffen L.", ""], ["Mortera", "Julia", ""]]}, {"id": "1206.6910", "submitter": "Anton Korobeynikov", "authors": "Nina Golyandina and Anton Korobeynikov", "title": "Basic Singular Spectrum Analysis and Forecasting with R", "comments": null, "journal-ref": "Computational Statistics and Data Analysis, Volume 71, March 2014,\n  Pages 934-954", "doi": "10.1016/j.csda.2013.04.009", "report-no": null, "categories": "stat.ME stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Singular Spectrum Analysis (SSA) as a tool for analysis and forecasting of\ntime series is considered. The main features of the Rssa package, which\nimplements the SSA algorithms and methodology in R, are described and examples\nof its use are presented. Analysis, forecasting and parameter estimation are\ndemonstrated by means of case study with an accompanying code in R.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jun 2012 22:22:44 GMT"}, {"version": "v2", "created": "Fri, 18 Jan 2013 22:13:31 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Golyandina", "Nina", ""], ["Korobeynikov", "Anton", ""]]}, {"id": "1206.6952", "submitter": "Xi Kathy Zhou", "authors": "Xi Kathy Zhou, Fei Liu, Andrew J. Dannenberg", "title": "A Bayesian model averaging approach for observational gene expression\n  studies", "comments": "Published in at http://dx.doi.org/10.1214/11-AOAS526 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2012, Vol. 6, No. 2, 497-520", "doi": "10.1214/11-AOAS526", "report-no": "IMS-AOAS-AOAS526", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying differentially expressed (DE) genes associated with a sample\ncharacteristic is the primary objective of many microarray studies. As more and\nmore studies are carried out with observational rather than well controlled\nexperimental samples, it becomes important to evaluate and properly control the\nimpact of sample heterogeneity on DE gene finding. Typical methods for\nidentifying DE genes require ranking all the genes according to a preselected\nstatistic based on a single model for two or more group comparisons, with or\nwithout adjustment for other covariates. Such single model approaches\nunavoidably result in model misspecification, which can lead to increased error\ndue to bias for some genes and reduced efficiency for the others. We evaluated\nthe impact of model misspecification from such approaches on detecting DE genes\nand identified parameters that affect the magnitude of impact. To properly\ncontrol for sample heterogeneity and to provide a flexible and coherent\nframework for identifying simultaneously DE genes associated with a single or\nmultiple sample characteristics and/or their interactions, we proposed a\nBayesian model averaging approach which corrects the model misspecification by\naveraging over model space formed by all relevant covariates. An empirical\napproach is suggested for specifying prior model probabilities. We demonstrated\nthrough simulated microarray data that this approach resulted in improved\nperformance in DE gene identification compared to the single model approaches.\nThe flexibility of this approach is demonstrated through our analysis of data\nfrom two observational microarray studies.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jun 2012 06:42:21 GMT"}], "update_date": "2012-07-02", "authors_parsed": [["Zhou", "Xi Kathy", ""], ["Liu", "Fei", ""], ["Dannenberg", "Andrew J.", ""]]}, {"id": "1206.6962", "submitter": "Chong Liu", "authors": "Chong Liu, Surajit Ray, Giles Hooker, Mark Friedl", "title": "Functional factor analysis for periodic remote sensing data", "comments": "Published in at http://dx.doi.org/10.1214/11-AOAS518 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2012, Vol. 6, No. 2, 601-624", "doi": "10.1214/11-AOAS518", "report-no": "IMS-AOAS-AOAS518", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new approach to factor rotation for functional data. This is\nachieved by rotating the functional principal components toward a predefined\nspace of periodic functions designed to decompose the total variation into\ncomponents that are nearly-periodic and nearly-aperiodic with a predefined\nperiod. We show that the factor rotation can be obtained by calculation of\ncanonical correlations between appropriate spaces which make the methodology\ncomputationally efficient. Moreover, we demonstrate that our proposed rotations\nprovide stable and interpretable results in the presence of highly complex\ncovariance. This work is motivated by the goal of finding interpretable sources\nof variability in gridded time series of vegetation index measurements obtained\nfrom remote sensing, and we demonstrate our methodology through an application\nof factor rotation of this data.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jun 2012 08:37:38 GMT"}], "update_date": "2012-07-02", "authors_parsed": [["Liu", "Chong", ""], ["Ray", "Surajit", ""], ["Hooker", "Giles", ""], ["Friedl", "Mark", ""]]}, {"id": "1206.6980", "submitter": "Laurent Jacob", "authors": "Laurent Jacob, Pierre Neuvial, Sandrine Dudoit", "title": "More power via graph-structured tests for differential expression of\n  gene networks", "comments": "Published in at http://dx.doi.org/10.1214/11-AOAS528 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org). arXiv admin note:\n  substantial text overlap with arXiv:1009.5173", "journal-ref": "Annals of Applied Statistics 2012, Vol. 6, No. 2, 561-600", "doi": "10.1214/11-AOAS528", "report-no": "IMS-AOAS-AOAS528", "categories": "stat.AP q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider multivariate two-sample tests of means, where the location shift\nbetween the two populations is expected to be related to a known graph\nstructure. An important application of such tests is the detection of\ndifferentially expressed genes between two patient populations, as shifts in\nexpression levels are expected to be coherent with the structure of graphs\nreflecting gene properties such as biological process, molecular function,\nregulation or metabolism. For a fixed graph of interest, we demonstrate that\naccounting for graph structure can yield more powerful tests under the\nassumption of smooth distribution shift on the graph. We also investigate the\nidentification of nonhomogeneous subgraphs of a given large graph, which poses\nboth computational and multiple hypothesis testing problems. The relevance and\nbenefits of the proposed approach are illustrated on synthetic data and on\nbreast and bladder cancer gene expression data analyzed in the context of KEGG\nand NCI pathways.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jun 2012 10:37:22 GMT"}], "update_date": "2012-07-02", "authors_parsed": [["Jacob", "Laurent", ""], ["Neuvial", "Pierre", ""], ["Dudoit", "Sandrine", ""]]}]