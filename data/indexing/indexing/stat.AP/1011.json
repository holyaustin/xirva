[{"id": "1011.0126", "submitter": "Zhengping Fan", "authors": "Zhengping Fan, Guanrong Chen, and Yunong Zhang", "title": "Using topological characteristics to evaluate complex network models can\n  be misleading", "comments": "15 pags, 7 figures, submitted to Phys. A", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphical models are frequently used to represent topological structures of\nvarious complex networks. Current criteria to assess different models of a\nnetwork mainly rely on how close a model matches the network in terms of\ntopological characteristics. Typical topological metrics are clustering\ncoefficient, distance distribution, the largest eigenvalue of the adjacency\nmatrix, and the gap between the first and the second largest eigenvalues, which\nare widely used to evaluate and compare different models of a network. In this\npaper, we show that evaluating complex network models based on the current\ntopological metrics can be quite misleading. Taking several models of the\nAS-level Internet as examples, we show that although a model seems to be good\nto describe the Internet in terms of the aforementioned topological\ncharacteristics, it is far from being realistic to represent the real Internet\nin performances such as robustness in resisting intentional attacks and traffic\nload distributions. We further show that it is not useful to assess network\nmodels by examining some topological characteristics such as clustering\ncoefficient and distance distribution, if robustness of the Internet against\nrandom node removals is the only concern. Our findings shed new lights on how\nto reasonably evaluate different models of a network, not only the Internet but\nalso other types of complex networks.\n", "versions": [{"version": "v1", "created": "Sun, 31 Oct 2010 04:27:30 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Fan", "Zhengping", ""], ["Chen", "Guanrong", ""], ["Zhang", "Yunong", ""]]}, {"id": "1011.0174", "submitter": "Pavel Gapeev", "authors": "Pavel V. Gapeev", "title": "Two switching multiple disorder problems for Brownian motions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The multiple disorder problem seeks to determine a sequence of stopping times\nwhich are as close as possible to the unknown times of disorders at which the\nobservation process changes its probability characteristics. We derive closed\nform solutions in two formulations of the multiple disorder problem for an\nobservable Brownian motion with switching constant drift rates. The method of\nproof is based on the reduction of the initial problems to appropriate optimal\nswitching problems and the analysis of the associated coupled free-boundary\nproblems. We also describe the sequential switching multiple disorder detection\nprocedures resulting from these formulations.\n", "versions": [{"version": "v1", "created": "Sun, 31 Oct 2010 16:14:51 GMT"}], "update_date": "2010-11-02", "authors_parsed": [["Gapeev", "Pavel V.", ""]]}, {"id": "1011.0413", "submitter": "Michael Mahoney", "authors": "Jacob Bien and Ya Xu and Michael W. Mahoney", "title": "CUR from a Sparse Optimization Viewpoint", "comments": "9 pages; in NIPS 2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The CUR decomposition provides an approximation of a matrix $X$ that has low\nreconstruction error and that is sparse in the sense that the resulting\napproximation lies in the span of only a few columns of $X$. In this regard, it\nappears to be similar to many sparse PCA methods. However, CUR takes a\nrandomized algorithmic approach, whereas most sparse PCA methods are framed as\nconvex optimization problems. In this paper, we try to understand CUR from a\nsparse optimization viewpoint. We show that CUR is implicitly optimizing a\nsparse regression objective and, furthermore, cannot be directly cast as a\nsparse PCA method. We also observe that the sparsity attained by CUR possesses\nan interesting structure, which leads us to formulate a sparse PCA method that\nachieves a CUR-like sparsity.\n", "versions": [{"version": "v1", "created": "Mon, 1 Nov 2010 19:07:15 GMT"}], "update_date": "2010-11-02", "authors_parsed": [["Bien", "Jacob", ""], ["Xu", "Ya", ""], ["Mahoney", "Michael W.", ""]]}, {"id": "1011.0471", "submitter": "Sean Simpson", "authors": "Lloyd J. Edwards", "title": "A Note on an R^2 Measure for Fixed Effects in the Generalized Linear\n  Mixed Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using the LRT statistic, a model R^2 is proposed for the generalized linear\nmixed model for assessing the association between the correlated outcomes and\nfixed effects. The R^2 compares the full model to a null model with all fixed\neffects deleted.\n", "versions": [{"version": "v1", "created": "Mon, 1 Nov 2010 23:36:50 GMT"}], "update_date": "2010-11-03", "authors_parsed": [["Edwards", "Lloyd J.", ""]]}, {"id": "1011.0592", "submitter": "Tabea  Rebafka", "authors": "Fabienne Comte and Tabea Rebafka", "title": "Adaptive Density Estimation in the Pile-up Model Involving Measurement\n  Errors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by fluorescence lifetime measurements this paper considers the\nproblem of nonparametric density estimation in the pile-up model. Adaptive\nnonparametric estimators are proposed for the pile-up model in its simple form\nas well as in the case of additional measurement errors. Furthermore, oracle\ntype risk bounds for the mean integrated squared error (MISE) are provided.\nFinally, the estimation methods are assessed by a simulation study and the\napplication to real fluorescence lifetime data.\n", "versions": [{"version": "v1", "created": "Tue, 2 Nov 2010 12:15:52 GMT"}], "update_date": "2010-11-03", "authors_parsed": [["Comte", "Fabienne", ""], ["Rebafka", "Tabea", ""]]}, {"id": "1011.0601", "submitter": "Youyi Fong", "authors": "Youyi Fong, Peter Guttorp, Janis Abkowitz", "title": "Bayesian inference and model choice in a hidden stochastic\n  two-compartment model of hematopoietic stem cell fate decisions", "comments": "Published in at http://dx.doi.org/10.1214/09-AOAS269 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2009, Vol. 3, No. 4, 1695-1709", "doi": "10.1214/09-AOAS269", "report-no": "IMS-AOAS-AOAS269", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite rapid advances in experimental cell biology, the in vivo behavior of\nhematopoietic stem cells (HSC) cannot be directly observed and measured.\nPreviously we modeled feline hematopoiesis using a two-compartment hidden\nMarkov process that had birth and emigration events in the first compartment.\nHere we perform Bayesian statistical inference on models which contain two\nadditional events in the first compartment in order to determine if HSC fate\ndecisions are linked to cell division or occur independently. Pareto Optimal\nModel Assessment approach is used to cross check the estimates from Bayesian\ninference. Our results show that HSC must divide symmetrically (i.e., produce\ntwo HSC daughter cells) in order to maintain hematopoiesis. We then demonstrate\nthat the augmented model that adds asymmetric division events provides a better\nfit to the competitive transplantation data, and we thus provide evidence that\nHSC fate determination in vivo occurs both in association with cell division\nand at a separate point in time. Last we show that assuming each cat has a\nunique set of parameters leads to either a significant decrease or a\nnonsignificant increase in model fit, suggesting that the kinetic parameters\nfor HSC are not unique attributes of individual animals, but shared within a\nspecies.\n", "versions": [{"version": "v1", "created": "Tue, 2 Nov 2010 12:46:20 GMT"}], "update_date": "2010-11-03", "authors_parsed": [["Fong", "Youyi", ""], ["Guttorp", "Peter", ""], ["Abkowitz", "Janis", ""]]}, {"id": "1011.0608", "submitter": "Wei-Yin Loh", "authors": "Wei-Yin Loh", "title": "Improving the precision of classification trees", "comments": "Published in at http://dx.doi.org/10.1214/09-AOAS260 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2009, Vol. 3, No. 4, 1710-1737", "doi": "10.1214/09-AOAS260", "report-no": "IMS-AOAS-AOAS260", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Besides serving as prediction models, classification trees are useful for\nfinding important predictor variables and identifying interesting subgroups in\nthe data. These functions can be compromised by weak split selection algorithms\nthat have variable selection biases or that fail to search beyond local main\neffects at each node of the tree. The resulting models may include many\nirrelevant variables or select too few of the important ones. Either\neventuality can lead to erroneous conclusions. Four techniques to improve the\nprecision of the models are proposed and their effectiveness compared with that\nof other algorithms, including tree ensembles, on real and simulated data sets.\n", "versions": [{"version": "v1", "created": "Tue, 2 Nov 2010 13:08:38 GMT"}], "update_date": "2010-11-03", "authors_parsed": [["Loh", "Wei-Yin", ""]]}, {"id": "1011.0610", "submitter": "Ming Yuan", "authors": "Ming Yuan, V. Roshan Joseph, Hui Zou", "title": "Structured variable selection and estimation", "comments": "Published in at http://dx.doi.org/10.1214/09-AOAS254 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2009, Vol. 3, No. 4, 1738-1757", "doi": "10.1214/09-AOAS254", "report-no": "IMS-AOAS-AOAS254", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In linear regression problems with related predictors, it is desirable to do\nvariable selection and estimation by maintaining the hierarchical or structural\nrelationships among predictors. In this paper we propose non-negative garrote\nmethods that can naturally incorporate such relationships defined through\neffect heredity principles or marginality principles. We show that the methods\nare very easy to compute and enjoy nice theoretical properties. We also show\nthat the methods can be easily extended to deal with more general regression\nproblems such as generalized linear models. Simulations and real examples are\nused to illustrate the merits of the proposed methods.\n", "versions": [{"version": "v1", "created": "Tue, 2 Nov 2010 13:27:03 GMT"}], "update_date": "2010-11-03", "authors_parsed": [["Yuan", "Ming", ""], ["Joseph", "V. Roshan", ""], ["Zou", "Hui", ""]]}, {"id": "1011.0619", "submitter": "Daniel Gervini", "authors": "Daniel Gervini", "title": "Detecting and handling outlying trajectories in irregularly sampled\n  functional datasets", "comments": "Published in at http://dx.doi.org/10.1214/09-AOAS257 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2009, Vol. 3, No. 4, 1758-1775", "doi": "10.1214/09-AOAS257", "report-no": "IMS-AOAS-AOAS257", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Outlying curves often occur in functional or longitudinal datasets, and can\nbe very influential on parameter estimators and very hard to detect visually.\nIn this article we introduce estimators of the mean and the principal\ncomponents that are resistant to, and then can be used for detection of,\noutlying sample trajectories. The estimators are based on reduced-rank t-models\nand are specifically aimed at sparse and irregularly sampled functional data.\nThe outlier-resistance properties of the estimators and their relative\nefficiency for noncontaminated data are studied theoretically and by\nsimulation. Applications to the analysis of Internet traffic data and glycated\nhemoglobin levels in diabetic children are presented.\n", "versions": [{"version": "v1", "created": "Tue, 2 Nov 2010 13:51:24 GMT"}], "update_date": "2010-11-03", "authors_parsed": [["Gervini", "Daniel", ""]]}, {"id": "1011.0626", "submitter": "Fabio Rigat", "authors": "Fabio Rigat, Jim Q. Smith", "title": "Semi-parametric dynamic time series modelling with applications to\n  detecting neural dynamics", "comments": "Published in at http://dx.doi.org/10.1214/09-AOAS275 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2009, Vol. 3, No. 4, 1776-1804", "doi": "10.1214/09-AOAS275", "report-no": "IMS-AOAS-AOAS275", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper illustrates novel methods for nonstationary time series modeling\nalong with their applications to selected problems in neuroscience. These\nmethods are semi-parametric in that inferences are derived by combining\nsequential Bayesian updating with a non-parametric change-point test. As a test\nstatistic, we propose a Kullback--Leibler (KL) divergence between posterior\ndistributions arising from different sets of data. A closed form expression of\nthis statistic is derived for exponential family models, whereas standard\nMarkov chain Monte Carlo output is used to approximate its value and its\ncritical region for more general models. The behavior of one-step ahead\npredictive distributions under our semi-parametric framework is described\nanalytically for a dynamic linear time series model. Conditions under which our\napproach reduces to fully parametric state-space modeling are also illustrated.\nWe apply our methods to estimating the functional dynamics of a wide range of\nneural data, including multi-channel electroencephalogram recordings,\nlongitudinal behavioral experiments and in-vivo multiple spike trains\nrecordings. The estimated dynamics are related to the presentation of visual\nstimuli, to the evaluation of a learning performance and to changes in the\nfunctional connections between neurons over a sequence of experiments.\n", "versions": [{"version": "v1", "created": "Tue, 2 Nov 2010 14:26:36 GMT"}], "update_date": "2010-11-03", "authors_parsed": [["Rigat", "Fabio", ""], ["Smith", "Jim Q.", ""]]}, {"id": "1011.0646", "submitter": "Sudipto Banerjee", "authors": "Yufen Zhang, James S. Hodges, Sudipto Banerjee", "title": "Smoothed ANOVA with spatial effects as a competitor to MCAR in\n  multivariate spatial smoothing", "comments": "Published in at http://dx.doi.org/10.1214/09-AOAS267 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2009, Vol. 3, No. 4, 1805-1830", "doi": "10.1214/09-AOAS267", "report-no": "IMS-AOAS-AOAS267", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rapid developments in geographical information systems (GIS) continue to\ngenerate interest in analyzing complex spatial datasets. One area of activity\nis in creating smoothed disease maps to describe the geographic variation of\ndisease and generate hypotheses for apparent differences in risk. With multiple\ndiseases, a multivariate conditionally autoregressive (MCAR) model is often\nused to smooth across space while accounting for associations between the\ndiseases. The MCAR, however, imposes complex covariance structures that are\ndifficult to interpret and estimate. This article develops a much simpler\nalternative approach building upon the techniques of smoothed ANOVA (SANOVA).\nInstead of simply shrinking effects without any structure, here we use SANOVA\nto smooth spatial random effects by taking advantage of the spatial structure.\nWe extend SANOVA to cases in which one factor is a spatial lattice, which is\nsmoothed using a CAR model, and a second factor is, for example, type of\ncancer. Datasets routinely lack enough information to identify the additional\nstructure of MCAR. SANOVA offers a simpler and more intelligible structure than\nthe MCAR while performing as well. We demonstrate our approach with simulation\nstudies designed to compare SANOVA with different design matrices versus MCAR\nwith different priors. Subsequently a cancer-surveillance dataset, describing\nincidence of 3-cancers in Minnesota's 87 counties, is analyzed using both\napproaches, showing the competitiveness of the SANOVA approach.\n", "versions": [{"version": "v1", "created": "Tue, 2 Nov 2010 15:39:57 GMT"}], "update_date": "2010-11-03", "authors_parsed": [["Zhang", "Yufen", ""], ["Hodges", "James S.", ""], ["Banerjee", "Sudipto", ""]]}, {"id": "1011.0662", "submitter": "Nikolai Gagunashvili", "authors": "N.D. Gagunashvili", "title": "Parametric fitting of data obtained from detectors with finite\n  resolution and limited acceptance", "comments": "11 pages, two figures", "journal-ref": "Nuclear Instruments and Methods A 635 (2011) 86-91", "doi": "10.1016/j.nima.2010.12.230", "report-no": null, "categories": "physics.data-an astro-ph.IM hep-ex nucl-ex stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A goodness-of-fit test for the fitting of a parametric model to data obtained\nfrom a detector with finite resolution and limited acceptance is proposed. The\nparameters of the model are found by minimization of a statistic that is used\nfor comparing experimental data and simulated reconstructed data. Numerical\nexamples are presented to illustrate and validate the fitting procedure.\n", "versions": [{"version": "v1", "created": "Tue, 2 Nov 2010 16:16:02 GMT"}, {"version": "v2", "created": "Wed, 5 Jan 2011 16:25:53 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Gagunashvili", "N. D.", ""]]}, {"id": "1011.0748", "submitter": "Jun-ichi Inoue", "authors": "Takero Ibuki, Jun-ichi Inoue", "title": "Response of double-auction markets to instantaneous Selling-Buying\n  signals with stochastic Bid-Ask spread", "comments": "27 pages, 66 figures, using svjour3.cls", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.TR stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical properties of order-driven double-auction markets with Bid-Ask\nspread are investigated through the dynamical quantities such as response\nfunction. We first attempt to utilize the so-called {\\it\nMadhavan-Richardson-Roomans model} (MRR for short) to simulate the stochastic\nprocess of the price-change in empirical data sets (say, EUR/JPY or USD/JPY\nexchange rates) in which the Bid-Ask spread fluctuates in time. We find that\nthe MRR theory apparently fails to simulate so much as the qualitative\nbehaviour ('non-monotonic' behaviour) of the response function $R(l)$ ($l$\ndenotes the difference of times at which the response function is evaluated)\ncalculated from the data. Especially, we confirm that the stochastic nature of\nthe Bid-Ask spread causes apparent deviations from a linear relationship\nbetween the $R(l)$ and the auto-correlation function $C(l)$, namely, $R(l)\n\\propto -C(l)$. To make the microscopic model of double-auction markets having\nstochastic Bid-Ask spread, we use the minority game with a finite market\nhistory length and find numerically that appropriate extension of the game\nshows quite similar behaviour of the response function to the empirical\nevidence. We also reveal that the minority game modeling with the adaptive\n('annealed') look-up table reproduces the non-linear relationship $R(l) \\propto\n-f(C(l))$ ($f(x)$ stands for a non-linear function leading to\n'$\\lambda$-shapes') more effectively than the fixed (`quenched') look-up table\ndoes.\n", "versions": [{"version": "v1", "created": "Tue, 2 Nov 2010 20:27:23 GMT"}, {"version": "v2", "created": "Thu, 31 Mar 2011 15:27:19 GMT"}], "update_date": "2011-04-01", "authors_parsed": [["Ibuki", "Takero", ""], ["Inoue", "Jun-ichi", ""]]}, {"id": "1011.1470", "submitter": "Luca Ferretti", "authors": "Luca Ferretti, Giacomo Marmorini, Sebastian Ramos-Onsins", "title": "Properties of neutrality tests based on allele frequency spectrum", "comments": "42 pages, 3 figures, elsarticle", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM q-bio.PE stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the main necessities for population geneticists is the availability of\nstatistical tools that enable to accept or reject the neutral Wright-Fisher\nmodel with high power. A number of statistical tests have been developed to\ndetect specific deviations from the null frequency spectrum in different\ndirections (i.e., Tajima's D, Fu and Li's F and D test, Fay and Wu's H).\nRecently, a general framework was proposed to generate all neutrality tests\nthat are linear functions of the frequency spectrum. In this framework, a\nfamily of optimal tests was developed to have almost maximum power against a\nspecific alternative evolutionary scenario. Following these developments, in\nthis paper we provide a thorough discussion of linear and nonlinear neutrality\ntests. First, we present the general framework for linear tests and emphasize\nthe importance of the property of scalability with the sample size (that is,\nthe results of the tests should not depend on the sample size), which, if\nmissing, can guide to errors in data interpretation. The motivation and\nstructure of linear optimal tests are discussed. In a further generalization,\nwe develop a general framework for nonlinear neutrality tests and we derive\nnonlinear optimal tests for polynomials of any degree in the frequency\nspectrum.\n", "versions": [{"version": "v1", "created": "Fri, 5 Nov 2010 18:16:24 GMT"}], "update_date": "2010-11-08", "authors_parsed": [["Ferretti", "Luca", ""], ["Marmorini", "Giacomo", ""], ["Ramos-Onsins", "Sebastian", ""]]}, {"id": "1011.1512", "submitter": "Umut Orguner PhD", "authors": "Umut Orguner", "title": "CPHD filter derivation for extended targets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.DS math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This document derives the CPHD filter for extended targets. Only the update\nstep is derived here. Target generated measurements, false alarms and prior are\nall assumed to be independent identically distributed cluster processes. We\nalso prove here that the derived CPHD filter for extended targets reduce to PHD\nfilter for extended targets and CPHD filter for standard targets under suitable\nassumptions.\n", "versions": [{"version": "v1", "created": "Fri, 5 Nov 2010 21:04:55 GMT"}, {"version": "v2", "created": "Mon, 15 Nov 2010 13:38:11 GMT"}], "update_date": "2010-11-16", "authors_parsed": [["Orguner", "Umut", ""]]}, {"id": "1011.1717", "submitter": "Stephen E. Fienberg", "authors": "Stephen E. Fienberg", "title": "Introduction to papers on the modeling and analysis of network data---II", "comments": "Published in at http://dx.doi.org/10.1214/10-AOAS365 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2010, Vol. 4, No. 2, 533-534", "doi": "10.1214/10-AOAS365", "report-no": "IMS-AOAS-AOAS365", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Introduction to papers on the modeling and analysis of network data---II\n", "versions": [{"version": "v1", "created": "Mon, 8 Nov 2010 07:05:37 GMT"}], "update_date": "2010-11-09", "authors_parsed": [["Fienberg", "Stephen E.", ""]]}, {"id": "1011.1753", "submitter": "Tom A. B. Snijders", "authors": "Tom A. B. Snijders, Johan Koskinen, Michael Schweinberger", "title": "Maximum likelihood estimation for social network dynamics", "comments": "Published in at http://dx.doi.org/10.1214/09-AOAS313 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2010, Vol. 4, No. 2, 567-588", "doi": "10.1214/09-AOAS313", "report-no": "IMS-AOAS-AOAS313", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A model for network panel data is discussed, based on the assumption that the\nobserved data are discrete observations of a continuous-time Markov process on\nthe space of all directed graphs on a given node set, in which changes in tie\nvariables are independent conditional on the current graph. The model for tie\nchanges is parametric and designed for applications to social network analysis,\nwhere the network dynamics can be interpreted as being generated by choices\nmade by the social actors represented by the nodes of the graph. An algorithm\nfor calculating the Maximum Likelihood estimator is presented, based on data\naugmentation and stochastic approximation. An application to an evolving\nfriendship network is given and a small simulation study is presented which\nsuggests that for small data sets the Maximum Likelihood estimator is more\nefficient than the earlier proposed Method of Moments estimator.\n", "versions": [{"version": "v1", "created": "Mon, 8 Nov 2010 10:18:34 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Snijders", "Tom A. B.", ""], ["Koskinen", "Johan", ""], ["Schweinberger", "Michael", ""]]}, {"id": "1011.1766", "submitter": "Art B. Owen", "authors": "Ya Xu, Justin S. Dyer, Art B. Owen", "title": "Empirical stationary correlations for semi-supervised learning on graphs", "comments": "Published in at http://dx.doi.org/10.1214/09-AOAS293 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2010, Vol. 4, No. 2, 589-614", "doi": "10.1214/09-AOAS293", "report-no": "IMS-AOAS-AOAS293", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In semi-supervised learning on graphs, response variables observed at one\nnode are used to estimate missing values at other nodes. The methods exploit\ncorrelations between nearby nodes in the graph. In this paper we prove that\nmany such proposals are equivalent to kriging predictors based on a fixed\ncovariance matrix driven by the link structure of the graph. We then propose a\ndata-driven estimator of the correlation structure that exploits patterns among\nthe observed response values. By incorporating even a small fraction of\nobserved covariation into the predictions, we are able to obtain much improved\nprediction on two graph data sets.\n", "versions": [{"version": "v1", "created": "Mon, 8 Nov 2010 10:45:03 GMT"}], "update_date": "2010-11-09", "authors_parsed": [["Xu", "Ya", ""], ["Dyer", "Justin S.", ""], ["Owen", "Art B.", ""]]}, {"id": "1011.1788", "submitter": "Nicholas A. Heard", "authors": "Nicholas A. Heard, David J. Weston, Kiriaki Platanioti, David J. Hand", "title": "Bayesian anomaly detection methods for social networks", "comments": "Published in at http://dx.doi.org/10.1214/10-AOAS329 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2010, Vol. 4, No. 2, 645-662", "doi": "10.1214/10-AOAS329", "report-no": "IMS-AOAS-AOAS329", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning the network structure of a large graph is computationally demanding,\nand dynamically monitoring the network over time for any changes in structure\nthreatens to be more challenging still. This paper presents a two-stage method\nfor anomaly detection in dynamic graphs: the first stage uses simple, conjugate\nBayesian models for discrete time counting processes to track the pairwise\nlinks of all nodes in the graph to assess normality of behavior; the second\nstage applies standard network inference tools on a greatly reduced subset of\npotentially anomalous nodes. The utility of the method is demonstrated on\nsimulated and real data sets.\n", "versions": [{"version": "v1", "created": "Mon, 8 Nov 2010 12:57:36 GMT"}], "update_date": "2010-11-09", "authors_parsed": [["Heard", "Nicholas A.", ""], ["Weston", "David J.", ""], ["Platanioti", "Kiriaki", ""], ["Hand", "David J.", ""]]}, {"id": "1011.1796", "submitter": "Fabio Sigrist", "authors": "Fabio Sigrist and Werner A. Stahel", "title": "Using The Censored Gamma Distribution for Modeling Fractional Response\n  Variables with an Application to Loss Given Default", "comments": null, "journal-ref": null, "doi": "10.2143/AST.41.2.2136992", "report-no": null, "categories": "stat.AP q-fin.RM q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regression models for limited continuous dependent variables having a\nnon-negligible probability of attaining exactly their limits are presented. The\nmodels differ in the number of parameters and in their flexibility. Fractional\ndata being a special case of limited dependent data, the models also apply to\nvariables that are a fraction or a proportion. It is shown how to fit these\nmodels and they are applied to a Loss Given Default dataset from insurance to\nwhich they provide a good fit.\n", "versions": [{"version": "v1", "created": "Mon, 8 Nov 2010 13:21:05 GMT"}, {"version": "v2", "created": "Wed, 17 Nov 2010 08:30:02 GMT"}, {"version": "v3", "created": "Fri, 19 Aug 2011 13:35:55 GMT"}, {"version": "v4", "created": "Sat, 24 Dec 2011 01:31:51 GMT"}, {"version": "v5", "created": "Wed, 30 May 2012 07:14:00 GMT"}], "update_date": "2012-05-31", "authors_parsed": [["Sigrist", "Fabio", ""], ["Stahel", "Werner A.", ""]]}, {"id": "1011.1798", "submitter": "Gareth M. James", "authors": "Gareth M. James, Chiara Sabatti, Nengfeng Zhou, Ji Zhu", "title": "Sparse regulatory networks", "comments": "Published in at http://dx.doi.org/10.1214/10-AOAS350 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2010, Vol. 4, No. 2, 663-686", "doi": "10.1214/10-AOAS350", "report-no": "IMS-AOAS-AOAS350", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many organisms the expression levels of each gene are controlled by the\nactivation levels of known \"Transcription Factors\" (TF). A problem of\nconsiderable interest is that of estimating the \"Transcription Regulation\nNetworks\" (TRN) relating the TFs and genes. While the expression levels of\ngenes can be observed, the activation levels of the corresponding TFs are\nusually unknown, greatly increasing the difficulty of the problem. Based on\nprevious experimental work, it is often the case that partial information about\nthe TRN is available. For example, certain TFs may be known to regulate a given\ngene or in other cases a connection may be predicted with a certain\nprobability. In general, the biology of the problem indicates there will be\nvery few connections between TFs and genes. Several methods have been proposed\nfor estimating TRNs. However, they all suffer from problems such as unrealistic\nassumptions about prior knowledge of the network structure or computational\nlimitations. We propose a new approach that can directly utilize prior\ninformation about the network structure in conjunction with observed gene\nexpression data to estimate the TRN. Our approach uses $L_1$ penalties on the\nnetwork to ensure a sparse structure. This has the advantage of being\ncomputationally efficient as well as making many fewer assumptions about the\nnetwork structure. We use our methodology to construct the TRN for E. coli and\nshow that the estimate is biologically sensible and compares favorably with\nprevious estimates.\n", "versions": [{"version": "v1", "created": "Mon, 8 Nov 2010 13:29:35 GMT"}], "update_date": "2010-11-09", "authors_parsed": [["James", "Gareth M.", ""], ["Sabatti", "Chiara", ""], ["Zhou", "Nengfeng", ""], ["Zhu", "Ji", ""]]}, {"id": "1011.1813", "submitter": "Mahendra Mariadassou", "authors": "Mahendra Mariadassou, St\\'ephane Robin, Corinne Vacher", "title": "Uncovering latent structure in valued graphs: A variational approach", "comments": "Published in at http://dx.doi.org/10.1214/10-AOAS361 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2010, Vol. 4, No. 2, 715-742", "doi": "10.1214/10-AOAS361", "report-no": "IMS-AOAS-AOAS361", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As more and more network-structured data sets are available, the statistical\nanalysis of valued graphs has become common place. Looking for a latent\nstructure is one of the many strategies used to better understand the behavior\nof a network. Several methods already exist for the binary case. We present a\nmodel-based strategy to uncover groups of nodes in valued graphs. This\nframework can be used for a wide span of parametric random graphs models and\nallows to include covariates. Variational tools allow us to achieve approximate\nmaximum likelihood estimation of the parameters of these models. We provide a\nsimulation study showing that our estimation method performs well over a broad\nrange of situations. We apply this method to analyze host--parasite interaction\nnetworks in forest ecosystems.\n", "versions": [{"version": "v1", "created": "Mon, 8 Nov 2010 14:50:30 GMT"}], "update_date": "2010-11-09", "authors_parsed": [["Mariadassou", "Mahendra", ""], ["Robin", "St\u00e9phane", ""], ["Vacher", "Corinne", ""]]}, {"id": "1011.1845", "submitter": "Michela Cameletti", "authors": "Michela Cameletti, Rosaria Ignaccolo, Stefano Bande", "title": "Comparing air quality statistical models", "comments": "53 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Air pollution is a great concern because of its impact on human health and on\nthe environment. Statistical models play an important role in improving\nknowledge of this complex spatio-temporal phenomenon and in supporting public\nagencies and policy makers. We focus on the class of hierarchical models that\nprovides a flexible framework for incorporating spatio-temporal interactions at\ndifferent hierarchical levels. The challenge is to choose a model that is\nsatisfactory in terms of goodness of fit, interpretability, parsimoniousness,\nprediction capability and computational costs. In order to support this choice,\nwe propose a comparison approach based on a set of criteria summarized in a\ntable that can be easily communicated to non-statisticians. Our proposal -\nsimple in principle but articulated in practice - holds true for many\nenvironmental phenomena where a hierarchical structure is suitable, a\nlarge-scale trend is included and a spatio-temporal covariance function has to\nbe chosen. We illustrate the details of our proposal through a case study\nconcerning particulate matter concentrations in Piemonte region (Italy) during\nthe cold season October 2005-March 2006. From the evaluation of the proposed\ncriteria for our case study we draw some conclusions. First, a model with a\ncomplex hierarchical structure is globally preferable to one with a complex\nspatio-temporal covariance function. Moreover, in the absence of suitable\ncomputational resources, a model simple in structure and with a simple\ncovariance function can be chosen, since it shows good prediction performance\nat reasonable computational costs.\n", "versions": [{"version": "v1", "created": "Mon, 8 Nov 2010 16:37:51 GMT"}, {"version": "v2", "created": "Mon, 14 Mar 2011 11:43:46 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Cameletti", "Michela", ""], ["Ignaccolo", "Rosaria", ""], ["Bande", "Stefano", ""]]}, {"id": "1011.1987", "submitter": "Anat Sakov", "authors": "Anat Sakov, Ilan Golani, Dina Lipkind, Yoav Benjamini", "title": "High-throughput data analysis in behavior genetics", "comments": "Published in at http://dx.doi.org/10.1214/09-AOAS304 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2010, Vol. 4, No. 2, 743-763", "doi": "10.1214/09-AOAS304", "report-no": "IMS-AOAS-AOAS304", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, a growing need has arisen in different fields for the\ndevelopment of computational systems for automated analysis of large amounts of\ndata (high-throughput). Dealing with nonstandard noise structure and outliers,\nthat could have been detected and corrected in manual analysis, must now be\nbuilt into the system with the aid of robust methods. We discuss such problems\nand present insights and solutions in the context of behavior genetics, where\ndata consists of a time series of locations of a mouse in a circular arena. In\norder to estimate the location, velocity and acceleration of the mouse, and\nidentify stops, we use a nonstandard mix of robust and resistant methods:\nLOWESS and repeated running median. In addition, we argue that protection\nagainst small deviations from experimental protocols can be handled\nautomatically using statistical methods. In our case, it is of biological\ninterest to measure a rodent's distance from the arena's wall, but this measure\nis corrupted if the arena is not a perfect circle, as required in the protocol.\nThe problem is addressed by estimating robustly the actual boundary of the\narena and its center using a nonparametric regression quantile of the\nbehavioral data, with the aid of a fast algorithm developed for that purpose.\n", "versions": [{"version": "v1", "created": "Tue, 9 Nov 2010 07:00:47 GMT"}], "update_date": "2010-11-10", "authors_parsed": [["Sakov", "Anat", ""], ["Golani", "Ilan", ""], ["Lipkind", "Dina", ""], ["Benjamini", "Yoav", ""]]}, {"id": "1011.1996", "submitter": "Michael R. Huber", "authors": "Michael R. Huber, Rodney X. Sturdivant", "title": "Building a model for scoring 20 or more runs in a baseball game", "comments": "Published in at http://dx.doi.org/10.1214/09-AOAS301 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2010, Vol. 4, No. 2, 791-804", "doi": "10.1214/09-AOAS301", "report-no": "IMS-AOAS-AOAS301", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How often can we expect a Major League Baseball team to score at least 20\nruns in a single game? Considered a rare event in baseball, the outcome of\nscoring at least 20 runs in a game has occurred 224 times during regular season\ngames since 1901 in the American and National Leagues. Each outcome is modeled\nas a Poisson process; the time of occurrence of one of these events does not\naffect the next future occurrence. Using various distributions, probabilities\nof events are generated, goodness-of-fit tests are conducted, and predictions\nof future events are offered. The statistical package R is employed for\nanalysis.\n", "versions": [{"version": "v1", "created": "Tue, 9 Nov 2010 07:50:45 GMT"}], "update_date": "2010-11-10", "authors_parsed": [["Huber", "Michael R.", ""], ["Sturdivant", "Rodney X.", ""]]}, {"id": "1011.1999", "submitter": "Dipankar Bandyopadhyay", "authors": "Dipankar Bandyopadhyay, Debajyoti Sinha, Stuart Lipsitz, Elizabeth\n  Letourneau", "title": "Changing approaches of prosecutors towards juvenile repeated\n  sex-offenders: A Bayesian evaluation", "comments": "Published in at http://dx.doi.org/10.1214/09-AOAS295 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2010, Vol. 4, No. 2, 805-829", "doi": "10.1214/09-AOAS295", "report-no": "IMS-AOAS-AOAS295", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing state-wide data bases on prosecutors' decisions about juvenile\noffenders are important, yet often un-explored resources for understanding\nchanges in patterns of judicial decisions over time. We investigate the extent\nand nature of change in judicial behavior toward juveniles following the\nenactment of a new set of mandatory registration policies between 1992 and 1996\nvia analyzing the data on prosecutors' decisions of moving forward for youths\nrepeatedly charged with sexual violence in South Carolina. To analyze this\nlongitudinal binary data, we use a random effects logistic regression model via\nincorporating an unknown change-point year. For convenient physical\ninterpretation, our models allow the proportional odds interpretation of\neffects of the explanatory variables and the change-point year with and without\nconditioning on the youth-specific random effects. As a consequence, the\neffects of the unknown change-point year and other factors can be interpreted\nas changes in both within youth and population averaged odds of moving forward.\nUsing a Bayesian paradigm, we consider various prior opinions about the unknown\nyear of the change in the pattern of prosecutors' decision. Based on the\navailable data, we make posteriori conclusions about whether a change-point has\noccurred between 1992 and 1996 (inclusive), evaluate the degree of confidence\nabout the year of change-point, estimate the magnitude of the effects of the\nchange-point and other factors, and investigate other provocative questions\nabout patterns of prosecutors' decisions over time.\n", "versions": [{"version": "v1", "created": "Tue, 9 Nov 2010 08:14:31 GMT"}], "update_date": "2010-11-10", "authors_parsed": [["Bandyopadhyay", "Dipankar", ""], ["Sinha", "Debajyoti", ""], ["Lipsitz", "Stuart", ""], ["Letourneau", "Elizabeth", ""]]}, {"id": "1011.2005", "submitter": "John Hughes", "authors": "John Hughes, John Fricks, William Hancock", "title": "Likelihood inference for particle location in fluorescence microscopy", "comments": "Published in at http://dx.doi.org/10.1214/09-AOAS299 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2010, Vol. 4, No. 2, 830-848", "doi": "10.1214/09-AOAS299", "report-no": "IMS-AOAS-AOAS299", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a procedure to automatically count and locate the fluorescent\nparticles in a microscopy image. Our procedure employs an approximate\nlikelihood estimator derived from a Poisson random field model for photon\nemission. Estimates of standard errors are generated for each image along with\nthe parameter estimates, and the number of particles in the image is determined\nusing an information criterion and likelihood ratio tests. Realistic\nsimulations show that our procedure is robust and that it leads to accurate\nestimates, both of parameters and of standard errors. This approach improves on\nprevious ad hoc least squares procedures by giving a more explicit stochastic\nmodel for certain fluorescence images and by employing a consistent framework\nfor analysis.\n", "versions": [{"version": "v1", "created": "Tue, 9 Nov 2010 08:49:01 GMT"}], "update_date": "2010-11-10", "authors_parsed": [["Hughes", "John", ""], ["Fricks", "John", ""], ["Hancock", "William", ""]]}, {"id": "1011.2025", "submitter": "Audrey Qiuyan Fu", "authors": "Audrey Qiuyan Fu, Diane P. Genereux, Reinhard St\\\"oger, Charles D.\n  Laird, Matthew Stephens", "title": "Statistical inference of transmission fidelity of DNA methylation\n  patterns over somatic cell divisions in mammals", "comments": "Published in at http://dx.doi.org/10.1214/09-AOAS297 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2010, Vol. 4, No. 2, 871-892", "doi": "10.1214/09-AOAS297", "report-no": "IMS-AOAS-AOAS297", "categories": "stat.AP q-bio.GN q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop Bayesian inference methods for a recently-emerging type of\nepigenetic data to study the transmission fidelity of DNA methylation patterns\nover cell divisions. The data consist of parent-daughter double-stranded DNA\nmethylation patterns with each pattern coming from a single cell and\nrepresented as an unordered pair of binary strings. The data are technically\ndifficult and time-consuming to collect, putting a premium on an efficient\ninference method. Our aim is to estimate rates for the maintenance and de novo\nmethylation events that gave rise to the observed patterns, while accounting\nfor measurement error. We model data at multiple sites jointly, thus using\nwhole-strand information, and considerably reduce confounding between\nparameters. We also adopt a hierarchical structure that allows for variation in\nrates across sites without an explosion in the effective number of parameters.\nOur context-specific priors capture the expected stationarity, or\nnear-stationarity, of the stochastic process that generated the data analyzed\nhere. This expected stationarity is shown to greatly increase the precision of\nthe estimation. Applying our model to a data set collected at the human FMR1\nlocus, we find that measurement errors, generally ignored in similar studies,\noccur at a nontrivial rate (inappropriate bisulfite conversion error: 1.6$%$\nwith 80$%$ CI: 0.9--2.3$%$). Accounting for these errors has a substantial\nimpact on estimates of key biological parameters. The estimated average failure\nof maintenance rate and daughter de novo rate decline from 0.04 to 0.024 and\nfrom 0.14 to 0.07, respectively, when errors are accounted for. Our results\nalso provide evidence that de novo events may occur on both parent and daughter\nstrands: the median parent and daughter de novo rates are 0.08 (80$%$ CI:\n0.04--0.13) and 0.07 (80$%$ CI: 0.04--0.11), respectively.\n", "versions": [{"version": "v1", "created": "Tue, 9 Nov 2010 10:19:42 GMT"}], "update_date": "2016-08-14", "authors_parsed": [["Fu", "Audrey Qiuyan", ""], ["Genereux", "Diane P.", ""], ["St\u00f6ger", "Reinhard", ""], ["Laird", "Charles D.", ""], ["Stephens", "Matthew", ""]]}, {"id": "1011.2037", "submitter": "Woncheol Jang", "authors": "Woncheol Jang, Ji Meng Loh", "title": "Density estimation for grouped data with application to line transect\n  sampling", "comments": "Published in at http://dx.doi.org/10.1214/09-AOAS307 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2010, Vol. 4, No. 2, 893-915", "doi": "10.1214/09-AOAS307", "report-no": "IMS-AOAS-AOAS307", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Line transect sampling is a method used to estimate wildlife populations,\nwith the resulting data often grouped in intervals. Estimating the density from\ngrouped data can be challenging. In this paper we propose a kernel density\nestimator of wildlife population density for such grouped data. Our method uses\na combined cross-validation and smoothed bootstrap approach to select the\noptimal bandwidth for grouped data. Our simulation study shows that with the\nsmoothing parameter selected with this method, the estimated density from\ngrouped data matches the true density more closely than with other approaches.\nUsing smoothed bootstrap, we also construct bias-adjusted confidence intervals\nfor the value of the density at the boundary. We apply the proposed method to\ntwo grouped data sets, one from a wooden stake study where the true density is\nknown, and the other from a survey of kangaroos in Australia.\n", "versions": [{"version": "v1", "created": "Tue, 9 Nov 2010 10:58:34 GMT"}], "update_date": "2010-11-10", "authors_parsed": [["Jang", "Woncheol", ""], ["Loh", "Ji Meng", ""]]}, {"id": "1011.2065", "submitter": "Kristin P. Lennox", "authors": "Kristin P. Lennox, David B. Dahl, Marina Vannucci, Ryan Day, Jerry W.\n  Tsai", "title": "A Dirichlet process mixture of hidden Markov models for protein\n  structure prediction", "comments": "Published in at http://dx.doi.org/10.1214/09-AOAS296 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2010, Vol. 4, No. 2, 916-942", "doi": "10.1214/09-AOAS296", "report-no": "IMS-AOAS-AOAS296", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By providing new insights into the distribution of a protein's torsion\nangles, recent statistical models for this data have pointed the way to more\nefficient methods for protein structure prediction. Most current approaches\nhave concentrated on bivariate models at a single sequence position. There is,\nhowever, considerable value in simultaneously modeling angle pairs at multiple\nsequence positions in a protein. One area of application for such models is in\nstructure prediction for the highly variable loop and turn regions. Such\nmodeling is difficult due to the fact that the number of known protein\nstructures available to estimate these torsion angle distributions is typically\nsmall. Furthermore, the data is \"sparse\" in that not all proteins have angle\npairs at each sequence position. We propose a new semiparametric model for the\njoint distributions of angle pairs at multiple sequence positions. Our model\naccommodates sparse data by leveraging known information about the behavior of\nprotein secondary structure. We demonstrate our technique by predicting the\ntorsion angles in a loop from the globin fold family. Our results show that a\ntemplate-based approach can now be successfully extended to modeling the\nnotoriously difficult loop and turn regions.\n", "versions": [{"version": "v1", "created": "Tue, 9 Nov 2010 12:43:57 GMT"}], "update_date": "2010-11-10", "authors_parsed": [["Lennox", "Kristin P.", ""], ["Dahl", "David B.", ""], ["Vannucci", "Marina", ""], ["Day", "Ryan", ""], ["Tsai", "Jerry W.", ""]]}, {"id": "1011.2077", "submitter": "Kimberly F. Sellers", "authors": "Kimberly F. Sellers, Galit Shmueli", "title": "A flexible regression model for count data", "comments": "Published in at http://dx.doi.org/10.1214/09-AOAS306 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2010, Vol. 4, No. 2, 943-961", "doi": "10.1214/09-AOAS306", "report-no": "IMS-AOAS-AOAS306", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Poisson regression is a popular tool for modeling count data and is applied\nin a vast array of applications from the social to the physical sciences and\nbeyond. Real data, however, are often over- or under-dispersed and, thus, not\nconducive to Poisson regression. We propose a regression model based on the\nConway--Maxwell-Poisson (COM-Poisson) distribution to address this problem. The\nCOM-Poisson regression generalizes the well-known Poisson and logistic\nregression models, and is suitable for fitting count data with a wide range of\ndispersion levels. With a GLM approach that takes advantage of exponential\nfamily properties, we discuss model estimation, inference, diagnostics, and\ninterpretation, and present a test for determining the need for a COM-Poisson\nregression over a standard Poisson regression. We compare the COM-Poisson to\nseveral alternatives and illustrate its advantages and usefulness using three\ndata sets with varying dispersion.\n", "versions": [{"version": "v1", "created": "Tue, 9 Nov 2010 13:32:49 GMT"}], "update_date": "2010-11-10", "authors_parsed": [["Sellers", "Kimberly F.", ""], ["Shmueli", "Galit", ""]]}, {"id": "1011.2087", "submitter": "Qunhua Li", "authors": "Qunhua Li, Michael J. MacCoss, Matthew Stephens", "title": "A nested mixture model for protein identification using mass\n  spectrometry", "comments": "Published in at http://dx.doi.org/10.1214/09-AOAS316 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2010, Vol. 4, No. 2, 962-987", "doi": "10.1214/09-AOAS316", "report-no": "IMS-AOAS-AOAS316", "categories": "stat.AP physics.bio-ph q-bio.BM q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mass spectrometry provides a high-throughput way to identify proteins in\nbiological samples. In a typical experiment, proteins in a sample are first\nbroken into their constituent peptides. The resulting mixture of peptides is\nthen subjected to mass spectrometry, which generates thousands of spectra, each\ncharacteristic of its generating peptide. Here we consider the problem of\ninferring, from these spectra, which proteins and peptides are present in the\nsample. We develop a statistical approach to the problem, based on a nested\nmixture model. In contrast to commonly used two-stage approaches, this model\nprovides a one-stage solution that simultaneously identifies which proteins are\npresent, and which peptides are correctly identified. In this way our model\nincorporates the evidence feedback between proteins and their constituent\npeptides. Using simulated data and a yeast data set, we compare and contrast\nour method with existing widely used approaches (PeptideProphet/ProteinProphet)\nand with a recently published new approach, HSM. For peptide identification,\nour single-stage approach yields consistently more accurate results. For\nprotein identification the methods have similar accuracy in most settings,\nalthough we exhibit some scenarios in which the existing methods perform\npoorly.\n", "versions": [{"version": "v1", "created": "Tue, 9 Nov 2010 13:55:30 GMT"}], "update_date": "2010-11-10", "authors_parsed": [["Li", "Qunhua", ""], ["MacCoss", "Michael J.", ""], ["Stephens", "Matthew", ""]]}, {"id": "1011.2104", "submitter": "Xiaodan Fan", "authors": "Xiaodan Fan, Saumyadipta Pyne, Jun S. Liu", "title": "Bayesian meta-analysis for identifying periodically expressed genes in\n  fission yeast cell cycle", "comments": "Published in at http://dx.doi.org/10.1214/09-AOAS300 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2010, Vol. 4, No. 2, 988-1013", "doi": "10.1214/09-AOAS300", "report-no": "IMS-AOAS-AOAS300", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The effort to identify genes with periodic expression during the cell cycle\nfrom genome-wide microarray time series data has been ongoing for a decade.\nHowever, the lack of rigorous modeling of periodic expression as well as the\nlack of a comprehensive model for integrating information across genes and\nexperiments has impaired the effort for the accurate identification of\nperiodically expressed genes. To address the problem, we introduce a Bayesian\nmodel to integrate multiple independent microarray data sets from three recent\ngenome-wide cell cycle studies on fission yeast. A hierarchical model was used\nfor data integration. In order to facilitate an efficient Monte Carlo sampling\nfrom the joint posterior distribution, we develop a novel Metropolis--Hastings\ngroup move. A surprising finding from our integrated analysis is that more than\n40% of the genes in fission yeast are significantly periodically expressed,\ngreatly enhancing the reported 10--15% of the genes in the current literature.\nIt calls for a reconsideration of the periodically expressed gene detection\nproblem.\n", "versions": [{"version": "v1", "created": "Tue, 9 Nov 2010 14:47:11 GMT"}], "update_date": "2010-11-10", "authors_parsed": [["Fan", "Xiaodan", ""], ["Pyne", "Saumyadipta", ""], ["Liu", "Jun S.", ""]]}, {"id": "1011.2288", "submitter": "Maria L. Rizzo", "authors": "Maria L. Rizzo, G\\'abor J. Sz\\'ekely", "title": "DISCO analysis: A nonparametric extension of analysis of variance", "comments": "Published in at http://dx.doi.org/10.1214/09-AOAS245 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2010, Vol. 4, No. 2, 1034-1055", "doi": "10.1214/09-AOAS245", "report-no": "IMS-AOAS-AOAS245", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In classical analysis of variance, dispersion is measured by considering\nsquared distances of sample elements from the sample mean. We consider a\nmeasure of dispersion for univariate or multivariate response based on all\npairwise distances between-sample elements, and derive an analogous distance\ncomponents (DISCO) decomposition for powers of distance in $(0,2]$. The ANOVA F\nstatistic is obtained when the index (exponent) is 2. For each index in\n$(0,2)$, this decomposition determines a nonparametric test for the\nmulti-sample hypothesis of equal distributions that is statistically consistent\nagainst general alternatives.\n", "versions": [{"version": "v1", "created": "Wed, 10 Nov 2010 08:02:49 GMT"}], "update_date": "2010-11-11", "authors_parsed": [["Rizzo", "Maria L.", ""], ["Sz\u00e9kely", "G\u00e1bor J.", ""]]}, {"id": "1011.2295", "submitter": "Wei Sun", "authors": "Wei Sun, Fred A. Wright", "title": "A geometric interpretation of the permutation $p$-value and its\n  application in eQTL studies", "comments": "Published in at http://dx.doi.org/10.1214/09-AOAS298 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2010, Vol. 4, No. 2, 1014-1033", "doi": "10.1214/09-AOAS298", "report-no": "IMS-AOAS-AOAS298", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Permutation $p$-values have been widely used to assess the significance of\nlinkage or association in genetic studies. However, the application in\nlarge-scale studies is hindered by a heavy computational burden. We propose a\ngeometric interpretation of permutation $p$-values, and based on this geometric\ninterpretation, we develop an efficient permutation $p$-value estimation method\nin the context of regression with binary predictors. An application to a study\nof gene expression quantitative trait loci (eQTL) shows that our method\nprovides reliable estimates of permutation $p$-values while requiring less than\n5% of the computational time compared with direct permutations. In fact, our\nmethod takes a constant time to estimate permutation $p$-values, no matter how\nsmall the $p$-value. Our method enables a study of the relationship between\nnominal $p$-values and permutation $p$-values in a wide range, and provides a\ngeometric perspective on the effective number of independent tests.\n", "versions": [{"version": "v1", "created": "Wed, 10 Nov 2010 08:18:23 GMT"}], "update_date": "2010-11-11", "authors_parsed": [["Sun", "Wei", ""], ["Wright", "Fred A.", ""]]}, {"id": "1011.2315", "submitter": "Martin Slawski", "authors": "Martin Slawski, Wolfgang zu Castell, Gerhard Tutz", "title": "Feature selection guided by structural information", "comments": "Published in at http://dx.doi.org/10.1214/09-AOAS302 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2010, Vol. 4, No. 2, 1056-1080", "doi": "10.1214/09-AOAS302", "report-no": "IMS-AOAS-AOAS302", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In generalized linear regression problems with an abundant number of\nfeatures, lasso-type regularization which imposes an $\\ell^1$-constraint on the\nregression coefficients has become a widely established technique. Deficiencies\nof the lasso in certain scenarios, notably strongly correlated design, were\nunmasked when Zou and Hastie [J. Roy. Statist. Soc. Ser. B 67 (2005) 301--320]\nintroduced the elastic net. In this paper we propose to extend the elastic net\nby admitting general nonnegative quadratic constraints as a second form of\nregularization. The generalized ridge-type constraint will typically make use\nof the known association structure of features, for example, by using temporal-\nor spatial closeness. We study properties of the resulting \"structured elastic\nnet\" regression estimation procedure, including basic asymptotics and the issue\nof model selection consistency. In this vein, we provide an analog to the\nso-called \"irrepresentable condition\" which holds for the lasso. Moreover, we\noutline algorithmic solutions for the structured elastic net within the\ngeneralized linear model family. The rationale and the performance of our\napproach is illustrated by means of simulated and real world data, with a focus\non signal regression.\n", "versions": [{"version": "v1", "created": "Wed, 10 Nov 2010 08:51:05 GMT"}], "update_date": "2010-11-11", "authors_parsed": [["Slawski", "Martin", ""], ["Castell", "Wolfgang zu", ""], ["Tutz", "Gerhard", ""]]}, {"id": "1011.2322", "submitter": "Stergios B. Fotopoulos", "authors": "Stergios B. Fotopoulos, Venkata K. Jandhyala, Elena Khapalova", "title": "Exact asymptotic distribution of change-point mle for change in the mean\n  of Gaussian sequences", "comments": "Published in at http://dx.doi.org/10.1214/09-AOAS294 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2010, Vol. 4, No. 2, 1081-1104", "doi": "10.1214/09-AOAS294", "report-no": "IMS-AOAS-AOAS294", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive exact computable expressions for the asymptotic distribution of the\nchange-point mle when a change in the mean occurred at an unknown point of a\nsequence of time-ordered independent Gaussian random variables. The derivation,\nwhich assumes that nuisance parameters such as the amount of change and\nvariance are known, is based on ladder heights of Gaussian random walks hitting\nthe half-line. We then show that the exact distribution easily extends to the\ndistribution of the change-point mle when a change occurs in the mean vector of\na multivariate Gaussian process. We perform simulations to examine the accuracy\nof the derived distribution when nuisance parameters have to be estimated as\nwell as robustness of the derived distribution to deviations from Gaussianity.\nThrough simulations, we also compare it with the well-known conditional\ndistribution of the mle, which may be interpreted as a Bayesian solution to the\nchange-point problem. Finally, we apply the derived methodology to monthly\naverages of water discharges of the Nacetinsky creek, Germany.\n", "versions": [{"version": "v1", "created": "Wed, 10 Nov 2010 09:30:01 GMT"}], "update_date": "2010-11-11", "authors_parsed": [["Fotopoulos", "Stergios B.", ""], ["Jandhyala", "Venkata K.", ""], ["Khapalova", "Elena", ""]]}, {"id": "1011.2328", "submitter": "Jan van den Brakel", "authors": "Jan van den Brakel, Joeri Roels", "title": "Intervention analysis with state-space models to estimate\n  discontinuities due to a survey redesign", "comments": "Published in at http://dx.doi.org/10.1214/09-AOAS305 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2010, Vol. 4, No. 2, 1105-1138", "doi": "10.1214/09-AOAS305", "report-no": "IMS-AOAS-AOAS305", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important quality aspect of official statistics produced by national\nstatistical institutes is comparability over time. To maintain uninterrupted\ntime series, surveys conducted by national statistical institutes are often\nkept unchanged as long as possible. To improve the quality or efficiency of a\nsurvey process, however, it remains inevitable to adjust methods or redesign\nthis process from time to time. Adjustments in the survey process generally\naffect survey characteristics such as response bias and therefore have a\nsystematic effect on the parameter estimates of a sample survey. Therefore, it\nis important that the effects of a survey redesign on the estimated series are\nexplained and quantified. In this paper a structural time series model is\napplied to estimate discontinuities in series of the Dutch survey on social\nparticipation and environmental consciousness due to a redesign of the\nunderlying survey process.\n", "versions": [{"version": "v1", "created": "Wed, 10 Nov 2010 09:58:08 GMT"}], "update_date": "2010-11-11", "authors_parsed": [["Brakel", "Jan van den", ""], ["Roels", "Joeri", ""]]}, {"id": "1011.2553", "submitter": "Luke Bornn", "authors": "Luke Bornn, Gavin Shaddick, and James V Zidek", "title": "Modeling Non-Stationary Processes Through Dimension Expansion", "comments": null, "journal-ref": "Bornn, L., Shaddick, G., Zidek, J. (2012) Modelling Nonstationary\n  Processes Through Dimension Expansion. Journal of the American Statistical\n  Association Vol. 107, No. 497, 281-289", "doi": null, "report-no": null, "categories": "stat.ME stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel approach to modeling nonstationary spatial\nfields. The proposed method works by expanding the geographic plane over which\nthese processes evolve into higher dimensional spaces, transforming and\nclarifying complex patterns in the physical plane. By combining aspects of\nmulti-dimensional scaling, group lasso, and latent variables models, a\ndimensionally sparse projection is found in which the originally nonstationary\nfield exhibits stationarity. Following a comparison with existing methods in a\nsimulated environment, dimension expansion is studied on a classic test-bed\ndata set historically used to study nonstationary models. Following this, we\nexplore the use of dimension expansion in modeling air pollution in the United\nKingdom, a process known to be strongly influenced by rural/urban effects,\namongst others, which gives rise to a nonstationary field.\n", "versions": [{"version": "v1", "created": "Thu, 11 Nov 2010 04:41:42 GMT"}, {"version": "v2", "created": "Thu, 2 Jun 2011 21:37:56 GMT"}], "update_date": "2013-01-22", "authors_parsed": [["Bornn", "Luke", ""], ["Shaddick", "Gavin", ""], ["Zidek", "James V", ""]]}, {"id": "1011.2649", "submitter": "Andrea Tancredi", "authors": "Andrea Tancredi, Brunero Liseo", "title": "A hierarchical Bayesian approach to record linkage and population size\n  problems", "comments": "Published in at http://dx.doi.org/10.1214/10-AOAS447 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2011, Vol. 5, No. 2B, 1553-1585", "doi": "10.1214/10-AOAS447", "report-no": "IMS-AOAS-AOAS447", "categories": "stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose and illustrate a hierarchical Bayesian approach for matching\nstatistical records observed on different occasions. We show how this model can\nbe profitably adopted both in record linkage problems and in capture--recapture\nsetups, where the size of a finite population is the real object of interest.\nThere are at least two important differences between the proposed model-based\napproach and the current practice in record linkage. First, the statistical\nmodel is built up on the actually observed categorical variables and no\nreduction (to 0--1 comparisons) of the available information takes place.\nSecond, the hierarchical structure of the model allows a two-way propagation of\nthe uncertainty between the parameter estimation step and the matching\nprocedure so that no plug-in estimates are used and the correct uncertainty is\naccounted for both in estimating the population size and in performing the\nrecord linkage. We illustrate and motivate our proposal through a real data\nexample and simulations.\n", "versions": [{"version": "v1", "created": "Thu, 11 Nov 2010 13:33:20 GMT"}, {"version": "v2", "created": "Mon, 13 Dec 2010 14:15:12 GMT"}, {"version": "v3", "created": "Thu, 28 Jul 2011 12:10:46 GMT"}], "update_date": "2011-07-29", "authors_parsed": [["Tancredi", "Andrea", ""], ["Liseo", "Brunero", ""]]}, {"id": "1011.2851", "submitter": "George Woodworth", "authors": "George Woodworth, Joseph Kadane", "title": "Age- and time-varying proportional hazards models for employment\n  discrimination", "comments": "Published in at http://dx.doi.org/10.1214/10-AOAS330 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2010, Vol. 4, No. 3, 1139-1157", "doi": "10.1214/10-AOAS330", "report-no": "IMS-AOAS-AOAS330", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use a discrete-time proportional hazards model of time to involuntary\nemployment termination. This model enables us to examine both the continuous\neffect of the age of an employee and whether that effect has varied over time,\ngeneralizing earlier work [Kadane and Woodworth J. Bus. Econom. Statist. 22\n(2004) 182--193]. We model the log hazard surface (over age and time) as a\nthin-plate spline, a Bayesian smoothness-prior implementation of penalized\nlikelihood methods of surface-fitting [Wahba (1990) Spline Models for\nObservational Data. SIAM]. The nonlinear component of the surface has only two\nparameters, smoothness and anisotropy. The first, a scale parameter, governs\nthe overall smoothness of the surface, and the second, anisotropy, controls the\nrelative smoothness over time and over age. For any fixed value of the\nanisotropy parameter, the prior is equivalent to a Gaussian process with linear\ndrift over the time--age plane with easily computed eigenvectors and\neigenvalues that depend only on the configuration of data in the time--age\nplane and the anisotropy parameter. This model has application to legal cases\nin which a company is charged with disproportionately disadvantaging older\nworkers when deciding whom to terminate. We illustrate the application of the\nmodeling approach using data from an actual discrimination case.\n", "versions": [{"version": "v1", "created": "Fri, 12 Nov 2010 09:07:34 GMT"}], "update_date": "2010-11-15", "authors_parsed": [["Woodworth", "George", ""], ["Kadane", "Joseph", ""]]}, {"id": "1011.2858", "submitter": "Xiaoquan Wen", "authors": "Xiaoquan Wen, Matthew Stephens", "title": "Using linear predictors to impute allele frequencies from summary or\n  pooled genotype data", "comments": "Published in at http://dx.doi.org/10.1214/10-AOAS338 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2010, Vol. 4, No. 3, 1158-1182", "doi": "10.1214/10-AOAS338", "report-no": "IMS-AOAS-AOAS338", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently-developed genotype imputation methods are a powerful tool for\ndetecting untyped genetic variants that affect disease susceptibility in\ngenetic association studies. However, existing imputation methods require\nindividual-level genotype data, whereas, in practice, it is often the case that\nonly summary data are available. For example, this may occur because, for\nreasons of privacy or politics, only summary data are made available to the\nresearch community at large; or because only summary data are collected, as in\nDNA pooling experiments. In this article we introduce a new statistical method\nthat can accurately infer the frequencies of untyped genetic variants in these\nsettings, and indeed substantially improve frequency estimates at typed\nvariants in pooling experiments where observations are noisy. Our approach,\nwhich predicts each allele frequency using a linear combination of observed\nfrequencies, is statistically straightforward, and related to a long history of\nthe use of linear methods for estimating missing values (e.g., Kriging). The\nmain statistical novelty is our approach to regularizing the covariance matrix\nestimates, and the resulting linear predictors, which is based on methods from\npopulation genetics. We find that, besides being both fast and\nflexible---allowing new problems to be tackled that cannot be handled by\nexisting imputation approaches purpose-built for the genetic context---these\nlinear methods are also very accurate. Indeed, imputation accuracy using this\napproach is similar to that obtained by state-of-the-art imputation methods\nthat use individual-level data, but at a fraction of the computational cost.\n", "versions": [{"version": "v1", "created": "Fri, 12 Nov 2010 09:39:16 GMT"}], "update_date": "2010-11-15", "authors_parsed": [["Wen", "Xiaoquan", ""], ["Stephens", "Matthew", ""]]}, {"id": "1011.2877", "submitter": "Gengxin Li", "authors": "Gengxin Li, Yuehua Cui", "title": "A general statistical framework for dissecting parent-of-origin effects\n  underlying endosperm traits in flowering plants", "comments": "Published in at http://dx.doi.org/10.1214/09-AOAS323 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2010, Vol. 4, No. 3, 1214-1233", "doi": "10.1214/09-AOAS323", "report-no": "IMS-AOAS-AOAS323", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Genomic imprinting has been thought to play an important role in seed\ndevelopment in flowering plants. Seed in a flowering plant normally contains\ndiploid embryo and triploid endosperm. Empirical studies have shown that some\neconomically important endosperm traits are genetically controlled by imprinted\ngenes. However, the exact number and location of the imprinted genes are\nlargely unknown due to the lack of efficient statistical mapping methods. Here\nwe propose a general statistical variance components framework by utilizing the\nnatural information of sex-specific allelic sharing among sibpairs in line\ncrosses, to map imprinted quantitative trait loci (iQTL) underlying endosperm\ntraits. We propose a new variance components partition method considering the\nunique characteristic of the triploid endosperm genome, and develop a\nrestricted maximum likelihood estimation method in an interval scan for\nestimating and testing genome-wide iQTL effects. Cytoplasmic maternal effect\nwhich is thought to have primary influences on yield and grain quality is also\nconsidered when testing for genomic imprinting. Extension to multiple iQTL\nanalysis is proposed. Asymptotic distribution of the likelihood ratio test for\ntesting the variance components under irregular conditions are studied. Both\nsimulation study and real data analysis indicate good performance and\npowerfulness of the developed approach.\n", "versions": [{"version": "v1", "created": "Fri, 12 Nov 2010 10:57:35 GMT"}], "update_date": "2010-11-15", "authors_parsed": [["Li", "Gengxin", ""], ["Cui", "Yuehua", ""]]}, {"id": "1011.2890", "submitter": "Brian Kriegler", "authors": "Brian Kriegler, Richard Berk", "title": "Small area estimation of the homeless in Los Angeles: An application of\n  cost-sensitive stochastic gradient boosting", "comments": "Published in at http://dx.doi.org/10.1214/10-AOAS328 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2010, Vol. 4, No. 3, 1234-1255", "doi": "10.1214/10-AOAS328", "report-no": "IMS-AOAS-AOAS328", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many metropolitan areas efforts are made to count the homeless to ensure\nproper provision of social services. Some areas are very large, which makes\nspatial sampling a viable alternative to an enumeration of the entire terrain.\nCounts are observed in sampled regions but must be imputed in unvisited areas.\nAlong with the imputation process, the costs of underestimating and\noverestimating may be different. For example, if precise estimation in areas\nwith large homeless c ounts is critical, then underestimation should be\npenalized more than overestimation in the loss function. We analyze data from\nthe 2004--2005 Los Angeles County homeless study using an augmentation of $L_1$\nstochastic gradient boosting that can weight overestimates and underestimates\nasymmetrically. We discuss our choice to utilize stochastic gradient boosting\nover other function estimation procedures. In-sample fitted and out-of-sample\nimputed values, as well as relationships between the response and predictors,\nare analyzed for various cost functions. Practical usage and policy\nimplications of these results are discussed briefly.\n", "versions": [{"version": "v1", "created": "Fri, 12 Nov 2010 12:05:07 GMT"}], "update_date": "2010-11-15", "authors_parsed": [["Kriegler", "Brian", ""], ["Berk", "Richard", ""]]}, {"id": "1011.2895", "submitter": "Siddhartha R. Dalal", "authors": "Siddhartha R. Dalal, Bing Han", "title": "Detection of radioactive material entering national ports: A Bayesian\n  approach to radiation portal data", "comments": "Published in at http://dx.doi.org/10.1214/10-AOAS334 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2010, Vol. 4, No. 3, 1256-1271", "doi": "10.1214/10-AOAS334", "report-no": "IMS-AOAS-AOAS334", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given the potential for illicit nuclear material being used for terrorism,\nmost ports now inspect a large number of goods entering national borders for\nradioactive cargo. The U.S. Department of Homeland Security is moving toward\none hundred percent inspection of all containers entering the U.S. at various\nports of entry for nuclear material. We propose a Bayesian classification\napproach for the real-time data collected by the inline Polyvinyl Toluene\nradiation portal monitors. We study the computational and asymptotic properties\nof the proposed method and demonstrate its efficacy in simulations. Given data\navailable to the authorities, it should be feasible to implement this approach\nin practice.\n", "versions": [{"version": "v1", "created": "Fri, 12 Nov 2010 12:22:36 GMT"}], "update_date": "2010-11-15", "authors_parsed": [["Dalal", "Siddhartha R.", ""], ["Han", "Bing", ""]]}, {"id": "1011.2901", "submitter": "Karl J. Friston", "authors": "James M. Kilner, Karl J. Friston", "title": "Topological inference for EEG and MEG", "comments": "Published in at http://dx.doi.org/10.1214/10-AOAS337 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2010, Vol. 4, No. 3, 1272-1290", "doi": "10.1214/10-AOAS337", "report-no": "IMS-AOAS-AOAS337", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neuroimaging produces data that are continuous in one or more dimensions.\nThis calls for an inference framework that can handle data that approximate\nfunctions of space, for example, anatomical images, time--frequency maps and\ndistributed source reconstructions of electromagnetic recordings over time.\nStatistical parametric mapping (SPM) is the standard framework for whole-brain\ninference in neuroimaging: SPM uses random field theory to furnish $p$-values\nthat are adjusted to control family-wise error or false discovery rates, when\nmaking topological inferences over large volumes of space. Random field theory\nregards data as realizations of a continuous process in one or more dimensions.\nThis contrasts with classical approaches like the Bonferroni correction, which\nconsider images as collections of discrete samples with no continuity\nproperties (i.e., the probabilistic behavior at one point in the image does not\ndepend on other points). Here, we illustrate how random field theory can be\napplied to data that vary as a function of time, space or frequency. We\nemphasize how topological inference of this sort is invariant to the geometry\nof the manifolds on which data are sampled. This is particularly useful in\nelectromagnetic studies that often deal with very smooth data on scalp or\ncortical meshes. This application illustrates the versatility and simplicity of\nrandom field theory and the seminal contributions of Keith Worsley\n(1951--2009), a key architect of topological inference.\n", "versions": [{"version": "v1", "created": "Fri, 12 Nov 2010 13:04:18 GMT"}], "update_date": "2010-11-15", "authors_parsed": [["Kilner", "James M.", ""], ["Friston", "Karl J.", ""]]}, {"id": "1011.2905", "submitter": "Natalie Shlomo", "authors": "Natalie Shlomo, Chris Skinner", "title": "Assessing the protection provided by misclassification-based disclosure\n  limitation methods for survey microdata", "comments": "Published in at http://dx.doi.org/10.1214/09-AOAS317 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2010, Vol. 4, No. 3, 1291-1310", "doi": "10.1214/09-AOAS317", "report-no": "IMS-AOAS-AOAS317", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Government statistical agencies often apply statistical disclosure limitation\ntechniques to survey microdata to protect the confidentiality of respondents.\nThere is a need for valid and practical ways to assess the protection provided.\nThis paper develops some simple methods for disclosure limitation techniques\nwhich perturb the values of categorical identifying variables. The methods are\napplied in numerical experiments based upon census data from the United Kingdom\nwhich are subject to two perturbation techniques: data swapping (random and\ntargeted) and the post randomization method. Some simplifying approximations to\nthe measure of risk are found to work well in capturing the impacts of these\ntechniques. These approximations provide simple extensions of existing risk\nassessment methods based upon Poisson log-linear models. A numerical experiment\nis also undertaken to assess the impact of multivariate misclassification with\nan increasing number of identifying variables. It is found that the\nmisclassification dominates the usual monotone increasing relationship between\nthis number and risk so that the risk eventually declines, implying less\nsensitivity of risk to choice of identifying variables. The methods developed\nin this paper may also be used to obtain more realistic assessments of risk\nwhich take account of the kinds of measurement and other nonsampling errors\ncommonly arising in surveys.\n", "versions": [{"version": "v1", "created": "Fri, 12 Nov 2010 13:32:43 GMT"}], "update_date": "2010-11-15", "authors_parsed": [["Shlomo", "Natalie", ""], ["Skinner", "Chris", ""]]}, {"id": "1011.2924", "submitter": "Stefano Bellucci", "authors": "Neeraj Gupta, Bhupendra Nath Tiwari and Stefano Bellucci", "title": "Geometric Design and Stability of Power Networks", "comments": "23 pages, 11 figures, Keywords: Correlation; Geometry; Power Flow;\n  Network; Stability", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP math-ph math.MP physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  From the perspective of the network theory, the present work illustrates how\nthe parametric intrinsic geometric description exhibits an exact set of pair\ncorrection functions and global correlation volume with and without the\ninclusion of the imaginary power flow. The Gaussian fluctuations about the\nequilibrium basis accomplish a well-defined, non-degenerate, curved regular\nintrinsic Riemannian surfaces for the purely real and the purely imaginary\npower flows and their linear combinations. An explicit computation demonstrates\nthat the underlying real and imaginary power correlations involve ordinary\nsummations of the power factors, with and without their joint effects. Novel\naspect of the intrinsic geometry constitutes a stable design for the power\nsystems.\n", "versions": [{"version": "v1", "created": "Fri, 12 Nov 2010 14:45:03 GMT"}], "update_date": "2010-11-15", "authors_parsed": [["Gupta", "Neeraj", ""], ["Tiwari", "Bhupendra Nath", ""], ["Bellucci", "Stefano", ""]]}, {"id": "1011.2929", "submitter": "Stefano Bellucci", "authors": "N. Gupta, B. N. Tiwari, and S. Bellucci", "title": "Intrinsic Geometric Analysis of the Network Reliability and Voltage\n  Stability", "comments": "8 pages, 4 figures, 2 tables, Index Terms -- Circuit modeling,\n  geometric modeling, parameter space method, power system reliability, power\n  system stability, transmission planning, nonlinear methods, geometric\n  controls, components optimization", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP math-ph math.MP physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the intrinsic geometric model for the solution of power\nsystem planning and its operation. This problem is large-scale and nonlinear,\nin general. Thus, we have developed the intrinsic geometric model for the\nnetwork reliability and voltage stability, and examined it for the IEEE 5 bus\nsystem. The robustness of the proposed model is illustrated by introducing\nvariations of the network parameters. Exact analytical results show the\naccuracy as well as the efficiency of the proposed solution technique.\n", "versions": [{"version": "v1", "created": "Fri, 12 Nov 2010 14:52:23 GMT"}], "update_date": "2010-11-15", "authors_parsed": [["Gupta", "N.", ""], ["Tiwari", "B. N.", ""], ["Bellucci", "S.", ""]]}, {"id": "1011.3107", "submitter": "Francesco Russo", "authors": "Nadia Belaribi (LAGA, ENSTA Paris Tech), Fran\\c{c}ois Cuvelier (LAGA),\n  Francesco Russo (ENSTA Paris Tech, INRIA Rocquencourt)", "title": "A probabilistic algorithm approximating solutions of a singular PDE of\n  porous media type", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.NA stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The object of this paper is a one-dimensional generalized porous media\nequation (PDE) with possibly discontinuous coefficient $\\beta$, which is\nwell-posed as an evolution problem in $L^1(\\mathbb{R})$. In some recent papers\nof Blanchard et alia and Barbu et alia, the solution was represented by the\nsolution of a non-linear stochastic differential equation in law if the initial\ncondition is a bounded integrable function. We first extend this result, at\nleast when $\\beta$ is continuous and the initial condition is only integrable\nwith some supplementary technical assumption. The main purpose of the article\nconsists in introducing and implementing a stochastic particle algorithm to\napproach the solution to (PDE) which also fits in the case when $\\beta$ is\npossibly irregular, to predict some long-time behavior of the solution and in\ncomparing with some recent numerical deterministic techniques.\n", "versions": [{"version": "v1", "created": "Sat, 13 Nov 2010 06:24:02 GMT"}], "update_date": "2010-11-17", "authors_parsed": [["Belaribi", "Nadia", "", "LAGA, ENSTA Paris Tech"], ["Cuvelier", "Fran\u00e7ois", "", "LAGA"], ["Russo", "Francesco", "", "ENSTA Paris Tech, INRIA Rocquencourt"]]}, {"id": "1011.3241", "submitter": "Fionn Murtagh", "authors": "Fionn Murtagh, Adam Ganz and Joe Reddington", "title": "New Methods of Analysis of Narrative and Semantics in Support of\n  Interactivity", "comments": "17 pages, 6 figures", "journal-ref": "Entertainment Computing, 2, 115-121, 2011", "doi": "10.1016/j.entcom.2010.12.008", "report-no": null, "categories": "cs.AI cs.HC stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our work has focused on support for film or television scriptwriting. Since\nthis involves potentially varied story-lines, we note the implicit or latent\nsupport for interactivity. Furthermore the film, television, games, publishing\nand other sectors are converging, so that cross-over and re-use of one form of\nproduct in another of these sectors is ever more common. Technically our work\nhas been largely based on mathematical algorithms for data clustering and\ndisplay. Operationally, we also discuss how our algorithms can support\ncollective, distributed problem-solving.\n", "versions": [{"version": "v1", "created": "Sun, 14 Nov 2010 17:57:40 GMT"}], "update_date": "2011-07-07", "authors_parsed": [["Murtagh", "Fionn", ""], ["Ganz", "Adam", ""], ["Reddington", "Joe", ""]]}, {"id": "1011.3309", "submitter": "Kingshuk Roy Choudhury", "authors": "Kingshuk Roy Choudhury, Limian Zheng, John J. Mackrill", "title": "Analysis of spatial distribution of marker expression in cells using\n  boundary distance plots", "comments": "Published in at http://dx.doi.org/10.1214/10-AOAS340 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2010, Vol. 4, No. 3, 1365-1382", "doi": "10.1214/10-AOAS340", "report-no": "IMS-AOAS-AOAS340", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Boundary distance (BD) plotting is a technique for making orientation\ninvariant comparisons of the spatial distribution of biochemical markers within\nand across cells/nuclei. Marker expression is aggregated over points with the\nsame distance from the boundary. We present a suite of tools for improved data\nanalysis and statistical inference using BD plotting. BD is computed using the\nEuclidean distance transform after presmoothing and oversampling of nuclear\nboundaries. Marker distribution profiles are averaged using smoothing with\nlinearly decreasing bandwidth. Average expression curves are scaled and\nregistered by x-axis dilation to compensate for uneven lighting and errors in\nnuclear boundary marking. Penalized discriminant analysis is used to\ncharacterize the quality of separation between average marker distributions. An\nadaptive piecewise linear model is used to compare expression gradients in\nintra, peri and extra nuclear zones. The techniques are illustrated by the\nfollowing: (a) a two sample problem involving a pair of voltage gated calcium\nchannels (Cav1.2 and AB70) marked in different cells; (b) a paired sample\nproblem of calcium channels (Y1F4 and RyR1) marked in the same cell.\n", "versions": [{"version": "v1", "created": "Mon, 15 Nov 2010 08:24:38 GMT"}], "update_date": "2010-11-16", "authors_parsed": [["Choudhury", "Kingshuk Roy", ""], ["Zheng", "Limian", ""], ["Mackrill", "John J.", ""]]}, {"id": "1011.3319", "submitter": "David I. Warton", "authors": "David I. Warton, Leah C. Shepherd", "title": "Poisson point process models solve the \"pseudo-absence problem\" for\n  presence-only data in ecology", "comments": "Published in at http://dx.doi.org/10.1214/10-AOAS331 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2010, Vol. 4, No. 3, 1383-1402", "doi": "10.1214/10-AOAS331", "report-no": "IMS-AOAS-AOAS331", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Presence-only data, point locations where a species has been recorded as\nbeing present, are often used in modeling the distribution of a species as a\nfunction of a set of explanatory variables---whether to map species occurrence,\nto understand its association with the environment, or to predict its response\nto environmental change. Currently, ecologists most commonly analyze\npresence-only data by adding randomly chosen \"pseudo-absences\" to the data such\nthat it can be analyzed using logistic regression, an approach which has\nweaknesses in model specification, in interpretation, and in implementation. To\naddress these issues, we propose Poisson point process modeling of the\nintensity of presences. We also derive a link between the proposed approach and\nlogistic regression---specifically, we show that as the number of\npseudo-absences increases (in a regular or uniform random arrangement),\nlogistic regression slope parameters and their standard errors converge to\nthose of the corresponding Poisson point process model. We discuss the\npractical implications of these results. In particular, point process modeling\noffers a framework for choice of the number and location of pseudo-absences,\nboth of which are currently chosen by ad hoc and sometimes ineffective methods\nin ecology, a point which we illustrate by example.\n", "versions": [{"version": "v1", "created": "Mon, 15 Nov 2010 09:16:31 GMT"}], "update_date": "2010-11-16", "authors_parsed": [["Warton", "David I.", ""], ["Shepherd", "Leah C.", ""]]}, {"id": "1011.3327", "submitter": "Avishek Chakraborty", "authors": "Avishek Chakraborty, Alan E. Gelfand, Adam M. Wilson, Andrew M.\n  Latimer, John A. Silander Jr", "title": "Modeling large scale species abundance with latent spatial processes", "comments": "Published in at http://dx.doi.org/10.1214/10-AOAS335 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2010, Vol. 4, No. 3, 1403-1429", "doi": "10.1214/10-AOAS335", "report-no": "IMS-AOAS-AOAS335", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling species abundance patterns using local environmental features is an\nimportant, current problem in ecology. The Cape Floristic Region (CFR) in South\nAfrica is a global hot spot of diversity and endemism, and provides a rich\nclass of species abundance data for such modeling. Here, we propose a\nmulti-stage Bayesian hierarchical model for explaining species abundance over\nthis region. Our model is specified at areal level, where the CFR is divided\ninto roughly $37{,}000$ one minute grid cells; species abundance is observed at\nsome locations within some cells. The abundance values are ordinally\ncategorized. Environmental and soil-type factors, likely to influence the\nabundance pattern, are included in the model. We formulate the empirical\nabundance pattern as a degraded version of the potential pattern, with the\ndegradation effect accomplished in two stages. First, we adjust for land use\ntransformation and then we adjust for measurement error, hence\nmisclassification error, to yield the observed abundance classifications. An\nimportant point in this analysis is that only $28%$ of the grid cells have been\nsampled and that, for sampled grid cells, the number of sampled locations\nranges from one to more than one hundred. Still, we are able to develop\npotential and transformed abundance surfaces over the entire region. In the\nhierarchical framework, categorical abundance classifications are induced by\ncontinuous latent surfaces. The degradation model above is built on the latent\nscale. On this scale, an areal level spatial regression model was used for\nmodeling the dependence of species abundance on the environmental factors.\n", "versions": [{"version": "v1", "created": "Mon, 15 Nov 2010 09:47:42 GMT"}, {"version": "v2", "created": "Tue, 23 Nov 2010 13:45:37 GMT"}], "update_date": "2010-11-24", "authors_parsed": [["Chakraborty", "Avishek", ""], ["Gelfand", "Alan E.", ""], ["Wilson", "Adam M.", ""], ["Latimer", "Andrew M.", ""], ["Silander", "John A.", "Jr"]]}, {"id": "1011.3333", "submitter": "Holger Dette", "authors": "Holger Dette, Andrey Pepelyshev, Tim Holland-Letz", "title": "Optimal designs for random effect models with correlated errors with\n  applications in population pharmacokinetics", "comments": "Published in at http://dx.doi.org/10.1214/09-AOAS324 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2010, Vol. 4, No. 3, 1430-1450", "doi": "10.1214/09-AOAS324", "report-no": "IMS-AOAS-AOAS324", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of constructing optimal designs for population\npharmacokinetics which use random effect models. It is common practice in the\ndesign of experiments in such studies to assume uncorrelated errors for each\nsubject. In the present paper a new approach is introduced to determine\nefficient designs for nonlinear least squares estimation which addresses the\nproblem of correlation between observations corresponding to the same subject.\nWe use asymptotic arguments to derive optimal design densities, and the designs\nfor finite sample sizes are constructed from the quantiles of the corresponding\noptimal distribution function. It is demonstrated that compared to the optimal\nexact designs, whose determination is a hard numerical problem, these designs\nare very efficient. Alternatively, the designs derived from asymptotic theory\ncould be used as starting designs for the numerical computation of exact\noptimal designs. Several examples of linear and nonlinear models are presented\nin order to illustrate the methodology. In particular, it is demonstrated that\nnaively chosen equally spaced designs may lead to less accurate estimation.\n", "versions": [{"version": "v1", "created": "Mon, 15 Nov 2010 10:29:24 GMT"}], "update_date": "2010-11-16", "authors_parsed": [["Dette", "Holger", ""], ["Pepelyshev", "Andrey", ""], ["Holland-Letz", "Tim", ""]]}, {"id": "1011.3351", "submitter": "Andrea S. Foulkes", "authors": "Andrea S. Foulkes, Livio Azzoni, Xiaohong Li, Margaret A. Johnson,\n  Colette Smith, Karam Mounzer, Luis J. Montaner", "title": "Prediction-based classification for longitudinal biomarkers", "comments": "Published in at http://dx.doi.org/10.1214/10-AOAS326 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2010, Vol. 4, No. 3, 1476-1497", "doi": "10.1214/10-AOAS326", "report-no": "IMS-AOAS-AOAS326", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Assessment of circulating CD4 count change over time in HIV-infected subjects\non antiretroviral therapy (ART) is a central component of disease monitoring.\nThe increasing number of HIV-infected subjects starting therapy and the limited\ncapacity to support CD4 count testing within resource-limited settings have\nfueled interest in identifying correlates of CD4 count change such as total\nlymphocyte count, among others. The application of modeling techniques will be\nessential to this endeavor due to the typically nonlinear CD4 trajectory over\ntime and the multiple input variables necessary for capturing CD4 variability.\nWe propose a prediction-based classification approach that involves first stage\nmodeling and subsequent classification based on clinically meaningful\nthresholds. This approach draws on existing analytical methods described in the\nreceiver operating characteristic curve literature while presenting an\nextension for handling a continuous outcome. Application of this method to an\nindependent test sample results in greater than 98% positive predictive value\nfor CD4 count change. The prediction algorithm is derived based on a cohort of\n$n=270$ HIV-1 infected individuals from the Royal Free Hospital, London who\nwere followed for up to three years from initiation of ART. A test sample\ncomprised of $n=72$ individuals from Philadelphia and followed for a similar\nlength of time is used for validation. Results suggest that this approach may\nbe a useful tool for prioritizing limited laboratory resources for CD4 testing\nafter subjects start antiretroviral therapy.\n", "versions": [{"version": "v1", "created": "Mon, 15 Nov 2010 12:02:14 GMT"}], "update_date": "2010-11-16", "authors_parsed": [["Foulkes", "Andrea S.", ""], ["Azzoni", "Livio", ""], ["Li", "Xiaohong", ""], ["Johnson", "Margaret A.", ""], ["Smith", "Colette", ""], ["Mounzer", "Karam", ""], ["Montaner", "Luis J.", ""]]}, {"id": "1011.3360", "submitter": "Caiyan Li", "authors": "Caiyan Li, Hongzhe Li", "title": "Variable selection and regression analysis for graph-structured\n  covariates with an application to genomics", "comments": "Published in at http://dx.doi.org/10.1214/10-AOAS332 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2010, Vol. 4, No. 3, 1498-1516", "doi": "10.1214/10-AOAS332", "report-no": "IMS-AOAS-AOAS332", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphs and networks are common ways of depicting biological information. In\nbiology, many different biological processes are represented by graphs, such as\nregulatory networks, metabolic pathways and protein--protein interaction\nnetworks. This kind of a priori use of graphs is a useful supplement to the\nstandard numerical data such as microarray gene expression data. In this paper\nwe consider the problem of regression analysis and variable selection when the\ncovariates are linked on a graph. We study a graph-constrained regularization\nprocedure and its theoretical properties for regression analysis to take into\naccount the neighborhood information of the variables measured on a graph. This\nprocedure involves a smoothness penalty on the coefficients that is defined as\na quadratic form of the Laplacian matrix associated with the graph. We\nestablish estimation and model selection consistency results and provide\nestimation bounds for both fixed and diverging numbers of parameters in\nregression models. We demonstrate by simulations and a real data set that the\nproposed procedure can lead to better variable selection and prediction than\nexisting methods that ignore the graph information associated with the\ncovariates.\n", "versions": [{"version": "v1", "created": "Mon, 15 Nov 2010 12:36:13 GMT"}], "update_date": "2010-11-16", "authors_parsed": [["Li", "Caiyan", ""], ["Li", "Hongzhe", ""]]}, {"id": "1011.3367", "submitter": "Yijie Zhou", "authors": "Yijie Zhou, Francesca Dominici, Thomas A. Louis", "title": "A smoothing approach for masking spatial data", "comments": "Published in at http://dx.doi.org/10.1214/09-AOAS325 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2010, Vol. 4, No. 3, 1451-1475", "doi": "10.1214/09-AOAS325", "report-no": "IMS-AOAS-AOAS325", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Individual-level health data are often not publicly available due to\nconfidentiality; masked data are released instead. Therefore, it is important\nto evaluate the utility of using the masked data in statistical analyses such\nas regression. In this paper we propose a data masking method which is based on\nspatial smoothing techniques. The proposed method allows for selecting both the\nform and the degree of masking, thus resulting in a large degree of\nflexibility. We investigate the utility of the masked data sets in terms of the\nmean square error (MSE) of regression parameter estimates when fitting a\nGeneralized Linear Model (GLM) to the masked data. We also show that\nincorporating prior knowledge on the spatial pattern of the exposure into the\ndata masking may reduce the bias and MSE of the parameter estimates. By\nevaluating both utility and disclosure risk as functions of the form and the\ndegree of masking, our method produces a risk-utility profile which can\nfacilitate the selection of masking parameters. We apply the method to a study\nof racial disparities in mortality rates using data on more than 4 million\nMedicare enrollees residing in 2095 zip codes in the Northeast region of the\nUnited States.\n", "versions": [{"version": "v1", "created": "Mon, 15 Nov 2010 12:53:21 GMT"}], "update_date": "2010-11-16", "authors_parsed": [["Zhou", "Yijie", ""], ["Dominici", "Francesca", ""], ["Louis", "Thomas A.", ""]]}, {"id": "1011.3371", "submitter": "Paul S. Albert", "authors": "Paul S. Albert, Joanna H. Shih", "title": "An approach for jointly modeling multivariate longitudinal measurements\n  and discrete time-to-event data", "comments": "Published in at http://dx.doi.org/10.1214/10-AOAS339 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2010, Vol. 4, No. 3, 1517-1532", "doi": "10.1214/10-AOAS339", "report-no": "IMS-AOAS-AOAS339", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many medical studies, patients are followed longitudinally and interest is\non assessing the relationship between longitudinal measurements and time to an\nevent. Recently, various authors have proposed joint modeling approaches for\nlongitudinal and time-to-event data for a single longitudinal variable. These\njoint modeling approaches become intractable with even a few longitudinal\nvariables. In this paper we propose a regression calibration approach for\njointly modeling multiple longitudinal measurements and discrete time-to-event\ndata. Ideally, a two-stage modeling approach could be applied in which the\nmultiple longitudinal measurements are modeled in the first stage and the\nlongitudinal model is related to the time-to-event data in the second stage.\nBiased parameter estimation due to informative dropout makes this direct\ntwo-stage modeling approach problematic. We propose a regression calibration\napproach which appropriately accounts for informative dropout. We approximate\nthe conditional distribution of the multiple longitudinal measurements given\nthe event time by modeling all pairwise combinations of the longitudinal\nmeasurements using a bivariate linear mixed model which conditions on the event\ntime. Complete data are then simulated based on estimates from these pairwise\nconditional models, and regression calibration is used to estimate the\nrelationship between longitudinal data and time-to-event data using the\ncomplete data. We show that this approach performs well in estimating the\nrelationship between multivariate longitudinal measurements and the\ntime-to-event data and in estimating the parameters of the multiple\nlongitudinal process subject to informative dropout. We illustrate this\nmethodology with simulations and with an analysis of primary biliary cirrhosis\n(PBC) data.\n", "versions": [{"version": "v1", "created": "Mon, 15 Nov 2010 13:13:46 GMT"}], "update_date": "2010-11-16", "authors_parsed": [["Albert", "Paul S.", ""], ["Shih", "Joanna H.", ""]]}, {"id": "1011.3411", "submitter": "Pepa Ramirez-Cobo", "authors": "Pepa Ramirez-Cobo, Rosa E. Lillo, Simon Wilson, Michael P. Wiper", "title": "Bayesian inference for double Pareto lognormal queues", "comments": "Published in at http://dx.doi.org/10.1214/10-AOAS336 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2010, Vol. 4, No. 3, 1533-1557", "doi": "10.1214/10-AOAS336", "report-no": "IMS-AOAS-AOAS336", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we describe a method for carrying out Bayesian estimation for\nthe double Pareto lognormal (dPlN) distribution which has been proposed as a\nmodel for heavy-tailed phenomena. We apply our approach to estimate the\n$\\mathit{dPlN}/M/1$ and $M/\\mathit{dPlN}/1$ queueing systems. These systems\ncannot be analyzed using standard techniques due to the fact that the dPlN\ndistribution does not possess a Laplace transform in closed form. This\ndifficulty is overcome using some recent approximations for the Laplace\ntransform of the interarrival distribution for the $\\mathit{Pareto}/M/1$\nsystem. Our procedure is illustrated with applications in internet traffic\nanalysis and risk theory.\n", "versions": [{"version": "v1", "created": "Mon, 15 Nov 2010 14:58:21 GMT"}], "update_date": "2010-11-16", "authors_parsed": [["Ramirez-Cobo", "Pepa", ""], ["Lillo", "Rosa E.", ""], ["Wilson", "Simon", ""], ["Wiper", "Michael P.", ""]]}, {"id": "1011.3612", "submitter": "J. L. Wadsworth", "authors": "J. L. Wadsworth, J. A. Tawn, P. Jonathan", "title": "Accounting for choice of measurement scale in extreme value modeling", "comments": "Published in at http://dx.doi.org/10.1214/10-AOAS333 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2010, Vol. 4, No. 3, 1558-1578", "doi": "10.1214/10-AOAS333", "report-no": "IMS-AOAS-AOAS333", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the effect that the choice of measurement scale has upon\ninference and extrapolation in extreme value analysis. Separate analyses of\nvariables from a single process on scales which are linked by a nonlinear\ntransformation may lead to discrepant conclusions concerning the tail behavior\nof the process. We propose the use of a Box--Cox power transformation\nincorporated as part of the inference procedure to account parametrically for\nthe uncertainty surrounding the scale of extrapolation. This has the additional\nfeature of increasing the rate of convergence of the distribution tails to an\nextreme value form in certain cases and thus reducing bias in the model\nestimation. Inference without reparameterization is practicably infeasible, so\nwe explore a reparameterization which exploits the asymptotic theory of\nnormalizing constants required for nondegenerate limit distributions. Inference\nis carried out in a Bayesian setting, an advantage of this being the\navailability of posterior predictive return levels. The methodology is\nillustrated on both simulated data and significant wave height data from the\nNorth Sea.\n", "versions": [{"version": "v1", "created": "Tue, 16 Nov 2010 08:43:29 GMT"}], "update_date": "2010-11-17", "authors_parsed": [["Wadsworth", "J. L.", ""], ["Tawn", "J. A.", ""], ["Jonathan", "P.", ""]]}, {"id": "1011.3626", "submitter": "Seokho Lee", "authors": "Seokho Lee, Jianhua Z. Huang, Jianhua Hu", "title": "Sparse logistic principal components analysis for binary data", "comments": "Published in at http://dx.doi.org/10.1214/10-AOAS327 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2010, Vol. 4, No. 3, 1579-1601", "doi": "10.1214/10-AOAS327", "report-no": "IMS-AOAS-AOAS327", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a new principal components analysis (PCA) type dimension reduction\nmethod for binary data. Different from the standard PCA which is defined on the\nobserved data, the proposed PCA is defined on the logit transform of the\nsuccess probabilities of the binary observations. Sparsity is introduced to the\nprincipal component (PC) loading vectors for enhanced interpretability and more\nstable extraction of the principal components. Our sparse PCA is formulated as\nsolving an optimization problem with a criterion function motivated from a\npenalized Bernoulli likelihood. A Majorization--Minimization algorithm is\ndeveloped to efficiently solve the optimization problem. The effectiveness of\nthe proposed sparse logistic PCA method is illustrated by application to a\nsingle nucleotide polymorphism data set and a simulation study.\n", "versions": [{"version": "v1", "created": "Tue, 16 Nov 2010 09:40:22 GMT"}], "update_date": "2010-11-17", "authors_parsed": [["Lee", "Seokho", ""], ["Huang", "Jianhua Z.", ""], ["Hu", "Jianhua", ""]]}, {"id": "1011.3638", "submitter": "Kwun Chuen Gary Chan", "authors": "Kwun Chuen Gary Chan, Mei-Cheng Wang", "title": "Backward estimation of stochastic processes with failure events as time\n  origins", "comments": "Published in at http://dx.doi.org/10.1214/09-AOAS319 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2010, Vol. 4, No. 3, 1602-1620", "doi": "10.1214/09-AOAS319", "report-no": "IMS-AOAS-AOAS319", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic processes often exhibit sudden systematic changes in pattern a\nshort time before certain failure events. Examples include increase in medical\ncosts before death and decrease in CD4 counts before AIDS diagnosis. To study\nsuch terminal behavior of stochastic processes, a natural and direct way is to\nalign the processes using failure events as time origins. This paper studies\nbackward stochastic processes counting time backward from failure events, and\nproposes one-sample nonparametric estimation of the mean of backward processes\nwhen follow-up is subject to left truncation and right censoring. We will\ndiscuss benefits of including prevalent cohort data to enlarge the identifiable\nregion and large sample properties of the proposed estimator with related\nextensions. A SEER--Medicare linked data set is used to illustrate the proposed\nmethodologies.\n", "versions": [{"version": "v1", "created": "Tue, 16 Nov 2010 10:13:06 GMT"}], "update_date": "2010-11-17", "authors_parsed": [["Chan", "Kwun Chuen Gary", ""], ["Wang", "Mei-Cheng", ""]]}, {"id": "1011.3801", "submitter": "Sofia C. Olhede", "authors": "Sofia C. Olhede, Brandon Whitcher", "title": "Nonparametric tests of structure for high angular resolution diffusion\n  imaging in Q-space", "comments": "Published in at http://dx.doi.org/10.1214/10-AOAS441 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2011, Vol. 5, No. 2B, 1293-1327", "doi": "10.1214/10-AOAS441", "report-no": "IMS-AOAS-AOAS441", "categories": "stat.AP physics.med-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High angular resolution diffusion imaging data is the observed characteristic\nfunction for the local diffusion of water molecules in tissue. This data is\nused to infer structural information in brain imaging. Nonparametric scalar\nmeasures are proposed to summarize such data, and to locally characterize\nspatial features of the diffusion probability density function (PDF), relying\non the geometry of the characteristic function. Summary statistics are defined\nso that their distributions are, to first-order, both independent of nuisance\nparameters and also analytically tractable. The dominant direction of the\ndiffusion at a spatial location (voxel) is determined, and a new set of axes\nare introduced in Fourier space. Variation quantified in these axes determines\nthe local spatial properties of the diffusion density. Nonparametric hypothesis\ntests for determining whether the diffusion is unimodal, isotropic or\nmulti-modal are proposed. More subtle characteristics of white-matter\nmicrostructure, such as the degree of anisotropy of the PDF and symmetry\ncompared with a variety of asymmetric PDF alternatives, may be ascertained\ndirectly in the Fourier domain without parametric assumptions on the form of\nthe diffusion PDF. We simulate a set of diffusion processes and characterize\ntheir local properties using the newly introduced summaries. We show how\ncomplex white-matter structures across multiple voxels exhibit clear\nellipsoidal and asymmetric structure in simulation, and assess the performance\nof the statistics in clinically-acquired magnetic resonance imaging data.\n", "versions": [{"version": "v1", "created": "Tue, 16 Nov 2010 20:01:04 GMT"}, {"version": "v2", "created": "Tue, 16 Aug 2011 08:02:05 GMT"}], "update_date": "2011-08-17", "authors_parsed": [["Olhede", "Sofia C.", ""], ["Whitcher", "Brandon", ""]]}, {"id": "1011.3805", "submitter": "Rodrigo Labouriau", "authors": "Gabriel C. G. de Abreu and Rodrigo Labouriau", "title": "Characterization of differentially expressed genes using\n  high-dimensional co-expression networks", "comments": "28 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP q-bio.MN stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a technique to characterize differentially expressed genes in\nterms of their position in a high-dimensional co-expression network. The set-up\nof Gaussian graphical models is used to construct representations of the\nco-expression network in such a way that redundancy and the propagation of\nspurious information along the network are avoided. The proposed inference\nprocedure is based on the minimization of the Bayesian Information Criterion\n(BIC) in the class of decomposable graphical models. This class of models can\nbe used to represent complex relationships and has suitable properties that\nallow to make effective inference in problems with high degree of complexity\n(e.g. several thousands of genes) and small number of observations (e.g.\n10-100) as typically occurs in high throughput gene expression studies. Taking\nadvantage of the internal structure of decomposable graphical models, we\nconstruct a compact representation of the co-expression network that allows to\nidentify the regions with high concentration of differentially expressed genes.\nIt is argued that differentially expressed genes located in highly\ninterconnected regions of the co-expression network are less informative than\ndifferentially expressed genes located in less interconnected regions. Based on\nthat idea, a measure of uncertainty that resembles the notion of relative\nentropy is proposed. Our methods are illustrated with three publically\navailable data sets on microarray experiments (the larger involving more than\n50,000 genes and 64 patients) and a short simulation study.\n", "versions": [{"version": "v1", "created": "Mon, 15 Nov 2010 13:37:45 GMT"}], "update_date": "2010-11-17", "authors_parsed": [["de Abreu", "Gabriel C. G.", ""], ["Labouriau", "Rodrigo", ""]]}, {"id": "1011.4018", "submitter": "Simon Wilson", "authors": "Simon P. Wilson and Jiwon Yoon", "title": "Bayesian ICA-based source separation of Cosmic Microwave Background by a\n  discrete functional approximation", "comments": "12 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": "Discipline of Statistics, Trinity College Dublin, Technical Report\n  11/01", "categories": "astro-ph.CO stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A functional approximation to implement Bayesian source separation analysis\nis introduced and applied to separation of the Cosmic Microwave Background\n(CMB) using WMAP data. The approximation allows for tractable full-sky map\nreconstructions at the scale of both WMAP and Planck data and models the\nspatial smoothness of sources through a Gaussian Markov random field prior. It\nis orders of magnitude faster than the usual MCMC approaches. The performance\nand limitations of the approximation are also discussed.\n", "versions": [{"version": "v1", "created": "Wed, 17 Nov 2010 18:31:24 GMT"}, {"version": "v2", "created": "Wed, 19 Jan 2011 11:45:22 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Wilson", "Simon P.", ""], ["Yoon", "Jiwon", ""]]}, {"id": "1011.4098", "submitter": "Nandakishore Santhi", "authors": "Sachin Kadloor and Nandakishore Santhi", "title": "Understanding Cascading Failures in Power Grids", "comments": "12 pages; 9 figures; being submitted to IEEE Trans. on Smart Grids", "journal-ref": null, "doi": null, "report-no": "LA-UR 10-07070", "categories": "cs.SI math.PR stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the past, we have observed several large blackouts, i.e. loss of power to\nlarge areas. It has been noted by several researchers that these large\nblackouts are a result of a cascade of failures of various components. As a\npower grid is made up of several thousands or even millions of components\n(relays, breakers, transformers, etc.), it is quite plausible that a few of\nthese components do not perform their function as desired. Their\nfailure/misbehavior puts additional burden on the working components causing\nthem to misbehave, and thus leading to a cascade of failures.\n  The complexity of the entire power grid makes it difficult to model each and\nevery individual component and study the stability of the entire system. For\nthis reason, it is often the case that abstract models of the working of the\npower grid are constructed and then analyzed. These models need to be\ncomputationally tractable while serving as a reasonable model for the entire\nsystem. In this work, we construct one such model for the power grid, and\nanalyze it.\n", "versions": [{"version": "v1", "created": "Wed, 17 Nov 2010 23:10:50 GMT"}], "update_date": "2010-11-19", "authors_parsed": [["Kadloor", "Sachin", ""], ["Santhi", "Nandakishore", ""]]}, {"id": "1011.4291", "submitter": "Bulent Kiziltan", "authors": "Bulent Kiziltan, Athanasios Kottas and Stephen E. Thorsett", "title": "The Neutron Star Mass Distribution", "comments": "14 pages, 7 figures, 2 tables, in emulateapj format", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.GA astro-ph.SR stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, the number of pulsars with secure mass measurements has\nincreased to a level that allows us to probe the underlying neutron star mass\ndistribution in detail. We critically review radio pulsar mass measurements and\npresent a detailed examination through which we are able to put stringent\nconstraints on the underlying neutron star mass distribution. For the first\ntime, we are able to analyze a sizable population of neutron star-white dwarf\nsystems in addition to double neutron star systems with a technique that\naccounts for systematically different measurement errors. We find that neutron\nstars that have evolved through different evolutionary paths reflect\ndistinctive signatures through dissimilar distribution peak and mass cutoff\nvalues. Neutron stars in double neutron star and neutron star-white dwarf\nsystems show consistent respective peaks at 1.35 Msun and 1.50 Msun which\nsuggest significant mass accretion (Delta m~0.15 Msun) has occurred during the\nspin up phase. The width of the mass distribution implied by double neutron\nstar systems is indicative of a tight initial mass function while the inferred\nmass range is significantly wider for neutron stars that have gone through\nrecycling. We find a mass cutoff at 2 Msun for neutron stars with white dwarf\ncompanions which establishes a firm lower bound for the maximum neutron star\nmass. This rules out the majority of strange quark and soft equation of state\nmodels as viable configurations for neutron star matter. The lack of truncation\nclose to the maximum mass cutoff suggests that the 2 Msun limit is set by\nevolutionary constraints rather than nuclear physics or general relativity, and\nthe existence of rare super-massive neutron stars is possible.\n", "versions": [{"version": "v1", "created": "Thu, 18 Nov 2010 21:00:00 GMT"}], "update_date": "2016-02-09", "authors_parsed": [["Kiziltan", "Bulent", ""], ["Kottas", "Athanasios", ""], ["Thorsett", "Stephen E.", ""]]}, {"id": "1011.4339", "submitter": "Srikanth Jagabathula", "authors": "Vivek F. Farias and Srikanth Jagabathula and Devavrat Shah", "title": "Sparse Choice Models", "comments": "28 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Choice models, which capture popular preferences over objects of interest,\nplay a key role in making decisions whose eventual outcome is impacted by human\nchoice behavior. In most scenarios, the choice model, which can effectively be\nviewed as a distribution over permutations, must be learned from observed data.\nThe observed data, in turn, may frequently be viewed as (partial, noisy)\ninformation about marginals of this distribution over permutations. As such,\nthe search for an appropriate choice model boils down to learning a\ndistribution over permutations that is (near-)consistent with observed\ninformation about this distribution.\n  In this work, we pursue a non-parametric approach which seeks to learn a\nchoice model (i.e. a distribution over permutations) with {\\em sparsest}\npossible support, and consistent with observed data. We assume that the data\nobserved consists of noisy information pertaining to the marginals of the\nchoice model we seek to learn. We establish that {\\em any} choice model admits\na `very' sparse approximation in the sense that there exists a choice model\nwhose support is small relative to the dimension of the observed data and whose\nmarginals approximately agree with the observed marginal information. We\nfurther show that under, what we dub, `signature' conditions, such a sparse\napproximation can be found in a computationally efficiently fashion relative to\na brute force approach. An empirical study using the American Psychological\nAssociation election data-set suggests that our approach manages to unearth\nuseful structural properties of the underlying choice model using the sparse\napproximation found. Our results further suggest that the signature condition\nis a potential alternative to the recently popularized Restricted Null Space\ncondition for efficient recovery of sparse models.\n", "versions": [{"version": "v1", "created": "Fri, 19 Nov 2010 03:51:01 GMT"}, {"version": "v2", "created": "Wed, 21 Sep 2011 07:05:07 GMT"}], "update_date": "2011-09-22", "authors_parsed": [["Farias", "Vivek F.", ""], ["Jagabathula", "Srikanth", ""], ["Shah", "Devavrat", ""]]}, {"id": "1011.4910", "submitter": "Dragana Bajovic", "authors": "Dragana Bajovic and Bruno Sinopoli and Joao Xavier", "title": "Sensor Selection for Event Detection in Wireless Sensor Networks", "comments": "30 pages, journal, submitted", "journal-ref": null, "doi": "10.1109/TSP.2011.2160630", "report-no": null, "categories": "cs.IT math.IT stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of sensor selection for event detection in wireless\nsensor networks (WSNs). We want to choose a subset of p out of n sensors that\nyields the best detection performance. As the sensor selection optimality\ncriteria, we propose the Kullback-Leibler and Chernoff distances between the\ndistributions of the selected measurements under the two hypothesis. We\nformulate the maxmin robust sensor selection problem to cope with the\nuncertainties in distribution means. We prove that the sensor selection problem\nis NP hard, for both Kullback-Leibler and Chernoff criteria. To (sub)optimally\nsolve the sensor selection problem, we propose an algorithm of affordable\ncomplexity. Extensive numerical simulations on moderate size problem instances\n(when the optimum by exhaustive search is feasible to compute) demonstrate the\nalgorithm's near optimality in a very large portion of problem instances. For\nlarger problems, extensive simulations demonstrate that our algorithm\noutperforms random searches, once an upper bound on computational time is set.\nWe corroborate numerically the validity of the Kullback-Leibler and Chernoff\nsensor selection criteria, by showing that they lead to sensor selections\nnearly optimal both in the Neyman-Pearson and Bayes sense.\n", "versions": [{"version": "v1", "created": "Mon, 22 Nov 2010 18:52:19 GMT"}], "update_date": "2015-05-20", "authors_parsed": [["Bajovic", "Dragana", ""], ["Sinopoli", "Bruno", ""], ["Xavier", "Joao", ""]]}, {"id": "1011.4992", "submitter": "Yan Kagan Y.", "authors": "Yan Y. Kagan", "title": "Random stress and Omori's law", "comments": null, "journal-ref": "Geophys. J. Int., 186(3), 1347-1364, 2011", "doi": "10.1111/j.1365-246X.2011.05114.x", "report-no": null, "categories": "stat.AP physics.geo-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider two statistical regularities that were used to explain Omori's\nlaw of the aftershock rate decay: the Levy and Inverse Gaussian (IGD)\ndistributions. These distributions are thought to describe stress behavior\ninfluenced by various random factors: post-earthquake stress time history is\ndescribed by a Brownian motion. Both distributions decay to zero for time\nintervals close to zero. But this feature contradicts the high immediate\naftershock level according to Omori's law. We propose that these statistical\ndistributions are influenced by the power-law stress distribution near the\nearthquake focal zone and we derive new distributions as a mixture of power-law\nstress with the exponent psi and Levy as well as IGD distributions. Such new\ndistributions describe the resulting inter-earthquake time intervals and\nclosely resemble Omori's law. The new Levy distribution has a pure power-law\nform with the exponent -(1+psi/2) and the mixed IGD has two exponents: the same\nas Levy for small time intervals and -(1+psi) for longer times. For even longer\ntime intervals this power-law behavior should be replaced by a uniform\nseismicity rate corresponding to the long-term tectonic deformation. We compute\nthese background rates using our former analysis of earthquake size\ndistribution and its connection to plate tectonics. We analyze several\nearthquake catalogs to confirm and illustrate our theoretical results. Finally,\nwe discuss how the parameters of random stress dynamics can be determined\nthrough a more detailed statistical analysis of earthquake occurrence or by new\nlaboratory experiments.\n", "versions": [{"version": "v1", "created": "Tue, 23 Nov 2010 02:48:10 GMT"}], "update_date": "2012-07-24", "authors_parsed": [["Kagan", "Yan Y.", ""]]}, {"id": "1011.5209", "submitter": "Loet Leydesdorff", "authors": "Loet Leydesdorff, Kasper Welbers", "title": "The semantic mapping of words and co-words in contexts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Meaning can be generated when information is related at a systemic level.\nSuch a system can be an observer, but also a discourse, for example,\noperationalized as a set of documents. The measurement of semantics as\nsimilarity in patterns (correlations) and latent variables (factor analysis)\nhas been enhanced by computer techniques and the use of statistics; for\nexample, in \"Latent Semantic Analysis\". This communication provides an\nintroduction, an example, pointers to relevant software, and summarizes the\nchoices that can be made by the analyst. Visualization (\"semantic mapping\") is\nthus made more accessible.\n", "versions": [{"version": "v1", "created": "Tue, 23 Nov 2010 20:11:35 GMT"}, {"version": "v2", "created": "Sat, 29 Jan 2011 10:31:58 GMT"}], "update_date": "2011-02-01", "authors_parsed": [["Leydesdorff", "Loet", ""], ["Welbers", "Kasper", ""]]}, {"id": "1011.5396", "submitter": "Bernhard Stoevesandt", "authors": "Bernhard Stoevesandt and Joachim Peinke", "title": "Effects of Sudden Changes in Inflow Conditions on the Angle of Attack on\n  HAWT Blades", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP physics.ao-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper changes in wind speed and wind direction from a measured wind\nfield are being analyzed at high frequencies. This is used to estimate changes\nin the angle of attack (AOA) on a blade segment over short time periods for\ndifferent estimated turbine concepts. Here a statistical approach is chosen to\ngrasp the characteristics of the probability distributions to give an over all\nview of the magnitude and rate of the changes. The main interest is the\ngeneration of basic distributions for the calculation of dynamic stall effects\nand stall flutter due to wind fluctuations.\n", "versions": [{"version": "v1", "created": "Wed, 24 Nov 2010 15:18:48 GMT"}], "update_date": "2010-11-25", "authors_parsed": [["Stoevesandt", "Bernhard", ""], ["Peinke", "Joachim", ""]]}, {"id": "1011.5631", "submitter": "Valderio Reisen VAR", "authors": "Valderio A. Reisen, Wilfredo Palma, Josu Arteche, Bartolomeu Zamprogno", "title": "Seasonal fractional long-memory processes. A semiparametric estimation\n  approach", "comments": "submitted for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores seasonal and long-memory time series properties by using\nthe seasonal fractional ARIMA model when the seasonal data has one and two\nseasonal periods and short-memory counterparts. The stationarity and\ninvertibility parameter conditions are established for the model studied. To\nestimate the memory parameters, the method given in Reisen, Rodrigues and Palma\n(2006 a,b) is generalized here to deal with a time series with two seasonal\nfractional long-memory parameters. The asymptotic properties are established\nand the accuracy of the method is investigated through Monte Carlo experiments.\nThe good performance of the estimator indicates that it can be an alternative\ncompetitive procedure to estimate seasonal long-memory time series data.\nArtificial and PM10 series were considered as examples of applications of the\nproposed estimation method.\n", "versions": [{"version": "v1", "created": "Thu, 25 Nov 2010 14:15:19 GMT"}], "update_date": "2010-11-29", "authors_parsed": [["Reisen", "Valderio A.", ""], ["Palma", "Wilfredo", ""], ["Arteche", "Josu", ""], ["Zamprogno", "Bartolomeu", ""]]}, {"id": "1011.5770", "submitter": "Marc Henrion", "authors": "Marc Henrion, Daniel J. Mortlock, David J. Hand, Axel Gandy", "title": "A Bayesian approach to star-galaxy classification", "comments": "Accepted 22 November 2010, 19 pages, 17 figures", "journal-ref": "MNRAS (2011) 412 (4): 2286-2302", "doi": "10.1111/j.1365-2966.2010.18055.x", "report-no": null, "categories": "astro-ph.IM physics.data-an stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Star-galaxy classification is one of the most fundamental data-processing\ntasks in survey astronomy, and a critical starting point for the scientific\nexploitation of survey data. For bright sources this classification can be done\nwith almost complete reliability, but for the numerous sources close to a\nsurvey's detection limit each image encodes only limited morphological\ninformation. In this regime, from which many of the new scientific discoveries\nare likely to come, it is vital to utilise all the available information about\na source, both from multiple measurements and also prior knowledge about the\nstar and galaxy populations. It is also more useful and realistic to provide\nclassification probabilities than decisive classifications. All these\ndesiderata can be met by adopting a Bayesian approach to star-galaxy\nclassification, and we develop a very general formalism for doing so. An\nimmediate implication of applying Bayes's theorem to this problem is that it is\nformally impossible to combine morphological measurements in different bands\nwithout using colour information as well; however we develop several\napproximations that disregard colour information as much as possible. The\nresultant scheme is applied to data from the UKIRT Infrared Deep Sky Survey\n(UKIDSS), and tested by comparing the results to deep Sloan Digital Sky Survey\n(SDSS) Stripe 82 measurements of the same sources. The Bayesian classification\nprobabilities obtained from the UKIDSS data agree well with the deep SDSS\nclassifications both overall (a mismatch rate of 0.022, compared to 0.044 for\nthe UKIDSS pipeline classifier) and close to the UKIDSS detection limit (a\nmismatch rate of 0.068 compared to 0.075 for the UKIDSS pipeline classifier).\nThe Bayesian formalism developed here can be applied to improve the reliability\nof any star-galaxy classification schemes based on the measured values of\nmorphology statistics alone.\n", "versions": [{"version": "v1", "created": "Fri, 26 Nov 2010 12:21:51 GMT"}], "update_date": "2013-07-30", "authors_parsed": [["Henrion", "Marc", ""], ["Mortlock", "Daniel J.", ""], ["Hand", "David J.", ""], ["Gandy", "Axel", ""]]}, {"id": "1011.5910", "submitter": "Kaisey Mandel", "authors": "Kaisey S. Mandel, Gautham Narayan, and Robert P. Kirshner", "title": "Type Ia Supernova Light Curve Inference: Hierarchical Models in the\n  Optical and Near Infrared", "comments": "trivial edits to match published version", "journal-ref": "Astrophys.J.731:120,2011", "doi": "10.1088/0004-637X/731/2/120", "report-no": null, "categories": "astro-ph.CO stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We have constructed a comprehensive statistical model for Type Ia supernova\n(SN Ia) light curves spanning optical through near infrared (NIR) data. A\nhierarchical framework coherently models multiple random and uncertain effects,\nincluding intrinsic supernova light curve covariances, dust extinction and\nreddening, and distances. An improved BayeSN MCMC code computes probabilistic\ninferences for the hierarchical model by sampling the global probability\ndensity of parameters describing individual supernovae and the population. We\nhave applied this hierarchical model to optical and NIR data of 127 SN Ia from\nPAIRITEL, CfA3, CSP, and the literature. We find an apparent population\ncorrelation between the host galaxy extinction A_V and the the ratio of\ntotal-to-selective dust absorption R_V. For SN with low dust extinction, A_V <\n0.4, we find R_V = 2.5 - 2.9, while at high extinctions, A_V > 1, low values of\nR_V < 2 are favored. The NIR luminosities are excellent standard candles and\nare less sensitive to dust extinction. They exhibit low correlation with\noptical peak luminosities, and thus provide independent information on\ndistances. The combination of NIR and optical data constrains the dust\nextinction and improves the predictive precision of individual SN Ia distances\nby about 60%. Using cross-validation, we estimate an rms distance modulus\nprediction error of 0.11 mag for SN with optical and NIR data versus 0.15 mag\nfor SN with optical data alone. Continued study of SN Ia in the NIR is\nimportant for improving their utility as precise and accurate cosmological\ndistance indicators.\n", "versions": [{"version": "v1", "created": "Fri, 26 Nov 2010 21:00:01 GMT"}, {"version": "v2", "created": "Tue, 1 Feb 2011 21:00:20 GMT"}, {"version": "v3", "created": "Tue, 5 Apr 2011 04:49:25 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Mandel", "Kaisey S.", ""], ["Narayan", "Gautham", ""], ["Kirshner", "Robert P.", ""]]}, {"id": "1011.6228", "submitter": "Francisco Kitaura", "authors": "Simona Gallerani, Francisco-Shu Kitaura, Andrea Ferrara", "title": "Cosmic density field reconstruction from Ly-alpha forest data", "comments": "5 pages, 3 figures, accepted for publication in MNRAS Letters", "journal-ref": null, "doi": "10.1111/j.1745-3933.2011.01020.x", "report-no": null, "categories": "astro-ph.CO stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel, fast method to recover the density field through the\nstatistics of the transmitted flux in high redshift quasar absorption spectra.\nThe proposed technique requires the computation of the probability distribution\nfunction of the transmitted flux (P_F) in the Ly-alpha forest region and, as a\nsole assumption, the knowledge of the probability distribution function of the\nmatter density field (P_Delta). We show that the probability density\nconservation of the flux and matter density unveils a flux-density (F-Delta)\nrelation which can be used to invert the Ly-alpha forest without any assumption\non the physical properties of the intergalactic medium. We test our inversion\nmethod at z=3 through the following steps: [i] simulation of a sample of\nsynthetic spectra for which P_Delta is known; [ii] computation of P_F; [iii]\ninversion of the Ly-alpha forest through the F-Delta relation. Our technique,\nwhen applied to only 10 observed spectra characterized by a signal-to noise\nratio S/N >= 100 provides an exquisite (relative error epsilon_Delta <~ 12 % in\n>~ 50 % of the pixels) reconstruction of the density field in >~ 90 % of the\nline of sight. We finally discuss strengths and limitations of the method.\n", "versions": [{"version": "v1", "created": "Mon, 29 Nov 2010 13:57:44 GMT"}, {"version": "v2", "created": "Wed, 26 Jan 2011 20:17:25 GMT"}], "update_date": "2015-05-20", "authors_parsed": [["Gallerani", "Simona", ""], ["Kitaura", "Francisco-Shu", ""], ["Ferrara", "Andrea", ""]]}, {"id": "1011.6233", "submitter": "Francisco Kitaura", "authors": "Francisco-Shu Kitaura, Simona Gallerani and Andrea Ferrara", "title": "Multiscale Inference of Matter Fields and Baryon Acoustic Oscillations\n  from the Ly-alpha Forest", "comments": "14 pages, 7 figures; accepted in MNRAS 2011 October 12, in original\n  form 2010 November 29, Publication Date: 02/2012", "journal-ref": null, "doi": "10.1111/j.1365-2966.2011.19997.x", "report-no": null, "categories": "astro-ph.CO math.ST stat.AP stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel Bayesian method for the joint reconstruction of\ncosmological matter density fields, peculiar velocities and power-spectra in\nthe quasi-nonlinear regime. We study its applicability to the Ly-alpha forest\nbased on multiple quasar absorption spectra. Our approach to this problem\nincludes a multiscale, nonlinear, two-step scheme since the statistics\ndescribing the matter distribution depends on scale, being strongly\nnon-Gaussian on small scales (< 0.1 h^{-1} Mpc) and closely lognormal on scales\n>~10 h^{-1} Mpc. The first step consists on performing 1D highly resolved\nmatter density reconstructions along the line-of-sight towards z~2-3 quasars\nbased on an arbitrary non-Gaussian univariate model for matter statistics. The\nsecond step consists on Gibbs-sampling based on conditional PDFs. The matter\ndensity field is sampled in real space with Hamiltonian-sampling using the\nPoisson/Gamma-lognormal model, while redshift distortions are corrected with\nlinear Lagrangian perturbation theory. The power-spectrum of the lognormal\ntransformed variable which is Gaussian distributed (and thus close to the\nlinear regime) can consistently be sampled with the inverse Gamma distribution\nfunction. We test our method through numerical N-body simulations with a\ncomputational volume large enough (> 1 h^{-3} Gpc^3) to show that the linear\npower-spectra are nicely recovered over scales larger than >~20 h^{-1} Mpc,\ni.e. the relevant range where features imprinted by the baryon-acoustics\noscillations (BAOs) appear.\n", "versions": [{"version": "v1", "created": "Mon, 29 Nov 2010 14:09:22 GMT"}, {"version": "v2", "created": "Mon, 29 Aug 2011 14:32:01 GMT"}, {"version": "v3", "created": "Wed, 27 Jun 2012 12:11:03 GMT"}], "update_date": "2015-05-20", "authors_parsed": [["Kitaura", "Francisco-Shu", ""], ["Gallerani", "Simona", ""], ["Ferrara", "Andrea", ""]]}, {"id": "1011.6293", "submitter": "David Knowles", "authors": "David Knowles, Zoubin Ghahramani", "title": "Nonparametric Bayesian sparse factor models with application to gene\n  expression modeling", "comments": "Published in at http://dx.doi.org/10.1214/10-AOAS435 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2011, Vol. 5, No. 2B, 1534-1552", "doi": "10.1214/10-AOAS435", "report-no": "IMS-AOAS-AOAS435", "categories": "stat.AP cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A nonparametric Bayesian extension of Factor Analysis (FA) is proposed where\nobserved data $\\mathbf{Y}$ is modeled as a linear superposition, $\\mathbf{G}$,\nof a potentially infinite number of hidden factors, $\\mathbf{X}$. The Indian\nBuffet Process (IBP) is used as a prior on $\\mathbf{G}$ to incorporate sparsity\nand to allow the number of latent features to be inferred. The model's utility\nfor modeling gene expression data is investigated using randomly generated data\nsets based on a known sparse connectivity matrix for E. Coli, and on three\nbiological data sets of increasing complexity.\n", "versions": [{"version": "v1", "created": "Mon, 29 Nov 2010 17:06:41 GMT"}, {"version": "v2", "created": "Thu, 28 Jul 2011 12:20:24 GMT"}], "update_date": "2011-07-29", "authors_parsed": [["Knowles", "David", ""], ["Ghahramani", "Zoubin", ""]]}]