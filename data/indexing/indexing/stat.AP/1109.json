[{"id": "1109.0152", "submitter": "Bernd Fellinghauer", "authors": "Bernd Fellinghauer, Peter B\\\"uhlmann, Martin Ryffel, Michael von Rhein\n  and Jan D. Reinhardt", "title": "Stable Graphical Model Estimation with Random Forests for Discrete,\n  Continuous, and Mixed Variables", "comments": "The authors report no conflict of interest. There was no external\n  funding", "journal-ref": null, "doi": "10.1016/j.csda.2013.02.022", "report-no": null, "categories": "stat.ME stat.AP stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A conditional independence graph is a concise representation of pairwise\nconditional independence among many variables. Graphical Random Forests (GRaFo)\nare a novel method for estimating pairwise conditional independence\nrelationships among mixed-type, i.e. continuous and discrete, variables. The\nnumber of edges is a tuning parameter in any graphical model estimator and\nthere is no obvious number that constitutes a good choice. Stability Selection\nhelps choosing this parameter with respect to a bound on the expected number of\nfalse positives (error control).\n  The performance of GRaFo is evaluated and compared with various other methods\nfor p = 50, 100, and 200 possibly mixed-type variables while sample size is n =\n100 (n = 500 for maximum likelihood). Furthermore, GRaFo is applied to data\nfrom the Swiss Health Survey in order to evaluate how well it can reproduce the\ninterconnection of functional health components, personal, and environmental\nfactors, as hypothesized by the World Health Organization's International\nClassification of Functioning, Disability and Health (ICF). Finally, GRaFo is\nused to identify risk factors which may be associated with adverse\nneurodevelopment of children who suffer from trisomy 21 and experienced\nopen-heart surgery.\n  GRaFo performs well with mixed data and thanks to Stability Selection it\nprovides an error control mechanism for false positive selection.\n", "versions": [{"version": "v1", "created": "Thu, 1 Sep 2011 11:20:49 GMT"}, {"version": "v2", "created": "Fri, 30 Nov 2012 21:30:12 GMT"}], "update_date": "2013-04-08", "authors_parsed": [["Fellinghauer", "Bernd", ""], ["B\u00fchlmann", "Peter", ""], ["Ryffel", "Martin", ""], ["von Rhein", "Michael", ""], ["Reinhardt", "Jan D.", ""]]}, {"id": "1109.0262", "submitter": "Gail E. Potter", "authors": "Gail E. Potter, Mark S. Handcock, Ira M. Longini, Jr., M. Elizabeth\n  Halloran", "title": "Estimating within-school contact networks to understand influenza\n  transmission", "comments": "Published in at http://dx.doi.org/10.1214/11-AOAS505 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2012, Vol. 6, No. 1, 1-26", "doi": "10.1214/11-AOAS505", "report-no": "IMS-AOAS-AOAS505", "categories": "stat.ME cs.SI physics.soc-ph stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many epidemic models approximate social contact behavior by assuming random\nmixing within mixing groups (e.g., homes, schools and workplaces). The effect\nof more realistic social network structure on estimates of epidemic parameters\nis an open area of exploration. We develop a detailed statistical model to\nestimate the social contact network within a high school using friendship\nnetwork data and a survey of contact behavior. Our contact network model\nincludes classroom structure, longer durations of contacts to friends than\nnonfriends and more frequent contacts with friends, based on reports in the\ncontact survey. We performed simulation studies to explore which network\nstructures are relevant to influenza transmission. These studies yield two key\nfindings. First, we found that the friendship network structure important to\nthe transmission process can be adequately represented by a dyad-independent\nexponential random graph model (ERGM). This means that individual-level sampled\ndata is sufficient to characterize the entire friendship network. Second, we\nfound that contact behavior was adequately represented by a static rather than\ndynamic contact network.\n", "versions": [{"version": "v1", "created": "Thu, 1 Sep 2011 19:00:15 GMT"}, {"version": "v2", "created": "Thu, 6 Oct 2011 23:18:57 GMT"}, {"version": "v3", "created": "Tue, 18 Oct 2011 19:17:13 GMT"}, {"version": "v4", "created": "Thu, 15 Mar 2012 14:04:54 GMT"}], "update_date": "2012-08-27", "authors_parsed": [["Potter", "Gail E.", ""], ["Handcock", "Mark S.", ""], ["Longini,", "Ira M.", "Jr."], ["Halloran", "M. Elizabeth", ""]]}, {"id": "1109.0701", "submitter": "Bryony J. Hill", "authors": "Bryony J. Hill, Wilfrid S. Kendall, Elke Th\\\"onnes", "title": "Fibre-generated point processes and fields of orientations", "comments": "Published in at http://dx.doi.org/10.1214/12-AOAS553 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2012, Vol. 6, No. 3, 994-1020", "doi": "10.1214/12-AOAS553", "report-no": "IMS-AOAS-AOAS553", "categories": "stat.ME stat.AP stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a new approach to analyzing spatial point data\nclustered along or around a system of curves or \"fibres.\" Such data arise in\ncatalogues of galaxy locations, recorded locations of earthquakes, aerial\nimages of minefields and pore patterns on fingerprints. Finding the underlying\ncurvilinear structure of these point-pattern data sets may not only facilitate\na better understanding of how they arise but also aid reconstruction of missing\ndata. We base the space of fibres on the set of integral lines of an\norientation field. Using an empirical Bayes approach, we estimate the field of\norientations from anisotropic features of the data. We then sample from the\nposterior distribution of fibres, exploring models with different numbers of\nclusters, fitting fibres to the clusters as we proceed. The Bayesian approach\npermits inference on various properties of the clusters and associated fibres,\nand the results perform well on a number of very different curvilinear\nstructures.\n", "versions": [{"version": "v1", "created": "Sun, 4 Sep 2011 11:36:33 GMT"}, {"version": "v2", "created": "Mon, 19 Mar 2012 16:48:33 GMT"}, {"version": "v3", "created": "Fri, 28 Sep 2012 06:45:09 GMT"}], "update_date": "2012-10-01", "authors_parsed": [["Hill", "Bryony J.", ""], ["Kendall", "Wilfrid S.", ""], ["Th\u00f6nnes", "Elke", ""]]}, {"id": "1109.0863", "submitter": "Antti Honkela", "authors": "Peter Glaus, Antti Honkela and Magnus Rattray", "title": "Identifying differentially expressed transcripts from RNA-seq data with\n  biological variation", "comments": "12 pages, 6 figures in main text; 11 pages, 5 figures in\n  supplementary information (included in the same file)", "journal-ref": "Bioinformatics 28(13):1721-1728, 2012", "doi": "10.1093/bioinformatics/bts260", "report-no": null, "categories": "q-bio.GN stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivation: High-throughput sequencing enables expression analysis at the\nlevel of individual transcripts. The analysis of transcriptome expression\nlevels and differential expression estimation requires a probabilistic approach\nto properly account for ambiguity caused by shared exons and finite read\nsampling as well as the intrinsic biological variance of transcript expression.\n  Results: We present BitSeq (Bayesian Inference of Transcripts from Sequencing\ndata), a Bayesian approach for estimation of transcript expression level from\nRNA-seq experiments. Inferred relative expression is represented by Markov\nchain Monte Carlo (MCMC) samples from the posterior probability distribution of\na generative model of the read data. We propose a novel method for differential\nexpression analysis across replicates which propagates uncertainty from the\nsample-level model while modelling biological variance using an\nexpression-level-dependent prior. We demonstrate the advantages of our method\nusing simulated data as well as an RNA-seq dataset with technical and\nbiological replication for both studied conditions.\n  Availability: The implementation of the transcriptome expression estimation\nand differential expression analysis, BitSeq, has been written in C++.\n", "versions": [{"version": "v1", "created": "Mon, 5 Sep 2011 11:49:04 GMT"}, {"version": "v2", "created": "Mon, 5 Mar 2012 13:35:07 GMT"}], "update_date": "2012-10-10", "authors_parsed": [["Glaus", "Peter", ""], ["Honkela", "Antti", ""], ["Rattray", "Magnus", ""]]}, {"id": "1109.1172", "submitter": "Piet Groeneboom", "authors": "Piet Groeneboom, Geurt Jongbloed and Birgit Witte", "title": "A maximum smoothed likelihood estimator in the current status continuous\n  mark model", "comments": "24 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of estimating the joint distribution function of the\nevent time and a continuous mark variable based on censored data. More\nspecifically, the event time is subject to current status censoring and the\ncontinuous mark is only observed in case inspection takes place after the event\ntime. The nonparametric maximum likelihood estimator (MLE) in this model is\nknown to be inconsistent. We propose and study an alternative likelihood based\nestimator, maximizing a smoothed log-likelihood, hence called a maximum\nsmoothed likelihood estimator (MSLE). This estimator is shown to be well\ndefined and consistent, and a simple algorithm is described that can be used to\ncompute it. The MSLE is compared with other estimators in a small simulation\nstudy.\n", "versions": [{"version": "v1", "created": "Tue, 6 Sep 2011 13:18:31 GMT"}], "update_date": "2011-09-07", "authors_parsed": [["Groeneboom", "Piet", ""], ["Jongbloed", "Geurt", ""], ["Witte", "Birgit", ""]]}, {"id": "1109.1402", "submitter": "Andrea Rau", "authors": "Andrea Rau, Florence Jaffr\\'ezic, Jean-Louis Foulley, R.W. Doerge", "title": "Reverse engineering gene regulatory networks using approximate Bayesian\n  computation", "comments": "16 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": "Purdue University Technical Report #11-02", "categories": "stat.AP q-bio.MN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gene regulatory networks are collections of genes that interact with one\nother and with other substances in the cell. By measuring gene expression over\ntime using high-throughput technologies, it may be possible to reverse\nengineer, or infer, the structure of the gene network involved in a particular\ncellular process. These gene expression data typically have a high\ndimensionality and a limited number of biological replicates and time points.\nDue to these issues and the complexity of biological systems, the problem of\nreverse engineering networks from gene expression data demands a specialized\nsuite of statistical tools and methodologies. We propose a non-standard\nadaptation of a simulation-based approach known as Approximate Bayesian\nComputing based on Markov chain Monte Carlo sampling. This approach is\nparticularly well suited for the inference of gene regulatory networks from\nlongitudinal data. The performance of this approach is investigated via\nsimulations and using longitudinal expression data from a genetic repair system\nin Escherichia coli.\n", "versions": [{"version": "v1", "created": "Wed, 7 Sep 2011 09:48:15 GMT"}], "update_date": "2011-09-08", "authors_parsed": [["Rau", "Andrea", ""], ["Jaffr\u00e9zic", "Florence", ""], ["Foulley", "Jean-Louis", ""], ["Doerge", "R. W.", ""]]}, {"id": "1109.1746", "submitter": "Taha Yasseri", "authors": "Taha Yasseri, R\\'obert Sumi, J\\'anos Kert\\'esz", "title": "Circadian patterns of Wikipedia editorial activity: A demographic\n  analysis", "comments": null, "journal-ref": "PLoS ONE 7(1): e30091 (2012)", "doi": "10.1371/journal.pone.0030091", "report-no": null, "categories": "physics.soc-ph cs.SI stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wikipedia (WP) as a collaborative, dynamical system of humans is an\nappropriate subject of social studies. Each single action of the members of\nthis society, i.e. editors, is well recorded and accessible. Using the\ncumulative data of 34 Wikipedias in different languages, we try to characterize\nand find the universalities and differences in temporal activity patterns of\neditors. Based on this data, we estimate the geographical distribution of\neditors for each WP in the globe. Furthermore we also clarify the differences\namong different groups of WPs, which originate in the variance of cultural and\nsocial features of the communities of editors.\n", "versions": [{"version": "v1", "created": "Thu, 8 Sep 2011 15:32:54 GMT"}, {"version": "v2", "created": "Fri, 14 Oct 2011 15:27:17 GMT"}, {"version": "v3", "created": "Mon, 28 Nov 2011 21:48:32 GMT"}], "update_date": "2012-01-19", "authors_parsed": [["Yasseri", "Taha", ""], ["Sumi", "R\u00f3bert", ""], ["Kert\u00e9sz", "J\u00e1nos", ""]]}, {"id": "1109.2044", "submitter": "Piotr Migda{\\l}", "authors": "Piotr Migda{\\l}, Micha{\\l} Denkiewicz, Joanna R\\c{a}czaszek-Leonardi,\n  Dariusz Plewczynski", "title": "Information-sharing and aggregation models for interacting minds", "comments": "22 pages, 4 figures, 2 tables; after the final revision", "journal-ref": "Journal of Mathematical Psychology 56 (2012) 417-426", "doi": "10.1016/j.jmp.2013.01.002", "report-no": null, "categories": "physics.soc-ph cs.SI stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study mathematical models of the collaborative solving of a two-choice\ndiscrimination task. We estimate the difference between the shared performance\nfor a group of n observers over a single person performance. Our paper is a\ntheoretical extension of the recent work of Bahrami et al. (2010) from a dyad\n(a pair) to a group of n interacting minds. We analyze several models of\ncommunication, decision-making and hierarchical information-aggregation.\n  The maximal slope of psychometric function (closely related to the percentage\nof right answers vs. easiness of the task) is a convenient parameter\ncharacterizing performance. For every model we investigated, the group\nperformance turns out to be a product of two numbers: a scaling factor\ndepending of the group size and an average performance. The scaling factor is a\npower function of the group size (with the exponent ranging from 0 to 1),\nwhereas the average is arithmetic mean, quadratic mean, or maximum of the\nindividual slopes. Moreover, voting can be almost as efficient as more\nelaborate communication models, given the participants have similar individual\nperformances.\n", "versions": [{"version": "v1", "created": "Fri, 9 Sep 2011 15:47:40 GMT"}, {"version": "v2", "created": "Tue, 6 Mar 2012 16:37:03 GMT"}, {"version": "v3", "created": "Sun, 10 Mar 2013 19:53:12 GMT"}, {"version": "v4", "created": "Tue, 12 Mar 2013 13:31:56 GMT"}], "update_date": "2013-03-13", "authors_parsed": [["Migda\u0142", "Piotr", ""], ["Denkiewicz", "Micha\u0142", ""], ["Rcaczaszek-Leonardi", "Joanna", ""], ["Plewczynski", "Dariusz", ""]]}, {"id": "1109.2272", "submitter": "Mikhail Simkin", "authors": "M.V. Simkin and V.P. Roychowdhury", "title": "Theory of citing", "comments": null, "journal-ref": "Theory of citing. In M.T. Thai and P.M. Pardalos (eds.), Handbook\n  of Optimization in Complex Networks: Theory and Applications, Springer\n  Optimization and Its Applications 57, 2012", "doi": "10.1007/978-1-4614-0754-6_16", "report-no": null, "categories": "physics.soc-ph cond-mat.dis-nn stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present empirical data on misprints in citations to twelve high-profile\npapers. The great majority of misprints are identical to misprints in articles\nthat earlier cited the same paper. The distribution of the numbers of misprint\nrepetitions follows a power law. We develop a stochastic model of the citation\nprocess, which explains these findings and shows that about 70-90% of\nscientific citations are copied from the lists of references used in other\npapers. Citation copying can explain not only why some misprints become\npopular, but also why some papers become highly cited. We show that a model\nwhere a scientist picks few random papers, cites them, and copies a fraction of\ntheir references accounts quantitatively for empirically observed distribution\nof citations.\n", "versions": [{"version": "v1", "created": "Sun, 11 Sep 2011 01:10:45 GMT"}], "update_date": "2011-09-13", "authors_parsed": [["Simkin", "M. V.", ""], ["Roychowdhury", "V. P.", ""]]}, {"id": "1109.2363", "submitter": "Douglas Cochran", "authors": "Alfred O. Hero III, Douglas Cochran", "title": "Sensor Management: Past, Present, and Future", "comments": "15 pages, 112 references", "journal-ref": "IEEE Sensors Journal, vol. 11, issue 12, pp. 3064-3075, December\n  2011", "doi": null, "report-no": null, "categories": "stat.AP cs.RO cs.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sensor systems typically operate under resource constraints that prevent the\nsimultaneous use of all resources all of the time. Sensor management becomes\nrelevant when the sensing system has the capability of actively managing these\nresources; i.e., changing its operating configuration during deployment in\nreaction to previous measurements. Examples of systems in which sensor\nmanagement is currently used or is likely to be used in the near future include\nautonomous robots, surveillance and reconnaissance networks, and waveform-agile\nradars. This paper provides an overview of the theory, algorithms, and\napplications of sensor management as it has developed over the past decades and\nas it stands today.\n", "versions": [{"version": "v1", "created": "Mon, 12 Sep 2011 00:13:10 GMT"}], "update_date": "2012-05-31", "authors_parsed": [["Hero", "Alfred O.", "III"], ["Cochran", "Douglas", ""]]}, {"id": "1109.2527", "submitter": "SM Enayetur Raheem", "authors": "SM Enayetur Raheem and S. Ejaz Ahmed", "title": "Positive-shrinkage and Pretest Estimation in Multiple Regression: A\n  Monte Carlo study with Applications", "comments": "17 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a problem of predicting a response variable using a set of\ncovariates in a linear regression model. If it is \\emph{a priori} known or\nsuspected that a subset of the covariates do not significantly contribute to\nthe overall fit of the model, a restricted model that excludes these\ncovariates, may be sufficient. If, on the other hand, the subset provides\nuseful information, shrinkage method combines restricted and unrestricted\nestimators to obtain the parameter estimates. Such an estimator outperforms the\nclassical maximum likelihood estimators. Any \\emph{prior} information may be\nvalidated through preliminary test (or pretest), and depending on the validity,\nmay be incorporated in the model as a parametric restriction. Thus, pretest\nestimator chooses between the restricted and unrestricted estimators depending\non the outcome of the preliminary test. Examples using three real life data\nsets are provided to illustrate the application of shrinkage and pretest\nestimation. Performance of positive-shrinkage and pretest estimators are\ncompared with unrestricted estimator under varying degree of uncertainty of the\nprior information. Monte Carlo study reconfirms the asymptotic properties of\nthe estimators available in the literature.\n", "versions": [{"version": "v1", "created": "Mon, 12 Sep 2011 16:40:36 GMT"}], "update_date": "2011-09-13", "authors_parsed": [["Raheem", "SM Enayetur", ""], ["Ahmed", "S. Ejaz", ""]]}, {"id": "1109.3160", "submitter": "Natallia Katenka Dr", "authors": "Natallia Katenka and Eric D. Kolaczyk", "title": "Inference and Characterization of Multi-Attribute Networks with\n  Application to Computational Biology", "comments": "Updated bibliography references", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.SI physics.soc-ph q-bio.MN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our work is motivated by and illustrated with application of association\nnetworks in computational biology, specifically in the context of gene/protein\nregulatory networks. Association networks represent systems of interacting\nelements, where a link between two different elements indicates a sufficient\nlevel of similarity between element attributes. While in reality relational\nties between elements can be expected to be based on similarity across multiple\nattributes, the vast majority of work to date on association networks involves\nties defined with respect to only a single attribute. We propose an approach\nfor the inference of multi-attribute association networks from measurements on\ncontinuous attribute variables, using canonical correlation and a\nhypothesis-testing strategy. Within this context, we then study the impact of\npartial information on multi-attribute network inference and characterization,\nwhen only a subset of attributes is available. We consider in detail the case\nof two attributes, wherein we examine through a combination of analytical and\nnumerical techniques the implications of the choice and number of node\nattributes on the ability to detect network links and, more generally, to\nestimate higher-level network summary statistics, such as node degree,\nclustering coefficients, and measures of centrality. Illustration and\napplications throughout the paper are developed using gene and protein\nexpression measurements on human cancer cell lines from the NCI-60 database.\n", "versions": [{"version": "v1", "created": "Wed, 14 Sep 2011 18:29:47 GMT"}, {"version": "v2", "created": "Fri, 23 Sep 2011 18:05:01 GMT"}, {"version": "v3", "created": "Fri, 27 Apr 2012 21:31:11 GMT"}], "update_date": "2012-05-01", "authors_parsed": [["Katenka", "Natallia", ""], ["Kolaczyk", "Eric D.", ""]]}, {"id": "1109.3488", "submitter": "Andrew Clark", "authors": "Andrew Clark and Jeff Kenyon", "title": "Using MOEAs To Outperform Stock Benchmarks In The Presence of Typical\n  Investment Constraints", "comments": "21 pages, Index Terms - multi-objective evolutionary algorithms\n  (MOEA), mean-variance optimization, financial constraints, multi-period MOEAs\n  Updated version of paper. Will appear in Journal of Investing in 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PM cs.CE cs.NE stat.AP stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Portfolio managers are typically constrained by turnover limits, minimum and\nmaximum stock positions, cardinality, a target market capitalization and\nsometimes the need to hew to a style (such as growth or value). In addition,\nportfolio managers often use multifactor stock models to choose stocks based\nupon their respective fundamental data.\n  We use multiobjective evolutionary algorithms (MOEAs) to satisfy the above\nreal-world constraints. The portfolios generated consistently outperform\ntypical performance benchmarks and have statistically significant asset\nselection.\n", "versions": [{"version": "v1", "created": "Thu, 15 Sep 2011 21:15:22 GMT"}, {"version": "v2", "created": "Mon, 2 Jan 2012 21:33:25 GMT"}], "update_date": "2012-01-04", "authors_parsed": [["Clark", "Andrew", ""], ["Kenyon", "Jeff", ""]]}, {"id": "1109.3829", "submitter": "Pierre E. Jacob", "authors": "Luke Bornn (Harvard University), Pierre Jacob (Universite Paris\n  Dauphine), Pierre Del Moral (INRIA Bordeaux Sud-Ouest and Universite de\n  Bordeaux), Arnaud Doucet (University of Oxford)", "title": "An Adaptive Interacting Wang-Landau Algorithm for Automatic Density\n  Exploration", "comments": "33 pages, 20 figures (the supplementary materials are included as\n  appendices)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While statisticians are well-accustomed to performing exploratory analysis in\nthe modeling stage of an analysis, the notion of conducting preliminary\ngeneral-purpose exploratory analysis in the Monte Carlo stage (or more\ngenerally, the model-fitting stage) of an analysis is an area which we feel\ndeserves much further attention. Towards this aim, this paper proposes a\ngeneral-purpose algorithm for automatic density exploration. The proposed\nexploration algorithm combines and expands upon components from various\nadaptive Markov chain Monte Carlo methods, with the Wang-Landau algorithm at\nits heart. Additionally, the algorithm is run on interacting parallel chains --\na feature which both decreases computational cost as well as stabilizes the\nalgorithm, improving its ability to explore the density. Performance is studied\nin several applications. Through a Bayesian variable selection example, the\nauthors demonstrate the convergence gains obtained with interacting chains. The\nability of the algorithm's adaptive proposal to induce mode-jumping is\nillustrated through a trimodal density and a Bayesian mixture modeling\napplication. Lastly, through a 2D Ising model, the authors demonstrate the\nability of the algorithm to overcome the high correlations encountered in\nspatial models.\n", "versions": [{"version": "v1", "created": "Sun, 18 Sep 2011 01:02:31 GMT"}, {"version": "v2", "created": "Wed, 25 Apr 2012 07:03:31 GMT"}, {"version": "v3", "created": "Thu, 14 Jun 2012 04:10:10 GMT"}], "update_date": "2012-06-15", "authors_parsed": [["Bornn", "Luke", "", "Harvard University"], ["Jacob", "Pierre", "", "Universite Paris\n  Dauphine"], ["Del Moral", "Pierre", "", "INRIA Bordeaux Sud-Ouest and Universite de\n  Bordeaux"], ["Doucet", "Arnaud", "", "University of Oxford"]]}, {"id": "1109.4168", "submitter": "Robert Erhardt", "authors": "Robert J. Erhardt, Richard L. Smith", "title": "Pricing Weather Derivatives for Extreme Events", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider pricing weather derivatives for use as protection against weather\nextremes. The method described utilizes results from spatial statistics and\nextreme value theory to first model extremes in the weather as a max-stable\nprocess, and then use these models to simulate payments for a general\ncollection of weather derivatives. These simulations capture the spatial\ndependence of payments. Incorporating results from catastrophe ratemaking, we\nshow how this method can be used to compute risk loads and premiums for weather\nderivatives which are renewal-additive.\n", "versions": [{"version": "v1", "created": "Mon, 19 Sep 2011 20:47:16 GMT"}], "update_date": "2011-09-21", "authors_parsed": [["Erhardt", "Robert J.", ""], ["Smith", "Richard L.", ""]]}, {"id": "1109.4518", "submitter": "Matt Taddy", "authors": "Matthew A. Taddy", "title": "On Estimation and Selection for Topic Models", "comments": "Scheduled to appear in the proceedings of AISTATS 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article describes posterior maximization for topic models, identifying\ncomputational and conceptual gains from inference under a non-standard\nparametrization. We then show that fitted parameters can be used as the basis\nfor a novel approach to marginal likelihood estimation, via block-diagonal\napproximation to the information matrix,that facilitates choosing the number of\nlatent topics. This likelihood-based model selection is complemented with a\ngoodness-of-fit analysis built around estimated residual dispersion. Examples\nare provided to illustrate model selection as well as to compare our estimation\nagainst standard alternative techniques.\n", "versions": [{"version": "v1", "created": "Wed, 21 Sep 2011 13:14:49 GMT"}, {"version": "v2", "created": "Tue, 25 Oct 2011 21:01:38 GMT"}, {"version": "v3", "created": "Tue, 27 Dec 2011 22:55:40 GMT"}], "update_date": "2011-12-30", "authors_parsed": [["Taddy", "Matthew A.", ""]]}, {"id": "1109.4533", "submitter": "Anne Philippe", "authors": "Tristan Launay (LMJL), Anne Philippe (LMJL), Sophie Lamarche", "title": "Construction of an informative hierarchical prior for a small sample\n  with the help of historical data and application to electricity load\n  forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are interested in the estimation and prediction of a parametric model on a\nshort dataset upon which it is expected to overfit and perform badly. To\novercome the lack of data (relatively to the dimension of the model) we propose\nthe construction of an informative hierarchical Bayesian prior based upon\nanother longer dataset which is assumed to share some similarities with the\noriginal, short dataset. We illustrate the performance of our prior on\nsimulated dataset from three standard models. Then we apply the methodology to\na working model for the electricity load forecasting on real datasets, where it\nleads to a substantial improvement of the quality of the predictions.\n", "versions": [{"version": "v1", "created": "Wed, 21 Sep 2011 14:08:57 GMT"}, {"version": "v2", "created": "Mon, 12 Mar 2012 07:35:47 GMT"}, {"version": "v3", "created": "Thu, 21 Jun 2012 19:00:57 GMT"}, {"version": "v4", "created": "Tue, 3 Jul 2012 13:19:30 GMT"}, {"version": "v5", "created": "Tue, 25 Mar 2014 18:36:23 GMT"}], "update_date": "2014-03-26", "authors_parsed": [["Launay", "Tristan", "", "LMJL"], ["Philippe", "Anne", "", "LMJL"], ["Lamarche", "Sophie", ""]]}, {"id": "1109.4928", "submitter": "Leo Lahti", "authors": "Leo Lahti, Laura L. Elo, Tero Aittokallio, Samuel Kaski", "title": "RPA: Probabilistic analysis of probe performance and robust\n  summarization", "comments": "Replaced by extended work which forms an independent publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE stat.AP stat.ML", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Probe-level models have led to improved performance in microarray studies but\nthe various sources of probe-level contamination are still poorly understood.\nData-driven analysis of probe performance can be used to quantify the\nuncertainty in individual probes and to highlight the relative contribution of\ndifferent noise sources. Improved understanding of the probe-level effects can\nlead to improved preprocessing techniques and microarray design.\n  We have implemented probabilistic tools for probe performance analysis and\nsummarization on short oligonucleotide arrays. In contrast to standard\npreprocessing approaches, the methods provide quantitative estimates of\nprobe-specific noise and affinity terms and tools to investigate these\nparameters. Tools to incorporate prior information of the probes in the\nanalysis are provided as well. Comparisons to known probe-level error sources\nand spike-in data sets validate the approach.\n  Implementation is freely available in R/BioConductor:\nhttp://www.bioconductor.org/packages/release/bioc/html/RPA.html\n", "versions": [{"version": "v1", "created": "Thu, 22 Sep 2011 19:46:02 GMT"}, {"version": "v2", "created": "Sat, 6 Apr 2013 09:39:10 GMT"}], "update_date": "2013-04-09", "authors_parsed": [["Lahti", "Leo", ""], ["Elo", "Laura L.", ""], ["Aittokallio", "Tero", ""], ["Kaski", "Samuel", ""]]}, {"id": "1109.4962", "submitter": "Yvik Swan", "authors": "Christophe Ley, Yvik Swan, Baba Thiam and Thomas Verdebout", "title": "Optimal R-Estimation of a Spherical Location", "comments": "Accepted in Statistica Sinica", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we provide $R$-estimators of the location of a rotationally\nsymmetric distribution on the unit sphere of $\\R^k$. In order to do so we first\nprove the local asymptotic normality property of a sequence of rotationally\nsymmetric models; this is a non standard result due to the curved nature of the\nunit sphere. We then construct our estimators by adapting the Le Cam one-step\nmethodology to spherical statistics and ranks. We show that they are\nasymptotically normal under any rotationally symmetric distribution and achieve\nthe efficiency bound under a specific density. Their small sample behavior is\nstudied via a Monte Carlo simulation and our methodology is illustrated on\ngeological data.\n", "versions": [{"version": "v1", "created": "Thu, 22 Sep 2011 22:20:48 GMT"}, {"version": "v2", "created": "Tue, 27 Mar 2012 19:06:04 GMT"}], "update_date": "2012-03-28", "authors_parsed": [["Ley", "Christophe", ""], ["Swan", "Yvik", ""], ["Thiam", "Baba", ""], ["Verdebout", "Thomas", ""]]}, {"id": "1109.5316", "submitter": "Tim Leung", "authors": "Tim Leung and Qingshuo Song and Jie Yang", "title": "Outperformance Portfolio Optimization via the Equivalence of Pure and\n  Randomized Hypothesis Testing", "comments": "34 pages, 3 figures", "journal-ref": null, "doi": "10.1007/s00780-013-0213-8", "report-no": null, "categories": "q-fin.PM stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the portfolio problem of maximizing the outperformance probability\nover a random benchmark through dynamic trading with a fixed initial capital.\nUnder a general incomplete market framework, this stochastic control problem\ncan be formulated as a composite pure hypothesis testing problem. We analyze\nthe connection between this pure testing problem and its randomized\ncounterpart, and from latter we derive a dual representation for the maximal\noutperformance probability. Moreover, in a complete market setting, we provide\na closed-form solution to the problem of beating a leveraged exchange traded\nfund. For a general benchmark under an incomplete stochastic factor model, we\nprovide the Hamilton-Jacobi-Bellman PDE characterization for the maximal\noutperformance probability.\n", "versions": [{"version": "v1", "created": "Sun, 25 Sep 2011 01:32:32 GMT"}, {"version": "v2", "created": "Wed, 23 Nov 2011 22:00:59 GMT"}, {"version": "v3", "created": "Tue, 17 Jan 2012 07:57:15 GMT"}, {"version": "v4", "created": "Fri, 10 Aug 2012 02:28:17 GMT"}, {"version": "v5", "created": "Tue, 27 Nov 2012 01:03:53 GMT"}, {"version": "v6", "created": "Sun, 31 Mar 2013 23:20:04 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Leung", "Tim", ""], ["Song", "Qingshuo", ""], ["Yang", "Jie", ""]]}, {"id": "1109.5485", "submitter": "Marta Ferreira", "authors": "Marta Ferreira", "title": "A new estimator for the tail-dependence coefficient", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the concept of tail dependence has been discussed in financial\napplications related to market or credit risk. The multivariate extreme value\ntheory is a proper tool to measure and model dependence, for example, of large\nloss events. A common measure of tail dependence is given by the so-called\ntail-dependence coefficient. We present a simple estimator of this latter that\navoids the drawbacks of the estimation procedure that has been used so far. We\nprove strong consistency and asymptotic normality and analyze the finite sample\nbehavior through simulation. We illustrate with an application to financial\ndata.\n", "versions": [{"version": "v1", "created": "Mon, 26 Sep 2011 08:37:43 GMT"}], "update_date": "2011-09-27", "authors_parsed": [["Ferreira", "Marta", ""]]}, {"id": "1109.5791", "submitter": "Joachim Kaldasch", "authors": "Joachim Kaldasch", "title": "Dynamic Model of Markets of Homogenous Non-Durable", "comments": null, "journal-ref": "British Journal of Economics, Management & Trade 9(3): 1-12, 2015,\n  Article no.BJEMT.19254", "doi": null, "report-no": null, "categories": "stat.AP q-fin.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new microeconomic model is presented that aims at a description of the\nlong-term unit sales and price evolution of homogeneous non-durable goods in\npolypoly markets. It merges the product lifecycle approach with the price\ndispersion dynamics of homogeneous goods. The model predicts a minimum critical\nlifetime of non-durables in order to survive. Under the condition that the\nsupply side of the market evolves much faster than the demand side the theory\nsuggests that unsatisfied demands are present in the first stages of the\nlifecycle. With the growth of production capacities these demands disappear\naccompanied with a logistic decrease of the mean price of the good. The model\nis applied to electricity as a non-durable satisfying the model condition. The\npresented theory allows a deeper understanding of the sales and price dynamics\nof non-durables.\n", "versions": [{"version": "v1", "created": "Tue, 27 Sep 2011 07:12:16 GMT"}, {"version": "v2", "created": "Mon, 27 Jul 2015 15:19:39 GMT"}], "update_date": "2015-07-28", "authors_parsed": [["Kaldasch", "Joachim", ""]]}, {"id": "1109.5796", "submitter": "Xuan Vinh Nguyen", "authors": "Nguyen Xuan Vinh", "title": "Genetic Testing for Complex Diseases: a Simulation Study Perspective", "comments": "5 pages technical report", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.CE q-bio.GN q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is widely recognized nowadays that complex diseases are caused by, amongst\nthe others, multiple genetic factors. The recent advent of genome-wide\nassociation study (GWA) has triggered a wave of research aimed at discovering\ngenetic factors underlying common complex diseases. While the number of\nreported susceptible genetic variants is increasing steadily, the application\nof such findings into diseases prognosis for the general population is still\nunclear, and there are doubts about whether the size of the contribution by\nsuch factors is significant. In this respect, some recent simulation-based\nstudies have shed more light to the prospect of genetic tests. In this report,\nwe discuss several aspects of simulation-based studies: their parameters, their\nassumptions, and the information they provide.\n", "versions": [{"version": "v1", "created": "Tue, 27 Sep 2011 07:36:07 GMT"}, {"version": "v2", "created": "Thu, 29 Sep 2011 12:24:56 GMT"}], "update_date": "2011-09-30", "authors_parsed": [["Vinh", "Nguyen Xuan", ""]]}, {"id": "1109.6191", "submitter": "Ondrej Hlinka", "authors": "Ondrej Hlinka, Franz Hlawatsch, and Petar M. Djuric", "title": "Likelihood Consensus-Based Distributed Particle Filtering with\n  Distributed Proposal Density Adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a consensus-based distributed particle filter (PF) for wireless\nsensor networks. Each sensor runs a local PF to compute a global state estimate\nthat takes into account the measurements of all sensors. The local PFs use the\njoint (all-sensors) likelihood function, which is calculated in a distributed\nway by a novel generalization of the likelihood consensus scheme. A performance\nimprovement (or a reduction of the required number of particles) is achieved by\na novel distributed, consensus-based method for adapting the proposal densities\nof the local PFs. The performance of the proposed distributed PF is\ndemonstrated for a target tracking problem.\n", "versions": [{"version": "v1", "created": "Wed, 28 Sep 2011 12:58:56 GMT"}], "update_date": "2011-09-29", "authors_parsed": [["Hlinka", "Ondrej", ""], ["Hlawatsch", "Franz", ""], ["Djuric", "Petar M.", ""]]}, {"id": "1109.6565", "submitter": "Jacob Levman", "authors": "Jacob Levman", "title": "A Statistical Significance Simulation Study for the General Scientist", "comments": "16 pages, 3 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.OT physics.data-an stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When a scientist performs an experiment they normally acquire a set of\nmeasurements and are expected to demonstrate that their results are\n\"statistically significant\" thus confirming whatever hypothesis they are\ntesting. The main method for establishing statistical significance involves\ndemonstrating that there is a low probability that the observed experimental\nresults were the product of random chance. This is typically defined as p <\n0.05, which indicates there is less than a 5% chance that the observed results\noccurred randomly. This research study visually demonstrates that the commonly\nused definition for \"statistical significance\" can erroneously imply a\nsignificant finding. This is demonstrated by generating random Gaussian noise\ndata and analyzing that data using statistical testing based on the established\ntwo-sample t-test. This study demonstrates that insignificant yet\n\"statistically significant\" findings are possible at moderately large sample\nsizes which are very common in many fields of modern science.\n", "versions": [{"version": "v1", "created": "Thu, 29 Sep 2011 15:42:07 GMT"}], "update_date": "2011-09-30", "authors_parsed": [["Levman", "Jacob", ""]]}, {"id": "1109.6628", "submitter": "Yvik Swan", "authors": "Yves Dominicy, Christophe Ley and Yvik Swan", "title": "A Stochastic Analysis of Table Tennis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We establish a general formula for the distribution of the score in table\ntennis. We use this formula to derive the probability distribution (and hence\nthe expectation and variance) of the number of rallies necessary to achieve any\ngiven score. We use these findings to investigate the dependence of these\nquantities on the different parameters involved (number of points needed to win\na set, number of consecutive serves, etc.), with particular focus on the rule\nchange imposed in 2001 by the International Table Tennis Federation (ITTF).\nFinally we briefly indicate how our results can lead to more efficient\nestimation techniques of individual players' abilities.\n", "versions": [{"version": "v1", "created": "Tue, 27 Sep 2011 09:22:55 GMT"}], "update_date": "2011-10-02", "authors_parsed": [["Dominicy", "Yves", ""], ["Ley", "Christophe", ""], ["Swan", "Yvik", ""]]}, {"id": "1109.6760", "submitter": "Maxime Lenormand", "authors": "Maxime Lenormand (UR LISC), Sylvie Huet (UR LISC), Guillaume Deffuant\n  (UR LISC)", "title": "Deriving the number of jobs in proximity services from the number of\n  inhabitants in French rural municipalities", "comments": "6 pages, 5 figures", "journal-ref": "PLoS ONE 7, e40001 (2012)", "doi": "10.1371/journal.pone.0040001", "report-no": null, "categories": "stat.AP math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use a minimum requirement approach to derive the number of jobs in\nproximity services per inhabitant in French rural municipalities. We first\nclassify the municipalities according to their time distance to the\nmunicipality where the inhabitants go the most frequently to get services\n(called MFM). For each set corresponding to a range of time distance to MFM, we\nperform a quantile regression estimating the minimum number of service jobs per\ninhabitant, that we interpret as an estimation of the number of proximity jobs\nper inhabitant. We observe that the minimum number of service jobs per\ninhabitant is smaller in small municipalities. Moreover, for municipalities of\nsimilar sizes, when the distance to the MFM increases, we find that the number\nof jobs of proximity services per inhabitant increases.\n", "versions": [{"version": "v1", "created": "Fri, 30 Sep 2011 09:07:44 GMT"}, {"version": "v2", "created": "Wed, 7 Mar 2012 20:39:09 GMT"}, {"version": "v3", "created": "Thu, 7 May 2015 17:02:25 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Lenormand", "Maxime", "", "UR LISC"], ["Huet", "Sylvie", "", "UR LISC"], ["Deffuant", "Guillaume", "", "UR LISC"]]}]