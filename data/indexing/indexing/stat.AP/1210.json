[{"id": "1210.0225", "submitter": "Andrzej Jarynowski", "authors": "Andrzej Buda, Andrzej Jarynowski", "title": "Network structure of phonographic market with characteristic\n  similarities between musicians", "comments": "15p", "journal-ref": "ACTA PHYSICA POLONICA A, Vol. 123, No. 3 (2013)", "doi": null, "report-no": null, "categories": "nlin.AO cs.SI physics.soc-ph stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate relations between best selling artists in last decade on\nphonographic market and from perspective of listeners by using the Social\nNetwork Analyzes. Starting network is obtained from the matrix of correlations\nbetween the world's best selling artists by considering the synchronous time\nevolution of weekly record sales. This method reveals the structure of\nphonographic market, but we claim that it has no impact on people who see\nrelationship between artists and music genres. We compare 'sale' (based on\ncorrelation of record sales) or 'popularity' (based on data mining of the\nrecord charts) networks with 'similarity' (obtained mainly from survey within\nmusic experts opinion) and find no significant relations. We postulate that\nnon-laminar phenomena on this specific market introduce turbulence to how\npeople view relations of artists.\n", "versions": [{"version": "v1", "created": "Sun, 30 Sep 2012 17:59:52 GMT"}], "update_date": "2013-03-29", "authors_parsed": [["Buda", "Andrzej", ""], ["Jarynowski", "Andrzej", ""]]}, {"id": "1210.0286", "submitter": "Siddharth Reddy", "authors": "Siddharth G. Reddy, Weimin Xiao, and Preethi H. Gunaratne", "title": "MiRank: A bioinformatics tool for gene/miRNA ranking and pathway\n  profiling with TCGA-KEGG data sets", "comments": "Withdrawn", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM q-bio.MN stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Cancer Genome Atlas (TCGA) provides researchers with clinicopathological\ndata and genomic characterizations of various carcinomas. These data sets\ninclude expression microarrays for genes and microRNAs -- short, non-coding\nstrands of RNA that downregulate gene expression through RNA interference -- as\nwell as days_to_death and days_to_last_followup fields for each tumor sample.\nOur aim is to develop a software tool that screens TCGA data sets for\ngenes/miRNAs with functional involvement in specific cancers. Furthermore, our\ncomputational pipeline is intended to produce a set of visualizations, or\nprofiles, that place our screened outputs in a pathway-centric context. We\naccomplish our 'screening' by ranking genes/miRNAs by the correlation of their\nexpression misregulation with differential patient survival. In other words, if\na gene/miRNA is consistently misregulated in patients with poor survival rates\nand, on the other hand, is expressed more 'normally' in patients with longer\nsurvival rates, then it is ranked highly; if its misregulation has no such\ncorrelation with good/bad survival in patients, then its rank is low. Our\npathway profiling pipeline produces several outputs, which allow us to examine\nthe functional roles played by highly ranked genes discovered by our screening.\nRunning the OV (ovarian serous cystadenocarcinoma) data set through our\nanalysis pipeline, we find that several highly ranked pathways and functional\ngroups of genes (VEGF, Jun, Fos, etc.) have already been shown to play some\npart in the development of epithelial ovarian carcinomas. We also observe that\nthe dysfunction of the Wnt signaling pathway, which regulates cell-fate\nspecification and progenitor cell differentiation, has a disproportionate\nimpact on the survival of ovarian cancer patients.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2012 04:39:55 GMT"}, {"version": "v2", "created": "Thu, 4 Jul 2013 04:31:52 GMT"}], "update_date": "2013-07-05", "authors_parsed": [["Reddy", "Siddharth G.", ""], ["Xiao", "Weimin", ""], ["Gunaratne", "Preethi H.", ""]]}, {"id": "1210.0300", "submitter": "Hai Liu", "authors": "Hai Liu, Shuangge Ma, Richard Kronmal, Kung-Sik Chan", "title": "Semiparametric zero-inflated modeling in multi-ethnic study of\n  atherosclerosis (MESA)", "comments": "Published in at http://dx.doi.org/10.1214/11-AOAS534 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2012, Vol. 6, No. 3, 1236-1255", "doi": "10.1214/11-AOAS534", "report-no": "IMS-AOAS-AOAS534", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the Agatston score of coronary artery calcium (CAC) from the\nMulti-Ethnic Study of Atherosclerosis (MESA) using the semiparametric\nzero-inflated modeling approach, where the observed CAC scores from this cohort\nconsist of high frequency of zeroes and continuously distributed positive\nvalues. Both partially constrained and unconstrained models are considered to\ninvestigate the underlying biological processes of CAC development from zero to\npositive, and from small amount to large amount. Different from existing\nstudies, a model selection procedure based on likelihood cross-validation is\nadopted to identify the optimal model, which is justified by comparative Monte\nCarlo studies. A shrinkaged version of cubic regression spline is used for\nmodel estimation and variable selection simultaneously. When applying the\nproposed methods to the MESA data analysis, we show that the two biological\nmechanisms influencing the initiation of CAC and the magnitude of CAC when it\nis positive are better characterized by an unconstrained zero-inflated normal\nmodel. Our results are significantly different from those in published studies,\nand may provide further insights into the biological mechanisms underlying CAC\ndevelopment in humans. This highly flexible statistical framework can be\napplied to zero-inflated data analyses in other areas.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2012 07:35:13 GMT"}], "update_date": "2012-10-02", "authors_parsed": [["Liu", "Hai", ""], ["Ma", "Shuangge", ""], ["Kronmal", "Richard", ""], ["Chan", "Kung-Sik", ""]]}, {"id": "1210.0307", "submitter": "Ying Hung", "authors": "Ying Hung", "title": "Order selection in nonlinear time series models with application to the\n  study of cell memory", "comments": "Published in at http://dx.doi.org/10.1214/12-AOAS546 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2012, Vol. 6, No. 3, 1256-1279", "doi": "10.1214/12-AOAS546", "report-no": "IMS-AOAS-AOAS546", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cell adhesion experiments are biomechanical experiments studying the binding\nof a cell to another cell at the level of single molecules. Such a study plays\nan important role in tumor metastasis in cancer study. Motivated by analyzing a\nrepeated cell adhesion experiment, a new class of nonlinear time series models\nwith an order selection procedure is developed in this paper. Due to the\nnonlinearity, there are two types of overfitting. Therefore, a double penalized\napproach is introduced for order selection. To implement this approach, a\nglobal optimization algorithm using mixed integer programming is discussed. The\nprocedure is shown to be asymptotically consistent in estimating both the order\nand parameters of the proposed model. Simulations show that the new order\nselection approach outperforms standard methods. The finite-sample performance\nof the estimator is also examined via a simulation study. The application of\nthe proposed methodology to a T-cell experiment provides a better understanding\nof the kinetics and mechanics of cell adhesion, including quantifying the\nmemory effect on a repeated unbinding force experiment and identifying the\norder of the memory.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2012 08:20:52 GMT"}], "update_date": "2012-10-02", "authors_parsed": [["Hung", "Ying", ""]]}, {"id": "1210.0345", "submitter": "Yue S. Niu", "authors": "Yue S. Niu, Heping Zhang", "title": "The screening and ranking algorithm to detect DNA copy number variations", "comments": "Published in at http://dx.doi.org/10.1214/12-AOAS539 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2012, Vol. 6, No. 3, 1306-1326", "doi": "10.1214/12-AOAS539", "report-no": "IMS-AOAS-AOAS539", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  DNA Copy number variation (CNV) has recently gained considerable interest as\na source of genetic variation that likely influences phenotypic differences.\nMany statistical and computational methods have been proposed and applied to\ndetect CNVs based on data that generated by genome analysis platforms. However,\nmost algorithms are computationally intensive with complexity at least\n$O(n^2)$, where $n$ is the number of probes in the experiments. Moreover, the\ntheoretical properties of those existing methods are not well understood. A\nfaster and better characterized algorithm is desirable for the ultra high\nthroughput data. In this study, we propose the Screening and Ranking algorithm\n(SaRa) which can detect CNVs fast and accurately with complexity down to O(n).\nIn addition, we characterize theoretical properties and present numerical\nanalysis for our algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2012 10:36:10 GMT"}], "update_date": "2012-10-02", "authors_parsed": [["Niu", "Yue S.", ""], ["Zhang", "Heping", ""]]}, {"id": "1210.0493", "submitter": "Pavel  Krivitsky", "authors": "Pavel N. Krivitsky (School of Mathematics and Applied Statistics and\n  National Institute for Applied Statistics Research Australia (NIASRA),\n  University of Wollongong, Wollongong), Carter T. Butts (Departments of\n  Sociology and Statistics and Institute for Mathematical Behavioral Sciences,\n  University of California, Irvine)", "title": "Exponential-Family Random Graph Models for Rank-Order Relational Data", "comments": "50 pages, 6 figures, 4 tables, 1 algorithm. The paper has been\n  expanded and clarified, and some terms were changed", "journal-ref": "Krivitsky, P. N. & Butts, C. T. (2017) Exponential-Family Random\n  Graph Models for Rank-Order Relational Data. Sociological Methodology, 47(1):\n  68-112", "doi": "10.1177/0081175017692623", "report-no": null, "categories": "stat.ME stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rank-order relational data, in which each actor ranks the others according to\nsome criterion, often arise from sociometric measurements of judgment (e.g.,\nself-reported interpersonal interaction) or preference (e.g., relative liking).\nWe propose a class of exponential-family models for rank-order relational data\nand derive a new class of sufficient statistics for such data, which assume no\nmore than within-subject ordinal properties. Application of MCMC MLE to this\nfamily allows us to estimate effects for a variety of plausible mechanisms\ngoverning rank structure in cross-sectional context, and to model the evolution\nof such structures over time. We apply this framework to model the evolution of\nrelative liking judgments in an acquaintance process, and to model recall of\nrelative volume of interpersonal interaction among members of a technology\neducation program.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2012 18:21:12 GMT"}, {"version": "v2", "created": "Sat, 20 Jun 2015 13:49:12 GMT"}], "update_date": "2018-04-11", "authors_parsed": [["Krivitsky", "Pavel N.", "", "School of Mathematics and Applied Statistics and\n  National Institute for Applied Statistics Research Australia"], ["Butts", "Carter T.", "", "Departments of\n  Sociology and Statistics and Institute for Mathematical Behavioral Sciences,\n  University of California, Irvine"]]}, {"id": "1210.0557", "submitter": "Robert T. Krafty", "authors": "Robert T. Krafty, Martica Hall", "title": "Canonical correlation analysis between time series and static outcomes,\n  with application to the spectral analysis of heart rate variability", "comments": "Published in at http://dx.doi.org/10.1214/12-AOAS601 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2013, Vol. 7, No. 1, 570-587", "doi": "10.1214/12-AOAS601", "report-no": "IMS-AOAS-AOAS601", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although many studies collect biomedical time series signals from multiple\nsubjects, there is a dearth of models and methods for assessing the association\nbetween frequency domain properties of time series and other study outcomes.\nThis article introduces the random Cramer representation as a joint model for\ncollections of time series and static outcomes where power spectra are random\nfunctions that are correlated with the outcomes. A canonical correlation\nanalysis between cepstral coefficients and static outcomes is developed to\nprovide a flexible yet interpretable measure of association. Estimates of the\ncanonical correlations and weight functions are obtained from a canonical\ncorrelation analysis between the static outcomes and maximum Whittle likelihood\nestimates of truncated cepstral coefficients. The proposed methodology is used\nto analyze the association between the spectrum of heart rate variability and\nmeasures of sleep duration and fragmentation in a study of older adults who\nserve as the primary caregiver for their ill spouse.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2012 20:10:15 GMT"}, {"version": "v2", "created": "Wed, 16 Jan 2013 19:01:24 GMT"}, {"version": "v3", "created": "Fri, 24 May 2013 11:54:05 GMT"}], "update_date": "2015-03-13", "authors_parsed": [["Krafty", "Robert T.", ""], ["Hall", "Martica", ""]]}, {"id": "1210.0586", "submitter": "Elvan Ceyhan", "authors": "Elvan Ceyhan, K{\\i}van\\c{c} Ertu\\u{g}ay, \\c{S}ebnem D\\\"uzg\\\"un", "title": "Exploratory and Inferential Methods for Spatio-Temporal Analysis of\n  Residential Fire Clustering in Urban Areas", "comments": "37 pages, 23 figures", "journal-ref": null, "doi": null, "report-no": "#KU-EC-12-2", "categories": "stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The spatio-temporal analysis of residential fires could allow decision makers\nto plan effective resource allocations in fire management according to fire\nclustering levels in space and time. In this study, we provide guidelines for\nthe use of various methods in detecting the differences in clustering patterns\nof fire and non-fire (i.e., background residential) locations and how these\npatterns change over time. As a preliminary analysis step, various exploratory\ndata analysis methods, such as, intensity plots (i.e., kernel density\nestimates) are used. Moreover, the use of Diggle's D-function (a second order\nanalysis technique) is proposed for detecting the clustering of residential\nfire locations (if any) and whether there is additional clustering (or\nregularity) in the locations of the fires compared to background residential\npattern. A test for trend over time (in years, months, and weeks) of the fire\nlocation patterns are provided with a space-time interaction analysis by\nspatio-temporal K-function. Residential fire data from \\c{C}ankaya Municipality\nof Ankara, Turkey is used as an illustrative example. The presented methodology\nis also applicable to residential fire data from similar urban settings.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2012 21:33:06 GMT"}], "update_date": "2016-08-14", "authors_parsed": [["Ceyhan", "Elvan", ""], ["Ertu\u011fay", "K\u0131van\u00e7", ""], ["D\u00fczg\u00fcn", "\u015eebnem", ""]]}, {"id": "1210.0702", "submitter": "Matthias Kormaksson", "authors": "Matthias Kormaksson, James G. Booth, Maria E. Figueroa, Ari Melnick", "title": "Integrative Model-based clustering of microarray methylation and\n  expression data", "comments": "Published in at http://dx.doi.org/10.1214/11-AOAS533 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2012, Vol. 6, No. 3, 1327-1347", "doi": "10.1214/11-AOAS533", "report-no": "IMS-AOAS-AOAS533", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many fields, researchers are interested in large and complex biological\nprocesses. Two important examples are gene expression and DNA methylation in\ngenetics. One key problem is to identify aberrant patterns of these processes\nand discover biologically distinct groups. In this article we develop a\nmodel-based method for clustering such data. The basis of our method involves\nthe construction of a likelihood for any given partition of the subjects. We\nintroduce cluster specific latent indicators that, along with some standard\nassumptions, impose a specific mixture distribution on each cluster. Estimation\nis carried out using the EM algorithm. The methods extend naturally to multiple\ndata types of a similar nature, which leads to an integrated analysis over\nmultiple data platforms, resulting in higher discriminating power.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2012 09:03:20 GMT"}], "update_date": "2012-10-03", "authors_parsed": [["Kormaksson", "Matthias", ""], ["Booth", "James G.", ""], ["Figueroa", "Maria E.", ""], ["Melnick", "Ari", ""]]}, {"id": "1210.0732", "submitter": "Olesya Mryglod", "authors": "O. Mryglod, R. Kenna, Yu. Holovatch, and B. Berche", "title": "Absolute and specific measures of research group excellence", "comments": null, "journal-ref": "Scientometrics 95 (2013) 115-127", "doi": "10.1007/s11192-012-0874-7", "report-no": null, "categories": "stat.AP cs.DL physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A desirable goal of scientific management is to introduce, if it exists, a\nsimple and reliable way to measure the scientific excellence of publicly-funded\nresearch institutions and universities to serve as a basis for their ranking\nand financing. While citation-based indicators and metrics are easily\naccessible, they are far from being universally accepted as way to automate or\ninform evaluation processes or to replace evaluations based on peer review.\nHere we consider absolute measurements of research excellence at an\namalgamated, institutional level and specific measures of research excellence\nas performance per head. Using biology research institutions in the UK as a\ntest case, we examine the correlations between peer-review-based and\ncitation-based measures of research excellence on these two scales. We find\nthat citation-based indicators are very highly correlated with peer-evaluated\nmeasures of group strength but are poorly correlated with group quality. Thus,\nand almost paradoxically, our analysis indicates that citation counts could\npossibly form a basis for deciding on how to fund research institutions but\nthey should not be used as a basis for ranking them in terms of quality.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2012 11:20:23 GMT"}], "update_date": "2014-09-23", "authors_parsed": [["Mryglod", "O.", ""], ["Kenna", "R.", ""], ["Holovatch", "Yu.", ""], ["Berche", "B.", ""]]}, {"id": "1210.0770", "submitter": "Anne Philippe", "authors": "Tristan Launay (LMJL), Anne Philippe (LMJL), Sophie Lamarche", "title": "On particle filters applied to electricity load forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are interested in the online prediction of the electricity load, within\nthe Bayesian framework of dynamic models. We offer a review of sequential Monte\nCarlo methods, and provide the calculations needed for the derivation of\nso-called particles filters. We also discuss the practical issues arising from\ntheir use, and some of the variants proposed in the literature to deal with\nthem, giving detailed algorithms whenever possible for an easy implementation.\nWe propose an additional step to help make basic particle filters more robust\nwith regard to outlying observations. Finally we use such a particle filter to\nestimate a state-space model that includes exogenous variables in order to\nforecast the electricity load for the customers of the French electricity\ncompany \\'Electricit\\'e de France and discuss the various results obtained.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2012 13:34:18 GMT"}, {"version": "v2", "created": "Mon, 15 Apr 2013 18:05:11 GMT"}], "update_date": "2013-04-16", "authors_parsed": [["Launay", "Tristan", "", "LMJL"], ["Philippe", "Anne", "", "LMJL"], ["Lamarche", "Sophie", ""]]}, {"id": "1210.1226", "submitter": "Greg Finak", "authors": "Andrew McDavid, Greg Finak, Pratip K. Chattopadyay, Maria Dominguez,\n  Laurie Lamoreaux, Steven S. Ma, Mario Roederer and Raphael Gottardo", "title": "Data Exploration, Quality Control and Testing in Single-Cell qPCR-Based\n  Gene Expression Experiments", "comments": "9 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cell populations are never truly homogeneous; individual cells exist in\nbiochemical states that define functional differences between them. New\ntechnology based on microfluidic arrays combined with multiplexed quantitative\npolymerase chain reactions (qPCR) now enables high-throughput single-cell gene\nexpression measurement, allowing assessment of cellular heterogeneity. However\nvery little analytic tools have been developed specifically for the statistical\nand analytical challenges of single-cell qPCR data. We present a statistical\nframework for the exploration, quality control, and analysis of single-cell\ngene expression data from microfluidic arrays. We assess accuracy and\nwithin-sample heterogeneity of single-cell expression and develop quality\ncontrol criteria to filter unreliable cell measurements. We propose a\nstatistical model accounting for the fact that genes at the single-cell level\ncan be on (and for which a continuous expression measure is recorded) or\ndichotomously off (and the recorded expression is zero). Based on this model,\nwe derive a combined likelihood-ratio test for differential expression that\nincorporates both the discrete and continuous components. Using an experiment\nthat examines treatment-specific changes in expression, we show that this\ncombined test is more powerful than either the continuous or dichotomous\ncomponent in isolation, or a t-test on the zero-inflated data. While developed\nfor measurements from a specific platform (Fluidigm), these tools are\ngeneralizable to other multi-parametric measures over large numbers of events.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2012 20:21:59 GMT"}], "update_date": "2012-10-05", "authors_parsed": [["McDavid", "Andrew", ""], ["Finak", "Greg", ""], ["Chattopadyay", "Pratip K.", ""], ["Dominguez", "Maria", ""], ["Lamoreaux", "Laurie", ""], ["Ma", "Steven S.", ""], ["Roederer", "Mario", ""], ["Gottardo", "Raphael", ""]]}, {"id": "1210.1288", "submitter": "Murphy Choy", "authors": "Murphy Choy, Cally Claire Ong, Michelle Cheong", "title": "Modified Entropy Measure for Detection of Association Rules Under\n  Simpson's Paradox Context", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapid explosion in retail data calls for more effective and efficient\ndiscovery of association rules to develop relevant business strategies and\nrules.Unlike online shopping sites, most brick and mortar retail shops are\nlocated in geographically and demographically diverse areas. This diversity\npresents a new challenge to the classical association rule model which assumes\na homogenous group of customers behaving differently. The focus of this paper\nis centered on the discovery of association rules that were hidden as a result\nof a geographical and demographically diverse data. We will introduce a novel\nmeasure which incorporates the entropy measure with modified weighting for the\ndetection of association rules not detected by the standard measures due to\nSimpson's paradox. The proposed measure is evaluated using a real-word case\nstudy involving a major retailer of fashion good in the context of traditional\nbrick and mortar setting.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2012 03:37:17 GMT"}], "update_date": "2012-10-05", "authors_parsed": [["Choy", "Murphy", ""], ["Ong", "Cally Claire", ""], ["Cheong", "Michelle", ""]]}, {"id": "1210.1418", "submitter": "Mattia Galiazzo", "authors": "Mattia Alvise Galiazzo, \\'Akos Bazs\\'o and Rudolf Dvorak", "title": "Fugitives from the Hungaria region: close encounters and impacts with\n  terrestrial planets", "comments": "To be published in Planetary and SPace Science", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.EP stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hungaria asteroids, whose orbits occupy the region in element space between\n$1.78< a< 2.03$ AU, $e<0.19$, $12^\\circ<i<31^\\circ$, are a possible source of\nNear-Earth Asteroids (NEAs). Named after (434) Hungaria these asteroids are\nrelatively small, since the largest member of the group has a diameter of just\nabout 11 km. They are mainly perturbed by Jupiter and Mars, possibly becoming\nMars-crossers and, later, they may even cross the orbits of Earth and Venus. In\nthis paper we analyze the close encounters and possible impacts of escaped\nHungarias with the terrestrial planets. Out of about 8000 known Hungarias we\nselected 200 objects which are on the edge of the group. We integrated their\norbits over 100 million years in a simplified model of the planetary system\n(Mars to Saturn) subject only to gravitational forces. We picked out a sample\nof 11 objects (each with 50 clones) with large variations in semi-major axis\nand restarted the numerical integration in a gravitational model including the\nplanets from Venus to Saturn. Due to close encounters, some of them achieve\nhigh inclinations and eccentricities which, in turn, lead to relatively high\nvelocity impacts on Venus, Earth, and Mars. We statistically analyze all close\nencounters and impacts with the terrestrial planets and determine the encounter\nand impact velocities of these fictitious Hungarias.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2012 12:40:18 GMT"}, {"version": "v2", "created": "Tue, 9 Apr 2013 23:06:10 GMT"}], "update_date": "2013-04-11", "authors_parsed": [["Galiazzo", "Mattia Alvise", ""], ["Bazs\u00f3", "\u00c1kos", ""], ["Dvorak", "Rudolf", ""]]}, {"id": "1210.1547", "submitter": "Van Hanh Nguyen", "authors": "Van Hanh Nguyen (SG, LM-Orsay), Catherine Matias (SG)", "title": "Nonparametric estimation of the density of the alternative hypothesis in\n  a multiple testing setup. Application to local false discovery rate\n  estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a multiple testing context, we consider a semiparametric mixture model\nwith two components where one component is known and corresponds to the\ndistribution of $p$-values under the null hypothesis and the other component\n$f$ is nonparametric and stands for the distribution under the alternative\nhypothesis. Motivated by the issue of local false discovery rate estimation, we\nfocus here on the estimation of the nonparametric unknown component $f$ in the\nmixture, relying on a preliminary estimator of the unknown proportion $\\theta$\nof true null hypotheses. We propose and study the asymptotic properties of two\ndifferent estimators for this unknown component. The first estimator is a\nrandomly weighted kernel estimator. We establish an upper bound for its\npointwise quadratic risk, exhibiting the classical nonparametric rate of\nconvergence over a class of H\\\"older densities. To our knowledge, this is the\nfirst result establishing convergence as well as corresponding rate for the\nestimation of the unknown component in this nonparametric mixture. The second\nestimator is a maximum smoothed likelihood estimator. It is computed through an\niterative algorithm, for which we establish a descent property. In addition,\nthese estimators are used in a multiple testing procedure in order to estimate\nthe local false discovery rate. Their respective performances are then compared\non synthetic data.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2012 19:14:35 GMT"}, {"version": "v2", "created": "Wed, 3 Apr 2013 07:57:02 GMT"}], "update_date": "2013-04-04", "authors_parsed": [["Nguyen", "Van Hanh", "", "SG, LM-Orsay"], ["Matias", "Catherine", "", "SG"]]}, {"id": "1210.1814", "submitter": "William Kleiber", "authors": "William Kleiber, Richard W. Katz, Balaji Rajagopalan", "title": "Daily minimum and maximum temperature simulation over complex terrain", "comments": "Published in at http://dx.doi.org/10.1214/12-AOAS602 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2013, Vol. 7, No. 1, 588-612", "doi": "10.1214/12-AOAS602", "report-no": "IMS-AOAS-AOAS602", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spatiotemporal simulation of minimum and maximum temperature is a fundamental\nrequirement for climate impact studies and hydrological or agricultural models.\nParticularly over regions with variable orography, these simulations are\ndifficult to produce due to terrain driven nonstationarity. We develop a\nbivariate stochastic model for the spatiotemporal field of minimum and maximum\ntemperature. The proposed framework splits the bivariate field into two\ncomponents of \"local climate\" and \"weather.\" The local climate component is a\nlinear model with spatially varying process coefficients capturing the annual\ncycle and yielding local climate estimates at all locations, not only those\nwithin the observation network. The weather component spatially correlates the\nbivariate simulations, whose matrix-valued covariance function we estimate\nusing a nonparametric kernel smoother that retains nonnegative definiteness and\nallows for substantial nonstationarity across the simulation domain. The\nstatistical model is augmented with a spatially varying nugget effect to allow\nfor locally varying small scale variability. Our model is applied to a daily\ntemperature data set covering the complex terrain of Colorado, USA, and\nsuccessfully accommodates substantial temporally varying nonstationarity in\nboth the direct-covariance and cross-covariance functions.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2012 17:12:40 GMT"}, {"version": "v2", "created": "Fri, 31 May 2013 06:05:04 GMT"}], "update_date": "2013-06-03", "authors_parsed": [["Kleiber", "William", ""], ["Katz", "Richard W.", ""], ["Rajagopalan", "Balaji", ""]]}, {"id": "1210.1840", "submitter": "Paul Slater", "authors": "Paul B. Slater", "title": "A Further (Itakura-Saito/beta=0) Bi-stochaticization and Associated\n  Clustering/Regionalization of the 3,107-County 1995-2000 U. S. Migration\n  Network", "comments": "39 pages, one 34-page dendrogram. Through further iterations of our\n  heuristic, greedy algorithm, we are able to reduce the (Burg-entropy-based)\n  objective function from the previously-reported 1.60316 x 10^{11} to 1.59538\n  x 10^{11}. Some significant clustering changes (in the ordering of\n  cosmopolitan counties) are noted", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.SI stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend to the beta-divergence (Itakura-Saito) case beta =0, the\ncomparative bi-stochaticization analyses-previously conducted (arXiv:1208.3428)\nfor the (Kullback-Leibler) beta=1 and (squared-Euclidean) beta = 2 cases -of\nthe 3,107 - county 1995-2000 U. S. migration network. A heuristic, \"greedy\"\nalgorithm is devised. While the largest 25,329 entries of the 735,531 non-zero\nentries of the bi-stochasticized table - in the beta=1 case - are required to\ncomplete the widely-applied two-stage (double-standardization and\nstrong-component hierarchical clustering) procedure, 105,363 of the 735,531 are\nneeded (reflective of greater uniformity of entries) in the beta=0 instance.\nThe North Carolina counties of Mecklenburg (Charlotte) and Wake (Raleigh) are\nconsiderably relatively more cosmopolitan in the beta=0 study. The Colorado\ncounty of El Paso (Colorado Springs) replaces the Florida Atlantic county of\nBrevard (the \"Space Coast\") as the most cosmopolitan, with Brevard becoming the\nsecond-most. Honolulu County splinters away from the other four (still-grouped)\nHawaiian counties, becoming the fifth most cosmopolitan county nation-wide. The\nfive counties of Rhode Island remain intact as a regional entity, but the eight\ncounties of Connecticut fragment, leaving only five counties clustered.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2012 19:27:30 GMT"}, {"version": "v2", "created": "Thu, 25 Oct 2012 16:48:59 GMT"}], "update_date": "2012-10-26", "authors_parsed": [["Slater", "Paul B.", ""]]}, {"id": "1210.1844", "submitter": "Francisco-Jose Perez-Reche", "authors": "Francisco J. Perez-Reche, Franco M. Neri, Sergei N. Taraskin and\n  Christopher A. Gilligan", "title": "Prediction of invasion from the early stage of an epidemic", "comments": "Main text: 18 pages, 7 figures. Supporting information: 21 pages, 8\n  figures", "journal-ref": "Journal of the Royal Society Interface, 9, 2085 (2012)", "doi": "10.1098/rsif.2012.0130", "report-no": null, "categories": "q-bio.PE stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predictability of undesired events is a question of great interest in many\nscientific disciplines including seismology, economy, and epidemiology. Here,\nwe focus on the predictability of invasion of a broad class of epidemics caused\nby diseases that lead to permanent immunity of infected hosts after recovery or\ndeath. We approach the problem from the perspective of the science of\ncomplexity by proposing and testing several strategies for the estimation of\nimportant characteristics of epidemics, such as the probability of invasion.\nOur results suggest that parsimonious approximate methodologies may lead to the\nmost reliable and robust predictions. The proposed methodologies are first\napplied to analysis of experimentally observed epidemics: invasion of the\nfungal plant pathogen \\emph{Rhizoctonia solani} in replicated host microcosms.\nWe then consider numerical experiments of the SIR\n(susceptible-infected-removed) model to investigate the performance of the\nproposed methods in further detail. The suggested framework can be used as a\nvaluable tool for quick assessment of epidemic threat at the stage when\nepidemics only start developing. Moreover, our work amplifies the significance\nof the small-scale and finite-time microcosm realizations of epidemics\nrevealing their predictive power.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2012 19:52:42 GMT"}], "update_date": "2012-10-08", "authors_parsed": [["Perez-Reche", "Francisco J.", ""], ["Neri", "Franco M.", ""], ["Taraskin", "Sergei N.", ""], ["Gilligan", "Christopher A.", ""]]}, {"id": "1210.2022", "submitter": "Bruno Scarpa", "authors": "Daniele Durante, Bruno Scarpa and David B. Dunson", "title": "Locally adaptive factor processes for multivariate time series", "comments": null, "journal-ref": "Journal of Machine Learning Research (2014), 15: 1493-1522.\n  http://jmlr.org/papers/v15/durante14a.html", "doi": null, "report-no": null, "categories": "stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In modeling multivariate time series, it is important to allow time-varying\nsmoothness in the mean and covariance process. In particular, there may be\ncertain time intervals exhibiting rapid changes and others in which changes are\nslow. If such time-varying smoothness is not accounted for, one can obtain\nmisleading inferences and predictions, with over-smoothing across erratic time\nintervals and under-smoothing across times exhibiting slow variation. This can\nlead to mis-calibration of predictive intervals, which can be substantially too\nnarrow or wide depending on the time. We propose a locally adaptive factor\nprocess for characterizing multivariate mean-covariance changes in continuous\ntime, allowing locally varying smoothness in both the mean and covariance\nmatrix. This process is constructed utilizing latent dictionary functions\nevolving in time through nested Gaussian processes and linearly related to the\nobserved data with a sparse mapping. Using a differential equation\nrepresentation, we bypass usual computational bottlenecks in obtaining MCMC and\nonline algorithms for approximate Bayesian inference. The performance is\nassessed in simulations and illustrated in a financial application.\n", "versions": [{"version": "v1", "created": "Sun, 7 Oct 2012 05:40:25 GMT"}, {"version": "v2", "created": "Fri, 21 Jun 2013 07:39:35 GMT"}], "update_date": "2014-06-02", "authors_parsed": [["Durante", "Daniele", ""], ["Scarpa", "Bruno", ""], ["Dunson", "David B.", ""]]}, {"id": "1210.2253", "submitter": "J. Martin van Zyl", "authors": "J. Martin van Zyl", "title": "Testing approximate normality of an estimator using the estimated MSE\n  and bias with an application to the shape parameter of the generalized Pareto\n  distribution", "comments": null, "journal-ref": "South African Statistical Journal, 2014, 48(2), pp. 279-289", "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Often it is not easy to choose between estimators, based on the estimated MSE\nand bias using simulation studies. Normality in small samples and a variance of\nthe estimator, which is correct and easy to calculate using a single sample,\ngive the added advantage that hypotheses concerning the parameter can be tested\nin new samples. A procedure to check normality is proposed where previously\npublished MSE and bias are used to perform a test for normality. A confidence\ninterval for the index of the S&P500 index is found by applying the results to\nestimators of the generalized Pareto distribution.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2012 12:05:36 GMT"}, {"version": "v2", "created": "Wed, 21 Nov 2012 10:38:41 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["van Zyl", "J. Martin", ""]]}, {"id": "1210.2294", "submitter": "Ccsd", "authors": "Guillaume Allain (MM), Fabrice Gamboa (IMT), Philippe Goudal (MM),\n  Jean-No\\\"el Kien (MM, IMT), Jean-Michel Loubes (IMT)", "title": "Modeling Weather Conditions Consequences on Road Trafficking Behaviors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a model to understand how adverse weather conditions modify\ntraffic flow dynamic. We first prove that the microscopic Free Flow Speed of\nthe vehicles is changed and then provide a rule to model this change. For this,\nwe consider a thresholded linear model, corresponding to an application of a\nMARS model to road trafficking. This model adapts itself locally to the whole\nroad network and provides accurate unbiased forecasted speed using live or\nshort term forecasted weather data information.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2012 14:25:16 GMT"}], "update_date": "2012-10-09", "authors_parsed": [["Allain", "Guillaume", "", "MM"], ["Gamboa", "Fabrice", "", "IMT"], ["Goudal", "Philippe", "", "MM"], ["Kien", "Jean-No\u00ebl", "", "MM, IMT"], ["Loubes", "Jean-Michel", "", "IMT"]]}, {"id": "1210.2474", "submitter": "Akshay Soni", "authors": "Akshay Soni and Jarvis Haupt", "title": "Level Set Estimation from Compressive Measurements using Box Constrained\n  Total Variation Regularization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating the level set of a signal from measurements is a task that arises\nin a variety of fields, including medical imaging, astronomy, and digital\nelevation mapping. Motivated by scenarios where accurate and complete\nmeasurements of the signal may not available, we examine here a simple\nprocedure for estimating the level set of a signal from highly incomplete\nmeasurements, which may additionally be corrupted by additive noise. The\nproposed procedure is based on box-constrained Total Variation (TV)\nregularization. We demonstrate the performance of our approach, relative to\nexisting state-of-the-art techniques for level set estimation from compressive\nmeasurements, via several simulation examples.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2012 02:57:12 GMT"}], "update_date": "2012-10-10", "authors_parsed": [["Soni", "Akshay", ""], ["Haupt", "Jarvis", ""]]}, {"id": "1210.2555", "submitter": "Maria Oliveira", "authors": "Mar\\'ia Oliveira, Rosa M. Crujeiras, Alberto Rodr\\'iguez-Casal", "title": "CircSiZer: an exploratory tool for circular data", "comments": "17 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smoothing methods and SiZer (SIgnificant ZERo crossing of the derivatives)\nare useful tools for exploring significant underlying structures in data\nsamples. An extension of SiZer to circular data, namely CircSiZer, is\nintroduced. Based on scale-space ideas, CircSiZer presents a graphical device\nto assess which observed features are statistically significant, both for\ndensity and regression analysis with circular data. The method is intended for\nanalyzing the behavior of wind direction in the atlantic coast of Galicia (NW\nSpain) and how it has an influence over wind speed. The performance of\nCircSiZer is also checked with some simulated examples.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2012 10:48:24 GMT"}, {"version": "v2", "created": "Tue, 26 Feb 2013 16:33:12 GMT"}], "update_date": "2013-02-27", "authors_parsed": [["Oliveira", "Mar\u00eda", ""], ["Crujeiras", "Rosa M.", ""], ["Rodr\u00edguez-Casal", "Alberto", ""]]}, {"id": "1210.3252", "submitter": "Mohammad Esmalifalak", "authors": "Mohammad Esmalifalak, Ge Shi, Zhu Han, and Lingyang Song", "title": "Bad Data Injection Attack and Defense in Electricity Market using Game\n  Theory Study", "comments": "To appear in IEEE Transactions on Smart Grid, Special Issue on Cyber,\n  Physical, and System Security for Smart Grid", "journal-ref": null, "doi": "10.1109/TSG.2012.2224391", "report-no": null, "categories": "cs.CR cs.GT stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Applications of cyber technologies improve the quality of monitoring and\ndecision making in smart grid. These cyber technologies are vulnerable to\nmalicious attacks, and compromising them can have serious technical and\neconomical problems. This paper specifies the effect of compromising each\nmeasurement on the price of electricity, so that the attacker is able to change\nthe prices in the desired direction (increasing or decreasing). Attacking and\ndefending all measurements are impossible for the attacker and defender,\nrespectively. This situation is modeled as a zero sum game between the attacker\nand defender. The game defines the proportion of times that the attacker and\ndefender like to attack and defend different measurements, respectively. From\nthe simulation results based on the PJM 5 Bus test system, we can show the\neffectiveness and properties of the studied game.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2012 18:27:09 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Esmalifalak", "Mohammad", ""], ["Shi", "Ge", ""], ["Han", "Zhu", ""], ["Song", "Lingyang", ""]]}, {"id": "1210.3313", "submitter": "John Storey", "authors": "Troels T. Marstrand, John D. Storey", "title": "Identifying and Mapping Cell-type Specific Chromatin Programming of Gene\n  Expression", "comments": "First version completed December 2010. Last modified August 2011. We\n  remain in the submission and publication process, so the content of this\n  manuscript may change in the future. With the recent publication of 30 ENCODE\n  papers, we would like to share our related work with the research community.\n  The Supplementary Information may be found among the source files,\n  specifically in arxiv_SI.pdf", "journal-ref": "Proceedings of the National Academy of Sciences (2014), 111(6),\n  E645-E654", "doi": "10.1073/pnas.1312523111", "report-no": null, "categories": "q-bio.QM q-bio.GN stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A problem of substantial interest is to systematically map variation in\nchromatin structure to gene expression regulation across conditions,\nenvironments, or differentiated cell types. We developed and applied a\nquantitative framework for determining the existence, strength, and type of\nrelationship between high-resolution chromatin structure in terms of DNaseI\nhypersensitivity (DHS) and genome-wide gene expression levels in 20 diverse\nhuman cell lines. We show that ~25% of genes show cell-type specific expression\nexplained by alterations in chromatin structure. We find that distal regions of\nchromatin structure (e.g., +/- 200kb) capture more genes with this relationship\nthan local regions (e.g., +/- 2.5kb), yet the local regions show a more\npronounced effect. By exploiting variation across cell-types, we were capable\nof pinpointing the most likely hypersensitive sites related to cell-type\nspecific expression, which we show have a range of contextual usages. This\nquantitative framework is likely applicable to other settings aimed at relating\ncontinuous genomic measurements to gene expression variation.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2012 18:25:26 GMT"}], "update_date": "2015-03-05", "authors_parsed": [["Marstrand", "Troels T.", ""], ["Storey", "John D.", ""]]}, {"id": "1210.3456", "submitter": "Mingjun Zhong", "authors": "Mingjun Zhong, Rong Liu, Bo Liu", "title": "Bayesian Analysis for miRNA and mRNA Interactions Using Expression Data", "comments": "21 pages, 11 figures, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG q-bio.GN q-bio.MN stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  MicroRNAs (miRNAs) are small RNA molecules composed of 19-22 nt, which play\nimportant regulatory roles in post-transcriptional gene regulation by\ninhibiting the translation of the mRNA into proteins or otherwise cleaving the\ntarget mRNA. Inferring miRNA targets provides useful information for\nunderstanding the roles of miRNA in biological processes that are potentially\ninvolved in complex diseases. Statistical methodologies for point estimation,\nsuch as the Least Absolute Shrinkage and Selection Operator (LASSO) algorithm,\nhave been proposed to identify the interactions of miRNA and mRNA based on\nsequence and expression data. In this paper, we propose using the Bayesian\nLASSO (BLASSO) and the non-negative Bayesian LASSO (nBLASSO) to analyse the\ninteractions between miRNA and mRNA using expression data. The proposed\nBayesian methods explore the posterior distributions for those parameters\nrequired to model the miRNA-mRNA interactions. These approaches can be used to\nobserve the inferred effects of the miRNAs on the targets by plotting the\nposterior distributions of those parameters. For comparison purposes, the Least\nSquares Regression (LSR), Ridge Regression (RR), LASSO, non-negative LASSO\n(nLASSO), and the proposed Bayesian approaches were applied to four public\ndatasets. We concluded that nLASSO and nBLASSO perform best in terms of\nsensitivity and specificity. Compared to the point estimate algorithms, which\nonly provide single estimates for those parameters, the Bayesian methods are\nmore meaningful and provide credible intervals, which take into account the\nuncertainty of the inferred interactions of the miRNA and mRNA. Furthermore,\nBayesian methods naturally provide statistical significance to select\nconvincing inferred interactions, while point estimate algorithms require a\nmanually chosen threshold, which is less meaningful, to choose the possible\ninteractions.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2012 09:03:14 GMT"}, {"version": "v2", "created": "Mon, 30 Jun 2014 10:16:51 GMT"}], "update_date": "2014-07-01", "authors_parsed": [["Zhong", "Mingjun", ""], ["Liu", "Rong", ""], ["Liu", "Bo", ""]]}, {"id": "1210.3477", "submitter": "Lutz Bornmann Dr.", "authors": "Lutz Bornmann, Loet Leydesdorff", "title": "Statistical Tests and Research Assessments: A comment on Schneider\n  (2012)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a recent presentation at the 17th International Conference on Science and\nTechnology Indicators, Schneider (2012) criticised the proposal of Bornmann, de\nMoya Anegon, and Leydesdorff (2012) and Leydesdorff and Bornmann (2012) to use\nstatistical tests in order to evaluate research assessments and university\nrankings. We agree with Schneider's proposal to add statistical power analysis\nand effect size measures to research evaluations, but disagree that these\nprocedures would replace significance testing. Accordingly, effect size\nmeasures were added to the Excel sheets that we bring online for testing\nperformance differences between institutions in the Leiden Ranking and the\nSCImago Institutions Ranking.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2012 11:25:00 GMT"}], "update_date": "2012-10-15", "authors_parsed": [["Bornmann", "Lutz", ""], ["Leydesdorff", "Loet", ""]]}, {"id": "1210.3555", "submitter": "Danielle Bassett", "authors": "Danielle S. Bassett, Nicholas F. Wymbs, M. Puck Rombach, Mason A.\n  Porter, Peter J. Mucha, Scott T. Grafton", "title": "Task-Based Core-Periphery Organisation of Human Brain Dynamics", "comments": "21 pages, 9 figures, and Supplementary Information", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn nlin.AO stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a person learns a new skill, distinct synapses, brain regions, and\ncircuits are engaged and change over time. In this paper, we develop methods to\nexamine patterns of correlated activity across a large set of brain regions.\nOur goal is to identify properties that enable robust learning of a motor\nskill. We measure brain activity during motor sequencing and characterize\nnetwork properties based on coherent activity between brain regions. Using\nrecently developed algorithms to detect time-evolving communities, we find that\nthe complex reconfiguration patterns of the brain's putative functional modules\nthat control learning can be described parsimoniously by the combined presence\nof a relatively stiff temporal core that is composed primarily of sensorimotor\nand visual regions whose connectivity changes little in time and a flexible\ntemporal periphery that is composed primarily of multimodal association regions\nwhose connectivity changes frequently. The separation between temporal core and\nperiphery changes over the course of training and, importantly, is a good\npredictor of individual differences in learning success. The core of\ndynamically stiff regions exhibits dense connectivity, which is consistent with\nnotions of core-periphery organization established previously in social\nnetworks. Our results demonstrate that core-periphery organization provides an\ninsightful way to understand how putative functional modules are linked. This,\nin turn, enables the prediction of fundamental human capacities, including the\nproduction of complex goal-directed behavior.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2012 15:50:47 GMT"}, {"version": "v2", "created": "Wed, 30 Oct 2013 15:30:56 GMT"}], "update_date": "2013-10-31", "authors_parsed": [["Bassett", "Danielle S.", ""], ["Wymbs", "Nicholas F.", ""], ["Rombach", "M. Puck", ""], ["Porter", "Mason A.", ""], ["Mucha", "Peter J.", ""], ["Grafton", "Scott T.", ""]]}, {"id": "1210.3718", "submitter": "Mariano Tepper", "authors": "Mariano Tepper, Pablo Mus\\'e, and Andr\\'es Almansa", "title": "On the Role of Contrast and Regularity in Perceptual Boundary Saliency", "comments": null, "journal-ref": null, "doi": "10.1007/s10851-012-0411-6", "report-no": null, "categories": "cs.CV stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mathematical Morphology proposes to extract shapes from images as connected\ncomponents of level sets. These methods prove very suitable for shape\nrecognition and analysis. We present a method to select the perceptually\nsignificant (i.e., contrasted) level lines (boundaries of level sets), using\nthe Helmholtz principle as first proposed by Desolneux et al. Contrarily to the\nclassical formulation by Desolneux et al. where level lines must be entirely\nsalient, the proposed method allows to detect partially salient level lines,\nthus resulting in more robust and more stable detections. We then tackle the\nproblem of combining two gestalts as a measure of saliency and propose a method\nthat reinforces detections. Results in natural images show the good performance\nof the proposed methods.\n", "versions": [{"version": "v1", "created": "Sat, 13 Oct 2012 16:27:52 GMT"}], "update_date": "2014-10-01", "authors_parsed": [["Tepper", "Mariano", ""], ["Mus\u00e9", "Pablo", ""], ["Almansa", "Andr\u00e9s", ""]]}, {"id": "1210.3744", "submitter": "Iolanda-Gabriela Craifaleanu", "authors": "Iolanda-Gabriela Craifaleanu", "title": "Evaluation des differents parametres utilises pour l'estimation du\n  contenu en frequences des mouvements du sol, avec application aux forts\n  tremblements de terre de Vrancea, Roumanie", "comments": "10 pages, Proceedings of the Colloquium of the French Association of\n  Earthquake Engineering, AFPS 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cond-mat.stat-mech physics.data-an physics.geo-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper presents results of a comprehensive study of ground motions\nrecorded during the strong earthquakes (moment magnitude Mw > 6) generated\nduring last 34 years by the seismic source of Vrancea, Romania. By analyzing\nover 300 accelerograms, the capacity of different expressions in the literature\nto estimate the predominant period of a ground motion is compared. The\ncorrelation between the values obtained from different evaluations is assessed\nas well. The dependence of the predominant period of different factors of\ninfluence is analysed. Comparisons are made between the parameters determined\nfor the same seismic event at different stations, as well as for ground motions\nrecorded on the same site at successive earthquakes. The results are\ninterpreted in correlation with the information provided by frequency bandwidth\nparameters. Considerations are made on the measure in which the influence on\nthe frequency content of the source and of local geological conditions can be\nseparated, for seismic motions recorded on different locations.\n", "versions": [{"version": "v1", "created": "Sat, 13 Oct 2012 22:31:53 GMT"}], "update_date": "2013-01-15", "authors_parsed": [["Craifaleanu", "Iolanda-Gabriela", ""]]}, {"id": "1210.3745", "submitter": "Iolanda-Gabriela Craifaleanu", "authors": "I.G. Craifaleanu, I.S. Borcia", "title": "Instrumental Intensity as a Tool for Post-Earthquake Damage Assessment:\n  Validation for the Strong Vrancea Earthquakes of August 1986 and May 1990", "comments": "8 pages;\n  http://constructii.incerc2004.ro/Archive/2011-1/art4-1-2011.pdf", "journal-ref": "Constructii, Vol. 11, No. 1/2011, pp. 25-32", "doi": null, "report-no": null, "categories": "stat.AP cond-mat.stat-mech physics.geo-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The frequency-dependent spectrum based seismic intensity, also called\ninstrumental intensity, is calculated basically from the integration of the\nsquare values of spectral acceleration ordinates. The values of the\ninstrumental intensity are calibrated to match the values of the EMS-98\nintensity scale, providing a promising analytical indicator for estimating the\ndestructive potential of earthquakes. Previous studies have shown that the\nproposed index could be used as a basis for the development of a new improved\nseismic intensity scale. The paper presents a set of maps describing the\nspatial distribution of instrumental intensity ordinates for three seismic\nevents recorded in 1986 and 1990. These events, generated by the Vrancea\nsource, are the strongest earthquakes in Romania for which accelerographic data\nwas recorded at multiple stations. Intensity maps were generated for separate\nsignificant frequency bands, in order to reveal the destructiveness of the\nconsidered earthquakes for different building categories. Results were compared\nand correlated with previous studies on Vrancea earthquakes and with\ninformation provided by building damage reports from the considered\nearthquakes.\n", "versions": [{"version": "v1", "created": "Sat, 13 Oct 2012 22:39:28 GMT"}], "update_date": "2013-01-15", "authors_parsed": [["Craifaleanu", "I. G.", ""], ["Borcia", "I. S.", ""]]}, {"id": "1210.3749", "submitter": "Koichi Yamagata", "authors": "Koichi Yamagata, Akio Fujiwara, Richard D. Gill", "title": "Quantum local asymptotic normality based on a new quantum likelihood\n  ratio", "comments": "Published in at http://dx.doi.org/10.1214/13-AOS1147 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2013, Vol. 41, No. 4, 2197-2217", "doi": "10.1214/13-AOS1147", "report-no": "IMS-AOS-AOS1147", "categories": "quant-ph math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a theory of local asymptotic normality in the quantum domain based\non a novel quantum analogue of the log-likelihood ratio. This formulation is\napplicable to any quantum statistical model satisfying a mild smoothness\ncondition. As an application, we prove the asymptotic achievability of the\nHolevo bound for the local shift parameter.\n", "versions": [{"version": "v1", "created": "Sun, 14 Oct 2012 00:31:48 GMT"}, {"version": "v2", "created": "Thu, 29 Aug 2013 10:56:10 GMT"}, {"version": "v3", "created": "Fri, 8 Nov 2013 13:32:02 GMT"}], "update_date": "2013-11-11", "authors_parsed": [["Yamagata", "Koichi", ""], ["Fujiwara", "Akio", ""], ["Gill", "Richard D.", ""]]}, {"id": "1210.3771", "submitter": "J\\\"uri Lember", "authors": "Erik Hirmo and J\\\"uri Lember and Heinrich Matzinger", "title": "Detecting the homology of DNA-sequences based on the variety of optimal\n  alignments: a case study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a novel approach of measuring the homology of DNA sequences based\nof the variety of optimal alignments in the longest common subsequence sense.\nThe proposed approach is compared with BLAST in measuring the homology of four\ngenes.\n", "versions": [{"version": "v1", "created": "Sun, 14 Oct 2012 09:41:08 GMT"}], "update_date": "2012-10-16", "authors_parsed": [["Hirmo", "Erik", ""], ["Lember", "J\u00fcri", ""], ["Matzinger", "Heinrich", ""]]}, {"id": "1210.3849", "submitter": "Gareth Peters Dr", "authors": "Gareth W. Peters, Alice X. D. Dong, Robert Kohn", "title": "A Copula Based Bayesian Approach for Paid-Incurred Claims Models for\n  Non-Life Insurance Reserving", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM stat.AP stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our article considers the class of recently developed stochastic models that\ncombine claims payments and incurred losses information into a coherent\nreserving methodology. In particular, we develop a family of Heirarchical\nBayesian Paid-Incurred-Claims models, combining the claims reserving models of\nHertig et al. (1985) and Gogol et al. (1993). In the process we extend the\nindependent log-normal model of Merz et al. (2010) by incorporating different\ndependence structures using a Data-Augmented mixture Copula Paid-Incurred\nclaims model.\n  The utility and influence of incorporating both payment and incurred losses\ninto estimating of the full predictive distribution of the outstanding loss\nliabilities and the resulting reserves is demonstrated in the following cases:\n(i) an independent payment (P) data model; (ii) the independent\nPayment-Incurred Claims (PIC) data model of Merz et al. (2010); (iii) a novel\ndependent lag-year telescoping block diagonal Gaussian Copula PIC data model\nincorporating conjugacy via transformation; (iv) a novel data-augmented mixture\nArchimedean copula dependent PIC data model.\n  Inference in such models is developed via a class of adaptive Markov chain\nMonte Carlo sampling algorithms. These incorporate a data-augmentation\nframework utilized to efficiently evaluate the likelihood for the copula based\nPIC model in the loss reserving triangles. The adaptation strategy is based on\nrepresenting a positive definite covariance matrix by the exponential of a\nsymmetric matrix as proposed by Leonard et al. (1992).\n", "versions": [{"version": "v1", "created": "Sun, 14 Oct 2012 22:12:41 GMT"}, {"version": "v2", "created": "Wed, 31 Oct 2012 20:36:38 GMT"}, {"version": "v3", "created": "Mon, 5 Nov 2012 23:02:22 GMT"}, {"version": "v4", "created": "Sun, 9 Dec 2012 16:36:55 GMT"}], "update_date": "2012-12-11", "authors_parsed": [["Peters", "Gareth W.", ""], ["Dong", "Alice X. D.", ""], ["Kohn", "Robert", ""]]}, {"id": "1210.3889", "submitter": "Qiang Luo Dr", "authors": "Qiang Luo, Wenlian Lu, Wei Cheng, Pedro A. Valdes-Sosa, Xiaotong Wen,\n  Mingzhou Ding and Jianfeng Feng", "title": "Spatio-temporal Granger causality: a new framework", "comments": "62 pages, 10 figures", "journal-ref": "Neuroimage, 2013", "doi": "10.1016/j.neuroimage.2013.04.091", "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  That physiological oscillations of various frequencies are present in fMRI\nsignals is the rule, not the exception. Herein, we propose a novel theoretical\nframework, spatio-temporal Granger causality, which allows us to more reliably\nand precisely estimate the Granger causality from experimental datasets\npossessing time-varying properties caused by physiological oscillations. Within\nthis framework, Granger causality is redefined as a global index measuring the\ndirected information flow between two time series with time-varying properties.\nBoth theoretical analyses and numerical examples demonstrate that Granger\ncausality is a monotonically increasing function of the temporal resolution\nused in the estimation. This is consistent with the general principle of coarse\ngraining, which causes information loss by smoothing out very fine-scale\ndetails in time and space. Our results confirm that the Granger causality at\nthe finer spatio-temporal scales considerably outperforms the traditional\napproach in terms of an improved consistency between two resting-state scans of\nthe same subject. To optimally estimate the Granger causality, the proposed\ntheoretical framework is implemented through a combination of several\napproaches, such as dividing the optimal time window and estimating the\nparameters at the fine temporal and spatial scales. Taken together, our\napproach provides a novel and robust framework for estimating the Granger\ncausality from fMRI, EEG, and other related data.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2012 03:42:15 GMT"}, {"version": "v2", "created": "Wed, 17 Oct 2012 00:21:43 GMT"}, {"version": "v3", "created": "Thu, 14 Mar 2013 19:05:56 GMT"}, {"version": "v4", "created": "Wed, 17 Apr 2013 16:41:42 GMT"}], "update_date": "2018-03-15", "authors_parsed": [["Luo", "Qiang", ""], ["Lu", "Wenlian", ""], ["Cheng", "Wei", ""], ["Valdes-Sosa", "Pedro A.", ""], ["Wen", "Xiaotong", ""], ["Ding", "Mingzhou", ""], ["Feng", "Jianfeng", ""]]}, {"id": "1210.4139", "submitter": "Emmanuel Candes", "authors": "Emmanuel J. Candes, Carlos A. Sing-Long and Joshua D. Trzasko", "title": "Unbiased Risk Estimates for Singular Value Thresholding and Spectral\n  Estimators", "comments": "29 pages, 8 figures", "journal-ref": null, "doi": "10.1109/TSP.2013.2270464", "report-no": null, "categories": "math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In an increasing number of applications, it is of interest to recover an\napproximately low-rank data matrix from noisy observations. This paper develops\nan unbiased risk estimate---holding in a Gaussian model---for any spectral\nestimator obeying some mild regularity assumptions. In particular, we give an\nunbiased risk estimate formula for singular value thresholding (SVT), a popular\nestimation strategy which applies a soft-thresholding rule to the singular\nvalues of the noisy observations. Among other things, our formulas offer a\nprincipled and automated way of selecting regularization parameters in a\nvariety of problems. In particular, we demonstrate the utility of the unbiased\nrisk estimation for SVT-based denoising of real clinical cardiac MRI series\ndata. We also give new results concerning the differentiability of certain\nmatrix-valued functions.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2012 19:06:43 GMT"}], "update_date": "2015-06-11", "authors_parsed": [["Candes", "Emmanuel J.", ""], ["Sing-Long", "Carlos A.", ""], ["Trzasko", "Joshua D.", ""]]}, {"id": "1210.4844", "submitter": "Cedric Archambeau", "authors": "Cedric Archambeau, Francois Caron", "title": "Plackett-Luce regression: A new Bayesian model for polychotomous data", "comments": "Appears in Proceedings of the Twenty-Eighth Conference on Uncertainty\n  in Artificial Intelligence (UAI2012)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2012-PG-84-92", "categories": "stat.ME stat.AP stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multinomial logistic regression is one of the most popular models for\nmodelling the effect of explanatory variables on a subject choice between a set\nof specified options. This model has found numerous applications in machine\nlearning, psychology or economy. Bayesian inference in this model is non\ntrivial and requires, either to resort to a MetropolisHastings algorithm, or\nrejection sampling within a Gibbs sampler. In this paper, we propose an\nalternative model to multinomial logistic regression. The model builds on the\nPlackett-Luce model, a popular model for multiple comparisons. We show that the\nintroduction of a suitable set of auxiliary variables leads to an\nExpectation-Maximization algorithm to find Maximum A Posteriori estimates of\nthe parameters. We further provide a full Bayesian treatment by deriving a\nGibbs sampler, which only requires to sample from highly standard\ndistributions. We also propose a variational approximate inference scheme. All\nare very simple to implement. One property of our Plackett-Luce regression\nmodel is that it learns a sparse set of feature weights. We compare our method\nto sparse Bayesian multinomial logistic regression and show that it is\ncompetitive, especially in presence of polychotomous data.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2012 17:34:18 GMT"}], "update_date": "2012-10-19", "authors_parsed": [["Archambeau", "Cedric", ""], ["Caron", "Francois", ""]]}, {"id": "1210.4864", "submitter": "Wen Dong", "authors": "Wen Dong, Alex Pentland, Katherine A. Heller", "title": "Graph-Coupled HMMs for Modeling the Spread of Infection", "comments": "Appears in Proceedings of the Twenty-Eighth Conference on Uncertainty\n  in Artificial Intelligence (UAI2012)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2012-PG-227-236", "categories": "cs.SI physics.soc-ph stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop Graph-Coupled Hidden Markov Models (GCHMMs) for modeling the\nspread of infectious disease locally within a social network. Unlike most\nprevious research in epidemiology, which typically models the spread of\ninfection at the level of entire populations, we successfully leverage mobile\nphone data collected from 84 people over an extended period of time to model\nthe spread of infection on an individual level. Our model, the GCHMM, is an\nextension of widely-used Coupled Hidden Markov Models (CHMMs), which allow\ndependencies between state transitions across multiple Hidden Markov Models\n(HMMs), to situations in which those dependencies are captured through the\nstructure of a graph, or to social networks that may change over time. The\nbenefit of making infection predictions on an individual level is enormous, as\nit allows people to receive more personalized and relevant health advice.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2012 17:39:07 GMT"}], "update_date": "2012-10-19", "authors_parsed": [["Dong", "Wen", ""], ["Pentland", "Alex", ""], ["Heller", "Katherine A.", ""]]}, {"id": "1210.4868", "submitter": "Jie Liu", "authors": "Jie Liu, Chunming Zhang, Catherine McCarty, Peggy Peissig, Elizabeth\n  Burnside, David Page", "title": "Graphical-model Based Multiple Testing under Dependence, with\n  Applications to Genome-wide Association Studies", "comments": "Appears in Proceedings of the Twenty-Eighth Conference on Uncertainty\n  in Artificial Intelligence (UAI2012)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2012-PG-511-522", "categories": "stat.ME cs.CE stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale multiple testing tasks often exhibit dependence, and leveraging\nthe dependence between individual tests is still one challenging and important\nproblem in statistics. With recent advances in graphical models, it is feasible\nto use them to perform multiple testing under dependence. We propose a multiple\ntesting procedure which is based on a Markov-random-field-coupled mixture\nmodel. The ground truth of hypotheses is represented by a latent binary Markov\nrandom field, and the observed test statistics appear as the coupled mixture\nvariables. The parameters in our model can be automatically learned by a novel\nEM algorithm. We use an MCMC algorithm to infer the posterior probability that\neach hypothesis is null (termed local index of significance), and the false\ndiscovery rate can be controlled accordingly. Simulations show that the\nnumerical performance of multiple testing can be improved substantially by\nusing our procedure. We apply the procedure to a real-world genome-wide\nassociation study on breast cancer, and we identify several SNPs with strong\nassociation evidence.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2012 17:40:38 GMT"}], "update_date": "2012-10-19", "authors_parsed": [["Liu", "Jie", ""], ["Zhang", "Chunming", ""], ["McCarty", "Catherine", ""], ["Peissig", "Peggy", ""], ["Burnside", "Elizabeth", ""], ["Page", "David", ""]]}, {"id": "1210.4908", "submitter": "Julia A. Palacios", "authors": "Julia A. Palacios, Vladimir N. Minin", "title": "Integrated Nested Laplace Approximation for Bayesian Nonparametric\n  Phylodynamics", "comments": "Appears in Proceedings of the Twenty-Eighth Conference on Uncertainty\n  in Artificial Intelligence (UAI2012)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2012-PG-726-735", "categories": "stat.AP q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of phylodynamics, an area on the intersection of phylogenetics and\npopulation genetics, is to reconstruct population size dynamics from genetic\ndata. Recently, a series of nonparametric Bayesian methods have been proposed\nfor such demographic reconstructions. These methods rely on prior\nspecifications based on Gaussian processes and proceed by approximating the\nposterior distribution of population size trajectories via Markov chain Monte\nCarlo (MCMC) methods. In this paper, we adapt an integrated nested Laplace\napproximation (INLA), a recently proposed approximate Bayesian inference for\nlatent Gaussian models, to the estimation of population size trajectories. We\nshow that when a genealogy of sampled individuals can be reliably estimated\nfrom genetic data, INLA enjoys high accuracy and can replace MCMC entirely. We\ndemonstrate significant computational efficiency over the state-of-the-art MCMC\nmethods. We illustrate INLA-based population size inference using simulations\nand genealogies of hepatitis C and human influenza viruses.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2012 17:52:51 GMT"}], "update_date": "2012-10-19", "authors_parsed": [["Palacios", "Julia A.", ""], ["Minin", "Vladimir N.", ""]]}, {"id": "1210.5029", "submitter": "Audrey Qiuyan Fu", "authors": "Audrey Qiuyan Fu, Steven Russell, Sarah J. Bray, Simon Tavar\\'e", "title": "Bayesian clustering of replicated time-course gene expression data with\n  weak signals", "comments": "Published in at http://dx.doi.org/10.1214/13-AOAS650 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2013, Vol. 7, No. 3, 1334-1361", "doi": "10.1214/13-AOAS650", "report-no": "IMS-AOAS-AOAS650", "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To identify novel dynamic patterns of gene expression, we develop a\nstatistical method to cluster noisy measurements of gene expression collected\nfrom multiple replicates at multiple time points, with an unknown number of\nclusters. We propose a random-effects mixture model coupled with a\nDirichlet-process prior for clustering. The mixture model formulation allows\nfor probabilistic cluster assignments. The random-effects formulation allows\nfor attributing the total variability in the data to the sources that are\nconsistent with the experimental design, particularly when the noise level is\nhigh and the temporal dependence is not strong. The Dirichlet-process prior\ninduces a prior distribution on partitions and helps to estimate the number of\nclusters (or mixture components) from the data. We further tackle two\nchallenges associated with Dirichlet-process prior-based methods. One is\nefficient sampling. We develop a novel Metropolis-Hastings Markov Chain Monte\nCarlo (MCMC) procedure to sample the partitions. The other is efficient use of\nthe MCMC samples in forming clusters. We propose a two-step procedure for\nposterior inference, which involves resampling and relabeling, to estimate the\nposterior allocation probability matrix. This matrix can be directly used in\ncluster assignments, while describing the uncertainty in clustering. We\ndemonstrate the effectiveness of our model and sampling procedure through\nsimulated data. Applying our method to a real data set collected from\nDrosophila adult muscle cells after five-minute Notch activation, we identify\n14 clusters of different transcriptional responses among 163 differentially\nexpressed genes, which provides novel insights into underlying transcriptional\nmechanisms in the Notch signaling pathway. The algorithm developed here is\nimplemented in the R package DIRECT, available on CRAN.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2012 05:53:52 GMT"}, {"version": "v2", "created": "Wed, 27 Mar 2013 00:12:51 GMT"}, {"version": "v3", "created": "Thu, 28 Nov 2013 08:43:52 GMT"}], "update_date": "2013-12-02", "authors_parsed": [["Fu", "Audrey Qiuyan", ""], ["Russell", "Steven", ""], ["Bray", "Sarah J.", ""], ["Tavar\u00e9", "Simon", ""]]}, {"id": "1210.5095", "submitter": "Tomas Iesmantas", "authors": "Robertas Alzbutas, Tomas Ie\\v{s}mantas", "title": "Application of Bayesian Methods for Age-dependent Reliability Analysis", "comments": "Accepted draft for publication in Quality and Reliability Engineering\n  International", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper authors present a general methodology for age dependent\nreliability analysis of degrading or ageing systems, structures and\ncomponents.The methodology is based on Bayesian methods and inference, its\nability to incorporate prior information and on idea that ageing can be thought\nas age dependent change of believes about reliability parameters, when change\nof belief occurs not just due to new failure data or other information which\nbecomes available in time, but also it continuously changes due to flow of time\nand beliefs evolution. The main objective of this paper is to present the clear\nway of how Bayesian methods can be applied by practitioners to deal with risk\nand reliability analysis considering ageing phenomena. The methodology\ndescribes step by step failure rate analysis of ageing systems: from the\nBayesian model building to its verification and generalization with Bayesian\nmodel averaging which, as authors suggest in this paper, could serve as\nalternative for various goodness of fit assessment tools and as universal tool\nto cope with various sources of uncertainty.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2012 11:20:05 GMT"}], "update_date": "2012-10-19", "authors_parsed": [["Alzbutas", "Robertas", ""], ["Ie\u0161mantas", "Tomas", ""]]}, {"id": "1210.5111", "submitter": "Berdjane Belkacem", "authors": "Belkacem Berdjane (LMRS), Sergei Pergamenshchikov (LMRS)", "title": "Sequential $\\delta$-optimal consumption and investment for stochastic\n  volatility markets with unknown parameters", "comments": "pages:38. arXiv admin note: text overlap with arXiv:1102.1186", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PM stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider an optimal investment and consumption problem for a Black-Scholes\nfinancial market with stochastic volatility and unknown stock appreciation\nrate. The volatility parameter is driven by an external economic factor modeled\nas a diffusion process of Ornstein-Uhlenbeck type with unknown drift. We use\nthe dynamical programming approach and find an optimal financial strategy which\ndepends on the drift parameter. To estimate the drift coefficient we observe\nthe economic factor $Y$ in an interval $[0,T_0]$ for fixed $T_0>0$, and use\nsequential estimation. We show, that the consumption and investment strategy\ncalculated through this sequential procedure is $\\delta$-optimal.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2012 12:34:21 GMT"}, {"version": "v2", "created": "Mon, 26 Aug 2013 04:34:10 GMT"}, {"version": "v3", "created": "Thu, 14 May 2015 01:19:55 GMT"}], "update_date": "2015-05-15", "authors_parsed": [["Berdjane", "Belkacem", "", "LMRS"], ["Pergamenshchikov", "Sergei", "", "LMRS"]]}, {"id": "1210.5267", "submitter": "Silvia Bacci Dr", "authors": "Francesco Bartolucci, Silvia Bacci, Michela Gnaldi", "title": "MultiLCIRT: An R package for multidimensional latent class item response\n  models", "comments": "36 pages, 1 figures, 4 tables. arXiv admin note: substantial text\n  overlap with arXiv:1201.4667", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We illustrate a class of Item Response Theory (IRT) models for binary and\nordinal polythomous items and we describe an R package for dealing with these\nmodels, which is named MultiLCIRT. The models at issue extend traditional IRT\nmodels allowing for (i) multidimensionality and (ii) discreteness of latent\ntraits. This class of models also allows for different parameterizations for\nthe conditional distribution of the response variables given the latent traits,\ndepending on both the type of link function and the constraints imposed on the\ndiscriminating and the difficulty item parameters. We illustrate how the\nproposed class of models may be estimated by the maximum likelihood approach\nvia an Expectation-Maximization algorithm, which is implemented in the\nMultiLCIRT package, and we discuss in detail issues related to model selection.\nIn order to illustrate this package, we analyze two datasets: one concerning\nbinary items and referred to the measurement of ability in mathematics and the\nother one coming from the administration of ordinal polythomous items for the\nassessment of anxiety and depression. In the first application, we illustrate\nhow aggregating items in homogeneous groups through a model-based hierarchical\nclustering procedure which is implemented in the proposed package. In the\nsecond application, we describe the steps to select a specific model having the\nbest fit in our class of IRT models.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2012 21:40:33 GMT"}], "update_date": "2012-10-22", "authors_parsed": [["Bartolucci", "Francesco", ""], ["Bacci", "Silvia", ""], ["Gnaldi", "Michela", ""]]}, {"id": "1210.5418", "submitter": "Nikolai Krivulin", "authors": "Nikolai Krivulin", "title": "Unbiased estimates for gradients of stochastic network performance\n  measures", "comments": null, "journal-ref": "Acta Applicandae Mathematicae, October 1993, Volume 33, Issue 1,\n  pp. 21-43. ISSN: 0167-8019", "doi": "10.1007/BF00995493", "report-no": null, "categories": "math.OC stat.AP stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Three classes of stochastic networks and their performance measures are\nconsidered. These performance measures are defined as the expected value of\nsome random variables and cannot normally be obtained analytically as functions\nof network parameters in a closed form. We give similar representations for the\nrandom variables to provide a useful way of analytical study of these functions\nand their gradients. The representations are used to obtain sufficient\nconditions for the gradient estimates to be unbiased. The conditions are rather\ngeneral and usually met in simulation study of the stochastic networks.\nApplications of the results are discussed and some practical algorithms of\ncalculating unbiased estimates of the gradients are also presented.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2012 13:38:06 GMT"}], "update_date": "2012-10-24", "authors_parsed": [["Krivulin", "Nikolai", ""]]}, {"id": "1210.5552", "submitter": "Taposh Banerjee", "authors": "Venugopal V. Veeravalli and Taposh Banerjee", "title": "Quickest Change Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT math.IT math.OC math.PR stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of detecting changes in the statistical properties of a\nstochastic system and time series arises in various branches of science and\nengineering. It has a wide spectrum of important applications ranging from\nmachine monitoring to biomedical signal processing. In all of these\napplications the observations being monitored undergo a change in distribution\nin response to a change or anomaly in the environment, and the goal is to\ndetect the change as quickly as possibly, subject to false alarm constraints.\nIn this chapter, two formulations of the quickest change detection problem,\nBayesian and minimax, are introduced, and optimal or asymptotically optimal\nsolutions to these formulations are discussed. Then some generalizations and\nextensions of the quickest change detection problem are described. The chapter\nis concluded with a discussion of applications and open issues.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2012 21:54:46 GMT"}], "update_date": "2012-11-19", "authors_parsed": [["Veeravalli", "Venugopal V.", ""], ["Banerjee", "Taposh", ""]]}, {"id": "1210.5693", "submitter": "Fabrice Rossi", "authors": "St\\'ephan Cl\\'emen\\c{c}on (LTCI), Hector De Arazoza (MATCOM, LPP),\n  Fabrice Rossi (LTCI), Viet Chi Tran (LPP, CMAP)", "title": "Hierarchical clustering for graph visualization", "comments": "6 pages", "journal-ref": "European Symposium on Artificial Neural Networks (ESANN 2011),\n  Bruges : Belgium (2011)", "doi": null, "report-no": null, "categories": "stat.AP cs.SI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a graph visualization methodology based on hierarchical\nmaximal modularity clustering, with interactive and significant coarsening and\nrefining possibilities. An application of this method to HIV epidemic analysis\nin Cuba is outlined.\n", "versions": [{"version": "v1", "created": "Sun, 21 Oct 2012 06:19:43 GMT"}], "update_date": "2012-10-23", "authors_parsed": [["Cl\u00e9men\u00e7on", "St\u00e9phan", "", "LTCI"], ["De Arazoza", "Hector", "", "MATCOM, LPP"], ["Rossi", "Fabrice", "", "LTCI"], ["Tran", "Viet Chi", "", "LPP, CMAP"]]}, {"id": "1210.5694", "submitter": "Fabrice Rossi", "authors": "St\\'ephan Cl\\'emen\\c{c}on (LTCI), Hector De Arazoza (MATCOM, LPP),\n  Fabrice Rossi (LTCI), Viet Chi Tran (LPP, CMAP)", "title": "Visual Mining of Epidemic Networks", "comments": "8 pages", "journal-ref": "International Work Conference on Artificial Neural Networks,\n  Torremolinos : Spain (2011)", "doi": "10.1007/978-3-642-21498-1_35", "report-no": null, "categories": "stat.AP cs.SI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how an interactive graph visualization method based on maximal\nmodularity clustering can be used to explore a large epidemic network. The\nvisual representation is used to display statistical tests results that expose\nthe relations between the propagation of HIV in a sexual contact network and\nthe sexual orientation of the patients.\n", "versions": [{"version": "v1", "created": "Sun, 21 Oct 2012 06:20:13 GMT"}], "update_date": "2012-10-23", "authors_parsed": [["Cl\u00e9men\u00e7on", "St\u00e9phan", "", "LTCI"], ["De Arazoza", "Hector", "", "MATCOM, LPP"], ["Rossi", "Fabrice", "", "LTCI"], ["Tran", "Viet Chi", "", "LPP, CMAP"]]}, {"id": "1210.6003", "submitter": "Ioannis Papastathopoulos", "authors": "Ioannis Papastathopoulos and Jonathan A. Tawn", "title": "Stochastic Ordering under Conditional Modelling of Extreme Values:\n  Drug-Induced Liver Injury", "comments": "24 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Drug-induced liver injury (DILI) is a major public health issue and of\nserious concern for the pharmaceutical industry. Early detection of signs of a\ndrug's potential for DILI is vital for pharmaceutical companies' evaluation of\nnew drugs. A combination of extreme values of liver specific variables indicate\npotential DILI (Hy's Law). We estimate the probability of severe DILI using the\nHeffernan and Tawn (2004) conditional dependence model which arises naturally\nin applications where a multidimensional random variable is extreme in at least\none component. We extend the current model by including the assumption of\nstochastically ordered survival curves for different doses in a Phase 3 study.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2012 19:06:48 GMT"}, {"version": "v2", "created": "Mon, 26 May 2014 13:47:48 GMT"}], "update_date": "2014-05-27", "authors_parsed": [["Papastathopoulos", "Ioannis", ""], ["Tawn", "Jonathan A.", ""]]}, {"id": "1210.6044", "submitter": "Andrew Lucas", "authors": "Andrew Lucas, Ching Hua Lee", "title": "Multistable binary decision making on networks", "comments": "v3: mostly published version; v2: fixed minor textual errors; 21\n  pages, 8 figures, 1 table", "journal-ref": "Physical Review E87 (2013) 032806", "doi": "10.1103/PhysRevE.87.032806", "report-no": null, "categories": "physics.soc-ph cond-mat.stat-mech cs.SI stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a simple model for a binary decision making process on a graph,\nmotivated by modeling social decision making with cooperative individuals. The\nmodel is similar to a random field Ising model or fiber bundle model, but with\nkey differences on heterogeneous networks. For many types of disorder and\ninteractions between the nodes, we predict discontinuous phase transitions with\nmean field theory which are largely independent of network structure. We show\nhow these phase transitions can also be understood by studying microscopic\navalanches, and describe how network structure enhances fluctuations in the\ndistribution of avalanches. We suggest theoretically the existence of a\n\"glassy\" spectrum of equilibria associated with a typical phase, even on\ninfinite graphs, so long as the first moment of the degree distribution is\nfinite. This behavior implies that the model is robust against noise below a\ncertain scale, and also that phase transitions can switch from discontinuous to\ncontinuous on networks with too few edges. Numerical simulations suggest that\nour theory is accurate.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2012 20:00:12 GMT"}, {"version": "v2", "created": "Sun, 9 Dec 2012 19:54:04 GMT"}, {"version": "v3", "created": "Fri, 15 Mar 2013 03:56:25 GMT"}], "update_date": "2017-01-20", "authors_parsed": [["Lucas", "Andrew", ""], ["Lee", "Ching Hua", ""]]}, {"id": "1210.6232", "submitter": "Stefano Andreon", "authors": "S. Andreon (1), M. A. Hurn (2) ((1) INAF-OA Brera, (2) Bath Univ.,\n  Math Dept.)", "title": "Measurement errors and scaling relations in astrophysics: a review", "comments": "Invited review on \"Statistical Analysis and Data Mining\", a referred\n  journal of the American Statistical Association. In press", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.IM astro-ph.CO physics.data-an stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This review article considers some of the most common methods used in\nastronomy for regressing one quantity against another in order to estimate the\nmodel parameters or to predict an observationally expensive quantity using\ntrends between object values. These methods have to tackle some of the awkward\nfeatures prevalent in astronomical data, namely heteroscedastic\n(point-dependent) errors, intrinsic scatter, non-ignorable data collection and\nselection effects, data structure and non-uniform population (often called\nMalmquist bias), non-Gaussian data, outliers and mixtures of regressions. We\noutline how least square fits, weighted least squares methods, Maximum\nLikelihood, survival analysis, and Bayesian methods have been applied in the\nastrophysics literature when one or more of these features is present. In\nparticular we concentrate on errors-in-variables regression and we advocate\nBayesian techniques.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2012 13:41:39 GMT"}], "update_date": "2012-10-24", "authors_parsed": [["Andreon", "S.", ""], ["Hurn", "M. A.", ""]]}, {"id": "1210.6260", "submitter": "John Matthews", "authors": "John N.S. Matthews", "title": "An optimal multi-period crossover design for an application in\n  paediatric nephrology", "comments": "13 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Crossover clinical trials can provide substantial benefits by eliminating\ninter-patient variation from treatment comparisons and by allowing multiple\nobservations of each patient. They are particularly useful when sample sizes\nare necessarily small. These advantages proved particularly valuable in an\nassessment of clot prevention in children undergoing haemodialysis. Only small\nnumbers of children are treated at any given time in any single unit, but each\npatient is obliged to attend two or three times each week, suggesting the use\nof a crossover trial with many periods. Standard crossover trials described in\nthe literature a) typically have fewer than 10 periods and b) are based on a\nmodel of questionable applicability to this study. This paper describes the\nderivation of an optimal crossover trial with 30 periods which was used to\ncompare the treatments using nine patients.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2012 15:03:22 GMT"}], "update_date": "2012-10-24", "authors_parsed": [["Matthews", "John N. S.", ""]]}, {"id": "1210.6317", "submitter": "Shivakumar Viswanathan", "authors": "Shivakumar Viswanathan, Matthew Cieslak and Scott T. Grafton", "title": "On the geometric structure of fMRI searchlight-based information maps", "comments": "15 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC q-bio.QM stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information mapping is a popular application of Multivoxel Pattern Analysis\n(MVPA) to fMRI. Information maps are constructed using the so called\nsearchlight method, where the spherical multivoxel neighborhood of every voxel\n(i.e., a searchlight) in the brain is evaluated for the presence of\ntask-relevant response patterns. Despite their widespread use, information maps\npresent several challenges for interpretation. One such challenge has to do\nwith inferring the size and shape of a multivoxel pattern from its signature on\nthe information map. To address this issue, we formally examined the geometric\nbasis of this mapping relationship. Based on geometric considerations, we show\nhow and why small patterns (i.e., having smaller spatial extents) can produce a\nlarger signature on the information map as compared to large patterns,\nindependent of the size of the searchlight radius. Furthermore, we show that\nthe number of informative searchlights over the brain increase as a function of\nsearchlight radius, even in the complete absence of any multivariate response\npatterns. These properties are unrelated to the statistical capabilities of the\npattern-analysis algorithms used but are obligatory geometric properties\narising from using the searchlight procedure.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2012 18:21:16 GMT"}], "update_date": "2012-10-24", "authors_parsed": [["Viswanathan", "Shivakumar", ""], ["Cieslak", "Matthew", ""], ["Grafton", "Scott T.", ""]]}, {"id": "1210.6492", "submitter": "Aaron Smith", "authors": "Aaron Carl Smith", "title": "Using Householder Matrices to Establish Mixing Test Critical Values", "comments": "24 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.DS stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A measure-preserving dynamical system can be approximated by a Markov shift\nwith a bistochastic matrix. This leads to using empirical stochastic matrices\nto measure and estimate properties of stirring protocols. Specifically, the\nsecond largest eigenvalue can be used to statistically decide if a stirring\nprotocol is weak-mixing, ergodic, or nonergodic. Such hypothesis tests require\nappropriate probability distributions. In this paper, we propose using Monte\nCarlo empirical probability distributions from unistochastic matrices to\nestablish critical values. These unistochastic matrices arise from randomly\nconstructed Householder matrices.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2012 11:17:42 GMT"}], "update_date": "2012-10-25", "authors_parsed": [["Smith", "Aaron Carl", ""]]}, {"id": "1210.6958", "submitter": "Sami Stouli", "authors": "Richard Spady and Sami Stouli", "title": "Dual Regression", "comments": "Version accepted for publication, 39 pages, 4 figures", "journal-ref": "Biometrika. Vol. 105(1), pp.1-18 (2018)", "doi": null, "report-no": null, "categories": "stat.ME econ.EM stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose dual regression as an alternative to the quantile regression\nprocess for the global estimation of conditional distribution functions under\nminimal assumptions. Dual regression provides all the interpretational power of\nthe quantile regression process while avoiding the need for repairing the\nintersecting conditional quantile surfaces that quantile regression often\nproduces in practice. Our approach introduces a mathematical programming\ncharacterization of conditional distribution functions which, in its simplest\nform, is the dual program of a simultaneous estimator for linear location-scale\nmodels. We apply our general characterization to the specification and\nestimation of a flexible class of conditional distribution functions, and\npresent asymptotic theory for the corresponding empirical dual regression\nprocess.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2012 19:25:04 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2013 01:04:49 GMT"}, {"version": "v3", "created": "Tue, 12 Jan 2016 00:17:13 GMT"}, {"version": "v4", "created": "Sun, 23 Sep 2018 13:10:48 GMT"}], "update_date": "2018-09-26", "authors_parsed": [["Spady", "Richard", ""], ["Stouli", "Sami", ""]]}, {"id": "1210.7125", "submitter": "Michael Eichler", "authors": "Michael Eichler", "title": "Comment on: Evaluating causal relations in neural systems: Granger\n  causality, directed transfer function and statistical assessment of\n  significance", "comments": "3 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We comment on a paper by Kaminski et al. (2001) and show that their claim of\na relationship between the directed transfer function (DTF) and the concept of\nGranger causality is false.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2012 12:44:28 GMT"}], "update_date": "2012-10-29", "authors_parsed": [["Eichler", "Michael", ""]]}, {"id": "1210.7141", "submitter": "Maximilian Schlupp", "authors": "Till Moritz Karbach and Maximilian Schlupp", "title": "Constraints on Yield Parameters in Extended Maximum Likelihood Fits", "comments": "6 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.data-an hep-ex stat.AP", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  The method of extended maximum likelihood is a well known concept of\nparameter estimation. One can implement external knowledge on the unknown\nparameters by multiplying the likelihood by constraint terms. In this note, we\nemphasize that this is also true for yield parameters in an extended maximum\nlikelihood fit, which is widely used in the particle physics community. We\nrecommend a way to generate pseudo-experiments in presence of constraint terms\non yield parameters, and point to pitfalls inside the RooFit framework.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2012 13:23:37 GMT"}], "update_date": "2012-10-29", "authors_parsed": [["Karbach", "Till Moritz", ""], ["Schlupp", "Maximilian", ""]]}, {"id": "1210.7215", "submitter": "Gareth Peters Dr", "authors": "Kylie-Anne Richards, Gareth W. Peters, William Dunsmuir", "title": "Heavy-Tailed Features and Empirical Analysis of the Limit Order Book\n  Volume Profiles in Futures Markets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST q-fin.TR stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper poses a few fundamental questions regarding the attributes of the\nvolume profile of a Limit Order Books stochastic structure by taking into\nconsideration aspects of intraday and interday statistical features, the impact\nof different exchange features and the impact of market participants in\ndifferent asset sectors. This paper aims to address the following questions:\n  1. Is there statistical evidence that heavy-tailed sub-exponential volume\nprofiles occur at different levels of the Limit Order Book on the bid and ask\nand if so does this happen on intra or interday time scales ?\n  2.In futures exchanges, are heavy tail features exchange (CBOT, CME, EUREX,\nSGX and COMEX) or asset class (government bonds, equities and precious metals)\ndependent and do they happen on ultra-high (<1sec) or mid-range (1sec -10min)\nhigh frequency data?\n  3.Does the presence of stochastic heavy-tailed volume profile features evolve\nin a manner that would inform or be indicative of market participant behaviors,\nsuch as high frequency algorithmic trading, quote stuffing and price discovery\nintra-daily?\n  4. Is there statistical evidence for a need to consider dynamic behavior of\nthe parameters of models for Limit Order Book volume profiles on an intra-daily\ntime scale ?\n  Progress on aspects of each question is obtained via statistically rigorous\nresults to verify the empirical findings for an unprecedentedly large set of\nfutures market LOB data. The data comprises several exchanges, several futures\nasset classes and all trading days of 2010, using market depth (Type II) order\nbook data to 5 levels on the bid and ask.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2012 19:05:49 GMT"}, {"version": "v2", "created": "Wed, 22 Apr 2015 08:46:08 GMT"}], "update_date": "2015-04-23", "authors_parsed": [["Richards", "Kylie-Anne", ""], ["Peters", "Gareth W.", ""], ["Dunsmuir", "William", ""]]}, {"id": "1210.7583", "submitter": "Bertrand Servin", "authors": "Mar\\`ia In\\`es Fariello, Simon Boitard, Hugo Naya, Magali\n  SanCristobal, Bertrand Servin", "title": "Using haplotype differentiation among hierarchically structured\n  populations for the detection of selection signatures", "comments": null, "journal-ref": null, "doi": "10.1534/genetics.112.147231", "report-no": null, "categories": "q-bio.PE q-bio.QM stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The detection of molecular signatures of selection is one of the major\nconcerns of modern population genetics. A widely used strategy in this context\nis to compare samples from several populations, and to look for genomic regions\nwith outstanding genetic differentiation between these populations. Genetic\ndifferentiation is generally based on allele frequency differences between\npopulations, which are measured by Fst or related statistics. Here we introduce\na new statistic, denoted hapFLK, which focuses instead on the differences of\nhaplotype frequencies between populations. In contrast to most existing\nstatistics, hapFLK accounts for the hierarchical structure of the sampled\npopulations. Using computer simulations, we show that each of these two\nfeatures - the use of haplotype information and of the hierarchical structure\nof populations - significantly improves the detection power of selected loci,\nand that combining them in the hapFLK statistic provides even greater power. We\nalso show that hapFLK is robust with respect to bottlenecks and migration and\nimproves over existing approaches in many situations. Finally, we apply hapFLK\nto a set of six sheep breeds from Northern Europe, and identify seven regions\nunder selection, which include already reported regions but also several new\nones. We propose a method to help identifying the population(s) under selection\nin a detected region, which reveals that in many of these regions selection\nmost likely occurred in more than one population. Furthermore, several of the\ndetected regions correspond to incomplete sweeps, where the favourable\nhaplotype is only at intermediate frequency in the population(s) under\nselection.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2012 07:53:00 GMT"}], "update_date": "2013-01-24", "authors_parsed": [["Fariello", "Mar\u00eca In\u00e8s", ""], ["Boitard", "Simon", ""], ["Naya", "Hugo", ""], ["SanCristobal", "Magali", ""], ["Servin", "Bertrand", ""]]}, {"id": "1210.7762", "submitter": "Martin Kunz", "authors": "Martin Kunz, Ren\\'ee Hlozek, Bruce A. Bassett, Mathew Smith, James\n  Newling and Melvin Varughese", "title": "BEAMS: separating the wheat from the chaff in supernova analysis", "comments": "23 pages, 9 figures. Chapter 4 in \"Astrostatistical Challenges for\n  the New Astronomy\" (Joseph M. Hilbe, ed., Springer, New York, forthcoming in\n  2012), the inaugural volume for the Springer Series in Astrostatistics", "journal-ref": null, "doi": "10.1007/978-1-4614-3508-2_4", "report-no": null, "categories": "astro-ph.IM astro-ph.CO physics.data-an stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Bayesian Estimation Applied to Multiple Species (BEAMS), an\nalgorithm designed to deal with parameter estimation when using contaminated\ndata. We present the algorithm and demonstrate how it works with the help of a\nGaussian simulation. We then apply it to supernova data from the Sloan Digital\nSky Survey (SDSS), showing how the resulting confidence contours of the\ncosmological parameters shrink significantly.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2012 18:20:39 GMT"}], "update_date": "2016-12-07", "authors_parsed": [["Kunz", "Martin", ""], ["Hlozek", "Ren\u00e9e", ""], ["Bassett", "Bruce A.", ""], ["Smith", "Mathew", ""], ["Newling", "James", ""], ["Varughese", "Melvin", ""]]}, {"id": "1210.8176", "submitter": "Paulo Urriza", "authors": "Paulo Urriza, Eric Rebeiz, Danijela Cabric", "title": "Eigenvalue-based Cyclostationary Spectrum Sensing Using Multiple\n  Antennas", "comments": "6 pages, 6 figures, accepted to IEEE GLOBECOM 2012", "journal-ref": null, "doi": "10.1109/GLOCOM.2012.6503326", "report-no": null, "categories": "cs.PF cs.IT math.IT stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a signal-selective spectrum sensing method for\ncognitive radio networks and specifically targeted for receivers with\nmultiple-antenna capability. This method is used for detecting the presence or\nabsence of primary users based on the eigenvalues of the cyclic covariance\nmatrix of received signals. In particular, the cyclic correlation significance\ntest is used to detect a specific signal-of-interest by exploiting knowledge of\nits cyclic frequencies. The analytical threshold for achieving constant false\nalarm rate using this detection method is presented, verified through\nsimulations, and shown to be independent of both the number of samples used and\nthe noise variance, effectively eliminating the dependence on accurate noise\nestimation. The proposed method is also shown, through numerical simulations,\nto outperform existing multiple-antenna cyclostationary-based spectrum sensing\nalgorithms under a quasi-static Rayleigh fading channel, in both spatially\ncorrelated and uncorrelated noise environments. The algorithm also has\nsignificantly lower computational complexity than these other approaches.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2012 21:23:57 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Urriza", "Paulo", ""], ["Rebeiz", "Eric", ""], ["Cabric", "Danijela", ""]]}]