[{"id": "1004.0682", "submitter": "Jean-Claude Juhel", "authors": "Jean-Claude Juhel (CRIFP)", "title": "L'effet de levier de tr\\'esorerie", "comments": null, "journal-ref": "La Revue du Financier Septembre-d\\'ecembre, Num\\'ero 173-174\n  (2008) 16 - 46", "doi": null, "report-no": null, "categories": "q-fin.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The effect of leverage on liquidity is a tool for analysing the level of\nliquidity for a given production process. It measures the sensitivity of the\nlevel of liquidity that results from changes in the volume of production and\nunit operating margin. A commercial activity is liquid at the moment when all\ncosts are covered by revenues. However, not all of the cash flows from\nproduction influence liquidity levels. The estimated costs do not directly\ninfluence the level of liquidity. Therefore, two indicators are to be taken\ninto consideration: the elasticity of ongoing liquidity - fixed costs include\nestimated costs, and, the elasticity of immediate liquidity - fixed costs only\ninclude costs that are payable. The coefficients of leverage of ongoing\nliquidity and of leverage of immediate liquidity in relation to the operating\nmargin have a behaviour that is identical to that calculated in relation to\nproduction. If the productive capacity remains unchanged, the regulation of the\nchange in elasticity of the costs and of its influence on the unitary operating\nmargin is the sole parameter available to the entrepreneur to maintain the\nliquidity of the company at the desired level. But, if the productive capacity\nis variable, the entrepreneur can use the volume of sales to control liquidity\nbut then the transformation of the production process must be analysed so as to\nadjust the relevant elements to retain in the operating structure the degree of\nliquidity wished for.\n", "versions": [{"version": "v1", "created": "Mon, 5 Apr 2010 19:07:57 GMT"}], "update_date": "2010-04-08", "authors_parsed": [["Juhel", "Jean-Claude", "", "CRIFP"]]}, {"id": "1004.0844", "submitter": "Fredrick Michael", "authors": "Fredrick Michael", "title": "Quantum Portfolios of Observables and the Risk Neutral Valuation Model", "comments": "8 pages, no figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum Portfolios of quantum algorithms encoded on qbits have recently been\nreported. In this paper a discussion of the continuous variables version of\nquantum portfolios is presented. A risk neutral valuation model for options\ndependent on the measured values of the observables, analogous to the\ntraditional Black-Scholes valuation model, is obtained from the underlying\nstochastic equations. The quantum algorithms are here encoded on simple\nharmonic oscillator (SHO) states, and a Fokker-Planck equation for the Glauber\nP-representation is obtained as a starting point for the analysis. A discussion\nof the observation of the polarization of a portfolio of qbits is also obtained\nand the resultant Fokker-Planck equation is used to obtain the risk neutral\nvaluation of the qbit polarization portfolio.\n", "versions": [{"version": "v1", "created": "Fri, 2 Apr 2010 06:14:37 GMT"}], "update_date": "2015-03-14", "authors_parsed": [["Michael", "Fredrick", ""]]}, {"id": "1004.1670", "submitter": "Philip Maymin", "authors": "Philip Z. Maymin and Zakhar G. Maymin", "title": "Any Regulation of Risk Increases Risk", "comments": "25 pages; forthcoming in Financial Markets and Portfolio Management", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM q-fin.GN q-fin.PM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that any objective risk measurement algorithm mandated by central\nbanks for regulated financial entities will result in more risk being taken on\nby those financial entities than would otherwise be the case. Furthermore, the\nrisks taken on by the regulated financial entities are far more systemically\nconcentrated than they would have been otherwise, making the entire financial\nsystem more fragile. This result leaves three directions for the future of\nfinancial regulation: continue regulating by enforcing risk measurement\nalgorithms at the cost of occasional severe crises, regulate more severely and\nsubjectively by fully nationalizing all financial entities, or abolish all\ncentral banking regulations including deposit insurance to let risk be\ndetermined by the entities themselves and, ultimately, by their depositors\nthrough voluntary market transactions rather than by the taxpayers through\nenforced government participation.\n", "versions": [{"version": "v1", "created": "Sat, 10 Apr 2010 02:24:12 GMT"}, {"version": "v2", "created": "Thu, 15 Apr 2010 13:55:56 GMT"}, {"version": "v3", "created": "Wed, 25 May 2011 02:32:30 GMT"}, {"version": "v4", "created": "Fri, 20 Apr 2012 19:05:19 GMT"}], "update_date": "2012-04-23", "authors_parsed": [["Maymin", "Philip Z.", ""], ["Maymin", "Zakhar G.", ""]]}, {"id": "1004.1726", "submitter": "Andrew Ledvina", "authors": "Andrew Ledvina and Ronnie Sircar", "title": "Dynamic Bertrand Oligopoly", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC q-fin.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study continuous time Bertrand oligopolies in which a small number of\nfirms producing similar goods compete with one another by setting prices. We\nfirst analyze a static version of this game in order to better understand the\nstrategies played in the dynamic setting. Within the static game, we\ncharacterize the Nash equilibrium when there are $N$ players with heterogeneous\ncosts. In the dynamic game with uncertain market demand, firms of different\nsizes have different lifetime capacities which deplete over time according to\nthe market demand for their good. We setup the nonzero-sum stochastic\ndifferential game and its associated system of HJB partial differential\nequations in the case of linear demand functions. We characterize certain\nqualitative features of the game using an asymptotic approximation in the limit\nof small competition. The equilibrium of the game is further studied using\nnumerical solutions. We find that consumers benefit the most when a market is\nstructured with many firms of the same relative size producing highly\nsubstitutable goods. However, a large degree of substitutability does not\nalways lead to large drops in price, for example when two firms have a large\ndifference in their size.\n", "versions": [{"version": "v1", "created": "Sat, 10 Apr 2010 16:52:36 GMT"}, {"version": "v2", "created": "Wed, 30 Jun 2010 16:34:22 GMT"}], "update_date": "2010-07-01", "authors_parsed": [["Ledvina", "Andrew", ""], ["Sircar", "Ronnie", ""]]}, {"id": "1004.3067", "submitter": "Eugen Perchik", "authors": "Eugen Perchik", "title": "Fundamental defect of the macroeconomic thinking as one of the main\n  causes of the crisis endured", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main points of the first section of the article written by S.I.\nChernyshov, A.V. Voronin and S.A. Razumovsky arXiv:1003.4382), which deals with\nthe fundamental bases of the macroeconomic theory, have been analyzed. An\nincorrectness of the Harrod's model of the economical growth in its generally\naccepted interpretation was specifically considered. The inevitability of the\neconomic crisis has been shown to follow directly from the premises of this\nmodel. At the same time there is an opportunity to realize the damping\nstrategies.\n", "versions": [{"version": "v1", "created": "Sun, 18 Apr 2010 22:36:31 GMT"}], "update_date": "2010-04-20", "authors_parsed": [["Perchik", "Eugen", ""]]}, {"id": "1004.3229", "submitter": "Roehner", "authors": "Bertrand M. Roehner", "title": "Fifteen years of econophysics: worries, hopes and prospects", "comments": "15 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph nlin.AO physics.pop-ph q-fin.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This anniversary paper is an occasion to recall some of the events that\nshaped institutional econophysics. But in these thoughts about the evolution of\neconophysics in the last 15 years we also express some concerns. Our main worry\nconcerns the relinquishment of the simplicity requirement. Ever since the\ngroundbreaking experiments of Galileo some three centuries ago, the great\nsuccesses of physicists were largely due to the fact that they were able to\ndecompose complex phenomena into simpler ones. Remember that the first\nobservation of the effects of an electrical current was made by Alessandro\nVolta (1745-1827) on the leg of a frog! Clearly, to make sense this observation\nhad to be broken down into several separate effects. Nowadays, with computers\nbeing able to handle huge amounts of data and to simulate any stochastic\nprocess no matter how complicated, there is no longer any real need for such a\nsearch for simplicity. Why should one spend time and effort trying to break up\ncomplicated phenomena when it is possible to handle them globally? On this new\nroad there are several stumbling blocks, however. Do such global mathematical\ndescriptions lead to a real understanding? Do they produce building blocks\nwhich can be used elsewhere and thus make our knowledge and comprehension to\ngrow in a cumulative way? Should econophysics also adopt the \"globalized\"\nperspective that has been endorsed, developed and spread by the numerous\n\"Complexity Departments\" which sprang up during the last decade?\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2010 16:37:51 GMT"}], "update_date": "2010-04-20", "authors_parsed": [["Roehner", "Bertrand M.", ""]]}, {"id": "1004.5109", "submitter": "Anirban Chakraborti", "authors": "Mehdi Lallouache, Aymen Jedidi and Anirban Chakraborti", "title": "Wealth distribution: To be or not to be a Gamma?", "comments": "7 pages, 4 figures in REVTeX format. Revised version. To appear in\n  \"Econophysics\", a special issue in Science and Culture (Kolkata, India) to\n  celebrate 15 years of Econophysics", "journal-ref": "Science and Culture (Kolkata, India) Volume 76 (9-10), 478 (2010)", "doi": null, "report-no": null, "categories": "physics.soc-ph cond-mat.stat-mech q-fin.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We review some aspects, especially those we can tackle analytically, of a\nminimal model of closed economy analogous to the kinetic theory model of ideal\ngases where the agents exchange wealth amongst themselves such that the total\nwealth is conserved, and each individual agent saves a fraction (0 < lambda <\n1) of wealth before transaction. We are interested in the special case where\nthe fraction lambda is constant for all the agents (global saving propensity)\nin the closed system. We show by moment calculations that the resulting wealth\ndistribution cannot be the Gamma distribution that was conjectured in Phys.\nRev. E 70, 016104 (2004). We also derive a form for the distribution at low\nwealth, which is a new result.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2010 19:04:05 GMT"}, {"version": "v2", "created": "Sun, 23 May 2010 16:29:43 GMT"}], "update_date": "2010-10-27", "authors_parsed": [["Lallouache", "Mehdi", ""], ["Jedidi", "Aymen", ""], ["Chakraborti", "Anirban", ""]]}, {"id": "1004.5169", "submitter": "Andrey Sokolov", "authors": "Andrey Sokolov, Andrew Melatos, Tien Kieu", "title": "Laplace transform analysis of a multiplicative asset transfer model", "comments": null, "journal-ref": "Physica A 389 (2010) 2782-2792", "doi": "10.1016/j.physa.2010.02.045", "report-no": null, "categories": "q-fin.GN physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze a simple asset transfer model in which the transfer amount is a\nfixed fraction $f$ of the giver's wealth. The model is analyzed in a new way by\nLaplace transforming the master equation, solving it analytically and\nnumerically for the steady-state distribution, and exploring the solutions for\nvarious values of $f\\in(0,1)$. The Laplace transform analysis is superior to\nagent-based simulations as it does not depend on the number of agents, enabling\nus to study entropy and inequality in regimes that are costly to address with\nsimulations. We demonstrate that Boltzmann entropy is not a suitable (e.g.\nnon-monotonic) measure of disorder in a multiplicative asset transfer system\nand suggest an asymmetric stochastic process that is equivalent to the asset\ntransfer model.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2010 01:04:14 GMT"}], "update_date": "2015-05-18", "authors_parsed": [["Sokolov", "Andrey", ""], ["Melatos", "Andrew", ""], ["Kieu", "Tien", ""]]}]