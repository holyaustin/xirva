[{"id": "1710.01578", "submitter": "Steffen Schuldenzucker", "authors": "Steffen Schuldenzucker, Sven Seuken, Stefano Battiston", "title": "The Computational Complexity of Financial Networks with Credit Default\n  Swaps", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM cs.CC cs.GT q-fin.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The 2008 financial crisis has been attributed to \"excessive complexity\" of\nthe financial system due to financial innovation. We employ computational\ncomplexity theory to make this notion precise. Specifically, we consider the\nproblem of clearing a financial network after a shock. Prior work has shown\nthat when banks can only enter into simple debt contracts with each other, then\nthis problem can be solved in polynomial time. In contrast, if they can also\nenter into credit default swaps (CDSs), i.e., financial derivative contracts\nthat depend on the default of another bank, a solution may not even exist.\n  In this work, we show that deciding if a solution exists is NP-complete if\nCDSs are allowed. This remains true if we relax the problem to\n$\\varepsilon$-approximate solutions, for a constant $\\varepsilon$. We further\nshow that, under sufficient conditions where a solution is guaranteed to exist,\nthe approximate search problem is PPAD-complete for constant $\\varepsilon$. We\nthen try to isolate the \"origin\" of the complexity. It turns out that already\ndetermining which banks default is hard. Further, we show that the complexity\nis not driven by the dependence of counterparties on each other, but rather\nhinges on the presence of so-called naked CDSs. If naked CDSs are not present,\nwe receive a simple polynomial-time algorithm. Our results are of practical\nimportance for regulators' stress tests and regulatory policy.\n", "versions": [{"version": "v1", "created": "Wed, 4 Oct 2017 12:47:49 GMT"}, {"version": "v2", "created": "Wed, 1 Nov 2017 12:54:48 GMT"}, {"version": "v3", "created": "Mon, 20 May 2019 12:45:20 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Schuldenzucker", "Steffen", ""], ["Seuken", "Sven", ""], ["Battiston", "Stefano", ""]]}, {"id": "1710.02755", "submitter": "Abhishek Mohan", "authors": "Agnibho Roy, Abhishek Mohan", "title": "An Optimized Microeconomic Modeling System for Analyzing Industrial\n  Externalities in Non-OECD Countries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.EC q-fin.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we provide an integrated systems modeling approach to\nanalyzing global externalities from a microeconomic perspective. Various forms\nof policy (fiscal, monetary, etc.) have addressed flaws and market failures in\nmodels, but few have been able to successfully eliminate modern externalities\nthat remain an environmental and human threat. We assess three primary global\nindustries (pollution, agriculture, and energy) with respect to non-OECD\nentities through both qualitative and quantitative studies. By combining key\nmutual points of specific externalities present within each respective\nindustry, we are able to propose an alternative and optimized solution to\ninternalizing them via incentives and cooperative behavior rather than by\ntraditional Pigouvian taxes and subsidies.\n", "versions": [{"version": "v1", "created": "Sat, 7 Oct 2017 22:58:46 GMT"}], "update_date": "2017-10-10", "authors_parsed": [["Roy", "Agnibho", ""], ["Mohan", "Abhishek", ""]]}, {"id": "1710.03211", "submitter": "Svetlozar Rachev", "authors": "Svetlozar Rachev, Stoyan Stoyanov, Stefan Mittnik, Frank J. Fabozzi,\n  Abootaleb Shirvani", "title": "Behavioral Finance -- Asset Prices Predictability, Equity Premium\n  Puzzle, Volatility Puzzle: The Rational Finance Approach", "comments": null, "journal-ref": null, "doi": "10.13140/RG.2.2.29789.77287", "report-no": null, "categories": "q-fin.MF q-fin.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we address three main objections of behavioral finance to the\ntheory of rational finance, considered as anomalies the theory of rational\nfinance cannot explain: Predictability of asset returns, The Equity Premium,\n(The Volatility Puzzle. We offer resolutions of those objections within the\nrational finance. We do not claim that those are the only possible explanations\nof the anomalies, but offer statistical models within the rational theory of\nfinance which can be used without relying on behavioral finance assumptions\nwhen searching for explanations of those anomalies.\n", "versions": [{"version": "v1", "created": "Mon, 9 Oct 2017 17:45:44 GMT"}, {"version": "v2", "created": "Sun, 2 Feb 2020 05:31:57 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Rachev", "Svetlozar", ""], ["Stoyanov", "Stoyan", ""], ["Mittnik", "Stefan", ""], ["Fabozzi", "Frank J.", ""], ["Shirvani", "Abootaleb", ""]]}, {"id": "1710.03526", "submitter": "Pablo Dorta-Gonzalez", "authors": "M\\'onica Clavel, Jes\\'us Arteaga-Ortiz, Rub\\'en Fern\\'andez-Ortiz,\n  Pablo Dorta-Gonz\\'alez", "title": "Measuring the gradualist approach to internationalization", "comments": "18 pages, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP physics.soc-ph q-fin.GN", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The objective of this paper is to fill a gap in the literature on\ninternationalization, in relation to the absence of objective and measurable\nperformance indicators on the process of how firms sequentially enter external\nmarkets. To that end, this research develops a quantitative tool that can be\nused as a performance indicator of gradualness for firms entering external\nmarkets at a sectoral level. The performance indicator is based on firms'\nexport volume, number of years of exporting, geographic areas targeted for\nexport, and when exports were initiated for each area. Additionally, the\nindicator is tested empirically in the Spanish wine sector. The main\ncontribution of this study is the creation of an international priority index\nwhich serves as a valuable and reliable tool because of its potential use in\nother industry sectors and geographic areas, allowing us to analyze how\ngeographically differentiated internationalization strategies develop.\n", "versions": [{"version": "v1", "created": "Tue, 10 Oct 2017 12:00:06 GMT"}], "update_date": "2017-10-11", "authors_parsed": [["Clavel", "M\u00f3nica", ""], ["Arteaga-Ortiz", "Jes\u00fas", ""], ["Fern\u00e1ndez-Ortiz", "Rub\u00e9n", ""], ["Dorta-Gonz\u00e1lez", "Pablo", ""]]}, {"id": "1710.06285", "submitter": "Yaneer Bar-Yam", "authors": "Yaneer Bar-Yam, Jean Langlois-Meurinne, Mari Kawakatsu, Rodolfo Garcia", "title": "Preliminary steps toward a universal economic dynamics for monetary and\n  fiscal policy", "comments": "45 pages, 15 figures; Expanded overview and references", "journal-ref": null, "doi": null, "report-no": "New England Complex Systems Institute Report 2017-10-01", "categories": "physics.soc-ph cs.CY nlin.AO q-fin.EC q-fin.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the relationship between economic activity and intervention,\nincluding monetary and fiscal policy, using a universal dynamic framework.\nCentral bank policies are designed for growth without excess inflation.\nHowever, unemployment, investment, consumption, and inflation are interlinked.\nUnderstanding dynamics is crucial to assessing the effects of policy,\nespecially in the aftermath of the financial crisis. Here we lay out a program\nof research into monetary and economic dynamics and preliminary steps toward\nits execution. We use principles of response theory to derive implications for\npolicy. We find that the current approach, which considers the overall money\nsupply, is insufficient to regulate economic growth. While it can achieve some\ndegree of control, optimizing growth also requires a fiscal policy balancing\nmonetary injection between two dominant loop flows, the consumption and wages\nloop, and investment and returns loop. The balance arises from a composite of\ngovernment tax, entitlement, subsidy policies, corporate policies, as well as\nmonetary policy. We show empirically that a transition occurred in 1980 between\ntwo regimes--an oversupply to the consumption and wages loop, to an oversupply\nof the investment and returns loop. The imbalance is manifest in savings and\nborrowing by consumers and investors, and in inflation. The latter increased\nuntil 1980, and decreased subsequently, resulting in a zero rate largely\nunrelated to the financial crisis. Three recessions and the financial crisis\nare part of this dynamic. Optimizing growth now requires shifting the balance.\nOur analysis supports advocates of greater income and / or government support\nfor the poor who use a larger fraction of income for consumption. This promotes\ninvestment due to growth in demand. Otherwise, investment opportunities are\nlimited, capital remains uninvested, and does not contribute to growth.\n", "versions": [{"version": "v1", "created": "Tue, 17 Oct 2017 13:54:45 GMT"}, {"version": "v2", "created": "Fri, 29 Dec 2017 15:33:10 GMT"}], "update_date": "2018-01-01", "authors_parsed": [["Bar-Yam", "Yaneer", ""], ["Langlois-Meurinne", "Jean", ""], ["Kawakatsu", "Mari", ""], ["Garcia", "Rodolfo", ""]]}, {"id": "1710.07918", "submitter": "Haoyong Chen", "authors": "Haoyong Chen, Lijia Han", "title": "Electricity Market Theory Based on Continuous Time Commodity Model", "comments": "17 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM q-fin.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent research report of U.S. Department of Energy prompts us to\nre-examine the pricing theories applied in electricity market design. The\ntheory of spot pricing is the basis of electricity market design in many\ncountries, but it has two major drawbacks: one is that it is still based on the\ntraditional hourly scheduling/dispatch model, ignores the crucial time\ncontinuity in electric power production and consumption and does not treat the\ninter-temporal constraints seriously; the second is that it assumes that the\nelectricity products are homogeneous in the same dispatch period and cannot\ndistinguish the base, intermediate and peak power with obviously different\ntechnical and economic characteristics. To overcome the shortcomings, this\npaper presents a continuous time commodity model of electricity, including spot\npricing model and load duration model. The market optimization models under the\ntwo pricing mechanisms are established with the Riemann and Lebesgue integrals\nrespectively and the functional optimization problem are solved by the\nEuler-Lagrange equation to obtain the market equilibria. The feasibility of\npricing according to load duration is proved by strict mathematical derivation.\nSimulation results show that load duration pricing can correctly identify and\nvalue different attributes of generators, reduce the total electricity\npurchasing cost, and distribute profits among the power plants more equitably.\nThe theory and methods proposed in this paper will provide new ideas and\ntheoretical foundation for the development of electric power markets.\n", "versions": [{"version": "v1", "created": "Sun, 22 Oct 2017 10:11:18 GMT"}], "update_date": "2017-10-24", "authors_parsed": [["Chen", "Haoyong", ""], ["Han", "Lijia", ""]]}, {"id": "1710.09419", "submitter": "Bent Flyvbjerg", "authors": "Bent Flyvbjerg, Chi-keung Hon, and Wing Huen Fok", "title": "Reference Class Forecasting for Hong Kong's Major Roadworks Projects", "comments": null, "journal-ref": "Proceedings of the Institution of Civil Engineers 169, November\n  2016, Issue CE6, pp. 17-24", "doi": "10.1680/jcien.15.00075", "report-no": null, "categories": "q-fin.GN q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reference class forecasting is a method to remove optimism bias and strategic\nmisrepresentation in infrastructure projects and programmes. In 2012 the Hong\nKong government's Development Bureau commissioned a feasibility study on\nreference class forecasting in Hong Kong - a first for the Asia-Pacific region.\nThis study involved 25 roadwork projects, for which forecast costs and\ndurations were compared with actual outcomes. The analysis established and\nverified the statistical distribution of the forecast accuracy at various\nstages of project development, and benchmarked the projects against a sample of\n863 similar projects. The study contributed to the understanding of how to\nimprove forecasts by de-biasing early estimates, explicitly considering the\nrisk appetite of decision makers, and safeguarding public funding allocation by\nbalancing exceedance and under-use of project budgets.\n", "versions": [{"version": "v1", "created": "Tue, 3 Oct 2017 13:37:40 GMT"}], "update_date": "2017-10-27", "authors_parsed": [["Flyvbjerg", "Bent", ""], ["Hon", "Chi-keung", ""], ["Fok", "Wing Huen", ""]]}, {"id": "1710.09678", "submitter": "Bent Flyvbjerg", "authors": "Bent Flyvbjerg and J. Rodney Turner", "title": "Do Classics Exist in Megaproject Management?", "comments": null, "journal-ref": null, "doi": "10.1016/j.ijproman.2017.07.006", "report-no": null, "categories": "q-fin.GN q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper asks, \"Do classics exist in megaproject management?\" We identify\nthree types of classic texts: conventional, Kuhnian, and citation classics. We\nfind that the answer to our question depends on the definition of \"classic\"\nemployed. First, \"citation classics\" do exist in megaproject management, and\nthey perform remarkably well when compared to the rest of the management\nliterature. A preliminary Top Ten of citation classics is presented. Second,\nthere is no indication that \"conventional classics\" exist in megaproject\nmanagement, i.e., texts recognized as definitive by a majority of experts.\nThird, there is also no consensus as to whether \"Kuhnian classics\" exist, i.e.,\ntexts with paradigmatic clout. The importance of classics seems to be accepted,\nhowever, just as work to develop, discuss, and consolidate classics is seen as\nessential by megaproject scholars. A set of guidelines is presented for\ndeveloping classics in megaproject management research.\n", "versions": [{"version": "v1", "created": "Wed, 6 Sep 2017 20:33:15 GMT"}], "update_date": "2017-10-27", "authors_parsed": [["Flyvbjerg", "Bent", ""], ["Turner", "J. Rodney", ""]]}, {"id": "1710.10143", "submitter": "Mika J. Straka", "authors": "Mika J. Straka, Guido Caldarelli, Tiziano Squartini, Fabio Saracco", "title": "From Ecology to Finance (and Back?): Recent Advancements in the Analysis\n  of Bipartite Networks", "comments": "26 pages, 12 Figures", "journal-ref": "J. Stat. Phys. (2018)", "doi": "10.1007/s10955-018-2039-4", "report-no": null, "categories": "physics.soc-ph q-bio.PE q-fin.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bipartite networks provide an insightful representation of many systems,\nranging from mutualistic networks of species interactions to investment\nnetworks in finance. The analysis of their topological structures has revealed\nthe ubiquitous presence of properties which seem to characterize many -\napparently different - systems. Nestedness, for example, has been observed in\nplants-pollinator as well as in country-product trade networks. This has raised\nquestions about the significance of these patterns, which are often believed to\nconstitute a genuine signature of self-organization. Here, we review several\nmethods that have been developed for the analysis of such evidence. Due to the\ninterdisciplinary character of complex networks, tools developed in one field,\nfor example ecology, can greatly enrich other areas of research, such as\neconomy and finance, and vice versa. With this in mind, we briefly review\nseveral entropy-based bipartite null models that have been recently proposed\nand discuss their application to several real-world systems. The focus on these\nmodels is motivated by the fact that they show three very desirable features:\nanalytical character, general applicability and versatility. In this respect,\nentropy-based methods have been proven to perform satisfactorily both in\nproviding benchmarks for testing evidence-based null hypotheses and in\nreconstructing unknown network configurations from partial information. On top\nof that, entropy-based models have been successfully employed to analyze\necological as well as economic systems, thus representing an ideal,\ninterdisciplinary tool to approach the study of bipartite complex systems.\n[...]\n", "versions": [{"version": "v1", "created": "Fri, 27 Oct 2017 14:12:00 GMT"}], "update_date": "2018-07-20", "authors_parsed": [["Straka", "Mika J.", ""], ["Caldarelli", "Guido", ""], ["Squartini", "Tiziano", ""], ["Saracco", "Fabio", ""]]}, {"id": "1710.10377", "submitter": "Gavin K. Brennen", "authors": "Divesh Aggarwal, Gavin K. Brennen, Troy Lee, Miklos Santha, Marco\n  Tomamichel", "title": "Quantum attacks on Bitcoin, and how to protect against them", "comments": "21 pages, 6 figures. For a rough update on the progress of Quantum\n  devices and prognostications on time from now to break Digital signatures,\n  see https://www.quantumcryptopocalypse.com/quantum-moores-law/", "journal-ref": "Ledger, [S.l.], v. 3, oct. 2018", "doi": "10.5195/ledger.2018.127", "report-no": null, "categories": "quant-ph q-fin.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The key cryptographic protocols used to secure the internet and financial\ntransactions of today are all susceptible to attack by the development of a\nsufficiently large quantum computer. One particular area at risk are\ncryptocurrencies, a market currently worth over 150 billion USD. We investigate\nthe risk of Bitcoin, and other cryptocurrencies, to attacks by quantum\ncomputers. We find that the proof-of-work used by Bitcoin is relatively\nresistant to substantial speedup by quantum computers in the next 10 years,\nmainly because specialized ASIC miners are extremely fast compared to the\nestimated clock speed of near-term quantum computers. On the other hand, the\nelliptic curve signature scheme used by Bitcoin is much more at risk, and could\nbe completely broken by a quantum computer as early as 2027, by the most\noptimistic estimates. We analyze an alternative proof-of-work called Momentum,\nbased on finding collisions in a hash function, that is even more resistant to\nspeedup by a quantum computer. We also review the available post-quantum\nsignature schemes to see which one would best meet the security and efficiency\nrequirements of blockchain applications.\n", "versions": [{"version": "v1", "created": "Sat, 28 Oct 2017 03:02:11 GMT"}], "update_date": "2020-06-07", "authors_parsed": [["Aggarwal", "Divesh", ""], ["Brennen", "Gavin K.", ""], ["Lee", "Troy", ""], ["Santha", "Miklos", ""], ["Tomamichel", "Marco", ""]]}]