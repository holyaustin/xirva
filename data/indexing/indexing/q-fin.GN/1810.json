[{"id": "1810.01310", "submitter": "Oleg Yu Vorobyev", "authors": "Oleg Yu Vorobyev", "title": "The logic of uncertainty as a logic of experience and chance and the\n  co~event-based Bayes' theorem", "comments": null, "journal-ref": "Proc. of the XVI Intern. FAMEMS Conf. on Financial and Actuarial\n  Mathematics and Eventology of Multivariate Statistics and the II Workshop on\n  Hilbert's Sixth Problem; Krasnoyarsk, SFU (Oleg Vorobyev ed.), 92-110, 2017", "doi": null, "report-no": null, "categories": "q-fin.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The logic of uncertainty is not the logic of experience and as well as it is\nnot the logic of chance. It is the logic of experience and chance. Experience\nand chance are two inseparable poles. These are two dual reflections of one\nessence, which is called co~event. The theory of experience and chance is the\ntheory of co~events. To study the co~events, it is not enough to study the\nexperience and to study the chance. For this, it is necessary to study the\nexperience and chance as a single entire, a co~event. In other words, it is\nnecessary to study their interaction within a co~event. The new co~event\naxiomatics and the theory of co~events following from it were created precisely\nfor these purposes. In this work, I am going to demonstrate the effectiveness\nof the new theory of co~events in a studying the logic of uncertainty. I will\ndo this by the example of a co~event splitting of the logic of the Bayesian\nscheme, which has a long history of fierce debates between Bayesianists and\nfrequentists. I hope the logic of the theory of experience and chance will make\nits modest contribution to the application of these old dual debaters.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 00:42:37 GMT"}], "update_date": "2018-10-03", "authors_parsed": [["Vorobyev", "Oleg Yu", ""]]}, {"id": "1810.02125", "submitter": "Adriano Koshiyama", "authors": "Adriano Soares Koshiyama, Nick Firoozye and Philip Treleaven", "title": "A Machine Learning-based Recommendation System for Swaptions Strategies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PM cs.LG q-fin.GN stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Derivative traders are usually required to scan through hundreds, even\nthousands of possible trades on a daily basis. Up to now, not a single solution\nis available to aid in their job. Hence, this work aims to develop a trading\nrecommendation system, and apply this system to the so-called Mid-Curve\nCalendar Spread (MCCS), an exotic swaption-based derivatives package. In\nsummary, our trading recommendation system follows this pipeline: (i) on a\ncertain trade date, we compute metrics and sensitivities related to an MCCS;\n(ii) these metrics are feed in a model that can predict its expected return for\na given holding period; and after repeating (i) and (ii) for all trades we\n(iii) rank the trades using some dominance criteria. To suggest that such\napproach is feasible, we used a list of 35 different types of MCCS; a total of\n11 predictive models; and 4 benchmark models. Our results suggest that in\ngeneral linear regression with lasso regularisation compared favourably to\nother approaches from a predictive and interpretability perspective.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 09:55:40 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Koshiyama", "Adriano Soares", ""], ["Firoozye", "Nick", ""], ["Treleaven", "Philip", ""]]}, {"id": "1810.02444", "submitter": "Alex Garivaltis", "authors": "Alex Garivaltis", "title": "Super-Replication of the Best Pairs Trade in Hindsight", "comments": "22 pages, 1 figure", "journal-ref": "Cogent Economics & Finance (2019), 7: 1568657", "doi": null, "report-no": null, "categories": "q-fin.PM econ.GN econ.TH q-fin.EC q-fin.GN q-fin.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper derives a robust on-line equity trading algorithm that achieves\nthe greatest possible percentage of the final wealth of the best pairs\nrebalancing rule in hindsight. A pairs rebalancing rule chooses some pair of\nstocks in the market and then perpetually executes rebalancing trades so as to\nmaintain a target fraction of wealth in each of the two. After each discrete\nmarket fluctuation, a pairs rebalancing rule will sell a precise amount of the\noutperforming stock and put the proceeds into the underperforming stock. Under\ntypical conditions, in hindsight one can find pairs rebalancing rules that\nwould have spectacularly beaten the market. Our trading strategy, which extends\nOrdentlich and Cover's (1998) \"max-min universal portfolio,\" guarantees to\nachieve an acceptable percentage of the hindsight-optimized wealth, a\npercentage which tends to zero at a slow (polynomial) rate. This means that on\na long enough investment horizon, the trader can enforce a compound-annual\ngrowth rate that is arbitrarily close to that of the best pairs rebalancing\nrule in hindsight. The strategy will \"beat the market asymptotically\" if there\nturns out to exist a pairs rebalancing rule that grows capital at a higher\nasymptotic rate than the market index. The advantages of our algorithm over the\nOrdentlich and Cover (1998) strategy are twofold. First, their strategy is\nimpossible to compute in practice. Second, in considering the more modest\nbenchmark (instead of the best all-stock rebalancing rule in hindsight), we\nreduce the \"cost of universality\" and achieve a higher learning rate.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 22:30:01 GMT"}, {"version": "v2", "created": "Wed, 17 Oct 2018 21:44:08 GMT"}, {"version": "v3", "created": "Thu, 14 Mar 2019 21:18:41 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Garivaltis", "Alex", ""]]}, {"id": "1810.02447", "submitter": "Alex Garivaltis", "authors": "Alex Garivaltis", "title": "Multilinear Superhedging of Lookback Options", "comments": "41 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PR econ.TH q-fin.CP q-fin.GN q-fin.PM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a pathbreaking paper, Cover and Ordentlich (1998) solved a max-min\nportfolio game between a trader (who picks an entire trading algorithm,\n$\\theta(\\cdot)$) and \"nature,\" who picks the matrix $X$ of gross-returns of all\nstocks in all periods. Their (zero-sum) game has the payoff kernel\n$W_\\theta(X)/D(X)$, where $W_\\theta(X)$ is the trader's final wealth and $D(X)$\nis the final wealth that would have accrued to a $\\$1$ deposit into the best\nconstant-rebalanced portfolio (or fixed-fraction betting scheme) determined in\nhindsight. The resulting \"universal portfolio\" compounds its money at the same\nasymptotic rate as the best rebalancing rule in hindsight, thereby beating the\nmarket asymptotically under extremely general conditions. Smitten with this\n(1998) result, the present paper solves the most general tractable version of\nCover and Ordentlich's (1998) max-min game. This obtains for performance\nbenchmarks (read: derivatives) that are separately convex and homogeneous in\neach period's gross-return vector. For completely arbitrary (even\nnon-measurable) performance benchmarks, we show how the axiom of choice can be\nused to \"find\" an exact maximin strategy for the trader.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 22:50:42 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Garivaltis", "Alex", ""]]}, {"id": "1810.04623", "submitter": "Giovanni Taglialatela Dr.", "authors": "Michele Mininni, Giuseppe Orlando, Giovanni Taglialatela", "title": "Challenges in approximating the Black and Scholes call formula with\n  hyperbolic tangents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce the concept of standardized call function and we\nobtain a new approximating formula for the Black and Scholes call function\nthrough the hyperbolic tangent. This formula is useful for pricing and risk\nmanagement as well as for extracting the implied volatility from quoted\noptions. The latter is of particular importance since it indicates the risk of\nthe underlying and it is the main component of the option's price. Further we\nestimate numerically the approximating error of the suggested solution and, by\ncomparing our results in computing the implied volatility with the most common\nmethods available in literature we discuss the challenges of this approach.\n", "versions": [{"version": "v1", "created": "Thu, 20 Sep 2018 11:11:18 GMT"}], "update_date": "2018-10-11", "authors_parsed": [["Mininni", "Michele", ""], ["Orlando", "Giuseppe", ""], ["Taglialatela", "Giovanni", ""]]}, {"id": "1810.04624", "submitter": "Jorge Rosenblatt JR", "authors": "J. Rosenblatt (Institut National de Sciences Appliqu\\'ees, Rennes,\n  France)", "title": "Symmetry, Entropy, Diversity and (why not?) Quantum Statistics in\n  Society", "comments": "13 pages, 2 figures", "journal-ref": null, "doi": "10.3390/e21020144", "report-no": null, "categories": "q-fin.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe society as a nonequilibrium probabilistic system: N individuals\noccupy W resource states in it and produce entropy S over definite time\nperiods. Resulting thermodynamics is however unusual because a second entropy,\nH, measures a typically social feature, inequality or diversity in the\ndistribution of available resources. A symmetry phase transition takes place at\nGini values 1/3, where realistic distributions become asymmetric. Four\nconstraints act on S: expectedly, N and W, and new ones, diversity and\ninteractions between individuals; the latter result from the two coordinates of\na single point in the data, the peak. The occupation number of a job is either\nzero or one, suggesting Fermi-Dirac statistics for employment. Contrariwise, an\nindefinite nujmber of individuals can occupy a state defined as a quantile of\nincome or of age, so Bose-Einstein statistics may be required.\nIndistinguishability rather than anonymity of individuals and resources is thus\nneeded. Interactions between individuals define define classes of equivalence\nthat happen to coincide with acceptable definitions of social classes or\nperiods in human life. The entropy S is non-extensive and obtainable from data.\nTheoretical laws are compared to data in four different cases of economical or\nphysiological diversity. Acceptable fits are found for all of them.\n", "versions": [{"version": "v1", "created": "Sat, 22 Sep 2018 00:00:20 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Rosenblatt", "J.", "", "Institut National de Sciences Appliqu\u00e9es, Rennes,\n  France"]]}, {"id": "1810.07178", "submitter": "Pierre Gosselin", "authors": "A\\\"ileen Lotz, Pierre Gosselin (IF), Marc Wambst (IRMA)", "title": "A Path Integral Approach to Business Cycle Models with Large Number of\n  Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.GN cond-mat.stat-mech q-fin.EC q-fin.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an analytical treatment of economic systems with an\narbitrary number of agents that keeps track of the systems' interactions and\nagents' complexity. This formalism does not seek to aggregate agents. It rather\nreplaces the standard optimization approach by a probabilistic description of\nboth the entire system and agents'behaviors. This is done in two distinct\nsteps. A first step considers an interacting system involving an arbitrary\nnumber of agents, where each agent's utility function is subject to\nunpredictable shocks. In such a setting, individual optimization problems need\nnot be resolved. Each agent is described by a time-dependent probability\ndistribution centered around his utility optimum. The entire system of agents\nis thus defined by a composite probability depending on time, agents'\ninteractions and forward-looking behaviors. This dynamic system is described by\na path integral formalism in an abstract space-the space of the agents'\nactions-and is very similar to a statistical physics or quantum mechanics\nsystem. We show that this description, applied to the space of agents'actions,\nreduces to the usual optimization results in simple cases. Compared to a\nstandard optimization, such a description markedly eases the treatment of\nsystems with small number of agents. It becomes however useless for a large\nnumber of agents. In a second step therefore, we show that for a large number\nof agents, the previous description is equivalent to a more compact description\nin terms of field theory. This yields an analytical though approximate\ntreatment of the system. This field theory does not model the aggregation of a\nmicroeconomic system in the usual sense. It rather describes an environment of\na large number of interacting agents. From this description, various phases or\nequilibria may be retrieved, along with individual agents' behaviors and their\ninteractions with the environment. For illustrative purposes, this paper\nstudies a Business Cycle model with a large number of agents.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 10:03:35 GMT"}], "update_date": "2018-10-18", "authors_parsed": [["Lotz", "A\u00efleen", "", "IF"], ["Gosselin", "Pierre", "", "IF"], ["Wambst", "Marc", "", "IRMA"]]}, {"id": "1810.07690", "submitter": "Roman Orus", "authors": "Roman Orus, Samuel Mugel, Enrique Lizaso", "title": "Forecasting financial crashes with quantum computing", "comments": "6 pages, 4 figures, revised version. To appear in PRA", "journal-ref": "Phys. Rev. A 99, 060301 (2019)", "doi": "10.1103/PhysRevA.99.060301", "report-no": null, "categories": "q-fin.GN quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key problem in financial mathematics is the forecasting of financial\ncrashes: if we perturb asset prices, will financial institutions fail on a\nmassive scale? This was recently shown to be a computationally intractable\n(NP-hard) problem. Financial crashes are inherently difficult to predict, even\nfor a regulator which has complete information about the financial system. In\nthis paper we show how this problem can be handled by quantum annealers. More\nspecifically, we map the equilibrium condition of a toy-model financial network\nto the ground-state problem of a spin-1/2 quantum Hamiltonian with 2-body\ninteractions, i.e., a quadratic unconstrained binary optimization (QUBO)\nproblem. The equilibrium market values of institutions after a sudden shock to\nthe network can then be calculated via adiabatic quantum computation and, more\ngenerically, by quantum annealers. Our procedure could be implemented on\nnear-term quantum processors, thus providing a potentially more efficient way\nto assess financial equilibrium and predict financial crashes.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 18:08:51 GMT"}, {"version": "v2", "created": "Sat, 22 Jun 2019 06:48:07 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Orus", "Roman", ""], ["Mugel", "Samuel", ""], ["Lizaso", "Enrique", ""]]}, {"id": "1810.07774", "submitter": "James McNerney", "authors": "James McNerney, Charles Savoie, Francesco Caravelli, J. Doyne Farmer", "title": "How production networks amplify economic growth", "comments": "41 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.GN physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Technological improvement is the most important cause of long-term economic\ngrowth, but the factors that drive it are still not fully understood. In\nstandard growth models technology is treated in the aggregate, and a main goal\nhas been to understand how growth depends on factors such as knowledge\nproduction. But an economy can also be viewed as a network, in which producers\npurchase goods, convert them to new goods, and sell them to households or other\nproducers. Here we develop a simple theory that shows how the network\nproperties of an economy can amplify the effects of technological improvements\nas they propagate along chains of production. A key property of an industry is\nits output multiplier, which can be understood as the average number of\nproduction steps required to make a good. The model predicts that the output\nmultiplier of an industry predicts future changes in prices, and that the\naverage output multiplier of a country predicts future economic growth. We test\nthese predictions using data from the World Input Output Database and find\nresults in good agreement with the model. The results show how purely\nstructural properties of an economy, that have nothing to do with innovation or\nhuman creativity, can exert an important influence on long-term growth.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 20:25:10 GMT"}], "update_date": "2018-10-19", "authors_parsed": [["McNerney", "James", ""], ["Savoie", "Charles", ""], ["Caravelli", "Francesco", ""], ["Farmer", "J. Doyne", ""]]}, {"id": "1810.07783", "submitter": "Mingyu Joo", "authors": "Rex Yuxing Du, Mingyu Joo, Kenneth C. Wilbur", "title": "Advertising and Brand Attitudes: Evidence from 575 Brands over Five\n  Years", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Little is known about how different types of advertising affect brand\nattitudes. We investigate the relationships between three brand attitude\nvariables (perceived quality, perceived value and recent satisfaction) and\nthree types of advertising (national traditional, local traditional and\ndigital). The data represent ten million brand attitude surveys and $264\nbillion spent on ads by 575 regular advertisers over a five-year period,\napproximately 37% of all ad spend measured between 2008 and 2012. Inclusion of\nbrand/quarter fixed effects and industry/week fixed effects brings parameter\nestimates closer to expectations without major reductions in estimation\nprecision. The findings indicate that (i) national traditional ads increase\nperceived quality, perceived value, and recent satisfaction; (ii) local\ntraditional ads increase perceived quality and perceived value; (iii) digital\nads increase perceived value; and (iv) competitor ad effects are generally\nnegative.\n", "versions": [{"version": "v1", "created": "Tue, 4 Sep 2018 20:29:13 GMT"}], "update_date": "2018-10-19", "authors_parsed": [["Du", "Rex Yuxing", ""], ["Joo", "Mingyu", ""], ["Wilbur", "Kenneth C.", ""]]}, {"id": "1810.08330", "submitter": "Inho Hong", "authors": "Inho Hong, Morgan R. Frank, Iyad Rahwan, Woo-Sung Jung, Hyejin Youn", "title": "A common trajectory recapitulated by urban economies", "comments": null, "journal-ref": "Science Advances 6, eaba4934 (2020)", "doi": "10.1126/sciadv.aba4934", "report-no": null, "categories": "physics.soc-ph q-fin.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Is there a general economic pathway recapitulated by individual cities over\nand over? Identifying such evolution structure, if any, would inform models for\nthe assessment, maintenance, and forecasting of urban sustainability and\neconomic success as a quantitative baseline. This premise seems to contradict\nthe existing body of empirical evidences for path-dependent growth shaping the\nunique history of individual cities. And yet, recent empirical evidences and\ntheoretical models have amounted to the universal patterns, mostly\nsize-dependent, thereby expressing many of urban quantities as a set of simple\nscaling laws. Here, we provide a mathematical framework to integrate repeated\ncross-sectional data, each of which freezes in time dimension, into a frame of\nreference for longitudinal evolution of individual cities in time. Using data\nof over 100 millions employment in thousand business categories between 1998\nand 2013, we decompose each city's evolution into a pre-factor and relative\nchanges to eliminate national and global effects. In this way, we show the\nlongitudinal dynamics of individual cities recapitulate the observed\ncross-sectional regularity. Larger cities are not only scaled-up versions of\ntheir smaller peers but also of their past. In addition, our model shows that\nboth specialization and diversification are attributed to the distribution of\nindustry's scaling exponents, resulting a critical population of 1.2 million at\nwhich a city makes an industrial transition into innovative economies.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 01:34:56 GMT"}], "update_date": "2020-08-27", "authors_parsed": [["Hong", "Inho", ""], ["Frank", "Morgan R.", ""], ["Rahwan", "Iyad", ""], ["Jung", "Woo-Sung", ""], ["Youn", "Hyejin", ""]]}, {"id": "1810.08495", "submitter": "Peter Bank", "authors": "Peter Bank and David Besslich", "title": "Modelling information flows by Meyer-$\\sigma$-fields in the singular\n  stochastic control problem of irreversible investment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC math.PR q-fin.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In stochastic control problems delicate issues arise when the controlled\nsystem can jump due to both exogenous shocks and endogenous controls. Here one\nhas to specify what the controller knows when about the exogenous shocks and\nhow and when she can act on this information. We propose to use\nMeyer-$\\sigma$-fields as a flexible tool to model information flow in such\nsituations. The possibilities of this approach are illustrated first in a very\nsimple linear stochastic control problem and then in a fairly general\nformulation for the singular stochastic control problem of irreversible\ninvestment with inventory risk. For the latter, we illustrate in a first case\nstudy how different signals on exogenous jumps lead to different optimal\ncontrols, interpolating between the predictable and the optional case in a\nsystematic manner.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 13:36:09 GMT"}, {"version": "v2", "created": "Fri, 8 Nov 2019 12:50:40 GMT"}, {"version": "v3", "created": "Wed, 25 Mar 2020 10:26:41 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Bank", "Peter", ""], ["Besslich", "David", ""]]}, {"id": "1810.10970", "submitter": "Roland Ramsahai", "authors": "Roland R. Ramsahai", "title": "Defining and estimating stochastic rate change in a dynamic general\n  insurance portfolio", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PM q-fin.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rate change calculations in the literature involve deterministic methods that\nmeasure the change in premium for a given policy. The definition of rate change\nas a statistical parameter is proposed to address the stochastic nature of the\npremium charged for a policy. It promotes the idea that rate change is a\nproperty of an asymptotic population to be estimated, not just a property to\nmeasure or monitor in the sample of observed policies that are written. Various\nmodels and techniques are given for estimating this stochastic rate change and\nquantifying the uncertainty in the estimates. The use of matched sampling is\nemphasized for rate change estimation, as it adjusts for changes in policy\ncharacteristics by directly searching for similar policies across policy years.\nThis avoids any of the assumptions and recipes that are required to re-rate\npolicies in years where they were not written, as is common with deterministic\nmethods. Such procedures can be subjective or implausible if the structure of\nrating algorithms change or there are complex and heterogeneous exposure bases\nand coverages. The methods discussed are applied to a motor premium database.\nThe application includes the use of a genetic algorithm with parallel\ncomputations to automatically optimize the matched sampling.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 19:20:08 GMT"}], "update_date": "2018-10-26", "authors_parsed": [["Ramsahai", "Roland R.", ""]]}, {"id": "1810.11458", "submitter": "Alvaro Gonzalez-Castellanos", "authors": "Alvaro Gonzalez-Castellanos, David Pozo, Sergio Martinez, Luis Lopez,\n  Ingrid Oliveros", "title": "Economic Impact of Wind Generation Penetration in the Colombian\n  Electricity Market", "comments": "This paper is a preprint of a paper submitted to \"IET Generation,\n  Transmission & Distribution\". If accepted, the copy of record will be\n  available at the IET Digital Library", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The creation of the Renewable Energy Law (Law 1715 of 2014) promotes the\nintroduction of large-scale renewable energy generation in the Colombian\nelectricity market. The new legislation aims to diversify the country's\ngeneration matrix, mainly composed of hydro and fuel-based generation, with a\nshare of 66% and 34% respectively. Currently, three wind generation projects,\nwith an aggregated capacity of 500 MW, have been commissioned in the North of\nthe country. This study analyses the economic impact of the large-scale\nintroduction of wind generation on both, the market spot price and conventional\ngeneration plants operation. For this purpose, the study builds a unit\ncommitment model to mimic the current market legislation and the system's\ngeneration data. We show that the introduction of wind energy into the\nColombian electricity market would impact the generation share of large hydro\nand gas-fired power plants. The hydro generation has an important role in\nbalancing the generation for fluctuations on the wind resource. Meanwhile, the\ngas-fired plants would decrease their participation in the market,\nproportionally to the introduction of wind generation in the system, by as low\nas 20% of its current operation.\n", "versions": [{"version": "v1", "created": "Sun, 28 Oct 2018 12:38:08 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Gonzalez-Castellanos", "Alvaro", ""], ["Pozo", "David", ""], ["Martinez", "Sergio", ""], ["Lopez", "Luis", ""], ["Oliveros", "Ingrid", ""]]}, {"id": "1810.12022", "submitter": "Jozef Barunik", "authors": "Jozef Barunik and Mattia Bevilacqua and Radu Tunaru", "title": "Asymmetric Network Connectedness of Fears", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces forward-looking measures of the network connectedness\nof fears in the financial system, arising due to the good and bad beliefs of\nmarket participants about uncertainty that spreads unequally across a network\nof banks. We argue that this asymmetric network structure extracted from call\nand put traded option prices of the main U.S. banks contains valuable\ninformation for predicting macroeconomic conditions and economic uncertainty,\nand it can serve as a tool for forward-looking systemic risk monitoring.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 09:33:44 GMT"}, {"version": "v2", "created": "Mon, 26 Oct 2020 14:38:15 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Barunik", "Jozef", ""], ["Bevilacqua", "Mattia", ""], ["Tunaru", "Radu", ""]]}, {"id": "1810.12200", "submitter": "Juho Kanniainen", "authors": "Juho Kanniainen and Martin Magris", "title": "Option market (in)efficiency and implied volatility dynamics after\n  return jumps", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST q-fin.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In informationally efficient financial markets, option prices and this\nimplied volatility should immediately be adjusted to new information that\narrives along with a jump in underlying's return, whereas gradual changes in\nimplied volatility would indicate market inefficiency. Using minute-by-minute\ndata on S&P 500 index options, we provide evidence regarding delayed and\ngradual movements in implied volatility after the arrival of return jumps.\nThese movements are directed and persistent, especially in the case of negative\nreturn jumps. Our results are significant when the implied volatilities are\nextracted from at-the-money options and out-of-the-money puts, while the\nimplied volatility obtained from out-of-the-money calls converges to its new\nlevel immediately rather than gradually. Thus, our analysis reveals that the\nimplied volatility smile is adjusted to jumps in underlying's return\nasymmetrically. Finally, it would be possible to have statistical arbitrage in\nzero-transaction-cost option markets, but under actual option price spreads,\nour results do not imply abnormal option returns.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 15:41:37 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Kanniainen", "Juho", ""], ["Magris", "Martin", ""]]}, {"id": "1810.12840", "submitter": "Ricardo Fernholz", "authors": "Ricardo T. Fernholz and Caleb Stroup", "title": "Asset Price Distributions and Efficient Markets", "comments": "45 pages, 6 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PM q-fin.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore a decomposition in which returns on a large class of portfolios\nrelative to the market depend on a smooth non-negative drift and changes in the\nasset price distribution. This decomposition is obtained using general\ncontinuous semimartingale price representations, and is thus consistent with\nvirtually any asset pricing model. Fluctuations in portfolio relative returns\ndepend on stochastic time-varying dispersion in asset prices. Thus, our\nframework uncovers an asset pricing factor whose existence emerges from an\naccounting identity universal across different economic and financial\nenvironments, a fact that has deep implications for market efficiency. In\nparticular, in a closed, dividend-free market in which asset price dispersion\nis relatively constant, a large class of portfolios must necessarily outperform\nthe market portfolio over time. We show that price dispersion in commodity\nfutures markets has increased only slightly, and confirm the existence of\nsubstantial excess returns that co-vary with changes in price dispersion as\npredicted by our theory.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 16:27:49 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Fernholz", "Ricardo T.", ""], ["Stroup", "Caleb", ""]]}, {"id": "1810.13250", "submitter": "Rosanna Grassi", "authors": "Roy Cerqueti, Gian Paolo Clemente, Rosanna Grassi", "title": "Systemic risk assessment through high order clustering coefficient", "comments": "Submitted", "journal-ref": "ANNALS OF OPERATIONS RESEARCH 2020", "doi": "10.1007/s10479-020-03525-8", "report-no": null, "categories": "physics.soc-ph q-fin.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we propose a novel measure of systemic risk in the context of\nfinancial networks. To this aim, we provide a definition of systemic risk which\nis based on the structure, developed at different levels, of clustered\nneighbours around the nodes of the network. The proposed measure incorporates\nthe generalized concept of clustering coefficient of order $l$ of a node $i$\nintroduced in Cerqueti et al. (2018). Its properties are also explored in terms\nof systemic risk assessment. Empirical experiments on the time-varying global\nbanking network show the effectiveness of the presented systemic risk measure\nand provide insights on how systemic risk has changed over the last years, also\nin the light of the recent financial crisis and the subsequent more stringent\nregulation for globally systemically important banks.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 12:33:41 GMT"}, {"version": "v2", "created": "Wed, 29 Jul 2020 12:09:35 GMT"}], "update_date": "2020-07-30", "authors_parsed": [["Cerqueti", "Roy", ""], ["Clemente", "Gian Paolo", ""], ["Grassi", "Rosanna", ""]]}]