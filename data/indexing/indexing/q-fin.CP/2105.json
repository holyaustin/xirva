[{"id": "2105.00655", "submitter": "Marco Bianchetti", "authors": "Riccardo Aiolfi, Nicola Moreni, Marco Bianchetti, Marco Scaringi,\n  Filippo Fogliani", "title": "Learning Bermudans", "comments": "24 pages, 6 figures, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PR q-fin.CP", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  American and Bermudan-type financial instruments are often priced with\nspecific Monte Carlo techniques whose efficiency critically depends on the\neffective dimensionality of the problem and the available computational power.\nIn our work we focus on Bermudan Swaptions, well-known interest rate\nderivatives embedded in callable debt instruments or traded in the OTC market\nfor hedging or speculation purposes, and we adopt an original pricing approach\nbased on Supervised Learning (SL) algorithms. In particular, we link the price\nof a Bermudan Swaption to its natural hedges, i.e. the underlying European\nSwaptions, and other sound financial quantities through SL non-parametric\nregressions. We test different algorithms, from linear models to decision\ntree-based models and Artificial Neural Networks (ANN), analyzing their\npredictive performances. All the SL algorithms result to be reliable and fast,\nallowing to overcome the computational bottleneck of standard Monte Carlo\nsimulations; the best performing algorithms for our problem result to be Ridge,\nANN and Gradient Boosted Regression Tree. Moreover, using feature importance\ntechniques, we are able to rank the most important driving factors of a\nBermudan Swaption price, confirming that the value of the maximum underlying\nEuropean Swaption is the prevailing feature.\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2021 07:12:51 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Aiolfi", "Riccardo", ""], ["Moreni", "Nicola", ""], ["Bianchetti", "Marco", ""], ["Scaringi", "Marco", ""], ["Fogliani", "Filippo", ""]]}, {"id": "2105.00778", "submitter": "Christian Bayer", "authors": "Christian Bayer and Paul Hager and Sebastian Riedel and John\n  Schoenmakers", "title": "Optimal stopping with signatures", "comments": "39 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new method for solving optimal stopping problems (such as\nAmerican option pricing in finance) under minimal assumptions on the underlying\nstochastic process $X$.\n  We consider classic and randomized stopping times represented by linear and\nnon-linear functionals of the rough path signature $\\mathbb{X}^{<\\infty}$\nassociated to $X$, and prove that maximizing over these classes of signature\nstopping times, in fact, solves the original optimal stopping problem. Using\nthe algebraic properties of the signature, we can then recast the problem as a\n(deterministic) optimization problem depending only on the (truncated) expected\nsignature $\\mathbb{E}\\left[ \\mathbb{X}^{\\le N}_{0,T} \\right]$. By applying a\ndeep neural network approach to approximate the non-linear signature\nfunctionals, we can efficiently solve the optimal stopping problem numerically.\n  The only assumption on the process $X$ is that it is a continuous (geometric)\nrandom rough path. Hence, the theory encompasses processes such as fractional\nBrownian motion, which fail to be either semi-martingales or Markov processes,\nand can be used, in particular, for American-type option pricing in fractional\nmodels, e.g. on financial or electricity markets.\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2021 12:34:06 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Bayer", "Christian", ""], ["Hager", "Paul", ""], ["Riedel", "Sebastian", ""], ["Schoenmakers", "John", ""]]}, {"id": "2105.02211", "submitter": "Ivan Jericevich", "authors": "Ivan Jericevich and Patrick Chang and Tim Gebbie", "title": "Simulation and estimation of a point-process market-model with a\n  matching engine", "comments": "19 pages, 33 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.TR q-fin.CP stat.CO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The extent to which a matching engine can cloud the modelling of underlying\norder submission and management processes in a financial market remains an\nunanswered concern with regards to market models. Here we consider a 10-variate\nHawkes process with simple rules to simulate common order types which are\nsubmitted to a matching engine. Hawkes processes can be used to model the time\nand order of events, and how these events relate to each other. However, they\nprovide a freedom with regards to implementation mechanics relating to the\nprices and volumes of injected orders. This allows us to consider a reference\nHawkes model and two additional models which have rules that change the\nbehaviour of limit orders. The resulting trade and quote data from the\nsimulations are then calibrated and compared with the original order generating\nprocess to determine the extent with which implementation rules can distort\nmodel parameters. Evidence from validation and hypothesis tests suggest that\nthe true model specification can be significantly distorted by market\nmechanics, and that practical considerations not directly due to model\nspecification can be important with regards to model identification within an\ninherently asynchronous trading environment.\n", "versions": [{"version": "v1", "created": "Wed, 5 May 2021 17:38:27 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Jericevich", "Ivan", ""], ["Chang", "Patrick", ""], ["Gebbie", "Tim", ""]]}, {"id": "2105.03071", "submitter": "Piergiacomo Sabino Dr", "authors": "Piergiacomo Sabino", "title": "Normal Tempered Stable Processes and the Pricing of Energy Derivatives", "comments": "27 pages, 3 figures. arXiv admin note: text overlap with\n  arXiv:2103.13252", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP math.PR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this study we consider the pricing of energy derivatives when the\nevolution of spot prices is modeled with a normal tempered stable driven\nOrnstein-Uhlenbeck process. Such processes are the generalization of normal\ninverse Gaussian processes that are widely used in energy finance applications.\nWe first specify their statistical properties calculating their characteristic\nfunction in closed form. This result is instrumental for the derivation of\nnon-arbitrage conditions such that the spot dynamics is consistent with the\nforward curve without relying on numerical approximations or on numerical\nintegration. Moreover, we conceive an efficient algorithm for the exact\ngeneration of the trajectories which gives the possibility to implement Monte\nCarlo simulations without approximations or bias. We illustrate the\napplicability of the theoretical findings and the simulation algorithms in the\ncontext of the pricing of different contracts, namely, strips of daily call\noptions, Asian options with European style and swing options. Finally, we\npresent an extension to future markets.\n", "versions": [{"version": "v1", "created": "Fri, 7 May 2021 05:31:59 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Sabino", "Piergiacomo", ""]]}, {"id": "2105.03514", "submitter": "Abootaleb Shirvani", "authors": "Thilini Mahanama, Abootaleb Shirvani, and Svetlozar Rachev", "title": "Global Index on Financial Losses due to Crime in the United States", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM q-fin.CP q-fin.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Crime can have a volatile impact on investments. Despite the potential\nimportance of crime rates in investments, there are no indices dedicated to\nevaluating the financial impact of crime in the United States. As such, this\npaper presents an index-based insurance portfolio for crime in the United\nStates by utilizing the financial losses reported by the Federal Bureau of\nInvestigation for property crimes and cybercrimes. Our research intends to help\ninvestors envision risk exposure in our portfolio, gauge investment risk based\non their desired risk level, and hedge strategies for potential losses due to\neconomic crashes. Underlying the index, we hedge the investments by issuing\nmarketable European call and put options and providing risk budgets\n(diversifying risk to each type of crime). We find that real estate,\nransomware, and government impersonation are the main risk contributors. We\nthen evaluate the performance of our index to determine its resilience to\neconomic crisis. The unemployment rate potentially demonstrates a high systemic\nrisk on the portfolio compared to the economic factors used in this study. In\nconclusion, we provide a basis for the securitization of insurance risk from\ncertain crimes that could forewarn investors to transfer their risk to capital\nmarket investors.\n", "versions": [{"version": "v1", "created": "Fri, 7 May 2021 21:26:52 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Mahanama", "Thilini", ""], ["Shirvani", "Abootaleb", ""], ["Rachev", "Svetlozar", ""]]}, {"id": "2105.04511", "submitter": "Henrique Guerreiro", "authors": "Henrique Guerreiro and Jo\\~ao Guerra", "title": "Least squares Monte Carlo methods in stochastic Volterra rough\n  volatility models", "comments": "30 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PR q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In stochastic Volterra rough volatility models, the volatility follows a\ntruncated Brownian semi-stationary process with stochastic vol-of-vol.\nRecently, efficient VIX pricing Monte Carlo methods have been proposed for the\ncase where the vol-of-vol is Markovian and independent of the volatility.\nFollowing recent empirical data, we discuss the VIX option pricing problem for\na generalized framework of these models, where the vol-of-vol may depend on the\nvolatility and/or not be Markovian. In such a setting, the aforementioned Monte\nCarlo methods are not valid. Moreover, the classical least squares Monte Carlo\nfaces exponentially increasing complexity with the number of grid time steps,\nwhilst the nested Monte Carlo method requires a prohibitive number of\nsimulations. By exploring the infinite dimensional Markovian representation of\nthese models, we device a scalable least squares Monte Carlo for VIX option\npricing. We apply our method firstly under the independence assumption for\nbenchmarks, and then to the generalized framework. We also discuss the rough\nvol-of-vol setting, where Markovianity of the vol-of-vol is not present. We\npresent simulations and benchmarks to establish the efficiency of our method.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 17:03:22 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Guerreiro", "Henrique", ""], ["Guerra", "Jo\u00e3o", ""]]}, {"id": "2105.05356", "submitter": "Stefano De Marco", "authors": "Florian Bourgey and Stefano De Marco", "title": "Multilevel Monte Carlo simulation for VIX options in the rough Bergomi\n  model", "comments": "20 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP q-fin.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the pricing of VIX options in the rough Bergomi model [Bayer,\nFriz, and Gatheral, Pricing under rough volatility, Quantitative Finance 16(6),\n887-904, 2016]. In this setting, the VIX random variable is defined by the\none-dimensional integral of the exponential of a Gaussian process with\ncorrelated increments, hence approximate samples of the VIX can be constructed\nvia discretization of the integral and simulation of a correlated Gaussian\nvector. A Monte-Carlo estimator of VIX options based on a rectangle\ndiscretization scheme and exact Gaussian sampling via the Cholesky method has a\ncomputational complexity of order $\\mathcal O(\\varepsilon^{-4})$ when the\nmean-squared error is set to $\\varepsilon^2$. We demonstrate that this cost can\nbe reduced to $\\mathcal O(\\varepsilon^{-2} \\log^2(\\varepsilon))$ combining the\nscheme above with the multilevel method [Giles, Multilevel Monte Carlo path\nsimulation, Oper. Res. 56(3), 607-617, 2008], and further reduced to the\nasymptotically optimal cost $\\mathcal O(\\varepsilon^{-2})$ when using a\ntrapezoidal discretization. We provide numerical experiments highlighting the\nefficiency of the multilevel approach in the pricing of VIX options in such a\nrough forward variance setting.\n", "versions": [{"version": "v1", "created": "Tue, 11 May 2021 22:35:46 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Bourgey", "Florian", ""], ["De Marco", "Stefano", ""]]}, {"id": "2105.07061", "submitter": "Asif Lakhany", "authors": "Yuriy Krepkiy, Asif Lakhany and Amber Zhang", "title": "Efficient Least Squares Monte-Carlo Technique for PFE/EE Calculations", "comments": null, "journal-ref": null, "doi": null, "report-no": "ARPS 16-01", "categories": "q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a regression-based method, generally referred to as the Least\nSquares Monte Carlo (LSMC) method, to speed up exposure calculations of a\nportfolio. We assume that the portfolio contains several exotic derivatives\nthat are priced using Monte-Carlo on each real world scenario and time step.\nSuch a setting is often referred to as a Monte Carlo over a Monte Carlo or a\nNested Monte Carlo method.\n", "versions": [{"version": "v1", "created": "Fri, 14 May 2021 20:31:04 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Krepkiy", "Yuriy", ""], ["Lakhany", "Asif", ""], ["Zhang", "Amber", ""]]}, {"id": "2105.08133", "submitter": "Tim Leung", "authors": "Tim Leung and Theodore Zhao", "title": "Adaptive Complementary Ensemble EMD and Energy-Frequency Spectra of\n  Cryptocurrency Prices", "comments": "20 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST q-fin.CP stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the price dynamics of cryptocurrencies using adaptive complementary\nensemble empirical mode decomposition (ACE-EMD) and Hilbert spectral analysis.\nThis is a multiscale noise-assisted approach that decomposes any time series\ninto a number of intrinsic mode functions, along with the corresponding\ninstantaneous amplitudes and instantaneous frequencies. The decomposition is\nadaptive to the time-varying volatility of each cryptocurrency price evolution.\nDifferent combinations of modes allow us to reconstruct the time series using\ncomponents of different timescales. We then apply Hilbert spectral analysis to\ndefine and compute the instantaneous energy-frequency spectrum of each\ncryptocurrency to illustrate the properties of various timescales embedded in\nthe original time series.\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 19:53:45 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Leung", "Tim", ""], ["Zhao", "Theodore", ""]]}, {"id": "2105.08310", "submitter": "Dave Cliff", "authors": "Dave Cliff", "title": "BBE: Simulating the Microstructural Dynamics of an In-Play Betting\n  Exchange via Agent-Based Modelling", "comments": "47 pages, 9 figures, 120 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.CE q-fin.CP q-fin.TR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  I describe the rationale for, and design of, an agent-based simulation model\nof a contemporary online sports-betting exchange: such exchanges, closely\nrelated to the exchange mechanisms at the heart of major financial markets,\nhave revolutionized the gambling industry in the past 20 years, but gathering\nsufficiently large quantities of rich and temporally high-resolution data from\nreal exchanges - i.e., the sort of data that is needed in large quantities for\nDeep Learning - is often very expensive, and sometimes simply impossible; this\ncreates a need for a plausibly realistic synthetic data generator, which is\nwhat this simulation now provides. The simulator, named the \"Bristol Betting\nExchange\" (BBE), is intended as a common platform, a data-source and\nexperimental test-bed, for researchers studying the application of AI and\nmachine learning (ML) techniques to issues arising in betting exchanges; and,\nas far as I have been able to determine, BBE is the first of its kind: a free\nopen-source agent-based simulation model consisting not only of a\nsports-betting exchange, but also a minimal simulation model of racetrack\nsporting events (e.g., horse-races or car-races) about which bets may be made,\nand a population of simulated bettors who each form their own private\nevaluation of odds and place bets on the exchange before and - crucially -\nduring the race itself (i.e., so-called \"in-play\" betting) and whose betting\nopinions change second-by-second as each race event unfolds. BBE is offered as\na proof-of-concept system that enables the generation of large high-resolution\ndata-sets for automated discovery or improvement of profitable strategies for\nbetting on sporting events via the application of AI/ML and advanced data\nanalytics techniques. This paper offers an extensive survey of relevant\nliterature and explains the motivation and design of BBE, and presents brief\nillustrative results.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 06:52:08 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Cliff", "Dave", ""]]}, {"id": "2105.08664", "submitter": "Farzan Soleymani", "authors": "Farzan Soleymani, Eric Paquet", "title": "Deep Graph Convolutional Reinforcement Learning for Financial Portfolio\n  Management -- DeepPocket", "comments": null, "journal-ref": null, "doi": "10.1016/j.eswa.2021.115127", "report-no": null, "categories": "q-fin.CP cs.CE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Portfolio management aims at maximizing the return on investment while\nminimizing risk by continuously reallocating the assets forming the portfolio.\nThese assets are not independent but correlated during a short time period. A\ngraph convolutional reinforcement learning framework called DeepPocket is\nproposed whose objective is to exploit the time-varying interrelations between\nfinancial instruments. These interrelations are represented by a graph whose\nnodes correspond to the financial instruments while the edges correspond to a\npair-wise correlation function in between assets. DeepPocket consists of a\nrestricted, stacked autoencoder for feature extraction, a convolutional network\nto collect underlying local information shared among financial instruments, and\nan actor-critic reinforcement learning agent. The actor-critic structure\ncontains two convolutional networks in which the actor learns and enforces an\ninvestment policy which is, in turn, evaluated by the critic in order to\ndetermine the best course of action by constantly reallocating the various\nportfolio assets to optimize the expected return on investment. The agent is\ninitially trained offline with online stochastic batching on historical data.\nAs new data become available, it is trained online with a passive concept drift\napproach to handle unexpected changes in their distributions. DeepPocket is\nevaluated against five real-life datasets over three distinct investment\nperiods, including during the Covid-19 crisis, and clearly outperformed market\nindexes.\n", "versions": [{"version": "v1", "created": "Thu, 6 May 2021 15:07:36 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Soleymani", "Farzan", ""], ["Paquet", "Eric", ""]]}, {"id": "2105.08804", "submitter": "Massinissa Ferhoune", "authors": "Laurence Carassus and Massinissa Ferhoune", "title": "An efficient Monte Carlo method for utility-based pricing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP q-fin.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an efficient numerical method, based on the Lambert function, for\nthe computation and study of the reservation price as well as the value\nfunction in the case of illiquidity. Our theoretical results are illustrated by\nnumerical simulations.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 19:48:06 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Carassus", "Laurence", ""], ["Ferhoune", "Massinissa", ""]]}, {"id": "2105.09264", "submitter": "Haoran Wang", "authors": "Haoran Wang, Shi Yu", "title": "Robo-Advising: Enhancing Investment with Inverse Optimization and Deep\n  Reinforcement Learning", "comments": "13 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PM cs.LG q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning (ML) has been embraced as a powerful tool by the financial\nindustry, with notable applications spreading in various domains including\ninvestment management. In this work, we propose a full-cycle data-driven\ninvestment robo-advising framework, consisting of two ML agents. The first\nagent, an inverse portfolio optimization agent, infers an investor's risk\npreference and expected return directly from historical allocation data using\nonline inverse optimization. The second agent, a deep reinforcement learning\n(RL) agent, aggregates the inferred sequence of expected returns to formulate a\nnew multi-period mean-variance portfolio optimization problem that can be\nsolved using deep RL approaches. The proposed investment pipeline is applied on\nreal market data from April 1, 2016 to February 1, 2021 and has shown to\nconsistently outperform the S&P 500 benchmark portfolio that represents the\naggregate market optimal allocation. The outperformance may be attributed to\nthe the multi-period planning (versus single-period planning) and the\ndata-driven RL approach (versus classical estimation approach).\n", "versions": [{"version": "v1", "created": "Wed, 19 May 2021 17:20:03 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Wang", "Haoran", ""], ["Yu", "Shi", ""]]}, {"id": "2105.09581", "submitter": "Max Jensen", "authors": "Bartosz Jaroszkowski, Max Jensen", "title": "Valuation of European Options under an Uncertain Market Price of\n  Volatility Risk", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PR q-fin.CP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a model to quantify the effect of parameter uncertainty on the\noption price in the Heston model. More precisely, we present a\nHamilton-Jacobi-Bellman framework which allows us to evaluate best and worst\ncase scenarios under an uncertain market price of volatility risk. For the\nnumerical approximation the Hamilton--Jacobi--Bellman equation is reformulated\nto enable the solution with a finite element method. A case study with\nbutterfly options exhibits how the dependence of Delta on the magnitude of the\nuncertainty is nonlinear and highly varied across the parameter regime.\n  Keywords: Uncertain market price, Volatility risk, Hamilton-Jacobi-Bellman\nequation, Finite element method, Uncertainty quantification\n", "versions": [{"version": "v1", "created": "Thu, 20 May 2021 08:14:39 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Jaroszkowski", "Bartosz", ""], ["Jensen", "Max", ""]]}, {"id": "2105.10467", "submitter": "Michael Tretyakov", "authors": "Haozhe Su, M.V. Tretyakov, David P. Newton", "title": "Option Valuation through Deep Learning of Transition Probability Density", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP cs.NA math.NA math.PR q-fin.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transition probability densities are fundamental to option pricing. Advancing\nrecent work in deep learning, we develop novel transition density function\ngenerators through solving backward Kolmogorov equations in parametric space\nfor cumulative probability functions, using neural networks to obtain accurate\napproximations of transition probability densities, creating ultra-fast\ntransition density function generators offline that can be trained for any\nunderlying. These are 'single solve' , so they do not require recalculation\nwhen parameters are changed (e.g. recalibration of volatility) and are portable\nto other option pricing setups as well as to less powerful computers, where\nthey can be accessed as quickly as closed-form solutions. We demonstrate the\nrange of application for one-dimensional cases, exemplified by the\nBlack-Scholes-Merton model, two-dimensional cases, exemplified by the Heston\nprocess, and finally for a modified Heston model with time-dependent parameters\nthat has no closed-form solution.\n", "versions": [{"version": "v1", "created": "Fri, 21 May 2021 17:11:31 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Su", "Haozhe", ""], ["Tretyakov", "M. V.", ""], ["Newton", "David P.", ""]]}, {"id": "2105.10871", "submitter": "Theodore Zhao", "authors": "Tim Leung, Theodore Zhao", "title": "Financial Time Series Analysis and Forecasting with HHT Feature\n  Generation and Machine Learning", "comments": "28 pages, 10 figures. arXiv admin note: text overlap with\n  arXiv:2105.08133", "journal-ref": "Appl Stochastic Models Bus Ind. 2021; 1 - 24", "doi": null, "report-no": null, "categories": "q-fin.CP q-fin.ST", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present the method of complementary ensemble empirical mode decomposition\n(CEEMD) and Hilbert-Huang transform (HHT) for analyzing nonstationary financial\ntime series. This noise-assisted approach decomposes any time series into a\nnumber of intrinsic mode functions, along with the corresponding instantaneous\namplitudes and instantaneous frequencies. Different combinations of modes allow\nus to reconstruct the time series using components of different timescales. We\nthen apply Hilbert spectral analysis to define and compute the associated\ninstantaneous energy-frequency spectrum to illustrate the properties of various\ntimescales embedded in the original time series. Using HHT, we generate a\ncollection of new features and integrate them into machine learning models,\nsuch as regression tree ensemble, support vector machine (SVM), and long\nshort-term memory (LSTM) neural network. Using empirical financial data, we\ncompare several HHT-enhanced machine learning models in terms of forecasting\nperformance.\n", "versions": [{"version": "v1", "created": "Sun, 23 May 2021 07:26:52 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Leung", "Tim", ""], ["Zhao", "Theodore", ""]]}, {"id": "2105.11053", "submitter": "Sheng (Victor) Wang", "authors": "Samuel N. Cohen and Christoph Reisinger and Sheng Wang", "title": "Arbitrage-free neural-SDE market models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP math.PR q-fin.RM q-fin.ST stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modelling joint dynamics of liquid vanilla options is crucial for\narbitrage-free pricing of illiquid derivatives and managing risks of option\ntrade books. This paper develops a nonparametric model for the European options\nbook respecting underlying financial constraints and while being practically\nimplementable. We derive a state space for prices which are free from static\n(or model-independent) arbitrage and study the inference problem where a model\nis learnt from discrete time series data of stock and option prices. We use\nneural networks as function approximators for the drift and diffusion of the\nmodelled SDE system, and impose constraints on the neural nets such that\nno-arbitrage conditions are preserved. In particular, we give methods to\ncalibrate \\textit{neural SDE} models which are guaranteed to satisfy a set of\nlinear inequalities. We validate our approach with numerical experiments using\ndata generated from a Heston stochastic local volatility model.\n", "versions": [{"version": "v1", "created": "Mon, 24 May 2021 00:53:10 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Cohen", "Samuel N.", ""], ["Reisinger", "Christoph", ""], ["Wang", "Sheng", ""]]}, {"id": "2105.12267", "submitter": "Maximilian Vierlboeck", "authors": "Maximilian Vierlboeck, Roshanak Rose Nilchiani", "title": "Effects of COVID-19 Vaccine Developments and Rollout on the Capital\n  Market -- A Case Study", "comments": "12 pages, 8 figures, 4 tables, full reference list", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Various companies have developed vaccines to combat the pandemic caused 2020\nby the virus COVID-19. Such vaccines and the distribution can have a major\nimpact on the success of pharmaceutical companies, which in turn can show\nitself in their valuation and stock price. This poses the question if and how\nthe trends or popularity of the companies might be connected to the value and\nstock price of said entities. To gain some insight into these questions, the\nwork at hand looks at five COVID vaccine development companies and evaluates\ntheir correlations over the development of the vaccine as well as after the\nrollout start. The process was conducted by using python including various\nlibraries. The result of this analysis was that there is a significant\ncorrelation between the Google Trend data and the respective stock prices\n(retrieved from yahoo! Finance) of the companies on average, where the time\nduring the development of the drugs is more positively correlated and the\npost-rollout periods show a shift to a slightly negative inclining correlation.\nFurthermore, it was found that the smaller companies based on their market cap\nshow a higher price volatility overall. In addition, higher average trend\nscores and thus popularity values were found after the rollout of the\nrespective companies. In conclusion, a correlations between the trend data and\nthe financial values have been found and corroborate the plots of the data. Due\nto the small size of the sample, the result cannot yet be considered\nstatistically significant, but possibility for expansion exists and is already\nbeing worked on.\n", "versions": [{"version": "v1", "created": "Wed, 26 May 2021 00:10:32 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Vierlboeck", "Maximilian", ""], ["Nilchiani", "Roshanak Rose", ""]]}, {"id": "2105.12293", "submitter": "Wei Dai", "authors": "Yong Shi, Wei Dai, Wen Long, Bo Li", "title": "Deep Kernel Gaussian Process Based Financial Market Predictions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Gaussian Process with a deep kernel is an extension of the classic GP\nregression model and this extended model usually constructs a new kernel\nfunction by deploying deep learning techniques like long short-term memory\nnetworks. A Gaussian Process with the kernel learned by LSTM, abbreviated as\nGP-LSTM, has the advantage of capturing the complex dependency of financial\nsequential data, while retaining the ability of probabilistic inference.\nHowever, the deep kernel Gaussian Process has not been applied to forecast the\nconditional returns and volatility in financial market to the best of our\nknowledge. In this paper, grid search algorithm, used for performing\nhyper-parameter optimization, is integrated with GP-LSTM to predict both the\nconditional mean and volatility of stock returns, which are then combined\ntogether to calculate the conditional Sharpe Ratio for constructing a\nlong-short portfolio. The experiments are performed on a dataset covering all\nconstituents of Shenzhen Stock Exchange Component Index. Based on empirical\nresults, we find that the GP-LSTM model can provide more accurate forecasts in\nstock returns and volatility, which are jointly evaluated by the performance of\nconstructed portfolios. Further sub-period analysis of the experiment results\nindicates that the superiority of GP-LSTM model over the benchmark models stems\nfrom better performance in highly volatile periods.\n", "versions": [{"version": "v1", "created": "Wed, 26 May 2021 01:51:02 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Shi", "Yong", ""], ["Dai", "Wei", ""], ["Long", "Wen", ""], ["Li", "Bo", ""]]}, {"id": "2105.12432", "submitter": "Patrick Cheridito", "authors": "Patrick Cheridito, John Ery and Mario V. W\\\"uthrich", "title": "Assessing asset-liability risk with neural networks", "comments": null, "journal-ref": "Risks 2020, 8, 16", "doi": "10.3390/risks8010016", "report-no": null, "categories": "q-fin.RM q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a neural network approach for assessing the risk of a portfolio\nof assets and liabilities over a given time period. This requires a conditional\nvaluation of the portfolio given the state of the world at a later time, a\nproblem that is particularly challenging if the portfolio contains structured\nproducts or complex insurance contracts which do not admit closed form\nvaluation formulas. We illustrate the method on different examples from banking\nand insurance. We focus on value-at-risk and expected shortfall, but the\napproach also works for other risk measures.\n", "versions": [{"version": "v1", "created": "Wed, 26 May 2021 09:41:51 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Cheridito", "Patrick", ""], ["Ery", "John", ""], ["W\u00fcthrich", "Mario V.", ""]]}, {"id": "2105.12825", "submitter": "Zhihan Zhou", "authors": "Zhihan Zhou, Liqian Ma, Han Liu", "title": "Trade the Event: Corporate Events Detection for News-Based Event-Driven\n  Trading", "comments": "Accepted to publish in Findings of ACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL q-fin.CP q-fin.TR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce an event-driven trading strategy that predicts\nstock movements by detecting corporate events from news articles. Unlike\nexisting models that utilize textual features (e.g., bag-of-words) and\nsentiments to directly make stock predictions, we consider corporate events as\nthe driving force behind stock movements and aim to profit from the temporary\nstock mispricing that may occur when corporate events take place. The core of\nthe proposed strategy is a bi-level event detection model. The low-level event\ndetector identifies events' existences from each token, while the high-level\nevent detector incorporates the entire article's representation and the\nlow-level detected results to discover events at the article-level. We also\ndevelop an elaborately-annotated dataset EDT for corporate event detection and\nnews-based stock prediction benchmark. EDT includes 9721 news articles with\ntoken-level event labels as well as 303893 news articles with minute-level\ntimestamps and comprehensive stock price labels. Experiments on EDT indicate\nthat the proposed strategy outperforms all the baselines in winning rate,\nexcess returns over the market, and the average return on each transaction.\n", "versions": [{"version": "v1", "created": "Wed, 26 May 2021 20:39:40 GMT"}, {"version": "v2", "created": "Fri, 28 May 2021 01:40:55 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Zhou", "Zhihan", ""], ["Ma", "Liqian", ""], ["Liu", "Han", ""]]}, {"id": "2105.13320", "submitter": "Timothy DeLise", "authors": "Timothy DeLise", "title": "Neural Options Pricing", "comments": "9 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.MF cs.CE cs.LG q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This research investigates pricing financial options based on the traditional\nmartingale theory of arbitrage pricing applied to neural SDEs. We treat neural\nSDEs as universal It\\^o process approximators. In this way we can lift all\nassumptions on the form of the underlying price process, and compute\ntheoretical option prices numerically. We propose a variation of the SDE-GAN\napproach by implementing the Wasserstein distance metric as a loss function for\ntraining. Furthermore, it is conjectured that the error of the option price\nimplied by the learnt model can be bounded by the very Wasserstein distance\nmetric that was used to fit the empirical data.\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2021 17:22:30 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["DeLise", "Timothy", ""]]}, {"id": "2105.13822", "submitter": "Ye Wang", "authors": "Ye Wang, Lioba Heimbach, Roger Wattenhofer", "title": "Behavior of Liquidity Providers in Decentralized Exchanges", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Decentralized exchanges (DEXes) have introduced an innovative trading\nmechanism, where it is not necessary to match buy-orders and sell-orders to\nexecute a trade. DEXes execute each trade individually, and the exchange rate\nis automatically determined by the ratio of assets reserved in the market.\nTherefore, apart from trading, financial players can also liquidity providers,\nbenefiting from transaction fees from trades executed in DEXes. Although\nliquidity providers are essential for the functionality of DEXes, it is not\nclear how liquidity providers behave in such markets.In this paper, we aim to\nunderstand how liquidity providers react to market information and how they\nbenefit from providing liquidity in DEXes. We measure the operations of\nliquidity providers on Uniswap and analyze how they determine their investment\nstrategy based on market changes. We also reveal their returns and risks of\ninvestments in different trading pair categories, i.e., stable pairs, normal\npairs, and exotic pairs. Further, we investigate the movement of liquidity\nbetween trading pools. To the best of our knowledge, this is the first work\nthat systematically studies the behavior of liquidity providers in DEXes.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 13:34:14 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Wang", "Ye", ""], ["Heimbach", "Lioba", ""], ["Wattenhofer", "Roger", ""]]}, {"id": "2105.13898", "submitter": "Jaydip Sen", "authors": "Jaydip Sen, Sidra Mehtab, Abhishek Dutta", "title": "Volatility Modeling of Stocks from Selected Sectors of the Indian\n  Economy Using GARCH", "comments": "This paper is the accepted version of our paper in the IEEE Asian\n  Conference on Innovation Technology (IEEE ASIANCON'2021) which will be\n  organized in Pune, INDIA during August 28 - 29, 2021. The paper consists of 8\n  pages and it contains 13 figures and 22 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP cs.LG q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Volatility clustering is an important characteristic that has a significant\neffect on the behavior of stock markets. However, designing robust models for\naccurate prediction of future volatilities of stock prices is a very\nchallenging research problem. We present several volatility models based on\ngeneralized autoregressive conditional heteroscedasticity (GARCH) framework for\nmodeling the volatility of ten stocks listed in the national stock exchange\n(NSE) of India. The stocks are selected from the auto sector and the banking\nsector of the Indian economy, and they have a significant impact on the\nsectoral index of their respective sectors in the NSE. The historical stock\nprice records from Jan 1, 2010, to Apr 30, 2021, are scraped from the Yahoo\nFinance website using the DataReader API of the Pandas module in the Python\nprogramming language. The GARCH modules are built and fine-tuned on the\ntraining data and then tested on the out-of-sample data to evaluate the\nperformance of the models. The analysis of the results shows that asymmetric\nGARCH models yield more accurate forecasts on the future volatility of stocks.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 14:59:40 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Sen", "Jaydip", ""], ["Mehtab", "Sidra", ""], ["Dutta", "Abhishek", ""]]}]