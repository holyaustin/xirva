[{"id": "2008.00462", "submitter": "Anindya Goswami Mr.", "authors": "Anindya Goswami and Sharan Rajani and Atharva Tanksale", "title": "Data-Driven Option Pricing using Single and Multi-Asset Supervised\n  Learning", "comments": "18 figures, 11 tables, 25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST q-fin.CP q-fin.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose three different data-driven approaches for pricing European-style\ncall options using supervised machine-learning algorithms. These approaches\nyield models that give a range of fair prices instead of a single price point.\nThe performance of the models are tested on two stock market indices: NIFTY$50$\nand BANKNIFTY from the Indian equity market. Although neither historical nor\nimplied volatility is used as an input, the results show that the trained\nmodels have been able to capture the option pricing mechanism better than or\nsimilar to the Black-Scholes formula for all the experiments. Our choice of\nscale free I/O allows us to train models using combined data of multiple\ndifferent assets from a financial market. This not only allows the models to\nachieve far better generalization and predictive capability, but also solves\nthe problem of paucity of data, the primary limitation of using machine\nlearning techniques. We also illustrate the performance of the trained models\nin the period leading up to the 2020 Stock Market Crash (Jan 2019 to April\n2020).\n", "versions": [{"version": "v1", "created": "Sun, 2 Aug 2020 11:14:43 GMT"}, {"version": "v2", "created": "Sat, 5 Dec 2020 14:26:37 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Goswami", "Anindya", ""], ["Rajani", "Sharan", ""], ["Tanksale", "Atharva", ""]]}, {"id": "2008.00925", "submitter": "Chinonso Nwankwo", "authors": "Chinonso Nwankwo and Weizhong Dai", "title": "Multigrid Iterative Algorithms based on Compact Finite Difference\n  Schemes and Hermite interpolation for Solving Regime Switching American\n  Options", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP q-fin.MF q-fin.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present multigrid iterative algorithms for solving a system of coupled\nfree boundary problems for pricing American put options with regime-switching.\nThe algorithms are based on our recent developed compact finite difference\nscheme coupled with Hermite interpolation for solving the m coupled partial\ndifferential equations consisting of the asset, delta, gamma, and speed\noptions. In the algorithms, we first use the Gauss-Seidel as a smoother, and\nthen implement V-cycle and modified multigrid strategies for solving our\ndiscretized equations. Hermite interpolation with Newton interpolatory divided\ndifference (as the basis) is used in estimating the coupled asset, delta,\ngamma, and speed options in the set of equations. A numerical experiment is\nperformed with the two-regimes example and compared with other existing methods\nto validate the optimal strategy. Results show that these algorithms provide\nfast and efficient tools for pricing American put options with\nregime-switching.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 15:02:02 GMT"}, {"version": "v2", "created": "Wed, 12 Aug 2020 14:49:16 GMT"}, {"version": "v3", "created": "Sun, 6 Sep 2020 16:56:43 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Nwankwo", "Chinonso", ""], ["Dai", "Weizhong", ""]]}, {"id": "2008.01463", "submitter": "Udomsak Rakwongwan", "authors": "Teemu Pennanen and Udomsak Rakwongwan", "title": "Optimal semi-static hedging in illiquid markets", "comments": "25 pages, 21 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PR q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study indifference pricing of exotic derivatives by using hedging\nstrategies that take static positions in quoted derivatives but trade the\nunderlying and cash dynamically over time. We use real quotes that come with\nbid-ask spreads and finite quantities. Galerkin method and integration\nquadratures are used to approximate the hedging problem by a finite dimensional\nconvex optimization problem which is solved by an interior point method. The\ntechniques are extended also to situations where the underlying is subject to\nbid-ask spreads. As an illustration, we compute indifference prices of\npath-dependent options written on S&P500 index. Semi-static hedging improves\nconsiderably on the purely static options strategy as well as dynamic trading\nwithout options. The indifference prices make good economic sense even in the\npresence of arbitrage opportunities that are found when the underlying is\nassumed perfectly liquid. When transaction costs are introduced, the arbitrage\nopportunities vanish but the indifference prices remain almost unchanged.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 11:16:54 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Pennanen", "Teemu", ""], ["Rakwongwan", "Udomsak", ""]]}, {"id": "2008.05147", "submitter": "Vica Tendenan", "authors": "Vica Tendenan, Richard Gerlach, and Chao Wang", "title": "Tail risk forecasting using Bayesian realized EGARCH models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper develops a Bayesian framework for the realized exponential\ngeneralized autoregressive conditional heteroskedasticity (realized EGARCH)\nmodel, which can incorporate multiple realized volatility measures for the\nmodelling of a return series. The realized EGARCH model is extended by adopting\na standardized Student-t and a standardized skewed Student-t distribution for\nthe return equation. Different types of realized measures, such as sub-sampled\nrealized variance, sub-sampled realized range, and realized kernel, are\nconsidered in the paper. The Bayesian Markov chain Monte Carlo (MCMC)\nestimation employs the robust adaptive Metropolis algorithm (RAM) in the burn\nin period and the standard random walk Metropolis in the sample period. The\nBayesian estimators show more favourable results than maximum likelihood\nestimators in a simulation study. We test the proposed models with several\nindices to forecast one-step-ahead Value at Risk (VaR) and Expected Shortfall\n(ES) over a period of 1000 days. Rigorous tail risk forecast evaluations show\nthat the realized EGARCH models employing the standardized skewed Student-t\ndistribution and incorporating sub-sampled realized range are favored, compared\nto a range of models.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 07:36:57 GMT"}, {"version": "v2", "created": "Mon, 24 Aug 2020 11:37:50 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Tendenan", "Vica", ""], ["Gerlach", "Richard", ""], ["Wang", "Chao", ""]]}, {"id": "2008.06042", "submitter": "Bairui Du", "authors": "Bairui Du, Delmiro Fernandez-Reyes and Paolo Barucca", "title": "Image Processing Tools for Financial Time Series Classification", "comments": "12 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The application of deep learning to time series forecasting is one of the\nmajor challenges in present machine learning. We propose a novel methodology\nthat combines machine learning and image processing methods to define and\npredict market states with intraday financial data. A wavelet transform is\napplied to the log-return of stock prices for both image extraction and\ndenoising. A convolutional neural network then extracts patterns from denoised\nwavelet images to classify daily time series, i.e. a market state is associated\nwith the binary prediction of the daily close price movement based on the\nwavelet image constructed from the price changes in the first hours of the day.\nThis method overcomes the low signal-to-noise ratio problem in financial time\nseries and gets a competitive prediction accuracy of the market states 'Up' and\n'Down' of financial data as tested on the S&P 500.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 17:56:17 GMT"}, {"version": "v2", "created": "Tue, 18 Aug 2020 14:13:07 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Du", "Bairui", ""], ["Fernandez-Reyes", "Delmiro", ""], ["Barucca", "Paolo", ""]]}, {"id": "2008.06598", "submitter": "Peter  Forsyth", "authors": "Peter A. Forsyth", "title": "A Stochastic Control Approach to Defined Contribution Plan Decumulation:\n  \"The Nastiest, Hardest Problem in Finance\"", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP q-fin.PM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We pose the decumulation strategy for a Defined Contribution (DC) pension\nplan as a problem in optimal stochastic control. The controls are the\nwithdrawal amounts and the asset allocation strategy. We impose maximum and\nminimum constraints on the withdrawal amounts, and impose no-shorting\nno-leverage constraints on the asset allocation strategy. Our objective\nfunction measures reward as the expected total withdrawals over the\ndecumulation horizon, and risk is measured by Expected Shortfall (ES) at the\nend of the decumulation period. We solve the stochastic control problem\nnumerically, based on a parametric model of market stochastic processes. We\nfind that, compared to a fixed constant withdrawal strategy, with minimum\nwithdrawal set to the constant withdrawal amount, the optimal strategy has a\nsignificantly higher expected average withdrawal, at the cost of a very small\nincrease in ES risk. Tests on bootstrapped resampled historical market data\nindicate that this strategy is robust to parametric model misspecification.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 22:56:39 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Forsyth", "Peter A.", ""]]}, {"id": "2008.07564", "submitter": "Eduardo Ramos", "authors": "Eduardo Ramos-P\\'erez, Pablo J. Alonso-Gonz\\'alez, Jos\\'e Javier\n  N\\'u\\~nez-Vel\\'azquez", "title": "Stochastic reserving with a stacked model based on a hybridized\n  Artificial Neural Network", "comments": null, "journal-ref": "Expert Systems with Applications, Volume 163, January 2021", "doi": "10.1016/j.eswa.2020.113782", "report-no": null, "categories": "q-fin.RM q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Currently, legal requirements demand that insurance companies increase their\nemphasis on monitoring the risks linked to the underwriting and asset\nmanagement activities. Regarding underwriting risks, the main uncertainties\nthat insurers must manage are related to the premium sufficiency to cover\nfuture claims and the adequacy of the current reserves to pay outstanding\nclaims. Both risks are calibrated using stochastic models due to their nature.\nThis paper introduces a reserving model based on a set of machine learning\ntechniques such as Gradient Boosting, Random Forest and Artificial Neural\nNetworks. These algorithms and other widely used reserving models are stacked\nto predict the shape of the runoff. To compute the deviation around a former\nprediction, a log-normal approach is combined with the suggested model. The\nempirical results demonstrate that the proposed methodology can be used to\nimprove the performance of the traditional reserving techniques based on\nBayesian statistics and a Chain Ladder, leading to a more accurate assessment\nof the reserving risk.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 18:26:05 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Ramos-P\u00e9rez", "Eduardo", ""], ["Alonso-Gonz\u00e1lez", "Pablo J.", ""], ["N\u00fa\u00f1ez-Vel\u00e1zquez", "Jos\u00e9 Javier", ""]]}, {"id": "2008.07836", "submitter": "Tomoshiro Ochiai", "authors": "Tomoshiro Ochiai and Jose C. Nacher", "title": "Unveiling the directional network behind the financial statements data\n  using volatility constraint correlation", "comments": "14 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.GN q-fin.CP q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Financial data, such as financial statements, stores valuable and critical\ninformation to potentially assist stakeholders and investors optimize their\ncapital so that it maximizes overall economic growth. Since there are many\nvariables in financial statements, it is important to determine the causal\nrelationships, that is, the directional influence between them in a structural\nway, as well as to understand the related accounting mechanisms. However, the\nanalysis of variable-to-variable relationships in financial information by\nusing the standard correlation functions is not sufficient to unveil\ndirectionality. Here, we use the volatility constrained correlation (VC\ncorrelation) method that enables us to predict the directional relationship\nbetween the two variables. To be precise, we apply the VC correlation method to\nfive major financial information variables (revenue, net income, operating\nincome, own capital and market capitalization) of 2321 firms in 28 years from\n1990 to 2018 listed on Tokyo Stock Exchange in order to identify which\nvariables are influential and which are susceptible variables. Our findings\nshow that operating income is the most influential variable and market capital\nand revenue are the most susceptible variables among the five major accounting\nvariables. Surprisingly, the results are different from the existing intuitive\nunderstanding suggested by widely used investment strategy indicators known as\nPER and PBR, which report that net income and own capital are the most\ninfluential variable on market capital. Taken together, the presented analysis\nmay assist managers, stakeholders and investors to improve performance of\nfinancial management as well as optimize financial strategies for firms in\nfuture operations.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 10:17:09 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Ochiai", "Tomoshiro", ""], ["Nacher", "Jose C.", ""]]}, {"id": "2008.07871", "submitter": "Peter Belc\\'ak", "authors": "Peter Belcak, Jan-Peter Calliess, Stefan Zohren", "title": "Fast Agent-Based Simulation Framework of Limit Order Books with\n  Applications to Pro-Rata Markets and the Study of Latency Effects", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP cs.MA q-fin.TR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new software toolbox, called Multi-Agent eXchange Environment\n(MAXE), for agent-based simulation of limit order books. Offering both\nefficient C++ implementations and Python APIs, it allows the user to simulate\nlarge-scale agent-based market models while providing user-friendliness for\nrapid prototyping. Furthermore, it benefits from a versatile message-driven\narchitecture that offers the flexibility to simulate a range of different\n(easily customisable) market rules and to study the effect of auxiliary\nfactors, such as delays, on the market dynamics.\n  Showcasing its utility for research, we employ our simulator to investigate\nthe influence the choice of the matching algorithm has on the behaviour of\nartificial trader agents in a zero-intelligence model. In addition, we\ninvestigate the role of the order processing delay in normal trading on an\nexchange and in the scenario of a significant price change. Our results include\nthe findings that (i) the variance of the bid-ask spread exhibits a behavior\nsimilar to resonance of a damped harmonic oscillator with respect to the\nprocessing delay and that (ii) the delay markedly affects the impact a large\ntrade has on the limit order book.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 11:37:34 GMT"}, {"version": "v2", "created": "Tue, 25 Aug 2020 10:55:40 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Belcak", "Peter", ""], ["Calliess", "Jan-Peter", ""], ["Zohren", "Stefan", ""]]}, {"id": "2008.09108", "submitter": "Konstantin E. Feldman", "authors": "K.E. Feldman", "title": "Analytic Calibration in Andreasen-Huge SABR Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP math.PR q-fin.MF q-fin.PR q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive analytic formulae which link $\\alpha$, $\\nu$ and $\\rho$ parameters\nin Andreasen-Huge style SABR model to the ATM price and option prices at four\nstrikes close to ATM. Based on these formulae we give a characterisation for\nthe SABR parameters in terms of derivatives of the swap rate forward\nprobability density function. We test the analytic result in the application to\nthe interest rate futures option market.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 17:51:47 GMT"}, {"version": "v2", "created": "Mon, 1 Feb 2021 07:03:34 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Feldman", "K. E.", ""]]}, {"id": "2008.09454", "submitter": "Sheng (Victor) Wang", "authors": "Samuel N. Cohen, Christoph Reisinger and Sheng Wang", "title": "Detecting and repairing arbitrage in traded option prices", "comments": "Our implementation of this algorithm in Python is available in the\n  repository https://github.com/vicaws/arbitragerepair", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PR q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Option price data are used as inputs for model calibration, risk-neutral\ndensity estimation and many other financial applications. The presence of\narbitrage in option price data can lead to poor performance or even failure of\nthese tasks, making pre-processing of the data to eliminate arbitrage\nnecessary. Most attention in the relevant literature has been devoted to\narbitrage-free smoothing and filtering (i.e. removing) of data. In contrast to\nsmoothing, which typically changes nearly all data, or filtering, which\ntruncates data, we propose to repair data by only necessary and minimal\nchanges. We formulate the data repair as a linear programming (LP) problem,\nwhere the no-arbitrage relations are constraints, and the objective is to\nminimise prices' changes within their bid and ask price bounds. Through\nempirical studies, we show that the proposed arbitrage repair method gives\nsparse perturbations on data, and is fast when applied to real world\nlarge-scale problems due to the LP formulation. In addition, we show that\nremoving arbitrage from prices data by our repair method can improve model\ncalibration with enhanced robustness and reduced calibration error.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 12:49:33 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Cohen", "Samuel N.", ""], ["Reisinger", "Christoph", ""], ["Wang", "Sheng", ""]]}, {"id": "2008.11327", "submitter": "Hideaki Aoyama", "authors": "Makoto Mizuno, Hideaki Aoyama, Yoshi Fujiwara", "title": "Untangling the complexity of market competition in consumer goods -A\n  complex Hilbert PCA analysis", "comments": "27 pages with 9 Figures and 7 Tables, including a 2-page Appendix", "journal-ref": null, "doi": "10.1371/journal.pone.0245531", "report-no": "RIKEN-iTHEMS-Report-20", "categories": "q-fin.GN q-fin.CP q-fin.MF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today's consumer goods markets are rapidly evolving with significant growth\nin the number of information media as well as the number of competitive\nproducts. In this environment, obtaining a quantitative grasp of heterogeneous\ninteractions of firms and customers, which have attracted interest of\nmanagement scientists and economists, requires the analysis of extremely\nhigh-dimensional data. Existing approaches in quantitative research could not\nhandle such data without any reliable prior knowledge nor strong assumptions.\nAlternatively, we propose a novel method called complex Hilbert principal\ncomponent analysis (CHPCA) and construct a synchronization network using Hodge\ndecomposition. CHPCA enables us to extract significant comovements with a time\nlead/delay in the data, and Hodge decomposition is useful for identifying the\ntime-structure of correlations. We apply this method to the Japanese beer\nmarket data and reveal comovement of variables related to the consumer choice\nprocess across multiple products. Furthermore, we find remarkable customer\nheterogeneity by calculating the coordinates of each customer in the space\nderived from the results of CHPCA. Lastly, we discuss the policy and managerial\nimplications, limitations, and further development of the proposed method.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 01:11:22 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Mizuno", "Makoto", ""], ["Aoyama", "Hideaki", ""], ["Fujiwara", "Yoshi", ""]]}, {"id": "2008.11757", "submitter": "Ashley Davey", "authors": "Ashley Davey, Harry Zheng", "title": "Deep Learning for Constrained Utility Maximisation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes two algorithms for solving stochastic control problems\nwith deep reinforcement learning, with a focus on the utility maximisation\nproblem. The first algorithm solves Markovian problems via the Hamilton Jacobi\nBellman (HJB) equation. We solve this highly nonlinear partial differential\nequation (PDE) with a second order backward stochastic differential equation\n(2BSDE) formulation. The convex structure of the problem allows us to describe\na dual problem that can either verify the original primal approach or bypass\nsome of the complexity. The second algorithm utilises the full power of the\nduality method to solve non-Markovian problems, which are often beyond the\nscope of stochastic control solvers in the existing literature. We solve an\nadjoint BSDE that satisfies the dual optimality conditions. We apply these\nalgorithms to problems with power, log and non-HARA utilities in the\nBlack-Scholes, the Heston stochastic volatility, and path dependent volatility\nmodels. Numerical experiments show highly accurate results with low\ncomputational cost, supporting our proposed algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 18:40:57 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Davey", "Ashley", ""], ["Zheng", "Harry", ""]]}, {"id": "2008.12050", "submitter": "Diego  Porras", "authors": "Samuel Fern\\'andez-Lorenzo, Diego Porras, Juan Jos\\'e Garc\\'ia-Ripoll", "title": "Hybrid quantum-classical optimization for financial index tracking", "comments": "24 pages, 12 figures", "journal-ref": "Quantum Sci. Technol. 6 034010 (2021)", "doi": "10.1088/2058-9565/abf9af", "report-no": null, "categories": "quant-ph cs.LG q-fin.CP q-fin.PM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tracking a financial index boils down to replicating its trajectory of\nreturns for a well-defined time span by investing in a weighted subset of the\nsecurities included in the benchmark. Picking the optimal combination of assets\nbecomes a challenging NP-hard problem even for moderately large indices\nconsisting of dozens or hundreds of assets, thereby requiring heuristic methods\nto find approximate solutions. Hybrid quantum-classical optimization with\nvariational gate-based quantum circuits arises as a plausible method to improve\nperformance of current schemes. In this work we introduce a heuristic pruning\nalgorithm to find weighted combinations of assets subject to cardinality\nconstraints. We further consider different strategies to respect such\nconstraints and compare the performance of relevant quantum ans\\\"{a}tze and\nclassical optimizers through numerical simulations.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 10:59:21 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Fern\u00e1ndez-Lorenzo", "Samuel", ""], ["Porras", "Diego", ""], ["Garc\u00eda-Ripoll", "Juan Jos\u00e9", ""]]}]