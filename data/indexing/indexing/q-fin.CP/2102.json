[{"id": "2102.00001", "submitter": "Jessica Martin", "authors": "Jessica Martin (INSA Toulouse), St\\'ephane Villeneuve (TSE)", "title": "A Class of Explicit optimal contracts in the face of shutdown", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC math.PR q-fin.CP q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  What type of delegation contract should be offered when facing a risk of the\nmagnitude of the pandemic we are currently experiencing and how does the\nlikelihood of an exogenous early termination of the relationship modify the\nterms of a full-commitment contract? We study these questions by considering a\ndynamic principal-agent model that naturally extends the classical\nHolmstr{\\\"o}m-Milgrom setting to include a risk of default whose origin is\nindependent of the inherent agency problem. We obtain an explicit\ncharacterization of the optimal wage along with the optimal action provided by\nthe agent. The optimal contract is linear by offering both a fixed share of the\noutput which is similar to the standard shutdown-free Holmstr{\\\"o}m-Milgrom\nmodel and a linear prevention mechanism that is proportional to the random\nlifetime of the contract. We then tweak the model to add a possibility for risk\nmitigation through investment and study its optimality.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jan 2021 08:36:58 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Martin", "Jessica", "", "INSA Toulouse"], ["Villeneuve", "St\u00e9phane", "", "TSE"]]}, {"id": "2102.00477", "submitter": "Bruno Scalzo Dees", "authors": "Bruno Scalzo, Alvaro Arroyo, Ljubisa Stankovic, Danilo P. Mandic", "title": "Nonstationary Portfolios: Diversification in the Spectral Domain", "comments": "5 pages, 3 figures, 1 table. arXiv admin note: text overlap with\n  arXiv:2007.13855", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST eess.SP q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical portfolio optimization methods typically determine an optimal\ncapital allocation through the implicit, yet critical, assumption of\nstatistical time-invariance. Such models are inadequate for real-world markets\nas they employ standard time-averaging based estimators which suffer\nsignificant information loss if the market observables are non-stationary. To\nthis end, we reformulate the portfolio optimization problem in the spectral\ndomain to cater for the nonstationarity inherent to asset price movements and,\nin this way, allow for optimal capital allocations to be time-varying. Unlike\nexisting spectral portfolio techniques, the proposed framework employs\naugmented complex statistics in order to exploit the interactions between the\nreal and imaginary parts of the complex spectral variables, which in turn\nallows for the modelling of both harmonics and cyclostationarity in the time\ndomain. The advantages of the proposed framework over traditional methods are\ndemonstrated through numerical simulations using real-world price data.\n", "versions": [{"version": "v1", "created": "Sun, 31 Jan 2021 16:12:46 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Scalzo", "Bruno", ""], ["Arroyo", "Alvaro", ""], ["Stankovic", "Ljubisa", ""], ["Mandic", "Danilo P.", ""]]}, {"id": "2102.00626", "submitter": "Yixin Cao", "authors": "Yixin Cao and Chuanwei Zou and Xianfeng Cheng", "title": "Flashot: A Snapshot of Flash Loan Attack on DeFi Ecosystem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP q-fin.TR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Flash Loan attack can grab millions of dollars from decentralized vaults in\none single transaction, drawing increasing attention from the Decentralized\nFinance (DeFi) players. It has also demonstrated an exciting opportunity that a\nhuge wealth could be created by composing DeFi's building blocks and exploring\nthe arbitrage change. However, a fundamental framework to study the field of\nDeFi has not yet reached a consensus and there's a lack of standard tools or\nlanguages to help better describe, design and improve the running processes of\nthe infant DeFi systems, which naturally makes it harder to understand the\nbasic principles behind the complexity of Flash Loan attacks.\n  In this paper, we are the first to propose Flashot, a prototype that is able\nto transparently illustrate the precise asset flows intertwined with smart\ncontracts in a standardized diagram for each Flash Loan event. Some use cases\nare shown and specifically, based on Flashot, we study a typical Pump and\nArbitrage case and present in-depth economic explanations to the attacker's\nbehaviors. Finally, we conclude the development trends of Flash Loan attacks\nand discuss the great impact on DeFi ecosystem brought by Flash Loan. We\nenvision a brand new quantitative financial industry powered by highly\nefficient automatic risk and profit detection systems based on the blockchain.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2021 04:20:56 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Cao", "Yixin", ""], ["Zou", "Chuanwei", ""], ["Cheng", "Xianfeng", ""]]}, {"id": "2102.01290", "submitter": "Pratyush Muthukumar", "authors": "Pratyush Muthukumar, Jie Zhong", "title": "A Stochastic Time Series Model for Predicting Financial Trends using NLP", "comments": "16 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Stock price forecasting is a highly complex and vitally important field of\nresearch. Recent advancements in deep neural network technology allow\nresearchers to develop highly accurate models to predict financial trends. We\npropose a novel deep learning model called ST-GAN, or Stochastic Time-series\nGenerative Adversarial Network, that analyzes both financial news texts and\nfinancial numerical data to predict stock trends. We utilize cutting-edge\ntechnology like the Generative Adversarial Network (GAN) to learn the\ncorrelations among textual and numerical data over time. We develop a new\nmethod of training a time-series GAN directly using the learned representations\nof Naive Bayes' sentiment analysis on financial text data alongside technical\nindicators from numerical data. Our experimental results show significant\nimprovement over various existing models and prior research on deep neural\nnetworks for stock price forecasting.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 04:03:01 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Muthukumar", "Pratyush", ""], ["Zhong", "Jie", ""]]}, {"id": "2102.01533", "submitter": "Denis Belomestny", "authors": "Denis Belomestny and John Schoenmakers", "title": "From optimal martingales to randomized dual optimal stopping", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.OC q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we study and classify optimal martingales in the dual\nformulation of optimal stopping problems. In this respect we distinguish\nbetween weakly optimal and surely optimal martingales. It is shown that the\nfamily of weakly optimal and surely optimal martingales may be quite large. On\nthe other hand it is shown that the Doob-martingale, that is, the martingale\npart of the Snell envelope, is in a certain sense the most robust surely\noptimal martingale under random perturbations. This new insight leads to a\nnovel randomized dual martingale minimization algorithm that doesn't require\nnested simulation. As a main feature, in a possibly large family of optimal\nmartingales the algorithm efficiently selects a martingale that is as close as\npossible to the Doob martingale. As a result, one obtains the dual upper bound\nfor the optimal stopping problem with low variance.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 15:01:56 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Belomestny", "Denis", ""], ["Schoenmakers", "John", ""]]}, {"id": "2102.01962", "submitter": "Josef Teichmann", "authors": "Blanka Horvath, Josef Teichmann, Zan Zuric", "title": "Deep Hedging under Rough Volatility", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP cs.CE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We investigate the performance of the Deep Hedging framework under training\npaths beyond the (finite dimensional) Markovian setup. In particular we analyse\nthe hedging performance of the original architecture under rough volatility\nmodels with view to existing theoretical results for those. Furthermore, we\nsuggest parsimonious but suitable network architectures capable of capturing\nthe non-Markoviantity of time-series. Secondly, we analyse the hedging\nbehaviour in these models in terms of P\\&L distributions and draw comparisons\nto jump diffusion models if the the rebalancing frequency is realistically\nsmall.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2021 09:27:16 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Horvath", "Blanka", ""], ["Teichmann", "Josef", ""], ["Zuric", "Zan", ""]]}, {"id": "2102.01980", "submitter": "Hanna Sophia Wutte", "authors": "Nicolas Curin, Michael Kettler, Xi Kleisinger-Yu, Vlatka Komaric,\n  Thomas Krabichler, Josef Teichmann, Hanna Wutte", "title": "A deep learning model for gas storage optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  To the best of our knowledge, the application of deep learning in the field\nof quantitative risk management is still a relatively recent phenomenon. In\nthis article, we utilize techniques inspired by reinforcement learning in order\nto optimize the operation plans of underground natural gas storage facilities.\nWe provide a theoretical framework and assess the performance of the proposed\nmethod numerically in comparison to a state-of-the-art least-squares\nMonte-Carlo approach. Due to the inherent intricacy originating from the\nhigh-dimensional forward market as well as the numerous constraints and\nfrictions, the optimization exercise can hardly be tackled by means of\ntraditional techniques.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2021 09:54:44 GMT"}, {"version": "v2", "created": "Fri, 5 Mar 2021 13:53:33 GMT"}], "update_date": "2021-03-08", "authors_parsed": [["Curin", "Nicolas", ""], ["Kettler", "Michael", ""], ["Kleisinger-Yu", "Xi", ""], ["Komaric", "Vlatka", ""], ["Krabichler", "Thomas", ""], ["Teichmann", "Josef", ""], ["Wutte", "Hanna", ""]]}, {"id": "2102.03502", "submitter": "Zhenhan Huang", "authors": "Zhenhan Huang, Fumihide Tanaka", "title": "MSPM: A Modularized and Scalable Multi-Agent Reinforcement\n  Learning-based System for Financial Portfolio Management", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PM cs.AI cs.LG q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Financial portfolio management is one of the most applicable problems in\nreinforcement learning (RL) owing to its sequential decision-making nature.\nExisting RL-based approaches, while inspiring, often lack scalability,\nreusability, or profundity of intake information to accommodate the\never-changing capital markets. In this paper, we propose MSPM, a modularized\nand scalable, multi-agent RL-based system for financial portfolio management.\nMSPM involves two asynchronously updated units: an Evolving Agent Module (EAM)\nand Strategic Agent Module (SAM). A self-sustained EAM produces\nsignal-comprised information for a specific asset using heterogeneous data\ninputs, and each EAM employs its reusability to have connections to multiple\nSAMs. An SAM is responsible for asset reallocation in a portfolio using\nprofound information from the connected EAMs. With the elaborate architecture\nand the multi-step condensation of volatile market information, MSPM aims to\nprovide a customizable, stable, and dedicated solution to portfolio management,\nunlike existing approaches. We also tackle the data-shortage issue of\nnewly-listed stocks by transfer learning, and validate the indispensability of\nEAM with four different portfolios. Experiments on 8-year U.S. stock market\ndata prove the effectiveness of MSPM in profit accumulation, by its\noutperformance over existing benchmarks.\n", "versions": [{"version": "v1", "created": "Sat, 6 Feb 2021 04:04:57 GMT"}, {"version": "v2", "created": "Tue, 9 Feb 2021 16:19:01 GMT"}, {"version": "v3", "created": "Fri, 11 Jun 2021 08:42:30 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Huang", "Zhenhan", ""], ["Tanaka", "Fumihide", ""]]}, {"id": "2102.03945", "submitter": "Nicholas Fung", "authors": "Maxime Bergeron, Nicholas Fung, John Hull and Zissis Poulos", "title": "Variational Autoencoders: A Hands-Off Approach to Volatility", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP q-fin.MF", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A volatility surface is an important tool for pricing and hedging\nderivatives. The surface shows the volatility that is implied by the market\nprice of an option on an asset as a function of the option's strike price and\nmaturity. Often, market data is incomplete and it is necessary to estimate\nmissing points on partially observed surfaces. In this paper, we show how\nvariational autoencoders can be used for this task. The first step is to derive\nlatent variables that can be used to construct synthetic volatility surfaces\nthat are indistinguishable from those observed historically. The second step is\nto determine the synthetic surface generated by our latent variables that fits\navailable data as closely as possible. As a dividend of our first step, the\nsynthetic surfaces produced can also be used in stress testing, in market\nsimulators for developing quantitative investment strategies, and for the\nvaluation of exotic options. We illustrate our procedure and demonstrate its\npower using foreign exchange market data.\n", "versions": [{"version": "v1", "created": "Sun, 7 Feb 2021 23:31:33 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Bergeron", "Maxime", ""], ["Fung", "Nicholas", ""], ["Hull", "John", ""], ["Poulos", "Zissis", ""]]}, {"id": "2102.04757", "submitter": "Samuel Cohen", "authors": "Samuel N. Cohen and Derek Snow and Lukasz Szpruch", "title": "Black-box model risk in finance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP econ.GN q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models are increasingly used in a wide variety of financial\nsettings. The difficulty of understanding the inner workings of these systems,\ncombined with their wide applicability, has the potential to lead to\nsignificant new risks for users; these risks need to be understood and\nquantified. In this sub-chapter, we will focus on a well studied application of\nmachine learning techniques, to pricing and hedging of financial options. Our\naim will be to highlight the various sources of risk that the introduction of\nmachine learning emphasises or de-emphasises, and the possible risk mitigation\nand management strategies that are available.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 11:10:51 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Cohen", "Samuel N.", ""], ["Snow", "Derek", ""], ["Szpruch", "Lukasz", ""]]}, {"id": "2102.05799", "submitter": "Nicholas Moehle", "authors": "Nicholas Moehle, Stephen Boyd, Andrew Ang", "title": "Portfolio Performance Attribution via Shapley Value", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider an investment process that includes a number of features, each of\nwhich can be active or inactive. Our goal is to attribute or decompose an\nachieved performance to each of these features, plus a baseline value. There\nare many ways to do this, which lead to potentially different attributions in\nany specific case. We argue that a specific attribution method due to Shapley\nis the preferred method, and discuss methods that can be used to compute this\nattribution exactly, or when that is not practical, approximately.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2021 01:33:24 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Moehle", "Nicholas", ""], ["Boyd", "Stephen", ""], ["Ang", "Andrew", ""]]}, {"id": "2102.08186", "submitter": "A. Christian Silva", "authors": "A. Christian Silva and Fernando F. Ferreira", "title": "Surrogate Monte Carlo", "comments": "2 columns, 6 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP q-fin.GN", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This article proposes an artificial data generating algorithm that is simple\nand easy to customize. The fundamental concept is to perform random permutation\nof Monte Carlo generated random numbers which conform to the unconditional\nprobability distribution of the original real time series. Similar to\nconstraint surrogate methods, random permutations are only accepted if a given\nobjective function is minimized. The objective function is selected in order to\ndescribe the most important features of the stochastic process. The algorithm\nis demonstrated by producing simulated log-returns of the S\\&P 500 stock index.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 11:02:49 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Silva", "A. Christian", ""], ["Ferreira", "Fernando F.", ""]]}, {"id": "2102.08338", "submitter": "Andrey Itkin", "authors": "A. Itkin, A. Lipton, D. Muravey", "title": "Multilayer heat equations: application to finance", "comments": "36 pages, 6 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP q-fin.MF q-fin.PR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we develop a Multilayer (ML) method for solving one-factor\nparabolic equations. Our approach provides a powerful alternative to the\nwell-known finite difference and Monte Carlo methods. We discuss various\nadvantages of this approach, which judiciously combines semi-analytical and\nnumerical techniques and provides a fast and accurate way of finding solutions\nto the corresponding equations. To introduce the core of the method, we\nconsider multilayer heat equations, known in physics for a relatively long time\nbut never used when solving financial problems. Thus, we expand the analytic\nmachinery of quantitative finance by augmenting it with the ML method. We\ndemonstrate how one can solve various problems of mathematical finance by using\nour approach. Specifically, we develop efficient algorithms for pricing barrier\noptions for time-dependent one-factor short-rate models, such as\nBlack-Karasinski and Verhulst. Besides, we show how to solve the well-known\nDupire equation quickly and accurately. Numerical examples confirm that our\napproach is considerably more efficient for solving the corresponding partial\ndifferential equations than the conventional finite difference method by being\nmuch faster and more accurate than the known alternatives.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 18:22:12 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Itkin", "A.", ""], ["Lipton", "A.", ""], ["Muravey", "D.", ""]]}, {"id": "2102.08378", "submitter": "d'Artis Kancs", "authors": "Pavel Ciaian, d'Artis Kancs, Miroslava Rajcaniova", "title": "The economic dependency of the Bitcoin security", "comments": "arXiv admin note: substantial text overlap with arXiv:2102.08107", "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.GN q-fin.CP q-fin.EC q-fin.PR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We study to what extent the Bitcoin blockchain security permanently depends\non the underlying distribution of cryptocurrency market outcomes. We use daily\nblockchain and Bitcoin data for 2014-2019 and employ the ARDL approach. We test\nthree equilibrium hypotheses: (i) sensitivity of the Bitcoin blockchain to\nmining reward; (ii) security outcomes of the Bitcoin blockchain and the\nproof-of-work cost; and (iii) the speed of adjustment of the Bitcoin blockchain\nsecurity to deviations from the equilibrium path. Our results suggest that the\nBitcoin price and mining rewards are intrinsically linked to Bitcoin security\noutcomes. The Bitcoin blockchain security's dependency on mining costs is\ngeographically differenced - it is more significant for the global mining\nleader China than for other world regions. After input or output price shocks,\nthe Bitcoin blockchain security reverts to its equilibrium security level.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 12:36:21 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Ciaian", "Pavel", ""], ["Kancs", "d'Artis", ""], ["Rajcaniova", "Miroslava", ""]]}, {"id": "2102.09180", "submitter": "Benjamin Patrick Evans", "authors": "Benjamin Patrick Evans, Mikhail Prokopenko", "title": "A maximum entropy model of bounded rational decision-making with prior\n  beliefs and market feedback", "comments": "39 pages, 15 figures", "journal-ref": null, "doi": "10.3390/e23060669", "report-no": null, "categories": "cs.IT cs.AI econ.TH math.IT physics.soc-ph q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bounded rationality is an important consideration stemming from the fact that\nagents often have limits on their processing abilities, making the assumption\nof perfect rationality inapplicable to many real tasks. We propose an\ninformation-theoretic approach to the inference of agent decisions under\nSmithian competition. The model explicitly captures the boundedness of agents\n(limited in their information-processing capacity) as the cost of information\nacquisition for expanding their prior beliefs. The expansion is measured as the\nKullblack-Leibler divergence between posterior decisions and prior beliefs.\nWhen information acquisition is free, the homo economicus agent is recovered,\nwhile in cases when information acquisition becomes costly, agents instead\nrevert to their prior beliefs. The maximum entropy principle is used to infer\nleast-biased decisions based upon the notion of Smithian competition formalised\nwithin the Quantal Response Statistical Equilibrium framework. The\nincorporation of prior beliefs into such a framework allowed us to\nsystematically explore the effects of prior beliefs on decision-making in the\npresence of market feedback, as well as importantly adding a temporal\ninterpretation to the framework. We verified the proposed model using\nAustralian housing market data, showing how the incorporation of prior\nknowledge alters the resulting agent decisions. Specifically, it allowed for\nthe separation of past beliefs and utility maximisation behaviour of the agent\nas well as the analysis into the evolution of agent beliefs.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 06:41:59 GMT"}, {"version": "v2", "created": "Wed, 14 Apr 2021 02:41:14 GMT"}, {"version": "v3", "created": "Sun, 23 May 2021 09:16:38 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Evans", "Benjamin Patrick", ""], ["Prokopenko", "Mikhail", ""]]}, {"id": "2102.09851", "submitter": "William Lefebvre", "authors": "William Lefebvre (LPSM (UMR\\_8001)), Enzo Miller (LPSM (UMR\\_8001))", "title": "Linear-quadratic stochastic delayed control and deep learning resolution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC math.PR q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a class of stochastic control problems with a delayed control,\nboth in drift and diffusion, of the type dX t = $\\alpha$ t--d (bdt + $\\sigma$dW\nt). We provide a new characterization of the solution in terms of a set of\nRiccati partial differential equations. Existence and uniqueness are obtained\nunder a sufficient condition expressed directly as a relation between the\nhorizon T and the quantity d(b/$\\sigma$) 2. Furthermore, a deep learning scheme\nis designed and used to illustrate the effect of delay on the Markowitz\nportfolio allocation problem with execution delay.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2021 10:39:35 GMT"}, {"version": "v2", "created": "Tue, 23 Feb 2021 09:55:37 GMT"}, {"version": "v3", "created": "Wed, 24 Feb 2021 09:53:04 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Lefebvre", "William", "", "LPSM"], ["Miller", "Enzo", "", "LPSM"]]}, {"id": "2102.10925", "submitter": "Ivan Jericevich", "authors": "Ivan Jericevich and Dharmesh Sing and Tim Gebbie", "title": "CoinTossX: An open-source low-latency high-throughput matching engine", "comments": "21 pages, 10 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.MA q-fin.CP q-fin.TR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We deploy and demonstrate the CoinTossX low-latency, high-throughput,\nopen-source matching engine with orders sent using the Julia and Python\nlanguages. We show how this can be deployed for small-scale local desk-top\ntesting and discuss a larger scale, but local hosting, with multiple traded\ninstruments managed concurrently and managed by multiple clients. We then\ndemonstrate a cloud based deployment using Microsoft Azure, with large-scale\nindustrial and simulation research use cases in mind. The system is exposed and\ninteracted with via sockets using UDP SBE message protocols and can be\nmonitored using a simple web browser interface using HTTP. We give examples\nshowing how orders can be be sent to the system and market data feeds monitored\nusing the Julia and Python languages. The system is developed in Java with\norders submitted as binary encodings (SBE) via UDP protocols using the Aeron\nMedia Driver as the low-latency, high throughput message transport. The system\nseparates the order-generation and simulation environments e.g. agent-based\nmodel simulation, from the matching of orders, data-feeds and various\nmodularised components of the order-book system. This ensures a more natural\nand realistic asynchronicity between events generating orders, and the events\nassociated with order-book dynamics and market data-feeds. We promote the use\nof Julia as the preferred order submission and simulation environment.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2021 11:50:34 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Jericevich", "Ivan", ""], ["Sing", "Dharmesh", ""], ["Gebbie", "Tim", ""]]}, {"id": "2102.12051", "submitter": "Junchao Chen", "authors": "Jean-Fran\\c{c}ois Chassagneux, Junchao Chen, Noufel Frikha and Chao\n  Zhou", "title": "A learning scheme by sparse grids and Picard approximations for\n  semilinear parabolic PDEs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA math.PR q-fin.CP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Relying on the classical connection between Backward Stochastic Differential\nEquations (BSDEs) and non-linear parabolic partial differential equations\n(PDEs), we propose a new probabilistic learning scheme for solving\nhigh-dimensional semi-linear parabolic PDEs. This scheme is inspired by the\napproach coming from machine learning and developed using deep neural networks\nin Han and al. [32]. Our algorithm is based on a Picard iteration scheme in\nwhich a sequence of linear-quadratic optimisation problem is solved by means of\nstochastic gradient descent (SGD) algorithm. In the framework of a linear\nspecification of the approximation space, we manage to prove a convergence\nresult for our scheme, under some smallness condition. In practice, in order to\nbe able to treat high-dimensional examples, we employ sparse grid approximation\nspaces. In the case of periodic coefficients and using pre-wavelet basis\nfunctions, we obtain an upper bound on the global complexity of our method. It\nshows in particular that the curse of dimensionality is tamed in the sense that\nin order to achieve a root mean squared error of order ${\\epsilon}$, for a\nprescribed precision ${\\epsilon}$, the complexity of the Picard algorithm grows\npolynomially in ${\\epsilon}^{-1}$ up to some logarithmic factor $\n|log({\\epsilon})| $ which grows linearly with respect to the PDE dimension.\nVarious numerical results are presented to validate the performance of our\nmethod and to compare them with some recent machine learning schemes proposed\nin Han and al. [20] and Hur\\'e and al. [37].\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 03:46:07 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Chassagneux", "Jean-Fran\u00e7ois", ""], ["Chen", "Junchao", ""], ["Frikha", "Noufel", ""], ["Zhou", "Chao", ""]]}, {"id": "2102.12694", "submitter": "Alexandre Carbonneau", "authors": "Alexandre Carbonneau and Fr\\'ed\\'eric Godin", "title": "Deep Equal Risk Pricing of Financial Derivatives with Multiple Hedging\n  Instruments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP math.OC q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the equal risk pricing (ERP) framework for the valuation\nof European financial derivatives. This option pricing approach is consistent\nwith global trading strategies by setting the premium as the value such that\nthe residual hedging risk of the long and short positions in the option are\nequal under optimal hedging. The ERP setup of Marzban et al. (2020) is\nconsidered where residual hedging risk is quantified with convex risk measures.\nThe main objective of this paper is to assess through extensive numerical\nexperiments the impact of including options as hedging instruments within the\nERP framework. The reinforcement learning procedure developed in Carbonneau and\nGodin (2020), which relies on the deep hedging algorithm of Buehler et al.\n(2019b), is applied to numerically solve the global hedging problems by\nrepresenting trading policies with neural networks. Among other findings,\nnumerical results indicate that in the presence of jump risk, hedging long-term\nputs with shorter-term options entails a significant decrease of both equal\nrisk prices and market incompleteness as compared to trading only the stock.\nMonte Carlo experiments demonstrate the potential of ERP as a fair valuation\napproach providing prices consistent with observable market prices. Analyses\nexhibit the ability of ERP to span a large interval of prices through the\nchoice of convex risk measures which is close to encompass the variance-optimal\npremium.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 05:45:45 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Carbonneau", "Alexandre", ""], ["Godin", "Fr\u00e9d\u00e9ric", ""]]}, {"id": "2102.13503", "submitter": "Baptiste Barreau", "authors": "Baptiste Barreau, Laurent Carlier", "title": "History-Augmented Collaborative Filtering for Financial Recommendations", "comments": null, "journal-ref": "RecSys '20: Fourteenth ACM Conference on Recommender Systems, Sep\n  2020, Virtual Event, Brazil. pp.492-497", "doi": "10.1145/3383313.3412206", "report-no": null, "categories": "cs.LG q-fin.CP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many businesses, and particularly in finance, the behavior of a client\nmight drastically change over time. It is consequently crucial for recommender\nsystems used in such environments to be able to adapt to these changes. In this\nstudy, we propose a novel collaborative filtering algorithm that captures the\ntemporal context of a user-item interaction through the users' and items'\nrecent interaction histories to provide dynamic recommendations. The algorithm,\ndesigned with issues specific to the financial world in mind, uses a custom\nneural network architecture that tackles the non-stationarity of users' and\nitems' behaviors. The performance and properties of the algorithm are monitored\nin a series of experiments on a G10 bond request for quotation proprietary\ndatabase from BNP Paribas Corporate and Institutional Banking.\n", "versions": [{"version": "v1", "created": "Fri, 26 Feb 2021 14:24:04 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Barreau", "Baptiste", ""], ["Carlier", "Laurent", ""]]}, {"id": "2102.13505", "submitter": "Aurelien Alfonsi", "authors": "Aur\\'elien Alfonsi and Ahmed Kebaier", "title": "Approximation of Stochastic Volterra Equations with kernels of\n  completely monotone type", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.NA math.NA q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we develop a multi-factor approximation for Stochastic Volterra\nEquations with Lipschitz coefficients and kernels of completely monotone type\nthat may be singular. Our approach consists in truncating and then discretizing\nthe integral defining the kernel, which corresponds to a classical Stochastic\nDifferential Equation. We prove strong convergence results for this\napproximation. For the particular rough kernel case with Hurst parameter lying\nin $(0,1/2)$, we propose various discretization procedures and give their\nprecise rates of convergence. We illustrate the efficiency of our approximation\nschemes with numerical tests for the rough Bergomi model.\n", "versions": [{"version": "v1", "created": "Fri, 26 Feb 2021 14:25:59 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Alfonsi", "Aur\u00e9lien", ""], ["Kebaier", "Ahmed", ""]]}]