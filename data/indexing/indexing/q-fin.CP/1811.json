[{"id": "1811.02028", "submitter": "Vinicius Albani", "authors": "Vinicius Albani and Jorge Zubelli", "title": "A Splitting Strategy for the Calibration of Jump-Diffusion Models", "comments": "34 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a detailed analysis and implementation of a splitting strategy to\nidentify simultaneously the local-volatility surface and the jump-size\ndistribution from quoted European prices. The underlying model consists of a\njump-diffusion driven asset with time and price dependent volatility. Our\napproach uses a forward Dupire-type partial-integro-differential equations for\nthe option prices to produce a parameter-to-solution map. The ill-posed inverse\nproblem for such map is then solved by means of a Tikhonov-type convex\nregularization. The proofs of convergence and stability of the algorithm are\nprovided together with numerical examples that substantiate the robustness of\nthe method both for synthetic and real data.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 20:51:53 GMT"}], "update_date": "2018-11-07", "authors_parsed": [["Albani", "Vinicius", ""], ["Zubelli", "Jorge", ""]]}, {"id": "1811.05270", "submitter": "Rastin Matin", "authors": "Rastin Matin, Casper Hansen, Christian Hansen and Pia M{\\o}lgaard", "title": "Predicting Distresses using Deep Learning of Text Segments in Annual\n  Reports", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL q-fin.CP q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Corporate distress models typically only employ the numerical financial\nvariables in the firms' annual reports. We develop a model that employs the\nunstructured textual data in the reports as well, namely the auditors' reports\nand managements' statements. Our model consists of a convolutional recurrent\nneural network which, when concatenated with the numerical financial variables,\nlearns a descriptive representation of the text that is suited for corporate\ndistress prediction. We find that the unstructured data provides a\nstatistically significant enhancement of the distress prediction performance,\nin particular for large firms where accurate predictions are of the utmost\nimportance. Furthermore, we find that auditors' reports are more informative\nthan managements' statements and that a joint model including both managements'\nstatements and auditors' reports displays no enhancement relative to a model\nincluding only auditors' reports. Our model demonstrates a direct improvement\nover existing state-of-the-art models.\n", "versions": [{"version": "v1", "created": "Tue, 13 Nov 2018 13:09:58 GMT"}], "update_date": "2018-11-14", "authors_parsed": [["Matin", "Rastin", ""], ["Hansen", "Casper", ""], ["Hansen", "Christian", ""], ["M\u00f8lgaard", "Pia", ""]]}, {"id": "1811.05741", "submitter": "Christian Fries", "authors": "Christian P. Fries", "title": "Stochastic Algorithmic Differentiation of (Expectations of)\n  Discontinuous Functions (Indicator Functions)", "comments": "21 pages, 5 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP cs.NA math.NA", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In this paper, we present a method for the accurate estimation of the\nderivative (aka.~sensitivity) of expectations of functions involving an\nindicator function by combining a stochastic algorithmic differentiation and a\nregression.\n  The method is an improvement of the approach presented in [Risk Magazine\nApril 2018].\n  The finite difference approximation of a partial derivative of a Monte-Carlo\nintegral of a discontinuous function is known to exhibit a high Monte-Carlo\nerror. The issue is evident since the Monte-Carlo approximation of a\ndiscontinuous function is just a finite sum of discontinuous functions and as\nsuch, not even differentiable.\n  The algorithmic differentiation of a discontinuous function is problematic. A\nnatural approach is to replace the discontinuity by continuous functions. This\nis equivalent to replacing a path-wise automatic differentiation by a (local)\nfinite difference approximation.\n  We present an improvement (in terms of variance reduction) by decoupling the\nintegration of the Dirac delta and the remaining conditional expectation and\nestimating the two parts by separate regressions. For the algorithmic\ndifferentiation, we derive an operator that can be injected seamlessly - with\nminimal code changes - into the algorithm resulting in the exact result.\n", "versions": [{"version": "v1", "created": "Wed, 14 Nov 2018 11:59:11 GMT"}, {"version": "v2", "created": "Wed, 21 Nov 2018 18:14:53 GMT"}, {"version": "v3", "created": "Thu, 22 Nov 2018 18:56:10 GMT"}, {"version": "v4", "created": "Mon, 26 Nov 2018 16:51:27 GMT"}, {"version": "v5", "created": "Mon, 11 Nov 2019 21:49:56 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Fries", "Christian P.", ""]]}, {"id": "1811.06173", "submitter": "Huicheng Liu", "authors": "Huicheng Liu", "title": "Leveraging Financial News for Stock Trend Prediction with\n  Attention-Based Recurrent Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stock market prediction is one of the most attractive research topic since\nthe successful prediction on the market's future movement leads to significant\nprofit. Traditional short term stock market predictions are usually based on\nthe analysis of historical market data, such as stock prices, moving averages\nor daily returns. However, financial news also contains useful information on\npublic companies and the market. Existing methods in finance literature exploit\nsentiment signal features, which are limited by not considering factors such as\nevents and the news context. We address this issue by leveraging deep neural\nmodels to extract rich semantic features from news text. In particular, a\nBidirectional-LSTM are used to encode the news text and capture the context\ninformation, self attention mechanism are applied to distribute attention on\nmost relative words, news and days. In terms of predicting directional changes\nin both Standard & Poor's 500 index and individual companies stock price, we\nshow that this technique is competitive with other state of the art approaches,\ndemonstrating the effectiveness of recent NLP technology advances for\ncomputational finance.\n", "versions": [{"version": "v1", "created": "Thu, 15 Nov 2018 04:49:21 GMT"}], "update_date": "2018-11-16", "authors_parsed": [["Liu", "Huicheng", ""]]}, {"id": "1811.06893", "submitter": "Huyen Pham", "authors": "Carmine De Franco, Johann Nicolle (LPSM UMR 8001), Huy\\^en Pham (LPSM\n  UMR 8001, CREST)", "title": "Bayesian learning for the Markowitz portfolio selection problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PM math.OC q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the Markowitz portfolio selection problem with unknown drift vector\nin the multidimensional framework. The prior belief on the uncertain expected\nrate of return is modeled by an arbitrary probability law, and a Bayesian\napproach from filtering theory is used to learn the posterior distribution\nabout the drift given the observed market data of the assets. The Bayesian\nMarkowitz problem is then embedded into an auxiliary standard control problem\nthat we characterize by a dynamic programming method and prove the existence\nand uniqueness of a smooth solution to the related semi-linear partial\ndifferential equation (PDE). The optimal Markowitz portfolio strategy is\nexplicitly computed in the case of a Gaussian prior distribution. Finally, we\nmeasure the quantitative impact of learning, updating the strategy from\nobserved data, compared to non-learning, using a constant drift in an uncertain\ncontext, and analyze the sensitivity of the value of information w.r.t. various\nrelevant parameters of our model.\n", "versions": [{"version": "v1", "created": "Fri, 16 Nov 2018 16:30:19 GMT"}], "update_date": "2018-11-19", "authors_parsed": [["De Franco", "Carmine", "", "LPSM UMR 8001"], ["Nicolle", "Johann", "", "LPSM UMR 8001"], ["Pham", "Huy\u00ean", "", "LPSM\n  UMR 8001, CREST"]]}, {"id": "1811.07294", "submitter": "Alessandro Ramponi", "authors": "Fabio Antonelli, Alessandro Ramponi, Sergio Scarlatti", "title": "CVA and vulnerable options pricing by correlation expansions", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of computing the Credit Value Adjustment ({CVA}) of a\nEuropean option in presence of the Wrong Way Risk ({WWR}) in a default\nintensity setting. Namely we model the asset price evolution as solution to a\nlinear equation that might depend on different stochastic factors and we\nprovide an approximate evaluation of the option's price, by exploiting a\ncorrelation expansion approach, introduced in \\cite{AS}. We compare the\nnumerical performance of such a method with that recently proposed by Brigo et\nal. (\\cite{BR18}, \\cite{BRH18}) in the case of a call option driven by a GBM\ncorrelated with the CIR default intensity. We additionally report some\nnumerical evaluations obtained by other methods.\n", "versions": [{"version": "v1", "created": "Sun, 18 Nov 2018 08:10:02 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Antonelli", "Fabio", ""], ["Ramponi", "Alessandro", ""], ["Scarlatti", "Sergio", ""]]}, {"id": "1811.07792", "submitter": "Mar\\'ia Planas", "authors": "Javier Franco-Pedroso, Joaquin Gonzalez-Rodriguez, Maria Planas, Jorge\n  Cubero, Rafael Cobo, Fernando Pablos", "title": "The ETS challenges: a machine learning approach to the evaluation of\n  simulated financial time series for improving generation processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an evaluation framework that attempts to quantify the\n\"degree of realism\" of simulated financial time series, whatever the simulation\nmethod could be, with the aim of discover unknown characteristics that are not\nbeing properly reproduced by such methods in order to improve them. For that\npurpose, the evaluation framework is posed as a machine learning problem in\nwhich some given time series examples have to be classified as simulated or\nreal financial time series. The \"challenge\" is proposed as an open competition,\nsimilar to those published at the Kaggle platform, in which participants must\nsend their classification results along with a description of the features and\nthe classifiers used. The results of these \"challenges\" have revealed some\ninteresting properties of financial data, and have lead to substantial\nimprovements in our simulation methods under research, some of which will be\ndescribed in this work.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2018 16:42:49 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Franco-Pedroso", "Javier", ""], ["Gonzalez-Rodriguez", "Joaquin", ""], ["Planas", "Maria", ""], ["Cubero", "Jorge", ""], ["Cobo", "Rafael", ""], ["Pablos", "Fernando", ""]]}, {"id": "1811.08509", "submitter": "Christian Weiss", "authors": "Christian Wei{\\ss}, Zoran Nikoli\\'c", "title": "An Aspect of Optimal Regression Design for LSMC", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Practitioners sometimes suggest to use a combination of Sobol sequences and\northonormal polynomials when applying an LSMC algorithm for evaluation of\noption prices or in the context of risk capital calculation under the Solvency\nII regime. In this paper, we give a theoretical justification why good\nimplementations of an LSMC algorithm should indeed combine these two features\nin order to assure numerical stability. Moreover, an explicit bound for the\nnumber of outer scenarios necessary to guarantee a prescribed degree of\nnumerical stability is derived. We embed our observations into a coherent\npresentation of the theoretical background of LSMC in the insurance setting.\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2018 22:09:34 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 07:17:19 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Wei\u00df", "Christian", ""], ["Nikoli\u0107", "Zoran", ""]]}, {"id": "1811.08726", "submitter": "Jian-Huang She", "authors": "Jian-Huang She, and Dan Grecu", "title": "Neural Network for CVA: Learning Future Values", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP q-fin.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new challenge to quantitative finance after the recent financial crisis is\nthe study of credit valuation adjustment (CVA), which requires modeling of the\nfuture values of a portfolio. In this paper, following recent work in [Weinan\nE(2017), Han(2017)], we apply deep learning to attack this problem. The future\nvalues are parameterized by neural networks, and the parameters are then\ndetermined through optimization. Two concrete products are studied: Bermudan\nswaption and Mark-to-Market cross-currency swap. We obtain their expected\npositive/negative exposures, and further study the resulting functional form of\nfuture values. Such an approach represents a new framework for modeling XVA,\nand it also sheds new lights on other methods like American Monte Carlo.\n", "versions": [{"version": "v1", "created": "Wed, 21 Nov 2018 13:43:16 GMT"}], "update_date": "2018-11-22", "authors_parsed": [["She", "Jian-Huang", ""], ["Grecu", "Dan", ""]]}, {"id": "1811.08773", "submitter": "Michael Harre", "authors": "Michael S. Harre", "title": "Entropy and Transfer Entropy: The Dow Jones and the build up to the 1997\n  Asian Crisis", "comments": "11 pages, 5 figures. econophysics conference", "journal-ref": "Proceedings of the International Conference on Social Modeling and\n  Simulation, plus Econophysics Colloquium, 2014, pages 15-25", "doi": "10.1007/978-3-319-20591-5_2", "report-no": null, "categories": "q-fin.ST q-fin.CP q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entropy measures in their various incarnations play an important role in the\nstudy of stochastic time series providing important insights into both the\ncorrelative and the causative structure of the stochastic relationships between\nthe individual components of a system. Recent applications of entropic\ntechniques and their linear progenitors such as Pearson correlations and\nGranger causality have have included both normal as well as critical periods in\na system's dynamical evolution. Here I measure the entropy, Pearson correlation\nand transfer entropy of the intra-day price changes of the Dow Jones Industrial\nAverage in the period immediately leading up to and including the Asian\nfinancial crisis and subsequent mini-crash of the DJIA on the 27th October\n1997. I use a novel variation of transfer entropy that dynamically adjusts to\nthe arrival rate of individual prices and does not require the binning of data\nto show that quite different relationships emerge from those given by the\nconventional Pearson correlations between equities. These preliminary results\nillustrate how this modified form of the TE compares to results using Pearson\ncorrelation.\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2018 03:39:53 GMT"}], "update_date": "2018-11-22", "authors_parsed": [["Harre", "Michael S.", ""]]}, {"id": "1811.08782", "submitter": "Ali Al-Aradi", "authors": "Ali Al-Aradi, Adolfo Correia, Danilo Naiff, Gabriel Jardim, Yuri\n  Saporito", "title": "Solving Nonlinear and High-Dimensional Partial Differential Equations\n  via Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we apply the Deep Galerkin Method (DGM) described in Sirignano\nand Spiliopoulos (2018) to solve a number of partial differential equations\nthat arise in quantitative finance applications including option pricing,\noptimal execution, mean field games, etc. The main idea behind DGM is to\nrepresent the unknown function of interest using a deep neural network. A key\nfeature of this approach is the fact that, unlike other commonly used numerical\napproaches such as finite difference methods, it is mesh-free. As such, it does\nnot suffer (as much as other numerical methods) from the curse of\ndimensionality associated with highdimensional PDEs and PDE systems. The main\ngoals of this paper are to elucidate the features, capabilities and limitations\nof DGM by analyzing aspects of its implementation for a number of different\nPDEs and PDE systems. Additionally, we present: (1) a brief overview of PDEs in\nquantitative finance along with numerical methods for solving them; (2) a brief\noverview of deep learning and, in particular, the notion of neural networks;\n(3) a discussion of the theoretical foundations of DGM with a focus on the\njustification of why this method is expected to perform well.\n", "versions": [{"version": "v1", "created": "Wed, 21 Nov 2018 15:34:05 GMT"}], "update_date": "2018-11-22", "authors_parsed": [["Al-Aradi", "Ali", ""], ["Correia", "Adolfo", ""], ["Naiff", "Danilo", ""], ["Jardim", "Gabriel", ""], ["Saporito", "Yuri", ""]]}, {"id": "1811.09257", "submitter": "Ron TL Chan", "authors": "Tat Lung Chan and Nicholas Hale", "title": "Hedging and Pricing European-type, Early-Exercise and Discrete Barrier\n  Options using Algorithm for the Convolution of Legendre Series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP math.NA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper applies an algorithm for the convolution of compactly supported\nLegendre series (the CONLeg method) (cf. Hale and Townsend 2014a), to\npricing/hedging European-type, early-exercise and discrete-monitored barrier\noptions under a Levy process. The paper employs Chebfun (cf. Trefethen et al.\n2014) in computational finance and provides a quadrature-free approach by\napplying the Chebyshev series in financial modelling. A significant advantage\nof using the CONLeg method is to formulate option pricing and option Greek\ncurves rather than individual prices/values. Moreover, the CONLeg method can\nyield high accuracy in option pricing and hedging when the risk-free smooth\nprobability density function (PDF) is smooth/non-smooth. Finally, we show that\nour method can accurately price/hedge options deep in/out of the money and with\nvery long/short maturities. Compared with existing techniques, the CONLeg\nmethod performs either favourably or comparably in numerical experiments.\n", "versions": [{"version": "v1", "created": "Thu, 22 Nov 2018 17:58:26 GMT"}, {"version": "v2", "created": "Wed, 28 Nov 2018 15:43:24 GMT"}, {"version": "v3", "created": "Fri, 3 May 2019 09:10:30 GMT"}], "update_date": "2019-05-06", "authors_parsed": [["Chan", "Tat Lung", ""], ["Hale", "Nicholas", ""]]}, {"id": "1811.09549", "submitter": "Tom Jin", "authors": "Vangelis Bacoyannis, Vacslav Glukhov, Tom Jin, Jonathan Kochems, Doo\n  Re Song", "title": "Idiosyncrasies and challenges of data driven learning in electronic\n  trading", "comments": "Accepted for NIPS 2018 Workshop on Challenges and Opportunities for\n  AI in Financial Services: the Impact of Fairness, Explainability, Accuracy,\n  and Privacy", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.TR q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We outline the idiosyncrasies of neural information processing and machine\nlearning in quantitative finance. We also present some of the approaches we\ntake towards solving the fundamental challenges we face.\n", "versions": [{"version": "v1", "created": "Fri, 23 Nov 2018 16:40:16 GMT"}, {"version": "v2", "created": "Fri, 30 Nov 2018 18:33:25 GMT"}], "update_date": "2018-12-03", "authors_parsed": [["Bacoyannis", "Vangelis", ""], ["Glukhov", "Vacslav", ""], ["Jin", "Tom", ""], ["Kochems", "Jonathan", ""], ["Song", "Doo Re", ""]]}, {"id": "1811.10041", "submitter": "Zihao Zhang", "authors": "Zihao Zhang, Stefan Zohren, Stephen Roberts", "title": "BDLOB: Bayesian Deep Convolutional Neural Networks for Limit Order Books", "comments": "6 pages, 4 figures, 1 table, Third workshop on Bayesian Deep Learning\n  (NeurIPS 2018)", "journal-ref": "Third workshop on Bayesian Deep Learning (NeurIPS 2018)", "doi": null, "report-no": null, "categories": "q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We showcase how dropout variational inference can be applied to a large-scale\ndeep learning model that predicts price movements from limit order books\n(LOBs), the canonical data source representing trading and pricing movements.\nWe demonstrate that uncertainty information derived from posterior predictive\ndistributions can be utilised for position sizing, avoiding unnecessary trades\nand improving profits. Further, we test our models by using millions of\nobservations across several instruments and markets from the London Stock\nExchange. Our results suggest that those Bayesian techniques not only deliver\nuncertainty information that can be used for trading but also improve\npredictive performance as stochastic regularisers. To the best of our\nknowledge, we are the first to apply Bayesian networks to LOBs.\n", "versions": [{"version": "v1", "created": "Sun, 25 Nov 2018 15:53:31 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Zhang", "Zihao", ""], ["Zohren", "Stefan", ""], ["Roberts", "Stephen", ""]]}, {"id": "1811.10195", "submitter": "Th\\'arsis Tuani Pinto Souza", "authors": "Jonathan Manfield, Derek Lukacsko and Th\\'arsis T. P. Souza", "title": "Bull Bear Balance: A Cluster Analysis of Socially Informed Financial\n  Volatility", "comments": null, "journal-ref": "2017 IEEE Computing Conference, London, 2017, pp. 421-428", "doi": "10.1109/SAI.2017.8252134", "report-no": null, "categories": "q-fin.CP physics.data-an", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Using a method rooted in information theory, we present results that have\nidentified a large set of stocks for which social media can be informative\nregarding financial volatility. By clustering stocks based on the joint feature\nsets of social and financial variables, our research provides an important\ncontribution by characterizing the conditions in which social media signals can\nlead financial volatility. The results indicate that social media is most\ninformative about financial market volatility when the ratio of bullish to\nbearish sentiment is high, even when the number of messages is low. The\nrobustness of these findings is verified across 500 stocks from both NYSE and\nNASDAQ exchanges. The reported results are reproducible via an open-source\nlibrary for social-financial analysis made freely available.\n", "versions": [{"version": "v1", "created": "Mon, 26 Nov 2018 06:16:13 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Manfield", "Jonathan", ""], ["Lukacsko", "Derek", ""], ["Souza", "Th\u00e1rsis T. P.", ""]]}, {"id": "1811.11287", "submitter": "Ben Moews", "authors": "Ben Moews, J. Michael Herrmann, Gbenga Ibikunle", "title": "Lagged correlation-based deep learning for directional trend change\n  prediction in financial time series", "comments": "11 pages, 4 figures", "journal-ref": "Expert Syst. Appl. 120 (2019) 197-206", "doi": "10.1016/j.eswa.2018.11.027", "report-no": null, "categories": "q-fin.CP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Trend change prediction in complex systems with a large number of noisy time\nseries is a problem with many applications for real-world phenomena, with stock\nmarkets as a notoriously difficult to predict example of such systems. We\napproach predictions of directional trend changes via complex lagged\ncorrelations between them, excluding any information about the target series\nfrom the respective inputs to achieve predictions purely based on such\ncorrelations with other series. We propose the use of deep neural networks that\nemploy step-wise linear regressions with exponential smoothing in the\npreparatory feature engineering for this task, with regression slopes as trend\nstrength indicators for a given time interval. We apply this method to\nhistorical stock market data from 2011 to 2016 as a use case example of lagged\ncorrelations between large numbers of time series that are heavily influenced\nby externally arising new information as a random factor. The results\ndemonstrate the viability of the proposed approach, with state-of-the-art\naccuracies and accounting for the statistical significance of the results for\nadditional validation, as well as important implications for modern financial\neconomics.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 22:03:41 GMT"}, {"version": "v2", "created": "Thu, 29 Nov 2018 09:35:15 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["Moews", "Ben", ""], ["Herrmann", "J. Michael", ""], ["Ibikunle", "Gbenga", ""]]}]