[{"id": "1301.0109", "submitter": "Jia-Wen Gu", "authors": "Jia-Wen Gu, Wai-Ki Ching, Tak-Kuen Siu and Harry Zheng", "title": "On Reduced Form Intensity-based Model with Trigger Events", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Corporate defaults may be triggered by some major market news or events such\nas financial crises or collapses of major banks or financial institutions. With\na view to develop a more realistic model for credit risk analysis, we introduce\na new type of reduced-form intensity-based model that can incorporate the\nimpacts of both observable \"trigger\" events and economic environment on\ncorporate defaults. The key idea of the model is to augment a Cox process with\ntrigger events. Both single-default and multiple-default cases are considered\nin this paper. In the former case, a simple expression for the distribution of\nthe default time is obtained. Applications of the proposed model to price\ndefaultable bonds and multi-name Credit Default Swaps (CDSs) are provided.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jan 2013 17:17:06 GMT"}], "update_date": "2013-01-03", "authors_parsed": [["Gu", "Jia-Wen", ""], ["Ching", "Wai-Ki", ""], ["Siu", "Tak-Kuen", ""], ["Zheng", "Harry", ""]]}, {"id": "1301.0186", "submitter": "Jia-Wen Gu", "authors": "Jia-Wen Gu, Wai-Ki Ching, Tak-Kuen Siu and Harry Zheng", "title": "On Infectious Model for Dependent Defaults", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a two-sector Markovian infectious model, which is\nan extension of Greenwood's model. The central idea of this model is that the\ncausality of defaults of two sectors is in both direction, which enrich\ndependence dynamics. The Bayesian Information Criterion is adopted to compare\nthe proposed model with the two-sector model in credit literature using the\nreal data. We find that the newly proposed model is statistically better than\nthe model in past literature. We also introduce two measures: CRES and CRVaR to\ngive risk evaluation of our model.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jan 2013 08:35:33 GMT"}], "update_date": "2013-01-03", "authors_parsed": [["Gu", "Jia-Wen", ""], ["Ching", "Wai-Ki", ""], ["Siu", "Tak-Kuen", ""], ["Zheng", "Harry", ""]]}, {"id": "1301.3118", "submitter": "Qasim  Nasar-Ullah", "authors": "Qasim Nasar-Ullah", "title": "A parallel implementation of a derivative pricing model incorporating\n  SABR calibration and probability lookup tables", "comments": "21 pages, 16 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CE q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a high performance parallel implementation of a derivative\npricing model, within which we introduce a new parallel method for the\ncalibration of the industry standard SABR (stochastic-\\alpha \\beta \\rho)\nstochastic volatility model using three strike inputs. SABR calibration\ninvolves a non-linear three dimensional minimisation and parallelisation is\nachieved by incorporating several assumptions unique to the SABR class of\nmodels. Our calibration method is based on principles of surface intersection,\nguarantees convergence to a unique solution and operates by iteratively\nrefining a two dimensional grid with local mesh refinement. As part of our\npricing model we additionally present a fast parallel iterative algorithm for\nthe creation of dynamically sized cumulative probability lookup tables that are\nable to cap maximum estimated linear interpolation error. We optimise\nperformance for probability distributions that exhibit clustering of linear\ninterpolation error. We also make an empirical assessment of error propagation\nthrough our pricing model as a result of changes in accuracy parameters within\nthe pricing model's multiple algorithmic steps. Algorithms are implemented on a\nGPU (graphics processing unit) using Nvidia's Fermi architecture. The pricing\nmodel targets the evaluation of spread options using copula methods, however\nthe presented algorithms can be applied to a wider class of financial\ninstruments.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jan 2013 20:33:00 GMT"}], "update_date": "2013-01-15", "authors_parsed": [["Nasar-Ullah", "Qasim", ""]]}, {"id": "1301.4194", "submitter": "Ankit Dangi Mr.", "authors": "Ankit Dangi", "title": "Financial Portfolio Optimization: Computationally guided agents to\n  investigate, analyse and invest!?", "comments": "Thesis work under the guidance of Dr. Abhijit Kulkarni, Advanced\n  Analytics Lab. (SSO), SAS Research & Development, India. Submitted at Centre\n  for Modeling and Simulation, University of Pune for completion of Master of\n  Technology (M. Tech.) in Modeling and Simulation (M&S)", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PM cs.CE cs.NE q-fin.CP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Financial portfolio optimization is a widely studied problem in mathematics,\nstatistics, financial and computational literature. It adheres to determining\nan optimal combination of weights associated with financial assets held in a\nportfolio. In practice, it faces challenges by virtue of varying math.\nformulations, parameters, business constraints and complex financial\ninstruments. Empirical nature of data is no longer one-sided; thereby\nreflecting upside and downside trends with repeated yet unidentifiable cyclic\nbehaviours potentially caused due to high frequency volatile movements in asset\ntrades. Portfolio optimization under such circumstances is theoretically and\ncomputationally challenging. This work presents a novel mechanism to reach an\noptimal solution by encoding a variety of optimal solutions in a solution bank\nto guide the search process for the global investment objective formulation. It\nconceptualizes the role of individual solver agents that contribute optimal\nsolutions to a bank of solutions, a super-agent solver that learns from the\nsolution bank, and, thus reflects a knowledge-based computationally guided\nagents approach to investigate, analyse and reach to optimal solution for\ninformed investment decisions.\n  Conceptual understanding of classes of solver agents that represent varying\nproblem formulations and, mathematically oriented deterministic solvers along\nwith stochastic-search driven evolutionary and swarm-intelligence based\ntechniques for optimal weights are discussed. Algorithmic implementation is\npresented by an enhanced neighbourhood generation mechanism in Simulated\nAnnealing algorithm. A framework for inclusion of heuristic knowledge and human\nexpertise from financial literature related to investment decision making\nprocess is reflected via introduction of controlled perturbation strategies\nusing a decision matrix for neighbourhood generation.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jan 2013 19:26:02 GMT"}], "update_date": "2013-01-21", "authors_parsed": [["Dangi", "Ankit", ""]]}, {"id": "1301.4442", "submitter": "Andrey Itkin", "authors": "Igor Halperin and Andrey Itkin", "title": "USLV: Unspanned Stochastic Local Volatility Model", "comments": "Sections 3.2 and 3.3 are re-written, 3 figures added", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PR q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new framework for modeling stochastic local volatility, with\npotential applications to modeling derivatives on interest rates, commodities,\ncredit, equity, FX etc., as well as hybrid derivatives. Our model extends the\nlinearity-generating unspanned volatility term structure model by Carr et al.\n(2011) by adding a local volatility layer to it. We outline efficient numerical\nschemes for pricing derivatives in this framework for a particular four-factor\nspecification (two \"curve\" factors plus two \"volatility\" factors). We show that\nthe dynamics of such a system can be approximated by a Markov chain on a\ntwo-dimensional space (Z_t,Y_t), where coordinates Z_t and Y_t are given by\ndirect (Kroneker) products of values of pairs of curve and volatility factors,\nrespectively. The resulting Markov chain dynamics on such partly \"folded\" state\nspace enables fast pricing by the standard backward induction. Using a\nnonparametric specification of the Markov chain generator, one can accurately\nmatch arbitrary sets of vanilla option quotes with different strikes and\nmaturities. Furthermore, we consider an alternative formulation of the model in\nterms of an implied time change process. The latter is specified\nnonparametrically, again enabling accurate calibration to arbitrary sets of\nvanilla option quotes.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jan 2013 17:39:24 GMT"}, {"version": "v2", "created": "Wed, 27 Mar 2013 21:10:48 GMT"}], "update_date": "2013-03-29", "authors_parsed": [["Halperin", "Igor", ""], ["Itkin", "Andrey", ""]]}, {"id": "1301.5007", "submitter": "Francois Roueff", "authors": "Ban Zheng (LTCI, FiQuant), Fran\\c{c}ois Roueff (LTCI), Fr\\'ed\\'eric\n  Abergel (FiQuant, MAS)", "title": "Ergodicity and scaling limit of a constrained multivariate Hawkes\n  process", "comments": "32 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP q-fin.CP q-fin.TR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a multivariate Hawkes process with constraints on its\nconditional density. It is a multivariate point process with conditional\nintensity similar to that of a multivariate Hawkes process but certain events\nare forbidden with respect to boundary conditions on a multidimensional\nconstraint variable, whose evolution is driven by the point process. We study\nthis process in the special case where the fertility function is exponential so\nthat the process is entirely described by an underlying Markov chain, which\nincludes the constraint variable. Some conditions on the parameters are\nestablished to ensure the ergodicity of the chain. Moreover, scaling limits are\nderived for the integrated point process. This study is primarily motivated by\nthe stochastic modelling of a limit order book for high frequency financial\ndata analysis.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jan 2013 15:15:31 GMT"}, {"version": "v2", "created": "Thu, 13 Feb 2014 19:42:15 GMT"}], "update_date": "2014-02-14", "authors_parsed": [["Zheng", "Ban", "", "LTCI, FiQuant"], ["Roueff", "Fran\u00e7ois", "", "LTCI"], ["Abergel", "Fr\u00e9d\u00e9ric", "", "FiQuant, MAS"]]}]