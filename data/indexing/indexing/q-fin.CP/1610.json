[{"id": "1610.00256", "submitter": "Chris Kenyon", "authors": "Andrew Green and Chris Kenyon", "title": "XVA at the Exercise Boundary", "comments": "15 pages, 8 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PR q-fin.CP q-fin.PM q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  XVA is a material component of a trade valuation and hence it must impact the\ndecision to exercise options within a given netting set. This is true for both\nunsecured trades and secured / cleared trades where KVA and MVA play a material\nrole even if CVA and FVA do not. However, this effect has frequently been\nignored in XVA models and indeed in exercise decisions made by option owners.\nThis paper describes how XVA impacts the exercise decision and how this can be\nreadily evaluated using regression techniques (Longstaff and Schwartz 2001).\nThe paper then assesses the materiality of the impact of XVA at the exercise\nboundary on swaption examples.\n", "versions": [{"version": "v1", "created": "Sun, 2 Oct 2016 10:25:56 GMT"}], "update_date": "2016-10-04", "authors_parsed": [["Green", "Andrew", ""], ["Kenyon", "Chris", ""]]}, {"id": "1610.00795", "submitter": "Daniele Petrone", "authors": "Daniele Petrone and Vito Latora", "title": "A dynamic approach merging network theory and credit risk techniques to\n  assess systemic risk in financial networks", "comments": "8 pages, 5 figures, 1 table", "journal-ref": "Scientific Reports 8 (2018) 5561", "doi": "10.1038/s41598-018-23689-5", "report-no": null, "categories": "q-fin.CP q-fin.RM q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The interconnectedness of financial institutions affects instability and\ncredit crises. To quantify systemic risk we introduce here the PD model, a\ndynamic model that combines credit risk techniques with a contagion mechanism\non the network of exposures among banks. A potential loss distribution is\nobtained through a multi-period Monte Carlo simulation that considers the\nprobability of default (PD) of the banks and their tendency of defaulting in\nthe same time interval. A contagion process increases the PD of banks exposed\ntoward distressed counterparties. The systemic risk is measured by statistics\nof the loss distribution, while the contribution of each node is quantified by\nthe new measures PDRank and PDImpact. We illustrate how the model works on the\nnetwork of the European Global Systemically Important Banks. For a certain\nrange of the banks' capital and of their assets volatility, our results reveal\nthe emergence of a strong contagion regime where lower default correlation\nbetween banks corresponds to higher losses. This is the opposite of the\ndiversification benefits postulated by standard credit risk models used by\nbanks and regulators who could therefore underestimate the capital needed to\novercome a period of crisis, thereby contributing to the financial system\ninstability.\n", "versions": [{"version": "v1", "created": "Mon, 3 Oct 2016 23:40:44 GMT"}, {"version": "v2", "created": "Sun, 8 Apr 2018 12:34:28 GMT"}], "update_date": "2018-04-10", "authors_parsed": [["Petrone", "Daniele", ""], ["Latora", "Vito", ""]]}, {"id": "1610.01946", "submitter": "Seyed Amir Hejazi", "authors": "Seyed Amir Hejazi, Kenneth R. Jackson", "title": "Efficient Valuation of SCR via a Neural Network Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As part of the new regulatory framework of Solvency II, introduced by the\nEuropean Union, insurance companies are required to monitor their solvency by\ncomputing a key risk metric called the Solvency Capital Requirement (SCR). The\nofficial description of the SCR is not rigorous and has lead researchers to\ndevelop their own mathematical frameworks for calculation of the SCR. These\nframeworks are complex and are difficult to implement. Recently, Bauer et al.\nsuggested a nested Monte Carlo (MC) simulation framework to calculate the SCR.\nBut the proposed MC framework is computationally expensive even for a simple\ninsurance product. In this paper, we propose incorporating a neural network\napproach into the nested simulation framework to significantly reduce the\ncomputational complexity in the calculation. We study the performance of our\nneural network approach in estimating the SCR for a large portfolio of an\nimportant class of insurance products called Variable Annuities (VAs). Our\nexperiments show that the proposed neural network approach is both efficient\nand accurate.\n", "versions": [{"version": "v1", "created": "Thu, 6 Oct 2016 17:01:07 GMT"}], "update_date": "2016-10-07", "authors_parsed": [["Hejazi", "Seyed Amir", ""], ["Jackson", "Kenneth R.", ""]]}, {"id": "1610.03050", "submitter": "Damien Ackerer", "authors": "Damien Ackerer and Thibault Vatter", "title": "Dependent Defaults and Losses with Factor Copula Models", "comments": "29 pages, 11 figures, 3 tables", "journal-ref": "Dependence Modeling, Volume 5, Issue 1, Pages 375-399, 2017", "doi": "10.1515/demo-2017-0022", "report-no": null, "categories": "q-fin.MF q-fin.CP q-fin.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a class of flexible and tractable static factor models for the\nterm structure of joint default probabilities, the factor copula models. These\nhigh-dimensional models remain parsimonious with pair-copula constructions, and\nnest many standard models as special cases. The loss distribution of a\nportfolio of contingent claims can be exactly and efficiently computed when\nindividual losses are discretely supported on a finite grid. Numerical examples\nstudy the key features affecting the loss distribution and multi-name credit\nderivatives prices. An empirical exercise illustrates the flexibility of our\napproach by fitting credit index tranche prices.\n", "versions": [{"version": "v1", "created": "Mon, 10 Oct 2016 19:57:28 GMT"}, {"version": "v2", "created": "Sun, 24 Sep 2017 19:10:49 GMT"}, {"version": "v3", "created": "Sun, 10 Dec 2017 11:11:41 GMT"}, {"version": "v4", "created": "Wed, 17 Jan 2018 19:37:30 GMT"}], "update_date": "2018-01-19", "authors_parsed": [["Ackerer", "Damien", ""], ["Vatter", "Thibault", ""]]}, {"id": "1610.03086", "submitter": "Julien Hok", "authors": "Julien Hok and Tat Lung Chan", "title": "Option pricing with Legendre polynomials", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.MF q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Here we develop an option pricing method based on Legendre series expansion\nof the density function. The key insight, relying on the close relation of the\ncharacteristic function with the series coefficients, allows to recover the\ndensity function rapidly and accurately. Based on this representation for the\ndensity function, approximations formulas for pricing European type options are\nderived. To obtain highly accurate result for European call option, the\nimplementation involves integrating high degree Legendre polynomials against\nexponential function. Some numerical instabilities arise because of serious\nsubtractive cancellations in its formulation (96) in proposition 7.1. To\novercome this difficulty, we rewrite this quantity as solution of a\nsecond-order linear difference equation and solve it using a robust and stable\nalgorithm from Olver. Derivation of the pricing method has been accompanied by\nan error analysis. Errors bounds have been derived and the study relies more on\nsmoothness properties which are not provided by the payoff? functions, but\nrather by the density function of the underlying stochastic models. This is\nparticularly relevant for options pricing where the payoff of the contract are\ngenerally not smooth functions. The numerical experiments on a class of models\nwidely used in quantitative finance show exponential convergence.\n", "versions": [{"version": "v1", "created": "Mon, 10 Oct 2016 20:34:44 GMT"}, {"version": "v2", "created": "Sun, 19 Mar 2017 09:49:50 GMT"}], "update_date": "2017-03-21", "authors_parsed": [["Hok", "Julien", ""], ["Chan", "Tat Lung", ""]]}, {"id": "1610.05383", "submitter": "Marcello Rambaldi", "authors": "Marcello Rambaldi, Vladimir Filimonov, Fabrizio Lillo", "title": "Detection of intensity bursts using Hawkes processes: an application to\n  high frequency financial data", "comments": null, "journal-ref": "Phys. Rev. E 97, 032318 (2018)", "doi": "10.1103/PhysRevE.97.032318", "report-no": null, "categories": "q-fin.TR q-fin.CP q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a stationary point process, an intensity burst is defined as a short\ntime period during which the number of counts is larger than the typical count\nrate. It might signal a local non-stationarity or the presence of an external\nperturbation to the system. In this paper we propose a novel procedure for the\ndetection of intensity bursts within the Hawkes process framework. By using a\nmodel selection scheme we show that our procedure can be used to detect\nintensity bursts when both their occurrence time and their total number is\nunknown. Moreover, the initial time of the burst can be determined with a\nprecision given by the typical inter-event time. We apply our methodology to\nthe mid-price change in FX markets showing that these bursts are frequent and\nthat only a relatively small fraction is associated to news arrival. We show\nlead-lag relations in intensity burst occurrence across different FX rates and\nwe discuss their relation with price jumps.\n", "versions": [{"version": "v1", "created": "Mon, 17 Oct 2016 23:41:28 GMT"}], "update_date": "2018-04-04", "authors_parsed": [["Rambaldi", "Marcello", ""], ["Filimonov", "Vladimir", ""], ["Lillo", "Fabrizio", ""]]}, {"id": "1610.07694", "submitter": "Nicolas Langren\\'e", "authors": "Rongju Zhang, Nicolas Langren\\'e, Yu Tian, Zili Zhu, Fima Klebaner,\n  Kais Hamza", "title": "Dynamic portfolio optimization with liquidity cost and market impact: a\n  simulation-and-regression approach", "comments": "25 pages, 4 figures", "journal-ref": "Quantitative Finance 19(3) 519-532 (2019)", "doi": "10.1080/14697688.2018.1524155", "report-no": null, "categories": "q-fin.PM q-fin.CP q-fin.TR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a simulation-and-regression method for solving dynamic portfolio\nallocation problems in the presence of general transaction costs, liquidity\ncosts and market impacts. This method extends the classical least squares Monte\nCarlo algorithm to incorporate switching costs, corresponding to transaction\ncosts and transient liquidity costs, as well as multiple endogenous state\nvariables, namely the portfolio value and the asset prices subject to permanent\nmarket impacts. To do so, we improve the accuracy of the control randomization\napproach in the case of discrete controls, and propose a global iteration\nprocedure to further improve the allocation estimates. We validate our\nnumerical method by solving a realistic cash-and-stock portfolio with a\npower-law liquidity model. We quantify the certainty equivalent losses\nassociated with ignoring liquidity effects, and illustrate how our dynamic\nallocation protects the investor's capital under illiquid market conditions.\nLastly, we analyze, under different liquidity conditions, the sensitivities of\ncertainty equivalent returns and optimal allocations with respect to trading\nvolume, stock price volatility, initial investment amount, risk-aversion level\nand investment horizon.\n", "versions": [{"version": "v1", "created": "Tue, 25 Oct 2016 00:57:09 GMT"}, {"version": "v2", "created": "Fri, 20 Oct 2017 05:44:15 GMT"}, {"version": "v3", "created": "Tue, 4 Jun 2019 02:28:09 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Zhang", "Rongju", ""], ["Langren\u00e9", "Nicolas", ""], ["Tian", "Yu", ""], ["Zhu", "Zili", ""], ["Klebaner", "Fima", ""], ["Hamza", "Kais", ""]]}, {"id": "1610.09085", "submitter": "Youtoh Imai", "authors": "Takuji Arai and Yuto Imai", "title": "On the difference between locally risk-minimizing and delta hedging\n  strategies for exponential L\\'evy models", "comments": "11 pages and 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss the difference between locally risk-minimizing and delta hedging\nstrategies for exponential L\\'evy models, where delta hedging strategies in\nthis paper are defined under the minimal martingale measure. We give firstly\nmodel-independent upper estimations for the difference. In addition we show\nnumerical examples for two typical exponential L\\'evy models: Merton models and\nvariance gamma models.\n", "versions": [{"version": "v1", "created": "Fri, 28 Oct 2016 05:56:16 GMT"}], "update_date": "2016-10-31", "authors_parsed": [["Arai", "Takuji", ""], ["Imai", "Yuto", ""]]}, {"id": "1610.09622", "submitter": "Karel in 't Hout", "authors": "Karel in 't Hout, Radoslav Valkov", "title": "Numerical study of splitting methods for American option valuation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with the numerical approximation of American-style option\nvalues governed by partial differential complementarity problems. For a variety\nof one- and two-asset American options we investigate by ample numerical\nexperiments the temporal convergence behaviour of three modern splitting\nmethods: the explicit payoff approach, the Ikonen-Toivanen approach and the\nPeaceman-Rachford method. In addition, the temporal accuracy of these splitting\nmethods is compared to that of the penalty approach.\n", "versions": [{"version": "v1", "created": "Sun, 30 Oct 2016 09:22:39 GMT"}], "update_date": "2016-11-01", "authors_parsed": [["Hout", "Karel in 't", ""], ["Valkov", "Radoslav", ""]]}]