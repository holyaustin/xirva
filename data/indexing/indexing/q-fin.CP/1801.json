[{"id": "1801.00091", "submitter": "Nicole Langballe", "authors": "Raeid Saqur and Nicole Langballe", "title": "PrivySense: $\\underline{Pri}$ce $\\underline{V}$olatilit$\\underline{y}$\n  based $\\underline{Sen}$timent$\\underline{s}$ $\\underline{E}$stimation from\n  Financial News using Machine Learning", "comments": "Initial draft, updates are w.i.p", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As machine learning ascends the peak of computer science zeitgeist, the usage\nand experimentation with sentiment analysis using various forms of textual data\nseems pervasive. The effect is especially pronounced in formulating securities\ntrading strategies, due to a plethora of reasons including the relative ease of\nimplementation and the abundance of academic research suggesting automated\nsentiment analysis can be productively used in trading strategies. The source\ndata for such analyzers ranges a broad spectrum like social media feeds,\nmicro-blogs, real-time news feeds, ex-post financial data etc. The abstract\ntechnique underlying these analyzers involve supervised learning of sentiment\nclassification where the classifier is trained on annotated source corpus, and\naccuracy is measured by testing how well the classifiers generalizes on unseen\ntest data from the corpus. Post training, and validation of fitted models, the\nclassifiers are used to execute trading strategies, and the corresponding\nreturns are compared with appropriate benchmark returns (for e.g., the S&P500\nreturns).\n  In this paper, we introduce $\\underline{a\\ novel\\ technique\\ of\\ using\\\nprice\\ volatilities\\ to\\ empirically\\ determine\\ the\\ sentiment\\ in\\ news\\\ndata}$, instead of the traditional reverse approach. We also perform meta\nsentiment analysis by evaluating the efficacy of existing sentiment classifiers\nand the precise definition of sentiment from securities trading context. We\nscrutinize the efficacy of using human-annotated sentiment classification and\nthe tacit assumptions that introduces subjective bias in existing financial\nnews sentiment classifiers.\n", "versions": [{"version": "v1", "created": "Sat, 30 Dec 2017 06:56:37 GMT"}, {"version": "v2", "created": "Wed, 21 Feb 2018 22:25:38 GMT"}], "update_date": "2018-02-23", "authors_parsed": [["Saqur", "Raeid", ""], ["Langballe", "Nicole", ""]]}, {"id": "1801.00362", "submitter": "Vadim Kaushansky", "authors": "Vadim Kaushansky, Alexander Lipton, Christoph Reisinger", "title": "Transition probability of Brownian motion in the octant and its\n  application to default modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive a semi-analytic formula for the transition probability of\nthree-dimensional Brownian motion in the positive octant with absorption at the\nboundaries. Separation of variables in spherical coordinates leads to an\neigenvalue problem for the resulting boundary value problem in the two angular\ncomponents. The main theoretical result is a solution to the original problem\nexpressed as an expansion into special functions and an eigenvalue which has to\nbe chosen to allow a matching of the boundary condition. We discuss and test\nseveral computational methods to solve a finite-dimensional approximation to\nthis nonlinear eigenvalue problem. Finally, we apply our results to the\ncomputation of default probabilities and credit valuation adjustments in a\nstructural credit model with mutual liabilities.\n", "versions": [{"version": "v1", "created": "Sun, 31 Dec 2017 21:56:11 GMT"}, {"version": "v2", "created": "Wed, 23 May 2018 16:57:24 GMT"}], "update_date": "2018-05-24", "authors_parsed": [["Kaushansky", "Vadim", ""], ["Lipton", "Alexander", ""], ["Reisinger", "Christoph", ""]]}, {"id": "1801.01243", "submitter": "Johan Dahlin PhD", "authors": "Johan Dahlin, Adrian Wills, Brett Ninness", "title": "Constructing Metropolis-Hastings proposals using damped BFGS updates", "comments": "16 pages, 2 figures. Accepted for publication in the Proceedings of\n  the 18th IFAC Symposium on System Identification (SYSID)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The computation of Bayesian estimates of system parameters and functions of\nthem on the basis of observed system performance data is a common problem\nwithin system identification. This is a previously studied issue where\nstochastic simulation approaches have been examined using the popular\nMetropolis--Hastings (MH) algorithm. This prior study has identified a\nrecognised difficulty of tuning the {proposal distribution so that the MH\nmethod provides realisations with sufficient mixing to deliver efficient\nconvergence. This paper proposes and empirically examines a method of tuning\nthe proposal using ideas borrowed from the numerical optimisation literature\naround efficient computation of Hessians so that gradient and curvature\ninformation of the target posterior can be incorporated in the proposal.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jan 2018 04:33:57 GMT"}, {"version": "v2", "created": "Tue, 8 May 2018 00:06:21 GMT"}], "update_date": "2018-05-09", "authors_parsed": [["Dahlin", "Johan", ""], ["Wills", "Adrian", ""], ["Ninness", "Brett", ""]]}, {"id": "1801.01811", "submitter": "Torsten Trimborn", "authors": "Torsten Trimborn, Philipp Otte, Simon Cramer, Max Beikirch, Emma\n  Pabich, Martin Frank", "title": "SABCEMM-A Simulator for Agent-Based Computational Economic Market Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP econ.EM q-fin.GN q-fin.TR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the simulation tool SABCEMM (Simulator for Agent-Based\nComputational Economic Market Models) for agent-based computational economic\nmarket (ABCEM) models. Our simulation tool is implemented in C++ and we can\neasily run ABCEM models with several million agents. The object-oriented\nsoftware design enables the isolated implementation of building blocks for\nABCEM models, such as agent types and market mechanisms. The user can design\nand compare ABCEM models in a unified environment by recombining existing\nbuilding blocks using the XML-based SABCEMM configuration file. We introduce an\nabstract ABCEM model class which our simulation tool is built upon.\nFurthermore, we present the software architecture as well as computational\naspects of SABCEMM. Here, we focus on the efficiency of SABCEMM with respect to\nthe run time of our simulations. We show the great impact of different random\nnumber generators on the run time of ABCEM models. The code and documentation\nis published on GitHub at https://github.com/SABCEMM/SABCEMM, such that all\nresults can be reproduced by the reader.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jan 2018 16:08:14 GMT"}, {"version": "v2", "created": "Tue, 9 Oct 2018 23:10:22 GMT"}], "update_date": "2018-10-11", "authors_parsed": [["Trimborn", "Torsten", ""], ["Otte", "Philipp", ""], ["Cramer", "Simon", ""], ["Beikirch", "Max", ""], ["Pabich", "Emma", ""], ["Frank", "Martin", ""]]}, {"id": "1801.03018", "submitter": "Yun-Cheng Tsai", "authors": "Yun-Cheng Tsai, Jun-Hao Chen, Jun-Jie Wang", "title": "Predict Forex Trend via Convolutional Neural Networks", "comments": "30 pages, 41 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning is an effective approach to solving image recognition problems.\nPeople draw intuitive conclusions from trading charts; this study uses the\ncharacteristics of deep learning to train computers in imitating this kind of\nintuition in the context of trading charts. The three steps involved are as\nfollows: 1. Before training, we pre-process the input data from quantitative\ndata to images. 2. We use a convolutional neural network (CNN), a type of deep\nlearning, to train our trading model. 3. We evaluate the model's performance in\nterms of the accuracy of classification. A trading model is obtained with this\napproach to help devise trading strategies. The main application is designed to\nhelp clients automatically obtain personalized trading strategies.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jan 2018 16:10:47 GMT"}], "update_date": "2018-01-10", "authors_parsed": [["Tsai", "Yun-Cheng", ""], ["Chen", "Jun-Hao", ""], ["Wang", "Jun-Jie", ""]]}, {"id": "1801.03523", "submitter": "Fernando Fernandes Neto", "authors": "Fernando Fernandes Neto", "title": "Generative Models for Stochastic Processes Using Convolutional Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.NE physics.comp-ph q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The present paper aims to demonstrate the usage of Convolutional Neural\nNetworks as a generative model for stochastic processes, enabling researchers\nfrom a wide range of fields (such as quantitative finance and physics) to\ndevelop a general tool for forecasts and simulations without the need to\nidentify/assume a specific system structure or estimate its parameters.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jan 2018 03:35:20 GMT"}], "update_date": "2018-01-12", "authors_parsed": [["Neto", "Fernando Fernandes", ""]]}, {"id": "1801.05597", "submitter": "Takuji Arai", "authors": "Takuji Arai, Yuto Imai and Ryo Nakashima", "title": "Numerical analysis on quadratic hedging strategies for normal inverse\n  Gaussian models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The authors aim to develop numerical schemes of the two representative\nquadratic hedging strategies: locally risk minimizing and mean-variance hedging\nstrategies, for models whose asset price process is given by the exponential of\na normal inverse Gaussian process, using the results of Arai et al. \\cite{AIS},\nand Arai and Imai. Here normal inverse Gaussian process is a framework of\nL\\'evy processes frequently appeared in financial literature. In addition, some\nnumerical results are also introduced.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jan 2018 08:59:19 GMT"}], "update_date": "2018-01-18", "authors_parsed": [["Arai", "Takuji", ""], ["Imai", "Yuto", ""], ["Nakashima", "Ryo", ""]]}, {"id": "1801.05752", "submitter": "Rilwan Adewoyin", "authors": "Rilwan Adewoyin", "title": "Part 1: Training Sets & ASG Transforms", "comments": "This was an undergraduate project, subsequently the research was not\n  exhaustive", "journal-ref": null, "doi": "10.13140/RG.2.2.25313.81760", "report-no": null, "categories": "q-fin.CP q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, I discuss a method to tackle the issues arising from the small\ndata-sets available to data-scientists when building price predictive\nalgorithms that use monthly/quarterly macro-financial indicators. I approach\nthis by training separate classifiers on the equivalent dataset from a range of\ncountries. Using these classifiers, a three level meta learning algorithm (MLA)\nis developed. I develop a transform, ASG, to create a country agnostic proxy\nfor the macro-financial indicators. Using these proposed methods, I investigate\nthe degree to which a predictive algorithm for the US 5Y bond price,\npredominantly using macro-financial indicators, can outperform an identical\nalgorithm which only uses statistics deriving from previous price.\n  This was an undergraduate project, subsequently the research was not\nexhaustive.\n", "versions": [{"version": "v1", "created": "Fri, 15 Dec 2017 16:59:20 GMT"}, {"version": "v2", "created": "Wed, 27 May 2020 12:25:41 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Adewoyin", "Rilwan", ""]]}, {"id": "1801.05770", "submitter": "Anas Yassine", "authors": "Anas Yassine (MSFGR), Abdelmadjid Ibenrissoul", "title": "The macroeconomics determinants of default of the borrowers: The case of\n  Moroccan bank", "comments": "in French", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article aims to explore an empirical approach to analyze the\nmacroeconomicsdeterminants of default of borrowers. For this purpose, we have\nmeasured the impact of the adverse economic conditions on the degradation of\nthe credit portfolio quality.In our paper, we have shed more light on the\nquestion of the aggravation of default rate. For this, we have undertaken\neconometric modeling of the default rate distribution of a Moroccan bank while\nwe inspired from some studies carried out. Our findings demonstrate that the\ndecline in the economic situation has a positive impact on default of\nborrowers. Hence, the bank also has responsibility for monitoring the adverse\neconomic conditions.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jan 2018 09:53:49 GMT"}, {"version": "v2", "created": "Mon, 22 Jan 2018 09:33:14 GMT"}, {"version": "v3", "created": "Wed, 28 Mar 2018 13:57:14 GMT"}], "update_date": "2018-03-29", "authors_parsed": [["Yassine", "Anas", "", "MSFGR"], ["Ibenrissoul", "Abdelmadjid", ""]]}, {"id": "1801.05947", "submitter": "Tetsuya Takaishi", "authors": "Tetsuya Takaishi", "title": "Large-Scale Simulation of Multi-Asset Ising Financial Markets", "comments": "10 pages, 9 figures", "journal-ref": "J. Phys.: Conf. Ser. 820 (2017) 012016", "doi": "10.1088/1742-6596/820/1/012016", "report-no": null, "categories": "q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We perform a large-scale simulation of an Ising-based financial market model\nthat includes 300 asset time series. The financial system simulated by the\nmodel shows a fat-tailed return distribution and volatility clustering and\nexhibits unstable periods indicated by the volatility index measured as the\naverage of absolute-returns. Moreover, we determine that the cumulative risk\nfraction, which measures the system risk, changes at high volatility periods.\nWe also calculate the inverse participation ratio (IPR) and its higher-power\nversion, IPR6, from the absolute-return cross-correlation matrix. Finally, we\nshow that the IPR and IPR6 also change at high volatility periods.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jan 2018 06:00:44 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Takaishi", "Tetsuya", ""]]}, {"id": "1801.06077", "submitter": "Igor Halperin", "authors": "Igor Halperin", "title": "The QLBS Q-Learner Goes NuQLear: Fitted Q Iteration, Inverse RL, and\n  Option Portfolios", "comments": "18 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The QLBS model is a discrete-time option hedging and pricing model that is\nbased on Dynamic Programming (DP) and Reinforcement Learning (RL). It combines\nthe famous Q-Learning method for RL with the Black-Scholes (-Merton) model's\nidea of reducing the problem of option pricing and hedging to the problem of\noptimal rebalancing of a dynamic replicating portfolio for the option, which is\nmade of a stock and cash. Here we expand on several NuQLear (Numerical\nQ-Learning) topics with the QLBS model. First, we investigate the performance\nof Fitted Q Iteration for a RL (data-driven) solution to the model, and\nbenchmark it versus a DP (model-based) solution, as well as versus the BSM\nmodel. Second, we develop an Inverse Reinforcement Learning (IRL) setting for\nthe model, where we only observe prices and actions (re-hedges) taken by a\ntrader, but not rewards. Third, we outline how the QLBS model can be used for\npricing portfolios of options, rather than a single option in isolation, thus\nproviding its own, data-driven and model independent solution to the (in)famous\nvolatility smile problem of the Black-Scholes model.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jan 2018 15:51:09 GMT"}], "update_date": "2018-01-19", "authors_parsed": [["Halperin", "Igor", ""]]}, {"id": "1801.06141", "submitter": "Alan Lewis", "authors": "Yiannis A. Papadopoulos and Alan L. Lewis", "title": "A First Option Calibration of the GARCH Diffusion Model by a PDE Method", "comments": "29 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time-series calibrations often suggest that the GARCH diffusion model could\nalso be a suitable candidate for option (risk-neutral) calibration. But unlike\nthe popular Heston model, it lacks a fast, semi-analytic solution for the\npricing of vanilla options, perhaps the main reason why it is not used in this\nway. In this paper we show how an efficient finite difference-based PDE solver\ncan effectively replace analytical solutions, enabling accurate option\ncalibrations in less than a minute. The proposed pricing engine is shown to be\nrobust under a wide range of model parameters and combines smoothly with\nblack-box optimizers. We use this approach to produce a first PDE calibration\nof the GARCH diffusion model to SPX options and present some benchmark results\nfor future reference.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jan 2018 17:40:16 GMT"}], "update_date": "2018-01-19", "authors_parsed": [["Papadopoulos", "Yiannis A.", ""], ["Lewis", "Alan L.", ""]]}, {"id": "1801.06737", "submitter": "Chung-Han Hsieh", "authors": "Chung-Han Hsieh, B. Ross Barmish, John A. Gubner", "title": "At What Frequency Should the Kelly Bettor Bet?", "comments": "To appear in Proceedings of the IEEE American Control Conference\n  (ACC), 2018", "journal-ref": "Proceedings of the IEEE American Control Conference (ACC), 2018", "doi": "10.23919/ACC.2018.8431224", "report-no": null, "categories": "math.OC q-fin.CP q-fin.MF q-fin.PM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of optimizing the betting frequency in a dynamic game\nsetting using Kelly's celebrated expected logarithmic growth criterion as the\nperformance metric. The game is defined by a sequence of bets with independent\nand identically distributed returns X(k). The bettor selects the fraction of\nwealth K wagered at k = 0 and waits n steps before updating the bet size.\nBetween updates, the proceeds from the previous bets remain at risk in the\nspirit of \"buy and hold.\" Within this context, the main questions we consider\nare as follows: How does the optimal performance, we call it gn*, change with\nn? Does the high-frequency case, n = 1, always lead to the best performance?\nWhat are the effects of accrued interest and transaction costs? First, we\nprovide rather complete answers to these questions for the important special\ncase when X(k) in {-1,1} is a Bernoulli random variable with probability p that\nX(k) = 1. This serves as an entry point for future research using a binomial\nlattice model for stock trading. The latter sections focus on more general\nprobability distributions for X(k) and two conjectures. The first conjecture is\nsimple to state: Absent transaction costs, gn* is non-increasing in n. The\nsecond conjecture involves the technical condition which we call the sufficient\nattractiveness inequality. We first prove that satisfaction of this inequality\nis sufficient to guarantee that the low-frequency bettor using large n can\nmatch the performance of the high-frequency bettor using n = 1. Subsequently,\nwe conjecture, and provide supporting evidence that this condition is also\nnecessary.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jan 2018 22:51:47 GMT"}, {"version": "v2", "created": "Tue, 21 Aug 2018 21:13:57 GMT"}], "update_date": "2018-08-23", "authors_parsed": [["Hsieh", "Chung-Han", ""], ["Barmish", "B. Ross", ""], ["Gubner", "John A.", ""]]}, {"id": "1801.07044", "submitter": "Ralph Rudd", "authors": "Ralph Rudd, Thomas A. McWalter, Joerg Kienitz, Eckhard Platen", "title": "Quantization Under the Real-world Measure: Fast and Accurate Valuation\n  of Long-dated Contracts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides a methodology for fast and accurate pricing of the\nlong-dated contracts that arise as the building blocks of insurance and pension\nfund agreements. It applies the recursive marginal quantization (RMQ) and joint\nrecursive marginal quantization (JRMQ) algorithms outside the framework of\ntraditional risk-neutral methods by pricing options under the real-world\nprobability measure, using the benchmark approach. The benchmark approach is\nreviewed, and the real-world pricing theorem is presented and applied to\nvarious long-dated claims to obtain less expensive prices than suggested by\ntraditional risk-neutral valuation. The growth-optimal portfolio (GOP), the\ncentral object of the benchmark approach, is modelled using the time-dependent\nconstant elasticity of variance model (TCEV). Analytic European option prices\nare derived and the RMQ algorithm is used to efficiently and accurately price\nBermudan options on the GOP. The TCEV model is then combined with a $3/2$\nstochastic short-rate model and RMQ is used to price zero-coupon bonds and\nzero-coupon bond options, highlighting the departure from risk-neutral pricing.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jan 2018 11:22:56 GMT"}, {"version": "v2", "created": "Wed, 24 Jan 2018 12:54:39 GMT"}], "update_date": "2018-01-25", "authors_parsed": [["Rudd", "Ralph", ""], ["McWalter", "Thomas A.", ""], ["Kienitz", "Joerg", ""], ["Platen", "Eckhard", ""]]}, {"id": "1801.07358", "submitter": "Hao Xing", "authors": "Luting Li and Hao Xing", "title": "Capital allocation under the Fundamental Review of Trading Book", "comments": "25 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Facing the FRTB, banks need to allocate their capital to each business units\nor risk positions to evaluate the capital efficiency of their strategies. This\npaper proposes two computationally efficient allocation methods which are\nweighted according to liquidity horizon. Both methods provide more stable and\nless negative allocations under the FRTB than under the current regulatory\nframework.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jan 2018 00:26:21 GMT"}, {"version": "v2", "created": "Mon, 14 Jan 2019 23:20:08 GMT"}], "update_date": "2019-01-16", "authors_parsed": [["Li", "Luting", ""], ["Xing", "Hao", ""]]}, {"id": "1801.07941", "submitter": "Aurelio Fernandez Bariviera", "authors": "Aurelio F. Bariviera, Angelo Plastino, George Judge", "title": "Spurious seasonality detection: a non-parametric test proposal", "comments": null, "journal-ref": "Econometrics 6, no. 1: 3", "doi": "10.3390/econometrics6010003", "report-no": null, "categories": "q-fin.ST q-fin.CP q-fin.MF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper offers a general and comprehensive definition of the\nday-of-the-week effect. Using symbolic dynamics, we develop a unique test based\non ordinal patterns in order to detect it. This test uncovers the fact that the\nso-called \"day-of-the-week\" effect is partly an artifact of the hidden\ncorrelation structure of the data. We present simulations based on artificial\ntime series as well. Whereas time series generated with long memory are prone\nto exhibit daily seasonality, pure white noise signals exhibit no pattern\npreference. Since ours is a non parametric test, it requires no assumptions\nabout the distribution of returns so that it could be a practical alternative\nto conventional econometric tests. We made also an exhaustive application of\nthe here proposed technique to 83 stock indices around the world. Finally, the\npaper highlights the relevance of symbolic analysis in economic time series\nstudies.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jan 2018 11:54:24 GMT"}], "update_date": "2018-01-25", "authors_parsed": [["Bariviera", "Aurelio F.", ""], ["Plastino", "Angelo", ""], ["Judge", "George", ""]]}, {"id": "1801.07960", "submitter": "Aurelio Fernandez Bariviera", "authors": "Martin Iglesias Caride, Aurelio F. Bariviera, Laura Lanzarini", "title": "Stock returns forecast: an examination by means of Artificial Neural\n  Networks", "comments": null, "journal-ref": "Studies in Systems, Decision and Control, vol 125. Springer, Cham", "doi": "10.1007/978-3-319-69989-9_23", "report-no": null, "categories": "q-fin.CP q-fin.PR q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The validity of the Efficient Market Hypothesis has been under severe\nscrutiny since several decades. However, the evidence against it is not\nconclusive. Artificial Neural Networks provide a model-free means to analize\nthe prediction power of past returns on current returns. This chapter analizes\nthe predictability in the intraday Brazilian stock market using a\nbackpropagation Artificial Neural Network. We selected 20 stocks from Bovespa\nindex, according to different market capitalization, as a proxy for stock size.\nWe find that predictability is related to capitalization. In particular, larger\nstocks are less predictable than smaller ones.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jan 2018 12:38:59 GMT"}], "update_date": "2018-01-25", "authors_parsed": [["Caride", "Martin Iglesias", ""], ["Bariviera", "Aurelio F.", ""], ["Lanzarini", "Laura", ""]]}, {"id": "1801.08215", "submitter": "Tai-Ho Wang", "authors": "Elisa Alos, Rupak Chatterjee, Sebastian Tudor, and Tai-Ho Wang", "title": "Target volatility option pricing in lognormal fractional SABR model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP q-fin.MF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine in this article the pricing of target volatility options in the\nlognormal fractional SABR model. A decomposition formula by Ito's calculus\nyields a theoretical replicating strategy for the target volatility option,\nassuming the accessibilities of all variance swaps and swaptions. The same\nformula also suggests an approximation formula for the price of target\nvolatility option in small time by the technique of freezing the coefficient.\nAlternatively, we also derive closed formed expressions for a small volatility\nof volatility expansion of the price of target volatility option. Numerical\nexperiments show accuracy of the approximations in a reasonably wide range of\nparameters.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jan 2018 22:07:12 GMT"}], "update_date": "2018-01-26", "authors_parsed": [["Alos", "Elisa", ""], ["Chatterjee", "Rupak", ""], ["Tudor", "Sebastian", ""], ["Wang", "Tai-Ho", ""]]}, {"id": "1801.08222", "submitter": "Boris Gutkin", "authors": "J. Lussange, A. Belianin, S. Bourgeois-Gironde, B. Gutkin", "title": "A bright future for financial agent-based models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The history of research in finance and economics has been widely impacted by\nthe field of Agent-based Computational Economics (ACE). While at the same time\nbeing popular among natural science researchers for its proximity to the\nsuccessful methods of physics and chemistry for example, the field of ACE has\nalso received critics by a part of the social science community for its lack of\nempiricism. Yet recent trends have shifted the weights of these general\narguments and potentially given ACE a whole new range of realism. At the base\nof these trends are found two present-day major scientific breakthroughs: the\nsteady shift of psychology towards a hard science due to the advances of\nneuropsychology, and the progress of artificial intelligence and more\nspecifically machine learning due to increasing computational power and big\ndata. These two have also found common fields of study in the form of\ncomputational neuroscience, and human-computer interaction, among others. We\noutline here the main lines of a computational research study of collective\neconomic behavior via Agent-Based Models (ABM) or Multi-Agent System (MAS),\nwhere each agent would be endowed with specific cognitive and behavioral biases\nknown to the field of neuroeconomics, and at the same time autonomously\nimplement rational quantitative financial strategies updated by machine\nlearning. We postulate that such ABMs would offer a whole new range of realism.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jan 2018 22:24:56 GMT"}], "update_date": "2018-01-26", "authors_parsed": [["Lussange", "J.", ""], ["Belianin", "A.", ""], ["Bourgeois-Gironde", "S.", ""], ["Gutkin", "B.", ""]]}, {"id": "1801.08675", "submitter": "Masaaki Fukasawa", "authors": "Omar El Euch, Masaaki Fukasawa, Jim Gatheral, Mathieu Rosenbaum", "title": "Short-term at-the-money asymptotics under stochastic volatility models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A small-time Edgeworth expansion of the density of an asset price is given\nunder a general stochastic volatility model, from which asymptotic expansions\nof put option prices and at-the-money implied volatilities follow. A limit\ntheorem for at-the-money implied volatility skew and curvature is also given as\na corollary. The rough Bergomi model is treated as an example.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jan 2018 05:07:54 GMT"}, {"version": "v2", "created": "Mon, 29 Jan 2018 08:01:04 GMT"}, {"version": "v3", "created": "Fri, 22 Mar 2019 05:22:03 GMT"}], "update_date": "2019-03-25", "authors_parsed": [["Euch", "Omar El", ""], ["Fukasawa", "Masaaki", ""], ["Gatheral", "Jim", ""], ["Rosenbaum", "Mathieu", ""]]}, {"id": "1801.10359", "submitter": "Eduardo Abi Jaber", "authors": "Eduardo Abi Jaber (CEREMADE), Omar El Euch (X)", "title": "Multi-factor approximation of rough volatility models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR q-fin.CP q-fin.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rough volatility models are very appealing because of their remarkable fit of\nboth historical and implied volatilities. However, due to the non-Markovian and\nnon-semimartingale nature of the volatility process, there is no simple way to\nsimulate efficiently such models, which makes risk management of derivatives an\nintricate task. In this paper, we design tractable multi-factor stochastic\nvolatility models approximating rough volatility models and enjoying a\nMarkovian structure. Furthermore, we apply our procedure to the specific case\nof the rough Heston model. This in turn enables us to derive a numerical method\nfor solving fractional Riccati equations appearing in the characteristic\nfunction of the log-price in this setting.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jan 2018 09:00:52 GMT"}, {"version": "v2", "created": "Fri, 30 Mar 2018 13:15:01 GMT"}, {"version": "v3", "created": "Wed, 11 Apr 2018 07:06:15 GMT"}], "update_date": "2018-04-12", "authors_parsed": [["Jaber", "Eduardo Abi", "", "CEREMADE"], ["Euch", "Omar El", "", "X"]]}]