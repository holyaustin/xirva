[{"id": "1412.3140", "submitter": "Plamen Turkedjiev", "authors": "Dirk Becherer and Plamen Turkedjiev", "title": "Multilevel approximation of backward stochastic differential equations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.NA q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a multilevel approach to compute approximate solutions to backward\ndifferential equations (BSDEs). The fully implementable algorithm of our\nmultilevel scheme constructs sequential martingale control variates along a\nsequence of refining time-grids to reduce statistical approximation errors in\nan adaptive and generic way. We provide an error analysis with explicit and\nnon-asymptotic error estimates for the multilevel scheme under general\nconditions on the forward process and the BSDE data. It is shown that the\nmultilevel approach can reduce the computational complexity to achieve\nprecision $\\epsilon$, ensured by error estimates, essentially by one order (in\n$\\epsilon^{-1}$) in comparison to established methods, which is substantial.\nComputational examples support the validity of the theoretical analysis,\ndemonstrating efficiency improvements in practice.\n", "versions": [{"version": "v1", "created": "Tue, 9 Dec 2014 22:27:32 GMT"}], "update_date": "2014-12-11", "authors_parsed": [["Becherer", "Dirk", ""], ["Turkedjiev", "Plamen", ""]]}, {"id": "1412.3623", "submitter": "Qian Feng", "authors": "Q. Feng, C.W. Oosterlee", "title": "Monte Carlo Calculation of Exposure Profiles and Greeks for Bermudan and\n  Barrier Options under the Heston Hull-White Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Valuation of Credit Valuation Adjustment (CVA) has become an important field\nas its calculation is required in Basel III, issued in 2010, in the wake of the\ncredit crisis. Exposure, which is defined as the potential future loss of a\ndefault event without any recovery, is one of the key elementsfor pricing CVA.\nThis paper provides a backward dynamics framework for assessing exposure\nprofiles of European, Bermudan and barrier options under the Heston and Heston\nHull-White asset dynamics. We discuss the potential of an efficient and\nadaptive Monte Carlo approach, the Stochastic Grid Bundling Method}(SGBM),\nwhich employs the techniques of simulation, regression and bundling. Greeks of\nthe exposure profiles can be calculated in the same backward iteration with\nlittle extra effort. Assuming independence between default event and exposure\nprofiles, we give examples of calculating exposure, CVA and Greeks for Bermudan\nand barrier options.\n", "versions": [{"version": "v1", "created": "Thu, 11 Dec 2014 12:14:22 GMT"}], "update_date": "2014-12-12", "authors_parsed": [["Feng", "Q.", ""], ["Oosterlee", "C. W.", ""]]}, {"id": "1412.3948", "submitter": "Giacomo Bormetti", "authors": "Gabriele Ranco, Ilaria Bordino, Giacomo Bormetti, Guido Caldarelli,\n  Fabrizio Lillo, Michele Treccani", "title": "Coupling news sentiment with web browsing data improves prediction of\n  intra-day price dynamics", "comments": "24 pages, 4 figures, 5 tables. Figure 2 replaced. Few typos corrected", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The new digital revolution of big data is deeply changing our capability of\nunderstanding society and forecasting the outcome of many social and economic\nsystems. Unfortunately, information can be very heterogeneous in the\nimportance, relevance, and surprise it conveys, affecting severely the\npredictive power of semantic and statistical methods. Here we show that the\naggregation of web users' behavior can be elicited to overcome this problem in\na hard to predict complex system, namely the financial market. Specifically,\nour in-sample analysis shows that the combined use of sentiment analysis of\nnews and browsing activity of users of Yahoo! Finance greatly helps forecasting\nintra-day and daily price changes of a set of 100 highly capitalized US stocks\ntraded in the period 2012-2013. Sentiment analysis or browsing activity when\ntaken alone have very small or no predictive power. Conversely, when\nconsidering a \"news signal\" where in a given time interval we compute the\naverage sentiment of the clicked news, weighted by the number of clicks, we\nshow that for nearly 50% of the companies such signal Granger-causes hourly\nprice returns. Our result indicates a \"wisdom-of-the-crowd\" effect that allows\nto exploit users' activity to identify and weigh properly the relevant and\nsurprising news, enhancing considerably the forecasting power of the news\nsentiment.\n", "versions": [{"version": "v1", "created": "Fri, 12 Dec 2014 11:06:49 GMT"}, {"version": "v2", "created": "Wed, 31 Dec 2014 10:29:48 GMT"}, {"version": "v3", "created": "Fri, 4 Dec 2015 15:37:18 GMT"}, {"version": "v4", "created": "Tue, 15 Dec 2015 16:55:39 GMT"}], "update_date": "2015-12-16", "authors_parsed": [["Ranco", "Gabriele", ""], ["Bordino", "Ilaria", ""], ["Bormetti", "Giacomo", ""], ["Caldarelli", "Guido", ""], ["Lillo", "Fabrizio", ""], ["Treccani", "Michele", ""]]}, {"id": "1412.4045", "submitter": "Tigran Nagapetyan", "authors": "Denis Belomestny and Tigran Nagapetyan", "title": "Variance reduced multilevel path simulation: going beyond the complexity\n  $\\varepsilon^{-2}$", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper a novel modification of the multilevel Monte Carlo approach,\nallowing for further significant complexity reduction, is proposed. The idea of\nthe modification is to use the method of control variates to reduce variance at\nlevel zero. We show that, under a proper choice of control variates, one can\nreduce the complexity order of the modified MLMC algorithm down to\n$\\varepsilon^{-2+\\delta}$ for any $\\delta\\in [0,1)$ with $\\varepsilon$ being\nthe precision to be achieved. These theoretical results are illustrated by\nseveral numerical examples.\n", "versions": [{"version": "v1", "created": "Fri, 12 Dec 2014 16:32:55 GMT"}, {"version": "v2", "created": "Sat, 11 Mar 2017 12:21:51 GMT"}], "update_date": "2017-03-14", "authors_parsed": [["Belomestny", "Denis", ""], ["Nagapetyan", "Tigran", ""]]}, {"id": "1412.5332", "submitter": "Chris Kenyon", "authors": "Chris Kenyon and Andrew Green", "title": "Efficient XVA Management: Pricing, Hedging, and Attribution using\n  Trade-Level Regression and Global Conditioning", "comments": "17 pages, 4 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP q-fin.PM q-fin.PR q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Banks must manage their trading books, not just value them. Pricing includes\nvaluation adjustments collectively known as XVA (at least credit, funding,\ncapital and tax), so management must also include XVA. In trading book\nmanagement we focus on pricing, hedging, and allocation of prices or hedging\ncosts to desks on an individual trade basis. We show how to combine three\ntechnical elements to radically simplify XVA management, both in terms of the\ncalculations, and the implementation of the calculations. The three technical\nelements are: trade-level regression; analytic computation of sensitivities;\nand global conditioning. All three are required to obtain the radical\nefficiency gains and implementation simplification. Moreover, many of the\ncalculations are inherently parallel and suitable for GPU implementation. The\nresulting methodology for XVA management is sufficiently general that we can\ncover pricing, first- and second-order sensitivities, and exact trade-level\nallocation of pricing and sensitivities within the same framework. Managing\nincremental changes to portfolios exactly is also radically simplified.\n", "versions": [{"version": "v1", "created": "Wed, 17 Dec 2014 10:56:02 GMT"}, {"version": "v2", "created": "Mon, 22 Dec 2014 19:58:28 GMT"}], "update_date": "2014-12-23", "authors_parsed": [["Kenyon", "Chris", ""], ["Green", "Andrew", ""]]}, {"id": "1412.5558", "submitter": "Andreas Platen", "authors": "Stanislaus Maier-Paape and Andreas Platen", "title": "Backtest of Trading Systems on Candle Charts", "comments": "12 pages, 19 figures; Keywords: backtest evaluation, historical\n  simulation, trading system, candle chart, imperfect data", "journal-ref": "IFTA Journal, pp. 10-17, 2016", "doi": null, "report-no": null, "categories": "q-fin.TR q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we try to design the necessary calculation needed for\nbacktesting trading systems when only candle chart data are available. We lay\nparticular emphasis on situations which are not or not uniquely decidable and\ngive possible strategies to handle such situations.\n", "versions": [{"version": "v1", "created": "Wed, 17 Dec 2014 20:07:35 GMT"}], "update_date": "2015-11-30", "authors_parsed": [["Maier-Paape", "Stanislaus", ""], ["Platen", "Andreas", ""]]}, {"id": "1412.6063", "submitter": "Jamal Amani Rad", "authors": "Jamal Amani Rad and Kourosh Parand and Saeid Abbasbandy", "title": "Local weak form meshless techniques based on the radial point\n  interpolation (RPI) method and local boundary integral equation (LBIE) method\n  to evaluate European and American options", "comments": null, "journal-ref": "dx.doi.org/10.1016/j.cnsns.2014.07.015", "doi": null, "report-no": null, "categories": "cs.CE q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For the first time in mathematical finance field, we propose the local weak\nform meshless methods for option pricing; especially in this paper we select\nand analysis two schemes of them named local boundary integral equation method\n(LBIE) based on moving least squares approximation (MLS) and local radial point\ninterpolation (LRPI) based on Wu's compactly supported radial basis functions\n(WCS-RBFs). LBIE and LRPI schemes are the truly meshless methods, because, a\ntraditional non-overlapping, continuous mesh is not required, either for the\nconstruction of the shape functions, or for the integration of the local\nsub-domains. In this work, the American option which is a free boundary\nproblem, is reduced to a problem with fixed boundary using a Richardson\nextrapolation technique. Then the $\\theta$-weighted scheme is employed for the\ntime derivative. Stability analysis of the methods is analyzed and performed by\nthe matrix method. In fact, based on an analysis carried out in the present\npaper, the methods are unconditionally stable for implicit Euler (\\theta = 0)\nand Crank-Nicolson (\\theta = 0.5) schemes. It should be noted that LBIE and\nLRPI schemes lead to banded and sparse system matrices. Therefore, we use a\npowerful iterative algorithm named the Bi-conjugate gradient stabilized method\n(BCGSTAB) to get rid of this system. Numerical experiments are presented\nshowing that the LBIE and LRPI approaches are extremely accurate and fast.\n", "versions": [{"version": "v1", "created": "Wed, 29 Oct 2014 20:05:08 GMT"}], "update_date": "2014-12-19", "authors_parsed": [["Rad", "Jamal Amani", ""], ["Parand", "Kourosh", ""], ["Abbasbandy", "Saeid", ""]]}, {"id": "1412.6064", "submitter": "Jamal Amani Rad", "authors": "Jamal Amani Rad and Kourosh Parand", "title": "Numerical pricing of American options under two stochastic factor models\n  with jumps using a meshless local Petrov-Galerkin method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The most recent update of financial option models is American options under\nstochastic volatility models with jumps in returns (SVJ) and stochastic\nvolatility models with jumps in returns and volatility (SVCJ). To evaluate\nthese options, mesh-based methods are applied in a number of papers but it is\nwell-known that these methods depend strongly on the mesh properties which is\nthe major disadvantage of them. Therefore, we propose the use of the meshless\nmethods to solve the aforementioned options models, especially in this work we\nselect and analyze one scheme of them, named local radial point interpolation\n(LRPI) based on Wendland's compactly supported radial basis functions\n(WCS-RBFs) with C6, C4 and C2 smoothness degrees. The LRPI method which is a\nspecial type of meshless local Petrov-Galerkin method (MLPG), offers several\nadvantages over the mesh-based methods, nevertheless it has never been applied\nto option pricing, at least to the very best of our knowledge. These schemes\nare the truly meshless methods, because, a traditional non-overlapping\ncontinuous mesh is not required, neither for the construction of the shape\nfunctions, nor for the integration of the local sub-domains. In this work, the\nAmerican option which is a free boundary problem, is reduced to a problem with\nfixed boundary using a Richardson extrapolation technique. Then the\nimplicit-explicit (IMEX) time stepping scheme is employed for the time\nderivative which allows us to smooth the discontinuities of the options'\npayoffs. Stability analysis of the method is analyzed and performed. In fact,\naccording to an analysis carried out in the present paper, the proposed method\nis unconditionally stable. Numerical experiments are presented showing that the\nproposed approaches are extremely accurate and fast.\n", "versions": [{"version": "v1", "created": "Wed, 29 Oct 2014 19:37:14 GMT"}], "update_date": "2014-12-19", "authors_parsed": [["Rad", "Jamal Amani", ""], ["Parand", "Kourosh", ""]]}, {"id": "1412.7269", "submitter": "Jun-ichi Inoue", "authors": "Mitsuaki Murota, Jun-ichi Inoue", "title": "Large-scale empirical study on pairs trading for all possible pairs of\n  stocks listed on the first section of the Tokyo Stock Exchange", "comments": "19 pages, 14 figures, using svjour3.cls", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.TR q-fin.CP q-fin.PM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We carry out a large-scale empirical data analysis to examine the efficiency\nof the so-called pairs trading. On the basis of relevant three thresholds,\nnamely, starting, profit-taking, and stop-loss for the `first-passage process'\nof the spread (gap) between two highly-correlated stocks, we construct an\neffective strategy to make a trade via `active' stock-pairs automatically. The\nalgorithm is applied to $1,784$ stocks listed on the first section of the Tokyo\nStock Exchange leading up to totally $1,590,436$ pairs. We are numerically\nconfirmed that the asset management by means of the pairs trading works\neffectively at least for the past three years (2010-2012) data sets in the\nsense that the profit rate becomes positive (totally positive arbitrage) in\nmost cases of the possible combinations of thresholds corresponding to\n`absorbing boundaries' in the literature of first-passage processes.\n", "versions": [{"version": "v1", "created": "Tue, 23 Dec 2014 06:55:04 GMT"}, {"version": "v2", "created": "Thu, 19 Mar 2015 04:20:17 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Murota", "Mitsuaki", ""], ["Inoue", "Jun-ichi", ""]]}, {"id": "1412.7412", "submitter": "Aurelien Alfonsi", "authors": "Abdelkoddousse Ahdida, Aur\\'elien Alfonsi, Ernesto Palidda", "title": "Smile with the Gaussian term structure model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.MF q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an affine extension of the Linear Gaussian term structure Model\n(LGM) such that the instantaneous covariation of the factors is given by an\naffine process on semidefinite positive matrices. First, we set up the model\nand present some important properties concerning the Laplace transform of the\nfactors and the ergodicity of the model. Then, we present two main numerical\ntools to implement the model in practice. First, we obtain an expansion of\ncaplets and swaptions prices around the LGM. Such a fast and accurate\napproximation is useful for assessing the model behavior on the implied\nvolatility smile. Second, we provide a second order scheme for the weak error,\nwhich enables to calculate exotic options by a Monte-Carlo algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 23 Dec 2014 15:49:54 GMT"}, {"version": "v2", "created": "Wed, 4 Nov 2015 12:47:40 GMT"}], "update_date": "2015-11-05", "authors_parsed": [["Ahdida", "Abdelkoddousse", ""], ["Alfonsi", "Aur\u00e9lien", ""], ["Palidda", "Ernesto", ""]]}, {"id": "1412.8414", "submitter": "Marco Santoli", "authors": "Tim Leung and Marco Santoli", "title": "Accounting for Earnings Announcements in the Pricing of Equity Options", "comments": "34 Pages", "journal-ref": "Journal of Financial Engineering, Vol. 1, No. 4 (December 2014)", "doi": null, "report-no": null, "categories": "q-fin.PR q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study an option pricing framework that accounts for the price impact of an\nearnings announcement (EA), and analyze the behavior of the implied volatility\nsurface prior to the event. On the announcement date, we incorporate a random\njump to the stock price to represent the shock due to earnings. We consider\ndifferent distributions of the scheduled earnings jump as well as different\nunderlying stock price dynamics before and after the EA date. Our main\ncontributions include analytical option pricing formulas when the underlying\nstock price follows the Kou model along with a double-exponential or Gaussian\nEA jump on the announcement date. Furthermore, we derive analytic bounds and\nasymptotics for the pre-EA implied volatility under various models. The\ncalibration results demonstrate adequate fit of the entire implied volatility\nsurface prior to an announcement. We also compare the risk-neutral distribution\nof the EA jump to its historical distribution. Finally, we discuss the\nvaluation and exercise strategy of pre-EA American options, and illustrate an\nanalytical approximation and numerical results.\n", "versions": [{"version": "v1", "created": "Mon, 29 Dec 2014 18:30:01 GMT"}, {"version": "v2", "created": "Wed, 8 Apr 2015 01:00:03 GMT"}], "update_date": "2015-04-09", "authors_parsed": [["Leung", "Tim", ""], ["Santoli", "Marco", ""]]}]