[{"id": "2010.01319", "submitter": "Lorenc Kapllani M.Sc.", "authors": "Lorenc Kapllani and Long Teng", "title": "Deep Learning algorithms for solving high dimensional nonlinear Backward\n  Stochastic Differential Equations", "comments": "21 pages, 5 figures, 16 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA q-fin.CP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study deep learning-based schemes for solving high dimensional nonlinear\nbackward stochastic differential equations (BSDEs). First we show how to\nimprove the performances of the proposed scheme in [W. E and J. Han and A.\nJentzen, Commun. Math. Stat., 5 (2017), pp.349-380] regarding computational\ntime by using a single neural network architecture instead of the stacked deep\nneural networks. Furthermore, those schemes can be stuck in poor local minima\nor diverges, especially for a complex solution structure and longer terminal\ntime. To solve this problem, we investigate to reformulate the problem by\nincluding local losses and exploit the Long Short Term Memory (LSTM) networks\nwhich are a type of recurrent neural networks (RNN). Finally, in order to study\nnumerical convergence and thus illustrate the improved performances with the\nproposed methods, we provide numerical results for several 100-dimensional\nnonlinear BSDEs including nonlinear pricing problems in finance.\n", "versions": [{"version": "v1", "created": "Sat, 3 Oct 2020 10:18:58 GMT"}, {"version": "v2", "created": "Fri, 26 Feb 2021 11:53:21 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Kapllani", "Lorenc", ""], ["Teng", "Long", ""]]}, {"id": "2010.04404", "submitter": "Miquel Noguer Alonso", "authors": "Miquel Noguer i Alonso and Sonam Srivastava", "title": "Deep Reinforcement Learning for Asset Allocation in US Equities", "comments": "Submitting to Journal of Machine Learning in Finance", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PM q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning is a machine learning approach concerned with solving\ndynamic optimization problems in an almost model-free way by maximizing a\nreward function in state and action spaces. This property makes it an exciting\narea of research for financial problems. Asset allocation, where the goal is to\nobtain the weights of the assets that maximize the rewards in a given state of\nthe market considering risk and transaction costs, is a problem easily framed\nusing a reinforcement learning framework. It is first a prediction problem for\nexpected returns and covariance matrix and then an optimization problem for\nreturns, risk, and market impact. Investors and financial researchers have been\nworking with approaches like mean-variance optimization, minimum variance, risk\nparity, and equally weighted and several methods to make expected returns and\ncovariance matrices' predictions more robust. This paper demonstrates the\napplication of reinforcement learning to create a financial model-free solution\nto the asset allocation problem, learning to solve the problem using time\nseries and deep neural networks. We demonstrate this on daily data for the top\n24 stocks in the US equities universe with daily rebalancing. We use a deep\nreinforcement model on US stocks using different architectures. We use Long\nShort Term Memory networks, Convolutional Neural Networks, and Recurrent Neural\nNetworks and compare them with more traditional portfolio management. The Deep\nReinforcement Learning approach shows better results than traditional\napproaches using a simple reward function and only being given the time series\nof stocks. In Finance, no training to test error generalization results come\nguaranteed. We can say that the modeling framework can deal with time series\nprediction and asset allocation, including transaction costs.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 07:25:55 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Alonso", "Miquel Noguer i", ""], ["Srivastava", "Sonam", ""]]}, {"id": "2010.05601", "submitter": "Conrad Beyers", "authors": "Arno Botha, Conrad Beyers, Pieter de Villiers", "title": "The loss optimisation of loan recovery decision times using forecast\n  cash flows", "comments": "29 pages (including appendix), 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM q-fin.CP q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A theoretical method is empirically illustrated in finding the best time to\nforsake a loan such that the overall credit loss is minimised. This is\npredicated by forecasting the future cash flows of a loan portfolio up to the\ncontractual term, as a remedy to the inherent right-censoring of real-world\n`incomplete' portfolios. Two techniques, a simple probabilistic model as well\nas an eight-state Markov chain, are used to forecast these cash flows\nindependently. We train both techniques from different segments within\nresidential mortgage data, provided by a large South African bank, as part of a\ncomparative experimental framework. As a result, the recovery decision's\nimplied timing is empirically illustrated as a multi-period optimisation\nproblem across uncertain cash flows and competing costs. Using a delinquency\nmeasure as a central criterion, our procedure helps to find a loss-optimal\nthreshold at which loan recovery should ideally occur for a given portfolio.\nFurthermore, both the portfolio's historical risk profile and forecasting\nthereof are shown to influence the timing of the recovery decision. This work\ncan therefore facilitate the revision of relevant bank policies or strategies\ntowards optimising the loan collections process, especially that of secured\nlending.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 11:12:39 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Botha", "Arno", ""], ["Beyers", "Conrad", ""], ["de Villiers", "Pieter", ""]]}, {"id": "2010.08407", "submitter": "Mike Ludkovski", "authors": "Mike Ludkovski and Yuri Saporito", "title": "KrigHedge: Gaussian Process Surrogates for Delta Hedging", "comments": "29 pages, 6 figures, plus RMarkdown supplement", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate a machine learning approach to option Greeks approximation\nbased on Gaussian process (GP) surrogates. The method takes in noisily observed\noption prices, fits a nonparametric input-output map and then analytically\ndifferentiates the latter to obtain the various price sensitivities. Our\nmotivation is to compute Greeks in cases where direct computation is expensive,\nsuch as in local volatility models, or can only ever be done approximately. We\nprovide a detailed analysis of numerous aspects of GP surrogates, including\nchoice of kernel family, simulation design, choice of trend function and impact\nof noise.\n  We further discuss the application to Delta hedging, including a new Lemma\nthat relates quality of the Delta approximation to discrete-time hedging loss.\nResults are illustrated with two extensive case studies that consider\nestimation of Delta, Theta and Gamma and benchmark approximation quality and\nuncertainty quantification using a variety of statistical metrics. Among our\nkey take-aways are the recommendation to use Matern kernels, the benefit of\nincluding virtual training points to capture boundary conditions, and the\nsignificant loss of fidelity when training on stock-path-based datasets.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 14:08:13 GMT"}, {"version": "v2", "created": "Mon, 26 Oct 2020 13:05:53 GMT"}, {"version": "v3", "created": "Tue, 3 Nov 2020 17:20:28 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Ludkovski", "Mike", ""], ["Saporito", "Yuri", ""]]}, {"id": "2010.08601", "submitter": "Honggao Cao", "authors": "Feng Zhang, Ruite Guo and Honggao Cao", "title": "Information Coefficient as a Performance Measure of Stock Selection\n  Models", "comments": "15 pages, 2 figures, and 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP q-fin.RM stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information coefficient (IC) is a widely used metric for measuring investment\nmanagers' skills in selecting stocks. However, its adequacy and effectiveness\nfor evaluating stock selection models has not been clearly understood, as IC\nfrom a realistic stock selection model can hardly be materially different from\nzero and is often accompanies with high volatility. In this paper, we\ninvestigate the behavior of IC as a performance measure of stick selection\nmodels. Through simulation and simple statistical modeling, we examine the IC\nbehavior both statically and dynamically. The examination helps us propose two\npractical procedures that one may use for IC-based ongoing performance\nmonitoring of stock selection models.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 19:40:49 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Zhang", "Feng", ""], ["Guo", "Ruite", ""], ["Cao", "Honggao", ""]]}, {"id": "2010.09285", "submitter": "Huyen Pham", "authors": "Ren\\'e Aid, Andrea Cosso (UNIBO), Huy\\^en Pham (LPSM (UMR\\_8001),\n  ENSAE ParisTech )", "title": "Equilibrium price in intraday electricity markets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We formulate an equilibrium model of intraday trading in electricity markets.\nAgents face balancing constraints between their customers consumption plus\nintraday sales and their production plus intraday purchases. They have\ncontinuously updated forecast of their customers consumption at maturity with\ndecreasing volatility error. Forecasts are prone to idiosyncratic noise as well\nas common noise (weather). Agents production capacities are subject to\nindependent random outages, which are each modelled by a Markov chain. The\nequilibrium price is defined as the price that minimises trading cost plus\nimbalance cost of each agent and satisfies the usual market clearing condition.\nExistence and uniqueness of the equilibrium are proved, and we show that the\nequilibrium price and the optimal trading strategies are martingales. The main\neconomic insights are the following. (i) When there is no uncertainty on\ngeneration, it is shown that the market price is a convex combination of\nforecasted marginal cost of each agent, with deterministic weights.\nFurthermore, the equilibrium market price follows Almgren and Chriss's model\nand we identify the fundamental part as well as the permanent market impact. It\nturns out that heterogeneity across agents is a necessary condition for the\nSamuelson's effect to hold. (ii) When there is production uncertainty, the\nprice volatility becomes stochastic but converges to the case without\nproduction uncertainty when the number of agents increases to infinity.\nFurther, on a two-agent case, we show that the potential outages of a low\nmarginal cost producer reduces her sales position.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 07:56:50 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Aid", "Ren\u00e9", "", "UNIBO"], ["Cosso", "Andrea", "", "UNIBO"], ["Pham", "Huy\u00ean", "", "LPSM"]]}, {"id": "2010.12651", "submitter": "Aurelien Alfonsi", "authors": "Aur\\'elien Alfonsi and Adel Cherchali and Jose Arturo Infante Acevedo", "title": "Multilevel Monte-Carlo for computing the SCR with the standard formula\n  and other stress tests", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the multilevel Monte-Carlo estimator for the expectation\nof a maximum of conditional expectations. This problem arises naturally when\nconsidering many stress tests and appears in the calculation of the interest\nrate module of the standard formula for the SCR. We obtain theoretical\nconvergence results that complements the recent work of Giles and Goda and\ngives some additional tractability through a parameter that somehow describes\nregularity properties around the maximum. We then apply the MLMC estimator to\nthe calculation of the SCR at future dates with the standard formula for an ALM\nsavings business on life insurance. We compare it with estimators obtained with\nLeast Square Monte-Carlo or Neural Networks. We find that the MLMC estimator is\ncomputationally more efficient and has the main advantage to avoid regression\nissues, which is particularly significant in the context of projection of a\nbalance sheet by an insurer due to the path dependency. Last, we discuss the\npotentiality of this numerical method and analyze in particular the effect of\nthe portfolio allocation on the SCR at future~dates.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 20:29:59 GMT"}, {"version": "v2", "created": "Tue, 13 Apr 2021 09:25:18 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Alfonsi", "Aur\u00e9lien", ""], ["Cherchali", "Adel", ""], ["Acevedo", "Jose Arturo Infante", ""]]}, {"id": "2010.13541", "submitter": "Yogi Erlangga", "authors": "Dongming Wei and Yogi Ahmad Erlangga and Gulzat Zhumakhanova", "title": "A Finite Element Approach to the Numerical Solutions of Leland's Mode", "comments": "13 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, finite element method is applied to Leland's model for\nnumerical simulation of option pricing with transaction costs. Spatial finite\nelement models based on P1 and/or P2 elements are formulated in combination\nwith a Crank-Nicolson-type temporal scheme. The temporal scheme is implemented\nusing the Rannacher approach. Examples with several sets of parameter values\nare presented and compared with finite difference results in the literature.\nSpatial-temporal mesh-size ratios are observed for controlling the stability of\nour method. Our results compare favorably with the finite difference results in\nthe literature for the model.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 12:50:37 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Wei", "Dongming", ""], ["Erlangga", "Yogi Ahmad", ""], ["Zhumakhanova", "Gulzat", ""]]}, {"id": "2010.13891", "submitter": "Jaydip Sen", "authors": "Sidra Mehtab and Jaydip Sen", "title": "Stock Price Prediction Using CNN and LSTM-Based Deep Learning Models", "comments": "The paper consists of 7 pages, 10 figures, and 5 tables. This is the\n  accepted version of our paper in the IEEE International Conference on\n  Decision Aid Sciences and Applications (DASA'20), November 8-9, 2020, Bahrain", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing robust and accurate predictive models for stock price prediction\nhas been an active area of research for a long time. While on one side, the\nsupporters of the efficient market hypothesis claim that it is impossible to\nforecast stock prices accurately, many researchers believe otherwise. There\nexist propositions in the literature that have demonstrated that if properly\ndesigned and optimized, predictive models can very accurately and reliably\npredict future values of stock prices. This paper presents a suite of deep\nlearning based models for stock price prediction. We use the historical records\nof the NIFTY 50 index listed in the National Stock Exchange of India, during\nthe period from December 29, 2008 to July 31, 2020, for training and testing\nthe models. Our proposition includes two regression models built on\nconvolutional neural networks and three long and short term memory network\nbased predictive models. To forecast the open values of the NIFTY 50 index\nrecords, we adopted a multi step prediction technique with walk forward\nvalidation. In this approach, the open values of the NIFTY 50 index are\npredicted on a time horizon of one week, and once a week is over, the actual\nindex values are included in the training set before the model is trained\nagain, and the forecasts for the next week are made. We present detailed\nresults on the forecasting accuracies for all our proposed models. The results\nshow that while all the models are very accurate in forecasting the NIFTY 50\nopen values, the univariate encoder decoder convolutional LSTM with the\nprevious two weeks data as the input is the most accurate model. On the other\nhand, a univariate CNN model with previous one week data as the input is found\nto be the fastest model in terms of its execution speed.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 03:09:07 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Mehtab", "Sidra", ""], ["Sen", "Jaydip", ""]]}]