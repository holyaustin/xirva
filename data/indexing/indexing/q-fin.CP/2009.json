[{"id": "2009.00557", "submitter": "Giacomo Bormetti", "authors": "Fabio Baschetti, Giacomo Bormetti, Silvia Romagnoli, Pietro Rossi", "title": "The SINC way: A fast and accurate approach to Fourier pricing", "comments": "49 pages, 4 figures, 13 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PR q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of this paper is to investigate the method outlined by one of us\n(PR) in Cherubini et al. (2009) to compute option prices. We name it the SINC\napproach. While the COS method by Fang and Osterlee (2009) leverages the\nFourier-cosine expansion of truncated densities, the SINC approach builds on\nthe Shannon Sampling Theorem revisited for functions with bounded support. We\nprovide several results which were missing in the early derivation: i) a\nrigorous proof of the convergence of the SINC formula to the correct option\nprice when the support grows and the number of Fourier frequencies increases;\nii) ready to implement formulas for put, Cash-or-Nothing, and Asset-or-Nothing\noptions; iii) a systematic comparison with the COS formula for several\nlog-price models; iv) a numerical challenge against alternative Fast Fourier\nspecifications, such as Carr and Madan (1999) and Lewis (2000); v) an extensive\npricing exercise under the rough Heston model of Jaisson and Rosenbaum (2015);\nvi) formulas to evaluate numerically the moments of a truncated density. The\nadvantages of the SINC approach are numerous. When compared to benchmark\nmethodologies, SINC provides the most accurate and fast pricing computation.\nThe method naturally lends itself to price all options in a smile concurrently\nby means of Fast Fourier techniques, boosting fast calibration. Pricing\nrequires to resort only to odd moments in the Fourier space. A previous version\nof this manuscript circulated with the title `Rough Heston: The SINC way'.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 16:43:07 GMT"}, {"version": "v2", "created": "Wed, 19 May 2021 13:01:45 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Baschetti", "Fabio", ""], ["Bormetti", "Giacomo", ""], ["Romagnoli", "Silvia", ""], ["Rossi", "Pietro", ""]]}, {"id": "2009.01219", "submitter": "Eric Hall", "authors": "Christian Bayer and Eric Joseph Hall and Ra\\'ul Tempone", "title": "Weak error rates for option pricing under the rough Bergomi model", "comments": "27 pages, 4 figures. Fixed error in a calculation that does not\n  impact the overall weak error rate", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP cs.NA math.NA math.PR q-fin.MF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In quantitative finance, modeling the volatility structure of underlying\nassets is a key component in the pricing of options. Rough stochastic\nvolatility models, such as the rough Bergomi model [Bayer, Friz, Gatheral,\nQuantitative Finance 16(6), 887-904, 2016], seek to fit observed market data\nbased on the observation that the log-realized variance behaves like a\nfractional Brownian motion with small Hurst parameter, $H < 1/2$, over\nreasonable timescales. Both time series data of asset prices and option derived\nprice data indicate that $H$ often takes values close to $0.1$ or smaller, i.e.\nrougher than Brownian Motion. This change greatly improves the fit to time\nseries data of underlying asset prices as well as to option prices while\nmaintaining parsimoniousness. However, the non-Markovian nature of the driving\nfractional Brownian motion in the rough Bergomi model poses severe challenges\nfor theoretical and numerical analyses as well as for computational practice.\nWhile the explicit Euler method is known to converge to the solution of the\nrough Bergomi model, its strong rate of convergence is only $H$. For a\nsimplified rough Bergomi model, we prove rate $H + 1/2$ for the weak\nconvergence of the Euler method and, surprisingly, in the case of quadratic\npayoff functions we obtain rate one. Indeed, the problem of weak convergence\nfor rough Bergomi is very subtle; we provide examples demonstrating that the\nrate of convergence for payoff functions well approximated by second-order\npolynomials, as weighted by the law of the fractional Brownian motion, may be\nhard to distinguish from rate one empirically. Our proof relies on Taylor\nexpansions and an affine Markovian representation of the underlying and is\nfurther supported by numerical experiments.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 17:51:46 GMT"}, {"version": "v2", "created": "Wed, 12 May 2021 10:49:05 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Bayer", "Christian", ""], ["Hall", "Eric Joseph", ""], ["Tempone", "Ra\u00fal", ""]]}, {"id": "2009.03202", "submitter": "Shuaiqiang Liu", "authors": "Shuaiqiang Liu and Lech A. Grzelak and Cornelis W. Oosterlee", "title": "The Seven-League Scheme: Deep learning for large time step Monte Carlo\n  simulations of stochastic differential equations", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an accurate data-driven numerical scheme to solve Stochastic\nDifferential Equations (SDEs), by taking large time steps. The SDE\ndiscretization is built up by means of a polynomial chaos expansion method, on\nthe basis of accurately determined stochastic collocation (SC) points. By\nemploying an artificial neural network to learn these SC points, we can perform\nMonte Carlo simulations with large time steps. Error analysis confirms that\nthis data-driven scheme results in accurate SDE solutions in the sense of\nstrong convergence, provided the learning methodology is robust and accurate.\nWith a variant method called the compression-decompression collocation and\ninterpolation technique, we can drastically reduce the number of neural network\nfunctions that have to be learned, so that computational speed is enhanced.\nNumerical results show the high quality strong convergence error results, when\nusing large time steps, and the novel scheme outperforms some classical\nnumerical SDE discretizations. Some applications, here in financial option\nvaluation, are also presented.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 16:06:20 GMT"}, {"version": "v2", "created": "Tue, 8 Sep 2020 08:41:14 GMT"}, {"version": "v3", "created": "Thu, 10 Sep 2020 13:53:13 GMT"}, {"version": "v4", "created": "Fri, 11 Sep 2020 19:22:27 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Liu", "Shuaiqiang", ""], ["Grzelak", "Lech A.", ""], ["Oosterlee", "Cornelis W.", ""]]}, {"id": "2009.05034", "submitter": "Josef Teichmann", "authors": "Thomas Krabichler and Josef Teichmann", "title": "Deep Replication of a Runoff Portfolio", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To the best of our knowledge, the application of deep learning in the field\nof quantitative risk management is still a relatively recent phenomenon. This\narticle presents the key notions of Deep Asset Liability Management (Deep~ALM)\nfor a technological transformation in the management of assets and liabilities\nalong a whole term structure. The approach has a profound impact on a wide\nrange of applications such as optimal decision making for treasurers, optimal\nprocurement of commodities or the optimisation of hydroelectric power plants.\nAs a by-product, intriguing aspects of goal-based investing or Asset Liability\nManagement (ALM) in abstract terms concerning urgent challenges of our society\nare expected alongside. We illustrate the potential of the approach in a\nstylised case.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 17:55:03 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Krabichler", "Thomas", ""], ["Teichmann", "Josef", ""]]}, {"id": "2009.05508", "submitter": "G\\'abor Petneh\\'azi", "authors": "Bernadett Aradi, G\\'abor Petneh\\'azi, J\\'ozsef G\\'all", "title": "Volatility Forecasting with 1-dimensional CNNs via transfer learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Volatility is a natural risk measure in finance as it quantifies the\nvariation of stock prices. A frequently considered problem in mathematical\nfinance is to forecast different estimates of volatility. What makes it\npromising to use deep learning methods for the prediction of volatility is the\nfact, that stock price returns satisfy some common properties, referred to as\n`stylized facts'. Also, the amount of data used can be high, favoring the\napplication of neural networks. We used 10 years of daily prices for hundreds\nof frequently traded stocks, and compared different CNN architectures: some\nnetworks use only the considered stock, but we tried out a construction which,\nfor training, uses much more series, but not the considered stocks.\nEssentially, this is an application of transfer learning, and its performance\nturns out to be much better in terms of prediction error. We also compare our\ndilated causal CNNs to the classical ARIMA method using an automatic model\nselection procedure.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 19:09:33 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Aradi", "Bernadett", ""], ["Petneh\u00e1zi", "G\u00e1bor", ""], ["G\u00e1ll", "J\u00f3zsef", ""]]}, {"id": "2009.06914", "submitter": "Benjamin Patrick Evans", "authors": "Benjamin Patrick Evans, Kirill Glavatskiy, Michael S. Harr\\'e, Mikhail\n  Prokopenko", "title": "The impact of social influence in Australian real-estate: market\n  forecasting with a spatial agent-based model", "comments": "25 pages + 31 page appendix", "journal-ref": null, "doi": "10.1007/s11403-021-00324-7", "report-no": null, "categories": "q-fin.CP cs.CE nlin.AO physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Housing markets are inherently spatial, yet many existing models fail to\ncapture this spatial dimension. Here we introduce a new graph-based approach\nfor incorporating a spatial component in a large-scale urban housing\nagent-based model (ABM). The model explicitly captures several social and\neconomic factors that influence the agents' decision-making behaviour (such as\nfear of missing out, their trend following aptitude, and the strength of their\nsubmarket outreach), and interprets these factors in spatial terms. The\nproposed model is calibrated and validated with the housing market data for the\nGreater Sydney region. The ABM simulation results not only include predictions\nfor the overall market, but also produce area-specific forecasting at the level\nof local government areas within Sydney as arising from individual buy and sell\ndecisions. In addition, the simulation results elucidate agent preferences in\nsubmarkets, highlighting differences in agent behaviour, for example, between\nfirst-time home buyers and investors, and between both local and overseas\ninvestors.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 08:21:11 GMT"}, {"version": "v2", "created": "Wed, 10 Feb 2021 00:51:23 GMT"}], "update_date": "2021-03-25", "authors_parsed": [["Evans", "Benjamin Patrick", ""], ["Glavatskiy", "Kirill", ""], ["Harr\u00e9", "Michael S.", ""], ["Prokopenko", "Mikhail", ""]]}, {"id": "2009.07947", "submitter": "Thomas Dierckx", "authors": "Thomas Dierckx, Jesse Davis and Wim Schoutens", "title": "Using Machine Learning and Alternative Data to Predict Movements in\n  Market Risk", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using machine learning and alternative data for the prediction of financial\nmarkets has been a popular topic in recent years. Many financial variables such\nas stock price, historical volatility and trade volume have already been\nthrough extensive investigation. Remarkably, we found no existing research on\nthe prediction of an asset's market implied volatility within this context.\nThis forward-looking measure gauges the sentiment on the future volatility of\nan asset, and is deemed one of the most important parameters in the world of\nderivatives. The ability to predict this statistic may therefore provide a\ncompetitive edge to practitioners of market making and asset management alike.\nConsequently, in this paper we investigate Google News statistics and Wikipedia\nsite traffic as alternative data sources to quantitative market data and\nconsider Logistic Regression, Support Vector Machines and AdaBoost as machine\nlearning models. We show that movements in market implied volatility can indeed\nbe predicted through the help of machine learning techniques. Although the\nemployed alternative data appears to not enhance predictive accuracy, we reveal\npreliminary evidence of non-linear relationships between features obtained from\nWikipedia page traffic and movements in market implied volatility.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 21:36:03 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Dierckx", "Thomas", ""], ["Davis", "Jesse", ""], ["Schoutens", "Wim", ""]]}, {"id": "2009.08214", "submitter": "Huyen Pham", "authors": "William Lefebvre (LPSM), Gregoire Loeper (BNPP CIB GM Lab), Huy\\^en\n  Pham (LPSM)", "title": "Mean-variance portfolio selection with tracking error penalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies a variation of the continuous-time mean-variance portfolio\nselection where a tracking-error penalization is added to the mean-variance\ncriterion. The tracking error term penalizes the distance between the\nallocation controls and a reference portfolio with same wealth and fixed\nweights. Such consideration is motivated as follows: (i) On the one hand, it is\na way to robustify the mean-variance allocation in case of misspecified\nparameters, by \"fitting\" it to a reference portfolio that can be agnostic to\nmarket parameters; (ii) On the other hand, it is a procedure to track a\nbenchmark and improve the Sharpe ratio of the resulting portfolio by\nconsidering a mean-variance criterion in the objective function. This problem\nis formulated as a McKean-Vlasov control problem. We provide explicit solutions\nfor the optimal portfolio strategy and asymptotic expansions of the portfolio\nstrategy and efficient frontier for small values of the tracking error\nparameter. Finally, we compare the Sharpe ratios obtained by the standard\nmean-variance allocation and the penalized one for four different reference\nportfolios: equal-weights, minimum-variance, equal risk contributions and\nshrinking portfolio. This comparison is done on a simulated misspecified model,\nand on a backtest performed with historical data. Our results show that in most\ncases, the penalized portfolio outperforms in terms of Sharpe ratio both the\nstandard mean-variance and the reference portfolio.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 11:27:28 GMT"}, {"version": "v2", "created": "Fri, 18 Sep 2020 08:21:00 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Lefebvre", "William", "", "LPSM"], ["Loeper", "Gregoire", "", "BNPP CIB GM Lab"], ["Pham", "Huy\u00ean", "", "LPSM"]]}, {"id": "2009.08412", "submitter": "Kyle Steinhauer", "authors": "Kyle Steinhauer, Takahisa Fukadai, Sho Yoshida", "title": "Solving the Optimal Trading Trajectory Problem Using Simulated\n  Bifurcation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP q-fin.PM q-fin.RM quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use an optimization procedure based on simulated bifurcation (SB) to solve\nthe integer portfolio and trading trajectory problem with an unprecedented\ncomputational speed. The underlying algorithm is based on a classical\ndescription of quantum adiabatic evolutions of a network of non-linearly\ninteracting oscillators. This formulation has already proven to beat state of\nthe art computation times for other NP-hard problems and is expected to show\nsimilar performance for certain portfolio optimization problems. Inspired by\nsuch we apply the SB approach to the portfolio integer optimization problem\nwith quantity constraints and trading activities. We show first numerical\nresults for portfolios of up to 1000 assets, which already confirm the power of\nthe SB algorithm for its novel use-case as a portfolio and trading trajectory\noptimizer.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 16:42:04 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Steinhauer", "Kyle", ""], ["Fukadai", "Takahisa", ""], ["Yoshida", "Sho", ""]]}, {"id": "2009.08814", "submitter": "Paolo Pigato", "authors": "Peter K. Friz, Paul Gassiat, Paolo Pigato", "title": "Short dated smile under Rough Volatility: asymptotics and numerics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In [Precise Asymptotics for Robust Stochastic Volatility Models; Ann. Appl.\nProbab. 2020] we introduce a new methodology to analyze large classes of\n(classical and rough) stochastic volatility models, with special regard to\nshort-time and small noise formulae for option prices, using the framework\n[Bayer et al; A regularity structure for rough volatility; Math. Fin. 2020]. We\ninvestigate here the fine structure of this expansion in large deviations and\nmoderate deviations regimes, together with consequences for implied volatility.\nWe discuss computational aspects relevant for the practical application of\nthese formulas. We specialize such expansions to prototypical rough volatility\nexamples and discuss numerical evidence.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 12:43:06 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Friz", "Peter K.", ""], ["Gassiat", "Paul", ""], ["Pigato", "Paolo", ""]]}, {"id": "2009.08821", "submitter": "Frederic Butin", "authors": "Fr\\'ed\\'eric Butin", "title": "A bounded operator approach to technical indicators without lag", "comments": "10 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.TR q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the framework of technical analysis for algorithmic trading we use a\nlinear algebra approach in order to define classical technical indicators as\nbounded operators of the space $l^\\infty(\\mathbb{N})$. This more abstract view\nenables us to define in a very simple way the no-lag versions of these tools.\nThen we apply our results to a basic trading system in order to compare the\nclassical Elder's impulse system with its no-lag version and the so-called\nNyquist-Elder's impulse system.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 13:07:38 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Butin", "Fr\u00e9d\u00e9ric", ""]]}, {"id": "2009.09058", "submitter": "Anne MacKay", "authors": "Iro Ren\\'e Kouarfate, Michael A. Kouritzin, Anne MacKay", "title": "Explicit solution simulation method for the 3/2 model", "comments": "21 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An explicit weak solution for the 3/2 stochastic volatility model is obtained\nand used to develop a simulation algorithm for option pricing purposes. The 3/2\nmodel is a non-affine stochastic volatility model whose variance process is the\ninverse of a CIR process. This property is exploited here to obtain an explicit\nweak solution, similarly to Kouritzin (2018). A simulation algorithm based on\nthis solution is proposed and tested via numerical examples. The performance of\nthe resulting pricing algorithm is comparable to that of other popular\nsimulation algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 20:43:33 GMT"}, {"version": "v2", "created": "Fri, 8 Jan 2021 23:26:08 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Kouarfate", "Iro Ren\u00e9", ""], ["Kouritzin", "Michael A.", ""], ["MacKay", "Anne", ""]]}, {"id": "2009.09342", "submitter": "Andrey Itkin", "authors": "Andrey Itkin and Dmitry Muravey", "title": "Semi-analytic pricing of double barrier options with time-dependent\n  barriers and rebates at hit", "comments": "25 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP q-fin.MF q-fin.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We continue a series of papers devoted to construction of semi-analytic\nsolutions for barrier options. These options are written on underlying\nfollowing some simple one-factor diffusion model, but all the parameters of the\nmodel as well as the barriers are time-dependent. We managed to show that these\nsolutions are systematically more efficient for pricing and calibration than,\neg., the corresponding finite-difference solvers. In this paper we extend this\ntechnique to pricing double barrier options and present two approaches to\nsolving it: the General Integral transform method and the Heat Potential\nmethod. Our results confirm that for double barrier options these semi-analytic\ntechniques are also more efficient than the traditional numerical methods used\nto solve this type of problems.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 03:23:04 GMT"}, {"version": "v2", "created": "Wed, 23 Sep 2020 02:19:52 GMT"}, {"version": "v3", "created": "Mon, 12 Oct 2020 17:53:09 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Itkin", "Andrey", ""], ["Muravey", "Dmitry", ""]]}, {"id": "2009.10764", "submitter": "Michele Leonardo Bianchi", "authors": "Michele Leonardo Bianchi and Giovanni De Luca and Giorgia Rivieccio", "title": "CoVaR with volatility clustering, heavy tails and non-linear dependence", "comments": "21 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM q-fin.CP q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we estimate the conditional value-at-risk by fitting different\nmultivariate parametric models capturing some stylized facts about multivariate\nfinancial time series of equity returns: heavy tails, negative skew, asymmetric\ndependence, and volatility clustering. While the volatility clustering effect\nis got by AR-GARCH dynamics of the GJR type, the other stylized facts are\ncaptured through non-Gaussian multivariate models and copula functions. The\nCoVaR$^{\\leq}$ is computed on the basis on the multivariate normal model, the\nmultivariate normal tempered stable (MNTS) model, the multivariate generalized\nhyperbolic model (MGH) and four possible copula functions. These risk measure\nestimates are compared to the CoVaR$^{=}$ based on the multivariate normal\nGARCH model. The comparison is conducted by backtesting the competitor models\nover the time span from January 2007 to March 2020. In the empirical study we\nconsider a sample of listed banks of the euro area belonging to the main or to\nthe additional global systemically important banks (GSIBs) assessment sample.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 19:03:06 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Bianchi", "Michele Leonardo", ""], ["De Luca", "Giovanni", ""], ["Rivieccio", "Giorgia", ""]]}, {"id": "2009.10972", "submitter": "Eduardo Abi Jaber", "authors": "Eduardo Abi Jaber", "title": "The characteristic function of Gaussian stochastic volatility models: an\n  analytic expression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic volatility models based on Gaussian processes, like fractional\nBrownian motion, are able to reproduce important stylized facts of financial\nmarkets such as rich autocorrelation structures, persistence and roughness of\nsample paths. This is made possible by virtue of the flexibility introduced in\nthe choice of the covariance function of the Gaussian process. The price to pay\nis that, in general, such models are no longer Markovian nor semimartingales,\nwhich limits their practical use. We derive, in two different ways, an explicit\nanalytic expression for the joint characteristic function of the log-price and\nits integrated variance in general Gaussian stochastic volatility models. Such\nanalytic expression can be approximated by closed form matrix expressions\nstemming from Wishart distributions. This opens the door to fast approximation\nof the joint density and pricing of derivatives on both the stock and its\nrealized variance using Fourier inversion techniques. In the context of rough\nvolatility modeling, our results apply to the (rough) fractional Stein-Stein\nmodel and provide the first analytic formulae for option pricing known to date,\ngeneralizing that of Stein-Stein, Sch{\\\"o}bel-Zhu and a special case of Heston.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 07:23:12 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Jaber", "Eduardo Abi", ""]]}, {"id": "2009.11064", "submitter": "Arno Botha", "authors": "Arno Botha, Conrad Beyers, Pieter de Villiers", "title": "Simulation-based optimisation of the timing of loan recovery across\n  different portfolios", "comments": "Accepted by the journal \"Expert Systems with Applications\". 25 pages\n  (including appendix), 9 figures. arXiv admin note: text overlap with older\n  arXiv:1907.12615", "journal-ref": null, "doi": "10.1016/j.eswa.2021.114878", "report-no": null, "categories": "q-fin.RM q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel procedure is presented for the objective comparison and evaluation of\na bank's decision rules in optimising the timing of loan recovery. This\nprocedure is based on finding a delinquency threshold at which the financial\nloss of a loan portfolio (or segment therein) is minimised. Our procedure is an\nexpert system that incorporates the time value of money, costs, and the\nfundamental trade-off between accumulating arrears versus forsaking future\ninterest revenue. Moreover, the procedure can be used with different\ndelinquency measures (other than payments in arrears), thereby allowing an\nindirect comparison of these measures. We demonstrate the system across a range\nof credit risk scenarios and portfolio compositions. The computational results\nshow that threshold optima can exist across all reasonable values of both the\npayment probability (default risk) and the loss rate (loan collateral). In\naddition, the procedure reacts positively to portfolios afflicted by either\nsystematic defaults (such as during an economic downturn) or episodic\ndelinquency (i.e., cycles of curing and re-defaulting). In optimising a\nportfolio's recovery decision, our procedure can better inform the quantitative\naspects of a bank's collection policy than relying on arbitrary discretion\nalone.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 20:23:14 GMT"}, {"version": "v2", "created": "Fri, 26 Feb 2021 06:37:03 GMT"}, {"version": "v3", "created": "Thu, 8 Apr 2021 18:14:31 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Botha", "Arno", ""], ["Beyers", "Conrad", ""], ["de Villiers", "Pieter", ""]]}, {"id": "2009.11075", "submitter": "Konstantinos P. Panousis", "authors": "Anastasios Petropoulos, Vassilis Siakoulis, Konstantinos P. Panousis,\n  Theodoros Christophides, and Sotirios Chatzis", "title": "A Deep Learning Approach for Dynamic Balance Sheet Stress Testing", "comments": "Preprint submitted to Journal of Forecasting", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP econ.GN q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the aftermath of the financial crisis, supervisory authorities have\nconsiderably improved their approaches in performing financial stress testing.\nHowever, they have received significant criticism by the market participants\ndue to the methodological assumptions and simplifications employed, which are\nconsidered as not accurately reflecting real conditions. First and foremost,\ncurrent stress testing methodologies attempt to simulate the risks underlying a\nfinancial institution's balance sheet by using several satellite models, making\ntheir integration a really challenging task with significant estimation errors.\nSecondly, they still suffer from not employing advanced statistical techniques,\nlike machine learning, which capture better the nonlinear nature of adverse\nshocks. Finally, the static balance sheet assumption, that is often employed,\nimplies that the management of a bank passively monitors the realization of the\nadverse scenario, but does nothing to mitigate its impact. To address the above\nmentioned criticism, we introduce in this study a novel approach utilizing deep\nlearning approach for dynamic balance sheet stress testing. Experimental\nresults give strong evidence that deep learning applied in big\nfinancial/supervisory datasets create a state of the art paradigm, which is\ncapable of simulating real world scenarios in a more efficient way.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 11:47:34 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Petropoulos", "Anastasios", ""], ["Siakoulis", "Vassilis", ""], ["Panousis", "Konstantinos P.", ""], ["Christophides", "Theodoros", ""], ["Chatzis", "Sotirios", ""]]}, {"id": "2009.14764", "submitter": "Orcan Ogetbil", "authors": "Orcan Ogetbil, Narayan Ganesan, Bernhard Hientzsch", "title": "Calibrating Local Volatility Models with Stochastic Drift and Diffusion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.MF q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Monte Carlo calibration algorithms for three models: local\nvolatility with stochastic interest rates, stochastic local volatility with\ndeterministic interest rates, and finally stochastic local volatility with\nstochastic interest rates. For each model, we include detailed derivations of\nthe corresponding SDE systems, and list the required input data and steps for\ncalibration. We give conditions under which a local volatility can exist given\nEuropean option prices, stochastic interest rate model parameters, and\ncorrelations. The models are posed in a foreign exchange setting. The drift\nterm for the exchange rate is given as a difference of two stochastic short\nrates, domestic and foreign, each modeled by a G1++ process. For stochastic\nvolatility, we model the variance for the exchange rate by a CIR process. We\ninclude tests to show the convergence and the accuracy of the proposed\nalgorithms.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 16:03:08 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Ogetbil", "Orcan", ""], ["Ganesan", "Narayan", ""], ["Hientzsch", "Bernhard", ""]]}]