[{"id": "1508.00090", "submitter": "Man Chung Fung", "authors": "Man Chung Fung, Katja Ignatieva, Michael Sherris", "title": "Managing Systematic Mortality Risk in Life Annuities: An Application of\n  Longevity Derivatives", "comments": "23 pages; under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper assesses the hedge effectiveness of an index-based longevity swap\nand a longevity cap. Although swaps are a natural instrument for hedging\nlongevity risk, derivatives with non-linear pay-offs, such as longevity caps,\nalso provide downside protection. A tractable stochastic mortality model with\nage dependent drift and volatility is developed and analytical formulae for\nprices of these longevity derivatives are derived. Hedge effectiveness is\nconsidered for a hypothetical life annuity portfolio. The hedging of the life\nannuity portfolio is comprehensively assessed for a range of assumptions for\nthe market price of longevity risk, the term to maturity of the hedging\ninstruments, as well as the size of the underlying annuity portfolio. The model\nis calibrated using Australian mortality data. The results provide a\ncomprehensive analysis of longevity hedging, highlighting the risk management\nbenefits and costs of linear and nonlinear payoff structures.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2015 06:58:37 GMT"}], "update_date": "2015-08-04", "authors_parsed": [["Fung", "Man Chung", ""], ["Ignatieva", "Katja", ""], ["Sherris", "Michael", ""]]}, {"id": "1508.00322", "submitter": "Man Chung Fung", "authors": "Man Chung Fung, Gareth W. Peters, Pavel V. Shevchenko", "title": "A State-Space Estimation of the Lee-Carter Mortality Model and\n  Implications for Annuity Pricing", "comments": "9 pages; conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we investigate a state-space representation of the Lee-Carter\nmodel which is a benchmark stochastic mortality model for forecasting\nage-specific death rates. Existing relevant literature focuses mainly on\nmortality forecasting or pricing of longevity derivatives, while the full\nimplications and methods of using the state-space representation of the\nLee-Carter model in pricing retirement income products is yet to be examined.\nThe main contribution of this article is twofold. First, we provide a rigorous\nand detailed derivation of the posterior distributions of the parameters and\nthe latent process of the Lee-Carter model via Gibbs sampling. Our assumption\nfor priors is slightly more general than the current literature in this area.\nMoreover, we suggest a new form of identification constraint not yet utilised\nin the actuarial literature that proves to be a more convenient approach for\nestimating the model under the state-space framework. Second, by exploiting the\nposterior distribution of the latent process and parameters, we examine the\npricing range of annuities, taking into account the stochastic nature of the\ndynamics of the mortality rates. In this way we aim to capture the impact of\nlongevity risk on the pricing of annuities. The outcome of our study\ndemonstrates that an annuity price can be more than 4% under-valued when\ndifferent assumptions are made on determining the survival curve constructed\nfrom the distribution of the forecasted death rates. Given that a typical\nannuity portfolio consists of a large number of policies with maturities which\nspan decades, we conclude that the impact of longevity risk on the accurate\npricing of annuities is a significant issue to be further researched. In\naddition, we find that mis-pricing is increasingly more pronounced for older\nages as well as for annuity policies having a longer maturity.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2015 06:42:04 GMT"}], "update_date": "2015-08-04", "authors_parsed": [["Fung", "Man Chung", ""], ["Peters", "Gareth W.", ""], ["Shevchenko", "Pavel V.", ""]]}, {"id": "1508.02367", "submitter": "Zachary Feinstein", "authors": "Zachary Feinstein and Birgit Rudloff", "title": "A recursive algorithm for multivariate risk measures and a set-valued\n  Bellman's principle", "comments": "25 pages, 5 figures", "journal-ref": null, "doi": "10.1007/s10898-016-0459-8", "report-no": null, "categories": "q-fin.RM q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A method for calculating multi-portfolio time consistent multivariate risk\nmeasures in discrete time is presented. Market models for $d$ assets with\ntransaction costs or illiquidity and possible trading constraints are\nconsidered on a finite probability space. The set of capital requirements at\neach time and state is calculated recursively backwards in time along the event\ntree. We motivate why the proposed procedure can be seen as a set-valued\nBellman's principle, that might be of independent interest within the growing\nfield of set optimization. We give conditions under which the backwards\ncalculation of the sets reduces to solving a sequence of linear, respectively\nconvex vector optimization problems. Numerical examples are given and include\nsuperhedging under illiquidity, the set-valued entropic risk measure, and the\nmulti-portfolio time consistent version of the relaxed worst case risk measure\nand of the set-valued average value at risk.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2015 19:28:35 GMT"}, {"version": "v2", "created": "Mon, 4 Jul 2016 16:22:06 GMT"}], "update_date": "2017-01-27", "authors_parsed": [["Feinstein", "Zachary", ""], ["Rudloff", "Birgit", ""]]}, {"id": "1508.03841", "submitter": "Juan-Fernando Ospina-Giraldo", "authors": "Juan Ospina", "title": "New Analytical Solutions of a Modified Black-Scholes Equation with the\n  European Put Option", "comments": "16 pages,4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using Maple, we compute some analytical solutions of a modified Black-Scholes\nequation, recently proposed, in the case of the European put option. We show\nthat the modified Black-Scholes equation with the European put option is\nexactly solvable in terms of associated Laguerre polynomials. We make some\nnumerical experiments with the analytical solutions and we compare our results\nwith the results derived from numerical experiments using the standard\nBlack-Scholes equation.\n", "versions": [{"version": "v1", "created": "Sun, 16 Aug 2015 15:59:53 GMT"}], "update_date": "2015-08-18", "authors_parsed": [["Ospina", "Juan", ""]]}, {"id": "1508.04487", "submitter": "J. Nathan Kutz", "authors": "Jordan Mann and J. Nathan Kutz", "title": "Dynamic Mode Decomposition for Financial Trading Strategies", "comments": "18 pages, 7 figures. arXiv admin note: text overlap with\n  arXiv:1506.00564", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate the application of an algorithmic trading strategy based upon\nthe recently developed dynamic mode decomposition (DMD) on portfolios of\nfinancial data. The method is capable of characterizing complex dynamical\nsystems, in this case financial market dynamics, in an equation-free manner by\ndecomposing the state of the system into low-rank terms whose temporal\ncoefficients in time are known. By extracting key temporal coherent structures\n(portfolios) in its sampling window, it provides a regression to a best fit\nlinear dynamical system, allowing for a predictive assessment of the market\ndynamics and informing an investment strategy. The data-driven analytics\ncapitalizes on stock market patterns, either real or perceived, to inform\nbuy/sell/hold investment decisions. Critical to the method is an associated\nlearning algorithm that optimizes the sampling and prediction windows of the\nalgorithm by discovering trading hot-spots. The underlying mathematical\nstructure of the algorithms is rooted in methods from nonlinear dynamical\nsystems and shows that the decomposition is an effective mathematical tool for\ndata-driven discovery of market patterns.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2015 23:51:57 GMT"}], "update_date": "2015-08-20", "authors_parsed": [["Mann", "Jordan", ""], ["Kutz", "J. Nathan", ""]]}, {"id": "1508.04512", "submitter": "Aurelio Fernandez Bariviera", "authors": "Aurelio F. Bariviera, M.T. Martin, A. Plastino, V. Vampa", "title": "LIBOR troubles: anomalous movements detection based on Maximum Entropy", "comments": null, "journal-ref": null, "doi": "10.1016/j.physa.2016.01.005", "report-no": null, "categories": "q-fin.ST q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  According to the definition of the London Interbank Offered Rate (LIBOR),\ncontributing banks should give fair estimates of their own borrowing costs in\nthe interbank market. Between 2007 and 2009, several banks made inappropriate\nsubmissions of LIBOR, sometimes motivated by profit-seeking from their trading\npositions. In 2012, several newspapers' articles began to cast doubt on LIBOR\nintegrity, leading surveillance authorities to conduct investigations on banks'\nbehavior. Such procedures resulted in severe fines imposed to involved banks,\nwho recognized their financial inappropriate conduct. In this paper, we uncover\nsuch unfair behavior by using a forecasting method based on the Maximum Entropy\nprinciple. Our results are robust against changes in parameter settings and\ncould be of great help for market surveillance.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2015 03:17:36 GMT"}], "update_date": "2016-03-23", "authors_parsed": [["Bariviera", "Aurelio F.", ""], ["Martin", "M. T.", ""], ["Plastino", "A.", ""], ["Vampa", "V.", ""]]}, {"id": "1508.04748", "submitter": "Aurelio Fernandez Bariviera", "authors": "Aurelio F. Bariviera, M. Bel\\'en Guercio, Lisana B. Martinez, Osvaldo\n  A. Rosso", "title": "The (in)visible hand in the Libor market: an Information Theory approach", "comments": "PACS 89.65.Gh Econophysics; 74.40.De noise and chaos", "journal-ref": "The European Physical Journal B (2015) 88(8):208", "doi": "10.1140/epjb/e2015-60410-1", "report-no": null, "categories": "q-fin.ST q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper analyzes several interest rates time series from the United\nKingdom during the period 1999 to 2014. The analysis is carried out using a\npioneering statistical tool in the financial literature: the complexity-entropy\ncausality plane. This representation is able to classify different stochastic\nand chaotic regimes in time series. We use sliding temporal windows to assess\nchanges in the intrinsic stochastic dynamics of the time series. Anomalous\nbehavior in the Libor is detected, especially around the time of the last\nfinancial crisis, that could be consistent with data manipulation.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2015 19:27:39 GMT"}], "update_date": "2015-08-20", "authors_parsed": [["Bariviera", "Aurelio F.", ""], ["Guercio", "M. Bel\u00e9n", ""], ["Martinez", "Lisana B.", ""], ["Rosso", "Osvaldo A.", ""]]}, {"id": "1508.04900", "submitter": "Dieter Hendricks", "authors": "Dieter Hendricks, Tim Gebbie, Diane Wilcox", "title": "Detecting intraday financial market states using temporal clustering", "comments": "30 pages, 16 figures, 8 tables, published in Quantitative Finance", "journal-ref": "Quantitative Finance, (2016),16:11, 1657-1678", "doi": "10.1080/14697688.2016.1171378", "report-no": null, "categories": "q-fin.TR q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the application of a high-speed maximum likelihood clustering\nalgorithm to detect temporal financial market states, using correlation\nmatrices estimated from intraday market microstructure features. We first\ndetermine the ex-ante intraday temporal cluster configurations to identify\nmarket states, and then study the identified temporal state features to extract\nstate signature vectors which enable online state detection. The state\nsignature vectors serve as low-dimensional state descriptors which can be used\nin learning algorithms for optimal planning in the high-frequency trading\ndomain. We present a feasible scheme for real-time intraday state detection\nfrom streaming market data feeds. This study identifies an interesting\nhierarchy of system behaviour which motivates the need for time-scale-specific\nstate space reduction for participating agents.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2015 07:22:55 GMT"}, {"version": "v2", "created": "Tue, 22 Mar 2016 14:12:31 GMT"}, {"version": "v3", "created": "Fri, 24 Feb 2017 16:37:27 GMT"}], "update_date": "2018-10-08", "authors_parsed": [["Hendricks", "Dieter", ""], ["Gebbie", "Tim", ""], ["Wilcox", "Diane", ""]]}, {"id": "1508.06117", "submitter": "Leonard Rogers", "authors": "L. C. G. Rogers", "title": "Bermudan options by simulation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of this study is to devise numerical methods for dealing with very\nhigh-dimensional Bermudan-style derivatives. For such problems, we quickly see\nthat we can at best hope for price bounds, and we can only use a simulation\napproach. We use the approach of Barraquand & Martineau which proposes that the\nreward process should be treated as if it were Markovian, and then uses this to\ngenerate a stopping rule and hence a lower bound on the price. Using the dual\napproach introduced by Rogers, and Haugh & Kogan, this approximate Markov\nprocess leads us to hedging strategies, and upper bounds on the price. The\nmethodology is generic, and is illustrated on eight examples of varying levels\nof difficulty. Run times are largely insensitive to dimension.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2015 11:46:48 GMT"}, {"version": "v2", "created": "Tue, 5 Jan 2016 12:27:04 GMT"}], "update_date": "2016-01-06", "authors_parsed": [["Rogers", "L. C. G.", ""]]}, {"id": "1508.06182", "submitter": "Gili Rosenberg", "authors": "Gili Rosenberg, Poya Haghnegahdar, Phil Goddard, Peter Carr, Kesheng\n  Wu and Marcos L\\'opez de Prado", "title": "Solving the Optimal Trading Trajectory Problem Using a Quantum Annealer", "comments": "7 pages; expanded and updated", "journal-ref": "IEEE Journal of Selected Topics in Signal Processing (JSTSP),\n  Volume 10, Issue 6, 2016, and Proc. of the 8th Workshop on High Performance\n  Computational Finance (WHPCF), p. 7, ACM, 2015", "doi": "10.1109/JSTSP.2016.2574703", "report-no": null, "categories": "q-fin.CP cs.DS math.OC q-fin.PM quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We solve a multi-period portfolio optimization problem using D-Wave Systems'\nquantum annealer. We derive a formulation of the problem, discuss several\npossible integer encoding schemes, and present numerical examples that show\nhigh success rates. The formulation incorporates transaction costs (including\npermanent and temporary market impact), and, significantly, the solution does\nnot require the inversion of a covariance matrix. The discrete multi-period\nportfolio optimization problem we solve is significantly harder than the\ncontinuous variable problem. We present insight into how results may be\nimproved using suitable software enhancements, and why current quantum\nannealing technology limits the size of problem that can be successfully solved\ntoday. The formulation presented is specifically designed to be scalable, with\nthe expectation that as quantum annealing technology improves, larger problems\nwill be solvable using the same techniques.\n", "versions": [{"version": "v1", "created": "Sat, 22 Aug 2015 18:52:49 GMT"}, {"version": "v2", "created": "Fri, 28 Aug 2015 21:09:04 GMT"}, {"version": "v3", "created": "Thu, 11 Aug 2016 15:26:21 GMT"}], "update_date": "2016-09-29", "authors_parsed": [["Rosenberg", "Gili", ""], ["Haghnegahdar", "Poya", ""], ["Goddard", "Phil", ""], ["Carr", "Peter", ""], ["Wu", "Kesheng", ""], ["de Prado", "Marcos L\u00f3pez", ""]]}, {"id": "1508.06236", "submitter": "Luca Di Persio", "authors": "Luca Di Persio and Michele Bonollo and Gregorio Pellegrini", "title": "A computational spectral approach to interest rate models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP q-fin.MF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Polynomial Chaos Expansion (PCE) technique recovers a finite second order\nrandom variable exploiting suitable linear combinations of orthogonal\npolynomials which are functions of a given stochas- tic quantity {\\xi}, hence\nacting as a kind of random basis. The PCE methodology has been developed as a\nmathematically rigorous Uncertainty Quantification (UQ) method which aims at\nproviding reliable numerical estimates for some uncertain physical quantities\ndefining the dynamic of certain engineering models and their related\nsimulations. In the present paper we exploit the PCE approach to analyze some\nequity and interest rate models considering, without loss of generality, the\none dimensional case. In particular we will take into account those models\nwhich are based on the Geometric Brownian Motion (gBm), e.g. the Vasicek model,\nthe CIR model, etc. We also provide several numerical applications and results\nwhich are discussed for a set of volatility values. The latter allows us to\ntest the PCE technique on a quite large set of different scenarios, hence\nproviding a rather complete and detailed investigation on PCE-approximation's\nfeatures and properties, such as the convergence of statistics, distribution\nand quantiles. Moreover we give results concerning both an efficiency and an\naccuracy study of our approach by comparing our outputs with the ones obtained\nadopting the Monte Carlo approach in its standard form as well as in its\nenhanced version.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2015 18:17:40 GMT"}], "update_date": "2016-10-31", "authors_parsed": [["Di Persio", "Luca", ""], ["Bonollo", "Michele", ""], ["Pellegrini", "Gregorio", ""]]}, {"id": "1508.06339", "submitter": "Masaaki Fujii", "authors": "Masaaki Fujii, Akihiko Takahashi", "title": "A General Framework for the Benchmark pricing in a Fully Collateralized\n  Market", "comments": "Revised version. Initial title was \"choice of collateral currency\n  updated.\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PR q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collateralization with daily margining has become a new standard in the\npost-crisis market. Although there appeared vast literature on a so-called\nmulti-curve framework, a complete picture of a multi-currency setup with\ncross-currency basis can be rarely found since our initial attempts. This work\ngives its extension regarding a general framework of interest rates in a fully\ncollateralized market. It gives a new formulation of the currency funding\nspread which is better suited for the general dependence. In the last half, it\ndevelops a discretization of the HJM framework with a fixed tenor structure,\nwhich makes it implementable as a traditional Market Model.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2015 01:28:44 GMT"}, {"version": "v2", "created": "Mon, 7 Sep 2015 01:31:14 GMT"}], "update_date": "2015-09-08", "authors_parsed": [["Fujii", "Masaaki", ""], ["Takahashi", "Akihiko", ""]]}, {"id": "1508.06492", "submitter": "Anis Al Gerbi", "authors": "Anis Al Gerbi, Benjamin Jourdain, Emmanuelle Cl\\'ement", "title": "Ninomiya-Victoir scheme: strong convergence, antithetic version and\n  application to multilevel estimators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we are interested in the strong convergence properties of the\nNinomiya-Victoir scheme which is known to exhibit weak convergence with order\n2. We prove strong convergence with order $1/2$. This study is aimed at\nanalysing the use of this scheme either at each level or only at the finest\nlevel of a multilevel Monte Carlo estimator: indeed, the variance of a\nmultilevel Monte Carlo estimator is related to the strong error between the two\nschemes used on the coarse and fine grids at each level. Recently, Giles and\nSzpruch proposed a scheme permitting to construct a multilevel Monte Carlo\nestimator achieving the optimal complexity $O\\left(\\epsilon^{-2}\\right)$ for\nthe precision $\\epsilon$. In the same spirit, we propose a modified\nNinomiya-Victoir scheme, which may be strongly coupled with order $1$ to the\nGiles-Szpruch scheme at the finest level of a multilevel Monte Carlo estimator.\nNumerical experiments show that this choice improves the efficiency, since the\norder $2$ of weak convergence of the Ninomiya-Victoir scheme permits to reduce\nthe number of discretization levels.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2015 13:45:43 GMT"}, {"version": "v2", "created": "Wed, 7 Oct 2015 15:32:45 GMT"}], "update_date": "2015-10-08", "authors_parsed": [["Gerbi", "Anis Al", ""], ["Jourdain", "Benjamin", ""], ["Cl\u00e9ment", "Emmanuelle", ""]]}, {"id": "1508.06586", "submitter": "Carlos Pedro dos Santos Gon\\c{c}alves", "authors": "Carlos Pedro Gon\\c{c}alves", "title": "Financial Market Modeling with Quantum Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP cs.NE physics.soc-ph q-fin.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Econophysics has developed as a research field that applies the formalism of\nStatistical Mechanics and Quantum Mechanics to address Economics and Finance\nproblems. The branch of Econophysics that applies of Quantum Theory to\nEconomics and Finance is called Quantum Econophysics. In Finance, Quantum\nEconophysics' contributions have ranged from option pricing to market dynamics\nmodeling, behavioral finance and applications of Game Theory, integrating the\nempirical finding, from human decision analysis, that shows that nonlinear\nupdate rules in probabilities, leading to non-additive decision weights, can be\ncomputationally approached from quantum computation, with resulting quantum\ninterference terms explaining the non-additive probabilities. The current work\ndraws on these results to introduce new tools from Quantum Artificial\nIntelligence, namely Quantum Artificial Neural Networks as a way to build and\nsimulate financial market models with adaptive selection of trading rules,\nleading to turbulence and excess kurtosis in the returns distributions for a\nwide range of parameters.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2015 17:49:14 GMT"}], "update_date": "2015-08-27", "authors_parsed": [["Gon\u00e7alves", "Carlos Pedro", ""]]}]