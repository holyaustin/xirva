[{"id": "1406.0052", "submitter": "Martin Wahl", "authors": "Martin Wahl", "title": "Variable selection in high-dimensional additive models based on norms of\n  projections", "comments": "27 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of variable selection in high-dimensional sparse\nadditive models. We focus on the case that the components belong to\nnonparametric classes of functions. The proposed method is motivated by\ngeometric considerations in Hilbert spaces and consists of comparing the norms\nof the projections of the data onto various additive subspaces. Under minimal\ngeometric assumptions, we prove concentration inequalities which lead to new\nconditions under which consistent variable selection is possible. As an\napplication, we establish conditions under which a single component can be\nestimated with the rate of convergence corresponding to the situation in which\nthe other components are known.\n", "versions": [{"version": "v1", "created": "Sat, 31 May 2014 07:38:17 GMT"}, {"version": "v2", "created": "Sun, 1 Feb 2015 15:30:48 GMT"}], "update_date": "2015-02-03", "authors_parsed": [["Wahl", "Martin", ""]]}, {"id": "1406.0067", "submitter": "Can Le", "authors": "Can M. Le, Elizaveta Levina, Roman Vershynin", "title": "Optimization via Low-rank Approximation for Community Detection in\n  Networks", "comments": "45 pages, 7 figures; added discussions about computational complexity\n  and extension to more than two communities", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.SI math.ST physics.soc-ph stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Community detection is one of the fundamental problems of network analysis,\nfor which a number of methods have been proposed. Most model-based or\ncriteria-based methods have to solve an optimization problem over a discrete\nset of labels to find communities, which is computationally infeasible. Some\nfast spectral algorithms have been proposed for specific methods or models, but\nonly on a case-by-case basis. Here we propose a general approach for maximizing\na function of a network adjacency matrix over discrete labels by projecting the\nset of labels onto a subspace approximating the leading eigenvectors of the\nexpected adjacency matrix. This projection onto a low-dimensional space makes\nthe feasible set of labels much smaller and the optimization problem much\neasier. We prove a general result about this method and show how to apply it to\nseveral previously proposed community detection criteria, establishing its\nconsistency for label estimation in each case and demonstrating the fundamental\nconnection between spectral properties of the network and various model-based\napproaches to community detection. Simulations and applications to real-world\ndata are included to demonstrate our method performs well for multiple problems\nover a wide range of parameters.\n", "versions": [{"version": "v1", "created": "Sat, 31 May 2014 11:02:37 GMT"}, {"version": "v2", "created": "Sun, 10 May 2015 08:31:14 GMT"}], "update_date": "2015-05-12", "authors_parsed": [["Le", "Can M.", ""], ["Levina", "Elizaveta", ""], ["Vershynin", "Roman", ""]]}, {"id": "1406.0148", "submitter": "Serkan Hosten", "authors": "Javier Arsuaga, Ido Heskia, Serkan Hosten, Tatsiana Maskalevich", "title": "Uncovering Proximity of Chromosome Territories using Classical Algebraic\n  Statistics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP math.AC math.ST q-bio.GN stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exchange type chromosome aberrations (ETCAs) are rearrangements of the genome\nthat occur when chromosomes break and the resulting fragments rejoin with other\nfragments from other chromosomes. ETCAs are commonly observed in cancer cells\nand in cells exposed to radiation. The frequency of these chromosome\nrearrangements is correlated with their spatial proximity, therefore it can be\nused to infer the three dimensional organization of the genome. Extracting\nstatistical significance of spatial proximity from cancer and radiation data\nhas remained somewhat elusive because of the sparsity of the data. We here\npropose a new approach to study the three dimensional organization of the\ngenome using algebraic statistics. We test our method on a published data set\nof irradiated human blood lymphocyte cells. We provide a rigorous method for\ntesting the overall organization of the genome, and in agreement with previous\nresults we find a random relative positioning of chromosomes with the exception\nof the chromosome pairs \\{1,22\\} and \\{13,14\\} that have a significantly larger\nnumber of ETCAs than the rest of the chromosome pairs suggesting their spatial\nproximity. We conclude that algebraic methods can successfully be used to\nanalyze genetic data and have potential applications to larger and more complex\ndata sets.\n", "versions": [{"version": "v1", "created": "Sun, 1 Jun 2014 09:15:41 GMT"}], "update_date": "2014-06-03", "authors_parsed": [["Arsuaga", "Javier", ""], ["Heskia", "Ido", ""], ["Hosten", "Serkan", ""], ["Maskalevich", "Tatsiana", ""]]}, {"id": "1406.0266", "submitter": "Wenge Guo", "authors": "Wenge Guo, Li He, Sanat K. Sarkar", "title": "Further results on controlling the false discovery proportion", "comments": "Published in at http://dx.doi.org/10.1214/14-AOS1214 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2014, Vol. 42, No. 3, 1070-1101", "doi": "10.1214/14-AOS1214", "report-no": "IMS-AOS-AOS1214", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The probability of false discovery proportion (FDP) exceeding\n$\\gamma\\in[0,1)$, defined as $\\gamma$-FDP, has received much attention as a\nmeasure of false discoveries in multiple testing. Although this measure has\nreceived acceptance due to its relevance under dependency, not much progress\nhas been made yet advancing its theory under such dependency in a nonasymptotic\nsetting, which motivates our research in this article. We provide a larger\nclass of procedures containing the stepup analog of, and hence more powerful\nthan, the stepdown procedure in Lehmann and Romano [Ann. Statist. 33 (2005)\n1138-1154] controlling the $\\gamma$-FDP under similar positive dependence\ncondition assumed in that paper. We offer better alternatives of the stepdown\nand stepup procedures in Romano and Shaikh [IMS Lecture Notes Monogr. Ser. 49\n(2006a) 33-50, Ann. Statist. 34 (2006b) 1850-1873] using pairwise joint\ndistributions of the null $p$-values. We generalize the notion of $\\gamma$-FDP\nmaking it appropriate in situations where one is willing to tolerate a few\nfalse rejections or, due to high dependency, some false rejections are\ninevitable, and provide methods that control this generalized $\\gamma$-FDP in\ntwo different scenarios: (i) only the marginal $p$-values are available and\n(ii) the marginal $p$-values as well as the common pairwise joint distributions\nof the null $p$-values are available, and assuming both positive dependence and\narbitrary dependence conditions on the $p$-values in each scenario. Our\ntheoretical findings are being supported through numerical studies.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jun 2014 07:03:03 GMT"}], "update_date": "2014-06-03", "authors_parsed": [["Guo", "Wenge", ""], ["He", "Li", ""], ["Sarkar", "Sanat K.", ""]]}, {"id": "1406.0267", "submitter": "Prathapasinghe Dharmawansa", "authors": "Prathapasinghe Dharmawansa, Iain M. Johnstone", "title": "Joint density of eigenvalues in spiked multivariate models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT math.IT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The classical methods of multivariate analysis are based on the eigenvalues\nof one or two sample covariance matrices. In many applications of these\nmethods, for example to high dimensional data, it is natural to consider\nalternative hypotheses which are a low rank departure from the null hypothesis.\nFor rank one alternatives, this note provides a representation for the joint\neigenvalue density in terms of a single contour integral. This will be of use\nfor deriving approximate distributions for likelihood ratios and linear\nstatistics used in testing.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jun 2014 07:04:22 GMT"}, {"version": "v2", "created": "Sat, 14 Jun 2014 19:02:28 GMT"}], "update_date": "2014-06-17", "authors_parsed": [["Dharmawansa", "Prathapasinghe", ""], ["Johnstone", "Iain M.", ""]]}, {"id": "1406.0345", "submitter": "Viktor Witkovsky", "authors": "Viktor Witkovsk\\'y, Gejza Wimmer, Tomy Duby", "title": "Logarithmic Lambert $\\mathrm{W}\\times {\\cal F}$ random variables for the\n  family of chi-squared distributions and their applications", "comments": "http://www.sciencedirect.com/science/article/pii/S0167715214003484", "journal-ref": "Statistics and Probability Letters, 96, 2015, 223-231", "doi": "10.1016/j.spl.2014.09.028", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a class of logarithmic Lambert W random variables for a specific\nfamily of distributions. In particular, we characterize the log-Lambert W\nrandom variables for chi-squared distributions which naturally appear in the\nlikelihood based inference of normal random variables.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jun 2014 12:46:13 GMT"}, {"version": "v2", "created": "Thu, 4 Sep 2014 12:00:35 GMT"}, {"version": "v3", "created": "Tue, 21 Oct 2014 09:49:23 GMT"}], "update_date": "2014-10-22", "authors_parsed": [["Witkovsk\u00fd", "Viktor", ""], ["Wimmer", "Gejza", ""], ["Duby", "Tomy", ""]]}, {"id": "1406.0437", "submitter": "Nestor Parolya Jun.-Prof. Dr.", "authors": "Taras Bodnar, Nestor Parolya and Wolfgang Schmid", "title": "Estimation of the Global Minimum Variance Portfolio in High Dimensions", "comments": "38 pages inc. 16 figures. Revised and corrected version", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST math.ST q-fin.PM stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We estimate the global minimum variance (GMV) portfolio in the\nhigh-dimensional case using results from random matrix theory. This approach\nleads to a shrinkage-type estimator which is distribution-free and it is\noptimal in the sense of minimizing the out-of-sample variance. Its asymptotic\nproperties are investigated assuming that the number of assets $p$ depends on\nthe sample size $n$ such that $\\frac{p}{n}\\rightarrow c\\in (0,+\\infty)$ as $n$\ntends to infinity. The results are obtained under weak assumptions imposed on\nthe distribution of the asset returns, namely it is only required the fourth\nmoments existence. Furthermore, we make no assumption on the upper bound of the\nspectrum of the covariance matrix. As a result, the theoretical findings are\nalso valid if the dependencies between the asset returns are described by a\nfactor model which appears to be very popular in financial literature nowadays.\nThis is also well-documented in a numerical study where the small- and\nlarge-sample behavior of the derived estimator are compared with existing\nestimators of the GMV portfolio. The resulting estimator shows significant\nimprovements and it turns out to be robust to the deviations from normality.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jun 2014 16:34:36 GMT"}, {"version": "v2", "created": "Fri, 13 Nov 2015 10:47:39 GMT"}], "update_date": "2015-11-16", "authors_parsed": [["Bodnar", "Taras", ""], ["Parolya", "Nestor", ""], ["Schmid", "Wolfgang", ""]]}, {"id": "1406.0476", "submitter": "Julien Chevallier", "authors": "Julien Chevallier (JAD), Thomas Lalo\\\"e (JAD)", "title": "Detection of dependence patterns with delay", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST q-bio.NC stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Unitary Events (UE) method is a popular and efficient method used this\nlast decade to detect dependence patterns of joint spike activity among\nsimultaneously recorded neurons. The first introduced method is based on binned\ncoincidence count \\citep{Grun1996} and can be applied on two or more\nsimultaneously recorded neurons. Among the improvements of the methods, a\ntransposition to the continuous framework has recently been proposed in\n\\citep{muino2014frequent} and fully investigated in \\citep{MTGAUE} for two\nneurons. The goal of the present paper is to extend this study to more than two\nneurons. The main result is the determination of the limit distribution of the\ncoincidence count. This leads to the construction of an independence test\nbetween $L\\geq 2$ neurons. Finally we propose a multiple test procedure via a\nBenjamini and Hochberg approach \\citep{Benjamini1995}. All the theoretical\nresults are illustrated by a simulation study, and compared to the UE method\nproposed in \\citep{Grun2002}. Furthermore our method is applied on real data.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jun 2014 18:55:17 GMT"}, {"version": "v2", "created": "Fri, 22 May 2015 13:22:20 GMT"}, {"version": "v3", "created": "Mon, 27 Jul 2015 08:48:35 GMT"}], "update_date": "2015-07-28", "authors_parsed": [["Chevallier", "Julien", "", "JAD"], ["Lalo\u00eb", "Thomas", "", "JAD"]]}, {"id": "1406.0526", "submitter": "Natalia Stepanova", "authors": "Natalia Stepanova and Tatjana Pavlenko", "title": "Goodness-of-fit tests based on sup-functionals of weighted empirical\n  processes", "comments": "29 pages, 1 figure, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A large class of goodness-of-fit test statistics based on sup-functionals of\nweighted empirical processes is proposed and studied. The weight functions\nemployed are Erd\\H{o}s-Feller-Kolmogorov-Petrovski upper-class functions of a\nBrownian bridge. Based on the result of M. Cs\\\"{o}rg\\H{o}, S. Cs\\\"{o}rg\\H{o},\nHorv\\'{a}th, and Mason obtained for this type of test statistics, we provide\nthe asymptotic null distribution theory for the class of tests in hand, and\npresent an algorithm for tabulating the limit distribution functions under the\nnull hypothesis. A new family of nonparametric confidence bands is constructed\nfor the true distribution function and it is found to perform very well. The\nresults obtained, together with a new result on the convergence in distribution\nof the higher criticism statistic, introduced by Donoho and Jin, demonstrate\nthe advantage of our approach over a common approach that utilizes a family of\nregularly varying weight functions. Furthermore, we show that, in various\nsubtle problems of detecting sparse heterogeneous mixtures, the proposed test\nstatistics achieve the detection boundary found by Ingster and, when\ndistinguishing between the null and alternative hypotheses, perform optimally\nadaptively to unknown sparsity and size of the non-null effects.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jun 2014 20:17:02 GMT"}, {"version": "v2", "created": "Fri, 1 Apr 2016 01:29:32 GMT"}], "update_date": "2016-04-04", "authors_parsed": [["Stepanova", "Natalia", ""], ["Pavlenko", "Tatjana", ""]]}, {"id": "1406.0541", "submitter": "John Rhodes", "authors": "Elizabeth S. Allman, John A. Rhodes, Elena Stanghellini, Marco\n  Valtorta", "title": "Parameter identifiability of discrete Bayesian networks with hidden\n  variables", "comments": "23 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifiability of parameters is an essential property for a statistical\nmodel to be useful in most settings. However, establishing parameter\nidentifiability for Bayesian networks with hidden variables remains\nchallenging. In the context of finite state spaces, we give algebraic arguments\nestablishing identifiability of some special models on small DAGs. We also\nestablish that, for fixed state spaces, generic identifiability of parameters\ndepends only on the Markov equivalence class of the DAG. To illustrate the use\nof these results, we investigate identifiability for all binary Bayesian\nnetworks with up to five variables, one of which is hidden and parental to all\nobservable ones. Surprisingly, some of these models have parameterizations that\nare generically 4-to-one, and not 2-to-one as label swapping of the hidden\nstates would suggest. This leads to interesting difficulties in interpreting\ncausal effects.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jun 2014 21:49:14 GMT"}], "update_date": "2014-06-04", "authors_parsed": [["Allman", "Elizabeth S.", ""], ["Rhodes", "John A.", ""], ["Stanghellini", "Elena", ""], ["Valtorta", "Marco", ""]]}, {"id": "1406.0791", "submitter": "Damien Passemier", "authors": "Damien Passemier (ECE), Matthew R. Mckay (ECE), Yang Chen", "title": "Hypergeometric Functions of Matrix Arguments and Linear Statistics of\n  Multi-Spiked Hermitian Matrix Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper derives central limit theorems (CLTs) for general linear spectral\nstatistics (LSS) of three important multi-spiked Hermitian random matrix\nensembles. The first is the most common spiked scenario, proposed by Johnstone,\nwhich is a central Wishart ensemble with fixed-rank perturbation of the\nidentity matrix, the second is a non-central Wishart ensemble with fixed-rank\nnoncentrality parameter, and the third is a similarly defined non-central $F$\nensemble. These CLT results generalize our recent work to account for multiple\nspikes, which is the most common scenario met in practice. The generalization\nis non-trivial, as it now requires dealing with hypergeometric functions of\nmatrix arguments. To facilitate our analysis, for a broad class of such\nfunctions, we first generalize a recent result of Onatski to present new\ncontour integral representations, which are particularly suitable for computing\nlarge-dimensional properties of spiked matrix ensembles. Armed with such\nrepresentations, our CLT formulas are derived for each of the three spiked\nmodels of interest by employing the Coulomb fluid method from random matrix\ntheory along with saddlepoint techniques. We find that for each matrix model,\nand for general LSS, the individual spikes contribute additively to yield a\n$O(1)$ correction term to the asymptotic mean of the linear statistic, which we\nspecify explicitly, whilst having no effect on the leading order terms of the\nmean or variance.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jun 2014 17:22:34 GMT"}, {"version": "v2", "created": "Wed, 4 Jun 2014 19:09:14 GMT"}], "update_date": "2014-06-05", "authors_parsed": [["Passemier", "Damien", "", "ECE"], ["Mckay", "Matthew R.", "", "ECE"], ["Chen", "Yang", ""]]}, {"id": "1406.0812", "submitter": "James Barrett", "authors": "James E. Barrett and Anthony C. C. Coolen", "title": "Covariate dimension reduction for survival data via the Gaussian process\n  latent variable model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The analysis of high dimensional survival data is challenging, primarily due\nto the problem of overfitting which occurs when spurious relationships are\ninferred from data that subsequently fail to exist in test data. Here we\npropose a novel method of extracting a low dimensional representation of\ncovariates in survival data by combining the popular Gaussian Process Latent\nVariable Model (GPLVM) with a Weibull Proportional Hazards Model (WPHM). The\ncombined model offers a flexible non-linear probabilistic method of detecting\nand extracting any intrinsic low dimensional structure from high dimensional\ndata. By reducing the covariate dimension we aim to diminish the risk of\noverfitting and increase the robustness and accuracy with which we infer\nrelationships between covariates and survival outcomes. In addition, we can\nsimultaneously combine information from multiple data sources by expressing\nmultiple datasets in terms of the same low dimensional space. We present\nresults from several simulation studies that illustrate a reduction in\noverfitting and an increase in predictive performance, as well as successful\ndetection of intrinsic dimensionality. We provide evidence that it is\nadvantageous to combine dimensionality reduction with survival outcomes rather\nthan performing unsupervised dimensionality reduction on its own. Finally, we\nuse our model to analyse experimental gene expression data and detect and\nextract a low dimensional representation that allows us to distinguish high and\nlow risk groups with superior accuracy compared to doing regression on the\noriginal high dimensional data.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jun 2014 18:39:07 GMT"}, {"version": "v2", "created": "Wed, 27 Jan 2016 15:20:30 GMT"}], "update_date": "2016-01-28", "authors_parsed": [["Barrett", "James E.", ""], ["Coolen", "Anthony C. C.", ""]]}, {"id": "1406.1000", "submitter": "Ya'acov Ritov", "authors": "E. Greenshtein, A. Mansura, and Y. Ritov", "title": "Empirical Bayes improvement of Kalman filter type of estimators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of estimating the means $\\mu_i$ of $n$ random\nvariables $Y_i \\sim N(\\mu_i,1)$, $i=1,\\ldots ,n$. Assuming some structure on\nthe $\\mu$ process, e.g., a state space model, one may use a summary statistics\nfor the contribution of the rest of the observations to the estimation of\n$\\mu_i$. The most important example for this is the Kalman filter. We introduce\na non-linear improvement of the standard weighted average of the given summary\nstatistics and $Y_i$ itself, using empirical Bayes methods. The improvement is\nobtained under mild assumptions. It is strict when the process that governs the\nstates $\\mu_1,\\ldots,\\mu_n $ is not a linear Gaussian state-space model. We\nconsider both the sequential and the retrospective estimation problems.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jun 2014 10:59:15 GMT"}], "update_date": "2014-06-05", "authors_parsed": [["Greenshtein", "E.", ""], ["Mansura", "A.", ""], ["Ritov", "Y.", ""]]}, {"id": "1406.1037", "submitter": "Guang Cheng", "authors": "Xianyang Zhang (Univ of Missouri, Columbia) and Guang Cheng (Purdue)", "title": "Bootstrapping High Dimensional Time Series", "comments": "53 pages, 1 figure. This works was presented in SAMSI workshop on May\n  13, 2014 under a slightly different title: Bootstrapping High Dimensional\n  Vector: Interplay Between Dependence and Dimensionality. See\n  http://www.samsi.info/workshop/2013-14-ldhd-transition-workshop-may-12-14-2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article studies bootstrap inference for high dimensional weakly\ndependent time series in a general framework of approximately linear\nstatistics. The following high dimensional applications are covered: (1)\nuniform confidence band for mean vector; (2) specification testing on the\nsecond order property of time series such as white noise testing and bandedness\ntesting of covariance matrix; (3) specification testing on the spectral\nproperty of time series. In theory, we first derive a Gaussian approximation\nresult for the maximum of a sum of weakly dependent vectors, where the\ndimension of the vectors is allowed to be exponentially larger than the sample\nsize. In particular, we illustrate an interesting interplay between dependence\nand dimensionality, and also discuss one type of \"dimension free\" dependence\nstructure. We further propose a blockwise multiplier (wild) bootstrap that\nworks for time series with unknown autocovariance structure. These\ndistributional approximation errors, which are finite sample valid, decrease\npolynomially in sample size. A non-overlapping block bootstrap is also studied\nas a more flexible alternative. The above results are established under the\ngeneral physical/functional dependence framework proposed in Wu (2005). Our\nwork can be viewed as a substantive extension of Chernozhukov et al. (2013) to\ntime series based on a variant of Stein's method developed therein.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jun 2014 13:22:29 GMT"}, {"version": "v2", "created": "Mon, 11 Aug 2014 04:33:27 GMT"}], "update_date": "2014-08-12", "authors_parsed": [["Zhang", "Xianyang", "", "Univ of Missouri, Columbia"], ["Cheng", "Guang", "", "Purdue"]]}, {"id": "1406.1138", "submitter": "Alexander Bulinski", "authors": "Alexander V. Bulinski and Alexander S. Rakitko", "title": "Simulation and analytical approach to the identification of significant\n  factors", "comments": "25 pages, 6 tables, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop our previous works concerning the identification of the collection\nof significant factors determining some, in general, non-binary random response\nvariable. Such identification is important, e.g., in biological and medical\nstudies. Our approach is to examine the quality of response variable prediction\nby functions in (certain part of) the factors. The prediction error estimation\nrequires some cross-validation procedure, certain prediction algorithm and\nestimation of the penalty function. Using simulated data we demonstrate the\nefficiency of our method. We prove a new central limit theorem for introduced\nregularized estimates under some natural conditions for arrays of exchangeable\nrandom variables.\n  Keywords: nonbinary random response; identification of significant factors;\nregularized estimates of prediction error; exchangeable random variables;\ncentral limit theorem.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jun 2014 18:38:13 GMT"}], "update_date": "2014-06-05", "authors_parsed": [["Bulinski", "Alexander V.", ""], ["Rakitko", "Alexander S.", ""]]}, {"id": "1406.1230", "submitter": "Jihad Fahs", "authors": "Naeem Akl, Jihad Fahs, Zaher Dawy", "title": "Statistical Intercell Interference Modeling for Capacity-Coverage\n  Tradeoff Analysis in Downlink Cellular Networks", "comments": "5 pages, 7 figures, conference", "journal-ref": null, "doi": "10.1109/ICCSPA.2015.7081269", "report-no": null, "categories": "cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interference shapes the interplay between capacity and coverage in cellular\nnetworks. However, interference is non-deterministic and depends on various\nsystem and channel parameters including user scheduling, frequency reuse, and\nfading variations. We present an analytical approach for modeling the\ndistribution of intercell interference in the downlink of cellular networks as\na function of generic fading channel models and various scheduling schemes. We\ndemonstrate the usefulness of the derived expressions in calculating\nlocation-based and average-based data rates in addition to capturing practical\ntradeoffs between cell capacity and coverage in downlink cellular networks.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jun 2014 22:59:57 GMT"}], "update_date": "2015-04-16", "authors_parsed": [["Akl", "Naeem", ""], ["Fahs", "Jihad", ""], ["Dawy", "Zaher", ""]]}, {"id": "1406.1234", "submitter": "Lijiang Chen", "authors": "Chen Lijiang", "title": "A Geometric Method to Obtain the Generation Probability of a Sentence", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI math.ST stat.CO stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  \"How to generate a sentence\" is the most critical and difficult problem in\nall the natural language processing technologies. In this paper, we present a\nnew approach to explain the generation process of a sentence from the\nperspective of mathematics. Our method is based on the premise that in our\nbrain a sentence is a part of a word network which is formed by many word\nnodes. Experiments show that the probability of the entire sentence can be\nobtained by the probabilities of single words and the probabilities of the\nco-occurrence of word pairs, which indicate that human use the synthesis method\nto generate a sentence.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jun 2014 23:28:51 GMT"}], "update_date": "2014-07-28", "authors_parsed": [["Lijiang", "Chen", ""]]}, {"id": "1406.1336", "submitter": "Alexander Novikov", "authors": "Alexander Novikov, Nino Kordzakhia and Timothy Ling", "title": "On moments of Pitman estimators: the case of fractional Brownian Motion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  In some non-regular statistical estimation problems, the limiting likelihood\nprocesses are functionals of fractional Brownian motion (fBm) with Hurst's\nparameter H; 0 < H <=? 1. In this paper we present several analytical and\nnumerical results on the moments of Pitman estimators represented in the form\nof integral functionals of fBm. We also provide Monte Carlo simulation results\nfor variances of Pitman and asymptotic maximum likelihood estimators.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jun 2014 11:07:13 GMT"}], "update_date": "2014-06-06", "authors_parsed": [["Novikov", "Alexander", ""], ["Kordzakhia", "Nino", ""], ["Ling", "Timothy", ""]]}, {"id": "1406.1440", "submitter": "Pierre Alquier", "authors": "Pierre Alquier, Vincent Cottet, Nicolas Chopin, Judith Rousseau", "title": "Bayesian matrix completion: prior specification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML math.ST stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low-rank matrix estimation from incomplete measurements recently received\nincreased attention due to the emergence of several challenging applications,\nsuch as recommender systems; see in particular the famous Netflix challenge.\nWhile the behaviour of algorithms based on nuclear norm minimization is now\nwell understood, an as yet unexplored avenue of research is the behaviour of\nBayesian algorithms in this context. In this paper, we briefly review the\npriors used in the Bayesian literature for matrix completion. A standard\napproach is to assign an inverse gamma prior to the singular values of a\ncertain singular value decomposition of the matrix of interest; this prior is\nconjugate. However, we show that two other types of priors (again for the\nsingular values) may be conjugate for this model: a gamma prior, and a discrete\nprior. Conjugacy is very convenient, as it makes it possible to implement\neither Gibbs sampling or Variational Bayes. Interestingly enough, the maximum a\nposteriori for these different priors is related to the nuclear norm\nminimization problems. We also compare all these priors on simulated datasets,\nand on the classical MovieLens and Netflix datasets.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jun 2014 16:46:46 GMT"}, {"version": "v2", "created": "Wed, 11 Jun 2014 15:32:24 GMT"}, {"version": "v3", "created": "Wed, 22 Oct 2014 15:34:33 GMT"}], "update_date": "2014-10-23", "authors_parsed": [["Alquier", "Pierre", ""], ["Cottet", "Vincent", ""], ["Chopin", "Nicolas", ""], ["Rousseau", "Judith", ""]]}, {"id": "1406.1568", "submitter": "Lam Ho", "authors": "C\\'ecile An\\'e, Lam Si Tung Ho, Sebastien Roch", "title": "Phase transition on the convergence rate of parameter estimation under\n  an Ornstein-Uhlenbeck diffusion on a tree", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE cs.CE math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diffusion processes on trees are commonly used in evolutionary biology to\nmodel the joint distribution of continuous traits, such as body mass, across\nspecies. Estimating the parameters of such processes from tip values presents\nchallenges because of the intrinsic correlation between the observations\nproduced by the shared evolutionary history, thus violating the standard\nindependence assumption of large-sample theory. For instance Ho and An\\'e\n\\cite{HoAne13} recently proved that the mean (also known in this context as\nselection optimum) of an Ornstein-Uhlenbeck process on a tree cannot be\nestimated consistently from an increasing number of tip observations if the\ntree height is bounded. Here, using a fruitful connection to the so-called\nreconstruction problem in probability theory, we study the convergence rate of\nparameter estimation in the unbounded height case. For the mean of the process,\nwe provide a necessary and sufficient condition for the consistency of the\nmaximum likelihood estimator (MLE) and establish a phase transition on its\nconvergence rate in terms of the growth of the tree. In particular we show that\na loss of $\\sqrt{n}$-consistency (i.e., the variance of the MLE becomes\n$\\Omega(n^{-1})$, where $n$ is the number of tips) occurs when the tree growth\nis larger than a threshold related to the phase transition of the\nreconstruction problem. For the covariance parameters, we give a novel,\nefficient estimation method which achieves $\\sqrt{n}$-consistency under natural\nassumptions on the tree.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jun 2014 02:03:54 GMT"}, {"version": "v2", "created": "Mon, 26 Jan 2015 21:14:21 GMT"}, {"version": "v3", "created": "Wed, 25 May 2016 22:52:33 GMT"}], "update_date": "2016-05-27", "authors_parsed": [["An\u00e9", "C\u00e9cile", ""], ["Ho", "Lam Si Tung", ""], ["Roch", "Sebastien", ""]]}, {"id": "1406.1629", "submitter": "Aziz El Kaabouchi", "authors": "Azzouz Dermoune and Aziz El Kaabouchi", "title": "Strong noise estimation in cubic splines", "comments": "9 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The data $(y_i,x_i)\\in$ $\\textbf{R}\\times[a,b]$, $i=1,\\ldots,n$ satisfy\n$y_i=s(x_i)+e_i$ where $s$ belongs to the set of cubic splines. The unknown\nnoises $(e_i)$ are such that $var(e_I)=1$ for some $I\\in \\{1, \\ldots, n\\}$ and\n$var(e_i)=\\sigma^2$ for $i\\neq I$. We suppose that the most important noise is\n$e_I$, i.e. the ratio $r_I=\\frac{1}{\\sigma^2}$ is larger than one. If the ratio\n$r_I$ is large, then we show, for all smoothing parameter, that the penalized\nleast squares estimator of the $B$-spline basis recovers exactly the position\n$I$ and the sign of the most important noise $e_I$.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jun 2014 10:15:47 GMT"}], "update_date": "2014-06-09", "authors_parsed": [["Dermoune", "Azzouz", ""], ["Kaabouchi", "Aziz El", ""]]}, {"id": "1406.1643", "submitter": "Melisande Albert", "authors": "M\\'elisande Albert (JAD), Yann Bouret (JAD), Magalie Fromont (IRMAR),\n  Patricia Reynaud-Bouret (JAD)", "title": "Bootstrap and permutation tests of independence for point processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by a neuroscience question about synchrony detection in spike train\nanalysis, we deal with the independence testing problem for point processes. We\nintroduce non-parametric test statistics, which are rescaled general\n$U$-statistics, whose corresponding critical values are constructed from\nbootstrap and randomization/permutation approaches, making as few assumptions\nas possible on the underlying distribution of the point processes. We derive\ngeneral consistency results for the bootstrap and for the permutation w.r.t. to\nWasserstein's metric, which induce weak convergence as well as convergence of\nsecond order moments. The obtained bootstrap or permutation independence tests\nare thus proved to be asymptotically of the prescribed size, and to be\nconsistent against any reasonable alternative. A simulation study is performed\nto illustrate the derived theoretical results, and to compare the performance\nof our new tests with existing ones in the neuroscientific literature.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jun 2014 11:13:56 GMT"}, {"version": "v2", "created": "Tue, 5 Aug 2014 16:17:54 GMT"}, {"version": "v3", "created": "Tue, 13 Jan 2015 12:55:30 GMT"}, {"version": "v4", "created": "Wed, 27 May 2015 14:05:01 GMT"}], "update_date": "2015-05-28", "authors_parsed": [["Albert", "M\u00e9lisande", "", "JAD"], ["Bouret", "Yann", "", "JAD"], ["Fromont", "Magalie", "", "IRMAR"], ["Reynaud-Bouret", "Patricia", "", "JAD"]]}, {"id": "1406.1758", "submitter": "Igor Kortchemski", "authors": "Nicolas Curien, Thomas Duquesne, Igor Kortchemski, Ioan Manolescu", "title": "Scaling limits and influence of the seed graph in preferential\n  attachment trees", "comments": "32 pages, 11 figures", "journal-ref": "J. \\'Ec. polytech. Math. 2 (2015), 1-34", "doi": null, "report-no": null, "categories": "math.PR cs.DM math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are interested in the asymptotics of random trees built by linear\npreferential attachment, also known in the literature as Barab\\'asi-Albert\ntrees or plane-oriented recursive trees. We first prove a conjecture of Bubeck,\nMossel \\& R\\'acz concerning the influence of the seed graph on the asymptotic\nbehavior of such trees. Separately we study the geometric structure of nodes of\nlarge degrees in a plane version of Barab\\'asi-Albert trees via their\nassociated looptrees. As the number of nodes grows, we show that these\nlooptrees, appropriately rescaled, converge in the Gromov-Hausdorff sense\ntowards a random compact metric space which we call the Brownian looptree. The\nlatter is constructed as a quotient space of Aldous' Brownian Continuum Random\nTree and is shown to have almost sure Hausdorff dimension $2$.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jun 2014 17:52:34 GMT"}], "update_date": "2018-02-19", "authors_parsed": [["Curien", "Nicolas", ""], ["Duquesne", "Thomas", ""], ["Kortchemski", "Igor", ""], ["Manolescu", "Ioan", ""]]}, {"id": "1406.1779", "submitter": "Mark Huber", "authors": "Mark Huber and Nevena Maric", "title": "Minimum correlation for any bivariate Geometric distribution", "comments": "11 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a bivariate Geometric random variable where the first component has\nparameter $p_1$ and the second parameter $p_2$. It is not possible to make the\ncorrelation between the marginals equal to -1. Here the properties of this\nminimum correlation are studied both numerically and analytically. It is shown\nthat the minimum correlation can be computed exactly in time $O(p_1^{-1}\n\\ln(p_2^{-1}) + p_2^{-1} \\ln(p_1^{-1}))$. The minimum correlation is shown to\nbe nonmonotonic in $p_1$ and $p_2$, moreover, the partial derivatives are not\ncontinuous. For $p_1 = p_2$, these discontinuities are characterized completely\nand shown to lie near (1- roots of 1/2). In addition, we construct analytical\nbounds on the minimum correlation.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jun 2014 19:25:22 GMT"}, {"version": "v2", "created": "Fri, 22 Aug 2014 20:24:34 GMT"}, {"version": "v3", "created": "Wed, 27 Aug 2014 20:45:53 GMT"}], "update_date": "2014-08-29", "authors_parsed": [["Huber", "Mark", ""], ["Maric", "Nevena", ""]]}, {"id": "1406.1849", "submitter": "Nishant Chandgotia", "authors": "Nishant Chandgotia", "title": "Generalisation of the Hammersley-Clifford Theorem on Bipartite Graphs", "comments": "27 pages, 7 figures; Typos corrected and some notation has been\n  changed", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Hammersley-Clifford theorem states that if the support of a Markov random\nfield has a safe symbol then it is a Gibbs state with some nearest neighbour\ninteraction. In this paper we generalise the theorem with an added condition\nthat the underlying graph is bipartite. Taking inspiration from \"Gibbs Measures\nand Dismantlable Graphs\" by Brightwell and Winkler we introduce a notion of\nfolding for configuration spaces called strong config-folding proving that if\nall Markov random fields supported on $X$ are Gibbs with some nearest neighbour\ninteraction so are Markov random fields supported on the 'strong config-folds'\nand 'strong config-unfolds' of $X$.\n", "versions": [{"version": "v1", "created": "Sat, 7 Jun 2014 02:23:40 GMT"}, {"version": "v2", "created": "Mon, 30 Nov 2015 17:00:28 GMT"}], "update_date": "2015-12-01", "authors_parsed": [["Chandgotia", "Nishant", ""]]}, {"id": "1406.1939", "submitter": "Wen Zhou", "authors": "Jinyuan Chang, Chao Zheng, Wen-Xin Zhou, and Wen Zhou", "title": "Simulation-Based Hypothesis Testing of High Dimensional Means Under\n  Covariance Heterogeneity", "comments": "34 pages, 10 figures; Accepted for biometrics", "journal-ref": "Biometrics 2017, Vol. 73, No. 4, 1300-1310", "doi": "10.1111/biom.12695", "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of testing the mean vectors of high\ndimensional data in both one-sample and two-sample cases. The proposed testing\nprocedures employ maximum-type statistics and the parametric bootstrap\ntechniques to compute the critical values. Different from the existing tests\nthat heavily rely on the structural conditions on the unknown covariance\nmatrices, the proposed tests allow general covariance structures of the data\nand therefore enjoy wide scope of applicability in practice. To enhance powers\nof the tests against sparse alternatives, we further propose two-step\nprocedures with a preliminary feature screening step. Theoretical properties of\nthe proposed tests are investigated. Through extensive numerical experiments on\nsynthetic datasets and an human acute lymphoblastic leukemia gene expression\ndataset, we illustrate the performance of the new tests and how they may\nprovide assistance on detecting disease-associated gene-sets. The proposed\nmethods have been implemented in an R-package HDtest and are available on CRAN.\n", "versions": [{"version": "v1", "created": "Sun, 8 Jun 2014 00:48:47 GMT"}, {"version": "v2", "created": "Fri, 17 Apr 2015 03:25:29 GMT"}, {"version": "v3", "created": "Fri, 24 Feb 2017 21:14:33 GMT"}], "update_date": "2018-01-23", "authors_parsed": [["Chang", "Jinyuan", ""], ["Zheng", "Chao", ""], ["Zhou", "Wen-Xin", ""], ["Zhou", "Wen", ""]]}, {"id": "1406.2083", "submitter": "Aaditya Ramdas", "authors": "Sashank J. Reddi, Aaditya Ramdas, Barnab\\'as P\\'oczos, Aarti Singh and\n  Larry Wasserman", "title": "On the Decreasing Power of Kernel and Distance based Nonparametric\n  Hypothesis Tests in High Dimensions", "comments": "19 pages, 9 figures, published in AAAI-15: The 29th AAAI Conference\n  on Artificial Intelligence (with author order reversed from ArXiv)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is about two related decision theoretic problems, nonparametric\ntwo-sample testing and independence testing. There is a belief that two\nrecently proposed solutions, based on kernels and distances between pairs of\npoints, behave well in high-dimensional settings. We identify different sources\nof misconception that give rise to the above belief. Specifically, we\ndifferentiate the hardness of estimation of test statistics from the hardness\nof testing whether these statistics are zero or not, and explicitly discuss a\nnotion of \"fair\" alternative hypotheses for these problems as dimension\nincreases. We then demonstrate that the power of these tests actually drops\npolynomially with increasing dimension against fair alternatives. We end with\nsome theoretical insights and shed light on the \\textit{median heuristic} for\nkernel bandwidth selection. Our work advances the current understanding of the\npower of modern nonparametric hypothesis tests in high dimensions.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jun 2014 05:59:21 GMT"}, {"version": "v2", "created": "Mon, 24 Nov 2014 00:23:35 GMT"}], "update_date": "2014-11-25", "authors_parsed": [["Reddi", "Sashank J.", ""], ["Ramdas", "Aaditya", ""], ["P\u00f3czos", "Barnab\u00e1s", ""], ["Singh", "Aarti", ""], ["Wasserman", "Larry", ""]]}, {"id": "1406.2112", "submitter": "Abhik Ghosh", "authors": "Avijit Maji, Abhik Ghosh and Ayanendranath Basu", "title": "The Logarithmic Super Divergence and Statistical Inference : Asymptotic\n  Properties", "comments": "26 pages; Pre-print, Under Review", "journal-ref": "AStA Advances in Statistical Analysis, 2016, 100(1), 99 - 131", "doi": "10.1007/s10182-015-0252-x", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical inference based on divergence measures have a long history.\nRecently, Maji, Ghosh and Basu (2014) have introduced a general family of\ndivergences called the logarithmic super divergence (LSD) family. This family\nacts as a superfamily for both of the logarithmic power divergence (LPD) family\n(eg. Renyi, 1961) and the logarithmic density power divergence (LDPD)family\nintroduced by Jones et al. (2001). In this paper we describe the asymptotic\nproperties of the inference procedures resulting from this divergence in\ndiscrete models. The properties are well supported by real data examples.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jun 2014 09:09:25 GMT"}], "update_date": "2016-07-04", "authors_parsed": [["Maji", "Avijit", ""], ["Ghosh", "Abhik", ""], ["Basu", "Ayanendranath", ""]]}, {"id": "1406.2206", "submitter": "Martin Azizyan", "authors": "Martin Azizyan and Aarti Singh and Larry Wasserman", "title": "Efficient Sparse Clustering of High-Dimensional Non-spherical Gaussian\n  Mixtures", "comments": "11 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of clustering data points in high dimensions, i.e.\nwhen the number of data points may be much smaller than the number of\ndimensions. Specifically, we consider a Gaussian mixture model (GMM) with\nnon-spherical Gaussian components, where the clusters are distinguished by only\na few relevant dimensions. The method we propose is a combination of a recent\napproach for learning parameters of a Gaussian mixture model and sparse linear\ndiscriminant analysis (LDA). In addition to cluster assignments, the method\nreturns an estimate of the set of features relevant for clustering. Our results\nindicate that the sample complexity of clustering depends on the sparsity of\nthe relevant feature set, while only scaling logarithmically with the ambient\ndimension. Additionally, we require much milder assumptions than existing work\non clustering in high dimensions. In particular, we do not require spherical\nclusters nor necessitate mean separation along relevant dimensions.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jun 2014 14:57:16 GMT"}], "update_date": "2014-06-10", "authors_parsed": [["Azizyan", "Martin", ""], ["Singh", "Aarti", ""], ["Wasserman", "Larry", ""]]}, {"id": "1406.2240", "submitter": "Martin Azizyan", "authors": "Larry Wasserman and Martin Azizyan and Aarti Singh", "title": "Feature Selection For High-Dimensional Clustering", "comments": "11 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a nonparametric method for selecting informative features in\nhigh-dimensional clustering problems. We start with a screening step that uses\na test for multimodality. Then we apply kernel density estimation and mode\nclustering to the selected features. The output of the method consists of a\nlist of relevant features, and cluster assignments. We provide explicit bounds\non the error rate of the resulting clustering. In addition, we provide the\nfirst error bounds on mode based clustering.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jun 2014 16:57:51 GMT"}], "update_date": "2014-06-10", "authors_parsed": [["Wasserman", "Larry", ""], ["Azizyan", "Martin", ""], ["Singh", "Aarti", ""]]}, {"id": "1406.2275", "submitter": "Andrius \\v{C}iginas", "authors": "Andrius \\v{C}iginas, Dalius Pumputis", "title": "Gini's mean difference and variance as measures of finite populations\n  scales", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider Gini's mean difference statistic as an alternative to the\nempirical variance in the settings of finite populations where simple random\nsamples are drawn without replacement. In particular, we discuss specific (in\nthe finite population context) estimation strategies for a scale of the\npopulation, related to the alternative statistic under possible presence of\noutliers in the data. The paper presents also a wide comparative survey of\nproperties of the Gini mean difference statistic and the empirical variance. It\nincludes asymptotic properties of both statistics: the asymptotic normality,\none-term Edgeworth expansions and bootstrap approximations for Studentized\nversions of the statistics. An estimation of the variances and other parameters\nof the statistics is also in the study, where we exploit an auxiliary\ninformation on the population elements in the case of its availability.\nTheoretical results are illustrated with a simulation study.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jun 2014 18:28:03 GMT"}], "update_date": "2014-06-10", "authors_parsed": [["\u010ciginas", "Andrius", ""], ["Pumputis", "Dalius", ""]]}, {"id": "1406.2280", "submitter": "Gelu M. Nita", "authors": "Gelu M. Nita, Gregory D. Fleishman, Dale E. Gary, William Marin, and\n  Kristine Boone", "title": "Fitting FFT-derived Spectra: Theory, Tool, and Application to Solar\n  Radio Spike Decomposition", "comments": "Accepted to ApJ, 57 pages, 16 figures", "journal-ref": null, "doi": "10.1088/0004-637X/789/2/152", "report-no": null, "categories": "astro-ph.SR math.ST physics.data-an stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spectra derived from fast Fourier transform (FFT) analysis of time-domain\ndata intrinsically contain statistical fluctuations whose distribution depends\non the number of accumulated spectra contributing to a measurement. The tail of\nthis distribution, which is essential for separation of the true signal from\nthe statistical fluctuations, deviates noticeably from the normal distribution\nfor a finite number of the accumulations. In this paper we develop a theory to\nproperly account for the statistical fluctuations when fitting a model to a\ngiven accumulated spectrum. The method is implemented in software for the\npurpose of automatically fitting a large body of such FFT-derived spectra. We\napply this tool to analyze a portion of a dense cluster of spikes recorded by\nour FST instrument during a record-breaking event that occurred on 06 Dec 2006.\nThe outcome of this analysis is briefly discussed.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jun 2014 18:54:38 GMT"}], "update_date": "2015-06-19", "authors_parsed": [["Nita", "Gelu M.", ""], ["Fleishman", "Gregory D.", ""], ["Gary", "Dale E.", ""], ["Marin", "William", ""], ["Boone", "Kristine", ""]]}, {"id": "1406.2721", "submitter": "Zhaoshi Meng", "authors": "Zhaoshi Meng, Brian Eriksson, Alfred O. Hero III", "title": "Learning Latent Variable Gaussian Graphical Models", "comments": "To appear in The 31st International Conference on Machine Learning\n  (ICML 2014)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian graphical models (GGM) have been widely used in many\nhigh-dimensional applications ranging from biological and financial data to\nrecommender systems. Sparsity in GGM plays a central role both statistically\nand computationally. Unfortunately, real-world data often does not fit well to\nsparse graphical models. In this paper, we focus on a family of latent variable\nGaussian graphical models (LVGGM), where the model is conditionally sparse\ngiven latent variables, but marginally non-sparse. In LVGGM, the inverse\ncovariance matrix has a low-rank plus sparse structure, and can be learned in a\nregularized maximum likelihood framework. We derive novel parameter estimation\nerror bounds for LVGGM under mild conditions in the high-dimensional setting.\nThese results complement the existing theory on the structural learning, and\nopen up new possibilities of using LVGGM for statistical inference.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jun 2014 21:03:22 GMT"}], "update_date": "2014-06-12", "authors_parsed": [["Meng", "Zhaoshi", ""], ["Eriksson", "Brian", ""], ["Hero", "Alfred O.", "III"]]}, {"id": "1406.2796", "submitter": "Christophe Ange Napol\\'{e}on Biscio", "authors": "Christophe Ange Napol\\'eon Biscio, Fr\\'ed\\'eric Lavancier", "title": "Quantifying repulsiveness of determinantal point processes", "comments": "Published at http://dx.doi.org/10.3150/15-BEJ718 in the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2016, Vol. 22, No. 4, 2001-2028", "doi": "10.3150/15-BEJ718", "report-no": "IMS-BEJ-BEJ718", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Determinantal point processes (DPPs) have recently proved to be a useful\nclass of models in several areas of statistics, including spatial statistics,\nstatistical learning and telecommunications networks. They are models for\nrepulsive (or regular, or inhibitive) point processes, in the sense that nearby\npoints of the process tend to repel each other. We consider two ways to\nquantify the repulsiveness of a point process, both based on its second-order\nproperties, and we address the question of how repulsive a stationary DPP can\nbe. We determine the most repulsive stationary DPP, when the intensity is\nfixed, and for a given $R>0$ we investigate repulsiveness in the subclass of\n$R$-dependent stationary DPPs, that is, stationary DPPs with $R$-compactly\nsupported kernels. Finally, in both the general case and the $R$-dependent\ncase, we present some new parametric families of stationary DPPs that can cover\na large range of DPPs, from the stationary Poisson process (the case of no\ninteraction) to the most repulsive DPP.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jun 2014 07:07:42 GMT"}, {"version": "v2", "created": "Tue, 16 Dec 2014 10:40:36 GMT"}, {"version": "v3", "created": "Mon, 6 Jun 2016 07:00:09 GMT"}], "update_date": "2016-06-07", "authors_parsed": [["Biscio", "Christophe Ange Napol\u00e9on", ""], ["Lavancier", "Fr\u00e9d\u00e9ric", ""]]}, {"id": "1406.2845", "submitter": "Nathalie Krell", "authors": "Nathalie Krell (IRMAR)", "title": "Statistical estimation of jump rates for a specific class of Piecewise\n  Deterministic Markov Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the class of Piecewise Deterministic Markov Processes (PDMP),\nwhose state space is $\\R\\_{+}^{*}$, that possess an increasing deterministic\nmotion and that shrink deterministically when they jump. Well known examples\nfor this class of processes are Transmission Control Protocol (TCP) window size\nprocess and the processes modeling the size of a \"marked\" {\\it Escherichia\ncoli} cell. Having observed the PDMP until its $n$th jump, we construct a\nnonparametric estimator of the jump rate $\\lambda$. Our main result is that for\n$D$ a compact subset of $\\R\\_{+}^{*}$, if $\\lambda$ is in the H{\\''{o}}lder\nspace ${\\mathcal H}^s({\\mathcal D})$, the squared-loss error of the estimator\nis asymptotically close to the rate of $n^{-s/(2s+1)}$. Simulations illustrate\nthe behavior of our estimator.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jun 2014 09:51:33 GMT"}, {"version": "v2", "created": "Tue, 10 Mar 2015 20:16:16 GMT"}], "update_date": "2015-03-12", "authors_parsed": [["Krell", "Nathalie", "", "IRMAR"]]}, {"id": "1406.3325", "submitter": "Matyas Barczy", "authors": "Matyas Barczy, Krist\\'of K\\\"ormendi, Gyula Pap", "title": "Statistical inference for 2-type doubly symmetric critical irreducible\n  continuous state and continuous time branching processes with immigration", "comments": "67 pages. Estimation of a new parameter is added. In Section 2 we\n  recall some notions and statements from arXiv:1403.0245 and arXiv:1404.2242", "journal-ref": "Journal of Multivariate Analysis 139, (2015), 92-123", "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study asymptotic behavior of conditional least squares estimators for\n2-type doubly symmetric critical irreducible continuous state and continuous\ntime branching processes with immigration based on discrete time (low\nfrequency) observations.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jun 2014 19:05:42 GMT"}, {"version": "v2", "created": "Sat, 6 Dec 2014 21:00:41 GMT"}, {"version": "v3", "created": "Wed, 8 Apr 2015 18:18:07 GMT"}], "update_date": "2016-07-25", "authors_parsed": [["Barczy", "Matyas", ""], ["K\u00f6rmendi", "Krist\u00f3f", ""], ["Pap", "Gyula", ""]]}, {"id": "1406.3334", "submitter": "Clement Levrard", "authors": "Cl\\'ement Levrard (LPMA)", "title": "Sparse Oracle Inequalities for Variable Selection via Regularized\n  Quantization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give oracle inequalities on procedures which combines quantization and\nvariable selection via a weighted Lasso $k$-means type algorithm. The results\nare derived for a general family of weights, which can be tuned to size the\ninfluence of the variables in different ways. Moreover, these theoretical\nguarantees are proved to adapt the corresponding sparsity of the optimal\ncodebooks, if appropriate. Even if there is no sparsity assumption on the\noptimal codebooks, our procedure is proved to be close to a sparse\napproximation of the optimal codebooks, as has been done for the Generalized\nLinear Models in regression. If the optimal codebooks have a sparse support, we\nalso show that this support can be asymptotically recovered, giving an\nasymptotic upper bound on the probability of misclassification. These results\nare illustrated with Gaussian mixture models in arbitrary dimension with\nsparsity assumptions on the means, which are standard distributions in\nmodel-based clustering.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jun 2014 19:42:31 GMT"}, {"version": "v2", "created": "Wed, 15 Apr 2015 12:55:51 GMT"}, {"version": "v3", "created": "Wed, 6 Jul 2016 09:37:27 GMT"}], "update_date": "2016-07-07", "authors_parsed": [["Levrard", "Cl\u00e9ment", "", "LPMA"]]}, {"id": "1406.3372", "submitter": "Ashivni Shekhawat", "authors": "Ashivni Shekhawat", "title": "Improving extreme value statistics", "comments": "10 pages; 3 figures", "journal-ref": "Phys. Rev. E 90, 052148, 2014", "doi": "10.1103/PhysRevE.90.052148", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rate of uniform convergence in extreme value statistics is non-universal\nand can be arbitrarily slow. Further, the relative error can be unbounded in\nthe tail of the approximation, leading to difficulty in extrapolating the\nextreme value fit beyond the available data. We show that by using simple\nnonlinear transformations the extreme value approximation can be rendered\nrapidly convergent in the bulk, and asymptotic in the tail, thus fixing both\nissues. The transformations are often parameterized by just one parameter which\ncan be estimated numerically. The classical extreme value method is shown to be\na special case of the proposed method. We demonstrate that vastly improved\nresults can be obtained with almost no extra cost.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jun 2014 20:42:41 GMT"}], "update_date": "2014-12-05", "authors_parsed": [["Shekhawat", "Ashivni", ""]]}, {"id": "1406.3521", "submitter": "Ryan Martin", "authors": "Qianshun Cheng, Xu Gao, Ryan Martin", "title": "Exact prior-free probabilistic inference on the heritability coefficient\n  in a linear mixed model", "comments": "15 pages, 1 table, 2 figures", "journal-ref": "Electronic Journal of Statistics, volume 8, pages 3062-3076, 2014", "doi": "10.1214/15-EJS984", "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linear mixed-effect models with two variance components are often used when\nvariability comes from two sources. In genetics applications, variation in\nobserved traits can be attributed to biological and environmental effects, and\nthe heritability coefficient is a fundamental quantity that measures the\nproportion of total variability due to the biological effect. We propose a new\ninferential model approach which yields exact prior-free probabilistic\ninference on the heritability coefficient. In particular we construct exact\nconfidence intervals and demonstrate numerically our method's efficiency\ncompared to that of existing methods.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jun 2014 12:41:32 GMT"}, {"version": "v2", "created": "Wed, 30 Jul 2014 11:40:36 GMT"}], "update_date": "2015-01-19", "authors_parsed": [["Cheng", "Qianshun", ""], ["Gao", "Xu", ""], ["Martin", "Ryan", ""]]}, {"id": "1406.3960", "submitter": "Zahraa Salloum", "authors": "Zahraa Salloum", "title": "Empirical likelihood confidence regions for the parameters of a two\n  phases nonlinear model with and without missing response data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we use the empirical likelihood method to construct the\nconfidence regions for the difference between the parameters of a two-phases\nnonlinear model with random design. We show that the empirical likelihood ratio\nhas an asymptotic chi-squared distribution. The result is a nonparametric\nversion of Wilk's theorem. Empirical likelihood method is also used to\nconstruct the confidence regions for the difference between the parameters of a\ntwo-phases nonlinear model with response variables missing at randoms (MAR). In\norder to construct the confidence regions of the parameter in question, we\npropose three empirical likelihood statistics : Empirical likelihood based on\ncomplete-case data, weighted empiri- cal likelihood and empirical likelihood\nwith imputed values. We prove that all three empirical likelihood ratios have\nasymptotically chi-squared distributions. The effectiveness of the proposed\napproaches in aspects of coverage probability and interval length is\ndemonstrated by a Monte-Carlo simulations.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jun 2014 10:34:39 GMT"}, {"version": "v2", "created": "Tue, 17 Feb 2015 12:38:02 GMT"}], "update_date": "2015-02-18", "authors_parsed": [["Salloum", "Zahraa", ""]]}, {"id": "1406.3994", "submitter": "Botond Szabo", "authors": "Richard Nickl and Botond Szab\\'o", "title": "A sharp adaptive confidence ball for self-similar functions", "comments": "To appear in Stochastic Processes and Applications (memorial issue\n  for E. Gin\\'e)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the nonparametric Gaussian sequence space model an $\\ell^2$-confidence\nball $C_n$ is constructed that adapts to unknown smoothness and Sobolev-norm of\nthe infinite-dimensional parameter to be estimated. The confidence ball has\nexact and honest asymptotic coverage over appropriately defined `self-similar'\nparameter spaces. It is shown by information-theoretic methods that this\n`self-similarity' condition is weakest possible.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jun 2014 12:39:28 GMT"}, {"version": "v2", "created": "Tue, 11 Nov 2014 08:11:33 GMT"}, {"version": "v3", "created": "Wed, 8 Jul 2015 21:23:02 GMT"}], "update_date": "2015-07-10", "authors_parsed": [["Nickl", "Richard", ""], ["Szab\u00f3", "Botond", ""]]}, {"id": "1406.4045", "submitter": "Andreas Andresen", "authors": "Andreas Andresen", "title": "A result on the bias of sieve profile estimators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how to control the bias of a sieve type profile estimator under\nnatural conditions on the Hessian of the expected contrast functional.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jun 2014 15:29:42 GMT"}, {"version": "v2", "created": "Tue, 17 Jun 2014 14:00:55 GMT"}], "update_date": "2014-06-18", "authors_parsed": [["Andresen", "Andreas", ""]]}, {"id": "1406.4052", "submitter": "Andreas Andresen", "authors": "Andreas Andresen", "title": "Finite sample analysis of profile M-estimation in the Single Index model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We apply the results of Andresen A. and Spokoiny V. on profile M-estimators\nand the alternating maximization procedure to analyse a sieve profile quasi\nmaximum likelihood estimator in the single index model with linear index\nfunction. The link function is approximated with \\(C^3\\)-Daubechies-wavelets\nwith compact support. We derive results like Wilks phenomenon and Fisher\nTheorem in a finite sample setup. Further we show that an alternation\nmaximization procedure converges to the global maximizer and assess the\nperformance of a projection pursuit procedure in that context. The approach is\nbased on showing that the conditions of Andresen A. and Spokoiny V. on profile\nM-estimators and the alternating maximization procedure can be satisfied under\na set of mild regularity and moment conditions on the index function, the\nregressors and the additive noise. This allows to construct nonasymptotic\nconfidence sets and to derive asymptotic bounds for the estimator as\ncorollaries.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jun 2014 15:44:49 GMT"}, {"version": "v2", "created": "Tue, 17 Jun 2014 12:59:38 GMT"}, {"version": "v3", "created": "Tue, 24 Feb 2015 15:45:29 GMT"}], "update_date": "2015-02-25", "authors_parsed": [["Andresen", "Andreas", ""]]}, {"id": "1406.4062", "submitter": "Jan  Vrbik", "authors": "Jan Vrbik", "title": "Finding an ARMA(p,q) model given its spectral density or its correlogram", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An ARMA model can be fully determined based on either its spectral density,\nor its correlogram, i.e. a formula for computing the corresponding k th serial\ncorrelation for any integer k. In this article we describe how to find, given\none of these three ways of specifying the model, the other two.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jun 2014 16:40:52 GMT"}, {"version": "v2", "created": "Mon, 23 Jun 2014 14:00:47 GMT"}], "update_date": "2014-06-24", "authors_parsed": [["Vrbik", "Jan", ""]]}, {"id": "1406.4175", "submitter": "Christopher Metzler", "authors": "Christopher A. Metzler, Arian Maleki, and Richard G. Baraniuk", "title": "From Denoising to Compressed Sensing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A denoising algorithm seeks to remove noise, errors, or perturbations from a\nsignal. Extensive research has been devoted to this arena over the last several\ndecades, and as a result, today's denoisers can effectively remove large\namounts of additive white Gaussian noise. A compressed sensing (CS)\nreconstruction algorithm seeks to recover a structured signal acquired using a\nsmall number of randomized measurements. Typical CS reconstruction algorithms\ncan be cast as iteratively estimating a signal from a perturbed observation.\nThis paper answers a natural question: How can one effectively employ a generic\ndenoiser in a CS reconstruction algorithm? In response, we develop an extension\nof the approximate message passing (AMP) framework, called Denoising-based AMP\n(D-AMP), that can integrate a wide class of denoisers within its iterations. We\ndemonstrate that, when used with a high performance denoiser for natural\nimages, D-AMP offers state-of-the-art CS recovery performance while operating\ntens of times faster than competing methods. We explain the exceptional\nperformance of D-AMP by analyzing some of its theoretical features. A key\nelement in D-AMP is the use of an appropriate Onsager correction term in its\niterations, which coerces the signal perturbation at each iteration to be very\nclose to the white Gaussian noise that denoisers are typically designed to\nremove.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jun 2014 21:20:41 GMT"}, {"version": "v2", "created": "Fri, 20 Jun 2014 02:59:58 GMT"}, {"version": "v3", "created": "Fri, 4 Jul 2014 06:30:47 GMT"}, {"version": "v4", "created": "Mon, 21 Jul 2014 16:50:49 GMT"}, {"version": "v5", "created": "Sun, 17 Apr 2016 17:30:46 GMT"}], "update_date": "2016-04-19", "authors_parsed": [["Metzler", "Christopher A.", ""], ["Maleki", "Arian", ""], ["Baraniuk", "Richard G.", ""]]}, {"id": "1406.4261", "submitter": "Morteza Amini", "authors": "S. Shemehsavar, Morteza Amini", "title": "Failure Inference and Optimization for Step Stress Model Based on\n  Bivariate Wiener Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the situation under a life test, in which the\nfailure time of the test units are not related deterministically to an\nobservable stochastic time varying covariate. In such a case, the joint\ndistribution of failure time and a marker value would be useful for modeling\nthe step stress life test. The problem of accelerating such an experiment is\nconsidered as the main aim of this paper. We present a step stress accelerated\nmodel based on a bivariate Wiener process with one component as the latent\n(unobservable) degradation process, which determines the failure times and the\nother as a marker process, the degradation values of which are recorded at\ntimes of failure. Parametric inference based on the proposed model is discussed\nand the optimization procedure for obtaining the optimal time for changing the\nstress level is presented. The optimization criterion is to minimize the\napproximate variance of the maximum likelihood estimator of a percentile of the\nproducts' lifetime distribution.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jun 2014 07:41:35 GMT"}], "update_date": "2014-06-18", "authors_parsed": [["Shemehsavar", "S.", ""], ["Amini", "Morteza", ""]]}, {"id": "1406.4406", "submitter": "Sophie Donnet", "authors": "Sophie Donnet, Vincent Rivoirard, Judith Rousseau and Catia Scricciolo", "title": "Posterior concentration rates for empirical Bayes procedures, with\n  applications to Dirichlet Process mixtures", "comments": "With supplementary material", "journal-ref": null, "doi": null, "report-no": "1001815", "categories": "math.ST stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we provide general conditions to check on the model and the\nprior to derive posterior concentration rates for data-dependent priors (or\nempirical Bayes approaches). We aim at providing conditions that are close to\nthe conditions provided in the seminal paper by Ghosal and van der Vaart\n(2007a). We then apply the general theorem to two different settings: the\nestimation of a density using Dirichlet process mixtures of Gaussian random\nvariables with base measure depending on some empirical quantities and the\nestimation of the intensity of a counting process under the Aalen model. A\nsimulation study for inhomogeneous Poisson processes also illustrates our\nresults. In the former case we also derive some results on the estimation of\nthe mixing density and on the deconvolution problem. In the latter, we provide\na general theorem on posterior concentration rates for counting processes with\nAalen multiplicative intensity with priors not depending on the data.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jun 2014 15:46:44 GMT"}], "update_date": "2014-06-18", "authors_parsed": [["Donnet", "Sophie", ""], ["Rivoirard", "Vincent", ""], ["Rousseau", "Judith", ""], ["Scricciolo", "Catia", ""]]}, {"id": "1406.4421", "submitter": "Shih-Kang Chao", "authors": "Shih-Kang Chao, Katharina Proksch, Holger Dette, Wolfgang H\u007f\\\"ardle", "title": "Confidence Corridors for Multivariate Generalized Quantile Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We focus on the construction of confidence corridors for multivariate\nnonparametric generalized quantile regression functions. This construction is\nbased on asymptotic results for the maximal deviation between a suitable\nnonparametric estimator and the true function of interest which follow after a\nseries of approximation steps including a Bahadur representation, a new strong\napproximation theorem and exponential tail inequalities for Gaussian random\nfields. As a byproduct we also obtain confidence corridors for the regression\nfunction in the classical mean regression. In order to deal with the problem of\nslowly decreasing error in coverage probability of the asymptotic confidence\ncorridors, which results in meager coverage for small sample sizes, a simple\nbootstrap procedure is designed based on the leading term of the Bahadur\nrepresentation. The finite sample properties of both procedures are\ninvestigated by means of a simulation study and it is demonstrated that the\nbootstrap procedure considerably outperforms the asymptotic bands in terms of\ncoverage accuracy. Finally, the bootstrap confidence corridors are used to\nstudy the efficacy of the National Supported Work Demonstration, which is a\nrandomized employment enhancement program launched in the 1970s. This article\nhas supplementary materials.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jun 2014 16:47:03 GMT"}, {"version": "v2", "created": "Mon, 2 Feb 2015 20:08:32 GMT"}], "update_date": "2015-02-03", "authors_parsed": [["Chao", "Shih-Kang", ""], ["Proksch", "Katharina", ""], ["Dette", "Holger", ""], ["H\u007f\u00e4rdle", "Wolfgang", ""]]}, {"id": "1406.4543", "submitter": "Victor Yohai", "authors": "Daniel Pe\\~na and V\\'ictor J. Yohai", "title": "Dynamic Principal Components in the Time Domain", "comments": "35 pages,6 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a time domain approach to define dynamic principal components\n(DPC) using a reconstruction of the original series criterion. This approach to\ndefine DPC was introduced by Brillinger, who gave a very elegant theoretical\nsolution in the stationary case using the cross spectrum. Our procedure can be\napplied under more general conditions including the case ofnon stationary\nseries and relatively short series. We also present a robust version of our\nprocedure that allows to estimate the DPC when the series have outlier\ncontamination. Our non robust and robust procedures are illustrated with real\ndatasets.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jun 2014 21:09:39 GMT"}], "update_date": "2014-06-19", "authors_parsed": [["Pe\u00f1a", "Daniel", ""], ["Yohai", "V\u00edctor J.", ""]]}, {"id": "1406.4584", "submitter": "Anindya Roy", "authors": "Anindya Roy, Tucker S. McElroy and Peter Linton", "title": "Estimation of Causal Invertible VARMA Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a re-parameterization of vector autoregressive moving average\n(VARMA) models that allows estimation of parameters under the constraints of\ncausality and invertibility. The parameter constraints associated with a causal\ninvertible VARMA model are highly complex. Currently there are no procedures\nthat can maintain the constraints in the estimated VARMA process, except in the\nspecial case of a vector autoregression (VAR), where some moment based causal\nestimators are available. Even in the VAR case, the available likelihood based\nestimators are not causal. The maximum likelihood estimator based on the full\nlikelihood that does not condition on the initial observations by definition\nsatisfies the causal invertible constraints but optimization of the likelihood\nunder the complex constraints is an intractable problem. The commonly used\nBayesian procedure for VAR often has posterior mass outside the causal set\nbecause the priors are not constrained to the causal set of parameters.\n  We provide an exact mathematical solution to this problem. An $m$-variate\nVARMA$(p, q)$ process contains $(p+ q) m^2 + \\binom{m+1}{2}$ parameters, which\nmust be constrained to a subset of Euclidean space in order to guarantee\ncausality and invertibility. This space is implicitly described in this paper,\nthrough the device of parameterizing the entire space of block Toeplitz\nmatrices in terms of positive definite matrices and orthogonal matrices. The\nparameterization has connection to Schur- stability of polynomials and the\nassociated Stein transformation that are often used in dynamical systems\nliterature. As an important by-product of our investigation, we generalize a\nclassical result in dynamical systems to provide a characterization of Schur\nstable matrix polynomials.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jun 2014 03:41:36 GMT"}], "update_date": "2014-06-19", "authors_parsed": [["Roy", "Anindya", ""], ["McElroy", "Tucker S.", ""], ["Linton", "Peter", ""]]}, {"id": "1406.4689", "submitter": "Kammoun Abla", "authors": "Nadhir Ben Rached, Fatma Benkhelifa, Abla Kammoun, Mohamed-Slim\n  Alouini, and Raul Tempone", "title": "A Fast Simulation Method for the Sum of Subexponential Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating the probability that a sum of random variables (RVs) exceeds a\ngiven threshold is a well-known challenging problem. Closed-form expression of\nthe sum distribution is usually intractable and presents an open problem. A\ncrude Monte Carlo (MC) simulation is the standard technique for the estimation\nof this type of probability. However, this approach is computationally\nexpensive especially when dealing with rare events (i.e events with very small\nprobabilities). Importance Sampling (IS) is an alternative approach which\neffectively improves the computational efficiency of the MC simulation. In this\npaper, we develop a general framework based on IS approach for the efficient\nestimation of the probability that the sum of independent and not necessarily\nidentically distributed heavy-tailed RVs exceeds a given threshold. The\nproposed IS approach is based on constructing a new sampling distribution by\ntwisting the hazard rate of the original underlying distribution of each\ncomponent in the summation. A minmax approach is carried out for the\ndetermination of the twisting parameter, for any given threshold. Moreover,\nusing this minmax optimal choice, the estimation of the probability of interest\nis shown to be asymptotically optimal as the threshold goes to infinity. We\nalso offer some selected simulation results illustrating first the efficiency\nof the proposed IS approach compared to the naive MC simulation. The\nnear-optimality of the minmax approach is then numerically analyzed.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jun 2014 11:46:59 GMT"}, {"version": "v2", "created": "Tue, 24 Jun 2014 09:33:37 GMT"}, {"version": "v3", "created": "Wed, 25 Jun 2014 09:04:44 GMT"}, {"version": "v4", "created": "Sun, 21 Sep 2014 13:24:49 GMT"}], "update_date": "2014-09-23", "authors_parsed": [["Rached", "Nadhir Ben", ""], ["Benkhelifa", "Fatma", ""], ["Kammoun", "Abla", ""], ["Alouini", "Mohamed-Slim", ""], ["Tempone", "Raul", ""]]}, {"id": "1406.4765", "submitter": "Jari Miettinen", "authors": "Jari Miettinen, Sara Taskinen, Klaus Nordhausen, Hannu Oja", "title": "Fourth Moments and Independent Component Analysis", "comments": "Published at http://dx.doi.org/10.1214/15-STS520 in the Statistical\n  Science (http://www.imstat.org/sts/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Statistical Science 2015, Vol. 30, No. 3, 372-390", "doi": "10.1214/15-STS520", "report-no": "IMS-STS-STS520", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In independent component analysis it is assumed that the components of the\nobserved random vector are linear combinations of latent independent random\nvariables, and the aim is then to find an estimate for a transformation matrix\nback to these independent components. In the engineering literature, there are\nseveral traditional estimation procedures based on the use of fourth moments,\nsuch as FOBI (fourth order blind identification), JADE (joint approximate\ndiagonalization of eigenmatrices), and FastICA, but the statistical properties\nof these estimates are not well known. In this paper various independent\ncomponent functionals based on the fourth moments are discussed in detail,\nstarting with the corresponding optimization problems, deriving the estimating\nequations and estimation algorithms, and finding asymptotic statistical\nproperties of the estimates. Comparisons of the asymptotic variances of the\nestimates in wide independent component models show that in most cases JADE and\nthe symmetric version of FastICA perform better than their competitors.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jun 2014 15:23:14 GMT"}, {"version": "v2", "created": "Thu, 10 Sep 2015 10:42:33 GMT"}], "update_date": "2015-09-11", "authors_parsed": [["Miettinen", "Jari", ""], ["Taskinen", "Sara", ""], ["Nordhausen", "Klaus", ""], ["Oja", "Hannu", ""]]}, {"id": "1406.4775", "submitter": "Andrea Montanari", "authors": "Andrea Montanari and Emile Richard", "title": "Non-negative Principal Component Analysis: Message Passing Algorithms\n  and Sharp Asymptotics", "comments": "51 pages, 7 pdf figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Principal component analysis (PCA) aims at estimating the direction of\nmaximal variability of a high-dimensional dataset. A natural question is: does\nthis task become easier, and estimation more accurate, when we exploit\nadditional knowledge on the principal vector? We study the case in which the\nprincipal vector is known to lie in the positive orthant. Similar constraints\narise in a number of applications, ranging from analysis of gene expression\ndata to spike sorting in neural signal processing.\n  In the unconstrained case, the estimation performances of PCA has been\nprecisely characterized using random matrix theory, under a statistical model\nknown as the `spiked model.' It is known that the estimation error undergoes a\nphase transition as the signal-to-noise ratio crosses a certain threshold.\nUnfortunately, tools from random matrix theory have no bearing on the\nconstrained problem. Despite this challenge, we develop an analogous\ncharacterization in the constrained case, within a one-spike model.\n  In particular: $(i)$~We prove that the estimation error undergoes a similar\nphase transition, albeit at a different threshold in signal-to-noise ratio that\nwe determine exactly; $(ii)$~We prove that --unlike in the unconstrained case--\nestimation error depends on the spike vector, and characterize the least\nfavorable vectors; $(iii)$~We show that a non-negative principal component can\nbe approximately computed --under the spiked model-- in nearly linear time.\nThis despite the fact that the problem is non-convex and, in general, NP-hard\nto solve exactly.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jun 2014 15:47:33 GMT"}], "update_date": "2014-06-19", "authors_parsed": [["Montanari", "Andrea", ""], ["Richard", "Emile", ""]]}, {"id": "1406.4777", "submitter": "Emanuel Ben-David", "authors": "Emanuel Ben-David", "title": "Sharper lower and upper bounds for the gaussian rank of a graph", "comments": "19 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An open problem in graphical Gaussian models is to determine the smallest\nnumber of observations needed to guarantee the existence of the maximum\nlikelihood estimator of the covariance matrix with probability one. In this\npaper we formalize a closely related problem in which the existence of the\nmaximum likelihood estimator is guaranteed for all generic observations. We\ncall the number determined by this problem the Gaussian rank of the graph\nrepresenting the model. We prove that the Gaussian rank is strictly between the\nsubgraph connectivity number and the graph degeneracy number. These bounds are\nin general much sharper than the best bounds known in the literature and\nfurthermore computable in polynomial time.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jun 2014 15:55:09 GMT"}, {"version": "v2", "created": "Mon, 4 Aug 2014 19:52:10 GMT"}], "update_date": "2014-08-05", "authors_parsed": [["Ben-David", "Emanuel", ""]]}, {"id": "1406.4901", "submitter": "Caroline Uhler", "authors": "Caroline Uhler, Alex Lenkoski and Donald Richards", "title": "Exact formulas for the normalizing constants of Wishart distributions\n  for graphical models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian graphical models have received considerable attention during the\npast four decades from the statistical and machine learning communities. In\nBayesian treatments of this model, the G-Wishart distribution serves as the\nconjugate prior for inverse covariance matrices satisfying graphical\nconstraints. While it is straightforward to posit the unnormalized densities,\nthe normalizing constants of these distributions have been known only for\ngraphs that are chordal, or decomposable. Up until now, it was unknown whether\nthe normalizing constant for a general graph could be represented explicitly,\nand a considerable body of computational literature emerged that attempted to\navoid this apparent intractability. We close this question by providing an\nexplicit representation of the G-Wishart normalizing constant for general\ngraphs.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jun 2014 22:03:28 GMT"}, {"version": "v2", "created": "Wed, 22 Jun 2016 17:04:08 GMT"}], "update_date": "2016-06-23", "authors_parsed": [["Uhler", "Caroline", ""], ["Lenkoski", "Alex", ""], ["Richards", "Donald", ""]]}, {"id": "1406.4904", "submitter": "David Tyler", "authors": "David E. Tyler", "title": "Breakdown Properties of the M-Estimators of Multivariate Scatter", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The M-estimators of multivariate scatter are known to have breakdown points\nno greater than 1/(p+1), where p is the dimension of the data. In high\ndimension, the breakdown points are usually considered to be disappointingly\nlow. This paper studies the breakdown problem in more detail. The exact\nbreakdown points for the M-estimators of scatter are obtained and it is shown\nthat their low values are primarily due to contamination restricted to some\nplane. If such \"coplanar\" contamination is not present, then there exists\nM-estimators which have breakdown points close to 1/2. The effect of coplanar\ncontamination is further examined and is shown to be related to the singularity\nof the scatter matrix. Finally, the implications of the results of this paper\non whether the low breakdown point is necessarily a bad feature and on\nmultivariate outlier detection are briefly discussed.\n  This paper is a reprint of an unpublished 1986 Rutgers Technical Report.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jun 2014 22:12:24 GMT"}], "update_date": "2014-06-20", "authors_parsed": [["Tyler", "David E.", ""]]}, {"id": "1406.5387", "submitter": "Theofanis Sapatinas", "authors": "Clement Marteau and Theofanis Sapatinas", "title": "A unified treatment for non-asymptotic and asymptotic approaches to\n  minimax signal detection", "comments": "37 pages, 4 Figures", "journal-ref": "Statistics Surveys, Vol. 9, 253-297 (2015)", "doi": "10.1214/15-SS112", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are concerned with minimax signal detection. In this setting, we discuss\nnon-asymptotic and asymptotic approaches through a unified treatment. In\nparticular, we consider a Gaussian sequence model that contains classical\nmodels as special cases, such as, direct, well-posed inverse and ill-posed\ninverse problems. Working with certain ellipsoids in the space of\nsquared-summable sequences of real numbers, with a ball of positive radius\nremoved, we compare the construction of lower and upper bounds for the minimax\nseparation radius (non-asymptotic approach) and the minimax separation rate\n(asymptotic approach) that have been proposed in the literature. Some\nadditional contributions, bringing into light links between non-asymptotic and\nasymptotic approaches to minimax signal, are also presented. An example of a\nmildly ill-posed inverse problem is used for illustrative purposes. In\nparticular, it is shown that tools used to derive `asymptotic' results can be\nexploited to draw `non-asymptotic' conclusions, and vice-versa.\n", "versions": [{"version": "v1", "created": "Fri, 20 Jun 2014 13:49:29 GMT"}, {"version": "v2", "created": "Mon, 7 Jul 2014 11:43:30 GMT"}, {"version": "v3", "created": "Wed, 15 Oct 2014 16:19:47 GMT"}, {"version": "v4", "created": "Thu, 9 Jul 2015 09:27:02 GMT"}], "update_date": "2016-01-27", "authors_parsed": [["Marteau", "Clement", ""], ["Sapatinas", "Theofanis", ""]]}, {"id": "1406.5540", "submitter": "Philip Dawid", "authors": "A. Philip Dawid", "title": "On Individual Risk", "comments": "31 pages", "journal-ref": "Synthese 194 (2017(, 3445-3474", "doi": "10.1007/s11229-015-0953-4", "report-no": null, "categories": "stat.AP math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We survey a variety of possible explications of the term \"Individual Risk.\"\nThese in turn are based on a variety of interpretations of \"Probability,\"\nincluding Classical, Enumerative, Frequency, Formal, Metaphysical, Personal,\nPropensity, Chance and Logical conceptions of Probability, which we review and\ncompare. We distinguish between \"groupist\" and \"individualist\" understandings\nof Probability, and explore both \"group to individual\" (G2i) and \"individual to\ngroup\" (i2G) approaches to characterising Individual Risk. Although in the end\nthat concept remains subtle and elusive, some pragmatic suggestions for\nprogress are made.\n", "versions": [{"version": "v1", "created": "Fri, 20 Jun 2014 21:07:40 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Dawid", "A. Philip", ""]]}, {"id": "1406.5556", "submitter": "Raja Manish", "authors": "Raja Manish", "title": "Linear and Non-linear Estimation Techniques: Theory and Comparison", "comments": "17 Pages, Matlab algorithm", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The wide application of estimation techniques in system analysis enable us to\nbest determine and understand the history of system states. This paper attempts\nto delineate the theory behind linear and non-linear estimation with a suitable\nexample for the comparison of some of the techniques of non-linear estimation.\n", "versions": [{"version": "v1", "created": "Fri, 20 Jun 2014 23:34:36 GMT"}, {"version": "v2", "created": "Sat, 18 Oct 2014 22:19:19 GMT"}], "update_date": "2014-10-21", "authors_parsed": [["Manish", "Raja", ""]]}, {"id": "1406.5577", "submitter": "Tvrtko Tadi\\'c", "authors": "Tvrtko Tadi\\'c", "title": "Graphical structure of conditional independencies in determinantal point\n  processes", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Determinantal point process have recently been used as models in machine\nlearning and this has raised questions regarding the characterizations of\nconditional independence. In this paper we investigate characterizations of\nconditional independence. We describe some conditional independencies through\nthe conditions on the kernel of a determinantal point process, and show many\ncan be obtained using the graph induced by a kernel of the $L$-ensemble.\n", "versions": [{"version": "v1", "created": "Sat, 21 Jun 2014 04:38:47 GMT"}, {"version": "v2", "created": "Sun, 29 Jun 2014 02:43:26 GMT"}], "update_date": "2014-07-01", "authors_parsed": [["Tadi\u0107", "Tvrtko", ""]]}, {"id": "1406.5580", "submitter": "Takumi Saegusa", "authors": "Takumi Saegusa", "title": "Bootstrapping Two-phase Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a nonparametric bootstrap procedure for two-phase stratified\nsampling without replacement. In this design, a weighted likelihood estimator\nis known to have smaller asymptotic variance than under the convenient\nassumption of independence often made in practice. Variance estimation,\nhowever, has not been well studied for semiparametric models where variance may\nnot have a closed form. Motivated by semiparametric inference, we establish\nconditional weak convergence of bootstrap inverse probability weighted\nempirical processes with several variants of calibration. Two main obstacles to\napplying existing bootstrap empirical process theory are the dependent and\nbiased sample due to sampling design, and the complex limiting processes of the\nlinear combinations of Brownian bridge processes. To address these issues, the\nproposed bootstrap weights take the form of the product of two weights\ncorresponding to randomness from each phase and stratum. We apply our bootstrap\nto weighted likelihood estimation and establish two Z-theorems for a general\nsemiparametric model where a nuisance parameter can be estimated either at a\nregular or a non-regular rate. We show different bootstrap calibration methods\nproposed in the survey sampling literature yield different bootstrap asymptotic\ndistributions.\n", "versions": [{"version": "v1", "created": "Sat, 21 Jun 2014 06:18:35 GMT"}, {"version": "v2", "created": "Wed, 24 Sep 2014 21:27:39 GMT"}], "update_date": "2014-09-26", "authors_parsed": [["Saegusa", "Takumi", ""]]}, {"id": "1406.5638", "submitter": "Jiaming Xu", "authors": "Bruce Hajek and Sewoong Oh and Jiaming Xu", "title": "Minimax-optimal Inference from Partial Rankings", "comments": "16 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the problem of inferring a global preference based on the\npartial rankings provided by many users over different subsets of items\naccording to the Plackett-Luce model. A question of particular interest is how\nto optimally assign items to users for ranking and how many item assignments\nare needed to achieve a target estimation error. For a given assignment of\nitems to users, we first derive an oracle lower bound of the estimation error\nthat holds even for the more general Thurstone models. Then we show that the\nCram\\'er-Rao lower bound and our upper bounds inversely depend on the spectral\ngap of the Laplacian of an appropriately defined comparison graph. When the\nsystem is allowed to choose the item assignment, we propose a random assignment\nscheme. Our oracle lower bound and upper bounds imply that it is\nminimax-optimal up to a logarithmic factor among all assignment schemes and the\nlower bound can be achieved by the maximum likelihood estimator as well as\npopular rank-breaking schemes that decompose partial rankings into pairwise\ncomparisons. The numerical experiments corroborate our theoretical findings.\n", "versions": [{"version": "v1", "created": "Sat, 21 Jun 2014 17:55:54 GMT"}], "update_date": "2014-06-24", "authors_parsed": [["Hajek", "Bruce", ""], ["Oh", "Sewoong", ""], ["Xu", "Jiaming", ""]]}, {"id": "1406.5663", "submitter": "Yen-Chi Chen", "authors": "Yen-Chi Chen, Christopher R. Genovese, Larry Wasserman", "title": "Asymptotic theory for density ridges", "comments": "Published at http://dx.doi.org/10.1214/15-AOS1329 in the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2015, Vol. 43, No. 5, 1896-1928", "doi": "10.1214/15-AOS1329", "report-no": "IMS-AOS-AOS1329", "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The large sample theory of estimators for density modes is well understood.\nIn this paper we consider density ridges, which are a higher-dimensional\nextension of modes. Modes correspond to zero-dimensional, local high-density\nregions in point clouds. Density ridges correspond to $s$-dimensional, local\nhigh-density regions in point clouds. We establish three main results. First we\nshow that under appropriate regularity conditions, the local variation of the\nestimated ridge can be approximated by an empirical process. Second, we show\nthat the distribution of the estimated ridge converges to a Gaussian process.\nThird, we establish that the bootstrap leads to valid confidence sets for\ndensity ridges.\n", "versions": [{"version": "v1", "created": "Sun, 22 Jun 2014 02:16:33 GMT"}, {"version": "v2", "created": "Fri, 13 Mar 2015 20:32:14 GMT"}, {"version": "v3", "created": "Tue, 13 Oct 2015 13:25:53 GMT"}], "update_date": "2015-10-14", "authors_parsed": [["Chen", "Yen-Chi", ""], ["Genovese", "Christopher R.", ""], ["Wasserman", "Larry", ""]]}, {"id": "1406.5706", "submitter": "Francesca Paola Carli", "authors": "Francesca Paola Carli", "title": "On the Maximum Entropy Property of the First-Order Stable Spline Kernel\n  and its Implications", "comments": "12 pages. In 2014 IEEE Multi-conference on Systems and Control. IEEE,\n  2014", "journal-ref": null, "doi": "10.1109/CCA.2014.6981380", "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new nonparametric approach for system identification has been recently\nproposed where the impulse response is seen as the realization of a zero--mean\nGaussian process whose covariance, the so--called stable spline kernel,\nguarantees that the impulse response is almost surely stable. Maximum entropy\nproperties of the stable spline kernel have been pointed out in the literature.\nIn this paper we provide an independent proof that relies on the theory of\nmatrix extension problems in the graphical model literature and leads to a\nclosed form expression for the inverse of the first order stable spline kernel\nas well as to a new factorization in the form $UWU^\\top$ with $U$ upper\ntriangular and $W$ diagonal. Interestingly, all first--order stable spline\nkernels share the same factor $U$ and $W$ admits a closed form representation\nin terms of the kernel hyperparameter, making the factorization computationally\ninexpensive. Maximum likelihood properties of the stable spline kernel are also\nhighlighted. These results can be applied both to improve the stability and to\nreduce the computational complexity associated with the computation of stable\nspline estimators.\n", "versions": [{"version": "v1", "created": "Sun, 22 Jun 2014 11:38:59 GMT"}, {"version": "v2", "created": "Sun, 21 Sep 2014 22:03:06 GMT"}], "update_date": "2016-11-18", "authors_parsed": [["Carli", "Francesca Paola", ""]]}, {"id": "1406.5840", "submitter": "Eitan Greenshtein", "authors": "Eitan Greenshtein and Theodor Itskov", "title": "Deconvolution, convex optimization, non-parametric empirical Bayes and\n  treatment of non-response", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $(Y_i,\\theta_i)$, $i=1,...,n$, be independent random vectors distributed\nlike $(Y,\\theta) \\sim G^*$, where the marginal distribution of $\\theta$ is\ncompletely unknown, and the conditional distribution of $Y$ conditional on\n$\\theta$ is known. It is desired to estimate the marginal distribution of\n$\\theta$ under $G^*$, as well as functionals of the form $E_{G^*} h(Y,\\theta)$\nfor a given $h$, based on the observed $Y_1,...,Y_n$.\n  In this paper we suggest a deconvolution method for the above estimation\nproblems and discuss some of its applications in Empirical Bayes analysis. The\nmethod involves a quadratic programming step, which is an elaboration on the\nformulation and technique in Efron(2013). It is computationally efficient and\nmay handle large data sets, where the popular method, of deconvolution using\nEM-algorithm, is impractical.\n  The main application that we study is treatment of non-response. Our approach\nis nonstandard and does not involve missing at random type of assumptions. The\nmethod is demonstrated in simulations, as well as in an analysis of a real data\nset from the Labor force survey in Israel. Other applications including\nestimation of the risk, and estimation of False Discovery Rates, are also\ndiscussed.\n  We also present a method, that involves convex optimization, for constructing\nconfidence intervals for $E_{G^*} h$, under the above setup.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jun 2014 09:12:48 GMT"}], "update_date": "2014-06-24", "authors_parsed": [["Greenshtein", "Eitan", ""], ["Itskov", "Theodor", ""]]}, {"id": "1406.5863", "submitter": "Valentine Genon-Catalot", "authors": "Valentine Genon-Catalot, Catherine Lar\\'edo", "title": "Asymptotic equivalence of nonparametric diffusion and Euler scheme\n  experiments", "comments": "Published in at http://dx.doi.org/10.1214/14-AOS1216 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2014, Vol. 42, No. 3, 1145-1165", "doi": "10.1214/14-AOS1216", "report-no": "IMS-AOS-AOS1216", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove a global asymptotic equivalence of experiments in the sense of Le\nCam's theory. The experiments are a continuously observed diffusion with\nnonparametric drift and its Euler scheme. We focus on diffusions with\nnonconstant-known diffusion coefficient. The asymptotic equivalence is proved\nby constructing explicit equivalence mappings based on random time changes. The\nequivalence of the discretized observation of the diffusion and the\ncorresponding Euler scheme experiment is then derived. The impact of these\nequivalence results is that it justifies the use of the Euler scheme instead of\nthe discretized diffusion process for inference purposes.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jun 2014 10:44:30 GMT"}], "update_date": "2014-06-24", "authors_parsed": [["Genon-Catalot", "Valentine", ""], ["Lar\u00e9do", "Catherine", ""]]}, {"id": "1406.5881", "submitter": "Thomas Trikalinos", "authors": "Ingram Olkin, Thomas A. Trikalinos", "title": "Constructions for a bivariate beta distribution", "comments": "10 pages, 1 table, 1 figure", "journal-ref": null, "doi": null, "report-no": "tech2014_0001", "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The beta distribution is a basic distribution serving several purposes. It is\nused to model data, and also, as a more flexible version of the uniform\ndistribution, it serves as a prior distribution for a binomial probability. The\nbivariate beta distribution plays a similar role for two probabilities that\nhave a bivariate binomial distribution. We provide a new multivariate\ndistribution with beta marginal distributions, positive probability over the\nunit square, and correlations over the full range. We discuss its extension to\nthree or more dimensions.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jun 2014 12:11:47 GMT"}, {"version": "v2", "created": "Tue, 16 Sep 2014 12:24:06 GMT"}], "update_date": "2014-09-17", "authors_parsed": [["Olkin", "Ingram", ""], ["Trikalinos", "Thomas A.", ""]]}, {"id": "1406.5933", "submitter": "Jay Bartroff", "authors": "Jay Bartroff", "title": "Multiple Hypothesis Tests Controlling Generalized Error Rates for\n  Sequential Data", "comments": "35 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The $\\gamma$-FDP and $k$-FWER multiple testing error metrics, which are tail\nprobabilities of the respective error statistics, have become popular recently\nas less-stringent alternatives to the FDR and FWER. We propose general and\nflexible stepup and stepdown procedures for testing multiple hypotheses about\nsequential (or streaming) data that simultaneously control both the type I and\nII versions of $\\gamma$-FDP, or $k$-FWER. The error control holds regardless of\nthe dependence between data streams, which may be of arbitrary size and shape.\nAll that is needed is a test statistic for each data stream that controls the\nconventional type I and II error probabilities, and no information or\nassumptions are required about the joint distribution of the statistics or data\nstreams. The procedures can be used with sequential, group sequential,\ntruncated, or other sampling schemes. We give recommendations for the\nprocedures' implementation including closed-form expressions for the needed\ncritical values in some commonly-encountered testing situations. The proposed\nsequential procedures are compared with each other and with comparable fixed\nsample size procedures in the context of strongly positively correlated\nGaussian data streams. For this setting we conclude that both the stepup and\nstepdown sequential procedures provide substantial savings over the fixed\nsample procedures in terms of expected sample size, and the stepup procedure\nperforms slightly but consistently better than the stepdown for $\\gamma$-FDP\ncontrol, with the relationship reversed for $k$-FWER control.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jun 2014 14:57:17 GMT"}, {"version": "v2", "created": "Fri, 19 Sep 2014 15:14:08 GMT"}, {"version": "v3", "created": "Mon, 19 Oct 2015 20:47:53 GMT"}, {"version": "v4", "created": "Mon, 19 Dec 2016 16:41:09 GMT"}], "update_date": "2016-12-20", "authors_parsed": [["Bartroff", "Jay", ""]]}, {"id": "1406.5936", "submitter": "Seth Sullivant", "authors": "Johannes Rauh and Seth Sullivant", "title": "The Markov basis of $K_{3,N}$", "comments": "14 pages. An HTML version of this document is available at\n  http://markov-bases.de/models/K3N/K3N.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AC math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This document explains how to obtain a Markov basis of the graphical model of\nthe complete bipartite graph $K_{3,N}$ with binary nodes. The computations\nillustrate the theory developed in arXiv:1404.6392 that explains how to compute\nMarkov bases of toric fiber products.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jun 2014 15:05:42 GMT"}, {"version": "v2", "created": "Thu, 26 Jun 2014 16:02:58 GMT"}], "update_date": "2014-06-27", "authors_parsed": [["Rauh", "Johannes", ""], ["Sullivant", "Seth", ""]]}, {"id": "1406.5973", "submitter": "Helena Ferreira", "authors": "Helena Ferreira and Luisa Pereira", "title": "Dependence of maxima in space", "comments": null, "journal-ref": null, "doi": "10.1088/1742-6596/574/1/012021", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a coefficient that measures the dependence among large values for\nspatial processes of maxima. Its main properties are: a) $k$ locations can be\ntaken into account; b) it takes values in $[0,1]$ and higher values indicate\nstronger dependence; c) it is independent of the univariate marginal\ndistributions of the random field; d) it can be related with the tail\ndependence and the extremal coefficients; e) it agrees with the concordance\nproperty for multivariate distributions; f) it has as a particular case the\nvariogram from geostatistics; g) it can be easily estimated.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jun 2014 16:34:09 GMT"}], "update_date": "2015-06-22", "authors_parsed": [["Ferreira", "Helena", ""], ["Pereira", "Luisa", ""]]}, {"id": "1406.6031", "submitter": "Claudio Agostinelli", "authors": "Claudio Agostinelli, Andy Leung, Victor J. Yohai and Ruben H. Zamar", "title": "Robust estimation of multivariate location and scatter in the presence\n  of cellwise and casewise contamination", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multivariate location and scatter matrix estimation is a cornerstone in\nmultivariate data analysis. We consider this problem when the data may contain\nindependent cellwise and casewise outliers. Flat data sets with a large number\nof variables and a relatively small number of cases are common place in modern\nstatistical applications. In these cases global down-weighting of an entire\ncase, as performed by traditional robust procedures, may lead to poor results.\nWe highlight the need for a new generation of robust estimators that can\nefficiently deal with cellwise outliers and at the same time show good\nperformance under casewise outliers.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jun 2014 19:30:41 GMT"}], "update_date": "2014-06-24", "authors_parsed": [["Agostinelli", "Claudio", ""], ["Leung", "Andy", ""], ["Yohai", "Victor J.", ""], ["Zamar", "Ruben H.", ""]]}, {"id": "1406.6085", "submitter": "Olivier Ledoit", "authors": "Olivier Ledoit and Michael Wolf", "title": "Spectrum Estimation: A Unified Framework for Covariance Matrix\n  Estimation and PCA in Large Dimensions", "comments": "40 pages, 8 figures, 5 tables, University of Zurich, Department of\n  Economics, Working Paper No. 105, Revised version, July 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.OT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Covariance matrix estimation and principal component analysis (PCA) are two\ncornerstones of multivariate analysis. Classic textbook solutions perform\npoorly when the dimension of the data is of a magnitude similar to the sample\nsize, or even larger. In such settings, there is a common remedy for both\nstatistical problems: nonlinear shrinkage of the eigenvalues of the sample\ncovariance matrix. The optimal nonlinear shrinkage formula depends on unknown\npopulation quantities and is thus not available. It is, however, possible to\nconsistently estimate an oracle nonlinear shrinkage, which is motivated on\nasymptotic grounds. A key tool to this end is consistent estimation of the set\nof eigenvalues of the population covariance matrix (also known as the\nspectrum), an interesting and challenging problem in its own right. Extensive\nMonte Carlo simulations demonstrate that our methods have desirable\nfinite-sample properties and outperform previous proposals.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jun 2014 20:46:26 GMT"}], "update_date": "2014-06-25", "authors_parsed": [["Ledoit", "Olivier", ""], ["Wolf", "Michael", ""]]}, {"id": "1406.6106", "submitter": "Javier Segura", "authors": "J. Segura", "title": "Monotonicity properties and bounds for the chi-square and gamma\n  distributions", "comments": "Submitted on April 10,2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CA math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The generalized Marcum functions $Q_{\\mu}(x,y)$ and $P_{\\mu}(x,y)$ have as\nparticular cases the non-central $\\chi^2$ and gamma cumulative distributions,\nwhich become central distributions (incomplete gamma function ratios) when the\nnon-centrality parameter $x$ is set to zero. We analyze monotonicity and\nconvexity properties for the generalized Marcum functions and for ratios of\nMarcum functions of consecutive parameters (differing in one unity) and we\nobtain upper and lower bounds for the Marcum functions. These bounds are proven\nto be sharper than previous estimations for a wide range of the parameters.\nAdditionally we show how to build convergent sequences of upper and lower\nbounds. The particularization to incomplete gamma functions, together with some\nadditional bounds obtained for this particular case, lead to combined bounds\nwhich improve previously exiting inequalities.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jun 2014 23:15:14 GMT"}], "update_date": "2014-06-25", "authors_parsed": [["Segura", "J.", ""]]}, {"id": "1406.6227", "submitter": "Samuel Maistre", "authors": "Samuel Maistre and Valentin Patilea", "title": "Testing for the significance of functional covariates in regression\n  models", "comments": "31 pages, 3 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regression models with a response variable taking values in a Hilbert space\nand hybrid covariates are considered. This means two sets of regressors are\nallowed, one of finite dimension and a second one functional with values in a\nHilbert space. The problem we address is the test of the effect of the\nfunctional covariates. This problem occurs for instance when checking the\ngoodness-of-fit of some regression models for functional data. The significance\ntest for functional regressors in nonparametric regression with hybrid\ncovariates and scalar or functional responses is another example where the core\nproblem is the test on the effect of functional covariates. We propose a new\ntest based on kernel smoothing. The test statistic is asymptotically standard\nnormal under the null hypothesis provided the smoothing parameter tends to zero\nat a suitable rate. The one-sided test is consistent against any fixed\nalternative and detects local alternatives \\`a la Pitman approaching the null\nhypothesis. In particular we show that neither the dimension of the outcome nor\nthe dimension of the functional covariates influences the theoretical power of\nthe test against such local alternatives. Simulation experiments and a real\ndata application illustrate the performance of the new test with finite\nsamples.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jun 2014 13:14:55 GMT"}], "update_date": "2014-06-25", "authors_parsed": [["Maistre", "Samuel", ""], ["Patilea", "Valentin", ""]]}, {"id": "1406.6326", "submitter": "Selden Crary", "authors": "Selden Crary", "title": "Factorization of the Determinant of the Gaussian-Correlation Matrix of\n  Evenly Spaced Points Using an Inter-dimensional Multiset Duality", "comments": "13 pages and 1 figure; Credit given to earlier proofs of Parts b and\n  d of lemma", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that the determinant of a Gaussian-correlation matrix V of n evenly\nspaced points has leading power n(n-1) in the nearest-neighbor distance between\npoints. The proof uses Neville elimination to determine all elements of the\nupper triangular matrix U of V and provides a factorization of det(V). The\nproof makes use of an inter-dimensional multiset duality involving simplices\nthat emerge during the factorization. We conjecture that V for evenly spaced\npoints is strictly totally positive.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jun 2014 18:04:43 GMT"}, {"version": "v2", "created": "Mon, 30 Jun 2014 15:28:25 GMT"}, {"version": "v3", "created": "Tue, 28 May 2019 03:02:17 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Crary", "Selden", ""]]}, {"id": "1406.6348", "submitter": "Simon Nanty", "authors": "Vincent Moutoussamy (EDF R&D, IMT), Simon Nanty (DER, Grenoble 1 UJF),\n  Beno\\^it Pauwels (IFPEN, UPS)", "title": "Emulators for stochastic simulation codes", "comments": null, "journal-ref": null, "doi": "10.1051/proc/201448005", "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Numerical simulation codes are very common tools to study complex phenomena,\nbut they are often time-consuming and considered as black boxes. For some\nstatistical studies (e.g. asset management, sensitivity analysis) or\noptimization problems (e.g. tuning of a molecular model), a high number of runs\nof such codes is needed. Therefore it is more convenient to build a\nfast-running approximation - or metamodel - of this code based on a design of\nexperiments. The topic of this paper is the definition of metamodels for\nstochastic codes. Contrary to deterministic codes, stochastic codes can give\ndifferent results when they are called several times with the same input. In\nthis paper, two approaches are proposed to build a metamodel of the probability\ndensity function of a stochastic code output. The first one is based on kernel\nregression and the second one consists in decomposing the output density on a\nbasis of well-chosen probability density functions, with a metamodel linking\nthe coefficients and the input parameters. For the second approach, two types\nof decomposition are proposed, but no metamodel has been designed for the\ncoefficients yet. This is a topic of future research. These methods are applied\nto two analytical models and three industrial cases.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jun 2014 19:37:56 GMT"}, {"version": "v2", "created": "Thu, 26 Jun 2014 06:57:23 GMT"}], "update_date": "2017-08-14", "authors_parsed": [["Moutoussamy", "Vincent", "", "EDF R&D, IMT"], ["Nanty", "Simon", "", "DER, Grenoble 1 UJF"], ["Pauwels", "Beno\u00eet", "", "IFPEN, UPS"]]}, {"id": "1406.6419", "submitter": "Agniva Som", "authors": "Agniva Som, Christopher M. Hans, Steven N. MacEachern", "title": "Block Hyper-g Priors in Bayesian Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The development of prior distributions for Bayesian regression has\ntraditionally been driven by the goal of achieving sensible model selection and\nparameter estimation. The formalization of properties that characterize good\nperformance has led to the development and popularization of thick tailed\nmixtures of g priors such as the Zellner--Siow and hyper-g priors. The\nproperties of a particular prior are typically illuminated under limits on the\nlikelihood or the prior. In this paper we introduce a new, conditional\ninformation asymptotic that is motivated by the common data analysis setting\nwhere at least one regression coefficient is much larger than others. We\nanalyze existing mixtures of g priors under this limit and reveal two new\nbehaviors, Essentially Least Squares (ELS) estimation and the Conditional\nLindley's Paradox (CLP), and argue that these behaviors are, in general,\nundesirable. As the driver behind both of these behaviors is the use of a\nsingle, latent scale parameter that is common to all coefficients, we propose a\nblock hyper-g prior, defined by first partitioning the covariates into groups\nand then placing independent hyper-g priors on the corresponding blocks of\ncoefficients. We provide conditions under which ELS and the CLP are avoided by\nthe new class of priors, and provide consistency results under traditional\nsample size asymptotics.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jun 2014 00:04:50 GMT"}, {"version": "v2", "created": "Tue, 13 Jan 2015 16:49:59 GMT"}], "update_date": "2015-01-14", "authors_parsed": [["Som", "Agniva", ""], ["Hans", "Christopher M.", ""], ["MacEachern", "Steven N.", ""]]}, {"id": "1406.6514", "submitter": "Danning Li", "authors": "Danning Li and Hui Zou", "title": "SURE Information Criteria for Large Covariance Matrix Estimation and\n  Their Asymptotic Properties", "comments": null, "journal-ref": null, "doi": "10.1109/TIT.2016.2530090", "report-no": null, "categories": "math.ST cs.IT math.IT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider $n$ independent and identically distributed $p$-dimensional Gaussian\nrandom vectors with covariance matrix $\\Sigma.$ The problem of estimating\n$\\Sigma$ when $p$ is much larger than $n$ has received a lot of attention in\nrecent years. Yet little is known about the information criterion for\ncovariance matrix estimation. How to properly define such a criterion and what\nare the statistical properties? We attempt to answer these questions in the\npresent paper by focusing on the estimation of bandable covariance matrices\nwhen $p>n$ but $\\log(p)=o(n)$. Motivated by the deep connection between Stein's\nunbiased risk estimation (SURE) and AIC in regression models, we propose a\nfamily of generalized SURE ($\\text{SURE}_c$) indexed by $c$ for covariance\nmatrix estimation, where $c$ is some constant. When $c$ is 2, $\\text{SURE}_2$\nprovides an unbiased estimator of the Frobenious risk of the covariance matrix\nestimator. Furthermore, we show that by minimizing $\\text{SURE}_2$ over all\npossible banding covariance matrix estimators we attain the minimax optimal\nrate of convergence and the resulting estimator behaves like the covariance\nmatrix estimator obtained by the so-called oracle tuning. On the other hand, we\nalso show that $\\text{SURE}_2$ is selection inconsistent when the true\ncovariance matrix is exactly banded. To fix the selection inconsistency, we\nconsider using SURE with $c=\\log(n)$ and prove that by minimizing\n$\\text{SURE}_{\\log(n)}$ we select the true bandwith with probability tending to\none. Therefore, our analysis indicates that $\\text{SURE}_2$ and\n$\\text{SURE}_{\\log(n)}$ can be regarded as the AIC and BIC for large covariance\nmatrix estimation, respectively.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jun 2014 10:04:00 GMT"}, {"version": "v2", "created": "Mon, 20 Oct 2014 23:14:08 GMT"}, {"version": "v3", "created": "Fri, 4 Mar 2016 12:07:51 GMT"}], "update_date": "2016-03-07", "authors_parsed": [["Li", "Danning", ""], ["Zou", "Hui", ""]]}, {"id": "1406.6519", "submitter": "Nirian Mart\\'in", "authors": "Abhik Ghosh, Abhijit Mandal, Nirian Martin, Leandro Pardo", "title": "Influence Analysis of Robust Wald-type Tests", "comments": "36 pages", "journal-ref": "Journal of Multivariate Analysis, 2016, 147, 102 - 126", "doi": "10.1016/j.jmva.2016.01.004", "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a robust version of the classical Wald test statistics for\ntesting simple and composite null hypotheses for general parametric models.\nThese test statistics are based on the minimum density power divergence\nestimators instead of the maximum likelihood estimators. An extensive study of\ntheir robustness properties is given though the influence functions as well as\nthe chi-square inflation factors. It is theoretically established that the\nlevel and power of these robust tests are stable against outliers, whereas the\nclassical Wald test breaks down. Some numerical examples confirm the validity\nof the theoretical results.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jun 2014 10:38:54 GMT"}, {"version": "v2", "created": "Wed, 5 Nov 2014 08:02:58 GMT"}, {"version": "v3", "created": "Fri, 5 Jun 2015 09:00:37 GMT"}, {"version": "v4", "created": "Mon, 16 Nov 2015 17:09:43 GMT"}], "update_date": "2016-07-04", "authors_parsed": [["Ghosh", "Abhik", ""], ["Mandal", "Abhijit", ""], ["Martin", "Nirian", ""], ["Pardo", "Leandro", ""]]}, {"id": "1406.6521", "submitter": "J. Martin van Zyl", "authors": "J.M. van Zyl", "title": "Exact expressions for the weights used in least-squares regression\n  estimation for the log-logistic and Weibull distribution", "comments": null, "journal-ref": "Communications in Statistics - Theory and Methods, 2017, 46(4),\n  pp. 1720-1730", "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimation for the log-logistic and Weibull distributions can be performed by\nusing the equations used for probability plotting. The equations leads to\nhighly heteroscedastic regression. Exact expressions for the variances of the\nresiduals are derived which can be used to perform weighted regression. In\nlarge samples maximum likelihood performs best, but it is shown that in smaller\nsamples the weighted regression outperforms maximum likelihood estimation with\nrespect to bias and mean square error.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jun 2014 10:56:52 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["van Zyl", "J. M.", ""]]}, {"id": "1406.6569", "submitter": "Jiang Hu", "authors": "Jiang Hu, Zhidong Bai, Chen Wang, Wei Wang", "title": "On testing the equality of high dimensional mean vectors with unequal\n  covariance matrices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we focus on the problem of testing the equality of several\nhigh dimensional mean vectors with unequal covariance matrices. This is one of\nthe most important problem in multivariate statistical analysis and there have\nbeen various tests proposed in the literature. Motivated by \\citet{BaiS96E} and\n\\cite{ChenQ10T}, a test statistic is introduced and the asymptomatic\ndistributions under the null hypothesis as well as the alternative hypothesis\nare given. In addition, it is compared with a test statistic recently proposed\nby \\cite{SrivastavaK13Ta}. It is shown that our test statistic performs much\nbetter especially in the large dimensional case.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jun 2014 13:52:00 GMT"}, {"version": "v2", "created": "Sun, 26 Apr 2015 13:09:54 GMT"}], "update_date": "2015-04-28", "authors_parsed": [["Hu", "Jiang", ""], ["Bai", "Zhidong", ""], ["Wang", "Chen", ""], ["Wang", "Wei", ""]]}, {"id": "1406.6592", "submitter": "Thibault Espinasse", "authors": "Thibault Espinasse (ICJ), Jean-Michel Loubes (IMT)", "title": "A Kriging procedure for processes indexed by graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a new kriging procedure of processes on graphs. Based on the\nconstruction of Gaussian random processes indexed by graphs, we extend to this\nframework the usual linear prediction method for spatial random fields, known\nas kriging. We provide the expression of the estimator of such a random field\nat unobserved locations as well as a control for the prediction error.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jun 2014 14:48:29 GMT"}], "update_date": "2014-06-26", "authors_parsed": [["Espinasse", "Thibault", "", "ICJ"], ["Loubes", "Jean-Michel", "", "IMT"]]}, {"id": "1406.6625", "submitter": "Jiaming Xu", "authors": "Bruce Hajek and Yihong Wu and Jiaming Xu", "title": "Computational Lower Bounds for Community Detection on Random Graphs", "comments": "28 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.CC stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the problem of detecting the presence of a small dense\ncommunity planted in a large Erd\\H{o}s-R\\'enyi random graph $\\mathcal{G}(N,q)$,\nwhere the edge probability within the community exceeds $q$ by a constant\nfactor. Assuming the hardness of the planted clique detection problem, we show\nthat the computational complexity of detecting the community exhibits the\nfollowing phase transition phenomenon: As the graph size $N$ grows and the\ngraph becomes sparser according to $q=N^{-\\alpha}$, there exists a critical\nvalue of $\\alpha = \\frac{2}{3}$, below which there exists a computationally\nintensive procedure that can detect far smaller communities than any\ncomputationally efficient procedure, and above which a linear-time procedure is\nstatistically optimal. The results also lead to the average-case hardness\nresults for recovering the dense community and approximating the densest\n$K$-subgraph.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jun 2014 16:15:36 GMT"}, {"version": "v2", "created": "Sun, 6 Jul 2014 21:19:16 GMT"}, {"version": "v3", "created": "Wed, 11 Mar 2015 20:21:00 GMT"}], "update_date": "2015-03-13", "authors_parsed": [["Hajek", "Bruce", ""], ["Wu", "Yihong", ""], ["Xu", "Jiaming", ""]]}, {"id": "1406.6638", "submitter": "Santosh Kumar", "authors": "Santosh Kumar", "title": "Eigenvalue statistics for the sum of two complex Wishart matrices", "comments": "Published version", "journal-ref": "Europhysics Letters, Volume 107, Page 60002, Year 2014", "doi": "10.1209/0295-5075/107/60002", "report-no": null, "categories": "math-ph math.MP math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The sum of independent Wishart matrices, taken from distributions with\nunequal covariance matrices, plays a crucial role in multivariate statistics,\nand has applications in the fields of quantitative finance and\ntelecommunication. However, analytical results concerning the corresponding\neigenvalue statistics have remained unavailable, even for the sum of two\nWishart matrices. This can be attributed to the complicated and rotationally\nnoninvariant nature of the matrix distribution that makes extracting the\ninformation about eigenvalues a nontrivial task. Using a generalization of the\nHarish-Chandra-Itzykson-Zuber integral, we find exact solution to this problem\nfor the complex Wishart case when one of the covariance matrices is\nproportional to the identity matrix, while the other is arbitrary. We derive\nexact and compact expressions for the joint probability density and marginal\ndensity of eigenvalues. The analytical results are compared with numerical\nsimulations and we find perfect agreement.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jun 2014 16:55:03 GMT"}, {"version": "v2", "created": "Mon, 22 Sep 2014 17:50:52 GMT"}], "update_date": "2014-09-23", "authors_parsed": [["Kumar", "Santosh", ""]]}, {"id": "1406.6668", "submitter": "Houman Owhadi", "authors": "Houman Owhadi", "title": "Bayesian Numerical Homogenization", "comments": "22 pages. To appear in SIAM Multiscale Modeling and Simulation", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Numerical homogenization, i.e. the finite-dimensional approximation of\nsolution spaces of PDEs with arbitrary rough coefficients, requires the\nidentification of accurate basis elements. These basis elements are oftentimes\nfound after a laborious process of scientific investigation and plain\nguesswork. Can this identification problem be facilitated? Is there a general\nrecipe/decision framework for guiding the design of basis elements? We suggest\nthat the answer to the above questions could be positive based on the\nreformulation of numerical homogenization as a Bayesian Inference problem in\nwhich a given PDE with rough coefficients (or multi-scale operator) is excited\nwith noise (random right hand side/source term) and one tries to estimate the\nvalue of the solution at a given point based on a finite number of\nobservations. We apply this reformulation to the identification of bases for\nthe numerical homogenization of arbitrary integro-differential equations and\nshow that these bases have optimal recovery properties. In particular we show\nhow Rough Polyharmonic Splines can be re-discovered as the optimal solution of\na Gaussian filtering problem.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jun 2014 19:06:56 GMT"}, {"version": "v2", "created": "Sat, 9 May 2015 23:05:34 GMT"}], "update_date": "2015-05-12", "authors_parsed": [["Owhadi", "Houman", ""]]}, {"id": "1406.6670", "submitter": "Eran Shmaya", "authors": "Nabil Al-Najjar and Eran Shmaya", "title": "Learning the ergodic decomposition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Bayesian agent learns about the structure of a stationary process from ob-\nserving past outcomes. We prove that his predictions about the near future\nbecome ap- proximately those he would have made if he knew the long run\nempirical frequencies of the process.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jun 2014 19:07:52 GMT"}], "update_date": "2014-06-26", "authors_parsed": [["Al-Najjar", "Nabil", ""], ["Shmaya", "Eran", ""]]}, {"id": "1406.6720", "submitter": "Seyed Mostafa Kia", "authors": "Seyed Mostafa Kia", "title": "Mass-Univariate Hypothesis Testing on MEEG Data using Cross-Validation", "comments": "Master thesis, July 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in statistical theory, together with advances in the\ncomputational power of computers, provide alternative methods to do\nmass-univariate hypothesis testing in which a large number of univariate tests,\ncan be properly used to compare MEEG data at a large number of time-frequency\npoints and scalp locations. One of the major problematic aspects of this kind\nof mass-univariate analysis is due to high number of accomplished hypothesis\ntests. Hence procedures that remove or alleviate the increased probability of\nfalse discoveries are crucial for this type of analysis. Here, I propose a new\nmethod for mass-univariate analysis of MEEG data based on cross-validation\nscheme. In this method, I suggest a hierarchical classification procedure under\nk-fold cross-validation to detect which sensors at which time-bin and which\nfrequency-bin contributes in discriminating between two different stimuli or\ntasks. To achieve this goal, a new feature extraction method based on the\ndiscrete cosine transform (DCT) employed to get maximum advantage of all three\ndata dimensions. Employing cross-validation and hierarchy architecture\nalongside the DCT feature space makes this method more reliable and at the same\ntime enough sensitive to detect the narrow effects in brain activities.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jun 2014 22:01:56 GMT"}], "update_date": "2014-06-27", "authors_parsed": [["Kia", "Seyed Mostafa", ""]]}, {"id": "1406.6751", "submitter": "Yusuke Shimizu", "authors": "Hiroki Masuda and Yusuke Shimizu", "title": "Moment convergence in regularized estimation under multiple and\n  mixed-rates asymptotics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In $M$-estimation under standard asymptotics, the weak convergence combined\nwith the polynomial type large deviation estimate of the associated statistical\nrandom field Yoshida (2011) provides us with not only the asymptotic\ndistribution of the associated $M$-estimator but also the convergence of its\nmoments, the latter playing an important role in theoretical statistics. In\nthis paper, we study the above program for statistical random fields of\nmultiple and also possibly mixed-rates type in the sense of Radchenko (2008)\nwhere the associated statistical random fields may be non-differentiable and\nmay fail to be locally asymptotically quadratic. Consequently, a very strong\nmode of convergence of a wide range of regularized $M$-estimators is ensured.\nThe results are applied to regularized estimation of an ergodic diffusion\nobserved at high frequency.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jun 2014 02:39:46 GMT"}, {"version": "v2", "created": "Thu, 9 Oct 2014 10:19:15 GMT"}, {"version": "v3", "created": "Sat, 27 Aug 2016 01:37:48 GMT"}, {"version": "v4", "created": "Sat, 24 Sep 2016 03:54:16 GMT"}, {"version": "v5", "created": "Sun, 16 Apr 2017 11:42:07 GMT"}], "update_date": "2017-04-18", "authors_parsed": [["Masuda", "Hiroki", ""], ["Shimizu", "Yusuke", ""]]}, {"id": "1406.6766", "submitter": "Robin Evans", "authors": "Robin J. Evans", "title": "Smoothness of marginal log-linear parameterizations", "comments": "19 pages", "journal-ref": "Electronic Journal of Statistics, Volume 9, Number 1 (2015),\n  475-491", "doi": "10.1214/15-EJS1009", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide results demonstrating the smoothness of some marginal log-linear\nparameterizations for distributions on multi-way contingency tables. First we\ngive an analytical relationship between log-linear parameters defined within\ndifferent margins, and use this to prove that some parameterizations are\nequivalent to ones already known to be smooth. Second we construct an iterative\nmethod for recovering joint probability distributions from marginal log-linear\npieces, and prove its correctness in particular cases. Finally we use Markov\nchain theory to prove that certain cyclic conditional parameterizations are\nalso smooth. These results are applied to show that certain conditional\nindependence models are curved exponential families.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jun 2014 04:27:58 GMT"}, {"version": "v2", "created": "Mon, 23 Feb 2015 15:16:54 GMT"}], "update_date": "2016-08-12", "authors_parsed": [["Evans", "Robin J.", ""]]}, {"id": "1406.6897", "submitter": "Jiaming Xu", "authors": "Jiaming Xu and Laurent Massouli\\'e and Marc Lelarge", "title": "Edge Label Inference in Generalized Stochastic Block Models: from\n  Spectral Theory to Impossibility Results", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The classical setting of community detection consists of networks exhibiting\na clustered structure. To more accurately model real systems we consider a\nclass of networks (i) whose edges may carry labels and (ii) which may lack a\nclustered structure. Specifically we assume that nodes possess latent\nattributes drawn from a general compact space and edges between two nodes are\nrandomly generated and labeled according to some unknown distribution as a\nfunction of their latent attributes. Our goal is then to infer the edge label\ndistributions from a partially observed network. We propose a computationally\nefficient spectral algorithm and show it allows for asymptotically correct\ninference when the average node degree could be as low as logarithmic in the\ntotal number of nodes. Conversely, if the average node degree is below a\nspecific constant threshold, we show that no algorithm can achieve better\ninference than guessing without using the observations. As a byproduct of our\nanalysis, we show that our model provides a general procedure to construct\nrandom graph models with a spectrum asymptotic to a pre-specified eigenvalue\ndistribution such as a power-law distribution.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jun 2014 14:22:54 GMT"}], "update_date": "2014-06-27", "authors_parsed": [["Xu", "Jiaming", ""], ["Massouli\u00e9", "Laurent", ""], ["Lelarge", "Marc", ""]]}, {"id": "1406.6956", "submitter": "Jiantao Jiao", "authors": "Jiantao Jiao, Kartik Venkat, Yanjun Han, Tsachy Weissman", "title": "Minimax Estimation of Functionals of Discrete Distributions", "comments": "To appear in IEEE Transactions on Information Theory", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a general methodology for the construction and analysis of minimax\nestimators for a wide class of functionals of finite dimensional parameters,\nand elaborate on the case of discrete distributions, where the alphabet size\n$S$ is unknown and may be comparable with the number of observations $n$. We\ntreat the respective regions where the functional is \"nonsmooth\" and \"smooth\"\nseparately. In the \"nonsmooth\" regime, we apply an unbiased estimator for the\nbest polynomial approximation of the functional whereas, in the \"smooth\"\nregime, we apply a bias-corrected Maximum Likelihood Estimator (MLE). We\nillustrate the merit of this approach by thoroughly analyzing two important\ncases: the entropy $H(P) = \\sum_{i = 1}^S -p_i \\ln p_i$ and $F_\\alpha(P) =\n\\sum_{i = 1}^S p_i^\\alpha,\\alpha>0$. We obtain the minimax $L_2$ rates for\nestimating these functionals. In particular, we demonstrate that our estimator\nachieves the optimal sample complexity $n \\asymp S/\\ln S$ for entropy\nestimation. We also show that the sample complexity for estimating\n$F_\\alpha(P),0<\\alpha<1$ is $n\\asymp S^{1/\\alpha}/ \\ln S$, which can be\nachieved by our estimator but not the MLE. For $1<\\alpha<3/2$, we show the\nminimax $L_2$ rate for estimating $F_\\alpha(P)$ is $(n\\ln n)^{-2(\\alpha-1)}$\nregardless of the alphabet size, while the $L_2$ rate for the MLE is\n$n^{-2(\\alpha-1)}$. For all the above cases, the behavior of the minimax\nrate-optimal estimators with $n$ samples is essentially that of the MLE with\n$n\\ln n$ samples. We highlight the practical advantages of our schemes for\nentropy and mutual information estimation. We demonstrate that our approach\nreduces running time and boosts the accuracy compared to existing various\napproaches. Moreover, we show that the mutual information estimator induced by\nour methodology leads to significant performance boosts over the Chow--Liu\nalgorithm in learning graphical models.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jun 2014 17:50:40 GMT"}, {"version": "v2", "created": "Fri, 27 Jun 2014 16:30:15 GMT"}, {"version": "v3", "created": "Thu, 28 Aug 2014 18:20:38 GMT"}, {"version": "v4", "created": "Sat, 7 Feb 2015 07:03:52 GMT"}, {"version": "v5", "created": "Tue, 10 Mar 2015 07:05:20 GMT"}], "update_date": "2015-03-11", "authors_parsed": [["Jiao", "Jiantao", ""], ["Venkat", "Kartik", ""], ["Han", "Yanjun", ""], ["Weissman", "Tsachy", ""]]}, {"id": "1406.6959", "submitter": "Jiantao Jiao", "authors": "Jiantao Jiao, Kartik Venkat, Yanjun Han, Tsachy Weissman", "title": "Maximum Likelihood Estimation of Functionals of Discrete Distributions", "comments": "27 pages, 1 figure, published in IEEE Transactions on Information\n  Theory", "journal-ref": null, "doi": "10.1109/TIT.2017.2733537", "report-no": null, "categories": "cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of estimating functionals of discrete distributions,\nand focus on tight nonasymptotic analysis of the worst case squared error risk\nof widely used estimators. We apply concentration inequalities to analyze the\nrandom fluctuation of these estimators around their expectations, and the\ntheory of approximation using positive linear operators to analyze the\ndeviation of their expectations from the true functional, namely their\n\\emph{bias}.\n  We characterize the worst case squared error risk incurred by the Maximum\nLikelihood Estimator (MLE) in estimating the Shannon entropy $H(P) = \\sum_{i =\n1}^S -p_i \\ln p_i$, and $F_\\alpha(P) = \\sum_{i = 1}^S p_i^\\alpha,\\alpha>0$, up\nto multiplicative constants, for any alphabet size $S\\leq \\infty$ and sample\nsize $n$ for which the risk may vanish. As a corollary, for Shannon entropy\nestimation, we show that it is necessary and sufficient to have $n \\gg S$\nobservations for the MLE to be consistent. In addition, we establish that it is\nnecessary and sufficient to consider $n \\gg S^{1/\\alpha}$ samples for the MLE\nto consistently estimate $F_\\alpha(P), 0<\\alpha<1$. The minimax rate-optimal\nestimators for both problems require $S/\\ln S$ and $S^{1/\\alpha}/\\ln S$\nsamples, which implies that the MLE has a strictly sub-optimal sample\ncomplexity. When $1<\\alpha<3/2$, we show that the worst-case squared error rate\nof convergence for the MLE is $n^{-2(\\alpha-1)}$ for infinite alphabet size,\nwhile the minimax squared error rate is $(n\\ln n)^{-2(\\alpha-1)}$. When\n$\\alpha\\geq 3/2$, the MLE achieves the minimax optimal rate $n^{-1}$ regardless\nof the alphabet size.\n  As an application of the general theory, we analyze the Dirichlet prior\nsmoothing techniques for Shannon entropy estimation. We show that no matter how\nwe tune the parameters in the Dirichlet prior, this technique cannot achieve\nthe minimax rates in entropy estimation.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jun 2014 17:53:58 GMT"}, {"version": "v2", "created": "Tue, 12 Aug 2014 02:49:27 GMT"}, {"version": "v3", "created": "Fri, 28 Nov 2014 23:10:34 GMT"}, {"version": "v4", "created": "Sun, 22 Feb 2015 19:15:47 GMT"}, {"version": "v5", "created": "Tue, 30 May 2017 04:13:23 GMT"}, {"version": "v6", "created": "Wed, 5 Jul 2017 17:53:18 GMT"}, {"version": "v7", "created": "Thu, 10 Aug 2017 02:13:15 GMT"}], "update_date": "2017-08-11", "authors_parsed": [["Jiao", "Jiantao", ""], ["Venkat", "Kartik", ""], ["Han", "Yanjun", ""], ["Weissman", "Tsachy", ""]]}, {"id": "1406.7114", "submitter": "Viacheslav Saenko", "authors": "Viacheslav Saenko and Yurij Saenko", "title": "Application of the fractional stable distributions for approximation of\n  gene expression profiles", "comments": null, "journal-ref": "Stat. Appl. Genet. Mol. Biol. 2015; 14(3): 295--306", "doi": "10.1515/sagmb-2014-0094", "report-no": null, "categories": "math.ST q-bio.GN stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  At the present time reliably established that probability density functions\nof gene expression of microarray experiments possess a number of universal\nproperties. First of all these distributions have power asymptotic and secondly\nthe shape of these distributions are inherent for all organisms and tissues.\nThis fact led to appearance of a number works where authors are investigating\nvarious probability distributions for approximation of empirical distributions\nof gene expression. Nevertheless all these distributions aren't limit\ndistribution and aren't solution of any equations. These facts by our opinion\nare essential shortcoming of these probability laws. Besides, expression of\nindividual gene aren't accidental event and it depends from expression other\ngenes. This allows to talk about existence of genic regulatory net in the cell.\nIn the work the class of fractional stable distributions (FSD) are described.\nThis class of distributions is limit distribution of sum independent identical\ndistributed random variables. These distributions have power-law asymptotic and\nthis fact allow us to apply their for approximation of experimental densities\ngene expression of microarray experiments. The parameters of FSDs are\nstatistically estimated by experimental dates and empirical density is compared\nwhit theoretical density. In the work the algorithms of parameters estimation\nand simulating of FSD variables are presented. The results of such comparison\nallow to make conclusion that empirical densities of gene expression can be\napproximate by FSD.\n", "versions": [{"version": "v1", "created": "Fri, 27 Jun 2014 08:56:57 GMT"}], "update_date": "2015-06-08", "authors_parsed": [["Saenko", "Viacheslav", ""], ["Saenko", "Yurij", ""]]}, {"id": "1406.7173", "submitter": "Wilfrid Kendall", "authors": "Wilfrid S. Kendall", "title": "Barycentres and Hurricane Trajectories", "comments": "19 pages, 7 figures. Contribution to Mardia festschrift \"Geometry\n  Driven Statistics\". Version 2: added further reference to HURDAT2 data\n  format. Version 3: various minor corrections, and added dedication to Mardia", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of barycentres in data analysis is illustrated, using as example a\ndataset of hurricane trajectories.\n", "versions": [{"version": "v1", "created": "Fri, 27 Jun 2014 13:11:20 GMT"}, {"version": "v2", "created": "Mon, 7 Jul 2014 13:49:12 GMT"}, {"version": "v3", "created": "Sat, 18 Oct 2014 12:48:15 GMT"}], "update_date": "2014-10-21", "authors_parsed": [["Kendall", "Wilfrid S.", ""]]}, {"id": "1406.7698", "submitter": "Dave Zachariah", "authors": "Petre Stoica, Dave Zachariah, Jian Li", "title": "Weighted SPICE: A Unifying Approach for Hyperparameter-Free Sparse\n  Estimation", "comments": null, "journal-ref": "Digital Signal Processing, Volume 33, October 2014, pages 1-12", "doi": "10.1016/j.dsp.2014.06.010", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present the SPICE approach for sparse parameter estimation\nin a framework that unifies it with other hyperparameter-free methods, namely\nLIKES, SLIM and IAA. Specifically, we show how the latter methods can be\ninterpreted as variants of an adaptively reweighted SPICE method. Furthermore,\nwe establish a connection between SPICE and the l1-penalized LAD estimator as\nwell as the square-root LASSO method. We evaluate the four methods mentioned\nabove in a generic sparse regression problem and in an array processing\napplication.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jun 2014 12:34:07 GMT"}], "update_date": "2015-05-12", "authors_parsed": [["Stoica", "Petre", ""], ["Zachariah", "Dave", ""], ["Li", "Jian", ""]]}, {"id": "1406.7711", "submitter": "Henryk Z\\\"ahle", "authors": "Henryk Z\\\"ahle", "title": "A definition of qualitative robustness for general point estimators, and\n  examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  A definition of qualitative robustness for point estimators in general\nstatistical models is proposed. Some criteria for robustness are established\nand applied to estimators in parametric, semiparametric, and nonparametric\nmodels. In specific nonparametric models, the proposed definition boils down to\nHampel robustness. It is also explained how plug-in estimators in certain\nnonparametric models can be reasonably classified w.r.t. their degrees of\nrobustness.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jun 2014 12:59:26 GMT"}, {"version": "v2", "created": "Fri, 5 Jun 2015 14:52:59 GMT"}, {"version": "v3", "created": "Wed, 17 Jun 2015 15:44:50 GMT"}], "update_date": "2015-06-18", "authors_parsed": [["Z\u00e4hle", "Henryk", ""]]}, {"id": "1406.7718", "submitter": "Ryan Martin", "authors": "Ryan Martin, Raymond Mess and Stephen G. Walker", "title": "Empirical Bayes posterior concentration in sparse high-dimensional\n  linear models", "comments": "24 pages, 3 tables, and 3 extra pages to correct a couple minor\n  mistakes in the published version", "journal-ref": "Bernoulli, 2017, volume 23, number 3, pages 1822--1847", "doi": "10.3150/15-BEJ797", "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new empirical Bayes approach for inference in the $p \\gg n$\nnormal linear model. The novelty is the use of data in the prior in two ways,\nfor centering and regularization. Under suitable sparsity assumptions, we\nestablish a variety of concentration rate results for the empirical Bayes\nposterior distribution, relevant for both estimation and model selection.\nComputation is straightforward and fast, and simulation results demonstrate the\nstrong finite-sample performance of the empirical Bayes model selection\nprocedure.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jun 2014 13:11:37 GMT"}, {"version": "v2", "created": "Tue, 16 Dec 2014 19:46:21 GMT"}, {"version": "v3", "created": "Wed, 9 Sep 2015 17:16:00 GMT"}, {"version": "v4", "created": "Fri, 8 Sep 2017 13:21:49 GMT"}, {"version": "v5", "created": "Wed, 5 Dec 2018 18:26:51 GMT"}], "update_date": "2018-12-06", "authors_parsed": [["Martin", "Ryan", ""], ["Mess", "Raymond", ""], ["Walker", "Stephen G.", ""]]}, {"id": "1406.7728", "submitter": "Yuan Yao", "authors": "Stanley Osher and Feng Ruan and Jiechao Xiong and Yuan Yao and Wotao\n  Yin", "title": "Sparse Recovery via Differential Inclusions", "comments": "In Applied and Computational Harmonic Analysis, 2016", "journal-ref": null, "doi": "10.1016/j.acha.2016.01.002", "report-no": "CAM Report 14-61", "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we recover sparse signals from their noisy linear measurements\nby solving nonlinear differential inclusions, which is based on the notion of\ninverse scale space (ISS) developed in applied mathematics. Our goal here is to\nbring this idea to address a challenging problem in statistics, \\emph{i.e.}\nfinding the oracle estimator which is unbiased and sign-consistent using\ndynamics. We call our dynamics \\emph{Bregman ISS} and \\emph{Linearized Bregman\nISS}. A well-known shortcoming of LASSO and any convex regularization\napproaches lies in the bias of estimators. However, we show that under proper\nconditions, there exists a bias-free and sign-consistent point on the solution\npaths of such dynamics, which corresponds to a signal that is the unbiased\nestimate of the true signal and whose entries have the same signs as those of\nthe true signs, \\emph{i.e.} the oracle estimator. Therefore, their solution\npaths are regularization paths better than the LASSO regularization path, since\nthe points on the latter path are biased when sign-consistency is reached. We\nalso show how to efficiently compute their solution paths in both continuous\nand discretized settings: the full solution paths can be exactly computed piece\nby piece, and a discretization leads to \\emph{Linearized Bregman iteration},\nwhich is a simple iterative thresholding rule and easy to parallelize.\nTheoretical guarantees such as sign-consistency and minimax optimal $l_2$-error\nbounds are established in both continuous and discrete settings for specific\npoints on the paths. Early-stopping rules for identifying these points are\ngiven. The key treatment relies on the development of differential inequalities\nfor differential inclusions and their discretizations, which extends the\nprevious results and leads to exponentially fast recovering of sparse signals\nbefore selecting wrong ones.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jun 2014 13:30:15 GMT"}, {"version": "v2", "created": "Tue, 1 Jul 2014 01:42:32 GMT"}, {"version": "v3", "created": "Thu, 31 Jul 2014 05:11:00 GMT"}, {"version": "v4", "created": "Fri, 1 Aug 2014 02:10:11 GMT"}, {"version": "v5", "created": "Thu, 21 Jan 2016 18:27:34 GMT"}], "update_date": "2016-01-22", "authors_parsed": [["Osher", "Stanley", ""], ["Ruan", "Feng", ""], ["Xiong", "Jiechao", ""], ["Yao", "Yuan", ""], ["Yin", "Wotao", ""]]}, {"id": "1406.7773", "submitter": "Akimichi Takemura", "authors": "Masayuki Kumon, Akimichi Takemura, Kei Takeuchi", "title": "Conformal Geometry of Sequential Test in Multidimensional Curved\n  Exponential Family", "comments": null, "journal-ref": "Sequential Analysis 35 (2016) 30-68", "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article presents a differential geometrical method for analyzing\nsequential test procedures. It is based on the primal result on the conformal\ngeometry of statistical manifold developed in Kumon, Takemura and Takeuchi\n(2011). By introducing curvature-type random variables, the condition is first\nclarified for a statistical manifold to be an exponential family under an\nappropriate sequential test procedure. This result is further elaborated for\ninvestigating the efficient sequential test in a multidimensional curved\nexponential family. The theoretical results are numerically examined by using\nvon Mises-Fisher and hyperboloid models.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jun 2014 15:19:16 GMT"}], "update_date": "2016-05-02", "authors_parsed": [["Kumon", "Masayuki", ""], ["Takemura", "Akimichi", ""], ["Takeuchi", "Kei", ""]]}]