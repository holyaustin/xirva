[{"id": "0903.0022", "submitter": "Lajos Horvath", "authors": "Istvan Berkes, Lajos Horvath, Shiqing Ling", "title": "Estimation in nonstationary random coefficient autoregressive models", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the estimation of parameters in the random coefficient\nautoregressive model. We consider a nonstationary RCA process and show that the\ninnovation variance parameter cannot be estimated by the quasi-maximum\nlikelihood method. The asymptotic normality of the quasi-maximum likelihood\nestimator for the remaining model parameters is proven so the unit root problem\ndoes not exist in the random coefficient autoregressive model.\n", "versions": [{"version": "v1", "created": "Fri, 27 Feb 2009 23:33:37 GMT"}], "update_date": "2009-03-03", "authors_parsed": [["Berkes", "Istvan", ""], ["Horvath", "Lajos", ""], ["Ling", "Shiqing", ""]]}, {"id": "0903.0226", "submitter": "Yacine A\\\"{\\i}t-Sahalia", "authors": "Yacine A\\\"it-Sahalia, Jean Jacod", "title": "Testing for jumps in a discretely observed process", "comments": "Published in at http://dx.doi.org/10.1214/07-AOS568 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2009, Vol. 37, No. 1, 184-222", "doi": "10.1214/07-AOS568", "report-no": "IMS-AOS-AOS568", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new test to determine whether jumps are present in asset returns\nor other discretely sampled processes. As the sampling interval tends to 0, our\ntest statistic converges to 1 if there are jumps, and to another deterministic\nand known value (such as 2) if there are no jumps. The test is valid for all\nIt\\^{o} semimartingales, depends neither on the law of the process nor on the\ncoefficients of the equation which it solves, does not require a preliminary\nestimation of these coefficients, and when there are jumps the test is\napplicable whether jumps have finite or infinite-activity and for an arbitrary\nBlumenthal--Getoor index. We finally implement the test on simulations and\nasset returns data.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2009 08:05:45 GMT"}], "update_date": "2009-03-03", "authors_parsed": [["A\u00eft-Sahalia", "Yacine", ""], ["Jacod", "Jean", ""]]}, {"id": "0903.0290", "submitter": "Omiros Papaspiliopoulos", "authors": "Alexandros Beskos, Omiros Papaspiliopoulos, Gareth Roberts", "title": "Monte Carlo maximum likelihood estimation for discretely observed\n  diffusion processes", "comments": "Published in at http://dx.doi.org/10.1214/07-AOS550 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2009, Vol. 37, No. 1, 223-245", "doi": "10.1214/07-AOS550", "report-no": "IMS-AOS-AOS550", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a Monte Carlo method for maximum likelihood inference\nin the context of discretely observed diffusion processes. The method gives\nunbiased and a.s.\\@ continuous estimators of the likelihood function for a\nfamily of diffusion models and its performance in numerical examples is\ncomputationally efficient. It uses a recently developed technique for the exact\nsimulation of diffusions, and involves no discretization error. We show that,\nunder regularity conditions, the Monte Carlo MLE converges a.s. to the true\nMLE. For datasize $n\\to\\infty$, we show that the number of Monte Carlo\niterations should be tuned as $\\mathcal{O}(n^{1/2})$ and we demonstrate the\nconsistency properties of the Monte Carlo MLE as an estimator of the true\nparameter value.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2009 13:25:15 GMT"}], "update_date": "2009-03-03", "authors_parsed": [["Beskos", "Alexandros", ""], ["Papaspiliopoulos", "Omiros", ""], ["Roberts", "Gareth", ""]]}, {"id": "0903.0447", "submitter": "Stefan Van Aelst", "authors": "Fatemah Alqallaf, Stefan Van Aelst, Victor J. Yohai, Ruben H. Zamar", "title": "Propagation of outliers in multivariate data", "comments": "Published in at http://dx.doi.org/10.1214/07-AOS588 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2009, Vol. 37, No. 1, 311-331", "doi": "10.1214/07-AOS588", "report-no": "IMS-AOS-AOS588", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the performance of robust estimates of multivariate location\nunder nonstandard data contamination models such as componentwise outliers\n(i.e., contamination in each variable is independent from the other variables).\nThis model brings up a possible new source of statistical error that we call\n\"propagation of outliers.\" This source of error is unusual in the sense that it\nis generated by the data processing itself and takes place after the data has\nbeen collected. We define and derive the influence function of robust\nmultivariate location estimates under flexible contamination models and use it\nto investigate the effect of propagation of outliers. Furthermore, we show that\nstandard high-breakdown affine equivariant estimators propagate outliers and\ntherefore show poor breakdown behavior under componentwise contamination when\nthe dimension $d$ is high.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2009 07:00:41 GMT"}], "update_date": "2009-03-04", "authors_parsed": [["Alqallaf", "Fatemah", ""], ["Van Aelst", "Stefan", ""], ["Yohai", "Victor J.", ""], ["Zamar", "Ruben H.", ""]]}, {"id": "0903.0464", "submitter": "Sandy Clarke", "authors": "Sandy Clarke, Peter Hall", "title": "Robustness of multiple testing procedures against dependence", "comments": "Published in at http://dx.doi.org/10.1214/07-AOS557 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2009, Vol. 37, No. 1, 332-358", "doi": "10.1214/07-AOS557", "report-no": "IMS-AOS-AOS557", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important aspect of multiple hypothesis testing is controlling the\nsignificance level, or the level of Type I error. When the test statistics are\nnot independent it can be particularly challenging to deal with this problem,\nwithout resorting to very conservative procedures. In this paper we show that,\nin the context of contemporary multiple testing problems, where the number of\ntests is often very large, the difficulties caused by dependence are less\nserious than in classical cases. This is particularly true when the null\ndistributions of test statistics are relatively light-tailed, for example, when\nthey can be based on Normal or Student's $t$ approximations. There, if the test\nstatistics can fairly be viewed as being generated by a linear process, an\nanalysis founded on the incorrect assumption of independence is asymptotically\ncorrect as the number of hypotheses diverges. In particular, the point process\nrepresenting the null distribution of the indices at which statistically\nsignificant test results occur is approximately Poisson, just as in the case of\nindependence. The Poisson process also has the same mean as in the independence\ncase, and of course exhibits no clustering of false discoveries. However, this\nresult can fail if the null distributions are particularly heavy-tailed. There\nclusters of statistically significant results can occur, even when the null\nhypothesis is correct. We give an intuitive explanation for these disparate\nproperties in light- and heavy-tailed cases, and provide rigorous theory\nunderpinning the intuition.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2009 08:32:55 GMT"}], "update_date": "2009-03-04", "authors_parsed": [["Clarke", "Sandy", ""], ["Hall", "Peter", ""]]}, {"id": "0903.0474", "submitter": "Daniel J. Nordman", "authors": "Daniel J. Nordman", "title": "A note on the stationary bootstrap's variance", "comments": "Published in at http://dx.doi.org/10.1214/07-AOS567 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2009, Vol. 37, No. 1, 359-370", "doi": "10.1214/07-AOS567", "report-no": "IMS-AOS-AOS567", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Because the stationary bootstrap resamples data blocks of random length, this\nmethod has been thought to have the largest asymptotic variance among block\nbootstraps Lahiri [Ann. Statist. 27 (1999) 386--404]. It is shown here that the\nvariance of the stationary bootstrap surprisingly matches that of a block\nbootstrap based on nonrandom, nonoverlapping blocks. This argument translates\nthe variance expansion into the frequency domain and provides a unified way of\ndetermining variances for other block bootstraps. Some previous results on the\nstationary bootstrap, related to asymptotic relative efficiency and optimal\nblock size, are also updated.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2009 09:30:06 GMT"}], "update_date": "2009-03-04", "authors_parsed": [["Nordman", "Daniel J.", ""]]}, {"id": "0903.0487", "submitter": "Yanqing Sun", "authors": "Yanqing Sun, Peter B. Gilbert, Ian W. McKeague", "title": "Proportional hazards models with continuous marks", "comments": "Published in at http://dx.doi.org/10.1214/07-AOS554 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2009, Vol. 37, No. 1, 394-426", "doi": "10.1214/07-AOS554", "report-no": "IMS-AOS-AOS554", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For time-to-event data with finitely many competing risks, the proportional\nhazards model has been a popular tool for relating the cause-specific outcomes\nto covariates [Prentice et al. Biometrics 34 (1978) 541--554]. This article\nstudies an extension of this approach to allow a continuum of competing risks,\nin which the cause of failure is replaced by a continuous mark only observed at\nthe failure time. We develop inference for the proportional hazards model in\nwhich the regression parameters depend nonparametrically on the mark and the\nbaseline hazard depends nonparametrically on both time and mark. This work is\nmotivated by the need to assess HIV vaccine efficacy, while taking into account\nthe genetic divergence of infecting HIV viruses in trial participants from the\nHIV strain that is contained in the vaccine, and adjusting for covariate\neffects. Mark-specific vaccine efficacy is expressed in terms of one of the\nregression functions in the mark-specific proportional hazards model. The new\napproach is evaluated in simulations and applied to the first HIV vaccine\nefficacy trial.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2009 10:44:17 GMT"}], "update_date": "2009-03-04", "authors_parsed": [["Sun", "Yanqing", ""], ["Gilbert", "Peter B.", ""], ["McKeague", "Ian W.", ""]]}, {"id": "0903.0499", "submitter": "Hua Liang", "authors": "Yong Zhou, Hua Liang", "title": "Statistical inference for semiparametric varying-coefficient partially\n  linear models with error-prone linear covariates", "comments": "Published in at http://dx.doi.org/10.1214/07-AOS561 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2009, Vol. 37, No. 1, 427-458", "doi": "10.1214/07-AOS561", "report-no": "IMS-AOS-AOS561", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study semiparametric varying-coefficient partially linear models when some\nlinear covariates are not observed, but ancillary variables are available.\nSemiparametric profile least-square based estimation procedures are developed\nfor parametric and nonparametric components after we calibrate the error-prone\ncovariates. Asymptotic properties of the proposed estimators are established.\nWe also propose the profile least-square based ratio test and Wald test to\nidentify significant parametric and nonparametric components. To improve\naccuracy of the proposed tests for small or moderate sample sizes, a wild\nbootstrap version is also proposed to calculate the critical values. Intensive\nsimulation experiments are conducted to illustrate the proposed approaches.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2009 11:38:07 GMT"}], "update_date": "2009-03-04", "authors_parsed": [["Zhou", "Yong", ""], ["Liang", "Hua", ""]]}, {"id": "0903.0623", "submitter": "Shui Feng", "authors": "Shui Feng and Wei Sun", "title": "Some Diffusion Processes Associated With Two Parameter Poisson-Dirichlet\n  Distribution and Dirichlet Process", "comments": "24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The two parameter Poisson-Dirichlet distribution $PD(\\alpha,\\theta)$ is the\ndistribution of an infinite dimensional random discrete probability. It is a\ngeneralization of Kingman's Poisson-Dirichlet distribution. The two parameter\nDirichlet process $\\Pi_{\\alpha,\\theta,\\nu_0}$ is the law of a pure atomic\nrandom measure with masses following the two parameter Poisson-Dirichlet\ndistribution. In this article we focus on the construction and the properties\nof the infinite dimensional symmetric diffusion processes with respective\nsymmetric measures $PD(\\alpha,\\theta)$ and $\\Pi_{\\alpha,\\theta,\\nu_0}$. The\nmethods used come from the theory of Dirichlet forms.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2009 21:14:25 GMT"}, {"version": "v2", "created": "Sun, 22 Mar 2009 01:16:47 GMT"}], "update_date": "2009-03-22", "authors_parsed": [["Feng", "Shui", ""], ["Sun", "Wei", ""]]}, {"id": "0903.0702", "submitter": "Gerhard Osius", "authors": "Gerhard Osius", "title": "Asymptotic inference for semiparametric association models", "comments": "Published in at http://dx.doi.org/10.1214/07-AOS572 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2009, Vol. 37, No. 1, 459-489", "doi": "10.1214/07-AOS572", "report-no": "IMS-AOS-AOS572", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Association models for a pair of random elements $X$ and $Y$ (e.g., vectors)\nare considered which specify the odds ratio function up to an unknown parameter\n$\\bolds\\theta$. These models are shown to be semiparametric in the sense that\nthey do not restrict the marginal distributions of $X$ and $Y$. Inference for\nthe odds ratio parameter $\\bolds\\theta$ may be obtained from sampling either\n$Y$ conditionally on $X$ or vice versa. Generalizing results from Prentice and\nPyke, Weinberg and Wacholder and Scott and Wild, we show that asymptotic\ninference for $\\bolds\\theta$ under sampling conditional on $Y$ is the same as\nif sampling had been conditional on $X$. Common regression models, for example,\ngeneralized linear models with canonical link or multivariate linear,\nrespectively, logistic models, are association models where the regression\nparameter $\\bolds\\beta$ is closely related to the odds ratio parameter\n$\\bolds\\theta$. Hence inference for $\\bolds\\beta$ may be drawn from samples\nconditional on $Y$ using an association model.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2009 07:10:06 GMT"}], "update_date": "2009-03-05", "authors_parsed": [["Osius", "Gerhard", ""]]}, {"id": "0903.0726", "submitter": "Song Xi Chen", "authors": "Dong Wang, Song Xi Chen", "title": "Empirical likelihood for estimating equations with missing values", "comments": "Published in at http://dx.doi.org/10.1214/07-AOS585 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2009, Vol. 37, No. 1, 490-517", "doi": "10.1214/07-AOS585", "report-no": "IMS-AOS-AOS585", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider an empirical likelihood inference for parameters defined by\ngeneral estimating equations when some components of the random observations\nare subject to missingness. As the nature of the estimating equations is\nwide-ranging, we propose a nonparametric imputation of the missing values from\na kernel estimator of the conditional distribution of the missing variable\ngiven the always observable variable. The empirical likelihood is used to\nconstruct a profile likelihood for the parameter of interest. We demonstrate\nthat the proposed nonparametric imputation can remove the selection bias in the\nmissingness and the empirical likelihood leads to more efficient parameter\nestimation. The proposed method is further evaluated by simulation and an\nempirical study on a genetic dataset on recombinant inbred mice.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2009 10:42:57 GMT"}], "update_date": "2009-03-05", "authors_parsed": [["Wang", "Dong", ""], ["Chen", "Song Xi", ""]]}, {"id": "0903.0728", "submitter": "John Stufken", "authors": "Min Yang, John Stufken", "title": "Support points of locally optimal designs for nonlinear models with two\n  parameters", "comments": "Published in at http://dx.doi.org/10.1214/07-AOS560 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2009, Vol. 37, No. 1, 518-541", "doi": "10.1214/07-AOS560", "report-no": "IMS-AOS-AOS560", "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new approach for identifying the support points of a locally\noptimal design when the model is a nonlinear model. In contrast to the commonly\nused geometric approach, we use an approach based on algebraic tools.\nConsiderations are restricted to models with two parameters, and the general\nresults are applied to often used special cases, including logistic, probit,\ndouble exponential and double reciprocal models for binary data, a loglinear\nPoisson regression model for count data, and the Michaelis--Menten model. The\napproach, which is also of value for multi-stage experiments, works both with\nconstrained and unconstrained design regions and is relatively easy to\nimplement.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2009 10:59:35 GMT"}], "update_date": "2009-03-05", "authors_parsed": [["Yang", "Min", ""], ["Stufken", "John", ""]]}, {"id": "0903.0913", "submitter": "Anatoli Iouditski", "authors": "Anatoli Iouditski (LJK), Arkadii S. Nemirovski (ISyE)", "title": "Nonparametric denoising Signals of Unknown Local Structure, II:\n  Nonparametric Regression Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of recovering of continuous multi-dimensional\nfunctions from the noisy observations over the regular grid. Our focus is at\nthe adaptive estimation in the case when the function can be well recovered\nusing a linear filter, which can depend on the unknown function itself. In the\ncompanion paper \"Nonparametric Denoising of Signals with Unknown Local\nStructure, I: Oracle Inequalities\" we have shown in the case when there exists\nan adapted time-invariant filter, which locally recovers \"well\" the unknown\nsignal, there is a numerically efficient construction of an adaptive filter\nwhich recovers the signals \"almost as well\". In the current paper we study the\napplication of the proposed estimation techniques in the non-parametric\nregression setting. Namely, we propose an adaptive estimation procedure for\n\"locally well-filtered\" signals (some typical examples being smooth signals,\nmodulated smooth signals and harmonic functions) and show that the rate of\nrecovery of such signals in the $\\ell_p$-norm on the grid is essentially the\nsame as that rate for regular signals with nonhomogeneous smoothness.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2009 05:35:38 GMT"}], "update_date": "2009-03-06", "authors_parsed": [["Iouditski", "Anatoli", "", "LJK"], ["Nemirovski", "Arkadii S.", "", "ISyE"]]}, {"id": "0903.0959", "submitter": "Adam Bzowski", "authors": "Adam Bzowski, Michal K. Urbanski", "title": "Convergence, Strong Law of Large Numbers, and Measurement Theory in the\n  Language of Fuzzy Variables", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the paper we define the convergence of compact fuzzy sets as a convergence\nof alpha-cuts in the topology of compact subsets of a metric space. Furthermore\nwe define typical convergences of fuzzy variables and show relations with\nconvergence of their fuzzy distributions. In this context we prove a general\nformulation of the Strong Law of Large Numbers for fuzzy sets and fuzzy\nvariables with Archimedean t-norms. Next we dispute a structure of fuzzy logics\nand postulate a new definition of necessity measures. Finally, we prove fuzzy\nversion of the Glivenko-Cantelli theorem and use it for a construction of a\ncomplete fuzzy measurement theory.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2009 10:59:57 GMT"}, {"version": "v2", "created": "Mon, 6 Apr 2009 13:51:34 GMT"}], "update_date": "2009-04-06", "authors_parsed": [["Bzowski", "Adam", ""], ["Urbanski", "Michal K.", ""]]}, {"id": "0903.1000", "submitter": "Michael Taylor", "authors": "MD Taylor", "title": "Bernstein Polynomials and n-Copulas", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give derivations of some basic results for the Bernstein approximation in\n$n$ variables that are useful in investigating copulas. It is shown that\nBernstein approximations of copulas are again copulas. We exhibit a stochastic\ninterpretation for the Bernstein approximation of a copula.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2009 14:17:34 GMT"}], "update_date": "2009-03-06", "authors_parsed": [["Taylor", "MD", ""]]}, {"id": "0903.1223", "submitter": "Arnak Dalalyan", "authors": "Arnak Dalalyan (IGM-LabInfo), Alexandre B. Tsybakov (PMA)", "title": "Sparse Regression Learning by Aggregation and Langevin Monte-Carlo", "comments": "Short version published in COLT 2009", "journal-ref": "Journal of Computer and System Sciences 78 (2012) 1423-1443", "doi": "10.1016/j.jcss.2011.12.023", "report-no": null, "categories": "stat.AP math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of regression learning for deterministic design and\nindependent random errors. We start by proving a sharp PAC-Bayesian type bound\nfor the exponentially weighted aggregate (EWA) under the expected squared\nempirical loss. For a broad class of noise distributions the presented bound is\nvalid whenever the temperature parameter $\\beta$ of the EWA is larger than or\nequal to $4\\sigma^2$, where $\\sigma^2$ is the noise variance. A remarkable\nfeature of this result is that it is valid even for unbounded regression\nfunctions and the choice of the temperature parameter depends exclusively on\nthe noise level. Next, we apply this general bound to the problem of\naggregating the elements of a finite-dimensional linear space spanned by a\ndictionary of functions $\\phi_1,...,\\phi_M$. We allow $M$ to be much larger\nthan the sample size $n$ but we assume that the true regression function can be\nwell approximated by a sparse linear combination of functions $\\phi_j$. Under\nthis sparsity scenario, we propose an EWA with a heavy tailed prior and we show\nthat it satisfies a sparsity oracle inequality with leading constant one.\nFinally, we propose several Langevin Monte-Carlo algorithms to approximately\ncompute such an EWA when the number $M$ of aggregated functions can be large.\nWe discuss in some detail the convergence of these algorithms and present\nnumerical experiments that confirm our theoretical findings.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2009 15:09:42 GMT"}, {"version": "v2", "created": "Mon, 9 Mar 2009 10:31:27 GMT"}, {"version": "v3", "created": "Tue, 16 Feb 2010 07:28:58 GMT"}], "update_date": "2012-06-27", "authors_parsed": [["Dalalyan", "Arnak", "", "IGM-LabInfo"], ["Tsybakov", "Alexandre B.", "", "PMA"]]}, {"id": "0903.1283", "submitter": "Ami Wiesel", "authors": "Ami Wiesel, Yonina C. Eldar and Alfred O. Hero III", "title": "Covariance estimation in decomposable Gaussian graphical models", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2009.2037350", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphical models are a framework for representing and exploiting prior\nconditional independence structures within distributions using graphs. In the\nGaussian case, these models are directly related to the sparsity of the inverse\ncovariance (concentration) matrix and allow for improved covariance estimation\nwith lower computational complexity. We consider concentration estimation with\nthe mean-squared error (MSE) as the objective, in a special type of model known\nas decomposable. This model includes, for example, the well known banded\nstructure and other cases encountered in practice. Our first contribution is\nthe derivation and analysis of the minimum variance unbiased estimator (MVUE)\nin decomposable graphical models. We provide a simple closed form solution to\nthe MVUE and compare it with the classical maximum likelihood estimator (MLE)\nin terms of performance and complexity. Next, we extend the celebrated Stein's\nunbiased risk estimate (SURE) to graphical models. Using SURE, we prove that\nthe MSE of the MVUE is always smaller or equal to that of the biased MLE, and\nthat the MVUE itself is dominated by other approaches. In addition, we propose\nthe use of SURE as a constructive mechanism for deriving new covariance\nestimators. Similarly to the classical MLE, all of our proposed estimators have\nsimple closed form solutions but result in a significant reduction in MSE.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2009 19:51:27 GMT"}], "update_date": "2015-10-28", "authors_parsed": [["Wiesel", "Ami", ""], ["Eldar", "Yonina C.", ""], ["Hero", "Alfred O.", "III"]]}, {"id": "0903.1314", "submitter": "Michael Nussbaum", "authors": "Georgi K. Golubev, Michael Nussbaum, Harrison H. Zhou", "title": "Asymptotic equivalence of spectral density estimation and gaussian white\n  noise", "comments": "39 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the statistical experiment given by a sample of a stationary\nGaussian process with an unknown smooth spectral density f. Asymptotic\nequivalence, in the sense of Le Cam's deficiency Delta-distance, to two\nGaussian experiments with simpler structure is established. The first one is\ngiven by independent zero mean Gaussians with variance approximately the value\nof f in points of a uniform grid (nonparametric Gaussian scale regression).\nThis approximation is closely related to well-known asymptotic independence\nresults for the periodogram and corresponding inference methods. The second\nasymptotic equivalence is to a Gaussian white noise model where the drift\nfunction is the log-spectral density. This represents the step from a Gaussian\nscale model to a location model, and also has a counterpart in established\ninference methods, i.e. log-periodogram regression. The problem of simple\nexplicit equivalence maps (Markov kernels), allowing to directly carry over\ninference, appears in this context but is not solved here.\n", "versions": [{"version": "v1", "created": "Sat, 7 Mar 2009 00:25:06 GMT"}], "update_date": "2009-03-10", "authors_parsed": [["Golubev", "Georgi K.", ""], ["Nussbaum", "Michael", ""], ["Zhou", "Harrison H.", ""]]}, {"id": "0903.1468", "submitter": "Massimiliano Pontil", "authors": "Karim Lounici, Massimiliano Pontil, Alexandre B. Tsybakov, Sara van de\n  Geer", "title": "Taking Advantage of Sparsity in Multi-Task Learning", "comments": null, "journal-ref": "10 pages, 1 figure, Proc. Computational Learning Theory Conference\n  (COLT 2009)", "doi": null, "report-no": null, "categories": "stat.ML math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of estimating multiple linear regression equations for\nthe purpose of both prediction and variable selection. Following recent work on\nmulti-task learning Argyriou et al. [2008], we assume that the regression\nvectors share the same sparsity pattern. This means that the set of relevant\npredictor variables is the same across the different equations. This assumption\nleads us to consider the Group Lasso as a candidate estimation method. We show\nthat this estimator enjoys nice sparsity oracle inequalities and variable\nselection properties. The results hold under a certain restricted eigenvalue\ncondition and a coherence condition on the design matrix, which naturally\nextend recent work in Bickel et al. [2007], Lounici [2008]. In particular, in\nthe multi-task learning scenario, in which the number of tasks can grow, we are\nable to remove completely the effect of the number of predictor variables in\nthe bounds. Finally, we show how our results can be extended to more general\nnoise distributions, of which we only require the variance to be finite.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2009 00:54:46 GMT"}], "update_date": "2012-08-21", "authors_parsed": [["Lounici", "Karim", ""], ["Pontil", "Massimiliano", ""], ["Tsybakov", "Alexandre B.", ""], ["van de Geer", "Sara", ""]]}, {"id": "0903.1721", "submitter": "Vladimir Spokoiny", "authors": "V. Spokoiny", "title": "A penalized exponential risk bound in parametric estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper offers a novel unified approach to studying the accuracy of\nparameter estimation by the quasi likelihood method. Important features of the\napproach are: (1) The underlying model {is not assumed to be parametric}. (2)\nNo conditions on parameter identifiability are required. The parameter set can\nbe unbounded. (3) The model assumptions are quite general and there is no\nspecific structural assumptions like independence or weak dependence of\nobservations. The imposed conditions on the model are very mild and can be\neasily checked in specific applications. (4) The established risk bounds are\n{nonasymptotic} and valid for large, moderate and small samples. (5) The main\nresult is the concentration property of the quasi MLE giving an nonasymptotic\nexponential bound for the probability that the considered estimate deviates out\nof a small neighborhood of the \"true\" point.\n  In standard situations under mild regularity conditions, the usual\nconsistency and rate results can be easily obtained as corollaries from the\nestablished risk bounds. % The approach and the results are illustrated on the\nexample of generalized linear and single-index models.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2009 09:54:45 GMT"}], "update_date": "2009-03-11", "authors_parsed": [["Spokoiny", "V.", ""]]}, {"id": "0903.1765", "submitter": "Jochen Br\\\"ocker", "authors": "Jochen Br\\\"ocker", "title": "A Lower Bound on Arbitrary $f$--Divergences in Terms of the Total\n  Variation", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important tool to quantify the likeness of two probability measures are\nf-divergences, which have seen widespread application in statistics and\ninformation theory. An example is the total variation, which plays an\nexceptional role among the f-divergences. It is shown that every f-divergence\nis bounded from below by a monotonous function of the total variation. Under\nappropriate regularity conditions, this function is shown to be monotonous.\n  Remark: The proof of the main proposition is relatively easy, whence it is\nhighly likely that the result is known. The author would be very grateful for\nany information regarding references or related work.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2009 13:20:48 GMT"}], "update_date": "2009-03-11", "authors_parsed": [["Br\u00f6cker", "Jochen", ""]]}, {"id": "0903.1846", "submitter": "Larissa Stanberry", "authors": "Larissa I. Stanberry and Hanna K. Jankowski", "title": "Expectations of Random Sets and Their Boundaries Using Oriented Distance\n  Functions", "comments": "23 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Shape estimation and object reconstruction are common problems in image\nanalysis. Mathematically, viewing objects in the image plane as random sets\nreduces the problem of shape estimation to inference about sets. Currently\nexisting definitions of the expected set rely on different criteria to\nconstruct the expectation. This paper introduces new definitions of the\nexpected set and the expected boundary, based on oriented distance functions.\nThe proposed expectations have a number of attractive properties, including\ninclusion relations, convexity preservation and equivariance with respect to\nrigid motions. The paper introduces a special class of separable oriented\ndistance functions for parametric sets and gives the definition and properties\nof separable random closed sets. Further, the definitions of the empirical mean\nset and the empirical mean boundary are proposed and empirical evidence of the\nconsistency of the boundary estimator is presented. In addition, the paper\ngives loss functions for set inference in frequentist framework and shows how\nsome of the existing expectations arise naturally as optimal estimators. The\nproposed definitions of the set and boundary expectations are illustrated on\ntheoretical examples and real data.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2009 20:10:44 GMT"}], "update_date": "2009-03-12", "authors_parsed": [["Stanberry", "Larissa I.", ""], ["Jankowski", "Hanna K.", ""]]}, {"id": "0903.1869", "submitter": "Hanna Jankowski", "authors": "Hanna K. Jankowski, Larissa I. Stanberry", "title": "Confidence Regions for Means of Random Sets using Oriented Distance\n  Functions", "comments": "26 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image analysis frequently deals with shape estimation and image\nreconstruction. The ob jects of interest in these problems may be thought of as\nrandom sets, and one is interested in finding a representative, or expected,\nset. We consider a definition of set expectation using oriented distance\nfunctions and study the properties of the associated empirical set. Conditions\nare given such that the empirical average is consistent, and a method to\ncalculate a confidence region for the expected set is introduced. The proposed\nmethod is applied to both real and simulated data examples.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2009 21:48:02 GMT"}, {"version": "v2", "created": "Wed, 8 Jun 2011 14:57:09 GMT"}], "update_date": "2011-06-09", "authors_parsed": [["Jankowski", "Hanna K.", ""], ["Stanberry", "Larissa I.", ""]]}, {"id": "0903.1951", "submitter": "J\\'{e}r\\^{o}me Dedecker", "authors": "J\\'er\\^ome Dedecker, Florence Merlev\\`ede, Magda Peligrad", "title": "Invariance principles for linear processes with application to isotonic\n  regression", "comments": "Published in at http://dx.doi.org/10.3150/10-BEJ273 the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2011, Vol. 17, No. 1, 88-113", "doi": "10.3150/10-BEJ273", "report-no": "IMS-BEJ-BEJ273", "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we prove maximal inequalities and study the functional central\nlimit theorem for the partial sums of linear processes generated by dependent\ninnovations. Due to the general weights, these processes can exhibit long-range\ndependence and the limiting distribution is a fractional Brownian motion. The\nproofs are based on new approximations by a linear process with martingale\ndifference innovations. The results are then applied to study an estimator of\nthe isotonic regression when the error process is a (possibly long-range\ndependent) time series.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2009 11:27:55 GMT"}, {"version": "v2", "created": "Fri, 18 Mar 2011 13:42:48 GMT"}], "update_date": "2011-03-21", "authors_parsed": [["Dedecker", "J\u00e9r\u00f4me", ""], ["Merlev\u00e8de", "Florence", ""], ["Peligrad", "Magda", ""]]}, {"id": "0903.2012", "submitter": "Giovanni Pistone", "authors": "Giovanni Pistone", "title": "$\\kappa$-exponential models from the geometrical viewpoint", "comments": null, "journal-ref": null, "doi": "10.1140/epjb/e2009-00154-y", "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss the use of Kaniadakis' $\\kappa$-exponential in the construction of\na statistical manifold modelled on Lebesgue spaces of real random variables.\nSome algebraic features of the deformed exponential models are considered. A\nchart is defined for each strictly positive densities; every other strictly\npositive density in a suitable neighborhood of the reference probability is\nrepresented by the centered $\\Kln$ likelihood\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2009 17:07:36 GMT"}], "update_date": "2015-05-13", "authors_parsed": [["Pistone", "Giovanni", ""]]}, {"id": "0903.2421", "submitter": "Matyas Barczy", "authors": "Matyas Barczy, Marton Ispany, Gyula Pap, Manuel Scotto, Maria Eduarda\n  Silva", "title": "Outliers in INAR(1) models", "comments": "106 pages; the proofs of the existence of CLS estimators are\n  corrected", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper the integer-valued autoregressive model of order one,\ncontaminated with additive or innovational outliers is studied in some detail.\nMoreover, parameter estimation is also addressed. Supposing that the time\npoints of the outliers are known but their sizes are unknown, we prove that the\nConditional Least Squares (CLS) estimators of the offspring and innovation\nmeans are strongly consistent. In contrast, however, the CLS estimators of the\noutliers' sizes are not strongly consistent, although they converge to a random\nlimit with probability 1. This random limit depends on the values of the\nprocess at the outliers' time points and on the values at the preceding time\npoints and in case of additive outliers also on the values at the following\ntime points. We also prove that the joint CLS estimator of the offspring and\ninnovation means is asymptotically normal. Conditionally on the above described\nvalues of the process, the joint CLS estimator of the sizes of the outliers is\nalso asymptotically normal.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2009 16:16:22 GMT"}, {"version": "v2", "created": "Sun, 28 Feb 2010 10:06:22 GMT"}], "update_date": "2010-02-28", "authors_parsed": [["Barczy", "Matyas", ""], ["Ispany", "Marton", ""], ["Pap", "Gyula", ""], ["Scotto", "Manuel", ""], ["Silva", "Maria Eduarda", ""]]}, {"id": "0903.2515", "submitter": "Shuheng Zhou", "authors": "Shuheng Zhou, Sara van de Geer, Peter B\\\"uhlmann", "title": "Adaptive Lasso for High Dimensional Regression and Gaussian Graphical\n  Modeling", "comments": "30 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the two-stage adaptive Lasso procedure (Zou, 2006) is consistent\nfor high-dimensional model selection in linear and Gaussian graphical models.\nOur conditions for consistency cover more general situations than those\naccomplished in previous work: we prove that restricted eigenvalue conditions\n(Bickel et al., 2008) are also sufficient for sparse structure estimation.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2009 23:17:49 GMT"}], "update_date": "2009-03-17", "authors_parsed": [["Zhou", "Shuheng", ""], ["van de Geer", "Sara", ""], ["B\u00fchlmann", "Peter", ""]]}, {"id": "0903.2572", "submitter": "Bercu Bernard", "authors": "Bernard Bercu and Victor Vazquez", "title": "On the usefulness of persistent excitation in ARX adaptive tracking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The usefulness of persistent excitation is well-known in the control\ncommunity. Thanks to a persistently excited adaptive tracking control, we show\nthat it is possible to avoid the strong controllability assumption recently\nproposed in the multidimensional ARX framework. We establish the almost sure\nconvergence for both least squares and weighted least squares estimators of the\nunknown parameters. A central limit theorem and a law of iterated logarithm are\nalso provided. All this asymptotical analysis is related to the Schur\ncomplement of a suitable limiting matrix.\n", "versions": [{"version": "v1", "created": "Sat, 14 Mar 2009 19:39:09 GMT"}], "update_date": "2009-03-17", "authors_parsed": [["Bercu", "Bernard", ""], ["Vazquez", "Victor", ""]]}, {"id": "0903.2692", "submitter": "Songzi Du", "authors": "Songzi Du", "title": "Random Walks on Dicyclic Group", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper works out the rate of convergence of two \"natural\" random walks on\nthe dicyclic group.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2009 04:40:11 GMT"}], "update_date": "2009-03-17", "authors_parsed": [["Du", "Songzi", ""]]}, {"id": "0903.2875", "submitter": "Jose A. Diaz-Garcia", "authors": "Jose A. Diaz-Garcia and R. Gutierrez-Jaimez", "title": "Compound and scale mixture of vector and spherical matrix variate\n  elliptical distributions", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several matrix variate hypergeometric type distributions are derived. The\ncompound distributions of left-spherical matrix variate elliptical\ndistributions and inverted hypergeometric type distributions with matrix\narguments are then proposed. The scale mixture of left-spherical matrix variate\nelliptical distributions and univariate inverted hypergeometric type\ndistributions is also derived as a particular case of the compound distribution\napproach.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2009 23:23:15 GMT"}], "update_date": "2009-03-18", "authors_parsed": [["Diaz-Garcia", "Jose A.", ""], ["Gutierrez-Jaimez", "R.", ""]]}, {"id": "0903.2890", "submitter": "Soummya Kar", "authors": "Soummya Kar, Bruno Sinopoli, and Jose M. F. Moura", "title": "Kalman Filtering with Intermittent Observations: Weak Convergence to a\n  Stationary Distribution", "comments": "Submitted for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper studies the asymptotic behavior of Random Algebraic Riccati\nEquations (RARE) arising in Kalman filtering when the arrival of the\nobservations is described by a Bernoulli i.i.d. process. We model the RARE as\nan order-preserving, strongly sublinear random dynamical system (RDS). Under a\nsufficient condition, stochastic boundedness, and using a limit-set dichotomy\nresult for order-preserving, strongly sublinear RDS, we establish the\nasymptotic properties of the RARE: the sequence of random prediction error\ncovariance matrices converges weakly to a unique invariant distribution, whose\nsupport exhibits fractal behavior. In particular, this weak convergence holds\nunder broad conditions and even when the observations arrival rate is below the\ncritical probability for mean stability. We apply the weak-Feller property of\nthe Markov process governing the RARE to characterize the support of the\nlimiting invariant distribution as the topological closure of a countable set\nof points, which, in general, is not dense in the set of positive semi-definite\nmatrices. We use the explicit characterization of the support of the invariant\ndistribution and the almost sure ergodicity of the sample paths to easily\ncompute the moments of the invariant distribution. A one dimensional example\nillustrates that the support is a fractured subset of the non-negative reals\nwith self-similarity properties.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2009 01:39:01 GMT"}, {"version": "v2", "created": "Fri, 28 May 2010 08:33:21 GMT"}], "update_date": "2010-05-31", "authors_parsed": [["Kar", "Soummya", ""], ["Sinopoli", "Bruno", ""], ["Moura", "Jose M. F.", ""]]}, {"id": "0903.2919", "submitter": "Patricia Reynaud-Bouret", "authors": "Patricia Reynaud-Bouret, Sophie Schbath", "title": "Adaptive estimation for Hawkes processes; application to genome analysis", "comments": "Published in at http://dx.doi.org/10.1214/10-AOS806 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2010, Vol. 38, No. 5, 2781-2822", "doi": "10.1214/10-AOS806", "report-no": "IMS-AOS-AOS806", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of this paper is to provide a new method for the detection of either\nfavored or avoided distances between genomic events along DNA sequences. These\nevents are modeled by a Hawkes process. The biological problem is actually\ncomplex enough to need a nonasymptotic penalized model selection approach. We\nprovide a theoretical penalty that satisfies an oracle inequality even for\nquite complex families of models. The consecutive theoretical estimator is\nshown to be adaptive minimax for H\\\"{o}lderian functions with regularity in\n$(1/2,1]$: those aspects have not yet been studied for the Hawkes' process.\nMoreover, we introduce an efficient strategy, named Islands, which is not\nclassically used in model selection, but that happens to be particularly\nrelevant to the biological question we want to answer. Since a multiplicative\nconstant in the theoretical penalty is not computable in practice, we provide\nextensive simulations to find a data-driven calibration of this constant. The\nresults obtained on real genomic data are coherent with biological knowledge\nand eventually refine them.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2009 08:27:51 GMT"}, {"version": "v2", "created": "Wed, 3 Feb 2010 09:17:40 GMT"}, {"version": "v3", "created": "Mon, 19 Apr 2010 12:54:30 GMT"}, {"version": "v4", "created": "Wed, 10 Nov 2010 14:50:35 GMT"}], "update_date": "2010-11-11", "authors_parsed": [["Reynaud-Bouret", "Patricia", ""], ["Schbath", "Sophie", ""]]}, {"id": "0903.3002", "submitter": "Tong Zhang", "authors": "Junzhou Huang, Tong Zhang, Dimitris Metaxas", "title": "Learning with Structured Sparsity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates a new learning formulation called structured\nsparsity, which is a natural extension of the standard sparsity concept in\nstatistical learning and compressive sensing. By allowing arbitrary structures\non the feature set, this concept generalizes the group sparsity idea that has\nbecome popular in recent years. A general theory is developed for learning with\nstructured sparsity, based on the notion of coding complexity associated with\nthe structure. It is shown that if the coding complexity of the target signal\nis small, then one can achieve improved performance by using coding complexity\nregularization methods, which generalize the standard sparse regularization.\nMoreover, a structured greedy algorithm is proposed to efficiently solve the\nstructured sparsity problem. It is shown that the greedy algorithm\napproximately solves the coding complexity optimization problem under\nappropriate conditions. Experiments are included to demonstrate the advantage\nof structured sparsity over standard sparsity on some real applications.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2009 16:32:55 GMT"}, {"version": "v2", "created": "Tue, 5 May 2009 14:33:07 GMT"}], "update_date": "2009-05-05", "authors_parsed": [["Huang", "Junzhou", ""], ["Zhang", "Tong", ""], ["Metaxas", "Dimitris", ""]]}, {"id": "0903.3180", "submitter": "Xiaofeng Shao", "authors": "Xiaofeng Shao", "title": "Nonstationarity-extended Whittle Estimation", "comments": "32 pages, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For long memory time series models with uncorrelated but dependent errors, we\nestablish the asymptotic normality of the Whittle estimator under mild\nconditions. Our framework includes the widely used FARIMA models with\nGARCH-type innovations. To cover nonstationary fractionally integrated\nprocesses, we extend the idea of Abadir, Distaso and Giraitis (2007, Journal of\nEconometrics 141, 1353-1384) and develop the nonstationarity-extended Whittle\nestimation. The resulting estimator is shown to be asymptotically normal and is\nmore efficient than the tapered Whittle estimator. Finally, the results from a\nsmall simulation study are presented to corroborate our theoretical findings.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2009 15:11:50 GMT"}], "update_date": "2009-03-19", "authors_parsed": [["Shao", "Xiaofeng", ""]]}, {"id": "0903.3330", "submitter": "Johan Segers", "authors": "Christian Genest, Johan Segers", "title": "On the covariance of the asymptotic empirical copula process", "comments": "14 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": "Institut de statistique, biostatistique et sciences actuarielles\n  (ISBA), Universit\\'e catholique de Louvain, DP0906", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conditions are given under which the empirical copula process associated with\na random sample from a bivariate continuous distribution has a smaller\nasymptotic covariance function than the standard empirical process based on\nobservations from the copula. Illustrations are provided and consequences for\ninference are outlined.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2009 13:45:35 GMT"}, {"version": "v2", "created": "Tue, 16 Mar 2010 09:01:58 GMT"}], "update_date": "2010-03-17", "authors_parsed": [["Genest", "Christian", ""], ["Segers", "Johan", ""]]}, {"id": "0903.3400", "submitter": "Xin Qi", "authors": "Xin Qi, Hongyu Zhao", "title": "Asymptotic efficiency and finite-sample properties of the generalized\n  profiling estimation of parameters in ordinary differential equations", "comments": "Published in at http://dx.doi.org/10.1214/09-AOS724 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2010, Vol. 38, No. 1, 435-481", "doi": "10.1214/09-AOS724", "report-no": "IMS-AOS-AOS724", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ordinary differential equations (ODEs) are commonly used to model dynamic\nbehavior of a system. Because many parameters are unknown and have to be\nestimated from the observed data, there is growing interest in statistics to\ndevelop efficient estimation procedures for these parameters. Among the\nproposed methods in the literature, the generalized profiling estimation method\ndeveloped by Ramsay and colleagues is particularly promising for its\ncomputational efficiency and good performance. In this approach, the ODE\nsolution is approximated with a linear combination of basis functions. The\ncoefficients of the basis functions are estimated by a penalized smoothing\nprocedure with an ODE-defined penalty. However, the statistical properties of\nthis procedure are not known. In this paper, we first give an upper bound on\nthe uniform norm of the difference between the true solutions and their\napproximations. Then we use this bound to prove the consistency and asymptotic\nnormality of this estimation procedure. We show that the asymptotic covariance\nmatrix is the same as that of the maximum likelihood estimation. Therefore,\nthis procedure is asymptotically efficient. For a fixed sample and fixed basis\nfunctions, we study the limiting behavior of the approximation when the\nsmoothing parameter tends to infinity. We propose an algorithm to choose the\nsmoothing parameters and a method to compute the deviation of the spline\napproximation from solution without solving the ODEs.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2009 19:52:18 GMT"}, {"version": "v2", "created": "Thu, 19 Mar 2009 20:15:42 GMT"}, {"version": "v3", "created": "Wed, 13 Jan 2010 07:07:33 GMT"}], "update_date": "2010-01-13", "authors_parsed": [["Qi", "Xin", ""], ["Zhao", "Hongyu", ""]]}, {"id": "0903.3438", "submitter": "Ali Devin Sezer Dr.", "authors": "Ferruh Ozbudak, Ali Devin Sezer", "title": "Approximation of Bounds on Mixed Level Orthogonal Arrays", "comments": "28 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.OC stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mixed level orthogonal arrays are basic structures in experimental design. We\ndevelop three algorithms that compute Rao and Gilbert-Varshamov type bounds for\nmixed level orthogonal arrays. The computational complexity of the terms\ninvolved in these bounds can grow fast as the parameters of the arrays increase\nand this justifies the construction of these algorithms. The first is a\nrecursive algorithm that computes the bounds exactly, the second is based on an\nasymptotic analysis and the third is a simulation algorithm. They are all based\non the representation of the combinatorial expressions that appear in the\nbounds as expectations involving a symmetric random walk. The Markov property\nof the underlying random walk gives the recursive formula to compute the\nexpectations. A large deviation (LD) analysis of the expectations provide the\nasymptotic algorithm. The asymptotically optimal importance sampling (IS) of\nthe same expectation provides the simulation algorithm. Both the LD analysis\nand the construction of the IS algorithm uses a representation of these\nproblems as a sequence of stochastic optimal control problems converging to a\nlimit calculus of variations problem. The construction of the IS algorithm uses\na recently discovered method of using subsolutions to the Hamilton Jacobi\nBellman equation associated with the limit problem.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2009 22:45:17 GMT"}, {"version": "v2", "created": "Sun, 3 May 2009 15:21:46 GMT"}], "update_date": "2009-05-03", "authors_parsed": [["Ozbudak", "Ferruh", ""], ["Sezer", "Ali Devin", ""]]}, {"id": "0903.3470", "submitter": "Yingcun Xia", "authors": "Yingcun Xia", "title": "A Note on The Backfitting Estimation of Additive Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The additive model is one of the most popular semiparametric models. The\nbackfitting estimation (Buja, Hastie and Tibshirani, 1989, \\textit{Ann.\nStatist.}) for the model is intuitively easy to understand and theoretically\nmost efficient (Opsomer and Ruppert, 1997, \\textit{Ann. Statist.}); its\nimplementation is equivalent to solving simple linear equations. However,\nconvergence of the algorithm is very difficult to investigate and is still\nunsolved. For bivariate additive models, Opsomer and Ruppert (1997,\n\\textit{Ann. Statist.}) proved the convergence under a very strong condition\nand conjectured that a much weaker condition is sufficient. In this short note,\nwe show that a weak condition can guarantee the convergence of the backfitting\nestimation algorithm when the Nadaraya-Watson kernel smoothing is used.\n", "versions": [{"version": "v1", "created": "Fri, 20 Mar 2009 09:46:03 GMT"}], "update_date": "2009-03-23", "authors_parsed": [["Xia", "Yingcun", ""]]}, {"id": "0903.3620", "submitter": "Guido Consonni", "authors": "George Casella and Guido Consonni", "title": "Reconciling Model Selection and Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is known that there is a dichotomy in the performance of model selectors.\nThose that are consistent (having the \"oracle property\") do not achieve the\nasymptotic minimax rate for prediction error. We look at this phenomenon\nclosely, and argue that the set of parameters on which this dichotomy occurs is\nextreme, even pathological, and should not be considered when evaluating model\nselectors. We characterize this set, and show that, when such parameters are\ndismissed from consideration, consistency and asymptotic minimaxity can be\nattained simultaneously.\n", "versions": [{"version": "v1", "created": "Fri, 20 Mar 2009 21:55:35 GMT"}], "update_date": "2009-03-24", "authors_parsed": [["Casella", "George", ""], ["Consonni", "Guido", ""]]}, {"id": "0903.3795", "submitter": "George Moustakides", "authors": "George V. Moustakides", "title": "Finite Sample Size Optimality of GLR Tests", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In several interesting applications one is faced with the problem of\nsimultaneous binary hypothesis testing and parameter estimation. Although such\njoint problems are not infrequent, there exist no systematic analysis in the\nliterature that treats them effectively. Existing approaches consider the\ndetection and the estimation subproblems separately, applying in each case the\ncorresponding optimum strategy. As it turns out the overall scheme is not\nnecessarily optimum since the criteria used for the two parts are usually\nincompatible. In this article we propose a mathematical setup that considers\nthe two problems jointly. Specifically we propose a meaningful combination of\nthe Neyman-Pearson and the Bayesian criterion and we provide the optimum\nsolution for the joint problem. In the resulting optimum scheme the two parts\ninteract with each other, producing detection/estimation structures that are\ncompletely novel. Notable side-product of our work is the proof that the well\nknown GLR test is finite-sample-size optimum under this combined sense.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2009 06:30:14 GMT"}, {"version": "v2", "created": "Wed, 25 Nov 2009 17:32:03 GMT"}], "update_date": "2009-11-25", "authors_parsed": [["Moustakides", "George V.", ""]]}, {"id": "0903.4061", "submitter": "Matti Vihola", "authors": "Matti Vihola", "title": "On the stability and ergodicity of adaptive scaling Metropolis\n  algorithms", "comments": "24 pages, 1 figure; major revision", "journal-ref": "Stochastic Processes and their Applications 121(12):2839-2860,\n  2011", "doi": "10.1016/j.spa.2011.08.006", "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The stability and ergodicity properties of two adaptive random walk\nMetropolis algorithms are considered. The both algorithms adjust the scaling of\nthe proposal distribution continuously based on the observed acceptance\nprobability. Unlike the previously proposed forms of the algorithms, the\nadapted scaling parameter is not constrained within a predefined compact\ninterval. The first algorithm is based on scale adaptation only, while the\nsecond one incorporates also covariance adaptation. A strong law of large\nnumbers is shown to hold assuming that the target density is smooth enough and\nhas either compact support or super-exponentially decaying tails.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2009 11:51:25 GMT"}, {"version": "v2", "created": "Mon, 26 Apr 2010 08:23:06 GMT"}, {"version": "v3", "created": "Tue, 5 Apr 2011 12:59:00 GMT"}], "update_date": "2011-11-21", "authors_parsed": [["Vihola", "Matti", ""]]}, {"id": "0903.4550", "submitter": "Yury Kutoyants", "authors": "Yury A. Kutoyants", "title": "On the Goodness-of-Fit Testing for Ergodic Diffusion Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the goodness of fit testing problem for ergodic diffusion\nprocesses. The basic hypothesis is supposed to be simple. The diffusion\ncoefficient is known and the alternatives are described by the different trend\ncoefficients. We study the asymptotic distribution of the Cramer-von Mises type\ntests based on the empirical distribution function and local time estimator of\nthe invariant density. At particularly, we propose a transformation which makes\nthese tests asymptotically distribution free. We discuss the modifications of\nthis test in the case of composite basic hypothesis.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2009 10:54:36 GMT"}], "update_date": "2009-03-27", "authors_parsed": [["Kutoyants", "Yury A.", ""]]}, {"id": "0903.4579", "submitter": "Zvika Ben-Haim", "authors": "Zvika Ben-Haim, Yonina C. Eldar, and Michael Elad", "title": "Coherence-Based Performance Guarantees for Estimating a Sparse Vector\n  Under Random Noise", "comments": "12 pages, 3 figures. Submitted to IEEE Transactions on Signal\n  Processing", "journal-ref": null, "doi": "10.1109/TSP.2010.2052460", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of estimating a deterministic sparse vector x from\nunderdetermined measurements Ax+w, where w represents white Gaussian noise and\nA is a given deterministic dictionary. We analyze the performance of three\nsparse estimation algorithms: basis pursuit denoising (BPDN), orthogonal\nmatching pursuit (OMP), and thresholding. These algorithms are shown to achieve\nnear-oracle performance with high probability, assuming that x is sufficiently\nsparse. Our results are non-asymptotic and are based only on the coherence of\nA, so that they are applicable to arbitrary dictionaries. Differences in the\nprecise conditions required for the performance guarantees of each algorithm\nare manifested in the observed performance at high and low signal-to-noise\nratios. This provides insight on the advantages and drawbacks of convex\nrelaxation techniques such as BPDN as opposed to greedy approaches such as OMP\nand thresholding.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2009 13:37:09 GMT"}, {"version": "v2", "created": "Wed, 2 Dec 2009 07:02:27 GMT"}], "update_date": "2015-05-13", "authors_parsed": [["Ben-Haim", "Zvika", ""], ["Eldar", "Yonina C.", ""], ["Elad", "Michael", ""]]}, {"id": "0903.4612", "submitter": "Yury Kutoyants", "authors": "Yury A. Kutoyants", "title": "Goodness-of-Fit Tests for Perturbed Dynamical Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the goodness of fit testing problem for stochastic differential\nequation with small diffiusion coefficient. The basic hypothesis is always\nsimple and it is described by the known trend coefficient. We propose several\ntests of the type of Cramer-von Mises, Kolmogorov-Smirnov and Chi-Square. The\npower functions of these tests we study for a special classes of close\nalternatives. We discuss the construction of the goodness of fit test based on\nthe local time and the possibility of the construction of asymptotically\ndistribution free tests in the case of composite basic hypothesis.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2009 15:25:00 GMT"}], "update_date": "2009-03-27", "authors_parsed": [["Kutoyants", "Yury A.", ""]]}, {"id": "0903.4613", "submitter": "Yury Kutoyants", "authors": "Yury A. Kutoyants", "title": "On Properties of Estimators in non Regular Situations for Poisson\n  Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of parameter estimation by observations of\ninhomogeneous Poisson process. It is well-known that if the regularity\nconditions are fulfilled then the maximum likelihood and Bayesian estimators\nare consistent, asymptotically normal and asymptotically efficient. These\nregularity conditions can be roughly presented as follows: a) the intensity\nfunction of observed process belongs to known parametric family of functions,\nb) the model is identifiable, c) the Fisher information is positive continuous\nfunction, d) the intensity function is sufficiently smooth with respect to the\nunknown parameter, e) this parameter is an interior point of the interval. We\nare interested in the properties of estimators when these regularity conditions\nare not fulfilled. More precisely, we preset a review of the results which\ncorrespond to the rejection of these conditions one by one and we show how the\nproperties of the MLE and Bayesian estimators change. The proofs of these\nresults are essentially based on some general results by Ibragimov and\nKhasminskii.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2009 15:33:09 GMT"}], "update_date": "2009-03-27", "authors_parsed": [["Kutoyants", "Yury A.", ""]]}, {"id": "0903.4636", "submitter": "Yury Kutoyants", "authors": "Serguei Dachian, Yury A. Kutoyants", "title": "Hypotheses Testing: Poisson Versus Self-exciting", "comments": "23 pages, 6 figures", "journal-ref": "In SCANDINAVIAN J. of STATISTICS 33 391 (2006)", "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of hypotheses testing with the basic simple\nhypothesis: observed sequence of points corresponds to stationary Poisson\nprocess with known intensity. The alternatives are stationary self-exciting\npoint processes. We consider one-sided parametric and one-sided nonparametric\ncomposite alternatives and construct locally asymptotically uniformly most\npowerful tests. The results of numerical simulations of the tests are\npresented.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2009 17:01:30 GMT"}], "update_date": "2009-03-27", "authors_parsed": [["Dachian", "Serguei", ""], ["Kutoyants", "Yury A.", ""]]}, {"id": "0903.4642", "submitter": "Yury Kutoyants", "authors": "Serguei Dachian, Yury A. Kutoyants", "title": "On the Goodness-of-Fit Tests for Some Continuous Time Processes", "comments": "22 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a review of several results concerning the construction of the\nCramer-von Mises and Kolmogorov-Smirnov type goodness-of-fit tests for\ncontinuous time processes. As the models we take a stochastic differential\nequation with small noise, ergodic diffusion process, Poisson process and\nself-exciting point processes. For every model we propose the tests which\nprovide the asymptotic size $\\alpha $ and discuss the behaviour of the power\nfunction under local alternatives. The results of numerical simulations of the\ntests are presented.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2009 17:12:33 GMT"}], "update_date": "2009-03-27", "authors_parsed": [["Dachian", "Serguei", ""], ["Kutoyants", "Yury A.", ""]]}, {"id": "0903.4807", "submitter": "Christophe Pouet", "authors": "Yuri I. Ingster (LETI), Christophe Pouet (LATP), Alexandre B. Tsybakov\n  (PMA, CREST)", "title": "Sparse classification boundaries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a training sample of size $m$ from a $d$-dimensional population, we\nwish to allocate a new observation $Z\\in \\R^d$ to this population or to the\nnoise. We suppose that the difference between the distribution of the\npopulation and that of the noise is only in a shift, which is a sparse vector.\nFor the Gaussian noise, fixed sample size $m$, and the dimension $d$ that tends\nto infinity, we obtain the sharp classification boundary and we propose\nclassifiers attaining this boundary. We also give extensions of this result to\nthe case where the sample size $m$ depends on $d$ and satisfies the condition\n$(\\log m)/\\log d \\to \\gamma$, $0\\le \\gamma<1$, and to the case of non-Gaussian\nnoise satisfying the Cram\\'er condition.\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2009 14:27:45 GMT"}], "update_date": "2009-03-30", "authors_parsed": [["Ingster", "Yuri I.", "", "LETI"], ["Pouet", "Christophe", "", "LATP"], ["Tsybakov", "Alexandre B.", "", "PMA, CREST"]]}, {"id": "0903.4954", "submitter": "Omar El-Dakkak", "authors": "Salim Bouzebda (LSTA), Omar El-Dakkak (LSTA)", "title": "Approximation for general bootstrap of empirical processes with an\n  application to kernel-type density estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The purpose of this note is to provide an approximation for the generalized\nbootstrapped empirical process achieving the rate in Kolmos et al. (1975). The\nproof is based on much the same arguments as in Horvath et al. (2000). As a\nconsequence, we establish an approximation of the bootstrapped kernel-type\ndensity estimator\n", "versions": [{"version": "v1", "created": "Sat, 28 Mar 2009 07:53:29 GMT"}], "update_date": "2009-03-31", "authors_parsed": [["Bouzebda", "Salim", "", "LSTA"], ["El-Dakkak", "Omar", "", "LSTA"]]}, {"id": "0903.5061", "submitter": "Yury Kutoyants", "authors": "Reinhard Hoepfner and Yury Kutoyants", "title": "Estimating discontinuous periodic signals in a non-time homogeneous\n  diffusion process", "comments": "42 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a diffusion $(\\xi_t)_{t\\ge 0}$ with some $T$-periodic time\ndependent input term contained in the drift: under an unknown parameter\n$\\vth\\in\\Theta$, some discontinuity - an additional periodic signal - occurs at\ntimes $kT{+}\\vth$, $k\\in\\bbn$. Assuming positive Harris recurrence of\n$(\\xi_{kT})_{k\\in\\bbn_0}$ and exploiting the periodicity structure, we prove\nlimit theorems for certain martingales and functionals of the process\n$(\\xi_t)_{t\\ge 0}$. They allow to consider the statistical model parametrized\nby $\\vth\\in\\Theta$ locally in small neighbourhoods of some fixed $\\vth$, with\nradius $1/n$ as $\\nto$. We prove convergence of local models to a limit\nexperiment studied by Ibragimov and Khasminskii [IH 81] and discuss the\nbehaviour of estimators under contiguous alternatives.\n", "versions": [{"version": "v1", "created": "Sun, 29 Mar 2009 16:11:41 GMT"}, {"version": "v2", "created": "Wed, 17 Mar 2010 12:06:42 GMT"}], "update_date": "2010-03-18", "authors_parsed": [["Hoepfner", "Reinhard", ""], ["Kutoyants", "Yury", ""]]}, {"id": "0903.5066", "submitter": "Namrata Vaswani", "authors": "Namrata Vaswani and Wei Lu", "title": "Modified-CS: Modifying Compressive Sensing for Problems with Partially\n  Known Support", "comments": "To Appear in IEEE Trans. Signal Processing, September 2010, shorter\n  version presented at ISIT 2009", "journal-ref": "IEEE Trans. Signal Processing, pages 4595--4607, vol. 58 (9),\n  September 2010", "doi": "10.1109/TSP.2010.2051150", "report-no": null, "categories": "cs.IT math.IT math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of reconstructing a sparse signal from a limited number\nof its linear projections when a part of its support is known, although the\nknown part may contain some errors. The ``known\" part of the support, denoted\nT, may be available from prior knowledge. Alternatively, in a problem of\nrecursively reconstructing time sequences of sparse spatial signals, one may\nuse the support estimate from the previous time instant as the ``known\" part.\nThe idea of our proposed solution (modified-CS) is to solve a convex relaxation\nof the following problem: find the signal that satisfies the data constraint\nand is sparsest outside of T. We obtain sufficient conditions for exact\nreconstruction using modified-CS. These are much weaker than those needed for\ncompressive sensing (CS) when the sizes of the unknown part of the support and\nof errors in the known part are small compared to the support size. An\nimportant extension called Regularized Modified-CS (RegModCS) is developed\nwhich also uses prior signal estimate knowledge. Simulation comparisons for\nboth sparse and compressible signals are shown.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2009 16:45:17 GMT"}, {"version": "v2", "created": "Tue, 31 Mar 2009 14:10:03 GMT"}, {"version": "v3", "created": "Mon, 26 Oct 2009 22:39:13 GMT"}, {"version": "v4", "created": "Wed, 24 Mar 2010 04:25:42 GMT"}, {"version": "v5", "created": "Tue, 27 Jul 2010 19:45:48 GMT"}], "update_date": "2015-03-13", "authors_parsed": [["Vaswani", "Namrata", ""], ["Lu", "Wei", ""]]}, {"id": "0903.5147", "submitter": "T. Tony Cai", "authors": "T. Tony Cai, Harrison H. Zhou", "title": "A data-driven block thresholding approach to wavelet estimation", "comments": "Published in at http://dx.doi.org/10.1214/07-AOS538 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2009, Vol. 37, No. 2, 569-595", "doi": "10.1214/07-AOS538", "report-no": "IMS-AOS-AOS538", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A data-driven block thresholding procedure for wavelet regression is proposed\nand its theoretical and numerical properties are investigated. The procedure\nempirically chooses the block size and threshold level at each resolution level\nby minimizing Stein's unbiased risk estimate. The estimator is sharp adaptive\nover a class of Besov bodies and achieves simultaneously within a small\nconstant factor of the minimax risk over a wide collection of Besov Bodies\nincluding both the ``dense'' and ``sparse'' cases. The procedure is easy to\nimplement. Numerical results show that it has superior finite sample\nperformance in comparison to the other leading wavelet thresholding estimators.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2009 08:14:37 GMT"}], "update_date": "2009-03-31", "authors_parsed": [["Cai", "T. Tony", ""], ["Zhou", "Harrison H.", ""]]}, {"id": "0903.5161", "submitter": "Helmut Finner", "authors": "Helmut Finner, Thorsten Dickhaus, Markus Roters", "title": "On the false discovery rate and an asymptotically optimal rejection\n  curve", "comments": "Published in at http://dx.doi.org/10.1214/07-AOS569 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2009, Vol. 37, No. 2, 596-618", "doi": "10.1214/07-AOS569", "report-no": "IMS-AOS-AOS569", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce and investigate a new rejection curve for\nasymptotic control of the false discovery rate (FDR) in multiple hypotheses\ntesting problems. We first give a heuristic motivation for this new curve and\npropose some procedures related to it. Then we introduce a set of possible\nassumptions and give a unifying short proof of FDR control for procedures based\non Simes' critical values, whereby certain types of dependency are allowed.\nThis methodology of proof is then applied to other fixed rejection curves\nincluding the proposed new curve. Among others, we investigate the problem of\nfinding least favorable parameter configurations such that the FDR becomes\nlargest. We then derive a series of results concerning asymptotic FDR control\nfor procedures based on the new curve and discuss several example procedures in\nmore detail. A main result will be an asymptotic optimality statement for\nvarious procedures based on the new curve in the class of fixed rejection\ncurves. Finally, we briefly discuss strict FDR control for a finite number of\nhypotheses.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2009 09:21:28 GMT"}], "update_date": "2009-03-31", "authors_parsed": [["Finner", "Helmut", ""], ["Dickhaus", "Thorsten", ""], ["Roters", "Markus", ""]]}, {"id": "0903.5255", "submitter": "Jianqing Fan", "authors": "Jianqing Fan, Rui Song", "title": "Sure independence screening in generalized linear models with\n  NP-dimensionality", "comments": "Published in at http://dx.doi.org/10.1214/10-AOS798 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2010, Vol. 38, No. 6, 3567-3604", "doi": "10.1214/10-AOS798", "report-no": "IMS-AOS-AOS798", "categories": "stat.ME math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ultrahigh-dimensional variable selection plays an increasingly important role\nin contemporary scientific discoveries and statistical research. Among others,\nFan and Lv [J. R. Stat. Soc. Ser. B Stat. Methodol. 70 (2008) 849-911] propose\nan independent screening framework by ranking the marginal correlations. They\nshowed that the correlation ranking procedure possesses a sure independence\nscreening property within the context of the linear model with Gaussian\ncovariates and responses. In this paper, we propose a more general version of\nthe independent learning with ranking the maximum marginal likelihood estimates\nor the maximum marginal likelihood itself in generalized linear models. We show\nthat the proposed methods, with Fan and Lv [J. R. Stat. Soc. Ser. B Stat.\nMethodol. 70 (2008) 849-911] as a very special case, also possess the sure\nscreening property with vanishing false selection rate. The conditions under\nwhich the independence learning possesses a sure screening is surprisingly\nsimple. This justifies the applicability of such a simple method in a wide\nspectrum. We quantify explicitly the extent to which the dimensionality can be\nreduced by independence screening, which depends on the interactions of the\ncovariance matrix of covariates and true parameters. Simulation studies are\nused to illustrate the utility of the proposed approaches. In addition, we\nestablish an exponential inequality for the quasi-maximum likelihood estimator\nwhich is useful for high-dimensional statistical learning.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2009 15:58:51 GMT"}, {"version": "v2", "created": "Sat, 4 Apr 2009 22:26:42 GMT"}, {"version": "v3", "created": "Thu, 8 Oct 2009 04:12:40 GMT"}, {"version": "v4", "created": "Mon, 18 Jan 2010 17:53:14 GMT"}, {"version": "v5", "created": "Tue, 13 Nov 2012 09:49:29 GMT"}], "update_date": "2012-11-14", "authors_parsed": [["Fan", "Jianqing", ""], ["Song", "Rui", ""]]}, {"id": "0903.5299", "submitter": "Larry Guth", "authors": "Larry Guth", "title": "Systolic inequalities and minimal hypersurfaces", "comments": "5 pages. Accepted for publication in GAFA", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.DG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a short proof of the systolic inequality for the n-dimensional torus.\nThe proof uses minimal hypersurfaces. It is based on the Schoen-Yau proof that\nan n-dimensional torus admits no metric of positive scalar curvature.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2009 19:31:08 GMT"}, {"version": "v2", "created": "Thu, 2 Jul 2009 18:04:08 GMT"}], "update_date": "2009-07-02", "authors_parsed": [["Guth", "Larry", ""]]}, {"id": "0903.5341", "submitter": "Wojciech Sarnowski", "authors": "Wojciech Sarnowski, Krzysztof Szajowski", "title": "Unspecified distribution in single disorder problem", "comments": "23 pages", "journal-ref": "Applied Stochastic Models in Business and Industry. 2018, vol. 34,\n  nr 5, s. 700-717", "doi": "10.1002/asmb.2317", "report-no": "Rap. Inst. Mat. Copm. Sci. PWr. 2009,, Ser. PRE ; no 8", "categories": "math.PR cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We register a stochastic sequence affected by one disorder. Monitoring of the\nsequence is made in the circumstances when not full information about\ndistributions before and after the change is available. The initial problem of\ndisorder detection is transformed to optimal stopping of observed sequence.\nFormula for optimal decision functions is derived.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2009 23:13:52 GMT"}, {"version": "v2", "created": "Sun, 13 Dec 2009 17:37:26 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Sarnowski", "Wojciech", ""], ["Szajowski", "Krzysztof", ""]]}, {"id": "0903.5342", "submitter": "Marcus Hutter", "authors": "Marcus Hutter", "title": "Exact Non-Parametric Bayesian Inference on Infinite Trees", "comments": "32 LaTeX pages, 9 figures, 5 theorems, 1 algorithm", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given i.i.d. data from an unknown distribution, we consider the problem of\npredicting future items. An adaptive way to estimate the probability density is\nto recursively subdivide the domain to an appropriate data-dependent\ngranularity. A Bayesian would assign a data-independent prior probability to\n\"subdivide\", which leads to a prior over infinite(ly many) trees. We derive an\nexact, fast, and simple inference algorithm for such a prior, for the data\nevidence, the predictive distribution, the effective model dimension, moments,\nand other quantities. We prove asymptotic convergence and consistency results,\nand illustrate the behavior of our model on some prototypical functions.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2009 23:24:08 GMT"}], "update_date": "2009-12-30", "authors_parsed": [["Hutter", "Marcus", ""]]}, {"id": "0903.5373", "submitter": "Yoav Benjamini", "authors": "Yulia Gavrilov, Yoav Benjamini, Sanat K. Sarkar", "title": "An adaptive step-down procedure with proven FDR control under\n  independence", "comments": "Published in at http://dx.doi.org/10.1214/07-AOS586 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2009, Vol. 37, No. 2, 619-629", "doi": "10.1214/07-AOS586", "report-no": "IMS-AOS-AOS586", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we study an adaptive step-down procedure for testing $m$\nhypotheses. It stems from the repeated use of the false discovery rate\ncontrolling the linear step-up procedure (sometimes called BH), and makes use\nof the critical constants $iq/[(m+1-i(1-q)]$, $i=1,...,m$. Motivated by its\nsuccess as a model selection procedure, as well as by its asymptotic\noptimality, we are interested in its false discovery rate (FDR) controlling\nproperties for a finite number of hypotheses. We prove this step-down procedure\ncontrols the FDR at level $q$ for independent test statistics. We then\nnumerically compare it with two other procedures with proven FDR control under\nindependence, both in terms of power under independence and FDR control under\npositive dependence.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2009 05:54:03 GMT"}], "update_date": "2009-04-01", "authors_parsed": [["Gavrilov", "Yulia", ""], ["Benjamini", "Yoav", ""], ["Sarkar", "Sanat K.", ""]]}, {"id": "0903.5426", "submitter": "Peter Harremo\\\"es", "authors": "Peter Harremoes", "title": "Testing Goodness-of-Fit via Rate Distortion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A framework is developed using techniques from rate distortion theory in\nstatistical testing. The idea is first to do optimal compression according to a\ncertain distortion function and then use information divergence from the\ncompressed empirical distribution to the compressed null hypothesis as\nstatistic. Only very special cases have been studied in more detail, but they\nindicate that the approach can be used under very general conditions.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2009 10:15:24 GMT"}], "update_date": "2009-04-01", "authors_parsed": [["Harremoes", "Peter", ""]]}, {"id": "0903.5474", "submitter": "Huiliang Xie", "authors": "Huiliang Xie, Jian Huang", "title": "SCAD-penalized regression in high-dimensional partially linear models", "comments": "Published in at http://dx.doi.org/10.1214/07-AOS580 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2009, Vol. 37, No. 2, 673-696", "doi": "10.1214/07-AOS580", "report-no": "IMS-AOS-AOS580", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of simultaneous variable selection and estimation in\npartially linear models with a divergent number of covariates in the linear\npart, under the assumption that the vector of regression coefficients is\nsparse. We apply the SCAD penalty to achieve sparsity in the linear part and\nuse polynomial splines to estimate the nonparametric component. Under\nreasonable conditions, it is shown that consistency in terms of variable\nselection and estimation can be achieved simultaneously for the linear and\nnonparametric components. Furthermore, the SCAD-penalized estimators of the\nnonzero coefficients are shown to have the asymptotic oracle property, in the\nsense that it is asymptotically normal with the same means and covariances that\nthey would have if the zero coefficients were known in advance. The finite\nsample behavior of the SCAD-penalized estimators is evaluated with simulation\nand illustrated with a data set.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2009 13:56:52 GMT"}], "update_date": "2009-04-01", "authors_parsed": [["Xie", "Huiliang", ""], ["Huang", "Jian", ""]]}, {"id": "0903.5480", "submitter": "Christophe Andrieu", "authors": "Christophe Andrieu, Gareth O. Roberts", "title": "The pseudo-marginal approach for efficient Monte Carlo computations", "comments": "Published in at http://dx.doi.org/10.1214/07-AOS574 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2009, Vol. 37, No. 2, 697-725", "doi": "10.1214/07-AOS574", "report-no": "IMS-AOS-AOS574", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a powerful and flexible MCMC algorithm for stochastic\nsimulation. The method builds on a pseudo-marginal method originally introduced\nin [Genetics 164 (2003) 1139--1160], showing how algorithms which are\napproximations to an idealized marginal algorithm, can share the same marginal\nstationary distribution as the idealized method. Theoretical results are given\ndescribing the convergence properties of the proposed method, and simple\nnumerical examples are given to illustrate the promising empirical\ncharacteristics of the technique. Interesting comparisons with a more obvious,\nbut inexact, Monte Carlo approximation to the marginal algorithm, are also\ngiven.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2009 14:50:43 GMT"}], "update_date": "2009-04-01", "authors_parsed": [["Andrieu", "Christophe", ""], ["Roberts", "Gareth O.", ""]]}]