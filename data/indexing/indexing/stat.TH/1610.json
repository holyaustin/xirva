[{"id": "1610.00032", "submitter": "Xiaohui Chen", "authors": "Xiaohui Chen", "title": "Gaussian and bootstrap approximations for high-dimensional U-statistics\n  and their applications", "comments": "This paper is accepted for publication in the Annals of Statistics\n  and it supersedes the arXiv preprint \"Gaussian approximation for the sup-norm\n  of high-dimensional matrix-variate U-statistics and its applications\"\n  (arXiv:1602.00199)", "journal-ref": null, "doi": "10.1214/17-AOS1563", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the Gaussian and bootstrap approximations for the\nprobabilities of a non-degenerate U-statistic belonging to the hyperrectangles\nin $\\mathbb{R}^d$ when the dimension $d$ is large. A two-step Gaussian\napproximation procedure that does not impose structural assumptions on the data\ndistribution is proposed. Subject to mild moment conditions on the kernel, we\nestablish the explicit rate of convergence uniformly in the class of all\nhyperrectangles in $\\mathbb{R}^d$ that decays polynomially in sample size for a\nhigh-dimensional scaling limit, where the dimension can be much larger than the\nsample size. We also provide computable approximation methods for the quantiles\nof the maxima of centered U-statistics. Specifically, we provide a unified\nperspective for the empirical bootstrap, the randomly reweighted bootstrap, and\nthe Gaussian multiplier bootstrap with the jackknife estimator of covariance\nmatrix as randomly reweighted quadratic forms and we establish their validity.\nWe show that all three methods are inferentially first-order equivalent for\nhigh-dimensional U-statistics in the sense that they achieve the same uniform\nrate of convergence over all $d$-dimensional hyperrectangles. In particular,\nthey are asymptotically valid when the dimension $d$ can be as large as\n$O(e^{n^c})$ for some constant $c \\in (0,1/7)$.\n  (Full abstract can be found in the paper.)\n", "versions": [{"version": "v1", "created": "Fri, 30 Sep 2016 20:59:06 GMT"}, {"version": "v2", "created": "Sun, 26 Feb 2017 19:11:40 GMT"}, {"version": "v3", "created": "Mon, 10 Jul 2017 05:28:52 GMT"}], "update_date": "2017-07-11", "authors_parsed": [["Chen", "Xiaohui", ""]]}, {"id": "1610.00094", "submitter": "Abdelhakim Necir", "authors": "Nawel Haouas, Abdelhakim Necir, Brahim Brahimi", "title": "Estimating the second-order parameter of regular variation and bias\n  reduction in tail index estimation under random truncation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we propose an estimator of the second-order parameter of\nrandomly right-truncated Pareto-type distributions data and establish its\nconsistency and asymptotic normality. Moreover, we derive an asymptotically\nunbiased estimator of the tail index and study its asymptotic behaviour. Our\nconsiderations are based on a useful Gaussian approximation of the tail\nproduct-limit process recently given by Benchaira et al. [Tail product-limit\nprocess for truncated data with application to extreme value index estimation.\nExtremes, 2016; 19: 219-251] and the results of Gomes et al. [Semi-parametric\nestimation of the second order parameter in statistics of extremes. Extremes,\n2002; 5: 387-414]. We show, by simulation, that the proposed estimators behave\nwell, in terms of bias and mean square error.\n", "versions": [{"version": "v1", "created": "Sat, 1 Oct 2016 06:40:01 GMT"}, {"version": "v2", "created": "Thu, 20 Oct 2016 11:43:44 GMT"}], "update_date": "2016-10-21", "authors_parsed": [["Haouas", "Nawel", ""], ["Necir", "Abdelhakim", ""], ["Brahimi", "Brahim", ""]]}, {"id": "1610.00124", "submitter": "Udaysinh T. Bhosale", "authors": "Udaysinh T. Bhosale and M. S. Santhanam", "title": "Signatures of bifurcation on quantum correlations: Case of the quantum\n  kicked top", "comments": "10 pages, 10 figures. Comments are welcome", "journal-ref": "Phys. Rev. E 95, 012216 (2017)", "doi": "10.1103/PhysRevE.95.012216", "report-no": null, "categories": "quant-ph math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum correlations reflect the quantumness of a system and are useful\nresources for quantum information and computational processes. The measures of\nquantum correlations do not have a classical analog and yet are influenced by\nthe classical dynamics. In this work, by modelling the quantum kicked top as a\nmulti-qubit system, the effect of classical bifurcations on the measures of\nquantum correlations such as quantum discord, geometric discord, Meyer and\nWallach $Q$ measure is studied. The quantum correlation measures change rapidly\nin the vicinity of a classical bifurcation point. If the classical system is\nlargely chaotic, time averages of the correlation measures are in good\nagreement with the values obtained by considering the appropriate random matrix\nensembles. The quantum correlations scale with the total spin of the system,\nrepresenting its semiclassical limit. In the vicinity of the trivial fixed\npoints of the kicked top, scaling function decays as a power-law. In the\nchaotic limit, for large total spin, quantum correlations saturate to a\nconstant, which we obtain analytically, based on random matrix theory, for the\n$Q$ measure. We also suggest that it can have experimental consequences.\n", "versions": [{"version": "v1", "created": "Sat, 1 Oct 2016 12:28:04 GMT"}, {"version": "v2", "created": "Sat, 28 Jan 2017 09:36:25 GMT"}], "update_date": "2018-07-23", "authors_parsed": [["Bhosale", "Udaysinh T.", ""], ["Santhanam", "M. S.", ""]]}, {"id": "1610.00207", "submitter": "Johannes Lederer", "authors": "Wei Li and Johannes Lederer", "title": "Tuning parameter calibration for $\\ell_1$-regularized logistic\n  regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature selection is a standard approach to understanding and modeling\nhigh-dimensional classification data, but the corresponding statistical methods\nhinge on tuning parameters that are difficult to calibrate. In particular,\nexisting calibration schemes in the logistic regression framework lack any\nfinite sample guarantees. In this paper, we introduce a novel calibration\nscheme for $\\ell_1$-penalized logistic regression. It is based on simple tests\nalong the tuning parameter path and is equipped with optimal guarantees for\nfeature selection. It is also amenable to easy and efficient implementations,\nand it rivals or outmatches existing methods in simulations and real data\napplications.\n", "versions": [{"version": "v1", "created": "Sat, 1 Oct 2016 23:53:04 GMT"}, {"version": "v2", "created": "Thu, 28 Feb 2019 14:27:23 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["Li", "Wei", ""], ["Lederer", "Johannes", ""]]}, {"id": "1610.00316", "submitter": "Petr Koldanov Alexander", "authors": "Koldanov Petr, Koldanov Alexander, Kalyagin Valeriy, Pardalos Panos", "title": "Uniformly most powerful unbiased test for conditional independence in\n  Gaussian graphical model", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model selection for Gaussian concentration graph is based on multiple testing\nof pairwise conditional independence. In practical applications partial\ncorrelation tests are widely used. However it is not known whether partial\ncorrelation test is uniformly most powerful for pairwise conditional\nindependence testing. This question is answered in the paper. Uniformly most\npowerful unbiased test of Neymann structure is obtained. It turns out, that\nthis test can be reduced to usual partial correlation test. It implies that\npartial correlation test is uniformly most powerful unbiased one.\n", "versions": [{"version": "v1", "created": "Sun, 2 Oct 2016 17:21:05 GMT"}], "update_date": "2016-10-04", "authors_parsed": [["Petr", "Koldanov", ""], ["Alexander", "Koldanov", ""], ["Valeriy", "Kalyagin", ""], ["Panos", "Pardalos", ""]]}, {"id": "1610.00667", "submitter": "Xin Gao Dr.", "authors": "Xin Gao and Raymond J. Carroll", "title": "Data Integration with High Dimensionality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a problem of data integration. Consider determining which genes\naffect a disease. The genes, which we call predictor objects, can be measured\nin different experiments on the same individual. We address the question of\nfinding which genes are predictors of disease by any of the experiments. Our\nformulation is more general. In a given data set, there are a fixed number of\nresponses for each individual, which may include a mix of discrete, binary and\ncontinuous variables. There is also a class of predictor objects, which may\ndiffer within a subject depending on how the predictor object is measured,\ni.e., depend on the experiment. The goal is to select which predictor objects\naffect any of the responses, where the number of such informative predictor\nobjects or features tends to infinity as sample size increases. There are\nmarginal likelihoods for each way the predictor object is measured, i.e., for\neach experiment. We specify a pseudolikelihood combining the marginal\nlikelihoods, and propose a pseudolikelihood information criterion. Under\nregularity conditions, we establish selection consistency for the\npseudolikelihood information criterion with unbounded true model size, which\nincludes a Bayesian information criterion with appropriate penalty term as a\nspecial case. Simulations indicate that data integration improves upon,\nsometimes dramatically, using only one of the data sources.\n", "versions": [{"version": "v1", "created": "Mon, 3 Oct 2016 18:40:25 GMT"}], "update_date": "2016-10-04", "authors_parsed": [["Gao", "Xin", ""], ["Carroll", "Raymond J.", ""]]}, {"id": "1610.00684", "submitter": "Shuyang (Ray) Bai", "authors": "Shuyang Bai, Murad S. Taqqu", "title": "Hermite rank, power rank and the generalized Weierstrass transform", "comments": "Proofs greatly simplified", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using the theory of generalized Weierstrass transform, we show that the\nHermite rank is identical to the power rank in the Gaussian case, and that an\nHermite rank higher than one is unstable with respect to a level shift.\n", "versions": [{"version": "v1", "created": "Mon, 3 Oct 2016 19:23:28 GMT"}, {"version": "v2", "created": "Sun, 28 May 2017 19:35:44 GMT"}], "update_date": "2017-05-30", "authors_parsed": [["Bai", "Shuyang", ""], ["Taqqu", "Murad S.", ""]]}, {"id": "1610.00690", "submitter": "Shuyang (Ray) Bai", "authors": "Shuyang Bai, Murad S. Taqqu", "title": "How the instability of ranks under long memory affects large-sample\n  inference", "comments": "31 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Under long memory, the limit theorems for normalized sums of random variables\ntypically involve a positive integer called \"Hermite rank\". There is a\ndifferent limit for each Hermite rank. From a statistical point of view,\nhowever, we argue that a rank other than one is unstable, whereas, a rank equal\nto one is stable. We provide empirical evidence supporting this argument. This\nhas important consequences. Assuming a higher-order rank when it is not really\nthere usually results in underestimating the order of the fluctuations of the\nstatistic of interest. We illustrate this through various examples involving\nthe sample variance, the empirical processes and the Whittle estimator.\n", "versions": [{"version": "v1", "created": "Mon, 3 Oct 2016 19:35:54 GMT"}, {"version": "v2", "created": "Thu, 2 Nov 2017 03:01:08 GMT"}], "update_date": "2017-11-03", "authors_parsed": [["Bai", "Shuyang", ""], ["Taqqu", "Murad S.", ""]]}, {"id": "1610.00732", "submitter": "Yao Xie", "authors": "Yao Xie and Lee Seversky", "title": "Sequential Low-Rank Change Detection", "comments": "Presented at Allerton Conference, 2016. Partially supported by a AFRI\n  Visiting Faculty Fellowship", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting emergence of a low-rank signal from high-dimensional data is an\nimportant problem arising from many applications such as camera surveillance\nand swarm monitoring using sensors. We consider a procedure based on the\nlargest eigenvalue of the sample covariance matrix over a sliding window to\ndetect the change. To achieve dimensionality reduction, we present a\nsketching-based approach for rank change detection using the low-dimensional\nlinear sketches of the original high-dimensional observations. The premise is\nthat when the sketching matrix is a random Gaussian matrix, and the dimension\nof the sketching vector is sufficiently large, the rank of sample covariance\nmatrix for these sketches equals the rank of the original sample covariance\nmatrix with high probability. Hence, we may be able to detect the low-rank\nchange using sample covariance matrices of the sketches without having to\nrecover the original covariance matrix. We character the performance of the\nlargest eigenvalue statistic in terms of the false-alarm-rate and the expected\ndetection delay, and present an efficient online implementation via subspace\ntracking.\n", "versions": [{"version": "v1", "created": "Mon, 3 Oct 2016 20:29:37 GMT"}, {"version": "v2", "created": "Fri, 7 Oct 2016 16:44:49 GMT"}], "update_date": "2016-10-10", "authors_parsed": [["Xie", "Yao", ""], ["Seversky", "Lee", ""]]}, {"id": "1610.00780", "submitter": "Arturo Erdely", "authors": "Arturo Erdely", "title": "A subcopula based dependence measure", "comments": "11 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A dependence measure for arbitrary type pairs of random variables is proposed\nand analyzed, which in the particular case where both random variables are\ncontinuous turns out to be a concordance measure. Also, a sample version of the\nproposed dependence measure based on the empirical subcopula is provided, along\nwith an R package to perform the corresponding calculations.\n", "versions": [{"version": "v1", "created": "Mon, 3 Oct 2016 22:49:08 GMT"}, {"version": "v2", "created": "Wed, 5 Oct 2016 14:48:42 GMT"}, {"version": "v3", "created": "Mon, 6 Feb 2017 16:03:10 GMT"}], "update_date": "2017-02-07", "authors_parsed": [["Erdely", "Arturo", ""]]}, {"id": "1610.00951", "submitter": "Anirvan Chakraborty Mr.", "authors": "Anirvan Chakraborty and Victor M. Panaretos", "title": "Hybrid Regularisation of Functional Linear Models", "comments": "34 pages, 1 figure and 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of estimating the slope function in a functional\nregression with a scalar response and a functional covariate. This central\nproblem of functional data analysis is well known to be ill-posed, thus\nrequiring a regularised estimation procedure. The two most commonly used\napproaches are based on spectral truncation or Tikhonov regularisation of the\nempirical covariance operator. In principle, Tikhonov regularisation is the\nmore canonical choice. Compared to spectral truncation, it is robust to\neigenvalue ties, while it attains the optimal minimax rate of convergence in\nthe mean squared sense, and not just in a concentration probability sense. In\nthis paper, we show that, surprisingly, one can strictly improve upon the\nperformance of the Tikhonov estimator in finite samples by means of a linear\nestimator, while retaining its stability and asymptotic properties by combining\nit with a form of spectral truncation. Specifically, we construct an estimator\nthat additively decomposes the functional covariate by projecting it onto two\northogonal subspaces defined via functional PCA; it then applies Tikhonov\nregularisation to the one component, while leaving the other component\nunregularised. We prove that when the covariate is Gaussian, this hybrid\nestimator uniformly improves upon the MSE of the Tikhonov estimator in a\nnon-asymptotic sense, effectively rendering it inadmissible. This domination is\nshown to also persist under discrete observation of the covariate function. The\nhybrid estimator is linear, straightforward to construct in practice, and with\nno computational overhead relative to the standard regularisation methods. By\nmeans of simulation, it is shown to furnish sizeable gains even for modest\nsample sizes.\n", "versions": [{"version": "v1", "created": "Tue, 4 Oct 2016 12:37:55 GMT"}], "update_date": "2016-10-05", "authors_parsed": [["Chakraborty", "Anirvan", ""], ["Panaretos", "Victor M.", ""]]}, {"id": "1610.01230", "submitter": "Shev MacNamara", "authors": "Gilbert Strang and Shev MacNamara", "title": "A Local Inverse Formula and a Factorization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When a matrix has a banded inverse there is a remarkable formula that quickly\ncomputes that inverse, using only local information in the original matrix.\nThis local inverse formula holds more generally, for matrices with sparsity\npatterns that are examples of chordal graphs or perfect eliminators. The\nformula has a long history going back at least as far as the completion problem\nfor covariance matrices with missing data. Maximum entropy estimates,\nlog-determinants, rank conditions, the Nullity Theorem and wavelets are all\nclosely related, and the formula has found wide applications in machine\nlearning and graphical models. We describe that local inverse and explain how\nit can be understood as a matrix factorization.\n", "versions": [{"version": "v1", "created": "Tue, 4 Oct 2016 23:10:32 GMT"}], "update_date": "2016-10-06", "authors_parsed": [["Strang", "Gilbert", ""], ["MacNamara", "Shev", ""]]}, {"id": "1610.01290", "submitter": "Lionel Truquet", "authors": "Lionel Truquet", "title": "Local stationarity and time-inhomogeneous Markov chains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study a notion of local stationarity for discrete time\nMarkov chains which is useful for applications in statistics. In the spirit of\nsome locally stationary processes introduced in the literature, we consider\ntriangular arrays of time-inhomogeneous Markov chains, defined by some families\nof contracting Markov kernels. Using the Dobrushin's contraction coefficients\nfor various metrics, we show that the distribution of such Markov chains can be\napproximated locally with the distribution of ergodic Markov chains and we also\nstudy some mixing properties. From our approximation results in Wasserstein\nmetrics, we recover several properties obtained for autoregressive processes.\nMoreover, using the total variation distance or more generally some distances\ninduced by a drift function, we consider new models, such as finite state space\nMarkov chains with time-varying transition matrices or some time-varying\nversions of integer-valued autoregressive processes. For these two examples,\nnonparametric kernel estimation of the transition matrix is discussed.\n\\end{abstract}\n", "versions": [{"version": "v1", "created": "Wed, 5 Oct 2016 07:15:42 GMT"}], "update_date": "2016-10-06", "authors_parsed": [["Truquet", "Lionel", ""]]}, {"id": "1610.01353", "submitter": "Jana Jankova", "authors": "Jana Jankov\\'a and Sara van de Geer", "title": "Confidence regions for high-dimensional generalized linear models under\n  sparsity", "comments": "40 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study asymptotically normal estimation and confidence regions for\nlow-dimensional parameters in high-dimensional sparse models. Our approach is\nbased on the $\\ell_1$-penalized M-estimator which is used for construction of a\nbias corrected estimator. We show that the proposed estimator is asymptotically\nnormal, under a sparsity assumption on the high-dimensional parameter,\nsmoothness conditions on the expected loss and an entropy condition. This leads\nto uniformly valid confidence regions and hypothesis testing for\nlow-dimensional parameters. The present approach is different in that it allows\nfor treatment of loss functions that we not sufficiently differentiable, such\nas quantile loss, Huber loss or hinge loss functions. We also provide new\nresults for estimation of the inverse Fisher information matrix, which is\nnecessary for the construction of the proposed estimator. We formulate our\nresults for general models under high-level conditions, but investigate these\nconditions in detail for generalized linear models and provide mild sufficient\nconditions. As particular examples, we investigate the case of quantile loss\nand Huber loss in linear regression and demonstrate the performance of the\nestimators in a simulation study and on real datasets from genome-wide\nassociation studies. We further investigate the case of logistic regression and\nillustrate the performance of the estimator on simulated and real data.\n", "versions": [{"version": "v1", "created": "Wed, 5 Oct 2016 10:44:09 GMT"}], "update_date": "2016-10-06", "authors_parsed": [["Jankov\u00e1", "Jana", ""], ["van de Geer", "Sara", ""]]}, {"id": "1610.01456", "submitter": "Christoph Thaele", "authors": "Tobias Fissler, Christoph Thaele", "title": "A new quantitative central limit theorem on the Wiener space with\n  applications to Gaussian processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantitative limit theorems for non-linear functionals on the Wiener space\nare considered. Given the possibly infinite sequence of kernels of the chaos\ndecomposition of such a functional, an estimate for different probability\ndistances between the functional and a Gaussian random variable in terms of\ncontraction norms of these kernels is derived. The applicability of this result\nis demonstrated by means of the Breuer-Major theorem, unfolding thereby a new\nconnection between the Hermite rank of the considered function and a chaotic\ngap. Especially, power variations of the fractional Brownian motion and\nprocesses belonging to the Cauchy class are studied.\n", "versions": [{"version": "v1", "created": "Wed, 5 Oct 2016 14:43:42 GMT"}], "update_date": "2016-10-06", "authors_parsed": [["Fissler", "Tobias", ""], ["Thaele", "Christoph", ""]]}, {"id": "1610.01747", "submitter": "Wenxin Jiang", "authors": "Wenxin Jiang", "title": "On Limiting Distribution of Quasi-Posteriors under Partial\n  Identification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We establish the limiting distribution (in total variation) of the quasi\nposteriors based on moment conditions, which only partially identify the\nparameters of interest. Some examples are discussed.\n", "versions": [{"version": "v1", "created": "Thu, 6 Oct 2016 06:47:12 GMT"}], "update_date": "2016-10-07", "authors_parsed": [["Jiang", "Wenxin", ""]]}, {"id": "1610.01895", "submitter": "Zacharie Naulet", "authors": "Zacharie Naulet and Eric Barat", "title": "Bayesian nonparametric estimation for Quantum Homodyne Tomography", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We estimate the quantum state of a light beam from results of quantum\nhomodyne tomography noisy measurements performed on identically prepared\nquantum systems. We propose two Bayesian nonparametric approaches. The first\napproach is based on mixture models and is illustrated through simulation\nexamples. The second approach is based on random basis expansions. We study the\ntheoretical performance of the second approach by quantifying the rate of\ncontraction of the posterior distribution around the true quantum state in the\n$L^2$ metric.\n", "versions": [{"version": "v1", "created": "Thu, 6 Oct 2016 14:43:22 GMT"}], "update_date": "2016-10-07", "authors_parsed": [["Naulet", "Zacharie", ""], ["Barat", "Eric", ""]]}, {"id": "1610.01952", "submitter": "Valeriya Naumova", "authors": "Ernesto De Vito, Massimo Fornasier, Valeriya Naumova", "title": "A Machine Learning Approach to Optimal Tikhonov Regularisation I: Affine\n  Manifolds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite a variety of available techniques the issue of the proper\nregularization parameter choice for inverse problems still remains one of the\nbiggest challenges. The main difficulty lies in constructing a rule, allowing\nto compute the parameter from given noisy data without relying either on a\npriori knowledge of the solution or on the noise level. In this paper we\npropose a novel method based on supervised machine learning to approximate the\nhigh-dimensional function, mapping noisy data into a good approximation to the\noptimal Tikhonov regularization parameter. Our assumptions are that solutions\nof the inverse problem are statistically distributed in a concentrated manner\non (lower-dimensional) linear subspaces and the noise is sub-gaussian. One of\nthe surprising facts is that the number of previously observed examples for the\nsupervised learning of the optimal parameter mapping scales at most linearly\nwith the dimension of the solution subspace. We also provide explicit error\nbounds on the accuracy of the approximated parameter and the corresponding\nregularization solution. Even though the results are more of theoretical\nnature, we present a recipe for the practical implementation of the approach\nand provide numerical experiments confirming the theoretical results. We also\noutline interesting directions for future research with some preliminary\nresults, confirming their feasibility.\n", "versions": [{"version": "v1", "created": "Thu, 6 Oct 2016 17:09:32 GMT"}, {"version": "v2", "created": "Thu, 12 Oct 2017 09:55:40 GMT"}], "update_date": "2017-10-13", "authors_parsed": [["De Vito", "Ernesto", ""], ["Fornasier", "Massimo", ""], ["Naumova", "Valeriya", ""]]}, {"id": "1610.02080", "submitter": "Art Owen", "authors": "Art B. Owen and Cl\\'ementine Prieur", "title": "On Shapley value for measuring importance of dependent inputs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.NA stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper makes the case for using Shapley value to quantify the importance\nof random input variables to a function. Alternatives based on the ANOVA\ndecomposition can run into conceptual and computational problems when the input\nvariables are dependent. Our main goal here is to show that Shapley value\nremoves the conceptual problems. We do this with some simple examples where\nShapley value leads to intuitively reasonable nearly closed form values.\n", "versions": [{"version": "v1", "created": "Thu, 6 Oct 2016 21:45:35 GMT"}, {"version": "v2", "created": "Tue, 14 Mar 2017 22:48:17 GMT"}, {"version": "v3", "created": "Tue, 21 Mar 2017 02:24:07 GMT"}], "update_date": "2017-03-22", "authors_parsed": [["Owen", "Art B.", ""], ["Prieur", "Cl\u00e9mentine", ""]]}, {"id": "1610.02122", "submitter": "Jelena Bradic", "authors": "Yinchu Zhu and Jelena Bradic", "title": "Significance testing in non-sparse high-dimensional linear models", "comments": "43 pages", "journal-ref": null, "doi": "10.1214/18-EJS1443", "report-no": null, "categories": "stat.ME math.SP math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In high-dimensional linear models, the sparsity assumption is typically made,\nstating that most of the parameters are equal to zero. Under the sparsity\nassumption, estimation and, recently, inference have been well studied.\nHowever, in practice, sparsity assumption is not checkable and more importantly\nis often violated; a large number of covariates might be expected to be\nassociated with the response, indicating that possibly all, rather than just a\nfew, parameters are non-zero. A natural example is a genome-wide gene\nexpression profiling, where all genes are believed to affect a common disease\nmarker. We show that existing inferential methods are sensitive to the sparsity\nassumption, and may, in turn, result in the severe lack of control of Type-I\nerror. In this article, we propose a new inferential method, named CorrT, which\nis robust to model misspecification such as heteroscedasticity and lack of\nsparsity. CorrT is shown to have Type I error approaching the nominal level for\n\\textit{any} models and Type II error approaching zero for sparse and many\ndense models.\n  In fact, CorrT is also shown to be optimal in a variety of frameworks:\nsparse, non-sparse and hybrid models where sparse and dense signals are mixed.\nNumerical experiments show a favorable performance of the CorrT test compared\nto the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Fri, 7 Oct 2016 02:17:00 GMT"}, {"version": "v2", "created": "Tue, 3 Jan 2017 01:35:02 GMT"}, {"version": "v3", "created": "Mon, 28 Aug 2017 06:08:42 GMT"}, {"version": "v4", "created": "Mon, 28 May 2018 01:31:25 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Zhu", "Yinchu", ""], ["Bradic", "Jelena", ""]]}, {"id": "1610.02145", "submitter": "Taku Moriyama", "authors": "Yoshihiko Maesono, Taku Moriyama and Mengxin Lu", "title": "Smoothed nonparametric tests and their properties", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose new smoothed sign and Wilcoxon's signed rank tests,\nwhich are based on a kernel estimator of the underlying distribution function\nof data. We discuss approximations of $p$-values and asymptotic properties of\nthese tests. The new smoothed tests are equivalent to the ordinary sign and\nWilcoxon's tests in the sense of the Pitman's asymptotic relative efficiency,\nand the differences of the ordinary and the new tests converge to zero in\nprobability. Under the null hypothesis, the main terms of the asymptotic\nexpectations and variances of the tests do not depend on the underlying\ndistribution. Though the smoothed tests are not distribution-free, we can\nobtain Edgeworth expansions with residual term $o(n^{-1})$, which do not depend\non the underlying distribution.\n", "versions": [{"version": "v1", "created": "Fri, 7 Oct 2016 05:13:50 GMT"}, {"version": "v2", "created": "Mon, 17 Oct 2016 03:28:47 GMT"}, {"version": "v3", "created": "Fri, 21 Oct 2016 01:30:35 GMT"}], "update_date": "2016-10-24", "authors_parsed": [["Maesono", "Yoshihiko", ""], ["Moriyama", "Taku", ""], ["Lu", "Mengxin", ""]]}, {"id": "1610.02207", "submitter": "Steffen Gr{\\o}nneberg", "authors": "Steffen Gr{\\o}nneberg, Nj{\\aa}l Foldnes", "title": "New testing procedures for Structural Equation Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce and evaluate a new class of hypothesis testing procedures for\nmoment structures. The methods are valid under weak assumptions and includes\nthe well-known Satorra-Bentler adjustment as a special case. The proposed\nprocedures applies also to difference testing among nested models. We prove the\nconsistency of our approach. We introduce a bootstrap selection mechanism to\noptimally choose a p-value approximation for a given sample. Also, we propose\nbootstrap procedures for assessing the asymptotic robustness (AR) of the\nnormal-theory maximum likelihood test, and for the key assumption underlying\nthe Satorra-Bentler adjustment (Satorra-Bentler consistency). Simulation\nstudies indicate that our new p-value approximations performs well even under\nsevere nonnormality and realistic sample sizes, but that our tests for AR and\nSatorra-Bentler consistency require very large sample sizes to work well.\n", "versions": [{"version": "v1", "created": "Fri, 7 Oct 2016 09:54:29 GMT"}], "update_date": "2016-10-10", "authors_parsed": [["Gr\u00f8nneberg", "Steffen", ""], ["Foldnes", "Nj\u00e5l", ""]]}, {"id": "1610.02351", "submitter": "Lucas Janson", "authors": "Emmanuel Candes, Yingying Fan, Lucas Janson, Jinchi Lv", "title": "Panning for Gold: Model-X Knockoffs for High-dimensional Controlled\n  Variable Selection", "comments": "39 pages, 10 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many contemporary large-scale applications involve building interpretable\nmodels linking a large set of potential covariates to a response in a nonlinear\nfashion, such as when the response is binary. Although this modeling problem\nhas been extensively studied, it remains unclear how to effectively control the\nfraction of false discoveries even in high-dimensional logistic regression, not\nto mention general high-dimensional nonlinear models. To address such a\npractical problem, we propose a new framework of $model$-$X$ knockoffs, which\nreads from a different perspective the knockoff procedure (Barber and Cand\\`es,\n2015) originally designed for controlling the false discovery rate in linear\nmodels. Whereas the knockoffs procedure is constrained to homoscedastic linear\nmodels with $n\\ge p$, the key innovation here is that model-X knockoffs provide\nvalid inference from finite samples in settings in which the conditional\ndistribution of the response is arbitrary and completely unknown. Furthermore,\nthis holds no matter the number of covariates. Correct inference in such a\nbroad setting is achieved by constructing knockoff variables probabilistically\ninstead of geometrically. To do this, our approach requires the covariates be\nrandom (independent and identically distributed rows) with a distribution that\nis known, although we provide preliminary experimental evidence that our\nprocedure is robust to unknown/estimated distributions. To our knowledge, no\nother procedure solves the $controlled$ variable selection problem in such\ngenerality, but in the restricted settings where competitors exist, we\ndemonstrate the superior power of knockoffs through simulations. Finally, we\napply our procedure to data from a case-control study of Crohn's disease in the\nUnited Kingdom, making twice as many discoveries as the original analysis of\nthe same data.\n", "versions": [{"version": "v1", "created": "Fri, 7 Oct 2016 17:18:02 GMT"}, {"version": "v2", "created": "Sat, 26 Nov 2016 18:25:01 GMT"}, {"version": "v3", "created": "Fri, 6 Jan 2017 05:37:10 GMT"}, {"version": "v4", "created": "Tue, 12 Dec 2017 14:57:10 GMT"}], "update_date": "2017-12-13", "authors_parsed": [["Candes", "Emmanuel", ""], ["Fan", "Yingying", ""], ["Janson", "Lucas", ""], ["Lv", "Jinchi", ""]]}, {"id": "1610.02581", "submitter": "Hongseok Namkoong", "authors": "John Duchi and Hongseok Namkoong", "title": "Variance-based regularization with convex objectives", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop an approach to risk minimization and stochastic optimization that\nprovides a convex surrogate for variance, allowing near-optimal and\ncomputationally efficient trading between approximation and estimation error.\nOur approach builds off of techniques for distributionally robust optimization\nand Owen's empirical likelihood, and we provide a number of finite-sample and\nasymptotic results characterizing the theoretical performance of the estimator.\nIn particular, we show that our procedure comes with certificates of\noptimality, achieving (in some scenarios) faster rates of convergence than\nempirical risk minimization by virtue of automatically balancing bias and\nvariance. We give corroborating empirical evidence showing that in practice,\nthe estimator indeed trades between variance and absolute performance on a\ntraining sample, improving out-of-sample (test) performance over standard\nempirical risk minimization for a number of classification problems.\n", "versions": [{"version": "v1", "created": "Sat, 8 Oct 2016 20:52:13 GMT"}, {"version": "v2", "created": "Sat, 22 Oct 2016 22:31:57 GMT"}, {"version": "v3", "created": "Thu, 14 Dec 2017 18:50:19 GMT"}], "update_date": "2017-12-15", "authors_parsed": [["Duchi", "John", ""], ["Namkoong", "Hongseok", ""]]}, {"id": "1610.02680", "submitter": "Taposh Banerjee", "authors": "Taposh Banerjee and George V. Moustakides", "title": "Minimax Optimality of Shiryaev-Roberts Procedure for Quickest Drift\n  Change Detection of a Brownian motion", "comments": "Submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT math.IT math.OC stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of detecting a change in the drift of a Brownian motion is\nconsidered. The change point is assumed to have a modified exponential prior\ndistribution with unknown parameters. A worst-case analysis with respect to\nthese parameters is adopted leading to a min-max problem formulation.\nAnalytical and numerical justifications are provided towards establishing that\nthe Shiryaev-Roberts procedure with a specially designed starting point is\nexactly optimal for the proposed mathematical setup.\n", "versions": [{"version": "v1", "created": "Sun, 9 Oct 2016 14:11:13 GMT"}], "update_date": "2016-10-11", "authors_parsed": [["Banerjee", "Taposh", ""], ["Moustakides", "George V.", ""]]}, {"id": "1610.02753", "submitter": "Myung Hwan Seo", "authors": "Myung Hwan Seo and Taisuke Otsu", "title": "Local M-estimation with Discontinuous Criterion for Dependent and\n  Limited Observations", "comments": null, "journal-ref": "the Annals of Statistics (2018), 46, 344-369,", "doi": "10.1214/17-AOS1552", "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper examines asymptotic properties of local M-estimators under three\nsets of high-level conditions. These conditions are sufficiently general to\ncover the minimum volume predictive region, conditional maximum score estimator\nfor a panel data discrete choice model, and many other widely used estimators\nin statistics and econometrics. Specifically, they allow for discontinuous\ncriterion functions of weakly dependent observations, which may be localized by\nkernel smoothing and contain nuisance parameters whose dimension may grow to\ninfinity. Furthermore, the localization can occur around parameter values\nrather than around a fixed point and the observation may take limited values,\nwhich leads to set estimators. Our theory produces three different\nnonparametric cube root rates and enables valid inference for the local\nM-estimators, building on novel maximal inequalities for weakly dependent data.\nOur results include the standard cube root asymptotics as a special case. To\nillustrate the usefulness of our results, we verify our conditions for various\nexamples such as the Hough transform estimator with diminishing bandwidth,\nmaximum score-type set estimator, and many others.\n", "versions": [{"version": "v1", "created": "Mon, 10 Oct 2016 02:28:57 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Seo", "Myung Hwan", ""], ["Otsu", "Taisuke", ""]]}, {"id": "1610.02863", "submitter": "Olivier Wintenberger", "authors": "F Blasques, P Gorgi, S Koopman (CREATES), O Wintenberger (University\n  of Copenhagen, LSTA)", "title": "Feasible Invertibility Conditions for Maximum Likelihood Estimation for\n  Observation-Driven Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Invertibility conditions for observation-driven time series models often fail\nto be guaranteed in empirical applications. As a result, the asymptotic theory\nof maximum likelihood and quasi-maximum likelihood estimators may be\ncompromised. We derive considerably weaker conditions that can be used in\npractice to ensure the consistency of the maximum likelihood estimator for a\nwide class of observation-driven time series models. Our consistency results\nhold for both correctly specified and misspecified models. The practical\nrelevance of the theory is highlighted in a set of empirical examples. We\nfurther obtain an asymptotic test and confidence bounds for the unfeasible \"\ntrue \" invertibility region of the parameter space.\n", "versions": [{"version": "v1", "created": "Mon, 10 Oct 2016 11:46:54 GMT"}], "update_date": "2016-10-11", "authors_parsed": [["Blasques", "F", "", "CREATES"], ["Gorgi", "P", "", "CREATES"], ["Koopman", "S", "", "CREATES"], ["Wintenberger", "O", "", "University\n  of Copenhagen, LSTA"]]}, {"id": "1610.02872", "submitter": "Francois Bachoc", "authors": "Francois Bachoc (1), Agnes Lagnoux (1), Thi Mong Ngoc Nguyen (1) ((1)\n  IMT)", "title": "Cross-validation estimation of covariance parameters under fixed-domain\n  asymptotics", "comments": null, "journal-ref": "Journal of Multivariate Analysis, Elsevier, 2017, 160, pp.42 - 67", "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a one-dimensional Gaussian process having exponential covariance\nfunction. Under fixed-domain asymptotics, we prove the strong consistency and\nasymptotic normality of a cross validation estimator of the microergodic\ncovariance parameter. In this setting, Ying [40] proved the same asymptotic\nproperties for the maximum likelihood estimator. Our proof includes several\noriginal or more involved components, compared to that of Ying. Also, while the\nasymptotic variance of maximum likelihood does not depend on the triangular\narray of observation points under consideration, that of cross validation does,\nand is shown to be lower and upper bounded. The lower bound coincides with the\nasymptotic variance of maximum likelihood. We provide examples of triangular\narrays of observation points achieving the lower and upper bounds. We\nillustrate our asymptotic results with simulations, and provide extensions to\nthe case of an unknown mean function. To our knowledge, this work constitutes\nthe first fixed-domain asymptotic analysis of cross validation.\n", "versions": [{"version": "v1", "created": "Mon, 10 Oct 2016 12:02:26 GMT"}, {"version": "v2", "created": "Tue, 25 Jul 2017 14:03:36 GMT"}], "update_date": "2017-07-26", "authors_parsed": [["Bachoc", "Francois", ""], ["Lagnoux", "Agnes", ""], ["Nguyen", "Thi Mong Ngoc", ""]]}, {"id": "1610.02987", "submitter": "Jelena Bradic", "authors": "Yinchu Zhu and Jelena Bradic", "title": "Linear Hypothesis Testing in Dense High-Dimensional Linear Models", "comments": "42 pages, 8 figures", "journal-ref": "Journal of the American Statistical Association: theory and\n  methods, 2017", "doi": "10.1080/01621459.2017.1356319", "report-no": null, "categories": "stat.ME cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a methodology for testing linear hypothesis in high-dimensional\nlinear models. The proposed test does not impose any restriction on the size of\nthe model, i.e. model sparsity or the loading vector representing the\nhypothesis. Providing asymptotically valid methods for testing general linear\nfunctions of the regression parameters in high-dimensions is extremely\nchallenging -- especially without making restrictive or unverifiable\nassumptions on the number of non-zero elements. We propose to test the moment\nconditions related to the newly designed restructured regression, where the\ninputs are transformed and augmented features. These new features incorporate\nthe structure of the null hypothesis directly. The test statistics are\nconstructed in such a way that lack of sparsity in the original model parameter\ndoes not present a problem for the theoretical justification of our procedures.\nWe establish asymptotically exact control on Type I error without imposing any\nsparsity assumptions on model parameter or the vector representing the linear\nhypothesis. Our method is also shown to achieve certain optimality in detecting\ndeviations from the null hypothesis. We demonstrate the favorable finite-sample\nperformance of the proposed methods, via a number of numerical and a real data\nexample.\n", "versions": [{"version": "v1", "created": "Mon, 10 Oct 2016 16:30:27 GMT"}, {"version": "v2", "created": "Tue, 3 Jan 2017 01:10:12 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Zhu", "Yinchu", ""], ["Bradic", "Jelena", ""]]}, {"id": "1610.03083", "submitter": "Luai Al Labadi Dr.", "authors": "Luai Al-Labadi", "title": "On Metrizing Vague Convergence of Random Measures with Applications on\n  Bayesian Nonparametric Models", "comments": "arXiv admin note: text overlap with arXiv:1411.3434 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with studying vague convergence of random measures of the\nform $\\mu_{n}=\\sum_{i=1}^{n} p_{i,n} \\delta_{\\theta_i}$, where\n$(\\theta_i)_{1\\le i \\le n}$ is a sequence of independent and identically\ndistributed random variables with common distribution $\\Pi$, $(p_{i,n})_{1 \\le\ni \\le n}$ are random variables chosen according to certain procedures and are\nindependent of $(\\theta_i)_{i \\geq 1}$ and $\\delta_{\\theta_i}$ denotes the\nDirac measure at $\\theta_i$. We show that $\\mu_{n}$ converges vaguely to\n$\\mu=\\sum_{i=1}^{\\infty} p_{i} \\delta_{\\theta_i}$ if and only if\n$\\mu^{(k)}_{n}=\\sum_{i=1}^{k} p_{i,n} \\delta_{\\theta_i}$ converges vaguely to\n$\\mu^{(k)}=\\sum_{i=1}^{k} p_{i} \\delta_{\\theta_i}$ for all $k$ fixed. The\nlimiting process $\\mu$ plays a central role in many areas in statistics,\nincluding Bayesian nonparametric models. A finite approximation of the beta\nprocess is derived from the application of this result. A simulated example is\nincorporated, in which the proposed approach exhibits an excellent performance\nover several existing algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 10 Oct 2016 20:25:26 GMT"}], "update_date": "2016-10-12", "authors_parsed": [["Al-Labadi", "Luai", ""]]}, {"id": "1610.03153", "submitter": "Rogemar Mamon", "authors": "Fuqi Chen, Rogemar Mamon, Severien Nkurunziza", "title": "Determination of a structural break in a mean-reverting process", "comments": "31 pages, 15 figures, 11 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Determining accurately when regime and structural changes occur in various\ntime-series data is critical in many social and natural sciences. We develop\nand show further the equivalence of two consistent estimation techniques in\nlocating the change point under the framework of a generalised version of the\nOrnstein-Uhlehnbeck process. Our methods are based on the least sum of squared\nerror and the maximum log-likelihood approaches. The case where both the\nexistence and the location of the change point are unknown is investigated and\nan informational methodology is employed to address these issues. Numerical\nillustrations are presented to assess the performance of the methods.\n", "versions": [{"version": "v1", "created": "Tue, 11 Oct 2016 01:47:45 GMT"}, {"version": "v2", "created": "Mon, 29 May 2017 06:48:17 GMT"}, {"version": "v3", "created": "Tue, 30 May 2017 00:58:14 GMT"}], "update_date": "2017-05-31", "authors_parsed": [["Chen", "Fuqi", ""], ["Mamon", "Rogemar", ""], ["Nkurunziza", "Severien", ""]]}, {"id": "1610.03215", "submitter": "Leonie Selk", "authors": "Marie Hu\\v{s}kov\\'a, Natalie Neumeyer, Tobias Niebuhr, Leonie Selk", "title": "Specification testing in nonparametric AR-ARCH models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper an autoregressive time series model with conditional\nheteroscedasticity is considered, where both conditional mean and conditional\nvariance function are modeled nonparametrically. A test for the model\nassumption of independence of innovations from past time series values is\nsuggested. The test is based on an weighted $L^2$-distance of empirical\ncharacteristic functions. The asymptotic distribution under the null hypothesis\nof independence is derived and consistency against fixed alternatives is shown.\nA smooth autoregressive residual bootstrap procedure is suggested and its\nperformance is shown in a simulation study.\n", "versions": [{"version": "v1", "created": "Tue, 11 Oct 2016 07:07:53 GMT"}], "update_date": "2016-10-12", "authors_parsed": [["Hu\u0161kov\u00e1", "Marie", ""], ["Neumeyer", "Natalie", ""], ["Niebuhr", "Tobias", ""], ["Selk", "Leonie", ""]]}, {"id": "1610.03316", "submitter": "Guillame Papa", "authors": "Cl\\'emen\\c{c}on Stephan and Patrice Bertail and Guillaume Papa", "title": "Learning from Survey Training Samples: Rate Bounds for Horvitz-Thompson\n  Risk Minimizers", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The generalization ability of minimizers of the empirical risk in the context\nof binary classification has been investigated under a wide variety of\ncomplexity assumptions for the collection of classifiers over which\noptimization is performed. In contrast, the vast majority of the works\ndedicated to this issue stipulate that the training dataset used to compute the\nempirical risk functional is composed of i.i.d. observations. Beyond the cases\nwhere training data are drawn uniformly without replacement among a large\ni.i.d. sample or modelled as a realization of a weakly dependent sequence of\nr.v.'s, statistical guarantees when the data used to train a classifier are\ndrawn by means of a more general sampling/survey scheme and exhibit a complex\ndependence structure have not been documented yet. It is the main purpose of\nthis paper to show that the theory of empirical risk minimization can be\nextended to situations where statistical learning is based on survey samples\nand knowledge of the related inclusion probabilities. Precisely, we prove that\nminimizing a weighted version of the empirical risk, refered to as the\nHorvitz-Thompson risk (HT risk), over a class of controlled complexity lead to\na rate for the excess risk of the order $O_{\\mathbb{P}}((\\kappa_N (\\log\nN)/n)^{1/2})$ with $\\kappa_N=(n/N)/\\min_{i\\leq N}\\pi_i$, when data are sampled\nby means of a rejective scheme of (deterministic) size $n$ within a statistical\npopulation of cardinality $N\\geq n$, a generalization of basic {\\it sampling\nwithout replacement} with unequal probability weights $\\pi_i>0$. Extension to\nother sampling schemes are then established by a coupling argument. Beyond\ntheoretical results, numerical experiments are displayed in order to show the\nrelevance of HT risk minimization and that ignoring the sampling scheme used to\ngenerate the training dataset may completely jeopardize the learning procedure.\n", "versions": [{"version": "v1", "created": "Tue, 11 Oct 2016 13:04:17 GMT"}, {"version": "v2", "created": "Fri, 18 Jan 2019 10:45:01 GMT"}], "update_date": "2019-01-21", "authors_parsed": [["Stephan", "Cl\u00e9men\u00e7on", ""], ["Bertail", "Patrice", ""], ["Papa", "Guillaume", ""]]}, {"id": "1610.03375", "submitter": "Riet van Bork", "authors": "Riet van Bork, Raoul P. P. P. Grasman, and Lourens J. Waldorp", "title": "Unidimensional factor models imply weaker partial correlations than\n  zero-order correlations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a unidimensional factor model it is assumed that the set of indicators\nthat loads on this factor are conditionally independent given the latent\nfactor. Two indicators are, however, never conditionally independent given (a\nset of) other indicators that load on this factor, as this would require one of\nthe indicators that is conditioned on to correlate one with the latent factor.\nAlthough partial correlations between two indicators given the other indicators\ncan thus never equal zero (Holland and Rosenbaum, 1986), we show in this paper\nthat the partial correlations do need to be always weaker than the zero-order\ncorrelations. More precisely, we prove that the partial correlation between two\nobserved variables that load on one factor given all other observed variables\nthat load on this factor, is always closer to zero than the zero-order\ncorrelation between these two variables.\n", "versions": [{"version": "v1", "created": "Tue, 11 Oct 2016 14:51:58 GMT"}, {"version": "v2", "created": "Wed, 12 Oct 2016 12:02:35 GMT"}], "update_date": "2016-10-13", "authors_parsed": [["van Bork", "Riet", ""], ["Grasman", "Raoul P. P. P.", ""], ["Waldorp", "Lourens J.", ""]]}, {"id": "1610.03555", "submitter": "George Yanev", "authors": "George P. Yanev and Roberto Colson", "title": "Monotone Empirical Bayes Estimators for the Reproduction Number in\n  Borel-Tanner Distribution", "comments": "17th International Summer Conference on Probability and Statistics,\n  Pomorie, Bulgaria, 25 June to 1 July, 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A monotone version of an empirical Bayes estimator for the parameter of the\nBorel-Tanner distribution is constructed. Some properties of the estimator's\nregret risk are illustrated through simulations.\n", "versions": [{"version": "v1", "created": "Tue, 11 Oct 2016 22:58:02 GMT"}], "update_date": "2016-10-13", "authors_parsed": [["Yanev", "George P.", ""], ["Colson", "Roberto", ""]]}, {"id": "1610.03595", "submitter": "David Hong", "authors": "David Hong, Laura Balzano, Jeffrey A. Fessler", "title": "Towards a Theoretical Analysis of PCA for Heteroscedastic Data", "comments": "Presented at 54th Annual Allerton Conference on Communication,\n  Control, and Computing (Allerton)", "journal-ref": null, "doi": "10.1109/ALLERTON.2016.7852272", "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Principal Component Analysis (PCA) is a method for estimating a subspace\ngiven noisy samples. It is useful in a variety of problems ranging from\ndimensionality reduction to anomaly detection and the visualization of high\ndimensional data. PCA performs well in the presence of moderate noise and even\nwith missing data, but is also sensitive to outliers. PCA is also known to have\na phase transition when noise is independent and identically distributed;\nrecovery of the subspace sharply declines at a threshold noise variance.\nEffective use of PCA requires a rigorous understanding of these behaviors. This\npaper provides a step towards an analysis of PCA for samples with\nheteroscedastic noise, that is, samples that have non-uniform noise variances\nand so are no longer identically distributed. In particular, we provide a\nsimple asymptotic prediction of the recovery of a one-dimensional subspace from\nnoisy heteroscedastic samples. The prediction enables: a) easy and efficient\ncalculation of the asymptotic performance, and b) qualitative reasoning to\nunderstand how PCA is impacted by heteroscedasticity (such as outliers).\n", "versions": [{"version": "v1", "created": "Wed, 12 Oct 2016 04:13:03 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Hong", "David", ""], ["Balzano", "Laura", ""], ["Fessler", "Jeffrey A.", ""]]}, {"id": "1610.03694", "submitter": "Masaaki Fukasawa", "authors": "Alexandre Brouste and Masaaki Fukasawa", "title": "Local asymptotic normality property for fractional Gaussian noise under\n  high-frequency observations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Local Asymptotic Normality (LAN) property for fractional Gaussian noise under\nhigh-frequency observations is proved with a non-diagonal rate matrix depending\non the parameter to be estimated. In contrast to the LAN families in the\nliterature, non-diagonal rate matrices are inevitable.\n", "versions": [{"version": "v1", "created": "Wed, 12 Oct 2016 13:02:12 GMT"}], "update_date": "2016-10-13", "authors_parsed": [["Brouste", "Alexandre", ""], ["Fukasawa", "Masaaki", ""]]}, {"id": "1610.03776", "submitter": "St\\'ephan Cl\\'emen\\c{c}on", "authors": "Patrice Bertail and Stephan Cl\\'emen\\c{c}on", "title": "Sharp exponential inequalities in survey sampling: conditional Poisson\n  sampling schemes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is devoted to establishing exponential bounds for the\nprobabilities of deviation of a sample sum from its expectation, when the\nvariables involved in the summation are obtained by sampling in a finite\npopulation according to a rejective scheme, generalizing sampling without\nreplacement, and by using an appropriate normalization. In contrast to Poisson\nsampling, classical deviation inequalities in the i.i.d. setting do not\nstraightforwardly apply to sample sums related to rejective schemes, due to the\ninherent dependence structure of the sampled points. We show here how to\novercome this difficulty, by combining the formulation of rejective sampling as\nPoisson sampling conditioned upon the sample size with the Escher\ntransformation. In particular, the Bennett/Bernstein type bounds established\nhighlight the effect of the asymptotic variance of the (properly standardized)\nsample weighted sum and are shown to be much more accurate than those based on\nthe negative association property shared by the terms involved in the\nsummation. Beyond its interest in itself, such a result for rejective sampling\nis crucial, insofar as it can be extended to many other sampling schemes,\nnamely those that can be accurately approximated by rejective plans in the\nsense of the total variation distance.\n", "versions": [{"version": "v1", "created": "Wed, 12 Oct 2016 16:34:44 GMT"}], "update_date": "2016-10-13", "authors_parsed": [["Bertail", "Patrice", ""], ["Cl\u00e9men\u00e7on", "Stephan", ""]]}, {"id": "1610.03783", "submitter": "Valeriy Avanesov", "authors": "Valeriy Avanesov and Nazar Buzun", "title": "Change-point detection in high-dimensional covariance structure", "comments": "Acknowledgement correction", "journal-ref": "Electron. J. Statist. Volume 12, Number 2 (2018), 3254-3294", "doi": "10.1214/18-EJS1484", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce a novel approach for an important problem of break\ndetection. Specifically, we are interested in detection of an abrupt change in\nthe covariance structure of a high-dimensional random process -- a problem,\nwhich has applications in many areas e.g., neuroimaging and finance. The\ndeveloped approach is essentially a testing procedure involving a choice of a\ncritical level. To that end a non-standard bootstrap scheme is proposed and\ntheoretically justified under mild assumptions. Theoretical study features a\nresult providing guaranties for break detection. All the theoretical results\nare established in a high-dimensional setting (dimensionality $p \\gg n$).\nMultiscale nature of the approach allows for a trade-off between sensitivity of\nbreak detection and localization. The approach can be naturally employed in an\non-line setting. Simulation study demonstrates that the approach matches the\nnominal level of false alarm probability and exhibits high power, outperforming\na recent approach.\n", "versions": [{"version": "v1", "created": "Wed, 12 Oct 2016 16:46:56 GMT"}, {"version": "v2", "created": "Mon, 21 Nov 2016 19:44:11 GMT"}, {"version": "v3", "created": "Tue, 28 Mar 2017 15:14:17 GMT"}, {"version": "v4", "created": "Wed, 3 May 2017 13:36:51 GMT"}, {"version": "v5", "created": "Sat, 29 Sep 2018 19:17:46 GMT"}, {"version": "v6", "created": "Wed, 29 Jul 2020 11:20:22 GMT"}], "update_date": "2020-07-30", "authors_parsed": [["Avanesov", "Valeriy", ""], ["Buzun", "Nazar", ""]]}, {"id": "1610.03819", "submitter": "Haizhao Yang", "authors": "Jieren Xu and Haizhao Yang and Ingrid Daubechies", "title": "Recursive Diffeomorphism-Based Regression for Shape Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.CV math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a recursive diffeomorphism based regression method for\none-dimensional generalized mode decomposition problem that aims at extracting\ngeneralized modes $\\alpha_k(t)s_k(2\\pi N_k\\phi_k(t))$ from their superposition\n$\\sum_{k=1}^K \\alpha_k(t)s_k(2\\pi N_k\\phi_k(t))$. First, a one-dimensional\nsynchrosqueezed transform is applied to estimate instantaneous information,\ne.g., $\\alpha_k(t)$ and $N_k\\phi_k(t)$. Second, a novel approach based on\ndiffeomorphisms and nonparametric regression is proposed to estimate wave shape\nfunctions $s_k(t)$. These two methods lead to a framework for the generalized\nmode decomposition problem under a weak well-separation condition. Numerical\nexamples of synthetic and real data are provided to demonstrate the fruitful\napplications of these methods.\n", "versions": [{"version": "v1", "created": "Wed, 12 Oct 2016 18:43:51 GMT"}, {"version": "v2", "created": "Sat, 29 Jul 2017 04:44:15 GMT"}], "update_date": "2017-08-01", "authors_parsed": [["Xu", "Jieren", ""], ["Yang", "Haizhao", ""], ["Daubechies", "Ingrid", ""]]}, {"id": "1610.03944", "submitter": "Kenneth Hung", "authors": "Kenneth Hung and William Fithian", "title": "Rank Verification for Exponential Families", "comments": null, "journal-ref": "Ann. Statist., Volume 47, Number 2 (2019), 758-782", "doi": "10.1214/17-AOS1634", "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many statistical experiments involve comparing multiple population groups.\nFor example, a public opinion poll may ask which of several political\ncandidates commands the most support; a social scientific survey may report the\nmost common of several responses to a question; or, a clinical trial may\ncompare binary patient outcomes under several treatment conditions to determine\nthe most effective treatment. Having observed the \"winner\" (largest observed\nresponse) in a noisy experiment, it is natural to ask whether that candidate,\nsurvey response, or treatment is actually the \"best\" (stochastically largest\nresponse). This article concerns the problem of rank verification --- post hoc\nsignificance tests of whether the orderings discovered in the data reflect the\npopulation ranks. For exponential family models, we show under mild conditions\nthat an unadjusted two-tailed pairwise test comparing the top two observations\n(i.e., comparing the \"winner\" to the \"runner-up\") is a valid test of whether\nthe winner is truly the best. We extend our analysis to provide equally simple\nprocedures to obtain lower confidence bounds on the gap between the winning\npopulation and the others, and to verify ranks beyond the first.\n", "versions": [{"version": "v1", "created": "Thu, 13 Oct 2016 05:34:30 GMT"}, {"version": "v2", "created": "Mon, 3 Jul 2017 17:37:37 GMT"}], "update_date": "2019-03-20", "authors_parsed": [["Hung", "Kenneth", ""], ["Fithian", "William", ""]]}, {"id": "1610.03945", "submitter": "Tomoki Tokuda", "authors": "Tomoki Tokuda", "title": "Statistical test for detecting community structure in real-valued\n  edge-weighted graphs", "comments": null, "journal-ref": "PLOS ONE, 13(3), 2018", "doi": "10.1371/journal.pone.0194079", "report-no": null, "categories": "math.ST cs.SI physics.soc-ph stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel method to test the existence of community structure of\nundirected real-valued edge-weighted graph. The method is based on Wigner\nsemicircular law on the asymptotic behavior of the random distribution for\neigenvalues of a real symmetric matrix. We provide a theoretical foundation for\nthis method and report on its performance in synthetic and real data,\nsuggesting that our method outperforms other state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Thu, 13 Oct 2016 06:00:03 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Tokuda", "Tomoki", ""]]}, {"id": "1610.04052", "submitter": "Maeva Biret", "authors": "Maeva Biret (LSTA), Michel Broniatowski (LSTA), Zangsheng Cao", "title": "A Gibbs Conditional theorem under extreme deviation", "comments": "arXiv admin note: text overlap with arXiv:1206.6951, arXiv:1305.3482", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore some properties of the conditional distribution of an i.i.d.\nsample under large exceedances of its sum. Thresholds for the asymptotic\nindependance of the summands are observed, in contrast with the classical case\nwhen the conditioning event is in the range of a large deviation. This paper is\nan extension to [7]. Tools include a new Edgeworth expansion adapted to\nspecific triangular arrays where the rows are generated by tilted distribution\nwith diverging parameters, together with some Abelian type results.\n", "versions": [{"version": "v1", "created": "Thu, 13 Oct 2016 12:38:25 GMT"}], "update_date": "2016-10-14", "authors_parsed": [["Biret", "Maeva", "", "LSTA"], ["Broniatowski", "Michel", "", "LSTA"], ["Cao", "Zangsheng", ""]]}, {"id": "1610.04056", "submitter": "Paul Escande", "authors": "J\\'er\\'emie Bigot (1), Paul Escande (2,3), Pierre Weiss (3,4) ((1)\n  IMB, (2) DISC, (3) ITAV, (4) IMT)", "title": "Estimation of linear operators from scattered impulse responses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT math.NA math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a new estimator of integral operators with smooth kernels,\nobtained from a set of scattered and noisy impulse responses. The proposed\napproach relies on the formalism of smoothing in reproducing kernel Hilbert\nspaces and on the choice of an appropriate regularization term that takes the\nsmoothness of the operator into account. It is numerically tractable in very\nlarge dimensions. We study the estimator's robustness to noise and analyze its\napproximation properties with respect to the size and the geometry of the\ndataset. In addition, we show minimax optimality of the proposed estimator.\n", "versions": [{"version": "v1", "created": "Thu, 13 Oct 2016 12:48:06 GMT"}, {"version": "v2", "created": "Fri, 1 Dec 2017 10:13:49 GMT"}], "update_date": "2017-12-04", "authors_parsed": [["Bigot", "J\u00e9r\u00e9mie", ""], ["Escande", "Paul", ""], ["Weiss", "Pierre", ""]]}, {"id": "1610.04093", "submitter": "Simon Holbach", "authors": "Simon Holbach", "title": "Local Asymptotic Normality for Shape and Periodicity in the Drift of a\n  Time Inhomogeneous Diffusion", "comments": null, "journal-ref": null, "doi": "10.1007/s11203-017-9157-5", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a one-dimensional diffusion whose drift contains a deterministic\nperiodic signal with unknown periodicity $T$ and carrying some unknown\n$d$-dimensional shape parameter $\\theta$. We prove Local Asymptotic Normality\n(LAN) jointly in $\\theta$ and $T$ for the statistical experiment arising from\ncontinuous observation of this diffusion. The local scale turns out to be\n$n^{-1/2}$ for the shape parameter and $n^{-3/2}$ for the periodicity which\ngeneralizes known results about LAN when either $\\theta$ or $T$ is assumed to\nbe known.\n", "versions": [{"version": "v1", "created": "Thu, 13 Oct 2016 14:17:44 GMT"}, {"version": "v2", "created": "Mon, 16 Jan 2017 11:59:07 GMT"}], "update_date": "2017-01-17", "authors_parsed": [["Holbach", "Simon", ""]]}, {"id": "1610.04135", "submitter": "Sherzod Mirakhmedov", "authors": "Sherzod M. Mirakhmedov", "title": "Asymptotic Intermediate Efficiency of the Chi-square and Likelihood\n  Ratio Goodness of Fit Tests", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of testing the goodness of fit of an absolutely continuous\ndistribution to a set of observations grouped into equal probability intervals,\nagainst to a family of sequences of alternatives approaching the hypothesis is\nconsidered. We focus our study to the asymptotic intermediate efficiency (AIE)\ndue to Inglot (1999) of the chi-squared and log-likelihood ratio tests. It is\nassumed that the number of groups increases together with the number of\nobservations.\n", "versions": [{"version": "v1", "created": "Thu, 13 Oct 2016 15:44:56 GMT"}, {"version": "v2", "created": "Mon, 20 Nov 2017 14:06:39 GMT"}, {"version": "v3", "created": "Thu, 21 Feb 2019 07:59:13 GMT"}], "update_date": "2019-02-22", "authors_parsed": [["Mirakhmedov", "Sherzod M.", ""]]}, {"id": "1610.04199", "submitter": "Tobias Siems", "authors": "Tobias Siems and Marc Hellmuth and Volkmar Liebscher", "title": "Simultaneous Credible Regions for Multiple Changepoint Locations", "comments": null, "journal-ref": "Journal of Computational and Graphical Statistics 2018", "doi": "10.1080/10618600.2018.1513366", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Within a Bayesian retrospective framework, we present a way of examining the\ndistribution of \\cps through a novel set estimator. For a given level,\n$\\alpha$, we aim at smallest sets that cover all \\cps with a probability of at\nleast $1-\\alpha$. These so-called smallest simultaneous credible regions,\ncomputed for certain values of $\\alpha$, provide parsimonious representations\nof the possible \\cp locations. In addition, combining them for a range of\ndifferent $\\alpha$'s enables very informative yet condensed visualisations.\nTherewith we allow for the evaluation of model choices and the analysis of \\cp\ndata to an unprecedented degree. This approach exhibits superior sensitivity,\nspecificity and interpretability in comparison with highest density regions,\nmarginal inclusion probabilities and confidence intervals inferred by \\stepR.\nWhilst their direct construction is usually intractable, asymptotically correct\nsolutions can be derived from posterior samples. This leads to a novel\nNP-complete problem. Through reformulations into an Integer Linear Program we\nshow empirically that a fast greedy heuristic computes virtually exact\nsolutions.\n", "versions": [{"version": "v1", "created": "Thu, 13 Oct 2016 18:59:49 GMT"}, {"version": "v2", "created": "Fri, 14 Oct 2016 08:19:07 GMT"}, {"version": "v3", "created": "Tue, 27 Jun 2017 11:02:10 GMT"}, {"version": "v4", "created": "Mon, 3 Sep 2018 12:34:46 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Siems", "Tobias", ""], ["Hellmuth", "Marc", ""], ["Liebscher", "Volkmar", ""]]}, {"id": "1610.04336", "submitter": "Michael Brand", "authors": "Michael Brand", "title": "MML is not consistent for Neyman-Scott", "comments": "16 pages, 0 tables, 0 figures", "journal-ref": null, "doi": "10.1109/TIT.2019.2943464", "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Strict Minimum Message Length (SMML) is an information-theoretic statistical\ninference method widely cited (but only with informal arguments) as providing\nestimations that are consistent for general estimation problems. It is,\nhowever, almost invariably intractable to compute, for which reason only\napproximations of it (known as MML algorithms) are ever used in practice. Using\nnovel techniques that allow for the first time direct, non-approximated\nanalysis of SMML solutions, we investigate the Neyman-Scott estimation problem,\nan oft-cited showcase for the consistency of MML, and show that even with a\nnatural choice of prior neither SMML nor its popular approximations are\nconsistent for it, thereby providing a counterexample to the general claim.\nThis is the first known explicit construction of an SMML solution for a\nnatural, high-dimensional problem.\n", "versions": [{"version": "v1", "created": "Fri, 14 Oct 2016 06:07:45 GMT"}, {"version": "v2", "created": "Thu, 9 Feb 2017 12:04:50 GMT"}, {"version": "v3", "created": "Tue, 2 May 2017 15:25:59 GMT"}, {"version": "v4", "created": "Wed, 19 Jul 2017 13:20:52 GMT"}, {"version": "v5", "created": "Mon, 6 Jan 2020 05:43:12 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Brand", "Michael", ""]]}, {"id": "1610.04580", "submitter": "Jelena Bradic", "authors": "Yinchu Zhu and Jelena Bradic", "title": "Two-sample testing in non-sparse high-dimensional linear models", "comments": "55 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In analyzing high-dimensional models, sparsity of the model parameter is a\ncommon but often undesirable assumption. In this paper, we study the following\ntwo-sample testing problem: given two samples generated by two high-dimensional\nlinear models, we aim to test whether the regression coefficients of the two\nlinear models are identical. We propose a framework named TIERS (short for\nTestIng Equality of Regression Slopes), which solves the two-sample testing\nproblem without making any assumptions on the sparsity of the regression\nparameters. TIERS builds a new model by convolving the two samples in such a\nway that the original hypothesis translates into a new moment condition. A\nself-normalization construction is then developed to form a moment test. We\nprovide rigorous theory for the developed framework. Under very weak conditions\nof the feature covariance, we show that the accuracy of the proposed test in\ncontrolling Type I errors is robust both to the lack of sparsity in the\nfeatures and to the heavy tails in the error distribution, even when the sample\nsize is much smaller than the feature dimension. Moreover, we discuss minimax\noptimality and efficiency properties of the proposed test. Simulation analysis\ndemonstrates excellent finite-sample performance of our test. In deriving the\ntest, we also develop tools that are of independent interest. The test is built\nupon a novel estimator, called Auto-aDaptive Dantzig Selector (ADDS), which not\nonly automatically chooses an appropriate scale of the error term but also\nincorporates prior information. To effectively approximate the critical value\nof the test statistic, we develop a novel high-dimensional plug-in approach\nthat complements the recent advances in Gaussian approximation theory.\n", "versions": [{"version": "v1", "created": "Fri, 14 Oct 2016 18:51:34 GMT"}], "update_date": "2017-08-16", "authors_parsed": [["Zhu", "Yinchu", ""], ["Bradic", "Jelena", ""]]}, {"id": "1610.04599", "submitter": "Yao Xie", "authors": "Shuang Li, Yao Xie, and Le Song", "title": "Data-Driven Threshold Machine: Scan Statistics, Change-Point Detection,\n  and Extreme Bandits", "comments": "Submitted to conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel distribution-free approach, the data-driven threshold\nmachine (DTM), for a fundamental problem at the core of many learning tasks:\nchoose a threshold for a given pre-specified level that bounds the tail\nprobability of the maximum of a (possibly dependent but stationary) random\nsequence. We do not assume data distribution, but rather relying on the\nasymptotic distribution of extremal values, and reduce the problem to estimate\nthree parameters of the extreme value distributions and the extremal index. We\nspecially take care of data dependence via estimating extremal index since in\nmany settings, such as scan statistics, change-point detection, and extreme\nbandits, where dependence in the sequence of statistics can be significant. Key\nfeatures of our DTM also include robustness and the computational efficiency,\nand it only requires one sample path to form a reliable estimate of the\nthreshold, in contrast to the Monte Carlo sampling approach which requires\ndrawing a large number of sample paths. We demonstrate the good performance of\nDTM via numerical examples in various dependent settings.\n", "versions": [{"version": "v1", "created": "Fri, 14 Oct 2016 19:43:16 GMT"}], "update_date": "2016-10-17", "authors_parsed": [["Li", "Shuang", ""], ["Xie", "Yao", ""], ["Song", "Le", ""]]}, {"id": "1610.04659", "submitter": "Amir Sepehri", "authors": "Amir Sepehri", "title": "Cauchy Identities for the Characters of the Compact Classical Groups", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.RT math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by statistical applications, this paper introduces Cauchy\nidentities for characters of the compact classical groups. These identities\ngeneralize the well-known Cauchy identity for characters of the unitary group,\nwhich are Schur functions of symmetric function theory. Application to\nstatistical hypothesis testing is briefly sketched.\n", "versions": [{"version": "v1", "created": "Fri, 14 Oct 2016 22:04:07 GMT"}, {"version": "v2", "created": "Thu, 17 Nov 2016 19:39:54 GMT"}], "update_date": "2016-11-18", "authors_parsed": [["Sepehri", "Amir", ""]]}, {"id": "1610.04821", "submitter": "Xinran Li", "authors": "Xinran Li and Peng Ding", "title": "General forms of finite population central limit theorems with\n  applications to causal inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Frequentists' inference often delivers point estimators associated with\nconfidence intervals or sets for parameters of interest. Constructing the\nconfidence intervals or sets requires understanding the sampling distributions\nof the point estimators, which, in many but not all cases, are related to\nasymptotic Normal distributions ensured by central limit theorems. Although\nprevious literature has established various forms of central limit theorems for\nstatistical inference in super population models, we still need general and\nconvenient forms of central limit theorems for some randomization-based causal\nanalysis of experimental data, where the parameters of interests are functions\nof a finite population and randomness comes solely from the treatment\nassignment. We use central limit theorems for sample surveys and rank\nstatistics to establish general forms of the finite population central limit\ntheorems that are particularly useful for proving asymptotic distributions of\nrandomization tests under the sharp null hypothesis of zero individual causal\neffects, and for obtaining the asymptotic repeated sampling distributions of\nthe causal effect estimators. The new central limit theorems hold for general\nexperimental designs with multiple treatment levels and multiple treatment\nfactors, and are immediately applicable for studying the asymptotic properties\nof many methods in causal inference, including instrumental variable,\nregression adjustment, rerandomization, clustered randomized experiments, and\nso on. Previously, the asymptotic properties of these problems are often based\non heuristic arguments, which in fact rely on general forms of finite\npopulation central limit theorems that have not been established before. Our\nnew theorems fill in this gap by providing more solid theoretical foundation\nfor asymptotic randomization-based causal inference.\n", "versions": [{"version": "v1", "created": "Sun, 16 Oct 2016 05:16:21 GMT"}], "update_date": "2016-10-18", "authors_parsed": [["Li", "Xinran", ""], ["Ding", "Peng", ""]]}, {"id": "1610.05022", "submitter": "Pierre Gaillard", "authors": "Pierre Gaillard and Olivier Wintenberger", "title": "Sparse Accelerated Exponential Weights", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the stochastic optimization problem where a convex function is\nminimized observing recursively the gradients. We introduce SAEW, a new\nprocedure that accelerates exponential weights procedures with the slow rate\n$1/\\sqrt{T}$ to procedures achieving the fast rate $1/T$. Under the strong\nconvexity of the risk, we achieve the optimal rate of convergence for\napproximating sparse parameters in $\\mathbb{R}^d$. The acceleration is achieved\nby using successive averaging steps in an online fashion. The procedure also\nproduces sparse estimators thanks to additional hard threshold steps.\n", "versions": [{"version": "v1", "created": "Mon, 17 Oct 2016 09:14:34 GMT"}], "update_date": "2016-10-18", "authors_parsed": [["Gaillard", "Pierre", ""], ["Wintenberger", "Olivier", ""]]}, {"id": "1610.05225", "submitter": "Randolf Altmeyer", "authors": "Randolf Altmeyer, Jakub Chorowski", "title": "Estimation error for occupation time functionals of stationary Markov\n  processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The approximation of integral functionals with respect to a stationary Markov\nprocess by a Riemann-sum estimator is studied. Stationarity and the functional\ncalculus of the infinitesimal generator of the process are used to get a better\nunderstanding of the estimation error and to prove a general error bound. The\npresented approach admits general integrands and gives a unifying explanation\nfor different rates obtained in the literature. Several examples demonstrate\nhow the general bound can be related to well-known function spaces.\n", "versions": [{"version": "v1", "created": "Mon, 17 Oct 2016 17:44:23 GMT"}], "update_date": "2016-10-18", "authors_parsed": [["Altmeyer", "Randolf", ""], ["Chorowski", "Jakub", ""]]}, {"id": "1610.05232", "submitter": "Tomoaki Imoto", "authors": "Imoto Tomoaki, Ng Choung Min, Ong Seng Huat, Subrata Chakraborty", "title": "A modified Conway-Maxwell-Poisson type binomial distribution and its\n  applications", "comments": "Under submitting to Communications in Statistics - Theory and Methods", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a generalized binomial distribution with four parameters,\nwhich is derived from the finite capacity queueing system with state-dependent\nservice and arrival rates. This distribution is also generated from the\nconditional Conway-Maxwell-Poisson distribution given a sum of two\nConway-Maxwell-Poisson variables. In this paper, we consider the properties\nabout the probability mass function, index of dispersion, skewness and kurtosis\nand give applications of the proposed distribution from its geneses. The\nestimation method and simulation study are also considered.\n", "versions": [{"version": "v1", "created": "Mon, 17 Oct 2016 17:59:08 GMT"}], "update_date": "2016-10-18", "authors_parsed": [["Tomoaki", "Imoto", ""], ["Min", "Ng Choung", ""], ["Huat", "Ong Seng", ""], ["Chakraborty", "Subrata", ""]]}, {"id": "1610.05246", "submitter": "Kai Zhang", "authors": "Kai Zhang", "title": "BET on Independence", "comments": null, "journal-ref": null, "doi": "10.1080/01621459.2018.1537921", "report-no": null, "categories": "math.ST cs.LG stat.CO stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of nonparametric dependence detection. Many existing\nmethods may suffer severe power loss due to non-uniform consistency, which we\nillustrate with a paradox. To avoid such power loss, we approach the\nnonparametric test of independence through the new framework of binary\nexpansion statistics (BEStat) and binary expansion testing (BET), which examine\ndependence through a novel binary expansion filtration approximation of the\ncopula. Through a Hadamard transform, we find that the symmetry statistics in\nthe filtration are complete sufficient statistics for dependence. These\nstatistics are also uncorrelated under the null. By utilizing symmetry\nstatistics, the BET avoids the problem of non-uniform consistency and improves\nupon a wide class of commonly used methods (a) by achieving the minimax rate in\nsample size requirement for reliable power and (b) by providing clear\ninterpretations of global relationships upon rejection of independence. The\nbinary expansion approach also connects the symmetry statistics with the\ncurrent computing system to facilitate efficient bitwise implementation. We\nillustrate the BET with a study of the distribution of stars in the night sky\nand with an exploratory data analysis of the TCGA breast cancer data.\n", "versions": [{"version": "v1", "created": "Mon, 17 Oct 2016 18:19:49 GMT"}, {"version": "v2", "created": "Thu, 12 Jan 2017 03:26:00 GMT"}, {"version": "v3", "created": "Thu, 26 Jan 2017 07:09:37 GMT"}, {"version": "v4", "created": "Sun, 23 Apr 2017 02:08:08 GMT"}, {"version": "v5", "created": "Mon, 20 Nov 2017 15:57:14 GMT"}, {"version": "v6", "created": "Sun, 13 May 2018 02:25:46 GMT"}, {"version": "v7", "created": "Mon, 15 Apr 2019 20:39:38 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Zhang", "Kai", ""]]}, {"id": "1610.05448", "submitter": "Ning Xu", "authors": "Ning Xu, Jian Hong, Timothy C.G. Fisher", "title": "Generalization error minimization: a new approach to model evaluation\n  and selection with an application to penalized regression", "comments": "The theoretical generalization and extension of arXiv:1606.00142 and\n  arXiv:1609.03344", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML math.ST q-fin.EC stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study model evaluation and model selection from the perspective of\ngeneralization ability (GA): the ability of a model to predict outcomes in new\nsamples from the same population. We believe that GA is one way formally to\naddress concerns about the external validity of a model. The GA of a model\nestimated on a sample can be measured by its empirical out-of-sample errors,\ncalled the generalization errors (GE). We derive upper bounds for the GE, which\ndepend on sample sizes, model complexity and the distribution of the loss\nfunction. The upper bounds can be used to evaluate the GA of a model, ex ante.\nWe propose using generalization error minimization (GEM) as a framework for\nmodel selection. Using GEM, we are able to unify a big class of penalized\nregression estimators, including lasso, ridge and bridge, under the same set of\nassumptions. We establish finite-sample and asymptotic properties (including\n$\\mathcal{L}_2$-consistency) of the GEM estimator for both the $n \\geqslant p$\nand the $n < p$ cases. We also derive the $\\mathcal{L}_2$-distance between the\npenalized and corresponding unpenalized regression estimates. In practice, GEM\ncan be implemented by validation or cross-validation. We show that the GE\nbounds can be used for selecting the optimal number of folds in $K$-fold\ncross-validation. We propose a variant of $R^2$, the $GR^2$, as a measure of\nGA, which considers both both in-sample and out-of-sample goodness of fit.\nSimulations are used to demonstrate our key results.\n", "versions": [{"version": "v1", "created": "Tue, 18 Oct 2016 06:26:47 GMT"}], "update_date": "2016-10-19", "authors_parsed": [["Xu", "Ning", ""], ["Hong", "Jian", ""], ["Fisher", "Timothy C. G.", ""]]}, {"id": "1610.05627", "submitter": "Karthyek Murthy", "authors": "Jose Blanchet, Yang Kang, and Karthyek Murthy", "title": "Robust Wasserstein Profile Inference and Applications to Machine\n  Learning", "comments": null, "journal-ref": "Journal of Applied Probability, 56(3), 830-857 (2019)", "doi": "10.1017/jpr.2019.49", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that several machine learning estimators, including square-root LASSO\n(Least Absolute Shrinkage and Selection) and regularized logistic regression\ncan be represented as solutions to distributionally robust optimization (DRO)\nproblems. The associated uncertainty regions are based on suitably defined\nWasserstein distances. Hence, our representations allow us to view\nregularization as a result of introducing an artificial adversary that perturbs\nthe empirical distribution to account for out-of-sample effects in loss\nestimation. In addition, we introduce RWPI (Robust Wasserstein Profile\nInference), a novel inference methodology which extends the use of methods\ninspired by Empirical Likelihood to the setting of optimal transport costs (of\nwhich Wasserstein distances are a particular case). We use RWPI to show how to\noptimally select the size of uncertainty regions, and as a consequence, we are\nable to choose regularization parameters for these machine learning estimators\nwithout the use of cross validation. Numerical experiments are also given to\nvalidate our theoretical findings.\n", "versions": [{"version": "v1", "created": "Tue, 18 Oct 2016 14:17:31 GMT"}, {"version": "v2", "created": "Sat, 25 Feb 2017 17:30:56 GMT"}, {"version": "v3", "created": "Tue, 26 Mar 2019 16:00:23 GMT"}, {"version": "v4", "created": "Wed, 21 Oct 2020 15:59:49 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Blanchet", "Jose", ""], ["Kang", "Yang", ""], ["Murthy", "Karthyek", ""]]}, {"id": "1610.05891", "submitter": "Gyorgy Terdik DR", "authors": "T. Subba Rao and Gy. Terdik", "title": "On the frequency variogram and on frequency domain methods for the\n  analysis of spatio-temporal data", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The covariance function and the variogram play very important roles in\nmodelling and in prediction of spatial and spatio-temporal data. The assumption\nof second order stationarity, in space and time, is often made in the analysis\nof spatial data and the spatio-temporal data. Several times the assumption of\nstationarity is considered to be very restrictive, and therefore, a weaker\nassumption that the data is Intrinsically stationary both in space and time is\noften made and used, mainly by the geo-statisticians and other environmental\nscientists. In this paper we consider the data to be intrinsically stationary.\nBecause of the inclusion of time dimension,the estimation and derivation of the\nsampling properties of various estimators related to spatio-temporal data\nbecome complicated. In this paper our object is to present an alternative way,\nbased on Frequency Domain methods for modelling the data. Here we consider\nDiscrete Fourier Transforms (DFT) defined for the (Intrinsic) time series data\nobserved at several locations as our data, and then consider the estimation of\nthe parameters of spatio-temporal covariance function, estimation of Frequency\nVariogram, tests of independence etc. We use the well known property that the\nDiscrete Fourier Transforms of stationary time series evaluated at distinct\nFourier Frequencies are asymptotically independent and distributed as complex\nnormal in deriving many results considered in this paper.\n", "versions": [{"version": "v1", "created": "Wed, 19 Oct 2016 07:19:02 GMT"}], "update_date": "2016-10-20", "authors_parsed": [["Rao", "T. Subba", ""], ["Terdik", "Gy.", ""]]}, {"id": "1610.06026", "submitter": "Fadoua Balabdaoui", "authors": "F. Balabdaoui, C. Durot and H. Jankowski", "title": "Least squares estimation in the monotone single index model", "comments": "54 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the monotone single index model where a real response variable $Y $\nis linked to a $d$-dimensional covariate $X$ through the relationship $E[Y | X]\n= \\Psi_0(\\alpha^T_0 X)$ almost surely. Both the ridge function, $\\Psi_0$, and\nthe index parameter, $\\alpha_0$, are unknown and the ridge function is assumed\nto be monotone on its interval of support. Under some regularity conditions,\nwithout imposing a particular distribution on the regression error, we show the\n$n^{-1/3}$ rate of convergence in the $\\ell_2$-norm for the least squares\nestimator of the bundled function $\\psi_0({\\alpha}^T_0 \\cdot),$ and also that\nof the ridge function and the index separately. Furthermore, we show that the\nleast squares estimator is nearly parametrically rate-adaptive to piecewise\nconstant ridge functions.\n", "versions": [{"version": "v1", "created": "Wed, 19 Oct 2016 14:19:21 GMT"}, {"version": "v2", "created": "Wed, 18 Apr 2018 08:09:15 GMT"}], "update_date": "2018-04-19", "authors_parsed": [["Balabdaoui", "F.", ""], ["Durot", "C.", ""], ["Jankowski", "H.", ""]]}, {"id": "1610.06107", "submitter": "Xiaoying Tian Harris", "authors": "Xiaoying Tian Harris", "title": "Prediction error after model search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimation of the prediction error of a linear estimation rule is difficult\nif the data analyst also use data to select a set of variables and construct\nthe estimation rule using only the selected variables. In this work, we propose\nan asymptotically unbiased estimator for the prediction error after model\nsearch. Under some additional mild assumptions, we show that our estimator\nconverges to the true prediction error in $L^2$ at the rate of $O(n^{-1/2})$,\nwith $n$ being the number of data points. Our estimator applies to general\nselection procedures, not requiring analytical forms for the selection. The\nnumber of variables to select from can grow as an exponential factor of $n$,\nallowing applications in high-dimensional data. It also allows model\nmisspecifications, not requiring linear underlying models. One application of\nour method is that it provides an estimator for the degrees of freedom for many\ndiscontinuous estimation rules like best subset selection or relaxed Lasso.\nConnection to Stein's Unbiased Risk Estimator is discussed. We consider\nin-sample prediction errors in this work, with some extension to out-of-sample\nerrors in low dimensional, linear models. Examples such as best subset\nselection and relaxed Lasso are considered in simulations, where our estimator\noutperforms both $C_p$ and cross validation in various settings.\n", "versions": [{"version": "v1", "created": "Wed, 19 Oct 2016 17:04:50 GMT"}, {"version": "v2", "created": "Thu, 9 Feb 2017 23:00:15 GMT"}], "update_date": "2017-02-13", "authors_parsed": [["Harris", "Xiaoying Tian", ""]]}, {"id": "1610.06427", "submitter": "Samuel Rosa", "authors": "Samuel Rosa", "title": "On weighted optimality of experimental designs", "comments": "24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When the experimental objective is expressed by a set of estimable functions,\nand any eigenvalue-based optimality criterion is selected, we prove the\nequivalence of the recently introduced weighted optimality and the 'standard'\noptimality criteria for estimating this set of functions of interest. Also,\ngiven a weighted eigenvalue-based criterion, we construct a system of estimable\nfunctions, so that the optimality for estimating this system of functions is\nequivalent to the weighted optimality. This allows one to use the large body of\nexisting theoretical and computational results for the standard optimality\ncriteria for estimating a system of interest to derive theorems and numerical\nalgorithms for the weighted optimality of experimental designs. Moreover, we\nextend the theory of weighted optimality so that it captures the experimental\nobjective consisting of any system of estimable functions, which was not the\ncase in the literature on weighted optimality so far. For any set of estimable\nfunctions, we propose a corresponding weight matrix of a simple form, and with\na straightforward interpretation. Given a set of estimable functions with their\ncorresponding weights, we show that it is useful to distinguish between the\nprimary weights selected by the experimenters and the secondary weights implied\nby the weight matrix.\n", "versions": [{"version": "v1", "created": "Thu, 20 Oct 2016 14:22:57 GMT"}], "update_date": "2016-10-21", "authors_parsed": [["Rosa", "Samuel", ""]]}, {"id": "1610.06461", "submitter": "Abbas Kazemipour", "authors": "Abbas Kazemipour, Ji Liu, Patrick Kanold, Min Wu, Behtash Babadi", "title": "Efficient Estimation of Compressible State-Space Models with Application\n  to Calcium Signal Deconvolution", "comments": "2016 IEEE Global Conference on Signal and Information Processing\n  (GlobalSIP), Dec. 7-9, 2016, Washington D.C", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.IT math.DS math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider linear state-space models with compressible\ninnovations and convergent transition matrices in order to model\nspatiotemporally sparse transient events. We perform parameter and state\nestimation using a dynamic compressed sensing framework and develop an\nefficient solution consisting of two nested Expectation-Maximization (EM)\nalgorithms. Under suitable sparsity assumptions on the innovations, we prove\nrecovery guarantees and derive confidence bounds for the state estimates. We\nprovide simulation studies as well as application to spike deconvolution from\ncalcium imaging data which verify our theoretical results and show significant\nimprovement over existing algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 20 Oct 2016 15:37:53 GMT"}], "update_date": "2016-10-21", "authors_parsed": [["Kazemipour", "Abbas", ""], ["Liu", "Ji", ""], ["Kanold", "Patrick", ""], ["Wu", "Min", ""], ["Babadi", "Behtash", ""]]}, {"id": "1610.06731", "submitter": "Evgeny Burnaev", "authors": "Alexey Zaytsev and Evgeny Burnaev", "title": "Minimax Error of Interpolation and Optimal Design of Experiments for\n  Variable Fidelity Data", "comments": "25 pages, 5 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Engineering problems often involve data sources of variable fidelity with\ndifferent costs of obtaining an observation. In particular, one can use both a\ncheap low fidelity function (e.g. a computational experiment with a CFD code)\nand an expensive high fidelity function (e.g. a wind tunnel experiment) to\ngenerate a data sample in order to construct a regression model of a high\nfidelity function. The key question in this setting is how the sizes of the\nhigh and low fidelity data samples should be selected in order to stay within a\ngiven computational budget and maximize accuracy of the regression model prior\nto committing resources on data acquisition.\n  In this paper we obtain minimax interpolation errors for single and variable\nfidelity scenarios for a multivariate Gaussian process regression. Evaluation\nof the minimax errors allows us to identify cases when the variable fidelity\ndata provides better interpolation accuracy than the exclusively high fidelity\ndata for the same computational budget.\n  These results allow us to calculate the optimal shares of variable fidelity\ndata samples under the given computational budget constraint. Real and\nsynthetic data experiments suggest that using the obtained optimal shares often\noutperforms natural heuristics in terms of the regression accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 21 Oct 2016 10:24:08 GMT"}, {"version": "v2", "created": "Tue, 11 Apr 2017 15:02:57 GMT"}, {"version": "v3", "created": "Mon, 18 Dec 2017 10:58:19 GMT"}], "update_date": "2017-12-19", "authors_parsed": [["Zaytsev", "Alexey", ""], ["Burnaev", "Evgeny", ""]]}, {"id": "1610.06774", "submitter": "F\\'elix Balazard", "authors": "F\\'elix Balazard", "title": "Asymptotic equivalence of paired Hotelling test and conditional logistic\n  regression", "comments": "9 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matching, the stratification of observations, is of primary importance for\nthe analysis of observational studies. We show that the score test of\nconditional logistic regression and the paired Student/Hotelling test, two\ntests for paired data, are asymptotically equivalent.\n", "versions": [{"version": "v1", "created": "Fri, 21 Oct 2016 13:17:03 GMT"}], "update_date": "2016-10-24", "authors_parsed": [["Balazard", "F\u00e9lix", ""]]}, {"id": "1610.06833", "submitter": "Alfred Galichon", "authors": "Guillaume Carlier, Victor Chernozhukov, Alfred Galichon", "title": "Vector quantile regression beyond correct specification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies vector quantile regression (VQR), which is a way to model\nthe dependence of a random vector of interest with respect to a vector of\nexplanatory variables so to capture the whole conditional distribution, and not\nonly the conditional mean. The problem of vector quantile regression is\nformulated as an optimal transport problem subject to an additional\nmean-independence condition. This paper provides a new set of results on VQR\nbeyond the case with correct specification which had been the focus of previous\nwork. First, we show that even under misspecification, the VQR problem still\nhas a solution which provides a general representation of the conditional\ndependence between random vectors. Second, we provide a detailed comparison\nwith the classical approach of Koenker and Bassett in the case when the\ndependent variable is univariate and we show that in that case, VQR is\nequivalent to classical quantile regression with an additional monotonicity\nconstraint.\n", "versions": [{"version": "v1", "created": "Fri, 21 Oct 2016 15:55:24 GMT"}], "update_date": "2016-10-24", "authors_parsed": [["Carlier", "Guillaume", ""], ["Chernozhukov", "Victor", ""], ["Galichon", "Alfred", ""]]}, {"id": "1610.06960", "submitter": "Adolfo Quiroz", "authors": "Alejandra Caba\\~na, Ana Maria Estrada, Jairo I. Pe\\~na, Adolfo J.\n  Quiroz", "title": "Permutation tests in the two-sample problem for functional data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Three different permutation test schemes are discussed and compared in the\ncontext of the two-sample problem for functional data. One of the procedures\nwas essentially introduced by Lopez-Pintado and Romo (2009), using notions of\nfunctional data depth to adapt the ideas originally proposed by Liu and Singh\n(1993) for multivariate data. Of the new methods introduced here, one is also\nbased on functional data depths, but uses a different way (inspired by\nMeta-Analysis) to assess the significance of the depth differences. The second\nnew method presented here adapts, to the functional data setting, the\nk-nearest-neighbors statistic of Schilling (1986). The three methods are\ncompared among them and against the test of Horvath and Kokoszka (2012) in\nsimulated examples and real data. The comparison considers the performance of\nthe statistics in terms of statistical power and in terms of computational\ncost.\n", "versions": [{"version": "v1", "created": "Fri, 21 Oct 2016 21:36:57 GMT"}], "update_date": "2016-10-25", "authors_parsed": [["Caba\u00f1a", "Alejandra", ""], ["Estrada", "Ana Maria", ""], ["Pe\u00f1a", "Jairo I.", ""], ["Quiroz", "Adolfo J.", ""]]}, {"id": "1610.07193", "submitter": "Benjamin Guedj", "authors": "Pierre Alquier and Benjamin Guedj", "title": "Simpler PAC-Bayesian Bounds for Hostile Data", "comments": "18 pages", "journal-ref": "Machine Learning (2018), vol. 107 (5), 887--902", "doi": "10.1007/s10994-017-5690-0", "report-no": null, "categories": "stat.ML math.ST stat.TH", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  PAC-Bayesian learning bounds are of the utmost interest to the learning\ncommunity. Their role is to connect the generalization ability of an\naggregation distribution $\\rho$ to its empirical risk and to its\nKullback-Leibler divergence with respect to some prior distribution $\\pi$.\nUnfortunately, most of the available bounds typically rely on heavy assumptions\nsuch as boundedness and independence of the observations. This paper aims at\nrelaxing these constraints and provides PAC-Bayesian learning bounds that hold\nfor dependent, heavy-tailed observations (hereafter referred to as\n\\emph{hostile data}). In these bounds the Kullack-Leibler divergence is\nreplaced with a general version of Csisz\\'ar's $f$-divergence. We prove a\ngeneral PAC-Bayesian bound, and show how to use it in various hostile settings.\n", "versions": [{"version": "v1", "created": "Sun, 23 Oct 2016 16:20:46 GMT"}, {"version": "v2", "created": "Thu, 23 May 2019 05:54:26 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Alquier", "Pierre", ""], ["Guedj", "Benjamin", ""]]}, {"id": "1610.07403", "submitter": "Matthew Reimherr", "authors": "Rina Foygel Barber, Matthew Reimherr and Thomas Schill", "title": "The Function-on-Scalar LASSO with Applications to Longitudinal GWAS", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new methodology for simultaneous variable selection and\nparameter estimation in function-on-scalar regression with an ultra-high\ndimensional predictor vector. We extend the LASSO to functional data in both\nthe $\\textit{dense}$ functional setting and the $\\textit{sparse}$ functional\nsetting. We provide theoretical guarantees which allow for an exponential\nnumber of predictor variables. Simulations are carried out which illustrate the\nmethodology and compare the sparse/functional methods. Using the Framingham\nHeart Study, we demonstrate how our tools can be used in genome-wide\nassociation studies, finding a number of genetic mutations which affect blood\npressure and are therefore important for cardiovascular health.\n", "versions": [{"version": "v1", "created": "Mon, 24 Oct 2016 13:37:59 GMT"}], "update_date": "2016-10-25", "authors_parsed": [["Barber", "Rina Foygel", ""], ["Reimherr", "Matthew", ""], ["Schill", "Thomas", ""]]}, {"id": "1610.07487", "submitter": "Nicole M\\\"ucke", "authors": "Gilles Blanchard and Nicole M\\\"ucke", "title": "Parallelizing Spectral Algorithms for Kernel Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a distributed learning approach in supervised learning for a\nlarge class of spectral regularization methods in an RKHS framework. The data\nset of size n is partitioned into $m=O(n^\\alpha)$ disjoint subsets. On each\nsubset, some spectral regularization method (belonging to a large class,\nincluding in particular Kernel Ridge Regression, $L^2$-boosting and spectral\ncut-off) is applied. The regression function $f$ is then estimated via simple\naveraging, leading to a substantial reduction in computation time. We show that\nminimax optimal rates of convergence are preserved if m grows sufficiently\nslowly (corresponding to an upper bound for $\\alpha$) as $n \\to \\infty$,\ndepending on the smoothness assumptions on $f$ and the intrinsic\ndimensionality. In spirit, our approach is classical.\n", "versions": [{"version": "v1", "created": "Mon, 24 Oct 2016 16:50:43 GMT"}, {"version": "v2", "created": "Sun, 13 Nov 2016 08:07:03 GMT"}, {"version": "v3", "created": "Sun, 22 Jan 2017 21:13:22 GMT"}, {"version": "v4", "created": "Wed, 9 Aug 2017 11:30:39 GMT"}], "update_date": "2017-08-10", "authors_parsed": [["Blanchard", "Gilles", ""], ["M\u00fccke", "Nicole", ""]]}, {"id": "1610.07507", "submitter": "Matthew Reimherr", "authors": "Zhaohu Fan and Matthew Reimherr", "title": "High-Dimensional Adaptive Function-on-Scalar Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Applications of functional data with large numbers of predictors have grown\nprecipitously in recent years, driven, in part, by rapid advances in genotyping\ntechnologies. Given the large numbers of genetic mutations encountered in\ngenetic association studies, statistical methods which more fully exploit the\nunderlying structure of the data are imperative for maximizing statistical\npower. However, there is currently very limited work in functional data with\nlarge numbers of predictors. Tools are presented for simultaneous variable\nselection and parameter estimation in a functional linear model with a\nfunctional outcome and a large number of scalar predictors; the technique is\ncalled AFSL for $\\textit{Adaptive Function-on-Scalar Lasso}.$ It is\ndemonstrated how techniques from convex analysis over Hilbert spaces can be\nused to establish a functional version of the oracle property for AFSL over any\nreal separable Hilbert space, even when the number of predictors, $I$, is\nexponentially large compared to the sample size, $N$. AFSL is illustrated via a\nsimulation study and data from the Childhood Asthma Management Program, CAMP,\nselecting those genetic mutations which are important for lung growth.\n", "versions": [{"version": "v1", "created": "Mon, 24 Oct 2016 17:46:42 GMT"}], "update_date": "2016-10-25", "authors_parsed": [["Fan", "Zhaohu", ""], ["Reimherr", "Matthew", ""]]}, {"id": "1610.07554", "submitter": "Peter Peskun", "authors": "Peter Peskun", "title": "Some Relationships and Properties of the Hypergeometric Distribution", "comments": "8 pages, 0 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The binomial and Poisson distributions have interesting relationships with\nthe beta and gamma distributions, respectively, which involve their cumulative\ndistribution functions and the use of conjugate priors in Bayesian statistics.\nWe briefly discuss these relationships and some properties resulting from them\nwhich play an important role in the construction of exact nested two-sided\nconfidence intervals and the computation of two-tailed P-values. The purpose of\nthis article is to show that such relationships also exist between the\nhypergeometric distribution and a special case of the Polya (or beta-binomial)\ndistribution, and to derive some properties of the hypergeometric distribution\nresulting from these relationships.\n  KEY WORDS: Beta, binomial, gamma, Poisson, and Polya (or beta-binomial)\ndistributions; Conjugate prior distribution; Cumulative distribution function;\nPosterior distribution.\n", "versions": [{"version": "v1", "created": "Mon, 24 Oct 2016 19:12:23 GMT"}], "update_date": "2016-10-25", "authors_parsed": [["Peskun", "Peter", ""]]}, {"id": "1610.07662", "submitter": "Ryan Rogers", "authors": "Daniel Kifer, Ryan Rogers", "title": "A New Class of Private Chi-Square Tests", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.CR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we develop new test statistics for private hypothesis testing.\nThese statistics are designed specifically so that their asymptotic\ndistributions, after accounting for noise added for privacy concerns, match the\nasymptotics of the classical (non-private) chi-square tests for testing if the\nmultinomial data parameters lie in lower dimensional manifolds (examples\ninclude goodness of fit and independence testing). Empirically, these new test\nstatistics outperform prior work, which focused on noisy versions of existing\nstatistics.\n", "versions": [{"version": "v1", "created": "Mon, 24 Oct 2016 21:55:25 GMT"}], "update_date": "2016-10-26", "authors_parsed": [["Kifer", "Daniel", ""], ["Rogers", "Ryan", ""]]}, {"id": "1610.07683", "submitter": "Ming Yuan", "authors": "Shulei Wang and Ming Yuan", "title": "Combined Hypothesis Testing on Graphs with Applications to Gene Set\n  Enrichment Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by gene set enrichment analysis, we investigate the problem of\ncombined hypothesis testing on a graph. We introduce a general framework to\neffectively use the structural information of the underlying graph when testing\nmultivariate means. A new testing procedure is proposed within this framework.\nWe show that the test is optimal in that it can consistently detect departure\nfrom the collective null at a rate that no other test could improve, for almost\nall graphs. We also provide general performance bounds for the proposed test\nunder any specific graph, and illustrate their utility through several common\ntypes of graphs. Numerical experiments are presented to further demonstrate the\nmerits of our approach.\n", "versions": [{"version": "v1", "created": "Mon, 24 Oct 2016 23:51:07 GMT"}], "update_date": "2016-10-26", "authors_parsed": [["Wang", "Shulei", ""], ["Yuan", "Ming", ""]]}, {"id": "1610.07697", "submitter": "Quefeng Li", "authors": "Quefeng Li, Guang Cheng, Jianqing Fan and Yuyan Wang", "title": "Embracing the Blessing of Dimensionality in Factor Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Factor modeling is an essential tool for exploring intrinsic dependence\nstructures among high-dimensional random variables. Much progress has been made\nfor estimating the covariance matrix from a high-dimensional factor model.\nHowever, the blessing of dimensionality has not yet been fully embraced in the\nliterature: much of the available data is often ignored in constructing\ncovariance matrix estimates. If our goal is to accurately estimate a covariance\nmatrix of a set of targeted variables, shall we employ additional data, which\nare beyond the variables of interest, in the estimation? In this paper, we\nprovide sufficient conditions for an affirmative answer, and further quantify\nits gain in terms of Fisher information and convergence rate. In fact, even an\noracle-like result (as if all the factors were known) can be achieved when a\nsufficiently large number of variables is used. The idea of utilizing data as\nmuch as possible brings computational challenges. A divide-and-conquer\nalgorithm is thus proposed to alleviate the computational burden, and also\nshown not to sacrifice any statistical accuracy in comparison with a pooled\nanalysis. Simulation studies further confirm our advocacy for the use of full\ndata, and demonstrate the effectiveness of the above algorithm. Our proposal is\napplied to a microarray data example that shows empirical benefits of using\nmore data.\n", "versions": [{"version": "v1", "created": "Tue, 25 Oct 2016 01:07:43 GMT"}], "update_date": "2016-10-26", "authors_parsed": [["Li", "Quefeng", ""], ["Cheng", "Guang", ""], ["Fan", "Jianqing", ""], ["Wang", "Yuyan", ""]]}, {"id": "1610.08104", "submitter": "Jo\\\"el Bun", "authors": "Jo\\\"el Bun, Jean-Philippe Bouchaud and Marc Potters", "title": "Cleaning large correlation matrices: tools from random matrix theory", "comments": "165 pages, article submitted to Physics Reports", "journal-ref": null, "doi": "10.1016/j.physrep.2016.10.005", "report-no": null, "categories": "cond-mat.stat-mech math.ST q-fin.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This review covers recent results concerning the estimation of large\ncovariance matrices using tools from Random Matrix Theory (RMT). We introduce\nseveral RMT methods and analytical techniques, such as the Replica formalism\nand Free Probability, with an emphasis on the Marchenko-Pastur equation that\nprovides information on the resolvent of multiplicatively corrupted noisy\nmatrices. Special care is devoted to the statistics of the eigenvectors of the\nempirical correlation matrix, which turn out to be crucial for many\napplications. We show in particular how these results can be used to build\nconsistent \"Rotationally Invariant\" estimators (RIE) for large correlation\nmatrices when there is no prior on the structure of the underlying process. The\nlast part of this review is dedicated to some real-world applications within\nfinancial markets as a case in point. We establish empirically the efficacy of\nthe RIE framework, which is found to be superior in this case to all previously\nproposed methods. The case of additively (rather than multiplicatively)\ncorrupted noisy matrices is also dealt with in a special Appendix. Several open\nproblems and interesting technical developments are discussed throughout the\npaper.\n", "versions": [{"version": "v1", "created": "Tue, 25 Oct 2016 21:53:28 GMT"}], "update_date": "2017-02-01", "authors_parsed": [["Bun", "Jo\u00ebl", ""], ["Bouchaud", "Jean-Philippe", ""], ["Potters", "Marc", ""]]}, {"id": "1610.08148", "submitter": "Vu Dinh", "authors": "Vu Dinh, Aaron E. Darling and Frederick A. Matsen IV", "title": "Online Bayesian phylogenetic inference: theoretical foundations via\n  Sequential Monte Carlo", "comments": "17 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Phylogenetics, the inference of evolutionary trees from molecular sequence\ndata such as DNA, is an enterprise that yields valuable evolutionary\nunderstanding of many biological systems. Bayesian phylogenetic algorithms,\nwhich approximate a posterior distribution on trees, have become a popular if\ncomputationally expensive means of doing phylogenetics. Modern data collection\ntechnologies are quickly adding new sequences to already substantial databases.\nWith all current techniques for Bayesian phylogenetics, computation must start\nanew each time a sequence becomes available, making it costly to maintain an\nup-to-date estimate of a phylogenetic posterior. These considerations highlight\nthe need for an \\emph{online} Bayesian phylogenetic method which can update an\nexisting posterior with new sequences.\n  Here we provide theoretical results on the consistency and stability of\nmethods for online Bayesian phylogenetic inference based on Sequential Monte\nCarlo (SMC) and Markov chain Monte Carlo (MCMC). We first show a consistency\nresult, demonstrating that the method samples from the correct distribution in\nthe limit of a large number of particles. Next we derive the first reported set\nof bounds on how phylogenetic likelihood surfaces change when new sequences are\nadded. These bounds enable us to characterize the theoretical performance of\nsampling algorithms by bounding the effective sample size (ESS) with a given\nnumber of particles from below. We show that the ESS is guaranteed to grow\nlinearly as the number of particles in an SMC sampler grows. Surprisingly, this\nresult holds even though the dimensions of the phylogenetic model grow with\neach new added sequence.\n", "versions": [{"version": "v1", "created": "Wed, 26 Oct 2016 02:14:03 GMT"}], "update_date": "2016-10-27", "authors_parsed": [["Dinh", "Vu", ""], ["Darling", "Aaron E.", ""], ["Matsen", "Frederick A.", "IV"]]}, {"id": "1610.08203", "submitter": "Robin Genuer", "authors": "Robin Genuer (SISTM), Jean-Michel Poggi (LMO, UPD5)", "title": "Arbres CART et For\\^ets al\\'eatoires, Importance et s\\'election de\n  variables", "comments": "in French", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two algorithms proposed by Leo Breiman : CART trees (Classification And\nRegression Trees for) introduced in the first half of the 80s and random\nforests emerged, meanwhile, in the early 2000s, are the subject of this\narticle. The goal is to provide each of the topics, a presentation, a\ntheoretical guarantee, an example and some variants and extensions. After a\npreamble, introduction recalls objectives of classification and regression\nproblems before retracing some predecessors of the Random Forests. Then, a\nsection is devoted to CART trees then random forests are presented. Then, a\nvariable selection procedure based on permutation variable importance is\nproposed. Finally the adaptation of random forests to the Big Data context is\nsketched.\n", "versions": [{"version": "v1", "created": "Wed, 26 Oct 2016 06:56:14 GMT"}, {"version": "v2", "created": "Fri, 20 Jan 2017 14:05:06 GMT"}], "update_date": "2017-01-23", "authors_parsed": [["Genuer", "Robin", "", "SISTM"], ["Poggi", "Jean-Michel", "", "LMO, UPD5"]]}, {"id": "1610.08227", "submitter": "Franz Chouly", "authors": "Marine Bruneau (LMB), Thierry Mottet, Serge Moulin, Ma\\\"el Kerbiriou\n  (LMB), Franz Chouly (LMB), St\\'ephane Chretien (NPL), Christophe Guyeux", "title": "A clustering tool for nucleotide sequences using Laplacian Eigenmaps and\n  Gaussian Mixture Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new procedure for clustering nucleotide sequences based on the\n\"Laplacian Eigenmaps\" and Gaussian Mixture modelling. This proposal is then\napplied to a set of 100 DNA sequences from the mitochondrially encoded NADH\ndehydrogenase 3 (ND3) gene of a collection of Platyhelminthes and Nematoda\nspecies. The resulting clusters are then shown to be consistent with the gene\nphylogenetic tree computed using a maximum likelihood approach. This comparison\nshows in particular that the clustering produced by the methodology combining\nLaplacian Eigenmaps with Gaussian Mixture models is coherent with the phylogeny\nas well as with the NCBI taxonomy. We also developed a Python package for this\nprocedure which is available online.\n", "versions": [{"version": "v1", "created": "Wed, 26 Oct 2016 08:43:58 GMT"}], "update_date": "2016-10-27", "authors_parsed": [["Bruneau", "Marine", "", "LMB"], ["Mottet", "Thierry", "", "LMB"], ["Moulin", "Serge", "", "LMB"], ["Kerbiriou", "Ma\u00ebl", "", "LMB"], ["Chouly", "Franz", "", "LMB"], ["Chretien", "St\u00e9phane", "", "NPL"], ["Guyeux", "Christophe", ""]]}, {"id": "1610.08239", "submitter": "Daniil Ryabko", "authors": "Daniil Ryabko", "title": "Things Bayes can't do", "comments": null, "journal-ref": "Proceedings of ALT, LNCS 9925, pp.253-260, Bari, Italy, 2016", "doi": "10.1007/978-3-319-46379-7_17", "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of forecasting conditional probabilities of the next event given\nthe past is considered in a general probabilistic setting. Given an arbitrary\n(large, uncountable) set C of predictors, we would like to construct a single\npredictor that performs asymptotically as well as the best predictor in C, on\nany data. Here we show that there are sets C for which such predictors exist,\nbut none of them is a Bayesian predictor with a prior concentrated on C. In\nother words, there is a predictor with sublinear regret, but every Bayesian\npredictor must have a linear regret. This negative finding is in sharp contrast\nwith previous results that establish the opposite for the case when one of the\npredictors in $C$ achieves asymptotically vanishing error. In such a case, if\nthere is a predictor that achieves asymptotically vanishing error for any\nmeasure in C, then there is a Bayesian predictor that also has this property,\nand whose prior is concentrated on (a countable subset of) C.\n", "versions": [{"version": "v1", "created": "Wed, 26 Oct 2016 09:13:28 GMT"}, {"version": "v2", "created": "Thu, 27 Oct 2016 12:13:37 GMT"}], "update_date": "2016-10-28", "authors_parsed": [["Ryabko", "Daniil", ""]]}, {"id": "1610.08249", "submitter": "Daniil Ryabko", "authors": "Daniil Ryabko", "title": "Universality of Bayesian mixture predictors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT cs.LG math.IT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem is that of sequential probability forecasting for finite-valued\ntime series. The data is generated by an unknown probability distribution over\nthe space of all one-way infinite sequences. It is known that this measure\nbelongs to a given set C, but the latter is completely arbitrary (uncountably\ninfinite, without any structure given). The performance is measured with\nasymptotic average log loss. In this work it is shown that the minimax\nasymptotic performance is always attainable, and it is attained by a convex\ncombination of a countably many measures from the set C (a Bayesian mixture).\nThis was previously only known for the case when the best achievable asymptotic\nerror is 0. This also contrasts previous results that show that in the\nnon-realizable case all Bayesian mixtures may be suboptimal, while there is a\npredictor that achieves the optimal performance.\n", "versions": [{"version": "v1", "created": "Wed, 26 Oct 2016 09:29:32 GMT"}, {"version": "v2", "created": "Tue, 1 Nov 2016 13:01:03 GMT"}], "update_date": "2016-11-02", "authors_parsed": [["Ryabko", "Daniil", ""]]}, {"id": "1610.08386", "submitter": "Ra\\'ul Torres", "authors": "Ra\\'ul Torres and Elena Di Bernardino and Henry Laniado and Rosa E.\n  Lillo", "title": "On the estimation of extreme directional multivariate quantiles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In multivariate extreme value theory (MEVT), the focus is on analysis outside\nof the observable sampling zone, which implies that the region of interest is\nassociated to high risk levels. This work provides tools to include directional\nnotions into the MEVT, giving the opportunity to characterize the recently\nintroduced directional multivariate quantiles (DMQ) at high levels. Then, an\nout-sample estimation method for these quantiles is given. A bootstrap\nprocedure carries out the estimation of the tuning parameter in this\nmultivariate framework and helps with the estimation of the DMQ. Asymptotic\nnormality for the proposed estimator is provided and the methodology is\nillustrated with simulated data-sets. Finally, a real-life application to a\nfinancial case is also performed.\n", "versions": [{"version": "v1", "created": "Wed, 26 Oct 2016 15:42:13 GMT"}, {"version": "v2", "created": "Wed, 14 Jun 2017 21:28:57 GMT"}, {"version": "v3", "created": "Wed, 14 Mar 2018 11:01:28 GMT"}, {"version": "v4", "created": "Wed, 1 Aug 2018 16:58:28 GMT"}, {"version": "v5", "created": "Tue, 4 Dec 2018 12:59:42 GMT"}], "update_date": "2018-12-05", "authors_parsed": [["Torres", "Ra\u00fal", ""], ["Di Bernardino", "Elena", ""], ["Laniado", "Henry", ""], ["Lillo", "Rosa E.", ""]]}, {"id": "1610.08405", "submitter": "Adam Kashlak", "authors": "Adam B Kashlak", "title": "Improved Rademacher symmetrization through a Wasserstein based measure\n  of asymmetry", "comments": "15 pages, 3 figures", "journal-ref": "EJS 12 (2018) 2091-2113", "doi": "10.1214/18-EJS1440", "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose of an improved version of the ubiquitous symmetrization inequality\nmaking use of the Wasserstein distance between a measure and its reflection in\norder to quantify the symmetry of the given measure. An empirical bound on this\nasymmetric correction term is derived through a bootstrap procedure and shown\nto give tighter results in practical settings than the original uncorrected\ninequality. Lastly, a wide range of applications are detailed including testing\nfor data symmetry, constructing nonasymptotic high dimensional confidence sets,\nbounding the variance of an empirical process, and improving constants in\nNemirovski style inequalities for Banach space valued random variables.\n", "versions": [{"version": "v1", "created": "Wed, 26 Oct 2016 16:31:44 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Kashlak", "Adam B", ""]]}, {"id": "1610.08621", "submitter": "Qing Zhou", "authors": "Qing Zhou and Seunghyun Min", "title": "Estimator Augmentation with Applications in High-Dimensional Group\n  Inference", "comments": "35 pages, 4 figures", "journal-ref": "Electronic Journal of Statistics, Vol. 11 (2017): 3039-3080", "doi": "10.1214/17-EJS1309", "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To make inference about a group of parameters on high-dimensional data, we\ndevelop the method of estimator augmentation for the block Lasso, which is\ndefined via the block norm. By augmenting a block Lasso estimator $\\hat{\\beta}$\nwith the subgradient $S$ of the block norm evaluated at $\\hat{\\beta}$, we\nderive a closed-form density for the joint distribution of $(\\hat{\\beta},S)$\nunder a high-dimensional setting. This allows us to draw from an estimated\nsampling distribution of $\\hat{\\beta}$, or more generally any function of\n$(\\hat{\\beta},S)$, by Monte Carlo algorithms. We demonstrate the application of\nestimator augmentation in group inference with the group Lasso and a de-biased\ngroup Lasso constructed as a function of $(\\hat{\\beta},S)$. Our numerical\nresults show that importance sampling via estimator augmentation can be orders\nof magnitude more efficient than parametric bootstrap in estimating tail\nprobabilities for significance tests. This work also brings new insights into\nthe geometry of the sample space and the solution uniqueness of the block\nLasso.\n", "versions": [{"version": "v1", "created": "Thu, 27 Oct 2016 05:31:10 GMT"}, {"version": "v2", "created": "Fri, 23 Dec 2016 20:34:58 GMT"}], "update_date": "2017-08-16", "authors_parsed": [["Zhou", "Qing", ""], ["Min", "Seunghyun", ""]]}, {"id": "1610.08627", "submitter": "Abhinav Kumar", "authors": "Abhinav Kumar and Animesh Kumar", "title": "Estimation of Bandlimited Grayscale Images From the Single Bit\n  Observations of Pixels Affected by Additive Gaussian Noise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The estimation of grayscale images using their single-bit zero mean Gaussian\nnoise-affected pixels is presented in this paper. The images are assumed to be\nbandlimited in the Fourier Cosine transform (FCT) domain. The images are\noversampled over their Nyquist rate in the FCT domain. We propose a\nnon-recursive approach based on first order approximation of Cumulative\nDistribution Function (CDF) to estimate the image from single bit pixels which\nitself is based on Banach's contraction theorem. The decay rate for mean\nsquared error of estimating such images is found to be independent of the\nprecision of the quantizer and it varies as $O(1/N)$ where $N$ is the\n\"effective\" oversampling ratio with respect to the Nyquist rate in the FCT\ndomain.\n", "versions": [{"version": "v1", "created": "Thu, 27 Oct 2016 06:15:26 GMT"}], "update_date": "2016-10-28", "authors_parsed": [["Kumar", "Abhinav", ""], ["Kumar", "Animesh", ""]]}, {"id": "1610.08663", "submitter": "Justin Chown", "authors": "Nicolai Bissantz, Justin Chown and Holger Dette", "title": "Regularization parameter selection in indirect regression by residual\n  based bootstrap", "comments": "Keywords: bandwidth selection, indirect regression estimator, inverse\n  problems, regularization, residual-based empirical distribution function,\n  smooth bootstrap", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Residual-based analysis is generally considered a cornerstone of statistical\nmethodology. For a special case of indirect regression, we investigate the\nresidual-based empirical distribution function and provide a uniform expansion\nof this estimator, which is also shown to be asymptotically most precise. This\ninvestigation naturally leads to a completely data-driven technique for\nselecting a regularization parameter used in our indirect regression function\nestimator. The resulting methodology is based on a smooth bootstrap of the\nmodel residuals. A simulation study demonstrates the effectiveness of our\napproach.\n", "versions": [{"version": "v1", "created": "Thu, 27 Oct 2016 08:50:01 GMT"}, {"version": "v2", "created": "Thu, 6 Apr 2017 12:12:19 GMT"}, {"version": "v3", "created": "Wed, 4 Oct 2017 12:35:33 GMT"}, {"version": "v4", "created": "Wed, 28 Feb 2018 16:07:46 GMT"}], "update_date": "2018-03-01", "authors_parsed": [["Bissantz", "Nicolai", ""], ["Chown", "Justin", ""], ["Dette", "Holger", ""]]}, {"id": "1610.08732", "submitter": "Lioudmila Vostrikova Professor", "authors": "P. Salminen, L. Vostrikova", "title": "On exponential functionals of processes with independent increments", "comments": null, "journal-ref": null, "doi": null, "report-no": "29 pages, no figures", "categories": "math.PR math.ST q-fin.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study the exponential functionals of the processes $X$ with\nindependent increments , namely $$I_t= \\int _0^t\\exp(-X_s)ds, _,\\,\\, t\\geq 0,$$\nand also $$I_{\\infty}= \\int _0^{\\infty}\\exp(-X_s)ds.$$ When $X$ is a\nsemi-martingale with absolutely continuous characteristics, we derive recurrent\nintegral equations for Mellin transform ${\\bf E}( I_t^{\\alpha})$,\n$\\alpha\\in\\mathbb{R}$, of the integral functional $I_t$. Then we apply these\nrecurrent formulas to calculate the moments. We present also the corresponding\nresults for the exponential functionals of Levy processes, which hold under\nless restrictive conditions then in the paper of Bertoin, Yor (2005). In\nparticular, we obtain an explicit formula for the moments of $I_t$ and\n$I_{\\infty}$, and we precise the exact number of finite moments of\n$I_{\\infty}$.\n", "versions": [{"version": "v1", "created": "Thu, 27 Oct 2016 12:06:49 GMT"}, {"version": "v2", "created": "Mon, 17 Jul 2017 11:18:57 GMT"}, {"version": "v3", "created": "Thu, 8 Mar 2018 13:41:20 GMT"}], "update_date": "2018-03-09", "authors_parsed": [["Salminen", "P.", ""], ["Vostrikova", "L.", ""]]}, {"id": "1610.08876", "submitter": "Thiago VedoVatto", "authors": "T. VedoVatto, A. D. C. Nascimento, W. R. Miranda Filho, M. C. S. Lima,\n  L. G. B. Pinho, G. M. Cordeiro", "title": "Some Computational and Theoretical Aspects of the Exponentiated\n  Generalized Nadarajah-Haghighi Distribution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real data from applications in the survival context have required the use of\nmore flexible models. A new four-parameter model called the Exponentiated\nGeneralized Nadarajah-Haghighi (EGNH) distribution has been introduced in order\nto verify this requirement.\n", "versions": [{"version": "v1", "created": "Thu, 27 Oct 2016 16:41:16 GMT"}], "update_date": "2016-10-28", "authors_parsed": [["VedoVatto", "T.", ""], ["Nascimento", "A. D. C.", ""], ["Filho", "W. R. Miranda", ""], ["Lima", "M. C. S.", ""], ["Pinho", "L. G. B.", ""], ["Cordeiro", "G. M.", ""]]}, {"id": "1610.08929", "submitter": "Tim Patschkowski", "authors": "Tim Patschkowski, Angelika Rohde", "title": "Locally Adaptive Confidence Bands", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop honest and locally adaptive confidence bands for probability\ndensities. They provide substantially improved confidence statements in case of\ninhomogeneous smoothness, and are easily implemented and visualized. The\narticle contributes conceptual work on locally adaptive inference as a\nstraightforward modification of the global setting imposes severe obstacles for\nstatistical purposes. Among others, we introduce a statistical notion of local\nH\\\"older regularity and prove a correspondingly strong version of local\nadaptivity. We substantially relax the straightforward localization of the\nself-similarity condition in order not to rule out prototypical densities. The\nset of densities permanently excluded from the consideration is shown to be\npathological in a mathematically rigorous sense. On a technical level, the\ncrucial component for the verification of honesty is the identification of an\nasymptotically least favorable stationary case by means of Slepian's comparison\ninequality.\n", "versions": [{"version": "v1", "created": "Thu, 27 Oct 2016 19:01:02 GMT"}, {"version": "v2", "created": "Wed, 23 Nov 2016 15:22:31 GMT"}], "update_date": "2016-11-24", "authors_parsed": [["Patschkowski", "Tim", ""], ["Rohde", "Angelika", ""]]}, {"id": "1610.09005", "submitter": "Vincent Brault", "authors": "Vincent Brault and Antoine Channarond", "title": "Fast and Consistent Algorithm for the Latent Block Model", "comments": "22 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the algorithm $Largest$ $Gaps$ is introduced, for\nsimultaneously clustering both rows and columns of a matrix to form homogeneous\nblocks. The definition of clustering is model-based: clusters and data are\ngenerated under the Latent Block Model. In comparison with algorithms designed\nfor this model, the major advantage of the $Largest$ $Gaps$ algorithm is to\ncluster using only some marginals of the matrix, the size of which is much\nsmaller than the whole matrix. The procedure is linear with respect to the\nnumber of entries and thus much faster than the classical algorithms. It\nsimultaneously selects the number of classes as well, and the estimation of the\nparameters is then made very easily once the classification is obtained.\nMoreover, the paper proves the procedure to be consistent under the LBM, and it\nillustrates the statistical performance with some numerical experiments.\n", "versions": [{"version": "v1", "created": "Thu, 27 Oct 2016 20:36:58 GMT"}], "update_date": "2016-10-31", "authors_parsed": [["Brault", "Vincent", ""], ["Channarond", "Antoine", ""]]}, {"id": "1610.09018", "submitter": "Reimar Heinrich Leike", "authors": "Reimar H. Leike, Torsten A. En{\\ss}lin", "title": "Optimal Belief Approximation", "comments": "made improvements on the proof and the language", "journal-ref": null, "doi": "10.3390/e19080402", "report-no": null, "categories": "math.ST cs.AI physics.data-an stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Bayesian statistics probability distributions express beliefs. However,\nfor many problems the beliefs cannot be computed analytically and\napproximations of beliefs are needed. We seek a loss function that quantifies\nhow \"embarrassing\" it is to communicate a given approximation. We reproduce and\ndiscuss an old proof showing that there is only one ranking under the\nrequirements that (1) the best ranked approximation is the non-approximated\nbelief and (2) that the ranking judges approximations only by their predictions\nfor actual outcomes. The loss function that is obtained in the derivation is\nequal to the Kullback-Leibler divergence when normalized. This loss function is\nfrequently used in the literature. However, there seems to be confusion about\nthe correct order in which its functional arguments, the approximated and\nnon-approximated beliefs, should be used. The correct order ensures that the\nrecipient of a communication is only deprived of the minimal amount of\ninformation. We hope that the elementary derivation settles the apparent\nconfusion. For example when approximating beliefs with Gaussian distributions\nthe optimal approximation is given by moment matching. This is in contrast to\nmany suggested computational schemes.\n", "versions": [{"version": "v1", "created": "Thu, 27 Oct 2016 21:38:08 GMT"}, {"version": "v2", "created": "Tue, 29 Nov 2016 13:18:57 GMT"}, {"version": "v3", "created": "Tue, 18 Apr 2017 15:05:30 GMT"}, {"version": "v4", "created": "Mon, 12 Jun 2017 13:59:29 GMT"}, {"version": "v5", "created": "Tue, 4 Jul 2017 11:38:44 GMT"}, {"version": "v6", "created": "Thu, 3 Aug 2017 12:15:13 GMT"}], "update_date": "2017-08-07", "authors_parsed": [["Leike", "Reimar H.", ""], ["En\u00dflin", "Torsten A.", ""]]}, {"id": "1610.09051", "submitter": "Tingran Gao", "authors": "Tingran Gao, Jacek Brodzki, Sayan Mukherjee", "title": "The Geometry of Synchronization Problems and Learning Group Actions", "comments": "43 pages, 6 figures. To appear in Discrete \\& Computational Geometry", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.CG stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a geometric framework that characterizes the synchronization\nproblem --- the problem of consistently registering or aligning a collection of\nobjects. The theory we formulate characterizes the cohomological nature of\nsynchronization based on the classical theory of fibre bundles. We first\nestablish the correspondence between synchronization problems in a topological\ngroup $G$ over a connected graph $\\Gamma$ and the moduli space of flat\nprincipal $G$-bundles over $\\Gamma$, and develop a discrete analogy of the\nrenowned theorem of classifying flat principal bundles with fix base and\nstructural group using the representation variety. In particular, we show that\nprescribing an edge potential on a graph is equivalent to specifying an\nequivalence class of flat principal bundles, of which the triviality of\nholonomy dictates the synchronizability of the edge potential. We then develop\na twisted cohomology theory for associated vector bundles of the flat principal\nbundle arising from an edge potential, which is a discrete version of the\ntwisted cohomology in differential geometry. This theory realizes the\nobstruction to synchronizability as a cohomology group of the twisted de Rham\ncochain complex. We then build a discrete twisted Hodge theory --- a fibre\nbundle analog of the discrete Hodge theory on graphs --- which geometrically\nrealizes the graph connection Laplacian as a Hodge Laplacian of degree zero.\nMotivated by our geometric framework, we study the problem of learning group\nactions --- partitioning a collection of objects based on the local\nsynchronizability of pairwise correspondence relations. A dual interpretation\nis to learn finitely generated subgroups of an ambient transformation group\nfrom noisy observed group elements. A synchronization-based algorithm is also\nprovided, and we demonstrate its efficacy using simulations and real data.\n", "versions": [{"version": "v1", "created": "Fri, 28 Oct 2016 01:20:52 GMT"}, {"version": "v2", "created": "Sun, 7 Apr 2019 03:46:08 GMT"}, {"version": "v3", "created": "Tue, 14 May 2019 03:51:35 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Gao", "Tingran", ""], ["Brodzki", "Jacek", ""], ["Mukherjee", "Sayan", ""]]}, {"id": "1610.09109", "submitter": "Ingrid Blaschzyk", "authors": "Ingrid Blaschzyk and Ingo Steinwart", "title": "Improved Classification Rates under Refined Margin Conditions", "comments": "32 pages", "journal-ref": "Electron. J. Statist., vol. 12, pp. 793-823, 2018", "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a simple partitioning based technique to refine the\nstatistical analysis of classification algorithms. The core of our idea is to\ndivide the input space into two parts such that the first part contains a\nsuitable vicinity around the decision boundary, while the second part is\nsufficiently far away from the decision boundary. Using a set of margin\nconditions we are then able to control the classification error on both parts\nseparately. By balancing out these two error terms we obtain a refined error\nanalysis in a final step. We apply this general idea to the histogram rule and\nshow that even for this simple method we obtain, under certain assumptions,\nbetter rates than the ones known for support vector machines, for certain\nplug-in classifiers, and for a recently analyzed tree based\nadaptive-partitioning ansatz. Moreover, we show that a margin condition which\nsets the critical noise in relation to the decision boundary makes it possible\nto improve the optimal rates proven for distributions without this margin\ncondition.\n", "versions": [{"version": "v1", "created": "Fri, 28 Oct 2016 08:04:00 GMT"}, {"version": "v2", "created": "Fri, 17 Feb 2017 16:18:31 GMT"}, {"version": "v3", "created": "Wed, 17 Jan 2018 10:11:47 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Blaschzyk", "Ingrid", ""], ["Steinwart", "Ingo", ""]]}, {"id": "1610.09110", "submitter": "Igal Sason", "authors": "Igal Sason and Sergio Verd\\'u", "title": "$f$-Divergence Inequalities via Functional Domination", "comments": "A conference paper, 5 pages. To be presented in the 2016 ICSEE\n  International Conference on the Science of Electrical Engineering, Nov.\n  16--18, Eilat, Israel. See https://arxiv.org/abs/1508.00335 for the full\n  paper version, published as a journal paper in the IEEE Trans. on Information\n  Theory, vol. 62, no. 11, pp. 5973-6006, November 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers derivation of $f$-divergence inequalities via the\napproach of functional domination. Bounds on an $f$-divergence based on one or\nseveral other $f$-divergences are introduced, dealing with pairs of probability\nmeasures defined on arbitrary alphabets. In addition, a variety of bounds are\nshown to hold under boundedness assumptions on the relative information. The\njournal paper, which includes more approaches for the derivation of\nf-divergence inequalities and proofs, is available on the arXiv at\nhttps://arxiv.org/abs/1508.00335, and it has been published in the IEEE Trans.\non Information Theory, vol. 62, no. 11, pp. 5973-6006, November 2016.\n", "versions": [{"version": "v1", "created": "Fri, 28 Oct 2016 08:11:26 GMT"}], "update_date": "2016-10-31", "authors_parsed": [["Sason", "Igal", ""], ["Verd\u00fa", "Sergio", ""]]}, {"id": "1610.09187", "submitter": "Akimichi Takemura", "authors": "Hiroki Hashiguchi, Nobuki Takayama, Akimichi Takemura", "title": "Distribution of ratio of two Wishart matrices and evaluation of\n  cumulative probability by holonomic gradient method", "comments": null, "journal-ref": "Journal of Multivariate Analysis 165 (2018) 270-278", "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the distribution of the ratio of two central Wishart matrices with\ndifferent covariance matrices. We first derive the density function of a\nparticular matrix form of the ratio and show that its cumulative distribution\nfunction can be expressed in terms of the hypergeometric function 2F1 of a\nmatrix argument. Then we apply the holonomic gradient method for numerical\nevaluation of the hypergeometric function. This approach enables us to compute\nthe power function of Roy's maximum root test for testing the equality of two\ncovariance matrices.\n", "versions": [{"version": "v1", "created": "Fri, 28 Oct 2016 12:38:48 GMT"}], "update_date": "2018-05-08", "authors_parsed": [["Hashiguchi", "Hiroki", ""], ["Takayama", "Nobuki", ""], ["Takemura", "Akimichi", ""]]}, {"id": "1610.09272", "submitter": "Lionel Truquet", "authors": "Lionel Truquet", "title": "Root-n consistent estimation of the marginal density in some time series\n  models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the problem of estimating the marginal density in\nsome nonlinear autoregressive time series models for which the conditional mean\nand variance have a parametric specification. Under some regularity conditions,\nwe show that a kernel type estimate based on the residuals can be root-n\nconsistent even if the noise density is unknown. Our results, which are shown\nto be valid for classical time series models such as ARMA or GARCH processes,\nextend substantially the existing results obtained for some homoscedatic time\nseries models. Asymptotic expansion of our estimator is obtained by combining\nsome martingale type arguments and a coupling method for time series which is\nof independent interest. We also study the uniform convergence of our estimator\non compact intervals.\n", "versions": [{"version": "v1", "created": "Fri, 28 Oct 2016 15:32:33 GMT"}], "update_date": "2016-10-31", "authors_parsed": [["Truquet", "Lionel", ""]]}, {"id": "1610.09289", "submitter": "Lei Yu", "authors": "Lei Yu, Houqiang Li, Chang Wen Chen", "title": "Generalized Common Informations: Measuring Commonness by the Conditional\n  Maximal Correlation", "comments": "Some typos are corrected", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR math.IT math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In literature, different common informations were defined by G\\'acs and\nK\\\"orner, by Wyner, and by Kumar, Li, and Gamal, respectively. In this paper,\nwe define two generalized versions of common informations, named approximate\nand exact information-correlation functions, by exploiting the conditional\nmaximal correlation as a commonness or privacy measure. These two generalized\ncommon informations encompass the notions of G\\'acs-K\\\"orner's, Wyner's, and\nKumar-Li-Gamal's common informations as special cases. Furthermore, to give\noperational characterizations of these two generalized common informations, we\nalso study the problems of private sources synthesis and common information\nextraction, and show that the information-correlation functions are equal to\nthe minimum rates of commonness needed to ensure that some conditional maximal\ncorrelation constraints are satisfied for the centralized setting versions of\nthese problems. As a byproduct, the conditional maximal correlation has been\nstudied as well.\n", "versions": [{"version": "v1", "created": "Fri, 28 Oct 2016 16:07:30 GMT"}, {"version": "v2", "created": "Tue, 17 Jan 2017 00:05:39 GMT"}, {"version": "v3", "created": "Mon, 24 Jul 2017 14:08:54 GMT"}], "update_date": "2017-07-26", "authors_parsed": [["Yu", "Lei", ""], ["Li", "Houqiang", ""], ["Chen", "Chang Wen", ""]]}, {"id": "1610.09292", "submitter": "Nestor Parolya Jun.-Prof. Dr.", "authors": "Taras Bodnar, Ostap Okhrin, Nestor Parolya", "title": "Optimal Shrinkage Estimator for High-Dimensional Mean Vector", "comments": "20 pages, UPDATE2: revised version of the manuscript accepted for\n  publication in Journal of Multivariate Analysis", "journal-ref": null, "doi": "10.1016/j.jmva.2018.07.004", "report-no": null, "categories": "math.ST q-fin.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we derive the optimal linear shrinkage estimator for the\nhigh-dimensional mean vector using random matrix theory. The results are\nobtained under the assumption that both the dimension $p$ and the sample size\n$n$ tend to infinity in such a way that $p/n \\to c\\in(0,\\infty)$. Under weak\nconditions imposed on the underlying data generating mechanism, we find the\nasymptotic equivalents to the optimal shrinkage intensities and estimate them\nconsistently. The proposed nonparametric estimator for the high-dimensional\nmean vector has a simple structure and is proven to minimize asymptotically,\nwith probability $1$, the quadratic loss when $c\\in(0,1)$. When $c\\in(1,\n\\infty)$ we modify the estimator by using a feasible estimator for the\nprecision covariance matrix. To this end, an exhaustive simulation study and an\napplication to real data are provided where the proposed estimator is compared\nwith known benchmarks from the literature. It turns out that the existing\nestimators of the mean vector, including the new proposal, converge to the\nsample mean vector when the true mean vector has an unbounded Euclidean norm.\n", "versions": [{"version": "v1", "created": "Fri, 28 Oct 2016 16:10:19 GMT"}, {"version": "v2", "created": "Tue, 10 Oct 2017 18:21:44 GMT"}, {"version": "v3", "created": "Sat, 14 Jul 2018 10:53:20 GMT"}], "update_date": "2018-07-17", "authors_parsed": [["Bodnar", "Taras", ""], ["Okhrin", "Ostap", ""], ["Parolya", "Nestor", ""]]}, {"id": "1610.09433", "submitter": "Colin LaMont", "authors": "Colin H. LaMont and Paul A. Wiggins", "title": "The Lindley paradox: The loss of resolution in Bayesian inference", "comments": "11 pages, 5 figures, and Appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are three principle paradigms of statistics: Bayesian, frequentist and\ninformation-based inference. Although these paradigms are in agreement in some\ncontexts, the Lindley paradox describes a class of problems, models of unknown\ndimension, where conflicting conclusions are generated by frequentist and\nBayesian inference. This conflict can materially affect the scientific\nconclusions. Understanding the Lindley paradox---where it applies, why it\noccurs, and how it can be avoided---is therefore essential to the understanding\nof statistical analysis. In this paper, we revisit the Lindley paradox in the\ncontext of a simple biophysical application. We describe how predictive and\npostdictive measures of model performance provide a natural framework for\nunderstanding the Lindley paradox. We then identify methods which result in\noptimal experimental resolution for discovery.\n", "versions": [{"version": "v1", "created": "Sat, 29 Oct 2016 00:53:20 GMT"}, {"version": "v2", "created": "Wed, 16 Aug 2017 18:30:26 GMT"}], "update_date": "2017-08-18", "authors_parsed": [["LaMont", "Colin H.", ""], ["Wiggins", "Paul A.", ""]]}, {"id": "1610.09502", "submitter": "Eugenia Stoimenova", "authors": "Eugenia Stoimenova, N. Balakrishnan", "title": "Sidak-type tests for the two-sample problem based on precedence and\n  exceedance statistics", "comments": "To appear in Statistics: A Journal of Theoretical and Applied\n  Statistics", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with a class of nonparametric two-sample tests for ordered\nalternatives. The test statistics proposed are based on the number of\nobservations from one sample that precede or exceed a threshold specified by\nthe other sample, and they are extensions of \\v{S}id\\'ak's test. We derive\ntheir exact null distributions and also discuss a large-sample approximation.\nWe then study their power properties exactly against the Lehmann alternative\nand make some comparative comments. Finally, we present an example to\nillustrate the proposed tests.\n", "versions": [{"version": "v1", "created": "Sat, 29 Oct 2016 13:01:36 GMT"}], "update_date": "2016-11-01", "authors_parsed": [["Stoimenova", "Eugenia", ""], ["Balakrishnan", "N.", ""]]}, {"id": "1610.09735", "submitter": "Haolei Weng", "authors": "Haolei Weng and Yang Feng", "title": "Community detection with nodal information", "comments": "53 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Community detection is one of the fundamental problems in the study of\nnetwork data. Most existing community detection approaches only consider edge\ninformation as inputs, and the output could be suboptimal when nodal\ninformation is available. In such cases, it is desirable to leverage nodal\ninformation for the improvement of community detection accuracy. Towards this\ngoal, we propose a flexible network model incorporating nodal information, and\ndevelop likelihood-based inference methods. For the proposed methods, we\nestablish favorable asymptotic properties as well as efficient algorithms for\ncomputation. Numerical experiments show the effectiveness of our methods in\nutilizing nodal information across a variety of simulated and real network data\nsets.\n", "versions": [{"version": "v1", "created": "Mon, 31 Oct 2016 00:00:49 GMT"}, {"version": "v2", "created": "Sat, 10 Dec 2016 19:27:25 GMT"}], "update_date": "2016-12-13", "authors_parsed": [["Weng", "Haolei", ""], ["Feng", "Yang", ""]]}, {"id": "1610.09780", "submitter": "Rebecca Steorts", "authors": "Giacomo Zanella, Brenda Betancourt, Hanna Wallach, Jeffrey Miller,\n  Abbas Zaidi, and Rebecca C. Steorts", "title": "Flexible Models for Microclustering with Application to Entity\n  Resolution", "comments": "15 pages, 3 figures, 1 table, to appear NIPS 2016. arXiv admin note:\n  text overlap with arXiv:1512.00792", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.AP stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most generative models for clustering implicitly assume that the number of\ndata points in each cluster grows linearly with the total number of data\npoints. Finite mixture models, Dirichlet process mixture models, and\nPitman--Yor process mixture models make this assumption, as do all other\ninfinitely exchangeable clustering models. However, for some applications, this\nassumption is inappropriate. For example, when performing entity resolution,\nthe size of each cluster should be unrelated to the size of the data set, and\neach cluster should contain a negligible fraction of the total number of data\npoints. These applications require models that yield clusters whose sizes grow\nsublinearly with the size of the data set. We address this requirement by\ndefining the microclustering property and introducing a new class of models\nthat can exhibit this property. We compare models within this class to two\ncommonly used clustering models using four entity-resolution data sets.\n", "versions": [{"version": "v1", "created": "Mon, 31 Oct 2016 04:00:11 GMT"}], "update_date": "2016-11-01", "authors_parsed": [["Zanella", "Giacomo", ""], ["Betancourt", "Brenda", ""], ["Wallach", "Hanna", ""], ["Miller", "Jeffrey", ""], ["Zaidi", "Abbas", ""], ["Steorts", "Rebecca C.", ""]]}, {"id": "1610.09957", "submitter": "Joydeep Chowdhury", "authors": "Joydeep Chowdhury and Probal Chaudhuri", "title": "Convergence Rates for Kernel Regression in Infinite Dimensional Spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a nonparametric regression setup, where the covariate is a random\nelement in a complete separable metric space, and the parameter of interest\nassociated with the conditional distribution of the response lies in a\nseparable Banach space. We derive the optimum convergence rate for the kernel\nestimate of the parameter in this setup. The small ball probability in the\ncovariate space plays a critical role in determining the asymptotic variance of\nkernel estimates. Unlike the case of finite dimensional covariates, we show\nthat the asymptotic orders of the bias and the variance of the estimate\nachieving the optimum convergence rate may be different for infinite\ndimensional covariates. Also, the bandwidth, which balances the bias and the\nvariance, may lead to an estimate with suboptimal mean square error for\ninfinite dimensional covariates. We describe a data-driven adaptive choice of\nthe bandwidth, and derive the asymptotic behavior of the adaptive estimate.\n", "versions": [{"version": "v1", "created": "Mon, 31 Oct 2016 14:58:43 GMT"}, {"version": "v2", "created": "Thu, 5 Jul 2018 16:17:30 GMT"}, {"version": "v3", "created": "Tue, 23 Oct 2018 12:04:39 GMT"}, {"version": "v4", "created": "Thu, 15 Nov 2018 15:18:55 GMT"}], "update_date": "2018-11-16", "authors_parsed": [["Chowdhury", "Joydeep", ""], ["Chaudhuri", "Probal", ""]]}, {"id": "1610.10028", "submitter": "Art Owen", "authors": "Art B. Owen", "title": "Refiltering hypothesis tests to control sign error", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common, though not recommended statistical practice is to report confidence\nintervals if and only if they exclude a null value of 0. The resulting filtered\nconfidence intervals generally do not have their nominal confidence level. More\nworryingly, in low power settings their center points will be much farther from\nzero than the true parameter is and they will frequently lie on the wrong side\nof zero. Many confidence intervals are constructed using an asymptotically\nGaussian parameter estimate accompanied by a weakly consistent estimate of its\nvariance. In these cases, we can subject the given confidence interval(s) to a\nsecond filtering step such that the probability of a sign error is controled.\nThis refiltering step retains only those confidence intervals that are\nsufficiently well separated from the origin. It requires no assumptions on the\ndependencies among the test statistics.\n", "versions": [{"version": "v1", "created": "Mon, 31 Oct 2016 17:30:33 GMT"}, {"version": "v2", "created": "Sat, 24 Aug 2019 00:20:29 GMT"}, {"version": "v3", "created": "Wed, 13 Nov 2019 22:46:53 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Owen", "Art B.", ""]]}]