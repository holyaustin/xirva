[{"id": "1609.00286", "submitter": "Kengo Kato", "authors": "Masaaki Imaizumi and Kengo Kato", "title": "PCA-based estimation for functional linear regression with functional\n  responses", "comments": "30 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies a regression model where both predictor and response\nvariables are random functions. We consider a functional linear model where the\nconditional mean of the response variable at each time point is given by a\nlinear functional of the predictor variable. In this paper, we are interested\nin estimation of the integral kernel $b(s,t)$ of the conditional expectation\noperator, where $s$ is an output variable while $t$ is a variable that\ninteracts with the predictor variable. This problem is an ill-posed inverse\nproblem, and we consider two estimators based on the functional principal\ncomponent analysis (PCA). We show that under suitable regularity conditions, an\nestimator based on the single truncation attains the convergence rate for the\nintegrated squared error that is characterized by smoothness of the function $b\n(s,t)$ in $t$ together with the decay rate of the eigenvalues of the covariance\noperator, but the rate does not depend on smoothness of $b(s,t)$ in $s$. This\nrate is shown to be minimax optimal, and consequently smoothness of $b(s,t)$ in\n$s$ does not affect difficulty of estimating $b$. We also consider an\nalternative estimator based on the double truncation, and provide conditions\nunder which the alternative estimator attains the optimal rate. We conduct\nsimulations to verify the performance of PCA-based estimators in the finite\nsample. Finally, we apply our estimators to investigate the relation between\nthe lifetime pattern of working hours and total income, and the relation\nbetween the electricity spot price and the wind power infeed.\n", "versions": [{"version": "v1", "created": "Thu, 1 Sep 2016 15:48:21 GMT"}, {"version": "v2", "created": "Wed, 22 Mar 2017 11:41:06 GMT"}], "update_date": "2017-03-23", "authors_parsed": [["Imaizumi", "Masaaki", ""], ["Kato", "Kengo", ""]]}, {"id": "1609.00368", "submitter": "Emmanouil Zampetakis", "authors": "Constantinos Daskalakis, Christos Tzamos, Manolis Zampetakis", "title": "Ten Steps of EM Suffice for Mixtures of Two Gaussians", "comments": "Accepted for presentation at Conference on Learning Theory (COLT)\n  2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DS math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Expectation-Maximization (EM) algorithm is a widely used method for\nmaximum likelihood estimation in models with latent variables. For estimating\nmixtures of Gaussians, its iteration can be viewed as a soft version of the\nk-means clustering algorithm. Despite its wide use and applications, there are\nessentially no known convergence guarantees for this method. We provide global\nconvergence guarantees for mixtures of two Gaussians with known covariance\nmatrices. We show that the population version of EM, where the algorithm is\ngiven access to infinitely many samples from the mixture, converges\ngeometrically to the correct mean vectors, and provide simple, closed-form\nexpressions for the convergence rate. As a simple illustration, we show that,\nin one dimension, ten steps of the EM algorithm initialized at infinity result\nin less than 1\\% error estimation of the means. In the finite sample regime, we\nshow that, under a random initialization, $\\tilde{O}(d/\\epsilon^2)$ samples\nsuffice to compute the unknown vectors to within $\\epsilon$ in Mahalanobis\ndistance, where $d$ is the dimension. In particular, the error rate of the EM\nbased estimator is $\\tilde{O}\\left(\\sqrt{d \\over n}\\right)$ where $n$ is the\nnumber of samples, which is optimal up to logarithmic factors.\n", "versions": [{"version": "v1", "created": "Thu, 1 Sep 2016 19:57:26 GMT"}, {"version": "v2", "created": "Thu, 15 Sep 2016 19:55:11 GMT"}, {"version": "v3", "created": "Wed, 12 Apr 2017 17:59:27 GMT"}, {"version": "v4", "created": "Thu, 13 Apr 2017 00:55:32 GMT"}, {"version": "v5", "created": "Mon, 5 Jun 2017 07:53:53 GMT"}], "update_date": "2017-06-06", "authors_parsed": [["Daskalakis", "Constantinos", ""], ["Tzamos", "Christos", ""], ["Zampetakis", "Manolis", ""]]}, {"id": "1609.00395", "submitter": "Stefan Sommer", "authors": "Stefan Sommer", "title": "Anisotropically Weighted and Nonholonomically Constrained Evolutions on\n  Manifolds", "comments": null, "journal-ref": null, "doi": "10.3390/e18120425", "report-no": null, "categories": "math.DG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present evolution equations for a family of paths that results from\nanisotropically weighting curve energies in non-linear statistics of manifold\nvalued data. This situation arises when performing inference on data that have\nnon-trivial covariance and are anisotropic distributed. The family can be\ninterpreted as most probable paths for a driving semi-martingale that through\nstochastic development is mapped to the manifold. We discuss how the paths are\nprojections of geodesics for a sub-Riemannian metric on the frame bundle of the\nmanifold, and how the curvature of the underlying connection appears in the\nsub-Riemannian Hamilton-Jacobi equations. Evolution equations for both metric\nand cometric formulations of the sub-Riemannian metric are derived. We\nfurthermore show how rank-deficient metrics can be mixed with an underlying\nRiemannian metric, and we relate the paths to geodesics and polynomials in\nRiemannian geometry. Examples from the family of paths are visualized on\nembedded surfaces, and we explore computational representations on finite\ndimensional landmark manifolds with geometry induced from right-invariant\nmetrics on diffeomorphism groups.\n", "versions": [{"version": "v1", "created": "Thu, 1 Sep 2016 20:15:23 GMT"}, {"version": "v2", "created": "Wed, 23 Nov 2016 10:03:19 GMT"}], "update_date": "2016-12-21", "authors_parsed": [["Sommer", "Stefan", ""]]}, {"id": "1609.00402", "submitter": "Andy Leung", "authors": "Andy Leung and Victor J. Yohai and Ruben H. Zamar", "title": "Multivariate Location and Scatter Matrix Estimation Under Cellwise and\n  Casewise Contamination", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of multivariate location and scatter matrix\nestimation when the data contain cellwise and casewise outliers. Agostinelli et\nal. (2015) propose a two-step approach to deal with this problem: first, apply\na univariate filter to remove cellwise outliers and second, apply a generalized\nS-estimator to downweight casewise outliers. We improve this proposal in three\nmain directions. First, we introduce a consistent bivariate filter to be used\nin combination with the univariate filter in the first step. Second, we propose\na new fast subsampling procedure to generate starting points for the\ngeneralized S-estimator in the second step. Third, we consider a non-monotonic\nweight function for the generalized S-estimator to better deal with casewise\noutliers in high dimension. A simulation study and real data example show that,\nunlike the original two-step procedure, the modified two-step approach performs\nand scales well for high dimension. Moreover, the modified procedure\noutperforms the original one and other state-of-the-art robust procedures under\ncellwise and casewise data contamination.\n", "versions": [{"version": "v1", "created": "Thu, 1 Sep 2016 21:03:49 GMT"}, {"version": "v2", "created": "Sun, 25 Dec 2016 10:36:00 GMT"}], "update_date": "2016-12-28", "authors_parsed": [["Leung", "Andy", ""], ["Yohai", "Victor J.", ""], ["Zamar", "Ruben H.", ""]]}, {"id": "1609.00606", "submitter": "Trang Nguyen", "authors": "Trang Quynh Nguyen, Allan Dafoe and Elizabeth L. Ogburn", "title": "The magnitude and direction of collider bias for binary variables", "comments": null, "journal-ref": "Epidemiologic Methods. 2019. Vol 8, Issue 1", "doi": "10.1515/em-2017-0013", "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Suppose we are interested in the effect of variable $X$ on variable $Y$. If\n$X$ and $Y$ both influence, or are associated with variables that influence, a\ncommon outcome, called a collider, then conditioning on the collider (or on a\nvariable influenced by the collider -- its \"child\") induces a spurious\nassociation between $X$ and $Y$, which is known as collider bias.\nCharacterizing the magnitude and direction of collider bias is crucial for\nunderstanding the implications of selection bias and for adjudicating decisions\nabout whether to control for variables that are known to be associated with\nboth exposure and outcome but could be either confounders or colliders.\nConsidering a class of situations where all variables are binary, and where $X$\nand $Y$ either are, or are respectively influenced by, two marginally\nindependent causes of a collider, we derive collider bias that results from (i)\nconditioning on specific levels of, or (ii) linear regression adjustment for,\nthe collider (or its child). We also derive simple conditions that determine\nthe sign of such bias.\n", "versions": [{"version": "v1", "created": "Fri, 2 Sep 2016 14:09:48 GMT"}, {"version": "v2", "created": "Fri, 28 Apr 2017 23:10:27 GMT"}, {"version": "v3", "created": "Mon, 14 Jan 2019 20:01:30 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Nguyen", "Trang Quynh", ""], ["Dafoe", "Allan", ""], ["Ogburn", "Elizabeth L.", ""]]}, {"id": "1609.00672", "submitter": "Elie Wolfe", "authors": "Elie Wolfe, Robert W. Spekkens, Tobias Fritz", "title": "The Inflation Technique for Causal Inference with Latent Variables", "comments": "Minor final corrections, updated to match the published version as\n  closely as possible", "journal-ref": "J. Causal Inference 7(2), 2019", "doi": "10.1515/jci-2017-0020", "report-no": null, "categories": "quant-ph math.ST stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of causal inference is to determine if a given probability\ndistribution on observed variables is compatible with some causal structure.\nThe difficult case is when the causal structure includes latent variables. We\nhere introduce the $\\textit{inflation technique}$ for tackling this problem. An\ninflation of a causal structure is a new causal structure that can contain\nmultiple copies of each of the original variables, but where the ancestry of\neach copy mirrors that of the original. To every distribution of the observed\nvariables that is compatible with the original causal structure, we assign a\nfamily of marginal distributions on certain subsets of the copies that are\ncompatible with the inflated causal structure. It follows that compatibility\nconstraints for the inflation can be translated into compatibility constraints\nfor the original causal structure. Even if the constraints at the level of\ninflation are weak, such as observable statistical independences implied by\ndisjoint causal ancestry, the translated constraints can be strong. We apply\nthis method to derive new inequalities whose violation by a distribution\nwitnesses that distribution's incompatibility with the causal structure (of\nwhich Bell inequalities and Pearl's instrumental inequality are prominent\nexamples). We describe an algorithm for deriving all such inequalities for the\noriginal causal structure that follow from ancestral independences in the\ninflation. For three observed binary variables with pairwise common causes, it\nyields inequalities that are stronger in at least some aspects than those\nobtainable by existing methods. We also describe an algorithm that derives a\nweaker set of inequalities but is more efficient. Finally, we discuss which\ninflations are such that the inequalities one obtains from them remain valid\neven for quantum (and post-quantum) generalizations of the notion of a causal\nmodel.\n", "versions": [{"version": "v1", "created": "Fri, 2 Sep 2016 17:21:25 GMT"}, {"version": "v2", "created": "Mon, 12 Sep 2016 10:55:55 GMT"}, {"version": "v3", "created": "Wed, 14 Jun 2017 16:22:04 GMT"}, {"version": "v4", "created": "Fri, 10 Aug 2018 03:39:13 GMT"}, {"version": "v5", "created": "Mon, 22 Jul 2019 20:08:08 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Wolfe", "Elie", ""], ["Spekkens", "Robert W.", ""], ["Fritz", "Tobias", ""]]}, {"id": "1609.00675", "submitter": "Tulasi Ram Reddy Annapareddy", "authors": "Tulasi Ram Reddy", "title": "Limiting empirical distribution of zeros and critical points of random\n  polynomials agree in general", "comments": "17 Pages. Based on author's Ph.D thesis arXiv:1602.05298", "journal-ref": "Electron. J. Probab. Volume 22 (2017), paper no. 74, 18 pp", "doi": "10.1214/17-EJP85", "report-no": null, "categories": "math.PR math.CV math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we study critical points (zeros of derivative) of random\npolynomials. Take two deterministic sequences $\\{a_n\\}_{n\\geq1}$ and\n$\\{b_n\\}_{n\\geq1}$ of complex numbers whose limiting empirical measures are\nsame. By choosing $\\xi_n = a_n$ or $b_n$ with equal probability, define the\nsequence of polynomials by $P_n(z)=(z-\\xi_1)\\dots(z-\\xi_n)$. We show that the\nlimiting measure of zeros and critical points agree for this sequence of random\npolynomials under some assumption. We also prove a similar result for\ntriangular array of numbers. A similar result for zeros of generalized\nderivative (can be thought as random rational function) is also proved.\nPemantle and Rivin initiated the study of critical points of random\npolynomials. Kabluchko proved the result considering the zeros to be i.i.d.\nrandom variables.\n", "versions": [{"version": "v1", "created": "Fri, 2 Sep 2016 17:29:16 GMT"}], "update_date": "2017-10-02", "authors_parsed": [["Reddy", "Tulasi Ram", ""]]}, {"id": "1609.00710", "submitter": "Mohammad Arshad Rahman", "authors": "Mohammad Arshad Rahman and Shubham Karnawat", "title": "Flexible Bayesian Quantile Regression in Ordinal Models", "comments": "39 pages, 4 Figures", "journal-ref": "Advances in Econometrics, Volume 40B, 2019", "doi": "10.1108/S0731-90532019000040B011", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper introduces an estimation method for flexible Bayesian quantile\nregression in ordinal (FBQROR) models i.e., an ordinal quantile regression\nwhere the error follows a generalized asymmetric Laplace (GAL) distribution.\nThe GAL distribution, unlike the asymmetric Laplace (AL) distribution, allows\nto fix specific quantiles while simultaneously letting the mode, skewness and\ntails to vary. We also introduce the cumulative distribution function\n(necessary for constructing the likelihood) and the moment generating function\nof the GAL distribution. The algorithm is illustrated in multiple simulation\nstudies and implemented to analyze public opinion on homeownership as the best\nlong-term investment in the United States.\n", "versions": [{"version": "v1", "created": "Fri, 2 Sep 2016 19:32:00 GMT"}, {"version": "v2", "created": "Thu, 14 Sep 2017 05:39:55 GMT"}, {"version": "v3", "created": "Fri, 13 Sep 2019 04:13:02 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Rahman", "Mohammad Arshad", ""], ["Karnawat", "Shubham", ""]]}, {"id": "1609.00711", "submitter": "Philipp Otto", "authors": "Philipp Otto and Wolfgang Schmid and Robert Garthoff", "title": "Generalized Spatial and Spatiotemporal Autoregressive Conditional\n  Heteroscedasticity", "comments": null, "journal-ref": null, "doi": "10.1016/j.spasta.2018.07.005", "report-no": null, "categories": "math.ST stat.AP stat.ME stat.OT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a new spatial model that incorporates\nheteroscedastic variance depending on neighboring locations. The proposed\nprocess is regarded as the spatial equivalent to the temporal autoregressive\nconditional heteroscedasticity (ARCH) model. We show additionally how the\nintroduced spatial ARCH model can be used in spatiotemporal settings. In\ncontrast to the temporal ARCH model, in which the distribution is known given\nthe full information set of the prior periods, the distribution is not\nstraightforward in the spatial and spatiotemporal setting. However, it is\npossible to estimate the parameters of the model using the maximum-likelihood\napproach. Via Monte Carlo simulations, we demonstrate the performance of the\nestimator for a specific spatial weighting matrix. Moreover, we combine the\nknown spatial autoregressive model with the spatial ARCH model assuming\nheteroscedastic errors. Eventually, the proposed autoregressive process is\nillustrated using an empirical example. Specifically, we model lung cancer\nmortality in 3108 U.S. counties and compare the introduced model with two\nbenchmark approaches.\n", "versions": [{"version": "v1", "created": "Fri, 2 Sep 2016 19:38:23 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Otto", "Philipp", ""], ["Schmid", "Wolfgang", ""], ["Garthoff", "Robert", ""]]}, {"id": "1609.00814", "submitter": "Stephan Huckemann", "authors": "Stephan F. Huckemann and Benjamin Eltzner", "title": "Backward Nested Descriptors Asymptotics with Inference on Stem Cell\n  Differentiation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For sequences of random backward nested subspaces as occur, say, in dimension\nreduction for manifold or stratified space valued data, asymptotic results are\nderived. In fact, we formulate our results more generally for backward nested\nfamilies of descriptors (BNFD). Under rather general conditions, asymptotic\nstrong consistency holds. Under additional, still rather general hypotheses,\namong them existence of a.s. local twice differentiable charts, asymptotic\njoint normality of a BNFD can be shown. If charts factor suitably, this leads\nto individual asymptotic normality for the last element, a principal nested\nmean or a principal nested geodesic, say. It turns out that these results\npertain to principal nested spheres (PNS) and principal nested great subsphere\n(PNGS) analysis by Jung et al. (2010) as well as to the intrinsic mean on a\nfirst geodesic principal component (IMo1GPC) for manifolds and Kendall's shape\nspaces. A nested bootstrap two-sample test is derived and illustrated with\nsimulations. In a study on real data, PNGS is applied to track early human\nmesenchymal stem cell differentiation over a coarse time grid and, among\nothers, to locate a change point with direct consequences for the design of\nfurther studies.\n", "versions": [{"version": "v1", "created": "Sat, 3 Sep 2016 11:00:00 GMT"}], "update_date": "2016-09-06", "authors_parsed": [["Huckemann", "Stephan F.", ""], ["Eltzner", "Benjamin", ""]]}, {"id": "1609.00834", "submitter": "Marie-H\\'el\\`ene Descary", "authors": "Marie-H\\'el\\`ene Descary and Victor M. Panaretos", "title": "Functional Data Analysis by Matrix Completion", "comments": "To appear in the Annals of Statistics", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Functional data analyses typically proceed by smoothing, followed by\nfunctional PCA. This paradigm implicitly assumes that rough variation is due to\nnuisance noise. Nevertheless, relevant functional features such as\ntime-localised or short scale fluctuations may indeed be rough relative to the\nglobal scale, but still smooth at shorter scales. These may be confounded with\nthe global smooth components of variation by the smoothing and PCA, potentially\ndistorting the parsimony and interpretability of the analysis. The goal of this\npaper is to investigate how both smooth and rough variations can be recovered\non the basis of discretely observed functional data. Assuming that a functional\ndatum arises as the sum of two uncorrelated components, one smooth and one\nrough, we develop identifiability conditions for the recovery of the two\ncorresponding covariance operators. The key insight is that they should possess\ncomplementary forms of parsimony: one smooth and finite rank (large scale), and\nthe other banded and potentially infinite rank (small scale). Our conditions\nelucidate the precise interplay between rank, bandwidth, and grid resolution.\nUnder these conditions, we show that the recovery problem is equivalent to\nrank-constrained matrix completion, and exploit this to construct estimators of\nthe two covariances, without assuming knowledge of the true bandwidth or rank;\nwe study their asymptotic behaviour, and then use them to recover the smooth\nand rough components of each functional datum by best linear prediction. As a\nresult, we effectively produce separate functional PCAs for smooth and rough\nvariation.\n", "versions": [{"version": "v1", "created": "Sat, 3 Sep 2016 15:03:02 GMT"}, {"version": "v2", "created": "Tue, 18 Sep 2018 06:24:20 GMT"}], "update_date": "2018-09-19", "authors_parsed": [["Descary", "Marie-H\u00e9l\u00e8ne", ""], ["Panaretos", "Victor M.", ""]]}, {"id": "1609.00861", "submitter": "Richard Samworth", "authors": "Arlene K. H. Kim, Adityanand Guntuboyina and Richard J. Samworth", "title": "Adaptation in log-concave density estimation", "comments": "38 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The log-concave maximum likelihood estimator of a density on the real line\nbased on a sample of size $n$ is known to attain the minimax optimal rate of\nconvergence of $O(n^{-4/5})$ with respect to, e.g., squared Hellinger distance.\nIn this paper, we show that it also enjoys attractive adaptation properties, in\nthe sense that it achieves a faster rate of convergence when the logarithm of\nthe true density is $k$-affine (i.e.\\ made up of $k$ affine pieces), provided\n$k$ is not too large. Our results use two different techniques: the first\nrelies on a new Marshall's inequality for log-concave density estimation, and\nreveals that when the true density is close to log-linear on its support, the\nlog-concave maximum likelihood estimator can achieve the parametric rate of\nconvergence in total variation distance. Our second approach depends on local\nbracketing entropy methods, and allows us to prove a sharp oracle inequality,\nwhich implies in particular that the rate of convergence with respect to\nvarious global loss functions, including Kullback--Leibler divergence, is\n$O\\bigl(\\frac{k}{n}\\log^{5/4} n\\bigr)$ when the true density is log-concave and\nits logarithm is close to $k$-affine.\n", "versions": [{"version": "v1", "created": "Sat, 3 Sep 2016 20:38:16 GMT"}], "update_date": "2016-09-06", "authors_parsed": [["Kim", "Arlene K. H.", ""], ["Guntuboyina", "Adityanand", ""], ["Samworth", "Richard J.", ""]]}, {"id": "1609.00883", "submitter": "Zheng Tracy Ke", "authors": "Zheng Tracy Ke", "title": "Detecting Rare and Weak Spikes in Large Covariance Matrices", "comments": "45 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given $p$-dimensional Gaussian vectors $X_i \\stackrel{iid}{\\sim} N(0,\n\\Sigma)$, $1 \\leq i \\leq n$, where $p \\geq n$, we are interested in testing a\nnull hypothesis where $\\Sigma = I_p$ against an alternative hypothesis where\nall eigenvalues of $\\Sigma$ are $1$, except for $r$ of them are larger than $1$\n(i.e., spiked eigenvalues).\n  We consider a Rare/Weak setting where the spikes are sparse (i.e., $1 \\ll r\n\\ll p$) and individually weak (i.e., each spiked eigenvalue is only slightly\nlarger than $1$), and discover a phase transition: the two-dimensional phase\nspace that calibrates the spike sparsity and strengths partitions into the\nRegion of Impossibility and the Region of Possibility. In Region of\nImpossibility, all tests are (asymptotically) powerless in separating the\nalternative from the null. In Region of Possibility, there are tests that have\n(asymptotically) full power.\n  We consider a CuSum test, a trace-based test, an eigenvalue-based Higher\nCriticism test, and a Tracy-Widom test (Johnstone 2001), and show that the\nfirst two tests have asymptotically full power in Region of Possibility.\n  To use our results from a different angle, we derive new bounds for (a)\nempirical eigenvalues, and (b) cumulative sums of the empirical eigenvalues,\nboth under the alternative hypothesis. Part (a) is related to those in Baik,\nBen-Arous and Peche (2005), but both the settings and results are different.\n  The study requires careful analysis of the $L^1$-distance of our testing\nproblem and delicate Radom Matrix Theory. Our technical devises include (a) a\nGaussian proxy model, (b) Le Cam's comparison of experiments, and (c) large\ndeviation bounds on empirical eigenvalues.\n", "versions": [{"version": "v1", "created": "Sun, 4 Sep 2016 01:16:55 GMT"}, {"version": "v2", "created": "Wed, 5 Sep 2018 21:20:08 GMT"}], "update_date": "2018-09-07", "authors_parsed": [["Ke", "Zheng Tracy", ""]]}, {"id": "1609.00926", "submitter": "Lorenzo Mercuri", "authors": "Asmerilda Hitaj, Friedrich Hubalek, Lorenzo Mercuri and Edit Rroji", "title": "Multivariate Mixed Tempered Stable Distribution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The multivariate version of the Mixed Tempered Stable is proposed. It is a\ngeneralization of the Normal Variance Mean Mixtures. Characteristics of this\nnew distribution and its capacity in fitting tails and capturing dependence\nstructure between components are investigated. We discuss a random number\ngenerating procedure and introduce an estimation methodology based on the\nminimization of a distance between empirical and theoretical characteristic\nfunctions. Asymptotic tail behavior of the univariate Mixed Tempered Stable is\nexploited in the estimation procedure in order to obtain a better model\nfitting. Advantages of the multivariate Mixed Tempered Stable distribution are\ndiscussed and illustrated via simulation study.\n", "versions": [{"version": "v1", "created": "Sun, 4 Sep 2016 12:43:57 GMT"}, {"version": "v2", "created": "Sat, 10 Sep 2016 22:23:11 GMT"}, {"version": "v3", "created": "Sat, 1 Oct 2016 11:02:58 GMT"}], "update_date": "2016-10-04", "authors_parsed": [["Hitaj", "Asmerilda", ""], ["Hubalek", "Friedrich", ""], ["Mercuri", "Lorenzo", ""], ["Rroji", "Edit", ""]]}, {"id": "1609.00940", "submitter": "Keisuke Yano", "authors": "Keisuke Yano, Fumiyasu Komaki", "title": "Non-asymptotic Bayesian Minimax Adaptation", "comments": "30pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies a Bayesian approach to non-asymptotic minimax adaptation\nin nonparametric estimation. Estimating an input function on the basis of\noutput functions in a Gaussian white-noise model is discussed. The input\nfunction is assumed to be in a Sobolev ellipsoid with an unknown smoothness and\nan unknown radius. Our purpose in this paper is to present a Bayesian approach\nattaining minimaxity up to a universal constant without any knowledge regarding\nthe smoothness and the radius. Our Bayesian approach provides not only a\nrate-exact minimax adaptive estimator in large sample asymptotics but also a\nrisk bound for the Bayes estimator quantifying the effects of both the\nsmoothness and the ratio of the squared radius to the noise variance, where the\nsmoothness and the ratio are the key parameters to describe the minimax risk in\nthis model. Application to non-parametric regression models is also discussed.\n", "versions": [{"version": "v1", "created": "Sun, 4 Sep 2016 14:48:41 GMT"}, {"version": "v2", "created": "Thu, 6 Jul 2017 01:40:02 GMT"}, {"version": "v3", "created": "Fri, 5 Jan 2018 07:25:05 GMT"}, {"version": "v4", "created": "Tue, 6 Mar 2018 09:41:15 GMT"}, {"version": "v5", "created": "Wed, 29 Aug 2018 09:34:06 GMT"}], "update_date": "2018-08-30", "authors_parsed": [["Yano", "Keisuke", ""], ["Komaki", "Fumiyasu", ""]]}, {"id": "1609.01025", "submitter": "Stanislav Minsker", "authors": "Larry Goldstein, Stanislav Minsker and Xiaohan Wei", "title": "Structured signal recovery from non-linear and heavy-tailed measurements", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study high-dimensional signal recovery from non-linear measurements with\ndesign vectors having elliptically symmetric distribution. Special attention is\ndevoted to the situation when the unknown signal belongs to a set of low\nstatistical complexity, while both the measurements and the design vectors are\nheavy-tailed. We propose and analyze a new estimator that adapts to the\nstructure of the problem, while being robust both to the possible model\nmisspecification characterized by arbitrary non-linearity of the measurements\nas well as to data corruption modeled by the heavy-tailed distributions.\nMoreover, this estimator has low computational complexity. Our results are\nexpressed in the form of exponential concentration inequalities for the error\nof the proposed estimator. On the technical side, our proofs rely on the\ngeneric chaining methods, and illustrate the power of this approach for\nstatistical applications. Theory is supported by numerical experiments\ndemonstrating that our estimator outperforms existing alternatives when data is\nheavy-tailed.\n", "versions": [{"version": "v1", "created": "Mon, 5 Sep 2016 03:38:21 GMT"}, {"version": "v2", "created": "Fri, 11 Nov 2016 02:01:41 GMT"}], "update_date": "2016-11-14", "authors_parsed": [["Goldstein", "Larry", ""], ["Minsker", "Stanislav", ""], ["Wei", "Xiaohan", ""]]}, {"id": "1609.01057", "submitter": "Romain Aza\\\"is", "authors": "Romain Aza\\\"is, Alexandre Genadot, Beno\\^it Henry", "title": "Inference for conditioned Galton-Watson trees from their Harris path", "comments": "43 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tree-structured data naturally appear in various fields, particularly in\nbiology where plants and blood vessels may be described by trees, but also in\ncomputer science because XML documents form a tree structure. This paper is\ndevoted to the estimation of the relative scale parameter of conditioned\nGalton-Watson trees. New estimators are introduced and their consistency is\nstated. A comparison is made with an existing approach of the literature. A\nsimulation study shows the good behavior of our procedure on finite-sample\nsizes and from missing or noisy data. An application to the analysis of\nrevisions of Wikipedia articles is also considered through real data.\n", "versions": [{"version": "v1", "created": "Mon, 5 Sep 2016 08:32:32 GMT"}, {"version": "v2", "created": "Wed, 14 Sep 2016 22:29:12 GMT"}, {"version": "v3", "created": "Fri, 16 Jun 2017 20:50:57 GMT"}, {"version": "v4", "created": "Wed, 31 Oct 2018 11:15:42 GMT"}, {"version": "v5", "created": "Mon, 8 Apr 2019 08:03:10 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Aza\u00efs", "Romain", ""], ["Genadot", "Alexandre", ""], ["Henry", "Beno\u00eet", ""]]}, {"id": "1609.01067", "submitter": "Dragi Anevski", "authors": "Dragi Anevski", "title": "Functional central limit theorems for the Nelson-Aalen and Kaplan-Meier\n  estimators for dependent stationary data", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive process limit distribution results for the Nelson-Aalen estimator\nof a hasard function and for the Kaplan-Meier estimator of a distribution\nfunction, under different dependence assumptions. The data are assumed to be\nright censored observations of a stationary time series. We treat weakly\ndependent as well as long range dependent data, and allow for qualitative\ndifferences in the dependence for the censoring times versus the time of\ninterest\n", "versions": [{"version": "v1", "created": "Mon, 5 Sep 2016 09:01:14 GMT"}], "update_date": "2016-09-06", "authors_parsed": [["Anevski", "Dragi", ""]]}, {"id": "1609.01165", "submitter": "Romain Aza\\\"is", "authors": "Romain Aza\\\"is, Bernard Delyon, Fran\\c{c}ois Portier", "title": "Integral estimation based on Markovian design", "comments": "45 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Suppose that a mobile sensor describes a Markovian trajectory in the ambient\nspace. At each time the sensor measures an attribute of interest, e.g., the\ntemperature. Using only the location history of the sensor and the associated\nmeasurements, the aim is to estimate the average value of the attribute over\nthe space. In contrast to classical probabilistic integration methods, e.g.,\nMonte Carlo, the proposed approach does not require any knowledge on the\ndistribution of the sensor trajectory. Probabilistic bounds on the convergence\nrates of the estimator are established. These rates are better than the\ntraditional \"root n\"-rate, where n is the sample size, attached to other\nprobabilistic integration methods. For finite sample sizes, the good behaviour\nof the procedure is demonstrated through simulations and an application to the\nevaluation of the average temperature of oceans is considered.\n", "versions": [{"version": "v1", "created": "Mon, 5 Sep 2016 13:58:13 GMT"}, {"version": "v2", "created": "Fri, 29 Sep 2017 07:07:58 GMT"}], "update_date": "2017-10-02", "authors_parsed": [["Aza\u00efs", "Romain", ""], ["Delyon", "Bernard", ""], ["Portier", "Fran\u00e7ois", ""]]}, {"id": "1609.01233", "submitter": "James P. Crutchfield", "authors": "Ryan G. James and James P. Crutchfield", "title": "Multivariate Dependence Beyond Shannon Information", "comments": "10 pages, 6 figures, 3 tables;\n  http://csc.ucdavis.edu/~cmg/compmech/pubs/mdbsi.htm", "journal-ref": null, "doi": "10.3390/e19100531", "report-no": null, "categories": "cs.IT cond-mat.stat-mech math.IT math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurately determining dependency structure is critical to discovering a\nsystem's causal organization. We recently showed that the transfer entropy\nfails in a key aspect of this---measuring information flow---due to its\nconflation of dyadic and polyadic relationships. We extend this observation to\ndemonstrate that this is true of all such Shannon information measures when\nused to analyze multivariate dependencies. This has broad implications,\nparticularly when employing information to express the organization and\nmechanisms embedded in complex systems, including the burgeoning efforts to\ncombine complex network theory with information theory. Here, we do not suggest\nthat any aspect of information theory is wrong. Rather, the vast majority of\nits informational measures are simply inadequate for determining the meaningful\ndependency structure within joint probability distributions. Therefore, such\ninformation measures are inadequate for discovering intrinsic causal relations.\nWe close by demonstrating that such distributions exist across an arbitrary set\nof variables.\n", "versions": [{"version": "v1", "created": "Mon, 5 Sep 2016 17:38:07 GMT"}, {"version": "v2", "created": "Thu, 8 Sep 2016 23:07:39 GMT"}], "update_date": "2017-11-22", "authors_parsed": [["James", "Ryan G.", ""], ["Crutchfield", "James P.", ""]]}, {"id": "1609.01577", "submitter": "Jan van Waaij MSc", "authors": "Jan van Waaij and Harry van Zanten", "title": "Full adaptation to smoothness using randomly truncated series priors\n  with Gaussian coefficients and inverse gamma scaling", "comments": null, "journal-ref": null, "doi": "10.1016/j.spl.2016.12.009", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study random series priors for estimating a functional parameter (f\\in\nL^2[0,1]). We show that with a series prior with random truncation, Gaussian\ncoefficients, and inverse gamma multiplicative scaling, it is possible to\nachieve posterior contraction at optimal rates and adaptation to arbitrary\ndegrees of smoothness. We present general results that can be combined with\nexisting rate of contraction results for various nonparametric estimation\nproblems. We give concrete examples for signal estimation in white noise and\ndrift estimation for a one-dimensional SDE.\n", "versions": [{"version": "v1", "created": "Tue, 6 Sep 2016 14:38:14 GMT"}, {"version": "v2", "created": "Mon, 5 Dec 2016 14:36:36 GMT"}], "update_date": "2017-06-15", "authors_parsed": [["van Waaij", "Jan", ""], ["van Zanten", "Harry", ""]]}, {"id": "1609.01668", "submitter": "Giulio D'Agostini", "authors": "Giulio D'Agostini", "title": "The Waves and the Sigmas (To Say Nothing of the 750 GeV Mirage)", "comments": "28 pages, 6 figures, based on on the invited talk \"Claims of\n  discoveries based on sigmas\" at MaxEnt 2016 (Ghent, Belgium, 15 July 2016)\n  and on seminars and courses to PhD students in the first half of 2016. (the R\n  script and the Hugin Bayesian network mentioned in the text, as well as\n  related links, can be found in\n  http://www.roma1.infn.it/~dagos/prob+stat.html#waves-sigmas)", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.data-an gr-qc hep-ph math.HO math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper shows how p-values do not only create, as well known, wrong\nexpectations in the case of flukes, but they might also dramatically diminish\nthe `significance' of most likely genuine signals. As real life examples, the\n2015 first detections of gravitational waves are discussed. The March 2016\nstatement of the American Statistical Association, warning scientists about\ninterpretation and misuse of p-values, is also reminded and commented. (The\npaper is complemented with some remarks on past, recent and future claims of\ndiscoveries based on sigmas from Particles Physics.)\n", "versions": [{"version": "v1", "created": "Tue, 6 Sep 2016 17:41:50 GMT"}], "update_date": "2018-02-12", "authors_parsed": [["D'Agostini", "Giulio", ""]]}, {"id": "1609.01679", "submitter": "Mikhail Moklyachuk", "authors": "Mikhail Moklyachuk, Maria Sidei", "title": "Filtering Problem for Functionals of Stationary Processes with Missing\n  Observations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of the mean-square optimal linear estimation of the functional\n$A\\xi=\\ \\int\\limits_{R^s}a(t)\\xi(-t)dt,$ which depends on the unknown values of\nstochastic stationary process $\\xi(t)$ from observations of the process\n$\\xi(t)+\\eta(t)$ at points $t\\in\\mathbb{R} ^{-} \\backslash S $,\n$S=\\bigcup\\limits_{l=1}^{s}[-M_{l}-N_{l}, \\, \\ldots, \\, -M_{l} ],$\n$R^s=[0,\\infty) \\backslash S^{+},$ $S^{+}=\\bigcup\\limits_{l=1}^{s}[ M_{l}, \\,\n\\ldots, \\, M_{l}+N_{l}]$ is considered. Formulas for calculating the\nmean-square error and the spectral characteristic of the optimal linear\nestimate of the functional are proposed under the condition of spectral\ncertainty, where spectral densities of the processes $\\xi(t)$ and $\\eta(t)$ are\nexactly known. The minimax (robust) method of estimation is applied in the case\nwhere spectral densities are not known exactly, but sets of admissible spectral\ndensities are given. Formulas that determine the least favorable spectral\ndensities and minimax spectral characteristics are proposed for some special\nsets of admissible densities.\n", "versions": [{"version": "v1", "created": "Sun, 4 Sep 2016 10:16:10 GMT"}], "update_date": "2016-09-07", "authors_parsed": [["Moklyachuk", "Mikhail", ""], ["Sidei", "Maria", ""]]}, {"id": "1609.01799", "submitter": "Raimundas Vidunas", "authors": "Raimundas Vidunas and Akimichi Takemura", "title": "Differential relations for the largest root distribution of complex\n  non-central Wishart matrices", "comments": "23 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A holonomic system for the probability density function of the largest\neigenvalue of a non-central complex Wishart distribution with identity\ncovariance matrix is derived. Furthermore a new determinantal formula for the\nprobability density function is derived (for m=2,3) or conjectured.\n", "versions": [{"version": "v1", "created": "Wed, 7 Sep 2016 01:38:55 GMT"}], "update_date": "2016-09-08", "authors_parsed": [["Vidunas", "Raimundas", ""], ["Takemura", "Akimichi", ""]]}, {"id": "1609.01811", "submitter": "Simon Mak", "authors": "Simon Mak, V. Roshan Joseph", "title": "Support points", "comments": "Accepted, Annals of Statistics", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a new way to compact a continuous probability\ndistribution $F$ into a set of representative points called support points.\nThese points are obtained by minimizing the energy distance, a statistical\npotential measure initially proposed by Sz\\'ekely and Rizzo (2004) for testing\ngoodness-of-fit. The energy distance has two appealing features. First, its\ndistance-based structure allows us to exploit the duality between powers of the\nEuclidean distance and its Fourier transform for theoretical analysis. Using\nthis duality, we show that support points converge in distribution to $F$, and\nenjoy an improved error rate to Monte Carlo for integrating a large class of\nfunctions. Second, the minimization of the energy distance can be formulated as\na difference-of-convex program, which we manipulate using two algorithms to\nefficiently generate representative point sets. In simulation studies, support\npoints provide improved integration performance to both Monte Carlo and a\nspecific Quasi-Monte Carlo method. Two important applications of support points\nare then highlighted: (a) as a way to quantify the propagation of uncertainty\nin expensive simulations, and (b) as a method to optimally compact Markov chain\nMonte Carlo (MCMC) samples in Bayesian computation.\n", "versions": [{"version": "v1", "created": "Wed, 7 Sep 2016 02:59:22 GMT"}, {"version": "v2", "created": "Sun, 2 Oct 2016 04:23:09 GMT"}, {"version": "v3", "created": "Sun, 12 Feb 2017 05:37:18 GMT"}, {"version": "v4", "created": "Fri, 16 Jun 2017 22:50:44 GMT"}, {"version": "v5", "created": "Wed, 23 Aug 2017 14:57:50 GMT"}, {"version": "v6", "created": "Fri, 8 Sep 2017 17:38:15 GMT"}, {"version": "v7", "created": "Sun, 9 Sep 2018 17:50:58 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Mak", "Simon", ""], ["Joseph", "V. Roshan", ""]]}, {"id": "1609.02490", "submitter": "Dan Mikulincer", "authors": "Ronen Eldan and Dan Mikulincer", "title": "Information and dimensionality of anisotropic random geometric graphs", "comments": "38 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.SI math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with the problem of detecting non-isotropic high-dimensional\ngeometric structure in random graphs. Namely, we study a model of a random\ngeometric graph in which vertices correspond to points generated randomly and\nindependently from a non-isotropic $d$-dimensional Gaussian distribution, and\ntwo vertices are connected if the distance between them is smaller than some\npre-specified threshold. We derive new notions of dimensionality which depend\nupon the eigenvalues of the covariance of the Gaussian distribution. If\n$\\alpha$ denotes the vector of eigenvalues, and $n$ is the number of vertices,\nthen the quantities $\\left(\\frac{||\\alpha||_2}{||\\alpha||_3}\\right)^6/n^3$ and\n$\\left(\\frac{||\\alpha||_2}{||\\alpha||_4}\\right)^4/n^3$ determine upper and\nlower bounds for the possibility of detection. This generalizes a recent result\nby Bubeck, Ding, R\\'acz and the first named author from [BDER14] which shows\nthat the quantity $d/n^3$ determines the boundary of detection for isotropic\ngeometry. Our methods involve Fourier analysis and the theory of characteristic\nfunctions to investigate the underlying probabilities of the model. The proof\nof the lower bound uses information theoretic tools, based on the method\npresented in [BG15].\n", "versions": [{"version": "v1", "created": "Thu, 8 Sep 2016 16:48:48 GMT"}, {"version": "v2", "created": "Sun, 23 Feb 2020 13:05:51 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Eldan", "Ronen", ""], ["Mikulincer", "Dan", ""]]}, {"id": "1609.02519", "submitter": "James P. Crutchfield", "authors": "James P. Crutchfield and Cina Aghamohammadi", "title": "Not All Fluctuations are Created Equal: Spontaneous Variations in\n  Thermodynamic Function", "comments": "14 pages, 4 figures, 1 table;\n  http://csc.ucdavis.edu/~cmg/compmech/pubs/naface.htm", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.stat-mech cs.IT math.IT math.ST q-bio.BM q-bio.PE stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Almost all processes -- highly correlated, weakly correlated, or correlated\nnot at all---exhibit statistical fluctuations. Often physical laws, such as the\nSecond Law of Thermodynamics, address only typical realizations -- as\nhighlighted by Shannon's asymptotic equipartition property and as entailed by\ntaking the thermodynamic limit of an infinite number of degrees of freedom.\nIndeed, our interpretations of the functioning of macroscopic thermodynamic\ncycles are so focused. Using a recently derived Second Law for information\nprocessing, we show that different subsets of fluctuations lead to distinct\nthermodynamic functioning in Maxwellian Demons. For example, while typical\nrealizations may operate as an engine -- converting thermal fluctuations to\nuseful work -- even \"nearby\" fluctuations (nontypical, but probable\nrealizations) behave differently, as Landauer erasers -- converting available\nstored energy to dissipate stored information. One concludes that ascribing a\nsingle, unique functional modality to a thermodynamic system, especially one on\nthe nanoscale, is at best misleading, likely masking an array of simultaneous,\nparallel thermodynamic transformations. This alters how we conceive of cellular\nprocesses, engineering design, and evolutionary adaptation.\n", "versions": [{"version": "v1", "created": "Thu, 8 Sep 2016 18:04:38 GMT"}], "update_date": "2016-09-09", "authors_parsed": [["Crutchfield", "James P.", ""], ["Aghamohammadi", "Cina", ""]]}, {"id": "1609.02655", "submitter": "Nhat Ho", "authors": "Nhat Ho and XuanLong Nguyen", "title": "Singularity structures and impacts on parameter estimation in finite\n  mixtures of distributions", "comments": "87 pages. This version has improved introduction and expanded\n  discussion of related work. An abridged version is to appear on SIAM Journal\n  on Mathematics of Data Science", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Singularities of a statistical model are the elements of the model's\nparameter space which make the corresponding Fisher information matrix\ndegenerate. These are the points for which estimation techniques such as the\nmaximum likelihood estimator and standard Bayesian procedures do not admit the\nroot-$n$ parametric rate of convergence. We propose a general framework for the\nidentification of singularity structures of the parameter space of finite\nmixtures, and study the impacts of the singularity structures on minimax lower\nbounds and rates of convergence for the maximum likelihood estimator over a\ncompact parameter space. Our study makes explicit the deep links between model\nsingularities, parameter estimation convergence rates and minimax lower bounds,\nand the algebraic geometry of the parameter space for mixtures of continuous\ndistributions. The theory is applied to establish concrete convergence rates of\nparameter estimation for finite mixture of skew-normal distributions. This rich\nand increasingly popular mixture model is shown to exhibit a remarkably complex\nrange of asymptotic behaviors which have not been hitherto reported in the\nliterature.\n", "versions": [{"version": "v1", "created": "Fri, 9 Sep 2016 04:22:03 GMT"}, {"version": "v2", "created": "Sat, 1 Sep 2018 19:06:27 GMT"}, {"version": "v3", "created": "Thu, 18 Jul 2019 21:05:28 GMT"}, {"version": "v4", "created": "Tue, 23 Jul 2019 22:12:15 GMT"}], "update_date": "2019-07-25", "authors_parsed": [["Ho", "Nhat", ""], ["Nguyen", "XuanLong", ""]]}, {"id": "1609.02661", "submitter": "Georgios Fellouris Dr.", "authors": "Georgios Fellouris, Erhan Bayraktar and Lifeng Lai", "title": "Efficient Byzantine Sequential Change Detection", "comments": "36 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT math.IT stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the multisensor sequential change detection problem, a disruption occurs\nin an environment monitored by multiple sensors. This disruption induces a\nchange in the observations of an unknown subset of sensors. In the Byzantine\nversion of this problem, which is the focus of this work, it is further assumed\nthat the postulated change-point model may be misspecified for an unknown\nsubset of sensors. The problem then is to detect the change quickly and\nreliably, for any possible subset of affected sensors, even if the misspecified\nsensors are controlled by an adversary. Given a user-specified upper bound on\nthe number of compromised sensors, we propose and study three families of\nsequential change-detection rules for this problem. These are designed and\nevaluated under a generalization of Lorden's criterion, where conditional\nexpected detection delay and expected time to false alarm are both computed in\nthe worst-case scenario for the compromised sensors. The first-order asymptotic\nperformance of these procedures is characterized as the worst-case false alarm\nrate goes to 0. The insights from these theoretical results are corroborated by\na simulation study.\n", "versions": [{"version": "v1", "created": "Fri, 9 Sep 2016 05:32:57 GMT"}, {"version": "v2", "created": "Thu, 24 Aug 2017 03:23:07 GMT"}], "update_date": "2017-08-25", "authors_parsed": [["Fellouris", "Georgios", ""], ["Bayraktar", "Erhan", ""], ["Lai", "Lifeng", ""]]}, {"id": "1609.02688", "submitter": "Guillaume Chauvet", "authors": "Guillaume Chauvet (ENSAI, IRMAR), Anne Ruiz-Gazen (TSE)", "title": "A comparison of pivotal sampling and unequal probability sampling with\n  replacement", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.AP stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that any implementation of pivotal sampling is more efficient than\nmultinomial sampling. This property entails the weak consistency of the\nHorvitz-Thompson estimator and the existence of a conservative variance\nestimator. A small simulation study supports our findings.\n", "versions": [{"version": "v1", "created": "Fri, 9 Sep 2016 08:23:26 GMT"}, {"version": "v2", "created": "Tue, 13 Sep 2016 14:29:33 GMT"}], "update_date": "2016-09-14", "authors_parsed": [["Chauvet", "Guillaume", "", "ENSAI, IRMAR"], ["Ruiz-Gazen", "Anne", "", "TSE"]]}, {"id": "1609.02855", "submitter": "Fabian Latorre", "authors": "Fabi\\'an Latorre", "title": "Complexity Regularization and Local Metric Entropy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of Structural Risk Minimization, one is presented a sequence\nof classes $\\{\\mathcal{G}_j\\}$ from which, given a random sample $(X_i,Y_i)$\none wants to choose a strongly consistent estimator. For certain types of\nclasses of functions, we present a criterion to choose an estimator, based on\nthe minimization of the sum of empirical error and a complexity penalty\n$r(n,j)$ over each class $\\G_j$.\n  We present also several other results together with important results found\non current literature on the subject, in an attempt to present and unify the\ntheory in the context of regression estimation. In particular we present a\ngeneralization of the consistency of Structural Risk Minimization in the\ncontext of regression estimation which are all new results found on Chapter 5.\n", "versions": [{"version": "v1", "created": "Fri, 9 Sep 2016 16:44:22 GMT"}], "update_date": "2016-09-12", "authors_parsed": [["Latorre", "Fabi\u00e1n", ""]]}, {"id": "1609.02992", "submitter": "Sungwon Lee", "authors": "Sungwon Lee", "title": "High-Dimension, Low Sample Size Asymptotics of Canonical Correlation\n  Analysis", "comments": "Technical report, typos corrected, wrong entry of mentors removed", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An asymptotic behavior of canonical correlation analysis is studied when\ndimension d grows and the sample size n is fxed. In particular, we are\ninterested in the conditions for which CCA works or fails in the HDLSS\nsituation. This technical report investigates those conditions in a rather\nsimplified setting where there exists one pair of directions in two sets of\nrandom variables with non-zero correlation between two sets of scores on them.\nProofs and an extensive simulation study supports the findings.\n", "versions": [{"version": "v1", "created": "Sat, 10 Sep 2016 02:06:58 GMT"}, {"version": "v2", "created": "Tue, 13 Sep 2016 01:57:44 GMT"}], "update_date": "2016-09-14", "authors_parsed": [["Lee", "Sungwon", ""]]}, {"id": "1609.03088", "submitter": "Ir\\`ene Waldspurger", "authors": "Ir\\`ene Waldspurger", "title": "Phase retrieval with random Gaussian sensing vectors by alternating\n  projections", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.OC stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a phase retrieval problem, where we want to reconstruct a\n$n$-dimensional vector from its phaseless scalar products with $m$ sensing\nvectors. We assume the sensing vectors to be independently sampled from complex\nnormal distributions. We propose to solve this problem with the classical\nnon-convex method of alternating projections. We show that, when $m\\geq Cn$ for\n$C$ large enough, alternating projections succeed with high probability,\nprovided that they are carefully initialized. We also show that there is a\nregime in which the stagnation points of the alternating projections method\ndisappear, and the initialization procedure becomes useless. However, in this\nregime, $m$ has to be of the order of $n^2$. Finally, we conjecture from our\nnumerical experiments that, in the regime $m=O(n)$, there are stagnation\npoints, but the size of their attraction basin is small if $m/n$ is large\nenough, so alternating projections can succeed with probability close to $1$\neven with no special initialization.\n", "versions": [{"version": "v1", "created": "Sat, 10 Sep 2016 21:05:48 GMT"}], "update_date": "2016-09-13", "authors_parsed": [["Waldspurger", "Ir\u00e8ne", ""]]}, {"id": "1609.03167", "submitter": "Max Tabord-Meehan", "authors": "Eric Mbakop and Max Tabord-Meehan", "title": "Model Selection for Treatment Choice: Penalized Welfare Maximization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST econ.EM stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies a penalized statistical decision rule for the treatment\nassignment problem. Consider the setting of a utilitarian policy maker who must\nuse sample data to allocate a binary treatment to members of a population,\nbased on their observable characteristics. We model this problem as a\nstatistical decision problem where the policy maker must choose a subset of the\ncovariate space to assign to treatment, out of a class of potential subsets. We\nfocus on settings in which the policy maker may want to select amongst a\ncollection of constrained subset classes: examples include choosing the number\nof covariates over which to perform best-subset selection, and model selection\nwhen approximating a complicated class via a sieve. We adapt and extend results\nfrom statistical learning to develop the Penalized Welfare Maximization (PWM)\nrule. We establish an oracle inequality for the regret of the PWM rule which\nshows that it is able to perform model selection over the collection of\navailable classes. We then use this oracle inequality to derive relevant bounds\non maximum regret for PWM. An important consequence of our results is that we\nare able to formalize model-selection using a \"hold-out\" procedure, where the\npolicy maker would first estimate various policies using half of the data, and\nthen select the policy which performs the best when evaluated on the other half\nof the data.\n", "versions": [{"version": "v1", "created": "Sun, 11 Sep 2016 15:09:28 GMT"}, {"version": "v2", "created": "Mon, 10 Oct 2016 14:43:54 GMT"}, {"version": "v3", "created": "Tue, 31 Jan 2017 17:42:43 GMT"}, {"version": "v4", "created": "Mon, 12 Mar 2018 16:21:13 GMT"}, {"version": "v5", "created": "Sat, 7 Dec 2019 16:38:53 GMT"}, {"version": "v6", "created": "Wed, 9 Dec 2020 15:57:31 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Mbakop", "Eric", ""], ["Tabord-Meehan", "Max", ""]]}, {"id": "1609.03241", "submitter": "Yuzo Maruyama", "authors": "Yuzo Maruyama and William E. Strawderman", "title": "A sharp boundary for SURE-based admissibility for the Normal means\n  problem under unknown scale", "comments": "28 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider quasi-admissibility/inadmissibility of Stein-type shrinkage\nestimators of the mean of a multivariate normal distribution with covariance\nmatrix an unknown multiple of the identity. Quasi-admissibility/inadmissibility\nis defined in terms of non-existence/existence of a solution to a differential\ninequality based on Stein's unbiased risk estimate (SURE). We find a sharp\nboundary between quasi-admissible and quasi-inadmissible estimators related to\nthe optimal James-Stein estimator. We also find a class of priors related to\nthe Strawderman class in the known variance case where the boundary between\nquasi-admissibility and quasi-inadmissibility corresponds to the boundary\nbetween admissibility and inadmissibility in the known variance case.\nAdditionally, we also briefly consider generalization to the case of general\nspherically symmetric distributions with a residual vector.\n", "versions": [{"version": "v1", "created": "Mon, 12 Sep 2016 01:33:22 GMT"}], "update_date": "2016-09-13", "authors_parsed": [["Maruyama", "Yuzo", ""], ["Strawderman", "William E.", ""]]}, {"id": "1609.03344", "submitter": "Ning Xu", "authors": "Ning Xu, Jian Hong, Timothy C.G. Fisher", "title": "Finite-sample and asymptotic analysis of generalization ability with an\n  application to penalized regression", "comments": "The theoretical generalization and extension of arXiv:1606.00142", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST q-fin.EC stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the performance of extremum estimators from the\nperspective of generalization ability (GA): the ability of a model to predict\noutcomes in new samples from the same population. By adapting the classical\nconcentration inequalities, we derive upper bounds on the empirical\nout-of-sample prediction errors as a function of the in-sample errors,\nin-sample data size, heaviness in the tails of the error distribution, and\nmodel complexity. We show that the error bounds may be used for tuning key\nestimation hyper-parameters, such as the number of folds $K$ in\ncross-validation. We also show how $K$ affects the bias-variance trade-off for\ncross-validation. We demonstrate that the $\\mathcal{L}_2$-norm difference\nbetween penalized and the corresponding un-penalized regression estimates is\ndirectly explained by the GA of the estimates and the GA of empirical moment\nconditions. Lastly, we prove that all penalized regression estimates are\n$L_2$-consistent for both the $n \\geqslant p$ and the $n < p$ cases.\nSimulations are used to demonstrate key results.\n  Keywords: generalization ability, upper bound of generalization error,\npenalized regression, cross-validation, bias-variance trade-off,\n$\\mathcal{L}_2$ difference between penalized and unpenalized regression, lasso,\nhigh-dimensional data.\n", "versions": [{"version": "v1", "created": "Mon, 12 Sep 2016 11:09:50 GMT"}, {"version": "v2", "created": "Tue, 13 Sep 2016 09:34:17 GMT"}], "update_date": "2016-09-14", "authors_parsed": [["Xu", "Ning", ""], ["Hong", "Jian", ""], ["Fisher", "Timothy C. G.", ""]]}, {"id": "1609.03470", "submitter": "Yuzhen Zhou", "authors": "Yuzhen Zhou and Yimin Xiao", "title": "Joint Asymptotics for Estimating the Fractal Indices of Bivariate\n  Gaussian Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multivariate (or vector-valued) processes are important for modeling multiple\nvariables. The fractal indices of the components of the underlying multivariate\nprocess play a key role in characterizing the dependence structures and\nstatistical properties of the multivariate process.\n  In this paper, under the infill asymptotics framework, we establish joint\nasymptotic results for the increment-based estimators of bivariate fractal\nindices. Our main results quantitatively describe the effect of the\ncross-dependence structure on the performance of the estimators.\n", "versions": [{"version": "v1", "created": "Mon, 12 Sep 2016 16:36:29 GMT"}, {"version": "v2", "created": "Mon, 24 Jul 2017 13:56:55 GMT"}], "update_date": "2017-07-25", "authors_parsed": [["Zhou", "Yuzhen", ""], ["Xiao", "Yimin", ""]]}, {"id": "1609.03511", "submitter": "Miklos Z. Racz", "authors": "Miklos Z. Racz, S\\'ebastien Bubeck", "title": "Basic models and questions in statistical network analysis", "comments": "38 pages, 10 figures. Lecture notes for a graduate minicourse\n  presented at University of Washington and the XX Brazilian School of\n  Probability in June/July 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT cs.SI math.IT math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extracting information from large graphs has become an important statistical\nproblem since network data is now common in various fields. In this minicourse\nwe will investigate the most natural statistical questions for three canonical\nprobabilistic models of networks: (i) community detection in the stochastic\nblock model, (ii) finding the embedding of a random geometric graph, and (iii)\nfinding the original vertex in a preferential attachment tree. Along the way we\nwill cover many interesting topics in probability theory such as P\\'olya urns,\nlarge deviation theory, concentration of measure in high dimension, entropic\ncentral limit theorems, and more.\n", "versions": [{"version": "v1", "created": "Mon, 12 Sep 2016 18:05:38 GMT"}], "update_date": "2016-09-13", "authors_parsed": [["Racz", "Miklos Z.", ""], ["Bubeck", "S\u00e9bastien", ""]]}, {"id": "1609.03680", "submitter": "Wilmer Pineda R\\'ios", "authors": "Wilmer Pineda-R\\'ios and Ram\\'on Giraldo", "title": "Functional SAR Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study a functional SAR model in which explanatory variables\nare sampling points of a continuous-time process. We propose a procedure for\nthe maximum likelihood estimation for the spatial parameter dependence and the\nparameter function. Both convergence in probability and almost sure convergence\nof this estimator are stated.\n", "versions": [{"version": "v1", "created": "Tue, 13 Sep 2016 05:12:35 GMT"}], "update_date": "2016-09-14", "authors_parsed": [["Pineda-R\u00edos", "Wilmer", ""], ["Giraldo", "Ram\u00f3n", ""]]}, {"id": "1609.03779", "submitter": "Martin Wahl", "authors": "Markus Rei\\ss, Martin Wahl", "title": "Non-asymptotic upper bounds for the reconstruction error of PCA", "comments": "44 pages, 1 figure, to appear in Annals of Statistics", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyse the reconstruction error of principal component analysis (PCA) and\nprove non-asymptotic upper bounds for the corresponding excess risk. These\nbounds unify and improve existing upper bounds from the literature. In\nparticular, they give oracle inequalities under mild eigenvalue conditions. The\nbounds reveal that the excess risk differs significantly from usually\nconsidered subspace distances based on canonical angles. Our approach relies on\nthe analysis of empirical spectral projectors combined with concentration\ninequalities for weighted empirical covariance operators and empirical\neigenvalues.\n", "versions": [{"version": "v1", "created": "Tue, 13 Sep 2016 11:44:16 GMT"}, {"version": "v2", "created": "Mon, 15 Jan 2018 13:40:21 GMT"}, {"version": "v3", "created": "Fri, 29 Mar 2019 17:34:33 GMT"}], "update_date": "2019-04-01", "authors_parsed": [["Rei\u00df", "Markus", ""], ["Wahl", "Martin", ""]]}, {"id": "1609.03810", "submitter": "Hacene Djellout", "authors": "Hac\\`ene Djellout (LMBP), Arnaud Guillin (LMBP, IUF), Hui Jiang\n  (Nanjing University of Aeronautics and Astronautics), Yacouba Samoura (LMBP)", "title": "Moderate deviations for bipower variation of general function and\n  Hayashi-Yoshida estimators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the moderate deviations behaviors for two (co-) volatility\nestima-tors: generalised bipower variation, Hayashi-Yoshida estimator. The\nresults are obtained by using a new result about the moderate deviations\nprinciple for m-dependent random variables based on the Chen-Ledoux type\ncondition. In the last decade there has been a considerable development of the\nasymptotic theory for processes observed at a high frequency. This was mainly\nmotivated by financial applications , where the data, such as stock prices or\ncurrencies, are observed very frequently. As under the no-arbitrage assumptions\nprice processes must follow a semimartingale, there was a need for\nprobabilistic tools for functionals of semimartingales based on high frequency\nobservations. Inspired by potential applications, probabilists started to\ndevelop limit theorems for semimartingales. Statisticians applied the\nasymptotic theory to analyze the path properties of discretely observed\nsemimartingales: for the estimation of certain volatility functionals and\nrealised jumps, or for performing various test procedures. We consider X t = (X\n1,t , X 2,t) t$\\in$[0,T ] a 2-dimensional semimartingale, defined on the\nfiltred probability space ($\\Omega$, F , (F t) [0,T ] , P), of the form\n", "versions": [{"version": "v1", "created": "Tue, 13 Sep 2016 12:57:10 GMT"}, {"version": "v2", "created": "Mon, 19 Sep 2016 11:00:48 GMT"}, {"version": "v3", "created": "Fri, 3 Feb 2017 13:45:01 GMT"}], "update_date": "2017-02-06", "authors_parsed": [["Djellout", "Hac\u00e8ne", "", "LMBP"], ["Guillin", "Arnaud", "", "LMBP, IUF"], ["Jiang", "Hui", "", "Nanjing University of Aeronautics and Astronautics"], ["Samoura", "Yacouba", "", "LMBP"]]}, {"id": "1609.03958", "submitter": "Akshay Soni", "authors": "Akshay Soni, Troy Chevalier, Swayambhoo Jain", "title": "Noisy Inductive Matrix Completion Under Sparse Factor Models", "comments": "5 pages. arXiv admin note: text overlap with arXiv:1411.0282", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inductive Matrix Completion (IMC) is an important class of matrix completion\nproblems that allows direct inclusion of available features to enhance\nestimation capabilities. These models have found applications in personalized\nrecommendation systems, multilabel learning, dictionary learning, etc. This\npaper examines a general class of noisy matrix completion tasks where the\nunderlying matrix is following an IMC model i.e., it is formed by a mixing\nmatrix (a priori unknown) sandwiched between two known feature matrices. The\nmixing matrix here is assumed to be well approximated by the product of two\nsparse matrices---referred here to as \"sparse factor models.\" We leverage the\nmain theorem of Soni:2016:NMC and extend it to provide theoretical error bounds\nfor the sparsity-regularized maximum likelihood estimators for the class of\nproblems discussed in this paper. The main result is general in the sense that\nit can be used to derive error bounds for various noise models. In this paper,\nwe instantiate our main result for the case of Gaussian noise and provide\ncorresponding error bounds in terms of squared loss.\n", "versions": [{"version": "v1", "created": "Tue, 13 Sep 2016 18:08:06 GMT"}], "update_date": "2016-09-14", "authors_parsed": [["Soni", "Akshay", ""], ["Chevalier", "Troy", ""], ["Jain", "Swayambhoo", ""]]}, {"id": "1609.03970", "submitter": "Robert Gaunt", "authors": "Andreas Anastasiou and Robert E. Gaunt", "title": "Multivariate normal approximation of the maximum likelihood estimator\n  via the delta method", "comments": "17 pages. To appear in Brazilian Journal of Probability and\n  Statistics, 2018+", "journal-ref": "Brazilian Journal of Probability and Statistics 34 (2020), pp.\n  136-149", "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use the delta method and Stein's method to derive, under regularity\nconditions, explicit upper bounds for the distributional distance between the\ndistribution of the maximum likelihood estimator (MLE) of a $d$-dimensional\nparameter and its asymptotic multivariate normal distribution. Our bounds apply\nin situations in which the MLE can be written as a function of a sum of i.i.d.\n$t$-dimensional random vectors. We apply our general bound to establish a bound\nfor the multivariate normal approximation of the MLE of the normal distribution\nwith unknown mean and variance.\n", "versions": [{"version": "v1", "created": "Tue, 13 Sep 2016 18:34:45 GMT"}, {"version": "v2", "created": "Thu, 9 Aug 2018 09:50:18 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Anastasiou", "Andreas", ""], ["Gaunt", "Robert E.", ""]]}, {"id": "1609.04057", "submitter": "Dootika Vats", "authors": "Dootika Vats", "title": "Geometric Ergodicity of Gibbs Samplers in Bayesian Penalized Regression\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider three Bayesian penalized regression models and show that the\nrespective deterministic scan Gibbs samplers are geometrically ergodic\nregardless of the dimension of the regression problem. We prove geometric\nergodicity of the Gibbs samplers for the Bayesian fused lasso, the Bayesian\ngroup lasso, and the Bayesian sparse group lasso. Geometric ergodicity along\nwith a moment condition results in the existence of a Markov chain central\nlimit theorem for Monte Carlo averages and ensures reliable output analysis.\nOur results of geometric ergodicity allow us to also provide default starting\nvalues for the Gibbs samplers.\n", "versions": [{"version": "v1", "created": "Tue, 13 Sep 2016 21:22:49 GMT"}, {"version": "v2", "created": "Tue, 4 Jul 2017 16:42:30 GMT"}], "update_date": "2017-07-05", "authors_parsed": [["Vats", "Dootika", ""]]}, {"id": "1609.04117", "submitter": "Joseph Chow", "authors": "Susan Jia Xu, Mehdi Nourinejad, Xuebo Lai, Joseph Y. J. Chow", "title": "Network learning via multi-agent inverse transportation problems", "comments": null, "journal-ref": "Transportation Science 52(6) 1347-1364 (2018)", "doi": "10.1287/trsc.2017.0805", "report-no": null, "categories": "cs.MA cs.CE cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the ubiquity of transportation data, methods to infer the state\nparameters of a network either ignore sensitivity of route decisions, require\nroute enumeration for parameterizing descriptive models of route selection, or\nrequire complex bilevel models of route assignment behavior. These limitations\nprevent modelers from fully exploiting ubiquitous data in monitoring\ntransportation networks. Inverse optimization methods that capture network\nroute choice behavior can address this gap, but they are designed to take\nobservations of the same model to learn the parameters of that model, which is\nstatistically inefficient (e.g. requires estimating population route and link\nflows). New inverse optimization models and supporting algorithms are proposed\nto learn the parameters of heterogeneous travelers' route behavior to infer\nshared network state parameters (e.g. link capacity dual prices). The inferred\nvalues are consistent with observations of each agent's optimization behavior.\nWe prove that the method can obtain unique dual prices for a network shared by\nthese agents in polynomial time. Four experiments are conducted. The first one,\nconducted on a 4-node network, verifies the methodology to obtain heterogeneous\nlink cost parameters even when multinomial or mixed logit models would not be\nmeaningfully estimated. The second is a parameter recovery test on the\nNguyen-Dupuis network that shows that unique latent link capacity dual prices\ncan be inferred using the proposed method. The third test on the same network\ndemonstrates how a monitoring system in an online learning environment can be\ndesigned using this method. The last test demonstrates this learning on real\ndata obtained from a freeway network in Queens, New York, using only real-time\nGoogle Maps queries.\n", "versions": [{"version": "v1", "created": "Wed, 14 Sep 2016 03:07:18 GMT"}, {"version": "v2", "created": "Sun, 18 Sep 2016 18:53:26 GMT"}, {"version": "v3", "created": "Mon, 26 Jun 2017 18:20:35 GMT"}, {"version": "v4", "created": "Thu, 7 Sep 2017 22:52:22 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Xu", "Susan Jia", ""], ["Nourinejad", "Mehdi", ""], ["Lai", "Xuebo", ""], ["Chow", "Joseph Y. J.", ""]]}, {"id": "1609.04228", "submitter": "Sebastien Gadat", "authors": "S\\'ebastien Gadat and Fabien Panloup and Sofiane Saadane", "title": "Stochastic Heavy Ball", "comments": "39 pages, 3 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with a natural stochastic optimization procedure derived\nfrom the so-called Heavy-ball method differential equation, which was\nintroduced by Polyak in the 1960s with his seminal contribution [Pol64]. The\nHeavy-ball method is a second-order dynamics that was investigated to minimize\nconvex functions f . The family of second-order methods recently received a\nlarge amount of attention, until the famous contribution of Nesterov [Nes83],\nleading to the explosion of large-scale optimization problems. This work\nprovides an in-depth description of the stochastic heavy-ball method, which is\nan adaptation of the deterministic one when only unbiased evalutions of the\ngradient are available and used throughout the iterations of the algorithm. We\nfirst describe some almost sure convergence results in the case of general\nnon-convex coercive functions f . We then examine the situation of convex and\nstrongly convex potentials and derive some non-asymptotic results about the\nstochastic heavy-ball method. We end our study with limit theorems on several\nrescaled algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 14 Sep 2016 11:54:04 GMT"}, {"version": "v2", "created": "Fri, 21 Oct 2016 12:19:06 GMT"}], "update_date": "2016-10-24", "authors_parsed": [["Gadat", "S\u00e9bastien", ""], ["Panloup", "Fabien", ""], ["Saadane", "Sofiane", ""]]}, {"id": "1609.04231", "submitter": "Jia Guo", "authors": "Jia Guo and Jin-Ting Zhang", "title": "A Further Study of an $L^2$-norm Based Test for the Equality of Several\n  Covariance Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.AP stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For the multi-sample equal covariance function (ECF) testing problem, Zhang\n(2013) proposed an $L^{2}$-norm based test. However, its asymptotic power and\nfinite sample performance have not been studied. In this paper, its asymptotic\npower is investigated under some mild conditions. It is shown that the\n$L^2$-norm based test is root-$n$ consistent. In addition, intensive simulation\nstudies demonstrate that in terms of size-controlling and power, the\n$L^{2}$-norm based test outperforms the dimension-reduction based test proposed\nby Fremdt et al. (2013) when the functional data are less correlated or when\nthe effective signal information is located in high frequencies. Two real data\napplications are also presented to demonstrate the good performance of the\n$L^2$-norm based test.\n", "versions": [{"version": "v1", "created": "Wed, 14 Sep 2016 12:13:07 GMT"}], "update_date": "2016-09-15", "authors_parsed": [["Guo", "Jia", ""], ["Zhang", "Jin-Ting", ""]]}, {"id": "1609.04234", "submitter": "Jia Guo", "authors": "Jia Guo and Jin-Ting Zhang", "title": "Two New Tests for Equality of Several Covariance Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose two new tests for testing the equality of the\ncovariance functions of several functional populations, namely a quasi GPF test\nand a quasi $F_{\\max}$ test. The asymptotic random expressions of the two tests\nunder the null hypothesis are derived. We show that the asymptotic null\ndistribution of the quasi GPF test is a chi-squared-type mixture whose\ndistribution can be well approximated by a simple scaled chi-squared\ndistribution. We also adopt a random permutation method for approximating the\nnull distributions of the quasi GPF and $F_{\\max}$ tests. The random\npermutation method is applicable for both large and finite sample sizes. The\nasymptotic distributions of the two tests under a local alternative are\ninvestigated and they are shown to be root-n consistent. Simulation studies are\npresented to demonstrate the finite-sample performance of the new tests against\nthree existing tests. They show that our new tests are more powerful than the\nthree existing tests when the covariance functions at different time points\nhave different scales. An illustrative example is also presented.\n", "versions": [{"version": "v1", "created": "Wed, 14 Sep 2016 12:16:32 GMT"}], "update_date": "2016-09-15", "authors_parsed": [["Guo", "Jia", ""], ["Zhang", "Jin-Ting", ""]]}, {"id": "1609.04237", "submitter": "Degui Li", "authors": "Degui Li, Dag Tj{\\o}stheim, Jiti Gao", "title": "Estimation in nonlinear regression with Harris recurrent Markov chains", "comments": "Published at http://dx.doi.org/10.1214/15-AOS1379 in the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2016, Vol. 44, No. 5, 1957-1987", "doi": "10.1214/15-AOS1379", "report-no": "IMS-AOS-AOS1379", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study parametric nonlinear regression under the Harris\nrecurrent Markov chain framework. We first consider the nonlinear least squares\nestimators of the parameters in the homoskedastic case, and establish\nasymptotic theory for the proposed estimators. Our results show that the\nconvergence rates for the estimators rely not only on the properties of the\nnonlinear regression function, but also on the number of regenerations for the\nHarris recurrent Markov chain. Furthermore, we discuss the estimation of the\nparameter vector in a conditional volatility function, and apply our results to\nthe nonlinear regression with $I(1)$ processes and derive an asymptotic\ndistribution theory which is comparable to that obtained by Park and Phillips\n[Econometrica 69 (2001) 117-161]. Some numerical studies including simulation\nand empirical application are provided to examine the finite sample performance\nof the proposed approaches and results.\n", "versions": [{"version": "v1", "created": "Wed, 14 Sep 2016 12:35:04 GMT"}], "update_date": "2016-09-15", "authors_parsed": [["Li", "Degui", ""], ["Tj\u00f8stheim", "Dag", ""], ["Gao", "Jiti", ""]]}, {"id": "1609.04558", "submitter": "Ting Yan", "authors": "Ting Yan, Binyan Jiang, Stephen E. Fienberg, Chenlei Leng", "title": "Statistical Inference in a Directed Network Model with Covariates", "comments": "29 pages. minor revision", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Networks are often characterized by node heterogeneity for which nodes\nexhibit different degrees of interaction and link homophily for which nodes\nsharing common features tend to associate with each other. In this paper, we\npropose a new directed network model to capture the former via node-specific\nparametrization and the latter by incorporating covariates. In particular, this\nmodel quantifies the extent of heterogeneity in terms of outgoingness and\nincomingness of each node by different parameters, thus allowing the number of\nheterogeneity parameters to be twice the number of nodes. We study the maximum\nlikelihood estimation of the model and establish the uniform consistency and\nasymptotic normality of the resulting estimators. Numerical studies demonstrate\nour theoretical findings and a data analysis confirms the usefulness of our\nmodel.\n", "versions": [{"version": "v1", "created": "Thu, 15 Sep 2016 09:54:37 GMT"}, {"version": "v2", "created": "Sat, 17 Sep 2016 07:50:57 GMT"}, {"version": "v3", "created": "Sat, 21 Jan 2017 08:02:53 GMT"}, {"version": "v4", "created": "Thu, 22 Feb 2018 08:59:14 GMT"}, {"version": "v5", "created": "Sun, 11 Mar 2018 01:55:46 GMT"}], "update_date": "2018-03-13", "authors_parsed": [["Yan", "Ting", ""], ["Jiang", "Binyan", ""], ["Fienberg", "Stephen E.", ""], ["Leng", "Chenlei", ""]]}, {"id": "1609.04961", "submitter": "Claudia Kluppelberg", "authors": "Sven Buhl and Claudia Kl\\\"uppelberg", "title": "Limit theory for the empirical extremogram of random fields", "comments": "27 pages, 0 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regularly varying stochastic processes are able to model extremal dependence\nbetween process values at locations in random fields. We investigate the\nempirical extremogram as an estimator of dependence in the extremes. We provide\nconditions to ensure asymptotic normality of the empirical extremogram centred\nby a pre-asymptotic version. For max-stable processes with Fr{\\'e}chet margins\nwe provide conditions such that the empirical extremogram centred by its true\nversion is asymptotically normal. The results of this paper apply to a variety\nof spatial and space-time processes, and to time series models. We apply our\nresults to max-moving average processes and Brown-Resnick processes.\n", "versions": [{"version": "v1", "created": "Fri, 16 Sep 2016 09:21:42 GMT"}, {"version": "v2", "created": "Sun, 9 Apr 2017 05:52:50 GMT"}], "update_date": "2017-04-11", "authors_parsed": [["Buhl", "Sven", ""], ["Kl\u00fcppelberg", "Claudia", ""]]}, {"id": "1609.04967", "submitter": "Sven Buhl", "authors": "Sven Buhl, Richard A. Davis, Claudia Kl\\\"uppelberg and Christina\n  Steinkohl", "title": "Semiparametric estimation for isotropic max-stable space-time processes", "comments": "43 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regularly varying space-time processes have proved useful to study extremal\ndependence in space-time data. We propose a semiparametric estimation procedure\nbased on a closed form expression of the extremogram to estimate parametric\nmodels of extremal dependence functions. We establish the asymptotic properties\nof the resulting parameter estimates and propose subsampling procedures to\nobtain asymptotically correct confidence intervals. A simulation study shows\nthat the proposed procedure works well for moderate sample sizes and is robust\nto small departures from the underlying model. Finally, we apply this\nestimation procedure to fitting a max-stable process to radar rainfall\nmeasurements in a region in Florida. Complementary results and some proofs of\nkey results are presented together with the simulation study in the supplement.\n", "versions": [{"version": "v1", "created": "Fri, 16 Sep 2016 09:33:32 GMT"}, {"version": "v2", "created": "Sun, 9 Apr 2017 06:25:57 GMT"}, {"version": "v3", "created": "Sun, 5 Nov 2017 09:20:30 GMT"}, {"version": "v4", "created": "Sun, 15 Jul 2018 19:07:28 GMT"}], "update_date": "2018-07-17", "authors_parsed": [["Buhl", "Sven", ""], ["Davis", "Richard A.", ""], ["Kl\u00fcppelberg", "Claudia", ""], ["Steinkohl", "Christina", ""]]}, {"id": "1609.05067", "submitter": "Botond Szabo", "authors": "Judith Rousseau and Botond Szabo", "title": "Asymptotic frequentist coverage properties of Bayesian credible sets for\n  sieve priors", "comments": "74 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the frequentist coverage properties of Bayesian credible sets\nin a general, adaptive, nonparametric framework. It is well known that the\nconstruction of adaptive and honest confidence sets is not possible in general.\nTo overcome this problem we introduce an extra assumption on the functional\nparameters, the so called \"general polished tail\" condition. We then show that\nunder standard assumptions both the hierarchical and empirical Bayes methods\nresults in honest confidence sets for sieve type of priors in general settings\nand we characterize their size. We apply the derived abstract results to\nvarious examples, including the nonparametric regression model, density\nestimation using exponential families of priors, density estimation using\nhistogram priors and nonparametric classification model, for which we show that\ntheir size is near minimax adaptive with respect to the considered specific\nsemi-metrics.\n", "versions": [{"version": "v1", "created": "Fri, 16 Sep 2016 14:12:52 GMT"}, {"version": "v2", "created": "Mon, 19 Sep 2016 06:26:11 GMT"}, {"version": "v3", "created": "Fri, 19 Jan 2018 12:12:15 GMT"}, {"version": "v4", "created": "Mon, 4 Feb 2019 08:41:12 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Rousseau", "Judith", ""], ["Szabo", "Botond", ""]]}, {"id": "1609.05479", "submitter": "Antoine Godichon-Baggioni", "authors": "Antoine Godichon-Baggioni", "title": "Lp and almost sure rates of convergence of averaged stochastic gradient\n  algorithms: locally strongly convex objective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An usual problem in statistics consists in estimating the minimizer of a\nconvex function. When we have to deal with large samples taking values in high\ndimensional spaces, stochastic gradient algorithms and their averaged versions\nare efficient candidates. Indeed, (1) they do not need too much computational\nefforts, (2) they do not need to store all the data, which is crucial when we\ndeal with big data, (3) they allow to simply update the estimates, which is\nimportant when data arrive sequentially. The aim of this work is to give\nasymptotic and non asymptotic rates of convergence of stochastic gradient\nestimates as well as of their averaged versions when the function we would like\nto minimize is only locally strongly convex.\n", "versions": [{"version": "v1", "created": "Sun, 18 Sep 2016 12:34:16 GMT"}, {"version": "v2", "created": "Tue, 4 Jul 2017 09:12:27 GMT"}], "update_date": "2017-07-05", "authors_parsed": [["Godichon-Baggioni", "Antoine", ""]]}, {"id": "1609.05551", "submitter": "Johannes Lederer", "authors": "Rui Zhuang, Noah Simon, and Johannes Lederer", "title": "Graphical Models for Discrete and Continuous Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.OT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a general framework for undirected graphical models. It\ngeneralizes Gaussian graphical models to a wide range of continuous, discrete,\nand combinations of different types of data. The models in the framework,\ncalled exponential trace models, are amenable to estimation based on maximum\nlikelihood. We introduce a sampling-based approximation algorithm for computing\nthe maximum likelihood estimator, and we apply this pipeline to learn\nsimultaneous neural activities from spike data.\n", "versions": [{"version": "v1", "created": "Sun, 18 Sep 2016 21:21:39 GMT"}, {"version": "v2", "created": "Sun, 27 Aug 2017 18:48:37 GMT"}, {"version": "v3", "created": "Sat, 15 Jun 2019 12:24:57 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Zhuang", "Rui", ""], ["Simon", "Noah", ""], ["Lederer", "Johannes", ""]]}, {"id": "1609.05573", "submitter": "Alexander Wein", "authors": "Amelia Perry and Alexander S. Wein and Afonso S. Bandeira and Ankur\n  Moitra", "title": "Optimality and Sub-optimality of PCA for Spiked Random Matrices and\n  Synchronization", "comments": "58 pages, 5 figures. This version adds improved results for the\n  Wishart model", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.DS cs.IT math.IT math.PR stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A central problem of random matrix theory is to understand the eigenvalues of\nspiked random matrix models, in which a prominent eigenvector is planted into a\nrandom matrix. These distributions form natural statistical models for\nprincipal component analysis (PCA) problems throughout the sciences. Baik, Ben\nArous and P\\'ech\\'e showed that the spiked Wishart ensemble exhibits a sharp\nphase transition asymptotically: when the signal strength is above a critical\nthreshold, it is possible to detect the presence of a spike based on the top\neigenvalue, and below the threshold the top eigenvalue provides no information.\nSuch results form the basis of our understanding of when PCA can detect a\nlow-rank signal in the presence of noise.\n  However, not all the information about the spike is necessarily contained in\nthe spectrum. We study the fundamental limitations of statistical methods,\nincluding non-spectral ones. Our results include:\n  I) For the Gaussian Wigner ensemble, we show that PCA achieves the optimal\ndetection threshold for a variety of benign priors for the spike. We extend\nprevious work on the spherically symmetric and i.i.d. Rademacher priors through\nan elementary, unified analysis.\n  II) For any non-Gaussian Wigner ensemble, we show that PCA is always\nsuboptimal for detection. However, a variant of PCA achieves the optimal\nthreshold (for benign priors) by pre-transforming the matrix entries according\nto a carefully designed function. This approach has been stated before, and we\ngive a rigorous and general analysis.\n  III) For both the Gaussian Wishart ensemble and various synchronization\nproblems over groups, we show that inefficient procedures can work below the\nthreshold where PCA succeeds, whereas no known efficient algorithm achieves\nthis. This conjectural gap between what is statistically possible and what can\nbe done efficiently remains open.\n", "versions": [{"version": "v1", "created": "Mon, 19 Sep 2016 00:25:43 GMT"}, {"version": "v2", "created": "Fri, 23 Dec 2016 08:11:18 GMT"}], "update_date": "2016-12-26", "authors_parsed": [["Perry", "Amelia", ""], ["Wein", "Alexander S.", ""], ["Bandeira", "Afonso S.", ""], ["Moitra", "Ankur", ""]]}, {"id": "1609.05609", "submitter": "Jonathan Taylor", "authors": "Xiaoying Tian Harris, Snigdha Panigrahi, Jelena Markovic, Nan Bi,\n  Jonathan Taylor", "title": "Selective sampling after solving a convex problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of selective inference after solving a (randomized)\nconvex statistical learning program in the form of a penalized or constrained\nloss function. Our first main result is a change-of-measure formula that\ndescribes many conditional sampling problems of interest in selective\ninference. Our approach is model-agnostic in the sense that users may provide\ntheir own statistical model for inference, we simply provide the modification\nof each distribution in the model after the selection.\n  Our second main result describes the geometric structure in the Jacobian\nappearing in the change of measure, drawing connections to curvature measures\nappearing in Weyl-Steiner volume-of-tubes formulae. This Jacobian is necessary\nfor problems in which the convex penalty is not polyhedral, with the\nprototypical example being group LASSO or the nuclear norm. We derive explicit\nformulae for the Jacobian of the group LASSO.\n  To illustrate the generality of our method, we consider many examples\nthroughout, varying both the penalty or constraint in the statistical learning\nproblem as well as the loss function, also considering selective inference\nafter solving multiple statistical learning programs. Penalties considered\ninclude LASSO, forward stepwise, stagewise algorithms, marginal screening and\ngeneralized LASSO. Loss functions considered include squared-error, logistic,\nand log-det for covariance matrix estimation.\n  Having described the appropriate distribution we wish to sample from through\nour first two results, we outline a framework for sampling using a projected\nLangevin sampler in the (commonly occuring) case that the distribution is\nlog-concave.\n", "versions": [{"version": "v1", "created": "Mon, 19 Sep 2016 06:48:44 GMT"}], "update_date": "2016-09-20", "authors_parsed": [["Harris", "Xiaoying Tian", ""], ["Panigrahi", "Snigdha", ""], ["Markovic", "Jelena", ""], ["Bi", "Nan", ""], ["Taylor", "Jonathan", ""]]}, {"id": "1609.05714", "submitter": "Andreas Anastasiou Dr", "authors": "Andreas Anastasiou", "title": "Bounds for the normal approximation of the maximum likelihood estimator\n  from m-dependent random variables", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The asymptotic normality of the Maximum Likelihood Estimator (MLE) is a long\nestablished result. Explicit bounds for the distributional distance between the\ndistribution of the MLE and the normal distribution have recently been obtained\nfor the case of independent random variables. In this paper, a local dependence\nstructure is introduced between the random variables and we give upper bounds\nwhich are specified for the Wasserstein metric.\n", "versions": [{"version": "v1", "created": "Mon, 19 Sep 2016 13:26:17 GMT"}], "update_date": "2016-09-20", "authors_parsed": [["Anastasiou", "Andreas", ""]]}, {"id": "1609.05803", "submitter": "Henryk Z\\\"ahle", "authors": "Eric Beutner and Henryk Z\\\"ahle", "title": "Functional delta-method for the bootstrap of uniformly quasi-Hadamard\n  differentiable functionals", "comments": "arXiv admin note: text overlap with arXiv:1510.06207", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The functional delta-method provides a convenient tool for deriving bootstrap\nconsistency of a sequence of plug-in estimators w.r.t. a given functional from\nbootstrap consistency of the underlying sequence of estimators. It has recently\nbeen shown in Beutner and Z\\\"ahle (2016) that the range of applications of the\nfunctional delta-method for establishing bootstrap consistency in probability\nof the sequence of plug-in estimators can be considerably enlarged by replacing\nthe usual condition of Hadamard differentiability of the given functional by\nthe weaker condition of quasi-Hadamard differentiability. Here we introduce the\nnotion of uniform quasi-Hadamard differentiability and show that this notion\nextends the set of functionals for which almost sure bootstrap consistency of\nthe corresponding sequence of plug-in estimators can be obtained by the\nfunctional delta-method. We illustrate the benefit of our results by means of\nthe Average Value at Risk functional as well as the composition of the Average\nValue at Risk functional and the compound convolution functional. For the\nlatter we use a chain rule to be proved here. In our examples we consider the\nweighted exchangeable bootstrap for independent observations and the blockwise\nbootstrap for $\\beta$-mixing observations.\n", "versions": [{"version": "v1", "created": "Mon, 19 Sep 2016 15:55:58 GMT"}, {"version": "v2", "created": "Tue, 20 Sep 2016 12:46:21 GMT"}], "update_date": "2016-09-21", "authors_parsed": [["Beutner", "Eric", ""], ["Z\u00e4hle", "Henryk", ""]]}, {"id": "1609.05865", "submitter": "Matyas Barczy", "authors": "Matyas Barczy, Mohamed Ben Alaya, Ahmed Kebaier, Gyula Pap", "title": "Asymptotic properties of maximum likelihood estimator for the growth\n  rate for a jump-type CIR process based on continuous time observations", "comments": "36 pages. In Appendices we recall some notions and statements from\n  arXiv:1509.08869", "journal-ref": "Stochastic Processes and their Applications 128 (4), (2018),\n  1135-1164", "doi": null, "report-no": null, "categories": "math.ST q-fin.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a jump-type Cox--Ingersoll--Ross (CIR) process driven by a\nstandard Wiener process and a subordinator, and we study asymptotic properties\nof the maximum likelihood estimator (MLE) for its growth rate. We distinguish\nthree cases: subcritical, critical and supercritical. In the subcritical case\nwe prove weak consistency and asymptotic normality, and, under an additional\nmoment assumption, strong consistency as well. In the supercritical case, we\nprove strong consistency and mixed normal (but non-normal) asymptotic behavior,\nwhile in the critical case, weak consistency and non-standard asymptotic\nbehavior are described. We specialize our results to so-called basic affine\njump-diffusions as well. Concerning the asymptotic behavior of the MLE in the\nsupercritical case, we derive a stochastic representation of the limiting mixed\nnormal distribution, where the almost sure limit of an appropriately scaled\njump-type supercritical CIR process comes into play. This is a new phenomenon,\ncompared to the critical case, where a diffusion-type critical CIR process\nplays a role.\n", "versions": [{"version": "v1", "created": "Mon, 19 Sep 2016 18:54:18 GMT"}, {"version": "v2", "created": "Sat, 1 Apr 2017 11:06:13 GMT"}, {"version": "v3", "created": "Thu, 13 Jul 2017 08:45:06 GMT"}, {"version": "v4", "created": "Thu, 10 Aug 2017 18:30:10 GMT"}], "update_date": "2018-06-08", "authors_parsed": [["Barczy", "Matyas", ""], ["Alaya", "Mohamed Ben", ""], ["Kebaier", "Ahmed", ""], ["Pap", "Gyula", ""]]}, {"id": "1609.06029", "submitter": "Efstathios Paparoditis", "authors": "Efstathios Paparoditis", "title": "Sieve Bootstrap for Functional Time Series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A bootstrap procedure for functional time series is proposed which exploits a\ngeneral vector autoregressive representation of the time series of Fourier\ncoefficients appearing in the Karhunen-Lo\\`eve expansion of the functional\nprocess. A double sieve-type bootstrap method is developed which avoids the\nestimation of process operators and generates functional pseudo-time series\nthat appropriately mimic the dependence structure of the functional time series\nat hand. The method uses a finite set of functional principal components to\ncapture the essential driving parts of the infinite dimensional process and a\nfinite order vector autoregressive process to imitate the temporal dependence\nstructure of the corresponding vector time series of Fourier coefficients. By\nallowing the number of functional principal components as well as the\nautoregressive order used to increase to infinity (at some appropriate rate) as\nthe sample size increases, a basic bootstrap central limit theorem is\nestablished which shows validity of the bootstrap procedure proposed for\nfunctional finite Fourier transforms. Some numerical examples illustrate the\ngood finite sample performance of the new bootstrap method proposed.\n", "versions": [{"version": "v1", "created": "Tue, 20 Sep 2016 06:18:05 GMT"}, {"version": "v2", "created": "Tue, 13 Jun 2017 08:11:03 GMT"}, {"version": "v3", "created": "Wed, 27 Sep 2017 06:32:52 GMT"}, {"version": "v4", "created": "Fri, 1 Dec 2017 07:51:24 GMT"}], "update_date": "2017-12-04", "authors_parsed": [["Paparoditis", "Efstathios", ""]]}, {"id": "1609.06031", "submitter": "Subhajit Dutta Dr.", "authors": "Minerva Mukhopadhyay and Subhajit Dutta", "title": "Bayesian Variable Selection for Ultrahigh-dimensional Sparse Linear\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a Bayesian variable selection procedure for ultrahigh-dimensional\nlinear regression models. The number of regressors involved in regression,\n$p_n$, is allowed to grow exponentially with $n$. Assuming the true model to be\nsparse, in the sense that only a small number of regressors contribute to this\nmodel, we propose a set of priors suitable for this regime. The model selection\nprocedure based on the proposed set of priors is shown to be variable selection\nconsistent when all the $2^{p_n}$ models are considered. In the\nultrahigh-dimensional setting, selection of the true model among all the\n$2^{p_n}$ possible ones involves prohibitive computation. To cope with this, we\npresent a two-step model selection algorithm based on screening and Gibbs\nsampling. The first step of screening discards a large set of unimportant\ncovariates, and retains a smaller set containing all the active covariates with\nprobability tending to one. In the next step, we search for the best model\namong the covariates obtained in the screening step. This procedure is\ncomputationally quite fast, simple and intuitive. We demonstrate competitive\nperformance of the proposed algorithm for a variety of simulated and real data\nsets when compared with several frequentist, as well as Bayesian methods.\n", "versions": [{"version": "v1", "created": "Tue, 20 Sep 2016 06:34:27 GMT"}], "update_date": "2016-09-21", "authors_parsed": [["Mukhopadhyay", "Minerva", ""], ["Dutta", "Subhajit", ""]]}, {"id": "1609.06145", "submitter": "Mo Hossny", "authors": "Marwa Hassan, Mo Hossny, Douglas Creighton and Saeid Nahavandi", "title": "Quantifying Heteroskedasticity via Bhattacharyya Distance", "comments": "9 pages and 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Heteroskedasticity is a statistical anomaly that describes differing\nvariances of error terms in a time series dataset. The presence of\nheteroskedasticity in data imposes serious challenges for forecasting models\nand many statistical tests are not valid in the presence of heteroskedasticity.\nHeteroskedasticity of the data affects the relation between the predictor\nvariable and the outcome, which leads to false positive and false negative\ndecisions in the hypothesis testing. Available approaches to study\nheteroskedasticity thus far adopt the strategy of accommodating\nheteroskedasticity in the time series and consider it an inevitable source of\nnoise. In these existing approaches, two forecasting models are prepared for\nnormal and heteroskedastic scenarios and a statistical test is to determine\nwhether or not the data is heteroskedastic.\n  This work-in-progress research introduces a quantifying measurement for\nheteroskedasticity. The idea behind the proposed metric is the fact that a\nheteroskedastic time series features a uniformly distributed local variances.\nThe proposed measurement is obtained by calculating the local variances using\nlinear time invariant filters. A probability density function of the calculated\nlocal variances is then derived and compared to a uniform distribution of\ntheoretical ultimate heteroskedasticity using statistical divergence\nmeasurements. The results demonstrated on synthetic datasets shows a strong\ncorrelation between the proposed metric and number of variances locally\nestimated in a heteroskedastic time series.\n", "versions": [{"version": "v1", "created": "Tue, 6 Sep 2016 12:05:15 GMT"}], "update_date": "2016-09-21", "authors_parsed": [["Hassan", "Marwa", ""], ["Hossny", "Mo", ""], ["Creighton", "Douglas", ""], ["Nahavandi", "Saeid", ""]]}, {"id": "1609.06347", "submitter": "Christopher Rozell", "authors": "Armin Eftekhari, Han Lun Yap, Michael B. Wakin, and Christopher J.\n  Rozell", "title": "Stabilizing Embedology: Geometry-Preserving Delay-Coordinate Maps", "comments": null, "journal-ref": "Phys. Rev. E 97, 022222 (2018)", "doi": "10.1103/PhysRevE.97.022222", "report-no": null, "categories": "nlin.CD math.DS math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Delay-coordinate mapping is an effective and widely used technique for\nreconstructing and analyzing the dynamics of a nonlinear system based on\ntime-series outputs. The efficacy of delay-coordinate mapping has long been\nsupported by Takens' embedding theorem, which guarantees that delay-coordinate\nmaps use the time-series output to provide a reconstruction of the hidden state\nspace that is a one-to-one embedding of the system's attractor. While this\ntopological guarantee ensures that distinct points in the reconstruction\ncorrespond to distinct points in the original state space, it does not\ncharacterize the quality of this embedding or illuminate how the specific\nparameters affect the reconstruction. In this paper, we extend Takens' result\nby establishing conditions under which delay-coordinate mapping is guaranteed\nto provide a stable embedding of a system's attractor. Beyond only preserving\nthe attractor topology, a stable embedding preserves the attractor geometry by\nensuring that distances between points in the state space are approximately\npreserved. In particular, we find that delay-coordinate mapping stably embeds\nan attractor of a dynamical system if the stable rank of the system is large\nenough to be proportional to the dimension of the attractor. The stable rank\nreflects the relation between the sampling interval and the number of delays in\ndelay-coordinate mapping. Our theoretical findings give guidance to choosing\nsystem parameters, echoing the trade-off between irrelevancy and redundancy\nthat has been heuristically investigated in the literature. Our initial result\nis stated for attractors that are smooth submanifolds of Euclidean space, with\nextensions provided for the case of strange attractors.\n", "versions": [{"version": "v1", "created": "Tue, 20 Sep 2016 20:36:17 GMT"}, {"version": "v2", "created": "Thu, 10 Aug 2017 16:37:59 GMT"}], "update_date": "2018-03-07", "authors_parsed": [["Eftekhari", "Armin", ""], ["Yap", "Han Lun", ""], ["Wakin", "Michael B.", ""], ["Rozell", "Christopher J.", ""]]}, {"id": "1609.06357", "submitter": "Axel Flinth", "authors": "Axel Flinth", "title": "Sparse Blind Deconvolution and Demixing Through\n  $\\ell_{1,2}$-Minimization", "comments": "Changes in v2: A few errors were fixed, resulting in slightly\n  different results. Also, some efforts were made to increase readability.\n  Changes in v3: Version accepted for publication", "journal-ref": null, "doi": "10.1007/s10444-017-9533-0", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper concerns solving the sparse deconvolution and demixing problem\nusing $\\ell_{1,2}$-minimization. We show that under a certain structured random\nmodel, robust and stable recovery is possible. The results extend results of\nLing and Strohmer [Self Calibration and Biconvex Compressive Sensing, Inverse\nProblems, 2015], and in particular theoretically explain certain experimental\nfindings from that paper. Our results do not only apply to the deconvolution\nand demixing problem, but to recovery of column-sparse matrices in general.\n", "versions": [{"version": "v1", "created": "Thu, 8 Sep 2016 08:21:12 GMT"}, {"version": "v2", "created": "Tue, 13 Dec 2016 13:49:39 GMT"}, {"version": "v3", "created": "Thu, 13 Apr 2017 06:09:37 GMT"}], "update_date": "2017-05-11", "authors_parsed": [["Flinth", "Axel", ""]]}, {"id": "1609.06418", "submitter": "Michael Evans", "authors": "Michael Evans and Jabed Tomal", "title": "Multiple testing via relative belief ratios", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Some large scale inference problems are considered based on using the\nrelative belief ratio as a measure of statistical evidence. This approach is\napplied to the multiple testing problem. A particular application of this is\nconcerned with assessing sparsity. The approach taken to sparsity has several\nadvantages as it is based on a measure of evidence and does not require that\nthe prior be restricted in any way.\n", "versions": [{"version": "v1", "created": "Wed, 21 Sep 2016 04:22:51 GMT"}], "update_date": "2016-09-22", "authors_parsed": [["Evans", "Michael", ""], ["Tomal", "Jabed", ""]]}, {"id": "1609.06421", "submitter": "Juan Carlos Escanciano", "authors": "Juan Carlos Escanciano", "title": "Semiparametric Identification and Fisher Information", "comments": null, "journal-ref": null, "doi": "10.1017/S0266466621000116", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides a systematic approach to semiparametric identification\nthat is based on statistical information as a measure of its \"quality\".\nIdentification can be regular or irregular, depending on whether the Fisher\ninformation for the parameter is positive or zero, respectively. I first\ncharacterize these cases in models with densities linear in a nonparametric\nparameter. I then introduce a novel \"generalized Fisher information\". If\npositive, it implies (possibly irregular) identification when other conditions\nhold. If zero, it implies impossibility results on rates of estimation. Three\nexamples illustrate the applicability of the general results. First, I find\nnecessary conditions for semiparametric regular identification in a structural\nmodel for unemployment duration with two spells and nonparametric\nheterogeneity. Second, I show irregular identification of the median\nwillingness to pay in contingent valuation studies. Finally, I study\nidentification of the discount factor and average measures of risk aversion in\na nonparametric Euler Equation with nonparametric measurement error in\nconsumption.\n", "versions": [{"version": "v1", "created": "Wed, 21 Sep 2016 06:03:15 GMT"}, {"version": "v2", "created": "Thu, 5 Apr 2018 17:35:39 GMT"}, {"version": "v3", "created": "Sun, 22 Apr 2018 16:37:44 GMT"}, {"version": "v4", "created": "Thu, 26 Sep 2019 15:05:28 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Escanciano", "Juan Carlos", ""]]}, {"id": "1609.06545", "submitter": "Samuel Cohen", "authors": "Samuel N. Cohen", "title": "Data-driven nonlinear expectations for statistical uncertainty in\n  decisions", "comments": null, "journal-ref": null, "doi": "10.1214/17-EJS1278", "report-no": null, "categories": "math.ST math.OC math.PR q-fin.MF stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In stochastic decision problems, one often wants to estimate the underlying\nprobability measure statistically, and then to use this estimate as a basis for\ndecisions. We shall consider how the uncertainty in this estimation can be\nexplicitly and consistently incorporated in the valuation of decisions, using\nthe theory of nonlinear expectations.\n", "versions": [{"version": "v1", "created": "Wed, 21 Sep 2016 13:15:51 GMT"}], "update_date": "2017-05-24", "authors_parsed": [["Cohen", "Samuel N.", ""]]}, {"id": "1609.06561", "submitter": "Olga Moreva", "authors": "Olga Moreva, Martin Schlather", "title": "Bivariate Covariance Functions of P\\'olya Type", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide sufficient conditions of P\\'olya type which guarantee the positive\ndefiniteness of a $2\\times 2$-matrix-valued function in $\\mathbb{R}$ and\n$\\mathbb{R}^3$. Several bivariate covariance models have been proposed in\nliterature, where all components of the covariance matrix are of the same\nparametric family, such as the bivariate Mat\\'{e}rn model. Based on the P\\'olya\ntype conditions, we introduce two novel bivariate parametric covariance models\nof this class, the powered exponential (or stable) covariance model and the\ngeneralized Cauchy covariance model. Both models allow for flexible smoothness,\nvariance, scale, and cross-correlation parameters. The smoothness parameters\nare in $(0, 1]$. Additionally, the bivariate generalized Cauchy model allows\nfor distinct long range parameters. We also show that the univariate spherical\nmodel can be generalized to the bivariate case within the above class only in a\ntrivial way. In a data example on the content of copper and zinc in the top\nsoil of Swiss Jura we compare the bivariate powered exponential model to the\ntraditional linear model of coregionalization and the bivariate Mat\\'{e}rn\nmodel.\n", "versions": [{"version": "v1", "created": "Wed, 21 Sep 2016 13:53:36 GMT"}, {"version": "v2", "created": "Fri, 22 Dec 2017 12:54:52 GMT"}, {"version": "v3", "created": "Sun, 3 Mar 2019 17:04:25 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Moreva", "Olga", ""], ["Schlather", "Martin", ""]]}, {"id": "1609.06617", "submitter": "Eni Musta", "authors": "Hendrik P. Lopuha\\\"a and Eni Musta", "title": "Smoothed isotonic estimators of a monotone baseline hazard in the Cox\n  model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the smoothed maximum likelihood estimator and the smoothed\nGrenander-type estimator for a monotone baseline hazard rate $\\lambda_0$ in the\nCox model. We analyze their asymptotic behavior and show that they are\nasymptotically normal at rate $n^{m/(2m+1)}$, when~$\\lambda_0$ is $m\\geq 2$\ntimes continuously differentiable, and that both estimators are asymptotically\nequivalent. Finally, we present numerical results on pointwise confidence\nintervals that illustrate the comparable behavior of the two methods.\n", "versions": [{"version": "v1", "created": "Wed, 21 Sep 2016 16:10:13 GMT"}, {"version": "v2", "created": "Thu, 22 Sep 2016 07:47:04 GMT"}, {"version": "v3", "created": "Thu, 17 May 2018 13:32:21 GMT"}], "update_date": "2018-05-18", "authors_parsed": [["Lopuha\u00e4", "Hendrik P.", ""], ["Musta", "Eni", ""]]}, {"id": "1609.06675", "submitter": "Pierre C. Bellec", "authors": "Pierre C. Bellec and Alexandre B. Tsybakov", "title": "Bounds on the prediction error of penalized least squares estimators\n  with convex penalty", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the penalized least squares estimator with arbitrary\nconvex penalty. When the observation noise is Gaussian, we show that the\nprediction error is a subgaussian random variable concentrated around its\nmedian. We apply this concentration property to derive sharp oracle\ninequalities for the prediction error of the LASSO, the group LASSO and the\nSLOPE estimators, both in probability and in expectation. In contrast to the\nprevious work on the LASSO type methods, our oracle inequalities in probability\nare obtained at any confidence level for estimators with tuning parameters that\ndo not depend on the confidence level. This is also the reason why we are able\nto establish sparsity oracle bounds in expectation for the LASSO type\nestimators, while the previously known techniques did not allow for the control\nof the expected risk. In addition, we show that the concentration rate in the\noracle inequalities is better than it was commonly understood before.\n", "versions": [{"version": "v1", "created": "Wed, 21 Sep 2016 18:44:30 GMT"}], "update_date": "2016-09-22", "authors_parsed": [["Bellec", "Pierre C.", ""], ["Tsybakov", "Alexandre B.", ""]]}, {"id": "1609.06713", "submitter": "Zijian Guo", "authors": "Zijian Guo, Hyunseung Kang, T. Tony Cai and Dylan S. Small", "title": "Testing Endogeneity with High Dimensional Covariates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern, high dimensional data has renewed investigation on instrumental\nvariables (IV) analysis, primarily focusing on estimation of effects of\nendogenous variables and putting little attention towards specification tests.\nThis paper studies in high dimensions the Durbin-Wu-Hausman (DWH) test, a\npopular specification test for endogeneity in IV regression. We show,\nsurprisingly, that the DWH test maintains its size in high dimensions, but at\nan expense of power. We propose a new test that remedies this issue and has\nbetter power than the DWH test. Simulation studies reveal that our test\nachieves near-oracle performance to detect endogeneity.\n", "versions": [{"version": "v1", "created": "Wed, 21 Sep 2016 17:59:28 GMT"}, {"version": "v2", "created": "Tue, 4 Apr 2017 00:52:59 GMT"}, {"version": "v3", "created": "Thu, 8 Mar 2018 03:13:05 GMT"}], "update_date": "2018-03-09", "authors_parsed": [["Guo", "Zijian", ""], ["Kang", "Hyunseung", ""], ["Cai", "T. Tony", ""], ["Small", "Dylan S.", ""]]}, {"id": "1609.06744", "submitter": "Johannes Krebs", "authors": "Johannes T. N. Krebs", "title": "Non-parametric Regression for Spatially Dependent Data with Wavelets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study non-parametric regression estimates for random fields. The data\nsatisfies certain strong mixing conditions and is defined on the regular\n$N$-dimensional lattice structure. We show consistency and obtain rates of\nconvergence. The rates are optimal modulo a logarithmic factor in some cases.\nAs an application, we estimate the regression function with multidimensional\nwavelets which are not necessarily isotropic. We simulate random fields on\nplanar graphs with the concept of concliques (cf. Kaiser et al. [2012]) in\nnumerical examples of the estimation procedure.\n", "versions": [{"version": "v1", "created": "Wed, 21 Sep 2016 20:43:48 GMT"}, {"version": "v2", "created": "Thu, 9 Feb 2017 12:50:11 GMT"}, {"version": "v3", "created": "Sun, 11 Feb 2018 06:11:57 GMT"}, {"version": "v4", "created": "Wed, 4 Jul 2018 21:32:31 GMT"}], "update_date": "2018-07-06", "authors_parsed": [["Krebs", "Johannes T. N.", ""]]}, {"id": "1609.06757", "submitter": "Taposh Banerjee", "authors": "Taposh Banerjee, Miao Liu, and Jonathan P. How", "title": "Quickest Change Detection Approach to Optimal Control in Markov Decision\n  Processes with Model Changes", "comments": "In Proceedings of American Control Conference 2017, 7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.SY math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimal control in non-stationary Markov decision processes (MDP) is a\nchallenging problem. The aim in such a control problem is to maximize the\nlong-term discounted reward when the transition dynamics or the reward function\ncan change over time. When a prior knowledge of change statistics is available,\nthe standard Bayesian approach to this problem is to reformulate it as a\npartially observable MDP (POMDP) and solve it using approximate POMDP solvers,\nwhich are typically computationally demanding. In this paper, the problem is\nanalyzed through the viewpoint of quickest change detection (QCD), a set of\ntools for detecting a change in the distribution of a sequence of random\nvariables. Current methods applying QCD to such problems only passively detect\nchanges by following prescribed policies, without optimizing the choice of\nactions for long term performance. We demonstrate that ignoring the\nreward-detection trade-off can cause a significant loss in long term rewards,\nand propose a two threshold switching strategy to solve the issue. A\nnon-Bayesian problem formulation is also proposed for scenarios where a\nBayesian formulation cannot be defined. The performance of the proposed two\nthreshold strategy is examined through numerical analysis on a non-stationary\nMDP task, and the strategy outperforms the state-of-the-art QCD methods in both\nBayesian and non-Bayesian settings.\n", "versions": [{"version": "v1", "created": "Wed, 21 Sep 2016 21:13:33 GMT"}, {"version": "v2", "created": "Wed, 1 Mar 2017 21:37:52 GMT"}], "update_date": "2017-03-03", "authors_parsed": [["Banerjee", "Taposh", ""], ["Liu", "Miao", ""], ["How", "Jonathan P.", ""]]}, {"id": "1609.06806", "submitter": "Kejun He", "authors": "Kejun He and Jianhua Z. Huang", "title": "Asymptotic properties of adaptive group Lasso for sparse reduced rank\n  regression", "comments": null, "journal-ref": null, "doi": "10.1002/sta4.123", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the asymptotic properties of the penalized least squares\nestimator using an adaptive group Lasso penalty for the reduced rank\nregression. The group Lasso penalty is defined in the way that the regression\ncoefficients corresponding to each predictor are treated as one group. It is\nshown that under certain regularity conditions, the estimator can achieve the\nminimax optimal rate of convergence. Moreover, the variable selection\nconsistency can also be achieved, that is, the relevant predictors can be\nidentified with probability approaching one. In the asymptotic theory, the\nnumber of response variables, the number of predictors, and the rank number are\nallowed to grow to infinity with the sample size.\n", "versions": [{"version": "v1", "created": "Thu, 22 Sep 2016 03:18:10 GMT"}, {"version": "v2", "created": "Mon, 24 Oct 2016 20:44:51 GMT"}], "update_date": "2016-10-26", "authors_parsed": [["He", "Kejun", ""], ["Huang", "Jianhua Z.", ""]]}, {"id": "1609.06819", "submitter": "Ali Akbar Jafari", "authors": "Hojatollah Zakerzadeh and Ali Akbar Jafari and Mahdieh Karimi", "title": "Preliminary Test and Shrinkage Estimations of Scale Parameters for Two\n  Exponential Distributions based on Record Values", "comments": "Accepted for publication in Journal of Statistical Research of Iran", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The exponential distribution is applied in a very wide variety of statistical\nprocedures. Among the most prominent applications are those in the field of\nlife testing and reliability theory. When there are two record samples\navailable for estimating the scale parameter, a preliminary test is usually\nused to determine whether to pool the samples or use the individual sample. In\nthis paper, the preliminary test estimator and shrinkage estimator are studied.\nThe optimum level of significance for preliminary test estimation and the\noptimum values of shrinkage coefficient are obtained based on minimax regret\ncriterion under the weighted square error loss function.\n", "versions": [{"version": "v1", "created": "Thu, 22 Sep 2016 04:42:44 GMT"}], "update_date": "2016-09-23", "authors_parsed": [["Zakerzadeh", "Hojatollah", ""], ["Jafari", "Ali Akbar", ""], ["Karimi", "Mahdieh", ""]]}, {"id": "1609.06821", "submitter": "Fang Han", "authors": "Fang Han", "title": "An Exponential Inequality for U-Statistics under Mixing Conditions", "comments": "to appear in Journal of Theoretical Probability", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The family of U-statistics plays a fundamental role in statistics. This paper\nproves a novel exponential inequality for U-statistics under the time series\nsetting. Explicit mixing conditions are given for guaranteeing fast\nconvergence, the bound proves to be analogous to the one under independence,\nand extension to non-stationary time series is straightforward. The proof\nrelies on a novel decomposition of U-statistics via exploiting the temporal\ncorrelatedness structure. Such results are of interest in many fields where\nhigh dimensional time series data are present. In particular, applications to\nhigh dimensional time series inference are discussed.\n", "versions": [{"version": "v1", "created": "Thu, 22 Sep 2016 04:49:12 GMT"}, {"version": "v2", "created": "Wed, 2 Nov 2016 18:58:37 GMT"}, {"version": "v3", "created": "Tue, 15 Nov 2016 05:29:05 GMT"}], "update_date": "2016-11-16", "authors_parsed": [["Han", "Fang", ""]]}, {"id": "1609.06830", "submitter": "Johannes Krebs", "authors": "Johannes T. N. Krebs", "title": "Nonparametric Density Estimation for Spatial Data with Wavelets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonparametric density estimators are studied for $d$-dimensional, strongly\nspatial mixing data which is defined on a general $N$-dimensional lattice\nstructure. We consider linear and nonlinear hard thresholded wavelet estimators\nwhich are derived from a $d$-dimensional multiresolution analysis. We give\nsufficient criteria for the consistency of these estimators and derive rates of\nconvergence in $L^{p'}$ for $p'\\in [1,\\infty)$. For this reason, we study\ndensity functions which are elements of a $d$-dimensional Besov space\n$B^s_{p,q}(\\mathbb{R}^d)$. We also verify the analytic correctness of our\nresults in numerical simulations.\n", "versions": [{"version": "v1", "created": "Thu, 22 Sep 2016 06:10:37 GMT"}, {"version": "v2", "created": "Fri, 4 Aug 2017 14:55:30 GMT"}, {"version": "v3", "created": "Mon, 25 Dec 2017 13:44:17 GMT"}], "update_date": "2017-12-27", "authors_parsed": [["Krebs", "Johannes T. N.", ""]]}, {"id": "1609.06865", "submitter": "Johannes Krebs", "authors": "Johannes T. N. Krebs", "title": "Orthogonal Series Estimates on Strong Spatial Mixing Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a nonparametric regression model for sample data which is defined on\nan $N$-dimensional lattice structure and which is assumed to be strong spatial\nmixing: we use design adapted multidimensional Haar wavelets which form an\northonormal system w.r.t. the empirical measure of the sample data. For such\northonormal systems, we consider a nonparametric hard thresholding estimator.\nWe give sufficient criteria for the consistency of this estimator and we derive\nrates of convergence. The theorems reveal that our estimator is able to adapt\nto the local smoothness of the underlying regression function and the design\ndistribution. We illustrate our results with simulated examples.\n", "versions": [{"version": "v1", "created": "Thu, 22 Sep 2016 08:28:43 GMT"}, {"version": "v2", "created": "Sat, 11 Feb 2017 08:11:20 GMT"}, {"version": "v3", "created": "Fri, 28 Jul 2017 07:42:32 GMT"}], "update_date": "2017-07-31", "authors_parsed": [["Krebs", "Johannes T. N.", ""]]}, {"id": "1609.06875", "submitter": "Muneya Matsui", "authors": "Muneya Matsui", "title": "Log-convexity and the cycle index polynomials with relation to compound\n  Poisson distributions", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend the exponential formula by Bender and Canfield (1996), which\nrelates log-concavity and the cycle index polynomials. The extension clarifies\nthe log-convexity relation. The proof is by noticing the property of a compound\nPoisson distribution together with its moment generating function. We also give\na combinatorial proof of extended \"log-convex part\" referring Bender and\nCanfield's approach, where the formula by Bruijn and Erd\\\"os (1953) is\nadditionally exploited. The combinatorial approach yields richer structural\nresults more than log-convexity. Furthermore, we consider normal and binomial\nconvolutions of sequences which satisfy the exponential formula. The operations\ngenerate interesting examples which are not included in well known laws about\nlog-concavity/convexity.\n", "versions": [{"version": "v1", "created": "Thu, 22 Sep 2016 09:02:41 GMT"}, {"version": "v2", "created": "Fri, 28 Jul 2017 13:37:24 GMT"}], "update_date": "2017-07-31", "authors_parsed": [["Matsui", "Muneya", ""]]}, {"id": "1609.06877", "submitter": "Anuran Makur", "authors": "Anuran Makur and Yury Polyanskiy", "title": "Comparison of Channels: Criteria for Domination by a Symmetric Channel", "comments": "31 pages, 2 figures. Presented at 2017 IEEE International Symposium\n  on Information Theory (ISIT)", "journal-ref": "IEEE Transactions on Information Theory, vol. 64, no. 8, Aug. 2018", "doi": "10.1109/TIT.2018.2839743", "report-no": null, "categories": "cs.IT math.IT math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the basic question of whether a given channel $V$ can be\ndominated (in the precise sense of being more noisy) by a $q$-ary symmetric\nchannel. The concept of \"less noisy\" relation between channels originated in\nnetwork information theory (broadcast channels) and is defined in terms of\nmutual information or Kullback-Leibler divergence. We provide an equivalent\ncharacterization in terms of $\\chi^2$-divergence. Furthermore, we develop a\nsimple criterion for domination by a $q$-ary symmetric channel in terms of the\nminimum entry of the stochastic matrix defining the channel $V$. The criterion\nis strengthened for the special case of additive noise channels over finite\nAbelian groups. Finally, it is shown that domination by a symmetric channel\nimplies (via comparison of Dirichlet forms) a logarithmic Sobolev inequality\nfor the original channel.\n", "versions": [{"version": "v1", "created": "Thu, 22 Sep 2016 09:17:05 GMT"}, {"version": "v2", "created": "Wed, 22 Nov 2017 22:00:03 GMT"}, {"version": "v3", "created": "Mon, 3 Dec 2018 14:57:43 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Makur", "Anuran", ""], ["Polyanskiy", "Yury", ""]]}, {"id": "1609.06880", "submitter": "Johannes Krebs", "authors": "Johannes T. N. Krebs", "title": "Consistency and Asymptotic Normality of Stochastic Euler Schemes for\n  Ordinary Differential Equations", "comments": "9 pages", "journal-ref": "Statistics & Probability Letters, 125, 1-8 (2017)", "doi": "10.1016/j.spl.2017.01.016", "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  General stochastic Euler schemes for ordinary differential equations are\nstudied. We give proofs on the consistency, the rate of convergence and the\nasymptotic normality of these procedures.\n", "versions": [{"version": "v1", "created": "Thu, 22 Sep 2016 09:21:23 GMT"}], "update_date": "2017-02-09", "authors_parsed": [["Krebs", "Johannes T. N.", ""]]}, {"id": "1609.06942", "submitter": "Matan Sela", "authors": "Matan Sela and Ron Kimmel", "title": "Randomized Independent Component Analysis", "comments": "Accepted to ICSEE 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SY math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Independent component analysis (ICA) is a method for recovering statistically\nindependent signals from observations of unknown linear combinations of the\nsources. Some of the most accurate ICA decomposition methods require searching\nfor the inverse transformation which minimizes different approximations of the\nMutual Information, a measure of statistical independence of random vectors.\nTwo such approximations are the Kernel Generalized Variance or the Kernel\nCanonical Correlation which has been shown to reach the highest performance of\nICA methods. However, the computational effort necessary just for computing\nthese measures is cubic in the sample size. Hence, optimizing them becomes even\nmore computationally demanding, in terms of both space and time. Here, we\npropose a couple of alternative novel measures based on randomized features of\nthe samples - the Randomized Generalized Variance and the Randomized Canonical\nCorrelation. The computational complexity of calculating the proposed\nalternatives is linear in the sample size and provide a controllable\napproximation of their Kernel-based non-random versions. We also show that\noptimization of the proposed statistical properties yields a comparable\nseparation error at an order of magnitude faster compared to Kernel-based\nmeasures.\n", "versions": [{"version": "v1", "created": "Thu, 22 Sep 2016 12:40:58 GMT"}], "update_date": "2016-09-23", "authors_parsed": [["Sela", "Matan", ""], ["Kimmel", "Ron", ""]]}, {"id": "1609.07060", "submitter": "Madhu Advani", "authors": "Madhu Advani, Surya Ganguli", "title": "An equivalence between high dimensional Bayes optimal inference and\n  M-estimation", "comments": "To appear in NIPS 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cond-mat.dis-nn math.ST q-bio.NC stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When recovering an unknown signal from noisy measurements, the computational\ndifficulty of performing optimal Bayesian MMSE (minimum mean squared error)\ninference often necessitates the use of maximum a posteriori (MAP) inference, a\nspecial case of regularized M-estimation, as a surrogate. However, MAP is\nsuboptimal in high dimensions, when the number of unknown signal components is\nsimilar to the number of measurements. In this work we demonstrate, when the\nsignal distribution and the likelihood function associated with the noise are\nboth log-concave, that optimal MMSE performance is asymptotically achievable\nvia another M-estimation procedure. This procedure involves minimizing convex\nloss and regularizer functions that are nonlinearly smoothed versions of the\nwidely applied MAP optimization problem. Our findings provide a new heuristic\nderivation and interpretation for recent optimal M-estimators found in the\nsetting of linear measurements and additive noise, and further extend these\nresults to nonlinear measurements with non-additive noise. We numerically\ndemonstrate superior performance of our optimal M-estimators relative to MAP.\nOverall, at the heart of our work is the revelation of a remarkable equivalence\nbetween two seemingly very different computational problems: namely that of\nhigh dimensional Bayesian integration underlying MMSE inference, and high\ndimensional convex optimization underlying M-estimation. In essence we show\nthat the former difficult integral may be computed by solving the latter,\nsimpler optimization problem.\n", "versions": [{"version": "v1", "created": "Thu, 22 Sep 2016 16:46:18 GMT"}], "update_date": "2016-09-23", "authors_parsed": [["Advani", "Madhu", ""], ["Ganguli", "Surya", ""]]}, {"id": "1609.07135", "submitter": "Wentao Li", "authors": "Wentao Li and Paul Fearnhead", "title": "Convergence of Regression Adjusted Approximate Bayesian Computation", "comments": "Main text is shortened and proof is revised. To appear in Biometrika", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present asymptotic results for the regression-adjusted version of\napproximate Bayesian computation introduced by Beaumont(2002). We show that for\nan appropriate choice of the bandwidth, regression adjustment will lead to a\nposterior that, asymptotically, correctly quantifies uncertainty. Furthermore,\nfor such a choice of bandwidth we can implement an importance sampling\nalgorithm to sample from the posterior whose acceptance probability tends to\nunity as the data sample size increases. This compares favourably to results\nfor standard approximate Bayesian computation, where the only way to obtain a\nposterior that correctly quantifies uncertainty is to choose a much smaller\nbandwidth; one for which the acceptance probability tends to zero and hence for\nwhich Monte Carlo error will dominate.\n", "versions": [{"version": "v1", "created": "Thu, 22 Sep 2016 19:59:15 GMT"}, {"version": "v2", "created": "Tue, 28 Nov 2017 10:22:54 GMT"}], "update_date": "2017-11-29", "authors_parsed": [["Li", "Wentao", ""], ["Fearnhead", "Paul", ""]]}, {"id": "1609.07165", "submitter": "Jelena Bradic", "authors": "Jelena Bradic and Jiaqi Guo", "title": "Robust Confidence Intervals in High-Dimensional Left-Censored Regression", "comments": "62 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper develops robust confidence intervals in high-dimensional and\nleft-censored regression. Type-I censored regression models are extremely\ncommon in practice, where a competing event makes the variable of interest\nunobservable. However, techniques developed for entirely observed data do not\ndirectly apply to the censored observations. In this paper, we develop smoothed\nestimating equations that augment the de-biasing method, such that the\nresulting estimator is adaptive to censoring and is more robust to the\nmisspecification of the error distribution. We propose a unified class of\nrobust estimators, including Mallow's, Schweppe's and Hill-Ryan's one-step\nestimator.\n  In the ultra-high-dimensional setting, where the dimensionality can grow\nexponentially with the sample size, we show that as long as the preliminary\nestimator converges faster than $n^{-1/4}$, the one-step estimator inherits\nasymptotic distribution of fully iterated version. Moreover, we show that the\nsize of the residuals of the Bahadur representation matches those of the simple\nlinear models, $s^{3/4 } (\\log (p \\vee n))^{3/4} / n^{1/4}$ -- that is, the\neffects of censoring asymptotically disappear. Simulation studies demonstrate\nthat our method is adaptive to the censoring level and asymmetry in the error\ndistribution, and does not lose efficiency when the errors are from symmetric\ndistributions. Finally, we apply the developed method to a real data set from\nthe MAQC-II repository that is related to the HIV-1 study.\n", "versions": [{"version": "v1", "created": "Thu, 22 Sep 2016 21:09:43 GMT"}], "update_date": "2017-08-16", "authors_parsed": [["Bradic", "Jelena", ""], ["Guo", "Jiaqi", ""]]}, {"id": "1609.07415", "submitter": "Anelia Somekh-Baruch", "authors": "Anelia Somekh-Baruch, Amir Leshem, Venkatesh Saligrama", "title": "On the Non-Existence of Unbiased Estimators in Constrained Estimation\n  Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT math.IT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of existence of unbiased constrained parameter\nestimators. We show that if the constrained set of parameters is compact and\nthe hypothesized distributions are absolutely continuous with respect to one\nanother, then there exists no unbiased estimator. Weaker conditions for the\nabsence of unbiased constrained estimators are also specified. We provide\nseveral examples which demonstrate the utility of these conditions.\n", "versions": [{"version": "v1", "created": "Fri, 23 Sep 2016 16:15:47 GMT"}], "update_date": "2016-09-26", "authors_parsed": [["Somekh-Baruch", "Anelia", ""], ["Leshem", "Amir", ""], ["Saligrama", "Venkatesh", ""]]}, {"id": "1609.07452", "submitter": "Nirian Mart\\'in", "authors": "Ayandrendanath Basu, Abhik Ghosh, Abhijit Mandal, Nirian Martin,\n  Leandro Pardo", "title": "A Wald-type test statistic for testing linear hypothesis in logistic\n  regression models based on minimum density power divergence estimator", "comments": null, "journal-ref": "Electron. J. Statist. Volume 11, Number 2 (2017), 2741-2772", "doi": "10.1214/17-EJS1295", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper a robust version of the classical Wald test statistics for\nlinear hypothesis in the logistic regression model is introduced and its\nproperties are explored. We study the problem under the assumption of random\ncovariates although some ideas with non random covariates are also considered.\nThe family of tests considered is based on the minimum density power divergence\nestimator instead of the maximum likelihood estimator and it is referred to as\nthe Wald-type test statistic in the paper. We obtain the asymptotic\ndistribution and also study the robustness properties of the Wald type test\nstatistic. The robustness of the tests is investigated theoretically through\nthe influence function analysis as well as suitable practical examples. It is\ntheoretically established that the level as well as the power of the Wald-type\ntests are stable against contamination, while the classical Wald type test\nbreaks down in this scenario. Some classical examples are presented which\nnumerically substantiate the theory developed. Finally a simulation study is\nincluded to provide further confirmation of the validity of the theoretical\nresults established in the paper.\n", "versions": [{"version": "v1", "created": "Fri, 23 Sep 2016 18:21:08 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["Basu", "Ayandrendanath", ""], ["Ghosh", "Abhik", ""], ["Mandal", "Abhijit", ""], ["Martin", "Nirian", ""], ["Pardo", "Leandro", ""]]}, {"id": "1609.07532", "submitter": "Bamdad Hosseini Mr.", "authors": "Bamdad Hosseini", "title": "Well-posed Bayesian Inverse Problems with Infinitely-Divisible and\n  Heavy-Tailed Prior Measures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.NA math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new class of prior measures in connection to $\\ell_p$\nregularization techniques when $p \\in(0,1)$ which is based on the generalized\nGamma distribution. We show that the resulting prior measure is heavy-tailed,\nnon-convex and infinitely divisible. Motivated by this observation we discuss\nthe class of infinitely divisible prior measures and draw a connection between\ntheir tail behavior and the tail behavior of their L{\\'evy} measures. Next, we\nuse the laws of pure jump L{\\'e}vy processes in order to define new classes of\nprior measures that are concentrated on the space of functions with bounded\nvariation. These priors serve as an alternative to the classic total variation\nprior and result in well-defined inverse problems. We then study the\nwell-posedness of Bayesian inverse problems in a general enough setting that\nencompasses the above mentioned classes of prior measures. We establish that\nwell-posedness relies on a balance between the growth of the log-likelihood\nfunction and the tail behavior of the prior and apply our results to special\ncases such as additive noise models and linear problems. Finally, we discuss\nsome of the practical aspects of Bayesian inverse problems such as their\nconsistent approximation and present three concrete examples of well-posed\nBayesian inverse problems with heavy-tailed or stochastic process prior\nmeasures.\n", "versions": [{"version": "v1", "created": "Fri, 23 Sep 2016 22:08:45 GMT"}, {"version": "v2", "created": "Tue, 21 Feb 2017 21:21:16 GMT"}], "update_date": "2017-02-23", "authors_parsed": [["Hosseini", "Bamdad", ""]]}, {"id": "1609.07696", "submitter": "Stanislav Volgushev", "authors": "Melanie Birke, Natalie Neumeyer, Stanislav Volgushev", "title": "The independence process in conditional quantile location-scale models\n  and an application to testing for monotonicity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper the nonparametric quantile regression model is considered in a\nlocation-scale context. The asymptotic properties of the empirical independence\nprocess based on covariates and estimated residuals are investigated. In\nparticular an asymptotic expansion and weak convergence to a Gaussian process\nare proved. The results can, on the one hand, be applied to test for validity\nof the location-scale model. On the other hand, they allow to derive various\nspecification tests in conditional quantile location-scale models. In detail a\ntest for monotonicity of the conditional quantile curve is investigated. For\nthe test for validity of the location-scale model as well as for the\nmonotonicity test smooth residual bootstrap versions of Kolmogorov-Smirnov and\nCramer-von Mises type test statistics are suggested. We give rigorous proofs\nfor bootstrap versions of the weak convergence results. The performance of the\ntests is demonstrated in a simulation study.\n", "versions": [{"version": "v1", "created": "Sun, 25 Sep 2016 03:57:03 GMT"}], "update_date": "2016-09-27", "authors_parsed": [["Birke", "Melanie", ""], ["Neumeyer", "Natalie", ""], ["Volgushev", "Stanislav", ""]]}, {"id": "1609.07827", "submitter": "Chenguang Lu", "authors": "Cheguang Lu", "title": "Semantic Information Measure with Two Types of Probability for\n  Falsification and Confirmation", "comments": "27 pages, 8 figure, 10tables, a list of symbols", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT math.LO math.PR math.ST stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Logical Probability (LP) is strictly distinguished from Statistical\nProbability (SP). To measure semantic information or confirm hypotheses, we\nneed to use sampling distribution (conditional SP function) to test or confirm\nfuzzy truth function (conditional LP function). The Semantic Information\nMeasure (SIM) proposed is compatible with Shannon's information theory and\nFisher's likelihood method. It can ensure that the less the LP of a predicate\nis and the larger the true value of the proposition is, the more information\nthere is. So the SIM can be used as Popper's information criterion for\nfalsification or test. The SIM also allows us to optimize the true-value of\ncounterexamples or degrees of disbelief in a hypothesis to get the optimized\ndegree of belief, i. e. Degree of Confirmation (DOC). To explain confirmation,\nthis paper 1) provides the calculation method of the DOC of universal\nhypotheses; 2) discusses how to resolve Raven Paradox with new DOC and its\nincrement; 3) derives the DOC of rapid HIV tests: DOC of\ntest-positive=1-(1-specificity)/sensitivity, which is similar to Likelihood\nRatio (=sensitivity/(1-specificity)) but has the upper limit 1; 4) discusses\nnegative DOC for excessive affirmations, wrong hypotheses, or lies; and 5)\ndiscusses the DOC of general hypotheses with GPS as example.\n", "versions": [{"version": "v1", "created": "Mon, 26 Sep 2016 01:46:50 GMT"}], "update_date": "2016-09-27", "authors_parsed": [["Lu", "Cheguang", ""]]}, {"id": "1609.07834", "submitter": "Zhichao Jiang", "authors": "Zhichao Jiang and Peng Ding", "title": "The Directions of Selection Bias", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that if the exposure and the outcome affect the selection indicator\nin the same direction and have non-positive interaction on the risk difference,\nrisk ratio or odds ratio scale, the exposure-outcome odds ratio in the selected\npopulation is a lower bound for true odds ratio.\n", "versions": [{"version": "v1", "created": "Mon, 26 Sep 2016 02:58:32 GMT"}, {"version": "v2", "created": "Sun, 15 Jan 2017 00:42:38 GMT"}], "update_date": "2017-01-17", "authors_parsed": [["Jiang", "Zhichao", ""], ["Ding", "Peng", ""]]}, {"id": "1609.07887", "submitter": "Karel Hron", "authors": "Ivo Muller, Karel Hron, Eva Fiserova, Jan Smahaj, Panajotis\n  Cakirpaloglu, Jana Vancakova", "title": "Interpretation of Compositional Regression with Application to Time\n  Budget Analysis", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regression with compositional response or covariates, or even regression\nbetween parts of a composition, is frequently employed in social sciences.\nAmong other possible applications, it may help to reveal interesting features\nin time allocation analysis. As individual activities represent relative\ncontributions to the total amount of time, statistical processing of raw data\n(frequently represented directly as proportions or percentages) using standard\nmethods may lead to biased results. Specific geometrical features of time\nbudget variables are captured by the logratio methodology of compositional\ndata, whose aim is to build (preferably orthonormal) coordinates to be applied\nwith popular statistical methods. The aim of this paper is to present recent\ntools of regression analysis within the logratio methodology and apply them to\nreveal potential relationships among psychometric indicators in a real-world\ndata set. In particular, orthogonal logratio coordinates have been introduced\nto enhance the interpretability of coefficients in regression models.\n", "versions": [{"version": "v1", "created": "Mon, 26 Sep 2016 08:58:38 GMT"}], "update_date": "2016-09-27", "authors_parsed": [["Muller", "Ivo", ""], ["Hron", "Karel", ""], ["Fiserova", "Eva", ""], ["Smahaj", "Jan", ""], ["Cakirpaloglu", "Panajotis", ""], ["Vancakova", "Jana", ""]]}, {"id": "1609.07942", "submitter": "Davit Varron", "authors": "Davit Varron", "title": "On the bracketing entropy condition and generalized empirical measures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove a Donsker and a Glivenko--Cantelli theorem for sequences of random\ndiscrete measures generalizing empirical measures. Those two results hold under\nstandard conditions upon bracketing numbers of the indexing class of functions.\nAs a byproduct, we derive a posterior consistency and a Bernstein--von Mises\ntheorem for the Dirichlet process prior, under the topology of total variation,\nwhen the observation space is countable. We also obtain new information about\nthe Durst--Dudley--Borisov theorem\n", "versions": [{"version": "v1", "created": "Mon, 26 Sep 2016 12:17:22 GMT"}], "update_date": "2016-09-27", "authors_parsed": [["Varron", "Davit", ""]]}, {"id": "1609.07953", "submitter": "Yann Guermeur", "authors": "Yann Guermeur (ABC)", "title": "L p -norm Sauer-Shelah Lemma for Margin Multi-category Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the framework of agnostic learning, one of the main open problems of the\ntheory of multi-category pattern classification is the characterization of the\nway the complexity varies with the number C of categories. More precisely, if\nthe classifier is characterized only through minimal learnability hypotheses,\nthen the optimal dependency on C that an upper bound on the probability of\nerror should exhibit is unknown. We consider margin classifiers. They are based\non classes of vector-valued functions with one component function per category,\nand the classes of component functions are uniform Glivenko-Cantelli classes.\nFor these classifiers, an L p-norm Sauer-Shelah lemma is established. It is\nthen used to derive guaranteed risks in the L $\\infty$ and L 2-norms. These\nbounds improve over the state-of-the-art ones with respect to their dependency\non C, which is sublinear.\n", "versions": [{"version": "v1", "created": "Mon, 26 Sep 2016 12:49:07 GMT"}], "update_date": "2016-09-27", "authors_parsed": [["Guermeur", "Yann", "", "ABC"]]}, {"id": "1609.08199", "submitter": "Khalifa Es-Sebaiy", "authors": "Salwa Bajja, Khalifa Es-Sebaiy and Lauri Viitasaari", "title": "Least squares estimator of fractional Ornstein Uhlenbeck processes with\n  periodic mean", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We first study the drift parameter estimation of the fractional\nOrnstein-Uhlenbeck process (fOU) with periodic mean for every\n$\\frac{1}{2}<H<1$. More precisely, we extend the consistency proved in\n\\cite{DFW} for $\\frac{1}{2}<H<\\frac{3}{4}$ to the strong consistency for any\n$\\frac{1}{2}<H<1$ on the one hand, and on the other, we also discuss the\nasymptotic normality given in \\cite{DFW}. In the second main part of the paper,\nwe study the strong consistency and the asymptotic normality of the fOU of the\nsecond kind with periodic mean for any $\\frac{1}{2}<H<1$.\n", "versions": [{"version": "v1", "created": "Mon, 26 Sep 2016 21:46:06 GMT"}], "update_date": "2016-09-28", "authors_parsed": [["Bajja", "Salwa", ""], ["Es-Sebaiy", "Khalifa", ""], ["Viitasaari", "Lauri", ""]]}, {"id": "1609.08347", "submitter": "Juha Karvanen", "authors": "Juha Karvanen, Jarno Vanhatalo, Kari Auranen, Sangita Kulathinal and\n  Samu M\\\"antyniemi", "title": "Optimal design of observational studies: overview and synthesis", "comments": "Submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We review typical design problems encountered in the planning of\nobservational studies and propose a unifying framework that allows us to use\nthe same concepts and notation for different problems. In the framework, the\ndesign is defined as a probability measure in the space of observational\nprocesses that determine whether the value of a variable is observed for a\nspecific unit at the given time. The optimal design is then defined, according\nto Bayesian decision theory, to be the one that maximizes the expected utility\nrelated to the design. We present examples on the use of the framework and\ndiscuss methods for deriving optimal or approximately optimal designs.\n", "versions": [{"version": "v1", "created": "Tue, 27 Sep 2016 10:46:32 GMT"}, {"version": "v2", "created": "Tue, 18 Oct 2016 05:34:55 GMT"}, {"version": "v3", "created": "Wed, 1 Nov 2017 13:05:59 GMT"}], "update_date": "2017-11-02", "authors_parsed": [["Karvanen", "Juha", ""], ["Vanhatalo", "Jarno", ""], ["Auranen", "Kari", ""], ["Kulathinal", "Sangita", ""], ["M\u00e4ntyniemi", "Samu", ""]]}, {"id": "1609.08512", "submitter": "Xiaohan Wei", "authors": "Larry Goldstein, Xiaohan Wei", "title": "Non-Gaussian Observations in Nonlinear Compressed Sensing via Stein\n  Discrepancies", "comments": "31 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Performance guarantees for compression in nonlinear models under non-Gaussian\nobservations can be achieved through the use of distributional characteristics\nthat are sensitive to the distance to normality, and which in particular return\nthe value of zero under Gaussian or linear sensing. The use of these\ncharacteristics, or discrepancies, improves some previous results in this area\nby relaxing conditions and tightening performance bounds. In addition, these\ncharacteristics are tractable to compute when Gaussian sensing is corrupted by\neither additive errors or mixing.\n", "versions": [{"version": "v1", "created": "Tue, 27 Sep 2016 16:04:39 GMT"}, {"version": "v2", "created": "Sat, 30 Sep 2017 05:38:08 GMT"}], "update_date": "2017-10-03", "authors_parsed": [["Goldstein", "Larry", ""], ["Wei", "Xiaohan", ""]]}, {"id": "1609.08882", "submitter": "Alexander Aue", "authors": "Alexander Aue, Rex C.Y. Cheung, Thomas C.M. Lee, Ming Zhong", "title": "Piecewise quantile autoregressive modeling for nonstationary time series", "comments": "Published at http://dx.doi.org/10.3150/14-BEJ671 in the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2017, Vol. 23, No. 1, 1-22", "doi": "10.3150/14-BEJ671", "report-no": "IMS-BEJ-BEJ671", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a new methodology for the fitting of nonstationary time series\nthat exhibit nonlinearity, asymmetry, local persistence and changes in location\nscale and shape of the underlying distribution. In order to achieve this goal,\nwe perform model selection in the class of piecewise stationary quantile\nautoregressive processes. The best model is defined in terms of minimizing a\nminimum description length criterion derived from an asymmetric Laplace\nlikelihood. Its practical minimization is done with the use of genetic\nalgorithms. If the data generating process follows indeed a piecewise quantile\nautoregression structure, we show that our method is consistent for estimating\nthe break points and the autoregressive parameters. Empirical work suggests\nthat the proposed method performs well in finite samples.\n", "versions": [{"version": "v1", "created": "Wed, 28 Sep 2016 12:24:49 GMT"}], "update_date": "2016-09-29", "authors_parsed": [["Aue", "Alexander", ""], ["Cheung", "Rex C. Y.", ""], ["Lee", "Thomas C. M.", ""], ["Zhong", "Ming", ""]]}, {"id": "1609.08898", "submitter": "Chih-Hao Chang", "authors": "Chih-Hao Chang, Hsin-Cheng Huang, Ching-Kang Ing", "title": "Mixed domain asymptotics for a stochastic process model with time trend\n  and measurement error", "comments": "Published at http://dx.doi.org/10.3150/15-BEJ740 in the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2017, Vol. 23, No. 1, 159-190", "doi": "10.3150/15-BEJ740", "report-no": "IMS-BEJ-BEJ740", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a stochastic process model with time trend and measurement error.\nWe establish consistency and derive the limiting distributions of the maximum\nlikelihood (ML) estimators of the covariance function parameters under a\ngeneral asymptotic framework, including both the fixed domain and the\nincreasing domain frameworks, even when the time trend model is misspecified or\nits complexity increases with the sample size. In particular, the convergence\nrates of the ML estimators are thoroughly characterized in terms of the growing\nrate of the domain and the degree of model misspecification/complexity.\n", "versions": [{"version": "v1", "created": "Wed, 28 Sep 2016 13:07:30 GMT"}], "update_date": "2016-09-29", "authors_parsed": [["Chang", "Chih-Hao", ""], ["Huang", "Hsin-Cheng", ""], ["Ing", "Ching-Kang", ""]]}, {"id": "1609.08997", "submitter": "Abdelfattah Mustafa", "authors": "Abdelfattah Mustafa, B.S.El-Desouky and Shamsan AL-Garash", "title": "The Marshall-Olkin Flexible Weibull Extension Distribution", "comments": "18 pages, 17 figures. arXiv admin note: substantial text overlap with\n  arXiv:1605.08152, arXiv:1606.07378", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  This paper introduces a new generalization of the flexible Weibull\ndistribution with three parameters this model called the Marshall-Olkin\nflexible Weibull extension (MO-FWE) distribution which exhibits bathtub-shaped\nhazard rate. We studied it's statistical properties include, quantile function\nskewness and kurtosis, the mode, rth moments and moment generating function and\norder statistics. We used the method of maximum likelihood for estimating the\nmodel parameters and the observed Fisher's information matrix is derived. We\nillustrate the usefulness of the proposed model by applications to real data.\n", "versions": [{"version": "v1", "created": "Sun, 25 Sep 2016 19:22:40 GMT"}], "update_date": "2016-09-29", "authors_parsed": [["Mustafa", "Abdelfattah", ""], ["El-Desouky", "B. S.", ""], ["AL-Garash", "Shamsan", ""]]}, {"id": "1609.09033", "submitter": "David Kaplan", "authors": "David M. Kaplan and Yixiao Sun", "title": "Smoothed estimating equations for instrumental variables quantile\n  regression", "comments": "Authors' accepted manuscript; forthcoming in Econometric Theory,\n  copyright Cambridge University Press, published version at\n  http://dx.doi.org/10.1017/S0266466615000407", "journal-ref": "Econometric Theory 33 (2017) 105-157", "doi": "10.1017/S0266466615000407", "report-no": null, "categories": "stat.ME econ.EM math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The moment conditions or estimating equations for instrumental variables\nquantile regression involve the discontinuous indicator function. We instead\nuse smoothed estimating equations (SEE), with bandwidth $h$. We show that the\nmean squared error (MSE) of the vector of the SEE is minimized for some $h>0$,\nleading to smaller asymptotic MSE of the estimating equations and associated\nparameter estimators. The same MSE-optimal $h$ also minimizes the higher-order\ntype I error of a SEE-based $\\chi^2$ test and increases size-adjusted power in\nlarge samples. Computation of the SEE estimator also becomes simpler and more\nreliable, especially with (more) endogenous regressors. Monte Carlo simulations\ndemonstrate all of these superior properties in finite samples, and we apply\nour estimator to JTPA data. Smoothing the estimating equations is not just a\ntechnical operation for establishing Edgeworth expansions and bootstrap\nrefinements; it also brings the real benefits of having more precise estimators\nand more powerful tests. Code for the estimator, simulations, and empirical\nexamples is available from the first author's website.\n", "versions": [{"version": "v1", "created": "Wed, 28 Sep 2016 18:33:54 GMT"}], "update_date": "2018-02-28", "authors_parsed": [["Kaplan", "David M.", ""], ["Sun", "Yixiao", ""]]}, {"id": "1609.09035", "submitter": "David Kaplan", "authors": "Matt Goldman and David M. Kaplan", "title": "Fractional order statistic approximation for nonparametric conditional\n  quantile inference", "comments": "Authors' accepted manuscript (Journal of Econometrics); DOI TBD", "journal-ref": "Journal of Econometrics 196 (2017) 331-346", "doi": "10.1016/j.jeconom.2016.09.015", "report-no": null, "categories": "math.ST econ.EM stat.AP stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using and extending fractional order statistic theory, we characterize the\n$O(n^{-1})$ coverage probability error of the previously proposed confidence\nintervals for population quantiles using $L$-statistics as endpoints in Hutson\n(1999). We derive an analytic expression for the $n^{-1}$ term, which may be\nused to calibrate the nominal coverage level to get\n$O\\bigl(n^{-3/2}[\\log(n)]^3\\bigr)$ coverage error. Asymptotic power is shown to\nbe optimal. Using kernel smoothing, we propose a related method for\nnonparametric inference on conditional quantiles. This new method compares\nfavorably with asymptotic normality and bootstrap methods in theory and in\nsimulations. Code is available from the second author's website for both\nunconditional and conditional methods, simulations, and empirical examples.\n", "versions": [{"version": "v1", "created": "Wed, 28 Sep 2016 18:34:27 GMT"}], "update_date": "2018-02-28", "authors_parsed": [["Goldman", "Matt", ""], ["Kaplan", "David M.", ""]]}, {"id": "1609.09147", "submitter": "Trevor Campbell", "authors": "Trevor Campbell, Diana Cai, Tamara Broderick", "title": "Exchangeable Trait Allocations", "comments": "30 pages, 2 figures", "journal-ref": "Electronic Journal of Statistics 12(2), 2018, 2290-2322", "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Trait allocations are a class of combinatorial structures in which data may\nbelong to multiple groups and may have different levels of belonging in each\ngroup. Often the data are also exchangeable, i.e., their joint distribution is\ninvariant to reordering. In clustering---a special case of trait\nallocation---exchangeability implies the existence of both a de Finetti\nrepresentation and an exchangeable partition probability function (EPPF),\ndistributional representations useful for computational and theoretical\npurposes. In this work, we develop the analogous de Finetti representation and\nexchangeable trait probability function (ETPF) for trait allocations, along\nwith a characterization of all trait allocations with an ETPF. Unlike previous\nfeature allocation characterizations, our proofs fully capture\nsingle-occurrence \"dust\" groups. We further introduce a novel constrained\nversion of the ETPF that we use to establish an intuitive connection between\nthe probability functions for clustering, feature allocations, and trait\nallocations. As an application of our general theory, we characterize the\ndistribution of all edge-exchangeable graphs, a class of recently-developed\nmodels that captures realistic sparse graph sequences.\n", "versions": [{"version": "v1", "created": "Wed, 28 Sep 2016 22:44:57 GMT"}, {"version": "v2", "created": "Tue, 17 Apr 2018 15:19:35 GMT"}, {"version": "v3", "created": "Thu, 5 Jul 2018 19:25:05 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Campbell", "Trevor", ""], ["Cai", "Diana", ""], ["Broderick", "Tamara", ""]]}, {"id": "1609.09272", "submitter": "Giorgio Picci", "authors": "Giorgio Picci and Bin Zhu", "title": "A New Algorithm for Circulant Rational Covariance Extension and\n  Applications to Finite-interval Smoothing", "comments": "Submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The partial stochastic realization of periodic processes from finite\ncovariance data has recently been solved by Lindquist and Picci based on convex\noptimization of a generalized entropy functional. The meaning and the role of\nthis criterion have an unclear origin. In this paper we propose a solution\nbased on a nonlinear generalization of the classical Yule-Walker type equations\nand on a new iterative algorithm which is shown to converge to the same\n(unique) solution of the variational problem. This provides a conceptual link\nto the variational principles and at the same time yields a robust algorithm\nwhich can for example be successfully applied to finite-interval smoothing\nproblems providing a simpler procedure if compared with the classical\nRiccati-based calculations.\n", "versions": [{"version": "v1", "created": "Thu, 29 Sep 2016 09:39:42 GMT"}], "update_date": "2016-09-30", "authors_parsed": [["Picci", "Giorgio", ""], ["Zhu", "Bin", ""]]}, {"id": "1609.09287", "submitter": "Jianhai Bao", "authors": "Jianhai Bao, George Yin, Chenggui Yuan", "title": "Two-time-scale stochastic partial differential equations driven by\n  $\\alpha$-stable noises: Averaging principles", "comments": "Published at http://dx.doi.org/10.3150/14-BEJ677 in the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2017, Vol. 23, No. 1, 645-669", "doi": "10.3150/14-BEJ677", "report-no": "IMS-BEJ-BEJ677", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on stochastic partial differential equations (SPDEs) under\ntwo-time-scale formulation. Distinct from the work in the existing literature,\nthe systems are driven by $\\alpha$-stable processes with $\\alpha \\in(1,2)$. In\naddition, the SPDEs are either modulated by a continuous-time Markov chain with\na finite state space or have an addition fast jump component. The inclusion of\nthe Markov chain is for the needs of treating random environment, whereas the\naddition of the fast jump process enables the consideration of discontinuity in\nthe sample paths of the fast processes. Assuming either a fast changing Markov\nswitching or an additional fast-varying jump process, this work aims to obtain\nthe averaging principles for such systems. There are several distinct\ndifficulties. First, the noise is not square integrable. Second, in our setup,\nfor the underlying SPDE, there is only a unique mild solution and as a result,\nthere is only mild It\\^{o}'s formula that can be used. Moreover, another new\naspect is the addition of the fast regime switching and the addition of the\nfast varying jump processes in the formulation, which enlarges the\napplicability of the underlying systems. To overcome these difficulties, a\nsemigroup approach is taken. Under suitable conditions, it is proved that the\n$p$th moment convergence takes place with $p\\in(1,\\alpha )$, which is stronger\nthan the usual weak convergence approaches.\n", "versions": [{"version": "v1", "created": "Thu, 29 Sep 2016 10:27:14 GMT"}], "update_date": "2016-09-30", "authors_parsed": [["Bao", "Jianhai", ""], ["Yin", "George", ""], ["Yuan", "Chenggui", ""]]}, {"id": "1609.09331", "submitter": "Ola L{\\o}vsletten", "authors": "Ola L{\\o}vsletten", "title": "Consistency of detrended fluctuation analysis", "comments": null, "journal-ref": "Phys. Rev. E 96, 012141 (2017)", "doi": "10.1103/PhysRevE.96.012141", "report-no": null, "categories": "math.ST physics.data-an stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The scaling function $F(s)$ in detrended fluctuation analysis (DFA) scales as\n$F(s)\\sim s^{H}$ for stochastic processes with Hurst exponents $H$. We prove\nthis scaling law for both stationary stochastic processes with $0<H<1$, and\nnon-stationary stochastic processes with $1<H<2$. For $H<0.5$ we observe that\nusing the asymptotic (power-law) auto-correlation function (ACF) yield\n$F(s)\\sim s^{1/2}$. We also show that the fluctuation function in DFA is equal\nin expectation to: i) A weighted sum of the ACF ii) A weighted sum of the\nsecond order structure function. These results enable us to compute the exact\nfinite-size bias for signals that are scaling, as well as studying DFA for\nsignals that do not have power-law statistics. We illustrate this with\nexamples, where we find that a previous suggested modified DFA will increase\nthe bias for signals with Hurst exponents $H>1$. As a final application of the\nnew theory, we present an estimator $\\hat F(s)$ that can handle missing data in\nregularly sampled time series without the need for interpolation schemes. Under\nmild regularity conditions, $\\hat F(s)$ is equal in expectation to the\nfluctuation function $F(s)$ in the gap-free case.\n", "versions": [{"version": "v1", "created": "Thu, 29 Sep 2016 13:36:34 GMT"}, {"version": "v2", "created": "Fri, 16 Feb 2018 20:32:58 GMT"}], "update_date": "2018-02-20", "authors_parsed": [["L\u00f8vsletten", "Ola", ""]]}]