[{"id": "1209.0012", "submitter": "Lee Dicker", "authors": "Lee H. Dicker", "title": "Residual variance and the signal-to-noise ratio in high-dimensional\n  linear models", "comments": "50 pages, including supplemental text (included after the\n  bibliography); 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Residual variance and the signal-to-noise ratio are important quantities in\nmany statistical models and model fitting procedures. They play an important\nrole in regression diagnostics, in determining the performance limits in\nestimation and prediction problems, and in shrinkage parameter selection in\nmany popular regularized regression methods for high-dimensional data analysis.\nWe propose new estimators for the residual variance, the l2-signal strength,\nand the signal-to-noise ratio that are consistent and asymptotically normal in\nhigh-dimensional linear models with Gaussian predictors and errors, where the\nnumber of predictors d is proportional to the number of observations n.\nExisting results on residual variance estimation in high-dimensional linear\nmodels depend on sparsity in the underlying signal. Our results require no\nsparsity assumptions and imply that the residual variance may be consistently\nestimated even when d > n and the underlying signal itself is non-estimable.\nBasic numerical work suggests that some of the distributional assumptions made\nfor our theoretical results may be relaxed.\n", "versions": [{"version": "v1", "created": "Fri, 31 Aug 2012 20:30:26 GMT"}], "update_date": "2012-09-04", "authors_parsed": [["Dicker", "Lee H.", ""]]}, {"id": "1209.0285", "submitter": "Caroline Uhler", "authors": "Shaowei Lin, Caroline Uhler, Bernd Sturmfels and Peter B\\\"uhlmann", "title": "Hypersurfaces and their singularities in partial correlation testing", "comments": null, "journal-ref": null, "doi": "10.1007/s10208-014-9205-0", "report-no": null, "categories": "math.ST math.AG stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An asymptotic theory is developed for computing volumes of regions in the\nparameter space of a directed Gaussian graphical model that are obtained by\nbounding partial correlations. We study these volumes using the method of real\nlog canonical thresholds from algebraic geometry. Our analysis involves the\ncomputation of the singular loci of correlation hypersurfaces. Statistical\napplications include the strong-faithfulness assumption for the PC-algorithm,\nand the quantification of confounder bias in causal inference. A detailed\nanalysis is presented for trees, bow-ties, tripartite graphs, and complete\ngraphs.\n", "versions": [{"version": "v1", "created": "Mon, 3 Sep 2012 09:45:40 GMT"}, {"version": "v2", "created": "Mon, 2 Dec 2013 17:56:43 GMT"}], "update_date": "2014-11-05", "authors_parsed": [["Lin", "Shaowei", ""], ["Uhler", "Caroline", ""], ["Sturmfels", "Bernd", ""], ["B\u00fchlmann", "Peter", ""]]}, {"id": "1209.0304", "submitter": "Anne Vanhems", "authors": "Markus Grasmair, Otmar Scherzer, Anne Vanhems", "title": "Nonparametric instrumental regression with non-convex constraints", "comments": null, "journal-ref": null, "doi": "10.1088/0266-5611/29/3/035006", "report-no": null, "categories": "math.ST math.NA math.OC stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the nonparametric regression model with an additive\nerror that is dependent on the explanatory variables. As is common in empirical\nstudies in epidemiology and economics, it also supposes that valid instrumental\nvariables are observed. A classical example in microeconomics considers the\nconsumer demand function as a function of the price of goods and the income,\nboth variables often considered as endogenous. In this framework, the economic\ntheory also imposes shape restrictions on the demand function, like\nintegrability conditions. Motivated by this illustration in microeconomics, we\nstudy an estimator of a nonparametric constrained regression function using\ninstrumental variables by means of Tikhonov regularization. We derive rates of\nconvergence for the regularized model both in a deterministic and stochastic\nsetting under the assumption that the true regression function satisfies a\nprojected source condition including, because of the non-convexity of the\nimposed constraints, an additional smallness condition.\n", "versions": [{"version": "v1", "created": "Mon, 3 Sep 2012 11:03:29 GMT"}], "update_date": "2015-06-11", "authors_parsed": [["Grasmair", "Markus", ""], ["Scherzer", "Otmar", ""], ["Vanhems", "Anne", ""]]}, {"id": "1209.0542", "submitter": "Piet Groeneboom", "authors": "Piet Groeneboom", "title": "The bivariate current status model", "comments": "18 pages, 7 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For the univariate current status and, more generally, the interval censoring\nmodel, distribution theory has been developed for the maximum likelihood\nestimator (MLE) and smoothed maximum likelihood estimator (SMLE) of the unknown\ndistribution function, see, e.g., [12], [7], [4], [5], [6], [10], [11] and [8].\nFor the bivariate current status and interval censoring models distribution\ntheory of this type is still absent and even the rate at which we can expect\nreasonable estimators to converge is unknown. We define a purely discrete\nplug-in estimator of the distribution function which locally converges at rate\nn^{1/3} and derive its (normal) limit distribution. Unlike the MLE or SMLE,\nthis estimator is not a proper distribution function. Since the estimator is\npurely discrete, it demonstrates that the n^{1/3} convergence rate is in\nprinciple possible for the MLE, but whether this actually holds for the MLE is\nstill an open problem. If the cube root n rate holds for the MLE, this would\nmean that the local 1-dimensional rate of the MLE continues to hold in\ndimension 2, a (perhaps) somewhat surprising result. The simulation results do\nnot seem to be in contradiction with this assumption, however. We compare the\nbehavior of the plug-in estimator with the behavior of the MLE on a sieve and\nthe SMLE in a simulation study. This indicates that the plug-in estimator and\nthe SMLE have a smaller variance but a larger bias than the sieved MLE. The\nSMLE is conjectured to have a n^{1/3}-rate of convergence if we use bandwidths\nof order n^{-1/6}. We derive its (normal) limit distribution, using this\nassumption. Finally, we demonstrate the behavior of the MLE and SMLE for the\nbivariate interval censored data of [1], which have been discussed by many\nauthors, see e.g., [18], [3], [2] and [15].\n", "versions": [{"version": "v1", "created": "Tue, 4 Sep 2012 07:11:30 GMT"}, {"version": "v2", "created": "Tue, 25 Sep 2012 14:19:50 GMT"}, {"version": "v3", "created": "Fri, 28 Sep 2012 09:22:19 GMT"}, {"version": "v4", "created": "Sat, 15 Jun 2013 09:38:15 GMT"}], "update_date": "2013-06-18", "authors_parsed": [["Groeneboom", "Piet", ""]]}, {"id": "1209.0633", "submitter": "Sylvain Le Corff", "authors": "Thierry Dumont (MODAL'X), Sylvain Le Corff", "title": "Nonparametric regression on hidden phi-mixing variables: identifiability\n  and consistency of a pseudo-likelihood based estimation procedure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper outlines a new nonparametric estimation procedure for unobserved\nphi-mixing processes. It is assumed that the only information on the stationary\nhidden states (Xk) is given by the process (Yk), where Yk is a noisy\nobservation of f(Xk). The paper introduces a maximum pseudo-likelihood\nprocedure to estimate the function f and the distribution of the hidden states\nusing blocks of observations of length b. The identifiability of the model is\nstudied in the particular cases b=1 and b=2. The consistency of the estimators\nof f and of the distribution of the hidden states as the number of observations\ngrows to infinity is established.\n", "versions": [{"version": "v1", "created": "Tue, 4 Sep 2012 12:56:27 GMT"}, {"version": "v2", "created": "Mon, 10 Sep 2012 14:24:37 GMT"}, {"version": "v3", "created": "Mon, 10 Feb 2014 21:03:39 GMT"}, {"version": "v4", "created": "Wed, 26 Aug 2015 12:46:14 GMT"}], "update_date": "2015-08-27", "authors_parsed": [["Dumont", "Thierry", "", "MODAL'X"], ["Corff", "Sylvain Le", ""]]}, {"id": "1209.0703", "submitter": "Yves F. Atchad\\'{e}", "authors": "Yves F. Atchad\\'e", "title": "Markov Chain Monte Carlo confidence intervals", "comments": "Published at http://dx.doi.org/10.3150/15-BEJ712 in the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2016, Vol. 22, No. 3, 1808-1838", "doi": "10.3150/15-BEJ712", "report-no": "IMS-BEJ-BEJ712", "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For a reversible and ergodic Markov chain $\\{X_n,n\\geq0\\}$ with invariant\ndistribution $\\pi$, we show that a valid confidence interval for $\\pi(h)$ can\nbe constructed whenever the asymptotic variance $\\sigma^2_P(h)$ is finite and\npositive. We do not impose any additional condition on the convergence rate of\nthe Markov chain. The confidence interval is derived using the so-called\nfixed-b lag-window estimator of $\\sigma_P^2(h)$. We also derive a result that\nsuggests that the proposed confidence interval procedure converges faster than\nclassical confidence interval procedures based on the Gaussian distribution and\nstandard central limit theorems for Markov chains.\n", "versions": [{"version": "v1", "created": "Tue, 4 Sep 2012 16:52:43 GMT"}, {"version": "v2", "created": "Tue, 26 May 2015 17:13:53 GMT"}, {"version": "v3", "created": "Wed, 4 May 2016 12:06:08 GMT"}], "update_date": "2016-08-14", "authors_parsed": [["Atchad\u00e9", "Yves F.", ""]]}, {"id": "1209.0736", "submitter": "Bruno Ribeiro", "authors": "Fabricio Murai and Bruno Ribeiro and Don Towsley and Pinghui Wang", "title": "On Set Size Distribution Estimation and the Characterization of Large\n  Networks via Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": "Technical Report UM-CS-2012-023v2", "categories": "math.ST cs.IT cs.SI math.IT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we study the set size distribution estimation problem, where\nelements are randomly sampled from a collection of non-overlapping sets and we\nseek to recover the original set size distribution from the samples. This\nproblem has applications to capacity planning, network theory, among other\nareas. Examples of real-world applications include characterizing in-degree\ndistributions in large graphs and uncovering TCP/IP flow size distributions on\nthe Internet. We demonstrate that it is hard to estimate the original set size\ndistribution. The recoverability of original set size distributions presents a\nsharp threshold with respect to the fraction of elements that remain in the\nsets. If this fraction remains below a threshold, typically half of the\nelements in power-law and heavier-than-exponential-tailed distributions, then\nthe original set size distribution is unrecoverable. We also discuss practical\nimplications of our findings.\n", "versions": [{"version": "v1", "created": "Tue, 4 Sep 2012 19:04:36 GMT"}, {"version": "v2", "created": "Sun, 2 Dec 2012 14:16:48 GMT"}], "update_date": "2012-12-04", "authors_parsed": [["Murai", "Fabricio", ""], ["Ribeiro", "Bruno", ""], ["Towsley", "Don", ""], ["Wang", "Pinghui", ""]]}, {"id": "1209.0899", "submitter": "Nina Huber", "authors": "Nina Huber and Hannes Leeb", "title": "Shrinkage estimators for prediction out-of-sample: Conditional\n  performance", "comments": null, "journal-ref": "Communications in Statistics - Theory and Methods, 42:7,\n  1246-1264, 2013", "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We find that, in a linear model, the James-Stein estimator, which dominates\nthe maximum-likelihood estimator in terms of its in-sample prediction error,\ncan perform poorly compared to the maximum-likelihood estimator in\nout-of-sample prediction. We give a detailed analysis of this phenomenon and\ndiscuss its implications. When evaluating the predictive performance of\nestimators, we treat the regressor matrix in the training data as fixed, i.e.,\nwe condition on the design variables. Our findings contrast those obtained by\nBaranchik (1973, Ann. Stat. 1:312-321) and, more recently, by Dicker (2012,\narXiv:1102.2952) in an unconditional performance evaluation.\n", "versions": [{"version": "v1", "created": "Wed, 5 Sep 2012 09:11:52 GMT"}, {"version": "v2", "created": "Fri, 29 Nov 2013 12:37:44 GMT"}], "update_date": "2013-12-02", "authors_parsed": [["Huber", "Nina", ""], ["Leeb", "Hannes", ""]]}, {"id": "1209.0952", "submitter": "Eckhard Schlemm", "authors": "Peter J. Brockwell and Eckhard Schlemm", "title": "Parametric estimation of the driving L\\'evy process of multivariate\n  CARMA processes from discrete observations", "comments": "38 pages, four figures; to appear in Journal of Multivariate Analysis", "journal-ref": "2013, Journal of Multivariate Analysis, 115, pp 217-251", "doi": "10.1016/j.jmva.2012.09.004", "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the parametric estimation of the driving L\\'evy process of a\nmultivariate continuous-time autoregressive moving average (MCARMA) process,\nwhich is observed on the discrete time grid $(0,h,2h,...)$. Beginning with a\nnew state space representation, we develop a method to recover the driving\nL\\'evy process exactly from a continuous record of the observed MCARMA process.\nWe use tools from numerical analysis and the theory of infinitely divisible\ndistributions to extend this result to allow for the approximate recovery of\nunit increments of the driving L\\'evy process from discrete-time observations\nof the MCARMA process. We show that, if the sampling interval $h=h_N$ is chosen\ndependent on $N$, the length of the observation horizon, such that $N h_N$\nconverges to zero as $N$ tends to infinity, then any suitable generalized\nmethod of moments estimator based on this reconstructed sample of unit\nincrements has the same asymptotic distribution as the one based on the true\nincrements, and is, in particular, asymptotically normally distributed.\n", "versions": [{"version": "v1", "created": "Wed, 5 Sep 2012 12:49:26 GMT"}], "update_date": "2015-05-19", "authors_parsed": [["Brockwell", "Peter J.", ""], ["Schlemm", "Eckhard", ""]]}, {"id": "1209.1031", "submitter": "Ahmed Bensalma", "authors": "Ahmed Bensalma and Mohamed Bentarzi", "title": "Testing the Fractional Integration Parameter Revisited: a Fractional\n  Dickey-Fuller Test", "comments": null, "journal-ref": null, "doi": "10.1504/IJMOR.2018.10011879", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, in the first step, we show that the fractional Dickey-Fuller\ntest proposed by Dolado et al [10] is useless in practice. In the second step,\nwe propose a new testing procedure for the degree of fractional integration of\na time series inspired on the unit root test of Dickey-Fuller [7]. Through a\nsimulation study, we show the good performance of the test in terms of size and\npower. Finally, in order to show how to use the new testing procedure, the test\nis applied to the well-known Nelson and Plosser data.\n", "versions": [{"version": "v1", "created": "Wed, 5 Sep 2012 16:28:14 GMT"}, {"version": "v2", "created": "Fri, 12 Jul 2013 14:52:36 GMT"}, {"version": "v3", "created": "Sun, 1 May 2016 18:54:46 GMT"}], "update_date": "2018-04-03", "authors_parsed": [["Bensalma", "Ahmed", ""], ["Bentarzi", "Mohamed", ""]]}, {"id": "1209.1156", "submitter": "Takuma Yoshida", "authors": "Takuma Yoshida", "title": "Asymptotics for penalized spline estimators in quantile regression", "comments": "20 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantile regression predicts the $\\tau$-quantile of the conditional\ndistribution of a response variable given the explanatory variable for\n$\\tau\\in(0,1)$. The aim of this paper is to establish the asymptotic\ndistribution of the quantile estimator obtained by penalized spline method. A\nsimulation and an exploration of real data are performed to validate our\nresults.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2012 02:19:59 GMT"}], "update_date": "2012-09-07", "authors_parsed": [["Yoshida", "Takuma", ""]]}, {"id": "1209.1302", "submitter": "L\\'aszl\\'o Varga", "authors": "L\\'aszl\\'o Varga and Andr\\'as Zempl\\'eni", "title": "Weighted bootstrap in GARCH models", "comments": "20 pages, 5 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  GARCH models are useful tools in the investigation of phenomena, where\nvolatility changes are prominent features, like most financial data. The\nparameter estimation via quasi maximum likelihood (QMLE) and its properties are\nby now well understood. However, there is a gap between practical applications\nand the theory, as in reality there are usually not enough observations for the\nlimit results to be valid approximations. We try to fill this gap by this\npaper, where the properties of a recent bootstrap methodology in the context of\nGARCH modeling are revealed. The results are promising as it turns out that\nthis remarkably simple method has essentially the same limit distribution, as\nthe original estimatorwith the advantage of easy confidence interval\nconstruction, as it is demonstrated in the paper.\n  The finite-sample properties of the suggested estimators are investigated\nthrough a simulation study, which ensures that the results are practically\napplicable for sample sizes as low as a thousand. On the other hand, the\nresults are not 100% accurate until sample size reaches 100 thousands - but it\nis shown that this property is not a feature of our bootstrap procedure only,\nas it is shared by the original QMLE, too.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2012 14:51:52 GMT"}], "update_date": "2012-09-07", "authors_parsed": [["Varga", "L\u00e1szl\u00f3", ""], ["Zempl\u00e9ni", "Andr\u00e1s", ""]]}, {"id": "1209.1508", "submitter": "Richard Nickl", "authors": "Richard Nickl, Sara van de Geer", "title": "Confidence sets in sparse regression", "comments": "Published in at http://dx.doi.org/10.1214/13-AOS1170 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2013, Vol. 41, No. 6, 2852-2876", "doi": "10.1214/13-AOS1170", "report-no": "IMS-AOS-AOS1170", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of constructing confidence sets in the high-dimensional linear\nmodel with $n$ response variables and $p$ parameters, possibly $p\\ge n$, is\nconsidered. Full honest adaptive inference is possible if the rate of sparse\nestimation does not exceed $n^{-1/4}$, otherwise sparse adaptive confidence\nsets exist only over strict subsets of the parameter spaces for which sparse\nestimators exist. Necessary and sufficient conditions for the existence of\nconfidence sets that adapt to a fixed sparsity level of the parameter vector\nare given in terms of minimal $\\ell^2$-separation conditions on the parameter\nspace. The design conditions cover common coherence assumptions used in models\nfor sparsity, including (possibly correlated) sub-Gaussian designs.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2012 12:00:20 GMT"}, {"version": "v2", "created": "Wed, 6 Feb 2013 10:52:49 GMT"}, {"version": "v3", "created": "Tue, 17 Sep 2013 10:03:37 GMT"}, {"version": "v4", "created": "Wed, 18 Dec 2013 12:40:59 GMT"}], "update_date": "2013-12-19", "authors_parsed": [["Nickl", "Richard", ""], ["van de Geer", "Sara", ""]]}, {"id": "1209.1533", "submitter": "Samu Potka", "authors": "Samu Potka", "title": "Higher connectivity of fiber graphs of Gr\\\"obner bases", "comments": "18 pages. Minor revisions", "journal-ref": "J. Alg. Stat., 4(1):93-107, 2013", "doi": null, "report-no": null, "categories": "math.CO math.AC math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fiber graphs of Gr\\\"obner bases from contingency tables are important in\nstatistical hypothesis testing, where one studies random walks on these graphs\nusing the Metropolis-Hastings algorithm. The connectivity of the graphs has\nimplications on how fast the algorithm converges. In this paper, we study a\nclass of fiber graphs with elementary combinatorial techniques and provide\nresults that support a recent conjecture of Engstr\\\"om: the connectivity is\ngiven by the minimum vertex degree.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2012 13:37:05 GMT"}, {"version": "v2", "created": "Thu, 31 Jan 2013 21:14:20 GMT"}], "update_date": "2013-10-29", "authors_parsed": [["Potka", "Samu", ""]]}, {"id": "1209.1544", "submitter": "Ma{\\l}gorzata Snarska", "authors": "Jerzy P. Rydlewski, Ma{\\l}gorzata Snarska", "title": "On Geometric Ergodicity of Skewed - SVCHARME models", "comments": null, "journal-ref": "Statistics & Probability Letters, Volume 84, January 2014, Pages\n  192-197", "doi": "10.1016/j.spl.2013.10.008", "report-no": null, "categories": "q-fin.ST math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Markov Chain Monte Carlo is repeatedly used to analyze the properties of\nintractable distributions in a convenient way. In this paper we derive\nconditions for geometric ergodicity of a general class of nonparametric\nstochastic volatility models with skewness driven by hidden Markov Chain with\nswitching.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2012 14:15:51 GMT"}], "update_date": "2016-12-09", "authors_parsed": [["Rydlewski", "Jerzy P.", ""], ["Snarska", "Ma\u0142gorzata", ""]]}, {"id": "1209.1706", "submitter": "Abel Rodriguez", "authors": "Abel Rodriguez", "title": "Default Bayesian Analysis for the Multivariate Ewens Distribution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive the Jeffreys prior for the parameter of the Multivariate Ewens\nDistribution and study some of its properties. In particular, we show that this\nprior is proper and has no finite moments. We also investigate the impact of\nthis default prior on the a priori distribution of the number of species and\nthe a priori probability of discovery of a new species, which are usually\nemployed in subjective prior elicitation. The effect of the Jeffreys prior for\nposterior inference is illustrated using examples arising in the context of\ninference for species sampling models and Dirichlet process mixture models.\n", "versions": [{"version": "v1", "created": "Sat, 8 Sep 2012 11:31:49 GMT"}], "update_date": "2012-09-11", "authors_parsed": [["Rodriguez", "Abel", ""]]}, {"id": "1209.1764", "submitter": "Daniel Dougherty", "authors": "Karleigh Cameron, Marissa Saladin", "title": "Conditioned Likelihoods Using Bifurcation Continuation in Inverse\n  Modeling of Dynamical Systems", "comments": "26 pages, 11 figures. Work was completed by the authors while\n  attending the SURIEM REU at Michigan State University", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.DS math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Morris-Lecar (ML) model has applications to neuroscience and cognition. A\nsimple network consisting of a pair of synaptically coupled ML neurons can\nexhibit a wide variety of deterministic behaviors including asymmetric\namplitude state (AAS), equal amplitude state (EAS), and steady state (SS). In\naddition, in the presence of noise this network can exhibit mixed-mode\noscillations (MMO), which represent the system being stochastically driven\nbetween these behaviors. In this paper, we develop a method to specifically\nestimate the parameters representing the coupling strength (gsyn) and the\napplied current (Iapp) of two reciprocally coupled and biologically similar\nneurons. This method employs conditioning the likelihood on cumulative power\nand mean voltage. Conditioning has the potential to improve the identifiability\nof the estimation problem. Conditioning likelihoods are typically much simpler\nto model than the explicit joint distribution, which several studies have shown\nto be difficult or impossible to determine analytically. We adopt a rejection\nsampling procedure over a closed defined region determined by bifurcation\ncontinuation analyses. This rejection sampling procedure is easily embedded\nwithin the proposal distribution of a Bayesian Markov chain Monte Carlo (MCMC)\nscheme and we evaluate its performance. This is the first report of a Bayesian\nparameter estimation for two reciprocally coupled Morris-Lecar neurons, and we\nfind a proposal utilizing rejection sampling reduces parameter estimate bias\nrelative to naive sampling. Application to stochastically coupled ML neurons is\na future goal.\n", "versions": [{"version": "v1", "created": "Sun, 9 Sep 2012 00:55:09 GMT"}], "update_date": "2012-09-11", "authors_parsed": [["Cameron", "Karleigh", ""], ["Saladin", "Marissa", ""]]}, {"id": "1209.1988", "submitter": "Paul Marriott", "authors": "Karim Anaya-Izquierdo and Frank Critchley and Paul Marriott and Paul\n  W. Vos", "title": "Computational information geometry: theory and practice", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper lays the foundations for a unified framework for numerically and\ncomputationally applying methods drawn from a range of currently distinct\ngeometrical approaches to statistical modelling. In so doing, it extends\ninformation geometry from a manifold based approach to one where the simplex is\nthe fundamental geometrical object, thereby allowing applications to models\nwhich do not have a fixed dimension or support. Finally, it starts to build a\ncomputational framework which will act as a proxy for the 'space of all\ndistributions' that can be used, in particular, to investigate model selection\nand model uncertainty. A varied set of substantive running examples is used to\nillustrate theoretical and practical aspects of the discussion. Further\ndevelopments are briefly indicated.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2012 13:47:12 GMT"}], "update_date": "2012-09-11", "authors_parsed": [["Anaya-Izquierdo", "Karim", ""], ["Critchley", "Frank", ""], ["Marriott", "Paul", ""], ["Vos", "Paul W.", ""]]}, {"id": "1209.2013", "submitter": "Daniel Simpson", "authors": "Yu Ryan Yue, Daniel Simpson, Finn Lindgren and H{\\aa}vard Rue", "title": "Bayesian Adaptive Smoothing Spline using Stochastic Differential\n  Equations", "comments": "26 Pages, 3 Figures", "journal-ref": null, "doi": null, "report-no": "NTNU Statistics Technical Report number 8/2012", "categories": "math.ST stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The smoothing spline is one of the most popular curve-fitting methods, partly\nbecause of empirical evidence supporting its effectiveness and partly because\nof its elegant mathematical formulation. However, there are two obstacles that\nrestrict the use of smoothing spline in practical statistical work. Firstly, it\nbecomes computationally prohibitive for large data sets because the number of\nbasis functions roughly equals the sample size. Secondly, its global smoothing\nparameter can only provide constant amount of smoothing, which often results in\npoor performances when estimating inhomogeneous functions. In this work, we\nintroduce a class of adaptive smoothing spline models that is derived by\nsolving certain stochastic differential equations with finite element methods.\nThe solution extends the smoothing parameter to a continuous data-driven\nfunction, which is able to capture the change of the smoothness of underlying\nprocess. The new model is Markovian, which makes Bayesian computation fast. A\nsimulation study and real data example are presented to demonstrate the\neffectiveness of our method.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2012 14:46:56 GMT"}], "update_date": "2012-09-11", "authors_parsed": [["Yue", "Yu Ryan", ""], ["Simpson", "Daniel", ""], ["Lindgren", "Finn", ""], ["Rue", "H\u00e5vard", ""]]}, {"id": "1209.2085", "submitter": "Valentin Patilea", "authors": "Valentin Patilea, Cesar Sanchez-Sellero, Matthieu Saumard", "title": "Nonparametric testing for no-effect with functional responses and\n  functional covariates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper examines the problem of nonparametric testing for the no-effect of\na random covariate (or predictor) on a functional response. This means testing\nwhether the conditional expectation of the response given the covariate is\nalmost surely zero or not, without imposing any model relating response and\ncovariate. The covariate could be univariate, multivariate or functional. Our\ntest statistic is a quadratic form involving univariate nearest neighbor\nsmoothing and the asymptotic critical values are given by the standard normal\nlaw. When the covariate is multidimensional or functional, a preliminary\ndimension reduction device is used which allows the effect of the covariate to\nbe summarized into a univariate random quantity. The test is able to detect not\nonly linear but nonparametric alternatives. The responses could have\nconditional variance of unknown form and the law of the covariate does not need\nto be known. An empirical study with simulated and real data shows that the\ntest performs well in applications.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2012 18:31:35 GMT"}, {"version": "v2", "created": "Sat, 22 Nov 2014 09:06:46 GMT"}], "update_date": "2014-11-25", "authors_parsed": [["Patilea", "Valentin", ""], ["Sanchez-Sellero", "Cesar", ""], ["Saumard", "Matthieu", ""]]}, {"id": "1209.2275", "submitter": "Jingwei Liu", "authors": "Jingwei Liu", "title": "Inequality for Variance of Weighted Sum of Correlated Random Variables\n  and WLLN", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The upper bound inequality for variance of weighted sum of correlated random\nvariables is derived according to Cauchy-Schwarz's inequality, while the\nweights are non-negative with sum of 1. We also give a novel proof with\npositive semidefinite matrix method. And the variance inequality of sum of\ncorrelated random variable with general weights is also obtained. Then, the\nvariance inequalities are applied to the Chebyshev's inequality and sufficient\ncondition of weak law of large numbers (WLLN) for sum of correlated random\nvariables .\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2012 10:04:33 GMT"}, {"version": "v2", "created": "Tue, 25 Sep 2012 18:24:41 GMT"}, {"version": "v3", "created": "Wed, 3 Oct 2012 15:27:22 GMT"}, {"version": "v4", "created": "Thu, 4 Oct 2012 11:40:25 GMT"}, {"version": "v5", "created": "Sat, 13 Oct 2012 15:28:18 GMT"}, {"version": "v6", "created": "Sun, 23 Dec 2012 14:17:45 GMT"}, {"version": "v7", "created": "Sat, 29 Dec 2012 16:39:47 GMT"}, {"version": "v8", "created": "Wed, 17 Dec 2014 00:34:33 GMT"}], "update_date": "2014-12-18", "authors_parsed": [["Liu", "Jingwei", ""]]}, {"id": "1209.2303", "submitter": "Sebastian Engelke", "authors": "Sebastian Engelke and Alexander Malinowski and Marco Oesting and\n  Martin Schlather", "title": "Representations of max-stable processes based on single extreme events", "comments": "29 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides the basis for new methods of inference for max-stable\nprocesses \\xi\\ on general spaces that admit a certain incremental\nrepresentation, which, in important cases, has a much simpler structure than\nthe max-stable process itself. A corresponding peaks-over-threshold approach\nwill incorporate all single events that are extreme in some sense and will\ntherefore rely on a substantially larger amount of data in comparison to\nestimation procedures based on block maxima. Conditioning a process \\eta\\ in\nthe max-domain of attraction of \\xi\\ on being extremal, several convergence\nresults for the increments of \\eta\\ are proved. In a similar way, the shape\nfunctions of mixed moving maxima (M3) processes can be extracted from suitably\nconditioned single events \\eta. Connecting the two approaches, transformation\nformulae for processes that admit both an incremental and an M3 representation\nare identified.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2012 12:30:38 GMT"}], "update_date": "2012-09-12", "authors_parsed": [["Engelke", "Sebastian", ""], ["Malinowski", "Alexander", ""], ["Oesting", "Marco", ""], ["Schlather", "Martin", ""]]}, {"id": "1209.2355", "submitter": "L\\'eon Bottou", "authors": "L\\'eon Bottou, Jonas Peters, Joaquin Qui\\~nonero-Candela, Denis X.\n  Charles, D. Max Chickering, Elon Portugaly, Dipankar Ray, Patrice Simard, Ed\n  Snelson", "title": "Counterfactual Reasoning and Learning Systems", "comments": "revised version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work shows how to leverage causal inference to understand the behavior\nof complex learning systems interacting with their environment and predict the\nconsequences of changes to the system. Such predictions allow both humans and\nalgorithms to select changes that improve both the short-term and long-term\nperformance of such systems. This work is illustrated by experiments carried\nout on the ad placement system associated with the Bing search engine.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2012 15:47:43 GMT"}, {"version": "v2", "created": "Wed, 12 Sep 2012 16:47:55 GMT"}, {"version": "v3", "created": "Fri, 28 Sep 2012 21:36:18 GMT"}, {"version": "v4", "created": "Thu, 10 Jan 2013 03:09:16 GMT"}, {"version": "v5", "created": "Sat, 27 Jul 2013 18:02:46 GMT"}], "update_date": "2013-07-30", "authors_parsed": [["Bottou", "L\u00e9on", ""], ["Peters", "Jonas", ""], ["Qui\u00f1onero-Candela", "Joaquin", ""], ["Charles", "Denis X.", ""], ["Chickering", "D. Max", ""], ["Portugaly", "Elon", ""], ["Ray", "Dipankar", ""], ["Simard", "Patrice", ""], ["Snelson", "Ed", ""]]}, {"id": "1209.2544", "submitter": "David K\\\"allberg Mr", "authors": "David K\\\"allberg and Oleg Seleznjev", "title": "Estimation of entropy-type integral functionals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entropy-type integral functionals of densities are widely used in\nmathematical statistics, information theory, and computer science. Examples\ninclude measures of closeness between distributions (e.g., density power\ndivergence) and uncertainty characteristics for a random variable (e.g.,\nR\\'enyi entropy). In this paper, we study U-statistic estimators for a class of\nsuch functionals. The estimators are based on epsilon-close vector observations\nin the corresponding independent and identically distributed samples. We prove\nasymptotic properties of the estimators (consistency and asymptotic normality)\nunder mild integrability and smoothness conditions for the densities. The\nresults can be applied in diverse problems in mathematical statistics and\ncomputer science (e.g., distribution identification problems, approximate\nmatching for random databases, two-sample problems).\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2012 10:05:17 GMT"}, {"version": "v2", "created": "Sun, 20 Jan 2013 12:40:46 GMT"}, {"version": "v3", "created": "Thu, 24 Jan 2013 10:48:31 GMT"}, {"version": "v4", "created": "Thu, 7 Mar 2013 16:28:23 GMT"}], "update_date": "2013-03-08", "authors_parsed": [["K\u00e4llberg", "David", ""], ["Seleznjev", "Oleg", ""]]}, {"id": "1209.2669", "submitter": "Deniz Akdemir", "authors": "Deniz Akdemir", "title": "Likelihood Estimation with Incomplete Array Variate Observations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Missing data is an important challenge when dealing with high dimensional\ndata arranged in the form of an array. In this paper, we propose methods for\nestimation of the parameters of array variate normal probability model from\npartially observed multiway data. The methods developed here are useful for\nmissing data imputation, estimation of mean and covariance parameters for\nmultiway data. A multiway semi-parametric mixed effects model that allows\nseparation of multiway covariance effects is also defined and an efficient\nalgorithm for estimation is recommended. We provide simulation results along\nwith real life data from genetics to demonstrate these methods.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2012 17:08:36 GMT"}, {"version": "v2", "created": "Mon, 17 Sep 2012 16:10:45 GMT"}, {"version": "v3", "created": "Tue, 15 Oct 2013 18:59:47 GMT"}, {"version": "v4", "created": "Mon, 2 Jun 2014 19:45:27 GMT"}, {"version": "v5", "created": "Sun, 6 Jul 2014 00:28:39 GMT"}, {"version": "v6", "created": "Sat, 11 Oct 2014 11:18:04 GMT"}, {"version": "v7", "created": "Wed, 24 Dec 2014 18:48:16 GMT"}, {"version": "v8", "created": "Tue, 30 Dec 2014 14:49:14 GMT"}, {"version": "v9", "created": "Mon, 5 Jan 2015 15:54:01 GMT"}], "update_date": "2015-01-06", "authors_parsed": [["Akdemir", "Deniz", ""]]}, {"id": "1209.2978", "submitter": "Robin Evans", "authors": "Robin J. Evans", "title": "Graphical methods for inequality constraints in marginalized DAGs", "comments": "A final version will appear in the proceedings of the 22nd Workshop\n  on Machine Learning and Signal Processing, 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.CO stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a graphical approach to deriving inequality constraints for\ndirected acyclic graph (DAG) models, where some variables are unobserved. In\nparticular we show that the observed distribution of a discrete model is always\nrestricted if any two observed variables are neither adjacent in the graph, nor\nshare a latent parent; this generalizes the well known instrumental inequality.\nThe method also provides inequalities on interventional distributions, which\ncan be used to bound causal effects. All these constraints are characterized in\nterms of a new graphical separation criterion, providing an easy and intuitive\nmethod for their derivation.\n", "versions": [{"version": "v1", "created": "Thu, 13 Sep 2012 18:05:26 GMT"}], "update_date": "2012-09-14", "authors_parsed": [["Evans", "Robin J.", ""]]}, {"id": "1209.3215", "submitter": "Petr  Tichavsky", "authors": "Petr Tichavsky, Anh Huy Phan, and Zbynek Koldovsky", "title": "Cramer-Rao-Induced Bounds for CANDECOMP/PARAFAC tensor decomposition", "comments": "revised version with one new theorem and one new section", "journal-ref": "IEEE Transactions On Signal Processing, Vol 61, No. 8, April 15,\n  2013, pp. 1986-1997", "doi": "10.1109/TSP.2013.2245660", "report-no": null, "categories": "stat.OT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a Cramer-Rao lower bound (CRLB) on the variance of\nunbiased estimates of factor matrices in Canonical Polyadic (CP) or\nCANDECOMP/PARAFAC (CP) decompositions of a tensor from noisy observations,\n(i.e., the tensor plus a random Gaussian i.i.d. tensor). A novel expression is\nderived for a bound on the mean square angular error of factors along a\nselected dimension of a tensor of an arbitrary dimension. The expression needs\nless operations for computing the bound, O(NR^6), than the best existing\nstate-of-the art algorithm, O(N^3R^6) operations, where N and R are the tensor\norder and the tensor rank. Insightful expressions are derived for tensors of\nrank 1 and rank 2 of arbitrary dimension and for tensors of arbitrary dimension\nand rank, where two factor matrices have orthogonal columns.\n  The results can be used as a gauge of performance of different approximate CP\ndecomposition algorithms, prediction of their accuracy, and for checking\nstability of a given decomposition of a tensor (condition whether the CRLB is\nfinite or not). A novel expression is derived for a Hessian matrix needed in\npopular damped Gauss-Newton method for solving the CP decomposition of tensors\nwith missing elements. Beside computing the CRLB for these tensors the\nexpression may serve for design of damped Gauss-Newton algorithm for the\ndecomposition.\n", "versions": [{"version": "v1", "created": "Fri, 14 Sep 2012 15:06:40 GMT"}, {"version": "v2", "created": "Tue, 4 Dec 2012 16:27:01 GMT"}], "update_date": "2014-02-10", "authors_parsed": [["Tichavsky", "Petr", ""], ["Phan", "Anh Huy", ""], ["Koldovsky", "Zbynek", ""]]}, {"id": "1209.3357", "submitter": "Michael Burkhart", "authors": "Michael C. Burkhart", "title": "Linear Transformations & the Multivariate Generating Function", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This note examines linear combinations of multi-indexed sequences and derives\nthe multivariate generating function of such a linear combination in terms of\nthe original sequence's m.g.f. Applications include finding distributions and\nmoments of non-negative discrete random variables conditioned on non-negative\nlinear combinations of the original variables. Examples include independent\nPoisson r.v.'s and a $d$-variate multinomial distribution.\n", "versions": [{"version": "v1", "created": "Sat, 15 Sep 2012 05:56:19 GMT"}], "update_date": "2012-09-18", "authors_parsed": [["Burkhart", "Michael C.", ""]]}, {"id": "1209.3394", "submitter": "Marco Chiani Dr.", "authors": "Marco Chiani", "title": "Distribution of the largest eigenvalue for real Wishart and Gaussian\n  random matrices and a simple approximation for the Tracy-Widom distribution", "comments": "Journal of Multivariate Analysis (2014)", "journal-ref": "Journal of Multivariate Analysis, Vol. 129, p. 69-81, 2014", "doi": "10.1016/j.jmva.2014.04.002", "report-no": null, "categories": "cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive efficient recursive formulas giving the exact distribution of the\nlargest eigenvalue for finite dimensional real Wishart matrices and for the\nGaussian Orthogonal Ensemble (GOE). In comparing the exact distribution with\nthe limiting distribution of large random matrices, we also found that the\nTracy-Widom law can be approximated by a properly scaled and shifted Gamma\ndistribution, with great accuracy for the values of common interest in\nstatistical applications.\n", "versions": [{"version": "v1", "created": "Sat, 15 Sep 2012 11:58:28 GMT"}, {"version": "v2", "created": "Tue, 17 Sep 2013 11:52:00 GMT"}, {"version": "v3", "created": "Wed, 11 Dec 2013 05:07:40 GMT"}, {"version": "v4", "created": "Wed, 5 Feb 2014 08:51:00 GMT"}, {"version": "v5", "created": "Tue, 22 Apr 2014 07:40:58 GMT"}], "update_date": "2014-10-21", "authors_parsed": [["Chiani", "Marco", ""]]}, {"id": "1209.3570", "submitter": "Alois Pichler", "authors": "Alois Pichler", "title": "Spectral Risk Measures, With Adaptions For Stochastic Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST q-fin.RM stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic optimization problems often involve the expectation in its\nobjective. When risk is incorporated in the problem description as well, then\nrisk measures have to be involved in addition to quantify the acceptable risk,\noften in the objective. For this purpose it is important to have an adjusted,\nadapted and efficient evaluation scheme for the risk measure available. In this\narticle different representations of an important class of risk measures, the\nspectral risk measures, are elaborated. The results allow concise problem\nformulations, they are particularly adapted for stochastic optimization\nproblems. Efficient evaluation algorithms can be built on these new results,\nwhich finally make optimization problems involving spectral risk measures\neligible for stochastic optimization.\n", "versions": [{"version": "v1", "created": "Mon, 17 Sep 2012 08:01:18 GMT"}], "update_date": "2012-09-18", "authors_parsed": [["Pichler", "Alois", ""]]}, {"id": "1209.3628", "submitter": "Bartek Knapik", "authors": "B. T. Knapik, B. T. Szab\\'o, A. W. van der Vaart, J. H. van Zanten", "title": "Bayes procedures for adaptive inference in inverse problems for the\n  white noise model", "comments": "41 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study empirical and hierarchical Bayes approaches to the problem of\nestimating an infinite-dimensional parameter in mildly ill-posed inverse\nproblems. We consider a class of prior distributions indexed by a\nhyperparameter that quantifies regularity. We prove that both methods we\nconsider succeed in automatically selecting this parameter optimally, resulting\nin optimal convergence rates for truths with Sobolev or analytic \"smoothness\",\nwithout using knowledge about this regularity. Both methods are illustrated by\nsimulation examples.\n", "versions": [{"version": "v1", "created": "Mon, 17 Sep 2012 11:27:45 GMT"}, {"version": "v2", "created": "Wed, 29 May 2013 13:37:34 GMT"}], "update_date": "2013-05-30", "authors_parsed": [["Knapik", "B. T.", ""], ["Szab\u00f3", "B. T.", ""], ["van der Vaart", "A. W.", ""], ["van Zanten", "J. H.", ""]]}, {"id": "1209.3672", "submitter": "Mark Davenport", "authors": "Mark A. Davenport, Yaniv Plan, Ewout van den Berg, Mary Wootters", "title": "1-Bit Matrix Completion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT math.IT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we develop a theory of matrix completion for the extreme case\nof noisy 1-bit observations. Instead of observing a subset of the real-valued\nentries of a matrix M, we obtain a small number of binary (1-bit) measurements\ngenerated according to a probability distribution determined by the real-valued\nentries of M. The central question we ask is whether or not it is possible to\nobtain an accurate estimate of M from this data. In general this would seem\nimpossible, but we show that the maximum likelihood estimate under a suitable\nconstraint returns an accurate estimate of M when ||M||_{\\infty} <= \\alpha, and\nrank(M) <= r. If the log-likelihood is a concave function (e.g., the logistic\nor probit observation models), then we can obtain this maximum likelihood\nestimate by optimizing a convex program. In addition, we also show that if\ninstead of recovering M we simply wish to obtain an estimate of the\ndistribution generating the 1-bit measurements, then we can eliminate the\nrequirement that ||M||_{\\infty} <= \\alpha. For both cases, we provide lower\nbounds showing that these estimates are near-optimal. We conclude with a suite\nof experiments that both verify the implications of our theorems as well as\nillustrate some of the practical applications of 1-bit matrix completion. In\nparticular, we compare our program to standard matrix completion methods on\nmovie rating data in which users submit ratings from 1 to 5. In order to use\nour program, we quantize this data to a single bit, but we allow the standard\nmatrix completion program to have access to the original ratings (from 1 to 5).\nSurprisingly, the approach based on binary data performs significantly better.\n", "versions": [{"version": "v1", "created": "Mon, 17 Sep 2012 14:47:31 GMT"}, {"version": "v2", "created": "Thu, 5 Sep 2013 00:21:25 GMT"}, {"version": "v3", "created": "Tue, 1 Jul 2014 18:43:15 GMT"}], "update_date": "2014-07-02", "authors_parsed": [["Davenport", "Mark A.", ""], ["Plan", "Yaniv", ""], ["Berg", "Ewout van den", ""], ["Wootters", "Mary", ""]]}, {"id": "1209.4013", "submitter": "Yunwei Cui", "authors": "Yunwei Cui, Rongning Wu, Thomas J. Fisher", "title": "Diagnostic Tests for Non-causal Time Series with Infinite Variance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study goodness-of-fit testing for non-causal autoregressive time series\nwith non-Gaussian stable noise. To model time series exhibiting sharp spikes or\noccasional bursts of outlying observations, the exponent of the non-Gaussian\nstable variables is assumed to be less than two. Under such conditions, the\ninnovation variables have no finite second moment. We proved that the sample\nautocorrelation functions of the trimmed residuals are asymptotically normal.\nNonparametric tests are also investigated. The rank correlations of the\nresiduals or the squared residuals are shown to be asymptotically normal. Thus,\nan assortment of portmanteau statistics are available for model assessment.\n", "versions": [{"version": "v1", "created": "Tue, 18 Sep 2012 16:17:14 GMT"}], "update_date": "2012-09-19", "authors_parsed": [["Cui", "Yunwei", ""], ["Wu", "Rongning", ""], ["Fisher", "Thomas J.", ""]]}, {"id": "1209.4065", "submitter": "Ahmet Yilmaz", "authors": "Ahmet Yilmaz, Ferkan Yilmaz, Mohamed-Slim Alouini and O\\u{g}uz Kucur", "title": "On the Performance of Transmit Antenna Selection Based on Shadowing Side\n  Information", "comments": "7 pages, 5 figures, journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT math.ST stat.OT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a transmit antenna selection scheme, which is based on\nshadowing side information, is investigated. In this scheme, the selected\nsingle transmit antenna provides the highest shadowing coefficient between\ntransmitter and receiver. By the proposed technique, the frequency of the usage\nof the feedback channel from the receiver to the transmitter and also channel\nestimation complexity at the receiver can be reduced. We study the performance\nof our proposed technique and in the analysis, we consider an independent but\nnot identically distributed Generalized-K composite fading model. More\nspecifically exact and closed-form expressions for the outage probability, the\nmoment generating function, the moments of signal-to-noise ratio, and the\naverage symbol error probability are derived. In addition, asymptotic outage\nprobability and symbol error probability expressions are also presented in\norder to investigate the diversity order and the array gain. Finally, our\ntheoretical performance results are validated by Monte Carlo simulations.\n", "versions": [{"version": "v1", "created": "Tue, 18 Sep 2012 19:14:13 GMT"}, {"version": "v2", "created": "Wed, 19 Sep 2012 12:18:01 GMT"}], "update_date": "2012-09-20", "authors_parsed": [["Yilmaz", "Ahmet", ""], ["Yilmaz", "Ferkan", ""], ["Alouini", "Mohamed-Slim", ""], ["Kucur", "O\u011fuz", ""]]}, {"id": "1209.4089", "submitter": "Masoud  Nasari", "authors": "Miklos Csorgo, Yuliya Martsynyuk, Masoud Nasari", "title": "Another look at Bootstrapping the Student t-statistic", "comments": "33 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let X, X_1,X_2,... be a sequence of i.i.d. random variables with mean $\\mu=E\nX$. Let ${v_1^{(n)},...,v_n^{(n)}}_{n=1}^\\infty$ be vectors of non-negative\nrandom variables (weights), independent of the data sequence\n${X_1,...,X_n}_{n=1}^\\infty$, and put $m_n=\\sumn v_i^{(n)}$. Consider $\nX^{*}_1,..., X^{*}_{m_n}$, $m_n\\geq 1$, a bootstrap sample, resulting from\nre-sampling or stochastically re-weighing a random sample $X_1,...,X_n$, $n\\geq\n1$. Put $\\bar{X}_n= \\sumn X_i/n$, the original sample mean, and define\n$\\bar{X^*}_{m_n}=\\sumn v_i^{(n)} X_i/m_n$, the bootstrap sample mean. Thus,\n$\\bar{X^*}_{m_n}- \\bar{X}_n=\\sumn ({v_i^{(n)}}/{m_n}-{1}/{n}) X_i$. Put\n$V_n^{2}=\\sumn ({v_i^{(n)}}/{m_n}-{1}/{n})^2$ and let $S_n^{2}$,\n$S_{m_{n}}^{*^{2}}$ respectively be the the original sample variance and the\nbootstrap sample variance. The main aim of this exposition is to study the\nasymptotic behavior of the bootstrapped $t$-statistics $T_{m_n}^{*}:=\n(\\bar{X^*}_{m_n}- \\bar{X}_n)/(S_n V_n)$ and $T_{m_n}^{**}:=\n\\sqrt{m_n}(\\bar{X^*}_{m_n}- \\bar{X}_n)/ S_{m_{n}}^{*} $ in terms of\nconditioning on the weights via assuming that, as $n,m_n\\to \\infty$,\n$\\max_{1\\leq i \\leq n}({v_i^{(n)}}/{m_n}-{1}/{n})^2\\big/ V_n^{2}=o(1)$ almost\nsurely or in probability on the probability space of the weights. This view of\njustifying the validity of the bootstrap is believed to be new. The need for it\narises naturally in practice when exploring the nature of information contained\nin a random sample via re-sampling, for example. Conditioning on the data is\nalso revisited for Efron's bootstrap weights under conditions on $n,m_n$ as\n$n\\to \\infty $ that differ from requiring $m_n /n$ to be in the interval\n$(\\lambda_1,\\lambda_2)$ with 0< \\lambda_1 < \\lambda_2 < \\infty as in Mason and\nShao. Also, the validity of the bootstrapped $t$-intervals for both approaches\nto conditioning is established.\n", "versions": [{"version": "v1", "created": "Tue, 18 Sep 2012 20:02:41 GMT"}, {"version": "v2", "created": "Mon, 7 Jan 2013 00:56:42 GMT"}, {"version": "v3", "created": "Tue, 8 Jan 2013 16:03:42 GMT"}, {"version": "v4", "created": "Mon, 27 May 2013 16:14:39 GMT"}], "update_date": "2013-05-28", "authors_parsed": [["Csorgo", "Miklos", ""], ["Martsynyuk", "Yuliya", ""], ["Nasari", "Masoud", ""]]}, {"id": "1209.4173", "submitter": "Jean Jacod", "authors": "Jean Jacod, Markus Reiss", "title": "A remark on the rates of convergence for integrated volatility\n  estimation in the presence of jumps", "comments": "Published in at http://dx.doi.org/10.1214/13-AOS1179 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2014, Vol. 42, No. 3, 1131-1144", "doi": "10.1214/13-AOS1179", "report-no": "IMS-AOS-AOS1179", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The optimal rate of convergence of estimators of the integrated volatility,\nfor a discontinuous It\\^{o} semimartingale sampled at regularly spaced times\nand over a fixed time interval, has been a long-standing problem, at least when\nthe jumps are not summable. In this paper, we study this optimal rate, in the\nminimax sense and for appropriate \"bounded\" nonparametric classes of\nsemimartingales. We show that, if the $r$th powers of the jumps are summable\nfor some $r\\in[0,2)$, the minimax rate is equal to $\\min(\\sqrt{n},(n\\log\nn)^{(2-r)/2})$, where $n$ is the number of observations.\n", "versions": [{"version": "v1", "created": "Wed, 19 Sep 2012 08:00:30 GMT"}, {"version": "v2", "created": "Mon, 23 Jun 2014 13:05:22 GMT"}], "update_date": "2014-06-24", "authors_parsed": [["Jacod", "Jean", ""], ["Reiss", "Markus", ""]]}, {"id": "1209.4177", "submitter": "Marc Hallin", "authors": "Marc Hallin, Christophe Ley", "title": "Skew-symmetric distributions and Fisher information: The double sin of\n  the skew-normal", "comments": "Published in at http://dx.doi.org/10.3150/13-BEJ528 the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2014, Vol. 20, No. 3, 1432-1453", "doi": "10.3150/13-BEJ528", "report-no": "IMS-BEJ-BEJ528", "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hallin and Ley [Bernoulli 18 (2012) 747-763] investigate and fully\ncharacterize the Fisher singularity phenomenon in univariate and multivariate\nfamilies of skew-symmetric distributions. This paper proposes a refined\nanalysis of the (univariate) problem, showing that singularity can be more or\nless severe, inducing $n^{1/4}$ (\"simple singularity\"), $n^{1/6}$ (\"double\nsingularity\"), or $n^{1/8}$ (\"triple singularity\") consistency rates for the\nskewness parameter. We show, however, that simple singularity (yielding\n$n^{1/4}$ consistency rates), if any singularity at all, is the rule, in the\nsense that double and triple singularities are possible for generalized\nskew-normal families only. We also show that higher-order singularities,\nleading to worse-than-$n^{1/8}$ rates, cannot occur. Depending on the degree of\nthe singularity, our analysis also suggests a simple reparametrization that\noffers an alternative to the so-called centred parametrization proposed, in the\nparticular case of skew-normal and skew-$t$ families, by Azzalini [Scand. J.\nStat. 12 (1985) 171-178], Arellano-Valle and Azzalini [J. Multivariate Anal.\n113 (2013) 73-90], and DiCiccio and Monti [Quaderni di Statistica 13 (2011)\n1-21], respectively.\n", "versions": [{"version": "v1", "created": "Wed, 19 Sep 2012 08:16:00 GMT"}, {"version": "v2", "created": "Fri, 15 Mar 2013 11:07:14 GMT"}, {"version": "v3", "created": "Wed, 9 Jul 2014 11:17:34 GMT"}], "update_date": "2014-07-10", "authors_parsed": [["Hallin", "Marc", ""], ["Ley", "Christophe", ""]]}, {"id": "1209.4188", "submitter": "Juan-Pablo Ortega", "authors": "Lyudmila Grigoryeva and Juan-Pablo Ortega", "title": "Finite sample forecasting with estimated temporally aggregated linear\n  processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a finite sample based predictor for estimated linear one\ndimensional time series models and compute the associated total forecasting\nerror. The expression for the error that we present takes into account the\nestimation error. Unlike existing solutions in the literature, our formulas\nrequire neither assumptions on the second order stationarity of the sample nor\nMonte Carlo simulations for their evaluation. This result is used to prove the\npertinence of a new hybrid scheme that we put forward for the forecast of\nlinear temporal aggregates. This novel strategy consists of carrying out the\nparameter estimation based on disaggregated data and the prediction based on\nthe corresponding aggregated model and data. We show that in some instances\nthis scheme has a better performance than the \"all-disaggregated\" approach\npresented as optimal in the literature.\n", "versions": [{"version": "v1", "created": "Wed, 19 Sep 2012 08:58:53 GMT"}], "update_date": "2012-09-20", "authors_parsed": [["Grigoryeva", "Lyudmila", ""], ["Ortega", "Juan-Pablo", ""]]}, {"id": "1209.4280", "submitter": "Ali Taylan Cemgil", "authors": "Y. Kenan Yilmaz and A. Taylan Cemgil", "title": "Alpha/Beta Divergences and Tweedie Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe the underlying probabilistic interpretation of alpha and beta\ndivergences. We first show that beta divergences are inherently tied to Tweedie\ndistributions, a particular type of exponential family, known as exponential\ndispersion models. Starting from the variance function of a Tweedie model, we\noutline how to get alpha and beta divergences as special cases of Csisz\\'ar's\n$f$ and Bregman divergences. This result directly generalizes the well-known\nrelationship between the Gaussian distribution and least squares estimation to\nTweedie models and beta divergence minimization.\n", "versions": [{"version": "v1", "created": "Wed, 19 Sep 2012 15:20:47 GMT"}], "update_date": "2012-09-20", "authors_parsed": [["Yilmaz", "Y. Kenan", ""], ["Cemgil", "A. Taylan", ""]]}, {"id": "1209.4340", "submitter": "Andreas Winkelbauer", "authors": "Andreas Winkelbauer", "title": "Moments and Absolute Moments of the Normal Distribution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT math.IT math.PR stat.OT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present formulas for the (raw and central) moments and absolute moments of\nthe normal distribution. We note that these results are not new, yet many\ntextbooks miss out on at least some of them. Hence, we believe that it is\nworthwhile to collect these formulas and their derivations in these notes.\n", "versions": [{"version": "v1", "created": "Wed, 19 Sep 2012 19:31:58 GMT"}, {"version": "v2", "created": "Tue, 15 Jul 2014 14:41:58 GMT"}], "update_date": "2014-07-18", "authors_parsed": [["Winkelbauer", "Andreas", ""]]}, {"id": "1209.4543", "submitter": "Benedikt M. P\\\"otscher", "authors": "Hannes Leeb and Benedikt M. P\\\"otscher", "title": "Testing in the Presence of Nuisance Parameters: Some Comments on Tests\n  Post-Model-Selection and Random Critical Values", "comments": "Minor revision. Some typos and errors corrected, some references\n  added", "journal-ref": "In: S. Ejaz Ahmed (ed.), Big and Complex Data Analysis:\n  Methodology and Applications, Springer, 2017", "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We point out that the ideas underlying some test procedures recently proposed\nfor testing post-model-selection (and for some other test problems) in the\neconometrics literature have been around for quite some time in the statistics\nliterature. We also sharpen some of these results in the statistics literature.\nFurthermore, we show that some intuitively appealing testing procedures, that\nhave found their way into the econometrics literature, lead to tests that do\nnot have desirable size properties, not even asymptotically.\n", "versions": [{"version": "v1", "created": "Thu, 20 Sep 2012 14:22:07 GMT"}, {"version": "v2", "created": "Mon, 20 May 2013 16:35:30 GMT"}, {"version": "v3", "created": "Wed, 28 May 2014 15:45:04 GMT"}], "update_date": "2017-08-30", "authors_parsed": [["Leeb", "Hannes", ""], ["P\u00f6tscher", "Benedikt M.", ""]]}, {"id": "1209.4675", "submitter": "Mindaugas Bloznelis", "authors": "Mindaugas Bloznelis, Jerzy Jaworski, Valentas Kurauskas", "title": "Assortativity and clustering of sparse random intersection graphs", "comments": null, "journal-ref": "Electron. J. Probab. Volume 18 (2013), paper no. 38, 24 pp", "doi": "10.1214/ejp.v18-2277", "report-no": null, "categories": "math.PR math.CO math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider sparse random intersection graphs with the property that the\nclustering coefficient does not vanish as the number of nodes tends to\ninfinity. We find explicit asymptotic expressions for the correlation\ncoefficient of degrees of adjacent nodes (called the assortativity\ncoefficient), the expected number of common neighbours of adjacent nodes, and\nthe expected degree of a neighbour of a node of a given degree k. These\nexpressions are written in terms of the asymptotic degree distribution and,\nalternatively, in terms of the parameters defining the underlying random graph\nmodel.\n", "versions": [{"version": "v1", "created": "Thu, 20 Sep 2012 22:15:48 GMT"}], "update_date": "2019-08-24", "authors_parsed": [["Bloznelis", "Mindaugas", ""], ["Jaworski", "Jerzy", ""], ["Kurauskas", "Valentas", ""]]}, {"id": "1209.4746", "submitter": "Jean-Marc Bardet", "authors": "Jean-Marc Bardet (SAMM), William Chakry Kengne (SAMM)", "title": "Monitoring procedure for parameter change in causal time series", "comments": "arXiv admin note: text overlap with arXiv:1101.5960 by other authors", "journal-ref": "Journal of Multivariate Analysis 125 (2014) 204-221", "doi": "10.1016/j.jmva.2013.12.004", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new sequential procedure to detect change in the parameters of a\nprocess $ X= (X_t)_{t\\in \\Z}$ belonging to a large class of causal models (such\nas AR($\\infty$), ARCH($\\infty$), TARCH($\\infty$), ARMA-GARCH processes). The\nprocedure is based on a difference between the historical parameter estimator\nand the updated parameter estimator, where both these estimators are based on a\nquasi-likelihood of the model. Unlike classical recursive fluctuation test, the\nupdated estimator is computed without the historical observations. The\nasymptotic behavior of the test is studied and the consistency in power as well\nas an upper bound of the detection delay are obtained. Some simulation results\nare reported with comparisons to some other existing procedures exhibiting the\naccuracy of our new procedure. The procedure is also applied to the daily\nclosing values of the Nikkei 225, S$&$P 500 and FTSE 100 stock index. We show\nin this real-data applications how the procedure can be used to solve off-line\nmultiple breaks detection.\n", "versions": [{"version": "v1", "created": "Fri, 21 Sep 2012 08:36:32 GMT"}, {"version": "v2", "created": "Thu, 21 Feb 2013 19:56:00 GMT"}], "update_date": "2014-02-12", "authors_parsed": [["Bardet", "Jean-Marc", "", "SAMM"], ["Kengne", "William Chakry", "", "SAMM"]]}, {"id": "1209.4875", "submitter": "Youngki Shin Youngki Shin", "authors": "Sokbae Lee, Myung Hwan Seo, Youngki Shin", "title": "The Lasso for High-Dimensional Regression with a Possible Change-Point", "comments": null, "journal-ref": "Journal of the Royal Statistical Society: Series B, 78(1), 2016,\n  pp. 193-210", "doi": "10.1111/rssb.12108", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a high-dimensional regression model with a possible change-point\ndue to a covariate threshold and develop the Lasso estimator of regression\ncoefficients as well as the threshold parameter. Our Lasso estimator not only\nselects covariates but also selects a model between linear and threshold\nregression models. Under a sparsity assumption, we derive non-asymptotic oracle\ninequalities for both the prediction risk and the $\\ell_1$ estimation loss for\nregression coefficients. Since the Lasso estimator selects variables\nsimultaneously, we show that oracle inequalities can be established without\npretesting the existence of the threshold effect. Furthermore, we establish\nconditions under which the estimation error of the unknown threshold parameter\ncan be bounded by a nearly $n^{-1}$ factor even when the number of regressors\ncan be much larger than the sample size ($n$). We illustrate the usefulness of\nour proposed estimation method via Monte Carlo simulations and an application\nto real data.\n", "versions": [{"version": "v1", "created": "Fri, 21 Sep 2012 18:08:32 GMT"}, {"version": "v2", "created": "Mon, 31 Dec 2012 15:03:55 GMT"}, {"version": "v3", "created": "Thu, 22 Aug 2013 13:20:41 GMT"}, {"version": "v4", "created": "Sat, 19 Apr 2014 04:48:49 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["Lee", "Sokbae", ""], ["Seo", "Myung Hwan", ""], ["Shin", "Youngki", ""]]}, {"id": "1209.4947", "submitter": "Paulo C. Marques F.", "authors": "Paulo C. Marques F. and Carlos A. de B. Pereira", "title": "Bayesian Analysis of Simple Random Densities", "comments": "19 pages; 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A tractable nonparametric prior over densities is introduced which is closed\nunder sampling and exhibits proper posterior asymptotics.\n", "versions": [{"version": "v1", "created": "Sat, 22 Sep 2012 00:58:27 GMT"}, {"version": "v2", "created": "Tue, 10 Jun 2014 20:17:39 GMT"}], "update_date": "2014-06-12", "authors_parsed": [["F.", "Paulo C. Marques", ""], ["Pereira", "Carlos A. de B.", ""]]}, {"id": "1209.4957", "submitter": "Michael Burkhart", "authors": "Michael C. Burkhart", "title": "Conditional Probabilities of Multivariate Poisson Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multivariate Poisson distributions have numerous applications. Fast\ncomputation of these distributions, holding constant a fixed set of linear\ncombinations of these variables, has been explored by Sontag and Zeilberger.\nThis elaborates on their work.\n", "versions": [{"version": "v1", "created": "Sat, 22 Sep 2012 03:45:08 GMT"}], "update_date": "2012-09-25", "authors_parsed": [["Burkhart", "Michael C.", ""]]}, {"id": "1209.5075", "submitter": "Shuheng Zhou", "authors": "Shuheng Zhou", "title": "Gemini: Graph estimation with matrix variate normal instances", "comments": "Published in at http://dx.doi.org/10.1214/13-AOS1187 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2014, Vol. 42, No. 2, 532-562", "doi": "10.1214/13-AOS1187", "report-no": "IMS-AOS-AOS1187", "categories": "stat.ML math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Undirected graphs can be used to describe matrix variate distributions. In\nthis paper, we develop new methods for estimating the graphical structures and\nunderlying parameters, namely, the row and column covariance and inverse\ncovariance matrices from the matrix variate data. Under sparsity conditions, we\nshow that one is able to recover the graphs and covariance matrices with a\nsingle random matrix from the matrix variate normal distribution. Our method\nextends, with suitable adaptation, to the general setting where replicates are\navailable. We establish consistency and obtain the rates of convergence in the\noperator and the Frobenius norm. We show that having replicates will allow one\nto estimate more complicated graphical structures and achieve faster rates of\nconvergence. We provide simulation evidence showing that we can recover\ngraphical structures as well as estimating the precision matrices, as predicted\nby theory.\n", "versions": [{"version": "v1", "created": "Sun, 23 Sep 2012 15:22:02 GMT"}, {"version": "v2", "created": "Fri, 23 May 2014 10:25:58 GMT"}], "update_date": "2014-05-26", "authors_parsed": [["Zhou", "Shuheng", ""]]}, {"id": "1209.5170", "submitter": "Yacine A\\\"{i}t-Sahalia", "authors": "Yacine A\\\"it-Sahalia, Jean Jacod", "title": "Identifying the successive Blumenthal-Getoor indices of a discretely\n  observed process", "comments": "Published in at http://dx.doi.org/10.1214/12-AOS976 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2012, Vol. 40, No. 3, 1430-1464", "doi": "10.1214/12-AOS976", "report-no": "IMS-AOS-AOS976", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the identification of the L\\'{e}vy jump measure of a\ndiscretely-sampled semimartingale. We define successive Blumenthal-Getoor\nindices of jump activity, and show that the leading index can always be\nidentified, but that higher order indices are only identifiable if they are\nsufficiently close to the previous one, even if the path is fully observed.\nThis result establishes a clear boundary on which aspects of the jump measure\ncan be identified on the basis of discrete observations, and which cannot. We\nthen propose an estimation procedure for the identifiable indices and compare\nthe rates of convergence of these estimators with the optimal rates in a\nspecial parametric case, which we can compute explicitly.\n", "versions": [{"version": "v1", "created": "Mon, 24 Sep 2012 07:20:29 GMT"}], "update_date": "2012-09-25", "authors_parsed": [["A\u00eft-Sahalia", "Yacine", ""], ["Jacod", "Jean", ""]]}, {"id": "1209.5183", "submitter": "Yu-Ru Su", "authors": "Yu-Ru Su, Jane-Ling Wang", "title": "Modeling left-truncated and right-censored survival data with\n  longitudinal covariates", "comments": "Published in at http://dx.doi.org/10.1214/12-AOS996 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2012, Vol. 40, No. 3, 1465-1488", "doi": "10.1214/12-AOS996", "report-no": "IMS-AOS-AOS996", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a surge in medical follow-up studies that include longitudinal\ncovariates in the modeling of survival data. So far, the focus has been largely\non right-censored survival data. We consider survival data that are subject to\nboth left truncation and right censoring. Left truncation is well known to\nproduce biased sample. The sampling bias issue has been resolved in the\nliterature for the case which involves baseline or time-varying covariates that\nare observable. The problem remains open, however, for the important case where\nlongitudinal covariates are present in survival models. A joint likelihood\napproach has been shown in the literature to provide an effective way to\novercome those difficulties for right-censored data, but this approach faces\nsubstantial additional challenges in the presence of left truncation. Here we\nthus propose an alternative likelihood to overcome these difficulties and show\nthat the regression coefficient in the survival component can be estimated\nunbiasedly and efficiently. Issues about the bias for the longitudinal\ncomponent are discussed. The new approach is illustrated numerically through\nsimulations and data from a multi-center AIDS cohort study.\n", "versions": [{"version": "v1", "created": "Mon, 24 Sep 2012 08:05:03 GMT"}], "update_date": "2012-09-25", "authors_parsed": [["Su", "Yu-Ru", ""], ["Wang", "Jane-Ling", ""]]}, {"id": "1209.5240", "submitter": "M. J. Bayarri", "authors": "M. J. Bayarri, J. O. Berger, A. Forte, G. Garc\\'ia-Donato", "title": "Criteria for Bayesian model choice with application to variable\n  selection", "comments": "Published in at http://dx.doi.org/10.1214/12-AOS1013 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2012, Vol. 40, No. 3, 1550-1577", "doi": "10.1214/12-AOS1013", "report-no": "IMS-AOS-AOS1013", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In objective Bayesian model selection, no single criterion has emerged as\ndominant in defining objective prior distributions. Indeed, many criteria have\nbeen separately proposed and utilized to propose differing prior choices. We\nfirst formalize the most general and compelling of the various criteria that\nhave been suggested, together with a new criterion. We then illustrate the\npotential of these criteria in determining objective model selection priors by\nconsidering their application to the problem of variable selection in normal\nlinear models. This results in a new model selection objective prior with a\nnumber of compelling properties.\n", "versions": [{"version": "v1", "created": "Mon, 24 Sep 2012 12:07:52 GMT"}], "update_date": "2012-09-25", "authors_parsed": [["Bayarri", "M. J.", ""], ["Berger", "J. O.", ""], ["Forte", "A.", ""], ["Garc\u00eda-Donato", "G.", ""]]}, {"id": "1209.5356", "submitter": "Nicole Kraemer", "authors": "Nicole Kraemer and Eike C. Brechmann and Daniel Silvestrini and\n  Claudia Czado", "title": "Total loss estimation using copula-based regression models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.AP stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a joint copula-based model for insurance claims and sizes. It uses\nbivariate copulae to accommodate for the dependence between these quantities.\nWe derive the general distribution of the policy loss without the restrictive\nassumption of independence. We illustrate that this distribution tends to be\nskewed and multi-modal, and that an independence assumption can lead to\nsubstantial bias in the estimation of the policy loss. Further, we extend our\nframework to regression models by combining marginal generalized linear models\nwith a copula. We show that this approach leads to a flexible class of models,\nand that the parameters can be estimated efficiently using maximum-likelihood.\nWe propose a test procedure for the selection of the optimal copula family. The\nusefulness of our approach is illustrated in a simulation study and in an\nanalysis of car insurance policies.\n", "versions": [{"version": "v1", "created": "Mon, 24 Sep 2012 18:28:04 GMT"}], "update_date": "2012-09-25", "authors_parsed": [["Kraemer", "Nicole", ""], ["Brechmann", "Eike C.", ""], ["Silvestrini", "Daniel", ""], ["Czado", "Claudia", ""]]}, {"id": "1209.5543", "submitter": "Yuan Wu", "authors": "Yuan Wu, Ying Zhang", "title": "Partially monotone tensor spline estimation of the joint distribution\n  function with bivariate current status data", "comments": "Published in at http://dx.doi.org/10.1214/12-AOS1016 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2012, Vol. 40, No. 3, 1609-1636", "doi": "10.1214/12-AOS1016", "report-no": "IMS-AOS-AOS1016", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The analysis of the joint cumulative distribution function (CDF) with\nbivariate event time data is a challenging problem both theoretically and\nnumerically. This paper develops a tensor spline-based sieve maximum likelihood\nestimation method to estimate the joint CDF with bivariate current status data.\nThe I-splines are used to approximate the joint CDF in order to simplify the\nnumerical computation of a constrained maximum likelihood estimation problem.\nThe generalized gradient projection algorithm is used to compute the\nconstrained optimization problem. Based on the properties of B-spline basis\nfunctions it is shown that the proposed tensor spline-based nonparametric sieve\nmaximum likelihood estimator is consistent with a rate of convergence\npotentially better than $n^{1/3}$ under some mild regularity conditions. The\nsimulation studies with moderate sample sizes are carried out to demonstrate\nthat the finite sample performance of the proposed estimator is generally\nsatisfactory.\n", "versions": [{"version": "v1", "created": "Tue, 25 Sep 2012 08:57:34 GMT"}], "update_date": "2012-09-26", "authors_parsed": [["Wu", "Yuan", ""], ["Zhang", "Ying", ""]]}, {"id": "1209.5654", "submitter": "Fran\\c{c}ois Giraud", "authors": "Fran\\c{c}ois Giraud, Pierre Del Moral", "title": "Nonasymptotic analysis of adaptive and annealed Feynman-Kac particle\n  models", "comments": "Published at http://dx.doi.org/10.3150/14-BEJ680 in the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2017, Vol. 23, No. 1, 670-709", "doi": "10.3150/14-BEJ680", "report-no": "IMS-BEJ-BEJ680", "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequential and quantum Monte Carlo methods, as well as genetic type search\nalgorithms can be interpreted as a mean field and interacting particle\napproximations of Feynman-Kac models in distribution spaces. The performance of\nthese population Monte Carlo algorithms is strongly related to the stability\nproperties of nonlinear Feynman-Kac semigroups. In this paper, we analyze these\nmodels in terms of Dobrushin ergodic coefficients of the reference Markov\ntransitions and the oscillations of the potential functions. Sufficient\nconditions for uniform concentration inequalities w.r.t. time are expressed\nexplicitly in terms of these two quantities. We provide an original\nperturbation analysis that applies to annealed and adaptive Feynman-Kac models,\nyielding what seems to be the first results of this kind for these types of\nmodels. Special attention is devoted to the particular case of Boltzmann-Gibbs\nmeasures' sampling. In this context, we design an explicit way of tuning the\nnumber of Markov chain Monte Carlo iterations with temperature schedule. We\nalso design an alternative interacting particle method based on an adaptive\nstrategy to define the temperature increments. The theoretical analysis of the\nperformance of this adaptive model is much more involved as both the potential\nfunctions and the reference Markov transitions now depend on the random\nevolution on the particle model. The nonasymptotic analysis of these complex\nadaptive models is an open research problem. We initiate this study with the\nconcentration analysis of a simplified adaptive models based on reference\nMarkov transitions that coincide with the limiting quantities, as the number of\nparticles tends to infinity.\n", "versions": [{"version": "v1", "created": "Tue, 25 Sep 2012 15:57:04 GMT"}, {"version": "v2", "created": "Fri, 30 Sep 2016 09:59:59 GMT"}], "update_date": "2016-10-03", "authors_parsed": [["Giraud", "Fran\u00e7ois", ""], ["Del Moral", "Pierre", ""]]}, {"id": "1209.5908", "submitter": "Peter B\\\"uhlmann", "authors": "Peter B\\\"uhlmann, Philipp R\\\"utimann, Sara van de Geer and Cun-Hui\n  Zhang", "title": "Correlated variables in regression: clustering and sparse estimation", "comments": "40 pages, 6 figures", "journal-ref": "Journal of Statistical Planning and Inference 2013, Vol. 143,\n  1835-1858", "doi": "10.1016/j.jspi.2013.05.019", "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider estimation in a high-dimensional linear model with strongly\ncorrelated variables. We propose to cluster the variables first and do\nsubsequent sparse estimation such as the Lasso for cluster-representatives or\nthe group Lasso based on the structure from the clusters. Regarding the first\nstep, we present a novel and bottom-up agglomerative clustering algorithm based\non canonical correlations, and we show that it finds an optimal solution and is\nstatistically consistent. We also present some theoretical arguments that\ncanonical correlation based clustering leads to a better-posed compatibility\nconstant for the design matrix which ensures identifiability and an oracle\ninequality for the group Lasso. Furthermore, we discuss circumstances where\ncluster-representatives and using the Lasso as subsequent estimator leads to\nimproved results for prediction and detection of variables. We complement the\ntheoretical analysis with various empirical results.\n", "versions": [{"version": "v1", "created": "Wed, 26 Sep 2012 11:52:44 GMT"}], "update_date": "2015-01-14", "authors_parsed": [["B\u00fchlmann", "Peter", ""], ["R\u00fctimann", "Philipp", ""], ["van de Geer", "Sara", ""], ["Zhang", "Cun-Hui", ""]]}, {"id": "1209.5923", "submitter": "Thierry Dumont", "authors": "Thierry Dumont, Sylvain Le Corff (LTCI)", "title": "Simultaneous Localization and Mapping Problem in Wireless Sensor\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile device localization in wireless sensor networks is a challenging task.\nIt has already been addressed when the WiFI propagation maps of the access\npoints are modeled deterministically. However, this procedure does not take\ninto account the environmental dynamics and also assumes an offline human\ntraining calibration. In this paper, the maps are made of an average indoor\npropagation model combined with a perturbation field which represents the\ninfluence of the environment. This perturbation field is embedded with a prior\ndistribution. The device localization is dealt with using Sequential Monte\nCarlo methods and relies on the estimation of the propagation maps. This\ninference task is performed online, i.e. using the observations sequentially,\nwith a recently proposed online Expectation Maximization based algorithm. The\nperformance of the algorithm are illustrated through Monte Carlo experiments.\n", "versions": [{"version": "v1", "created": "Wed, 26 Sep 2012 13:13:35 GMT"}], "update_date": "2012-09-27", "authors_parsed": [["Dumont", "Thierry", "", "LTCI"], ["Corff", "Sylvain Le", "", "LTCI"]]}, {"id": "1209.6156", "submitter": "Kolyan Ray", "authors": "Kolyan Ray", "title": "Bayesian inverse problems with non-conjugate priors", "comments": "31 pages, minor correction to the proof of Proposition 3.5", "journal-ref": "Electron. J. Statist. Volume 7 (2013), 2516-2549", "doi": "10.1214/13-EJS851", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the frequentist posterior contraction rate of nonparametric\nBayesian procedures in linear inverse problems in both the mildly and severely\nill-posed cases. A theorem is proved in a general Hilbert space setting under\napproximation-theoretic assumptions on the prior. The result is applied to\nnon-conjugate priors, notably sieve and wavelet series priors, as well as in\nthe conjugate setting. In the mildly ill-posed setting minimax optimal rates\nare obtained, with sieve priors being rate adaptive over Sobolev classes. In\nthe severely ill-posed setting, oversmoothing the prior yields minimax rates.\nPreviously established results in the conjugate setting are obtained using this\nmethod. Examples of applications include deconvolution, recovering the initial\ncondition in the heat equation and the Radon transform.\n", "versions": [{"version": "v1", "created": "Thu, 27 Sep 2012 08:20:10 GMT"}, {"version": "v2", "created": "Mon, 1 Jul 2013 17:35:02 GMT"}, {"version": "v3", "created": "Thu, 22 Jan 2015 13:48:26 GMT"}], "update_date": "2015-01-23", "authors_parsed": [["Ray", "Kolyan", ""]]}, {"id": "1209.6267", "submitter": "Yuejie Chi", "authors": "Yuejie Chi, Robert Calderbank", "title": "Coherence-Based Performance Guarantees of Orthogonal Matching Pursuit", "comments": "appeared at 2012 Allerton conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present coherence-based performance guarantees of\nOrthogonal Matching Pursuit (OMP) for both support recovery and signal\nreconstruction of sparse signals when the measurements are corrupted by noise.\nIn particular, two variants of OMP either with known sparsity level or with a\nstopping rule are analyzed. It is shown that if the measurement matrix\n$X\\in\\mathbb{C}^{n\\times p}$ satisfies the strong coherence property, then with\n$n\\gtrsim\\mathcal{O}(k\\log p)$, OMP will recover a $k$-sparse signal with high\nprobability. In particular, the performance guarantees obtained here separate\nthe properties required of the measurement matrix from the properties required\nof the signal, which depends critically on the minimum signal to noise ratio\nrather than the power profiles of the signal. We also provide performance\nguarantees for partial support recovery. Comparisons are given with other\nperformance guarantees for OMP using worst-case analysis and the sorted one\nstep thresholding algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 27 Sep 2012 16:11:19 GMT"}], "update_date": "2012-09-28", "authors_parsed": [["Chi", "Yuejie", ""], ["Calderbank", "Robert", ""]]}, {"id": "1209.6473", "submitter": "Irene Crimaldi", "authors": "Patrizia Berti, Irene Crimaldi, Luca Pratelli, Pietro Rigo", "title": "An Anscombe-type theorem", "comments": "10 pages, preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let (X_n) be a sequence of random variables (with values in a separable\nmetric space) and (N_n) a sequence of random indices. Conditions for X_{N_n} to\nconverge stably (in particular, in distribution) are provided. Some examples,\nwhere such conditions work but those already existing fail, are given as well.\n  Key words and phrases: Anscombe theorem, Exchangeability, Random indices,\nRandom sums, Stable convergence\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2012 10:20:30 GMT"}], "update_date": "2012-10-01", "authors_parsed": [["Berti", "Patrizia", ""], ["Crimaldi", "Irene", ""], ["Pratelli", "Luca", ""], ["Rigo", "Pietro", ""]]}, {"id": "1209.6503", "submitter": "Herv\\'e Cardot", "authors": "Herv\\'e Cardot and Camelia Goga and Pauline Lardin", "title": "Variance estimation and asymptotic confidence bands for the mean\n  estimator of sampled functional data with high entropy unequal probability\n  sampling designs", "comments": "Revised for the Scandinavian Journal of Statistics", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For fixed size sampling designs with high entropy it is well known that the\nvariance of the Horvitz-Thompson estimator can be approximated by the H\\'ajek\nformula. The interest of this asymptotic variance approximation is that it only\ninvolves the first order inclusion probabilities of the statistical units. We\nextend this variance formula when the variable under study is functional and we\nprove, under general conditions on the regularity of the individual\ntrajectories and the sampling design, that we can get a uniformly convergent\nestimator of the variance function of the Horvitz-Thompson estimator of the\nmean function. Rates of convergence to the true variance function are given for\nthe rejective sampling. We deduce, under conditions on the entropy of the\nsampling design, that it is possible to build confidence bands whose coverage\nis asymptotically the desired one via simulation of Gaussian processes with\nvariance function given by the H\\'ajek formula. Finally, the accuracy of the\nproposed variance estimator is evaluated on samples of electricity consumption\ndata measured every half an hour over a period of one week.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2012 12:43:49 GMT"}, {"version": "v2", "created": "Sat, 13 Oct 2012 11:52:45 GMT"}, {"version": "v3", "created": "Fri, 28 Jun 2013 15:55:53 GMT"}], "update_date": "2013-07-01", "authors_parsed": [["Cardot", "Herv\u00e9", ""], ["Goga", "Camelia", ""], ["Lardin", "Pauline", ""]]}, {"id": "1209.6534", "submitter": "Xavier Gendre", "authors": "Xavier Gendre (IMT)", "title": "Model selection and estimation of a component in additive regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $Y\\in\\R^n$ be a random vector with mean $s$ and covariance matrix\n$\\sigma^2P_n\\tra{P_n}$ where $P_n$ is some known $n\\times n$-matrix. We\nconstruct a statistical procedure to estimate $s$ as well as under moment\ncondition on $Y$ or Gaussian hypothesis. Both cases are developed for known or\nunknown $\\sigma^2$. Our approach is free from any prior assumption on $s$ and\nis based on non-asymptotic model selection methods. Given some linear spaces\ncollection $\\{S_m,\\ m\\in\\M\\}$, we consider, for any $m\\in\\M$, the least-squares\nestimator $\\hat{s}_m$ of $s$ in $S_m$. Considering a penalty function that is\nnot linear in the dimensions of the $S_m$'s, we select some $\\hat{m}\\in\\M$ in\norder to get an estimator $\\hat{s}_{\\hat{m}}$ with a quadratic risk as close as\npossible to the minimal one among the risks of the $\\hat{s}_m$'s.\nNon-asymptotic oracle-type inequalities and minimax convergence rates are\nproved for $\\hat{s}_{\\hat{m}}$. A special attention is given to the estimation\nof a non-parametric component in additive models. Finally, we carry out a\nsimulation study in order to illustrate the performances of our estimators in\npractice.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2012 14:31:42 GMT"}], "update_date": "2012-10-01", "authors_parsed": [["Gendre", "Xavier", "", "IMT"]]}]