[{"id": "1606.00092", "submitter": "Tatsushi Oka", "authors": "Tatsushi Oka and Pierre Perron", "title": "Testing for Common Breaks in a Multiple Equations System", "comments": "44 pages, 2 tables and 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST econ.EM q-fin.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The issue addressed in this paper is that of testing for common breaks across\nor within equations of a multivariate system. Our framework is very general and\nallows integrated regressors and trends as well as stationary regressors. The\nnull hypothesis is that breaks in different parameters occur at common\nlocations and are separated by some positive fraction of the sample size unless\nthey occur across different equations. Under the alternative hypothesis, the\nbreak dates across parameters are not the same and also need not be separated\nby a positive fraction of the sample size whether within or across equations.\nThe test considered is the quasi-likelihood ratio test assuming normal errors,\nthough as usual the limit distribution of the test remains valid with\nnon-normal errors. Of independent interest, we provide results about the rate\nof convergence of the estimates when searching over all possible partitions\nsubject only to the requirement that each regime contains at least as many\nobservations as some positive fraction of the sample size, allowing break dates\nnot separated by a positive fraction of the sample size across equations.\nSimulations show that the test has good finite sample properties. We also\nprovide an application to issues related to level shifts and persistence for\nvarious measures of inflation to illustrate its usefulness.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jun 2016 01:55:19 GMT"}, {"version": "v2", "created": "Thu, 11 Jan 2018 01:35:15 GMT"}], "update_date": "2018-01-12", "authors_parsed": [["Oka", "Tatsushi", ""], ["Perron", "Pierre", ""]]}, {"id": "1606.00187", "submitter": "Ilaria Giulini", "authors": "Ilaria Giulini", "title": "Robust Principal Component Analysis in Hilbert spaces", "comments": "arXiv admin note: substantial text overlap with arXiv:1511.06263", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a stable version of Principal Component Analysis (PCA) in the\ngeneral framework of a separable Hilbert space. It consists in interpreting the\nprojection on the first eigenvectors as a step function applied to the spectrum\nof the covariance operator and in replacing it with a smooth cut-off of the\neigenvalues. We study the problem from a statistical point of view, so that we\nassume that we do not have direct access to the covariance operator but we have\nto estimate it from an i.i.d. sample. We provide some results on the quality of\nthe approximation of our spectral cut-off in terms of the quality of the\napproximation of the eigenvalues of the covariance operator.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jun 2016 09:24:23 GMT"}, {"version": "v2", "created": "Fri, 31 Mar 2017 07:15:20 GMT"}], "update_date": "2017-04-03", "authors_parsed": [["Giulini", "Ilaria", ""]]}, {"id": "1606.00235", "submitter": "Didier Fraix-Burnet", "authors": "Didier Fraix-Burnet (IPAG)", "title": "Clustering with phylogenetic tools in astrophysics", "comments": "Proceedings of the 60th World Statistics Congress of the\n  International Statistical Institute, ISI2015, Jul 2015, Rio de Janeiro,\n  Brazil", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.IM math.ST q-bio.QM stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Phylogenetic approaches are finding more and more applications outside the\nfield of biology. Astrophysics is no exception since an overwhelming amount of\nmultivariate data has appeared in the last twenty years or so. In particular,\nthe diversification of galaxies throughout the evolution of the Universe quite\nnaturally invokes phylogenetic approaches. We have demonstrated that Maximum\nParsimony brings useful astrophysical results, and we now proceed toward the\nanalyses of large datasets for galaxies. In this talk I present how we solve\nthe major difficulties for this goal: the choice of the parameters, their\ndiscretization, and the analysis of a high number of objects with an\nunsupervised NP-hard classification technique like cladistics. 1. Introduction\nHow do the galaxy form, and when? How did the galaxy evolve and transform\nthemselves to create the diversity we observe? What are the progenitors to\npresent-day galaxies? To answer these big questions, observations throughout\nthe Universe and the physical modelisation are obvious tools. But between\nthese, there is a key process, without which it would be impossible to extract\nsome digestible information from the complexity of these systems. This is\nclassification. One century ago, galaxies were discovered by Hubble. From\nimages obtained in the visible range of wavelengths, he synthetised his\nobservations through the usual process: classification. With only one parameter\n(the shape) that is qualitative and determined with the eye, he found four\ncategories: ellipticals, spirals, barred spirals and irregulars. This is the\nfamous Hubble classification. He later hypothetized relationships between these\nclasses, building the Hubble Tuning Fork. The Hubble classification has been\nrefined, notably by de Vaucouleurs, and is still used as the only global\nclassification of galaxies. Even though the physical relationships proposed by\nHubble are not retained any more, the Hubble Tuning Fork is nearly always used\nto represent the classification of the galaxy diversity under its new name the\nHubble sequence (e.g. Delgado-Serrano, 2012). Its success is impressive and can\nbe understood by its simplicity, even its beauty, and by the many correlations\nfound between the morphology of galaxies and their other properties. And one\nmust admit that there is no alternative up to now, even though both the Hubble\nclassification and diagram have been recognised to be unsatisfactory. Among the\nmost obvious flaws of this classification, one must mention its monovariate,\nqualitative, subjective and old-fashioned nature, as well as the difficulty to\ncharacterise the morphology of distant galaxies. The first two most significant\nmultivariate studies were by Watanabe et al. (1985) and Whitmore (1984). Since\nthe year 2005, the number of studies attempting to go beyond the Hubble\nclassification has increased largely. Why, despite of this, the Hubble\nclassification and its sequence are still alive and no alternative have yet\nemerged (Sandage, 2005)? My feeling is that the results of the multivariate\nanalyses are not easily integrated into a one-century old practice of modeling\nthe observations. In addition, extragalactic objects like galaxies, stellar\nclusters or stars do evolve. Astronomy now provides data on very distant\nobjects, raising the question of the relationships between those and our\npresent day nearby galaxies. Clearly, this is a phylogenetic problem.\nAstrocladistics 1 aims at exploring the use of phylogenetic tools in\nastrophysics (Fraix-Burnet et al., 2006a,b). We have proved that Maximum\nParsimony (or cladistics) can be applied in astrophysics and provides a new\nexploration tool of the data (Fraix-Burnet et al., 2009, 2012, Cardone \\&\nFraix-Burnet, 2013). As far as the classification of galaxies is concerned, a\nlarger number of objects must now be analysed. In this paper, I\n", "versions": [{"version": "v1", "created": "Wed, 1 Jun 2016 11:34:24 GMT"}], "update_date": "2016-06-02", "authors_parsed": [["Fraix-Burnet", "Didier", "", "IPAG"]]}, {"id": "1606.00250", "submitter": "Sherzod Mirakhmedov", "authors": "Sherzod Mirakhmedov", "title": "The Probabilities of Large Deviations for the Chi-square and\n  Log-likelihood Ratio Statistics", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new large deviation results for the Pearson chi-square and Log-likelihood\nratio statistics are obtained. Here attention is focused on the case when the\nnumber of groups increases to infinity and the probabilities of groups\ndecreases to zero, as the sample size tends to infinity.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jun 2016 12:18:16 GMT"}], "update_date": "2016-06-02", "authors_parsed": [["Mirakhmedov", "Sherzod", ""]]}, {"id": "1606.00263", "submitter": "L\\'aszl\\'o Varga", "authors": "L\\'aszl\\'o Varga and Andr\\'as Zempl\\'eni", "title": "Generalised block bootstrap and its use in meteorology", "comments": "18 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In an earlier paper Rakonczai et al. (2014), we have emphasized the effective\nsample size for autocorrelated data. The simulations were based on the block\nbootstrap methodology. However, the discreteness of the usual block size did\nnot allow for exact calculations. In this paper we propose a generalisation of\nthe block bootstrap methodology, relate it to the existing optimisation\nprocedures and apply it to a temperature data set. Our other focus is on\nstatistical tests, where quite often the actual sample size plays an important\nrole, even in case of relatively large samples. This is especially the case for\ncopulas. These are used for investigating the dependencies among data sets. As\nin quite a few real applications the time dependence cannot be neglected, we\ninvestigated the effect of this phenomenon to the used test statistic. The\ncritical values can be computed by the proposed new block bootstrap simulation,\nwhere the block sizes are determined e.g. by fitting a VAR model to the\nobservations. The results are illustrated for models of the used temperature\ndata.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jun 2016 12:48:43 GMT"}], "update_date": "2016-06-02", "authors_parsed": [["Varga", "L\u00e1szl\u00f3", ""], ["Zempl\u00e9ni", "Andr\u00e1s", ""]]}, {"id": "1606.00304", "submitter": "Richard Samworth", "authors": "Thomas B. Berrett, Richard J. Samworth and Ming Yuan", "title": "Efficient multivariate entropy estimation via $k$-nearest neighbour\n  distances", "comments": "69 pages, 0 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many statistical procedures, including goodness-of-fit tests and methods for\nindependent component analysis, rely critically on the estimation of the\nentropy of a distribution. In this paper, we seek entropy estimators that are\nefficient and achieve the local asymptotic minimax lower bound with respect to\nsquared error loss. To this end, we study weighted averages of the estimators\noriginally proposed by Kozachenko and Leonenko (1987), based on the $k$-nearest\nneighbour distances of a sample of $n$ independent and identically distributed\nrandom vectors in $\\mathbb{R}^d$. A careful choice of weights enables us to\nobtain an efficient estimator in arbitrary dimensions, given sufficient\nsmoothness, while the original unweighted estimator is typically only efficient\nwhen $d \\leq 3$. In addition to the new estimator proposed and theoretical\nunderstanding provided, our results facilitate the construction of\nasymptotically valid confidence intervals for the entropy of asymptotically\nminimal width.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jun 2016 14:32:47 GMT"}, {"version": "v2", "created": "Thu, 14 Jul 2016 14:59:54 GMT"}, {"version": "v3", "created": "Thu, 22 Jun 2017 15:53:10 GMT"}], "update_date": "2017-06-23", "authors_parsed": [["Berrett", "Thomas B.", ""], ["Samworth", "Richard J.", ""], ["Yuan", "Ming", ""]]}, {"id": "1606.00451", "submitter": "Jacob Bien", "authors": "Jacob Bien", "title": "Graph-Guided Banding of the Covariance Matrix", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.CO stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regularization has become a primary tool for developing reliable estimators\nof the covariance matrix in high-dimensional settings. To curb the curse of\ndimensionality, numerous methods assume that the population covariance (or\ninverse covariance) matrix is sparse, while making no particular structural\nassumptions on the desired pattern of sparsity. A highly-related, yet\ncomplementary, literature studies the specific setting in which the measured\nvariables have a known ordering, in which case a banded population matrix is\noften assumed. While the banded approach is conceptually and computationally\neasier than asking for \"patternless sparsity,\" it is only applicable in very\nspecific situations (such as when data are measured over time or\none-dimensional space). This work proposes a generalization of the notion of\nbandedness that greatly expands the range of problems in which banded\nestimators apply.\n  We develop convex regularizers occupying the broad middle ground between the\nformer approach of \"patternless sparsity\" and the latter reliance on having a\nknown ordering. Our framework defines bandedness with respect to a known graph\non the measured variables. Such a graph is available in diverse situations, and\nwe provide a theoretical, computational, and applied treatment of two new\nestimators. An R package, called ggb, implements these new methods.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jun 2016 20:01:02 GMT"}, {"version": "v2", "created": "Thu, 15 Feb 2018 20:27:43 GMT"}], "update_date": "2018-02-19", "authors_parsed": [["Bien", "Jacob", ""]]}, {"id": "1606.00614", "submitter": "Remi Servien", "authors": "Victor Picheny (MIAT INRA), R\\'emi Servien (ToxAlim), Nathalie\n  Villa-Vialaneix (MIAT INRA)", "title": "Interpretable sparse SIR for functional data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work focuses on the issue of variable selection in functional\nregression. Unlike most work in this framework, our approach does not select\nisolated points in the definition domain of the predictors, nor does it rely on\nthe expansion of the predictors in a given functional basis. It provides an\napproach to select full intervals made of consecutive points. This feature\nimproves the interpretability of the estimated coefficients and is desirable in\nthe functional framework for which small shifts are frequent when comparing one\npredictor (curve) to another. Our method is described in a semiparametric\nframework based on Sliced Inverse Regression (SIR). SIR is an effective method\nfor dimension reduction of high-dimensional data which computes a linear\nprojection of the predictors in a low-dimensional space, without loss on\nregression information. We extend the approaches of variable selection\ndeveloped for multidimensional SIR to select intervals rather than separated\nevaluation points in the definition domain of the functional predictors.\nDifferent and equivalent formulations of SIR are combined in a shrinkage\napproach with a group-LASSO-like penalty. Finally, a fully automated iterative\nprocedure is also proposed to find the critical (interpretable) intervals. The\napproach is proved efficient on simulated and real data.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jun 2016 10:44:42 GMT"}, {"version": "v2", "created": "Mon, 6 Jun 2016 06:35:51 GMT"}, {"version": "v3", "created": "Mon, 19 Dec 2016 10:25:48 GMT"}, {"version": "v4", "created": "Fri, 2 Mar 2018 10:22:15 GMT"}], "update_date": "2018-03-05", "authors_parsed": [["Picheny", "Victor", "", "MIAT INRA"], ["Servien", "R\u00e9mi", "", "ToxAlim"], ["Villa-Vialaneix", "Nathalie", "", "MIAT INRA"]]}, {"id": "1606.00622", "submitter": "Luc Leh\\'ericy", "authors": "Luc Leh\\'ericy (LMO)", "title": "Consistent order estimation for nonparametric Hidden Markov Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of estimating the number of hidden states (the order)\nof a nonparametric hidden Markov model (HMM). We propose two different methods\nand prove their almost sure consistency without any prior assumption, be it on\nthe order or on the emission distributions. This is the first time a\nconsistency result is proved in such a general setting without using\nrestrictive assumptions such as a priori upper bounds on the order or\nparametric restrictions on the emission distributions. Our main method relies\non the minimization of a penalized least squares criterion. In addition to the\nconsistency of the order estimation, we also prove that this method yields rate\nminimax adaptive estimators of the parameters of the HMM - up to a logarithmic\nfactor. Our second method relies on estimating the rank of a matrix obtained\nfrom the distribution of two consecutive observations. Finally, numerical\nexperiments are used to compare both methods and study their ability to select\nthe right order in several situations.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jun 2016 11:09:46 GMT"}, {"version": "v2", "created": "Tue, 13 Sep 2016 13:21:46 GMT"}, {"version": "v3", "created": "Mon, 21 Nov 2016 15:37:43 GMT"}, {"version": "v4", "created": "Thu, 6 Apr 2017 14:41:05 GMT"}, {"version": "v5", "created": "Thu, 18 May 2017 15:58:03 GMT"}], "update_date": "2017-05-19", "authors_parsed": [["Leh\u00e9ricy", "Luc", "", "LMO"]]}, {"id": "1606.00922", "submitter": "Nikita Zhivotovskiy", "authors": "Nikita Zhivotovskiy and Steve Hanneke", "title": "Localization of VC Classes: Beyond Local Rademacher Complexities", "comments": "28 pages, accepted version", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce an alternative localization approach for binary\nclassification that leads to a novel complexity measure: fixed points of the\nlocal empirical entropy. We show that this complexity measure gives a tight\ncontrol over complexity in the upper bounds. Our results are accompanied by a\nnovel minimax lower bound that involves the same quantity. In particular, we\npractically answer the question of optimality of ERM under bounded noise for\ngeneral VC classes.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jun 2016 22:16:20 GMT"}, {"version": "v2", "created": "Mon, 1 Aug 2016 09:32:40 GMT"}, {"version": "v3", "created": "Sun, 17 Dec 2017 21:39:27 GMT"}], "update_date": "2017-12-19", "authors_parsed": [["Zhivotovskiy", "Nikita", ""], ["Hanneke", "Steve", ""]]}, {"id": "1606.00976", "submitter": "William Dunsmuir", "authors": "W. T. M. Dunsmuir and J. Y. He", "title": "Marginal Estimation of Parameter Driven Binomial Time Series Models", "comments": "23 pages, 2 tables, submitted for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper develops asymptotic theory for estimation of parameters in\nregression models for binomial response time series where serial dependence is\npresent through a latent process. Use of generalized linear model (GLM)\nestimating equations leads to asymptotically biased estimates of regression\ncoefficients for binomial responses. An alternative is to use marginal\nlikelihood, in which the variance of the latent process but not the serial\ndependence is accounted for. In practice this is equivalent to using\ngeneralized linear mixed model estimation procedures treating the observations\nas independent with a random effect on the intercept term in the regression\nmodel. We prove this method leads to consistent and asymptotically normal\nestimates even if there is an autocorrelated latent process. Simulations\nsuggest that the use of marginal likelihood can lead to GLM estimates result.\nThis problem reduces rapidly with increasing number of binomial trials at each\ntime point but, for binary data, the chance of it can remain over 45% even in\nvery long time series. We provide a combination of theoretical and heuristic\nexplanations for this phenomenon in terms of the properties of the regression\ncomponent of the model and these can be used to guide application of the method\nin practice.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jun 2016 06:27:34 GMT"}], "update_date": "2016-06-06", "authors_parsed": [["Dunsmuir", "W. T. M.", ""], ["He", "J. Y.", ""]]}, {"id": "1606.00983", "submitter": "William Dunsmuir", "authors": "W. T. M. Dunsmuir and J. Y. He", "title": "Testing for Serial Dependence in Binomial Time Series I: Parameter\n  Driven Models", "comments": "12 page, 3 table, submitted for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Binomial time series in which the logit of the probability of success is\nmodelled as a linear function of observed regressors and a stationary latent\nGaussian process are considered. Score tests are developed to first test for\nthe existence of a latent process and, subsequent to that, evidence of serial\ndependence in that latent process. The test for the existence of a latent\nprocess is important because, if one is present, standard logistic regression\nmethods will produce inconsistent estimates of the regression parameters.\nHowever the score test is non-standard and any serial dependence in the latent\nprocess will require consideration of nuisance parameters which cannot be\nestimated under the null hypothesis of no latent process. The paper describes\nhow a supremum-type test can be applied. If a latent process is detected,\nconsistent estimation of its variance and the regression parameters can be done\nusing marginal estimation which is easily implemented using generalised linear\nmixed model methods. The test for serial dependence in a latent process does\nnot involve nuisance parameters and is based on the covariances between\nresiduals centered at functions of the latent process conditional on the\nobservations. This requires numerical integration in order to compute the test\nstatistic. Relevant asymptotic results are derived and confirmed using\nsimulation evidence. Application to binary and binomial time series is made.\nFor binary series in particular, a complication is that the variance of the\nlatent process, even if present, can be estimated to be zero with a high\nprobability.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jun 2016 07:02:09 GMT"}], "update_date": "2016-06-06", "authors_parsed": [["Dunsmuir", "W. T. M.", ""], ["He", "J. Y.", ""]]}, {"id": "1606.00984", "submitter": "William Dunsmuir", "authors": "W. T. M. Dunsmuir and J. Y. He", "title": "Detecting Serial Dependence in Binomial Time Series II: Observation\n  Driven Models", "comments": "15 pages, 5 tables, submitted for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The detection of serial dependence in binary or binomial valued time series\nis difficult using standard time series methods, particularly when there are\nregression effects to be modelled. In this paper we derive score-type tests for\ndetecting departures from independence in the directions of the GLARMA\\ and\nBARMA\\ type observation driven models. These score tests can easily be applied\nusing a standard logistic regression and so may have appeal to practitioners\nwho wish to initially assess the need to incorporate serial dependence effects.\nTo deal with the nuisance parameters in some GLARMA models a supremum type test\nis implemented.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jun 2016 07:03:18 GMT"}], "update_date": "2016-06-06", "authors_parsed": [["Dunsmuir", "W. T. M.", ""], ["He", "J. Y.", ""]]}, {"id": "1606.01004", "submitter": "Elvira Di Nardo Prof.", "authors": "E. Di Nardo", "title": "On multivariable cumulant polynomial sequences with applications", "comments": "17 pages, In press", "journal-ref": "Journal of Algebraic Statistics (2016)", "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new family of polynomials, called cumulant polynomial sequence, and its\nextensions to the multivariate case is introduced relied on a purely symbolic\ncombinatorial method. The coefficients of these polynomials are cumulants, but\ndepending on what is plugged in the indeterminates, either sequences of moments\neither sequences of cumulants can be recovered. The main tool is a formal\ngeneralization of random sums, also with a multivariate random index and not\nnecessarily integer-valued. Applications are given within parameter\nestimations, L\\'evy processes and random matrices and, more generally, problems\ninvolving multivariate functions. The connection between exponential models and\nmultivariable Sheffer polynomial sequences offers a different viewpoint in\ncharacterizing these models. Some open problems end the paper.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jun 2016 08:35:06 GMT"}], "update_date": "2016-06-06", "authors_parsed": [["Di Nardo", "E.", ""]]}, {"id": "1606.01025", "submitter": "Elsa Cazelles", "authors": "J\\'er\\'emie Bigot, Elsa Cazelles and Nicolas Papadakis", "title": "Penalized Barycenters in the Wasserstein Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a regularization of Wasserstein barycenters for random\nmeasures supported on $\\mathbb{R}^{d}$ is introduced via convex penalization.\nThe existence and uniqueness of such barycenters is first proved for a large\nclass of penalization functions. The Bregman divergence associated to the\npenalization term is then considered to obtain a stability result on penalized\nbarycenters. This allows the comparison of data made of $n$ absolutely\ncontinuous probability measures, within the more realistic setting where one\nonly has access to a dataset of random variables sampled from unknown\ndistributions. The convergence of the penalized empirical barycenter of a set\nof $n$ iid random probability measures towards its population counterpart is\nfinally analyzed. This approach is shown to be appropriate for the statistical\nanalysis of either discrete or absolutely continuous random measures. It also\nallows to construct, from a set of discrete measures, consistent estimators of\npopulation Wasserstein barycenters that are absolutely continuous.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jun 2016 09:59:07 GMT"}, {"version": "v2", "created": "Tue, 4 Jul 2017 19:18:35 GMT"}, {"version": "v3", "created": "Wed, 25 Apr 2018 07:14:28 GMT"}, {"version": "v4", "created": "Mon, 29 Oct 2018 15:37:58 GMT"}, {"version": "v5", "created": "Mon, 18 Mar 2019 19:21:56 GMT"}], "update_date": "2019-03-20", "authors_parsed": [["Bigot", "J\u00e9r\u00e9mie", ""], ["Cazelles", "Elsa", ""], ["Papadakis", "Nicolas", ""]]}, {"id": "1606.01117", "submitter": "Celine Duval", "authors": "C\\'eline Duval (MAP5), Johanna Kappus", "title": "Nonparametric adaptive estimation for grouped data", "comments": null, "journal-ref": null, "doi": null, "report-no": "MAP5 2015-38", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of this paper is to estimate the density f of a random variable X\nwhen one has access to independent observations of the sum of K $\\ge$ 2\nindependent copies of X. We provide a constructive estimator based on a\nsuitable definition of the logarithm of the empirical characteristic\nfunction.We propose a new strategy for the data driven choice of the cut-off\nparameter. The adaptive estimator is proven to be minimax-optimal up to some\nlogarithmic loss. A numerical study illustrates the performances of the method.\nMoreover, we discuss the fact that the definition of the estimator applies in a\nwider context than the one considered here.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jun 2016 14:47:22 GMT"}], "update_date": "2016-06-06", "authors_parsed": [["Duval", "C\u00e9line", "", "MAP5"], ["Kappus", "Johanna", ""]]}, {"id": "1606.01200", "submitter": "Michal Koles\\'ar", "authors": "Timothy B. Armstrong and Michal Koles\\'ar", "title": "Simple and Honest Confidence Intervals in Nonparametric Regression", "comments": "46 pages, plus a 54-page supplemental appendix", "journal-ref": "Quantitative Economics, Volume 11, Issue 1, January 2020, pages\n  1-39", "doi": "10.3982/QE1199", "report-no": null, "categories": "stat.AP math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of constructing honest confidence intervals (CIs) for\na scalar parameter of interest, such as the regression discontinuity parameter,\nin nonparametric regression based on kernel or local polynomial estimators. To\nensure that our CIs are honest, we use critical values that take into account\nthe possible bias of the estimator upon which the CIs are based. We show that\nthis approach leads to CIs that are more efficient than conventional CIs that\nachieve coverage by undersmoothing or subtracting an estimate of the bias. We\ngive sharp efficiency bounds of using different kernels, and derive the optimal\nbandwidth for constructing honest CIs. We show that using the bandwidth that\nminimizes the maximum mean-squared error results in CIs that are nearly\nefficient and that in this case, the critical value depends only on the rate of\nconvergence. For the common case in which the rate of convergence is\n$n^{-2/5}$, the appropriate critical value for 95% CIs is 2.18, rather than the\nusual 1.96 critical value. We illustrate our results in a Monte Carlo analysis\nand an empirical application.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jun 2016 17:47:30 GMT"}, {"version": "v2", "created": "Wed, 5 Oct 2016 20:00:05 GMT"}, {"version": "v3", "created": "Mon, 19 Mar 2018 00:51:02 GMT"}, {"version": "v4", "created": "Wed, 29 Aug 2018 22:05:31 GMT"}, {"version": "v5", "created": "Thu, 6 Jun 2019 16:27:20 GMT"}, {"version": "v6", "created": "Wed, 28 Aug 2019 21:15:21 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Armstrong", "Timothy B.", ""], ["Koles\u00e1r", "Michal", ""]]}, {"id": "1606.01382", "submitter": "Richard Kleeman", "authors": "Gordon V. Chavez, Richard Kleeman", "title": "Near-Gaussian entropic functional calculation and density estimation\n  using an asymptotic series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math-ph math.MP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Near-Gaussian probability densities are common in many important physical\napplications. Here we develop an asymptotic expansion methodology for computing\nentropic functionals for such densities. The expansion proposed is a close\nrelative of standard perturbation expansions in quantum field theory. We give\nnovel results on the low-order effects of non-Gaussian even moments and\nasymmetry (e.g. skewness) on the entropy. The asymptotic expansion is also used\nto define a best fit maximum entropy density given a set of observed low order\nmoments. The maximum entropy density estimation technique consists simply of\nthe solution of a small set of algebraic equations and is therefore more\nstraightforward numerically than classical maximum-entropy methods which rely\non sophisticated convex optimization techniques.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jun 2016 14:52:41 GMT"}, {"version": "v2", "created": "Tue, 7 Jun 2016 01:45:41 GMT"}], "update_date": "2016-06-29", "authors_parsed": [["Chavez", "Gordon V.", ""], ["Kleeman", "Richard", ""]]}, {"id": "1606.01484", "submitter": "Hideyuki Miyahara", "authors": "Hideyuki Miyahara and Koji Tsumura", "title": "Relaxation of the EM Algorithm via Quantum Annealing", "comments": "6 pages, accepted to ACC 2016, minor revisions after the final\n  submission to ACC 2016", "journal-ref": null, "doi": "10.1109/ACC.2016.7526110", "report-no": null, "categories": "stat.ML cond-mat.stat-mech math.ST physics.comp-ph quant-ph stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The EM algorithm is a novel numerical method to obtain maximum likelihood\nestimates and is often used for practical calculations. However, many of\nmaximum likelihood estimation problems are nonconvex, and it is known that the\nEM algorithm fails to give the optimal estimate by being trapped by local\noptima. In order to deal with this difficulty, we propose a deterministic\nquantum annealing EM algorithm by introducing the mathematical mechanism of\nquantum fluctuations into the conventional EM algorithm because quantum\nfluctuations induce the tunnel effect and are expected to relax the difficulty\nof nonconvex optimization problems in the maximum likelihood estimation\nproblems. We show a theorem that guarantees its convergence and give numerical\nexperiments to verify its efficiency.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jun 2016 09:47:18 GMT"}], "update_date": "2016-08-16", "authors_parsed": [["Miyahara", "Hideyuki", ""], ["Tsumura", "Koji", ""]]}, {"id": "1606.01511", "submitter": "Mikhail Moklyachuk", "authors": "Iryna Golichenko, Oleksandr Masyutka, Mikhail Moklyachuk", "title": "Filtering of Continuous Time Periodically Correlated Isotropic Random\n  Fields", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of optimal linear estimation of functionals depending on the\nunknown values of a random field $\\zeta(t,x)$, which is mean-square continuous\nperiodically correlated with respect to time argument $t\\in\\mathbb R$ and\nisotropic on the unit sphere ${S_n}$ with respect to spatial argument\n$x\\in{S_n}$. Estimates are based on observations of the field\n$\\zeta(t,x)+\\theta(t,x)$ at points $(t,x):t\\leq 0,x\\in S_{n}$, where\n$\\theta(t,x)$ is an uncorrelated with $\\zeta(t,x)$ random field, which is\nmean-square continuous periodically correlated with respect to time argument\n$t\\in\\mathbb R$ and isotropic on the sphere ${S_n}$ with respect to spatial\nargument $x\\in{S_n}$. Formulas for calculating the mean square errors and the\nspectral characteristics of the optimal linear estimate of functionals are\nderived in the case of spectral certainty where the spectral densities of the\nfields are exactly known. Formulas that determine the least favourable spectral\ndensities and the minimax (robust) spectral characteristics are proposed in the\ncase where the spectral densities are not exactly known while a class of\nadmissible spectral densities is given.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jun 2016 14:00:22 GMT"}], "update_date": "2016-06-07", "authors_parsed": [["Golichenko", "Iryna", ""], ["Masyutka", "Oleksandr", ""], ["Moklyachuk", "Mikhail", ""]]}, {"id": "1606.01554", "submitter": "Shashank Singh", "authors": "Shashank Singh, Barnab\\'as P\\'oczos", "title": "Finite-Sample Analysis of Fixed-k Nearest Neighbor Density Functional\n  Estimators", "comments": "16 pages, 0 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT math.IT stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide finite-sample analysis of a general framework for using k-nearest\nneighbor statistics to estimate functionals of a nonparametric continuous\nprobability density, including entropies and divergences. Rather than plugging\na consistent density estimate (which requires $k \\to \\infty$ as the sample size\n$n \\to \\infty$) into the functional of interest, the estimators we consider fix\nk and perform a bias correction. This is more efficient computationally, and,\nas we show in certain cases, statistically, leading to faster convergence\nrates. Our framework unifies several previous estimators, for most of which\nours are the first finite sample guarantees.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jun 2016 20:17:29 GMT"}], "update_date": "2016-08-23", "authors_parsed": [["Singh", "Shashank", ""], ["P\u00f3czos", "Barnab\u00e1s", ""]]}, {"id": "1606.01627", "submitter": "Shoichi Eguchi", "authors": "Shoichi Eguchi and Hiroki Masuda", "title": "Schwarz type model comparison for LAQ models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For model-specification purpose, we study asymptotic behavior of the marginal\nquasi-log likelihood associated with a family of locally asymptotically\nquadratic (LAQ) statistical experiments. Our result entails a far-reaching\nextension of applicable scope of the classical approximate Bayesian model\ncomparison due to Schwarz, with frequentist-view theoretical foundation. In\nparticular, the proposed statistics can deal with both ergodic and non-ergodic\nstochastic-process models, where the corresponding $M$-estimator is of\nmulti-scaling type and the asymptotic quasi-information matrix is random.\nFocusing on the ergodic diffusion model, we also deduce the consistency of the\nmultistage optimal-model selection where we may select an optimal sub-model\nstructure step by step, so that computational cost can be much reduced. We\nillustrate the proposed method by the Gaussian quasi-likelihood for\ndiffusion-type models in details, together with several numerical experiments.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jun 2016 06:24:54 GMT"}, {"version": "v2", "created": "Fri, 23 Sep 2016 04:38:23 GMT"}], "update_date": "2016-09-26", "authors_parsed": [["Eguchi", "Shoichi", ""], ["Masuda", "Hiroki", ""]]}, {"id": "1606.01633", "submitter": "Ross A. Maller", "authors": "Ross A. Maller", "title": "Conditions for a L\\'evy process to stay positive near 0, in probability", "comments": "Published at http://dx.doi.org/10.3150/15-BEJ716 in the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2016, Vol. 22, No. 4, 1963-1978", "doi": "10.3150/15-BEJ716", "report-no": "IMS-BEJ-BEJ716", "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A necessary and sufficient condition for a L\\'evy process $X$ to stay\npositive, in probability, near 0, which arises in studies of Chung-type laws\nfor $X$ near 0, is given in terms of the characteristics of $X$.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jun 2016 06:54:16 GMT"}], "update_date": "2016-06-07", "authors_parsed": [["Maller", "Ross A.", ""]]}, {"id": "1606.01782", "submitter": "Daniel Naiman", "authors": "Daniel Q. Naiman and Fred Torcaso", "title": "To replace or not to replace in finite population sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the classical result in finite population sampling which states\nthat in equally-likely \"simple\" random sampling the sample mean is more\nreliable when we do not replace after each draw. In this paper we investigate\nif and when the same is true for samples where it may no longer be true that\neach member of the population has an equal chance of being selected. For a\ncertain class of sampling schemes, we are able to obtain convenient expressions\nfor the variance of the sample mean and surprisingly, we find that for some\nselection distributions a more reliable estimate of the population mean will\nhappen by replacing after each draw. We show for selection distributions lying\nin a certain polytope the classical result prevails.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jun 2016 15:16:02 GMT"}, {"version": "v2", "created": "Wed, 19 Oct 2016 19:29:05 GMT"}], "update_date": "2016-10-20", "authors_parsed": [["Naiman", "Daniel Q.", ""], ["Torcaso", "Fred", ""]]}, {"id": "1606.01800", "submitter": "Ramji Venkataramanan", "authors": "Cynthia Rush and Ramji Venkataramanan", "title": "Finite Sample Analysis of Approximate Message Passing Algorithms", "comments": "To appear in IEEE Transactions on Information Theory", "journal-ref": "IEEE Transactions on Information Theory, vol. 64, no. 11, pp.\n  7264-7286, November 2018", "doi": "10.1109/TIT.2018.2816681", "report-no": null, "categories": "cs.IT math.IT math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Approximate message passing (AMP) refers to a class of efficient algorithms\nfor statistical estimation in high-dimensional problems such as compressed\nsensing and low-rank matrix estimation. This paper analyzes the performance of\nAMP in the regime where the problem dimension is large but finite. For\nconcreteness, we consider the setting of high-dimensional regression, where the\ngoal is to estimate a high-dimensional vector $\\beta_0$ from a noisy\nmeasurement $y=A \\beta_0 + w$. AMP is a low-complexity, scalable algorithm for\nthis problem. Under suitable assumptions on the measurement matrix $A$, AMP has\nthe attractive feature that its performance can be accurately characterized in\nthe large system limit by a simple scalar iteration called state evolution.\nPrevious proofs of the validity of state evolution have all been asymptotic\nconvergence results. In this paper, we derive a concentration inequality for\nAMP with i.i.d. Gaussian measurement matrices with finite size $n \\times N$.\nThe result shows that the probability of deviation from the state evolution\nprediction falls exponentially in $n$. This provides theoretical support for\nempirical findings that have demonstrated excellent agreement of AMP\nperformance with state evolution predictions for moderately large dimensions.\nThe concentration inequality also indicates that the number of AMP iterations\n$t$ can grow no faster than order $\\frac{\\log n}{\\log \\log n}$ for the\nperformance to be close to the state evolution predictions with high\nprobability. The analysis can be extended to obtain similar non-asymptotic\nresults for AMP in other settings such as low-rank matrix estimation.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jun 2016 15:59:14 GMT"}, {"version": "v2", "created": "Sat, 11 Mar 2017 10:56:42 GMT"}, {"version": "v3", "created": "Wed, 1 Nov 2017 10:46:06 GMT"}, {"version": "v4", "created": "Fri, 16 Mar 2018 10:20:14 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Rush", "Cynthia", ""], ["Venkataramanan", "Ramji", ""]]}, {"id": "1606.01814", "submitter": "Josephine Yu", "authors": "Fatemeh Mohammadi, Caroline Uhler, Charles Wang, and Josephine Yu", "title": "Generalized Permutohedra from Probabilistic Graphical Models", "comments": "Appendix B is expanded. Final version to appear in SIAM J. Discrete\n  Math", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A graphical model encodes conditional independence relations via the Markov\nproperties. For an undirected graph these conditional independence relations\ncan be represented by a simple polytope known as the graph associahedron, which\ncan be constructed as a Minkowski sum of standard simplices. There is an\nanalogous polytope for conditional independence relations coming from a regular\nGaussian model, and it can be defined using multiinformation or relative\nentropy. For directed acyclic graphical models and also for mixed graphical\nmodels containing undirected, directed and bidirected edges, we give a\nconstruction of this polytope, up to equivalence of normal fans, as a Minkowski\nsum of matroid polytopes. Finally, we apply this geometric insight to construct\na new ordering-based search algorithm for causal inference via directed acyclic\ngraphical models.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jun 2016 16:23:46 GMT"}, {"version": "v2", "created": "Mon, 20 Feb 2017 02:03:18 GMT"}, {"version": "v3", "created": "Thu, 7 Dec 2017 04:08:32 GMT"}], "update_date": "2017-12-08", "authors_parsed": [["Mohammadi", "Fatemeh", ""], ["Uhler", "Caroline", ""], ["Wang", "Charles", ""], ["Yu", "Josephine", ""]]}, {"id": "1606.01950", "submitter": "Chunfeng Huang", "authors": "Chunfeng Huang, Haimeng Zhang, Scott M. Robeson, Jacob Shields", "title": "Intrinsic Random Functions on the sphere", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spatial stochastic processes that are modeled over the entire Earth's surface\nrequire statistical approaches that directly consider the spherical domain.\nHere, we extend the notion of intrinsic random functions (IRF) to model\nnon-stationary processes on the sphere and show that low-frequency truncation\nplays an essential role. Then, the universal kriging formula on the sphere is\nderived. We show that all of these developments can be presented through the\ntheory of reproducing kernel Hilbert space. In addition, the link between\nuniversal kriging and splines is carefully investigated, whereby we show that\nthin-plate splines are non-applicable for surface fitting on the sphere.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jun 2016 21:36:52 GMT"}], "update_date": "2016-06-08", "authors_parsed": [["Huang", "Chunfeng", ""], ["Zhang", "Haimeng", ""], ["Robeson", "Scott M.", ""], ["Shields", "Jacob", ""]]}, {"id": "1606.02448", "submitter": "Claire Vernade", "authors": "Paul Lagr\\'ee (UP11, LRI), Claire Vernade (LTCI), Olivier Capp\\'e\n  (LTCI)", "title": "Multiple-Play Bandits in the Position-Based Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequentially learning to place items in multi-position displays or lists is a\ntask that can be cast into the multiple-play semi-bandit setting. However, a\nmajor concern in this context is when the system cannot decide whether the user\nfeedback for each item is actually exploitable. Indeed, much of the content may\nhave been simply ignored by the user. The present work proposes to exploit\navailable information regarding the display position bias under the so-called\nPosition-based click model (PBM). We first discuss how this model differs from\nthe Cascade model and its variants considered in several recent works on\nmultiple-play bandits. We then provide a novel regret lower bound for this\nmodel as well as computationally efficient algorithms that display good\nempirical and theoretical performance.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jun 2016 08:31:46 GMT"}], "update_date": "2016-06-09", "authors_parsed": [["Lagr\u00e9e", "Paul", "", "UP11, LRI"], ["Vernade", "Claire", "", "LTCI"], ["Capp\u00e9", "Olivier", "", "LTCI"]]}, {"id": "1606.02927", "submitter": "Anja Jan{\\ss}en", "authors": "Holger Drees and Anja Jan{\\ss}en", "title": "Conditional Extreme Value Models: Fallacies and Pitfalls", "comments": "22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conditional extreme value models have been introduced by Heffernan and\nResnick (2007) to describe the asymptotic behavior of a random vector as one\nspecific component becomes extreme. Obviously, this class of models is related\nto classical multivariate extreme value theory which describes the behavior of\na random vector as its norm (and therefore at least one of its components)\nbecomes extreme. However, it turns out that this relationship is rather subtle\nand sometimes contrary to intuition. We clarify the differences between the two\napproaches with the help of several illuminative (counter)examples.\nFurthermore, we discuss marginal standardization, which is a useful tool in\nclassical multivariate extreme value theory but, as we point out, much less\nstraightforward and sometimes even obscuring in conditional extreme value\nmodels. Finally, we indicate how, in some situations, a more comprehensive\ncharacterization of the asymptotic behavior can be obtained if the conditions\nof conditional extreme value models are relaxed so that the limit is no longer\nunique.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jun 2016 12:10:06 GMT"}, {"version": "v2", "created": "Thu, 23 Feb 2017 15:43:29 GMT"}], "update_date": "2017-02-24", "authors_parsed": [["Drees", "Holger", ""], ["Jan\u00dfen", "Anja", ""]]}, {"id": "1606.02931", "submitter": "Anna Simoni", "authors": "Siddhartha Chib, Minchul Shin, Anna Simoni", "title": "Bayesian Estimation and Comparison of Moment Condition Models", "comments": "46 pages, 2 figures; revised results in Section 3, revised examples", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider the problem of inference in statistical models\ncharacterized by moment restrictions by casting the problem within the\nExponentially Tilted Empirical Likelihood (ETEL) framework. Because the ETEL\nfunction has a well defined probabilistic interpretation and plays the role of\na nonparametric likelihood, a fully Bayesian semiparametric framework can be\ndeveloped. We establish a number of powerful results surrounding the Bayesian\nETEL framework in such models. One major concern driving our work is the\npossibility of misspecification. To accommodate this possibility, we show how\nthe moment conditions can be reexpressed in terms of additional nuisance\nparameters and that, even under misspecification, the Bayesian ETEL posterior\ndistribution satisfies a Bernstein-von Mises result. A second key contribution\nof the paper is the development of a framework based on marginal likelihoods\nand Bayes factors to compare models defined by different moment conditions.\nComputation of the marginal likelihoods is by the method of Chib (1995) as\nextended to Metropolis-Hastings samplers in Chib and Jeliazkov (2001). We\nestablish the model selection consistency of the marginal likelihood and show\nthat the marginal likelihood favors the model with the minimum number of\nparameters and the maximum number of valid moment restrictions. When the models\nare misspecified, the marginal likelihood model selection procedure selects the\nmodel that is closer to the (unknown) true data generating process in terms of\nthe Kullback-Leibler divergence. The ideas and results in this paper provide a\nfurther broadening of the theoretical underpinning and value of the Bayesian\nETEL framework with likely far-reaching practical consequences. The discussion\nis illuminated through several examples.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jun 2016 12:29:35 GMT"}, {"version": "v2", "created": "Fri, 7 Apr 2017 13:48:07 GMT"}], "update_date": "2017-04-10", "authors_parsed": [["Chib", "Siddhartha", ""], ["Shin", "Minchul", ""], ["Simoni", "Anna", ""]]}, {"id": "1606.03059", "submitter": "Vu Dinh", "authors": "Vu Dinh, Lam Si Tung Ho, Marc A. Suchard, Frederick A. Matsen IV", "title": "Consistency and convergence rate of phylogenetic inference via\n  regularization", "comments": "34 pages, 5 figures. To appear on The Annals of Statistics", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is common in phylogenetics to have some, perhaps partial, information\nabout the overall evolutionary tree of a group of organisms and wish to find an\nevolutionary tree of a specific gene for those organisms. There may not be\nenough information in the gene sequences alone to accurately reconstruct the\ncorrect \"gene tree.\" Although the gene tree may deviate from the \"species tree\"\ndue to a variety of genetic processes, in the absence of evidence to the\ncontrary it is parsimonious to assume that they agree. A common statistical\napproach in these situations is to develop a likelihood penalty to incorporate\nsuch additional information. Recent studies using simulation and empirical data\nsuggest that a likelihood penalty quantifying concordance with a species tree\ncan significantly improve the accuracy of gene tree reconstruction compared to\nusing sequence data alone. However, the consistency of such an approach has not\nyet been established, nor have convergence rates been bounded. Because\nphylogenetics is a non-standard inference problem, the standard theory does not\napply. In this paper, we propose a penalized maximum likelihood estimator for\ngene tree reconstruction, where the penalty is the square of the\nBillera-Holmes-Vogtmann geodesic distance from the gene tree to the species\ntree. We prove that this method is consistent, and derive its convergence rate\nfor estimating the discrete gene tree structure and continuous edge lengths\n(representing the amount of evolution that has occurred on that branch)\nsimultaneously. We find that the regularized estimator is \"adaptive fast\nconverging,\" meaning that it can reconstruct all edges of length greater than\nany given threshold from gene sequences of polynomial length. Our method does\nnot require the species tree to be known exactly; in fact, our asymptotic\ntheory holds for any such guide tree.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jun 2016 18:45:54 GMT"}, {"version": "v2", "created": "Sat, 6 Jan 2018 00:40:09 GMT"}], "update_date": "2018-01-09", "authors_parsed": [["Dinh", "Vu", ""], ["Ho", "Lam Si Tung", ""], ["Suchard", "Marc A.", ""], ["Matsen", "Frederick A.", "IV"]]}, {"id": "1606.03077", "submitter": "Ilias Diakonikolas", "authors": "Ilias Diakonikolas and Daniel M. Kane and Alistair Stewart", "title": "Efficient Robust Proper Learning of Log-concave Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the {\\em robust proper learning} of univariate log-concave\ndistributions (over continuous and discrete domains). Given a set of samples\ndrawn from an unknown target distribution, we want to compute a log-concave\nhypothesis distribution that is as close as possible to the target, in total\nvariation distance. In this work, we give the first computationally efficient\nalgorithm for this learning problem. Our algorithm achieves the\ninformation-theoretically optimal sample size (up to a constant factor), runs\nin polynomial time, and is robust to model misspecification with nearly-optimal\nerror guarantees.\n  Specifically, we give an algorithm that, on input $n=O(1/\\eps^{5/2})$ samples\nfrom an unknown distribution $f$, runs in time $\\widetilde{O}(n^{8/5})$, and\noutputs a log-concave hypothesis $h$ that (with high probability) satisfies\n$\\dtv(h, f) = O(\\opt)+\\eps$, where $\\opt$ is the minimum total variation\ndistance between $f$ and the class of log-concave distributions. Our approach\nto the robust proper learning problem is quite flexible and may be applicable\nto many other univariate distribution families.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jun 2016 19:32:20 GMT"}], "update_date": "2016-06-10", "authors_parsed": [["Diakonikolas", "Ilias", ""], ["Kane", "Daniel M.", ""], ["Stewart", "Alistair", ""]]}, {"id": "1606.03275", "submitter": "{\\L}ukasz Rajkowski", "authors": "{\\L}ukasz Rajkowski", "title": "Analysis of the maximal posterior partition in the Dirichlet Process\n  Gaussian Mixture Model", "comments": "50 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mixture models are a natural choice in many applications, but it can be\ndifficult to place an a priori upper bound on the number of components. To\ncircumvent this, investigators are turning increasingly to Dirichlet process\nmixture models (DPMMs). It is therefore important to develop an understanding\nof the strengths and weaknesses of this approach. This work considers the MAP\n(maximum a posteriori) clustering for the Gaussian DPMM (where the cluster\nmeans have Gaussian distribution and, for each cluster, the observations within\nthe cluster have Gaussian distribution). Some desirable properties of the MAP\npartition are proved: `almost disjointness' of the convex hulls of clusters\n(they may have at most one point in common) and (with natural assumptions) the\ncomparability of sizes of those clusters that intersect any fixed ball with the\nnumber of observations (as the latter goes to infinity). Consequently, the\nnumber of such clusters remains bounded. Furthermore, if the data arises from\nindependent identically distributed sampling from a given distribution with\nbounded support then the asymptotic MAP partition of the observation space\nmaximises a function which has a straightforward expression, which depends only\non the within-group covariance parameter. As the operator norm of this\ncovariance parameter decreases, the number of clusters in the MAP partition\nbecomes arbitrarily large, which may lead to the overestimation of the number\nof mixture components.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jun 2016 11:27:24 GMT"}, {"version": "v2", "created": "Wed, 13 Dec 2017 12:55:33 GMT"}, {"version": "v3", "created": "Thu, 21 Jun 2018 09:47:59 GMT"}], "update_date": "2018-06-22", "authors_parsed": [["Rajkowski", "\u0141ukasz", ""]]}, {"id": "1606.03362", "submitter": "Zuoxiang Peng", "authors": "Jingyao Hou, Xin Liao, Zuoxiang Peng", "title": "Higher-order expansions of extremes from mixed skew-t distribution", "comments": "24 pages,8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the asymptotic behaviors of the extreme of mixed\nskew-t distribution. We considered limits on distribution and density of\nmaximum of mixed skew-t distribution under linear and power normalization, and\nfurther derived their higher-order expansions, respectively. Examples are given\nto support our findings.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jun 2016 15:24:06 GMT"}], "update_date": "2016-06-13", "authors_parsed": [["Hou", "Jingyao", ""], ["Liao", "Xin", ""], ["Peng", "Zuoxiang", ""]]}, {"id": "1606.03496", "submitter": "Marcelo Moreira", "authors": "Marcelo J. Moreira and Rafael Mourao", "title": "A Critical Value Function Approach, with an Application to Persistent\n  Time-Series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Researchers often rely on the t-statistic to make inference on parameters in\nstatistical models. It is common practice to obtain critical values by\nsimulation techniques. This paper proposes a novel numerical method to obtain\nan approximately similar test. This test rejects the null hypothesis when the\ntest statistic is larger than a critical value function (CVF) of the data. We\nillustrate this procedure when regressors are highly persistent, a case in\nwhich commonly-used simulation methods encounter difficulties controlling size\nuniformly. Our approach works satisfactorily, controls size, and yields a test\nwhich outperforms the two other known similar tests.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jun 2016 22:30:56 GMT"}, {"version": "v2", "created": "Wed, 23 Aug 2017 19:51:43 GMT"}, {"version": "v3", "created": "Fri, 25 Aug 2017 09:41:10 GMT"}, {"version": "v4", "created": "Tue, 29 Aug 2017 09:27:56 GMT"}], "update_date": "2017-08-30", "authors_parsed": [["Moreira", "Marcelo J.", ""], ["Mourao", "Rafael", ""]]}, {"id": "1606.03504", "submitter": "Ming Yuan", "authors": "Ming Yuan and Cun-Hui Zhang", "title": "Incoherent Tensor Norms and Their Applications in Higher Order Tensor\n  Completion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT math.IT math.OC stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the sample size requirement for a general class\nof nuclear norm minimization methods for higher order tensor completion. We\nintroduce a class of tensor norms by allowing for different levels of\ncoherence, which allows us to leverage the incoherence of a tensor. In\nparticular, we show that a $k$th order tensor of rank $r$ and dimension\n$d\\times\\cdots\\times d$ can be recovered perfectly from as few as\n$O((r^{(k-1)/2}d^{3/2}+r^{k-1}d)(\\log(d))^2)$ uniformly sampled entries through\nan appropriate incoherent nuclear norm minimization. Our results demonstrate\nsome key differences between completing a matrix and a higher order tensor:\nThey not only point to potential room for improvement over the usual nuclear\nnorm minimization but also highlight the importance of explicitly accounting\nfor incoherence, when dealing with higher order tensors.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jun 2016 23:59:12 GMT"}], "update_date": "2016-06-14", "authors_parsed": [["Yuan", "Ming", ""], ["Zhang", "Cun-Hui", ""]]}, {"id": "1606.03803", "submitter": "Zhao Ren", "authors": "Zhao Ren, Yongjian Kang, Yingying Fan, Jinchi Lv", "title": "Tuning-Free Heterogeneity Pursuit in Massive Networks", "comments": "29 pages for the main text including 1 figure and 7 tables, 28 pages\n  for the Supplementary Material", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Heterogeneity is often natural in many contemporary applications involving\nmassive data. While posing new challenges to effective learning, it can play a\ncrucial role in powering meaningful scientific discoveries through the\nunderstanding of important differences among subpopulations of interest. In\nthis paper, we exploit multiple networks with Gaussian graphs to encode the\nconnectivity patterns of a large number of features on the subpopulations. To\nuncover the heterogeneity of these structures across subpopulations, we suggest\na new framework of tuning-free heterogeneity pursuit (THP) via large-scale\ninference, where the number of networks is allowed to diverge. In particular,\ntwo new tests, the chi-based test and the linear functional-based test, are\nintroduced and their asymptotic null distributions are established. Under mild\nregularity conditions, we establish that both tests are optimal in achieving\nthe testable region boundary and the sample size requirement for the latter\ntest is minimal. Both theoretical guarantees and the tuning-free feature stem\nfrom efficient multiple-network estimation by our newly suggested approach of\nheterogeneous group square-root Lasso (HGSL) for high-dimensional\nmulti-response regression with heterogeneous noises. To solve this convex\nprogram, we further introduce a tuning-free algorithm that is scalable and\nenjoys provable convergence to the global optimum. Both computational and\ntheoretical advantages of our procedure are elucidated through simulation and\nreal data examples.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jun 2016 03:58:23 GMT"}], "update_date": "2016-06-14", "authors_parsed": [["Ren", "Zhao", ""], ["Kang", "Yongjian", ""], ["Fan", "Yingying", ""], ["Lv", "Jinchi", ""]]}, {"id": "1606.03848", "submitter": "Matthieu Lerasle", "authors": "Roland Diel (JAD), Matthieu Lerasle (JAD)", "title": "Non parametric estimation for random walks in random environment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a random walk in i.i.d. random environment with distribution\n$\\nu$ on Z. The problem we are interested in is to provide an estimator of the\ncumulative distribution function (c.d.f.) F of $\\nu$ from the observation of\none trajectory of the random walk. For that purpose we first estimate the\nmoments of $\\nu$, then combine these moment estimators to obtain a collection\nof estimators (F M n) M $\\ge$1 of F , our final estimator is chosen among this\ncollection by Lepskii's method. This estimator is therefore easily computable\nin practice. We derive convergence rates for this estimator depending on the\nH{\\\"o}lder regularity of F and on the divergence rate of the walk. Our rate is\noptimal when the chain realizes a trade-off between a fast exploration of the\nsites, allowing to get more informations and a larger number of visits of each\nsites, allowing a better recovery of the environment itself.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jun 2016 07:47:55 GMT"}], "update_date": "2016-06-14", "authors_parsed": [["Diel", "Roland", "", "JAD"], ["Lerasle", "Matthieu", "", "JAD"]]}, {"id": "1606.03933", "submitter": "Jeremie Bigot", "authors": "J\\'er\\'emie Bigot, Ra\\'ul Gouet, Thierry Klein and Alfredo L\\'opez", "title": "Minimax convergence rate for estimating the Wasserstein barycenter of\n  random measures on the real line", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is focused on the statistical analysis of probability measures\n$\\nu_{1},\\ldots,\\nu_{n}$ on $\\mathbb{R}$ that can be viewed as independent\nrealizations of an underlying stochastic process. We consider the situation of\npractical importance where the random measures $\\nu_{i}$ are absolutely\ncontinuous with densities $f_{i}$ that are not directly observable. In this\ncase, instead of the densities, we have access to datasets of real random\nvariables $(X_{i,j})_{1 \\leq i \\leq n; \\; 1 \\leq j \\leq p_{i} }$ organized in\nthe form of $n$ experimental units, such that $X_{i,1},\\ldots,X_{i,p_{i}}$ are\niid observations sampled from a random measure $\\nu_{i}$ for each $1 \\leq i\n\\leq n$. In this setting, we focus on first-order statistics methods for\nestimating, from such data, a meaningful structural mean measure. For the\npurpose of taking into account phase and amplitude variations in the\nobservations, we argue that the notion of Wasserstein barycenter is a relevant\ntool. The main contribution of this paper is to characterize the rate of\nconvergence of a (possibly smoothed) empirical Wasserstein barycenter towards\nits population counterpart in the asymptotic setting where both $n$ and\n$\\min_{1 \\leq i \\leq n} p_{i}$ may go to infinity. The optimality of this\nprocedure is discussed from the minimax point of view with respect to the\nWasserstein metric. We also highlight the connection between our approach and\nthe curve registration problem in statistics. Some numerical experiments are\nused to illustrate the results of the paper on the convergence rate of\nempirical Wasserstein barycenters.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jun 2016 13:10:03 GMT"}, {"version": "v2", "created": "Tue, 28 Mar 2017 19:53:01 GMT"}], "update_date": "2017-03-30", "authors_parsed": [["Bigot", "J\u00e9r\u00e9mie", ""], ["Gouet", "Ra\u00fal", ""], ["Klein", "Thierry", ""], ["L\u00f3pez", "Alfredo", ""]]}, {"id": "1606.03998", "submitter": "Sungkyu Jung", "authors": "Sungkyu Jung", "title": "Inference on subspheres model for directional data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling deformations of a real object is an important task in computer\nvision, biomedical engineering and biomechanics. In this paper, we focus on a\nsituation where a three-dimensional object is rotationally deformed about a\nfixed axis, and assume that many independent observations are available. Such a\nproblem is generalized to an estimation of concentric, co-dimension 1,\nsubspheres of a polysphere. We formulate least-square estimators as generalized\nFr\\'{e}chet means, and evaluate the consistency and asymptotic normality.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jun 2016 15:43:13 GMT"}], "update_date": "2016-06-14", "authors_parsed": [["Jung", "Sungkyu", ""]]}, {"id": "1606.04010", "submitter": "Joost Kruis", "authors": "Joost Kruis, Gunter Maris", "title": "Three representations of the Ising model", "comments": "11 pages, 1 figure", "journal-ref": "Sci. Rep. 6, 34175 (2016)", "doi": "10.1038/srep34175", "report-no": null, "categories": "stat.ME cond-mat.dis-nn cond-mat.stat-mech math.ST stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Statistical models that analyse (pairwise) relations between variables\nencompass assumptions about the underlying mechanism that generated the\nassociations in the observed data. In the present paper we demonstrate that\nthree Ising model representations exist that, although each proposes a distinct\ntheoretical explanation for the observed associations, are mathematically\nequivalent. This equivalence allows the researcher to interpret the results of\none model in three different ways. We illustrate the ramifications of this by\ndiscussing concepts that are conceived as problematic in their traditional\nexplanation, yet when interpreted in the context of another explanation make\nimmediate sense.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jun 2016 16:07:45 GMT"}, {"version": "v2", "created": "Mon, 5 Sep 2016 11:53:00 GMT"}, {"version": "v3", "created": "Thu, 6 Oct 2016 13:11:38 GMT"}], "update_date": "2016-10-07", "authors_parsed": [["Kruis", "Joost", ""], ["Maris", "Gunter", ""]]}, {"id": "1606.04276", "submitter": "Antoine Godichon-Baggioni", "authors": "Antoine Godichon-Baggioni and Bruno Portier", "title": "An averaged projected Robbins-Monro algorithm for estimating the\n  parameters of a truncated spherical distribution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The objective of this work is to propose a new algorithm to fit a sphere on a\nnoisy 3D point cloud distributed around a complete or a truncated sphere. More\nprecisely, we introduce a projected Robbins-Monro algorithm and its averaged\nversion for estimating the center and the radius of the sphere. We give\nasymptotic results such as the almost sure convergence of these algorithms as\nwell as the asymptotic normality of the averaged algorithm. Furthermore, some\nnon-asymptotic results will be given, such as the rates of convergence in\nquadratic mean. Some numerical experiments show the efficiency of the proposed\nalgorithm on simulated data for small to moderate sample sizes.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jun 2016 09:40:14 GMT"}], "update_date": "2016-06-15", "authors_parsed": [["Godichon-Baggioni", "Antoine", ""], ["Portier", "Bruno", ""]]}, {"id": "1606.04417", "submitter": "Guangming Pan", "authors": "Xiao Han, Guangming Pan and Qing Yang", "title": "A unified matrix model including both CCA and F matrices in multivariate\n  analysis: the largest eigenvalue and its applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $\\bbZ_{M_1\\times N}=\\bbT^{\\frac{1}{2}}\\bbX$ where\n$(\\bbT^{\\frac{1}{2}})^2=\\bbT$ is a positive definite matrix and $\\bbX$ consists\nof independent random variables with mean zero and variance one. This paper\nproposes a unified matrix model\n$$\\bold{\\bbom}=(\\bbZ\\bbU_2\\bbU_2^T\\bbZ^T)^{-1}\\bbZ\\bbU_1\\bbU_1^T\\bbZ^T,$$ where\n$\\bbU_1$ and $\\bbU_2$ are isometric with dimensions $N\\times N_1$ and $N\\times\n(N-N_2)$ respectively such that $\\bbU_1^T\\bbU_1=\\bbI_{N_1}$,\n$\\bbU_2^T\\bbU_2=\\bbI_{N-N_2}$ and $\\bbU_1^T\\bbU_2=0$. Moreover, $\\bbU_1$ and\n$\\bbU_2$ (random or non-random) are independent of $\\bbZ_{M_1\\times N}$ and\nwith probability tending to one, $rank(\\bbU_1)=N_1$ and $rank(\\bbU_2)=N-N_2$.\n  We establish the asymptotic Tracy-Widom distribution for its largest\neigenvalue under moment assumptions on $\\bbX$ when $N_1,N_2$ and $M_1$ are\ncomparable.\n  By selecting appropriate matrices $\\bbU_1$ and $\\bbU_2$, the asymptotic\ndistributions of the maximum eigenvalues of the matrices used in Canonical\nCorrelation Analysis (CCA) and of F matrices (including centered and\nnon-centered versions) can be both obtained from that of $\\bold{\\bbom}$. %In\nparticular, $\\bbom$ can also cover nonzero mean by appropriate matrices\n$\\bbU_1$ and $\\bbU_2$. %relax the zero mean value restriction for F matrix in\n\\cite{WY} to allow for any nonzero mean vetors. %thus a direct application of\nour proposed Tracy-Widom distribution is the independence testing via CCA.\nMoreover, via appropriate matrices $\\bbU_1$ and $\\bbU_2$, this matrix\n$\\bold{\\bbom}$ can be applied to some multivariate testing problems that cannot\nbe done by the traditional CCA matrix.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jun 2016 15:16:13 GMT"}, {"version": "v2", "created": "Wed, 22 Jun 2016 08:26:08 GMT"}], "update_date": "2016-06-23", "authors_parsed": [["Han", "Xiao", ""], ["Pan", "Guangming", ""], ["Yang", "Qing", ""]]}, {"id": "1606.04425", "submitter": "Alex Ely Kossovsky", "authors": "Alex Ely Kossovsky", "title": "Exponential Growth Series and Benford's Law", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exponential growth occurs when the growth rate of a given quantity is\nproportional to the quantity's current value. Surprisingly, when exponential\ngrowth data is plotted as a simple histogram disregarding the time dimension, a\nremarkable fit to the positively skewed k/x distribution is found, where the\nsmall is numerous and the big is rare. Such quantitative preference for the\nsmall has a corresponding digital preference known as Benford's Law which\npredicts that the first significant digit on the left-most side of numbers in\ntypical real-life data is proportioned between all possible 1 to 9 digits\napproximately as in LOG(1 + 1/digit), so that low digits occur much more\nfrequently than high digits in the first place. Exponential growth series with\nhigh growth rate are nearly perfectly Benford given that plenty of elements are\nconsidered. An additional constraint is that the logarithm of the growth factor\nmust be an irrational number. Since the irrationals vastly outnumber the\nrationals, on the face of it, this constraint seems to constitute the\nexplanation of why almost all growth series are Benford, yet, in reality this\nis all too simplistic, and the real and more complex explanation is provided in\nthis article. Empirical examinations of close to a half a million growth series\nvia computerized programs almost perfectly match the prediction of the\ntheoretical study on rational versus irrational occurrences, thus in a sense\nconfirming both, the empirical work as well as the theoretical study. In\naddition, a rigorous mathematical proof is provided in the continuous growth\ncase showing that it exactly obeys Benford's Law. A non-rigorous proof is given\nin the discrete case via uniformity of mantissa argument. Finally cases of\ndiscrete series embedded within continuous series are studied, detailing the\ndegree of deviation from the ideal Benford configuration.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jun 2016 15:33:57 GMT"}, {"version": "v2", "created": "Sun, 6 Jan 2019 14:13:38 GMT"}], "update_date": "2019-01-08", "authors_parsed": [["Kossovsky", "Alex Ely", ""]]}, {"id": "1606.04430", "submitter": "Corinne Sinner", "authors": "Corinne Sinner, Yves Dominicy, Christophe Ley, Julien Trufin, Patrick\n  Weber", "title": "An Interpolating Family of Size Distributions", "comments": "20 pages, v2: minor corrections", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new five-parameter family of size distributions on the\nsemi-finite interval $[x_0, \\infty), x_0 \\geqslant 0$, with two attractive\nfeatures. First, it interpolates between power laws, such as the Pareto\ndistribution, and power laws with exponential cut-off, such as the Weibull\ndistribution. The proposed family is thus very flexible and spans over a broad\nrange of well-known size distributions which are special cases of our family.\nSecond, it has important tractability advantages over the popular\nfive-parameter Generalized Beta distribution. We derive the hazard function,\nsurvival function, modes and quantiles, propose a random number generation\nprocedure and discuss maximum likelihood estimation issues. Finally, we\nillustrate the wide applicability and fitting capacities of our new model on\nbasis of three real data sets from very diverse domains, namely actuarial\nscience, environmental science and survival analysis.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jun 2016 15:45:13 GMT"}, {"version": "v2", "created": "Thu, 7 Jul 2016 08:13:47 GMT"}], "update_date": "2016-07-08", "authors_parsed": [["Sinner", "Corinne", ""], ["Dominicy", "Yves", ""], ["Ley", "Christophe", ""], ["Trufin", "Julien", ""], ["Weber", "Patrick", ""]]}, {"id": "1606.04760", "submitter": "Joseph  Salmon", "authors": "Claire Boyer and Yohann De Castro and Joseph Salmon", "title": "Adapting to unknown noise level in sparse deconvolution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT math.OC math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study sparse spike deconvolution over the space of\ncomplex-valued measures when the input measure is a finite sum of Dirac masses.\nWe introduce a modified version of the Beurling Lasso (BLasso), a semi-definite\nprogram that we refer to as the Concomitant Beurling Lasso (CBLasso). This new\nprocedure estimates the target measure and the unknown noise level\nsimultaneously. Contrary to previous estimators in the literature, theory holds\nfor a tuning parameter that depends only on the sample size, so that it can be\nused for unknown noise level problems. Consistent noise level estimation is\nstandardly proved. As for Radon measure estimation, theoretical guarantees\nmatch the previous state-of-the-art results in Super-Resolution regarding\nminimax prediction and localization. The proofs are based on a bound on the\nnoise level given by a new tail estimate of the supremum of a stationary\nnon-Gaussian process through the Rice method.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jun 2016 13:40:31 GMT"}, {"version": "v2", "created": "Wed, 19 Oct 2016 20:46:04 GMT"}], "update_date": "2016-10-21", "authors_parsed": [["Boyer", "Claire", ""], ["De Castro", "Yohann", ""], ["Salmon", "Joseph", ""]]}, {"id": "1606.04819", "submitter": "J\\\"org Stoye", "authors": "Yuichi Kitamura and J\\\"org Stoye", "title": "Nonparametric Analysis of Random Utility Models", "comments": "54 pages, 2 figures", "journal-ref": null, "doi": "10.3982/ECTA14478", "report-no": null, "categories": "math.ST econ.EM stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper develops and implements a nonparametric test of Random Utility\nModels. The motivating application is to test the null hypothesis that a sample\nof cross-sectional demand distributions was generated by a population of\nrational consumers. We test a necessary and sufficient condition for this that\ndoes not rely on any restriction on unobserved heterogeneity or the number of\ngoods. We also propose and implement a control function approach to account for\nendogenous expenditure. An econometric result of independent interest is a test\nfor linear inequality constraints when these are represented as the vertices of\na polyhedron rather than its faces. An empirical application to the U.K.\nHousehold Expenditure Survey illustrates computational feasibility of the\nmethod in demand problems with 5 goods.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jun 2016 15:28:29 GMT"}, {"version": "v2", "created": "Fri, 8 Dec 2017 11:24:29 GMT"}, {"version": "v3", "created": "Thu, 20 Sep 2018 00:06:12 GMT"}], "update_date": "2018-12-06", "authors_parsed": [["Kitamura", "Yuichi", ""], ["Stoye", "J\u00f6rg", ""]]}, {"id": "1606.04995", "submitter": "Tan Le Thanh", "authors": "Le Thanh Tan and Long Bao Le", "title": "Joint Data Compression and MAC Protocol Design for Smartgrids with\n  Renewable Energy", "comments": "https://arxiv.org/admin/q/1589135, Wireless Communications and Mobile\n  Computing, 2016. arXiv admin note: substantial text overlap with\n  arXiv:1506.08318", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.IT math.IT math.OC math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the joint design of data compression and\n802.15.4-based medium access control (MAC) protocol for smartgrids with\nrenewable energy. We study the setting where a number of nodes, each of which\ncomprises electricity load and/or renewable sources, report periodically their\ninjected powers to a data concentrator. Our design exploits the correlation of\nthe reported data in both time and space to efficiently design the data\ncompression using the compressed sensing (CS) technique and theMAC protocol so\nthat the reported data can be recovered reliably within minimum reporting time.\nSpecifically, we perform the following design tasks: i) we employ the\ntwo-dimensional (2D) CS technique to compress the reported data in the\ndistributed manner; ii) we propose to adapt the 802.15.4 MAC protocol frame\nstructure to enable efficient data transmission and reliable data\nreconstruction; and iii) we develop an analytical model based on which we can\nobtain efficient MAC parameter configuration to minimize the reporting delay.\nFinally, numerical results are presented to demonstrate the effectiveness of\nour proposed framework compared to existing solutions.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jun 2016 22:14:15 GMT"}], "update_date": "2016-06-17", "authors_parsed": [["Tan", "Le Thanh", ""], ["Le", "Long Bao", ""]]}, {"id": "1606.05046", "submitter": "Xiaojing Shen", "authors": "Zhiguo Wang, Xiaojing Shen, Yunmin Zhu and Jianxin Pan", "title": "Monte Carlo Set-Membership Filtering for Nonlinear Dynamic Systems", "comments": "25 pages, 8 figures, submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.OC stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When underlying probability density functions of nonlinear dynamic systems\nare unknown, the filtering problem is known to be a challenging problem. This\npaper attempts to make progress on this problem by proposing a new class of\nfiltering methods in bounded noise setting via set-membership theory and Monte\nCarlo (boundary) sampling technique, called Monte Carlo set-membership filter.\nThe set-membership prediction and measurement update are derived by recent\nconvex optimization methods based on S-procedure and Schur complement. To\nguarantee the on-line usage, the nonlinear dynamics are linearized about the\ncurrent estimate and the remainder terms are then bounded by an optimization\nellipsoid, which can be described as a semi-infinite optimization problem. In\ngeneral, it is an analytically intractable problem when dynamic systems are\nnonlinear. However, for a typical nonlinear dynamic system in target tracking,\nwe can analytically derive some regular properties for the remainder. Moreover,\nbased on the remainder properties and the inverse function theorem, the\nsemi-infinite optimization problem can be efficiently solved by Monte Carlo\nboundary sampling technique. Compared with the particle filter, numerical\nexamples show that when the probability density functions of noises are\nunknown, the performance of the Monte Carlo set-membership filter is better\nthan that of the particle filter.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jun 2016 04:03:00 GMT"}], "update_date": "2016-06-17", "authors_parsed": [["Wang", "Zhiguo", ""], ["Shen", "Xiaojing", ""], ["Zhu", "Yunmin", ""], ["Pan", "Jianxin", ""]]}, {"id": "1606.05097", "submitter": "Gwo Dong Lin", "authors": "Gwo Dong Lin, Xiaoling Dou and Satoshi Kuriki", "title": "The Bivariate Lack-of-Memory Distributions", "comments": null, "journal-ref": "Sankhya Series A, 2017, Vol. 79", "doi": "10.1007/s13171-017-0119-1", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We treat all the bivariate lack-of-memory (BLM) distributions in a unified\napproach and develop some new general properties of the BLM distributions,\nincluding joint moment generating function, product moments and dependence\nstructure. Necessary and sufficient conditions for the survival functions of\nBLM distributions to be totally positive of order two are given. Some previous\nresults about specific BLM distributions are improved. In particular, we show\nthat both the Marshall--Olkin survival copula and survival function are totally\npositive of all orders, regardless of parameters. Besides, we point out that\nSlepian's inequality also holds true for BLM distributions.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jun 2016 08:53:18 GMT"}, {"version": "v2", "created": "Fri, 30 Sep 2016 10:31:14 GMT"}, {"version": "v3", "created": "Tue, 6 Dec 2016 05:57:47 GMT"}, {"version": "v4", "created": "Tue, 28 Nov 2017 07:58:56 GMT"}, {"version": "v5", "created": "Sat, 16 Dec 2017 08:22:04 GMT"}], "update_date": "2017-12-19", "authors_parsed": [["Lin", "Gwo Dong", ""], ["Dou", "Xiaoling", ""], ["Kuriki", "Satoshi", ""]]}, {"id": "1606.05100", "submitter": "Christophe Giraud", "authors": "Florentina Bunea and Christophe Giraud and Martin Royer and Nicolas\n  Verzelen", "title": "PECOK: a convex optimization approach to variable clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of variable clustering is that of grouping similar components of\na $p$-dimensional vector $X=(X_{1},\\ldots,X_{p})$, and estimating these groups\nfrom $n$ independent copies of $X$. When cluster similarity is defined via\n$G$-latent models, in which groups of $X$-variables have a common latent\ngenerator, and groups are relative to a partition $G$ of the index set $\\{1,\n\\ldots, p\\}$, the most natural clustering strategy is $K$-means. We explain why\nthis strategy cannot lead to perfect cluster recovery and offer a correction,\nbased on semi-definite programing, that can be viewed as a penalized convex\nrelaxation of $K$-means (PECOK). We introduce a cluster separation measure\ntailored to $G$-latent models, and derive its minimax lower bound for perfect\ncluster recovery. The clusters estimated by PECOK are shown to recover $G$ at a\nnear minimax optimal cluster separation rate, a result that holds true even if\n$K$, the number of clusters, is estimated adaptively from the data. We compare\nPECOK with appropriate corrections of spectral clustering-type procedures, and\nshow that the former outperforms the latter for perfect cluster recovery of\nminimally separated clusters.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jun 2016 08:58:34 GMT"}], "update_date": "2016-06-17", "authors_parsed": [["Bunea", "Florentina", ""], ["Giraud", "Christophe", ""], ["Royer", "Martin", ""], ["Verzelen", "Nicolas", ""]]}, {"id": "1606.05158", "submitter": "Joseph  Salmon", "authors": "C-A. Deledalle and N. Papadakis and J. Salmon and S. Vaiter", "title": "CLEAR: Covariant LEAst-square Re-fitting with applications to image\n  restoration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.CV stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a new framework to remove parts of the systematic\nerrors affecting popular restoration algorithms, with a special focus for image\nprocessing tasks. Generalizing ideas that emerged for $\\ell_1$ regularization,\nwe develop an approach re-fitting the results of standard methods towards the\ninput data. Total variation regularizations and non-local means are special\ncases of interest. We identify important covariant information that should be\npreserved by the re-fitting method, and emphasize the importance of preserving\nthe Jacobian (w.r.t. the observed signal) of the original estimator. Then, we\nprovide an approach that has a \"twicing\" flavor and allows re-fitting the\nrestored signal by adding back a local affine transformation of the residual\nterm. We illustrate the benefits of our method on numerical simulations for\nimage restoration tasks.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jun 2016 12:23:55 GMT"}, {"version": "v2", "created": "Wed, 14 Sep 2016 20:45:02 GMT"}], "update_date": "2016-09-16", "authors_parsed": [["Deledalle", "C-A.", ""], ["Papadakis", "N.", ""], ["Salmon", "J.", ""], ["Vaiter", "S.", ""]]}, {"id": "1606.05167", "submitter": "Maroua Ben Abdeddaiem", "authors": "Maroua Ben Abdeddaiem", "title": "On goodness-of-fit tests for parametric hypotheses in perturbed\n  dynamical systems using a minimum distance estimator", "comments": null, "journal-ref": "Statistical Inference for Stochastic Processes, 2016 pp 1-29", "doi": "10.1007/s11203-016-9132-6", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of the construction of the Goodness-of-Fit test in\nthe case of continuous time observations of a diffusion process with small\nnoise. The null hypothesis is parametric and we use a minimum distance\nestimator of the unknown parameter. We propose an asymptotically distribution\nfree test for this model.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jun 2016 12:49:51 GMT"}], "update_date": "2016-06-17", "authors_parsed": [["Abdeddaiem", "Maroua Ben", ""]]}, {"id": "1606.05302", "submitter": "Farideh Fazayeli", "authors": "Farideh Fazayeli and Arindam Banerjee", "title": "Generalized Direct Change Estimation in Ising Model Structure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of estimating change in the dependency structure\nbetween two $p$-dimensional Ising models, based on respectively $n_1$ and $n_2$\nsamples drawn from the models. The change is assumed to be structured, e.g.,\nsparse, block sparse, node-perturbed sparse, etc., such that it can be\ncharacterized by a suitable (atomic) norm. We present and analyze a\nnorm-regularized estimator for directly estimating the change in structure,\nwithout having to estimate the structures of the individual Ising models. The\nestimator can work with any norm, and can be generalized to other graphical\nmodels under mild assumptions. We show that only one set of samples, say $n_2$,\nneeds to satisfy the sample complexity requirement for the estimator to work,\nand the estimation error decreases as $\\frac{c}{\\sqrt{\\min(n_1,n_2)}}$, where\n$c$ depends on the Gaussian width of the unit norm ball. For example, for\n$\\ell_1$ norm applied to $s$-sparse change, the change can be accurately\nestimated with $\\min(n_1,n_2)=O(s \\log p)$ which is sharper than an existing\nresult $n_1= O(s^2 \\log p)$ and $n_2 = O(n_1^2)$. Experimental results\nillustrating the effectiveness of the proposed estimator are presented.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jun 2016 18:21:45 GMT"}], "update_date": "2016-06-17", "authors_parsed": [["Fazayeli", "Farideh", ""], ["Banerjee", "Arindam", ""]]}, {"id": "1606.05481", "submitter": "Muneya Matsui", "authors": "Richard A. Davis, Muneya Matsui, Thomas Mikosch and Phyllis Wan", "title": "Applications of Distance Correlation to Time Series", "comments": "28 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of empirical characteristic functions for inference problems,\nincluding estimation in some special parametric settings and testing for\ngoodness of fit, has a long history dating back to the 70s (see for example,\nFeuerverger and Mureika (1977), Csorgo (1981a,1981b,1981c), Feuerverger\n(1993)). More recently, there has been renewed interest in using empirical\ncharacteristic functions in other inference settings. The distance covariance\nand correlation, developed by Szekely and Rizzo (2009) for measuring dependence\nand testing independence between two random vectors, are perhaps the best known\nillustrations of this. We apply these ideas to stationary univariate and\nmultivariate time series to measure lagged auto- and cross-dependence in a time\nseries. Assuming strong mixing, we establish the relevant asymptotic theory for\nthe sample auto- and cross-distance correlation functions. We also apply the\nauto-distance correlation function (ADCF) to the residuals of an autoregressive\nprocesses as a test of goodness of fit. Under the null that an autoregressive\nmodel is true, the limit distribution of the empirical ADCF can differ markedly\nfrom the corresponding one based on an iid sequence. We illustrate the use of\nthe empirical auto- and cross-distance correlation functions for testing\ndependence and cross-dependence of time series in a variety of different\ncontexts.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jun 2016 11:14:29 GMT"}], "update_date": "2016-06-20", "authors_parsed": [["Davis", "Richard A.", ""], ["Matsui", "Muneya", ""], ["Mikosch", "Thomas", ""], ["Wan", "Phyllis", ""]]}, {"id": "1606.05687", "submitter": "Gaonyalelwe Maribe Mr", "authors": "Gaonyalelwe Maribe, Andr\\'ehette Verster and Jan Beirlant", "title": "Reducing MSE in estimation of heavy tails: a Bayesian approach", "comments": "12 Pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bias reduction in tail estimation has received considerable interest in\nextreme value analysis. Estimation methods that minimize the bias while keeping\nthe mean squared error (MSE) under control, are especially useful when applying\nclassical methods such as the Hill (1975) estimator. In Caeiro et al. (2005)\nminimum variance reduced bias estimators of the Pareto tail index were first\nproposed where the bias is reduced without increasing the variance with respect\nto the Hill estimator. This method is based on adequate external estimation of\na pair of second-order parameters. Here we revisit this problem from a Bayesian\npoint of view starting from the extended Pareto distribution (EPD)\napproximation to excesses over a high threshold, as developed in Beirlant et\nal. (2009) using maximum likelihood (ML) estimation. Using asymptotic\nconsiderations, we derive an appropriate choice of priors leading to a Bayes\nestimator for which the MSE curve is a weighted average of the Hill and EPD-ML\nMSE curves for a large range of thresholds, under the same conditions as in\nBeirlant et al.(2009). A similar result is obtained for tail probability\nestimation. Simulations show surprisingly good MSE performance with respect to\nthe existing estimators.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jun 2016 22:06:26 GMT"}], "update_date": "2016-06-21", "authors_parsed": [["Maribe", "Gaonyalelwe", ""], ["Verster", "Andr\u00e9hette", ""], ["Beirlant", "Jan", ""]]}, {"id": "1606.06033", "submitter": "Gilles Durrieu", "authors": "Bernard Bercu and Sami Capderou and Gilles Durrieu", "title": "Nonparametric estimation of the derivative of the regression function:\n  application to sea shores water quality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is devoted to the nonparametric estimation of the derivative of\nthe regression function in a nonparametric regression model. We implement a\nvery efficient and easy to handle statistical procedure based on the derivative\nof the recursive Nadaraya-Watson estimator. We establish the almost sure\nconvergence as well as the asymptotic normality for our estimates. We also\nillustrate our nonparametric estimation procedure on simulated and real life\ndata associated with sea shores water quality and valvometry.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jun 2016 09:39:06 GMT"}], "update_date": "2016-06-21", "authors_parsed": [["Bercu", "Bernard", ""], ["Capderou", "Sami", ""], ["Durrieu", "Gilles", ""]]}, {"id": "1606.06179", "submitter": "Arnak Dalalyan S.", "authors": "Pierre C. Bellec and Arnak S. Dalalyan and Edwin Grappin and Quentin\n  Paris", "title": "On the prediction loss of the lasso in the partially labeled setting", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we revisit the risk bounds of the lasso estimator in the\ncontext of transductive and semi-supervised learning. In other terms, the\nsetting under consideration is that of regression with random design under\npartial labeling. The main goal is to obtain user-friendly bounds on the\noff-sample prediction risk. To this end, the simple setting of bounded response\nvariable and bounded (high-dimensional) covariates is considered. We propose\nsome new adaptations of the lasso to these settings and establish oracle\ninequalities both in expectation and in deviation. These results provide\nnon-asymptotic upper bounds on the risk that highlight the interplay between\nthe bias due to the mis-specification of the linear model, the bias due to the\napproximate sparsity and the variance. They also demonstrate that the presence\nof a large number of unlabeled features may have significant positive impact in\nthe situations where the restricted eigenvalue of the design matrix vanishes or\nis very small.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jun 2016 15:38:59 GMT"}, {"version": "v2", "created": "Tue, 8 Nov 2016 12:49:32 GMT"}], "update_date": "2016-11-09", "authors_parsed": [["Bellec", "Pierre C.", ""], ["Dalalyan", "Arnak S.", ""], ["Grappin", "Edwin", ""], ["Paris", "Quentin", ""]]}, {"id": "1606.06246", "submitter": "Richard Samworth", "authors": "Tengyao Wang, Richard J. Samworth", "title": "High-dimensional changepoint estimation via sparse projection", "comments": "59 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Changepoints are a very common feature of Big Data that arrive in the form of\na data stream. In this paper, we study high-dimensional time series in which,\nat certain time points, the mean structure changes in a sparse subset of the\ncoordinates. The challenge is to borrow strength across the coordinates in\norder to detect smaller changes than could be observed in any individual\ncomponent series. We propose a two-stage procedure called `inspect' for\nestimation of the changepoints: first, we argue that a good projection\ndirection can be obtained as the leading left singular vector of the matrix\nthat solves a convex optimisation problem derived from the CUSUM transformation\nof the time series. We then apply an existing univariate changepoint estimation\nalgorithm to the projected series. Our theory provides strong guarantees on\nboth the number of estimated changepoints and the rates of convergence of their\nlocations, and our numerical studies validate its highly competitive empirical\nperformance for a wide range of data generating mechanisms. Software\nimplementing the methodology is available in the R package\n`InspectChangepoint'.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jun 2016 18:54:28 GMT"}, {"version": "v2", "created": "Fri, 17 Mar 2017 18:29:12 GMT"}], "update_date": "2017-03-21", "authors_parsed": [["Wang", "Tengyao", ""], ["Samworth", "Richard J.", ""]]}, {"id": "1606.06459", "submitter": "Chunhao Cai", "authors": "Chunhao Cai, Junyi Guo and Honglong You", "title": "Non-parametric threshold estimation for classical risk process perturbed\n  by diffusion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper,we consider a macro approximation of the flow of a risk\nreserve, The process is observed at discrete time points. Because we cannot\ndirectly observe each jump time and size then we will make use of a technique\nfor identifying the times when jumps larger than a suitably defined threshold\noccurred. We estimate the jump size and survival probability of our risk\nprocess from discrete observations.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jun 2016 07:50:32 GMT"}], "update_date": "2016-06-22", "authors_parsed": [["Cai", "Chunhao", ""], ["Guo", "Junyi", ""], ["You", "Honglong", ""]]}, {"id": "1606.06519", "submitter": "Ilaria Giulini", "authors": "Ilaria Giulini", "title": "Kernel Spectral Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the question of studying spectral clustering in a Hilbert\nspace where the set of points to cluster are drawn i.i.d. according to an\nunknown probability distribution whose support is a union of compact connected\ncomponents. We modify the algorithm proposed by Ng, Jordan and Weiss in order\nto propose a new algorithm that automatically estimates the number of clusters\nand we characterize the convergence of this new algorithm in terms of\nconvergence of Gram operators. We also give a hint of how this approach may\nlead to learn transformation-invariant representations in the context of image\nclassification.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jun 2016 11:17:45 GMT"}], "update_date": "2016-06-22", "authors_parsed": [["Giulini", "Ilaria", ""]]}, {"id": "1606.06658", "submitter": "Aleksey Polunchenko", "authors": "Aleksey S. Polunchenko", "title": "On the Quasi-Stationary Distribution of the Shiryaev-Roberts Diffusion", "comments": "25 pages; 2 figures", "journal-ref": "Sequential Analysis, Vol. 36, No. 1, pp. 126-149, March 2017", "doi": "10.1080/07474946.2016.1275512", "report-no": null, "categories": "math.ST math.PR stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the diffusion $(R_t^r)_{t\\ge0}$ generated by the equation\n$dR_t^r=dt+\\mu R_t^r dB_t$ with $R_0^r\\triangleq r\\ge0$ fixed, and where\n$\\mu\\neq0$ is given, and $(B_t)_{t\\ge0}$ is standard Brownian motion. We assume\nthat $(R_t^r)_{t\\ge0}$ is stopped at\n$\\mathcal{S}_A^r\\triangleq\\inf\\{t\\ge0\\colon R_t^r=A\\}$ with $A>0$ preset, and\nobtain a closed-from formula for the quasi-stationary distribution of\n$(R_t^r)_{t\\ge0}$, i.e., the limit\n$Q_A(x)\\triangleq\\lim_{t\\to+\\infty}\\Pr(R_t^r\\le x|\\mathcal{S}_A^r>t)$,\n$x\\in[0,A]$. Further, we also prove $Q_A(x)$ to be unimodal for any $A>0$, and\nobtain its entire moment series. More importantly, the pair\n$(\\mathcal{S}_A^r,R_t^r)$ with $r\\ge0$ and $A>0$ is the well-known Generalized\nShiryaev-Roberts change-point detection procedure, and its characteristics for\n$r\\sim Q_A(x)$ are of particular interest, especially when $A>0$ is large. In\nview of this circumstance we offer an order-three large-$A$ asymptotic\napproximation of $Q_A(x)$ valid for all $x\\in[0,A]$. The approximation is\nrather accurate even if $A$ is lower than what would be considered \"large\" in\npractice.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jun 2016 17:00:13 GMT"}, {"version": "v2", "created": "Thu, 1 Sep 2016 17:38:01 GMT"}, {"version": "v3", "created": "Thu, 9 Mar 2017 13:31:42 GMT"}], "update_date": "2017-03-10", "authors_parsed": [["Polunchenko", "Aleksey S.", ""]]}, {"id": "1606.06746", "submitter": "Kevin Lin", "authors": "Kevin Lin, James Sharpnack, Alessandro Rinaldo, Ryan J. Tibshirani", "title": "Approximate Recovery in Changepoint Problems, from $\\ell_2$ Estimation\n  Error Rates", "comments": "43 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the 1-dimensional multiple changepoint detection problem, we prove that\nany procedure with a fast enough $\\ell_2$ error rate, in terms of its\nestimation of the underlying piecewise constant mean vector, automatically has\nan (approximate) changepoint screening property---specifically, each true jump\nin the underlying mean vector has an estimated jump nearby. We also show, again\nassuming only knowledge of the $\\ell_2$ error rate, that a simple\npost-processing step can be used to eliminate spurious estimated changepoints,\nand thus delivers an (approximate) changepoint recovery\nproperty---specifically, in addition to the screening property described above,\nwe are assured that each estimated jump has a true jump nearby. As a special\ncase, we focus on the application of these results to the 1-dimensional fused\nlasso, i.e., 1-dimensional total variation denoising, and compare the\nimplications with existing results from the literature. We also study\nextensions to related problems, such as changepoint detection over graphs.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jun 2016 20:02:30 GMT"}, {"version": "v2", "created": "Fri, 2 Dec 2016 21:41:22 GMT"}], "update_date": "2016-12-06", "authors_parsed": [["Lin", "Kevin", ""], ["Sharpnack", "James", ""], ["Rinaldo", "Alessandro", ""], ["Tibshirani", "Ryan J.", ""]]}, {"id": "1606.06763", "submitter": "Alexander Bulinski", "authors": "Alexander Bulinski and Alexey Kozhevin", "title": "Modification of the MDR-EFE method for stratified samples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The MDR-EFE method of performing identification of relevant factors within a\ngiven collection X_1,...,X_n is developed for stratified samples in the case of\nbinary response variable Y. We establish a criterion of strong consistency of\nestimates (involving K-cross-validation procedure and penalty) for a specified\nprediction error function. The cost approach is proposed to compare experiments\nwith random and nonrandom number of observations. Analytic results and\nsimulations demonstrate advantages of the method introduced for stratified\nsamples over that employed for i.i.d. learning sample.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jun 2016 20:47:03 GMT"}], "update_date": "2016-06-23", "authors_parsed": [["Bulinski", "Alexander", ""], ["Kozhevin", "Alexey", ""]]}, {"id": "1606.06772", "submitter": "Fr\\'ed\\'eric Pro\\\"ia", "authors": "Fr\\'ed\\'eric Pro\\\"ia, Marius Soltane", "title": "A test of correlation in the random coefficients of an autoregressive\n  process", "comments": "29 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A random coefficient autoregressive process is deeply investigated in which\nthe coefficients are correlated. First we look at the existence of a strictly\nstationary causal solution, we give the second-order stationarity conditions\nand the autocorrelation function of the process. Then we study some asymptotic\nproperties of the empirical mean and the usual estimators of the process, such\nas convergence, asymptotic normality and rates of convergence, supplied with\nthe appropriate assumptions on the driving perturbations. Our objective is to\nget an overview of the influence of correlated coefficients in the estimation\nstep, through a simple model. In particular, the lack of consistency is shown\nfor the estimation of the autoregressive parameter when the independence\nhypothesis is violated in the random coefficients. Finally, a consistent\nestimation is given together with a testing procedure for the existence of\ncorrelation in the coefficients. While convergence properties rely on the\nergodicity, we use a martingale approach to reach most of the results.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jun 2016 21:17:22 GMT"}, {"version": "v2", "created": "Wed, 2 Aug 2017 10:35:42 GMT"}, {"version": "v3", "created": "Wed, 28 Mar 2018 08:16:20 GMT"}], "update_date": "2018-03-29", "authors_parsed": [["Pro\u00efa", "Fr\u00e9d\u00e9ric", ""], ["Soltane", "Marius", ""]]}, {"id": "1606.06903", "submitter": "Emilija Perkovi\\'c", "authors": "Emilija Perkovi\\'c, Johannes Textor, Markus Kalisch and Marloes H.\n  Maathuis", "title": "Complete Graphical Characterization and Construction of Adjustment Sets\n  in Markov Equivalence Classes of Ancestral Graphs", "comments": "58 pages, 12 figures, to appear in JMLR", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a graphical criterion for covariate adjustment that is sound and\ncomplete for four different classes of causal graphical models: directed\nacyclic graphs (DAGs), maximum ancestral graphs (MAGs), completed partially\ndirected acyclic graphs (CPDAGs), and partial ancestral graphs (PAGs). Our\ncriterion unifies covariate adjustment for a large set of graph classes.\nMoreover, we define an explicit set that satisfies our criterion, if there is\nany set that satisfies our criterion. We also give efficient algorithms for\nconstructing all sets that fulfill our criterion, implemented in the R package\ndagitty. Finally, we discuss the relationship between our criterion and other\ncriteria for adjustment, and we provide new soundness and completeness proofs\nfor the adjustment criterion for DAGs.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jun 2016 11:24:54 GMT"}, {"version": "v2", "created": "Fri, 9 Jun 2017 09:59:08 GMT"}, {"version": "v3", "created": "Tue, 10 Apr 2018 10:25:32 GMT"}, {"version": "v4", "created": "Tue, 19 Jun 2018 15:11:23 GMT"}], "update_date": "2018-06-20", "authors_parsed": [["Perkovi\u0107", "Emilija", ""], ["Textor", "Johannes", ""], ["Kalisch", "Markus", ""], ["Maathuis", "Marloes H.", ""]]}, {"id": "1606.06988", "submitter": "Yousri Slaoui", "authors": "Yousri Slaoui", "title": "Recursive kernel density estimators under missing data", "comments": "to appear in Communication in Statistics - Theory and Methods", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose an automatic bandwidth selection of the recursive\nkernel density estimators with missing data in the context of global and local\ndensity estimation. We showed that, using the selected bandwidth and a special\nstepsize, the proposed recursive estimators outperformed the nonrecursive one\nin terms of estimation error in the case of global estimation. However, the\nrecursive estimators are much better in terms of computational costs. We\ncorroborated these theoretical results through simulation studies and on the\nsimulated data of the Aquitaine cohort of HIV-1 infected patients and on the\ncoriell cell lines using the chromosome number 11.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jun 2016 15:35:47 GMT"}], "update_date": "2016-06-23", "authors_parsed": [["Slaoui", "Yousri", ""]]}, {"id": "1606.07246", "submitter": "Mathias Vetter", "authors": "Ole Martin, Mathias Vetter", "title": "Testing for simultaneous jumps in case of asynchronous observations", "comments": "35 pages, 4 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a novel test for simultaneous jumps in a bivariate It\\^o\nsemimartingale when observation times are asynchronous and irregular. Inference\nis built on a realized correlation coefficient for the jumps of the two\nprocesses which is estimated using bivariate power variations of\nHayashi-Yoshida type without an additional synchronization step. An associated\ncentral limit theorem is shown whose asymptotic distribution is assessed using\na bootstrap procedure. Simulations show that the test works remarkably well in\ncomparison with the much simpler case of regular observations.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jun 2016 09:44:41 GMT"}], "update_date": "2016-06-24", "authors_parsed": [["Martin", "Ole", ""], ["Vetter", "Mathias", ""]]}, {"id": "1606.07268", "submitter": "Anru Zhang", "authors": "Anru Zhang and Lawrence D. Brown and T. Tony Cai", "title": "Semi-supervised Inference: General Theory and Estimation of Means", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We propose a general semi-supervised inference framework focused on the\nestimation of the population mean. As usual in semi-supervised settings, there\nexists an unlabeled sample of covariate vectors and a labeled sample consisting\nof covariate vectors along with real-valued responses (\"labels\"). Otherwise,\nthe formulation is \"assumption-lean\" in that no major conditions are imposed on\nthe statistical or functional form of the data. We consider both the ideal\nsemi-supervised setting where infinitely many unlabeled samples are available,\nas well as the ordinary semi-supervised setting in which only a finite number\nof unlabeled samples is available.\n  Estimators are proposed along with corresponding confidence intervals for the\npopulation mean. Theoretical analysis on both the asymptotic distribution and\n$\\ell_2$-risk for the proposed procedures are given. Surprisingly, the proposed\nestimators, based on a simple form of the least squares method, outperform the\nordinary sample mean. The simple, transparent form of the estimator lends\nconfidence to the perception that its asymptotic improvement over the ordinary\nsample mean also nearly holds even for moderate size samples. The method is\nfurther extended to a nonparametric setting, in which the oracle rate can be\nachieved asymptotically. The proposed estimators are further illustrated by\nsimulation studies and a real data example involving estimation of the homeless\npopulation.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jun 2016 10:53:05 GMT"}, {"version": "v2", "created": "Tue, 14 Aug 2018 01:07:04 GMT"}], "update_date": "2018-08-15", "authors_parsed": [["Zhang", "Anru", ""], ["Brown", "Lawrence D.", ""], ["Cai", "T. Tony", ""]]}, {"id": "1606.07378", "submitter": "Abdelfattah  Mustafa AM", "authors": "Abdelfattah Mustafa, B. S. El-Desouky and Shamsan AL-Garash", "title": "Weibull Generalized Exponential Distribution", "comments": "15 pages, 11 figures. arXiv admin note: substantial text overlap with\n  arXiv:1605.08152", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  This paper introduces a new three-parameters model called the Weibull-G\nexponential distribution (WGED) distribution which exhibits bathtub-shaped\nhazard rate. Some of it's statistical properties are obtained including\nquantile, moments, generating functions, reliability and order statistics. The\nmethod of maximum likelihood is used for estimating the model parameters and\nthe observed Fisher's information matrix is derived. We illustrate the\nusefulness of the proposed model by applications to real data.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jun 2016 03:57:10 GMT"}], "update_date": "2016-06-24", "authors_parsed": [["Mustafa", "Abdelfattah", ""], ["El-Desouky", "B. S.", ""], ["AL-Garash", "Shamsan", ""]]}, {"id": "1606.07384", "submitter": "Yu Cheng", "authors": "Yu Cheng, Ilias Diakonikolas, Daniel Kane, Alistair Stewart", "title": "Robust Learning of Fixed-Structure Bayesian Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the problem of learning Bayesian networks in a robust model\nwhere an $\\epsilon$-fraction of the samples are adversarially corrupted. In\nthis work, we study the fully observable discrete case where the structure of\nthe network is given. Even in this basic setting, previous learning algorithms\neither run in exponential time or lose dimension-dependent factors in their\nerror guarantees. We provide the first computationally efficient robust\nlearning algorithm for this problem with dimension-independent error\nguarantees. Our algorithm has near-optimal sample complexity, runs in\npolynomial time, and achieves error that scales nearly-linearly with the\nfraction of adversarially corrupted samples. Finally, we show on both synthetic\nand semi-synthetic data that our algorithm performs well in practice.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jun 2016 17:47:13 GMT"}, {"version": "v2", "created": "Mon, 29 Oct 2018 05:31:52 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Cheng", "Yu", ""], ["Diakonikolas", "Ilias", ""], ["Kane", "Daniel", ""], ["Stewart", "Alistair", ""]]}, {"id": "1606.07602", "submitter": "Songkiat Sumetkijakan", "authors": "Songkiat Sumetkijakan", "title": "Supports of Implicit Dependence Copulas", "comments": "19 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A copula of continuous random variables $X$ and $Y$ is called an\n\\emph{implicit dependence copula} if there exist functions $\\alpha$ and $\\beta$\nsuch that $\\alpha(X) = \\beta(Y)$ almost surely, which is equivalent to $C$\nbeing factorizable as the $*$-product of a left invertible copula and a right\ninvertible copula. Every implicit dependence copula is supported on the graph\nof $f(x) = g(y)$ for some measure-preserving functions $f$ and $g$ but the\nconverse is not true in general.\n  We obtain a characterization of copulas with implicit dependence supports in\nterms of the non-atomicity of two newly defined associated $\\sigma$-algebras.\nAs an application, we give a broad sufficient condition under which a\nself-similar copula has an implicit dependence support. Under certain extra\nconditions, we explicitly compute the left invertible and right invertible\nfactors of the self-similar copula.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jun 2016 08:35:12 GMT"}, {"version": "v2", "created": "Tue, 28 Jun 2016 09:56:39 GMT"}], "update_date": "2016-06-29", "authors_parsed": [["Sumetkijakan", "Songkiat", ""]]}, {"id": "1606.07664", "submitter": "Christoph Schumacher", "authors": "Christoph Schumacher, Fabian Schwarzenberger, Ivan Veselic", "title": "A Glivenko-Cantelli Theorem for almost additive functions", "comments": "31 pages, to appear in Stochastic Processes and Applications", "journal-ref": "Stochastic Processes and their Applications Volume 127, Issue 1,\n  January 2017, Pages 179-208", "doi": "10.1016/j.spa.2016.06.005", "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a Glivenko--Cantelli theory for monotone, almost additive\nfunctions of i.\\,i.\\,d.\\ sequences of random variables indexed by~$\\Z^d$. Under\ncertain conditions on the random sequence, short range correlations are allowed\nas well. We have an explicit error estimate, consisting of a probabilistic and\na geometric part. We apply the results to yield uniform convergence for several\nquantities arising naturally in statistical physics.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jun 2016 12:46:54 GMT"}], "update_date": "2018-09-28", "authors_parsed": [["Schumacher", "Christoph", ""], ["Schwarzenberger", "Fabian", ""], ["Veselic", "Ivan", ""]]}, {"id": "1606.07702", "submitter": "Markus Rei{\\ss}", "authors": "Gilles Blanchard, Marc Hoffmann and Markus Rei{\\ss}", "title": "Optimal adaptation for early stopping in statistical inverse problems", "comments": "abridged and corrected version", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For linear inverse problems $Y=\\mathsf{A}\\mu+\\xi$, it is classical to recover\nthe unknown signal $\\mu$ by iterative regularisation methods $(\\widehat\n\\mu^{(m)}, m=0,1,\\ldots)$ and halt at a data-dependent iteration $\\tau$ using\nsome stopping rule, typically based on a discrepancy principle, so that the\nweak (or prediction) squared-error $\\|\\mathsf{A}(\\widehat\n\\mu^{(\\tau)}-\\mu)\\|^2$ is controlled. In the context of statistical estimation\nwith stochastic noise $\\xi$, we study oracle adaptation (that is, compared to\nthe best possible stopping iteration) in strong squared-error $E[\\|\\hat\n\\mu^{(\\tau)}-\\mu\\|^2]$.\n  For a residual-based stopping rule oracle adaptation bounds are established\nfor general spectral regularisation methods. The proofs use bias and variance\ntransfer techniques from weak prediction error to strong $L^2$-error, as well\nas convexity arguments and concentration bounds for the stochastic part.\nAdaptive early stopping for the Landweber method is studied in further detail\nand illustrated numerically.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jun 2016 14:32:32 GMT"}, {"version": "v2", "created": "Thu, 26 Oct 2017 09:12:01 GMT"}], "update_date": "2017-10-27", "authors_parsed": [["Blanchard", "Gilles", ""], ["Hoffmann", "Marc", ""], ["Rei\u00df", "Markus", ""]]}, {"id": "1606.07749", "submitter": "Nanang Susyanto", "authors": "Chris A.J. Klaassen and Nanang Susyanto", "title": "Semiparametrically Efficient Estimation of Euclidean Parameters under\n  Equality Constraints", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Assume a (semi)parametrically efficient estimator is given of the Euclidean\nparameter in a (semi)parametric model. A submodel is obtained by constraining\nthis model in that a continuously differentiable function of the Euclidean\nparameter vanishes. We present an explicit method to construct\n(semi)parametrically efficient estimators of the Euclidean parameter in such\nequality constrained submodels and prove their efficiency. Our construction is\nbased solely on the original efficient estimator and the constraining function.\n  Only the parametric case of this estimation problem and a nonparametric\nversion of it have been considered in literature.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jun 2016 16:32:17 GMT"}], "update_date": "2016-06-27", "authors_parsed": [["Klaassen", "Chris A. J.", ""], ["Susyanto", "Nanang", ""]]}, {"id": "1606.07798", "submitter": "Jacques Pienaar", "authors": "Jacques Pienaar", "title": "Which causal structures might support a quantum-classical gap?", "comments": "13 pages, 9 figures, 1 bicycle. Added an appendix showing that\n  e-separation is strictly more general than the skeleton method. Added journal\n  reference", "journal-ref": "New Journal of Physics, Volume 19, Number 4, page 043021, April\n  2017", "doi": "10.1088/1367-2630/aa673e", "report-no": null, "categories": "quant-ph math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A causal scenario is a graph that describes the cause and effect\nrelationships between all relevant variables in an experiment. A scenario is\ndeemed `not interesting' if there is no device-independent way to distinguish\nthe predictions of classical physics from any generalised probabilistic theory\n(including quantum mechanics). Conversely, an interesting scenario is one in\nwhich there exists a gap between the predictions of different operational\nprobabilistic theories, as occurs for example in Bell-type experiments. Henson,\nLal and Pusey (HLP) recently proposed a sufficient condition for a causal\nscenario to not be interesting. In this paper we supplement their analysis with\nsome new techniques and results. We first show that existing graphical\ntechniques due to Evans can be used to confirm by inspection that many graphs\nare interesting without having to explicitly search for inequality violations.\nFor three exceptional cases -- the graphs numbered 15,16,20 in HLP -- we show\nthat there exist non-Shannon type entropic inequalities that imply these graphs\nare interesting. In doing so, we find that existing methods of entropic\ninequalities can be greatly enhanced by conditioning on the specific values of\ncertain variables.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jun 2016 19:42:22 GMT"}, {"version": "v2", "created": "Sat, 3 Sep 2016 17:12:02 GMT"}, {"version": "v3", "created": "Sat, 10 Sep 2016 18:24:42 GMT"}, {"version": "v4", "created": "Tue, 25 Apr 2017 17:57:26 GMT"}], "update_date": "2017-04-26", "authors_parsed": [["Pienaar", "Jacques", ""]]}, {"id": "1606.07896", "submitter": "Keisuke Yano", "authors": "Keisuke Yano, Fumiyasu Komaki", "title": "Asymptotically Minimax Prediction in Infinite Sequence Models", "comments": "Accepted for publication in Electronic Journal of Statistics", "journal-ref": "Electronic Journal of Statistics, Volume 11, Number 2 (2017),\n  3165-3195", "doi": "10.1214/17-EJS1312", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study asymptotically minimax predictive distributions in an infinite\nsequence model. First, we discuss the connection between the prediction in the\ninfinite sequence model and the prediction in the function model. Second, we\nconstruct an asymptotically minimax predictive distribution when the parameter\nspace is a known ellipsoid. We show that the Bayesian predictive distribution\nbased on the Gaussian prior distribution is asymptotically minimax in the\nellipsoid. Third, we construct an asymptotically minimax predictive\ndistribution for any Sobolev ellipsoid. We show that the Bayesian predictive\ndistribution based on the product of Stein's priors is asymptotically minimax\nfor any Sobolev ellipsoid. Finally, we present an efficient sampling method\nfrom the proposed Bayesian predictive distribution.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jun 2016 11:03:12 GMT"}, {"version": "v2", "created": "Wed, 19 Jul 2017 07:31:19 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Yano", "Keisuke", ""], ["Komaki", "Fumiyasu", ""]]}, {"id": "1606.07948", "submitter": "Yousri Slaoui", "authors": "Yousri Slaoui", "title": "Bandwidth selection in deconvolution kernel distribution estimators\n  defined by stochastic approximation method with Laplace errors", "comments": "to appear in Journal of Japan Statistical Society. arXiv admin note:\n  text overlap with arXiv:1606.06988", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider the kernel estimators of a distribution function\ndefined by the stochastic approximation algorithm when the observation are\ncontamined by measurement errors. It is well known that this estimators depends\nheavily on the choice of a smoothing parameter called the bandwidth. We propose\na specific second generation plug-in method of the deconvolution kernel\ndistribution estimators defined by the stochastic approximation algorithm. We\nshow that, using the proposed bandwidth selection and the stepsize which\nminimize the MISE (Mean Integrated Squared Error), the proposed estimator will\nbe better than the classical one for small sample setting when the error\nvariance is controlled by the noise to signal ratio. We corroborate these\ntheoretical results through simulations and a real dataset.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jun 2016 18:22:48 GMT"}], "update_date": "2016-06-28", "authors_parsed": [["Slaoui", "Yousri", ""]]}, {"id": "1606.08090", "submitter": "Peng Lu Peng Lu", "authors": "Peng Lu, Erik-Jan van Kampen, Cornelis C. de Visser, Qiping Chu", "title": "Framework for state and unknown input estimation of linear time-varying\n  systems", "comments": "This paper has been accepted by Automatica. It considers unknown\n  input estimation or fault and disturbances estimation. Existing approaches\n  considers the case where the effects of fault and disturbance can be\n  decoupled. In our paper, we consider the case where the effects of fault and\n  disturbance are coupled. This approach can be easily extended to nonlinear\n  systems", "journal-ref": "Automatica, 73 (2016), 145-154", "doi": "10.1016/j.automatica.2016.07.009", "report-no": null, "categories": "cs.SY cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The design of unknown-input decoupled observers and filters requires the\nassumption of an existence condition in the literature. This paper addresses an\nunknown input filtering problem where the existence condition is not satisfied.\nInstead of designing a traditional unknown input decoupled filter, a\nDouble-Model Adaptive Estimation approach is extended to solve the unknown\ninput filtering problem. It is proved that the state and the unknown inputs can\nbe estimated and decoupled using the extended Double-Model Adaptive Estimation\napproach without satisfying the existence condition. Numerical examples are\npresented in which the performance of the proposed approach is compared to\nmethods from literature.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jun 2016 22:14:44 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Lu", "Peng", ""], ["van Kampen", "Erik-Jan", ""], ["de Visser", "Cornelis C.", ""], ["Chu", "Qiping", ""]]}, {"id": "1606.08151", "submitter": "Kanika", "authors": "Kanika, Somesh Kumar", "title": "Methods for improving estimators of truncated circular parameters", "comments": "Published at http://dx.doi.org/10.3150/15-BEJ736 in the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2016, Vol. 22, No. 4, 2521-2547", "doi": "10.3150/15-BEJ736", "report-no": "IMS-BEJ-BEJ736", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In decision theoretic estimation of parameters in Euclidean space\n$\\mathbb{R}^p$, the action space is chosen to be the convex closure of the\nestimand space. In this paper, the concept has been extended to the estimation\nof circular parameters of distributions having support as a circle, torus or\ncylinder. As directional distributions are of curved nature, existing methods\nfor distributions with parameters taking values in $\\mathbb{R}^p$ are not\nimmediately applicable here. A circle is the simplest one-dimensional\nRiemannian manifold. We employ concepts of convexity, projection, etc., on\nmanifolds to develop sufficient conditions for inadmissibility of estimators\nfor circular parameters. Further invariance under a compact group of\ntransformations is introduced in the estimation problem and a complete class\ntheorem for equivariant estimators is derived. This extends the results of\nMoors [J. Amer. Statist. Assoc. 76 (1981) 910-915] on $\\mathbb{R}^p$ to\ncircles. The findings are of special interest to the case when a circular\nparameter is truncated. The results are implemented to a wide range of\ndirectional distributions to obtain improved estimators of circular parameters.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jun 2016 07:56:32 GMT"}], "update_date": "2016-06-28", "authors_parsed": [["Kanika", "", ""], ["Kumar", "Somesh", ""]]}, {"id": "1606.08248", "submitter": "Xiaoou Li", "authors": "Xiaoou Li, Jingchen Liu, and Zhiliang Ying", "title": "Chernoff Index for Cox Test of Separate Parametric Families", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The asymptotic efficiency of a generalized likelihood ratio test proposed by\nCox is studied under the large deviations framework for error probabilities\ndeveloped by Chernoff. In particular, two separate parametric families of\nhypotheses are considered [Cox, 1961, 1962]. The significance level is set such\nthat the maximal type I and type II error probabilities for the generalized\nlikelihood ratio test decay exponentially fast with the same rate. We derive\nthe analytic form of such a rate that is also known as the Chernoff index\n[Chernoff, 1952], a relative efficiency measure when there is no preference\nbetween the null and the alternative hypotheses. We further extend the analysis\nto approximate error probabilities when the two families are not completely\nseparated. Discussions are provided concerning the implications of the present\nresult on model selection.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jun 2016 12:56:45 GMT"}], "update_date": "2016-06-28", "authors_parsed": [["Li", "Xiaoou", ""], ["Liu", "Jingchen", ""], ["Ying", "Zhiliang", ""]]}, {"id": "1606.08596", "submitter": "Wolfgang Bischoff Dr.", "authors": "Wolfgang Bischoff", "title": "On Designs for Recursive Least Squares Residuals to Detect Alternatives", "comments": "8 pages, Kunert, Joachim, M\\\"uller, Christine H., Atkinson, Anthony\n  C. (Hrsg.): mODa 11 - Advances in Model-Oriented Design and Analysis,\n  Springer International Publishing, 2016. - S. 37-45. - (Contributions to\n  Statistics)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linear regression models are checked by a lack-of-fit (LOF) test to be sure\nthat the model is at least approximatively true. In many practical cases data\nare sampled sequentially. Such a situation appears in industrial production\nwhen goods are produced one after the other. So it is of some interest to check\nthe regression model sequentially. This can be done by recursive least squares\nresiduals. A sequential LOF test can be based on the recursive residual partial\nsum process. In this paper we state the limit of the partial sum process of a\ntriangular array of recursive residuals given a constant regression model when\nthe number of observations goes to infinity. Furthermore, we state the\ncorresponding limit process for local alternatives. For specific alternatives\ndesigns are determined dominating other designs in respect of power of the\nsequential LOF test described above. In this context a result is given in which\n$e^{-1}$ plays a crucial role.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jun 2016 08:09:13 GMT"}], "update_date": "2016-06-29", "authors_parsed": [["Bischoff", "Wolfgang", ""]]}, {"id": "1606.08628", "submitter": "Igor Rodionov V.", "authors": "Igor Rodionov", "title": "Discrimination between close hypotheses about Weibull and log-Weibull\n  type distributions by the higher order statistics", "comments": "30 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The proposed paper discusses the problem of discrimination between close\nhypotheses about distributions belonging to the Gumbel maximum domain of\nattraction. The distinctive feature of the proposed work is using only k higher\norder statistics of the sample in the construction of criteria, because there\nare many situations when we do not know the whole sample, as it occurs in the\nproblems linked with safety, life span, catastrofes, sea level and other. This\nwork is the first in the series of the author's works that deal with the\nstatistics of extrema.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jun 2016 09:48:22 GMT"}], "update_date": "2016-06-29", "authors_parsed": [["Rodionov", "Igor", ""]]}, {"id": "1606.08920", "submitter": "Iosif Pinelis", "authors": "Aryeh Kontorovich and Iosif Pinelis", "title": "Exact Lower Bounds for the Agnostic Probably-Approximately-Correct (PAC)\n  Machine Learning Model", "comments": "Version 2: modified presentation in accordance with referees'\n  comments", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide an exact non-asymptotic lower bound on the minimax expected excess\nrisk (EER) in the agnostic probably-ap\\-proximately-correct (PAC) machine\nlearning classification model and identify minimax learning algorithms as\ncertain maximally symmetric and minimally randomized \"voting\" procedures. Based\non this result, an exact asymptotic lower bound on the minimax EER is provided.\nThis bound is of the simple form $c_\\infty/\\sqrt{\\nu}$ as $\\nu\\to\\infty$, where\n$c_\\infty=0.16997\\dots$ is a universal constant, $\\nu=m/d$, $m$ is the size of\nthe training sample, and $d$ is the Vapnik--Chervonenkis dimension of the\nhypothesis class. It is shown that the differences between these asymptotic and\nnon-asymptotic bounds, as well as the differences between these two bounds and\nthe maximum EER of any learning algorithms that minimize the empirical risk,\nare asymptotically negligible, and all these differences are due to ties in the\nmentioned \"voting\" procedures. A few easy to compute non-asymptotic lower\nbounds on the minimax EER are also obtained, which are shown to be close to the\nexact asymptotic lower bound $c_\\infty/\\sqrt{\\nu}$ even for rather small values\nof the ratio $\\nu=m/d$. As an application of these results, we substantially\nimprove existing lower bounds on the tail probability of the excess risk. Among\nthe tools used are Bayes estimation and apparently new identities and\ninequalities for binomial distributions.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jun 2016 00:19:55 GMT"}, {"version": "v2", "created": "Sun, 31 Dec 2017 03:45:48 GMT"}], "update_date": "2018-01-03", "authors_parsed": [["Kontorovich", "Aryeh", ""], ["Pinelis", "Iosif", ""]]}, {"id": "1606.08974", "submitter": "Paul Rochet", "authors": "Paul Rochet (LMJL), Isabel Serra (UAB)", "title": "The Mean/Max Statistic in Extreme Value Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most extreme events in real life can be faithfully modeled as random\nrealizations from a Generalized Pareto distribution, which depends on two\nparameters: the scale and the shape. In many actual situations, one is mostly\nconcerned with the shape parameter, also called tail index, as it contains the\nmain information on the likelihood of extreme events. In this paper, we show\nthat the mean/max statistic, that is the empirical mean divided by the maximal\nvalue of the sample, constitutes an ideal normalization to study the tail index\nindependently of the scale. This statistic appears naturally when trying to\ndistinguish between uniform and exponential distributions, the two transitional\nphases of the Generalized Pareto model. We propose a simple methodology based\non the mean/max statistic to detect, classify and infer on the tail of the\ndistribution of a sample. Applications to seismic events and detection of\nsaturation in experimental measurements are presented.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jun 2016 06:45:59 GMT"}], "update_date": "2016-06-30", "authors_parsed": [["Rochet", "Paul", "", "LMJL"], ["Serra", "Isabel", "", "UAB"]]}, {"id": "1606.09087", "submitter": "Xin Tong Thomson", "authors": "Andrew J. Majda and Xin T. Tong", "title": "Rigorous accuracy and robustness analysis for two-scale reduced random\n  Kalman filters in high dimensions", "comments": "42 pages, submitted to SIAM JUQ", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contemporary data assimilation often involves millions of prediction\nvariables. The classical Kalman filter is no longer computationally feasible in\nsuch a high dimensional context. This problem can often be resolved by\nexploiting the underlying multiscale structure, applying the full Kalman\nfiltering procedures only to the large scale vari- ables, and estimating the\nsmall scale variables with proper statistical strategies, including\nmultiplicative inflation, representation model error in the observations, and\ncrude localization. The resulting two-scale reduced filters can have close to\noptimal numerical filtering skill based on previous numerical evidence. Yet, no\nrigorous explanation exists for this success, because these modifications\ncreate unavoidable bias and model error. This paper contributes to this issue\nby establishing a new error analysis framework for two different reduced random\nKalman filters, valid independent of the large dimension. The first part of our\nresults examines the fidelity of the covariance estimators, which is essential\nfor accurate uncertainty quantification. In a simplified setting, this is\ndemonstrated by showing the true error covariance is dominated by its\nestimators. In general settings, the Mahalanobis error and its intrinsic\ndissipation can indicate covariance fidelity. The second part develops upper\nbounds for the covariance estimators by comparing with proper Kalman filters.\nCombining both results, the classical tools for Kalman filters can be used as\na-priori performance criteria for the reduced filters. In applications, these\ncriteria guarantee the reduced filters are robust, and accurate for small noise\nsystems. They also shed light on how to tune the reduced filters for stochastic\nturbulence.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jun 2016 13:30:30 GMT"}], "update_date": "2016-06-30", "authors_parsed": [["Majda", "Andrew J.", ""], ["Tong", "Xin T.", ""]]}, {"id": "1606.09126", "submitter": "Christophe Leuridan", "authors": "Jean Brossard, Christophe Leuridan", "title": "Iterated proportional fitting procedure and infinite products of\n  stochastic matrices", "comments": "30 pages, prepublication", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The iterative proportional fitting procedure, introduced in 1937 by Kruithof,\naims to adjust the elements of an array to satisfy specified row and column\nsums. Given a rectangular non-negative matrix $X_0$ and two positive marginals\n$a$ and $b$, the algorithm generates a sequence of matrices $(X_n)$ starting at\n$X_0$, supposed to converge to a biproportional fitting, that is, to a matrix\n$Y$ whose marginals are $a$ and $b$ and of the form $Y=D_1X_0D_2$, for some\ndiagonal matrices $D_1$ and $D_2$ with positive diagonal entries.\n  When a biproportional fitting does exist, it is unique and the sequence\n$(X_n)$ converges to it at an at least geometric rate. More generally, when\nthere exists some matrix with marginal $a$ and $b$ and with support included in\nthe support of $X_0$, the sequence $(X_n)$ converges to the unique matrix whose\nmarginals are $a$ and $b$ and which can be written as a limit of matrices of\nthe form $D_1X_0D_2$. In the opposite case, the sequence $(X_n)$ diverges but\nboth subsequences $(X_{2n})$ and $(X_{2n+1})$ converge.\n  In the present paper, we use a new method to prove again these results and\ndetermine the two limit-points in the case of divergence. Our proof relies on a\nnew convergence theorem for backward infinite products $\\cdots M_2M_1$ of\nstochatic matrices $M_n$, with diagonal entries $M_n(i,i)$ bounded away from\n$0$ and with bounded ratios $M_n(j,i)/M_n(i,j)$. This theorem generalizes\nLorenz' stabilization theorem.\n  We also provide an alternative proof of Touric and Nedi\\'c's theorem on\nbackward infinite products of doubly-stochatic matrices, with diagonal entries\nbounded away from $0$. In both situations, we improve slightly the conclusion,\nsince we establish not only the convergence of the sequence $(M_n \\cdots M_1)$,\nbut also its finite variation.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jun 2016 14:41:22 GMT"}, {"version": "v2", "created": "Tue, 8 May 2018 16:02:24 GMT"}], "update_date": "2018-05-09", "authors_parsed": [["Brossard", "Jean", ""], ["Leuridan", "Christophe", ""]]}, {"id": "1606.09193", "submitter": "Stephane Chretien", "authors": "St\\'ephane Chr\\'etien and Zhen Wai Olivier Ho", "title": "Small coherence implies the weak Null Space Property", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the Compressed Sensing community, it is well known that given a matrix $X\n\\in \\mathbb R^{n\\times p}$ with $\\ell_2$ normalized columns, the Restricted\nIsometry Property (RIP) implies the Null Space Property (NSP). It is also well\nknown that a small Coherence $\\mu$ implies a weak RIP, i.e. the singular values\nof $X_T$ lie between $1-\\delta$ and $1+\\delta$ for \"most\" index subsets $T\n\\subset \\{1,\\ldots,p\\}$ with size governed by $\\mu$ and $\\delta$. In this short\nnote, we show that a small Coherence implies a weak Null Space Property, i.e.\n$\\Vert h_T\\Vert_2 \\le C \\ \\Vert h_{T^c}\\Vert_1/\\sqrt{s}$ for most $T \\subset\n\\{1,\\ldots,p\\}$ with cardinality $|T|\\le s$. We moreover prove some singular\nvalue perturbation bounds that may also prove useful for other applications.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jun 2016 17:29:05 GMT"}], "update_date": "2016-06-30", "authors_parsed": [["Chr\u00e9tien", "St\u00e9phane", ""], ["Ho", "Zhen Wai Olivier", ""]]}, {"id": "1606.09288", "submitter": "Yaser Mehrali", "authors": "Yaser Mehrali and Majid Asadi", "title": "Parameter estimation based on cumulative Kullback-Leibler divergence", "comments": "22 pages, 7 figures Presented in The 2nd Workshop on Information\n  Measures and Their Applications Submitted to appear in Metrika", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose some estimators for the parameters of a statistical\nmodel based on Kullback-Leibler divergence of the survival function in\ncontinuous setting. We prove that the proposed estimators are subclass of\n\"generalized estimating equations\" estimators. The asymptotic properties of the\nestimators such as consistency, asymptotic normality, asymptotic confidence\ninterval and asymptotic hypothesis testing are investigated.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jun 2016 21:06:55 GMT"}], "update_date": "2016-07-01", "authors_parsed": [["Mehrali", "Yaser", ""], ["Asadi", "Majid", ""]]}, {"id": "1606.09321", "submitter": "Xin Tong Thomson", "authors": "Andrew J. Majda and Xin T. Tong", "title": "Performance of Ensemble Kalman filters in large dimensions", "comments": "41 pages, all comments are welcomed", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contemporary data assimilation often involves more than a million prediction\nvariables. Ensemble Kalman filters (EnKF) have been developed by geoscientists.\nThey are successful indispensable tools in science and engineering, because\nthey allow for computationally cheap low ensemble state approximation for\nextremely large dimensional turbulent dynamical systems. The practical finite\nensemble filter like EnKF necessarily involve modifications such as covariance\ninflation and localization, and it is a genuine mystery why they perform so\nwell with small ensemble sizes in large dimensions. This paper provides the\nfirst rigorous stochastic analysis of the accuracy and covariance fidelity of\nEnKF in the practical regime where the ensemble size is much smaller than the\nlarge ambient dimension for EnKFs with random coefficients. A challenging issue\novercome here is that EnKF in huge dimensions introduces unavoidable bias and\nmodel errors which need to be controlled and estimated.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jun 2016 01:37:47 GMT"}, {"version": "v2", "created": "Thu, 25 May 2017 06:50:21 GMT"}], "update_date": "2017-05-26", "authors_parsed": [["Majda", "Andrew J.", ""], ["Tong", "Xin T.", ""]]}, {"id": "1606.09424", "submitter": "Marco Scarsini", "authors": "Riccardo Colini-Baldeschi and Marco Scarsini and Stefano Vaccari", "title": "Variance Allocation and Shapley Value", "comments": "20pages", "journal-ref": null, "doi": "10.1007/s11009-016-9540-5", "report-no": null, "categories": "math.PR cs.GT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the problem of utility allocation in a portfolio under a\nMarkowitz mean-variance choice paradigm, we propose an allocation criterion for\nthe variance of the sum of $n$ possibly dependent random variables. This\ncriterion, the Shapley value, requires to translate the problem into a\ncooperative game. The Shapley value has nice properties, but, in general, is\ncomputationally demanding. The main result of this paper shows that in our\nparticular case the Shapley value has a very simple form that can be easily\ncomputed. The same criterion is used also to allocate the standard deviation of\nthe sum of $n$ random variables and a conjecture about the relation of the\nvalues in the two games is formulated.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jun 2016 10:47:34 GMT"}, {"version": "v2", "created": "Sun, 1 Jan 2017 11:55:08 GMT"}], "update_date": "2017-04-04", "authors_parsed": [["Colini-Baldeschi", "Riccardo", ""], ["Scarsini", "Marco", ""], ["Vaccari", "Stefano", ""]]}, {"id": "1606.09522", "submitter": "Emilien Joly", "authors": "Patrice Bertail (MODAL'X, CREST), Antoine Chambaz (MODAL'X), Emilien\n  Joly (MODAL'X)", "title": "Practical targeted learning from large data sets by survey sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the practical construction of asymptotic confidence intervals for\nsmooth (i.e., path-wise differentiable), real-valued statistical parameters by\ntargeted learning from independent and identically distributed data in contexts\nwhere sample size is so large that it poses computational challenges. We\nobserve some summary measure of all data and select a sub-sample from the\ncomplete data set by Poisson rejective sampling with unequal inclusion\nprobabilities based on the summary measures. Targeted learning is carried out\nfrom the easier to handle sub-sample. We derive a central limit theorem for the\ntargeted minimum loss estimator (TMLE) which enables the construction of the\nconfidence intervals. The inclusion probabilities can be optimized to reduce\nthe asymptotic variance of the TMLE. We illustrate the procedure with two\nexamples where the parameters of interest are variable importance measures of\nan exposure (binary or continuous) on an outcome. We also conduct a simulation\nstudy and comment on its results. keywords: semiparametric inference; survey\nsampling; targeted minimum loss estimation (TMLE)\n", "versions": [{"version": "v1", "created": "Thu, 30 Jun 2016 14:49:59 GMT"}], "update_date": "2016-07-01", "authors_parsed": [["Bertail", "Patrice", "", "MODAL'X, CREST"], ["Chambaz", "Antoine", "", "MODAL'X"], ["Joly", "Emilien", "", "MODAL'X"]]}, {"id": "1606.09527", "submitter": "Moreno Bevilacqua", "authors": "E. Porcu, P. Zastavyi, M. Bevilacqua", "title": "Buhmann covariance functions, their compact supports, and their\n  smoothness", "comments": "16 pages, 3 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the Buhmann class of compactly supported radial basis functions,\nwhih includes a wealth of special cases that have been studied in both\nnumerical analysis and spatial statistics literatures. In particular, the\ncelebrated Wu, Wendland and Missing Wendland functions are notable special\ncases of this class. We propose a very simple difference operator and show the\nconditions for which the application of it to Buhmann functions preserves\npositive definiteness on $m$-dimensional Euclidean spaces. We also show that\nthe application of the difference operator increases smoothness at the origin,\nwhilst keeping positive definiteness in the same $m$-dimensional Euclidean\nspace, as well as compact support. Thus, our operator is a competitor of the\ncelebrated Mont{\\'e}e operator, which allows to increase the smoothness at the\norigin, at the expense of losing positive definiteness in the space where the\nradial basis function is originally defined. The proofs of our results\nhighlight surprising connections with past literatures on celebrated class of\nfunctions. Amongst them, absolute and completely monotone functions.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jun 2016 14:58:06 GMT"}, {"version": "v2", "created": "Fri, 1 Jul 2016 08:06:01 GMT"}, {"version": "v3", "created": "Tue, 27 Sep 2016 02:02:13 GMT"}], "update_date": "2016-09-28", "authors_parsed": [["Porcu", "E.", ""], ["Zastavyi", "P.", ""], ["Bevilacqua", "M.", ""]]}]