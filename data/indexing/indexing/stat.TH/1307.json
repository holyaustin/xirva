[{"id": "1307.0067", "submitter": "Mohammad Naghshvar", "authors": "Mohammad Naghshvar, Tara Javidi, and Mich\\`ele Wigger", "title": "Extrinsic Jensen-Shannon Divergence: Applications to Variable-Length\n  Coding", "comments": "17 pages (two-column), 4 figures, to appear in IEEE Transactions on\n  Information Theory", "journal-ref": null, "doi": "10.1109/TIT.2015.2401004", "report-no": null, "categories": "cs.IT math.IT math.OC math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the problem of variable-length coding over a discrete\nmemoryless channel (DMC) with noiseless feedback. The paper provides a\nstochastic control view of the problem whose solution is analyzed via a newly\nproposed symmetrized divergence, termed extrinsic Jensen-Shannon (EJS)\ndivergence. It is shown that strictly positive lower bounds on EJS divergence\nprovide non-asymptotic upper bounds on the expected code length. The paper\npresents strictly positive lower bounds on EJS divergence, and hence\nnon-asymptotic upper bounds on the expected code length, for the following two\ncoding schemes: variable-length posterior matching and MaxEJS coding scheme\nwhich is based on a greedy maximization of the EJS divergence.\n  As an asymptotic corollary of the main results, this paper also provides a\nrate-reliability test. Variable-length coding schemes that satisfy the\ncondition(s) of the test for parameters $R$ and $E$, are guaranteed to achieve\nrate $R$ and error exponent $E$. The results are specialized for posterior\nmatching and MaxEJS to obtain deterministic one-phase coding schemes achieving\ncapacity and optimal error exponent. For the special case of symmetric\nbinary-input channels, simpler deterministic schemes of optimal performance are\nproposed and analyzed.\n", "versions": [{"version": "v1", "created": "Sat, 29 Jun 2013 04:57:02 GMT"}, {"version": "v2", "created": "Mon, 5 Jan 2015 08:26:11 GMT"}], "update_date": "2016-11-18", "authors_parsed": [["Naghshvar", "Mohammad", ""], ["Javidi", "Tara", ""], ["Wigger", "Mich\u00e8le", ""]]}, {"id": "1307.0366", "submitter": "Caroline Uhler", "authors": "Garvesh Raskutti and Caroline Uhler", "title": "Learning directed acyclic graphs based on sparsest permutations", "comments": "22 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning a Bayesian network or directed acyclic\ngraph (DAG) model from observational data. A number of constraint-based,\nscore-based and hybrid algorithms have been developed for this purpose. For\nconstraint-based methods, statistical consistency guarantees typically rely on\nthe faithfulness assumption, which has been show to be restrictive especially\nfor graphs with cycles in the skeleton. However, there is only limited work on\nconsistency guarantees for score-based and hybrid algorithms and it has been\nunclear whether consistency guarantees can be proven under weaker conditions\nthan the faithfulness assumption. In this paper, we propose the sparsest\npermutation (SP) algorithm. This algorithm is based on finding the causal\nordering of the variables that yields the sparsest DAG. We prove that this new\nscore-based method is consistent under strictly weaker conditions than the\nfaithfulness assumption. We also demonstrate through simulations on small DAGs\nthat the SP algorithm compares favorably to the constraint-based PC and SGS\nalgorithms as well as the score-based Greedy Equivalence Search and hybrid\nMax-Min Hill-Climbing method. In the Gaussian setting, we prove that our\nalgorithm boils down to finding the permutation of the variables with sparsest\nCholesky decomposition for the inverse covariance matrix. Using this\nconnection, we show that in the oracle setting, where the true covariance\nmatrix is known, the SP algorithm is in fact equivalent to $\\ell_0$-penalized\nmaximum likelihood estimation.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2013 13:41:40 GMT"}, {"version": "v2", "created": "Sat, 20 Jul 2013 01:07:21 GMT"}, {"version": "v3", "created": "Mon, 24 Feb 2014 12:16:10 GMT"}, {"version": "v4", "created": "Sat, 27 Jul 2019 12:33:21 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Raskutti", "Garvesh", ""], ["Uhler", "Caroline", ""]]}, {"id": "1307.0470", "submitter": "Gabriel A. Durkin", "authors": "Sergey I. Knysh and Gabriel A. Durkin", "title": "Estimation of Phase and Diffusion: Combining Quantum Statistics and\n  Classical Noise", "comments": "7 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph math.ST physics.ins-det physics.optics stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Coherent ensembles of $N$ qubits present an advantage in quantum phase\nestimation over separable mixtures, but coherence decay due to classical phase\ndiffusion reduces overall precision. In some contexts, the strength of\ndiffusion may be the parameter of interest. We examine estimation of both phase\nand diffusion in large spin systems using a novel mathematical formulation. For\nthe first time, we show a closed form expression for the quantum Fisher\ninformation for estimation of a unitary parameter in a noisy environment. The\noptimal probe state has a non-Gaussian profile and differs also from the\ncanonical phase state; it saturates a new tight precision bound. For noise\nbelow a critical threshold, entanglement always leads to enhanced precision,\nbut the shot-noise limit is beaten only by a constant factor, independent of\n$N$. We provide upper and lower bounds to this factor, valid in low and high\nnoise regimes. Unlike other noise types, it is shown for $N \\gg 1$ that phase\nand diffusion can be measured simultaneously and optimally.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2013 18:35:29 GMT"}], "update_date": "2013-07-02", "authors_parsed": [["Knysh", "Sergey I.", ""], ["Durkin", "Gabriel A.", ""]]}, {"id": "1307.0584", "submitter": "Shankar C. Venkataramani", "authors": "Nusret Balci, Juan M. Restrepo and Shankar C. Venkataramani", "title": "Using Data to Tune Nearshore Dynamics Models: A Bayesian Approach with\n  Parametric Likelihood", "comments": "18 pages, 7 figures, Submitted Ocean Modeling", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.data-an math.ST physics.ao-ph stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a modification of a maximum likelihood procedure for tuning\nparameter values in models, based upon the comparison of their output to field\ndata. Our methodology, which uses polynomial approximations of the sample space\nto increase the computational efficiency, differs from similar Bayesian\nestimation frameworks in the use of an alternative likelihood distribution, is\nshown to better address problems in which covariance information is lacking,\nthan its more conventional counterpart.\n  Lack of covariance information is a frequent challenge in large-scale\ngeophysical estimation. This is the case in the geophysical problem considered\nhere. We use a nearshore model for long shore currents and observational data\nof the same to show the contrast between both maximum likelihood methodologies.\n  Beyond a methodological comparison, this study gives estimates of parameter\nvalues for the bottom drag and surface forcing that make the particular model\nmost consistent with data; furthermore, we also derive sensitivity estimates\nthat provide useful insights regarding the estimation procedure as well as of\nthe model itself.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2013 03:44:43 GMT"}], "update_date": "2013-07-03", "authors_parsed": [["Balci", "Nusret", ""], ["Restrepo", "Juan M.", ""], ["Venkataramani", "Shankar C.", ""]]}, {"id": "1307.1067", "submitter": "Patric M\\\"uller", "authors": "Patric M\\\"uller and Sara van de Geer", "title": "The partial linear model in high dimensions", "comments": "48 pages, 16 figures, submitted to Scandinavian Journal of Statistics", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Partial linear models have been widely used as flexible method for modelling\nlinear components in conjunction with non-parametric ones. Despite the presence\nof the non-parametric part, the linear, parametric part can under certain\nconditions be estimated with parametric rate. In this paper, we consider a\nhigh-dimensional linear part. We show that it can be estimated with oracle\nrates, using the LASSO penalty for the linear part and a smoothness penalty for\nthe nonparametric part.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2013 16:27:05 GMT"}], "update_date": "2013-07-04", "authors_parsed": [["M\u00fcller", "Patric", ""], ["van de Geer", "Sara", ""]]}, {"id": "1307.1077", "submitter": "Philip Dawid", "authors": "A. Philip Dawid and Panayiota Constantinou", "title": "A Formal Treatment of Sequential Ignorability", "comments": "25 pages, 5 figures, 1 table", "journal-ref": "Statistics in Biosciences 6 (2014), 166-188", "doi": "10.1007/s12561-014-9110-8", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Taking a rigorous formal approach, we consider sequential decision problems\ninvolving observable variables, unobservable variables, and action variables.\nWe can typically assume the property of extended stability, which allows\nidentification (by means of G-computation) of the consequence of a specified\ntreatment strategy if the unobserved variables are, in fact, observed - but not\ngenerally otherwise. However, under certain additional special conditions we\ncan infer simple stability (or sequential ignorability), which supports\nG-computation based on the observed variables alone. One such additional\ncondition is sequential randomization, where the unobserved variables\nessentially behave as random noise in their effects on the actions. Another is\nsequential irrelevance, where the unobserved variables do not influence future\nobserved variables. In the latter case, to deduce sequential ignorability in\nfull generality requires additional positivity conditions. We show here that\nthese positivity conditions are not required when all variables are discrete.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2013 16:55:25 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Dawid", "A. Philip", ""], ["Constantinou", "Panayiota", ""]]}, {"id": "1307.1123", "submitter": "Omer Bobrowski", "authors": "Omer Bobrowski, Sayan Mukherjee", "title": "The Topology of Probability Distributions on Manifolds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.AT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $P$ be a set of $n$ random points in $R^d$, generated from a probability\nmeasure on a $m$-dimensional manifold $M \\subset R^d$. In this paper we study\nthe homology of $U(P,r)$ -- the union of $d$-dimensional balls of radius $r$\naround $P$, as $n \\to \\infty$, and $r \\to 0$. In addition we study the critical\npoints of $d_P$ -- the distance function from the set $P$. These two objects\nare known to be related via Morse theory. We present limit theorems for the\nBetti numbers of $U(P,r)$, as well as for number of critical points of index\n$k$ for $d_P$. Depending on how fast $r$ decays to zero as $n$ grows, these two\nobjects exhibit different types of limiting behavior. In one particular case\n($n r^m > C \\log n$), we show that the Betti numbers of $U(P,r)$ perfectly\nrecover the Betti numbers of the original manifold $M$, a result which is of\nsignificant interest in topological manifold learning.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2013 19:57:54 GMT"}, {"version": "v2", "created": "Sat, 1 Mar 2014 16:02:29 GMT"}], "update_date": "2014-03-04", "authors_parsed": [["Bobrowski", "Omer", ""], ["Mukherjee", "Sayan", ""]]}, {"id": "1307.1185", "submitter": "Josef Dick", "authors": "Houying Zhu and Josef Dick", "title": "A Discrepancy Bound for a Deterministic Acceptance-Rejection Sampler", "comments": "To appear in the Electronic Journal of Statistics", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider an acceptance-rejection sampler based on a deterministic driver\nsequence. The deterministic sequence is chosen such that the discrepancy\nbetween the empirical target distribution and the target distribution is small.\nWe use quasi-Monte Carlo (QMC) point sets for this purpose. The empirical\nevidence shows convergence rates beyond the crude Monte Carlo rate of\n$N^{-1/2}$. We prove that the discrepancy of samples generated by the QMC\nacceptance-rejection sampler is bounded from above by $N^{-1/s}$. A lower bound\nshows that for any given driver sequence, there always exists a target density\nsuch that the star discrepancy is at most $N^{-2/(s+1)}$. For a general\ndensity, whose domain is the real state space $\\mathbb{R}^{s-1}$, the inverse\nRosenblatt transformation can be used to convert samples from the\n$(s-1)-$dimensional cube to $\\mathbb{R}^{s-1}$. We show that this\ntransformation is measure preserving. This way, under certain conditions, we\nobtain the same convergence rate for a general target density defined in\n$\\mathbb{R}^{s-1}$. Moreover, we also consider a deterministic reduced\nacceptance-rejection algorithm recently introduced by Barekat and Caflisch [F.\nBarekat and R.Caflisch. Simulation with Fluctuation and Singular Rates.\nArXiv:1310.4555[math.NA], 2013.]\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2013 02:27:19 GMT"}, {"version": "v2", "created": "Sun, 4 May 2014 23:37:21 GMT"}], "update_date": "2014-05-06", "authors_parsed": [["Zhu", "Houying", ""], ["Dick", "Josef", ""]]}, {"id": "1307.1201", "submitter": "Ryan Budney", "authors": "Ryan Budney, William Sethares", "title": "Topology of Musical Data", "comments": "32 pages, 42 figures, v1->v2 reference updates, typos and many small\n  touch-ups", "journal-ref": null, "doi": "10.1080/17459737.2013.850597", "report-no": null, "categories": "math.AT cs.SD math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The musical realm is a promising area in which to expect to find nontrivial\ntopological structures. This paper describes several kinds of metrics on\nmusical data, and explores the implications of these metrics in two ways: via\ntechniques of classical topology where the metric space of all-possible musical\ndata can be described explicitly, and via modern data-driven ideas of\npersistent homology which calculates the Betti-number bar-codes of individual\nmusical works. Both analyses are able to recover three well known topological\nstructures in music: the circle of notes (octave-reduced scalar structures),\nthe circle of fifths, and the rhythmic repetition of timelines. Applications to\na variety of musical works (for example, folk music in the form of standard\nMIDI files) are presented, and the bar codes show many interesting features.\nExamples show that individual pieces may span the complete space (in which case\nthe classical and the data-driven analyses agree), or they may span only part\nof the space.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2013 05:00:59 GMT"}, {"version": "v2", "created": "Sat, 19 Oct 2013 13:21:39 GMT"}], "update_date": "2014-03-20", "authors_parsed": [["Budney", "Ryan", ""], ["Sethares", "William", ""]]}, {"id": "1307.1223", "submitter": "Sheehan Olver", "authors": "Sheehan Olver and Alex Townsend", "title": "Fast inverse transform sampling in one and two dimensions", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a computationally efficient and robust algorithm for generating\npseudo-random samples from a broad class of smooth probability distributions in\none and two dimensions. The algorithm is based on inverse transform sampling\nwith a polynomial approximation scheme using Chebyshev polynomials, Chebyshev\ngrids, and low rank function approximation. Numerical experiments demonstrate\nthat our algorithm outperforms existing approaches.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2013 07:03:07 GMT"}], "update_date": "2013-07-05", "authors_parsed": [["Olver", "Sheehan", ""], ["Townsend", "Alex", ""]]}, {"id": "1307.1501", "submitter": "Philippe  Soulier", "authors": "Rafal Kulik and Philippe Soulier", "title": "Heavy tailed time series with extremal independence", "comments": "Revised version", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST q-fin.RM stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider strictly stationary heavy tailed time series whose\nfinite-dimensional exponent measures are concentrated on axes, and hence their\nextremal properties cannot be tackled using classical multivariate regular\nvariation that is suitable for time series with extremal dependence. We recover\nrelevant information about limiting behavior of time series with extremal\nindependence by introducing a sequence of scaling functions and conditional\nscaling exponent. Both quantities provide more information about joint extremes\nthan a widely used tail dependence coefficient. We calculate the scaling\nfunctions and the scaling exponent for variety of models, including Markov\nchains, exponential autoregressive model, stochastic volatility with heavy\ntailed innovations or volatility.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jul 2013 00:37:52 GMT"}, {"version": "v2", "created": "Thu, 9 Oct 2014 14:18:05 GMT"}], "update_date": "2014-10-10", "authors_parsed": [["Kulik", "Rafal", ""], ["Soulier", "Philippe", ""]]}, {"id": "1307.1565", "submitter": "Denis Belomestny", "authors": "Denis Belomestny and Vladimir Spokoiny", "title": "Concentration inequalities for smooth random fields", "comments": "arXiv admin note: text overlap with arXiv:1205.0498", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this note we derive a sharp concentration inequality for the supremum of a\nsmooth random field over a finite dimensional set. It is shown that this\nsupremum can be bounded with high probability by the value of the field at some\ndeterministic point plus an intrinsic dimension of the optimisation problem. As\nan application we prove the exponential inequality for a function of the\nmaximal eigenvalue of a random matrix is proved.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jul 2013 09:47:22 GMT"}], "update_date": "2013-07-08", "authors_parsed": [["Belomestny", "Denis", ""], ["Spokoiny", "Vladimir", ""]]}, {"id": "1307.1695", "submitter": "Yoichi Nishiyama", "authors": "Yoichi Nishiyama", "title": "A stochastic maximal inequality, strict countability, and related topics", "comments": "This paper has been withdrawn by the author due to a crucial error in\n  the proof of Lemma 16 (i)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As an alternative to the well-known methods of \"chaining\" and \"bracketing\"\nthat have been developed in the study of random fields, a new method, which is\nbased on a stochastic maximal inequality derived by using It\\^o's formula and\non a new concept named strict countability, is presented. The main results are\nsome weak convergence theorems for sequences of separable random fields of\nlocally square-integrable martingales under the uniform topology with the help\nalso of entropy methods. As special cases, some new results for i.i.d. random\nsequences, including a new Donsker theorem and a moment bound for suprema of\nempirical processes indexed by classes of sets or functions, are obtained. An\napplication to statistical estimation in semiparametric models is presented\nwith an illustration to construct adaptive estimators in Cox's regression\nmodel.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jul 2013 19:35:46 GMT"}, {"version": "v2", "created": "Thu, 29 Aug 2013 23:43:26 GMT"}, {"version": "v3", "created": "Mon, 17 Mar 2014 18:51:51 GMT"}, {"version": "v4", "created": "Sun, 20 Jul 2014 05:33:37 GMT"}, {"version": "v5", "created": "Sun, 31 Aug 2014 01:54:32 GMT"}, {"version": "v6", "created": "Wed, 24 Jun 2015 11:16:13 GMT"}, {"version": "v7", "created": "Fri, 17 Jul 2015 00:36:52 GMT"}, {"version": "v8", "created": "Wed, 10 Feb 2016 22:01:42 GMT"}], "update_date": "2016-02-12", "authors_parsed": [["Nishiyama", "Yoichi", ""]]}, {"id": "1307.1952", "submitter": "A. Chatterjee", "authors": "A. Chatterjee, S. N. Lahiri", "title": "Rates of convergence of the Adaptive LASSO estimators to the Oracle\n  distribution and higher order refinements by the bootstrap", "comments": "Published in at http://dx.doi.org/10.1214/13-AOS1106 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2013, Vol. 41, No. 3, 1232-1259", "doi": "10.1214/13-AOS1106", "report-no": "IMS-AOS-AOS1106", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Zou [J. Amer. Statist. Assoc. 101 (2006) 1418-1429] proposed the Adaptive\nLASSO (ALASSO) method for simultaneous variable selection and estimation of the\nregression parameters, and established its oracle property. In this paper, we\ninvestigate the rate of convergence of the ALASSO estimator to the oracle\ndistribution when the dimension of the regression parameters may grow to\ninfinity with the sample size. It is shown that the rate critically depends on\nthe choices of the penalty parameter and the initial estimator, among other\nfactors, and that confidence intervals (CIs) based on the oracle limit law\noften have poor coverage accuracy. As an alternative, we consider the residual\nbootstrap method for the ALASSO estimators that has been recently shown to be\nconsistent; cf. Chatterjee and Lahiri [J. Amer. Statist. Assoc. 106 (2011a)\n608-625]. We show that the bootstrap applied to a suitable studentized version\nof the ALASSO estimator achieves second-order correctness, even when the\ndimension of the regression parameters is unbounded. Results from a moderately\nlarge simulation study show marked improvement in coverage accuracy for the\nbootstrap CIs over the oracle based CIs.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2013 06:09:44 GMT"}], "update_date": "2013-07-09", "authors_parsed": [["Chatterjee", "A.", ""], ["Lahiri", "S. N.", ""]]}, {"id": "1307.1962", "submitter": "Ngai Hang Chan", "authors": "Ngai Hang Chan, Shih-Feng Huang, Ching-Kang Ing", "title": "Moment bounds and mean squared prediction errors of long-memory time\n  series", "comments": "Published in at http://dx.doi.org/10.1214/13-AOS1110 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2013, Vol. 41, No. 3, 1268-1298", "doi": "10.1214/13-AOS1110", "report-no": "IMS-AOS-AOS1110", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A moment bound for the normalized conditional-sum-of-squares (CSS) estimate\nof a general autoregressive fractionally integrated moving average (ARFIMA)\nmodel with an arbitrary unknown memory parameter is derived in this paper. To\nachieve this goal, a uniform moment bound for the inverse of the normalized\nobjective function is established. An important application of these results is\nto establish asymptotic expressions for the one-step and multi-step mean\nsquared prediction errors (MSPE) of the CSS predictor. These asymptotic\nexpressions not only explicitly demonstrate how the multi-step MSPE of the CSS\npredictor manifests with the model complexity and the dependent structure, but\nalso offer means to compare the performance of the CSS predictor with the least\nsquares (LS) predictor for integrated autoregressive models. It turns out that\nthe CSS predictor can gain substantial advantage over the LS predictor when the\nintegration order is high. Numerical findings are also conducted to illustrate\nthe theoretical results.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2013 07:04:31 GMT"}], "update_date": "2013-07-09", "authors_parsed": [["Chan", "Ngai Hang", ""], ["Huang", "Shih-Feng", ""], ["Ing", "Ching-Kang", ""]]}, {"id": "1307.2217", "submitter": "Marc Joannides", "authors": "Fabien Campillo (INRIA Sophia Antipolis, MISTEA), Marc Joannides\n  (I3M), Ir\\`ene Larramendy-Valverde (I3M)", "title": "Estimation of the parameters of a stochastic logistic growth model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a stochastic logistic growth model involving both birth and death\nrates in the drift and diffusion coefficients for which extinction eventually\noccurs almost surely. The associated complete Fokker-Planck equation describing\nthe law of the process is established and studied. We then use its solution to\nbuild a likelihood function for the unknown model parameters, when discretely\nsampled data is available. The existing estimation methods need adaptation in\norder to deal with the extinction problem. We propose such adaptations, based\non the particular form of the Fokker-Planck equation, and we evaluate their\nperformances with numerical simulations. In the same time, we explore the\nidentifiability of the parameters which is a crucial problem for the\ncorresponding deterministic (noise free) model.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2013 19:48:30 GMT"}], "update_date": "2013-07-09", "authors_parsed": [["Campillo", "Fabien", "", "INRIA Sophia Antipolis, MISTEA"], ["Joannides", "Marc", "", "I3M"], ["Larramendy-Valverde", "Ir\u00e8ne", "", "I3M"]]}, {"id": "1307.2223", "submitter": "Loic Le Gratiet", "authors": "Loic Le Gratiet (LPMA, - M\\'ethodes d'Analyse Stochastique des Codes\n  et Traitements Num\\'eriques), Claire Cannamela (- M\\'ethodes d'Analyse\n  Stochastique des Codes et Traitements Num\\'eriques), Bertrand Iooss (-\n  M\\'ethodes d'Analyse Stochastique des Codes et Traitements Num\\'eriques)", "title": "A Bayesian approach for global sensitivity analysis of (multi-fidelity)\n  computer codes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complex computer codes are widely used in science and engineering to model\nphysical phenomena. Furthermore, it is common that they have a large number of\ninput parameters. Global sensitivity analysis aims to identify those which have\nthe most important impact on the output. Sobol indices are a popular tool to\nperform such analysis. However, their estimations require an important number\nof simulations and often cannot be processed under reasonable time constraint.\nTo handle this problem, a Gaussian process regression model is built to\nsurrogate the computer code and the Sobol indices are estimated through it. The\naim of this paper is to provide a methodology to estimate the Sobol indices\nthrough a surrogate model taking into account both the estimation errors and\nthe surrogate model errors. In particular, it allows us to derive\nnon-asymptotic confidence intervals for the Sobol index estimations.\nFurthermore, we extend the suggested strategy to the case of multi-fidelity\ncomputer codes which can be run at different levels of accuracy. For such\nsimulators, we use an extension of Gaussian process regression models for\nmultivariate outputs.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2013 19:50:59 GMT"}], "update_date": "2013-07-09", "authors_parsed": [["Gratiet", "Loic Le", "", "LPMA, - M\u00e9thodes d'Analyse Stochastique des Codes\n  et Traitements Num\u00e9riques"], ["Cannamela", "Claire", "", "- M\u00e9thodes d'Analyse\n  Stochastique des Codes et Traitements Num\u00e9riques"], ["Iooss", "Bertrand", "", "-\n  M\u00e9thodes d'Analyse Stochastique des Codes et Traitements Num\u00e9riques"]]}, {"id": "1307.2297", "submitter": "Fan Wu", "authors": "Fan Wu and Min Tsao", "title": "Multivariate two-sample extended empirical likelihood", "comments": "10 pages, 2 tables, 1 Figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Jing (1995) and Liu et al. (2008) studied the two-sample empirical likelihood\nand showed it is Bartlett correctable for the univariate and multivariate\ncases, respectively. We expand its domain to the full parameter space and\nobtain a two-sample extended empirical likelihood which is more accurate and\ncan also achieve the second-order accuracy of the Bartlett correction.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2013 22:59:58 GMT"}, {"version": "v2", "created": "Tue, 20 Aug 2013 17:43:32 GMT"}], "update_date": "2013-08-21", "authors_parsed": [["Wu", "Fan", ""], ["Tsao", "Min", ""]]}, {"id": "1307.2342", "submitter": "Gabriel Peyre", "authors": "Samuel Vaiter (CEREMADE), Mohammad Golbabaee (CEREMADE), Jalal M.\n  Fadili (GREYC), Gabriel Peyr\\'e (CEREMADE)", "title": "Model Selection with Low Complexity Priors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regularization plays a pivotal role when facing the challenge of solving\nill-posed inverse problems, where the number of observations is smaller than\nthe ambient dimension of the object to be estimated. A line of recent work has\nstudied regularization models with various types of low-dimensional structures.\nIn such settings, the general approach is to solve a regularized optimization\nproblem, which combines a data fidelity term and some regularization penalty\nthat promotes the assumed low-dimensional/simple structure. This paper provides\na general framework to capture this low-dimensional structure through what we\ncoin partly smooth functions relative to a linear manifold. These are convex,\nnon-negative, closed and finite-valued functions that will promote objects\nliving on low-dimensional subspaces. This class of regularizers encompasses\nmany popular examples such as the L1 norm, L1-L2 norm (group sparsity), as well\nas several others including the Linfty norm. We also show that the set of\npartly smooth functions relative to a linear manifold is closed under addition\nand pre-composition by a linear operator, which allows to cover mixed\nregularization, and the so-called analysis-type priors (e.g. total variation,\nfused Lasso, finite-valued polyhedral gauges). Our main result presents a\nunified sharp analysis of exact and robust recovery of the low-dimensional\nsubspace model associated to the object to recover from partial measurements.\nThis analysis is illustrated on a number of special and previously studied\ncases, and on an analysis of the performance of Linfty regularization in a\ncompressed sensing scenario.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2013 06:27:47 GMT"}, {"version": "v2", "created": "Wed, 2 Jul 2014 18:56:50 GMT"}], "update_date": "2014-07-03", "authors_parsed": [["Vaiter", "Samuel", "", "CEREMADE"], ["Golbabaee", "Mohammad", "", "CEREMADE"], ["Fadili", "Jalal M.", "", "GREYC"], ["Peyr\u00e9", "Gabriel", "", "CEREMADE"]]}, {"id": "1307.2546", "submitter": "Dominique Dehay", "authors": "Dominique Dehay (IRMAR), Harry L. Hurd (STOR), Andrzej Makagon", "title": "Spectrum of periodically correlated fields", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper deals with Hilbert space valued fields over any locally compact\nAbelian group G, in particular over G = Z^n x R^m, which are periodically\ncorrelated (PC) with respect to a closed subgroup of G. PC fields can be\nregarded as multi-parameter extensions of PC processes. We study structure,\ncovariance function, and an analogue of the spectrum for such fields. As an\nexample a weakly PC field over Z^2 is thoroughly examined.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2013 19:22:40 GMT"}], "update_date": "2013-07-10", "authors_parsed": [["Dehay", "Dominique", "", "IRMAR"], ["Hurd", "Harry L.", "", "STOR"], ["Makagon", "Andrzej", ""]]}, {"id": "1307.2662", "submitter": "Yuan Liao", "authors": "Jushan Bai, Yuan Liao", "title": "Statistical Inferences Using Large Estimated Covariances for Panel Data\n  and Factor Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While most of the convergence results in the literature on high dimensional\ncovariance matrix are concerned about the accuracy of estimating the covariance\nmatrix (and precision matrix), relatively less is known about the effect of\nestimating large covariances on statistical inferences. We study two important\nmodels: factor analysis and panel data model with interactive effects, and\nfocus on the statistical inference and estimation efficiency of structural\nparameters based on large covariance estimators. For efficient estimation, both\nmodels call for a weighted principle components (WPC), which relies on a high\ndimensional weight matrix. This paper derives an efficient and feasible WPC\nusing the covariance matrix estimator of Fan et al. (2013). However, we\ndemonstrate that existing results on large covariance estimation based on\nabsolute convergence are not suitable for statistical inferences of the\nstructural parameters. What is needed is some weighted consistency and the\nassociated rate of convergence, which are obtained in this paper. Finally, the\nproposed method is applied to the US divorce rate data. We find that the\nefficient WPC identifies the significant effects of divorce-law reforms on the\ndivorce rate, and it provides more accurate estimation and tighter confidence\nintervals than existing methods.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2013 03:38:26 GMT"}, {"version": "v2", "created": "Thu, 11 Jul 2013 11:47:38 GMT"}, {"version": "v3", "created": "Wed, 21 Aug 2013 21:45:30 GMT"}, {"version": "v4", "created": "Tue, 12 Nov 2013 14:18:11 GMT"}], "update_date": "2013-11-13", "authors_parsed": [["Bai", "Jushan", ""], ["Liao", "Yuan", ""]]}, {"id": "1307.3369", "submitter": "Sebastien Loustau", "authors": "S\\'ebastien Loustau (LAREMA), Cl\\'ement Marteau (IMT)", "title": "Noisy classification with boundary assumptions", "comments": "arXiv admin note: substantial text overlap with arXiv:1201.3283", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of classification when data are collected from two\nsamples with measurement errors. This problem turns to be an inverse problem\nand requires a specific treatment. In this context, we investigate the minimax\nrates of convergence using both a margin assumption, and a smoothness condition\non the boundary of the set associated to the Bayes classifier. We establish\nlower and upper bounds (based on a deconvolution classifier) on these rates.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jul 2013 08:36:11 GMT"}], "update_date": "2013-07-15", "authors_parsed": [["Loustau", "S\u00e9bastien", "", "LAREMA"], ["Marteau", "Cl\u00e9ment", "", "IMT"]]}, {"id": "1307.3375", "submitter": "Celine Labart", "authors": "Philippe Briand (LAMA), Edwige Id\\'ee (LAMA), C\\'eline Labart (LAMA)", "title": "An asymptotical method to estimate the parameters of a deteriorating\n  system under condition-based maintenance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we develop a new method to estimate the parameters of a\ndeteriorating system under perfect condition-based maintenance. This method is\nbased on the asymptotical behavior of the system, which is studied by using the\nrenewal process theory. We obtain a Central Limit Theorem (CLT in the\nfollowing) for the parameters. We compare the accuracy and the speed of the\nmethod with the maximum likelihood one (ML method in the following) on\ndifferent examples.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jul 2013 08:42:38 GMT"}], "update_date": "2013-07-15", "authors_parsed": [["Briand", "Philippe", "", "LAMA"], ["Id\u00e9e", "Edwige", "", "LAMA"], ["Labart", "C\u00e9line", "", "LAMA"]]}, {"id": "1307.3654", "submitter": "Lutz Mattner", "authors": "Abram M. Kagan, Yaakov Malinovsky, and Lutz Mattner", "title": "Partially complete sufficient statistics are jointly complete", "comments": "16 pages. Very minor changes (one more reference, abstract slightly\n  longer). To appear in Teoriya Veroyatnostei i ee Primeneniya", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The theory of the basic statistical concept of\n(Lehmann-Scheff\\'e-)completeness is perfected by providing the theorem\nindicated in the title and previously overlooked for several decades. Relations\nto earlier results are discussed and illustrating examples are presented.\n  Of the two proofs offered for the main result, the first is direct and short,\nfollowing the prototypical example of Landers and Rogge (1976), and the second\nis very short and purely statistical, utilizing the basic theory of optimal\nunbiased estimation in the little known version completed by Schmetterer and\nStrasser (1974).\n", "versions": [{"version": "v1", "created": "Sat, 13 Jul 2013 15:11:30 GMT"}, {"version": "v2", "created": "Fri, 23 May 2014 15:23:24 GMT"}], "update_date": "2014-05-26", "authors_parsed": [["Kagan", "Abram M.", ""], ["Malinovsky", "Yaakov", ""], ["Mattner", "Lutz", ""]]}, {"id": "1307.3730", "submitter": "Giles Hooker", "authors": "Giles Hooker", "title": "Consistency, efficiency and robustness of conditional disparity methods", "comments": "Published at http://dx.doi.org/10.3150/14-BEJ678 in the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2016, Vol. 22, No. 2, 857-900", "doi": "10.3150/14-BEJ678", "report-no": "IMS-BEJ-BEJ678", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers extensions of minimum-disparity estimators to the\nproblem of estimating parameters in a regression model that is conditionally\nspecified; that is where a parametric model describes the distribution of a\nresponse $y$ conditional on covariates $x$ but does not specify the\ndistribution of $x$. We define these estimators by estimating a non-parametric\nconditional density estimates and minimizing a disparity between this estimate\nand the parametric model averaged over values of $x$. The consistency and\nasymptotic normality of such estimators is demonstrated for a broad class of\nmodels in which response and covariate vectors can take both discrete and\ncontinuous values and incorportates a wide set of choices for kernel-based\nconditional density estimation. It also establishes the robustness of these\nestimators for a broad class of disparities. As has been observed in Tamura and\nBoos (J. Amer. Statist. Assoc. 81 (1986) 223--229), minimum disparity\nestimators incorporating kernel density estimates of more than one dimension\ncan result in an asymptotic bias that is larger that $n^{-1/2}$ and we\ncharacterize a similar bias in our results and show that in specialized cases\nit can be eliminated by appropriately centering the kernel density estimate. We\nalso demonstrate empirically that bootstrap methods can be employed to reduce\nthis bias and to provide robust confidence intervals. In order to demonstrate\nthese results, we establish a set of $L_1$-consistency results for kernel-based\nestimates of centered conditional densities.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jul 2013 11:54:44 GMT"}, {"version": "v2", "created": "Wed, 16 Apr 2014 13:37:09 GMT"}, {"version": "v3", "created": "Tue, 9 Feb 2016 10:28:29 GMT"}], "update_date": "2016-02-10", "authors_parsed": [["Hooker", "Giles", ""]]}, {"id": "1307.4101", "submitter": "Jose Acacio de Barros", "authors": "J. Acacio de Barros", "title": "Decision Making for Inconsistent Expert Judgments Using Negative\n  Probabilities", "comments": "14 pages, revised version to appear in the Proceedings of the QI2013\n  (Quantum Interactions) conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.OT cs.AI math.ST quant-ph stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we provide a simple random-variable example of inconsistent\ninformation, and analyze it using three different approaches: Bayesian,\nquantum-like, and negative probabilities. We then show that, at least for this\nparticular example, both the Bayesian and the quantum-like approaches have less\nnormative power than the negative probabilities one.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2013 20:53:57 GMT"}, {"version": "v2", "created": "Thu, 26 Sep 2013 03:47:47 GMT"}], "update_date": "2013-09-27", "authors_parsed": [["de Barros", "J. Acacio", ""]]}, {"id": "1307.4173", "submitter": "Wanyang Dai", "authors": "Xuebin Lu, Wanyang Dai", "title": "Stochastic integration for fractional Levy process and stochastic\n  differential equation driven by fractional Levy noise", "comments": "16 pages, Accepted by ACTA MATHEMATICA SCIENTIA (A): Chinese Series\n  (Chinese Journal of Mathematical Physics), 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math-ph math.DS math.MP math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, based on the white noise analysis of square integrable\npure-jump Levy process given by [1], we define the formal derivative of\nfractional Levy process defined by the square integrable pure-jump Levy process\nas the fractional Levy noises by considering fractional Levy process as the\ngeneralized functional of Levy process, and then we define the Skorohod\nintegral with respect to the fractional Levy process. Moreover, we propose a\nclass of stochastic Volterra equations driven by fractional Levy noises and\ninvestigate the existence and uniqueness of their solutions; In addition, we\npropose a class of stochastic differential equations driven by fractional Levy\nnoises and prove that under the Lipschtz and linear conditions there exists\nunique stochastic distribution-valued solution.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2013 06:12:25 GMT"}], "update_date": "2013-07-17", "authors_parsed": [["Lu", "Xuebin", ""], ["Dai", "Wanyang", ""]]}, {"id": "1307.4602", "submitter": "Giovanni Mana", "authors": "Giovanni Mana, Paolo Alberto Giuliano Albo, Simona Lago", "title": "Bayesian estimate of the degree of a polynomial given a noisy data\n  sample", "comments": "10 pages, 5 figures, submitted to Metrologia", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR physics.data-an stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A widely used method to create a continuous representation of a discrete\ndata-set is regression analysis. When the regression model is not based on a\nmathematical description of the physics underlying the data, heuristic\ntechniques play a crucial role and the model choice can have a significant\nimpact on the result. In this paper, the problem of identifying the most\nappropriate model is formulated and solved in terms of Bayesian selection.\nBesides, probability calculus is the best way to choose among different\nalternatives. The results obtained are applied to the case of both univariate\nand bivariate polynomials used as trial solutions of systems of thermodynamic\npartial differential equations.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2013 12:47:29 GMT"}], "update_date": "2013-07-18", "authors_parsed": [["Mana", "Giovanni", ""], ["Albo", "Paolo Alberto Giuliano", ""], ["Lago", "Simona", ""]]}, {"id": "1307.4621", "submitter": "Gyorgy Terdik DR", "authors": "Gy\\\"orgy Terdik", "title": "Trispectrum and higher order spectra for non-Gaussian homogenous and\n  isotropic field on the 2D-plane", "comments": "16 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.SP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study the non-Gaussian homogenous and isotropic field on the\nplane in frequency domain. The trispectrum and higher order spectra of such a\nfield are described in terms of Bessel functions. Poisson formulae are given\nfor the spectrum and for the bispectrum. Some particular integrals of Bessel\nfunctions are considered as well.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2013 13:32:53 GMT"}, {"version": "v2", "created": "Fri, 19 Jul 2013 06:40:47 GMT"}, {"version": "v3", "created": "Fri, 8 Apr 2016 22:08:06 GMT"}], "update_date": "2016-04-12", "authors_parsed": [["Terdik", "Gy\u00f6rgy", ""]]}, {"id": "1307.4625", "submitter": "Gyorgy Terdik DR", "authors": "E. Igl\\'oi and Gy. Terdik", "title": "When the bispectrum is real-valued", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let {X(t)} be a stationary time series with a.e. positive spectrum. Two\nconsequences of that the bispectrum of {X(t)} is real-valued but nonzero: 1) if\n{X(t)} is also linear, then it is reversible; 2) {X(t),} can not be causal\nlinear. A corollary of the first statement: if {X(t)} is linear, and the\nskewness of X(0) is nonzero, then third order reversibility implies\nreversibility. In this paper the notion of bispectrum is of a broader scope.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2013 13:42:23 GMT"}], "update_date": "2013-07-18", "authors_parsed": [["Igl\u00f3i", "E.", ""], ["Terdik", "Gy.", ""]]}, {"id": "1307.4666", "submitter": "Delaram Motamedvaziri", "authors": "D. Motamedvaziri, M.H. Rohban, V. Saligrama", "title": "Sparse Signal Recovery under Poisson Statistics", "comments": "13 pages, 11 figures, 2 tables, submitted to IEEE Transactions on\n  Signal Processing", "journal-ref": null, "doi": "10.1109/Allerton.2013.6736698", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are motivated by problems that arise in a number of applications such as\nOnline Marketing and explosives detection, where the observations are usually\nmodeled using Poisson statistics. We model each observation as a Poisson random\nvariable whose mean is a sparse linear superposition of known patterns. Unlike\nmany conventional problems observations here are not identically distributed\nsince they are associated with different sensing modalities. We analyze the\nperformance of a Maximum Likelihood (ML) decoder, which for our Poisson setting\ninvolves a non-linear optimization but yet is computationally tractable. We\nderive fundamental sample complexity bounds for sparse recovery when the\nmeasurements are contaminated with Poisson noise. In contrast to the\nleast-squares linear regression setting with Gaussian noise, we observe that in\naddition to sparsity, the scale of the parameters also fundamentally impacts\nsample complexity. We introduce a novel notion of Restricted Likelihood\nPerturbation (RLP), to jointly account for scale and sparsity. We derive sample\ncomplexity bounds for $\\ell_1$ regularized ML estimators in terms of RLP and\nfurther specialize these results for deterministic and random sensing matrix\ndesigns.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2013 15:12:22 GMT"}, {"version": "v2", "created": "Tue, 29 Jul 2014 14:49:17 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Motamedvaziri", "D.", ""], ["Rohban", "M. H.", ""], ["Saligrama", "V.", ""]]}, {"id": "1307.4765", "submitter": "Maxwell Grazier G'Sell", "authors": "Max Grazier G'Sell, Jonathan Taylor, Robert Tibshirani", "title": "Adaptive testing for the graphical lasso", "comments": "33 pages, 8 figures. Submitted to Annals of Statistics", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider tests of significance in the setting of the graphical lasso for\ninverse covariance matrix estimation. We propose a simple test statistic based\non a subsequence of the knots in the graphical lasso path. We show that this\nstatistic has an exponential asymptotic null distribution, under the null\nhypothesis that the model contains the true connected components.\n  Though the null distribution is asymptotic, we show through simulation that\nit provides a close approximation to the true distribution at reasonable sample\nsizes. Thus the test provides a simple, tractable test for the significance of\nnew edges as they are introduced into the model. Finally, we show connections\nbetween our results and other results for regularized regression, as well as\nextensions of our results to other correlation matrix based methods like\nsingle-linkage clustering.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2013 20:00:57 GMT"}, {"version": "v2", "created": "Mon, 22 Jul 2013 23:27:02 GMT"}], "update_date": "2013-07-24", "authors_parsed": [["G'Sell", "Max Grazier", ""], ["Taylor", "Jonathan", ""], ["Tibshirani", "Robert", ""]]}, {"id": "1307.4953", "submitter": "Guillaume Sagnol", "authors": "Guillaume Sagnol, Radoslav Harman", "title": "Computing exact $D$-optimal designs by mixed integer second-order cone\n  programming", "comments": "Published at http://dx.doi.org/10.1214/15-AOS1339 in the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2015, Vol. 43, No. 5, 2198-2224", "doi": "10.1214/15-AOS1339", "report-no": "IMS-AOS-AOS1339", "categories": "math.ST math.OC stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let the design of an experiment be represented by an $s$-dimensional vector\n$\\mathbf {w}$ of weights with nonnegative components. Let the quality of\n$\\mathbf {w}$ for the estimation of the parameters of the statistical model be\nmeasured by the criterion of $D$-optimality, defined as the $m$th root of the\ndeterminant of the information matrix $M(\\mathbf {w})=\\sum_{i=1}^sw_iA_iA_i^T$,\nwhere $A_i,i=1,\\ldots,s$ are known matrices with $m$ rows. In this paper, we\nshow that the criterion of $D$-optimality is second-order cone representable.\nAs a result, the method of second-order cone programming can be used to compute\nan approximate $D$-optimal design with any system of linear constraints on the\nvector of weights. More importantly, the proposed characterization allows us to\ncompute an exact $D$-optimal design, which is possible thanks to high-quality\nbranch-and-cut solvers specialized to solve mixed integer second-order cone\nprogramming problems. Our results extend to the case of the criterion of\n$D_K$-optimality, which measures the quality of $\\mathbf {w}$ for the\nestimation of a linear parameter subsystem defined by a full-rank coefficient\nmatrix $K$. We prove that some other widely used criteria are also second-order\ncone representable, for instance, the criteria of $A$-, $A_K$-, $G$- and\n$I$-optimality. We present several numerical examples demonstrating the\nefficiency and general applicability of the proposed method. We show that in\nmany cases the mixed integer second-order cone programming approach allows us\nto find a provably optimal exact design, while the standard heuristics\nsystematically miss the optimum.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2013 14:16:16 GMT"}, {"version": "v2", "created": "Sat, 28 Dec 2013 22:18:03 GMT"}, {"version": "v3", "created": "Thu, 15 Oct 2015 06:45:57 GMT"}], "update_date": "2015-10-16", "authors_parsed": [["Sagnol", "Guillaume", ""], ["Harman", "Radoslav", ""]]}, {"id": "1307.5231", "submitter": "Jim Griffin", "authors": "Jim E. Griffin and Philip J. Brown", "title": "Hierarchical sparsity priors for regression models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We focus on the increasingly important area of sparse regression problems\nwhere there are many variables and the effects of a large subset of these are\nnegligible. This paper describes the construction of hierarchical prior\ndistributions when the effects are considered related. These priors allow\ndependence between the regression coefficients and encourage related shrinkage\ntowards zero of different regression coefficients. The properties of these\npriors are discussed and applications to linear models with interactions and\ngeneralized additive models are used as illustrations. Ideas of heredity\nrelating different levels of interaction are encompassed.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2013 14:32:46 GMT"}, {"version": "v2", "created": "Tue, 22 Jul 2014 11:01:16 GMT"}], "update_date": "2014-07-23", "authors_parsed": [["Griffin", "Jim E.", ""], ["Brown", "Philip J.", ""]]}, {"id": "1307.5243", "submitter": "Gianluca Baio", "authors": "Gianluca Baio", "title": "Bayesian models for cost-effectiveness analysis in the presence of\n  structural zero costs", "comments": "15 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian modelling for cost-effectiveness data has received much attention in\nboth the health economics and the statistical literature in recent years.\nCost-effectiveness data are characterised by a relatively complex structure of\nrelationships linking the suitable measure of clinical benefit (\\eg QALYs) and\nthe associated costs. Simplifying assumptions, such as (bivariate) normality of\nthe underlying distributions are usually not granted, particularly for the cost\nvariable, which is characterised by markedly skewed distributions. In addition,\nindividual-level datasets are often characterised by the presence of structural\nzeros in the cost variable.\n  Hurdle models can be used to account for the presence of excess zeros in a\ndistribution and have been applied in the context of cost data. We extend their\napplication to cost-effectiveness data, defining a full Bayesian model which\nconsists of a selection model for the subjects with null costs, a marginal\nmodel for the costs and a conditional model for the measure of effectiveness\n(conditionally on the observed costs). The model is presented using a working\nexample to describe its main features.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2013 14:53:06 GMT"}], "update_date": "2013-07-22", "authors_parsed": [["Baio", "Gianluca", ""]]}, {"id": "1307.5286", "submitter": "Matthieu Solnon", "authors": "Matthieu Solnon (LIENS, INRIA Paris - Rocquencourt)", "title": "Comparison bewteen multi-task and single-task oracle risks in kernel\n  ridge regression", "comments": "Submitted to the Electronic Journal of Statistics", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study multi-task kernel ridge regression and try to\nunderstand when the multi-task procedure performs better than the single-task\none, in terms of averaged quadratic risk. In order to do so, we compare the\nrisks of the estimators with perfect calibration, the \\emph{oracle risk}. We\nare able to give explicit settings, favorable to the multi-task procedure,\nwhere the multi-task oracle performs better than the single-task one. In\nsituations where the multi-task procedure is conjectured to perform badly, we\nalso show the oracle does so. We then complete our study with simulated\nexamples, where we can compare both oracle risks in more natural situations. A\nconsequence of our result is that the multi-task ridge estimator has a lower\nrisk than any single-task estimator, in favorable situations.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2013 17:25:30 GMT"}], "update_date": "2013-07-22", "authors_parsed": [["Solnon", "Matthieu", "", "LIENS, INRIA Paris - Rocquencourt"]]}, {"id": "1307.5476", "submitter": "Masoud  Nasari", "authors": "Miklos Csorgo and Masoud M Nasari", "title": "Bootstrapped Pivots for Sample and Population Means and Distribution\n  Functions", "comments": "50 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce the concept of bootstrapped pivots for the sample\nand the population means. This is in contrast to the classical method of\nconstructing bootstrapped confidence intervals for the population mean via\nestimating the cutoff points via drawing a number of bootstrap sub-samples. We\nshow that this new method leads to constructing asymptotic confidence intervals\nwith significantly smaller error in comparison to both of the traditional\nt-intervals and the classical bootstrapped confidence intervals. The approach\ntaken in this paper relates naturally to super-population modeling, as well as\nto estimating empirical and theoretical distributions.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jul 2013 23:18:47 GMT"}], "update_date": "2013-07-23", "authors_parsed": [["Csorgo", "Miklos", ""], ["Nasari", "Masoud M", ""]]}, {"id": "1307.5574", "submitter": "Jeremy Sumner", "authors": "Peter D Jarvis and Jeremy G Sumner", "title": "Matrix group structure and Markov invariants in the strand symmetric\n  phylogenetic substitution model", "comments": "v2: Major revision now includes explicit forms for quadratic and\n  cubic Markov invariants", "journal-ref": "J Mathematical Biology (Online First, Dec 2015)", "doi": "10.1007/s00285-015-0951-7", "report-no": null, "categories": "q-bio.PE math.RT math.ST q-bio.QM stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the continuous-time presentation of the strand symmetric\nphylogenetic substitution model (in which rate parameters are unchanged under\nnucleotide permutations given by Watson-Crick base conjugation). Algebraic\nanalysis of the model's underlying structure as a matrix group leads to a\nchange of basis where the rate generator matrix is given by a two-part block\ndecomposition. We apply representation theoretic techniques and, for any\n(fixed) number of phylogenetic taxa $L$ and polynomial degree $D$ of interest,\nprovide the means to classify and enumerate the associated Markov invariants.\nIn particular, in the quadratic and cubic cases we prove there are precisely\n1/3$(3^L+(-1)^L)$ and $6^{L-1}$ linearly independent Markov invariants,\nrespectively. Additionally, we give the explicit polynomial forms of the Markov\ninvariants for (i) the quadratic case with any number of taxa $L$, and (ii) the\ncubic case in the special case of a three-taxa phylogenetic tree. We close by\nshowing our results are of practical interest since the quadratic Markov\ninvariants provide independent estimates of phylogenetic distances based on (i)\nsubstitution rates within Watson-Crick conjugate pairs, and (ii) substitution\nrates across conjugate base pairs.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2013 00:51:40 GMT"}, {"version": "v2", "created": "Tue, 28 Oct 2014 05:55:19 GMT"}], "update_date": "2016-02-11", "authors_parsed": [["Jarvis", "Peter D", ""], ["Sumner", "Jeremy G", ""]]}, {"id": "1307.5706", "submitter": "Daniel Vogel", "authors": "Alexander D\\\"urre, Daniel Vogel, David E. Tyler", "title": "The spatial sign covariance matrix with unknown location", "comments": "14 pages, 3 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The consistency and asymptotic normality of the spatial sign covariance\nmatrix with unknown location are shown. Simulations illustrate the different\nasymptotic behavior when using the mean and the spatial median as location\nestimator.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2013 13:42:45 GMT"}, {"version": "v2", "created": "Tue, 15 Apr 2014 17:40:27 GMT"}], "update_date": "2014-04-16", "authors_parsed": [["D\u00fcrre", "Alexander", ""], ["Vogel", "Daniel", ""], ["Tyler", "David E.", ""]]}, {"id": "1307.5962", "submitter": "Serdar Altok", "authors": "Serdar Altok", "title": "Unimodularity for multi-type Galton-Watson trees", "comments": "Published in at http://dx.doi.org/10.3150/11-BEJ416 the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2013, Vol. 19, No. 3, 780-802", "doi": "10.3150/11-BEJ416", "report-no": "IMS-BEJ-BEJ416", "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fix $n\\in\\mathbb{N}$. Let $\\mathbf{T}_n$ be the set of rooted trees $(T,o)$\nwhose vertices are labeled by elements of $\\{1,...,n\\}$. Let $\\nu$ be a\nstrongly connected multi-type Galton-Watson measure. We give necessary and\nsufficient conditions for the existence of a measure $\\mu$ that is reversible\nfor simple random walk on $\\mathbf{T}_n$ and has the property that given the\nlabels of the root and its neighbors, the descendant subtrees rooted at the\nneighbors of the root are independent multi-type Galton-Watson trees with\nconditional offspring distributions that are the same as the conditional\noffspring distributions of $\\nu$ when the types are $\\nu$ are ordered pairs of\nelements of $[n]$. If the types of $\\nu$ are given by the labels of vertices,\nthen we give an explicit description of such $\\mu$.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2013 07:19:48 GMT"}], "update_date": "2013-07-24", "authors_parsed": [["Altok", "Serdar", ""]]}, {"id": "1307.5965", "submitter": "Enkelejd Hashorva", "authors": "Enkelejd Hashorva", "title": "Minima and maxima of elliptical arrays and spherical processes", "comments": "Published in at http://dx.doi.org/10.3150/12-BEJ463 the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2013, Vol. 19, No. 3, 886-904", "doi": "10.3150/12-BEJ463", "report-no": "IMS-BEJ-BEJ463", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate first the asymptotics of the minima of\nelliptical triangular arrays. Motivated by the findings of Kabluchko (Extremes\n14 (2011) 285-310), we discuss further the asymptotic behaviour of the maxima\nof elliptical triangular arrays with marginal distribution functions in the\nGumbel or Weibull max-domain of attraction. We present an application\nconcerning the asymptotics of the maximum and the minimum of independent\nspherical processes.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2013 07:34:11 GMT"}], "update_date": "2013-07-24", "authors_parsed": [["Hashorva", "Enkelejd", ""]]}, {"id": "1307.5971", "submitter": "Adrian Baddeley", "authors": "Adrian Baddeley, David Dereudre", "title": "Variational estimators for the parameters of Gibbs point process models", "comments": "Published in at http://dx.doi.org/10.3150/12-BEJ419 the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2013, Vol. 19, No. 3, 905-930", "doi": "10.3150/12-BEJ419", "report-no": "IMS-BEJ-BEJ419", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a new estimation technique for fitting parametric Gibbs\npoint process models to a spatial point pattern dataset. The technique is a\ncounterpart, for spatial point processes, of the variational estimators for\nMarkov random fields developed by Almeida and Gidas. The estimator does not\nrequire the point process density to be hereditary, so it is applicable to\nmodels which do not have a conditional intensity, including models which\nexhibit geometric regularity or rigidity. The disadvantage is that the\nintensity parameter cannot be estimated: inference is effectively conditional\non the observed number of points. The new procedure is faster and more stable\nthan existing techniques, since it does not require simulation, numerical\nintegration or optimization with respect to the parameters.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2013 08:11:42 GMT"}], "update_date": "2013-07-24", "authors_parsed": [["Baddeley", "Adrian", ""], ["Dereudre", "David", ""]]}, {"id": "1307.5976", "submitter": "Michael Kohler", "authors": "Michael Kohler, Harro Walk", "title": "On data-based optimal stopping under stationarity and ergodicity", "comments": "Published in at http://dx.doi.org/10.3150/12-BEJ439 the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2013, Vol. 19, No. 3, 931-953", "doi": "10.3150/12-BEJ439", "report-no": "IMS-BEJ-BEJ439", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of optimal stopping with finite horizon in discrete time is\nconsidered in view of maximizing the expected gain. The algorithm proposed in\nthis paper is completely nonparametric in the sense that it uses observed data\nfrom the past of the process up to time $-n+1$, $n\\in\\mathbb{N}$, not relying\non any specific model assumption. Kernel regression estimation of conditional\nexpectations and prediction theory of individual sequences are used as tools.\nIt is shown that the algorithm is universally consistent: the achieved expected\ngain converges to the optimal value for $n\\to\\infty$ whenever the underlying\nprocess is stationary and ergodic. An application to exercising American\noptions is given, and the algorithm is illustrated by simulated data.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2013 08:42:54 GMT"}], "update_date": "2013-07-24", "authors_parsed": [["Kohler", "Michael", ""], ["Walk", "Harro", ""]]}, {"id": "1307.5982", "submitter": "Hanxiang Peng", "authors": "Hanxiang Peng, Anton Schick", "title": "Empirical likelihood approach to goodness of fit testing", "comments": "Published in at http://dx.doi.org/10.3150/12-BEJ440 the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2013, Vol. 19, No. 3, 954-981", "doi": "10.3150/12-BEJ440", "report-no": "IMS-BEJ-BEJ440", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by applications to goodness of fit testing, the empirical\nlikelihood approach is generalized to allow for the number of constraints to\ngrow with the sample size and for the constraints to use estimated criteria\nfunctions. The latter is needed to deal with nuisance parameters. The proposed\nempirical likelihood based goodness of fit tests are asymptotically\ndistribution free. For univariate observations, tests for a specified\ndistribution, for a distribution of parametric form, and for a symmetric\ndistribution are presented. For bivariate observations, tests for independence\nare developed.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2013 09:05:50 GMT"}], "update_date": "2013-07-24", "authors_parsed": [["Peng", "Hanxiang", ""], ["Schick", "Anton", ""]]}, {"id": "1307.5990", "submitter": "Mark S. Veillette", "authors": "Mark S. Veillette, Murad S. Taqqu", "title": "Properties and numerical evaluation of the Rosenblatt distribution", "comments": "Published in at http://dx.doi.org/10.3150/12-BEJ421 the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2013, Vol. 19, No. 3, 982-1005", "doi": "10.3150/12-BEJ421", "report-no": "IMS-BEJ-BEJ421", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies various distributional properties of the Rosenblatt\ndistribution. We begin by describing a technique for computing the cumulants.\nWe then study the expansion of the Rosenblatt distribution in terms of shifted\nchi-squared distributions. We derive the coefficients of this expansion and use\nthese to obtain the L\\'{e}vy-Khintchine formula and derive asymptotic\nproperties of the L\\'{e}vy measure. This allows us to compute the cumulants,\nmoments, coefficients in the chi-square expansion and the density and\ncumulative distribution functions of the Rosenblatt distribution with a high\ndegree of precision. Tables are provided and software written to implement the\nmethods described here is freely available by request from the authors.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2013 09:34:28 GMT"}], "update_date": "2013-07-24", "authors_parsed": [["Veillette", "Mark S.", ""], ["Taqqu", "Murad S.", ""]]}, {"id": "1307.5992", "submitter": "Felix Abramovich", "authors": "Felix Abramovich and Tal Lahav", "title": "Sparse additive regression on a regular lattice", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider estimation in a sparse additive regression model with the design\npoints on a regular lattice. We establish the minimax convergence rates over\nSobolev classes and propose a Fourier-based rate-optimal estimator which is\nadaptive to the unknown sparsity and smoothness of the response function. The\nestimator is derived within Bayesian formalism but can be naturally viewed as a\npenalized maximum likelihood estimator with the complexity penalties on the\nnumber of nonzero univariate additive components of the response and on the\nnumbers of the nonzero coefficients of their Fourer expansions. We compare it\nwith several existing counterparts and perform a short simulation study to\ndemonstrate its performance.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2013 09:36:51 GMT"}, {"version": "v2", "created": "Tue, 1 Apr 2014 13:38:35 GMT"}], "update_date": "2014-04-02", "authors_parsed": [["Abramovich", "Felix", ""], ["Lahav", "Tal", ""]]}, {"id": "1307.6044", "submitter": "Weidong Liu", "authors": "Weidong Liu, Qi-Man Shao, Qiying Wang", "title": "Self-normalized Cram\\'{e}r type moderate deviations for the maximum of\n  sums", "comments": "Published in at http://dx.doi.org/10.3150/12-BEJ415 the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2013, Vol. 19, No. 3, 1006-1027", "doi": "10.3150/12-BEJ415", "report-no": "IMS-BEJ-BEJ415", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $X_1,X_2,...$ be independent random variables with zero means and finite\nvariances, and let $S_n=\\sum_{i=1}^nX_i$ and $V^2_n=\\sum_{i=1}^nX^2_i$. A\nCram\\'{e}r type moderate deviation for the maximum of the self-normalized sums\n$\\max_{1\\leq k\\leq n}S_k/V_n$ is obtained. In particular, for identically\ndistributed $X_1,X_2,...,$ it is proved that $P(\\max_{1\\leq k\\leq n}S_k\\geq\nxV_n)/(1-\\Phi (x))\\rightarrow2$ uniformly for $0<x\\leq\\mathrm{o}(n^{1/6})$\nunder the optimal finite third moment of $X_1$.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2013 12:41:33 GMT"}], "update_date": "2013-07-24", "authors_parsed": [["Liu", "Weidong", ""], ["Shao", "Qi-Man", ""], ["Wang", "Qiying", ""]]}, {"id": "1307.6188", "submitter": "Jose Perea", "authors": "Jose Perea, John Harer", "title": "Sliding Windows and Persistence: An Application of Topological Methods\n  to Signal Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop in this paper a theoretical framework for the topological study of\ntime series data. Broadly speaking, we describe geometrical and topological\nproperties of sliding window (or time-delay) embeddings, as seen through the\nlens of persistent homology. In particular, we show that maximum persistence at\nthe point-cloud level can be used to quantify periodicity at the signal level,\nprove structural and convergence theorems for the resulting persistence\ndiagrams, and derive estimates for their dependency on window size and\nembedding dimension. We apply this methodology to quantifying periodicity in\nsynthetic data sets, and compare the results with those obtained using\nstate-of-the-art methods in gene expression analysis. We call this new method\nSW1PerS which stands for Sliding Windows and 1-dimensional Persistence Scoring.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2013 18:46:59 GMT"}, {"version": "v2", "created": "Mon, 25 Nov 2013 19:13:31 GMT"}], "update_date": "2013-11-26", "authors_parsed": [["Perea", "Jose", ""], ["Harer", "John", ""]]}, {"id": "1307.6332", "submitter": "Ole E. Barndorff-Nielsen", "authors": "Ole E. Barndorff-Nielsen, Fred Espen Benth, Almut E. D. Veraart", "title": "Modelling energy spot prices by volatility modulated L\\'{e}vy-driven\n  Volterra processes", "comments": "Published in at http://dx.doi.org/10.3150/12-BEJ476 the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2013, Vol. 19, No. 3, 803-845", "doi": "10.3150/12-BEJ476", "report-no": "IMS-BEJ-BEJ476", "categories": "q-fin.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces the class of volatility modulated L\\'{e}vy-driven\nVolterra (VMLV) processes and their important subclass of L\\'{e}vy\nsemistationary (LSS) processes as a new framework for modelling energy spot\nprices. The main modelling idea consists of four principles: First,\ndeseasonalised spot prices can be modelled directly in stationarity. Second,\nstochastic volatility is regarded as a key factor for modelling energy spot\nprices. Third, the model allows for the possibility of jumps and extreme spikes\nand, lastly, it features great flexibility in terms of modelling the\nautocorrelation structure and the Samuelson effect. We provide a detailed\nanalysis of the probabilistic properties of VMLV processes and show how they\ncan capture many stylised facts of energy markets. Further, we derive forward\nprices based on our new spot price models and discuss option pricing. An\nempirical example based on electricity spot prices from the European Energy\nExchange confirms the practical relevance of our new modelling framework.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2013 08:45:00 GMT"}], "update_date": "2013-07-25", "authors_parsed": [["Barndorff-Nielsen", "Ole E.", ""], ["Benth", "Fred Espen", ""], ["Veraart", "Almut E. D.", ""]]}, {"id": "1307.6338", "submitter": "Zsolt Talata", "authors": "Zsolt Talata", "title": "Divergence rates of Markov order estimators and their application to\n  statistical estimation of stationary ergodic processes", "comments": "Published in at http://dx.doi.org/10.3150/12-BEJ468 the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2013, Vol. 19, No. 3, 846-885", "doi": "10.3150/12-BEJ468", "report-no": "IMS-BEJ-BEJ468", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stationary ergodic processes with finite alphabets are estimated by finite\nmemory processes from a sample, an n-length realization of the process, where\nthe memory depth of the estimator process is also estimated from the sample\nusing penalized maximum likelihood (PML). Under some assumptions on the\ncontinuity rate and the assumption of non-nullness, a rate of convergence in\n$\\bar{d}$-distance is obtained, with explicit constants. The result requires an\nanalysis of the divergence of PML Markov order estimators for not necessarily\nfinite memory processes. This divergence problem is investigated in more\ngenerality for three information criteria: the Bayesian information criterion\nwith generalized penalty term yielding the PML, and the normalized maximum\nlikelihood and the Krichevsky-Trofimov code lengths. Lower and upper bounds on\nthe estimated order are obtained. The notion of consistent Markov order\nestimation is generalized for infinite memory processes using the concept of\noracle order estimates, and generalized consistency of the PML Markov order\nestimator is presented.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2013 09:02:00 GMT"}], "update_date": "2013-07-25", "authors_parsed": [["Talata", "Zsolt", ""]]}, {"id": "1307.6501", "submitter": "Cees de Valk", "authors": "Cees de Valk", "title": "Approximation of high quantiles from intermediate quantiles", "comments": null, "journal-ref": "Extremes 19(4) 661-686 (2016)", "doi": "10.1007/s10687-016-0255-3", "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by applications requiring quantile estimates for very small\nprobabilities of exceedance, this article addresses estimation of high\nquantiles for probabilities bounded by powers of sample size with exponents\nbelow -1. As regularity assumption, an alternative to the Generalised Pareto\ntail limit is explored for this purpose. Motivation for the alternative\nregularity assumption is provided, and it is shown to be equivalent to a limit\nrelation for the logarithm of survival function, the log-GW tail limit, which\ngeneralises the GW (Generalised Weibull) tail limit, a generalisation of the\nWeibull tail limit. The domain of attraction is described, and convergence\nresults are presented for quantile approximation and for a simple quantile\nestimator based on the log-GW tail. Simulations are presented, and advantages\nand limitations of log-GW-based estimation of high quantiles are indicated.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2013 17:26:44 GMT"}, {"version": "v2", "created": "Thu, 17 Jul 2014 22:19:28 GMT"}, {"version": "v3", "created": "Thu, 3 Dec 2015 20:17:47 GMT"}, {"version": "v4", "created": "Tue, 15 Mar 2016 08:33:05 GMT"}], "update_date": "2017-02-23", "authors_parsed": [["de Valk", "Cees", ""]]}, {"id": "1307.6512", "submitter": "Lav Varshney", "authors": "Kush R. Varshney and Lav R. Varshney", "title": "Optimal Grouping for Group Minimax Hypothesis Testing", "comments": "12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian hypothesis testing and minimax hypothesis testing represent extreme\ninstances of detection in which the prior probabilities of the hypotheses are\neither completely and precisely known, or are completely unknown. Group\nminimax, also known as Gamma-minimax, is a robust intermediary between Bayesian\nand minimax hypothesis testing that allows for coarse or partial advance\nknowledge of the hypothesis priors by using information on sets in which the\nprior lies. Existing work on group minimax, however, does not consider the\nquestion of how to define the sets or groups of priors; it is assumed that the\ngroups are given. In this work, we propose a novel intermediate detection\nscheme formulated through the quantization of the space of prior probabilities\nthat optimally determines groups and also representative priors within the\ngroups. We show that when viewed from a quantization perspective, group minimax\namounts to determining centroids with a minimax Bayes risk error divergence\ndistortion criterion: the appropriate Bregman divergence for this task.\nMoreover, the optimal partitioning of the space of prior probabilities is a\nBregman Voronoi diagram. Together, the optimal grouping and representation\npoints are an epsilon-net with respect to Bayes risk error divergence, and\npermit a rate-distortion type asymptotic analysis of detection performance with\nthe number of groups. Examples of detecting signals corrupted by additive white\nGaussian noise and of distinguishing exponentially-distributed signals are\npresented.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2013 18:08:49 GMT"}], "update_date": "2013-07-25", "authors_parsed": [["Varshney", "Kush R.", ""], ["Varshney", "Lav R.", ""]]}, {"id": "1307.6522", "submitter": "Mu Zhu", "authors": "Mu Zhu", "title": "When is the majority-vote classifier beneficial?", "comments": "Submitted to \"The American Statistician\", January 2013; revised, July\n  2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In his seminal work, Schapire (1990) proved that weak classifiers could be\nimproved to achieve arbitrarily high accuracy, but he never implied that a\nsimple majority-vote mechanism could always do the trick. By comparing the\nasymptotic misclassification error of the majority-vote classifier with the\naverage individual error, we discover an interesting phase-transition\nphenomenon. For binary classification with equal prior probabilities, our\nresult implies that, for the majority-vote mechanism to work, the collection of\nweak classifiers must meet the minimum requirement of having an average true\npositive rate of at least 50% and an average false positive rate of at most\n50%.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2013 18:33:51 GMT"}], "update_date": "2013-07-25", "authors_parsed": [["Zhu", "Mu", ""]]}, {"id": "1307.6610", "submitter": "Mathias Trabs", "authors": "Mathias Trabs", "title": "Information bounds for inverse problems with application to\n  deconvolution and L\\'evy models", "comments": "To appear in Annales de l'Institut Henri Poincar\\'e", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  If a functional in an inverse problem can be estimated with parametric rate,\nthen the minimax rate gives no information about the ill-posedness of the\nproblem. To have a more precise lower bound, we study semiparametric efficiency\nin the sense of H\\'ajek-Le Cam for functional estimation in regular indirect\nmodels. These are characterized as models that can be locally approximated by a\nlinear white noise model that is described by the generalized score operator. A\nconvolution theorem for regular indirect models is proved. This applies to a\nlarge class of statistical inverse problems, which is illustrated for the\nprototypical white noise and deconvolution model. It is especially useful for\nnonlinear models. We discuss in detail a nonlinear model of deconvolution type\nwhere a L\\'evy process is observed at low frequency, concluding an information\nbound for the estimation of linear functionals of the jump measure.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2013 23:37:54 GMT"}, {"version": "v2", "created": "Tue, 6 May 2014 14:37:14 GMT"}], "update_date": "2014-05-07", "authors_parsed": [["Trabs", "Mathias", ""]]}, {"id": "1307.6685", "submitter": "Nzouankeu Nana Giles-Arnaud", "authors": "Giles-Arnaud Nzouankeu Nana, Ralf Korn and Christina Erlwein-Sayer", "title": "GARCH-extended models: theoretical properties and applications", "comments": "submitted to Journal of Econometrics", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is concerned with some properties of the generalized GARCH models,\nobtained by extending GARCH models with exogenous variables, the so-called\nGARCH extended (GARCHX) models. For these, we establish sufficient conditions\nfor some properties such as stationarity, existence of moments, ergodicity,\ngeometric ergodicity, consistence and asymptotic normality of likelihood\nestimators of the model parameters. For some of these properties we show that\nthe conditions that we propose are also necessary. We further provide examples\nand applications to illustrate and highlight the importance of our findings.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2013 10:01:27 GMT"}], "update_date": "2013-07-26", "authors_parsed": [["Nana", "Giles-Arnaud Nzouankeu", ""], ["Korn", "Ralf", ""], ["Erlwein-Sayer", "Christina", ""]]}, {"id": "1307.6701", "submitter": "Fabian Dunker", "authors": "Fabian Dunker, Jean-Pierre Florens, Thorsten Hohage, Jan Johannes,\n  Enno Mammen", "title": "Iterative Estimation of Solutions to Noisy Nonlinear Operator Equations\n  in Nonparametric Instrumental Regression", "comments": null, "journal-ref": "Journal of Econometrics , 2014, 178, 444-455", "doi": "10.1016/j.jeconom.2013.06.001", "report-no": null, "categories": "math.NA math.ST stat.CO stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper discusses the solution of nonlinear integral equations with noisy\nintegral kernels as they appear in nonparametric instrumental regression. We\npropose a regularized Newton-type iteration and establish convergence and\nconvergence rate results. A particular emphasis is on instrumental regression\nmodels where the usual conditional mean assumption is replaced by a stronger\nindependence assumption. We demonstrate for the case of a binary instrument\nthat our approach allows the correct estimation of regression functions which\nare not identifiable with the standard model. This is illustrated in computed\nexamples with simulated data.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2013 11:25:11 GMT"}], "update_date": "2015-04-01", "authors_parsed": [["Dunker", "Fabian", ""], ["Florens", "Jean-Pierre", ""], ["Hohage", "Thorsten", ""], ["Johannes", "Jan", ""], ["Mammen", "Enno", ""]]}, {"id": "1307.6835", "submitter": "Bertrand Iooss", "authors": "Guillaume Damblin, Mathieu Couplet (EDF R\\&D), Bertrand Iooss (-\n  M\\'ethodes d'Analyse Stochastique des Codes et Traitements Num\\'eriques)", "title": "Numerical studies of space filling designs: optimization of Latin\n  Hypercube Samples and subprojection properties", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantitative assessment of the uncertainties tainting the results of computer\nsimulations is nowadays a major topic of interest in both industrial and\nscientific communities. One of the key issues in such studies is to get\ninformation about the output when the numerical simulations are expensive to\nrun. This paper considers the problem of exploring the whole space of\nvariations of the computer model input variables in the context of a large\ndimensional exploration space. Various properties of space filling designs are\njustified: interpoint-distance, discrepancy, minimum spanning tree criteria. A\nspecific class of design, the optimized Latin Hypercube Sample, is considered.\nSeveral optimization algorithms, coming from the literature, are studied in\nterms of convergence speed, robustness to subprojection and space filling\nproperties of the resulting design. Some recommendations for building such\ndesigns are given. Finally, another contribution of this paper is the deep\nanalysis of the space filling properties of the design 2D-subprojections.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2013 18:35:59 GMT"}], "update_date": "2013-07-26", "authors_parsed": [["Damblin", "Guillaume", "", "EDF R\\&D"], ["Couplet", "Mathieu", "", "EDF R\\&D"], ["Iooss", "Bertrand", "", "-\n  M\u00e9thodes d'Analyse Stochastique des Codes et Traitements Num\u00e9riques"]]}, {"id": "1307.6836", "submitter": "Nicolas Chauffert", "authors": "Nicolas Chauffert (INRIA Saclay - Ile de France), Philippe Ciuciu\n  (INRIA Saclay - Ile de France), Pierre Weiss (ITAV)", "title": "Variable Density Compressed Sensing In MRI. Theoretical vs Heuristic\n  Sampling Strategies", "comments": "ISBI - 10th International Symposium on Biomedical Imaging (2013)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The structure of Magnetic Resonance Images (MRI) and especially their\ncompressibility in an appropriate representation basis enables the application\nof the compressive sensing theory, which guarantees exact image recovery from\nincomplete measurements. According to recent theoretical conditions on the\nreconstruction guarantees, the optimal strategy is to downsample the k-space\nusing an independent drawing of the acquisition basis entries. Here, we first\nbring a novel answer to the synthesis problem, which amounts to deriving the\nop- timal distribution (according to a given criterion) from which the data\nshould be sampled. Then, given that the sparsity hypothesis is not fulfilled in\nthe k-space center in MRI, we extend this approach by densely sampling this\ncenter and drawing the remaining samples from the optimal distribution. We\ncompare this theoretical approach to heuristic strategies, and show that the\nproposed two-stage process drastically improves reconstruction results on\nanatomical MRI.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2013 18:37:29 GMT"}], "update_date": "2013-07-26", "authors_parsed": [["Chauffert", "Nicolas", "", "INRIA Saclay - Ile de France"], ["Ciuciu", "Philippe", "", "INRIA Saclay - Ile de France"], ["Weiss", "Pierre", "", "ITAV"]]}, {"id": "1307.6865", "submitter": "Radhendushka Srivastava", "authors": "Radhendushka Srivastava and Ping Li", "title": "Effect of sampling on the estimation of drift parameter of continuous\n  time AR(1) processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the effect of stochastic sampling on the estimation of the drift\nparameter of continuous time AR(1) process. A natural distribution free moment\nestimator is considered for the drift based on stochastically observed time\npoints. The effect of the constraint of the minimum separation between\nsuccessive samples on the estimation of the drift is studied.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2013 20:04:11 GMT"}], "update_date": "2013-07-29", "authors_parsed": [["Srivastava", "Radhendushka", ""], ["Li", "Ping", ""]]}, {"id": "1307.7054", "submitter": "Mohamed EL MACHKOURI", "authors": "Mohamed El Machkouri (LMRS)", "title": "On the asymptotic normality of frequency polygons for strongly mixing\n  spatial processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper establishes the asymptotic normality of frequency polygons in the\ncontext of stationary strongly mixing random fields indexed by $\\Z^d$. Our\nmethod allows us to consider only minimal conditions on the width bins and\nprovides a simple criterion on the mixing coefficients. In particular, we\nimprove in several directions a previous result by Carbon, Francq and Tran\n(2010).\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2013 14:48:11 GMT"}], "update_date": "2013-07-29", "authors_parsed": [["Machkouri", "Mohamed El", "", "LMRS"]]}, {"id": "1307.7624", "submitter": "Steven Ellis", "authors": "Steven P. Ellis", "title": "Singularity of Data Analytic Operations", "comments": "395 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical data by their very nature are indeterminate in the sense that if\none repeated the process of collecting the data the new data set would be\nsomewhat different from the original. Therefore, a statistical method, a map\n$\\Phi$ taking a data set $x$ to a point in some space F, should be stable at\n$x$: Small perturbations in $x$ should result in a small change in $\\Phi(x)$.\nOtherwise, $\\Phi$ is useless at $x$ or -- and this is important -- near $x$. So\none doesn't want $\\Phi$ to have \"singularities,\" data sets $x$ such that the\nthe limit of $\\Phi(y)$ as $y$ approaches $x$ doesn't exist. (Yes, the same\nissue arises elsewhere in applied math.)\n  However, broad classes of statistical methods have topological obstructions\nof continuity: They must have singularities. We show why and give lower bounds\non the Hausdorff dimension, even Hausdorff measure, of the set of singularities\nof such data maps. There seem to be numerous examples.\n  We apply mainly topological methods to study the (topological) singularities\nof functions defined (on dense subsets of) \"data spaces\" and taking values in\nspaces with nontrivial homology. At least in this book, data spaces are usually\ncompact manifolds. The purpose is to gain insight into the numerical\nconditioning of statistical description, data summarization, and inference and\nlearning methods. We prove general results that can often be used to bound\nbelow the dimension of the singular set. We apply our topological results to\ndevelop lower bounds on Hausdorff measure of the singular set. We apply these\nmethods to the study of plane fitting and measuring location of data on\nspheres.\n  This is not a \"final\" version, merely another attempt.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jul 2013 15:48:54 GMT"}, {"version": "v2", "created": "Mon, 3 Aug 2015 15:24:30 GMT"}, {"version": "v3", "created": "Fri, 18 Oct 2019 19:15:48 GMT"}, {"version": "v4", "created": "Mon, 23 Dec 2019 19:45:17 GMT"}, {"version": "v5", "created": "Wed, 12 May 2021 12:51:07 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Ellis", "Steven P.", ""]]}, {"id": "1307.7650", "submitter": "Johanna F. Ziegel", "authors": "Johanna F. Ziegel and Tilmann Gneiting", "title": "Copula Calibration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose notions of calibration for probabilistic forecasts of general\nmultivariate quantities. Probabilistic copula calibration is a natural analogue\nof probabilistic calibration in the univariate setting. It can be assessed\nempirically by checking for the uniformity of the copula probability integral\ntransform (CopPIT), which is invariant under coordinate permutations and\ncoordinatewise strictly monotone transformations of the predictive distribution\nand the outcome. The CopPIT histogram can be interpreted as a generalization\nand variant of the multivariate rank histogram, which has been used to check\nthe calibration of ensemble forecasts. Climatological copula calibration is an\nanalogue of marginal calibration in the univariate setting. Methods and tools\nare illustrated in a simulation study and applied to compare raw numerical\nmodel and statistically postprocessed ensemble forecasts of bivariate wind\nvectors.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jul 2013 17:23:19 GMT"}], "update_date": "2013-07-30", "authors_parsed": [["Ziegel", "Johanna F.", ""], ["Gneiting", "Tilmann", ""]]}, {"id": "1307.7666", "submitter": "Sivaraman Balakrishnan", "authors": "Sivaraman Balakrishnan, Alessandro Rinaldo, Aarti Singh and Larry\n  Wasserman", "title": "Tight Lower Bounds for Homology Inference", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The homology groups of a manifold are important topological invariants that\nprovide an algebraic summary of the manifold. These groups contain rich\ntopological information, for instance, about the connected components, holes,\ntunnels and sometimes the dimension of the manifold. In earlier work, we have\nconsidered the statistical problem of estimating the homology of a manifold\nfrom noiseless samples and from noisy samples under several different noise\nmodels. We derived upper and lower bounds on the minimax risk for this problem.\nIn this note we revisit the noiseless case. In previous work we used Le Cam's\nlemma to establish a lower bound that differed from the upper bound of Niyogi,\nSmale and Weinberger by a polynomial factor in the condition number.\n  In this note we use a different construction based on the direct analysis of\nthe likelihood ratio test to show that the upper bound of Niyogi, Smale and\nWeinberger is in fact tight, thus establishing rate optimal asymptotic minimax\nbounds for the problem. The techniques we use here extend in a straightforward\nway to the noisy settings considered in our earlier work.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jul 2013 17:57:33 GMT"}], "update_date": "2013-07-30", "authors_parsed": [["Balakrishnan", "Sivaraman", ""], ["Rinaldo", "Alessandro", ""], ["Singh", "Aarti", ""], ["Wasserman", "Larry", ""]]}, {"id": "1307.7682", "submitter": "Allan McRobie", "authors": "Allan McRobie", "title": "Probability-Matching Predictors for Extreme Extremes", "comments": "22 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A location- and scale-invariant predictor is constructed which exhibits good\nprobability matching for extreme predictions outside the span of data drawn\nfrom a variety of (stationary) general distributions. It is constructed via the\nthree-parameter {\\mu, \\sigma, \\xi} Generalized Pareto Distribution (GPD). The\npredictor is designed to provide matching probability exactly for the GPD in\nboth the extreme heavy-tailed limit and the extreme bounded-tail limit, whilst\ngiving a good approximation to probability matching at all intermediate values\nof the tail parameter \\xi. The predictor is valid even for small sample sizes\nN, even as small as N = 3.\n  The main purpose of this paper is to present the somewhat lengthy derivations\nwhich draw heavily on the theory of hypergeometric functions, particularly the\nLauricella functions. Whilst the construction is inspired by the Bayesian\napproach to the prediction problem, it considers the case of vague prior\ninformation about both parameters and model, and all derivations are undertaken\nusing sampling theory.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jul 2013 18:50:40 GMT"}], "update_date": "2013-07-30", "authors_parsed": [["McRobie", "Allan", ""]]}, {"id": "1307.7721", "submitter": "Alfredo Lopez", "authors": "J\\'er\\'emie Bigot, Ra\\'ul Gouet, Thierry Klein, Alfredo L\\'opez", "title": "Geodesic PCA in the Wasserstein space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the method of Geodesic Principal Component Analysis (GPCA) on\nthe space of probability measures on the line, with finite second moment,\nendowed with the Wasserstein metric. We discuss the advantages of this\napproach, over a standard functional PCA of probability densities in the\nHilbert space of square-integrable functions. We establish the consistency of\nthe method by showing that the empirical GPCA converges to its population\ncounterpart, as the sample size tends to infinity. A key property in the study\nof GPCA is the isometry between the Wasserstein space and a closed convex\nsubset of the space of square-integrable functions, with respect to an\nappropriate measure. Therefore, we consider the general problem of PCA in a\nclosed convex subset of a separable Hilbert space, which serves as basis for\nthe analysis of GPCA and also has interest in its own right. We provide\nillustrative examples on simple statistical models, to show the benefits of\nthis approach for data analysis. The method is also applied to a real dataset\nof population pyramids.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jul 2013 20:03:21 GMT"}, {"version": "v2", "created": "Sat, 31 Aug 2013 22:19:32 GMT"}, {"version": "v3", "created": "Fri, 3 Oct 2014 21:33:58 GMT"}], "update_date": "2014-10-07", "authors_parsed": [["Bigot", "J\u00e9r\u00e9mie", ""], ["Gouet", "Ra\u00fal", ""], ["Klein", "Thierry", ""], ["L\u00f3pez", "Alfredo", ""]]}, {"id": "1307.7931", "submitter": "Nicy Sebastian", "authors": "Nicy Sebastian, Dhannya P. Joseph and Seema S. Nair", "title": "An Overview of the Pathway Idea in Statistical and Physical Sciences", "comments": "arXiv admin note: text overlap with arXiv:cond-mat/0609526 by other\n  authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "math-ph math.CV math.MP math.ST physics.space-ph stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pathway idea is a switching mechanism by which one can go from one functional\nform to another, and to yet another. It is shown that through a parameter\n$\\alpha$, called the pathway parameter, one can connect generalized type-1 beta\nfamily of densities, generalized type-2 beta family of densities, and\ngeneralized gamma family of densities, in the scalar as well as the matrix\ncases, also in the real and complex domains. It is shown that when the model is\napplied to physical situations then the current hot topics of Tsallis\nstatistics and superstatistics in statistical mechanics become special cases of\nthe pathway model, and the model is capable of capturing many stable situations\nas well as the unstable or chaotic neighborhoods of the stable situations and\ntransitional stages. The pathway model is shown to be connected to generalized\ninformation measures or entropies, power law, likelihood ratio criterion or\n$\\lambda-$criterion in multivariate statistical analysis, generalized Dirichlet\ndensities, fractional calculus, Mittag-Leffler stochastic process, Kr\\\"{a}tzel\nintegral in applied analysis, and many other topics in different disciplines.\nThe pathway model enables one to extend the current results on quadratic and\nbilinear forms, when the samples come from Gaussian populations, to wider\nclasses of populations.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2013 12:01:12 GMT"}], "update_date": "2013-07-31", "authors_parsed": [["Sebastian", "Nicy", ""], ["Joseph", "Dhannya P.", ""], ["Nair", "Seema S.", ""]]}, {"id": "1307.7949", "submitter": "Nicy Sebastian", "authors": "Nicy Sebastian", "title": "Limiting Approach to Generalized Gamma Bessel Model via Fractional\n  Calculus and its Applications in Various Disciplines", "comments": "arXiv admin note: text overlap with arXiv:0705.0148 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "math-ph math.MP math.ST physics.data-an stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The essentials of fractional calculus according to different approaches that\ncan be useful for our applications in the theory of probability and stochastic\nprocesses are established. In addition to this, from this fractional integral\none can list out almost all the extended densities for the pathway parameter $q\n< 1$ and $q \\rightarrow 1$. Here we bring out the idea of thicker or thinner\ntailed models associated with a gamma type distribution as a limiting case of\npathway operator. Applications of this extended gamma model in Statistical\nMechanics, input-output models, and solar spectral irradiance modeling etc are\nestablished.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2013 12:45:41 GMT"}], "update_date": "2013-07-31", "authors_parsed": [["Sebastian", "Nicy", ""]]}, {"id": "1307.8137", "submitter": "Stanislav Minsker", "authors": "Vladimir Koltchinskii and Stanislav Minsker", "title": "$L_1$-Penalization in Functional Linear Regression with Subgaussian\n  Design", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study functional regression with random subgaussian design and real-valued\nresponse. The focus is on the problems in which the regression function can be\nwell approximated by a functional linear model with the slope function being\n\"sparse\" in the sense that it can be represented as a sum of a small number of\nwell separated \"spikes\". This can be viewed as an extension of now classical\nsparse estimation problems to the case of infinite dictionaries. We study an\nestimator of the regression function based on penalized empirical risk\nminimization with quadratic loss and the complexity penalty defined in terms of\n$L_1$-norm (a continuous version of LASSO). The main goal is to introduce\nseveral important parameters characterizing sparsity in this class of problems\nand to prove sharp oracle inequalities showing how the $L_2$-error of the\ncontinuous LASSO estimator depends on the underlying sparsity of the problem.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2013 20:24:48 GMT"}, {"version": "v2", "created": "Sun, 14 Sep 2014 16:37:49 GMT"}], "update_date": "2014-09-16", "authors_parsed": [["Koltchinskii", "Vladimir", ""], ["Minsker", "Stanislav", ""]]}, {"id": "1307.8229", "submitter": "Mengjie Chen", "authors": "Mengjie Chen, Chao Gao, Hongyu Zhao", "title": "Posterior Contraction Rates of the Phylogenetic Indian Buffet Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML math.ST q-bio.QM stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By expressing prior distributions as general stochastic processes,\nnonparametric Bayesian methods provide a flexible way to incorporate prior\nknowledge and constrain the latent structure in statistical inference. The\nIndian buffet process (IBP) is such an example that can be used to define a\nprior distribution on infinite binary features, where the exchangeability among\nsubjects is assumed. The phylogenetic Indian buffet process (pIBP), a\nderivative of IBP, enables the modeling of non-exchangeability among subjects\nthrough a stochastic process on a rooted tree, which is similar to that used in\nphylogenetics, to describe relationships among the subjects. In this paper, we\nstudy the theoretical properties of IBP and pIBP under a binary factor model.\nWe establish the posterior contraction rates for both IBP and pIBP and\nsubstantiate the theoretical results through simulation studies. This is the\nfirst work addressing the frequentist property of the posterior behaviors of\nIBP and pIBP. We also demonstrated its practical usefulness by applying pIBP\nprior to a real data example arising in the field of cancer genomics where the\nexchangeability among subjects is violated.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2013 05:56:20 GMT"}, {"version": "v2", "created": "Tue, 19 May 2015 20:02:07 GMT"}], "update_date": "2015-05-21", "authors_parsed": [["Chen", "Mengjie", ""], ["Gao", "Chao", ""], ["Zhao", "Hongyu", ""]]}, {"id": "1307.8271", "submitter": "Nicy Sebastian", "authors": "Nicy Sebastian and Rudolf Gorenflo", "title": "A Fractional Generalization of the Poisson Processes and Some of its\n  Properties", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math-ph math.MP stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We have provided a fractional generalization of the Poisson renewal processes\nby replacing the first time derivative in the relaxation equation of the\nsurvival probability by a fractional derivative of order $\\alpha ~(0 < \\alpha\n\\leq 1)$. A generalized Laplacian model associated with the Mittag-Leffler\ndistribution is examined. We also discuss some properties of this new model and\nits relevance to time series. Distribution of gliding sums, regression\nbehaviors and sample path properties are studied. Finally we introduce the\n$q$-Mittag-Leffler process associated with the $q$-Mittag-Leffler distribution.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2013 10:23:45 GMT"}], "update_date": "2013-08-01", "authors_parsed": [["Sebastian", "Nicy", ""], ["Gorenflo", "Rudolf", ""]]}, {"id": "1307.8300", "submitter": "Katharine Turner", "authors": "Katharine Turner", "title": "Medians of populations of persistence diagrams", "comments": "22 pages, 13 figures. Mainly exposition changes and minor figure\n  changes. It now focuses on the median and the mean case moved as an appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.CG math.AT math.MG stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Persistence diagrams are common objects in the field of Topological Data\nAnalysis. They are topological summaries that capture both topological and\ngeometric structure within data. Recently there has been a surge of interest in\ndeveloping tools to statistically analyse populations of persistence diagrams,\na process hampered by the complicated geometry of the space of persistence\ndiagrams. In this paper we study the median of a set of diagrams, defined as\nthe minimizer of an appropriate cost function analogous to the sum of distances\nused for samples of real numbers. We then characterize the local minima of this\ncost function and in doing so characterize the median. We also do some\ncomparative analysis of the properties of the median and the mean.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2013 12:26:55 GMT"}, {"version": "v2", "created": "Wed, 6 Feb 2019 00:33:02 GMT"}], "update_date": "2019-02-07", "authors_parsed": [["Turner", "Katharine", ""]]}, {"id": "1307.8369", "submitter": "Ying Ding", "authors": "Ying Ding and Bin Nan", "title": "Estimating mean survival time: when is it possible?", "comments": "31 pages, 3 Postscript figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For right censored survival data, it is well known that the mean survival\ntime can be consistently estimated when the support of the censoring time\ncontains the support of the survival time. In practice, however, this condition\ncan be easily violated because the follow-up of a study is usually within a\nfinite window. In this article we show that the mean survival time is still\nestimable from a linear model when the support of some covariate(s) with\nnonzero coefficient(s) is unbounded regardless of the length of follow-up. This\nimplies that the mean survival time can be well estimated when the covariate\nrange is wide in practice. The theoretical finding is further verified for\nfinite samples by simulation studies. Simulations also show that, when both\nmodels are correctly specified, the linear model yields reasonable mean square\nprediction errors and outperforms the Cox model, particularly with heavy\ncensoring and short follow-up time.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2013 16:03:03 GMT"}], "update_date": "2013-08-01", "authors_parsed": [["Ding", "Ying", ""], ["Nan", "Bin", ""]]}]