[{"id": "1309.0003", "submitter": "Xinjia Chen", "authors": "Xinjia Chen", "title": "Concentration Inequalities for Bounded Random Vectors", "comments": "9 pages, no figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive simple concentration inequalities for bounded random vectors, which\ngeneralize Hoeffding's inequalities for bounded scalar random variables. As\napplications, we apply the general results to multinomial and Dirichlet\ndistributions to obtain multivariate concentration inequalities.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2013 18:27:01 GMT"}], "update_date": "2013-11-05", "authors_parsed": [["Chen", "Xinjia", ""]]}, {"id": "1309.0024", "submitter": "Jeffrey Miller", "authors": "Jeffrey W. Miller, Matthew T. Harrison", "title": "Inconsistency of Pitman-Yor process mixtures for the number of\n  components", "comments": "This is a general treatment of the problem discussed in our related\n  article, \"A simple example of Dirichlet process mixture inconsistency for the\n  number of components\", Miller and Harrison (2013) arXiv:1301.2708", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many applications, a finite mixture is a natural model, but it can be\ndifficult to choose an appropriate number of components. To circumvent this\nchoice, investigators are increasingly turning to Dirichlet process mixtures\n(DPMs), and Pitman-Yor process mixtures (PYMs), more generally. While these\nmodels may be well-suited for Bayesian density estimation, many investigators\nare using them for inferences about the number of components, by considering\nthe posterior on the number of components represented in the observed data. We\nshow that this posterior is not consistent --- that is, on data from a finite\nmixture, it does not concentrate at the true number of components. This result\napplies to a large class of nonparametric mixtures, including DPMs and PYMs,\nover a wide variety of families of component distributions, including\nessentially all discrete families, as well as continuous exponential families\nsatisfying mild regularity conditions (such as multivariate Gaussians).\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2013 20:43:10 GMT"}], "update_date": "2013-09-03", "authors_parsed": [["Miller", "Jeffrey W.", ""], ["Harrison", "Matthew T.", ""]]}, {"id": "1309.0334", "submitter": "Rajesh  Singh", "authors": "Jayant Singh, Viplav K. Singh, Sachin Malik, Rajesh Singh", "title": "Use of Auxiliary Information in Variance Estimation", "comments": "9 pages, 1 table", "journal-ref": "INSPIRA Jour. Of Modern Managmt. & Entr. (2013), 75-81", "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a class of ratio type estimators of finite population\nvariance, when the population variance of an auxiliary character is known.\nAsymptotic expression for mean square error (MSE) is derived and compared with\nthe mean square errors of some existing estimators. An empirical study is\ncarried out to illustrate the performance of the constructed estimator over\nothers.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2013 09:22:10 GMT"}], "update_date": "2013-11-27", "authors_parsed": [["Singh", "Jayant", ""], ["Singh", "Viplav K.", ""], ["Malik", "Sachin", ""], ["Singh", "Rajesh", ""]]}, {"id": "1309.0482", "submitter": "Tengyuan Liang", "authors": "T. Tony Cai, Tengyuan Liang and Harrison H. Zhou", "title": "Law of Log Determinant of Sample Covariance Matrix and Optimal\n  Estimation of Differential Entropy for High-Dimensional Gaussian\n  Distributions", "comments": "19 pages", "journal-ref": "Journal of Multivariate Analysis 137 (2015) 161-172", "doi": "10.1016/j.jmva.2015.02.003", "report-no": "YJMVA3886", "categories": "math.ST cs.IT math.IT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differential entropy and log determinant of the covariance matrix of a\nmultivariate Gaussian distribution have many applications in coding,\ncommunications, signal processing and statistical inference. In this paper we\nconsider in the high dimensional setting optimal estimation of the differential\nentropy and the log-determinant of the covariance matrix. We first establish a\ncentral limit theorem for the log determinant of the sample covariance matrix\nin the high dimensional setting where the dimension $p(n)$ can grow with the\nsample size $n$. An estimator of the differential entropy and the log\ndeterminant is then considered. Optimal rate of convergence is obtained. It is\nshown that in the case $p(n)/n \\rightarrow 0$ the estimator is asymptotically\nsharp minimax. The ultra-high dimensional setting where $p(n) > n$ is also\ndiscussed.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2013 18:46:28 GMT"}], "update_date": "2015-03-10", "authors_parsed": [["Cai", "T. Tony", ""], ["Liang", "Tengyuan", ""], ["Zhou", "Harrison H.", ""]]}, {"id": "1309.0485", "submitter": "Fr\\'ed\\'eric Pro\\\"ia", "authors": "Pro\\\"ia Fr\\'ed\\'eric", "title": "Stationarity against integration in the autoregressive process with\n  polynomial trend", "comments": "21 pages, 6 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We tackle the stationarity issue of an autoregressive path with a polynomial\ntrend, and we generalize some aspects of the LMC test, the testing procedure of\nLeybourne and McCabe. First, we show that it is possible to get the asymptotic\ndistribution of the test statistic under the null hypothesis of\ntrend-stationarity as well as under the alternative of nonstationarity, for any\npolynomial trend of order $r$. Then, we explain the reason why the LMC test,\nand by extension the KPSS test, does not reject the null hypothesis of\ntrend-stationarity, mistakenly, when the random walk is generated by a unit\nroot located at $-1$. We also observe it on simulated data and we correct the\nprocedure. Finally, we describe some useful stochastic processes that appear in\nour limiting distributions.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2013 18:59:50 GMT"}, {"version": "v2", "created": "Sat, 21 Jun 2014 18:49:03 GMT"}, {"version": "v3", "created": "Thu, 2 Jul 2015 15:53:14 GMT"}, {"version": "v4", "created": "Sat, 20 Aug 2016 17:15:41 GMT"}], "update_date": "2016-08-23", "authors_parsed": [["Fr\u00e9d\u00e9ric", "Pro\u00efa", ""]]}, {"id": "1309.0609", "submitter": "{\\L}ukasz Kwiatkowski", "authors": "{\\L}ukasz Kwiatkowski", "title": "Coherent prior distributions in univariate finite mixture and\n  Markov-switching models", "comments": "24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finite mixture and Markov-switching models generalize and, therefore, nest\nspecifications featuring only one component. While specifying priors in the\ntwo: the general (mixture) model and its special (single-component) case, it\nmay be desirable to ensure that the prior assumptions introduced into both\nstructures are coherent in the sense that the prior distribution in the nested\nmodel amounts to the conditional prior in the mixture model under relevant\nparametric restriction. The study provides the rudiments of setting coherent\npriors in Bayesian univariate finite mixture and Markov-switching models. Once\nsome primary results are delivered, we derive specific conditions for coherence\nin the case of three types of continuous priors commonly engaged in Bayesian\nmodeling: the normal, inverse gamma, and gamma distributions. Further, we study\nthe consequences of introducing additional constraints into the mixture model's\nprior (such as the ones enforcing identifiability or some sort of regularity,\ne.g. second-order stationarity) on the coherence conditions. Finally, the\nmethodology is illustrated through a discussion of setting coherent priors for\na class of Markov-switching AR(2) models.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2013 08:23:35 GMT"}], "update_date": "2013-09-04", "authors_parsed": [["Kwiatkowski", "\u0141ukasz", ""]]}, {"id": "1309.0805", "submitter": "Xinjia Chen", "authors": "Xinjia Chen", "title": "An Urn Model Approach for Deriving Multivariate Generalized\n  Hypergeometric Distributions", "comments": "12 pages, no figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose new generalized multivariate hypergeometric distributions, which\nextremely resemble the classical multivariate hypergeometric distributions. The\nproposed distributions are derived based on an urn model approach. In contrast\nto existing methods, this approach does not involve hypergeometric series.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2013 01:54:35 GMT"}], "update_date": "2013-09-05", "authors_parsed": [["Chen", "Xinjia", ""]]}, {"id": "1309.0997", "submitter": "Boris Oreshkin", "authors": "Boris N. Oreshkin and Ekaterina Turkina", "title": "Sensor fusion for bimodal generalized likelihood ratio test with unknown\n  noise variances", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we address the problem of sensor fusion. We formulate the joint\ndetection problem using a general linear observation model and inter-modality\nindependence assumption for noises. We derive the fusion architecture based on\nthe generalized likelihood ratio principle and calculate the expressions for\nthe distributions of the test statistic under the signal present and the null\nhypotheses. To obtain these results we develop a methodology for the joint\ndetection algorithm analysis based on the theory of the Meijer G-function.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2013 12:10:37 GMT"}], "update_date": "2013-09-05", "authors_parsed": [["Oreshkin", "Boris N.", ""], ["Turkina", "Ekaterina", ""]]}, {"id": "1309.1262", "submitter": "Gabriela Ciuperca", "authors": "Gabriela Ciuperca", "title": "Adaptive LASSO model selection in a multiphase quantile regression", "comments": null, "journal-ref": null, "doi": "10.1080/02331888.2016.1151427", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a general adaptive LASSO method for a quantile regression model.\nOur method is very interesting when we know nothing about the first two moments\nof the model error. We first prove that the obtained estimators satisfy the\noracle properties, which involves the relevant variable selection without using\nhypothesis test. Next, we study the proposed method when the (multiphase) model\nchanges to unknown observations called change-points. Convergence rates of the\nchange-points and of the regression parameters estimators in each phase are\nfound. The sparsity of the adaptive LASSO quantile estimators of the regression\nparameters is not affected by the change-points estimation. If the phases\nnumber is unknown, a consistent criterion is proposed. Numerical studies by\nMonte Carlo simulations show the performance of the proposed method, compared\nto other existing methods in the literature, for models with a single phase or\nfor multiphase models. The adaptive LASSO quantile method performs better than\nknown variable selection methods, as the least squared method with adaptive\nLASSO penalty, $L_1$-method with LASSO-type penalty and quantile method with\nSCAD penalty.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2013 08:04:46 GMT"}, {"version": "v2", "created": "Wed, 12 Mar 2014 10:44:57 GMT"}, {"version": "v3", "created": "Tue, 21 Oct 2014 15:25:56 GMT"}], "update_date": "2016-02-05", "authors_parsed": [["Ciuperca", "Gabriela", ""]]}, {"id": "1309.1309", "submitter": "Philip Preu{\\ss}", "authors": "Philip Preu{\\ss}, Ruprecht Puchstein, Holger Dette", "title": "Detection of multiple structural breaks in multivariate time series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new nonparametric procedure for the detection and estimation of\nmultiple structural breaks in the autocovariance function of a multivariate\n(second- order) piecewise stationary process, which also identifies the\ncomponents of the series where the breaks occur. The new method is based on a\ncomparison of the estimated spectral distribution on different segments of the\nobserved time series and consists of three steps: it starts with a consistent\ntest, which allows to prove the existence of structural breaks at a controlled\ntype I error. Secondly, it estimates sets containing possible break points and\nfinally these sets are reduced to identify the relevant structural breaks and\ncorresponding components which are responsible for the changes in the\nautocovariance structure. In contrast to all other methods which have been\nproposed in the literature, our approach does not make any parametric\nassumptions, is not especially designed for detecting one single change point\nand addresses the problem of multiple structural breaks in the autocovariance\nfunction directly with no use of the binary segmentation algorithm. We prove\nthat the new procedure detects all components and the corresponding locations\nwhere structural breaks occur with probability converging to one as the sample\nsize increases and provide data-driven rules for the selection of all\nregularization parameters. The results are illustrated by analyzing financial\nreturns, and in a simulation study it is demonstrated that the new procedure\noutperforms the currently available nonparametric methods for detecting breaks\nin the dependency structure of multivariate time series.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2013 11:00:11 GMT"}], "update_date": "2013-09-06", "authors_parsed": [["Preu\u00df", "Philip", ""], ["Puchstein", "Ruprecht", ""], ["Dette", "Holger", ""]]}, {"id": "1309.1392", "submitter": "James P. Crutchfield", "authors": "Christopher C. Strelioff and James P. Crutchfield", "title": "Bayesian Structural Inference for Hidden Processes", "comments": "20 pages, 11 figures, 1 table; supplementary materials, 15 pages, 11\n  figures, 6 tables; http://csc.ucdavis.edu/~cmg/compmech/pubs/bsihp.htm", "journal-ref": "Phys. Rev. E 89, 042119 (2014)", "doi": "10.1103/PhysRevE.89.042119", "report-no": "Santa Fe Institute Working Paper 13-09-027", "categories": "stat.ML cs.LG math.ST nlin.CD physics.data-an stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a Bayesian approach to discovering patterns in structurally\ncomplex processes. The proposed method of Bayesian Structural Inference (BSI)\nrelies on a set of candidate unifilar HMM (uHMM) topologies for inference of\nprocess structure from a data series. We employ a recently developed exact\nenumeration of topological epsilon-machines. (A sequel then removes the\ntopological restriction.) This subset of the uHMM topologies has the added\nbenefit that inferred models are guaranteed to be epsilon-machines,\nirrespective of estimated transition probabilities. Properties of\nepsilon-machines and uHMMs allow for the derivation of analytic expressions for\nestimating transition probabilities, inferring start states, and comparing the\nposterior probability of candidate model topologies, despite process internal\nstructure being only indirectly present in data. We demonstrate BSI's\neffectiveness in estimating a process's randomness, as reflected by the Shannon\nentropy rate, and its structure, as quantified by the statistical complexity.\nWe also compare using the posterior distribution over candidate models and the\nsingle, maximum a posteriori model for point estimation and show that the\nformer more accurately reflects uncertainty in estimated values. We apply BSI\nto in-class examples of finite- and infinite-order Markov processes, as well to\nan out-of-class, infinite-state hidden process.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2013 16:18:35 GMT"}, {"version": "v2", "created": "Mon, 9 Dec 2013 05:21:31 GMT"}], "update_date": "2014-04-23", "authors_parsed": [["Strelioff", "Christopher C.", ""], ["Crutchfield", "James P.", ""]]}, {"id": "1309.1412", "submitter": "Stefan Aulbach", "authors": "Stefan Aulbach and Michael Falk", "title": "Testing for a {\\delta}-neighborhood of a generalized Pareto copula", "comments": "32 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A multivariate distribution function F is in the max-domain of attraction of\nan extreme value distribution if and only if this is true for the copula\ncorresponding to F and its univariate margins. Aulbach et al. (2012a) have\nshown that a copula satisfies the extreme value condition if and only if the\ncopula is tail equivalent to a generalized Pareto copula (GPC). In this paper\nwe propose a chi-square goodness-of-fit test in arbitrary dimension for testing\nwhether a copula is in a certain neighborhood of a GPC. The test can be applied\nto stochastic processes as well to check whether the corresponding copula\nprocess is close to a generalized Pareto process. Since the p-value of the\nproposed test is highly sensitive to a proper selection of a certain threshold,\nwe also present a graphical tool that makes the decision, whether or not to\nreject the hypothesis, more comfortable.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2013 17:29:33 GMT"}], "update_date": "2013-09-06", "authors_parsed": [["Aulbach", "Stefan", ""], ["Falk", "Michael", ""]]}, {"id": "1309.1754", "submitter": "Sayantan Banerjee", "authors": "Sayantan Banerjee and Subhashis Ghosal", "title": "Bayesian estimation of a sparse precision matrix", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of estimating a sparse precision matrix of a\nmultivariate Gaussian distribution, including the case where the dimension $p$\nis large. Gaussian graphical models provide an important tool in describing\nconditional independence through presence or absence of the edges in the\nunderlying graph. A popular non-Bayesian method of estimating a graphical\nstructure is given by the graphical lasso. In this paper, we consider a\nBayesian approach to the problem. We use priors which put a mixture of a point\nmass at zero and certain absolutely continuous distribution on off-diagonal\nelements of the precision matrix. Hence the resulting posterior distribution\ncan be used for graphical structure learning. The posterior convergence rate of\nthe precision matrix is obtained. The posterior distribution on the model space\nis extremely cumbersome to compute. We propose a fast computational method for\napproximating the posterior probabilities of various graphs using the Laplace\napproximation approach by expanding the posterior density around the posterior\nmode, which is the graphical lasso by our choice of the prior distribution. We\nalso provide estimates of the accuracy in the approximation.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2013 19:55:36 GMT"}, {"version": "v2", "created": "Mon, 7 Apr 2014 01:45:34 GMT"}], "update_date": "2014-04-08", "authors_parsed": [["Banerjee", "Sayantan", ""], ["Ghosal", "Subhashis", ""]]}, {"id": "1309.1913", "submitter": "Charalambos Charalambous D.", "authors": "Charalambos D. Charalambous, Nasir U. Ahmed", "title": "Dynamic Team Theory of Stochastic Differential Decision Systems with\n  Decentralized Noisy Information Structures via Girsanov's Measure\n  Transformation", "comments": "50 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.SY math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present two methods which generalize static team theory to\ndynamic team theory, in the context of continuous-time stochastic nonlinear\ndifferential decentralized decision systems, with relaxed strategies, which are\nmeasurable to different noisy information structures. For both methods we apply\nGirsanov's measure transformation to obtain an equivalent dynamic team problem\nunder a reference probability measure, so that the observations and information\nstructures available for decisions, are not affected by any of the team\ndecisions. The first method is based on function space integration with respect\nto products of Wiener measures, and generalizes Witsenhausen's [1] definition\nof equivalence between discrete-time static and dynamic team problems. The\nsecond method is based on stochastic Pontryagin's maximum principle. The team\noptimality conditions are given by a \"Hamiltonian System\" consisting of forward\nand backward stochastic differential equations, and a conditional variational\nHamiltonian with respect to the information structure of each team member,\nexpressed under the initial and a reference probability space via Girsanov's\nmeasure transformation. Under global convexity conditions, we show that that\nPbP optimality implies team optimality. In addition, we also show existence of\nteam and PbP optimal relaxed decentralized strategies (conditional\ndistributions), in the weak$^*$ sense, without imposing convexity on the action\nspaces of the team members. Moreover, using the embedding of regular strategies\ninto relaxed strategies, we also obtain team and PbP optimality conditions for\nregular team strategies, which are measurable functions of decentralized\ninformation structures, and we use the Krein-Millman theorem to show\nrealizability of relaxed strategies by regular strategies.\n", "versions": [{"version": "v1", "created": "Sat, 7 Sep 2013 22:25:03 GMT"}, {"version": "v2", "created": "Thu, 10 Oct 2013 08:25:49 GMT"}], "update_date": "2013-10-11", "authors_parsed": [["Charalambous", "Charalambos D.", ""], ["Ahmed", "Nasir U.", ""]]}, {"id": "1309.1915", "submitter": "David Tyler", "authors": "Andrew F. Magyar and David E. Tyler", "title": "The asymptotic inadmissibility of the spatial sign covariance matrix for\n  elliptically symmetric distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The asymptotic efficiency of the spatial sign covariance matrix (SSCM)\nrelative to affine equivariant estimates of scatter is studied in detail. In\nparticular, the SSCM is shown to be asymptoticaly inadmissible, i.e. the\nasymptotic variance-covariance matrix of the consistency corrected SSCM is\nuniformly smaller than that of its affine equivariant counterpart, namely\nTyler's scatter matrix. Although the SSCM has often been recommended when one\nis interested in principal components analysis, the degree of the inefficiency\nof the SSCM is shown to be most severe in situations where principal components\nare of most interest. A finite sample simulation shows the inefficiency of the\nSSCM also holds for small sample sizes, and that the asymptotic relative\nefficiency is a good approximation to the finite sample efficiency for\nrelatively modest sample sizes.\n", "versions": [{"version": "v1", "created": "Sat, 7 Sep 2013 22:44:54 GMT"}], "update_date": "2013-09-10", "authors_parsed": [["Magyar", "Andrew F.", ""], ["Tyler", "David E.", ""]]}, {"id": "1309.2136", "submitter": "Eitan Greenshtein", "authors": "Eitan Greenshtein and Theodor Itskov", "title": "Deconvolution with application to estimation of sampling probabilities\n  and the Horvitz-Thompson estimator", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We elaborate on a deconvolution method, used to estimate the empirical\ndistribution of unknown parameters, as suggested recently by Efron (2013). It\nis applied to estimating the empirical distribution of the 'sampling\nprobabilities' of m sampled items. The estimated empirical distribution is used\nto modify the Horvitz-Thompson estimator. The performance of the modified\nHorvitz-Thompson estimator is studied in two examples. In one example the\nsampling probabilities are estimated based on the number of visits until a\nresponse was obtained. The other example is based on real data from panel\nsampling, where in four consecutive months there are corresponding four\nattempts to interview each member in a panel. The sampling probabilities are\nestimated based on the number of successful attempts.\n  We also discuss briefly, further applications of deconvolution, including\nestimation of False discovery rate.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2013 12:46:43 GMT"}, {"version": "v2", "created": "Wed, 9 Oct 2013 09:57:16 GMT"}, {"version": "v3", "created": "Tue, 19 Nov 2013 11:34:34 GMT"}], "update_date": "2013-11-20", "authors_parsed": [["Greenshtein", "Eitan", ""], ["Itskov", "Theodor", ""]]}, {"id": "1309.2178", "submitter": "Giles Hooker", "authors": "Giles Hooker", "title": "On the Identifiability of the Functional Convolution Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This report details conditions under which the Functional Convolution Model\ndescribed in \\citet{AHG13} can be identified from Ordinary Least Squares\nestimates without either dimension reduction or smoothing penalties. We\ndemonstrate that if the covariate functions are not spanned by the space of\nsolutions to linear differential equations, the functional coefficients in the\nmodel are uniquely determined in the Sobolev space of functions with absolutely\ncontinuous second derivatives.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2013 14:50:53 GMT"}], "update_date": "2013-09-10", "authors_parsed": [["Hooker", "Giles", ""]]}, {"id": "1309.2431", "submitter": "Rajesh  Singh", "authors": "Sachin Malik and Rajesh Singh", "title": "An improved class of exponential ratio- type estimator in the presence\n  of measurement errors", "comments": "10 pages, 2 tables. OCTOGON Mathematical Magazine, 21,1", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we have suggested a family of estimators for the population\nmean in the presence of measurement errors. Expression for the mean squared\nerror (MSE) of the suggested family is derived. An empirical study has been\ncarried out to verify the theoretical findings.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2013 09:37:41 GMT"}], "update_date": "2013-09-11", "authors_parsed": [["Malik", "Sachin", ""], ["Singh", "Rajesh", ""]]}, {"id": "1309.2505", "submitter": "Shahzad Gishkori", "authors": "Shahzad Gishkori, Geert Leus", "title": "Compressed Sensing for Block-Sparse Smooth Signals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present reconstruction algorithms for smooth signals with block sparsity\nfrom their compressed measurements. We tackle the issue of varying group size\nvia group-sparse least absolute shrinkage selection operator (LASSO) as well as\nvia latent group LASSO regularizations. We achieve smoothness in the signal via\nfusion. We develop low-complexity solvers for our proposed formulations through\nthe alternating direction method of multipliers.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2013 13:38:16 GMT"}], "update_date": "2013-09-11", "authors_parsed": [["Gishkori", "Shahzad", ""], ["Leus", "Geert", ""]]}, {"id": "1309.2585", "submitter": "Arlene K. H. Kim", "authors": "Alexandra Carpentier and Arlene K.H. Kim", "title": "Adaptive and minimax optimal estimation of the tail coefficient", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of estimating the tail index $\\alpha$ of a\ndistribution satisfying a $(\\alpha, \\beta)$ second-order Pareto-type condition,\nwhere \\beta is the second-order coefficient. When $\\beta$ is available, it was\npreviously proved that $\\alpha$ can be estimated with the oracle rate\n$n^{-\\beta/(2\\beta+1)}$. On the contrary, when $\\beta$ is not available,\nestimating $\\alpha$ with the oracle rate is challenging; so additional\nassumptions that imply the estimability of $\\beta$ are usually made. In this\npaper, we propose an adaptive estimator of $\\alpha$, and show that this\nestimator attains the rate $(n/\\log\\log n)^{-\\beta/(2\\beta+1)}$ without a\npriori knowledge of $\\beta$ and any additional assumptions. Moreover, we prove\nthat this $(\\log\\log n)^{\\beta/(2\\beta+1)}$ factor is unavoidable by obtaining\nthe companion lower bound.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2013 17:36:56 GMT"}, {"version": "v2", "created": "Fri, 4 Jul 2014 03:44:38 GMT"}], "update_date": "2014-07-07", "authors_parsed": [["Carpentier", "Alexandra", ""], ["Kim", "Arlene K. H.", ""]]}, {"id": "1309.2779", "submitter": "Hazhir Homei", "authors": "Hazhir Homei", "title": "Uniform Random Sample and Symmetric Beta Distribution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  N.L. Johnson and S. Kotz introduced in 1990 an interesting family of\nsymmetric distributions which is based on randomly weighted average from\nuniform random samples. The only example that could be addressed to their work\nis the so-called \"uniformly randomly modified tin\" distribution from which two\nrandom samples have been computed. In this paper, we generalize a subfamily of\ntheir symmetric distributions and identify a concrete instance of this\ngeneralized subfamily. That instance turns out to belong to the family of\nJohnson and Kotz, which had not seemingly received proper attention in the\nliterature.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2013 10:08:06 GMT"}], "update_date": "2013-09-12", "authors_parsed": [["Homei", "Hazhir", ""]]}, {"id": "1309.2819", "submitter": "Roberto Imbuzeiro Oliveira", "authors": "Roberto Imbuzeiro Oliveira", "title": "Stochastic processes with random contexts: a characterization, and\n  adaptive estimators for the transition probabilities", "comments": null, "journal-ref": "IEEE Transactions on Information Theory ( Volume: 61, Issue: 12,\n  Dec. 2015 )", "doi": "10.1109/TIT.2015.2496200", "report-no": null, "categories": "math.PR cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces the concept of random context representations for the\ntransition probabilities of a finite-alphabet stochastic process. Processes\nwith these representations generalize context tree processes (a.k.a. variable\nlength Markov chains), and are proven to coincide with processes whose\ntransition probabilities are almost surely continuous functions of the\n(infinite) past. This is similar to a classical result by Kalikow about\ncontinuous transition probabilities. Existence and uniqueness of a minimal\nrandom context representation are proven, and an estimator of the transition\nprobabilities based on this representation is shown to have very good \"pastwise\nadaptativity\" properties. In particular, it achieves minimax performance, up to\nlogarithmic factors, for binary renewal processes with bounded $2+\\gamma$\nmoments.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2013 13:17:55 GMT"}, {"version": "v2", "created": "Thu, 8 Dec 2016 11:48:32 GMT"}], "update_date": "2016-12-09", "authors_parsed": [["Oliveira", "Roberto Imbuzeiro", ""]]}, {"id": "1309.2896", "submitter": "Rajesh Sharma", "authors": "R. Sharma, R. Bhandari", "title": "Skewness, kurtosis and Newton's inequality", "comments": "This paper has been withdrawn by the author due to personal reasons", "journal-ref": "Rocky Mountain journal of mathematics, vol 45, no. 5, pp\n  1639-1643, (2015)", "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that an inequality related to Newton's inequality provides one more\nrelation between skewness and kurtosis. This also gives simple and alternative\nproofs of the bounds for skewness and kurtosis.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2013 17:19:51 GMT"}, {"version": "v2", "created": "Fri, 21 Feb 2014 14:14:57 GMT"}], "update_date": "2016-02-16", "authors_parsed": [["Sharma", "R.", ""], ["Bhandari", "R.", ""]]}, {"id": "1309.2983", "submitter": "Tatiana Xifara Ph.D.", "authors": "Tatiana Xifara, Chris Sherlock, Samuel Livingstone, Simon Byrne, Mark\n  Girolami", "title": "Langevin diffusions and the Metropolis-adjusted Langevin algorithm", "comments": null, "journal-ref": "Statistics & Probability Letters. Volume 91, August 2014, pages\n  14-19", "doi": "10.1016/j.spl.2014.04.002", "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a clarification of the description of Langevin diffusions on\nRiemannian manifolds and of the measure underlying the invariant density. As a\nresult we propose a new position-dependent Metropolis-adjusted Langevin\nalgorithm (MALA) based upon a Langevin diffusion in $\\mathbb{R}^d$ which has\nthe required invariant density with respect to Lebesgue measure. We show that\nour diffusion and the diffusion upon which a previously-proposed\nposition-dependent MALA is based are equivalent in some cases but are distinct\nin general. A simulation study illustrates the gain in efficiency provided by\nthe new position-dependent MALA.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2013 22:04:18 GMT"}], "update_date": "2014-08-15", "authors_parsed": [["Xifara", "Tatiana", ""], ["Sherlock", "Chris", ""], ["Livingstone", "Samuel", ""], ["Byrne", "Simon", ""], ["Girolami", "Mark", ""]]}, {"id": "1309.3032", "submitter": "Rajesh  Singh", "authors": "prayas sharma, rajesh singh and Jong-Min Kim", "title": "Study of some improved ratio type estimators using information on\n  auxiliary attributes under second order approximation", "comments": "10 pages, 1 table", "journal-ref": "Sharma, P., Singh, R. and Kim, J. M. (2013) : Study of some\n  improved ratio type estimators using information on auxiliary attributes\n  under second order approximation. Jour. Sci. Res., 57, 138-146", "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chakrabarty, Khoshnevisan, Sahai and Ray, Solanki suggested some estimators\nto estimate unknown population mean of the study variable. These authors\ndiscussed the estimators along with their first order biases and mean square\nerrors(MSEs). In this paper, we have tried to found out the second order biases\nand mean square errors of some estimators using information on auxiliary\nattribute. We have compared the performance of the estimators with the help of\na numerical illustration.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2013 04:49:01 GMT"}], "update_date": "2013-09-13", "authors_parsed": [["sharma", "prayas", ""], ["singh", "rajesh", ""], ["Kim", "Jong-Min", ""]]}, {"id": "1309.3034", "submitter": "Rajesh  Singh", "authors": "Rajesh Singh, Viplav K. Singh, A. A. Adewara", "title": "Some improved estimators for estimating population mean in stratified\n  random sampling", "comments": null, "journal-ref": "Singh, R. Singh, V.K. and Adewara, A.A. (2013) : Some improved\n  estimators for estimating population mean in stratified random sampling.\n  Jour. Sci. Res., 57, 154-164", "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Some improved estimators are proposed for estimating the population mean in\nstratified sampling in the presence of auxiliary information. Mean square error\n(MSE) of the proposed estimators have been derived under large sample\napproximation. It has been shown that under optimum conditions proposed\nestimators are better than usual unbiased estimator and Hansen (1946)\nestimator. Both theoretical and empirical findings are encouraging and support\nthe soundness of the proposed procedure for mean estimation.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2013 04:53:26 GMT"}], "update_date": "2013-09-13", "authors_parsed": [["Singh", "Rajesh", ""], ["Singh", "Viplav K.", ""], ["Adewara", "A. A.", ""]]}, {"id": "1309.3197", "submitter": "Arthur Carvalho", "authors": "Arthur Carvalho, Stanko Dimitrov, Kate Larson", "title": "Inducing Honest Reporting Without Observing Outcomes: An Application to\n  the Peer-Review Process", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.DL math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When eliciting opinions from a group of experts, traditional devices used to\npromote honest reporting assume that there is an observable future outcome. In\npractice, however, this assumption is not always reasonable. In this paper, we\npropose a scoring method built on strictly proper scoring rules to induce\nhonest reporting without assuming observable outcomes. Our method provides\nscores based on pairwise comparisons between the reports made by each pair of\nexperts in the group. For ease of exposition, we introduce our scoring method\nby illustrating its application to the peer-review process. In order to do so,\nwe start by modeling the peer-review process using a Bayesian model where the\nuncertainty regarding the quality of the manuscript is taken into account.\nThereafter, we introduce our scoring method to evaluate the reported reviews.\nUnder the assumptions that reviewers are Bayesian decision-makers and that they\ncannot influence the reviews of other reviewers, we show that risk-neutral\nreviewers strictly maximize their expected scores by honestly disclosing their\nreviews. We also show how the group's scores can be used to find a consensual\nreview. Experimental results show that encouraging honest reporting through the\nproposed scoring method creates more accurate reviews than the traditional\npeer-review process.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2013 15:34:21 GMT"}, {"version": "v2", "created": "Tue, 22 Oct 2013 13:39:51 GMT"}], "update_date": "2013-10-23", "authors_parsed": [["Carvalho", "Arthur", ""], ["Dimitrov", "Stanko", ""], ["Larson", "Kate", ""]]}, {"id": "1309.3233", "submitter": "Franz J. Kir\\'aly", "authors": "Franz J. Kir\\'aly", "title": "Efficient Orthogonal Tensor Decomposition, with an Application to Latent\n  Variable Model Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decomposing tensors into orthogonal factors is a well-known task in\nstatistics, machine learning, and signal processing. We study orthogonal outer\nproduct decompositions where the factors in the summands in the decomposition\nare required to be orthogonal across summands, by relating this orthogonal\ndecomposition to the singular value decompositions of the flattenings. We show\nthat it is a non-trivial assumption for a tensor to have such an orthogonal\ndecomposition, and we show that it is unique (up to natural symmetries) in case\nit exists, in which case we also demonstrate how it can be efficiently and\nreliably obtained by a sequence of singular value decompositions. We\ndemonstrate how the factoring algorithm can be applied for parameter\nidentification in latent variable and mixture models.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2013 18:23:33 GMT"}], "update_date": "2013-09-13", "authors_parsed": [["Kir\u00e1ly", "Franz J.", ""]]}, {"id": "1309.3241", "submitter": "Shuyang Bai", "authors": "Shuyang Bai, Murad S. Taqqu", "title": "Generalized Hermite processes, discrete chaos and limit theorems", "comments": "Corrected some errors", "journal-ref": "Stochastic Processes and their Applications Volume 124, Issue 4,\n  April 2014, Pages 1710-1739", "doi": "10.1016/j.spa.2013.12.011", "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a broad class of self-similar processes $\\{Z(t),t\\ge 0\\}$ called\ngeneralized Hermite process. They have stationary increments, are defined on a\nWiener chaos with Hurst index $H\\in (1/2,1)$, and include Hermite processes as\na special case. They are defined through a homogeneous kernel $g$, called\n\"generalized Hermite kernel\", which replaces the product of power functions in\nthe definition of Hermite processes. The generalized Hermite kernels $g$ can\nalso be used to generate long-range dependent stationary sequences forming a\ndiscrete chaos process $\\{X(n)\\}$. In addition, we consider a\nfractionally-filtered version $Z^\\beta(t)$ of $Z(t)$, which allows $H\\in\n(0,1/2)$. Corresponding non-central limit theorems are established. We also\ngive a multivariate limit theorem which mixes central and non-central limit\ntheorems.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2013 18:57:35 GMT"}, {"version": "v2", "created": "Sun, 15 Sep 2013 01:01:09 GMT"}, {"version": "v3", "created": "Thu, 19 Dec 2013 21:43:04 GMT"}, {"version": "v4", "created": "Thu, 23 Jan 2014 23:09:24 GMT"}, {"version": "v5", "created": "Wed, 10 Sep 2014 21:13:34 GMT"}], "update_date": "2015-05-15", "authors_parsed": [["Bai", "Shuyang", ""], ["Taqqu", "Murad S.", ""]]}, {"id": "1309.3370", "submitter": "Rajesh  Singh", "authors": "Viplav K. Singh and Rajesh Singh", "title": "A generalised family of ratio product estimator using transformation\n  equation", "comments": "7 pages, 1 table", "journal-ref": "OCTOGON Mathematical Magazine, 21,1 (2013)", "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we deal with the estimation of population variance of the study\nvariable y using auxiliary information on variable x. A family of ratio and\nproduct-type estimators are proposed using suitable transformation on both\nrandom variable x(auxiliary variable) and(study variable).Up to the first order\nof approximation the expression of mean square error and Bias term are\nobtained. An empirical study is carried out to illustrate the performance of\nthe constructed estimator over others.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2013 05:32:16 GMT"}], "update_date": "2013-09-16", "authors_parsed": [["Singh", "Viplav K.", ""], ["Singh", "Rajesh", ""]]}, {"id": "1309.3376", "submitter": "Aur\\'elien Garivier", "authors": "Aur\\'elien Garivier", "title": "Informational Confidence Bounds for Self-Normalized Averages and\n  Applications", "comments": null, "journal-ref": "2013 IEEE Information Theory Workshop p.489-493", "doi": "10.1109/ITW.2013.6691311", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present deviation bounds for self-normalized averages and applications to\nestimation with a random number of observations. The results rely on a peeling\nargument in exponential martingale techniques that represents an alternative to\nthe method of mixture. The motivating examples of bandit problems and context\ntree estimation are detailed.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2013 06:37:07 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Garivier", "Aur\u00e9lien", ""]]}, {"id": "1309.3399", "submitter": "Karol Wawrzyniak K.W.", "authors": "Karol Wawrzyniak and Wojciech Wi\\'slicki", "title": "Grand canonical minority game as a sign predictor", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP math.ST q-fin.TR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper the extended model of Minority game (MG), incorporating\nvariable number of agents and therefore called Grand Canonical, is used for\nprediction. We proved that the best MG-based predictor is constituted by a\ntremendously degenerated system, when only one agent is involved. The\nprediction is the most efficient if the agent is equipped with all strategies\nfrom the Full Strategy Space. Each of these filters is evaluated and, in each\nstep, the best one is chosen. Despite the casual simplicity of the method its\nusefulness is invaluable in many cases including real problems. The significant\npower of the method lies in its ability to fast adaptation if \\lambda-GCMG\nmodification is used. The success rate of prediction is sensitive to the\nproperly set memory length. We considered the feasibility of prediction for the\nMinority and Majority games. These two games are driven by different dynamics\nwhen self-generated time series are considered. Both dynamics tend to be the\nsame when a feedback effect is removed and an exogenous signal is applied.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2013 08:51:04 GMT"}], "update_date": "2013-09-16", "authors_parsed": [["Wawrzyniak", "Karol", ""], ["Wi\u015blicki", "Wojciech", ""]]}, {"id": "1309.3663", "submitter": "Mathukumalli Vidyasagar", "authors": "Mathukumalli Vidyasagar", "title": "An Elementary Derivation of the Large Deviation Rate Function for Finite\n  State Markov Chains", "comments": "34 pages, no figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large deviation theory is a branch of probability theory that is devoted to a\nstudy of the \"rate\" at which empirical estimates of various quantities converge\nto their true values. The object of study in this paper is the rate at which\nestimates of the doublet frequencies of a Markov chain over a finite alphabet\nconverge to their true values. In case the Markov process is actually an\ni.i.d.\\ process, the rate function turns out to be the relative entropy (or\nKullback-Leibler divergence) between the true and the estimated probability\nvectors. This result is a special case of a very general result known as\nSanov's theorem and dates back to 1957. Moreover, since the introduction of the\n\"method of types\" by Csisz\\'{a}r and his co-workers during the 1980s, the proof\nof this version of Sanov's theorem has been \"elementary,\" using some\ncombinatorial arguments. However, when the i.i.d.\\ process is replaced by a\nMarkov process, the available proofs are far more complex. The main objective\nof this paper is therefore to present a first-principles derivation of the LDP\nfor finite state Markov chains, using only simple combinatorial arguments\n(e.g.\\ the method of types), thus gathering in one place various arguments and\nestimates that are scattered over the literature.\n", "versions": [{"version": "v1", "created": "Sat, 14 Sep 2013 13:08:16 GMT"}], "update_date": "2013-09-17", "authors_parsed": [["Vidyasagar", "Mathukumalli", ""]]}, {"id": "1309.3700", "submitter": "Karthik Bharath", "authors": "Karthik Bharath", "title": "A Note on Density Estimation for Binary Sequences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A histogram estimate of the Radon-Nikodym derivative of a probability measure\nwith respect to a dominating measure is developed for binary sequences in\n$\\{0,1\\}^{\\mathbb{N}}$. A necessary and sufficient condition for the\nconsistency of the estimate in the mean-square sense is given. It is noted that\nthe product topology on $\\{0,1\\}^{\\mathbb{N}}$ and the corresponding dominating\nproduct measure pose considerable restrictions on the rate of sampling required\nfor the requisite convergence.\n", "versions": [{"version": "v1", "created": "Sat, 14 Sep 2013 21:14:44 GMT"}], "update_date": "2013-09-17", "authors_parsed": [["Bharath", "Karthik", ""]]}, {"id": "1309.3771", "submitter": "Dmitry Schmerling", "authors": "Dmitry Schmerling", "title": "New models of income distribution, graduation as the explanation of Gini\n  coefficient", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.GN math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper covers the new model of wage distribution in typical group of\npeople. The model provides the opportunity to reparameterize applicable income\ndistribution model: Pareto, logarithmically normal, logarithmically logistic,\nDagum etc. The model ensures the graduation of Gini index values by polynomial\ndegree of wage distribution as well as different types of income distribution.\nThe given approach clarifies the nature of income inequality.\n", "versions": [{"version": "v1", "created": "Sun, 15 Sep 2013 15:45:48 GMT"}], "update_date": "2013-09-17", "authors_parsed": [["Schmerling", "Dmitry", ""]]}, {"id": "1309.3842", "submitter": "Anne Marie Svane", "authors": "Anne Marie Svane", "title": "Estimation of intrinsic volumes from digital grey-scale images", "comments": "33 pages", "journal-ref": null, "doi": "10.1007/s10851-013-0469-9", "report-no": null, "categories": "math.ST cs.CV stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Local algorithms are common tools for estimating intrinsic volumes from\nblack-and-white digital images. However, these algorithms are typically biased\nin the design based setting, even when the resolution tends to infinity.\nMoreover, images recorded in practice are most often blurred grey-scale images\nrather than black-and-white. In this paper, an extended definition of local\nalgorithms, applying directly to grey-scale images without thresholding, is\nsuggested. We investigate the asymptotics of these new algorithms when the\nresolution tends to infinity and apply this to construct estimators for surface\narea and integrated mean curvature that are asymptotically unbiased in certain\nnatural settings.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2013 07:56:12 GMT"}], "update_date": "2014-02-11", "authors_parsed": [["Svane", "Anne Marie", ""]]}, {"id": "1309.3845", "submitter": "Anne Marie Svane", "authors": "Anne Marie Svane", "title": "Local digital algorithms for estimating the integrated mean curvature of\n  r-regular sets", "comments": "29 pages", "journal-ref": "Discrete Comput. Geom. 54 (2015), no. 2, 316-338", "doi": "10.1007/s00454-015-9708-8", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider the design based situation where an $r$-regular set is sampled on a\nrandom lattice. A fast algorithm for estimating the integrated mean curvature\nbased on this observation is to use a weighted sum of $2\\times \\dotsm \\times 2$\nconfiguration counts. We show that for a randomly translated lattice, no\nasymptotically unbiased estimator of this type exists in dimension greater than\nor equal to three, while for stationary isotropic lattices, asymptotically\nunbiased estimators are plenty. Both results follow from a general formula that\nwe state and prove, describing the asymptotic behavior of hit-or-miss\ntransforms of $r$-regular sets.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2013 08:08:03 GMT"}, {"version": "v2", "created": "Mon, 7 Oct 2013 13:58:03 GMT"}], "update_date": "2016-02-24", "authors_parsed": [["Svane", "Anne Marie", ""]]}, {"id": "1309.3912", "submitter": "Joseph Rynkiewicz", "authors": "Joseph Rynkiewicz (SAMM)", "title": "Asymptotics for regression models under loss of identifiability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper discusses the asymptotic behavior of regression models under\ngeneral conditions. First, we give a general inequality for the difference of\nthe sum of square errors (SSE) of the estimated regression model and the SSE of\nthe theoretical best regression function in our model. A set of generalized\nderivative functions is a key tool in deriving such inequality. Under suitable\nDonsker condition for this set, we give the asymptotic distribution for the\ndifference of SSE. We show how to get this Donsker property for parametric\nmodels even if the parameters characterizing the best regression function are\nnot unique. This result is applied to neural networks regression models with\nredundant hidden units when loss of identifiability occurs.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2013 11:50:05 GMT"}], "update_date": "2013-09-17", "authors_parsed": [["Rynkiewicz", "Joseph", "", "SAMM"]]}, {"id": "1309.4029", "submitter": "R\\'{e}mi Bardenet", "authors": "R\\'emi Bardenet, Odalric-Ambrym Maillard", "title": "Concentration inequalities for sampling without replacement", "comments": "Published at http://dx.doi.org/10.3150/14-BEJ605 in the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2015, Vol. 21, No. 3, 1361-1385", "doi": "10.3150/14-BEJ605", "report-no": "IMS-BEJ-BEJ605", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Concentration inequalities quantify the deviation of a random variable from a\nfixed value. In spite of numerous applications, such as opinion surveys or\necological counting procedures, few concentration results are known for the\nsetting of sampling without replacement from a finite population. Until now,\nthe best general concentration inequality has been a Hoeffding inequality due\nto Serfling [Ann. Statist. 2 (1974) 39-48]. In this paper, we first improve on\nthe fundamental result of Serfling [Ann. Statist. 2 (1974) 39-48], and further\nextend it to obtain a Bernstein concentration bound for sampling without\nreplacement. We then derive an empirical version of our bound that does not\nrequire the variance to be known to the user.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2013 16:38:20 GMT"}, {"version": "v2", "created": "Mon, 27 Jul 2015 12:08:24 GMT"}], "update_date": "2015-07-28", "authors_parsed": [["Bardenet", "R\u00e9mi", ""], ["Maillard", "Odalric-Ambrym", ""]]}, {"id": "1309.4111", "submitter": "Tai Qin", "authors": "Tai Qin, Karl Rohe", "title": "Regularized Spectral Clustering under the Degree-Corrected Stochastic\n  Blockmodel", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spectral clustering is a fast and popular algorithm for finding clusters in\nnetworks. Recently, Chaudhuri et al. (2012) and Amini et al.(2012) proposed\ninspired variations on the algorithm that artificially inflate the node degrees\nfor improved statistical performance. The current paper extends the previous\nstatistical estimation results to the more canonical spectral clustering\nalgorithm in a way that removes any assumption on the minimum degree and\nprovides guidance on the choice of the tuning parameter. Moreover, our results\nshow how the \"star shape\" in the eigenvectors--a common feature of empirical\nnetworks--can be explained by the Degree-Corrected Stochastic Blockmodel and\nthe Extended Planted Partition model, two statistical models that allow for\nhighly heterogeneous degrees. Throughout, the paper characterizes and justifies\nseveral of the variations of the spectral clustering algorithm in terms of\nthese models.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2013 20:47:51 GMT"}], "update_date": "2013-09-18", "authors_parsed": [["Qin", "Tai", ""], ["Rohe", "Karl", ""]]}, {"id": "1309.4158", "submitter": "Masoud  Nasari", "authors": "Miklos Csorgo, Masoud M Nasari and Mohamedou Ould-Haye", "title": "Randomized pivots for means of short and long memory linear processes", "comments": "35 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce randomized pivots for the means of short and long\nmemory linear processes. We show that, under the same conditions, these pivots\nconverge in distribution to the same limit as that of their classical\nnon-randomized counterparts. We also present numerical results that indicate\nthat these randomized pivots significantly outperform their classical\ncounterparts and as a result they lead to a more accurate inference about the\npopulation mean.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2013 02:35:21 GMT"}, {"version": "v2", "created": "Tue, 13 May 2014 01:23:18 GMT"}], "update_date": "2014-05-14", "authors_parsed": [["Csorgo", "Miklos", ""], ["Nasari", "Masoud M", ""], ["Ould-Haye", "Mohamedou", ""]]}, {"id": "1309.4193", "submitter": "Ying  Zhu", "authors": "Ying Zhu", "title": "Sparse Linear Models and Two-Stage Estimation in High-Dimensional\n  Settings with Possibly Many Endogenous Regressors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores the validity of the two-stage estimation procedure for\nsparse linear models in high-dimensional settings with possibly many endogenous\nregressors. In particular, the number of endogenous regressors in the main\nequation and the instruments in the first-stage equations can grow with and\nexceed the sample size n. The analysis concerns the exact sparsity case, i.e.,\nthe maximum number of non-zero components in the vectors of parameters in the\nfirst-stage equations, k1, and the number of non-zero components in the vector\nof parameters in the second-stage equation, k2, are allowed to grow with n but\nslowly compared to n. I consider the high-dimensional version of the two-stage\nleast square estimator where one obtains the fitted regressors from the\nfirst-stage regression by a least square estimator with l_1-regularization (the\nLasso or Dantzig selector) when the first-stage regression concerns a large\nnumber of instruments relative to n, and then construct a similar estimator\nusing these fitted regressors in the second-stage regression. The main\ntheoretical results of this paper are non-asymptotic bounds from which I\nestablish sufficient scaling conditions on the sample size for estimation\nconsistency in l_2-norm and variable-selection consistency. A technical issue\nregarding the so-called \"restricted eigenvalue (RE) condition\" for estimation\nconsistency and the \"mutual incoherence (MI) condition\" for selection\nconsistency arises in the two-stage estimation from allowing the number of\nregressors in the main equation to exceed n and this paper provides analysis to\nverify these RE and MI conditions. Depending on the underlying assumptions, the\nupper bounds on the l_2-error and the sample size required to obtain these\nconsistency results differ by factors involving k1 and/or k2. Simulations are\nconducted to gain insight on the finite sample performance.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2013 06:13:19 GMT"}], "update_date": "2013-09-18", "authors_parsed": [["Zhu", "Ying", ""]]}, {"id": "1309.4632", "submitter": "Valerie Isham", "authors": "Jo Kaczmarska, Valerie Isham, Christian Onof", "title": "Point process models for fine-resolution rainfall", "comments": "To appear in Hydrological Sciences Journal. 36 pages, 6 tables, 10\n  figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a recent development in the literature, a new temporal rainfall model,\nbased on the Bartlett-Lewis clustering mechanism and intended for sub-hourly\napplication, was introduced. That model replaced the rectangular rain cells of\nthe original model with finite Poisson processes of instantaneous pulses,\nallowing greater variability in rainfall intensity over short intervals. In the\npresent paper, the basic instantaneous pulse model is first extended to allow\nfor randomly varying storm types. A systematic comparison of a number of key\nmodel variants, fitted to 5-minute rainfall data from Germany, then generates\nfurther new insights into the models, leading to the development of an\nadditional model extension, which introduces dependence between rainfall\nintensity and duration in a simple way. The new model retains the original\nrectangular cells, previously assumed inappropriate for fine-scale data,\nobviating the need for the computationally more intensive instantaneous pulse\nmodel.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2013 12:57:27 GMT"}, {"version": "v2", "created": "Fri, 20 Sep 2013 13:03:59 GMT"}], "update_date": "2013-09-23", "authors_parsed": [["Kaczmarska", "Jo", ""], ["Isham", "Valerie", ""], ["Onof", "Christian", ""]]}, {"id": "1309.4652", "submitter": "Holger Dette", "authors": "Holger Dette, Viatcheslav B. Melas, Petr Shpilev", "title": "Robust T-optimal discriminating designs", "comments": "Published in at http://dx.doi.org/10.1214/13-AOS1117 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2013, Vol. 41, No. 4, 1693-1715", "doi": "10.1214/13-AOS1117", "report-no": "IMS-AOS-AOS1117", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the problem of constructing optimal discriminating\nexperimental designs for competing regression models on the basis of the\nT-optimality criterion introduced by Atkinson and Fedorov [Biometrika 62 (1975)\n57-70]. T-optimal designs depend on unknown model parameters and it is\ndemonstrated that these designs are sensitive with respect to misspecification.\nAs a solution to this problem we propose a Bayesian and standardized maximin\napproach to construct robust and efficient discriminating designs on the basis\nof the T-optimality criterion. It is shown that the corresponding Bayesian and\nstandardized maximin optimality criteria are closely related to linear\noptimality criteria. For the problem of discriminating between two polynomial\nregression models which differ in the degree by two the robust T-optimal\ndiscriminating designs can be found explicitly. The results are illustrated in\nseveral examples.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2013 14:04:44 GMT"}], "update_date": "2014-01-30", "authors_parsed": [["Dette", "Holger", ""], ["Melas", "Viatcheslav B.", ""], ["Shpilev", "Petr", ""]]}, {"id": "1309.4656", "submitter": "Valen E. Johnson", "authors": "Valen E. Johnson", "title": "Uniformly most powerful Bayesian tests", "comments": "Published in at http://dx.doi.org/10.1214/13-AOS1123 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2013, Vol. 41, No. 4, 1716-1741", "doi": "10.1214/13-AOS1123", "report-no": "IMS-AOS-AOS1123", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uniformly most powerful tests are statistical hypothesis tests that provide\nthe greatest power against a fixed null hypothesis among all tests of a given\nsize. In this article, the notion of uniformly most powerful tests is extended\nto the Bayesian setting by defining uniformly most powerful Bayesian tests to\nbe tests that maximize the probability that the Bayes factor, in favor of the\nalternative hypothesis, exceeds a specified threshold. Like their classical\ncounterpart, uniformly most powerful Bayesian tests are most easily defined in\none-parameter exponential family models, although extensions outside of this\nclass are possible. The connection between uniformly most powerful tests and\nuniformly most powerful Bayesian tests can be used to provide an approximate\ncalibration between p-values and Bayes factors. Finally, issues regarding the\nstrong dependence of resulting Bayes factors and p-values on sample size are\ndiscussed.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2013 14:24:03 GMT"}], "update_date": "2014-01-30", "authors_parsed": [["Johnson", "Valen E.", ""]]}, {"id": "1309.4667", "submitter": "Jia Li", "authors": "Jia Li, Viktor Todorov, George Tauchen", "title": "Volatility occupation times", "comments": "Published in at http://dx.doi.org/10.1214/13-AOS1135 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2013, Vol. 41, No. 4, 1865-1891", "doi": "10.1214/13-AOS1135", "report-no": "IMS-AOS-AOS1135", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose nonparametric estimators of the occupation measure and the\noccupation density of the diffusion coefficient (stochastic volatility) of a\ndiscretely observed It\\^{o} semimartingale on a fixed interval when the mesh of\nthe observation grid shrinks to zero asymptotically. In a first step we\nestimate the volatility locally over blocks of shrinking length, and then in a\nsecond step we use these estimates to construct a sample analogue of the\nvolatility occupation time and a kernel-based estimator of its density. We\nprove the consistency of our estimators and further derive bounds for their\nrates of convergence. We use these results to estimate nonparametrically the\nquantiles associated with the volatility occupation measure.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2013 14:51:52 GMT"}], "update_date": "2014-01-30", "authors_parsed": [["Li", "Jia", ""], ["Todorov", "Viktor", ""], ["Tauchen", "George", ""]]}, {"id": "1309.4686", "submitter": "Max Farrell", "authors": "Max H. Farrell", "title": "Robust Inference on Average Treatment Effects with Possibly More\n  Covariates than Observations", "comments": "48 pages, 1 figure, 1 table", "journal-ref": "Journal of Econometrics 189 (2015), pp. 1-23", "doi": "10.1016/j.jeconom.2015.06.017", "report-no": null, "categories": "math.ST econ.EM stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper concerns robust inference on average treatment effects following\nmodel selection. In the selection on observables framework, we show how to\nconstruct confidence intervals based on a doubly-robust estimator that are\nrobust to model selection errors and prove that they are valid uniformly over a\nlarge class of treatment effect models. The class allows for multivalued\ntreatments with heterogeneous effects (in observables), general\nheteroskedasticity, and selection amongst (possibly) more covariates than\nobservations. Our estimator attains the semiparametric efficiency bound under\nappropriate conditions. Precise conditions are given for any model selector to\nyield these results, and we show how to combine data-driven selection with\neconomic theory. For implementation, we give a specific proposal for selection\nbased on the group lasso, which is particularly well-suited to treatment\neffects data, and derive new results for high-dimensional, sparse multinomial\nlogistic regression. A simulation study shows our estimator performs very well\nin finite samples over a wide range of models. Revisiting the National\nSupported Work demonstration data, our method yields accurate estimates and\ntight confidence intervals.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2013 15:47:27 GMT"}, {"version": "v2", "created": "Wed, 1 Apr 2015 19:24:26 GMT"}, {"version": "v3", "created": "Thu, 1 Feb 2018 22:49:57 GMT"}], "update_date": "2018-04-13", "authors_parsed": [["Farrell", "Max H.", ""]]}, {"id": "1309.4740", "submitter": "Song Cai", "authors": "Song Cai, Jiahua Chen, James V. Zidek", "title": "Hypothesis testing in the presence of multiple samples under density\n  ratio models", "comments": "38 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a hypothesis testing method given independent samples\nfrom a number of connected populations. The method is motivated by a forestry\nproject for monitoring change in the strength of lumber. Traditional practice\nhas been built upon nonparametric methods which ignore the fact that these\npopulations are connected. By pooling the information in multiple samples\nthrough a density ratio model, the proposed empirical likelihood method leads\nto a more efficient inference and therefore reduces the cost in applications.\nThe new test has a classical chi-square null limiting distribution. Its power\nfunction is obtained under a class of local alternatives. The local power is\nfound increased even when some underlying populations are unrelated to the\nhypothesis of interest. Simulation studies confirm that this test has better\npower properties than potential competitors, and is robust to model\nmisspecification. An application example to lumber strength is included.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2013 18:36:44 GMT"}, {"version": "v2", "created": "Fri, 1 Nov 2013 13:51:17 GMT"}, {"version": "v3", "created": "Sun, 22 Dec 2013 01:50:46 GMT"}, {"version": "v4", "created": "Thu, 14 May 2015 19:54:48 GMT"}], "update_date": "2015-05-15", "authors_parsed": [["Cai", "Song", ""], ["Chen", "Jiahua", ""], ["Zidek", "James V.", ""]]}, {"id": "1309.4864", "submitter": "Peter Hall", "authors": "Peter Hall, Joel Horowitz", "title": "A simple bootstrap method for constructing nonparametric confidence\n  bands for functions", "comments": "Published in at http://dx.doi.org/10.1214/13-AOS1137 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2013, Vol. 41, No. 4, 1892-1921", "doi": "10.1214/13-AOS1137", "report-no": "IMS-AOS-AOS1137", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard approaches to constructing nonparametric confidence bands for\nfunctions are frustrated by the impact of bias, which generally is not\nestimated consistently when using the bootstrap and conventionally smoothed\nfunction estimators. To overcome this problem it is common practice to either\nundersmooth, so as to reduce the impact of bias, or oversmooth, and thereby\nintroduce an explicit or implicit bias estimator. However, these approaches,\nand others based on nonstandard smoothing methods, complicate the process of\ninference, for example, by requiring the choice of new, unconventional\nsmoothing parameters and, in the case of undersmoothing, producing relatively\nwide bands. In this paper we suggest a new approach, which exploits to our\nadvantage one of the difficulties that, in the past, has prevented an\nattractive solution to the problem - the fact that the standard bootstrap bias\nestimator suffers from relatively high-frequency stochastic error. The high\nfrequency, together with a technique based on quantiles, can be exploited to\ndampen down the stochastic error term, leading to relatively narrow,\nsimple-to-construct confidence bands.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2013 06:07:09 GMT"}], "update_date": "2014-01-30", "authors_parsed": [["Hall", "Peter", ""], ["Horowitz", "Joel", ""]]}, {"id": "1309.4889", "submitter": "Minjing Tao", "authors": "Minjing Tao, Yazhen Wang, Harrison H. Zhou", "title": "Optimal sparse volatility matrix estimation for high-dimensional It\\^{o}\n  processes with measurement errors", "comments": "Published in at http://dx.doi.org/10.1214/13-AOS1128 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2013, Vol. 41, No. 4, 1816-1864", "doi": "10.1214/13-AOS1128", "report-no": "IMS-AOS-AOS1128", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic processes are often used to model complex scientific problems in\nfields ranging from biology and finance to engineering and physical science.\nThis paper investigates rate-optimal estimation of the volatility matrix of a\nhigh-dimensional It\\^{o} process observed with measurement errors at discrete\ntime points. The minimax rate of convergence is established for estimating\nsparse volatility matrices. By combining the multi-scale and threshold\napproaches we construct a volatility matrix estimator to achieve the optimal\nconvergence rate. The minimax lower bound is derived by considering a subclass\nof It\\^{o} processes for which the minimax lower bound is obtained through a\nnovel equivalent model of covariance matrix estimation for independent but\nnonidentically distributed observations and through a delicate construction of\nthe least favorable parameters. In addition, a simulation study was conducted\nto test the finite sample performance of the optimal estimator, and the\nsimulation results were found to support the established asymptotic theory.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2013 08:16:07 GMT"}], "update_date": "2014-01-30", "authors_parsed": [["Tao", "Minjing", ""], ["Wang", "Yazhen", ""], ["Zhou", "Harrison H.", ""]]}, {"id": "1309.4981", "submitter": "Enkelejd Hashorva", "authors": "Enkelejd Hashorva and Lanpeng Ji", "title": "Extremes and first passage times of correlated fBm's", "comments": "16 pages, title changed", "journal-ref": "Journal of Applied Probability, 51(3), 713-726 (2014)", "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $\\{X_i(t),t\\ge0\\}, i=1,2$ be two standard fractional Brownian motions\nbeing jointly Gaussian with constant cross-correlation. In this paper we derive\nthe exact asymptotics of the joint survival function $$\n\\mathbb{P}\\{\\sup_{s\\in[0,1]}X_1(s)>u,\\ \\sup_{t\\in[0,1]}X_2(t)>u\\} $$ as\n$u\\rightarrow \\infty$. A novel finding of this contribution is the exponential\napproximation of the joint conditional first passage times of $X_1, X_2$. As a\nby-product we obtain generalizations of the Borell-TIS inequality and the\nPiterbarg inequality for 2-dimensional Gaussian random fields.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2013 14:00:10 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2014 20:22:04 GMT"}], "update_date": "2014-10-08", "authors_parsed": [["Hashorva", "Enkelejd", ""], ["Ji", "Lanpeng", ""]]}, {"id": "1309.4984", "submitter": "Arnold Janssen Prof. Dr.", "authors": "Arnold Janssen and Vladimir Ostrovski", "title": "The Convolution Theorem of Hajek and Le Cam - Revisited", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The present paper establishes convolution theorems for regular estimators\nwhen the limit experiment is non-Gaussian or of infnite dimension with sparse\nparameter space. Applications are given for Gaussian shift experiments of\ninfnite dimension, the Brownian motion signal plus noise model, Levy processes\nwhich are observed at discrete times and estimators of the endpoints of\ndensities with jumps. The method of proof is also of interest for the classical\nconvolution theorem of Hajek and Le Cam. As technical tool we present an\nelementary approach for the comparison of limit experiments on standard Borel\nspaces.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2013 14:01:59 GMT"}], "update_date": "2013-09-20", "authors_parsed": [["Janssen", "Arnold", ""], ["Ostrovski", "Vladimir", ""]]}, {"id": "1309.5003", "submitter": "David K\\\"allberg Mr", "authors": "David K\\\"allberg and Oleg Seleznjev", "title": "Estimation of quadratic density functionals under m-dependence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study estimation of certain integral functionals of one or\ntwo densities with samples from stationary m-dependent sequences. We consider\ntwo types of U-statistic estimators for these functionals that are functions of\nthe number of epsilon-close vector observations in the samples. We show that\nthe estimators are consistent and obtain their rates of convergence under weak\ndistributional assumptions. In particular, we propose estimators based on\nincomplete U-statistics which have favorable consistency properties even when\nm-dependence is the only dependence condition that can be imposed on the\nstationary sequences. The results can be used for divergence and entropy\nestimation, and thus find many applications in statistics and applied sciences.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2013 14:43:17 GMT"}], "update_date": "2013-09-20", "authors_parsed": [["K\u00e4llberg", "David", ""], ["Seleznjev", "Oleg", ""]]}, {"id": "1309.5056", "submitter": "Anand Bhaskar", "authors": "Anand Bhaskar, Yun S. Song", "title": "Descartes' rule of signs and the identifiability of population\n  demographic models from genomic variation data", "comments": "Published in at http://dx.doi.org/10.1214/14-AOS1264 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2014, Vol. 42, No. 6, 2469-2493", "doi": "10.1214/14-AOS1264", "report-no": "IMS-AOS-AOS1264", "categories": "q-bio.PE math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The sample frequency spectrum (SFS) is a widely-used summary statistic of\ngenomic variation in a sample of homologous DNA sequences. It provides a highly\nefficient dimensional reduction of large-scale population genomic data and its\nmathematical dependence on the underlying population demography is well\nunderstood, thus enabling the development of efficient inference algorithms.\nHowever, it has been recently shown that very different population demographies\ncan actually generate the same SFS for arbitrarily large sample sizes. Although\nin principle this nonidentifiability issue poses a thorny challenge to\nstatistical inference, the population size functions involved in the\ncounterexamples are arguably not so biologically realistic. Here, we revisit\nthis problem and examine the identifiability of demographic models under the\nrestriction that the population sizes are piecewise-defined where each piece\nbelongs to some family of biologically-motivated functions. Under this\nassumption, we prove that the expected SFS of a sample uniquely determines the\nunderlying demographic model, provided that the sample is sufficiently large.\nWe obtain a general bound on the sample size sufficient for identifiability;\nthe bound depends on the number of pieces in the demographic model and also on\nthe type of population size function in each piece. In the cases of\npiecewise-constant, piecewise-exponential and piecewise-generalized-exponential\nmodels, which are often assumed in population genomic inferences, we provide\nexplicit formulas for the bounds as simple functions of the number of pieces.\nLastly, we obtain analogous results for the \"folded\" SFS, which is often used\nwhen there is ambiguity as to which allelic type is ancestral. Our results are\nproved using a generalization of Descartes' rule of signs for polynomials to\nthe Laplace transform of piecewise continuous functions.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2013 17:22:24 GMT"}, {"version": "v2", "created": "Mon, 11 Aug 2014 00:09:18 GMT"}, {"version": "v3", "created": "Mon, 1 Dec 2014 10:56:46 GMT"}], "update_date": "2014-12-02", "authors_parsed": [["Bhaskar", "Anand", ""], ["Song", "Yun S.", ""]]}, {"id": "1309.5192", "submitter": "Hamid  Zareifard Jahromi", "authors": "Hamid Zareifard, Havard Rue, Majid Jafari Khaledi, Finn Lindgren", "title": "A skew Gaussian decomposable graphical model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper propose a novel decomposable graphical model to accommodate skew\nGaussian graphical models. We encode conditional independence structure among\nthe components of the multivariate closed skew normal random vector by means of\na decomposable graph and so that the pattern of zero off-diagonal elements in\nthe precision matrix corresponds to the missing edges of the given graph. We\npresent conditions that guarantee the propriety of the posterior distributions\nunder the standard noninformative priors for mean vector and precision matrix,\nand a proper prior for skewness parameter. The identifiability of the\nparameters is investigated by a simulation study. Finally, we apply our\nmethodology to two data sets.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2013 07:40:06 GMT"}], "update_date": "2013-09-23", "authors_parsed": [["Zareifard", "Hamid", ""], ["Rue", "Havard", ""], ["Khaledi", "Majid Jafari", ""], ["Lindgren", "Finn", ""]]}, {"id": "1309.5310", "submitter": "Marco Duarte", "authors": "Waheed U. Bajwa, Marco F. Duarte, and Robert Calderbank", "title": "Conditioning of Random Block Subdictionaries with Applications to\n  Block-Sparse Recovery and Regression", "comments": "39 pages, 3 figures. A revised and expanded version of the paper\n  published in IEEE Transactions on Information Theory (DOI:\n  10.1109/TIT.2015.2429632); this revision includes corrections in the proofs\n  of some of the results", "journal-ref": "IEEE Trans. Information Theory, vol. 61, no. 7, pp. 4060-4079,\n  Jul. 2015", "doi": "10.1109/TIT.2015.2429632", "report-no": null, "categories": "math.ST cs.IT math.IT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The linear model, in which a set of observations is assumed to be given by a\nlinear combination of columns of a matrix, has long been the mainstay of the\nstatistics and signal processing literature. One particular challenge for\ninference under linear models is understanding the conditions on the dictionary\nunder which reliable inference is possible. This challenge has attracted\nrenewed attention in recent years since many modern inference problems deal\nwith the \"underdetermined\" setting, in which the number of observations is much\nsmaller than the number of columns in the dictionary. This paper makes several\ncontributions for this setting when the set of observations is given by a\nlinear combination of a small number of groups of columns of the dictionary,\ntermed the \"block-sparse\" case. First, it specifies conditions on the\ndictionary under which most block subdictionaries are well conditioned. This\nresult is fundamentally different from prior work on block-sparse inference\nbecause (i) it provides conditions that can be explicitly computed in\npolynomial time, (ii) the given conditions translate into near-optimal scaling\nof the number of columns of the block subdictionaries as a function of the\nnumber of observations for a large class of dictionaries, and (iii) it suggests\nthat the spectral norm and the quadratic-mean block coherence of the dictionary\n(rather than the worst-case coherences) fundamentally limit the scaling of\ndimensions of the well-conditioned block subdictionaries. Second, this paper\ninvestigates the problems of block-sparse recovery and block-sparse regression\nin underdetermined settings. Near-optimal block-sparse recovery and regression\nare possible for certain dictionaries as long as the dictionary satisfies\neasily computable conditions and the coefficients describing the linear\ncombination of groups of columns can be modeled through a mild statistical\nprior.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2013 16:21:04 GMT"}, {"version": "v2", "created": "Sun, 14 Dec 2014 01:39:19 GMT"}, {"version": "v3", "created": "Tue, 28 Apr 2015 16:56:33 GMT"}, {"version": "v4", "created": "Sun, 28 Aug 2016 20:15:12 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Bajwa", "Waheed U.", ""], ["Duarte", "Marco F.", ""], ["Calderbank", "Robert", ""]]}, {"id": "1309.5352", "submitter": "Maxwell Grazier G'Sell", "authors": "Max Grazier G'Sell, Stefan Wager, Alexandra Chouldechova, Robert\n  Tibshirani", "title": "Sequential Selection Procedures and False Discovery Rate Control", "comments": "31 pages, 14 figures. Accepted to the Journal of the Royal\n  Statistical Society: Series B", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a multiple hypothesis testing setting where the hypotheses are\nordered and one is only permitted to reject an initial contiguous block,\nH_1,\\dots,H_k, of hypotheses. A rejection rule in this setting amounts to a\nprocedure for choosing the stopping point k. This setting is inspired by the\nsequential nature of many model selection problems, where choosing a stopping\npoint or a model is equivalent to rejecting all hypotheses up to that point and\nnone thereafter. We propose two new testing procedures, and prove that they\ncontrol the false discovery rate in the ordered testing setting. We also show\nhow the methods can be applied to model selection using recent results on\np-values in sequential model selection settings.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2013 19:21:01 GMT"}, {"version": "v2", "created": "Fri, 25 Apr 2014 03:35:52 GMT"}, {"version": "v3", "created": "Mon, 23 Mar 2015 20:46:11 GMT"}], "update_date": "2015-03-25", "authors_parsed": [["G'Sell", "Max Grazier", ""], ["Wager", "Stefan", ""], ["Chouldechova", "Alexandra", ""], ["Tibshirani", "Robert", ""]]}, {"id": "1309.5413", "submitter": "Mark Huber", "authors": "Mark Huber", "title": "An unbiased estimate for the mean of a {0,1} random variable with\n  relative error distribution independent of the mean", "comments": "12 pages; 0 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.CC math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Say $X_1,X_2,\\ldots$ are independent identically distributed Bernoulli random\nvariables with mean $p$. This paper builds a new estimate $\\hat p$ of $p$ that\nhas the property that the relative error, $\\hat p /p - 1$, of the estimate does\nnot depend in any way on the value of $p$. This allows the construction of\nexact confidence intervals for $p$ of any desired level without needing any\nsort of limit or approximation. In addition, $\\hat p$ is unbiased. For\n$\\epsilon$ and $\\delta$ in $(0,1)$, to obtain an estimate where\n$\\mathbb{P}(|\\hat p/p - 1| > \\epsilon) \\leq \\delta$, the new algorithm takes on\naverage at most $2\\epsilon^{-2} p^{-1}\\ln(2\\delta^{-1})(1 - (14/3)\n\\epsilon)^{-1}$ samples. It is also shown that any such algorithm that applies\nwhenever $p \\leq 1/2$ requires at least $0.2\\epsilon^{-2}\np^{-1}\\ln((2-\\delta)\\delta^{-1})(1 + 2 \\epsilon)$ samples. The same algorithm\ncan also be applied to estimate the mean of any random variable that falls in\n$[0,1]$.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2013 23:37:27 GMT"}, {"version": "v2", "created": "Tue, 17 Nov 2015 00:15:41 GMT"}], "update_date": "2015-11-18", "authors_parsed": [["Huber", "Mark", ""]]}, {"id": "1309.5534", "submitter": "Mariela  Sued", "authors": "Julieta Molina, Lucio Pantazis, Mariela Sued", "title": "Some considerations on the back door theorem and conditional\n  randomization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we propose a different surgical modified model for the\nconstruction of counterfactual variables under non parametric structural\nequation models. This approach allows the simultaneous representation of\ncounterfactual responses and observed treatment assignment, at least when the\nintervention is done in one node. Using the new proposal, the d-separation\ncriterion is used verify conditions related with ignorability or conditional\nignorability and a new proof of the back door theorem is provided under this\nframework.\n", "versions": [{"version": "v1", "created": "Sat, 21 Sep 2013 20:45:48 GMT"}, {"version": "v2", "created": "Mon, 7 Oct 2013 12:58:57 GMT"}], "update_date": "2013-10-08", "authors_parsed": [["Molina", "Julieta", ""], ["Pantazis", "Lucio", ""], ["Sued", "Mariela", ""]]}, {"id": "1309.5740", "submitter": "Stephan Morgenthaler", "authors": "Maya Shevlyakova and Stephan Morgenthaler", "title": "Identifying Graphical Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to identify reliably a positive or negative partial correlation\nbetween the expression levels of two genes is influenced by the number $p$ of\ngenes, the number $n$ of analyzed samples, and the statistical properties of\nthe measurements. Classical statistical theory teaches that the product of the\nroot sample size multiplied by the size of the partial correlation is the\ncrucial quantity. But this has to be combined with some adjustment for\nmultiplicity depending on $p$, which makes the classical analysis somewhat\narbitrary. We investigate this problem through the lens of the Kullback-Leibler\ndivergence, which is a measure of the average information for detecting an\neffect. We conclude that commonly sized studies in genetical epidemiology are\nnot able to reliably detect moderately strong links.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2013 09:37:37 GMT"}], "update_date": "2013-09-24", "authors_parsed": [["Shevlyakova", "Maya", ""], ["Morgenthaler", "Stephan", ""]]}, {"id": "1309.5914", "submitter": "Zongming Ma", "authors": "Zongming Ma, Yihong Wu", "title": "Computational barriers in minimax submatrix detection", "comments": "Published at http://dx.doi.org/10.1214/14-AOS1300 in the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2015, Vol. 43, No. 3, 1089-1116", "doi": "10.1214/14-AOS1300", "report-no": "IMS-AOS-AOS1300", "categories": "math.ST cs.IT math.IT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the minimax detection of a small submatrix of elevated\nmean in a large matrix contaminated by additive Gaussian noise. To investigate\nthe tradeoff between statistical performance and computational cost from a\ncomplexity-theoretic perspective, we consider a sequence of discretized models\nwhich are asymptotically equivalent to the Gaussian model. Under the hypothesis\nthat the planted clique detection problem cannot be solved in randomized\npolynomial time when the clique size is of smaller order than the square root\nof the graph size, the following phase transition phenomenon is established:\nwhen the size of the large matrix $p\\to\\infty$, if the submatrix size\n$k=\\Theta(p^{\\alpha})$ for any $\\alpha\\in(0,{2}/{3})$, computational complexity\nconstraints can incur a severe penalty on the statistical performance in the\nsense that any randomized polynomial-time test is minimax suboptimal by a\npolynomial factor in $p$; if $k=\\Theta(p^{\\alpha})$ for any\n$\\alpha\\in({2}/{3},1)$, minimax optimal detection can be attained within\nconstant factors in linear time. Using Schatten norm loss as a representative\nexample, we show that the hardness of attaining the minimax estimation rate can\ncrucially depend on the loss function. Implications on the hardness of support\nrecovery are also obtained.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2013 19:07:58 GMT"}, {"version": "v2", "created": "Mon, 18 Nov 2013 09:41:02 GMT"}, {"version": "v3", "created": "Tue, 19 Aug 2014 15:13:27 GMT"}, {"version": "v4", "created": "Wed, 3 Jun 2015 07:26:00 GMT"}], "update_date": "2015-06-04", "authors_parsed": [["Ma", "Zongming", ""], ["Wu", "Yihong", ""]]}, {"id": "1309.5923", "submitter": "Mengjie Chen", "authors": "Mengjie Chen and Zhao Ren and Hongyu Zhao and Harrison Zhou", "title": "Asymptotically Normal and Efficient Estimation of Covariate-Adjusted\n  Gaussian Graphical Model", "comments": "54 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A tuning-free procedure is proposed to estimate the covariate-adjusted\nGaussian graphical model. For each finite subgraph, this estimator is\nasymptotically normal and efficient. As a consequence, a confidence interval\ncan be obtained for each edge. The procedure enjoys easy implementation and\nefficient computation through parallel estimation on subgraphs or edges. We\nfurther apply the asymptotic normality result to perform support recovery\nthrough edge-wise adaptive thresholding. This support recovery procedure is\ncalled ANTAC, standing for Asymptotically Normal estimation with Thresholding\nafter Adjusting Covariates. ANTAC outperforms other methodologies in the\nliterature in a range of simulation studies. We apply ANTAC to identify\ngene-gene interactions using an eQTL dataset. Our result achieves better\ninterpretability and accuracy in comparison with CAMPE.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2013 19:17:48 GMT"}], "update_date": "2013-09-24", "authors_parsed": [["Chen", "Mengjie", ""], ["Ren", "Zhao", ""], ["Zhao", "Hongyu", ""], ["Zhou", "Harrison", ""]]}, {"id": "1309.5936", "submitter": "Patrick J. Wolfe", "authors": "Patrick J. Wolfe and Sofia C. Olhede", "title": "Nonparametric graphon estimation", "comments": "52 pages; submitted for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.CO math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a nonparametric framework for the analysis of networks, based on a\nnatural limit object termed a graphon. We prove consistency of graphon\nestimation under general conditions, giving rates which include the important\npractical setting of sparse networks. Our results cover dense and sparse\nstochastic blockmodels with a growing number of classes, under model\nmisspecification. We use profile likelihood methods, and connect our results to\napproximation theory, nonparametric function estimation, and the theory of\ngraph limits.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2013 19:54:20 GMT"}], "update_date": "2013-09-30", "authors_parsed": [["Wolfe", "Patrick J.", ""], ["Olhede", "Sofia C.", ""]]}, {"id": "1309.5979", "submitter": "Ali Mousavi", "authors": "Ali Mousavi, Arian Maleki, Richard G. Baraniuk", "title": "Asymptotic Analysis of LASSOs Solution Path with Implications for\n  Approximate Message Passing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT math.IT stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper concerns the performance of the LASSO (also knows as basis pursuit\ndenoising) for recovering sparse signals from undersampled, randomized, noisy\nmeasurements. We consider the recovery of the signal $x_o \\in \\mathbb{R}^N$\nfrom $n$ random and noisy linear observations $y= Ax_o + w$, where $A$ is the\nmeasurement matrix and $w$ is the noise. The LASSO estimate is given by the\nsolution to the optimization problem $x_o$ with $\\hat{x}_{\\lambda} = \\arg\n\\min_x \\frac{1}{2} \\|y-Ax\\|_2^2 + \\lambda \\|x\\|_1$. Despite major progress in\nthe theoretical analysis of the LASSO solution, little is known about its\nbehavior as a function of the regularization parameter $\\lambda$. In this paper\nwe study two questions in the asymptotic setting (i.e., where $N \\rightarrow\n\\infty$, $n \\rightarrow \\infty$ while the ratio $n/N$ converges to a fixed\nnumber in $(0,1)$): (i) How does the size of the active set\n$\\|\\hat{x}_\\lambda\\|_0/N$ behave as a function of $\\lambda$, and (ii) How does\nthe mean square error $\\|\\hat{x}_{\\lambda} - x_o\\|_2^2/N$ behave as a function\nof $\\lambda$? We then employ these results in a new, reliable algorithm for\nsolving LASSO based on approximate message passing (AMP).\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2013 20:45:51 GMT"}], "update_date": "2013-09-26", "authors_parsed": [["Mousavi", "Ali", ""], ["Maleki", "Arian", ""], ["Baraniuk", "Richard G.", ""]]}, {"id": "1309.6013", "submitter": "Wen-Xin Zhou", "authors": "T. Tony Cai and Wen-Xin Zhou", "title": "A Max-Norm Constrained Minimization Approach to 1-Bit Matrix Completion", "comments": "33 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider in this paper the problem of noisy 1-bit matrix completion under\na general non-uniform sampling distribution using the max-norm as a convex\nrelaxation for the rank. A max-norm constrained maximum likelihood estimate is\nintroduced and studied. The rate of convergence for the estimate is obtained.\nInformation-theoretical methods are used to establish a minimax lower bound\nunder the general sampling model. The minimax upper and lower bounds together\nyield the optimal rate of convergence for the Frobenius norm loss.\nComputational algorithms and numerical performance are also discussed.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2013 00:31:41 GMT"}], "update_date": "2013-09-25", "authors_parsed": [["Cai", "T. Tony", ""], ["Zhou", "Wen-Xin", ""]]}, {"id": "1309.6024", "submitter": "Zhao Ren", "authors": "Zhao Ren, Tingni Sun, Cun-Hui Zhang, Harrison H. Zhou", "title": "Asymptotic normality and optimalities in estimation of large Gaussian\n  graphical models", "comments": "Published at http://dx.doi.org/10.1214/14-AOS1286 in the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2015, Vol. 43, No. 3, 991-1026", "doi": "10.1214/14-AOS1286", "report-no": "IMS-AOS-AOS1286", "categories": "math.ST stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Gaussian graphical model, a popular paradigm for studying relationship\namong variables in a wide range of applications, has attracted great attention\nin recent years. This paper considers a fundamental question: When is it\npossible to estimate low-dimensional parameters at parametric square-root rate\nin a large Gaussian graphical model? A novel regression approach is proposed to\nobtain asymptotically efficient estimation of each entry of a precision matrix\nunder a sparseness condition relative to the sample size. When the precision\nmatrix is not sufficiently sparse, or equivalently the sample size is not\nsufficiently large, a lower bound is established to show that it is no longer\npossible to achieve the parametric rate in the estimation of each entry. This\nlower bound result, which provides an answer to the delicate sample size\nquestion, is established with a novel construction of a subset of sparse\nprecision matrices in an application of Le Cam's lemma. Moreover, the proposed\nestimator is proven to have optimal convergence rate when the parametric rate\ncannot be achieved, under a minimal sample requirement. The proposed estimator\nis applied to test the presence of an edge in the Gaussian graphical model or\nto recover the support of the entire model, to obtain adaptive rate-optimal\nestimation of the entire precision matrix as measured by the matrix $\\ell_q$\noperator norm and to make inference in latent variables in the graphical model.\nAll of this is achieved under a sparsity condition on the precision matrix and\na side condition on the range of its spectrum. This significantly relaxes the\ncommonly imposed uniform signal strength condition on the precision matrix,\nirrepresentability condition on the Hessian tensor operator of the covariance\nmatrix or the $\\ell_1$ constraint on the precision matrix. Numerical results\nconfirm our theoretical findings. The ROC curve of the proposed algorithm,\nAsymptotic Normal Thresholding (ANT), for support recovery significantly\noutperforms that of the popular GLasso algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2013 01:58:23 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2013 18:16:51 GMT"}, {"version": "v3", "created": "Wed, 3 Jun 2015 05:08:24 GMT"}], "update_date": "2015-06-04", "authors_parsed": [["Ren", "Zhao", ""], ["Sun", "Tingni", ""], ["Zhang", "Cun-Hui", ""], ["Zhou", "Harrison H.", ""]]}, {"id": "1309.6061", "submitter": "Nathalie Krell", "authors": "Romain Aza\\\"is (IMB), Jean-Baptiste Bardet (LMRS), Alexandre Genadot\n  (LPMA), Nathalie Krell (IRMAR), Pierre-Andr\\'e Zitt (LAMA)", "title": "Piecewise deterministic Markov process - recent results", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a short overview of recent results on a specific class of Markov\nprocess: the Piecewise Deterministic Markov Processes (PDMPs). We first recall\nthe definition of these processes and give some general results. On more\nspecific cases such as the TCP model or a model of switched vector fields,\nbetter results can be proved, especially as regards long time behaviour. We\ncontinue our review with an infinite dimensional example of neuronal activity.\nFrom the statistical point of view, these models provide specific challenges:\nwe illustrate this point with the example of the estimation of the distribution\nof the inter-jumping times. We conclude with a short overview on numerical\nmethods used for simulating PDMPs.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2013 06:48:22 GMT"}], "update_date": "2013-09-25", "authors_parsed": [["Aza\u00efs", "Romain", "", "IMB"], ["Bardet", "Jean-Baptiste", "", "LMRS"], ["Genadot", "Alexandre", "", "LPMA"], ["Krell", "Nathalie", "", "IRMAR"], ["Zitt", "Pierre-Andr\u00e9", "", "LAMA"]]}, {"id": "1309.6108", "submitter": "Francesca Condino", "authors": "Ibrahim Elbatal, Francesca Condino, Filippo Domma", "title": "Reflected Generalized Beta Inverse Weibull Distribution: definition and\n  properties", "comments": "Baseline distribution changed, according to Jones (2012) [see\n  references]", "journal-ref": null, "doi": "10.1007/s13571-015-0114-2", "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study a broad class of distribution functions which is\ndefined by means of reflected generalized beta distribution. This class\nincludes that of Beta-generated distribution as a special case. In particular,\nwe use this class to extend the Inverse Weibull distribution in order to obtain\nthe Reflected Generalized Beta Inverse Weibull Distribution.For this new\ndistribution, moments, entropy, order statistics and a reliability measure are\nderived. The link between the Inverse Weibull and the Dagum distribution is\ngeneralized. Then the maximum likelihood estimators of the parameters are\nexamined and the observed Fisher information matrix provided. Finally, the\nusefulness of the model is illustrated by means of an application to real data.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2013 10:38:59 GMT"}, {"version": "v2", "created": "Tue, 28 Jan 2014 09:08:32 GMT"}], "update_date": "2016-07-20", "authors_parsed": [["Elbatal", "Ibrahim", ""], ["Condino", "Francesca", ""], ["Domma", "Filippo", ""]]}, {"id": "1309.6136", "submitter": "Enkelejd Hashorva", "authors": "Enkelejd Hashorva and Zhichao Weng", "title": "Berman's inequality under random scaling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Berman's inequality is the key for establishing asymptotic properties of\nmaxima of Gaussian random sequences and supremum of Gaussian random fields.\nThis contribution shows that, asymptotically an extended version of Berman's\ninequality can be established for randomly scaled Gaussian random vectors. Two\napplications presented in this paper demonstrate the use of Berman's inequality\nunder random scaling.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2013 12:51:42 GMT"}, {"version": "v2", "created": "Wed, 23 Apr 2014 10:30:25 GMT"}], "update_date": "2014-04-24", "authors_parsed": [["Hashorva", "Enkelejd", ""], ["Weng", "Zhichao", ""]]}, {"id": "1309.6138", "submitter": "Enkelejd Hashorva", "authors": "Enkelejd Hashorva and Zhichao Weng", "title": "Joint Limiting Distribution of Minima and Maxima of Complete and\n  Incomplete Samples of Stationary Sequences", "comments": null, "journal-ref": "Stochastics An International Journal of Probability and Stochastic\n  Processes, 86(5), 707-720 (2014)", "doi": "10.1080/17442508.2013.876423", "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the seminal contribution [4] the joint weak convergence of maxima and\nminima of weakly dependent stationary sequences is derived under some mild\nasymptotic conditions. In this paper we address additionally the case of\nincomplete samples assuming that the average proportion of incompleteness\nconverges in probability to some random variable. We show the joint weak\nconvergence of the maxima and minima of both complete and incomplete samples.\nIt turns out that for special cases, maxima and minima are asymptotically\nindependent.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2013 13:00:03 GMT"}], "update_date": "2014-10-08", "authors_parsed": [["Hashorva", "Enkelejd", ""], ["Weng", "Zhichao", ""]]}, {"id": "1309.6267", "submitter": "Michel Broniatowski", "authors": "Maeva Biret (LSTA), Michel Broniatowski (LSTA), Zhansheng Cao (LSTA)", "title": "A sharp Abelian theorem for the Laplace transform", "comments": "To appear in M. Hallin, D. Mason, D. Pfeifer, and J. Steinebach Eds,\n  Mathematical Statistics and Limit Theorems: Festschrift in Honor of Paul\n  Deheuvels. Springer, 20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.CA stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper states asymptotic equivalents for the three first moments of the\nEescher transform of a distribution on R with smooth density in the upper tail.\nAs a by product if provides a tail approximation for its moment generating\nfunction, and shows that the Esscher transforms have a Gaussian behavior for\nlarge values of the parameter.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2013 17:52:12 GMT"}, {"version": "v2", "created": "Fri, 18 Oct 2013 16:58:40 GMT"}, {"version": "v3", "created": "Sun, 19 Jan 2014 18:19:15 GMT"}, {"version": "v4", "created": "Thu, 20 Mar 2014 12:42:25 GMT"}], "update_date": "2014-03-21", "authors_parsed": [["Biret", "Maeva", "", "LSTA"], ["Broniatowski", "Michel", "", "LSTA"], ["Cao", "Zhansheng", "", "LSTA"]]}, {"id": "1309.6287", "submitter": "Sebastien Gadat", "authors": "S\\'ebastien Gadat, Laurent Miclo, Fabien Panloup", "title": "A stochastic model for speculative bubbles", "comments": "53 Pages, 8 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST q-fin.GN stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper aims to provide a simple modelling of speculative bubbles and\nderive some quantitative properties of its dynamical evolution. Starting from a\ndescription of individual speculative behaviours, we build and study a second\norder Markov process, which after simple transformations can be viewed as a\nturning two-dimensional Gaussian process. Then, our main problem is to ob- tain\nsome bounds for the persistence rate relative to the return time to a given\nprice. In our main results, we prove with both spectral and probabilistic\nmethods that this rate is almost proportional to the turning frequency {\\omega}\nof the model and provide some explicit bounds. In the continuity of this\nresult, we build some estimators of {\\omega} and of the pseudo-period of the\nprices. At last, we end the paper by a proof of the quasi-stationary\ndistribution of the process, as well as the existence of its persistence rate.\n", "versions": [{"version": "v1", "created": "Sun, 22 Sep 2013 08:32:44 GMT"}], "update_date": "2013-09-25", "authors_parsed": [["Gadat", "S\u00e9bastien", ""], ["Miclo", "Laurent", ""], ["Panloup", "Fabien", ""]]}, {"id": "1309.6473", "submitter": "Pierre E. Jacob", "authors": "Pierre E. Jacob, Alexandre H. Thiery", "title": "On nonnegative unbiased estimators", "comments": "Published at http://dx.doi.org/10.1214/15-AOS1311 in the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2015, Vol. 43, No. 2, 769-784", "doi": "10.1214/15-AOS1311", "report-no": "IMS-AOS-AOS1311", "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the existence of algorithms generating almost surely nonnegative\nunbiased estimators. We show that given a nonconstant real-valued function $f$\nand a sequence of unbiased estimators of $\\lambda\\in\\mathbb{R}$, there is no\nalgorithm yielding almost surely nonnegative unbiased estimators of\n$f(\\lambda)\\in\\mathbb{R}^+$. The study is motivated by pseudo-marginal Monte\nCarlo algorithms that rely on such nonnegative unbiased estimators. These\nmethods allow \"exact inference\" in intractable models, in the sense that\nintegrals with respect to a target distribution can be estimated without any\nsystematic error, even though the associated probability density function\ncannot be evaluated pointwise. We discuss the consequences of our results on\nthe applicability of pseudo-marginal algorithms and thus on the possibility of\nexact inference in intractable models. We illustrate our study with particular\nchoices of functions $f$ corresponding to known challenges in statistics, such\nas exact simulation of diffusions, inference in large datasets and doubly\nintractable distributions.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2013 11:58:04 GMT"}, {"version": "v2", "created": "Mon, 12 May 2014 08:47:05 GMT"}, {"version": "v3", "created": "Wed, 14 Jan 2015 15:19:08 GMT"}, {"version": "v4", "created": "Wed, 1 Apr 2015 12:48:39 GMT"}], "update_date": "2015-04-02", "authors_parsed": [["Jacob", "Pierre E.", ""], ["Thiery", "Alexandre H.", ""]]}, {"id": "1309.6488", "submitter": "Eugene Seneta", "authors": "Eugene Seneta", "title": "A Tricentenary history of the Law of Large Numbers", "comments": "Published in at http://dx.doi.org/10.3150/12-BEJSP12 the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2013, Vol. 19, No. 4, 1088-1121", "doi": "10.3150/12-BEJSP12", "report-no": "IMS-BEJ-BEJSP12", "categories": "math.ST math.HO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Weak Law of Large Numbers is traced chronologically from its inception as\nJacob Bernoulli's Theorem in 1713, through De Moivre's Theorem, to ultimate\nforms due to Uspensky and Khinchin in the 1930s, and beyond. Both aspects of\nJacob Bernoulli's Theorem: 1. As limit theorem (sample size $n\\to\\infty$), and:\n2. Determining sufficiently large sample size for specified precision, for\nknown and also unknown p (the inversion problem), are studied, in frequentist\nand Bayesian settings. The Bienaym\\'{e}-Chebyshev Inequality is shown to be a\nmeeting point of the French and Russian directions in the history. Particular\nemphasis is given to less well-known aspects especially of the Russian\ndirection, with the work of Chebyshev, Markov (the organizer of Bicentennial\ncelebrations), and S.N. Bernstein as focal points.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2013 12:55:01 GMT"}], "update_date": "2013-09-26", "authors_parsed": [["Seneta", "Eugene", ""]]}, {"id": "1309.6536", "submitter": "Kaniadakis Giorgio", "authors": "G. Kaniadakis", "title": "Theoretical foundations and mathematical formalism of the power-law\n  tailed statistical distributions", "comments": "Review paper, 22 pages, 5 figures", "journal-ref": "Entropy, 15(10) 3983-4010 (2013)", "doi": "10.3390/e15103983", "report-no": null, "categories": "math.ST hep-th math-ph math.MP math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the main features of the mathematical theory generated by the\n\\kappa-deformed exponential function exp_{\\kappa}(x)=(\\sqrt{1+\\kappa^2\nx^2}+\\kappa x)^{1/\\kappa}, with 0<\\kappa<1, developed in the last twelve years,\nwhich turns out to be a continuous one parameter deformation of the ordinary\nmathematics generated by the Euler exponential function. The \\kappa-mathematics\nhas its roots in special relativity and furnishes the theoretical foundations\nof the \\kappa-statistical mechanics predicting power law tailed statistical\ndistributions which have been observed experimentally in many physical, natural\nand artificial systems. After introducing the \\kappa-algebra we present the\nassociated \\kappa-differential and \\kappa-integral calculus. Then we obtain the\ncorresponding \\kappa-exponential and \\kappa-logarithm functions and give the\n\\kappa-version of the main functions of the ordinary mathematics.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2013 14:55:27 GMT"}], "update_date": "2013-09-27", "authors_parsed": [["Kaniadakis", "G.", ""]]}, {"id": "1309.6602", "submitter": "Victor-Emmanuel Brunel", "authors": "Victor-Emmanuel Brunel (CREST)", "title": "Adaptive estimation of convex and polytopal support", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We estimate the support of a uniform density, when it is assumed to be a\nconvex polytope or, more generally, a convex body in $\\R^d$. In the polytopal\ncase, we construct an estimator achieving a rate which does not depend on the\ndimension $d$, unlike the other estimators that have been proposed so far. For\n$d\\geq 3$, our estimator has a better risk than the previous ones, and it is\nnearly minimax, up to a logarithmic factor. We also propose an estimator which\nis adaptive with respect to the structure of the boundary of the unknown\nsupport.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2013 18:36:41 GMT"}], "update_date": "2013-09-26", "authors_parsed": [["Brunel", "Victor-Emmanuel", "", "CREST"]]}, {"id": "1309.6699", "submitter": "Natesh Pillai", "authors": "Natesh S. Pillai, Aaron Smith", "title": "Finite Sample Properties of Adaptive Markov Chains via Curvature", "comments": "Revised version of the earlier manuscript. In this version we only\n  focus on the equi-energy sampler", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adaptive Markov chains are an important class of Monte Carlo methods for\nsampling from probability distributions. The time evolution of adaptive\nalgorithms depends on past samples, and thus these algorithms are\nnon-Markovian. Although there has been previous work establishing conditions\nfor their ergodicity, not much is known theoretically about their finite sample\nproperties. In this paper, using a notion of discrete Ricci curvature for\nMarkov kernels introduced by Ollivier, we establish concentration inequalities\nand finite sample bounds for a class of adaptive Markov chains. After\nestablishing some general results, we give quantitative bounds for\n`multi-level' adaptive algorithms such as the equi-energy sampler. We also\nprovide the first rigorous proofs that the finite sample properties of an\nequi-energy sampler are superior to those of related parallel tempering and\nMetropolis-Hastings samplers after a learning period comparable to their mixing\ntimes.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2013 01:14:02 GMT"}, {"version": "v2", "created": "Wed, 1 Oct 2014 02:10:20 GMT"}], "update_date": "2014-10-02", "authors_parsed": [["Pillai", "Natesh S.", ""], ["Smith", "Aaron", ""]]}, {"id": "1309.6766", "submitter": "David Aldous", "authors": "David Aldous", "title": "Interacting particle systems as stochastic social dynamics", "comments": "Published in at http://dx.doi.org/10.3150/12-BEJSP04 the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2013, Vol. 19, No. 4, 1122-1149", "doi": "10.3150/12-BEJSP04", "report-no": "IMS-BEJ-BEJSP04", "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The style of mathematical models known to probabilists as Interacting\nParticle Systems and exemplified by the Voter, Exclusion and Contact processes\nhave found use in many academic disciplines. In many such disciplines the\nunderlying conceptual picture is of a social network, where individuals meet\npairwise and update their \"state\" (opinion, activity etc) in a way depending on\nthe two previous states. This picture motivates a precise general setup we call\nFinite Markov Information Exchange (FMIE) processes. We briefly describe a few\nless familiar models (Averaging, Compulsive Gambler, Deference, Fashionista)\nsuggested by the social network picture, as well as a few familiar ones.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2013 09:12:30 GMT"}], "update_date": "2013-09-27", "authors_parsed": [["Aldous", "David", ""]]}, {"id": "1309.6790", "submitter": "Alexander W. Blocker", "authors": "Alexander W. Blocker, Xiao-Li Meng", "title": "The potential and perils of preprocessing: Building new foundations", "comments": "Published in at http://dx.doi.org/10.3150/13-BEJSP16 the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2013, Vol. 19, No. 4, 1176-1211", "doi": "10.3150/13-BEJSP16", "report-no": "IMS-BEJ-BEJSP16", "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Preprocessing forms an oft-neglected foundation for a wide range of\nstatistical and scientific analyses. However, it is rife with subtleties and\npitfalls. Decisions made in preprocessing constrain all later analyses and are\ntypically irreversible. Hence, data analysis becomes a collaborative endeavor\nby all parties involved in data collection, preprocessing and curation, and\ndownstream inference. Even if each party has done its best given the\ninformation and resources available to them, the final result may still fall\nshort of the best possible in the traditional single-phase inference framework.\nThis is particularly relevant as we enter the era of \"big data\". The\ntechnologies driving this data explosion are subject to complex new forms of\nmeasurement error. Simultaneously, we are accumulating increasingly massive\ndatabases of scientific analyses. As a result, preprocessing has become more\nvital (and potentially more dangerous) than ever before.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2013 10:50:23 GMT"}], "update_date": "2013-09-27", "authors_parsed": [["Blocker", "Alexander W.", ""], ["Meng", "Xiao-Li", ""]]}, {"id": "1309.6933", "submitter": "Larry Wasserman", "authors": "Larry Wasserman, Mladen Kolar and Alessandro Rinaldo", "title": "Estimating Undirected Graphs Under Weak Assumptions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of providing nonparametric confidence guarantees for\nundirected graphs under weak assumptions. In particular, we do not assume\nsparsity, incoherence or Normality. We allow the dimension $D$ to increase with\nthe sample size $n$. First, we prove lower bounds that show that if we want\naccurate inferences with low assumptions then there are limitations on the\ndimension as a function of sample size. When the dimension increases slowly\nwith sample size, we show that methods based on Normal approximations and on\nthe bootstrap lead to valid inferences and we provide Berry-Esseen bounds on\nthe accuracy of the Normal approximation. When the dimension is large relative\nto sample size, accurate inferences for graphs under low assumptions are not\npossible. Instead we propose to estimate something less demanding than the\nentire partial correlation graph. In particular, we consider: cluster graphs,\nrestricted partial correlation graphs and correlation graphs.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2013 15:18:22 GMT"}], "update_date": "2013-09-27", "authors_parsed": [["Wasserman", "Larry", ""], ["Kolar", "Mladen", ""], ["Rinaldo", "Alessandro", ""]]}, {"id": "1309.7376", "submitter": "Hau-tieng Wu", "authors": "Jin-Ting Zhang, Ming-Yen Cheng, Chi-Jen Tseng, Hau-Tieng Wu", "title": "A New Test for One-Way ANOVA with Functional Data and Application to\n  Ischemic Heart Screening", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.AP stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose and study a new global test, namely the $F_{\\max}$-test, for the\none-way ANOVA problem in functional data analysis. The test statistic is taken\nas the maximum value of the usual pointwise $F$-test statistics over the\ninterval the functional responses are observed. A nonparametric bootstrap\nmethod is employed to approximate the null distribution of the test statistic\nand to obtain an estimated critical value for the test. The asymptotic random\nexpression of the test statistic is derived and the asymptotic power is\nstudied. In particular, under mild conditions, the $F_{\\max}$-test\nasymptotically has the correct level and is root-$n$ consistent in detecting\nlocal alternatives. Via some simulation studies, it is found that in terms of\nboth level accuracy and power, the $F_{\\max}$-test outperforms the Globalized\nPointwise F (GPF) test of \\cite{Zhang_Liang:2013} when the functional data are\nhighly or moderately correlated, and its performance is comparable with the\nlatter otherwise. An application to an ischemic heart real dataset suggests\nthat, after proper manipulation, resting electrocardiogram (ECG) signals can be\nused as an effective tool in clinical ischemic heart screening, without the\nneed of further stress tests as in the current standard procedure.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2013 21:55:10 GMT"}], "update_date": "2013-10-01", "authors_parsed": [["Zhang", "Jin-Ting", ""], ["Cheng", "Ming-Yen", ""], ["Tseng", "Chi-Jen", ""], ["Wu", "Hau-Tieng", ""]]}, {"id": "1309.7503", "submitter": "Abhik Ghosh", "authors": "Abhik Ghosh, Aritra Chakravorty", "title": "Estimating Copula and Test of Independence based on a generalized\n  framework of all rank-based Statistics in Bivariate Sample", "comments": "Project as a part of Multivariate Statistics Course in M. Stat. 1st\n  year in Indian Statistical Institute, Kolkata", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Copulas are mathematical objects that fully capture the dependence structure\namong random variables and hence, offer a great flexibility in building\nmultivariate stochastic models. In statistics, a copula is used as a general\nway of formulating a multivariate distribution in such a way that various\ngeneral types of dependence can be represented. In case of bivariate sample,\nthe notion of estimating copula is closely related to that of testing\nindependence in a bivariate sample, as when the components of the bivariate\nsample are independent the copula becomes simply product of two uniform\ndistributions. So apart from non-parametric estimation of copulas we also\nconsidered it relevant to introduce some non-parametric tests to better\nunderstand the very essence of copula in the explanation of association between\nthe components. In fact we will develop a general multivariate statistics that\ngives rise to a much larger class of non-parametric rank based statistics. This\nclass of statistics can be used in estimation and testing for the association\npresent in the bivariate sample. We choose some representative statistics from\nthat class and compared their power in testing independence using simulation as\nan attempt to choose the best candidate in that class.\n", "versions": [{"version": "v1", "created": "Sat, 28 Sep 2013 21:03:59 GMT"}], "update_date": "2013-10-01", "authors_parsed": [["Ghosh", "Abhik", ""], ["Chakravorty", "Aritra", ""]]}, {"id": "1309.7622", "submitter": "Fabio Rapallo", "authors": "Enrico Carlini, Fabio Rapallo", "title": "Toric ideals with linear components: an algebraic interpretation of\n  clustering the cells of a contingency table", "comments": "17 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.AC stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we show that the agglomeration of rows or columns of a\ncontingency table with a hierarchical clustering algorithm yields statistical\nmodels defined through toric ideals. In particular, starting from the classical\nindependence model, the agglomeration process adds a linear part to the toric\nideal generated by the $2 \\times 2$ minors.\n", "versions": [{"version": "v1", "created": "Sun, 29 Sep 2013 16:40:09 GMT"}], "update_date": "2013-10-01", "authors_parsed": [["Carlini", "Enrico", ""], ["Rapallo", "Fabio", ""]]}, {"id": "1309.7752", "submitter": "Geoffrey Decrouez", "authors": "Geoffrey Decrouez, Peter Hall", "title": "Normal approximation and smoothness for sums of means of lattice-valued\n  random variables", "comments": "Published in at http://dx.doi.org/10.3150/12-BEJSP02 the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2013, Vol. 19, No. 4, 1268-1293", "doi": "10.3150/12-BEJSP02", "report-no": "IMS-BEJ-BEJSP02", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by a problem arising when analysing data from quarantine searches,\nwe explore properties of distributions of sums of independent means of\nindependent lattice-valued random variables. The aim is to determine the extent\nto which approximations to those sums require continuity corrections. We show\nthat, in cases where there are only two different means, the main effects of\ndistribution smoothness can be understood in terms of the ratio\n$\\rho_{12}=(e_2n_1)/(e_1n_2)$, where $e_1$ and $e_2$ are the respective maximal\nlattice edge widths of the two populations, and $n_1$ and $n_2$ are the\nrespective sample sizes used to compute the means. If $\\rho_{12}$ converges to\nan irrational number, or converges sufficiently slowly to a rational number;\nand in a number of other cases too, for example those where $\\rho_{12}$ does\nnot converge; the effects of the discontinuity of lattice distributions are of\nsmaller order than the effects of skewness. However, in other instances, for\nexample where $\\rho_{12}$ converges relatively quickly to a rational number,\nthe effects of discontinuity and skewness are of the same size. We also treat\nhigher-order properties, arguing that cases where $\\rho_{12}$ converges to an\nalgebraic irrational number can be less prone to suffer the effects of\ndiscontinuity than cases where the limiting irrational is transcendental. These\nresults are extended to the case of three or more different means, and also to\nproblems where distributions are estimated using the bootstrap. The results\nhave practical interpretation in terms of the accuracy of inference for, among\nother quantities, the sum or difference of binomial proportions.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2013 08:32:54 GMT"}], "update_date": "2013-10-01", "authors_parsed": [["Decrouez", "Geoffrey", ""], ["Hall", "Peter", ""]]}, {"id": "1309.7754", "submitter": "Persi Diaconis", "authors": "Persi Diaconis", "title": "Some things we've learned (about Markov chain Monte Carlo)", "comments": "Published in at http://dx.doi.org/10.3150/12-BEJSP09 the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2013, Vol. 19, No. 4, 1294-1305", "doi": "10.3150/12-BEJSP09", "report-no": "IMS-BEJ-BEJSP09", "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper offers a personal review of some things we've learned about rates\nof convergence of Markov chains to their stationary distributions. The main\ntopic is ways of speeding up diffusive behavior. It also points to open\nproblems and how much more there is to do.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2013 08:44:46 GMT"}], "update_date": "2013-10-01", "authors_parsed": [["Diaconis", "Persi", ""]]}, {"id": "1309.7759", "submitter": "Hans F\\\"{o}llmer", "authors": "Hans F\\\"ollmer, Alexander Schied", "title": "Probabilistic aspects of finance", "comments": "Published in at http://dx.doi.org/10.3150/12-BEJSP05 the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2013, Vol. 19, No. 4, 1306-1326", "doi": "10.3150/12-BEJSP05", "report-no": "IMS-BEJ-BEJSP05", "categories": "q-fin.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the past decades, advanced probabilistic methods have had significant\nimpact on the field of finance, both in academia and in the financial industry.\nConversely, financial questions have stimulated new research directions in\nprobability. In this survey paper, we review some of these developments and\npoint to some areas that might deserve further investigation. We start by\nreviewing the basics of arbitrage pricing theory, with special emphasis on\nincomplete markets and on the different roles played by the \"real-world\"\nprobability measure and its equivalent martingale measures. We then focus on\nthe issue of model ambiguity, also called Knightian uncertainty. We present two\ncase studies in which it is possible to deal with Knightian uncertainty in\nmathematical terms. The first case study concerns the hedging of derivatives,\nsuch as variance swaps, in a strictly pathwise sense. The second one deals with\ncapital requirements and preferences specified by convex and coherent risk\nmeasures. In the final two sections we discuss mathematical issues arising from\nthe dramatic increase of algorithmic trading in modern financial markets.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2013 08:56:48 GMT"}], "update_date": "2013-10-01", "authors_parsed": [["F\u00f6llmer", "Hans", ""], ["Schied", "Alexander", ""]]}, {"id": "1309.7801", "submitter": "Francis Hirsch", "authors": "Francis Hirsch, Marc Yor", "title": "On the Mellin transforms of the perpetuity and the remainder variables\n  associated to a subordinator", "comments": "Published in at http://dx.doi.org/10.3150/12-BEJSP01 the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2013, Vol. 19, No. 4, 1350-1377", "doi": "10.3150/12-BEJSP01", "report-no": "IMS-BEJ-BEJSP01", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Results about the laws of the perpetuity and remainder variables associated\nto a subordinator are presented, with particular emphasis on their Mellin\ntransforms, and multiplicative infinite divisibility property. Previous results\nby Bertoin-Yor (Electron. Commun. Probab. 6 (2001) 95-106) are incorporated in\nour discussion; important examples when the subordinator is the inverse local\ntime of a diffusion are exhibited. Results of Urbanik (Probab. Math. Statist.\n15 (1995) 493-513) are also discussed in detail; they appear to be too little\nknown, despite the fact that quite a few of them have priority upon other works\nin this area.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2013 11:36:08 GMT"}], "update_date": "2013-10-01", "authors_parsed": [["Hirsch", "Francis", ""], ["Yor", "Marc", ""]]}, {"id": "1309.7804", "submitter": "Michael I. Jordan", "authors": "Michael I. Jordan", "title": "On statistics, computation and scalability", "comments": "Published in at http://dx.doi.org/10.3150/12-BEJSP17 the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2013, Vol. 19, No. 4, 1378-1390", "doi": "10.3150/12-BEJSP17", "report-no": "IMS-BEJ-BEJSP17", "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How should statistical procedures be designed so as to be scalable\ncomputationally to the massive datasets that are increasingly the norm? When\ncoupled with the requirement that an answer to an inferential question be\ndelivered within a certain time budget, this question has significant\nrepercussions for the field of statistics. With the goal of identifying\n\"time-data tradeoffs,\" we investigate some of the statistical consequences of\ncomputational perspectives on scability, in particular divide-and-conquer\nmethodology and hierarchies of convex relaxations.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2013 11:51:23 GMT"}], "update_date": "2013-10-01", "authors_parsed": [["Jordan", "Michael I.", ""]]}, {"id": "1309.7807", "submitter": "Hans R. K\\\"{u}nsch", "authors": "Hans R. K\\\"unsch", "title": "Particle filters", "comments": "Published in at http://dx.doi.org/10.3150/12-BEJSP07 the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2013, Vol. 19, No. 4, 1391-1403", "doi": "10.3150/12-BEJSP07", "report-no": "IMS-BEJ-BEJSP07", "categories": "math.ST stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is a short review of Monte Carlo methods for approximating filter\ndistributions in state space models. The basic algorithm and different\nstrategies to reduce imbalance of the weights are discussed. Finally, methods\nfor more difficult problems like smoothing and parameter estimation and\napplications outside the state space model context are presented.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2013 12:06:02 GMT"}], "update_date": "2013-10-01", "authors_parsed": [["K\u00fcnsch", "Hans R.", ""]]}, {"id": "1309.7816", "submitter": "Nancy Reid", "authors": "Nancy Reid", "title": "Aspects of likelihood inference", "comments": "Published in at http://dx.doi.org/10.3150/12-BEJSP03 the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2013, Vol. 19, No. 4, 1404-1418", "doi": "10.3150/12-BEJSP03", "report-no": "IMS-BEJ-BEJSP03", "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  I review the classical theory of likelihood based inference and consider how\nit is being extended and developed for use in complex models and sampling\nschemes.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2013 12:15:54 GMT"}], "update_date": "2013-10-01", "authors_parsed": [["Reid", "Nancy", ""]]}, {"id": "1309.7824", "submitter": "Patrick Loiseau", "authors": "Nicolas Gast, Stratis Ioannidis, Patrick Loiseau, and Benjamin\n  Roussillon", "title": "Linear Regression from Strategic Data Sources", "comments": "This version (v3) extends the results on the sub-optimality of GLS\n  (Section 6) and improves writing in multiple places compared to v2. Compared\n  to the initial version v1, it also fixes an error in Theorem 6 (now Theorem\n  5), and extended many of the results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linear regression is a fundamental building block of statistical data\nanalysis. It amounts to estimating the parameters of a linear model that maps\ninput features to corresponding outputs. In the classical setting where the\nprecision of each data point is fixed, the famous Aitken/Gauss-Markov theorem\nin statistics states that generalized least squares (GLS) is a so-called \"Best\nLinear Unbiased Estimator\" (BLUE). In modern data science, however, one often\nfaces strategic data sources, namely, individuals who incur a cost for\nproviding high-precision data.\n  In this paper, we study a setting in which features are public but\nindividuals choose the precision of the outputs they reveal to an analyst. We\nassume that the analyst performs linear regression on this dataset, and\nindividuals benefit from the outcome of this estimation. We model this scenario\nas a game where individuals minimize a cost comprising two components: (a) an\n(agent-specific) disclosure cost for providing high-precision data; and (b) a\n(global) estimation cost representing the inaccuracy in the linear model\nestimate. In this game, the linear model estimate is a public good that\nbenefits all individuals. We establish that this game has a unique non-trivial\nNash equilibrium. We study the efficiency of this equilibrium and we prove\ntight bounds on the price of stability for a large class of disclosure and\nestimation costs. Finally, we study the estimator accuracy achieved at\nequilibrium. We show that, in general, Aitken's theorem does not hold under\nstrategic data sources, though it does hold if individuals have identical\ndisclosure costs (up to a multiplicative factor). When individuals have\nnon-identical costs, we derive a bound on the improvement of the equilibrium\nestimation cost that can be achieved by deviating from GLS, under mild\nassumptions on the disclosure cost functions.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2013 12:48:35 GMT"}, {"version": "v2", "created": "Thu, 4 Jul 2019 14:29:00 GMT"}, {"version": "v3", "created": "Thu, 12 Dec 2019 23:47:00 GMT"}], "update_date": "2019-12-16", "authors_parsed": [["Gast", "Nicolas", ""], ["Ioannidis", "Stratis", ""], ["Loiseau", "Patrick", ""], ["Roussillon", "Benjamin", ""]]}, {"id": "1309.7837", "submitter": "Jonathan Taylor", "authors": "Jonathan Taylor", "title": "The geometry of least squares in the 21st century", "comments": "Published in at http://dx.doi.org/10.3150/12-BEJSP15 the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2013, Vol. 19, No. 4, 1449-1464", "doi": "10.3150/12-BEJSP15", "report-no": "IMS-BEJ-BEJSP15", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been over 200 years since Gauss's and Legendre's famous priority\ndispute on who discovered the method of least squares. Nevertheless, we argue\nthat the normal equations are still relevant in many facets of modern\nstatistics, particularly in the domain of high-dimensional inference. Even\ntoday, we are still learning new things about the law of large numbers, first\ndescribed in Bernoulli's Ars Conjectandi 300 years ago, as it applies to high\ndimensional inference. The other insight the normal equations provide is the\nasymptotic Gaussianity of the least squares estimators. The general form of the\nGaussian distribution, Gaussian processes, are another tool used in modern\nhigh-dimensional inference. The Gaussian distribution also arises via the\ncentral limit theorem in describing weak convergence of the usual least squares\nestimators. In terms of high-dimensional inference, we are still missing the\nright notion of weak convergence. In this mostly expository work, we try to\ndescribe how both the normal equations and the theory of Gaussian processes,\nwhat we refer to as the \"geometry of least squares,\" apply to many questions of\ncurrent interest.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2013 13:23:50 GMT"}], "update_date": "2013-10-01", "authors_parsed": [["Taylor", "Jonathan", ""]]}]