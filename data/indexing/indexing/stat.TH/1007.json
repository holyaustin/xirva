[{"id": "1007.0089", "submitter": "Nayantara Bhatnagar", "authors": "Nayantara Bhatnagar, Andrej Bogdanov and Elchanan Mossel", "title": "The Computational Complexity of Estimating Convergence Time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.ST stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important problem in the implementation of Markov Chain Monte Carlo\nalgorithms is to determine the convergence time, or the number of iterations\nbefore the chain is close to stationarity. For many Markov chains used in\npractice this time is not known. Even in cases where the convergence time is\nknown to be polynomial, the theoretical bounds are often too crude to be\npractical. Thus, practitioners like to carry out some form of statistical\nanalysis in order to assess convergence. This has led to the development of a\nnumber of methods known as convergence diagnostics which attempt to diagnose\nwhether the Markov chain is far from stationarity. We study the problem of\ntesting convergence in the following settings and prove that the problem is\nhard in a computational sense: Given a Markov chain that mixes rapidly, it is\nhard for Statistical Zero Knowledge (SZK-hard) to distinguish whether starting\nfrom a given state, the chain is close to stationarity by time t or far from\nstationarity at time ct for a constant c. We show the problem is in AM\nintersect coAM. Second, given a Markov chain that mixes rapidly it is coNP-hard\nto distinguish whether it is close to stationarity by time t or far from\nstationarity at time ct for a constant c. The problem is in coAM. Finally, it\nis PSPACE-complete to distinguish whether the Markov chain is close to\nstationarity by time t or far from being mixed at time ct for c at least 1.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2010 07:34:58 GMT"}], "update_date": "2010-07-02", "authors_parsed": [["Bhatnagar", "Nayantara", ""], ["Bogdanov", "Andrej", ""], ["Mossel", "Elchanan", ""]]}, {"id": "1007.0097", "submitter": "Peter Harremo\\\"es", "authors": "Peter Harremo\\\"es and Igor Vajda", "title": "On Pairs of $f$-divergences and their Joint Range", "comments": "7 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We compare two f-divergences and prove that their joint range is the convex\nhull of the joint range for distributions supported on only two points. Some\napplications of this result are given.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2010 08:02:40 GMT"}], "update_date": "2010-07-02", "authors_parsed": [["Harremo\u00ebs", "Peter", ""], ["Vajda", "Igor", ""]]}, {"id": "1007.0179", "submitter": "P. J. Bickel", "authors": "P. J. Bickel, B. J. K. Kleijn", "title": "The semiparametric Bernstein-von Mises theorem", "comments": "Published in at http://dx.doi.org/10.1214/11-AOS921 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2012, Vol. 40, No. 1, 206-237", "doi": "10.1214/11-AOS921", "report-no": "IMS-AOS-AOS921", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a smooth semiparametric estimation problem, the marginal posterior for the\nparameter of interest is expected to be asymptotically normal and satisfy\nfrequentist criteria of optimality if the model is endowed with a suitable\nprior. It is shown that, under certain straightforward and interpretable\nconditions, the assertion of Le Cam's acclaimed, but strictly parametric,\nBernstein-von Mises theorem [Univ. California Publ. Statist. 1 (1953) 277-329]\nholds in the semiparametric situation as well. As a consequence, Bayesian\npoint-estimators achieve efficiency, for example, in the sense of H\\'{a}jek's\nconvolution theorem [Z. Wahrsch. Verw. Gebiete 14 (1970) 323-330]. The model is\nrequired to satisfy differentiability and metric entropy conditions, while the\nnuisance prior must assign nonzero mass to certain Kullback-Leibler\nneighborhoods [Ghosal, Ghosh and van der Vaart Ann. Statist. 28 (2000)\n500-531]. In addition, the marginal posterior is required to converge at\nparametric rate, which appears to be the most stringent condition in examples.\nThe results are applied to estimation of the linear coefficient in partial\nlinear regression, with a Gaussian prior on a smoothness class for the\nnuisance.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2010 14:25:39 GMT"}, {"version": "v2", "created": "Thu, 14 Oct 2010 15:15:30 GMT"}, {"version": "v3", "created": "Tue, 29 May 2012 08:41:12 GMT"}], "update_date": "2012-05-30", "authors_parsed": [["Bickel", "P. J.", ""], ["Kleijn", "B. J. K.", ""]]}, {"id": "1007.0296", "submitter": "Marcus Hutter", "authors": "Wray Buntine and Marcus Hutter", "title": "A Bayesian View of the Poisson-Dirichlet Process", "comments": "50 LaTeX pages, 10 figures, 3 tables, 1 algorithm", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The two parameter Poisson-Dirichlet Process (PDP), a generalisation of the\nDirichlet Process, is increasingly being used for probabilistic modelling in\ndiscrete areas such as language technology, bioinformatics, and image analysis.\nThere is a rich literature about the PDP and its derivative distributions such\nas the Chinese Restaurant Process (CRP). This article reviews some of the basic\ntheory and then the major results needed for Bayesian modelling of discrete\nproblems including details of priors, posteriors and computation.\n  The PDP allows one to build distributions over countable partitions. The PDP\nhas two other remarkable properties: first it is partially conjugate to itself,\nwhich allows one to build hierarchies of PDPs, and second using a marginalised\nrelative the CRP, one gets fragmentation and clustering properties that lets\none layer partitions to build trees. This article presents the basic theory for\nunderstanding the notion of partitions and distributions over them, the PDP and\nthe CRP, and the important properties of conjugacy, fragmentation and\nclustering, as well as some key related properties such as consistency and\nconvergence. This article also presents a Bayesian interpretation of the\nPoisson-Dirichlet process based on an improper and infinite dimensional\nDirichlet distribution. This means we can understand the process as just\nanother Dirichlet and thus all its sampling properties emerge naturally.\n  The theory of PDPs is usually presented for continuous distributions (more\ngenerally referred to as non-atomic distributions), however, when applied to\ndiscrete distributions its remarkable conjugacy property emerges. This context\nand basic results are also presented, as well as techniques for computing the\nsecond order Stirling numbers that occur in the posteriors for discrete\ndistributions.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2010 05:10:49 GMT"}, {"version": "v2", "created": "Wed, 15 Feb 2012 21:56:08 GMT"}], "update_date": "2012-02-17", "authors_parsed": [["Buntine", "Wray", ""], ["Hutter", "Marcus", ""]]}, {"id": "1007.0434", "submitter": "Madalin Guta", "authors": "Madalin Guta", "title": "Fisher information and asymptotic normality in system identification for\n  quantum Markov chains", "comments": "10 pages, 2 figures. final version", "journal-ref": "Phys. Rev. A, 83, 062324, (2011)", "doi": "10.1103/PhysRevA.83.062324", "report-no": null, "categories": "quant-ph math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with the problem of estimating the coupling constant\n$\\theta$ of a mixing quantum Markov chain. For a repeated measurement on the\nchain's output we show that the outcomes' time average has an asymptotically\nnormal (Gaussian) distribution, and we give the explicit expressions of its\nmean and variance. In particular we obtain a simple estimator of $\\theta$ whose\nclassical Fisher information can be optimized over different choices of\nmeasured observables. We then show that the quantum state of the output\ntogether with the system, is itself asymptotically Gaussian and compute its\nquantum Fisher information which sets an absolute bound to the estimation\nerror. The classical and quantum Fisher informations are compared in a simple\nexample. In the vicinity of $\\theta=0$ we find that the quantum Fisher\ninformation has a quadratic rather than linear scaling in output size, and\nasymptotically the Fisher information is localised in the system, while the\noutput is independent of the parameter.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2010 19:38:52 GMT"}, {"version": "v2", "created": "Wed, 7 Jul 2010 07:46:46 GMT"}, {"version": "v3", "created": "Sun, 20 Feb 2011 21:54:17 GMT"}, {"version": "v4", "created": "Wed, 22 Jun 2011 18:14:26 GMT"}], "update_date": "2011-06-23", "authors_parsed": [["Guta", "Madalin", ""]]}, {"id": "1007.0549", "submitter": "Larry Wasserman", "authors": "Christopher Genovese, Marco Perone-Pacifico, Isabella Verdinelli and\n  Larry Wasserman", "title": "Minimax Manifold Estimation", "comments": "journal submission, revision with some errors corrected", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We find the minimax rate of convergence in Hausdorff distance for estimating\na manifold M of dimension d embedded in R^D given a noisy sample from the\nmanifold. We assume that the manifold satisfies a smoothness condition and that\nthe noise distribution has compact support. We show that the optimal rate of\nconvergence is n^{-2/(2+d)}. Thus, the minimax rate depends only on the\ndimension of the manifold, not on the dimension of the space in which M is\nembedded.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jul 2010 13:11:40 GMT"}, {"version": "v2", "created": "Tue, 23 Nov 2010 17:21:02 GMT"}, {"version": "v3", "created": "Wed, 28 Sep 2011 18:14:13 GMT"}], "update_date": "2011-09-29", "authors_parsed": [["Genovese", "Christopher", ""], ["Perone-Pacifico", "Marco", ""], ["Verdinelli", "Isabella", ""], ["Wasserman", "Larry", ""]]}, {"id": "1007.0828", "submitter": "Anne Philippe", "authors": "Pierre-Olivier Amblard (GIPSA-lab), Jean-Fran\\c{c}ois Coeurjolly\n  (GIPSA-lab, LJK), Fr\\'ed\\'eric Lavancier (LMJL), Anne Philippe (LMJL)", "title": "Basic properties of the Multivariate Fractional Brownian Motion", "comments": "D\\'epartement Images et Signal", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper reviews and extends some recent results on the multivariate\nfractional Brownian motion (mfBm) and its increment process. A characterization\nof the mfBm through its covariance function is obtained. Similarly, the\ncorrelation and spectral analyses of the increments are investigated. On the\nother hand we show that (almost) all mfBm's may be reached as the limit of\npartial sums of (super)linear processes. Finally, an algorithm to perfectly\nsimulate the mfBm is presented and illustrated by some simulations.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2010 07:59:37 GMT"}, {"version": "v2", "created": "Wed, 25 Apr 2012 14:27:55 GMT"}], "update_date": "2012-04-27", "authors_parsed": [["Amblard", "Pierre-Olivier", "", "GIPSA-lab"], ["Coeurjolly", "Jean-Fran\u00e7ois", "", "GIPSA-lab, LJK"], ["Lavancier", "Fr\u00e9d\u00e9ric", "", "LMJL"], ["Philippe", "Anne", "", "LMJL"]]}, {"id": "1007.0842", "submitter": "Josef Dick", "authors": "Josef Dick", "title": "Higher order scrambled digital nets achieve the optimal rate of the root\n  mean square error for smooth integrands", "comments": "Published in at http://dx.doi.org/10.1214/11-AOS880 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2011, Vol. 39, No. 3, 1372-1398", "doi": "10.1214/11-AOS880", "report-no": "IMS-AOS-AOS880", "categories": "math.NA math.ST stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a random sampling technique to approximate integrals\n$\\int_{[0,1]^s}f(\\mathbf{x})\\,\\mathrm{d}\\mathbf{x}$ by averaging the function\nat some sampling points. We focus on cases where the integrand is smooth, which\nis a problem which occurs in statistics. The convergence rate of the\napproximation error depends on the smoothness of the function $f$ and the\nsampling technique. For instance, Monte Carlo (MC) sampling yields a\nconvergence of the root mean square error (RMSE) of order $N^{-1/2}$ (where $N$\nis the number of samples) for functions $f$ with finite variance. Randomized\nQMC (RQMC), a combination of MC and quasi-Monte Carlo (QMC), achieves a RMSE of\norder $N^{-3/2+\\varepsilon}$ under the stronger assumption that the integrand\nhas bounded variation. A combination of RQMC with local antithetic sampling\nachieves a convergence of the RMSE of order $N^{-3/2-1/s+\\varepsilon}$ (where\n$s\\ge1$ is the dimension) for functions with mixed partial derivatives up to\norder two. Additional smoothness of the integrand does not improve the rate of\nconvergence of these algorithms in general. On the other hand, it is known that\nwithout additional smoothness of the integrand it is not possible to improve\nthe convergence rate. This paper introduces a new RQMC algorithm, for which we\nprove that it achieves a convergence of the root mean square error (RMSE) of\norder $N^{-\\alpha-1/2+\\varepsilon}$ provided the integrand satisfies the strong\nassumption that it has square integrable partial mixed derivatives up to order\n$\\alpha>1$ in each variable. Known lower bounds on the RMSE show that this rate\nof convergence cannot be improved in general for integrands with this\nsmoothness. We provide numerical examples for which the RMSE converges\napproximately with order $N^{-5/2}$ and $N^{-7/2}$, in accordance with the\ntheoretical upper bound.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2010 09:30:11 GMT"}, {"version": "v2", "created": "Wed, 7 Jul 2010 05:04:24 GMT"}, {"version": "v3", "created": "Thu, 8 Jul 2010 00:14:31 GMT"}, {"version": "v4", "created": "Tue, 20 Nov 2012 09:12:28 GMT"}], "update_date": "2012-11-21", "authors_parsed": [["Dick", "Josef", ""]]}, {"id": "1007.0921", "submitter": "Mohamed El Machkouri", "authors": "Mohamed EL Machkouri", "title": "Berry-Esseen's central limit theorem for non-causal linear processes in\n  Hilbert space", "comments": null, "journal-ref": "African Diaspora Journal of Mathematics, 10, 2, p. 81-86, 2010", "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $H$ be a real separable Hilbert space and $(a_k)_{k\\in\\mathbb{Z}}$ a\nsequence of bounded linear operators from $H$ to $H$. We consider the linear\nprocess $X$ defined for any $k$ in $\\mathbb{Z}$ by\n$X_k=\\sum_{j\\in\\mathbb{Z}}a_j(\\varepsilon_{k-j})$ where\n$(\\varepsilon_k)_{k\\in\\mathbb{Z}}$ is a sequence of i.i.d. centered $H$-valued\nrandom variables. We investigate the rate of convergence in the CLT for $X$ and\nin particular we obtain the usual Berry-Esseen's bound provided that\n$\\sum_{j\\in\\mathbb{Z}}\\vert j\\vert\\|a_j\\|_{\\mathcal{L}(H)}<+\\infty$ and\n$\\varepsilon_0$ belongs to $L_H^{\\infty}$.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2010 15:18:42 GMT"}], "update_date": "2010-07-07", "authors_parsed": [["Machkouri", "Mohamed EL", ""]]}, {"id": "1007.0959", "submitter": "Omer Tamuz", "authors": "Elchanan Mossel and Omer Tamuz", "title": "Making Consensus Tractable", "comments": "18 pages. To appear in Transactions on Economics and Computation", "journal-ref": "ACM Transactions on Economics and Computation, Volume 1 Issue 4,\n  December 2013", "doi": "10.1145/2542174.2542176", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a model of consensus decision making, in which a finite group of\nBayesian agents has to choose between one of two courses of action. Each member\nof the group has a private and independent signal at his or her disposal,\ngiving some indication as to which action is optimal. To come to a common\ndecision, the participants perform repeated rounds of voting. In each round,\neach agent casts a vote in favor of one of the two courses of action,\nreflecting his or her current belief, and observes the votes of the rest.\n  We provide an efficient algorithm for the calculation the agents have to\nperform, and show that consensus is always reached and that the probability of\nreaching a wrong decision decays exponentially with the number of agents.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jul 2010 11:59:39 GMT"}, {"version": "v2", "created": "Wed, 2 Nov 2011 13:11:37 GMT"}, {"version": "v3", "created": "Mon, 7 Oct 2013 12:26:47 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Mossel", "Elchanan", ""], ["Tamuz", "Omer", ""]]}, {"id": "1007.1298", "submitter": "Etienne Roquain", "authors": "Sylvain Delattre (PMA), Etienne Roquain (LPMA)", "title": "On the false discovery proportion convergence under Gaussian\n  equi-correlation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the convergence of the false discovery proportion (FDP) of the\nBenjamini-Hochberg procedure in the Gaussian equi-correlated model, when the\ncorrelation $\\rho_m$ converges to zero as the hypothesis number $m$ grows to\ninfinity. By contrast with the standard convergence rate $m^{1/2}$ holding\nunder independence, this study shows that the FDP converges to the false\ndiscovery rate (FDR) at rate $\\{\\min(m,1/\\rho_m)\\}^{1/2}$ in this\nequi-correlated model.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2010 07:00:59 GMT"}], "update_date": "2010-07-26", "authors_parsed": [["Delattre", "Sylvain", "", "PMA"], ["Roquain", "Etienne", "", "LPMA"]]}, {"id": "1007.1414", "submitter": "Peter Tankov", "authors": "Mathieu Rosenbaum, Peter Tankov", "title": "Asymptotic results and statistical procedures for time-changed L\\'evy\n  processes sampled at hitting times", "comments": "minor revision", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide asymptotic results and develop high frequency statistical\nprocedures for time-changed L\\'evy processes sampled at random instants. The\nsampling times are given by first hitting times of symmetric barriers whose\ndistance with respect to the starting point is equal to $\\varepsilon$. This\nsetting can be seen as a first step towards a model for tick-by-tick financial\ndata allowing for large jumps. For a wide class of L\\'evy processes, we\nintroduce a renormalization depending on $\\varepsilon$, under which the L\\'evy\nprocess converges in law to an $\\alpha$-stable process as $\\varepsilon$ goes to\n$0$. The convergence is extended to moments of hitting times and overshoots. In\nparticular, these results allow us to construct consistent estimators of the\ntime change and of the Blumenthal-Getoor index of the underlying L\\'evy\nprocess. Convergence rates and a central limit theorem are established under\nadditional assumptions.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2010 16:42:55 GMT"}, {"version": "v2", "created": "Mon, 19 Jul 2010 08:59:28 GMT"}], "update_date": "2010-07-20", "authors_parsed": [["Rosenbaum", "Mathieu", ""], ["Tankov", "Peter", ""]]}, {"id": "1007.1434", "submitter": "Ery Arias-Castro", "authors": "Ery Arias-Castro, Emmanuel J. Cand\\`es, Yaniv Plan", "title": "Global testing under sparse alternatives: ANOVA, multiple comparisons\n  and the higher criticism", "comments": "Published in at http://dx.doi.org/10.1214/11-AOS910 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2011, Vol. 39, No. 5, 2533-2556", "doi": "10.1214/11-AOS910", "report-no": "IMS-AOS-AOS910", "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Testing for the significance of a subset of regression coefficients in a\nlinear model, a staple of statistical analysis, goes back at least to the work\nof Fisher who introduced the analysis of variance (ANOVA). We study this\nproblem under the assumption that the coefficient vector is sparse, a common\nsituation in modern high-dimensional settings. Suppose we have $p$ covariates\nand that under the alternative, the response only depends upon the order of\n$p^{1-\\alpha}$ of those, $0\\le\\alpha\\le1$. Under moderate sparsity levels, that\nis, $0\\le\\alpha\\le1/2$, we show that ANOVA is essentially optimal under some\nconditions on the design. This is no longer the case under strong sparsity\nconstraints, that is, $\\alpha>1/2$. In such settings, a multiple comparison\nprocedure is often preferred and we establish its optimality when\n$\\alpha\\geq3/4$. However, these two very popular methods are suboptimal, and\nsometimes powerless, under moderately strong sparsity where $1/2<\\alpha<3/4$.\nWe suggest a method based on the higher criticism that is powerful in the whole\nrange $\\alpha>1/2$. This optimality property is true for a variety of designs,\nincluding the classical (balanced) multi-way designs and more modern \"$p>n$\"\ndesigns arising in genetics and signal processing. In addition to the standard\nfixed effects model, we establish similar results for a random effects model\nwhere the nonzero coefficients of the regression vector are normally\ndistributed.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2010 18:21:59 GMT"}, {"version": "v2", "created": "Thu, 23 Feb 2012 14:57:43 GMT"}], "update_date": "2012-02-24", "authors_parsed": [["Arias-Castro", "Ery", ""], ["Cand\u00e8s", "Emmanuel J.", ""], ["Plan", "Yaniv", ""]]}, {"id": "1007.1490", "submitter": "Atul Mallik", "authors": "Atul Mallik and Michael Woodroofe", "title": "A Central Limit Theorem For Linear Random Fields", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Central Limit Theorem is proved for linear random fields when sums are\ntaken over finite disjoint union of rectangles. The approach does not rely upon\nthe use of Beveridge Nelson decomposition and the conditions needed are similar\nto those given by Ibragimov for linear processes. When specializing this result\nto the case when sums are being taken over rectangles, a complete analogue of\nIbragimov result is obtained with a lot of uniformity.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2010 00:59:21 GMT"}, {"version": "v2", "created": "Tue, 13 Jul 2010 15:21:56 GMT"}], "update_date": "2010-07-14", "authors_parsed": [["Mallik", "Atul", ""], ["Woodroofe", "Michael", ""]]}, {"id": "1007.1684", "submitter": "Karl Rohe", "authors": "Karl Rohe, Sourav Chatterjee, Bin Yu", "title": "Spectral clustering and the high-dimensional stochastic blockmodel", "comments": "Published in at http://dx.doi.org/10.1214/11-AOS887 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2011, Vol. 39, No. 4, 1878-1915", "doi": "10.1214/11-AOS887", "report-no": "IMS-AOS-AOS887", "categories": "stat.ML math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Networks or graphs can easily represent a diverse set of data sources that\nare characterized by interacting units or actors. Social networks, representing\npeople who communicate with each other, are one example. Communities or\nclusters of highly connected actors form an essential feature in the structure\nof several empirical networks. Spectral clustering is a popular and\ncomputationally feasible method to discover these communities. The stochastic\nblockmodel [Social Networks 5 (1983) 109--137] is a social network model with\nwell-defined communities; each node is a member of one community. For a network\ngenerated from the Stochastic Blockmodel, we bound the number of nodes\n\"misclustered\" by spectral clustering. The asymptotic results in this paper are\nthe first clustering results that allow the number of clusters in the model to\ngrow with the number of nodes, hence the name high-dimensional. In order to\nstudy spectral clustering under the stochastic blockmodel, we first show that\nunder the more general latent space model, the eigenvectors of the normalized\ngraph Laplacian asymptotically converge to the eigenvectors of a \"population\"\nnormalized graph Laplacian. Aside from the implication for spectral clustering,\nthis provides insight into a graph visualization technique. Our method of\nstudying the eigenvectors of random matrices is original.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2010 23:19:06 GMT"}, {"version": "v2", "created": "Thu, 30 Dec 2010 23:08:38 GMT"}, {"version": "v3", "created": "Tue, 13 Dec 2011 11:25:27 GMT"}], "update_date": "2011-12-14", "authors_parsed": [["Rohe", "Karl", ""], ["Chatterjee", "Sourav", ""], ["Yu", "Bin", ""]]}, {"id": "1007.1771", "submitter": "Massimiliano Pontil", "authors": "Karim Lounici, Massimiliano Pontil, Alexandre B. Tsybakov, Sara van de\n  Geer", "title": "Oracle Inequalities and Optimal Inference under Group Sparsity", "comments": "37 pages", "journal-ref": "Annals of Statistics 39(4): 2164-2204, 2011", "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of estimating a sparse linear regression vector\n$\\beta^*$ under a gaussian noise model, for the purpose of both prediction and\nmodel selection. We assume that prior knowledge is available on the sparsity\npattern, namely the set of variables is partitioned into prescribed groups,\nonly few of which are relevant in the estimation process. This group sparsity\nassumption suggests us to consider the Group Lasso method as a means to\nestimate $\\beta^*$. We establish oracle inequalities for the prediction and\n$\\ell_2$ estimation errors of this estimator. These bounds hold under a\nrestricted eigenvalue condition on the design matrix. Under a stronger\ncoherence condition, we derive bounds for the estimation error for mixed\n$(2,p)$-norms with $1\\le p\\leq \\infty$. When $p=\\infty$, this result implies\nthat a threshold version of the Group Lasso estimator selects the sparsity\npattern of $\\beta^*$ with high probability. Next, we prove that the rate of\nconvergence of our upper bounds is optimal in a minimax sense, up to a\nlogarithmic factor, for all estimators over a class of group sparse vectors.\nFurthermore, we establish lower bounds for the prediction and $\\ell_2$\nestimation errors of the usual Lasso estimator. Using this result, we\ndemonstrate that the Group Lasso can achieve an improvement in the prediction\nand estimation properties as compared to the Lasso.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jul 2010 11:54:13 GMT"}, {"version": "v2", "created": "Wed, 21 Jul 2010 11:44:02 GMT"}, {"version": "v3", "created": "Thu, 22 Jul 2010 09:49:24 GMT"}], "update_date": "2012-08-21", "authors_parsed": [["Lounici", "Karim", ""], ["Pontil", "Massimiliano", ""], ["Tsybakov", "Alexandre B.", ""], ["van de Geer", "Sara", ""]]}, {"id": "1007.1894", "submitter": "Jean-Francois Coeurjolly", "authors": "Jean-Fran\\c{c}ois Coeurjolly (LJK, GIPSA-lab), R\\'emy Drouilhet (LJK)", "title": "Asymptotic properties of the maximum pseudo-likelihood estimator for\n  stationary Gibbs point processes including the Lennard-Jones model", "comments": null, "journal-ref": "Electronic Journal of Statistics 4 (2010) 677-706", "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents asymptotic properties of the maximum pseudo-likelihood\nestimator of a vector $\\Vect{\\theta}$ parameterizing a stationary Gibbs point\nprocess. Sufficient conditions, expressed in terms of the local energy function\ndefining a Gibbs point process, to establish strong consistency and asymptotic\nnormality results of this estimator depending on a single realization, are\npresented.These results are general enough to no longer require the local\nstability and the linearity in terms of the parameters of the local energy\nfunction. We consider characteristic examples of such models, the Lennard-Jones\nand the finite range Lennard-Jones models. We show that the different\nassumptions ensuring the consistency are satisfied for both models whereas the\nassumptions ensuring the asymptotic normality are fulfilled only for the finite\nrange Lennard-Jones model.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2010 12:54:05 GMT"}], "update_date": "2010-09-08", "authors_parsed": [["Coeurjolly", "Jean-Fran\u00e7ois", "", "LJK, GIPSA-lab"], ["Drouilhet", "R\u00e9my", "", "LJK"]]}, {"id": "1007.1906", "submitter": "Shota Gugushvili", "authors": "Shota Gugushvili, Bert van Es and Peter Spreij", "title": "Deconvolution for an atomic distribution: rates of convergence", "comments": "27 pages", "journal-ref": "J. Nonparametr. Stat. 23 (2011), no. 4, 1003-1029", "doi": "10.1080/10485252.2011.576763", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $X_1,..., X_n$ be i.i.d.\\ copies of a random variable $X=Y+Z,$ where $\nX_i=Y_i+Z_i,$ and $Y_i$ and $Z_i$ are independent and have the same\ndistribution as $Y$ and $Z,$ respectively. Assume that the random variables\n$Y_i$'s are unobservable and that $Y=AV,$ where $A$ and $V$ are independent,\n$A$ has a Bernoulli distribution with probability of success equal to $1-p$ and\n$V$ has a distribution function $F$ with density $f.$ Let the random variable\n$Z$ have a known distribution with density $k.$ Based on a sample\n$X_1,...,X_n,$ we consider the problem of nonparametric estimation of the\ndensity $f$ and the probability $p.$ Our estimators of $f$ and $p$ are\nconstructed via Fourier inversion and kernel smoothing. We derive their\nconvergence rates over suitable functional classes. By establishing in a number\nof cases the lower bounds for estimation of $f$ and $p$ we show that our\nestimators are rate-optimal in these cases.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2010 13:57:07 GMT"}, {"version": "v2", "created": "Mon, 27 Sep 2010 13:17:50 GMT"}, {"version": "v3", "created": "Thu, 24 Feb 2011 13:52:07 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Gugushvili", "Shota", ""], ["van Es", "Bert", ""], ["Spreij", "Peter", ""]]}, {"id": "1007.2096", "submitter": "Christophe Giraud", "authors": "Yannick Baraud (JAD), Christophe Giraud (CMAP), Sylvie Huet (MIAJ)", "title": "Estimator selection in the Gaussian setting", "comments": "44 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of estimating the mean $f$ of a Gaussian vector $Y$\nwith independent components of common unknown variance $\\sigma^{2}$. Our\nestimation procedure is based on estimator selection. More precisely, we start\nwith an arbitrary and possibly infinite collection $\\FF$ of estimators of $f$\nbased on $Y$ and, with the same data $Y$, aim at selecting an estimator among\n$\\FF$ with the smallest Euclidean risk. No assumptions on the estimators are\nmade and their dependencies with respect to $Y$ may be unknown. We establish a\nnon-asymptotic risk bound for the selected estimator. As particular cases, our\napproach allows to handle the problems of aggregation and model selection as\nwell as those of choosing a window and a kernel for estimating a regression\nfunction, or tuning the parameter involved in a penalized criterion. We also\nderive oracle-type inequalities when $\\FF$ consists of linear estimators. For\nillustration, we carry out two simulation studies. One aims at comparing our\nprocedure to cross-validation for choosing a tuning parameter. The other shows\nhow to implement our approach to solve the problem of variable selection in\npractice.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2010 12:54:55 GMT"}, {"version": "v2", "created": "Wed, 22 Jun 2011 06:58:15 GMT"}], "update_date": "2011-06-24", "authors_parsed": [["Baraud", "Yannick", "", "JAD"], ["Giraud", "Christophe", "", "CMAP"], ["Huet", "Sylvie", "", "MIAJ"]]}, {"id": "1007.2109", "submitter": "Jean-Francois Coeurjolly", "authors": "Jean-Fran\\c{c}ois Coeurjolly (GIPSA-lab, LJK), Pierre-Olivier Amblard\n  (GIPSA-lab), Sophie Achard (GIPSA-lab)", "title": "Wavelet analysis of the multivariate fractional Brownian motion", "comments": null, "journal-ref": "ESAIM: Probability and Statistics 17 (2013) 592-604", "doi": "10.1051/ps/2012011", "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The work developed in the paper concerns the multivariate fractional Brownian\nmotion (mfBm) viewed through the lens of the wavelet transform. After recalling\nsome basic properties on the mfBm, we calculate the correlation structure of\nits wavelet transform. We particularly study the asymptotic behavior of the\ncorrelation, showing that if the analyzing wavelet has a sufficient number of\nnull first order moments, the decomposition eliminates any possible long-range\n(inter)dependence. The cross-spectral density is also considered in a second\npart. Its existence is proved and its evaluation is performed using a von\nBahr-Essen like representation of the function $\\sign(t) |t|^\\alpha$. The\nbehavior of the cross-spectral density of the wavelet field at the zero\nfrequency is also developed and confirms the results provided by the asymptotic\nanalysis of the correlation.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2010 13:45:51 GMT"}, {"version": "v2", "created": "Thu, 30 Jun 2011 11:36:37 GMT"}], "update_date": "2013-08-07", "authors_parsed": [["Coeurjolly", "Jean-Fran\u00e7ois", "", "GIPSA-lab, LJK"], ["Amblard", "Pierre-Olivier", "", "GIPSA-lab"], ["Achard", "Sophie", "", "GIPSA-lab"]]}, {"id": "1007.2137", "submitter": "Iosif Pinelis", "authors": "Iosif Pinelis", "title": "An asymptotically Gaussian bound on the Rademacher tails", "comments": "The discussion and references are expanded; the proofs of Lemmas 2.2\n  and 2.3 are simplified", "journal-ref": "Electron. J. Probab., 17:1--22, 2012", "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An explicit upper bound on the tail probabilities for the normalized\nRademacher sums is given. This bound, which is best possible in a certain\nsense, is asymptotically equivalent to the corresponding tail probability of\nthe standard normal distribution, thus affirming a longstanding conjecture by\nEfron. Applications to sums of general centered uniformly bounded independent\nrandom variables and to the Student test are presented.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2010 16:40:00 GMT"}, {"version": "v2", "created": "Tue, 20 Jul 2010 16:08:31 GMT"}, {"version": "v3", "created": "Mon, 18 Jul 2011 16:29:50 GMT"}], "update_date": "2017-01-17", "authors_parsed": [["Pinelis", "Iosif", ""]]}, {"id": "1007.2612", "submitter": "Edsel Pena", "authors": "Edsel A. Pena and Joshua D. Habiger and Wensong Wu", "title": "Classes of Multiple Decision Functions Strongly Controlling FWER and FDR", "comments": "19 pages", "journal-ref": "Metrika, 2015, 78:563-595", "doi": "10.1007/s00184-014-0516-6", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides two general classes of multiple decision functions where\neach member of the first class strongly controls the family-wise error rate\n(FWER), while each member of the second class strongly controls the false\ndiscovery rate (FDR). These classes offer the possibility that an optimal\nmultiple decision function with respect to a pre-specified criterion, such as\nthe missed discovery rate (MDR), could be found within these classes. Such\nmultiple decision functions can be utilized in multiple testing, specifically,\nbut not limited to, the analysis of high-dimensional microarray data sets.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2010 16:44:06 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Pena", "Edsel A.", ""], ["Habiger", "Joshua D.", ""], ["Wu", "Wensong", ""]]}, {"id": "1007.2656", "submitter": "John Noble", "authors": "John M. Noble", "title": "An Algorithm for Learning the Essential Graph", "comments": "55 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article presents an algorithm for learning the essential graph of a\nBayesian network. The basis of the algorithm is the Maximum Minimum Parents and\nChildren algorithm developed by previous authors, with three substantial\nmodifications. The MMPC algorithm is the first stage of the Maximum Minimum\nHill Climbing algorithm for learning the directed acyclic graph of a Bayesian\nnetwork, introduced by previous authors. The MMHC algorithm runs in two phases;\nfirstly, the MMPC algorithm to locate the skeleton and secondly an edge\norientation phase. The computationally expensive part is the edge orientation\nphase.\n  The first modification introduced to the MMPC algorithm, which requires\nlittle additional computational cost, is to obtain the immoralities and hence\nthe essential graph. This renders the edge orientation phase, the\ncomputationally expensive part, unnecessary, since the entire Markov structure\nthat can be derived from data is present in the essential graph.\n  Secondly, the MMPC algorithm can accept independence statements that are\nlogically inconsistent with those rejected, since with tests for independence,\na `do not reject' conclusion for a particular independence statement is taken\nas `accept' independence. An example is given to illustrate this and a\nmodification is suggested to ensure that the conditional independence\nstatements are logically consistent.\n  Thirdly, the MMHC algorithm makes an assumption of faithfulness. An example\nof a data set is given that does not satisfy this assumption and a modification\nis suggested to deal with some situations where the assumption is not\nsatisfied. The example in question also illustrates problems with the\n`faithfulness' assumption that cannot be tackled by this modification.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2010 10:20:16 GMT"}], "update_date": "2010-07-19", "authors_parsed": [["Noble", "John M.", ""]]}, {"id": "1007.2758", "submitter": "Serguei Dachian", "authors": "Serguei Dachian, Ilia Negri", "title": "On Compound Poisson Processes Arising in Change-Point Type Statistical\n  Models as Limiting Likelihood Ratios", "comments": null, "journal-ref": "Statistical Inference for Stochastic Processes 14, 3 (2011) pp\n  255-271", "doi": "10.1007/s11203-011-9059-x", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Different change-point type models encountered in statistical inference for\nstochastic processes give rise to different limiting likelihood ratio\nprocesses. In a previous paper of one of the authors it was established that\none of these likelihood ratios, which is an exponential functional of a\ntwo-sided Poisson process driven by some parameter, can be approximated (for\nsufficiently small values of the parameter) by another one, which is an\nexponential functional of a two-sided Brownian motion. In this paper we\nconsider yet another likelihood ratio, which is the exponent of a two-sided\ncompound Poisson process driven by some parameter. We establish, that similarly\nto the Poisson type one, the compound Poisson type likelihood ratio can be\napproximated by the Brownian type one for sufficiently small values of the\nparameter. We equally discuss the asymptotics for large values of the parameter\nand illustrate the results by numerical simulations.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2010 12:43:08 GMT"}], "update_date": "2012-11-06", "authors_parsed": [["Dachian", "Serguei", ""], ["Negri", "Ilia", ""]]}, {"id": "1007.2964", "submitter": "Andrew Nobel", "authors": "Terrence M. Adams and Andrew B. Nobel", "title": "The Gap Dimension and Uniform Laws of Large Numbers for Ergodic\n  Processes", "comments": "24 pages, submitted for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let F be a family of Borel measurable functions on a complete separable\nmetric space. The gap (or fat-shattering) dimension of F is a combinatorial\nquantity that measures the extent to which functions f in F can separate finite\nsets of points at a predefined resolution gamma > 0. We establish a connection\nbetween the gap dimension of F and the uniform convergence of its sample\naverages under ergodic sampling. In particular, we show that if the gap\ndimension of F at resolution gamma > 0 is finite, then for every ergodic\nprocess the sample averages of functions in F are eventually within 10 gamma of\ntheir limiting expectations uniformly over the class F. If the gap dimension of\nF is finite for every resolution gamma > 0 then the sample averages of\nfunctions in F converge uniformly to their limiting expectations. We assume\nonly that F is uniformly bounded and countable (or countably approximable). No\nsmoothness conditions are placed on F, and no assumptions beyond ergodicity are\nplaced on the sampling processes. Our results extend existing work for i.i.d.\nprocesses.\n", "versions": [{"version": "v1", "created": "Sat, 17 Jul 2010 23:41:15 GMT"}], "update_date": "2016-11-25", "authors_parsed": [["Adams", "Terrence M.", ""], ["Nobel", "Andrew B.", ""]]}, {"id": "1007.3025", "submitter": "Jay Bartroff", "authors": "Jay Bartroff, Larry Goldstein, and Ester Samuel-Cahn", "title": "The Spend-It-All Region and Small Time Results for the Continuous Bomber\n  Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A problem of optimally allocating partially effective ammunition $x$ to be\nused on randomly arriving enemies in order to maximize an aircraft's\nprobability of surviving for time~$t$, known as the Bomber Problem, was first\nposed by \\citet{Klinger68}. They conjectured a set of apparently obvious\nmonotonicity properties of the optimal allocation function $K(x,t)$. Although\nsome of these conjectures, and versions thereof, have been proved or disproved\nby other authors since then, the remaining central question, that $K(x,t)$ is\nnondecreasing in~$x$, remains unsettled. After reviewing the problem and\nsummarizing the state of these conjectures, in the setting where $x$ is\ncontinuous we prove the existence of a ``spend-it-all'' region in which\n$K(x,t)=x$ and find its boundary, inside of which the long-standing, unproven\nconjecture of monotonicity of~$K(\\cdot,t)$ holds. A new approach is then taken\nof directly estimating~$K(x,t)$ for small~$t$, providing a complete small-$t$\nasymptotic description of~$K(x,t)$ and the optimal probability of survival.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jul 2010 18:05:15 GMT"}], "update_date": "2010-07-20", "authors_parsed": [["Bartroff", "Jay", ""], ["Goldstein", "Larry", ""], ["Samuel-Cahn", "Ester", ""]]}, {"id": "1007.3351", "submitter": "Jean-Francois Coeurjolly", "authors": "Jean-Fran\\c{c}ois Coeurjolly (GIPSA-lab, LJK), David Dereudre (LAMAV),\n  R\\'emy Drouilhet (LJK), Fr\\'ed\\'eric Lavancier (LMJL)", "title": "Takacs Fiksel method for stationary marked Gibbs point processes", "comments": null, "journal-ref": "Scandinavian Journal of Statistics (2012) \\`a para\\^itre", "doi": "10.1111/j.1467-9469.2011.00738.x", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies a method to estimate the parameters governing the\ndistribution of a stationary marked Gibbs point process. This procedure, known\nas the Takacs-Fiksel method, is based on the estimation of the left and right\nhand sides of the Georgii-Nguyen-Zessin formula and leads to a family of\nestimators due to the possible choices of test functions. We propose several\nexamples illustrating the interest and flexibility of this procedure. We also\nprovide sufficient conditions based on the model and the test functions to\nderive asymptotic properties (consistency and asymptotic normality) of the\nresulting estimator. The different assumptions are discussed for exponential\nfamily models and for a large class of test functions. A short simulation study\nis proposed to assess the correctness of the methodology and the asymptotic\nresults.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2010 06:54:43 GMT"}, {"version": "v2", "created": "Thu, 6 Jan 2011 12:28:00 GMT"}], "update_date": "2012-02-27", "authors_parsed": [["Coeurjolly", "Jean-Fran\u00e7ois", "", "GIPSA-lab, LJK"], ["Dereudre", "David", "", "LAMAV"], ["Drouilhet", "R\u00e9my", "", "LJK"], ["Lavancier", "Fr\u00e9d\u00e9ric", "", "LMJL"]]}, {"id": "1007.3662", "submitter": "G. Afendras", "authors": "G. Afendras, N. Papadatos, V. Papathanasiou", "title": "An extended Stein-type covariance identity for the Pearson family with\n  applications to lower variance bounds", "comments": "Published in at http://dx.doi.org/10.3150/10-BEJ282 the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2011, Vol. 17, No. 2, 507-529", "doi": "10.3150/10-BEJ282", "report-no": "IMS-BEJ-BEJ282", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For an absolutely continuous (integer-valued) r.v. $X$ of the Pearson (Ord)\nfamily, we show that, under natural moment conditions, a Stein-type covariance\nidentity of order $k$ holds (cf. [Goldstein and Reinert, J. Theoret. Probab. 18\n(2005) 237--260]). This identity is closely related to the corresponding\nsequence of orthogonal polynomials, obtained by a Rodrigues-type formula, and\nprovides convenient expressions for the Fourier coefficients of an arbitrary\nfunction. Application of the covariance identity yields some novel expressions\nfor the corresponding lower variance bounds for a function of the r.v. $X$,\nexpressions that seem to be known only in particular cases (for the Normal, see\n[Houdr\\'{e} and Kagan, J. Theoret. Probab. 8 (1995) 23--30]; see also\n[Houdr\\'{e} and P\\'{e}rez-Abreu, Ann. Probab. 23 (1995) 400--419] for\ncorresponding results related to the Wiener and Poisson processes). Some\napplications are also given.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2010 13:58:46 GMT"}, {"version": "v2", "created": "Tue, 3 May 2011 12:42:33 GMT"}], "update_date": "2016-11-18", "authors_parsed": [["Afendras", "G.", ""], ["Papadatos", "N.", ""], ["Papathanasiou", "V.", ""]]}, {"id": "1007.3784", "submitter": "Luis David Garcia-Puente", "authors": "Luis David Garc\\'ia-Puente, Sarah Spielvogel and Seth Sullivant", "title": "Identifying Causal Effects with Computer Algebra", "comments": "8 pages, 3 figures, companion website: http://graphicalmodels.info", "journal-ref": "Proceedings of the 26th Conference of Uncertainty in Artificial\n  Intelligence (2010)", "doi": null, "report-no": null, "categories": "math.ST math.AC stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The long-standing identification problem for causal effects in graphical\nmodels has many partial results but lacks a systematic study. We show how\ncomputer algebra can be used to either prove that a causal effect can be\nidentified, generically identified, or show that the effect is not generically\nidentifiable. We report on the results of our computations for linear\nstructural equation models, where we determine precisely which causal effects\nare generically identifiable for all graphs on three and four vertices.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2010 02:08:37 GMT"}], "update_date": "2010-07-23", "authors_parsed": [["Garc\u00eda-Puente", "Luis David", ""], ["Spielvogel", "Sarah", ""], ["Sullivant", "Seth", ""]]}, {"id": "1007.3823", "submitter": "Judith Rousseau", "authors": "Judith Rousseau, Nicolas Chopin, Brunero Liseo", "title": "Bayesian nonparametric estimation of the spectral density of a long or\n  intermediate memory Gaussian process", "comments": "Published in at http://dx.doi.org/10.1214/11-AOS955 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2012, Vol. 40, No. 2, 964-995", "doi": "10.1214/11-AOS955", "report-no": "IMS-AOS-AOS955", "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A stationary Gaussian process is said to be long-range dependent (resp.,\nanti-persistent) if its spectral density $f(\\lambda)$ can be written as\n$f(\\lambda)=|\\lambda|^{-2d}g(|\\lambda|)$, where $0<d<1/2$ (resp., $-1/2<d<0$),\nand $g$ is continuous and positive. We propose a novel Bayesian nonparametric\napproach for the estimation of the spectral density of such processes. We prove\nposterior consistency for both $d$ and $g$, under appropriate conditions on the\nprior distribution. We establish the rate of convergence for a general class of\npriors and apply our results to the family of fractionally exponential priors.\nOur approach is based on the true likelihood and does not resort to Whittle's\napproximation.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2010 08:25:07 GMT"}, {"version": "v2", "created": "Mon, 23 Jul 2012 08:58:29 GMT"}], "update_date": "2012-07-24", "authors_parsed": [["Rousseau", "Judith", ""], ["Chopin", "Nicolas", ""], ["Liseo", "Brunero", ""]]}, {"id": "1007.3880", "submitter": "Shota Gugushvili", "authors": "Shota Gugushvili, Chris A. J. Klaassen", "title": "$\\sqrt{n}$-consistent parameter estimation for systems of ordinary\n  differential equations: bypassing numerical integration via smoothing", "comments": "Published in at http://dx.doi.org/10.3150/11-BEJ362 the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2012, Vol. 18, No. 3, 1061-1098", "doi": "10.3150/11-BEJ362", "report-no": "IMS-BEJ-BEJ362", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of parameter estimation for a system of ordinary\ndifferential equations from noisy observations on a solution of the system. In\ncase the system is nonlinear, as it typically is in practical applications, an\nanalytic solution to it usually does not exist. Consequently, straightforward\nestimation methods like the ordinary least squares method depend on repetitive\nuse of numerical integration in order to determine the solution of the system\nfor each of the parameter values considered, and to find subsequently the\nparameter estimate that minimises the objective function. This induces a huge\ncomputational load to such estimation methods. We study the consistency of an\nalternative estimator that is defined as a minimiser of an appropriate distance\nbetween a nonparametrically estimated derivative of the solution and the\nright-hand side of the system applied to a nonparametrically estimated\nsolution. This smooth and match estimator (SME) bypasses numerical integration\naltogether and reduces the amount of computational time drastically compared to\nordinary least squares. Moreover, we show that under suitable regularity\nconditions this smooth and match estimation procedure leads to a\n$\\sqrt{n}$-consistent estimator of the parameter of interest.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2010 13:20:57 GMT"}, {"version": "v2", "created": "Fri, 25 Feb 2011 15:16:31 GMT"}, {"version": "v3", "created": "Thu, 26 Jul 2012 12:53:10 GMT"}], "update_date": "2012-07-27", "authors_parsed": [["Gugushvili", "Shota", ""], ["Klaassen", "Chris A. J.", ""]]}, {"id": "1007.3910", "submitter": "Larry Goldstein", "authors": "Richard Arratia and Larry Goldstein", "title": "Size bias, sampling, the waiting time paradox, and infinite\n  divisibility: when is the increment independent?", "comments": "30 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With $X^*$ denoting a random variable with the $X$-size bias distribution,\nwhat are all distributions for $X$ such that it is possible to have $X^*=X+Y$,\n$Y\\geq 0$, with $X$ and $Y$ {\\em independent}? We give the answer, due to\nSteutel \\cite{steutel}, and also discuss the relations of size biasing to the\nwaiting time paradox, renewal theory, sampling, tightness and uniform\nintegrability, compound Poisson distributions, infinite divisibility, and the\nlognormal distributions.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2010 15:14:46 GMT"}], "update_date": "2010-07-23", "authors_parsed": [["Arratia", "Richard", ""], ["Goldstein", "Larry", ""]]}, {"id": "1007.4013", "submitter": "Roger Koenker", "authors": "Roger Koenker, Ivan Mizera", "title": "Quasi-concave density estimation", "comments": "Published in at http://dx.doi.org/10.1214/10-AOS814 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2010, Vol. 38, No. 5, 2998-3027", "doi": "10.1214/10-AOS814", "report-no": "IMS-AOS-AOS814", "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Maximum likelihood estimation of a log-concave probability density is\nformulated as a convex optimization problem and shown to have an equivalent\ndual formulation as a constrained maximum Shannon entropy problem. Closely\nrelated maximum Renyi entropy estimators that impose weaker concavity\nrestrictions on the fitted density are also considered, notably a minimum\nHellinger discrepancy estimator that constrains the reciprocal of the\nsquare-root of the density to be concave. A limiting form of these estimators\nconstrains solutions to the class of quasi-concave densities.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2010 21:28:38 GMT"}, {"version": "v2", "created": "Mon, 15 Nov 2010 07:04:10 GMT"}], "update_date": "2010-11-16", "authors_parsed": [["Koenker", "Roger", ""], ["Mizera", "Ivan", ""]]}, {"id": "1007.4037", "submitter": "Andrew Nobel", "authors": "Terrence M. Adams and Andrew B. Nobel", "title": "Uniform Approximation and Bracketing Properties of VC classes", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the sets in a family with finite VC dimension can be uniformly\napproximated within a given error by a finite partition. Immediate corollaries\ninclude the fact that VC classes have finite bracketing numbers, satisfy\nuniform laws of averages under strong dependence, and exhibit uniform mixing.\nOur results are based on recent work concerning uniform laws of averages for VC\nclasses under ergodic sampling.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2010 02:52:08 GMT"}], "update_date": "2010-07-26", "authors_parsed": [["Adams", "Terrence M.", ""], ["Nobel", "Andrew B.", ""]]}, {"id": "1007.4148", "submitter": "Andrey Shabalin", "authors": "Andrey Shabalin and Andrew Nobel", "title": "Reconstruction of a Low-rank Matrix in the Presence of Gaussian Noise", "comments": "34 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study the problem of reconstruction of a low-rank matrix\nobserved with additive Gaussian noise. First we show that under mild\nassumptions (about the prior distribution of the signal matrix) we can restrict\nour attention to reconstruction methods that are based on the singular value\ndecomposition of the observed matrix and act only on its singular values\n(preserving the singular vectors). Then we determine the effect of noise on the\nSVD of low-rank matrices by building a connection between matrix reconstruction\nproblem and spiked population model in random matrix theory. Based on this\nknowledge, we propose a new reconstruction method, called RMT, that is designed\nto reverse the effect of the noise on the singular values of the signal matrix\nand adjust for its effect on the singular vectors. With an extensive simulation\nstudy we show that the proposed method outperform even oracle versions of both\nsoft and hard thresholding methods and closely matches the performance of a\ngeneral oracle scheme.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2010 15:13:23 GMT"}], "update_date": "2010-07-26", "authors_parsed": [["Shabalin", "Andrey", ""], ["Nobel", "Andrew", ""]]}, {"id": "1007.4259", "submitter": "Wicher Bergsma", "authors": "Wicher Bergsma, Angelos Dassios", "title": "A consistent test of independence based on a sign covariance related to\n  Kendall's tau", "comments": "Published in at http://dx.doi.org/10.3150/13-BEJ514 the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2014, Vol. 20, No. 2, 1006-1028", "doi": "10.3150/13-BEJ514", "report-no": "IMS-BEJ-BEJ514", "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The most popular ways to test for independence of two ordinal random\nvariables are by means of Kendall's tau and Spearman's rho. However, such tests\nare not consistent, only having power for alternatives with ``monotonic''\nassociation. In this paper, we introduce a natural extension of Kendall's tau,\ncalled $\\tau^*$, which is non-negative and zero if and only if independence\nholds, thus leading to a consistent independence test. Furthermore,\nnormalization gives a rank correlation which can be used as a measure of\ndependence, taking values between zero and one. A comparison with alternative\nmeasures of dependence for ordinal random variables is given, and it is shown\nthat, in a well-defined sense, $\\tau ^*$ is the simplest, similarly to\nKendall's tau being the simplest of ordinal measures of monotone association.\nSimulation studies show our test compares well with the alternatives in terms\nof average $p$-values.\n", "versions": [{"version": "v1", "created": "Sat, 24 Jul 2010 09:07:50 GMT"}, {"version": "v2", "created": "Fri, 12 Nov 2010 18:52:24 GMT"}, {"version": "v3", "created": "Mon, 24 Jan 2011 18:06:52 GMT"}, {"version": "v4", "created": "Mon, 17 Dec 2012 20:53:40 GMT"}, {"version": "v5", "created": "Mon, 31 Dec 2012 13:11:01 GMT"}, {"version": "v6", "created": "Fri, 14 Mar 2014 07:04:12 GMT"}], "update_date": "2014-03-17", "authors_parsed": [["Bergsma", "Wicher", ""], ["Dassios", "Angelos", ""]]}, {"id": "1007.4278", "submitter": "Xinjia Chen", "authors": "Xinjia Chen", "title": "Sequential Tests of Statistical Hypotheses with Confidence Limits", "comments": "23 pages, no figure; added more applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a general method for testing composite hypotheses.\nOur idea is to use confidence limits to define stopping and decision rules. The\nrequirements of operating characteristic function can be satisfied by adjusting\nthe coefficients of the confidence limits. For common distributions, such\nadjustment can be done via efficient computation by making use of the\nmonotonicity of the associated operating characteristic function. We show that\nthe problem of testing multiple hypotheses can be cast into the general\nframework of constructing sequential random intervals with prescribed coverage\nprobabilities. We propose an inclusion principle for constructing multistage\ntesting plans. It is demonstrated that our proposed testing plans can be\nsubstantially more efficient than the sequential probability ratio test and its\nvariations. We apply our general methodology to develop an exact approach for\ntesting hypotheses regarding the difference of two binomial proportions.\n", "versions": [{"version": "v1", "created": "Sat, 24 Jul 2010 18:58:01 GMT"}, {"version": "v2", "created": "Fri, 12 Nov 2010 17:34:58 GMT"}, {"version": "v3", "created": "Mon, 21 Mar 2011 01:48:52 GMT"}, {"version": "v4", "created": "Mon, 6 Jun 2011 01:19:42 GMT"}, {"version": "v5", "created": "Sun, 31 Jul 2011 19:33:10 GMT"}, {"version": "v6", "created": "Wed, 30 Nov 2011 19:18:13 GMT"}, {"version": "v7", "created": "Thu, 29 Dec 2011 02:23:22 GMT"}, {"version": "v8", "created": "Thu, 9 Feb 2012 18:11:56 GMT"}], "update_date": "2012-02-10", "authors_parsed": [["Chen", "Xinjia", ""]]}, {"id": "1007.4282", "submitter": "Giovanni Pistone", "authors": "Giovanni Pistone and Maria Piera Rogantin", "title": "The Algebra of Reversible Markov Chains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.AC math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For a Markov chain both the detailed balance condition and the cycle\nKolmogorov condition are algebraic binomials. This remark suggests to study\nreversible Markov chains with the tool of Algebraic Statistics, such as toric\nstatistical models. One of the results of this study in an algebraic\nparameterization of reversible Markov transitions and their invariant\nprobability.\n", "versions": [{"version": "v1", "created": "Sat, 24 Jul 2010 19:40:00 GMT"}, {"version": "v2", "created": "Wed, 30 Mar 2011 14:05:08 GMT"}], "update_date": "2011-03-31", "authors_parsed": [["Pistone", "Giovanni", ""], ["Rogantin", "Maria Piera", ""]]}, {"id": "1007.4334", "submitter": "Jean Nuyts", "authors": "Jean Nuyts", "title": "Inference about the tail of a distribution. Improvement on the Hill\n  estimator", "comments": "22 pages, 4 figures", "journal-ref": "International Journal of Mathematics and Mathematical Sciences\n  Volume 2010, Article ID 924013", "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Hill estimator is often used to infer the power behavior in tails of\nexperimental distribution functions. This estimator is known to produce bad\nresults in certain situations which have lead to the so-called Hill horror\nplots. In this brief note, we propose an improved estimator which is simple and\ncoherent and often provides an efficient remedy in the bad situations,\nespecially when the distribution is decreasing slowly, when the data is\nrestricted by external cuts to lie within a finite domain, or even when the\ndistribution is increasing.\n", "versions": [{"version": "v1", "created": "Sun, 25 Jul 2010 16:55:09 GMT"}], "update_date": "2010-07-27", "authors_parsed": [["Nuyts", "Jean", ""]]}, {"id": "1007.4350", "submitter": "Hailin Sang", "authors": "Evarist Gin\\'e and Hailin Sang", "title": "Uniform asymptotics for kernel density estimators with variable\n  bandwidths", "comments": "24 pages", "journal-ref": "Journal of Nonparametric Statistics, 2010", "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is shown that the Hall, Hu and Marron [Hall, P., Hu, T., and Marron J.S.\n(1995), Improved Variable Window Kernel Estimates of Probability Densities,\n{\\it Annals of Statistics}, 23, 1--10] modification of Abramson's [Abramson, I.\n(1982), On Bandwidth Variation in Kernel Estimates - A Square-root Law, {\\it\nAnnals of Statistics}, 10, 1217--1223] variable bandwidth kernel density\nestimator satisfies the optimal asymptotic properties for estimating densities\nwith four uniformly continuous derivatives, uniformly on bounded sets where the\npreliminary estimator of the density is bounded away from zero.\n", "versions": [{"version": "v1", "created": "Sun, 25 Jul 2010 20:37:13 GMT"}], "update_date": "2016-08-14", "authors_parsed": [["Gin\u00e9", "Evarist", ""], ["Sang", "Hailin", ""]]}, {"id": "1007.4528", "submitter": "Matthieu Lerasle", "authors": "Matthieu Lerasle (IME-USP)", "title": "Adaptive non-asymptotic confidence balls in density estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We build confidence balls for the common density $s$ of a real valued sample\n$X_1,...,X_n$. We use resampling methods to estimate the projection of $s$ onto\nfinite dimensional linear spaces and a model selection procedure to choose an\noptimal approximation space. The covering property is ensured for all $n\\geq2$\nand the balls are adaptive over a collection of linear spaces.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2010 18:22:04 GMT"}], "update_date": "2010-07-27", "authors_parsed": [["Lerasle", "Matthieu", "", "IME-USP"]]}, {"id": "1007.4622", "submitter": "Johannes Schmidt-Hieber", "authors": "Marc Hoffmann, Axel Munk and Johannes Schmidt-Hieber", "title": "Adaptive wavelet estimation of the diffusion coefficient under additive\n  error measurements", "comments": "46 pages. This is the second version. A first draft of the paper\n  appeared as a working paper in 2010 under the title \"Nonparametric estimation\n  of the volatility under microstructure noise: wavelet adaptation\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study nonparametric estimation of the diffusion coefficient from discrete\ndata, when the observations are blurred by additional noise. Such issues have\nbeen developed over the last 10 years in several application fields and in\nparticular in high frequency financial data modelling, however mainly from a\nparametric and semiparametric point of view. This paper addresses the\nnonparametric estimation of the path of the (possibly stochastic) diffusion\ncoefficient in a relatively general setting. By developing pre-averaging\ntechniques combined with wavelet thresholding, we construct adaptive estimators\nthat achieve a nearly optimal rate within a large scale of smoothness\nconstraints of Besov type. Since the diffusion coefficient is usually genuinely\nrandom, we propose a new criterion to assess the quality of estimation; we\nretrieve the usual minimax theory when this approach is restricted to a\ndeterministic diffusion coefficient. In particular, we take advantage of recent\nresults of Reiss [33] of asymptotic equivalence between a Gaussian diffusion\nwith additive noise and Gaussian white noise model, in order to prove a sharp\nlower bound.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2010 05:47:12 GMT"}, {"version": "v2", "created": "Thu, 29 Dec 2011 18:26:27 GMT"}], "update_date": "2011-12-30", "authors_parsed": [["Hoffmann", "Marc", ""], ["Munk", "Axel", ""], ["Schmidt-Hieber", "Johannes", ""]]}, {"id": "1007.4791", "submitter": "Caroline Meynet", "authors": "Pascal Massart (LM-Orsay), Caroline Meynet (LM-Orsay)", "title": "An l1-Oracle Inequality for the Lasso", "comments": null, "journal-ref": null, "doi": null, "report-no": "RR-7356", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Lasso has attracted the attention of many authors these last years. While\nmany efforts have been made to prove that the Lasso behaves like a variable\nselection procedure at the price of strong (though unavoidable) assumptions on\nthe geometric structure of these variables, much less attention has been paid\nto the analysis of the performance of the Lasso as a regularization algorithm.\nOur first purpose here is to provide a conceptually very simple result in this\ndirection. We shall prove that, provided that the regularization parameter is\nproperly chosen, the Lasso works almost as well as the deterministic Lasso.\nThis result does not require any assumption at all, neither on the structure of\nthe variables nor on the regression function. Our second purpose is to\nintroduce a new estimator particularly adapted to deal with infinite countable\ndictionaries. This estimator is constructed as an l0-penalized estimator among\na sequence of Lasso estimators associated to a dyadic sequence of growing\ntruncated dictionaries. The selection procedure automatically chooses the best\nlevel of truncation of the dictionary so as to make the best tradeoff between\napproximation, l1-regularization and sparsity. From a theoretical point of\nview, we shall provide an oracle inequality satisfied by this selected Lasso\nestimator. The oracle inequalities established for the Lasso and the selected\nLasso estimators shall enable us to derive rates of convergence on a wide class\nof functions, showing that these estimators perform at least as well as greedy\nalgorithms. Besides, we shall prove that the rates of convergence achieved by\nthe selected Lasso estimator are optimal in the orthonormal case by bounding\nfrom below the minimax risk on some Besov bodies. Finally, some theoretical\nresults about the performance of the Lasso for infinite uncountable\ndictionaries will be studied in the specific framework of neural networks. All\nthe oracle inequalities presented in this paper are obtained via the\napplication of a single general theorem of model selection among a collection\nof nonlinear models which is a direct consequence of the Gaussian concentration\ninequality. The key idea that enables us to apply this general theorem is to\nsee l1-regularization as a model selection procedure among l1-balls.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2010 18:50:07 GMT"}], "update_date": "2010-08-31", "authors_parsed": [["Massart", "Pascal", "", "LM-Orsay"], ["Meynet", "Caroline", "", "LM-Orsay"]]}, {"id": "1007.4909", "submitter": "Nenad Suvak", "authors": "F. Avram, N. N. Leonenko, N. \\v{S}uvak", "title": "On spectral properties and statistical analysis of Fisher-Snedecor\n  diffusion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of parameter estimation for an ergodic diffusion with\nFisher-Snedecor invariant distribution, to be called Fisher-Snedecor diffusion.\nWe compute the spectral representation of its transition density, which\ninvolves a finite number of discrete eigenfunctions (Fisher-Snedecor\npolynomials) as well as a continuous part. We propose moments based estimators\n(related to the Fisher-Snedecor polynomials) and prove their consistency and\nasymptotic normality. Furthermore, we propose a statistical test for the\ndistributional assumptions on the marginal distribution of the Fisher-Snedecor\ndiffusion, based on the moment condition derived from the corresponding Stein's\nequation.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2010 09:28:20 GMT"}], "update_date": "2010-07-29", "authors_parsed": [["Avram", "F.", ""], ["Leonenko", "N. N.", ""], ["\u0160uvak", "N.", ""]]}, {"id": "1007.5107", "submitter": "Clement Ampadu B", "authors": "Clement Ampadu", "title": "On the Powers of Some New Chi-Square Type Statistics", "comments": "15 pages, 6 figures", "journal-ref": "Far East Journal of Theoretical Statistics 2008 (Vol 26, Number 1,\n  pp 59-72)", "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, four new Chi-Square type statistics are presented for testing\nthe hypothesis of a uniform null versus specified trend alternatives. The\npowers of these test statistics are compared with the powers of the statistics\nconsidered by Steele and Chaseling [8]. The four test statistics are shown to\nhave superior or equivalent powers to the powers of the test statistics\nconsidered by the authors for certain trend alternatives and for certain\nconditions placed on the cell count.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2010 04:53:27 GMT"}], "update_date": "2010-07-30", "authors_parsed": [["Ampadu", "Clement", ""]]}, {"id": "1007.5109", "submitter": "Clement Ampadu B", "authors": "Clement Ampadu, Daniel Wang, Michael Steele", "title": "Simulated Power of Some Discrete Goodness-of-Fit Test Statistics For\n  Testing the Null Hypothesis of a Zig-Zag Distribution", "comments": "15 pages, 7 figures, 3 tables", "journal-ref": "Far East Journal of Theoretical Statistics 2009 (Volume 28, Number\n  2, pp 157-171)", "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we compare the powers of several discrete goodness-of-fit test\nstatistics considered by Steele and Chaseling [10] under the null hypothesis of\na 'zig-zag' distribution. The results suggest that the Discrete\nKolmogorov-Smirnov test statistic is generally more powerful for the decreasing\ntrend alternative. The Pearson Chi-Square statistic is generally more powerful\nfor the increasing, unimodal, leptokurtic, platykurtic and bath-tub shaped\nalternatives. Finally, both the Nominal Kolmogorov- Smirnov and the Pearson\nChi-Square test statistic are generally more powerful for the bimodal\nalternative. We also address the issue of the sensitivity of the test\nstatistics to the alternatives under the 'zig-zag' null. In comparison to the\nuniform null of Steele and Chaseling [10], our investigation shows that the\nDiscrete KS test statistic is most sensitive to the decreasing trend\nalternative; the Pearson Chi-Square statistic is most sensitive to both the\nleptokurtic and platykurtic trend alternatives. In particular, under the\n'zig-zag' null we are able to clearly identify the most powerful test statistic\nfor the platykurtic and leptokurtic alternatives, compared to the uniform null\nof Steele and Chaseling [10], which could not make such identification.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2010 05:06:21 GMT"}, {"version": "v2", "created": "Fri, 30 Jul 2010 21:25:30 GMT"}], "update_date": "2010-08-03", "authors_parsed": [["Ampadu", "Clement", ""], ["Wang", "Daniel", ""], ["Steele", "Michael", ""]]}, {"id": "1007.5388", "submitter": "Nicolas Bousquet", "authors": "Nicolas Bousquet", "title": "Reference priors of nuisance parameters in Bayesian sequential\n  population analysis", "comments": "This paper has been withdrawn by the author. 8 pages (short\n  communication) : this paper is currently submitted and should not be cited", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prior distributions elicited for modelling the natural fluctuations or the\nuncertainty on parameters of Bayesian fishery population models, can be chosen\namong a vast range of statistical laws. Since the statistical framework is\ndefined by observational processes, observational parameters enter into the\nestimation and must be considered random, similarly to parameters or states of\ninterest like population levels or real catches. The former are thus perceived\nas nuisance parameters whose values are intrinsically linked to the considered\nexperiment, which also require noninformative priors. In fishery research\nJeffreys methodology has been presented by Millar (2002) as a practical way to\nelicit such priors. However they can present wrong properties in multiparameter\ncontexts. Therefore we suggest to use the elicitation method proposed by Berger\nand Bernardo to avoid paradoxical results raised by Jeffreys priors. These\nbenchmark priors are derived here in the framework of sequential population\nanalysis.\n", "versions": [{"version": "v1", "created": "Fri, 30 Jul 2010 08:21:54 GMT"}, {"version": "v2", "created": "Sun, 8 Aug 2010 11:55:00 GMT"}, {"version": "v3", "created": "Thu, 19 Aug 2010 06:51:19 GMT"}, {"version": "v4", "created": "Mon, 11 Oct 2010 07:30:34 GMT"}], "update_date": "2010-10-12", "authors_parsed": [["Bousquet", "Nicolas", ""]]}]