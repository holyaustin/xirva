[{"id": "1204.0064", "submitter": "Hongtu Zhu", "authors": "Hongtu Zhu, Joseph G. Ibrahim, Hyunsoon Cho", "title": "Perturbation and scaled Cook's distance", "comments": "Published in at http://dx.doi.org/10.1214/12-AOS978 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2012, Vol. 40, No. 2, 785-811", "doi": "10.1214/12-AOS978", "report-no": "IMS-AOS-AOS978", "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cook's distance [Technometrics 19 (1977) 15-18] is one of the most important\ndiagnostic tools for detecting influential individual or subsets of\nobservations in linear regression for cross-sectional data. However, for many\ncomplex data structures (e.g., longitudinal data), no rigorous approach has\nbeen developed to address a fundamental issue: deleting subsets with different\nnumbers of observations introduces different degrees of perturbation to the\ncurrent model fitted to the data, and the magnitude of Cook's distance is\nassociated with the degree of the perturbation. The aim of this paper is to\naddress this issue in general parametric models with complex data structures.\nWe propose a new quantity for measuring the degree of the perturbation\nintroduced by deleting a subset. We use stochastic ordering to quantify the\nstochastic relationship between the degree of the perturbation and the\nmagnitude of Cook's distance. We develop several scaled Cook's distances to\nresolve the comparison of Cook's distance for different subset deletions.\nTheoretical and numerical examples are examined to highlight the broad spectrum\nof applications of these scaled Cook's distances in a formal influence\nanalysis.\n", "versions": [{"version": "v1", "created": "Sat, 31 Mar 2012 03:02:49 GMT"}, {"version": "v2", "created": "Thu, 7 Jun 2012 07:26:18 GMT"}], "update_date": "2012-06-08", "authors_parsed": [["Zhu", "Hongtu", ""], ["Ibrahim", "Joseph G.", ""], ["Cho", "Hyunsoon", ""]]}, {"id": "1204.0147", "submitter": "Adityanand Guntuboyina", "authors": "Adityanand Guntuboyina and Bodhisattva Sen", "title": "Covering Numbers for Convex Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study the covering numbers of the space of convex and\nuniformly bounded functions in multi-dimension. We find optimal upper and lower\nbounds for the $\\epsilon$-covering number of $\\C([a, b]^d, B)$, in the\n$L_p$-metric, $1 \\le p < \\infty$, in terms of the relevant constants, where $d\n\\geq 1$, $a < b \\in \\mathbb{R}$, $B>0$, and $\\C([a,b]^d, B)$ denotes the set of\nall convex functions on $[a, b]^d$ that are uniformly bounded by $B$. We\nsummarize previously known results on covering numbers for convex functions and\nalso provide alternate proofs of some known results. Our results have direct\nimplications in the study of rates of convergence of empirical minimization\nprocedures as well as optimal convergence rates in the numerous convexity\nconstrained function estimation problems.\n", "versions": [{"version": "v1", "created": "Sat, 31 Mar 2012 23:25:53 GMT"}], "update_date": "2012-04-03", "authors_parsed": [["Guntuboyina", "Adityanand", ""], ["Sen", "Bodhisattva", ""]]}, {"id": "1204.0249", "submitter": "Iosif Pinelis", "authors": "Iosif Pinelis", "title": "On the extreme points of moments sets", "comments": "10 pages", "journal-ref": "Math. Methods Oper. Res., 83(3):325--349 (2016)", "doi": null, "report-no": null, "categories": "math.OC math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Necessary and sufficient conditions for a measure to be an extreme point of\nthe set of measures (on an abstract measurable space) with prescribed\ngeneralized moments are given, as well as an application to extremal problems\nover such moment sets; these conditions are expressed in terms of atomic\npartitions of the measurable space. It is also shown that every such extreme\nmeasure can be adequately represented by a linear combination of k Dirac\nprobability measures with nonnegative coefficients, where k is the number of\nrestrictions on moments; moreover, when the measurable space has appropriate\ntopological properties, the phrase \"can be adequately represented by\" here can\nbe replaced simply by \"is\". The proofs are elementary and mainly\nself-contained.\n", "versions": [{"version": "v1", "created": "Sun, 1 Apr 2012 17:48:11 GMT"}], "update_date": "2017-01-17", "authors_parsed": [["Pinelis", "Iosif", ""]]}, {"id": "1204.0316", "submitter": "Stefan Wager", "authors": "Stefan Wager", "title": "Subsampling Extremes: From Block Maxima to Smooth Tail Estimation", "comments": "Added references", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a new estimator for the tail index of a distribution in the Frechet\ndomain of attraction that arises naturally by computing subsample maxima. This\nestimator is equivalent to taking a U-statistic over a Hill estimator with two\norder statistics. The estimator presents multiple advantages over the Hill\nestimator. In particular, it has asymptotically smooth sample paths as a\nfunction of the threshold k, making it considerably more stable than the Hill\nestimator. The estimator also admits a simple and intuitive threshold selection\nrule that does not require fitting a second-order model. Journal of\nMultivariate Analysis, 130, 2014\n", "versions": [{"version": "v1", "created": "Mon, 2 Apr 2012 06:03:25 GMT"}, {"version": "v2", "created": "Sat, 13 Oct 2012 22:54:10 GMT"}, {"version": "v3", "created": "Thu, 17 Oct 2013 23:36:38 GMT"}, {"version": "v4", "created": "Sun, 27 Apr 2014 01:36:26 GMT"}, {"version": "v5", "created": "Sun, 19 Oct 2014 21:57:16 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Wager", "Stefan", ""]]}, {"id": "1204.0405", "submitter": "Songkiat Sumetkijakan", "authors": "Pongpol Ruankong, Tippawan Santiwipanont and Songkiat Sumetkijakan", "title": "Shuffles of copulas and a new measure of dependence", "comments": "28 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using a characterization of Mutual Complete Dependence copulas, we show that,\nwith respect to the Sobolev norm, the MCD copulas can be approximated\narbitrarily closed by shuffles of Min. This result is then used to obtain a\ncharacterization of generalized shuffles of copulas introduced by Durante,\nSarkoci and Sempi in terms of MCD copulas and the $\\star$-product discovered by\nDarsow, Nguyen and Olsen. Since shuffles of a copula is the copula of the\ncorresponding shuffles of the two continuous random variables, we define a new\nnorm which is invariant under shuffling. This norm gives rise to a new measure\nof dependence which shares many properties with the maximal correlation\ncoefficient, the only measure of dependence that satisfies all of R\\'enyi's\npostulates.\n", "versions": [{"version": "v1", "created": "Mon, 2 Apr 2012 13:42:31 GMT"}], "update_date": "2012-04-03", "authors_parsed": [["Ruankong", "Pongpol", ""], ["Santiwipanont", "Tippawan", ""], ["Sumetkijakan", "Songkiat", ""]]}, {"id": "1204.0711", "submitter": "Mil\\'an Mosonyi", "authors": "Koenraad M.R. Audenaert, Milan Mosonyi, Frank Verstraete", "title": "Quantum state discrimination bounds for finite sample size", "comments": "31 pages. v4: A few typos corrected. To appear in J.Math.Phys", "journal-ref": "J. Math. Phys. 53, 122205 (2012)", "doi": "10.1063/1.4768252", "report-no": "Mittag-Leffler-2010fall", "categories": "quant-ph math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the problem of quantum state discrimination, one has to determine by\nmeasurements the state of a quantum system, based on the a priori side\ninformation that the true state is one of two given and completely known\nstates, rho or sigma. In general, it is not possible to decide the identity of\nthe true state with certainty, and the optimal measurement strategy depends on\nwhether the two possible errors (mistaking rho for sigma, or the other way\naround) are treated as of equal importance or not. Results on the quantum\nChernoff and Hoeffding bounds and the quantum Stein's lemma show that, if\nseveral copies of the system are available then the optimal error probabilities\ndecay exponentially in the number of copies, and the decay rate is given by a\ncertain statistical distance between rho and sigma (the Chernoff distance, the\nHoeffding distances, and the relative entropy, respectively). While these\nresults provide a complete solution to the asymptotic problem, they are not\ncompletely satisfying from a practical point of view. Indeed, in realistic\nscenarios one has access only to finitely many copies of a system, and\ntherefore it is desirable to have bounds on the error probabilities for finite\nsample size. In this paper we provide finite-size bounds on the so-called Stein\nerrors, the Chernoff errors, the Hoeffding errors and the mixed error\nprobabilities related to the Chernoff and the Hoeffding errors.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2012 15:28:23 GMT"}, {"version": "v2", "created": "Tue, 8 May 2012 15:04:46 GMT"}, {"version": "v3", "created": "Fri, 21 Sep 2012 20:19:38 GMT"}, {"version": "v4", "created": "Sat, 24 Nov 2012 17:25:52 GMT"}], "update_date": "2012-12-11", "authors_parsed": [["Audenaert", "Koenraad M. R.", ""], ["Mosonyi", "Milan", ""], ["Verstraete", "Frank", ""]]}, {"id": "1204.1035", "submitter": "Xiaofeng Shao", "authors": "Xiaofeng Shao, Dimitris N. Politis", "title": "Fixed-b Subsampling and Block Bootstrap: Improved Confidence Sets Based\n  on P-value Calibration", "comments": "43 pages, 9 pages of figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Subsampling and block-based bootstrap methods have been used in a wide range\nof inference problems for time series. To accommodate the dependence, these\nresampling methods involve a bandwidth parameter, such as subsampling window\nwidth and block size in the block-based bootstrap. In empirical work, using\ndifferent bandwidth parameters could lead to different inference results, but\nthe traditional first order asymptotic theory does not capture the choice of\nthe bandwidth. In this article, we propose to adopt the fixed-b approach, as\nadvocated by Kiefer and Vogelsang (2005) in the\nheteroscedasticity-autocorrelation robust testing context, to account for the\ninfluence of the bandwidth on the inference. Under the fixed-b asymptotic\nframework, we derive the asymptotic null distribution of the p-values for\nsubsampling and the moving block bootstrap, and further propose a calibration\nof the traditional small-b based confidence intervals (regions, bands) and\ntests. Our treatment is fairly general as it includes both finite dimensional\nparameters and infinite dimensional parameters, such as marginal distribution\nfunction and normalized spectral distribution function. Simulation results show\nthat the fixed-b approach is more accurate than the traditional small-b\napproach in terms of approximating the finite sample distribution, and that the\ncalibrated confidence sets tend to have smaller coverage errors than the\nuncalibrated counterparts.\n", "versions": [{"version": "v1", "created": "Wed, 4 Apr 2012 19:07:17 GMT"}], "update_date": "2012-04-05", "authors_parsed": [["Shao", "Xiaofeng", ""], ["Politis", "Dimitris N.", ""]]}, {"id": "1204.1220", "submitter": "James Saunderson", "authors": "James Saunderson, Venkat Chandrasekaran, Pablo A. Parrilo and Alan S.\n  Willsky", "title": "Diagonal and Low-Rank Matrix Decompositions, Correlation Matrices, and\n  Ellipsoid Fitting", "comments": "20 pages", "journal-ref": "SIAM J. Matrix Analysis and Applications, 33(4), 1395-1416, 2012", "doi": "10.1137/120872516", "report-no": null, "categories": "math.OC math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we establish links between, and new results for, three problems\nthat are not usually considered together. The first is a matrix decomposition\nproblem that arises in areas such as statistical modeling and signal\nprocessing: given a matrix $X$ formed as the sum of an unknown diagonal matrix\nand an unknown low rank positive semidefinite matrix, decompose $X$ into these\nconstituents. The second problem we consider is to determine the facial\nstructure of the set of correlation matrices, a convex set also known as the\nelliptope. This convex body, and particularly its facial structure, plays a\nrole in applications from combinatorial optimization to mathematical finance.\nThe third problem is a basic geometric question: given points\n$v_1,v_2,...,v_n\\in \\R^k$ (where $n > k$) determine whether there is a centered\nellipsoid passing \\emph{exactly} through all of the points.\n  We show that in a precise sense these three problems are equivalent.\nFurthermore we establish a simple sufficient condition on a subspace $U$ that\nensures any positive semidefinite matrix $L$ with column space $U$ can be\nrecovered from $D+L$ for any diagonal matrix $D$ using a convex\noptimization-based heuristic known as minimum trace factor analysis. This\nresult leads to a new understanding of the structure of rank-deficient\ncorrelation matrices and a simple condition on a set of points that ensures\nthere is a centered ellipsoid passing through them.\n", "versions": [{"version": "v1", "created": "Thu, 5 Apr 2012 13:19:09 GMT"}], "update_date": "2013-02-05", "authors_parsed": [["Saunderson", "James", ""], ["Chandrasekaran", "Venkat", ""], ["Parrilo", "Pablo A.", ""], ["Willsky", "Alan S.", ""]]}, {"id": "1204.1226", "submitter": "Maik Schwarz", "authors": "Jan Johannes and Maik Schwarz", "title": "Adaptive Gaussian inverse regression with partially unknown operator", "comments": null, "journal-ref": "Communications in Statistics - Theory and Methods (2013),\n  42(7):1343-1362", "doi": "10.1080/03610926.2012.731548", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work deals with the ill-posed inverse problem of reconstructing a\nfunction $f$ given implicitly as the solution of $g = Af$, where $A$ is a\ncompact linear operator with unknown singular values and known eigenfunctions.\nWe observe the function $g$ and the singular values of the operator subject to\nGaussian white noise with respective noise levels $\\varepsilon$ and $\\sigma$.\n  We develop a minimax theory in terms of both noise levels and propose an\northogonal series estimator attaining the minimax rates. This estimator\nrequires the optimal choice of a dimension parameter depending on certain\ncharacteristics of $f$ and $A$. This work addresses the fully data-driven\nchoice of the dimension parameter combining model selection with Lepski's\nmethod. We show that the fully data-driven estimator preserves minimax\noptimality over a wide range of classes for $f$ and $A$ and noise levels\n$\\varepsilon$ and $\\sigma$. The results are illustrated considering Sobolev\nspaces and mildly and severely ill-posed inverse problems.\n", "versions": [{"version": "v1", "created": "Thu, 5 Apr 2012 13:43:44 GMT"}], "update_date": "2013-02-28", "authors_parsed": [["Johannes", "Jan", ""], ["Schwarz", "Maik", ""]]}, {"id": "1204.1454", "submitter": "Yuping Song", "authors": "Song Yu-Ping, Lin Zheng-Yan", "title": "Local linear estimator for stochastic differential equations driven by\n  $\\alpha$-stable L\\'{e}vy motions", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the local linear estimator for the drift coefficient of stochastic\ndifferential equations driven by $\\alpha$-stable L\\'{e}vy motions observed at\ndiscrete instants letting $T \\rightarrow \\infty$. Under regular conditions, we\nderive the weak consistency and central limit theorem of the estimator. Compare\nwith Nadaraya-Watson estimator, the local linear estimator has a bias reduction\nwhether kernel function is symmetric or not under different schemes.\n", "versions": [{"version": "v1", "created": "Fri, 6 Apr 2012 11:36:34 GMT"}], "update_date": "2012-04-09", "authors_parsed": [["Yu-Ping", "Song", ""], ["Zheng-Yan", "Lin", ""]]}, {"id": "1204.1470", "submitter": "Catia  Scricciolo", "authors": "Sonia Petrone, Judith Rousseau and Catia Scricciolo", "title": "Bayes and empirical Bayes: do they merge?", "comments": "27 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian inference is attractive for its coherence and good frequentist\nproperties. However, it is a common experience that eliciting a honest prior\nmay be difficult and, in practice, people often take an {\\em empirical Bayes}\napproach, plugging empirical estimates of the prior hyperparameters into the\nposterior distribution. Even if not rigorously justified, the underlying idea\nis that, when the sample size is large, empirical Bayes leads to \"similar\"\ninferential answers. Yet, precise mathematical results seem to be missing. In\nthis work, we give a more rigorous justification in terms of merging of Bayes\nand empirical Bayes posterior distributions. We consider two notions of\nmerging: Bayesian weak merging and frequentist merging in total variation.\nSince weak merging is related to consistency, we provide sufficient conditions\nfor consistency of empirical Bayes posteriors. Also, we show that, under\nregularity conditions, the empirical Bayes procedure asymptotically selects the\nvalue of the hyperparameter for which the prior mostly favors the \"truth\".\nExamples include empirical Bayes density estimation with Dirichlet process\nmixtures.\n", "versions": [{"version": "v1", "created": "Fri, 6 Apr 2012 13:14:36 GMT"}], "update_date": "2012-04-09", "authors_parsed": [["Petrone", "Sonia", ""], ["Rousseau", "Judith", ""], ["Scricciolo", "Catia", ""]]}, {"id": "1204.1563", "submitter": "Dayu Huang", "authors": "Dayu Huang and Sean Meyn", "title": "Generalized Error Exponents For Small Sample Universal Hypothesis\n  Testing", "comments": "43 pages, 4 figures", "journal-ref": "IEEE Transactions on Information Theory, vol.59, no.12,\n  pp.8157,8181, Dec. 2013", "doi": "10.1109/TIT.2013.2283266", "report-no": null, "categories": "math.ST cs.IT math.IT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The small sample universal hypothesis testing problem is investigated in this\npaper, in which the number of samples $n$ is smaller than the number of\npossible outcomes $m$. The goal of this work is to find an appropriate\ncriterion to analyze statistical tests in this setting. A suitable model for\nanalysis is the high-dimensional model in which both $n$ and $m$ increase to\ninfinity, and $n=o(m)$. A new performance criterion based on large deviations\nanalysis is proposed and it generalizes the classical error exponent applicable\nfor large sample problems (in which $m=O(n)$). This generalized error exponent\ncriterion provides insights that are not available from asymptotic consistency\nor central limit theorem analysis. The following results are established for\nthe uniform null distribution:\n  (i) The best achievable probability of error $P_e$ decays as\n$P_e=\\exp\\{-(n^2/m) J (1+o(1))\\}$ for some $J>0$.\n  (ii) A class of tests based on separable statistics, including the\ncoincidence-based test, attains the optimal generalized error exponents.\n  (iii) Pearson's chi-square test has a zero generalized error exponent and\nthus its probability of error is asymptotically larger than the optimal test.\n", "versions": [{"version": "v1", "created": "Fri, 6 Apr 2012 20:55:34 GMT"}, {"version": "v2", "created": "Mon, 26 Nov 2012 18:33:54 GMT"}, {"version": "v3", "created": "Sun, 28 Dec 2014 19:51:39 GMT"}], "update_date": "2014-12-30", "authors_parsed": [["Huang", "Dayu", ""], ["Meyn", "Sean", ""]]}, {"id": "1204.1605", "submitter": "Mohamed Hebiri", "authors": "Mohamed Hebiri, Johannes C. Lederer", "title": "How Correlations Influence Lasso Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study how correlations in the design matrix influence Lasso prediction.\nFirst, we argue that the higher the correlations are, the smaller the optimal\ntuning parameter is. This implies in particular that the standard tuning\nparameters, that do not depend on the design matrix, are not favorable.\nFurthermore, we argue that Lasso prediction works well for any degree of\ncorrelations if suitable tuning parameters are chosen. We study these two\nsubjects theoretically as well as with simulations.\n", "versions": [{"version": "v1", "created": "Sat, 7 Apr 2012 07:08:28 GMT"}, {"version": "v2", "created": "Mon, 9 Jul 2012 06:45:36 GMT"}], "update_date": "2012-07-11", "authors_parsed": [["Hebiri", "Mohamed", ""], ["Lederer", "Johannes C.", ""]]}, {"id": "1204.1627", "submitter": "Pongpol Ruankong", "authors": "Pongpol Ruankong and Songkiat Sumetkijakan", "title": "On a Generalized $*$-Product for Copulas", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on a generalization of the *-product called\n$\\mathbf{C}$-product. This product, first introduced by Durante, Klement and\nQuesada-Molina, was used to characterize classes of compatible copulas. The\n$\\mathbf{C}$-product of copulas $A$ and $B$ is defined to be an integral of a\nfunction which involves the copulas $A$ and $B$ and the family of copulas\n$\\mathbf{C}$. However, measurability of the integrand in the definition is\nquestionable. We will discuss this in details and attempt to re-define the\nproduct. Then we derive some properties of the re-defined product.\n", "versions": [{"version": "v1", "created": "Sat, 7 Apr 2012 12:33:44 GMT"}], "update_date": "2012-04-10", "authors_parsed": [["Ruankong", "Pongpol", ""], ["Sumetkijakan", "Songkiat", ""]]}, {"id": "1204.1673", "submitter": "Igor Kheifets", "authors": "Igor Kheifets and Carlos Velasco", "title": "Model Adequacy Checks for Discrete Choice Dynamic Models", "comments": null, "journal-ref": null, "doi": "10.1007/978-1-4614-1653-1_14", "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes new parametric model adequacy tests for possibly\nnonlinear and nonstationary time series models with noncontinuous data\ndistribution, which is often the case in applied work. In particular, we\nconsider the correct specification of parametric conditional distributions in\ndynamic discrete choice models, not only of some particular conditional\ncharacteristics such as moments or symmetry. Knowing the true distribution is\nimportant in many circumstances, in particular to apply efficient maximum\nlikelihood methods, obtain consistent estimates of partial effects and\nappropriate predictions of the probability of future events. We propose a\ntransformation of data which under the true conditional distribution leads to\ncontinuous uniform iid series. The uniformity and serial independence of the\nnew series is then examined simultaneously. The transformation can be\nconsidered as an extension of the integral transform tool for noncontinuous\ndata. We derive asymptotic properties of such tests taking into account the\nparameter estimation effect. Since transformed series are iid we do not require\nany mixing conditions and asymptotic results illustrate the double simultaneous\nchecking nature of our test. The test statistics converges under the null with\na parametric rate to the asymptotic distribution, which is case dependent,\nhence we justify a parametric bootstrap approximation. The test has power\nagainst local alternatives and is consistent. The performance of the new tests\nis compared with classical specification checks for discrete choice models.\n", "versions": [{"version": "v1", "created": "Sat, 7 Apr 2012 19:19:29 GMT"}], "update_date": "2017-06-02", "authors_parsed": [["Kheifets", "Igor", ""], ["Velasco", "Carlos", ""]]}, {"id": "1204.1685", "submitter": "Martin Azizyan", "authors": "Martin Azizyan, Aarti Singh, Larry Wasserman", "title": "Density-sensitive semisupervised inference", "comments": "Published in at http://dx.doi.org/10.1214/13-AOS1092 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2013, Vol. 41, No. 2, 751-771", "doi": "10.1214/13-AOS1092", "report-no": "IMS-AOS-AOS1092", "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semisupervised methods are techniques for using labeled data\n$(X_1,Y_1),\\ldots,(X_n,Y_n)$ together with unlabeled data $X_{n+1},\\ldots,X_N$\nto make predictions. These methods invoke some assumptions that link the\nmarginal distribution $P_X$ of X to the regression function f(x). For example,\nit is common to assume that f is very smooth over high density regions of\n$P_X$. Many of the methods are ad-hoc and have been shown to work in specific\nexamples but are lacking a theoretical foundation. We provide a minimax\nframework for analyzing semisupervised methods. In particular, we study methods\nbased on metrics that are sensitive to the distribution $P_X$. Our model\nincludes a parameter $\\alpha$ that controls the strength of the semisupervised\nassumption. We then use the data to adapt to $\\alpha$.\n", "versions": [{"version": "v1", "created": "Sat, 7 Apr 2012 21:49:22 GMT"}, {"version": "v2", "created": "Fri, 24 May 2013 13:14:50 GMT"}], "update_date": "2013-05-27", "authors_parsed": [["Azizyan", "Martin", ""], ["Singh", "Aarti", ""], ["Wasserman", "Larry", ""]]}, {"id": "1204.1688", "submitter": "John C. Duchi", "authors": "John C. Duchi, Lester Mackey, Michael I. Jordan", "title": "The asymptotics of ranking algorithms", "comments": "Published in at http://dx.doi.org/10.1214/13-AOS1142 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2013, Vol. 41, No. 5, 2292-2323", "doi": "10.1214/13-AOS1142", "report-no": "IMS-AOS-AOS1142", "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the predictive problem of supervised ranking, where the task is\nto rank sets of candidate items returned in response to queries. Although there\nexist statistical procedures that come with guarantees of consistency in this\nsetting, these procedures require that individuals provide a complete ranking\nof all items, which is rarely feasible in practice. Instead, individuals\nroutinely provide partial preference information, such as pairwise comparisons\nof items, and more practical approaches to ranking have aimed at modeling this\npartial preference data directly. As we show, however, such an approach raises\nserious theoretical challenges. Indeed, we demonstrate that many commonly used\nsurrogate losses for pairwise comparison data do not yield consistency;\nsurprisingly, we show inconsistency even in low-noise settings. With these\nnegative results as motivation, we present a new approach to supervised ranking\nbased on aggregation of partial preferences, and we develop $U$-statistic-based\nempirical risk minimization procedures. We present an asymptotic analysis of\nthese new procedures, showing that they yield consistency results that parallel\nthose available for classification. We complement our theoretical results with\nan experiment studying the new procedures in a large-scale web-ranking task.\n", "versions": [{"version": "v1", "created": "Sat, 7 Apr 2012 22:33:22 GMT"}, {"version": "v2", "created": "Tue, 29 Jan 2013 18:04:41 GMT"}, {"version": "v3", "created": "Tue, 26 Nov 2013 09:25:03 GMT"}], "update_date": "2013-11-27", "authors_parsed": [["Duchi", "John C.", ""], ["Mackey", "Lester", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1204.1761", "submitter": "Iosif Pinelis", "authors": "Iosif Pinelis", "title": "On the supremum of the tails of normalized sums of independent\n  Rademacher random variables", "comments": "6 pages", "journal-ref": "Statistics and Probability Letters, 99:131--134 (2015)", "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A well-known longstanding conjecture on the supremum of the tails of\nnormalized sums of independent Rademacher random variables is disproved. A\nrelated conjecture, also recently disproved, is discussed.\n", "versions": [{"version": "v1", "created": "Sun, 8 Apr 2012 19:58:20 GMT"}], "update_date": "2017-01-17", "authors_parsed": [["Pinelis", "Iosif", ""]]}, {"id": "1204.1905", "submitter": "Ana Paula Martins", "authors": "Jo\\~ao Renato Sebasti\\~ao, Ana Paula Martins, Helena Ferreira and\n  Lu\\'isa Pereira", "title": "Estimating the Upcrossings Index", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For stationary sequences, under general local and asymptotic dependence\nrestrictions, any limiting point process for time normalized upcrossings of\nhigh levels is a compound Poisson process, i.e., there is a clustering of high\nupcrossings, where the underlying Poisson points represent cluster positions,\nand the multiplicities correspond to cluster sizes. For such classes of\nstationary sequences there exists the upcrossings index $\\eta,$ $0\\leq \\eta\\leq\n1,$ which is directly related to the extremal index $\\theta,$ $0\\leq \\theta\\leq\n1,$ for suitable high levels. In this paper we consider the problem of\nestimating the upcrossings index $\\eta$ for a class of stationary sequences\nsatisfying a mild oscillation restriction. For the proposed estimator,\nproperties such as consistency and asymptotic normality are studied. Finally,\nthe performance of the estimator is assessed through simulation studies for\nautoregressive processes and case studies in the fields of environment and\nfinance.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2012 15:36:35 GMT"}], "update_date": "2012-04-10", "authors_parsed": [["Sebasti\u00e3o", "Jo\u00e3o Renato", ""], ["Martins", "Ana Paula", ""], ["Ferreira", "Helena", ""], ["Pereira", "Lu\u00edsa", ""]]}, {"id": "1204.1992", "submitter": "Bin Nan Dr", "authors": "Shengchun Kong and Bin Nan", "title": "Non-asymptotic Oracle Inequalities for the High-Dimensional Cox\n  Regression via Lasso", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the finite sample properties of the regularized high-dimensional\nCox regression via lasso. Existing literature focuses on linear models or\ngeneralized linear models with Lipschitz loss functions, where the empirical\nrisk functions are the summations of independent and identically distributed\n(iid) losses. The summands in the negative log partial likelihood function for\ncensored survival data, however, are neither iid nor Lipschitz. We first\napproximate the negative log partial likelihood function by a sum of iid\nnon-Lipschitz terms, then derive the non-asymptotic oracle inequalities for the\nlasso penalized Cox regression using pointwise arguments to tackle the\ndifficulty caused by the lack of iid and Lipschitz property.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2012 21:16:17 GMT"}], "update_date": "2012-04-11", "authors_parsed": [["Kong", "Shengchun", ""], ["Nan", "Bin", ""]]}, {"id": "1204.2067", "submitter": "Charles Bouveyron", "authors": "Charles Bouveyron and Camille Brunet", "title": "Discriminative variable selection for clustering with the sparse\n  Fisher-EM algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The interest in variable selection for clustering has increased recently due\nto the growing need in clustering high-dimensional data. Variable selection\nallows in particular to ease both the clustering and the interpretation of the\nresults. Existing approaches have demonstrated the efficiency of variable\nselection for clustering but turn out to be either very time consuming or not\nsparse enough in high-dimensional spaces. This work proposes to perform a\nselection of the discriminative variables by introducing sparsity in the\nloading matrix of the Fisher-EM algorithm. This clustering method has been\nrecently proposed for the simultaneous visualization and clustering of\nhigh-dimensional data. It is based on a latent mixture model which fits the\ndata into a low-dimensional discriminative subspace. Three different approaches\nare proposed in this work to introduce sparsity in the orientation matrix of\nthe discriminative subspace through $\\ell_{1}$-type penalizations. Experimental\ncomparisons with existing approaches on simulated and real-world data sets\ndemonstrate the interest of the proposed methodology. An application to the\nsegmentation of hyperspectral images of the planet Mars is also presented.\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2012 07:34:07 GMT"}], "update_date": "2012-04-11", "authors_parsed": [["Bouveyron", "Charles", ""], ["Brunet", "Camille", ""]]}, {"id": "1204.2090", "submitter": "Damiano  Brigo", "authors": "Damiano Brigo, Kyriakos Chourdakis", "title": "Consistent single- and multi-step sampling of multivariate arrival\n  times: A characterization of self-chaining copulas", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST q-fin.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with dependence across marginally exponentially distributed\narrival times, such as default times in financial modeling or inter-failure\ntimes in reliability theory. We explore the relationship between dependence and\nthe possibility to sample final multivariate survival in a long time-interval\nas a sequence of iterations of local multivariate survivals along a partition\nof the total time interval. We find that this is possible under a form of\nmultivariate lack of memory that is linked to a property of the survival times\ncopula. This property defines a \"self-chaining-copula\", and we show that this\ncoincides with the extreme value copulas characterization. The self-chaining\ncondition is satisfied by the Gumbel-Hougaard copula, a full characterization\nof self chaining copulas in the Archimedean family, and by the Marshall-Olkin\ncopula. The result has important practical implications for consistent\nsingle-step and multi-step simulation of multivariate arrival times in a way\nthat does not destroy dependency through iterations, as happens when\ninconsistently iterating a Gaussian copula.\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2012 09:39:25 GMT"}, {"version": "v2", "created": "Fri, 13 Apr 2012 19:33:59 GMT"}, {"version": "v3", "created": "Sat, 28 Apr 2012 17:01:58 GMT"}], "update_date": "2012-05-01", "authors_parsed": [["Brigo", "Damiano", ""], ["Chourdakis", "Kyriakos", ""]]}, {"id": "1204.2108", "submitter": "Kengo Kato", "authors": "Kengo Kato", "title": "Quasi-Bayesian analysis of nonparametric instrumental variables models", "comments": "Published in at http://dx.doi.org/10.1214/13-AOS1150 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2013, Vol. 41, No. 5, 2359-2390", "doi": "10.1214/13-AOS1150", "report-no": "IMS-AOS-AOS1150", "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper aims at developing a quasi-Bayesian analysis of the nonparametric\ninstrumental variables model, with a focus on the asymptotic properties of\nquasi-posterior distributions. In this paper, instead of assuming a\ndistributional assumption on the data generating process, we consider a\nquasi-likelihood induced from the conditional moment restriction, and put\npriors on the function-valued parameter. We call the resulting posterior\nquasi-posterior, which corresponds to ``Gibbs posterior'' in the literature.\nHere we focus on priors constructed on slowly growing finite-dimensional\nsieves. We derive rates of contraction and a nonparametric Bernstein-von Mises\ntype result for the quasi-posterior distribution, and rates of convergence for\nthe quasi-Bayes estimator defined by the posterior expectation. We show that,\nwith priors suitably chosen, the quasi-posterior distribution (the quasi-Bayes\nestimator) attains the minimax optimal rate of contraction (convergence,\nresp.). These results greatly sharpen the previous related work.\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2012 11:28:45 GMT"}, {"version": "v2", "created": "Mon, 23 Apr 2012 00:19:18 GMT"}, {"version": "v3", "created": "Thu, 20 Dec 2012 09:45:20 GMT"}, {"version": "v4", "created": "Wed, 17 Jul 2013 13:06:42 GMT"}, {"version": "v5", "created": "Wed, 20 Nov 2013 06:59:17 GMT"}], "update_date": "2013-11-21", "authors_parsed": [["Kato", "Kengo", ""]]}, {"id": "1204.2109", "submitter": "Andrius \\v{C}iginas", "authors": "Andrius \\v{C}iginas", "title": "On the asymptotic normality of finite population L-statistics", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give sufficient conditions for the asymptotic normality of linear\ncombinations of order statistics (L-statistics) in the case of simple random\nsamples without replacement. In the first case, restrictions are imposed on the\nweights of L-statistics. The second case is on trimmed means, where we\nintroduce a new finite population smoothness condition.\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2012 11:36:17 GMT"}], "update_date": "2012-04-11", "authors_parsed": [["\u010ciginas", "Andrius", ""]]}, {"id": "1204.2194", "submitter": "Cedric Ginestet", "authors": "Cedric E. Ginestet, Andrew Simmons and Eric D. Kolaczyk", "title": "Weighted Frechet Means as Convex Combinations in Metric Spaces:\n  Properties and Generalized Median Inequalities", "comments": "7 pages, 1 figure. Submitted to Probability and Statistics Letters", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST q-bio.QM stat.TH", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  In this short note, we study the properties of the weighted Frechet mean as a\nconvex combination operator on an arbitrary metric space, (Y,d). We show that\nthis binary operator is commutative, non-associative, idempotent, invariant to\nmultiplication by a constant weight and possesses an identity element. We also\ntreat the properties of the weighted cumulative Frechet mean. These tools allow\nus to derive several types of median inequalities for abstract metric spaces\nthat hold for both negative and positive Alexandrov spaces. In particular, we\nshow through an example that these bounds cannot be improved upon in general\nmetric spaces. For weighted Frechet means, however, such inequalities can\nsolely be derived for weights equal or greater than one. This latter limitation\nhighlights the inherent difficulties associated with working with\nabstract-valued random variables.\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2012 15:33:03 GMT"}, {"version": "v2", "created": "Sun, 10 Jun 2012 13:02:16 GMT"}, {"version": "v3", "created": "Tue, 12 Jun 2012 07:22:59 GMT"}], "update_date": "2012-06-13", "authors_parsed": [["Ginestet", "Cedric E.", ""], ["Simmons", "Andrew", ""], ["Kolaczyk", "Eric D.", ""]]}, {"id": "1204.2296", "submitter": "Karl Rohe", "authors": "Karl Rohe and Tai Qin and Bin Yu", "title": "Co-clustering for directed graphs: the Stochastic co-Blockmodel and\n  spectral algorithm Di-Sim", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Directed graphs have asymmetric connections, yet the current graph clustering\nmethodologies cannot identify the potentially global structure of these\nasymmetries. We give a spectral algorithm called di-sim that builds on a dual\nmeasure of similarity that correspond to how a node (i) sends and (ii) receives\nedges. Using di-sim, we analyze the global asymmetries in the networks of Enron\nemails, political blogs, and the c elegans neural connectome. In each example,\na small subset of nodes have persistent asymmetries; these nodes send edges\nwith one cluster, but receive edges with another cluster. Previous approaches\nwould have assigned these asymmetric nodes to only one cluster, failing to\nidentify their sending/receiving asymmetries. Regularization and \"projection\"\nare two steps of di-sim that are essential for spectral clustering algorithms\nto work in practice. The theoretical results show that these steps make the\nalgorithm weakly consistent under the degree corrected Stochastic\nco-Blockmodel, a model that generalizes the Stochastic Blockmodel to allow for\nboth (i) degree heterogeneity and (ii) the global asymmetries that we intend to\ndetect. The theoretical results make no assumptions on the smallest degree\nnodes. Instead, the theorem requires that the average degree grows sufficiently\nfast and that the weak consistency only applies to the subset of the nodes with\nsufficiently large leverage scores. The results results also apply to bipartite\ngraphs.\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2012 22:30:16 GMT"}, {"version": "v2", "created": "Thu, 8 Jan 2015 20:35:40 GMT"}], "update_date": "2015-01-09", "authors_parsed": [["Rohe", "Karl", ""], ["Qin", "Tai", ""], ["Yu", "Bin", ""]]}, {"id": "1204.2392", "submitter": "Julyan Arbel", "authors": "Julyan Arbel, Ghislaine Gayraud, Judith Rousseau", "title": "Bayesian optimal adaptive estimation using a sieve prior", "comments": "33 pages, 2 figures", "journal-ref": "Scandinavian Journal of Statistics, 2013", "doi": "10.1002/sjos.12002", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive rates of contraction of posterior distributions on nonparametric\nmodels resulting from sieve priors. The aim of the paper is to provide general\nconditions to get posterior rates when the parameter space has a general\nstructure, and rate adaptation when the parameter space is, e.g., a Sobolev\nclass. The conditions employed, although standard in the literature, are\ncombined in a different way. The results are applied to density, regression,\nnonlinear autoregression and Gaussian white noise models. In the latter we have\nalso considered a loss function which is different from the usual l2 norm,\nnamely the pointwise loss. In this case it is possible to prove that the\nadaptive Bayesian approach for the l2 loss is strongly suboptimal and we\nprovide a lower bound on the rate.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2012 09:51:20 GMT"}, {"version": "v2", "created": "Mon, 18 Feb 2013 11:19:13 GMT"}], "update_date": "2016-05-03", "authors_parsed": [["Arbel", "Julyan", ""], ["Gayraud", "Ghislaine", ""], ["Rousseau", "Judith", ""]]}, {"id": "1204.2410", "submitter": "Marius Hofert", "authors": "Marius Hofert, David Pham", "title": "Densities of nested Archimedean copulas", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.CO stat.OT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nested Archimedean copulas recently gained interest since they generalize the\nwell-known class of Archimedean copulas to allow for partial asymmetry.\nSampling algorithms and strategies have been well investigated for nested\nArchimedean copulas. However, for likelihood based inference it is important to\nhave the density. The present work fills this gap. A general formula for the\nderivatives of the nodes and inner generators appearing in nested Archimedean\ncopulas is developed. This leads to a tractable formula for the density of\nnested Archimedean copulas in arbitrary dimensions if the number of nesting\nlevels is not too large. Various examples including famous Archimedean families\nand transformations of such are given. Furthermore, a numerically efficient way\nto evaluate the log-density is presented.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2012 10:54:22 GMT"}, {"version": "v2", "created": "Sun, 28 Oct 2012 22:35:06 GMT"}], "update_date": "2012-10-30", "authors_parsed": [["Hofert", "Marius", ""], ["Pham", "David", ""]]}, {"id": "1204.2458", "submitter": "Alexander Schied", "authors": "Volker Kr\\\"atschmer, Alexander Schied, Henryk Z\\\"ahle", "title": "Comparative and qualitative robustness for law-invariant risk measures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When estimating the risk of a P&L from historical data or Monte Carlo\nsimulation, the robustness of the estimate is important. We argue here that\nHampel's classical notion of qualitative robustness is not suitable for risk\nmeasurement and we propose and analyze a refined notion of robustness that\napplies to tail-dependent law-invariant convex risk measures on Orlicz space.\nThis concept of robustness captures the tradeoff between robustness and\nsensitivity and can be quantified by an index of qualitative robustness. By\nmeans of this index, we can compare various risk measures, such as distortion\nrisk measures, in regard to their degree of robustness. Our analysis also\nyields results that are of independent interest such as continuity properties\nand consistency of estimators for risk measures, or a Skorohod representation\ntheorem for {\\psi}-weak convergence.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2012 14:21:06 GMT"}, {"version": "v2", "created": "Mon, 24 Jun 2013 18:13:53 GMT"}, {"version": "v3", "created": "Sun, 7 Jul 2013 05:20:03 GMT"}, {"version": "v4", "created": "Wed, 17 Jul 2013 17:06:06 GMT"}, {"version": "v5", "created": "Wed, 2 Oct 2013 13:41:35 GMT"}, {"version": "v6", "created": "Tue, 14 Jan 2014 12:58:12 GMT"}], "update_date": "2014-01-15", "authors_parsed": [["Kr\u00e4tschmer", "Volker", ""], ["Schied", "Alexander", ""], ["Z\u00e4hle", "Henryk", ""]]}, {"id": "1204.2579", "submitter": "Bin Nan Dr", "authors": "Bin Nan and Jon A. Wellner", "title": "A general semiparametric Z-estimation approach for case-cohort studies", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Case-cohort design, an outcome-dependent sampling design for censored\nsurvival data, is increasingly used in biomedical research. The development of\nasymptotic theory for a case-cohort design in the current literature primarily\nrelies on counting process stochastic integrals. Such an approach, however, is\nrather limited and lacks theoretical justification for outcome-dependent\nweighted methods due to non-predictability. Instead of stochastic integrals, we\nderive asymptotic properties for case-cohort studies based on a general\nZ-estimation theory for semiparametric models with bundled parameters using\nmodern empirical processes. Both the Cox model and the additive hazards model\nwith time-dependent covariates are considered.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2012 22:06:55 GMT"}], "update_date": "2012-04-13", "authors_parsed": [["Nan", "Bin", ""], ["Wellner", "Jon A.", ""]]}, {"id": "1204.2762", "submitter": "Joseph P. Romano", "authors": "Joseph P. Romano, Azeem M. Shaikh", "title": "On the uniform asymptotic validity of subsampling and the bootstrap", "comments": "Published in at http://dx.doi.org/10.1214/12-AOS1051 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2012, Vol. 40, No. 6, 2798-2822", "doi": "10.1214/12-AOS1051", "report-no": "IMS-AOS-AOS1051", "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides conditions under which subsampling and the bootstrap can\nbe used to construct estimators of the quantiles of the distribution of a root\nthat behave well uniformly over a large class of distributions $\\mathbf{P}$.\nThese results are then applied (i) to construct confidence regions that behave\nwell uniformly over $\\mathbf{P}$ in the sense that the coverage probability\ntends to at least the nominal level uniformly over $\\mathbf{P}$ and (ii) to\nconstruct tests that behave well uniformly over $\\mathbf{P}$ in the sense that\nthe size tends to no greater than the nominal level uniformly over\n$\\mathbf{P}$. Without these stronger notions of convergence, the asymptotic\napproximations to the coverage probability or size may be poor, even in very\nlarge samples. Specific applications include the multivariate mean, testing\nmoment inequalities, multiple testing, the empirical process and U-statistics.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2012 15:59:18 GMT"}, {"version": "v2", "created": "Mon, 18 Feb 2013 14:25:45 GMT"}], "update_date": "2013-02-19", "authors_parsed": [["Romano", "Joseph P.", ""], ["Shaikh", "Azeem M.", ""]]}, {"id": "1204.2763", "submitter": "Paul Rochet", "authors": "Thibault Espinasse, Paul Rochet", "title": "A Cram\\'er-Rao inequality for non differentiable models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We compute a variance lower bound for unbiased estimators in specified\nstatistical models. The construction of the bound is related to the original\nCram\\'er-Rao bound, although it does not require the differentiability of the\nmodel. Moreover, we show our efficiency bound to be always greater than the\nCram\\'er-Rao bound in smooth models, thus providing a sharper result.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2012 16:04:39 GMT"}], "update_date": "2012-04-13", "authors_parsed": [["Espinasse", "Thibault", ""], ["Rochet", "Paul", ""]]}, {"id": "1204.2964", "submitter": "Sylvain Delattre Mr", "authors": "S. Delattre, M. Hoffmann, D. Picard, T. Vareschi", "title": "Blockwise SVD with error in the operator and application to blind\n  deconvolution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider linear inverse problems in a nonparametric statistical framework.\nBoth the signal and the operator are unknown and subject to error measurements.\nWe establish minimax rates of convergence under squared error loss when the\noperator admits a blockwise singular value decomposition (blockwise SVD) and\nthe smoothness of the signal is measured in a Sobolev sense. We construct a\nnonlinear procedure adapting simultaneously to the unknown smoothness of both\nthe signal and the operator and achieving the optimal rate of convergence to\nwithin logarithmic terms. When the noise level in the operator is dominant, by\ntaking full advantage of the blockwise SVD property, we demonstrate that the\nblock SVD procedure overperforms classical methods based on Galerkin projection\nor nonlinear wavelet thresholding. We subsequently apply our abstract framework\nto the specific case of blind deconvolution on the torus and on the sphere.\n", "versions": [{"version": "v1", "created": "Fri, 13 Apr 2012 12:02:35 GMT"}], "update_date": "2012-04-16", "authors_parsed": [["Delattre", "S.", ""], ["Hoffmann", "M.", ""], ["Picard", "D.", ""], ["Vareschi", "T.", ""]]}, {"id": "1204.2975", "submitter": "Evgueni Haroutunian", "authors": "Evgueni Haroutunian and Parandzem Hakobyan", "title": "Multiple Objects: Error Exponents in Hypotheses Testing and\n  Identification", "comments": "35 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We servey a series of investigations of optimal testing of multiple\nhypotheses conserning various multiobject models. These studies are a bright\ninstance of application of methods and technics developed in Shannon\ninformation theory to solution of typical statistical problems.\n", "versions": [{"version": "v1", "created": "Fri, 13 Apr 2012 12:55:30 GMT"}], "update_date": "2012-04-16", "authors_parsed": [["Haroutunian", "Evgueni", ""], ["Hakobyan", "Parandzem", ""]]}, {"id": "1204.2996", "submitter": "Davy Paindaveine", "authors": "Davy Paindaveine, Germain Van Bever", "title": "Nonparametrically consistent depth-based classifiers", "comments": "Published at http://dx.doi.org/10.3150/13-BEJ561 in the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2015, Vol. 21, No. 1, 62-82", "doi": "10.3150/13-BEJ561", "report-no": "IMS-BEJ-BEJ561", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a class of depth-based classification procedures that are of a\nnearest-neighbor nature. Depth, after symmetrization, indeed provides the\ncenter-outward ordering that is necessary and sufficient to define nearest\nneighbors. Like all their depth-based competitors, the resulting classifiers\nare affine-invariant, hence in particular are insensitive to unit changes.\nUnlike the former, however, the latter achieve Bayes consistency under\nvirtually any absolutely continuous distributions - a concept we call\nnonparametric consistency, to stress the difference with the stronger universal\nconsistency of the standard $k$NN classifiers. We investigate the finite-sample\nperformances of the proposed classifiers through simulations and show that they\noutperform affine-invariant nearest-neighbor classifiers obtained through an\nobvious standardization construction. We illustrate the practical value of our\nclassifiers on two real data examples. Finally, we shortly discuss the possible\nuses of our depth-based neighbors in other inference problems.\n", "versions": [{"version": "v1", "created": "Fri, 13 Apr 2012 14:04:23 GMT"}, {"version": "v2", "created": "Fri, 3 Apr 2015 12:53:02 GMT"}], "update_date": "2015-04-06", "authors_parsed": [["Paindaveine", "Davy", ""], ["Van Bever", "Germain", ""]]}, {"id": "1204.3070", "submitter": "Ruriko Yoshida", "authors": "David Haws and Abraham Mart\\'in del Campo, Akimichi Takemura and\n  Ruriko Yoshida", "title": "Markov degree of the three-state toric homogeneous Markov chain model", "comments": "26 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the three-state toric homogeneous Markov chain model (THMC)\nwithout loops and initial parameters. At time $T$, the size of the design\nmatrix is $6 \\times 3\\cdot 2^{T-1}$ and the convex hull of its columns is the\nmodel polytope. We study the behavior of this polytope for $T\\geq 3$ and we\nshow that it is defined by 24 facets for all $T\\ge 5$. Moreover, we give a\ncomplete description of these facets. From this, we deduce that the toric ideal\nassociated with the design matrix is generated by binomials of degree at most\n6. Our proof is based on a result due to Sturmfels, who gave a bound on the\ndegree of the generators of a toric ideal, provided the normality of the\ncorresponding toric variety. In our setting, we established the normality of\nthe toric variety associated to the THMC model by studying the geometric\nproperties of the model polytope.\n", "versions": [{"version": "v1", "created": "Fri, 13 Apr 2012 18:33:17 GMT"}, {"version": "v2", "created": "Sun, 29 Apr 2012 13:47:40 GMT"}, {"version": "v3", "created": "Tue, 17 Sep 2013 23:11:00 GMT"}], "update_date": "2013-09-19", "authors_parsed": [["Haws", "David", ""], ["del Campo", "Abraham Mart\u00edn", ""], ["Takemura", "Akimichi", ""], ["Yoshida", "Ruriko", ""]]}, {"id": "1204.3132", "submitter": "Paul von Hippel", "authors": "Paul T. von Hippel", "title": "The Bias and Efficiency of Incomplete-Data Estimators in Small\n  Univariate Normal Samples", "comments": "32 pages, 3 figures, 3 tables, 2 Appendices", "journal-ref": "Sociological Methods & Research, November 2013; vol. 42, 4: pp.\n  531-558", "doi": "10.1177/0049124113494582", "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Widely used methods for analyzing missing data can be biased in small\nsamples. To understand these biases, we evaluate in detail the situation where\na small univariate normal sample, with values missing at random, is analyzed\nusing either observed-data maximum likelihood (ML) or multiple imputation (MI).\nWe evaluate two types of MI: the usual Bayesian approach, which we call\nposterior draw (PD) imputation, and a little-used alternative, which we call ML\nimputation, in which values are imputed conditionally on an ML estimate. We\nfind that observed-data ML is more efficient and has lower mean squared error\nthan either type of MI. Between the two types of MI, ML imputation is more\nefficient than PD imputation, and ML imputation also has less potential for\nbias in small samples. The bias and efficiency of PD imputation can be improved\nby a change of prior.\n", "versions": [{"version": "v1", "created": "Sat, 14 Apr 2012 02:25:58 GMT"}, {"version": "v2", "created": "Tue, 3 Jul 2012 21:32:32 GMT"}, {"version": "v3", "created": "Tue, 2 Oct 2012 18:58:43 GMT"}, {"version": "v4", "created": "Thu, 20 Jun 2013 16:10:36 GMT"}], "update_date": "2017-03-27", "authors_parsed": [["von Hippel", "Paul T.", ""]]}, {"id": "1204.3183", "submitter": "Cedric Ginestet", "authors": "Cedric E. Ginestet", "title": "Strong Consistency of Frechet Sample Mean Sets for Graph-Valued Random\n  Variables", "comments": "21 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST q-bio.QM stat.ME stat.TH", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  The Frechet mean or barycenter generalizes the idea of averaging in spaces\nwhere pairwise addition is not well-defined. In general metric spaces, the\nFrechet sample mean is not a consistent estimator of the theoretical Frechet\nmean. For graph-valued random variables, for instance, the Frechet sample mean\nmay fail to converge to a unique value. Hence, it becomes necessary to consider\nthe convergence of sequences of sets of graphs. We show that a specific type of\nalmost sure convergence for the Frechet sample mean previously introduced by\nZiezold (1977) is, in fact, equivalent to the Kuratowski outer limit of a\nsequence of Frechet sample means. Equipped with this outer limit, we provide a\nnew proof of the strong consistency of the Frechet sample mean for graph-valued\nrandom variables in separable (pseudo-)metric space. Our proof strategy\nexploits the fact that the metric of interest is bounded, since we are\nconsidering graphs over a finite number of vertices. In this setting, we\ndescribe two strong laws of large numbers for both the restricted and\nunrestricted Frechet sample means of all orders, thereby generalizing a\nprevious result, due to Sverdrup-Thygeson (1981).\n", "versions": [{"version": "v1", "created": "Sat, 14 Apr 2012 15:37:04 GMT"}, {"version": "v2", "created": "Fri, 29 Jun 2012 08:27:45 GMT"}, {"version": "v3", "created": "Sat, 16 Mar 2013 20:19:37 GMT"}, {"version": "v4", "created": "Wed, 15 May 2013 13:42:43 GMT"}], "update_date": "2013-05-16", "authors_parsed": [["Ginestet", "Cedric E.", ""]]}, {"id": "1204.3186", "submitter": "Abolfazl Saghafi Dr.", "authors": "Constantinos Georghiou, Andreas N. Philippou, Abolfazl Saghafi", "title": "On the modes of the Poisson distribution of order k", "comments": "This article is related to several papers published in the Fibonacci\n  Quarterly and solves partially an open problem since 1983, which was posed\n  again and published in the Proceedings of the Thirteenth International\n  Conference on Fibonacci Numbers and their Applications, Congressus\n  Numerantium, 201 (2010), 382-383", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sharp upper and lower bounds are established for the modes of the Poisson\ndistribution of order k. The lower bound established in this paper is better\nthan the previously established lower bound. In addition, for k = 2, 3, 4, 5, a\nrecent conjecture is presently proved solving partially an open problem since\n1983.\n", "versions": [{"version": "v1", "created": "Sat, 14 Apr 2012 17:01:51 GMT"}, {"version": "v2", "created": "Mon, 30 Apr 2012 06:57:14 GMT"}, {"version": "v3", "created": "Thu, 8 Nov 2012 13:31:43 GMT"}, {"version": "v4", "created": "Fri, 4 Jan 2013 14:41:54 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["Georghiou", "Constantinos", ""], ["Philippou", "Andreas N.", ""], ["Saghafi", "Abolfazl", ""]]}, {"id": "1204.3212", "submitter": "Gabriel Peyre", "authors": "Samuel Vaiter (CEREMADE), Charles Deledalle (CEREMADE), Gabriel\n  Peyr\\'e (CEREMADE), Charles Dossal (IMB), Jalal Fadili (GREYC)", "title": "Local Behavior of Sparse Analysis Regularization: Applications to Risk\n  Estimation", "comments": null, "journal-ref": "Applied and Computational Harmonic Analysis 35, 3 (2013) 433-451", "doi": "10.1016/j.acha.2012.11.006", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we aim at recovering an unknown signal x0 from noisy\nL1measurements y=Phi*x0+w, where Phi is an ill-conditioned or singular linear\noperator and w accounts for some noise. To regularize such an ill-posed inverse\nproblem, we impose an analysis sparsity prior. More precisely, the recovery is\ncast as a convex optimization program where the objective is the sum of a\nquadratic data fidelity term and a regularization term formed of the L1-norm of\nthe correlations between the sought after signal and atoms in a given\n(generally overcomplete) dictionary. The L1-sparsity analysis prior is weighted\nby a regularization parameter lambda>0. In this paper, we prove that any\nminimizers of this problem is a piecewise-affine function of the observations y\nand the regularization parameter lambda. As a byproduct, we exploit these\nproperties to get an objectively guided choice of lambda. In particular, we\ndevelop an extension of the Generalized Stein Unbiased Risk Estimator (GSURE)\nand show that it is an unbiased and reliable estimator of an appropriately\ndefined risk. The latter encompasses special cases such as the prediction risk,\nthe projection risk and the estimation risk. We apply these risk estimators to\nthe special case of L1-sparsity analysis regularization. We also discuss\nimplementation issues and propose fast algorithms to solve the L1 analysis\nminimization problem and to compute the associated GSURE. We finally illustrate\nthe applicability of our framework to parameter(s) selection on several imaging\nproblems.\n", "versions": [{"version": "v1", "created": "Sat, 14 Apr 2012 20:30:55 GMT"}, {"version": "v2", "created": "Wed, 10 Oct 2012 12:23:21 GMT"}], "update_date": "2013-11-05", "authors_parsed": [["Vaiter", "Samuel", "", "CEREMADE"], ["Deledalle", "Charles", "", "CEREMADE"], ["Peyr\u00e9", "Gabriel", "", "CEREMADE"], ["Dossal", "Charles", "", "IMB"], ["Fadili", "Jalal", "", "GREYC"]]}, {"id": "1204.3213", "submitter": "Pierre-Andre Zitt", "authors": "Herv\\'e Cardot (IMB), Peggy C\\'enac (IMB), Pierre-Andr\\'e Zitt (IMB)", "title": "Recursive estimation of the conditional geometric median in Hilbert\n  spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A recursive estimator of the conditional geometric median in Hilbert spaces\nis studied. It is based on a stochastic gradient algorithm whose aim is to\nminimize a weighted L1 criterion and is consequently well adapted for robust\nonline estimation. The weights are controlled by a kernel function and an\nassociated bandwidth. Almost sure convergence and L2 rates of convergence are\nproved under general conditions on the conditional distribution as well as the\nsequence of descent steps of the algorithm and the sequence of bandwidths.\nAsymptotic normality is also proved for the averaged version of the algorithm\nwith an optimal rate of convergence. A simulation study confirms the interest\nof this new and fast algorithm when the sample sizes are large. Finally, the\nability of these recursive algorithms to deal with very high-dimensional data\nis illustrated on the robust estimation of television audience profiles\nconditional on the total time spent watching television over a period of 24\nhours.\n", "versions": [{"version": "v1", "created": "Sat, 14 Apr 2012 20:32:35 GMT"}], "update_date": "2012-04-18", "authors_parsed": [["Cardot", "Herv\u00e9", "", "IMB"], ["C\u00e9nac", "Peggy", "", "IMB"], ["Zitt", "Pierre-Andr\u00e9", "", "IMB"]]}, {"id": "1204.3339", "submitter": "Guilherme Pumi", "authors": "Guilherme Pumi and S\\'ilvia R. C. Lopes", "title": "Parameterization of Copulas and Covariance Decay of Stochastic Processes\n  with Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.AP stat.CO stat.OT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we study the problem of constructing stochastic processes with a\npredetermined covariance decay by parameterizing its marginals and a given\nfamily of copulas. We present several examples to illustrate the theory,\nincluding the important Gaussian and Euclidean families of copulas. We\nassociate the theory to common applied time series models and present a general\nmethodology to estimate a given parameter of interest identifiable through the\nprocess' covariance decay. To exemplify the proposed methodology, we present\nsimple Monte Carlo applications to parameter estimation in time series. The\nmethodology is also applied to the S&P500 US stock market index.\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2012 00:54:45 GMT"}], "update_date": "2012-04-17", "authors_parsed": [["Pumi", "Guilherme", ""], ["Lopes", "S\u00edlvia R. C.", ""]]}, {"id": "1204.3358", "submitter": "Peter Ruckdeschel", "authors": "Peter Ruckdeschel, Bernhard Spangl and Daria Pupashenko", "title": "Robust Kalman tracking and smoothing with propagating and\n  non-propagating outliers", "comments": "27 pages, 12 figures, 2 tables", "journal-ref": "Statistical Papers 55(1), 93-123", "doi": "10.1007/s00362-012-0496-4", "report-no": null, "categories": "math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common situation in filtering where classical Kalman filtering does not\nperform particularly well is tracking in the presence of propagating outliers.\nThis calls for robustness understood in a distributional sense, i.e.; we\nenlarge the distribution assumptions made in the ideal model by suitable\nneighborhoods. Based on optimality results for distributional-robust Kalman\nfiltering from Ruckdeschel[01,10], we propose new robust recursive filters and\nsmoothers designed for this purpose as well as specialized versions for\nnon-propagating outliers. We apply these procedures in the context of a GPS\nproblem arising in the car industry. To better understand these filters, we\nstudy their behavior at stylized outlier patterns (for which they are not\ndesigned) and compare them to other approaches for the tracking problem.\nFinally, in a simulation study we discuss efficiency of our procedures in\ncomparison to competitors.\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2012 04:27:21 GMT"}, {"version": "v2", "created": "Mon, 26 Nov 2012 19:28:11 GMT"}], "update_date": "2014-01-28", "authors_parsed": [["Ruckdeschel", "Peter", ""], ["Spangl", "Bernhard", ""], ["Pupashenko", "Daria", ""]]}, {"id": "1204.3719", "submitter": "Ferkan Yilmaz", "authors": "Ferkan Yilmaz and Mohamed-Slim Alouini", "title": "On the Computation of the Higher Order Statistics of the Channel\n  Capacity over Generalized Fading Channels", "comments": "Submitted to IEEE Wireless Communications Letter, February 18, 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.PF math.IT math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The higher-order statistics (HOS) of the channel capacity\n$\\mu_n=\\mathbb{E}[\\log^n(1+\\gamma_{end})]$, where $n\\in\\mathbb{N}$ denotes the\norder of the statistics, has received relatively little attention in the\nliterature, due in part to the intractability of its analysis. In this letter,\nwe propose a novel and unified analysis, which is based on the moment\ngenerating function (MGF) technique, to exactly compute the HOS of the channel\ncapacity. More precisely, our mathematical formalism can be readily applied to\nmaximal-ratio-combining (MRC) receivers operating in generalized fading\nenvironments (i.e., the sum of the correlated noncentral chi-squared\ndistributions / the correlated generalized Rician distributions). The\nmathematical formalism is illustrated by some numerical examples focussing on\nthe correlated generalized fading environments.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2012 07:37:46 GMT"}, {"version": "v2", "created": "Wed, 18 Apr 2012 00:19:54 GMT"}, {"version": "v3", "created": "Fri, 27 Jul 2012 17:06:54 GMT"}], "update_date": "2012-07-30", "authors_parsed": [["Yilmaz", "Ferkan", ""], ["Alouini", "Mohamed-Slim", ""]]}, {"id": "1204.3765", "submitter": "Florian Alexander Johann Ueltzh\\\"ofer", "authors": "Florian A. J. Ueltzh\\\"ofer", "title": "On Non-parametric Estimation of the L\\'evy Kernel of Markov Processes", "comments": "53 pages; 1 figure; Accepted for publication in the journal\n  Stochastic Processes and their Applications (April 30, 2013)", "journal-ref": null, "doi": "10.1016/j.spa.2013.04.023", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a recurrent Markov process which is an It\\^o semi-martingale. The\nL\\'evy kernel describes the law of its jumps. Based on observations\nX(0),X({\\Delta}),...,X(n{\\Delta}), we construct an estimator for the L\\'evy\nkernel's density. We prove its consistency (as n{\\Delta}->\\infty and\n{\\Delta}->0) and a central limit theorem. In the positive recurrent case, our\nestimator is asymptotically normal; in the null recurrent case, it is\nasymptotically mixed normal. Our estimator's rate of convergence equals the\nnon-parametric minimax rate of smooth density estimation. The asymptotic bias\nand variance are analogous to those of the classical Nadaraya-Watson estimator\nfor conditional densities. Asymptotic confidence intervals are provided.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2012 11:32:54 GMT"}, {"version": "v2", "created": "Tue, 2 Oct 2012 12:40:19 GMT"}, {"version": "v3", "created": "Sun, 12 May 2013 16:35:11 GMT"}], "update_date": "2013-05-14", "authors_parsed": [["Ueltzh\u00f6fer", "Florian A. J.", ""]]}, {"id": "1204.3786", "submitter": "Carlo Sgarra", "authors": "Fabio Bellini, Franco Pellerey, Carlo Sgarra and Salimeh Yasaei Sekeh", "title": "Comparison results for Garch processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST math.PR math.ST q-fin.RM stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of stochastic comparison of general Garch-like\nprocesses, for different parameters and different distributions of the\ninnovations. We identify several stochastic orders that are propagated from the\ninnovations to the Garch process itself, and discuss their interpretations. We\nfocus on the convex order and show that in the case of symmetric innovations it\nis also propagated to the cumulated sums of the Garch process. More generally,\nwe discuss multivariate comparison results related to the multivariate convex\nand supermodular order. Finally we discuss ordering with respect to the\nparameters in the Garch (1,1) case. Key words: Garch, Convex Order, Peakedness,\nKurtosis, Supermodularity.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2012 13:15:31 GMT"}], "update_date": "2012-04-18", "authors_parsed": [["Bellini", "Fabio", ""], ["Pellerey", "Franco", ""], ["Sgarra", "Carlo", ""], ["Sekeh", "Salimeh Yasaei", ""]]}, {"id": "1204.3915", "submitter": "Heng Liu", "authors": "Richard A. Davis and Heng Liu", "title": "Theory and Inference for a Class of Observation-driven Models with\n  Application to Time Series of Counts", "comments": "32 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies theory and inference related to a class of time series\nmodels that incorporates nonlinear dynamics. It is assumed that the\nobservations follow a one-parameter exponential family of distributions given\nan accompanying process that evolves as a function of lagged observations. We\nemploy an iterated random function approach and a special coupling technique to\nshow that, under suitable conditions on the parameter space, the conditional\nmean process is a geometric moment contracting Markov chain and that the\nobservation process is absolutely regular with geometrically decaying\ncoefficients. Moreover the asymptotic theory of the maximum likelihood\nestimates of the parameters is established under some mild assumptions. These\nmodels are applied to two examples; the first is the number of transactions per\nminute of Ericsson stock and the second is related to return times of extreme\nevents of Goldman Sachs Group stock.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2012 20:51:25 GMT"}], "update_date": "2012-04-19", "authors_parsed": [["Davis", "Richard A.", ""], ["Liu", "Heng", ""]]}, {"id": "1204.3949", "submitter": "Eliane  Pinheiro", "authors": "Silvia L. P. Ferrari and Eliane C. Pinheiro", "title": "Small-sample likelihood inference in extreme-value regression models", "comments": "18 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We deal with a general class of extreme-value regression models introduced by\nBarreto- Souza and Vasconcellos (2011). Our goal is to derive an adjusted\nlikelihood ratio statistic that is approximately distributed as \\c{hi}2 with a\nhigh degree of accuracy. Although the adjusted statistic requires more\ncomputational effort than its unadjusted counterpart, it is shown that the\nadjustment term has a simple compact form that can be easily implemented in\nstandard statistical software. Further, we compare the finite sample\nperformance of the three classical tests (likelihood ratio, Wald, and score),\nthe gradient test that has been recently proposed by Terrell (2002), and the\nadjusted likelihood ratio test obtained in this paper. Our simulations favor\nthe latter. Applications of our results are presented. Key words: Extreme-value\nregression; Gradient test; Gumbel distribution; Likelihood ratio test;\nNonlinear models; Score test; Small-sample adjustments; Wald test.\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2012 00:15:17 GMT"}, {"version": "v2", "created": "Wed, 20 Jun 2012 21:59:03 GMT"}, {"version": "v3", "created": "Mon, 13 Aug 2012 18:08:57 GMT"}], "update_date": "2012-08-14", "authors_parsed": [["Ferrari", "Silvia L. P.", ""], ["Pinheiro", "Eliane C.", ""]]}, {"id": "1204.4154", "submitter": "Nathan Lay", "authors": "Nathan Lay (Department of Scientific Computing, FSU) and Adrian Barbu\n  (Department of Statistics, FSU)", "title": "The Artificial Regression Market", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Artificial Prediction Market is a recent machine learning technique for\nmulti-class classification, inspired from the financial markets. It involves a\nnumber of trained market participants that bet on the possible outcomes and are\nrewarded if they predict correctly. This paper generalizes the scope of the\nArtificial Prediction Markets to regression, where there are uncountably many\npossible outcomes and the error is usually the MSE. For that, we introduce the\nreward kernel that rewards each participant based on its prediction error and\nwe derive the price equations. Using two reward kernels we obtain two different\nlearning rules, one of which is approximated using Hermite-Gauss quadrature.\nThe market setting makes it easy to aggregate specialized regressors that only\npredict when an observation falls into their specialization domain. Experiments\nshow that regression markets based on the two learning rules outperform Random\nForest Regression on many UCI datasets and are rarely outperformed.\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2012 18:16:59 GMT"}], "update_date": "2014-08-18", "authors_parsed": [["Lay", "Nathan", "", "Department of Scientific Computing, FSU"], ["Barbu", "Adrian", "", "Department of Statistics, FSU"]]}, {"id": "1204.4227", "submitter": "Miles Lopes", "authors": "Miles E. Lopes", "title": "Estimating Unknown Sparsity in Compressed Sensing", "comments": "This is version 2. Many aspects of the paper have been revised. The\n  restriction to non-negative signals has been removed. 22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT math.ST stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the theory of compressed sensing (CS), the sparsity ||x||_0 of the unknown\nsignal x\\in\\R^p is commonly assumed to be a known parameter. However, it is\ntypically unknown in practice. Due to the fact that many aspects of CS depend\non knowing ||x||_0, it is important to estimate this parameter in a data-driven\nway. A second practical concern is that ||x||_0 is a highly unstable function\nof x. In particular, for real signals with entries not exactly equal to 0, the\nvalue ||x||_0=p is not a useful description of the effective number of\ncoordinates. In this paper, we propose to estimate a stable measure of sparsity\ns(x):=||x||_1^2/||x||_2^2, which is a sharp lower bound on ||x||_0. Our\nestimation procedure uses only a small number of linear measurements, does not\nrely on any sparsity assumptions, and requires very little computation. A\nconfidence interval for s(x) is provided, and its width is shown to have no\ndependence on the signal dimension p. Moreover, this result extends naturally\nto the matrix recovery setting, where a soft version of matrix rank can be\nestimated with analogous guarantees. Finally, we show that the use of\nrandomized measurements is essential to estimating s(x). This is accomplished\nby proving that the minimax risk for estimating s(x) with deterministic\nmeasurements is large when n<<p.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2012 00:43:05 GMT"}, {"version": "v2", "created": "Mon, 25 Feb 2013 14:51:32 GMT"}], "update_date": "2013-02-26", "authors_parsed": [["Lopes", "Miles E.", ""]]}, {"id": "1204.4228", "submitter": "Xianyang Zhang", "authors": "Xianyang Zhang, Xiaofeng Shao", "title": "Fixed-smoothing asymptotics for time series", "comments": "Published in at http://dx.doi.org/10.1214/13-AOS1113 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2013, Vol. 41, No. 3, 1329-1349", "doi": "10.1214/13-AOS1113", "report-no": "IMS-AOS-AOS1113", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we derive higher order Edgeworth expansions for the finite\nsample distributions of the subsampling-based t-statistic and the Wald\nstatistic in the Gaussian location model under the so-called fixed-smoothing\nparadigm. In particular, we show that the error of asymptotic approximation is\nat the order of the reciprocal of the sample size and obtain explicit forms for\nthe leading error terms in the expansions. The results are used to justify the\nsecond-order correctness of a new bootstrap method, the Gaussian dependent\nbootstrap, in the context of Gaussian location model.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2012 01:13:02 GMT"}, {"version": "v2", "created": "Tue, 10 Sep 2013 08:25:50 GMT"}], "update_date": "2013-09-11", "authors_parsed": [["Zhang", "Xianyang", ""], ["Shao", "Xiaofeng", ""]]}, {"id": "1204.4238", "submitter": "Weining Shen", "authors": "Weining Shen and Subhashis Ghosal", "title": "MCMC-free adaptive Bayesian procedures using random series prior", "comments": "This paper has been replaced by a new version: arXiv article\n  1403.0625", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider priors for several nonparametric Bayesian models which use finite\nrandom series with a random number of terms. The prior is constructed through\ndistributions on the number of basis functions and the associated coefficients.\nWe derive a general result on the construction of an appropriate sieve and\nobtain adaptive posterior contraction rates for all smoothness levels of the\nfunction in the true model. We apply this general result on several statistical\nproblems such as signal processing, density estimation, nonparametric additive\nregression, classification, spectral density estimation, functional regression\netc. The prior can be viewed as an alternative to commonly used Gaussian\nprocess prior, but can be analyzed by relatively simpler techniques and in many\ncases allows a simpler approach to computation without using Markov chain\nMonte-Carlo (MCMC) methods. A simulation study was conducted to show that the\nperformance of the random series prior is comparable to that of a Gaussian\nprocess prior.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2012 02:12:35 GMT"}, {"version": "v2", "created": "Sat, 7 Feb 2015 05:51:25 GMT"}], "update_date": "2015-02-10", "authors_parsed": [["Shen", "Weining", ""], ["Ghosal", "Subhashis", ""]]}, {"id": "1204.4268", "submitter": "Bruno Saussereau", "authors": "Bruno Saussereau", "title": "Deviation probability bounds for fractional martingales and related\n  remarks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we prove exponential inequalities (also called Bernstein's\ninequality) for fractional martingales. As an immediate corollary, we will\ndiscuss weak law of large numbers for fractional martingales under divergence\nassumption on the $\\beta-$variation of the fractional martingale. A non trivial\nexample of application of this convergence result is proposed.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2012 07:40:20 GMT"}], "update_date": "2012-04-20", "authors_parsed": [["Saussereau", "Bruno", ""]]}, {"id": "1204.4413", "submitter": "John Rhodes", "authors": "Elizabeth S. Allman, James H. Degnan, and John A. Rhodes", "title": "Species tree inference by the STAR method, and generalizations", "comments": "18 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The multispecies coalescent model describes the generation of gene trees from\na rooted metric species tree, and thus provides a framework for the inference\nof species trees from sampled gene trees. We prove that the STAR method of Liu\net al., and generalizations of it, are statistically consistent methods of\ntopological species tree inference under this model. We discuss the impact of\ngene tree sampling schemes for species tree inference using generalized STAR\nmethods, and reinterpret the original STAR as a consensus method based on\nclades.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2012 17:07:51 GMT"}], "update_date": "2012-04-20", "authors_parsed": [["Allman", "Elizabeth S.", ""], ["Degnan", "James H.", ""], ["Rhodes", "John A.", ""]]}, {"id": "1204.4440", "submitter": "Victor Ivanenko", "authors": "Victor I. Ivanenko and Valery A. Labkovsky", "title": "On regularities of mass random phenomena", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper contains an answer to the question of existence of regularities of\nthe so called \\textit{random in a broad sense} mass phenomena, asked by A. N.\nKolmogorov in \\cite{Kolmogorov}. It turns out that some family of\nfinitely-additive probabilities is the statistical regularity of any such\nphenomenon. If the mass phenomenon is stochastic, then this family degenerates\ninto a single probability measure. The paper provides definitions, the\nformulation and the proof of the theorem of existence of statistical\nregularities, as well as the examples of their application.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2012 19:23:56 GMT"}, {"version": "v2", "created": "Sun, 29 Apr 2012 19:10:53 GMT"}, {"version": "v3", "created": "Sat, 14 Jul 2012 20:30:38 GMT"}, {"version": "v4", "created": "Sat, 15 Sep 2012 13:46:52 GMT"}, {"version": "v5", "created": "Mon, 11 Mar 2013 12:02:57 GMT"}, {"version": "v6", "created": "Wed, 28 Aug 2013 12:19:03 GMT"}], "update_date": "2013-08-29", "authors_parsed": [["Ivanenko", "Victor I.", ""], ["Labkovsky", "Valery A.", ""]]}, {"id": "1204.4460", "submitter": "Adina Soaita", "authors": "Robb J. Muirhead and Adina I. Soaita", "title": "On an Approach to Bayesian Sample Sizing in Clinical Trials", "comments": "To appear in \"Festschrift in honor of Professor Morris L. Eaton\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores an approach to Bayesian sample size determination in\nclinical trials. The approach falls into the category of what is often called\n\"proper Bayesian\", in that it does not mix frequentist concepts with Bayesian\nones. A criterion for a \"successful trial\" is defined in terms of a posterior\nprobability, its probability is assessed using the marginal distribution of the\ndata, and this probability forms the basis for choosing sample sizes. We\nillustrate with a standard problem in clinical trials, that of establishing\nsuperiority of a new drug over a control.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2012 20:13:03 GMT"}], "update_date": "2012-04-23", "authors_parsed": [["Muirhead", "Robb J.", ""], ["Soaita", "Adina I.", ""]]}, {"id": "1204.4494", "submitter": "David Degras", "authors": "David Degras", "title": "Rotation Sampling for Functional Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the survey estimation of a population mean in continuous\ntime. For this purpose we extend the rotation sampling method to functional\ndata. In contrast to conventional rotation designs that select the sample\nbefore the survey, our approach randomizes each sample replacement and thus\nallows for adaptive sampling. Using Markov chain theory, we evaluate the\ncovariance structure and the integrated squared error [ISE] of the related\nHorvitz-Thompson estimator. Our sampling designs decrease the mean ISE by\nsuitably reallocating the sample across population strata during replacements.\nThey also reduce the variance of the ISE by increasing the frequency or the\nintensity of replacements. To investigate the benefits of using both current\nand past measurements in the estimation, we develop a new composite estimator.\nIn an application to electricity usage data, our rotation method outperforms\nfixed panels and conventional rotation samples. Because of the weak temporal\ndependence of the data, the composite estimator only slightly improves upon the\nHorvitz-Thompson estimator.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2012 23:04:14 GMT"}, {"version": "v2", "created": "Wed, 25 Apr 2012 02:14:31 GMT"}, {"version": "v3", "created": "Wed, 18 Jul 2012 13:57:26 GMT"}, {"version": "v4", "created": "Tue, 9 Apr 2013 17:15:01 GMT"}], "update_date": "2013-04-10", "authors_parsed": [["Degras", "David", ""]]}, {"id": "1204.4611", "submitter": "Martin Tietje", "authors": "Arnold Janssen and Martin Tietje", "title": "Applications of the Likelihood Theory in Finance: Modelling and Pricing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper discusses the connection between mathematical finance and\nstatistical modelling which turns out to be more than a formal mathematical\ncorrespondence. We like to figure out how common results and notions in\nstatistics and their meaning can be translated to the world of mathematical\nfinance and vice versa. A lot of similarities can be expressed in terms of\nLeCam's theory for statistical experiments which is the theory of the behaviour\nof likelihood processes. For positive prices the arbitrage free financial\nassets fit into filtered experiments. It is shown that they are given by\nfiltered likelihood ratio processes. From the statistical point of view,\nmartingale measures, completeness and pricing formulas are revisited. The\npricing formulas for various options are connected with the power functions of\ntests. For instance the Black-Scholes price of a European option has an\ninterpretation as Bayes risk of a Neyman Pearson test. Under contiguity the\nconvergence of financial experiments and option prices are obtained. In\nparticular, the approximation of Ito type price processes by discrete models\nand the convergence of associated option prices is studied. The result relies\non the central limit theorem for statistical experiments, which is well known\nin statistics in connection with local asymptotic normal (LAN) families. As\napplication certain continuous time option prices can be approximated by\nrelated discrete time pricing formulas.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2012 13:03:37 GMT"}], "update_date": "2012-04-23", "authors_parsed": [["Janssen", "Arnold", ""], ["Tietje", "Martin", ""]]}, {"id": "1204.4677", "submitter": "Bercu Bernard", "authors": "Bernard Bercu, Bruno Portier, Victor Vazquez", "title": "On the asymptotic behavior of the Durbin-Watson statistic for ARX\n  processes in adaptive tracking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A wide literature is available on the asymptotic behavior of the\nDurbin-Watson statistic for autoregressive models. However, it is impossible to\nfind results on the Durbin-Watson statistic for autoregressive models with\nadaptive control. Our purpose is to fill the gap by establishing the asymptotic\nbehavior of the Durbin Watson statistic for ARX models in adaptive tracking. On\nthe one hand, we show the almost sure convergence as well as the asymptotic\nnormality of the least squares estimators of the unknown parameters of the ARX\nmodels. On the other hand, we establish the almost sure convergence of the\nDurbin-Watson statistic and its asymptotic normality. Finally, we propose a\nbilateral statistical test for residual autocorrelation in adaptive tracking.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2012 17:11:35 GMT"}], "update_date": "2012-04-23", "authors_parsed": [["Bercu", "Bernard", ""], ["Portier", "Bruno", ""], ["Vazquez", "Victor", ""]]}, {"id": "1204.4699", "submitter": "Subhadeep Mukhopadhyay", "authors": "Emanuel Parzen and Subhadeep Mukhopadhyay (Deep)", "title": "Modeling, dependence, classification, united statistical science, many\n  cultures", "comments": "31 pages, 10 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Breiman (2001) proposed to statisticians awareness of two cultures: 1.\nParametric modeling culture, pioneered by R.A.Fisher and Jerzy Neyman; 2.\nAlgorithmic predictive culture, pioneered by machine learning research.\n  Parzen (2001), as a part of discussing Breiman (2001), proposed that\nresearchers be aware of many cultures, including the focus of our research: 3.\nNonparametric, quantile based, information theoretic modeling. We provide a\nunification of many statistical methods for traditional small data sets and\nemerging big data sets in terms of comparison density, copula density, measure\nof dependence, correlation, information, new measures (called LP score\ncomoments) that apply to long tailed distributions with out finite second order\nmoments. A very important goal is to unify methods for discrete and continuous\nrandom variables. Our research extends these methods to modern high dimensional\ndata modeling.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2012 18:50:20 GMT"}, {"version": "v2", "created": "Mon, 23 Apr 2012 01:12:08 GMT"}, {"version": "v3", "created": "Tue, 24 Apr 2012 02:11:01 GMT"}], "update_date": "2012-04-25", "authors_parsed": [["Parzen", "Emanuel", "", "Deep"], ["Mukhopadhyay", "Subhadeep", "", "Deep"]]}, {"id": "1204.4761", "submitter": "Wei Sun", "authors": "Hongwei Long, Yasutaka Shimizu, Wei Sun", "title": "Least squares estimators for discretely observed stochastic processes\n  driven by small Levy noises", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of parameter estimation for discretely observed\nstochastic processes driven by additive small L\\'{e}vy noises. We do not impose\nany moment condition on the driving L\\'{e}vy process. Under certain regularity\nconditions on the drift function, we obtain consistency and rate of convergence\nof the least squares estimator (LSE) of the drift parameter when a small\ndispersion coefficient $\\varepsilon \\to 0$ and $n \\to \\infty$ simultaneously.\nThe asymptotic distribution of the LSE in our general setting is shown to be\nthe convolution of a normal distribution and a distribution related to the jump\npart of the L\\'evy process.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2012 23:06:30 GMT"}, {"version": "v2", "created": "Mon, 21 May 2012 22:29:04 GMT"}], "update_date": "2012-05-23", "authors_parsed": [["Long", "Hongwei", ""], ["Shimizu", "Yasutaka", ""], ["Sun", "Wei", ""]]}, {"id": "1204.4762", "submitter": "Jeremy Sumner", "authors": "Barbara R. Holland, Peter D. Jarvis, and Jeremy G. Sumner", "title": "Low-parameter phylogenetic estimation under the general Markov model", "comments": "22 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM math.ST q-bio.PE stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In their 2008 and 2009 papers, Sumner and colleagues introduced the\n\"squangles\" - a small set of Markov invariants for phylogenetic quartets. The\nsquangles are consistent with the general Markov model (GM) and can be used to\ninfer quartets without the need to explicitly estimate all parameters. As GM is\ninhomogeneous and hence non-stationary, the squangles are expected to perform\nwell compared to standard approaches when there are changes in base-composition\namongst species. However, GM includes the IID assumption, so the squangles\nshould be confounded by data generated with invariant sites or with\nrate-variation across sites. Here we implement the squangles in a least-squares\nsetting that returns quartets weighted by either confidence or internal edge\nlengths; and use these as input into a variety of quartet-based supertree\nmethods. For the first time, we quantitatively investigate the robustness of\nthe squangles to the breaking of IID assumptions on both simulated and real\ndata sets; and we suggest a modification that improves the performance of the\nsquangles in the presence of invariant sites. Our conclusion is that the\nsquangles provide a novel tool for phylogenetic estimation that is\ncomplementary to methods that explicitly account for rate-variation across\nsites, but rely on homogeneous - and hence stationary - models.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2012 23:33:42 GMT"}], "update_date": "2012-04-24", "authors_parsed": [["Holland", "Barbara R.", ""], ["Jarvis", "Peter D.", ""], ["Sumner", "Jeremy G.", ""]]}, {"id": "1204.4801", "submitter": "Mateusz Pipie\\'n", "authors": "Lukasz Lenart, Mateusz Pipien", "title": "Almost Periodically Correlated Time Series in Business Fluctuations\n  Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a non-standard subsampling procedure to make formal statistical\ninference about the business cycle, one of the most important unobserved\nfeature characterising fluctuations of economic growth. We show that some\ncharacteristics of business cycle can be modelled in a non-parametric way by\ndiscrete spectrum of the Almost Periodically Correlated (APC) time series. On\nthe basis of estimated characteristics of this spectrum business cycle is\nextracted by filtering. As an illustration we characterise the man properties\nof business cycles in industrial production index for Polish economy.\n", "versions": [{"version": "v1", "created": "Sat, 21 Apr 2012 11:00:39 GMT"}], "update_date": "2012-04-24", "authors_parsed": [["Lenart", "Lukasz", ""], ["Pipien", "Mateusz", ""]]}, {"id": "1204.4813", "submitter": "Sara van de Geer", "authors": "Sara van de Geer", "title": "Weakly decomposable regularization penalties and structured sparsity", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been shown in literature that the Lasso estimator, or l1-penalized\nleast squares estimator, enjoys good oracle properties. This paper examines\nwhich special properties of the l1-penalty allow for sharp oracle results, and\nthen extends the situation to general norm-based penalties that satisfy a weak\ndecomposability condition.\n", "versions": [{"version": "v1", "created": "Sat, 21 Apr 2012 14:07:00 GMT"}, {"version": "v2", "created": "Mon, 10 Dec 2012 13:24:02 GMT"}], "update_date": "2012-12-11", "authors_parsed": [["van de Geer", "Sara", ""]]}, {"id": "1204.4995", "submitter": "Sumit Kumar", "authors": "Garimella Rama Murthy (Associate Professor, IIIT - Hyderabad,\n  Gachibowli, India)", "title": "Finite / Countable State Space Stochastic Processes : Point Processes:\n  Characterization of Associated Auto-Correlation Functions:", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this research paper, the relationship between finite / countable state\nspace stochastic processes and point processes is explored. Utilizing the known\nrelationship between Poisson processes and continuous time Markov chains,\nfinite / countable state space random processes are related to continuous time\nMarkov Chains. Based on the known results for binary random processes,\ncharacterization of auto-correlation function of finite state space random\nprocesses is explored. An important characterization of corner positive\ndefinite matrices is provided.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2012 08:18:36 GMT"}], "update_date": "2012-04-24", "authors_parsed": [["Murthy", "Garimella Rama", "", "Associate Professor, IIIT - Hyderabad,\n  Gachibowli, India"]]}, {"id": "1204.5291", "submitter": "Georgios Fellouris Dr.", "authors": "Georgios Fellouris, Alexander G. Tartakovsky", "title": "Almost optimal sequential tests of discrete composite hypotheses", "comments": "31 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of sequentially testing a simple null hypothesis\nversus a composite alternative hypothesis that consists of a finite set of\ndensities. We study sequential tests that are based on thresholding of\nmixture-based likelihood ratio statistics and weighted generalized likelihood\nratio statistics. It is shown that both sequential tests have several\nasymptotic optimality properties as error probabilities go to zero. First, for\nany weights, they minimize the expected sample size within a constant term\nunder every scenario in the alternative hypothesis and at least to first order\nunder the null hypothesis. Second, for appropriate weights that are specified\nup to a prior distribution, they minimize within an asymptotically negligible\nterm a weighted expected sample size in the alternative hypothesis. Third, for\na particular prior distribution, they are almost minimax with respect to the\nexpected Kullback-Leibler divergence until stopping. Furthermore, based on\nhigh-order asymptotic expansions for the operating characteristics, we propose\nprior distributions that lead to a robust behavior. Finally, based on\nasymptotic analysis as well as on simulation experiments, we argue that both\ntests have the same performance when they are designed with the same weights.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2012 07:49:49 GMT"}, {"version": "v2", "created": "Tue, 22 Jan 2013 06:33:02 GMT"}], "update_date": "2013-01-23", "authors_parsed": [["Fellouris", "Georgios", ""], ["Tartakovsky", "Alexander G.", ""]]}, {"id": "1204.5357", "submitter": "Jose M. Pe\\~na", "authors": "Jose M. Pe\\~na", "title": "Learning AMP Chain Graphs under Faithfulness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with chain graphs under the alternative\nAndersson-Madigan-Perlman (AMP) interpretation. In particular, we present a\nconstraint based algorithm for learning an AMP chain graph a given probability\ndistribution is faithful to. We also show that the extension of Meek's\nconjecture to AMP chain graphs does not hold, which compromises the development\nof efficient and correct score+search learning algorithms under assumptions\nweaker than faithfulness.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2012 12:49:47 GMT"}], "update_date": "2012-04-25", "authors_parsed": [["Pe\u00f1a", "Jose M.", ""]]}, {"id": "1204.5399", "submitter": "Arthur Carvalho", "authors": "Arthur Carvalho and Kate Larson", "title": "A Consensual Linear Opinion Pool", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important question when eliciting opinions from experts is how to\naggregate the reported opinions. In this paper, we propose a pooling method to\naggregate expert opinions. Intuitively, it works as if the experts were\ncontinuously updating their opinions in order to accommodate the expertise of\nothers. Each updated opinion takes the form of a linear opinion pool, where the\nweight that an expert assigns to a peer's opinion is inversely related to the\ndistance between their opinions. In other words, experts are assumed to prefer\nopinions that are close to their own opinions. We prove that such an updating\nprocess leads to consensus, \\textit{i.e.}, the experts all converge towards the\nsame opinion. Further, we show that if rational experts are rewarded using the\nquadratic scoring rule, then the assumption that they prefer opinions that are\nclose to their own opinions follows naturally. We empirically demonstrate the\nefficacy of the proposed method using real-world data.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2012 15:12:34 GMT"}, {"version": "v2", "created": "Wed, 3 Apr 2013 23:57:08 GMT"}, {"version": "v3", "created": "Tue, 9 Apr 2013 21:49:06 GMT"}], "update_date": "2013-04-11", "authors_parsed": [["Carvalho", "Arthur", ""], ["Larson", "Kate", ""]]}, {"id": "1204.5536", "submitter": "Jianqing Fan", "authors": "Jianqing Fan, Yuan Liao", "title": "Endogeneity in high dimensions", "comments": "Published in at http://dx.doi.org/10.1214/13-AOS1202 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2014, Vol. 42, No. 3, 872-917", "doi": "10.1214/13-AOS1202", "report-no": "IMS-AOS-AOS1202", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most papers on high-dimensional statistics are based on the assumption that\nnone of the regressors are correlated with the regression error, namely, they\nare exogenous. Yet, endogeneity can arise incidentally from a large pool of\nregressors in a high-dimensional regression. This causes the inconsistency of\nthe penalized least-squares method and possible false scientific discoveries. A\nnecessary condition for model selection consistency of a general class of\npenalized regression methods is given, which allows us to prove formally the\ninconsistency claim. To cope with the incidental endogeneity, we construct a\nnovel penalized focused generalized method of moments (FGMM) criterion\nfunction. The FGMM effectively achieves the dimension reduction and applies the\ninstrumental variable methods. We show that it possesses the oracle property\neven in the presence of endogenous predictors, and that the solution is also\nnear global minimum under the over-identification assumption. Finally, we also\nshow how the semi-parametric efficiency of estimation can be achieved via a\ntwo-step approach.\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2012 02:25:21 GMT"}, {"version": "v2", "created": "Tue, 27 May 2014 07:12:05 GMT"}], "update_date": "2014-05-28", "authors_parsed": [["Fan", "Jianqing", ""], ["Liao", "Yuan", ""]]}, {"id": "1204.5623", "submitter": "Pongpol Ruankong", "authors": "Pongpol Ruankong, Songkiat Sumetkijakan", "title": "Essential Closures and Supports of Multivariate Copulas", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We generalize the notion of essential closures which is used in formulating a\ngeometric necessary condition for a set to be the support of a multivariate\ncopula. Furthermore, in some special cases, we derive an explicit formula of\nthe support in terms of essential closures and obtain a stronger necessary\ncondition.\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2012 11:24:35 GMT"}, {"version": "v2", "created": "Wed, 25 Jul 2012 09:35:57 GMT"}], "update_date": "2012-07-26", "authors_parsed": [["Ruankong", "Pongpol", ""], ["Sumetkijakan", "Songkiat", ""]]}, {"id": "1204.5633", "submitter": "Martin Wendler", "authors": "O. Sh. Sharipov, M. Wendler", "title": "Normal Limits, Nonnormal Limits, and the Bootstrap for Quantiles of\n  Dependent Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We will show under very weak conditions on differentiability and dependence\nthat the central limit theorem for quantiles holds and that the block bootstrap\nis weakly consistent. Under slightly stronger conditions, the bootstrap is\nstrongly consistent. Without the differentiability condition, quantiles might\nhave a non-normal asymptotic distribution and the bootstrap might fail.\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2012 12:08:56 GMT"}, {"version": "v2", "created": "Wed, 24 Oct 2012 15:35:56 GMT"}, {"version": "v3", "created": "Fri, 14 Dec 2012 14:08:58 GMT"}], "update_date": "2012-12-17", "authors_parsed": [["Sharipov", "O. Sh.", ""], ["Wendler", "M.", ""]]}, {"id": "1204.5894", "submitter": "M{\\aa}ns Thulin", "authors": "M{\\aa}ns Thulin", "title": "Coverage-adjusted confidence intervals for a binomial proportion", "comments": "20 pages, 10 figures, 2 tables", "journal-ref": "Scandinavian Journal of Statistics, 41, 291-300 (2014)", "doi": "10.1111/sjos.12021", "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the classic problem of interval estimation of a proportion $p$\nbased on binomial sampling. The \"exact\" Clopper-Pearson confidence interval for\n$p$ is known to be unnecessarily conservative. We propose coverage-adjustments\nof the Clopper-Pearson interval using prior and posterior distributions of $p$.\nThe adjusted intervals have improved coverage and are often shorter than\ncompeting intervals found in the literature. Using new heatmap-type plots for\ncomparing confidence intervals, we find that the coverage-adjusted intervals\nare particularly suitable for $p$ close to 0 or 1.\n", "versions": [{"version": "v1", "created": "Thu, 26 Apr 2012 11:57:59 GMT"}, {"version": "v2", "created": "Tue, 10 Jul 2012 14:10:05 GMT"}], "update_date": "2015-03-11", "authors_parsed": [["Thulin", "M\u00e5ns", ""]]}, {"id": "1204.6054", "submitter": "Othmane Kortbi", "authors": "Othmane Kortbi, \\'Eric Marchand", "title": "Estimation of a multivariate normal mean with a bounded signal to noise\n  ratio", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For normal canonical models with $X \\sim N_p(\\theta, \\sigma^{2} I_{p}), \\;\\;\nS^{2} \\sim \\sigma^{2}\\chi^{2}_{k}, \\;{independent}$, we consider the problem of\nestimating $\\theta$ under scale invariant squared error loss $\\frac{\\|d-\\theta\n\\|^{2}}{\\sigma^{2}}$, when it is known that the signal-to-noise ratio\n$\\frac{\\|\\theta\\|}{\\sigma}$ is bounded above by $m$. Risk analysis is achieved\nby making use of a conditional risk decomposition and we obtain in particular\nsufficient conditions for an estimator to dominate either the unbiased\nestimator $\\delta_{UB}(X)=X$, or the maximum likelihood estimator\n$\\delta_{\\hbox{mle}}(X,S^2)$, or both of these benchmark procedures. The given\ndevelopments bring into play the pivotal role of the boundary Bayes estimator\n$\\delta_{BU}$ associated with a prior on $(\\theta,\\sigma)$ such that\n$\\theta|\\sigma$ is uniformly distributed on the (boundary) sphere of radius $m$\nand a non-informative $\\frac{1}{\\sigma}$ prior measure is placed marginally on\n$\\sigma$. With a series of technical results related to $\\delta_{BU}$; which\nrelate to particular ratios of confluent hypergeometric functions; we show\nthat, whenever $m \\leq \\sqrt{p}$ and $p \\geq 2$, $\\delta_{BU}$ dominates both\n$\\delta_{UB}$ and $\\delta_{\\hbox{mle}}$. The finding can be viewed as both a\nmultivariate extension of $p=1$ result due to Kubokawa (2005) and a unknown\nvariance extension of a similar dominance finding due to Marchand and Perron\n(2001). Various other dominance results are obtained, illustrations are\nprovided and commented upon. In particular, for $m \\leq \\sqrt{\\frac{p}{2}}$, a\nwide class of Bayes estimators, which include priors where $\\theta|\\sigma$ is\nuniformly distributed on the ball of radius $m$, are shown to dominate\n$\\delta_{UB}$.\n", "versions": [{"version": "v1", "created": "Thu, 26 Apr 2012 20:28:18 GMT"}], "update_date": "2012-04-30", "authors_parsed": [["Kortbi", "Othmane", ""], ["Marchand", "\u00c9ric", ""]]}, {"id": "1204.6160", "submitter": "Jos\\'e Enrique Chac\\'on", "authors": "Jos\\'e E. Chac\\'on and Tarn Duong", "title": "Data-driven density derivative estimation, with applications to\n  nonparametric clustering and bump hunting", "comments": "36 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Important information concerning a multivariate data set, such as clusters\nand modal regions, is contained in the derivatives of the probability density\nfunction. Despite this importance, nonparametric estimation of higher order\nderivatives of the density functions have received only relatively scant\nattention. Kernel estimators of density functions are widely used as they\nexhibit excellent theoretical and practical properties, though their\ngeneralization to density derivatives has progressed more slowly due to the\nmathematical intractabilities encountered in the crucial problem of bandwidth\n(or smoothing parameter) selection. This paper presents the first fully\nautomatic, data-based bandwidth selectors for multivariate kernel density\nderivative estimators. This is achieved by synthesizing recent advances in\nmatrix analytic theory which allow mathematically and computationally tractable\nrepresentations of higher order derivatives of multivariate vector valued\nfunctions. The theoretical asymptotic properties as well as the finite sample\nbehaviour of the proposed selectors are studied. {In addition, we explore in\ndetail the applications of the new data-driven methods for two other\nstatistical problems: clustering and bump hunting. The introduced techniques\nare combined with the mean shift algorithm to develop novel automatic,\nnonparametric clustering procedures which are shown to outperform mixture-model\ncluster analysis and other recent nonparametric approaches in practice.\nFurthermore, the advantage of the use of smoothing parameters designed for\ndensity derivative estimation for feature significance analysis for bump\nhunting is illustrated with a real data example.\n", "versions": [{"version": "v1", "created": "Fri, 27 Apr 2012 10:04:13 GMT"}, {"version": "v2", "created": "Mon, 21 May 2012 18:22:25 GMT"}, {"version": "v3", "created": "Tue, 19 Feb 2013 19:18:10 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Chac\u00f3n", "Jos\u00e9 E.", ""], ["Duong", "Tarn", ""]]}, {"id": "1204.6265", "submitter": "Kevin McGoff", "authors": "Kevin McGoff, Sayan Mukherjee, Natesh S. Pillai", "title": "Statistical inference for dynamical systems: a review", "comments": "Some minor typos corrected", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.DS stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The topic of statistical inference for dynamical systems has been studied\nextensively across several fields. In this survey we focus on the problem of\nparameter estimation for non-linear dynamical systems. Our objective is to\nplace results across distinct disciplines in a common setting and highlight\nopportunities for further research.\n", "versions": [{"version": "v1", "created": "Fri, 27 Apr 2012 16:44:40 GMT"}, {"version": "v2", "created": "Thu, 14 Jun 2012 13:47:07 GMT"}, {"version": "v3", "created": "Sat, 16 Jun 2012 10:15:29 GMT"}], "update_date": "2012-06-19", "authors_parsed": [["McGoff", "Kevin", ""], ["Mukherjee", "Sayan", ""], ["Pillai", "Natesh S.", ""]]}, {"id": "1204.6382", "submitter": "Herv\\'e Cardot", "authors": "Herv\\'e Cardot, Camelia Goga, Pauline Lardin", "title": "Uniform convergence and asymptotic confidence bands for model-assisted\n  estimators of the mean of sampled functional data", "comments": "To appear in the Electronic J. of Statistics", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When the study variable is functional and storage capacities are limited or\ntransmission costs are high, selecting with survey sampling techniques a small\nfraction of the observations is an interesting alternative to signal\ncompression techniques, particularly when the goal is the estimation of simple\nquantities such as means or totals. We extend, in this functional framework,\nmodel-assisted estimators with linear regression models that can take account\nof auxiliary variables whose totals over the population are known. We first\nshow, under weak hypotheses on the sampling design and the regularity of the\ntrajectories, that the estimator of the mean function as well as its variance\nestimator are uniformly consistent. Then, under additional assumptions, we\nprove a functional central limit theorem and we assess rigorously a fast\ntechnique based on simulations of Gaussian processes which is employed to build\nasymptotic confidence bands. The accuracy of the variance function estimator is\nevaluated on a real dataset of sampled electricity consumption curves measured\nevery half an hour over a period of one week.\n", "versions": [{"version": "v1", "created": "Sat, 28 Apr 2012 08:03:17 GMT"}, {"version": "v2", "created": "Mon, 19 Nov 2012 10:52:16 GMT"}, {"version": "v3", "created": "Thu, 14 Feb 2013 18:06:54 GMT"}], "update_date": "2013-02-15", "authors_parsed": [["Cardot", "Herv\u00e9", ""], ["Goga", "Camelia", ""], ["Lardin", "Pauline", ""]]}, {"id": "1204.6452", "submitter": "Qi Zhang", "authors": "Jiashun Jin, Cun-Hui Zhang, Qi Zhang", "title": "Optimality of Graphlet Screening in High Dimensional Variable Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Consider a linear regression model where the design matrix X has n rows and p\ncolumns. We assume (a) p is much large than n, (b) the coefficient vector beta\nis sparse in the sense that only a small fraction of its coordinates is\nnonzero, and (c) the Gram matrix G = X'X is sparse in the sense that each row\nhas relatively few large coordinates (diagonals of G are normalized to 1).\n  The sparsity in G naturally induces the sparsity of the so-called graph of\nstrong dependence (GOSD). We find an interesting interplay between the signal\nsparsity and the graph sparsity, which ensures that in a broad context, the set\nof true signals decompose into many different small-size components of GOSD,\nwhere different components are disconnected.\n  We propose Graphlet Screening (GS) as a new approach to variable selection,\nwhich is a two-stage Screen and Clean method. The key methodological innovation\nof GS is to use GOSD to guide both the screening and cleaning. Compared to\nm-variate brute-forth screening that has a computational cost of p^m, the GS\nonly has a computational cost of p (up to some multi-log(p) factors) in\nscreening.\n  We measure the performance of any variable selection procedure by the minimax\nHamming distance. We show that in a very broad class of situations, GS achieves\nthe optimal rate of convergence in terms of the Hamming distance. Somewhat\nsurprisingly, the well-known procedures subset selection and the lasso are rate\nnon-optimal, even in very simple settings and even when their tuning parameters\nare ideally set.\n", "versions": [{"version": "v1", "created": "Sun, 29 Apr 2012 03:57:18 GMT"}, {"version": "v2", "created": "Fri, 13 Jun 2014 08:23:49 GMT"}], "update_date": "2014-06-16", "authors_parsed": [["Jin", "Jiashun", ""], ["Zhang", "Cun-Hui", ""], ["Zhang", "Qi", ""]]}, {"id": "1204.6481", "submitter": "Pedro Alejandro Ortega", "authors": "Pedro A. Ortega and Daniel A. Braun", "title": "Thermodynamics as a theory of decision-making with information\n  processing costs", "comments": "26 pages, 5 figures, (under revision since February 2012)", "journal-ref": null, "doi": "10.1098/rspa.2012.0683", "report-no": null, "categories": "math.ST math.OC stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Perfectly rational decision-makers maximize expected utility, but crucially\nignore the resource costs incurred when determining optimal actions. Here we\npropose an information-theoretic formalization of bounded rational\ndecision-making where decision-makers trade off expected utility and\ninformation processing costs. Such bounded rational decision-makers can be\nthought of as thermodynamic machines that undergo physical state changes when\nthey compute. Their behavior is governed by a free energy functional that\ntrades off changes in internal energy-as a proxy for utility-and entropic\nchanges representing computational costs induced by changing states. As a\nresult, the bounded rational decision-making problem can be rephrased in terms\nof well-known concepts from statistical physics. In the limit when\ncomputational costs are ignored, the maximum expected utility principle is\nrecovered. We discuss the relation to satisficing decision-making procedures as\nwell as links to existing theoretical frameworks and human decision-making\nexperiments that describe deviations from expected utility theory. Since most\nof the mathematical machinery can be borrowed from statistical physics, the\nmain contribution is to axiomatically derive and interpret the thermodynamic\nfree energy as a model of bounded rational decision-making.\n", "versions": [{"version": "v1", "created": "Sun, 29 Apr 2012 14:13:26 GMT"}, {"version": "v2", "created": "Mon, 30 Jul 2012 23:04:25 GMT"}], "update_date": "2015-06-04", "authors_parsed": [["Ortega", "Pedro A.", ""], ["Braun", "Daniel A.", ""]]}, {"id": "1204.6491", "submitter": "Jian Huang", "authors": "Jian Huang, Patrick Breheny, Shuangge Ma", "title": "A Selective Review of Group Selection in High-Dimensional Models", "comments": "Published in at http://dx.doi.org/10.1214/12-STS392 the Statistical\n  Science (http://www.imstat.org/sts/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Statistical Science 2012, Vol. 27, No. 4, 481-499", "doi": "10.1214/12-STS392", "report-no": "IMS-STS-STS392", "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Grouping structures arise naturally in many statistical modeling problems.\nSeveral methods have been proposed for variable selection that respect grouping\nstructure in variables. Examples include the group LASSO and several concave\ngroup selection methods. In this article, we give a selective review of group\nselection concerning methodological developments, theoretical properties and\ncomputational algorithms. We pay particular attention to group selection\nmethods involving concave penalties. We address both group selection and\nbi-level selection methods. We describe several applications of these methods\nin nonparametric additive models, semiparametric regression, seemingly\nunrelated regressions, genomic data analysis and genome wide association\nstudies. We also highlight some issues that require further study.\n", "versions": [{"version": "v1", "created": "Sun, 29 Apr 2012 16:15:48 GMT"}, {"version": "v2", "created": "Fri, 4 Jan 2013 14:17:33 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["Huang", "Jian", ""], ["Breheny", "Patrick", ""], ["Ma", "Shuangge", ""]]}, {"id": "1204.6641", "submitter": "Alvaro Calvache", "authors": "\\'Alvaro Calvache, and Viswanathan Arunachalam", "title": "Theory of two-parameter Markov chain with an application in warranty\n  study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present the classical results of Kolmogorov's backward and\nforward equations to the case of a two-parameter Markov process. These\nequations relates the infinitesimal transition matrix of the two-parameter\nMarkov process. However, solving these equations is not possible and we require\na numerical procedure. In this paper, we give an alternative method by use of\ndouble Laplace transform of the transition probability matrix and of the\ninfinitesimal transition matrix of the process. An illustrative example is\npresented for the method proposed. In this example, we consider a two-parameter\nwarranty model, in which a system can be any of these states: working, failure.\nWe calculate the transition density matrix of these states and also the cost of\nthe warranty for the proposed model.\n", "versions": [{"version": "v1", "created": "Mon, 30 Apr 2012 14:08:47 GMT"}], "update_date": "2012-05-01", "authors_parsed": [["Calvache", "\u00c1lvaro", ""], ["Arunachalam", "Viswanathan", ""]]}, {"id": "1204.6650", "submitter": "Friedrich G\\\"otze", "authors": "S. G. Bobkov, G. P. Chistyakov and F. G\\\"otze", "title": "Fisher information and the central limit theorem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An Edgeworth-type expansion is established for the relative Fisher\ninformation distance to the class of normal distributions of sums of i.i.d.\nrandom variables, satisfying moment conditions. The validity of the central\nlimit theorem is studied via properties of the Fisher information along\nconvolutions.\n", "versions": [{"version": "v1", "created": "Mon, 30 Apr 2012 14:39:46 GMT"}], "update_date": "2012-05-01", "authors_parsed": [["Bobkov", "S. G.", ""], ["Chistyakov", "G. P.", ""], ["G\u00f6tze", "F.", ""]]}]