[{"id": "1801.00038", "submitter": "Shantanu Jain", "authors": "Shantanu Jain, Michael Levine, Predrag Radivojac, Michael W. Trosset", "title": "Identifiability of two-component skew normal mixtures with one known\n  component", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give sufficient identifiability conditions for estimating mixing\nproportions in two-component mixtures of skew normal distributions with one\nknown component. We consider the univariate case as well as two multivariate\nextensions: a multivariate skew normal distribution (MSN) by Azzalini and Dalla\nValle (1996) and the canonical fundamental skew normal distribution (CFUSN) by\nArellano-Valle and Genton (2005). The characteristic function of the CFUSN\ndistribution is additionally derived.\n", "versions": [{"version": "v1", "created": "Fri, 29 Dec 2017 21:05:06 GMT"}], "update_date": "2018-01-03", "authors_parsed": [["Jain", "Shantanu", ""], ["Levine", "Michael", ""], ["Radivojac", "Predrag", ""], ["Trosset", "Michael W.", ""]]}, {"id": "1801.00149", "submitter": "Tvrtko Tadi\\'c", "authors": "Krzysztof Burdzy, Bartosz Ko{\\l}odziejek, Tvrtko Tadi\\'c", "title": "Inverse Exponential Decay: Stochastic Fixed Point Equation and ARMA\n  Models", "comments": "32 pages, 1 figure. To appear in Bernoulli", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.DS math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study solutions to the stochastic fixed point equation\n$X\\stackrel{d}{=}AX+B$ when the coefficients are nonnegative and $B$ is an\n\"inverse exponential decay\" (IED) random variable. We provide theorems on the\nleft tail of $X$ which complement well-known tail results of Kesten and Goldie.\nWe generalize our results to ARMA processes with nonnegative coefficients whose\nnoise terms are from the IED class. We describe the lower envelope for these\nARMA processes.\n", "versions": [{"version": "v1", "created": "Sat, 30 Dec 2017 16:41:55 GMT"}, {"version": "v2", "created": "Mon, 19 Nov 2018 02:17:50 GMT"}, {"version": "v3", "created": "Mon, 21 Jan 2019 00:30:25 GMT"}, {"version": "v4", "created": "Sat, 2 Mar 2019 19:56:47 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Burdzy", "Krzysztof", ""], ["Ko\u0142odziejek", "Bartosz", ""], ["Tadi\u0107", "Tvrtko", ""]]}, {"id": "1801.00212", "submitter": "Rebecca Durst", "authors": "Rebecca F. Durst, Steven J. Miller", "title": "Benford's Law Beyond Independence: Tracking Benford Behavior in Copula\n  Models", "comments": null, "journal-ref": "Involve 12 (2019) 1193-1218", "doi": "10.2140/involve.2019.12.1193", "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Benford's law describes a common phenomenon among many naturally occurring\ndata sets and distributions in which the leading digits of the data are\ndistributed with the probability of a first digit of $d$ base $B$ being\n$\\log_{B}{\\frac{d+1}{d}}$. As it often successfully detects fraud in medical\ntrials, voting, science and finance, significant effort has been made to\nunderstand when and how distributions exhibit Benford behavior. Most of the\nprevious work has been restricted to cases of independent variables, and little\nis known about situations involving dependence. We use copulas to investigate\nthe Benford behavior of the product of $n$ dependent random variables. We\ndevelop a method for approximating the Benford behavior of a product of $n$\ndependent random variables modeled by a copula distribution $C$ and quantify\nand bound a copula distribution's distance from Benford behavior. We then\ninvestigate the Benford behavior of various copulas under varying dependence\nparameters and number of marginals. Our investigations show that the\nconvergence to Benford behavior seen with independent random variables as the\nnumber of variables in the product increases is not necessarily preserved when\nthe variables are dependent and modeled by a copula. Furthermore, there is\nstrong indication that the preservation of Benford behavior of the product of\ndependent random variables may be linked more to the structure of the copula\nthan to the Benford behavior of the marginal distributions.\n", "versions": [{"version": "v1", "created": "Sun, 31 Dec 2017 00:18:46 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Durst", "Rebecca F.", ""], ["Miller", "Steven J.", ""]]}, {"id": "1801.00279", "submitter": "Nakahiro Yoshida", "authors": "Nakahiro Yoshida", "title": "Partial quasi likelihood analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The quasi likelihood analysis is generalized to the partial quasi likelihood\nanalysis. Limit theorems for the quasi likelihood estimators, especially the\nquasi Bayesian estimator, are derived in the situation where existence of a\nslow mixing component prohibits the Rosenthal type inequality from applying to\nthe derivation of the polynomial type large deviation inequality for the\nstatistical random field. We give two illustrative examples.\n", "versions": [{"version": "v1", "created": "Sun, 31 Dec 2017 12:58:51 GMT"}], "update_date": "2018-01-03", "authors_parsed": [["Yoshida", "Nakahiro", ""]]}, {"id": "1801.00380", "submitter": "Xinwei Deng", "authors": "Xiaoning Kang and Xinwei Deng", "title": "On Variable Ordination of Modified Cholesky Decomposition for Sparse\n  Covariance Matrix Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimation of large sparse covariance matrices is of great importance for\nstatistical analysis, especially in the high-dimensional settings. The\ntraditional approach such as the sample covariance matrix performs poorly due\nto the high dimensionality. The modified Cholesky decomposition (MCD) is a\ncommonly used method for sparse covariance matrix estimation. However, the MCD\nmethod relies on the order of variables, which is often not available or cannot\nbe pre-determined in practice. In this work, we solve this order issue by\nobtaining a set of covariance matrix estimates under different orders of\nvariables used in the MCD. Then we consider an ensemble estimator as the\n\"center\" of such a set of covariance matrix estimates with respect to the\nFrobenius norm. The proposed method not only ensures the estimator to be\npositive definite, but also can capture the underlying sparse structure of the\ncovariance matrix. Under some weak regularity conditions, we establish both\nalgorithmic convergence and asymptotical convergence of the proposed method.\nThe merits of the proposed method are illustrated through simulation studies\nand one real data example.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jan 2018 01:33:54 GMT"}, {"version": "v2", "created": "Mon, 30 Mar 2020 03:26:50 GMT"}, {"version": "v3", "created": "Wed, 1 Apr 2020 01:03:26 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Kang", "Xiaoning", ""], ["Deng", "Xinwei", ""]]}, {"id": "1801.00513", "submitter": "Jeffrey Miller", "authors": "Jeffrey W. Miller", "title": "An elementary derivation of the Chinese restaurant process from\n  Sethuraman's stick-breaking process", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Chinese restaurant process (CRP) and the stick-breaking process are the\ntwo most commonly used representations of the Dirichlet process. However, the\nusual proof of the connection between them is indirect, relying on abstract\nproperties of the Dirichlet process that are difficult for nonexperts to\nverify. This short note provides a direct proof that the stick-breaking process\nleads to the CRP, without using any measure theory. We also discuss how the\nstick-breaking representation arises naturally from the CRP.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jan 2018 21:31:49 GMT"}, {"version": "v2", "created": "Wed, 3 Jan 2018 03:34:03 GMT"}, {"version": "v3", "created": "Mon, 15 Oct 2018 02:08:47 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Miller", "Jeffrey W.", ""]]}, {"id": "1801.00518", "submitter": "Yihong Wu", "authors": "T. Tony Cai and Yihong Wu", "title": "Statistical and Computational Limits for Sparse Matrix Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT math.IT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the fundamental limits for detecting a\nhigh-dimensional sparse matrix contaminated by white Gaussian noise from both\nthe statistical and computational perspectives. We consider $p\\times p$\nmatrices whose rows and columns are individually $k$-sparse. We provide a tight\ncharacterization of the statistical and computational limits for sparse matrix\ndetection, which precisely describe when achieving optimal detection is easy,\nhard, or impossible, respectively. Although the sparse matrices considered in\nthis paper have no apparent submatrix structure and the corresponding\nestimation problem has no computational issue at all, the detection problem has\na surprising computational barrier when the sparsity level $k$ exceeds the\ncubic root of the matrix size $p$: attaining the optimal detection boundary is\ncomputationally at least as hard as solving the planted clique problem.\n  The same statistical and computational limits also hold in the sparse\ncovariance matrix model, where each variable is correlated with at most $k$\nothers. A key step in the construction of the statistically optimal test is a\nstructural property for sparse matrices, which can be of independent interest.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jan 2018 21:53:55 GMT"}], "update_date": "2018-01-03", "authors_parsed": [["Cai", "T. Tony", ""], ["Wu", "Yihong", ""]]}, {"id": "1801.00523", "submitter": "Luke Prendergast", "authors": "Chandima N. P. G. Arachchige, Maxwell Cairns and Luke A. Prendergast", "title": "Interval estimators for ratios of independent quantiles and\n  interquantile ranges", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research has shown that interval estimators with good coverage\nproperties are achievable for some functions of quantiles, even when sample\nsizes are not large. Motivated by this, we consider interval estimators for the\nratios of independent quantiles and interquantile ranges that will be useful\nwhen comparing location and scale for two samples. Simulations show that the\nintervals have excellent coverage properties for a wide range of distributions,\nincluding those that are heavily skewed. Examples are also considered that\nhighlight the usefulness of using these approaches to compare location and\nscale.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jan 2018 22:40:07 GMT"}, {"version": "v2", "created": "Sun, 19 May 2019 23:06:35 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Arachchige", "Chandima N. P. G.", ""], ["Cairns", "Maxwell", ""], ["Prendergast", "Luke A.", ""]]}, {"id": "1801.00572", "submitter": "Abdelhakim Necir", "authors": "Brahim Brahimi, Djamel Meraghni, Abdelhakim Necir, Louiza Soltane", "title": "Tail empirical process and weighted extreme value index estimator for\n  randomly right-censored data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A tail empirical process for heavy-tailed and right-censored data is\nintroduced and its Gaussian approximation is established. In this context, a\n(weighted) new Hill-type estimator for positive extreme value index is proposed\nand its consistency and asymptotic normality are proved by means of the\naforementioned process in the framework of second-order conditions of regular\nvariation. In a comparative simulation study, the newly defined estimator is\nseen to perform better than the already existing ones in terms of both bias and\nmean squared error. As a real data example, we apply our estimation procedure\nto evaluate the tail index of the survival time of Australian male Aids\npatients. It is noteworthy that our approach may also serve to develop other\nstatistics related to the distribution tail such as second-order parameter and\nreduced-bias tail index estimators. Furthermore, the proposed tail empirical\nprocess provides a goodness-of-fit test for Pareto-like models under\ncensorship.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jan 2018 08:08:42 GMT"}, {"version": "v2", "created": "Fri, 12 Jan 2018 20:00:31 GMT"}, {"version": "v3", "created": "Tue, 16 Jan 2018 06:06:55 GMT"}, {"version": "v4", "created": "Sat, 3 Feb 2018 21:44:23 GMT"}], "update_date": "2018-02-06", "authors_parsed": [["Brahimi", "Brahim", ""], ["Meraghni", "Djamel", ""], ["Necir", "Abdelhakim", ""], ["Soltane", "Louiza", ""]]}, {"id": "1801.00591", "submitter": "Fabio Rapallo", "authors": "Roberto Fontana and Fabio Rapallo", "title": "Unions of Orthogonal Arrays and their aberrations via Hilbert bases", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We generate all the Orthogonal Arrays (OAs) of a given size n and strength t\nas the union of a collection of OAs which belong to an inclusion-minimal set of\nOAs. We derive a formula for computing the (Generalized) Word Length Pattern of\na union of OAs that makes use of their polynomial counting functions. In this\nway the best OAs according to the Generalized Minimum Aberration criterion can\nbe found by simply exploring a relatively small set of counting functions. The\nclasses of OAs with 5 binary factors, strength 2, and sizes 16 and 20 are fully\ndescribed.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jan 2018 09:59:27 GMT"}], "update_date": "2018-01-03", "authors_parsed": [["Fontana", "Roberto", ""], ["Rapallo", "Fabio", ""]]}, {"id": "1801.00753", "submitter": "Franz J. Kir\\'aly", "authors": "Frithjof Gressmann, Franz J. Kir\\'aly, Bilal Mateen and Harald\n  Oberhauser", "title": "Probabilistic supervised learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predictive modelling and supervised learning are central to modern data\nscience. With predictions from an ever-expanding number of supervised black-box\nstrategies - e.g., kernel methods, random forests, deep learning aka neural\nnetworks - being employed as a basis for decision making processes, it is\ncrucial to understand the statistical uncertainty associated with these\npredictions.\n  As a general means to approach the issue, we present an overarching framework\nfor black-box prediction strategies that not only predict the target but also\ntheir own predictions' uncertainty. Moreover, the framework allows for fair\nassessment and comparison of disparate prediction strategies. For this, we\nformally consider strategies capable of predicting full distributions from\nfeature variables, so-called probabilistic supervised learning strategies.\n  Our work draws from prior work including Bayesian statistics, information\ntheory, and modern supervised machine learning, and in a novel synthesis leads\nto (a) new theoretical insights such as a probabilistic bias-variance\ndecomposition and an entropic formulation of prediction, as well as to (b) new\nalgorithms and meta-algorithms, such as composite prediction strategies,\nprobabilistic boosting and bagging, and a probabilistic predictive independence\ntest.\n  Our black-box formulation also leads (c) to a new modular interface view on\nprobabilistic supervised learning and a modelling workflow API design, which we\nhave implemented in the newly released skpro machine learning toolbox,\nextending the familiar modelling interface and meta-modelling functionality of\nsklearn. The skpro package provides interfaces for construction, composition,\nand tuning of probabilistic supervised learning strategies, together with\norchestration features for validation and comparison of any such strategy - be\nit frequentist, Bayesian, or other.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jan 2018 18:08:49 GMT"}, {"version": "v2", "created": "Sat, 28 Apr 2018 21:22:42 GMT"}, {"version": "v3", "created": "Tue, 7 May 2019 14:30:27 GMT"}], "update_date": "2019-05-08", "authors_parsed": [["Gressmann", "Frithjof", ""], ["Kir\u00e1ly", "Franz J.", ""], ["Mateen", "Bilal", ""], ["Oberhauser", "Harald", ""]]}, {"id": "1801.00852", "submitter": "Fengqiao Luo Dr.", "authors": "Fengqiao Luo and Sanjay Mehrotra", "title": "A Concentration Result of Estimating Phi-Divergence using Data Dependent\n  Partition", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimation of the $\\phi$-divergence between two unknown probability\ndistributions using empirical data is a fundamental problem in information\ntheory and statistical learning. We consider a multi-variate generalization of\nthe data dependent partitioning method for estimating divergence between the\ntwo unknown distributions. Under the assumption that the distribution satisfies\na power law of decay, we provide a convergence rate result for this method on\nthe number of samples and hyper-rectangles required to ensure the estimation\nerror is bounded by a given level with a given probability.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jan 2018 22:51:08 GMT"}], "update_date": "2018-01-04", "authors_parsed": [["Luo", "Fengqiao", ""], ["Mehrotra", "Sanjay", ""]]}, {"id": "1801.00898", "submitter": "Lizhen Lin", "authors": "Rabi Bhattacharya and Lizhen Lin", "title": "Differential Geometry for Model Independent Analysis of Images and Other\n  Non-Euclidean Data: Recent Developments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article provides an exposition of recent methodologies for nonparametric\nanalysis of digital observations on images and other non-Euclidean objects.\nFr\\'echet means of distributions on metric spaces, such as manifolds and\nstratified spaces, have played an important role in this endeavor. Apart from\ntheoretical issues of uniqueness of the Fr\\'echet minimizer and the asymptotic\ndistribution of the sample Fr\\'echet mean under uniqueness, applications to\nimage analysis are highlighted. In addition, nonparametric Bayes theory is\nbrought to bear on the problems of density estimation and classification on\nmanifolds.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jan 2018 05:04:18 GMT"}], "update_date": "2018-01-04", "authors_parsed": [["Bhattacharya", "Rabi", ""], ["Lin", "Lizhen", ""]]}, {"id": "1801.00974", "submitter": "Gunnar Taraldsen", "authors": "Gunnar Taraldsen", "title": "Optimal Learning from the Doob-Dynkin lemma", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Doob-Dynkin Lemma gives conditions on two functions $X$ and $Y$ that\nensure existence of a function ${\\phi}$ so that $X = {\\phi} \\circ Y$. This\ncommunication proves different versions of the Doob-Dynkin Lemma, and shows how\nit is related to optimal statistical learning algorithms.\n  Keywords and phrases: Improper prior, Descriptive set theory, Conditional\nMonte Carlo, Fiducial, Machine learning, Complex data.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jan 2018 12:29:07 GMT"}], "update_date": "2018-01-04", "authors_parsed": [["Taraldsen", "Gunnar", ""]]}, {"id": "1801.00981", "submitter": "Veronique Maume-Deschamps", "authors": "Abul-Fattah Abu-Awwad (ICJ), V\\'eronique Maume-Deschamps (ICJ), Pierre\n  Ribereau (ICJ)", "title": "A Model-Free Selection Criterion For The Mixing Coefficient Of Spatial\n  Max-Mixture Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the main concerns in extreme value theory is to quantify the\ndependence between joint tails. Using stochastic processes that lack\nflexibility in the joint tail may lead to severe under-or over-estimation of\nprobabilities associated to simultaneous extreme events. Following recent\nadvances in the literature, a flexible model called max-mixture model has been\nintroduced for modeling situations where the extremal dependence structure may\nvary with the distance. In this paper we propose a nonparametric model-free\nselection criterion for the mixing coefficient Our criterion is derived from a\nmadogram, a notion classically used in geostatistics to capture spatial\nstructures. The procedure is based on a nonlinear least squares between the\ntheoretical madogram and the empirical one. We perform a simulation study and\napply our criterion to daily precipitation over the East of Australia.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jan 2018 12:55:47 GMT"}], "update_date": "2018-01-04", "authors_parsed": [["Abu-Awwad", "Abul-Fattah", "", "ICJ"], ["Maume-Deschamps", "V\u00e9ronique", "", "ICJ"], ["Ribereau", "Pierre", "", "ICJ"]]}, {"id": "1801.01007", "submitter": "Joseph Mur\\'e", "authors": "Joseph Mur\\'e", "title": "A Comprehensive Bayesian Treatment of the Universal Kriging model with\n  Mat\\'ern correlation kernels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Gibbs reference posterior distribution provides an objective\nfull-Bayesian solution to the problem of prediction of a stationary Gaussian\nprocess with Mat\\'ern anisotropic kernel. A full-Bayesian approach is possible,\nbecause the posterior distribution is expressed as the invariant distribution\nof a uniformly ergodic Markovian kernel for which we give an explicit\nexpression. In this paper, we show that it is appropriate for the Universal\nKriging framework, that is when an unknown function is added to the stationary\nGaussian process. We give sufficient conditions for the existence and propriety\nof the Gibbs reference posterior that apply to a wide variety of practical\ncases and illustrate the method with several examples. Finally, simulations of\nGaussian processes suggest that the Gibbs reference posterior has good\nfrequentist properties in terms of coverage of prediction intervals.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jan 2018 14:09:48 GMT"}, {"version": "v2", "created": "Mon, 8 Jan 2018 15:28:48 GMT"}, {"version": "v3", "created": "Thu, 11 Jan 2018 17:31:21 GMT"}, {"version": "v4", "created": "Mon, 15 Jan 2018 11:00:31 GMT"}], "update_date": "2018-01-16", "authors_parsed": [["Mur\u00e9", "Joseph", ""]]}, {"id": "1801.01170", "submitter": "Junjie Ma", "authors": "Junjie Ma and Ji Xu and Arian Maleki", "title": "Optimization-based AMP for Phase Retrieval: The Impact of Initialization\n  and $\\ell_2$-regularization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider an $\\ell_2$-regularized non-convex optimization problem for\nrecovering signals from their noisy phaseless observations. We design and study\nthe performance of a message passing algorithm that aims to solve this\noptimization problem. We consider the asymptotic setting $m,n \\rightarrow\n\\infty$, $m/n \\rightarrow \\delta$ and obtain sharp performance bounds, where\n$m$ is the number of measurements and $n$ is the signal dimension. We show that\nfor complex signals the algorithm can perform accurate recovery with only $m=\n\\left(\\frac{64}{\\pi^2}-4\\right)n \\approx 2.5n$ measurements. Also, we provide\nsharp analysis on the sensitivity of the algorithm to noise. We highlight the\nfollowing facts about our message passing algorithm: (i) Adding $\\ell_2$\nregularization to the non-convex loss function can be beneficial. (ii) Spectral\ninitialization has marginal impact on the performance of the algorithm. The\nsharp analyses in this paper, not only enable us to compare the performance of\nour method with other phase recovery schemes, but also shed light on designing\nbetter iterative algorithms for other non-convex optimization problems.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jan 2018 21:02:25 GMT"}, {"version": "v2", "created": "Sat, 24 Feb 2018 20:01:00 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Ma", "Junjie", ""], ["Xu", "Ji", ""], ["Maleki", "Arian", ""]]}, {"id": "1801.01394", "submitter": "Johannes Lederer", "authors": "Jacob Bien, Irina Gaynanova, Johannes Lederer, Christian M\\\"uller", "title": "Prediction Error Bounds for Linear Regression With the TREX", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The TREX is a recently introduced approach to sparse linear regression. In\ncontrast to most well-known approaches to penalized regression, the TREX can be\nformulated without the use of tuning parameters. In this paper, we establish\nthe first known prediction error bounds for the TREX. Additionally, we\nintroduce extensions of the TREX to a more general class of penalties, and we\nprovide a bound on the prediction error in this generalized setting. These\nresults deepen the understanding of TREX from a theoretical perspective and\nprovide new insights into penalized regression in general.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jan 2018 15:16:13 GMT"}], "update_date": "2018-01-08", "authors_parsed": [["Bien", "Jacob", ""], ["Gaynanova", "Irina", ""], ["Lederer", "Johannes", ""], ["M\u00fcller", "Christian", ""]]}, {"id": "1801.01593", "submitter": "Ahmed El Alaoui", "authors": "Ahmed El Alaoui, Florent Krzakala", "title": "Estimation in the spiked Wigner model: A short proof of the replica\n  formula", "comments": "11 pages. Appears in proc. of the IEEE International Symposium on\n  Information Theory (ISIT) 2018", "journal-ref": "2018 IEEE International Symposium on Information Theory (ISIT),\n  Vail, CO, 2018, pp. 1874-1878", "doi": "10.1109/ISIT.2018.8437810", "report-no": null, "categories": "cs.IT math.IT math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of estimating a rank-one perturbation of a Wigner\nmatrix in a setting of low signal-to-noise ratio. This serves as a simple model\nfor principal component analysis in high dimensions. The mutual information per\nvariable between the spike and the observed matrix, or equivalently, the\nnormalized Kullback-Leibler divergence between the planted and null models are\nknown to converge to the so-called {\\em replica-symmetric} formula, the\nproperties of which determine the fundamental limits of estimation in this\nmodel. We provide in this note a short and transparent proof of this formula,\nbased on simple executions of Gaussian interpolations and standard\nconcentration-of-measure arguments. The \\emph{Franz-Parisi potential}, that is,\nthe free entropy at a fixed overlap, plays an important role in our proof.\nFurthermore, our proof can be generalized straightforwardly to spiked tensor\nmodels of even order.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jan 2018 00:47:37 GMT"}, {"version": "v2", "created": "Thu, 14 Jun 2018 18:14:31 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Alaoui", "Ahmed El", ""], ["Krzakala", "Florent", ""]]}, {"id": "1801.01696", "submitter": "Ismael Castillo", "authors": "Isma\\\"el Castillo and Romain Mismer", "title": "Empirical Bayes analysis of spike and slab posterior distributions", "comments": "37 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the sparse normal means model, convergence of the Bayesian posterior\ndistribution associated to spike and slab prior distributions is considered.\nThe key sparsity hyperparameter is calibrated via marginal maximum likelihood\nempirical Bayes. The plug-in posterior squared-$L^2$ norm is shown to converge\nat the minimax rate for the euclidean norm for appropriate choices of spike and\nslab distributions. Possible choices include standard spike and slab with heavy\ntailed slab, and the spike and slab LASSO of Rockov\\'a and George with heavy\ntailed slab. Surprisingly, the popular Laplace slab is shown to lead to a\nsuboptimal rate for the full empirical Bayes posterior. This provides a\nstriking example where convergence of aspects of the empirical Bayes posterior\ndoes not entail convergence of the full empirical Bayes posterior itself.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jan 2018 10:34:31 GMT"}, {"version": "v2", "created": "Tue, 16 Oct 2018 12:54:34 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Castillo", "Isma\u00ebl", ""], ["Mismer", "Romain", ""]]}, {"id": "1801.01797", "submitter": "Johan Segers", "authors": "Fran\\c{c}ois Portier and Johan Segers", "title": "Monte Carlo integration with a growing number of control variates", "comments": "22 pages. Numerical experiments in earlier version", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well known that Monte Carlo integration with variance reduction by\nmeans of control variates can be implemented by the ordinary least squares\nestimator for the intercept in a multiple linear regression model. A central\nlimit theorem is established for the integration error if the number of control\nvariates tends to infinity. The integration error is scaled by the standard\ndeviation of the error term in the regression model. If the linear span of the\ncontrol variates is dense in a function space that contains the integrand, the\nintegration error tends to zero at a rate which is faster than the square root\nof the number of Monte Carlo replicates. Depending on the situation, increasing\nthe number of control variates may or may not be computationally more efficient\nthan increasing the Monte Carlo sample size.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jan 2018 15:47:21 GMT"}, {"version": "v2", "created": "Mon, 26 Feb 2018 20:15:27 GMT"}, {"version": "v3", "created": "Fri, 23 Mar 2018 13:55:19 GMT"}, {"version": "v4", "created": "Wed, 9 Oct 2019 08:41:47 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Portier", "Fran\u00e7ois", ""], ["Segers", "Johan", ""]]}, {"id": "1801.01990", "submitter": "Yoav Zemel", "authors": "Valentina Masarotto and Victor M. Panaretos and Yoav Zemel", "title": "Procrustes Metrics on Covariance Operators and Optimal Transportation of\n  Gaussian Processes", "comments": "30 pages", "journal-ref": "Invited paper, Special Issue on Manifold Statistics, Sankhya A\n  81(1):172-213, 2019", "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Covariance operators are fundamental in functional data analysis, providing\nthe canonical means to analyse functional variation via the celebrated\nKarhunen--Lo\\`eve expansion. These operators may themselves be subject to\nvariation, for instance in contexts where multiple functional populations are\nto be compared. Statistical techniques to analyse such variation are intimately\nlinked with the choice of metric on covariance operators, and the intrinsic\ninfinite-dimensionality of these operators. In this paper, we describe the\nmanifold geometry of the space of trace-class infinite-dimensional covariance\noperators and associated key statistical properties, under the recently\nproposed infinite-dimensional version of the Procrustes metric. We identify\nthis space with that of centred Gaussian processes equipped with the\nWasserstein metric of optimal transportation. The identification allows us to\nprovide a complete description of those aspects of this manifold geometry that\nare important in terms of statistical inference, and establish key properties\nof the Fr\\'echet mean of a random sample of covariances, as well as generative\nmodels that are canonical for such metrics and link with the problem of\nregistration of functional data.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jan 2018 08:43:25 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Masarotto", "Valentina", ""], ["Panaretos", "Victor M.", ""], ["Zemel", "Yoav", ""]]}, {"id": "1801.02050", "submitter": "Alexander Bulinski", "authors": "Alexander Bulinski, Denis Dimitrov", "title": "Statistical estimation of the Shannon entropy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The behavior of the Kozachenko - Leonenko estimates for the (differential)\nShannon entropy is studied when the number of i.i.d. vector-valued observations\ntends to infinity. The asymptotic unbiasedness and L^2-consistency of the\nestimates are established. The conditions employed involve the analogues of the\nHardy - Littlewood maximal function. It is shown that the results are valid in\nparticular for the entropy estimation of any nondegenerate Gaussian vector.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jan 2018 16:57:54 GMT"}], "update_date": "2018-01-09", "authors_parsed": [["Bulinski", "Alexander", ""], ["Dimitrov", "Denis", ""]]}, {"id": "1801.02090", "submitter": "Kate\\v{r}ina Helisov\\'a", "authors": "Vesna Gotovac, Kate\\v{r}ina Helisov\\'a", "title": "Testing equality in distribution of random convex compact sets via\n  theory of N-distances and its application to assessing similarity of general\n  random sets", "comments": "24 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper concerns a method of testing equality of distribution of random\nconvex compact sets and the way how to use the test to distinguish between two\nrealisations of general random sets. The family of metrics on the space of\ndistributions of random convex compact sets is constructed using the theory of\nN-distances and characteristic functions of random convex compact sets.\nFurther, the approximation of the metrics through its finite dimensional\ncounterparts is proposed, which lead to a new statistical test for testing\nequality in distribution of two random convex compact sets. Then, it is\ndescribed how to approximate a realisation of a general random set by a union\nof convex compact sets, and it is shown how to determine whether two\nrealisations of general random sets come from the same process using the\nconstructed test. The procedure is justified by an extensive simulation study.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jan 2018 21:04:59 GMT"}], "update_date": "2018-01-09", "authors_parsed": [["Gotovac", "Vesna", ""], ["Helisov\u00e1", "Kate\u0159ina", ""]]}, {"id": "1801.02321", "submitter": "Daniel Schmidt Dr", "authors": "Daniel F. Schmidt and Enes Makalic", "title": "Log-Scale Shrinkage Priors and Adaptive Bayesian Global-Local Shrinkage\n  Estimation", "comments": "34 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Global-local shrinkage hierarchies are an important innovation in Bayesian\nestimation. We propose the use of log-scale distributions as a novel basis for\ngenerating familes of prior distributions for local shrinkage hyperparameters.\nBy varying the scale parameter one may vary the degree to which the prior\ndistribution promotes sparsity in the coefficient estimates. By examining the\nclass of distributions over the logarithm of the local shrinkage parameter that\nhave log-linear, or sub-log-linear tails, we show that many standard prior\ndistributions for local shrinkage parameters can be unified in terms of the\ntail behaviour and concentration properties of their corresponding marginal\ndistributions over the coefficients $\\beta_j$. We derive upper bounds on the\nrate of concentration around $|\\beta_j|=0$, and the tail decay as $|\\beta_j|\n\\to \\infty$, achievable by this wide class of prior distributions.\n  We then propose a new type of ultra-heavy tailed prior, called the log-$t$\nprior with the property that, irrespective of the choice of associated scale\nparameter, the marginal distribution always diverges at $\\beta_j = 0$, and\nalways possesses super-Cauchy tails. We develop results demonstrating when\nprior distributions with (sub)-log-linear tails attain Kullback--Leibler\nsuper-efficiency and prove that the log-$t$ prior distribution is always\nsuper-efficient. We show that the log-$t$ prior is less sensitive to\nmisspecification of the global shrinkage parameter than the horseshoe or lasso\npriors. By incorporating the scale parameter of the log-scale prior\ndistributions into the Bayesian hierarchy we derive novel adaptive shrinkage\nprocedures. Simulations show that the adaptive log-$t$ procedure appears to\nalways perform well, irrespective of the level of sparsity or signal-to-noise\nratio of the underlying model.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jan 2018 06:44:37 GMT"}, {"version": "v2", "created": "Thu, 30 Jan 2020 12:55:08 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Schmidt", "Daniel F.", ""], ["Makalic", "Enes", ""]]}, {"id": "1801.02364", "submitter": "Yusufu Simayi", "authors": "Yusufu Simayi", "title": "Weak convergence of the sequential empirical copula processes under\n  long-range dependence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider multivariate copula-based stationary time-series under Gaussian\nsubordination. Observed time series are subordinated to long-range dependent\nGaussian processes and characterized by arbitrary marginal copula\ndistributions. First of all, we establish limit theorems for the marginal and\nquantile marginal empirical processes of multivariate stationary long-range\ndependent sequences under Gaussian subordination. Furthermore, we establish the\nasymptotic behavior of sequential empirical copula processes under\nnon-restrictive smoothness assumptions. The limiting processes in the case of\nlong-memory sequences are quite different from the cases of of i.i.d. and\nweakly dependent observations.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jan 2018 10:11:55 GMT"}, {"version": "v2", "created": "Wed, 10 Jan 2018 21:07:10 GMT"}, {"version": "v3", "created": "Thu, 15 Mar 2018 10:50:17 GMT"}], "update_date": "2018-03-16", "authors_parsed": [["Simayi", "Yusufu", ""]]}, {"id": "1801.02373", "submitter": "Daniele Agostini", "authors": "Daniele Agostini, Carlos Am\\'endola", "title": "Discrete Gaussian distributions via theta functions", "comments": "23 pages. Final version. To appear in SIAGA. v2: changed notation and\n  added references", "journal-ref": null, "doi": "10.1137/18M1164937", "report-no": null, "categories": "math.AG math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a discrete analogue of the classical multivariate Gaussian\ndistribution. It is supported on the integer lattice and is parametrized by the\nRiemann theta function. Over the reals, the discrete Gaussian is characterized\nby the property of maximizing entropy, just as its continuous counterpart. We\ncapitalize on the theta function representation to derive statistical\nproperties. Throughout, we exhibit strong connections to the study of abelian\nvarieties in algebraic geometry.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jan 2018 10:45:11 GMT"}, {"version": "v2", "created": "Wed, 28 Nov 2018 14:10:40 GMT"}], "update_date": "2019-04-19", "authors_parsed": [["Agostini", "Daniele", ""], ["Am\u00e9ndola", "Carlos", ""]]}, {"id": "1801.02504", "submitter": "Marc Ditzhaus", "authors": "Marc Ditzhaus and Arnold Janssen", "title": "On the consistency of adaptive multiple tests", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much effort has been done to control the \"false discovery rate\" (FDR) when\n$m$ hypotheses are tested simultaneously. The FDR is the expectation of the\n\"false discovery proportion\" $\\text{FDP}=V/R$ given by the ratio of the number\nof false rejections $V$ and all rejections $R$. In this paper, we have a closer\nlook at the FDP for adaptive linear step-up multiple tests. These tests extend\nthe well known Benjamini and Hochberg test by estimating the unknown amount\n$m_0$ of the true null hypotheses. We give exact finite sample formulas for\nhigher moments of the FDP and, in particular, for its variance. Using these\nallows us a precise discussion about the consistency of adaptive step-up tests.\nWe present sufficient and necessary conditions for consistency on the\nestimators $\\widehat m_0$ and the underlying probability regime. We apply our\nresults to convex combinations of generalized Storey type estimators with\nvarious tuning parameters and (possibly) data-driven weights. The corresponding\nstep-up tests allow a flexible adaptation. Moreover, these tests control the\nFDR at finite sample size. We compare these tests to the classical Benjamini\nand Hochberg test and discuss the advantages of it.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jan 2018 15:30:32 GMT"}], "update_date": "2018-01-09", "authors_parsed": [["Ditzhaus", "Marc", ""], ["Janssen", "Arnold", ""]]}, {"id": "1801.02515", "submitter": "Jean-Marc Bardet", "authors": "Jean-Marc Bardet (SAMM), Abdellatif Guenaizi", "title": "Data-driven semi-parametric detection of multiple changes in long-range\n  dependent processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is devoted to the offline multiple changes detection for\nlong-range dependence processes. The observations are supposed to satisfy a\nsemi-parametric long-range dependence assumption with distinct memory\nparameters on each stage. A penalized local Whittle contrast is considered for\nestimating all the parameters, notably the number of changes. The consistency\nas well as convergence rates are obtained. Monte-Carlo experiments exhibit the\naccuracy of the estimators. They also show that the estimation of the number of\nbreaks is improved by using a data-driven slope heuristic procedure of choice\nof the penalization parameter.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jan 2018 15:42:51 GMT"}, {"version": "v2", "created": "Sat, 29 Dec 2018 17:40:56 GMT"}], "update_date": "2019-01-01", "authors_parsed": [["Bardet", "Jean-Marc", "", "SAMM"], ["Guenaizi", "Abdellatif", ""]]}, {"id": "1801.02539", "submitter": "Lixue Pang", "authors": "Geurt Jongbloed, Frank van der Meulen and Lixue Pang", "title": "Bayesian estimation of a decreasing density", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Suppose $X_1,\\dots, X_n$ is a random sample from a bounded and decreasing\ndensity $f_0$ on $[0,\\infty)$. We are interested in estimating such $f_0$, with\nspecial interest in $f_0(0)$. This problem is encountered in various\nstatistical applications and has gained quite some attention in the statistical\nliterature. It is well known that the maximum likelihood estimator is\ninconsistent at zero. This has led several authors to propose alternative\nestimators which are consistent. As any decreasing density can be represented\nas a scale mixture of uniform densities, a Bayesian estimator is obtained by\nendowing the mixture distribution with the Dirichlet process prior. Assuming\nthis prior, we derive contraction rates of the posterior density at zero by\ncarefully revising arguments presented in Salomond (2014). Various methods for\nestimating the density are compared using a simulation study. We apply the\nBayesian procedure to the current durations data described in Keiding et\nal.(2012).\n", "versions": [{"version": "v1", "created": "Mon, 8 Jan 2018 16:28:06 GMT"}, {"version": "v2", "created": "Wed, 25 Jul 2018 12:57:59 GMT"}, {"version": "v3", "created": "Fri, 10 Aug 2018 10:04:30 GMT"}, {"version": "v4", "created": "Fri, 22 Mar 2019 14:12:19 GMT"}, {"version": "v5", "created": "Mon, 2 Sep 2019 10:16:32 GMT"}, {"version": "v6", "created": "Fri, 11 Sep 2020 10:22:06 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Jongbloed", "Geurt", ""], ["van der Meulen", "Frank", ""], ["Pang", "Lixue", ""]]}, {"id": "1801.02962", "submitter": "Sean van der Merwe", "authors": "Sean van der Merwe and Daan de Waal", "title": "Bayesian Fitting of Dirichlet Type I and II Distributions", "comments": "15 pages, 4 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In his 1986 book, Aitchison explains that compositional data is regularly\nmishandled in statistical analyses, a pattern that continues to this day. The\nDirichlet Type I distribution is a multivariate distribution commonly used to\nmodel a set of proportions that sum to one. Aitchinson goes on to lament the\ndifficulties of Dirichlet modelling and the scarcity of alternatives. While he\naddresses the second of these issues, we address the first. The Dirichlet Type\nII distribution is a transformation of the Dirichlet Type I distribution and is\na multivariate distribution on the positive real numbers with only one more\nparameter than the number of dimensions. This property of Dirichlet\ndistributions implies advantages over common alternatives as the number of\ndimensions increase. While not all data is amenable to Dirichlet modelling,\nthere are many cases where the Dirichlet family is the obvious choice. We\ndescribe the Dirichlet distributions and show how to fit them using both\nfrequentist and Bayesian methods (we derive and apply two objective priors).\nThe Beta distribution is discussed as a special case. We report a small\nsimulation study to compare the fitting methods. We derive the conditional\ndistributions and posterior predictive conditional distributions. The\nflexibility of this distribution family is illustrated via examples, the last\nof which discusses imputation (using the posterior predictive conditional\ndistributions).\n", "versions": [{"version": "v1", "created": "Tue, 9 Jan 2018 14:45:45 GMT"}, {"version": "v2", "created": "Thu, 5 Apr 2018 07:52:03 GMT"}], "update_date": "2018-04-06", "authors_parsed": [["van der Merwe", "Sean", ""], ["de Waal", "Daan", ""]]}, {"id": "1801.02986", "submitter": "Gleb Oshanin", "authors": "Diego Krapf, Enzo Marinari, Ralf Metzler, Gleb Oshanin, Xinran Xu,\n  Alessio Squarcini", "title": "Power spectral density of a single Brownian trajectory: What one can and\n  cannot learn from it", "comments": "24 pages, 13 figures", "journal-ref": "New J Phys 20, 023029 (2018)", "doi": "10.1088/1367-2630/aaa67c", "report-no": null, "categories": "cond-mat.stat-mech math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The power spectral density (PSD) of any time-dependent stochastic processes\n$X_t$ is a meaningful feature of its spectral content. In its text-book\ndefinition, the PSD is the Fourier transform of the covariance function of\n$X_t$ over an infinitely large observation time $T$, that is, it is defined as\nan ensemble-averaged property taken in the limit $T \\to \\infty$. A legitimate\nquestion is what information on the PSD can be reliably obtained from\nsingle-trajectory experiments, if one goes beyond the standard definition and\nanalyzes the PSD of a \\textit{single} trajectory recorded for a \\textit{finite}\nobservation time $T$. In quest for this answer, for a $d$-dimensional Brownian\nmotion we calculate the probability density function of a single-trajectory PSD\nfor arbitrary frequency $f$, finite observation time $T$ and arbitrary number\n$k$ of projections of the trajectory on different axes. We show analytically\nthat the scaling exponent for the frequency-dependence of the PSD specific to\nan ensemble of Brownian motion trajectories can be already obtained from a\nsingle trajectory, while the numerical amplitude in the relation between the\nensemble-averaged and single-trajectory PSDs is a fluctuating property which\nvaries from realization to realization. The distribution of this amplitude is\ncalculated exactly and is discussed in detail. Our results are confirmed by\nnumerical simulations and single particle tracking experiments, with remarkably\ngood agreement. In addition we consider a truncated Wiener representation of\nBrownian motion, and the case of a discrete-time lattice random walk. We\nhighlight some differences in the behavior of a single-trajectory PSD for\nBrownian motion and for the two latter situations. The framework developed\nherein will allow for meaningful physical analysis of experimental stochastic\ntrajectories.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jan 2018 15:07:10 GMT"}], "update_date": "2018-06-12", "authors_parsed": [["Krapf", "Diego", ""], ["Marinari", "Enzo", ""], ["Metzler", "Ralf", ""], ["Oshanin", "Gleb", ""], ["Xu", "Xinran", ""], ["Squarcini", "Alessio", ""]]}, {"id": "1801.03122", "submitter": "Jeffrey Miller", "authors": "Jeffrey W. Miller", "title": "A detailed treatment of Doob's theorem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Doob's theorem provides guarantees of consistent estimation and posterior\nconsistency under very general conditions. Despite the limitation that it only\nguarantees consistency on a set with prior probability 1, for many models\narising in practice, Doob's theorem is an easy way of showing that consistency\nwill hold almost everywhere. In this article, we give a detailed proof of\nDoob's theorem.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jan 2018 19:58:41 GMT"}], "update_date": "2018-01-11", "authors_parsed": [["Miller", "Jeffrey W.", ""]]}, {"id": "1801.03185", "submitter": "Debashis Ghosh", "authors": "Debashis Ghosh, Efr\\'en Cruz-Cort\\'es", "title": "A Gaussian process framework for overlap and causal effect estimation\n  with high-dimensional covariates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  A powerful tool for the analysis of nonrandomized observational studies has\nbeen the potential outcomes model. Utilization of this framework allows\nanalysts to estimate average treatment effects. This article considers the\nsituation in which high-dimensional covariates are present and revisits the\nstandard assumptions made in causal inference. We show that by employing a\nflexible Gaussian process framework, the assumption of strict overlap leads to\nvery restrictive assumptions about the distribution of covariates, results for\nwhich can be characterized using classical results from Gaussian random\nmeasures as well as reproducing kernel Hilbert space theory. In addition, we\npropose a strategy for data-adaptive causal effect estimation that does not\nrely on the strict overlap assumption. These findings reveal the stringency\nthat accompanies the use of the treatment positivity assumption in\nhigh-dimensional settings.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jan 2018 23:31:01 GMT"}, {"version": "v2", "created": "Wed, 5 Sep 2018 04:14:44 GMT"}, {"version": "v3", "created": "Thu, 30 May 2019 04:12:43 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Ghosh", "Debashis", ""], ["Cruz-Cort\u00e9s", "Efr\u00e9n", ""]]}, {"id": "1801.03300", "submitter": "Nazih Benoumechiara", "authors": "Nazih Benoumechiara (LPSM UMR 8001, EDF R\\&D), Kevin Elie-Dit-Cosaque\n  (ICJ)", "title": "Shapley effects for sensitivity analysis with dependent inputs:\n  bootstrap and kriging-based algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In global sensitivity analysis, the well known Sobol' sensitivity indices aim\nto quantify how the variance in the output of a mathematical model can be\napportioned to the different variances of its input random variables. These\nindices are based on the functional variance decomposition and their\ninterpretation become difficult in the presence of statistical dependence\nbetween the inputs. However, as there is dependence in many application\nstudies, that enhances the development of interpretable sensitivity indices.\nRecently, the Shapley values developed in the field of cooperative games theory\nhave been connected to global sensitivity analysis and present good properties\nin the presence of dependencies. Nevertheless, the available estimation methods\ndon't always provide confidence intervals and require a large number of model\nevaluation. In this paper, we implement a bootstrap sampling in the existing\nalgorithms to estimate confidence intervals of the indice estimations. We also\nproposed to consider a metamodel in substitution of a costly numerical model.\nThe estimation error from the Monte-Carlo sampling is combined with the\nmetamodel error in order to have confidence intervals on the Shapley effects.\nBesides, we compare for different examples with dependent random variables the\nresults of the Shapley effects with existing extensions of the Sobol' indices.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jan 2018 10:47:36 GMT"}], "update_date": "2018-01-11", "authors_parsed": [["Benoumechiara", "Nazih", "", "LPSM UMR 8001, EDF R\\&D"], ["Elie-Dit-Cosaque", "Kevin", "", "ICJ"]]}, {"id": "1801.03345", "submitter": "Clement Marteau", "authors": "S\\'ebastien Gadat (TSE), S\\'ebastien Gerchinovitz (IMT), Cl\\'ement\n  Marteau (ICJ)", "title": "Optimal functional supervised classification with separation condition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the binary supervised classification problem with the Gaussian\nfunctional model introduced in [7]. Taking advantage of the Gaussian structure,\nwe design a natural plug-in classifier and derive a family of upper bounds on\nits worst-case excess risk over Sobolev spaces. These bounds are parametrized\nby a separation distance quantifying the difficulty of the problem, and are\nproved to be optimal (up to logarithmic factors) through matching minimax lower\nbounds. Using the recent works of [9] and [14] we also derive a logarithmic\nlower bound showing that the popular k-nearest neighbors classifier is far from\noptimality in this specific functional setting.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jan 2018 12:32:19 GMT"}], "update_date": "2018-01-11", "authors_parsed": [["Gadat", "S\u00e9bastien", "", "TSE"], ["Gerchinovitz", "S\u00e9bastien", "", "IMT"], ["Marteau", "Cl\u00e9ment", "", "ICJ"]]}, {"id": "1801.03592", "submitter": "Ruanui Nicholson", "authors": "Ruanui Nicholson and Noemi Petra and Jari Kaipio", "title": "Estimation of the Robin coefficient field in a Poisson problem with\n  uncertain conductivity field", "comments": null, "journal-ref": null, "doi": "10.1088/1361-6420/aad91e", "report-no": null, "categories": "math.OC math.NA math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the reconstruction of a heterogeneous coefficient field in a\nRobin boundary condition on an inaccessible part of the boundary in a Poisson\nproblem with an uncertain (or unknown) inhomogeneous conductivity field in the\ninterior of the domain. To account for model errors that stem from the\nuncertainty in the conductivity coefficient, we treat the unknown conductivity\nas a nuisance parameter and carry out approximative premarginalization over it,\nand invert for the Robin coefficient field only. We approximate the related\nmodelling errors via the Bayesian approximation error (BAE) approach. The\nuncertainty analysis presented here relies on a local linearization of the\nparameter-to-observable map at the maximum a posteriori (MAP) estimates, which\nleads to a normal (Gaussian) approximation of the parameter posterior density.\nTo compute the MAP point we apply an inexact Newton conjugate gradient approach\nbased on the adjoint methodology. The construction of the covariance is made\ntractable by invoking a low-rank approximation of the data misfit component of\nthe Hessian. Two numerical experiments are considered: one where the prior\ncovariance on the conductivity is isotropic, and one where the prior covariance\non the conductivity is anisotropic. Results are compared to those based on\nstandard error models, with particular emphasis on the feasibility of the\nposterior uncertainty estimates. We show that the BAE approach is a feasible\none in the sense that the predicted posterior uncertainty is consistent with\nthe actual estimation errors, while neglecting the related modelling error\nyields infeasible estimates for the Robin coefficient. In addition, we\ndemonstrate that the BAE approach is approximately as computationally expensive\n(measured in the number of PDE solves) as the conventional error approach.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jan 2018 00:05:37 GMT"}], "update_date": "2018-09-26", "authors_parsed": [["Nicholson", "Ruanui", ""], ["Petra", "Noemi", ""], ["Kaipio", "Jari", ""]]}, {"id": "1801.03705", "submitter": "Atsushi Suzuki", "authors": "Atsushi Suzuki and Kenji Yamanishi", "title": "Exact Calculation of Normalized Maximum Likelihood Code Length Using\n  Fourier Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The normalized maximum likelihood code length has been widely used in model\nselection, and its favorable properties, such as its consistency and the upper\nbound of its statistical risk, have been demonstrated. This paper proposes a\nnovel methodology for calculating the normalized maximum likelihood code length\non the basis of Fourier analysis. Our methodology provides an efficient\nnon-asymptotic calculation formula for exponential family models and an\nasymptotic calculation formula for general parametric models with a weaker\nassumption compared to that in previous work.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jan 2018 10:57:04 GMT"}], "update_date": "2018-01-12", "authors_parsed": [["Suzuki", "Atsushi", ""], ["Yamanishi", "Kenji", ""]]}, {"id": "1801.03742", "submitter": "Clement Levrard", "authors": "Cl\\'ement Levrard (1) ((1) LPSM UMR 8001)", "title": "Quantization/clustering: when and why does k-means work?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Though mostly used as a clustering algorithm, k-means are originally designed\nas a quantization algorithm. Namely, it aims at providing a compression of a\nprobability distribution with k points. Building upon [21, 33], we try to\ninvestigate how and when these two approaches are compatible. Namely, we show\nthat provided the sample distribution satisfies a margin like condition (in the\nsense of [27] for supervised learning), both the associated empirical risk\nminimizer and the output of Lloyd's algorithm provide almost optimal\nclassification in certain cases (in the sense of [6]). Besides, we also show\nthat they achieved fast and optimal convergence rates in terms of sample size\nand compression risk.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jan 2018 13:15:41 GMT"}, {"version": "v2", "created": "Tue, 30 Jan 2018 08:20:09 GMT"}], "update_date": "2018-01-31", "authors_parsed": [["Levrard", "Cl\u00e9ment", "", "LPSM UMR 8001"]]}, {"id": "1801.03744", "submitter": "Boris Hanin", "authors": "Boris Hanin", "title": "Which Neural Net Architectures Give Rise To Exploding and Vanishing\n  Gradients?", "comments": "v3. 18p. 1 fig. Accepted at NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a rigorous analysis of the statistical behavior of gradients in a\nrandomly initialized fully connected network N with ReLU activations. Our\nresults show that the empirical variance of the squares of the entries in the\ninput-output Jacobian of N is exponential in a simple architecture-dependent\nconstant beta, given by the sum of the reciprocals of the hidden layer widths.\nWhen beta is large, the gradients computed by N at initialization vary wildly.\nOur approach complements the mean field theory analysis of random networks.\nFrom this point of view, we rigorously compute finite width corrections to the\nstatistics of gradients at the edge of chaos.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jan 2018 13:17:22 GMT"}, {"version": "v2", "created": "Wed, 6 Jun 2018 13:25:08 GMT"}, {"version": "v3", "created": "Sat, 27 Oct 2018 01:02:57 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Hanin", "Boris", ""]]}, {"id": "1801.04003", "submitter": "Abbas Mehrabian", "authors": "Hassan Ashtiani and Abbas Mehrabian", "title": "Some techniques in density estimation", "comments": "18 pages; new version includes tight results on mixtures of general\n  Gaussians", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Density estimation is an interdisciplinary topic at the intersection of\nstatistics, theoretical computer science and machine learning. We review some\nold and new techniques for bounding the sample complexity of estimating\ndensities of continuous distributions, focusing on the class of mixtures of\nGaussians and its subclasses. In particular, we review the main techniques used\nto prove the new sample complexity bounds for mixtures of Gaussians by\nAshtiani, Ben-David, Harvey, Liaw, Mehrabian, and Plan arXiv:1710.05209.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jan 2018 21:51:18 GMT"}, {"version": "v2", "created": "Thu, 22 Feb 2018 05:44:21 GMT"}], "update_date": "2018-02-23", "authors_parsed": [["Ashtiani", "Hassan", ""], ["Mehrabian", "Abbas", ""]]}, {"id": "1801.04005", "submitter": "Martin Zhang", "authors": "Martin J. Zhang, Meisam Razaviyayn, David Tse", "title": "Minimax Optimality of Sign Test for Paired Heterogeneous Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Comparing two groups under different conditions is ubiquitous in the\nbiomedical sciences. In many cases, samples from the two groups can be\nnaturally paired; for example a pair of samples may come from the same\nindividual under the two conditions. However samples across different\nindividuals may be highly heterogeneous. Traditional methods often ignore such\nheterogeneity by assuming the samples are identically distributed. In this\nwork, we study the problem of comparing paired heterogeneous data by modeling\nthe data as Gaussian distributed with different parameters across the samples.\nWe show that in the minimax setting where we want to maximize the worst-case\npower, the sign test, which only uses the signs of the differences between the\npaired sample, is optimal in the one-sided case and near optimal in the\ntwo-sided case. The superiority of the sign test over other popular tests for\npaired heterogeneous data is demonstrated using both synthetic data and a\nreal-world RNA-Seq dataset.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jan 2018 22:21:26 GMT"}], "update_date": "2018-01-15", "authors_parsed": [["Zhang", "Martin J.", ""], ["Razaviyayn", "Meisam", ""], ["Tse", "David", ""]]}, {"id": "1801.04050", "submitter": "Anit Kumar Sahu", "authors": "Anit Kumar Sahu, Dusan Jakovetic and Soummya Kar", "title": "Communication Optimality Trade-offs For Distributed Estimation", "comments": "37 pages. Submitted for journal publication. Initial Submission: Jan.\n  2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes $\\mathbf{C}$ommunication efficient $\\mathbf{RE}$cursive\n$\\mathbf{D}$istributed estimati$\\mathbf{O}$n algorithm, $\\mathcal{CREDO}$, for\nnetworked multi-worker setups without a central master node. $\\mathcal{CREDO}$\nis designed for scenarios in which the worker nodes aim to collaboratively\nestimate a vector parameter of interest using distributed online time-series\ndata at the individual worker nodes. The individual worker nodes iteratively\nupdate their estimate of the parameter by assimilating latest locally sensed\ninformation and estimates from neighboring worker nodes exchanged over a\n(possibly sparse) time-varying communication graph. The underlying inter-worker\ncommunication protocol is adaptive, making communications increasingly\n(probabilistically) sparse as time progresses. Under minimal conditions on the\ninter-worker information exchange network and the sensing models, almost sure\nconvergence of the estimate sequences at the worker nodes to the true parameter\nis established. Further, the paper characterizes the performance of\n$\\mathcal{CREDO}$ in terms of asymptotic covariance of the estimate sequences\nand specifically establishes the achievability of optimal asymptotic\ncovariance. The analysis reveals an interesting interplay between the\nalgorithm's communication cost~$\\mathcal{C}_{t}$ (over $t$ time-steps) and the\nasymptotic covariance. Most notably, it is shown that $\\mathcal{CREDO}$ may be\ndesigned to achieve a $\\Theta\\left(\\mathcal{C}_{t}^{-2+\\zeta}\\right)$ decay of\nthe mean square error~($\\zeta>0$, arbitrarily small) at each worker node, which\nsignificantly improves over the existing $\n\\Theta\\left(\\mathcal{C}_{t}^{-1}\\right)$ rates. Simulation examples on both\nsynthetic and real data sets demonstrate $\\mathcal{CREDO}$'s communication\nefficiency.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jan 2018 03:51:29 GMT"}], "update_date": "2018-01-15", "authors_parsed": [["Sahu", "Anit Kumar", ""], ["Jakovetic", "Dusan", ""], ["Kar", "Soummya", ""]]}, {"id": "1801.04063", "submitter": "Shanyun Liu", "authors": "Shanyun Liu, Rui She and Pingyi Fan", "title": "How Many Samples Required in Big Data Collection: A Differential Message\n  Importance Measure", "comments": "5 pages, 3figures, conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information collection is a fundamental problem in big data, where the size\nof sampling sets plays a very important role. This work considers the\ninformation collection process by taking message importance into account.\nSimilar to differential entropy, we define differential message importance\nmeasure (DMIM) as a measure of message importance for continuous random\nvariable. It is proved that the change of DMIM can describe the gap between the\ndistribution of a set of sample values and a theoretical distribution. In fact,\nthe deviation of DMIM is equivalent to Kolmogorov-Smirnov statistic, but it\noffers a new way to characterize the distribution goodness-of-fit. Numerical\nresults show some basic properties of DMIM and the accuracy of the proposed\napproximate values. Furthermore, it is also obtained that the empirical\ndistribution approaches the real distribution with decreasing of the DMIM\ndeviation, which contributes to the selection of suitable sampling points in\nactual system.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jan 2018 05:57:11 GMT"}], "update_date": "2018-01-15", "authors_parsed": [["Liu", "Shanyun", ""], ["She", "Rui", ""], ["Fan", "Pingyi", ""]]}, {"id": "1801.04064", "submitter": "Rui She", "authors": "Rui She, Shanyun Liu, and Pingyi Fan", "title": "State Variation Mining: On Information Divergence with Message\n  Importance in Big Data", "comments": "6 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information transfer which reveals the state variation of variables usually\nplays a vital role in big data analytics and processing. In fact, the measures\nfor information transfer could reflect the system change by use of the variable\ndistributions, similar to KL divergence and Renyi divergence. Furthermore, in\nterms of the information transfer in big data, small probability events usually\ndominate the importance of the total message to some degree. Therefore, it is\nsignificant to design an information transfer measure based on the message\nimportance which emphasizes the small probability events. In this paper, we\npropose a message importance transfer measure (MITM) and investigate its\ncharacteristics and applications on three aspects. First, the message\nimportance transfer capacity based on MITM is presented to offer an upper bound\nfor the information transfer process with disturbance. Then, we extend the MITM\nto the continuous case and discuss the robustness by using it to measuring\ninformation distance. Finally, we utilize the MITM to guide the queue length\nselection in the caching operation of mobile edge computing.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jan 2018 05:57:29 GMT"}, {"version": "v2", "created": "Mon, 15 Jan 2018 09:23:15 GMT"}, {"version": "v3", "created": "Sun, 11 Nov 2018 04:47:05 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["She", "Rui", ""], ["Liu", "Shanyun", ""], ["Fan", "Pingyi", ""]]}, {"id": "1801.04095", "submitter": "Baptiste Broto", "authors": "Baptiste Broto (CEA), Fran\\c{c}ois Bachoc (IMT), Marine Depecker\n  (LTCI), Jean-Marc Martinez (DM2S)", "title": "Sensitivity indices for independent groups of variables", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study sensitivity indices for independent groups of\nvariables and we look at the particular case of block-additive models. We show\nin this case that most of the Sobol indices are equal to zero and that Shapley\neffects can be estimated more efficiently. We then apply this study to Gaussian\nlinear models, and we provide an efficient algorithm to compute the theoretical\nsensitivity indices. In numerical experiments, we show that this algorithm\ncompares favourably to other existing methods. We also use the theoretical\nresults to improve the estimation of the Shapley effects for general models,\nwhen the inputs form independent groups of variables.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jan 2018 09:14:18 GMT"}, {"version": "v2", "created": "Tue, 11 Dec 2018 09:54:31 GMT"}], "update_date": "2018-12-12", "authors_parsed": [["Broto", "Baptiste", "", "CEA"], ["Bachoc", "Fran\u00e7ois", "", "IMT"], ["Depecker", "Marine", "", "LTCI"], ["Martinez", "Jean-Marc", "", "DM2S"]]}, {"id": "1801.04212", "submitter": "Mor Absa Loum", "authors": "Mor Absa Loum (LM-Orsay), Marie-Anne Poursat (LM-Orsay), Abdourahmane\n  Sow, Amadou Sall, Cheikh Loucoubar (G4-IPD), Elisabeth Gassiat (LM-Orsay)", "title": "Multinomial logistic model for coinfection diagnosis between arbovirus\n  and malaria in Kedougou", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In tropical regions, populations continue to suffer morbidity and mortality\nfrom malaria and arboviral diseases. In Kedougou (Senegal), these illnesses are\nall endemic due to the climate and its geographical position. The\nco-circulation of malaria parasites and arboviruses can explain the observation\nof coinfected cases. Indeed there is strong resemblance in symptoms between\nthese diseases making problematic targeted medical care of coinfected cases.\nThis is due to the fact that the origin of illness is not obviously known. Some\ncases could be immunized against one or the other of the pathogens, immunity\ntypically acquired with factors like age and exposure as usual for endemic\narea. Then, coinfection needs to be better diagnosed. Using data collected from\npatients in Kedougou region, from 2009 to 2013, we adjusted a multinomial\nlogistic model and selected relevant variables in explaining coinfection\nstatus. We observed specific sets of variables explaining each of the diseases\nexclusively and the coinfection. We tested the independence between arboviral\nand malaria infections and derived coinfection probabilities from the model\nfitting. In case of a coinfection probability greater than a threshold value to\nbe calibrated on the data, duration of illness above 3 days and age above 10\nyears-old are mostly indicative of arboviral disease while body temperature\nhigher than 40{\\textdegree}C and presence of nausea or vomiting symptoms during\nthe rainy season are mostly indicative of malaria disease.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jan 2018 16:05:56 GMT"}, {"version": "v2", "created": "Tue, 27 Aug 2019 14:47:17 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Loum", "Mor Absa", "", "LM-Orsay"], ["Poursat", "Marie-Anne", "", "LM-Orsay"], ["Sow", "Abdourahmane", "", "G4-IPD"], ["Sall", "Amadou", "", "G4-IPD"], ["Loucoubar", "Cheikh", "", "G4-IPD"], ["Gassiat", "Elisabeth", "", "LM-Orsay"]]}, {"id": "1801.04262", "submitter": "Anne van Delft Dr.", "authors": "Anne van Delft and Michael Eichler", "title": "A note on Herglotz's theorem for time series on function spaces", "comments": null, "journal-ref": "Stochastic Processes and their Applications, Volume 130(6), 2020,\n  Pages 3687-3710", "doi": "10.1016/j.spa.2019.10.006", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we prove Herglotz's theorem for Hilbert-valued time series.\nThis requires the notion of an operator-valued measure, which we shall make\nprecise for our setting. Herglotz's theorem for functional time series allows\nto generalize existing results that are central to frequency domain analysis on\nthe function space. In particular, we use this result to prove the existence of\na functional Cram{\\'e}r representation of a large class of processes, including\nthose with jumps in the spectral distribution and long-memory processes. We\nfurthermore obtain an optimal finite dimensional reduction of the time series\nunder weaker assumptions than available in the literature. The results of this\npaper therefore enable Fourier analysis for processes of which the spectral\ndensity operator does not necessarily exist.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jan 2018 18:34:24 GMT"}, {"version": "v2", "created": "Wed, 26 Dec 2018 18:52:07 GMT"}, {"version": "v3", "created": "Fri, 26 Jul 2019 13:11:08 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["van Delft", "Anne", ""], ["Eichler", "Michael", ""]]}, {"id": "1801.04339", "submitter": "Jason Klusowski M", "authors": "Jason M. Klusowski and Yihong Wu", "title": "Estimating the Number of Connected Components in a Graph via Subgraph\n  Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.DM cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning properties of large graphs from samples has been an important\nproblem in statistical network analysis since the early work of Goodman\n\\cite{Goodman1949} and Frank \\cite{Frank1978}. We revisit a problem formulated\nby Frank \\cite{Frank1978} of estimating the number of connected components in a\nlarge graph based on the subgraph sampling model, in which we randomly sample a\nsubset of the vertices and observe the induced subgraph. The key question is\nwhether accurate estimation is achievable in the \\emph{sublinear} regime where\nonly a vanishing fraction of the vertices are sampled. We show that it is\nimpossible if the parent graph is allowed to contain high-degree vertices or\nlong induced cycles. For the class of chordal graphs, where induced cycles of\nlength four or above are forbidden, we characterize the optimal sample\ncomplexity within constant factors and construct linear-time estimators that\nprovably achieve these bounds. This significantly expands the scope of previous\nresults which have focused on unbiased estimators and special classes of graphs\nsuch as forests or cliques.\n  Both the construction and the analysis of the proposed methodology rely on\ncombinatorial properties of chordal graphs and identities of induced subgraph\ncounts. They, in turn, also play a key role in proving minimax lower bounds\nbased on construction of random instances of graphs with matching structures of\nsmall subgraphs.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jan 2018 22:13:48 GMT"}, {"version": "v2", "created": "Wed, 8 Aug 2018 21:28:29 GMT"}, {"version": "v3", "created": "Sat, 15 Jun 2019 21:13:30 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Klusowski", "Jason M.", ""], ["Wu", "Yihong", ""]]}, {"id": "1801.04369", "submitter": "Oliver Maclaren", "authors": "Oliver J. Maclaren", "title": "Is profile likelihood a true likelihood? An argument in favor", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Profile likelihood is the key tool for dealing with nuisance parameters in\nlikelihood theory. It is often asserted, however, that profile likelihood is\nnot a 'true' likelihood. One implication is that likelihood theory lacks the\ngenerality of e.g. Bayesian inference, wherein marginalization is the universal\ntool for dealing with nuisance parameters. Here we argue that profile\nlikelihood has as much claim to being a true likelihood as a marginal\nprobability has to being a true probability distribution. The crucial point we\nargue is that a likelihood function is naturally interpreted as a maxitive\npossibility measure: given this, the associated theory of integration with\nrespect to maxitive measures delivers profile likelihood as the direct analogue\nof marginal probability in additive measure theory. Thus, given a background\nlikelihood function, we argue that profiling over the likelihood function is as\nnatural (or as unnatural, as the case may be) as marginalizing over a\nbackground probability measure. The connections to Bayesian inference can also\nbe further clarified with the introduction of a suitable logarithmic distance\nfunction, in which case the present theory can be naturally described as\n'Tropical Bayes' in the sense of tropical algebra.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jan 2018 03:05:29 GMT"}, {"version": "v2", "created": "Tue, 24 Apr 2018 01:07:32 GMT"}, {"version": "v3", "created": "Fri, 15 Jun 2018 00:28:48 GMT"}, {"version": "v4", "created": "Thu, 5 Jul 2018 05:51:56 GMT"}], "update_date": "2018-07-06", "authors_parsed": [["Maclaren", "Oliver J.", ""]]}, {"id": "1801.04489", "submitter": "Tim Brown", "authors": "Tim W. C. Brown, Patrick C. F. Eggers", "title": "A Stochastic Singular Vector Based MIMO Channel Model for MAC Layer\n  Tracking", "comments": "ArXiv Submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel stochastic technique is presented to directly model singular vectors\nand singular values of a multiple input multiple output channel. Thus the\ncomponent smodeled directly in the eigen domain can be adapted to exhibit\nrealistic physical domain behavior when assembled. The model exploites natural\npaths of eigenmodes, such that a simple Doppler filter generator process can be\nused. Furthermore it is possible to directly manipulate the singular vector\ndynamics in a way that an unrealistic \"stress channel\" can be modeled in the\neigen domain. This is particularly useful for testing the eigenmode channel\ntracking ability internal to a communication device such as a modem, where\nimpairments in tracking will cause interference between eigenmodes. The model\ncan also facilitate mode tracking testing as it directly produces tracked\nungtangled eigenmodes, providing the narrowest possible singular vector Doppler\nspectra and consequently lowest required update rates of each eigenmode. The\nsingular vector based model targets testing of the eigen domain functionality\nof MIMO modems/devices, an apparatus focus, without the need for including the\ndecomposition stages.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jan 2018 21:51:57 GMT"}], "update_date": "2018-01-16", "authors_parsed": [["Brown", "Tim W. C.", ""], ["Eggers", "Patrick C. F.", ""]]}, {"id": "1801.04848", "submitter": "Alessandro De Gregorio", "authors": "Alessandro De Gregorio, Stefano M. Iacus", "title": "Empirical $L^2$-distance test statistics for ergodic diffusions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of this paper is to introduce a new type of test statistic for simple\nnull hypothesis on one-dimensional ergodic diffusion processes sampled at\ndiscrete times. We deal with a quasi-likelihood approach for stochastic\ndifferential equations (i.e. local gaussian approximation of the transition\nfunctions) and define a test statistic by means of the empirical $L^2$-distance\nbetween quasi-likelihoods. We prove that the introduced test statistic is\nasymptotically distribution free; namely it weakly converges to a $\\chi^2$\nrandom variable. Furthermore, we study the power under local alternatives of\nthe parametric test. We show by the Monte Carlo analysis that, in the small\nsample case, the introduced test seems to perform better than other tests\nproposed in literature.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jan 2018 15:28:22 GMT"}], "update_date": "2018-01-16", "authors_parsed": [["De Gregorio", "Alessandro", ""], ["Iacus", "Stefano M.", ""]]}, {"id": "1801.05048", "submitter": "Antonio Lijoi", "authors": "Federico Camerlenghi and David B. Dunson and Antonio Lijoi and Igor\n  Pr\\\"unster and Abel Rodr\\'iguez", "title": "Latent nested nonparametric priors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discrete random structures are important tools in Bayesian nonparametrics and\nthe resulting models have proven effective in density estimation, clustering,\ntopic modeling and prediction, among others. In this paper, we consider nested\nprocesses and study the dependence structures they induce. Dependence ranges\nbetween homogeneity, corresponding to full exchangeability, and maximum\nheterogeneity, corresponding to (unconditional) independence across samples.\nThe popular nested Dirichlet process is shown to degenerate to the fully\nexchangeable case when there are ties across samples at the observed or latent\nlevel. To overcome this drawback, inherent to nesting general discrete random\nmeasures, we introduce a novel class of latent nested processes. These are\nobtained by adding common and group-specific completely random measures and,\nthen, normalising to yield dependent random probability measures. We provide\nresults on the partition distributions induced by latent nested processes, and\ndevelop an Markov Chain Monte Carlo sampler for Bayesian inferences. A test for\ndistributional homogeneity across groups is obtained as a by product. The\nresults and their inferential implications are showcased on synthetic and real\ndata.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jan 2018 22:12:52 GMT"}], "update_date": "2018-01-17", "authors_parsed": [["Camerlenghi", "Federico", ""], ["Dunson", "David B.", ""], ["Lijoi", "Antonio", ""], ["Pr\u00fcnster", "Igor", ""], ["Rodr\u00edguez", "Abel", ""]]}, {"id": "1801.05242", "submitter": "Jon Cockayne", "authors": "Jon Cockayne and Chris Oates and Ilse Ipsen and Mark Girolami", "title": "A Bayesian Conjugate Gradient Method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.NA math.NA math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fundamental task in numerical computation is the solution of large linear\nsystems. The conjugate gradient method is an iterative method which offers\nrapid convergence to the solution, particularly when an effective\npreconditioner is employed. However, for more challenging systems a substantial\nerror can be present even after many iterations have been performed. The\nestimates obtained in this case are of little value unless further information\ncan be provided about the numerical error. In this paper we propose a novel\nstatistical model for this numerical error set in a Bayesian framework. Our\napproach is a strict generalisation of the conjugate gradient method, which is\nrecovered as the posterior mean for a particular choice of prior. The estimates\nobtained are analysed with Krylov subspace methods and a contraction result for\nthe posterior is presented. The method is then analysed in a simulation study\nas well as being applied to a challenging problem in medical imaging.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jan 2018 13:18:11 GMT"}, {"version": "v2", "created": "Thu, 18 Jan 2018 13:35:28 GMT"}, {"version": "v3", "created": "Mon, 17 Dec 2018 10:15:36 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Cockayne", "Jon", ""], ["Oates", "Chris", ""], ["Ipsen", "Ilse", ""], ["Girolami", "Mark", ""]]}, {"id": "1801.05362", "submitter": "Kazuto Fukuchi", "authors": "Kazuto Fukuchi, Jun Sakuma", "title": "Minimax Optimal Additive Functional Estimation with Discrete\n  Distribution: Slow Divergence Speed Case", "comments": "35 pages. arXiv admin note: text overlap with arXiv:1701.06381", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses an estimation problem of an additive functional of\n$\\phi$, which is defined as $\\theta(P;\\phi)=\\sum_{i=1}^k\\phi(p_i)$, given $n$\ni.i.d. random samples drawn from a discrete distribution $P=(p_1,...,p_k)$ with\nalphabet size $k$. We have revealed in the previous paper that the minimax\noptimal rate of this problem is characterized by the divergence speed of the\nfourth derivative of $\\phi$ in a range of fast divergence speed. In this paper,\nwe prove this fact for a more general range of the divergence speed. As a\nresult, we show the minimax optimal rate of the additive functional estimation\nfor each range of the parameter $\\alpha$ of the divergence speed. For $\\alpha\n\\in (1,3/2)$, we show that the minimax rate is $\\frac{1}{n}+\\frac{k^2}{(n\\ln\nn)^{2\\alpha}}$. Besides, we show that the minimax rate is $\\frac{1}{n}$ for\n$\\alpha \\in [3/2,2]$.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jan 2018 10:49:53 GMT"}], "update_date": "2018-01-17", "authors_parsed": [["Fukuchi", "Kazuto", ""], ["Sakuma", "Jun", ""]]}, {"id": "1801.05465", "submitter": "Roberto Vila Gabriel", "authors": "Roberto Vila, Jeremias Le\\~ao, Helton Saulo, Mirza Nabeed and Manoel\n  Santos-Neto", "title": "On a bimodal Birnbaum-Saunders distribution with applications to\n  lifetime data", "comments": "31 pages, 5 figures", "journal-ref": null, "doi": "10.1214/19-BJPS448", "report-no": null, "categories": "math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Birnbaum-Saunders distribution is a flexible and useful model which has\nbeen used in several fields. In this paper, a new bimodal version of this\ndistribution based on the alpha-skew-normal distribution is established. We\ndiscuss some of its mathematical and inferential properties. We consider\nlikelihood-based methods to estimate the model parameters. We carry out a Monte\nCarlo simulation study to evaluate the performance of the maximum likelihood\nestimators. For illustrative purposes, three real data sets are analyzed. The\nresults indicated that the proposed model outperformed some existing models in\nthe literature, in special, a recent bimodal extension of the Birnbaum-Saunders\ndistribution.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jan 2018 19:57:59 GMT"}, {"version": "v2", "created": "Sun, 28 Apr 2019 19:55:10 GMT"}], "update_date": "2020-07-27", "authors_parsed": [["Vila", "Roberto", ""], ["Le\u00e3o", "Jeremias", ""], ["Saulo", "Helton", ""], ["Nabeed", "Mirza", ""], ["Santos-Neto", "Manoel", ""]]}, {"id": "1801.05466", "submitter": "Panayiotis Constantinou", "authors": "Panayiotis Constantinou, Piotr Kokoszka, Matthew Reimherr", "title": "Testing Separability of Functional Time Series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive and study a significance test for determining if a panel of\nfunctional time series is separable. In the context of this paper, separability\nmeans that the covariance structure factors into the product of two functions,\none depending only on time and the other depending only on the coordinates of\nthe panel. Separability is a property which can dramatically improve\ncomputational efficiency by substantially reducing model complexity. It is\nespecially useful for functional data as it implies that the functional\nprincipal components are the same for each member of the panel. However such an\nassumption must be verified before proceeding with further inference. Our\napproach is based on functional norm differences and provides a test with well\ncontrolled size and high power. We establish our procedure quite generally,\nallowing one to test separability of autocovariances as well. In addition to an\nasymptotic justification, our methodology is validated by a simulation study.\nIt is applied to functional panels of particulate pollution and stock market\ndata.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jan 2018 19:58:09 GMT"}], "update_date": "2018-01-18", "authors_parsed": [["Constantinou", "Panayiotis", ""], ["Kokoszka", "Piotr", ""], ["Reimherr", "Matthew", ""]]}, {"id": "1801.05565", "submitter": "Stanislav Minsker", "authors": "Stanislav Minsker and Xiaohan Wei", "title": "Robust Modifications of U-statistics and Applications to Covariance\n  Estimation Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $Y$ be a $d$-dimensional random vector with unknown mean $\\mu$ and\ncovariance matrix $\\Sigma$. This paper is motivated by the problem of designing\nan estimator of $\\Sigma$ that admits tight deviation bounds in the operator\nnorm under minimal assumptions on the underlying distribution, such as\nexistence of only 4th moments of the coordinates of $Y$. To address this\nproblem, we propose robust modifications of the operator-valued U-statistics,\nobtain non-asymptotic guarantees for their performance, and demonstrate the\nimplications of these results to the covariance estimation problem under\nvarious structural assumptions.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jan 2018 06:08:35 GMT"}, {"version": "v2", "created": "Thu, 18 Jan 2018 22:33:10 GMT"}, {"version": "v3", "created": "Thu, 8 Mar 2018 08:41:21 GMT"}], "update_date": "2018-03-09", "authors_parsed": [["Minsker", "Stanislav", ""], ["Wei", "Xiaohan", ""]]}, {"id": "1801.06069", "submitter": "Johan Steen", "authors": "Johan Steen, Stijn Vansteelandt", "title": "Graphical models for mediation analysis", "comments": null, "journal-ref": null, "doi": "10.1201/9780429463976-17", "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mediation analysis seeks to infer how much of the effect of an exposure on an\noutcome can be attributed to specific pathways via intermediate variables or\nmediators. This requires identification of so-called path-specific effects.\nThese express how a change in exposure affects those intermediate variables\n(along certain pathways), and how the resulting changes in those variables in\nturn affect the outcome (along subsequent pathways). However, unlike\nidentification of total effects, adjustment for confounding is insufficient for\nidentification of path-specific effects because their magnitude is also\ndetermined by the extent to which individuals who experience large exposure\neffects on the mediator, tend to experience relatively small or large mediator\neffects on the outcome. This chapter therefore provides an accessible review of\nidentification strategies under general nonparametric structural equation\nmodels (with possibly unmeasured variables), which rule out certain such\ndependencies. In particular, it is shown which path-specific effects can be\nidentified under such models, and how this can be done.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jan 2018 14:52:56 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Steen", "Johan", ""], ["Vansteelandt", "Stijn", ""]]}, {"id": "1801.06319", "submitter": "Lingtao Kong", "authors": "Kong Lingtao, Zhang Yanli, Dai Hongshuai", "title": "Single index regression models with randomly left-truncated data", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, based on the kernel estimator proposed by Ould-Said and\nLemdani (Ann. Instit. Statist. Math. 2006), we develop some new generalized\nM-estimator procedures for single index regression models with left-truncated\nresponses. The consistency and asymptotic normality of our estimators are also\nestablished. Some simulation studies are given to investigate the finite sample\nperformance of the proposed estimators.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jan 2018 06:56:13 GMT"}], "update_date": "2018-01-22", "authors_parsed": [["Lingtao", "Kong", ""], ["Yanli", "Zhang", ""], ["Hongshuai", "Dai", ""]]}, {"id": "1801.06423", "submitter": "Rafa\\\"el Pinot", "authors": "Rafael Pinot", "title": "Minimum spanning tree release under differential privacy constraints", "comments": "Thesis of Master Degree of Statistics, Universit\\'e Paris 6 Pierre et\n  Marie Curie", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the problem of nodes clustering under privacy constraints when\nrepresenting a dataset as a graph. Our contribution is threefold. First we\nformally define the concept of differential privacy for structured databases\nsuch as graphs, and give an alternative definition based on a new neighborhood\nnotion between graphs. This definition is adapted to particular frameworks that\ncan be met in various application fields such as genomics, world wide web,\npopulation survey, etc. Second, we introduce a new algorithm to tackle the\nissue of privately releasing an approximated minimum spanning tree topology for\na simple-undirected-weighted graph. It provides a simple way of producing the\ntopology of a private almost minimum spanning tree which outperforms, in most\ncases, the state of the art \"Laplace mechanism\" in terms of\nweight-approximation error.\n  Finally, we propose a theoretically motivated method combining a sanitizing\nmechanism (such as Laplace or our new algorithm) with a Minimum Spanning Tree\n(MST)-based clustering algorithm. It provides an accurate method for nodes\nclustering in a graph while keeping the sensitive information contained in the\nedges weights of the private graph. We provide some theoretical results on the\nrobustness of an almost minimum spanning tree construction for Laplace\nsanitizing mechanisms. These results exhibit which conditions the graph weights\nshould respect in order to consider that the nodes form well separated clusters\nboth for Laplace and our algorithm as sanitizing mechanism. The method has been\nexperimentally evaluated on simulated data, and preliminary results show the\ngood behavior of the algorithm while identifying well separated clusters.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jan 2018 14:45:06 GMT"}], "update_date": "2018-01-22", "authors_parsed": [["Pinot", "Rafael", ""]]}, {"id": "1801.06570", "submitter": "Promit Ghosal Mr.", "authors": "Promit Ghosal and Sumit Mukherjee", "title": "Joint estimation of parameters in Ising model", "comments": "30 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study joint estimation of the inverse temperature and magnetization\nparameters $(\\beta,B)$ of an Ising model with a non-negative coupling matrix\n$A_n$ of size $n\\times n$, given one sample from the Ising model. We give a\ngeneral bound on the rate of consistency of the bi-variate pseudolikelihood\nestimator. Using this, we show that estimation at rate $n^{-1/2}$ is always\npossible if $A_n$ is the adjacency matrix of a bounded degree graph. If $A_n$\nis the scaled adjacency matrix of a graph whose average degree goes to\n$+\\infty$, the situation is a bit more delicate. In this case estimation at\nrate $n^{-1/2}$ is still possible if the graph is not regular (in an asymptotic\nsense). Finally, we show that consistent estimation of both parameters is\nimpossible if the graph is Erd\\\"os-Renyi with parameter $p>0$ free of $n$, thus\nconfirming that estimation is harder on approximately regular graphs with large\ndegree.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jan 2018 20:50:43 GMT"}], "update_date": "2018-01-23", "authors_parsed": [["Ghosal", "Promit", ""], ["Mukherjee", "Sumit", ""]]}, {"id": "1801.06581", "submitter": "Stephan Huckemann", "authors": "Benjamin Eltzner and Stephan F. Huckemann", "title": "A Smeary Central Limit Theorem for Manifolds with Application to High\n  Dimensional Spheres", "comments": "16 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The (CLT) central limit theorems for generalized Frechet means (data\ndescriptors assuming values in stratified spaces, such as intrinsic means,\ngeodesics, etc.) on manifolds from the literature are only valid if a certain\nempirical process of Hessians of the Frechet function converges suitably, as in\nthe proof of the prototypical BP-CLT (Bhattacharya and Patrangenaru (2005)).\nThis is not valid in many realistic scenarios and we provide for a new very\ngeneral CLT. In particular this includes scenarios where, in a suitable chart,\nthe sample mean fluctuates asymptotically at a scale $n^{\\alpha}$ with\nexponents ${\\alpha} < 1/2$ with a non-normal distribution. As the BP-CLT yields\nonly fluctuations that are, rescaled with $n^{1/2}$ , asymptotically normal,\njust as the classical CLT for random vectors, these lower rates, somewhat\nloosely called smeariness, had to date been observed only on the circle (Hotz\nand Huckemann (2015)). We make the concept of smeariness on manifolds precise,\ngive an example for two-smeariness on spheres of arbitrary dimension, and show\nthat smeariness, although \"almost never\" occurring, may have serious\nstatistical implications on a continuum of sample scenarios nearby. In fact,\nthis effect increases with dimension, striking in particular in high dimension\nlow sample size scenarios.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jan 2018 21:38:55 GMT"}], "update_date": "2018-01-23", "authors_parsed": [["Eltzner", "Benjamin", ""], ["Huckemann", "Stephan F.", ""]]}, {"id": "1801.06609", "submitter": "Fariborz Salehi", "authors": "Fariborz Salehi, Ehsan Abbasi, Babak Hassibi", "title": "A Precise Analysis of PhaseMax in Phase Retrieval", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recovering an unknown complex signal from the magnitude of linear\ncombinations of the signal is referred to as phase retrieval. We present an\nexact performance analysis of a recently proposed\nconvex-optimization-formulation for this problem, known as PhaseMax. Standard\nconvex-relaxation-based methods in phase retrieval resort to the idea of\n\"lifting\" which makes them computationally inefficient, since the number of\nunknowns is effectively squared. In contrast, PhaseMax is a novel convex\nrelaxation that does not increase the number of unknowns. Instead it relies on\nan initial estimate of the true signal which must be externally provided. In\nthis paper, we investigate the required number of measurements for exact\nrecovery of the signal in the large system limit and when the linear\nmeasurement matrix is random with iid standard normal entries. If $n$ denotes\nthe dimension of the unknown complex signal and $m$ the number of phaseless\nmeasurements, then in the large system limit, $\\frac{m}{n} >\n\\frac{4}{\\cos^2(\\theta)}$ measurements is necessary and sufficient to recover\nthe signal with high probability, where $\\theta$ is the angle between the\ninitial estimate and the true signal. Our result indicates a sharp phase\ntransition in the asymptotic regime which matches the empirical result in\nnumerical simulations.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jan 2018 01:08:48 GMT"}], "update_date": "2018-01-23", "authors_parsed": [["Salehi", "Fariborz", ""], ["Abbasi", "Ehsan", ""], ["Hassibi", "Babak", ""]]}, {"id": "1801.06634", "submitter": "Jianfeng Yao", "authors": "Weiming Li, Zeng Li and Jianfeng Yao", "title": "Joint CLT for eigenvalue statistics from several dependent large\n  dimensional sample covariance matrices with application", "comments": "37 pages, 2 figures and 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $\\mathbf{X}_n=(x_{ij})$ be a $k \\times n$ data matrix with\ncomplex-valued, independent and standardized entries satisfying a\nLindeberg-type moment condition. We consider simultaneously $R$ sample\ncovariance matrices $\\mathbf{B}_{nr}=\\frac1n \\mathbf{Q}_r \\mathbf{X}_n\n\\mathbf{X}_n^*\\mathbf{Q}_r^\\top,~1\\le r\\le R$, where the $\\mathbf{Q}_{r}$'s are\nnonrandom real matrices with common dimensions $p\\times k~(k\\geq p)$. Assuming\nthat both the dimension $p$ and the sample size $n$ grow to infinity, the\nlimiting distributions of the eigenvalues of the matrices $\\{\\mathbf{B}_{nr}\\}$\nare identified, and as the main result of the paper, we establish a joint\ncentral limit theorem for linear spectral statistics of the $R$ matrices\n$\\{\\mathbf{B}_{nr}\\}$. Next, this new CLT is applied to the problem of testing\na high dimensional white noise in time series modelling. In experiments the\nderived test has a controlled size and is significantly faster than the\nclassical permutation test, though it does have lower power. This application\nhighlights the necessity of such joint CLT in the presence of several dependent\nsample covariance matrices. In contrast, all the existing works on CLT for\nlinear spectral statistics of large sample covariance matrices deal with a\nsingle sample covariance matrix ($R=1$).\n", "versions": [{"version": "v1", "created": "Sat, 20 Jan 2018 06:27:59 GMT"}], "update_date": "2018-01-23", "authors_parsed": [["Li", "Weiming", ""], ["Li", "Zeng", ""], ["Yao", "Jianfeng", ""]]}, {"id": "1801.06669", "submitter": "Jinyuan Chang", "authors": "Jinyuan Chang, Aurore Delaigle, Peter Hall, Cheng Yong Tang", "title": "A frequency domain analysis of the error distribution from noisy\n  high-frequency data", "comments": null, "journal-ref": "Biometrika 2018, Vol. 105, No. 2, 353-369", "doi": "10.1093/biomet/asy006", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data observed at high sampling frequency are typically assumed to be an\nadditive composite of a relatively slow-varying continuous-time component, a\nlatent stochastic process or a smooth random function, and measurement error.\nSupposing that the latent component is an It\\^{o} diffusion process, we propose\nto estimate the measurement error density function by applying a deconvolution\ntechnique with appropriate localization. Our estimator, which does not require\nequally-spaced observed times, is consistent and minimax rate optimal. We also\ninvestigate estimators of the moments of the error distribution and their\nproperties, propose a frequency domain estimator for the integrated volatility\nof the underlying stochastic process, and show that it achieves the optimal\nconvergence rate. Simulations and a real data analysis validate our analysis.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jan 2018 12:53:19 GMT"}], "update_date": "2018-12-21", "authors_parsed": [["Chang", "Jinyuan", ""], ["Delaigle", "Aurore", ""], ["Hall", "Peter", ""], ["Tang", "Cheng Yong", ""]]}, {"id": "1801.06677", "submitter": "J. Eduardo Vera-Vald\\'es", "authors": "J. Eduardo Vera-Vald\\'es", "title": "Nonfractional Memory: Filtering, Antipersistence, and Forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST econ.EM stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The fractional difference operator remains to be the most popular mechanism\nto generate long memory due to the existence of efficient algorithms for their\nsimulation and forecasting. Nonetheless, there is no theoretical argument\nlinking the fractional difference operator with the presence of long memory in\nreal data. In this regard, one of the most predominant theoretical explanations\nfor the presence of long memory is cross-sectional aggregation of persistent\nmicro units. Yet, the type of processes obtained by cross-sectional aggregation\ndiffers from the one due to fractional differencing. Thus, this paper develops\nfast algorithms to generate and forecast long memory by cross-sectional\naggregation. Moreover, it is shown that the antipersistent phenomenon that\narises for negative degrees of memory in the fractional difference literature\nis not present for cross-sectionally aggregated processes. Pointedly, while the\nautocorrelations for the fractional difference operator are negative for\nnegative degrees of memory by construction, this restriction does not apply to\nthe cross-sectional aggregated scheme. We show that this has implications for\nlong memory tests in the frequency domain, which will be misspecified for\ncross-sectionally aggregated processes with negative degrees of memory.\nFinally, we assess the forecast performance of high-order $AR$ and $ARFIMA$\nmodels when the long memory series are generated by cross-sectional\naggregation. Our results are of interest to practitioners developing forecasts\nof long memory variables like inflation, volatility, and climate data, where\naggregation may be the source of long memory.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jan 2018 13:59:44 GMT"}], "update_date": "2018-01-23", "authors_parsed": [["Vera-Vald\u00e9s", "J. Eduardo", ""]]}, {"id": "1801.06727", "submitter": "Denisa Roberts", "authors": "Denisa Roberts and Douglas Patterson", "title": "A Second Order Cumulant Spectrum Test That a Stochastic Process is\n  Strictly Stationary and a Step Toward a Test for Graph Signal Strict\n  Stationarity", "comments": "6 pages", "journal-ref": "NeurIPS 2018 Workshop for the Spatiotemporal Domain", "doi": null, "report-no": null, "categories": "q-fin.ST math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article develops a statistical test for the null hypothesis of strict\nstationarity of a discrete time stochastic process in the frequency domain.\nWhen the null hypothesis is true, the second order cumulant spectrum is zero at\nall the discrete Fourier frequency pairs in the principal domain. The test uses\na window averaged sample estimate of the second order cumulant spectrum to\nbuild a test statistic with an asymptotic complex standard normal distribution.\nWe derive the test statistic, study the properties of the test and demonstrate\nits application using 137Cs gamma ray decay data. Future areas of research\ninclude testing for strict stationarity of graph signals, with applications in\nlearning convolutional neural networks on graphs, denoising, and inpainting.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jan 2018 20:47:27 GMT"}, {"version": "v2", "created": "Sun, 29 Mar 2020 18:46:52 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Roberts", "Denisa", ""], ["Patterson", "Douglas", ""]]}, {"id": "1801.06862", "submitter": "Katsumi Shimotsu", "authors": "Hiroyuki Kasahara and Katsumi Shimotsu", "title": "Testing the Number of Regimes in Markov Regime Switching Models", "comments": "72 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM math.ST q-fin.MF stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Markov regime switching models have been used in numerous empirical studies\nin economics and finance. However, the asymptotic distribution of the\nlikelihood ratio test statistic for testing the number of regimes in Markov\nregime switching models has been an unresolved problem. This paper derives the\nasymptotic distribution of the likelihood ratio test statistic for testing the\nnull hypothesis of $M_0$ regimes against the alternative hypothesis of $M_0 +\n1$ regimes for any $M_0 \\geq 1$ both under the null hypothesis and under local\nalternatives. We show that the contiguous alternatives converge to the null\nhypothesis at a rate of $n^{-1/8}$ in regime switching models with normal\ndensity. The asymptotic validity of the parametric bootstrap is also\nestablished.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jan 2018 17:49:27 GMT"}, {"version": "v2", "created": "Sun, 28 Jan 2018 14:35:49 GMT"}, {"version": "v3", "created": "Tue, 30 Jan 2018 16:27:58 GMT"}], "update_date": "2018-01-31", "authors_parsed": [["Kasahara", "Hiroyuki", ""], ["Shimotsu", "Katsumi", ""]]}, {"id": "1801.06877", "submitter": "Yongcheng Qi", "authors": "Shuhua Chang and Deli Li and Yongcheng Qi", "title": "Limiting Distributions of Spectral Radii for Product of Matrices from\n  the Spherical Ensemble", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider the product of $m$ independent $n\\times n$ random matrices from the\nspherical ensemble for $m\\ge 1$. The spectral radius is defined as the maximum\nabsolute value of the $n$ eigenvalues of the product matrix. When $m=1$, the\nlimiting distribution for the spectral radii has been obtained by Jiang and Qi\n(2017). In this paper, we investigate the limiting distributions for the\nspectral radii in general. When $m$ is a fixed integer, we show that the\nspectral radii converge weakly to distributions of functions of independent\nGamma random variables. When $m=m_n$ tends to infinity as $n$ goes to infinity,\nwe show that the logarithmic spectral radii have a normal limit.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jan 2018 18:56:47 GMT"}], "update_date": "2018-01-23", "authors_parsed": [["Chang", "Shuhua", ""], ["Li", "Deli", ""], ["Qi", "Yongcheng", ""]]}, {"id": "1801.07083", "submitter": "Shanyun Liu", "authors": "Shanyun Liu, Rui She and Pingyi Fan", "title": "Differential Message Importance Measure: A New Approach to the Required\n  Sampling Number in Big Data Structure Characterization", "comments": "11pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NA math.IT math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data collection is a fundamental problem in the scenario of big data, where\nthe size of sampling sets plays a very important role, especially in the\ncharacterization of data structure. This paper considers the information\ncollection process by taking message importance into account, and gives a\ndistribution-free criterion to determine how many samples are required in big\ndata structure characterization. Similar to differential entropy, we define\ndifferential message importance measure (DMIM) as a measure of message\nimportance for continuous random variable. The DMIM for many common densities\nis discussed, and high-precision approximate values for normal distribution are\ngiven. Moreover, it is proved that the change of DMIM can describe the gap\nbetween the distribution of a set of sample values and a theoretical\ndistribution. In fact, the deviation of DMIM is equivalent to\nKolmogorov-Smirnov statistic, but it offers a new way to characterize the\ndistribution goodness-of-fit. Numerical results show some basic properties of\nDMIM and the accuracy of the proposed approximate values. Furthermore, it is\nalso obtained that the empirical distribution approaches the real distribution\nwith decreasing of the DMIM deviation, which contributes to the selection of\nsuitable sampling points in actual system.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jan 2018 13:38:29 GMT"}], "update_date": "2018-01-23", "authors_parsed": [["Liu", "Shanyun", ""], ["She", "Rui", ""], ["Fan", "Pingyi", ""]]}, {"id": "1801.07310", "submitter": "Alexander Volfovsky", "authors": "Panos Toulis and Alexander Volfovsky and Edoardo M. Airoldi", "title": "Propensity score methodology in the presence of network entanglement\n  between treatments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In experimental design and causal inference, it may happen that the treatment\nis not defined on individual experimental units, but rather on pairs or, more\ngenerally, on groups of units. For example, teachers may choose pairs of\nstudents who do not know each other to teach a new curriculum; regulators might\nallow or disallow merging of firms, and biologists may introduce or inhibit\ninteractions between genes or proteins. In this paper, we formalize this\nexperimental setting, and we refer to the individual treatments in such setting\nas entangled treatments. We then consider the special case where individual\ntreatments depend on a common population quantity, and develop theory and\nmethodology to deal with this case. In our target applications, the common\npopulation quantity is a network, and the individual treatments are defined as\nfunctions of the change in the network between two specific time points. Our\nfocus is on estimating the causal effect of entangled treatments in\nobservational studies where entangled treatments are endogenous and cannot be\ndirectly manipulated. When treatment cannot be manipulated, be it entangled or\nnot, it is necessary to account for the treatment assignment mechanism to avoid\nselection bias, commonly through a propensity score methodology. In this paper,\nwe quantify the extent to which classical propensity score methodology ignores\ntreatment entanglement, and characterize the bias in the estimated causal\neffects. To characterize such bias we introduce a novel similarity function\nbetween propensity score models, and a practical approximation of it, which we\nuse to quantify model misspecification of propensity scores due to\nentanglement. One solution to avoid the bias in the presence of entangled\ntreatments is to model the change in the network, directly, and calculate an\nindividual unit's propensity score by averaging treatment assignments over this\nchange.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jan 2018 20:38:29 GMT"}], "update_date": "2018-01-24", "authors_parsed": [["Toulis", "Panos", ""], ["Volfovsky", "Alexander", ""], ["Airoldi", "Edoardo M.", ""]]}, {"id": "1801.07644", "submitter": "Hao Zhou", "authors": "Hao Henry Zhou and Garvesh Raskutti", "title": "Non-parametric Sparse Additive Auto-regressive Network Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a multi-variate time series $(X_t)_{t=0}^{T}$ where $X_t \\in\n\\mathbb{R}^d$ which may represent spike train responses for multiple neurons in\na brain, crime event data across multiple regions, and many others. An\nimportant challenge associated with these time series models is to estimate an\ninfluence network between the $d$ variables, especially when the number of\nvariables $d$ is large meaning we are in the high-dimensional setting. Prior\nwork has focused on parametric vector auto-regressive models. However,\nparametric approaches are somewhat restrictive in practice. In this paper, we\nuse the non-parametric sparse additive model (SpAM) framework to address this\nchallenge. Using a combination of $\\beta$ and $\\phi$-mixing properties of\nMarkov chains and empirical process techniques for reproducing kernel Hilbert\nspaces (RKHSs), we provide upper bounds on mean-squared error in terms of the\nsparsity $s$, logarithm of the dimension $\\log d$, number of time points $T$,\nand the smoothness of the RKHSs. Our rates are sharp up to logarithm factors in\nmany cases. We also provide numerical experiments that support our theoretical\nresults and display potential advantages of using our non-parametric SpAM\nframework for a Chicago crime dataset.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jan 2018 16:34:11 GMT"}, {"version": "v2", "created": "Wed, 24 Jan 2018 20:16:18 GMT"}], "update_date": "2018-01-26", "authors_parsed": [["Zhou", "Hao Henry", ""], ["Raskutti", "Garvesh", ""]]}, {"id": "1801.07665", "submitter": "Wolfgang Trutschnig", "authors": "Noppadon Kamnitui, Christian Genest, Wolfgang Trutschnig", "title": "On all Pickands Dependence Functions whose corresponding\n  Extreme-Value-Copulas have Spearman $\\rho$ (Kendall $\\tau$) identical to some\n  value $v \\in [0,1]$", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We answer an open question posed by the second author at the Salzburg\nworkshop on Dependence Models and Copulas in 2016 concerning the size of the\nfamily $\\mathcal{A}^\\rho_v$ ($\\mathcal{A}^\\tau_v$) of all Pickands dependence\nfunctions $A$ whose corresponding Extreme-Value-Copulas have Spearman $\\rho$\n(Kendall $\\tau$) equal to some arbitrary, fixed value $v \\in [0,1]$. After\ndetermining compact sets $\\Omega^\\rho_v, \\Omega^\\tau_v \\subseteq [0,1] \\times\n[\\frac{1}{2},1]$ containing the graphs of all Pickands dependence functions\nfrom the classes $\\mathcal{A}^\\rho_v$ and $\\mathcal{A}^\\tau_v$ respectively, we\nthen show that both sets are best possible.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jan 2018 17:24:34 GMT"}], "update_date": "2018-01-24", "authors_parsed": [["Kamnitui", "Noppadon", ""], ["Genest", "Christian", ""], ["Trutschnig", "Wolfgang", ""]]}, {"id": "1801.07902", "submitter": "Landy Rabehasaina", "authors": "Yacouba Boubacar Ma\\\"inassara (LMB), Landy Rabehasaina (LMB)", "title": "Estimation of weak ARMA models with regime changes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we derive the asymptotic properties of the least squares\nestimator (LSE) of autoregressive moving-average (ARMA) models with regime\nchanges under the assumption that the errors are uncorrelated but not\nnecessarily independent. Relaxing the independence assumption considerably\nextends the range of application of the class of ARMA models with regime\nchanges. Conditions are given for the consistency and asymptotic normality of\nthe LSE. A particular attention is given to the estimation of the asymptotic\ncovariance matrix, which may be very different from that obtained in the\nstandard framework. The theoretical results are illustrated by means of Monte\nCarlo experiments.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jan 2018 08:19:26 GMT"}, {"version": "v2", "created": "Tue, 6 Nov 2018 07:53:27 GMT"}, {"version": "v3", "created": "Wed, 10 Jul 2019 13:34:28 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Ma\u00efnassara", "Yacouba Boubacar", "", "LMB"], ["Rabehasaina", "Landy", "", "LMB"]]}, {"id": "1801.08120", "submitter": "Rong Ma", "authors": "Rong Ma, T. Tony Cai, Hongzhe Li", "title": "Optimal Estimation of Simultaneous Signals Using Absolute Inner Product\n  with Applications to Integrative Genomics", "comments": null, "journal-ref": "Statistica Sinica (2020)", "doi": "10.5705/ss.202019.0445", "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Integrating the summary statistics from genome-wide association study\n(\\textsc{gwas}) and expression quantitative trait loci (e\\textsc{qtl}) data\nprovides a powerful way of identifying the genes whose expression levels are\npotentially associated with complex diseases. A parameter called $T$-score that\nquantifies the genetic overlap between a gene and the disease phenotype based\non the summary statistics is introduced based on the mean values of two\nGaussian sequences. Specifically, given two independent samples\n$\\mathbf{x}_n\\sim N(\\theta, \\Sigma_1)$ and $\\mathbf{y}_n\\sim N(\\mu, \\Sigma_2)$,\nthe $T$-score is defined as $\\sum_{i=1}^n |\\theta_i\\mu_i|$, a non-smooth\nfunctional, which characterizes the amount of shared signals between two\nabsolute normal mean vectors $|\\theta|$ and $|\\mu|$. Using approximation\ntheory, estimators are constructed and shown to be minimax rate-optimal and\nadaptive over various parameter spaces. Simulation studies demonstrate the\nsuperiority of the proposed estimators over existing methods. The method is\napplied to an integrative analysis of heart failure genomics datasets and we\nidentify several genes and biological pathways that are potentially causal to\nhuman heart failure.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jan 2018 18:40:50 GMT"}, {"version": "v2", "created": "Wed, 7 Aug 2019 23:41:12 GMT"}, {"version": "v3", "created": "Thu, 14 Nov 2019 14:43:13 GMT"}, {"version": "v4", "created": "Mon, 5 Oct 2020 02:20:52 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Ma", "Rong", ""], ["Cai", "T. Tony", ""], ["Li", "Hongzhe", ""]]}, {"id": "1801.08364", "submitter": "Robin Evans", "authors": "Robin J. Evans", "title": "Model selection and local geometry", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider problems in model selection caused by the geometry of models\nclose to their points of intersection. In some cases---including common classes\nof causal or graphical models, as well as time series models---distinct models\nmay nevertheless have identical tangent spaces. This has two immediate\nconsequences: first, in order to obtain constant power to reject one model in\nfavour of another we need local alternative hypotheses that decrease to the\nnull at a slower rate than the usual parametric $n^{-1/2}$ (typically we will\nrequire $n^{-1/4}$ or slower); in other words, to distinguish between the\nmodels we need large effect sizes or very large sample sizes. Second, we show\nthat under even weaker conditions on their tangent cones, models in these\nclasses cannot be made simultaneously convex by a reparameterization.\n  This shows that Bayesian network models, amongst others, cannot be learned\ndirectly with a convex method similar to the graphical lasso. However, we are\nable to use our results to suggest methods for model selection that learn the\ntangent space directly, rather than the model itself. In particular, we give a\ngeneric algorithm for learning Bayesian network models.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jan 2018 11:45:36 GMT"}, {"version": "v2", "created": "Wed, 31 Jan 2018 23:03:06 GMT"}, {"version": "v3", "created": "Thu, 4 Jul 2019 10:30:20 GMT"}, {"version": "v4", "created": "Thu, 5 Dec 2019 16:16:09 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Evans", "Robin J.", ""]]}, {"id": "1801.08512", "submitter": "Jana Jankova", "authors": "Jana Jankova and Sara van de Geer", "title": "Inference in high-dimensional graphical models", "comments": "29 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a selected overview of methodology and theory for estimation and\ninference on the edge weights in high-dimensional directed and undirected\nGaussian graphical models. For undirected graphical models, two main explicit\nconstructions are provided: one based on a global method that maximizes the\njoint likelihood (the graphical Lasso) and one based on a local (nodewise)\nmethod that sequentially applies the Lasso to estimate the neighbourhood of\neach node. The proposed estimators lead to confidence intervals for edge\nweights and recovery of the edge structure. We evaluate their empirical\nperformance in an extensive simulation study. The theoretical guarantees for\nthe methods are achieved under a sparsity condition relative to the sample size\nand regularity conditions. For directed acyclic graphs, we apply similar ideas\nto construct confidence intervals for edge weights, when the directed acyclic\ngraph is identifiable.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jan 2018 18:21:41 GMT"}], "update_date": "2018-01-26", "authors_parsed": [["Jankova", "Jana", ""], ["van de Geer", "Sara", ""]]}, {"id": "1801.08698", "submitter": "Chengshi Liu", "authors": "Cheng-shi Liu", "title": "Average values of functionals and concentration without measure", "comments": "32 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math-ph math.FA math.MP math.ST physics.data-an stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although there doesn't exist the Lebesgue measure in the ball $M$ of $C[0,1]$\nwith $p-$norm, the average values (expectation) $EY$ and variance $DY$ of some\nfunctionals $Y$ on $M$ can still be defined through the procedure of limitation\nfrom finite dimension to infinite dimension. In particular, the probability\ndensities of coordinates of points in the ball $M$ exist and are derived out\neven though the density of points in $M$ doesn't exist. These densities include\nhigh order normal distribution, high order exponent distribution. This also can\nbe considered as the geometrical origins of these probability distributions.\nFurther, the exact values (which is represented in terms of finite dimensional\nintegral) of a kind of infinite-dimensional functional integrals are obtained,\nand specially the variance $DY$ is proven to be zero, and then the nonlinear\nexchange formulas of average values of functionals are also given. Instead of\nmeasure, the variance is used to measure the deviation of functional from its\naverage value. $DY=0$ means that a functional takes its average on a ball with\nprobability 1 by using the language of probability theory, and this is just the\nconcentration without measure. In addition, we prove that the average value\ndepends on the discretization.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jan 2018 07:29:25 GMT"}, {"version": "v2", "created": "Mon, 19 Feb 2018 05:00:16 GMT"}], "update_date": "2018-02-20", "authors_parsed": [["Liu", "Cheng-shi", ""]]}, {"id": "1801.08724", "submitter": "Can Le", "authors": "Can M. Le, Elizaveta Levina and Roman Vershynin", "title": "Concentration of random graphs and application to community detection", "comments": "Submission for International Congress of Mathematicians, Rio de\n  Janeiro, Brazil 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random matrix theory has played an important role in recent work on\nstatistical network analysis. In this paper, we review recent results on\nregimes of concentration of random graphs around their expectation, showing\nthat dense graphs concentrate and sparse graphs concentrate after\nregularization. We also review relevant network models that may be of interest\nto probabilists considering directions for new random matrix theory\ndevelopments, and random matrix theory tools that may be of interest to\nstatisticians looking to prove properties of network algorithms. Applications\nof concentration results to the problem of community detection in networks are\ndiscussed in detail.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jan 2018 09:24:19 GMT"}], "update_date": "2018-01-29", "authors_parsed": [["Le", "Can M.", ""], ["Levina", "Elizaveta", ""], ["Vershynin", "Roman", ""]]}, {"id": "1801.08817", "submitter": "Javier \\'Alvarez-Li\\'ebana", "authors": "M. D. Ruiz-Medina and J. \\'Alvarez-Li\\'ebana", "title": "Strongly consistent autoregressive predictors in abstract Banach spaces", "comments": "37 pages (Supplementary Material has been included) with 6 figures.\n  Manuscript accepted, in press", "journal-ref": "Journal of Multivariate Analysis, 2018", "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This work derives new results on strong consistent estimation and prediction\nfor autoregressive processes of order 1 in a separable Banach space B. The\nconsistency results are obtained for the componentwise estimator of the\nautocorrelation operator in the norm of the space $\\mathcal{L}(B)$ of bounded\nlinear operators on B. The strong consistency of the associated plug-in\npredictor then follows in the $B$-norm. A Gelfand triple is defined through the\nHilbert space constructed in Kuelbs' Lemma \\cite{Kuelbs70}. A Hilbert--Schmidt\nembedding introduces the Reproducing Kernel Hilbert space (RKHS), generated by\nthe autocovariance operator, into the Hilbert space conforming the Rigged\nHilbert space structure. This paper extends the work of \\cite{Bosq00} and\n\\cite{LabbasMourid02}.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jan 2018 14:10:17 GMT"}, {"version": "v2", "created": "Wed, 5 Sep 2018 07:31:58 GMT"}], "update_date": "2018-09-06", "authors_parsed": [["Ruiz-Medina", "M. D.", ""], ["\u00c1lvarez-Li\u00e9bana", "J.", ""]]}, {"id": "1801.08821", "submitter": "Lubna Amro", "authors": "Lubna Amro, Frank Konietschke, Markus Pauly", "title": "Multiplication-Combination Tests for Incomplete Paired Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider statistical procedures for hypothesis testing of real valued\nfunctionals of matched pairs with missing values. In order to improve the\naccuracy of existing methods, we propose a novel multiplication combination\nprocedure. Dividing the observed data into dependent (completely observed)\npairs and independent (incompletely observed) components, it is based on\ncombining separate results of adequate tests for the two sub datasets. Our\nmethods can be applied for parametric as well as semi- and nonparametric models\nand make efficient use of all available data. In particular, the approaches are\nflexible and can be used to test different hypotheses in various models of\ninterest. This is exemplified by a detailed study of mean- as well as\nrank-based apporaches. Extensive simulations show that the proposed procedures\nare more accurate than existing competitors. A real data set illustrates the\napplication of the methods.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jan 2018 14:23:30 GMT"}], "update_date": "2018-01-29", "authors_parsed": [["Amro", "Lubna", ""], ["Konietschke", "Frank", ""], ["Pauly", "Markus", ""]]}, {"id": "1801.08898", "submitter": "Huiming Zhang", "authors": "Huiming Zhang", "title": "A note on \"MLE in logistic regression with a diverging dimension\"", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This short note is to point the reader to notice that the proof of high\ndimensional asymptotic normality of MLE estimator for logistic regression under\nthe regime $p_n=o(n)$ given in paper: \"Maximum likelihood estimation in\nlogistic regression models with a diverging number of covariates. Electronic\nJournal of Statistics, 6, 1838-1846.\" is wrong.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jan 2018 16:58:30 GMT"}], "update_date": "2018-01-29", "authors_parsed": [["Zhang", "Huiming", ""]]}, {"id": "1801.09100", "submitter": "Atin Gayen", "authors": "Atin Gayen and M. Ashok Kumar", "title": "Generalized Estimating Equation for the Student-t Distributions", "comments": "6 pages, Submitted to ISIT 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT math.IT math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In \\cite{KumarS15J2}, it was shown that a generalized maximum likelihood\nestimation problem on a (canonical) $\\alpha$-power-law model\n($\\mathbb{M}^{(\\alpha)}$-family) can be solved by solving a system of linear\nequations. This was due to an orthogonality relationship between the\n$\\mathbb{M}^{(\\alpha)}$-family and a linear family with respect to the relative\n$\\alpha$-entropy (or the $\\mathscr{I}_\\alpha$-divergence). Relative\n$\\alpha$-entropy is a generalization of the usual relative entropy (or the\nKullback-Leibler divergence). $\\mathbb{M}^{(\\alpha)}$-family is a\ngeneralization of the usual exponential family. In this paper, we first\ngeneralize the $\\mathbb{M}^{(\\alpha)}$-family including the multivariate,\ncontinuous case and show that the Student-t distributions fall in this family.\nWe then extend the above stated result of \\cite{KumarS15J2} to the general\n$\\mathbb{M}^{(\\alpha)}$-family. Finally we apply this result to the Student-t\ndistribution and find generalized estimators for its parameters.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jan 2018 15:04:48 GMT"}], "update_date": "2018-01-30", "authors_parsed": [["Gayen", "Atin", ""], ["Kumar", "M. Ashok", ""]]}, {"id": "1801.09138", "submitter": "Whitney Newey", "authors": "Whitney K. Newey and James R. Robins", "title": "Cross-Fitting and Fast Remainder Rates for Semiparametric Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are many interesting and widely used estimators of a functional with\nfinite semiparametric variance bound that depend on nonparametric estimators of\nnuisance functions. We use cross-fitting (i.e. sample splitting) to construct\nnovel estimators with fast remainder rates. We give cross-fit doubly robust\nestimators that use separate subsamples to estimate different nuisance\nfunctions. We obtain general, precise results for regression spline estimation\nof average linear functionals of conditional expectations with a finite\nsemiparametric variance bound. We show that a cross-fit doubly robust spline\nregression estimator of the expected conditional covariance is semiparametric\nefficient under minimal conditions. Cross-fit doubly robust estimators of other\naverage linear functionals of a conditional expectation are shown to have the\nfastest known remainder rates for the Haar basis or under certain smoothness\nconditions. Surprisingly, the cross-fit plug-in estimator also has nearly the\nfastest known remainder rate, but the remainder converges to zero slower than\nthe cross-fit doubly robust estimator. As specific examples we consider the\nexpected conditional covariance, mean with randomly missing data, and a\nweighted average derivative.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jan 2018 20:40:41 GMT"}], "update_date": "2018-01-30", "authors_parsed": [["Newey", "Whitney K.", ""], ["Robins", "James R.", ""]]}, {"id": "1801.09269", "submitter": "Giovanni Pistone", "authors": "Luigi Malag\\`o, Luigi Montrucchio, Giovanni Pistone", "title": "Wasserstein Riemannian Geometry of Positive Definite Matrices", "comments": "Revised version. Introduction extended. References added", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Wasserstein distance on multivariate non-degenerate Gaussian densities is\na Riemannian distance. After reviewing the properties of the distance and the\nmetric geodesic, we present an explicit form of the Riemannian metrics on\npositive-definite matrices and compute its tensor form with respect to the\ntrace inner product. The tensor is a matrix which is the solution to a Lyapunov\nequation. We compute the explicit formula for the Riemannian exponential, the\nnormal coordinates charts and the Riemannian gradient. Finally, the Levi-Civita\ncovariant derivative is computed in matrix form together with the differential\nequation for the parallel transport. While all computations are given in matrix\nform, nonetheless we discuss also the use of a special moving frame.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jan 2018 19:00:43 GMT"}, {"version": "v2", "created": "Mon, 19 Mar 2018 11:51:35 GMT"}, {"version": "v3", "created": "Tue, 22 May 2018 15:45:43 GMT"}, {"version": "v4", "created": "Sun, 23 Sep 2018 11:45:10 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Malag\u00f2", "Luigi", ""], ["Montrucchio", "Luigi", ""], ["Pistone", "Giovanni", ""]]}, {"id": "1801.09326", "submitter": "Guang Cheng", "authors": "Botao Hao, Anru Zhang, Guang Cheng", "title": "Sparse and Low-rank Tensor Estimation via Cubic Sketchings", "comments": "Accepted at IEEE Transactions on Information Theory", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a general framework for sparse and low-rank tensor\nestimation from cubic sketchings. A two-stage non-convex implementation is\ndeveloped based on sparse tensor decomposition and thresholded gradient\ndescent, which ensures exact recovery in the noiseless case and stable recovery\nin the noisy case with high probability. The non-asymptotic analysis sheds\nlight on an interplay between optimization error and statistical error. The\nproposed procedure is shown to be rate-optimal under certain conditions. As a\ntechnical by-product, novel high-order concentration inequalities are derived\nfor studying high-moment sub-Gaussian tensors. An interesting tensor\nformulation illustrates the potential application to high-order interaction\npursuit in high-dimensional linear regression.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jan 2018 00:26:39 GMT"}, {"version": "v2", "created": "Tue, 5 Mar 2019 03:09:42 GMT"}, {"version": "v3", "created": "Sat, 11 Jan 2020 04:05:03 GMT"}, {"version": "v4", "created": "Sun, 15 Mar 2020 01:07:20 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Hao", "Botao", ""], ["Zhang", "Anru", ""], ["Cheng", "Guang", ""]]}, {"id": "1801.09419", "submitter": "Thibaut Le Gouic", "authors": "Thibaut Le Gouic (1), Quentin Paris (2) ((1) I2M, (2) CS-HSE)", "title": "A notion of stability for k-means clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we define and study a new notion of stability for the\n$k$-means clustering scheme building upon the notion of quantization of a\nprobability measure. We connect this notion of stability to a geometric feature\nof the underlying distribution of the data, named absolute margin condition,\ninspired by recent works on the subject.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jan 2018 09:39:10 GMT"}, {"version": "v2", "created": "Thu, 8 Mar 2018 15:38:56 GMT"}], "update_date": "2018-03-09", "authors_parsed": [["Gouic", "Thibaut Le", "", "I2M"], ["Paris", "Quentin", "", "CS-HSE"]]}, {"id": "1801.09540", "submitter": "Peter Math\\'e", "authors": "Peter Math\\'e", "title": "Bayesian inverse problems with non-commuting operators", "comments": "This is an update of the previously uploaded version, improving the\n  readability", "journal-ref": null, "doi": "10.1090/mcom/3439", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Bayesian approach to ill-posed operator equations in Hilbert space\nrecently gained attraction. In this context, and when the prior distribution is\nGaussian, then two operators play a significant role, the one which governs the\noperator equation, and the one which describes the prior covariance. Typically\nit is assumed that these operators commute. Here we extend this analysis to\nnon-commuting operators, replacing the commutativity assumption by a link\ncondition. We discuss its relation to the commuting case, and we indicate that\nthis allows to use interpolation type results to obtain tight bounds for the\ncontraction of the posterior Gaussian distribution towards the data generating\nelement.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jan 2018 14:51:58 GMT"}, {"version": "v2", "created": "Mon, 3 Dec 2018 12:34:24 GMT"}], "update_date": "2019-08-19", "authors_parsed": [["Math\u00e9", "Peter", ""]]}, {"id": "1801.09652", "submitter": "Qingyuan Zhao", "authors": "Qingyuan Zhao, Jingshu Wang, Gibran Hemani, Jack Bowden, Dylan S.\n  Small", "title": "Statistical inference in two-sample summary-data Mendelian randomization\n  using robust adjusted profile score", "comments": "59 pages, 5 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mendelian randomization (MR) is a method of exploiting genetic variation to\nunbiasedly estimate a causal effect in presence of unmeasured confounding. MR\nis being widely used in epidemiology and other related areas of population\nscience. In this paper, we study statistical inference in the increasingly\npopular two-sample summary-data MR design. We show a linear model for the\nobserved associations approximately holds in a wide variety of settings when\nall the genetic variants satisfy the exclusion restriction assumption, or in\ngenetic terms, when there is no pleiotropy. In this scenario, we derive a\nmaximum profile likelihood estimator with provable consistency and asymptotic\nnormality. However, through analyzing real datasets, we find strong evidence of\nboth systematic and idiosyncratic pleiotropy in MR, echoing the omnigenic model\nof complex traits that is recently proposed in genetics. We model the\nsystematic pleiotropy by a random effects model, where no genetic variant\nsatisfies the exclusion restriction condition exactly. In this case we propose\na consistent and asymptotically normal estimator by adjusting the profile\nscore. We then tackle the idiosyncratic pleiotropy by robustifying the adjusted\nprofile score. We demonstrate the robustness and efficiency of the proposed\nmethods using several simulated and real datasets.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jan 2018 18:13:44 GMT"}, {"version": "v2", "created": "Wed, 7 Feb 2018 19:09:50 GMT"}, {"version": "v3", "created": "Wed, 2 Jan 2019 02:31:18 GMT"}], "update_date": "2019-01-03", "authors_parsed": [["Zhao", "Qingyuan", ""], ["Wang", "Jingshu", ""], ["Hemani", "Gibran", ""], ["Bowden", "Jack", ""], ["Small", "Dylan S.", ""]]}, {"id": "1801.09817", "submitter": "Zhiqiang Tan", "authors": "Zhiqiang Tan", "title": "Model-assisted inference for treatment effects using regularized\n  calibrated estimation with high-dimensional data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider the problem of estimating average treatment effects when a large\nnumber of covariates are used to adjust for possible confounding through\noutcome regression and propensity score models. The conventional approach of\nmodel building and fitting iteratively can be difficult to implement, depending\non ad hoc choices of what variables are included. In addition, uncertainty from\nthe iterative process of model selection is complicated and often ignored in\nsubsequent inference about treatment effects. We develop new methods and theory\nto obtain not only doubly robust point estimators for average treatment\neffects, which remain consistent if either the propensity score model or the\noutcome regression model is correctly specified, but also model-assisted\nconfidence intervals, which are valid when the propensity score model is\ncorrectly specified but the outcome regression model may be misspecified. With\na linear outcome model, the confidence intervals are doubly robust, that is,\nbeing also valid when the outcome model is correctly specified but the\npropensity score model may be misspecified. Our methods involve regularized\ncalibrated estimators with Lasso penalties, but carefully chosen loss\nfunctions, for fitting propensity score and outcome regression models. We\nprovide high-dimensional analysis to establish the desired properties of our\nmethods under comparable conditions to previous results, which give valid\nconfidence intervals when both the propensity score and outcome regression are\ncorrectly specified. We present a simulation study and an empirical application\nwhich confirm the advantages of the proposed methods compared with related\nmethods based on regularized maximum likelihood estimation.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jan 2018 01:20:15 GMT"}], "update_date": "2018-01-31", "authors_parsed": [["Tan", "Zhiqiang", ""]]}, {"id": "1801.09834", "submitter": "James Long", "authors": "Zhenfeng Lin and James P. Long", "title": "A Flexible Procedure for Mixture Proportion Estimation in\n  Positive-Unlabeled Learning", "comments": "28 pages (including 9 pages of Technical Notes), 4 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Positive--unlabeled (PU) learning considers two samples, a positive set P\nwith observations from only one class and an unlabeled set U with observations\nfrom two classes. The goal is to classify observations in U. Class mixture\nproportion estimation (MPE) in U is a key step in PU learning. Blanchard et al.\n[2010] showed that MPE in PU learning is a generalization of the problem of\nestimating the proportion of true null hypotheses in multiple testing problems.\nMotivated by this idea, we propose reducing the problem to one dimension via\nconstruction of a probabilistic classifier trained on the P and U data sets\nfollowed by application of a one--dimensional mixture proportion method from\nthe multiple testing literature to the observation class probabilities. The\nflexibility of this framework lies in the freedom to choose the classifier and\nthe one--dimensional MPE method. We prove consistency of two mixture proportion\nestimators using bounds from empirical process theory, develop tuning parameter\nfree implementations, and demonstrate that they have competitive performance on\nsimulated waveform data and a protein signaling problem.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jan 2018 03:02:12 GMT"}, {"version": "v2", "created": "Wed, 31 Jan 2018 22:23:11 GMT"}, {"version": "v3", "created": "Thu, 12 Jul 2018 21:12:26 GMT"}, {"version": "v4", "created": "Fri, 10 Jan 2020 03:30:27 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Lin", "Zhenfeng", ""], ["Long", "James P.", ""]]}, {"id": "1801.09874", "submitter": "Weichi Wu", "authors": "Holger Dette, Weichi Wu", "title": "Change point analysis in non-stationary processes - a mass excess\n  approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the problem of testing if a sequence of means\n$(\\mu_t)_{t =1,\\ldots ,n }$ of a non-stationary time series $(X_t)_{t =1,\\ldots\n,n }$ is stable in the sense that the difference of the means $\\mu_1$ and\n$\\mu_t$ between the initial time $t=1$ and any other time is smaller than a\ngiven level, that is $ | \\mu_1 - \\mu_t | \\leq c $ for all $t =1,\\ldots ,n $. A\ntest for hypotheses of this type is developed using a biascorrected monotone\nrearranged local linear estimator and asymptotic normality of the corresponding\ntest statistic is established. As the asymptotic variance depends on the\nlocation and order of the critical roots of the equation $| \\mu_1 - \\mu_t | =\nc$ a new bootstrap procedure is proposed to obtain critical values and its\nconsistency is established. As a consequence we are able to quantitatively\ndescribe relevant deviations of a non-stationary sequence from its initial\nvalue. The results are illustrated by means of a simulation study and by\nanalyzing data examples.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jan 2018 07:30:25 GMT"}, {"version": "v2", "created": "Mon, 7 Jan 2019 06:52:16 GMT"}], "update_date": "2019-01-08", "authors_parsed": [["Dette", "Holger", ""], ["Wu", "Weichi", ""]]}, {"id": "1801.09883", "submitter": "Valeriy Kalyagin", "authors": "L.P. Semenov, V.A. Kalyagin, P.A. Koldanov, M.V. Batsyn, S.V.\n  Golovanova, M.A. Voronina", "title": "Comparison of robustness of statistical procedures for network structure\n  analysis", "comments": "21 pages, in Russian", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Different network structures are compiared with respect to degree of\nrobustnes of identification statistical procedures. It is shown that threshold\n(market) graph, cliques and independent sets in the threshold (market) graphs\nare preferable network structure from this point of view.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jan 2018 08:08:51 GMT"}], "update_date": "2018-01-31", "authors_parsed": [["Semenov", "L. P.", ""], ["Kalyagin", "V. A.", ""], ["Koldanov", "P. A.", ""], ["Batsyn", "M. V.", ""], ["Golovanova", "S. V.", ""], ["Voronina", "M. A.", ""]]}, {"id": "1801.09884", "submitter": "Antoine Usseglio-Carleve", "authors": "Antoine Usseglio-Carleve (ICJ)", "title": "Estimation of conditional extreme risk measures from heavy-tailed\n  elliptical random vectors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we focus on some conditional extreme risk measures estimation\nfor elliptical random vectors. In a previous paper, we proposed a methodology\nto approximate extreme quantiles, based on two extremal parameters. We thus\npropose some estimators for these parameters, and study their asymptotic\nproperties in the case of heavy-tailed distributions. Thereafter, from these\nparameters, we construct extreme conditional quantiles estimators, and give\ntheir consistency properties. Using recent results on the asymptotic\nrelationship between quantiles and other risk measures, we deduce estimators\nfor extreme conditional Lp-quantiles and Haezendonck-Goovaerts risk measures.\nIn order to test the efficiency of our estimators, we propose a simulation\nstudy. A financial data example is also proposed.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jan 2018 08:09:39 GMT"}, {"version": "v2", "created": "Wed, 25 Jul 2018 07:14:03 GMT"}], "update_date": "2018-07-26", "authors_parsed": [["Usseglio-Carleve", "Antoine", "", "ICJ"]]}, {"id": "1801.09894", "submitter": "Mathias Trabs", "authors": "Mathias Trabs", "title": "Bayesian inverse problems with unknown operators", "comments": "24 pages, 2 figures", "journal-ref": "Inverse problems, 34 (8), 085001, 2018", "doi": "10.1088/1361-6420/aac3aa", "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the Bayesian approach to linear inverse problems when the\nunderlying operator depends on an unknown parameter. Allowing for finite\ndimensional as well as infinite dimensional parameters, the theory covers\nseveral models with different levels of uncertainty in the operator. Using\nproduct priors, we prove contraction rates for the posterior distribution which\ncoincide with the optimal convergence rates up to logarithmic factors. In order\nto adapt to the unknown smoothness, an empirical Bayes procedure is constructed\nbased on Lepski's method. The procedure is illustrated in numerical examples.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jan 2018 08:45:46 GMT"}, {"version": "v2", "created": "Fri, 6 Apr 2018 13:08:09 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Trabs", "Mathias", ""]]}, {"id": "1801.09911", "submitter": "Carter Butts", "authors": "Carter T. Butts", "title": "A Dynamic Process Interpretation of the Sparse ERGM Reference Model", "comments": null, "journal-ref": "Journal of Mathematical Sociology, 43(1), 40-57 (2019)", "doi": "10.1080/0022250X.2018.1490737", "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exponential family random graph models (ERGMs) can be understood in terms of\na set of structural biases that act on an underlying reference distribution.\nThis distribution determines many aspects of the behavior and interpretation of\nthe ERGM families incorporating it. One important innovation in this area has\nbeen the development of an ERGM reference model that produces realistic\nbehavior when generalized to sparse networks of varying size. Here, we show\nthat this model can be derived from a latent dynamic process in which tie\nformation takes place within small local settings between which individuals\nmove. This derivation provides one possible micro-process interpretation of the\nsparse ERGM reference model, and sheds light on the conditions under which\nconstant mean degree scaling can emerge.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jan 2018 09:37:34 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Butts", "Carter T.", ""]]}, {"id": "1801.09956", "submitter": "Moritz Schauer", "authors": "Shota Gugushvili, Frank van der Meulen, Moritz Schauer, Peter Spreij", "title": "Nonparametric Bayesian volatility estimation", "comments": null, "journal-ref": "2017 MATRIX Annals, Springer International Publishing, 2019", "doi": "10.1007/978-3-030-04161-8_19", "report-no": null, "categories": "stat.ME math.ST q-fin.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given discrete time observations over a fixed time interval, we study a\nnonparametric Bayesian approach to estimation of the volatility coefficient of\na stochastic differential equation. We postulate a histogram-type prior on the\nvolatility with piecewise constant realisations on bins forming a partition of\nthe time interval. The values on the bins are assigned an inverse Gamma Markov\nchain (IGMC) prior. Posterior inference is straightforward to implement via\nGibbs sampling, as the full conditional distributions are available explicitly\nand turn out to be inverse Gamma. We also discuss in detail the hyperparameter\nselection for our method. Our nonparametric Bayesian approach leads to good\npractical results in representative simulation examples. Finally, we apply it\non a classical data set in change-point analysis: weekly closings of the\nDow-Jones industrial averages.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jan 2018 12:31:06 GMT"}, {"version": "v2", "created": "Fri, 29 Mar 2019 14:48:17 GMT"}], "update_date": "2019-04-01", "authors_parsed": [["Gugushvili", "Shota", ""], ["van der Meulen", "Frank", ""], ["Schauer", "Moritz", ""], ["Spreij", "Peter", ""]]}, {"id": "1801.10015", "submitter": "Mona Azadkia", "authors": "Mona Azadkia", "title": "Adaptive Estimation of Noise Variance and Matrix Estimation via USVT\n  Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method for estimating the entries of a large noisy matrix when\nthe variance of the noise, $\\sigma^2$, is unknown without putting any\nassumption on the rank of the matrix. We consider the estimator for $\\sigma$\nintroduced by Gavish and Donoho \\cite{Gavish} and give an upper bound on its\nmean squared error. Then with the estimate of the variance, we use a modified\nversion of the Universal Singular Value Thresholding (USVT) algorithm\nintroduced by Chatterjee \\cite{Chatterjee} to estimate the noisy matrix.\nFinally, we give an upper bound on the mean squared error of the estimated\nmatrix.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jan 2018 00:40:46 GMT"}, {"version": "v2", "created": "Tue, 29 Oct 2019 00:43:49 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Azadkia", "Mona", ""]]}, {"id": "1801.10229", "submitter": "Erez Peterfreund", "authors": "Erez Peterfreund and Matan Gavish", "title": "Multidimensional Scaling of Noisy High Dimensional Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multidimensional Scaling (MDS) is a classical technique for embedding data in\nlow dimensions, still in widespread use today. Originally introduced in the\n1950's, MDS was not designed with high-dimensional data in mind; while it\nremains popular with data analysis practitioners, no doubt it should be adapted\nto the high-dimensional data regime. In this paper we study MDS under modern\nsetting, and specifically, high dimensions and ambient measurement noise. We\nshow that, as the ambient noise level increase, MDS suffers a sharp breakdown\nthat depends on the data dimension and noise level, and derive an explicit\nformula for this breakdown point in the case of white noise. We then introduce\nMDS+, an extremely simple variant of MDS, which applies a carefully derived\nshrinkage nonlinearity to the eigenvalues of the MDS similarity matrix. Under a\nloss function measuring the embedding quality, MDS+ is the unique\nasymptotically optimal shrinkage function. We prove that MDS+ offers improved\nembedding, sometimes significantly so, compared with classical MDS.\nFurthermore, MDS+ does not require external estimates of the embedding\ndimension (a famous difficulty in classical MDS), as it calculates the optimal\ndimension into which the data should be embedded.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jan 2018 21:28:21 GMT"}], "update_date": "2018-02-01", "authors_parsed": [["Peterfreund", "Erez", ""], ["Gavish", "Matan", ""]]}, {"id": "1801.10341", "submitter": "Stefan Sommer", "authors": "Stefan Sommer", "title": "An Infinitesimal Probabilistic Model for Principal Component Analysis of\n  Manifold Valued Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.CV stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a probabilistic and infinitesimal view of how the principal\ncomponent analysis procedure (PCA) can be generalized to analysis of nonlinear\nmanifold valued data. Starting with the probabilistic PCA interpretation of the\nEuclidean PCA procedure, we show how PCA can be generalized to manifolds in an\nintrinsic way that does not resort to linearization of the data space. The\nunderlying probability model is constructed by mapping a Euclidean stochastic\nprocess to the manifold using stochastic development of Euclidean\nsemimartingales. The construction uses a connection and bundles of covariant\ntensors to allow global transport of principal eigenvectors, and the model is\nthereby an example of how principal fiber bundles can be used to handle the\nlack of global coordinate system and orientations that characterizes manifold\nvalued statistics. We show how curvature implies non-integrability of the\nequivalent of Euclidean principal subspaces, and how the stochastic flows\nprovide an alternative to explicit construction of such subspaces. We describe\nestimation procedures for inference of parameters and prediction of principal\ncomponents, and we give examples of properties of the model on embedded\nsurfaces.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jan 2018 08:16:16 GMT"}, {"version": "v2", "created": "Sun, 24 Jun 2018 19:21:08 GMT"}], "update_date": "2018-06-26", "authors_parsed": [["Sommer", "Stefan", ""]]}, {"id": "1801.10346", "submitter": "Claire Brecheteau", "authors": "Claire Br\\'echeteau (DATASHAPE), Cl\\'ement Levrard (LPSM UMR 8001)", "title": "The k-PDTM : a coreset for robust geometric inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.CG stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analyzing the sub-level sets of the distance to a compact sub-manifold of R d\nis a common method in TDA to understand its topology. The distance to measure\n(DTM) was introduced by Chazal, Cohen-Steiner and M{\\'e}rigot in [7] to face\nthe non-robustness of the distance to a compact set to noise and outliers. This\nfunction makes possible the inference of the topology of a compact subset of R\nd from a noisy cloud of n points lying nearby in the Wasserstein sense. In\npractice, these sub-level sets may be computed using approximations of the DTM\nsuch as the q-witnessed distance [10] or other power distance [6]. These\napproaches lead eventually to compute the homology of unions of n growing\nballs, that might become intractable whenever n is large. To simultaneously\nface the two problems of large number of points and noise, we introduce the\nk-power distance to measure (k-PDTM). This new approximation of the distance to\nmeasure may be thought of as a k-coreset based approximation of the DTM. Its\nsublevel sets consist in union of k-balls, k << n, and this distance is also\nproved robust to noise. We assess the quality of this approximation for k\npossibly dramatically smaller than n, for instance k = n 1 3 is proved to be\noptimal for 2-dimensional shapes. We also provide an algorithm to compute this\nk-PDTM.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jan 2018 08:30:49 GMT"}], "update_date": "2018-02-01", "authors_parsed": [["Br\u00e9cheteau", "Claire", "", "DATASHAPE"], ["Levrard", "Cl\u00e9ment", "", "LPSM UMR 8001"]]}, {"id": "1801.10378", "submitter": "Shoichi Eguchi", "authors": "Shoichi Eguchi, Hiroki Masuda", "title": "Data driven time scale in Gaussian quasi-likelihood inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study parametric estimation of ergodic diffusions observed at high\nfrequency. Different from the previous studies, we suppose that sampling\nstepsize is unknown, thereby making the conventional Gaussian quasi-likelihood\nnot directly applicable. In this situation, we construct estimators of both\nmodel parameters and sampling stepsize in a fully explicit way, and prove that\nthey are jointly asymptotically normally distributed. The $L^{q}$-boundedness\nof the obtained estimator is also derived. Further, we propose the Schwarz\n(BIC) type statistics for model selection and show its model-selection\nconsistency. We conducted some numerical experiments and found that the\nobserved finite-sample performance well supports our theoretical findings. Also\nprovided is a real data example.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jan 2018 09:54:48 GMT"}, {"version": "v2", "created": "Wed, 7 Feb 2018 08:45:47 GMT"}, {"version": "v3", "created": "Fri, 3 Aug 2018 02:28:04 GMT"}, {"version": "v4", "created": "Thu, 31 Jan 2019 05:11:21 GMT"}], "update_date": "2019-02-01", "authors_parsed": [["Eguchi", "Shoichi", ""], ["Masuda", "Hiroki", ""]]}, {"id": "1801.10381", "submitter": "Lionel Riou-Durand", "authors": "Lionel Riou-Durand and Nicolas Chopin", "title": "Noise contrastive estimation: asymptotics, comparison with MC-MLE", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A statistical model is said to be un-normalised when its likelihood function\ninvolves an intractable normalising constant. Two popular methods for parameter\ninference for these models are MC-MLE (Monte Carlo maximum likelihood\nestimation), and NCE (noise contrastive estimation); both methods rely on\nsimulating artificial data-points to approximate the normalising constant.\nWhile the asymptotics of MC-MLE have been established under general hypotheses\n(Geyer, 1994), this is not so for NCE. We establish consistency and asymptotic\nnormality of NCE estimators under mild assumptions. We compare NCE and MC-MLE\nunder several asymptotic regimes. In particular, we show that, when m goes to\ninfinity while n is fixed (m and n being respectively the number of artificial\ndata-points, and actual data-points), the two estimators are asymptotically\nequivalent. Conversely, we prove that, when the artificial data-points are IID,\nand when n goes to infinity while m/n converges to a positive constant, the\nasymptotic variance of a NCE estimator is always smaller than the asymptotic\nvariance of the corresponding MC-MLE estimator. We illustrate the variance\nreduction brought by NCE through a numerical study.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jan 2018 10:05:22 GMT"}], "update_date": "2018-02-01", "authors_parsed": [["Riou-Durand", "Lionel", ""], ["Chopin", "Nicolas", ""]]}, {"id": "1801.10567", "submitter": "Jana Jankova", "authors": "Jana Jankov\\'a and Sara van de Geer", "title": "De-biased sparse PCA: Inference and testing for eigenstructure of large\n  covariance matrices", "comments": "41 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse principal component analysis (sPCA) has become one of the most widely\nused techniques for dimensionality reduction in high-dimensional datasets. The\nmain challenge underlying sPCA is to estimate the first vector of loadings of\nthe population covariance matrix, provided that only a certain number of\nloadings are non-zero. In this paper, we propose confidence intervals for\nindividual loadings and for the largest eigenvalue of the population covariance\nmatrix. Given an independent sample $X^i \\in\\mathbb R^p, i = 1,...,n,$\ngenerated from an unknown distribution with an unknown covariance matrix\n$\\Sigma_0$, our aim is to estimate the first vector of loadings and the largest\neigenvalue of $\\Sigma_0$ in a setting where $p\\gg n$. Next to the\nhigh-dimensionality, another challenge lies in the inherent non-convexity of\nthe problem. We base our methodology on a Lasso-penalized M-estimator which,\ndespite non-convexity, may be solved by a polynomial-time algorithm such as\ncoordinate or gradient descent. We show that our estimator achieves the minimax\noptimal rates in $\\ell_1$ and $\\ell_2$-norm. We identify the bias in the\nLasso-based estimator and propose a de-biased sparse PCA estimator for the\nvector of loadings and for the largest eigenvalue of the covariance matrix\n$\\Sigma_0$. Our main results provide theoretical guarantees for asymptotic\nnormality of the de-biased estimator. The major conditions we impose are\nsparsity in the first eigenvector of small order $\\sqrt{n}/\\log p$ and sparsity\nof the same order in the columns of the inverse Hessian matrix of the\npopulation risk.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jan 2018 17:30:55 GMT"}], "update_date": "2018-02-01", "authors_parsed": [["Jankov\u00e1", "Jana", ""], ["van de Geer", "Sara", ""]]}]