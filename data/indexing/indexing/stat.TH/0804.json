[{"id": "0804.0407", "submitter": "Sergey V. Lototsky", "authors": "Igor Cialenco, Sergey Lototsky, Jan Pospisil", "title": "Asymptotic Properties of the Maximum Likelihood Estimator for Stochastic\n  Parabolic Equations with Additive Fractional Brownian Motion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A parameter estimation problem is considered for a diagonaliazable stochastic\nevolution equation using a finite number of the Fourier coefficients of the\nsolution. The equation is driven by additive noise that is white in space and\nfractional in time with the Hurst parameter $H\\geq 1/2$.\n  The objective is to study asymptotic properties of the maximum likelihood\nestimator as the number of the Fourier coefficients increases. A necessary and\nsufficient condition for consistency and asymptotic normality is presented in\nterms of the eigenvalues of the operators in the equation.\n", "versions": [{"version": "v1", "created": "Wed, 2 Apr 2008 18:17:17 GMT"}], "update_date": "2008-04-03", "authors_parsed": [["Cialenco", "Igor", ""], ["Lototsky", "Sergey", ""], ["Pospisil", "Jan", ""]]}, {"id": "0804.0486", "submitter": "Jordi Vallverd\\'{u}", "authors": "Jordi Vallverd\\'u", "title": "The False Dilemma: Bayesian vs. Frequentist", "comments": "Submitted to the Electronic Journal of Statistics\n  (http://www.i-journals.org/ejs/) by the Institute of Mathematical Statistics\n  (http://www.imstat.org)", "journal-ref": null, "doi": null, "report-no": "IMS-EJS-EJS_2008_220", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are two main opposing schools of statistical reasoning, Frequentist and\nBayesian approaches. Until recent days, the frequentist or classical approach\nhas dominated the scientific research, but Bayesianism has reappeared with a\nstrong impulse that is starting to change the situation. Recently the\ncontroversy about the primacy of one of the two approaches seems to be\nunfinished at a philosophical level, but scientific practices are giving an\nincreasingly important position to the Bayesian approach. This paper eludes\nphilosophical debate to focus on the pragmatic point of view of scientists'\nday-to-day practices, in which Bayesian methodology is very useful. Several\nfacts and operational values are described as the core-set for understanding\nthe change.\n", "versions": [{"version": "v1", "created": "Thu, 3 Apr 2008 07:31:13 GMT"}], "update_date": "2008-12-18", "authors_parsed": [["Vallverd\u00fa", "Jordi", ""]]}, {"id": "0804.0510", "submitter": "Daniil Ryabko", "authors": "Daniil Ryabko (INRIA Lille - Nord Europe), Boris Ryabko (SIBSUTI, ICT\n  SBRAS)", "title": "Nonparametric Statistical Inference for Ergodic Processes", "comments": "Conference version in: D. Ryabko, B. Ryabko, On hypotheses testing\n  for ergodic processes, in Proceedgings of Information Theory Workshop, 2008,\n  Porto, Portugal, pp. 281-283", "journal-ref": "IEEE Transactions on Information Theory 56, 3 (2010) 1430-1435", "doi": null, "report-no": null, "categories": "cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work a method for statistical analysis of time series is proposed,\nwhich is used to obtain solutions to some classical problems of mathematical\nstatistics under the only assumption that the process generating the data is\nstationary ergodic. Namely, three problems are considered: goodness-of-fit (or\nidentity) testing, process classification, and the change point problem. For\neach of the problems a test is constructed that is asymptotically accurate for\nthe case when the data is generated by stationary ergodic processes. The tests\nare based on empirical estimates of distributional distance.\n", "versions": [{"version": "v1", "created": "Thu, 3 Apr 2008 09:24:26 GMT"}, {"version": "v2", "created": "Fri, 11 Apr 2008 09:16:49 GMT"}, {"version": "v3", "created": "Mon, 6 Jul 2009 09:04:00 GMT"}, {"version": "v4", "created": "Tue, 3 Apr 2012 06:25:44 GMT"}], "update_date": "2012-04-05", "authors_parsed": [["Ryabko", "Daniil", "", "INRIA Lille - Nord Europe"], ["Ryabko", "Boris", "", "SIBSUTI, ICT\n  SBRAS"]]}, {"id": "0804.0551", "submitter": "Gilles Blanchard", "authors": "Gilles Blanchard, Olivier Bousquet, Pascal Massart", "title": "Statistical performance of support vector machines", "comments": "Published in at http://dx.doi.org/10.1214/009053607000000839 the\n  Annals of Statistics (http://www.imstat.org/aos/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2008, Vol. 36, No. 2, 489-531", "doi": "10.1214/009053607000000839", "report-no": "IMS-AOS-AOS0313", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The support vector machine (SVM) algorithm is well known to the computer\nlearning community for its very good practical results. The goal of the present\npaper is to study this algorithm from a statistical perspective, using tools of\nconcentration theory and empirical processes. Our main result builds on the\nobservation made by other authors that the SVM can be viewed as a statistical\nregularization procedure. From this point of view, it can also be interpreted\nas a model selection principle using a penalized criterion. It is then possible\nto adapt general methods related to model selection in this framework to study\ntwo important points: (1) what is the minimum penalty and how does it compare\nto the penalty actually used in the SVM algorithm; (2) is it possible to obtain\n``oracle inequalities'' in that setting, for the specific loss function used in\nthe SVM algorithm? We show that the answer to the latter question is positive\nand provides relevant insight to the former. Our result shows that it is\npossible to obtain fast rates of convergence for SVMs.\n", "versions": [{"version": "v1", "created": "Thu, 3 Apr 2008 13:22:02 GMT"}], "update_date": "2008-12-18", "authors_parsed": [["Blanchard", "Gilles", ""], ["Bousquet", "Olivier", ""], ["Massart", "Pascal", ""]]}, {"id": "0804.0650", "submitter": "Nathalie Villa", "authors": "Anne Ruiz (IMT, Gremaq), Nathalie Villa (IMT)", "title": "Storms prediction : Logistic regression vs random forest for unbalanced\n  data", "comments": null, "journal-ref": "Case Studies in Business, Industry and Government Statistics 1, 2\n  (2007) 91-101", "doi": null, "report-no": null, "categories": "stat.AP math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of this study is to compare two supervised classification methods on\na crucial meteorological problem. The data consist of satellite measurements of\ncloud systems which are to be classified either in convective or non convective\nsystems. Convective cloud systems correspond to lightning and detecting such\nsystems is of main importance for thunderstorm monitoring and warning. Because\nthe problem is highly unbalanced, we consider specific performance criteria and\ndifferent strategies. This case study can be used in an advanced course of data\nmining in order to illustrate the use of logistic regression and random forest\non a real data set with unbalanced classes.\n", "versions": [{"version": "v1", "created": "Fri, 4 Apr 2008 05:02:11 GMT"}], "update_date": "2008-12-18", "authors_parsed": [["Ruiz", "Anne", "", "IMT, Gremaq"], ["Villa", "Nathalie", "", "IMT"]]}, {"id": "0804.0658", "submitter": "Joseph Rynkiewicz", "authors": "Madalina Olteanu (CES, Samos), Joseph Rynkiewicz (CES, Samos, Matisse)", "title": "Estimating the Number of Components in a Mixture of Multilayer\n  Perceptrons", "comments": null, "journal-ref": "Neurocomputing / EEG Neurocomputing 71, 7-9 (2008) 1321-1329", "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  BIC criterion is widely used by the neural-network community for model\nselection tasks, although its convergence properties are not always\ntheoretically established. In this paper we will focus on estimating the number\nof components in a mixture of multilayer perceptrons and proving the\nconvergence of the BIC criterion in this frame. The penalized\nmarginal-likelihood for mixture models and hidden Markov models introduced by\nKeribin (2000) and, respectively, Gassiat (2002) is extended to mixtures of\nmultilayer perceptrons for which a penalized-likelihood criterion is proposed.\nWe prove its convergence under some hypothesis which involve essentially the\nbracketing entropy of the generalized score-functions class and illustrate it\nby some numerical examples.\n", "versions": [{"version": "v1", "created": "Fri, 4 Apr 2008 06:58:11 GMT"}], "update_date": "2008-12-18", "authors_parsed": [["Olteanu", "Madalina", "", "CES, Samos"], ["Rynkiewicz", "Joseph", "", "CES, Samos, Matisse"]]}, {"id": "0804.0671", "submitter": "James P. Hobert", "authors": "James P. Hobert, Dobrin Marchev", "title": "A theoretical comparison of the data augmentation, marginal augmentation\n  and PX-DA algorithms", "comments": "Published in at http://dx.doi.org/10.1214/009053607000000569 the\n  Annals of Statistics (http://www.imstat.org/aos/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2008, Vol. 36, No. 2, 532-554", "doi": "10.1214/009053607000000569", "report-no": "IMS-AOS-AOS0307", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The data augmentation (DA) algorithm is a widely used Markov chain Monte\nCarlo (MCMC) algorithm that is based on a Markov transition density of the form\n$p(x|x')=\\int_{\\mathsf{Y}}f_{X|Y}(x|y)f_{Y|X}(y|x') dy$, where $f_{X|Y}$ and\n$f_{Y|X}$ are conditional densities. The PX-DA and marginal augmentation\nalgorithms of Liu and Wu [J. Amer. Statist. Assoc. 94 (1999) 1264--1274] and\nMeng and van Dyk [Biometrika 86 (1999) 301--320] are alternatives to DA that\noften converge much faster and are only slightly more computationally\ndemanding. The transition densities of these alternative algorithms can be\nwritten in the form $p_R(x|x')=\\int_{\\mathsf{Y}}\\int\n_{\\mathsf{Y}}f_{X|Y}(x|y')R(y,dy')f_{Y|X}(y|x') dy$, where $R$ is a Markov\ntransition function on $\\mathsf{Y}$. We prove that when $R$ satisfies certain\nconditions, the MCMC algorithm driven by $p_R$ is at least as good as that\ndriven by $p$ in terms of performance in the central limit theorem and in the\noperator norm sense. These results are brought to bear on a theoretical\ncomparison of the DA, PX-DA and marginal augmentation algorithms. Our focus is\non situations where the group structure exploited by Liu and Wu is available.\nWe show that the PX-DA algorithm based on Haar measure is at least as good as\nany PX-DA algorithm constructed using a proper prior on the group.\n", "versions": [{"version": "v1", "created": "Fri, 4 Apr 2008 09:27:31 GMT"}], "update_date": "2008-12-18", "authors_parsed": [["Hobert", "James P.", ""], ["Marchev", "Dobrin", ""]]}, {"id": "0804.0676", "submitter": "Arnak Dalalyan", "authors": "Arnak Dalalyan (IGM-LabInfo), Nakahiro Yoshida", "title": "Second-order asymptotic expansion for a non-synchronous covariation\n  estimator", "comments": null, "journal-ref": "Annales de l'Institut Henri Poincar\\'e (B) Probabilit\\'es et\n  Statistiques 47, 3 (2011) 748-789", "doi": "10.1214/10-AIHP383", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the problem of estimating the covariation of two\ndiffusion processes when observations are subject to non-synchronicity.\nBuilding on recent papers \\cite{Hay-Yos03, Hay-Yos04}, we derive second-order\nasymptotic expansions for the distribution of the Hayashi-Yoshida estimator in\na fairly general setup including random sampling schemes and non-anticipative\nrandom drifts. The key steps leading to our results are a second-order\ndecomposition of the estimator's distribution in the Gaussian set-up, a\nstochastic decomposition of the estimator itself and an accurate evaluation of\nthe Malliavin covariance. To give a concrete example, we compute the constants\ninvolved in the resulting expansions for the particular case of sampling scheme\ngenerated by two independent Poisson processes.\n", "versions": [{"version": "v1", "created": "Fri, 4 Apr 2008 10:00:31 GMT"}, {"version": "v2", "created": "Mon, 2 Aug 2010 12:12:03 GMT"}], "update_date": "2012-02-15", "authors_parsed": [["Dalalyan", "Arnak", "", "IGM-LabInfo"], ["Yoshida", "Nakahiro", ""]]}, {"id": "0804.0678", "submitter": "Ulrike von Luxburg", "authors": "Ulrike von Luxburg, Mikhail Belkin, Olivier Bousquet", "title": "Consistency of spectral clustering", "comments": "Published in at http://dx.doi.org/10.1214/009053607000000640 the\n  Annals of Statistics (http://www.imstat.org/aos/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2008, Vol. 36, No. 2, 555-586", "doi": "10.1214/009053607000000640", "report-no": "IMS-AOS-AOS0287", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consistency is a key property of all statistical procedures analyzing\nrandomly sampled data. Surprisingly, despite decades of work, little is known\nabout consistency of most clustering algorithms. In this paper we investigate\nconsistency of the popular family of spectral clustering algorithms, which\nclusters the data with the help of eigenvectors of graph Laplacian matrices. We\ndevelop new methods to establish that, for increasing sample size, those\neigenvectors converge to the eigenvectors of certain limit operators. As a\nresult, we can prove that one of the two major classes of spectral clustering\n(normalized clustering) converges under very general conditions, while the\nother (unnormalized clustering) is only consistent under strong additional\nassumptions, which are not always satisfied in real data. We conclude that our\nanalysis provides strong evidence for the superiority of normalized spectral\nclustering.\n", "versions": [{"version": "v1", "created": "Fri, 4 Apr 2008 10:04:44 GMT"}], "update_date": "2008-12-18", "authors_parsed": [["von Luxburg", "Ulrike", ""], ["Belkin", "Mikhail", ""], ["Bousquet", "Olivier", ""]]}, {"id": "0804.0686", "submitter": "Masahito Hayashi", "authors": "Masahito Hayashi", "title": "Discrimination of two channels by adaptive methods and its application\n  to quantum system", "comments": null, "journal-ref": "IEEE Transactions on Information Theory, Volume 55, Issue 8, 3807\n  - 3820 (2009)", "doi": "10.1109/TIT.2009.2023726", "report-no": null, "categories": "quant-ph cs.IT math.IT math.ST stat.TH", "license": "http://creativecommons.org/licenses/publicdomain/", "abstract": "  The optimal exponential error rate for adaptive discrimination of two\nchannels is discussed. In this problem, adaptive choice of input signal is\nallowed. This problem is discussed in various settings. It is proved that\nadaptive choice does not improve the exponential error rate in these settings.\nThese results are applied to quantum state discrimination.\n", "versions": [{"version": "v1", "created": "Fri, 4 Apr 2008 10:16:40 GMT"}], "update_date": "2011-06-24", "authors_parsed": [["Hayashi", "Masahito", ""]]}, {"id": "0804.0693", "submitter": "Jian Huang", "authors": "Jian Huang, Joel L. Horowitz, Shuangge Ma", "title": "Asymptotic properties of bridge estimators in sparse high-dimensional\n  regression models", "comments": "Published in at http://dx.doi.org/10.1214/009053607000000875 the\n  Annals of Statistics (http://www.imstat.org/aos/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2008, Vol. 36, No. 2, 587-613", "doi": "10.1214/009053607000000875", "report-no": "IMS-AOS-AOS0324", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the asymptotic properties of bridge estimators in sparse,\nhigh-dimensional, linear regression models when the number of covariates may\nincrease to infinity with the sample size. We are particularly interested in\nthe use of bridge estimators to distinguish between covariates whose\ncoefficients are zero and covariates whose coefficients are nonzero. We show\nthat under appropriate conditions, bridge estimators correctly select\ncovariates with nonzero coefficients with probability converging to one and\nthat the estimators of nonzero coefficients have the same asymptotic\ndistribution that they would have if the zero coefficients were known in\nadvance. Thus, bridge estimators have an oracle property in the sense of Fan\nand Li [J. Amer. Statist. Assoc. 96 (2001) 1348--1360] and Fan and Peng [Ann.\nStatist. 32 (2004) 928--961]. In general, the oracle property holds only if the\nnumber of covariates is smaller than the sample size. However, under a partial\northogonality condition in which the covariates of the zero coefficients are\nuncorrelated or weakly correlated with the covariates of nonzero coefficients,\nwe show that marginal bridge estimators can correctly distinguish between\ncovariates with nonzero and zero coefficients with probability converging to\none even when the number of covariates is greater than the sample size.\n", "versions": [{"version": "v1", "created": "Fri, 4 Apr 2008 10:59:06 GMT"}], "update_date": "2008-12-18", "authors_parsed": [["Huang", "Jian", ""], ["Horowitz", "Joel L.", ""], ["Ma", "Shuangge", ""]]}, {"id": "0804.0703", "submitter": "Sara A. van de Geer", "authors": "Sara A. van de Geer", "title": "High-dimensional generalized linear models and the lasso", "comments": "Published in at http://dx.doi.org/10.1214/009053607000000929 the\n  Annals of Statistics (http://www.imstat.org/aos/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2008, Vol. 36, No. 2, 614-645", "doi": "10.1214/009053607000000929", "report-no": "IMS-AOS-AOS0344", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider high-dimensional generalized linear models with Lipschitz loss\nfunctions, and prove a nonasymptotic oracle inequality for the empirical risk\nminimizer with Lasso penalty. The penalty is based on the coefficients in the\nlinear predictor, after normalization with the empirical norm. The examples\ninclude logistic regression, density estimation and classification with hinge\nloss. Least squares regression is also discussed.\n", "versions": [{"version": "v1", "created": "Fri, 4 Apr 2008 11:33:02 GMT"}], "update_date": "2008-12-18", "authors_parsed": [["van de Geer", "Sara A.", ""]]}, {"id": "0804.0709", "submitter": "T. Tony Cai", "authors": "Lie Wang, Lawrence D. Brown, T. Tony Cai, Michael Levine", "title": "Effect of mean on variance function estimation in nonparametric\n  regression", "comments": "Published in at http://dx.doi.org/10.1214/009053607000000901 the\n  Annals of Statistics (http://www.imstat.org/aos/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2008, Vol. 36, No. 2, 646-664", "doi": "10.1214/009053607000000901", "report-no": "IMS-AOS-AOS0340", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variance function estimation in nonparametric regression is considered and\nthe minimax rate of convergence is derived. We are particularly interested in\nthe effect of the unknown mean on the estimation of the variance function. Our\nresults indicate that, contrary to the common practice, it is not desirable to\nbase the estimator of the variance function on the residuals from an optimal\nestimator of the mean when the mean function is not smooth. Instead it is more\ndesirable to use estimators of the mean with minimal bias. On the other hand,\nwhen the mean function is very smooth, our numerical results show that the\nresidual-based method performs better, but not substantial better than the\nfirst-order-difference-based estimator. In addition our asymptotic results also\ncorrect the optimal rate claimed in Hall and Carroll [J. Roy. Statist. Soc.\nSer. B 51 (1989) 3--14].\n", "versions": [{"version": "v1", "created": "Fri, 4 Apr 2008 12:03:35 GMT"}], "update_date": "2008-12-18", "authors_parsed": [["Wang", "Lie", ""], ["Brown", "Lawrence D.", ""], ["Cai", "T. Tony", ""], ["Levine", "Michael", ""]]}, {"id": "0804.0713", "submitter": "Aurore Delaigle", "authors": "Aurore Delaigle, Peter Hall, Alexander Meister", "title": "On deconvolution with repeated measurements", "comments": "Published in at http://dx.doi.org/10.1214/009053607000000884 the\n  Annals of Statistics (http://www.imstat.org/aos/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2008, Vol. 36, No. 2, 665-685", "doi": "10.1214/009053607000000884", "report-no": "IMS-AOS-AOS0326", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a large class of statistical inverse problems it is necessary to suppose\nthat the transformation that is inverted is known. Although, in many\napplications, it is unrealistic to make this assumption, the problem is often\ninsoluble without it. However, if additional data are available, then it is\npossible to estimate consistently the unknown error density. Data are seldom\navailable directly on the transformation, but repeated, or replicated,\nmeasurements increasingly are becoming available. Such data consist of\n``intrinsic'' values that are measured several times, with errors that are\ngenerally independent. Working in this setting we treat the nonparametric\ndeconvolution problems of density estimation with observation errors, and\nregression with errors in variables. We show that, even if the number of\nrepeated measurements is quite small, it is possible for modified kernel\nestimators to achieve the same level of performance they would if the error\ndistribution were known. Indeed, density and regression estimators can be\nconstructed from replicated data so that they have the same first-order\nproperties as conventional estimators in the known-error case, without any\nreplication, but with sample size equal to the sum of the numbers of\nreplicates. Practical methods for constructing estimators with these properties\nare suggested, involving empirical rules for smoothing-parameter choice.\n", "versions": [{"version": "v1", "created": "Fri, 4 Apr 2008 12:19:05 GMT"}], "update_date": "2008-12-18", "authors_parsed": [["Delaigle", "Aurore", ""], ["Hall", "Peter", ""], ["Meister", "Alexander", ""]]}, {"id": "0804.0719", "submitter": "Ingrid Van Keilegom", "authors": "Oliver Linton, Stefan Sperlich, Ingrid Van Keilegom", "title": "Estimation of a semiparametric transformation model", "comments": "Published in at http://dx.doi.org/10.1214/009053607000000848 the\n  Annals of Statistics (http://www.imstat.org/aos/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2008, Vol. 36, No. 2, 686-718", "doi": "10.1214/009053607000000848", "report-no": "IMS-AOS-AOS0322", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes consistent estimators for transformation parameters in\nsemiparametric models. The problem is to find the optimal transformation into\nthe space of models with a predetermined regression structure like additive or\nmultiplicative separability. We give results for the estimation of the\ntransformation when the rest of the model is estimated non- or\nsemi-parametrically and fulfills some consistency conditions. We propose two\nmethods for the estimation of the transformation parameter: maximizing a\nprofile likelihood function or minimizing the mean squared distance from\nindependence. First the problem of identification of such models is discussed.\nWe then state asymptotic results for a general class of nonparametric\nestimators. Finally, we give some particular examples of nonparametric\nestimators of transformed separable models. The small sample performance is\nstudied in several simulations.\n", "versions": [{"version": "v1", "created": "Fri, 4 Apr 2008 12:43:50 GMT"}], "update_date": "2008-12-18", "authors_parsed": [["Linton", "Oliver", ""], ["Sperlich", "Stefan", ""], ["Van Keilegom", "Ingrid", ""]]}, {"id": "0804.0723", "submitter": "Ethan B. Anderes", "authors": "Ethan B. Anderes, Michael L. Stein", "title": "Estimating deformations of isotropic Gaussian random fields on the plane", "comments": "Published in at http://dx.doi.org/10.1214/009053607000000893 the\n  Annals of Statistics (http://www.imstat.org/aos/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2008, Vol. 36, No. 2, 719-741", "doi": "10.1214/009053607000000893", "report-no": "IMS-AOS-AOS0328", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new approach to the estimation of the deformation of an\nisotropic Gaussian random field on $\\mathbb{R}^2$ based on dense observations\nof a single realization of the deformed random field. Under this framework we\ninvestigate the identification and estimation of deformations. We then present\na complete methodological package--from model assumptions to algorithmic\nrecovery of the deformation--for the class of nonstationary processes obtained\nby deforming isotropic Gaussian random fields.\n", "versions": [{"version": "v1", "created": "Fri, 4 Apr 2008 13:04:02 GMT"}], "update_date": "2008-12-18", "authors_parsed": [["Anderes", "Ethan B.", ""], ["Stein", "Michael L.", ""]]}, {"id": "0804.0737", "submitter": "Theofanis Sapatinas", "authors": "Piotr Fryzlewicz, Theofanis Sapatinas, Suhasini Subba Rao", "title": "Normalized least-squares estimation in time-varying ARCH models", "comments": "Published in at http://dx.doi.org/10.1214/07-AOS510 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2008, Vol. 36, No. 2, 742-786", "doi": "10.1214/07-AOS510", "report-no": "IMS-AOS-AOS510", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the time-varying ARCH (tvARCH) process. It is shown that it\ncan be used to describe the slow decay of the sample autocorrelations of the\nsquared returns often observed in financial time series, which warrants the\nfurther study of parameter estimation methods for the model. Since the\nparameters are changing over time, a successful estimator needs to perform well\nfor small samples. We propose a kernel normalized-least-squares (kernel-NLS)\nestimator which has a closed form, and thus outperforms the previously proposed\nkernel quasi-maximum likelihood (kernel-QML) estimator for small samples. The\nkernel-NLS estimator is simple, works under mild moment assumptions and avoids\nsome of the parameter space restrictions imposed by the kernel-QML estimator.\nTheoretical evidence shows that the kernel-NLS estimator has the same rate of\nconvergence as the kernel-QML estimator. Due to the kernel-NLS estimator's ease\nof computation, computationally intensive procedures can be used. A\nprediction-based cross-validation method is proposed for selecting the\nbandwidth of the kernel-NLS estimator. Also, we use a residual-based bootstrap\nscheme to bootstrap the tvARCH process. The bootstrap sample is used to obtain\npointwise confidence intervals for the kernel-NLS estimator. It is shown that\ndistributions of the estimator using the bootstrap and the ``true'' tvARCH\nestimator asymptotically coincide. We illustrate our estimation method on a\nvariety of currency exchange and stock index data for which we obtain both good\nfits to the data and accurate forecasts.\n", "versions": [{"version": "v1", "created": "Fri, 4 Apr 2008 13:37:41 GMT"}], "update_date": "2008-12-18", "authors_parsed": [["Fryzlewicz", "Piotr", ""], ["Sapatinas", "Theofanis", ""], ["Rao", "Suhasini Subba", ""]]}, {"id": "0804.0741", "submitter": "George V. Moustakides", "authors": "George V. Moustakides", "title": "Sequential change detection revisited", "comments": "Published in at http://dx.doi.org/10.1214/009053607000000938 the\n  Annals of Statistics (http://www.imstat.org/aos/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2008, Vol. 36, No. 2, 787-807", "doi": "10.1214/009053607000000938", "report-no": "IMS-AOS-AOS0346", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In sequential change detection, existing performance measures differ\nsignificantly in the way they treat the time of change. By modeling this\nquantity as a random time, we introduce a general framework capable of\ncapturing and better understanding most well-known criteria and also propose\nnew ones. For a specific new criterion that constitutes an extension to\nLorden's performance measure, we offer the optimum structure for detecting a\nchange in the constant drift of a Brownian motion and a formula for the\ncorresponding optimum performance.\n", "versions": [{"version": "v1", "created": "Fri, 4 Apr 2008 13:58:30 GMT"}], "update_date": "2008-12-18", "authors_parsed": [["Moustakides", "George V.", ""]]}, {"id": "0804.0758", "submitter": "Yacine A\\\"{{\\i}}t-Sahalia", "authors": "Yacine A\\\"it-Sahalia", "title": "Closed-form likelihood expansions for multivariate diffusions", "comments": "Published in at http://dx.doi.org/10.1214/009053607000000622 the\n  Annals of Statistics (http://www.imstat.org/aos/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2008, Vol. 36, No. 2, 906-937", "doi": "10.1214/009053607000000622", "report-no": "IMS-AOS-AOS0303", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides closed-form expansions for the log-likelihood function of\nmultivariate diffusions sampled at discrete time intervals. The coefficients of\nthe expansion are calculated explicitly by exploiting the special structure\nafforded by the diffusion model. Examples of interest in financial statistics\nand Monte Carlo evidence are included, along with the convergence of the\nexpansion to the true likelihood function.\n", "versions": [{"version": "v1", "created": "Fri, 4 Apr 2008 15:10:50 GMT"}], "update_date": "2008-12-18", "authors_parsed": [["A\u00eft-Sahalia", "Yacine", ""]]}, {"id": "0804.0768", "submitter": "Judith Rousseau", "authors": "Antoine Chambaz, Judith Rousseau", "title": "Bounds for Bayesian order identification with application to mixtures", "comments": "Published in at http://dx.doi.org/10.1214/009053607000000857 the\n  Annals of Statistics (http://www.imstat.org/aos/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2008, Vol. 36, No. 2, 938-962", "doi": "10.1214/009053607000000857", "report-no": "IMS-AOS-AOS0311", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The efficiency of two Bayesian order estimators is studied. By using\nnonparametric techniques, we prove new underestimation and overestimation\nbounds. The results apply to various models, including mixture models. In this\ncase, the errors are shown to be $O(e^{-an})$ and $O((\\log n)^b/\\sqrt{n})$\n($a,b>0$), respectively.\n", "versions": [{"version": "v1", "created": "Fri, 4 Apr 2008 15:28:45 GMT"}], "update_date": "2008-12-18", "authors_parsed": [["Chambaz", "Antoine", ""], ["Rousseau", "Judith", ""]]}, {"id": "0804.0819", "submitter": "Namrata Vaswani", "authors": "Namrata Vaswani", "title": "Kalman Filtered Compressed Sensing", "comments": "A slightly shorter version submitted to IEEE Intl. Conf. Image Proc.\n  (ICIP) 2008. (5 pages, 1 figure)", "journal-ref": null, "doi": "10.1109/ICIP.2008.4711899", "report-no": null, "categories": "cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of reconstructing time sequences of spatially sparse\nsignals (with unknown and time-varying sparsity patterns) from a limited number\nof linear \"incoherent\" measurements, in real-time. The signals are sparse in\nsome transform domain referred to as the sparsity basis. For a single spatial\nsignal, the solution is provided by Compressed Sensing (CS). The question that\nwe address is, for a sequence of sparse signals, can we do better than CS, if\n(a) the sparsity pattern of the signal's transform coefficients' vector changes\nslowly over time, and (b) a simple prior model on the temporal dynamics of its\ncurrent non-zero elements is available. The overall idea of our solution is to\nuse CS to estimate the support set of the initial signal's transform vector. At\nfuture times, run a reduced order Kalman filter with the currently estimated\nsupport and estimate new additions to the support set by applying CS to the\nKalman innovations or filtering error (whenever it is \"large\").\n", "versions": [{"version": "v1", "created": "Fri, 4 Apr 2008 22:56:33 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Vaswani", "Namrata", ""]]}, {"id": "0804.0987", "submitter": "Dongchu Sun", "authors": "James O. Berger, Dongchu Sun", "title": "Objective priors for the bivariate normal model", "comments": "Published in at http://dx.doi.org/10.1214/07-AOS501 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2008, Vol. 36, No. 2, 963-982", "doi": "10.1214/07-AOS501", "report-no": "IMS-AOS-AOS501", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Study of the bivariate normal distribution raises the full range of issues\ninvolving objective Bayesian inference, including the different types of\nobjective priors (e.g., Jeffreys, invariant, reference, matching), the\ndifferent modes of inference (e.g., Bayesian, frequentist, fiducial) and the\ncriteria involved in deciding on optimal objective priors (e.g., ease of\ncomputation, frequentist performance, marginalization paradoxes). Summary\nrecommendations as to optimal objective priors are made for a variety of\ninferences involving the bivariate normal distribution. In the course of the\ninvestigation, a variety of surprising results were found, including the\navailability of objective priors that yield exact frequentist inferences for\nmany functions of the bivariate normal parameters, including the correlation\ncoefficient.\n", "versions": [{"version": "v1", "created": "Mon, 7 Apr 2008 08:54:56 GMT"}], "update_date": "2008-12-18", "authors_parsed": [["Berger", "James O.", ""], ["Sun", "Dongchu", ""]]}, {"id": "0804.0991", "submitter": "Marianthi Markatou", "authors": "Bruce G. Lindsay, Marianthi Markatou, Surajit Ray, Ke Yang, Shu-Chuan\n  Chen", "title": "Quadratic distances on probabilities: A unified foundation", "comments": "Published in at http://dx.doi.org/10.1214/009053607000000956 the\n  Annals of Statistics (http://www.imstat.org/aos/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2008, Vol. 36, No. 2, 983-1006", "doi": "10.1214/009053607000000956", "report-no": "IMS-AOS-AOS0330", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work builds a unified framework for the study of quadratic form distance\nmeasures as they are used in assessing the goodness of fit of models. Many\nimportant procedures have this structure, but the theory for these methods is\ndispersed and incomplete. Central to the statistical analysis of these\ndistances is the spectral decomposition of the kernel that generates the\ndistance. We show how this determines the limiting distribution of natural\ngoodness-of-fit tests. Additionally, we develop a new notion, the spectral\ndegrees of freedom of the test, based on this decomposition. The degrees of\nfreedom are easy to compute and estimate, and can be used as a guide in the\nconstruction of useful procedures in this class.\n", "versions": [{"version": "v1", "created": "Mon, 7 Apr 2008 09:23:06 GMT"}], "update_date": "2008-12-18", "authors_parsed": [["Lindsay", "Bruce G.", ""], ["Markatou", "Marianthi", ""], ["Ray", "Surajit", ""], ["Yang", "Ke", ""], ["Chen", "Shu-Chuan", ""]]}, {"id": "0804.1001", "submitter": "Zhengjun Zhang", "authors": "Zhengjun Zhang", "title": "Quotient correlation: A sample based alternative to Pearson's\n  correlation", "comments": "Published in at http://dx.doi.org/10.1214/009053607000000866 the\n  Annals of Statistics (http://www.imstat.org/aos/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2008, Vol. 36, No. 2, 1007-1030", "doi": "10.1214/009053607000000866", "report-no": "IMS-AOS-AOS0320", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The quotient correlation is defined here as an alternative to Pearson's\ncorrelation that is more intuitive and flexible in cases where the tail\nbehavior of data is important. It measures nonlinear dependence where the\nregular correlation coefficient is generally not applicable. One of its most\nuseful features is a test statistic that has high power when testing nonlinear\ndependence in cases where the Fisher's $Z$-transformation test may fail to\nreach a right conclusion. Unlike most asymptotic test statistics, which are\neither normal or $\\chi^2$, this test statistic has a limiting gamma\ndistribution (henceforth, the gamma test statistic). More than the common\nusages of correlation, the quotient correlation can easily and intuitively be\nadjusted to values at tails. This adjustment generates two new concepts--the\ntail quotient correlation and the tail independence test statistics, which are\nalso gamma statistics. Due to the fact that there is no analogue of the\ncorrelation coefficient in extreme value theory, and there does not exist an\nefficient tail independence test statistic, these two new concepts may open up\na new field of study. In addition, an alternative to Spearman's rank\ncorrelation, a rank based quotient correlation, is also defined. The advantages\nof using these new concepts are illustrated with simulated data and a real data\nanalysis of internet traffic.\n", "versions": [{"version": "v1", "created": "Mon, 7 Apr 2008 09:51:05 GMT"}], "update_date": "2008-12-18", "authors_parsed": [["Zhang", "Zhengjun", ""]]}, {"id": "0804.1030", "submitter": "Alberto Gandolfi", "authors": "L. Cecconi, A. Gandolfi, C. C. A. Sastri", "title": "A New Estimator for the Number of Species in a Population", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP math.PR math.ST q-bio.QM stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the classic problem of estimating T, the total number of species\nin a population, from repeated counts in a simple random sample. We look first\nat the Chao-Lee estimator: we initially show that such estimator can be\nobtained by reconciling two estimators of the unobserved probability, and then\ndevelop a sequence of improvements culminating in a Dirichlet prior Bayesian\nreinterpretation of the estimation problem. By means of this, we obtain\nsimultaneous estimates of T, of the normalized interspecies variance $\\gamma^2$\nand of the parameter $\\lambda$ of the prior. Several simulations show that our\nestimation method is more flexible than several known methods we used as\ncomparison; the only limitation, apparently shared by all other methods, seems\nto be that it cannot deal with the rare cases in which $\\gamma^2 >1$\n", "versions": [{"version": "v1", "created": "Mon, 7 Apr 2008 14:27:49 GMT"}], "update_date": "2008-04-09", "authors_parsed": [["Cecconi", "L.", ""], ["Gandolfi", "A.", ""], ["Sastri", "C. C. A.", ""]]}, {"id": "0804.1038", "submitter": "Sofia Olhede Professor", "authors": "Heidi Hindberg and Sofia C. Olhede", "title": "Estimation of Ambiguity Functions With Limited Spread", "comments": "various small changes", "journal-ref": null, "doi": null, "report-no": "Stat Sci 293", "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a new estimation procedure for the ambiguity function of\na non-stationary time series. The stochastic properties of the empirical\nambiguity function calculated from a single sample in time are derived.\nDifferent thresholding procedures are introduced for the estimation of the\nambiguity function. Such estimation methods are suitable if the ambiguity\nfunction is only non-negligible in a limited region of the ambiguity plane. The\nthresholds of the procedures are formally derived for each point in the plane,\nand methods for the estimation of nuisance parameters that the thresholds\ndepend on are proposed. The estimation method is tested on several signals, and\nreductions in mean square error when estimating the ambiguity function by\nfactors of over a hundred are obtained. An estimator of the spread of the\nambiguity function is proposed.\n", "versions": [{"version": "v1", "created": "Mon, 7 Apr 2008 14:24:37 GMT"}, {"version": "v2", "created": "Fri, 21 Aug 2009 16:12:49 GMT"}], "update_date": "2009-08-21", "authors_parsed": [["Hindberg", "Heidi", ""], ["Olhede", "Sofia C.", ""]]}, {"id": "0804.1039", "submitter": "Enno Veerman", "authors": "Peter Spreij, Enno Veerman, Peter Vlaar", "title": "Multivariate Feller conditions in term structure models: Why do(n't) we\n  care?", "comments": "19 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST math.PR math.ST q-fin.CP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the relevance of the Feller conditions in discrete time\nmacro-finance term structure models is investigated. The Feller conditions are\nusually imposed on a continuous time multivariate square root process to ensure\nthat the roots have nonnegative arguments. For a discrete time approximate\nmodel, the Feller conditions do not give this guarantee. Moreover, in a\nmacro-finance context the restrictions imposed might be economically\nunappealing. At the same time, it has also been observed that even without the\nFeller conditions imposed, for a practically relevant term structure model,\nnegative arguments rarely occur. Using models estimated on German data, we\ncompare the yields implied by (approximate) analytic exponentially affine\nexpressions to those obtained through Monte Carlo simulations of very high\nnumbers of sample paths. It turns out that the differences are rarely\nstatistically significant, whether the Feller conditions are imposed or not.\nMoreover, economically the differences are negligible, as they are always below\none basis point.\n", "versions": [{"version": "v1", "created": "Mon, 7 Apr 2008 14:48:28 GMT"}], "update_date": "2008-12-02", "authors_parsed": [["Spreij", "Peter", ""], ["Veerman", "Enno", ""], ["Vlaar", "Peter", ""]]}, {"id": "0804.1040", "submitter": "Alessandra Luati", "authors": "Alessandra Luati, Tommaso Proietti", "title": "On the Spectral Properties of Matrices Associated with Trend Filters", "comments": null, "journal-ref": null, "doi": null, "report-no": "IMS-EJS-EJS_2008_221", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is concerned with the spectral properties of matrices associated\nwith linear filters for the estimation of the underlying trend of a time\nseries. The interest lies in the fact that the eigenvectors can be interpreted\nas the latent components of any time series that the filter smooths through the\ncorresponding eigenvalues. A difficulty arises because matrices associated with\ntrend filters are finite approximations of Toeplitz operators and therefore\nvery little is known about their eigenstructure, which also depends on the\nboundary conditions or, equivalently, on the filters for trend estimation at\nthe end of the sample. Assuming reflecting boundary conditions, we derive a\ntime series decomposition in terms of periodic latent components and\ncorresponding smoothing eigenvalues. This decomposition depends on the local\npolynomial regression estimator chosen for the interior. Otherwise, the\neigenvalue distribution is derived with an approximation measured by the size\nof the perturbation that different boundary conditions apport to the\neigenvalues of matrices belonging to algebras with known spectral properties,\nsuch as the Circulant or the Cosine. The analytical form of the eigenvectors is\nthen derived with an approximation that involves the extremes only. A further\ntopic investigated in the paper concerns a strategy for a filter design in the\ntime domain. Based on cut-off eigenvalues, new estimators are derived, that are\nless variable and almost equally biased as the original estimator, based on all\nthe eigenvalues. Empirical examples illustrate the effectiveness of the method.\n", "versions": [{"version": "v1", "created": "Mon, 7 Apr 2008 14:31:30 GMT"}, {"version": "v2", "created": "Fri, 23 May 2008 15:38:25 GMT"}], "update_date": "2008-12-18", "authors_parsed": [["Luati", "Alessandra", ""], ["Proietti", "Tommaso", ""]]}, {"id": "0804.1056", "submitter": "Cristina Butucea", "authors": "Cristina Butucea, Catherine Matias, Christophe Pouet", "title": "Adaptivity in convolution models with partially known noise distribution", "comments": "Published in at http://dx.doi.org/10.1214/08-EJS225 the Electronic\n  Journal of Statistics (http://www.i-journals.org/ejs/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Electronic Journal of Statistics 2008, Vol. 2, 897-915", "doi": "10.1214/08-EJS225", "report-no": "IMS-EJS-EJS_2008_225", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a semiparametric convolution model. We observe random variables\nhaving a distribution given by the convolution of some unknown density $f$ and\nsome partially known noise density $g$. In this work, $g$ is assumed\nexponentially smooth with stable law having unknown self-similarity index $s$.\nIn order to ensure identifiability of the model, we restrict our attention to\npolynomially smooth, Sobolev-type densities $f$, with smoothness parameter\n$\\beta$. In this context, we first provide a consistent estimation procedure\nfor $s$. This estimator is then plugged-into three different procedures:\nestimation of the unknown density $f$, of the functional $\\int f^2$ and\ngoodness-of-fit test of the hypothesis $H_0:f=f_0$, where the alternative $H_1$\nis expressed with respect to $\\mathbb {L}_2$-norm (i.e. has the form\n$\\psi_n^{-2}\\|f-f_0\\|_2^2\\ge \\mathcal{C}$). These procedures are adaptive with\nrespect to both $s$ and $\\beta$ and attain the rates which are known optimal\nfor known values of $s$ and $\\beta$. As a by-product, when the noise density is\nknown and exponentially smooth our testing procedure is optimal adaptive for\ntesting Sobolev-type densities. The estimating procedure of $s$ is illustrated\non synthetic data.\n", "versions": [{"version": "v1", "created": "Mon, 7 Apr 2008 15:11:34 GMT"}, {"version": "v2", "created": "Fri, 3 Oct 2008 13:33:53 GMT"}], "update_date": "2008-10-03", "authors_parsed": [["Butucea", "Cristina", ""], ["Matias", "Catherine", ""], ["Pouet", "Christophe", ""]]}, {"id": "0804.1143", "submitter": "Jie Yang", "authors": "Zhishen Ye and Jie Yang", "title": "Sliced Inverse Moment Regression Using Weighted Chi-Squared Tests for\n  Dimension Reduction", "comments": "30 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new method for dimension reduction in regression using the first\ntwo inverse moments. We develop corresponding weighted chi-squared tests for\nthe dimension of the regression. The proposed method considers linear\ncombinations of Sliced Inverse Regression (SIR) and the method using a new\ncandidate matrix which is designed to recover the entire inverse second moment\nsubspace. The optimal combination may be selected based on the p-values derived\nfrom the dimension tests. Theoretically, the proposed method, as well as Sliced\nAverage Variance Estimate (SAVE), are more capable of recovering the complete\ncentral dimension reduction subspace than SIR and Principle Hessian Directions\n(pHd). Therefore it can substitute for SIR, pHd, SAVE, or any linear\ncombination of them at a theoretical level. Simulation study indicates that the\nproposed method may have consistently greater power than SIR, pHd, and SAVE.\n", "versions": [{"version": "v1", "created": "Mon, 7 Apr 2008 20:50:53 GMT"}, {"version": "v2", "created": "Fri, 10 Apr 2009 13:30:34 GMT"}, {"version": "v3", "created": "Sat, 24 Aug 2013 16:22:18 GMT"}], "update_date": "2013-08-27", "authors_parsed": [["Ye", "Zhishen", ""], ["Yang", "Jie", ""]]}, {"id": "0804.1181", "submitter": "Leonid Gurvits", "authors": "Leonid Gurvits", "title": "A short, based on the mixed volume, proof of Liggett's theorem on the\n  convolution of ultra-logconcave sequences", "comments": "4 pages; short and easy", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  R. Pemantle conjectured, and T.M. Liggett proved in 1997, that the\nconvolution of two ultra-logconcave is ultra-logconcave. Liggett's proof is\nelementary but long. We present here a short proof, based on the mixed volume\nof convex sets.\n", "versions": [{"version": "v1", "created": "Tue, 8 Apr 2008 04:22:57 GMT"}], "update_date": "2008-04-10", "authors_parsed": [["Gurvits", "Leonid", ""]]}, {"id": "0804.1189", "submitter": "Alain Celisse", "authors": "Alain Celisse, St\\'ephane Robin", "title": "A leave-p-out based estimation of the proportion of null hypotheses", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the multiple testing context, a challenging problem is the estimation of\nthe proportion $\\pi_0$ of true-null hypotheses. A large number of estimators of\nthis quantity rely on identifiability assumptions that either appear to be\nviolated on real data, or may be at least relaxed. Under independence, we\npropose an estimator $\\hat{\\pi}_0$ based on density estimation using both\nhistograms and cross-validation. Due to the strong connection between the false\ndiscovery rate (FDR) and $\\pi_0$, many multiple testing procedures (MTP)\ndesigned to control the FDR may be improved by introducing an estimator of\n$\\pi_0$. We provide an example of such an improvement (plug-in MTP) based on\nthe procedure of Benjamini and Hochberg. Asymptotic optimality results may be\nderived for both $\\hat{\\pi}_0$ and the resulting plug-in procedure. The latter\nensures the desired asymptotic control of the FDR, while it is more powerful\nthan the BH-procedure. Finally, we compare our estimator of $\\pi_0$ with other\nwidespread estimators in a wide range of simulations. We obtain better results\nthan other tested methods in terms of mean square error (MSE) of the proposed\nestimator. Finally, both asymptotic optimality results and the interest in\ntightly estimating $\\pi_0$ are confirmed (empirically) by results obtained with\nthe plug-in MTP.\n", "versions": [{"version": "v1", "created": "Tue, 8 Apr 2008 06:58:28 GMT"}], "update_date": "2008-12-18", "authors_parsed": [["Celisse", "Alain", ""], ["Robin", "St\u00e9phane", ""]]}, {"id": "0804.1302", "submitter": "Francis Bach", "authors": "Francis Bach (INRIA Rocquencourt)", "title": "Bolasso: model consistent Lasso estimation through the bootstrap", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the least-square linear regression problem with regularization by\nthe l1-norm, a problem usually referred to as the Lasso. In this paper, we\npresent a detailed asymptotic analysis of model consistency of the Lasso. For\nvarious decays of the regularization parameter, we compute asymptotic\nequivalents of the probability of correct model selection (i.e., variable\nselection). For a specific rate decay, we show that the Lasso selects all the\nvariables that should enter the model with probability tending to one\nexponentially fast, while it selects all other variables with strictly positive\nprobability. We show that this property implies that if we run the Lasso for\nseveral bootstrapped replications of a given sample, then intersecting the\nsupports of the Lasso bootstrap estimates leads to consistent model selection.\nThis novel variable selection algorithm, referred to as the Bolasso, is\ncompared favorably to other linear regression methods on synthetic data and\ndatasets from the UCI machine learning repository.\n", "versions": [{"version": "v1", "created": "Tue, 8 Apr 2008 15:40:03 GMT"}], "update_date": "2008-12-18", "authors_parsed": [["Bach", "Francis", "", "INRIA Rocquencourt"]]}, {"id": "0804.1392", "submitter": "Xinjia Chen", "authors": "Xinjia Chen", "title": "Coverage Probability of Wald Interval for Binomial Parameters", "comments": "4 pages, no figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we develop an exact method for computing the minimum coverage\nprobability of Wald interval for estimation of binomial parameters. Similar\napproach can be used for other type of confidence intervals.\n", "versions": [{"version": "v1", "created": "Wed, 9 Apr 2008 02:07:36 GMT"}, {"version": "v2", "created": "Fri, 30 Jan 2009 17:34:22 GMT"}], "update_date": "2009-01-30", "authors_parsed": [["Chen", "Xinjia", ""]]}, {"id": "0804.1393", "submitter": "Xinjia Chen", "authors": "Xinjia Chen", "title": "Optimal Explicit Binomial Confidence Interval with Guaranteed Coverage\n  Probability", "comments": "6 pages, no figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we develop an approach for optimizing the explicit binomial\nconfidence interval recently derived by Chen et al. The optimization reduces\nconservativeness while guaranteeing prescribed coverage probability.\n", "versions": [{"version": "v1", "created": "Wed, 9 Apr 2008 02:14:49 GMT"}, {"version": "v2", "created": "Fri, 30 Jan 2009 17:38:08 GMT"}], "update_date": "2009-01-30", "authors_parsed": [["Chen", "Xinjia", ""]]}, {"id": "0804.1399", "submitter": "Xinjia Chen", "authors": "Xinjia Chen", "title": "On Estimation and Optimization of Mean Values of Bounded Variables", "comments": "10 pages, no figure. Generalized to the case of bounded variables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we develop a general approach for probabilistic estimation and\noptimization. An explicit formula and a computational approach are established\nfor controlling the reliability of probabilistic estimation based on a mixed\ncriterion of absolute and relative errors. By employing the Chernoff-Hoeffding\nbound and the concept of sampling, the minimization of a probabilistic function\nis transformed into an optimization problem amenable for gradient descendent\nalgorithms.\n", "versions": [{"version": "v1", "created": "Wed, 9 Apr 2008 02:43:46 GMT"}, {"version": "v2", "created": "Fri, 18 Apr 2008 15:03:56 GMT"}, {"version": "v3", "created": "Tue, 4 Dec 2012 21:24:52 GMT"}], "update_date": "2012-12-06", "authors_parsed": [["Chen", "Xinjia", ""]]}, {"id": "0804.1584", "submitter": "Gregory Thureau", "authors": "Leonid Galtchouk (IRMA), Serguey Pergamenshchikov (LMRS)", "title": "Adaptive nonparametric estimation in heteroscedastic regression models.\n  Part 2: Asymptotic efficiency", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper deals with asymptotic properties of the adaptive procedure proposed\nin the author paper (2007) for estimation of unknown nonparametric regression.\nWe prove that this procedure is asymptotically efficient for a quadratic risk.\nIt means that the asymptotic quadratic risk for this procedure coincides with a\nsharp lower bound.\n", "versions": [{"version": "v1", "created": "Thu, 10 Apr 2008 14:10:07 GMT"}], "update_date": "2008-12-18", "authors_parsed": [["Galtchouk", "Leonid", "", "IRMA"], ["Pergamenshchikov", "Serguey", "", "LMRS"]]}, {"id": "0804.1653", "submitter": "Mario Figueiredo", "authors": "Andre Martins, Pedro Aguiar, Mario Figueiredo", "title": "Nonextensive Generalizations of the Jensen-Shannon Divergence", "comments": "Submitted to the IEEE Transactions on Information Theory", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convexity is a key concept in information theory, namely via the many\nimplications of Jensen's inequality, such as the non-negativity of the\nKullback-Leibler divergence (KLD). Jensen's inequality also underlies the\nconcept of Jensen-Shannon divergence (JSD), which is a symmetrized and smoothed\nversion of the KLD. This paper introduces new JSD-type divergences, by\nextending its two building blocks: convexity and Shannon's entropy. In\nparticular, a new concept of q-convexity is introduced and shown to satisfy a\nJensen's q-inequality. Based on this Jensen's q-inequality, the Jensen-Tsallis\nq-difference is built, which is a nonextensive generalization of the JSD, based\non Tsallis entropies. Finally, the Jensen-Tsallis q-difference is charaterized\nin terms of convexity and extrema.\n", "versions": [{"version": "v1", "created": "Thu, 10 Apr 2008 09:48:56 GMT"}], "update_date": "2008-04-11", "authors_parsed": [["Martins", "Andre", ""], ["Aguiar", "Pedro", ""], ["Figueiredo", "Mario", ""]]}, {"id": "0804.1715", "submitter": "Gregory Thureau", "authors": "Leonid Galtchouk (IRMA), Serguey Pergamenshchikov (LMRS)", "title": "Adaptive sequential estimation for ergodic diffusion processes in\n  quadratic metric. Part 2: Asymptotic efficiency", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Asymptotic efficiency is proved for the constructed in part 1 procedure, i.e.\nPinsker's constant is found in the asymptotic lower bound for the minimax\nquadratic risk. It is shown that the asymptotic minimax quadratic risk of the\nconstructed procedure coincides with this constant.\n", "versions": [{"version": "v1", "created": "Thu, 10 Apr 2008 14:09:12 GMT"}], "update_date": "2008-12-18", "authors_parsed": [["Galtchouk", "Leonid", "", "IRMA"], ["Pergamenshchikov", "Serguey", "", "LMRS"]]}, {"id": "0804.1716", "submitter": "Gregory Thureau", "authors": "Leonid Galtchouk (IRMA), Serguey Pergamenshchikov (LMRS)", "title": "Adaptive nonparametric estimation in heteroscedastic regression models.\n  Part 1: Sharp non-asymptotic Oracle inequalities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An adaptive nonparametric estimation procedure is constructed for the\nestimation problem of heteroscedastic regression when the noise variance\ndepends on the unknown regression. A non-asymptotic upper bound for a quadratic\nrisk (an oracle inequality) is constructed.\n", "versions": [{"version": "v1", "created": "Thu, 10 Apr 2008 14:09:46 GMT"}], "update_date": "2008-12-18", "authors_parsed": [["Galtchouk", "Leonid", "", "IRMA"], ["Pergamenshchikov", "Serguey", "", "LMRS"]]}, {"id": "0804.1905", "submitter": "Tomi Zivko", "authors": "Tomaz Podobnik and Tomi Zivko", "title": "On Probabilistic Parametric Inference", "comments": "23 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An objective operational theory of probabilistic parametric inference is\nformulated without invoking the so-called non-informative prior probability\ndistributions.\n", "versions": [{"version": "v1", "created": "Fri, 11 Apr 2008 14:08:07 GMT"}], "update_date": "2008-04-14", "authors_parsed": [["Podobnik", "Tomaz", ""], ["Zivko", "Tomi", ""]]}, {"id": "0804.2138", "submitter": "Alexey Koloydenko", "authors": "J. Lember, A. Koloydenko", "title": "A constructive proof of the existence of Viterbi processes", "comments": "Submitted to the IEEE Transactions on Information Theory, focuses on\n  the proofs of the results presented in arXiv:0709.2317, and arXiv:0803.2394", "journal-ref": "IEEE Transactions on Information Theory, volume 56, issue 4, 2010,\n  pages 2017 - 2033", "doi": "10.1109/TIT.2010.2040897", "report-no": null, "categories": "math.ST cs.IT math.IT math.PR stat.CO stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since the early days of digital communication, hidden Markov models (HMMs)\nhave now been also routinely used in speech recognition, processing of natural\nlanguages, images, and in bioinformatics. In an HMM $(X_i,Y_i)_{i\\ge 1}$,\nobservations $X_1,X_2,...$ are assumed to be conditionally independent given an\n``explanatory'' Markov process $Y_1,Y_2,...$, which itself is not observed;\nmoreover, the conditional distribution of $X_i$ depends solely on $Y_i$.\nCentral to the theory and applications of HMM is the Viterbi algorithm to find\n{\\em a maximum a posteriori} (MAP) estimate $q_{1:n}=(q_1,q_2,...,q_n)$ of\n$Y_{1:n}$ given observed data $x_{1:n}$. Maximum {\\em a posteriori} paths are\nalso known as Viterbi paths or alignments. Recently, attempts have been made to\nstudy the behavior of Viterbi alignments when $n\\to \\infty$. Thus, it has been\nshown that in some special cases a well-defined limiting Viterbi alignment\nexists. While innovative, these attempts have relied on rather strong\nassumptions and involved proofs which are existential. This work proves the\nexistence of infinite Viterbi alignments in a more constructive manner and for\na very general class of HMMs.\n", "versions": [{"version": "v1", "created": "Mon, 14 Apr 2008 18:31:18 GMT"}], "update_date": "2012-07-24", "authors_parsed": [["Lember", "J.", ""], ["Koloydenko", "A.", ""]]}, {"id": "0804.2310", "submitter": "Vyacheslav Abramov M.", "authors": "Vyacheslav M. Abramov", "title": "Bounds for the loss probability in large loss queueing systems", "comments": "27 pages, double spaced, completely rewritten", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $\\mathcal{G}(\\frak{g}_1,\\frak{g}_2)$ be the class of all probability\ndistribution functions of positive random variables having the given first two\nmoments $\\frak{g}_1$ and $\\frak{g}_2$. Let $G_1(x)$ and $G_2(x)$ be two\nprobability distribution functions of this class satisfying the condition\n$|G_1(x)-G_2(x)|<\\epsilon$ for some small positive value $\\epsilon$ and let\n$\\widehat{G}_1(s)$ and, respectively, $\\widehat{G}_2(s)$ denote their\nLaplace-Stieltjes transforms. For real $\\mu$ satisfying $\\mu\\frak{g}_1>1$ let\nus denote by $\\gamma_{G_1}$ and $\\gamma_{G_2}$ the least positive roots of the\nequations $z=\\widehat{G}_1(\\mu-\\mu z)$ and $z=\\widehat{G}_2(\\mu-\\mu z)$\nrespectively. In the paper, the upper bound for $|\\gamma_{G_1}-\\gamma_{G_2}|$\nis derived. This upper bound is then used to find lower and upper bounds for\nthe loss probabilities in different large loss queueing systems.\n", "versions": [{"version": "v1", "created": "Tue, 15 Apr 2008 05:14:43 GMT"}, {"version": "v2", "created": "Wed, 15 Oct 2008 05:47:15 GMT"}, {"version": "v3", "created": "Mon, 9 Mar 2009 04:42:39 GMT"}, {"version": "v4", "created": "Thu, 16 Apr 2009 23:01:24 GMT"}, {"version": "v5", "created": "Fri, 29 May 2009 22:30:52 GMT"}, {"version": "v6", "created": "Tue, 3 Nov 2009 04:17:07 GMT"}, {"version": "v7", "created": "Thu, 19 Nov 2009 23:32:26 GMT"}], "update_date": "2009-11-20", "authors_parsed": [["Abramov", "Vyacheslav M.", ""]]}, {"id": "0804.2434", "submitter": "Katia Meziani", "authors": "Jean-Marie Aubry (LAMA), Cristina Butucea (LPP), Katia M\\'eziani (PMA)", "title": "State estimation in quantum homodyne tomography with noisy data", "comments": null, "journal-ref": null, "doi": "10.1088/0266-5611/25/1/015003", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the framework of noisy quantum homodyne tomography with efficiency\nparameter $0 < \\eta \\leq 1$, we propose two estimators of a quantum state whose\ndensity matrix elements $\\rho_{m,n}$ decrease like $e^{-B(m+n)^{r/ 2}}$, for\nfixed known $B>0$ and $0<r\\leq 2$. The first procedure estimates the matrix\ncoefficients by a projection method on the pattern functions (that we introduce\nhere for $0<\\eta \\leq 1/2$), the second procedure is a kernel estimator of the\nassociated Wigner function. We compute the convergence rates of these\nestimators, in $\\mathbb{L}_2$ risk.\n", "versions": [{"version": "v1", "created": "Tue, 15 Apr 2008 17:06:37 GMT"}, {"version": "v2", "created": "Sat, 26 Jul 2008 12:06:14 GMT"}], "update_date": "2009-11-13", "authors_parsed": [["Aubry", "Jean-Marie", "", "LAMA"], ["Butucea", "Cristina", "", "LPP"], ["M\u00e9ziani", "Katia", "", "PMA"]]}, {"id": "0804.2733", "submitter": "Yang Xing", "authors": "Yang Xing", "title": "Convergence Rates of Nonparametric Posterior Distributions", "comments": "22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the asymptotic behavior of posterior distributions. We present\ngeneral posterior convergence rate theorems, which extend several results on\nposterior convergence rates provided by Ghosal and Van der Vaart (2000), Shen\nand Wasserman (2001) and Walker, Lijor and Prunster (2007). Our main tools are\nthe Hausdorff $\\alpha$-entropy introduced by Xing and Ranneby (2008) and a new\nnotion of prior concentration, which is a slight improvement of the usual prior\nconcentration provided by Ghosal and Van der Vaart (2000). We apply our results\nto several statistical models.\n", "versions": [{"version": "v1", "created": "Thu, 17 Apr 2008 07:41:20 GMT"}], "update_date": "2008-04-18", "authors_parsed": [["Xing", "Yang", ""]]}, {"id": "0804.2937", "submitter": "Sylvain Arlot", "authors": "Sylvain Arlot, Peter L. Bartlett", "title": "Margin-adaptive model selection in statistical learning", "comments": "Published in at http://dx.doi.org/10.3150/10-BEJ288 the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 17, 2 (2011) 687-713", "doi": "10.3150/10-BEJ288", "report-no": "IMS-BEJ-BEJ288", "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A classical condition for fast learning rates is the margin condition, first\nintroduced by Mammen and Tsybakov. We tackle in this paper the problem of\nadaptivity to this condition in the context of model selection, in a general\nlearning framework. Actually, we consider a weaker version of this condition\nthat allows one to take into account that learning within a small model can be\nmuch easier than within a large one. Requiring this \"strong margin adaptivity\"\nmakes the model selection problem more challenging. We first prove, in a\ngeneral framework, that some penalization procedures (including local\nRademacher complexities) exhibit this adaptivity when the models are nested.\nContrary to previous results, this holds with penalties that only depend on the\ndata. Our second main result is that strong margin adaptivity is not always\npossible when the models are not nested: for every model selection procedure\n(even a randomized one), there is a problem for which it does not demonstrate\nstrong margin adaptivity.\n", "versions": [{"version": "v1", "created": "Fri, 18 Apr 2008 04:24:42 GMT"}, {"version": "v2", "created": "Mon, 8 Feb 2010 07:57:36 GMT"}, {"version": "v3", "created": "Fri, 22 Apr 2011 07:32:12 GMT"}], "update_date": "2011-05-02", "authors_parsed": [["Arlot", "Sylvain", ""], ["Bartlett", "Peter L.", ""]]}, {"id": "0804.3010", "submitter": "Yonina C. Eldar", "authors": "Yonina C. Eldar", "title": "Generalized SURE for Exponential Families: Applications to\n  Regularization", "comments": "to appear in the IEEE Transactions on Signal Processing", "journal-ref": null, "doi": "10.1109/TSP.2008.2008212", "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stein's unbiased risk estimate (SURE) was proposed by Stein for the\nindependent, identically distributed (iid) Gaussian model in order to derive\nestimates that dominate least-squares (LS). In recent years, the SURE criterion\nhas been employed in a variety of denoising problems for choosing\nregularization parameters that minimize an estimate of the mean-squared error\n(MSE). However, its use has been limited to the iid case which precludes many\nimportant applications. In this paper we begin by deriving a SURE counterpart\nfor general, not necessarily iid distributions from the exponential family.\nThis enables extending the SURE design technique to a much broader class of\nproblems. Based on this generalization we suggest a new method for choosing\nregularization parameters in penalized LS estimators. We then demonstrate its\nsuperior performance over the conventional generalized cross validation\napproach and the discrepancy method in the context of image deblurring and\ndeconvolution. The SURE technique can also be used to design estimates without\npredefining their structure. However, allowing for too many free parameters\nimpairs the performance of the resulting estimates. To address this inherent\ntradeoff we propose a regularized SURE objective. Based on this design\ncriterion, we derive a wavelet denoising strategy that is similar in sprit to\nthe standard soft-threshold approach but can lead to improved MSE performance.\n", "versions": [{"version": "v1", "created": "Mon, 14 Apr 2008 20:48:46 GMT"}, {"version": "v2", "created": "Mon, 21 Apr 2008 18:34:19 GMT"}], "update_date": "2009-11-13", "authors_parsed": [["Eldar", "Yonina C.", ""]]}, {"id": "0804.3033", "submitter": "Xinjia Chen", "authors": "Xinjia Chen", "title": "A Simple Sample Size Formula for Estimating Means of Poisson Random\n  Variables", "comments": "6 pages, nofigure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we derive an explicit sample size formula based a mixed\ncriterion of absolute and relative errors for estimating means of Poisson\nrandom variables.\n", "versions": [{"version": "v1", "created": "Fri, 18 Apr 2008 14:57:05 GMT"}], "update_date": "2008-04-21", "authors_parsed": [["Chen", "Xinjia", ""]]}, {"id": "0804.3037", "submitter": "Nicolas Fournier", "authors": "Nicolas Fournier, Jacques Printems", "title": "Absolute continuity for some one-dimensional processes", "comments": "Published in at http://dx.doi.org/10.3150/09-BEJ215 the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2010, Vol. 16, No. 2, 343-360", "doi": "10.3150/09-BEJ215", "report-no": "IMS-BEJ-BEJ215", "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an elementary method for proving the absolute continuity of the\ntime marginals of one-dimensional processes. It is based on a comparison\nbetween the Fourier transform of such time marginals with those of the one-step\nEuler approximation of the underlying process. We obtain some absolute\ncontinuity results for stochastic differential equations with H\\\"{o}lder\ncontinuous coefficients. Furthermore, we allow such coefficients to be random\nand to depend on the whole path of the solution. We also show how it can be\nextended to some stochastic partial differential equations and to some\nL\\'{e}vy-driven stochastic differential equations. In the cases under study,\nthe Malliavin calculus cannot be used, because the solution in generally not\nMalliavin differentiable.\n", "versions": [{"version": "v1", "created": "Fri, 18 Apr 2008 15:11:56 GMT"}, {"version": "v2", "created": "Tue, 8 Jul 2008 07:02:12 GMT"}, {"version": "v3", "created": "Mon, 11 Oct 2010 08:50:53 GMT"}], "update_date": "2010-10-12", "authors_parsed": [["Fournier", "Nicolas", ""], ["Printems", "Jacques", ""]]}, {"id": "0804.3166", "submitter": "Cecile Ane", "authors": "C\\'ecile An\\'e", "title": "Analysis of comparative data with hierarchical autocorrelation", "comments": "Published in at http://dx.doi.org/10.1214/08-AOAS173 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2008, Vol. 2, No. 3, 1078-1102", "doi": "10.1214/08-AOAS173", "report-no": "IMS-AOAS-AOAS173", "categories": "stat.AP math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The asymptotic behavior of estimates and information criteria in linear\nmodels are studied in the context of hierarchically correlated sampling units.\nThe work is motivated by biological data collected on species where\nautocorrelation is based on the species' genealogical tree. Hierarchical\nautocorrelation is also found in many other kinds of data, such as from\nmicroarray experiments or human languages. Similar correlation also arises in\nANOVA models with nested effects. I show that the best linear unbiased\nestimators are almost surely convergent but may not be consistent for some\nparameters such as the intercept and lineage effects, in the context of\nBrownian motion evolution on the genealogical tree. For the purpose of model\nselection I show that the usual BIC does not provide an appropriate\napproximation to the posterior probability of a model. To correct for this, an\neffective sample size is introduced for parameters that are inconsistently\nestimated. For biological studies, this work implies that tree-aware sampling\ndesign is desirable; adding more sampling units may not help ancestral\nreconstruction and only strong lineage effects may be detected with high power.\n", "versions": [{"version": "v1", "created": "Sat, 19 Apr 2008 21:01:22 GMT"}, {"version": "v2", "created": "Fri, 14 Nov 2008 07:27:08 GMT"}], "update_date": "2008-11-14", "authors_parsed": [["An\u00e9", "C\u00e9cile", ""]]}, {"id": "0804.3173", "submitter": "Christian Robert P", "authors": "Christian P. Robert, Nicolas Chopin, Judith Rousseau", "title": "Harold Jeffreys's Theory of Probability Revisited", "comments": "This paper commented in: [arXiv:1001.2967], [arXiv:1001.2968],\n  [arXiv:1001.2970], [arXiv:1001.2975], [arXiv:1001.2985], [arXiv:1001.3073].\n  Rejoinder in [arXiv:0909.1008]. Published in at\n  http://dx.doi.org/10.1214/09-STS284 the Statistical Science\n  (http://www.imstat.org/sts/) by the Institute of Mathematical Statistics\n  (http://www.imstat.org)", "journal-ref": "Statistical Science (2009), Vol. 24, No. 2, 141-172", "doi": "10.1214/09-STS284", "report-no": "IMS-STS-STS284", "categories": "math.ST math.HO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Published exactly seventy years ago, Jeffreys's Theory of Probability (1939)\nhas had a unique impact on the Bayesian community and is now considered to be\none of the main classics in Bayesian Statistics as well as the initiator of the\nobjective Bayes school. In particular, its advances on the derivation of\nnoninformative priors as well as on the scaling of Bayes factors have had a\nlasting impact on the field. However, the book reflects the characteristics of\nthe time, especially in terms of mathematical rigor. In this paper we point out\nthe fundamental aspects of this reference work, especially the thorough\ncoverage of testing problems and the construction of both estimation and\ntesting noninformative priors based on functional divergences. Our major aim\nhere is to help modern readers in navigating in this difficult text and in\nconcentrating on passages that are still relevant today.\n", "versions": [{"version": "v1", "created": "Mon, 21 Apr 2008 16:21:18 GMT"}, {"version": "v2", "created": "Fri, 25 Apr 2008 10:30:10 GMT"}, {"version": "v3", "created": "Sun, 4 May 2008 18:02:59 GMT"}, {"version": "v4", "created": "Fri, 3 Apr 2009 19:38:50 GMT"}, {"version": "v5", "created": "Wed, 8 Apr 2009 06:29:56 GMT"}, {"version": "v6", "created": "Mon, 11 May 2009 06:31:35 GMT"}, {"version": "v7", "created": "Mon, 18 Jan 2010 14:41:24 GMT"}], "update_date": "2010-10-11", "authors_parsed": [["Robert", "Christian P.", ""], ["Chopin", "Nicolas", ""], ["Rousseau", "Judith", ""]]}, {"id": "0804.3678", "submitter": "Dominik Janzing", "authors": "Dominik Janzing and Bernhard Schoelkopf", "title": "Causal inference using the algorithmic Markov condition", "comments": "16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT math.IT stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inferring the causal structure that links n observables is usually based upon\ndetecting statistical dependences and choosing simple graphs that make the\njoint measure Markovian. Here we argue why causal inference is also possible\nwhen only single observations are present.\n  We develop a theory how to generate causal graphs explaining similarities\nbetween single objects. To this end, we replace the notion of conditional\nstochastic independence in the causal Markov condition with the vanishing of\nconditional algorithmic mutual information and describe the corresponding\ncausal inference rules.\n  We explain why a consistent reformulation of causal inference in terms of\nalgorithmic complexity implies a new inference principle that takes into\naccount also the complexity of conditional probability densities, making it\npossible to select among Markov equivalent causal graphs. This insight provides\na theoretical foundation of a heuristic principle proposed in earlier work.\n  We also discuss how to replace Kolmogorov complexity with decidable\ncomplexity criteria. This can be seen as an algorithmic analog of replacing the\nempirically undecidable question of statistical independence with practical\nindependence tests that are based on implicit or explicit assumptions on the\nunderlying distribution.\n", "versions": [{"version": "v1", "created": "Wed, 23 Apr 2008 10:39:41 GMT"}], "update_date": "2008-04-24", "authors_parsed": [["Janzing", "Dominik", ""], ["Schoelkopf", "Bernhard", ""]]}, {"id": "0804.3715", "submitter": "Jean-Fran\\c{c}ois Coeurjolly", "authors": "Jean-Michel Billiot, Jean-Fran\\c{c}ois Coeurjolly, R\\'emy Drouilhet", "title": "Maximum pseudolikelihood estimator for exponential family models of\n  marked Gibbs point processes", "comments": "Published in at http://dx.doi.org/10.1214/07-EJS160 the Electronic\n  Journal of Statistics (http://www.i-journals.org/ejs/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Electronic Journal of Statistics 2008, Vol. 2, 234-264", "doi": "10.1214/07-EJS160", "report-no": "IMS-EJS-EJS_2007_160", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is devoted to the estimation of a vector $\\bm {\\theta}$\nparametrizing an energy function of a Gibbs point process, via the maximum\npseudolikelihood method. Strong consistency and asymptotic normality results of\nthis estimator depending on a single realization are presented. In the\nframework of exponential family models, sufficient conditions are expressed in\nterms of the local energy function and are verified on a wide variety of\nexamples.\n", "versions": [{"version": "v1", "created": "Wed, 23 Apr 2008 13:39:03 GMT"}], "update_date": "2008-12-18", "authors_parsed": [["Billiot", "Jean-Michel", ""], ["Coeurjolly", "Jean-Fran\u00e7ois", ""], ["Drouilhet", "R\u00e9my", ""]]}, {"id": "0804.3779", "submitter": "Xinjia Chen", "authors": "Xinjia Chen", "title": "On Estimation of Finite Population Proportion", "comments": "11 pages, no figure, added multistage fixed-width confidence interval\n  method", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the classical problem of estimating the proportion of\na finite population. First, we consider a fixed sample size method and derive\nan explicit sample size formula which ensures a mixed criterion of absolute and\nrelative errors. Second, we consider an inverse sampling scheme such that the\nsampling is continue until the number of units having a certain attribute\nreaches a threshold value or the whole population is examined. We have\nestablished a simple method to determine the threshold so that a prescribed\nrelative precision is guaranteed. Finally, we develop a multistage sampling\nscheme for constructing fixed-width confidence interval for the proportion of a\nfinite population. Powerful computational techniques are introduced to make it\npossible that the fixed-width confidence interval ensures prescribed level of\ncoverage probability.\n", "versions": [{"version": "v1", "created": "Wed, 23 Apr 2008 18:50:16 GMT"}, {"version": "v2", "created": "Fri, 25 Apr 2008 16:17:59 GMT"}, {"version": "v3", "created": "Tue, 3 Feb 2009 19:55:55 GMT"}], "update_date": "2009-02-03", "authors_parsed": [["Chen", "Xinjia", ""]]}, {"id": "0804.3926", "submitter": "Marian Grendar", "authors": "M. Grendar", "title": "Maximum Probability and Relative Entropy Maximization. Bayesian Maximum\n  Probability and Empirical Likelihood", "comments": "Intnl. Workshop on Applied Probability 2008, Compiegne, France", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Works, briefly surveyed here, are concerned with two basic methods: Maximum\nProbability and Bayesian Maximum Probability; as well as with their asymptotic\ninstances: Relative Entropy Maximization and Maximum Non-parametric Likelihood.\nParametric and empirical extensions of the latter methods - Empirical Maximum\nMaximum Entropy and Empirical Likelihood - are also mentioned. The methods are\nviewed as tools for solving certain ill-posed inverse problems, called\nPi-problem, Phi-problem, respectively. Within the two classes of problems,\nprobabilistic justification and interpretation of the respective methods are\ndiscussed.\n", "versions": [{"version": "v1", "created": "Thu, 24 Apr 2008 13:44:28 GMT"}], "update_date": "2008-04-25", "authors_parsed": [["Grendar", "M.", ""]]}, {"id": "0804.4123", "submitter": "Mathew D. Penrose", "authors": "Yu. Baryshnikov, Mathew D. Penrose, J. E. Yukich", "title": "Gaussian limits for generalized spacings", "comments": "Published in at http://dx.doi.org/10.1214/08-AAP537 the Annals of\n  Applied Probability (http://www.imstat.org/aap/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Probability 2009, Vol. 19, No. 1, 158-185", "doi": "10.1214/08-AAP537", "report-no": "IMS-AAP-AAP537", "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nearest neighbor cells in $R^d,d\\in\\mathbb{N}$, are used to define\ncoefficients of divergence ($\\phi$-divergences) between continuous multivariate\nsamples. For large sample sizes, such distances are shown to be asymptotically\nnormal with a variance depending on the underlying point density. In $d=1$,\nthis extends classical central limit theory for sum functions of spacings. The\ngeneral results yield central limit theorems for logarithmic $k$-spacings,\ninformation gain, log-likelihood ratios and the number of pairs of sample\npoints within a fixed distance of each other.\n", "versions": [{"version": "v1", "created": "Fri, 25 Apr 2008 18:54:12 GMT"}, {"version": "v2", "created": "Fri, 6 Mar 2009 06:37:43 GMT"}], "update_date": "2009-03-06", "authors_parsed": [["Baryshnikov", "Yu.", ""], ["Penrose", "Mathew D.", ""], ["Yukich", "J. E.", ""]]}, {"id": "0804.4202", "submitter": "Martin Wainwright", "authors": "Pradeep Ravikumar, Martin J. Wainwright, John D. Lafferty", "title": "High-Dimensional Graphical Model Selection Using $\\ell_1$-Regularized\n  Logistic Regression", "comments": "Appeared as UC Berkeley, Department of Statistics, Technical Report", "journal-ref": null, "doi": null, "report-no": "Technical Report 750", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of estimating the graph structure associated with a\ndiscrete Markov random field. We describe a method based on\n$\\ell_1$-regularized logistic regression, in which the neighborhood of any\ngiven node is estimated by performing logistic regression subject to an\n$\\ell_1$-constraint. Our framework applies to the high-dimensional setting, in\nwhich both the number of nodes $p$ and maximum neighborhood sizes $d$ are\nallowed to grow as a function of the number of observations $n$. Our main\nresults provide sufficient conditions on the triple $(n, p, d)$ for the method\nto succeed in consistently estimating the neighborhood of every node in the\ngraph simultaneously. Under certain assumptions on the population Fisher\ninformation matrix, we prove that consistent neighborhood selection can be\nobtained for sample sizes $n = \\Omega(d^3 \\log p)$, with the error decaying as\n$\\order(\\exp(-C n/d^3))$ for some constant $C$. If these same assumptions are\nimposed directly on the sample matrices, we show that $n = \\Omega(d^2 \\log p)$\nsamples are sufficient.\n", "versions": [{"version": "v1", "created": "Sat, 26 Apr 2008 03:47:39 GMT"}], "update_date": "2008-04-29", "authors_parsed": [["Ravikumar", "Pradeep", ""], ["Wainwright", "Martin J.", ""], ["Lafferty", "John D.", ""]]}, {"id": "0804.4266", "submitter": "Heng Lian", "authors": "Heng Lian", "title": "Parameter estimation of high-dimensional linear differential equations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of estimating the coefficients in linear ordinary\ndifferential equations (ODE's) with a diverging number of variables when the\nsolutions are observed with noise. The solution trajectories are first smoothed\nwith local polynomial regression and the coefficients are estimated with\nnonconcave penalty proposed by \\cite{fan01}. Under some regularity and sparsity\nconditions, we show the procedure can correctly identifies nonzero coefficients\nwith probability converging to one and the estimators for nonzero coefficients\nhave the same asymptotic normal distribution as they would have when the zero\ncoefficients are known and the same two-step procedure is used. Our asymptotic\nresults are valid under the misspecified case where linear ODE's are only used\nas an approximation to nonlinear ODE's, and the estimates will converge to the\ncoefficients of the best approximating linear system. From our results, when\nthe solution trajectories of the ODE's are sufficiently smooth, the parametric\n$\\sqrt{n}$ rate is achieved even though nonparametric regression estimator is\nused in the first step of the procedure. The performance of the two-step\nprocedure is illustrated by a simulation study as well as an application to\nyeast cell-cycle data.\n", "versions": [{"version": "v1", "created": "Sun, 27 Apr 2008 05:32:25 GMT"}], "update_date": "2008-04-29", "authors_parsed": [["Lian", "Heng", ""]]}, {"id": "0804.4361", "submitter": "Stephen Lee", "authors": "Stephen M.S. Lee, P.Y. Lai", "title": "Improving Coverage Accuracy of Block Bootstrap Confidence Intervals", "comments": null, "journal-ref": null, "doi": null, "report-no": "Research Report No. 435. Department of Statistics and Actuarial\n  Science, The University of Hong Kong", "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The block bootstrap confidence interval based on dependent data can\noutperform the computationally more convenient normal approximation only with\nnon-trivial Studentization which, in the case of complicated statistics, calls\nfor highly specialist treatment. We propose two different approaches to\nimproving the accuracy of the block bootstrap confidence interval under very\ngeneral conditions. The first calibrates the coverage level by iterating the\nblock bootstrap. The second calculates Studentizing factors directly from block\nbootstrap series and requires no non-trivial analytic treatment. Both\napproaches involve two nested levels of block bootstrap resampling and yield\nhigh-order accuracy with simple tuning of block lengths at the two resampling\nlevels. A simulation study is reported to provide empirical support for our\ntheory.\n", "versions": [{"version": "v1", "created": "Mon, 28 Apr 2008 10:04:07 GMT"}], "update_date": "2008-04-29", "authors_parsed": [["Lee", "Stephen M. S.", ""], ["Lai", "P. Y.", ""]]}, {"id": "0804.4738", "submitter": "Hilmar B\\\"{o}hm", "authors": "Hilmar B\\\"ohm, Rainer von Sachs", "title": "Structural shrinkage of nonparametric spectral estimators for\n  multivariate time series", "comments": "Published in at http://dx.doi.org/10.1214/08-EJS236 the Electronic\n  Journal of Statistics (http://www.i-journals.org/ejs/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Electronic Journal of Statistics 2008, Vol. 2, 696-721", "doi": "10.1214/08-EJS236", "report-no": "IMS-EJS-EJS_2008_236", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we investigate the performance of periodogram based estimators\nof the spectral density matrix of possibly high-dimensional time series. We\nsuggest and study shrinkage as a remedy against numerical instabilities due to\ndeteriorating condition numbers of (kernel) smoothed periodogram matrices.\nMoreover, shrinking the empirical eigenvalues in the frequency domain towards\none another also improves at the same time the Mean Squared Error (MSE) of\nthese widely used nonparametric spectral estimators. Compared to some existing\ntime domain approaches, restricted to i.i.d. data, in the frequency domain it\nis necessary to take the size of the smoothing span as \"effective or local\nsample size\" into account. While B\\\"{o}hm and von Sachs (2007) proposes a\nmultiple of the identity matrix as optimal shrinkage target in the absence of\nknowledge about the multidimensional structure of the data, here we consider\n\"structural\" shrinkage. We assume that the spectral structure of the data is\ninduced by underlying factors. However, in contrast to actual factor modelling\nsuffering from the need to choose the number of factors, we suggest a\nmodel-free approach. Our final estimator is the asymptotically MSE-optimal\nlinear combination of the smoothed periodogram and the parametric estimator\nbased on an underfitting (and hence deliberately misspecified) factor model. We\ncomplete our theoretical considerations by some extensive simulation studies.\nIn the situation of data generated from a higher-order factor model, we compare\nall four types of involved estimators (including the one of B\\\"{o}hm and von\nSachs (2007)).\n", "versions": [{"version": "v1", "created": "Wed, 30 Apr 2008 05:49:30 GMT"}, {"version": "v2", "created": "Wed, 13 Aug 2008 12:05:04 GMT"}], "update_date": "2008-08-13", "authors_parsed": [["B\u00f6hm", "Hilmar", ""], ["von Sachs", "Rainer", ""]]}, {"id": "0804.4780", "submitter": "S. Soubeyrand", "authors": "S. Soubeyrand, F. Carpentier, N. Desassis, J. Chad{\\oe}uf", "title": "Incorporating a contrast in the Bayesian formula: What consequences for\n  the MAP estimator and the posterior distribution? Applications in spatial\n  statistics", "comments": "Submitted to the Electronic Journal of Statistics\n  (http://www.i-journals.org/ejs/) by the Institute of Mathematical Statistics\n  (http://www.imstat.org)", "journal-ref": null, "doi": null, "report-no": "IMS-EJS-EJS_2008_235", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to estimate model parameters and circumvent possible difficulties\nencountered with the likelihood function, we propose to replace the likelihood\nin the formula of the posterior distribution by a function depending on a\ncontrast. The properties of the contrast-based (CB) posterior distribution and\nMAP estimator are studied to understand what the consequences of incorporating\na contrast in the Bayesian formula are. We show that the proposed method can be\nused to make frequentist inference and allows the reduction of analytical\ncalculations to get the limit variance matrix of the estimator. For specific\ncontrasts, the CB--posterior distribution directly approximates the limit\ndistribution of the estimator; the calculation of the limit variance matrix is\nthen avoided. Moreover, for these contrasts, the CB--posterior distribution can\nalso be used to make inference in the Bayesian way. The method is applied to\nthree spatial data sets.\n", "versions": [{"version": "v1", "created": "Wed, 30 Apr 2008 10:37:13 GMT"}], "update_date": "2008-12-18", "authors_parsed": [["Soubeyrand", "S.", ""], ["Carpentier", "F.", ""], ["Desassis", "N.", ""], ["Chad\u0153uf", "J.", ""]]}]