[{"id": "1509.00049", "submitter": "Karine Bertin", "authors": "Meili Baragatti and Karine Bertin and Emilie Lebarbier and Cristian\n  Meza", "title": "A Bayesian approach for the segmentation of series corrupted by a\n  functional part", "comments": "36 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a Bayesian approach to detect multiple change-points in a\npiecewise-constant signal corrupted by a functional part corresponding to\nenvironmental or experimental disturbances. The piecewise constant part (also\ncalled segmentation part) is expressed as the product of a lower triangular\nmatrix by a sparse vector. The functional part is a linear combination of\nfunctions from a large dictionary. A Stochastic Search Variable Selection\napproach is used to obtain sparse estimations of the segmentation parameters\n(the change-points and the means over the segments) and of the functional part.\nThe performance of our proposed method is assessed using simulation\nexperiments. Applications to two real datasets from geodesy and economy fields\nare also presented.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2015 20:26:39 GMT"}, {"version": "v2", "created": "Mon, 7 Sep 2015 15:12:11 GMT"}, {"version": "v3", "created": "Fri, 20 Jan 2017 15:29:51 GMT"}], "update_date": "2017-01-23", "authors_parsed": [["Baragatti", "Meili", ""], ["Bertin", "Karine", ""], ["Lebarbier", "Emilie", ""], ["Meza", "Cristian", ""]]}, {"id": "1509.00114", "submitter": "Yao Xie", "authors": "Yang Cao, Yao Xie, and Nagi Gebraeel", "title": "Multi-Sensor Slope Change Detection", "comments": "Accepted with minor revision at ANOR", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a mixture procedure for multi-sensor systems to monitor data\nstreams for a change-point that causes a gradual degradation to a subset of the\nstreams. Observations are assumed to be initially normal random variables with\nknown constant means and variances. After the change-point, observations in the\nsubset will have increasing or decreasing means. The subset and the\nrate-of-changes are unknown. Our procedure uses a mixture statistics, which\nassumes that each sensor is affected by the change-point with probability\n$p_0$. Analytic expressions are obtained for the average run length (ARL) and\nthe expected detection delay (EDD) of the mixture procedure, which are\ndemonstrated to be quite accurate numerically. We establish the asymptotic\noptimality of the mixture procedure. Numerical examples demonstrate the good\nperformance of the proposed procedure. We also discuss an adaptive mixture\nprocedure using empirical Bayes. This paper extends our earlier work on\ndetecting an abrupt change-point that causes a mean-shift, by tackling the\nchallenges posed by the non-stationarity of the slope-change problem.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2015 01:49:15 GMT"}, {"version": "v2", "created": "Thu, 18 Feb 2016 03:08:31 GMT"}], "update_date": "2016-02-19", "authors_parsed": [["Cao", "Yang", ""], ["Xie", "Yao", ""], ["Gebraeel", "Nagi", ""]]}, {"id": "1509.00130", "submitter": "Yao Xie", "authors": "Ruiyang Song, Yao Xie, and Sebastian Pokutta", "title": "Sequential Information Guided Sensing", "comments": "Submitted for journal publication. arXiv admin note: substantial text\n  overlap with arXiv:1501.06241", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the value of information in sequential compressed sensing by\ncharacterizing the performance of sequential information guided sensing in\npractical scenarios when information is inaccurate. In particular, we assume\nthe signal distribution is parameterized through Gaussian or Gaussian mixtures\nwith estimated mean and covariance matrices, and we can measure compressively\nthrough a noisy linear projection or using one-sparse vectors, i.e., observing\none entry of the signal each time. We establish a set of performance bounds for\nthe bias and variance of the signal estimator via posterior mean, by capturing\nthe conditional entropy (which is also related to the size of the uncertainty),\nand the additional power required due to inaccurate information to reach a\ndesired precision. Based on this, we further study how to estimate covariance\nbased on direct samples or covariance sketching. Numerical examples also\ndemonstrate the superior performance of Info-Greedy Sensing algorithms compared\nwith their random and non-adaptive counterparts.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2015 03:59:33 GMT"}], "update_date": "2015-09-02", "authors_parsed": [["Song", "Ruiyang", ""], ["Xie", "Yao", ""], ["Pokutta", "Sebastian", ""]]}, {"id": "1509.00137", "submitter": "Yao Xie", "authors": "Yao Xie, Ruiyang Song, Hanjun Dai, Qingbin Li, Le Song", "title": "Online Supervised Subspace Tracking", "comments": "Submitted for journal publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a framework for supervised subspace tracking, when there are two\ntime series $x_t$ and $y_t$, one being the high-dimensional predictors and the\nother being the response variables and the subspace tracking needs to take into\nconsideration of both sequences. It extends the classic online subspace\ntracking work which can be viewed as tracking of $x_t$ only. Our online\nsufficient dimensionality reduction (OSDR) is a meta-algorithm that can be\napplied to various cases including linear regression, logistic regression,\nmultiple linear regression, multinomial logistic regression, support vector\nmachine, the random dot product model and the multi-scale union-of-subspace\nmodel. OSDR reduces data-dimensionality on-the-fly with low-computational\ncomplexity and it can also handle missing data and dynamic data. OSDR uses an\nalternating minimization scheme and updates the subspace via gradient descent\non the Grassmannian manifold. The subspace update can be performed efficiently\nutilizing the fact that the Grassmannian gradient with respect to the subspace\nin many settings is rank-one (or low-rank in certain cases). The optimization\nproblem for OSDR is non-convex and hard to analyze in general; we provide\nconvergence analysis of OSDR in a simple linear regression setting. The good\nperformance of OSDR compared with the conventional unsupervised subspace\ntracking are demonstrated via numerical examples on simulated and real data.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2015 04:42:39 GMT"}], "update_date": "2015-09-02", "authors_parsed": [["Xie", "Yao", ""], ["Song", "Ruiyang", ""], ["Dai", "Hanjun", ""], ["Li", "Qingbin", ""], ["Song", "Le", ""]]}, {"id": "1509.00172", "submitter": "Andrew Golightly", "authors": "Chris Sherlock, Andrew Golightly, Daniel A. Henderson", "title": "Adaptive, delayed-acceptance MCMC for targets with expensive likelihoods", "comments": "50 pages (including supplementary material)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When conducting Bayesian inference, delayed acceptance (DA)\nMetropolis-Hastings (MH) algorithms and DA pseudo-marginal MH algorithms can be\napplied when it is computationally expensive to calculate the true posterior or\nan unbiased estimate thereof, but a computationally cheap approximation is\navailable. A first accept-reject stage is applied, with the cheap approximation\nsubstituted for the true posterior in the MH acceptance ratio. Only for those\nproposals which pass through the first stage is the computationally expensive\ntrue posterior (or unbiased estimate thereof) evaluated, with a second\naccept-reject stage ensuring that detailed balance is satisfied with respect to\nthe intended true posterior. In some scenarios there is no obvious\ncomputationally cheap approximation. A weighted average of previous evaluations\nof the computationally expensive posterior provides a generic approximation to\nthe posterior. If only the $k$-nearest neighbours have non-zero weights then\nevaluation of the approximate posterior can be made computationally cheap\nprovided that the points at which the posterior has been evaluated are stored\nin a multi-dimensional binary tree, known as a KD-tree. The contents of the\nKD-tree are potentially updated after every computationally intensive\nevaluation. The resulting adaptive, delayed-acceptance [pseudo-marginal]\nMetropolis-Hastings algorithm is justified both theoretically and empirically.\nGuidance on tuning parameters is provided and the methodology is applied to a\ndiscretely observed Markov jump process characterising predator-prey\ninteractions and an ODE system describing the dynamics of an autoregulatory\ngene network.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2015 08:17:27 GMT"}, {"version": "v2", "created": "Wed, 1 Jun 2016 14:28:49 GMT"}], "update_date": "2016-06-02", "authors_parsed": [["Sherlock", "Chris", ""], ["Golightly", "Andrew", ""], ["Henderson", "Daniel A.", ""]]}, {"id": "1509.00253", "submitter": "Olivier Wintenberger", "authors": "T. Mikosch, O. Wintenberger (LSTA)", "title": "A large deviations approach to limit theory for heavy-tailed time series", "comments": null, "journal-ref": "Probability Theory and Related Fields, Springer Verlag (Germany),\n  2015, pp.654", "doi": "10.1007/s00440-015-0654-4", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propagate a large deviations approach for proving limit\ntheory for (generally) multivariate time series with heavy tails. We make this\nnotion precise by introducing regularly varying time series. We provide general\nlarge deviation results for functionals acting on a sample path and vanishing\nin some neighborhood of the origin. We study a variety of such functionals,\nincluding large deviations of random walks, their suprema, the ruin functional,\nand further derive weak limit theory for maxima, point processes, cluster\nfunctionals and the tail empirical process. One of the main results of this\npaper concerns bounds for the ruin probability in various heavy-tailed models\nincluding GARCH, stochastic volatility models and solutions to stochastic\nrecurrence equations. 1. Preliminaries and basic motivation In the last\ndecades, a lot of efforts has been put into the understanding of limit theory\nfor dependent sequences, including Markov chains (Meyn and Tweedie [42]),\nweakly dependent sequences (Dedecker et al. [21]), long-range dependent\nsequences (Doukhan et al. [23], Samorodnitsky [54]), empirical processes\n(Dehling et al. [22]) and more general structures (Eberlein and Taqqu [25]), to\nname a few references. A smaller part of the theory was devoted to limit theory\nunder extremal dependence for point processes, maxima, partial sums, tail\nempirical processes. Resnick [49, 50] started a systematic study of the\nrelations between the convergence of point processes, sums and maxima, see also\nResnick [51] for a recent account. He advocated the use of multivariate regular\nvariation as a flexible tool to describe heavy-tail phenomena combined with\nadvanced continuous mapping techniques. For example, maxima and sums are\nunderstood as functionals acting on an underlying point process, if the point\nprocess converges these functionals converge as well and their limits are\ndescribed in terms of the points of the limiting point process. Davis and Hsing\n[13] recognized the power of this approach for limit theory of point processes,\nmaxima, sums, and large deviations for dependent regularly varying processes,\ni.e., stationary sequences whose finite-dimensional distributions are regularly\nvarying with the same index. Before [13], limit theory for particular regularly\nvarying stationary sequences was studied for the sample mean, maxima, sample\nautocovariance and autocorrelation functions of linear and bilinear processes\nwith iid regularly varying noise and extreme value theory was considered for\nregularly varying ARCH processes and solutions to stochastic recurrence\nequation, see Rootz\\'en [53], Davis and 1991 Mathematics Subject\nClassification. Primary 60F10, 60G70, secondary 60F05. Key words and phrases.\nLarge deviation principle, regularly varying processes, central limit theorem,\nruin probabilities, GARCH.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2015 12:24:09 GMT"}], "update_date": "2015-09-02", "authors_parsed": [["Mikosch", "T.", "", "LSTA"], ["Wintenberger", "O.", "", "LSTA"]]}, {"id": "1509.00268", "submitter": "Michael Kallitsis", "authors": "Michael Kallitsis, Stilian Stoev, Shrijita Bhattacharya, George\n  Michailidis", "title": "AMON: An Open Source Architecture for Online Monitoring, Statistical\n  Analysis and Forensics of Multi-gigabit Streams", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Internet, as a global system of interconnected networks, carries an\nextensive array of information resources and services. Key requirements include\ngood quality-of-service and protection of the infrastructure from nefarious\nactivity (e.g. distributed denial of service--DDoS--attacks). Network\nmonitoring is essential to network engineering, capacity planning and\nprevention / mitigation of threats. We develop an open source architecture,\nAMON (All-packet MONitor), for online monitoring and analysis of multi-gigabit\nnetwork streams. It leverages the high-performance packet monitor PF RING and\nis readily deployable on commodity hardware. AMON examines all packets,\npartitions traffic into sub-streams by using rapid hashing and computes certain\nreal-time data products. The resulting data structures provide views of the\nintensity and connectivity structure of network traffic at the time-scale of\nrouting. The proposed integrated framework includes modules for the\nidentification of heavy-hitters as well as for visualization and statistical\ndetection at the time-of-onset of high impact events such as DDoS. This allows\noperators to quickly visualize and diagnose attacks, and limit offline and time\nconsuming post-mortem analysis. We demonstrate our system in the context of\nreal-world attack incidents, and validate it against state-of-the-art\nalternatives. AMON has been deployed and is currently processing 10Gbps+ live\nInternet traffic at Merit Network. It is extensible and allows the addition of\nfurther statistical and filtering modules for real-time forensics.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2015 13:00:10 GMT"}, {"version": "v2", "created": "Wed, 27 Jan 2016 13:32:51 GMT"}], "update_date": "2016-08-02", "authors_parsed": [["Kallitsis", "Michael", ""], ["Stoev", "Stilian", ""], ["Bhattacharya", "Shrijita", ""], ["Michailidis", "George", ""]]}, {"id": "1509.00319", "submitter": "Olga Klopp", "authors": "O. Klopp (CREST, MODAL'X), A.B. Tsybakov (CREST)", "title": "Estimation of matrices with row sparsity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An increasing number of applications is concerned with recovering a sparse\nmatrix from noisy observations. In this paper, we consider the setting where\neach row of the unknown matrix is sparse. We establish minimax optimal rates of\nconvergence for estimating matrices with row sparsity. A major focus in the\npresent paper is on the derivation of lower bounds.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2015 14:39:45 GMT"}], "update_date": "2015-09-02", "authors_parsed": [["Klopp", "O.", "", "CREST, MODAL'X"], ["Tsybakov", "A. B.", "", "CREST"]]}, {"id": "1509.00351", "submitter": "Judith Lok", "authors": "Judith J. Lok", "title": "Defining and estimating causal direct and indirect effects when setting\n  the mediator to specific values is not feasible", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural direct and indirect effects decompose the effect of a treatment into\nthe part that is mediated by a covariate (the mediator) and the part that is\nnot. Their definitions rely on the concept of outcomes under treatment with the\nmediator \"set\" to its value without treatment. Typically, the mechanism through\nwhich the mediator is set to this value is left unspecified, and in many\napplications it may be challenging to fix the mediator to particular values for\neach unit or individual. Moreover, how one sets the mediator may affect the\ndistribution of the outcome. This article introduces \"organic\" direct and\nindirect effects, which can be defined and estimated without relying on setting\nthe mediator to specific values. Organic direct and indirect effects can be\napplied for example to estimate how much of the effect of some treatments for\nHIV/AIDS on mother-to-child transmission of HIV-infection is mediated by the\neffect of the treatment on the HIV viral load in the blood of the mother.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2015 15:26:15 GMT"}], "update_date": "2015-09-02", "authors_parsed": [["Lok", "Judith J.", ""]]}, {"id": "1509.00368", "submitter": "Toby Hocking", "authors": "Toby Dylan Hocking", "title": "A breakpoint detection error function for segmentation model selection\n  and evaluation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We consider the multiple breakpoint detection problem, which is concerned\nwith detecting the locations of several distinct changes in a one-dimensional\nnoisy data series. We propose the breakpointError, a function that can be used\nto evaluate estimated breakpoint locations, given the known locations of true\nbreakpoints. We discuss an application of the breakpointError for finding\noptimal penalties for breakpoint detection in simulated data. Finally, we show\nhow to relax the breakpointError to obtain an annotation error function which\ncan be used more readily in practice on real data. A fast C implementation of\nan algorithm that computes the breakpointError is available in an R package on\nR-Forge.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2015 15:55:42 GMT"}], "update_date": "2015-09-02", "authors_parsed": [["Hocking", "Toby Dylan", ""]]}, {"id": "1509.00426", "submitter": "Yves Atchade F", "authors": "Yves F. Atchad\\'e, Rahul Mazumder, and Jie Chen", "title": "Scalable Computation of Regularized Precision Matrices via Stochastic\n  Optimization", "comments": "42 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.OC stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of computing a positive definite $p \\times p$ inverse\ncovariance matrix aka precision matrix $\\theta=(\\theta_{ij})$ which optimizes a\nregularized Gaussian maximum likelihood problem, with the elastic-net\nregularizer $\\sum_{i,j=1}^{p} \\lambda (\\alpha|\\theta_{ij}| + \\frac{1}{2}(1-\n\\alpha) \\theta_{ij}^2),$ with regularization parameters $\\alpha \\in [0,1]$ and\n$\\lambda>0$. The associated convex semidefinite optimization problem is\nnotoriously difficult to scale to large problems and has demanded significant\nattention over the past several years. We propose a new algorithmic framework\nbased on stochastic proximal optimization (on the primal problem) that can be\nused to obtain near optimal solutions with substantial computational savings\nover deterministic algorithms. A key challenge of our work stems from the fact\nthat the optimization problem being investigated does not satisfy the usual\nassumptions required by stochastic gradient methods. Our proposal has (a)\ncomputational guarantees and (b) scales well to large problems, even if the\nsolution is not too sparse; thereby, enhancing the scope of regularized maximum\nlikelihood problems to many large-scale problems of contemporary interest. An\nimportant aspect of our proposal is to bypass the \\emph{deterministic}\ncomputation of a matrix inverse by drawing random samples from a suitable\nmultivariate Gaussian distribution.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2015 18:25:32 GMT"}], "update_date": "2015-09-02", "authors_parsed": [["Atchad\u00e9", "Yves F.", ""], ["Mazumder", "Rahul", ""], ["Chen", "Jie", ""]]}, {"id": "1509.00571", "submitter": "Michael Vaillant", "authors": "Thibault Laurent (GREMAQ), Christine Thomas-Agnan (GREMAQ), Micha\\\"el\n  Vaillant", "title": "Spatial Point Pattern Analysis of the Unidentified Aerial Phenomena in\n  France", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We model the unidentified aerial phenomena observed in France during the last\n60 years as a spatial point pattern. We use some public information such as\npopulation density, rate of moisture or presence of airports to model the\nintensity of the unidentified aerial phenomena. Spatial exploratory data\nanalysis is a first approach to appreciate the link between the intensity of\nthe unidentified aerial phenomena and the covariates. We then fit an\ninhomogeneous spatial Poisson process model with covariates. We find that the\nsignificant variables are the population density, the presence of the factories\nwith a nuclear risk and contaminated land, and the rate of moisture. The\nanalysis of the residuals shows that some parts of France (the Belgian border,\nthe tip of Britany, some parts in the SouthEast , the Picardie and\nHaute-Normandie regions, the Loiret and Corr eze departments) present a high\nvalue of local intensity which are not explained by our model.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2015 06:42:07 GMT"}], "update_date": "2015-09-03", "authors_parsed": [["Laurent", "Thibault", "", "GREMAQ"], ["Thomas-Agnan", "Christine", "", "GREMAQ"], ["Vaillant", "Micha\u00ebl", ""]]}, {"id": "1509.00727", "submitter": "Anupama Nandi", "authors": "Joseph Anderson, Navin Goyal, Anupama Nandi, Luis Rademacher", "title": "Heavy-tailed Independent Component Analysis", "comments": "30 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.CO stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Independent component analysis (ICA) is the problem of efficiently recovering\na matrix $A \\in \\mathbb{R}^{n\\times n}$ from i.i.d. observations of $X=AS$\nwhere $S \\in \\mathbb{R}^n$ is a random vector with mutually independent\ncoordinates. This problem has been intensively studied, but all existing\nefficient algorithms with provable guarantees require that the coordinates\n$S_i$ have finite fourth moments. We consider the heavy-tailed ICA problem\nwhere we do not make this assumption, about the second moment. This problem\nalso has received considerable attention in the applied literature. In the\npresent work, we first give a provably efficient algorithm that works under the\nassumption that for constant $\\gamma > 0$, each $S_i$ has finite\n$(1+\\gamma)$-moment, thus substantially weakening the moment requirement\ncondition for the ICA problem to be solvable. We then give an algorithm that\nworks under the assumption that matrix $A$ has orthogonal columns but requires\nno moment assumptions. Our techniques draw ideas from convex geometry and\nexploit standard properties of the multivariate spherical Gaussian distribution\nin a novel way.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2015 14:56:22 GMT"}], "update_date": "2015-09-03", "authors_parsed": [["Anderson", "Joseph", ""], ["Goyal", "Navin", ""], ["Nandi", "Anupama", ""], ["Rademacher", "Luis", ""]]}, {"id": "1509.00899", "submitter": "Souhil Chakar", "authors": "Souhil Chakar", "title": "A robust approach for estimating change-points in the mean of an AR(p)\n  process", "comments": "33 pages, 7 tables, 14 figures. arXiv admin note: text overlap with\n  arXiv:1403.1958", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of change-points estimation in the mean of an AR(p)\nprocess. Taking into account the dependence structure does not allow us to use\nthe approach of the independent case. Especially, the dynamic programming\nalgorithm giving the optimal solution in the independent case cannot be used\nanymore. We propose a two-step method, based on the preliminary robust (to the\nchange-points) estimation of the autoregression parameters. Then, we propose to\nfollow the classical approach, by plugging this estimator in the criterion used\nfor change-point estimation, which is equivalent to decorrelate the series\nusing the estimated autoregression parameters. We show that the asymptotic\nproperties of these change-point location and mean estimators are the same as\nthose of the classical estimators in the independent framework. The same\nplug-in approach is then used to approximate the modified BIC and choose the\nnumber of segments, and to derive a heuristic BIC criterion to select both the\nnumber of changes and the order of the autoregression. Finally, we show, in the\nsimulation section, that for finite sample size taking into account the\ndependence structure improves the statistical performance of the change-point\nestimators and of the selection criterion.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2015 23:22:47 GMT"}], "update_date": "2015-09-04", "authors_parsed": [["Chakar", "Souhil", ""]]}, {"id": "1509.01042", "submitter": "Sergio Venturini", "authors": "Sergio Venturini, Francesca Dominici, Giovanni Parmigiani", "title": "Generalized Quantile Treatment Effect: A Flexible Bayesian Approach\n  Using Quantile Ratio Smoothing", "comments": "Published at http://dx.doi.org/10.1214/14-BA922 in the Bayesian\n  Analysis (http://projecteuclid.org/euclid.ba) by the International Society of\n  Bayesian Analysis (http://bayesian.org/)", "journal-ref": "Bayesian Analysis 2015, Vol. 10, No. 3, 523-552", "doi": "10.1214/14-BA922", "report-no": "VTeX-BA-BA922", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new general approach for estimating the effect of a binary\ntreatment on a continuous and potentially highly skewed response variable, the\ngeneralized quantile treatment effect (GQTE). The GQTE is defined as the\ndifference between a function of the quantiles under the two treatment\nconditions. As such, it represents a generalization over the standard\napproaches typically used for estimating a treatment effect (i.e., the average\ntreatment effect and the quantile treatment effect) because it allows the\ncomparison of any arbitrary characteristic of the outcome's distribution under\nthe two treatments. Following Dominici et al. (2005), we assume that a\npre-specified transformation of the two quantiles is modeled as a smooth\nfunction of the percentiles. This assumption allows us to link the two quantile\nfunctions and thus to borrow information from one distribution to the other.\nThe main theoretical contribution we provide is the analytical derivation of a\nclosed form expression for the likelihood of the model. Exploiting this result\nwe propose a novel Bayesian inferential methodology for the GQTE. We show some\nfinite sample properties of our approach through a simulation study which\nconfirms that in some cases it performs better than other nonparametric\nmethods. As an illustration we finally apply our methodology to the 1987\nNational Medicare Expenditure Survey data to estimate the difference in the\nsingle hospitalization medical cost distributions between cases (i.e., subjects\naffected by smoking attributable diseases) and controls.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2015 11:45:35 GMT"}], "update_date": "2015-09-04", "authors_parsed": [["Venturini", "Sergio", ""], ["Dominici", "Francesca", ""], ["Parmigiani", "Giovanni", ""]]}, {"id": "1509.01058", "submitter": "James Barrett", "authors": "James E. Barrett", "title": "Information-adaptive clinical trials with selective recruitment and\n  binary outcomes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Selective recruitment designs preferentially recruit individuals that are\nestimated to be statistically informative onto a clinical trial. Individuals\nthat are expected to contribute less information have a lower probability of\nrecruitment. Furthermore, in an information-adaptive design recruits are\nallocated to treatment arms in a manner that maximises information gain. The\ninformativeness of an individual depends on their covariate (or biomarker)\nvalues and how information is defined is a critical element of\ninformation-adaptive designs. In this paper we define and evaluate four\ndifferent methods for quantifying statistical information. Using both\nexperimental data and numerical simulations we show that selective recruitment\ndesigns can offer a substantial increase in statistical power compared to\nrandomised designs. In trials without selective recruitment we find that\nallocating individuals to treatment arms according to information-adaptive\nprotocols also leads to an increase in statistical power. Consequently,\nselective recruitment designs can potentially achieve successful trials using\nfewer recruits thereby offering economic and ethical advantages.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2015 12:41:28 GMT"}, {"version": "v2", "created": "Mon, 28 Mar 2016 16:10:56 GMT"}, {"version": "v3", "created": "Tue, 30 May 2017 15:06:24 GMT"}], "update_date": "2017-05-31", "authors_parsed": [["Barrett", "James E.", ""]]}, {"id": "1509.01060", "submitter": "Douglas K. Sparks", "authors": "Douglas K. Sparks, Kshitij Khare, Malay Ghosh", "title": "Necessary and Sufficient Conditions for High-Dimensional Posterior\n  Consistency under $g$-Priors", "comments": "Published at http://dx.doi.org/10.1214/14-BA893 in the Bayesian\n  Analysis (http://projecteuclid.org/euclid.ba) by the International Society of\n  Bayesian Analysis (http://bayesian.org/)", "journal-ref": "Bayesian Analysis 2015, Vol. 10, No. 3, 627-664", "doi": "10.1214/14-BA893", "report-no": "VTeX-BA-BA893", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine necessary and sufficient conditions for posterior consistency\nunder $g$-priors, including extensions to hierarchical and empirical Bayesian\nmodels. The key features of this article are that we allow the number of\nregressors to grow at the same rate as the sample size and define posterior\nconsistency under the sup vector norm instead of the more conventional\nEuclidean norm. We consider in particular the empirical Bayesian model of\nGeorge and Foster (2000), the hyper-$g$-prior of Liang et al. (2008), and the\nprior considered by Zellner and Siow (1980).\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2015 12:46:27 GMT"}], "update_date": "2015-09-04", "authors_parsed": [["Sparks", "Douglas K.", ""], ["Khare", "Kshitij", ""], ["Ghosh", "Malay", ""]]}, {"id": "1509.01291", "submitter": "Michal Pe\\v{s}ta PhD", "authors": "Barbora Pe\\v{s}tov\\'a and Michal Pe\\v{s}ta", "title": "Testing Structural Changes in Panel Data with Small Fixed Panel Size and\n  Bootstrap", "comments": "Corrected version of the original paper: Pe\\v{s}tov\\'{a}, B. and\n  Pe\\v{s}ta, M. (2015). Testing structural changes in panel data with small\n  fixed panel size and bootstrap. Metrika, August 2015, Volume 78, Issue 6, pp\n  665-689, DOI 10.1007/s00184-014-0522-8,\n  http://link.springer.com/article/10.1007%2Fs00184-014-0522-8", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Panel data of our interest consist of a moderate or relatively large number\nof panels, while the panels contain a small number of observations. This paper\nestablishes testing procedures to detect a possible common change in means of\nthe panels. To this end, we consider a ratio type test statistic and derive its\nasymptotic distribution under the no change null hypothesis. Moreover, we prove\nthe consistency of the test under the alternative. The main advantage of such\nan approach is that the variance of the observations neither has to be known\nnor estimated. On the other hand, the correlation structure is required to be\ncalculated. To overcome this issue, a bootstrap technique is proposed in the\nway of a completely data driven approach without any tuning parameters. The\nvalidity of the bootstrap algorithm is shown. As a by-product of the developed\ntests, we introduce a common break point estimate and prove its consistency.\nThe results are illustrated through a simulation study. An application of the\nprocedure to actuarial data is presented.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2015 22:27:04 GMT"}], "update_date": "2016-08-07", "authors_parsed": [["Pe\u0161tov\u00e1", "Barbora", ""], ["Pe\u0161ta", "Michal", ""]]}, {"id": "1509.01384", "submitter": "Robert Stelzer", "authors": "Robert Stelzer and \\.Zywilla fechner", "title": "Limit behaviour of the truncated pathwise Fourier-transformation of\n  L\\'evy-driven CARMA processes for non-equidistant discrete time observations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers a continuous time analogue of the classical\nautoregressive moving average processes, L\\'evy-driven CARMA processes. First\nwe describe limiting properties of the periodogram by means of the so-called\ntruncated Fourier transform if observations are available continuously. The\nobtained results are in accordance with their counterparts from the\ndiscrete-time case. Then we discuss the numerical approximation of the\ntruncated Fourier transform based on non-equidistant high frequency data. In\norder to ensure convergence of the numerical approximation to the true value of\nthe truncated Fourier transform a certain control on the maximal distance\nbetween observations and the number of observations is needed. We obtain both\nconvergence to the continuous time quantity and asymptotic normality under a\nhigh-frequency infinite time horizon limit.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2015 09:49:26 GMT"}, {"version": "v2", "created": "Mon, 15 Aug 2016 11:04:18 GMT"}], "update_date": "2016-08-16", "authors_parsed": [["Stelzer", "Robert", ""], ["fechner", "\u017bywilla", ""]]}, {"id": "1509.01604", "submitter": "Alejandro  Cholaquidis", "authors": "Alejandro Cholaquidis, Ricardo Fraiman, Juan Kalemkerian, Pamela Llop", "title": "A nonlinear aggregation type classifier", "comments": "arXiv admin note: text overlap with arXiv:1411.2687", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a nonlinear aggregation type classifier for functional data\ndefined on a separable and complete metric space. The new rule is built up from\na collection of $M$ arbitrary training classifiers. If the classifiers are\nconsistent, then so is the aggregation rule. Moreover, asymptotically the\naggregation rule behaves as well as the best of the $M$ classifiers. The\nresults of a small simulation are reported both, for high dimensional and\nfunctional data, and a real data example is analyzed.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2015 20:58:20 GMT"}, {"version": "v2", "created": "Wed, 9 Sep 2015 01:44:03 GMT"}], "update_date": "2015-09-10", "authors_parsed": [["Cholaquidis", "Alejandro", ""], ["Fraiman", "Ricardo", ""], ["Kalemkerian", "Juan", ""], ["Llop", "Pamela", ""]]}, {"id": "1509.01708", "submitter": "Ieva Grublyt\\.e", "authors": "Ieva Grublyt\\.e, Andrius \\v{S}karnulis", "title": "A generalized nonlinear model for long memory conditional\n  heteroscedasticity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the existence and properties of stationary solution of ARCH-type\nequation $r_t= \\zeta_t \\sigma_t$, where $\\zeta_t$ are standardized i.i.d.\nr.v.'s and the conditional variance satisfies an AR(1) equation $\\sigma^2_t =\nQ^2\\big(a + \\sum_{j=1}^\\infty b_j r_{t-j}\\big) + \\gamma \\sigma^2_{t-1}$ with a\nLipschitz function $Q(x)$ and real parameters $a, \\gamma, b_j $. The paper\nextends the model and the results in Doukhan et al. (2015) from the case\n$\\gamma = 0$ to the case $0< \\gamma < 1$. We also obtain a new condition for\nthe existence of higher moments of $r_t$ which does not include the Rosenthal\nconstant. In particular case when $Q$ is the square root of a quadratic\npolynomial, we prove that $r_t$ can exhibit a leverage effect and long memory.\nWe also present simulated trajectories and histograms of marginal density of\n$\\sigma_t$ for different values of $\\gamma$.\n", "versions": [{"version": "v1", "created": "Sat, 5 Sep 2015 15:12:30 GMT"}, {"version": "v2", "created": "Sun, 6 Mar 2016 13:25:40 GMT"}], "update_date": "2016-03-08", "authors_parsed": [["Grublyt\u0117", "Ieva", ""], ["\u0160karnulis", "Andrius", ""]]}, {"id": "1509.01817", "submitter": "Gaurav Pandey", "authors": "Gaurav Pandey and Ambedkar Dukkipati", "title": "On collapsed representation of hierarchical Completely Random Measures", "comments": "11 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of the paper is to provide an exact approach for generating a Poisson\nprocess sampled from a hierarchical CRM, without having to instantiate the\ninfinitely many atoms of the random measures. We use completely random\nmeasures~(CRM) and hierarchical CRM to define a prior for Poisson processes. We\nderive the marginal distribution of the resultant point process, when the\nunderlying CRM is marginalized out. Using well known properties unique to\nPoisson processes, we were able to derive an exact approach for instantiating a\nPoisson process with a hierarchical CRM prior. Furthermore, we derive Gibbs\nsampling strategies for hierarchical CRM models based on Chinese restaurant\nfranchise sampling scheme. As an example, we present the sum of generalized\ngamma process (SGGP), and show its application in topic-modelling. We show that\none can determine the power-law behaviour of the topics and words in a Bayesian\nfashion, by defining a prior on the parameters of SGGP.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2015 14:44:38 GMT"}, {"version": "v2", "created": "Thu, 2 Jun 2016 06:46:28 GMT"}], "update_date": "2016-06-03", "authors_parsed": [["Pandey", "Gaurav", ""], ["Dukkipati", "Ambedkar", ""]]}, {"id": "1509.01877", "submitter": "Xi Chen", "authors": "Xi Chen and Qihang Lin and Bodhisattva Sen", "title": "On Degrees of Freedom of Projection Estimators with Applications to\n  Multivariate Nonparametric Regression", "comments": "72 pages, 7 figures, Journal of the American Statistical Association\n  (Theory and Methods), 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the nonparametric regression problem with\nmultivariate predictors. We provide a characterization of the degrees of\nfreedom and divergence for estimators of the unknown regression function, which\nare obtained as outputs of linearly constrained quadratic optimization\nprocedures, namely, minimizers of the least squares criterion with linear\nconstraints and/or quadratic penalties. As special cases of our results, we\nderive explicit expressions for the degrees of freedom in many nonparametric\nregression problems, e.g., bounded isotonic regression, multivariate\n(penalized) convex regression, and additive total variation regularization. Our\ntheory also yields, as special cases, known results on the degrees of freedom\nof many well-studied estimators in the statistics literature, such as ridge\nregression, Lasso and generalized Lasso. Our results can be readily used to\nchoose the tuning parameter(s) involved in the estimation procedure by\nminimizing the Stein's unbiased risk estimate. As a by-product of our analysis\nwe derive an interesting connection between bounded isotonic regression and\nisotonic regression on a general partially ordered set, which is of independent\ninterest.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2015 01:20:37 GMT"}, {"version": "v2", "created": "Thu, 17 Sep 2015 02:33:23 GMT"}, {"version": "v3", "created": "Thu, 5 Nov 2015 05:11:08 GMT"}, {"version": "v4", "created": "Sat, 6 Oct 2018 17:44:22 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Chen", "Xi", ""], ["Lin", "Qihang", ""], ["Sen", "Bodhisattva", ""]]}, {"id": "1509.01900", "submitter": "Isma\\\"{e}l Castillo", "authors": "Isma\\\"el Castillo", "title": "Discussion of \"Frequentist coverage of adaptive nonparametric Bayesian\n  credible sets\"", "comments": "Published at http://dx.doi.org/10.1214/15-AOS1270B in the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2015, Vol. 43, No. 4, 1437-1443", "doi": "10.1214/15-AOS1270B", "report-no": "IMS-AOS-AOS1270B", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discussion of \"Frequentist coverage of adaptive nonparametric Bayesian\ncredible sets\" by Szab\\'o, van der Vaart and van Zanten [arXiv:1310.4489v5].\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2015 04:45:58 GMT"}], "update_date": "2015-09-08", "authors_parsed": [["Castillo", "Isma\u00ebl", ""]]}, {"id": "1509.01903", "submitter": "Judith Rousseau", "authors": "Judith Rousseau", "title": "Discussion of \"Frequentist coverage of adaptive nonparametric Bayesian\n  credible sets\"", "comments": "Published at http://dx.doi.org/10.1214/15-AOS1270C in the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2015, Vol. 43, No. 4, 1444-1447", "doi": "10.1214/15-AOS1270C", "report-no": "IMS-AOS-AOS1270C", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discussion of \"Frequentist coverage of adaptive nonparametric Bayesian\ncredible sets\" by Szab\\'o, van der Vaart and van Zanten [arXiv:1310.4489v5].\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2015 05:07:34 GMT"}], "update_date": "2015-09-08", "authors_parsed": [["Rousseau", "Judith", ""]]}, {"id": "1509.01904", "submitter": "Zongming Ma", "authors": "Mark G. Low, Zongming Ma", "title": "Discussion of \"Frequentist coverage of adaptive nonparametric Bayesian\n  credible sets\"", "comments": "Published at http://dx.doi.org/10.1214/15-AOS1270D in the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2015, Vol. 43, No. 4, 1448-1454", "doi": "10.1214/15-AOS1270D", "report-no": "IMS-AOS-AOS1270D", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discussion of \"Frequentist coverage of adaptive nonparametric Bayesian\ncredible sets\" by Szab\\'o, van der Vaart and van Zanten [arXiv:1310.4489v5].\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2015 05:10:13 GMT"}], "update_date": "2015-09-08", "authors_parsed": [["Low", "Mark G.", ""], ["Ma", "Zongming", ""]]}, {"id": "1509.01905", "submitter": "Subhashis Ghosal", "authors": "Subhashis Ghosal", "title": "Discussion of \"Frequentist coverage of adaptive nonparametric Bayesian\n  credible sets\"", "comments": "Published at http://dx.doi.org/10.1214/15-AOS1270E in the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2015, Vol. 43, No. 4, 1455-1462", "doi": "10.1214/15-AOS1270E", "report-no": "IMS-AOS-AOS1270E", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discussion of \"Frequentist coverage of adaptive nonparametric Bayesian\ncredible sets\" by Szab\\'o, van der Vaart and van Zanten [arXiv:1310.4489v5].\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2015 05:12:41 GMT"}], "update_date": "2015-09-08", "authors_parsed": [["Ghosal", "Subhashis", ""]]}, {"id": "1509.01906", "submitter": "Botond Szab\\'{o}", "authors": "Botond Szab\\'o, A. W. van der Vaart, J. H. van Zanten", "title": "Rejoinder to discussions of \"Frequentist coverage of adaptive\n  nonparametric Bayesian credible sets\"", "comments": "Published at http://dx.doi.org/10.1214/15-AOS1270REJ in the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2015, Vol. 43, No. 4, 1463-1470", "doi": "10.1214/15-AOS1270REJ", "report-no": "IMS-AOS-AOS1270REJ", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rejoinder of \"Frequentist coverage of adaptive nonparametric Bayesian\ncredible sets\" by Szab\\'o, van der Vaart and van Zanten [arXiv:1310.4489v5].\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2015 05:15:44 GMT"}], "update_date": "2016-08-07", "authors_parsed": [["Szab\u00f3", "Botond", ""], ["van der Vaart", "A. W.", ""], ["van Zanten", "J. H.", ""]]}, {"id": "1509.02017", "submitter": "Matthias Kirchner", "authors": "Matthias Kirchner", "title": "An estimation procedure for the Hawkes process", "comments": "35 pages including 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a nonparametric estimation procedure for the\nmultivariate Hawkes point process. The timeline is cut into bins and---for each\ncomponent process---the number of points in each bin is counted. The\ndistribution of the resulting \"bin-count sequences\" can be approximated by an\ninteger-valued autoregressive model known as the (multivariate) INAR($p$)\nmodel. We represent the INAR($p$) model as a standard vector-valued linear\nautoregressive time series with white-noise innovations (VAR($p$)). We\nestablish consistency and asymptotic normality for conditional least-squares\nestimation of the VAR($p$), respectively, the INAR($p$) model. After an\nappropriate scaling, these time series estimates yield estimates for the\nunderlying multivariate Hawkes process as well as formulas for their asymptotic\ndistribution. All results are presented in such a way that computer\nimplementation, e.g., in R, is straightforward. Simulation studies confirm the\neffectiveness of our estimation procedure. Finally, we present a data example\nwhere the method is applied to bivariate event-streams in financial\nlimit-order-book data. We fit a bivariate Hawkes model on the joint process of\nlimit and market order arrivals. The analysis exhibits a remarkably asymmetric\nrelation between the two component processes: incoming market orders excite the\nlimit order flow heavily whereas the market order flow is hardly affected by\nincoming limit orders.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2015 12:51:45 GMT"}], "update_date": "2015-09-08", "authors_parsed": [["Kirchner", "Matthias", ""]]}, {"id": "1509.02019", "submitter": "Richard Fischer", "authors": "Cristina Butucea, Jean-Fran\\c{c}ois Delmas, Anne Dutfoy, Richard\n  Fischer", "title": "Maximum entropy distribution of order statistics with given marginals", "comments": "35 pages, overview of the notations at page 33", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider distributions of ordered random vectors with given\none-dimensional marginal distributions. We give an elementary necessary and\nsufficient condition for the existence of such a distribution with finite\nentropy. In this case, we give explicitly the density of the unique\ndistribution which achieves the maximal entropy and compute the value of its\nentropy. This density is the unique one which has a product form on its support\nand the given one-dimensional marginals. The proof relies on the study of\ncopulas with given one-dimensional marginal distributions for its order\nstatistics.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2015 13:01:14 GMT"}], "update_date": "2015-09-08", "authors_parsed": [["Butucea", "Cristina", ""], ["Delmas", "Jean-Fran\u00e7ois", ""], ["Dutfoy", "Anne", ""], ["Fischer", "Richard", ""]]}, {"id": "1509.02237", "submitter": "Aaditya Ramdas", "authors": "Aaditya Ramdas, Nicolas Garcia, Marco Cuturi", "title": "On Wasserstein Two Sample Testing and Related Families of Nonparametric\n  Tests", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonparametric two sample or homogeneity testing is a decision theoretic\nproblem that involves identifying differences between two random variables\nwithout making parametric assumptions about their underlying distributions. The\nliterature is old and rich, with a wide variety of statistics having being\nintelligently designed and analyzed, both for the unidimensional and the\nmultivariate setting. Our contribution is to tie together many of these tests,\ndrawing connections between seemingly very different statistics. In this work,\nour central object is the Wasserstein distance, as we form a chain of\nconnections from univariate methods like the Kolmogorov-Smirnov test, PP/QQ\nplots and ROC/ODC curves, to multivariate tests involving energy statistics and\nkernel based maximum mean discrepancy. Some connections proceed through the\nconstruction of a \\textit{smoothed} Wasserstein distance, and others through\nthe pursuit of a \"distribution-free\" Wasserstein test. Some observations in\nthis chain are implicit in the literature, while others seem to have not been\nnoticed thus far. Given nonparametric two sample testing's classical and\ncontinued importance, we aim to provide useful connections for theorists and\npractitioners familiar with one subset of methods but not others.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2015 01:08:04 GMT"}, {"version": "v2", "created": "Tue, 13 Oct 2015 01:42:46 GMT"}], "update_date": "2015-10-14", "authors_parsed": [["Ramdas", "Aaditya", ""], ["Garcia", "Nicolas", ""], ["Cuturi", "Marco", ""]]}, {"id": "1509.02451", "submitter": "Didier Ch\\'etelat", "authors": "Didier Ch\\'etelat, Martin T. Wells", "title": "Improved Second Order Estimation in the Singular Multivariate Normal\n  Model", "comments": "34 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of estimating covariance and precision matrices, and\ntheir associated discriminant coefficients, from normal data when the rank of\nthe covariance matrix is strictly smaller than its dimension and the available\nsample size. Using unbiased risk estimation, we construct novel estimators by\nminimizing upper bounds on the difference in risk over several classes. Our\nproposal estimates are empirically demonstrated to offer substantial\nimprovement over classical approaches.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2015 17:14:54 GMT"}], "update_date": "2015-09-09", "authors_parsed": [["Ch\u00e9telat", "Didier", ""], ["Wells", "Martin T.", ""]]}, {"id": "1509.02473", "submitter": "Jean-Marc Bardet", "authors": "Jean-Marc Bardet (SAMM), Solohaja-Faniaha Dimby (SAMM)", "title": "A new non-parametric detector of univariate outliers for distributions\n  with unbounded support", "comments": null, "journal-ref": "Extremes, Springer Verlag (Germany), 2017", "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The purpose of this paper is to construct a new non-parametric detector of\nunivariate outliers and to study its asymptotic properties. This detector is\nbased on a Hill's type statistic. It satisfies a unique asymptotic behavior for\na large set of probability distributions with positive unbounded support (for\ninstance: for the absolute value of Gaussian, Gamma, Weibull, Student or\nregular variations distributions). We have illustrated our results by numerical\nsimulations which show the accuracy of this detector with respect to other\nusual univariate outlier detectors (Tukey, MAD or Local Outlier Factor\ndetectors). The detection of outliers in a database providing the prices of\nused cars is also proposed as an application to real-life database.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2015 18:04:14 GMT"}, {"version": "v2", "created": "Wed, 3 May 2017 09:11:42 GMT"}], "update_date": "2017-05-04", "authors_parsed": [["Bardet", "Jean-Marc", "", "SAMM"], ["Dimby", "Solohaja-Faniaha", "", "SAMM"]]}, {"id": "1509.02551", "submitter": "Jasmijn Baaijens", "authors": "Jasmijn A. Baaijens and Jan Draisma", "title": "On the existence of identifiable reparametrizations for linear\n  compartment models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The parameters of a linear compartment model are usually estimated from\nexperimental input-output data. A problem arises when infinitely many parameter\nvalues can yield the same result; such a model is called unidentifiable. In\nthis case, one can search for an identifiable reparametrization of the model: a\nmap which reduces the number of parameters, such that the reduced model is\nidentifiable. We study a specific class of models which are known to be\nunidentifiable. Using algebraic geometry and graph theory, we translate a\ncriterion given by Meshkat and Sullivant for the existence of an identifiable\nscaling reparametrization to a new criterion based on the rank of a weighted\nadjacency matrix of a certain bipartite graph. This allows us to derive several\nnew constructions to obtain graphs with an identifiable scaling\nreparametrization. Using these constructions, a large subclass of such graphs\nis obtained. Finally, we present a procedure of subdividing or deleting edges\nto ensure that a model has an identifiable scaling reparametrization.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2015 09:05:01 GMT"}, {"version": "v2", "created": "Mon, 7 Mar 2016 20:56:37 GMT"}], "update_date": "2016-03-08", "authors_parsed": [["Baaijens", "Jasmijn A.", ""], ["Draisma", "Jan", ""]]}, {"id": "1509.02564", "submitter": "Andy Leung", "authors": "Andy Leung, Hongyang Zhang, Ruben H. Zamar", "title": "Robust regression estimation and inference in the presence of cellwise\n  and casewise contamination", "comments": null, "journal-ref": null, "doi": "10.1016/j.csda.2016.01.004", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cellwise outliers are likely to occur together with casewise outliers in\nmodern data sets with relatively large dimension. Recent work has shown that\ntraditional robust regression methods may fail for data sets in this paradigm.\nThe proposed method, called three-step regression, proceeds as follows: first,\nit uses a consistent univariate filter to detect and eliminate extreme cellwise\noutliers; second, it applies a robust estimator of multivariate location and\nscatter to the filtered data to down-weight casewise outliers; third, it\ncomputes robust regression coefficients from the estimates obtained in the\nsecond step. The three-step estimator is shown to be consistent and\nasymptotically normal at the central model under some assumptions on the tail\ndistributions of the continuous covariates. The estimator is extended to handle\nboth numerical and dummy covariates using an iterative algorithm. Extensive\nsimulation results show that the three-step estimator is resilient to cellwise\noutliers. It also performs well under casewise contaminations when comparing\nwith traditional high breakdown point estimators.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2015 21:37:10 GMT"}, {"version": "v2", "created": "Mon, 26 Dec 2016 04:05:07 GMT"}], "update_date": "2016-12-28", "authors_parsed": [["Leung", "Andy", ""], ["Zhang", "Hongyang", ""], ["Zamar", "Ruben H.", ""]]}, {"id": "1509.02650", "submitter": "Chanchal Kundu", "authors": "Amarjit Kundu and Chanchal Kundu", "title": "Bivariate Extension of (Dynamic) Cumulative Past Entropy", "comments": "22 pages and 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the concept of cumulative residual entropy (CRE) has been studied\nby many researchers in higher dimensions. In this article, we extend the\ndefinition of (dynamic) cumulative past entropy (DCPE), a dual measure of\n(dynamic) CRE, to bivariate setup and obtain some of its properties including\nbounds. We also look into the problem of extending DCPE for conditionally\nspecified models. Several properties, including monotonicity, and bounds of\nDCPE are obtained for conditional distributions. It is shown that the proposed\nmeasure uniquely determines the distribution function. Moreover, we also\npropose a stochastic order based on this measure.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2015 06:37:20 GMT"}], "update_date": "2015-09-10", "authors_parsed": [["Kundu", "Amarjit", ""], ["Kundu", "Chanchal", ""]]}, {"id": "1509.02704", "submitter": "Yury Kutoyants", "authors": "Rafail Khasminskii and Yury Kutoyants", "title": "On Parameter Estimation of Hidden Telegraph Process", "comments": "26 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of parameter estimation by the observations of the two-state\ntelegraph process in the presence of white Gaussian noise is considered. The\nproperties of estimator of the method of moments are described in the\nasymptotics of large samples. Then this estimator is used as preliminary one to\nconstruct the one-step MLE-process, which provides the asymptotically normal\nand asymptotically efficient estimation of the unknown parameters.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2015 10:18:41 GMT"}], "update_date": "2015-09-10", "authors_parsed": [["Khasminskii", "Rafail", ""], ["Kutoyants", "Yury", ""]]}, {"id": "1509.02715", "submitter": "Yury Kutoyants", "authors": "Oleg Chernoyarov, Yury Kutoyants and Andrei Trifonov", "title": "On Misspecifications in Regularity and Properties of Estimators", "comments": "26 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of parameter estimation by the continuous time observations of a\ndeterministic signal in white gaussian noise is considered. The asymptotic\nproperties of the maximul likelihood estimator are described in the asymptotics\nof small noise (large siglal-to-noise ratio). We are interested by the\nsituation when there is a misspecification in the regularity conditions. In\nparticular it is supposed that the statistician uses a discontinuous\n(change-point type) model of signal, when the true signal is continuously\ndifferentiable function of the unknown parameter.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2015 10:43:51 GMT"}], "update_date": "2015-09-10", "authors_parsed": [["Chernoyarov", "Oleg", ""], ["Kutoyants", "Yury", ""], ["Trifonov", "Andrei", ""]]}, {"id": "1509.02811", "submitter": "Ankit Parekh", "authors": "Ankit Parekh and Ivan W. Selesnick", "title": "Convex Fused Lasso Denoising with Non-Convex Regularization and its use\n  for Pulse Detection", "comments": "Supplementary MATLAB code available at http://goo.gl/xAi85N. in 2015\n  IEEE Signal Processing in Medicine and Biology Symposium", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a convex formulation of the fused lasso signal approximation\nproblem consisting of non-convex penalty functions. The fused lasso signal\nmodel aims to estimate a sparse piecewise constant signal from a noisy\nobservation. Originally, the $\\ell_1$ norm was used as a sparsity-inducing\nconvex penalty function for the fused lasso signal approximation problem.\nHowever, the $\\ell_1$ norm underestimates signal values. Non-convex\nsparsity-inducing penalty functions better estimate signal values. In this\npaper, we show how to ensure the convexity of the fused lasso signal\napproximation problem with non-convex penalty functions. We further derive a\ncomputationally efficient algorithm using the majorization-minimization\ntechnique. We apply the proposed fused lasso method for the detection of\npulses.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2015 15:44:08 GMT"}, {"version": "v2", "created": "Thu, 1 Oct 2015 16:42:31 GMT"}, {"version": "v3", "created": "Mon, 7 Dec 2015 20:01:13 GMT"}], "update_date": "2015-12-08", "authors_parsed": [["Parekh", "Ankit", ""], ["Selesnick", "Ivan W.", ""]]}, {"id": "1509.02872", "submitter": "Van Ha Hoang", "authors": "Van Ha Hoang (LPP)", "title": "Estimating the Division Kernel of a Size-Structured Population", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a size-structured population describing the cell divisions. The\ncell population is described by an empirical measure and we observe the\ndivisions in the continuous time interval [0, T ]. We address here the problem\nof estimating the division kernel h (or fragmentation kernel) in case of\ncomplete data. An adaptive estimator of h is constructed based on a kernel\nfunction K with a fully data-driven bandwidth selection method. We obtain an\noracle inequality and an exponential convergence rate, for which optimality is\nconsidered.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2015 17:58:54 GMT"}, {"version": "v2", "created": "Thu, 24 Sep 2015 12:04:58 GMT"}, {"version": "v3", "created": "Thu, 24 Dec 2015 10:50:33 GMT"}, {"version": "v4", "created": "Thu, 19 May 2016 10:09:19 GMT"}], "update_date": "2016-05-20", "authors_parsed": [["Hoang", "Van Ha", "", "LPP"]]}, {"id": "1509.02880", "submitter": "Yury Kutoyants", "authors": "Oleg Chernoyarov, Serguei Dachian and Yury Kutoyants", "title": "On Parameter Estimation for Cusp-type Signals", "comments": "22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of parameter estimation by the observations of\ndeterministic signal in white gaussian noise. It is supposed that the signal\nhas a singularity of cusp-type. The properties of the maximum likelihood and\nbayesian estimators are described in the asymptotics of small noise. Special\nattention is paid to the problem of parameter estimation in the situation of\nmisspecification in regularity, i.e.; the statistician supposes that the\nobserved signal has this singularity, but the real signal is smooth. The rate\nand the asymptotic distribution of the maximum likelihood estimator in this\nsituation are described.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2015 18:25:22 GMT"}], "update_date": "2015-09-10", "authors_parsed": [["Chernoyarov", "Oleg", ""], ["Dachian", "Serguei", ""], ["Kutoyants", "Yury", ""]]}, {"id": "1509.02992", "submitter": "Cameron Freer", "authors": "Nathanael L. Ackerman and Cameron E. Freer and Daniel M. Roy", "title": "On computability and disintegration", "comments": "28 pages. Substantially updated following referee suggestions", "journal-ref": "Mathematical Structures in Computer Science, 27:8 (2017), pp.\n  1287-1314", "doi": "10.1017/S0960129516000098", "report-no": null, "categories": "math.LO cs.LO math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the disintegration operator on a complete separable metric space\nalong a projection map, restricted to measures for which there is a unique\ncontinuous disintegration, is strongly Weihrauch equivalent to the limit\noperator Lim. When a measure does not have a unique continuous disintegration,\nwe may still obtain a disintegration when some basis of continuity sets has the\nVitali covering property with respect to the measure; the disintegration,\nhowever, may depend on the choice of sets. We show that, when the basis is\ncomputable, the resulting disintegration is strongly Weihrauch reducible to\nLim, and further exhibit a single distribution realizing this upper bound.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2015 02:56:21 GMT"}, {"version": "v2", "created": "Tue, 10 May 2016 18:51:35 GMT"}], "update_date": "2017-11-22", "authors_parsed": [["Ackerman", "Nathanael L.", ""], ["Freer", "Cameron E.", ""], ["Roy", "Daniel M.", ""]]}, {"id": "1509.03025", "submitter": "Yudong Chen", "authors": "Yudong Chen, Martin J. Wainwright", "title": "Fast low-rank estimation by projected gradient descent: General\n  statistical and algorithmic guarantees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimization problems with rank constraints arise in many applications,\nincluding matrix regression, structured PCA, matrix completion and matrix\ndecomposition problems. An attractive heuristic for solving such problems is to\nfactorize the low-rank matrix, and to run projected gradient descent on the\nnonconvex factorized optimization problem. The goal of this problem is to\nprovide a general theoretical framework for understanding when such methods\nwork well, and to characterize the nature of the resulting fixed point. We\nprovide a simple set of conditions under which projected gradient descent, when\ngiven a suitable initialization, converges geometrically to a statistically\nuseful solution. Our results are applicable even when the initial solution is\noutside any region of local convexity, and even when the problem is globally\nconcave. Working in a non-asymptotic framework, we show that our conditions are\nsatisfied for a wide range of concrete models, including matrix regression,\nstructured PCA, matrix completion with real and quantized observations, matrix\ndecomposition, and graph clustering problems. Simulation results show excellent\nagreement with the theoretical predictions.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2015 06:07:52 GMT"}], "update_date": "2015-09-11", "authors_parsed": [["Chen", "Yudong", ""], ["Wainwright", "Martin J.", ""]]}, {"id": "1509.03119", "submitter": "Ad\\'ela\\\"ide Olivier", "authors": "S. Val\\`ere Bitseki Penda and Marc Hoffmann and Ad\\'ela\\\"ide Olivier", "title": "Adaptive estimation for bifurcating Markov chains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a first part, we prove Bernstein-type deviation inequalities for\nbifurcating Markov chains (BMC) under a geometric ergodicity assumption,\ncompleting former results of Guyon and Bitseki Penda, Djellout and Guillin.\nThese preliminary results are the key ingredient to implement nonparametric\nwavelet thresholding estimation procedures: in a second part, we construct\nnonparametric estimators of the transition density of a BMC, of its mean\ntransition density and of the corresponding invariant density, and show\nsmoothness adaptation over various multivariate Besov classes under $L^p$-loss\nerror, for $1 \\leq p < \\infty$. We prove that our estimators are (nearly)\noptimal in a minimax sense. As an application, we obtain new results for the\nestimation of the splitting size-dependent rate of growth-fragmentation models\nand we extend the statistical study of bifurcating autoregressive processes.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2015 12:06:44 GMT"}], "update_date": "2015-09-11", "authors_parsed": [["Penda", "S. Val\u00e8re Bitseki", ""], ["Hoffmann", "Marc", ""], ["Olivier", "Ad\u00e9la\u00efde", ""]]}, {"id": "1509.03163", "submitter": "Herold Dehling", "authors": "Herold Dehling, Brice Franke, Jeannette H.C. Woerner", "title": "Estimating Drift Parameters in a Fractional Ornstein Uhlenbeck Process\n  with Periodic Mean", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We construct a least squares estimator for the drift parameters of a\nfractional Ornstein Uhlenbeck process with periodic mean function and long\nrange dependence. For this estimator we prove consistency and asymptotic\nnormality. In contrast to the classical fractional Ornstein Uhlenbeck process\nwithout periodic mean function the rate of convergence is slower depending on\nthe Hurst parameter $H$, namely $n^{1-H}$.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2015 14:02:20 GMT"}], "update_date": "2015-09-11", "authors_parsed": [["Dehling", "Herold", ""], ["Franke", "Brice", ""], ["Woerner", "Jeannette H. C.", ""]]}, {"id": "1509.03258", "submitter": "Shirshendu Ganguly", "authors": "S\\'ebastien Bubeck, Shirshendu Ganguly", "title": "Entropic CLT and phase transition in high-dimensional Wishart matrices", "comments": "16 pages. Final Version. Appeared in IMRN (2018), Issue 2, Pages\n  588-606", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.IT math.FA math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider high dimensional Wishart matrices $\\mathbb{X} \\mathbb{X}^{\\top}$\nwhere the entries of $\\mathbb{X} \\in {\\mathbb{R}^{n \\times d}}$ are i.i.d. from\na log-concave distribution. We prove an information theoretic phase transition:\nsuch matrices are close in total variation distance to the corresponding\nGaussian ensemble if and only if $d$ is much larger than $n^3$. Our proof is\nentropy-based, making use of the chain rule for relative entropy along with the\nrecursive structure in the definition of the Wishart ensemble. The proof\ncrucially relies on the well known relation between Fisher information and\nentropy, a variational representation for Fisher information, concentration\nbounds for the spectral norm of a random matrix, and certain small ball\nprobability estimates for log-concave measures.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2015 18:37:23 GMT"}, {"version": "v2", "created": "Sun, 13 Sep 2015 18:16:16 GMT"}, {"version": "v3", "created": "Sun, 12 Aug 2018 19:11:50 GMT"}], "update_date": "2018-08-14", "authors_parsed": [["Bubeck", "S\u00e9bastien", ""], ["Ganguly", "Shirshendu", ""]]}, {"id": "1509.03410", "submitter": "Gustavo da Silva Ferreira", "authors": "Gustavo da Silva Ferreira, Dani Gamerman", "title": "Optimal Design in Geostatistics under Preferential Sampling", "comments": "Published at http://dx.doi.org/10.1214/15-BA944 in the Bayesian\n  Analysis (http://projecteuclid.org/euclid.ba) by the International Society of\n  Bayesian Analysis (http://bayesian.org/)", "journal-ref": "Bayesian Analysis 2015, Vol. 10, No. 3, 711-735", "doi": "10.1214/15-BA944", "report-no": "VTeX-BA-BA944", "categories": "math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper analyses the effect of preferential sampling in Geostatistics when\nthe choice of new sampling locations is the main interest of the researcher. A\nBayesian criterion based on maximizing utility functions is used. Simulated\nstudies are presented and highlight the strong influence of preferential\nsampling in the decisions. The computational complexity is faced by treating\nthe new local sampling locations as a model parameter and the optimal choice is\nthen made by analysing its posterior distribution. Finally, an application is\npresented using rainfall data collected during spring in Rio de Janeiro. The\nresults showed that the optimal design is substantially changed under\npreferential sampling effects. Furthermore, it was possible to identify other\ninteresting aspects related to preferential sampling effects in estimation and\nprediction in Geostatistics. With the Rejoinder to Comments [arXiv:1509.04817],\n[arXiv:1509.04819], [arXiv:1509.04821].\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2015 08:09:02 GMT"}, {"version": "v2", "created": "Tue, 22 Sep 2015 10:55:02 GMT"}], "update_date": "2015-09-23", "authors_parsed": [["Ferreira", "Gustavo da Silva", ""], ["Gamerman", "Dani", ""]]}, {"id": "1509.03459", "submitter": "Chao Zheng", "authors": "Wen-Xin Zhou, Chao Zheng and Zhen Zhang", "title": "Two-Sample Smooth Tests for the Equality of Distributions", "comments": "40 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the problem of testing the equality of two unspecified\ndistributions. The classical omnibus tests such as the Kolmogorov-Smirnov and\nCram\\`er-von Mises are known to suffer from low power against essentially all\nbut location-scale alternatives. We propose a new two-sample test that modifies\nthe Neyman's smooth test and extend it to the multivariate case based on the\nidea of projection pursue. The asymptotic null property of the test and its\npower against local alternatives are studied. The multiplier bootstrap method\nis employed to compute the critical value of the multivariate test. We\nestablish validity of the bootstrap approximation in the case where the\ndimension is allowed to grow with the sample size. Numerical studies show that\nthe new testing procedures perform well even for small sample sizes and are\npowerful in detecting local features or high-frequency components.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2015 11:10:56 GMT"}, {"version": "v2", "created": "Mon, 14 Sep 2015 10:25:27 GMT"}], "update_date": "2015-09-15", "authors_parsed": [["Zhou", "Wen-Xin", ""], ["Zheng", "Chao", ""], ["Zhang", "Zhen", ""]]}, {"id": "1509.03466", "submitter": "Tomasz Checinski", "authors": "Gernot Akemann, Tomasz Checinski and Mario Kieburg", "title": "Spectral correlation functions of the sum of two independent complex\n  Wishart matrices with unequal covariances", "comments": "32 pages, 2 figures", "journal-ref": "J. Phys. A: Math. Theor. 49 (2016) 315201", "doi": "10.1088/1751-8113/49/31/315201", "report-no": null, "categories": "math-ph cond-mat.stat-mech math.MP math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We compute the spectral statistics of the sum H of two independent complex\nWishart matrices, each of which is correlated with a different covariance\nmatrix. Random matrix theory enjoys many applications including sums and\nproducts of random matrices. Typically ensembles with correlations among the\nmatrix elements are much more difficult to solve. Using a combination of\nsupersymmetry, superbosonisation and bi-orthogonal functions we are able to\ndetermine all spectral k-point density correlation functions of H for arbitrary\nmatrix size N. In the half-degenerate case, when one of the covariance matrices\nis proportional to the identity, the recent results by Kumar for the joint\neigenvalue distribution of H serve as our starting point. In this case the\nensemble has a bi-orthogonal structure and we explicitly determine its kernel,\nproviding its exact solution for finite N. The kernel follows from computing\nthe expectation value of a single characteristic polynomial. In the general\nnon-degenerate case the generating function for the k-point resolvent is\ndetermined from a supersymmetric evaluation of the expectation value of k\nratios of characteristic polynomials. Numerical simulations illustrate our\nfindings for the spectral density at finite N and we also give indications how\nto do the asymptotic large-N analysis.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2015 11:48:46 GMT"}, {"version": "v2", "created": "Wed, 4 May 2016 14:57:57 GMT"}, {"version": "v3", "created": "Sat, 2 Jul 2016 15:46:32 GMT"}], "update_date": "2016-07-05", "authors_parsed": [["Akemann", "Gernot", ""], ["Checinski", "Tomasz", ""], ["Kieburg", "Mario", ""]]}, {"id": "1509.03860", "submitter": "Peng Ding", "authors": "Wang Miao, Peng Ding, and Zhi Geng", "title": "Identifiability of Normal and Normal Mixture Models With Nonignorable\n  Missing Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Missing data problems arise in many applied research studies. They may\njeopardize statistical inference of the model of interest, if the missing\nmechanism is nonignorable, that is, the missing mechanism depends on the\nmissing values themselves even conditional on the observed data. With a\nnonignorable missing mechanism, the model of interest is often not identifiable\nwithout imposing further assumptions. We find that even if the missing\nmechanism has a known parametric form, the model is not identifiable without\nspecifying a parametric outcome distribution. Although it is fundamental for\nvalid statistical inference, identifiability under nonignorable missing\nmechanisms is not established for many commonly-used models. In this paper, we\nfirst demonstrate identifiability of the normal distribution under monotone\nmissing mechanisms. We then extend it to the normal mixture and $t$ mixture\nmodels with non-monotone missing mechanisms. We discover that models under the\nLogistic missing mechanism are less identifiable than those under the Probit\nmissing mechanism. We give necessary and sufficient conditions for\nidentifiability of models under the Logistic missing mechanism, which sometimes\ncan be checked in real data analysis. We illustrate our methods using a series\nof simulations, and apply them to a real-life dataset.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2015 15:34:26 GMT"}], "update_date": "2015-09-15", "authors_parsed": [["Miao", "Wang", ""], ["Ding", "Peng", ""], ["Geng", "Zhi", ""]]}, {"id": "1509.03880", "submitter": "Bertrand Iooss", "authors": "Thomas Browne, Bertrand Iooss (GdR MASCOT-NUM), Lo\\\"ic Le Gratiet,\n  J\\'erome Lonchampt", "title": "Stochastic simulators based optimization by Gaussian process metamodels\n  - Application to maintenance investments planning issues", "comments": "ENBIS 2015, Sep 2015, Prague, Czech Republic. 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with the construction of a metamodel (i.e. a simplified\nmathematical model) for a stochastic computer code (also called stochastic\nnumerical model or stochastic simulator), where stochastic means that the code\nmaps the realization of a random variable. The goal is to get, for a given\nmodel input, the main information about the output probability distribution by\nusing this metamodel and without running the computer code. In practical\napplications, such a metamodel enables one to have estimations of every\npossible random variable properties, such as the expectation, the probability\nof exceeding a threshold or any quantile. The present work is concentrated on\nthe emulation of the quantile function of the stochastic simulator by\ninterpolating well chosen basis function and metamodeling their coefficients\n(using the Gaussian process metamodel). This quantile function metamodel is\nthen used to treat a simple optimization strategy maintenance problem using a\nstochastic code, in order to optimize the quantile of an economic indicator.\nUsing the Gaussian process framework, an adaptive design method (called QFEI)\nis defined by extending in our case the well known EGO algorithm. This allows\nto obtain an \"optimal\" solution using a small number of simulator runs.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2015 18:53:41 GMT"}], "update_date": "2015-09-15", "authors_parsed": [["Browne", "Thomas", "", "GdR MASCOT-NUM"], ["Iooss", "Bertrand", "", "GdR MASCOT-NUM"], ["Gratiet", "Lo\u00efc Le", ""], ["Lonchampt", "J\u00e9rome", ""]]}, {"id": "1509.03882", "submitter": "Peggy Cenac", "authors": "Peggy C\\'enac (IMB), Basile De Loynes (IRMA), Arnaud Le Ny (LAMA),\n  Yoann Offret (IMB)", "title": "Persistent random walks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a walker that at each step keeps the same direction with a\nprobabilitythat depends on the time already spent in the direction the walker\nis currently moving. In this paper, we study some asymptotic properties of this\npersistent random walk and give the conditions of recurrence or transience in\nterms of \"transition\" probabilities to keep on the same direction or to change,\nwithout assuming that the latter admits any stationary probability. Examples\nare exhibited when this process is recurrent even if the random walk is not\nsymmetric.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2015 18:57:33 GMT"}], "update_date": "2015-09-15", "authors_parsed": [["C\u00e9nac", "Peggy", "", "IMB"], ["De Loynes", "Basile", "", "IRMA"], ["Ny", "Arnaud Le", "", "LAMA"], ["Offret", "Yoann", "", "IMB"]]}, {"id": "1509.03935", "submitter": "Eric Strobl", "authors": "Eric V. Strobl, Shyam Visweswaran", "title": "Markov Boundary Discovery with Ridge Regularized Linear Models", "comments": "submitted to the Journal of Causal Inference", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ridge regularized linear models (RRLMs), such as ridge regression and the\nSVM, are a popular group of methods that are used in conjunction with\ncoefficient hypothesis testing to discover explanatory variables with a\nsignificant multivariate association to a response. However, many investigators\nare reluctant to draw causal interpretations of the selected variables due to\nthe incomplete knowledge of the capabilities of RRLMs in causal inference.\nUnder reasonable assumptions, we show that a modified form of RRLMs can get\nvery close to identifying a subset of the Markov boundary by providing a\nworst-case bound on the space of possible solutions. The results hold for any\nconvex loss, even when the underlying functional relationship is nonlinear, and\nthe solution is not unique. Our approach combines ideas in Markov boundary and\nsufficient dimension reduction theory. Experimental results show that the\nmodified RRLMs are competitive against state-of-the-art algorithms in\ndiscovering part of the Markov boundary from gene expression data.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2015 02:58:58 GMT"}], "update_date": "2015-09-15", "authors_parsed": [["Strobl", "Eric V.", ""], ["Visweswaran", "Shyam", ""]]}, {"id": "1509.03938", "submitter": "Yiyuan She", "authors": "Yiyuan She and Kun Chen", "title": "Robust Reduced Rank Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.AP stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In high-dimensional multivariate regression problems, enforcing low rank in\nthe coefficient matrix offers effective dimension reduction, which greatly\nfacilitates parameter estimation and model interpretation. However,\ncommonly-used reduced-rank methods are sensitive to data corruption, as the\nlow-rank dependence structure between response variables and predictors is\neasily distorted by outliers. We propose a robust reduced-rank regression\napproach for joint modeling and outlier detection. The problem is formulated as\na regularized multivariate regression with a sparse mean-shift parametrization,\nwhich generalizes and unifies some popular robust multivariate methods. An\nefficient thresholding-based iterative procedure is developed for optimization.\nWe show that the algorithm is guaranteed to converge, and the coordinatewise\nminimum point produced is statistically accurate under regularity conditions.\nOur theoretical investigations focus on nonasymptotic robust analysis, which\ndemonstrates that joint rank reduction and outlier detection leads to improved\nprediction accuracy. In particular, we show that redescending $\\psi$-functions\ncan essentially attain the minimax optimal error rate, and in some less\nchallenging problems convex regularization guarantees the same low error rate.\nThe performance of the proposed method is examined by simulation studies and\nreal data examples.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2015 03:09:04 GMT"}, {"version": "v2", "created": "Sat, 19 Nov 2016 04:35:58 GMT"}, {"version": "v3", "created": "Sat, 1 Apr 2017 20:06:39 GMT"}, {"version": "v4", "created": "Thu, 13 Apr 2017 16:54:31 GMT"}, {"version": "v5", "created": "Sat, 15 Jul 2017 09:52:38 GMT"}], "update_date": "2017-07-18", "authors_parsed": [["She", "Yiyuan", ""], ["Chen", "Kun", ""]]}, {"id": "1509.03966", "submitter": "Animesh Kumar", "authors": "Animesh Kumar", "title": "Bandlimited Spatial Field Sampling with Mobile Sensors in the Absence of\n  Location Information", "comments": "Submitted to IEEE Trans on Signal Processing", "journal-ref": null, "doi": "10.1109/TIT.2017.2651878", "report-no": null, "categories": "cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sampling of physical fields with mobile sensor is an emerging area. In this\ncontext, this work introduces and proposes solutions to a fundamental question:\ncan a spatial field be estimated from samples taken at unknown sampling\nlocations?\n  Unknown sampling location, sample quantization, unknown bandwidth of the\nfield, and presence of measurement-noise present difficulties in the process of\nfield estimation. In this work, except for quantization, the other three issues\nwill be tackled together in a mobile-sampling framework. Spatially bandlimited\nfields are considered. It is assumed that measurement-noise affected field\nsamples are collected on spatial locations obtained from an unknown renewal\nprocess. That is, the samples are obtained on locations obtained from a renewal\nprocess, but the sampling locations and the renewal process distribution are\nunknown. In this unknown sampling location setup, it is shown that the\nmean-squared error in field estimation decreases as $O(1/n)$ where $n$ is the\naverage number of samples collected by the mobile sensor. The average number of\nsamples collected is determined by the inter-sample spacing distribution in the\nrenewal process. An algorithm to ascertain spatial field's bandwidth is\ndetailed, which works with high probability as the average number of samples\n$n$ increases. This algorithm works in the same setup, i.e., in the presence of\nmeasurement-noise and unknown sampling locations.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2015 07:18:30 GMT"}, {"version": "v2", "created": "Sun, 24 Jan 2016 14:34:45 GMT"}], "update_date": "2017-07-12", "authors_parsed": [["Kumar", "Animesh", ""]]}, {"id": "1509.04093", "submitter": "Benjamin Stucky", "authors": "Benjamin Stucky, Sara van de Geer", "title": "Sharp Oracle Inequalities for Square Root Regularization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a set of regularization methods for high-dimensional linear\nregression models. These penalized estimators have the square root of the\nresidual sum of squared errors as loss function, and any weakly decomposable\nnorm as penalty function. This fit measure is chosen because of its property\nthat the estimator does not depend on the unknown standard deviation of the\nnoise. On the other hand, a generalized weakly decomposable norm penalty is\nvery useful in being able to deal with different underlying sparsity\nstructures. We can choose a different sparsity inducing norm depending on how\nwe want to interpret the unknown parameter vector $\\beta$. Structured sparsity\nnorms, as defined in Micchelli et al. [18], are special cases of weakly\ndecomposable norms, therefore we also include the square root LASSO (Belloni et\nal. [3]), the group square root LASSO (Bunea et al. [10]) and a new method\ncalled the square root SLOPE (in a similar fashion to the SLOPE from Bogdan et\nal. [6]). For this collection of estimators our results provide sharp oracle\ninequalities with the Karush-Kuhn-Tucker conditions. We discuss some examples\nof estimators. Based on a simulation we illustrate some advantages of the\nsquare root SLOPE.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2015 13:48:24 GMT"}, {"version": "v2", "created": "Mon, 27 Jun 2016 15:30:22 GMT"}], "update_date": "2016-06-28", "authors_parsed": [["Stucky", "Benjamin", ""], ["van de Geer", "Sara", ""]]}, {"id": "1509.04388", "submitter": "Murat A. Erdogdu", "authors": "Lee H. Dicker and Murat A. Erdogdu", "title": "Flexible results for quadratic forms with applications to variance\n  components estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive convenient uniform concentration bounds and finite sample\nmultivariate normal approximation results for quadratic forms, then describe\nsome applications involving variance components estimation in linear\nrandom-effects models. Random-effects models and variance components estimation\nare classical topics in statistics, with a corresponding well-established\nasymptotic theory. However, our finite sample results for quadratic forms\nprovide additional flexibility for easily analyzing random-effects models in\nnon-standard settings, which are becoming more important in modern applications\n(e.g. genomics). For instance, in addition to deriving novel non-asymptotic\nbounds for variance components estimators in classical linear random-effects\nmodels, we provide a concentration bound for variance components estimators in\nlinear models with correlated random-effects. Our general concentration bound\nis a uniform version of the Hanson-Wright inequality. The main normal\napproximation result in the paper is derived using Reinert and R\\\"{o}llin's\n(2009) embedding technique and multivariate Stein's method with exchangeable\npairs.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2015 03:46:12 GMT"}], "update_date": "2015-09-16", "authors_parsed": [["Dicker", "Lee H.", ""], ["Erdogdu", "Murat A.", ""]]}, {"id": "1509.04413", "submitter": "Fran\\c{c}ois Portier", "authors": "Fran\\c{c}ois Portier", "title": "Efficiency of Z-estimators indexed by the objective functions", "comments": "25 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the convergence of $Z$-estimators $\\widehat \\theta(\\eta)\\in \\mathbb\nR^p$ for which the objective function depends on a parameter $\\eta$ that\nbelongs to a Banach space $\\mathcal H$. Our results include the uniform\nconsistency over $\\mathcal H$ and the weak convergence in the space of bounded\n$\\mathbb R^p$-valued functions defined on $\\mathcal H$. Furthermore when $\\eta$\nis a tuning parameter optimally selected at $\\eta_0$, we provide conditions\nunder which an estimated $\\widehat \\eta$ can be replaced by $\\eta_0$ without\naffecting the asymptotic variance. Interestingly, these conditions are free\nfrom any rate of convergence of $\\widehat \\eta$ to $\\eta_0$ but they require\nthe space described by $\\widehat \\eta$ to be not too large. We highlight\nseveral applications of our results and we study in detail the case where\n$\\eta$ is the weight function in weighted regression.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2015 06:17:07 GMT"}], "update_date": "2015-09-16", "authors_parsed": [["Portier", "Fran\u00e7ois", ""]]}, {"id": "1509.04508", "submitter": "Wang Miao", "authors": "Wang Miao and Eric Tchetgen Tchetgen", "title": "On Varieties of Doubly Robust Estimators Under Missingness Not at Random\n  With a Shadow Variable", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Suppose we are interested in the mean of an outcome variable missing not at\nrandom. Suppose however that one has available a fully observed shadow\nvariable, which is associated with the outcome but independent of the\nmissingness process conditional on covariates and the possibly unobserved\noutcome. Such a variable may be a proxy or a mismeasured version of the outcome\navailable for all individuals. We have previously established necessary and\nsufficient conditions for identification of the full data law in such a\nsetting, and have described semiparametric estimators including a doubly robust\nestimator of the outcome mean. Here, we propose two alternative doubly robust\nestimators for the outcome mean, which may be viewed as extensions of analogous\nmethods under missingness at random, but enjoy different properties. We assess\ncorrectness of the required working models via straightforward goodness-of-fit\ntests.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2015 11:57:33 GMT"}, {"version": "v2", "created": "Mon, 25 Jan 2016 16:31:38 GMT"}], "update_date": "2016-01-26", "authors_parsed": [["Miao", "Wang", ""], ["Tchetgen", "Eric Tchetgen", ""]]}, {"id": "1509.04632", "submitter": "Diego Hernan Diaz Martinez", "authors": "Diego Hern\\'an D\\'iaz Mart\\'inez, Facundo M\\'emoli, Washington Mio", "title": "The Shape of Data and Probability Measures", "comments": "46 pages, 12 figures, Theorems 1 and 3 have been revised, as well as\n  the results derived from them", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML math.MG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the notion of multiscale covariance tensor fields (CTF)\nassociated with Euclidean random variables as a gateway to the shape of their\ndistributions. Multiscale CTFs quantify variation of the data about every point\nin the data landscape at all spatial scales, unlike the usual covariance tensor\nthat only quantifies global variation about the mean. Empirical forms of\nlocalized covariance previously have been used in data analysis and\nvisualization, but we develop a framework for the systematic treatment of\ntheoretical questions and computational models based on localized covariance.\nWe prove strong stability theorems with respect to the Wasserstein distance\nbetween probability measures, obtain consistency results, as well as estimates\nfor the rate of convergence of empirical CTFs. These results ensure that CTFs\nare robust to sampling, noise and outliers. We provide numerous illustrations\nof how CTFs let us extract shape from data and also apply CTFs to manifold\nclustering, the problem of categorizing data points according to their noisy\nmembership in a collection of possibly intersecting, smooth submanifolds of\nEuclidean space. We prove that the proposed manifold clustering method is\nstable and carry out several experiments to validate the method.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2015 16:36:26 GMT"}, {"version": "v2", "created": "Tue, 28 Feb 2017 02:26:39 GMT"}], "update_date": "2017-03-01", "authors_parsed": [["Mart\u00ednez", "Diego Hern\u00e1n D\u00edaz", ""], ["M\u00e9moli", "Facundo", ""], ["Mio", "Washington", ""]]}, {"id": "1509.04704", "submitter": "Xiao Li", "authors": "Xiao Li and Karl Rohe", "title": "Central limit theorems for network driven sampling", "comments": "33 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Respondent-Driven Sampling is a popular technique for sampling hidden\npopulations. This paper models Respondent-Driven Sampling as a Markov process\nindexed by a tree. Our main results show that the Volz-Heckathorn estimator is\nasymptotically normal below a critical threshold. The key technical\ndifficulties stem from (i) the dependence between samples and (ii) the tree\nstructure which characterizes the dependence. The theorems allow the growth\nrate of the tree to exceed one and suggest that this growth rate should not be\ntoo large. To illustrate the usefulness of these results beyond their obvious\nuse, an example shows that in certain cases the sample average is preferable to\ninverse probability weighting. We provide a test statistic to distinguish\nbetween these two cases.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2015 11:22:56 GMT"}, {"version": "v2", "created": "Sun, 28 Aug 2016 00:56:50 GMT"}], "update_date": "2016-08-30", "authors_parsed": [["Li", "Xiao", ""], ["Rohe", "Karl", ""]]}, {"id": "1509.04817", "submitter": "Michael Chipeta", "authors": "Michael Chipeta, Peter J. Diggle", "title": "Comment on Article by Ferreira and Gamerman", "comments": "Published at http://dx.doi.org/10.1214/15-BA944A in the Bayesian\n  Analysis (http://projecteuclid.org/euclid.ba) by the International Society of\n  Bayesian Analysis (http://bayesian.org/)", "journal-ref": "Bayesian Analysis 2015, Vol. 10, No. 3, 737-739", "doi": "10.1214/15-BA944A", "report-no": "VTeX-BA-BA944A", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Comment on Article by Ferreira and Gamerman [arXiv:1509.03410].\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2015 06:14:38 GMT"}], "update_date": "2015-09-17", "authors_parsed": [["Chipeta", "Michael", ""], ["Diggle", "Peter J.", ""]]}, {"id": "1509.04819", "submitter": "Noel Cressie", "authors": "Noel Cressie, Raymond L. Chambers", "title": "Comment on Article by Ferreira and Gamerman", "comments": "Published at http://dx.doi.org/10.1214/15-BA944B in the Bayesian\n  Analysis (http://projecteuclid.org/euclid.ba) by the International Society of\n  Bayesian Analysis (http://bayesian.org/)", "journal-ref": "Bayesian Analysis 2015, Vol. 10, No. 3, 741-748", "doi": "10.1214/15-BA944B", "report-no": "VTeX-BA-BA944B", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A utility-function approach to optimal spatial sampling design is a powerful\nway to quantify what \"optimality\" means. The emphasis then should be to capture\nall possible contributions to utility, including scientific impact and the cost\nof sampling. The resulting sampling plan should contain a component of designed\nrandomness that would allow for a non-parametric design-based analysis if\nmodel-based assumptions were in doubt. [arXiv:1509.03410]\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2015 06:22:31 GMT"}], "update_date": "2015-09-17", "authors_parsed": [["Cressie", "Noel", ""], ["Chambers", "Raymond L.", ""]]}, {"id": "1509.04821", "submitter": "James V. Zidek", "authors": "James V. Zidek", "title": "Comment on Article by Ferreira and Gamerman", "comments": "Published at http://dx.doi.org/10.1214/15-BA944C in the Bayesian\n  Analysis (http://projecteuclid.org/euclid.ba) by the International Society of\n  Bayesian Analysis (http://bayesian.org/)", "journal-ref": "Bayesian Analysis 2015, Vol. 10, No. 3, 749-752", "doi": "10.1214/15-BA944C", "report-no": "VTeX-BA-BA944C", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Comment on Article by Ferreira and Gamerman [arXiv:1509.03410].\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2015 06:33:09 GMT"}], "update_date": "2015-09-17", "authors_parsed": [["Zidek", "James V.", ""]]}, {"id": "1509.04910", "submitter": "Jamal Najim", "authors": "Walid Hachem (LTCI), Adrien Hardy, Jamal Najim (LIGM)", "title": "A Survey on the Eigenvalues Local Behavior of Large Complex Correlated\n  Wishart Matrices", "comments": "29 pages; 7 figures; to be published in the \"Proceedings of the\n  Journ{\\'e}es MAS 2014\"", "journal-ref": "ESAIM: Proceedings and Surveys vol. 51, p. 150-174, october 2015", "doi": "10.1051/proc/201551009", "report-no": null, "categories": "math.PR math-ph math.MP math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of this note is to provide a pedagogical survey of the recent works\nby the authors ( arXiv:1409.7548 and arXiv:1507.06013) concerning the local\nbehavior of the eigenvalues of large complex correlated Wishart matrices at the\nedges and cusp points of the spectrum: Under quite general conditions, the\neigenvalues fluctuations at a soft edge of the limiting spectrum, at the hard\nedge when it is present, or at a cusp point, are respectively described by mean\nof the Airy kernel, the Bessel kernel, or the Pearcey kernel. Moreover, the\neigenvalues fluctuations at several soft edges are asymptotically independent.\nIn particular, the asymptotic fluctuations of the matrix condition number can\nbe described. Finally, the next order term of the hard edge asymptotics is\nprovided.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2015 13:26:26 GMT"}], "update_date": "2016-03-09", "authors_parsed": [["Hachem", "Walid", "", "LTCI"], ["Hardy", "Adrien", "", "LIGM"], ["Najim", "Jamal", "", "LIGM"]]}, {"id": "1509.05017", "submitter": "James Duffy", "authors": "James A. Duffy", "title": "Asymptotic Theory for Kernel Estimators under Moderate Deviations from a\n  Unit Root, with an Application to the Asymptotic Size of Nonparametric Tests", "comments": "Author accepted version for Econometric Theory. 26 pp. + 8 pp.\n  supplement", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide new asymptotic theory for kernel density estimators, when these\nare applied to autoregressive processes exhibiting moderate deviations from a\nunit root. This fills a gap in the existing literature, which has to date\nconsidered only nearly integrated and stationary autoregressive processes.\nThese results have applications to nonparametric predictive regression models.\nIn particular, we show that the null rejection probability of a nonparametric t\ntest is controlled uniformly in the degree of persistence of the regressor.\nThis provides a rigorous justification for the validity of the usual\nnonparametric inferential procedures, even in cases where regressors may be\nhighly persistent.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2015 19:50:33 GMT"}, {"version": "v2", "created": "Sat, 14 Nov 2015 19:05:08 GMT"}, {"version": "v3", "created": "Fri, 29 Dec 2017 00:56:23 GMT"}, {"version": "v4", "created": "Fri, 16 Aug 2019 13:05:48 GMT"}], "update_date": "2019-08-19", "authors_parsed": [["Duffy", "James A.", ""]]}, {"id": "1509.05099", "submitter": "Luis Enrique Benites S\\'anchez", "authors": "Luis E. Benites, V\\'ictor H. Lachos, Filidor E. Vilca", "title": "Case-Deletion Diagnostics for Quantile Regression Using the Asymmetric\n  Laplace Distribution", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To make inferences about the shape of a population distribution, the widely\npopular mean regression model, for example, is inadequate if the distribution\nis not approximately Gaussian (or symmetric). Compared to conventional mean\nregression (MR), quantile regression (QR) can characterize the entire\nconditional distribution of the outcome variable, and is more robust to\noutliers and misspecification of the error distribution. We present a\nlikelihood-based approach to the estimation of the regression quantiles based\non the asymmetric Laplace distribution (ALD), which has a hierarchical\nrepresentation that facilitates the implementation of the EM algorithm for the\nmaximum-likelihood estimation. We develop a case-deletion diagnostic analysis\nfor QR models based on the conditional expectation of the complete-data\nlog-likelihood function related to the EM algorithm. The techniques are\nillustrated with both simulated and real data sets, showing that our approach\nout-performed other common classic estimators. The proposed algorithm and\nmethods are implemented in the R package ALDqr().\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2015 01:44:49 GMT"}], "update_date": "2015-09-18", "authors_parsed": [["Benites", "Luis E.", ""], ["Lachos", "V\u00edctor H.", ""], ["Vilca", "Filidor E.", ""]]}, {"id": "1509.05453", "submitter": "Xi Chen", "authors": "Xi Chen and Weidong Liu", "title": "Graph Estimation for Matrix-variate Gaussian Data", "comments": "50 pages; 8 figures", "journal-ref": "Statistica Sinica (2017)", "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matrix-variate Gaussian graphical models (GGM) have been widely used for\nmodeling matrix-variate data. Since the support of sparse precision matrix\nrepresents the conditional independence graph among matrix entries, conducting\nsupport recovery yields valuable information. A commonly used approach is the\npenalized log-likelihood method. However, due to the complicated structure of\nprecision matrices in the form of Kronecker product, the log-likelihood is\nnon-convex, which presents challenges for both computation and theoretical\nanalysis. In this paper, we propose an alternative approach by formulating the\nsupport recovery problem into a multiple testing problem. A new test statistic\nis developed and based on that, we use the popular Benjamini and Hochberg's\nprocedure to control false discovery rate (FDR) asymptotically. Our method\ninvolves only convex optimization, making it computationally attractive.\nTheoretically, our method allows very weak conditions, i.e., even when the\nsample size is finite and the dimensions go to infinity, the asymptotic\nnormality of the test statistics and FDR control can still be guaranteed. We\nfurther provide the power analysis result. The finite sample performance of the\nproposed method is illustrated by both simulated and real data analysis.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2015 21:52:26 GMT"}, {"version": "v2", "created": "Thu, 31 Aug 2017 02:40:24 GMT"}], "update_date": "2017-09-01", "authors_parsed": [["Chen", "Xi", ""], ["Liu", "Weidong", ""]]}, {"id": "1509.05457", "submitter": "Ziwei Zhu", "authors": "Heather Battey, Jianqing Fan, Han Liu, Junwei Lu, Ziwei Zhu", "title": "Distributed Estimation and Inference with Statistical Guarantees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies hypothesis testing and parameter estimation in the context\nof the divide and conquer algorithm. In a unified likelihood based framework,\nwe propose new test statistics and point estimators obtained by aggregating\nvarious statistics from $k$ subsamples of size $n/k$, where $n$ is the sample\nsize. In both low dimensional and high dimensional settings, we address the\nimportant question of how to choose $k$ as $n$ grows large, providing a\ntheoretical upper bound on $k$ such that the information loss due to the divide\nand conquer algorithm is negligible. In other words, the resulting estimators\nhave the same inferential efficiencies and estimation rates as a practically\ninfeasible oracle with access to the full sample. Thorough numerical results\nare provided to back up the theory.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2015 22:08:41 GMT"}], "update_date": "2015-09-21", "authors_parsed": [["Battey", "Heather", ""], ["Fan", "Jianqing", ""], ["Liu", "Han", ""], ["Lu", "Junwei", ""], ["Zhu", "Ziwei", ""]]}, {"id": "1509.05569", "submitter": "Gilles Rebelles", "authors": "Gilles Rebelles", "title": "Pointwise adaptive estimation of a multivariate density under\n  independence hypothesis", "comments": "Published at http://dx.doi.org/10.3150/14-BEJ633 in the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2015, Vol. 21, No. 4, 1984-2023", "doi": "10.3150/14-BEJ633", "report-no": "IMS-BEJ-BEJ633", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of pointwise estimation of a multivariate\ndensity. We provide a data-driven selection rule from the family of kernel\nestimators and derive for it a pointwise oracle inequality. Using the latter\nbound, we show that the proposed estimator is minimax and minimax adaptive over\nthe scale of anisotropic Nikolskii classes. It is important to emphasize that\nour estimation method adjusts automatically to eventual independence structure\nof the underlying density. This, in its turn, allows to reduce significantly\nthe influence of the dimension on the accuracy of estimation (curse of\ndimensionality). The main technical tools used in our considerations are\npointwise uniform bounds of empirical processes developed recently in Lepski\n[Math. Methods Statist. 22 (2013) 83-99].\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2015 10:08:06 GMT"}], "update_date": "2015-09-21", "authors_parsed": [["Rebelles", "Gilles", ""]]}, {"id": "1509.05574", "submitter": "Paul Vos", "authors": "Paul Vos, Qiang Wu", "title": "Maximum likelihood estimators uniformly minimize distribution variance\n  among distribution unbiased estimators in exponential families", "comments": "Published at http://dx.doi.org/10.3150/14-BEJ637 in the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2015, Vol. 21, No. 4, 2120-2138", "doi": "10.3150/14-BEJ637", "report-no": "IMS-BEJ-BEJ637", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We employ a parameter-free distribution estimation framework where estimators\nare random distributions and utilize the Kullback-Leibler (KL) divergence as a\nloss function. Wu and Vos [J. Statist. Plann. Inference 142 (2012) 1525-1536]\nshow that when an estimator obtained from an i.i.d. sample is viewed as a\nrandom distribution, the KL risk of the estimator decomposes in a fashion\nparallel to the mean squared error decomposition when the estimator is a\nreal-valued random variable. In this paper, we explore how conditional versions\nof distribution expectation ($E^{\\dagger}$) can be defined so that a\ndistribution version of the Rao-Blackwell theorem holds. We define\ndistributional expectation and variance ($V^{\\dagger}$) that also provide a\ndecomposition of KL risk in exponential and mixture families. For exponential\nfamilies, we show that the maximum likelihood estimator (viewed as a random\ndistribution) is distribution unbiased and is the unique uniformly minimum\ndistribution variance unbiased (UMV$^{\\dagger}$U) estimator. Furthermore, we\nshow that the MLE is robust against model specification in that if the true\ndistribution does not belong to the exponential family, the MLE is\nUMV$^{\\dagger}$U for the KL projection of the true distribution onto the\nexponential families provided these two distribution have the same expectation\nfor the canonical statistic. To allow for estimators taking values outside of\nthe exponential family, we include results for KL projection and define an\nextended projection to accommodate the non-existence of the MLE for families\nhaving discrete sample space. Illustrative examples are provided.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2015 10:21:56 GMT"}], "update_date": "2015-09-21", "authors_parsed": [["Vos", "Paul", ""], ["Wu", "Qiang", ""]]}, {"id": "1509.05581", "submitter": "Fuqi Chen", "authors": "Fuqi Chen, S\\'ev\\'erien Nkurunziza", "title": "Optimal method in multiple regression with structural changes", "comments": "Published at http://dx.doi.org/10.3150/14-BEJ642 in the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2015, Vol. 21, No. 4, 2217-2241", "doi": "10.3150/14-BEJ642", "report-no": "IMS-BEJ-BEJ642", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider an estimation problem of the regression\ncoefficients in multiple regression models with several unknown change-points.\nUnder some realistic assumptions, we propose a class of estimators which\nincludes as a special cases shrinkage estimators (SEs) as well as the\nunrestricted estimator (UE) and the restricted estimator (RE). We also derive a\nmore general condition for the SEs to dominate the UE. To this end, we\ngeneralize some identities for the evaluation of the bias and risk functions of\nshrinkage-type estimators. As illustrative example, our method is applied to\nthe \"gross domestic product\" data set of 10 countries whose USA, Canada, UK,\nFrance and Germany. The simulation results corroborate our theoretical\nfindings.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2015 10:37:55 GMT"}], "update_date": "2016-08-07", "authors_parsed": [["Chen", "Fuqi", ""], ["Nkurunziza", "S\u00e9v\u00e9rien", ""]]}, {"id": "1509.05697", "submitter": "Victor Picheny", "authors": "Victor Picheny (INRA TOULOUSE, UBIA), Ronan Tr\\'epos (INRA TOULOUSE,\n  UBIA), Bastien Poublan (INRA TOULOUSE), Pierre Casadebaig (AGIR)", "title": "Sunflower phenotype optimization under climatic uncertainties using crop\n  models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accounting for the annual climatic variability is a well-known issue for\nsimulation-based studies of environmental models. It often requires intensive\nsampling (e.g., averaging the simulation outputs over many climatic series),\nwhich hinders many sequential processes, in particular optimization algorithms.\nWe propose here an approach based on a subset selection of a large basis of\nclimatic series, using an ad-hoc similarity function and clustering. A\nnon-parametric reconstruction technique is introduced to estimate accurately\nthe distribution of the output of interest using only the subset sampling. The\nproposed strategy is non-intrusive and generic (i.e. transposable to most\nmodels with climatic data inputs), and can be combined to most \"off-the-shelf\"\noptimization solvers. We apply our approach to sunflower phenotype optimization\nusing the crop model SUNFLO. The underlying optimization problem is formulated\nas multi-objective to account for risk-aversion. Our approach achieves good\nperformances even for limited computational budgets, outperforming\nsignificantly more \"naive\" strategies.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2015 09:30:42 GMT"}], "update_date": "2015-09-21", "authors_parsed": [["Picheny", "Victor", "", "INRA TOULOUSE, UBIA"], ["Tr\u00e9pos", "Ronan", "", "INRA TOULOUSE,\n  UBIA"], ["Poublan", "Bastien", "", "INRA TOULOUSE"], ["Casadebaig", "Pierre", "", "AGIR"]]}, {"id": "1509.05720", "submitter": "Martin Wendler", "authors": "Annika Betken, Martin Wendler", "title": "Subsampling for General Statistics under Long Range Dependence with\n  application to change point analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the statistical inference for long range dependent time series the shape\nof the limit distribution typically depends on unknown parameters. Therefore,\nwe propose to use subsampling. We show the validity of subsampling for general\nstatistics and long range dependent subordinated Gaussian processes which\nsatisfy mild regularity conditions. We apply our method to a self-normalized\nchange-point test statistic so that we can test for structural breaks in long\nrange dependent time series without having to estimate any nuisance parameter.\nThe finite sample properties are investigated in a simulation study. We analyze\nthree data sets and compare our results to the conclusions of other authors.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2015 17:29:03 GMT"}, {"version": "v2", "created": "Tue, 3 Nov 2015 12:03:54 GMT"}, {"version": "v3", "created": "Wed, 19 Oct 2016 14:52:40 GMT"}], "update_date": "2016-10-20", "authors_parsed": [["Betken", "Annika", ""], ["Wendler", "Martin", ""]]}, {"id": "1509.05790", "submitter": "Ery Arias-Castro", "authors": "Ery Arias-Castro and Bruno Pelletier", "title": "On the Consistency of the Crossmatch Test", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rosenbaum (2005) proposed the crossmatch test for two-sample goodness-of-fit\ntesting in arbitrary dimensions. We prove that the test is consistent against\nall fixed alternatives. In the process, we develop a general consistency result\nbased on (Henze & Penrose, 1999) that applies more generally.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2015 20:22:30 GMT"}], "update_date": "2015-09-22", "authors_parsed": [["Arias-Castro", "Ery", ""], ["Pelletier", "Bruno", ""]]}, {"id": "1509.05845", "submitter": "Roberto Imbuzeiro Oliveira", "authors": "Luc Devroye, Matthieu Lerasle, Gabor Lugosi, Roberto I. Oliveira", "title": "Sub-Gaussian mean estimators", "comments": "34 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss the possibilities and limitations of estimating the mean of a\nreal-valued random variable from independent and identically distributed\nobservations from a non-asymptotic point of view. In particular, we define\nestimators with a sub-Gaussian behavior even for certain heavy-tailed\ndistributions. We also prove various impossibility results for mean estimators.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2015 03:22:07 GMT"}], "update_date": "2015-09-22", "authors_parsed": [["Devroye", "Luc", ""], ["Lerasle", "Matthieu", ""], ["Lugosi", "Gabor", ""], ["Oliveira", "Roberto I.", ""]]}, {"id": "1509.05861", "submitter": "Fabio Rapallo", "authors": "Roberto Fontana, Fabio Rapallo and Maria-Piera Rogantin", "title": "Aberration in qualitative multilevel designs", "comments": "16 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generalized Word Length Pattern (GWLP) is an important and widely-used tool\nfor comparing fractional factorial designs. We consider qualitative factors,\nand we code their levels using the roots of the unity. We write the GWLP of a\nfraction ${\\mathcal F}$ using the polynomial indicator function, whose\ncoefficients encode many properties of the fraction. We show that the\ncoefficient of a simple or interaction term can be written using the counts of\nits levels. This apparently simple remark leads to major consequence, including\na convolution formula for the counts. We also show that the mean aberration of\na term over the permutation of its levels provides a connection with the\nvariance of the level counts. Moreover, using mean aberrations for symmetric\n$s^m$ designs with $s$ prime, we derive a new formula for computing the GWLP of\n${\\mathcal F}$. It is computationally easy, does not use complex numbers and\nalso provides a clear way to interpret the GWLP. As case studies, we consider\nnon-isomorphic orthogonal arrays that have the same GWLP. The different\ndistributions of the mean aberrations suggest that they could be used as a\nfurther tool to discriminate between fractions.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2015 08:58:22 GMT"}], "update_date": "2015-09-22", "authors_parsed": [["Fontana", "Roberto", ""], ["Rapallo", "Fabio", ""], ["Rogantin", "Maria-Piera", ""]]}, {"id": "1509.06064", "submitter": "Sergiy Maksymenko", "authors": "Sergiy Maksymenko, Oksana Marunkevych", "title": "Topological stability of continuous functions with respect to averagings", "comments": "11 pages", "journal-ref": "Ukrainian Mathematical Journal, vol. 68, no. 5 (2016) 625-633", "doi": null, "report-no": null, "categories": "math.GN math.GT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present sufficient conditions for topological stability of continuous\nfunctions $f:\\mathbb{R}\\to\\mathbb{R}$ having finitely many local extrema with\nrespect to averagings by discrete measures with finite supports.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2015 22:14:56 GMT"}], "update_date": "2017-10-19", "authors_parsed": [["Maksymenko", "Sergiy", ""], ["Marunkevych", "Oksana", ""]]}, {"id": "1509.06075", "submitter": "Claudia Solis-Lemus", "authors": "Claudia Sol\\'is-Lemus and C\\'ecile An\\'e", "title": "Inferring phylogenetic networks with maximum pseudolikelihood under\n  incomplete lineage sorting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE math.ST stat.AP stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Phylogenetic networks are necessary to represent the tree of life expanded by\nedges to represent events such as horizontal gene transfers, hybridizations or\ngene flow. Not all species follow the paradigm of vertical inheritance of their\ngenetic material. While a great deal of research has flourished into the\ninference of phylogenetic trees, statistical methods to infer phylogenetic\nnetworks are still limited and under development. The main disadvantage of\nexisting methods is a lack of scalability. Here, we present a statistical\nmethod to infer phylogenetic networks from multi-locus genetic data in a\npseudolikelihood framework. Our model accounts for incomplete lineage sorting\nthrough the coalescent model, and for horizontal inheritance of genes through\nreticulation nodes in the network. Computation of the pseudolikelihood is fast\nand simple, and it avoids the burdensome calculation of the full likelihood\nwhich can be intractable with many species. Moreover, estimation at the\nquartet-level has the added computational benefit that it is easily\nparallelizable. Simulation studies comparing our method to a full likelihood\napproach show that our pseudolikelihood approach is much faster without\ncompromising accuracy. We applied our method to reconstruct the evolutionary\nrelationships among swordtails and platyfishes ($Xiphophorus$: Poeciliidae),\nwhich is characterized by widespread hybridizations.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2015 23:41:03 GMT"}, {"version": "v2", "created": "Fri, 8 Jan 2016 20:48:47 GMT"}, {"version": "v3", "created": "Fri, 12 Feb 2016 19:23:35 GMT"}], "update_date": "2016-02-15", "authors_parsed": [["Sol\u00eds-Lemus", "Claudia", ""], ["An\u00e9", "C\u00e9cile", ""]]}, {"id": "1509.06121", "submitter": "Florian Heinrichs", "authors": "Taras Bodnar, Holger Dette, Nestor Parolya", "title": "Spectral analysis of the Moore-Penrose inverse of a large dimensional\n  sample covariance matrix", "comments": "AMS 2010 subject classifications: 60B20, 60F05, 60F15, 60F17, 62H10\n  Keywords: CLT, large-dimensional asymptotics, Moore-Penrose inverse, random\n  matrix theory", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For a sample of $n$ independent identically distributed $p$-dimensional\ncentered random vectors with covariance matrix $\\mathbf{\\Sigma}_n$ let\n$\\tilde{\\mathbf{S}}_n$ denote the usual sample covariance (centered by the\nmean) and $\\mathbf{S}_n$ the non-centered sample covariance matrix (i.e. the\nmatrix of second moment estimates), where $p> n$. In this paper, we provide the\nlimiting spectral distribution and central limit theorem for linear spectral\nstatistics of the Moore-Penrose inverse of $\\mathbf{S}_n$ and\n$\\tilde{\\mathbf{S}}_n$. We consider the large dimensional asymptotics when the\nnumber of variables $p\\rightarrow\\infty$ and the sample size\n$n\\rightarrow\\infty$ such that $p/n\\rightarrow c\\in (1, +\\infty)$. We present a\nMarchenko-Pastur law for both types of matrices, which shows that the limiting\nspectral distributions for both sample covariance matrices are the same. On the\nother hand, we demonstrate that the asymptotic distribution of linear spectral\nstatistics of the Moore-Penrose inverse of $\\tilde{\\mathbf{S}}_n$ differs in\nthe mean from that of $\\mathbf{S}_n$.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2015 06:52:40 GMT"}], "update_date": "2015-09-22", "authors_parsed": [["Bodnar", "Taras", ""], ["Dette", "Holger", ""], ["Parolya", "Nestor", ""]]}, {"id": "1509.06296", "submitter": "Hayoung Choi", "authors": "Hayoung Choi and Farhad Jafari", "title": "Positive definite Hankel matrix completions and Hamburger moment\n  completions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.FA math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we give solutions to Hamburger moment problems with missing\nentries. The problem of completing partial positive sequences is considered.\nThe main result is a characterization of positive definite completable\npatterns, namely patterns that guarantee the existence of Hamburger moment\ncompletion of a partial positive definite sequence. Moreover, several patterns\nwhich are not positive definite completable are given.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2015 16:41:52 GMT"}], "update_date": "2015-09-22", "authors_parsed": [["Choi", "Hayoung", ""], ["Jafari", "Farhad", ""]]}, {"id": "1509.06310", "submitter": "Aixin Tan", "authors": "Vivekananda Roy, Aixin Tan, and James M. Flegal", "title": "Estimating standard errors for importance sampling estimators with\n  multiple Markov chains", "comments": "49 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.CO stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The naive importance sampling estimator, based on samples from a single\nimportance density, can be numerically unstable. Instead, we consider\ngeneralized importance sampling estimators where samples from more than one\nprobability distribution are combined. We study this problem in the Markov\nchain Monte Carlo context, where independent samples are replaced with Markov\nchain samples. If the chains converge to their respective target distributions\nat a polynomial rate, then under two finite moment conditions, we show a\ncentral limit theorem holds for the generalized estimators. Further, we develop\nan easy to implement method to calculate valid asymptotic standard errors based\non batch means. We also provide a batch means estimator for calculating\nasymptotically valid standard errors of Geyer(1994) reverse logistic estimator.\nWe illustrate the method using a Bayesian variable selection procedure in\nlinear regression. In particular, the generalized importance sampling estimator\nis used to perform empirical Bayes variable selection and the batch means\nestimator is used to obtain standard errors in a high-dimensional setting where\ncurrent methods are not applicable.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2015 17:18:34 GMT"}, {"version": "v2", "created": "Thu, 11 Aug 2016 15:10:30 GMT"}], "update_date": "2016-08-12", "authors_parsed": [["Roy", "Vivekananda", ""], ["Tan", "Aixin", ""], ["Flegal", "James M.", ""]]}, {"id": "1509.06311", "submitter": "Andres Santos", "authors": "Victor Chernozhukov, Whitney K. Newey and Andres Santos", "title": "Constrained Conditional Moment Restriction Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper examines a general class of inferential problems in semiparametric\nand nonparametric models defined by conditional moment restrictions. We\nconstruct tests for the hypothesis that at least one element of the identified\nset satisfies a conjectured (Banach space) \"equality\" and/or (a Banach lattice)\n\"inequality\" constraint. Our procedure is applicable to identified and\npartially identified models, and is shown to control the level, and under some\nconditions the size, asymptotically uniformly in an appropriate class of\ndistributions. The critical values are obtained by building a strong\napproximation to the statistic and then bootstrapping a (conservatively)\nrelaxed form of the statistic. Sufficient conditions are provided, including\nstrong approximations using Koltchinskii's coupling.\n  Leading important special cases encompassed by the framework we study\ninclude: (i) Tests of shape restrictions for infinite dimensional parameters;\n(ii) Confidence regions for functionals that impose shape restrictions on the\nunderlying parameter; (iii) Inference for functionals in semiparametric and\nnonparametric models defined by conditional moment (in)equalities; and (iv)\nUniform inference in possibly nonlinear and severely ill-posed problems.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2015 17:18:40 GMT"}], "update_date": "2015-09-22", "authors_parsed": [["Chernozhukov", "Victor", ""], ["Newey", "Whitney K.", ""], ["Santos", "Andres", ""]]}, {"id": "1509.06403", "submitter": "Amadou Diadie Ba", "authors": "Gane Samb Lo, Diadie Ba, Elhadji Deme and Cheikh Seck", "title": "Consistency bands for the mean excess function and application to\n  graphical goodness of fit test for financial data", "comments": "34 pages, 23 figures, Conference: Galaye Dia- Scientific days\n  28-29-30 july 2015 , Gaston Berger University. Saint louis", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we use the modern setting of functional empirical processes\nand recent techniques on uniform estimation for non parametric objects to\nderive consistency bands for the mean excess function in the i.i.d. case. We\napply our results for modelling financial data, in particular Dow Jones data\nbasis to see how good the Generalized hyperbolic distribution models fit\nmonthly data.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2015 21:09:13 GMT"}, {"version": "v2", "created": "Tue, 13 Oct 2015 18:08:50 GMT"}], "update_date": "2015-10-14", "authors_parsed": [["Lo", "Gane Samb", ""], ["Ba", "Diadie", ""], ["Deme", "Elhadji", ""], ["Seck", "Cheikh", ""]]}, {"id": "1509.06418", "submitter": "Varun  Jog", "authors": "Varun Jog and Po-Ling Loh", "title": "Information-theoretic bounds for exact recovery in weighted stochastic\n  block models using the Renyi divergence", "comments": "32 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.SI math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive sharp thresholds for exact recovery of communities in a weighted\nstochastic block model, where observations are collected in the form of a\nweighted adjacency matrix, and the weight of each edge is generated\nindependently from a distribution determined by the community membership of its\nendpoints. Our main result, characterizing the precise boundary between success\nand failure of maximum likelihood estimation when edge weights are drawn from\ndiscrete distributions, involves the Renyi divergence of order $\\frac{1}{2}$\nbetween the distributions of within-community and between-community edges. When\nthe Renyi divergence is above a certain threshold, meaning the edge\ndistributions are sufficiently separated, maximum likelihood succeeds with\nprobability tending to 1; when the Renyi divergence is below the threshold,\nmaximum likelihood fails with probability bounded away from 0. In the language\nof graphical channels, the Renyi divergence pinpoints the information-theoretic\ncapacity of discrete graphical channels with binary inputs. Our results\ngeneralize previously established thresholds derived specifically for\nunweighted block models, and support an important natural intuition relating\nthe intrinsic hardness of community estimation to the problem of edge\nclassification. Along the way, we establish a general relationship between the\nRenyi divergence and the probability of success of the maximum likelihood\nestimator for arbitrary edge weight distributions. Finally, we discuss\nconsequences of our bounds for the related problems of censored block models\nand submatrix localization, which may be seen as special cases of the framework\ndeveloped in our paper.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2015 22:26:14 GMT"}], "update_date": "2015-09-23", "authors_parsed": [["Jog", "Varun", ""], ["Loh", "Po-Ling", ""]]}, {"id": "1509.06422", "submitter": "Ieva Grublyt\\.e", "authors": "Ieva Grublyt\\.e, Donatas Surgailis, Andrius \\v{S}karnulis", "title": "Quasi-MLE for quadratic ARCH model with long memory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss parametric quasi-maximum likelihood estimation for quadratic ARCH\nprocess with long memory introduced in Doukhan et al. (2015) and Grublyt\\.e and\n\\v{S}karnulis (2015) with conditional variance given by a strictly positive\nquadratic form of observable stationary sequence. We prove consistency and\nasymptotic normality of the corresponding QMLE estimates, including the\nestimate of long memory parameter $0< d < 1/2$. A simulation study of empirical\nMSE is included.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2015 22:44:32 GMT"}], "update_date": "2015-09-23", "authors_parsed": [["Grublyt\u0117", "Ieva", ""], ["Surgailis", "Donatas", ""], ["\u0160karnulis", "Andrius", ""]]}, {"id": "1509.06428", "submitter": "Subhadeep Mukhopadhyay", "authors": "Subhadeep Mukhopadhyay", "title": "Large-Scale Mode Identification and Data-Driven Sciences", "comments": "I would like to express my sincere thanks to the Editor and the\n  anonymous reviewers for their in-depth comments, which have greatly improved\n  the manuscript", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bump-hunting or mode identification is a fundamental problem that arises in\nalmost every scientific field of data-driven discovery. Surprisingly, very few\ndata modeling tools are available for automatic (not requiring manual\ncase-by-base investigation), objective (not subjective), and nonparametric (not\nbased on restrictive parametric model assumptions) mode discovery, which can\nscale to large data sets. This article introduces LPMode--an algorithm based on\na new theory for detecting multimodality of a probability density. We apply\nLPMode to answer important research questions arising in various fields from\nenvironmental science, ecology, econometrics, analytical chemistry to astronomy\nand cancer genomics.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2015 23:44:36 GMT"}, {"version": "v2", "created": "Sun, 27 Sep 2015 12:57:25 GMT"}, {"version": "v3", "created": "Thu, 12 Nov 2015 23:51:32 GMT"}, {"version": "v4", "created": "Tue, 8 Nov 2016 22:19:37 GMT"}], "update_date": "2016-11-10", "authors_parsed": [["Mukhopadhyay", "Subhadeep", ""]]}, {"id": "1509.06442", "submitter": "Yu-Pin Hu", "authors": "Yu-Pin Hu and J. T. Gene Hwang", "title": "A new approach for analyzing panel AR(1) series with application to the\n  unit root test", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper derives several novel tests to improve on the t-test for testing\nAR(1) coefficients of panel time series, i.e., of multiple time series, when\neach has a small number of observations. These tests can determine the\nacceptance or the rejection of each hypothesis individually while controlling\nthe average type one error. Strikingly, the testing statistics derived by the\nempirical Bayes approach can be approximated by a simple form similar to the\nt-statistic; the only difference is that the means and the variances are\nestimated by shrinkage estimators. Simulations demonstrate that the proposed\ntests have higher average power than the t-test in all settings we examine\nincluding those when the priors are miss-specified and the cross section series\nare dependent.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2015 01:45:50 GMT"}], "update_date": "2015-09-23", "authors_parsed": [["Hu", "Yu-Pin", ""], ["Hwang", "J. T. Gene", ""]]}, {"id": "1509.06673", "submitter": "S\\\"oren Christensen", "authors": "S\\\"oren Christensen, Albrecht Irle, and Lars Willert", "title": "Classification error in multiclass discrimination from Markov data", "comments": null, "journal-ref": null, "doi": "10.1007/s11203-015-9129-6", "report-no": null, "categories": "stat.ML math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a model for an on-line classification setting we consider a stochastic\nprocess $(X_{-n},Y_{-n})_{n}$, the present time-point being denoted by 0, with\nobservables $ \\ldots,X_{-n},X_{-n+1},\\ldots, X_{-1}, X_0$ from which the\npattern $Y_0$ is to be inferred. So in this classification setting, in addition\nto the present observation $X_0$ a number $l$ of preceding observations may be\nused for classification, thus taking a possible dependence structure into\naccount as it occurs e.g. in an ongoing classification of handwritten\ncharacters. We treat the question how the performance of classifiers is\nimproved by using such additional information. For our analysis, a hidden\nMarkov model is used. Letting $R_l$ denote the minimal risk of\nmisclassification using $l$ preceding observations we show that the difference\n$\\sup_k |R_l - R_{l+k}|$ decreases exponentially fast as $l$ increases. This\nsuggests that a small $l$ might already lead to a noticeable improvement. To\nfollow this point we look at the use of past observations for kernel\nclassification rules. Our practical findings in simulated hidden Markov models\nand in the classification of handwritten characters indicate that using $l=1$,\ni.e. just the last preceding observation in addition to $X_0$, can lead to a\nsubstantial reduction of the risk of misclassification. So, in the presence of\nstochastic dependencies, we advocate to use $ X_{-1},X_0$ for finding the\npattern $Y_0$ instead of only $X_0$ as one would in the independent situation.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2015 16:32:30 GMT"}], "update_date": "2017-07-07", "authors_parsed": [["Christensen", "S\u00f6ren", ""], ["Irle", "Albrecht", ""], ["Willert", "Lars", ""]]}, {"id": "1509.07040", "submitter": "Yuheng Bu", "authors": "Yuheng Bu, Shaofeng Zou, Yingbin Liang and Venugopal V. Veeravalli", "title": "Universal Outlying sequence detection For Continuous Observations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The following detection problem is studied, in which there are $M$ sequences\nof samples out of which one outlier sequence needs to be detected. Each typical\nsequence contains $n$ independent and identically distributed (i.i.d.)\ncontinuous observations from a known distribution $\\pi$, and the outlier\nsequence contains $n$ i.i.d. observations from an outlier distribution $\\mu$,\nwhich is distinct from $\\pi$, but otherwise unknown. A universal test based on\nKL divergence is built to approximate the maximum likelihood test, with known\n$\\pi$ and unknown $\\mu$. A data-dependent partitions based KL divergence\nestimator is employed. Such a KL divergence estimator is further shown to\nconverge to its true value exponentially fast when the density ratio satisfies\n$0<K_1\\leq \\frac{d\\mu}{d\\pi}\\leq K_2$, where $K_1$ and $K_2$ are positive\nconstants, and this further implies that the test is exponentially consistent.\nThe performance of the test is compared with that of a recently introduced test\nfor this problem based on the machine learning approach of maximum mean\ndiscrepancy (MMD). We identify regimes in which the KL divergence based test is\nbetter than the MMD based test.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2015 15:56:59 GMT"}, {"version": "v2", "created": "Wed, 7 Oct 2015 19:02:48 GMT"}], "update_date": "2015-10-08", "authors_parsed": [["Bu", "Yuheng", ""], ["Zou", "Shaofeng", ""], ["Liang", "Yingbin", ""], ["Veeravalli", "Venugopal V.", ""]]}, {"id": "1509.07229", "submitter": "Xin Lu Tan", "authors": "Po-Ling Loh and Xin Lu Tan", "title": "High-dimensional robust precision matrix estimation: Cellwise corruption\n  under $\\epsilon$-contamination", "comments": "52 pages including appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the statistical consistency of robust estimators for precision\nmatrices in high dimensions. We focus on a contamination mechanism acting\ncellwise on the data matrix. The estimators we analyze are formed by plugging\nappropriately chosen robust covariance matrix estimators into the graphical\nLasso and CLIME. Such estimators were recently proposed in the robust\nstatistics literature, but only analyzed mathematically from the point of view\nof the breakdown point. This paper provides complementary high-dimensional\nerror bounds for the precision matrix estimators that reveal the interplay\nbetween the dimensionality of the problem and the degree of contamination\npermitted in the observed distribution. We also show that although the\ngraphical Lasso and CLIME estimators perform equally well from the point of\nview of statistical consistency, the breakdown property of the graphical Lasso\nis superior to that of CLIME. We discuss implications of our work for problems\ninvolving graphical model estimation when the uncontaminated data follow a\nmultivariate normal distribution, and the goal is to estimate the support of\nthe population-level precision matrix. Our error bounds do not make any\nassumptions about the the contaminating distribution and allow for a\nnonvanishing fraction of cellwise contamination.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2015 03:49:47 GMT"}], "update_date": "2015-09-25", "authors_parsed": [["Loh", "Po-Ling", ""], ["Tan", "Xin Lu", ""]]}, {"id": "1509.07269", "submitter": "Alexei Onatski", "authors": "Iain M. Johnstone and Alexei Onatski", "title": "Testing in high-dimensional spiked models", "comments": "Includes Supplementary Material (see the second half of the file)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the five classes of multivariate statistical problems identified\nby James (1964), which together cover much of classical multivariate analysis,\nplus a simpler limiting case, symmetric matrix denoising. Each of James'\nproblems involves the eigenvalues of $E^{-1}H$ where $H$ and $E$ are\nproportional to high dimensional Wishart matrices. Under the null hypothesis,\nboth Wisharts are central with identity covariance. Under the alternative, the\nnon-centrality or the covariance parameter of $H$ has a single eigenvalue, a\nspike, that stands alone. When the spike is smaller than a case-specific phase\ntransition threshold, none of the sample eigenvalues separate from the bulk,\nmaking the testing problem challenging. Using a unified strategy for the six\ncases, we show that the log likelihood ratio processes parameterized by the\nvalue of the sub-critical spike converge to Gaussian processes with logarithmic\ncorrelation. We then derive asymptotic power envelopes for tests for the\npresence of a spike.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2015 08:20:38 GMT"}, {"version": "v2", "created": "Sat, 3 Feb 2018 14:53:09 GMT"}], "update_date": "2018-02-06", "authors_parsed": [["Johnstone", "Iain M.", ""], ["Onatski", "Alexei", ""]]}, {"id": "1509.07409", "submitter": "Leonid Torgovitski", "authors": "Leonid Torgovitski", "title": "Detecting changes in Hilbert space data based on \"repeated\" and\n  change-aligned principal components", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a CUSUM (cumulative sums) procedure for the detection of changes in\nthe means of weakly dependent time series within an abstract Hilbert space\nframework. We use an empirical projection approach via a principal component\nrepresentation of the data, i.e., we work with the eigenelements of the (long\nrun) covariance operator. This article contributes to the existing theory in\ntwo directions: By means of a recent result of Reimherr (2015) we show, on one\nhand, that the commonly assumed \"separation of the leading eigenvalues\" for\nCUSUM procedures can be avoided. This assumption is not a consequence of the\nmethodology but merely a consequence of the usual proof techniques. On the\nother hand, we propose to consider change-aligned principal components that\nallow to further reduce common assumptions on the eigenstructure under the\nalternative. This approach extends directly to multidirectional changes, i.e.\nchanges that occur at different time points and in different directions, by\nfusing sufficient information on them into the first component. The latter\nfindings are illustrated by a few simulations and compared with existing\nprocedures in a functional data framework.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2015 15:41:34 GMT"}, {"version": "v2", "created": "Wed, 7 Oct 2015 16:56:54 GMT"}], "update_date": "2015-10-08", "authors_parsed": [["Torgovitski", "Leonid", ""]]}, {"id": "1509.07566", "submitter": "Jonathan Ligo", "authors": "Jonathan G. Ligo and George V. Moustakides and Venugopal V. Veeravalli", "title": "Detecting Sparse Mixtures: Rate of Decay of Error Probability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the rate of decay of the probability of error for distinguishing\nbetween a sparse signal with noise, modeled as a sparse mixture, from pure\nnoise. This problem has many applications in signal processing, evolutionary\nbiology, bioinformatics, astrophysics and feature selection for machine\nlearning. We let the mixture probability tend to zero as the number of\nobservations tends to infinity and derive oracle rates at which the error\nprobability can be driven to zero for a general class of signal and noise\ndistributions via the likelihood ratio test. In contrast to the problem of\ndetection of non-sparse signals, we see the log-probability of error decays\nsublinearly rather than linearly and is characterized through the\n$\\chi^2$-divergence rather than the Kullback-Leibler divergence for \"weak\"\nsignals and can be independent of divergence for \"strong\" signals. Our\ncontribution is the first characterization of the rate of decay of the error\nprobability for this problem for both the false alarm and miss probabilities.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2015 23:20:51 GMT"}, {"version": "v2", "created": "Sat, 24 Dec 2016 18:48:25 GMT"}], "update_date": "2016-12-28", "authors_parsed": [["Ligo", "Jonathan G.", ""], ["Moustakides", "George V.", ""], ["Veeravalli", "Venugopal V.", ""]]}, {"id": "1509.07601", "submitter": "Matteo Ruggiero", "authors": "Pierpaolo De Blasi, Matteo Ruggiero and Stephen G. Walker", "title": "Birth-and-death Polya urns and stationary random partitions", "comments": "Substantially revised", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a class of birth-and-death Polya urns, which allow for both\nsampling and removal of observations governed by an auxiliary inhomogeneous\nBernoulli process, and investigate the asymptotic behaviour of the induced\nallelic partitions. By exploiting some embedded models, we show that the\nasymptotic regimes exhibit a phase transition from partitions with almost\nsurely infinitely many blocks and independent counts, to stationary partitions\nwith a random number of blocks. The first regime corresponds to limits of\nEwens-type partitions and includes a result of Arratia, Barbour and Tavar\\'e\n(1992) as a special case. We identify the invariant and reversible measure in\nthe second regime, which preserves asymptotically the dependence between\ncounts, and is shown to be a mixture of Ewens sampling formulas, with a tilted\nNegative Binomial mixing distribution on the sample size.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2015 07:13:26 GMT"}, {"version": "v2", "created": "Tue, 22 Nov 2016 11:44:13 GMT"}], "update_date": "2016-11-23", "authors_parsed": [["De Blasi", "Pierpaolo", ""], ["Ruggiero", "Matteo", ""], ["Walker", "Stephen G.", ""]]}, {"id": "1509.07636", "submitter": "Irene Winkler", "authors": "Irene Winkler and Danny Panknin and Daniel Bartz and Klaus-Robert\n  M\\\"uller and Stefan Haufe", "title": "Validity of time reversal for testing Granger causality", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2016.2531628", "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inferring causal interactions from observed data is a challenging problem,\nespecially in the presence of measurement noise. To alleviate the problem of\nspurious causality, Haufe et al. (2013) proposed to contrast measures of\ninformation flow obtained on the original data against the same measures\nobtained on time-reversed data. They show that this procedure, time-reversed\nGranger causality (TRGC), robustly rejects causal interpretations on mixtures\nof independent signals. While promising results have been achieved in\nsimulations, it was so far unknown whether time reversal leads to valid\nmeasures of information flow in the presence of true interaction. Here we prove\nthat, for linear finite-order autoregressive processes with unidirectional\ninformation flow, the application of time reversal for testing Granger\ncausality indeed leads to correct estimates of information flow and its\ndirectionality. Using simulations, we further show that TRGC is able to infer\ncorrect directionality with similar statistical power as the net Granger\ncausality between two variables, while being much more robust to the presence\nof measurement noise.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2015 08:58:24 GMT"}, {"version": "v2", "created": "Thu, 11 Feb 2016 19:55:53 GMT"}], "update_date": "2016-05-04", "authors_parsed": [["Winkler", "Irene", ""], ["Panknin", "Danny", ""], ["Bartz", "Daniel", ""], ["M\u00fcller", "Klaus-Robert", ""], ["Haufe", "Stefan", ""]]}, {"id": "1509.07747", "submitter": "Vytaut\u00c4\u0097 Pilipauskait\u00c4\u0097", "authors": "Remigijus Leipus, Anne Philippe, Vytaut\\.e Pilipauskait\\.e, Donatas\n  Surgailis", "title": "Nonparametric estimation of the distribution of the autoregressive\n  coefficient from panel random-coefficient AR(1) data", "comments": null, "journal-ref": "Journal of Multivariate Analysis 153 (2017) 121-135", "doi": "10.1016/j.jmva.2016.09.007", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss nonparametric estimation of the distribution function $G(x)$ of\nthe autoregressive coefficient $a \\in (-1,1)$ from a panel of $N$\nrandom-coefficient AR(1) data, each of length $n$, by the empirical\ndistribution function of lag 1 sample autocorrelations of individual AR(1)\nprocesses. Consistency and asymptotic normality of the empirical distribution\nfunction and a class of kernel density estimators is established under some\nregularity conditions on $G(x)$ as $N$ and $n$ increase to infinity. The\nKolmogorov-Smirnov goodness-of-fit test for simple and composite hypotheses of\nBeta distributed $a$ is discussed. A simulation study for goodness-of-fit\ntesting compares the finite-sample performance of our nonparametric estimator\nto the performance of its parametric analogue discussed in Beran et al. (2010).\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2015 15:10:21 GMT"}, {"version": "v2", "created": "Wed, 5 Oct 2016 19:18:47 GMT"}], "update_date": "2016-10-06", "authors_parsed": [["Leipus", "Remigijus", ""], ["Philippe", "Anne", ""], ["Pilipauskait\u0117", "Vytaut\u0117", ""], ["Surgailis", "Donatas", ""]]}, {"id": "1509.07776", "submitter": "Daniil Ryabko", "authors": "Daniil Ryabko, Boris Ryabko", "title": "Predicting the outcomes of every process for which an asymptotically\n  accurate stationary predictor exists is impossible", "comments": "appears in the proceedings of ISIT 2015, pp. 1204-1206, Hong Kong", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of prediction consists in forecasting the conditional\ndistribution of the next outcome given the past. Assume that the source\ngenerating the data is such that there is a stationary ergodic predictor whose\nerror converges to zero (in a certain sense). The question is whether there is\na universal predictor for all such sources, that is, a predictor whose error\ngoes to zero if any of the sources that have this property is chosen to\ngenerate the data. This question is answered in the negative, contrasting a\nnumber of previously established positive results concerning related but\nsmaller sets of processes.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2015 16:23:26 GMT"}], "update_date": "2015-09-28", "authors_parsed": [["Ryabko", "Daniil", ""], ["Ryabko", "Boris", ""]]}, {"id": "1509.07983", "submitter": "Soledad Villar", "authors": "Takayuki Iguchi, Dustin G. Mixon, Jesse Peterson, Soledad Villar", "title": "Probably certifiably correct k-means clustering", "comments": "Major revision from previous version. This paper is a extension of\n  and improvement to the authors' preprint [arXiv:1505.04778]", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DS cs.LG math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, Bandeira [arXiv:1509.00824] introduced a new type of algorithm (the\nso-called probably certifiably correct algorithm) that combines fast solvers\nwith the optimality certificates provided by convex relaxations. In this paper,\nwe devise such an algorithm for the problem of k-means clustering. First, we\nprove that Peng and Wei's semidefinite relaxation of k-means is tight with high\nprobability under a distribution of planted clusters called the stochastic ball\nmodel. Our proof follows from a new dual certificate for integral solutions of\nthis semidefinite program. Next, we show how to test the optimality of a\nproposed k-means solution using this dual certificate in quasilinear time.\nFinally, we analyze a version of spectral clustering from Peng and Wei that is\ndesigned to solve k-means in the case of two clusters. In particular, we show\nthat this quasilinear-time method typically recovers planted clusters under the\nstochastic ball model.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2015 14:09:56 GMT"}, {"version": "v2", "created": "Sat, 23 Apr 2016 19:55:12 GMT"}], "update_date": "2016-04-26", "authors_parsed": [["Iguchi", "Takayuki", ""], ["Mixon", "Dustin G.", ""], ["Peterson", "Jesse", ""], ["Villar", "Soledad", ""]]}, {"id": "1509.08083", "submitter": "Jan Vyb\\'iral", "authors": "Anton Kolleck, Jan Vyb\\'iral", "title": "Non-asymptotic Analysis of $\\ell_1$-norm Support Vector Machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.FA math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Support Vector Machines (SVM) with $\\ell_1$ penalty became a standard tool in\nanalysis of highdimensional classification problems with sparsity constraints\nin many applications including bioinformatics and signal processing. Although\nSVM have been studied intensively in the literature, this paper has to our\nknowledge first non-asymptotic results on the performance of $\\ell_1$-SVM in\nidentification of sparse classifiers. We show that a $d$-dimensional $s$-sparse\nclassification vector can be (with high probability) well approximated from\nonly $O(s\\log(d))$ Gaussian trials. The methods used in the proof include\nconcentration of measure and probability in Banach spaces.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2015 11:07:03 GMT"}], "update_date": "2015-09-29", "authors_parsed": [["Kolleck", "Anton", ""], ["Vyb\u00edral", "Jan", ""]]}, {"id": "1509.08100", "submitter": "Xueying Tang", "authors": "Xueying Tang, Ke Li and Malay Ghosh", "title": "Bayesian Multiple Testing Under Sparsity for Polynomial-Tailed\n  Distributions", "comments": "27 pages, 4 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers Bayesian multiple testing under sparsity for\npolynomial-tailed distributions satisfying a monotone likelihood ratio\nproperty. Included in this class of distributions are the Student's t, the\nPareto, and many other distributions. We prove some general asymptotic\noptimality results under fixed and random thresholding. As examples of these\ngeneral results, we establish the Bayesian asymptotic optimality of several\nmultiple testing procedures in the literature for appropriately chosen false\ndiscovery rate levels. We also show by simulation that the Benjamini-Hochberg\nprocedure with a false discovery rate level different from the asymptotically\noptimal one can lead to high Bayes risk.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2015 15:21:53 GMT"}, {"version": "v2", "created": "Thu, 28 Jul 2016 18:01:50 GMT"}], "update_date": "2016-07-29", "authors_parsed": [["Tang", "Xueying", ""], ["Li", "Ke", ""], ["Ghosh", "Malay", ""]]}, {"id": "1509.08108", "submitter": "Subrata Chakraborty", "authors": "Laba Handique and Subrata Chakraborty", "title": "The Marshall-Olkin-Kumarswamy-G family of distributions", "comments": "40 pages, 6 Figures, 2 Tables, version-II, preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new family of continuous distribution is proposed by using Kumaraswamy-G\n(Cordeiro and de Castro, 2011) distribution as the base line distribution in\nthe Marshal-Olkin (Marshall and Olkin, 1997) construction. A number of known\ndistributions are derived as particular cases. Various properties of the\nproposed family like formulation of the pdf as different mixture of\nexponentiated baseline distributions, order statistics, moments, moment\ngenerating function, Renyi entropy, quantile function and random sample\ngeneration have been investigated. Asymptotes, shapes and stochastic ordering\nare also investigated. The parameter estimation by methods of maximum\nlikelihood, their large sample standard errors and confidence intervals and\nmethod of moment are also presented. Two members of the proposed family are\ncompared with corresponding members of Kumaraswamy-Marshal-Olkin-G family\n(Alizadeh et al., 2015) by fitting of two real life data sets.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2015 17:06:17 GMT"}, {"version": "v2", "created": "Sun, 21 Aug 2016 19:01:30 GMT"}], "update_date": "2016-08-23", "authors_parsed": [["Handique", "Laba", ""], ["Chakraborty", "Subrata", ""]]}, {"id": "1509.08185", "submitter": "Harry Crane", "authors": "Harry Crane and Walter Dempsey", "title": "A framework for statistical network modeling", "comments": "31 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Basic principles of statistical inference are commonly violated in network\ndata analysis. Under the current approach, it is often impossible to identify a\nmodel that accommodates known empirical behaviors, possesses crucial\ninferential properties, and accurately models the data generating process. In\nthe absence of one or more of these properties, sensible inference from network\ndata cannot be assured.\n  Our proposed framework decomposes every network model into a (relatively)\nexchangeable data generating process} and a sampling mechanism that relates\nobserved data to the population network. This framework, which encompasses all\nmodels in current use as well as many new models, such as edge exchangeable and\nrelationally exchangeable models, that lie outside the existing paradigm,\noffers a sound context within which to develop theory and methods for network\nanalysis.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2015 03:45:08 GMT"}, {"version": "v2", "created": "Sat, 27 Feb 2016 02:18:44 GMT"}, {"version": "v3", "created": "Mon, 14 Mar 2016 06:44:12 GMT"}, {"version": "v4", "created": "Fri, 30 Dec 2016 12:28:47 GMT"}], "update_date": "2017-01-02", "authors_parsed": [["Crane", "Harry", ""], ["Dempsey", "Walter", ""]]}, {"id": "1509.08362", "submitter": "Fredrik Lindsten", "authors": "Sumeetpal S. Singh, Fredrik Lindsten, Eric Moulines", "title": "Blocking Strategies and Stability of Particle Gibbs Samplers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sampling from the conditional (or posterior) probability distribution of the\nlatent states of a Hidden Markov Model, given the realization of the observed\nprocess, is a non-trivial problem in the context of Markov Chain Monte Carlo.\nTo do this Andrieu et al. (2010) constructed a Markov kernel which leaves this\nconditional distribution invariant using a Particle Filter. From a\npractitioner's point of view, this Markov kernel attempts to mimic the act of\nsampling all the latent state variables as one block from the posterior\ndistribution but for models where exact simulation is not possible. There are\nsome recent theoretical results that establish the uniform ergodicity of this\nMarkov kernel and that the mixing rate does not diminish provided the number of\nparticles grows at least linearly with the number of latent states in the\nposterior. This gives rise to a cost, per application of the kernel, that is\nquadratic in the number of latent states which could be prohibitive for long\nobservation sequences. We seek to answer an obvious but important question: is\nthere a different implementation with a cost per-iteration that grows linearly\nwith the number of latent states, but which is still stable in the sense that\nits mixing rate does not deteriorate? We address this problem using blocking\nstrategies, which are easily parallelizable, and prove stability of the\nresulting sampler.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2015 15:36:10 GMT"}], "update_date": "2015-09-29", "authors_parsed": [["Singh", "Sumeetpal S.", ""], ["Lindsten", "Fredrik", ""], ["Moulines", "Eric", ""]]}, {"id": "1509.08451", "submitter": "Cheng Qian", "authors": "Cheng Qian, Nicholas D. Sidiropoulos, Kejun Huang, Lei Huang and H. C.\n  So", "title": "Phase Retrieval Using Feasible Point Pursuit: Algorithms and\n  Cram\\'er-Rao Bound", "comments": "13 pages, 13 figures", "journal-ref": null, "doi": "10.1109/TSP.2016.2593688", "report-no": null, "categories": "cs.IT math.IT math.NA math.OC math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reconstructing a signal from squared linear (rank-one quadratic) measurements\nis a challenging problem with important applications in optics and imaging,\nwhere it is known as phase retrieval. This paper proposes two new phase\nretrieval algorithms based on non-convex quadratically constrained quadratic\nprogramming (QCQP) formulations, and a recently proposed approximation\ntechnique dubbed feasible point pursuit (FPP). The first is designed for\nuniformly distributed bounded measurement errors, such as those arising from\nhigh-rate quantization (B-FPP). The second is designed for Gaussian measurement\nerrors, using a least squares criterion (LS-FPP). Their performance is measured\nagainst state-of-the-art algorithms and the Cram\\'er-Rao bound (CRB), which is\nalso derived here. Simulations show that LS-FPP outperforms the state-of-art\nand operates close to the CRB. Compact CRB expressions, properties, and\ninsights are obtained by explicitly computing the CRB in various special cases\n-- including when the signal of interest admits a sparse parametrization, using\nharmonic retrieval as an example.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2015 16:21:10 GMT"}, {"version": "v2", "created": "Mon, 28 Mar 2016 18:35:58 GMT"}], "update_date": "2016-09-21", "authors_parsed": [["Qian", "Cheng", ""], ["Sidiropoulos", "Nicholas D.", ""], ["Huang", "Kejun", ""], ["Huang", "Lei", ""], ["So", "H. C.", ""]]}, {"id": "1509.08490", "submitter": "Xiaohan Wei", "authors": "Xiaohan Wei, Qing Ling, and Zhu Han", "title": "Recoverability of Group Sparse Signals from Corrupted Measurements via\n  Robust Group Lasso", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the problem of recovering a group sparse signal matrix\n$\\mathbf{Y} = [\\mathbf{y}_1, \\cdots, \\mathbf{y}_L]$ from sparsely corrupted\nmeasurements $\\mathbf{M} = [\\mathbf{A}_{(1)}\\mathbf{y}_{1}, \\cdots,\n\\mathbf{A}_{(L)}\\mathbf{y}_{L}] + \\mathbf{S}$, where $\\mathbf{A}_{(i)}$'s are\nknown sensing matrices and $\\mathbf{S}$ is an unknown sparse error matrix. A\nrobust group lasso (RGL) model is proposed to recover $\\mathbf{Y}$ and\n$\\mathbf{S}$ through simultaneously minimizing the $\\ell_{2,1}$-norm of\n$\\mathbf{Y}$ and the $\\ell_1$-norm of $\\mathbf{S}$ under the measurement\nconstraints. We prove that $\\mathbf{Y}$ and $\\mathbf{S}$ can be exactly\nrecovered from the RGL model with a high probability for a very general class\nof $\\mathbf{A}_{(i)}$'s.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2015 20:27:23 GMT"}], "update_date": "2016-06-14", "authors_parsed": [["Wei", "Xiaohan", ""], ["Ling", "Qing", ""], ["Han", "Zhu", ""]]}, {"id": "1509.08535", "submitter": "Siamak Ravanbakhsh", "authors": "Siamak Ravanbakhsh, Barnabas Poczos, Russell Greiner", "title": "Boolean Matrix Factorization and Noisy Completion via Message Passing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.AI cs.DM stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Boolean matrix factorization and Boolean matrix completion from noisy\nobservations are desirable unsupervised data-analysis methods due to their\ninterpretability, but hard to perform due to their NP-hardness. We treat these\nproblems as maximum a posteriori inference problems in a graphical model and\npresent a message passing approach that scales linearly with the number of\nobservations and factors. Our empirical study demonstrates that message passing\nis able to recover low-rank Boolean matrices, in the boundaries of\ntheoretically possible recovery and compares favorably with state-of-the-art in\nreal-world applications, such collaborative filtering with large-scale Boolean\ndata.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2015 23:11:16 GMT"}, {"version": "v2", "created": "Fri, 9 Oct 2015 19:27:13 GMT"}, {"version": "v3", "created": "Thu, 4 Feb 2016 21:05:32 GMT"}], "update_date": "2016-02-08", "authors_parsed": [["Ravanbakhsh", "Siamak", ""], ["Poczos", "Barnabas", ""], ["Greiner", "Russell", ""]]}, {"id": "1509.08869", "submitter": "Matyas Barczy", "authors": "Matyas Barczy, Mohamed Ben Alaya, Ahmed Kebaier, Gyula Pap", "title": "Asymptotic behavior of maximum likelihood estimators for a jump-type\n  Heston model", "comments": "51 pages, 3 figures", "journal-ref": "Journal of Statistical Planning and Inference 198, (2019), 139-164", "doi": null, "report-no": null, "categories": "math.ST math.PR q-fin.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study asymptotic properties of maximum likelihood estimators of drift\nparameters for a jump-type Heston model based on continuous time observations,\nwhere the jump process can be any purely non-Gaussian L\\'evy process of not\nnecessarily bounded variation with a L\\'evy measure concentrated on\n$(-1,\\infty)$. We prove strong consistency and asymptotic normality for all\nadmissible parameter values except one, where we show only weak consistency and\nmixed normal (but non-normal) asymptotic behavior. It turns out that the\nvolatility of the price process is a measurable function of the price process.\nWe also present some numerical illustrations to confirm our results.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2015 18:05:47 GMT"}, {"version": "v2", "created": "Thu, 26 May 2016 06:48:39 GMT"}, {"version": "v3", "created": "Thu, 15 Dec 2016 11:06:42 GMT"}, {"version": "v4", "created": "Fri, 18 May 2018 18:44:16 GMT"}], "update_date": "2018-06-08", "authors_parsed": [["Barczy", "Matyas", ""], ["Alaya", "Mohamed Ben", ""], ["Kebaier", "Ahmed", ""], ["Pap", "Gyula", ""]]}, {"id": "1509.08892", "submitter": "Xin Hunt", "authors": "Xin Jiang, Patricia Reynaud-Bouret, Vincent Rivoirard, Laure\n  Sansonnet, Rebecca Willett", "title": "A data-dependent weighted LASSO under Poisson noise", "comments": "25 pages (48 pages with appendix), 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT math.IT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse linear inverse problems appear in a variety of settings, but often the\nnoise contaminating observations cannot accurately be described as bounded by\nor arising from a Gaussian distribution. Poisson observations in particular are\na feature of several real-world applications. Previous work on sparse Poisson\ninverse problems encountered several limiting technical hurdles. This paper\ndescribes a novel alternative analysis approach for sparse Poisson inverse\nproblems that (a) sidesteps the technical challenges in previous work, (b)\nadmits estimators that can readily be computed using off-the-shelf LASSO\nalgorithms, and (c) hints at a general framework for broad classes of noise in\nsparse linear inverse problems. At the heart of this new approach lies a\nweighted LASSO estimator for which data-dependent weights are based on Poisson\nconcentration inequalities. Unlike previous analyses of the weighted LASSO, the\nproposed analysis depends on conditions which can be checked or shown to hold\nin general settings with high probability.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2015 19:12:53 GMT"}, {"version": "v2", "created": "Tue, 13 Feb 2018 16:41:18 GMT"}], "update_date": "2018-02-14", "authors_parsed": [["Jiang", "Xin", ""], ["Reynaud-Bouret", "Patricia", ""], ["Rivoirard", "Vincent", ""], ["Sansonnet", "Laure", ""], ["Willett", "Rebecca", ""]]}, {"id": "1509.09048", "submitter": "Tepmony Sim", "authors": "Randal Douc (CITI), Francois Roueff (LTCI), Tepmony Sim (LTCI)", "title": "The maximizing set of the asymptotic normalized log-likelihood for\n  partially observed Markov chains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with a parametrized family of partially observed bivariate\nMarkov chains. We establish that, under very mild assumptions, the limit of the\nnormalized log-likelihood function is maximized when the parameters belong to\nthe equivalence class of the true parameter, which is a key feature for\nobtaining the consistency of the maximum likelihood estimators (MLEs) in\nwell-specified models. This result is obtained in the general framework of\npartially dominated models. We examine two specific cases of interest, namely,\nhidden Markov models (HMMs) and observation-driven time series models. In\ncontrast with previous approaches, the identifiability is addressed by relying\non the uniqueness of the invariant distribution of the Markov chain associated\nto the complete data, regardless its rate of convergence to the equilibrium.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2015 07:52:53 GMT"}], "update_date": "2015-10-01", "authors_parsed": [["Douc", "Randal", "", "CITI"], ["Roueff", "Francois", "", "LTCI"], ["Sim", "Tepmony", "", "LTCI"]]}, {"id": "1509.09103", "submitter": "Sylvain Le", "authors": "Pierre Gloaguen (IFREMER), Marie-Pierre Etienne (MIA-Paris), Sylvain\n  Le Corff", "title": "Stochastic differential equation based on a multimodal potential to\n  model movement data in ecology", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a new model for individuals movement in ecology. The\nmovement process is defined as a solution to a stochastic differential equation\nwhose drift is the gradient of a multimodal potential surface. This offers a\nnew flexible approach among the popular potential based movement models in\necology. To perform parameter inference, the widely used Euler method is\ncompared with two other pseudo-likelihood procedures and with a Monte Carlo\nExpectation Maximization approach based on exact simulation of diffusions.\nPerformances of all methods are assessed with simulated data and with a data\nset of fishing vessels trajectories. We show that the usual Euler method\nperforms worse than the other procedures for all sampling schemes.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2015 09:53:32 GMT"}, {"version": "v2", "created": "Fri, 18 Nov 2016 15:37:22 GMT"}, {"version": "v3", "created": "Thu, 21 Sep 2017 07:39:20 GMT"}], "update_date": "2017-09-22", "authors_parsed": [["Gloaguen", "Pierre", "", "IFREMER"], ["Etienne", "Marie-Pierre", "", "MIA-Paris"], ["Corff", "Sylvain Le", ""]]}, {"id": "1509.09129", "submitter": "Cathy Maugis-Rabusseau", "authors": "B\\'eatrice Laurent (IMT), Cl\\'ement Marteau (IMT), Cathy\n  Maugis-Rabusseau (IMT)", "title": "Multidimensional two-component Gaussian mixtures detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $(X\\_1,\\ldots,X\\_n)$ be a $d$-dimensional i.i.d sample from a\ndistribution with density $f$. The problem of detection of a two-component\nmixture is considered. Our aim is to decide whether $f$ is the density of a\nstandard Gaussian random $d$-vector ($f=\\phi\\_d$) against $f$ is a\ntwo-component mixture: $f=(1-\\varepsilon)\\phi\\_d +\\varepsilon \\phi\\_d (.-\\mu)$\nwhere $(\\varepsilon,\\mu)$ are unknown parameters. Optimal separation conditions\non $\\varepsilon, \\mu, n$ and the dimension $d$ are established, allowing to\nseparate both hypotheses with prescribed errors. Several testing procedures are\nproposed and two alternative subsets are considered.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2015 11:38:07 GMT"}], "update_date": "2015-10-01", "authors_parsed": [["Laurent", "B\u00e9atrice", "", "IMT"], ["Marteau", "Cl\u00e9ment", "", "IMT"], ["Maugis-Rabusseau", "Cathy", "", "IMT"]]}, {"id": "1509.09167", "submitter": "Marie du Roy de Chaumaray", "authors": "Marie du Roy de Chaumaray", "title": "Weighted least squares estimation for the subcritical Heston process", "comments": null, "journal-ref": null, "doi": "10.1017/jpr.2018.34", "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We simultaneously estimate the four parameters of a subcritical Heston\nprocess. We do not restrict ourself to the case where the stochastic volatility\nprocess never reaches zero. In order to avoid the use of unmanageable stopping\ntimes and natural but intractable estimator, we propose to make use of a\nweighted least squares estimator. We establish strong consistency and\nasymptotic normality for this estimator. Numerical simulations are also\nprovided, illustrating the good performances of our estimation procedure.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2015 13:28:36 GMT"}, {"version": "v2", "created": "Tue, 14 Jun 2016 10:13:00 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["de Chaumaray", "Marie du Roy", ""]]}, {"id": "1509.09225", "submitter": "Jose Rodriguez", "authors": "Emil Horobet and Jose Israel Rodriguez", "title": "The Maximum Likelihood Data Singular Locus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For general data, the number of complex solutions to the likelihood equations\nis constant and this number is called the (maximum likelihood) ML-degree of the\nmodel. In this article, we describe the special locus of data for which the\nlikelihood equations have a solution in the model's singular locus.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2015 15:36:13 GMT"}], "update_date": "2015-10-01", "authors_parsed": [["Horobet", "Emil", ""], ["Rodriguez", "Jose Israel", ""]]}, {"id": "1509.09273", "submitter": "H\\'el\\`ene Boistard", "authors": "H\\'el\\`ene Boistard, Hendrik P. Lopuha\\\"a and Anne Ruiz-Gazen", "title": "Functional central limit theorems for single-stage samplings designs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For a joint model-based and design-based inference, we establish functional\ncentral limit theorems for the Horvitz-Thompson empirical process and the\nH\\'ajek empirical process centered by their finite population mean as well as\nby their super-population mean in a survey sampling framework. The results\napply to single-stage unequal probability sampling designs and essentially only\nrequire conditions on higher order correlations. We apply our main results to a\nHadamard differentiable statistical functional and illustrate its limit\nbehavior by means of a computer simulation.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2015 17:52:21 GMT"}, {"version": "v2", "created": "Wed, 4 May 2016 03:00:09 GMT"}], "update_date": "2016-05-05", "authors_parsed": [["Boistard", "H\u00e9l\u00e8ne", ""], ["Lopuha\u00e4", "Hendrik P.", ""], ["Ruiz-Gazen", "Anne", ""]]}, {"id": "1509.09286", "submitter": "Eduard Belitser", "authors": "Eduard Belitser", "title": "Pinsker bound under measurement budget constrain: optimal allocation", "comments": "12 p", "journal-ref": "Statist. Probab. Lett., 117, 46-53 (2016)", "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the classical many normal means with different variances, we consider the\nsituation when the observer is allowed to allocate the available measurement\nbudget over the coordinates of the parameter of interest. The benchmark is the\nminimax linear risk over a set. We solve the problem of optimal allocation of\nobservations under the measurement budget constrain for two types of sets,\nellipsoids and hyperrectangles. By elaborating on the two examples of Sobolev\nellipsoids and hyperectangles, we demonstrate how re-allocating the\nmeasurements in the (sub-)optimal way improves on the standard uniform\nallocation. In particular, we improve the famous Pinsker (1980) bound.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2015 18:24:11 GMT"}], "update_date": "2019-04-01", "authors_parsed": [["Belitser", "Eduard", ""]]}]