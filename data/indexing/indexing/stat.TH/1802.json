[{"id": "1802.00001", "submitter": "Hoi Nguyen", "authors": "Hoi H. Nguyen and Elliot Paquette", "title": "Surjectivity of near square random matrices", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.CO math.NT math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that a nearly square iid random integral matrix is surjective over\nthe integral lattice with very high probability. This answers a question by\nKoplewitz. Our result extends to sparse matrices as well as to matrices of\ndependent entries.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jan 2018 21:59:23 GMT"}], "update_date": "2018-02-02", "authors_parsed": [["Nguyen", "Hoi H.", ""], ["Paquette", "Elliot", ""]]}, {"id": "1802.00047", "submitter": "Rui Zhang", "authors": "Alexander Shapiro, Yao Xie, Rui Zhang", "title": "Matrix completion with deterministic pattern - a geometric perspective", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2018.2885494", "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the matrix completion problem with a deterministic pattern of\nobserved entries. In this setting, we aim to answer the question: under what\ncondition there will be (at least locally) unique solution to the matrix\ncompletion problem, i.e., the underlying true matrix is identifiable. We answer\nthe question from a certain point of view and outline a geometric perspective.\nWe give an algebraically verifiable sufficient condition, which we call the\nwell-posedness condition, for the local uniqueness of MRMC solutions. We argue\nthat this condition is necessary for local stability of MRMC solutions, and we\nshow that the condition is generic using the characteristic rank. We also argue\nthat the low-rank approximation approaches are more stable than MRMC and\nfurther propose a sequential statistical testing procedure to determine the\n\"true\" rank from observed entries. Finally, we provide numerical examples aimed\nat verifying validity of the presented theory.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jan 2018 20:03:07 GMT"}, {"version": "v2", "created": "Fri, 2 Feb 2018 02:29:26 GMT"}, {"version": "v3", "created": "Fri, 16 Feb 2018 03:25:36 GMT"}, {"version": "v4", "created": "Wed, 29 Aug 2018 19:03:53 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Shapiro", "Alexander", ""], ["Xie", "Yao", ""], ["Zhang", "Rui", ""]]}, {"id": "1802.00211", "submitter": "Bai Jiang", "authors": "Jianqing Fan and Bai Jiang and Qiang Sun", "title": "Hoeffding's lemma for Markov Chains and its applications to statistical\n  learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend Hoeffding's lemma to general-state-space and not necessarily\nreversible Markov chains. Let $\\{X_i\\}_{i \\ge 1}$ be a stationary Markov chain\nwith invariant measure $\\pi$ and absolute spectral gap $1-\\lambda$, where\n$\\lambda$ is defined as the operator norm of the transition kernel acting on\nmean zero and square-integrable functions with respect to $\\pi$. Then, for any\nbounded functions $f_i: x \\mapsto [a_i,b_i]$, the sum of $f_i(X_i)$ is\nsub-Gaussian with variance proxy $\\frac{1+\\lambda}{1-\\lambda} \\cdot \\sum_i\n\\frac{(b_i-a_i)^2}{4}$. This result differs from the classical Hoeffding's\nlemma by a multiplicative coefficient of $(1+\\lambda)/(1-\\lambda)$, and\nsimplifies to the latter when $\\lambda = 0$. The counterpart of Hoeffding's\ninequality for Markov chains immediately follows. Our results assume none of\ncountable state space, reversibility and time-homogeneity of Markov chains and\ncover time-dependent functions with various ranges. We illustrate the utility\nof these results by applying them to six problems in statistics and machine\nlearning.\n", "versions": [{"version": "v1", "created": "Thu, 1 Feb 2018 09:36:24 GMT"}, {"version": "v2", "created": "Fri, 2 Feb 2018 15:38:56 GMT"}, {"version": "v3", "created": "Wed, 13 Jun 2018 08:25:36 GMT"}, {"version": "v4", "created": "Tue, 17 Jul 2018 20:05:41 GMT"}], "update_date": "2018-07-19", "authors_parsed": [["Fan", "Jianqing", ""], ["Jiang", "Bai", ""], ["Sun", "Qiang", ""]]}, {"id": "1802.00381", "submitter": "Joshua Cape", "authors": "Joshua Cape and Minh Tang and Carey E. Priebe", "title": "Signal-plus-noise matrix models: eigenvector deviations and fluctuations", "comments": "12 pages, 2 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating eigenvectors and low-dimensional subspaces is of central\nimportance for numerous problems in statistics, computer science, and applied\nmathematics. This paper characterizes the behavior of perturbed eigenvectors\nfor a range of signal-plus-noise matrix models encountered in both statistical\nand random matrix theoretic settings. We prove both first-order approximation\nresults (i.e. sharp deviations) as well as second-order distributional limit\ntheory (i.e. fluctuations). The concise methodology considered in this paper\nsynthesizes tools rooted in two core concepts, namely (i) deterministic\ndecompositions of matrix perturbations and (ii) probabilistic matrix\nconcentration phenomena. We illustrate our theoretical results via simulation\nexamples involving stochastic block model random graphs.\n", "versions": [{"version": "v1", "created": "Thu, 1 Feb 2018 16:45:04 GMT"}, {"version": "v2", "created": "Wed, 12 Sep 2018 21:39:31 GMT"}], "update_date": "2018-09-14", "authors_parsed": [["Cape", "Joshua", ""], ["Tang", "Minh", ""], ["Priebe", "Carey E.", ""]]}, {"id": "1802.00430", "submitter": "Andrew Lan", "authors": "Andrew S. Lan, Mung Chiang, Christoph Studer", "title": "Linearized Binary Regression", "comments": "To be presented at CISS (http://ee-ciss.princeton.edu/)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probit regression was first proposed by Bliss in 1934 to study mortality\nrates of insects. Since then, an extensive body of work has analyzed and used\nprobit or related binary regression methods (such as logistic regression) in\nnumerous applications and fields. This paper provides a fresh angle to such\nwell-established binary regression methods. Concretely, we demonstrate that\nlinearizing the probit model in combination with linear estimators performs on\npar with state-of-the-art nonlinear regression methods, such as posterior mean\nor maximum aposteriori estimation, for a broad range of real-world regression\nproblems. We derive exact, closed-form, and nonasymptotic expressions for the\nmean-squared error of our linearized estimators, which clearly separates them\nfrom nonlinear regression methods that are typically difficult to analyze. We\nshowcase the efficacy of our methods and results for a number of synthetic and\nreal-world datasets, which demonstrates that linearized binary regression finds\npotential use in a variety of inference, estimation, signal processing, and\nmachine learning applications that deal with binary-valued observations or\nmeasurements.\n", "versions": [{"version": "v1", "created": "Thu, 1 Feb 2018 18:49:14 GMT"}], "update_date": "2018-02-02", "authors_parsed": [["Lan", "Andrew S.", ""], ["Chiang", "Mung", ""], ["Studer", "Christoph", ""]]}, {"id": "1802.00474", "submitter": "Subhadeep Mukhopadhyay", "authors": "Subhadeep (Deep) Mukhopadhyay and Douglas Fletcher", "title": "Bayesian Modeling via Goodness-of-fit", "comments": "Revised version", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The two key issues of modern Bayesian statistics are: (i) establishing\nprincipled approach for distilling statistical prior that is consistent with\nthe given data from an initial believable scientific prior; and (ii)\ndevelopment of a Bayes-frequentist consolidated data analysis workflow that is\nmore effective than either of the two separately. In this paper, we propose the\nidea of \"Bayes via goodness of fit\" as a framework for exploring these\nfundamental questions, in a way that is general enough to embrace almost all of\nthe familiar probability models. Several illustrative examples show the benefit\nof this new point of view as a practical data analysis tool. Relationship with\nother Bayesian cultures is also discussed.\n", "versions": [{"version": "v1", "created": "Thu, 1 Feb 2018 20:15:31 GMT"}, {"version": "v2", "created": "Fri, 9 Feb 2018 03:08:44 GMT"}, {"version": "v3", "created": "Mon, 16 Apr 2018 22:28:39 GMT"}], "update_date": "2018-04-18", "authors_parsed": [["Subhadeep", "", "", "Deep"], ["Mukhopadhyay", "", ""], ["Fletcher", "Douglas", ""]]}, {"id": "1802.00555", "submitter": "Alexander Giessing", "authors": "Alexander Giessing, Xuming He", "title": "On the Predictive Risk in Misspecified Quantile Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In the present paper we investigate the predictive risk of possibly\nmisspecified quantile regression functions. The in-sample risk is well-known to\nbe an overly optimistic estimate of the predictive risk and we provide two\nrelatively simple (asymptotic) characterizations of the associated bias, also\ncalled expected optimism. We propose estimates for the expected optimism and\nthe predictive risk, and establish their uniform consistency under mild\nconditions. Our results hold for models of moderately growing size and allow\nthe quantile function to be incorrectly specified. Empirical evidence from our\nestimates is encouraging as it compares favorably with cross-validation.\n", "versions": [{"version": "v1", "created": "Fri, 2 Feb 2018 04:27:45 GMT"}, {"version": "v2", "created": "Thu, 1 Nov 2018 22:36:25 GMT"}], "update_date": "2018-11-05", "authors_parsed": [["Giessing", "Alexander", ""], ["He", "Xuming", ""]]}, {"id": "1802.00578", "submitter": "Koji Tsukuda", "authors": "Koji Tsukuda, Shuhei Mano", "title": "A reversal phenomenon in estimation based on multiple samples from the\n  Poisson--Dirichlet distribution", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider two forms of sampling from a population: (i) drawing $s$ samples of\n$n$ elements with replacement and (ii) drawing a single sample of $ns$\nelements. In this paper, under the setting where the descending order\npopulation frequency follows the Poisson--Dirichlet distribution with parameter\n$\\theta$, we report that the magnitude relation of the Fisher information,\nwhich sample partitions converted from samples (i) and (ii) possess, can change\ndepending on the parameters, $n$, $s$, and $\\theta$. Roughly speaking, if\n$\\theta$ is small relative to $n$ and $s$, the Fisher information of (i) is\nlarger than that of (ii); on the contrary, if $\\theta$ is large relative to $n$\nand $s$, the Fisher information of (ii) is larger than that of (i). The result\nrepresents one aspect of random distributions.\n", "versions": [{"version": "v1", "created": "Fri, 2 Feb 2018 06:47:34 GMT"}], "update_date": "2018-02-05", "authors_parsed": [["Tsukuda", "Koji", ""], ["Mano", "Shuhei", ""]]}, {"id": "1802.00926", "submitter": "I-Hsiang Wang", "authors": "I Chien, Chung-Yi Lin, and I-Hsiang Wang", "title": "On the Minimax Misclassification Ratio of Hypergraph Community Detection", "comments": "Submitted to IEEE Transactions on Information Theory. Parts of this\n  paper was presented at ISIT 2017 and to appear at AISTATS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Community detection in hypergraphs is explored. Under a generative hypergraph\nmodel called \"d-wise hypergraph stochastic block model\" (d-hSBM) which\nnaturally extends the Stochastic Block Model from graphs to d-uniform\nhypergraphs, the asymptotic minimax mismatch ratio is characterized. For\nproving the achievability, we propose a two-step polynomial time algorithm that\nachieves the fundamental limit. The first step of the algorithm is a hypergraph\nspectral clustering method which achieves partial recovery to a certain\nprecision level. The second step is a local refinement method which leverages\nthe underlying probabilistic model along with parameter estimation from the\noutcome of the first step. To characterize the asymptotic performance of the\nproposed algorithm, we first derive a sufficient condition for attaining weak\nconsistency in the hypergraph spectral clustering step. Then, under the\nguarantee of weak consistency in the first step, we upper bound the worst-case\nrisk attained in the local refinement step by an exponentially decaying\nfunction of the size of the hypergraph and characterize the decaying rate. For\nproving the converse, the lower bound of the minimax mismatch ratio is set by\nfinding a smaller parameter space which contains the most dominant error\nevents, inspired by the analysis in the achievability part. It turns out that\nthe minimax mismatch ratio decays exponentially fast to zero as the number of\nnodes tends to infinity, and the rate function is a weighted combination of\nseveral divergence terms, each of which is the Renyi divergence of order 1/2\nbetween two Bernoulli's. The Bernoulli's involved in the characterization of\nthe rate function are those governing the random instantiation of hyperedges in\nd-hSBM. Experimental results on synthetic data validate our theoretical finding\nthat the refinement step is critical in achieving the optimal statistical\nlimit.\n", "versions": [{"version": "v1", "created": "Sat, 3 Feb 2018 06:35:23 GMT"}], "update_date": "2018-02-06", "authors_parsed": [["Chien", "I", ""], ["Lin", "Chung-Yi", ""], ["Wang", "I-Hsiang", ""]]}, {"id": "1802.00982", "submitter": "Chunhao Cai", "authors": "Chunhao Cai and Yingzhong Huang", "title": "Malliavin Derivative for the Unknown Parameter in surplus process with\n  mixed fractional Brownian motion", "comments": "In the proof of Theorem 3.1 of the V3 and V4 we do not give the\n  suitable citation and also there exists mistakes in this Theorem", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we will construct the Malliavin derivative and the stochastic\nintegral with respect to the Mixed fractional Brownian motion (mfbm) for H >\n1/2. As an application, we try to estimate the drift parameter via Malliavin\nderivative for surplus process with mixed fractional Brownian motion\n", "versions": [{"version": "v1", "created": "Sat, 3 Feb 2018 14:45:16 GMT"}, {"version": "v2", "created": "Fri, 16 Mar 2018 22:38:36 GMT"}, {"version": "v3", "created": "Thu, 16 Jan 2020 19:04:47 GMT"}, {"version": "v4", "created": "Thu, 15 Apr 2021 09:29:07 GMT"}, {"version": "v5", "created": "Wed, 7 Jul 2021 01:03:18 GMT"}, {"version": "v6", "created": "Thu, 8 Jul 2021 01:01:23 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Cai", "Chunhao", ""], ["Huang", "Yingzhong", ""]]}, {"id": "1802.01041", "submitter": "Colin McCrimmon", "authors": "Colin M. McCrimmon", "title": "Distance Metrics for Gamma Distributions", "comments": "4 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Here I present the analytic form of two common distance metrics, the\nsymmetrised Kullback-Leibler Divergence and the Kolmogorov-Smirnov statistic,\nas well as an extension of the Kolmogorov-Smirnov statistic for comparing\ntheoretical gamma distributions. In doing so, I also present the analytic\nsolution to the intersection of two gamma distributions. Lastly, I provide\nexamples that demonstrate the similarity between these distance metrics and\ntheir usefulness in describing the separability of gamma distributions.\n", "versions": [{"version": "v1", "created": "Sat, 3 Feb 2018 22:12:59 GMT"}], "update_date": "2018-02-06", "authors_parsed": [["McCrimmon", "Colin M.", ""]]}, {"id": "1802.01056", "submitter": "Pooriya Beyhaghi", "authors": "Pooriya Beyhaghi, Shahrouz Alimohammadi, Thomas Bewley", "title": "Uncertainty Quantification of the time averaging of a Statistics\n  Computed from Numerical Simulation of Turbulent Flow", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST physics.comp-ph stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rigorous assessment of the uncertainty is crucial to the utility of numerical\nsimulation of Turbulent flow. The Turbulent flows are often stationary and\nergodic, after some initial transient time. Therefore, the time averaged of a\nquantity (velocity, TKE (turbulence kinetic energy), total drag, etc) converges\nto a constant as the averaging interval increases. This infinite-time-average\nstatistic is of particular interest in many problems, such as aerodynamic shape\noptimization. Since taking an average over the infinite time horizon is not\npossible, some finite-time approximation of the infinite-time-average statistic\nof interest is used in practice. However, because of the initial transient\nbehavior of the turbulence simulations, this estimate is biased. This issue is\nsolved by deleting the initial transient part of the simulation. The other\nimportant issue is the error of this approximation decreases slowly, like the\nreciprocal of the square roots of the averaging time. In this paper, we develop\na framework to first automatically deleted the transient part of a turbulence\nsimulation, then, quantify precisely the uncertainty of such a\nfinite-time-average approximation of an infinite-time-average statistic of a\nstationary and ergodic process.\n", "versions": [{"version": "v1", "created": "Sun, 4 Feb 2018 01:27:51 GMT"}], "update_date": "2018-02-06", "authors_parsed": [["Beyhaghi", "Pooriya", ""], ["Alimohammadi", "Shahrouz", ""], ["Bewley", "Thomas", ""]]}, {"id": "1802.01171", "submitter": "Joona Karjalainen", "authors": "Joona Karjalainen and Johan S.H. van Leeuwaarden and Lasse Leskel\\\"a", "title": "Parameter estimators of random intersection graphs with thinned\n  communities", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.SI math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies a statistical network model generated by a large number of\nrandomly sized overlapping communities, where any pair of nodes sharing a\ncommunity is linked with probability $q$ via the community. In the special case\nwith $q=1$ the model reduces to a random intersection graph which is known to\ngenerate high levels of transitivity also in the sparse context. The parameter\n$q$ adds a degree of freedom and leads to a parsimonious and analytically\ntractable network model with tunable density, transitivity, and degree\nfluctuations. We prove that the parameters of this model can be consistently\nestimated in the large and sparse limiting regime using moment estimators based\non partially observed densities of links, 2-stars, and triangles.\n", "versions": [{"version": "v1", "created": "Sun, 4 Feb 2018 18:23:30 GMT"}, {"version": "v2", "created": "Sun, 24 Jun 2018 19:26:09 GMT"}], "update_date": "2018-06-26", "authors_parsed": [["Karjalainen", "Joona", ""], ["van Leeuwaarden", "Johan S. H.", ""], ["Leskel\u00e4", "Lasse", ""]]}, {"id": "1802.01227", "submitter": "Xiaochao Xia", "authors": "Xiaochao Xia and Jialiang Li", "title": "Copula-based Partial Correlation Screening: a Joint and Robust Approach", "comments": "50 pages, 1 figures, 10 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Screening for ultrahigh dimensional features may encounter complicated issues\nsuch as outlying observations, heteroscedasticity or heavy-tailed distribution,\nmulti-collinearity and confounding effects. Standard correlation-based marginal\nscreening methods may be a weak solution to these issues. We contribute a novel\nrobust joint screener to safeguard against outliers and distribution\nmis-specification for both the response variable and the covariates, and to\naccount for external variables at the screening step. Specifically, we\nintroduce a copula-based partial correlation (CPC) screener. We show that the\nempirical process of the estimated CPC converges weakly to a Gaussian process\nand establish the sure screening property for CPC screener under very mild\ntechnical conditions, where we need not require any moment condition, weaker\nthan existing alternatives in the literature. Moreover, our approach allows for\na diverging number of conditional variables from the theoretical point of view.\nExtensive simulation studies and two data applications are included to\nillustrate our proposal.\n", "versions": [{"version": "v1", "created": "Mon, 5 Feb 2018 01:11:37 GMT"}, {"version": "v2", "created": "Sun, 23 Dec 2018 15:03:19 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Xia", "Xiaochao", ""], ["Li", "Jialiang", ""]]}, {"id": "1802.01245", "submitter": "Yanqing Yin", "authors": "Yanqing Yin", "title": "On singular value distribution of large dimensional data matrices whose\n  columns have different correlations", "comments": "The final version of this paper will be published in Statistics", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Suppose $\\mathbf Y_n=(\\mathbf y_1,\\cdots,\\mathbf y_n)$ is a $p\\times n$ data\nmatrix whose columns $\\mathbf y_j, 1\\leq j\\leq n$ have different correlations.\nThe asymptotic spectral property of $\\mathbf S_n=\\frac1n\\mathbf Y_n\\mathbf\nY^*_n$ when $p$ increase with $n$ has been considered by some authors recently.\nThis model has known an increasing popularity due to its widely applications in\nmulti-user multiple-input single-output (MISO) systems and robust signal\nprocessing. In this paper, for more convenient applications in practice, we\nwill investigate the spectral distribution of $\\mathbf S_n$ under milder moment\nconditions than existing work. We also discuss a potential application in\nsample classification.\n", "versions": [{"version": "v1", "created": "Mon, 5 Feb 2018 03:04:15 GMT"}, {"version": "v2", "created": "Sun, 5 Aug 2018 06:02:48 GMT"}, {"version": "v3", "created": "Fri, 17 Jan 2020 15:56:31 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["Yin", "Yanqing", ""]]}, {"id": "1802.01458", "submitter": "Charles-Alban Deledalle", "authors": "Charles-Alban Deledalle (IMB, UCSD), Shibin Parameswaran (UCSD),\n  Truong Q. Nguyen (UCSD)", "title": "Image denoising with generalized Gaussian mixture model patch priors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Patch priors have become an important component of image restoration. A\npowerful approach in this category of restoration algorithms is the popular\nExpected Patch Log-Likelihood (EPLL) algorithm. EPLL uses a Gaussian mixture\nmodel (GMM) prior learned on clean image patches as a way to regularize\ndegraded patches. In this paper, we show that a generalized Gaussian mixture\nmodel (GGMM) captures the underlying distribution of patches better than a GMM.\nEven though GGMM is a powerful prior to combine with EPLL, the non-Gaussianity\nof its components presents major challenges to be applied to a computationally\nintensive process of image restoration. Specifically, each patch has to undergo\na patch classification step and a shrinkage step. These two steps can be\nefficiently solved with a GMM prior but are computationally impractical when\nusing a GGMM prior. In this paper, we provide approximations and computational\nrecipes for fast evaluation of these two steps, so that EPLL can embed a GGMM\nprior on an image with more than tens of thousands of patches. Our main\ncontribution is to analyze the accuracy of our approximations based on thorough\ntheoretical analysis. Our evaluations indicate that the GGMM prior is\nconsistently a better fit formodeling image patch distribution and performs\nbetter on average in image denoising task.\n", "versions": [{"version": "v1", "created": "Mon, 5 Feb 2018 15:18:21 GMT"}, {"version": "v2", "created": "Mon, 11 Jun 2018 13:00:13 GMT"}], "update_date": "2018-06-12", "authors_parsed": [["Deledalle", "Charles-Alban", "", "IMB, UCSD"], ["Parameswaran", "Shibin", "", "UCSD"], ["Nguyen", "Truong Q.", "", "UCSD"]]}, {"id": "1802.01755", "submitter": "Guido Kuersteiner", "authors": "Guido M. Kuersteiner and Ingmar R. Prucha", "title": "Dynamic Spatial Panel Models: Networks, Common Shocks, and Sequential\n  Exogeneity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers a class of GMM estimators for general dynamic panel\nmodels, allowing for weakly exogenous covariates and cross sectional dependence\ndue to spatial lags, unspecified common shocks and time-varying interactive\neffects. We significantly expand the scope of the existing literature by\nallowing for endogenous spatial weight matrices without imposing any\nrestrictions on how the weights are generated. An important area of application\nis in social interaction and network models where our specification can\naccommodate data dependent network formation. We consider an exemplary social\ninteraction model and show how identification of the interaction parameters is\nachieved through a combination of linear and quadratic moment conditions. For\nthe general setup we develop an orthogonal forward differencing transformation\nto aid in the estimation of factor components while maintaining orthogonality\nof moment conditions. This is an important ingredient to a tractable asymptotic\ndistribution of our estimators. In general, the asymptotic distribution of our\nestimators is found to be mixed normal due to random norming. However, the\nasymptotic distribution of our test statistics is still chi-square.\n", "versions": [{"version": "v1", "created": "Tue, 6 Feb 2018 01:41:55 GMT"}], "update_date": "2018-02-07", "authors_parsed": [["Kuersteiner", "Guido M.", ""], ["Prucha", "Ingmar R.", ""]]}, {"id": "1802.01841", "submitter": "Anne Eggels", "authors": "A.W. Eggels, D.T. Crommelin", "title": "Quantifying dependencies for sensitivity analysis with multivariate\n  input sample data", "comments": null, "journal-ref": "Entropy, Volume 21, Number 2, Article number 100, 2019", "doi": "10.3390/e21020100", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel method for quantifying dependencies in multivariate\ndatasets, based on estimating the R\\'{e}nyi entropy by minimum spanning trees\n(MSTs). The length of the MSTs can be used to order pairs of variables from\nstrongly to weakly dependent, making it a useful tool for sensitivity analysis\nwith dependent input variables. It is well-suited for cases where the input\ndistribution is unknown and only a sample of the inputs is available. We\nintroduce an estimator to quantify dependency based on the MST length, and\ninvestigate its properties with several numerical examples. To reduce the\ncomputational cost of constructing the exact MST for large datasets, we explore\nmethods to compute approximations to the exact MST, and find the multilevel\napproach introduced recently by Zhong et al. (2015) to be the most accurate. We\napply our proposed method to an artificial testcase based on the Ishigami\nfunction, as well as to a real-world testcase involving sediment transport in\nthe North Sea. The results are consistent with prior knowledge and heuristic\nunderstanding, as well as with variance-based analysis using Sobol indices in\nthe case where these indices can be computed.\n", "versions": [{"version": "v1", "created": "Tue, 6 Feb 2018 08:36:07 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Eggels", "A. W.", ""], ["Crommelin", "D. T.", ""]]}, {"id": "1802.02009", "submitter": "Sven Wang", "authors": "Sven Wang", "title": "The nonparametric LAN expansion for discretely observed diffusions", "comments": "30 pages", "journal-ref": "Electronic Journal of Statistics, Vol. 13 (2019), 1329-1358", "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a scalar reflected diffusion $(X_t:t\\geq 0)$, where the unknown\ndrift function $b$ is modelled nonparametrically. We show that in the low\nfrequency sampling case, when the sample consists of\n$(X_0,X_\\Delta,...,X_{n\\Delta})$ for some fixed sampling distance $\\Delta>0$,\nthe model satisfies the local asymptotic normality (LAN) property, assuming\nthat $b$ satisfies some mild regularity assumptions. This is established by\nusing the connections of diffusion processes to elliptic and parabolic PDEs.\nThe key tools will be regularity estimates from the theory of parabolic PDEs as\nwell as a detailed analysis of the spectral properties of the elliptic\ndifferential operator related to $(X_t:t\\geq 0)$.\n", "versions": [{"version": "v1", "created": "Tue, 6 Feb 2018 15:42:01 GMT"}, {"version": "v2", "created": "Thu, 8 Nov 2018 14:39:12 GMT"}, {"version": "v3", "created": "Mon, 15 Apr 2019 13:06:39 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Wang", "Sven", ""]]}, {"id": "1802.02074", "submitter": "Pierre Fernique", "authors": "Pierre Fernique, Jean Peyhardi and Jean-Baptiste Durand", "title": "Splitting models for multivariate count data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Considering discrete models, the univariate framework has been studied in\ndepth compared to the multivariate one. This paper first proposes two criteria\nto define a sensu stricto multivariate discrete distribution. It then\nintroduces the class of splitting distributions that encompasses all usual\nmultivariate discrete distributions (multinomial, negative multinomial,\nmultivariate hypergeometric, multivariate neg- ative hypergeometric, etc . . .\n) and contains several new. Many advantages derive from the compound aspect of\nsplit- ting distributions. It simplifies the study of their characteris- tics,\ninferences, interpretations and extensions to regression models. Moreover,\nsplitting models can be estimated only by combining existing methods, as\nillustrated on three datasets with reproducible studies.\n", "versions": [{"version": "v1", "created": "Tue, 6 Feb 2018 17:03:24 GMT"}], "update_date": "2018-02-07", "authors_parsed": [["Fernique", "Pierre", ""], ["Peyhardi", "Jean", ""], ["Durand", "Jean-Baptiste", ""]]}, {"id": "1802.02352", "submitter": "Bartosz Ko{\\l}odziejek", "authors": "Piotr Graczyk and Hideyuki Ishi and Bartosz Ko{\\l}odziejek", "title": "Wishart laws and variance function on homogeneous cones", "comments": "24 pages, Probab. Math. Statist (2019)", "journal-ref": "Probab. Math. Statist. 39, Fasc. 2 (2019), pp. 337-360", "doi": "10.19195/0208-4147.39.2.6", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a systematic study of Riesz measures and their natural exponential\nfamilies of Wishart laws on a homogeneous cone. We compute explicitly the\ninverse of the mean map and the variance function of a Wishart exponential\nfamily.\n", "versions": [{"version": "v1", "created": "Wed, 7 Feb 2018 08:43:17 GMT"}, {"version": "v2", "created": "Mon, 30 Apr 2018 12:30:23 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Graczyk", "Piotr", ""], ["Ishi", "Hideyuki", ""], ["Ko\u0142odziejek", "Bartosz", ""]]}, {"id": "1802.02368", "submitter": "Olivier Roustant", "authors": "Olivier Roustant (GdR MASCOT-NUM, LIMOS, FAYOL-ENSMSE, UCA), Esperan\n  Padonou, Yves Deville, Alo\\\"is Cl\\'ement (CEA/DAM), Guillaume Perrin\n  (DAM/DIF), Jean Giorla (DAM/DIF), Henry Wynn (LSE)", "title": "Group kernels for Gaussian process metamodels with categorical inputs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian processes (GP) are widely used as a metamodel for emulating\ntime-consuming computer codes. We focus on problems involving categorical\ninputs, with a potentially large number L of levels (typically several tens),\npartitioned in G << L groups of various sizes. Parsimonious covariance\nfunctions, or kernels, can then be defined by block covariance matrices T with\nconstant covariances between pairs of blocks and within blocks. We study the\npositive definiteness of such matrices to encourage their practical use. The\nhierarchical group/level structure, equivalent to a nested Bayesian linear\nmodel, provides a parameterization of valid block matrices T. The same model\ncan then be used when the assumption within blocks is relaxed, giving a\nflexible parametric family of valid covariance matrices with constant\ncovariances between pairs of blocks. The positive definiteness of T is\nequivalent to the positive definiteness of a smaller matrix of size G, obtained\nby averaging each block. The model is applied to a problem in nuclear waste\nanalysis, where one of the categorical inputs is atomic number, which has more\nthan 90 levels.\n", "versions": [{"version": "v1", "created": "Wed, 7 Feb 2018 09:37:20 GMT"}, {"version": "v2", "created": "Tue, 24 Jul 2018 09:25:54 GMT"}], "update_date": "2018-07-25", "authors_parsed": [["Roustant", "Olivier", "", "GdR MASCOT-NUM, LIMOS, FAYOL-ENSMSE, UCA"], ["Padonou", "Esperan", "", "CEA/DAM"], ["Deville", "Yves", "", "CEA/DAM"], ["Cl\u00e9ment", "Alo\u00efs", "", "CEA/DAM"], ["Perrin", "Guillaume", "", "DAM/DIF"], ["Giorla", "Jean", "", "DAM/DIF"], ["Wynn", "Henry", "", "LSE"]]}, {"id": "1802.02557", "submitter": "Yang Feng", "authors": "Xin Tong, Lucy Xia, Jiacheng Wang and Yang Feng", "title": "Neyman-Pearson classification: parametrics and sample size requirement", "comments": "44 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Neyman-Pearson (NP) paradigm in binary classification seeks classifiers\nthat achieve a minimal type II error while enforcing the prioritized type I\nerror controlled under some user-specified level $\\alpha$. This paradigm serves\nnaturally in applications such as severe disease diagnosis and spam detection,\nwhere people have clear priorities among the two error types. Recently, Tong,\nFeng and Li (2018) proposed a nonparametric umbrella algorithm that adapts all\nscoring-type classification methods (e.g., logistic regression, support vector\nmachines, random forest) to respect the given type I error upper bound $\\alpha$\nwith high probability, without specific distributional assumptions on the\nfeatures and the responses. Universal the umbrella algorithm is, it demands an\nexplicit minimum sample size requirement on class $0$, which is often the more\nscarce class, such as in rare disease diagnosis applications. In this work, we\nemploy the parametric linear discriminant analysis (LDA) model and propose a\nnew parametric thresholding algorithm, which does not need the minimum sample\nsize requirements on class $0$ observations and thus is suitable for small\nsample applications such as rare disease diagnosis. Leveraging both the\nexisting nonparametric and the newly proposed parametric thresholding rules, we\npropose four LDA-based NP classifiers, for both low- and high-dimensional\nsettings. On the theoretical front, we prove NP oracle inequalities for one\nproposed classifier, where the rate for excess type II error benefits from the\nexplicit parametric model assumption. Furthermore, as NP classifiers involve a\nsample splitting step of class $0$ observations, we construct a new adaptive\nsample splitting scheme that can be applied universally to NP classifiers, and\nthis adaptive strategy reduces the type II error of these classifiers.\n", "versions": [{"version": "v1", "created": "Wed, 7 Feb 2018 18:32:47 GMT"}, {"version": "v2", "created": "Sun, 3 Jun 2018 20:23:36 GMT"}, {"version": "v3", "created": "Sat, 16 Jun 2018 14:43:55 GMT"}, {"version": "v4", "created": "Fri, 5 Jul 2019 09:50:12 GMT"}, {"version": "v5", "created": "Tue, 28 Jan 2020 19:37:52 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Tong", "Xin", ""], ["Xia", "Lucy", ""], ["Wang", "Jiacheng", ""], ["Feng", "Yang", ""]]}, {"id": "1802.02643", "submitter": "Pavel Gurevich", "authors": "Pavel Gurevich, Hannes Stuke", "title": "Gradient conjugate priors and multi-layer neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper deals with learning probability distributions of observed data by\nartificial neural networks. We suggest a so-called gradient conjugate prior\n(GCP) update appropriate for neural networks, which is a modification of the\nclassical Bayesian update for conjugate priors. We establish a connection\nbetween the gradient conjugate prior update and the maximization of the\nlog-likelihood of the predictive distribution. Unlike for the Bayesian neural\nnetworks, we use deterministic weights of neural networks, but rather assume\nthat the ground truth distribution is normal with unknown mean and variance and\nlearn by the neural networks the parameters of a prior (normal-gamma\ndistribution) for these unknown mean and variance. The update of the parameters\nis done, using the gradient that, at each step, directs towards minimizing the\nKullback--Leibler divergence from the prior to the posterior distribution (both\nbeing normal-gamma). We obtain a corresponding dynamical system for the prior's\nparameters and analyze its properties. In particular, we study the limiting\nbehavior of all the prior's parameters and show how it differs from the case of\nthe classical full Bayesian update. The results are validated on synthetic and\nreal world data sets.\n", "versions": [{"version": "v1", "created": "Wed, 7 Feb 2018 21:29:52 GMT"}, {"version": "v2", "created": "Fri, 13 Jul 2018 14:27:07 GMT"}, {"version": "v3", "created": "Tue, 26 Mar 2019 09:20:22 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Gurevich", "Pavel", ""], ["Stuke", "Hannes", ""]]}, {"id": "1802.02943", "submitter": "Anna Melnykova", "authors": "Anna Melnykova", "title": "Parametric inference for hypoelliptic ergodic diffusions with full\n  observations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multidimensional hypoelliptic diffusions arise naturally in different fields,\nfor example to model neuronal activity. Estimation in those models is complex\nbecause of the degenerate structure of the diffusion coefficient. In this paper\nwe consider hypoelliptic diffusions, given as a solution of two-dimensional\nstochastic differential equations (SDEs), with the discrete time observations\nof both coordinates being available on an interval $T = n\\Delta_n$, with\n$\\Delta_n$ the time step between the observations. The estimation is studied in\nthe asymptotic setting, with $T\\to\\infty$ as $\\Delta_n\\to 0$. We build a\nconsistent estimator of the drift and variance parameters with the help of a\ndiscretized log-likelihood of the continuous process. We discuss the\ndifficulties generated by the hypoellipticity and provide a proof of the\nconsistency and the asymptotic normality of the estimator. We test our approach\nnumerically on the hypoelliptic FitzHugh-Nagumo model, which describes the\nfiring mechanism of a neuron.\n", "versions": [{"version": "v1", "created": "Thu, 8 Feb 2018 16:12:22 GMT"}, {"version": "v2", "created": "Fri, 26 Jun 2020 07:47:34 GMT"}, {"version": "v3", "created": "Fri, 24 Jul 2020 07:14:11 GMT"}], "update_date": "2020-07-27", "authors_parsed": [["Melnykova", "Anna", ""]]}, {"id": "1802.03195", "submitter": "Ahmed Elzanaty Eng", "authors": "Ahmed Elzanaty and Andrea Giorgetti and Marco Chiani", "title": "Limits on Sparse Data Acquisition: RIC Analysis of Finite Gaussian\n  Matrices", "comments": "11 pages, 6 figures, accepted for publication in IEEE transactions on\n  information theory", "journal-ref": null, "doi": "10.1109/TIT.2018.2859327", "report-no": null, "categories": "cs.IT eess.SP math.IT math.ST stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  One of the key issues in the acquisition of sparse data by means of\ncompressed sensing (CS) is the design of the measurement matrix. Gaussian\nmatrices have been proven to be information-theoretically optimal in terms of\nminimizing the required number of measurements for sparse recovery. In this\npaper we provide a new approach for the analysis of the restricted isometry\nconstant (RIC) of finite dimensional Gaussian measurement matrices. The\nproposed method relies on the exact distributions of the extreme eigenvalues\nfor Wishart matrices. First, we derive the probability that the restricted\nisometry property is satisfied for a given sufficient recovery condition on the\nRIC, and propose a probabilistic framework to study both the symmetric and\nasymmetric RICs. Then, we analyze the recovery of compressible signals in noise\nthrough the statistical characterization of stability and robustness. The\npresented framework determines limits on various sparse recovery algorithms for\nfinite size problems. In particular, it provides a tight lower bound on the\nmaximum sparsity order of the acquired data allowing signal recovery with a\ngiven target probability. Also, we derive simple approximations for the RICs\nbased on the Tracy-Widom distribution.\n", "versions": [{"version": "v1", "created": "Fri, 9 Feb 2018 10:37:08 GMT"}, {"version": "v2", "created": "Thu, 22 Nov 2018 15:52:05 GMT"}], "update_date": "2018-11-26", "authors_parsed": [["Elzanaty", "Ahmed", ""], ["Giorgetti", "Andrea", ""], ["Chiani", "Marco", ""]]}, {"id": "1802.03286", "submitter": "Rebekka Burkholz", "authors": "Rebekka Burkholz, Hans J. Herrmann, Frank Schweitzer", "title": "Explicit size distributions of failure cascades redefine systemic risk\n  on finite networks", "comments": "systemic risk, finite size effects, cascades, networks", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph math.ST q-fin.RM stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How big is the risk that a few initial failures of nodes in a network amplify\nto large cascades that span a substantial share of all nodes? Predicting the\nfinal cascade size is critical to ensure the functioning of a system as a\nwhole. Yet, this task is hampered by uncertain or changing parameters and\nmissing information. In infinitely large networks, the average cascade size can\noften be well estimated by established approaches building on local tree\napproximations and mean field approximations. Yet, as we demonstrate, in finite\nnetworks, this average does not even need to be a likely outcome. Instead, we\nfind broad and even bimodal cascade size distributions. This phenomenon\npersists for system sizes up to $10^{7}$ and different cascade models, i.e. it\nis relevant for most real systems. To show this, we derive explicit closed-form\nsolutions for the full probability distribution of the final cascade size. We\nfocus on two topological limit cases, the complete network representing a dense\nnetwork with a very narrow degree distribution, and the star network\nrepresenting a sparse network with a inhomogeneous degree distribution. Those\ntopologies are of great interest, as they either minimize or maximize the\naverage cascade size and are common motifs in many real world networks.\n", "versions": [{"version": "v1", "created": "Thu, 8 Feb 2018 09:55:26 GMT"}], "update_date": "2018-02-12", "authors_parsed": [["Burkholz", "Rebekka", ""], ["Herrmann", "Hans J.", ""], ["Schweitzer", "Frank", ""]]}, {"id": "1802.03425", "submitter": "Kolyan Ray", "authors": "Kolyan Ray, Johannes Schmidt-Hieber", "title": "Asymptotic nonequivalence of density estimation and Gaussian white noise\n  for small densities", "comments": "20 pages, 1 figure. Some results from an early version of\n  arXiv:1608.01824 are now found here", "journal-ref": "Ann. Inst. H. Poincare Probab. Statist. 55 (2019), no. 4,\n  2195-2208", "doi": "10.1214/18-AIHP946", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well-known that density estimation on the unit interval is\nasymptotically equivalent to a Gaussian white noise experiment, provided the\ndensities are sufficiently smooth and uniformly bounded away from zero. We show\nthat a uniform lower bound, whose size we sharply characterize, is in general\nnecessary for asymptotic equivalence to hold.\n", "versions": [{"version": "v1", "created": "Fri, 9 Feb 2018 19:37:50 GMT"}, {"version": "v2", "created": "Tue, 6 Nov 2018 11:30:54 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Ray", "Kolyan", ""], ["Schmidt-Hieber", "Johannes", ""]]}, {"id": "1802.04230", "submitter": "Olivier Collier", "authors": "La\\\"etitia Comminges, Olivier Collier, Mohamed Ndaoud and Alexandre B.\n  Tsybakov", "title": "Adaptive robust estimation in sparse vector model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For the sparse vector model, we consider estimation of the target vector, of\nits L2-norm and of the noise variance. We construct adaptive estimators and\nestablish the optimal rates of adaptive estimation when adaptation is\nconsidered with respect to the triplet \"noise level - noise distribution -\nsparsity\". We consider classes of noise distributions with polynomially and\nexponentially decreasing tails as well as the case of Gaussian noise. The\nobtained rates turn out to be different from the minimax non-adaptive rates\nwhen the triplet is known. A crucial issue is the ignorance of the noise\nvariance. Moreover, knowing or not knowing the noise distribution can also\ninfluence the rate. For example, the rates of estimation of the noise variance\ncan differ depending on whether the noise is Gaussian or sub-Gaussian without a\nprecise knowledge of the distribution. Estimation of noise variance in our\nsetting can be viewed as an adaptive variant of robust estimation of scale in\nthe contamination model, where instead of fixing the \"nominal\" distribution in\nadvance, we assume that it belongs to some class of distributions.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 18:23:40 GMT"}, {"version": "v2", "created": "Mon, 4 Jun 2018 06:47:24 GMT"}, {"version": "v3", "created": "Wed, 17 Apr 2019 07:54:10 GMT"}, {"version": "v4", "created": "Mon, 2 Mar 2020 20:45:22 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Comminges", "La\u00ebtitia", ""], ["Collier", "Olivier", ""], ["Ndaoud", "Mohamed", ""], ["Tsybakov", "Alexandre B.", ""]]}, {"id": "1802.04308", "submitter": "Olivier Catoni", "authors": "Olivier Catoni and Ilaria Giulini", "title": "Dimension-free PAC-Bayesian bounds for the estimation of the mean of a\n  random vector", "comments": "31st Conference on Neural Information Processing Systems (NIPS 2017),\n  Long Beach, CA, USA. Selected for oral presentation in the NIPS 2017 workshop\n  \"(Almost) 50 Shades of Bayesian Learning: PAC-Bayesian trends and insights\",\n  December 9, 2017. Workshop URL :\n  https://bguedj.github.io/nips2017/50shadesbayesian.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a new estimator of the mean of a random vector,\ncomputed by applying some threshold function to the norm. Non asymptotic\ndimension-free almost sub-Gaussian bounds are proved under weak moment\nassumptions, using PAC-Bayesian inequalities.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 19:07:16 GMT"}], "update_date": "2018-02-14", "authors_parsed": [["Catoni", "Olivier", ""], ["Giulini", "Ilaria", ""]]}, {"id": "1802.04397", "submitter": "Bryon Aragam", "authors": "Bryon Aragam, Chen Dan, Eric P. Xing, Pradeep Ravikumar", "title": "Identifiability of Nonparametric Mixture Models and Bayes Optimal\n  Clustering", "comments": "35 pages, to appear in the Annals of Statistics", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.AI cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by problems in data clustering, we establish general conditions\nunder which families of nonparametric mixture models are identifiable, by\nintroducing a novel framework involving clustering overfitted \\emph{parametric}\n(i.e. misspecified) mixture models. These identifiability conditions generalize\nexisting conditions in the literature, and are flexible enough to include for\nexample mixtures of Gaussian mixtures. In contrast to the recent literature on\nestimating nonparametric mixtures, we allow for general nonparametric mixture\ncomponents, and instead impose regularity assumptions on the underlying mixing\nmeasure. As our primary application, we apply these results to partition-based\nclustering, generalizing the notion of a Bayes optimal partition from classical\nparametric model-based clustering to nonparametric settings. Furthermore, this\nframework is constructive so that it yields a practical algorithm for learning\nidentified mixtures, which is illustrated through several examples on real\ndata. The key conceptual device in the analysis is the convex, metric geometry\nof probability measures on metric spaces and its connection to the Wasserstein\nconvergence of mixing measures. The result is a flexible framework for\nnonparametric clustering with formal consistency guarantees.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 23:53:52 GMT"}, {"version": "v2", "created": "Sun, 22 Apr 2018 16:20:25 GMT"}, {"version": "v3", "created": "Mon, 26 Nov 2018 20:31:51 GMT"}, {"version": "v4", "created": "Tue, 18 Feb 2020 03:52:29 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Aragam", "Bryon", ""], ["Dan", "Chen", ""], ["Xing", "Eric P.", ""], ["Ravikumar", "Pradeep", ""]]}, {"id": "1802.04472", "submitter": "Liudmila Ostroumova Prokhorenkova", "authors": "Liudmila Prokhorenkova and Alexey Tikhonov", "title": "Community Detection through Likelihood Optimization: In Search of a\n  Sound Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Community detection is one of the most important problems in network\nanalysis. Among many algorithms proposed for this task, methods based on\nstatistical inference are of particular interest: they are mathematically sound\nand were shown to provide partitions of good quality. Statistical inference\nmethods are based on fitting some random graph model (a.k.a. null model) to the\nobserved network by maximizing the likelihood. The choice of this model is\nextremely important and is the main focus of the current study. We provide an\nextensive theoretical and empirical analysis to compare several models: the\nwidely used planted partition model, recently proposed degree-corrected\nmodification of this model, and a new null model having some desirable\nstatistical properties. We also develop and compare two likelihood optimization\nalgorithms suitable for the models under consideration. An extensive empirical\nanalysis on a variety of datasets shows, in particular, that the new model is\nthe best one for describing most of the considered real-world complex networks\naccording to the likelihood of observed graph structures.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 06:12:30 GMT"}, {"version": "v2", "created": "Wed, 11 Jul 2018 07:55:49 GMT"}, {"version": "v3", "created": "Fri, 22 Feb 2019 11:47:03 GMT"}], "update_date": "2019-02-25", "authors_parsed": [["Prokhorenkova", "Liudmila", ""], ["Tikhonov", "Alexey", ""]]}, {"id": "1802.04483", "submitter": "Harsha K V", "authors": "Harsha K V, Alladi Subramanyam", "title": "Some Information Inequalities for Statistical Inference", "comments": "Some of the contents of this paper is accepted for a contributed talk\n  in The Ninth International Conference on Guided Self-Organisation (GSO-2018:\n  Information Geometry and Statistical Physics to be held in Max Planck\n  Institute for Mathematics in the Sciences,Leipzig, Germany during March 26 -\n  28, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we first describe the generalized notion of Cramer-Rao lower\nbound obtained by Naudts (2004) using two families of probability density\nfunctions, the original model and an escort model. We reinterpret the results\nin Naudts (2004) from a statistical point of view and obtain some interesting\nexamples in which this bound is attained. Further we obtain information\ninequalities which generalize the classical Bhattacharyya bounds in both\nregular and non-regular cases.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 06:59:25 GMT"}], "update_date": "2018-02-14", "authors_parsed": [["K", "Harsha", "V"], ["Subramanyam", "Alladi", ""]]}, {"id": "1802.04497", "submitter": "Salimeh Yasaei Sekeh", "authors": "Salimeh Yasaei Sekeh, Brandon Oselio, Alfred O. Hero", "title": "A Dimension-Independent discriminant between distributions", "comments": "5 pages, 5 figures, ICASSP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Henze-Penrose divergence is a non-parametric divergence measure that can be\nused to estimate a bound on the Bayes error in a binary classification problem.\nIn this paper, we show that a cross-match statistic based on optimal weighted\nmatching can be used to directly estimate Henze-Penrose divergence. Unlike an\nearlier approach based on the Friedman-Rafsky minimal spanning tree statistic,\nthe proposed method is dimension-independent. The new approach is evaluated\nusing simulation and applied to real datasets to obtain Bayes error estimates.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 08:02:07 GMT"}], "update_date": "2018-02-14", "authors_parsed": [["Sekeh", "Salimeh Yasaei", ""], ["Oselio", "Brandon", ""], ["Hero", "Alfred O.", ""]]}, {"id": "1802.04511", "submitter": "Eliana Duarte", "authors": "Eliana Duarte, Christiane G\\\"orgen", "title": "Equations defining probability tree models", "comments": "22 pages, 4 figures", "journal-ref": "Journal of Symbolic Computation 2020", "doi": "10.1016/j.jsc.2019.04.001", "report-no": null, "categories": "math.ST math.AC math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Coloured probability tree models are statistical models coding conditional\nindependence between events depicted in a tree graph. They are more general\nthan the very important class of context-specific Bayesian networks. In this\npaper, we study the algebraic properties of their ideal of model invariants.\nThe generators of this ideal can be easily read from the tree graph and have a\nstraightforward interpretation in terms of the underlying model: they are\ndifferences of odds ratios coming from conditional probabilities. One of the\nkey findings in this analysis is that the tree is a convenient tool for\nunderstanding the exact algebraic way in which the sum-to-1 conditions on the\nparameter space translate into the sum-to-one conditions on the joint\nprobabilities of the statistical model. This enables us to identify necessary\nand sufficient graphical conditions for a staged tree model to be a toric\nvariety intersected with a probability simplex.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 09:09:03 GMT"}, {"version": "v2", "created": "Mon, 15 Jun 2020 07:01:05 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Duarte", "Eliana", ""], ["G\u00f6rgen", "Christiane", ""]]}, {"id": "1802.04700", "submitter": "Yuping Song", "authors": "Yuping Song", "title": "On Double Smoothed Volatility Estimation of Potentially Nonstationary\n  Jump-Diffusion Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present the double smoothed nonparametric approach for\ninfinitesimal conditional volatility of jump-diffusion model based on high\nfrequency data. Under certain minimal conditions, we obtain the strong\nconsistency and asymptotic normality for the estimator as the time span $T\n\\rightarrow \\infty$ and the sample interval $\\Delta_{n} \\rightarrow 0.$ The\nprocedure and asymptotic behavior can be applied for both null Harris recurrent\nand positive Harris recurrent processes.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 16:12:34 GMT"}], "update_date": "2018-02-14", "authors_parsed": [["Song", "Yuping", ""]]}, {"id": "1802.04774", "submitter": "Carey Caginalp", "authors": "Carey Caginalp and Gunduz Caginalp", "title": "Asset Price Volatility and Price Extrema", "comments": "23 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.MF math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The relationship between price volatilty and a market extremum is examined\nusing a fundamental economics model of supply and demand. By examining\nrandomness through a microeconomic setting, we obtain the implications of\nrandomness in the supply and demand, rather than assuming that price has\nrandomness on an empirical basis. Within a very general setting the volatility\nhas an extremum that precedes the extremum of the price. A key issue is that\nrandomness arises from the supply and demand, and the variance in the\nstochastic differential equation govening the logarithm of price must reflect\nthis. Analogous results are obtained by further assuming that the supply and\ndemand are dependent on the deviation from fundamental value of the asset.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 18:07:43 GMT"}, {"version": "v2", "created": "Sat, 28 Jul 2018 18:15:07 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Caginalp", "Carey", ""], ["Caginalp", "Gunduz", ""]]}, {"id": "1802.04778", "submitter": "Carey Caginalp", "authors": "Carey Caginalp and Gunduz Caginalp", "title": "The Quotient of Normal Random Variables And Application to Asset Price\n  Fat Tails", "comments": "21 pages", "journal-ref": null, "doi": "10.1016/j.physa.2018.02.077", "report-no": null, "categories": "q-fin.MF math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The quotient of random variables with normal distributions is examined and\nproven to have have power law decay, with density $f\\left( x\\right) \\simeq\nf_{0}x^{-2}$, with the coefficient depending on the means and variances of the\nnumerator and denominator and their correlation. We also obtain the conditional\nprobability densities for each of the four quadrants given by the signs of the\nnumerator and denominator for arbitrary correlation $\\rho \\in\\lbrack-1,1).$ For\n$\\rho=-1$ we obtain a particularly simple closed form solution for all $x\\in$\n$\\mathbb{R}$. The results are applied to a basic issue in economics and\nfinance, namely the density of relative price changes. Classical finance\nstipulates a normal distribution of relative price changes, though empirical\nstudies suggest a power law at the tail end. By considering the supply and\ndemand in a basic price change model, we prove that the relative price change\nhas density that decays with an $x^{-2}$ power law. Various parameter limits\nare established.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 18:14:27 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Caginalp", "Carey", ""], ["Caginalp", "Gunduz", ""]]}, {"id": "1802.04784", "submitter": "Zoltan Szabo", "authors": "Matthieu Lerasle, Zoltan Szabo, Timothee Mathieu, Guillaume Lecue", "title": "MONK -- Outlier-Robust Mean Embedding Estimation by Median-of-Means", "comments": "ICML-2019: camera-ready paper. Code:\n  https://bitbucket.org/TimotheeMathieu/monk-mmd", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT math.FA math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mean embeddings provide an extremely flexible and powerful tool in machine\nlearning and statistics to represent probability distributions and define a\nsemi-metric (MMD, maximum mean discrepancy; also called N-distance or energy\ndistance), with numerous successful applications. The representation is\nconstructed as the expectation of the feature map defined by a kernel. As a\nmean, its classical empirical estimator, however, can be arbitrary severely\naffected even by a single outlier in case of unbounded features. To the best of\nour knowledge, unfortunately even the consistency of the existing few\ntechniques trying to alleviate this serious sensitivity bottleneck is unknown.\nIn this paper, we show how the recently emerged principle of median-of-means\ncan be used to design estimators for kernel mean embedding and MMD with\nexcessive resistance properties to outliers, and optimal sub-Gaussian deviation\nbounds under mild assumptions.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 18:35:25 GMT"}, {"version": "v2", "created": "Thu, 15 Feb 2018 12:41:04 GMT"}, {"version": "v3", "created": "Wed, 17 Oct 2018 16:40:19 GMT"}, {"version": "v4", "created": "Wed, 15 May 2019 20:12:22 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Lerasle", "Matthieu", ""], ["Szabo", "Zoltan", ""], ["Mathieu", "Timothee", ""], ["Lecue", "Guillaume", ""]]}, {"id": "1802.04838", "submitter": "Ben Mark", "authors": "Benjamin Mark, Garvesh Raskutti, Rebecca Willett", "title": "Network Estimation from Point Process Data", "comments": "Submitted to IEEE Transactions on Information Theory", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider observing a collection of discrete events within a network that\nreflect how network nodes influence one another. Such data are common in spike\ntrains recorded from biological neural networks, interactions within a social\nnetwork, and a variety of other settings. Data of this form may be modeled as\nself-exciting point processes, in which the likelihood of future events depends\non the past events. This paper addresses the problem of estimating\nself-excitation parameters and inferring the underlying functional network\nstructure from self-exciting point process data. Past work in this area was\nlimited by strong assumptions which are addressed by the novel approach here.\nSpecifically, in this paper we (1) incorporate saturation in a point process\nmodel which both ensures stability and models non-linear thresholding effects;\n(2) impose general low-dimensional structural assumptions that include\nsparsity, group sparsity and low-rankness that allows bounds to be developed in\nthe high-dimensional setting; and (3) incorporate long-range memory effects\nthrough moving average and higher-order auto-regressive components. Using our\ngeneral framework, we provide a number of novel theoretical guarantees for\nhigh-dimensional self-exciting point processes that reflect the role played by\nthe underlying network structure and long-term memory. We also provide\nsimulations and real data examples to support our methodology and main results.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 20:06:07 GMT"}], "update_date": "2018-02-15", "authors_parsed": [["Mark", "Benjamin", ""], ["Raskutti", "Garvesh", ""], ["Willett", "Rebecca", ""]]}, {"id": "1802.04925", "submitter": "Yuping Song", "authors": "Yuping Song, Ying Chen and Zhouwei Wang", "title": "Bias Correction Estimation for Continuous-Time Asset Return Model with\n  Jumps", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, local linear estimators are adapted for the unknown\ninfinitesimal coefficients associated with continuous-time asset return model\nwith jumps, which can correct the bias automatically due to their simple bias\nrepresentation. The integrated diffusion models with jumps, especially infinite\nactivity jumps are mainly investigated. In addition, under mild conditions, the\nweak consistency and asymptotic normality is provided through the conditional\nLindeberg theorem. Furthermore, our method presents advantages in bias\ncorrection through simulation whether jumps belong to the finite activity case\nor infinite activity case. Finally, the estimators are illustrated empirically\nthrough the returns for stock index under five-minute high sampling frequency\nfor real application.\n", "versions": [{"version": "v1", "created": "Wed, 14 Feb 2018 02:00:52 GMT"}], "update_date": "2018-02-15", "authors_parsed": [["Song", "Yuping", ""], ["Chen", "Ying", ""], ["Wang", "Zhouwei", ""]]}, {"id": "1802.04943", "submitter": "Anit Kumar Sahu", "authors": "Anit Kumar Sahu, Dusan Jakovetic and Soummya Kar", "title": "$\\mathcal{CIRFE}$: A Distributed Random Fields Estimator", "comments": "30 pages. Submitted for journal publication. Initial Submission: Feb\n  2018, Revised: June 2018", "journal-ref": null, "doi": "10.1109/TSP.2018.2863646", "report-no": null, "categories": "math.OC cs.IT math.IT math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a communication efficient distributed algorithm,\n$\\mathcal{CIRFE}$ of the \\emph{consensus}+\\emph{innovations} type, to estimate\na high-dimensional parameter in a multi-agent network, in which each agent is\ninterested in reconstructing only a few components of the parameter. This\nproblem arises for example when monitoring the high-dimensional distributed\nstate of a large-scale infrastructure with a network of limited capability\nsensors and where each sensor is tasked with estimating some local components\nof the state. At each observation sampling epoch, each agent updates its local\nestimate of the parameter components in its interest set by simultaneously\nprocessing the latest locally sensed information~(\\emph{innovations}) and the\nparameter estimates from agents~(\\emph{consensus}) in its communication\nneighborhood given by a time-varying possibly sparse graph. Under minimal\nconditions on the inter-agent communication network and the sensing models,\nalmost sure convergence of the estimate sequence at each agent to the\ncomponents of the true parameter in its interest set is established.\nFurthermore, the paper establishes the performance of $\\mathcal{CIRFE}$ in\nterms of asymptotic covariance of the estimate sequences and specifically\ncharacterizes the dependencies of the component wise asymptotic covariance in\nterms of the number of agents tasked with estimating it. Finally, simulation\nexperiments demonstrate the efficacy of $\\mathcal{CIRFE}$.\n", "versions": [{"version": "v1", "created": "Wed, 14 Feb 2018 03:52:01 GMT"}, {"version": "v2", "created": "Mon, 11 Jun 2018 21:57:10 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Sahu", "Anit Kumar", ""], ["Jakovetic", "Dusan", ""], ["Kar", "Soummya", ""]]}, {"id": "1802.05015", "submitter": "Sophie Hautphenne", "authors": "Anthony C. Davison, Sophie Hautphenne, Andrea Kraus", "title": "Parameter estimation for discretely-observed linear birth-and-death\n  processes", "comments": null, "journal-ref": null, "doi": "10.1111/biom.13282", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Birth-and-death processes are widely used to model the development of\nbiological populations. Although they are relatively simple models, their\nparameters can be challenging to estimate, because the likelihood can become\nnumerically unstable when data arise from the most common sampling schemes,\nsuch as annual population censuses. Simple estimators may be based on an\nembedded Galton-Watson process, but this presupposes that the observation times\nare equi-spaced. We estimate the birth, death, and growth rates of a linear\nbirth-and-death process whose population size is periodically observed via an\nembedded Galton-Watson process, and by maximizing a saddlepoint approximation\nto the likelihood. We show that a Gaussian approximation to the\nsaddlepoint-based likelihood connects the two approaches, we establish\nconsistency and asymptotic normality of quasi-likelihood estimators, compare\nour estimators on some numerical examples, and apply our results to census data\nfor two endangered bird populations and the H1N1 influenza pandemic.\n", "versions": [{"version": "v1", "created": "Wed, 14 Feb 2018 10:06:57 GMT"}, {"version": "v2", "created": "Tue, 9 Oct 2018 07:43:36 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Davison", "Anthony C.", ""], ["Hautphenne", "Sophie", ""], ["Kraus", "Andrea", ""]]}, {"id": "1802.05104", "submitter": "Celine Duval", "authors": "C\\'eline Duval (MAP5 - UMR 8145), Johanna Kappus", "title": "An adaptive procedure for Fourier estimators: illustration to\n  deconvolution and decompounding", "comments": null, "journal-ref": null, "doi": null, "report-no": "MAP5 2018-04", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new procedure to select the optimal cutoff parameter for\nFourier density estimators that leads to adaptive rate optimal estimators, up\nto a logarithmic factor. This adaptive procedure applies for different inverse\nproblems. We illustrate it on two classical examples: deconvolution and\ndecompounding, i.e. non-parametric estimation of the jump density of a compound\nPoisson process from the observation of n increments of length $\\Delta$ > 0.\nFor this latter example, we first build an estimator for which we provide an\nupper bound for its L 2-risk that is valid simultaneously for sampling rates\n$\\Delta$ that can vanish, $\\Delta$ := $\\Delta$ n $\\rightarrow$ 0, can be fixed,\n$\\Delta$ n $\\rightarrow$ $\\Delta$ 0 > 0 or can get large, $\\Delta$ n\n$\\rightarrow$ $\\infty$ slowly. This last result is new and presents interest on\nits own. Then, we show that the adaptive procedure we present leads to an\nadaptive and rate optimal (up to a logarithmic factor) estimator of the jump\ndensity.\n", "versions": [{"version": "v1", "created": "Wed, 14 Feb 2018 14:17:33 GMT"}], "update_date": "2018-02-15", "authors_parsed": [["Duval", "C\u00e9line", "", "MAP5 - UMR 8145"], ["Kappus", "Johanna", ""]]}, {"id": "1802.05218", "submitter": "Katharina Hees", "authors": "Katharina Hees, Smarak Nayak and Peter Straka", "title": "Statistical Inference for inter-arrival times of extreme events in\n  bursty time series", "comments": "24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many complex systems studied in statistical physics, inter-arrival times\nbetween events such as solar flares, trades and neuron voltages follow a\nheavy-tailed distribution. The set of event times is fractal-like, being dense\nin some time windows and empty in others, a phenomenon which has been dubbed\n\"bursty\". A new model for the inter-exceedance times of events above high\nthresholds is proposed. For high thresholds and infinite-mean waiting times, it\nis shown that the times between threshold crossings are Mittag-Leffler\ndistributed, and thus form a \"fractional Poisson Process\" which generalizes the\nstandard Poisson Process of threshold exceedances. Graphical means of\nestimating model parameters and assessing model fit are provided. The inference\nmethod is applied to an empirical bursty time series, and it is shown how the\nmemory of the Mittag-Leffler distribution affects prediction of the time until\nthe next extreme event.\"\n", "versions": [{"version": "v1", "created": "Wed, 14 Feb 2018 17:11:53 GMT"}, {"version": "v2", "created": "Sat, 17 Feb 2018 22:12:00 GMT"}, {"version": "v3", "created": "Wed, 25 Apr 2018 07:24:02 GMT"}, {"version": "v4", "created": "Sat, 28 Apr 2018 10:36:04 GMT"}, {"version": "v5", "created": "Tue, 15 Sep 2020 09:27:05 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Hees", "Katharina", ""], ["Nayak", "Smarak", ""], ["Straka", "Peter", ""]]}, {"id": "1802.05333", "submitter": "Yeonwoo Rho", "authors": "Yeonwoo Rho and Xiaofeng Shao", "title": "Bootstrap-Assisted Unit Root Testing With Piecewise Locally Stationary\n  Errors", "comments": "This paper has been accepted for publication and will appear in a\n  revised form, subsequent to editorial input by Cambridge University Press, in\n  Econometric Theory", "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In unit root testing, a piecewise locally stationary process is adopted to\naccommodate nonstationary errors that can have both smooth and abrupt changes\nin second- or higher-order properties. Under this framework, the limiting null\ndistributions of the conventional unit root test statistics are derived and\nshown to contain a number of unknown parameters. To circumvent the difficulty\nof direct consistent estimation, we propose to use the dependent wild bootstrap\nto approximate the non-pivotal limiting null distributions and provide a\nrigorous theoretical justification for bootstrap consistency. The proposed\nmethod is compared through finite sample simulations with the recolored wild\nbootstrap procedure, which was developed for errors that follow a\nheteroscedastic linear process. Further, a combination of autoregressive sieve\nrecoloring with the dependent wild bootstrap is shown to perform well. The\nvalidity of the dependent wild bootstrap in a nonstationary setting is\ndemonstrated for the first time, showing the possibility of extensions to other\ninference problems associated with locally stationary processes.\n", "versions": [{"version": "v1", "created": "Wed, 14 Feb 2018 22:00:23 GMT"}], "update_date": "2018-02-16", "authors_parsed": [["Rho", "Yeonwoo", ""], ["Shao", "Xiaofeng", ""]]}, {"id": "1802.05339", "submitter": "Andrew W. Steiner", "authors": "Andrew W. Steiner", "title": "Two- and Multi-dimensional Curve Fitting using Bayesian Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.data-an astro-ph.IM math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fitting models to data using Bayesian inference is quite common, but when\neach point in parameter space gives a curve, fitting the curve to a data set\nrequires new nuisance parameters, which specify the metric embedding the\none-dimensional curve into the higher-dimensional space occupied by the data. A\ngeneric formalism for curve fitting in the context of Bayesian inference is\ndeveloped which shows how the aforementioned metric arises. The result is a\nnatural generalization of previous works, and is compared to oft-used\nfrequentist approaches and similar Bayesian techniques.\n", "versions": [{"version": "v1", "created": "Wed, 14 Feb 2018 22:16:39 GMT"}, {"version": "v2", "created": "Thu, 22 Feb 2018 17:38:11 GMT"}], "update_date": "2018-02-23", "authors_parsed": [["Steiner", "Andrew W.", ""]]}, {"id": "1802.05635", "submitter": "Kweku Abraham", "authors": "Kweku Abraham", "title": "Nonparametric Bayesian posterior contraction rates for scalar diffusions\n  with high-frequency data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider inference in the scalar diffusion model\n$dX_t=b(X_t)dt+\\sigma(X_t)dW_t$ with discrete data $(X_{j\\Delta_n})_{0\\leq j\n\\leq n}$, $n\\to \\infty,~\\Delta_n\\to 0$ and periodic coefficients. For $\\sigma$\ngiven, we prove a general theorem detailing conditions under which Bayesian\nposteriors will contract in $L^2$-distance around the true drift function $b_0$\nat the frequentist minimax rate (up to logarithmic factors) over Besov\nsmoothness classes. We exhibit natural nonparametric priors which satisfy our\nconditions. Our results show that the Bayesian method adapts both to an unknown\nsampling regime and to unknown smoothness.\n", "versions": [{"version": "v1", "created": "Thu, 15 Feb 2018 16:11:54 GMT"}, {"version": "v2", "created": "Thu, 23 Aug 2018 14:27:30 GMT"}], "update_date": "2018-08-24", "authors_parsed": [["Abraham", "Kweku", ""]]}, {"id": "1802.05650", "submitter": "Frank Konietschke", "authors": "Edgar Brunner, Frank Konietschke, Arne C. Bathke, Markus Pauly", "title": "Ranks and Pseudo-Ranks - Paradoxical Results of Rank Tests -", "comments": "19 pages, 0 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rank-based inference methods are applied in various disciplines, typically\nwhen procedures relying on standard normal theory are not justifiable, for\nexample when data are not symmetrically distributed, contain outliers, or\nresponses are even measured on ordinal scales. Various specific rank-based\nmethods have been developed for two and more samples, and also for general\nfactorial designs (e.g., Kruskal-Wallis test, Jonckheere-Terpstra test). It is\nthe aim of the present paper (1) to demonstrate that traditional\nrank-procedures for several samples or general factorial designs may lead to\nparadoxical results in case of unbalanced samples, (2) to explain why this is\nthe case, and (3) to provide a way to overcome these disadvantages of\ntraditional rankbased inference. Theoretical investigations show that the\nparadoxical results can be explained by carefully considering the\nnon-centralities of the test statistics which may be non-zero for the\ntraditional tests in unbalanced designs. These non-centralities may even become\narbitrarily large for increasing sample sizes in the unbalanced case. A simple\nsolution is the use of socalled pseudo-ranks instead of ranks. As a special\ncase, we illustrate the effects in sub-group analyses which are often used when\ndealing with rare diseases.\n", "versions": [{"version": "v1", "created": "Thu, 15 Feb 2018 16:43:38 GMT"}], "update_date": "2018-02-16", "authors_parsed": [["Brunner", "Edgar", ""], ["Konietschke", "Frank", ""], ["Bathke", "Arne C.", ""], ["Pauly", "Markus", ""]]}, {"id": "1802.05801", "submitter": "Arun Kuchibhotla", "authors": "Arun Kumar Kuchibhotla, Lawrence D. Brown, Andreas Buja, Edward I.\n  George and Linda Zhao", "title": "Uniform-in-Submodel Bounds for Linear Regression in a Model Free\n  Framework", "comments": "Forthcoming at Econometric Theory", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For the last two decades, high-dimensional data and methods have proliferated\nthroughout the literature. Yet, the classical technique of linear regression\nhas not lost its usefulness in applications. In fact, many high-dimensional\nestimation techniques can be seen as variable selection that leads to a smaller\nset of variables (a ``sub-model'') where classical linear regression applies.\nWe analyze linear regression estimators resulting from model-selection by\nproving estimation error and linear representation bounds uniformly over sets\nof submodels. Based on deterministic inequalities, our results provide ``good''\nrates when applied to both independent and dependent data. These results are\nuseful in meaningfully interpreting the linear regression estimator obtained\nafter exploring and reducing the variables and also in justifying post\nmodel-selection inference. All results are derived under no model assumptions\nand are non-asymptotic in nature.\n", "versions": [{"version": "v1", "created": "Thu, 15 Feb 2018 23:37:01 GMT"}, {"version": "v2", "created": "Fri, 22 Jun 2018 01:16:30 GMT"}, {"version": "v3", "created": "Mon, 17 May 2021 14:55:58 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Kuchibhotla", "Arun Kumar", ""], ["Brown", "Lawrence D.", ""], ["Buja", "Andreas", ""], ["George", "Edward I.", ""], ["Zhao", "Linda", ""]]}, {"id": "1802.05975", "submitter": "Vincent Rivoirard", "authors": "Sophie Donnet (MIA-Paris), Vincent Rivoirard (CEREMADE), Judith\n  Rousseau (CEREMADE)", "title": "Nonparametric Bayesian estimation of multivariate Hawkes processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies nonparametric estimation of parameters of multivariate\nHawkes processes. We consider the Bayesian setting and derive posterior\nconcentration rates. First rates are derived for L1-metrics for stochastic\nintensities of the Hawkes process. We then deduce rates for the L1-norm of\ninteractions functions of the process. Our results are exemplified by using\npriors based on piecewise constant functions, with regular or random partitions\nand priors based on mixtures of Betas distributions. Numerical illustrations\nare then proposed with in mind applications for inferring functional\nconnec-tivity graphs of neurons.\n", "versions": [{"version": "v1", "created": "Fri, 16 Feb 2018 15:22:01 GMT"}, {"version": "v2", "created": "Mon, 26 Mar 2018 07:44:09 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Donnet", "Sophie", "", "MIA-Paris"], ["Rivoirard", "Vincent", "", "CEREMADE"], ["Rousseau", "Judith", "", "CEREMADE"]]}, {"id": "1802.06054", "submitter": "James Sharpnack", "authors": "James Sharpnack", "title": "Learning Patterns for Detection with Multiscale Scan Statistics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT math.IT stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses detecting anomalous patterns in images, time-series, and\ntensor data when the location and scale of the pattern is unknown a priori. The\nmultiscale scan statistic convolves the proposed pattern with the image at\nvarious scales and returns the maximum of the resulting tensor. Scale corrected\nmultiscale scan statistics apply different standardizations at each scale, and\nthe limiting distribution under the null hypothesis---that the data is only\nnoise---is known for smooth patterns. We consider the problem of simultaneously\nlearning and detecting the anomalous pattern from a dictionary of smooth\npatterns and a database of many tensors. To this end, we show that the\nmultiscale scan statistic is a subexponential random variable, and prove a\nchaining lemma for standardized suprema, which may be of independent interest.\nThen by averaging the statistics over the database of tensors we can learn the\npattern and obtain Bernstein-type error bounds. We will also provide a\nconstruction of an $\\epsilon$-net of the location and scale parameters,\nproviding a computationally tractable approximation with similar error bounds.\n", "versions": [{"version": "v1", "created": "Fri, 16 Feb 2018 17:59:11 GMT"}, {"version": "v2", "created": "Thu, 1 Mar 2018 17:50:31 GMT"}, {"version": "v3", "created": "Thu, 21 Jun 2018 05:07:15 GMT"}], "update_date": "2018-06-22", "authors_parsed": [["Sharpnack", "James", ""]]}, {"id": "1802.06093", "submitter": "Phil Long", "authors": "Peter L. Bartlett, David P. Helmbold and Philip M. Long", "title": "Gradient descent with identity initialization efficiently learns\n  positive definite linear transformations by deep residual networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE math.OC math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze algorithms for approximating a function $f(x) = \\Phi x$ mapping\n$\\Re^d$ to $\\Re^d$ using deep linear neural networks, i.e. that learn a\nfunction $h$ parameterized by matrices $\\Theta_1,...,\\Theta_L$ and defined by\n$h(x) = \\Theta_L \\Theta_{L-1} ... \\Theta_1 x$. We focus on algorithms that\nlearn through gradient descent on the population quadratic loss in the case\nthat the distribution over the inputs is isotropic.\n  We provide polynomial bounds on the number of iterations for gradient descent\nto approximate the least squares matrix $\\Phi$, in the case where the initial\nhypothesis $\\Theta_1 = ... = \\Theta_L = I$ has excess loss bounded by a small\nenough constant. On the other hand, we show that gradient descent fails to\nconverge for $\\Phi$ whose distance from the identity is a larger constant, and\nwe show that some forms of regularization toward the identity in each layer do\nnot help.\n  If $\\Phi$ is symmetric positive definite, we show that an algorithm that\ninitializes $\\Theta_i = I$ learns an $\\epsilon$-approximation of $f$ using a\nnumber of updates polynomial in $L$, the condition number of $\\Phi$, and\n$\\log(d/\\epsilon)$. In contrast, we show that if the least squares matrix\n$\\Phi$ is symmetric and has a negative eigenvalue, then all members of a class\nof algorithms that perform gradient descent with identity initialization, and\noptionally regularize toward the identity in each layer, fail to converge.\n  We analyze an algorithm for the case that $\\Phi$ satisfies $u^{\\top} \\Phi u >\n0$ for all $u$, but may not be symmetric. This algorithm uses two regularizers:\none that maintains the invariant $u^{\\top} \\Theta_L \\Theta_{L-1} ... \\Theta_1 u\n> 0$ for all $u$, and another that \"balances\" $\\Theta_1, ..., \\Theta_L$ so that\nthey have the same singular values.\n", "versions": [{"version": "v1", "created": "Fri, 16 Feb 2018 19:24:29 GMT"}, {"version": "v2", "created": "Sat, 24 Feb 2018 15:48:00 GMT"}, {"version": "v3", "created": "Thu, 14 Jun 2018 16:10:40 GMT"}, {"version": "v4", "created": "Mon, 18 Jun 2018 16:46:26 GMT"}], "update_date": "2018-06-19", "authors_parsed": [["Bartlett", "Peter L.", ""], ["Helmbold", "David P.", ""], ["Long", "Philip M.", ""]]}, {"id": "1802.06173", "submitter": "Jos\\'e A. D\\'iaz-Garc\\'ia", "authors": "Jose A. Diaz-Garcia and Francisco J. Caro-Lopera", "title": "Matrix variate Birnbaum-Saunders distribution under elliptical models", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper derives the elliptical matrix variate version of the well known\nunivariate Birnbaum and Saunders distribution. A generalisation based on a\nmatrix transformation is proposed, instead of the independent element by\nelement representation of the Gaussian univariate version of 1969. New results\non Jacobians were needed to derived the matrix variate distribution. A number\nof special cases are studied and some basic properties are found. Finally, an\nexample based on real data of two populations is provided. The maximum\nlikelihood estimates are found for a number of matrix variate generalised\nBirnbaum-Saunders distributions based on Kotz models. A comparison with the\nGaussian kernel is also given by using a modified BIC criterion.\n", "versions": [{"version": "v1", "created": "Sat, 17 Feb 2018 02:03:23 GMT"}, {"version": "v2", "created": "Tue, 17 Dec 2019 22:19:36 GMT"}], "update_date": "2019-12-19", "authors_parsed": [["Diaz-Garcia", "Jose A.", ""], ["Caro-Lopera", "Francisco J.", ""]]}, {"id": "1802.06186", "submitter": "Dheeraj Nagaraj", "authors": "Guy Bresler and Dheeraj Nagaraj", "title": "Optimal Single Sample Tests for Structured versus Unstructured Network\n  Data", "comments": "35 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of testing, using only a single sample, between mean\nfield distributions (like Curie-Weiss, Erd\\H{o}s-R\\'enyi) and structured Gibbs\ndistributions (like Ising model on sparse graphs and Exponential Random\nGraphs). Our goal is to test without knowing the parameter values of the\nunderlying models: only the \\emph{structure} of dependencies is known. We\ndevelop a new approach that applies to both the Ising and Exponential Random\nGraph settings based on a general and natural statistical test. The test can\ndistinguish the hypotheses with high probability above a certain threshold in\nthe (inverse) temperature parameter, and is optimal in that below the threshold\nno test can distinguish the hypotheses.\n  The thresholds do not correspond to the presence of long-range order in the\nmodels. By aggregating information at a global scale, our test works even at\nvery high temperatures.\n  The proofs are based on distributional approximation and sharp concentration\nof quadratic forms, when restricted to Hamming spheres. The restriction to\nHamming spheres is necessary, since otherwise any scalar statistic is useless\nwithout explicit knowledge of the temperature parameter. At the same time, this\nrestriction radically changes the behavior of the functions under\nconsideration, resulting in a much smaller variance than in the independent\nsetting; this makes it hard to directly apply standard methods (i.e., Stein's\nmethod) for concentration of weakly dependent variables. Instead, we carry out\nan additional tensorization argument using a Markov chain that respects the\nsymmetry of the Hamming sphere.\n", "versions": [{"version": "v1", "created": "Sat, 17 Feb 2018 04:07:29 GMT"}, {"version": "v2", "created": "Wed, 23 May 2018 08:43:36 GMT"}], "update_date": "2018-05-24", "authors_parsed": [["Bresler", "Guy", ""], ["Nagaraj", "Dheeraj", ""]]}, {"id": "1802.06190", "submitter": "Jos\\'e A. D\\'iaz-Garc\\'ia", "authors": "Jose A. Diaz-Garcia and Oscar Alejandro Martinez-Jaime", "title": "Tests about R multivariate simple linear models", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hypothesis about the parallelism of the regression lines in R multivariate\nsimple linear models are studied in this paper. Tests on common intercept and\nsets of lines intersected at a fixed value, are also developed. An application\nin an agricultural entomology context is provided.\n", "versions": [{"version": "v1", "created": "Sat, 17 Feb 2018 04:30:40 GMT"}], "update_date": "2018-02-20", "authors_parsed": [["Diaz-Garcia", "Jose A.", ""], ["Martinez-Jaime", "Oscar Alejandro", ""]]}, {"id": "1802.06248", "submitter": "Xin Wang", "authors": "Xin Wang and Vivekananda Roy", "title": "Geometric ergodicity of Polya-Gamma Gibbs sampler for Bayesian logistic\n  regression with a flat prior", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The logistic regression model is the most popular model for analyzing binary\ndata. In the absence of any prior information, an improper flat prior is often\nused for the regression coefficients in Bayesian logistic regression models.\nThe resulting intractable posterior density can be explored by running Polson\net al.'s (2013) data augmentation (DA) algorithm. In this paper, we establish\nthat the Markov chain underlying Polson et al.'s (2013) DA algorithm is\ngeometrically ergodic. Proving this theoretical result is practically important\nas it ensures the existence of central limit theorems (CLTs) for sample\naverages under a finite second moment condition. The CLT in turn allows users\nof the DA algorithm to calculate standard errors for posterior estimates.\n", "versions": [{"version": "v1", "created": "Sat, 17 Feb 2018 15:29:31 GMT"}, {"version": "v2", "created": "Sat, 24 Feb 2018 01:49:41 GMT"}, {"version": "v3", "created": "Mon, 2 Jul 2018 01:38:24 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Wang", "Xin", ""], ["Roy", "Vivekananda", ""]]}, {"id": "1802.06279", "submitter": "Michael Evans", "authors": "Luai Al-Labadi, Zeynep Baskurt and Michael Evans", "title": "Statistical Reasoning: Choosing and Checking the Ingredients, Inferences\n  Based on a Measure of Statistical Evidence with Some Applications", "comments": null, "journal-ref": null, "doi": "10.3390/e20040289", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The features of a logically sound approach to a theory of statistical\nreasoning are discussed. A particular approach that satisfies these criteria is\nreviewed. This is seen to involve selection of a model, model checking,\nelicitation of a prior, checking the prior for bias, checking for prior-data\nconflict and estimation and hypothesis assessment inferences based on a measure\nof evidence. A long-standing anomalous example is resolved by this approach to\ninference and an application is made to a practical problem of considerable\nimportance which, among other novel aspects of the analysis, involves the\ndevelopment of a relevant elicitation algorithm.\n", "versions": [{"version": "v1", "created": "Sat, 17 Feb 2018 19:23:59 GMT"}], "update_date": "2018-05-09", "authors_parsed": [["Al-Labadi", "Luai", ""], ["Baskurt", "Zeynep", ""], ["Evans", "Michael", ""]]}, {"id": "1802.06292", "submitter": "Fan Zhou", "authors": "Fan Zhou", "title": "Nonparametric Estimation of Low Rank Matrix Valued Function", "comments": null, "journal-ref": null, "doi": "10.1214/19-EJS1582", "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $A:[0,1]\\rightarrow\\mathbb{H}_m$ (the space of Hermitian matrices) be a\nmatrix valued function which is low rank with entries in H\\\"{o}lder class\n$\\Sigma(\\beta,L)$. The goal of this paper is to study statistical estimation of\n$A$ based on the regression model $\\mathbb{E}(Y_j|\\tau_j,X_j) = \\langle\nA(\\tau_j), X_j \\rangle,$ where $\\tau_j$ are i.i.d. uniformly distributed in\n$[0,1]$, $X_j$ are i.i.d. matrix completion sampling matrices, $Y_j$ are\nindependent bounded responses. We propose an innovative nuclear norm penalized\nlocal polynomial estimator and establish an upper bound on its point-wise risk\nmeasured by Frobenius norm. Then we extend this estimator globally and prove an\nupper bound on its integrated risk measured by $L_2$-norm. We also propose\nanother new estimator based on bias-reducing kernels to study the case when $A$\nis not necessarily low rank and establish an upper bound on its risk measured\nby $L_{\\infty}$-norm. We show that the obtained rates are all optimal up to\nsome logarithmic factor in minimax sense. Finally, we propose an adaptive\nestimation procedure based on Lepskii's method and model selection with data\nsplitting which is computationally efficient and can be easily implemented and\nparallelized.\n", "versions": [{"version": "v1", "created": "Sat, 17 Feb 2018 20:56:33 GMT"}, {"version": "v2", "created": "Tue, 6 Mar 2018 02:21:13 GMT"}, {"version": "v3", "created": "Sun, 14 Apr 2019 21:58:45 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Zhou", "Fan", ""]]}, {"id": "1802.06308", "submitter": "Guang Cheng", "authors": "Meimei Liu and Zuofeng Shang and Guang Cheng", "title": "Nonparametric Testing under Random Projection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common challenge in nonparametric inference is its high computational\ncomplexity when data volume is large. In this paper, we develop computationally\nefficient nonparametric testing by employing a random projection strategy. In\nthe specific kernel ridge regression setup, a simple distance-based test\nstatistic is proposed. Notably, we derive the minimum number of random\nprojections that is sufficient for achieving testing optimality in terms of the\nminimax rate. An adaptive testing procedure is further established without\nprior knowledge of regularity. One technical contribution is to establish upper\nbounds for a range of tail sums of empirical kernel eigenvalues. Simulations\nand real data analysis are conducted to support our theory.\n", "versions": [{"version": "v1", "created": "Sat, 17 Feb 2018 23:22:34 GMT"}], "update_date": "2018-02-20", "authors_parsed": [["Liu", "Meimei", ""], ["Shang", "Zuofeng", ""], ["Cheng", "Guang", ""]]}, {"id": "1802.06310", "submitter": "Karren Yang", "authors": "Karren D. Yang, Abigail Katcoff and Caroline Uhler", "title": "Characterizing and Learning Equivalence Classes of Causal DAGs under\n  Interventions", "comments": "18 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning causal DAGs in the setting where both\nobservational and interventional data is available. This setting is common in\nbiology, where gene regulatory networks can be intervened on using chemical\nreagents or gene deletions. Hauser and B\\\"uhlmann (2012) previously\ncharacterized the identifiability of causal DAGs under perfect interventions,\nwhich eliminate dependencies between targeted variables and their direct\ncauses. In this paper, we extend these identifiability results to general\ninterventions, which may modify the dependencies between targeted variables and\ntheir causes without eliminating them. We define and characterize the\ninterventional Markov equivalence class that can be identified from general\n(not necessarily perfect) intervention experiments. We also propose the first\nprovably consistent algorithm for learning DAGs in this setting and evaluate\nour algorithm on simulated and biological datasets.\n", "versions": [{"version": "v1", "created": "Sat, 17 Feb 2018 23:42:24 GMT"}, {"version": "v2", "created": "Wed, 11 Jul 2018 23:27:53 GMT"}, {"version": "v3", "created": "Thu, 7 Feb 2019 17:27:13 GMT"}], "update_date": "2019-02-08", "authors_parsed": [["Yang", "Karren D.", ""], ["Katcoff", "Abigail", ""], ["Uhler", "Caroline", ""]]}, {"id": "1802.06715", "submitter": "Debasis Kundu Professor", "authors": "Debasis Kundu and Vahid Nekoukhou", "title": "Univariate and Bivariate Geometric Discrete Generalized Exponential\n  Distributions", "comments": "arXiv admin note: text overlap with arXiv:1701.03569", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Marshall and Olkin (1997, Biometrika, 84, 641 - 652) introduced a very\npowerful method to introduce an additional parameter to a class of continuous\ndistribution functions and hence it brings more flexibility to the model. They\nhave demonstrated their method for the exponential and Weibull classes. In the\nsame paper they have briefly indicated regarding its bivariate extension. The\nmain aim of this paper is to introduce the same method, for the first time, to\nthe class of discrete generalized exponential distributions both for the\nunivariate and bivariate cases. We investigate several properties of the\nproposed univariate and bivariate classes. The univariate class has three\nparameters, whereas the bivariate class has five parameters. It is observed\nthat depending on the parameter values the univariate class can be both zero\ninflated as well as heavy tailed. We propose to use EM algorithm to estimate\nthe unknown parameters. Small simulation experiments have been performed to see\nthe effectiveness of the proposed EM algorithm, and a bivariate data set has\nbeen analyzed and it is observed that the proposed models and the EM algorithm\nwork quite well in practice.\n", "versions": [{"version": "v1", "created": "Fri, 16 Feb 2018 05:58:10 GMT"}], "update_date": "2018-02-20", "authors_parsed": [["Kundu", "Debasis", ""], ["Nekoukhou", "Vahid", ""]]}, {"id": "1802.06969", "submitter": "Elisa Perrone", "authors": "Elisa Perrone, Liam Solus, Caroline Uhler", "title": "Geometry of Discrete Copulas", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multivariate distributions are fundamental to modeling. Discrete copulas can\nbe used to construct diverse multivariate joint distributions over random\nvariables from estimated univariate marginals. The space of discrete copulas\nadmits a representation as a convex polytope which can be exploited in\nentropy-copula methods relevant to hydrology and climatology. To allow for an\nextensive use of such methods in a wide range of applied fields, it is\nimportant to have a geometric representation of discrete copulas with desirable\nstochastic properties. In this paper, we show that the families of ultramodular\ndiscrete copulas and their generalization to convex discrete quasi-copulas\nadmit representations as polytopes. We draw connections to the prominent\nBirkhoff polytope, alternating sign matrix polytope, and their most extensive\ngeneralizations in the discrete geometry literature. In doing so, we generalize\nsome well-known results on these polytopes from both the statistics literature\nand the discrete geometry literature.\n", "versions": [{"version": "v1", "created": "Tue, 20 Feb 2018 04:58:21 GMT"}, {"version": "v2", "created": "Wed, 30 May 2018 14:15:18 GMT"}], "update_date": "2018-05-31", "authors_parsed": [["Perrone", "Elisa", ""], ["Solus", "Liam", ""], ["Uhler", "Caroline", ""]]}, {"id": "1802.07309", "submitter": "Ahmed El Alaoui", "authors": "Ahmed El Alaoui and Michael I. Jordan", "title": "Detection limits in the high-dimensional spiked rectangular model", "comments": "28 pages. Appears in the proc. of the 31st annual Conference on\n  Learning Theory (COLT) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of detecting the presence of a single unknown spike in a\nrectangular data matrix, in a high-dimensional regime where the spike has fixed\nstrength and the aspect ratio of the matrix converges to a finite limit. This\nsetup includes Johnstone's spiked covariance model. We analyze the likelihood\nratio of the spiked model against an \"all noise\" null model of reference, and\nshow it has asymptotically Gaussian fluctuations in a region below---but in\ngeneral not up to---the so-called BBP threshold from random matrix theory. Our\nresult parallels earlier findings of Onatski et al.\\ (2013) and\nJohnstone-Onatski (2015) for spherical spikes. We present a probabilistic\napproach capable of treating generic product priors. In particular, sparsity in\nthe spike is allowed. Our approach is based on Talagrand's interpretation of\nthe cavity method from spin-glass theory. The question of the maximal parameter\nregion where asymptotic normality is expected to hold is left open. This region\nis shaped by the prior in a non-trivial way. We conjecture that this is the\nentire paramagnetic phase of an associated spin-glass model, and is defined by\nthe vanishing of the replica-symmetric solution of Lesieur et al.\\ (2015).\n", "versions": [{"version": "v1", "created": "Tue, 20 Feb 2018 20:19:06 GMT"}, {"version": "v2", "created": "Mon, 12 Mar 2018 22:11:32 GMT"}, {"version": "v3", "created": "Thu, 14 Jun 2018 18:29:20 GMT"}], "update_date": "2018-06-18", "authors_parsed": [["Alaoui", "Ahmed El", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1802.07613", "submitter": "Alexis Derumigny", "authors": "Alexis Derumigny and Jean-David Fermanian", "title": "About Kendall's regression", "comments": "37 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conditional Kendall's tau is a measure of dependence between two random\nvariables, conditionally on some covariates. We assume a regression-type\nrelationship between conditional Kendall's tau and some covariates, in a\nparametric setting with a large number of transformations of a small number of\nregressors. This model may be sparse, and the underlying parameter is estimated\nthrough a penalized criterion. We prove non-asymptotic bounds with explicit\nconstants that hold with high probabilities. We derive the consistency of a\ntwo-step estimator, its asymptotic law and some oracle properties. Some\nsimulations and applications to real data conclude the paper.\n", "versions": [{"version": "v1", "created": "Wed, 21 Feb 2018 15:28:37 GMT"}, {"version": "v2", "created": "Tue, 20 Nov 2018 09:13:01 GMT"}], "update_date": "2018-11-21", "authors_parsed": [["Derumigny", "Alexis", ""], ["Fermanian", "Jean-David", ""]]}, {"id": "1802.07617", "submitter": "Aurelie Fischer", "authors": "Aur\\'elie Fischer (LPSM), Dominique Picard (LPSM)", "title": "Convergence rates for smooth k-means change-point detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the estimation of a change-point for possibly\nhigh-dimensional data in a Gaussian model, using a k-means method. We prove\nthat, up to a logarithmic term, this change-point estimator has a minimax rate\nof convergence. Then, considering the case of sparse data, with a Sobolev\nregularity, we propose a smoothing procedure based on Lepski's method and show\nthat the resulting estimator attains the optimal rate of convergence. Our\nresults are illustrated by some simulations. As the theoretical statement\nrelying on Lepski's method depends on some unknown constant, practical\nstrategies are suggested to perform an optimal smoothing.\n", "versions": [{"version": "v1", "created": "Wed, 21 Feb 2018 15:40:03 GMT"}], "update_date": "2018-02-22", "authors_parsed": [["Fischer", "Aur\u00e9lie", "", "LPSM"], ["Picard", "Dominique", "", "LPSM"]]}, {"id": "1802.07696", "submitter": "Holger Dette", "authors": "Holger Dette, Josua G\\\"osmann", "title": "A likelihood ratio approach to sequential change point detection for a\n  general class of parameters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a new approach for sequential monitoring of a\nparameter of a $d$-dimensional time series, which can be estimated by\napproximately linear functionals of the empirical distribution function. We\nconsider a closed-end-method, which is motivated by the likelihood ratio test\nprinciple and compare the new method with two alternative procedures. We also\nincorporate self-normalization such that estimation of the long-run variance is\nnot necessary. We prove that for a large class of testing problems the new\ndetection scheme has asymptotic level $\\alpha$ and is consistent. The\nasymptotic theory is illustrated for the important cases of monitoring a change\nin the mean, variance and correlation. By means of a simulation study it is\ndemonstrated that the new test performs better than the currently available\nprocedures for these problems.Finally the methodology is illustrated by a small\ndata example investigating index prices from the dot-com bubble.\n", "versions": [{"version": "v1", "created": "Wed, 21 Feb 2018 17:54:14 GMT"}, {"version": "v2", "created": "Thu, 22 Nov 2018 17:35:42 GMT"}], "update_date": "2018-11-26", "authors_parsed": [["Dette", "Holger", ""], ["G\u00f6smann", "Josua", ""]]}, {"id": "1802.07773", "submitter": "Yihong Wu", "authors": "Jason M. Klusowski and Yihong Wu", "title": "Counting Motifs with Graph Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.DM stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Applied researchers often construct a network from a random sample of nodes\nin order to infer properties of the parent network. Two of the most widely used\nsampling schemes are subgraph sampling, where we sample each vertex\nindependently with probability $p$ and observe the subgraph induced by the\nsampled vertices, and neighborhood sampling, where we additionally observe the\nedges between the sampled vertices and their neighbors.\n  In this paper, we study the problem of estimating the number of motifs as\ninduced subgraphs under both models from a statistical perspective. We show\nthat: for any connected $h$ on $k$ vertices, to estimate $s=\\mathsf{s}(h,G)$,\nthe number of copies of $h$ in the parent graph $G$ of maximum degree $d$, with\na multiplicative error of $\\epsilon$, (a) For subgraph sampling, the optimal\nsampling ratio $p$ is $\\Theta_{k}(\\max\\{ (s\\epsilon^2)^{-\\frac{1}{k}}, \\;\n\\frac{d^{k-1}}{s\\epsilon^{2}} \\})$, achieved by Horvitz-Thompson type of\nestimators. (b) For neighborhood sampling, we propose a family of estimators,\nencompassing and outperforming the Horvitz-Thompson estimator and achieving the\nsampling ratio $O_{k}(\\min\\{ (\\frac{d}{s\\epsilon^2})^{\\frac{1}{k-1}}, \\;\n\\sqrt{\\frac{d^{k-2}}{s\\epsilon^2}}\\})$. This is shown to be optimal for all\nmotifs with at most $4$ vertices and cliques of all sizes.\n  The matching minimax lower bounds are established using certain algebraic\nproperties of subgraph counts. These results quantify how much more informative\nneighborhood sampling is than subgraph sampling, as empirically verified by\nexperiments on both synthetic and real-world data. We also address the issue of\nadaptation to the unknown maximum degree, and study specific problems for\nparent graphs with additional structures, e.g., trees or planar graphs.\n", "versions": [{"version": "v1", "created": "Wed, 21 Feb 2018 19:51:45 GMT"}], "update_date": "2018-02-23", "authors_parsed": [["Klusowski", "Jason M.", ""], ["Wu", "Yihong", ""]]}, {"id": "1802.07889", "submitter": "Jiantao Jiao", "authors": "Yanjun Han and Jiantao Jiao and Chuan-Zheng Lee and Tsachy Weissman\n  and Yihong Wu and Tiancheng Yu", "title": "Entropy Rate Estimation for Markov Chains with Large State Space", "comments": "Published as a conference paper on NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating the entropy based on data is one of the prototypical problems in\ndistribution property testing and estimation. For estimating the Shannon\nentropy of a distribution on $S$ elements with independent samples,\n[Paninski2004] showed that the sample complexity is sublinear in $S$, and\n[Valiant--Valiant2011] showed that consistent estimation of Shannon entropy is\npossible if and only if the sample size $n$ far exceeds $\\frac{S}{\\log S}$. In\nthis paper we consider the problem of estimating the entropy rate of a\nstationary reversible Markov chain with $S$ states from a sample path of $n$\nobservations. We show that:\n  (1) As long as the Markov chain mixes not too slowly, i.e., the relaxation\ntime is at most $O(\\frac{S}{\\ln^3 S})$, consistent estimation is achievable\nwhen $n \\gg \\frac{S^2}{\\log S}$.\n  (2) As long as the Markov chain has some slight dependency, i.e., the\nrelaxation time is at least $1+\\Omega(\\frac{\\ln^2 S}{\\sqrt{S}})$, consistent\nestimation is impossible when $n \\lesssim \\frac{S^2}{\\log S}$.\n  Under both assumptions, the optimal estimation accuracy is shown to be\n$\\Theta(\\frac{S^2}{n \\log S})$. In comparison, the empirical entropy rate\nrequires at least $\\Omega(S^2)$ samples to be consistent, even when the Markov\nchain is memoryless. In addition to synthetic experiments, we also apply the\nestimators that achieve the optimal sample complexity to estimate the entropy\nrate of the English language in the Penn Treebank and the Google One Billion\nWords corpora, which provides a natural benchmark for language modeling and\nrelates it directly to the widely used perplexity measure.\n", "versions": [{"version": "v1", "created": "Thu, 22 Feb 2018 03:10:17 GMT"}, {"version": "v2", "created": "Wed, 12 Sep 2018 04:51:30 GMT"}, {"version": "v3", "created": "Mon, 24 Sep 2018 06:45:27 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Han", "Yanjun", ""], ["Jiao", "Jiantao", ""], ["Lee", "Chuan-Zheng", ""], ["Weissman", "Tsachy", ""], ["Wu", "Yihong", ""], ["Yu", "Tiancheng", ""]]}, {"id": "1802.07995", "submitter": "Frank Werner", "authors": "Claudia K\\\"onig and Axel Munk and Frank Werner", "title": "Multidimensional multiscale scanning in Exponential Families: Limit\n  theory and statistical consequences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of finding anomalies in a $d$-dimensional field of\nindependent random variables $\\{Y_i\\}_{i \\in \\left\\{1,...,n\\right\\}^d}$, each\ndistributed according to a one-dimensional natural exponential family $\\mathcal\nF = \\left\\{F_\\theta\\right\\}_{\\theta \\in\\Theta}$. Given some baseline parameter\n$\\theta_0 \\in\\Theta$, the field is scanned using local likelihood ratio tests\nto detect from a (large) given system of regions $\\mathcal{R}$ those regions $R\n\\subset \\left\\{1,...,n\\right\\}^d$ with $\\theta_i \\neq \\theta_0$ for some $i \\in\nR$. We provide a unified methodology which controls the overall family wise\nerror (FWER) to make a wrong detection at a given error rate.\n  Fundamental to our method is a Gaussian approximation of the distribution of\nthe underlying multiscale test statistic with explicit rate of convergence.\nFrom this, we obtain a weak limit theorem which can be seen as a generalized\nweak invariance principle to non identically distributed data and is of\nindependent interest. Furthermore, we give an asymptotic expansion of the\nprocedures power, which yields minimax optimality in case of Gaussian\nobservations.\n", "versions": [{"version": "v1", "created": "Thu, 22 Feb 2018 11:52:56 GMT"}, {"version": "v2", "created": "Fri, 23 Feb 2018 10:42:02 GMT"}, {"version": "v3", "created": "Fri, 24 Aug 2018 07:02:23 GMT"}, {"version": "v4", "created": "Sun, 24 Mar 2019 08:42:40 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["K\u00f6nig", "Claudia", ""], ["Munk", "Axel", ""], ["Werner", "Frank", ""]]}, {"id": "1802.07998", "submitter": "Graciela Boente Prof.", "authors": "Graciela Boente, Daniela Rodriguez and Pablo Vena", "title": "Robust estimators in a generalized partly linear regression model under\n  monotony constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the situation in which the observations follow an\nisotonic generalized partly linear model. Under this model, the mean of the\nresponses is modelled, through a link function, linearly on some covariates and\nnonparametrically on an univariate regressor in such a way that the\nnonparametric component is assumed to be a monotone function. A class of robust\nestimates for the monotone nonparametric component and for the regression\nparameter, related to the linear one, is defined. The robust estimators are\nbased on a spline approach combined with a score function which bounds large\nvalues of the deviance. As an application, we consider the isotonic partly\nlinear log--Gamma regression model. Through a Monte Carlo study, we investigate\nthe performance of the proposed estimators under a partly linear log-Gamma\nregression model with increasing nonparametric component.\n", "versions": [{"version": "v1", "created": "Thu, 22 Feb 2018 11:57:09 GMT"}, {"version": "v2", "created": "Fri, 16 Nov 2018 02:42:54 GMT"}, {"version": "v3", "created": "Thu, 29 Nov 2018 17:32:35 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["Boente", "Graciela", ""], ["Rodriguez", "Daniela", ""], ["Vena", "Pablo", ""]]}, {"id": "1802.08004", "submitter": "Francesco Schirripa Spagnolo", "authors": "Francesco Schirripa Spagnolo, Nicola Salvati, Antonella D'Agostino,\n  Ides Nicaise", "title": "The use of sampling weights in the M-quantile random-effects regression:\n  an application to PISA mathematics scores", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  M-quantile random-effects regression represents an interesting approach for\nmodelling multilevel data when the interest of researchers is focused on the\nconditional quantiles. When data are based on complex survey designs, sampling\nweights have to be incorporate in the analysis. A pseudo-likelihood approach\nfor accommodating sampling weights in the M-quantile random-effects regression\nis presented. The proposed methodology is applied to the Italian sample of the\n\"Program for International Student Assessment 2015\" survey in order to study\nthe gender gap in mathematics at various quantiles of the conditional\ndistribution. Findings offer a possible explanation of the low share of females\nin \"Science, Technology, Engineering and Mathematics\" sectors.\n", "versions": [{"version": "v1", "created": "Thu, 22 Feb 2018 12:12:46 GMT"}], "update_date": "2018-02-23", "authors_parsed": [["Spagnolo", "Francesco Schirripa", ""], ["Salvati", "Nicola", ""], ["D'Agostino", "Antonella", ""], ["Nicaise", "Ides", ""]]}, {"id": "1802.08175", "submitter": "Cristiano Bocci", "authors": "Cristiano Bocci, Fabio Rapallo", "title": "Algebra and geometry of tensors for modeling rater agreement data", "comments": "24 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.AG stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study three different quasi-symmetry models and three different mixture\nmodels of $n\\times n\\times n$ tensors for modeling rater agreement data. For\nthese models we give a geometric description of the associated varieties and we\nstudy their invariants distinguishing between the case $n=2$ and the case\n$n>2$. Finally, for the two models for pairwise agreement we state some results\nabout the pairwise Cohen's $\\kappa$ coefficients.\n", "versions": [{"version": "v1", "created": "Wed, 21 Feb 2018 08:49:31 GMT"}], "update_date": "2018-02-26", "authors_parsed": [["Bocci", "Cristiano", ""], ["Rapallo", "Fabio", ""]]}, {"id": "1802.08513", "submitter": "Ilias Diakonikolas", "authors": "Ilias Diakonikolas and Jerry Li and Ludwig Schmidt", "title": "Fast and Sample Near-Optimal Algorithms for Learning Multidimensional\n  Histograms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of robustly learning multi-dimensional histograms. A\n$d$-dimensional function $h: D \\rightarrow \\mathbb{R}$ is called a\n$k$-histogram if there exists a partition of the domain $D \\subseteq\n\\mathbb{R}^d$ into $k$ axis-aligned rectangles such that $h$ is constant within\neach such rectangle. Let $f: D \\rightarrow \\mathbb{R}$ be a $d$-dimensional\nprobability density function and suppose that $f$ is $\\mathrm{OPT}$-close, in\n$L_1$-distance, to an unknown $k$-histogram (with unknown partition). Our goal\nis to output a hypothesis that is $O(\\mathrm{OPT}) + \\epsilon$ close to $f$, in\n$L_1$-distance. We give an algorithm for this learning problem that uses $n =\n\\tilde{O}_d(k/\\epsilon^2)$ samples and runs in time $\\tilde{O}_d(n)$. For any\nfixed dimension, our algorithm has optimal sample complexity, up to logarithmic\nfactors, and runs in near-linear time. Prior to our work, the time complexity\nof the $d=1$ case was well-understood, but significant gaps in our\nunderstanding remained even for $d=2$.\n", "versions": [{"version": "v1", "created": "Fri, 23 Feb 2018 13:07:32 GMT"}], "update_date": "2018-02-26", "authors_parsed": [["Diakonikolas", "Ilias", ""], ["Li", "Jerry", ""], ["Schmidt", "Ludwig", ""]]}, {"id": "1802.08572", "submitter": "Nadji Rahmania", "authors": "Daoud Ounaissi and Nadji Rahmania", "title": "Bayesian Lasso : Concentration and MCMC Diagnosis", "comments": "arXiv admin note: text overlap with arXiv:1512.01366", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using posterior distribution of Bayesian LASSO we construct a semi-norm on\nthe parameter space. We show that the partition function depends on the ratio\nof the l 1 and l 2 norms and present three regimes. We derive the con-\ncentration of Bayesian LASSO, and present MCMC convergence diagnosis.\n  Keywords: LASSO, Bayes, MCMC, log-concave, geometry, incomplete Gamma\nfunction\n", "versions": [{"version": "v1", "created": "Thu, 22 Feb 2018 14:50:04 GMT"}], "update_date": "2018-02-26", "authors_parsed": [["Ounaissi", "Daoud", ""], ["Rahmania", "Nadji", ""]]}, {"id": "1802.08658", "submitter": "Michael Hoffmann", "authors": "Michael Hoffmann, Holger Dette", "title": "On detecting changes in the jumps of arbitrary size of a time-continuous\n  stochastic process", "comments": "98 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces test and estimation procedures for abrupt and gradual\nchanges in the entire jump behaviour of a discretely observed Ito\nsemimartingale. In contrast to existing work we analyse jumps of arbitrary size\nwhich are not restricted to a minimum height. Our methods are based on weak\nconvergence of a truncated sequential empirical distribution function of the\njump characteristic of the underlying Ito semimartingale. Critical values for\nthe new tests are obtained by a multiplier bootstrap approach and we\ninvestigate the performance of the tests also under local alternatives. An\nextensive simulation study shows the finite-sample properties of the new\nprocedures.\n", "versions": [{"version": "v1", "created": "Fri, 23 Feb 2018 17:50:38 GMT"}, {"version": "v2", "created": "Thu, 7 Feb 2019 05:40:59 GMT"}], "update_date": "2019-02-08", "authors_parsed": [["Hoffmann", "Michael", ""], ["Dette", "Holger", ""]]}, {"id": "1802.08667", "submitter": "Rahul Singh", "authors": "Victor Chernozhukov, Whitney Newey, Rahul Singh", "title": "De-Biased Machine Learning of Global and Local Parameters Using\n  Regularized Riesz Representers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML econ.EM math.ST stat.TH", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We provide adaptive inference methods, based on $\\ell_1$ regularization, for\nregular (semiparametric) and non-regular (nonparametric) linear functionals of\nthe conditional expectation function. Examples of regular functionals include\naverage treatment effects, policy effects, and derivatives. Examples of\nnon-regular functionals include average treatment effects, policy effects, and\nderivatives conditional on a covariate subvector fixed at a point. We construct\na Neyman orthogonal equation for the target parameter that is approximately\ninvariant to small perturbations of the nuisance parameters. To achieve this\nproperty, we include the Riesz representer for the functional as an additional\nnuisance parameter. Our analysis yields weak \"double sparsity robustness\":\neither the approximation to the regression or the approximation to the\nrepresenter can be \"completely dense\" as long as the other is sufficiently\n\"sparse\". Our main results are non-asymptotic and imply asymptotic uniform\nvalidity over large classes of models, translating into honest confidence bands\nfor both global and local parameters.\n", "versions": [{"version": "v1", "created": "Fri, 23 Feb 2018 18:17:42 GMT"}, {"version": "v2", "created": "Mon, 19 Mar 2018 00:35:09 GMT"}, {"version": "v3", "created": "Mon, 9 Sep 2019 23:16:24 GMT"}, {"version": "v4", "created": "Fri, 10 Jul 2020 21:10:20 GMT"}, {"version": "v5", "created": "Tue, 13 Apr 2021 17:12:54 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Chernozhukov", "Victor", ""], ["Newey", "Whitney", ""], ["Singh", "Rahul", ""]]}, {"id": "1802.08715", "submitter": "Ery Arias-Castro", "authors": "Ery Arias-Castro and Andrew Ying", "title": "Detection of Sparse Mixtures: Higher Criticism and Scan Statistic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of detecting a sparse mixture as studied by Ingster\n(1997) and Donoho and Jin (2004). We consider a wide array of base\ndistributions. In particular, we study the situation when the base distribution\nhas polynomial tails, a situation that has not received much attention in the\nliterature. Perhaps surprisingly, we find that in the context of such a\npower-law distribution, the higher criticism does not achieve the detection\nboundary. However, the scan statistic does.\n", "versions": [{"version": "v1", "created": "Fri, 23 Feb 2018 19:53:59 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Arias-Castro", "Ery", ""], ["Ying", "Andrew", ""]]}, {"id": "1802.08855", "submitter": "Shashank Singh", "authors": "Shashank Singh, Barnab\\'as P\\'oczos", "title": "Minimax Distribution Estimation in Wasserstein Distance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT cs.LG math.IT stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Wasserstein metric is an important measure of distance between\nprobability distributions, with applications in machine learning, statistics,\nprobability theory, and data analysis. This paper provides upper and lower\nbounds on statistical minimax rates for the problem of estimating a probability\ndistribution under Wasserstein loss, using only metric properties, such as\ncovering and packing numbers, of the sample space, and weak moment assumptions\non the probability distributions.\n", "versions": [{"version": "v1", "created": "Sat, 24 Feb 2018 14:42:43 GMT"}, {"version": "v2", "created": "Wed, 23 May 2018 03:43:27 GMT"}, {"version": "v3", "created": "Thu, 7 Nov 2019 02:24:49 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Singh", "Shashank", ""], ["P\u00f3czos", "Barnab\u00e1s", ""]]}, {"id": "1802.08951", "submitter": "Indranil Ghosh", "authors": "Indranil Ghosh, Ayman Alzaatreh, and G.G. Hamedani", "title": "On the discrete analog of gamma-Lomax distribution: properties and\n  applications", "comments": "This is the most recent version (except the p.m.f. plots) because the\n  arxiv environment would not support in the latex format", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This article represents how certain types of blockades in any industrial\n(heavy industries) production, in particular, industrial strikes can be modeled\nwith the proposed discrete probabilistic distribution as a baseline\ndistribution. We considered the number of outbreaks of strikes in the coal\nmining industry, the vehicle manufacturing industry, and the transpose industry\nin the UK obtained from Consul (1989). We fitted those data sets with the\nproposed discrete gamma-Lomax distribution and compared the fit with the\ndiscrete generalized Pareto distribution (Consul, 1989). For this purpose, we\nexplore the basic properties of the discrete gamma-Lomax distribution including\nbut not limited to: cumulative distribution, survival, probability mass,\nquantile and hazard functions, genesis and rth-order moments; consider maximum\nlikelihood estimation under the normal set up as well as under the censored\ndata set scenario. It is observed that the newly proposed model can be useful\nto describe strikes arising from various types of industries.\n", "versions": [{"version": "v1", "created": "Sun, 25 Feb 2018 03:59:08 GMT"}, {"version": "v2", "created": "Fri, 20 Mar 2020 13:29:26 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Ghosh", "Indranil", ""], ["Alzaatreh", "Ayman", ""], ["Hamedani", "G. G.", ""]]}, {"id": "1802.08992", "submitter": "Shota Gugushvili", "authors": "Shota Gugushvili, Aad van der Vaart, Dong Yan", "title": "Bayesian linear inverse problems in regularity scales", "comments": "34 pages", "journal-ref": "Ann. Inst. H. Poincar\\'e Probab. Statist., 56(3): 2081-2107, 2020", "doi": "10.1214/19-AIHP1029", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We obtain rates of contraction of posterior distributions in inverse problems\ndefined by scales of smoothness classes. We derive abstract results for general\npriors, with contraction rates determined by Galerkin approximation. The rate\ndepends on the amount of prior concentration near the true function and the\nprior mass of functions with inferior Galerkin approximation. We apply the\ngeneral result to non-conjugate series priors, showing that these priors give\nnear optimal and adaptive recovery in some generality, Gaussian priors, and\nmixtures of Gaussian priors, where the latter are also shown to be near optimal\nand adaptive. The proofs are based on general testing and approximation\narguments, without explicit calculations on the posterior distribution. We are\nthus not restricted to priors based on the singular value decomposition of the\noperator. We illustrate the results with examples of inverse problems resulting\nfrom differential equations.\n", "versions": [{"version": "v1", "created": "Sun, 25 Feb 2018 12:14:33 GMT"}, {"version": "v2", "created": "Tue, 3 Dec 2019 15:13:26 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Gugushvili", "Shota", ""], ["van der Vaart", "Aad", ""], ["Yan", "Dong", ""]]}, {"id": "1802.08993", "submitter": "Shota Gugushvili", "authors": "Shota Gugushvili, Aad van der Vaart, Dong Yan", "title": "Bayesian inverse problems with partial observations", "comments": "22 pages, 2 figures", "journal-ref": "Transactions of A. Razmadze Mathematical Institute, Volume 172,\n  Issue 3, Part A, December 2018, pages 388-403", "doi": "10.1016/j.trmi.2018.09.002", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a nonparametric Bayesian approach to linear inverse problems under\ndiscrete observations. We use the discrete Fourier transform to convert our\nmodel into a truncated Gaussian sequence model, that is closely related to the\nclassical Gaussian sequence model. Upon placing the truncated series prior on\nthe unknown parameter, we show that as the number of observations\n$n\\rightarrow\\infty,$ the corresponding posterior distribution contracts around\nthe true parameter at a rate depending on the smoothness of the true parameter\nand the prior, and the ill-posedness degree of the problem. Correct\ncombinations of these values lead to optimal posterior contraction rates (up to\nlogarithmic factors). Similarly, the frequentist coverage of Bayesian credible\nsets is shown to be dependent on a combination of smoothness of the true\nparameter and the prior, and the ill-posedness of the problem. Oversmoothing\npriors lead to zero coverage, while undersmoothing priors produce highly\nconservative results. Finally, we illustrate our theoretical results by\nnumerical examples.\n", "versions": [{"version": "v1", "created": "Sun, 25 Feb 2018 12:15:17 GMT"}, {"version": "v2", "created": "Thu, 18 Oct 2018 13:06:06 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Gugushvili", "Shota", ""], ["van der Vaart", "Aad", ""], ["Yan", "Dong", ""]]}, {"id": "1802.09098", "submitter": "Aaditya Ramdas", "authors": "Aaditya Ramdas, Tijana Zrnic, Martin Wainwright, Michael Jordan", "title": "SAFFRON: an adaptive algorithm for online control of the false discovery\n  rate", "comments": "19 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the online false discovery rate (FDR) problem, one observes a possibly\ninfinite sequence of $p$-values $P_1,P_2,\\dots$, each testing a different null\nhypothesis, and an algorithm must pick a sequence of rejection thresholds\n$\\alpha_1,\\alpha_2,\\dots$ in an online fashion, effectively rejecting the\n$k$-th null hypothesis whenever $P_k \\leq \\alpha_k$. Importantly, $\\alpha_k$\nmust be a function of the past, and cannot depend on $P_k$ or any of the later\nunseen $p$-values, and must be chosen to guarantee that for any time $t$, the\nFDR up to time $t$ is less than some pre-determined quantity $\\alpha \\in\n(0,1)$. In this work, we present a powerful new framework for online FDR\ncontrol that we refer to as SAFFRON. Like older alpha-investing (AI)\nalgorithms, SAFFRON starts off with an error budget, called alpha-wealth, that\nit intelligently allocates to different tests over time, earning back some\nwealth on making a new discovery. However, unlike older methods, SAFFRON's\nthreshold sequence is based on a novel estimate of the alpha fraction that it\nallocates to true null hypotheses. In the offline setting, algorithms that\nemploy an estimate of the proportion of true nulls are called adaptive methods,\nand SAFFRON can be seen as an online analogue of the famous offline Storey-BH\nadaptive procedure. Just as Storey-BH is typically more powerful than the\nBenjamini-Hochberg (BH) procedure under independence, we demonstrate that\nSAFFRON is also more powerful than its non-adaptive counterparts, such as LORD\nand other generalized alpha-investing algorithms. Further, a monotone version\nof the original AI algorithm is recovered as a special case of SAFFRON, that is\noften more stable and powerful than the original. Lastly, the derivation of\nSAFFRON provides a novel template for deriving new online FDR rules.\n", "versions": [{"version": "v1", "created": "Sun, 25 Feb 2018 22:19:06 GMT"}, {"version": "v2", "created": "Wed, 10 Jul 2019 18:21:55 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Ramdas", "Aaditya", ""], ["Zrnic", "Tijana", ""], ["Wainwright", "Martin", ""], ["Jordan", "Michael", ""]]}, {"id": "1802.09117", "submitter": "Yinchu Zhu", "authors": "Jelena Bradic, Jianqing Fan, Yinchu Zhu", "title": "Testability of high-dimensional linear models with non-sparse structures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding statistical inference under possibly non-sparse\nhigh-dimensional models has gained much interest recently. For a given\ncomponent of the regression coefficient, we show that the difficulty of the\nproblem depends on the sparsity of the corresponding row of the precision\nmatrix of the covariates, not the sparsity of the regression coefficients. We\ndevelop new concepts of uniform and essentially uniform non-testability that\nallow the study of limitations of tests across a broad set of alternatives.\nUniform non-testability identifies a collection of alternatives such that the\npower of any test, against any alternative in the group, is asymptotically at\nmost equal to the nominal size. Implications of the new constructions include\nnew minimax testability results that, in sharp contrast to the current results,\ndo not depend on the sparsity of the regression parameters. We identify new\ntradeoffs between testability and feature correlation. In particular, we show\nthat, in models with weak feature correlations, minimax lower bound can be\nattained by a test whose power has the $\\sqrt{n}$ rate, regardless of the size\nof the model sparsity.\n", "versions": [{"version": "v1", "created": "Mon, 26 Feb 2018 01:00:06 GMT"}, {"version": "v2", "created": "Mon, 3 Dec 2018 18:49:17 GMT"}, {"version": "v3", "created": "Mon, 25 Nov 2019 02:15:24 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Bradic", "Jelena", ""], ["Fan", "Jianqing", ""], ["Zhu", "Yinchu", ""]]}, {"id": "1802.09226", "submitter": "Christian Robert Y", "authors": "Christian Y. Robert", "title": "Power variations for a class of Brown-Resnick processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the class of simple Brown-Resnick max-stable processes whose\nspectral processes are continuous exponential martingales. We develop the\nasymptotic theory for the realized power variations of these max-stable\nprocesses, that is, sums of powers of absolute increments. We consider an\ninfill asymptotic setting, where the sampling frequency converges to zero while\nthe time span remains fixed. More specifically we obtain a biased central limit\ntheorem whose bias depend on the local times of the differences between the\nlogarithms of the underlying spectral processes.\n", "versions": [{"version": "v1", "created": "Mon, 26 Feb 2018 09:56:36 GMT"}, {"version": "v2", "created": "Sat, 5 Jan 2019 09:35:11 GMT"}, {"version": "v3", "created": "Sun, 9 Jun 2019 08:48:25 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Robert", "Christian Y.", ""]]}, {"id": "1802.09370", "submitter": "Paul Rochet", "authors": "O. Chernova, F. Lavancier, P. Rochet", "title": "Averaging of density kernel estimators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Averaging provides an alternative to bandwidth selection for density kernel\nestimation. We propose a procedure to combine linearly several kernel\nestimators of a density obtained from different, possibly data-driven,\nbandwidths. The method relies on minimizing an easily tractable approximation\nof the integrated square error of the combination. It provides, at a small\ncomputational cost, a final solution that improves on the initial estimators in\nmost cases. The average estimator is proved to be asymptotically as efficient\nas the best possible combination (the oracle), with an error term that\ndecreases faster than the minimax rate obtained with separated learning and\nvalidation samples. The performances are tested numerically, with results that\ncompare favorably to other existing procedures in terms of mean integrated\nsquare errors.\n", "versions": [{"version": "v1", "created": "Mon, 26 Feb 2018 15:03:53 GMT"}, {"version": "v2", "created": "Mon, 4 Nov 2019 11:13:10 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Chernova", "O.", ""], ["Lavancier", "F.", ""], ["Rochet", "P.", ""]]}, {"id": "1802.09411", "submitter": "Jack Jewson", "authors": "Jack Jewson, Jim Q Smith and Chris Holmes", "title": "Principles of Bayesian Inference using General Divergence Criteria", "comments": null, "journal-ref": null, "doi": "10.3390/e20060442", "report-no": null, "categories": "math.ST stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  When it is acknowledged that all candidate parameterised statistical models\nare misspecified relative to the data generating process, the decision maker\n(DM) must currently concern themselves with inference for the parameter value\nminimising the KL-divergence between the model and the process (Walker, 2013).\nHowever, it has long been known that minimising the KL-divergence places a\nlarge weight on correctly capturing the tails of the sample distribution. As a\nresult the DM is required to worry about the robustness of their model to tail\nmisspecifications if they want to conduct principled inference. In this paper\nwe alleviate these concerns for the DM. We advance recent methodological\ndevelopments in general Bayesian updating (Bissiri, Holmes and Walker, 2016) to\npropose a statistically well principled Bayesian updating of beliefs targeting\nthe minimisation of more general divergence criteria. We improve both the\nmotivation and the statistical foundations of existing Bayesian minimum\ndivergence estimation (Hooker and Vidyashankar, 2014; Ghosh and Basu, 2016),\nallowing the well principled Bayesian to target predictions from the model that\nare close to the genuine model in terms of some alternative divergence measure\nto the KL-divergence. Our principled formulation allows us to consider a\nbroader range of divergences than have previously been considered. In fact we\nargue defining the divergence measure forms an important, subjective part of\nany statistical analysis, and aim to provide some decision theoretic rational\nfor this selection. We illustrate how targeting alternative divergence measures\ncan impact the conclusions of simple inference tasks, and discuss then how our\nmethods might apply to more complicated, high dimensional models.\n", "versions": [{"version": "v1", "created": "Mon, 26 Feb 2018 15:50:15 GMT"}, {"version": "v2", "created": "Thu, 17 May 2018 14:09:53 GMT"}], "update_date": "2018-07-04", "authors_parsed": [["Jewson", "Jack", ""], ["Smith", "Jim Q", ""], ["Holmes", "Chris", ""]]}, {"id": "1802.09509", "submitter": "Paulo Serra", "authors": "Paulo Serra, Michel Mandjes", "title": "Estimation of Local Degree Distributions via Local Weighted Averaging\n  and Monte Carlo Cross-Validation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Owing to their capability of summarising interactions between elements of a\nsystem, networks have become a common type of data in many fields. As networks\ncan be inhomogeneous, in that different regions of the network may exhibit\ndifferent topologies, an important topic concerns their local properties. This\npaper focuses on the estimation of the local degree distribution of a vertex in\nan inhomogeneous network. The contributions are twofold: we propose an\nestimator based on local weighted averaging, and we set up a Monte Carlo\ncross-validation procedure to pick the parameters of this estimator. Under a\nspecific modelling assumption we derive an oracle inequality that shows how the\nmodel parameters affect the precision of the estimator. We illustrate our\nmethod by several numerical experiments, on both real and synthetic data,\nshowing in particular that the approach considerably improves upon the natural,\nempirical estimator.\n", "versions": [{"version": "v1", "created": "Mon, 26 Feb 2018 18:52:56 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Serra", "Paulo", ""], ["Mandjes", "Michel", ""]]}, {"id": "1802.09513", "submitter": "Rainer Sinn", "authors": "Daniel Irving Bernstein, Grigoriy Blekherman, Rainer Sinn", "title": "Typical and Generic Ranks in Matrix Completion", "comments": "to appear in Linear Algebra and its Applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.NA math.AG math.NA math.RA stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of exact low-rank matrix completion from a geometric\nviewpoint: given a partially filled matrix M, we keep the positions of\nspecified and unspecified entries fixed, and study how the minimal completion\nrank depends on the values of the known entries. If the entries of the matrix\nare complex numbers, then for a fixed pattern of locations of specified and\nunspecified entries there is a unique completion rank which occurs with\npositive probability. We call this rank the generic completion rank. Over the\nreal numbers there can be multiple ranks that occur with positive probability;\nwe call them typical completion ranks. We introduce these notions formally, and\nprovide a number of inequalities and exact results on typical and generic ranks\nfor different families of patterns of known and unknown entries.\n", "versions": [{"version": "v1", "created": "Mon, 26 Feb 2018 18:54:50 GMT"}, {"version": "v2", "created": "Sun, 22 Sep 2019 13:41:52 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Bernstein", "Daniel Irving", ""], ["Blekherman", "Grigoriy", ""], ["Sinn", "Rainer", ""]]}, {"id": "1802.09514", "submitter": "Jason Altschuler", "authors": "Jason Altschuler, Victor-Emmanuel Brunel, Alan Malek", "title": "Best Arm Identification for Contaminated Bandits", "comments": "to appear in Journal of Machine Learning Research (JMLR)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies active learning in the context of robust statistics.\nSpecifically, we propose a variant of the Best Arm Identification problem for\n\\emph{contaminated bandits}, where each arm pull has probability $\\varepsilon$\nof generating a sample from an arbitrary contamination distribution instead of\nthe true underlying distribution. The goal is to identify the best (or\napproximately best) true distribution with high probability, with a secondary\ngoal of providing guarantees on the quality of this distribution. The primary\nchallenge of the contaminated bandit setting is that the true distributions are\nonly partially identifiable, even with infinite samples. To address this, we\ndevelop tight, non-asymptotic sample complexity bounds for high-probability\nestimation of the first two robust moments (median and median absolute\ndeviation) from contaminated samples. These concentration inequalities are the\nmain technical contributions of the paper and may be of independent interest.\nUsing these results, we adapt several classical Best Arm Identification\nalgorithms to the contaminated bandit setting and derive sample complexity\nupper bounds for our problem. Finally, we provide matching\ninformation-theoretic lower bounds on the sample complexity (up to a small\nlogarithmic factor).\n", "versions": [{"version": "v1", "created": "Mon, 26 Feb 2018 18:59:30 GMT"}, {"version": "v2", "created": "Sun, 8 Apr 2018 22:23:06 GMT"}, {"version": "v3", "created": "Tue, 19 Jun 2018 00:15:37 GMT"}, {"version": "v4", "created": "Fri, 19 Oct 2018 15:31:29 GMT"}, {"version": "v5", "created": "Wed, 15 May 2019 15:32:00 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Altschuler", "Jason", ""], ["Brunel", "Victor-Emmanuel", ""], ["Malek", "Alan", ""]]}, {"id": "1802.09673", "submitter": "Daniel Zelterman", "authors": "Daniel Zelterman", "title": "The maximum negative hypergeometric distribution", "comments": "25 pages, 6 figures; 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An urn contains a known number of balls of two different colors. We describe\nthe random variable counting the smallest number of draws needed in order to\nobserve at least $\\,c\\,$ of both colors when sampling without replacement for a\npre-specified value of $\\,c=1,2,\\ldots\\,$. This distribution is the finite\nsample analogy to the maximum negative binomial distribution described by\nZhang, Burtness, and Zelterman (2000). We describe the modes, approximating\ndistributions, and estimation of the contents of the urn.\n", "versions": [{"version": "v1", "created": "Sun, 25 Feb 2018 15:31:22 GMT"}], "update_date": "2018-02-28", "authors_parsed": [["Zelterman", "Daniel", ""]]}, {"id": "1802.09684", "submitter": "Jing Lei", "authors": "Jing Lei", "title": "Network Representation Using Graph Root Distributions", "comments": "47 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exchangeable random graphs serve as an important probabilistic framework for\nthe statistical analysis of network data. In this work we develop an\nalternative parameterization for a large class of exchangeable random graphs,\nwhere the nodes are independent random vectors in a linear space equipped with\nan indefinite inner product, and the edge probability between two nodes equals\nthe inner product of the corresponding node vectors. Therefore, the\ndistribution of exchangeable random graphs in this subclass can be represented\nby a node sampling distribution on this linear space, which we call the graph\nroot distribution. We study existence and identifiability of such\nrepresentations, the topological relationship between the graph root\ndistribution and the exchangeable random graph sampling distribution, and\nestimation of graph root distributions.\n", "versions": [{"version": "v1", "created": "Tue, 27 Feb 2018 02:12:30 GMT"}, {"version": "v2", "created": "Thu, 30 Apr 2020 15:06:52 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Lei", "Jing", ""]]}, {"id": "1802.09733", "submitter": "Andreas Elsener", "authors": "Andreas Elsener and Sara van de Geer", "title": "Sharp oracle inequalities for stationary points of nonconvex penalized\n  M-estimators", "comments": "49 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many statistical estimation procedures lead to nonconvex optimization\nproblems. Algorithms to solve these are often guaranteed to output a stationary\npoint of the optimization problem. Oracle inequalities are an important\ntheoretical instrument to asses the statistical performance of an estimator.\nOracle results have focused on the theoretical properties of the uncomputable\n(global) minimum or maximum. In the present work a general framework used for\nconvex optimization problems to derive oracle inequalities for stationary\npoints is extended. A main new ingredient of these oracle inequalities is that\nthey are sharp: they show closeness to the best approximation within the model\nplus a remainder term. We apply this framework to different estimation\nproblems.\n", "versions": [{"version": "v1", "created": "Tue, 27 Feb 2018 06:08:21 GMT"}], "update_date": "2018-02-28", "authors_parsed": [["Elsener", "Andreas", ""], ["van de Geer", "Sara", ""]]}, {"id": "1802.09899", "submitter": "Tommy Liu", "authors": "Tommy Liu", "title": "A Kolmogorov-Smirnov type test for two inter-dependent random variables", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST physics.data-an stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider $n$ iid random variables, where $\\xi_1, \\ldots, \\xi_n$ are $n$\nrealisations of a random variable $\\xi$ and $\\zeta_1, \\ldots, \\zeta_n$ are $n$\nrealisations of a random variable $\\zeta$. The distribution of each realisation\nof $\\xi$, that is the distribution of \\emph{one} $\\xi_i$, depends on the value\nof the corresponding $\\zeta_i$, that is the probability $P\\left(\\xi_i\\leq\nx\\right)=F(x,\\zeta_i)$. We develop a statistical test to see if the $\\xi_1,\n\\ldots, \\xi_n$ are distributed according to the distribution function\n$F(x,\\zeta_i)$. We call this new statistical test the condition\nKolmogorov-Smirnov test.\n", "versions": [{"version": "v1", "created": "Tue, 27 Feb 2018 14:28:32 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Liu", "Tommy", ""]]}, {"id": "1802.09963", "submitter": "Cheng Mao", "authors": "Cheng Mao, Ashwin Pananjady, Martin J. Wainwright", "title": "Breaking the $1/\\sqrt{n}$ Barrier: Faster Rates for Permutation-based\n  Models in Polynomial Time", "comments": "30 pages, 1 figure. Accepted for presentation at Conference on\n  Learning Theory (COLT) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many applications, including rank aggregation and crowd-labeling, can be\nmodeled in terms of a bivariate isotonic matrix with unknown permutations\nacting on its rows and columns. We consider the problem of estimating such a\nmatrix based on noisy observations of a subset of its entries, and design and\nanalyze a polynomial-time algorithm that improves upon the state of the art. In\nparticular, our results imply that any such $n \\times n$ matrix can be\nestimated efficiently in the normalized Frobenius norm at rate\n$\\widetilde{\\mathcal O}(n^{-3/4})$, thus narrowing the gap between\n$\\widetilde{\\mathcal O}(n^{-1})$ and $\\widetilde{\\mathcal O}(n^{-1/2})$, which\nwere hitherto the rates of the most statistically and computationally efficient\nmethods, respectively.\n", "versions": [{"version": "v1", "created": "Tue, 27 Feb 2018 15:26:15 GMT"}, {"version": "v2", "created": "Mon, 5 Mar 2018 04:19:26 GMT"}, {"version": "v3", "created": "Tue, 5 Jun 2018 15:52:59 GMT"}], "update_date": "2018-06-06", "authors_parsed": [["Mao", "Cheng", ""], ["Pananjady", "Ashwin", ""], ["Wainwright", "Martin J.", ""]]}, {"id": "1802.10024", "submitter": "Ryan Martin", "authors": "Yi Lin, Ryan Martin, Min Yang", "title": "On optimal designs for non-regular models", "comments": "23 pages of text; 3 figures; 11 pages of supplementary material", "journal-ref": "Annals of Statistics, 2019, volume 47, pages 3335--3359", "doi": "10.1214/18-AOS1780", "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classically, Fisher information is the relevant object in defining optimal\nexperimental designs. However, for models that lack certain regularity, the\nFisher information does not exist and, hence, there is no notion of design\noptimality available in the literature. This article seeks to fill the gap by\nproposing a so-called Hellinger information, which generalizes Fisher\ninformation in the sense that the two measures agree in regular problems, but\nthe former also exists for certain types of non-regular problems. We derive a\nHellinger information inequality, showing that Hellinger information defines a\nlower bound on the local minimax risk of estimators. This provides a connection\nbetween features of the underlying model---in particular, the design---and the\nperformance of estimators, motivating the use of this new Hellinger information\nfor non-regular optimal design problems. Hellinger optimal designs are derived\nfor several non-regular regression problems, with numerical results empirically\ndemonstrating the efficiency of these designs compared to alternatives.\n", "versions": [{"version": "v1", "created": "Tue, 27 Feb 2018 17:06:56 GMT"}, {"version": "v2", "created": "Sun, 27 Jan 2019 17:26:14 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Lin", "Yi", ""], ["Martin", "Ryan", ""], ["Yang", "Min", ""]]}, {"id": "1802.10163", "submitter": "S{\\o}ren Wengel Mogensen", "authors": "S{\\o}ren Wengel Mogensen and Niels Richard Hansen", "title": "Markov equivalence of marginalized local independence graphs", "comments": "49 pages (including supplementary material), updated to add examples\n  and fix typos", "journal-ref": "The Annals of Statistics 48(1), 2020, 539-559", "doi": "10.1214/19-AOS1821", "report-no": null, "categories": "math.ST stat.OT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Symmetric independence relations are often studied using graphical\nrepresentations. Ancestral graphs or acyclic directed mixed graphs with\n$m$-separation provide classes of symmetric graphical independence models that\nare closed under marginalization. Asymmetric independence relations appear\nnaturally for multivariate stochastic processes, for instance in terms of local\nindependence. However, no class of graphs representing such asymmetric\nindependence relations, which is also closed under marginalization, has been\ndeveloped. We develop the theory of directed mixed graphs with $\\mu$-separation\nand show that this provides a graphical independence model class which is\nclosed under marginalization and which generalizes previously considered\ngraphical representations of local independence.\n  For statistical applications, it is pivotal to characterize graphs that\ninduce the same independence relations as such a Markov equivalence class of\ngraphs is the object that is ultimately identifiable from observational data.\nOur main result is that for directed mixed graphs with $\\mu$-separation each\nMarkov equivalence class contains a maximal element which can be constructed\nfrom the independence relations alone. Moreover, we introduce the directed\nmixed equivalence graph as the maximal graph with edge markings. This graph\nencodes all the information about the edges that is identifiable from the\nindependence relations, and furthermore it can be computed efficiently from the\nmaximal graph.\n", "versions": [{"version": "v1", "created": "Tue, 27 Feb 2018 21:04:29 GMT"}, {"version": "v2", "created": "Mon, 11 Feb 2019 16:21:42 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Mogensen", "S\u00f8ren Wengel", ""], ["Hansen", "Niels Richard", ""]]}, {"id": "1802.10299", "submitter": "Xiaohui Liu", "authors": "Qing Liu and Xiaohui Liu", "title": "Limit theory for an AR(1) model with intercept and a possible infinite\n  variance", "comments": "21pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we derive the limit distribution of the least squares\nestimator for an AR(1) model with a non-zero intercept and a possible infinite\nvariance. It turns out that the estimator has a quite different limit for the\ncases of $|\\rho| < 1$, $|\\rho| > 1$, and $\\rho = 1 + \\frac{c}{n^\\alpha}$ for\nsome constant $c \\in R$ and $\\alpha \\in (0, 1]$, and whether or not the\nvariance of the model errors is infinite also has a great impact on both the\nconvergence rate and the limit distribution of the estimator.\n", "versions": [{"version": "v1", "created": "Wed, 28 Feb 2018 08:03:02 GMT"}], "update_date": "2018-03-01", "authors_parsed": [["Liu", "Qing", ""], ["Liu", "Xiaohui", ""]]}, {"id": "1802.10302", "submitter": "Xiaohui Liu", "authors": "Qing Liu and Xiaohui Liu", "title": "Bahadur representations for the bootstrap median absolute deviation and\n  the application to projection depth weighted mean", "comments": "23 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Median absolute deviation (hereafter MAD) is known as a robust alternative to\nthe ordinary variance. It has been widely utilized to induce robust statistical\ninferential procedures. In this paper, we investigate the strong and weak\nBahadur representations of its bootstrap counterpart. As a useful application,\nwe utilize the results to derive the weak Bahadur representation of the\nbootstrap sample projection depth weighted mean---a quite important location\nestimator depending on MAD.\n", "versions": [{"version": "v1", "created": "Wed, 28 Feb 2018 08:19:53 GMT"}], "update_date": "2018-03-01", "authors_parsed": [["Liu", "Qing", ""], ["Liu", "Xiaohui", ""]]}, {"id": "1802.10570", "submitter": "Thomai Tsiftsi", "authors": "Thomai Tsiftsi", "title": "Statistical shape analysis in a Bayesian framework for shapes in two and\n  three dimensions", "comments": "6 pages, 1 figure", "journal-ref": "In proceedings 31st International Workshop on Statistical\n  Modelling, 4-8 July 2016, Rennes, France. Amsterdam: Statistical Modelling\n  Society, pp. 309-314", "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.AP stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we describe a novel shape classification method which is\nembedded in the Bayesian paradigm. We discuss the modelling and the resulting\nshape classification algorithm for two and three dimensional data shapes. We\nconclude by evaluating the efficiency and efficacy of the proposed algorithm on\nthe Kimia shape database for the two dimensional case.\n", "versions": [{"version": "v1", "created": "Wed, 28 Feb 2018 18:20:12 GMT"}], "update_date": "2018-03-01", "authors_parsed": [["Tsiftsi", "Thomai", ""]]}, {"id": "1802.10575", "submitter": "Ilias Diakonikolas", "authors": "Timothy Carpenter, Ilias Diakonikolas, Anastasios Sidiropoulos,\n  Alistair Stewart", "title": "Near-Optimal Sample Complexity Bounds for Maximum Likelihood Estimation\n  of Multivariate Log-concave Densities", "comments": null, "journal-ref": "COLT 2018 proceedings version", "doi": null, "report-no": null, "categories": "math.ST cs.IT cs.LG math.IT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of learning multivariate log-concave densities with\nrespect to a global loss function. We obtain the first upper bound on the\nsample complexity of the maximum likelihood estimator (MLE) for a log-concave\ndensity on $\\mathbb{R}^d$, for all $d \\geq 4$. Prior to this work, no finite\nsample upper bound was known for this estimator in more than $3$ dimensions.\n  In more detail, we prove that for any $d \\geq 1$ and $\\epsilon>0$, given\n$\\tilde{O}_d((1/\\epsilon)^{(d+3)/2})$ samples drawn from an unknown log-concave\ndensity $f_0$ on $\\mathbb{R}^d$, the MLE outputs a hypothesis $h$ that with\nhigh probability is $\\epsilon$-close to $f_0$, in squared Hellinger loss. A\nsample complexity lower bound of $\\Omega_d((1/\\epsilon)^{(d+1)/2})$ was\npreviously known for any learning algorithm that achieves this guarantee. We\nthus establish that the sample complexity of the log-concave MLE is\nnear-optimal, up to an $\\tilde{O}(1/\\epsilon)$ factor.\n", "versions": [{"version": "v1", "created": "Wed, 28 Feb 2018 18:32:07 GMT"}, {"version": "v2", "created": "Wed, 5 Dec 2018 00:07:00 GMT"}], "update_date": "2018-12-06", "authors_parsed": [["Carpenter", "Timothy", ""], ["Diakonikolas", "Ilias", ""], ["Sidiropoulos", "Anastasios", ""], ["Stewart", "Alistair", ""]]}]