[{"id": "1811.00353", "submitter": "Rados{\\l}aw Adamczak", "authors": "Rados{\\l}aw Adamczak, Rafa{\\l} Lata{\\l}a, Rafa{\\l} Meller", "title": "Hanson-Wright inequality in Banach spaces", "comments": "MSC classification and acknowledgement added, minor typo corrected,\n  references updated", "journal-ref": "Ann. Inst. Henri Poincar\\'e Probab. Stat. 56 (2020), 2356-2376,", "doi": "10.1214/19-AIHP1041", "report-no": null, "categories": "math.PR math.FA math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss two-sided bounds for moments and tails of quadratic forms in\nGaussian random variables with values in Banach spaces. We state a natural\nconjecture and show that it holds up to additional logarithmic factors.\nMoreover in a certain class of Banach spaces (including $L_r$-spaces) these\nlogarithmic factors may be eliminated. As a corollary we derive upper bounds\nfor tails and moments of quadratic forms in subgaussian random variables, which\nextend the Hanson-Wright inequality.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 13:13:33 GMT"}, {"version": "v2", "created": "Sat, 4 Jan 2020 11:42:31 GMT"}, {"version": "v3", "created": "Thu, 20 Feb 2020 10:27:34 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Adamczak", "Rados\u0142aw", ""], ["Lata\u0142a", "Rafa\u0142", ""], ["Meller", "Rafa\u0142", ""]]}, {"id": "1811.00465", "submitter": "Victor-Emmanuel Brunel", "authors": "Victor-Emmanuel Brunel", "title": "Learning Signed Determinantal Point Processes through the Principal\n  Minor Assignment Problem", "comments": "Shorter version accepted at NIPS (Neural Information Processing\n  Systems) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Symmetric determinantal point processes (DPP's) are a class of probabilistic\nmodels that encode the random selection of items that exhibit a repulsive\nbehavior. They have attracted a lot of attention in machine learning, when\nreturning diverse sets of items is sought for. Sampling and learning these\nsymmetric DPP's is pretty well understood. In this work, we consider a new\nclass of DPP's, which we call signed DPP's, where we break the symmetry and\nallow attractive behaviors. We set the ground for learning signed DPP's through\na method of moments, by solving the so called principal assignment problem for\na class of matrices $K$ that satisfy $K_{i,j}=\\pm K_{j,i}$, $i\\neq j$, in\npolynomial time.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 16:06:10 GMT"}], "update_date": "2018-11-02", "authors_parsed": [["Brunel", "Victor-Emmanuel", ""]]}, {"id": "1811.00535", "submitter": "Guang Cheng", "authors": "Shengchun Kong, Zhuqing Yu, Xianyang Zhang, Guang Cheng", "title": "High Dimensional Robust Inference for Cox Regression Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider high-dimensional inference for potentially misspecified Cox\nproportional hazard models based on low dimensional results by Lin and Wei\n[1989]. A de-sparsified Lasso estimator is proposed based on the log partial\nlikelihood function and shown to converge to a pseudo-true parameter vector.\nInterestingly, the sparsity of the true parameter can be inferred from that of\nthe above limiting parameter. Moreover, each component of the above\n(non-sparse) estimator is shown to be asymptotically normal with a variance\nthat can be consistently estimated even under model misspecifications. In some\ncases, this asymptotic distribution leads to valid statistical inference\nprocedures, whose empirical performances are illustrated through numerical\nexamples.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 17:56:41 GMT"}], "update_date": "2018-11-02", "authors_parsed": [["Kong", "Shengchun", ""], ["Yu", "Zhuqing", ""], ["Zhang", "Xianyang", ""], ["Cheng", "Guang", ""]]}, {"id": "1811.00747", "submitter": "Simon Williams", "authors": "Simon Williams, Arthur George Suvorov, Wang Zeng Fu and Bill Moran", "title": "Information Geometry of Sensor Configuration", "comments": "submitted to Information Geometry 2018-11-02", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT eess.SP math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In problems of parameter estimation from sensor data, the Fisher Information\nprovides a measure of the performance of the sensor; effectively, in an\ninfinitesimal sense, how much information about the parameters can be obtained\nfrom the measurements. From the geometric viewpoint, it is a Riemannian metric\non the manifold of parameters of the observed system. In this paper we consider\nthe case of parameterized sensors and answer the question, \"How best to\nreconfigure a sensor (vary the parameters of the sensor) to optimize the\ninformation collected?\" A change in the sensor parameters results in a\ncorresponding change to the metric. We show that the change in information due\nto reconfiguration exactly corresponds to the natural metric on the infinite\ndimensional space of Riemannian metrics on the parameter manifold, restricted\nto finite-dimensional sub-manifold determined by the sensor parameters. The\ndistance measure on this configuration manifold is shown to provide optimal,\ndynamic sensor reconfiguration based on an information criterion. Geodesics on\nthe configuration manifold are shown to optimize the information gain but only\nif the change is made at a certain rate. An example of configuring two\nbearings-only sensors to optimally locate a target is developed in detail to\nillustrate the mathematical machinery, with Fast-Marching methods employed to\nefficiently calculate the geodesics and illustrate the practicality of using\nthis approach.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2018 05:53:00 GMT"}, {"version": "v2", "created": "Mon, 5 Nov 2018 02:59:29 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Williams", "Simon", ""], ["Suvorov", "Arthur George", ""], ["Fu", "Wang Zeng", ""], ["Moran", "Bill", ""]]}, {"id": "1811.00781", "submitter": "Avetik Karagulyan", "authors": "Avetik Karagulyan", "title": "Non-Asymptotic Guarantees For Sampling by Stochastic Gradient Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sampling from various kinds of distributions is an issue of paramount\nimportance in statistics since it is often the key ingredient for constructing\nestimators, test procedures or confidence intervals. In many situations, the\nexact sampling from a given distribution is impossible or computationally\nexpensive and, therefore, one needs to resort to approximate sampling\nstrategies. However, it is only very recently that a mathematical theory\nproviding non-asymptotic guarantees for approximate sampling problem in the\nhigh-dimensional settings started to be developed. In this paper we introduce a\nnew mathematical framework that helps to analyze the Stochastic Gradient\nDescent as a method of sampling, closely related to Langevin Monte-Carlo.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2018 08:51:02 GMT"}], "update_date": "2018-11-05", "authors_parsed": [["Karagulyan", "Avetik", ""]]}, {"id": "1811.00934", "submitter": "Ann-Kristin Becker", "authors": "Ann-Kristin Becker, Hajo Holzmann", "title": "Nonparametric identification in the dynamic stochastic block model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show nonparametric identification of the parameters in the dynamic\nstochastic block model as recently introduced in Matias and Miele (2017) in\ncase of binary, finitely weighted and general edge states. We formulate\nconditions on the true parameters which guarantee actual point identification\ninstead of mere generic identification, and which also lead to novel\nconclusions in the static case. In particular, our results justify in terms of\nidentification the applications in Matias and Miele (2017) to finitely weighted\nedges with three edge states. We also give numerical illustrations via the\nvariational EM algorithm in simulation settings covered by our identification\nanalysis.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2018 15:27:44 GMT"}], "update_date": "2018-11-05", "authors_parsed": [["Becker", "Ann-Kristin", ""], ["Holzmann", "Hajo", ""]]}, {"id": "1811.01061", "submitter": "Stephen Page", "authors": "Stephen Page and Steffen Gr\\\"unew\\\"alder", "title": "The Goldenshluger-Lepski Method for Constrained Least-Squares Estimators\n  over RKHSs", "comments": "50 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study an adaptive estimation procedure called the Goldenshluger-Lepski\nmethod in the context of reproducing kernel Hilbert space (RKHS) regression.\nAdaptive estimation provides a way of selecting tuning parameters for\nstatistical estimators using only the available data. This allows us to perform\nestimation without making strong assumptions about the estimand. In contrast to\nprocedures such as training and validation, the Goldenshluger-Lepski method\nuses all of the data to produce non-adaptive estimators for a range of values\nof the tuning parameters. An adaptive estimator is selected by performing\npairwise comparisons between these non-adaptive estimators. Applying the\nGoldenshluger-Lepski method is non-trivial as it requires a simultaneous\nhigh-probability bound on all of the pairwise comparisons. In the RKHS\nregression context, we choose our non-adaptive estimators to be clipped\nleast-squares estimators constrained to lie in a ball in an RKHS. Applying the\nGoldenshluger-Lepski method in this context is made more complicated by the\nfact that we cannot use the $L^2$ norm for performing the pairwise comparisons\nas it is unknown. We use the method to address two regression problems. In the\nfirst problem the RKHS is fixed, while in the second problem we adapt over a\ncollection of RKHSs.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2018 19:19:12 GMT"}, {"version": "v2", "created": "Thu, 10 Dec 2020 11:31:48 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Page", "Stephen", ""], ["Gr\u00fcnew\u00e4lder", "Steffen", ""]]}, {"id": "1811.01076", "submitter": "Rajen Shah", "authors": "Rajen D. Shah, Benjamin Frot, Gian-Andrea Thanei and Nicolai\n  Meinshausen", "title": "RSVP-graphs: Fast High-dimensional Covariance Matrix Estimation under\n  Latent Confounding", "comments": "49 pages; to appear in JRSSB", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we consider the problem of estimating a high-dimensional $p\n\\times p$ covariance matrix $\\Sigma$, given $n$ observations of confounded data\nwith covariance $\\Sigma + \\Gamma \\Gamma^T$, where $\\Gamma$ is an unknown $p\n\\times q$ matrix of latent factor loadings. We propose a simple and scalable\nestimator based on the projection on to the right singular vectors of the\nobserved data matrix, which we call RSVP. Our theoretical analysis of this\nmethod reveals that in contrast to PCA-based approaches, RSVP is able to cope\nwell with settings where the smallest eigenvalue of $\\Gamma^T \\Gamma$ is close\nto the largest eigenvalue of $\\Sigma$, as well as settings where the\neigenvalues of $\\Gamma^T \\Gamma$ are diverging fast. It is also able to handle\ndata that may have heavy tails and only requires that the data has an\nelliptical distribution. RSVP does not require knowledge or estimation of the\nnumber of latent factors $q$, but only recovers $\\Sigma$ up to an unknown\npositive scale factor. We argue this suffices in many applications, for example\nif an estimate of the correlation matrix is desired. We also show that by using\nsubsampling, we can further improve the performance of the method. We\ndemonstrate the favourable performance of RSVP through simulation experiments\nand an analysis of gene expression datasets collated by the GTEX consortium.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2018 20:23:20 GMT"}, {"version": "v2", "created": "Wed, 20 Mar 2019 10:24:30 GMT"}, {"version": "v3", "created": "Mon, 26 Aug 2019 16:00:42 GMT"}, {"version": "v4", "created": "Fri, 29 Nov 2019 20:07:48 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Shah", "Rajen D.", ""], ["Frot", "Benjamin", ""], ["Thanei", "Gian-Andrea", ""], ["Meinshausen", "Nicolai", ""]]}, {"id": "1811.01212", "submitter": "L\\'eo Miolane", "authors": "L\\'eo Miolane and Andrea Montanari", "title": "The distribution of the Lasso: Uniform control over sparse balls and\n  adaptive parameter tuning", "comments": "68 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Lasso is a popular regression method for high-dimensional problems in\nwhich the number of parameters $\\theta_1,\\dots,\\theta_N$, is larger than the\nnumber $n$ of samples: $N>n$. A useful heuristics relates the statistical\nproperties of the Lasso estimator to that of a simple soft-thresholding\ndenoiser,in a denoising problem in which the parameters $(\\theta_i)_{i\\le N}$\nare observed in Gaussian noise, with a carefully tuned variance. Earlier work\nconfirmed this picture in the limit $n,N\\to\\infty$, pointwise in the parameters\n$\\theta$, and in the value of the regularization parameter.\n  Here, we consider a standard random design model and prove exponential\nconcentration of its empirical distribution around the prediction provided by\nthe Gaussian denoising model. Crucially, our results are uniform with respect\nto $\\theta$ belonging to $\\ell_q$ balls, $q\\in [0,1]$, and with respect to the\nregularization parameter. This allows to derive sharp results for the\nperformances of various data-driven procedures to tune the regularization.\n  Our proofs make use of Gaussian comparison inequalities, and in particular of\na version of Gordon's minimax theorem developed by Thrampoulidis, Oymak, and\nHassibi, which controls the optimum value of the Lasso optimization problem.\nCrucially, we prove a stability property of the minimizer in Wasserstein\ndistance, that allows to characterize properties of the minimizer itself.\n", "versions": [{"version": "v1", "created": "Sat, 3 Nov 2018 13:28:40 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Miolane", "L\u00e9o", ""], ["Montanari", "Andrea", ""]]}, {"id": "1811.01261", "submitter": "Jonathan Levy", "authors": "Jonathan Levy", "title": "Canonical Least Favorable Submodels:A New TMLE Procedure for\n  Multidimensional Parameters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is a fundamental addition to the world of targeted maximum\nlikelihood estimation (TMLE) (or likewise, targeted minimum loss estimation)\nfor simultaneous estimation of multi-dimensional parameters of interest. TMLE,\nas part of the targeted learning framework, offers a crucial step in\nconstructing efficient plug-in estimators for nonparametric or semiparametric\nmodels. The so-called targeting step of targeted learning, involves fluctuating\nthe initial fit of the model in a way that maximally adjusts the plug-in\nestimate per change in the log likelihood. Previously for multidimensional\nparameters of interest, iterative TMLE's were constructed using locally least\nfavorable submodels as defined in van der Laan and Gruber, 2016, which are\nindexed by a multidimensional fluctuation parameter. In this paper we define a\ncanonical least favorable submodel in terms of a single dimensional epsilon for\na $d$-dimensional parameter of interest. One can view the clfm as the iterative\nanalog to the one-step TMLE as constructed in van der Laan and Gruber, 2016. It\nis currently implemented in several software packages we provide in the last\nsection. Using a single epsilon for the targeting step in TMLE could be useful\nfor high dimensional parameters, where using a fluctuation parameter of the\nsame dimension as the parameter of interest could suffer the consequences of\ncurse of dimensionality. The clfm also enables placing the so-called clever\ncovariate denominator as an inverse weight in an offset intercept model. It has\nbeen shown that such weighting mitigates the effect of large inverse weights\nsometimes caused by near positivity violations.\n", "versions": [{"version": "v1", "created": "Sat, 3 Nov 2018 18:06:44 GMT"}, {"version": "v2", "created": "Fri, 9 Nov 2018 03:02:41 GMT"}, {"version": "v3", "created": "Thu, 11 Apr 2019 04:29:09 GMT"}], "update_date": "2019-04-12", "authors_parsed": [["Levy", "Jonathan", ""]]}, {"id": "1811.01394", "submitter": "Koichi Tojo", "authors": "Koichi Tojo, Taro Yoshino", "title": "A method to construct exponential families by representation theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we give a method to construct \"good\" exponential families\nsystematically by representation theory. More precisely, we consider a\nhomogeneous space $G/H$ as a sample space and construct an exponential family\ninvariant under the transformation group $G$ by using a representation of $G$.\nThe method generates widely used exponential families such as normal, gamma,\nBernoulli, categorical, Wishart, von Mises, Fisher-Bingham and hyperboloid\ndistributions.\n", "versions": [{"version": "v1", "created": "Sun, 4 Nov 2018 16:08:07 GMT"}, {"version": "v2", "created": "Mon, 31 Dec 2018 12:17:34 GMT"}, {"version": "v3", "created": "Sat, 17 Aug 2019 08:05:07 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Tojo", "Koichi", ""], ["Yoshino", "Taro", ""]]}, {"id": "1811.01520", "submitter": "Wen-Xin Zhou", "authors": "Yuan Ke, Stanislav Minsker, Zhao Ren, Qiang Sun and Wen-Xin Zhou", "title": "User-Friendly Covariance Estimation for Heavy-Tailed Distributions", "comments": "56 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We offer a survey of recent results on covariance estimation for heavy-tailed\ndistributions. By unifying ideas scattered in the literature, we propose\nuser-friendly methods that facilitate practical implementation. Specifically,\nwe introduce element-wise and spectrum-wise truncation operators, as well as\ntheir $M$-estimator counterparts, to robustify the sample covariance matrix.\nDifferent from the classical notion of robustness that is characterized by the\nbreakdown property, we focus on the tail robustness which is evidenced by the\nconnection between nonasymptotic deviation and confidence level. The key\nobservation is that the estimators needs to adapt to the sample size,\ndimensionality of the data and the noise level to achieve optimal tradeoff\nbetween bias and robustness. Furthermore, to facilitate their practical use, we\npropose data-driven procedures that automatically calibrate the tuning\nparameters. We demonstrate their applications to a series of structured models\nin high dimensions, including the bandable and low-rank covariance matrices and\nsparse precision matrices. Numerical studies lend strong support to the\nproposed methods.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 05:53:22 GMT"}, {"version": "v2", "created": "Wed, 7 Nov 2018 05:26:23 GMT"}, {"version": "v3", "created": "Mon, 11 Mar 2019 05:19:26 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Ke", "Yuan", ""], ["Minsker", "Stanislav", ""], ["Ren", "Zhao", ""], ["Sun", "Qiang", ""], ["Zhou", "Wen-Xin", ""]]}, {"id": "1811.01714", "submitter": "Mor Absa Loum", "authors": "Benjamin Auder (LMO), Elisabeth Gassiat (LMO), Mor Absa Loum (LMO)", "title": "Least squares moment identification of binary regression mixtures models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider finite mixtures of generalized linear models with binary output.\nWe prove that cross moment (between the output and the regression variables)\nuntil order 3 are sufficient to identify all parameters of the model. We\npropose a least-squares estimation method based on those moments and we prove\nthe consistency and the Gaussian asymptotic behavior of the estimator. We\nprovide simulation results and comparisons with likelihood methods. Numerical\nexperiments were conducted using the R-package Morpheus that we developed for\nour least-squares moment method and with the R-package flexmix for likelihood\nmethods. We then give some possible extensions to finite mixtures of\nregressions with binary output including both continuous and categorical\ncovariates, and possibly longitudinal data.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 14:24:03 GMT"}, {"version": "v2", "created": "Wed, 12 Feb 2020 15:45:01 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Auder", "Benjamin", "", "LMO"], ["Gassiat", "Elisabeth", "", "LMO"], ["Loum", "Mor Absa", "", "LMO"]]}, {"id": "1811.01760", "submitter": "Junhong Lin", "authors": "Junhong Lin and Volkan Cevher", "title": "Kernel Conjugate Gradient Methods with Random Projections", "comments": "43 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.FA math.OC math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose and study kernel conjugate gradient methods (KCGM) with random\nprojections for least-squares regression over a separable Hilbert space.\nConsidering two types of random projections generated by randomized sketches\nand Nystr\\\"{o}m subsampling, we prove optimal statistical results with respect\nto variants of norms for the algorithms under a suitable stopping rule.\nParticularly, our results show that if the projection dimension is proportional\nto the effective dimension of the problem, KCGM with randomized sketches can\ngeneralize optimally, while achieving a computational advantage. As a\ncorollary, we derive optimal rates for classic KCGM in the case that the target\nfunction may not be in the hypothesis space, filling a theoretical gap.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 14:50:58 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Lin", "Junhong", ""], ["Cevher", "Volkan", ""]]}, {"id": "1811.02096", "submitter": "Po-Ling Loh", "authors": "Po-Ling Loh", "title": "Scale calibration for high-dimensional robust regression", "comments": "43 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new method for high-dimensional linear regression when a scale\nparameter of the additive errors is unknown. The proposed estimator is based on\na penalized Huber $M$-estimator, for which theoretical results on estimation\nerror have recently been proposed in high-dimensional statistics literature.\nHowever, the variance of the error term in the linear model is intricately\nconnected to the optimal parameter used to define the shape of the Huber loss.\nOur main idea is to use an adaptive technique, based on Lepski's method, to\novercome the difficulties in solving a joint nonconvex optimization problem\nwith respect to the location and scale parameters.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2018 00:07:17 GMT"}], "update_date": "2018-11-07", "authors_parsed": [["Loh", "Po-Ling", ""]]}, {"id": "1811.02201", "submitter": "William Leeb", "authors": "William Leeb and Elad Romanov", "title": "Optimal spectral shrinkage and PCA with heteroscedastic noise", "comments": null, "journal-ref": null, "doi": "10.1109/TIT.2021.3055075", "report-no": null, "categories": "stat.OT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the related problems of prediction, covariance estimation,\nand principal component analysis for the spiked covariance model with\nheteroscedastic noise. We consider an estimator of the principal components\nbased on whitening the noise, and we derive optimal singular value and\neigenvalue shrinkers for use with these estimated principal components.\nUnderlying these methods are new asymptotic results for the high-dimensional\nspiked model with heteroscedastic noise, and consistent estimators for the\nrelevant population parameters. We extend previous analysis on out-of-sample\nprediction to the setting of predictors with whitening. We demonstrate certain\nadvantages of noise whitening. Specifically, we show that in a certain\nasymptotic regime, optimal singular value shrinkage with whitening converges to\nthe best linear predictor, whereas without whitening it converges to a\nsuboptimal linear predictor. We prove that for generic signals, whitening\nimproves estimation of the principal components, and increases a natural\nsignal-to-noise ratio of the observations. We also show that for rank one\nsignals, our estimated principal components achieve the asymptotic minimax\nrate.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2018 07:22:50 GMT"}, {"version": "v2", "created": "Thu, 7 Feb 2019 21:04:09 GMT"}, {"version": "v3", "created": "Wed, 13 Nov 2019 16:25:37 GMT"}, {"version": "v4", "created": "Wed, 16 Sep 2020 22:09:34 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Leeb", "William", ""], ["Romanov", "Elad", ""]]}, {"id": "1811.02256", "submitter": "Wolfgang Trutschnig", "authors": "Thomas Mroz and Wolfgang Trutschnig", "title": "A sharp inequality for Kendall's $\\tau$ and Spearman's $\\rho$ of\n  Extreme-Value Copulas", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive a new (lower) inequality between Kendall's tau? and Spearman's rho?\nfor two-dimensional Extreme-Value Copulas, show that this inequality is sharp\nin each point and conclude that the comonotonic and the product copula are the\nonly Extreme-Value Copulas for which the well-known lower Hutchinson-Lai\ninequality is sharp.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2018 09:45:04 GMT"}], "update_date": "2018-11-07", "authors_parsed": [["Mroz", "Thomas", ""], ["Trutschnig", "Wolfgang", ""]]}, {"id": "1811.02547", "submitter": "Stefan Wager", "authors": "David A. Hirshberg and Stefan Wager", "title": "Debiased Inference of Average Partial Effects in Single-Index Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method for average partial effect estimation in high-dimensional\nsingle-index models that is root-n-consistent and asymptotically unbiased given\nsparsity assumptions on the underlying regression model. This note was prepared\nas a comment on Wooldridge and Zhu [2018], forthcoming in the Journal of\nBusiness and Economic Statistics.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2018 18:37:05 GMT"}], "update_date": "2018-11-07", "authors_parsed": [["Hirshberg", "David A.", ""], ["Wager", "Stefan", ""]]}, {"id": "1811.02596", "submitter": "Yakoub Boularouk", "authors": "Y.Boularouk and K.Djaballah", "title": "Consistency of quasi-maximum likelihood for processes with asymMetric\n  laplacian innovation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Strong consistency of the quasi-maximum likelihood estimator is given for a\ngeneral class of multidimensional causal processes based on asyMmetric\nlaplacian innovation.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2018 19:08:32 GMT"}], "update_date": "2018-11-08", "authors_parsed": [["Boularouk", "Y.", ""], ["Djaballah", "K.", ""]]}, {"id": "1811.02612", "submitter": "Chao Gao", "authors": "Bumeng Zhuo and Chao Gao", "title": "Mixing Time of Metropolis-Hastings for Bayesian Community Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the computational complexity of a Metropolis-Hastings algorithm for\nBayesian community detection. We first establish a posterior strong consistency\nresult for a natural prior distribution on stochastic block models under the\noptimal signal-to-noise ratio condition in the literature. We then give a set\nof conditions that guarantee rapid mixing of a simple Metropolis-Hastings\nalgorithm. The mixing time analysis is based on a careful study of posterior\nratios and a canonical path argument to control the spectral gap of the Markov\nchain.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2018 20:09:16 GMT"}], "update_date": "2018-11-08", "authors_parsed": [["Zhuo", "Bumeng", ""], ["Gao", "Chao", ""]]}, {"id": "1811.02663", "submitter": "Guy Martial Nkiet", "authors": "Emmanuel De Dieu Nkou and Guy Martial Nkiet", "title": "Strong consistency of kernel estimator in a semiparametric regression\n  model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating the effective dimension reduction (EDR) space, related to the\nsemiparametric regression model introduced by Li \\cite{sir}, is based on the\nestimation of the covariance matrix $\\Lambda$ of the conditional expectation of\nthe vector of predictors given the response. An estimator $\\widehat{\\Lambda}_n$\nof $\\Lambda $ based on kernel method was introduced by Zhu and Fang\n\\cite{Asymptotics} who then derived, under some conditions, the asymptotic\ndistribution of $\\sqrt{n}\\left(\\widehat{\\Lambda}_n-\\Lambda\\right)$, as\n$n\\rightarrow +\\infty$. In this paper, we obtain, under specified conditions,\nthe almost sure convergence of $\\widehat{\\Lambda}_n$ to $\\Lambda$, as\n$n\\rightarrow +\\infty$.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2018 21:27:39 GMT"}], "update_date": "2018-11-08", "authors_parsed": [["Nkou", "Emmanuel De Dieu", ""], ["Nkiet", "Guy Martial", ""]]}, {"id": "1811.02669", "submitter": "Guy Martial Nkiet", "authors": "Ulrich Djemby Bivigou and Guy Martial Nkiet", "title": "Robust multiple-set linear canonical analysis based on minimum\n  covariance determinant estimator", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By deriving influence functions related to multiple-set linear canonical\nanalysis (MSLCA) we show that the classical version of this analysis, based on\nempirical covariance operators, is not robust. Then, we introduce a robust\nversion of MSLCA by using the MCD estimator of the covariance operator of the\ninvolved random vector. The related influence functions are then derived and\nare shown to be bounded. Asymptotic properties of the introduced robust MSLCA\nare obtained and permit to propose a robust test for mutual non-correlation.\nThis test is shown to be robust by studying the related second order influence\nfunction under the null hypothesis.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2018 21:41:08 GMT"}], "update_date": "2018-11-08", "authors_parsed": [["Bivigou", "Ulrich Djemby", ""], ["Nkiet", "Guy Martial", ""]]}, {"id": "1811.02998", "submitter": "Martin Wahl", "authors": "Martin Wahl", "title": "A note on the prediction error of principal component regression", "comments": "24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyse the prediction error of principal component regression (PCR) and\nprove non-asymptotic upper bounds for the corresponding squared risk. Under\nmild assumptions, we show that PCR performs as well as the oracle method\nobtained by replacing empirical principal components by their population\ncounterparts. Our approach relies on upper bounds for the excess risk of\nprincipal component analysis.\n", "versions": [{"version": "v1", "created": "Wed, 7 Nov 2018 16:59:35 GMT"}, {"version": "v2", "created": "Tue, 16 Apr 2019 12:09:11 GMT"}], "update_date": "2019-04-17", "authors_parsed": [["Wahl", "Martin", ""]]}, {"id": "1811.03142", "submitter": "Snigdha Panigrahi", "authors": "Snigdha Panigrahi", "title": "Carving model-free inference", "comments": "50 pages, 2 figures, 6 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exploratory analyses mark a starting point for many scientific\ninvestigations, often carried out on pilot samples to find relevant parameters\nfor downstream inference. With the availability of fresh samples, construction\nof effect-size estimates for these parameters is a standard goal in\nconfirmatory analyses. Addressing the pitfalls of selection bias, a conditional\nperspective on inference-- via a data carved law-- offers an efficient way to\nreuse samples deployed during explorations. The principles of carving, in\npractice, apply very broadly to a wide range of generative schemes.\nNonetheless, the theory for valid inference is strongly tied to parametric\nmodels; an example being the ubiquitous Gaussian model. The results in this\npaper support model-free carved inference in an asymptotic sense.\n", "versions": [{"version": "v1", "created": "Wed, 7 Nov 2018 21:02:17 GMT"}, {"version": "v2", "created": "Sat, 5 Jan 2019 16:20:25 GMT"}, {"version": "v3", "created": "Mon, 29 Jun 2020 20:03:39 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Panigrahi", "Snigdha", ""]]}, {"id": "1811.03177", "submitter": "Younhun Kim", "authors": "Younhun Kim, Frederic Koehler, Ankur Moitra, Elchanan Mossel and\n  Govind Ramnarayan", "title": "How Many Subpopulations is Too Many? Exponential Lower Bounds for\n  Inferring Population Histories", "comments": "38 pages, Appeared in RECOMB 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE math.ST q-bio.QM stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reconstruction of population histories is a central problem in population\ngenetics. Existing coalescent-based methods, like the seminal work of Li and\nDurbin (Nature, 2011), attempt to solve this problem using sequence data but\nhave no rigorous guarantees. Determining the amount of data needed to correctly\nreconstruct population histories is a major challenge. Using a variety of tools\nfrom information theory, the theory of extremal polynomials, and approximation\ntheory, we prove new sharp information-theoretic lower bounds on the problem of\nreconstructing population structure -- the history of multiple subpopulations\nthat merge, split and change sizes over time. Our lower bounds are exponential\nin the number of subpopulations, even when reconstructing recent histories. We\ndemonstrate the sharpness of our lower bounds by providing algorithms for\ndistinguishing and learning population histories with matching dependence on\nthe number of subpopulations. Along the way and of independent interest, we\nessentially determine the optimal number of samples needed to learn an\nexponential mixture distribution information-theoretically, proving the upper\nbound by analyzing natural (and efficient) algorithms for this problem.\n", "versions": [{"version": "v1", "created": "Wed, 7 Nov 2018 23:00:15 GMT"}, {"version": "v2", "created": "Wed, 8 May 2019 15:24:19 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Kim", "Younhun", ""], ["Koehler", "Frederic", ""], ["Moitra", "Ankur", ""], ["Mossel", "Elchanan", ""], ["Ramnarayan", "Govind", ""]]}, {"id": "1811.03179", "submitter": "Tengyuan Liang", "authors": "Tengyuan Liang", "title": "How Well Generative Adversarial Networks Learn Distributions", "comments": "36 pages, 3 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the rates of convergence for learning distributions\nimplicitly with the adversarial framework and Generative Adversarial Networks\n(GAN), which subsume Wasserstein, Sobolev, MMD GAN, and Generalized/Simulated\nMethod of Moments (GMM/SMM) as special cases. We study a wide range of\nparametric and nonparametric target distributions, under a host of objective\nevaluation metrics. We investigate how to obtain a good statistical guarantee\nfor GANs through the lens of regularization. On the nonparametric end, we\nderive the optimal minimax rates for distribution estimation under the\nadversarial framework. On the parametric end, we establish a theory for general\nneural network classes (including deep leaky ReLU networks), that characterizes\nthe interplay on the choice of generator and discriminator pair. We discover\nand isolate a new notion of regularization, called the\ngenerator-discriminator-pair regularization, that sheds light on the advantage\nof GANs compared to classical parametric and nonparametric approaches for\nexplicit distribution estimation. We develop novel oracle inequalities as the\nmain technical tools for analyzing GANs, which is of independent interest.\n", "versions": [{"version": "v1", "created": "Wed, 7 Nov 2018 23:14:45 GMT"}, {"version": "v2", "created": "Tue, 4 Jun 2019 15:08:06 GMT"}, {"version": "v3", "created": "Mon, 24 Aug 2020 14:57:20 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Liang", "Tengyuan", ""]]}, {"id": "1811.03287", "submitter": "Ishfaq Shah Syed", "authors": "Deepesh Bhati and Ishfaq Shah Ahmad", "title": "A New Count Regression Model including Gauss Hypergeometric Function\n  with an application to model demand of health services", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, an alternative count distribution suitable for modeling over\ndispersed, zero vertex unimodality and monotonically decreasing data sets.\nThough the proposed probability model includes Gauss Hypergeometric special\nfunction, it possesses simple and closed expressions for various distributional\ncharacteristics. An application to count regression modeling using a well-known\ndata set from the National Medical Expenditure Survey is discussed by\nconsidering the length of stay in hospitalization as a dependent variable and\nfollowing the proposed count model. We compare our result with the classical\nNegative Binomial regression model and recently proposed Uniform Poisson\nregression model.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2018 06:23:36 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Bhati", "Deepesh", ""], ["Ahmad", "Ishfaq Shah", ""]]}, {"id": "1811.03472", "submitter": "Maryna Prus", "authors": "Maryna Prus", "title": "Optimal Designs for Minimax-Criteria in Random Coefficient Regression\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider minimax-optimal designs for the prediction of individual\nparameters in random coefficient regression models. We focus on the\nminimax-criterion, which minimizes the \"worst case\" for the basic criterion\nwith respect to the covariance matrix of random effects. We discuss particular\nmodels: linear and quadratic regression, in detail.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2018 14:52:27 GMT"}], "update_date": "2018-11-09", "authors_parsed": [["Prus", "Maryna", ""]]}, {"id": "1811.03735", "submitter": "Lu Zhang", "authors": "Lu Zhang, Sudipto Banerjee", "title": "A Note on the comparison of Nearest Neighbor Gaussian Process (NNGP)\n  based models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This note is devoted to the comparison between two Nearest-neighbor Gaussian\nprocesses (NNGP) based models: the response NNGP model and the latent NNGP\nmodel. We exhibit that the comparison based on the Kullback-Leibler divergence\n(KL-D) from the NNGP based models to their parent GP based model can result in\nreverse conclusions in different parameter spaces. And we suggest a heuristic\nexplanation on the phenomenon that the latent NNGP model tends to outperform\nthe response NNGP model in approximating their parent GP based model.\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2018 01:56:09 GMT"}], "update_date": "2018-11-12", "authors_parsed": [["Zhang", "Lu", ""], ["Banerjee", "Sudipto", ""]]}, {"id": "1811.03745", "submitter": "Jonathan Levy", "authors": "Jonathan Levy and Mark van der Laan and Alan Hubbard and Romain\n  Pirracchio", "title": "A Fundamental Measure of Treatment Effect Heterogeneity", "comments": "Presented at JSM 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We offer a non-parametric plug-in estimator for an important measure of\ntreatment effect variability and provide minimum conditions under which the\nestimator is asymptotically efficient. The stratum specific treatment effect\nfunction or so-called blip function, is the average treatment effect for a\nrandomly drawn stratum of confounders. The mean of the blip function is the\naverage treatment effect (ATE), whereas the variance of the blip function\n(VTE), the main subject of this paper, measures overall clinical effect\nheterogeneity, perhaps providing a strong impetus to refine treatment based on\nthe confounders. VTE is also an important measure for assessing reliability of\nthe treatment for an individual. The CV-TMLE provides simultaneous plug-in\nestimates and inference for both ATE and VTE, guaranteeing asymptotic\nefficiency under one less condition than for TMLE. This condition is difficult\nto guarantee a priori, particularly when using highly adaptive machine learning\nthat we need to employ in order to eliminate bias. Even in defiance of this\ncondition, CV-TMLE sampling distributions maintain normality, not guaranteed\nfor TMLE, and have a lower mean squared error than their TMLE counterparts. In\naddition to verifying the theoretical properties of TMLE and CV-TMLE through\nsimulations, we point out some of the challenges in estimating VTE, which lacks\ndouble robustness and might be unavoidably biased if the true VTE is small and\nsample size insufficient. We will provide an application of the estimator on a\ndata set for treatment of acute trauma patients.\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2018 02:39:38 GMT"}, {"version": "v2", "created": "Sat, 17 Nov 2018 08:07:58 GMT"}, {"version": "v3", "created": "Sun, 23 Dec 2018 09:58:22 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Levy", "Jonathan", ""], ["van der Laan", "Mark", ""], ["Hubbard", "Alan", ""], ["Pirracchio", "Romain", ""]]}, {"id": "1811.03918", "submitter": "Lei Yu", "authors": "Lei Yu", "title": "On Conditional Correlations", "comments": "20 pages. The application of our results on conditional correlations\n  to the non-interactive simulation problem was added", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Pearson correlation, correlation ratio, and maximal correlation have been\nwell-studied in the literature. In this paper, we study the conditional\nversions of these quantities. We extend the most important properties of the\nunconditional versions to the conditional versions, and also derive some new\nproperties. Based on the conditional maximal correlation, we define an\ninformation-correlation function of two arbitrary random variables, and use it\nto derive an impossibility result for the problem of the non-interactive\nsimulation of random variables.\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2018 14:23:34 GMT"}, {"version": "v2", "created": "Sun, 26 May 2019 07:21:25 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Yu", "Lei", ""]]}, {"id": "1811.03936", "submitter": "Liyan Xie", "authors": "Liyan Xie, Yao Xie, George V. Moustakides", "title": "Sequential Subspace Change-Point Detection", "comments": null, "journal-ref": "Sequential Analysis 39 (2020): 307-335", "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the online monitoring of multivariate streaming data for changes\nthat are characterized by an unknown subspace structure manifested in the\ncovariance matrix. In particular, we consider the covariance structure changes\nfrom an identity matrix to an unknown spiked covariance model. We assume the\npost-change distribution is unknown, and propose two detection procedures: the\nLargest-Eigenvalue Shewhart chart and the Subspace-CUSUM detection procedure.\nWe present theoretical approximations to the average run length (ARL) and the\nexpected detection delay (EDD) for the Largest-Eigenvalue Shewhart chart and\nalso provide analysis for tuning parameters of the Subspace-CUSUM procedure.\nThe performance of the proposed methods is illustrated using simulation and\nreal data for human gesture detection and seismic event detection.\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2018 14:56:27 GMT"}, {"version": "v2", "created": "Fri, 9 Apr 2021 16:00:05 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Xie", "Liyan", ""], ["Xie", "Yao", ""], ["Moustakides", "George V.", ""]]}, {"id": "1811.03946", "submitter": "Anuran Makur", "authors": "Anuran Makur and Elchanan Mossel and Yury Polyanskiy", "title": "Broadcasting on Random Directed Acyclic Graphs", "comments": "33 pages, double column format. arXiv admin note: text overlap with\n  arXiv:1803.07527", "journal-ref": "IEEE Transactions on Information Theory, vol. 66, no. 2, Feb. 2020", "doi": "10.1109/TIT.2019.2935772", "report-no": null, "categories": "cs.IT math.IT math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a generalization of the well-known model of broadcasting on trees.\nConsider a directed acyclic graph (DAG) with a unique source vertex $X$, and\nsuppose all other vertices have indegree $d\\geq 2$. Let the vertices at\ndistance $k$ from $X$ be called layer $k$. At layer $0$, $X$ is given a random\nbit. At layer $k\\geq 1$, each vertex receives $d$ bits from its parents in\nlayer $k-1$, which are transmitted along independent binary symmetric channel\nedges, and combines them using a $d$-ary Boolean processing function. The goal\nis to reconstruct $X$ with probability of error bounded away from $1/2$ using\nthe values of all vertices at an arbitrarily deep layer. This question is\nclosely related to models of reliable computation and storage, and information\nflow in biological networks.\n  In this paper, we analyze randomly constructed DAGs, for which we show that\nbroadcasting is only possible if the noise level is below a certain degree and\nfunction dependent critical threshold. For $d\\geq 3$, and random DAGs with\nlayer sizes $\\Omega(\\log k)$ and majority processing functions, we identify the\ncritical threshold. For $d=2$, we establish a similar result for NAND\nprocessing functions. We also prove a partial converse for odd $d\\geq 3$\nillustrating that the identified thresholds are impossible to improve by\nselecting different processing functions if the decoder is restricted to using\na single vertex.\n  Finally, for any noise level, we construct explicit DAGs (using expander\ngraphs) with bounded degree and layer sizes $\\Theta(\\log k)$ admitting\nreconstruction. In particular, we show that such DAGs can be generated in\ndeterministic quasi-polynomial time or randomized polylogarithmic time in the\ndepth. These results portray a doubly-exponential advantage for storing a bit\nin DAGs compared to trees, where $d=1$ but layer sizes must grow exponentially\nwith depth in order to enable broadcasting.\n", "versions": [{"version": "v1", "created": "Wed, 7 Nov 2018 22:26:54 GMT"}, {"version": "v2", "created": "Fri, 31 May 2019 10:37:18 GMT"}, {"version": "v3", "created": "Mon, 9 Mar 2020 05:09:32 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Makur", "Anuran", ""], ["Mossel", "Elchanan", ""], ["Polyanskiy", "Yury", ""]]}, {"id": "1811.04058", "submitter": "Matteo Giordano", "authors": "Matteo Giordano and Hanne Kekkonen", "title": "Bernstein-von Mises theorems and uncertainty quantification for linear\n  inverse problems", "comments": "34 pages, to appear in SIAM/ASA Journal on Uncertainty Quantification\n  (JUQ)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the statistical inverse problem of recovering an unknown function\n$f$ from a linear measurement corrupted by additive Gaussian white noise. We\nemploy a nonparametric Bayesian approach with standard Gaussian priors, for\nwhich the posterior-based reconstruction of $f$ corresponds to a Tikhonov\nregulariser $\\bar f$ with a reproducing kernel Hilbert space norm penalty. We\nprove a semiparametric Bernstein-von Mises theorem for a large collection of\nlinear functionals of $f$, implying that semiparametric posterior estimation\nand uncertainty quantification are valid and optimal from a frequentist point\nof view. The result is applied to study three concrete examples that cover both\nthe mildly and severely ill-posed cases: specifically, an elliptic inverse\nproblem, an elliptic boundary value problem and the heat equation. For the\nelliptic boundary value problem, we also obtain a nonparametric version of the\ntheorem that entails the convergence of the posterior distribution to a\nprior-independent infinite-dimensional Gaussian probability measure with\nminimal covariance. As a consequence, it follows that the Tikhonov regulariser\n$\\bar f$ is an efficient estimator of $f$, and we derive frequentist guarantees\nfor certain credible balls centred at $\\bar{f}$.\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2018 18:36:06 GMT"}, {"version": "v2", "created": "Wed, 4 Sep 2019 16:56:20 GMT"}, {"version": "v3", "created": "Wed, 4 Dec 2019 16:11:31 GMT"}, {"version": "v4", "created": "Fri, 17 Jan 2020 16:07:50 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["Giordano", "Matteo", ""], ["Kekkonen", "Hanne", ""]]}, {"id": "1811.04121", "submitter": "Pierre C. Bellec", "authors": "Pierre C Bellec and Cun-Hui Zhang", "title": "Second order Stein: SURE for SURE and other applications in\n  high-dimensional inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stein's formula states that a random variable of the form $z^\\top f(z) -\n\\text{div} f(z)$ is mean-zero for functions $f$ with integrable gradient. Here,\n$\\text{div} f$ is the divergence of the function $f$ and $z$ is a standard\nnormal vector. This paper aims to propose a Second Order Stein formula to\ncharacterize the variance of such random variables for all functions $f(z)$\nwith square integrable gradient, and to demonstrate the usefulness of this\nformula in various applications.\n  In the Gaussian sequence model, a consequence of Stein's formula is Stein's\nUnbiased Risk Estimate (SURE), an unbiased estimate of the mean squared risk\nfor almost any estimator $\\hat\\mu$ of the unknown mean. A first application of\nthe Second Order Stein formula is an Unbiased Risk Estimate for SURE itself\n(SURE for SURE): an unbiased estimate {providing} information about the squared\ndistance between SURE and the squared estimation error of $\\hat\\mu$. SURE for\nSURE has a simple form as a function of the data and is applicable to all\n$\\hat\\mu$ with square integrable gradient, e.g. the Lasso and the Elastic Net.\n  In addition to SURE for SURE, the following applications are developed: (1)\nUpper bounds on the risk of SURE when the estimation target is the mean squared\nerror; (2) Confidence regions based on SURE; (3) Oracle inequalities satisfied\nby SURE-tuned estimates; (4) An upper bound on the variance of the size of the\nmodel selected by the Lasso; (5) Explicit expressions of SURE for SURE for the\nLasso and the Elastic-Net; (6) In the linear model, a general semi-parametric\nscheme to de-bias a differentiable initial estimator for inference of a\nlow-dimensional projection of the unknown $\\beta$, with a characterization of\nthe variance after de-biasing; and (7) An accuracy analysis of a Gaussian Monte\nCarlo scheme to approximate the divergence of functions $f: R^n\\to R^n$.\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2018 20:08:43 GMT"}, {"version": "v2", "created": "Sat, 17 Nov 2018 23:53:30 GMT"}, {"version": "v3", "created": "Wed, 28 Aug 2019 22:40:44 GMT"}, {"version": "v4", "created": "Fri, 7 Feb 2020 04:30:10 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Bellec", "Pierre C", ""], ["Zhang", "Cun-Hui", ""]]}, {"id": "1811.04140", "submitter": "Edsel Pena", "authors": "Edsel A. Pena and Taeho Kim", "title": "Median Confidence Regions in a Nonparametric Model", "comments": null, "journal-ref": "Electronic Journal of Statistics, Vol 13, 2019, 2348-2390", "doi": "10.1214/19-EJS1577", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of constructing confidence regions for the median in the\nnonparametric measurement error model (NMEM) is considered. This problem arises\nin many settings, including inference about the median lifetime of a complex\nsystem arising in engineering, reliability, biomedical, and public health\nsettings. Current methods of constructing CRs are discussed, including the\nT-statistic based CR and the Wilcoxon signed-rank statistic based CR, arguably\nthe two default methods in applied work when a confidence interval about the\ncenter of a distribution is desired. Optimal equivariant CRs are developed with\nfocus on subclasses of of the class of all distributions. Applications to a\nreal car mileage efficiency data set and Proschan's air-conditioning data set\nare demonstrated. Simulation studies to compare the performances of the\ndifferent CR methods were undertaken. Results of these studies indicate that\nthe sign-statistic based CR and the optimal CR focused on symmetric\ndistributions satisfy the confidence level requirement, though they tended to\nhave higher contents; while two of the bootstrap-based CR procedures and one of\nthe developed adaptive CR tended to be a tad more liberal but with smaller\ncontents. A critical recommendation is that, under the NMEM, both the\nT-statistic based and Wilcoxon signed-rank statistic based confidence regions\nshould not be used since they have degraded confidence levels and/or inflated\ncontents.\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2018 21:29:53 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Pena", "Edsel A.", ""], ["Kim", "Taeho", ""]]}, {"id": "1811.04258", "submitter": "Mohamad Kazem Shirani Faradonbeh", "authors": "Mohamad Kazem Shirani Faradonbeh, Ambuj Tewari, and George Michailidis", "title": "Input Perturbations for Adaptive Control and Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.RO cs.SY math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies adaptive algorithms for simultaneous regulation (i.e.,\ncontrol) and estimation (i.e., learning) of Multiple Input Multiple Output\n(MIMO) linear dynamical systems. It proposes practical, easy to implement\ncontrol policies based on perturbations of input signals. Such policies are\nshown to achieve a worst-case regret that scales as the square-root of the time\nhorizon, and holds uniformly over time. Further, it discusses specific settings\nwhere such greedy policies attain the information theoretic lower bound of\nlogarithmic regret. To establish the results, recent advances on\nself-normalized martingales together with a novel method of policy\ndecomposition are leveraged.\n", "versions": [{"version": "v1", "created": "Sat, 10 Nov 2018 14:20:15 GMT"}, {"version": "v2", "created": "Sat, 6 Jul 2019 17:51:48 GMT"}, {"version": "v3", "created": "Wed, 4 Mar 2020 00:02:42 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Faradonbeh", "Mohamad Kazem Shirani", ""], ["Tewari", "Ambuj", ""], ["Michailidis", "George", ""]]}, {"id": "1811.04286", "submitter": "Michael Fauss", "authors": "Michael Fauss, Abdelhak M. Zoubir, H. Vincent Poor", "title": "Minimax Optimal Sequential Hypothesis Tests for Markov Processes", "comments": "43 pages, 5 figures, 2 tables", "journal-ref": "Annals of Statistics, vol. 48, no. 5, pp. 2599--2621, 2020", "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Under mild Markov assumptions, sufficient conditions for strict minimax\noptimality of sequential tests for multiple hypotheses under distributional\nuncertainty are derived. First, the design of optimal sequential tests for\nsimple hypotheses is revisited and it is shown that the partial derivatives of\nthe corresponding cost function are closely related to the performance metrics\nof the underlying sequential test. Second, an implicit characterization of the\nleast favorable distributions for a given testing policy is stated. By\ncombining the results on optimal sequential tests and least favorable\ndistributions, sufficient conditions for a sequential test to be minimax\noptimal under general distributional uncertainties are obtained. The cost\nfunction of the minimax optimal test is further identified as a generalized\n$f$-dissimilarity and the least favorable distributions as those that are most\nsimilar with respect to this dissimilarity. Numerical examples for minimax\noptimal sequential tests under different uncertainties illustrate the\ntheoretical results.\n", "versions": [{"version": "v1", "created": "Sat, 10 Nov 2018 17:31:17 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 22:17:17 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Fauss", "Michael", ""], ["Zoubir", "Abdelhak M.", ""], ["Poor", "H. Vincent", ""]]}, {"id": "1811.04423", "submitter": "Nan Wu", "authors": "Hau-tieng Wu and Nan Wu", "title": "When Locally Linear Embedding Hits Boundary", "comments": "11 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Based on the Riemannian manifold model, we study the asymptotic behavior of a\nwidely applied unsupervised learning algorithm, locally linear embedding (LLE),\nwhen the point cloud is sampled from a compact, smooth manifold with boundary.\nWe show several peculiar behaviors of LLE near the boundary that are different\nfrom those diffusion-based algorithms. Particularly, LLE converges to a\nmixed-type differential operator with degeneracy. This study leads to an\nalternative boundary detection algorithm and two potential approaches to\nrecover the Dirichlet Laplace-Beltrami operator.\n", "versions": [{"version": "v1", "created": "Sun, 11 Nov 2018 14:30:10 GMT"}, {"version": "v2", "created": "Fri, 15 Feb 2019 02:48:06 GMT"}], "update_date": "2019-02-18", "authors_parsed": [["Wu", "Hau-tieng", ""], ["Wu", "Nan", ""]]}, {"id": "1811.04522", "submitter": "Jae Youn Ahn", "authors": "Woojoo Lee, Jeonghwan Kim, Jae Youn Ahn", "title": "The Poisson random effect model for experience ratemaking: limitations\n  and alternative solutions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Poisson random effect models with a shared random effect have been widely\nused in actuarial science for analyzing the number of claims. In particular,\nthe random effect is a key factor in a posteriori risk classification. However,\nthe necessity of the random effect may not be properly assessed due to the dual\nrole of the random effect; it affects both the marginal distribution of the\nnumber of claims and the dependence among the numbers of claims obtained from\nan individual over time. In line with such observations, we explain that one\nshould be careful in using the score test for the nullity of the variance of\nthe shared random effect, as a sufficient condition for the existence of the\nposteriori risk classification. To safely perform the a posteriori risk\nclassification, we propose considering an alternative random effect model based\non the negative binomial distribution, and show that safer conclusions about\nthe a posteriori risk classification can be made based on it. We also derive\nthe score test as a sufficient condition for the existence of the a posteriori\nrisk classification based on the proposed model.\n", "versions": [{"version": "v1", "created": "Mon, 12 Nov 2018 01:03:45 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Lee", "Woojoo", ""], ["Kim", "Jeonghwan", ""], ["Ahn", "Jae Youn", ""]]}, {"id": "1811.04565", "submitter": "Mahdi Teimouri Yanesari", "authors": "Mahdi Teimouri", "title": "Statistical Inference for Stable Distribution Using EM algorithm", "comments": "3 Figures, 1 Table", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The class of $\\alpha$-stable distributions with a wide range of applications\nin economics, telecommunications, biology, applied, and theoretical physics.\nThis is due to the fact that it possesses both the skewness and heavy tails.\nSince $\\alpha$-stable distribution suffers from a closed-form expression for\ndensity function, finding efficient estimators for its parameters has attracted\na great deal of attention in the literature. Here, we propose some EM algorithm\nto estimate the maximum likelihood estimators of the parameters of\n$\\alpha$-stable distribution. The performance of the proposed EM algorithm is\ndemonstrated via comparison study in the presence of other well-known\ncompetitors and analyzing three sets of real data.\n", "versions": [{"version": "v1", "created": "Mon, 12 Nov 2018 05:45:54 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Teimouri", "Mahdi", ""]]}, {"id": "1811.04685", "submitter": "Xin Qin", "authors": "Xin Qin and Jyotirmoy V. Deshmukh", "title": "Joint Probability Distribution of Prediction Errors of ARIMA", "comments": "Revised notations, 16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Producing probabilistic guarantee for several steps of a predicted signal\nfollow a temporal logic defined behavior has its rising importance in\nmonitoring. In this paper, we derive a method to compute the joint probability\ndistribution of prediction errors of multiple steps based on Autoregressive\nIntegrated Moving Average(ARIMA) model. We cover scenarios in stationary\nprocess and intrinsically stationary process for univariate and multivariate.\n", "versions": [{"version": "v1", "created": "Mon, 12 Nov 2018 12:16:46 GMT"}, {"version": "v2", "created": "Fri, 11 Jan 2019 23:50:24 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Qin", "Xin", ""], ["Deshmukh", "Jyotirmoy V.", ""]]}, {"id": "1811.04866", "submitter": "Peter Jupp", "authors": "P. E. Jupp and A. Kume", "title": "Measures of goodness of fit obtained by canonical transformations on\n  Riemannian manifolds", "comments": "19 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The standard method of transforming a continuous distribution on the line to\nthe uniform distribution on the unit interval is the probability integral\ntransform. Analogous transforms exist on compact Riemannian manifolds, in that,\nfor each distribution with continuous positive density, there is a continuous\nmapping of the manifold to itself that transforms the distribution into the\nuniform distribution. In general, this mapping is far from unique. We introduce\na construction of a version of such a probability integral that is almost\ncanonical. The construction is extended to shape spaces, Cartan-Hadamard\nmanifolds, and simplices.\n  The probability integral transform is used to derive tests of goodness of fit\nfrom tests of uniformity. Illustrative examples of these tests of goodness of\nfit are given involving (i) Fisher distributions on the 2-sphere, (ii)\nisotropic Mardia-Dryden distributions on the shape space of triangles in the\nplane. Their behaviour is investigated by simulation.\n", "versions": [{"version": "v1", "created": "Mon, 12 Nov 2018 17:16:03 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Jupp", "P. E.", ""], ["Kume", "A.", ""]]}, {"id": "1811.05076", "submitter": "Miaoyan Wang", "authors": "Miaoyan Wang and Lexin Li", "title": "Learning from Binary Multiway Data: Probabilistic Tensor Decomposition\n  and its Statistical Optimality", "comments": "35 pages, 7 figures, 4 tables", "journal-ref": "Journal of Machine Learning Research, 21(154): 1-38, 2020", "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of decomposing a higher-order tensor with binary\nentries. Such data problems arise frequently in applications such as\nneuroimaging, recommendation system, topic modeling, and sensor network\nlocalization. We propose a multilinear Bernoulli model, develop a\nrank-constrained likelihood-based estimation method, and obtain the theoretical\naccuracy guarantees. In contrast to continuous-valued problems, the binary\ntensor problem exhibits an interesting phase transition phenomenon according to\nthe signal-to-noise ratio. The error bound for the parameter tensor estimation\nis established, and we show that the obtained rate is minimax optimal under the\nconsidered model. Furthermore, we develop an alternating optimization algorithm\nwith convergence guarantees. The efficacy of our approach is demonstrated\nthrough both simulations and analyses of multiple data sets on the tasks of\ntensor completion and clustering.\n", "versions": [{"version": "v1", "created": "Tue, 13 Nov 2018 02:49:17 GMT"}, {"version": "v2", "created": "Tue, 17 Sep 2019 04:48:47 GMT"}, {"version": "v3", "created": "Sun, 20 Sep 2020 04:05:02 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Wang", "Miaoyan", ""], ["Li", "Lexin", ""]]}, {"id": "1811.05124", "submitter": "Zheng Gao", "authors": "Zheng Gao, Stilian Stoev", "title": "Fundamental Limits of Exact Support Recovery in High Dimensions", "comments": "42 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the support recovery problem for a high-dimensional signal observed\nwith additive noise. With suitable parametrization of the signal sparsity and\nmagnitude of its non-zero components, we characterize a phase-transition\nphenomenon akin to the signal detection problem studied by Ingster in 1998.\nSpecifically, if the signal magnitude is above the so-called strong\nclassification boundary, we show that several classes of well-known procedures\nachieve asymptotically perfect support recovery as the dimension goes to\ninfinity. This is so, for a very broad class of error distributions with light,\nrapidly varying tails which may have arbitrary dependence. Conversely, if the\nsignal is below the boundary, then for a very broad class of error dependence\nstructures, no thresholding estimators (including ones with data-dependent\nthresholds) can achieve perfect support recovery. The proofs of these results\nexploit a certain concentration of maxima phenomenon known as relative\nstability. We provide a complete characterization of the relative stability\nphenomenon for Gaussian triangular arrays in terms their correlation structure.\nThe proof uses classic Sudakov-Fernique and Slepian lemma arguments along with\na curious application of Ramsey's coloring theorem.\n  We note that our study of the strong classification boundary is in a finer,\npoint-wise, rather than minimax, sense. We also establish the Bayes optimality\nand sub-optimality of thresholding procedures. Consequently, we obtain a\nminimax-type characterization of the strong classification boundary for errors\nwith log-concave densities.\n", "versions": [{"version": "v1", "created": "Tue, 13 Nov 2018 06:34:10 GMT"}, {"version": "v2", "created": "Fri, 16 Nov 2018 19:41:53 GMT"}, {"version": "v3", "created": "Sat, 24 Nov 2018 04:28:22 GMT"}, {"version": "v4", "created": "Mon, 15 Apr 2019 15:52:50 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Gao", "Zheng", ""], ["Stoev", "Stilian", ""]]}, {"id": "1811.05319", "submitter": "Evgeny Pchelintsev", "authors": "Evgeny Pchelintsev and Serguei Pergamenshchikov", "title": "Adaptive model selection method for a conditionally Gaussian\n  semimartingale regression in continuous time", "comments": "50 pages, 2 figures. arXiv admin note: text overlap with\n  arXiv:1710.03111, arXiv:1712.06454", "journal-ref": null, "doi": "10.17223/19988621/58/2", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the problem of robust adaptive efficient estimating of a\nperiodic function in a continuous time regression model with the dependent\nnoises given by a general square integrable semimartingale with a conditionally\nGaussian distribution. An example of such noise is the non-Gaussian\nOrnstein-Uhlenbeck-Levy processes. An adaptive model selection procedure, based\non the improved weighted least square estimates, is proposed. Under some\nconditions on the noise distribution, sharp oracle inequality for the robust\nrisk has been proved and the robust efficiency of the model selection procedure\nhas been established. The numerical analysis results are given.\n", "versions": [{"version": "v1", "created": "Sun, 11 Nov 2018 17:30:12 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Pchelintsev", "Evgeny", ""], ["Pergamenshchikov", "Serguei", ""]]}, {"id": "1811.05336", "submitter": "Xingwei Hu Dr", "authors": "Xingwei Hu", "title": "On Asymptotic Covariances of A Few Unrotated Factor Solutions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we provide explicit formulas, in terms of the covariances of\nsample covariances or sample correlations, for the asymptotic covariances of\nunrotated factor loading estimates and unique variance estimates. These\nestimates are extracted from least square, principal, iterative principal\ncomponent, alpha or image factor analysis. If the sample is taken from a\nmultivariate normal population, these formulas, together with the delta\nmethods, will produce the standard errors for the rotated loading estimates. A\nsimulation study shows that the formulas provide reasonable results.\n", "versions": [{"version": "v1", "created": "Mon, 12 Nov 2018 05:10:11 GMT"}], "update_date": "2018-11-14", "authors_parsed": [["Hu", "Xingwei", ""]]}, {"id": "1811.05379", "submitter": "Hirofumi Ota", "authors": "Hirofumi Ota, Kengo Kato, Satoshi Hara", "title": "Quantile regression approach to conditional mode estimation", "comments": "This paper supersedes \"On estimation of conditional modes using\n  multiple quantile regressions\" (Hirofumi Ohta and Satoshi Hara,\n  arXiv:1712.08754)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider estimation of the conditional mode of an outcome\nvariable given regressors. To this end, we propose and analyze a\ncomputationally scalable estimator derived from a linear quantile regression\nmodel and develop asymptotic distributional theory for the estimator.\nSpecifically, we find that the pointwise limiting distribution is a scale\ntransformation of Chernoff's distribution despite the presence of regressors.\nIn addition, we consider analytical and subsampling-based confidence intervals\nfor the proposed estimator. We also conduct Monte Carlo simulations to assess\nthe finite sample performance of the proposed estimator together with the\nanalytical and subsampling confidence intervals. Finally, we apply the proposed\nestimator to predicting the net hourly electrical energy output using Combined\nCycle Power Plant Data.\n", "versions": [{"version": "v1", "created": "Tue, 13 Nov 2018 16:06:12 GMT"}, {"version": "v2", "created": "Mon, 29 Jul 2019 14:16:20 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Ota", "Hirofumi", ""], ["Kato", "Kengo", ""], ["Hara", "Satoshi", ""]]}, {"id": "1811.05530", "submitter": "Angelos Armen", "authors": "Angelos P. Armen and Robin J. Evans", "title": "Towards Characterising Bayesian Network Models under Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-life statistical samples are often plagued by selection bias, which\ncomplicates drawing conclusions about the general population. When learning\ncausal relationships between the variables is of interest, the sample may be\nassumed to be from a distribution in a causal Bayesian network (BN) model under\nselection. Understanding the constraints in the model under selection is the\nfirst step towards recovering causal structure in the original model. The\nconditional-independence (CI) constraints in a BN model under selection have\nbeen already characterised; there exist, however, additional, non-CI\nconstraints in such models. In this work, some initial results are provided\nthat simplify the characterisation problem. In addition, an algorithm is\ndesigned for identifying compelled ancestors (definite causes) from a completed\npartially directed acyclic graph (CPDAG). Finally, a non-CI, non-factorisation\nconstraint in a BN model under selection is computed for the first time.\n", "versions": [{"version": "v1", "created": "Tue, 13 Nov 2018 21:11:55 GMT"}], "update_date": "2018-11-15", "authors_parsed": [["Armen", "Angelos P.", ""], ["Evans", "Robin J.", ""]]}, {"id": "1811.05910", "submitter": "Jonas Adler", "authors": "Jonas Adler, Ozan \\\"Oktem", "title": "Deep Bayesian Inversion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Characterizing statistical properties of solutions of inverse problems is\nessential for decision making. Bayesian inversion offers a tractable framework\nfor this purpose, but current approaches are computationally unfeasible for\nmost realistic imaging applications in the clinic. We introduce two novel deep\nlearning based methods for solving large-scale inverse problems using Bayesian\ninversion: a sampling based method using a WGAN with a novel mini-discriminator\nand a direct approach that trains a neural network using a novel loss function.\nThe performance of both methods is demonstrated on image reconstruction in\nultra low dose 3D helical CT. We compute the posterior mean and standard\ndeviation of the 3D images followed by a hypothesis test to assess whether a\n\"dark spot\" in the liver of a cancer stricken patient is present. Both methods\nare computationally efficient and our evaluation shows very promising\nperformance that clearly supports the claim that Bayesian inversion is usable\nfor 3D imaging in time critical applications.\n", "versions": [{"version": "v1", "created": "Wed, 14 Nov 2018 17:06:56 GMT"}], "update_date": "2018-11-15", "authors_parsed": [["Adler", "Jonas", ""], ["\u00d6ktem", "Ozan", ""]]}, {"id": "1811.05956", "submitter": "Holger Dette", "authors": "Holger Dette, Theresa Sch\\\"uler, Mathias Vetter", "title": "Multiscale change point detection for dependent data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study the theoretical properties of the simultaneous\nmultiscale change point estimator (SMUCE) proposed by Frick et al. (2014) in\nregression models with dependent error processes. Empirical studies show that\nin this case the change point estimate is inconsistent, but it is not known if\nalternatives suggested in the literature for correlated data are consistent. We\npropose a modification of SMUCE scaling the basic statistic by the long run\nvariance of the error process, which is estimated by a difference-type variance\nestimator calculated from local means from different blocks. For this\nmodification we prove model consistency for physical dependent error processes\nand illustrate the finite sample performance by means of a simulation study.\n", "versions": [{"version": "v1", "created": "Wed, 14 Nov 2018 18:42:46 GMT"}], "update_date": "2018-11-15", "authors_parsed": [["Dette", "Holger", ""], ["Sch\u00fcler", "Theresa", ""], ["Vetter", "Mathias", ""]]}, {"id": "1811.06055", "submitter": "Chao Gao", "authors": "Chao Gao and Zongming Ma", "title": "Minimax Rates in Network Analysis: Graphon Estimation, Community\n  Detection and Hypothesis Testing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.SI stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper surveys some recent developments in fundamental limits and optimal\nalgorithms for network analysis. We focus on minimax optimal rates in three\nfundamental problems of network analysis: graphon estimation, community\ndetection, and hypothesis testing. For each problem, we review state-of-the-art\nresults in the literature followed by general principles behind the optimal\nprocedures that lead to minimax estimation and testing. This allows us to\nconnect problems in network analysis to other statistical inference problems\nfrom a general perspective.\n", "versions": [{"version": "v1", "created": "Wed, 14 Nov 2018 20:49:47 GMT"}, {"version": "v2", "created": "Thu, 14 Feb 2019 05:34:34 GMT"}], "update_date": "2019-02-15", "authors_parsed": [["Gao", "Chao", ""], ["Ma", "Zongming", ""]]}, {"id": "1811.06123", "submitter": "Youzhou Zhou", "authors": "Youzhou Zhou", "title": "Some Moderate Deviations for Ewens-Pitman Sampling Model", "comments": "21 pages, three figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ewens-Pitman model has been successfully applied to various fields including\nBayesian statistics. There are four important estimators\n$K_{n},M_{l,n}$,$K_{m}^{(n)},M_{l,m}^{(n)}$. In particular, $M_{1,n},\nM_{1,m}^{(n)}$ are related to discovery probability. Their asymptotic behavior,\nsuch as large deviation principle, has already been discussed in [4],[1] and\n[2]. Moderate deviation principle is also discussed in [3] with some speed\nrestriction. In this article, we will apply complex asymptotic analysis to show\nthat this speed restriction is unnecessary.\n", "versions": [{"version": "v1", "created": "Thu, 15 Nov 2018 00:08:35 GMT"}, {"version": "v2", "created": "Sun, 18 Nov 2018 10:26:35 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Zhou", "Youzhou", ""]]}, {"id": "1811.06172", "submitter": "Johannes Krebs", "authors": "Johannes T. N. Krebs and J\\\"urgen E. Franke", "title": "The autoregression bootstrap for kernel estimates of smooth nonlinear\n  functional time series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Functional times series have become an integral part of both functional data\nand time series analysis. This paper deals with the functional autoregressive\nmodel of order 1 and the autoregression bootstrap for smooth functions. The\nregression operator is estimated in the framework developed by Ferraty and Vieu\n[2004] and Ferraty et al. [2007] which is here extended to the double\nfunctional case under an assumption of stationary ergodic data which dates back\nto Laib and Louani [2010]. The main result of this article is the\ncharacterization of the asymptotic consistency of the bootstrapped regression\noperator.\n", "versions": [{"version": "v1", "created": "Thu, 15 Nov 2018 04:47:12 GMT"}], "update_date": "2018-11-16", "authors_parsed": [["Krebs", "Johannes T. N.", ""], ["Franke", "J\u00fcrgen E.", ""]]}, {"id": "1811.06221", "submitter": "James Mathews", "authors": "James Mathews", "title": "A Schur transform for spatial stochastic processes", "comments": "9 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The variance, higher order moments, covariance, and joint moments or\ncumulants are shown to be special cases of a certain tensor in $V^{\\otimes n}$\ndefined in terms of a collection $X_1,...,X_n$ of $V$-valued random variables,\nfor an appropriate finite-dimensional real vector space $V$. A statistical\ntransform is proposed from such collections--finite spatial stochastic\nprocesses--to numerical tuples using the Schur-Weyl decomposition of\n$V^{\\otimes n}$. It is analogous to the Fourier transform, replacing the\nperiodicity group $\\mathbb{Z}$, $\\mathbb{R}$, or $U(1)$ with the permutation\ngroup $S_{n}$. As a test case, we apply the transform to one of the datasets\nused for benchmarking the Continuous Registration Challenge, the thoracic 4D\nComputed Tomography (CT) scans from the M.D. Anderson Cancer Center available\nfor download from DIR-Lab. Further applications to morphometry and statistical\nshape analysis are suggested.\n", "versions": [{"version": "v1", "created": "Thu, 15 Nov 2018 08:07:51 GMT"}, {"version": "v2", "created": "Fri, 16 Nov 2018 03:16:38 GMT"}], "update_date": "2018-11-19", "authors_parsed": [["Mathews", "James", ""]]}, {"id": "1811.06351", "submitter": "Fabian Mies", "authors": "Fabian Mies", "title": "Estimation of state-dependent jump activity and drift for Markovian\n  semimartingales", "comments": null, "journal-ref": null, "doi": "10.1016/j.jspi.2020.04.009", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The jump behavior of an infinitely active It\\^o semimartingale can be\nconveniently characterized by a jump activity index of Blumenthal-Getoor type,\ntypically assumed to be constant in time. We study Markovian semimartingales\nwith a non-constant, state-dependent jump activity index and a non-vanishing\ncontinuous diffusion component. A nonparametric estimator for the functional\njump activity index is proposed and shown to be asymptotically normal under\ncombined high-frequency and long-time-span asymptotics. Furthermore, we propose\na nonparametric drift estimator which is robust to symmetric jumps of infinite\nvariance and infinite variation, and which attains the same asymptotic variance\nas for a continuous diffusion process. Simulations demonstrate the finite\nsample behavior of our proposed estimators. The mathematical results are based\non a novel uniform bound on the Markov generator of the jump diffusion.\n", "versions": [{"version": "v1", "created": "Thu, 15 Nov 2018 14:05:06 GMT"}, {"version": "v2", "created": "Wed, 26 Jun 2019 16:00:15 GMT"}, {"version": "v3", "created": "Fri, 26 Jun 2020 11:04:28 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Mies", "Fabian", ""]]}, {"id": "1811.06433", "submitter": "Anja Jan{\\ss}en", "authors": "Holger Drees, Anja Jan{\\ss}en, Sidney I. Resnick and Tiandong Wang", "title": "On a minimum distance procedure for threshold selection in tail analysis", "comments": null, "journal-ref": "SIAM Journal on Mathematics of Data Science 2020 2:1, 75-102", "doi": "10.1137/19M1260463", "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Power-law distributions have been widely observed in different areas of\nscientific research. Practical estimation issues include how to select a\nthreshold above which observations follow a power-law distribution and then how\nto estimate the power-law tail index. A minimum distance selection procedure\n(MDSP) is proposed in Clauset et al. (2009) and has been widely adopted in\npractice, especially in the analyses of social networks. However, theoretical\njustifications for this selection procedure remain scant. In this paper, we\nstudy the asymptotic behavior of the selected threshold and the corresponding\npower-law index given by the MDSP. We find that the MDSP tends to choose too\nhigh a threshold level and leads to Hill estimates with large variances and\nroot mean squared errors for simulated data with Pareto-like tails.\n", "versions": [{"version": "v1", "created": "Thu, 15 Nov 2018 15:38:36 GMT"}, {"version": "v2", "created": "Wed, 12 Feb 2020 12:32:13 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Drees", "Holger", ""], ["Jan\u00dfen", "Anja", ""], ["Resnick", "Sidney I.", ""], ["Wang", "Tiandong", ""]]}, {"id": "1811.06687", "submitter": "Yaniv Romano", "authors": "Yaniv Romano, Matteo Sesia, Emmanuel J. Cand\\`es", "title": "Deep Knockoffs", "comments": "37 pages, 23 figures, 1 table", "journal-ref": "J. Am. Stat. Assoc., Volume 0, Issue 0, 17 Oct 2019, Pages 1-12", "doi": "10.1080/01621459.2019.1660174", "report-no": null, "categories": "stat.ME math.ST stat.AP stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a machine for sampling approximate model-X knockoffs\nfor arbitrary and unspecified data distributions using deep generative models.\nThe main idea is to iteratively refine a knockoff sampling mechanism until a\ncriterion measuring the validity of the produced knockoffs is optimized; this\ncriterion is inspired by the popular maximum mean discrepancy in machine\nlearning and can be thought of as measuring the distance to pairwise\nexchangeability between original and knockoff features. By building upon the\nexisting model-X framework, we thus obtain a flexible and model-free\nstatistical tool to perform controlled variable selection. Extensive numerical\nexperiments and quantitative tests confirm the generality, effectiveness, and\npower of our deep knockoff machines. Finally, we apply this new method to a\nreal study of mutations linked to changes in drug resistance in the human\nimmunodeficiency virus.\n", "versions": [{"version": "v1", "created": "Fri, 16 Nov 2018 06:26:33 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Romano", "Yaniv", ""], ["Sesia", "Matteo", ""], ["Cand\u00e8s", "Emmanuel J.", ""]]}, {"id": "1811.06857", "submitter": "Mahdi Teimouri Yanesari", "authors": "M. Teimouri", "title": "On the Parameter Estimation of the Generalized Exponential Distribution\n  Under Progressive Type-I Interval Censoring Scheme", "comments": "2 Figures, 1 Table", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chen and Lio (Computational Statistics and Data Analysis 54: 1581-1591, 2010)\nproposed five methods for estimating the parameters of generalized exponential\ndistribution under progressive type-I interval censoring scheme. Unfortunately,\namong them, the proposed EM algorithm is incorrect. Here, we propose the\ncorrect EM algorithm and compare its performance with the maximum likelihood\nestimators and that proposed by Chen and Lio (2010) in a simulation study.\n", "versions": [{"version": "v1", "created": "Fri, 16 Nov 2018 15:30:00 GMT"}], "update_date": "2018-11-19", "authors_parsed": [["Teimouri", "M.", ""]]}, {"id": "1811.07105", "submitter": "Ery Arias-Castro", "authors": "Ery Arias-Castro and Rong Huang and Nicolas Verzelen", "title": "Detection of Sparse Positive Dependence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a bivariate setting, we consider the problem of detecting a sparse\ncontamination or mixture component, where the effect manifests itself as a\npositive dependence between the variables, which are otherwise independent in\nthe main component. We first look at this problem in the context of a normal\nmixture model. In essence, the situation reduces to a univariate setting where\nthe effect is a decrease in variance. In particular, a higher criticism test\nbased on the pairwise differences is shown to achieve the detection boundary\ndefined by the (oracle) likelihood ratio test. We then turn to a Gaussian\ncopula model where the marginal distributions are unknown. Standard invariance\nconsiderations lead us to consider rank tests. In fact, a higher criticism test\nbased on the pairwise rank differences achieves the detection boundary in the\nnormal mixture model, although not in the very sparse regime. We do not know of\nany rank test that has any power in that regime.\n", "versions": [{"version": "v1", "created": "Sat, 17 Nov 2018 06:02:02 GMT"}, {"version": "v2", "created": "Thu, 9 Jan 2020 23:50:21 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Arias-Castro", "Ery", ""], ["Huang", "Rong", ""], ["Verzelen", "Nicolas", ""]]}, {"id": "1811.07232", "submitter": "Ting Ye", "authors": "Ting Ye and Jun Shao", "title": "Robust Tests for Treatment Effect in Survival Analysis under\n  Covariate-Adaptive Randomization", "comments": null, "journal-ref": null, "doi": "10.1111/rssb.12392", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Covariate-adaptive randomization is popular in clinical trials with\nsequentially arrived patients for balancing treatment assignments across\nprognostic factors which may have influence on the response. However, existing\ntheory on tests for treatment effect under covariate-adaptive randomization is\nlimited to tests under linear or generalized linear models, although\ncovariate-adaptive randomization has been used in survival analysis for a long\ntime and its main application is in survival analysis. Often times,\npractitioners would simply adopt a conventional test such as the log-rank test\nor score test to compare two treatments, which is controversial since tests\nderived under simple randomization may not be valid under other randomization\nschemes. In this article, we prove that the log-rank test valid under simple\nrandomization is conservative in terms of type I error under covariate-adaptive\nrandomization, and the robust score test developed under simple randomization\nis no longer robust under covariate-adaptive randomization. We then propose a\ncalibration type log-rank or score test that is valid and robust under both\nsimple randomization and a large family of covariate-adaptive randomization\nschemes. Furthermore, we obtain Pitman's efficacy of log-rank and score tests\nto compare their asymptotic relative efficiency. Simulation studies about the\ntype I error and power of various tests are presented under several popular\nrandomization schemes.\n", "versions": [{"version": "v1", "created": "Sat, 17 Nov 2018 22:12:22 GMT"}, {"version": "v2", "created": "Wed, 3 Apr 2019 03:22:03 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Ye", "Ting", ""], ["Shao", "Jun", ""]]}, {"id": "1811.07250", "submitter": "Xiaohong Lan", "authors": "Xiaohong Lan", "title": "Hitting Probability and the Hausdorff Measure of the Level sets for\n  Spherical Gaussian Fields", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider an isotropic spherical Gaussian random field T with values in R^{d}.\nWe investigate two problems: (i) When is the level set T^{-1}(t) nonempty with\npositive probability for any t\\in R^{d} ? (ii) If the level set is nonempty,\nwhat is its Hausdorff measure? These two question are not only very important\nin potential theory for random fields, but also foundamental in geometric\nmeasure theory. We give a complete answer to the questions under some very mild\nconditions.\n", "versions": [{"version": "v1", "created": "Sun, 18 Nov 2018 00:38:22 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Lan", "Xiaohong", ""]]}, {"id": "1811.07301", "submitter": "Dimbihery Rabenoro", "authors": "Dimbihery Rabenoro", "title": "A conditional limit theorem for independent random variables", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we prove a conditional limit theorem for independent not\nnecessarily identically distributed random variables. Namely, we obtain the\nasymptotic distribution of a large number of them given the sum.\n", "versions": [{"version": "v1", "created": "Sun, 18 Nov 2018 09:43:33 GMT"}, {"version": "v2", "created": "Tue, 3 Nov 2020 00:41:13 GMT"}, {"version": "v3", "created": "Wed, 11 Nov 2020 18:53:05 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Rabenoro", "Dimbihery", ""]]}, {"id": "1811.07307", "submitter": "Khashayar Gatmiry", "authors": "Khashayar Gatmiry, Seyed Abolfazl Motahari", "title": "Information Theoretic Bounds on Optimal Worst-case Error in Binary\n  Mixture Identification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT math.IT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identification of latent binary sequences from a pool of noisy observations\nhas a wide range of applications in both statistical learning and population\ngenetics. Each observed sequence is the result of passing one of the latent\nmother-sequences through a binary symmetric channel, which makes this\nconfiguration analogous to a special case of Bernoulli Mixture Models. This\npaper aims to attain an asymptotically tight upper-bound on the error of\nMaximum Likelihood mixture identification in such problems. The obtained\nresults demonstrate fundamental guarantees on the inference accuracy of the\noptimal estimator. To this end, we set out to find the closest pair of discrete\ndistributions with respect to the Chernoff Information measure. We provide a\nnovel technique to lower bound the Chernoff Information in an efficient way. We\nalso show that a drastic phase transition occurs at noise level 0.25. Our\nfindings reveal that the identification problem becomes much harder as the\nnoise probability exceeds this threshold.\n", "versions": [{"version": "v1", "created": "Sun, 18 Nov 2018 10:16:23 GMT"}, {"version": "v2", "created": "Mon, 26 Nov 2018 15:45:03 GMT"}, {"version": "v3", "created": "Tue, 27 Nov 2018 07:15:14 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["Gatmiry", "Khashayar", ""], ["Motahari", "Seyed Abolfazl", ""]]}, {"id": "1811.07499", "submitter": "Jose Figueroa-Lopez", "authors": "Jos\\'e E. Figueroa-L\\'opez, Cheng Li, and Jeffrey Nisen", "title": "Optimal Iterative Threshold-Kernel Estimation of Jump Diffusion\n  Processes", "comments": "29 pages", "journal-ref": null, "doi": "10.1007/s11203-020-09211-7.", "report-no": null, "categories": "math.ST econ.EM q-fin.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a new threshold-kernel jump-detection method for\njump-diffusion processes, which iteratively applies thresholding and kernel\nmethods in an approximately optimal way to achieve improved finite-sample\nperformance. We use the expected number of jump misclassifications as the\nobjective function to optimally select the threshold parameter of the jump\ndetection scheme. We prove that the objective function is quasi-convex and\nobtain a new second-order infill approximation of the optimal threshold in\nclosed form. The approximate optimal threshold depends not only on the spot\nvolatility, but also the jump intensity and the value of the jump density at\nthe origin. Estimation methods for these quantities are then developed, where\nthe spot volatility is estimated by a kernel estimator with thresholding and\nthe value of the jump density at the origin is estimated by a density kernel\nestimator applied to those increments deemed to contain jumps by the chosen\nthresholding criterion. Due to the interdependency between the model parameters\nand the approximate optimal estimators built to estimate them, a type of\niterative fixed-point algorithm is developed to implement them. Simulation\nstudies for a prototypical stochastic volatility model show that it is not only\nfeasible to implement the higher-order local optimal threshold scheme but also\nthat this is superior to those based only on the first order approximation\nand/or on average values of the parameters over the estimation time period.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2018 04:46:20 GMT"}, {"version": "v2", "created": "Wed, 11 Sep 2019 05:10:57 GMT"}, {"version": "v3", "created": "Mon, 2 Mar 2020 03:08:41 GMT"}, {"version": "v4", "created": "Sat, 4 Apr 2020 05:42:38 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Figueroa-L\u00f3pez", "Jos\u00e9 E.", ""], ["Li", "Cheng", ""], ["Nisen", "Jeffrey", ""]]}, {"id": "1811.07518", "submitter": "Stuart Johnston", "authors": "Stuart T. Johnston and Edmund J. Crampin", "title": "Corrected pair correlation functions for environments with obstacles", "comments": null, "journal-ref": "Phys. Rev. E 99, 032124 (2019)", "doi": "10.1103/PhysRevE.99.032124", "report-no": null, "categories": "math.ST stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Environments with immobile obstacles or void regions that inhibit and alter\nthe motion of individuals within that environment are ubiquitous. Correlation\nin the location of individuals within such environments arises as a combination\nof the mechanisms governing individual behavior and the heterogeneous structure\nof the environment. Measures of spatial structure and correlation have been\nsuccessfully implemented to elucidate the roles of the mechanisms underpinning\nthe behavior of individuals. In particular, the pair correlation function has\nbeen used across biology, ecology and physics to obtain quantitative insight\ninto a variety of processes. However, naively applying standard pair\ncorrelation functions in the presence of obstacles may fail to detect\ncorrelation, or suggest false correlations, due to a reliance on a distance\nmetric that does not account for obstacles. To overcome this problem, here we\npresent an analytic expression for calculating a corrected pair correlation\nfunction for lattice-based domains containing obstacles. We demonstrate that\nthis corrected pair correlation function is necessary for isolating the\ncorrelation associated with the behavior of individuals, rather than the\nstructure of the environment. Using simulations that mimic cell migration and\nproliferation we demonstrate that the corrected pair correlation function\nrecovers the short-range correlation known to be present in this process,\nindependent of the heterogeneous structure of the environment. Further, we show\nthat the analytic calculation of the corrected pair correlation derived here is\nsignificantly faster to implement than the corresponding numerical approach.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2018 06:17:51 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Johnston", "Stuart T.", ""], ["Crampin", "Edmund J.", ""]]}, {"id": "1811.07821", "submitter": "Yihong Wu", "authors": "Jian Ding, Zongming Ma, Yihong Wu, Jiaming Xu", "title": "Efficient random graph matching via degree profiles", "comments": "Proof of Theorem 4 expanded and revised", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DS cs.IT cs.LG math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random graph matching refers to recovering the underlying vertex\ncorrespondence between two random graphs with correlated edges; a prominent\nexample is when the two random graphs are given by Erd\\H{o}s-R\\'{e}nyi graphs\n$G(n,\\frac{d}{n})$. This can be viewed as an average-case and noisy version of\nthe graph isomorphism problem. Under this model, the maximum likelihood\nestimator is equivalent to solving the intractable quadratic assignment\nproblem. This work develops an $\\tilde{O}(n d^2+n^2)$-time algorithm which\nperfectly recovers the true vertex correspondence with high probability,\nprovided that the average degree is at least $d = \\Omega(\\log^2 n)$ and the two\ngraphs differ by at most $\\delta = O( \\log^{-2}(n) )$ fraction of edges. For\ndense graphs and sparse graphs, this can be improved to $\\delta = O(\n\\log^{-2/3}(n) )$ and $\\delta = O( \\log^{-2}(d) )$ respectively, both in\npolynomial time. The methodology is based on appropriately chosen distance\nstatistics of the degree profiles (empirical distribution of the degrees of\nneighbors). Before this work, the best known result achieves $\\delta=O(1)$ and\n$n^{o(1)} \\leq d \\leq n^c$ for some constant $c$ with an $n^{O(\\log n)}$-time\nalgorithm \\cite{barak2018nearly} and $\\delta=\\tilde O((d/n)^4)$ and $d =\n\\tilde{\\Omega}(n^{4/5})$ with a polynomial-time algorithm\n\\cite{dai2018performance}.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2018 17:33:48 GMT"}, {"version": "v2", "created": "Fri, 17 Jul 2020 18:55:50 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Ding", "Jian", ""], ["Ma", "Zongming", ""], ["Wu", "Yihong", ""], ["Xu", "Jiaming", ""]]}, {"id": "1811.08101", "submitter": "Pierre Etore", "authors": "Pierre Etor\\'e (LJK, IPS), Cl\\'ementine Prieur (AIRSEA, GdR\n  MASCOT-NUM, LJK), Dang Khoi Pham (AIRSEA, GdR MASCOT-NUM, LJK), Long Li\n  (AIRSEA, GdR MASCOT-NUM, LJK)", "title": "Global sensitivity analysis for models described by stochastic\n  differential equations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.AP math.NA math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many mathematical models involve input parameters, which are not precisely\nknown. Global sensitivity analysis aims to identify the parameters whose\nuncertainty has the largest impact on the variability of a quantity of\ninterest. One of the statistical tools used to quantify the influence of each\ninput variable on the quantity of interest are the Sobol' sensitivity indices.\nIn this paper, we consider stochastic models described by stochastic\ndifferential equations (SDE). We focus the study on mean quantities, defined as\nthe expectation with respect to the Wiener measure of a quantity of interest\nrelated to the solution of the SDE itself. Our approach is based on a\nFeynman-Kac representation of the quantity of interest, from which we get a\nparametrized partial differential equation (PDE) representation of our initial\nproblem. We then handle the uncertainty on the parametrized PDE using\npolynomial chaos expansion and a stochastic Galerkin projection.\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2018 07:17:30 GMT"}], "update_date": "2018-11-21", "authors_parsed": [["Etor\u00e9", "Pierre", "", "LJK, IPS"], ["Prieur", "Cl\u00e9mentine", "", "AIRSEA, GdR\n  MASCOT-NUM, LJK"], ["Pham", "Dang Khoi", "", "AIRSEA, GdR MASCOT-NUM, LJK"], ["Li", "Long", "", "AIRSEA, GdR MASCOT-NUM, LJK"]]}, {"id": "1811.08308", "submitter": "Andrei Soklakov N", "authors": "Andrei N. Soklakov", "title": "Economics of disagreement -- financial intuition for the R\\'enyi\n  divergence", "comments": "17 pages, 1 figure", "journal-ref": "Entropy 22 (8), 860 (2020)", "doi": "10.3390/e22080860", "report-no": null, "categories": "q-fin.GN cs.GT cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Disagreement is an essential element of science and life in general. The\nlanguage of probabilities and statistics is often used to describe\ndisagreements quantitatively. In practice, however, we want much more than\nthat. We want disagreements to be resolved. This leaves us with a substantial\nknowledge gap which is often perceived as a lack of practical intuition\nregarding probabilistic and statistical concepts.\n  Take for instance the R\\'enyi divergence which is a well-known statistical\nquantity specifically designed as a measure of disagreement between\nprobabilistic models. Despite its widespread use in science and engineering,\nthe R\\'enyi divergence remains a highly abstract axiomatically-motivated\nmeasure. Certainly, it offers no practical insight as to how disagreements can\nbe resolved.\n  Here we propose to address disagreements using the methods of financial\neconomics. In particular, we show how a large class of disagreements can be\ntransformed into investment opportunities. The expected financial performance\nof such investments quantifies the amount of disagreement in a tangible way.\nThis provides intuition for statistical concepts such as the R\\'enyi divergence\nwhich becomes connected to the financial performance of optimized investments.\nInvestment optimization takes into account individual opinions as well as\nattitudes towards risk. The result is a market-like social mechanism by which\nfunds flow naturally to support a more accurate view. Such social mechanisms\ncan help us with difficult disagreements (e.g., financial arguments concerning\nthe future climate).\n  In terms of scientific validation, we used the findings of independent\nneurophysiological experiments as well as our own research on the equity\npremium.\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2018 15:15:59 GMT"}, {"version": "v2", "created": "Sat, 8 Dec 2018 08:09:48 GMT"}, {"version": "v3", "created": "Mon, 21 Jan 2019 14:13:45 GMT"}, {"version": "v4", "created": "Fri, 19 Apr 2019 14:29:06 GMT"}, {"version": "v5", "created": "Wed, 18 Dec 2019 13:28:47 GMT"}, {"version": "v6", "created": "Wed, 1 Jul 2020 11:02:25 GMT"}, {"version": "v7", "created": "Mon, 31 Aug 2020 09:30:00 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Soklakov", "Andrei N.", ""]]}, {"id": "1811.08351", "submitter": "Yating Liu", "authors": "Yating Liu, Gilles Pag\\`es", "title": "Convergence rate of optimal quantization grids and application to\n  empirical measure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the convergence rate of the optimal quantization for a probability\nmeasure sequence $(\\mu_{n})_{n\\in\\mathbb{N}^{*}}$ on $\\mathbb{R}^{d}$\nconverging in the Wasserstein distance in two aspects: the first one is the\nconvergence rate of optimal quantizer $x^{(n)}\\in(\\mathbb{R}^{d})^{K}$ of\n$\\mu_{n}$ at level $K$; the other one is the convergence rate of the distortion\nfunction valued at $x^{(n)}$, called the \"performance\" of $x^{(n)}$. Moreover,\nwe also study the mean performance of the optimal quantization for the\nempirical measure of a distribution $\\mu$ with finite second moment but\npossibly unbounded support. As an application, we show that the mean\nperformance for the empirical measure of the multidimensional normal\ndistribution $\\mathcal{N}(m, \\Sigma)$ and of distributions with\nhyper-exponential tails behave like $\\mathcal{O}(\\frac{\\log n}{\\sqrt{n}})$.\nThis extends the results from [BDL08] obtained for compactly supported\ndistribution. We also derive an upper bound which is sharper in the\nquantization level $K$ but suboptimal in $n$ by applying results in [FG15].\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2018 16:31:26 GMT"}, {"version": "v2", "created": "Wed, 19 Feb 2020 12:06:12 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Liu", "Yating", ""], ["Pag\u00e8s", "Gilles", ""]]}, {"id": "1811.08769", "submitter": "Yacouba Boubacar Mainassara", "authors": "Yacouba Boubacar Ma\\\"inassara (UFC), Othman Kadmiri, Bruno Saussereau\n  (LMB)", "title": "Portmanteau test for the asymmetric power GARCH model when the power is\n  unknown", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.AP stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is now widely accepted that, to model the dynamics of daily financial\nreturns, volatility models have to incorporate the so-called leverage effect.\nWe derive the asymptotic behaviour of the squared residuals autocovariances for\nthe class of asymmetric power GARCH model when the power is unknown and is\njointly estimated with the model's parameters. We then deduce a portmanteau\nadequacy test based on the autocovariances of the squared residuals. These\nasymptotic results are illustrated by Monte Carlo experiments. An application\nto real financial data is also proposed.\n", "versions": [{"version": "v1", "created": "Wed, 21 Nov 2018 15:04:58 GMT"}], "update_date": "2018-11-22", "authors_parsed": [["Ma\u00efnassara", "Yacouba Boubacar", "", "UFC"], ["Kadmiri", "Othman", "", "LMB"], ["Saussereau", "Bruno", "", "LMB"]]}, {"id": "1811.08779", "submitter": "Anders Bredahl Kock", "authors": "Mehmet Caner and Anders Bredahl Kock", "title": "High Dimensional Linear GMM", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a desparsified GMM estimator for estimating\nhigh-dimensional regression models allowing for, but not requiring, many more\nendogenous regressors than observations. We provide finite sample upper bounds\non the estimation error of our estimator and show how asymptotically uniformly\nvalid inference can be conducted in the presence of conditionally\nheteroskedastic error terms. We do not require the projection of the endogenous\nvariables onto the linear span of the instruments to be sparse; that is we do\nnot impose the instruments to be sparse for our inferential procedure to be\nasymptotically valid. Furthermore, the variables of the model are not required\nto be sub-gaussian and we also explain how our results carry over to the\nclassic linear dynamic panel data model. Simulations show that our estimator\nhas a low mean square error and does well in terms of size and power of the\ntests constructed based on the estimator.\n", "versions": [{"version": "v1", "created": "Wed, 21 Nov 2018 15:20:25 GMT"}, {"version": "v2", "created": "Tue, 10 Sep 2019 11:53:14 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Caner", "Mehmet", ""], ["Kock", "Anders Bredahl", ""]]}, {"id": "1811.08814", "submitter": "Serguei Pergamenshchikov", "authors": "Dominique Fourdrinier and Sergey Pergamenshchikov", "title": "Sharp non asymptotic oracle inequalities for non parametric computerized\n  tomography model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider non parametric estimation problem for stochastic tomography\nregression model, i.e. we consider the estimation problem of function of\nmultivariate variables (image) observed through its Radon transformation\ncalculated with the random errors. For this problem we develop a new adaptive\nmodel selection method. By making use the Galtchouk and Pergamenshchikov\napproach we construct the model selection procedure for which we show a sharp\nnon asymptotic oracle inequality for the both usual and robust quadratic risks,\ni.e. we show that the proposed procedure is optimal in the oracle inequalities\nsense.\n", "versions": [{"version": "v1", "created": "Wed, 21 Nov 2018 16:33:31 GMT"}], "update_date": "2018-11-22", "authors_parsed": [["Fourdrinier", "Dominique", ""], ["Pergamenshchikov", "Sergey", ""]]}, {"id": "1811.08836", "submitter": "Albert Vexler", "authors": "Albert Vexler, Georgios Afendras, Marianthi Markatou", "title": "Multi-Panel Kendall Plot in Light of an ROC Curve Analysis Applied to\n  Measuring Dependence", "comments": "Statistics: A Journal of Theoretical and Applied Statistics. Accepted", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Kendall plot ($\\K$-plot) is a plot measuring dependence between the\ncomponents of a bivariate random variable. The $\\K$-plot graphs the Kendall\ndistribution function against the distribution function of $VU$, where $V$ and\n$U$ are independent uniform $[0,1]$ random variables. We associate $\\K$-plots\nwith the receiver operating characteristic ($\\ROC$) curve, a well-accepted\ngraphical tool in biostatistics for evaluating the ability of a biomarker to\ndiscriminate between two populations. The most commonly used global index of\ndiagnostic accuracy of biomarkers is the area under the $\\ROC$ curve ($\\AUC$).\nIn parallel with the $\\AUC$, we propose a novel strategy to measure the\nassociation between random variables from a continuous bivariate distribution.\nFirst, we discuss why the area under the conventional Kendall curve ($\\AUK$)\ncannot be used as an index of dependence. We then suggest a simple and\nmeaningful extension of the definition of the $\\K$-plots and define an index of\ndependence that is based on $\\AUK$. This measure characterizes a wide range of\ntwo-variable relationships, thereby completely detecting the underlying\ndependence structure. Properties of the proposed index satisfy the mathematical\ndefinition of a measure. Finally, simulations and real data examples illustrate\nthe applicability of the proposed method.\n", "versions": [{"version": "v1", "created": "Wed, 21 Nov 2018 17:27:05 GMT"}], "update_date": "2018-11-22", "authors_parsed": [["Vexler", "Albert", ""], ["Afendras", "Georgios", ""], ["Markatou", "Marianthi", ""]]}, {"id": "1811.08958", "submitter": "Guy Martial Nkiet", "authors": "M\\`Etolidji Moquilas Raymond Affossogbe, Guy Martial Nkiet and Carlos\n  Ogouyandjou", "title": "Smoothed functional average variance estimation for dimension reduction", "comments": "35 pages,14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an estimation method that we call functional average variance\nestimation (FAVE), for estimating the EDR space in functional semiparametric\nregression model, based on kernel estimates of density and regression.\nConsistency results are then established for the estimator of the interest\noperator, and for the directions of EDR space. A simulation study that shows\nthat the proposed approach performs as well as traditional ones is presented.\n", "versions": [{"version": "v1", "created": "Wed, 21 Nov 2018 21:25:49 GMT"}], "update_date": "2018-11-26", "authors_parsed": [["Affossogbe", "M\u00c8tolidji Moquilas Raymond", ""], ["Nkiet", "Guy Martial", ""], ["Ogouyandjou", "Carlos", ""]]}, {"id": "1811.09016", "submitter": "Takumi Suzuki", "authors": "Takumi Suzuki and Nakahiro Yoshida", "title": "Penalized least squares approximation methods and their applications to\n  stochastic processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We construct an objective function that consists of a quadratic approximation\nterm and a penalty term. Thanks to the quadratic approximation, we can deal\nwith various kinds of loss functions into a unified way, and by taking\nadvantage of the penalty term, we can simultaneously execute variable selection\nand parameter estimation. In this article, we show that our estimator has\noracle properties, and even better property. We also treat an stochastic\nprocesses as applications.\n", "versions": [{"version": "v1", "created": "Thu, 22 Nov 2018 04:07:14 GMT"}], "update_date": "2018-11-26", "authors_parsed": [["Suzuki", "Takumi", ""], ["Yoshida", "Nakahiro", ""]]}, {"id": "1811.09103", "submitter": "Guy Martial Nkiet", "authors": "Armando Sosthene Kali Balogoun, Guy Martial Nkiet and Carlos\n  Ogouyandjou", "title": "$k$-Sample problem based on generalized maximum mean discrepancy", "comments": "20 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we deal with the problem of testing for the quality of $k$\nprobability distributions. We introduce a generalization of the maximum mean\ndiscrepancy that permits to characterize the null hypothesis. Then, an\nestimator of it is proposed as test statistic, and its asymptotic distribution\nunder the null hypothesis is derived. Simulations show that the introduced\nprocedure outperforms classical ones.\n", "versions": [{"version": "v1", "created": "Thu, 22 Nov 2018 10:50:58 GMT"}], "update_date": "2018-11-26", "authors_parsed": [["Balogoun", "Armando Sosthene Kali", ""], ["Nkiet", "Guy Martial", ""], ["Ogouyandjou", "Carlos", ""]]}, {"id": "1811.09380", "submitter": "Yu Cheng", "authors": "Yu Cheng, Ilias Diakonikolas, Rong Ge", "title": "High-Dimensional Robust Mean Estimation in Nearly-Linear Time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the fundamental problem of high-dimensional mean estimation in a\nrobust model where a constant fraction of the samples are adversarially\ncorrupted. Recent work gave the first polynomial time algorithms for this\nproblem with dimension-independent error guarantees for several families of\nstructured distributions.\n  In this work, we give the first nearly-linear time algorithms for\nhigh-dimensional robust mean estimation. Specifically, we focus on\ndistributions with (i) known covariance and sub-gaussian tails, and (ii)\nunknown bounded covariance. Given $N$ samples on $\\mathbb{R}^d$, an\n$\\epsilon$-fraction of which may be arbitrarily corrupted, our algorithms run\nin time $\\tilde{O}(Nd) / \\mathrm{poly}(\\epsilon)$ and approximate the true mean\nwithin the information-theoretically optimal error, up to constant factors.\nPrevious robust algorithms with comparable error guarantees have running times\n$\\tilde{\\Omega}(N d^2)$, for $\\epsilon = \\Omega(1)$.\n  Our algorithms rely on a natural family of SDPs parameterized by our current\nguess $\\nu$ for the unknown mean $\\mu^\\star$. We give a win-win analysis\nestablishing the following: either a near-optimal solution to the primal SDP\nyields a good candidate for $\\mu^\\star$ -- independent of our current guess\n$\\nu$ -- or the dual SDP yields a new guess $\\nu'$ whose distance from\n$\\mu^\\star$ is smaller by a constant factor. We exploit the special structure\nof the corresponding SDPs to show that they are approximately solvable in\nnearly-linear time. Our approach is quite general, and we believe it can also\nbe applied to obtain nearly-linear time algorithms for other high-dimensional\nrobust learning problems.\n", "versions": [{"version": "v1", "created": "Fri, 23 Nov 2018 07:51:35 GMT"}], "update_date": "2018-11-26", "authors_parsed": [["Cheng", "Yu", ""], ["Diakonikolas", "Ilias", ""], ["Ge", "Rong", ""]]}, {"id": "1811.09511", "submitter": "Florian Wisheckel", "authors": "Michael Falk and Simone Padoan and Florian Wisheckel", "title": "Generalized Pareto Copulas: A Key to Multivariate Extremes", "comments": "38 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper reviews generalized Pareto copulas (GPC), which turn out to be a\nkey to multivariate extreme value theory. Any GPC can be represented in an easy\nanalytic way using a particular type of norm on $\\mathbb{R}^d$, called\n$D$-norm. The characteristic property of a GPC is its exceedance stability.\n  GPC might help to end the debate: What is a multivariate generalized Pareto\ndistribution? We present an easy way how to simulate data from an arbitrary GPC\nand, thus, from an arbitrary generalized Pareto distribution.\n  As an application we derive nonparametric estimates of the probability that a\nrandom vector, which follows a GPC, exceeds a high threshold, together with\nconfidence intervals. A case study on joint exceedance probabilities for air\npollutants completes the paper.\n", "versions": [{"version": "v1", "created": "Fri, 23 Nov 2018 15:13:27 GMT"}], "update_date": "2018-11-26", "authors_parsed": [["Falk", "Michael", ""], ["Padoan", "Simone", ""], ["Wisheckel", "Florian", ""]]}, {"id": "1811.09569", "submitter": "Karol Dziedziul", "authors": "Karol Dziedziul and Barbara Wolnik", "title": "Note on universal algorithms for learning theory", "comments": null, "journal-ref": "Applicationes Mathematicae (Warsaw) 34 (2007), no. 1, 47 - 52", "doi": "10.4064/am34-1-5", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the general way of study the universal estimator for the\nregression problem in learning theory considered in \"Universal algorithms for\nlearning theory Part I: piecewise constant functions\" and \"Universal algorithms\nfor learning theory Part II: piecewise constant functions\" written by Binev,\nP., Cohen, A., Dahmen, W., DeVore, R., Temlyakov, V. This new approch allows us\nto improve results.\n", "versions": [{"version": "v1", "created": "Fri, 23 Nov 2018 17:21:46 GMT"}], "update_date": "2018-11-26", "authors_parsed": [["Dziedziul", "Karol", ""], ["Wolnik", "Barbara", ""]]}, {"id": "1811.10106", "submitter": "Sung Min Park", "authors": "Guy Bresler, Sung Min Park, Madalina Persu", "title": "Sparse PCA from Sparse Linear Regression", "comments": "To appear in NeurIPS'18", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse Principal Component Analysis (SPCA) and Sparse Linear Regression (SLR)\nhave a wide range of applications and have attracted a tremendous amount of\nattention in the last two decades as canonical examples of statistical problems\nin high dimension. A variety of algorithms have been proposed for both SPCA and\nSLR, but an explicit connection between the two had not been made. We show how\nto efficiently transform a black-box solver for SLR into an algorithm for SPCA:\nassuming the SLR solver satisfies prediction error guarantees achieved by\nexisting efficient algorithms such as those based on the Lasso, the SPCA\nalgorithm derived from it achieves near state of the art guarantees for testing\nand for support recovery for the single spiked covariance model as obtained by\nthe current best polynomialtime algorithms. Our reduction not only highlights\nthe inherent similarity between the two problems, but also, from a practical\nstandpoint, allows one to obtain a collection of algorithms for SPCA directly\nfrom known algorithms for SLR. We provide experimental results on simulated\ndata comparing our proposed framework to other algorithms for SPCA.\n", "versions": [{"version": "v1", "created": "Sun, 25 Nov 2018 21:54:08 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Bresler", "Guy", ""], ["Park", "Sung Min", ""], ["Persu", "Madalina", ""]]}, {"id": "1811.10178", "submitter": "Gabriel Chandler", "authors": "Gabriel Chandler and Wolfgang Polonik", "title": "Multiscale geometric feature extraction for high-dimensional and\n  non-Euclidean data with application", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A method for extracting multiscale geometric features from a data cloud is\nproposed and analyzed. The basic idea is to map each pair of data points into a\nreal-valued feature function defined on $[0,1]$. The construction of these\nfeature functions is heavily based on geometric considerations, which has the\nbenefits of enhancing interpretability. Further statistical analysis is then\nbased on the collection of the feature functions. The potential of the method\nis illustrated by different applications, including classification of\nhigh-dimensional and non-Euclidean data. For continuous data in Euclidean\nspace, our feature functions contain information about the underlying density\nat a given base point (small scale features), and also about the depth of the\nbase point (large scale feature). As shown by our theoretical investigations,\nthe method combats the curse of dimensionality, and also shows some\nadaptiveness towards sparsity. Connections to other concepts, such as random\nset theory, localized depth measures and nonlinear multidimensional scaling,\nare also explored.\n", "versions": [{"version": "v1", "created": "Mon, 26 Nov 2018 05:09:40 GMT"}, {"version": "v2", "created": "Sun, 30 Dec 2018 22:17:33 GMT"}, {"version": "v3", "created": "Fri, 13 Dec 2019 03:55:26 GMT"}], "update_date": "2019-12-16", "authors_parsed": [["Chandler", "Gabriel", ""], ["Polonik", "Wolfgang", ""]]}, {"id": "1811.10197", "submitter": "Guang Cheng", "authors": "Yao Zheng and Guang Cheng", "title": "Finite Time Analysis of Vector Autoregressive Models under Linear\n  Restrictions", "comments": "To Appear in Biometrika", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper develops a unified finite-time theory for the ordinary least\nsquares estimation of possibly unstable and even slightly explosive vector\nautoregressive models under linear restrictions, with the applicable region\n$\\rho(A)\\leq 1+c/n$, where $\\rho(A)$ is the spectral radius of the transition\nmatrix $A$ in the \\VAR(1) representation, $n$ is the time horizon and $c>0$ is\na universal constant. The linear restriction framework encompasses various\nexisting models such as banded/network vector autoregressive models. We show\nthat the restrictions reduce the error bounds via not only the reduced\ndimensionality but also a scale factor resembling the asymptotic covariance\nmatrix of the estimator in the fixed-dimensional setup: as long as the model is\ncorrectly specified, this scale factor is decreasing in the number of\nrestrictions. It is revealed that the phase transition from slow to fast error\nrate regimes is determined by the smallest singular value of $A$, a measure of\nthe least excitable mode of the system. The minimax lower bounds are derived\nacross different regimes. The developed non-asymptotic theory not only bridges\nthe theoretical gap between stable and unstable regimes but precisely\ncharacterizes the effect of restrictions and its interplay with model\nparameters. Simulations support our theoretical results.\n", "versions": [{"version": "v1", "created": "Mon, 26 Nov 2018 06:22:45 GMT"}, {"version": "v2", "created": "Mon, 18 May 2020 15:19:09 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Zheng", "Yao", ""], ["Cheng", "Guang", ""]]}, {"id": "1811.10224", "submitter": "Irene Gannaz", "authors": "Sophie Achard (GIPSA-CICS), Ir\\`ene Gannaz (ICJ)", "title": "Wavelet-based and Fourier-based multivariate Whittle estimation:\n  multiwave", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multivariate time series with long-dependence are observed in many\napplications such as finance , geophysics or neuroscience. Many packages\nprovide estimation tools for univariate settings but few are addressing the\nproblem of long-dependence estimation for multivariate settings. The package\nmultiwave is providing efficient estimation procedures for multivariate time\nseries. Two semi-parametric estimation methods of the long-memory exponents and\nlong-run covariance matrix of time series are implemented. The first one is the\nFourier-based estimation proposed by [18] and the second one is a wavelet-based\nestimation described in [4]. The objective of this paper is to provide an\noverview of the R package multiwave with its practical application\nperspectives.\n", "versions": [{"version": "v1", "created": "Mon, 26 Nov 2018 08:09:02 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Achard", "Sophie", "", "GIPSA-CICS"], ["Gannaz", "Ir\u00e8ne", "", "ICJ"]]}, {"id": "1811.10241", "submitter": "Pierre Gruet", "authors": "Olivier F\\'eron and Pierre Gruet and Marc Hoffmann", "title": "Efficient volatility estimation in a two-factor model", "comments": "27 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We statistically analyse a multivariate HJM diffusion model with stochastic\nvolatility. The volatility process of the first factor is left totally\nunspecified while the volatility of the second factor is the product of an\nunknown process and an exponential function of time to maturity. This\nexponential term includes some real parameter measuring the rate of increase of\nthe second factor as time goes to maturity. From historical data, we\nefficiently estimate the time to maturity parameter in the sense of\nconstructing an estimator that achieves an optimal information bound in a\nsemiparametric setting. We also identify nonparametrically the paths of the\nvolatility processes and achieve minimax bounds. We address the problem of\ndegeneracy that occurs when the dimension of the process is greater than two,\nand give in particular optimal limit theorems under suitable regularity\nassumptions on the drift process. We consistently analyse the numerical\nbehaviour of our estimators on simulated and real datasets of prices of forward\ncontracts on electricity markets.\n", "versions": [{"version": "v1", "created": "Mon, 26 Nov 2018 09:26:57 GMT"}, {"version": "v2", "created": "Thu, 6 Jun 2019 12:57:41 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["F\u00e9ron", "Olivier", ""], ["Gruet", "Pierre", ""], ["Hoffmann", "Marc", ""]]}, {"id": "1811.10255", "submitter": "Giacomo Aletti", "authors": "Giacomo Aletti, Irene Crimaldi and Andrea Ghiglietti", "title": "Interacting reinforced stochastic processes: statistical inference based\n  on the weighted empirical means", "comments": null, "journal-ref": "Bernoulli, Volume 26, Number 2 (2020), 1098-1138", "doi": "10.3150/19-BEJ1143", "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work deals with a system of interacting reinforced stochastic processes,\nwhere each process $X^j=(X_{n,j})_n$ is located at a vertex $j$ of a finite\nweighted direct graph, and it can be interpreted as the sequence of \"actions\"\nadopted by an agent $j$ of the network. The interaction among the dynamics of\nthese processes depends on the weighted adjacency matrix $W$ associated to the\nunderlying graph: indeed, the probability that an agent $j$ chooses a certain\naction depends on its personal \"inclination\" $Z_{n,j}$ and on the inclinations\n$Z_{n,h}$, with $h\\neq j$, of the other agents according to the entries of $W$.\nThe best known example of reinforced stochastic process is the Polya urn.\n  The present paper characterizes the asymptotic behavior of the weighted\nempirical means $N_{n,j}=\\sum_{k=1}^n q_{n,k} X_{k,j}$, proving their almost\nsure synchronization and some central limit theorems in the sense of stable\nconvergence. By means of a more sophisticated decomposition of the considered\nprocesses adopted here, these findings complete and improve some asymptotic\nresults for the personal inclinations $Z^j=(Z_{n,j})_n$ and for the empirical\nmeans $\\overline{X}^j=(\\sum_{k=1}^n X_{k,j}/n)_n$ given in recent papers (e.g.\n[arXiv:1705.02126, Bernoulli, Forth.]; [arXiv:1607.08514, Ann. Appl. Probab.,\n27(6):3787-3844, 2017]; [arXiv:1602.06217, Stochastic Process. Appl.,\n129(1):70-101, 2019]). Our work is motivated by the aim to understand how the\ndifferent rates of convergence of the involved stochastic processes combine\nand, from an applicative point of view, by the construction of confidence\nintervals for the common limit inclination of the agents and of a test\nstatistics to make inference on the matrix $W$, based on the weighted empirical\nmeans. In particular, we answer a research question posed in [arXiv:1705.02126,\nBernoulli, Forth.]\n", "versions": [{"version": "v1", "created": "Mon, 26 Nov 2018 09:53:05 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Aletti", "Giacomo", ""], ["Crimaldi", "Irene", ""], ["Ghiglietti", "Andrea", ""]]}, {"id": "1811.10411", "submitter": "Rida Benhaddou", "authors": "Rida Benhaddou and Qing Liu", "title": "Minimax adaptive wavelet estimator for the anisotropic functional\n  deconvolution model with unknown kernel", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the present paper, we consider the estimation of a periodic\ntwo-dimensional function $f(\\cdot,\\cdot)$ based on observations from its noisy\nconvolution, and convolution kernel $g(\\cdot,\\cdot)$ unknown. We derive the\nminimax lower bounds for the mean squared error assuming that $f$ belongs to\ncertain Besov space and the kernel function $g$ satisfies some smoothness\nproperties. We construct an adaptive hard-thresholding wavelet estimator that\nis asymptotically near-optimal within a logarithmic factor in a wide range of\nBesov balls. The proposed estimation algorithm implements a truncation to\nestimate the wavelet coefficients, in addition to the conventional\nhard-thresholds. A limited simulations study confirms theoretical claims of the\npaper.\n", "versions": [{"version": "v1", "created": "Thu, 22 Nov 2018 02:30:59 GMT"}, {"version": "v2", "created": "Sat, 18 May 2019 18:55:09 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Benhaddou", "Rida", ""], ["Liu", "Qing", ""]]}, {"id": "1811.10443", "submitter": "Andreas Elsener", "authors": "Andreas Elsener and Sara van de Geer", "title": "Sparse spectral estimation with missing and corrupted measurements", "comments": "32 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supervised learning methods with missing data have been extensively studied\nnot just due to the techniques related to low-rank matrix completion. Also in\nunsupervised learning one often relies on imputation methods. As a matter of\nfact, missing values induce a bias in various estimators such as the sample\ncovariance matrix. In the present paper, a convex method for sparse subspace\nestimation is extended to the case of missing and corrupted measurements. This\nis done by correcting the bias instead of imputing the missing values. The\nestimator is then used as an initial value for a nonconvex procedure to improve\nthe overall statistical performance. The methodological as well as theoretical\nframeworks are applied to a wide range of statistical problems. These include\nsparse Principal Component Analysis with different types of randomly missing\ndata and the estimation of eigenvectors of low-rank matrices with missing\nvalues. Finally, the statistical performance is demonstrated on synthetic data.\n", "versions": [{"version": "v1", "created": "Mon, 26 Nov 2018 15:24:31 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Elsener", "Andreas", ""], ["van de Geer", "Sara", ""]]}, {"id": "1811.10450", "submitter": "Thomas Galtier", "authors": "H. Chraibi, A. Dutfoy, T. Galtier, and J. Garnier", "title": "Optimal input potential functions in the interacting particle system\n  method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The assessment of the probability of a rare event with a naive Monte-Carlo\nmethod is computationally intensive, so faster estimation or variance reduction\nmethods are needed. We focus on one of these methods which is the interacting\nparticle system (IPS) method. The method is not intrusive in the sense that the\nrandom Markov system under consideration is simulated with its original\ndistribution, but selection steps are introduced that favor trajectories\n(particles) with high potential values. An unbiased estimator with reduced\nvariance can then be proposed. The method requires to specify a set of\npotential functions. The choice of these functions is crucial, because it\ndetermines the magnitude of the variance reduction. So far, little information\nwas available on how to choose the potential functions. This paper provides the\nexpressions of the optimal potential functions minimizing the asymptotic\nvariance of the estimator of the IPS method and it proposes recommendations for\nthe practical design of the potential functions.\n", "versions": [{"version": "v1", "created": "Mon, 26 Nov 2018 15:29:23 GMT"}, {"version": "v2", "created": "Thu, 5 Nov 2020 17:29:40 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Chraibi", "H.", ""], ["Dutfoy", "A.", ""], ["Galtier", "T.", ""], ["Garnier", "J.", ""]]}, {"id": "1811.10790", "submitter": "Sen Na", "authors": "Sen Na, Mladen Kolar", "title": "High-dimensional Index Volatility Models via Stein's Identity", "comments": "44 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the estimation of the parametric components of single and multiple\nindex volatility models. Using the first- and second-order Stein's identities,\nwe develop methods that are applicable for the estimation of the variance index\nin the high-dimensional setting requiring finite moment condition, which allows\nfor heavy-tailed data. Our approach complements the existing literature in the\nlow-dimensional setting, while relaxing the conditions on estimation, and\nprovides a novel approach in the high-dimensional setting. We prove that the\nstatistical rate of convergence of our variance index estimators consists of a\nparametric rate and a nonparametric rate, where the latter appears from the\nestimation of the mean link function. However, under standard assumptions, the\nparametric rate dominates the rate of convergence and our results match the\nminimax optimal rate for the mean index estimation. Simulation results\nillustrate finite sample properties of our methodology and back our theoretical\nconclusions.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 03:32:03 GMT"}, {"version": "v2", "created": "Thu, 14 Mar 2019 16:40:28 GMT"}, {"version": "v3", "created": "Mon, 25 May 2020 21:22:52 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Na", "Sen", ""], ["Kolar", "Mladen", ""]]}, {"id": "1811.10957", "submitter": "Ivan Kojadinovic", "authors": "Ivan Kojadinovic and Kristina Stemikovskaya", "title": "Subsampling (weighted smooth) empirical copula processes", "comments": "34 pages, 5 figures, 4 + 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key tool to carry out inference on the unknown copula when modeling a\ncontinuous multivariate distribution is a nonparametric estimator known as the\nempirical copula. One popular way of approximating its sampling distribution\nconsists of using the multiplier bootstrap. The latter is however characterized\nby a high implementation cost. Given the rank-based nature of the empirical\ncopula, the classical empirical bootstrap of Efron does not appear to be a\nnatural alternative, as it relies on resamples which contain ties. The aim of\nthis work is to investigate the use of subsampling in the aforementioned\nframework. The latter consists of basing the inference on statistic values\ncomputed from subsamples of the initial data. One of its advantages in the\nrank-based context under consideration is that the formed subsamples do not\ncontain ties. Another advantage is its asymptotic validity under minimalistic\nconditions. In this work, we show the asymptotic validity of subsampling for\nseveral (weighted, smooth) empirical copula processes both in the case of\nserially independent observations and time series. In the former case,\nsubsampling is observed to be substantially better than the empirical bootstrap\nand equivalent, overall, to the multiplier bootstrap in terms of finite-sample\nperformance.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 13:17:28 GMT"}, {"version": "v2", "created": "Thu, 23 May 2019 14:23:28 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Kojadinovic", "Ivan", ""], ["Stemikovskaya", "Kristina", ""]]}, {"id": "1811.10963", "submitter": "Jari  Miettinen", "authors": "Jari Miettinen, Markus Matilainen, Klaus Nordhausen, Sara Taskinen", "title": "Extracting conditionally heteroscedastic components using ICA", "comments": "46 pages, 9 figures", "journal-ref": "Journal of Time Series Analysis 41: 293-311 (2020)", "doi": "10.1111/jtsa.12505", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the independent component model, the multivariate data is assumed to be a\nmixture of mutually independent latent components, and in independent component\nanalysis (ICA) the aim is to estimate these latent components. In this paper we\nstudy an ICA method which combines the use of linear and quadratic\nautocorrelations in order to enable efficient estimation of various kinds of\nstationary time series. Statistical properties of the estimator are studied by\nfinding its limiting distribution under general conditions, and the asymptotic\nvariances are derived in the case of ARMA-GARCH model. We use the asymptotic\nresults and a finite sample simulation study to compare different choices of a\nweight coefficient. As it is often of interest to identify all those components\nwhich exhibit stochastic volatility features we also suggest a test statistic\nfor this problem. We also show that a slightly modified version of principal\nvolatility components (PVC) can be seen as an ICA method. Finally, we apply the\nestimators in analyzing a data set which consists of time series of exchange\nrates of seven currencies to US dollar. Supplementary material including proofs\nof the theorems is available online.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 13:22:32 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Miettinen", "Jari", ""], ["Matilainen", "Markus", ""], ["Nordhausen", "Klaus", ""], ["Taskinen", "Sara", ""]]}, {"id": "1811.10996", "submitter": "Ning Miao", "authors": "Ning Miao, Hao Zhou, Lili Mou, Rui Yan, Lei Li", "title": "CGMH: Constrained Sentence Generation by Metropolis-Hastings Sampling", "comments": "AAAI19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In real-world applications of natural language generation, there are often\nconstraints on the target sentences in addition to fluency and naturalness\nrequirements. Existing language generation techniques are usually based on\nrecurrent neural networks (RNNs). However, it is non-trivial to impose\nconstraints on RNNs while maintaining generation quality, since RNNs generate\nsentences sequentially (or with beam search) from the first word to the last.\nIn this paper, we propose CGMH, a novel approach using Metropolis-Hastings\nsampling for constrained sentence generation. CGMH allows complicated\nconstraints such as the occurrence of multiple keywords in the target\nsentences, which cannot be handled in traditional RNN-based approaches.\nMoreover, CGMH works in the inference stage, and does not require parallel\ncorpora for training. We evaluate our method on a variety of tasks, including\nkeywords-to-sentence generation, unsupervised sentence paraphrasing, and\nunsupervised sentence error correction. CGMH achieves high performance compared\nwith previous supervised methods for sentence generation. Our code is released\nat https://github.com/NingMiao/CGMH\n", "versions": [{"version": "v1", "created": "Wed, 14 Nov 2018 15:46:57 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Miao", "Ning", ""], ["Zhou", "Hao", ""], ["Mou", "Lili", ""], ["Yan", "Rui", ""], ["Li", "Lei", ""]]}, {"id": "1811.11031", "submitter": "Eliane Pinheiro", "authors": "Eliane C. Pinheiro, Silvia L.P. Ferrari and Francisco M.C. Medeiros", "title": "Higher-order approximate confidence intervals", "comments": "25 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.AP stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard confidence intervals employed in applied statistical analysis are\nusually based on asymptotic approximations. Such approximations can be\nconsiderably inaccurate in small and moderate sized samples. We derive accurate\nconfidence intervals based on higher-order approximate quantiles of the score\nfunction. The coverage approximation error is $O(n^{-3/2})$ while the\napproximation error of confidence intervals based on the asymptotic normality\nof MLEs is $O(n^{-1/2})$. Monte Carlo simulations confirm the theoretical\nfindings. An implementation for regression models and real data applications\nare provided.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 14:46:11 GMT"}, {"version": "v2", "created": "Wed, 18 Dec 2019 14:37:08 GMT"}, {"version": "v3", "created": "Thu, 10 Dec 2020 21:55:13 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Pinheiro", "Eliane C.", ""], ["Ferrari", "Silvia L. P.", ""], ["Medeiros", "Francisco M. C.", ""]]}, {"id": "1811.11252", "submitter": "Agnieszka Wy{\\l}oma\\'nska", "authors": "G. Sikora, M. Hoell, A. Wylomanska, J. Gajda, A.V. Chechkin, H. Kantz", "title": "Probabilistic properties of detrended fluctuation analysis for Gaussian\n  processes", "comments": null, "journal-ref": "Phys. Rev. E 101, 032114 (2020)", "doi": "10.1103/PhysRevE.101.032114", "report-no": null, "categories": "cond-mat.stat-mech cond-mat.soft math.ST physics.data-an stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The detrended fluctuation analysis (DFA) is one of the most widely used tools\nfor the detection of long-range correlations in time series. Although DFA has\nfound many interesting applications and has been shown as one of the best\nperforming detrending methods, its probabilistic foundations are still unclear.\nIn this paper we study probabilistic properties of DFA for Gaussian processes.\nThe main attention is paid to the distribution of the squared error sum of the\ndetrended process. This allows us to find the expected value and the variance\nof the fluctuation function of DFA for a Gaussian process of general form. The\nresults obtained can serve as a starting point for analyzing the statistical\nproperties of the DFA-based estimators for the fluctuation and correlation\nparameters. The obtained theoretical formulas are supported by numerical\nsimulations of particular Gaussian processes possessing short-and long-memory\nbehaviour.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 20:47:45 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Sikora", "G.", ""], ["Hoell", "M.", ""], ["Wylomanska", "A.", ""], ["Gajda", "J.", ""], ["Chechkin", "A. V.", ""], ["Kantz", "H.", ""]]}, {"id": "1811.11253", "submitter": "Agnieszka Wy{\\l}oma\\'nska", "authors": "J. Gajda, A. Wylomanska, H. Kantz, A. V. Chechkin, G. Sikora", "title": "Large deviations of time-averaged statistics for Gaussian processes", "comments": null, "journal-ref": "Statistics and Probability Letters 143, 47-55, 2018", "doi": null, "report-no": null, "categories": "math.PR cond-mat.stat-mech math.ST physics.data-an stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study the large deviations of time averaged mean square\ndisplacement (TAMSD) for Gaussian processes. The theory of large deviations is\nrelated to the exponential decay of probabilities of large fluctuations in\nrandom systems. From the mathematical point of view a given statistics\nsatisfies the large deviation principle, if the probability that it belongs to\na certain range decreases exponentially. The TAMSD is one of the main\nstatistics used in the problem of anomalous diffusion detection. Applying the\ntheory of generalized chi-squared distribution and sub-gamma random variables\nwe prove the upper bound for large deviations of TAMSD for Gaussian processes.\nAs a special case we consider fractional Brownian motion, one of the most\npopular models of anomalous diffusion. Moreover, we derive the upper bound for\nlarge deviations of the estimator for the anomalous diffusion exponent.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 20:54:32 GMT"}], "update_date": "2018-11-29", "authors_parsed": [["Gajda", "J.", ""], ["Wylomanska", "A.", ""], ["Kantz", "H.", ""], ["Chechkin", "A. V.", ""], ["Sikora", "G.", ""]]}, {"id": "1811.11614", "submitter": "Thomas Deschatre", "authors": "Thomas Deschatre", "title": "Local polynomial estimation of the intensity of a doubly stochastic\n  Poisson process with bandwidth selection procedure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a doubly stochastic Poisson process with stochastic intensity\n$\\lambda_t =n q\\left(X_t\\right)$ where $X$ is a continuous It\\^o semimartingale\nand $n$ is an integer. Both processes are observed continuously over a fixed\nperiod $\\left[0,T\\right]$. An estimation procedure is proposed in a non\nparametrical setting for the function $q$ on an interval $I$ where $X$ is\nsufficiently observed using a local polynomial estimator. A method to select\nthe bandwidth in a non asymptotic framework is proposed, leading to an oracle\ninequality. If $m$ is the degree of the chosen polynomial, the accuracy of our\nestimator over the H\\\"older class of order $\\beta$ is\n$n^{\\frac{-\\beta}{2\\beta+1}}$ if $m \\geq \\lfloor \\beta \\rfloor$ and it is\noptimal in the minimax sense if $m \\geq \\lfloor \\beta \\rfloor$. A parametrical\ntest is also proposed to test if $q$ belongs to some parametrical family. Those\nresults are applied to French temperature and electricity spot prices data\nwhere we infer the intensity of electricity spot spikes as a function of the\ntemperature.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2018 15:14:23 GMT"}], "update_date": "2018-11-29", "authors_parsed": [["Deschatre", "Thomas", ""]]}, {"id": "1811.11708", "submitter": "Claudio Durastanti Dr.", "authors": "Claudio Durastanti and Tim Patschkowski", "title": "Aliasing effects for random fields over spheres of arbitrary dimension", "comments": "39 pages, 2 figures", "journal-ref": "Electron. J. Statist., Volume 13, Number 2 (2019), 3297-3335", "doi": "10.1214/19-EJS1596", "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, aliasing effects are investigated for random fields defined on\nthe d-dimensional sphere and reconstructed from discrete samples. First, we\nintroduce the concept of an aliasing function on the sphere. The aliasing\nfunction allows one to identify explicitly the aliases of a given harmonic\ncoefficient in the Fourier decomposition. Then, we exploit this tool to\nestablish the aliases of the harmonic coefficients approximated by means of the\nquadrature procedure named spherical uniform sampling. Subsequently, we study\nthe consequences of the aliasing errors in the approximation of the angular\npower spectrum of an isotropic random field, the harmonic decomposition of its\ncovariance function. Finally, we show that band-limited random fields are\naliases-free, under the assumption of a sufficiently large amount of nodes in\nthe quadrature rule.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2018 17:57:59 GMT"}, {"version": "v2", "created": "Fri, 17 May 2019 11:56:28 GMT"}, {"version": "v3", "created": "Tue, 26 Nov 2019 18:18:05 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Durastanti", "Claudio", ""], ["Patschkowski", "Tim", ""]]}, {"id": "1811.11709", "submitter": "Yuchen Zhou", "authors": "Pixu Shi and Yuchen Zhou and Anru R. Zhang", "title": "High-dimensional Log-Error-in-Variable Regression with Applications to\n  Microbial Compositional Data Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.AP stat.TH", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In microbiome and genomic studies, the regression of compositional data has\nbeen a crucial tool for identifying microbial taxa or genes that are associated\nwith clinical phenotypes. To account for the variation in sequencing depth, the\nclassic log-contrast model is often used where read counts are normalized into\ncompositions. However, zero read counts and the randomness in covariates remain\ncritical issues. In this article, we introduce a surprisingly simple,\ninterpretable, and efficient method for the estimation of compositional data\nregression through the lens of a novel high-dimensional log-error-in-variable\nregression model. The proposed method provides both corrections on sequencing\ndata with possible overdispersion and simultaneously avoids any subjective\nimputation of zero read counts. We provide theoretical justifications with\nmatching upper and lower bounds for the estimation error. The merit of the\nprocedure is illustrated through real data analysis and simulation studies.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2018 17:57:59 GMT"}, {"version": "v2", "created": "Sat, 15 Dec 2018 01:29:35 GMT"}, {"version": "v3", "created": "Wed, 10 Mar 2021 17:59:25 GMT"}], "update_date": "2021-03-11", "authors_parsed": [["Shi", "Pixu", ""], ["Zhou", "Yuchen", ""], ["Zhang", "Anru R.", ""]]}, {"id": "1811.11834", "submitter": "Shouto Yonekura", "authors": "Shouto Yonekura, Alexandros Beskos and Sumeetpal S.Singh", "title": "Asymptotic Analysis of Model Selection Criteria for General Hidden\n  Markov Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper obtains analytical results for the asymptotic properties of Model\nSelection Criteria -- widely used in practice -- for a general family of hidden\nMarkov models (HMMs), thereby substantially extending the related theory beyond\ntypical i.i.d.-like model structures and filling in an important gap in the\nrelevant literature. In particular, we look at the Bayesian and Akaike\nInformation Criteria (BIC and AIC) and the model evidence. In the setting of\nnested classes of models, we prove that BIC and the evidence are strongly\nconsistent for HMMs (under regularity conditions), whereas AIC is not weakly\nconsistent. Numerical experiments support our theoretical results.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2018 21:06:50 GMT"}, {"version": "v2", "created": "Wed, 5 Jun 2019 00:25:05 GMT"}, {"version": "v3", "created": "Mon, 30 Mar 2020 11:37:44 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Yonekura", "Shouto", ""], ["Beskos", "Alexandros", ""], ["Singh", "Sumeetpal S.", ""]]}, {"id": "1811.12061", "submitter": "Johan Segers", "authors": "Cees de Valk, Johan Segers", "title": "Tails of optimal transport plans for regularly varying probability\n  measures", "comments": "26 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For the basic case of $L_2$ optimal transport between two probability\nmeasures on a Euclidean space, the regularity of the coupling measure and the\ntransport map in the tail regions of these measures is studied. For this\npurpose, Robert McCann's classical existence and uniqueness results are\nextended to a class of possibly infinite measures, finite outside\nneighbourhoods of the origin. For convergent sequences of pairs of such\nmeasures, the stability of the multivalued transport maps is considered, and a\nuseful notion of locally uniform convergence of these maps is verified under\nlight assumptions. Applied to regularly varying probability measures, these\ngeneral results imply the existence of tail limits of the transport plan and\nthe coupling measure, these objects exhibiting distinct types of homogeneity.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2018 11:04:04 GMT"}, {"version": "v2", "created": "Thu, 2 May 2019 19:39:08 GMT"}], "update_date": "2019-05-06", "authors_parsed": [["de Valk", "Cees", ""], ["Segers", "Johan", ""]]}, {"id": "1811.12244", "submitter": "Sergios Agapiou", "authors": "Sergios Agapiou, Masoumeh Dashti and Tapio Helin", "title": "Rates of contraction of posterior distributions based on $p$-exponential\n  priors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a family of infinite dimensional product measures with tails\nbetween Gaussian and exponential, which we call $p$-exponential measures. We\nstudy their measure-theoretic properties and in particular their concentration.\nOur findings are used to develop a general contraction theory of posterior\ndistributions on nonparametric models with $p$-exponential priors in separable\nBanach parameter spaces. Our approach builds on the general contraction theory\nfor Gaussian process priors in van der Vaart and van Zanten 2008, namely we use\nprior concentration to verify prior mass and entropy conditions sufficient for\nposterior contraction. However, the specific concentration properties of\n$p$-exponential priors lead to a more complex entropy bound which can influence\nnegatively the obtained rate of contraction, depending on the topology of the\nparameter space. Subject to the more complex entropy bound, we show that the\nrate of contraction depends on the position of the true parameter relative to a\ncertain Banach space associated to $p$-exponential measures and on the small\nball probabilities of these measures. For example, we apply our theory in the\nwhite noise model under Besov regularity of the truth and obtain minimax rates\nof contraction using (rescaled) $\\alpha$-regular $p$-exponential priors. In\nparticular, our results suggest that when interested in spatially inhomogeneous\nunknown functions, in terms of posterior contraction, it is preferable to use\nLaplace rather than Gaussian priors.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2018 15:25:50 GMT"}, {"version": "v2", "created": "Fri, 30 Nov 2018 06:06:15 GMT"}, {"version": "v3", "created": "Wed, 3 Jun 2020 19:16:26 GMT"}, {"version": "v4", "created": "Thu, 8 Oct 2020 15:17:11 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Agapiou", "Sergios", ""], ["Dashti", "Masoumeh", ""], ["Helin", "Tapio", ""]]}, {"id": "1811.12304", "submitter": "Andrea Arfe", "authors": "Andrea Arf\\'e, Stefano Peluso, Pietro Muliere", "title": "Reinforced urns and the subdistribution beta-Stacy process prior for\n  competing risks analysis", "comments": "To appear in the Scandinavian Journal of Statistics", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce the subdistribution beta-Stacy process, a novel\nBayesian nonparametric process prior for subdistribution functions useful for\nthe analysis of competing risks data. In particular, we i) characterize this\nprocess from a predictive perspective by means of an urn model with\nreinforcement, ii) show that it is conjugate with respect to right-censored\ndata, and iii) highlight its relations with other prior processes for competing\nrisks data. Additionally, we consider the subdistribution beta-Stacy process\nprior in a nonparametric regression model for competing risks data which,\ncontrary to most others available in the literature, is not based on the\nproportional hazards assumption.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2018 17:01:02 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["Arf\u00e9", "Andrea", ""], ["Peluso", "Stefano", ""], ["Muliere", "Pietro", ""]]}, {"id": "1811.12593", "submitter": "Hongzhe Li", "authors": "Yezheng Li and Hongzhe Li", "title": "Two-sample Test of Community Memberships of Weighted Stochastic Block\n  Models", "comments": "53 pages, 2 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Suppose two networks are observed for the same set of nodes, where each\nnetwork is assumed to be generated from a weighted stochastic block model. This\npaper considers the problem of testing whether the community memberships of the\ntwo networks are the same. A test statistic based on singular subspace distance\nis developed. Under the weighted stochastic block models with dense graphs, the\nlimiting distribution of the proposed test statistic is developed. Simulation\nresults show that the test has correct empirical type 1 errors under the dense\ngraphs. The test also behaves as expected in empirical power, showing gradual\nchanges when the intra-block and inter-block distributions are close and\nachieving 1 when the two distributions are not so close, where the closeness of\nthe two distributions is characterized by Renyi divergence of order 1/2. The\nEnron email networks are used to demonstrate the proposed test.\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2018 03:14:16 GMT"}], "update_date": "2018-12-03", "authors_parsed": [["Li", "Yezheng", ""], ["Li", "Hongzhe", ""]]}, {"id": "1811.12602", "submitter": "Hossein Keshavarz", "authors": "Hossein Keshavarz, XuanLong Nguyen and Clayton Scott", "title": "Local inversion-free estimation of spatial Gaussian processes", "comments": "41 pages, 5 figures", "journal-ref": null, "doi": "10.13140/RG.2.2.17553.17764", "report-no": null, "categories": "math.ST stat.CO stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Maximizing the likelihood has been widely used for estimating the unknown\ncovariance parameters of spatial Gaussian processes. However, evaluating and\noptimizing the likelihood function can be computationally intractable,\nparticularly for large number of (possibly) irregularly spaced observations,\ndue to the need to handle the inverse of ill-conditioned and large covariance\nmatrices. Extending the \"inversion-free\" method of Anitescu, Chen and Stein\n\\cite{anitescu2017inversion}, we investigate a broad class of covariance\nparameter estimators based on inversion-free surrogate losses and block\ndiagonal approximation schemes of the covariance structure. This class of\nestimators yields a spectrum for negotiating the trade-off between statistical\naccuracy and computational cost. We present fixed-domain asymptotic properties\nof our proposed method, establishing $\\sqrt{n}$-consistency and asymptotic\nnormality results for isotropic Matern Gaussian processes observed on a\nmulti-dimensional and irregular lattice. Simulation studies are also presented\nfor assessing the scalability and statistical efficiency of the proposed\nalgorithm for large data sets.\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2018 03:44:51 GMT"}, {"version": "v2", "created": "Wed, 17 Apr 2019 09:00:48 GMT"}, {"version": "v3", "created": "Sun, 7 Jul 2019 19:50:59 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Keshavarz", "Hossein", ""], ["Nguyen", "XuanLong", ""], ["Scott", "Clayton", ""]]}, {"id": "1811.12783", "submitter": "Shuai Li", "authors": "Shuai Li", "title": "Measure, Manifold, Learning, and Optimization: A Theory Of Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.PR math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a formal measure-theoretical theory of neural networks (NN) built\non probability coupling theory. Our main contributions are summarized as\nfollows.\n  * Built on the formalism of probability coupling theory, we derive an\nalgorithm framework, named Hierarchical Measure Group and Approximate System\n(HMGAS), nicknamed S-System, that is designed to learn the complex\nhierarchical, statistical dependency in the physical world.\n  * We show that NNs are special cases of S-System when the probability kernels\nassume certain exponential family distributions. Activation Functions are\nderived formally. We further endow geometry on NNs through information\ngeometry, show that intermediate feature spaces of NNs are stochastic\nmanifolds, and prove that \"distance\" between samples is contracted as layers\nstack up.\n  * S-System shows NNs are inherently stochastic, and under a set of realistic\nboundedness and diversity conditions, it enables us to prove that for large\nsize nonlinear deep NNs with a class of losses, including the hinge loss, all\nlocal minima are global minima with zero loss errors, and regions around the\nminima are flat basins where all eigenvalues of Hessians are concentrated\naround zero, using tools and ideas from mean field theory, random matrix\ntheory, and nonlinear operator equations.\n  * S-System, the information-geometry structure and the optimization behaviors\ncombined completes the analog between Renormalization Group (RG) and NNs. It\nshows that a NN is a complex adaptive system that estimates the statistic\ndependency of microscopic object, e.g., pixels, in multiple scales. Unlike\nclear-cut physical quantity produced by RG in physics, e.g., temperature, NNs\nrenormalize/recompose manifolds emerging through learning/optimization that\ndivide the sample space into highly semantically meaningful groups that are\ndictated by supervised labels (in supervised NNs).\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2018 13:22:01 GMT"}], "update_date": "2018-12-03", "authors_parsed": [["Li", "Shuai", ""]]}, {"id": "1811.12788", "submitter": "Jerome Stenger", "authors": "Jerome Stenger, Fabrice Gamboa, Merlin Keller, Bertrand Iooss", "title": "Optimal Uncertainty Quantification on moment class using canonical\n  moments", "comments": "21 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.AP stat.CO stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We gain robustness on the quantification of a risk measurement by accounting\nfor all sources of uncertainties tainting the inputs of a computer code. We\nevaluate the maximum quantile over a class of distributions defined only by\nconstraints on their moments. The methodology is based on the theory of\ncanonical moments that appears to be a well-suited framework for practical\noptimization.\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2018 13:38:04 GMT"}], "update_date": "2018-12-03", "authors_parsed": [["Stenger", "Jerome", ""], ["Gamboa", "Fabrice", ""], ["Keller", "Merlin", ""], ["Iooss", "Bertrand", ""]]}, {"id": "1811.12804", "submitter": "Chen Cheng", "authors": "Yuxin Chen, Chen Cheng, Jianqing Fan", "title": "Asymmetry Helps: Eigenvalue and Eigenvector Analyses of Asymmetrically\n  Perturbed Low-Rank Matrices", "comments": "accepted to Annals of Statistics, 2020. 37 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT cs.NA eess.SP math.IT math.NA stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is concerned with the interplay between statistical asymmetry and\nspectral methods. Suppose we are interested in estimating a rank-1 and\nsymmetric matrix $\\mathbf{M}^{\\star}\\in \\mathbb{R}^{n\\times n}$, yet only a\nrandomly perturbed version $\\mathbf{M}$ is observed. The noise matrix\n$\\mathbf{M}-\\mathbf{M}^{\\star}$ is composed of zero-mean independent (but not\nnecessarily homoscedastic) entries and is, therefore, not symmetric in general.\nThis might arise, for example, when we have two independent samples for each\nentry of $\\mathbf{M}^{\\star}$ and arrange them into an {\\em asymmetric} data\nmatrix $\\mathbf{M}$. The aim is to estimate the leading eigenvalue and\neigenvector of $\\mathbf{M}^{\\star}$. We demonstrate that the leading eigenvalue\nof the data matrix $\\mathbf{M}$ can be $O(\\sqrt{n})$ times more accurate --- up\nto some log factor --- than its (unadjusted) leading singular value in\neigenvalue estimation. Further, the perturbation of any linear form of the\nleading eigenvector of $\\mathbf{M}$ --- say, entrywise eigenvector perturbation\n--- is provably well-controlled. This eigen-decomposition approach is fully\nadaptive to heteroscedasticity of noise without the need of careful bias\ncorrection or any prior knowledge about the noise variance. We also provide\npartial theory for the more general rank-$r$ case. The takeaway message is\nthis: arranging the data samples in an asymmetric manner and performing\neigen-decomposition could sometimes be beneficial.\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2018 14:18:26 GMT"}, {"version": "v2", "created": "Wed, 26 Dec 2018 14:50:03 GMT"}, {"version": "v3", "created": "Tue, 1 Jan 2019 07:52:48 GMT"}, {"version": "v4", "created": "Tue, 30 Jul 2019 01:25:22 GMT"}, {"version": "v5", "created": "Sun, 23 Feb 2020 08:41:24 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Chen", "Yuxin", ""], ["Cheng", "Chen", ""], ["Fan", "Jianqing", ""]]}, {"id": "1811.12853", "submitter": "Fritjof Freise", "authors": "Fritjof Freise and Rainer Schwabe", "title": "Optimal designs for $K$-factor two-level models with first-order\n  interactions on a symmetrically restricted design region", "comments": null, "journal-ref": "Statistical Papers 60 (2019) 145-163", "doi": "10.1007/s00362-018-01063-x", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop $D$-optimal designs for linear models with first-order\ninteractions on a subset of the $2^K$ full factorial design region, when both\nthe number of factors set to the higher level and the number of factors set to\nthe lower level are simultaneously bounded by the same threshold. It turns out\nthat in the case of narrow margins the optimal design is concentrated only on\nthose design points, for which either the threshold is attained or the numbers\nof high and low levels are as equal as possible. In the case of wider margins\nthe settings are more spread and the resulting optimal designs are as efficient\nas a full factorial design. These findings also apply to other optimality\ncriteria.\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2018 15:48:20 GMT"}, {"version": "v2", "created": "Thu, 20 Dec 2018 12:02:48 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Freise", "Fritjof", ""], ["Schwabe", "Rainer", ""]]}]