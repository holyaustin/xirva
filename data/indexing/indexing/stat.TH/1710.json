[{"id": "1710.00019", "submitter": "Luis Leon-Novelo", "authors": "Luis G. Leon-Novelo and Terrance D. Savitsky", "title": "Fully Bayesian Estimation Under Informative Sampling", "comments": "Pages 1-29 conform the main paper and they include seven figures and\n  three tables. Pages 30-36 contain Supplementary Material and pages 36-37\n  contain references", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian estimation is increasingly popular for performing model based\ninference to support policymaking. These data are often collected from surveys\nunder informative sampling designs where subject inclusion probabilities are\ndesigned to be correlated with the response variable of interest. Sampling\nweights constructed from marginal inclusion probabilities are typically used to\nform an exponentiated pseudo likelihood that adjusts the population likelihood\nfor estimation on the sample due to ease-of-estimation. We propose an\nalternative adjustment based on a Bayes rule construction that simultaneously\nperforms weight smoothing and estimates the population model parameters in a\nfully Bayesian construction. We formulate conditions on known marginal and\npairwise inclusion probabilities that define a class of sampling designs where\n$L_{1}$ consistency of the joint posterior is guaranteed. We compare\nperformances between the two approaches on synthetic data, which reveals that\nour fully Bayesian approach better estimates posterior uncertainty without a\nrequirement to calibrate the normalization of the sampling weights. We\ndemonstrate our method on an application concerning the National Health and\nNutrition Examination Survey exploring the relationship between caffeine\nconsumption and systolic blood pressure.\n", "versions": [{"version": "v1", "created": "Fri, 29 Sep 2017 18:26:03 GMT"}, {"version": "v2", "created": "Sat, 20 Jan 2018 01:29:20 GMT"}, {"version": "v3", "created": "Thu, 12 Jul 2018 00:59:58 GMT"}], "update_date": "2018-07-13", "authors_parsed": [["Leon-Novelo", "Luis G.", ""], ["Savitsky", "Terrance D.", ""]]}, {"id": "1710.00080", "submitter": "Davy Paindaveine", "authors": "Giuseppe Pandolfo, Davy Paindaveine, Giovanni Porzio", "title": "Distance-based Depths for Directional Data", "comments": "19 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Directional data are constrained to lie on the unit sphere of~$\\mathbb{R}^q$\nfor some~$q\\geq 2$. To address the lack of a natural ordering for such data,\ndepth functions have been defined on spheres. However, the depths available\neither lack flexibility or are so computationally expensive that they can only\nbe used for very small dimensions~$q$. In this work, we improve on this by\nintroducing a class of distance-based depths for directional data. Irrespective\nof the distance adopted, these depths can easily be computed in high dimensions\ntoo. We derive the main structural properties of the proposed depths and study\nhow they depend on the distance used. We discuss the asymptotic and robustness\nproperties of the corresponding deepest points. We show the practical relevance\nof the proposed depths in two applications, related to (i) spherical location\nestimation and (ii) supervised classification. For both problems, we show\nthrough simulation studies that distance-based depths have strong advantages\nover their competitors.\n", "versions": [{"version": "v1", "created": "Fri, 29 Sep 2017 20:26:29 GMT"}, {"version": "v2", "created": "Thu, 2 Aug 2018 18:33:39 GMT"}], "update_date": "2018-08-06", "authors_parsed": [["Pandolfo", "Giuseppe", ""], ["Paindaveine", "Davy", ""], ["Porzio", "Giovanni", ""]]}, {"id": "1710.00095", "submitter": "Arnak Dalalyan S.", "authors": "Arnak S. Dalalyan and Avetik G. Karagulyan", "title": "User-friendly guarantees for the Langevin Monte Carlo with inaccurate\n  gradient", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG math.PR stat.CO stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of sampling from a given probability\ndensity function that is known to be smooth and strongly log-concave. We\nanalyze several methods of approximate sampling based on discretizations of the\n(highly overdamped) Langevin diffusion and establish guarantees on its error\nmeasured in the Wasserstein-2 distance. Our guarantees improve or extend the\nstate-of-the-art results in three directions. First, we provide an upper bound\non the error of the first-order Langevin Monte Carlo (LMC) algorithm with\noptimized varying step-size. This result has the advantage of being horizon\nfree (we do not need to know in advance the target precision) and to improve by\na logarithmic factor the corresponding result for the constant step-size.\nSecond, we study the case where accurate evaluations of the gradient of the\nlog-density are unavailable, but one can have access to approximations of the\naforementioned gradient. In such a situation, we consider both deterministic\nand stochastic approximations of the gradient and provide an upper bound on the\nsampling error of the first-order LMC that quantifies the impact of the\ngradient evaluation inaccuracies. Third, we establish upper bounds for two\nversions of the second-order LMC, which leverage the Hessian of the\nlog-density. We nonasymptotic guarantees on the sampling error of these\nsecond-order LMCs. These guarantees reveal that the second-order LMC algorithms\nimprove on the first-order LMC in ill-conditioned settings.\n", "versions": [{"version": "v1", "created": "Fri, 29 Sep 2017 21:15:03 GMT"}, {"version": "v2", "created": "Mon, 6 Nov 2017 21:01:23 GMT"}, {"version": "v3", "created": "Mon, 10 Sep 2018 11:46:52 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Dalalyan", "Arnak S.", ""], ["Karagulyan", "Avetik G.", ""]]}, {"id": "1710.00229", "submitter": "Natalia Markovich M", "authors": "Natalia Markovich", "title": "Clustering and Hitting Times of Threshold Exceedances and Applications", "comments": "19 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate exceedances of the process over a sufficiently high threshold.\nThe exceedances determine the risk of hazardous events like climate\ncatastrophes, huge insurance claims, the loss and delay in telecommunication\nnetworks.\n  Due to dependence such exceedances tend to occur in clusters. The cluster\nstructure of social networks is caused by dependence (social relationships and\ninterests) between nodes and possibly heavy-tailed distributions of the node\ndegrees. A minimal time to reach a large node determines the first hitting\ntime. We derive an asymptotically equivalent distribution and a limit\nexpectation of the first hitting time to exceed the threshold $u_n$ as the\nsample size $n$ tends to infinity. The results can be extended to the second\nand, generally, to the $k$th ($k> 2$) hitting times. Applications in\nlarge-scale networks such as social, telecommunication and recommender systems\nare discussed.\n", "versions": [{"version": "v1", "created": "Sat, 30 Sep 2017 17:21:54 GMT"}], "update_date": "2017-10-03", "authors_parsed": [["Markovich", "Natalia", ""]]}, {"id": "1710.00479", "submitter": "Edgar Dobriban", "authors": "Edgar Dobriban", "title": "Permutation methods for factor analysis and PCA", "comments": "To appear in the Annals of Statistics", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Researchers often have datasets measuring features $x_{ij}$ of samples, such\nas test scores of students. In factor analysis and PCA, these features are\nthought to be influenced by unobserved factors, such as skills. Can we\ndetermine how many components affect the data? This is an important problem,\nbecause it has a large impact on all downstream data analysis. Consequently,\nmany approaches have been developed to address it. Parallel Analysis is a\npopular permutation method. It works by randomly scrambling each feature of the\ndata. It selects components if their singular values are larger than those of\nthe permuted data. Despite widespread use in leading textbooks and scientific\npublications, as well as empirical evidence for its accuracy, it currently has\nno theoretical justification.\n  In this paper, we show that the parallel analysis permutation method\nconsistently selects the large components in certain high-dimensional factor\nmodels. However, it does not select the smaller components. The intuition is\nthat permutations keep the noise invariant, while \"destroying\" the low-rank\nsignal. This provides justification for permutation methods in PCA and factor\nmodels under some conditions. Our work uncovers drawbacks of permutation\nmethods, and paves the way to improvements.\n", "versions": [{"version": "v1", "created": "Mon, 2 Oct 2017 04:29:22 GMT"}, {"version": "v2", "created": "Sat, 6 Oct 2018 15:44:39 GMT"}, {"version": "v3", "created": "Fri, 13 Sep 2019 13:25:11 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Dobriban", "Edgar", ""]]}, {"id": "1710.00499", "submitter": "Aaditya Ramdas", "authors": "Aaditya Ramdas, Fanny Yang, Martin J. Wainwright, Michael I. Jordan", "title": "Online control of the false discovery rate with decaying memory", "comments": "20 pages, 4 figures. Published in the proceedings of NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the online multiple testing problem, p-values corresponding to different\nnull hypotheses are observed one by one, and the decision of whether or not to\nreject the current hypothesis must be made immediately, after which the next\np-value is observed. Alpha-investing algorithms to control the false discovery\nrate (FDR), formulated by Foster and Stine, have been generalized and applied\nto many settings, including quality-preserving databases in science and\nmultiple A/B or multi-armed bandit tests for internet commerce. This paper\nimproves the class of generalized alpha-investing algorithms (GAI) in four\nways: (a) we show how to uniformly improve the power of the entire class of\nmonotone GAI procedures by awarding more alpha-wealth for each rejection,\ngiving a win-win resolution to a recent dilemma raised by Javanmard and\nMontanari, (b) we demonstrate how to incorporate prior weights to indicate\ndomain knowledge of which hypotheses are likely to be non-null, (c) we allow\nfor differing penalties for false discoveries to indicate that some hypotheses\nmay be more important than others, (d) we define a new quantity called the\ndecaying memory false discovery rate (mem-FDR) that may be more meaningful for\ntruly temporal applications, and which alleviates problems that we describe and\nrefer to as \"piggybacking\" and \"alpha-death\". Our GAI++ algorithms incorporate\nall four generalizations simultaneously, and reduce to more powerful variants\nof earlier algorithms when the weights and decay are all set to unity. Finally,\nwe also describe a simple method to derive new online FDR rules based on an\nestimated false discovery proportion.\n", "versions": [{"version": "v1", "created": "Mon, 2 Oct 2017 06:13:37 GMT"}], "update_date": "2017-10-03", "authors_parsed": [["Ramdas", "Aaditya", ""], ["Yang", "Fanny", ""], ["Wainwright", "Martin J.", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1710.00502", "submitter": "Ms Eliwa", "authors": "Mohamed Ibrahim, M. S. Eliwa, M. El- Morshedy", "title": "Bivariate Exponentiated Generalized Linear Exponential Distribution with\n  Applications in Reliability Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of this paper, is to define a bivariate exponentiated generalized\nlinear exponential distribution based on Marshall-Olkin shock model.\nStatistical and reliability properties of this distribution are discussed. This\nincludes quantiles, moments, stress-strength reliability, joint reliability\nfunction, joint reversed (hazard) rates functions and joint mean waiting time\nfunction. Moreover, the hazard rate, the availability and the mean residual\nlifetime functions for a parallel system, are established. One data set is\nanalyzed, and it is observed that, the proposed distribution provides a better\nfit than Marshall-Olkin bivariate exponential, bivariate generalized\nexponential and bivariate generalized linear failure rate distributions.\nSimulation studies are presented to estimate both the relative absolute bias,\nand the relative mean square error for the distribution parameters based on\ncomplete data.\n", "versions": [{"version": "v1", "created": "Mon, 2 Oct 2017 06:21:44 GMT"}], "update_date": "2017-10-03", "authors_parsed": [["Ibrahim", "Mohamed", ""], ["Eliwa", "M. S.", ""], ["Morshedy", "M. El-", ""]]}, {"id": "1710.00576", "submitter": "Mikhail  Ermakov s", "authors": "Mikhail Ermakov", "title": "On minimax nonparametric estimation of signal in Gaussian noise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For the problem of nonparametric estimation of signal in Gaussian noise we\npoint out the strong asymptotically minimax estimators on maxisets for linear\nestimators (see \\cite{ker93,rio}). It turns out that the order of rates of\nconvergence of Pinsker estimator on this maxisets is worse than the order of\nrates of convergence for the class of linear estimators considered on this\nmaxisets. We show that balls in Sobolev spaces are maxisets for Pinsker\nestimators.\n", "versions": [{"version": "v1", "created": "Mon, 2 Oct 2017 10:56:35 GMT"}, {"version": "v2", "created": "Sun, 5 Nov 2017 11:38:56 GMT"}], "update_date": "2017-11-07", "authors_parsed": [["Ermakov", "Mikhail", ""]]}, {"id": "1710.00643", "submitter": "Stephan Smeekes", "authors": "Eric Beutner, Alexander Heinemann and Stephan Smeekes", "title": "A Justification of Conditional Confidence Intervals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To quantify uncertainty around point estimates of conditional objects such as\nconditional means or variances, parameter uncertainty has to be taken into\naccount. Attempts to incorporate parameter uncertainty are typically based on\nthe unrealistic assumption of observing two independent processes, where one is\nused for parameter estimation, and the other for conditioning upon. Such\nunrealistic foundation raises the question whether these intervals are\ntheoretically justified in a realistic setting. This paper presents an\nasymptotic justification for this type of intervals that does not require such\nan unrealistic assumption, but relies on a sample-split approach instead. By\nshowing that our sample-split intervals coincide asymptotically with the\nstandard intervals, we provide a novel, and realistic, justification for\nconfidence intervals of conditional objects. The analysis is carried out for a\nrich class of time series models.\n", "versions": [{"version": "v1", "created": "Mon, 2 Oct 2017 13:53:13 GMT"}, {"version": "v2", "created": "Sat, 19 Jan 2019 14:43:53 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Beutner", "Eric", ""], ["Heinemann", "Alexander", ""], ["Smeekes", "Stephan", ""]]}, {"id": "1710.00769", "submitter": "Shovan Chowdhury", "authors": "Amarjit Kundu and Shovan Chowdhury", "title": "Stochastic Comparisons of Lifetimes of Two Series and Parallel Systems\n  with Location-Scale Family Distributed Components having Archimedean Copulas", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we compare the lifetimes of two series and two parallel\nsystems stochastically where the lifetime of each component follows\nlocation-scale (LS) family of distributions. The comparison is carried out\nunder two scenarios: one, that the components of the systems have a dependent\nstructure sharing Archimedean copula and two, that the components are\nindependently distributed. It is shown that the systems with components in\nseries or parallel sharing Archimedean copula with more dispersion in the\nlocation or scale parameters results in better performance in the sense of the\nusual stochastic order. It is also shown that if the components are\nindependently distributed, it is possible to obtain more generalized results as\ncompared to the dependent set-up. The results in this paper generalizes similar\nresults in both independent and dependent set up for exponential and Weibull\ndistributed components.\n", "versions": [{"version": "v1", "created": "Mon, 2 Oct 2017 16:45:37 GMT"}], "update_date": "2017-10-03", "authors_parsed": [["Kundu", "Amarjit", ""], ["Chowdhury", "Shovan", ""]]}, {"id": "1710.00862", "submitter": "Chao Gao", "authors": "Chao Gao and John Lafferty", "title": "Testing for Global Network Structure Using Small Subgraph Statistics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.SI math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of testing for community structure in networks using\nrelations between the observed frequencies of small subgraphs. We propose a\nsimple test for the existence of communities based only on the frequencies of\nthree-node subgraphs. The test statistic is shown to be asymptotically normal\nunder a null assumption of no community structure, and to have power\napproaching one under a composite alternative hypothesis of a degree-corrected\nstochastic block model. We also derive a version of the test that applies to\nmultivariate Gaussian data. Our approach achieves near-optimal detection rates\nfor the presence of community structure, in regimes where the signal-to-noise\nis too weak to explicitly estimate the communities themselves, using existing\ncomputationally efficient algorithms. We demonstrate how the method can be\neffective for detecting structure in social networks, citation networks for\nscientific articles, and correlations of stock returns between companies on the\nS\\&P 500.\n", "versions": [{"version": "v1", "created": "Mon, 2 Oct 2017 18:39:20 GMT"}, {"version": "v2", "created": "Mon, 16 Oct 2017 04:57:52 GMT"}], "update_date": "2017-10-17", "authors_parsed": [["Gao", "Chao", ""], ["Lafferty", "John", ""]]}, {"id": "1710.00915", "submitter": "Yanglei Song", "authors": "Yanglei Song and Georgios Fellouris", "title": "Change Acceleration and Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel sequential change detection problem is proposed, in which the change\nshould be not only detected but also accelerated. Specifically, it is assumed\nthat the sequentially collected observations are responses to treatments\nselected in real time. The assigned treatments not only determine the\npre-change and post-change distributions of the responses, but also influence\nwhen the change happens. The problem is to find a treatment assignment rule and\na stopping rule that minimize the expected total number of observations subject\nto a user-specified bound on the false alarm probability. The optimal solution\nto this problem is obtained under a general Markovian change-point model.\nMoreover, an alternative procedure is proposed, whose applicability is not\nrestricted to Markovian change-point models and whose design requires minimal\ncomputation. For a large class of change-point models, the proposed procedure\nis shown to achieve the optimal performance in an asymptotic sense. Finally,\nits performance is found in two simulation studies to be close to the optimal,\nuniformly with respect to the error probability.\n", "versions": [{"version": "v1", "created": "Mon, 2 Oct 2017 21:23:18 GMT"}, {"version": "v2", "created": "Wed, 12 Aug 2020 13:48:55 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Song", "Yanglei", ""], ["Fellouris", "Georgios", ""]]}, {"id": "1710.01094", "submitter": "Guillermo Durand", "authors": "Guillermo Durand (LPSM UMR 8001)", "title": "Adaptive p-value weighting with power optimality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Weighting the p-values is a well-established strategy that improves the power\nof multiple testing procedures while dealing with heterogeneous data. However,\nhow to achieve this task in an optimal way is rarely considered in the\nliterature. This paper contributes to fill the gap in the case of\ngroup-structured null hypotheses, by introducing a new class of procedures\nnamed ADDOW (for Adaptive Data Driven Optimal Weighting) that adapts both to\nthe alternative distribution and to the proportion of true null hypotheses. We\nprove the asymptotical FDR control and power optimality among all weighted\nprocedures of ADDOW, which shows that it dominates all existing procedures in\nthat framework. Some numerical experiments show that the proposed method\npreserves its optimal properties in the finite sample setting when the number\nof tests is moderately large.\n", "versions": [{"version": "v1", "created": "Tue, 3 Oct 2017 11:46:14 GMT"}, {"version": "v2", "created": "Thu, 21 Mar 2019 12:43:06 GMT"}], "update_date": "2019-03-22", "authors_parsed": [["Durand", "Guillermo", "", "LPSM UMR 8001"]]}, {"id": "1710.01200", "submitter": "Jiehua Xie", "authors": "Jiehua Xie, Jingping Yang, Wenhao Zhu", "title": "A family of transformed copulas with singular component", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a family of bivariate copulas by transforming a\ngiven copula function with two increasing functions, named as transformed\ncopula. One distinctive characteristic of the transformed copula is its\nsingular component along the main diagonal. Conditions guaranteeing the\ntransformed function to be a copula function are provided, and several classes\nof the transformed copulas are given. The singular component along the main\ndiagonal of the transformed copula is verified, and the tail dependence\ncoefficients of the transformed copulas are obtained. Finally, some properties\nof the transformed copula are discussed, such as the totally positive of order\n2 and the concordance order.\n", "versions": [{"version": "v1", "created": "Tue, 3 Oct 2017 15:02:42 GMT"}], "update_date": "2017-10-04", "authors_parsed": [["Xie", "Jiehua", ""], ["Yang", "Jingping", ""], ["Zhu", "Wenhao", ""]]}, {"id": "1710.01295", "submitter": "Ethan Anderes", "authors": "Ethan Anderes and Jesper M{\\o}ller and Jakob G. Rasmussen", "title": "Isotropic covariance functions on graphs and their edges", "comments": "6 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop parametric classes of covariance functions on linear networks and\ntheir extension to graphs with Euclidean edges, i.e., graphs with edges viewed\nas line segments or more general sets with a coordinate system allowing us to\nconsider points on the graph which are vertices or points on an edge. Our\ncovariance functions are defined on the vertices and edge points of these\ngraphs and are isotropic in the sense that they depend only on the geodesic\ndistance or on a new metric called the resistance metric (which extends the\nclassical resistance metric developed in electrical network theory on the\nvertices of a graph to the continuum of edge points). We discuss the advantages\nof using the resistance metric in comparison with the geodesic metric as well\nas the restrictions these metrics impose on the investigated covariance\nfunctions. In particular, many of the commonly used isotropic covariance\nfunctions in the spatial statistics literature (the power exponential,\nMat{\\'e}rn, generalized Cauchy, and Dagum classes) are shown to be valid with\nrespect to the resistance metric for any graph with Euclidean edges, whilst\nthey are only valid with respect to the geodesic metric in more special cases.\n", "versions": [{"version": "v1", "created": "Tue, 3 Oct 2017 17:53:36 GMT"}, {"version": "v2", "created": "Thu, 2 May 2019 15:29:22 GMT"}], "update_date": "2019-05-03", "authors_parsed": [["Anderes", "Ethan", ""], ["M\u00f8ller", "Jesper", ""], ["Rasmussen", "Jakob G.", ""]]}, {"id": "1710.01437", "submitter": "Elina Robeva Massachusetts Institute of Technology", "authors": "Elina Robeva and Anna Seigal", "title": "Duality of Graphical Models and Tensor Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.AI quant-ph stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we show the duality between tensor networks and undirected\ngraphical models with discrete variables. We study tensor networks on\nhypergraphs, which we call tensor hypernetworks. We show that the tensor\nhypernetwork on a hypergraph exactly corresponds to the graphical model given\nby the dual hypergraph. We translate various notions under duality. For\nexample, marginalization in a graphical model is dual to contraction in the\ntensor network. Algorithms also translate under duality. We show that belief\npropagation corresponds to a known algorithm for tensor network contraction.\nThis article is a reminder that the research areas of graphical models and\ntensor networks can benefit from interaction.\n", "versions": [{"version": "v1", "created": "Wed, 4 Oct 2017 01:55:05 GMT"}], "update_date": "2017-10-05", "authors_parsed": [["Robeva", "Elina", ""], ["Seigal", "Anna", ""]]}, {"id": "1710.01552", "submitter": "Moritz von Rohrscheidt", "authors": "Fritz Moritz von Rohrscheidt", "title": "Bayesian inference for stationary data on finite state spaces", "comments": "Supported by DFG (German research foundation); grant 1953", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work the issue of Bayesian inference for stationary data is\naddressed. Therefor a parametrization of a statistically suitable subspace of\nthe the shift-ergodic probability measures on a Cartesian product of some\nfinite state space is given using an inverse limit construction. Moreover, an\nexplicit model for the prior is given by taking into account an additional step\nin the usual stepwise sampling scheme of data. An update to the posterior is\ndefined by exploiting this augmented sample scheme. Thereby, its model-step is\nupdated using a measurement of the empirical distances between the model\nclasses.\n", "versions": [{"version": "v1", "created": "Wed, 4 Oct 2017 11:28:05 GMT"}, {"version": "v2", "created": "Thu, 5 Oct 2017 16:44:56 GMT"}, {"version": "v3", "created": "Mon, 23 Oct 2017 07:13:31 GMT"}], "update_date": "2017-10-24", "authors_parsed": [["von Rohrscheidt", "Fritz Moritz", ""]]}, {"id": "1710.01598", "submitter": "Anthony David Blaom", "authors": "Anthony D. Blaom", "title": "A geometer's view of the the Cram\\'er-Rao bound on estimator variance", "comments": "Added classical bound in terms of Fisher information matrix", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.OT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The classical Cram\\'er-Rao inequality gives a lower bound for the variance of\na unbiased estimator of an unknown parameter, in some statistical model of a\nrandom process. In this note we rewrite the statment and proof of the bound\nusing contemporary geometric language.\n", "versions": [{"version": "v1", "created": "Tue, 3 Oct 2017 04:03:19 GMT"}, {"version": "v2", "created": "Wed, 25 Oct 2017 21:48:37 GMT"}], "update_date": "2017-10-27", "authors_parsed": [["Blaom", "Anthony D.", ""]]}, {"id": "1710.01612", "submitter": "Murad S. Taqqu", "authors": "Shuyang Bai, Murad s. Taqqu", "title": "Sensivity of the Hermite rank", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Hermite rank appears in limit theorems involving long memory. We show\nthat an Hermite rank higher than one is unstable when the data is slightly\nperturbed by transformations such as shift and scaling. We carry out a \"near\nhigher order rank analysis\" to illustrate how the limit theorems are affected\nby a shift perturbation that is decreasing in size. As a byproduct of our\nanalysis, we also prove the coincidence of the Hermite rank and the power rank\nin the Gaussian context. The paper is a technical companion of\n\\citet{bai:taqqu:2017:instability} which discusses the instability of the\nHermite rank in the statistical context. (Older title \"Some properties of the\nHermite rank\">)\n", "versions": [{"version": "v1", "created": "Wed, 4 Oct 2017 14:18:00 GMT"}, {"version": "v2", "created": "Sat, 6 Jan 2018 16:03:18 GMT"}], "update_date": "2018-01-09", "authors_parsed": [["Bai", "Shuyang", ""], ["Taqqu", "Murad s.", ""]]}, {"id": "1710.01649", "submitter": "Igor Cialenco", "authors": "Igor Cialenco and Yicong Huang", "title": "A note on parameter estimation for discretely sampled SPDEs", "comments": "Forthcoming in Stochastics and Dynamics", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a parameter estimation problem for one dimensional stochastic\nheat equations, when data is sampled discretely in time or spatial component.\nWe prove that, the real valued parameter next to the Laplacian (the drift), and\nthe constant parameter in front of the noise (the volatility) can be\nconsistently estimated under somewhat surprisingly minimal information. Namely,\nit is enough to observe the solution at a fixed time and on a discrete spatial\ngrid, or at a fixed space point and at discrete time instances of a finite\ninterval, assuming that the mesh-size goes to zero. The proposed estimators\nhave the same form and asymptotic properties regardless of the nature of the\ndomain - bounded domain or whole space. The derivation of the estimators and\nthe proofs of their asymptotic properties are based on computations of power\nvariations of some relevant stochastic processes. We use elements of Malliavin\ncalculus to establish the asymptotic normality properties in the case of\nbounded domain. We also discuss the joint estimation problem of the drift and\nvolatility coefficient. We conclude with some numerical experiments that\nillustrate the obtained theoretical results.\n", "versions": [{"version": "v1", "created": "Wed, 4 Oct 2017 15:15:27 GMT"}, {"version": "v2", "created": "Tue, 16 Jul 2019 03:46:26 GMT"}], "update_date": "2019-07-17", "authors_parsed": [["Cialenco", "Igor", ""], ["Huang", "Yicong", ""]]}, {"id": "1710.01696", "submitter": "Elizabeth Allman", "authors": "Elizabeth S. Allman, Hector Ba\\~nos Cervantes, Robin Evans, Serkan\n  Ho\\c{s}ten, Kaie Kubjas, Daniel Lemke, John A. Rhodes, Piotr Zwiernik", "title": "Maximum likelihood estimation of the Latent Class Model through model\n  boundary decomposition", "comments": "Revised version after incorporating reviewers' comments", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.AG stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Expectation-Maximization (EM) algorithm is routinely used for the maximum\nlikelihood estimation in the latent class analysis. However, the EM algorithm\ncomes with no guarantees of reaching the global optimum. We study the geometry\nof the latent class model in order to understand the behavior of the maximum\nlikelihood estimator. In particular, we characterize the boundary\nstratification of the binary latent class model with a binary hidden variable.\nFor small models, such as for three binary observed variables, we show that\nthis stratification allows exact computation of the maximum likelihood\nestimator. In this case we use simulations to study the maximum likelihood\nestimation attraction basins of the various strata. Our theoretical study is\ncomplemented with a careful analysis of the EM fixed point ideal which provides\nan alternative method of studying the boundary stratification and maximizing\nthe likelihood function. In particular, we compute the minimal primes of this\nideal in the case of a binary latent class model with a binary or ternary\nhidden random variable.\n", "versions": [{"version": "v1", "created": "Wed, 4 Oct 2017 16:56:57 GMT"}, {"version": "v2", "created": "Mon, 20 Aug 2018 16:55:50 GMT"}], "update_date": "2018-08-21", "authors_parsed": [["Allman", "Elizabeth S.", ""], ["Cervantes", "Hector Ba\u00f1os", ""], ["Evans", "Robin", ""], ["Ho\u015ften", "Serkan", ""], ["Kubjas", "Kaie", ""], ["Lemke", "Daniel", ""], ["Rhodes", "John A.", ""], ["Zwiernik", "Piotr", ""]]}, {"id": "1710.01852", "submitter": "Mohamad Kazem Shirani Faradonbeh", "authors": "Mohamad Kazem Shirani Faradonbeh, Ambuj Tewari, and George Michailidis", "title": "Finite Time Identification in Unstable Linear Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY econ.EM eess.SP math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identification of the parameters of stable linear dynamical systems is a\nwell-studied problem in the literature, both in the low and high-dimensional\nsettings. However, there are hardly any results for the unstable case,\nespecially regarding finite time bounds. For this setting, classical results on\nleast-squares estimation of the dynamics parameters are not applicable and\ntherefore new concepts and technical approaches need to be developed to address\nthe issue. Unstable linear systems arise in key real applications in control\ntheory, econometrics, and finance. This study establishes finite time bounds\nfor the identification error of the least-squares estimates for a fairly large\nclass of heavy-tailed noise distributions, and transition matrices of such\nsystems. The results relate the time length (samples) required for estimation\nto a function of the problem dimension and key characteristics of the true\nunderlying transition matrix and the noise distribution. To establish them,\nappropriate concentration inequalities for random matrices and for sequences of\nmartingale differences are leveraged.\n", "versions": [{"version": "v1", "created": "Thu, 5 Oct 2017 01:27:34 GMT"}, {"version": "v2", "created": "Tue, 5 Jun 2018 06:26:08 GMT"}], "update_date": "2018-06-06", "authors_parsed": [["Faradonbeh", "Mohamad Kazem Shirani", ""], ["Tewari", "Ambuj", ""], ["Michailidis", "George", ""]]}, {"id": "1710.01871", "submitter": "Todd Kuffner", "authors": "John E. Kolassa and Todd A. Kuffner", "title": "On the validity of the formal Edgeworth expansion for posterior\n  densities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a fundamental open problem in parametric Bayesian theory, namely\nthe validity of the formal Edgeworth expansion of the posterior density. While\nthe study of valid asymptotic expansions for posterior distributions\nconstitutes a rich literature, the validity of the formal Edgeworth expansion\nhas not been rigorously established. Several authors have claimed connections\nof various posterior expansions with the classical Edgeworth expansion, or have\nsimply assumed its validity. Our main result settles this open problem. We also\nprove a lemma concerning the order of posterior cumulants which is of\nindependent interest in Bayesian parametric theory. The most relevant\nliterature is synthesized and compared to the newly-derived Edgeworth\nexpansions. Numerical investigations illustrate that our expansion has the\nbehavior expected of an Edgeworth expansion, and that it has better performance\nthan the other existing expansion which was previously claimed to be of\nEdgeworth-type.\n", "versions": [{"version": "v1", "created": "Thu, 5 Oct 2017 03:30:48 GMT"}], "update_date": "2017-10-06", "authors_parsed": [["Kolassa", "John E.", ""], ["Kuffner", "Todd A.", ""]]}, {"id": "1710.01898", "submitter": "Ansgar Steland", "authors": "Ansgar Steland and Yuan-Tsung Chang", "title": "Jackknife variance estimation for common mean estimators under ordered\n  variances and general two-sample statistics", "comments": "37 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Samples with a common mean but possibly different, ordered variances arise in\nvarious fields such as interlaboratory experiments, field studies or the\nanalysis of sensor data. Estimators for the common mean under ordered variances\ntypically employ random weights, which depend on the sample means and the\nunbiased variance estimators. They take different forms when the sample\nestimators are in agreement with the order constraints or not, which\ncomplicates even basic analyses such as estimating their variance. We propose\nto use the jackknife, whose consistency is established for general smooth\ntwo--sample statistics induced by continuously G\\^ateux or Fr\\'echet\ndifferentiable functionals, and, more generally, asymptotically linear\ntwo--sample statistics, allowing us to study a large class of common mean\nestimators. Further, it is shown that the common mean estimators under\nconsideration satisfy a central limit theorem (CLT). We investigate the\naccuracy of the resulting confidence intervals by simulations and illustrate\nthe approach by analyzing several data sets.\n", "versions": [{"version": "v1", "created": "Thu, 5 Oct 2017 07:08:18 GMT"}, {"version": "v2", "created": "Tue, 29 Jan 2019 09:14:58 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Steland", "Ansgar", ""], ["Chang", "Yuan-Tsung", ""]]}, {"id": "1710.02159", "submitter": "Benjamin Bloem-Reddy", "authors": "Benjamin Bloem-Reddy and Peter Orbanz", "title": "Preferential Attachment and Vertex Arrival Times", "comments": "34 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.SI math.ST physics.soc-ph stat.TH", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We study preferential attachment mechanisms in random graphs that are\nparameterized by (i) a constant bias affecting the degree-biased distribution\non the vertex set and (ii) the distribution of times at which new vertices are\ncreated by the model. The class of random graphs so defined admits a\nrepresentation theorem reminiscent of residual allocation, or \"stick-breaking\"\nschemes. We characterize how the vertex arrival times affect the asymptotic\ndegree distribution, and relate the latter to neutral-to-the-left processes.\nOur random graphs generate edges \"one end at a time\", which sets up a\none-to-one correspondence between random graphs and random partitions of\nnatural numbers; via this map, our representation induces a result on (not\nnecessarily exchangeable) random partitions that generalizes a theorem of\nGriffiths and Span\\'o. A number of examples clarify how the class intersects\nwith several known random graph models.\n", "versions": [{"version": "v1", "created": "Thu, 5 Oct 2017 18:01:09 GMT"}], "update_date": "2017-10-09", "authors_parsed": [["Bloem-Reddy", "Benjamin", ""], ["Orbanz", "Peter", ""]]}, {"id": "1710.02333", "submitter": "Bruno Ebner", "authors": "Bruno Ebner, Norbert Henze, Michael A. Klatt and Klaus Mecke", "title": "Goodness-of-fit tests for complete spatial randomness based on Minkowski\n  functionals of binary images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a class of goodness-of-fit tests for complete spatial randomness\n(CSR). In contrast to standard tests, our procedure utilizes a transformation\nof the data to a binary image, which is then characterized by geometric\nfunctionals. Under a suitable limiting regime, we derive the asymptotic\ndistribution of the test statistics under the null hypothesis and almost sure\nlimits under certain alternatives. The new tests are computationally efficient,\nand simulations show that they are strong competitors to other tests of CSR.\nThe tests are applied to a real data set in gamma-ray astronomy, and immediate\nextensions are presented to encourage further work.\n", "versions": [{"version": "v1", "created": "Fri, 6 Oct 2017 09:59:58 GMT"}], "update_date": "2017-10-09", "authors_parsed": [["Ebner", "Bruno", ""], ["Henze", "Norbert", ""], ["Klatt", "Michael A.", ""], ["Mecke", "Klaus", ""]]}, {"id": "1710.02537", "submitter": "Todd Kuffner", "authors": "Todd A. Kuffner, Stephen M.S. Lee and G. Alastair Young", "title": "Optimal hybrid block bootstrap for sample quantiles under weak\n  dependence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We establish a general theory of optimality for block bootstrap distribution\nestimation for sample quantiles under a mild strong mixing assumption. In\ncontrast to existing results, we study the block bootstrap for varying numbers\nof blocks. This corresponds to a hybrid between the subsampling bootstrap and\nthe moving block bootstrap (MBB), in which the number of blocks is somewhere\nbetween 1 and the ratio of sample size to block length. Our main theorem\ndetermines the optimal choice of the number of blocks and block length to\nachieve the best possible convergence rate for the block bootstrap distribution\nestimator for sample quantiles. As part of our analysis, we also prove an\nimportant lemma which gives the convergence rate of the block bootstrap\ndistribution estimator, with implications even for the smooth function model.\nWe propose an intuitive procedure for empirical selection of the optimal number\nand length of blocks. Relevant examples are presented which illustrate the\nbenefits of optimally choosing the number of blocks.\n", "versions": [{"version": "v1", "created": "Fri, 6 Oct 2017 18:01:58 GMT"}], "update_date": "2017-10-10", "authors_parsed": [["Kuffner", "Todd A.", ""], ["Lee", "Stephen M. S.", ""], ["Young", "G. Alastair", ""]]}, {"id": "1710.02561", "submitter": "Leonardo Moreno L. Moreno", "authors": "Ricardo Fraiman, Fabrice Gamboa, Leonardo Moreno", "title": "Connecting pairwise spheres by depth: DCOPS", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend the classical notion of the spherical depth in \\mathbb{R}^k, to the\nimportant setup of data on a Riemannian manifold. We show that this notion of\ndepth satisfies a set of desirable properties. For the empirical version of\nthis depth function both uniform consistency and the asymptotic distribution\nare studied. Consistency is also shown for functional data. The behaviour of\nthe depth is illustrated through several examples for Riemannian manifold data.\n", "versions": [{"version": "v1", "created": "Fri, 6 Oct 2017 19:24:38 GMT"}, {"version": "v2", "created": "Thu, 30 Nov 2017 12:00:02 GMT"}, {"version": "v3", "created": "Fri, 27 Apr 2018 22:03:51 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Fraiman", "Ricardo", ""], ["Gamboa", "Fabrice", ""], ["Moreno", "Leonardo", ""]]}, {"id": "1710.02696", "submitter": "Yury Kutoyants", "authors": "O.V. Chernoyarov, Yu.A. Kutoyants", "title": "On frequency estimation for partially observed processes with small\n  noise in observations", "comments": "24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of frequency estimation of the periodic signal\nmultiplied by a stationary Gaussian process (Ornstein-Uhlenbeck) and observed\nin the presence of the white Gaussian noise. We show the consistency and\nasymptotic normality of the maximum likelihood estimator in the asymptotics of\nsmall noise in observations. The model of observations is a linear\nnonhomogeneous partially observed system and the construction and study of the\nestimator is essentialy based on the asymptotics of the equations of\nKalman-Bucy filtration.\n", "versions": [{"version": "v1", "created": "Sat, 7 Oct 2017 15:15:51 GMT"}], "update_date": "2017-10-10", "authors_parsed": [["Chernoyarov", "O. V.", ""], ["Kutoyants", "Yu. A.", ""]]}, {"id": "1710.02704", "submitter": "Zemin Zheng", "authors": "Zemin Zheng, Jinchi Lv and Wei Lin", "title": "Nonsparse learning with latent variables", "comments": "30 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a popular tool for producing meaningful and interpretable models,\nlarge-scale sparse learning works efficiently when the underlying structures\nare indeed or close to sparse. However, naively applying the existing\nregularization methods can result in misleading outcomes due to model\nmisspecification. In particular, the direct sparsity assumption on coefficient\nvectors has been questioned in real applications. Therefore, we consider\nnonsparse learning with the conditional sparsity structure that the coefficient\nvector becomes sparse after taking out the impacts of certain unobservable\nlatent variables. A new methodology of nonsparse learning with latent variables\n(NSL) is proposed to simultaneously recover the significant observable\npredictors and latent factors as well as their effects. We explore a common\nlatent family incorporating population principal components and derive the\nconvergence rates of both sample principal components and their score vectors\nthat hold for a wide class of distributions. With the properly estimated latent\nvariables, properties including model selection consistency and oracle\ninequalities under various prediction and estimation losses are established for\nthe proposed methodology. Our new methodology and results are evidenced by\nsimulation and real data examples.\n", "versions": [{"version": "v1", "created": "Sat, 7 Oct 2017 16:14:08 GMT"}], "update_date": "2017-10-10", "authors_parsed": [["Zheng", "Zemin", ""], ["Lv", "Jinchi", ""], ["Lin", "Wei", ""]]}, {"id": "1710.02715", "submitter": "Ester Mariucci", "authors": "Ester Mariucci, Markus Rei{\\ss}", "title": "Wasserstein and total variation distance between marginals of L\\'evy\n  processes", "comments": "32 pages. To appear in Electronic Journal of Statistics", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present upper bounds for the Wasserstein distance of order $p$ between the\nmarginals of L\\'evy processes, including Gaussian approximations for jumps of\ninfinite activity. Using the convolution structure, we further derive upper\nbounds for the total variation distance between the marginals of L\\'evy\nprocesses. Connections to other metrics like Zolotarev and Toscani-Fourier\ndistances are established. The theory is illustrated by concrete examples and\nan application to statistical lower bounds.\n", "versions": [{"version": "v1", "created": "Sat, 7 Oct 2017 17:49:57 GMT"}, {"version": "v2", "created": "Mon, 16 Jul 2018 16:07:24 GMT"}], "update_date": "2018-07-17", "authors_parsed": [["Mariucci", "Ester", ""], ["Rei\u00df", "Markus", ""]]}, {"id": "1710.02761", "submitter": "Paromita Dubey", "authors": "Paromita Dubey, Hans-Georg M\\\"uller", "title": "Fr\\'echet Analysis Of Variance For Random Objects", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.MG stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fr\\'echet mean and variance provide a way of obtaining mean and variance for\ngeneral metric space valued random variables and can be used for statistical\nanalysis of data objects that lie in abstract spaces devoid of algebraic\nstructure and operations. Examples of such spaces include covariance matrices,\ngraph Laplacians of networks and univariate probability distribution functions.\nWe derive a central limit theorem for Fr\\'echet variance under mild regularity\nconditions, utilizing empirical process theory, and also provide a consistent\nestimator of the asymptotic variance. These results lead to a test to compare k\npopulations based on Fr\\'echet variance for general metric space valued data\nobjects, with emphasis on comparing means and variances. We examine the finite\nsample performance of this inference procedure through simulation studies for\nseveral special cases that include probability distributions and graph\nLaplacians, which leads to tests to compare populations of networks. The\nproposed methodology has good finite sample performance in simulations for\ndifferent kinds of random objects. We illustrate the proposed methods with data\non mortality profiles of various countries and resting state Functional\nMagnetic Resonance Imaging data.\n", "versions": [{"version": "v1", "created": "Sun, 8 Oct 2017 00:50:30 GMT"}, {"version": "v2", "created": "Thu, 19 Oct 2017 08:26:31 GMT"}, {"version": "v3", "created": "Sun, 20 Oct 2019 03:12:35 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Dubey", "Paromita", ""], ["M\u00fcller", "Hans-Georg", ""]]}, {"id": "1710.02794", "submitter": "Yuzo Maruyama", "authors": "Yuzo Maruyama and William E. Strawderman", "title": "Admissible Bayes equivariant estimation of location vectors for\n  spherically symmetric distributions with unknown scale", "comments": "57 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates estimation of the mean vector under invariant\nquadratic loss for a spherically symmetric location family with a residual\nvector with density of the form $\nf(x,u)=\\eta^{(p+n)/2}f(\\eta\\{\\|x-\\theta\\|^2+\\|u\\|^2\\}) $, where $\\eta$ is\nunknown. We show that the natural estimator $x$ is admissible for $p=1,2$.\nAlso, for $p\\geq 3$, we find classes of generalized Bayes estimators that are\nadmissible within the class of equivariant estimators of the form\n$\\{1-\\xi(x/\\|u\\|)\\}x$. In the Gaussian case, a variant of the James--Stein\nestimator, $[1-\\{(p-2)/(n+2)\\}/\\{\\|x\\|^2/\\|u\\|^2+(p-2)/(n+2)+1\\}]x$, which\ndominates the natural estimator $x$, is also admissible within this class. We\nalso study the related regression model.\n", "versions": [{"version": "v1", "created": "Sun, 8 Oct 2017 07:26:24 GMT"}], "update_date": "2017-10-10", "authors_parsed": [["Maruyama", "Yuzo", ""], ["Strawderman", "William E.", ""]]}, {"id": "1710.02903", "submitter": "Ahmed El Alaoui", "authors": "Ahmed El Alaoui, Florent Krzakala, Michael I. Jordan", "title": "Finite Size Corrections and Likelihood Ratio Fluctuations in the Spiked\n  Wigner Model", "comments": "40 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT math.IT math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study principal components analysis in the regime of high\ndimensionality and high noise. Our model of the problem is a rank-one\ndeformation of a Wigner matrix where the signal-to-noise ratio (SNR) is of\nconstant order, and we are interested in the fundamental limits of detection of\nthe spike. Our main goal is to gain a fine understanding of the asymptotics for\nthe log-likelihood ratio process, also known as the free energy, as a function\nof the SNR. Our main results are twofold. We first prove that the free energy\nhas a finite-size correction to its limit---the replica-symmetric\nformula---which we explicitly compute. This provides a formula for the\nKullback-Leibler divergence between the planted and null models. Second, we\nprove that below the reconstruction threshold, where it becomes impossible to\nreconstruct the spike, the log-likelihood ratio has fluctuations of constant\norder and converges in distribution to a Gaussian under both the planted and\n(under restrictions) the null model. As a consequence, we provide a general\nproof of contiguity between these two distributions that holds up to the\nreconstruction threshold, and is valid for an arbitrary separable prior on the\nspike. Formulae for the total variation distance, and the Type-I and Type-II\nerrors of the optimal test are also given. Our proofs are based on Gaussian\ninterpolation methods and a rigorous incarnation of the cavity method, as\ndevised by Guerra and Talagrand in their study of the Sherrington--Kirkpatrick\nspin-glass model.\n", "versions": [{"version": "v1", "created": "Mon, 9 Oct 2017 00:58:17 GMT"}], "update_date": "2017-10-10", "authors_parsed": [["Alaoui", "Ahmed El", ""], ["Krzakala", "Florent", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1710.02926", "submitter": "Susan Athey", "authors": "Alberto Abadie, Susan Athey, Guido Imbens, Jeffrey Wooldridge", "title": "When Should You Adjust Standard Errors for Clustering?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST econ.EM stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In empirical work in economics it is common to report standard errors that\naccount for clustering of units. Typically, the motivation given for the\nclustering adjustments is that unobserved components in outcomes for units\nwithin clusters are correlated. However, because correlation may occur across\nmore than one dimension, this motivation makes it difficult to justify why\nresearchers use clustering in some dimensions, such as geographic, but not\nothers, such as age cohorts or gender. It also makes it difficult to explain\nwhy one should not cluster with data from a randomized experiment. In this\npaper, we argue that clustering is in essence a design problem, either a\nsampling design or an experimental design issue. It is a sampling design issue\nif sampling follows a two stage process where in the first stage, a subset of\nclusters were sampled randomly from a population of clusters, while in the\nsecond stage, units were sampled randomly from the sampled clusters. In this\ncase the clustering adjustment is justified by the fact that there are clusters\nin the population that we do not see in the sample. Clustering is an\nexperimental design issue if the assignment is correlated within the clusters.\nWe take the view that this second perspective best fits the typical setting in\neconomics where clustering adjustments are used. This perspective allows us to\nshed new light on three questions: (i) when should one adjust the standard\nerrors for clustering, (ii) when is the conventional adjustment for clustering\nappropriate, and (iii) when does the conventional adjustment of the standard\nerrors matter.\n", "versions": [{"version": "v1", "created": "Mon, 9 Oct 2017 03:18:11 GMT"}, {"version": "v2", "created": "Tue, 24 Oct 2017 18:01:42 GMT"}], "update_date": "2017-10-27", "authors_parsed": [["Abadie", "Alberto", ""], ["Athey", "Susan", ""], ["Imbens", "Guido", ""], ["Wooldridge", "Jeffrey", ""]]}, {"id": "1710.02950", "submitter": "Rui Zhuang", "authors": "Rui Zhuang and Johannes Lederer", "title": "Maximum Regularized Likelihood Estimators: A General Prediction Theory\n  and Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Maximum regularized likelihood estimators (MRLEs) are arguably the most\nestablished class of estimators in high-dimensional statistics. In this paper,\nwe derive guarantees for MRLEs in Kullback-Leibler divergence, a general\nmeasure of prediction accuracy. We assume only that the densities have a convex\nparametrization and that the regularization is definite and positive\nhomogenous. The results thus apply to a very large variety of models and\nestimators, such as tensor regression and graphical models with convex and\nnon-convex regularized methods. A main conclusion is that MRLEs are broadly\nconsistent in prediction - regardless of whether restricted eigenvalues or\nsimilar conditions hold.\n", "versions": [{"version": "v1", "created": "Mon, 9 Oct 2017 06:16:50 GMT"}, {"version": "v2", "created": "Wed, 17 Oct 2018 05:13:06 GMT"}], "update_date": "2018-10-18", "authors_parsed": [["Zhuang", "Rui", ""], ["Lederer", "Johannes", ""]]}, {"id": "1710.03084", "submitter": "Natalia Markovich M", "authors": "Natalia Markovich and Marijus Vai\\v{c}iulis", "title": "Modification of Moment-Based Tail Index Estimator: Sums versus Maxima", "comments": "To appear in Springer Proceedings in Mathematics and Statistics", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we continue the investigation of the SRCEN estimator of the\nextreme value index $\\gamma$ (or the tail index $\\alpha=1/\\gamma$) proposed in\n\\cite{MCE} for $\\gamma>1/2$. We propose a new estimator based on the local\nmaximum. This, in fact, is a modification of the SRCEN estimator to the case\n$\\gamma>0$. We establish the consistency and asymptotic normality of the newly\nproposed estimator for i.i.d. data. Also, a short discussion on the comparison\nof the estimators is included.\n", "versions": [{"version": "v1", "created": "Mon, 9 Oct 2017 13:41:52 GMT"}], "update_date": "2017-10-10", "authors_parsed": [["Markovich", "Natalia", ""], ["Vai\u010diulis", "Marijus", ""]]}, {"id": "1710.03111", "submitter": "Evgeny Pchelintsev", "authors": "Evgeny Pchelintsev, Valerii Pchelintsev and Serguei Pergamenshchikov", "title": "Improved robust model selection methods for the Levy nonparametric\n  regression in continuous time", "comments": "arXiv admin note: text overlap with arXiv:1611.07378", "journal-ref": "Journal of Nonparametric Statistics 2019", "doi": "10.1080/10485252.2019.1609672", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we develop the James - Stein improved estimation method for a\nnonparametric periodic function observed with the Levy noises in continuous\ntime. An adaptive model selection procedure based on the improved weighted\nleast square estimates is constructed. The improvement effect for the\nnonparametric models is obtained. It turns out that in the nonasymptotic\nstudies the accuracy improvement for nonparametric problems is more\nsignificantly than for the parametric one. Moreover, sharp oracle inequalities\nfor the robust risks have been shown and the efficiency property for the\nimproved model selection procedure has been established in the adaptive\nsetting.\n", "versions": [{"version": "v1", "created": "Fri, 6 Oct 2017 14:13:59 GMT"}, {"version": "v2", "created": "Sun, 4 Nov 2018 11:56:12 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Pchelintsev", "Evgeny", ""], ["Pchelintsev", "Valerii", ""], ["Pergamenshchikov", "Serguei", ""]]}, {"id": "1710.03136", "submitter": "Cheng Wang", "authors": "Cheng Wang and Binyan Jiang", "title": "On the dimension effect of regularized linear discriminant analysis", "comments": "34pages,6figures", "journal-ref": "Electronic Journal of Statistics,2018", "doi": "10.1214/18-EJS1469", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the dimension effect of the linear discriminant analysis\n(LDA) and the regularized linear discriminant analysis (RLDA) classifiers for\nlarge dimensional data where the observation dimension $p$ is of the same order\nas the sample size $n$. More specifically, built on properties of the Wishart\ndistribution and recent results in random matrix theory, we derive explicit\nexpressions for the asymptotic misclassification errors of LDA and RLDA\nrespectively, from which we gain insights of how dimension affects the\nperformance of classification and in what sense. Motivated by these results, we\npropose adjusted classifiers by correcting the bias brought by the unequal\nsample sizes. The bias-corrected LDA and RLDA classifiers are shown to have\nsmaller misclassification rates than LDA and RLDA respectively. Several\ninteresting examples are discussed in detail and the theoretical results on\ndimension effect are illustrated via extensive simulation studies.\n", "versions": [{"version": "v1", "created": "Mon, 9 Oct 2017 15:04:02 GMT"}, {"version": "v2", "created": "Fri, 21 Sep 2018 01:11:04 GMT"}], "update_date": "2018-09-24", "authors_parsed": [["Wang", "Cheng", ""], ["Jiang", "Binyan", ""]]}, {"id": "1710.03266", "submitter": "Yun Yang", "authors": "Yun Yang and Debdeep Pati and Anirban Bhattacharya", "title": "$\\alpha$-Variational Inference with Statistical Guarantees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.CO stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a family of variational approximations to Bayesian posterior\ndistributions, called $\\alpha$-VB, with provable statistical guarantees. The\nstandard variational approximation is a special case of $\\alpha$-VB with\n$\\alpha=1$. When $\\alpha \\in(0,1]$, a novel class of variational inequalities\nare developed for linking the Bayes risk under the variational approximation to\nthe objective function in the variational optimization problem, implying that\nmaximizing the evidence lower bound in variational inference has the effect of\nminimizing the Bayes risk within the variational density family. Operating in a\nfrequentist setup, the variational inequalities imply that point estimates\nconstructed from the $\\alpha$-VB procedure converge at an optimal rate to the\ntrue parameter in a wide range of problems. We illustrate our general theory\nwith a number of examples, including the mean-field variational approximation\nto (low)-high-dimensional Bayesian linear regression with spike and slab\npriors, mixture of Gaussian models, latent Dirichlet allocation, and (mixture\nof) Gaussian variational approximation in regular parametric models.\n", "versions": [{"version": "v1", "created": "Mon, 9 Oct 2017 19:10:14 GMT"}, {"version": "v2", "created": "Wed, 7 Feb 2018 20:00:48 GMT"}], "update_date": "2018-02-09", "authors_parsed": [["Yang", "Yun", ""], ["Pati", "Debdeep", ""], ["Bhattacharya", "Anirban", ""]]}, {"id": "1710.03305", "submitter": "Nadezhda Gribkova Dr.", "authors": "Nadezhda Gribkova and Ri\\v{c}ardas Zitikis", "title": "Weighted allocations, their concomitant-based estimators, and\n  asymptotics", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Various members of the class of weighted insurance premiums and risk capital\nallocation rules have been researched from a number of perspectives.\nCorresponding formulas in the case of parametric families of distributions have\nbeen derived, and they have played a pivotal role when establishing parametric\nstatistical inference in the area. Non-parametric inference results have also\nbeen derived in special cases such as the tail conditional expectation,\ndistortion risk measure, and several members of the class of weighted premiums.\nFor weighted allocation rules, however, non-parametric inference results have\nnot yet been adequately developed. In the present paper, therefore, we put\nforward empirical estimators for the weighted allocation rules and establish\ntheir consistency and asymptotic normality under practically sound conditions.\nIntricate statistical considerations rely on the theory of induced order\nstatistics, known as concomitants.\n", "versions": [{"version": "v1", "created": "Mon, 9 Oct 2017 20:43:09 GMT"}], "update_date": "2017-10-11", "authors_parsed": [["Gribkova", "Nadezhda", ""], ["Zitikis", "Ri\u010dardas", ""]]}, {"id": "1710.03410", "submitter": "James Johndrow", "authors": "David Goldberg and James E. Johndrow", "title": "A Decision Theoretic Approach to A/B Testing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A/B testing is ubiquitous within the machine learning and data science\noperations of internet companies. Generically, the idea is to perform a\nstatistical test of the hypothesis that a new feature is better than the\nexisting platform---for example, it results in higher revenue. If the p value\nfor the test is below some pre-defined threshold---often, 0.05---the new\nfeature is implemented. The difficulty of choosing an appropriate threshold has\nbeen noted before, particularly because dependent tests are often done\nsequentially, leading some to propose control of the false discovery rate (FDR)\nrather than use of a single, universal threshold. However, it is still\nnecessary to make an arbitrary choice of the level at which to control FDR.\nHere we suggest a decision-theoretic approach to determining whether to adopt a\nnew feature, which enables automated selection of an appropriate threshold. Our\nmethod has the basic ingredients of any decision-theory problem: a loss\nfunction, action space, and a notion of optimality, for which we choose Bayes\nrisk. However, the loss function and the action space differ from the typical\nchoices made in the literature, which has focused on the theory of point\nestimation. We give some basic results for Bayes-optimal thresholding rules for\nthe feature adoption decision, and give some examples using eBay data. The\nresults suggest that the 0.05 p-value threshold may be too conservative in some\nsettings, but that its widespread use may reflect an ad-hoc means of\ncontrolling multiplicity in the common case of repeatedly testing variants of\nan experiment when the threshold is not reached.\n", "versions": [{"version": "v1", "created": "Tue, 10 Oct 2017 05:59:51 GMT"}], "update_date": "2017-10-11", "authors_parsed": [["Goldberg", "David", ""], ["Johndrow", "James E.", ""]]}, {"id": "1710.03494", "submitter": "Adelchi Azzalini", "authors": "Adelchi Azzalini and Giuliana Regoli", "title": "Yet another skew-elliptical family but of a different kind: return to\n  Lemma 1", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of modulated-symmetry distributions, there exist various forms\nof skew-elliptical families. We present yet another one, but with an unusual\nfeature: the modulation factor of the baseline elliptical density is\nrepresented by a distribution function with an argument which is not an odd\nfunction, as it occurs instead with the overwhelming majority of similar\nformulations, not only with other skew-elliptical families. The proposal is\nobtained by going back to the use of Lemma~1 of Azzalini and Capitanio (1999),\nwhich can be seen as the general frame for a vast number of existing\nformulations, and use it on a different route. The broader target is to show\nthat this `mother lemma' can still generate novel progeny.\n", "versions": [{"version": "v1", "created": "Tue, 10 Oct 2017 10:18:13 GMT"}], "update_date": "2017-10-11", "authors_parsed": [["Azzalini", "Adelchi", ""], ["Regoli", "Giuliana", ""]]}, {"id": "1710.03519", "submitter": "Markus Bibinger", "authors": "Markus Bibinger and Mathias Trabs", "title": "Volatility estimation for stochastic PDEs using high-frequency\n  observations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the parameter estimation for parabolic, linear, second-order,\nstochastic partial differential equations (SPDEs) observing a mild solution on\na discrete grid in time and space. A high-frequency regime is considered where\nthe mesh of the grid in the time variable goes to zero. Focusing on volatility\nestimation, we provide an explicit and easy to implement method of moments\nestimator based on squared increments. The estimator is consistent and admits a\ncentral limit theorem. This is established moreover for the joint estimation of\nthe integrated volatility and parameters in the differential operator in a\nsemi-parametric framework. Starting from a representation of the solution of\nthe SPDE with Dirichlet boundary conditions as an infinite factor model and\nexploiting mixing-type properties of time series, the theory considerably\ndiffers from the statistics for semi-martingales literature. The performance of\nthe method is illustrated in a simulation study.\n", "versions": [{"version": "v1", "created": "Tue, 10 Oct 2017 11:33:19 GMT"}, {"version": "v2", "created": "Tue, 4 Sep 2018 13:38:41 GMT"}, {"version": "v3", "created": "Tue, 10 Sep 2019 06:18:33 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Bibinger", "Markus", ""], ["Trabs", "Mathias", ""]]}, {"id": "1710.03550", "submitter": "Evgeny Pchelintsev", "authors": "Evgeny Pchelintsev, Svyatoslav Perelevskiy and Irina Makarova", "title": "Improved nonparametric estimation of the drift in diffusion processes", "comments": null, "journal-ref": "2018, Uchenye Zapiski Kazanskogo Universiteta-seriya\n  Fiziko-matematicheskie Nauki", "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the robust adaptive non parametric estimation\nproblem for the drift coefficient in diffusion processes. An adaptive model\nselection procedure, based on the improved weighted least square estimates, is\nproposed. Sharp oracle inequalities for the robust risk have been obtained.\n", "versions": [{"version": "v1", "created": "Tue, 10 Oct 2017 12:58:03 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Pchelintsev", "Evgeny", ""], ["Perelevskiy", "Svyatoslav", ""], ["Makarova", "Irina", ""]]}, {"id": "1710.03830", "submitter": "Vasilis Syrgkanis", "authors": "Vasilis Syrgkanis, Elie Tamer, Juba Ziani", "title": "Inference on Auctions with Weak Assumptions on Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM cs.GT cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a sample of bids from independent auctions, this paper examines the\nquestion of inference on auction fundamentals (e.g. valuation distributions,\nwelfare measures) under weak assumptions on information structure. The question\nis important as it allows us to learn about the valuation distribution in a\nrobust way, i.e., without assuming that a particular information structure\nholds across observations. We leverage the recent contributions of\n\\cite{Bergemann2013} in the robust mechanism design literature that exploit the\nlink between Bayesian Correlated Equilibria and Bayesian Nash Equilibria in\nincomplete information games to construct an econometrics framework for\nlearning about auction fundamentals using observed data on bids. We showcase\nour construction of identified sets in private value and common value auctions.\nOur approach for constructing these sets inherits the computational simplicity\nof solving for correlated equilibria: checking whether a particular valuation\ndistribution belongs to the identified set is as simple as determining whether\na {\\it linear} program is feasible. A similar linear program can be used to\nconstruct the identified set on various welfare measures and counterfactual\nobjects. For inference and to summarize statistical uncertainty, we propose\nnovel finite sample methods using tail inequalities that are used to construct\nconfidence regions on sets. We also highlight methods based on Bayesian\nbootstrap and subsampling. A set of Monte Carlo experiments show adequate\nfinite sample properties of our inference procedures. We illustrate our methods\nusing data from OCS auctions.\n", "versions": [{"version": "v1", "created": "Tue, 10 Oct 2017 21:46:47 GMT"}, {"version": "v2", "created": "Mon, 19 Mar 2018 14:22:31 GMT"}], "update_date": "2018-03-20", "authors_parsed": [["Syrgkanis", "Vasilis", ""], ["Tamer", "Elie", ""], ["Ziani", "Juba", ""]]}, {"id": "1710.03863", "submitter": "Yanjun Han", "authors": "Yanjun Han, Jiantao Jiao, Rajarshi Mukherjee", "title": "On Estimation of $L_{r}$-Norms in Gaussian White Noise Models", "comments": "This version (v6) fixed an error in the proof of Lemma 5.6, and\n  corrected some typos", "journal-ref": "Published in Probability Theory and Related Fields, vol. 177, no.\n  3-4, pp. 1243-1294, 2020", "doi": "10.1007/s00440-020-00982-x", "report-no": null, "categories": "math.ST cs.LG stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a complete picture of asymptotically minimax estimation of\n$L_r$-norms (for any $r\\ge 1$) of the mean in Gaussian white noise model over\nNikolskii-Besov spaces. In this regard, we complement the work of Lepski,\nNemirovski and Spokoiny (1999), who considered the cases of $r=1$ (with\npoly-logarithmic gap between upper and lower bounds) and $r$ even (with\nasymptotically sharp upper and lower bounds) over H\\\"{o}lder spaces. We\nadditionally consider the case of asymptotically adaptive minimax estimation\nand demonstrate a difference between even and non-even $r$ in terms of an\ninvestigator's ability to produce asymptotically adaptive minimax estimators\nwithout paying a penalty.\n", "versions": [{"version": "v1", "created": "Wed, 11 Oct 2017 00:22:03 GMT"}, {"version": "v2", "created": "Thu, 9 Nov 2017 06:45:30 GMT"}, {"version": "v3", "created": "Wed, 3 Apr 2019 04:47:50 GMT"}, {"version": "v4", "created": "Wed, 30 Oct 2019 02:59:15 GMT"}, {"version": "v5", "created": "Thu, 9 Jul 2020 05:46:24 GMT"}, {"version": "v6", "created": "Wed, 3 Mar 2021 06:31:53 GMT"}], "update_date": "2021-03-04", "authors_parsed": [["Han", "Yanjun", ""], ["Jiao", "Jiantao", ""], ["Mukherjee", "Rajarshi", ""]]}, {"id": "1710.03892", "submitter": "Tianzhou Ma", "authors": "Tianzhou Ma, Zhao Ren and George C. Tseng", "title": "Variable screening with multiple studies", "comments": "25 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advancement in technology has generated abundant high-dimensional data that\nallows integration of multiple relevant studies. Due to their huge\ncomputational advantage, variable screening methods based on marginal\ncorrelation have become promising alternatives to the popular regularization\nmethods for variable selection. However, all these screening methods are\nlimited to single study so far. In this paper, we consider a general framework\nfor variable screening with multiple related studies, and further propose a\nnovel two-step screening procedure using a self-normalized estimator for\nhigh-dimensional regression analysis in this framework. Compared to the\none-step procedure and rank-based sure independence screening (SIS) procedure,\nour procedure greatly reduces false negative errors while keeping a low false\npositive rate. Theoretically, we show that our procedure possesses the sure\nscreening property with weaker assumptions on signal strengths and allows the\nnumber of features to grow at an exponential rate of the sample size. In\naddition, we relax the commonly used normality assumption and allow\nsub-Gaussian distributions. Simulations and a real transcriptomic application\nillustrate the advantage of our method as compared to the rank-based SIS\nmethod.\n", "versions": [{"version": "v1", "created": "Wed, 11 Oct 2017 03:12:32 GMT"}], "update_date": "2017-10-12", "authors_parsed": [["Ma", "Tianzhou", ""], ["Ren", "Zhao", ""], ["Tseng", "George C.", ""]]}, {"id": "1710.04019", "submitter": "Bertrand Michel", "authors": "Fr\\'ed\\'eric Chazal (1), Bertrand Michel (2) ((1) DATASHAPE, (2) LSTA)", "title": "An introduction to Topological Data Analysis: fundamental and practical\n  aspects for data scientists", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG math.AT stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Topological Data Analysis is a recent and fast growing field providing a set\nof new topological and geometric tools to infer relevant features for possibly\ncomplex data. This paper is a brief introduction, through a few selected\ntopics, to basic fundamental and practical aspects of \\tda\\ for non experts.\n", "versions": [{"version": "v1", "created": "Wed, 11 Oct 2017 11:53:32 GMT"}, {"version": "v2", "created": "Thu, 25 Feb 2021 08:31:59 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Chazal", "Fr\u00e9d\u00e9ric", "", "DATASHAPE"], ["Michel", "Bertrand", "", "LSTA"]]}, {"id": "1710.04023", "submitter": "Manon Costa", "authors": "Manon Costa (1), S\\'ebastien Gadat (2), Pauline Gonnord (3), Laurent\n  Risser (1) ((1) IMT, (2) TSE, (3) CPTP)", "title": "Cytometry inference through adaptive atomic deconvolution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider a statistical estimation problem known as atomic\ndeconvolution. Introduced in reliability, this model has a direct application\nwhen considering biological data produced by flow cytometers. In these\nexperiments, biologists measure the fluorescence emission of treated cells and\ncompare them with their natural emission to study the presence of specific\nmolecules on the cells' surface. They observe a signal which is composed of a\nnoise (the natural fluorescence) plus some additional signal related to the\nquantity of molecule present on the surface if any. From a statistical point of\nview, we aim at inferring the percentage of cells expressing the selected\nmolecule and the probability distribution function associated with its\nfluorescence emission. We propose here an adap-tive estimation procedure based\non a previous deconvolution procedure introduced by [vEGS08, GvES11]. For both\nestimating the mixing parameter and the mixing density automatically, we use\nthe Lepskii method based on the optimal choice of a bandwidth using a\nbias-variance decomposition. We then derive some concentration inequalities for\nour estimators and obtain the convergence rates, that are shown to be minimax\noptimal (up to some log terms) in Sobolev classes. Finally, we apply our\nalgorithm on simulated and real biological data.\n", "versions": [{"version": "v1", "created": "Wed, 11 Oct 2017 11:59:30 GMT"}], "update_date": "2017-10-12", "authors_parsed": [["Costa", "Manon", "", "IMT"], ["Gadat", "S\u00e9bastien", "", "TSE"], ["Gonnord", "Pauline", "", "CPTP"], ["Risser", "Laurent", "", "IMT"]]}, {"id": "1710.04062", "submitter": "Alec Koppel", "authors": "Alec Koppel, Santiago Paternain, Cedric Richard, Alejandro Ribeiro", "title": "Decentralized Online Learning with Kernels", "comments": "Submitted to IEEE TSP. Partial results appear in 2017 IEEE GlobalSIP.\n  arXiv admin note: text overlap with arXiv:1612.04111", "journal-ref": null, "doi": "10.1109/TSP.2018.2830299", "report-no": null, "categories": "math.OC cs.DC cs.LG cs.MA math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider multi-agent stochastic optimization problems over reproducing\nkernel Hilbert spaces (RKHS). In this setting, a network of interconnected\nagents aims to learn decision functions, i.e., nonlinear statistical models,\nthat are optimal in terms of a global convex functional that aggregates data\nacross the network, with only access to locally and sequentially observed\nsamples. We propose solving this problem by allowing each agent to learn a\nlocal regression function while enforcing consensus constraints. We use a\npenalized variant of functional stochastic gradient descent operating\nsimultaneously with low-dimensional subspace projections. These subspaces are\nconstructed greedily by applying orthogonal matching pursuit to the sequence of\nkernel dictionaries and weights. By tuning the projection-induced bias, we\npropose an algorithm that allows for each individual agent to learn, based upon\nits locally observed data stream and message passing with its neighbors only, a\nregression function that is close to the globally optimal regression function.\nThat is, we establish that with constant step-size selections agents' functions\nconverge to a neighborhood of the globally optimal one while satisfying the\nconsensus constraints as the penalty parameter is increased. Moreover, the\ncomplexity of the learned regression functions is guaranteed to remain finite.\nOn both multi-class kernel logistic regression and multi-class kernel support\nvector classification with data generated from class-dependent Gaussian mixture\nmodels, we observe stable function estimation and state of the art performance\nfor distributed online multi-class classification. Experiments on the Brodatz\ntextures further substantiate the empirical validity of this approach.\n", "versions": [{"version": "v1", "created": "Wed, 11 Oct 2017 13:49:28 GMT"}], "update_date": "2018-07-04", "authors_parsed": [["Koppel", "Alec", ""], ["Paternain", "Santiago", ""], ["Richard", "Cedric", ""], ["Ribeiro", "Alejandro", ""]]}, {"id": "1710.04170", "submitter": "Gautam Kamath", "authors": "Constantinos Daskalakis, Nishanth Dikkala, Gautam Kamath", "title": "Concentration of Multilinear Functions of the Ising Model with\n  Applications to Network Data", "comments": "To appear in NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.LG math-ph math.MP math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove near-tight concentration of measure for polynomial functions of the\nIsing model under high temperature. For any degree $d$, we show that a\ndegree-$d$ polynomial of a $n$-spin Ising model exhibits exponential tails that\nscale as $\\exp(-r^{2/d})$ at radius $r=\\tilde{\\Omega}_d(n^{d/2})$. Our\nconcentration radius is optimal up to logarithmic factors for constant $d$,\nimproving known results by polynomial factors in the number of spins. We\ndemonstrate the efficacy of polynomial functions as statistics for testing the\nstrength of interactions in social networks in both synthetic and real world\ndata.\n", "versions": [{"version": "v1", "created": "Wed, 11 Oct 2017 16:55:14 GMT"}], "update_date": "2017-10-12", "authors_parsed": [["Daskalakis", "Constantinos", ""], ["Dikkala", "Nishanth", ""], ["Kamath", "Gautam", ""]]}, {"id": "1710.04217", "submitter": "Peter Orbanz", "authors": "Peter Orbanz", "title": "Subsampling large graphs and invariance in networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Specify a randomized algorithm that, given a very large graph or network,\nextracts a random subgraph. What can we learn about the input graph from a\nsingle subsample? We derive laws of large numbers for the sampler output, by\nrelating randomized subsampling to distributional invariance: Assuming an\ninvariance holds is tantamount to assuming the sample has been generated by a\nspecific algorithm. That in turn yields a notion of ergodicity. Sampling\nalgorithms induce model classes---graphon models, sparse generalizations of\nexchangeable graphs, and random multigraphs with exchangeable edges can all be\nobtained in this manner, and we specialize our results to a number of examples.\nOne class of sampling algorithms emerges as special: Roughly speaking, those\ndefined as limits of random transformations drawn uniformly from certain\nsequences of groups. Some known pathologies of network models based on graphons\nare explained as a form of selection bias.\n", "versions": [{"version": "v1", "created": "Wed, 11 Oct 2017 18:00:01 GMT"}], "update_date": "2017-10-13", "authors_parsed": [["Orbanz", "Peter", ""]]}, {"id": "1710.04273", "submitter": "Konstantinos Spiliopoulos", "authors": "Justin Sirignano, Konstantinos Spiliopoulos", "title": "Stochastic Gradient Descent in Continuous Time: A Central Limit Theorem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST q-fin.CP stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic gradient descent in continuous time (SGDCT) provides a\ncomputationally efficient method for the statistical learning of\ncontinuous-time models, which are widely used in science, engineering, and\nfinance. The SGDCT algorithm follows a (noisy) descent direction along a\ncontinuous stream of data. The parameter updates occur in continuous time and\nsatisfy a stochastic differential equation. This paper analyzes the asymptotic\nconvergence rate of the SGDCT algorithm by proving a central limit theorem\n(CLT) for strongly convex objective functions and, under slightly stronger\nconditions, for non-convex objective functions as well. An $L^{p}$ convergence\nrate is also proven for the algorithm in the strongly convex case. The\nmathematical analysis lies at the intersection of stochastic analysis and\nstatistical learning.\n", "versions": [{"version": "v1", "created": "Wed, 11 Oct 2017 19:41:36 GMT"}, {"version": "v2", "created": "Thu, 2 Nov 2017 17:26:15 GMT"}, {"version": "v3", "created": "Tue, 27 Nov 2018 18:42:25 GMT"}, {"version": "v4", "created": "Mon, 17 Jun 2019 06:52:10 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Sirignano", "Justin", ""], ["Spiliopoulos", "Konstantinos", ""]]}, {"id": "1710.04349", "submitter": "Ezequiel Smucler", "authors": "Efstathia Bura, Sabrina Duarte, Liliana Forzani, Ezequiel Smucler,\n  Mariela Sued", "title": "Asymptotic theory for maximum likelihood estimates in reduced-rank\n  multivariate generalised linear models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reduced-rank regression is a dimensionality reduction method with many\napplications. The asymptotic theory for reduced rank estimators of parameter\nmatrices in multivariate linear models has been studied extensively. In\ncontrast, few theoretical results are available for reduced-rank multivariate\ngeneralised linear models. We develop M-estimation theory for concave criterion\nfunctions that are maximised over parameters spaces that are neither convex nor\nclosed. These results are used to derive the consistency and asymptotic\ndistribution of maximum likelihood estimators in reduced-rank multivariate\ngeneralised linear models, when the response and predictor vectors have a joint\ndistribution. We illustrate our results in a real data classification problem\nwith binary covariates.\n", "versions": [{"version": "v1", "created": "Thu, 12 Oct 2017 03:06:13 GMT"}], "update_date": "2017-10-13", "authors_parsed": [["Bura", "Efstathia", ""], ["Duarte", "Sabrina", ""], ["Forzani", "Liliana", ""], ["Smucler", "Ezequiel", ""], ["Sued", "Mariela", ""]]}, {"id": "1710.04369", "submitter": "Ray Bai", "authors": "Ray Bai, Malay Ghosh", "title": "The Inverse Gamma-Gamma Prior for Optimal Posterior Contraction and\n  Multiple Hypothesis Testing", "comments": "NOTE: This manuscript is being split into two separate papers, each\n  of which expands on previous results that were in this original manuscript.\n  We expand our analysis of the multiple testing aspect in a new pre-print\n  (available at arXiv: 1807.02421). In another forthcoming paper, we will\n  consider high-dimensional regression models with this prior (with the normal\n  means model as a special case)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the well-known problem of estimating a sparse $n$-dimensional\nunknown mean vector $\\theta = (\\theta_1, ..., \\theta_n)$ with entries corrupted\nby Gaussian white noise. In the Bayesian framework, continuous shrinkage priors\nwhich can be expressed as scale-mixture normal densities are popular for\nobtaining sparse estimates of $\\theta$. In this article, we introduce a new\nfully Bayesian scale-mixture prior known as the inverse gamma-gamma (IGG)\nprior. We prove that the posterior distribution contracts around the true\n$\\theta$ at (near) minimax rate under very mild conditions. In the process, we\nprove that the sufficient conditions for minimax posterior contraction given by\nVan der Pas et al. (2016) are not necessary for optimal posterior contraction.\nWe further show that the IGG posterior density concentrates at a rate faster\nthan those of the horseshoe or the horseshoe+ in the Kullback-Leibler (K-L)\nsense. To classify true signals ($\\theta_i \\neq 0$), we also propose a\nhypothesis test based on thresholding the posterior mean. Taking the loss\nfunction to be the expected number of misclassified tests, we show that our\ntest procedure asymptotically attains the optimal Bayes risk exactly. We\nillustrate through simulations and data analysis that the IGG has excellent\nfinite sample performance for both estimation and classification.\n", "versions": [{"version": "v1", "created": "Thu, 12 Oct 2017 05:08:47 GMT"}, {"version": "v2", "created": "Mon, 23 Oct 2017 12:27:34 GMT"}, {"version": "v3", "created": "Wed, 28 Feb 2018 23:43:12 GMT"}, {"version": "v4", "created": "Mon, 9 Jul 2018 00:33:08 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Bai", "Ray", ""], ["Ghosh", "Malay", ""]]}, {"id": "1710.04532", "submitter": "Maria Umlauft", "authors": "Maria Umlauft, Marius Placzek, Frank Konietschke, Markus Pauly", "title": "Wild Bootstrapping Rank-Based Procedures: Multiple Testing in\n  Nonparametric Split-Plot Designs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Split-plot or repeated measures designs are frequently used for planning\nexperiments in the life or social sciences. Typical examples include the\ncomparison of different treatments over time, where both factors may possess an\nadditional factorial structure. For such designs, the statistical analysis\nusually consists of several steps. If the global null is rejected, multiple\ncomparisons are usually performed. Usually, general factorial repeated measures\ndesigns are inferred by classical linear mixed models. Common underlying\nassumptions, such as normality or variance homogeneity are often not met in\nreal data. Furthermore, to deal even with, e.g., ordinal or ordered categorical\ndata, adequate effect sizes should be used. Here, multiple contrast tests and\nsimultaneous confidence intervals for general factorial split-plot designs are\ndeveloped and equipped with a novel asymptotically correct wild bootstrap\napproach.\n  Because the regulatory authorities typically require the calculation of\nconfidence intervals, this work also provides simultaneous confidence intervals\nfor single contrasts and for the ratio of different contrasts in meaningful\neffects. Extensive simulations are conducted to foster the theoretical\nfindings. Finally, two different datasets exemplify the applicability of the\nnovel procedure.\n", "versions": [{"version": "v1", "created": "Thu, 12 Oct 2017 14:15:14 GMT"}], "update_date": "2017-10-13", "authors_parsed": [["Umlauft", "Maria", ""], ["Placzek", "Marius", ""], ["Konietschke", "Frank", ""], ["Pauly", "Markus", ""]]}, {"id": "1710.04556", "submitter": "Alain Celisse", "authors": "Alain Celisse (LPP, MODAL), Guillemette Marot (MODAL, CERIM), Morgane\n  Pierre-Jean (LaMME), Guillem Rigaill (URGV)", "title": "New efficient algorithms for multiple change-point detection with\n  kernels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.CO stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several statistical approaches based on reproducing kernels have been\nproposed to detect abrupt changes arising in the full distribution of the\nobservations and not only in the mean or variance. Some of these approaches\nenjoy good statistical properties (oracle inequality, \\ldots). Nonetheless,\nthey have a high computational cost both in terms of time and memory. This\nmakes their application difficult even for small and medium sample sizes ($n<\n10^4$). This computational issue is addressed by first describing a new\nefficient and exact algorithm for kernel multiple change-point detection with\nan improved worst-case complexity that is quadratic in time and linear in\nspace. It allows dealing with medium size signals (up to $n \\approx 10^5$).\nSecond, a faster but approximation algorithm is described. It is based on a\nlow-rank approximation to the Gram matrix. It is linear in time and space. This\napproximation algorithm can be applied to large-scale signals ($n \\geq 10^6$).\nThese exact and approximation algorithms have been implemented in \\texttt{R}\nand \\texttt{C} for various kernels. The computational and statistical\nperformances of these new algorithms have been assessed through empirical\nexperiments. The runtime of the new algorithms is observed to be faster than\nthat of other considered procedures. Finally, simulations confirmed the higher\nstatistical accuracy of kernel-based approaches to detect changes that are not\nonly in the mean. These simulations also illustrate the flexibility of\nkernel-based approaches to analyze complex biological profiles made of DNA copy\nnumber and allele B frequencies. An R package implementing the approach will be\nmade available on github.\n", "versions": [{"version": "v1", "created": "Thu, 12 Oct 2017 15:08:52 GMT"}], "update_date": "2017-10-13", "authors_parsed": [["Celisse", "Alain", "", "LPP, MODAL"], ["Marot", "Guillemette", "", "MODAL, CERIM"], ["Pierre-Jean", "Morgane", "", "LaMME"], ["Rigaill", "Guillem", "", "URGV"]]}, {"id": "1710.04569", "submitter": "Tetiana Gorbach", "authors": "Tetiana Gorbach, Xavier de Luna", "title": "Inference for partial correlation when data are missing not at random", "comments": null, "journal-ref": "Statistics & Probability letters 141 (2018) 82-89", "doi": "10.1016/j.spl.2018.05.027", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce uncertainty regions to perform inference on partial correlations\nwhen data are missing not at random. These uncertainty regions are shown to\nhave a desired asymptotic coverage. Their finite sample performance is\nillustrated via simulations and real data example.\n", "versions": [{"version": "v1", "created": "Thu, 12 Oct 2017 15:38:13 GMT"}], "update_date": "2018-10-08", "authors_parsed": [["Gorbach", "Tetiana", ""], ["de Luna", "Xavier", ""]]}, {"id": "1710.04765", "submitter": "Can Le", "authors": "Can M. Le, Keith Levin and Elizaveta Levina", "title": "Estimating a network from multiple noisy realizations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.SI stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complex interactions between entities are often represented as edges in a\nnetwork. In practice, the network is often constructed from noisy measurements\nand inevitably contains some errors. In this paper we consider the problem of\nestimating a network from multiple noisy observations where edges of the\noriginal network are recorded with both false positives and false negatives.\nThis problem is motivated by neuroimaging applications where brain networks of\na group of patients with a particular brain condition could be viewed as noisy\nversions of an unobserved true network corresponding to the disease. The key to\noptimally leveraging these multiple observations is to take advantage of\nnetwork structure, and here we focus on the case where the true network\ncontains communities. Communities are common in real networks in general and in\nparticular are believed to be presented in brain networks. Under a community\nstructure assumption on the truth, we derive an efficient method to estimate\nthe noise levels and the original network, with theoretical guarantees on the\nconvergence of our estimates. We show on synthetic networks that the\nperformance of our method is close to an oracle method using the true parameter\nvalues, and apply our method to fMRI brain data, demonstrating that it\nconstructs stable and plausible estimates of the population network.\n", "versions": [{"version": "v1", "created": "Fri, 13 Oct 2017 01:04:30 GMT"}, {"version": "v2", "created": "Mon, 10 Dec 2018 16:19:41 GMT"}], "update_date": "2018-12-11", "authors_parsed": [["Le", "Can M.", ""], ["Levin", "Keith", ""], ["Levina", "Elizaveta", ""]]}, {"id": "1710.04772", "submitter": "Can Le", "authors": "Can M. Le", "title": "Edge sampling using network local information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.SI stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Edge sampling is an important topic in network analysis. It provides a\nnatural way to reduce network size while retaining desired features of the\noriginal network. Sampling methods that only use local information are common\nin practice as they do not require access to the entire network and can be\nparallelized easily. Despite promising empirical performances, most of these\nmethods are derived from heuristic considerations and therefore still lack\ntheoretical justification. To address this issue, we study in this paper a\nsimple edge sampling scheme that uses network local information. We show that\nwhen local connectivity is sufficiently strong, the sampled network satisfies a\nstrong spectral property. We quantify the strength of local connectivity by a\nglobal parameter and relate it to more common network statistics such as the\nclustering coefficient and network curvature. Based on this result, we also\nprovide sufficient conditions under which random networks and hypergraphs can\nbe sampled efficiently.\n", "versions": [{"version": "v1", "created": "Fri, 13 Oct 2017 01:29:37 GMT"}, {"version": "v2", "created": "Tue, 11 Aug 2020 06:49:57 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Le", "Can M.", ""]]}, {"id": "1710.04813", "submitter": "Konstantinos  Fokianos", "authors": "Konstantinos Fokianos, Anne Leucht, Michael H. Neumann", "title": "On Integrated $L^{1}$ Convergence Rate of an Isotonic Regression\n  Estimator for Multivariate Observations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a general monotone regression estimation where we allow for\nindependent and dependent regressors. We propose a modification of the\nclassical isotonic least squares estimator and establish its rate of\nconvergence for the integrated $L_1$-loss function. The methodology captures\nthe shape of the data without assuming additivity or a parametric form for the\nregression function. Furthermore, the degree of smoothing is chosen\nautomatically and no auxiliary tuning is required for the theoretical analysis.\nSome simulations and two real data illustrations complement the study of the\nproposed estimator.\n", "versions": [{"version": "v1", "created": "Fri, 13 Oct 2017 05:52:26 GMT"}, {"version": "v2", "created": "Thu, 3 May 2018 19:21:54 GMT"}], "update_date": "2018-05-07", "authors_parsed": [["Fokianos", "Konstantinos", ""], ["Leucht", "Anne", ""], ["Neumann", "Michael H.", ""]]}, {"id": "1710.04995", "submitter": "Yannis Pantazis", "authors": "Yannis Pantazis, Vincenzo Lagani, Paulos Charonyktakis and Ioannis\n  Tsamardinos", "title": "Multiple Equivalent Solutions for the Lasso", "comments": "10 pages, 2 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature selection is an important problem studied in data analytics seeking\nto identify a minimal-size feature subset that is optimally predictive for an\noutcome of interest. It is also a powerful tool in Knowledge Discovery as a\nmeans for gaining domain insight, e.g., identifying which medical quantities\ncarry unique information for the disease status. It is arguably less recognized\nhowever, that the problem may have multiple, equivalent solutions. In that\ncase, it is misleading to domain experts to report only one of them and ignore\nall other equivalent solutions. In this paper, we extend a well-established\nsingle, feature selection algorithm (i.e., reporting a single solution), namely\nthe Lasso algorithm, to the multiple solution problem based on formalized\nnotion of equivalence for both classification and regression tasks. Empirical\nresults are obtained using a fully automated pipeline called Just Add Data Bio\nor JAD Bio training and selecting multiple, linear as well as nonlinear\nlearners, optimizing hyper-parameter values, and correcting for the bias of\nmultiple inductions (model selection). The results show that multiple solutions\ndo exist in real datasets, as well as the ability of the algorithm to identify\na subset of them. A comparison with the Statistical Equivalent Solutions (SES)\nalgorithm shows that Lasso equivalent solutions have better prediction\nperformance at the cost of selecting more features.\n", "versions": [{"version": "v1", "created": "Fri, 13 Oct 2017 16:37:09 GMT"}, {"version": "v2", "created": "Mon, 26 Feb 2018 16:39:34 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Pantazis", "Yannis", ""], ["Lagani", "Vincenzo", ""], ["Charonyktakis", "Paulos", ""], ["Tsamardinos", "Ioannis", ""]]}, {"id": "1710.05209", "submitter": "Abbas Mehrabian", "authors": "Hassan Ashtiani and Shai Ben-David and Nick Harvey and Christopher\n  Liaw and Abbas Mehrabian and Yaniv Plan", "title": "Near-optimal Sample Complexity Bounds for Robust Learning of Gaussians\n  Mixtures via Compression Schemes", "comments": "To appear in Journal of the ACM. 46 pages. An extended abstract\n  appeared in NeurIPS 2018. This version contains all the proofs, generalizes\n  the results to agnostic learning, and improves the bounds by logarithmic\n  factors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that $\\tilde{\\Theta}(k d^2 / \\varepsilon^2)$ samples are necessary\nand sufficient for learning a mixture of $k$ Gaussians in $\\mathbb{R}^d$, up to\nerror $\\varepsilon$ in total variation distance. This improves both the known\nupper bounds and lower bounds for this problem. For mixtures of axis-aligned\nGaussians, we show that $\\tilde{O}(k d / \\varepsilon^2)$ samples suffice,\nmatching a known lower bound. Moreover, these results hold in the\nagnostic-learning/robust-estimation setting as well, where the target\ndistribution is only approximately a mixture of Gaussians.\n  The upper bound is shown using a novel technique for distribution learning\nbased on a notion of `compression.' Any class of distributions that allows such\na compression scheme can also be learned with few samples. Moreover, if a class\nof distributions has such a compression scheme, then so do the classes of\nproducts and mixtures of those distributions. The core of our main result is\nshowing that the class of Gaussians in $\\mathbb{R}^d$ admits a small-sized\ncompression scheme.\n", "versions": [{"version": "v1", "created": "Sat, 14 Oct 2017 16:39:24 GMT"}, {"version": "v2", "created": "Fri, 16 Feb 2018 18:40:00 GMT"}, {"version": "v3", "created": "Thu, 29 Nov 2018 07:59:54 GMT"}, {"version": "v4", "created": "Sat, 20 Jul 2019 16:25:31 GMT"}, {"version": "v5", "created": "Tue, 21 Jul 2020 19:48:26 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Ashtiani", "Hassan", ""], ["Ben-David", "Shai", ""], ["Harvey", "Nick", ""], ["Liaw", "Christopher", ""], ["Mehrabian", "Abbas", ""], ["Plan", "Yaniv", ""]]}, {"id": "1710.05291", "submitter": "Davy Paindaveine", "authors": "Davy Paindaveine, Julien Remy, Thomas Verdebout", "title": "Testing for Principal Component Directions under Weak Identifiability", "comments": "45 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of testing, on the basis of a $p$-variate Gaussian\nrandom sample, the null hypothesis ${\\cal H}_0: {\\pmb \\theta}_1= {\\pmb\n\\theta}_1^0$ against the alternative ${\\cal H}_1: {\\pmb \\theta}_1 \\neq {\\pmb\n\\theta}_1^0$, where ${\\pmb \\theta}_1$ is the \"first\" eigenvector of the\nunderlying covariance matrix and ${\\pmb \\theta}_1^0$ is a fixed unit\n$p$-vector. In the classical setup where eigenvalues $\\lambda_1>\\lambda_2\\geq\n\\ldots\\geq \\lambda_p$ are fixed, the Anderson (1963) likelihood ratio test\n(LRT) and the Hallin, Paindaveine and Verdebout (2010) Le Cam optimal test for\nthis problem are asymptotically equivalent under the null hypothesis, hence\nalso under sequences of contiguous alternatives. We show that this equivalence\ndoes not survive asymptotic scenarios where\n$\\lambda_{n1}/\\lambda_{n2}=1+O(r_n)$ with $r_n=O(1/\\sqrt{n})$. For such\nscenarios, the Le Cam optimal test still asymptotically meets the nominal level\nconstraint, whereas the LRT severely overrejects the null hypothesis.\nConsequently, the former test should be favored over the latter one whenever\nthe two largest sample eigenvalues are close to each other. By relying on the\nLe Cam's asymptotic theory of statistical experiments, we study the non-null\nand optimality properties of the Le Cam optimal test in the aforementioned\nasymptotic scenarios and show that the null robustness of this test is not\nobtained at the expense of power. Our asymptotic investigation is extensive in\nthe sense that it allows $r_n$ to converge to zero at an arbitrary rate. While\nwe restrict to single-spiked spectra of the form\n$\\lambda_{n1}>\\lambda_{n2}=\\ldots=\\lambda_{np}$ to make our results as striking\nas possible, we extend our results to the more general elliptical case.\nFinally, we present an illustrative real data example.\n", "versions": [{"version": "v1", "created": "Sun, 15 Oct 2017 07:00:41 GMT"}, {"version": "v2", "created": "Mon, 16 Jul 2018 11:38:52 GMT"}, {"version": "v3", "created": "Sun, 30 Dec 2018 15:12:49 GMT"}], "update_date": "2019-01-01", "authors_parsed": [["Paindaveine", "Davy", ""], ["Remy", "Julien", ""], ["Verdebout", "Thomas", ""]]}, {"id": "1710.05377", "submitter": "Ge Zhao", "authors": "Ge Zhao, Yanyuan Ma and Wenbin Lu", "title": "Efficient Estimation for Dimension Reduction with Censored Data", "comments": "18 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a general index model for survival data, which generalizes many\ncommonly used semiparametric survival models and belongs to the framework of\ndimension reduction. Using a combination of geometric approach in\nsemiparametrics and martingale treatment in survival data analysis, we devise\nestimation procedures that are feasible and do not require\ncovariate-independent censoring as assumed in many dimension reduction methods\nfor censored survival data. We establish the root-$n$ consistency and\nasymptotic normality of the proposed estimators and derive the most efficient\nestimator in this class for the general index model. Numerical experiments are\ncarried out to demonstrate the empirical performance of the proposed estimators\nand an application to an AIDS data further illustrates the usefulness of the\nwork.\n", "versions": [{"version": "v1", "created": "Sun, 15 Oct 2017 18:50:30 GMT"}], "update_date": "2017-10-17", "authors_parsed": [["Zhao", "Ge", ""], ["Ma", "Yanyuan", ""], ["Lu", "Wenbin", ""]]}, {"id": "1710.05610", "submitter": "Tim Sullivan", "authors": "T. J. Sullivan", "title": "Well-posedness of Bayesian inverse problems in quasi-Banach spaces with\n  stable priors", "comments": "To appear in the proceedings of the 88th Annual Meeting of the\n  International Association of Applied Mathematics and Mechanics (GAMM), Weimar\n  2017. This preprint differs from the final published version in pagination\n  and typographical detail", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.NA math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Bayesian perspective on inverse problems has attracted much mathematical\nattention in recent years. Particular attention has been paid to Bayesian\ninverse problems (BIPs) in which the parameter to be inferred lies in an\ninfinite-dimensional space, a typical example being a scalar or tensor field\ncoupled to some observed data via an ODE or PDE. This article gives an\nintroduction to the framework of well-posed BIPs in infinite-dimensional\nparameter spaces, as advocated by Stuart (Acta Numer. 19:451--559, 2010) and\nothers. This framework has the advantage of ensuring uniformly well-posed\ninference problems independently of the finite-dimensional discretisation used\nfor numerical solution. Recently, this framework has been extended to the case\nof a heavy-tailed prior measure in the family of stable distributions, such as\nan infinite-dimensional Cauchy distribution, for which polynomial moments are\ninfinite or undefined. It is shown that analogues of the Karhunen--Lo\\`eve\nexpansion for square-integrable random variables can be used to sample such\nmeasures on quasi-Banach spaces. Furthermore, under weaker regularity\nassumptions than those used to date, the Bayesian posterior measure is shown to\ndepend Lipschitz continuously in the Hellinger and total variation metrics upon\nperturbations of the misfit function and observed data.\n", "versions": [{"version": "v1", "created": "Mon, 16 Oct 2017 10:38:58 GMT"}], "update_date": "2017-10-17", "authors_parsed": [["Sullivan", "T. J.", ""]]}, {"id": "1710.05963", "submitter": "Emmanuel Caron", "authors": "Emmanuel Caron, Sophie Dede", "title": "Asymptotic distribution of least squares estimators for linear models\n  with dependent errors : regular designs", "comments": "31 pages", "journal-ref": "Mathematical Methods of Statistics, 2018, Vol. 27, No. 4, pp.\n  268-293", "doi": "10.3103/S1066530718040026", "report-no": null, "categories": "math.ST math.PR stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the usual linear regression model in the case\nwhere the error process is assumed strictly stationary. We use a result from\nHannan, who proved a Central Limit Theorem for the usual least squares\nestimator under general conditions on the design and on the error process. We\nshow that for a large class of designs, the asymptotic covariance matrix is as\nsimple as the independent and identically distributed case. We then estimate\nthe covariance matrix using an estimator of the spectral density whose\nconsistency is proved under very mild conditions.\n", "versions": [{"version": "v1", "created": "Mon, 16 Oct 2017 19:25:18 GMT"}, {"version": "v2", "created": "Tue, 8 Jan 2019 13:46:30 GMT"}, {"version": "v3", "created": "Sat, 15 Jun 2019 16:35:19 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Caron", "Emmanuel", ""], ["Dede", "Sophie", ""]]}, {"id": "1710.05987", "submitter": "William Weimin Yoo", "authors": "William Weimin Yoo", "title": "Contributed Discussion to Uncertainty Quantification for the Horseshoe\n  by St\\'ephanie van der Pas, Botond Szab\\'o and Aad van der Vaart", "comments": "2 pages", "journal-ref": "Bayesian Anal. Volume 12, Number 4 (2017), 1262-1263", "doi": "10.1214/17-BA1065", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We begin by introducing the main ideas of the paper under discussion. We\ndiscuss some interesting issues regarding adaptive component-wise credible\nintervals. We then briefly touch upon the concepts of self-similarity and\nexcessive bias restriction. This is then followed by some comments on the\nextensive simulation study carried out in the paper.\n", "versions": [{"version": "v1", "created": "Mon, 16 Oct 2017 20:17:59 GMT"}, {"version": "v2", "created": "Sun, 28 Jan 2018 16:17:30 GMT"}], "update_date": "2018-01-30", "authors_parsed": [["Yoo", "William Weimin", ""]]}, {"id": "1710.06008", "submitter": "Yang Li", "authors": "Xiaodong Li, Yang Li, Shuyang Ling, Thomas Strohmer, and Ke Wei", "title": "When Do Birds of a Feather Flock Together? k-Means, Proximity, and Conic\n  Programming", "comments": "34 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a set of data, one central goal is to group them into clusters based on\nsome notion of similarity between the individual objects. One of the most\npopular and widely-used approaches is k-means despite the computational\nhardness to find its global minimum. We study and compare the properties of\ndifferent convex relaxations by relating them to corresponding proximity\nconditions, an idea originally introduced by Kumar and Kannan. Using conic\nduality theory, we present an improved proximity condition under which the\nPeng-Wei relaxation of k-means recovers the underlying clusters exactly. Our\nproximity condition improves upon Kumar and Kannan, and is comparable to that\nof Awashti and Sheffet where proximity conditions are established for\nprojective k-means. In addition, we provide a necessary proximity condition for\nthe exactness of the Peng-Wei relaxation. For the special case of equal cluster\nsizes, we establish a different and completely localized proximity condition\nunder which the Amini-Levina relaxation yields exact clustering, thereby having\naddressed an open problem by Awasthi and Sheffet in the balanced case. Our\nframework is not only deterministic and model-free but also comes with a clear\ngeometric meaning which allows for further analysis and generalization.\nMoreover, it can be conveniently applied to analyzing various data generative\nmodels such as the stochastic ball models and Gaussian mixture models. With\nthis method, we improve the current minimum separation bound for the stochastic\nball models and achieve the state-of-the-art results of learning Gaussian\nmixture models.\n", "versions": [{"version": "v1", "created": "Mon, 16 Oct 2017 22:10:29 GMT"}, {"version": "v2", "created": "Tue, 17 Jul 2018 23:59:11 GMT"}, {"version": "v3", "created": "Sun, 22 Jul 2018 04:03:30 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Li", "Xiaodong", ""], ["Li", "Yang", ""], ["Ling", "Shuyang", ""], ["Strohmer", "Thomas", ""], ["Wei", "Ke", ""]]}, {"id": "1710.06030", "submitter": "Martin Slawski", "authors": "Martin Slawski and Emanuel Ben-David", "title": "Linear Regression with Sparsely Permuted Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In regression analysis of multivariate data, it is tacitly assumed that\nresponse and predictor variables in each observed response-predictor pair\ncorrespond to the same entity or unit. In this paper, we consider the situation\nof \"permuted data\" in which this basic correspondence has been lost. Several\nrecent papers have considered this situation without further assumptions on the\nunderlying permutation. In applications, the latter is often to known to have\nadditional structure that can be leveraged. Specifically, we herein consider\nthe common scenario of \"sparsely permuted data\" in which only a small fraction\nof the data is affected by a mismatch between response and predictors. However,\nan adverse effect already observed for sparsely permuted data is that the least\nsquares estimator as well as other estimators not accounting for such partial\nmismatch are inconsistent. One approach studied in detail herein is to treat\npermuted data as outliers which motivates the use of robust regression\nformulations to estimate the regression parameter. The resulting estimate can\nsubsequently be used to recover the permutation. A notable benefit of the\nproposed approach is its computational simplicity given the general lack of\nprocedures for the above problem that are both statistically sound and\ncomputationally appealing.\n", "versions": [{"version": "v1", "created": "Mon, 16 Oct 2017 23:24:23 GMT"}, {"version": "v2", "created": "Wed, 15 Nov 2017 22:37:38 GMT"}], "update_date": "2017-11-17", "authors_parsed": [["Slawski", "Martin", ""], ["Ben-David", "Emanuel", ""]]}, {"id": "1710.06382", "submitter": "Jerry Chee", "authors": "Jerry Chee and Panos Toulis", "title": "Convergence diagnostics for stochastic gradient descent with constant\n  step size", "comments": "Accepted to Artificial Intelligence and Statistics, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many iterative procedures in stochastic optimization exhibit a transient\nphase followed by a stationary phase. During the transient phase the procedure\nconverges towards a region of interest, and during the stationary phase the\nprocedure oscillates in that region, commonly around a single point. In this\npaper, we develop a statistical diagnostic test to detect such phase transition\nin the context of stochastic gradient descent with constant learning rate. We\npresent theory and experiments suggesting that the region where the proposed\ndiagnostic is activated coincides with the convergence region. For a class of\nloss functions, we derive a closed-form solution describing such region.\nFinally, we suggest an application to speed up convergence of stochastic\ngradient descent by halving the learning rate each time stationarity is\ndetected. This leads to a new variant of stochastic gradient descent, which in\nmany settings is comparable to state-of-art.\n", "versions": [{"version": "v1", "created": "Tue, 17 Oct 2017 16:51:16 GMT"}, {"version": "v2", "created": "Fri, 23 Feb 2018 04:31:07 GMT"}], "update_date": "2018-02-26", "authors_parsed": [["Chee", "Jerry", ""], ["Toulis", "Panos", ""]]}, {"id": "1710.06566", "submitter": "Rajeshwari Majumdar", "authors": "Rajeshwari Majumdar", "title": "On Least Squares Linear Regression Without Second Moment", "comments": null, "journal-ref": "Minnesota Journal of Undergraduate Mathematics, Vol. 4, No. 1\n  (2018)", "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  If X and Y are real valued random variables such that the first moments of X,\nY, and XY exist and the conditional expectation of Y given X is an affine\nfunction of X, then the intercept and slope of the conditional expectation\nequal the intercept and slope of the least squares linear regression function,\neven though Y may not have a finite second moment. As a consequence, the affine\nin X form of the conditional expectation and zero covariance imply mean\nindependence.\n", "versions": [{"version": "v1", "created": "Wed, 18 Oct 2017 02:47:56 GMT"}], "update_date": "2018-08-06", "authors_parsed": [["Majumdar", "Rajeshwari", ""]]}, {"id": "1710.06573", "submitter": "Ming-Tien Tsai", "authors": "Ming-Tien Tsai", "title": "Towards an unified theory for testing statistical hypothesis:\n  Multinormal mean with nuisance covariance matrix", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Under a multinormal distribution with arbitrary unknown covariance matrix,\nthe main purpose of this paper is to propose a framework to achieve the goal of\nreconciliation of Bayesian, frequentist and Fisherian paradigms for the\nproblems of testing mean against restricted alternatives (closed convex cones).\nCombining Fisher's fiducial inference and Wald's decision theory via\nd-admissibility into an unified approach, the goal can then be achieved. To\nproceed, the tests constructed via the union-intersection principle are\nstudied.\n", "versions": [{"version": "v1", "created": "Wed, 18 Oct 2017 03:17:40 GMT"}, {"version": "v2", "created": "Sat, 21 Dec 2019 02:02:08 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Tsai", "Ming-Tien", ""]]}, {"id": "1710.06592", "submitter": "Ryoki Fukushima", "authors": "Marek Biskup, Ryoki Fukushima, Wolfgang Koenig", "title": "Eigenvalue fluctuations for lattice Anderson Hamiltonians: Unbounded\n  potentials", "comments": "25 pages", "journal-ref": "Interdisciplinary Information Sciences, 2018 Volume 24 Issue 1\n  Pages 59-76", "doi": "10.4036/iis.2018.A.03", "report-no": null, "categories": "math.PR math-ph math.MP math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider random Schr\\\"odinger operators with Dirichlet boundary conditions\noutside lattice approximations of a smooth Euclidean domain and study the\nbehavior of its lowest-lying eigenvalues in the limit when the lattice spacing\ntends to zero. Under a suitable moment assumption on the random potential and\nregularity of the spatial dependence of its mean, we prove that the eigenvalues\nof the random operator converge to those of a deterministic Schr\\\"odinger\noperator. Assuming also regularity of the variance, the fluctuation of the\nrandom eigenvalues around their mean are shown to obey a multivariate central\nlimit theorem. This extends the authors' recent work where similar conclusions\nhave been obtained for bounded random potentials.\n", "versions": [{"version": "v1", "created": "Wed, 18 Oct 2017 06:29:54 GMT"}], "update_date": "2018-07-04", "authors_parsed": [["Biskup", "Marek", ""], ["Fukushima", "Ryoki", ""], ["Koenig", "Wolfgang", ""]]}, {"id": "1710.06638", "submitter": "Martin Schindler", "authors": "Jana Jure\\v{c}kov\\'a, Martin Schindler and Jan Picek", "title": "Empirical regression quantile process with possible application to risk\n  analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The processes of the averaged regression quantiles and of their modifications\nprovide useful tools in the regression models when the covariates are not fully\nunder our control. As an application we mention the probabilistic risk\nassessment in the situation when the return depends on some exogenous\nvariables. The processes enable to evaluate the expected $\\alpha$-shortfall\n($0\\leq\\alpha\\leq 1$) and other measures of the risk, recently generally\naccepted in the financial literature, but also help to measure the risk in\nenvironment analysis and elsewhere.\n", "versions": [{"version": "v1", "created": "Wed, 18 Oct 2017 09:27:49 GMT"}], "update_date": "2017-10-19", "authors_parsed": [["Jure\u010dkov\u00e1", "Jana", ""], ["Schindler", "Martin", ""], ["Picek", "Jan", ""]]}, {"id": "1710.06676", "submitter": "Zoltan Kutalik", "authors": "Aaron McDaid, Zoltan Kutalik, Valentin Rousson", "title": "A five-decision testing procedure to infer on unidimensional parameter", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A statistical test can be seen as a procedure to produce a decision based on\nobserved data, where some decisions consist of rejecting a hypothesis (yielding\na significant result) and some do not, and where one controls the probability\nto make a wrong rejection at some pre-specified significance level. Whereas\ntraditional hypothesis testing involves only two possible decisions (to reject\nor not a null hypothesis), Kaiser's directional two-sided test as well as the\nmore recently introduced Jones and Tukey's testing procedure involve three\npossible decisions to infer on unidimensional parameter. The latter procedure\nassumes that a point null hypothesis is impossible (e.g. that two treatments\ncannot have exactly the same effect), allowing a gain of statistical power.\nThere are however situations where a point hypothesis is indeed plausible, for\nexample when considering hypotheses derived from Einstein's theories. In this\narticle, we introduce a five-decision rule testing procedure, which combines\nthe advantages of the testing procedures of Kaiser (no assumption on a point\nhypothesis being impossible) and of Jones and Tukey (higher power), allowing\nfor a non-negligible (typically 20%) reduction of the sample size needed to\nreach a given statistical power to get a significant result, compared to the\ntraditional approach.\n", "versions": [{"version": "v1", "created": "Wed, 18 Oct 2017 11:10:27 GMT"}], "update_date": "2017-10-19", "authors_parsed": [["McDaid", "Aaron", ""], ["Kutalik", "Zoltan", ""], ["Rousson", "Valentin", ""]]}, {"id": "1710.06683", "submitter": "Akitoshi Kimura", "authors": "Akitoshi Kimura", "title": "Confidence interval for correlation estimator between latent processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kimura and Yoshida treated a model in which the finite variation part of a\ntwo-dimensional semimartingale is expressed by time-integration of latent\nprocesses. They proposed a correlation estimator between the latent processes\nand proved its consistency and asymptotic mixed normality. In this paper, we\ndiscuss the confidence interval of the correlation estimator to detect the\ncorrelation. %between latent processes. We propose two types of estimators for\nasymptotic variance of the correlation estimator and prove their consistency in\na high frequency setting. Our model includes doubly stochastic Poisson\nprocesses whose intensity processes are correlated It\\^o processes. We compare\nour estimators based on the simulation of the doubly stochastic Poisson\nprocesses.\n", "versions": [{"version": "v1", "created": "Wed, 18 Oct 2017 11:34:45 GMT"}, {"version": "v2", "created": "Sat, 18 Aug 2018 08:56:32 GMT"}], "update_date": "2018-08-21", "authors_parsed": [["Kimura", "Akitoshi", ""]]}, {"id": "1710.06809", "submitter": "Wayne Gao", "authors": "Wayne Yuan Gao", "title": "Minimax Linear Estimation at a Boundary Point", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper characterizes the minimax linear estimator of the value of an\nunknown function at a boundary point of its domain in a Gaussian white noise\nmodel under the restriction that the first-order derivative of the unknown\nfunction is Lipschitz continuous (the second-order H\\\"{o}lder class). The\nresult is then applied to construct the minimax optimal estimator for the\nregression discontinuity design model, where the parameter of interest involves\nfunction values at boundary points.\n", "versions": [{"version": "v1", "created": "Wed, 18 Oct 2017 16:11:13 GMT"}], "update_date": "2017-10-19", "authors_parsed": [["Gao", "Wayne Yuan", ""]]}, {"id": "1710.06899", "submitter": "Jeha Yang", "authors": "Jeha Yang and Iain M. Johnstone", "title": "Edgeworth correction for the largest eigenvalue in a spiked PCA model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study improved approximations to the distribution of the largest\neigenvalue $\\hat{\\ell}$ of the sample covariance matrix of $n$ zero-mean\nGaussian observations in dimension $p+1$. We assume that one population\nprincipal component has variance $\\ell > 1$ and the remaining `noise'\ncomponents have common variance $1$. In the high dimensional limit $p/n \\to\n\\gamma > 0$, we begin study of Edgeworth corrections to the limiting Gaussian\ndistribution of $\\hat{\\ell}$ in the supercritical case $\\ell > 1 + \\sqrt\n\\gamma$. The skewness correction involves a quadratic polynomial as in\nclassical settings, but the coefficients reflect the high dimensional\nstructure. The methods involve Edgeworth expansions for sums of independent\nnon-identically distributed variates obtained by conditioning on the sample\nnoise eigenvalues, and limiting bulk properties \\textit{and} fluctuations of\nthese noise eigenvalues.\n", "versions": [{"version": "v1", "created": "Wed, 18 Oct 2017 19:10:11 GMT"}], "update_date": "2017-10-20", "authors_parsed": [["Yang", "Jeha", ""], ["Johnstone", "Iain M.", ""]]}, {"id": "1710.06959", "submitter": "Wenjia Wang", "authors": "Wenjia Wang, Rui Tuo, and C. F. Jeff Wu", "title": "On Prediction Properties of Kriging: Uniform Error Bounds and Robustness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kriging based on Gaussian random fields is widely used in reconstructing\nunknown functions. The kriging method has pointwise predictive distributions\nwhich are computationally simple. However, in many applications one would like\nto predict for a range of untried points simultaneously. In this work we obtain\nsome error bounds for the (simple) kriging predictor under the uniform metric.\nIt works for a scattered set of input points in an arbitrary dimension, and\nalso covers the case where the covariance function of the Gaussian process is\nmisspecified. These results lead to a better understanding of the rate of\nconvergence of kriging under the Gaussian or the Mat\\'ern correlation\nfunctions, the relationship between space-filling designs and kriging models,\nand the robustness of the Mat\\'ern correlation functions.\n", "versions": [{"version": "v1", "created": "Wed, 18 Oct 2017 23:20:08 GMT"}, {"version": "v2", "created": "Mon, 9 Jul 2018 15:27:50 GMT"}, {"version": "v3", "created": "Sun, 17 Mar 2019 21:34:22 GMT"}, {"version": "v4", "created": "Tue, 19 Mar 2019 01:50:27 GMT"}], "update_date": "2019-03-20", "authors_parsed": [["Wang", "Wenjia", ""], ["Tuo", "Rui", ""], ["Wu", "C. F. Jeff", ""]]}, {"id": "1710.06987", "submitter": "Rajeshwari Majumdar", "authors": "Rajeshwari Majumdar", "title": "On Affine and Conjugate Nonparametric Regression", "comments": "Revised and fixed typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Suppose the nonparametric regression function of a response variable $Y$ on\ncovariates $X$ and $Z$ is an affine function of $X$ such that the slope $\\beta$\nand the intercept $\\alpha$ are real valued measurable functions on the range of\nthe completely arbitrary random element $Z$. Assume that $X$ has a finite\nmoment of order greater than or equal to $2$, $Y$ has a finite moment of\nconjugate order, and $\\alpha\\left(Z\\right)$ and $\\alpha\\left(Z\\right)X$ have\nfinite first moments. Then, the nonparametric regression function equals the\nleast squares linear regression function of $Y$ on $X$ with all the moments\nthat appear in the expression of the linear regression function calculated\nconditional on $Z$. Consequently, conditional mean independence implies zero\nconditional covariance and a degenerate version of the aforesaid affine form\nfor the nonparametric regression function, whereas the aforesaid affine form\nand zero conditional covariance imply conditional mean independence. Further,\nit turns out that the nonparametric regression function has the aforesaid\naffine form if $X$ is Bernoulli, and since $1$ is the conjugate exponent of\n$\\infty$, the least squares linear regression formula for the nonparametric\nregression function holds when $Y$ has only a finite first moment and $Z$ is\ncompletely arbitrary.\n", "versions": [{"version": "v1", "created": "Thu, 19 Oct 2017 02:36:35 GMT"}, {"version": "v2", "created": "Mon, 18 Dec 2017 00:38:43 GMT"}], "update_date": "2017-12-19", "authors_parsed": [["Majumdar", "Rajeshwari", ""]]}, {"id": "1710.07000", "submitter": "Jay Ver Hoef", "authors": "Jay M. Ver Hoef and Ephraim M. Hanks and Mevin B. Hooten", "title": "On the Relationship between Conditional (CAR) and Simultaneous (SAR)\n  Autoregressive Models", "comments": "18 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We clarify relationships between conditional (CAR) and simultaneous (SAR)\nautoregressive models. We review the literature on this topic and find that it\nis mostly incomplete. Our main result is that a SAR model can be written as a\nunique CAR model, and while a CAR model can be written as a SAR model, it is\nnot unique. In fact, we show how any multivariate Gaussian distribution on a\nfinite set of points with a positive-definite covariance matrix can be written\nas either a CAR or a SAR model. We illustrate how to obtain any number of SAR\ncovariance matrices from a single CAR covariance matrix by using Givens\nrotation matrices on a simulated example. We also discuss sparseness in the\noriginal CAR construction, and for the resulting SAR weights matrix. For a real\nexample, we use crime data in 49 neighborhoods from Columbus, Ohio, and show\nthat a geostatistical model optimizes the likelihood much better than typical\nfirst-order CAR models. We then use the implied weights from the geostatistical\nmodel to estimate CAR model parameters that provides the best overall\noptimization.\n", "versions": [{"version": "v1", "created": "Thu, 19 Oct 2017 04:45:55 GMT"}], "update_date": "2017-10-20", "authors_parsed": [["Hoef", "Jay M. Ver", ""], ["Hanks", "Ephraim M.", ""], ["Hooten", "Mevin B.", ""]]}, {"id": "1710.07175", "submitter": "Thomas Kahle", "authors": "Tobias Boege, Alessio D'Al\\`i, Thomas Kahle and Bernd Sturmfels", "title": "The Geometry of Gaussoids", "comments": "32 pages, 4 figures, v2: Prop. 6.4 and Thm. 8.4 added, various small\n  improvements, 34 pages", "journal-ref": "Foundations of Computational Mathematics 19 (2019), pp. 775-812", "doi": "10.1007/s10208-018-9396-x", "report-no": null, "categories": "math.CO math.AC math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A gaussoid is a combinatorial structure that encodes independence in\nprobability and statistics, just like matroids encode independence in linear\nalgebra. The gaussoid axioms of Lnenicka and Mat\\'us are equivalent to\ncompatibility with certain quadratic relations among principal and\nalmost-principal minors of a symmetric matrix. We develop the geometric theory\nof gaussoids, based on the Lagrangian Grassmannian and its symmetries. We\nintroduce oriented gaussoids and valuated gaussoids, thus connecting to real\nand tropical geometry. We classify small realizable and non-realizable\ngaussoids. Positive gaussoids are as nice as positroids: they are all\nrealizable via graphical models.\n", "versions": [{"version": "v1", "created": "Thu, 19 Oct 2017 15:17:12 GMT"}, {"version": "v2", "created": "Thu, 24 May 2018 13:40:43 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Boege", "Tobias", ""], ["D'Al\u00ec", "Alessio", ""], ["Kahle", "Thomas", ""], ["Sturmfels", "Bernd", ""]]}, {"id": "1710.07278", "submitter": "Markus Rei{\\ss}", "authors": "Gilles Blanchard, Marc Hoffmann and Markus Rei{\\ss}", "title": "Early stopping for statistical inverse problems via truncated SVD\n  estimation", "comments": "slightly modified version. arXiv admin note: text overlap with\n  arXiv:1606.07702", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider truncated SVD (or spectral cut-off, projection) estimators for a\nprototypical statistical inverse problem in dimension $D$. Since calculating\nthe singular value decomposition (SVD) only for the largest singular values is\nmuch less costly than the full SVD, our aim is to select a data-driven\ntruncation level $\\widehat m\\in\\{1,\\ldots,D\\}$ only based on the knowledge of\nthe first $\\widehat m$ singular values and vectors. We analyse in detail\nwhether sequential {\\it early stopping} rules of this type can preserve\nstatistical optimality. Information-constrained lower bounds and matching upper\nbounds for a residual based stopping rule are provided, which give a clear\npicture in which situation optimal sequential adaptation is feasible. Finally,\na hybrid two-step approach is proposed which allows for classical oracle\ninequalities while considerably reducing numerical complexity.\n", "versions": [{"version": "v1", "created": "Thu, 19 Oct 2017 09:43:06 GMT"}, {"version": "v2", "created": "Tue, 12 Jun 2018 14:03:19 GMT"}, {"version": "v3", "created": "Fri, 7 Sep 2018 11:37:46 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Blanchard", "Gilles", ""], ["Hoffmann", "Marc", ""], ["Rei\u00df", "Markus", ""]]}, {"id": "1710.07285", "submitter": "Nazar Buzun", "authors": "Nazar Buzun, Valeriy Avanesov", "title": "Bootstrap for change point detection", "comments": "arXiv admin note: text overlap with arXiv:1507.05034 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Change point detection task Likelihood Ratio Test (LRT) is sequentially\napplied in a sliding window procedure. Its high values indicate changes of\nparametric distribution in the data sequence. Correspondingly LRT values\nrequire predefined bound for their maximum. The maximum value has unknown\ndistribution and may be calibrated with multiplier bootstrap. Bootstrap\nprocedure convolves independent components of the Likelihood function with\nrandom weights, that enables to estimate empirically LRT distribution. For this\nempirical distribution of the LRT we show convergence rates to the real maximum\nvalue distribution.\n", "versions": [{"version": "v1", "created": "Thu, 19 Oct 2017 17:13:25 GMT"}], "update_date": "2017-10-23", "authors_parsed": [["Buzun", "Nazar", ""], ["Avanesov", "Valeriy", ""]]}, {"id": "1710.07468", "submitter": "Valeriy Baskakov Prof", "authors": "Valery Baskakov and Anna Bartunova", "title": "Nonparametric estimation of multivariate distribution function for\n  truncated and censored lifetime data", "comments": "32 pages, 11 figures", "journal-ref": null, "doi": "10.1007/s13385-019-00194-1", "report-no": null, "categories": "stat.ME math.ST q-bio.QM stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A number of models for generating statistical data in various fields of\ninsurance, including life insurance, pensions, and general insurance have been\nconsidered. It is shown that the insurance statistics data, as a rule, are\ntruncated and censored, and often multivariate. We propose a non-parametric\nestimation of the distribution function for multivariate truncated-censored\ndata in the form of a quasi-empirical distribution and a simple iterative\nalgorithm for its construction. To check the accuracy of the proposed\nevaluation of the distribution function for truncated-censored data, simulation\nstudies have been conducted, which showed its high efficiency. The proposed\nestimates have been tested for many years by the IAAC Group of Companies in the\nactuarial valuation of corporate social liabilities according to IAS 19\nEmployee Benefits. Apart from insurance, some results of the work can be used,\nfor example in medicine, biology, demography, mathematical theory of\nreliability, etc.\n", "versions": [{"version": "v1", "created": "Fri, 20 Oct 2017 10:00:37 GMT"}, {"version": "v2", "created": "Sat, 13 Apr 2019 18:19:39 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Baskakov", "Valery", ""], ["Bartunova", "Anna", ""]]}, {"id": "1710.07502", "submitter": "Marie-Colette van Lieshout", "authors": "M.N.M. van Lieshout", "title": "Nearest-neighbour Markov point processes on graphs with Euclidean edges", "comments": null, "journal-ref": "Adv. Appl. Probab. 50 (2018) 1275-1293", "doi": "10.1017/apr.2018.60", "report-no": null, "categories": "math.ST math.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define nearest-neighbour point processes on graphs with Euclidean edges\nand linear networks. They can be seen as the analogues of renewal processes on\nthe real line. We show that the Delaunay neighbourhood relation on a tree\nsatisfies the Baddeley--M{\\o}ller consistency conditions and provide a\ncharacterisation of Markov functions with respect to this relation. We show\nthat a modified relation defined in terms of the local geometry of the graph\nsatisfies the consistency conditions for all graphs with Euclidean edges.\n", "versions": [{"version": "v1", "created": "Fri, 20 Oct 2017 12:21:33 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["van Lieshout", "M. N. M.", ""]]}, {"id": "1710.07755", "submitter": "Toshiyuki Fujii", "authors": "Toshiyuki Fujii, Noriyuki Hatakenaka", "title": "A path integral approach to Bayesian inference in Markov processes", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cond-mat.stat-mech stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We formulate Bayesian updates in Markov processes by means of path integral\ntechniques and derive the imaginary-time Schr\\\"{o}dinger equation with\nlikelihood to direct the inference incorporated as a potential for the\nposterior probability distribution\n", "versions": [{"version": "v1", "created": "Sat, 21 Oct 2017 05:55:04 GMT"}], "update_date": "2017-10-24", "authors_parsed": [["Fujii", "Toshiyuki", ""], ["Hatakenaka", "Noriyuki", ""]]}, {"id": "1710.07781", "submitter": "Kevin Kokot", "authors": "Holger Dette, Kevin Kokot and Alexander Aue", "title": "Functional data analysis in the Banach space of continuous functions", "comments": "- updated footnote and acknowledgements", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Functional data analysis is typically conducted within the $L^2$-Hilbert\nspace framework. There is by now a fully developed statistical toolbox allowing\nfor the principled application of the functional data machinery to real-world\nproblems, often based on dimension reduction techniques such as functional\nprincipal component analysis. At the same time, there have recently been a\nnumber of publications that sidestep dimension reduction steps and focus on a\nfully functional $L^2$-methodology. This paper goes one step further and\ndevelops data analysis methodology for functional time series in the space of\nall continuous functions. The work is motivated by the fact that objects with\nrather different shapes may still have a small $L^2$-distance and are therefore\nidentified as similar when using an $L^2$-metric. However, in applications it\nis often desirable to use metrics reflecting the visualization of the curves in\nthe statistical analysis. The methodological contributions are focused on\ndeveloping two-sample and change-point tests as well as confidence bands, as\nthese procedures appear do be conducive to the proposed setting. Particular\ninterest is put on relevant differences; that is, on not trying to test for\nexact equality, but rather for pre-specified deviations under the null\nhypothesis.\n  The procedures are justified through large-sample theory. To ensure\npracticability, non-standard bootstrap procedures are developed and\ninvestigated addressing particular features that arise in the problem of\ntesting relevant hypotheses. The finite sample properties are explored through\na simulation study and an application to annual temperature profiles.\n", "versions": [{"version": "v1", "created": "Sat, 21 Oct 2017 10:25:41 GMT"}, {"version": "v2", "created": "Fri, 24 Nov 2017 10:15:54 GMT"}], "update_date": "2017-11-27", "authors_parsed": [["Dette", "Holger", ""], ["Kokot", "Kevin", ""], ["Aue", "Alexander", ""]]}, {"id": "1710.07792", "submitter": "Won-Ki Seo", "authors": "Won-Ki Seo", "title": "Cointegrated Density-Valued Linear Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In data rich environments we may sometimes deal with time series that are\nprobability density-function valued, such as observations of cross-sectional\nincome distributions over time. To apply the methods of functional time series\nanalysis to such observations, we should first embed them in a linear space in\nwhich the essential properties of densities are preserved under addition and\nscalar multiplication. Bayes Hilbert spaces provide one way to achieve this\nembedding. In this paper we investigate the use of Bayes Hilbert spaces to\nmodel cointegrated density-valued linear processes. We develop an I(1)\nrepresentation theory for cointegrated linear processes in a Bayes Hilbert\nspace, and adapt existing statistical procedures for estimating the\ncorresponding attractor space to a Bayes Hilbert space setting. We revisit\nempirical applications involving earnings and wage densities to illustrate the\nutility of our approach.\n", "versions": [{"version": "v1", "created": "Sat, 21 Oct 2017 12:00:05 GMT"}, {"version": "v2", "created": "Fri, 17 Nov 2017 07:13:26 GMT"}, {"version": "v3", "created": "Wed, 16 May 2018 11:53:17 GMT"}], "update_date": "2018-05-17", "authors_parsed": [["Seo", "Won-Ki", ""]]}, {"id": "1710.07797", "submitter": "Junhong Lin", "authors": "Junhong Lin and Lorenzo Rosasco", "title": "Optimal Rates for Learning with Nystr\\\"om Stochastic Gradient Methods", "comments": "41pages, 6figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.FA math.OC math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the setting of nonparametric regression, we propose and study a\ncombination of stochastic gradient methods with Nystr\\\"om subsampling, allowing\nmultiple passes over the data and mini-batches. Generalization error bounds for\nthe studied algorithm are provided. Particularly, optimal learning rates are\nderived considering different possible choices of the step-size, the mini-batch\nsize, the number of iterations/passes, and the subsampling level. In comparison\nwith state-of-the-art algorithms such as the classic stochastic gradient\nmethods and kernel ridge regression with Nystr\\\"om, the studied algorithm has\nadvantages on the computational complexity, while achieving the same optimal\nlearning rates. Moreover, our results indicate that using mini-batches can\nreduce the total computational cost while achieving the same optimal\nstatistical results.\n", "versions": [{"version": "v1", "created": "Sat, 21 Oct 2017 12:36:39 GMT"}], "update_date": "2017-10-24", "authors_parsed": [["Lin", "Junhong", ""], ["Rosasco", "Lorenzo", ""]]}, {"id": "1710.07878", "submitter": "Junyong Park", "authors": "Mingxiang Cao, Junyong Park, Daojiang He", "title": "A test for k sample Behrens-Fisher problem in high dimensional data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the $k$ sample Behrens-Fisher problem is investigated in high\ndimensional setting. We propose a new test statistic and demonstrate that the\nproposed test is expected to have more powers than some existing test\nespecially when sample sizes are unbalanced. We provide theoretical\ninvestigation as well as numerical studies on both sizes and powers of the\nproposed tests and existing test. Both theoretical comparison of the asymptotic\npower functions and numerical studies show that the proposed test tends to have\nmore powers than existing test in many cases of unbalanced sample sizes.\n", "versions": [{"version": "v1", "created": "Sun, 22 Oct 2017 03:10:09 GMT"}], "update_date": "2017-10-24", "authors_parsed": [["Cao", "Mingxiang", ""], ["Park", "Junyong", ""], ["He", "Daojiang", ""]]}, {"id": "1710.07926", "submitter": "Antoine Godichon-Baggioni", "authors": "Antoine Godichon-Baggioni and Sofiane Saadane", "title": "On the rates of convergence of Parallelized Averaged Stochastic Gradient\n  Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growing interest for high dimensional and functional data analysis led in\nthe last decade to an important research developing a consequent amount of\ntechniques. Parallelized algorithms, which consist in distributing and treat\nthe data into different machines, for example, are a good answer to deal with\nlarge samples taking values in high dimensional spaces. We introduce here a\nparallelized averaged stochastic gradient algorithm, which enables to treat\nefficiently and recursively the data, and so, without taking care if the\ndistribution of the data into the machines is uniform. The rate of convergence\nin quadratic mean as well as the asymptotic normality of the parallelized\nestimates are given, for strongly and locally strongly convex objectives.\n", "versions": [{"version": "v1", "created": "Sun, 22 Oct 2017 11:47:40 GMT"}], "update_date": "2017-10-24", "authors_parsed": [["Godichon-Baggioni", "Antoine", ""], ["Saadane", "Sofiane", ""]]}, {"id": "1710.07954", "submitter": "Freweyni Kidane Teklehaymanot", "authors": "Freweyni K. Teklehaymanot, Michael Muma, and Abdelhak M. Zoubir", "title": "Bayesian Cluster Enumeration Criterion for Unsupervised Learning", "comments": "14 pages, 7 figures", "journal-ref": null, "doi": "10.1109/TSP.2018.2866385", "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive a new Bayesian Information Criterion (BIC) by formulating the\nproblem of estimating the number of clusters in an observed data set as\nmaximization of the posterior probability of the candidate models. Given that\nsome mild assumptions are satisfied, we provide a general BIC expression for a\nbroad class of data distributions. This serves as a starting point when\nderiving the BIC for specific distributions. Along this line, we provide a\nclosed-form BIC expression for multivariate Gaussian distributed variables. We\nshow that incorporating the data structure of the clustering problem into the\nderivation of the BIC results in an expression whose penalty term is different\nfrom that of the original BIC. We propose a two-step cluster enumeration\nalgorithm. First, a model-based unsupervised learning algorithm partitions the\ndata according to a given set of candidate models. Subsequently, the number of\nclusters is determined as the one associated with the model for which the\nproposed BIC is maximal. The performance of the proposed two-step algorithm is\ntested using synthetic and real data sets.\n", "versions": [{"version": "v1", "created": "Sun, 22 Oct 2017 14:59:08 GMT"}, {"version": "v2", "created": "Fri, 15 Dec 2017 17:31:04 GMT"}, {"version": "v3", "created": "Mon, 27 Aug 2018 13:53:56 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Teklehaymanot", "Freweyni K.", ""], ["Muma", "Michael", ""], ["Zoubir", "Abdelhak M.", ""]]}, {"id": "1710.07976", "submitter": "Mohamed El-Hadidy", "authors": "Mohamed Abd Allah El-Hadidy", "title": "Discrete Distribution for a Wiener Process Range and its Properties", "comments": "28 pages, 12 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the discrete distribution of a Wiener process range. Rather than\nfinding some basic distributional properties including hazard rate function,\nmoments, Stress-strength parameter and order statistics of this distribution,\nthis work studies some basic properties of the truncated version of this\ndistribution. The effectiveness of this distribution is established using a\ndata set.\n", "versions": [{"version": "v1", "created": "Sun, 22 Oct 2017 16:52:37 GMT"}], "update_date": "2017-10-24", "authors_parsed": [["El-Hadidy", "Mohamed Abd Allah", ""]]}, {"id": "1710.08017", "submitter": "Fangzheng Xie", "authors": "Fangzheng Xie, Yanxun Xu", "title": "Adaptive Bayesian nonparametric regression using kernel mixture of\n  polynomials with application to partial linear model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a kernel mixture of polynomials prior for Bayesian nonparametric\nregression. The regression function is modeled by local averages of polynomials\nwith kernel mixture weights. We obtain the minimax-optimal rate of contraction\nof the full posterior distribution up to a logarithmic factor that adapts to\nthe smoothness level of the true function by estimating metric entropies of\ncertain function classes. We also provide a frequentist sieve maximum\nlikelihood estimator with a near-optimal convergence rate. We further\ninvestigate the application of the kernel mixture of polynomials to the partial\nlinear model and obtain both the near-optimal rate of contraction for the\nnonparametric component and the Bernstein-von Mises limit (i.e., asymptotic\nnormality) of the parametric component. The proposed method is illustrated with\nnumerical examples and shows superior performance in terms of computational\nefficiency, accuracy, and uncertainty quantification compared to the local\npolynomial regression, DiceKriging, and the robust Gaussian stochastic process.\n", "versions": [{"version": "v1", "created": "Sun, 22 Oct 2017 21:28:09 GMT"}, {"version": "v2", "created": "Mon, 5 Mar 2018 02:04:30 GMT"}, {"version": "v3", "created": "Thu, 13 Sep 2018 20:13:07 GMT"}], "update_date": "2018-09-17", "authors_parsed": [["Xie", "Fangzheng", ""], ["Xu", "Yanxun", ""]]}, {"id": "1710.08051", "submitter": "Rajeshwari Majumdar", "authors": "Rajeshwari Majumdar and Suman Majumdar", "title": "On Asymptotic Standard Normality of the Two Sample Pivot", "comments": "arXiv admin note: text overlap with arXiv:1612.01668", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The asymptotic solution to the problem of comparing the means of two\nheteroscedastic populations, based on two random samples from the populations,\nhinges on the pivot underpinning the construction of the confidence interval\nand the test statistic being asymptotically standard Normal, which is known to\nhappen if the two samples are independent and the ratio of the sample sizes\nconverges to a finite positive number. This restriction on the asymptotic\nbehavior of the ratio of the sample sizes carries the risk of rendering the\nasymptotic justification of the finite sample approximation invalid. It turns\nout that neither the restriction on the asymptotic behavior of the ratio of the\nsample sizes nor the assumption of cross sample independence is necessary for\nthe pivotal convergence in question to take place. If the joint distribution of\nthe standardized sample means converges to a spherically symmetric\ndistribution, then that distribution must be bivariate standard Normal (which\ncan happen without the assumption of cross sample independence), and the\naforesaid pivotal convergence holds.\n", "versions": [{"version": "v1", "created": "Mon, 23 Oct 2017 00:39:37 GMT"}], "update_date": "2017-10-30", "authors_parsed": [["Majumdar", "Rajeshwari", ""], ["Majumdar", "Suman", ""]]}, {"id": "1710.08120", "submitter": "Veronique Maume-Deschamps", "authors": "M. Ahmed, V Maume-Deschamps (ICJ), P. Ribereau (ICJ), C. Vial (ICJ)", "title": "A semi-parametric estimation for max-mixture spatial processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We proposed a semi-parametric estimation procedure in order to estimate the\nparameters of a max-mixture model and also of a max-stable model (inverse\nmax-stable model) as an alternative to composite likelihood. A good estimation\nby the proposed estimator required the dependence measure to detect all\ndependence structures in the model, especially when dealing with the\nmax-mixture model. We overcame this challenge by using the F-madogram. The\nsemi-parametric estimation was then based on a quasi least square method, by\nminimizing the square difference between the theoretical F-madogram and an\nempirical one. We evaluated the performance of this estimator through a\nsimulation study. It was shown that on an average, the estimation is performed\nwell, although in some cases, it encountered some difficulties. We apply our\nestimation procedure to model the daily rainfalls over the East Australia.\n", "versions": [{"version": "v1", "created": "Mon, 23 Oct 2017 07:31:38 GMT"}, {"version": "v2", "created": "Tue, 5 Dec 2017 16:27:44 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["Ahmed", "M.", "", "ICJ"], ["Maume-Deschamps", "V", "", "ICJ"], ["Ribereau", "P.", "", "ICJ"], ["Vial", "C.", "", "ICJ"]]}, {"id": "1710.08388", "submitter": "Pramita Bagchi", "authors": "Pramita Bagchi and Holger Dette", "title": "A Test for Separability in Covariance Operators of Random Surfaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The assumption of separability is a simplifying and very popular assumption\nin the analysis of spatio-temporal or hypersurface data structures. It is often\nmade in situations where the covariance structure cannot be easily estimated,\nfor example because of a small sample size or because of computational storage\nproblems. In this paper we propose a new and very simple test to validate this\nassumption. Our approach is based on a measure of separability which is zero in\nthe case of separability and positive otherwise. The measure can be estimated\nwithout calculating the full non-separable covariance operator. We prove\nasymptotic normality of the corresponding statistic with a limiting variance,\nwhich can easily be estimated from the available data. As a consequence\nquantiles of the standard normal distribution can be used to obtain critical\nvalues and the new test of separability is very easy to implement. In\nparticular, our approach does neither require projections on subspaces\ngenerated by the eigenfunctions of the covariance operator, nor resampling\nprocedures to obtain critical values nor distributional assumptions as used by\nother available methods of constructing tests for separability. We investigate\nthe finite sample performance by means of a simulation study and also provide a\ncomparison with the currently available methodology. Finally, the new procedure\nis illustrated analyzing wind speed and temperature data.\n", "versions": [{"version": "v1", "created": "Mon, 23 Oct 2017 16:59:26 GMT"}, {"version": "v2", "created": "Mon, 13 Nov 2017 13:59:10 GMT"}, {"version": "v3", "created": "Wed, 2 Jan 2019 09:04:48 GMT"}], "update_date": "2019-01-03", "authors_parsed": [["Bagchi", "Pramita", ""], ["Dette", "Holger", ""]]}, {"id": "1710.08607", "submitter": "Shweta Jain", "authors": "Talya Eden and Shweta Jain and Ali Pinar and Dana Ron and C. Seshadhri", "title": "Provable and practical approximations for the degree distribution using\n  sublinear graph samples", "comments": "Longer version of the WWW 2018 submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.DS math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The degree distribution is one of the most fundamental properties used in the\nanalysis of massive graphs. There is a large literature on graph sampling,\nwhere the goal is to estimate properties (especially the degree distribution)\nof a large graph through a small, random sample. The degree distribution\nestimation poses a significant challenge, due to its heavy-tailed nature and\nthe large variance in degrees.\n  We design a new algorithm, SADDLES, for this problem, using recent\nmathematical techniques from the field of sublinear algorithms. The SADDLES\nalgorithm gives provably accurate outputs for all values of the degree\ndistribution. For the analysis, we define two fatness measures of the degree\ndistribution, called the $h$-index and the $z$-index. We prove that SADDLES is\nsublinear in the graph size when these indices are large. A corollary of this\nresult is a provably sublinear algorithm for any degree distribution bounded\nbelow by a power law.\n  We deploy our new algorithm on a variety of real datasets and demonstrate its\nexcellent empirical behavior. In all instances, we get extremely accurate\napproximations for all values in the degree distribution by observing at most\n$1\\%$ of the vertices. This is a major improvement over the state-of-the-art\nsampling algorithms, which typically sample more than $10\\%$ of the vertices to\ngive comparable results. We also observe that the $h$ and $z$-indices of real\ngraphs are large, validating our theoretical analysis.\n", "versions": [{"version": "v1", "created": "Tue, 24 Oct 2017 05:52:43 GMT"}, {"version": "v2", "created": "Fri, 19 Jan 2018 05:32:23 GMT"}, {"version": "v3", "created": "Tue, 28 Aug 2018 05:22:07 GMT"}], "update_date": "2018-08-29", "authors_parsed": [["Eden", "Talya", ""], ["Jain", "Shweta", ""], ["Pinar", "Ali", ""], ["Ron", "Dana", ""], ["Seshadhri", "C.", ""]]}, {"id": "1710.08775", "submitter": "Patrick Forr\\'e", "authors": "Patrick Forr\\'e and Joris M. Mooij", "title": "Markov Properties for Graphical Models with Cycles and Latent Variables", "comments": "131 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.ML stat.OT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate probabilistic graphical models that allow for both cycles and\nlatent variables. For this we introduce directed graphs with hyperedges\n(HEDGes), generalizing and combining both marginalized directed acyclic graphs\n(mDAGs) that can model latent (dependent) variables, and directed mixed graphs\n(DMGs) that can model cycles. We define and analyse several different Markov\nproperties that relate the graphical structure of a HEDG with a probability\ndistribution on a corresponding product space over the set of nodes, for\nexample factorization properties, structural equations properties,\nordered/local/global Markov properties, and marginal versions of these. The\nvarious Markov properties for HEDGes are in general not equivalent to each\nother when cycles or hyperedges are present, in contrast with the simpler case\nof directed acyclic graphical (DAG) models (also known as Bayesian networks).\nWe show how the Markov properties for HEDGes - and thus the corresponding\ngraphical Markov models - are logically related to each other.\n", "versions": [{"version": "v1", "created": "Tue, 24 Oct 2017 13:52:34 GMT"}], "update_date": "2017-10-25", "authors_parsed": [["Forr\u00e9", "Patrick", ""], ["Mooij", "Joris M.", ""]]}, {"id": "1710.08845", "submitter": "Joe Buhler", "authors": "J. P. Buhler, A. C. Gamst, R. L. Graham, and A. W. Hales", "title": "Explicit error bounds for lattice Edgeworth expansions", "comments": "Will appear in \"Connections in Discrete Mathematics\", Cambridge\n  University Press, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated, roughly, by comparing the mean and median of an IID sum of bounded\nlattice random variables, we develop explicit and effective bounds on the\nerrors involved in the one-term Edgeworth expansion for such sums.\n", "versions": [{"version": "v1", "created": "Tue, 24 Oct 2017 15:26:12 GMT"}], "update_date": "2017-10-25", "authors_parsed": [["Buhler", "J. P.", ""], ["Gamst", "A. C.", ""], ["Graham", "R. L.", ""], ["Hales", "A. W.", ""]]}, {"id": "1710.08903", "submitter": "Quan Zhou", "authors": "Quan Zhou", "title": "Asymptotics of multivariate contingency tables with fixed marginals", "comments": "Slightly revised", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the asymptotic distribution of a cell in a 2 x ... x 2\ncontingency table as the fixed marginal totals tend to infinity. The asymptotic\norder of the cell variance is derived and a useful diagnostic is given for\ndetermining whether the cell has a Poisson limit or a Gaussian limit. There are\nthree forms of Poisson convergence. The exact form is shown to be determined by\nthe growth rates of the two smallest marginal totals. The results are\ngeneralized to contingency tables with arbitrary sizes and are further\ncomplemented with concrete examples.\n", "versions": [{"version": "v1", "created": "Tue, 24 Oct 2017 17:38:38 GMT"}, {"version": "v2", "created": "Mon, 16 Apr 2018 02:42:14 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Zhou", "Quan", ""]]}, {"id": "1710.08933", "submitter": "Gunnar Taraldsen", "authors": "Gunnar Taraldsen, Jarle Tufto, and Bo H. Lindqvist", "title": "Improper posteriors are not improper", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In 1933 Kolmogorov constructed a general theory that defines the modern\nconcept of conditional expectation. In 1955 Renyi fomulated a new axiomatic\ntheory for probability motivated by the need to include unbounded measures. We\nintroduce a general concept of conditional expectation in Renyi spaces. In this\ntheory improper priors are allowed, and the resulting posterior can also be\nimproper.\n  In 1965 Lindley published his classic text on Bayesian statistics using the\ntheory of Renyi, but retracted this idea in 1973 due to the appearance of\nmarginalization paradoxes presented by Dawid, Stone, and Zidek. The paradoxes\nare investigated, and the seemingly conflicting results are explained. The\ntheory of Renyi can hence be used as an axiomatic basis for statistics that\nallows use of unbounded priors.\n  Keywords: Haldane's prior; Poisson intensity; Marginalization paradox;\nMeasure theory; conditional probability space; axioms for statistics;\nconditioning on a sigma field; improper prior\n", "versions": [{"version": "v1", "created": "Tue, 24 Oct 2017 18:07:05 GMT"}, {"version": "v2", "created": "Mon, 4 Dec 2017 20:46:09 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["Taraldsen", "Gunnar", ""], ["Tufto", "Jarle", ""], ["Lindqvist", "Bo H.", ""]]}, {"id": "1710.09020", "submitter": "Ziwei Zhu", "authors": "Ziwei Zhu, Wenjing Zhou", "title": "Taming heavy-tailed features by shrinkage", "comments": "24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we focus on a variant of the generalized linear model (GLM)\ncalled corrupted GLM (CGLM) with heavy-tailed features and responses. To\nrobustify the statistical inference on this model, we propose to apply\n$\\ell_4$-norm shrinkage to the feature vectors in the low-dimensional regime\nand apply elementwise shrinkage to them in the high-dimensional regime. Under\nbounded fourth moment assumptions, we show that the maximum likelihood\nestimator (MLE) based on the shrunk data enjoys nearly the minimax optimal rate\nwith an exponential deviation bound. Our simulations demonstrate that the\nproposed feature shrinkage significantly enhances the statistical performance\nin linear regression and logistic regression on heavy-tailed data. Finally, we\napply our shrinkage principle to guard against mislabeling and image noise in\nthe human-written digit recognition problem. We add an $\\ell_4$-norm shrinkage\nlayer to the original neural net and reduce the testing misclassification rate\nby more than $30\\%$ relatively in the presence of mislabeling and image noise.\n", "versions": [{"version": "v1", "created": "Tue, 24 Oct 2017 23:47:07 GMT"}, {"version": "v2", "created": "Fri, 17 Jul 2020 23:18:01 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Zhu", "Ziwei", ""], ["Zhou", "Wenjing", ""]]}, {"id": "1710.09071", "submitter": "Alexey Miroshnikov", "authors": "Alexey Miroshnikov, Konstandinos Kotsiopoulos, Erin Conlon", "title": "Asymptotic properties and approximation of Bayesian logspline density\n  estimators for communication-free parallel computing methods", "comments": "33 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we perform an asymptotic analysis of Bayesian parallel\ndensity estimators which are based on logspline density estimation. The\nparallel estimator we introduce is in the spirit of a kernel density estimator\nintroduced in recent studies. We provide a numerical procedure that produces\nthe density estimator itself in place of the sampling algorithm. We then derive\nan error bound for the mean integrated squared error for the full data\nposterior density estimator. We also investigate the parameters that arise from\nlogspline density estimation and the numerical approximation procedure. Our\ninvestigation identifies specific choices of parameters for logspline density\nestimation that result in the error bound scaling appropriately in relation to\nthese choices.\n", "versions": [{"version": "v1", "created": "Wed, 25 Oct 2017 04:33:58 GMT"}, {"version": "v2", "created": "Thu, 10 May 2018 08:30:33 GMT"}], "update_date": "2018-05-11", "authors_parsed": [["Miroshnikov", "Alexey", ""], ["Kotsiopoulos", "Konstandinos", ""], ["Conlon", "Erin", ""]]}, {"id": "1710.09072", "submitter": "Vladimir Koltchinskii", "authors": "Vladimir Koltchinskii", "title": "Asymptotically Efficient Estimation of Smooth Functionals of Covariance\n  Operators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $X$ be a centered Gaussian random variable in a separable Hilbert space\n${\\mathbb H}$ with covariance operator $\\Sigma.$ We study a problem of\nestimation of a smooth functional of $\\Sigma$ based on a sample $X_1,\\dots\n,X_n$ of $n$ independent observations of $X.$ More specifically, we are\ninterested in functionals of the form $\\langle f(\\Sigma), B\\rangle,$ where\n$f:{\\mathbb R}\\mapsto {\\mathbb R}$ is a smooth function and $B$ is a nuclear\noperator in ${\\mathbb H}.$ We prove concentration and normal approximation\nbounds for plug-in estimator $\\langle f(\\hat \\Sigma),B\\rangle,$ $\\hat\n\\Sigma:=n^{-1}\\sum_{j=1}^n X_j\\otimes X_j$ being the sample covariance based on\n$X_1,\\dots, X_n.$ These bounds show that $\\langle f(\\hat \\Sigma),B\\rangle$ is\nan asymptotically normal estimator of its expectation ${\\mathbb E}_{\\Sigma}\n\\langle f(\\hat \\Sigma),B\\rangle$ (rather than of parameter of interest $\\langle\nf(\\Sigma),B\\rangle$) with a parametric convergence rate $O(n^{-1/2})$ provided\nthat the effective rank ${\\bf r}(\\Sigma):= \\frac{{\\bf tr}(\\Sigma)}{\\|\\Sigma\\|}$\n(${\\rm tr}(\\Sigma)$ being the trace and $\\|\\Sigma\\|$ being the operator norm of\n$\\Sigma$) satisfies the assumption ${\\bf r}(\\Sigma)=o(n).$ At the same time, we\nshow that the bias of this estimator is typically as large as $\\frac{{\\bf\nr}(\\Sigma)}{n}$ (which is larger than $n^{-1/2}$ if ${\\bf r}(\\Sigma)\\geq\nn^{1/2}$). In the case when ${\\mathbb H}$ is finite-dimensional space of\ndimension $d=o(n),$ we develop a method of bias reduction and construct an\nestimator $\\langle h(\\hat \\Sigma),B\\rangle$ of $\\langle f(\\Sigma),B\\rangle$\nthat is asymptotically normal with convergence rate $O(n^{-1/2}).$ Moreover, we\nstudy asymptotic properties of the risk of this estimator and prove minimax\nlower bounds for arbitrary estimators showing the asymptotic efficiency of\n$\\langle h(\\hat \\Sigma),B\\rangle$ in a semi-parametric sense.\n", "versions": [{"version": "v1", "created": "Wed, 25 Oct 2017 04:36:53 GMT"}, {"version": "v2", "created": "Fri, 15 Dec 2017 15:36:16 GMT"}, {"version": "v3", "created": "Fri, 12 Jan 2018 16:56:53 GMT"}, {"version": "v4", "created": "Sat, 2 Mar 2019 05:11:41 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Koltchinskii", "Vladimir", ""]]}, {"id": "1710.09116", "submitter": "Roberto Benedetti", "authors": "Roberto Benedetti and Federica Piersimoni", "title": "Fast Selection of Spatially Balanced Samples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sampling from very large spatial populations is challenging. The solutions\nsuggested in recent literature on this subject often require that the randomly\nselected units are well distributed across the study region by using complex\nalgorithms that have the feature, essential in a design-based framework, to\nrespect the fixed first-order inclusion probabilities for every unit of the\npopulation. The size of the frame, $N$, often causes some problems to these\nalgorithms since, being based on the distance matrix between the units of the\npopulation, have at least a computational cost of order $N^2$. In this paper we\npropose a draw-by-draw algorithm that randomly selects a sample of size $n$ in\nexactly $n$ steps, updating at each step the selection probability of\nnot-selected units depending on their distance from the units already selected\nin the previous steps. The performance of this solution is compared with those\nof other methods derived from the {\\it spatially balanced sampling} literature\nin terms of their root mean squared error (RMSE) using the simple random\nsampling (SRS) without replacement as benchmark. The fundamental interest is\nnot only to evaluate the efficiency of a such different procedure, but also to\nunderstand if similar results can be obtained even with a notable reduction in\nthe computational burden needed to obtain more efficient sampling designs.\nRepeated sample selections on real and simulated populations support this\nperspective. An application to the Land Use and Land Cover Survey (LUCAS) 2012\ndata-set in an Italian region is presented as a concrete and practical\nillustration of the capabilities of the proposed sample selection method.\n", "versions": [{"version": "v1", "created": "Wed, 25 Oct 2017 08:29:15 GMT"}], "update_date": "2017-10-26", "authors_parsed": [["Benedetti", "Roberto", ""], ["Piersimoni", "Federica", ""]]}, {"id": "1710.09146", "submitter": "John Ormerod", "authors": "John T. Ormerod, Michael Stewart, Weichang Yu, and Sarah E. Romanes", "title": "Bayesian hypothesis tests with diffuse priors: Can we have our cake and\n  eat it too?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new class of priors for Bayesian hypothesis testing, which we\nname \"cake priors\". These priors circumvent Bartlett's paradox (also called the\nJeffreys-Lindley paradox); the problem associated with the use of diffuse\npriors leading to nonsensical statistical inferences. Cake priors allow the use\nof diffuse priors (having one's cake) while achieving theoretically justified\ninferences (eating it too). We demonstrate this methodology for Bayesian\nhypotheses tests for scenarios under which the one and two sample t-tests, and\nlinear models are typically derived. The resulting Bayesian test statistic\ntakes the form of a penalized likelihood ratio test statistic. By considering\nthe sampling distribution under the null and alternative hypotheses we show for\nindependent identically distributed regular parametric models that Bayesian\nhypothesis tests using cake priors are Chernoff-consistent, i.e., achieve zero\ntype I and II errors asymptotically. Lindley's paradox is also discussed. We\nargue that a true Lindley's paradox will only occur with small probability for\nlarge sample sizes.\n", "versions": [{"version": "v1", "created": "Wed, 25 Oct 2017 10:06:15 GMT"}], "update_date": "2017-10-26", "authors_parsed": [["Ormerod", "John T.", ""], ["Stewart", "Michael", ""], ["Yu", "Weichang", ""], ["Romanes", "Sarah E.", ""]]}, {"id": "1710.09170", "submitter": "Zheng Miaomiao", "authors": "Qingfeng Liu and Miaomiao Zheng", "title": "Model Averaging for Generalized Linear Model with Covariates that are\n  Missing completely at Random", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the estimation of generalized linear models with\ncovariates that are missing completely at random. We propose a model averaging\nestimation method and prove that the corresponding model averaging estimator is\nasymptotically optimal under certain assumptions. Simulaiton results illustrate\nthat this method has better performance than other alternatives under most\nsituations.\n", "versions": [{"version": "v1", "created": "Wed, 25 Oct 2017 11:17:40 GMT"}], "update_date": "2017-10-26", "authors_parsed": [["Liu", "Qingfeng", ""], ["Zheng", "Miaomiao", ""]]}, {"id": "1710.09172", "submitter": "Van Ha Hoang", "authors": "Van Ha Hoang (1), Thanh Mai Pham Ngoc (2), Vincent Rivoirard (3), Viet\n  Chi Tran (4) ((1) HCMC, (2) LM-Orsay, (3) CEREMADE, (4) LAMA)", "title": "Nonparametric estimation of the fragmentation kernel based on a PDE\n  stationary distribution approximation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a stochastic individual-based model in continuous time to\ndescribe a size-structured population for cell divisions. This model is\nmotivated by the detection of cellular aging in biology. We address here the\nproblem of nonparametric estimation of the kernel ruling the divisions based on\nthe eigenvalue problem related to the asymptotic behavior in large population.\nThis inverse problem involves a multiplicative deconvolution operator. Using\nFourier technics we derive a nonparametric estimator whose consistency is\nstudied. The main difficulty comes from the non-standard equations connecting\nthe Fourier transforms of the kernel and the parameters of the model. A\nnumerical study is carried out and we pay special attention to the derivation\nof bandwidths by using resampling.\n", "versions": [{"version": "v1", "created": "Wed, 25 Oct 2017 11:21:39 GMT"}, {"version": "v2", "created": "Thu, 11 Apr 2019 12:56:48 GMT"}, {"version": "v3", "created": "Fri, 25 Sep 2020 15:33:52 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Hoang", "Van Ha", "", "HCMC"], ["Ngoc", "Thanh Mai Pham", "", "LM-Orsay"], ["Rivoirard", "Vincent", "", "CEREMADE"], ["Tran", "Viet Chi", "", "LAMA"]]}, {"id": "1710.09285", "submitter": "Rajeshwari Majumdar", "authors": "Rajeshwari Majumdar and Suman Majumdar", "title": "On the Conditional Distribution of a Multivariate Normal given a\n  Transformation - the Linear Case", "comments": "2/6/18: Updated the proof of Theorem 4 & added a corollary. arXiv\n  admin note: text overlap with arXiv:1612.01210", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the orthogonal projection operator onto the range of the adjoint\nof a linear operator $T$ can be represented as $UT,$ where $U$ is an invertible\nlinear operator. Using this representation we obtain a decomposition of a\nNormal random vector $Y$ as the sum of a linear transformation of $Y$ that is\nindependent of $TY$ and an affine transformation of $TY$. We then use this\ndecomposition to prove that the conditional distribution of a Normal random\nvector $Y$ given a linear transformation $\\mathcal{T}Y$ is again a multivariate\nNormal distribution. This result is equivalent to the well-known result that\ngiven a $k$-dimensional component of a $n$-dimensional Normal random vector,\nwhere $k<n$, the conditional distribution of the remaining\n$\\left(n-k\\right)$-dimensional component is a $\\left(n-k\\right)$-dimensional\nmultivariate Normal distribution, and sets the stage for approximating the\nconditional distribution of $Y$ given $g\\left(Y\\right)$, where $g$ is a\ncontinuously differentiable vector field.\n", "versions": [{"version": "v1", "created": "Tue, 24 Oct 2017 05:30:16 GMT"}, {"version": "v2", "created": "Wed, 7 Feb 2018 04:53:22 GMT"}], "update_date": "2018-02-09", "authors_parsed": [["Majumdar", "Rajeshwari", ""], ["Majumdar", "Suman", ""]]}, {"id": "1710.09308", "submitter": "Frederik Vissing Mikkelsen", "authors": "Frederik Vissing Mikkelsen and Niels Richard Hansen", "title": "Learning Large Scale Ordinary Differential Equation Systems", "comments": "55 pages, 28 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.AP stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning large scale nonlinear ordinary differential equation (ODE) systems\nfrom data is known to be computationally and statistically challenging. We\npresent a framework together with the adaptive integral matching (AIM)\nalgorithm for learning polynomial or rational ODE systems with a sparse network\nstructure. The framework allows for time course data sampled from multiple\nenvironments representing e.g. different interventions or perturbations of the\nsystem. The algorithm AIM combines an initial penalised integral matching step\nwith an adapted least squares step based on solving the ODE numerically. The R\npackage episode implements AIM together with several other algorithms and is\navailable from CRAN. It is shown that AIM achieves state-of-the-art network\nrecovery for the in silico phosphoprotein abundance data from the eighth DREAM\nchallenge with an AUROC of 0.74, and it is demonstrated via a range of\nnumerical examples that AIM has good statistical properties while being\ncomputationally feasible even for large systems.\n", "versions": [{"version": "v1", "created": "Wed, 25 Oct 2017 15:38:43 GMT"}, {"version": "v2", "created": "Thu, 26 Oct 2017 06:13:15 GMT"}], "update_date": "2017-10-27", "authors_parsed": [["Mikkelsen", "Frederik Vissing", ""], ["Hansen", "Niels Richard", ""]]}, {"id": "1710.09351", "submitter": "Michael Abbott", "authors": "Michael C. Abbott, Benjamin B. Machta", "title": "A scaling law from discrete to continuous solutions of channel capacity\n  problems in the low-noise limit", "comments": "14 pages, 5 figures. v2: Journal version with extended introduction\n  (and extended title, was \"An information scaling law: \\zeta = 3/4\")", "journal-ref": "J. Stat. Phys. (2019)", "doi": "10.1007/s10955-019-02296-2", "report-no": null, "categories": "cond-mat.stat-mech hep-th math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An analog communication channel typically achieves its full capacity when the\ndistribution of inputs is discrete, composed of just K symbols, such as voltage\nlevels or wavelengths. As the effective noise level goes to zero, for example\nby sending the same message multiple times, it is known that optimal codes\nbecome continuous. Here we derive a scaling law for the optimal number of\nsymbols in this limit, finding a novel rational scaling exponent. The number of\nsymbols in the optimal code grows as $\\log K \\sim I^{4/3}$, where the channel\ncapacity I increases with decreasing noise. The same scaling applies to other\nproblems equivalent to maximizing channel capacity over a continuous\ndistribution.\n", "versions": [{"version": "v1", "created": "Wed, 25 Oct 2017 17:19:59 GMT"}, {"version": "v2", "created": "Mon, 6 May 2019 15:49:04 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Abbott", "Michael C.", ""], ["Machta", "Benjamin B.", ""]]}, {"id": "1710.09461", "submitter": "Itay Kavaler", "authors": "Itay Kavaler and Rann Smorodinsky", "title": "On Comparison Of Experts", "comments": "Journal title: Games and Economic Behavior. Article accepted for\n  publication: 19-AUG-2019", "journal-ref": "Games and Economic Behavior., Volume 118, November 2019, Pages\n  94-109", "doi": "10.1016/j.geb.2019.08.005", "report-no": null, "categories": "stat.ME cs.GT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A policy maker faces a sequence of unknown outcomes. At each stage two\n(self-proclaimed) experts provide probabilistic forecasts on the outcome in the\nnext stage. A comparison test is a protocol for the policy maker to\n(eventually) decide which of the two experts is better informed. The protocol\ntakes as input the sequence of pairs of forecasts and actual realizations and\n(weakly) ranks the two experts. We propose two natural properties that such a\ncomparison test must adhere to and show that these essentially uniquely\ndetermine the comparison test. This test is a function of the derivative of the\ninduced pair of measures at the realization.\n", "versions": [{"version": "v1", "created": "Mon, 2 Oct 2017 17:22:38 GMT"}, {"version": "v2", "created": "Mon, 12 Nov 2018 21:51:00 GMT"}, {"version": "v3", "created": "Wed, 28 Aug 2019 10:32:46 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Kavaler", "Itay", ""], ["Smorodinsky", "Rann", ""]]}, {"id": "1710.09497", "submitter": "Tomohiro Hayase", "authors": "Tomohiro Hayase", "title": "Free deterministic equivalent Z-scores of compound Wishart models: A\n  goodness of fit test of 2DARMA models", "comments": "14 pages, 7 figures", "journal-ref": "RMTA, No.08, Issue No. 02. (2019)", "doi": null, "report-no": null, "categories": "math.ST math.OA math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new method to qualify the goodness of fit parameter estimation\nof compound Wishart models. Our method based on the free deterministic\nequivalent Z-score, which we introduce in this paper. Furthermore, an\napplication to two dimensional autoregressive moving-average model is provided.\n  Our proposal method is a generalization of statistical hypothesis testing to\none dimensional moving average model based on fluctuations of real compound\nWishart matrices, which is a recent result by Hasegawa, Sakuma and Yoshida.\n", "versions": [{"version": "v1", "created": "Wed, 25 Oct 2017 23:58:15 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Hayase", "Tomohiro", ""]]}, {"id": "1710.09587", "submitter": "Nestor Parolya Dr.", "authors": "Taras Bodnar, Solomiia Dmytriv, Nestor Parolya and Wolfgang Schmid", "title": "Tests for the weights of the global minimum variance portfolio in a\n  high-dimensional setting", "comments": "16 pages, 10 figures (final version, accepted for publication in IEEE\n  Transactions of Signal Processing)", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, we construct two tests for the weights of the global minimum\nvariance portfolio (GMVP) in a high-dimensional setting, namely, when the\nnumber of assets $p$ depends on the sample size $n$ such that $\\frac{p}{n}\\to c\n\\in (0,1)$ as $n$ tends to infinity. In the case of a singular covariance\nmatrix with rank equal to $q$ we assume that $q/n\\to \\tilde{c}\\in(0, 1)$ as\n$n\\to\\infty$. The considered tests are based on the sample estimator and on the\nshrinkage estimator of the GMVP weights. We derive the asymptotic distributions\nof the test statistics under the null and alternative hypotheses. Moreover, we\nprovide a simulation study where the power functions and the receiver operating\ncharacteristic curves of the proposed tests are compared with other existing\napproaches. We observe that the test based on the shrinkage estimator performs\nwell even for values of $c$ close to one.\n", "versions": [{"version": "v1", "created": "Thu, 26 Oct 2017 08:41:39 GMT"}, {"version": "v2", "created": "Wed, 15 Nov 2017 10:15:47 GMT"}, {"version": "v3", "created": "Mon, 1 Jul 2019 10:01:21 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Bodnar", "Taras", ""], ["Dmytriv", "Solomiia", ""], ["Parolya", "Nestor", ""], ["Schmid", "Wolfgang", ""]]}, {"id": "1710.09610", "submitter": "Chunhao Cai", "authors": "Chunhao Cai", "title": "Controlled Mean-Reverting Estimation for The AR(1) Model with Stationary\n  Gaussian Noise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with the maximum likelihood estimator for the mean-reverting\nparameter of a first order autoregressive models with exogenous variables,\nwhich are stationary Gaussian noises (Colored noise). Using the method of the\nLaplace transform, both the asymptotic properties and the asymptotic design\nproblem of the maximum likelihood estimator are investigated. The numerical\nsimulation results confirm the theoretical analysis and show that the proposed\nmaximum likelihood estimator performs well in finite sample.\n", "versions": [{"version": "v1", "created": "Thu, 26 Oct 2017 09:35:12 GMT"}, {"version": "v2", "created": "Wed, 13 Mar 2019 01:32:42 GMT"}, {"version": "v3", "created": "Tue, 31 Dec 2019 03:35:28 GMT"}, {"version": "v4", "created": "Wed, 18 Nov 2020 03:07:02 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Cai", "Chunhao", ""]]}, {"id": "1710.09700", "submitter": "V\\'ictor Pe\\~na", "authors": "Joris Mulder, James O. Berger, V\\'ictor Pe\\~na, M. J. Bayarri", "title": "On the Ubiquity of Information Inconsistency for Conjugate Priors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Informally, \"Information Inconsistency\" is the property that has been\nobserved in many Bayesian hypothesis testing and model selection procedures\nwhereby the Bayesian conclusion does not become definitive when the data seems\nto become definitive. An example is that, when performing a t-test using\nstandard conjugate priors, the Bayes factor of the alternative hypothesis to\nthe null hypothesis remains bounded as the t statistic grows to infinity. This\npaper shows that information inconsistency is ubiquitous in Bayesian hypothesis\ntesting under conjugate priors. Yet the title does not fully describe the\npaper, since we also show that theoretically recommended priors, including\nscale mixtures of conjugate priors and adaptive priors, are information\nconsistent. Hence the paper is simply a forceful warning that use of conjugate\npriors in testing and model selection is highly problematical, and should be\nreplaced by the information consistent alternatives.\n", "versions": [{"version": "v1", "created": "Thu, 26 Oct 2017 13:56:15 GMT"}], "update_date": "2017-10-27", "authors_parsed": [["Mulder", "Joris", ""], ["Berger", "James O.", ""], ["Pe\u00f1a", "V\u00edctor", ""], ["Bayarri", "M. J.", ""]]}, {"id": "1710.09735", "submitter": "Anne Philippe", "authors": "Remigijus Leipus, Anne Philippe (LMJL, UN), Vytaute Pilipauskaite,\n  Donatas Surgailis", "title": "Estimating long memory in panel random-coefficient AR(1) data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well-known that random-coefficient AR(1) process can have long memory\ndepending on the index $\\beta$ of the tail distribution function of the random\ncoefficient, if it is a regularly varying function at unity. We discuss\nestimation of $\\beta$ from panel data comprising N random-coefficient AR(1)\nseries, each of length T. The estimator of $\\beta$ is constructed as a version\nof the tail index estimator of Goldie and Smith (1987) applied to sample lag 1\nautocorrelations of individual time series. Its asymptotic normality is derived\nunder certain conditions on N, T and some parameters of our statistical model.\nBased on this result, we construct a statistical procedure to test if the panel\nrandom-coefficient AR(1) data exhibit long memory. A simulation study\nillustrates finite-sample performance of the introduced estimator and testing\nprocedure.\n", "versions": [{"version": "v1", "created": "Thu, 26 Oct 2017 14:46:49 GMT"}, {"version": "v2", "created": "Tue, 30 Oct 2018 07:53:17 GMT"}, {"version": "v3", "created": "Fri, 20 Sep 2019 08:17:26 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Leipus", "Remigijus", "", "LMJL, UN"], ["Philippe", "Anne", "", "LMJL, UN"], ["Pilipauskaite", "Vytaute", ""], ["Surgailis", "Donatas", ""]]}, {"id": "1710.09763", "submitter": "Thierry Klein", "authors": "Philippe Berthet and Jean-Claude Fort and Thierry Klein", "title": "A Central Limit Theorem for Wasserstein type distances between two\n  different laws", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article is dedicated to the estimation of Wasserstein distances and\nWasserstein costs between two distinct continuous distributions $F$ and $G$ on\n$\\mathbb R$. The estimator is based on the order statistics of (possibly\ndependent) samples of $F$ resp. $G$. We prove the consistency and the\nasymptotic normality of our estimators. \\begin{it}Keywords:\\end{it} Central\nLimit Theorems- Generelized Wasserstein distances- Empirical processes- Strong\napproximation- Dependent samples.\n", "versions": [{"version": "v1", "created": "Thu, 26 Oct 2017 15:39:51 GMT"}, {"version": "v2", "created": "Fri, 27 Oct 2017 20:15:53 GMT"}], "update_date": "2017-10-31", "authors_parsed": [["Berthet", "Philippe", ""], ["Fort", "Jean-Claude", ""], ["Klein", "Thierry", ""]]}, {"id": "1710.09859", "submitter": "Guilherme Fran\\c{c}a", "authors": "Guilherme Fran\\c{c}a, Maria L. Rizzo, Joshua T. Vogelstein", "title": "Kernel k-Groups via Hartigan's Method", "comments": "several improvements; connections with community detection and\n  stochastic block model. Matches published version", "journal-ref": "IEEE Transactions on Pattern Analysis and Machine Intelligence,\n  2020", "doi": "10.1109/TPAMI.2020.2998120", "report-no": null, "categories": "stat.ML cs.CV cs.DS cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Energy statistics was proposed by Sz\\' ekely in the 80's inspired by Newton's\ngravitational potential in classical mechanics and it provides a model-free\nhypothesis test for equality of distributions. In its original form, energy\nstatistics was formulated in Euclidean spaces. More recently, it was\ngeneralized to metric spaces of negative type. In this paper, we consider a\nformulation for the clustering problem using a weighted version of energy\nstatistics in spaces of negative type. We show that this approach leads to a\nquadratically constrained quadratic program in the associated kernel space,\nestablishing connections with graph partitioning problems and kernel methods in\nmachine learning. To find local solutions of such an optimization problem, we\npropose kernel k-groups, which is an extension of Hartigan's method to kernel\nspaces. Kernel k-groups is cheaper than spectral clustering and has the same\ncomputational cost as kernel k-means (which is based on Lloyd's heuristic) but\nour numerical results show an improved performance, especially in higher\ndimensions. Moreover, we verify the efficiency of kernel k-groups in community\ndetection in sparse stochastic block models which has fascinating applications\nin several areas of science.\n", "versions": [{"version": "v1", "created": "Thu, 26 Oct 2017 18:38:28 GMT"}, {"version": "v2", "created": "Tue, 14 Aug 2018 14:02:55 GMT"}, {"version": "v3", "created": "Mon, 9 Dec 2019 15:29:58 GMT"}, {"version": "v4", "created": "Thu, 11 Jun 2020 19:57:09 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Fran\u00e7a", "Guilherme", ""], ["Rizzo", "Maria L.", ""], ["Vogelstein", "Joshua T.", ""]]}, {"id": "1710.10042", "submitter": "Marjan Cugmas", "authors": "Marjan Cugmas and Anu\\v{s}ka Ferligoj and Ale\\v{s} \\v{Z}iberna", "title": "Generating global network structures by triad types", "comments": null, "journal-ref": null, "doi": "10.1371/journal.pone.0197514", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the question of whether it is possible to generate\nnetworks with a given global structure (defined by selected blockmodels, i.e.,\ncohesive, core-periphery, hierarchical and transitivity), considering only\ndifferent types of triads. Two methods are used to generate networks: (i) the\nmethod of relocating links; and (ii) the Monte Carlo Multi Chain algorithm\nimplemented in the \"ergm\" package implemented in R. Although all types of\ntriads can generate networks with the selected blockmodel types, the selection\nof only a subset of triads improves the generated networks' blockmodel\nstructure. However, in the case of a hierarchical blockmodel without complete\nblocks on the diagonal, additional local structures are needed to achieve the\ndesired global structure of generated networks. This shows that blockmodels can\nemerge based on only local processes that do not take attributes into account.\n", "versions": [{"version": "v1", "created": "Fri, 27 Oct 2017 09:33:35 GMT"}], "update_date": "2018-07-04", "authors_parsed": [["Cugmas", "Marjan", ""], ["Ferligoj", "Anu\u0161ka", ""], ["\u017diberna", "Ale\u0161", ""]]}, {"id": "1710.10099", "submitter": "Dominik Liebl", "authors": "Alois Kneip and Dominik Liebl", "title": "On the Optimal Reconstruction of Partially Observed Functional Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new reconstruction operator that aims to recover the missing\nparts of a function given the observed parts. This new operator belongs to a\nnew, very large class of functional operators which includes the classical\nregression operators as a special case. We show the optimality of our\nreconstruction operator and demonstrate that the usually considered regression\noperators generally cannot be optimal reconstruction operators. Our estimation\ntheory allows for autocorrelated functional data and considers the practically\nrelevant situation in which each of the $n$ functions is observed at $m_i$,\n$i=1,\\dots,n$, discretization points. We derive rates of consistency for our\nnonparametric estimation procedures using a double asymptotic. For data\nsituations, as in our real data application where $m_i$ is considerably smaller\nthan $n$, we show that our functional principal components based estimator can\nprovide better rates of convergence than conventional nonparametric smoothing\nmethods.\n", "versions": [{"version": "v1", "created": "Fri, 27 Oct 2017 12:07:59 GMT"}, {"version": "v2", "created": "Thu, 13 Sep 2018 15:40:06 GMT"}, {"version": "v3", "created": "Fri, 1 Feb 2019 23:33:11 GMT"}, {"version": "v4", "created": "Fri, 10 May 2019 20:45:52 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Kneip", "Alois", ""], ["Liebl", "Dominik", ""]]}, {"id": "1710.10124", "submitter": "J\\\"uri Lember", "authors": "Raphael Hauser, Raul Kangro, J\\\"uri Lember, Heinrich Matzinger", "title": "Quantifying the Estimation Error of Principal Components", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Principal component analysis is an important pattern recognition and\ndimensionality reduction tool in many applications. Principal components are\ncomputed as eigenvectors of a maximum likelihood covariance $\\widehat{\\Sigma}$\nthat approximates a population covariance $\\Sigma$, and these eigenvectors are\noften used to extract structural information about the variables (or\nattributes) of the studied population. Since PCA is based on the\neigendecomposition of the proxy covariance $\\widehat{\\Sigma}$ rather than the\nground-truth $\\Sigma$, it is important to understand the approximation error in\neach individual eigenvector as a function of the number of available samples.\nThe recent results of Kolchinskii and Lounici yield such bounds. In the present\npaper we sharpen these bounds and show that eigenvectors can often be\nreconstructed to a required accuracy from a sample of strictly smaller size\norder.\n", "versions": [{"version": "v1", "created": "Fri, 27 Oct 2017 13:31:57 GMT"}], "update_date": "2017-10-30", "authors_parsed": [["Hauser", "Raphael", ""], ["Kangro", "Raul", ""], ["Lember", "J\u00fcri", ""], ["Matzinger", "Heinrich", ""]]}, {"id": "1710.10251", "submitter": "Mohsen Bayati", "authors": "Susan Athey, Mohsen Bayati, Nikolay Doudchenko, Guido Imbens,\n  Khashayar Khosravi", "title": "Matrix Completion Methods for Causal Panel Data Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST econ.EM stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study methods for estimating causal effects in settings with\npanel data, where some units are exposed to a treatment during some periods and\nthe goal is estimating counterfactual (untreated) outcomes for the treated\nunit/period combinations. We propose a class of matrix completion estimators\nthat uses the observed elements of the matrix of control outcomes corresponding\nto untreated unit/periods to impute the \"missing\" elements of the control\noutcome matrix, corresponding to treated units/periods. This leads to a matrix\nthat well-approximates the original (incomplete) matrix, but has lower\ncomplexity according to the nuclear norm for matrices. We generalize results\nfrom the matrix completion literature by allowing the patterns of missing data\nto have a time series dependency structure that is common in social science\napplications. We present novel insights concerning the connections between the\nmatrix completion literature, the literature on interactive fixed effects\nmodels and the literatures on program evaluation under unconfoundedness and\nsynthetic control methods. We show that all these estimators can be viewed as\nfocusing on the same objective function. They differ solely in the way they\ndeal with identification, in some cases solely through regularization (our\nproposed nuclear norm matrix completion estimator) and in other cases primarily\nthrough imposing hard restrictions (the unconfoundedness and synthetic control\napproaches). The proposed method outperforms unconfoundedness-based or\nsynthetic control estimators in simulations based on real data.\n", "versions": [{"version": "v1", "created": "Fri, 27 Oct 2017 17:34:11 GMT"}, {"version": "v2", "created": "Sat, 29 Sep 2018 06:43:20 GMT"}, {"version": "v3", "created": "Tue, 23 Jun 2020 17:42:12 GMT"}, {"version": "v4", "created": "Tue, 23 Feb 2021 17:41:28 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Athey", "Susan", ""], ["Bayati", "Mohsen", ""], ["Doudchenko", "Nikolay", ""], ["Imbens", "Guido", ""], ["Khosravi", "Khashayar", ""]]}, {"id": "1710.10366", "submitter": "Aditya Gangrade", "authors": "Aditya Gangrade, Bobak Nazer and Venkatesh Saligrama", "title": "Lower Bounds for Two-Sample Structural Change Detection in Ising and\n  Gaussian Models", "comments": "Presented at the 55th Annual Allerton Conference on Communication,\n  Control, and Computing, Oct. 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The change detection problem is to determine if the Markov network structures\nof two Markov random fields differ from one another given two sets of samples\ndrawn from the respective underlying distributions. We study the trade-off\nbetween the sample sizes and the reliability of change detection, measured as a\nminimax risk, for the important cases of the Ising models and the Gaussian\nMarkov random fields restricted to the models which have network structures\nwith $p$ nodes and degree at most $d$, and obtain information-theoretic lower\nbounds for reliable change detection over these models. We show that for the\nIsing model, $\\Omega\\left(\\frac{d^2}{(\\log d)^2}\\log p\\right)$ samples are\nrequired from each dataset to detect even the sparsest possible changes, and\nthat for the Gaussian, $\\Omega\\left( \\gamma^{-2} \\log(p)\\right)$ samples are\nrequired from each dataset to detect change, where $\\gamma$ is the smallest\nratio of off-diagonal to diagonal terms in the precision matrices of the\ndistributions. These bounds are compared to the corresponding results in\nstructure learning, and closely match them under mild conditions on the model\nparameters. Thus, our change detection bounds inherit partial tightness from\nthe structure learning schemes in previous literature, demonstrating that in\ncertain parameter regimes, the naive structure learning based approach to\nchange detection is minimax optimal up to constant factors.\n", "versions": [{"version": "v1", "created": "Sat, 28 Oct 2017 01:13:24 GMT"}], "update_date": "2017-10-31", "authors_parsed": [["Gangrade", "Aditya", ""], ["Nazer", "Bobak", ""], ["Saligrama", "Venkatesh", ""]]}, {"id": "1710.10388", "submitter": "Cheng Mao", "authors": "Cheng Mao, Jonathan Weed and Philippe Rigollet", "title": "Minimax Rates and Efficient Algorithms for Noisy Sorting", "comments": "27 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been a recent surge of interest in studying permutation-based\nmodels for ranking from pairwise comparison data. Despite being structurally\nricher and more robust than parametric ranking models, permutation-based models\nare less well understood statistically and generally lack efficient learning\nalgorithms. In this work, we study a prototype of permutation-based ranking\nmodels, namely, the noisy sorting model. We establish the optimal rates of\nlearning the model under two sampling procedures. Furthermore, we provide a\nfast algorithm to achieve near-optimal rates if the observations are sampled\nindependently. Along the way, we discover properties of the symmetric group\nwhich are of theoretical interest.\n", "versions": [{"version": "v1", "created": "Sat, 28 Oct 2017 04:45:51 GMT"}], "update_date": "2017-10-31", "authors_parsed": [["Mao", "Cheng", ""], ["Weed", "Jonathan", ""], ["Rigollet", "Philippe", ""]]}, {"id": "1710.10416", "submitter": "Kou Fujimori", "authors": "Kou Fujimori", "title": "Cox's proportional hazards model with a high-dimensional and sparse\n  regression parameter", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with the proportional hazards model proposed by D. R. Cox in\na high-dimensional and sparse setting for a regression parameter. To estimate\nthe regression parameter, the Dantzig selector is applied. The variable\nselection consistency of the Dantzig selector for the model will be proved.\nThis property enables us to reduce the dimension of the parameter and to\nconstruct asymptotically normal estimators for the regression parameter and the\ncumulative baseline hazard function.\n", "versions": [{"version": "v1", "created": "Sat, 28 Oct 2017 08:18:10 GMT"}], "update_date": "2017-10-31", "authors_parsed": [["Fujimori", "Kou", ""]]}, {"id": "1710.10457", "submitter": "Wenzheng Li", "authors": "Shichuan Deng, Wenzheng Li, Xuan Wu", "title": "Wasserstein Identity Testing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uniformity testing and the more general identity testing are well studied\nproblems in distributional property testing. Most previous work focuses on\ntesting under $L_1$-distance. However, when the support is very large or even\ncontinuous, testing under $L_1$-distance may require a huge (even infinite)\nnumber of samples. Motivated by such issues, we consider the identity testing\nin Wasserstein distance (a.k.a. transportation distance and earthmover\ndistance) on a metric space (discrete or continuous).\n  In this paper, we propose the Wasserstein identity testing problem (Identity\nTesting in Wasserstein distance). We obtain nearly optimal worst-case sample\ncomplexity for the problem. Moreover, for a large class of probability\ndistributions satisfying the so-called \"Doubling Condition\", we provide nearly\ninstance-optimal sample complexity.\n", "versions": [{"version": "v1", "created": "Sat, 28 Oct 2017 12:39:40 GMT"}], "update_date": "2017-10-31", "authors_parsed": [["Deng", "Shichuan", ""], ["Li", "Wenzheng", ""], ["Wu", "Xuan", ""]]}, {"id": "1710.10526", "submitter": "Holger Dette", "authors": "Holger Dette, Maria Konstantinou, Kirsten Schorning, Josua G\\\"osmann", "title": "Optimal designs for regression with spherical data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper optimal designs for regression problems with spherical\npredictors of arbitrary dimension are considered. Our work is motivated by\napplications in material sciences, where crystallographic textures such as the\nmissorientation distribution or the grain boundary distribution (depending on a\nfour dimensional spherical predictor) are represented by series of\nhyperspherical harmonics, which are estimated from experimental or simulated\ndata. For this type of estimation problems we explicitly determine optimal\ndesigns with respect to Kiefers $\\Phi_p$-criteria and a class of orthogonally\ninvariant information criteria recently introduced in the literature. In\nparticular, we show that the uniform distribution on the $m$-dimensional sphere\nis optimal and construct discrete and implementable designs with the same\ninformation matrices as the continuous optimal designs. Finally, we illustrate\nthe advantages of the new designs for series estimation by hyperspherical\nharmonics, which are symmetric with respect to the first and second\ncrystallographic point group.\n", "versions": [{"version": "v1", "created": "Sat, 28 Oct 2017 20:13:20 GMT"}], "update_date": "2017-10-31", "authors_parsed": [["Dette", "Holger", ""], ["Konstantinou", "Maria", ""], ["Schorning", "Kirsten", ""], ["G\u00f6smann", "Josua", ""]]}, {"id": "1710.10653", "submitter": "Serguei Pergamenshchikov", "authors": "Vlad Stefan Barbu, Slim Beltaief and Serguei Pergamenshchikov", "title": "Robust adaptive efficient estimation for a semi-Markov continuous time\n  regression from discrete data", "comments": "arXiv admin note: text overlap with arXiv:1604.04516", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we consider the nonparametric robust estimation problem for\nregression models in continuous time with semi-Markov noises observed in\ndiscrete time moments. An adaptive model selection procedure is proposed. A\nsharp non-asymptotic oracle inequality for the robust risks is obtained. We\nobtain sufficient conditions on the frequency observations under which the\nrobust efficiency is shown. It turns out that for the semi-Markov models the\nrobust minimax convergence rate may be faster or slower than the classical one.\n", "versions": [{"version": "v1", "created": "Sun, 29 Oct 2017 17:37:23 GMT"}, {"version": "v2", "created": "Thu, 14 May 2020 08:18:27 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Barbu", "Vlad Stefan", ""], ["Beltaief", "Slim", ""], ["Pergamenshchikov", "Serguei", ""]]}, {"id": "1710.10690", "submitter": "Saman Hosseini", "authors": "S. D. Gore, S. Hosseini, P. Nasiri", "title": "Maximum Likelihood Estimations Based on Upper Record Values for\n  Probability Density Function and Cumulative Distribution Function in\n  Exponential Family and Investigating Some of Their Properties", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper a useful subfamily of the exponential family has been\nconsidered. The ML estimation based on upper record values has been calculated\nfor the parameter, Cumulative Density Function, and Probability Density\nFunction of the family. Also, the relations between MLE based on record values\nand a random sample has been discussed. Additionally, some properties of these\nestimators have been investigated. Finally, it has been proven that these\nestimators have some useful properties for samples with large size\n", "versions": [{"version": "v1", "created": "Sun, 29 Oct 2017 20:54:33 GMT"}, {"version": "v2", "created": "Thu, 2 Nov 2017 18:35:17 GMT"}], "update_date": "2017-11-06", "authors_parsed": [["Gore", "S. D.", ""], ["Hosseini", "S.", ""], ["Nasiri", "P.", ""]]}, {"id": "1710.10709", "submitter": "Debraj Das", "authors": "Debraj Das and S. N. Lahiri", "title": "Distributional Consistency of Lasso by Perturbation Bootstrap", "comments": "17 pages, 5 tables, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Least Absolute Shrinkage and Selection Operator or the Lasso, introduced by\nTibshirani (1996), is a popular estimation procedure in multiple linear\nregression when underlying design has a sparse structure, because of its\nproperty that it sets some regression coefficients exactly equal to 0. In this\narticle, we develop a perturbation bootstrap method and establish its validity\nin approximating the distribution of the Lasso in heteroscedastic linear\nregression. We allow the underlying covariates to be either random or\nnon-random. We show that the proposed bootstrap method works irrespective of\nthe nature of the covariates, unlike the resample-based bootstrap of Freedman\n(1981) which must be tailored based on the nature (random vs non-random) of the\ncovariates. Simulation study also justifies our method in finite samples.\n", "versions": [{"version": "v1", "created": "Sun, 29 Oct 2017 22:36:48 GMT"}], "update_date": "2017-10-31", "authors_parsed": [["Das", "Debraj", ""], ["Lahiri", "S. N.", ""]]}, {"id": "1710.10821", "submitter": "Juozas Vaicenavicius", "authors": "Erik Ekstr\\\"om and Juozas Vaicenavicius", "title": "Monotonicity and robustness in Wiener disorder detection", "comments": "14 pages, improvements in presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of detecting a drift change of a Brownian motion under\nvarious extensions of the classical case. Specifically, we consider the case of\na random post-change drift and examine monotonicity properties of the solution\nwith respect to different model parameters. Moreover, robustness properties --\neffects of misspecification of the underlying model -- are explored.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 09:35:02 GMT"}, {"version": "v2", "created": "Wed, 16 Jan 2019 17:09:48 GMT"}], "update_date": "2019-01-17", "authors_parsed": [["Ekstr\u00f6m", "Erik", ""], ["Vaicenavicius", "Juozas", ""]]}, {"id": "1710.10870", "submitter": "Mathias Trabs", "authors": "Denis Belomestny, Mathias Trabs and Alexandre B. Tsybakov", "title": "Sparse covariance matrix estimation in high-dimensional deconvolution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the estimation of the covariance matrix $\\Sigma$ of a\n$p$-dimensional normal random vector based on $n$ independent observations\ncorrupted by additive noise. Only a general nonparametric assumption is imposed\non the distribution of the noise without any sparsity constraint on its\ncovariance matrix. In this high-dimensional semiparametric deconvolution\nproblem, we propose spectral thresholding estimators that are adaptive to the\nsparsity of $\\Sigma$. We establish an oracle inequality for these estimators\nunder model miss-specification and derive non-asymptotic minimax convergence\nrates that are shown to be logarithmic in $n/\\log p$. We also discuss the\nestimation of low-rank matrices based on indirect observations as well as the\ngeneralization to elliptical distributions. The finite sample performance of\nthe threshold estimators is illustrated in a numerical example.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 11:14:25 GMT"}, {"version": "v2", "created": "Mon, 26 Mar 2018 08:39:49 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Belomestny", "Denis", ""], ["Trabs", "Mathias", ""], ["Tsybakov", "Alexandre B.", ""]]}, {"id": "1710.10885", "submitter": "Boris Brodsky E.", "authors": "Boris Brodsky, Boris Darkhovsky", "title": "Models with varying structure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper the problems of the retrospective analysis of models with\ntime-varying structure are considered. These models include contamination\nmodels with randomly switching parameters and multivariate classification\nmodels with an arbitrary number of classes. Our main task here is to classify\nobservations with different stochastic generation mechanisms. A new\nclassification method is proposed. We analyze its properties both theoretically\nand empirically. The asymptotic optimality of the propodsed method (by the\norder of convergence to zero of the estimation error) is also established. At\nthe end of the paper we consider multivariate change-in-mean models and\nmultivariate regression models.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 11:52:05 GMT"}], "update_date": "2017-10-31", "authors_parsed": [["Brodsky", "Boris", ""], ["Darkhovsky", "Boris", ""]]}, {"id": "1710.10921", "submitter": "Marianna Pensky", "authors": "Felix Abramovich, Daniela De Canditiis and Marianna Pensky", "title": "Solution of linear ill-posed problems by model selection and aggregation", "comments": "20 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a general statistical linear inverse problem, where the solution\nis represented via a known (possibly overcomplete) dictionary that allows its\nsparse representation. We propose two different approaches. A model selection\nestimator selects a single model by minimizing the penalized empirical risk\nover all possible models. By contrast with direct problems, the penalty depends\non the model itself rather than on its size only as for complexity penalties. A\nQ-aggregate estimator averages over the entire collection of estimators with\nproperly chosen weights. Under mild conditions on the dictionary, we establish\noracle inequalities both with high probability and in expectation for the two\nestimators. Moreover, for the latter estimator these inequalities are sharp.\nThe proposed procedures are implemented numerically and their performance is\nassessed by a simulation study.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 13:08:28 GMT"}], "update_date": "2017-10-31", "authors_parsed": [["Abramovich", "Felix", ""], ["De Canditiis", "Daniela", ""], ["Pensky", "Marianna", ""]]}, {"id": "1710.11268", "submitter": "Ye Zhang", "authors": "Anderson Y. Zhang and Harrison H. Zhou", "title": "Theoretical and Computational Guarantees of Mean Field Variational\n  Inference for Community Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.SI stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The mean field variational Bayes method is becoming increasingly popular in\nstatistics and machine learning. Its iterative Coordinate Ascent Variational\nInference algorithm has been widely applied to large scale Bayesian inference.\nSee Blei et al. (2017) for a recent comprehensive review. Despite the\npopularity of the mean field method there exist remarkably little fundamental\ntheoretical justifications. To the best of our knowledge, the iterative\nalgorithm has never been investigated for any high dimensional and complex\nmodel. In this paper, we study the mean field method for community detection\nunder the Stochastic Block Model. For an iterative Batch Coordinate Ascent\nVariational Inference algorithm, we show that it has a linear convergence rate\nand converges to the minimax rate within $\\log n$ iterations. This complements\nthe results of Bickel et al. (2013) which studied the global minimum of the\nmean field variational Bayes and obtained asymptotic normal estimation of\nglobal model parameters. In addition, we obtain similar optimality results for\nGibbs sampling and an iterative procedure to calculate maximum likelihood\nestimation, which can be of independent interest.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 23:29:52 GMT"}, {"version": "v2", "created": "Fri, 17 Nov 2017 03:18:08 GMT"}, {"version": "v3", "created": "Mon, 11 Dec 2017 18:14:32 GMT"}], "update_date": "2017-12-12", "authors_parsed": [["Zhang", "Anderson Y.", ""], ["Zhou", "Harrison H.", ""]]}, {"id": "1710.11278", "submitter": "Boris Hanin", "authors": "Boris Hanin, Mark Sellke", "title": "Approximating Continuous Functions by ReLU Nets of Minimal Width", "comments": "v2. 13p. Extended main result to higher dimensional output. Comments\n  welcome", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CC cs.LG math.CO math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article concerns the expressive power of depth in deep feed-forward\nneural nets with ReLU activations. Specifically, we answer the following\nquestion: for a fixed $d_{in}\\geq 1,$ what is the minimal width $w$ so that\nneural nets with ReLU activations, input dimension $d_{in}$, hidden layer\nwidths at most $w,$ and arbitrary depth can approximate any continuous,\nreal-valued function of $d_{in}$ variables arbitrarily well? It turns out that\nthis minimal width is exactly equal to $d_{in}+1.$ That is, if all the hidden\nlayer widths are bounded by $d_{in}$, then even in the infinite depth limit,\nReLU nets can only express a very limited class of functions, and, on the other\nhand, any continuous function on the $d_{in}$-dimensional unit cube can be\napproximated to arbitrary precision by ReLU nets in which all hidden layers\nhave width exactly $d_{in}+1.$ Our construction in fact shows that any\ncontinuous function $f:[0,1]^{d_{in}}\\to\\mathbb R^{d_{out}}$ can be\napproximated by a net of width $d_{in}+d_{out}$. We obtain quantitative depth\nestimates for such an approximation in terms of the modulus of continuity of\n$f$.\n", "versions": [{"version": "v1", "created": "Tue, 31 Oct 2017 00:26:56 GMT"}, {"version": "v2", "created": "Sat, 10 Mar 2018 21:47:40 GMT"}], "update_date": "2018-03-13", "authors_parsed": [["Hanin", "Boris", ""], ["Sellke", "Mark", ""]]}, {"id": "1710.11286", "submitter": "Ezequiel Smucler", "authors": "Ezequiel Smucler", "title": "Consistency of Generalized Dynamic Principal Components in Dynamic\n  Factor Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the theoretical properties of the generalized dynamic principal\ncomponents introduced in Pe\\~na and Yohai (2016). In particular, we prove that\nwhen the data follows a dynamic factor model, the reconstruction provided by\nthe procedure converges in mean square to the common part of the model as the\nnumber of series and periods diverge to infinity. The results of a simulation\nstudy support our findings.\n", "versions": [{"version": "v1", "created": "Tue, 31 Oct 2017 01:24:08 GMT"}], "update_date": "2017-11-01", "authors_parsed": [["Smucler", "Ezequiel", ""]]}, {"id": "1710.11504", "submitter": "Sami Umut Can", "authors": "Sami Umut Can, John H.J. Einmahl, Roger J.A. Laeven", "title": "Goodness-of-Fit Testing for Copulas: A Distribution-Free Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a random sample from a continuous multivariate distribution function\n$F$ with copula $C$. In order to test the null hypothesis that $C$ belongs to a\ncertain parametric family, we construct an empirical process on the unit\nhypercube that converges weakly to a standard Wiener process under the null\nhypothesis. This process can therefore serve as a `tests generator' for\nasymptotically distribution-free goodness-of-fit testing of copula families. We\nalso prove maximal sensitivity of this process to contiguous alternatives.\nFinally, we demonstrate through a Monte Carlo simulation study that our\napproach has excellent finite-sample performance, and we illustrate its\napplicability with a data analysis.\n", "versions": [{"version": "v1", "created": "Tue, 31 Oct 2017 14:26:13 GMT"}, {"version": "v2", "created": "Wed, 19 Dec 2018 12:35:56 GMT"}], "update_date": "2018-12-20", "authors_parsed": [["Can", "Sami Umut", ""], ["Einmahl", "John H. J.", ""], ["Laeven", "Roger J. A.", ""]]}, {"id": "1710.11592", "submitter": "Aravindan Vijayaraghavan", "authors": "Oded Regev and Aravindan Vijayaraghavan", "title": "On Learning Mixtures of Well-Separated Gaussians", "comments": "Appeared in FOCS 2017. 55 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of efficiently learning mixtures of a large number of\nspherical Gaussians, when the components of the mixture are well separated. In\nthe most basic form of this problem, we are given samples from a uniform\nmixture of $k$ standard spherical Gaussians, and the goal is to estimate the\nmeans up to accuracy $\\delta$ using $poly(k,d, 1/\\delta)$ samples.\n  In this work, we study the following question: what is the minimum separation\nneeded between the means for solving this task? The best known algorithm due to\nVempala and Wang [JCSS 2004] requires a separation of roughly\n$\\min\\{k,d\\}^{1/4}$. On the other hand, Moitra and Valiant [FOCS 2010] showed\nthat with separation $o(1)$, exponentially many samples are required. We\naddress the significant gap between these two bounds, by showing the following\nresults.\n  1. We show that with separation $o(\\sqrt{\\log k})$, super-polynomially many\nsamples are required. In fact, this holds even when the $k$ means of the\nGaussians are picked at random in $d=O(\\log k)$ dimensions.\n  2. We show that with separation $\\Omega(\\sqrt{\\log k})$, $poly(k,d,1/\\delta)$\nsamples suffice. Note that the bound on the separation is independent of\n$\\delta$. This result is based on a new and efficient \"accuracy boosting\"\nalgorithm that takes as input coarse estimates of the true means and in time\n$poly(k,d, 1/\\delta)$ outputs estimates of the means up to arbitrary accuracy\n$\\delta$ assuming the separation between the means is $\\Omega(\\min\\{\\sqrt{\\log\nk},\\sqrt{d}\\})$ (independently of $\\delta$).\n  We also present a computationally efficient algorithm in $d=O(1)$ dimensions\nwith only $\\Omega(\\sqrt{d})$ separation. These results together essentially\ncharacterize the optimal order of separation between components that is needed\nto learn a mixture of $k$ spherical Gaussians with polynomial samples.\n", "versions": [{"version": "v1", "created": "Tue, 31 Oct 2017 17:10:21 GMT"}], "update_date": "2017-11-01", "authors_parsed": [["Regev", "Oded", ""], ["Vijayaraghavan", "Aravindan", ""]]}]