[{"id": "1510.00137", "submitter": "Myriam Tami", "authors": "Xavier Bry (UM), Christian Lavergne, Myriam Tami (UM)", "title": "EM estimation of a Structural Equation Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose a new estimation method of a Structural Equation\nModel. Our method is based on the EM likelihood-maximization algorithm. We show\nthat this method provides estimators, not only of the coefficients of the\nmodel, but also of its latent factors. Through a simulation study, we\ninvestigate how fast and accurate the method is, and then apply it to real\nenvironmental data.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2015 08:33:47 GMT"}], "update_date": "2015-10-02", "authors_parsed": [["Bry", "Xavier", "", "UM"], ["Lavergne", "Christian", "", "UM"], ["Tami", "Myriam", "", "UM"]]}, {"id": "1510.00179", "submitter": "Maria Padilla", "authors": "J. Castillo and M. Padilla", "title": "Modeling extreme values by the residual coefficient of variation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The possibilities of the use of the coefficient of variation over a high\nthreshold in tail modelling are discussed. The paper also considers multiple\nthreshold tests for a generalized Pareto distribution, together with a\nthreshold selection algorithm. One of the main contributions is to extend the\nmethodology based on moments to all distributions, even without finite moments.\nThese techniques are applied to Danish fire insurance losses.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2015 10:59:00 GMT"}], "update_date": "2015-10-02", "authors_parsed": [["Castillo", "J.", ""], ["Padilla", "M.", ""]]}, {"id": "1510.00290", "submitter": "Sidney Resnick", "authors": "Tiandong Wang and Sidney I. Resnick", "title": "Asymptotic Normality of In- and Out-Degree Counts in a Preferential\n  Attachment Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Preferential attachment in a directed scale-free graph is widely used to\nmodel the evolution of social networks. Statistical analyses of social networks\noften relies on node based data rather than conventional repeated sampling. For\nour directed edge model with preferential attachment, we prove asymptotic\nnormality of node counts based on a martingale construction and a martingale\ncentral limit theorem. This helps justify estimation methods based on the\nstatistics of node counts which have specified in-degree and out-degree.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2015 15:51:51 GMT"}], "update_date": "2015-10-02", "authors_parsed": [["Wang", "Tiandong", ""], ["Resnick", "Sidney I.", ""]]}, {"id": "1510.00486", "submitter": "Samuel Gross", "authors": "Samuel M. Gross, Jonathan Taylor, Robert Tibshirani", "title": "A Selective Approach to Internal Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common goal in modern biostatistics is to form a biomarker signature from\nhigh dimensional gene expression data that is predictive of some outcome of\ninterest. After learning this biomarker signature, an important question to\nanswer is how well it predicts the response compared to classical predictors.\nThis is challenging, because the biomarker signature is an internal predictor\n-- one that has been learned using the same dataset on which we want to\nevaluate it's significance. We propose a new method for approaching this\nproblem based on the technique of selective inference. Simulations show that\nour method is able to properly control the level of the test, and that in\ncertain settings we have more power than sample splitting.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2015 04:24:49 GMT"}], "update_date": "2015-10-05", "authors_parsed": [["Gross", "Samuel M.", ""], ["Taylor", "Jonathan", ""], ["Tibshirani", "Robert", ""]]}, {"id": "1510.00547", "submitter": "Ritabrata Dutta", "authors": "Ritabrata Dutta and Malgortaza Bogdan and Jayanta K. Ghosh", "title": "Model Selection and Multiple Testing - A Bayesian and Empirical Bayes\n  Overview and some New Results", "comments": "29 pages", "journal-ref": "Journal of Indian Statistical Association, 50, pp. 105-142, 2012", "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a brief overview of both Bayes and classical model selection. We\nargue tentatively that model selection has at least two major goals, that of\nfinding the correct model or predicting well, and that in general both these\ngoals may not be achieved in an optimum manner by a single model selection\nrule. We discuss, briefly but critically, through a study of well-known model\nselection rules like AIC, BIC, DIC and Lasso, how these different goals are\npursued in each paradigm. We introduce some new definitions of consistency,\nresults and conjectures about consistency in high dimensional model selection\nproblems. Finally we discuss some new or recent results in Full Bayes and\nEmpirical Bayes multiple testing, and cross-validation. We show that when the\nnumber of parameters tends to infinity at a smaller rate than sample size, then\nit is best from the point of view of consistency to use most of the data for\ninference and only a negligible proportion to make an improper prior proper.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2015 10:07:29 GMT"}], "update_date": "2015-10-05", "authors_parsed": [["Dutta", "Ritabrata", ""], ["Bogdan", "Malgortaza", ""], ["Ghosh", "Jayanta K.", ""]]}, {"id": "1510.00967", "submitter": "Thibaut Horel", "authors": "Panos Toulis, Thibaut Horel, Edoardo M. Airoldi", "title": "The Proximal Robbins-Monro Method", "comments": "35 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.CO stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The need for parameter estimation with massive datasets has reinvigorated\ninterest in stochastic optimization and iterative estimation procedures.\nStochastic approximations are at the forefront of this recent development as\nthey yield procedures that are simple, general, and fast. However, standard\nstochastic approximations are often numerically unstable. Deterministic\noptimization, on the other hand, increasingly uses proximal updates to achieve\nnumerical stability in a principled manner. A theoretical gap has thus emerged.\nWhile standard stochastic approximations are subsumed by the framework of\nRobbins and Monro (1951), there is no such framework for stochastic\napproximations with proximal updates. In this paper, we conceptualize a\nproximal version of the classical Robbins-Monro procedure. Our theoretical\nanalysis demonstrates that the proposed procedure has important stability\nbenefits over the classical Robbins-Monro procedure, while it retains the best\nknown convergence rates. Exact implementations of the proximal Robbins-Monro\nprocedure are challenging, but we show that approximate implementations lead to\nprocedures that are easy to implement, and still dominate classical procedures\nby achieving numerical stability, practically without tradeoffs. Moreover,\napproximate proximal Robbins-Monro procedures can be applied even when the\nobjective cannot be calculated analytically, and so they generalize stochastic\nproximal procedures currently in use.\n", "versions": [{"version": "v1", "created": "Sun, 4 Oct 2015 19:07:41 GMT"}, {"version": "v2", "created": "Tue, 13 Oct 2015 00:37:35 GMT"}, {"version": "v3", "created": "Mon, 5 Mar 2018 03:01:41 GMT"}, {"version": "v4", "created": "Sat, 1 Feb 2020 17:50:22 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Toulis", "Panos", ""], ["Horel", "Thibaut", ""], ["Airoldi", "Edoardo M.", ""]]}, {"id": "1510.01064", "submitter": "Jelena Bradic", "authors": "Alexander Hanbo Li and Jelena Bradic", "title": "Boosting in the presence of outliers: adaptive classification with\n  non-convex loss functions", "comments": null, "journal-ref": "Journal of the American Statistical Association: theory and\n  methods, 2017", "doi": "10.1080/01621459.2016.1273116", "report-no": null, "categories": "stat.ML cs.AI cs.LG math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper examines the role and efficiency of the non-convex loss functions\nfor binary classification problems. In particular, we investigate how to design\na simple and effective boosting algorithm that is robust to the outliers in the\ndata. The analysis of the role of a particular non-convex loss for prediction\naccuracy varies depending on the diminishing tail properties of the gradient of\nthe loss -- the ability of the loss to efficiently adapt to the outlying data,\nthe local convex properties of the loss and the proportion of the contaminated\ndata. In order to use these properties efficiently, we propose a new family of\nnon-convex losses named $\\gamma$-robust losses. Moreover, we present a new\nboosting framework, {\\it Arch Boost}, designed for augmenting the existing work\nsuch that its corresponding classification algorithm is significantly more\nadaptable to the unknown data contamination. Along with the Arch Boosting\nframework, the non-convex losses lead to the new class of boosting algorithms,\nnamed adaptive, robust, boosting (ARB). Furthermore, we present theoretical\nexamples that demonstrate the robustness properties of the proposed algorithms.\nIn particular, we develop a new breakdown point analysis and a new influence\nfunction analysis that demonstrate gains in robustness. Moreover, we present\nnew theoretical results, based only on local curvatures, which may be used to\nestablish statistical and optimization properties of the proposed Arch boosting\nalgorithms with highly non-convex loss functions. Extensive numerical\ncalculations are used to illustrate these theoretical properties and reveal\nadvantages over the existing boosting methods when data exhibits a number of\noutliers.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2015 08:50:56 GMT"}], "update_date": "2017-08-25", "authors_parsed": [["Li", "Alexander Hanbo", ""], ["Bradic", "Jelena", ""]]}, {"id": "1510.01188", "submitter": "Alexander Ly", "authors": "Alexander Ly, Maarten Marsman, and Eric-Jan Wagenmakers", "title": "Analytic Posteriors for Pearson's Correlation Coefficient", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pearson's correlation is one of the most common measures of linear\ndependence. Recently, Bernardo (2015) introduced a flexible class of priors to\nstudy this measure in a Bayesian setting. For this large class of priors we\nshow that the (marginal) posterior for Pearson's correlation coefficient and\nall of the posterior moments are analytic. Our results are available in the\nopen-source software package JASP.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2015 15:36:58 GMT"}, {"version": "v2", "created": "Fri, 28 Apr 2017 14:05:30 GMT"}], "update_date": "2017-05-01", "authors_parsed": [["Ly", "Alexander", ""], ["Marsman", "Maarten", ""], ["Wagenmakers", "Eric-Jan", ""]]}, {"id": "1510.01290", "submitter": "Piotr Zwiernik", "authors": "Shaun Fallat, Steffen Lauritzen, Kayvan Sadeghi, Caroline Uhler, Nanny\n  Wermuth, Piotr Zwiernik", "title": "Total positivity in Markov structures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss properties of distributions that are multivariate totally positive\nof order two (MTP2) related to conditional independence. In particular, we show\nthat any independence model generated by an MTP2 distribution is a\ncompositional semigraphoid which is upward-stable and singleton-transitive. In\naddition, we prove that any MTP2 distribution satisfying an appropriate support\ncondition is faithful to its concentration graph. Finally, we analyze\nfactorization properties of MTP2 distributions and discuss ways of constructing\nMTP2 distributions; in particular we give conditions on the log-linear\nparameters of a discrete distribution which ensure MTP2 and characterize\nconditional Gaussian distributions which satisfy MTP2.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2015 19:20:45 GMT"}, {"version": "v2", "created": "Mon, 2 May 2016 09:39:29 GMT"}], "update_date": "2016-05-03", "authors_parsed": [["Fallat", "Shaun", ""], ["Lauritzen", "Steffen", ""], ["Sadeghi", "Kayvan", ""], ["Uhler", "Caroline", ""], ["Wermuth", "Nanny", ""], ["Zwiernik", "Piotr", ""]]}, {"id": "1510.01307", "submitter": "Prasenjit Ghosh", "authors": "Prasenjit Ghosh and Arijit Chakrabarti", "title": "Asymptotic Minimaxity, Optimal Posterior Concentration and Asymptotic\n  Bayes Optimality of Horseshoe-type Priors Under Sparsity", "comments": "This is an extended and corrected manuscript of the article\n  \"Posterior Concentration Properties of a General Class of Shrinkage Priors\n  around Nearly Black Vectors\", arXiv:1412.8161 (v1-v4). The present version of\n  this manuscript (v4) is an improvement over the previous versions (v1-v3)\n  after doing some necessary corrections in Theorem 3.2 and subsequent\n  conclusions", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we investigate certain asymptotic optimality properties of a\nvery broad class of one-group continuous shrinkage priors for simultaneous\nestimation and testing of a sparse normal mean vector. Asymptotic optimality of\nBayes estimates and posterior concentration properties corresponding to the\ngeneral class of one-group priors under consideration are studied where the\ndata is assumed to be generated according to a multivariate normal distribution\nwith a fixed unknown mean vector. Under the assumption that the number of\nnon-zero means is known, we show that Bayes estimators arising out of this\ngeneral class of shrinkage priors under study, attain the minimax risk, up to\nsome multiplicative constant, under the $l_2$ norm. In particular, it is shown\nthat for the horseshoe-type priors such as the three parameter beta normal\nmixtures with parameters $a=0.5, b>0$ and the generalized double Pareto prior\nwith shape parameter $\\alpha=1$, the corresponding Bayes estimates become\nasymptotically minimax. Moreover, posterior distributions arising out of this\ngeneral class of one-group priors are shown to contract around the true mean\nvector at the minimax $l_2$ rate for a wide range of values of the global\nshrinkage parameter depending on the proportion of non-zero components of the\nunderlying mean vector. An important and remarkable fact that emerges as a\nconsequence of one key result essential for proving the aforesaid minimaxity\nresult is that, within the asymptotic framework of Bogdan et al. (2011), the\nnatural thresholding rules due to Carvalho et al. (2010) based on the\nhorseshoe-type priors, asymptotically attain the optimal Bayes risk w.r.t. a\n$0-1$ loss, up to the correct multiplicative constant and are thus,\nasymptotically Bayes optimal under sparsity (ABOS).\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2015 19:52:57 GMT"}, {"version": "v2", "created": "Wed, 4 Nov 2015 14:00:27 GMT"}, {"version": "v3", "created": "Sat, 7 Nov 2015 22:03:14 GMT"}, {"version": "v4", "created": "Tue, 10 Nov 2015 02:36:30 GMT"}], "update_date": "2015-11-11", "authors_parsed": [["Ghosh", "Prasenjit", ""], ["Chakrabarti", "Arijit", ""]]}, {"id": "1510.01355", "submitter": "Inom Mirzaev", "authors": "David M. Bortz, Erin C. Byrne, Inom Mirzaev", "title": "Inverse Problems for a Class of Conditional Probability\n  Measure-Dependent Evolution Equations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.AP math.FA math.OC stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the inverse problem of identifying a conditional probability\nmeasure in a measure-dependent dynamical system. We provide existence and\nwell-posedness results and outline a discretization scheme for approximating a\nmeasure. For this scheme, we prove general method stability.\n  The work is motivated by Partial Differential Equation (PDE) models of\nflocculation for which the shape of the post-fragmentation conditional\nprobability measure greatly impacts the solution dynamics. To illustrate our\nmethodology, we apply the theory to a particular PDE model that arises in the\nstudy of population dynamics for flocculating bacterial aggregates in\nsuspension, and provide numerical evidence for the utility of the approach.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2015 20:48:46 GMT"}], "update_date": "2015-10-07", "authors_parsed": [["Bortz", "David M.", ""], ["Byrne", "Erin C.", ""], ["Mirzaev", "Inom", ""]]}, {"id": "1510.01457", "submitter": "Anton M. Unakafov", "authors": "Anton M. Unakafov and Karsten Keller", "title": "Change-point detection using the conditional entropy of ordinal patterns", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is devoted to change-point detection using only the ordinal\nstructure of a time series. A statistic based on the conditional entropy of\nordinal patterns characterizing the local up and down in a time series is\nintroduced and investigated. The statistic requires only minimal a priori\ninformation on given data and shows good performance in numerical experiments.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2015 07:10:49 GMT"}, {"version": "v2", "created": "Sat, 15 Jul 2017 12:51:33 GMT"}], "update_date": "2017-07-18", "authors_parsed": [["Unakafov", "Anton M.", ""], ["Keller", "Karsten", ""]]}, {"id": "1510.01670", "submitter": "Sohail Bahmani", "authors": "Sohail Bahmani and Justin Romberg", "title": "Sketching for Simultaneously Sparse and Low-Rank Covariance Matrices", "comments": "Accepted in 2015 IEEE International Workshop on Computational\n  Advances in Multi-Sensor Adaptive Processing (CAMSAP 2015)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT math.NA math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a technique for estimating a structured covariance matrix from\nobservations of a random vector which have been sketched. Each observed random\nvector $\\boldsymbol{x}_t$ is reduced to a single number by taking its inner\nproduct against one of a number of pre-selected vector $\\boldsymbol{a}_\\ell$.\nThese observations are used to form estimates of linear observations of the\ncovariance matrix $\\boldsymbol{\\varSigma}$, which is assumed to be\nsimultaneously sparse and low-rank. We show that if the sketching vectors\n$\\boldsymbol{a}_\\ell$ have a special structure, then we can use straightforward\ntwo-stage algorithm that exploits this structure. We show that the estimate is\naccurate when the number of sketches is proportional to the maximum of the rank\ntimes the number of significant rows/columns of $\\boldsymbol{\\varSigma}$.\nMoreover, our algorithm takes direct advantage of the low-rank structure of\n$\\boldsymbol{\\varSigma}$ by only manipulating matrices that are far smaller\nthan the original covariance matrix.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2015 17:13:00 GMT"}, {"version": "v2", "created": "Thu, 8 Oct 2015 17:13:45 GMT"}], "update_date": "2015-10-09", "authors_parsed": [["Bahmani", "Sohail", ""], ["Romberg", "Justin", ""]]}, {"id": "1510.01844", "submitter": "Anuran Makur", "authors": "Anuran Makur and Lizhong Zheng", "title": "Linear Bounds between Contraction Coefficients for $f$-Divergences", "comments": "Part of this work has been published in the 53rd Annual Allerton\n  Conference on Communication, Control, and Computing, 2015. This version\n  includes an overview of contraction coefficients as well as some new results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data processing inequalities for $f$-divergences can be sharpened using\nconstants called \"contraction coefficients\" to produce strong data processing\ninequalities. For any discrete source-channel pair, the contraction\ncoefficients for $f$-divergences are lower bounded by the contraction\ncoefficient for $\\chi^2$-divergence. In this paper, we elucidate that this\nlower bound can be achieved by driving the input $f$-divergences of the\ncontraction coefficients to zero. Then, we establish a linear upper bound on\nthe contraction coefficients for a certain class of $f$-divergences using the\ncontraction coefficient for $\\chi^2$-divergence, and refine this upper bound\nfor the salient special case of Kullback-Leibler (KL) divergence. Furthermore,\nwe present an alternative proof of the fact that the contraction coefficients\nfor KL and $\\chi^2$-divergences are equal for a Gaussian source with an\nadditive Gaussian noise channel (where the former coefficient can be power\nconstrained). Finally, we generalize the well-known result that contraction\ncoefficients of channels (after extremizing over all possible sources) for all\n$f$-divergences with non-linear operator convex $f$ are equal. In particular,\nwe prove that the so called \"less noisy\" preorder over channels can be\nequivalently characterized by any non-linear operator convex $f$-divergence.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2015 07:06:02 GMT"}, {"version": "v2", "created": "Thu, 8 Oct 2015 01:02:13 GMT"}, {"version": "v3", "created": "Mon, 28 Aug 2017 12:42:47 GMT"}, {"version": "v4", "created": "Mon, 16 Jul 2018 07:42:32 GMT"}], "update_date": "2018-07-17", "authors_parsed": [["Makur", "Anuran", ""], ["Zheng", "Lizhong", ""]]}, {"id": "1510.01858", "submitter": "Sojung Kim", "authors": "Sojung Kim and Kyoung-kuk Kim", "title": "Saddlepoint methods for conditional expectations with applications to\n  risk management", "comments": "36 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper derives saddlepoint expansions for conditional expectations in the\nform of $\\mathsf{E}[\\overline{X} | \\overline{\\mathbf Y} = {\\mathbf a}]$ and\n$\\mathsf{E}[\\overline{X} | \\overline{\\mathbf Y} \\geq {\\mathbf a}]$ for the\nsample mean of a continuous random vector $(X, {\\mathbf Y}^\\top)$ whose joint\nmoment generating function is available. Theses conditional expectations\nfrequently appear in various applications, particularly in quantitative finance\nand risk management. Using the newly developed saddlepoint expansions, we\npropose fast and accurate methods to compute the sensitivities of risk measures\nsuch as value-at-risk and conditional value-at-risk, and the sensitivities of\nfinancial options with respect to a market parameter. Numerical studies are\nprovided for the accuracy verification of the new approximations.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2015 08:37:01 GMT"}], "update_date": "2015-10-08", "authors_parsed": [["Kim", "Sojung", ""], ["Kim", "Kyoung-kuk", ""]]}, {"id": "1510.01948", "submitter": "Amirhossein Taghvaei", "authors": "Amirhossein Taghvaei, Prashant G. Mehta", "title": "An Optimal Transport Formulation of the Linear Feedback Particle Filter", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feedback particle filter (FPF) is an algorithm to numerically approximate the\nsolution of the nonlinear filtering problem in continuous time. The algorithm\nimplements a feedback control law for a system of particles such that the\nempirical distribution of particles approximates the posterior distribution.\nHowever, it has been noted in the literature that the feedback control law is\nnot unique. To find a unique control law, the filtering task is formulated here\nas an optimal transportation problem between the prior and the posterior\ndistributions. Based on this formulation, a time stepping optimization\nprocedure is proposed for the optimal control design. A key difference between\nthe optimal control law and the one in the original FPF, is the replacement of\nnoise term with a deterministic term. This difference serves to decreases the\nsimulation variance, as illustrated with a simple numerical example.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2015 14:00:32 GMT"}], "update_date": "2015-10-08", "authors_parsed": [["Taghvaei", "Amirhossein", ""], ["Mehta", "Prashant G.", ""]]}, {"id": "1510.02232", "submitter": "St\\'ephanie van der Pas", "authors": "St\\'ephanie van der Pas, Jean-Bernard Salomond, Johannes\n  Schmidt-Hieber", "title": "Conditions for Posterior Contraction in the Sparse Normal Means Problem", "comments": null, "journal-ref": "Electron. J. Statist. 10 (2016), no. 1, 976--1000.\n  http://projecteuclid.org/euclid.ejs/1460463652", "doi": "10.1214/16-EJS1130", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The first Bayesian results for the sparse normal means problem were proven\nfor spike-and-slab priors. However, these priors are less convenient from a\ncomputational point of view. In the meanwhile, a large number of continuous\nshrinkage priors has been proposed. Many of these shrinkage priors can be\nwritten as a scale mixture of normals, which makes them particularly easy to\nimplement. We propose general conditions on the prior on the local variance in\nscale mixtures of normals, such that posterior contraction at the minimax rate\nis assured. The conditions require tails at least as heavy as Laplace, but not\ntoo heavy, and a large amount of mass around zero relative to the tails, more\nso as the sparsity increases. These conditions give some general guidelines for\nchoosing a shrinkage prior for estimation under a nearly black sparsity\nassumption. We verify these conditions for the class of priors considered by\nGhosh and Chakrabarti (2015), which includes the horseshoe and the\nnormal-exponential gamma priors, and for the horseshoe+, the inverse-Gaussian\nprior, the normal-gamma prior, and the spike-and-slab Lasso, and thus extend\nthe number of shrinkage priors which are known to lead to posterior contraction\nat the minimax estimation rate.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2015 08:31:31 GMT"}, {"version": "v2", "created": "Tue, 13 Oct 2015 11:04:55 GMT"}], "update_date": "2016-08-16", "authors_parsed": [["van der Pas", "St\u00e9phanie", ""], ["Salomond", "Jean-Bernard", ""], ["Schmidt-Hieber", "Johannes", ""]]}, {"id": "1510.02269", "submitter": "Nobuki Takayama", "authors": "Nobuki Takayama, Satoshi Kuriki, Akimichi Takemura", "title": "$A$-Hypergeometric Distributions and Newton Polytopes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CA math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a bijection between a quotient space of the parameters and the space\nof moments for any $A$-hypergeometric distribution. An algorithmic method to\ncompute the inverse image of the map is proposed utilizing the holonomic\ngradient method and an asymptotic equivalence of the map and the iterative\nproportional scaling. The algorithm gives a method to solve a conditional\nmaximum likelihood estimation problem in statistics. Our interplay between the\ntheory of hypergeometric functions and statistics gives some new formulas of\n$A$-hypergeometric polynomials.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2015 10:15:19 GMT"}, {"version": "v2", "created": "Thu, 12 Nov 2015 04:31:05 GMT"}], "update_date": "2015-11-13", "authors_parsed": [["Takayama", "Nobuki", ""], ["Kuriki", "Satoshi", ""], ["Takemura", "Akimichi", ""]]}, {"id": "1510.02330", "submitter": "Shahab Asoodeh", "authors": "Shahab Asoodeh, Fady Alajaji, and Tam\\'as Linder", "title": "On Maximal Correlation, Mutual Information and Data Privacy", "comments": "Appeared in Canadian Workshop on Information Theory 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rate-privacy function is defined in \\cite{Asoodeh} as a tradeoff between\nprivacy and utility in a distributed private data system in which both privacy\nand utility are measured using mutual information. Here, we use maximal\ncorrelation in lieu of mutual information in the privacy constraint. We first\nobtain some general properties and bounds for maximal correlation and then\nmodify the rate-privacy function to account for the privacy-constrained\nestimation problem. We find a bound for the utility in this problem when the\nmaximal correlation privacy is set to some threshold $\\epsilon>0$ and construct\nan explicit privacy scheme which achieves this bound.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2015 14:12:54 GMT"}], "update_date": "2015-10-09", "authors_parsed": [["Asoodeh", "Shahab", ""], ["Alajaji", "Fady", ""], ["Linder", "Tam\u00e1s", ""]]}, {"id": "1510.02399", "submitter": "Matteo Barigozzi", "authors": "Matteo Barigozzi and Marco Lippi and Matteo Luciani", "title": "Dynamic Factor Models, Cointegration, and Error Correction Mechanisms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper studies Non-Stationary Dynamic Factor Models such that the factors\n$\\mathbf F_t$ are $I(1)$ and singular, i.e. $\\mathbf F_t$ has dimension $r$ and\nis driven by a $q$-dimensional white noise, the common shocks, with $q<r$. We\nshow that $\\mathbf F_t$ is driven by $r-c$ permanent shocks, where $c$ is the\ncointegration rank of $\\mathbf F_t$, and $q-(r-c)<c$ transitory shocks, thus\nthe same result as in the non-singular case for the permanent shocks but not\nfor the transitory shocks. Our main result is obtained by combining the classic\nGranger Representation Theorem with recent results by Anderson and Deistler on\nsingular stochastic vectors: if $(1-L)\\mathbf F_t$ is singular and has {\\it\nrational} spectral density then, for generic values of the parameters, $\\mathbf\nF_t$ has an autoregressive representation with a {\\it finite-degree} matrix\npolynomial fulfilling the restrictions of a Vector Error Correction Mechanism\nwith $c$ error terms. This result is the basis for consistent estimation of\nNon-Stationary Dynamic Factor Models. The relationship between cointegration of\nthe factors and cointegration of the observable variables is also discussed.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2015 16:50:42 GMT"}, {"version": "v2", "created": "Wed, 23 Mar 2016 16:24:59 GMT"}, {"version": "v3", "created": "Wed, 11 Jan 2017 18:47:49 GMT"}], "update_date": "2017-01-12", "authors_parsed": [["Barigozzi", "Matteo", ""], ["Lippi", "Marco", ""], ["Luciani", "Matteo", ""]]}, {"id": "1510.02451", "submitter": "Sebastian Vollmer", "authors": "Alexandre Bouchard-C\\^ot\\'e and Sebastian J. Vollmer and Arnaud Doucet", "title": "The Bouncy Particle Sampler: A Non-Reversible Rejection-Free Markov\n  Chain Monte Carlo Method", "comments": "42 pages, 15 figures, reference in abstract is to arXiv:1112.1263v3", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Markov chain Monte Carlo methods have become standard tools in statistics to\nsample from complex probability measures. Many available techniques rely on\ndiscrete-time reversible Markov chains whose transition kernels build up over\nthe Metropolis-Hastings algorithm. We explore and propose several original\nextensions of an alternative approach introduced recently in Peters and de With\n(2012) where the target distribution of interest is explored using a\ncontinuous-time Markov process. In the Metropolis-Hastings algorithm, a trial\nmove to a region of lower target density, equivalently \"higher energy\", than\nthe current state can be rejected with positive probability. In this\nalternative approach, a particle moves along straight lines continuously around\nthe space and, when facing a high energy barrier, it is not rejected but its\npath is modified by bouncing against this barrier. The resulting non-reversible\nMarkov process provides a rejection-free MCMC sampling scheme. We propose\nseveral original techniques to simulate this continuous-time process exactly in\na wide range of scenarios of interest to statisticians. When the target\ndistribution factorizes as a product of factors involving only subsets of\nvariables, such as the posterior distribution associated to a probabilistic\ngraphical model, it is possible to modify the original algorithm to exploit\nthis structure and update in parallel variables within each clique. We present\nseveral extensions by proposing methods to sample mixed discrete-continuous\ndistributions and distributions restricted to a connected smooth domain. We\nalso show that it is possible to move the particle using a general flow instead\nof straight lines. We demonstrate the efficiency of this methodology through\nsimulations on a variety of applications and show that it can outperform Hybrid\nMonte Carlo schemes in interesting scenarios.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2015 19:17:41 GMT"}, {"version": "v2", "created": "Mon, 25 Jan 2016 20:37:57 GMT"}, {"version": "v3", "created": "Wed, 27 Jan 2016 17:22:04 GMT"}, {"version": "v4", "created": "Wed, 15 Jun 2016 18:58:54 GMT"}, {"version": "v5", "created": "Fri, 18 Nov 2016 22:17:41 GMT"}, {"version": "v6", "created": "Fri, 17 Feb 2017 20:49:02 GMT"}], "update_date": "2017-02-21", "authors_parsed": [["Bouchard-C\u00f4t\u00e9", "Alexandre", ""], ["Vollmer", "Sebastian J.", ""], ["Doucet", "Arnaud", ""]]}, {"id": "1510.02551", "submitter": "Qian He", "authors": "Qian He, Jianbin Hu, Rick S. Blum, and Yonggang Wu", "title": "Generalized Cramer-Rao Bound for Joint Estimation of Target Position and\n  Velocity for Active and Passive Radar Networks", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2015.2510978", "report-no": null, "categories": "math.ST cs.IT math.IT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we derive the Cramer-Rao bound (CRB) for joint target position\nand velocity estimation using an active or passive distributed radar network\nunder more general, and practically occurring, conditions than assumed in\nprevious work. In particular, the presented results allow nonorthogonal\nsignals, spatially dependent Gaussian reflection coefficients, and spatially\ndependent Gaussian clutter-plus-noise. These bounds allow designers to compare\nthe performance of their developed approaches, which are deemed to be of\nacceptable complexity, to the best achievable performance. If their developed\napproaches lead to performance close to the bounds, these developed approaches\ncan be deemed \"good enough\". A particular recent study where algorithms have\nbeen developed for a practical radar application which must involve\nnonorthogonal signals, for which the best performance is unknown, is a great\nexample. The presented results in our paper do not make any assumptions about\nthe approximate location of the target being known from previous target\ndetection signal processing. In addition, for situations in which we do not\nknow some parameters accurately, we also derive the mismatched CRB. Numerical\ninvestigations of the mean squared error of the maximum likelihood estimation\nare employed to support the validity of the CRBs. In order to demonstrate the\nutility of the provided results to a topic of great current interest, the\nnumerical results focus on a passive radar system using the Global System for\nMobile communication (GSM) cellar system.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2015 02:37:15 GMT"}], "update_date": "2016-04-20", "authors_parsed": [["He", "Qian", ""], ["Hu", "Jianbin", ""], ["Blum", "Rick S.", ""], ["Wu", "Yonggang", ""]]}, {"id": "1510.02668", "submitter": "Nicolas Desassis", "authors": "Nicolas Desassis, Didier Renard, H\\'el\\`ene Beucher, Sylvain Petiteau,\n  Xavier Freulon", "title": "A pairwise likelihood approach for the empirical estimation of the\n  underlyingvariograms in the plurigaussian models", "comments": "To be submitted to Spatial Statistics", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The plurigaussian model is particularly suited to describe categorical\nregionalized variables. Starting from a simple principle, the thresh-olding of\none or several Gaussian random fields (GRFs) to obtain categories, the\nplurigaussian model is well adapted for a wide range ofsituations. By acting on\nthe form of the thresholding rule and/or the threshold values (which can vary\nalong space) and the variograms ofthe underlying GRFs, one can generate many\nspatial configurations for the categorical variables. One difficulty is to\nchoose variogrammodel for the underlying GRFs. Indeed, these latter are hidden\nby the truncation and we only observe the simple and cross-variogramsof the\ncategory indicators. In this paper, we propose a semiparametric method based on\nthe pairwise likelihood to estimate the empiricalvariogram of the GRFs. It\nprovides an exploratory tool in order to choose a suitable model for each GRF\nand later to estimate its param-eters. We illustrate the efficiency of the\nmethod with a Monte-Carlo simulation study .The method presented in this paper\nis implemented in the R packageRGeostats.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2015 13:45:17 GMT"}, {"version": "v2", "created": "Fri, 16 Oct 2015 06:34:48 GMT"}], "update_date": "2015-10-19", "authors_parsed": [["Desassis", "Nicolas", ""], ["Renard", "Didier", ""], ["Beucher", "H\u00e9l\u00e8ne", ""], ["Petiteau", "Sylvain", ""], ["Freulon", "Xavier", ""]]}, {"id": "1510.02862", "submitter": "Guangyu Yang", "authors": "Hui Jiang, Mingming Yu, Guangyu Yang", "title": "Moderate deviations for the mildly stationary autoregressive models with\n  dependent errors", "comments": "Comments welcome. 28 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the normalized least squares estimator of the\nparameter in a mildly stationary first-order autoregressive model with\ndependent errors which are modeled as a mildly stationary AR(1) process. By\nmartingale methods, we establish the moderate deviations for the least squares\nestimators of the regressor and error, which can be applied to understand the\nnear-integrated second order autoregressive processes. As an application, we\nobtain the moderate deviations for the Durbin-Watson statistic.\n", "versions": [{"version": "v1", "created": "Sat, 10 Oct 2015 01:58:44 GMT"}], "update_date": "2015-10-13", "authors_parsed": [["Jiang", "Hui", ""], ["Yu", "Mingming", ""], ["Yang", "Guangyu", ""]]}, {"id": "1510.02903", "submitter": "Serguei Pergamenchtchikov", "authors": "Serguei M. Pergamenchtchikov and Alexander G. Tartakovsky", "title": "Asymptotically Optimal Pointwise and Minimax Quickest Change-point\n  Detection for Dependent Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the quickest change-point detection problem in pointwise and\nminimax settings for general dependent data models. Two new classes of\nsequential detection procedures associated with the maximal \"local\" probability\nof a false alarm within a period of some fixed length are introduced. For these\nclasses of detection procedures, we consider two popular risks: the expected\npositive part of the delay to detection and the conditional delay to detection.\nUnder very general conditions for the observations, we show that the popular\nShiryaev--Roberts procedure is asymptotically optimal, as the local probability\nof false alarm goes to zero, with respect to both these risks pointwise\n(uniformly for every possible point of change) and in the minimax sense (with\nrespect to maximal over point of change expected detection delays). The\nconditions are formulated in terms of the rate of convergence in the strong law\nof large numbers for the log-likelihood ratios between the \"change\" and\n\"no-change\" hypotheses, specifically as a uniform complete convergence of the\nnormalized log-likelihood ratio to a positive and finite number. We also\ndevelop tools and a set of sufficient conditions for verification of the\nuniform complete convergence for a large class of Markov processes. These tools\nare based on concentration inequalities for functions of Markov processes and\nthe Meyn--Tweedie geometric ergodic theory. Finally, we check these sufficient\nconditions for a number of challenging examples (time series) frequently\narising in applications, such as autoregression, autoregressive GARCH, etc.\n", "versions": [{"version": "v1", "created": "Sat, 10 Oct 2015 09:53:21 GMT"}, {"version": "v2", "created": "Fri, 15 Jan 2016 16:25:42 GMT"}], "update_date": "2016-01-18", "authors_parsed": [["Pergamenchtchikov", "Serguei M.", ""], ["Tartakovsky", "Alexander G.", ""]]}, {"id": "1510.03267", "submitter": "Andreas Christmann", "authors": "Andreas Christmann, Ding-Xuan Zhou", "title": "On the Robustness of Regularized Pairwise Learning Methods Based on\n  Kernels", "comments": "36 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.FA stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regularized empirical risk minimization including support vector machines\nplays an important role in machine learning theory. In this paper regularized\npairwise learning (RPL) methods based on kernels will be investigated. One\nexample is regularized minimization of the error entropy loss which has\nrecently attracted quite some interest from the viewpoint of consistency and\nlearning rates. This paper shows that such RPL methods have additionally good\nstatistical robustness properties, if the loss function and the kernel are\nchosen appropriately. We treat two cases of particular interest: (i) a bounded\nand non-convex loss function and (ii) an unbounded convex loss function\nsatisfying a certain Lipschitz type condition.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2015 13:01:47 GMT"}], "update_date": "2015-10-13", "authors_parsed": [["Christmann", "Andreas", ""], ["Zhou", "Ding-Xuan", ""]]}, {"id": "1510.03502", "submitter": "Diane  Donovan Dr", "authors": "Diane Donovan, Kevin Burrage, Pamela Burrage, Thomas A McCourt, Harold\n  Bevan Thompson and Emine Sule Yazici", "title": "Estimates of the coverage of parameter space by Latin Hypercube and\n  Orthogonal sampling: connections between Populations of Models and\n  Experimental Designs", "comments": "15 pages, 2 figures. arXiv admin note: text overlap with\n  arXiv:1502.06559", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we use counting arguments to prove that the expected percentage\ncoverage of a $d$ dimensional parameter space of size $n$ when performing $k$\ntrials with either Latin Hypercube sampling or Orthogonal sampling (when\n$n=p^d$) is the same. We then extend these results to an experimental design\nsetting by projecting onto a 2 dimensional subspace. In this case the coverage\nis equivalent to the Orthogonal sampling setting when the dimension of the\nparameter space is two. These results are confirmed by simulations. The ideas\npresented here have particular relevance when attempting to perform uncertainty\nquantification or when building populations of models.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2015 01:20:29 GMT"}], "update_date": "2015-10-14", "authors_parsed": [["Donovan", "Diane", ""], ["Burrage", "Kevin", ""], ["Burrage", "Pamela", ""], ["McCourt", "Thomas A", ""], ["Thompson", "Harold Bevan", ""], ["Yazici", "Emine Sule", ""]]}, {"id": "1510.03547", "submitter": "Romain Couillet", "authors": "Romain Couillet and Florent Benaych-Georges", "title": "Kernel spectral clustering of large dimensional data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article proposes a first analysis of kernel spectral clustering methods\nin the regime where the dimension $p$ of the data vectors to be clustered and\ntheir number $n$ grow large at the same rate. We demonstrate, under a $k$-class\nGaussian mixture model, that the normalized Laplacian matrix associated with\nthe kernel matrix asymptotically behaves similar to a so-called spiked random\nmatrix. Some of the isolated eigenvalue-eigenvector pairs in this model are\nshown to carry the clustering information upon a separability condition\nclassical in spiked matrix models. We evaluate precisely the position of these\neigenvalues and the content of the eigenvectors, which unveil important\n(sometimes quite disruptive) aspects of kernel spectral clustering both from a\ntheoretical and practical standpoints. Our results are then compared to the\nactual clustering performance of images from the MNIST database, thereby\nrevealing an important match between theory and practice.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2015 06:45:11 GMT"}, {"version": "v2", "created": "Tue, 3 Nov 2015 09:12:25 GMT"}, {"version": "v3", "created": "Thu, 21 Apr 2016 06:02:18 GMT"}], "update_date": "2016-04-22", "authors_parsed": [["Couillet", "Romain", ""], ["Benaych-Georges", "Florent", ""]]}, {"id": "1510.03600", "submitter": "Edward Cohen", "authors": "Johannes Lutzeyer and Edward A. K. Cohen", "title": "Correcting the estimator for the mean vectors in a multivariate\n  errors-in-variables regression model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The multivariate errors-in-variables regression model is applicable when both\ndependent and independent variables in a multivariate regression are subject to\nmeasurement errors. In such a scenario it is long established that the\ntraditional least squares approach to estimating the model parameters is biased\nand inconsistent. The generalized least squares, ordinary least squares and\nmaximum likelihood estimators (under the assumption of Gaussian errors) were\nderived in the seminal paper of Gleser (1981). However, the ordinary least\nsquares and maximum likelihood estimators for the mean vectors were incorrectly\nderived. In this short paper we amend this error, presenting the correct\nestimators of the mean vectors.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2015 09:48:23 GMT"}], "update_date": "2015-10-14", "authors_parsed": [["Lutzeyer", "Johannes", ""], ["Cohen", "Edward A. K.", ""]]}, {"id": "1510.03659", "submitter": "Hock Peng Chan", "authors": "Hock Peng Chan, Guenther Walther", "title": "Optimal detection of multi-sample aligned sparse signals", "comments": "Published at http://dx.doi.org/10.1214/15-AOS1328 in the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2015, Vol. 43, No. 5, 1865-1895", "doi": "10.1214/15-AOS1328", "report-no": "IMS-AOS-AOS1328", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe, in the detection of multi-sample aligned sparse signals, the\ncritical boundary separating detectable from nondetectable signals, and\nconstruct tests that achieve optimal detectability: penalized versions of the\nBerk-Jones and the higher-criticism test statistics evaluated over pooled\nscans, and an average likelihood ratio over the critical boundary. We show in\nour results an inter-play between the scale of the sequence length to signal\nlength ratio, and the sparseness of the signals. In particular the difficulty\nof the detection problem is not noticeably affected unless this ratio grows\nexponentially with the number of sequences. We also recover the multiscale and\nsparse mixture testing problems as illustrative special cases.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2015 13:10:17 GMT"}], "update_date": "2015-10-14", "authors_parsed": [["Chan", "Hock Peng", ""], ["Walther", "Guenther", ""]]}, {"id": "1510.03679", "submitter": "Andreas Anastasiou Dr", "authors": "Andreas Anastasiou", "title": "Assessing the multivariate normal approximation of the maximum\n  likelihood estimator from high-dimensional, heterogeneous data", "comments": "30 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The asymptotic normality of the maximum likelihood estimator (MLE) under\nregularity conditions is a cornerstone of statistical theory. In this paper, we\ngive explicit upper bounds on the distributional distance between the\ndistribution of the MLE of a vector parameter, and the multivariate normal\ndistribution. We work with possibly high-dimensional, independent but not\nnecessarily identically distributed random vectors. In addition, we obtain\nexplicit upper bounds even in cases where the MLE cannot be expressed\nanalytically.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2015 14:06:50 GMT"}, {"version": "v2", "created": "Wed, 31 Aug 2016 16:21:24 GMT"}, {"version": "v3", "created": "Fri, 20 Jul 2018 15:38:45 GMT"}], "update_date": "2018-07-23", "authors_parsed": [["Anastasiou", "Andreas", ""]]}, {"id": "1510.03827", "submitter": "Alexander Tartakovsky", "authors": "Alexander G. Tartakovsky", "title": "On Asymptotic Optimality in Sequential Changepoint Detection: Non-iid\n  Case", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a sequential Bayesian changepoint detection problem for a general\nstochastic model, assuming that the observed data may be dependent and\nnon-identically distributed and the prior distribution of the change point is\narbitrary, not necessarily geometric. Tartakovsky and Veeravalli (2004)\ndeveloped a general asymptotic theory of changepoint detection in the non-iid\ncase and discrete time, and Baron and Tartakovsky (2006) in continuous time\nassuming certain stability of the log-likelihood ratio process. This stability\nproperty was formulated in terms of the r-quick convergence of the normalized\nlog-likelihood ratio process to a positive and finite number, which can be\ninterpreted as the limiting Kullback-Leibler information between the \"change\"\nand \"no change\" hypotheses. In these papers, it was conjectured that the\nr-quick convergence can be relaxed in the r-complete convergence, which is\ntypically much easier to verify in particular examples. In the present paper,\nwe justify this conjecture by showing that the Shiryaev change detection\nprocedure is nearly optimal, minimizing asymptotically (as the probability of\nfalse alarm vanishes) the moments of the delay to detection up to order r\nwhenever r-complete convergence holds. We also study asymptotic properties of\nthe Shiryaev-Roberts detection procedure in the Bayesian context.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2015 19:15:39 GMT"}, {"version": "v2", "created": "Wed, 13 Jan 2016 23:59:52 GMT"}], "update_date": "2016-01-15", "authors_parsed": [["Tartakovsky", "Alexander G.", ""]]}, {"id": "1510.03898", "submitter": "Tomasz Maci\\\"A{\\AA}1/4ek", "authors": "Tomasz Maci\\k{a}\\.zek, Christopher H. Joyner, Uzy Smilansky", "title": "The probability distribution of spectral moments for the Gaussian\n  beta-ensembles", "comments": "13 pages", "journal-ref": "Acta Physica Polonica A, vol. 128, no.6, pp 983, December 2015", "doi": "10.12693/APhysPolA.128.983", "report-no": null, "categories": "math-ph math.MP math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive the joint probability distribution of the first two spectral\nmoments for the G$\\beta$E random matrix ensembles in N dimensions for any N.\nThis is achieved by making use of two complementary invariants of the domain in\n$\\mathbb{R}^N$ where the spectral moments are defined. Our approach is\nsignificantly different from those employed previously to answer related\nquestions and potentially offers new insights. We also discuss the problems\nfaced when attempting to include higher spectral moments.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2015 21:10:24 GMT"}, {"version": "v2", "created": "Fri, 25 Dec 2015 23:21:50 GMT"}], "update_date": "2016-08-08", "authors_parsed": [["Maci\u0105\u017cek", "Tomasz", ""], ["Joyner", "Christopher H.", ""], ["Smilansky", "Uzy", ""]]}, {"id": "1510.03966", "submitter": "Xiongzhi Chen", "authors": "Xiongzhi Chen", "title": "Natural Exponential Families: Resolution of A Conjecture and Existence\n  of Reduction Functions", "comments": "14 pages and 1 figure, in this version, the proof of the conjecture\n  is much more concise, and the proof of the existence of redunction functions\n  uses a different approach", "journal-ref": "Statistics & Probability Letters; 2016 and 2018", "doi": "10.1016/j.spl.2016.06.016; 10.1016/j.spl.2018.02.010", "report-no": null, "categories": "math.ST stat.TH", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  One-parameter natural exponential family (NEF) plays fundamental roles in\nprobability and statistics. This article contains two independent results: (a)\nA conjecture of Bar-Lev, Bshouty and Enis states that a polynomial with a\nsimple root at $0$ and a complex root with positive imaginary part is the\nvariance function of some NEF with mean domain $\\left(0,\\infty\\right)$ if and\nonly if the real part of the complex root is not positive. This conjecture is\nresolved. The positive answer to this conjecture enlarges existing family of\npolynomials that are able to generate NEFs, and it helps prevent practitioners\nfrom choosing incompatible functions as variance functions for statistical\nmodeling using NEFs. (b) if a random variable $\\xi$ has parametric\ndistributions that form a infinitely divisible NEF whose induced measure is\nabsolutely continuous with respect to its basis measure, then there exists a\ndeterministic function $h$, called \"reduction function\", such that $\\mathbb{E}\n\\left(h\\left(\\xi\\right)\\right)=\\mathbb{V}\\left(\\xi\\right)$, i.e.,\n$h\\left(\\xi\\right)$ is an unbiased estimator of the variance of $\\xi$. The\nreduction function has applications to estimating latent, low-dimensional\nstructures and to dimension reduction in the first and/or second moments in\nhigh-dimensional data.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2015 05:18:48 GMT"}, {"version": "v2", "created": "Sat, 19 Mar 2016 15:20:47 GMT"}], "update_date": "2018-03-05", "authors_parsed": [["Chen", "Xiongzhi", ""]]}, {"id": "1510.03970", "submitter": "Fei Jiang", "authors": "Fei Jiang, Yanyuan Ma, Yuanjia Wang", "title": "Fused kernel-spline smoothing for repeatedly measured outcomes in a\n  generalized partially linear model with functional single index", "comments": "Published at http://dx.doi.org/10.1214/15-AOS1330 in the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2015, Vol. 43, No. 5, 1929-1958", "doi": "10.1214/15-AOS1330", "report-no": "IMS-AOS-AOS1330", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a generalized partially linear functional single index risk score\nmodel for repeatedly measured outcomes where the index itself is a function of\ntime. We fuse the nonparametric kernel method and regression spline method, and\nmodify the generalized estimating equation to facilitate estimation and\ninference. We use local smoothing kernel to estimate the unspecified\ncoefficient functions of time, and use B-splines to estimate the unspecified\nfunction of the single index component. The covariance structure is taken into\naccount via a working model, which provides valid estimation and inference\nprocedure whether or not it captures the true covariance. The estimation method\nis applicable to both continuous and discrete outcomes. We derive large sample\nproperties of the estimation procedure and show a different convergence rate\nfor each component of the model. The asymptotic properties when the kernel and\nregression spline methods are combined in a nested fashion has not been studied\nprior to this work, even in the independent data case.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2015 05:49:59 GMT"}], "update_date": "2015-10-15", "authors_parsed": [["Jiang", "Fei", ""], ["Ma", "Yanyuan", ""], ["Wang", "Yuanjia", ""]]}, {"id": "1510.04027", "submitter": "Shujie Ma", "authors": "Shujie Ma, Raymond J. Carroll, Hua Liang, Shizhong Xu", "title": "Estimation and inference in generalized additive coefficient models for\n  nonlinear interactions with high-dimensional covariates", "comments": "Published at http://dx.doi.org/10.1214/15-AOS1344 in the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2015, Vol. 43, No. 5, 2102-2131", "doi": "10.1214/15-AOS1344", "report-no": "IMS-AOS-AOS1344", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the low-dimensional case, the generalized additive coefficient model\n(GACM) proposed by Xue and Yang [Statist. Sinica 16 (2006) 1423-1446] has been\ndemonstrated to be a powerful tool for studying nonlinear interaction effects\nof variables. In this paper, we propose estimation and inference procedures for\nthe GACM when the dimension of the variables is high. Specifically, we propose\na groupwise penalization based procedure to distinguish significant covariates\nfor the \"large $p$ small $n$\" setting. The procedure is shown to be consistent\nfor model structure identification. Further, we construct simultaneous\nconfidence bands for the coefficient functions in the selected model based on a\nrefined two-step spline estimator. We also discuss how to choose the tuning\nparameters. To estimate the standard deviation of the functional estimator, we\nadopt the smoothed bootstrap method. We conduct simulation experiments to\nevaluate the numerical performance of the proposed methods and analyze an\nobesity data set from a genome-wide association study as an illustration.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2015 10:01:55 GMT"}], "update_date": "2015-10-15", "authors_parsed": [["Ma", "Shujie", ""], ["Carroll", "Raymond J.", ""], ["Liang", "Hua", ""], ["Xu", "Shizhong", ""]]}, {"id": "1510.04062", "submitter": "Henryk Gzyl", "authors": "Henryk Gzyl", "title": "Sample dependence in the maximum entropy solution to the generalized\n  moment problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The method of maximum entropy is quite a powerful tool to solve the\ngeneralized moment problem, which consists of determining the probability\ndensity of a random variable X from the knowledge of the expected values of a\nfew functions of the variable. In actual practice, such expected values are\ndetermined from empirical samples, leaving open the question of the dependence\nof the solution upon the sample. It is the purpose of this note to take a few\nsteps towards the analysis of such dependence.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2015 12:31:54 GMT"}], "update_date": "2015-10-15", "authors_parsed": [["Gzyl", "Henryk", ""]]}, {"id": "1510.04064", "submitter": "Yingying Fan", "authors": "Yingying Fan, Gareth M. James, Peter Radchenko", "title": "Functional additive regression", "comments": "Published at http://dx.doi.org/10.1214/15-AOS1346 in the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2015, Vol. 43, No. 5, 2296-2325", "doi": "10.1214/15-AOS1346", "report-no": "IMS-AOS-AOS1346", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We suggest a new method, called Functional Additive Regression, or FAR, for\nefficiently performing high-dimensional functional regression. FAR extends the\nusual linear regression model involving a functional predictor, $X(t)$, and a\nscalar response, $Y$, in two key respects. First, FAR uses a penalized least\nsquares optimization approach to efficiently deal with high-dimensional\nproblems involving a large number of functional predictors. Second, FAR extends\nbeyond the standard linear regression setting to fit general nonlinear additive\nmodels. We demonstrate that FAR can be implemented with a wide range of penalty\nfunctions using a highly efficient coordinate descent algorithm. Theoretical\nresults are developed which provide motivation for the FAR optimization\ncriterion. Finally, we show through simulations and two real data sets that FAR\ncan significantly outperform competing methods.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2015 12:37:10 GMT"}], "update_date": "2015-10-15", "authors_parsed": [["Fan", "Yingying", ""], ["James", "Gareth M.", ""], ["Radchenko", "Peter", ""]]}, {"id": "1510.04115", "submitter": "Gyula Pap", "authors": "J\\'anos Marcell Benke and Gyula Pap", "title": "One-parameter statistical model for linear stochastic differential\n  equation with time delay", "comments": "21 pages", "journal-ref": "Statistics 51(3), (2017) 510-531", "doi": "10.1080/02331888.2016.1239728", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Assume that we observe a stochastic process $(X(t))_{t\\in[-r,T]}$, which\nsatisfies the linear stochastic delay differential equation \\[\n  \\mathrm{d} X(t)\n  = \\vartheta \\int_{[-r,0]} X(t + u) \\, a(\\mathrm{d} u) \\, \\mathrm{d} t +\n\\mathrm{d} W(t) ,\n  \\qquad t \\geq 0 , \\] where $a$ is a finite signed measure on $[-r, 0]$. The\nlocal asymptotic properties of the likelihood function are studied. Local\nasymptotic normality is proved in case of $v_\\vartheta^* < 0$, local asymptotic\nquadraticity is shown if $v_\\vartheta^* = 0$, and, under some additional\nconditions, local asymptotic mixed normality or periodic local asymptotic mixed\nnormality is valid if $v_\\vartheta^* > 0$, where $v_\\vartheta^*$ is an\nappropriately defined quantity. As an application, the asymptotic behaviour of\nthe maximum likelihood estimator $\\widehat{\\vartheta}_T$ of $\\vartheta$ based\non $(X(t))_{t\\in[-r,T]}$ can be derived as $T \\to \\infty$.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2015 14:30:50 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Benke", "J\u00e1nos Marcell", ""], ["Pap", "Gyula", ""]]}, {"id": "1510.04124", "submitter": "Alex Fink", "authors": "Alex Fink, Jenna Rajchgot, Seth Sullivant", "title": "Matrix Schubert varieties and Gaussian conditional independence models", "comments": "34pp, 1 figure. updated to accepted version", "journal-ref": "Journal of Algebraic Combinatorics, (2016), 1-38", "doi": "10.1007/s10801-016-0698-2", "report-no": null, "categories": "math.AG math.CO math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matrix Schubert varieties are certain varieties in the affine space of square\nmatrices which are determined by specifying rank conditions on submatrices. We\nstudy these varieties for generic matrices, symmetric matrices, and upper\ntriangular matrices in view of two applications to algebraic statistics: we\nobserve that special conditional independence models for Gaussian random\nvariables are intersections of matrix Schubert varieties in the symmetric case.\nConsequently, we obtain a combinatorial primary decomposition algorithm for\nsome conditional independence ideals. We also characterize the vanishing ideals\nof Gaussian graphical models for generalized Markov chains.\n  In the course of this investigation, we are led to consider three related\nstratifications, which come from the Schubert stratification of a flag variety.\nWe provide some combinatorial results, including describing the stratifications\nusing the language of rank arrays and enumerating the strata in each case.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2015 14:45:57 GMT"}, {"version": "v2", "created": "Mon, 12 Sep 2016 21:13:12 GMT"}], "update_date": "2016-09-14", "authors_parsed": [["Fink", "Alex", ""], ["Rajchgot", "Jenna", ""], ["Sullivant", "Seth", ""]]}, {"id": "1510.04195", "submitter": "Alexander Luedtke", "authors": "Alexander R. Luedtke, Marco Carone and Mark J. van der Laan", "title": "An Omnibus Nonparametric Test of Equality in Distribution for Unknown\n  Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel family of nonparametric omnibus tests of the hypothesis\nthat two unknown but estimable functions are equal in distribution when applied\nto the observed data structure. We developed these tests, which represent a\ngeneralization of the maximum mean discrepancy tests described in Gretton et\nal. [2006], using recent developments from the higher-order pathwise\ndifferentiability literature. Despite their complex derivation, the associated\ntest statistics can be expressed rather simply as U-statistics. We study the\nasymptotic behavior of the proposed tests under the null hypothesis and under\nboth fixed and local alternatives. We provide examples to which our tests can\nbe applied and show that they perform well in a simulation study. As an\nimportant special case, our proposed tests can be used to determine whether an\nunknown function, such as the conditional average treatment effect, is equal to\nzero almost surely.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2015 16:43:26 GMT"}, {"version": "v2", "created": "Sat, 24 Oct 2015 22:32:30 GMT"}, {"version": "v3", "created": "Wed, 14 Jun 2017 00:03:58 GMT"}], "update_date": "2017-06-15", "authors_parsed": [["Luedtke", "Alexander R.", ""], ["Carone", "Marco", ""], ["van der Laan", "Mark J.", ""]]}, {"id": "1510.04222", "submitter": "Frederic Lavancier", "authors": "Christophe Biscio (LMJL), Fr\\'ed\\'eric Lavancier (LMJL, SERPICO)", "title": "Contrast estimation for parametric stationary determinantal point\n  processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study minimum contrast estimation for parametric stationary determi-nantal\npoint processes. These processes form a useful class of models for repulsive\n(or regular, or inhibitive) point patterns and are already applied in numerous\nstatistical applications. Our main focus is on minimum contrast methods based\non the Ripley's K-function or on the pair correlation function. Strong\nconsistency and asymptotic normality of theses procedures are proved under\ngeneral conditions that only concern the existence of the process and its\nregularity with respect to the parameters. A key ingredient of the proofs is\nthe recently established Brillinger mixing property of stationary determinantal\npoint processes. This work may be viewed as a complement to the study of Y.\nGuan and M. Sherman who establish the same kind of asymptotic properties for a\nlarge class of Cox processes, which in turn are models for clustering (or\naggregation).\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2015 18:14:48 GMT"}], "update_date": "2015-10-15", "authors_parsed": [["Biscio", "Christophe", "", "LMJL"], ["Lavancier", "Fr\u00e9d\u00e9ric", "", "LMJL, SERPICO"]]}, {"id": "1510.04342", "submitter": "Stefan Wager", "authors": "Stefan Wager and Susan Athey", "title": "Estimation and Inference of Heterogeneous Treatment Effects using Random\n  Forests", "comments": "To appear in the Journal of the American Statistical Association.\n  Part of the results developed in this paper were made available as an earlier\n  technical report \"Asymptotic Theory for Random Forests\", available at\n  (arXiv:1405.0352)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many scientific and engineering challenges -- ranging from personalized\nmedicine to customized marketing recommendations -- require an understanding of\ntreatment effect heterogeneity. In this paper, we develop a non-parametric\ncausal forest for estimating heterogeneous treatment effects that extends\nBreiman's widely used random forest algorithm. In the potential outcomes\nframework with unconfoundedness, we show that causal forests are pointwise\nconsistent for the true treatment effect, and have an asymptotically Gaussian\nand centered sampling distribution. We also discuss a practical method for\nconstructing asymptotic confidence intervals for the true treatment effect that\nare centered at the causal forest estimates. Our theoretical results rely on a\ngeneric Gaussian theory for a large family of random forest algorithms. To our\nknowledge, this is the first set of results that allows any type of random\nforest, including classification and regression forests, to be used for\nprovably valid statistical inference. In experiments, we find causal forests to\nbe substantially more powerful than classical methods based on nearest-neighbor\nmatching, especially in the presence of irrelevant covariates.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2015 22:54:59 GMT"}, {"version": "v2", "created": "Sat, 21 Nov 2015 00:38:23 GMT"}, {"version": "v3", "created": "Sat, 19 Nov 2016 04:08:22 GMT"}, {"version": "v4", "created": "Mon, 10 Jul 2017 01:15:47 GMT"}], "update_date": "2017-07-11", "authors_parsed": [["Wager", "Stefan", ""], ["Athey", "Susan", ""]]}, {"id": "1510.04351", "submitter": "Xiongzhi Chen", "authors": "Xiongzhi Chen and R.W. Doerge", "title": "Stopping time property of thresholds of Storey-type FDR procedures", "comments": "11 pages; extended Sections 3 and 4", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  For multiple testing, we introduce Storey-type FDR procedures and the concept\nof \"regular estimator of the proportion of true nulls\". We show that the\nrejection threshold of a Storey-type FDR procedure is a stopping time with\nrespect to the backward filtration generated by the p-values and that a\nStorey-type FDR estimator at this rejection threshold equals the pre-specified\nFDR level, when the estimator of the proportion of true nulls is regular. These\nresults hold regardless of the dependence among or the types of distributions\nof the p-values. They directly imply that a Storey-type FDR procedure is\nconservative when the null p-values are independent and uniformly distributed.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2015 23:42:56 GMT"}, {"version": "v2", "created": "Mon, 28 Mar 2016 13:35:52 GMT"}, {"version": "v3", "created": "Tue, 28 Jun 2016 23:02:58 GMT"}], "update_date": "2016-06-30", "authors_parsed": [["Chen", "Xiongzhi", ""], ["Doerge", "R. W.", ""]]}, {"id": "1510.04514", "submitter": "Vahed Maroufy", "authors": "Vahed Maroufy and Paul Marriott", "title": "Mixture Models: Building a Parameter Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the flexibility and popularity of mixture models, their associated\nparameter spaces are often difficult to represent due to fundamental\nidentification problems. This paper looks at a novel way of representing such a\nspace for general mixtures of exponential families, where the parameters are\nidentifiable, interpretable, and, due to a tractable geometric structure, the\nspace allows fast computational algorithms to be constructed.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2015 12:56:44 GMT"}], "update_date": "2015-10-16", "authors_parsed": [["Maroufy", "Vahed", ""], ["Marriott", "Paul", ""]]}, {"id": "1510.04638", "submitter": "Mathias Trabs", "authors": "Denis Belomestny and Mathias Trabs", "title": "Low-rank diffusion matrix estimation for high-dimensional time-changed\n  L\\'evy processes", "comments": "39 pages, 5 figures", "journal-ref": "Annales de l'Institut Henri Poincar\\'e, Probabilit\\'es et\n  Statistiques, 54 (3), 1583-1621, 2018", "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The estimation of the diffusion matrix $\\Sigma$ of a high-dimensional,\npossibly time-changed L\\'evy process is studied, based on discrete observations\nof the process with a fixed distance. A low-rank condition is imposed on\n$\\Sigma$. Applying a spectral approach, we construct a weighted least-squares\nestimator with nuclear-norm-penalisation. We prove oracle inequalities and\nderive convergence rates for the diffusion matrix estimator. The convergence\nrates show a surprising dependency on the rank of $\\Sigma$ and are optimal in\nthe minimax sense for fixed dimensions. Theoretical results are illustrated by\na simulation study.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2015 17:30:38 GMT"}, {"version": "v2", "created": "Mon, 3 Apr 2017 20:24:58 GMT"}], "update_date": "2018-11-05", "authors_parsed": [["Belomestny", "Denis", ""], ["Trabs", "Mathias", ""]]}, {"id": "1510.04654", "submitter": "Bernd Sturmfels", "authors": "Carlos Am\\'endola, Jean-Charles Faug\\`ere, and Bernd Sturmfels", "title": "Moment Varieties of Gaussian Mixtures", "comments": "17 pages, 2 figures", "journal-ref": null, "doi": "10.18409/jas.v7i1.42", "report-no": null, "categories": "math.AG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The points of a moment variety are the vectors of all moments up to some\norder of a family of probability distributions. We study this variety for\nmixtures of Gaussians. Following up on Pearson's classical work from 1894, we\napply current tools from computational algebra to recover the parameters from\nthe moments. Our moment varieties extend objects familiar to algebraic\ngeometers. For instance, the secant varieties of Veronese varieties are the\nloci obtained by setting all covariance matrices to zero. We compute the ideals\nof the 5-dimensional moment varieties representing mixtures of two univariate\nGaussians, and we offer a comparison to the maximum likelihood approach.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2015 18:21:32 GMT"}], "update_date": "2017-04-06", "authors_parsed": [["Am\u00e9ndola", "Carlos", ""], ["Faug\u00e8re", "Jean-Charles", ""], ["Sturmfels", "Bernd", ""]]}, {"id": "1510.04740", "submitter": "Edward Kennedy", "authors": "Edward H. Kennedy", "title": "Semiparametric theory and empirical processes in causal inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we review important aspects of semiparametric theory and\nempirical processes that arise in causal inference problems. We begin with a\nbrief introduction to the general problem of causal inference, and go on to\ndiscuss estimation and inference for causal effects under semiparametric\nmodels, which allow parts of the data-generating process to be unrestricted if\nthey are not of particular interest (i.e., nuisance functions). These models\nare very useful in causal problems because the outcome process is often complex\nand difficult to model, and there may only be information available about the\ntreatment process (at best). Semiparametric theory gives a framework for\nbenchmarking efficiency and constructing estimators in such settings. In the\nsecond part of the paper we discuss empirical process theory, which provides\npowerful tools for understanding the asymptotic behavior of semiparametric\nestimators that depend on flexible nonparametric estimators of nuisance\nfunctions. These tools are crucial for incorporating machine learning and other\nmodern methods into causal inference analyses. We conclude by examining related\nextensions and future directions for work in semiparametric causal inference.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2015 22:56:03 GMT"}, {"version": "v2", "created": "Wed, 20 Jul 2016 14:49:04 GMT"}, {"version": "v3", "created": "Fri, 22 Jul 2016 14:48:54 GMT"}], "update_date": "2016-07-25", "authors_parsed": [["Kennedy", "Edward H.", ""]]}, {"id": "1510.04968", "submitter": "Sergei Zuyev", "authors": "Alexey Lindo, Sergei Zuyev and Serik Sagitov", "title": "Nonparametric estimation of infinitely divisible distributions based on\n  variational analysis on measures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper develops new methods of non-parametric estimation a compound\nPoisson distribution. Such a problem arise, in particular, in the inference of\na Levy process recorded at equidistant time intervals. Our key estimator is\nbased on series decomposition of functionals of a measure and relies on the\nsteepest descent technique recently developed in variational analysis of\nmeasures. Simulation studies demonstrate applicability domain of our methods\nand how they positively compare and complement the existing techniques. They\nare particularly suited for discrete compounding distributions, not necessarily\nconcentrated on a grid nor on the positive or negative semi-axis. They also\ngive good results for continuous distributions provided an appropriate\nsmoothing is used for the obtained atomic measure.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2015 18:11:44 GMT"}], "update_date": "2015-10-19", "authors_parsed": [["Lindo", "Alexey", ""], ["Zuyev", "Sergei", ""], ["Sagitov", "Serik", ""]]}, {"id": "1510.04977", "submitter": "Kody Law", "authors": "Ajay Jasra, Kengo Kamatani, Kody J. H. Law, Yan Zhou", "title": "Multilevel particle filter", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO math.NA math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper the filtering of partially observed diffusions, with\ndiscrete-time observations, is considered. It is assumed that only biased\napproximations of the diffusion can be obtained, for choice of an accuracy\nparameter indexed by $l$. A multilevel estimator is proposed, consisting of a\ntelescopic sum of increment estimators associated to the successive levels. The\nwork associated to $\\mathcal{O}(\\varepsilon^2)$ mean-square error between the\nmultilevel estimator and average with respect to the filtering distribution is\nshown to scale optimally, for example as $\\mathcal{O}(\\varepsilon^{-2})$ for\noptimal rates of convergence of the underlying diffusion approximation. The\nmethod is illustrated on some toy examples as well as estimation of interest\nrate based on real S&P 500 stock price data.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2015 18:48:10 GMT"}], "update_date": "2015-10-19", "authors_parsed": [["Jasra", "Ajay", ""], ["Kamatani", "Kengo", ""], ["Law", "Kody J. H.", ""], ["Zhou", "Yan", ""]]}, {"id": "1510.05014", "submitter": "Marco Singer", "authors": "Marco Singer, Tatyana Krivobokova, Bert L. de Groot, Axel Munk", "title": "Partial least squares for dependent data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The partial least squares algorithm for dependent data realisations is\nconsidered. Consequences of ignoring the dependence for the algorithm\nperformance are studied both theoretically and in simulations. It is shown that\nignoring certain non-stationary dependence structures leads to inconsistent\nestimation. A simple modification of the partial least squares algorithm for\ndependent data is proposed and consistency of corresponding estimators is\nshown. A real-data example on protein dynamics llustrates a superior predictive\npower of the method and the practical relevance of the problem.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2015 20:17:12 GMT"}, {"version": "v2", "created": "Thu, 3 Mar 2016 22:21:38 GMT"}], "update_date": "2016-03-07", "authors_parsed": [["Singer", "Marco", ""], ["Krivobokova", "Tatyana", ""], ["de Groot", "Bert L.", ""], ["Munk", "Axel", ""]]}, {"id": "1510.05077", "submitter": "Satoshi Kuriki", "authors": "Xiaolei Lu, Satoshi Kuriki", "title": "Simultaneous confidence bands for contrasts between several nonlinear\n  regression curves", "comments": "34 pages, 6 figures", "journal-ref": "Journal of Multivariate Analysis, Volume 155, March 2017, Pages\n  83-104", "doi": "10.1016/j.jmva.2016.11.011", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose simultaneous confidence bands of the hyperbolic-type for the\ncontrasts between several nonlinear (curvilinear) regression curves. The\ncritical value of a confidence band is determined from the distribution of the\nmaximum of a chi-square random process defined on the domain of explanatory\nvariables. We use the volume-of-tube method to derive an upper tail probability\nformula of the maximum of a chi-square random process, which is asymptotically\nexact and sufficiently accurate in commonly used tail regions. Moreover, we\nprove that the formula obtained is equivalent to the expectation of the\nEuler-Poincare characteristic of the excursion set of the chi-square random\nprocess, and hence conservative. This result is therefore a generalization of\nNaiman's inequality for Gaussian random processes. As an illustrative example,\ngrowth curves of consomic mice are analyzed.\n", "versions": [{"version": "v1", "created": "Sat, 17 Oct 2015 06:27:26 GMT"}, {"version": "v2", "created": "Mon, 25 Apr 2016 02:48:28 GMT"}, {"version": "v3", "created": "Wed, 28 Sep 2016 01:45:08 GMT"}, {"version": "v4", "created": "Thu, 17 Nov 2016 07:39:05 GMT"}, {"version": "v5", "created": "Tue, 10 Jan 2017 09:53:54 GMT"}], "update_date": "2017-01-11", "authors_parsed": [["Lu", "Xiaolei", ""], ["Kuriki", "Satoshi", ""]]}, {"id": "1510.05247", "submitter": "Minwoo Chae", "authors": "Minwoo Chae", "title": "The semiparametric Bernstein-von Mises theorem for models with symmetric\n  error", "comments": "PhD thesis, 92 pages, 2 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a smooth semiparametric model, the marginal posterior distribution of the\nfinite dimensional parameter of interest is expected to be asymptotically\nequivalent to the sampling distribution of frequentist's efficient estimators.\nThis is the assertion of the so-called Bernstein-von Mises theorem, and\nrecently, it has been proved in many interesting semiparametric models. In this\nthesis, we consider the semiparametric Bernstein-von Mises theorem in some\nmodels which have symmetric errors. The simplest example of these models is the\nsymmetric location model that has 1-dimensional location parameter and unknown\nsymmetric error. Also, the linear regression and random effects models are\nincluded provided the error distribution is symmetric. The condition required\nfor nonparametric priors on the error distribution is very mild, and the most\nwell-known Dirichlet process mixture of normals works well. As a consequence,\nBayes estimators in these models satisfy frequentist criteria of optimality\nsuch as Hajek-Le Cam convolution theorem. The proof of the main result requires\nthat the expected log likelihood ratio has a certain quadratic expansion, which\nis a special property of symmetric densities. One of the main contribution of\nthis thesis is to provide an efficient estimator of regression coefficients in\nthe random effects model, in which it is unknown to estimate the coefficients\nefficiently because the full likelihood inference is difficult. Our theorems\nimply that the posterior mean or median is efficient, and the result from\nnumerical studies also shows the superiority of Bayes estimators. For practical\nuse of our main results, efficient Gibbs sampler algorithms based on\nsymmetrized Dirichlet process mixtures are provided.\n", "versions": [{"version": "v1", "created": "Sun, 18 Oct 2015 14:14:33 GMT"}], "update_date": "2015-10-20", "authors_parsed": [["Chae", "Minwoo", ""]]}, {"id": "1510.05261", "submitter": "Thomas Kahle", "authors": "Thomas Kahle and Kai-Friederike Oelbermann and Rainer Schwabe", "title": "Algebraic geometry of Poisson regression", "comments": "15 pages, 2 figures", "journal-ref": "Journal of Algebraic Statistics 7 (2016), pp. 29-44", "doi": "10.18409/jas.v7i1.43", "report-no": null, "categories": "math.ST math.OC stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing experiments for generalized linear models is difficult because\noptimal designs depend on unknown parameters. Here we investigate local\noptimality. We propose to study for a given design its region of optimality in\nparameter space. Often these regions are semi-algebraic and feature interesting\nsymmetries. We demonstrate this with the Rasch Poisson counts model. For any\ngiven interaction order between the explanatory variables we give a\ncharacterization of the regions of optimality of a special saturated design.\nThis extends known results from the case of no interaction. We also give an\nalgebraic and geometric perspective on optimality of experimental designs for\nthe Rasch Poisson counts model using polyhedral and spectrahedral geometry.\n", "versions": [{"version": "v1", "created": "Sun, 18 Oct 2015 15:32:26 GMT"}], "update_date": "2016-07-15", "authors_parsed": [["Kahle", "Thomas", ""], ["Oelbermann", "Kai-Friederike", ""], ["Schwabe", "Rainer", ""]]}, {"id": "1510.05314", "submitter": "Jinglai Shen", "authors": "Teresa M. Lebair and Jinglai Shen", "title": "Uniform Lipschitz Property of Nonnegative Derivative Constrained\n  B-Splines and Applications to Shape Constrained Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CA math.OC math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by shape constrained estimation under general nonnegative derivative\nconstraints, this paper considers the B-spline approximation of constrained\nfunctions and studies the asymptotic performance of the constrained B-spline\nestimator. By invoking a deep result in B-spline theory (known as de Boor's\nconjecture) first proved by A. Shardin as well as other new analytic\ntechniques, we establish a critical uniform Lipschitz property of the B-spline\nestimator subject to arbitrary nonnegative derivative constraints under the\n$\\ell_\\infty$-norm with possibly non-equally spaced design points and knots.\nThis property leads to important asymptotic analysis results of the B-spline\nestimator, e.g., the uniform convergence and consistency on the entire interval\nunder consideration. The results developed in this paper not only recover the\nwell-studied monotone and convex approximation and estimation as special cases,\nbut also treat general nonnegative derivative constraints in a unified\nframework and open the door for the constrained B-spline approximation and\nestimation subject to a broader class of shape constraints.\n", "versions": [{"version": "v1", "created": "Sun, 18 Oct 2015 21:59:27 GMT"}], "update_date": "2015-10-20", "authors_parsed": [["Lebair", "Teresa M.", ""], ["Shen", "Jinglai", ""]]}, {"id": "1510.05439", "submitter": "Arampatzis Georgios", "authors": "Georgios Arampatzis, Markos A. Katsoulakis, Luc Rey-Bellet", "title": "Efficient estimators for likelihood ratio sensitivity indices of complex\n  stochastic dynamics", "comments": "Revision of the paper. Added a new estimator", "journal-ref": null, "doi": "10.1063/1.4943388", "report-no": null, "categories": "math.NA math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate that centered likelihood ratio estimators for the sensitivity\nindices of complex stochastic dynamics are highly efficient with low, constant\nin time variance and consequently they are suitable for sensitivity analysis in\nlong-time and steady-state regimes. These estimators rely on a new covariance\nformulation of the likelihood ratio that includes as a submatrix a Fisher\nInformation Matrix for stochastic dynamics and can also be used for fast\nscreening of insensitive parameters and parameter combinations. The proposed\nmethods are applicable to broad classes of stochastic dynamics such as chemical\nreaction networks, Langevin-type equations and stochastic models in finance,\nincluding systems with a high dimensional parameter space and/or disparate\ndecorrelation times between different observables. Furthermore, they are simple\nto implement as a standard observable in any existing simulation algorithms\nwithout additional modifications.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2015 11:58:23 GMT"}, {"version": "v2", "created": "Tue, 23 Feb 2016 13:46:52 GMT"}], "update_date": "2016-03-23", "authors_parsed": [["Arampatzis", "Georgios", ""], ["Katsoulakis", "Markos A.", ""], ["Rey-Bellet", "Luc", ""]]}, {"id": "1510.05461", "submitter": "Justin Khim", "authors": "Justin Khim, Po-Ling Loh", "title": "Confidence Sets for the Source of a Diffusion in Regular Trees", "comments": "23 pages", "journal-ref": "IEEE Transactions on Network Science and Engineering ( Volume: 4,\n  Issue: 1, Jan.-March 1 2017 )", "doi": "10.1109/TNSE.2016.2627502", "report-no": null, "categories": "math.ST cs.DM cs.SI math.PR stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of identifying the source of a diffusion spreading over\na regular tree. When the degree of each node is at least three, we show that it\nis possible to construct confidence sets for the diffusion source with size\nindependent of the number of infected nodes. Our estimators are motivated by\nanalogous results in the literature concerning identification of the root node\nin preferential attachment and uniform attachment trees. At the core of our\nproofs is a probabilistic analysis of P\\'{o}lya urns corresponding to the\nnumber of uninfected neighbors in specific subtrees of the infection tree. We\nalso provide an example illustrating the shortcomings of source estimation\ntechniques in settings where the underlying graph is asymmetric.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2015 13:21:39 GMT"}], "update_date": "2018-08-08", "authors_parsed": [["Khim", "Justin", ""], ["Loh", "Po-Ling", ""]]}, {"id": "1510.05517", "submitter": "Shuheng Zhou", "authors": "Shuheng Zhou", "title": "Sparse Hanson-Wright inequalities for subgaussian quadratic forms", "comments": "29 pages; added full proof of Theorem 1.2 using moment generating\n  functions, which had appeared in TR 539, October 2015", "journal-ref": null, "doi": null, "report-no": "Technical Report 539, October 2015, Department of Statistics,\n  University of Michigan", "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we provide a proof for the Hanson-Wright inequalities for\nsparsified quadratic forms in subgaussian random variables. This provides\nuseful concentration inequalities for sparse subgaussian random vectors in two\nways. Let $X = (X_1, \\ldots, X_m) \\in \\mathbb{R}^m$ be a random vector with\nindependent subgaussian components, and $\\xi =(\\xi_1, \\ldots, \\xi_m) \\in \\{0,\n1\\}^m$ be independent Bernoulli random variables. We prove the large deviation\nbound for a sparse quadratic form of $(X \\circ \\xi)^T A (X \\circ \\xi)$, where\n$A \\in \\mathbb{R}^{m \\times m}$ is an $m \\times m$ matrix, and random vector $X\n\\circ \\xi$ denotes the Hadamard product of an isotropic subgaussian random\nvector $X \\in \\mathbb{R}^m$ and a random vector $\\xi \\in \\{0, 1\\}^m$ such that\n$(X \\circ \\xi)_{i} = X_{i} \\xi_i$, where $\\xi_1, \\ldots,\\xi_m$ are independent\nBernoulli random variables. The second type of sparsity in a quadratic form\ncomes from the setting where we randomly sample the elements of an anisotropic\nsubgaussian vector $Y = H X$ where $H \\in \\mathbb{R}^{m\\times m}$ is an $m\n\\times m$ symmetric matrix; we study the large deviation bound on the\n$\\ell_2$-norm of $D_{\\xi} Y$ from its expected value, where for a given vector\n$x \\in \\mathbb{R}^m$, $D_{x}$ denotes the diagonal matrix whose main diagonal\nentries are the entries of $x$. This form arises naturally from the context of\ncovariance estimation.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2015 15:11:32 GMT"}, {"version": "v2", "created": "Sun, 14 Feb 2016 15:09:10 GMT"}, {"version": "v3", "created": "Sun, 19 Feb 2017 05:03:23 GMT"}], "update_date": "2017-02-21", "authors_parsed": [["Zhou", "Shuheng", ""]]}, {"id": "1510.05526", "submitter": "Jakob S\\\"ohl", "authors": "Richard Nickl and Jakob S\\\"ohl", "title": "Nonparametric Bayesian posterior contraction rates for discretely\n  observed scalar diffusions", "comments": "44 pages", "journal-ref": "Ann. Statist. 45(4) (2017) 1664-1693", "doi": "10.1214/16-AOS1504", "report-no": null, "categories": "math.ST math.PR stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider nonparametric Bayesian inference in a reflected diffusion model\n$dX_t = b (X_t)dt + \\sigma(X_t) dW_t,$ with discretely sampled observations\n$X_0, X_\\Delta, \\dots, X_{n\\Delta}$. We analyse the nonlinear inverse problem\ncorresponding to the `low frequency sampling' regime where $\\Delta>0$ is fixed\nand $n \\to \\infty$. A general theorem is proved that gives conditions for prior\ndistributions $\\Pi$ on the diffusion coefficient $\\sigma$ and the drift\nfunction $b$ that ensure minimax optimal contraction rates of the posterior\ndistribution over H\\\"older-Sobolev smoothness classes. These conditions are\nverified for natural examples of nonparametric random wavelet series priors.\nFor the proofs we derive new concentration inequalities for empirical processes\narising from discretely observed diffusions that are of independent interest.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2015 15:18:10 GMT"}, {"version": "v2", "created": "Tue, 29 Mar 2016 13:30:30 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Nickl", "Richard", ""], ["S\u00f6hl", "Jakob", ""]]}, {"id": "1510.05677", "submitter": "Jonas Haslbeck", "authors": "Jonas M. B. Haslbeck, Lourens J. Waldorp", "title": "Structure estimation for mixed graphical models in high-dimensional data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Undirected graphical models are a key component in the analysis of complex\nobservational data in a large variety of disciplines. In many of these\napplications one is interested in estimating the undirected graphical model\nunderlying a distribution over variables with different domains. Despite the\npervasive need for such an estimation method, to date there is no such method\nthat models all variables on their proper domain. We close this methodological\ngap by combining a new class of mixed graphical models with a structure\nestimation approach based on generalized covariance matrices. We report the\nperformance of our methods using simulations, illustrate the method with a\ndataset on Autism Spectrum Disorder (ASD) and provide an implementation as an\nR-package.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2015 20:36:35 GMT"}], "update_date": "2015-10-21", "authors_parsed": [["Haslbeck", "Jonas M. B.", ""], ["Waldorp", "Lourens J.", ""]]}, {"id": "1510.06085", "submitter": "Robert Staudte", "authors": "Luke A. Prendergast and Robert G. Staudte", "title": "Quantile Versions of the Lorenz Curve", "comments": "28 pages, 9 figures", "journal-ref": null, "doi": "10.1214/16-EJS1154", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The classical Lorenz curve is often used to depict inequality in a population\nof incomes, and the associated Gini coefficient is relied upon to make\ncomparisons between different countries and other groups. The sample estimates\nof these moment-based concepts are sensitive to outliers and so we investigate\nthe extent to which quantile-based definitions can capture income inequality\nand lead to more robust procedures. Distribution-free estimates of the\ncorresponding coefficients of inequality are obtained, as well as sample sizes\nrequired to estimate them to a given accuracy. Convexity, transference and\nrobustness of the measures are examined and illustrated.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2015 23:07:55 GMT"}], "update_date": "2017-02-01", "authors_parsed": [["Prendergast", "Luke A.", ""], ["Staudte", "Robert G.", ""]]}, {"id": "1510.06207", "submitter": "Henryk Z\\\"ahle", "authors": "Eric Beutner and Henryk Z\\\"ahle", "title": "Functional delta-method for the bootstrap of quasi-Hadamard\n  differentiable functionals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The functional delta-method provides a convenient tool for deriving the\nasymptotic distribution of a plug-in estimator of a statistical functional from\nthe asymptotic distribution of the respective empirical process. Moreover, it\nprovides a tool to derive bootstrap consistency for plug-in estimators from\nbootstrap consistency of empirical processes. It has recently been shown that\nthe range of applications of the functional delta-method for the asymptotic\ndistribution can be considerably enlarged by employing the notion of\nquasi-Hadamard differentiability. Here we show in a general setting that this\nenlargement carries over to the bootstrap. That is, for quasi-Hadamard\ndifferentiable functionals bootstrap consistency of the plug-in estimator\nfollows from bootstrap consistency of the respective empirical process. This\nenlargement often requires convergence in distribution of the bootstrapped\nempirical process w.r.t.\\ a nonuniform sup-norm. The latter is not problematic\nas will be illustrated by means of examples.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2015 11:04:15 GMT"}, {"version": "v2", "created": "Mon, 25 Apr 2016 08:04:02 GMT"}, {"version": "v3", "created": "Wed, 4 May 2016 15:55:58 GMT"}], "update_date": "2016-05-05", "authors_parsed": [["Beutner", "Eric", ""], ["Z\u00e4hle", "Henryk", ""]]}, {"id": "1510.06301", "submitter": "Kory Johnson", "authors": "Kory D. Johnson and Robert A. Stine and Dean P. Foster", "title": "Submodularity in Statistics: Comparing the Success of Model Selection\n  Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate the usefulness of submodularity in statistics as a\ncharacterization of the difficulty of the \\emph{search} problem of feature\nselection. The search problem is the ability of a procedure to identify an\ninformative set of features as opposed to the performance of the optimal set of\nfeatures. Submodularity arises naturally in this setting due to its connection\nto combinatorial optimization. In statistics, submodularity isolates cases in\nwhich collinearity makes the choice of model features difficult from those in\nwhich this task is routine. Researchers often report the signal-to-noise ratio\nto measure the difficulty of simulated data examples. A measure of\nsubmodularity should also be provided as it characterizes an independent\ncomponent difficulty. Furthermore, it is closely related to other statistical\nassumptions used in the development of the Lasso, Dantzig selector, and sure\ninformation screening.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2015 15:36:54 GMT"}, {"version": "v2", "created": "Fri, 13 May 2016 14:37:10 GMT"}], "update_date": "2016-05-16", "authors_parsed": [["Johnson", "Kory D.", ""], ["Stine", "Robert A.", ""], ["Foster", "Dean P.", ""]]}, {"id": "1510.06307", "submitter": "Spyridon Hatjispyros", "authors": "Spyridon J. Hatjispyros, Theodoros Nicoleris, Stephen G. Walker", "title": "Bayesian Nonparametric Density Estimation under Length Bias", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A density estimation method in a Bayesian nonparametric framework is\npresented when recorded data are not coming directly from the distribution of\ninterest, but from a length biased version. From a Bayesian perspective,\nefforts to computationally evaluate posterior quantities conditionally on\nlength biased data were hindered by the inability to circumvent the problem of\na normalizing constant. In this paper we present a novel Bayesian nonparametric\napproach to the length bias sampling problem which circumvents the issue of the\nnormalizing constant. Numerical illustrations as well as a real data example\nare presented and the estimator is compared against its frequentist\ncounterpart, the kernel density estimator for indirect data of Jones (1991).\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2015 15:46:58 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2015 16:01:36 GMT"}], "update_date": "2015-10-23", "authors_parsed": [["Hatjispyros", "Spyridon J.", ""], ["Nicoleris", "Theodoros", ""], ["Walker", "Stephen G.", ""]]}, {"id": "1510.06319", "submitter": "Kory Johnson", "authors": "Kory D. Johnson, Dongyu Lin, Lyle H. Ungar, Dean P. Foster, and Robert\n  A. Stine", "title": "A Risk Ratio Comparison of $l_0$ and $l_1$ Penalized Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been an explosion of interest in using $l_1$-regularization in\nplace of $l_0$-regularization for feature selection. We present theoretical\nresults showing that while $l_1$-penalized linear regression never outperforms\n$l_0$-regularization by more than a constant factor, in some cases using an\n$l_1$ penalty is infinitely worse than using an $l_0$ penalty. We also show\nthat the \"optimal\" $l_1$ solutions are often inferior to $l_0$ solutions found\nusing stepwise regression.\n  We also compare algorithms for solving these two problems and show that\nalthough solutions can be found efficiently for the $l_1$ problem, the\n\"optimal\" $l_1$ solutions are often inferior to $l_0$ solutions found using\ngreedy classic stepwise regression. Furthermore, we show that solutions\nobtained by solving the convex $l_1$ problem can be improved by selecting the\nbest of the $l_1$ models (for different regularization penalties) by using an\n$l_0$ criterion. In other words, an approximate solution to the right problem\ncan be better than the exact solution to the wrong problem.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2015 16:13:36 GMT"}], "update_date": "2015-10-22", "authors_parsed": [["Johnson", "Kory D.", ""], ["Lin", "Dongyu", ""], ["Ungar", "Lyle H.", ""], ["Foster", "Dean P.", ""], ["Stine", "Robert A.", ""]]}, {"id": "1510.06395", "submitter": "Abdelfattah  Mustafa AM", "authors": "M.A. El-Damcese, Abdelfattah Mustafa, B.S. El-Desouky and M.E. Mustafa", "title": "The Odd Generalized Exponential Linear Failure Rate Distribution", "comments": "15 Pages, 9 Figures (15 Images), 3 Tables. arXiv admin note: text\n  overlap with arXiv:1507.06400", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a new lifetime model, called the odd generalized\nexponential linear failure rate distribution. Some statistical properties of\nthe proposed distribution such as the moments, the quantiles, the median, and\nthe mode are investigated. The method of maximum likelihood is used for\nestimating the model parameters. An applications to real data is carried out to\nillustrate that the new distribution is more flexible and effective than other\npopular distributions in modeling lifetime data.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2015 18:32:00 GMT"}], "update_date": "2015-10-28", "authors_parsed": [["El-Damcese", "M. A.", ""], ["Mustafa", "Abdelfattah", ""], ["El-Desouky", "B. S.", ""], ["Mustafa", "M. E.", ""]]}, {"id": "1510.06419", "submitter": "Thomas Sch\\\"urmann", "authors": "Thomas Sch\\\"urmann", "title": "A note on the best invariant estimation of continuous probability\n  distributions under mean square loss", "comments": "5 pages, 1 table, 2 figures, (typo corrected)", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.data-an math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the nonparametric estimation problem of continuous probability\ndistribution functions. For the integrated mean square error we provide the\nstatistic corresponding to the best invariant estimator proposed by Aggarwal\n(1955) and Ferguson (1967). The table of critical values is computed and a\nnumerical power comparison of the statistic with the traditional Cram\\'{e}r-von\nMises statistic is done for several representative distributions.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2015 20:16:40 GMT"}, {"version": "v2", "created": "Sat, 26 Aug 2017 13:25:15 GMT"}], "update_date": "2017-08-29", "authors_parsed": [["Sch\u00fcrmann", "Thomas", ""]]}, {"id": "1510.06940", "submitter": "Yannis Yatracos", "authors": "Yannis G. Yatracos", "title": "Plug-in error bounds for a mixing density estimate in $R^d,$ and for its\n  derivatives", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A mixture density, $f_p,$ is estimable in $R^d, \\ d \\ge 1,$ but an estimate\nfor the mixing density, $p,$ is usually obtained only when $d$ is unity; $h$ is\nthe mixture's kernel. When $f_p$'s estimate has form $f_{\\hat p_n}$ and $p$ is\n$\\tilde q$-smooth, vanishing outside a compact in $R^d,$ plug-in upper bounds\nare obtained herein for the $L_u$-error (and risk)of $\\hat p_n$ and its\nderivatives; $d \\ge 1, 1 \\le u \\le \\infty.$ The bounds depend on $f_{\\hat\np_n}$'s $L_u$-error (or risk), $h$'s Fourier transform, $\\tilde h,$ and the\nbandwidth of kernel $K$ used in approximations. The choice of $\\hat p_n,$ via\n$f_{\\hat p_n},$ suggests that $\\hat p_n$'s error rate could be only nearly\noptimal when $f_{\\hat p_n}$ is optimal, but competing estimates and their error\nrates may not be available for $d>1.$ In examples with $d$ unity, the upper\nbound is optimal when $h$ is super smooth, misses the optimal rate by the\nfactor $(\\log n)^{\\xi}, \\ \\xi>0,$ when $h$ is smooth, and is satisfactory when\n$\\tilde h$ has periodic zeros.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2015 19:27:38 GMT"}], "update_date": "2015-10-26", "authors_parsed": [["Yatracos", "Yannis G.", ""]]}, {"id": "1510.06946", "submitter": "Tobias Kley", "authors": "Jozef Barun\\'ik and Tobias Kley", "title": "Quantile Coherency: A General Measure for Dependence between Cyclical\n  Economic Variables", "comments": "paper (49 pages) and online supplement (31 pages), R codes to\n  replicate the figures in the paper are available at\n  https://github.com/tobiaskley/quantile_coherency_replication", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST q-fin.EC q-fin.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce quantile coherency to measure general dependence\nstructures emerging in the joint distribution in the frequency domain and argue\nthat this type of dependence is natural for economic time series but remains\ninvisible when only the traditional analysis is employed. We define estimators\nwhich capture the general dependence structure, provide a detailed analysis of\ntheir asymptotic properties and discuss how to conduct inference for a general\nclass of possibly nonlinear processes. In an empirical illustration we examine\nthe dependence of bivariate stock market returns and shed new light on\nmeasurement of tail risk in financial markets. We also provide a modelling\nexercise to illustrate how applied researchers can benefit from using quantile\ncoherency when assessing time series models.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2015 14:38:15 GMT"}, {"version": "v2", "created": "Thu, 27 Dec 2018 18:51:21 GMT"}], "update_date": "2018-12-31", "authors_parsed": [["Barun\u00edk", "Jozef", ""], ["Kley", "Tobias", ""]]}, {"id": "1510.06951", "submitter": "Kenric Nelson Ph.D.", "authors": "Kenric P. Nelson, Sabir Umarov, and Mark A. Kon", "title": "On the average uncertainty for systems with nonlinear coupling", "comments": "24 pages, including 4 figures and 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increased uncertainty and complexity of nonlinear systems have motivated\ninvestigators to consider generalized approaches to defining an entropy\nfunction. New insights are achieved by defining the average uncertainty in the\nprobability domain as a transformation of entropy functions. The Shannon\nentropy when transformed to the probability domain is the weighted geometric\nmean of the probabilities. For the exponential and Gaussian distributions, we\nshow that the weighted geometric mean of the distribution is equal to the\ndensity of the distribution at the location plus the scale, i.e. at the width\nof the distribution. The average uncertainty is generalized via the weighted\ngeneralized mean, in which the moment is a function of the nonlinear source.\nBoth the Renyi and Tsallis entropies transform to this definition of the\ngeneralized average uncertainty in the probability domain. For the generalized\nPareto and Student's t-distributions, which are the maximum entropy\ndistributions for these generalized entropies, the appropriate weighted\ngeneralized mean also equals the density of the distribution at the location\nplus scale. A coupled entropy function is proposed, which is equal to the\nnormalized Tsallis entropy divided by one plus the coupling.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2015 15:51:30 GMT"}, {"version": "v2", "created": "Fri, 6 Nov 2015 20:46:20 GMT"}, {"version": "v3", "created": "Fri, 6 May 2016 19:54:54 GMT"}], "update_date": "2016-05-09", "authors_parsed": [["Nelson", "Kenric P.", ""], ["Umarov", "Sabir", ""], ["Kon", "Mark A.", ""]]}, {"id": "1510.06963", "submitter": "Eli Ben-Naim", "authors": "E. Ben-Naim, P.L. Krapivsky, and N.W. Lemons", "title": "Scaling Exponents for Ordered Maxima", "comments": "10 pages, 6 figures", "journal-ref": "Phys. Rev. E 92, 062139 (2015)", "doi": "10.1103/PhysRevE.92.062139", "report-no": null, "categories": "cond-mat.stat-mech math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study extreme value statistics of multiple sequences of random variables.\nFor each sequence with N variables, independently drawn from the same\ndistribution, the running maximum is defined as the largest variable to date.\nWe compare the running maxima of m independent sequences, and investigate the\nprobability S_N that the maxima are perfectly ordered, that is, the running\nmaximum of the first sequence is always larger than that of the second\nsequence, which is always larger than the running maximum of the third\nsequence, and so on. The probability S_N is universal: it does not depend on\nthe distribution from which the random variables are drawn. For two sequences,\nS_N ~ N^(-1/2), and in general, the decay is algebraic, S_N ~ N^(-\\sigma_m),\nfor large N. We analytically obtain the exponent sigma_3= 1.302931 as root of a\ntranscendental equation. Furthermore, the exponents sigma_m grow with m, and we\nshow that sigma_m ~ m for large m.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2015 15:04:59 GMT"}], "update_date": "2015-12-30", "authors_parsed": [["Ben-Naim", "E.", ""], ["Krapivsky", "P. L.", ""], ["Lemons", "N. W.", ""]]}, {"id": "1510.07074", "submitter": "Max Tabord-Meehan", "authors": "Max Tabord-Meehan", "title": "Inference with Dyadic Data: Asymptotic Behavior of the Dyadic-Robust\n  t-Statistic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is concerned with inference in the linear model with dyadic data.\nDyadic data is data that is indexed by pairs of \"units\", for example trade data\nbetween pairs of countries. Because of the potential for observations with a\nunit in common to be correlated, standard inference procedures may not perform\nas expected. We establish a range of conditions under which a t-statistic with\nthe dyadic-robust variance estimator of Fafchamps and Gubert (2007) is\nasymptotically normal. Using our theoretical results as a guide, we perform a\nsimulation exercise to study the validity of the normal approximation, as well\nas the performance of a novel finite-sample correction. We conclude with\nguidelines for applied researchers wishing to use the dyadic-robust estimator\nfor inference.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2015 21:37:39 GMT"}, {"version": "v2", "created": "Fri, 14 Oct 2016 17:25:27 GMT"}, {"version": "v3", "created": "Thu, 23 Feb 2017 23:56:57 GMT"}, {"version": "v4", "created": "Sat, 11 Mar 2017 21:50:41 GMT"}, {"version": "v5", "created": "Sun, 28 May 2017 19:26:18 GMT"}, {"version": "v6", "created": "Mon, 20 Nov 2017 22:54:17 GMT"}], "update_date": "2017-11-22", "authors_parsed": [["Tabord-Meehan", "Max", ""]]}, {"id": "1510.07105", "submitter": "Wanli Qiao", "authors": "Wanli Qiao and Wolfgang Polonik", "title": "Theoretical Analysis of Nonparametric Filament Estimation", "comments": "55 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides a rigorous study of the nonparametric estimation of\nfilaments or ridge lines of a probability density $f$. Points on the filament\nare considered as local extrema of the density when traversing the support of\n$f$ along the integral curve driven by the vector field of second eigenvectors\nof the Hessian of $f$. We `parametrize' points on the filaments by such\nintegral curves, and thus both the estimation of integral curves and of\nfilaments will be considered via a plug-in method using kernel density\nestimation. We establish rates of convergence and asymptotic distribution\nresults for the estimation of both the integral curves and the filaments. The\nmain theoretical result establishes the asymptotic distribution of the uniform\ndeviation of the estimated filament from its theoretical counterpart. This\nresult utilizes the extreme value behavior of non-stationary Gaussian processes\nindexed by manifolds $M_h, h \\in(0,1]$ as $h \\to 0$.\n", "versions": [{"version": "v1", "created": "Sat, 24 Oct 2015 04:15:41 GMT"}], "update_date": "2015-10-27", "authors_parsed": [["Qiao", "Wanli", ""], ["Polonik", "Wolfgang", ""]]}, {"id": "1510.07123", "submitter": "Abhirup Datta", "authors": "Abhirup Datta and Hui Zou", "title": "CoCoLasso for High-dimensional Error-in-variables Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much theoretical and applied work has been devoted to high-dimensional\nregression with clean data. However, we often face corrupted data in many\napplications where missing data and measurement errors cannot be ignored. Loh\nand Wainwright (2012) proposed a non-convex modification of the Lasso for doing\nhigh-dimensional regression with noisy and missing data. It is generally agreed\nthat the virtues of convexity contribute fundamentally the success and\npopularity of the Lasso. In light of this, we propose a new method named\nCoCoLasso that is convex and can handle a general class of corrupted datasets\nincluding the cases of additive measurement error and random missing data. We\nestablish the estimation error bounds of CoCoLasso and its asymptotic\nsign-consistent selection property. We further elucidate how the standard cross\nvalidation techniques can be misleading in presence of measurement error and\ndevelop a novel corrected cross-validation technique by using the basic idea in\nCoCoLasso. The corrected cross-validation has its own importance. We\ndemonstrate the superior performance of our method over the non-convex approach\nby simulation studies.\n", "versions": [{"version": "v1", "created": "Sat, 24 Oct 2015 09:50:11 GMT"}, {"version": "v2", "created": "Fri, 1 Jan 2016 06:40:45 GMT"}], "update_date": "2016-01-05", "authors_parsed": [["Datta", "Abhirup", ""], ["Zou", "Hui", ""]]}, {"id": "1510.07129", "submitter": "Abhirup Datta", "authors": "Abhirup Datta, Hui Zou and Sudipto Banerjee", "title": "Bayesian Inference for High Dimensional Changing Linear Regression with\n  Application to Minnesota House Price Index Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many applications, the dataset under investigation exhibits heterogeneous\nregimes that are more appropriately modeled using piece-wise linear models for\neach of the data segments separated by change-points. Although there have been\nmuch work on change point linear regression for the low dimensional case,\nhigh-dimensional change point regression is severely underdeveloped. Motivated\nby the analysis of Minnesota House Price Index data, we propose a fully\nBayesian framework for fitting changing linear regression models in\nhigh-dimensional settings. Using segment-specific shrinkage and diffusion\npriors, we deliver full posterior inference for the change points and\nsimultaneously obtain posterior probabilities of variable selection in each\nsegment via an efficient Gibbs sampler. Additionally, our method can detect an\nunknown number of change points and accommodate different variable selection\nconstraints like grouping or partial selection. We substantiate the accuracy of\nour method using simulation experiments for a wide range of scenarios. We apply\nour approach for a macro-economic analysis of Minnesota house price index data.\nThe results strongly favor the change point model over a homogeneous (no change\npoint) high-dimensional regression model.\n", "versions": [{"version": "v1", "created": "Sat, 24 Oct 2015 10:28:14 GMT"}], "update_date": "2015-10-27", "authors_parsed": [["Datta", "Abhirup", ""], ["Zou", "Hui", ""], ["Banerjee", "Sudipto", ""]]}, {"id": "1510.07153", "submitter": "Spyridon Hatjispyros", "authors": "Spyridon J. Hatjispyros, Theodoros Nicoleris, Stephen G. Walker", "title": "Dependent Random Density Functions with Common Atoms and Pairwise\n  Dependence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper is concerned with constructing pairwise dependence between $m$\nrandom density functions each of which is modeled as a mixture of Dirichlet\nprocess model. The key to this is how to create dependencies between random\nDirichlet processes. The present paper adopts a plan previously used for\ncreating pairwise dependence, with the simplification that all random Dirichlet\nprocesses share the same atoms. Our contention is that for all dependent\nDirichlet process models, common atoms are sufficient.\n  We show that by adopting common atoms, it is possible to compute the $L_p$\ndistances between all pairs of random probability measures.\n", "versions": [{"version": "v1", "created": "Sat, 24 Oct 2015 15:06:54 GMT"}], "update_date": "2015-10-27", "authors_parsed": [["Hatjispyros", "Spyridon J.", ""], ["Nicoleris", "Theodoros", ""], ["Walker", "Stephen G.", ""]]}, {"id": "1510.07220", "submitter": "Edward Bormashenko", "authors": "G. Whyman, E. Shulzinger, Ed. Bormashenko", "title": "Intuitive Considerations Clarifying the Origin and Applicability of the\n  Benford Law", "comments": "12 pages, 2 Tables, 3 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The diverse applications of the Benford law attract investigators working in\nvarious fields of physics, biology and sociology. At the same time, the\ngroundings of the Benford law remain obscure. Our paper demonstrates that the\nBenford law arises from the positional (place-value) notation accepted for\nrepresenting various sets of data. An alternative to Benford formulae to\npredict the distribution of digits in statistical data are derived. Application\nof these formulae to the statistical analysis of infrared spectra of polymers\nis presented. Violations of the Benford Law are discussed.\n", "versions": [{"version": "v1", "created": "Sun, 25 Oct 2015 08:50:16 GMT"}, {"version": "v2", "created": "Wed, 18 Nov 2015 11:17:22 GMT"}], "update_date": "2015-11-19", "authors_parsed": [["Whyman", "G.", ""], ["Shulzinger", "E.", ""], ["Bormashenko", "Ed.", ""]]}, {"id": "1510.07228", "submitter": "Spyridon Hatjispyros", "authors": "Spyridon J. Hatjispyros, Theodoros Nicoleris, Stephen G. Walker", "title": "Distributional Results Relating to the Posterior of a Dirichlet Process\n  Prior", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of this paper is to find distributional results for the posterior\nparameters which arise in the Sethuraman (1994) representation of the Dirichlet\nprocess. These results can then be used to derive simply the posterior of the\nDirichlet process.\n", "versions": [{"version": "v1", "created": "Sun, 25 Oct 2015 09:52:57 GMT"}], "update_date": "2015-10-27", "authors_parsed": [["Hatjispyros", "Spyridon J.", ""], ["Nicoleris", "Theodoros", ""], ["Walker", "Stephen G.", ""]]}, {"id": "1510.07294", "submitter": "Sourav Chatterjee", "authors": "Sourav Chatterjee", "title": "High dimensional regression and matrix estimation without tuning\n  parameters", "comments": "23 pages, 1 figure. Minor corrections in this revision", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A general theory for Gaussian mean estimation that automatically adapts to\nunknown sparsity under arbitrary norms is proposed. The theory is applied to\nproduce adaptively minimax rate-optimal estimators in high dimensional\nregression and matrix estimation that involve no tuning parameters.\n", "versions": [{"version": "v1", "created": "Sun, 25 Oct 2015 19:44:15 GMT"}, {"version": "v2", "created": "Fri, 13 Nov 2015 05:01:49 GMT"}, {"version": "v3", "created": "Sat, 28 Nov 2015 06:23:21 GMT"}], "update_date": "2015-12-01", "authors_parsed": [["Chatterjee", "Sourav", ""]]}, {"id": "1510.07679", "submitter": "Shogo Kato Ph.D.", "authors": "Shogo Kato, Peter McCullagh", "title": "M\\\"obius transformation and a Cauchy family on the sphere", "comments": "30 pages, 2 figures", "journal-ref": "Bernoulli, 26(4), 3224-3248, 2020", "doi": "10.3150/20-BEJ1222", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present some properties of a Cauchy family of distributions on the sphere,\nwhich is a spherical extension of the wrapped Cauchy family on the circle. The\nspherical Cauchy family is closed under the M\\\"obius transformation on the\nsphere and there is a similar induced transformation on the parameter space.\nStereographic projection transforms the the spherical Cauchy family into a\nmultivariate $t$-family with a certain degree of freedom on Euclidean space.\nMany tractable properties of the spherical Cauchy are derived using the\nM\\\"obius transformation and stereographic projection. A method of moments\nestimator and an asymptotically efficient estimator are expressed in closed\nform. The maximum likelihood estimation is also straightforward.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2015 20:57:02 GMT"}, {"version": "v2", "created": "Tue, 28 Aug 2018 06:12:46 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Kato", "Shogo", ""], ["McCullagh", "Peter", ""]]}, {"id": "1510.07789", "submitter": "Jason Leung", "authors": "Jason Leung", "title": "Estimation of the r-th derivative of a density function by the tilted\n  kernel estimator", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of estimating the s-th derivative of a density\nfunction f by the tilted Kernel estimator introduced in Hall and Doosti (2012).\nThen we further show this estimator achieves the same convergence rate, in\nprobability, the wavelet estimators achieved as shown in Hall and Patil (1995).\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2015 07:08:32 GMT"}], "update_date": "2015-10-28", "authors_parsed": [["Leung", "Jason", ""]]}, {"id": "1510.08029", "submitter": "Pierre C. Bellec", "authors": "Pierre C. Bellec", "title": "Sharp oracle inequalities for Least Squares estimators in shape\n  restricted regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of Least Squares (LS) estimators is studied in isotonic,\nunimodal and convex regression. Our results have the form of sharp oracle\ninequalities that account for the model misspecification error. In isotonic and\nunimodal regression, the LS estimator achieves the nonparametric rate\n$n^{-2/3}$ as well as a parametric rate of order $k/n$ up to logarithmic\nfactors, where $k$ is the number of constant pieces of the true parameter.\n  In univariate convex regression, the LS estimator satisfies an adaptive risk\nbound of order $q/n$ up to logarithmic factors, where $q$ is the number of\naffine pieces of the true regression function. This adaptive risk bound holds\nfor any design points. While Guntuboyina and Sen (2013) established that the\nnonparametric rate of convex regression is of order $n^{-4/5}$ for equispaced\ndesign points, we show that the nonparametric rate of convex regression can be\nas slow as $n^{-2/3}$ for some worst-case design points. This phenomenon can be\nexplained as follows: Although convexity brings more structure than\nunimodality, for some worst-case design points this extra structure is\nuninformative and the nonparametric rates of unimodal regression and convex\nregression are both $n^{-2/3}$.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2015 18:55:32 GMT"}, {"version": "v2", "created": "Mon, 11 Jul 2016 07:39:32 GMT"}, {"version": "v3", "created": "Mon, 8 Aug 2016 00:05:33 GMT"}], "update_date": "2016-08-09", "authors_parsed": [["Bellec", "Pierre C.", ""]]}, {"id": "1510.08178", "submitter": "Xiaotian Zhu", "authors": "Xiaotian Zhu and David R. Hunter", "title": "Clustering Via Finite Nonparametric ICA Mixture Models", "comments": "23 pages, 5 figures, Adv Data Anal Classif (2018)", "journal-ref": null, "doi": "10.1007/s11634-018-0338-x", "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an extension of non-parametric multivariate finite mixture models\nby dropping the standard conditional independence assumption and incorporating\nthe independent component analysis (ICA) structure instead. We formulate an\nobjective function in terms of penalized smoothed Kullback Leibler distance and\nintroduce the nonlinear smoothed majorization-minimization independent\ncomponent analysis (NSMM-ICA) algorithm for optimizing this function and\nestimating the model parameters. We have implemented a practical version of\nthis algorithm, which utilizes the FastICA algorithm, in the R package icamix.\nWe illustrate this new methodology using several applications in unsupervised\nlearning and image processing.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2015 03:21:48 GMT"}, {"version": "v2", "created": "Fri, 6 Nov 2015 04:09:45 GMT"}, {"version": "v3", "created": "Mon, 10 Sep 2018 04:39:36 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Zhu", "Xiaotian", ""], ["Hunter", "David R.", ""]]}, {"id": "1510.08226", "submitter": "Yo Sheena", "authors": "Yo Sheena", "title": "Asymptotic expansion of the risk of maximum likelihood estimator with\n  respect to $\\alpha$-divergence as a measure of the difficulty of specifying a\n  parametric model -- with detailed proof", "comments": "93 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For a given parametric probability model, we consider the risk of the maximum\nlikelihood estimator with respect to $\\alpha$-divergence, which includes the\nspecial cases of Kullback--Leibler divergence, the Hellinger distance and\n$\\chi^2$ divergence. The asymptotic expansion of the risk is given with respect\nto sample sizes of up to order $n^{-2}$. Each term in the expansion is\nexpressed with the geometrical properties of the Riemannian manifold formed by\nthe parametric probability model. We attempt to measure the difficulty of\nspecifying a model through this expansion.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2015 08:56:46 GMT"}, {"version": "v10", "created": "Thu, 11 Oct 2018 12:32:06 GMT"}, {"version": "v2", "created": "Thu, 9 Jun 2016 12:00:43 GMT"}, {"version": "v3", "created": "Sat, 13 Aug 2016 23:31:21 GMT"}, {"version": "v4", "created": "Thu, 1 Dec 2016 05:30:43 GMT"}, {"version": "v5", "created": "Mon, 9 Jan 2017 08:06:24 GMT"}, {"version": "v6", "created": "Tue, 10 Jan 2017 05:14:11 GMT"}, {"version": "v7", "created": "Mon, 13 Mar 2017 13:51:15 GMT"}, {"version": "v8", "created": "Thu, 7 Sep 2017 10:22:06 GMT"}, {"version": "v9", "created": "Mon, 30 Jul 2018 01:40:43 GMT"}], "update_date": "2018-10-12", "authors_parsed": [["Sheena", "Yo", ""]]}, {"id": "1510.08240", "submitter": "Bruno Torresani", "authors": "H Omer (I2M), B Torr\\'esani (I2M)", "title": "Time-frequency and time-scale analysis of deformed stationary processes,\n  with application to non-stationary sound modeling", "comments": "Applied and Computational Harmonic Analysis, Elsevier, 2016,\n  \\&lt;10.1016/j.acha.2015.10.002\\&gt", "journal-ref": null, "doi": "10.1016/j.acha.2015.10.002", "report-no": null, "categories": "cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A class of random non-stationary signals termed timbre x dynamics is\nintroduced and studied. These signals are obtained by non-linear\ntransformations of sta-tionary random gaussian signals, in such a way that the\ntransformation can be approximated by translations in an appropriate\nrepresentation domain. In such situations, approximate maximum likelihood\nestimation techniques can be de-rived, which yield simultaneous estimation of\nthe transformation and the power spectrum of the underlying stationary signal.\nThis paper focuses on the case of modulation and time warping of station-ary\nsignals, and proposes and studies estimation algorithms (based on\ntime-frequency and time-scale representations respectively) for these\nquantities of interest. The proposed approach is validated on numerical\nsimulations on synthetic signals, and examples on real life car engine sounds.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2015 09:35:38 GMT"}], "update_date": "2015-10-29", "authors_parsed": [["Omer", "H", "", "I2M"], ["Torr\u00e9sani", "B", "", "I2M"]]}, {"id": "1510.08401", "submitter": "Subrata Chakraborty", "authors": "Laba Handique and Subrata Chakraborty", "title": "The Generalized Marshall-Olkin-Kumaraswamy-G family of distributions", "comments": "37 pages,4 figures, 1 Table. Version-II. Preprint. arXiv admin note:\n  text overlap with arXiv:1509.08108", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new family of distribution is proposed by using Kumaraswamy-G (Cordeiro and\nde Castro, 2011) distribution as the base line distribution in the Generalized\nMarshal-Olkin (Jayakumar and Mathew, 2008) Construction. A number of special\ncases are presented. By expanding the probability density function and the\nsurvival function as infinite series the proposed family is seen as infinite\nmixtures of the Kumaraswamy-G (Cordeiro and de Castro, 2011) distribution.\nDensity function and its series expansions for order statistics are also\nobtained. Order statistics, moments, moment generating function, R\\'enyi\nentropy, quantile function, random sample generation, asymptotes, shapes and\nstochastic orderings are also investigated. The methods of parameter estimation\nby method of maximum likelihood and method of moment are presented. Large\nsample standard error and confidence intervals for the mles are also discussed.\nOne real life application of comparative data fitting with some of the\nimportant sub models of the family and some other models is considered.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2015 18:15:11 GMT"}, {"version": "v2", "created": "Sun, 21 Aug 2016 18:57:03 GMT"}], "update_date": "2016-08-23", "authors_parsed": [["Handique", "Laba", ""], ["Chakraborty", "Subrata", ""]]}, {"id": "1510.08440", "submitter": "Diana Cai", "authors": "Diana Cai, Nathanael Ackerman, Cameron Freer", "title": "Priors on exchangeable directed graphs", "comments": "27 pages, 11 figures", "journal-ref": "Electronic Journal of Statistics 10 (2016), 3490-3515", "doi": "10.1214/16-EJS1185", "report-no": null, "categories": "math.ST stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Directed graphs occur throughout statistical modeling of networks, and\nexchangeability is a natural assumption when the ordering of vertices does not\nmatter. There is a deep structural theory for exchangeable undirected graphs,\nwhich extends to the directed case via measurable objects known as digraphons.\nUsing digraphons, we first show how to construct models for exchangeable\ndirected graphs, including special cases such as tournaments, linear orderings,\ndirected acyclic graphs, and partial orderings. We then show how to construct\npriors on digraphons via the infinite relational digraphon model (di-IRM), a\nnew Bayesian nonparametric block model for exchangeable directed graphs, and\ndemonstrate inference on synthetic data.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2015 19:59:13 GMT"}, {"version": "v2", "created": "Fri, 16 Dec 2016 16:22:19 GMT"}], "update_date": "2016-12-19", "authors_parsed": [["Cai", "Diana", ""], ["Ackerman", "Nathanael", ""], ["Freer", "Cameron", ""]]}, {"id": "1510.08534", "submitter": "Peng Ding", "authors": "Peng Ding and Tyler J. VanderWeele", "title": "The Differential Geometry of Homogeneity Spaces Across Effect Scales", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  If an effect measure is more homogeneous than others, then its value is more\nlikely to be stable across different subgroups or subpopulations. Therefore, it\nis of great importance to find a more homogeneous effect measure that allows\nfor transportability of research results. For a binary outcome, applied\nresearchers often claim that the risk difference is more heterogeneous than the\nrisk ratio or odds ratio, because they find, based on evidence from surveys of\nmeta-analyses, that the null hypotheses of homogeneity are rejected more often\nfor the risk difference than for the risk ratio and odds ratio. However, the\nevidence for these claims are far from satisfactory, because of different\nstatistical powers of the homogeneity tests under different effect scales. For\nbinary treatment, covariate and outcome, we theoretically quantify the\nhomogeneity of different effect scales. Because when homogeneity holds the four\noutcome probabilities lie in a three dimensional sub-space of the four\ndimensional space, we can use results from differential geometry to compute the\nvolumes of these three dimensional spaces to compare the relative homogeneity\nof the risk difference, risk ratio, and odds ratio. We demonstrate that the\nhomogeneity space for the risk difference has the smallest volume, and the\nhomogeneity space for the odds ratio has the largest volume, providing some\nfurther evidence for the previous claim that the risk difference is more\nheterogeneous than the risk ratio and odds ratio.\n", "versions": [{"version": "v1", "created": "Thu, 29 Oct 2015 01:19:32 GMT"}, {"version": "v2", "created": "Sat, 7 Nov 2015 20:34:09 GMT"}], "update_date": "2015-11-10", "authors_parsed": [["Ding", "Peng", ""], ["VanderWeele", "Tyler J.", ""]]}, {"id": "1510.08539", "submitter": "Keli Liu", "authors": "Keli Liu and Xiao-Li Meng", "title": "There is Individualized Treatment. Why Not Individualized Inference?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Doctors use statistics to advance medical knowledge; we use a medical analogy\nto introduce statistical inference \"from scratch\" and to highlight an\nimprovement. Your doctor, perhaps implicitly, predicts the effectiveness of a\ntreatment for you based on its performance in a clinical trial; the trial\npatients serve as controls for you. The same logic underpins statistical\ninference: to identify the best statistical procedure to use for a problem, we\nsimulate a set of control problems and evaluate candidate procedures on the\ncontrols. Now for the improvement: recent interest in\npersonalized/individualized medicine stems from the recognition that some\nclinical trial patients are better controls for you than others. Therefore,\ntreatment decisions for you should depend only on a subset of relevant\npatients. Individualized statistical inference implements this idea for control\nproblems (rather than patients). Its potential for improving data analysis\nmatches personalized medicine's for improving healthcare. The central\nissue--for both individualized medicine and individualized inference--is how to\nmake the right relevance robustness trade-off: if we exercise too much\njudgement in determining which controls are relevant, our inferences will not\nbe robust. How much is too much? We argue that the unknown answer is the Holy\nGrail of statistical inference.\n", "versions": [{"version": "v1", "created": "Thu, 29 Oct 2015 01:46:48 GMT"}], "update_date": "2015-11-29", "authors_parsed": [["Liu", "Keli", ""], ["Meng", "Xiao-Li", ""]]}, {"id": "1510.08547", "submitter": "Zhenhua Lin", "authors": "Zhenhua Lin, Jiguo Cao, Liangliang Wang and Haonan Wang", "title": "A Smooth and Locally Sparse Estimator for Functional Linear Regression\n  via Functional SCAD Penalty", "comments": "23 pages, 9 figures", "journal-ref": "Journal of Computational and Graphical Statistics, 2017, 26(2):\n  306--318", "doi": "10.1080/10618600.2016.1195273", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a new regularization technique called \"functional\nSCAD\". We then combine this technique with the smoothing spline method to\ndevelop a smooth and locally sparse (i.e., zero on some sub-regions) estimator\nfor the coefficient function in functional linear regression. The functional\nSCAD has a nice shrinkage property that enables our estimating procedure to\nidentify the null subregions of the coefficient function without over shrinking\nthe non-zero values of the coefficient function. Additionally, the smoothness\nof our estimated coefficient function is regularized by a roughness penalty\nrather than by controlling the number of knots. Our method is more\ntheoretically sound and is computationally simpler than the other available\nmethods. An asymptotic analysis shows that our estimator is consistent and can\nidentify the null region with the probability tending to one. Furthermore,\nsimulation studies show that our estimator has superior numerical performance.\nFinally, the practical merit of our method is demonstrated on two real\napplications.\n", "versions": [{"version": "v1", "created": "Thu, 29 Oct 2015 02:31:25 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Lin", "Zhenhua", ""], ["Cao", "Jiguo", ""], ["Wang", "Liangliang", ""], ["Wang", "Haonan", ""]]}, {"id": "1510.08661", "submitter": "Ching-Shui Cheng", "authors": "Ching-Shui Cheng, Ming-Hung Kao", "title": "Optimal experimental designs for fMRI via circulant biased weighing\n  designs", "comments": "Published at http://dx.doi.org/10.1214/15-AOS1352 in the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2015, Vol. 43, No. 6, 2565-2587", "doi": "10.1214/15-AOS1352", "report-no": "IMS-AOS-AOS1352", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Functional magnetic resonance imaging (fMRI) technology is popularly used in\nmany fields for studying how the brain reacts to mental stimuli. The\nidentification of optimal fMRI experimental designs is crucial for rendering\nprecise statistical inference on brain functions, but research on this topic is\nvery lacking. We develop a general theory to guide the selection of fMRI\ndesigns for estimating a hemodynamic response function (HRF) that models the\neffect over time of the mental stimulus, and for studying the comparison of two\nHRFs. We provide a useful connection between fMRI designs and circulant biased\nweighing designs, establish the statistical optimality of some well-known fMRI\ndesigns and identify several new classes of fMRI designs. Construction methods\nof high-quality fMRI designs are also given.\n", "versions": [{"version": "v1", "created": "Thu, 29 Oct 2015 12:09:54 GMT"}], "update_date": "2015-10-30", "authors_parsed": [["Cheng", "Ching-Shui", ""], ["Kao", "Ming-Hung", ""]]}, {"id": "1510.08683", "submitter": "Degui Li", "authors": "Degui Li, Yuan Ke, Wenyang Zhang", "title": "Model selection and structure specification in ultra-high dimensional\n  generalised semi-varying coefficient models", "comments": "Published at http://dx.doi.org/10.1214/15-AOS1356 in the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2015, Vol. 43, No. 6, 2676-2705", "doi": "10.1214/15-AOS1356", "report-no": "IMS-AOS-AOS1356", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the model selection and structure specification for\nthe generalised semi-varying coefficient models (GSVCMs), where the number of\npotential covariates is allowed to be larger than the sample size. We first\npropose a penalised likelihood method with the LASSO penalty function to obtain\nthe preliminary estimates of the functional coefficients. Then, using the\nquadratic approximation for the local log-likelihood function and the adaptive\ngroup LASSO penalty (or the local linear approximation of the group SCAD\npenalty) with the help of the preliminary estimation of the functional\ncoefficients, we introduce a novel penalised weighted least squares procedure\nto select the significant covariates and identify the constant coefficients\namong the coefficients of the selected covariates, which could thus specify the\nsemiparametric modelling structure. The developed model selection and structure\nspecification approach not only inherits many nice statistical properties from\nthe local maximum likelihood estimation and nonconcave penalised likelihood\nmethod, but also computationally attractive thanks to the computational\nalgorithm that is proposed to implement our method. Under some mild conditions,\nwe establish the asymptotic properties for the proposed model selection and\nestimation procedure such as the sparsity and oracle property. We also conduct\nsimulation studies to examine the finite sample performance of the proposed\nmethod, and finally apply the method to analyse a real data set, which leads to\nsome interesting findings.\n", "versions": [{"version": "v1", "created": "Thu, 29 Oct 2015 13:38:26 GMT"}], "update_date": "2015-10-30", "authors_parsed": [["Li", "Degui", ""], ["Ke", "Yuan", ""], ["Zhang", "Wenyang", ""]]}, {"id": "1510.08694", "submitter": "John H. J. Einmahl", "authors": "John H. J. Einmahl, Jun Li, Regina Y. Liu", "title": "Bridging centrality and extremity: Refining empirical data depth using\n  extreme value statistics", "comments": "Published at http://dx.doi.org/10.1214/15-AOS1359 in the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2015, Vol. 43, No. 6, 2738-2765", "doi": "10.1214/15-AOS1359", "report-no": "IMS-AOS-AOS1359", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical depth measures the centrality of a point with respect to a given\ndistribution or data cloud. It provides a natural center-outward ordering of\nmultivariate data points and yields a systematic nonparametric multivariate\nanalysis scheme. In particular, the half-space depth is shown to have many\ndesirable properties and broad applicability. However, the empirical half-space\ndepth is zero outside the convex hull of the data. This property has rendered\nthe empirical half-space depth useless outside the data cloud, and limited its\nutility in applications where the extreme outlying probability mass is the\nfocal point, such as in classification problems and control charts with very\nsmall false alarm rates. To address this issue, we apply extreme value\nstatistics to refine the empirical half-space depth in \"the tail.\" This\nprovides an important linkage between data depth, which is useful for inference\non centrality, and extreme value statistics, which is useful for inference on\nextremity. The refined empirical half-space depth can thus extend all its\nutilities beyond the data cloud, and hence broaden greatly its applicability.\nThe refined estimator is shown to have substantially improved upon the\nempirical estimator in theory and simulations. The benefit of this improvement\nis also demonstrated through the applications in classification and statistical\nprocess control.\n", "versions": [{"version": "v1", "created": "Thu, 29 Oct 2015 13:58:17 GMT"}], "update_date": "2015-10-30", "authors_parsed": [["Einmahl", "John H. J.", ""], ["Li", "Jun", ""], ["Liu", "Regina Y.", ""]]}, {"id": "1510.08699", "submitter": "Wei-Liem Loh", "authors": "Wei-Liem Loh", "title": "Estimating the smoothness of a Gaussian random field from irregularly\n  spaced data via higher-order quadratic variations", "comments": "Published at http://dx.doi.org/10.1214/15-AOS1365 in the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2015, Vol. 43, No. 6, 2766-2794", "doi": "10.1214/15-AOS1365", "report-no": "IMS-AOS-AOS1365", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article introduces a method for estimating the smoothness of a\nstationary, isotropic Gaussian random field from irregularly spaced data. This\ninvolves novel constructions of higher-order quadratic variations and the\nestablishment of the corresponding fixed-domain asymptotic theory. In\nparticular, we consider: (i) higher-order quadratic variations using\nnonequispaced line transect data, (ii) second-order quadratic variations from a\nsample of Gaussian random field observations taken along a smooth curve in\n${\\mathbb{R}}^2$, (iii) second-order quadratic variations based on deformed\nlattice data on ${\\mathbb{R}}^2$. Smoothness estimators are proposed that are\nstrongly consistent under mild assumptions. Simulations indicate that these\nestimators perform well for moderate sample sizes.\n", "versions": [{"version": "v1", "created": "Thu, 29 Oct 2015 14:13:08 GMT"}], "update_date": "2015-10-30", "authors_parsed": [["Loh", "Wei-Liem", ""]]}, {"id": "1510.08765", "submitter": "Peng Ding", "authors": "Peng Ding and Joseph K. Blitzstein", "title": "Representation for the Gauss-Laplace Transmutation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Under certain conditions, a symmetric unimodal continuous random variable\n$\\xi$ can be represented as a scale mixture of the standard Normal distribution\n$Z$, i.e., $\\xi = \\sqrt{W} Z$, where the mixing distribution $W$ is independent\nof $Z.$ It is well known that if the mixing distribution is inverse Gamma, then\n$\\xi$ is student's $t$ distribution. However, it is less well known that if the\nmixing distribution is Gamma, then $\\xi$ is a Laplace distribution. Several\nexisting proofs of the latter result rely on complex calculus and change of\nvariables in integrals. We offer two simple and intuitive proofs based on\nrepresentation and moment generating functions.\n", "versions": [{"version": "v1", "created": "Thu, 29 Oct 2015 16:28:00 GMT"}], "update_date": "2015-10-30", "authors_parsed": [["Ding", "Peng", ""], ["Blitzstein", "Joseph K.", ""]]}, {"id": "1510.08873", "submitter": "Didier Ch\\'etelat", "authors": "Didier Ch\\'etelat, Rajendran Narayanan and Martin T. Wells", "title": "On the Domain of Attraction of a Tracy-Widom Law with Applications to\n  Testing Multiple Largest Roots", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The greatest root statistic arises as the test statistic in several\nmultivariate analysis settings. Suppose there is a global null hypothesis that\nconsists of different independent sub-null hypotheses, and suppose the greatest\nroot statistic is used as the test statistic for each sub-null hypothesis. Such\nproblems may arise when conducting a batch MANOVA or several batches of\npairwise testing for equality of covariance matrices. Using the\nunion-intersection testing approach and by letting the problem dimension tend\nto infinity faster than the number of batches, we show that the global null can\nbe tested using a Gumbel distribution to approximate the critical values.\nAlthough the theoretical results are asymptotic, simulation studies indicate\nthat the approximations are very good even for small to moderate dimensions.\nThe results are general and can be applied in any setting where the greatest\nroot statistic is used, not just for the two methods we use for illustrative\npurposes.\n", "versions": [{"version": "v1", "created": "Thu, 29 Oct 2015 20:12:16 GMT"}], "update_date": "2015-11-02", "authors_parsed": [["Ch\u00e9telat", "Didier", ""], ["Narayanan", "Rajendran", ""], ["Wells", "Martin T.", ""]]}, {"id": "1510.08887", "submitter": "Yi-Kai Liu", "authors": "Shelby Kimmel and Yi-Kai Liu", "title": "Phase Retrieval Using Unitary 2-Designs", "comments": "21 pages; v3: minor revisions, to appear at SampTA 2017; v2:\n  rewritten to focus on phase retrieval, with new title, improved error bounds,\n  and numerics; v1: original version, titled \"Quantum Compressed Sensing Using\n  2-Designs\"", "journal-ref": "International Conference on Sampling Theory and Applications\n  (SampTA), July 3-7, 2017, Tallinn, Estonia, pp.345-349", "doi": "10.1109/SAMPTA.2017.8024414", "report-no": null, "categories": "quant-ph cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a variant of the phase retrieval problem, where vectors are\nreplaced by unitary matrices, i.e., the unknown signal is a unitary matrix U,\nand the measurements consist of squared inner products |Tr(C*U)|^2 with unitary\nmatrices C that are chosen by the observer. This problem has applications to\nquantum process tomography, when the unknown process is a unitary operation.\n  We show that PhaseLift, a convex programming algorithm for phase retrieval,\ncan be adapted to this matrix setting, using measurements that are sampled from\nunitary 4- and 2-designs. In the case of unitary 4-design measurements, we show\nthat PhaseLift can reconstruct all unitary matrices, using a near-optimal\nnumber of measurements. This extends previous work on PhaseLift using spherical\n4-designs.\n  In the case of unitary 2-design measurements, we show that PhaseLift still\nworks pretty well on average: it recovers almost all signals, up to a constant\nadditive error, using a near-optimal number of measurements. These 2-design\nmeasurements are convenient for quantum process tomography, as they can be\nimplemented via randomized benchmarking techniques. This is the first positive\nresult on PhaseLift using 2-designs.\n", "versions": [{"version": "v1", "created": "Thu, 29 Oct 2015 20:24:21 GMT"}, {"version": "v2", "created": "Wed, 15 Feb 2017 23:34:07 GMT"}, {"version": "v3", "created": "Fri, 12 May 2017 19:58:55 GMT"}], "update_date": "2018-03-07", "authors_parsed": [["Kimmel", "Shelby", ""], ["Liu", "Yi-Kai", ""]]}, {"id": "1510.08895", "submitter": "Guillaume Chauvet", "authors": "Guillaume Chauvet", "title": "Martingale central-limit theorems for pivotal sampling", "comments": "24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ordered pivotal sampling is one of the simplest algorithm to perform\nwithout-replacement unequal probability sampling. It has found uses in the\ncontext of longitudinal surveys and spatial sampling, and enables in particular\na good spatial balance of the selected units. In this work, we follow the\napproach proposed by Ohlsson~(1986), and apply a martingale central-limit\ntheorem to prove the asymptotic normality of the Horvitz-Thompson estimator\nunder a design-based approach, and under a model-assisted approach. In\nparticular, our model assumptions allow for correlations between values, which\nis of particular interest for applications in spatial sampling.\n", "versions": [{"version": "v1", "created": "Thu, 29 Oct 2015 20:45:06 GMT"}], "update_date": "2015-11-02", "authors_parsed": [["Chauvet", "Guillaume", ""]]}, {"id": "1510.08986", "submitter": "Matey Neykov", "authors": "Matey Neykov, Yang Ning, Jun S. Liu, Han Liu", "title": "A Unified Theory of Confidence Regions and Testing for High Dimensional\n  Estimating Equations", "comments": "67 pages, 2 tables, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new inferential framework for constructing confidence regions\nand testing hypotheses in statistical models specified by a system of high\ndimensional estimating equations. We construct an influence function by\nprojecting the fitted estimating equations to a sparse direction obtained by\nsolving a large-scale linear program. Our main theoretical contribution is to\nestablish a unified Z-estimation theory of confidence regions for high\ndimensional problems.\n  Different from existing methods, all of which require the specification of\nthe likelihood or pseudo-likelihood, our framework is likelihood-free. As a\nresult, our approach provides valid inference for a broad class of high\ndimensional constrained estimating equation problems, which are not covered by\nexisting methods.\n  Such examples include, noisy compressed sensing, instrumental variable\nregression, undirected graphical models, discriminant analysis and vector\nautoregressive models. We present detailed theoretical results for all these\nexamples. Finally, we conduct thorough numerical simulations, and a real\ndataset analysis to back up the developed theoretical results.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2015 07:07:17 GMT"}, {"version": "v2", "created": "Thu, 23 Jun 2016 01:56:21 GMT"}], "update_date": "2016-06-24", "authors_parsed": [["Neykov", "Matey", ""], ["Ning", "Yang", ""], ["Liu", "Jun S.", ""], ["Liu", "Han", ""]]}, {"id": "1510.09072", "submitter": "Giovanni Marchetti", "authors": "Giovanni M. Marchetti and Nanny Wermuth", "title": "Palindromic Bernoulli distributions", "comments": "17 pages, 1 figure, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce and study a subclass of joint Bernoulli distributions which has\nthe palindromic property. For such distributions the vector of joint\nprobabilities is unchanged when the order of the elements is reversed. We prove\nfor binary variables that the palindromic property is equivalent to zero\nconstraints on all odd-order interaction parameters, be it in parameterizations\nwhich are log-linear, linear or multivariate logistic. In particular, we derive\nthe one-to-one parametric transformations for these three types of model\nspecifications and give simple closed forms of maximum likelihood estimates.\nSome special cases and a case study are described.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2015 13:02:10 GMT"}, {"version": "v2", "created": "Thu, 5 May 2016 12:17:58 GMT"}], "update_date": "2016-05-06", "authors_parsed": [["Marchetti", "Giovanni M.", ""], ["Wermuth", "Nanny", ""]]}, {"id": "1510.09090", "submitter": "Holger Drees", "authors": "Holger Drees, Holger Rootz\\'en", "title": "Correction note to \"Limit Theorems for Empirical Processes of Cluster\n  Functionals\" [arXiv:0910.0343]", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We correct an error in a technical lemma of Drees and Rootz\\'en (2010)\n[arXiv:0910.0343] and discuss consequences for applications.\n", "versions": [{"version": "v1", "created": "Thu, 29 Oct 2015 09:33:30 GMT"}], "update_date": "2015-11-02", "authors_parsed": [["Drees", "Holger", ""], ["Rootz\u00e9n", "Holger", ""]]}, {"id": "1510.09219", "submitter": "Jiaming Xu", "authors": "Bruce Hajek and Yihong Wu and Jiaming Xu", "title": "Submatrix localization via message passing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.SI math.IT math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The principal submatrix localization problem deals with recovering a $K\\times\nK$ principal submatrix of elevated mean $\\mu$ in a large $n\\times n$ symmetric\nmatrix subject to additive standard Gaussian noise. This problem serves as a\nprototypical example for community detection, in which the community\ncorresponds to the support of the submatrix. The main result of this paper is\nthat in the regime $\\Omega(\\sqrt{n}) \\leq K \\leq o(n)$, the support of the\nsubmatrix can be weakly recovered (with $o(K)$ misclassification errors on\naverage) by an optimized message passing algorithm if $\\lambda = \\mu^2K^2/n$,\nthe signal-to-noise ratio, exceeds $1/e$. This extends a result by Deshpande\nand Montanari previously obtained for $K=\\Theta(\\sqrt{n}).$ In addition, the\nalgorithm can be extended to provide exact recovery whenever\ninformation-theoretically possible and achieve the information limit of exact\nrecovery as long as $K \\geq \\frac{n}{\\log n} (\\frac{1}{8e} + o(1))$. The total\nrunning time of the algorithm is $O(n^2\\log n)$.\n  Another version of the submatrix localization problem, known as noisy\nbiclustering, aims to recover a $K_1\\times K_2$ submatrix of elevated mean\n$\\mu$ in a large $n_1\\times n_2$ Gaussian matrix. The optimized message passing\nalgorithm and its analysis are adapted to the bicluster problem assuming\n$\\Omega(\\sqrt{n_i}) \\leq K_i \\leq o(n_i)$ and $K_1\\asymp K_2.$ A sharp\ninformation-theoretic condition for the weak recovery of both clusters is also\nidentified.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2015 19:51:18 GMT"}], "update_date": "2015-11-02", "authors_parsed": [["Hajek", "Bruce", ""], ["Wu", "Yihong", ""], ["Xu", "Jiaming", ""]]}]