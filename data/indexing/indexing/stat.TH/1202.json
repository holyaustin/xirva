[{"id": "1202.0048", "submitter": "Jonathan Tuke", "authors": "J. Tuke, G. F. V. Glonek, and P. J. Solomon", "title": "P-values, q-values and posterior probabilities for equivalence in\n  genomics studies", "comments": "26 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP math.ST q-bio.QM stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Equivalence testing is of emerging importance in genomics studies but has\nhitherto been little studied in this content. In this paper, we define the\nnotion of equivalence of gene expression and determine a `strength of evidence'\nmeasure for gene equivalence. It is common practice in genome-wide studies to\nrank genes according to observed gene-specific P-values or adjusted P-values,\nwhich are assumed to measure the strength of evidence against the null\nhypothesis of no differential gene expression. We show here, both empirically\nand formally, that the equivalence P-value does not satisfy the basic\nconsistency requirements for a valid strength of evidence measure for\nequivalence. This means that the widely-used q-value (Storey, 2002) defined for\neach gene to be the minimum positive false discovery rate that would result in\nthe inclusion of the corresponding P-value in the discovery set, cannot be\ntranslated to the equivalence testing framework. However, when represented as a\nposterior probability, we find that the q-value does satisfy some basic\nconsistency requirements needed to be a credible measure of evidence for\nequivalence. We propose a simple estimate for the q-value from posterior\nprobabilities of equivalence, and analyse data from a mouse stem cell\nmicroarray experiment which demonstrate the theory and methods presented here.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jan 2012 23:10:04 GMT"}], "update_date": "2012-02-03", "authors_parsed": [["Tuke", "J.", ""], ["Glonek", "G. F. V.", ""], ["Solomon", "P. J.", ""]]}, {"id": "1202.0193", "submitter": "Mihail-Ioan Pop", "authors": "Mihail-Ioan Pop", "title": "Maximum entropy estimation of probability distributions with Gaussian\n  conditions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.CO stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a method to computationally estimate the probability density\nfunction of a univariate random variable by applying the maximum entropy\nprinciple with some local conditions given by Gaussian functions. The\nestimation errors and optimal values of parameters are determined. Experimental\nresults are presented. The method estimates the distribution well if a large\nenough selection is used, typically at least 1 000 values. Compared to the\nclassical approach of entropy maximisation, local conditions allow improving\nestimation locally. The method is well suited for a heuristic optimisation\napproach.\n", "versions": [{"version": "v1", "created": "Wed, 1 Feb 2012 15:38:44 GMT"}, {"version": "v2", "created": "Tue, 19 Jun 2012 21:59:45 GMT"}], "update_date": "2012-06-21", "authors_parsed": [["Pop", "Mihail-Ioan", ""]]}, {"id": "1202.0258", "submitter": "Elisabeth Gassiat", "authors": "Dominique Bontemps (IMT), St\\'ephane Boucheron (LPMA), Elisabeth\n  Gassiat (LM-Orsay)", "title": "About adaptive coding on countable alphabets", "comments": null, "journal-ref": "IEEE Transactions on Information Theory 60, 2 (2014) 808-821", "doi": "10.1109/TIT.2013.2288914", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper sheds light on universal coding with respect to classes of\nmemoryless sources over a countable alphabet defined by an envelope function\nwith finite and non-decreasing hazard rate. We prove that the auto-censuring AC\ncode introduced by Bontemps (2011) is adaptive with respect to the collection\nof such classes. The analysis builds on the tight characterization of universal\nredundancy rate in terms of metric entropy % of small source classes by Opper\nand Haussler (1997) and on a careful analysis of the performance of the\nAC-coding algorithm. The latter relies on non-asymptotic bounds for maxima of\nsamples from discrete distributions with finite and non-decreasing hazard rate.\n", "versions": [{"version": "v1", "created": "Wed, 1 Feb 2012 19:58:06 GMT"}, {"version": "v2", "created": "Fri, 13 Sep 2013 10:06:11 GMT"}, {"version": "v3", "created": "Mon, 16 Sep 2013 06:46:05 GMT"}, {"version": "v4", "created": "Sun, 9 Mar 2014 19:33:47 GMT"}], "update_date": "2014-03-11", "authors_parsed": [["Bontemps", "Dominique", "", "IMT"], ["Boucheron", "St\u00e9phane", "", "LPMA"], ["Gassiat", "Elisabeth", "", "LM-Orsay"]]}, {"id": "1202.0391", "submitter": "Wei Liu", "authors": "Wei Liu, Yuhong Yang", "title": "Parametric or nonparametric? A parametricness index for model selection", "comments": "Published in at http://dx.doi.org/10.1214/11-AOS899 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2011, Vol. 39, No. 4, 2074-2102", "doi": "10.1214/11-AOS899", "report-no": "IMS-AOS-AOS899", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In model selection literature, two classes of criteria perform well\nasymptotically in different situations: Bayesian information criterion (BIC)\n(as a representative) is consistent in selection when the true model is finite\ndimensional (parametric scenario); Akaike's information criterion (AIC)\nperforms well in an asymptotic efficiency when the true model is infinite\ndimensional (nonparametric scenario). But there is little work that addresses\nif it is possible and how to detect the situation that a specific model\nselection problem is in. In this work, we differentiate the two scenarios\ntheoretically under some conditions. We develop a measure, parametricness index\n(PI), to assess whether a model selected by a potentially consistent procedure\ncan be practically treated as the true model, which also hints on AIC or BIC is\nbetter suited for the data for the goal of estimating the regression function.\nA consequence is that by switching between AIC and BIC based on the PI, the\nresulting regression estimator is simultaneously asymptotically efficient for\nboth parametric and nonparametric scenarios. In addition, we systematically\ninvestigate the behaviors of PI in simulation and real data and show its\nusefulness.\n", "versions": [{"version": "v1", "created": "Thu, 2 Feb 2012 09:34:19 GMT"}], "update_date": "2012-02-03", "authors_parsed": [["Liu", "Wei", ""], ["Yang", "Yuhong", ""]]}, {"id": "1202.0666", "submitter": "Franti\\v{s}ek Mat\\'u\\v{s}", "authors": "Imre Csisz\\'ar and Franti\\v{s}ek Mat\\'u\\v{s}", "title": "Generalized minimizers of convex integral functionals, Bregman distance,\n  Pythagorean identities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.IT math.IT math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Integral functionals based on convex normal integrands are minimized subject\nto finitely many moment constraints. The integrands are finite on the positive\nand infinite on the negative numbers, strictly convex but not necessarily\ndifferentiable. The minimization is viewed as a primal problem and studied\ntogether with a dual one in the framework of convex duality. The effective\ndomain of the value function is described by a conic core, a modification of\nthe earlier concept of convex core. Minimizers and generalized minimizers are\nexplicitly constructed from solutions of modified dual problems, not assuming\nthe primal constraint qualification. A generalized Pythagorean identity is\npresented using Bregman distance and a correction term for lack of essential\nsmoothness in integrands. Results are applied to minimization of Bregman\ndistances. Existence of a generalized dual solution is established whenever the\ndual value is finite, assuming the dual constraint qualification. Examples of\n`irregular' situations are included, pointing to the limitations of generality\nof certain key results.\n", "versions": [{"version": "v1", "created": "Fri, 3 Feb 2012 11:25:11 GMT"}, {"version": "v2", "created": "Tue, 4 Sep 2012 13:41:46 GMT"}], "update_date": "2012-09-05", "authors_parsed": [["Csisz\u00e1r", "Imre", ""], ["Mat\u00fa\u0161", "Franti\u0161ek", ""]]}, {"id": "1202.0696", "submitter": "Terry McConnell", "authors": "Trrry R. McConnell", "title": "Note on the One and Two-Sided Z Tests", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The one sided Z test of elementary statistics is more powerful than the\ntwo-sided test of the same size.\n", "versions": [{"version": "v1", "created": "Fri, 3 Feb 2012 13:21:50 GMT"}], "update_date": "2012-02-06", "authors_parsed": [["McConnell", "Trrry R.", ""]]}, {"id": "1202.0786", "submitter": "Vincent Vu", "authors": "Vincent Q. Vu and Jing Lei", "title": "Minimax Rates of Estimation for Sparse PCA in High Dimensions", "comments": "To appear in Proceedings of the 15th International Conference on\n  Artificial Intelligence and Statistics (AISTATS) 2012, La Palma, Canary\n  Islands. Volume 22 of JMLR: W&CP 22", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study sparse principal components analysis in the high-dimensional\nsetting, where $p$ (the number of variables) can be much larger than $n$ (the\nnumber of observations). We prove optimal, non-asymptotic lower and upper\nbounds on the minimax estimation error for the leading eigenvector when it\nbelongs to an $\\ell_q$ ball for $q \\in [0,1]$. Our bounds are sharp in $p$ and\n$n$ for all $q \\in [0, 1]$ over a wide class of distributions. The upper bound\nis obtained by analyzing the performance of $\\ell_q$-constrained PCA. In\nparticular, our results provide convergence rates for $\\ell_1$-constrained PCA.\n", "versions": [{"version": "v1", "created": "Fri, 3 Feb 2012 17:44:36 GMT"}, {"version": "v2", "created": "Mon, 6 Feb 2012 01:19:43 GMT"}], "update_date": "2012-02-07", "authors_parsed": [["Vu", "Vincent Q.", ""], ["Lei", "Jing", ""]]}, {"id": "1202.0909", "submitter": "Larry Goldstein", "authors": "Jay Bartroff and Larry Goldstein", "title": "A Berry-Esseen bound for the uniform multinomial occupancy model", "comments": "Typo corrected in abstract", "journal-ref": "Electronic Journal of Probability (2013), vol 18, article 27, pp.\n  1-29", "doi": "10.1214/EJP.v18-1983", "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The inductive size bias coupling technique and Stein's method yield a\nBerry-Esseen theorem for the number of urns having occupancy $d \\ge 2$ when $n$\nballs are uniformly distributed over $m$ urns. In particular, there exists a\nconstant $C$ depending only on $d$ such that $$ \\sup_{z \\in\n\\mathbb{R}}|P(W_{n,m} \\le z) -P(Z \\le z)| \\le C \\left(\n\\frac{1+(\\frac{n}{m})^3}{\\sigma_{n,m}} \\right) \\quad \\mbox{for all $n \\ge d$\nand $m \\ge 2$,} $$ where $W_{n,m}$ and $\\sigma_{n,m}^2$ are the standardized\ncount and variance, respectively, of the number of urns with $d$ balls, and $Z$\nis a standard normal random variable. Asymptotically, the bound is optimal up\nto constants if $n$ and $m$ tend to infinity together in a way such that $n/m$\nstays bounded.\n", "versions": [{"version": "v1", "created": "Sat, 4 Feb 2012 17:23:36 GMT"}, {"version": "v2", "created": "Mon, 18 Feb 2013 18:30:05 GMT"}, {"version": "v3", "created": "Mon, 25 Mar 2019 19:53:24 GMT"}, {"version": "v4", "created": "Sat, 30 Mar 2019 14:29:23 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Bartroff", "Jay", ""], ["Goldstein", "Larry", ""]]}, {"id": "1202.0943", "submitter": "Bertrand Iooss", "authors": "Matieyendou Lamboni (IMT), Bertrand Iooss (- M\\'ethodes d'Analyse\n  Stochastique des Codes et Traitements Num\\'eriques), Anne-Laure Popelin,\n  Fabrice Gamboa (IMT)", "title": "Derivative-based global sensitivity measures: general links with Sobol'\n  indices and numerical tests", "comments": null, "journal-ref": "Mathematics and Computers in Simulation 87 (2013) 45-54", "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The estimation of variance-based importance measures (called Sobol' indices)\nof the input variables of a numerical model can require a large number of model\nevaluations. It turns to be unacceptable for high-dimensional model involving a\nlarge number of input variables (typically more than ten). Recently, Sobol and\nKucherenko have proposed the Derivative-based Global Sensitivity Measures\n(DGSM), defined as the integral of the squared derivatives of the model output,\nshowing that it can help to solve the problem of dimensionality in some cases.\nWe provide a general inequality link between DGSM and total Sobol' indices for\ninput variables belonging to the class of Boltzmann probability measures, thus\nextending the previous results of Sobol and Kucherenko for uniform and normal\nmeasures. The special case of log-concave measures is also described. This link\nprovides a DGSM-based maximal bound for the total Sobol indices. Numerical\ntests show the performance of the bound and its usefulness in practice.\n", "versions": [{"version": "v1", "created": "Sun, 5 Feb 2012 07:30:01 GMT"}, {"version": "v2", "created": "Mon, 2 Jul 2012 06:37:47 GMT"}], "update_date": "2013-05-28", "authors_parsed": [["Lamboni", "Matieyendou", "", "IMT"], ["Iooss", "Bertrand", "", "- M\u00e9thodes d'Analyse\n  Stochastique des Codes et Traitements Num\u00e9riques"], ["Popelin", "Anne-Laure", "", "IMT"], ["Gamboa", "Fabrice", "", "IMT"]]}, {"id": "1202.0957", "submitter": "David Leonard", "authors": "David Leonard", "title": "Estimating a bivariate linear relationship", "comments": "27 pages, 7 figures", "journal-ref": "Bayesian Analysis (2011) 6: 727-754", "doi": "10.1214/11-BA627", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Solutions of the bivariate, linear errors-in-variables estimation problem\nwith unspecified errors are expected to be invariant under interchange and\nscaling of the coordinates. The appealing model of normally distributed true\nvalues and errors is unidentified without additional information. I propose a\nprior density that incorporates the fact that the slope and variance parameters\ntogether determine the covariance matrix of the unobserved true values but is\notherwise diffuse. The marginal posterior density of the slope is invariant to\ninterchange and scaling of the coordinates and depends on the data only through\nthe sample correlation coefficient and ratio of standard deviations. It covers\nthe interval between the two ordinary least squares estimates but diminishes\nrapidly outside of it. I introduce the R package leiv for computing the\nposterior density, and I apply it to examples in astronomy and method\ncomparison.\n", "versions": [{"version": "v1", "created": "Sun, 5 Feb 2012 12:36:21 GMT"}], "update_date": "2012-02-07", "authors_parsed": [["Leonard", "David", ""]]}, {"id": "1202.1058", "submitter": "Ting Yan", "authors": "Ting Yan and Xu Jinfeng", "title": "Approximating the inverse of a balanced symmetric matrix with positive\n  elements", "comments": "Major revisions, 8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For an $n\\times n$ balanced symmetric matrix $T=(t_{i,j})$ with positive\nelements satisfying $t_{i,i}= \\sum_{j\\neq i} t_{i,j}$ and certain bounding\nconditions, we propose to use the matrix $S=(s_{i,j})$ to approximate its\ninverse, where $s_{i,j}=\\delta_{i,j}/t_{i,i}-1/t_{..}$, $\\delta_{i,j}$ is the\nKronecker delta function, and $t_{..}=\\sum_{i,j=1 }^{n}(1-\\delta_{i,j})\nt_{i,j}$. An explicit bound on the approximation error is obtained, showing\nthat the inverse is well approximated to order $1/(n-1)^2$ uniformly.\n", "versions": [{"version": "v1", "created": "Mon, 6 Feb 2012 07:12:46 GMT"}, {"version": "v2", "created": "Tue, 12 Jun 2012 23:09:44 GMT"}, {"version": "v3", "created": "Sun, 26 Oct 2014 10:25:02 GMT"}], "update_date": "2014-10-28", "authors_parsed": [["Yan", "Ting", ""], ["Jinfeng", "Xu", ""]]}, {"id": "1202.1125", "submitter": "Peter Harremo\\\"es", "authors": "Peter Harremo\\\"es and G\\'abor Tusn\\'ady", "title": "Information Divergence is more chi squared distributed than the chi\n  squared statistics", "comments": "5 pages, accepted for presentation at ISIT 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT math.IT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For testing goodness of fit it is very popular to use either the chi square\nstatistic or G statistics (information divergence). Asymptotically both are chi\nsquare distributed so an obvious question is which of the two statistics that\nhas a distribution that is closest to the chi square distribution.\nSurprisingly, when there is only one degree of freedom it seems like the\ndistribution of information divergence is much better approximated by a chi\nsquare distribution than the chi square statistic. For random variables we\nintroduce a new transformation that transform several important distributions\ninto new random variables that are almost Gaussian. For the binomial\ndistributions and the Poisson distributions we formulate a general conjecture\nabout how close their transform are to the Gaussian. The conjecture is proved\nfor Poisson distributions.\n", "versions": [{"version": "v1", "created": "Mon, 6 Feb 2012 12:50:10 GMT"}, {"version": "v2", "created": "Sun, 17 Jun 2012 17:01:26 GMT"}], "update_date": "2012-06-19", "authors_parsed": [["Harremo\u00ebs", "Peter", ""], ["Tusn\u00e1dy", "G\u00e1bor", ""]]}, {"id": "1202.1212", "submitter": "Yaniv Plan", "authors": "Yaniv Plan and Roman Vershynin", "title": "Robust 1-bit compressed sensing and sparse logistic regression: A convex\n  programming approach", "comments": "25 pages, 1 figure, error fixed in Lemma 4.1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper develops theoretical results regarding noisy 1-bit compressed\nsensing and sparse binomial regression. We show that a single convex program\ngives an accurate estimate of the signal, or coefficient vector, for both of\nthese models. We demonstrate that an s-sparse signal in R^n can be accurately\nestimated from m = O(slog(n/s)) single-bit measurements using a simple convex\nprogram. This remains true even if each measurement bit is flipped with\nprobability nearly 1/2. Worst-case (adversarial) noise can also be accounted\nfor, and uniform results that hold for all sparse inputs are derived as well.\nIn the terminology of sparse logistic regression, we show that O(slog(n/s))\nBernoulli trials are sufficient to estimate a coefficient vector in R^n which\nis approximately s-sparse. Moreover, the same convex program works for\nvirtually all generalized linear models, in which the link function may be\nunknown. To our knowledge, these are the first results that tie together the\ntheory of sparse logistic regression to 1-bit compressed sensing. Our results\napply to general signal structures aside from sparsity; one only needs to know\nthe size of the set K where signals reside. The size is given by the mean width\nof K, a computable quantity whose square serves as a robust extension of the\ndimension.\n", "versions": [{"version": "v1", "created": "Mon, 6 Feb 2012 17:23:47 GMT"}, {"version": "v2", "created": "Fri, 6 Jul 2012 00:11:56 GMT"}, {"version": "v3", "created": "Thu, 19 Jul 2012 16:19:42 GMT"}], "update_date": "2012-07-20", "authors_parsed": [["Plan", "Yaniv", ""], ["Vershynin", "Roman", ""]]}, {"id": "1202.1242", "submitter": "Debashis Paul", "authors": "Debashis Paul and Iain M. Johnstone", "title": "Augmented sparse principal component analysis for high dimensional data", "comments": "This manuscript was written in 2007, and a version has been available\n  on the first author's website, but it is posted to arXiv now in its 2007\n  form. Revisions incorporating later work will be posted separately", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of estimating the leading eigenvectors of a\nhigh-dimensional population covariance matrix based on independent Gaussian\nobservations. We establish lower bounds on the rates of convergence of the\nestimators of the leading eigenvectors under $l^q$-sparsity constraints when an\n$l^2$ loss function is used. We also propose an estimator of the leading\neigenvectors based on a coordinate selection scheme combined with PCA and show\nthat the proposed estimator achieves the optimal rate of convergence under a\nsparsity regime. Moreover, we establish that under certain scenarios, the usual\nPCA achieves the minimax convergence rate.\n", "versions": [{"version": "v1", "created": "Mon, 6 Feb 2012 19:18:19 GMT"}], "update_date": "2012-02-07", "authors_parsed": [["Paul", "Debashis", ""], ["Johnstone", "Iain M.", ""]]}, {"id": "1202.1377", "submitter": "Peter B\\\"{u}hlmann", "authors": "Peter B\\\"uhlmann", "title": "Statistical significance in high-dimensional linear models", "comments": "Published in at http://dx.doi.org/10.3150/12-BEJSP11 the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2013, Vol. 19, No. 4, 1212-1242", "doi": "10.3150/12-BEJSP11", "report-no": "IMS-BEJ-BEJSP11", "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method for constructing p-values for general hypotheses in a\nhigh-dimensional linear model. The hypotheses can be local for testing a single\nregression parameter or they may be more global involving several up to all\nparameters. Furthermore, when considering many hypotheses, we show how to\nadjust for multiple testing taking dependence among the p-values into account.\nOur technique is based on Ridge estimation with an additional correction term\ndue to a substantial projection bias in high dimensions. We prove strong error\ncontrol for our p-values and provide sufficient conditions for detection: for\nthe former, we do not make any assumption on the size of the true underlying\nregression coefficients while regarding the latter, our procedure might not be\noptimal in terms of power. We demonstrate the method in simulated examples and\na real data application.\n", "versions": [{"version": "v1", "created": "Tue, 7 Feb 2012 09:16:33 GMT"}, {"version": "v2", "created": "Tue, 27 Nov 2012 07:47:10 GMT"}, {"version": "v3", "created": "Fri, 11 Oct 2013 07:08:22 GMT"}], "update_date": "2013-10-14", "authors_parsed": [["B\u00fchlmann", "Peter", ""]]}, {"id": "1202.1399", "submitter": "Claudio Durastanti", "authors": "Claudio Durastanti, Xiaohong Lan, Domenico Marinucci", "title": "Needlet-Whittle Estimates on the Unit Sphere", "comments": "48 pages, 2 figures", "journal-ref": "Electronic Journal of Statistics, 7, 597-646, (2013)", "doi": null, "report-no": null, "categories": "math.ST astro-ph.IM math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the asymptotic behaviour of needlets-based approximate maximum\nlikelihood estimators for the spectral parameters of Gaussian and isotropic\nspherical random fields. We prove consistency and asymptotic Gaussianity, in\nthe high-frequency limit, thus generalizing earlier results by Durastanti et\nal. (2011) based upon standard Fourier analysis on the sphere. The asymptotic\nresults are then illustrated by an extensive Monte Carlo study.\n", "versions": [{"version": "v1", "created": "Tue, 7 Feb 2012 12:01:49 GMT"}, {"version": "v2", "created": "Fri, 1 Mar 2013 11:12:59 GMT"}], "update_date": "2015-04-27", "authors_parsed": [["Durastanti", "Claudio", ""], ["Lan", "Xiaohong", ""], ["Marinucci", "Domenico", ""]]}, {"id": "1202.1574", "submitter": "Dayu Huang", "authors": "Dayu Huang and Sean Meyn", "title": "Classification with High-Dimensional Sparse Samples", "comments": "final draft submitted to ISIT 2012", "journal-ref": null, "doi": "10.1109/ISIT.2012.6283985", "report-no": null, "categories": "cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The task of the binary classification problem is to determine which of two\ndistributions has generated a length-$n$ test sequence. The two distributions\nare unknown; two training sequences of length $N$, one from each distribution,\nare observed. The distributions share an alphabet of size $m$, which is\nsignificantly larger than $n$ and $N$. How does $N,n,m$ affect the probability\nof classification error? We characterize the achievable error rate in a\nhigh-dimensional setting in which $N,n,m$ all tend to infinity, under the\nassumption that probability of any symbol is $O(m^{-1})$. The results are:\n  1. There exists an asymptotically consistent classifier if and only if\n$m=o(\\min\\{N^2,Nn\\})$. This extends the previous consistency result in [1] to\nthe case $N\\neq n$.\n  2. For the sparse sample case where $\\max\\{n,N\\}=o(m)$, finer results are\nobtained: The best achievable probability of error decays as $-\\log(P_e)=J\n\\min\\{N^2, Nn\\}(1+o(1))/m$ with $J>0$.\n  3. A weighted coincidence-based classifier has non-zero generalized error\nexponent $J$.\n  4. The $\\ell_2$-norm based classifier has J=0.\n", "versions": [{"version": "v1", "created": "Wed, 8 Feb 2012 01:32:24 GMT"}, {"version": "v2", "created": "Tue, 10 Apr 2012 01:07:07 GMT"}, {"version": "v3", "created": "Tue, 3 Jul 2012 14:49:39 GMT"}], "update_date": "2016-04-18", "authors_parsed": [["Huang", "Dayu", ""], ["Meyn", "Sean", ""]]}, {"id": "1202.1617", "submitter": "Matyas Barczy", "authors": "Matyas Barczy, Marton Ispany, Gyula Pap", "title": "Asymptotic behavior of CLS estimators for unstable INAR(2) models", "comments": "67 pages; the CLS estimator of the mean of the innovation has been\n  added", "journal-ref": "Scandinavian Journal of Statistics 41 (4), 2014, 866-892", "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper the asymptotic behavior of the conditional least squares\nestimators of the autoregressive parameters $(\\alpha,\\beta)$, of the stability\nparameter $\\varrho := \\alpha + \\beta$, and of the mean $\\mu$ of the innovation\n$\\vare_k$, $k \\in \\NN$, for an unstable integer-valued autoregressive process\n$X_k = \\alpha \\circ X_{k-1} + \\beta \\circ X_{k-2} + \\vare_k$, $k \\in \\NN$, is\ndescribed. The limit distributions and the scaling factors are different\naccording to the following three cases: (i) decomposable, (ii) indecomposable\nbut not positively regular, and (iii) positively regular models.\n", "versions": [{"version": "v1", "created": "Wed, 8 Feb 2012 07:54:18 GMT"}, {"version": "v2", "created": "Tue, 30 Jul 2013 14:15:23 GMT"}], "update_date": "2016-07-25", "authors_parsed": [["Barczy", "Matyas", ""], ["Ispany", "Marton", ""], ["Pap", "Gyula", ""]]}, {"id": "1202.1838", "submitter": "Filippo Palombi", "authors": "Filippo Palombi, Simona Toti and Romina Filippini", "title": "Numerical reconstruction of the covariance matrix of a spherically\n  truncated multinormal distribution", "comments": "36 pages, 10 figures. v2: sects. 2 and 7 have been added, sect. 3 has\n  been revised. Results unchanged", "journal-ref": "J. Prob. Stat. Vol. 2017 (2017), Art. ID 6579537, 24 pages", "doi": "10.1155/2017/6579537", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we relate the matrix $S_B$ of the second moments of a\nspherically truncated normal multivariate to its full covariance matrix\n$\\Sigma$ and present an algorithm to invert the relation and reconstruct\n$\\Sigma$ from $S_B$. While the eigenvectors of $\\Sigma$ are left invariant by\nthe truncation, its eigenvalues are non-uniformly damped. We show that the\neigenvalues of $\\Sigma$ can be reconstructed from their truncated counterparts\nvia a fixed point iteration, whose convergence we prove analytically. The\nprocedure requires the computation of multidimensional Gaussian integrals over\na Euclidean ball, for which we extend a numerical technique, originally\nproposed by Ruben in 1962, based on a series expansion in chi-square\ndistributions. In order to study the feasibility of our approach, we examine\nthe convergence rate of some iterative schemes on suitably chosen ensembles of\nWishart matrices. We finally discuss the practical difficulties arising in\nsample space and outline a regularization of the problem based on perturbation\ntheory.\n", "versions": [{"version": "v1", "created": "Wed, 8 Feb 2012 21:34:19 GMT"}, {"version": "v2", "created": "Fri, 18 Apr 2014 13:06:21 GMT"}], "update_date": "2017-01-12", "authors_parsed": [["Palombi", "Filippo", ""], ["Toti", "Simona", ""], ["Filippini", "Romina", ""]]}, {"id": "1202.1928", "submitter": "Tim Sullivan", "authors": "T. J. Sullivan, M. McKerns, D. Meyer, F. Theil, H. Owhadi, and M.\n  Ortiz", "title": "Optimal uncertainty quantification for legacy data observations of\n  Lipschitz functions", "comments": "38 pages", "journal-ref": "ESAIM Math. Model. Numer. Anal. 47(6):1657--1689, 2013", "doi": "10.1051/m2an/2013083", "report-no": null, "categories": "math.PR cs.NA math.ST stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of providing optimal uncertainty quantification (UQ)\n--- and hence rigorous certification --- for partially-observed functions. We\npresent a UQ framework within which the observations may be small or large in\nnumber, and need not carry information about the probability distribution of\nthe system in operation. The UQ objectives are posed as optimization problems,\nthe solutions of which are optimal bounds on the quantities of interest; we\nconsider two typical settings, namely parameter sensitivities (McDiarmid\ndiameters) and output deviation (or failure) probabilities. The solutions of\nthese optimization problems depend non-trivially (even non-monotonically and\ndiscontinuously) upon the specified legacy data. Furthermore, the extreme\nvalues are often determined by only a few members of the data set; in our\nprincipal physically-motivated example, the bounds are determined by just 2 out\nof 32 data points, and the remainder carry no information and could be\nneglected without changing the final answer. We propose an analogue of the\nsimplex algorithm from linear programming that uses these observations to offer\nefficient and rigorous UQ for high-dimensional systems with high-cardinality\nlegacy data. These findings suggest natural methods for selecting optimal\n(maximally informative) next experiments.\n", "versions": [{"version": "v1", "created": "Thu, 9 Feb 2012 09:43:49 GMT"}, {"version": "v2", "created": "Thu, 24 Jan 2013 23:39:46 GMT"}, {"version": "v3", "created": "Sat, 13 Apr 2013 04:25:43 GMT"}], "update_date": "2016-05-20", "authors_parsed": [["Sullivan", "T. J.", ""], ["McKerns", "M.", ""], ["Meyer", "D.", ""], ["Theil", "F.", ""], ["Owhadi", "H.", ""], ["Ortiz", "M.", ""]]}, {"id": "1202.1964", "submitter": "Lutz Duembgen", "authors": "Lutz Duembgen", "title": "(Ab)Using Regression for Data Adjustment", "comments": "Replaces an older manuscript \"On Ranks of Regression Errors and\n  Residuals\"", "journal-ref": null, "doi": null, "report-no": "Technical report 78, IMSV, Univ. of Bern", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In various economic applications, people want to compare $n$ units with\nrespect to certain quantities $Y_1, Y_2, \\ldots, Y_n$ measuring their\nperformance. The latter, however, is often influenced by certain factors which\nare beyond control of the units, and one would like to extract an adjusted\nperformance from the data. Specifically, let $X_i \\in \\mathcal{X}$ summarize\nthe factors of the $i$-th unit. Then one could think of a model equation $Y_i =\nf_o(X_i) + \\epsilon_i$ with a regression function $f_o : \\mathcal{X} \\to\n\\mathbb{R}$ describing the unavoidable influence of the factors $X_i$ and\n$\\epsilon_i$ being the adjusted performance of the $i$-th unit. Now a common\nproposal is to estimate $f_o$ via regression methods by a function $\\hat{f}$\ndepending on the current data $(X_i,Y_i)$, possibly augmented by additional\npast data, and to use the residuals $\\hat{\\epsilon}_i := Y_i - \\hat{f}(X_i)$ as\nsurrogates for the adjusted performances $\\epsilon_i$. In the present report we\ndiscuss this approach, its potential pitfalls and (mis)interpretation. In\nparticular, an unavoidable property of the residuals $\\hat{\\epsilon}_i$ is that\nthey measure only parts of the adjusted performance while the remaining parts\nget hidden in the estimated function $\\hat{f}$. Possible alternatives are\nmentioned briefly.\n", "versions": [{"version": "v1", "created": "Thu, 9 Feb 2012 12:28:17 GMT"}, {"version": "v2", "created": "Mon, 27 Feb 2012 07:03:41 GMT"}, {"version": "v3", "created": "Thu, 11 Aug 2016 14:49:56 GMT"}, {"version": "v4", "created": "Wed, 24 Aug 2016 13:43:03 GMT"}, {"version": "v5", "created": "Mon, 19 Sep 2016 08:43:32 GMT"}, {"version": "v6", "created": "Thu, 29 Sep 2016 04:42:30 GMT"}], "update_date": "2016-09-30", "authors_parsed": [["Duembgen", "Lutz", ""]]}, {"id": "1202.2035", "submitter": "Thomas Laloe", "authors": "Elena Di Bernadino (SAF), Thomas Lalo\\\"e (JAD)", "title": "Estimating level sets of a distribution function using a plug-in method:\n  a multidimensional extension", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with the problem of estimating the level sets $L(c)= \\{F(x)\n\\geq c \\}$, with $c \\in (0,1)$, of an unknown distribution function $F$ on\n\\mathbb{R}^d_+$. A plug-in approach is followed. That is, given a consistent\nestimator $F_n$ of $F$, we estimate $L(c)$ by $L_n(c)= \\{F_n(x) \\geq c \\}$. We\nstate consistency results with respect to the Hausdorff distance and the volume\nof the symmetric difference. These results can be considered as generalizations\nof results previously obtained, in a bivariate framework, in Di Bernardino et\nal. (2011). Finally we investigate the effects of scaling data on our\nconsistency results.\n", "versions": [{"version": "v1", "created": "Thu, 9 Feb 2012 16:19:43 GMT"}], "update_date": "2012-02-13", "authors_parsed": [["Di Bernadino", "Elena", "", "SAF"], ["Lalo\u00eb", "Thomas", "", "JAD"]]}, {"id": "1202.2045", "submitter": "Juergen Laeuter", "authors": "Juergen Laeuter, Maciej Rosolowski and Ekkehard Glimm", "title": "Exact Multivariate Tests - A New Effective Principle of Controlled Model\n  Choice", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-dimensional tests are applied to find relevant sets of variables and\nrelevant models. If variables are selected by analyzing the sums of products\nmatrices and a corresponding mean-value test is performed, there is the danger\nthat the nominal error of first kind is exceeded. In the paper, well-known\nmultivariate tests receive a new mathematical interpretation such that the\nerror of first kind of the combined testing and selecting procedure can more\neasily be kept. The null hypotheses on mean values are replaced by hypotheses\non distributional sphericity of the individual score responses. Thus, model\nchoice is possible without too strong restrictions. The method is presented for\nall linear multivariate designs. It is illustrated by an example from\nbioinformatics: The selection of gene sets for the comparison of groups of\npatients suffering from B-cell lymphomas.\n", "versions": [{"version": "v1", "created": "Thu, 9 Feb 2012 16:54:17 GMT"}], "update_date": "2012-02-10", "authors_parsed": [["Laeuter", "Juergen", ""], ["Rosolowski", "Maciej", ""], ["Glimm", "Ekkehard", ""]]}, {"id": "1202.2211", "submitter": "Romain Aza\\\"is", "authors": "Romain Aza\\\"is, Fran\\c{c}ois Dufour, and Anne G\\'egout-Petit", "title": "Nonparametric estimation of the jump rate for non-homogeneous marked\n  renewal processes", "comments": null, "journal-ref": null, "doi": "10.1214/12-AIHP503", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is devoted to the nonparametric estimation of the jump rate and\nthe cumulative rate for a general class of non-homogeneous marked renewal\nprocesses, defined on a separable metric space. In our framework, the\nestimation needs only one observation of the process within a long time. Our\napproach is based on a generalization of the multiplicative intensity model,\nintroduced by Aalen in the seventies. We provide consistent estimators of these\ntwo functions, under some assumptions related to the ergodicity of an embedded\nchain and the characteristics of the process. The paper is illustrated by a\nnumerical example.\n", "versions": [{"version": "v1", "created": "Fri, 10 Feb 2012 08:44:41 GMT"}, {"version": "v2", "created": "Thu, 13 Sep 2012 08:55:10 GMT"}], "update_date": "2015-06-04", "authors_parsed": [["Aza\u00efs", "Romain", ""], ["Dufour", "Fran\u00e7ois", ""], ["G\u00e9gout-Petit", "Anne", ""]]}, {"id": "1202.2212", "submitter": "Romain Aza\\\"is", "authors": "Romain Aza\\\"is, Fran\\c{c}ois Dufour, and Anne G\\'egout-Petit", "title": "Nonparametric estimation of the conditional distribution of the\n  inter-jumping times for piecewise-deterministic Markov processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a nonparametric method for estimating the conditional\ndensity associated to the jump rate of a piecewise-deterministic Markov\nprocess. In our framework, the estimation needs only one observation of the\nprocess within a long time interval. Our method relies on a generalization of\nAalen's multiplicative intensity model. We prove the uniform consistency of our\nestimator, under some reasonable assumptions related to the primitive\ncharacteristics of the process. A simulation example illustrates the behavior\nof our estimator.\n", "versions": [{"version": "v1", "created": "Fri, 10 Feb 2012 08:51:49 GMT"}, {"version": "v2", "created": "Wed, 11 Jul 2012 10:09:04 GMT"}], "update_date": "2012-07-12", "authors_parsed": [["Aza\u00efs", "Romain", ""], ["Dufour", "Fran\u00e7ois", ""], ["G\u00e9gout-Petit", "Anne", ""]]}, {"id": "1202.2277", "submitter": "Junya Honda", "authors": "Junya Honda, Akimichi Takemura", "title": "Finite-time Regret Bound of a Bandit Algorithm for the Semi-bounded\n  Support Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider stochastic multiarmed bandit problems. Recently a\npolicy, DMED, is proposed and proved to achieve the asymptotic bound for the\nmodel that each reward distribution is supported in a known bounded interval,\ne.g. [0,1]. However, the derived regret bound is described in an asymptotic\nform and the performance in finite time has been unknown. We inspect this\npolicy and derive a finite-time regret bound by refining large deviation\nprobabilities to a simple finite form. Further, this observation reveals that\nthe assumption on the lower-boundedness of the support is not essential and can\nbe replaced with a weaker one, the existence of the moment generating function.\n", "versions": [{"version": "v1", "created": "Fri, 10 Feb 2012 15:00:53 GMT"}, {"version": "v2", "created": "Fri, 17 Feb 2012 06:55:04 GMT"}], "update_date": "2012-02-20", "authors_parsed": [["Honda", "Junya", ""], ["Takemura", "Akimichi", ""]]}, {"id": "1202.2395", "submitter": "Bernd Sing", "authors": "Peter S. Chami, Bernd Sing, and Doneal Thomas", "title": "A two parameter ratio-product-ratio estimator using auxiliary\n  information", "comments": "13 pages, 2 figures, 4 tables", "journal-ref": "ISRN Probability and Statistics Volume 2012 (2012), Article ID\n  103860, 15 pages", "doi": "10.5402/2012/103860", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a two parameter ratio-product-ratio estimator for a finite\npopulation mean in a simple random sample without replacement following the\nmethodology in Ray and Sahai (1980), Sahai and Ray (1980), Sahai and Sahai\n(1985) and Singh and Ruiz Espejo (2003).\n  The bias and mean square error of our proposed estimator are obtained to the\nfirst degree of approximation. We derive conditions for the parameters under\nwhich the proposed estimator has smaller mean square error than the sample\nmean, ratio and product estimators.\n  We carry out an application showing that the proposed estimator outperforms\nthe traditional estimators using groundwater data taken from a geological site\nin the state of Florida.\n", "versions": [{"version": "v1", "created": "Sat, 11 Feb 2012 01:21:43 GMT"}], "update_date": "2013-07-23", "authors_parsed": [["Chami", "Peter S.", ""], ["Sing", "Bernd", ""], ["Thomas", "Doneal", ""]]}, {"id": "1202.2396", "submitter": "John Rhodes", "authors": "Elizabeth S. Allman, John A. Rhodes, and Seth Sullivant", "title": "When Do Phylogenetic Mixture Models Mimic Other Phylogenetic Models?", "comments": "21 pages, 1 figure; revised to expand commentary; Mittag-Leffler\n  Institute, Spring 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Phylogenetic mixture models, in which the sites in sequences undergo\ndifferent substitution processes along the same or different trees, allow the\ndescription of heterogeneous evolutionary processes. As data sets consisting of\nlonger sequences become available, it is important to understand such models,\nfor both theoretical insights and use in statistical analyses. Some recent\narticles have highlighted disturbing \"mimicking\" behavior in which a\ndistribution from a mixture model is identical to one arising on a different\ntree or trees. Other works have indicated such problems are unlikely to occur\nin practice, as they require very special parameter choices.\n  After surveying some of these works on mixture models, we give several new\nresults. In general, if the number of components in a generating mixture is not\ntoo large and we disallow zero or infinite branch lengths, then it cannot mimic\nthe behavior of a non-mixture on a different tree. On the other hand, if the\nmixture model is locally over-parameterized, it is possible for a phylogenetic\nmixture model to mimic distributions of another tree model. Though theoretical\nquestions remain, these sorts of results can serve as a guide to when the use\nof mixture models in either ML or Bayesian frameworks is likely to lead to\nstatistically consistent inference, and when mimicking due to heterogeneity\nshould be considered a realistic possibility.\n", "versions": [{"version": "v1", "created": "Sat, 11 Feb 2012 01:49:18 GMT"}, {"version": "v2", "created": "Mon, 16 Jul 2012 18:03:27 GMT"}], "update_date": "2012-07-17", "authors_parsed": [["Allman", "Elizabeth S.", ""], ["Rhodes", "John A.", ""], ["Sullivant", "Seth", ""]]}, {"id": "1202.2408", "submitter": "Sergiy Vorobyov A.", "authors": "Mahdi Shaghaghi and Sergiy A. Vorobyov", "title": "Spectral Estimation from Undersampled Data: Correlogram and Model-Based\n  Least Squares", "comments": "This paper has been withdrawn by the author because a more detailed\n  paper on one of the developments reported here has been submitted\n  'Finite-Length and Asymptotic Analysis of Correlogram for Undersampled Data',\n  arXiv:1305.5592", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT math.IT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies two spectrum estimation methods for the case that the\nsamples are obtained at a rate lower than the Nyquist rate. The first method is\nthe correlogram method for undersampled data. The algorithm partitions the\nspectrum into a number of segments and estimates the average power within each\nspectral segment. We derive the bias and the variance of the spectrum\nestimator, and show that there is a tradeoff between the accuracy of the\nestimation and the frequency resolution. The asymptotic behavior of the\nestimator is also investigated, and it is proved that this spectrum estimator\nis consistent.\n  A new algorithm for reconstructing signals with sparse spectrum from noisy\ncompressive measurements is also introduced. Such model-based algorithm takes\nthe signal structure into account for estimating the unknown parameters which\nare the frequencies and the amplitudes of linearly combined sinusoidal signals.\nA high-resolution spectral estimation method is used to recover the frequencies\nof the signal elements, while the amplitudes of the signal components are\nestimated by minimizing the squared norm of the compressed estimation error\nusing the least squares technique. The Cramer-Rao bound for the given system\nmodel is also derived. It is shown that the proposed algorithm approaches the\nbound at high signal to noise ratios.\n", "versions": [{"version": "v1", "created": "Sat, 11 Feb 2012 03:58:45 GMT"}, {"version": "v2", "created": "Fri, 22 Nov 2013 06:40:27 GMT"}], "update_date": "2013-11-25", "authors_parsed": [["Shaghaghi", "Mahdi", ""], ["Vorobyov", "Sergiy A.", ""]]}, {"id": "1202.2525", "submitter": "Adel Javanmard", "authors": "Adel Javanmard and Andrea Montanari", "title": "Subsampling at Information Theoretically Optimal Rates", "comments": "5 pages, 4 figures, minor corrections", "journal-ref": "Proc. of IEEE Intl. Symp. on Information Theory (2012), pages\n  2431-2435", "doi": null, "report-no": null, "categories": "cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of sampling a random signal with sparse support in\nfrequency domain. Shannon famously considered a scheme that instantaneously\nsamples the signal at equispaced times. He proved that the signal can be\nreconstructed as long as the sampling rate exceeds twice the bandwidth (Nyquist\nrate). Cand\\`es, Romberg, Tao introduced a scheme that acquires instantaneous\nsamples of the signal at random times. They proved that the signal can be\nuniquely and efficiently reconstructed, provided the sampling rate exceeds the\nfrequency support of the signal, times logarithmic factors.\n  In this paper we consider a probabilistic model for the signal, and a\nsampling scheme inspired by the idea of spatial coupling in coding theory.\nNamely, we propose to acquire non-instantaneous samples at random times.\nMathematically, this is implemented by acquiring a small random subset of Gabor\ncoefficients. We show empirically that this scheme achieves correct\nreconstruction as soon as the sampling rate exceeds the frequency support of\nthe signal, thus reaching the information theoretic limit.\n", "versions": [{"version": "v1", "created": "Sun, 12 Feb 2012 12:43:32 GMT"}, {"version": "v2", "created": "Wed, 21 Nov 2012 03:39:49 GMT"}], "update_date": "2012-11-22", "authors_parsed": [["Javanmard", "Adel", ""], ["Montanari", "Andrea", ""]]}, {"id": "1202.2576", "submitter": "Imran Ansari", "authors": "Imran Shafique Ansari, Ferkan Yilmaz, Mohamed-Slim Alouini and\n  O\\u{g}uz Kucur", "title": "New Results on the Sum of Gamma Random Variates With Application to the\n  Performance of Wireless Communication Systems over Nakagami-m Fading Channels", "comments": "5 figures, 4 tables, Accepted in SPAWC 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The probability density function (PDF) and cumulative distribution function\nof the sum of L independent but not necessarily identically distributed Gamma\nvariates, applicable to the output statistics of maximal ratio combining (MRC)\nreceiver operating over Nakagami-m fading channels or in other words to the\nstatistical analysis of the scenario where the sum of squared Nakagami-m\ndistributions are user-of-interest, is presented in closed-form in terms of\nwell-known Meijer's G function and easily computable Fox's H-bar function for\ninteger valued and non-integer valued m fading parameters. Further analysis,\nparticularly on bit error rate via a PDF-based approach is also offered in\nclosed form in terms of Meijer's G function and Fox's H-bar function for\ninteger valued fading parameters, and extended Fox's H-bar function (H-hat) for\nnon-integer valued fading parameters. Our proposed results complement previous\nknown results that are either expressed in terms of infinite sums, nested sums,\nor higher order derivatives of the fading parameter m.\n", "versions": [{"version": "v1", "created": "Sun, 12 Feb 2012 21:23:04 GMT"}, {"version": "v2", "created": "Tue, 14 Feb 2012 13:43:33 GMT"}, {"version": "v3", "created": "Mon, 14 May 2012 11:42:11 GMT"}, {"version": "v4", "created": "Wed, 18 Jul 2012 13:21:03 GMT"}], "update_date": "2012-07-19", "authors_parsed": [["Ansari", "Imran Shafique", ""], ["Yilmaz", "Ferkan", ""], ["Alouini", "Mohamed-Slim", ""], ["Kucur", "O\u011fuz", ""]]}, {"id": "1202.2723", "submitter": "Tingni Sun", "authors": "Tingni Sun and Cun-Hui Zhang", "title": "Sparse Matrix Inversion with Scaled Lasso", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new method of learning a sparse nonnegative-definite target\nmatrix. Our primary example of the target matrix is the inverse of a population\ncovariance or correlation matrix. The algorithm first estimates each column of\nthe target matrix by the scaled Lasso and then adjusts the matrix estimator to\nbe symmetric. The penalty level of the scaled Lasso for each column is\ncompletely determined by data via convex minimization, without using\ncross-validation.\n  We prove that this scaled Lasso method guarantees the fastest proven rate of\nconvergence in the spectrum norm under conditions of weaker form than those in\nthe existing analyses of other $\\ell_1$ regularized algorithms, and has faster\nguaranteed rate of convergence when the ratio of the $\\ell_1$ and spectrum\nnorms of the target inverse matrix diverges to infinity. A simulation study\ndemonstrates the computational feasibility and superb performance of the\nproposed method.\n  Our analysis also provides new performance bounds for the Lasso and scaled\nLasso to guarantee higher concentration of the error at a smaller threshold\nlevel than previous analyses, and to allow the use of the union bound in\ncolumn-by-column applications of the scaled Lasso without an adjustment of the\npenalty level. In addition, the least squares estimation after the scaled Lasso\nselection is considered and proven to guarantee performance bounds similar to\nthat of the scaled Lasso.\n", "versions": [{"version": "v1", "created": "Mon, 13 Feb 2012 13:31:45 GMT"}, {"version": "v2", "created": "Mon, 14 Oct 2013 19:58:33 GMT"}], "update_date": "2013-10-15", "authors_parsed": [["Sun", "Tingni", ""], ["Zhang", "Cun-Hui", ""]]}, {"id": "1202.2849", "submitter": "Aleksey Polunchenko", "authors": "Aleksey S. Polunchenko and Alexander G. Tartakovsky and Nitis\n  Mukhopadhyay", "title": "Nearly Optimal Change-Point Detection with an Application to\n  Cybersecurity", "comments": "minor typos and formatting issues fixed, 23 pages, submitted to\n  Sequential Analysis", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the sequential change-point detection problem for the Gaussian\nmodel where baseline distribution is Gaussian with variance \\sigma^2 and mean\n\\mu such that \\sigma^2=a\\mu, where a>0 is a known constant; the change is in\n\\mu from one known value to another. First, we carry out a comparative\nperformance analysis of four detection procedures: the CUSUM procedure, the\nShiryaev-Roberts (SR) procedure, and two its modifications - the\nShiryaev-Roberts-Pollak and Shiryaev-Roberts-r procedures. The performance is\nbenchmarked via Pollak's maximal average delay to detection and Shiryaev's\nstationary average delay to detection, each subject to a fixed average run\nlength to false alarm. The analysis shows that in practically interesting cases\nthe accuracy of asymptotic approximations is \"reasonable\" to \"excellent\". We\nalso consider an application of change-point detection to cybersecurity - for\nrapid anomaly detection in computer networks. Using real network data we show\nthat statistically traffic's intensity can be well-described by the proposed\nGaussian model with \\sigma^2=a\\mu instead of the traditional Poisson model,\nwhich requires \\sigma^2=\\mu. By successively devising the SR and CUSUM\nprocedures to \"catch\" a low-contrast network anomaly (caused by an ICMP\nreflector attack), we then show that the SR rule is quicker. We conclude that\nthe SR procedure is a better cyber \"watch dog\" than the popular CUSUM\nprocedure.\n", "versions": [{"version": "v1", "created": "Mon, 13 Feb 2012 20:59:32 GMT"}, {"version": "v2", "created": "Sat, 3 Mar 2012 22:06:04 GMT"}], "update_date": "2012-03-06", "authors_parsed": [["Polunchenko", "Aleksey S.", ""], ["Tartakovsky", "Alexander G.", ""], ["Mukhopadhyay", "Nitis", ""]]}, {"id": "1202.2943", "submitter": "Kazuya Okamura", "authors": "Kazuya Okamura", "title": "The Quantum Relative Entropy as a Rate Function and Information Criteria", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph math-ph math.MP math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that the quantum relative entropy is a rate function in large\ndeviation principle. Next, we define information criteria for quantum states\nand estimate the accuracy of the use of them. Most of the results in this paper\nare essentially based on Hiai-Ohya-Tsukada theorem.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 06:03:33 GMT"}, {"version": "v2", "created": "Wed, 15 Feb 2012 04:20:54 GMT"}], "update_date": "2012-02-16", "authors_parsed": [["Okamura", "Kazuya", ""]]}, {"id": "1202.2982", "submitter": "Udaysinh T. Bhosale", "authors": "Udaysinh T. Bhosale, Steven Tomsovic, Arul Lakshminarayan", "title": "Entanglement between two subsystems, the Wigner semicircle and extreme\n  value statistics", "comments": "Substantially improved version (now 43 pages, 10 figures) that is\n  accepted for publication in Phys. Rev. A", "journal-ref": "Phys. Rev. A 85, 062331 (2012)", "doi": "10.1103/PhysRevA.85.062331", "report-no": "Preprint No. IITM/PH/TH/2012/2", "categories": "quant-ph math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The entanglement between two arbitrary subsystems of random pure states is\nstudied via properties of the density matrix's partial transpose,\n$\\rho_{12}^{T_2}$. The density of states of $\\rho_{12}^{T_2}$ is close to the\nsemicircle law when both subsystems have dimensions which are not too small and\nare of the same order. A simple random matrix model for the partial transpose\nis found to capture the entanglement properties well, including a transition\nacross a critical dimension. Log-negativity is used to quantify entanglement\nbetween subsystems and analytic formulas for this are derived based on the\nsimple model. The skewness of the eigenvalue density of $\\rho_{12}^{T_2}$ is\nderived analytically, using the average of the third moment over the ensemble\nof random pure states. The third moment after partial transpose is also shown\nto be related to a generalization of the Kempe invariant. The smallest\neigenvalue after partial transpose is found to follow the extreme value\nstatistics of random matrices, namely the Tracy-Widom distribution. This\ndistribution, with relevant parameters obtained from the model, is found to be\nuseful in calculating the fraction of entangled states at critical dimensions.\nThese results are tested in a quantum dynamical system of three coupled\nstandard maps, where one finds that if the parameters represent a strongly\nchaotic system, the results are close to those of random states, although there\nare some systematic deviations at critical dimensions.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 10:26:03 GMT"}, {"version": "v2", "created": "Sat, 16 Jun 2012 13:57:57 GMT"}], "update_date": "2018-07-23", "authors_parsed": [["Bhosale", "Udaysinh T.", ""], ["Tomsovic", "Steven", ""], ["Lakshminarayan", "Arul", ""]]}, {"id": "1202.3307", "submitter": "Ting Yan", "authors": "Ting Yan and Jinfeng Xu", "title": "A central limit theorem in the $\\beta$-model for undirected random\n  graphs with a diverging number of vertices", "comments": "6 pages. 2 tables", "journal-ref": "Biometrika. 2013, Volume 100, Issue 2, 519-524", "doi": "10.1093/biomet/ass084", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chatterjee, Diaconis and Sly (2011) recently established the consistency of\nthe maximum likelihood estimate in the $\\beta$-model when the number of\nvertices goes to infinity. By approximating the inverse of the Fisher\ninformation matrix, we obtain its asymptotic normality under mild conditions.\nSimulation studies and a data example illustrate the theoretical results.\n", "versions": [{"version": "v1", "created": "Wed, 15 Feb 2012 14:08:36 GMT"}, {"version": "v2", "created": "Mon, 17 Dec 2012 21:43:46 GMT"}, {"version": "v3", "created": "Sun, 30 Jun 2013 01:29:44 GMT"}], "update_date": "2013-07-02", "authors_parsed": [["Yan", "Ting", ""], ["Xu", "Jinfeng", ""]]}, {"id": "1202.3482", "submitter": "Ramon Van Handel", "authors": "Elisabeth Gassiat (LM-Orsay), Ramon Van Handel", "title": "The local geometry of finite mixtures", "comments": "25 pages", "journal-ref": "Trans. Amer. Math. Soc. 366, 1047-1072 (2014)", "doi": "10.1090/S0002-9947-2013-06041-2", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We establish that for q>=1, the class of convex combinations of q translates\nof a smooth probability density has local doubling dimension proportional to q.\nThe key difficulty in the proof is to control the local geometric structure of\nmixture classes. Our local geometry theorem yields a bound on the (bracketing)\nmetric entropy of a class of normalized densities, from which a local entropy\nbound is deduced by a general slicing procedure.\n", "versions": [{"version": "v1", "created": "Thu, 16 Feb 2012 00:59:11 GMT"}, {"version": "v2", "created": "Wed, 1 Aug 2012 16:06:38 GMT"}], "update_date": "2015-02-04", "authors_parsed": [["Gassiat", "Elisabeth", "", "LM-Orsay"], ["Van Handel", "Ramon", ""]]}, {"id": "1202.3483", "submitter": "Takuma Yoshida", "authors": "Takuma Yoshida and Kanta Naito", "title": "Semiparametric Penalized Spline Regression", "comments": "20 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a new semiparametric regression estimator by using\na hybrid technique of a parametric approach and a nonparametric penalized\nspline method. The overall shape of the true regression function is captured by\nthe parametric part, while its residual is consistently estimated by the\nnonparametric part. Asymptotic theory for the proposed semiparametric estimator\nis developed, showing that its behavior is dependent on the asymptotics for the\nnonparametric penalized spline estimator as well as on the discrepancy between\nthe true regression function and the parametric part. As a naturally associated\napplication of asymptotics, some criteria for the selection of parametric\nmodels are addressed. Numerical experiments show that the proposed estimator\nperforms better than the existing kernel-based semiparametric estimator and the\nfully nonparametric estimator, and that the proposed criteria work well for\nchoosing a reasonable parametric model.\n", "versions": [{"version": "v1", "created": "Thu, 16 Feb 2012 01:08:21 GMT"}], "update_date": "2012-02-17", "authors_parsed": [["Yoshida", "Takuma", ""], ["Naito", "Kanta", ""]]}, {"id": "1202.3570", "submitter": "Antar Bandyopadhyay", "authors": "Antar Bandyopadhyay and Sanjay Chaudhuri", "title": "Variance Estimation for Tree Order Restricted Models", "comments": "17 pages, 5 figures. A revised version with few typing errors\n  corrected and few more new results added", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we discuss estimation of the common variance of several\nnormal populations with tree order restricted means. We discuss the asymptotic\nproperties of the maximum likelihood estimator of the variance as the number of\npopulations tends to infinity. We consider several cases of various orders of\nthe sample sizes and show that the maximum likelihood estimator of the variance\nmay or may not be consistent or be asymptotically normal.\n", "versions": [{"version": "v1", "created": "Thu, 16 Feb 2012 12:15:51 GMT"}, {"version": "v2", "created": "Wed, 23 Jul 2014 07:00:25 GMT"}], "update_date": "2014-07-24", "authors_parsed": [["Bandyopadhyay", "Antar", ""], ["Chaudhuri", "Sanjay", ""]]}, {"id": "1202.3878", "submitter": "Sylvain Arlot", "authors": "Sylvain Arlot (LMO, SELECT), Alain Celisse (MODAL, LPP), Zaid\n  Harchaoui (CIMS)", "title": "A Kernel Multiple Change-point Algorithm via Model Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We tackle the change-point problem with data belonging to a general set. We\nbuild a penalty for choosing the number of change-points in the kernel-based\nmethod of Harchaoui and Capp{\\'e} (2007). This penalty generalizes the one\nproposed by Lebarbier (2005) for one-dimensional signals. We prove a\nnon-asymptotic oracle inequality for the proposed method, thanks to a new\nconcentration result for some function of Hilbert-space valued random\nvariables. Experiments on synthetic data illustrate the accuracy of our method,\nshowing that it can detect changes in the whole distribution of data, even when\nthe mean and variance are constant.\n", "versions": [{"version": "v1", "created": "Fri, 17 Feb 2012 10:59:57 GMT"}, {"version": "v2", "created": "Thu, 24 Mar 2016 08:21:44 GMT"}, {"version": "v3", "created": "Thu, 14 Mar 2019 13:04:31 GMT"}], "update_date": "2019-03-15", "authors_parsed": [["Arlot", "Sylvain", "", "LMO, SELECT"], ["Celisse", "Alain", "", "MODAL, LPP"], ["Harchaoui", "Zaid", "", "CIMS"]]}, {"id": "1202.4074", "submitter": "Francesco Bartolucci", "authors": "Francesco Bartolucci, Luisa Scaccia, Alessio Farcomeni", "title": "Bayesian inference through encompassing priors and importance sampling\n  for a class of marginal models for categorical data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a Bayesian approach for selecting the model which is the most\nsupported by the data within a class of marginal models for categorical\nvariables formulated through equality and/or inequality constraints on\ngeneralised logits (local, global, continuation or reverse continuation),\ngeneralised log-odds ratios and similar higher-order interactions. For each\nconstrained model, the prior distribution of the model parameters is formulated\nfollowing the encompassing prior approach. Then, model selection is performed\nby using Bayes factors which are estimated by an importance sampling method.\nThe approach is illustrated through three applications involving some datasets,\nwhich also include explanatory variables. In connection with one of these\nexamples, a sensitivity analysis to the prior specification is also considered.\n", "versions": [{"version": "v1", "created": "Sat, 18 Feb 2012 12:33:27 GMT"}], "update_date": "2012-02-21", "authors_parsed": [["Bartolucci", "Francesco", ""], ["Scaccia", "Luisa", ""], ["Farcomeni", "Alessio", ""]]}, {"id": "1202.4198", "submitter": "Bala Rajaratnam", "authors": "Richard A. Olshen and Bala Rajaratnam", "title": "Successive Standardization of Rectangular Arrays", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this note we illustrate and develop further with mathematics and examples,\nthe work on successive standardization (or normalization) that is studied\nearlier by the same authors in Olshen and Rajaratnam (2010) and Olshen and\nRajaratnam (2011). Thus, we deal with successive iterations applied to\nrectangular arrays of numbers, where to avoid technical difficulties an array\nhas at least three rows and at least three columns. Without loss, an iteration\nbegins with operations on columns: first subtract the mean of each column; then\ndivide by its standard deviation. The iteration continues with the same two\noperations done successively for rows. These four operations applied in\nsequence completes one iteration. One then iterates again, and again, and\nagain,.... In Olshen and Rajaratnam (2010) it was argued that if arrays are\nmade up of real numbers, then the set for which convergence of these successive\niterations fails has Lebesgue measure 0. The limiting array has row and column\nmeans 0, row and column standard deviations 1. A basic result on convergence\ngiven in Olshen and Rajaratnam (2010) is true, though the argument in Olshen\nand Rajaratnam (2010) is faulty. The result is stated in the form of a theorem\nhere, and the argument for the theorem is correct. Moreover, many graphics\ngiven in Olshen and Rajaratnam (2010) suggest that but for a set of entries of\nany array with Lebesgue measure 0, convergence is very rapid, eventually\nexponentially fast in the number of iterations. Because we learned this set of\nrules from Bradley Efron, we call it \"Efron's algorithm\". More importantly, the\nrapidity of convergence is illustrated by numerical examples.\n", "versions": [{"version": "v1", "created": "Mon, 20 Feb 2012 00:27:10 GMT"}], "update_date": "2012-02-21", "authors_parsed": [["Olshen", "Richard A.", ""], ["Rajaratnam", "Bala", ""]]}, {"id": "1202.4267", "submitter": "Thomas Hotz", "authors": "Thomas Hotz, Sean Skwerer, Stephan Huckemann, Huiling Le, J. S.\n  Marron, Jonathan C. Mattingly, Ezra Miller, James Nolen, Megan Owen, Vic\n  Patrangenaru", "title": "Sticky central limit theorems on open books", "comments": "Published in at http://dx.doi.org/10.1214/12-AAP899 the Annals of\n  Applied Probability (http://www.imstat.org/aap/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Probability 2013, Vol. 23, No. 6, 2238-2258", "doi": "10.1214/12-AAP899", "report-no": "IMS-AAP-AAP899", "categories": "math.PR math.MG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a probability distribution on an open book (a metric space obtained by\ngluing a disjoint union of copies of a half-space along their boundary\nhyperplanes), we define a precise concept of when the Fr\\'{e}chet mean\n(barycenter) is sticky. This nonclassical phenomenon is quantified by a law of\nlarge numbers (LLN) stating that the empirical mean eventually almost surely\nlies on the (codimension $1$ and hence measure $0$) spine that is the glued\nhyperplane, and a central limit theorem (CLT) stating that the limiting\ndistribution is Gaussian and supported on the spine. We also state versions of\nthe LLN and CLT for the cases where the mean is nonsticky (i.e., not lying on\nthe spine) and partly sticky (i.e., is, on the spine but not sticky).\n", "versions": [{"version": "v1", "created": "Mon, 20 Feb 2012 09:37:54 GMT"}, {"version": "v2", "created": "Tue, 3 Dec 2013 07:07:00 GMT"}], "update_date": "2013-12-04", "authors_parsed": [["Hotz", "Thomas", ""], ["Skwerer", "Sean", ""], ["Huckemann", "Stephan", ""], ["Le", "Huiling", ""], ["Marron", "J. S.", ""], ["Mattingly", "Jonathan C.", ""], ["Miller", "Ezra", ""], ["Nolen", "James", ""], ["Owen", "Megan", ""], ["Patrangenaru", "Vic", ""]]}, {"id": "1202.4283", "submitter": "Pierre Alquier", "authors": "Pierre Alquier (LPMA, CREST), Olivier Wintenberger (CREST, CEREMADE)", "title": "Fast rates in learning with dependent observations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we tackle the problem of fast rates in time series forecasting\nfrom a statistical learning perspective. In a serie of papers (e.g. Meir 2000,\nModha and Masry 1998, Alquier and Wintenberger 2012) it is shown that the main\ntools used in learning theory with iid observations can be extended to the\nprediction of time series. The main message of these papers is that, given a\nfamily of predictors, we are able to build a new predictor that predicts the\nseries as well as the best predictor in the family, up to a remainder of order\n$1/\\sqrt{n}$. It is known that this rate cannot be improved in general. In this\npaper, we show that in the particular case of the least square loss, and under\na strong assumption on the time series (phi-mixing) the remainder is actually\nof order $1/n$. Thus, the optimal rate for iid variables, see e.g. Tsybakov\n2003, and individual sequences, see \\cite{lugosi} is, for the first time,\nachieved for uniformly mixing processes. We also show that our method is\noptimal for aggregating sparse linear combinations of predictors.\n", "versions": [{"version": "v1", "created": "Mon, 20 Feb 2012 10:26:28 GMT"}], "update_date": "2012-02-22", "authors_parsed": [["Alquier", "Pierre", "", "LPMA, CREST"], ["Wintenberger", "Olivier", "", "CREST, CEREMADE"]]}, {"id": "1202.4294", "submitter": "Pierre Alquier", "authors": "Pierre Alquier (LPMA, CREST), Xiaoyin Li (AGM)", "title": "Prediction of quantiles by statistical learning and application to GDP\n  forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we tackle the problem of prediction and confidence intervals\nfor time series using a statistical learning approach and quantile loss\nfunctions. In a first time, we show that the Gibbs estimator (also known as\nExponentially Weighted aggregate) is able to predict as well as the best\npredictor in a given family for a wide set of loss functions. In particular,\nusing the quantile loss function of Koenker and Bassett (1978), this allows to\nbuild confidence intervals. We apply these results to the problem of prediction\nand confidence regions for the French Gross Domestic Product (GDP) growth, with\npromising results.\n", "versions": [{"version": "v1", "created": "Mon, 20 Feb 2012 11:40:50 GMT"}, {"version": "v2", "created": "Wed, 8 Aug 2012 19:40:53 GMT"}], "update_date": "2012-08-10", "authors_parsed": [["Alquier", "Pierre", "", "LPMA, CREST"], ["Li", "Xiaoyin", "", "AGM"]]}, {"id": "1202.4437", "submitter": "Gustavo Didier", "authors": "Gustavo Didier and John Fricks", "title": "On the wavelet-based simulation of anomalous diffusion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The characterization of particle diffusion is a classical problem in physics\nand probability theory. The field of microrheology is based on experiments in\nwhich microscopic tracer beads are placed into a non-Newtonian fluid and\ntracked using high speed video capture. The modeling of the behavior of these\nbeads is now an active scientific area which demands multiple stochastic and\nstatistical methods.\n  We propose an approximate wavelet-based simulation technique for two classes\nof continuous time anomalous diffusion models, the fractional\nOrnstein-Uhlenbeck process and the fractional generalized Langevin equation.\nThe proposed algorithm is an iterative method that provides approximate\ndiscretizations that converge quickly and in an appropriate sense to the\ncontinuous time target process. As compared to previous works, it covers cases\nwhere the natural discretization of the target process does not have closed\nform in the time domain. Moreover, we propose smoothing procedures as to speed\nthe time domain decay of the filters.\n", "versions": [{"version": "v1", "created": "Mon, 20 Feb 2012 20:09:04 GMT"}, {"version": "v2", "created": "Mon, 2 Jul 2012 19:02:28 GMT"}], "update_date": "2012-07-03", "authors_parsed": [["Didier", "Gustavo", ""], ["Fricks", "John", ""]]}, {"id": "1202.4696", "submitter": "Mathias Rafler", "authors": "Mathias Rafler", "title": "The P\\'olya sum kernel and Bayes estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a particular Cox process from a Bayesian viewpoint and show that\nthe Bayes estimator of the intensity measure is the so-called P\\'olya sum\nkernel, which occurred recently in the context of the construction of the\nso-called Papangelou processes. More precisely, if the prior, the directing\nmeasure of the Cox process, is a Poisson-Gamma random measure, then the\nposterior is again a Poisson-Gamma random measure and the Bayes estimator of\nthe intensity is the P\\'olya sum kernel. Moreover, we extend this result to\ndoubly stochastic Poisson-Gamma priors and give conditions under which one can\nidentify the Bayes estimator for the intensity.\n", "versions": [{"version": "v1", "created": "Tue, 21 Feb 2012 16:48:05 GMT"}, {"version": "v2", "created": "Thu, 10 May 2012 13:04:41 GMT"}], "update_date": "2012-05-11", "authors_parsed": [["Rafler", "Mathias", ""]]}, {"id": "1202.4737", "submitter": "Mathieu Ribatet", "authors": "Cl\\'ement Dombry and Mathieu Ribatet", "title": "Conditional simulation of extremal Gaussian processes", "comments": "This paper has been withdrawn since it was merged with another one as\n  suggested by the referees during the review process", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently the regular conditional distributions of max-infinitely divisible\nprocesses were derived by \\citet{Dombry2011} and although these conditional\ndistributions have complicated closed forms, \\citet{Dombry2011b} introduce an\nalgorithm to get conditional realizations of Brown-Resnick processes. In this\npaper we derive the regular conditional distributions of the max-stable process\nintroduced by \\citet{Schlather2002} and adapt the framework of\n\\citet{Dombry2011b} to this specific process. We test the methods on simulated\ndata and give an application to extreme temperatures in Switzerland. Results\nshow that the proposed sampling scheme provide accurate conditional simulations\nand can handle real-sized problems.\n", "versions": [{"version": "v1", "created": "Tue, 21 Feb 2012 19:53:38 GMT"}, {"version": "v2", "created": "Mon, 27 Aug 2012 12:54:04 GMT"}], "update_date": "2012-08-28", "authors_parsed": [["Dombry", "Cl\u00e9ment", ""], ["Ribatet", "Mathieu", ""]]}, {"id": "1202.4850", "submitter": "Kengo Kato", "authors": "Kengo Kato", "title": "Estimation in functional linear quantile regression", "comments": "Published in at http://dx.doi.org/10.1214/12-AOS1066 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2012, Vol. 40, No. 6, 3108-3136", "doi": "10.1214/12-AOS1066", "report-no": "IMS-AOS-AOS1066", "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies estimation in functional linear quantile regression in\nwhich the dependent variable is scalar while the covariate is a function, and\nthe conditional quantile for each fixed quantile index is modeled as a linear\nfunctional of the covariate. Here we suppose that covariates are discretely\nobserved and sampling points may differ across subjects, where the number of\nmeasurements per subject increases as the sample size. Also, we allow the\nquantile index to vary over a given subset of the open unit interval, so the\nslope function is a function of two variables: (typically) time and quantile\nindex. Likewise, the conditional quantile function is a function of the\nquantile index and the covariate. We consider an estimator for the slope\nfunction based on the principal component basis. An estimator for the\nconditional quantile function is obtained by a plug-in method. Since the\nso-constructed plug-in estimator not necessarily satisfies the monotonicity\nconstraint with respect to the quantile index, we also consider a class of\nmonotonized estimators for the conditional quantile function. We establish\nrates of convergence for these estimators under suitable norms, showing that\nthese rates are optimal in a minimax sense under some smoothness assumptions on\nthe covariance kernel of the covariate and the slope function. Empirical choice\nof the cutoff level is studied by using simulations.\n", "versions": [{"version": "v1", "created": "Wed, 22 Feb 2012 08:08:53 GMT"}, {"version": "v2", "created": "Wed, 27 Feb 2013 12:39:03 GMT"}], "update_date": "2013-02-28", "authors_parsed": [["Kato", "Kengo", ""]]}, {"id": "1202.4863", "submitter": "Judith Rousseau", "authors": "Willem Kruijer, Judith Rousseau (CEREMADE, CREST)", "title": "Bayesian semi-parametric estimation of the long-memory parameter under\n  FEXP-priors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For a Gaussian time series with long-memory behavior, we use the FEXP-model\nfor semi-parametric estimation of the long-memory parameter $d$. The true\nspectral density $f_o$ is assumed to have long-memory parameter $d_o$ and a\nFEXP-expansion of Sobolev-regularity $\\be > 1$. We prove that when $k$ follows\na Poisson or geometric prior, or a sieve prior increasing at rate\n$n^{\\frac{1}{1+2\\be}}$, $d$ converges to $d_o$ at a suboptimal rate. When the\nsieve prior increases at rate $n^{\\frac{1}{2\\be}}$ however, the minimax rate is\nalmost obtained. Our results can be seen as a Bayesian equivalent of the result\nwhich Moulines and Soulier obtained for some frequentist estimators.\n", "versions": [{"version": "v1", "created": "Wed, 22 Feb 2012 09:09:13 GMT"}], "update_date": "2012-02-24", "authors_parsed": [["Kruijer", "Willem", "", "CEREMADE, CREST"], ["Rousseau", "Judith", "", "CEREMADE, CREST"]]}, {"id": "1202.4962", "submitter": "Assaf Oron", "authors": "Assaf P. Oron and Peter D. Hoff", "title": "Small-Sample Behavior of Novel Phase I Cancer Trial Designs", "comments": "Somewhat modified version of the version accepted pending final\n  modifications at Clinical Trials. The supplement is in the back", "journal-ref": "Clinical Trials 2013, 10(1):63-92 (including comments and\n  rejoinder)", "doi": "10.1177/1740774512469311", "report-no": null, "categories": "stat.ME math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Novel dose-finding designs, using estimation to assign the best estimated\nmaximum- tolerated-dose (MTD) at each point in the experiment, most commonly\nvia Bayesian techniques, have recently entered large-scale implementation in\nPhase I cancer clinical trials. We examine the small-sample behavior of these\n\"Bayesian Phase I\" (BP1) designs, and also of non-Bayesian designs sharing the\nsame main \"long-memory\" traits (hereafter: LMP1s).\n  For all LMP1s examined, the number of cohorts treated at the true MTD\n(denoted here as n*) was highly variable between numerical runs drawn from the\nsame toxicity-threshold distribution, especially when compared with\n\"up-and-down\" (U&D) short-memory designs. Further investigation using the same\nset of thresholds in permuted order, produced a nearly-identical magnitude of\nvariability in n*. Therefore, this LMP1 behavior is driven by a strong\nsensitivity to the order in which toxicity thresholds appear in the experiment.\nWe suggest that the sensitivity is related to LMP1's tendency to \"settle\" early\non a specific dose level - a tendency caused by the repeated likelihood-based\n\"winner-takes-all\" dose assignment rule, which grants the early cohorts a\ndisproportionately large influence upon experimental trajectories.\n  Presently, U&D designs offer a simpler and more stable alternative, with\nroughly equivalent MTD estimation performance. A promising direction for\ncombining the two approaches is briefly discussed (note: the '3+3' protocol is\nnot a U&D design).\n", "versions": [{"version": "v1", "created": "Wed, 22 Feb 2012 16:35:24 GMT"}, {"version": "v2", "created": "Thu, 20 Sep 2012 21:31:20 GMT"}], "update_date": "2017-01-24", "authors_parsed": [["Oron", "Assaf P.", ""], ["Hoff", "Peter D.", ""]]}, {"id": "1202.5070", "submitter": "Quentin Berthet", "authors": "Quentin Berthet, Philippe Rigollet", "title": "Optimal detection of sparse principal components in high dimension", "comments": "Published in at http://dx.doi.org/10.1214/13-AOS1127 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2013, Vol. 41, No. 4, 1780-1815", "doi": "10.1214/13-AOS1127", "report-no": "IMS-AOS-AOS1127", "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We perform a finite sample analysis of the detection levels for sparse\nprincipal components of a high-dimensional covariance matrix. Our minimax\noptimal test is based on a sparse eigenvalue statistic. Alas, computing this\ntest is known to be NP-complete in general, and we describe a computationally\nefficient alternative test using convex relaxations. Our relaxation is also\nproved to detect sparse principal components at near optimal detection levels,\nand it performs well on simulated datasets. Moreover, using polynomial time\nreductions from theoretical computer science, we bring significant evidence\nthat our results cannot be improved, thus revealing an inherent trade off\nbetween statistical and computational performance.\n", "versions": [{"version": "v1", "created": "Thu, 23 Feb 2012 00:55:31 GMT"}, {"version": "v2", "created": "Mon, 17 Dec 2012 14:19:04 GMT"}, {"version": "v3", "created": "Thu, 19 Sep 2013 07:09:05 GMT"}], "update_date": "2014-01-30", "authors_parsed": [["Berthet", "Quentin", ""], ["Rigollet", "Philippe", ""]]}, {"id": "1202.5093", "submitter": "Nakagawa Shigekazu", "authors": "Shigekazu Nakagawa, Hiroki Hashiguchi and Naoto Niki", "title": "A measure of skewness for testing departures from normality", "comments": "17 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new skewness test statistic for normality based on the Pearson\nmeasure of skewness. We obtain asymptotic first four moments of the null\ndistribution for this statistic by using a computer algebra system and its\nnormalizing transformation based on the Johnson $S_{U}$ system. Finally the\nperformance of the proposed statistic is shown by comparing the powers of\nseveral skewness test statistics against some alternative hypotheses.\n", "versions": [{"version": "v1", "created": "Thu, 23 Feb 2012 06:17:39 GMT"}], "update_date": "2012-02-24", "authors_parsed": [["Nakagawa", "Shigekazu", ""], ["Hashiguchi", "Hiroki", ""], ["Niki", "Naoto", ""]]}, {"id": "1202.5096", "submitter": "Javier Rojo", "authors": "Javier Rojo", "title": "Erich Leo Lehmann---A glimpse into his life and work", "comments": "Published in at http://dx.doi.org/10.1214/11-AOS927 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2011, Vol. 39, No. 5, 2244-2265", "doi": "10.1214/11-AOS927", "report-no": "IMS-AOS-AOS927", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Through the use of a system-building approach, an approach that includes\nfinding common ground for the various philosophical paradigms within\nstatistics, Erich L. Lehmann is responsible for much of the synthesis of\nclassical statistical knowledge that developed from the Neyman--Pearson--Wald\nschool. A biographical sketch and a brief summary of some of his many\ncontributions are presented here. His complete bibliography is also included\nand the references present many other sources of information on his life and\nhis work.\n", "versions": [{"version": "v1", "created": "Thu, 23 Feb 2012 07:06:57 GMT"}], "update_date": "2012-02-24", "authors_parsed": [["Rojo", "Javier", ""]]}, {"id": "1202.5098", "submitter": "Willem R. van Zwet", "authors": "Willem R. van Zwet", "title": "Remembering Erich Lehmann", "comments": "Published in at http://dx.doi.org/10.1214/11-AOS881 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2011, Vol. 39, No. 5, 2266-2279", "doi": "10.1214/11-AOS881", "report-no": "IMS-AOS-AOS881", "categories": "math.HO math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper I shall try to sketch some typical aspects of Erich Lehmann's\ncontributions to statistics through his research, his teaching, his service to\nthe profession and his personality.\n", "versions": [{"version": "v1", "created": "Thu, 23 Feb 2012 07:19:01 GMT"}], "update_date": "2012-02-24", "authors_parsed": [["van Zwet", "Willem R.", ""]]}, {"id": "1202.5101", "submitter": "Peter J. Bickel", "authors": "Peter J. Bickel, Aiyou Chen, Elizaveta Levina", "title": "The method of moments and degree distributions for network models", "comments": "Published in at http://dx.doi.org/10.1214/11-AOS904 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2011, Vol. 39, No. 5, 2280-2301", "doi": "10.1214/11-AOS904", "report-no": "IMS-AOS-AOS904", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probability models on graphs are becoming increasingly important in many\napplications, but statistical tools for fitting such models are not yet well\ndeveloped. Here we propose a general method of moments approach that can be\nused to fit a large class of probability models through empirical counts of\ncertain patterns in a graph. We establish some general asymptotic properties of\nempirical graph moments and prove consistency of the estimates as the graph\nsize grows for all ranges of the average degree including $\\Omega(1)$.\nAdditional results are obtained for the important special case of degree\ndistributions.\n", "versions": [{"version": "v1", "created": "Thu, 23 Feb 2012 07:54:09 GMT"}], "update_date": "2012-02-24", "authors_parsed": [["Bickel", "Peter J.", ""], ["Chen", "Aiyou", ""], ["Levina", "Elizaveta", ""]]}, {"id": "1202.5118", "submitter": "Tony Cai", "authors": "Peter B\\\"uhlmann, Tony Cai", "title": "Introduction to the Lehmann special section", "comments": "Published in at http://dx.doi.org/10.1214/11-AOS928 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2011, Vol. 39, No. 5, 2243-2243", "doi": "10.1214/11-AOS928", "report-no": "IMS-AOS-AOS928", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The current Special Issue of The Annals of Statistics contains three invited\narticles. Javier Rojo discusses Erich's scientific achievements and provides\ncomplete lists of his scientific writings and his former Ph.D. students. Willem\nvan Zwet describes aspects of Erich's life and work, enriched with personal and\ninteresting anecdotes of Erich's long and productive scientific journey.\nFinally, Peter Bickel, Aiyou Chen and Elizaveta Levina present a research paper\non network models: they dedicate their contribution to Erich, emphasizing that\ntheir new nonparametric method and issues about optimality have been very much\ninfluenced by Erich's thinking.\n", "versions": [{"version": "v1", "created": "Thu, 23 Feb 2012 09:02:48 GMT"}], "update_date": "2012-02-24", "authors_parsed": [["B\u00fchlmann", "Peter", ""], ["Cai", "Tony", ""]]}, {"id": "1202.5130", "submitter": "Yair Goldberg", "authors": "Yair Goldberg and Michael R. Kosorok", "title": "Support Vector Regression for Right Censored Data", "comments": "In this version, we strengthened the theoretical results and\n  corrected a few mistakes", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a unified approach for classification and regression support\nvector machines for data subject to right censoring. We provide finite sample\nbounds on the generalization error of the algorithm, prove risk consistency for\na wide class of probability measures, and study the associated learning rates.\nWe apply the general methodology to estimation of the (truncated) mean, median,\nquantiles, and for classification problems. We present a simulation study that\ndemonstrates the performance of the proposed approach.\n", "versions": [{"version": "v1", "created": "Thu, 23 Feb 2012 09:33:17 GMT"}, {"version": "v2", "created": "Sat, 12 Jan 2013 20:43:14 GMT"}], "update_date": "2013-01-15", "authors_parsed": [["Goldberg", "Yair", ""], ["Kosorok", "Michael R.", ""]]}, {"id": "1202.5132", "submitter": "Tom M. W. Nye", "authors": "Tom M. W. Nye", "title": "Principal components analysis in the space of phylogenetic trees", "comments": "Published in at http://dx.doi.org/10.1214/11-AOS915 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2011, Vol. 39, No. 5, 2716-2739", "doi": "10.1214/11-AOS915", "report-no": "IMS-AOS-AOS915", "categories": "math.ST q-bio.PE stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Phylogenetic analysis of DNA or other data commonly gives rise to a\ncollection or sample of inferred evolutionary trees. Principal Components\nAnalysis (PCA) cannot be applied directly to collections of trees since the\nspace of evolutionary trees on a fixed set of taxa is not a vector space. This\npaper describes a novel geometrical approach to PCA in tree-space that\nconstructs the first principal path in an analogous way to standard linear\nEuclidean PCA. Given a data set of phylogenetic trees, a geodesic principal\npath is sought that maximizes the variance of the data under a form of\nprojection onto the path. Due to the high dimensionality of tree-space and the\nnonlinear nature of this problem, the computational complexity is potentially\nvery high, so approximate optimization algorithms are used to search for the\noptimal path. Principal paths identified in this way reveal and quantify the\nmain sources of variation in the original collection of trees in terms of both\ntopology and branch lengths. The approach is illustrated by application to\nsimulated sets of trees and to a set of gene trees from metazoan (animal)\nspecies.\n", "versions": [{"version": "v1", "created": "Thu, 23 Feb 2012 09:36:43 GMT"}], "update_date": "2012-02-24", "authors_parsed": [["Nye", "Tom M. W.", ""]]}, {"id": "1202.5134", "submitter": "T. Tony Cai", "authors": "T. Tony Cai, Ming Yuan", "title": "Optimal estimation of the mean function based on discretely sampled\n  functional data: Phase transition", "comments": "Published in at http://dx.doi.org/10.1214/11-AOS898 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2011, Vol. 39, No. 5, 2330-2355", "doi": "10.1214/11-AOS898", "report-no": "IMS-AOS-AOS898", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of estimating the mean of random functions based on discretely\nsampled data arises naturally in functional data analysis. In this paper, we\nstudy optimal estimation of the mean function under both common and independent\ndesigns. Minimax rates of convergence are established and easily implementable\nrate-optimal estimators are introduced. The analysis reveals interesting and\ndifferent phase transition phenomena in the two cases. Under the common design,\nthe sampling frequency solely determines the optimal rate of convergence when\nit is relatively small and the sampling frequency has no effect on the optimal\nrate when it is large. On the other hand, under the independent design, the\noptimal rate of convergence is determined jointly by the sampling frequency and\nthe number of curves when the sampling frequency is relatively small. When it\nis large, the sampling frequency has no effect on the optimal rate. Another\ninteresting contrast between the two settings is that smoothing is necessary\nunder the independent design, while, somewhat surprisingly, it is not essential\nunder the common design.\n", "versions": [{"version": "v1", "created": "Thu, 23 Feb 2012 09:38:27 GMT"}], "update_date": "2012-02-24", "authors_parsed": [["Cai", "T. Tony", ""], ["Yuan", "Ming", ""]]}, {"id": "1202.5140", "submitter": "Tze Leung Lai", "authors": "Tze Leung Lai, Shulamith T. Gross, David Bo Shen", "title": "Evaluating probability forecasts", "comments": "Published in at http://dx.doi.org/10.1214/11-AOS902 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2011, Vol. 39, No. 5, 2356-2382", "doi": "10.1214/11-AOS902", "report-no": "IMS-AOS-AOS902", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probability forecasts of events are routinely used in climate predictions, in\nforecasting default probabilities on bank loans or in estimating the\nprobability of a patient's positive response to treatment. Scoring rules have\nlong been used to assess the efficacy of the forecast probabilities after\nobserving the occurrence, or nonoccurrence, of the predicted events. We develop\nherein a statistical theory for scoring rules and propose an alternative\napproach to the evaluation of probability forecasts. This approach uses loss\nfunctions relating the predicted to the actual probabilities of the events and\napplies martingale theory to exploit the temporal structure between the\nforecast and the subsequent occurrence or nonoccurrence of the event.\n", "versions": [{"version": "v1", "created": "Thu, 23 Feb 2012 10:19:16 GMT"}], "update_date": "2012-02-24", "authors_parsed": [["Lai", "Tze Leung", ""], ["Gross", "Shulamith T.", ""], ["Shen", "David Bo", ""]]}, {"id": "1202.5145", "submitter": "Marc Hoffmann", "authors": "Marc Hoffmann, Richard Nickl", "title": "On adaptive inference and confidence bands", "comments": "Published in at http://dx.doi.org/10.1214/11-AOS903 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2011, Vol. 39, No. 5, 2383-2409", "doi": "10.1214/11-AOS903", "report-no": "IMS-AOS-AOS903", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of existence of adaptive confidence bands for an unknown density\n$f$ that belongs to a nested scale of H\\\"{o}lder classes over $\\mathbb{R}$ or\n$[0,1]$ is considered. Whereas honest adaptive inference in this problem is\nimpossible already for a pair of H\\\"{o}lder balls $\\Sigma(r),\\Sigma(s),r\\ne s$,\nof fixed radius, a nonparametric distinguishability condition is introduced\nunder which adaptive confidence bands can be shown to exist. It is further\nshown that this condition is necessary and sufficient for the existence of\nhonest asymptotic confidence bands, and that it is strictly weaker than similar\nanalytic conditions recently employed in Gin\\'{e} and Nickl [Ann. Statist. 38\n(2010) 1122--1170]. The exceptional sets for which honest inference is not\npossible have vanishingly small probability under natural priors on H\\\"{o}lder\nballs $\\Sigma(s)$. If no upper bound for the radius of the H\\\"{o}lder balls is\nknown, a price for adaptation has to be paid, and near-optimal adaptation is\npossible for standard procedures. The implications of these findings for a\ngeneral theory of adaptive inference are discussed.\n", "versions": [{"version": "v1", "created": "Thu, 23 Feb 2012 10:36:54 GMT"}], "update_date": "2012-02-24", "authors_parsed": [["Hoffmann", "Marc", ""], ["Nickl", "Richard", ""]]}, {"id": "1202.5151", "submitter": "Alois Kneip", "authors": "Alois Kneip, Pascal Sarda", "title": "Factor models and variable selection in high-dimensional regression\n  analysis", "comments": "Published in at http://dx.doi.org/10.1214/11-AOS905 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2011, Vol. 39, No. 5, 2410-2447", "doi": "10.1214/11-AOS905", "report-no": "IMS-AOS-AOS905", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper considers linear regression problems where the number of predictor\nvariables is possibly larger than the sample size. The basic motivation of the\nstudy is to combine the points of view of model selection and functional\nregression by using a factor approach: it is assumed that the predictor vector\ncan be decomposed into a sum of two uncorrelated random components reflecting\ncommon factors and specific variabilities of the explanatory variables. It is\nshown that the traditional assumption of a sparse vector of parameters is\nrestrictive in this context. Common factors may possess a significant influence\non the response variable which cannot be captured by the specific effects of a\nsmall number of individual variables. We therefore propose to include principal\ncomponents as additional explanatory variables in an augmented regression\nmodel. We give finite sample inequalities for estimates of these components. It\nis then shown that model selection procedures can be used to estimate the\nparameters of the augmented model, and we derive theoretical properties of the\nestimators. Finite sample performance is illustrated by a simulation study.\n", "versions": [{"version": "v1", "created": "Thu, 23 Feb 2012 11:05:55 GMT"}], "update_date": "2012-02-24", "authors_parsed": [["Kneip", "Alois", ""], ["Sarda", "Pascal", ""]]}, {"id": "1202.5159", "submitter": "Pauliina Ilmonen", "authors": "Pauliina Ilmonen, Davy Paindaveine", "title": "Semiparametrically efficient inference based on signed ranks in\n  symmetric independent component models", "comments": "Published in at http://dx.doi.org/10.1214/11-AOS906 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2011, Vol. 39, No. 5, 2448-2476", "doi": "10.1214/11-AOS906", "report-no": "IMS-AOS-AOS906", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider semiparametric location-scatter models for which the $p$-variate\nobservation is obtained as $X=\\Lambda Z+\\mu$, where $\\mu$ is a $p$-vector,\n$\\Lambda$ is a full-rank $p\\times p$ matrix and the (unobserved) random\n$p$-vector $Z$ has marginals that are centered and mutually independent but are\notherwise unspecified. As in blind source separation and independent component\nanalysis (ICA), the parameter of interest throughout the paper is $\\Lambda$. On\nthe basis of $n$ i.i.d. copies of $X$, we develop, under a symmetry assumption\non $Z$, signed-rank one-sample testing and estimation procedures for $\\Lambda$.\nWe exploit the uniform local and asymptotic normality (ULAN) of the model to\ndefine signed-rank procedures that are semiparametrically efficient under\ncorrectly specified densities. Yet, as is usual in rank-based inference, the\nproposed procedures remain valid (correct asymptotic size under the null, for\nhypothesis testing, and root-$n$ consistency, for point estimation) under a\nvery broad range of densities. We derive the asymptotic properties of the\nproposed procedures and investigate their finite-sample behavior through\nsimulations.\n", "versions": [{"version": "v1", "created": "Thu, 23 Feb 2012 12:23:08 GMT"}], "update_date": "2012-02-24", "authors_parsed": [["Ilmonen", "Pauliina", ""], ["Paindaveine", "Davy", ""]]}, {"id": "1202.5160", "submitter": "Eugenia Buta", "authors": "Eugenia Buta, Hani Doss", "title": "Computational approaches for empirical Bayes methods and Bayesian\n  sensitivity analysis", "comments": "Published in at http://dx.doi.org/10.1214/11-AOS913 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2011, Vol. 39, No. 5, 2658-2685", "doi": "10.1214/11-AOS913", "report-no": "IMS-AOS-AOS913", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider situations in Bayesian analysis where we have a family of priors\n$\\nu_h$ on the parameter $\\theta$, where $h$ varies continuously over a space\n$\\mathcal{H}$, and we deal with two related problems. The first involves\nsensitivity analysis and is stated as follows. Suppose we fix a function $f$ of\n$\\theta$. How do we efficiently estimate the posterior expectation of\n$f(\\theta)$ simultaneously for all $h$ in $\\mathcal{H}$? The second problem is\nhow do we identify subsets of $\\mathcal{H}$ which give rise to reasonable\nchoices of $\\nu_h$? We assume that we are able to generate Markov chain samples\nfrom the posterior for a finite number of the priors, and we develop a\nmethodology, based on a combination of importance sampling and the use of\ncontrol variates, for dealing with these two problems. The methodology applies\nvery generally, and we show how it applies in particular to a commonly used\nmodel for variable selection in Bayesian linear regression, and give an\nillustration on the US crime data of Vandaele.\n", "versions": [{"version": "v1", "created": "Thu, 23 Feb 2012 12:31:58 GMT"}], "update_date": "2012-02-24", "authors_parsed": [["Buta", "Eugenia", ""], ["Doss", "Hani", ""]]}, {"id": "1202.5183", "submitter": "Peter Hall", "authors": "Peter Hall, Tung Pham, M. P. Wand, S. S. J. Wang", "title": "Asymptotic normality and valid inference for Gaussian variational\n  approximation", "comments": "Published in at http://dx.doi.org/10.1214/11-AOS908 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2011, Vol. 39, No. 5, 2502-2532", "doi": "10.1214/11-AOS908", "report-no": "IMS-AOS-AOS908", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive the precise asymptotic distributional behavior of Gaussian\nvariational approximate estimators of the parameters in a single-predictor\nPoisson mixed model. These results are the deepest yet obtained concerning the\nstatistical properties of a variational approximation method. Moreover, they\ngive rise to asymptotically valid statistical inference. A simulation study\ndemonstrates that Gaussian variational approximate confidence intervals possess\ngood to excellent coverage properties, and have a similar precision to their\nexact likelihood counterparts.\n", "versions": [{"version": "v1", "created": "Thu, 23 Feb 2012 14:09:43 GMT"}], "update_date": "2012-02-24", "authors_parsed": [["Hall", "Peter", ""], ["Pham", "Tung", ""], ["Wand", "M. P.", ""], ["Wang", "S. S. J.", ""]]}, {"id": "1202.5205", "submitter": "Kshitij Khare", "authors": "Kshitij Khare, James P. Hobert", "title": "A spectral analytic comparison of trace-class data augmentation\n  algorithms and their sandwich variants", "comments": "Published in at http://dx.doi.org/10.1214/11-AOS916 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2011, Vol. 39, No. 5, 2585-2606", "doi": "10.1214/11-AOS916", "report-no": "IMS-AOS-AOS916", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The data augmentation (DA) algorithm is a widely used Markov chain Monte\nCarlo algorithm that is easy to implement but often suffers from slow\nconvergence. The sandwich algorithm is an alternative that can converge much\nfaster while requiring roughly the same computational effort per iteration.\nTheoretically, the sandwich algorithm always converges at least as fast as the\ncorresponding DA algorithm in the sense that $\\Vert {K^*}\\Vert \\le \\Vert\n{K}\\Vert$, where $K$ and $K^*$ are the Markov operators associated with the DA\nand sandwich algorithms, respectively, and $\\Vert\\cdot\\Vert$ denotes operator\nnorm. In this paper, a substantial refinement of this operator norm inequality\nis developed. In particular, under regularity conditions implying that $K$ is a\ntrace-class operator, it is shown that $K^*$ is also a positive, trace-class\noperator, and that the spectrum of $K^*$ dominates that of $K$ in the sense\nthat the ordered elements of the former are all less than or equal to the\ncorresponding elements of the latter. Furthermore, if the sandwich algorithm is\nconstructed using a group action, as described by Liu and Wu [J. Amer. Statist.\nAssoc. 94 (1999) 1264--1274] and Hobert and Marchev [Ann. Statist. 36 (2008)\n532--554], then there is strict inequality between at least one pair of\neigenvalues. These results are applied to a new DA algorithm for Bayesian\nquantile regression introduced by Kozumi and Kobayashi [J. Stat. Comput. Simul.\n81 (2011) 1565--1578].\n", "versions": [{"version": "v1", "created": "Thu, 23 Feb 2012 15:22:28 GMT"}], "update_date": "2012-02-24", "authors_parsed": [["Khare", "Kshitij", ""], ["Hobert", "James P.", ""]]}, {"id": "1202.5432", "submitter": "Bercu Bernard", "authors": "Bernard Bercu, Thi Mong Ngoc Nguyen, Jerome Saracco", "title": "On the asymptotic behavior of the Nadaraya-Watson estimator associated\n  with the recursive SIR method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the asymptotic behavior of the Nadaraya-Watson estimator for\nthe estimation of the regression function in a semiparametric regression model.\nOn the one hand, we make use of the recursive version of the sliced inverse\nregression method for the estimation of the unknown parameter of the model. On\nthe other hand, we implement a recursive Nadaraya-Watson procedure for the\nestimation of the regression function which takes into account the previous\nestimation of the parameter of the semiparametric regression model. We\nestablish the almost sure convergence as well as the asymptotic normality for\nour Nadaraya-Watson estimator. We also illustrate our semiparametric estimation\nprocedure on simulated data.\n", "versions": [{"version": "v1", "created": "Fri, 24 Feb 2012 12:22:33 GMT"}], "update_date": "2012-02-27", "authors_parsed": [["Bercu", "Bernard", ""], ["Nguyen", "Thi Mong Ngoc", ""], ["Saracco", "Jerome", ""]]}, {"id": "1202.5536", "submitter": "Ery Arias-Castro", "authors": "Ery Arias-Castro, S\\'ebastien Bubeck, G\\'abor Lugosi", "title": "Detecting positive correlations in a multivariate sample", "comments": "Published at http://dx.doi.org/10.3150/13-BEJ565 in the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2015, Vol. 21, No. 1, 209-241", "doi": "10.3150/13-BEJ565", "report-no": "IMS-BEJ-BEJ565", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of testing whether a correlation matrix of a\nmultivariate normal population is the identity matrix. We focus on sparse\nclasses of alternatives where only a few entries are nonzero and, in fact,\npositive. We derive a general lower bound applicable to various classes and\nstudy the performance of some near-optimal tests. We pay special attention to\ncomputational feasibility and construct near-optimal tests that can be computed\nefficiently. Finally, we apply our results to prove new lower bounds for the\nclique number of high-dimensional random geometric graphs.\n", "versions": [{"version": "v1", "created": "Fri, 24 Feb 2012 19:48:03 GMT"}, {"version": "v2", "created": "Fri, 29 Mar 2013 22:15:49 GMT"}, {"version": "v3", "created": "Tue, 14 Apr 2015 07:52:36 GMT"}], "update_date": "2015-04-15", "authors_parsed": [["Arias-Castro", "Ery", ""], ["Bubeck", "S\u00e9bastien", ""], ["Lugosi", "G\u00e1bor", ""]]}, {"id": "1202.5638", "submitter": "Sylvain Delattre Mr", "authors": "Sylvain Delattre and Mathieu Rosenbaum", "title": "Testing the finiteness of the support of a distribution: a statistical\n  look at Tsirelson's equation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the following statistical problem: based on an i.i.d.sample of\nsize n of integer valued random variables with common law m, is it possible to\ntest whether or not the support of m is finite as n goes to infinity? This\nquestion is in particular connected to a simple case of Tsirelson's equation,\nfor which it is natural to distinguish between two main configurations, the\nfirst one leading only to laws with finite support, and the second one\nincluding laws with infinite support. We show that it is in fact not possible\nto discriminate between the two situations, even using a very weak notion of\nstatistical test.\n", "versions": [{"version": "v1", "created": "Sat, 25 Feb 2012 10:48:03 GMT"}], "update_date": "2012-02-28", "authors_parsed": [["Delattre", "Sylvain", ""], ["Rosenbaum", "Mathieu", ""]]}, {"id": "1202.5839", "submitter": "Jiahao Chen", "authors": "Jiahao Chen (1), Eric Hontz (1), Jeremy Moix (1), Matthew Welborn (1),\n  Troy Van Voorhis (1), Alberto Su\\'arez (2), Ramis Movassagh (3), Alan Edelman\n  (3) ((1) Department of Chemistry, Massachusetts Institute of Technology (2)\n  Departamento de Ingenier\\'ia Inform\\'atica, Universidad Aut\\'onoma de Madrid\n  (3) Department of Mathematics, Massachusetts Institute of Technology)", "title": "Error analysis of free probability approximations to the density of\n  states of disordered systems", "comments": "5 pages, 3 figures, submitted to Phys. Rev. Lett", "journal-ref": "Phys. Rev. Lett. 109, 036403 (2012)", "doi": "10.1103/PhysRevLett.109.036403", "report-no": null, "categories": "cond-mat.dis-nn math.ST physics.chem-ph quant-ph stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Theoretical studies of localization, anomalous diffusion and ergodicity\nbreaking require solving the electronic structure of disordered systems. We use\nfree probability to approximate the ensemble- averaged density of states\nwithout exact diagonalization. We present an error analysis that quantifies the\naccuracy using a generalized moment expansion, allowing us to distinguish\nbetween different approximations. We identify an approximation that is accurate\nto the eighth moment across all noise strengths, and contrast this with the\nperturbation theory and isotropic entanglement theory.\n", "versions": [{"version": "v1", "created": "Mon, 27 Feb 2012 07:30:07 GMT"}], "update_date": "2012-11-07", "authors_parsed": [["Chen", "Jiahao", ""], ["Hontz", "Eric", ""], ["Moix", "Jeremy", ""], ["Welborn", "Matthew", ""], ["Van Voorhis", "Troy", ""], ["Su\u00e1rez", "Alberto", ""], ["Movassagh", "Ramis", ""], ["Edelman", "Alan", ""]]}, {"id": "1202.5983", "submitter": "Mathias Trabs", "authors": "Jakob S\\\"ohl and Mathias Trabs", "title": "Option calibration of exponential L\\'evy models: Confidence intervals\n  and empirical results", "comments": "to appear in Journal of Computational Finance", "journal-ref": "J. Comput. Finance 18(2) (2014) 91-119", "doi": "10.21314/JCF.2014.275", "report-no": null, "categories": "q-fin.PR math.ST q-fin.CP stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Observing prices of European put and call options, we calibrate exponential\nL\\'evy models nonparametrically. We discuss the efficient implementation of the\nspectral estimation procedures for L\\'evy models of finite jump activity as\nwell as for self-decomposable L\\'evy models. Based on finite sample variances,\nconfidence intervals are constructed for the volatility, for the drift and,\npointwise, for the jump density. As demonstrated by simulations, these\nintervals perform well in terms of size and coverage probabilities. We compare\nthe performance of the procedures for finite and infinite jump activity based\non options on the German DAX index and find that both methods achieve good\ncalibration results. The stability of the finite activity model is studied when\nthe option prices are observed in a sequence of trading days.\n", "versions": [{"version": "v1", "created": "Mon, 27 Feb 2012 15:59:52 GMT"}, {"version": "v2", "created": "Mon, 3 Sep 2012 14:11:21 GMT"}, {"version": "v3", "created": "Wed, 17 Oct 2012 11:53:11 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["S\u00f6hl", "Jakob", ""], ["Trabs", "Mathias", ""]]}, {"id": "1202.6316", "submitter": "Fabien Navarro", "authors": "Fabien Navarro, Christophe Chesneau, Jalal Fadili, Taoufik Sassi", "title": "Block thresholding for wavelet-based estimation of function derivatives\n  from a heteroscedastic multichannel convolution model", "comments": null, "journal-ref": "Electron. J. Statist. Volume 7 (2013), 428-453", "doi": "10.1214/13-EJS776", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We observe $n$ heteroscedastic stochastic processes $\\{Y_v(t)\\}_{v}$, where\nfor any $v\\in\\{1,\\ldots,n\\}$ and $t \\in [0,1]$, $Y_v(t)$ is the convolution\nproduct of an unknown function $f$ and a known blurring function $g_v$\ncorrupted by Gaussian noise. Under an ordinary smoothness assumption on\n$g_1,\\ldots,g_n$, our goal is to estimate the $d$-th derivatives (in weak\nsense) of $f$ from the observations. We propose an adaptive estimator based on\nwavelet block thresholding, namely the \"BlockJS estimator\". Taking the mean\nintegrated squared error (MISE), our main theoretical result investigates the\nminimax rates over Besov smoothness spaces, and shows that our block estimator\ncan achieve the optimal minimax rate, or is at least nearly-minimax in the\nleast favorable situation. We also report a comprehensive suite of numerical\nsimulations to support our theoretical findings. The practical performance of\nour block estimator compares very favorably to existing methods of the\nliterature on a large set of test functions.\n", "versions": [{"version": "v1", "created": "Tue, 28 Feb 2012 18:29:30 GMT"}, {"version": "v2", "created": "Mon, 26 Mar 2012 15:17:54 GMT"}, {"version": "v3", "created": "Wed, 13 Mar 2013 16:01:49 GMT"}], "update_date": "2017-03-13", "authors_parsed": [["Navarro", "Fabien", ""], ["Chesneau", "Christophe", ""], ["Fadili", "Jalal", ""], ["Sassi", "Taoufik", ""]]}, {"id": "1202.6427", "submitter": "Yaakov Malinovsky", "authors": "Abram M. Kagan and Yaakov Malinovsky", "title": "Monotonicity in the Sample Size of the Length of Classical Confidence\n  Intervals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is proved that the average length of standard confidence intervals for\nparameters of gamma and normal distributions monotonically decrease with the\nsample size. The proofs are based on fine properties of the classical gamma\nfunction.\n", "versions": [{"version": "v1", "created": "Wed, 29 Feb 2012 02:51:03 GMT"}, {"version": "v2", "created": "Thu, 19 Jul 2012 16:12:12 GMT"}, {"version": "v3", "created": "Tue, 28 Aug 2012 23:54:59 GMT"}], "update_date": "2012-08-30", "authors_parsed": [["Kagan", "Abram M.", ""], ["Malinovsky", "Yaakov", ""]]}, {"id": "1202.6469", "submitter": "Paul Rochet", "authors": "Paul Rochet (IMT)", "title": "Bayesian interpretation of Generalized empirical likelihood by maximum\n  entropy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a parametric estimation problem related to moment condition models.\nAs an alternative to the generalized empirical likelihood (GEL) and the\ngeneralized method of moments (GMM), a Bayesian approach to the problem can be\nadopted, extending the MEM procedure to parametric moment conditions. We show\nin particular that a large number of GEL estimators can be interpreted as a\nmaximum entropy solution. Moreover, we provide a more general field of\napplications by proving the method to be robust to approximate moment\nconditions.\n", "versions": [{"version": "v1", "created": "Wed, 29 Feb 2012 07:47:45 GMT"}], "update_date": "2012-03-02", "authors_parsed": [["Rochet", "Paul", "", "IMT"]]}, {"id": "1202.6545", "submitter": "Jean-Baptiste Durand", "authors": "Jean-Baptiste Durand (INRIA Grenoble Rh\\^one-Alpes / LJK Laboratoire\n  Jean Kuntzmann), Y. Gu\\'edon (DAP)", "title": "Localizing the Latent Structure Canonical Uncertainty: Entropy Profiles\n  for Hidden Markov Models", "comments": "Submitted to Journal of Machine Learning Research; No RR-7896 (2012)", "journal-ref": "Stat. Comput. (2016), 26(1-2):549-567", "doi": "10.1007/s11222-014-9494-9", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This report addresses state inference for hidden Markov models. These models\nrely on unobserved states, which often have a meaningful interpretation. This\nmakes it necessary to develop diagnostic tools for quantification of state\nuncertainty. The entropy of the state sequence that explains an observed\nsequence for a given hidden Markov chain model can be considered as the\ncanonical measure of state sequence uncertainty. This canonical measure of\nstate sequence uncertainty is not reflected by the classic multivariate state\nprofiles computed by the smoothing algorithm, which summarizes the possible\nstate sequences. Here, we introduce a new type of profiles which have the\nfollowing properties: (i) these profiles of conditional entropies are a\ndecomposition of the canonical measure of state sequence uncertainty along the\nsequence and makes it possible to localize this uncertainty, (ii) these\nprofiles are univariate and thus remain easily interpretable on tree\nstructures. We show how to extend the smoothing algorithms for hidden Markov\nchain and tree models to compute these entropy profiles efficiently.\n", "versions": [{"version": "v1", "created": "Wed, 29 Feb 2012 13:37:48 GMT"}], "update_date": "2018-10-26", "authors_parsed": [["Durand", "Jean-Baptiste", "", "INRIA Grenoble Rh\u00f4ne-Alpes / LJK Laboratoire\n  Jean Kuntzmann"], ["Gu\u00e9don", "Y.", "", "DAP"]]}, {"id": "1202.6558", "submitter": "Bruno Saussereau", "authors": "Bruno Saussereau", "title": "Transportation inequalities for stochastic differential equations driven\n  by a fractional Brownian motion", "comments": "Published in at http://dx.doi.org/10.3150/10-BEJ324 the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2012, Vol. 18, No. 1, 1-23", "doi": "10.3150/10-BEJ324", "report-no": "IMS-BEJ-BEJ324", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We establish Talagrand's $T_1$ and $T_2$ inequalities for the law of the\nsolution of a stochastic differential equation driven by a fractional Brownian\nmotion with Hurst parameter $H>1/2$. We use the $L^2$ metric and the uniform\nmetric on the path space of continuous functions on $[0,T]$. These results are\napplied to study small-time and large-time asymptotics for the solutions of\nsuch equations by means of a Hoeffding-type inequality.\n", "versions": [{"version": "v1", "created": "Wed, 29 Feb 2012 14:32:47 GMT"}], "update_date": "2012-03-01", "authors_parsed": [["Saussereau", "Bruno", ""]]}, {"id": "1202.6590", "submitter": "Giusi Moffa", "authors": "Jack Kuipers and Giusi Moffa", "title": "Uniform random generation of large acyclic digraphs", "comments": "15 pages, 2 figures. To appear in Statistics and Computing", "journal-ref": null, "doi": "10.1007/s11222-013-9428-y", "report-no": null, "categories": "stat.CO math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Directed acyclic graphs are the basic representation of the structure\nunderlying Bayesian networks, which represent multivariate probability\ndistributions. In many practical applications, such as the reverse engineering\nof gene regulatory networks, not only the estimation of model parameters but\nthe reconstruction of the structure itself is of great interest. As well as for\nthe assessment of different structure learning algorithms in simulation\nstudies, a uniform sample from the space of directed acyclic graphs is required\nto evaluate the prevalence of certain structural features. Here we analyse how\nto sample acyclic digraphs uniformly at random through recursive enumeration,\nan approach previously thought too computationally involved. Based on\ncomplexity considerations, we discuss in particular how the enumeration\ndirectly provides an exact method, which avoids the convergence issues of the\nalternative Markov chain methods and is actually computationally much faster.\nThe limiting behaviour of the distribution of acyclic digraphs then allows us\nto sample arbitrarily large graphs. Building on the ideas of recursive\nenumeration based sampling we also introduce a novel hybrid Markov chain with\nmuch faster convergence than current alternatives while still being easy to\nadapt to various restrictions. Finally we discuss how to include such\nrestrictions in the combinatorial enumeration and the new hybrid Markov chain\nmethod for efficient uniform sampling of the corresponding graphs.\n", "versions": [{"version": "v1", "created": "Wed, 29 Feb 2012 16:24:13 GMT"}, {"version": "v2", "created": "Thu, 27 Sep 2012 12:50:10 GMT"}, {"version": "v3", "created": "Fri, 3 May 2013 13:51:07 GMT"}, {"version": "v4", "created": "Thu, 14 Nov 2013 20:56:06 GMT"}], "update_date": "2013-11-15", "authors_parsed": [["Kuipers", "Jack", ""], ["Moffa", "Giusi", ""]]}, {"id": "1202.6611", "submitter": "Jakob S\\\"ohl", "authors": "Jakob S\\\"ohl", "title": "Confidence sets in nonparametric calibration of exponential L\\'evy\n  models", "comments": "to appear in Finance and Stochastics", "journal-ref": "Finance Stoch. 18 (2014) 617-649", "doi": "10.1007/s00780-014-0228-9", "report-no": null, "categories": "q-fin.ST math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Confidence intervals and joint confidence sets are constructed for the\nnonparametric calibration of exponential L\\'evy models based on prices of\nEuropean options. To this end, we show joint asymptotic normality in the\nspectral calibration method for the estimators of the volatility, the drift,\nthe jump intensity and the L\\'evy density at finitely many points.\n", "versions": [{"version": "v1", "created": "Wed, 29 Feb 2012 17:18:00 GMT"}, {"version": "v2", "created": "Thu, 19 Sep 2013 10:41:02 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["S\u00f6hl", "Jakob", ""]]}]