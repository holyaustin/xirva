[{"id": "1512.00133", "submitter": "Jinzhu Jia", "authors": "Jiyi Liu and Jinzhu Jia", "title": "Vanilla Lasso for sparse classification under single index models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper study sparse classification problems. We show that under\nsingle-index models, vanilla Lasso could give good estimate of unknown\nparameters. With this result, we see that even if the model is not linear, and\neven if the response is not continuous, we could still use vanilla Lasso to\ntrain classifiers. Simulations confirm that vanilla Lasso could be used to get\na good estimation when data are generated from a logistic regression model.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2015 03:33:40 GMT"}, {"version": "v2", "created": "Sun, 20 Dec 2015 12:11:50 GMT"}], "update_date": "2015-12-22", "authors_parsed": [["Liu", "Jiyi", ""], ["Jia", "Jinzhu", ""]]}, {"id": "1512.00150", "submitter": "Chao Gao", "authors": "Chao Gao, Yu Lu, Zongming Ma, Harrison H. Zhou", "title": "Optimal Estimation and Completion of Matrices with Biclustering\n  Structures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Biclustering structures in data matrices were first formalized in a seminal\npaper by John Hartigan (1972) where one seeks to cluster cases and variables\nsimultaneously. Such structures are also prevalent in block modeling of\nnetworks. In this paper, we develop a unified theory for the estimation and\ncompletion of matrices with biclustering structures, where the data is a\npartially observed and noise contaminated data matrix with a certain\nbiclustering structure. In particular, we show that a constrained least squares\nestimator achieves minimax rate-optimal performance in several of the most\nimportant scenarios. To this end, we derive unified high probability upper\nbounds for all sub-Gaussian data and also provide matching minimax lower bounds\nin both Gaussian and binary cases. Due to the close connection of graphon to\nstochastic block models, an immediate consequence of our general results is a\nminimax rate-optimal estimator for sparse graphons.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2015 05:54:23 GMT"}, {"version": "v2", "created": "Mon, 22 Oct 2018 19:54:21 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Gao", "Chao", ""], ["Lu", "Yu", ""], ["Ma", "Zongming", ""], ["Zhou", "Harrison H.", ""]]}, {"id": "1512.00209", "submitter": "Christiane G\\\"orgen", "authors": "Christiane G\\\"orgen and Jim Q. Smith", "title": "Equivalence Classes of Staged Trees", "comments": "18 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we give a complete characterization of the statistical\nequivalence classes of CEGs and of staged trees. We are able to show that all\ngraphical representations of the same model share a common polynomial\ndescription. Then, simple transformations on that polynomial enable us to\ntraverse the corresponding class of graphs. We illustrate our results with a\nreal analysis of the implicit dependence relationships within a previously\nstudied dataset.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2015 10:33:53 GMT"}, {"version": "v2", "created": "Tue, 12 Jan 2016 10:20:49 GMT"}, {"version": "v3", "created": "Mon, 12 Sep 2016 14:46:47 GMT"}, {"version": "v4", "created": "Fri, 26 May 2017 07:45:44 GMT"}], "update_date": "2017-05-29", "authors_parsed": [["G\u00f6rgen", "Christiane", ""], ["Smith", "Jim Q.", ""]]}, {"id": "1512.00218", "submitter": "Johannes Schmidt-Hieber", "authors": "Kolyan Ray and Johannes Schmidt-Hieber", "title": "Minimax theory for a class of non-linear statistical inverse problems", "comments": "37 pages", "journal-ref": "Inverse Problems 32 (2016) 065003", "doi": "10.1088/0266-5611/32/6/065003", "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a class of statistical inverse problems with non-linear pointwise\noperators motivated by concrete statistical applications. A two-step procedure\nis proposed, where the first step smoothes the data and inverts the\nnon-linearity. This reduces the initial non-linear problem to a linear inverse\nproblem with deterministic noise, which is then solved in a second step. The\nnoise reduction step is based on wavelet thresholding and is shown to be\nminimax optimal (up to logarithmic factors) in a pointwise function-dependent\nsense. Our analysis is based on a modified notion of H\\\"older smoothness scales\nthat are natural in this setting.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2015 10:53:59 GMT"}, {"version": "v2", "created": "Wed, 11 May 2016 12:33:32 GMT"}], "update_date": "2016-11-08", "authors_parsed": [["Ray", "Kolyan", ""], ["Schmidt-Hieber", "Johannes", ""]]}, {"id": "1512.00245", "submitter": "Panayiota Constantinou", "authors": "Panayiota Constantinou and A. Philip Dawid", "title": "Extended Conditional Independence and Applications in Causal Inference", "comments": null, "journal-ref": "Annals of Statistics 45 (2017), 2618-2653", "doi": "10.1214/16-AOS153", "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of this paper is to integrate the notions of stochastic conditional\nindependence and variation conditional independence under a more general notion\nof extended conditional independence. We show that under appropriate\nassumptions the calculus that applies for the two cases separately (axioms of a\nseparoid) still applies for the extended case. These results provide a rigorous\nbasis for a wide range of statistical concepts, including ancillarity and\nsufficiency, and, in particular, the Decision Theoretic framework for\nstatistical causality, which uses the language and calculus of conditional\nindependence in order to express causal properties and make causal inferences.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2015 13:06:01 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Constantinou", "Panayiota", ""], ["Dawid", "A. Philip", ""]]}, {"id": "1512.00319", "submitter": "Michael Messer", "authors": "Michael Messer, Kau\\^e M. Costa, Jochen Roeper and Gaby Schneider", "title": "Multi-scale detection of rate changes in spike trains with weak\n  dependencies", "comments": "The final publication is available at http://link.springer.com", "journal-ref": null, "doi": "10.1007/s10827-016-0635-3", "report-no": null, "categories": "math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The statistical analysis of neuronal spike trains by models of point\nprocesses often relies on the assumption of constant process parameters.\nHowever, it is a well-known problem that the parameters of empirical spike\ntrains can be highly variable, such as for example the firing rate. In order to\ntest the null hypothesis of a constant rate and to estimate the change points,\na Multiple Filter Test (MFT) and a corresponding algorithm (MFA) have been\nproposed that can be applied under the assumption of independent inter spike\nintervals (ISIs).\n  As empirical spike trains often show weak dependencies in the correlation\nstructure of ISIs, we extend the MFT here to point processes associated with\nshort range dependencies. By specifically estimating serial dependencies in the\ntest statistic, we show that the new MFT can be applied to a variety of\nempirical firing patterns, including positive and negative serial correlations\nas well as tonic and bursty firing. The new MFT is applied to a data set of\nempirical spike trains with serial correlations, and simulations show improved\nperformance against methods that assume independence. In case of positive\ncorrelations, our new MFT is necessary to reduce the number of false positives,\nwhich can be highly enhanced when falsely assuming independence. For the\nfrequent case of negative correlations, the new MFT shows an improved detection\nprobability of change points and thus, also a higher potential of signal\nextraction from noisy spike trains.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2015 16:14:46 GMT"}, {"version": "v2", "created": "Sat, 10 Dec 2016 20:51:11 GMT"}], "update_date": "2016-12-13", "authors_parsed": [["Messer", "Michael", ""], ["Costa", "Kau\u00ea M.", ""], ["Roeper", "Jochen", ""], ["Schneider", "Gaby", ""]]}, {"id": "1512.00377", "submitter": "Fatma Zehra Do\\u{g}ru", "authors": "Fatma Zehra Do\\u{g}ru and Olcay Arslan", "title": "Robust mixture regression based on the skew t distribution", "comments": "15", "journal-ref": null, "doi": "10.15446/rce.v40n1.53580", "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, we propose a robust mixture regression procedure based on the\nskew t distribution to model heavy-tailed and/or skewed errors in a mixture\nregression setting. Using the scale mixture representation of the skew t\ndistribution, we give an Expectation Maximization (EM) algorithm to compute the\nmaximum likelihood (ML) estimates for the paramaters of interest. The\nperformance of proposed estimators is demonstrated by a simulation study and a\nreal data example.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2015 18:34:00 GMT"}], "update_date": "2017-06-12", "authors_parsed": [["Do\u011fru", "Fatma Zehra", ""], ["Arslan", "Olcay", ""]]}, {"id": "1512.00384", "submitter": "Bhaswar Bhattacharya", "authors": "Bhaswar B. Bhattacharya", "title": "Asymptotic Distribution and Detection Thresholds for Two-Sample Tests\n  Based on Geometric Graphs", "comments": "66 pages", "journal-ref": "Annals of Statistics, Vol. 48 (5), 2879-2903, 2020", "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the problem of testing the equality of two\nmultivariate distributions based on geometric graphs constructed using the\ninterpoint distances between the observations. These include the tests based on\nthe minimum spanning tree and the $K$-nearest neighbor (NN) graphs, among\nothers. These tests are asymptotically distribution-free, universally\nconsistent and computationally efficient, making them particularly useful in\nmodern applications. However, very little is known about the power properties\nof these tests. In this paper, using the theory of stabilizing geometric\ngraphs, we derive the asymptotic distribution of these tests under general\nalternatives, in the Poissonized setting. Using this, the detection threshold\nand the limiting local power of the test based on the $K$-NN graph are\nobtained, where interesting exponents depending on dimension emerge. This\nprovides a way to compare and justify the performance of these tests in\ndifferent examples.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2015 18:46:14 GMT"}, {"version": "v2", "created": "Wed, 22 Jun 2016 19:16:11 GMT"}, {"version": "v3", "created": "Fri, 18 May 2018 05:24:01 GMT"}, {"version": "v4", "created": "Mon, 1 Mar 2021 23:42:45 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Bhattacharya", "Bhaswar B.", ""]]}, {"id": "1512.00425", "submitter": "Abdelhakim Necir", "authors": "Souad Benchaira, Djamel Meraghni, Abdelhakim Necir", "title": "Kernel estimation of the tail index of a right-truncated Pareto-type\n  distribution", "comments": "arXiv admin note: text overlap with arXiv:1507.01548", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we define a kernel estimator for the tail index of a\nPareto-type distribution under random right-truncation and establish its\nasymptotic normality. A simulation study shows that, compared to the estimators\nrecently proposed by Gardes & Stupfler (2015) and Benchaira et al. (2015), this\nnewly introduced estimator behaves better, in terms of bias and mean squared\nerror, for small samples.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2015 20:27:33 GMT"}], "update_date": "2015-12-02", "authors_parsed": [["Benchaira", "Souad", ""], ["Meraghni", "Djamel", ""], ["Necir", "Abdelhakim", ""]]}, {"id": "1512.00677", "submitter": "Sara van de Geer", "authors": "Sara van de Geer and Martin Wainwright", "title": "On concentration for (regularized) empirical risk minimization", "comments": "27 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rates of convergence for empirical risk minimizers have been well studied in\nthe literature. In this paper, we aim to provide a complementary set of\nresults, in particular by showing that after normalization, the risk of the\nempirical minimizer concentrates on a single point. Such results have been\nestablished by~\\cite{chatterjee2014new} for constrained estimators in the\nnormal sequence model. We first generalize and sharpen this result to\nregularized least squares with convex penalties, making use of a \"direct\"\nargument based on Borell's theorem. We then study generalizations to other loss\nfunctions, including the negative log-likelihood for exponential families\ncombined with a strictly convex regularization penalty. The results in this\ngeneral setting are based on more \"indirect\" arguments as well as on\nconcentration inequalities for maxima of empirical processes.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2015 12:54:09 GMT"}, {"version": "v2", "created": "Mon, 11 Jan 2016 11:16:58 GMT"}], "update_date": "2016-01-12", "authors_parsed": [["van de Geer", "Sara", ""], ["Wainwright", "Martin", ""]]}, {"id": "1512.00752", "submitter": "Ran J. Tessler", "authors": "Tomer M. Schlank, Ran J. Tessler and Amitai Zernik", "title": "Exact maximum-entropy estimation with Feynman diagrams", "comments": "A few minor corrections", "journal-ref": "J Stat Phys (2018) 170: 731", "doi": "10.1007/s10955-018-1960-x", "report-no": null, "categories": "math.CO math-ph math.MP math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A classical longstanding open problem in statistics is finding an explicit\nexpression for the probability measure which maximizes entropy with respect to\ngiven constraints. In this paper a solution to this problem is found, using\nperturbative Feynman calculus. The explicit expression is given as a sum over\nweighted trees.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2015 15:10:03 GMT"}, {"version": "v2", "created": "Thu, 10 Dec 2015 15:46:22 GMT"}, {"version": "v3", "created": "Mon, 22 Feb 2016 20:47:14 GMT"}, {"version": "v4", "created": "Sun, 23 Sep 2018 04:47:24 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Schlank", "Tomer M.", ""], ["Tessler", "Ran J.", ""], ["Zernik", "Amitai", ""]]}, {"id": "1512.00819", "submitter": "Shuyang (Ray) Bai", "authors": "Shuyang Bai and Murad S. Taqqu", "title": "On the validity of resampling methods under long memory", "comments": "36 pages. To appear in The Annals of Statistics", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For long-memory time series, inference based on resampling is of crucial\nimportance, since the asymptotic distribution can often be non-Gaussian and is\ndifficult to determine statistically. However due to the strong dependence,\nestablishing the asymptotic validity of resampling methods is nontrivial. In\nthis paper, we derive an efficient bound for the canonical correlation between\ntwo finite blocks of a long-memory time series. We show how this bound can be\napplied to establish the asymptotic consistency of subsampling procedures for\ngeneral statistics under long memory. It allows the subsample size $b$ to be\n$o(n)$, where $n$ is the sample size, irrespective of the strength of the\nmemory. We are then able to improve many results found in the literature. We\nalso consider applications of subsampling procedures under long memory to the\nsample covariance, M-estimation and empirical processes.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2015 19:38:03 GMT"}, {"version": "v2", "created": "Tue, 22 Dec 2015 22:25:26 GMT"}, {"version": "v3", "created": "Wed, 24 Feb 2016 05:33:28 GMT"}, {"version": "v4", "created": "Thu, 30 Jun 2016 08:12:37 GMT"}, {"version": "v5", "created": "Wed, 9 Nov 2016 01:30:36 GMT"}], "update_date": "2016-11-10", "authors_parsed": [["Bai", "Shuyang", ""], ["Taqqu", "Murad S.", ""]]}, {"id": "1512.00820", "submitter": "Shuyang Bai", "authors": "Shuyang Bai, Murad S. Taqqu and Ting Zhang", "title": "A unified approach to self-normalized block sampling", "comments": "32 pages, minor revision", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The inference procedure for the mean of a stationary time series is usually\nquite different under various model assumptions because the partial sum process\nbehaves differently depending on whether the time series is short or long-range\ndependent, or whether it has a light or heavy-tailed marginal distribution. In\nthe current paper, we develop an asymptotic theory for the self-normalized\nblock sampling, and prove that the corresponding block sampling method can\nprovide a unified inference approach for the aforementioned different\nsituations in the sense that it does not require the {\\em a priori} estimation\nof auxiliary parameters. Monte Carlo simulations are presented to illustrate\nits finite-sample performance. The R function implementing the method is\navailable from the authors.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2015 19:40:09 GMT"}, {"version": "v2", "created": "Sun, 20 Mar 2016 18:37:28 GMT"}], "update_date": "2016-03-22", "authors_parsed": [["Bai", "Shuyang", ""], ["Taqqu", "Murad S.", ""], ["Zhang", "Ting", ""]]}, {"id": "1512.00847", "submitter": "Yannis Yatracos", "authors": "Yannis G. Yatracos", "title": "Statistical Inference with Data Augmentation and Parameter Expansion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical pragmatism embraces all efficient methods in statistical\ninference. Augmentation of the collected data is used herein to obtain\nrepresentative population information from a large class of non-representative\npopulation's units. Parameter expansion of a probability model is shown to\nreduce the upper bound on the sum of error probabilities for a test of simple\nhypotheses, and a measure, R, is proposed for the effect of activating\nadditional component(s) in the sufficient statistic.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2015 18:17:38 GMT"}], "update_date": "2015-12-04", "authors_parsed": [["Yatracos", "Yannis G.", ""]]}, {"id": "1512.00933", "submitter": "Francois-Xavier Briol", "authors": "Fran\\c{c}ois-Xavier Briol, Chris. J. Oates, Mark Girolami, Michael A.\n  Osborne and Dino Sejdinovic", "title": "Probabilistic Integration: A Role in Statistical Computation?", "comments": "Several improvements suggested by reviewers, including additional\n  experiments on uncertainty quantification properties. Change of title:\n  previously \"Probabilistic Integration: A Role for Statisticians in Numerical\n  Analysis?\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.NA math.NA math.ST stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A research frontier has emerged in scientific computation, wherein numerical\nerror is regarded as a source of epistemic uncertainty that can be modelled.\nThis raises several statistical challenges, including the design of statistical\nmethods that enable the coherent propagation of probabilities through a\n(possibly deterministic) computational work-flow. This paper examines the case\nfor probabilistic numerical methods in routine statistical computation. Our\nfocus is on numerical integration, where a probabilistic integrator is equipped\nwith a full distribution over its output that reflects the presence of an\nunknown numerical error. Our main technical contribution is to establish, for\nthe first time, rates of posterior contraction for these methods. These show\nthat probabilistic integrators can in principle enjoy the \"best of both\nworlds\", leveraging the sampling efficiency of Monte Carlo methods whilst\nproviding a principled route to assess the impact of numerical error on\nscientific conclusions. Several substantial applications are provided for\nillustration and critical evaluation, including examples from statistical\nmodelling, computer graphics and a computer model for an oil reservoir.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2015 02:52:33 GMT"}, {"version": "v2", "created": "Mon, 4 Apr 2016 22:29:14 GMT"}, {"version": "v3", "created": "Wed, 6 Apr 2016 06:09:18 GMT"}, {"version": "v4", "created": "Mon, 11 Apr 2016 09:15:20 GMT"}, {"version": "v5", "created": "Thu, 20 Oct 2016 08:44:17 GMT"}, {"version": "v6", "created": "Wed, 18 Oct 2017 14:15:40 GMT"}], "update_date": "2017-10-19", "authors_parsed": [["Briol", "Fran\u00e7ois-Xavier", ""], ["Oates", "Chris. J.", ""], ["Girolami", "Mark", ""], ["Osborne", "Michael A.", ""], ["Sejdinovic", "Dino", ""]]}, {"id": "1512.00969", "submitter": "Daniel Williamson", "authors": "Daniel Williamson, Michael Goldstein", "title": "Posterior Belief Assessment: Extracting Meaningful Subjective Judgements\n  from Bayesian Analyses with Complex Statistical Models", "comments": "Published at http://dx.doi.org/10.1214/15-BA966SI in the Bayesian\n  Analysis (http://projecteuclid.org/euclid.ba) by the International Society of\n  Bayesian Analysis (http://bayesian.org/)", "journal-ref": "Bayesian Analysis 2015, Vol. 10, No. 4, 877-908", "doi": "10.1214/15-BA966SI", "report-no": "VTeX-BA-BA966SI", "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we are concerned with attributing meaning to the results of a\nBayesian analysis for a problem which is sufficiently complex that we are\nunable to assert a precise correspondence between the expert probabilistic\njudgements of the analyst and the particular forms chosen for the prior\nspecification and the likelihood for the analysis. In order to do this, we\npropose performing a finite collection of additional Bayesian analyses under\nalternative collections of prior and likelihood modelling judgements that we\nmay also view as representative of our prior knowledge and the problem\nstructure, and use these to compute posterior belief assessments for key\nquantities of interest. We show that these assessments are closer to our true\nunderlying beliefs than the original Bayesian analysis and use the temporal\nsure preference principle to establish a probabilistic relationship between our\ntrue posterior judgements, our posterior belief assessment and our original\nBayesian analysis to make this precise. We exploit second order exchangeability\nin order to generalise our approach to situations where there are infinitely\nmany alternative Bayesian analyses we might consider as informative for our\ntrue judgements so that the method remains tractable even in these cases. We\nargue that posterior belief assessment is a tractable and powerful alternative\nto robust Bayesian analysis. We describe a methodology for computing posterior\nbelief assessments in even the most complex of statistical models and\nillustrate with an example of calibrating an expensive ocean model in order to\nquantify uncertainty about global mean temperature in the real ocean.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2015 07:10:07 GMT"}], "update_date": "2015-12-04", "authors_parsed": [["Williamson", "Daniel", ""], ["Goldstein", "Michael", ""]]}, {"id": "1512.00976", "submitter": "Lutz Gruber", "authors": "Lutz Gruber, Claudia Czado", "title": "Sequential Bayesian Model Selection of Regular Vine Copulas", "comments": "Published at http://dx.doi.org/10.1214/14-BA930 in the Bayesian\n  Analysis (http://projecteuclid.org/euclid.ba) by the International Society of\n  Bayesian Analysis (http://bayesian.org/)", "journal-ref": "Bayesian Analysis 2015, Vol. 10, No. 4, 937-963", "doi": "10.1214/14-BA930", "report-no": "VTeX-BA-BA930", "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regular vine copulas can describe a wider array of dependency patterns than\nthe multivariate Gaussian copula or the multivariate Student's t copula. This\npaper presents two contributions related to model selection of regular vine\ncopulas. First, our pair copula family selection procedure extends existing\nBayesian family selection methods by allowing pair families to be chosen from\nan arbitrary set of candidate families. Second, our method represents the first\nBayesian model selection approach to include the regular vine density\nconstruction in its scope of inference. The merits of our approach are\nestablished in a simulation study that benchmarks against methods suggested in\ncurrent literature. A real data example about forecasting of portfolio asset\nreturns for risk measurement and investment allocation illustrates the\nviability and relevance of the proposed scheme.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2015 07:39:13 GMT"}], "update_date": "2015-12-04", "authors_parsed": [["Gruber", "Lutz", ""], ["Czado", "Claudia", ""]]}, {"id": "1512.00982", "submitter": "Jere Koskela", "authors": "Jere Koskela and Paul A. Jenkins and Dario Span\\`o", "title": "Bayesian non-parametric inference for $\\Lambda$-coalescents: consistency\n  and a parametric method", "comments": "28 pages, 3 figures", "journal-ref": "Bernoulli 24(3):2122-2153, 2018", "doi": "10.3150/16-BEJ923", "report-no": null, "categories": "stat.ME math.PR math.ST q-bio.PE stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate Bayesian non-parametric inference of the $\\Lambda$-measure of\n$\\Lambda$-coalescent processes with recurrent mutation, parametrised by\nprobability measures on the unit interval. We give verifiable criteria on the\nprior for posterior consistency when observations form a time series, and prove\nthat any non-trivial prior is inconsistent when all observations are\ncontemporaneous. We then show that the likelihood given a data set of size $n\n\\in \\mathbb{N}$ is constant across $\\Lambda$-measures whose leading $n - 2$\nmoments agree, and focus on inferring truncated sequences of moments. We\nprovide a large class of functionals which can be extremised using finite\ncomputation given a credible region of posterior truncated moment sequences,\nand a pseudo-marginal Metropolis-Hastings algorithm for sampling the posterior.\nFinally, we compare the efficiency of the exact and noisy pseudo-marginal\nalgorithms with and without delayed acceptance acceleration using a simulation\nstudy.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2015 08:03:36 GMT"}, {"version": "v2", "created": "Wed, 16 Dec 2015 15:32:37 GMT"}, {"version": "v3", "created": "Wed, 13 Jul 2016 11:03:21 GMT"}, {"version": "v4", "created": "Wed, 24 Aug 2016 16:19:58 GMT"}, {"version": "v5", "created": "Mon, 23 Jan 2017 18:21:10 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Koskela", "Jere", ""], ["Jenkins", "Paul A.", ""], ["Span\u00f2", "Dario", ""]]}, {"id": "1512.01013", "submitter": "Xiaofan Xu", "authors": "Xiaofan Xu, Malay Ghosh", "title": "Bayesian Variable Selection and Estimation for Group Lasso", "comments": "Published at http://dx.doi.org/10.1214/14-BA929 in the Bayesian\n  Analysis (http://projecteuclid.org/euclid.ba) by the International Society of\n  Bayesian Analysis (http://bayesian.org/)", "journal-ref": "Bayesian Analysis 2015, Vol. 10, No. 4, 909-936", "doi": "10.1214/14-BA929", "report-no": "VTeX-BA-BA929", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper revisits the Bayesian group lasso and uses spike and slab priors\nfor group variable selection. In the process, the connection of our model with\npenalized regression is demonstrated, and the role of posterior median for\nthresholding is pointed out. We show that the posterior median estimator has\nthe oracle property for group variable selection and estimation under\northogonal designs, while the group lasso has suboptimal asymptotic estimation\nrate when variable selection consistency is achieved. Next we consider bi-level\nselection problem and propose the Bayesian sparse group selection again with\nspike and slab priors to select variables both at the group level and also\nwithin a group. We demonstrate via simulation that the posterior median\nestimator of our spike and slab models has excellent performance for both\nvariable selection and estimation.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2015 09:47:17 GMT"}], "update_date": "2015-12-04", "authors_parsed": [["Xu", "Xiaofan", ""], ["Ghosh", "Malay", ""]]}, {"id": "1512.01068", "submitter": "Housen Li", "authors": "Markus Grasmair and Housen Li and Axel Munk", "title": "Variational Multiscale Nonparametric Regression: Smooth Functions", "comments": null, "journal-ref": "Annales de l'Institut Henri Poincar\\'e Probabilit\\'es et\n  Statistiques, 54(2), 1058--1097, 2018", "doi": "10.1214/17-AIHP832", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For the problem of nonparametric regression of smooth functions, we\nreconsider and analyze a constrained variational approach, which we call the\nMultIscale Nemirovski-Dantzig (MIND) estimator. This can be viewed as a\nmultiscale extension of the Dantzig selector (\\emph{Ann. Statist.}, 35(6):\n2313--51, 2009) based on early ideas of Nemirovski (\\emph{J. Comput. System\nSci.}, 23:1--11, 1986). MIND minimizes a homogeneous Sobolev norm under the\nconstraint that the multiresolution norm of the residual is bounded by a\nuniversal threshold. The main contribution of this paper is the derivation of\nconvergence rates of MIND with respect to $L^q$-loss, $1 \\le q \\le \\infty$,\nboth almost surely and in expectation. To this end, we introduce the method of\napproximate source conditions. For a one-dimensional signal, these can be\ntranslated into approximation properties of $B$-splines. A remarkable\nconsequence is that MIND attains almost minimax optimal rates simultaneously\nfor a large range of Sobolev and Besov classes, which provides certain\nadaptation. Complimentary to the asymptotic analysis, we examine the finite\nsample performance of MIND by numerical simulations.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2015 13:07:43 GMT"}], "update_date": "2018-05-02", "authors_parsed": [["Grasmair", "Markus", ""], ["Li", "Housen", ""], ["Munk", "Axel", ""]]}, {"id": "1512.01215", "submitter": "Garvesh Raskutti", "authors": "Garvesh Raskutti, Ming Yuan, Han Chen", "title": "Convex Regularization for High-Dimensional Multi-Response Tensor\n  Regression", "comments": "64 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a general convex optimization approach for solving\nhigh-dimensional multiple response tensor regression problems under\nlow-dimensional structural assumptions. We consider using convex and weakly\ndecomposable regularizers assuming that the underlying tensor lies in an\nunknown low-dimensional subspace. Within our framework, we derive general risk\nbounds of the resulting estimate under fairly general dependence structure\namong covariates. Our framework leads to upper bounds in terms of two very\nsimple quantities, the \\emph{Gaussian width} of a convex set in tensor space\nand the \\emph{intrinsic dimension} of the low-dimensional tensor subspace. To\nthe best of our knowledge, this is the first general framework that applies to\nmultiple response problems. These general bounds provide useful upper bounds on\nrates of convergence for a number of fundamental statistical models of interest\nincluding multi-response regression, vector auto-regressive models, low-rank\ntensor models and pairwise interaction models. Moreover, in many of these\nsettings we prove that the resulting estimates are minimax optimal. We also\nprovide a numerical study that both validates our theoretical guarantees and\ndemonstrates the breadth of our framework.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2015 20:25:15 GMT"}, {"version": "v2", "created": "Thu, 13 Apr 2017 20:26:07 GMT"}], "update_date": "2017-04-17", "authors_parsed": [["Raskutti", "Garvesh", ""], ["Yuan", "Ming", ""], ["Chen", "Han", ""]]}, {"id": "1512.01229", "submitter": "David Alvarez-Melis", "authors": "David Alvarez-Melis and Tamara Broderick", "title": "A translation of \"The characteristic function of a random phenomenon\" by\n  Bruno de Finetti", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article is a translation of Bruno de Finetti's paper \"Funzione\nCaratteristica di un fenomeno aleatorio\" which appeared in Atti del Congresso\nInternazionale dei Matematici, Bologna 3-10 Settembre 1928, Tomo VI, pp.\n179-190, originally published by Nicola Zanichelli Editore S.p.A. The\ntranslation was made as close as possible to the original in form and style,\nexcept for apparent mistakes found in the original document, which were\ncorrected and are mentioned as footnotes. Most of these were resolved by\ncomparing against a longer version of this work by de Finetti, published\nshortly after this one under the same titlea. The interested reader is highly\nencouraged to consult this other version for a more detailed treatment of the\ntopics covered here. Footnotes regarding the translation are labeled with\nletters to distinguish them from de Finetti's original footnotes.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2015 16:29:38 GMT"}], "update_date": "2015-12-07", "authors_parsed": [["Alvarez-Melis", "David", ""], ["Broderick", "Tamara", ""]]}, {"id": "1512.01366", "submitter": "Nadji Rahmania", "authors": "Azzouz Dermoune, Daoud Ounaissi and Nadji Rahmania", "title": "MCMC convergence diagnosis using geometry of Bayesian LASSO", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using posterior distribution of Bayesian LASSO we construct a semi-norm on\nthe parameter space. We show that the partition function depends on the ratio\nof the l1 and l2 norms and present three regimes. We derive the concentration\nof Bayesian LASSO, and present MCMC convergence diagnosis.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2015 10:53:27 GMT"}], "update_date": "2015-12-07", "authors_parsed": [["Dermoune", "Azzouz", ""], ["Ounaissi", "Daoud", ""], ["Rahmania", "Nadji", ""]]}, {"id": "1512.01382", "submitter": "Jana Jure\\v{c}kov\\'a", "authors": "Jana Jureckova", "title": "Averaged extreme regression quantile", "comments": "9 pages", "journal-ref": null, "doi": "10.1007/s10687-015-0232-2", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Various events in the nature, economics and in other areas force us to\ncombine the study of extremes with regression and other methods. A useful tool\nfor reducing the role of nuisance regression, while we are interested in the\nshape or tails of the basic distribution, is provided by the averaged\nregression quantile and namely by the average extreme regression quantile. Both\nare weighted means of regression quantile components, with weights depending on\nthe regressors. Our primary interest is the averaged extreme regression\nquantile (AERQ), its structure, qualities and its applications, e.g. in\ninvestigation of a conditional loss given a value exogenous economic and market\nvariables. AERQ has several interesting equivalent forms: While it is\noriginally defined as an optimal solution of a specific linear programming\nproblem, hence is a weighted mean of responses corresponding to the optimal\nbase of the pertaining linear program, we give another equivalent form as a\nmaximum residual of responses from a specific R-estimator of the slope\ncomponents of regression parameter. The latter form shows that while AERQ\nequals to the maximum of some residuals of the responses, it has minimal\npossible perturbation by the regressors. Notice that these finite-sample\nresults are true even for non-identically distributed model errors, e.g. under\nheteroscedasticity. Moreover, the representations are formally true even when\nthe errors are dependent - this all provokes a question of the right\ninterpretation and of other possible applications.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2015 12:10:48 GMT"}], "update_date": "2015-12-07", "authors_parsed": [["Jureckova", "Jana", ""]]}, {"id": "1512.01617", "submitter": "Wen-Xin Zhou", "authors": "Jianqing Fan, Wen-Xin Zhou", "title": "Guarding against Spurious Discoveries in High Dimensions", "comments": "49 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many data mining and statistical machine learning algorithms have been\ndeveloped to select a subset of covariates to associate with a response\nvariable. Spurious discoveries can easily arise in high-dimensional data\nanalysis due to enormous possibilities of such selections. How can we know\nstatistically our discoveries better than those by chance? In this paper, we\ndefine a measure of goodness of spurious fit, which shows how good a response\nvariable can be fitted by an optimally selected subset of covariates under the\nnull model, and propose a simple and effective LAMM algorithm to compute it. It\ncoincides with the maximum spurious correlation for linear models and can be\nregarded as a generalized maximum spurious correlation. We derive the\nasymptotic distribution of such goodness of spurious fit for generalized linear\nmodels and $L_1$ regression. Such an asymptotic distribution depends on the\nsample size, ambient dimension, the number of variables used in the fit, and\nthe covariance information. It can be consistently estimated by multiplier\nbootstrapping and used as a benchmark to guard against spurious discoveries. It\ncan also be applied to model selection, which considers only candidate models\nwith goodness of fits better than those by spurious fits. The theory and method\nare convincingly illustrated by simulated examples and an application to the\nbinary outcomes from German Neuroblastoma Trials.\n", "versions": [{"version": "v1", "created": "Sat, 5 Dec 2015 03:48:46 GMT"}, {"version": "v2", "created": "Tue, 29 Dec 2015 18:44:34 GMT"}, {"version": "v3", "created": "Sun, 23 Oct 2016 15:54:59 GMT"}], "update_date": "2016-10-25", "authors_parsed": [["Fan", "Jianqing", ""], ["Zhou", "Wen-Xin", ""]]}, {"id": "1512.01619", "submitter": "Nakahiro Yoshida", "authors": "Teppei Ogihara and Nakahiro Yoshida", "title": "Quasi likelihood analysis of point processes for ultra high frequency\n  data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a point process regression model that is applicable to price\nmodels and limit order book models. Hawkes type autoregression in the intensity\nprocess is generalized to a stochastic regression to covariate processes. We\nestablish the so-called quasi likelihood analysis, which gives a polynomial\ntype large deviation estimate for the statistical random field. We derive large\nsample properties of the maximum likelihood type estimator and the Bayesian\ntype estimator when the intensity processes become large under a finite time\nhorizon. There appears non-ergodic statistics. A classical approach is also\nmentioned.\n", "versions": [{"version": "v1", "created": "Sat, 5 Dec 2015 03:49:23 GMT"}], "update_date": "2015-12-08", "authors_parsed": [["Ogihara", "Teppei", ""], ["Yoshida", "Nakahiro", ""]]}, {"id": "1512.01631", "submitter": "Xiaohan Yan", "authors": "Xiaohan Yan and Jacob Bien", "title": "Hierarchical Sparse Modeling: A Choice of Two Group Lasso Formulations", "comments": "30 pages, 13 figures", "journal-ref": "Statist. Sci. 32 (2017), no. 4, 531--560", "doi": "10.1214/17-STS622", "report-no": null, "categories": "stat.ME math.ST stat.CO stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Demanding sparsity in estimated models has become a routine practice in\nstatistics. In many situations, we wish to require that the sparsity patterns\nattained honor certain problem-specific constraints. Hierarchical sparse\nmodeling (HSM) refers to situations in which these constraints specify that one\nset of parameters be set to zero whenever another is set to zero. In recent\nyears, numerous papers have developed convex regularizers for this form of\nsparsity structure, which arises in many areas of statistics including\ninteraction modeling, time series analysis, and covariance estimation. In this\npaper, we observe that these methods fall into two frameworks, the group lasso\n(GL) and latent overlapping group lasso (LOG), which have not been\nsystematically compared in the context of HSM. The purpose of this paper is to\nprovide a side-by-side comparison of these two frameworks for HSM in terms of\ntheir statistical properties and computational efficiency. We call special\nattention to GL's more aggressive shrinkage of parameters deep in the\nhierarchy, a property not shared by LOG. In terms of computation, we introduce\na finite-step algorithm that exactly solves the proximal operator of LOG for a\ncertain simple HSM structure; we later exploit this to develop a novel\npath-based block coordinate descent scheme for general HSM structures. Both\nalgorithms greatly improve the computational performance of LOG. Finally, we\ncompare the two methods in the context of covariance estimation, where we\nintroduce a new sparsely-banded estimator using LOG, which we show achieves the\nstatistical advantages of an existing GL-based method but is simpler to express\nand more efficient to compute.\n", "versions": [{"version": "v1", "created": "Sat, 5 Dec 2015 07:00:54 GMT"}, {"version": "v2", "created": "Tue, 29 Nov 2016 02:13:49 GMT"}, {"version": "v3", "created": "Mon, 3 Jul 2017 04:03:45 GMT"}, {"version": "v4", "created": "Wed, 29 Nov 2017 20:05:56 GMT"}], "update_date": "2017-12-04", "authors_parsed": [["Yan", "Xiaohan", ""], ["Bien", "Jacob", ""]]}, {"id": "1512.01734", "submitter": "Qian Qin", "authors": "Qian Qin, James P. Hobert", "title": "On the Data Augmentation Algorithm for Bayesian Multivariate Linear\n  Regression with Non-Gaussian Errors", "comments": "10 pages. arXiv admin note: text overlap with arXiv:1506.03113", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $\\pi$ denote the intractable posterior density that results when the\nlikelihood from a multivariate linear regression model with errors from a scale\nmixture of normals is combined with the standard non-informative prior. There\nis a simple data augmentation algorithm (based on latent data from the mixing\ndensity) that can be used to explore $\\pi$. Hobert et al. (2015)\n[arXiv:1506.03113v1] recently performed a convergence rate analysis of the\nMarkov chain underlying this MCMC algorithm in the special case where the\nregression model is univariate. These authors provide simple sufficient\nconditions (on the mixing density) for geometric ergodicity of the Markov\nchain. In this note, we extend Hobert et al.'s (2015) result to the\nmultivariate case.\n", "versions": [{"version": "v1", "created": "Sun, 6 Dec 2015 04:03:26 GMT"}], "update_date": "2015-12-08", "authors_parsed": [["Qin", "Qian", ""], ["Hobert", "James P.", ""]]}, {"id": "1512.01832", "submitter": "Mohamed Ndaoud", "authors": "Cristina Butucea, Mohamed Ndaoud, Natalia A. Stepanova and Alexandre\n  B. Tsybakov", "title": "Variable selection with Hamming loss", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive non-asymptotic bounds for the minimax risk of variable selection\nunder expected Hamming loss in the Gaussian mean model in $\\mathbb{R}^d$ for\nclasses of $s$-sparse vectors separated from 0 by a constant $a > 0$. In some\ncases, we get exact expressions for the nonasymptotic minimax risk as a\nfunction of $d, s, a$ and find explicitly the minimax selectors. These results\nare extended to dependent or non-Gaussian observations and to the problem of\ncrowdsourcing. Analogous conclusions are obtained for the probability of wrong\nrecovery of the sparsity pattern. As corollaries, we derive necessary and\nsufficient conditions for such asymptotic properties as almost full recovery\nand exact recovery. Moreover, we propose data-driven selectors that provide\nalmost full and exact recovery adaptively to the parameters of the classes.\n", "versions": [{"version": "v1", "created": "Sun, 6 Dec 2015 20:50:50 GMT"}, {"version": "v2", "created": "Fri, 23 Sep 2016 16:44:16 GMT"}, {"version": "v3", "created": "Sun, 15 Jan 2017 17:53:59 GMT"}, {"version": "v4", "created": "Fri, 10 Mar 2017 12:39:22 GMT"}, {"version": "v5", "created": "Fri, 12 Oct 2018 14:28:19 GMT"}], "update_date": "2018-10-15", "authors_parsed": [["Butucea", "Cristina", ""], ["Ndaoud", "Mohamed", ""], ["Stepanova", "Natalia A.", ""], ["Tsybakov", "Alexandre B.", ""]]}, {"id": "1512.01844", "submitter": "Nelson Muriel", "authors": "Nelson Muriel", "title": "The functional AR(1) process with a unit root", "comments": "19 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define strong and weak unit roots for the functional AR(1) process and\ngive some theoretical examples. It is shown that a functional form of\ncointegration occurs in which only a finite number of common trends exist.\nUsing functional Principal Component Analysis we illustrate the presence of\nfunctional unit roots in two demographic data sets. We close with some remarks\nconcerning our assumptions and the possibility of generalizing our results.\n", "versions": [{"version": "v1", "created": "Sun, 6 Dec 2015 22:08:07 GMT"}], "update_date": "2015-12-08", "authors_parsed": [["Muriel", "Nelson", ""]]}, {"id": "1512.01859", "submitter": "James P. Crutchfield", "authors": "Sarah E. Marzen and James P. Crutchfield", "title": "Statistical Signatures of Structural Organization: The case of long\n  memory in renewal processes", "comments": "13 pages, 2 figures, 3 appendixes;\n  http://csc.ucdavis.edu/~cmg/compmech/pubs/lrmrp.htm", "journal-ref": null, "doi": "10.1016/j.physleta.2016.02.052", "report-no": null, "categories": "cond-mat.stat-mech cs.IT math.DS math.IT math.ST physics.data-an stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying and quantifying memory are often critical steps in developing a\nmechanistic understanding of stochastic processes. These are particularly\nchallenging and necessary when exploring processes that exhibit long-range\ncorrelations. The most common signatures employed rely on second-order temporal\nstatistics and lead, for example, to identifying long memory in processes with\npower-law autocorrelation function and Hurst exponent greater than $1/2$.\nHowever, most stochastic processes hide their memory in higher-order temporal\ncorrelations. Information measures---specifically, divergences in the mutual\ninformation between a process' past and future (excess entropy) and minimal\npredictive memory stored in a process' causal states (statistical\ncomplexity)---provide a different way to identify long memory in processes with\nhigher-order temporal correlations. However, there are no ergodic stationary\nprocesses with infinite excess entropy for which information measures have been\ncompared to autocorrelation functions and Hurst exponents. Here, we show that\nfractal renewal processes---those with interevent distribution tails $\\propto\nt^{-\\alpha}$---exhibit long memory via a phase transition at $\\alpha = 1$.\nExcess entropy diverges only there and statistical complexity diverges there\nand for all $\\alpha < 1$. When these processes do have power-law\nautocorrelation function and Hurst exponent greater than $1/2$, they do not\nhave divergent excess entropy. This analysis breaks the intuitive association\nbetween these different quantifications of memory. We hope that the methods\nused here, based on causal states, provide some guide as to how to construct\nand analyze other long memory processes.\n", "versions": [{"version": "v1", "created": "Sun, 6 Dec 2015 23:30:32 GMT"}], "update_date": "2016-04-20", "authors_parsed": [["Marzen", "Sarah E.", ""], ["Crutchfield", "James P.", ""]]}, {"id": "1512.01899", "submitter": "Simon Clinet", "authors": "Simon Clinet and Nakahiro Yoshida", "title": "Statistical Inference for Ergodic Point Processes and Application to\n  Limit Order Book", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We construct a general procedure for the Quasi Likelihood Analysis applied to\na multivariate point process on the real half line in an ergodic framework.\nMore precisely, we assume that the stochastic intensity of the underlying model\nbelongs to a family of processes indexed by a finite dimensional parameter.\nWhen a particular family of laws of large numbers applies to those processes,\nwe establish the consistency, the asymptotic normality and the convergence of\nmoments of both the Quasi Maximum Likelihood estimator and the Quasi Bayesian\nestimator. In addition, we illustrate our main results by showing how they can\nbe applied to various Limit Order Book models existing in the literature. In\nparticular, we address the fundamental cases of Markovian models and\nexponential Hawkes process-based models.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2015 03:21:43 GMT"}, {"version": "v2", "created": "Wed, 10 Feb 2016 02:39:33 GMT"}, {"version": "v3", "created": "Tue, 27 Sep 2016 02:27:25 GMT"}], "update_date": "2016-09-28", "authors_parsed": [["Clinet", "Simon", ""], ["Yoshida", "Nakahiro", ""]]}, {"id": "1512.01955", "submitter": "Marco Iglesias", "authors": "Marco A. Iglesias and Kui Lin and Shuai Lu and Andrew M. Stuart", "title": "Filter Based Methods For Statistical Linear Inverse Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ill-posed inverse problems are ubiquitous in applications. Under- standing of\nalgorithms for their solution has been greatly enhanced by a deep understanding\nof the linear inverse problem. In the applied communities ensemble-based\nfiltering methods have recently been used to solve inverse problems by\nintroducing an artificial dynamical sys- tem. This opens up the possibility of\nusing a range of other filtering methods, such as 3DVAR and Kalman based\nmethods, to solve inverse problems, again by introducing an artificial\ndynamical system. The aim of this paper is to analyze such methods in the\ncontext of the ill-posed linear inverse problem. Statistical linear inverse\nproblems are studied in the sense that the observational noise is assumed to be\nderived via realization of a Gaussian random variable. We investigate the\nasymptotic behavior of filter based methods for these inverse problems.\nRigorous convergence rates are established for 3DVAR and for the Kalman\nfilters, including minimax rates in some instances. Blowup of 3DVAR and a\nvariant of its basic form is also presented, and optimality of the Kalman\nfilter is discussed. These analyses reveal a close connection between\n(iterative) regularization schemes in deterministic inverse problems and filter\nbased methods in data assimilation. Numerical experiments are presented to\nillustrate the theory.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2015 09:48:30 GMT"}], "update_date": "2015-12-08", "authors_parsed": [["Iglesias", "Marco A.", ""], ["Lin", "Kui", ""], ["Lu", "Shuai", ""], ["Stuart", "Andrew M.", ""]]}, {"id": "1512.02057", "submitter": "Dominik Janzing", "authors": "Dominik Janzing, Rafael Chaves, Bernhard Schoelkopf", "title": "Algorithmic independence of initial condition and dynamical law in\n  thermodynamics and causal inference", "comments": "7 pages, latex, 2 figures", "journal-ref": "New J. Phys. 18, 093052 (2016)", "doi": "10.1088/1367-2630/18/9/093052", "report-no": null, "categories": "cond-mat.stat-mech math.ST quant-ph stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We postulate a principle stating that the initial condition of a physical\nsystem is typically algorithmically independent of the dynamical law. We argue\nthat this links thermodynamics and causal inference. On the one hand, it\nentails behaviour that is similar to the usual arrow of time. On the other\nhand, it motivates a statistical asymmetry between cause and effect that has\nrecently postulated in the field of causal inference, namely, that the\nprobability distribution P(cause) contains no information about the conditional\ndistribution P(effect|cause) and vice versa, while P(effect) may contain\ninformation about P(cause|effect).\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2015 14:18:48 GMT"}], "update_date": "2016-11-08", "authors_parsed": [["Janzing", "Dominik", ""], ["Chaves", "Rafael", ""], ["Schoelkopf", "Bernhard", ""]]}, {"id": "1512.02109", "submitter": "Anmer Daskin", "authors": "Anmer Daskin", "title": "Obtaining A Linear Combination of the Principal Components of a Matrix\n  on Quantum Computers", "comments": "The title of the paper is changed. A couple of sections are extended.\n  8 pages and 3 figures", "journal-ref": "Quantum Inf Process (2016) 15: 4013", "doi": "10.1007/s11128-016-1388-7", "report-no": null, "categories": "quant-ph cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Principal component analysis is a multivariate statistical method frequently\nused in science and engineering to reduce the dimension of a problem or extract\nthe most significant features from a dataset. In this paper, using a similar\nnotion to the quantum counting, we show how to apply the amplitude\namplification together with the phase estimation algorithm to an operator in\norder to procure the eigenvectors of the operator associated to the eigenvalues\ndefined in the range $\\left[a, b\\right]$, where $a$ and $b$ are real and $0\n\\leq a \\leq b \\leq 1$. This makes possible to obtain a combination of the\neigenvectors associated to the largest eigenvalues and so can be used to do\nprincipal component analysis on quantum computers.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2015 14:31:12 GMT"}, {"version": "v2", "created": "Wed, 9 Dec 2015 13:37:00 GMT"}, {"version": "v3", "created": "Thu, 28 Jan 2016 09:53:59 GMT"}], "update_date": "2016-11-09", "authors_parsed": [["Daskin", "Anmer", ""]]}, {"id": "1512.02280", "submitter": "Eric Tchetgen Tchetgen", "authors": "James Robins, Lingling Li, Eric Tchetgen Tchetgen, Aad van der Vaart", "title": "Asymptotic Normality of Quadratic Estimators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove conditional asymptotic normality of a class of quadratic\nU-statistics that are dominated by their degenerate second order part and have\nkernels that change with the number of observations. These statistics arise in\nthe construction of estimators in high-dimensional semi- and non-parametric\nmodels, and in the construction of nonparametric confidence sets. This is\nillustrated by estimation of the integral of a square of a density or\nregression function, and estimation of the mean response with missing data. We\nshow that estimators are asymptotically normal even in the case that the rate\nis slower than the square root of the observations.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2015 23:10:01 GMT"}], "update_date": "2015-12-09", "authors_parsed": [["Robins", "James", ""], ["Li", "Lingling", ""], ["Tchetgen", "Eric Tchetgen", ""], ["van der Vaart", "Aad", ""]]}, {"id": "1512.02303", "submitter": "Sharif Rahman", "authors": "Sharif Rahman", "title": "The $f$-Sensitivity Index", "comments": "32 pages, 5 figures, accepted by SIAM/ASA Journal on Uncertainty\n  Quantification, 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article presents a general multivariate $f$-sensitivity index, rooted in\nthe $f$-divergence between the unconditional and conditional probability\nmeasures of a stochastic response, for global sensitivity analysis. Unlike the\nvariance-based Sobol index, the $f$-sensitivity index is applicable to random\ninput following dependent as well as independent probability distributions.\nSince the class of $f$-divergences supports a wide variety of divergence or\ndistance measures, a plethora of $f$-sensitivity indices are possible,\naffording diverse choices to sensitivity analysis. Commonly used sensitivity\nindices or measures, such as mutual information, squared-loss mutual\ninformation, and Borgonovo's importance measure, are shown to be special cases\nof the proposed sensitivity index. New theoretical results, revealing\nfundamental properties of the $f$-sensitivity index and establishing important\ninequalities, are presented. Three new approximate methods, depending on how\nthe probability densities of a stochastic response are determined, are proposed\nto estimate the sensitivity index. Four numerical examples, including a\ncomputationally intensive stochastic boundary-value problem, illustrate these\nmethods and explain when one method is more relevant than the others.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2015 02:05:27 GMT"}], "update_date": "2015-12-09", "authors_parsed": [["Rahman", "Sharif", ""]]}, {"id": "1512.02515", "submitter": "Igal Sason", "authors": "M. Ashok Kumar, Igal Sason", "title": "Projection Theorems for the R\\'enyi Divergence on $\\alpha$-Convex Sets", "comments": "Accepted to the IEEE Trans. on Information Theory, July 2016.\n  Presented in part at ISIT 2016, Barcelona", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies forward and reverse projections for the R\\'{e}nyi\ndivergence of order $\\alpha \\in (0, \\infty)$ on $\\alpha$-convex sets. The\nforward projection on such a set is motivated by some works of Tsallis {\\em et\nal.} in statistical physics, and the reverse projection is motivated by robust\nstatistics. In a recent work, van Erven and Harremo\\\"es proved a Pythagorean\ninequality for R\\'{e}nyi divergences on $\\alpha$-convex sets under the\nassumption that the forward projection exists. Continuing this study, a\nsufficient condition for the existence of forward projection is proved for\nprobability measures on a general alphabet. For $\\alpha \\in (1, \\infty)$, the\nproof relies on a new Apollonius theorem for the Hellinger divergence, and for\n$\\alpha \\in (0,1)$, the proof relies on the Banach-Alaoglu theorem from\nfunctional analysis. Further projection results are then obtained in the finite\nalphabet setting. These include a projection theorem on a specific\n$\\alpha$-convex set, which is termed an {\\em $\\alpha$-linear family},\ngeneralizing a result by Csisz\\'ar for $\\alpha \\neq 1$. The solution to this\nproblem yields a parametric family of probability measures which turns out to\nbe an extension of the exponential family, and it is termed an {\\em\n$\\alpha$-exponential family}. An orthogonality relationship between the\n$\\alpha$-exponential and $\\alpha$-linear families is established, and it is\nused to turn the reverse projection on an $\\alpha$-exponential family into a\nforward projection on a $\\alpha$-linear family. This paper also proves a\nconvergence result of an iterative procedure used to calculate the forward\nprojection on an intersection of a finite number of $\\alpha$-linear families.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2015 15:49:32 GMT"}, {"version": "v2", "created": "Tue, 26 Jul 2016 08:22:45 GMT"}], "update_date": "2016-07-27", "authors_parsed": [["Kumar", "M. Ashok", ""], ["Sason", "Igal", ""]]}, {"id": "1512.02666", "submitter": "Damian Kozbur", "authors": "Damian Kozbur", "title": "Analysis of Testing-Based Forward Model Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces and analyzes a procedure called Testing-based forward\nmodel selection (TBFMS) in linear regression problems. This procedure\ninductively selects covariates that add predictive power into a working\nstatistical model before estimating a final regression. The criterion for\ndeciding which covariate to include next and when to stop including covariates\nis derived from a profile of traditional statistical hypothesis tests. This\npaper proves probabilistic bounds, which depend on the quality of the tests,\nfor prediction error and the number of selected covariates. As an example, the\nbounds are then specialized to a case with heteroskedastic data, with tests\nconstructed with the help of Huber-Eicker-White standard errors. Under the\nassumed regularity conditions, these tests lead to estimation convergence rates\nmatching other common high-dimensional estimators including Lasso.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2015 21:19:10 GMT"}, {"version": "v10", "created": "Tue, 25 Feb 2020 14:58:09 GMT"}, {"version": "v11", "created": "Thu, 27 Feb 2020 17:11:27 GMT"}, {"version": "v12", "created": "Tue, 3 Mar 2020 17:51:26 GMT"}, {"version": "v13", "created": "Mon, 6 Apr 2020 17:01:39 GMT"}, {"version": "v2", "created": "Wed, 6 Apr 2016 17:07:58 GMT"}, {"version": "v3", "created": "Wed, 11 Apr 2018 17:30:26 GMT"}, {"version": "v4", "created": "Mon, 16 Apr 2018 11:33:01 GMT"}, {"version": "v5", "created": "Tue, 17 Apr 2018 12:02:20 GMT"}, {"version": "v6", "created": "Thu, 7 Jun 2018 12:21:07 GMT"}, {"version": "v7", "created": "Fri, 4 Oct 2019 12:49:29 GMT"}, {"version": "v8", "created": "Fri, 3 Jan 2020 14:03:44 GMT"}, {"version": "v9", "created": "Mon, 13 Jan 2020 21:50:26 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Kozbur", "Damian", ""]]}, {"id": "1512.02857", "submitter": "Eddie Aamari", "authors": "Eddie Aamari and Cl\\'ement Levrard", "title": "Stability and Minimax Optimality of Tangential Delaunay Complexes for\n  Manifold Reconstruction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of optimality in manifold reconstruction. A random\nsample $\\mathbb{X}_n = \\left\\{X_1,\\ldots,X_n\\right\\}\\subset \\mathbb{R}^D$\ncomposed of points close to a $d$-dimensional submanifold $M$, with or without\noutliers drawn in the ambient space, is observed. Based on the Tangential\nDelaunay Complex, we construct an estimator $\\hat{M}$ that is ambient isotopic\nand Hausdorff-close to $M$ with high probability. The estimator $\\hat{M}$ is\nbuilt from existing algorithms. In a model with additive noise of small\namplitude, we show that this estimator is asymptotically minimax optimal for\nthe Hausdorff distance over a class of submanifolds satisfying a reach\nconstraint. Therefore, even with no a priori information on the tangent spaces\nof $M$, our estimator based on Tangential Delaunay Complexes is optimal. This\nshows that the optimal rate of convergence can be achieved through existing\nalgorithms. A similar result is also derived in a model with outliers. A\ngeometric interpolation result is derived, showing that the Tangential Delaunay\nComplex is stable with respect to noise and perturbations of the tangent\nspaces. In the process, a decluttering procedure and a tangent space estimator\nboth based on local principal component analysis (PCA) are studied.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2015 13:43:05 GMT"}, {"version": "v2", "created": "Mon, 20 Jun 2016 15:10:31 GMT"}, {"version": "v3", "created": "Wed, 31 Jan 2018 20:28:10 GMT"}], "update_date": "2018-02-02", "authors_parsed": [["Aamari", "Eddie", ""], ["Levrard", "Cl\u00e9ment", ""]]}, {"id": "1512.02863", "submitter": "Daniel Vogel", "authors": "Alexander D\\\"urre, David E. Tyler, Daniel Vogel", "title": "On the eigenvalues of the spatial sign covariance matrix in more than\n  two dimensions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We gather several results on the eigenvalues of the spatial sign covariance\nmatrix of an elliptical distribution. It is shown that the eigenvalues are a\none-to-one function of the eigenvalues of the shape matrix and that they are\ncloser together than the latter. We further provide a one-dimensional integral\nrepresentation of the eigenvalues, which facilitates their numerical\ncomputation.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2015 14:14:56 GMT"}, {"version": "v2", "created": "Fri, 18 Mar 2016 14:01:17 GMT"}], "update_date": "2016-03-21", "authors_parsed": [["D\u00fcrre", "Alexander", ""], ["Tyler", "David E.", ""], ["Vogel", "Daniel", ""]]}, {"id": "1512.02956", "submitter": "Sabyasachi Chatterjee", "authors": "Sabyasachi Chatterjee, John Lafferty", "title": "Adaptive Risk Bounds in Unimodal Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the statistical properties of the least squares estimator in\nunimodal sequence estimation. Although closely related to isotonic regression,\nunimodal regression has not been as extensively studied. We show that the\nunimodal least squares estimator is adaptive in the sense that the risk scales\nas a function of the number of values in the true underlying sequence. Such\nadaptivity properties have been shown for isotonic regression by Chatterjee et\nal(2015) and Bellec(2015). A technical complication in unimodal regression is\nthe non-convexity of the underlying parameter space. We develop a general\nvariational representation of the risk that holds whenever the parameter space\ncan be expressed as a finite union of convex sets, using techniques that may be\nof interest in other settings.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2015 17:26:43 GMT"}, {"version": "v2", "created": "Thu, 10 Dec 2015 03:33:20 GMT"}, {"version": "v3", "created": "Fri, 15 Jul 2016 01:23:14 GMT"}, {"version": "v4", "created": "Fri, 5 Aug 2016 21:51:30 GMT"}, {"version": "v5", "created": "Tue, 9 May 2017 17:28:12 GMT"}], "update_date": "2017-05-10", "authors_parsed": [["Chatterjee", "Sabyasachi", ""], ["Lafferty", "John", ""]]}, {"id": "1512.03099", "submitter": "Victor Veitch", "authors": "Victor Veitch and Daniel M. Roy", "title": "The Class of Random Graphs Arising from Exchangeable Random Measures", "comments": "52 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.SI math.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a class of random graphs that we argue meets many of the\ndesiderata one would demand of a model to serve as the foundation for a\nstatistical analysis of real-world networks. The class of random graphs is\ndefined by a probabilistic symmetry: invariance of the distribution of each\ngraph to an arbitrary relabelings of its vertices. In particular, following\nCaron and Fox, we interpret a symmetric simple point process on\n$\\mathbb{R}_+^2$ as the edge set of a random graph, and formalize the\nprobabilistic symmetry as joint exchangeability of the point process. We give a\nrepresentation theorem for the class of random graphs satisfying this symmetry\nvia a straightforward specialization of Kallenberg's representation theorem for\njointly exchangeable random measures on $\\mathbb{R}_+^2$. The distribution of\nevery such random graph is characterized by three (potentially random)\ncomponents: a nonnegative real $I \\in \\mathbb{R}_+$, an integrable function $S:\n\\mathbb{R}_+ \\to \\mathbb{R}_+$, and a symmetric measurable function $W:\n\\mathbb{R}_+^2 \\to [0,1]$ that satisfies several weak integrability conditions.\nWe call the triple $(I,S,W)$ a graphex, in analogy to graphons, which\ncharacterize the (dense) exchangeable graphs on $\\mathbb{N}$. Indeed, the model\nwe introduce here contains the exchangeable graphs as a special case, as well\nas the \"sparse exchangeable\" model of Caron and Fox. We study the structure of\nthese random graphs, and show that they can give rise to interesting structure,\nincluding sparse graph sequences. We give explicit equations for expectations\nof certain graph statistics, as well as the limiting degree distribution. We\nalso show that certain families of graphexes give rise to random graphs that,\nasymptotically, contain an arbitrarily large fraction of the vertices in a\nsingle connected component.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2015 16:44:35 GMT"}], "update_date": "2015-12-11", "authors_parsed": [["Veitch", "Victor", ""], ["Roy", "Daniel M.", ""]]}, {"id": "1512.03188", "submitter": "Till Hoffmann", "authors": "Till Hoffmann and Nick S. Jones", "title": "Unified treatment of the asymptotics of asymmetric kernel density\n  estimators", "comments": "16 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend balloon and sample-smoothing estimators, two types of\nvariable-bandwidth kernel density estimators, by a shift parameter and derive\ntheir asymptotic properties. Our approach facilitates the unified study of a\nwide range of density estimators which are subsumed under these two general\nclasses of kernel density estimators. We demonstrate our method by deriving the\nasymptotic bias, variance, and mean (integrated) squared error of density\nestimators with gamma, log-normal, Birnbaum-Saunders, inverse Gaussian and\nreciprocal inverse Gaussian kernels. We propose two new density estimators for\npositive random variables that yield properly-normalised density estimates.\nPlugin expressions for bandwidth estimation are provided to facilitate easy\nexploratory data analysis.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2015 09:28:57 GMT"}], "update_date": "2015-12-11", "authors_parsed": [["Hoffmann", "Till", ""], ["Jones", "Nick S.", ""]]}, {"id": "1512.03341", "submitter": "Ricardo Ehlers", "authors": "Ricardo S Ehlers", "title": "A New Class of Skewed Bimodal Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose to obtain the skewed version of a unimodal\nsymmetric density using a skewing mechanism that is not based on a cumulative\ndistribution function. Then we disturb the unimodality of the resulting skewed\ndensity. In order to introduce skewness we use the general method which\ntransforms any continuous unimodal and symmetric distribution into a skewed one\nby changing the scale at each side of the mode.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2015 17:40:37 GMT"}], "update_date": "2015-12-11", "authors_parsed": [["Ehlers", "Ricardo S", ""]]}, {"id": "1512.03479", "submitter": "Rajarshi Mukherjee", "authors": "Rajarshi Mukherjee and Subhabrata Sen", "title": "Optimal Adaptive Inference in Random Design Binary Regression", "comments": "37 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We construct confidence sets for the regression function in nonparametric\nbinary regression with an unknown design density. These confidence sets are\nadaptive in $L^2$ loss over a continuous class of Sobolev type spaces.\nAdaptation holds in the smoothness of the regression function, over the maximal\nparameter spaces where adaptation is possible, provided the design density is\nsmooth enough. We identify two key regimes --- one where adaptation is\npossible, and one where some critical regions must be removed. We address\nrelated questions about goodness of fit testing and adaptive estimation of\nrelevant parameters.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2015 22:56:00 GMT"}, {"version": "v2", "created": "Mon, 14 Dec 2015 05:23:24 GMT"}, {"version": "v3", "created": "Sun, 10 Jan 2016 01:22:14 GMT"}, {"version": "v4", "created": "Tue, 2 Aug 2016 22:41:39 GMT"}], "update_date": "2016-08-04", "authors_parsed": [["Mukherjee", "Rajarshi", ""], ["Sen", "Subhabrata", ""]]}, {"id": "1512.03489", "submitter": "Mohammad Amin Rahimian", "authors": "Victor M. Preciado and M. Amin Rahimian", "title": "Moment-Based Spectral Analysis of Random Graphs with Given Expected\n  Degrees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.SI math.PR physics.soc-ph stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we analyze the limiting spectral distribution of the adjacency\nmatrix of a random graph ensemble, proposed by Chung and Lu, in which a given\nexpected degree sequence $\\overline{w}_n^{^{T}} = (w^{(n)}_1,\\ldots,w^{(n)}_n)$\nis prescribed on the ensemble. Let $\\mathbf{a}_{i,j} =1$ if there is an edge\nbetween the nodes $\\{i,j\\}$ and zero otherwise, and consider the normalized\nrandom adjacency matrix of the graph ensemble: $\\mathbf{A}_n$ $=$ $\n[\\mathbf{a}_{i,j}/\\sqrt{n}]_{i,j=1}^{n}$. The empirical spectral distribution\nof $\\mathbf{A}_n$ denoted by $\\mathbf{F}_n(\\mathord{\\cdot})$ is the empirical\nmeasure putting a mass $1/n$ at each of the $n$ real eigenvalues of the\nsymmetric matrix $\\mathbf{A}_n$. Under some technical conditions on the\nexpected degree sequence, we show that with probability one,\n$\\mathbf{F}_n(\\mathord{\\cdot})$ converges weakly to a deterministic\ndistribution $F(\\mathord{\\cdot})$. Furthermore, we fully characterize this\ndistribution by providing explicit expressions for the moments of\n$F(\\mathord{\\cdot})$. We apply our results to well-known degree distributions,\nsuch as power-law and exponential. The asymptotic expressions of the spectral\nmoments in each case provide significant insights about the bulk behavior of\nthe eigenvalue spectrum.\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2015 00:22:53 GMT"}, {"version": "v2", "created": "Thu, 13 Oct 2016 07:48:57 GMT"}, {"version": "v3", "created": "Fri, 24 Mar 2017 21:53:41 GMT"}], "update_date": "2017-03-28", "authors_parsed": [["Preciado", "Victor M.", ""], ["Rahimian", "M. Amin", ""]]}, {"id": "1512.03508", "submitter": "Siamak Noorbaloochi", "authors": "Siamak Noorbaloochi and Glen Meeden", "title": "Unbiasedness and Bayes Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Assuming squared error loss, we show that finding unbiased estimators and\nBayes estimators can be treated as using a pair of linear operators that\noperate between two Hilbert spaces. We note that these integral operators are\nadjoint and then investigate some consequences of this fact.\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2015 02:59:49 GMT"}], "update_date": "2015-12-14", "authors_parsed": [["Noorbaloochi", "Siamak", ""], ["Meeden", "Glen", ""]]}, {"id": "1512.03987", "submitter": "Yiyuan She", "authors": "Yiyuan She", "title": "On the Finite-Sample Analysis of $\\Theta$-estimators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In large-scale modern data analysis, first-order optimization methods are\nusually favored to obtain sparse estimators in high dimensions. This paper\nperforms theoretical analysis of a class of iterative thresholding based\nestimators defined in this way. Oracle inequalities are built to show the\nnearly minimax rate optimality of such estimators under a new type of\nregularity conditions. Moreover, the sequence of iterates is found to be able\nto approach the statistical truth within the best statistical accuracy\ngeometrically fast. Our results also reveal different benefits brought by\nconvex and nonconvex types of shrinkage.\n", "versions": [{"version": "v1", "created": "Sun, 13 Dec 2015 01:59:46 GMT"}, {"version": "v2", "created": "Thu, 28 Jan 2016 02:30:54 GMT"}, {"version": "v3", "created": "Sat, 8 Oct 2016 21:35:40 GMT"}], "update_date": "2016-10-11", "authors_parsed": [["She", "Yiyuan", ""]]}, {"id": "1512.04093", "submitter": "Ning Hao", "authors": "Yue S. Niu, Ning Hao, and Heping Zhang", "title": "Multiple Change-point Detection: a Selective Overview", "comments": "26 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Very long and noisy sequence data arise from biological sciences to social\nscience including high throughput data in genomics and stock prices in\neconometrics. Often such data are collected in order to identify and understand\nshifts in trend, e.g., from a bull market to a bear market in finance or from a\nnormal number of chromosome copies to an excessive number of chromosome copies\nin genetics. Thus, identifying multiple change points in a long, possibly very\nlong, sequence is an important problem. In this article, we review both\nclassical and new multiple change-point detection strategies. Considering the\nlong history and the extensive literature on the change-point detection, we\nprovide an in-depth discussion on a normal mean change-point model from aspects\nof regression analysis, hypothesis testing, consistency and inference. In\nparticular, we present a strategy to gather and aggregate local information for\nchange-point detection that has become the cornerstone of several emerging\nmethods because of its attractiveness in both computational and theoretical\nproperties.\n", "versions": [{"version": "v1", "created": "Sun, 13 Dec 2015 18:09:24 GMT"}, {"version": "v2", "created": "Thu, 14 Jul 2016 19:17:07 GMT"}], "update_date": "2016-07-15", "authors_parsed": [["Niu", "Yue S.", ""], ["Hao", "Ning", ""], ["Zhang", "Heping", ""]]}, {"id": "1512.04267", "submitter": "Gabor Lugosi", "authors": "Luc Devroye, L\\'aszl\\'o Gy\\\"orfi, G\\'abor Lugosi, Harro Walk", "title": "On the measure of Voronoi cells", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  $n$ independent random points drawn from a density $f$ in $R^d$ define a\nrandom Voronoi partition. We study the measure of a typical cell of the\npartition. We prove that the asymptotic distribution of the probability measure\nof the cell centered at a point $x \\in R^d$ is independent of $x$ and the\ndensity $f$. We determine all moments of the asymptotic distribution and show\nthat the distribution becomes more concentrated as $d$ becomes large. In\nparticular, we show that the variance converges to zero exponentially fast in\n$d$. %We also study the measure of the largest cell of the partition. %{\\red We\nalso obtain a density-free bound for the rate of convergence of the diameter of\na typical Voronoi cell.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2015 11:53:18 GMT"}], "update_date": "2015-12-15", "authors_parsed": [["Devroye", "Luc", ""], ["Gy\u00f6rfi", "L\u00e1szl\u00f3", ""], ["Lugosi", "G\u00e1bor", ""], ["Walk", "Harro", ""]]}, {"id": "1512.04594", "submitter": "Davy Paindaveine", "authors": "Davy Paindaveine, Thomas Verdebout", "title": "Inference on the mode of weak directional signals: a Le Cam perspective\n  on hypothesis testing near singularities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit, in an original and challenging perspective, the problem of\ntesting the null hypothesis that the mode of a directional signal is equal to a\ngiven value. Motivated by a real data example where the signal is weak, we\nconsider this problem under asymptotic scenarios for which the signal strength\ngoes to zero at an arbitrary rate~$\\eta_n$. Both under the null and the\nalternative, we focus on rotationally symmetric distributions. We show that,\nwhile they are asymptotically equivalent under fixed signal strength, the\nclassical Wald and Watson tests exhibit very different (null and non-null)\nbehaviours when the signal becomes arbitrarily weak. To fully characterize how\nchallenging the problem is as a function of~$\\eta_n$, we adopt a Le Cam,\nconvergence-of-statistical-experiments, point of view and show that the\nresulting limiting experiments crucially depend on~$\\eta_n$. In the light of\nthese results, the Watson test is shown to be \\emph{adaptively} rate-consistent\nand essentially adaptively Le Cam optimal. Throughout, our theoretical findings\nare illustrated via Monte-Carlo simulations. The practical relevance of our\nresults is also shown on the real data example that motivated the present work.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2015 22:48:58 GMT"}, {"version": "v2", "created": "Wed, 23 Mar 2016 10:12:35 GMT"}], "update_date": "2016-03-24", "authors_parsed": [["Paindaveine", "Davy", ""], ["Verdebout", "Thomas", ""]]}, {"id": "1512.04658", "submitter": "Sabyasachi Chatterjee", "authors": "Sabyasachi Chatterjee", "title": "An Improved Global Risk Bound in Concave Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  A new risk bound is presented for the problem of convex/concave function\nestimation, using the least squares estimator. The best known risk bound, as\nhad appeared in \\citet{GSvex}, scaled like $\\log(en) n^{-4/5}$ under the mean\nsquared error loss, up to a constant factor. The authors in \\cite{GSvex} had\nconjectured that the logarithmic term may be an artifact of their proof. We\nshow that indeed the logarithmic term is unnecessary and prove a risk bound\nwhich scales like $n^{-4/5}$ up to constant factors. Our proof technique has\none extra peeling step than in a usual chaining type argument. Our risk bound\nholds in expectation as well as with high probability and also extends to the\ncase of model misspecification, where the true function may not be concave.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2015 06:25:40 GMT"}, {"version": "v2", "created": "Sun, 20 Dec 2015 04:17:21 GMT"}, {"version": "v3", "created": "Fri, 8 Jan 2016 15:42:45 GMT"}], "update_date": "2016-01-11", "authors_parsed": [["Chatterjee", "Sabyasachi", ""]]}, {"id": "1512.04716", "submitter": "Bezirgen Veliyev", "authors": "Mark Podolskij, Bezirgen Veliyev, Nakahiro Yoshida", "title": "Edgeworth expansion for the pre-averaging estimator", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR q-fin.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the Edgeworth expansion for a pre-averaging estimator\nof quadratic variation in the framework of continuous diffusion models observed\nwith noise. More specifically, we obtain a second order expansion for the joint\ndensity of the estimators of quadratic variation and its asymptotic variance.\nOur approach is based on martingale embedding, Malliavin calculus and stable\ncentral limit theorems for continuous diffusions. Moreover, we derive the\ndensity expansion for the studentized statistic, which might be applied to\nconstruct asymptotic confidence regions.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2015 10:38:40 GMT"}], "update_date": "2015-12-16", "authors_parsed": [["Podolskij", "Mark", ""], ["Veliyev", "Bezirgen", ""], ["Yoshida", "Nakahiro", ""]]}, {"id": "1512.04734", "submitter": "Arnak Dalalyan S.", "authors": "Samuel Balmand and Arnak Dalalyan", "title": "Convex programming approach to robust estimation of a multivariate\n  Gaussian model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multivariate Gaussian is often used as a first approximation to the\ndistribution of high-dimensional data. Determining the parameters of this\ndistribution under various constraints is a widely studied problem in\nstatistics, and is often considered as a prototype for testing new algorithms\nor theoretical frameworks. In this paper, we develop a nonasymptotic approach\nto the problem of estimating the parameters of a multivariate Gaussian\ndistribution when data are corrupted by outliers. We propose an\nestimator---efficiently computable by solving a convex program---that robustly\nestimates the population mean and the population covariance matrix even when\nthe sample contains a significant proportion of outliers. Our estimator of the\ncorruption matrix is provably rate optimal simultaneously for the entry-wise\n$\\ell_1$-norm, the Frobenius norm and the mixed $\\ell_2/\\ell_1$ norm.\nFurthermore, this optimality is achieved by a penalized\nsquare-root-of-least-squares method with a universal tuning parameter\n(calibrating the strength of the penalization). These results are partly\nextended to the case where $p$ is potentially larger than $n$, under the\nadditional condition that the inverse covariance matrix is sparse.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2015 11:33:04 GMT"}, {"version": "v2", "created": "Wed, 3 Feb 2016 16:26:11 GMT"}, {"version": "v3", "created": "Sat, 6 Feb 2016 23:53:06 GMT"}], "update_date": "2016-02-09", "authors_parsed": [["Balmand", "Samuel", ""], ["Dalalyan", "Arnak", ""]]}, {"id": "1512.04823", "submitter": "Philipp Wacker", "authors": "Miguel de Benito Delgado, Philipp Wacker", "title": "Bayesian model selection for linear regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this note we introduce linear regression with basis functions in order to\napply Bayesian model selection. The goal is to incorporate Occam's razor as\nprovided by Bayes analysis in order to automatically pick the model optimally\nable to explain the data without overfitting.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2015 15:46:11 GMT"}], "update_date": "2015-12-16", "authors_parsed": [["Delgado", "Miguel de Benito", ""], ["Wacker", "Philipp", ""]]}, {"id": "1512.04858", "submitter": "Joram Soch", "authors": "Joram Soch", "title": "Solution for the Indefinite Integral of the Standard Normal Probability\n  Density Function", "comments": "6 pages, 1 figure (caption corrected)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.OT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional wisdom assumes that the indefinite integral of the probability\ndensity function for the standard normal distribution cannot be expressed in\nfinite elementary terms. While this is true, there is an expression for this\nanti-derivative in infinite elementary terms that, when being differentiated,\ndirectly yields the standard normal density function. We derive this function\nusing infinite partial integration and review its relation to the cumulative\ndistribution function for the standard normal distribution and the error\nfunction.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2015 17:06:23 GMT"}, {"version": "v2", "created": "Wed, 16 Dec 2015 16:54:08 GMT"}, {"version": "v3", "created": "Fri, 4 Nov 2016 12:44:06 GMT"}], "update_date": "2016-11-07", "authors_parsed": [["Soch", "Joram", ""]]}, {"id": "1512.04922", "submitter": "Ramesh Johari", "authors": "Ramesh Johari, Leo Pekelis, David J. Walsh", "title": "Always Valid Inference: Bringing Sequential Analysis to A/B Testing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.AP stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A/B tests are typically analyzed via frequentist p-values and confidence\nintervals; but these inferences are wholly unreliable if users endogenously\nchoose samples sizes by *continuously monitoring* their tests. We define\n*always valid* p-values and confidence intervals that let users try to take\nadvantage of data as fast as it becomes available, providing valid statistical\ninference whenever they make their decision. Always valid inference can be\ninterpreted as a natural interface for a sequential hypothesis test, which\nempowers users to implement a modified test tailored to them. In particular, we\nshow in an appropriate sense that the measures we develop tradeoff sample size\nand power efficiently, despite a lack of prior knowledge of the user's relative\npreference between these two goals. We also use always valid p-values to obtain\nmultiple hypothesis testing control in the sequential context. Our methodology\nhas been implemented in a large scale commercial A/B testing platform to\nanalyze hundreds of thousands of experiments to date.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2015 20:33:31 GMT"}, {"version": "v2", "created": "Wed, 17 Feb 2016 07:12:05 GMT"}, {"version": "v3", "created": "Tue, 16 Jul 2019 19:42:42 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["Johari", "Ramesh", ""], ["Pekelis", "Leo", ""], ["Walsh", "David J.", ""]]}, {"id": "1512.05054", "submitter": "Qidi Peng", "authors": "Sixian Jin, Qidi Peng and Henry Schellhorn", "title": "Estimation of the Pointwise H\\\"older Exponent of Hidden Multifractional\n  Brownian Motion Using Wavelet Coefficients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a wavelet-based approach to construct consistent estimators of the\npointwise H\\\"older exponent of a multifractional Brownian motion, in the case\nwhere this underlying process is not directly observed. The relative merits of\nour estimator are discussed, and we introduce an application to the problem of\nestimating the functional parameter of a nonlinear model.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2015 05:21:47 GMT"}, {"version": "v2", "created": "Sat, 9 Jul 2016 18:20:53 GMT"}, {"version": "v3", "created": "Tue, 12 Jul 2016 01:26:20 GMT"}, {"version": "v4", "created": "Sun, 17 Jul 2016 21:10:19 GMT"}], "update_date": "2016-07-19", "authors_parsed": [["Jin", "Sixian", ""], ["Peng", "Qidi", ""], ["Schellhorn", "Henry", ""]]}, {"id": "1512.05446", "submitter": "Mohammad Jafari Jozani", "authors": "Mohammad Nourmohammadi, Mohammad Jafari Jozani and Brad Johnson", "title": "Parametric inference for proportional (reverse) hazard rate models with\n  nomination sampling", "comments": "26 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  \\noindent Randomized nomination sampling (RNS) is a rank-based sampling\ntechnique which has been shown to be effective in several nonparametric studies\ninvolving environmental and ecological applications. In this paper, we\ninvestigate parametric inference using RNS design for estimating the unknown\nvector of parameters $\\boldsymbol{\\theta}$ in the proportional hazard rate and\nproportional reverse hazard rate models. We examine both maximum likelihood\n(ML) and method of moments (MM) methods and investigate the relative precision\nof our proposed RNS-based estimators compared with those based on simple random\nsampling (SRS). We introduce four types of RNS-based data as well as necessary\nEM algorithms for the ML estimation, and evaluate the performance of\ncorresponding estimators in estimating $\\boldsymbol{\\theta}$. We show that\nthere are always values of the design parameters on which RNS-based estimators\nare more efficient than those based on SRS. Inference based on imperfect\nranking is also explored and it is shown that the improvement holds even when\nthe ranking is imperfect. Theoretical results are augmented with numerical\nevaluations and a case study.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2015 02:51:06 GMT"}], "update_date": "2015-12-18", "authors_parsed": [["Nourmohammadi", "Mohammad", ""], ["Jozani", "Mohammad Jafari", ""], ["Johnson", "Brad", ""]]}, {"id": "1512.05534", "submitter": "Jari  Miettinen", "authors": "Jari Miettinen, Klaus Nordhausen, Hannu Oja, Sara Taskinen and Joni\n  Virta", "title": "The squared symmetric FastICA estimator", "comments": null, "journal-ref": "Signal Processing 131 (2017) 402-411", "doi": "10.1016/j.sigpro.2016.08.028", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study the theoretical properties of the deflation-based\nFastICA method, the original symmetric FastICA method, and a modified symmetric\nFastICA method, here called the squared symmetric FastICA. This modification is\nobtained by replacing the absolute values in the FastICA objective function by\ntheir squares. In the deflation-based case this replacement has no effect on\nthe estimate since the maximization problem stays the same. However, in the\nsymmetric case a novel estimate with unknown properties is obtained. In the\npaper we review the classic deflation-based and symmetric FastICA approaches\nand contrast these with the new squared symmetric version of FastICA. We find\nthe estimating equations and derive the asymptotical properties of the squared\nsymmetric FastICA estimator with an arbitrary choice of nonlinearity.\nAsymptotic variances of the unmixing matrix estimates are then used to compare\ntheir efficiencies for large sample sizes showing that the squared symmetric\nFastICA estimator outperforms the other two estimators in a wide variety of\nsituations.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2015 11:15:16 GMT"}], "update_date": "2016-10-24", "authors_parsed": [["Miettinen", "Jari", ""], ["Nordhausen", "Klaus", ""], ["Oja", "Hannu", ""], ["Taskinen", "Sara", ""], ["Virta", "Joni", ""]]}, {"id": "1512.05633", "submitter": "Dennis Prangle", "authors": "Dennis Prangle", "title": "Summary Statistics in Approximate Bayesian Computation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This document is due to appear as a chapter of the forthcoming Handbook of\nApproximate Bayesian Computation (ABC) edited by S. Sisson, Y. Fan, and M.\nBeaumont.\n  Since the earliest work on ABC, it has been recognised that using summary\nstatistics is essential to produce useful inference results. This is because\nABC suffers from a curse of dimensionality effect, whereby using high\ndimensional inputs causes large approximation errors in the output. It is\ntherefore crucial to find low dimensional summaries which are informative about\nthe parameter inference or model choice task at hand. This chapter reviews the\nmethods which have been proposed to select such summaries, extending the\nprevious review paper of Blum et al. (2013) with recent developments. Related\ntheoretical results on the ABC curse of dimensionality and sufficiency are also\ndiscussed.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2015 15:38:34 GMT"}], "update_date": "2015-12-18", "authors_parsed": [["Prangle", "Dennis", ""]]}, {"id": "1512.05871", "submitter": "Jean-Francois Coeurjolly", "authors": "Jean-Fran\\c{c}ois Coeurjolly (FIGAL), Jesper M{\\o}ller, Rasmus\n  Waagepetersen", "title": "A tutorial on Palm distributions for spatial point processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This tutorial provides an introduction to Palm distributions for spatial\npoint processes. Initially, in the context of finite point processes , we give\nan explicit definition of Palm distributions in terms of their density\nfunctions. Then we review Palm distributions in the general case. Finally we\ndiscuss some examples of Palm distributions for specific models and some\napplications.\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2015 08:48:33 GMT"}, {"version": "v2", "created": "Fri, 17 Jun 2016 10:45:09 GMT"}], "update_date": "2016-06-20", "authors_parsed": [["Coeurjolly", "Jean-Fran\u00e7ois", "", "FIGAL"], ["M\u00f8ller", "Jesper", ""], ["Waagepetersen", "Rasmus", ""]]}, {"id": "1512.06023", "submitter": "Julien Flamant", "authors": "Nicolas Le Bihan, Julien Flamant and Jonathan H. Manton", "title": "Density estimation on the rotation group using diffusive wavelets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the problem of estimating probability density functions\non the rotation group $SO(3)$. Two distinct approaches are proposed, one based\non characteristic functions and the other on wavelets using the heat kernel.\nExpressions are derived for their Mean Integrated Squared Errors. The\nperformance of the estimators is studied numerically and compared with the\nperformance of an existing technique using the De La Vall\\'ee Poussin kernel\nestimator. The heat-kernel wavelet approach appears to offer the best\nconvergence, with faster convergence to the optimal bound and guaranteed\npositivity of the estimated probability density function.\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2015 16:38:26 GMT"}], "update_date": "2015-12-21", "authors_parsed": [["Bihan", "Nicolas Le", ""], ["Flamant", "Julien", ""], ["Manton", "Jonathan H.", ""]]}, {"id": "1512.06159", "submitter": "Richard Chen", "authors": "Richard Y. Chen, Per A. Mykland", "title": "Model-Free Approaches to Discern Non-Stationary Microstructure Noise and\n  Time-Varying Liquidity in High-Frequency Data", "comments": null, "journal-ref": "Journal of Econometrics, Volume 200, Issue 1, September 2017,\n  Pages 79-103", "doi": "10.1016/j.jeconom.2017.05.015", "report-no": null, "categories": "q-fin.ST math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we provide non-parametric statistical tools to test\nstationarity of microstructure noise in general hidden Ito semimartingales, and\ndiscuss how to measure liquidity risk using high frequency financial data. In\nparticular, we investigate the impact of non-stationary microstructure noise on\nsome volatility estimators, and design three complementary tests by exploiting\nedge effects, information aggregation of local estimates and high-frequency\nasymptotic approximation. The asymptotic distributions of these tests are\navailable under both stationary and non-stationary assumptions, thereby enable\nus to conservatively control type-I errors and meanwhile ensure the proposed\ntests enjoy the asymptotically optimal statistical power. Besides it also\nenables us to empirically measure aggregate liquidity risks by these test\nstatistics. As byproducts, functional dependence and endogenous microstructure\nnoise are briefly discussed. Simulation with a realistic configuration\ncorroborates our theoretical results, and our empirical study indicates the\nprevalence of non-stationary microstructure noise in New York Stock Exchange.\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2015 22:57:28 GMT"}, {"version": "v2", "created": "Sat, 30 Jan 2016 00:25:42 GMT"}, {"version": "v3", "created": "Sun, 15 Jan 2017 17:48:02 GMT"}, {"version": "v4", "created": "Wed, 10 Oct 2018 20:13:04 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Chen", "Richard Y.", ""], ["Mykland", "Per A.", ""]]}, {"id": "1512.06290", "submitter": "Demian Pouzo", "authors": "Demian Pouzo", "title": "On the Non-Asymptotic Properties of Regularized M-estimators", "comments": "75 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST econ.EM stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a general framework for regularization in M-estimation problems\nunder time dependent (absolutely regular-mixing) data which encompasses many of\nthe existing estimators. We derive non-asymptotic concentration bounds for the\nregularized M-estimator. Our results exhibit a variance-bias trade-off, with\nthe variance term being governed by a novel measure of the complexity of the\nparameter set. We also show that the mixing structure affect the variance term\nby scaling the number of observations; depending on the decay rate of the\nmixing coefficients, this scaling can even affect the asymptotic behavior.\nFinally, we propose a data-driven method for choosing the tuning parameters of\nthe regularized estimator which yield the same (up to constants) concentration\nbound as one that optimally balances the (squared) bias and variance terms. We\nillustrate the results with several canonical examples.\n", "versions": [{"version": "v1", "created": "Sat, 19 Dec 2015 22:05:52 GMT"}, {"version": "v2", "created": "Tue, 3 May 2016 23:16:39 GMT"}, {"version": "v3", "created": "Fri, 21 Oct 2016 14:52:35 GMT"}], "update_date": "2018-01-04", "authors_parsed": [["Pouzo", "Demian", ""]]}, {"id": "1512.06412", "submitter": "Benjamin Frot", "authors": "Benjamin Frot, Luke Jostins, Gil McVean", "title": "Latent variable model selection for Gaussian conditional random fields", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning a conditional Gaussian graphical model in\nthe presence of latent variables. Building on recent advances in this field, we\nsuggest a method that decomposes the parameters of a conditional Markov random\nfield into the sum of a sparse and a low-rank matrix. We derive convergence\nbounds for this estimator and show that it is well-behaved in the\nhigh-dimensional regime as well as \"sparsistent\" (i.e. capable of recovering\nthe graph structure). We then show how proximal gradient algorithms and\nsemi-definite programming techniques can be employed to fit the model to\nthousands of variables. Through extensive simulations, we illustrate the\nconditions required for identifiability and show that there is a wide range of\nsituations in which this model performs significantly better than its\ncounterparts, for example, by accommodating more latent variables. Finally, the\nsuggested method is applied to two datasets comprising individual level data on\ngenetic variants and metabolites levels. We show our results replicate better\nthan alternative approaches and show enriched biological signal.\n", "versions": [{"version": "v1", "created": "Sun, 20 Dec 2015 17:44:49 GMT"}, {"version": "v2", "created": "Thu, 17 Mar 2016 00:24:33 GMT"}, {"version": "v3", "created": "Sat, 4 Mar 2017 21:49:35 GMT"}], "update_date": "2017-03-07", "authors_parsed": [["Frot", "Benjamin", ""], ["Jostins", "Luke", ""], ["McVean", "Gil", ""]]}, {"id": "1512.06479", "submitter": "James P. Crutchfield", "authors": "Ryan G. James and Nix Barnett and James P. Crutchfield", "title": "Information Flows? A Critique of Transfer Entropies", "comments": "6 pages, 2 figures; http://csc.ucdavis.edu/~cmg/compmech/pubs/if.htm", "journal-ref": "Phys. Rev. Lett. 116, 238701 (2016)", "doi": "10.1103/PhysRevLett.116.238701", "report-no": null, "categories": "cond-mat.stat-mech cs.IT math.IT math.ST nlin.AO q-bio.MN stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A central task in analyzing complex dynamics is to determine the loci of\ninformation storage and the communication topology of information flows within\na system. Over the last decade and a half, diagnostics for the latter have come\nto be dominated by the transfer entropy. Via straightforward examples, we show\nthat it and a derivative quantity, the causation entropy, do not, in fact,\nquantify the flow of information. At one and the same time they can\noverestimate flow or underestimate influence. We isolate why this is the case\nand propose several avenues to alternate measures for information flow. We also\naddress an auxiliary consequence: The proliferation of networks as a now-common\ntheoretical model for large-scale systems, in concert with the use of\ntransfer-like entropies, has shoehorned dyadic relationships into our\nstructural interpretation of the organization and behavior of complex systems.\nThis interpretation thus fails to include the effects of polyadic dependencies.\nThe net result is that much of the sophisticated organization of complex\nsystems may go undetected.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2015 03:07:40 GMT"}, {"version": "v2", "created": "Fri, 17 Jun 2016 15:32:43 GMT"}], "update_date": "2016-06-20", "authors_parsed": [["James", "Ryan G.", ""], ["Barnett", "Nix", ""], ["Crutchfield", "James P.", ""]]}, {"id": "1512.06564", "submitter": "Tamio Koyama", "authors": "Tamio Koyama", "title": "Holonomic gradient method for the probability content of a simplex\n  region with a multivariate normal distribution", "comments": "22 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use the holonomic gradient method to evaluate the probability content of a\nsimplex region under a multivariate normal distribution. This probability\nequals to the integral of the probability density function of the multivariate\nGaussian distribution on the simplex region. For this purpose, we generalize\nthe inclusion--exclusion identity which was given for polyhedra, to the faces\nof a polyhedron. This extended inclusion--exclusion identity enables us to\ncalculate the derivatives of the function associated with the probability\ncontent of a polyhedron in general position. We show that these derivatives can\nbe written as integrals of the faces of the polyhedron.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2015 10:25:16 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2020 06:22:40 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Koyama", "Tamio", ""]]}, {"id": "1512.06588", "submitter": "Sunanda Bagchi", "authors": "Sunanda Bagchi (Theoretical Statistics and Mathematics Unit, Indian\n  Statistical Institute, Bangalore 560059, India)", "title": "Inter-class orthogonal main effect plans for asymmetrical experiments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we construct `inter-class orthogonal' main effect plans (MEP)\nfor asymmetrical experiments. In such a plan, a factor is orthogonal to all\nothers except possibly the ones in its own class. We have also defined the\nconcept of \"partial orthogonality\" between a pair of factors. In many of our\nplans, \"partial orthogonality\" has been achieved when (total) orthogonality is\nnot possible due to divisibility or any other restriction.\n  We present a method of obtaining `inter-class orthogonal' MEPs. Using this\nmethod and also a method of `cut and paste' we have obtained several series of\n`inter-class orthogonal' MEPs. Interestingly some of these happen to be\northogonal MEP (OMEP), for example we have constructed an OMEP for a $3^{30}$\nexperiment on 64 runs. Further, many of the `inter-class orthogonal' MEPs are\n`almost orthogonal' in the sense that each factor is orthogonal to all others\nexcept possibly one. In many of the other MEPs factors are \"orthogonal through\nanother factor\", thus leading to simplification in the analysis. Plans of small\nsize ($\\leq 15$ runs) are also constructed by ad-hoc methods.\n  Finally, we present a user-friendly computational method for analysing data\nobtained from any general factorial design.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2015 11:49:24 GMT"}, {"version": "v2", "created": "Wed, 23 Dec 2015 06:13:02 GMT"}], "update_date": "2015-12-24", "authors_parsed": [["Bagchi", "Sunanda", "", "Theoretical Statistics and Mathematics Unit, Indian\n  Statistical Institute, Bangalore 560059, India"]]}, {"id": "1512.06693", "submitter": "Jean-Francois Coeurjolly", "authors": "Jean-Fran\\c{c}ois Coeurjolly (FIGAL), Yongtao Guan, Mahdieh\n  Khanmohammadi (DIKU), Rasmus Waagepetersen", "title": "Towards optimal Takacs--Fiksel estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Takacs--Fiksel method is a general approach to estimate the parameters of\na spatial Gibbs point process. This method embraces standard procedures such as\nthe pseudolikelihood and is defined via weight functions. In this paper we\npropose a general procedure to find weight functions which reduce the Godambe\ninformation and thus outperform pseudolikelihood in certain situations. The new\nprocedure is applied to a standard dataset and to a recent neuroscience\nreplicated point pattern dataset. Finally, the performance of the new procedure\nis investigated in a simulation study.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2015 16:48:01 GMT"}, {"version": "v2", "created": "Fri, 25 Mar 2016 14:19:19 GMT"}, {"version": "v3", "created": "Wed, 13 Jul 2016 07:58:26 GMT"}], "update_date": "2016-07-14", "authors_parsed": [["Coeurjolly", "Jean-Fran\u00e7ois", "", "FIGAL"], ["Guan", "Yongtao", "", "DIKU"], ["Khanmohammadi", "Mahdieh", "", "DIKU"], ["Waagepetersen", "Rasmus", ""]]}, {"id": "1512.06809", "submitter": "Pamela Llop", "authors": "Alejandro Cholaquidis, Liliana Forzani, Pamela Llop, Leonardo Moreno", "title": "On the classification problem for Poisson Point Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the binary classification problem for Poisson point processes, which\nare allowed to take values in a general metric space. The problem is tackled in\ntwo different ways: estimating nonparametricaly the intensity functions of the\nprocesses (and then plugged into a deterministic formula which expresses the\nregression function in terms of the intensities), and performing the classical\n$k$ nearest neighbor rule by introducing a suitable distance between patterns\nof points. In the first approach we prove the consistency of the estimated\nintensity so that the rule turns out to be also consistent. For the $k$-NN\nclassifier, we prove that the regression function fulfils the so called\n\"Besicovitch condition\", usually required for the consistency of the classical\nclassification rules. The theoretical findings are illustrated on simulated\ndata, where in one case the $k$-NN rule outperforms the first approach.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2015 20:31:50 GMT"}, {"version": "v2", "created": "Fri, 5 Feb 2016 17:13:39 GMT"}, {"version": "v3", "created": "Thu, 30 Jun 2016 19:09:41 GMT"}], "update_date": "2016-07-01", "authors_parsed": [["Cholaquidis", "Alejandro", ""], ["Forzani", "Liliana", ""], ["Llop", "Pamela", ""], ["Moreno", "Leonardo", ""]]}, {"id": "1512.06992", "submitter": "Christos Dimitrakakis", "authors": "Zuhe Zhang, Benjamin Rubinstein, Christos Dimitrakakis", "title": "On the Differential Privacy of Bayesian Inference", "comments": "AAAI 2016, Feb 2016, Phoenix, Arizona, United States", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CR cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study how to communicate findings of Bayesian inference to third parties,\nwhile preserving the strong guarantee of differential privacy. Our main\ncontributions are four different algorithms for private Bayesian inference on\nproba-bilistic graphical models. These include two mechanisms for adding noise\nto the Bayesian updates, either directly to the posterior parameters, or to\ntheir Fourier transform so as to preserve update consistency. We also utilise a\nrecently introduced posterior sampling mechanism, for which we prove bounds for\nthe specific but general case of discrete Bayesian networks; and we introduce a\nmaximum-a-posteriori private mechanism. Our analysis includes utility and\nprivacy bounds, with a novel focus on the influence of graph structure on\nprivacy. Worked examples and experiments with Bayesian na{\\\"i}ve Bayes and\nBayesian linear regression illustrate the application of our mechanisms.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2015 09:22:39 GMT"}], "update_date": "2015-12-23", "authors_parsed": [["Zhang", "Zuhe", ""], ["Rubinstein", "Benjamin", ""], ["Dimitrakakis", "Christos", ""]]}, {"id": "1512.07052", "submitter": "Mathieu Sart", "authors": "Mathieu Sart (ICJ)", "title": "Estimating the conditional density by histogram type estimators and\n  model selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new estimation procedure of the conditional density for\nindependent and identically distributed data. Our procedure aims at using the\ndata to select a function among arbitrary (at most countable) collections of\ncandidates. By using a deterministic Hellinger distance as loss, we prove that\nthe selected function satisfies a non-asymptotic oracle type inequality under\nminimal assumptions on the statistical setting. We derive an adaptive piecewise\nconstant estimator on a random partition that achieves the expected rate of\nconvergence over (possibly inhomogeneous and anisotropic) Besov spaces of small\nregularity. Moreover, we show that this oracle inequality may lead to a general\nmodel selection theorem under very mild assumptions on the statistical setting.\nThis theorem guarantees the existence of estimators possessing nice statistical\nproperties under various assumptions on the conditional density (such as\nsmoothness or structural ones).\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2015 12:32:11 GMT"}, {"version": "v2", "created": "Tue, 2 Feb 2016 13:52:58 GMT"}, {"version": "v3", "created": "Tue, 25 Oct 2016 12:03:02 GMT"}], "update_date": "2016-10-26", "authors_parsed": [["Sart", "Mathieu", "", "ICJ"]]}, {"id": "1512.07059", "submitter": "Tatiane Melo", "authors": "T. F. N. Melo, S. L. P. Ferrari and A. G. Patriota", "title": "Improved hypothesis testing in a general multivariate elliptical model", "comments": "20 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates improved testing inferences under a general\nmultivariate elliptical regression model. The model is very flexible in terms\nof the specification of the mean vector and the dispersion matrix, and of the\nchoice of the error distribution. The error terms are allowed to follow a\nmultivariate distribution in the class of the elliptical distributions, which\nhas the multivariate normal and Student-t distributions as special cases. We\nobtain Skovgaard's adjusted likelihood ratio statistics and Barndorff-Nielsen's\nadjusted signed likelihood ratio statistics and we conduct a simulation study.\nThe simulations suggest that the proposed tests display superior finite sample\nbehavior as compared to the standard tests. Two applications are presented in\norder to illustrate the methods.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2015 12:42:28 GMT"}, {"version": "v2", "created": "Mon, 31 Oct 2016 18:38:33 GMT"}], "update_date": "2016-11-01", "authors_parsed": [["Melo", "T. F. N.", ""], ["Ferrari", "S. L. P.", ""], ["Patriota", "A. G.", ""]]}, {"id": "1512.07060", "submitter": "Bertrand Iooss", "authors": "Thomas Browne (UPD5), Bertrand Iooss (IMT, GdR MASCOT-NUM), Lo\\\"ic Le\n  Gratiet, J\\'er\\^ome Lonchampt, Emmanuel Remy", "title": "Stochastic simulators based optimization by Gaussian process metamodels\n  -- Application to maintenance investments planning issues", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with the optimization of industrial asset management\nstrategies, whose profitability is characterized by the Net Present Value (NPV)\nindicator which is assessed by a Monte Carlo simulator. The developed method\nconsists in building a metamodel of this stochastic simulator, allowing to get,\nfor a given model input, the NPV probability distribution without running the\nsimulator. The present work is concentrated on the emulation of the quantile\nfunction of the stochastic simulator by interpolating well chosen basis\nfunctions and metamodeling their coefficients (using the Gaussian process\nmetamodel). This quantile function metamodel is then used to treat a problem of\nstrategy maintenance optimization (four systems installed on different plants),\nin order to optimize an NPV quantile. Using the Gaussian process framework, an\nadaptive design method (called QFEI) is defined by extending in our case the\nwell known EGO algorithm. This allows to obtain an \"optimal\" solution using a\nsmall number of simulator runs.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2015 12:42:47 GMT"}, {"version": "v2", "created": "Tue, 3 May 2016 14:32:06 GMT"}], "update_date": "2016-05-04", "authors_parsed": [["Browne", "Thomas", "", "UPD5"], ["Iooss", "Bertrand", "", "IMT, GdR MASCOT-NUM"], ["Gratiet", "Lo\u00efc Le", ""], ["Lonchampt", "J\u00e9r\u00f4me", ""], ["Remy", "Emmanuel", ""]]}, {"id": "1512.07146", "submitter": "Steve Hanneke", "authors": "Steve Hanneke", "title": "Refined Error Bounds for Several Learning Algorithms", "comments": null, "journal-ref": "Journal of Machine Learning Research, Vol. 17 (2016), No. 135, pp.\n  1-55", "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article studies the achievable guarantees on the error rates of certain\nlearning algorithms, with particular focus on refining logarithmic factors.\nMany of the results are based on a general technique for obtaining bounds on\nthe error rates of sample-consistent classifiers with monotonic error regions,\nin the realizable case. We prove bounds of this type expressed in terms of\neither the VC dimension or the sample compression size. This general technique\nalso enables us to derive several new bounds on the error rates of general\nsample-consistent learning algorithms, as well as refined bounds on the label\ncomplexity of the CAL active learning algorithm. Additionally, we establish a\nsimple necessary and sufficient condition for the existence of a\ndistribution-free bound on the error rates of all sample-consistent learning\nrules, converging at a rate inversely proportional to the sample size. We also\nstudy learning in the presence of classification noise, deriving a new excess\nerror rate guarantee for general VC classes under Tsybakov's noise condition,\nand establishing a simple and general necessary and sufficient condition for\nthe minimax excess risk under bounded noise to converge at a rate inversely\nproportional to the sample size.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2015 16:17:43 GMT"}, {"version": "v2", "created": "Sat, 10 Sep 2016 15:11:33 GMT"}], "update_date": "2016-09-13", "authors_parsed": [["Hanneke", "Steve", ""]]}, {"id": "1512.07267", "submitter": "Hyungsuk Tak", "authors": "Hyungsuk Tak and Carl N. Morris", "title": "Data-dependent Posterior Propriety of Bayesian Beta-Binomial-Logit Model", "comments": null, "journal-ref": "Bayesian Analysis (2017) 12, 2, 533-555", "doi": "10.1214/16-BA1012", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Beta-Binomial-Logit model is a Beta-Binomial model with covariate\ninformation incorporated via a logistic regression. Posterior propriety of a\nBayesian Beta-Binomial-Logit model can be data-dependent for improper\nhyper-prior distributions. Various researchers in the literature have\nunknowingly used improper posterior distributions or have given incorrect\nstatements about posterior propriety because checking posterior propriety can\nbe challenging due to the complicated functional form of a Beta-Binomial-Logit\nmodel. We derive data-dependent necessary and sufficient conditions for\nposterior propriety within a class of hyper-prior distributions that encompass\nthose used in previous studies.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2015 21:31:45 GMT"}], "update_date": "2017-03-30", "authors_parsed": [["Tak", "Hyungsuk", ""], ["Morris", "Carl N.", ""]]}, {"id": "1512.07383", "submitter": "Giorgio Mantica", "authors": "Giorgio Mantica and Luca Perotti", "title": "Extreme value laws for fractal intensity functions in dynamical systems:\n  Minkowski analysis", "comments": "20 pages, 13 figures", "journal-ref": null, "doi": "10.1088/1751-8113/49/37/374001", "report-no": null, "categories": "math.DS math-ph math.MP math.ST nlin.CD physics.geo-ph stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Typically, in the dynamical theory of extremal events, the function that\ngauges the intensity of a phenomenon is assumed to be convex and maximal, or\nsingular, at a single, or at most a finite collection of points in\nphase--space. In this paper we generalize this situation to fractal landscapes,\ni.e. intensity functions characterized by an uncountable set of singularities,\nlocated on a Cantor set. This reveals the dynamical r\\^ole of classical\nquantities like the Minkowski dimension and content, whose definition we extend\nto account for singular continuous invariant measures. We also introduce the\nconcept of extremely rare event, quantified by non--standard Minkowski\nconstants and we study its consequences to extreme value statistics. Limit laws\nare derived from formal calculations and are verified by numerical experiments.\n", "versions": [{"version": "v1", "created": "Wed, 23 Dec 2015 08:09:35 GMT"}, {"version": "v2", "created": "Fri, 18 Mar 2016 10:33:49 GMT"}], "update_date": "2016-09-21", "authors_parsed": [["Mantica", "Giorgio", ""], ["Perotti", "Luca", ""]]}, {"id": "1512.07385", "submitter": "Michael Creel", "authors": "Michael Creel, Jiti Gao, Han Hong, Dennis Kristensen", "title": "Bayesian Indirect Inference and the ABC of GMM", "comments": "Further work has led us to conflicting results, we are still working\n  on resolving the differences. This version is likely to have some incorrect\n  results", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose and study local linear and polynomial based\nestimators for implementing Approximate Bayesian Computation (ABC) style\nindirect inference and GMM estimators. This method makes use of nonparametric\nregression in the computation of GMM and Indirect Inference models. We provide\nformal conditions under which frequentist inference is asymptotically valid and\ndemonstrate the validity of the estimated posterior quantiles for confidence\ninterval construction. We also show that in this setting, local linear kernel\nregression methods have theoretical advantages over local constant kernel\nmethods that are also reflected in finite sample simulation results. Our\nresults also apply to both exactly and over identified models. These estimators\ndo not need to rely on numerical optimization or Markov Chain Monte Carlo\n(MCMC) simulations. They provide an effective complement to the classical\nM-estimators and to MCMC methods, and can be applied to both likelihood based\nmodels and method of moment based models.\n", "versions": [{"version": "v1", "created": "Wed, 23 Dec 2015 08:14:16 GMT"}, {"version": "v2", "created": "Thu, 12 Mar 2020 09:36:22 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Creel", "Michael", ""], ["Gao", "Jiti", ""], ["Hong", "Han", ""], ["Kristensen", "Dennis", ""]]}, {"id": "1512.07445", "submitter": "Eni Musta", "authors": "Hendrik P. Lopuha\\\"a and Eni Musta", "title": "Smooth estimation of a monotone hazard and a monotone density under\n  random censoring", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider kernel smoothed Grenander-type estimators for a monotone hazard\nrate and a monotone density in the presence of randomly right censored data. We\nshow that they converge at rate $n^{2/5}$ and that the limit distribution at a\nfixed point is Gaussian with explicitly given mean and variance. It is\nwell-known that standard kernel smoothing leads to inconsistency problems at\nthe boundary points. It turns out that, also by using a boundary correction, we\ncan only establish uniform consistency on intervals that stay away from the end\npoint of the support (though we can go arbitrarily close to the right\nboundary).\n", "versions": [{"version": "v1", "created": "Wed, 23 Dec 2015 12:06:56 GMT"}, {"version": "v2", "created": "Thu, 17 May 2018 13:23:37 GMT"}], "update_date": "2018-05-18", "authors_parsed": [["Lopuha\u00e4", "Hendrik P.", ""], ["Musta", "Eni", ""]]}, {"id": "1512.07560", "submitter": "Malek Ben Salem", "authors": "Malek Ben Salem (DEMO-ENSMSE), Olivier Roustant (DEMO-ENSMSE), Fabrice\n  Gamboa (IMT), Lionel Tomaso", "title": "Universal Prediction Distribution for Surrogate Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of surrogate models instead of computationally expensive simulation\ncodes is very convenient in engineering. Roughly speaking, there are two kinds\nof surrogate models: the deterministic and the probabilistic ones. These last\nare generally based on Gaussian assumptions. The main advantage of\nprobabilistic approach is that it provides a measure of uncertainty associated\nwith the surrogate model in the whole space. This uncertainty is an efficient\ntool to construct strategies for various problems such as prediction\nenhancement, optimization or inversion.In this paper, we propose a universal\nmethod to define a measure of uncertainty suitable for any surrogate model\neither deterministic or probabilistic. It relies on Cross-Validation (CV)\nsub-models predictions. This empirical distribution may be computed in much\nmore general frames than the Gaussian one. So that it is called the Universal\nPrediction distribution (UP distribution).It allows the definition of many\nsampling criteria. We give and study adaptive sampling techniques for global\nrefinement and an extension of the so-called Efficient Global Optimization\n(EGO) algorithm. We also discuss the use of the UP distribution for inversion\nproblems. The performances of these new algorithms are studied both on toys\nmodels and on an engineering design problem.\n", "versions": [{"version": "v1", "created": "Wed, 23 Dec 2015 17:52:24 GMT"}], "update_date": "2015-12-24", "authors_parsed": [["Salem", "Malek Ben", "", "DEMO-ENSMSE"], ["Roustant", "Olivier", "", "DEMO-ENSMSE"], ["Gamboa", "Fabrice", "", "IMT"], ["Tomaso", "Lionel", ""]]}, {"id": "1512.07619", "submitter": "Alexandre Belloni", "authors": "Alexandre Belloni, Victor Chernozhukov, Denis Chetverikov, and Ying\n  Wei", "title": "Uniformly Valid Post-Regularization Confidence Regions for Many\n  Functional Parameters in Z-Estimation Framework", "comments": "2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we develop procedures to construct simultaneous confidence\nbands for $\\tilde p$ potentially infinite-dimensional parameters after model\nselection for general moment condition models where $\\tilde p$ is potentially\nmuch larger than the sample size of available data, $n$. This allows us to\ncover settings with functional response data where each of the $\\tilde p$\nparameters is a function. The procedure is based on the construction of score\nfunctions that satisfy certain orthogonality condition. The proposed\nsimultaneous confidence bands rely on uniform central limit theorems for\nhigh-dimensional vectors (and not on Donsker arguments as we allow for $\\tilde\np \\gg n$). To construct the bands, we employ a multiplier bootstrap procedure\nwhich is computationally efficient as it only involves resampling the estimated\nscore functions (and does not require resolving the high-dimensional\noptimization problems). We formally apply the general theory to inference on\nregression coefficient process in the distribution regression model with a\nlogistic link, where two implementations are analyzed in detail. Simulations\nand an application to real data are provided to help illustrate the\napplicability of the results.\n", "versions": [{"version": "v1", "created": "Wed, 23 Dec 2015 20:33:45 GMT"}, {"version": "v2", "created": "Thu, 31 Mar 2016 21:44:27 GMT"}, {"version": "v3", "created": "Mon, 4 Sep 2017 18:33:38 GMT"}, {"version": "v4", "created": "Sun, 3 Feb 2019 22:48:04 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Belloni", "Alexandre", ""], ["Chernozhukov", "Victor", ""], ["Chetverikov", "Denis", ""], ["Wei", "Ying", ""]]}, {"id": "1512.07621", "submitter": "Jean-David Fermanian", "authors": "Jean-David Fermanian and Olivier Lopez", "title": "Single-index copulae", "comments": "Revised version: correction of Assumption 3 and some minor induced\n  modifications", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce so-called \"single-index copulae\". They are semi-parametric\nconditional copulae whose parameter is an unknown \"link\" function of a\nunivariate index only. We provide estimates of this link function and of the\nfinite dimensional unknown parameter. The asymptotic properties of the latter\nestimates are stated. Thanks to some properties of conditional Kendall's tau,\nwe illustrate our technical conditions with several usual copula families.\n", "versions": [{"version": "v1", "created": "Wed, 23 Dec 2015 20:43:23 GMT"}, {"version": "v2", "created": "Tue, 29 Mar 2016 09:17:27 GMT"}, {"version": "v3", "created": "Tue, 4 Jul 2017 18:42:06 GMT"}], "update_date": "2017-07-06", "authors_parsed": [["Fermanian", "Jean-David", ""], ["Lopez", "Olivier", ""]]}, {"id": "1512.07713", "submitter": "Dootika Vats", "authors": "Dootika Vats, James M. Flegal, and Galin L. Jones", "title": "Multivariate Output Analysis for Markov chain Monte Carlo", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Markov chain Monte Carlo (MCMC) produces a correlated sample for estimating\nexpectations with respect to a target distribution. A fundamental question is\nwhen should sampling stop so that we have good estimates of the desired\nquantities? The key to answering this question lies in assessing the Monte\nCarlo error through a multivariate Markov chain central limit theorem (CLT).\nThe multivariate nature of this Monte Carlo error largely has been ignored in\nthe MCMC literature. We present a multivariate framework for terminating\nsimulation in MCMC. We define a multivariate effective sample size, estimating\nwhich requires strongly consistent estimators of the covariance matrix in the\nMarkov chain CLT; a property we show for the multivariate batch means\nestimator. We then provide a lower bound on the number of minimum effective\nsamples required for a desired level of precision. This lower bound depends on\nthe problem only in the dimension of the expectation being estimated, and not\non the underlying stochastic process. This result is obtained by drawing a\nconnection between terminating simulation via effective sample size and\nterminating simulation using a relative standard deviation fixed-volume\nsequential stopping rule; which we demonstrate is an asymptotically valid\nprocedure. The finite sample properties of the proposed method are demonstrated\nin a variety of examples.\n", "versions": [{"version": "v1", "created": "Thu, 24 Dec 2015 04:43:47 GMT"}, {"version": "v2", "created": "Wed, 7 Sep 2016 22:25:35 GMT"}, {"version": "v3", "created": "Sun, 14 May 2017 11:55:08 GMT"}, {"version": "v4", "created": "Fri, 29 Sep 2017 15:13:46 GMT"}], "update_date": "2017-10-02", "authors_parsed": [["Vats", "Dootika", ""], ["Flegal", "James M.", ""], ["Jones", "Galin L.", ""]]}, {"id": "1512.07848", "submitter": "James Johndrow", "authors": "James E. Johndrow and Robert L. Wolpert", "title": "Model-free inference on extreme dependence via waiting times", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A variety of methods have been proposed for inference about extreme\ndependence for multivariate or spatially-indexed stochastic processes and time\nseries. Most of these proceed by first transforming data to some specific\nextreme value marginal distribution, often the unit Fr\\'echet, then fitting a\nfamily of max-stable processes to the transformed data and exploring dependence\nwithin the framework of that model. The marginal transformation, model\nselection, and model fitting are all possible sources of misspecification in\nthis approach.\n  We propose an alternative model-free approach, based on the idea that\nsubstantial information on the strength of tail dependence and its temporal\nstructure are encoded in the distribution of the waiting times between\nexceedances of high thresholds at different locations. We propose quantifying\nthe strength of extremal dependence and assessing uncertainty by using\nstatistics based on these waiting times. The method does not rely on any\nspecific underlying model for the process, nor on asymptotic distribution\ntheory. The method is illustrated by applications to climatological, financial,\nand electrophysiology data.\n  To put the proposed approach within the context of the existing literature,\nwe construct a class of spacetime-indexed stochastic processes whose waiting\ntime distributions are available in closed form by endowing the support points\nin de Haan's spectral representation of max-stable processes with random birth\ntimes, velocities, and lifetimes, and applying Smith's model to these\nprocesses. We show that waiting times in this model are stochatically\ndecreasing in mean speed, and the sample mean of the waiting times obeys a\ncentral limit theorem with a uniform convergence rate under mild conditions.\nThis indicates that our procedure can be implemented in this setting using\nstandard $t$ statistics and associated hypothesis tests.\n", "versions": [{"version": "v1", "created": "Thu, 24 Dec 2015 16:21:39 GMT"}, {"version": "v2", "created": "Thu, 28 Jul 2016 23:01:54 GMT"}, {"version": "v3", "created": "Mon, 21 May 2018 17:32:01 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Johndrow", "James E.", ""], ["Wolpert", "Robert L.", ""]]}, {"id": "1512.07934", "submitter": "Yves Atchade F", "authors": "Yves Atchade", "title": "A scalable quasi-Bayesian framework for Gaussian graphical models", "comments": "25 Pages, 2 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with the Bayesian estimation of high dimensional Gaussian\ngraphical models. We develop a quasi-Bayesian implementation of the\nneighborhood selection method of Meinshausen and Buhlmann (2006) for the\nestimation of Gaussian graphical models. The method produces a product-form\nquasi-posterior distribution that can be efficiently explored by parallel\ncomputing. We derive a non-asymptotic bound on the contraction rate of the\nquasi-posterior distribution. The result shows that the proposed\nquasi-posterior distribution contracts towards the true precision matrix at a\nrate given by the worst contraction rate of the linear regressions that are\ninvolved in the neighborhood selection. We develop a Markov Chain Monte Carlo\nalgorithm for approximate computations, following an approach from Atchade\n(2015). We illustrate the methodology with a simulation study. The results show\nthat the proposed method can fit Gaussian graphical models at a scale unmatched\nby other Bayesian methods for graphical models.\n", "versions": [{"version": "v1", "created": "Fri, 25 Dec 2015 00:11:51 GMT"}], "update_date": "2015-12-29", "authors_parsed": [["Atchade", "Yves", ""]]}, {"id": "1512.08159", "submitter": "Akimichi Takemura", "authors": "Constantin Siriteanu and Satoshi Kuriki and Donald Richards and\n  Akimichi Takemura", "title": "Chi-Square Mixture Representations for the Distribution of the Scalar\n  Schur Complement in a Noncentral Wishart Matrix", "comments": null, "journal-ref": "Statistics and Probability Letters 115 (2016) 79-87", "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the distribution of the scalar Schur complement in a noncentral\nWishart matrix is a mixture of central chi-square distributions with different\ndegrees of freedom. For the case of a rank-1 noncentrality matrix, the weights\nof the mixture representation arise from a noncentral beta mixture of Poisson\ndistributions.\n", "versions": [{"version": "v1", "created": "Sun, 27 Dec 2015 01:17:49 GMT"}], "update_date": "2016-05-24", "authors_parsed": [["Siriteanu", "Constantin", ""], ["Kuriki", "Satoshi", ""], ["Richards", "Donald", ""], ["Takemura", "Akimichi", ""]]}, {"id": "1512.08193", "submitter": "Salima El Kolei", "authors": "Salima El Kolei (ENSAI), Florian Pelgrin (EDHEC)", "title": "Parametric inference of hidden discrete-time diffusion processes by\n  deconvolution", "comments": "arXiv admin note: text overlap with arXiv:1202.2559", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a new parametric approach for hidden discrete-time diffusion models.\nThis method is based on contrast minimization and deconvolution and leads to\nestimate a large class of stochastic models with nonlinear drift and nonlinear\ndiffusion. It can be applied, for example, for ecological and financial state\nspace models. After proving consistency and asymptotic normality of the\nestimation, leading to asymptotic confidence intervals, we provide a thorough\nnumerical study, which compares many classical methods used in practice (Non\nLinear Least Square estimator, Monte Carlo Expectation Maxi-mization Likelihood\nestimator and Bayesian estimators) to estimate stochastic volatility model. We\nprove that our estimator clearly outperforms the Maximum Likelihood Estimator\nin term of computing time, but also most of the other methods. We also show\nthat this contrast method is the most stable and also does not need any tuning\nparameter.\n", "versions": [{"version": "v1", "created": "Sun, 27 Dec 2015 09:52:23 GMT"}, {"version": "v2", "created": "Mon, 19 Dec 2016 10:55:16 GMT"}], "update_date": "2017-01-01", "authors_parsed": [["Kolei", "Salima El", "", "ENSAI"], ["Pelgrin", "Florian", "", "EDHEC"]]}, {"id": "1512.08269", "submitter": "Fanny Yang", "authors": "Fanny Yang, Sivaraman Balakrishnan, Martin J. Wainwright", "title": "Statistical and Computational Guarantees for the Baum-Welch Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Hidden Markov Model (HMM) is one of the mainstays of statistical modeling\nof discrete time series, with applications including speech recognition,\ncomputational biology, computer vision and econometrics. Estimating an HMM from\nits observation process is often addressed via the Baum-Welch algorithm, which\nis known to be susceptible to local optima. In this paper, we first give a\ngeneral characterization of the basin of attraction associated with any global\noptimum of the population likelihood. By exploiting this characterization, we\nprovide non-asymptotic finite sample guarantees on the Baum-Welch updates,\nguaranteeing geometric convergence to a small ball of radius on the order of\nthe minimax rate around a global optimum. As a concrete example, we prove a\nlinear rate of convergence for a hidden Markov mixture of two isotropic\nGaussians given a suitable mean separation and an initialization within a ball\nof large radius around (one of) the true parameters. To our knowledge, these\nare the first rigorous local convergence guarantees to global optima for the\nBaum-Welch algorithm in a setting where the likelihood function is nonconvex.\nWe complement our theoretical results with thorough numerical simulations\nstudying the convergence of the Baum-Welch algorithm and illustrating the\naccuracy of our predictions.\n", "versions": [{"version": "v1", "created": "Sun, 27 Dec 2015 20:10:20 GMT"}], "update_date": "2015-12-29", "authors_parsed": [["Yang", "Fanny", ""], ["Balakrishnan", "Sivaraman", ""], ["Wainwright", "Martin J.", ""]]}, {"id": "1512.08379", "submitter": "Elvira Di Nardo Prof.", "authors": "Elvira Di Nardo", "title": "Symbolic Calculus in Mathematical Statistics: A Review", "comments": "72 pages", "journal-ref": "S\\'eminaire Lotharingien de Combinatoire 67 (2015), Article~B67a", "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last ten years, the employment of symbolic methods has substantially\nextended both the theory and the applications of statistics and probability.\nThis survey reviews the development of a symbolic technique arising from\nclassical umbral calculus, as introduced by Rota and Taylor in $1994.$ The\nusefulness of this symbolic technique is twofold. The first is to show how new\nalgebraic identities drive in discovering insights among topics apparently very\nfar from each other and related to probability and statistics. One of the main\ntools is a formal generalization of the convolution of identical probability\ndistributions, which allows us to employ compound Poisson random variables in\nvarious topics that are only somewhat interrelated. Having got a different and\ndeeper viewpoint, the second goal is to show how to set up algorithmic\nprocesses performing efficiently algebraic calculations. In particular, the\nchallenge of finding these symbolic procedures should lead to a new method, and\nit poses new problems involving both computational and conceptual issues.\nEvidence of efficiency in applying this symbolic method will be shown within\nstatistical inference, parameter estimation, L\\'evy processes, and, more\ngenerally, problems involving multivariate functions. The symbolic\nrepresentation of Sheffer polynomial sequences allows us to carry out a\nunifying theory of classical, Boolean and free cumulants. Recent connections\nwithin random matrices have extended the applications of the symbolic method.\n", "versions": [{"version": "v1", "created": "Mon, 28 Dec 2015 11:37:24 GMT"}], "update_date": "2015-12-29", "authors_parsed": [["Di Nardo", "Elvira", ""]]}, {"id": "1512.08407", "submitter": "Kien Kieu", "authors": "Ki\\^en Ki\\^eu, Katarzyna Adamczyk-Chauvat (MaIAGE)", "title": "Pseudolikelihood inference for Gibbsian T-tessellations ... and point\n  processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently a new class of planar tessellations, named T-tessellations, was\nintroduced. Splits, merges and a third local modification named flip where\nshown to be sufficient for exploring the space of T-tessellations. Based on\nthese local transformations and by analogy with point process theory, tools\nCampbell measures and a general simulation algorithm of\nMetropolis-Hastings-Green type were translated for random T-tessellations.The\ncurrent report is concerned with parametric inference for Gibbs models of\nT-tessellations. The estimation criterion referred to as the pseudolikelihood\nis derived from Campbell measures of random T-tessellations and the\nKullback-Leibler divergence. A detailed algorithm for approximating the\npseudolikelihood maximum is provided. A simulation study seems to show that\nbias and variability of the pseudolikelihood maximum decrease when the\ntessellated domain grows in size.In the last part of the report, it is shown\nthat an analogous approach based on the Campbell measure and the KL divergence\nwhen applied to point processes leads to the well-known pseudo-likelihood\nintroduced by Besag. More surprisingly, the binomial regression method recently\nproposed by Baddeley and his co-authors for computing the pseudolikelihood\nmaximum can be derived using the same approach starting from a slight\nmodification of the Campbell measure.\n", "versions": [{"version": "v1", "created": "Mon, 28 Dec 2015 13:22:47 GMT"}, {"version": "v2", "created": "Tue, 29 Dec 2015 14:59:35 GMT"}], "update_date": "2015-12-31", "authors_parsed": [["Ki\u00eau", "Ki\u00ean", "", "MaIAGE"], ["Adamczyk-Chauvat", "Katarzyna", "", "MaIAGE"]]}, {"id": "1512.08425", "submitter": "Jiaming Xu", "authors": "Yudong Chen and Xiaodong Li and Jiaming Xu", "title": "Convexified Modularity Maximization for Degree-corrected Stochastic\n  Block Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG cs.SI stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The stochastic block model (SBM) is a popular framework for studying\ncommunity detection in networks. This model is limited by the assumption that\nall nodes in the same community are statistically equivalent and have equal\nexpected degrees. The degree-corrected stochastic block model (DCSBM) is a\nnatural extension of SBM that allows for degree heterogeneity within\ncommunities. This paper proposes a convexified modularity maximization approach\nfor estimating the hidden communities under DCSBM. Our approach is based on a\nconvex programming relaxation of the classical (generalized) modularity\nmaximization formulation, followed by a novel doubly-weighted $ \\ell_1 $-norm $\nk $-median procedure. We establish non-asymptotic theoretical guarantees for\nboth approximate clustering and perfect clustering. Our approximate clustering\nresults are insensitive to the minimum degree, and hold even in sparse regime\nwith bounded average degrees. In the special case of SBM, these theoretical\nresults match the best-known performance guarantees of computationally feasible\nalgorithms. Numerically, we provide an efficient implementation of our\nalgorithm, which is applied to both synthetic and real-world networks.\nExperiment results show that our method enjoys competitive performance compared\nto the state of the art in the literature.\n", "versions": [{"version": "v1", "created": "Mon, 28 Dec 2015 14:48:03 GMT"}, {"version": "v2", "created": "Tue, 19 Jan 2016 17:17:32 GMT"}], "update_date": "2016-01-20", "authors_parsed": [["Chen", "Yudong", ""], ["Li", "Xiaodong", ""], ["Xu", "Jiaming", ""]]}, {"id": "1512.08472", "submitter": "Alberto J. Coca", "authors": "Alberto J. Coca", "title": "Efficient nonparametric inference for discretely observed compound\n  Poisson processes", "comments": "Probability Theory and Related Fields, to appear (39 pages)", "journal-ref": null, "doi": "10.1007/s00440-017-0761-5", "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A compound Poisson process whose parameters are all unknown is observed at\nfinitely many equispaced times. Nonparametric estimators of the jump and L\\'evy\ndistributions are proposed and functional central limit theorems using the\nuniform norm are proved for both under mild conditions. The limiting Gaussian\nprocesses are identified and efficiency of the estimators is established.\nKernel estimators for the mass function, the intensity and the drift are also\nproposed, their asymptotic properties including efficiency are analysed, and\njoint asymptotic normality is shown. Inference tools such as confidence regions\nand tests are briefly discussed.\n", "versions": [{"version": "v1", "created": "Mon, 28 Dec 2015 18:00:16 GMT"}, {"version": "v2", "created": "Thu, 3 Nov 2016 11:32:44 GMT"}, {"version": "v3", "created": "Fri, 27 Jan 2017 15:37:23 GMT"}], "update_date": "2017-02-06", "authors_parsed": [["Coca", "Alberto J.", ""]]}, {"id": "1512.08544", "submitter": "Stefan Sommer", "authors": "Stefan Sommer and Anne Marie Svane", "title": "Modelling Anisotropic Covariance using Stochastic Development and\n  Sub-Riemannian Frame Bundle Geometry", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.DG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss the geometric foundation behind the use of stochastic processes in\nthe frame bundle of a smooth manifold to build stochastic models with\napplications in statistical analysis of non-linear data. The transition\ndensities for the projection to the manifold of Brownian motions developed in\nthe frame bundle lead to a family of probability distributions on the manifold.\nWe explain how data mean and covariance can be interpreted as points in the\nframe bundle or, more precisely, in the bundle of symmetric positive definite\n2-tensors analogously to the parameters describing Euclidean normal\ndistributions. We discuss a factorization of the frame bundle projection map\nthrough this bundle, the natural sub-Riemannian structure of the frame bundle,\nthe effect of holonomy, and the existence of subbundles where the Hormander\ncondition is satisfied such that the Brownian motions have smooth transition\ndensities. We identify the most probable paths for the underlying Euclidean\nBrownian motion and discuss small time asymptotics of the transition densities\non the manifold. The geometric setup yields an intrinsic approach to the\nestimation of mean and covariance in non-linear spaces.\n", "versions": [{"version": "v1", "created": "Mon, 28 Dec 2015 22:26:13 GMT"}, {"version": "v2", "created": "Fri, 26 Aug 2016 06:23:38 GMT"}], "update_date": "2016-08-29", "authors_parsed": [["Sommer", "Stefan", ""], ["Svane", "Anne Marie", ""]]}, {"id": "1512.08732", "submitter": "Illya Karabash Mihailovich", "authors": "Illya M. Karabash and J\\\"urgen Prestin", "title": "Recovery of periodicities hidden in heavy-tailed noise", "comments": "This e-print differs in style, formatting, pagination, and small\n  non-mathematical details from the version of this paper accepted for\n  publication in \"Mathematische Nachrichten\" (Wiley-VCH). In comparison with\n  the previous version, the following changes have been made: The introduction\n  section 1 was split into two sections 1 and 2. The new section 5 was added.\n  The algorithm 4.1 was added", "journal-ref": "Mathematische Nachrichten 291 (2018), no. 1, 86-102", "doi": "10.1002/mana.201600361", "report-no": null, "categories": "math.CA math.NA math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address a parametric joint detection-estimation problem for discrete\nsignals of the form $x(t) = \\sum_{n=1}^{N} \\alpha_n e^{-i \\lambda_n t } +\n\\epsilon_t$, $t \\in \\mathbb{N}$, with an additive noise represented by\nindependent centered complex random variables $\\epsilon_t$. The distributions\nof $\\epsilon_t$ are assumed to be unknown, but satisfying various sets of\nconditions. We prove that in the case of a heavy-tailed noise it is possible to\nconstruct asymptotically strongly consistent estimators for the unknown\nparameters of the signal, i.e., the frequencies $\\lambda_n$, their number $N$,\nand complex amplitudes $\\alpha_n$. For example, one of considered classes of\nnoise is the following: $\\epsilon_t$ are independent identically distributed\nrandom variables with $\\mathbb{E} (\\epsilon_t) = 0$ and $\\mathbb{E}\n(|\\epsilon_t| \\ln |\\epsilon_t|) < \\infty$. The construction of estimators is\nbased on detection of singularities of anti-derivatives for $Z$-transforms and\non a two-level selection procedure for special discretized versions of\nsuperlevel sets. The consistency proof relies on the convergence theory for\nrandom Fourier series. We discuss also decaying signals and the case of\ninfinite number of frequencies.\n", "versions": [{"version": "v1", "created": "Tue, 29 Dec 2015 17:18:38 GMT"}, {"version": "v2", "created": "Thu, 18 Feb 2016 14:18:32 GMT"}, {"version": "v3", "created": "Sat, 20 May 2017 11:48:13 GMT"}], "update_date": "2018-08-14", "authors_parsed": [["Karabash", "Illya M.", ""], ["Prestin", "J\u00fcrgen", ""]]}, {"id": "1512.08819", "submitter": "Lingzhou Xue", "authors": "Danning Li and Lingzhou Xue", "title": "Joint limiting laws for high-dimensional independence tests", "comments": "31 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.ML stat.OT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Testing independence is of significant interest in many important areas of\nlarge-scale inference. Using extreme-value form statistics to test against\nsparse alternatives and using quadratic form statistics to test against dense\nalternatives are two important testing procedures for high-dimensional\nindependence. However, quadratic form statistics suffer from low power against\nsparse alternatives, and extreme-value form statistics suffer from low power\nagainst dense alternatives with small disturbances and may have size\ndistortions due to its slow convergence. For real-world applications, it is\nimportant to derive powerful testing procedures against more general\nalternatives. Based on intermediate limiting distributions, we derive\n(model-free) joint limiting laws of extreme-value form and quadratic form\nstatistics, and surprisingly, we prove that they are asymptotically\nindependent. Given such asymptotic independencies, we propose (model-free)\ntesting procedures to boost the power against general alternatives and also\nretain the correct asymptotic size. Under the high-dimensional setting, we\nderive the closed-form limiting null distributions, and obtain their explicit\nrates of uniform convergence. We prove their consistent statistical powers\nagainst general alternatives. We demonstrate the performance of our proposed\ntest statistics in simulation studies. Our work provides very helpful insights\nto high-dimensional independence tests, and fills an important gap.\n", "versions": [{"version": "v1", "created": "Wed, 30 Dec 2015 00:30:19 GMT"}], "update_date": "2015-12-31", "authors_parsed": [["Li", "Danning", ""], ["Xue", "Lingzhou", ""]]}, {"id": "1512.08857", "submitter": "Matija Vidmar", "authors": "Matija Vidmar and Matja\\v{z} Omladi\\v{c}", "title": "Copulas for maxmin systems", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Under a mild condition we give closed-form expressions for copulas of systems\nthat consist of maxima and of minima of subvectors of a given random vector $X$\nwith continuous marginals. Said expressions appear explicit in the copula of\n$X$ and the mentioned condition is for example met when the law of $X$ admits a\nstrictly positive density with respect to Lebesgue measure. In the i.i.d. case\nthese \"maxmin\" copulae become universal and the conditions on their validity\ncan be dropped entirely. Our main motivation comes from applications to shock\nmodels that arise in multivariate survival theory. Another application is to\norder statistics copulas.\n", "versions": [{"version": "v1", "created": "Wed, 30 Dec 2015 06:07:43 GMT"}], "update_date": "2015-12-31", "authors_parsed": [["Vidmar", "Matija", ""], ["Omladi\u010d", "Matja\u017e", ""]]}, {"id": "1512.09016", "submitter": "Kayvan Sadeghi", "authors": "Kayvan Sadeghi and Nanny Wermuth", "title": "Pairwise Markov properties for regression graphs", "comments": "11 pages, 1 figure", "journal-ref": "STAT, 5, (2016), 286-294", "doi": "10.1002/sta4.122", "report-no": null, "categories": "math.ST stat.OT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With a sequence of regressions, one may generate joint probability\ndistributions. One starts with a joint, marginal distribution of context\nvariables having possibly a concentration graph structure and continues with an\nordered sequence of conditional distributions, named regressions in joint\nresponses. The involved random variables may be discrete, continuous or of both\ntypes. Such a generating process specifies for each response a conditioning set\nwhich contains just its regressor variables and it leads to at least one valid\nordering of all nodes in the corresponding regression graph which has three\ntypes of edge; one for undirected dependences among context variables, another\nfor undirected dependences among joint responses and one for any directed\ndependence of a response on a regressor variable. For this regression graph,\nthere are several definitions of pairwise Markov properties, where each\ninterprets the conditional independence associated with a missing edge in the\ngraph in a different way. We explain how these properties arise, prove their\nequivalence for compositional graphoids and point at the equivalence of each\none of them to the global Markov property.\n", "versions": [{"version": "v1", "created": "Wed, 30 Dec 2015 17:05:31 GMT"}, {"version": "v2", "created": "Thu, 2 Feb 2017 14:55:25 GMT"}], "update_date": "2017-02-03", "authors_parsed": [["Sadeghi", "Kayvan", ""], ["Wermuth", "Nanny", ""]]}, {"id": "1512.09020", "submitter": "Peter Hoff", "authors": "Peter D. Hoff", "title": "Limitations on detecting row covariance in the presence of column\n  covariance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many inference techniques for multivariate data analysis assume that the rows\nof the data matrix are realizations of independent and identically distributed\nrandom vectors. Such an assumption will be met, for example, if the rows of the\ndata matrix are multivariate measurements on a set of independently sampled\nunits. In the absence of an independent random sample, a relevant question is\nwhether or not a statistical model that assumes such row exchangeability is\nplausible. One method for assessing this plausibility is a statistical test of\nrow covariation. Maintenance of a constant type I error rate regardless of the\ncolumn covariance or matrix mean can be accomplished with a test that is\ninvariant under an appropriate group of transformations. In the context of a\nclass of elliptically contoured matrix regression models (such as matrix normal\nmodels), I show that there are no non-trivial invariant tests if the number of\nrows is not sufficiently larger than the number of columns. Furthermore, I show\nthat even if the number of rows is large, there are no non-trivial invariant\ntests that have power to detect arbitrary row covariance in the presence of\narbitrary column covariance. However, we can construct biased tests that have\npower to detect certain types of row covariance that may be encountered in\npractice.\n", "versions": [{"version": "v1", "created": "Wed, 30 Dec 2015 17:12:35 GMT"}], "update_date": "2015-12-31", "authors_parsed": [["Hoff", "Peter D.", ""]]}, {"id": "1512.09193", "submitter": "Iuliana Teodorescu", "authors": "Iuliana Teodorescu, Razvan Teodorescu, Pranav Warman", "title": "Efficient algorithms for topological inference on random graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, we investigate the problem of classifying, characterizing, and\ndesigning efficient algorithms for hard inference problems on planar graphs, in\nthe limit of infinite size. The problem is considered hard if, for a\ndeterministic graph, it belongs to the NP class of computational complexity. A\ntypical example rich in applications is that of connectivity loss in evacuation\nmodels for natural hazards management (e.g. coastal floods, hurricanes).\nAlgorithmically, this model reduces to solving a min-cut (or max-flow) problem,\nwith is known to be intractable. The current work covers several\ngeneralizations: posing the same problem for non-directed networks subject to\nrandom fluctuations (specifically, random graphs from the Erd\\\"os-R\\'enyi\nclass); finding efficient convex classifiers for the associated decision\nproblem (deciding whether the graph had become disconnected or not); and the\nrole played by choice of topology (on the space of random graphs) in designing\nefficient, convex approximation algorithms (in the infinite-size limit of the\ngraph).\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2015 01:27:54 GMT"}], "update_date": "2016-01-01", "authors_parsed": [["Teodorescu", "Iuliana", ""], ["Teodorescu", "Razvan", ""], ["Warman", "Pranav", ""]]}, {"id": "1512.09226", "submitter": "Guang Cheng", "authors": "Zuofeng Shang and Guang Cheng", "title": "Computational Limits of A Distributed Algorithm For Smoothing Spline", "comments": "To Appear in Journal of Machine Learning Research", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we explore statistical versus computational trade-off to\naddress a basic question in the application of a distributed algorithm: what is\nthe minimal computational cost in obtaining statistical optimality? In\nsmoothing spline setup, we observe a phase transition phenomenon for the number\nof deployed machines that ends up being a simple proxy for computing cost.\nSpecifically, a sharp upper bound for the number of machines is established:\nwhen the number is below this bound, statistical optimality (in terms of\nnonparametric estimation or testing) is achievable; otherwise, statistical\noptimality becomes impossible. These sharp bounds partly capture intrinsic\ncomputational limits of the distributed algorithm considered in this paper, and\nturn out to be fully determined by the smoothness of the regression function.\nAs a side remark, we argue that sample splitting may be viewed as an\nalternative form of regularization, playing a similar role as smoothing\nparameter.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2015 06:32:55 GMT"}, {"version": "v2", "created": "Fri, 21 Jul 2017 18:26:07 GMT"}], "update_date": "2017-07-25", "authors_parsed": [["Shang", "Zuofeng", ""], ["Cheng", "Guang", ""]]}]