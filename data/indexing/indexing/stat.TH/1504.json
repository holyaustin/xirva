[{"id": "1504.00002", "submitter": "Trisha Maitra Mrs", "authors": "Trisha Maitra and Sourabh Bhattacharya", "title": "Asymptotic Theory of Bayes Factor in Stochastic Differential Equations:\n  Part II", "comments": "An updated version", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of model selection in the context of a system of stochastic\ndifferential equations (SDEs) has not been touched upon in the literature.\nIndeed, properties of Bayes factors have not been studied even in single SDE\nbased model comparison problems. In this article, we first develop an\nasymptotic theory of Bayes factors when two SDEs are compared, assuming the\ntime domain expands. Using this we then develop an asymptotic theory of Bayes\nfactors when systems of SDEs are compared, assuming that the number of\nequations in each system, as well as the time domain, increase indefinitely.\nOur asymptotic theory covers situations when the observed processes associated\nwith the SDEs are independently and identically distributed (iid), as well as\nwhen they are independently but not identically distributed (non-iid). Quite\nimportantly, we allow inclusion of available time-dependent covariate\ninformation into each SDE through a multiplicative factor of the drift function\nin a random effects set-up; different initial values for the SDEs are also\npermitted. Thus, our general model-selection framework includes simultaneously\nthe variable selection problem associated with time-varying covariates, as well\nas choice of the part of the drift function free of covariates. As we show, the\nBayes factor is inconsistent for comparing individual SDEs, in the sense that\nthe log-Bayes factor converges only in expectation, while the relevant variance\ndoes not converge to zero. Nevertheless, it has been possible to exploit this\nresult to establish almost sure exponential convergence of the Bayes factor\nwhen, in addition, the number of individuals are also allowed to increase\nindefinitely. We carry out simulated and real data analyses to demonstrate that\nBayes factor is a suitable candidate for covariate selection in our SDE models\neven in non-asymptotic situations.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2015 11:52:29 GMT"}, {"version": "v2", "created": "Wed, 22 Jul 2015 10:51:08 GMT"}, {"version": "v3", "created": "Wed, 23 Sep 2015 09:25:55 GMT"}, {"version": "v4", "created": "Wed, 11 May 2016 09:00:04 GMT"}, {"version": "v5", "created": "Tue, 17 Apr 2018 12:32:28 GMT"}], "update_date": "2018-04-18", "authors_parsed": [["Maitra", "Trisha", ""], ["Bhattacharya", "Sourabh", ""]]}, {"id": "1504.00461", "submitter": "Xin-Bing Kong", "authors": "Xin-Bing Kong, Zhi Liu, Bing-Yi Jing", "title": "Testing for pure-jump processes for high-frequency data", "comments": "Published at http://dx.doi.org/10.1214/14-AOS1298 in the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2015, Vol. 43, No. 2, 847-877", "doi": "10.1214/14-AOS1298", "report-no": "IMS-AOS-AOS1298", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pure-jump processes have been increasingly popular in modeling high-frequency\nfinancial data, partially due to their versatility and flexibility. In the\nmeantime, several statistical tests have been proposed in the literature to\ncheck the validity of using pure-jump models. However, these tests suffer from\nseveral drawbacks, such as requiring rather stringent conditions and having\nslow rates of convergence. In this paper, we propose a different test to check\nwhether the underlying process of high-frequency data can be modeled by a\npure-jump process. The new test is based on the realized characteristic\nfunction, and enjoys a much faster convergence rate of order $O(n^{1/2})$\n(where $n$ is the sample size) versus the usual $o(n^{1/4})$ available for\nexisting tests; it is applicable much more generally than previous tests; for\nexample, it is robust to jumps of infinite variation and flexible modeling of\nthe diffusion component. Simulation studies justify our findings and the test\nis also applied to some real high-frequency financial data.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2015 07:34:48 GMT"}], "update_date": "2015-04-03", "authors_parsed": [["Kong", "Xin-Bing", ""], ["Liu", "Zhi", ""], ["Jing", "Bing-Yi", ""]]}, {"id": "1504.00465", "submitter": "Sami Umut Can", "authors": "Sami Umut Can, John H. J. Einmahl, Estate V. Khmaladze, Roger J. A.\n  Laeven", "title": "Asymptotically distribution-free goodness-of-fit testing for tail\n  copulas", "comments": "Published at http://dx.doi.org/10.1214/14-AOS1304 in the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2015, Vol. 43, No. 2, 878-902", "doi": "10.1214/14-AOS1304", "report-no": "IMS-AOS-AOS1304", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $(X_1,Y_1),\\ldots,(X_n,Y_n)$ be an i.i.d. sample from a bivariate\ndistribution function that lies in the max-domain of attraction of an extreme\nvalue distribution. The asymptotic joint distribution of the standardized\ncomponent-wise maxima $\\bigvee_{i=1}^nX_i$ and $\\bigvee_{i=1}^nY_i$ is then\ncharacterized by the marginal extreme value indices and the tail copula $R$. We\npropose a procedure for constructing asymptotically distribution-free\ngoodness-of-fit tests for the tail copula $R$. The procedure is based on a\ntransformation of a suitable empirical process derived from a semi-parametric\nestimator of $R$. The transformed empirical process converges weakly to a\nstandard Wiener process, paving the way for a multitude of asymptotically\ndistribution-free goodness-of-fit tests. We also extend our results to the\n$m$-variate ($m>2$) case. In a simulation study we show that the limit theorems\nprovide good approximations for finite samples and that tests based on the\ntransformed empirical process have high power.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2015 07:56:51 GMT"}], "update_date": "2015-04-03", "authors_parsed": [["Can", "Sami Umut", ""], ["Einmahl", "John H. J.", ""], ["Khmaladze", "Estate V.", ""], ["Laeven", "Roger J. A.", ""]]}, {"id": "1504.00476", "submitter": "Zacharie Naulet", "authors": "Zacharie Naulet and Eric Barat", "title": "Some aspects of symmetric Gamma process mixtures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we present some specific aspects of symmetric Gamma process\nmixtures for use in regression models. We propose a new Gibbs sampler for\nsimulating the posterior and we establish adaptive posterior rates of\nconvergence related to the Gaussian mean regression problem.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2015 08:48:47 GMT"}, {"version": "v2", "created": "Tue, 14 Jul 2015 12:25:58 GMT"}, {"version": "v3", "created": "Mon, 28 Sep 2015 20:12:16 GMT"}, {"version": "v4", "created": "Thu, 28 Jul 2016 08:25:00 GMT"}], "update_date": "2016-07-29", "authors_parsed": [["Naulet", "Zacharie", ""], ["Barat", "Eric", ""]]}, {"id": "1504.00490", "submitter": "Anne-Laure Foug\\`{e}res", "authors": "Anne-Laure Foug\\`eres, Laurens de Haan, C\\'ecile Mercadier", "title": "Bias correction in multivariate extremes", "comments": "Published at http://dx.doi.org/10.1214/14-AOS1305 in the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2015, Vol. 43, No. 2, 903-934", "doi": "10.1214/14-AOS1305", "report-no": "IMS-AOS-AOS1305", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The estimation of the extremal dependence structure is spoiled by the impact\nof the bias, which increases with the number of observations used for the\nestimation. Already known in the univariate setting, the bias correction\nprocedure is studied in this paper under the multivariate framework. New\nfamilies of estimators of the stable tail dependence function are obtained.\nThey are asymptotically unbiased versions of the empirical estimator introduced\nby Huang [Statistics of bivariate extremes (1992) Erasmus Univ.]. Since the new\nestimators have a regular behavior with respect to the number of observations,\nit is possible to deduce aggregated versions so that the choice of the\nthreshold is substantially simplified. An extensive simulation study is\nprovided as well as an application on real data.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2015 09:42:14 GMT"}], "update_date": "2015-04-03", "authors_parsed": [["Foug\u00e8res", "Anne-Laure", ""], ["de Haan", "Laurens", ""], ["Mercadier", "C\u00e9cile", ""]]}, {"id": "1504.00534", "submitter": "Ruth Heller", "authors": "Marina Bogomolov and Ruth Heller", "title": "Assessing replicability of findings across two studies of multiple\n  features", "comments": null, "journal-ref": "Biometrika (2018)", "doi": "10.1093/biomet/asy029", "report-no": null, "categories": "stat.ME math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Replicability analysis aims to identify the findings that replicated across\nindependent studies that examine the same features. We provide powerful novel\nreplicability analysis procedures for two studies for FWER and for FDR control\non the replicability claims. The suggested procedures first select the\npromising features from each study solely based on that study, and then test\nfor replicability only the features that were selected in both studies. We\nincorporate the plug-in estimates of the fraction of null hypotheses in one\nstudy among the selected hypotheses by the other study. Since the fraction of\nnulls in one study among the selected features from the other study is\ntypically small, the power gain can be remarkable. We provide theoretical\nguarantees for the control of the appropriate error rates, as well as\nsimulations that demonstrate the excellent power properties of the suggested\nprocedures. We demonstrate the usefulness of our procedures on real data\nexamples from two application fields: behavioural genetics and microarray\nstudies.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2015 13:04:36 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["Bogomolov", "Marina", ""], ["Heller", "Ruth", ""]]}, {"id": "1504.00595", "submitter": "Claudio Durastanti Dr.", "authors": "Claudio Durastanti", "title": "Adaptive Density Estimation on the Circle by Nearly-Tight Frames", "comments": "30 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work is concerned with the study of asymptotic properties of\nnonparametric density estimates in the framework of circular data. The\nestimation procedure here applied is based on wavelet thresholding methods: the\nwavelets used are the so-called Mexican needlets, which describe a nearly-tight\nframe on the circle. We study the asymptotic behaviour of the $L^{2}$-risk\nfunction for these estimates, in particular its adaptivity, proving that its\nrate of convergence is nearly optimal.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2015 15:49:59 GMT"}, {"version": "v2", "created": "Tue, 15 Mar 2016 10:33:24 GMT"}], "update_date": "2016-03-16", "authors_parsed": [["Durastanti", "Claudio", ""]]}, {"id": "1504.00600", "submitter": "Ashkan Panahi", "authors": "Ashkan Panahi and Mats Viberg", "title": "A Novel Sparsity-Based Approach to Recursive Estimation of Dynamic\n  Parameter Sets", "comments": "The paper is to be submitted to the IEEE Transactions on Signal\n  Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of estimating a variable number of parameters with a\ndynamic nature. A familiar example is finding the position of moving targets\nusing sensor array observations. The problem is challenging in cases where\neither the observations are not reliable or the parameters evolve rapidly.\nInspired by the sparsity based techniques, we introduce a novel Bayesian model\nfor the problems of interest and study its associated recursive Bayesian\nfilter. We propose an algorithm approximating the Bayesian filter, maintaining\na reasonable amount of calculations. We compare by numerical evaluation the\nresulting technique to state-of-the-art algorithms in different scenarios. In a\nscenario with a low SNR, the proposed method outperforms other complex\ntechniques.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2015 16:05:12 GMT"}], "update_date": "2015-04-03", "authors_parsed": [["Panahi", "Ashkan", ""], ["Viberg", "Mats", ""]]}, {"id": "1504.00606", "submitter": "Claudio Durastanti", "authors": "Claudio Durastanti", "title": "Quantitative central limit theorems for Mexican needlet coefficients on\n  circular Poisson fields", "comments": "26 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of this paper is to establish rates of convergence to Gaussianity for\nwavelet coefficients on circular Poisson random fields. This result is\nestablished by using the Stein-Malliavin techniques introduced by Peccati and\nZheng (2011) and the concentration properties of so-called Mexican needlets on\nthe circle\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2015 16:17:47 GMT"}], "update_date": "2015-04-03", "authors_parsed": [["Durastanti", "Claudio", ""]]}, {"id": "1504.00828", "submitter": "Sergio Bacallado", "authors": "Sergio Bacallado, Stefano Favaro, Lorenzo Trippa", "title": "Looking-backward probabilities for Gibbs-type exchangeable random\n  partitions", "comments": "Published at http://dx.doi.org/10.3150/13-BEJ559 in the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2015, Vol. 21, No. 1, 1-37", "doi": "10.3150/13-BEJ559", "report-no": "IMS-BEJ-BEJ559", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gibbs-type random probability measures and the exchangeable random partitions\nthey induce represent the subject of a rich and active literature. They provide\na probabilistic framework for a wide range of theoretical and applied problems\nthat are typically referred to as species sampling problems. In this paper, we\nconsider the class of looking-backward species sampling problems introduced in\nLijoi et al. (Ann. Appl. Probab. 18 (2008) 1519-1547) in Bayesian\nnonparametrics. Specifically, given some information on the random partition\ninduced by an initial sample from a Gibbs-type random probability measure, we\nstudy the conditional distributions of statistics related to the old species,\nnamely those species detected in the initial sample and possibly re-observed in\nan additional sample. The proposed results contribute to the analysis of\nconditional properties of Gibbs-type exchangeable random partitions, so far\nfocused mainly on statistics related to those species generated by the\nadditional sample and not already detected in the initial sample.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2015 12:17:06 GMT"}], "update_date": "2015-04-06", "authors_parsed": [["Bacallado", "Sergio", ""], ["Favaro", "Stefano", ""], ["Trippa", "Lorenzo", ""]]}, {"id": "1504.00865", "submitter": "Stephane Chretien", "authors": "Stephane Chretien and Franck Corset", "title": "A lower bound on the expected optimal value of certain random linear\n  programs and application to shortest paths and reliability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper studies the expectation of the inspection time in complex aging\nsystems. Under reasonable assumptions, this problem is reduced to studying the\nexpectation of the length of the shortest path in the directed degradation\ngraph of the systems where the parameters are given by a pool of experts. The\nexpectation itself being sometimes out of reach, in closed form or even through\nMonte Carlo simulations in the case of large systems, we propose an easily\ncomputable lower bound. The proposed bound applies to a rather general class of\nlinear programs with random nonnegative costs and is directly inspired from the\nupper bound of Dyer, Frieze and McDiarmid [Math.Programming {\\bf 35} (1986),\nno.1,3--16].\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2015 15:37:56 GMT"}, {"version": "v2", "created": "Mon, 15 Feb 2016 16:54:24 GMT"}], "update_date": "2016-02-16", "authors_parsed": [["Chretien", "Stephane", ""], ["Corset", "Franck", ""]]}, {"id": "1504.01062", "submitter": "Wilson de Oliveira PhD", "authors": "C\\'icero Carlos Ramos de Brito, Leandro Chaves R\\^ego and Wilson Rosa\n  de Oliveira", "title": "Method for Generating Distributions and Classes of Probability\n  Distributions: The Univariate Case", "comments": "50 pages, submitted for journal publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present a method to generate probability distributions and\nclasses of probability distributions, which broadens a process of probability\ndistribution construction. In this method, distribution classes are built from\npre-defined monotonic functions and from known distributions. With the use of\nthis method, we can obtain different classes of probability distributions\ndescribed in literature. Beside these results, we could obtain results on the\nsupport and nature of the generated distributions.\n", "versions": [{"version": "v1", "created": "Sat, 4 Apr 2015 22:26:42 GMT"}], "update_date": "2015-04-07", "authors_parsed": [["de Brito", "C\u00edcero Carlos Ramos", ""], ["R\u00eago", "Leandro Chaves", ""], ["de Oliveira", "Wilson Rosa", ""]]}, {"id": "1504.01081", "submitter": "Ali Pezeshki", "authors": "Pooria Pakrooh, Ali Pezeshki, Louis L. Scharf, Douglas Cochran, and\n  Stephen D. Howard", "title": "Analysis of Fisher Information and the Cram\\'{e}r-Rao Bound for\n  Nonlinear Parameter Estimation after Compressed Sensing", "comments": "12 pages, 3figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we analyze the impact of compressed sensing with complex\nrandom matrices on Fisher information and the Cram\\'{e}r-Rao Bound (CRB) for\nestimating unknown parameters in the mean value function of a complex\nmultivariate normal distribution. We consider the class of random compression\nmatrices whose distribution is right-orthogonally invariant. The compression\nmatrix whose elements are i.i.d. standard normal random variables is one such\nmatrix. We show that for all such compression matrices, the Fisher information\nmatrix has a complex matrix beta distribution. We also derive the distribution\nof CRB. These distributions can be used to quantify the loss in CRB as a\nfunction of the Fisher information of the non-compressed data. In our numerical\nexamples, we consider a direction of arrival estimation problem and discuss the\nuse of these distributions as guidelines for choosing compression ratios based\non the resulting loss in CRB.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2015 04:24:31 GMT"}], "update_date": "2015-04-07", "authors_parsed": [["Pakrooh", "Pooria", ""], ["Pezeshki", "Ali", ""], ["Scharf", "Louis L.", ""], ["Cochran", "Douglas", ""], ["Howard", "Stephen D.", ""]]}, {"id": "1504.01227", "submitter": "Yihong Wu", "authors": "Yihong Wu and Pengkun Yang", "title": "Chebyshev polynomials, moment matching, and optimal estimation of the\n  unseen", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of estimating the support size of a discrete\ndistribution whose minimum non-zero mass is at least $ \\frac{1}{k}$. Under the\nindependent sampling model, we show that the sample complexity, i.e., the\nminimal sample size to achieve an additive error of $\\epsilon k$ with\nprobability at least 0.1 is within universal constant factors of $\n\\frac{k}{\\log k}\\log^2\\frac{1}{\\epsilon} $, which improves the state-of-the-art\nresult of $ \\frac{k}{\\epsilon^2 \\log k} $ in \\cite{VV13}. Similar\ncharacterization of the minimax risk is also obtained. Our procedure is a\nlinear estimator based on the Chebyshev polynomial and its\napproximation-theoretic properties, which can be evaluated in $O(n+\\log^2 k)$\ntime and attains the sample complexity within a factor of six asymptotically.\nThe superiority of the proposed estimator in terms of accuracy, computational\nefficiency and scalability is demonstrated in a variety of synthetic and real\ndatasets.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2015 07:42:31 GMT"}, {"version": "v2", "created": "Mon, 12 Dec 2016 05:29:58 GMT"}], "update_date": "2016-12-13", "authors_parsed": [["Wu", "Yihong", ""], ["Yang", "Pengkun", ""]]}, {"id": "1504.01281", "submitter": "Santosh Kumar", "authors": "Santosh Kumar", "title": "Random matrix ensembles involving Gaussian Wigner and Wishart matrices,\n  and biorthogonal structure", "comments": "Published version", "journal-ref": "Phys. Rev. E 92, 032903 (2015)", "doi": "10.1103/PhysRevE.92.032903", "report-no": null, "categories": "math-ph math.MP math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider four nontrivial ensembles involving Gaussian Wigner and Wishart\nmatrices. These are relevant to problems ranging from multiantenna\ncommunication to random supergravity. We derive the matrix probability density,\nas well as the eigenvalue densities for these ensembles. In all cases the joint\neigenvalue density exhibits a biorthogonal structure. A determinantal\nrepresentation, based on a generalization of Andr\\'{e}ief's integration\nformula, is used to compactly express the $r$-point correlation function of\neigenvalues. This representation circumvents the complications encountered in\nthe usual approaches, and the answer is obtained immediately by examining the\njoint density of eigenvalues. We validate our analytical results using Monte\nCarlo simulations.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2015 13:18:40 GMT"}, {"version": "v2", "created": "Wed, 13 May 2015 06:56:41 GMT"}, {"version": "v3", "created": "Tue, 15 Sep 2015 19:41:38 GMT"}], "update_date": "2015-09-16", "authors_parsed": [["Kumar", "Santosh", ""]]}, {"id": "1504.01291", "submitter": "Wilson de Oliveira PhD", "authors": "C\\'icero Carlos Ramos de Brito, Leandro Chaves R\\^ego and Wilson Rosa\n  de Oliveira", "title": "A New Class of Gamma distribution", "comments": "22 pages plus cover, 11 figures, submitted for journal publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new class of probability distributions generated from\nthe gamma distribution. For the new class proposed, we present several\nstatistical properties, such as the risk function, the density expansions,\nMoment-generating function, characteristic function, the moments of order m,\ncentral moments of order m, the log likelihood and its partial derivatives and\nalso entropy, kurtosis, symmetry and variance. These same properties are\ndetermined for a particular distribution within this new class that is used to\nillustrate the capability of the proposed new class through an application to a\nreal data set. The database presented in Choulakian and Stephens (2001) was\nused. Six models are compared and for the selection of these models were used\nthe Akaike Information Criterion (AIC), the Akaike Information Criterion\ncorrected (AICc), Bayesian Information Criterion (BIC), Hannan Quinn\nInformation Criterion (HQIC) and tests of Cramer-Von Mises and Anderson-Darling\nto assess the models fit. Finally, we present the conclusions from the analysis\nand comparison of the results obtained and the directions for future work.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2015 14:31:38 GMT"}], "update_date": "2015-04-07", "authors_parsed": [["de Brito", "C\u00edcero Carlos Ramos", ""], ["R\u00eago", "Leandro Chaves", ""], ["de Oliveira", "Wilson Rosa", ""]]}, {"id": "1504.01294", "submitter": "Tsvetan Asamov", "authors": "Tsvetan Asamov and Adi Ben-Israel", "title": "A Probabilistic $\\ell_1$ Method for Clustering High Dimensional Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG math.OC stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In general, the clustering problem is NP-hard, and global optimality cannot\nbe established for non-trivial instances. For high-dimensional data,\ndistance-based methods for clustering or classification face an additional\ndifficulty, the unreliability of distances in very high-dimensional spaces. We\npropose a distance-based iterative method for clustering data in very\nhigh-dimensional space, using the $\\ell_1$-metric that is less sensitive to\nhigh dimensionality than the Euclidean distance. For $K$ clusters in\n$\\mathbb{R}^n$, the problem decomposes to $K$ problems coupled by\nprobabilities, and an iteration reduces to finding $Kn$ weighted medians of\npoints on a line. The complexity of the algorithm is linear in the dimension of\nthe data space, and its performance was observed to improve significantly as\nthe dimension increases.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2015 14:49:13 GMT"}, {"version": "v2", "created": "Fri, 22 Apr 2016 21:58:42 GMT"}], "update_date": "2016-04-26", "authors_parsed": [["Asamov", "Tsvetan", ""], ["Ben-Israel", "Adi", ""]]}, {"id": "1504.01369", "submitter": "Yuxin Chen", "authors": "Yuxin Chen, Changho Suh, Andrea J. Goldsmith", "title": "Information Recovery from Pairwise Measurements", "comments": "This work has been presented in part in ISIT 2014\n  (http://arxiv.org/abs/1404.7105) and ISIT 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DM cs.LG math.IT math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is concerned with jointly recovering $n$ node-variables $\\left\\{\nx_{i}\\right\\}_{1\\leq i\\leq n}$ from a collection of pairwise difference\nmeasurements. Imagine we acquire a few observations taking the form of\n$x_{i}-x_{j}$; the observation pattern is represented by a measurement graph\n$\\mathcal{G}$ with an edge set $\\mathcal{E}$ such that $x_{i}-x_{j}$ is\nobserved if and only if $(i,j)\\in\\mathcal{E}$. To account for noisy\nmeasurements in a general manner, we model the data acquisition process by a\nset of channels with given input/output transition measures. Employing\ninformation-theoretic tools applied to channel decoding problems, we develop a\n\\emph{unified} framework to characterize the fundamental recovery criterion,\nwhich accommodates general graph structures, alphabet sizes, and channel\ntransition measures. In particular, our results isolate a family of\n\\emph{minimum} \\emph{channel divergence measures} to characterize the degree of\nmeasurement corruption, which together with the size of the minimum cut of\n$\\mathcal{G}$ dictates the feasibility of exact information recovery. For\nvarious homogeneous graphs, the recovery condition depends almost only on the\nedge sparsity of the measurement graph irrespective of other graphical metrics;\nalternatively, the minimum sample complexity required for these graphs scales\nlike \\[ \\text{minimum sample complexity }\\asymp\\frac{n\\log\nn}{\\mathsf{Hel}_{1/2}^{\\min}} \\] for certain information metric\n$\\mathsf{Hel}_{1/2}^{\\min}$ defined in the main text, as long as the alphabet\nsize is not super-polynomial in $n$. We apply our general theory to three\nconcrete applications, including the stochastic block model, the outlier model,\nand the haplotype assembly problem. Our theory leads to order-wise tight\nrecovery conditions for all these scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2015 19:47:01 GMT"}, {"version": "v2", "created": "Mon, 29 Jun 2015 14:07:04 GMT"}, {"version": "v3", "created": "Wed, 15 Jul 2015 05:37:56 GMT"}, {"version": "v4", "created": "Fri, 6 May 2016 03:18:52 GMT"}], "update_date": "2016-05-09", "authors_parsed": [["Chen", "Yuxin", ""], ["Suh", "Changho", ""], ["Goldsmith", "Andrea J.", ""]]}, {"id": "1504.01612", "submitter": "Pavel Mozgunov", "authors": "Mark Kelbert and Pavel Mozgunov", "title": "Asymptotic behaviour of weighted differential entropies in a Bayesian\n  problem", "comments": "33 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a Bayesian problem of estimating of probability of success in a\nseries of conditionally independent trials with binary outcomes. We study the\nasymptotic behaviour of differential entropy for posterior probability density\nfunction conditional on $x$ successes after $n$ conditionally independent\ntrials, when $n \\to \\infty$. It is shown that after an appropriate\nnormalization in cases $x \\sim n$ and $x$ $\\sim n^\\beta$ ($0<\\beta<1$) limiting\ndistribution is Gaussian and the differential entropy of standardized RV\nconverges to differential entropy of standard Gaussian random variable. When\n$x$ or $n-x$ is a constant the limiting distribution in not Gaussian, but still\nthe asymptotic of differential entropy can be found explicitly.\n  Then suppose that one is interested to know whether the coin is fair or not\nand for large $n$ is interested in the true frequency. To do so the concept of\nweighted differential entropy introduced in \\cite{Belis1968} is used when the\nfrequency $\\gamma$ is necessary to emphasize. It was found that the weight in\nsuggested form does not change the asymptotic form of Shannon, Renyi, Tsallis\nand Fisher entropies, but change the constants. The main term in weighted\nFisher Information is changed by some constant which depend on distance between\nthe true frequency and the value we want to emphasize.\n  In third part we derived the weighted versions of Rao-Cram\\'er, Bhattacharyya\nand Kullback inequalities. This result is applied to the Bayesian problem\ndescribed above. The asymptotic forms of these inequalities are obtained for a\nparticular class of weight functions.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2015 14:24:08 GMT"}, {"version": "v2", "created": "Wed, 22 Apr 2015 12:27:10 GMT"}, {"version": "v3", "created": "Sun, 7 Jun 2015 18:29:06 GMT"}, {"version": "v4", "created": "Wed, 29 Jul 2015 14:37:00 GMT"}], "update_date": "2015-07-30", "authors_parsed": [["Kelbert", "Mark", ""], ["Mozgunov", "Pavel", ""]]}, {"id": "1504.01702", "submitter": "Kevin Bleakley", "authors": "G\\'erard Biau (LPMA, LSTA), Kevin Bleakley (SELECT), David Mason", "title": "Long signal change-point detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The detection of change-points in a spatially or time ordered data sequence\nis an important problem in many fields such as genetics and finance. We derive\nthe asymptotic distribution of a statistic recently suggested for detecting\nchange-points. Simulation of its estimated limit distribution leads to a new\nand computationally efficient change-point detection algorithm, which can be\nused on very long signals. We assess the algorithm via simulations and on\npreviously benchmarked real-world data sets.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2015 18:35:36 GMT"}, {"version": "v2", "created": "Wed, 30 Sep 2015 07:59:43 GMT"}], "update_date": "2015-10-01", "authors_parsed": [["Biau", "G\u00e9rard", "", "LPMA, LSTA"], ["Bleakley", "Kevin", "", "SELECT"], ["Mason", "David", ""]]}, {"id": "1504.01823", "submitter": "Anru Zhang", "authors": "Tianxi Cai, T. Tony Cai, Anru Zhang", "title": "Structured Matrix Completion with Applications to Genomic Data\n  Integration", "comments": "Accepted for publication in Journal of the American Statistical\n  Association", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Matrix completion has attracted significant recent attention in many fields\nincluding statistics, applied mathematics and electrical engineering. Current\nliterature on matrix completion focuses primarily on independent sampling\nmodels under which the individual observed entries are sampled independently.\nMotivated by applications in genomic data integration, we propose a new\nframework of structured matrix completion (SMC) to treat structured missingness\nby design. Specifically, our proposed method aims at efficient matrix recovery\nwhen a subset of the rows and columns of an approximately low-rank matrix are\nobserved. We provide theoretical justification for the proposed SMC method and\nderive lower bound for the estimation errors, which together establish the\noptimal rate of recovery over certain classes of approximately low-rank\nmatrices. Simulation studies show that the method performs well in finite\nsample under a variety of configurations. The method is applied to integrate\nseveral ovarian cancer genomic studies with different extent of genomic\nmeasurements, which enables us to construct more accurate prediction rules for\novarian cancer survival.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2015 04:14:07 GMT"}], "update_date": "2015-04-09", "authors_parsed": [["Cai", "Tianxi", ""], ["Cai", "T. Tony", ""], ["Zhang", "Anru", ""]]}, {"id": "1504.01869", "submitter": "Yury Kutoyants", "authors": "Yury A. Kutoyants", "title": "On Multi-Step MLE-Process for Ergodic Diffusion", "comments": "22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new method of the construction of the asymptotically efficient\nestimator-processes asymptotically equivalent to the MLE and the same time much\nmore easy to calculate. We suppose that the observed process is ergodic\ndiffusion and that there is a learning time interval of the length negligeable\nwith respect to the whole time of observations. The preliminary estimator\nobtained after the learning time is then used in the construction of one-step\nand two-step MLE processes. We discuss the possibility of the applications of\nthe proposed estimation procedure to several other observations models.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2015 09:03:20 GMT"}], "update_date": "2015-04-09", "authors_parsed": [["Kutoyants", "Yury A.", ""]]}, {"id": "1504.02191", "submitter": "Shahar Mendelson", "authors": "Shahar Mendelson", "title": "`local' vs. `global' parameters -- breaking the gaussian complexity\n  barrier", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that if $F$ is a convex class of functions that is $L$-subgaussian,\nthe error rate of learning problems generated by independent noise is\nequivalent to a fixed point determined by `local' covering estimates of the\nclass, rather than by the gaussian averages. To that end, we establish new\nsharp upper and lower estimates on the error rate for such problems.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2015 04:54:29 GMT"}], "update_date": "2015-04-10", "authors_parsed": [["Mendelson", "Shahar", ""]]}, {"id": "1504.02267", "submitter": "Antoine Godichon", "authors": "Antoine Godichon", "title": "Estimating the geometric median in Hilbert spaces with stochastic\n  gradient algorithms: $L^{p}$ and almost sure rates of convergence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The geometric median, also called $L^{1}$-median, is often used in robust\nstatistics. Moreover, it is more and more usual to deal with large samples\ntaking values in high dimensional spaces. In this context, a fast recursive\nestimator has been introduced by Cardot, Cenac and Zitt. This work aims at\nstudying more precisely the asymptotic behavior of the estimators of the\ngeometric median based on such non linear stochastic gradient algorithms. The\n$L^{p}$ rates of convergence as well as almost sure rates of convergence of\nthese estimators are derived in general separable Hilbert spaces. Moreover, the\noptimal rate of convergence in quadratic mean of the averaged algorithm is also\ngiven.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2015 11:43:44 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2015 08:44:10 GMT"}], "update_date": "2015-06-17", "authors_parsed": [["Godichon", "Antoine", ""]]}, {"id": "1504.02553", "submitter": "Wolf-Dieter Richter", "authors": "Wolf-Dieter Richter", "title": "Skewness-kurtosis adjusted confidence estimators and significance tests", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  First and second kind modifications of usual confidence intervals for\nestimating the expectation and of usual local alternative parameter choices are\nintroduced in a way such that the asymptotic behavior of the true non-covering\nprobabilities and the covering probabilities under the modified local non-true\nparameter assumption can be asymptotically exactly controlled. The orders of\nconvergence to zero of both types of probabilities are assumed to be suitably\nbounded below according to an Osipov-type condition and the sample distribution\nis assumed to satisfy a corresponding tail condition due to Linnik. Analogous\nconsiderations are presented for the power function when testing a hypothesis\nconcerning the expectation both under the assumption of a true hypothesis as\nwell as under a modified local alternative. Applications are given for\nexponential families.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2015 05:24:11 GMT"}], "update_date": "2015-04-13", "authors_parsed": [["Richter", "Wolf-Dieter", ""]]}, {"id": "1504.02654", "submitter": "Lixing Zhu", "authors": "Tao Wang, Peirong Xu, Lixing Zhu", "title": "Variable selection and estimation for semi-parametric multiple-index\n  models", "comments": "Published at http://dx.doi.org/10.3150/13-BEJ566 in the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2015, Vol. 21, No. 1, 242-275", "doi": "10.3150/13-BEJ566", "report-no": "IMS-BEJ-BEJ566", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel method to select significant variables and\nestimate the corresponding coefficients in multiple-index models with a group\nstructure. All existing approaches for single-index models cannot be extended\ndirectly to handle this issue with several indices. This method integrates a\npopularly used shrinkage penalty such as LASSO with the group-wise minimum\naverage variance estimation. It is capable of simultaneous dimension reduction\nand variable selection, while incorporating the group structure in predictors.\nInterestingly, the proposed estimator with the LASSO penalty then behaves like\nan estimator with an adaptive LASSO penalty. The estimator achieves consistency\nof variable selection without sacrificing the root-$n$ consistency of basis\nestimation. Simulation studies and a real-data example illustrate the\neffectiveness and efficiency of the new method.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2015 12:22:56 GMT"}], "update_date": "2015-04-13", "authors_parsed": [["Wang", "Tao", ""], ["Xu", "Peirong", ""], ["Zhu", "Lixing", ""]]}, {"id": "1504.02658", "submitter": "Andrzej Ruszczy\\'nski", "authors": "Darinka Dentcheva, Spiridon Penev, Andrzej Ruszczynski", "title": "Statistical Estimation of Composite Risk Functionals and Risk\n  Optimization Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the statistical estimation of composite functionals which may be\nnonlinear in the probability measure. Our study is motivated by the need to\nestimate coherent measures of risk, which become increasingly popular in\nfinance, insurance, and other areas associated with optimization under\nuncertainty and risk. We establish central limit formulae for composite risk\nfunctionals. Furthermore, we discuss the asymptotic behavior of optimization\nproblems whose objectives are composite risk functionals and we establish a\ncentral limit formula of their optimal values when an estimator of the risk\nfunctional is used. While the mathematical structures accommodate commonly used\ncoherent measures of risk, they have more general character, which may be of\nindependent interest.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2015 12:30:45 GMT"}], "update_date": "2015-04-13", "authors_parsed": [["Dentcheva", "Darinka", ""], ["Penev", "Spiridon", ""], ["Ruszczynski", "Andrzej", ""]]}, {"id": "1504.02689", "submitter": "James O. Berger", "authors": "James O. Berger, Jose M. Bernardo, Dongchu Sun", "title": "Overall Objective Priors", "comments": "Published at http://dx.doi.org/10.1214/14-BA915 in the Bayesian\n  Analysis (http://projecteuclid.org/euclid.ba) by the International Society of\n  Bayesian Analysis (http://bayesian.org/)", "journal-ref": "Bayesian Analysis 2015, Vol. 10, No. 1, 189-221", "doi": "10.1214/14-BA915", "report-no": "VTeX-BA-BA915", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In multi-parameter models, reference priors typically depend on the parameter\nor quantity of interest, and it is well known that this is necessary to produce\nobjective posterior distributions with optimal properties. There are, however,\nmany situations where one is simultaneously interested in all the parameters of\nthe model or, more realistically, in functions of them that include aspects\nsuch as prediction, and it would then be useful to have a single objective\nprior that could safely be used to produce reasonable posterior inferences for\nall the quantities of interest. In this paper, we consider three methods for\nselecting a single objective prior and study, in a variety of problems\nincluding the multinomial problem, whether or not the resulting prior is a\nreasonable overall prior.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2015 14:15:02 GMT"}], "update_date": "2015-04-13", "authors_parsed": [["Berger", "James O.", ""], ["Bernardo", "Jose M.", ""], ["Sun", "Dongchu", ""]]}, {"id": "1504.02693", "submitter": "Henryk Z\\\"ahle", "authors": "Alexandra Lauer and Henryk Z\\\"ahle", "title": "Nonparametric estimation of risk measures of collective risks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider two nonparametric estimators for the risk measure of the sum of\n$n$ i.i.d. individual insurance risks where the number of historical single\nclaims that are used for the statistical estimation is of order $n$. This\nframework matches the situation that nonlife insurance companies are faced with\nwithin in the scope of premium calculation. Indeed, the risk measure of the\naggregate risk divided by $n$ can be seen as a suitable premium for each of the\nindividual risks. For both estimators divided by $n$ we derive a sort of\nMarcinkiewicz--Zygmund strong law as well as a weak limit theorem. The behavior\nof the estimators for small to moderate $n$ is studied by means of Monte-Carlo\nsimulations.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2015 14:44:11 GMT"}, {"version": "v2", "created": "Wed, 16 Sep 2015 07:35:49 GMT"}], "update_date": "2015-09-17", "authors_parsed": [["Lauer", "Alexandra", ""], ["Z\u00e4hle", "Henryk", ""]]}, {"id": "1504.02852", "submitter": "Antoine Godichon-Baggioni", "authors": "Herv\\'e Cardot and Antoine Godichon-Baggioni", "title": "Fast Estimation of the Median Covariation Matrix with Application to\n  Online Robust Principal Components Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The geometric median covariation matrix is a robust multivariate indicator of\ndispersion which can be extended without any difficulty to functional data. We\ndefine estimators, based on recursive algorithms, that can be simply updated at\neach new observation and are able to deal rapidly with large samples of high\ndimensional data without being obliged to store all the data in memory.\nAsymptotic convergence properties of the recursive algorithms are studied under\nweak conditions. The computation of the principal components can also be\nperformed online and this approach can be useful for online outlier detection.\nA simulation study clearly shows that this robust indicator is a competitive\nalternative to minimum covariance determinant when the dimension of the data is\nsmall and robust principal components analysis based on projection pursuit and\nspherical projections for high dimension data. An illustration on a large\nsample and high dimensional dataset consisting of individual TV audiences\nmeasured at a minute scale over a period of 24 hours confirms the interest of\nconsidering the robust principal components analysis based on the median\ncovariation matrix. All studied algorithms are available in the R package\nGmedian on CRAN.\n", "versions": [{"version": "v1", "created": "Sat, 11 Apr 2015 08:52:13 GMT"}, {"version": "v2", "created": "Fri, 24 Apr 2015 07:57:21 GMT"}, {"version": "v3", "created": "Tue, 20 Oct 2015 13:55:06 GMT"}, {"version": "v4", "created": "Thu, 22 Oct 2015 08:44:41 GMT"}, {"version": "v5", "created": "Sat, 9 Jul 2016 08:34:12 GMT"}], "update_date": "2016-07-12", "authors_parsed": [["Cardot", "Herv\u00e9", ""], ["Godichon-Baggioni", "Antoine", ""]]}, {"id": "1504.03009", "submitter": "Karim Lounici", "authors": "Vladimir Koltchinskii, Karim Lounici, Alexander B. Tsybakov", "title": "Estimation of Low-Rank Covariance Function", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of estimating a low rank covariance function $K(t,u)$\nof a Gaussian process $S(t), t\\in [0,1]$ based on $n$ i.i.d. copies of $S$\nobserved in a white noise. We suggest a new estimation procedure adapting\nsimultaneously to the low rank structure and the smoothness of the covariance\nfunction. The new procedure is based on nuclear norm penalization and exhibits\nsuperior performances as compared to the sample covariance function by a\npolynomial factor in the sample size $n$. Other results include a minimax lower\nbound for estimation of low-rank covariance functions showing that our\nprocedure is optimal as well as a scheme to estimate the unknown noise variance\nof the Gaussian process.\n", "versions": [{"version": "v1", "created": "Sun, 12 Apr 2015 19:23:21 GMT"}], "update_date": "2015-04-14", "authors_parsed": [["Koltchinskii", "Vladimir", ""], ["Lounici", "Karim", ""], ["Tsybakov", "Alexander B.", ""]]}, {"id": "1504.03084", "submitter": "Donald A. Pierce", "authors": "Donald A. Pierce, Ruggero Bellio", "title": "Beyond first-order asymptotics for Cox regression", "comments": "Published at http://dx.doi.org/10.3150/13-BEJ572 in the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2015, Vol. 21, No. 1, 401-419", "doi": "10.3150/13-BEJ572", "report-no": "IMS-BEJ-BEJ572", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To go beyond standard first-order asymptotics for Cox regression, we develop\nparametric bootstrap and second-order methods. In general, computation of\n$P$-values beyond first order requires more model specification than is\nrequired for the likelihood function. It is problematic to specify a censoring\nmechanism to be taken very seriously in detail, and it appears that\nconditioning on censoring is not a viable alternative to that. We circumvent\nthis matter by employing a reference censoring model, matching the extent and\ntiming of observed censoring. Our primary proposal is a parametric bootstrap\nmethod utilizing this reference censoring model to simulate inferential\nrepetitions of the experiment. It is shown that the most important part of\nimprovement on first-order methods - that pertaining to fitting nuisance\nparameters - is insensitive to the assumed censoring model. This is supported\nby numerical comparisons of our proposal to parametric bootstrap methods based\non usual random censoring models, which are far more unattractive to implement.\nAs an alternative to our primary proposal, we provide a second-order method\nrequiring less computing effort while providing more insight into the nature of\nimprovement on first-order methods. However, the parametric bootstrap method is\nmore transparent, and hence is our primary proposal. Indications are that\nfirst-order partial likelihood methods are usually adequate in practice, so we\nare not advocating routine use of the proposed methods. It is however useful to\nsee how best to check on first-order approximations, or improve on them, when\nthis is expressly desired.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2015 07:42:19 GMT"}], "update_date": "2015-04-14", "authors_parsed": [["Pierce", "Donald A.", ""], ["Bellio", "Ruggero", ""]]}, {"id": "1504.03144", "submitter": "D. Buraczewski", "authors": "D. Buraczewski, E. Damek, J. Zienkiewicz", "title": "Precise tail asymptotics of fixed points of the smoothing transform with\n  general weights", "comments": "Published at http://dx.doi.org/10.3150/13-BEJ576 in the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2015, Vol. 21, No. 1, 489-504", "doi": "10.3150/13-BEJ576", "report-no": "IMS-BEJ-BEJ576", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider solutions of the stochastic equation $R=_d\\sum_{i=1}^NA_iR_i+B$,\nwhere $N>1$ is a fixed constant, $A_i$ are independent, identically distributed\nrandom variables and $R_i$ are independent copies of $R$, which are independent\nboth from $A_i$'s and $B$. The hypotheses ensuring existence of solutions are\nwell known. Moreover under a number of assumptions the main being\n$\\mathbb{E}|A_1|^{\\alpha}=1/N$ and $\\mathbb{E}|A_1|^{\\alpha}\\log|A_1|>0$, the\nlimit $\\lim_{t\\to\\infty}t^{\\alpha}\\mathbb{P}[|R|>t]=K$ exists. In the present\npaper, we prove positivity of $K$.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2015 11:53:44 GMT"}], "update_date": "2015-04-14", "authors_parsed": [["Buraczewski", "D.", ""], ["Damek", "E.", ""], ["Zienkiewicz", "J.", ""]]}, {"id": "1504.03177", "submitter": "Mario Kieburg Dr. habil.", "authors": "Tim Wirtz, Mario Kieburg, Thomas Guhr", "title": "Asymptotic Coincidence of the Statistics for Degenerate and\n  Non-Degenerate Correlated Real Wishart Ensembles", "comments": "Drastically extended version compared to the first version. New\n  chapters on the analysis of the local and global spectral statistics\n  including approximations on the position and standard deviation of outliers.\n  New numerical simulations comparing the macroscopic level density and the\n  distributions of the largest and the smallest eigenvalue. 24 pages, 5 figures", "journal-ref": "J. Phys. A 50, 235203 (2017)", "doi": "10.1088/1751-8121/aa6a6c", "report-no": null, "categories": "math-ph cond-mat.stat-mech math.MP math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The correlated Wishart model provides the standard benchmark when analyzing\ntime series of any kind. Unfortunately, the real case, which is the most\nrelevant one in applications, poses serious challenges for analytical\ncalculations. Often these challenges are due to square root singularities which\ncannot be handled using common random matrix techniques. We present a new way\nto tackle this issue. Using supersymmetry, we carry out an anlaytical study\nwhich we support by numerical simulations. For large but finite matrix\ndimensions, we show that statistical properties of the fully correlated real\nWishart model generically approach those of a correlated real Wishart model\nwith doubled matrix dimensions and doubly degenerate empirical eigenvalues.\nThis holds for the local and global spectral statistics. With Monte Carlo\nsimulations we show that this is even approximately true for small matrix\ndimensions. We explicitly investigate the $k$-point correlation function as\nwell as the distribution of the largest eigenvalue for which we find a\nsurprisingly compact formula in the doubly degenerate case. Moreover we show\nthat on the local scale the $k$-point correlation function exhibits the sine\nand the Airy kernel in the bulk and at the soft edges, respectively. We also\naddress the positions and the fluctuations of the possible outliers in the\ndata.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2015 13:34:25 GMT"}, {"version": "v2", "created": "Wed, 2 Nov 2016 11:14:15 GMT"}, {"version": "v3", "created": "Wed, 26 Apr 2017 09:01:58 GMT"}], "update_date": "2018-08-08", "authors_parsed": [["Wirtz", "Tim", ""], ["Kieburg", "Mario", ""], ["Guhr", "Thomas", ""]]}, {"id": "1504.03184", "submitter": "Tslil Clingman", "authors": "T. Clingman, Jeff Murugan, Jonathan P. Shock", "title": "Probability Density Functions from the Fisher Information Metric", "comments": "16 pages, no figures", "journal-ref": null, "doi": null, "report-no": "QGaSLAB-15-02", "categories": "cs.IT math.DG math.IT math.ST physics.data-an stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show a general relation between the spatially disjoint product of\nprobability density functions and the sum of their Fisher information metric\ntensors. We then utilise this result to give a method for constructing the\nprobability density functions for an arbitrary Riemannian Fisher information\nmetric tensor. We note further that this construction is extremely\nunconstrained, depending only on certain continuity properties of the\nprobability density functions and a select symmetry of their domains.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2015 13:53:37 GMT"}], "update_date": "2015-04-14", "authors_parsed": [["Clingman", "T.", ""], ["Murugan", "Jeff", ""], ["Shock", "Jonathan P.", ""]]}, {"id": "1504.03234", "submitter": "Alexandra Carpentier", "authors": "Alexandra Carpentier, Jens Eisert, David Gross, Richard Nickl", "title": "Uncertainty Quantification for Matrix Compressed Sensing and Quantum\n  Tomography Problems", "comments": null, "journal-ref": "pp 385-430 (2019) In: Gozlan N., Lata{\\l}a R., Lounici K., Madiman\n  M. (eds) High Dimensional Probability VIII. Progress in Probability, vol 74.\n  Birkh\\", "doi": "10.1007/978-3-030-26391-1_18", "report-no": null, "categories": "math.ST quant-ph stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We construct minimax optimal non-asymptotic confidence sets for low rank\nmatrix recovery algorithms such as the Matrix Lasso or Dantzig selector. These\nare employed to devise adaptive sequential sampling procedures that guarantee\nrecovery of the true matrix in Frobenius norm after a data-driven stopping time\n$\\hat n$ for the number of measurements that have to be taken. With high\nprobability, this stopping time is minimax optimal. We detail applications to\nquantum tomography problems where measurements arise from Pauli observables. We\nalso give a theoretical construction of a confidence set for the density matrix\nof a quantum state that has optimal diameter in nuclear norm. The\nnon-asymptotic properties of our confidence sets are further investigated in a\nsimulation study.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2015 16:06:01 GMT"}, {"version": "v2", "created": "Mon, 21 Dec 2015 08:11:46 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Carpentier", "Alexandra", ""], ["Eisert", "Jens", ""], ["Gross", "David", ""], ["Nickl", "Richard", ""]]}, {"id": "1504.03381", "submitter": "Cedric Ginestet", "authors": "Cedric E. Ginestet, Richard Emsley, Sabine Landau", "title": "Convex Combination of Ordinary Least Squares and Two-stage Least Squares\n  Estimators", "comments": "33 pages. 8 figures, 1 table. To be presented at UK-CIM (Causal\n  Inference Meeting) in Bristol, in April 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the presence of confounders, the ordinary least squares (OLS) estimator is\nknown to be biased. This problem can be remedied by using the two-stage least\nsquares (TSLS) estimator, based on the availability of valid instrumental\nvariables (IVs). This reduction in bias, however, is offset by an increase in\nvariance. Under standard assumptions, the OLS has indeed a larger bias than the\nTSLS estimator; and moreover, one can prove that the sample variance of the OLS\nestimator is no greater than the one of the TSLS. Therefore, it is natural to\nask whether one could combine the desirable properties of the OLS and TSLS\nestimators. Such a trade-off can be achieved through a convex combination of\nthese two estimators, thereby producing our proposed convex least squares (CLS)\nestimator. The relative contribution of the OLS and TSLS estimators is here\nchosen to minimize a sample estimate of the mean squared error (MSE) of their\nconvex combination. This proportion parameter is proved to be unique, whenever\nthe OLS and TSLS differ in MSEs. Remarkably, we show that this proportion\nparameter can be estimated from the data, and that the resulting CLS estimator\nis consistent. We also show how the CLS framework can incorporate other\nasymptotically unbiased estimators, such as the jackknife IV estimator (JIVE).\nThe finite-sample properties of the CLS estimator are investigated using Monte\nCarlo simulations, in which we independently vary the amount of confounding and\nthe strength of the instrument. Overall, the CLS estimator is found to\noutperform the TSLS estimator in terms of MSE. The method is also applied to a\nclassic data set from econometrics, which models the financial return to\neducation.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2015 22:20:22 GMT"}], "update_date": "2015-04-15", "authors_parsed": [["Ginestet", "Cedric E.", ""], ["Emsley", "Richard", ""], ["Landau", "Sabine", ""]]}, {"id": "1504.03389", "submitter": "Victor Yohai", "authors": "Ricardo A. Maronna and Victor J. Yohai", "title": "Robust and efficient estimation of high dimensional scatter and location", "comments": "24 pages, 4 figures, 15 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We deal with the equivariant estimation of scatter and location for\np-dimensional data, giving emphasis to scatter. It it important that the\nestimators possess both a high efficiency for normal data and a high resistance\nto outliers, that is, a low bias under contamination. The most frequently\nemployed estimators are not quite satisfactory in this respect. The Minimum\nVolume Ellipsoid (MVE) and Minimum Covariance Determinant (MCD) estimators are\nknown to have a very low efficiency. S-Estimators (Davies 1987) with a\nmonotonic weight function like the bisquare behave satisfactorily for \"small\"\np, say p not larger than 10. Rocke (1996) showed that their efficiency tends to\none with increasing p. Unfortunately, this advantage is paid with a serious\nloss of robustness for large p. We consider three families of estimators with\ncontrollable efficiencies: non-monotonic S-estimators (Rocke 1996),\nMM-estimators (Tatsuoka and Tyler 2000) and tau-estimators (Lopuhaa 1991),\nwhose performance for large p has not been explored to date. Two types of\nstarting estimators are employed: the MVE computed through subsampling, and a\nsemi-deterministic procedure proposed by Pe\\~na and Prieto (2007) for outlier\ndetection. A simulation study shows that the Rocke and MM estimators starting\nfrom the Pe\\~na-Prieto estimator and with an adequate tuning, can\nsimultaneously attain high efficiency and high robustness.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2015 23:37:17 GMT"}, {"version": "v2", "created": "Tue, 4 Aug 2015 16:45:16 GMT"}, {"version": "v3", "created": "Thu, 13 Aug 2015 23:18:39 GMT"}], "update_date": "2015-08-17", "authors_parsed": [["Maronna", "Ricardo A.", ""], ["Yohai", "Victor J.", ""]]}, {"id": "1504.03438", "submitter": "Takashi Nakamura", "authors": "Takashi Nakamura", "title": "A complete Riemann zeta distribution and the Riemann hypothesis", "comments": "Published at http://dx.doi.org/10.3150/13-BEJ581 in the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2015, Vol. 21, No. 1, 604-617", "doi": "10.3150/13-BEJ581", "report-no": "IMS-BEJ-BEJ581", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $\\sigma,t\\in{\\mathbb{R}}$, $s=\\sigma+\\mathrm{{i}}t$, $\\Gamma (s)$ be the\nGamma function, $\\zeta(s)$ be the Riemann zeta function and $\\xi(s):=s(s-1)\\pi\n^{-s/2}\\Gamma(s/2)\\zeta(s)$ be the complete Riemann zeta function. We show that\n$\\Xi_{\\sigma}(t):=\\xi (\\sigma-\\mathrm{{i}}t)/\\xi(\\sigma)$ is a characteristic\nfunction for any $\\sigma\\in{\\mathbb{R}}$ by giving the probability density\nfunction. Next we prove that the Riemann hypothesis is true if and only if each\n$\\Xi_{\\sigma}(t)$ is a pretended-infinitely divisible characteristic function,\nwhich is defined in this paper, for each $1/2<\\sigma<1$. Moreover, we show that\n$\\Xi_{\\sigma}(t)$ is a pretended-infinitely divisible characteristic function\nwhen $\\sigma=1$. Finally we prove that the characteristic function\n$\\Xi_{\\sigma}(t)$ is not infinitely divisible but quasi-infinitely divisible\nfor any $\\sigma>1$.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2015 07:14:51 GMT"}], "update_date": "2015-04-15", "authors_parsed": [["Nakamura", "Takashi", ""]]}, {"id": "1504.03459", "submitter": "Kirstin Strokorb", "authors": "Kirstin Strokorb, Martin Schlather", "title": "An exceptional max-stable process fully parameterized by its extremal\n  coefficients", "comments": "Published at http://dx.doi.org/10.3150/13-BEJ567 in the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2015, Vol. 21, No. 1, 276-302", "doi": "10.3150/13-BEJ567", "report-no": "IMS-BEJ-BEJ567", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The extremal coefficient function (ECF) of a max-stable process $X$ on some\nindex set $T$ assigns to each finite subset $A\\subset T$ the effective number\nof independent random variables among the collection $\\{X_t\\}_{t\\in A}$. We\nintroduce the class of Tawn-Molchanov processes that is in a 1:1 correspondence\nwith the class of ECFs, thus also proving a complete characterization of the\nECF in terms of negative definiteness. The corresponding Tawn-Molchanov process\nturns out to be exceptional among all max-stable processes sharing the same ECF\nin that its dependency set is maximal w.r.t. inclusion. This entails sharp\nlower bounds for the finite dimensional distributions of arbitrary max-stable\nprocesses in terms of its ECF. A spectral representation of the Tawn-Molchanov\nprocess and stochastic continuity are discussed. We also show how to build new\nvalid ECFs from given ECFs by means of Bernstein functions.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2015 08:56:45 GMT"}], "update_date": "2015-04-15", "authors_parsed": [["Strokorb", "Kirstin", ""], ["Schlather", "Martin", ""]]}, {"id": "1504.03506", "submitter": "Jonas Kahn", "authors": "Philippe Heinrich and Jonas Kahn", "title": "Minimax rates for finite mixture estimation", "comments": "30 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that under some regularity and strong identifiability conditions,\naround a mixing distribution with $m_0$ components, the optimal local minimax\nrate of estimation of a mixture with $m$ components is $n^{-1/(4(m-m_0) + 2)}$.\nThis corrects a previous paper by Chen (1995) in The Annals of Statistics.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2015 12:03:27 GMT"}], "update_date": "2015-04-15", "authors_parsed": [["Heinrich", "Philippe", ""], ["Kahn", "Jonas", ""]]}, {"id": "1504.03796", "submitter": "Minerva Mukhopadhyay", "authors": "Minerva Mukhopadhyay", "title": "A Mixture of g-priors for Variable Selection when the Number of\n  Regressors Grows with the Sample Size", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider variable selection problem in linear regression using mixture of\n$g$-priors. A number of mixtures are proposed in the literature which work\nwell, especially when the number of regressors $p$ is fixed. In this paper, we\npropose a mixture of $g$-priors suitable for the case when $p$ grows with the\nsample size $n$. We study the performance of the method based on the proposed\nprior when $p=O(n^b),~0<b<1$. Along with model selection consistency, we also\ninvestigate the performance of the proposed prior when the true model does not\nbelong to the model space considered. We find conditions under which the\nproposed prior is consistent in appropriate sense when normal linear models are\nconsidered. Further, we consider the case with non-normal errors in the\nregression model and study the performance of the model selection procedure. We\nalso compare the performance of the proposed prior with that of several other\nmixtures available in the literature, both theoretically and using simulated\ndata sets.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2015 06:54:14 GMT"}], "update_date": "2015-04-16", "authors_parsed": [["Mukhopadhyay", "Minerva", ""]]}, {"id": "1504.04100", "submitter": "Abhik Ghosh", "authors": "Abhik Ghosh and Ayanendranath Basu", "title": "Testing Composite Null Hypothesis Based on $S$-Divergences", "comments": "13 pages", "journal-ref": "Statistics and Probability Letters, July 2016, 114, 38--47", "doi": "10.1016/j.spl.2016.02.007", "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a robust test for composite null hypothesis based on the general\n$S$-divergence family. This requires a non-trivial extension of the results of\nGhosh et al.~(2015). We derive the asymptotic and theoretical robustness\nproperties of the resulting test along with the properties of the minimum\n$S$-divergence estimators under parameter restrictions imposed by the null\nhypothesis. An illustration in the context of the normal model is also\npresented.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2015 05:38:25 GMT"}], "update_date": "2016-07-04", "authors_parsed": [["Ghosh", "Abhik", ""], ["Basu", "Ayanendranath", ""]]}, {"id": "1504.04103", "submitter": "Ananda Theertha Suresh", "authors": "Moein Falahatgar and Ashkan Jafarpour and Alon Orlitsky and\n  Venkatadheeraj Pichapathi and Ananda Theertha Suresh", "title": "Faster Algorithms for Testing under Conditional Sampling", "comments": "31 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been considerable recent interest in distribution-tests whose\nrun-time and sample requirements are sublinear in the domain-size $k$. We study\ntwo of the most important tests under the conditional-sampling model where each\nquery specifies a subset $S$ of the domain, and the response is a sample drawn\nfrom $S$ according to the underlying distribution.\n  For identity testing, which asks whether the underlying distribution equals a\nspecific given distribution or $\\epsilon$-differs from it, we reduce the known\ntime and sample complexities from $\\tilde{\\mathcal{O}}(\\epsilon^{-4})$ to\n$\\tilde{\\mathcal{O}}(\\epsilon^{-2})$, thereby matching the information\ntheoretic lower bound. For closeness testing, which asks whether two\ndistributions underlying observed data sets are equal or different, we reduce\nexisting complexity from $\\tilde{\\mathcal{O}}(\\epsilon^{-4} \\log^5 k)$ to an\neven sub-logarithmic $\\tilde{\\mathcal{O}}(\\epsilon^{-5} \\log \\log k)$ thus\nproviding a better bound to an open problem in Bertinoro Workshop on Sublinear\nAlgorithms [Fisher, 2004].\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2015 05:56:34 GMT"}], "update_date": "2015-04-17", "authors_parsed": [["Falahatgar", "Moein", ""], ["Jafarpour", "Ashkan", ""], ["Orlitsky", "Alon", ""], ["Pichapathi", "Venkatadheeraj", ""], ["Suresh", "Ananda Theertha", ""]]}, {"id": "1504.04105", "submitter": "Leonid Sirota", "authors": "E. Ostrovsky, L. Sirota", "title": "Problem of Estimation of Fractional Derivative for a Spectral Function\n  of Gaussian Stationary Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of nonparametric estimation of the fractional derivative\nof unknown spectral function of Gaussian stationary sequence (time series) and\nshow that these problems is well posed with the classical speed of convergence\nwhen the order of derivative is less than 0.5. We prove also the asymptotical\nunbiaseness and normality of offered estimates with optimal speed of\nconvergence. For the construction of the confidence region in some functional\nnorm we establish the Central Limit Theorem in correspondent space of\ncontinuous functions for offered estimates.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2015 06:11:31 GMT"}], "update_date": "2015-04-17", "authors_parsed": [["Ostrovsky", "E.", ""], ["Sirota", "L.", ""]]}, {"id": "1504.04472", "submitter": "Steffen Gr{\\o}nneberg", "authors": "Benjamin Holcblat, Steffen Gr{\\o}nneberg", "title": "On econometric inference and multiple use of the same data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In fields that are mainly nonexperimental, such as economics and finance, it\nis inescapable to compute test statistics and confidence regions that are not\nprobabilistically independent from previously examined data. The Bayesian and\nNeyman-Pearson inference theories are known to be inadequate for such a\npractice. We show that these inadequacies also hold m.a.e. (modulo\napproximation error). We develop a general econometric theory, called the\nneoclassical inference theory, that is immune to this inadequacy m.a.e. The\nneoclassical inference theory appears to nest model calibration, and most\neconometric practices, whether they are labelled Bayesian or \\`a la\nNeyman-Pearson. We derive a general, but simple adjustment to make standard\nerrors account for the approximation error.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2015 09:53:02 GMT"}], "update_date": "2015-04-20", "authors_parsed": [["Holcblat", "Benjamin", ""], ["Gr\u00f8nneberg", "Steffen", ""]]}, {"id": "1504.04521", "submitter": "Gyula Pap", "authors": "J\\'anos Marcell Benke and Gyula Pap", "title": "Asymptotic inference for a stochastic differential equation with\n  uniformly distributed time delay", "comments": null, "journal-ref": "J. Statist. Plann. Inference 167 (2015) 182-192", "doi": "10.1016/j.jspi.2015.04.010", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For affine stochastic differential equation with uniformly distributed time\ndelay the local asymptotic properties of the likelihood function are studied.\nLocal asymptotic normality, local asymptotic mixed normality, periodic local\nasymptotic mixed normality or local asymptotic quadraticity is proved for\ndifferent values of the parameter. Applications to the asymptotic behaviour of\nthe maximum likelihood estimator of the parameter based on continuous sample\nare given.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2015 12:48:44 GMT"}, {"version": "v2", "created": "Wed, 9 Sep 2015 08:04:01 GMT"}], "update_date": "2015-09-10", "authors_parsed": [["Benke", "J\u00e1nos Marcell", ""], ["Pap", "Gyula", ""]]}, {"id": "1504.04580", "submitter": "Emilien Joly", "authors": "Emilien Joly, G\\'abor Lugosi", "title": "Robust estimation of U-statistics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important part of the legacy of Evarist Gin\\'e is his fundamental\ncontributions to our understanding of $U$-statistics and $U$-processes. In this\npaper we discuss the estimation of the mean of multivariate functions in case\nof possibly heavy-tailed distributions. In such situations, reliable estimates\nof the mean cannot be obtained by usual $U$-statistics. We introduce a new\nestimator, based on the so-called median-of-means technique. We develop\nperformance bounds for this new estimator that generalizes an estimate of\nArcones and Gin\\'e (1993), showing that the new estimator performs, under\nminimal moment conditions, as well as classical $U$-statistics for bounded\nrandom variables. We discuss an application of this estimator to clustering.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2015 17:13:39 GMT"}], "update_date": "2015-04-20", "authors_parsed": [["Joly", "Emilien", ""], ["Lugosi", "G\u00e1bor", ""]]}, {"id": "1504.04599", "submitter": "Bhaswar Bhattacharya", "authors": "Bhaswar B. Bhattacharya and Gregory Valiant", "title": "Testing Closeness With Unequal Sized Samples", "comments": "27 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of closeness testing for two discrete distributions\nin the practically relevant setting of \\emph{unequal} sized samples drawn from\neach of them. Specifically, given a target error parameter $\\varepsilon > 0$,\n$m_1$ independent draws from an unknown distribution $p,$ and $m_2$ draws from\nan unknown distribution $q$, we describe a test for distinguishing the case\nthat $p=q$ from the case that $||p-q||_1 \\geq \\varepsilon$. If $p$ and $q$ are\nsupported on at most $n$ elements, then our test is successful with high\nprobability provided $m_1\\geq n^{2/3}/\\varepsilon^{4/3}$ and $m_2 =\n\\Omega(\\max\\{\\frac{n}{\\sqrt m_1\\varepsilon^2}, \\frac{\\sqrt\nn}{\\varepsilon^2}\\});$ we show that this tradeoff is optimal throughout this\nrange, to constant factors. These results extend the recent work of Chan et al.\nwho established the sample complexity when the two samples have equal sizes,\nand tightens the results of Acharya et al. by polynomials factors in both $n$\nand $\\varepsilon$. As a consequence, we obtain an algorithm for estimating the\nmixing time of a Markov chain on $n$ states up to a $\\log n$ factor that uses\n$\\tilde{O}(n^{3/2} \\tau_{mix})$ queries to a \"next node\" oracle, improving upon\nthe $\\tilde{O}(n^{5/3}\\tau_{mix})$ query algorithm of Batu et al. Finally, we\nnote that the core of our testing algorithm is a relatively simple statistic\nthat seems to perform well in practice, both on synthetic data and on natural\nlanguage data.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2015 18:35:35 GMT"}], "update_date": "2015-04-20", "authors_parsed": [["Bhattacharya", "Bhaswar B.", ""], ["Valiant", "Gregory", ""]]}, {"id": "1504.04636", "submitter": "Patrick L. Combettes", "authors": "Patrick L. Combettes, Saverio Salzo, and Silvia Villa", "title": "Consistent Learning by Composite Proximal Thresholding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the modeling and the numerical solution of machine learning\nproblems with prediction functions which are linear combinations of elements of\na possibly infinite-dimensional dictionary. We propose a novel flexible\ncomposite regularization model, which makes it possible to incorporate various\npriors on the coefficients of the prediction function, including sparsity and\nhard constraints. We show that the estimators obtained by minimizing the\nregularized empirical risk are consistent in a statistical sense, and we design\nan error-tolerant composite proximal thresholding algorithm for computing such\nestimators. New results on the asymptotic behavior of the proximal\nforward-backward splitting method are derived and exploited to establish the\nconvergence properties of the proposed algorithm. In particular, our method\nfeatures a $o(1/m)$ convergence rate in objective values.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2015 20:56:07 GMT"}, {"version": "v2", "created": "Tue, 1 Dec 2015 22:47:57 GMT"}], "update_date": "2015-12-03", "authors_parsed": [["Combettes", "Patrick L.", ""], ["Salzo", "Saverio", ""], ["Villa", "Silvia", ""]]}, {"id": "1504.04696", "submitter": "Arnak Dalalyan S.", "authors": "Samuel Balmand, Arnak S. Dalalyan", "title": "On estimation of the diagonal elements of a sparse precision matrix", "comments": "Companion R package at\n  http://cran.r-project.org/web/packages/DESP/index.html", "journal-ref": "Electron. J. Statist. Volume 10, Number 1, 1551-1579 (2016)", "doi": "10.1214/16-EJS1148", "report-no": null, "categories": "math.ST stat.CO stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present several estimators of the diagonal elements of the\ninverse of the covariance matrix, called precision matrix, of a sample of iid\nrandom vectors. The focus is on high dimensional vectors having a sparse\nprecision matrix. It is now well understood that when the underlying\ndistribution is Gaussian, the columns of the precision matrix can be estimated\nindependently form one another by solving linear regression problems under\nsparsity constraints. This approach leads to a computationally efficient\nstrategy for estimating the precision matrix that starts by estimating the\nregression vectors, then estimates the diagonal entries of the precision matrix\nand, in a final step, combines these estimators for getting estimators of the\noff-diagonal entries. While the step of estimating the regression vector has\nbeen intensively studied over the past decade, the problem of deriving\nstatistically accurate estimators of the diagonal entries has received much\nless attention. The goal of the present paper is to fill this gap by presenting\nfour estimators---that seem the most natural ones---of the diagonal entries of\nthe precision matrix and then performing a comprehensive empirical evaluation\nof these estimators. The estimators under consideration are the residual\nvariance, the relaxed maximum likelihood, the symmetry-enforced maximum\nlikelihood and the penalized maximum likelihood. We show, both theoretically\nand empirically, that when the aforementioned regression vectors are estimated\nwithout error, the symmetry-enforced maximum likelihood estimator has the\nsmallest estimation error. However, in a more realistic setting when the\nregression vector is estimated by a sparsity-favoring computationally efficient\nmethod, the qualities of the estimators become relatively comparable with a\nslight advantage for the residual variance estimator.\n", "versions": [{"version": "v1", "created": "Sat, 18 Apr 2015 08:56:38 GMT"}, {"version": "v2", "created": "Tue, 21 Apr 2015 10:04:17 GMT"}, {"version": "v3", "created": "Fri, 29 May 2015 12:17:08 GMT"}, {"version": "v4", "created": "Wed, 25 May 2016 14:16:17 GMT"}], "update_date": "2017-07-31", "authors_parsed": [["Balmand", "Samuel", ""], ["Dalalyan", "Arnak S.", ""]]}, {"id": "1504.04814", "submitter": "Botond Szabo", "authors": "Judith Rousseau and Botond Szabo", "title": "Asymptotic behaviour of the empirical Bayes posteriors associated to\n  maximum marginal likelihood estimator", "comments": "36 pages +24 pages supplementary material", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the asymptotic behaviour of the marginal maximum likelihood\nempirical Bayes posterior distribution in general setting. First we\ncharacterize the set where the maximum marginal likelihood estimator is located\nwith high probability. Then we provide oracle type of upper and lower bounds\nfor the contraction rates of the empirical Bayes posterior. We also show that\nthe hierarchical Bayes posterior achieves the same contraction rate as the\nmaximum marginal likelihood empirical Bayes posterior. We demonstrate the\napplicability of our general results for various models and prior distributions\nby deriving upper and lower bounds for the contraction rates of the\ncorresponding empirical and hierarchical Bayes posterior distributions.\n", "versions": [{"version": "v1", "created": "Sun, 19 Apr 2015 08:50:17 GMT"}, {"version": "v2", "created": "Fri, 30 Oct 2015 23:08:37 GMT"}, {"version": "v3", "created": "Mon, 4 Apr 2016 13:34:43 GMT"}], "update_date": "2016-04-05", "authors_parsed": [["Rousseau", "Judith", ""], ["Szabo", "Botond", ""]]}, {"id": "1504.04901", "submitter": "Xiaotian Zhu", "authors": "Xiaotian Zhu and David R. Hunter", "title": "Theoretical Grounding for Estimation in Conditional Independence\n  Multivariate Finite Mixture Models", "comments": "21 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For the nonparametric estimation of multivariate finite mixture models with\nthe conditional independence assumption, we propose a new formulation of the\nobjective function in terms of penalized smoothed Kullback-Leibler distance.\nThe nonlinearly smoothed majorization-minimization (NSMM) algorithm is derived\nfrom this perspective. An elegant representation of the NSMM algorithm is\nobtained using a novel projection-multiplication operator, a more precise\nmonotonicity property of the algorithm is discovered, and the existence of a\nsolution to the main optimization problem is proved for the first time.\n", "versions": [{"version": "v1", "created": "Sun, 19 Apr 2015 23:55:00 GMT"}, {"version": "v2", "created": "Wed, 28 Oct 2015 02:57:37 GMT"}], "update_date": "2015-10-29", "authors_parsed": [["Zhu", "Xiaotian", ""], ["Hunter", "David R.", ""]]}, {"id": "1504.05073", "submitter": "Sjoerd Dirksen", "authors": "Sjoerd Dirksen, Guillaume Lecu\\'e, Holger Rauhut", "title": "On the gap between RIP-properties and sparse recovery conditions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of recovering sparse vectors from underdetermined\nlinear measurements via $\\ell_p$-constrained basis pursuit. Previous analyses\nof this problem based on generalized restricted isometry properties have\nsuggested that two phenomena occur if $p\\neq 2$. First, one may need\nsubstantially more than $s \\log(en/s)$ measurements (optimal for $p=2$) for\nuniform recovery of all $s$-sparse vectors. Second, the matrix that achieves\nrecovery with the optimal number of measurements may not be Gaussian (as for\n$p=2$). We present a new, direct analysis which shows that in fact neither of\nthese phenomena occur. Via a suitable version of the null space property we\nshow that a standard Gaussian matrix provides $\\ell_q/\\ell_1$-recovery\nguarantees for $\\ell_p$-constrained basis pursuit in the optimal measurement\nregime. Our result extends to several heavier-tailed measurement matrices. As\nan application, we show that one can obtain a consistent reconstruction from\nuniform scalar quantized measurements in the optimal measurement regime.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2015 14:35:49 GMT"}], "update_date": "2015-04-21", "authors_parsed": [["Dirksen", "Sjoerd", ""], ["Lecu\u00e9", "Guillaume", ""], ["Rauhut", "Holger", ""]]}, {"id": "1504.05087", "submitter": "Jianfeng Yao", "authors": "Qinwen Wang and Jianfeng Yao", "title": "Extreme eigenvalues of large-dimensional spiked Fisher matrices with\n  application", "comments": "40 pages, 5 figures and 2 tables", "journal-ref": "The Annals of Statistics 45,415-460, 2017", "doi": "10.1214/16-AOS1463", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider two $p$-variate populations, not necessarily Gaussian, with\ncovariance matrices $\\Sigma_1$ and $\\Sigma_2$, respectively, and let $S_1$ and\n$S_2$ be the sample covariances matrices from samples of the populations with\ndegrees of freedom $T$ and $n$, respectively. When the difference $\\Delta$\nbetween $\\Sigma_1$ and $\\Sigma_2$ is of small rank compared to $p,T$ and $n$,\nthe Fisher matrix $F=S_2^{-1}S_1$ is called a {\\em spiked Fisher matrix}. When\n$p,T$ and $n$ grow to infinity proportionally, we establish a phase transition\nfor the extreme eigenvalues of $F$: when the eigenvalues of $\\Delta$ ({\\em\nspikes}) are above (or under) a critical value, the associated extreme\neigenvalues of the Fisher matrix will converge to some point outside the\nsupport of the global limit (LSD) of other eigenvalues; otherwise, they will\nconverge to the edge points of the LSD. Furthermore, we derive central limit\ntheorems for these extreme eigenvalues of the spiked Fisher matrix. The\nlimiting distributions are found to be Gaussian if and only if the\ncorresponding population spike eigenvalues in $\\Delta$ are {\\em simple}.\nNumerical examples are provided to demonstrate the finite sample performance of\nthe results. In addition to classical applications of a Fisher matrix in\nhigh-dimensional data analysis, we propose a new method for the detection of\nsignals allowing an arbitrary covariance structure of the noise. Simulation\nexperiments are conducted to illustrate the performance of this detector.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2015 15:33:00 GMT"}], "update_date": "2018-01-23", "authors_parsed": [["Wang", "Qinwen", ""], ["Yao", "Jianfeng", ""]]}, {"id": "1504.05219", "submitter": "Joanna Matysiak", "authors": "Joanna Matysiak", "title": "Bivariate natural exponential families with quadratic diagonal of the\n  variance function", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We characterize bivariate natural exponential families having the diagonal of\nthe variance function of the form \\[ \\textrm{diag}\nV(m_1,m_2)=\\left(Am_1^2+am_1+bm_2+e,Am_2^2+cm_1+dm_2+f\\right), \\] with $A<0$\nand $a,\\ldots,f\\in\\mathbb{R}$. The solution of the problem relies on finding\nthe conditions under which a specific parametric family of functions consists\nof Laplace transforms of some probability measures.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2015 20:32:36 GMT"}], "update_date": "2015-04-22", "authors_parsed": [["Matysiak", "Joanna", ""]]}, {"id": "1504.05229", "submitter": "Yao Xie", "authors": "Yang Cao and Yao Xie", "title": "Poisson Matrix Recovery and Completion", "comments": "Submitted to IEEE Journal. Parts of the paper have appeared in\n  GlobalSIP 2013, GlobalSIP 2014, and ISIT 2015. arXiv admin note: substantial\n  text overlap with arXiv:1501.06243", "journal-ref": null, "doi": "10.1109/TSP.2015.2500192", "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend the theory of low-rank matrix recovery and completion to the case\nwhen Poisson observations for a linear combination or a subset of the entries\nof a matrix are available, which arises in various applications with count\ndata. We consider the usual matrix recovery formulation through maximum\nlikelihood with proper constraints on the matrix $M$ of size $d_1$-by-$d_2$,\nand establish theoretical upper and lower bounds on the recovery error. Our\nbounds for matrix completion are nearly optimal up to a factor on the order of\n$\\mathcal{O}(\\log(d_1 d_2))$. These bounds are obtained by combing techniques\nfor compressed sensing for sparse vectors with Poisson noise and for analyzing\nlow-rank matrices, as well as adapting the arguments used for one-bit matrix\ncompletion \\cite{davenport20121} (although these two problems are different in\nnature) and the adaptation requires new techniques exploiting properties of the\nPoisson likelihood function and tackling the difficulties posed by the locally\nsub-Gaussian characteristic of the Poisson distribution. Our results highlight\na few important distinctions of the Poisson case compared to the prior work\nincluding having to impose a minimum signal-to-noise requirement on each\nobserved entry and a gap in the upper and lower bounds. We also develop a set\nof efficient iterative algorithms and demonstrate their good performance on\nsynthetic examples and real data.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2015 21:09:47 GMT"}, {"version": "v2", "created": "Sat, 12 Sep 2015 02:13:26 GMT"}], "update_date": "2016-04-20", "authors_parsed": [["Cao", "Yang", ""], ["Xie", "Yao", ""]]}, {"id": "1504.05289", "submitter": "Sebastian Roch", "authors": "Elchanan Mossel, Sebastien Roch", "title": "Distance-based species tree estimation: information-theoretic trade-off\n  between number of loci and sequence length under the coalescent", "comments": "To appear in The Annals of Applied Probability", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.LG math.ST q-bio.PE stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the reconstruction of a phylogeny from multiple genes under the\nmultispecies coalescent. We establish a connection with the sparse signal\ndetection problem, where one seeks to distinguish between a distribution and a\nmixture of the distribution and a sparse signal. Using this connection, we\nderive an information-theoretic trade-off between the number of genes, $m$,\nneeded for an accurate reconstruction and the sequence length, $k$, of the\ngenes. Specifically, we show that to detect a branch of length $f$, one needs\n$m = \\Theta(1/[f^{2} \\sqrt{k}])$.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2015 03:39:05 GMT"}, {"version": "v2", "created": "Thu, 20 Jul 2017 18:36:35 GMT"}], "update_date": "2017-07-24", "authors_parsed": [["Mossel", "Elchanan", ""], ["Roch", "Sebastien", ""]]}, {"id": "1504.05415", "submitter": "Harold Bae", "authors": "Harold Bae, Thomas Perls, Martin Steinberg, Paola Sebastiani", "title": "Bayesian Polynomial Regression Models to Fit Multiple Genetic Models for\n  Quantitative Traits", "comments": "Published at http://dx.doi.org/10.1214/14-BA880 in the Bayesian\n  Analysis (http://projecteuclid.org/euclid.ba) by the International Society of\n  Bayesian Analysis (http://bayesian.org/)", "journal-ref": "Bayesian Analysis 2015, Vol. 10, No. 1, 53-74", "doi": "10.1214/14-BA880", "report-no": "VTeX-BA-BA880", "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a coherent Bayesian framework for selection of the most likely\nmodel from the five genetic models (genotypic, additive, dominant, co-dominant,\nand recessive) commonly used in genetic association studies. The approach uses\na polynomial parameterization of genetic data to simultaneously fit the five\nmodels and save computations. We provide a closed-form expression of the\nmarginal likelihood for normally distributed data, and evaluate the performance\nof the proposed method and existing method through simulated and real\ngenome-wide data sets.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2015 13:09:25 GMT"}], "update_date": "2015-04-22", "authors_parsed": [["Bae", "Harold", ""], ["Perls", "Thomas", ""], ["Steinberg", "Martin", ""], ["Sebastiani", "Paola", ""]]}, {"id": "1504.05438", "submitter": "Yen-Chi Chen", "authors": "Yen-Chi Chen, Christopher R. Genovese, Larry Wasserman", "title": "Density Level Sets: Asymptotics, Inference, and Visualization", "comments": "Accepted to JASA-T&M. 40 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive asymptotic theory for the plug-in estimate for density level sets\nunder Hausdoff loss. Based on the asymptotic theory, we propose two bootstrap\nconfidence regions for level sets. The confidence regions can be used to\nperform tests for anomaly detection and clustering. We also introduce a\ntechnique to visualize high dimensional density level sets by combining mode\nclustering and multidimensional scaling.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2015 14:04:07 GMT"}, {"version": "v2", "created": "Mon, 5 Sep 2016 15:35:53 GMT"}], "update_date": "2016-09-06", "authors_parsed": [["Chen", "Yen-Chi", ""], ["Genovese", "Christopher R.", ""], ["Wasserman", "Larry", ""]]}, {"id": "1504.05443", "submitter": "Huiming Zhang", "authors": "Huiming Zhang", "title": "Characterizations and Infinite Divisibility of Extended COM-Poisson\n  Distribution", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article provides some characterizations of extended COM-Poisson\ndistribution: conditional distribution given the sum, functional operator\ncharacterization (Stein identity). We also give some conditions such that the\nextended COM-Poisson distribution is infinitely divisible, hence some subclass\nof extended COM-Poisson distributions are discrete compound Poisson\ndistribution.\n", "versions": [{"version": "v1", "created": "Sun, 19 Apr 2015 04:22:09 GMT"}, {"version": "v2", "created": "Tue, 25 Aug 2015 09:56:27 GMT"}], "update_date": "2015-08-26", "authors_parsed": [["Zhang", "Huiming", ""]]}, {"id": "1504.05690", "submitter": "Gabriela Ciuperca", "authors": "Gabriela Ciuperca and Zahraa Salloum", "title": "Empirical likelihood test for high-dimensional two-sample model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A non parametric method based on the empirical likelihood is proposed for\ndetecting the change in the coefficients of high-dimensional linear model where\nthe number of model variables may increase as the sample size increases. This\namounts to testing the null hypothesis of no change against the alternative of\none change in the regression coefficients. Based on the theoretical asymptotic\nbehaviour of the empirical likelihood ratio statistic, we propose, for a fixed\ndesign, a simpler test statistic, easier to use in practice. The asymptotic\nnormality of the proposed test statistic under the null hypothesis is proved, a\nresult which is different from the $\\chi^2$ law for a model with a fixed\nvariable number. Under alternative hypothesis, the test statistic diverges. We\ncan then find the asymptotic confidence region for the difference of parameters\nof the two phases. Some Monte-Carlo simulations study the behaviour of the\nproposed test statistic.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2015 08:27:43 GMT"}, {"version": "v2", "created": "Fri, 19 Jun 2015 17:07:49 GMT"}], "update_date": "2015-06-22", "authors_parsed": [["Ciuperca", "Gabriela", ""], ["Salloum", "Zahraa", ""]]}, {"id": "1504.05919", "submitter": "Joel Tropp", "authors": "Joel A. Tropp", "title": "Second-Order Matrix Concentration Inequalities", "comments": "27 pages. Revision corrects technical errors in several places", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matrix concentration inequalities give bounds for the spectral-norm deviation\nof a random matrix from its expected value. These results have a weak\ndimensional dependence that is sometimes, but not always, necessary. This paper\nidentifies one of the sources of the dimensional term and exploits this insight\nto develop sharper matrix concentration inequalities. In particular, this\nanalysis delivers two refinements of the matrix Khintchine inequality that use\ninformation beyond the matrix variance to reduce or eliminate the dimensional\ndependence.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2015 18:46:20 GMT"}, {"version": "v2", "created": "Wed, 3 Aug 2016 22:38:25 GMT"}], "update_date": "2016-08-05", "authors_parsed": [["Tropp", "Joel A.", ""]]}, {"id": "1504.06006", "submitter": "Xia Shen", "authors": "Xia Shen, Zheng Ning, Yudi Pawitan", "title": "A simple regression equivalence of Pillai's trace statistic", "comments": "3 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Derived here is a single regression coefficient equivalent to Pillai's trace\nstatistic in multivariate analysis of variance.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2015 23:30:42 GMT"}], "update_date": "2015-04-24", "authors_parsed": [["Shen", "Xia", ""], ["Ning", "Zheng", ""], ["Pawitan", "Yudi", ""]]}, {"id": "1504.06079", "submitter": "Samuel Rosa", "authors": "Samuel Rosa and Radoslav Harman", "title": "Optimal approximate designs for estimating treatment contrasts resistant\n  to nuisance effects", "comments": "31 pages. Compared to the previous version: added comparison with\n  multiple controls; some reformulations to add more clarity", "journal-ref": "Stat Papers (2016) 57", "doi": "10.1007/s00362-016-0809-0", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Suppose that we intend to perform an experiment consisting of a set of\nindependent trials. The mean value of the response of each trial is assumed to\nbe equal to the sum of the effect of the treatment selected for the trial, and\nsome nuisance effects, e.g., the effect of a time trend, or blocking. In this\nmodel, we examine optimal approximate designs for the estimation of a system of\ntreatment contrasts, with respect to a wide range of optimality criteria.\n  We show that it is necessary for any optimal design to attain the optimal\ntreatment proportions, which may be obtained from the marginal model that\nexcludes the nuisance effects. Moreover, we prove that for a design to be\noptimal, it is sufficient that it attains the optimal treatment proportions and\nsatisfies conditions of resistance to nuisance effects. For selected natural\nchoices of treatment contrasts and optimality criteria, we calculate the\noptimal treatment proportions and give an explicit form of optimal designs. In\nparticular, we obtain optimal treatment proportions for comparison of a set of\nnew treatments with a set of controls. The results allow us to construct a\nmethod of calculating optimal approximate designs with a small support by means\nof linear programming. As a consequence, we can construct efficient exact\ndesigns by a simple heuristic.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2015 08:29:06 GMT"}, {"version": "v2", "created": "Mon, 28 Sep 2015 16:49:16 GMT"}], "update_date": "2016-12-21", "authors_parsed": [["Rosa", "Samuel", ""], ["Harman", "Radoslav", ""]]}, {"id": "1504.06185", "submitter": "Theodoros Moysiadis", "authors": "Theodoros Moysiadis and Konstantinos Fokianos", "title": "On Locally Dyadic Stationary Processes", "comments": "27 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the concept of local dyadic stationarity, to account for\nnon-stationary time series, within the framework of Walsh-Fourier analysis. We\ndefine and study the time varying dyadic ARMA models (tvDARMA). It is proven\nthat the general tvDARMA process can be approximated locally by either a tvDMA\nand a tvDAR process.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2015 13:53:32 GMT"}, {"version": "v2", "created": "Mon, 4 Apr 2016 15:40:47 GMT"}, {"version": "v3", "created": "Mon, 7 Nov 2016 15:09:35 GMT"}], "update_date": "2016-11-08", "authors_parsed": [["Moysiadis", "Theodoros", ""], ["Fokianos", "Konstantinos", ""]]}, {"id": "1504.06246", "submitter": "Gilles Rebelles", "authors": "Gilles Rebelles", "title": "Structural adaptive deconvolution under $L_p$-losses", "comments": "29 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we address the problem of estimating a multidimensional\ndensity $f$ by using indirect observations from the statistical model\n$Y=X+\\varepsilon$. Here, $\\varepsilon$ is a measurement error independent of\nthe random vector $X$ of interest, and having a known density with respect to\nthe Lebesgue measure. Our aim is to obtain optimal accuracy of estimation under\n$L_p$-losses when the error $\\varepsilon$ has a characteristic function with a\npolynomial decay. To achieve this goal, we first construct a kernel estimator\nof $f$ which is fully data driven. Then, we derive for it an oracle inequality\nunder very mild assumptions on the characteristic function of the error\n$\\varepsilon$. As a consequence, we get minimax adaptive upper bounds over a\nlarge scale of anisotropic Nikolskii classes and we prove that our estimator is\nasymptotically rate optimal when $p\\in[2,+\\infty]$. Furthermore, our estimation\nprocedure adapts automatically to the possible independence structure of $f$\nand this allows us to improve significantly the accuracy of estimation.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2015 16:27:58 GMT"}, {"version": "v2", "created": "Wed, 13 May 2015 21:17:06 GMT"}], "update_date": "2015-05-15", "authors_parsed": [["Rebelles", "Gilles", ""]]}, {"id": "1504.06360", "submitter": "Debashis Paul", "authors": "Lili Wang, Alexander Aue and Debashis Paul", "title": "Spectral analysis of linear time series in moderately high dimensions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article is concerned with the spectral behavior of $p$-dimensional\nlinear processes in the moderately high-dimensional case when both\ndimensionality $p$ and sample size $n$ tend to infinity so that $p/n\\to0$. It\nis shown that, under an appropriate set of assumptions, the empirical spectral\ndistributions of the renormalized and symmetrized sample autocovariance\nmatrices converge almost surely to a nonrandom limit distribution supported on\nthe real line. The key assumption is that the linear process is driven by a\nsequence of $p$-dimensional real or complex random vectors with i.i.d. entries\npossessing zero mean, unit variance and finite fourth moments, and that the\n$p\\times p$ linear process coefficient matrices are Hermitian and\nsimultaneously diagonalizable. Several relaxations of these assumptions are\ndiscussed. The results put forth in this paper can help facilitate inference on\nmodel parameters, model diagnostics and prediction of future values of the\nlinear process.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2015 22:59:12 GMT"}], "update_date": "2015-04-27", "authors_parsed": [["Wang", "Lili", ""], ["Aue", "Alexander", ""], ["Paul", "Debashis", ""]]}, {"id": "1504.06384", "submitter": "Dan Cheng Mr.", "authors": "Dan Cheng, Zhibing He and Armin Schwartzman", "title": "Multiple Testing of Local Extrema for Detection of Change Points", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new approach to detect change points based on differential smoothing and\nmultiple testing is presented for long data sequences modeled as piecewise\nconstant functions plus stationary ergodic Gaussian noise. As an application of\nthe STEM algorithm for peak detection developed in\n\\citet{schwartzman2011multiple} and \\citet{cheng2017multiple}, the method\ndetects change points as significant local maxima and minima after smoothing\nand differentiating the observed sequence. The algorithm, combined with the\nBenjamini-Hochberg procedure for thresholding p-values, provides asymptotic\nstrong control of the False Discovery Rate (FDR) and power consistency, as the\nlength of the sequence and the size of the jumps get large. Simulations show\nthat FDR levels are maintained in non-asymptotic conditions and guide the\nchoice of smoothing bandwidth. The methods are illustrated in magnetometer\nsensor data and genomic array-CGH data. An R package named \"dSTEM\" is available\nin R cran.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2015 03:47:47 GMT"}, {"version": "v2", "created": "Tue, 19 Nov 2019 04:53:25 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Cheng", "Dan", ""], ["He", "Zhibing", ""], ["Schwartzman", "Armin", ""]]}, {"id": "1504.06441", "submitter": "Nadji Rahmania", "authors": "Azzouz Dermoune Daoud Ounaissi Nadji Rahmania", "title": "Multilevel Monte Carlo simulation of a diffusion with non-smooth drift", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that Lasso and Bayesian Lasso are very close when the sparsity is\nlarge and the noise is small. Then we propose to solve Bayesian Lasso using\nmultivalued stochastic differential equation. We obtain three discretizations\nalgorithms, and propose a method for calculating the cost of Monte-Carlo (MC),\nmultilevel Monte Carlo (MLMC) and MCMC algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2015 09:36:45 GMT"}], "update_date": "2015-04-27", "authors_parsed": [["Rahmania", "Azzouz Dermoune Daoud Ounaissi Nadji", ""]]}, {"id": "1504.06523", "submitter": "Cyr Emile M'lan", "authors": "Cyr Emile M'lan, Ming-Hui Chen", "title": "Objective Bayesian Inference for Bilateral Data", "comments": "Published at http://dx.doi.org/10.1214/14-BA890 in the Bayesian\n  Analysis (http://projecteuclid.org/euclid.ba) by the International Society of\n  Bayesian Analysis (http://bayesian.org/)", "journal-ref": "Bayesian Analysis 2015, Vol. 10, No. 1, 139-170", "doi": "10.1214/14-BA890", "report-no": "VTeX-BA-BA890", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents three objective Bayesian methods for analyzing bilateral\ndata under Dallal's model and the saturated model. Three parameters are of\ninterest, namely, the risk difference, the risk ratio, and the odds ratio. We\nderive Jeffreys' prior and Bernardo's reference prior associated with the three\nparameters that characterize Dallal's model. We derive the functional forms of\nthe posterior distributions of the risk difference and the risk ratio and\ndiscuss how to sample from their posterior distributions. We demonstrate the\nuse of the proposed methodology with two real data examples. We also\ninvestigate small, moderate, and large sample properties of the proposed\nmethodology and the frequentist counterpart via simulations.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2015 14:27:47 GMT"}], "update_date": "2015-04-27", "authors_parsed": [["M'lan", "Cyr Emile", ""], ["Chen", "Ming-Hui", ""]]}, {"id": "1504.06706", "submitter": "Yoshimasa Uematsu", "authors": "Yoshimasa Uematsu", "title": "Penalized Likelihood Estimation in High-Dimensional Time Series Models\n  and its Application", "comments": "This manuscript includes some theoretically insufficient points that\n  will be fixed", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a general theoretical framework of penalized\nquasi-maximum likelihood (PQML) estimation in stationary multiple time series\nmodels when the number of parameters possibly diverges. We show the oracle\nproperty of the PQML estimator under high-level, but tractable, assumptions,\ncomprising the first half of the paper. Utilizing these results, we propose in\nthe latter half of the paper a method of sparse estimation in high-dimensional\nvector autoregressive (VAR) models. Finally, the usability of the sparse\nhigh-dimensional VAR model is confirmed with a simulation study and an\nempirical analysis on a yield curve forecast.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2015 09:49:30 GMT"}, {"version": "v2", "created": "Tue, 28 Apr 2015 08:27:26 GMT"}, {"version": "v3", "created": "Wed, 26 Apr 2017 21:27:42 GMT"}], "update_date": "2017-04-28", "authors_parsed": [["Uematsu", "Yoshimasa", ""]]}, {"id": "1504.06745", "submitter": "Clint Scovel", "authors": "Houman Owhadi, Clint Scovel", "title": "Extreme points of a ball about a measure with finite support", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that, for the space of Borel probability measures on a Borel subset\nof a Polish metric space, the extreme points of the Prokhorov,\nMonge-Wasserstein and Kantorovich metric balls about a measure whose support\nhas at most n points, consist of measures whose supports have at most n+2\npoints. Moreover, we use the Strassen and Kantorovich-Rubinstein duality\ntheorems to develop representations of supersets of the extreme points based on\nlinear programming, and then develop these representations towards the goal of\ntheir efficient computation.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2015 17:40:24 GMT"}, {"version": "v2", "created": "Mon, 28 Mar 2016 15:19:11 GMT"}], "update_date": "2016-03-29", "authors_parsed": [["Owhadi", "Houman", ""], ["Scovel", "Clint", ""]]}, {"id": "1504.06898", "submitter": "Michael Evans", "authors": "Luai Al-Labadi and Michael Evans", "title": "Optimal Robustness Results for Some Bayesian Procedures and the\n  Relationship to Prior-Data Conflict", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The robustness to the prior of Bayesian inference procedures based on a\nmeasure of statistical evidence are considered. These inferences are shown to\nhave optimal properties with respect to robustness. Furthermore, a connection\nbetween robustness and prior-data conflict is established. In particular, the\ninferences are shown to be effectively robust when the choice of prior does not\nlead to prior-data conflict. When there is prior-data conflict, however,\nrobustness may fail to hold.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2015 00:54:11 GMT"}], "update_date": "2015-04-28", "authors_parsed": [["Al-Labadi", "Luai", ""], ["Evans", "Michael", ""]]}, {"id": "1504.06984", "submitter": "Ery Arias-Castro", "authors": "Ery Arias-Castro, S\\'ebastien Bubeck, G\\'abor Lugosi and Nicolas\n  Verzelen", "title": "Detecting Markov Random Fields Hidden in White Noise", "comments": "In the 2nd version we removed the part on path detection, which will\n  appear on its own in a separate paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by change point problems in time series and the detection of\ntextured objects in images, we consider the problem of detecting a piece of a\nGaussian Markov random field hidden in white Gaussian noise. We derive minimax\nlower bounds and propose near-optimal tests.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2015 09:17:16 GMT"}, {"version": "v2", "created": "Wed, 14 Oct 2015 16:00:51 GMT"}], "update_date": "2015-10-15", "authors_parsed": [["Arias-Castro", "Ery", ""], ["Bubeck", "S\u00e9bastien", ""], ["Lugosi", "G\u00e1bor", ""], ["Verzelen", "Nicolas", ""]]}, {"id": "1504.06999", "submitter": "Irene Crimaldi", "authors": "Irene Crimaldi", "title": "Central limit theorems for a hypergeometric randomly reinforced urn", "comments": "15 pages, submitted, Key-words: Central Limit Theorem; Polya urn;\n  Randomly Reinforced Urn; Stable Convergence", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a variant of the randomly reinforced urn where more balls can be\nsimultaneously drawn out and balls of different colors can be simultaneously\nadded. More precisely, at each time-step, the conditional distribution of the\nnumber of extracted balls of a certain color given the past is assumed to be\nhypergeometric. We prove some central limit theorems in the sense of stable\nconvergence and of almost sure conditional convergence, which are stronger than\nconvergence in distribution. The proven results provide asymptotic confidence\nintervals for the limit proportion, whose distribution is generally unknown.\nMoreover, we also consider the case of more urns subjected to some random\ncommon factors.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2015 09:36:51 GMT"}, {"version": "v2", "created": "Wed, 8 Jul 2015 08:12:37 GMT"}], "update_date": "2015-07-09", "authors_parsed": [["Crimaldi", "Irene", ""]]}, {"id": "1504.07046", "submitter": "Siva Sivaganesan", "authors": "Siva Sivaganesan", "title": "Comment on Article by Berger, Bernardo, and Sun", "comments": "Published at http://dx.doi.org/10.1214/14-BA935 in the Bayesian\n  Analysis (http://projecteuclid.org/euclid.ba) by the International Society of\n  Bayesian Analysis (http://bayesian.org/)", "journal-ref": "Bayesian Analysis 2015, Vol. 10, No. 1, 223-226", "doi": "10.1214/14-BA935", "report-no": "VTeX-BA-BA935", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discussion of Overall Objective Priors by James O. Berger, Jose M. Bernardo,\nDongchu Sun [arXiv:1504.02689].\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2015 12:18:13 GMT"}], "update_date": "2015-04-28", "authors_parsed": [["Sivaganesan", "Siva", ""]]}, {"id": "1504.07054", "submitter": "Ritabrata Sengupta", "authors": "K. R. Parthasarathy and Ritabrata Sengupta", "title": "From particle counting to Gaussian tomography", "comments": null, "journal-ref": "Infin. Dimens. Anal. Quantum Probab. Relat. Top., 18(4):1550023\n  [21 pages], Dec 2015", "doi": "10.1142/S021902571550023X", "report-no": null, "categories": "quant-ph math.FA math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  All the $n(2n+3)$ mean and covariance parameters of an $n$-mode Gaussian\nstates are expressed in terms of the expectation values of the same number of\nconjugates of the total number observable. This permits a complete tomography\nof the state. The same is applied to outputs of a Gaussian channel\ncorresponding to selected coherent states to perform the complete tomography of\nthe channel. This leads to some interesting problems concerning the\ndistribution of the number operator and also tomographic complexity.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2015 12:31:33 GMT"}], "update_date": "2016-01-14", "authors_parsed": [["Parthasarathy", "K. R.", ""], ["Sengupta", "Ritabrata", ""]]}, {"id": "1504.07072", "submitter": "Judith Rousseau", "authors": "Judith Rousseau", "title": "Comment on Article by Berger, Bernardo, and Sun", "comments": "Published at http://dx.doi.org/10.1214/14-BA937 in the Bayesian\n  Analysis (http://projecteuclid.org/euclid.ba) by the International Society of\n  Bayesian Analysis (http://bayesian.org/)", "journal-ref": "Bayesian Analysis 2015, Vol. 10, No. 1, 233-236", "doi": "10.1214/14-BA937", "report-no": "VTeX-BA-BA937", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discussion of Overall Objective Priors by James O. Berger, Jose M. Bernardo,\nDongchu Sun [arXiv:1504.02689].\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2015 13:11:46 GMT"}], "update_date": "2015-04-28", "authors_parsed": [["Rousseau", "Judith", ""]]}, {"id": "1504.07078", "submitter": "Gauri Sankar Datta", "authors": "Gauri Sankar Datta, Brunero Liseo", "title": "Comment on Article by Berger, Bernardo, and Sun", "comments": "Published at http://dx.doi.org/10.1214/14-BA938 in the Bayesian\n  Analysis (http://projecteuclid.org/euclid.ba) by the International Society of\n  Bayesian Analysis (http://bayesian.org/)", "journal-ref": "Bayesian Analysis 2015, Vol. 10, No. 1, 237-241", "doi": "10.1214/14-BA938", "report-no": "VTeX-BA-BA938", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discussion of Overall Objective Priors by James O. Berger, Jose M. Bernardo,\nDongchu Sun [arXiv:1504.02689].\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2015 13:25:53 GMT"}], "update_date": "2015-04-28", "authors_parsed": [["Datta", "Gauri Sankar", ""], ["Liseo", "Brunero", ""]]}, {"id": "1504.07081", "submitter": "James O. Berger", "authors": "James O. Berger, Jose M. Bernardo, Dongchu Sun", "title": "Rejoinder to Article by Berger, Bernardo, and Sun", "comments": "Published at http://dx.doi.org/10.1214/15-BA943 in the Bayesian\n  Analysis (http://projecteuclid.org/euclid.ba) by the International Society of\n  Bayesian Analysis (http://bayesian.org/)", "journal-ref": "Bayesian Analysis 2015, Vol. 10, No. 1, 243-246", "doi": "10.1214/15-BA943", "report-no": "VTeX-BA-BA943", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rejoinder to Overall Objective Priors by James O. Berger, Jose M. Bernardo,\nDongchu Sun [arXiv:1504.02689]\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2015 13:35:18 GMT"}], "update_date": "2015-04-28", "authors_parsed": [["Berger", "James O.", ""], ["Bernardo", "Jose M.", ""], ["Sun", "Dongchu", ""]]}, {"id": "1504.07218", "submitter": "Yuxin Chen", "authors": "Yuxin Chen, Changho Suh", "title": "Spectral MLE: Top-$K$ Rank Aggregation from Pairwise Comparisons", "comments": "accepted to International Conference on Machine Learning (ICML), 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS cs.IT math.IT math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores the preference-based top-$K$ rank aggregation problem.\nSuppose that a collection of items is repeatedly compared in pairs, and one\nwishes to recover a consistent ordering that emphasizes the top-$K$ ranked\nitems, based on partially revealed preferences. We focus on the\nBradley-Terry-Luce (BTL) model that postulates a set of latent preference\nscores underlying all items, where the odds of paired comparisons depend only\non the relative scores of the items involved.\n  We characterize the minimax limits on identifiability of top-$K$ ranked\nitems, in the presence of random and non-adaptive sampling. Our results\nhighlight a separation measure that quantifies the gap of preference scores\nbetween the $K^{\\text{th}}$ and $(K+1)^{\\text{th}}$ ranked items. The minimum\nsample complexity required for reliable top-$K$ ranking scales inversely with\nthe separation measure irrespective of other preference distribution metrics.\nTo approach this minimax limit, we propose a nearly linear-time ranking scheme,\ncalled \\emph{Spectral MLE}, that returns the indices of the top-$K$ items in\naccordance to a careful score estimate. In a nutshell, Spectral MLE starts with\nan initial score estimate with minimal squared loss (obtained via a spectral\nmethod), and then successively refines each component with the assistance of\ncoordinate-wise MLEs. Encouragingly, Spectral MLE allows perfect top-$K$ item\nidentification under minimal sample complexity. The practical applicability of\nSpectral MLE is further corroborated by numerical experiments.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2015 19:30:01 GMT"}, {"version": "v2", "created": "Thu, 28 May 2015 06:04:15 GMT"}], "update_date": "2015-05-29", "authors_parsed": [["Chen", "Yuxin", ""], ["Suh", "Changho", ""]]}, {"id": "1504.07320", "submitter": "Manuel Mendoza", "authors": "Manuel Mendoza, Eduardo Guti\\'errez-Pe\\~na", "title": "Comment on Article by Berger, Bernardo, and Sun", "comments": "Published at http://dx.doi.org/10.1214/14-BA936 in the Bayesian\n  Analysis (http://projecteuclid.org/euclid.ba) by the International Society of\n  Bayesian Analysis (http://bayesian.org/)", "journal-ref": "Bayesian Analysis 2015, Vol. 10, No. 1, 227-231", "doi": "10.1214/14-BA936", "report-no": "VTeX-BA-BA936", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discussion of Overall Objective Priors by James O. Berger, Jose M. Bernardo,\nDongchu Sun [arXiv:1504.02689].\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2015 08:18:55 GMT"}], "update_date": "2015-04-29", "authors_parsed": [["Mendoza", "Manuel", ""], ["Guti\u00e9rrez-Pe\u00f1a", "Eduardo", ""]]}, {"id": "1504.07333", "submitter": "Karim Lounici", "authors": "Vladimir Koltchinskii and Karim Lounici", "title": "Normal approximation and concentration of spectral projectors of sample\n  covariance", "comments": "arXiv admin note: text overlap with arXiv:1408.4643", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $X,X_1,\\dots, X_n$ be i.i.d. Gaussian random variables in a separable\nHilbert space ${\\mathbb H}$ with zero mean and covariance operator\n$\\Sigma={\\mathbb E}(X\\otimes X),$ and let $\\hat \\Sigma:=n^{-1}\\sum_{j=1}^n\n(X_j\\otimes X_j)$ be the sample (empirical) covariance operator based on\n$(X_1,\\dots, X_n).$ Denote by $P_r$ the spectral projector of $\\Sigma$\ncorresponding to its $r$-th eigenvalue $\\mu_r$ and by $\\hat P_r$ the empirical\ncounterpart of $P_r.$ The main goal of the paper is to obtain tight bounds on\n$$ \\sup_{x\\in {\\mathbb R}} \\left|{\\mathbb P}\\left\\{\\frac{\\|\\hat\nP_r-P_r\\|_2^2-{\\mathbb E}\\|\\hat P_r-P_r\\|_2^2}{{\\rm Var}^{1/2}(\\|\\hat\nP_r-P_r\\|_2^2)}\\leq x\\right\\}-\\Phi(x)\\right|, $$ where $\\|\\cdot\\|_2$ denotes\nthe Hilbert--Schmidt norm and $\\Phi$ is the standard normal distribution\nfunction. Such accuracy of normal approximation of the distribution of squared\nHilbert--Schmidt error is characterized in terms of so called effective rank of\n$\\Sigma$ defined as ${\\bf r}(\\Sigma)=\\frac{{\\rm\ntr}(\\Sigma)}{\\|\\Sigma\\|_{\\infty}},$ where ${\\rm tr}(\\Sigma)$ is the trace of\n$\\Sigma$ and $\\|\\Sigma\\|_{\\infty}$ is its operator norm, as well as another\nparameter characterizing the size of ${\\rm Var}(\\|\\hat P_r-P_r\\|_2^2).$ Other\nresults include non-asymptotic bounds and asymptotic representations for the\nmean squared Hilbert--Schmidt norm error ${\\mathbb E}\\|\\hat P_r-P_r\\|_2^2$ and\nthe variance ${\\rm Var}(\\|\\hat P_r-P_r\\|_2^2),$ and concentration inequalities\nfor $\\|\\hat P_r-P_r\\|_2^2$ around its expectation.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2015 02:38:44 GMT"}], "update_date": "2015-04-29", "authors_parsed": [["Koltchinskii", "Vladimir", ""], ["Lounici", "Karim", ""]]}, {"id": "1504.07336", "submitter": "Mohammad Jafari Jozani", "authors": "Armin Hatefi and Mohammad Jafari Jozani", "title": "Information content of partially rank-ordered set samples", "comments": "24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.OT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Partially rank-ordered set (PROS) sampling is a generalization of ranked set\nsampling in which rankers are not required to fully rank the sampling units in\neach set, hence having more flexibility to perform the necessary judgemental\nranking process. The PROS sampling has a wide range of applications in\ndifferent fields ranging from environmental and ecological studies to medical\nresearch and it has been shown to be superior over ranked set sampling and\nsimple random sampling for estimating the population mean. In this paper, we\nstudy the Fisher information content and uncertainty structure of the PROS\nsamples and compare them with those of simple random sample (SRS) and ranked\nset sample (RSS) counterparts of the same size from the underlying population.\nWe study the uncertainty structure in terms of the Shannon entropy, Renyi\nentropy and Kullback-Leibler (KL) discrimination measures. Several examples\nincluding the FI of PROS samples from the location-scale family of\ndistributions as well as a regression model are discussed.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2015 03:09:52 GMT"}], "update_date": "2015-04-29", "authors_parsed": [["Hatefi", "Armin", ""], ["Jozani", "Mohammad Jafari", ""]]}, {"id": "1504.07390", "submitter": "Frank Werner", "authors": "Farida Enikeeva, Axel Munk and Frank Werner", "title": "Bump detection in heterogeneous Gaussian regression", "comments": "32 pages, 6 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the effect of a heterogeneous variance on bump detection in a\nGaussian regression model. To this end we allow for a simultaneous bump in the\nvariance and specify its impact on the difficulty to detect the null signal\nagainst a single bump with known signal strength. This is done by calculating\nlower and upper bounds, both based on the likelihood ratio. Lower and upper\nbounds together lead to explicit characterizations of the detection boundary in\nseveral subregimes depending on the asymptotic behavior of the bump heights in\nmean and variance. In particular, we explicitly identify those regimes, where\nthe additional information about a simultaneous bump in variance eases the\ndetection problem for the signal. This effect is made explicit in the constant\nand / or the rate, appearing in the detection boundary. We also discuss the\ncase of an unknown bump height and provide an adaptive test and some upper\nbounds in that case.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2015 09:30:06 GMT"}, {"version": "v2", "created": "Fri, 29 Jan 2016 10:32:42 GMT"}, {"version": "v3", "created": "Tue, 3 May 2016 10:02:23 GMT"}], "update_date": "2016-05-04", "authors_parsed": [["Enikeeva", "Farida", ""], ["Munk", "Axel", ""], ["Werner", "Frank", ""]]}, {"id": "1504.07645", "submitter": "Konstantinos Spiliopoulos", "authors": "Siragan Gailus, Konstantinos Spiliopoulos", "title": "Statistical Inference for Perturbed Multiscale Dynamical Systems", "comments": "Final form of the paper will appear in Stochastic Processes and their\n  Applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study statistical inference for small-noise-perturbed multiscale dynamical\nsystems. We prove consistency, asymptotic normality, and convergence of all\nscaled moments of an appropriately-constructed maximum likelihood estimator\n(MLE) for a parameter of interest, identifying precisely its limiting variance.\nWe allow full dependence of coefficients on both slow and fast processes, which\ntake values in the full Euclidean space; coefficients in the equation for the\nslow process need not be bounded and there is no assumption of periodic\ndependence. The results provide a theoretical basis for calibration of\nsmall-noise-perturbed multiscale dynamical systems. Data from numerical\nsimulations are presented to illustrate the theory.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2015 20:14:42 GMT"}, {"version": "v2", "created": "Wed, 13 Jan 2016 19:44:57 GMT"}, {"version": "v3", "created": "Wed, 15 Jun 2016 19:36:48 GMT"}], "update_date": "2016-06-16", "authors_parsed": [["Gailus", "Siragan", ""], ["Spiliopoulos", "Konstantinos", ""]]}, {"id": "1504.07972", "submitter": "Suzanne Sniekers", "authors": "Suzanne Sniekers, Aad van der Vaart", "title": "Adaptive Bayesian credible sets in regression with a Gaussian process\n  prior", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate two empirical Bayes methods and a hierarchical Bayes method\nfor adapting the scale of a Gaussian process prior in a nonparametric\nregression model. We show that all methods lead to a posterior contraction rate\nthat adapts to the smoothness of the true regression function. Furthermore, we\nshow that the corresponding credible sets cover the true regression function\nwhenever this function satisfies a certain extrapolation condition. This\ncondition depends on the specific method, but is implied by a condition of\nself-similarity. The latter condition is shown to be satisfied with probability\none under the prior distribution.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2015 19:21:10 GMT"}], "update_date": "2015-04-30", "authors_parsed": [["Sniekers", "Suzanne", ""], ["van der Vaart", "Aad", ""]]}, {"id": "1504.08031", "submitter": "Xiaoying Tian Harris", "authors": "Xiaoying Tian, and Joshua R. Loftus, and Jonathan E. Taylor", "title": "Selective inference with unknown variance via the square-root LASSO", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been much recent work on inference after model selection when the\nnoise level is known, however, $\\sigma$ is rarely known in practice and its\nestimation is difficult in high-dimensional settings. In this work we propose\nusing the square-root LASSO (also known as the scaled LASSO) to perform\nselective inference for the coefficients and the noise level simultaneously.\nThe square-root LASSO has the property that choosing a reasonable tuning\nparameter is scale-free, namely it does not depend on the noise level in the\ndata. We provide valid p-values and confidence intervals for the coefficients\nafter selection, and estimates for model specific variance. Our estimates\nperform better than other estimates of $\\sigma^2$ in simulation.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2015 21:38:34 GMT"}, {"version": "v2", "created": "Thu, 9 Feb 2017 22:41:48 GMT"}], "update_date": "2017-02-13", "authors_parsed": [["Tian", "Xiaoying", ""], ["Loftus", "Joshua R.", ""], ["Taylor", "Jonathan E.", ""]]}, {"id": "1504.08070", "submitter": "Moein  Falahatgar", "authors": "Moein Falahatgar and Ashkan Jafarpour and Alon Orlitsky and\n  Venkatadheeraj Pichapati and Ananda Theertha Suresh", "title": "Universal Compression of Power-Law Distributions", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  English words and the outputs of many other natural processes are well-known\nto follow a Zipf distribution. Yet this thoroughly-established property has\nnever been shown to help compress or predict these important processes. We show\nthat the expected redundancy of Zipf distributions of order $\\alpha>1$ is\nroughly the $1/\\alpha$ power of the expected redundancy of unrestricted\ndistributions. Hence for these orders, Zipf distributions can be better\ncompressed and predicted than was previously known. Unlike the expected case,\nwe show that worst-case redundancy is roughly the same for Zipf and for\nunrestricted distributions. Hence Zipf distributions have significantly\ndifferent worst-case and expected redundancies, making them the first natural\ndistribution class shown to have such a difference.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2015 03:31:05 GMT"}, {"version": "v2", "created": "Fri, 1 May 2015 01:01:37 GMT"}], "update_date": "2015-05-04", "authors_parsed": [["Falahatgar", "Moein", ""], ["Jafarpour", "Ashkan", ""], ["Orlitsky", "Alon", ""], ["Pichapati", "Venkatadheeraj", ""], ["Suresh", "Ananda Theertha", ""]]}, {"id": "1504.08177", "submitter": "Pradeep Kr. Banerjee", "authors": "Pradeep Kr. Banerjee and Nirmal B. Chakrabarti", "title": "Noise Sensitivity of Teager-Kaiser Energy Operators and Their Ratios", "comments": "7 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD math.ST physics.data-an stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Teager-Kaiser energy operator (TKO) belongs to a class of autocorrelators\nand their linear combination that can track the instantaneous energy of a\nnonstationary sinusoidal signal source. TKO-based monocomponent AM-FM\ndemodulation algorithms work under the basic assumption that the operator\noutputs are always positive. In the absence of noise, this is assured for pure\nsinusoidal inputs and the instantaneous property is also guaranteed. Noise\ninvalidates both of these, particularly under small signal conditions.\nPost-detection filtering and thresholding are of use to reestablish these at\nthe cost of some time to acquire. Key questions are: (a) how many samples must\none use and (b) how much noise power at the detector input can one tolerate.\nResults of study of the role of delay and the limits imposed by additive\nGaussian noise are presented along with the computation of the cumulants and\nprobability density functions of the individual quadratic forms and their\nratios.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2015 11:49:38 GMT"}, {"version": "v2", "created": "Sat, 30 May 2015 02:21:43 GMT"}], "update_date": "2015-06-02", "authors_parsed": [["Banerjee", "Pradeep Kr.", ""], ["Chakrabarti", "Nirmal B.", ""]]}, {"id": "1504.08295", "submitter": "Madalin Guta", "authors": "Cristina Butucea, Madalin Guta and Theodore Kypraios", "title": "Spectral thresholding quantum tomography for low rank states", "comments": "35pages, 19 figures", "journal-ref": null, "doi": "10.1088/1367-2630/17/11/113050", "report-no": null, "categories": "quant-ph math-ph math.MP math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The estimation of high dimensional quantum states is an important statistical\nproblem arising in current quantum technology applications. A key example is\nthe tomography of multiple ions states, employed in the validation of state\npreparation in ion trap experiments \\cite{Haffner2005}. Since full tomography\nbecomes unfeasible even for a small number of ions, there is a need to\ninvestigate lower dimensional statistical models which capture prior\ninformation about the state, and to devise estimation methods tailored to such\nmodels. In this paper we propose several new methods aimed at the efficient\nestimation of low rank states in multiple ions tomography. All methods consist\nin first computing the least squares estimator, followed by its truncation to\nan appropriately chosen smaller rank. The latter is done by setting eigenvalues\nbelow a certain \"noise level\" to zero, while keeping the rest unchanged, or\nnormalising them appropriately. We show that (up to logarithmic factors in the\nspace dimension) the mean square error of the resulting estimators scales as\n$r\\cdot d/N$ where $r$ is the rank, $d=2^k$ is the dimension of the Hilbert\nspace, and $N$ is the number of quantum samples. Furthermore we establish a\nlower bound for the asymptotic minimax risk which shows that the above scaling\nis optimal. The performance of the estimators is analysed in an extensive\nsimulations study, with emphasis on the dependence on the state rank, and the\nnumber of measurement repetitions. We find that all estimators perform\nsignificantly better that the least squares, with the \"physical estimator\"\n(which is a bona fide density matrix) slightly outperforming the other\nestimators.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2015 16:31:06 GMT"}], "update_date": "2015-12-09", "authors_parsed": [["Butucea", "Cristina", ""], ["Guta", "Madalin", ""], ["Kypraios", "Theodore", ""]]}, {"id": "1504.08363", "submitter": "Gautam Kamath", "authors": "Constantinos Daskalakis and Gautam Kamath and Christos Tzamos", "title": "On the Structure, Covering, and Learning of Poisson Multinomial\n  Distributions", "comments": "49 pages, extended abstract appeared in FOCS 2015", "journal-ref": null, "doi": "10.1109/FOCS.2015.77", "report-no": null, "categories": "cs.DS cs.LG math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An $(n,k)$-Poisson Multinomial Distribution (PMD) is the distribution of the\nsum of $n$ independent random vectors supported on the set ${\\cal\nB}_k=\\{e_1,\\ldots,e_k\\}$ of standard basis vectors in $\\mathbb{R}^k$. We prove\na structural characterization of these distributions, showing that, for all\n$\\varepsilon >0$, any $(n, k)$-Poisson multinomial random vector is\n$\\varepsilon$-close, in total variation distance, to the sum of a discretized\nmultidimensional Gaussian and an independent $(\\text{poly}(k/\\varepsilon),\nk)$-Poisson multinomial random vector. Our structural characterization extends\nthe multi-dimensional CLT of Valiant and Valiant, by simultaneously applying to\nall approximation requirements $\\varepsilon$. In particular, it overcomes\nfactors depending on $\\log n$ and, importantly, the minimum eigenvalue of the\nPMD's covariance matrix from the distance to a multidimensional Gaussian random\nvariable.\n  We use our structural characterization to obtain an $\\varepsilon$-cover, in\ntotal variation distance, of the set of all $(n, k)$-PMDs, significantly\nimproving the cover size of Daskalakis and Papadimitriou, and obtaining the\nsame qualitative dependence of the cover size on $n$ and $\\varepsilon$ as the\n$k=2$ cover of Daskalakis and Papadimitriou. We further exploit this structure\nto show that $(n,k)$-PMDs can be learned to within $\\varepsilon$ in total\nvariation distance from $\\tilde{O}_k(1/\\varepsilon^2)$ samples, which is\nnear-optimal in terms of dependence on $\\varepsilon$ and independent of $n$. In\nparticular, our result generalizes the single-dimensional result of Daskalakis,\nDiakonikolas, and Servedio for Poisson Binomials to arbitrary dimension.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2015 19:53:03 GMT"}, {"version": "v2", "created": "Mon, 19 Oct 2015 00:04:51 GMT"}, {"version": "v3", "created": "Mon, 23 Nov 2015 20:58:00 GMT"}], "update_date": "2015-11-24", "authors_parsed": [["Daskalakis", "Constantinos", ""], ["Kamath", "Gautam", ""], ["Tzamos", "Christos", ""]]}]