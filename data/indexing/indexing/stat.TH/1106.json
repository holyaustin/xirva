[{"id": "1106.0192", "submitter": "Davit Varron", "authors": "Davit Varron", "title": "The almost sure behavior of certain spatial repartitions of local\n  empirical processes indexed by functions", "comments": "The paper ha been withdrawn by the author due to an incorrect Poisson\n  representation which seriously affects the clarity of the proofs", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate a particular form of weak convergence of the local empirical\nprocess.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jun 2011 14:42:41 GMT"}, {"version": "v2", "created": "Tue, 21 Feb 2012 11:27:29 GMT"}], "update_date": "2012-02-22", "authors_parsed": [["Varron", "Davit", ""]]}, {"id": "1106.0321", "submitter": "Anatoli Juditsky B.", "authors": "Elmar Diederichs, Anatoli Juditsky, Arkadi Nemirovski, and Vladimir\n  Spokoiny", "title": "Sparse Non Gaussian Component Analysis by Semidefinite Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.OC stat.CO stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse non-Gaussian component analysis (SNGCA) is an unsupervised method of\nextracting a linear structure from a high dimensional data based on estimating\na low-dimensional non-Gaussian data component. In this paper we discuss a new\napproach to direct estimation of the projector on the target space based on\nsemidefinite programming which improves the method sensitivity to a broad\nvariety of deviations from normality. We also discuss the procedures which\nallows to recover the structure when its effective dimension is unknown.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jun 2011 21:04:00 GMT"}, {"version": "v2", "created": "Thu, 10 Nov 2011 21:26:58 GMT"}, {"version": "v3", "created": "Fri, 13 Jan 2012 23:32:26 GMT"}], "update_date": "2012-01-17", "authors_parsed": [["Diederichs", "Elmar", ""], ["Juditsky", "Anatoli", ""], ["Nemirovski", "Arkadi", ""], ["Spokoiny", "Vladimir", ""]]}, {"id": "1106.0617", "submitter": "David A. Rolls", "authors": "David A. Rolls", "title": "Reduced long-range dependence combining Poisson bursts with on--off\n  sources", "comments": "Published in at http://dx.doi.org/10.1214/09-BJPS105 the Brazilian\n  Journal of Probability and Statistics (http://www.imstat.org/bjps/) by the\n  Brazilian Statistical Association/Institute of Mathematical Statistics\n  (http://www.redeabe.org.br/)", "journal-ref": "Brazilian Journal of Probability and Statistics 2010, Vol. 24, No.\n  3, 479-501", "doi": "10.1214/09-BJPS105", "report-no": "IMS-BJPS-BJPS105", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A workload model using the infinite source Poisson model for bursts is\ncombined with the on--off model for within burst activity. Burst durations and\non--off durations are assumed to have heavy-tailed distributions with infinite\nvariance and finite mean. Since the number of bursts is random, one can\nconsider limiting results based on \"random centering\" of a random sum for the\ntotal workload from all sources. Convergence results are shown to depend on the\ntail indices of both the on--off durations and the lifetimes distributions.\nMoreover, the results can be separated into cases depending on those tail\nindices. In one case where all distributions are heavy tailed it is shown that\nthe limiting result is Brownian motion. In another case, convergence to\nfractional Brownian motion is shown, where the Hurst parameter depends on the\nheavy-tail indices of the distribution of the on, off and burst durations.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jun 2011 12:07:30 GMT"}], "update_date": "2011-06-06", "authors_parsed": [["Rolls", "David A.", ""]]}, {"id": "1106.0721", "submitter": "Jingchen Liu", "authors": "Jingchen Liu, Gongjun Xu, and Zhiliang Ying", "title": "Learning Item-Attribute Relationship in Q-Matrix Based Diagnostic\n  Classification Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent surge of interests in cognitive assessment has led to the developments\nof novel statistical models for diagnostic classification. Central to many such\nmodels is the well-known Q-matrix, which specifies the item-attribute\nrelationship. This paper proposes a principled estimation procedure for the\nQ-matrix and related model parameters. Desirable theoretic properties are\nestablished through large sample analysis. The proposed method also provides a\nplatform under which important statistical issues, such as hypothesis testing\nand model selection, can be addressed.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jun 2011 18:06:06 GMT"}], "update_date": "2011-06-06", "authors_parsed": [["Liu", "Jingchen", ""], ["Xu", "Gongjun", ""], ["Ying", "Zhiliang", ""]]}, {"id": "1106.0972", "submitter": "Kjetil R{\\o}ysland", "authors": "Kjetil R{\\o}ysland", "title": "Counterfactual analyses with graphical models based on local\n  independence", "comments": "Published in at http://dx.doi.org/10.1214/12-AOS1031 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2012, Vol. 40, No. 4, 2162-2194", "doi": "10.1214/12-AOS1031", "report-no": "IMS-AOS-AOS1031", "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that one can perform causal inference in a natural way for\ncontinuous-time scenarios using tools from stochastic analysis. This provides\nnew alternatives to the positivity condition for inverse probability weighting.\nThe probability distribution that would govern the frequency of observations in\nthe counterfactual scenario can be characterized in terms of a so-called\nmartingale problem. The counterfactual and factual probability distributions\nmay be related through a likelihood ratio given by a stochastic differential\nequation. We can perform inference for counterfactual scenarios based on the\noriginal observations, re-weighted according to this likelihood ratio. This is\npossible if the solution of the stochastic differential equation is uniformly\nintegrable, a property that can be determined by comparing the corresponding\nfactual and counterfactual short-term predictions. Local independence graphs\nare directed, possibly cyclic, graphs that represent short-term prediction\namong sufficiently autonomous stochastic processes. We show through an example\nthat these graphs can be used to identify and provide consistent estimators for\ncounterfactual parameters in continuous time. This is analogous to how Judea\nPearl uses graphical information to identify causal effects in finite state\nBayesian networks.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jun 2011 07:06:16 GMT"}, {"version": "v2", "created": "Mon, 30 Jul 2012 11:26:28 GMT"}, {"version": "v3", "created": "Mon, 22 Apr 2013 05:34:01 GMT"}], "update_date": "2013-04-23", "authors_parsed": [["R\u00f8ysland", "Kjetil", ""]]}, {"id": "1106.1031", "submitter": "C\\'eline Duval", "authors": "C\\'eline Duval and Marc Hoffmann", "title": "Statistical inference across time scales", "comments": "29 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate statistical inference across time scales. We take as toy model\nthe estimation of the intensity of a discretely observed compound Poisson\nprocess with symmetric Bernoulli jumps. We have data at different time scales:\nmicroscopic, intermediate and macroscopic. We quantify the smooth statistical\ntransition from a microscopic Poissonian regime to a macroscopic Gaussian\nregime. The classical quadratic variation estimator is efficient in both\nmicroscopic and macroscopic scales but surprisingly shows a substantial loss of\ninformation in the intermediate scale that can be explicitly related to the\nsampling rate. We discuss the implications of these findings beyond this\nidealised framework.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jun 2011 11:44:32 GMT"}], "update_date": "2011-06-07", "authors_parsed": [["Duval", "C\u00e9line", ""], ["Hoffmann", "Marc", ""]]}, {"id": "1106.1056", "submitter": "Francois Portier", "authors": "Fran\\c{c}ois Portier (IRMAR), Bernard Delyon (IRMAR)", "title": "Test function: A new approach for covering the central subspace", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we offer a complete methodology for sufficient dimension\nreduction called the test function (TF). TF provides a new family of methods\nfor the estimation of the central subspace (CS) based on the introduction of a\nnonlinear transformation of the response. Theoretical background of TF is\ndeveloped under weaker conditions than the existing methods. By considering\norder 1 and 2 conditional moments of the predictor given the response, we\ndivide TF in two classes. In each class we provide conditions that guarantee an\nexhaustive estimation of the CS. Besides, the optimal members are calculated\nvia the minimization of the asymptotic mean squared error deriving from the\ndistance between the CS and its estimate. This leads us to two plug-in methods\nwhich are evaluated with several simulations.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jun 2011 13:10:56 GMT"}], "update_date": "2011-06-08", "authors_parsed": [["Portier", "Fran\u00e7ois", "", "IRMAR"], ["Delyon", "Bernard", "", "IRMAR"]]}, {"id": "1106.1151", "submitter": "Shuheng Zhou", "authors": "Mark Rudelson and Shuheng Zhou", "title": "Reconstruction from anisotropic random measurements", "comments": "30 Pages", "journal-ref": null, "doi": null, "report-no": "Technical Report 522, University of Michigan, Department of\n  Statistics", "categories": "math.ST cs.IT math.FA math.IT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random matrices are widely used in sparse recovery problems, and the relevant\nproperties of matrices with i.i.d. entries are well understood. The current\npaper discusses the recently introduced Restricted Eigenvalue (RE) condition,\nwhich is among the most general assumptions on the matrix, guaranteeing\nrecovery. We prove a reduction principle showing that the RE condition can be\nguaranteed by checking the restricted isometry on a certain family of\nlow-dimensional subspaces. This principle allows us to establish the RE\ncondition for several broad classes of random matrices with dependent entries,\nincluding random matrices with subgaussian rows and non-trivial covariance\nstructure, as well as matrices with independent rows, and uniformly bounded\nentries.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jun 2011 19:00:04 GMT"}], "update_date": "2011-06-07", "authors_parsed": [["Rudelson", "Mark", ""], ["Zhou", "Shuheng", ""]]}, {"id": "1106.1193", "submitter": "Ery Arias-Castro", "authors": "Ery Arias-Castro, S\\'ebastien Bubeck, G\\'abor Lugosi", "title": "Detection of correlations", "comments": "Published in at http://dx.doi.org/10.1214/11-AOS964 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2012, Vol. 40, No. 1, 412-435", "doi": "10.1214/11-AOS964", "report-no": "IMS-AOS-AOS964", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the hypothesis testing problem of deciding whether an observed\nhigh-dimensional vector has independent normal components or, alternatively, if\nit has a small subset of correlated components. The correlated components may\nhave a certain combinatorial structure known to the statistician. We establish\nupper and lower bounds for the worst-case (minimax) risk in terms of the size\nof the correlated subset, the level of correlation, and the structure of the\nclass of possibly correlated sets. We show that some simple tests have\nnear-optimal performance in many cases, while the generalized likelihood ratio\ntest is suboptimal in some important cases.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jun 2011 20:30:53 GMT"}, {"version": "v2", "created": "Fri, 1 Jun 2012 07:57:59 GMT"}], "update_date": "2012-06-04", "authors_parsed": [["Arias-Castro", "Ery", ""], ["Bubeck", "S\u00e9bastien", ""], ["Lugosi", "G\u00e1bor", ""]]}, {"id": "1106.1497", "submitter": "Jamal Najim", "authors": "Walid Hachem (LTCI), Philippe Loubaton (LIGM), X. Mestre (CTTC), Jamal\n  Najim (LTCI), Pascal Vallet (LIGM)", "title": "A Subspace Estimator for Fixed Rank Perturbations of Large Random\n  Matrices", "comments": "Assumption A6 has been modified (the speed of convergence of the\n  matrix S*S to its limit must be controlled). Proof of Proposition 3 has been\n  added accordingly. This article is accepted for publication in Journal of\n  Multivariate Analysis", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with the problem of parameter estimation based on certain\neigenspaces of the empirical covariance matrix of an observed multidimensional\ntime series, in the case where the time series dimension and the observation\nwindow grow to infinity at the same pace. In the area of large random matrix\ntheory, recent contributions studied the behavior of the extreme eigenvalues of\na random matrix and their associated eigenspaces when this matrix is subject to\na fixed-rank perturbation. The present work is concerned with the situation\nwhere the parameters to be estimated determine the eigenspace structure of a\ncertain fixed-rank perturbation of the empirical covariance matrix. An\nestimation algorithm in the spirit of the well-known MUSIC algorithm for\nparameter estimation is developed. It relies on an approach recently developed\nby Benaych-Georges and Nadakuditi, relating the eigenspaces of extreme\neigenvalues of the empirical covariance matrix with eigenspaces of the\nperturbation matrix. First and second order analyses of the new algorithm are\nperformed.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jun 2011 05:01:38 GMT"}, {"version": "v2", "created": "Tue, 21 Aug 2012 12:45:37 GMT"}], "update_date": "2012-08-22", "authors_parsed": [["Hachem", "Walid", "", "LTCI"], ["Loubaton", "Philippe", "", "LIGM"], ["Mestre", "X.", "", "CTTC"], ["Najim", "Jamal", "", "LTCI"], ["Vallet", "Pascal", "", "LIGM"]]}, {"id": "1106.1638", "submitter": "Tilmann Gneiting", "authors": "Tilmann Gneiting and Roopesh Ranjan", "title": "Combining Predictive Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predictive distributions need to be aggregated when probabilistic forecasts\nare merged, or when expert opinions expressed in terms of probability\ndistributions are fused. We take a prediction space approach that applies to\ndiscrete, mixed discrete-continuous and continuous predictive distributions\nalike, and study combination formulas for cumulative distribution functions\nfrom the perspectives of coherence, probabilistic and conditional calibration,\nand dispersion. Both linear and non-linear aggregation methods are\ninvestigated, including generalized, spread-adjusted and beta-transformed\nlinear pools. The effects and techniques are demonstrated theoretically, in\nsimulation examples, and in case studies on density forecasts for S&P 500\nreturns and daily maximum temperature at Seattle-Tacoma Airport.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jun 2011 19:54:19 GMT"}], "update_date": "2011-06-09", "authors_parsed": [["Gneiting", "Tilmann", ""], ["Ranjan", "Roopesh", ""]]}, {"id": "1106.1916", "submitter": "Atul Mallik", "authors": "Atul Mallik, Bodhisattva Sen, Moulinath Banerjee and George\n  Michailidis", "title": "Threshold estimation based on a p-value framework in dose-response and\n  regression settings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use p-values to identify the threshold level at which a regression\nfunction takes off from its baseline value, a problem motivated by applications\nin toxicological and pharmacological dose-response studies and environmental\nstatistics. We study the problem in two sampling settings: one where multiple\nresponses can be obtained at a number of different covariate-levels and the\nother the standard regression setting involving limited number of response\nvalues at each covariate. Our procedure involves testing the hypothesis that\nthe regression function is at its baseline at each covariate value and then\ncomputing the potentially approximate p-value of the test. An estimate of the\nthreshold is obtained by fitting a piecewise constant function with a single\njump discontinuity, otherwise known as a stump, to these observed p-values, as\nthey behave in markedly different ways on the two sides of the threshold. The\nestimate is shown to be consistent and its finite sample properties are studied\nthrough simulations. Our approach is computationally simple and extends to the\nestimation of the baseline value of the regression function, heteroscedastic\nerrors and to time-series. It is illustrated on some real data applications.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jun 2011 20:55:17 GMT"}], "update_date": "2011-06-13", "authors_parsed": [["Mallik", "Atul", ""], ["Sen", "Bodhisattva", ""], ["Banerjee", "Moulinath", ""], ["Michailidis", "George", ""]]}, {"id": "1106.2014", "submitter": "Emmanuel Guerre", "authors": "Alain Guay, Emmanuel Guerre and Stepana Lazarova", "title": "Robust Adaptive Rate-Optimal Testing for the White Noise Hypothesis", "comments": "Article plus Supplementary Material document which groups proofs", "journal-ref": "Journal of Econometrics Volume 176, Issue 2, October 2013, Pages\n  134-145", "doi": "10.1016/j.jeconom.2013.05.001", "report-no": null, "categories": "math.ST stat.AP stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new test is proposed for the weak white noise null hypothesis. The test is\nbased on a new automatic choice of the order for a Box-Pierce or Hong test\nstatistic. The test uses Lobato (2001) or Kuan and Lee (2006) HAC critical\nvalues. The data-driven order choice is tailored to detect a new class of\nalternatives with autocorrelation coefficients which can be $o(n^{-1/2})$\nprovided there are enough of them. A simulation experiment illustrates the good\nbehavior of the test both under the weak white noise null and the alternative.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jun 2011 10:58:35 GMT"}, {"version": "v2", "created": "Fri, 7 Oct 2011 10:54:54 GMT"}, {"version": "v3", "created": "Fri, 2 Nov 2012 17:03:49 GMT"}], "update_date": "2019-08-16", "authors_parsed": [["Guay", "Alain", ""], ["Guerre", "Emmanuel", ""], ["Lazarova", "Stepana", ""]]}, {"id": "1106.2068", "submitter": "Nicolai Meinshausen", "authors": "Nicolai Meinshausen, Marloes H. Maathuis, Peter B\\\"uhlmann", "title": "Asymptotic optimality of the Westfall--Young permutation procedure for\n  multiple testing under dependence", "comments": "Published in at http://dx.doi.org/10.1214/11-AOS946 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2011, Vol. 39, No. 6, 3369-3391", "doi": "10.1214/11-AOS946", "report-no": "IMS-AOS-AOS946", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Test statistics are often strongly dependent in large-scale multiple testing\napplications. Most corrections for multiplicity are unduly conservative for\ncorrelated test statistics, resulting in a loss of power to detect true\npositives. We show that the Westfall--Young permutation method has\nasymptotically optimal power for a broad class of testing problems with a\nblock-dependence and sparsity structure among the tests, when the number of\ntests tends to infinity.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jun 2011 14:18:25 GMT"}, {"version": "v2", "created": "Mon, 19 Mar 2012 06:20:26 GMT"}], "update_date": "2012-03-20", "authors_parsed": [["Meinshausen", "Nicolai", ""], ["Maathuis", "Marloes H.", ""], ["B\u00fchlmann", "Peter", ""]]}, {"id": "1106.2219", "submitter": "Nadezhda Gribkova Dr.", "authors": "Nadezhda Gribkova and Roelof Helmers", "title": "The Empirical Edgeworth Expansion for a Studentized Trimmed Mean", "comments": "26 pages", "journal-ref": "Math. Methods Statist. v. 15, pp. 61--87, 2006", "doi": null, "report-no": "Report PNA-R0214 Mar 2002", "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We establish the validity of the empirical Edgeworth expansion (EE) for a\nstudentized trimmed mean, under the sole condition that the underlying\ndistribution function of the observations satisfies a local smoothness\ncondition near the two quantiles where the trimming occurs. A simple explicit\nformula for the N^{-1/2} term (correcting for skewness and bias; N being the\nsample size) of the EE is given. In particular our result supplements previous\nwork by P. Hall and A.R. Padmanabhan, On the bootstrap and the trimmed mean},\nJ. of Multivariate Analysis, v. 41 (1992), pp. 132-153. and H. Putter and W.R.\nvan Zwet,\n  Empirical Edgeworth expansions for symmetric statistics, Ann. Statist., v. 26\n(1998), pp. 1540-1569. The proof is based on a U-statistic type approximation\nand also uses a version of Bahadur's representation for sample quantiles.\n", "versions": [{"version": "v1", "created": "Sat, 11 Jun 2011 08:24:52 GMT"}, {"version": "v2", "created": "Sat, 25 Jun 2011 16:39:24 GMT"}], "update_date": "2011-06-28", "authors_parsed": [["Gribkova", "Nadezhda", ""], ["Helmers", "Roelof", ""]]}, {"id": "1106.2246", "submitter": "Salim Bouzebda", "authors": "Salim Bouzebda and Mohamed Cherfi", "title": "General bootstrap for dual phi-divergence estimates", "comments": null, "journal-ref": "Journal of Probability and Statistics - 2012- Art. ID 834107", "doi": "10.1155/2012/834107", "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A general notion of bootstrapped $\\phi$-divergence estimates constructed by\nexchangeably weighting sample is introduced. Asymptotic properties of these\ngeneralized bootstrapped $\\phi$-divergence estimates are obtained, by mean of\nthe empirical process theory, which are applied to construct the bootstrap\nconfidence set with asymptotically correct coverage probability. Some of\npractical problems are discussed, including in particular, the choice of escort\nparameter and several examples of divergences are investigated. Simulation\nresults are provided to illustrate the finite sample performance of the\nproposed estimators.\n", "versions": [{"version": "v1", "created": "Sat, 11 Jun 2011 15:14:31 GMT"}, {"version": "v2", "created": "Sat, 15 Oct 2011 20:02:38 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Bouzebda", "Salim", ""], ["Cherfi", "Mohamed", ""]]}, {"id": "1106.2333", "submitter": "Yaming Yu", "authors": "Yaming Yu", "title": "On Normal Variance-Mean Mixtures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Normal variance-mean mixtures encompass a large family of useful\ndistributions such as the generalized hyperbolic distribution, which itself\nincludes the Student t, Laplace, hyperbolic, normal inverse Gaussian, and\nvariance gamma distributions as special cases. We study shape properties of\nnormal variance-mean mixtures, in both the univariate and multivariate cases,\nand determine conditions for unimodality and log-concavity of the density\nfunctions. This leads to a short proof of the unimodality of all generalized\nhyperbolic densities. We also interpret such results in practical terms and\ndiscuss discrete analogues.\n", "versions": [{"version": "v1", "created": "Sun, 12 Jun 2011 19:28:00 GMT"}], "update_date": "2011-06-14", "authors_parsed": [["Yu", "Yaming", ""]]}, {"id": "1106.2363", "submitter": "Daniel Hsu", "authors": "Daniel Hsu, Sham M. Kakade, Tong Zhang", "title": "Random design analysis of ridge regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.AI cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work gives a simultaneous analysis of both the ordinary least squares\nestimator and the ridge regression estimator in the random design setting under\nmild assumptions on the covariate/response distributions. In particular, the\nanalysis provides sharp results on the ``out-of-sample'' prediction error, as\nopposed to the ``in-sample'' (fixed design) error. The analysis also reveals\nthe effect of errors in the estimated covariance structure, as well as the\neffect of modeling errors, neither of which effects are present in the fixed\ndesign setting. The proofs of the main results are based on a simple\ndecomposition lemma combined with concentration inequalities for random vectors\nand matrices.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jun 2011 01:08:48 GMT"}, {"version": "v2", "created": "Tue, 25 Mar 2014 02:16:11 GMT"}], "update_date": "2014-03-26", "authors_parsed": [["Hsu", "Daniel", ""], ["Kakade", "Sham M.", ""], ["Zhang", "Tong", ""]]}, {"id": "1106.2467", "submitter": "Matthieu Lerasle", "authors": "Matthieu Lerasle, Daniel Y. Takahashi", "title": "Sharp oracle inequalities and slope heuristic for specification\n  probabilities estimation in discrete random fields", "comments": "Published at http://dx.doi.org/10.3150/14-BEJ660 in the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2016, Vol. 22, No. 1, 325-344", "doi": "10.3150/14-BEJ660", "report-no": "IMS-BEJ-BEJ660", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of estimating the one-point specification probabilities\nin non-necessary finite discrete random fields from partially observed\nindependent samples. Our procedures are based on model selection by\nminimization of a penalized empirical criterion. The selected estimators\nsatisfy sharp oracle inequalities in $L_2$-risk. We also obtain theoretical\nresults on the slope heuristic for this problem, justifying the slope algorithm\nto calibrate the leading constant in the penalty. The practical performances of\nour methods are investigated in two simulation studies. We illustrate the\nusefulness of our approach by applying the methods to a multi-unit neuronal\ndata from a rat hippocampus.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jun 2011 15:19:34 GMT"}, {"version": "v2", "created": "Fri, 15 Jan 2016 13:31:30 GMT"}], "update_date": "2016-01-18", "authors_parsed": [["Lerasle", "Matthieu", ""], ["Takahashi", "Daniel Y.", ""]]}, {"id": "1106.2525", "submitter": "Sumeetpal S Singh", "authors": "Pierre Del Moral, Arnaud Doucet and Sumeetpal Singh", "title": "Uniform Stability of a Particle Approximation of the Optimal Filter\n  Derivative", "comments": null, "journal-ref": null, "doi": null, "report-no": "Cambridge University Engineering Department Technical Report\n  CUED/F-INFENG/TR.668", "categories": "math.ST stat.CO stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequential Monte Carlo methods, also known as particle methods, are a widely\nused set of computational tools for inference in non-linear non-Gaussian\nstate-space models. In many applications it may be necessary to compute the\nsensitivity, or derivative, of the optimal filter with respect to the static\nparameters of the state-space model; for instance, in order to obtain maximum\nlikelihood model parameters of interest, or to compute the optimal controller\nin an optimal control problem. In Poyiadjis et al. [2011] an original particle\nalgorithm to compute the filter derivative was proposed and it was shown using\nnumerical examples that the particle estimate was numerically stable in the\nsense that it did not deteriorate over time. In this paper we substantiate this\nclaim with a detailed theoretical study. Lp bounds and a central limit theorem\nfor this particle approximation of the filter derivative are presented. It is\nfurther shown that under mixing conditions these Lp bounds and the asymptotic\nvariance characterized by the central limit theorem are uniformly bounded with\nrespect to the time index. We demon- strate the performance predicted by theory\nwith several numerical examples. We also use the particle approximation of the\nfilter derivative to perform online maximum likelihood parameter estimation for\na stochastic volatility model.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jun 2011 19:09:05 GMT"}], "update_date": "2011-06-14", "authors_parsed": [["Del Moral", "Pierre", ""], ["Doucet", "Arnaud", ""], ["Singh", "Sumeetpal", ""]]}, {"id": "1106.2559", "submitter": "Jay Bartroff", "authors": "Jay Bartroff, Matthew Finkelman, Tze Leung Lai", "title": "Modern Sequential Analysis and its Applications to Computerized Adaptive\n  Testing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  After a brief review of recent advances in sequential analysis involving\nsequential generalized likelihood ratio tests, we discuss their use in\npsychometric testing and extend the asymptotic optimality theory of these\nsequential tests to the case of sequentially generated experiments, of\nparticular interest in computerized adaptive testing. We then show how these\nmethods can be used to design adaptive mastery tests, which are asymptotically\noptimal and are also shown to provide substantial improvements over currently\nused sequential and fixed length tests.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jun 2011 20:14:59 GMT"}], "update_date": "2011-06-15", "authors_parsed": [["Bartroff", "Jay", ""], ["Finkelman", "Matthew", ""], ["Lai", "Tze Leung", ""]]}, {"id": "1106.2627", "submitter": "Mohamed Cherfi", "authors": "Mohamed Cherfi", "title": "Dual divergences estimation for censored survival data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is devoted to robust estimation based on dual divergences\nestimators for parametric models in the framework of right censored data. We\ngive limit laws of the proposed estimators and examine their asymptotic\nproperties through a simulation study.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jun 2011 07:34:53 GMT"}], "update_date": "2011-06-15", "authors_parsed": [["Cherfi", "Mohamed", ""]]}, {"id": "1106.2674", "submitter": "Frederic Lavancier", "authors": "Fr\\'ed\\'eric Lavancier (LMJL)", "title": "Aggregation of isotropic autoregressive fields", "comments": null, "journal-ref": "Journal of Statistical Planning and Inference 141, 12 (2011)\n  3862-3866", "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This note constitutes a corrigendum to the article of Azomahou, JSPI,\n139:2581-2597. The aggregation of isotropic four nearest neighbors\nautoregressive models on the lattice, with random coefficient, is investigated.\nThe spectral density of the resulting random field is studied in details for a\nlarge class of law of the AR coefficient. Depending on this law, the aggregated\nfield may exhibit short memory or isotropic long memory.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jun 2011 11:27:23 GMT"}], "update_date": "2014-05-30", "authors_parsed": [["Lavancier", "Fr\u00e9d\u00e9ric", "", "LMJL"]]}, {"id": "1106.2775", "submitter": "Nikhil Srivastava", "authors": "Nikhil Srivastava, Roman Vershynin", "title": "Covariance estimation for distributions with $2+\\varepsilon$ moments", "comments": "Published in at http://dx.doi.org/10.1214/12-AOP760 the Annals of\n  Probability (http://www.imstat.org/aop/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Probability 2013, Vol. 41, No. 5, 3081-3111", "doi": "10.1214/12-AOP760", "report-no": "IMS-AOP-AOP760", "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the minimal sample size N=N(n) that suffices to estimate the\ncovariance matrix of an n-dimensional distribution by the sample covariance\nmatrix in the operator norm, with an arbitrary fixed accuracy. We establish the\noptimal bound N=O(n) for every distribution whose k-dimensional marginals have\nuniformly bounded $2+\\varepsilon$ moments outside the sphere of radius\n$O(\\sqrt{k})$. In the specific case of log-concave distributions, this result\nprovides an alternative approach to the Kannan-Lovasz-Simonovits problem, which\nwas recently solved by Adamczak et al. [J. Amer. Math. Soc. 23 (2010) 535-561].\nMoreover, a lower estimate on the covariance matrix holds under a weaker\nassumption - uniformly bounded $2+\\varepsilon$ moments of one-dimensional\nmarginals. Our argument consists of randomizing the spectral sparsifier, a\ndeterministic tool developed recently by Batson, Spielman and Srivastava [SIAM\nJ. Comput. 41 (2012) 1704-1721]. The new randomized method allows one to\ncontrol the spectral edges of the sample covariance matrix via the Stieltjes\ntransform evaluated at carefully chosen random points.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jun 2011 18:14:35 GMT"}, {"version": "v2", "created": "Thu, 1 Mar 2012 08:34:51 GMT"}, {"version": "v3", "created": "Fri, 30 Mar 2012 19:41:24 GMT"}, {"version": "v4", "created": "Thu, 3 Oct 2013 07:03:43 GMT"}], "update_date": "2013-10-04", "authors_parsed": [["Srivastava", "Nikhil", ""], ["Vershynin", "Roman", ""]]}, {"id": "1106.2790", "submitter": "Gongjun Xu", "authors": "Xiaolong Luo, Gongjun Xu and Zhiliang Ying", "title": "Sequential Analysis of Cox Model under Response Dependent Allocation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sellke and Siegmund (1983) developed the Brownian approximation to the Cox\npartial likelihood score as a process of calendar time, laying the foundation\nfor group sequential analysis of survival studies. We extend their results to\ncover situations in which treatment allocations may depend on observed\noutcomes. The new development makes use of the entry time and calendar time\nalong with the corresponding $\\sigma$-filtrations to handle the natural\ninformation accumulation. Large sample properties are established under\nsuitable regularity conditions.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jun 2011 19:13:06 GMT"}, {"version": "v2", "created": "Sun, 22 Dec 2013 04:13:54 GMT"}], "update_date": "2013-12-24", "authors_parsed": [["Luo", "Xiaolong", ""], ["Xu", "Gongjun", ""], ["Ying", "Zhiliang", ""]]}, {"id": "1106.2791", "submitter": "Brahimi Brahim", "authors": "Brahim Brahimi, Djamel Meraghni, and Abdelhakim Necir", "title": "Distortion risk measures for sums of dependent losses", "comments": "Accepted 25 October 2010, Journal Afrika Statistika Vol. 5, N9, 2010,\n  page 260--267", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST q-fin.RM stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss two distinct approaches, for distorting risk measures of sums of\ndependent random variables, which preserve the property of coherence. The\nfirst, based on distorted expectations, operates on the survival function of\nthe sum. The second, simultaneously applies the distortion on the survival\nfunction of the sum and the dependence structure of risks, represented by\ncopulas. Our goal is to propose risk measures that take into account the\nfluctuations of losses and possible correlations between risk components.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jun 2011 19:16:19 GMT"}, {"version": "v2", "created": "Thu, 16 Jun 2011 06:58:04 GMT"}], "update_date": "2011-06-17", "authors_parsed": [["Brahimi", "Brahim", ""], ["Meraghni", "Djamel", ""], ["Necir", "Abdelhakim", ""]]}, {"id": "1106.2920", "submitter": "Philipp Arbenz", "authors": "Philipp Arbenz, Paul Embrechts, Giovanni Puccetti", "title": "The AEP algorithm for the fast computation of the distribution of the\n  sum of dependent random variables", "comments": "Published in at http://dx.doi.org/10.3150/10-BEJ284 the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2011, Vol. 17, No. 2, 562-591", "doi": "10.3150/10-BEJ284", "report-no": "IMS-BEJ-BEJ284", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new algorithm to compute numerically the distribution function\nof the sum of $d$ dependent, non-negative random variables with given joint\ndistribution.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jun 2011 10:00:26 GMT"}], "update_date": "2011-06-16", "authors_parsed": [["Arbenz", "Philipp", ""], ["Embrechts", "Paul", ""], ["Puccetti", "Giovanni", ""]]}, {"id": "1106.3352", "submitter": "Ryan Martin", "authors": "Ryan Martin, Surya T. Tokdar", "title": "Semiparametric inference in mixture models with predictive recursion\n  marginal likelihood", "comments": null, "journal-ref": "Biometrika, 98(3), 567-582, 2011", "doi": "10.1093/biomet/asr030", "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predictive recursion is an accurate and computationally efficient algorithm\nfor nonparametric estimation of mixing densities in mixture models. In\nsemiparametric mixture models, however, the algorithm fails to account for any\nuncertainty in the additional unknown structural parameter. As an alternative\nto existing profile likelihood methods, we treat predictive recursion as a\nfilter approximation to fitting a fully Bayes model, whereby an approximate\nmarginal likelihood of the structural parameter emerges and can be used for\ninference. We call this the predictive recursion marginal likelihood.\nConvergence properties of predictive recursion under model mis-specification\nalso lead to an attractive construction of this new procedure. We show\npointwise convergence of a normalized version of this marginal likelihood\nfunction. Simulations compare the performance of this new marginal likelihood\napproach that of existing profile likelihood methods as well as Dirichlet\nprocess mixtures in density estimation. Mixed-effects models and an empirical\nBayes multiple testing application in time series analysis are also considered.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jun 2011 21:22:42 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Martin", "Ryan", ""], ["Tokdar", "Surya T.", ""]]}, {"id": "1106.3415", "submitter": "Florian Rohart", "authors": "Florian Rohart", "title": "Multiple Hypotheses Testing For Variable Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many methods have been developed to estimate the set of relevant variables in\na sparse linear model Y= XB+e where the dimension p of B can be much higher\nthan the length n of Y. Here we propose two new methods based on multiple\nhypotheses testing, either for ordered or non-ordered variables. Our procedures\nare inspired by the testing procedure proposed by Baraud et al (2003). The new\nprocedures are proved to be powerful under some conditions on the signal and\ntheir properties are non asymptotic. They gave better results in estimating the\nset of relevant variables than both the False Discovery Rate (FDR) and the\nLasso, both in the common case (p<n) and in the high-dimensional case (p>n).\n", "versions": [{"version": "v1", "created": "Fri, 17 Jun 2011 08:47:57 GMT"}, {"version": "v2", "created": "Sun, 10 Jun 2012 13:31:34 GMT"}], "update_date": "2012-06-12", "authors_parsed": [["Rohart", "Florian", ""]]}, {"id": "1106.3503", "submitter": "Erwan Le Pennec", "authors": "Eric Gautier (TSE), Erwan Le Pennec (CMAP, XPOP)", "title": "Adaptive estimation in the nonparametric random coefficients binary\n  choice model by needlet thresholding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the random coefficients binary choice model, a binary variable equals 1\niff an index $X^\\top\\beta$ is positive.The vectors $X$ and $\\beta$ are\nindependent and belong to the sphere $\\mathbb{S}^{d-1}$ in $\\mathbb{R}^{d}$.We\nprove lower bounds on the minimax risk for estimation of the density\n$f\\_{\\beta}$ over Besov bodies where the loss is a power of the\n$L^p(\\mathbb{S}^{d-1})$ norm for $1\\le p\\le \\infty$. We show that a hard\nthresholding estimator based on a needlet expansion with data-driven thresholds\nachieves these lower bounds up to logarithmic factors.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jun 2011 14:51:11 GMT"}, {"version": "v2", "created": "Wed, 5 Oct 2016 14:27:10 GMT"}, {"version": "v3", "created": "Tue, 28 Nov 2017 15:05:01 GMT"}], "update_date": "2017-11-29", "authors_parsed": [["Gautier", "Eric", "", "TSE"], ["Pennec", "Erwan Le", "", "CMAP, XPOP"]]}, {"id": "1106.3520", "submitter": "Lutz Duembgen", "authors": "Lutz Duembgen, Dominic Schuhmacher, Richard Samworth", "title": "Stochastic Search for Semiparametric Linear Regression Models", "comments": "Technical report 75, IMSV, University of Bern", "journal-ref": "From Probability to Statistics and Back: High-Dimensional Models\n  and Processes - A Festschrift in Honor of Jon A. Wellner (2013)", "doi": "10.1214/12-IMSCOLL907", "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces and analyzes a stochastic search method for parameter\nestimation in linear regression models in the spirit of Beran and Millar\n(1987). The idea is to generate a random finite subset of a parameter space\nwhich will automatically contain points which are very close to an unknown true\nparameter. The motivation for this procedure comes from recent work of\nDuembgen, Samworth and Schuhmacher (2011) on regression models with log-concave\nerror distributions.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jun 2011 15:57:30 GMT"}, {"version": "v2", "created": "Mon, 10 Oct 2011 11:10:38 GMT"}], "update_date": "2013-11-26", "authors_parsed": [["Duembgen", "Lutz", ""], ["Schuhmacher", "Dominic", ""], ["Samworth", "Richard", ""]]}, {"id": "1106.3670", "submitter": "Yoav Benjamini", "authors": "Yoav Benjamini and Marina Bogomolov", "title": "Adjusting for selection bias in testing multiple families of hypotheses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many large multiple testing problems the hypotheses are divided into\nfamilies. Given the data, families with evidence for true discoveries are\nselected, and hypotheses within them are tested. Neither controlling the\nerror-rate in each family separately nor controlling the error-rate over all\nhypotheses together can assure that an error-rate is controlled in the selected\nfamilies. We formulate this concern about selective inference in its\ngenerality, for a very wide class of error-rates and for any selection\ncriterion, and present an adjustment of the testing level inside the selected\nfamilies that retains the average error-rate over the selected families.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jun 2011 16:59:39 GMT"}], "update_date": "2011-06-21", "authors_parsed": [["Benjamini", "Yoav", ""], ["Bogomolov", "Marina", ""]]}, {"id": "1106.3830", "submitter": "Cristina Tortora", "authors": "Mireille Gettler Summa (CEREMADE), Francesco Palumbo, Cristina Tortora\n  (CEREMADE)", "title": "Factor PD-Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Factorial clustering methods have been developed in recent years thanks to\nthe improving of computational power. These methods perform a linear\ntransformation of data and a clustering on transformed data optimizing a common\ncriterion. Factorial PD-clustering is based on Probabilistic Distance\nclustering (PD-clustering). PD-clustering is an iterative, distribution free,\nprobabilistic, clustering method. Factor PD-clustering make a linear\ntransformation of original variables into a reduced number of orthogonal ones\nusing a common criterion with PD-Clustering. It is demonstrated that Tucker 3\ndecomposition allows to obtain this transformation. Factor PD-clustering makes\nalternatively a Tucker 3 decomposition and a PD-clustering on transformed data\nuntil convergence. This method could significantly improve the algorithm\nperformance and allows to work with large dataset, to improve the stability and\nthe robustness of the method.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jun 2011 07:34:41 GMT"}, {"version": "v2", "created": "Thu, 20 Oct 2011 09:53:02 GMT"}, {"version": "v3", "created": "Tue, 3 Jul 2012 13:18:00 GMT"}], "update_date": "2012-07-05", "authors_parsed": [["Summa", "Mireille Gettler", "", "CEREMADE"], ["Palumbo", "Francesco", "", "CEREMADE"], ["Tortora", "Cristina", "", "CEREMADE"]]}, {"id": "1106.4149", "submitter": "Claudia Neves", "authors": "Laurens de Haan, Albert Klein Tank and Cl\\'audia Neves", "title": "On tail trend detection: modeling relative risk", "comments": "38 pages", "journal-ref": "Extremes, June 2015, Volume 18, Issue 2, pp 141-178", "doi": "10.1007/s10687-014-0207-8", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The climate change dispute is about changes over time of environmental\ncharacteristics (such as rainfall). Some people say that a possible change is\nnot so much in the mean but rather in the extreme phenomena (that is, the\naverage rainfall may not change much but heavy storms may become more or less\nfrequent). The paper studies changes over time in the probability that some\nhigh threshold is exceeded. The model is such that the threshold does not need\nto be specified, the results hold for any high threshold. For simplicity a\ncertain linear trend is studied depending on one real parameter. Estimation and\ntesting procedures (is there a trend?) are developed. Simulation results are\npresented. The method is applied to trends in heavy rainfall at 18 gauging\nstations across Germany and The Netherlands. A tentative conclusion is that the\ntrend seems to depend on whether or not a station is close to the sea.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jun 2011 09:42:35 GMT"}, {"version": "v2", "created": "Wed, 3 Apr 2013 14:33:41 GMT"}], "update_date": "2015-06-16", "authors_parsed": [["de Haan", "Laurens", ""], ["Tank", "Albert Klein", ""], ["Neves", "Cl\u00e1udia", ""]]}, {"id": "1106.4222", "submitter": "Bibinger Markus", "authors": "Markus Bibinger", "title": "Asymptotics of Asynchronicity", "comments": "technical report, 36 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we focus on estimating the quadratic covariation of\ncontinuous semimartingales from discrete observations that take place at\nasynchronous observation times. The Hayashi-Yoshida estimator serves as\nsynchronized realized covolatility for that we give our own distinct\nillustration based on an iterative synchronization algorithm. We consider\nhigh-frequency asymptotics and prove a feasible stable central limit theorem.\nThe characteristics of non-synchronous observation schemes affecting the\nasymptotic variance are captured by a notion of asymptotic covariations of\ntimes. These are precisely illuminated and explicitly deduced for the important\ncase of independent time-homogeneous Poisson sampling.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jun 2011 15:03:32 GMT"}], "update_date": "2011-06-22", "authors_parsed": [["Bibinger", "Markus", ""]]}, {"id": "1106.4223", "submitter": "Ryan Martin", "authors": "Ryan Martin", "title": "Convergence rate for predictive recursion estimation of finite mixtures", "comments": "12 pages, 1 figure", "journal-ref": "Statistics and Probability Letters, 82 (2012), pp. 378-384", "doi": "10.1016/j.spl.2011.10.023", "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predictive recursion (PR) is a fast stochastic algorithm for nonparametric\nestimation of mixing distributions in mixture models. It is known that the PR\nestimates of both the mixing and mixture densities are consistent under fairly\nmild conditions, but currently very little is known about the rate of\nconvergence. Here I first investigate asymptotic convergence properties of the\nPR estimate under model misspecification in the special case of finite mixtures\nwith known support. Tools from stochastic approximation theory are used to\nprove that the PR estimates converge, to the best Kullback--Leibler\napproximation, at a nearly root-$n$ rate. When the support is unknown, PR can\nbe used to construct an objective function which, when optimized, yields an\nestimate the support. I apply the known-support results to derive a rate of\nconvergence for this modified PR estimate in the unknown support case, which\ncompares favorably to known optimal rates.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jun 2011 15:04:08 GMT"}, {"version": "v2", "created": "Fri, 14 Oct 2011 17:11:19 GMT"}], "update_date": "2011-11-28", "authors_parsed": [["Martin", "Ryan", ""]]}, {"id": "1106.4228", "submitter": "Bibinger Markus", "authors": "Markus Bibinger", "title": "An estimator for the quadratic covariation of asynchronously observed\n  It\\^o processes with noise: Asymptotic distribution theory", "comments": "36 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The article is devoted to the nonparametric estimation of the quadratic\ncovariation of non-synchronously observed It\\^o processes in an additive\nmicrostructure noise model. In a high-frequency setting, we aim at establishing\nan asymptotic distribution theory for a generalized multiscale estimator\nincluding a feasible central limit theorem with optimal convergence rate on\nconvenient regularity assumptions. The inevitably remaining impact of\nasynchronous deterministic sampling schemes and noise corruption on the\nasymptotic distribution is precisely elucidated. A case study for various\nimportant examples, several generalizations of the model and an algorithm for\nthe implementation warrant the utility of the estimation method in\napplications.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jun 2011 15:15:23 GMT"}], "update_date": "2011-06-22", "authors_parsed": [["Bibinger", "Markus", ""]]}, {"id": "1106.4293", "submitter": "Arnak Dalalyan S.", "authors": "La\\\"etitia Comminges (LIGM), Arnak Dalalyan (LIGM, CREST)", "title": "Tight conditions for consistency of variable selection in the context of\n  high dimensionality", "comments": "arXiv admin note: text overlap with arXiv:1102.3616; Published in at\n  http://dx.doi.org/10.1214/12-AOS1046 the Annals of Statistics\n  (http://www.imstat.org/aos/) by the Institute of Mathematical Statistics\n  (http://www.imstat.org)", "journal-ref": "Annals of Statistics 40, 5 (2012) 2667-2696", "doi": "10.1214/12-AOS1046", "report-no": "IMS-AOS-AOS1046", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the issue of variable selection in the regression model with very\nhigh ambient dimension, that is, when the number of variables is very large.\nThe main focus is on the situation where the number of relevant variables,\ncalled intrinsic dimension, is much smaller than the ambient dimension d.\nWithout assuming any parametric form of the underlying regression function, we\nget tight conditions making it possible to consistently estimate the set of\nrelevant variables. These conditions relate the intrinsic dimension to the\nambient dimension and to the sample size. The procedure that is provably\nconsistent under these tight conditions is based on comparing quadratic\nfunctionals of the empirical Fourier coefficients with appropriately chosen\nthreshold values. The asymptotic analysis reveals the presence of two quite\ndifferent re gimes. The first regime is when the intrinsic dimension is fixed.\nIn this case the situation in nonparametric regression is the same as in linear\nregression, that is, consistent variable selection is possible if and only if\nlog d is small compared to the sample size n. The picture is different in the\nsecond regime, that is, when the number of relevant variables denoted by s\ntends to infinity as $n\\to\\infty$. Then we prove that consistent variable\nselection in nonparametric set-up is possible only if s+loglog d is small\ncompared to log n. We apply these results to derive minimax separation rates\nfor the problem of variable\n", "versions": [{"version": "v1", "created": "Tue, 21 Jun 2011 19:07:25 GMT"}, {"version": "v2", "created": "Wed, 29 Jun 2011 10:06:55 GMT"}, {"version": "v3", "created": "Fri, 30 Mar 2012 18:14:17 GMT"}, {"version": "v4", "created": "Tue, 19 Feb 2013 08:55:24 GMT"}], "update_date": "2013-03-25", "authors_parsed": [["Comminges", "La\u00ebtitia", "", "LIGM"], ["Dalalyan", "Arnak", "", "LIGM, CREST"]]}, {"id": "1106.4333", "submitter": "Alfredo A. Kalaitzis Mr", "authors": "Alfredo A. Kalaitzis and Neil D. Lawrence", "title": "Residual Component Analysis", "comments": "9 pages, 8 figures, submitted to NIPS2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI math.ST stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic principal component analysis (PPCA) seeks a low dimensional\nrepresentation of a data set in the presence of independent spherical Gaussian\nnoise, Sigma = (sigma^2)*I. The maximum likelihood solution for the model is an\neigenvalue problem on the sample covariance matrix. In this paper we consider\nthe situation where the data variance is already partially explained by other\nfactors, e.g. covariates of interest, or temporal correlations leaving some\nresidual variance. We decompose the residual variance into its components\nthrough a generalized eigenvalue problem, which we call residual component\nanalysis (RCA). We show that canonical covariates analysis (CCA) is a special\ncase of our algorithm and explore a range of new algorithms that arise from the\nframework. We illustrate the ideas on a gene expression time series data set\nand the recovery of human pose from silhouette.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jun 2011 21:17:51 GMT"}], "update_date": "2011-06-23", "authors_parsed": [["Kalaitzis", "Alfredo A.", ""], ["Lawrence", "Neil D.", ""]]}, {"id": "1106.4386", "submitter": "Wanyang Dai", "authors": "Wanyang Dai", "title": "Optimal Rate Scheduling via Utility-Maximization for J-User MIMO Markov\n  Fading Wireless Channels with Cooperation", "comments": "53 pages, Originally submitted on June 17, 2010; Revised version\n  submitted on December 24, 2010", "journal-ref": "Operations Research, Vol. 61, No. 6, 1450-1462 (with additional 26\n  page proof of online e-companion ( Supplemental)), 2013", "doi": null, "report-no": null, "categories": "math.PR cs.IT math.IT math.OC math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We design a dynamic rate scheduling policy of Markov type via the solution (a\nsocial optimal Nash equilibrium point) to a utility-maximization problem over a\nrandomly evolving capacity set for a class of generalized processor-sharing\nqueues living in a random environment, whose job arrivals to each queue follow\na doubly stochastic renewal process (DSRP). Both the random environment and the\nrandom arrival rate of each DSRP are driven by a finite state continuous time\nMarkov chain (FS-CTMC). Whereas the scheduling policy optimizes in a greedy\nfashion with respect to each queue and environmental state and since the\nclosed-form solution for the performance of such a queueing system under the\npolicy is difficult to obtain, we establish a reflecting diffusion with\nregime-switching (RDRS) model for its measures of performance and justify its\nasymptotic optimality through deriving the stochastic fluid and diffusion\nlimits for the corresponding system under heavy traffic and identifying a cost\nfunction related to the utility function, which is minimized through minimizing\nthe workload process in the diffusion limit. More importantly, our queueing\nmodel includes both J-user multi-input multi-output (MIMO) multiple access\nchannel (MAC) and broadcast channel (BC) with cooperation and admission control\nas special cases. In these wireless systems, data from the J users in the MAC\nor data to the J users in the BC is transmitted over a common channel that is\nfading according to the FS-CTMC. The J-user capacity region for the MAC or the\nBC is a set-valued stochastic process that switches with the FS-CTMC fading. In\nany particular channel state, we show that each of the J-user capacity regions\nis a convex set bounded by a number of linear or smooth curved facets.\nTherefore our queueing model can perfectly match the dynamics of these wireless\nsystems.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jun 2011 07:35:33 GMT"}], "update_date": "2015-08-28", "authors_parsed": [["Dai", "Wanyang", ""]]}, {"id": "1106.4461", "submitter": "Marianna Pensky", "authors": "Anestis Antoniadis, Marianna Pensky and Theofanis Sapatinas", "title": "Nonparametric Regression Estimation Based on Spatially Inhomogeneous\n  Data: Minimax Global Convergence Rates and Adaptivity", "comments": "45 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the nonparametric regression estimation problem of recovering an\nunknown response function f on the basis of spatially inhomogeneous data when\nthe design points follow a known compactly supported density g with a finite\nnumber of well separated zeros. In particular, we consider two different cases:\nwhen g has zeros of a polynomial order and when g has zeros of an exponential\norder. These two cases correspond to moderate and severe data losses,\nrespectively. We obtain asymptotic minimax lower bounds for the global risk of\nan estimator of f and construct adaptive wavelet nonlinear thresholding\nestimators of f which attain those minimax convergence rates (up to a\nlogarithmic factor in the case of a zero of a polynomial order), over a wide\nrange of Besov balls.\n  The spatially inhomogeneous ill-posed problem that we investigate is\ninherently more difficult than spatially homogeneous problems like, e.g.,\ndeconvolution. In particular, due to spatial irregularity, assessment of\nminimax global convergence rates is a much harder task than the derivation of\nminimax local convergence rates studied recently in the literature.\nFurthermore, the resulting estimators exhibit very different behavior and\nminimax global convergence rates in comparison with the solution of spatially\nhomogeneous ill-posed problems. For example, unlike in deconvolution problem,\nthe minimax global convergence rates are greatly influenced not only by the\nextent of data loss but also by the degree of spatial homogeneity of f.\nSpecifically, even if 1/g is not integrable, one can recover f as well as in\nthe case of an equispaced design (in terms of minimax global convergence rates)\nwhen it is homogeneous enough since the estimator is \"borrowing strength\" in\nthe areas where f is adequately sampled.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jun 2011 14:24:34 GMT"}, {"version": "v2", "created": "Tue, 28 Jun 2011 14:10:30 GMT"}, {"version": "v3", "created": "Tue, 11 Oct 2011 22:21:16 GMT"}, {"version": "v4", "created": "Tue, 21 Feb 2012 17:46:18 GMT"}, {"version": "v5", "created": "Fri, 26 Oct 2012 15:15:33 GMT"}], "update_date": "2012-10-29", "authors_parsed": [["Antoniadis", "Anestis", ""], ["Pensky", "Marianna", ""], ["Sapatinas", "Theofanis", ""]]}, {"id": "1106.4490", "submitter": "David R. Bickel", "authors": "David R. Bickel", "title": "Simple estimators of false discovery rates given as few as one or two\n  p-values without strong parametric assumptions", "comments": null, "journal-ref": "Statistical Applications in Genetics and Molecular Biology 12,\n  529-543 (2013)", "doi": "10.1515/sagmb-2013-0003", "report-no": null, "categories": "stat.ME math.ST q-bio.QM stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiple comparison procedures that control a family-wise error rate or false\ndiscovery rate provide an achieved error rate as the adjusted p-value for each\nhypothesis tested. However, since such p-values are not probabilities that the\nnull hypotheses are true, empirical Bayes methods have been devised to estimate\nsuch posterior probabilities, called local false discovery rates (LFDRs) to\nemphasize the frequency interpretation of their priors. The main approaches to\nLFDR estimation, relying either on numerical algorithms to maximize likelihood\nor on the selection of smoothing parameters for nonparametric density\nestimation, lack the automatic nature of the methods of error rate control. To\nbegin filling the gap, this paper introduces automatic methods of LFDR\nestimation with proven asymptotic conservatism under the independence of\np-values but without strong parametric assumptions. Simulations indicate that\nthey remain conservative even for very small numbers of hypotheses. One of the\nproposed procedures enables interpreting the original FDR control rule in terms\nof LFDR estimation, thereby facilitating practical interpretation. The most\nconservative of the new procedures is applied to measured abundance levels of\n20 proteins.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jun 2011 16:00:25 GMT"}], "update_date": "2013-09-03", "authors_parsed": [["Bickel", "David R.", ""]]}, {"id": "1106.4662", "submitter": "St\\'ephane Ga\\\"iffas", "authors": "S\\'ephane Ga\\\"iffas and Agathe Guilloux", "title": "High-dimensional additive hazard models and the Lasso", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a general high-dimensional additive hazard model in a\nnon-asymptotic setting, including regression for censored-data. In this\ncontext, we consider a Lasso estimator with a fully data-driven $\\ell_1$\npenalization, which is tuned for the estimation problem at hand. We prove sharp\noracle inequalities for this estimator. Our analysis involves a new\n\"data-driven\" Bernstein's inequality, that is of independent interest, where\nthe predictable variation is replaced by the optional variation.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jun 2011 09:26:49 GMT"}, {"version": "v2", "created": "Fri, 2 Mar 2012 23:09:30 GMT"}], "update_date": "2012-03-06", "authors_parsed": [["Ga\u00efffas", "S\u00e9phane", ""], ["Guilloux", "Agathe", ""]]}, {"id": "1106.4710", "submitter": "Gleb Oshanin", "authors": "G. Oshanin, Yu. Holovatch and G. Schehr", "title": "Proportionate vs disproportionate distribution of wealth of two\n  individuals in a tempered Paretian ensemble", "comments": "9 pages, 8 figures, to appear in Physica A", "journal-ref": "Physica A 390, 4340--4346 (2011)", "doi": "10.1016/j.physa.2011.06.067", "report-no": null, "categories": "q-fin.GN math.PR math.ST physics.data-an q-fin.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the distribution P(\\omega) of the random variable \\omega = x_1/(x_1\n+ x_2), where x_1 and x_2 are the wealths of two individuals selected at random\nfrom the same tempered Paretian ensemble characterized by the distribution\n\\Psi(x) \\sim \\phi(x)/x^{1 + \\alpha}, where \\alpha > 0 is the Pareto index and\n$\\phi(x)$ is the cut-off function. We consider two forms of \\phi(x): a bounded\nfunction \\phi(x) = 1 for L \\leq x \\leq H, and zero otherwise, and a smooth\nexponential function \\phi(x) = \\exp(-L/x - x/H). In both cases \\Psi(x) has\nmoments of arbitrary order.\n  We show that, for \\alpha > 1, P(\\omega) always has a unimodal form and is\npeaked at \\omega = 1/2, so that most probably x_1 \\approx x_2. For 0 < \\alpha <\n1 we observe a more complicated behavior which depends on the value of \\delta =\nL/H. In particular, for \\delta < \\delta_c - a certain threshold value -\nP(\\omega) has a three-modal (for a bounded \\phi(x)) and a bimodal M-shape (for\nan exponential \\phi(x)) form which signifies that in such ensembles the wealths\nx_1 and x_2 are disproportionately different.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jun 2011 13:14:55 GMT"}], "update_date": "2012-07-24", "authors_parsed": [["Oshanin", "G.", ""], ["Holovatch", "Yu.", ""], ["Schehr", "G.", ""]]}, {"id": "1106.4729", "submitter": "Makoto Yamada", "authors": "Makoto Yamada, Taiji Suzuki, Takafumi Kanamori, Hirotaka Hachiya,\n  Masashi Sugiyama", "title": "Relative Density-Ratio Estimation for Robust Distribution Comparison", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Divergence estimators based on direct approximation of density-ratios without\ngoing through separate approximation of numerator and denominator densities\nhave been successfully applied to machine learning tasks that involve\ndistribution comparison such as outlier detection, transfer learning, and\ntwo-sample homogeneity test. However, since density-ratio functions often\npossess high fluctuation, divergence estimation is still a challenging task in\npractice. In this paper, we propose to use relative divergences for\ndistribution comparison, which involves approximation of relative\ndensity-ratios. Since relative density-ratios are always smoother than\ncorresponding ordinary density-ratios, our proposed method is favorable in\nterms of the non-parametric convergence speed. Furthermore, we show that the\nproposed divergence estimator has asymptotic variance independent of the model\ncomplexity under a parametric setup, implying that the proposed estimator\nhardly overfits even with complex models. Through experiments, we demonstrate\nthe usefulness of the proposed approach.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jun 2011 14:05:34 GMT"}], "update_date": "2011-06-24", "authors_parsed": [["Yamada", "Makoto", ""], ["Suzuki", "Taiji", ""], ["Kanamori", "Takafumi", ""], ["Hachiya", "Hirotaka", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "1106.4739", "submitter": "Krzysztof {\\L}atuszy\\'{n}ski", "authors": "Krzysztof {\\L}atuszy\\'nski, B{\\l}a\\.zej Miasojedow, Wojciech Niemiro", "title": "Nonasymptotic bounds on the estimation error of MCMC algorithms", "comments": "Published in at http://dx.doi.org/10.3150/12-BEJ442 the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm). arXiv admin\n  note: text overlap with arXiv:0907.4915", "journal-ref": "Bernoulli 2013, Vol. 19, No. 5A, 2033-2066", "doi": "10.3150/12-BEJ442", "report-no": "IMS-BEJ-BEJ442", "categories": "stat.ME math.ST stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of upper bounding the mean square error of MCMC\nestimators. Our analysis is nonasymptotic. We first establish a general result\nvalid for essentially all ergodic Markov chains encountered in Bayesian\ncomputation and a possibly unbounded target function $f$. The bound is sharp in\nthe sense that the leading term is exactly $\\sigma_{\\mathrm {as}}^2(P,f)/n$,\nwhere $\\sigma_{\\mathrm{as}}^2(P,f)$ is the CLT asymptotic variance. Next, we\nproceed to specific additional assumptions and give explicit computable bounds\nfor geometrically and polynomially ergodic Markov chains under quantitative\ndrift conditions. As a corollary, we provide results on confidence estimation.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jun 2011 14:35:04 GMT"}, {"version": "v2", "created": "Mon, 26 Mar 2012 10:35:24 GMT"}, {"version": "v3", "created": "Wed, 11 Dec 2013 10:09:55 GMT"}], "update_date": "2013-12-12", "authors_parsed": [["\u0141atuszy\u0144ski", "Krzysztof", ""], ["Miasojedow", "B\u0142a\u017cej", ""], ["Niemiro", "Wojciech", ""]]}, {"id": "1106.4763", "submitter": "Guillermo Henry", "authors": "Guillermo Henry, Andr\\'es Mu\\~noz and Daniela Rodriguez", "title": "k-Nearest neighbor density estimation on Riemannian Manifolds", "comments": "17 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider a k-nearest neighbor kernel type estimator when\nthe random variables belong in a Riemannian manifolds. We study asymptotic\nproperties such as the consistency and the asymptotic distribution. A\nsimulation study is also consider to evaluate the performance of the proposal.\nFinally, to illustrate the potential applications of the proposed estimator, we\nanalyzed two real example where two different manifolds are considered.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jun 2011 16:16:37 GMT"}], "update_date": "2011-06-24", "authors_parsed": [["Henry", "Guillermo", ""], ["Mu\u00f1oz", "Andr\u00e9s", ""], ["Rodriguez", "Daniela", ""]]}, {"id": "1106.4983", "submitter": "Sixiang Cai", "authors": "Olivier Wintenberger (CEREMADE), Sixiang Cai (AGM)", "title": "Parametric inference and forecasting in continuously invertible\n  volatility models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the notion of continuously invertible volatility models that\nrelies on some Lyapunov condition and some regularity condition. We show that\nit is almost equivalent to the ability of the volatilities forecasting using\nthe parametric inference approach based on the SRE given in [16]. Under very\nweak assumptions, we prove the strong consistency and the asymptotic normality\nof the parametric inference. Based on this parametric estimation, a natural\nstrongly consistent forecast of the volatility is given. We apply successfully\nthis approach to recover known results on univariate and multivariate GARCH\ntype models and to the EGARCH(1,1) model. We prove the strong consistency of\nthe forecasting as soon as the model is invertible and the asymptotic normality\nof the parametric inference as soon as the limiting variance exists. Finally,\nwe give some encouraging empirical results of our approach on simulations and\nreal data.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jun 2011 14:50:15 GMT"}, {"version": "v2", "created": "Wed, 27 Jul 2011 19:35:29 GMT"}, {"version": "v3", "created": "Thu, 3 Nov 2011 19:03:31 GMT"}], "update_date": "2011-11-07", "authors_parsed": [["Wintenberger", "Olivier", "", "CEREMADE"], ["Cai", "Sixiang", "", "AGM"]]}, {"id": "1106.5119", "submitter": "Pascal Vallet", "authors": "Walid Hachem, Philippe Loubaton, Xavier Mestre, Jamal Najim and Pascal\n  Vallet", "title": "Large information plus noise random matrix models and consistent\n  subspace estimation in large sensor networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In array processing, a common problem is to estimate the angles of arrival of\n$K$ deterministic sources impinging on an array of $M$ antennas, from $N$\nobservations of the source signal, corrupted by gaussian noise. The problem\nreduces to estimate a quadratic form (called \"localization function\") of a\ncertain projection matrix related to the source signal empirical covariance\nmatrix. Recently, a new subspace estimation method (called \"G-MUSIC\") has been\nproposed, in the context where the number of available samples $N$ is of the\nsame order of magnitude than the number of sensors $M$. In this context, the\ntraditional subspace methods tend to fail because the empirical covariance\nmatrix of the observations is a poor estimate of the source signal covariance\nmatrix. The G-MUSIC method is based on a new consistent estimator of the\nlocalization function in the regime where $M$ and $N$ tend to $+\\infty$ at the\nsame rate. However, the consistency of the angles estimator was not adressed.\nThe purpose of this paper is to prove the consistency of the angles of arrival\nestimator in the previous asymptotic regime. To prove this result, we show the\nproperty that the singular values of M x N Gaussian information plus noise\nmatrix escape from certain intervals is an event of probability decreasing at\nrate O(1/N^p) for all p. A regularization trick is also introduced, which\nallows to confine these singular values into certain intervals and to use\nstandard tools as Poincar\\'e inequality to characterize any moments of the\nestimator. These results are believed to be of independent interest.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jun 2011 09:46:21 GMT"}], "update_date": "2011-06-28", "authors_parsed": [["Hachem", "Walid", ""], ["Loubaton", "Philippe", ""], ["Mestre", "Xavier", ""], ["Najim", "Jamal", ""], ["Vallet", "Pascal", ""]]}, {"id": "1106.5241", "submitter": "Yaming Yu", "authors": "Yaming Yu", "title": "The Shape of the Noncentral Chi-square Density", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.CA stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A noncentral chi-square density is log-concave if the degree of freedom is\nnu>=2. We complement this known result by showing that, for each 0<nu<2, there\nexists lambda_nu>0 such that the chi-square with nu degrees of freedom and\nnoncentrality parameter lambda has a decreasing density if lambda <= lambda_nu,\nand is bi-modal otherwise. The critical lambda_nu is characterized by an\nequation involving a ratio of modified Bessel functions. When an interior mode\nexists we derive precise bounds on its location.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jun 2011 18:05:30 GMT"}], "update_date": "2011-06-28", "authors_parsed": [["Yu", "Yaming", ""]]}, {"id": "1106.5485", "submitter": "Jacek Jakubowski", "authors": "Jacek Jakubowski, Maciej Wi\\'sniewolski", "title": "On hyperbolic Bessel processes and beyond", "comments": "Published in at http://dx.doi.org/10.3150/12-BEJ458 the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2013, Vol. 19, No. 5B, 2437-2454", "doi": "10.3150/12-BEJ458", "report-no": "IMS-BEJ-BEJ458", "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate distributions of hyperbolic Bessel processes. We find links\nbetween the hyperbolic cosine of hyperbolic Bessel processes and functionals of\ngeometric Brownian motion. We present an explicit formula for the Laplace\ntransform of the hyperbolic cosine of a hyperbolic Bessel process and some\nother interesting probabilistic representations of this Laplace transform. We\nexpress the one-dimensional distribution of a hyperbolic Bessel process in\nterms of other, known and independent processes. We present some applications\nincluding a new proof of Bougerol's identity and its generalization. We\ncharacterize the distribution of the process which is the hyperbolic sine of\nhyperbolic Bessel process.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jun 2011 19:54:56 GMT"}, {"version": "v2", "created": "Fri, 20 Dec 2013 13:27:42 GMT"}], "update_date": "2013-12-23", "authors_parsed": [["Jakubowski", "Jacek", ""], ["Wi\u015bniewolski", "Maciej", ""]]}, {"id": "1106.5531", "submitter": "Doron Zeilberger", "authors": "Shalosh B. Ekhad and Doron Zeilberger", "title": "Balls in Boxes: Variations on a Theme of Warren Ewens and Herbert Wilf", "comments": "13 pages; Dedicated to Herbert Saul Wilf on his 80th birthday", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We comment on, elaborate, and extend the work of Warren Ewens and Herbert\nWilf, described in their http://www.pnas.org/content/104/27/11189.full.pdf\nabout the maximum in balls-and-boxes problem. In particular we meta-apply their\ningenious method to show that it is not really needed, and that one is better\noff using the so-called Poisson Approximation, at least in applications to the\nreal world, because extremely unlikely events mever happen in real life. This\narticle is accompanied by the Maple package\nhttp://www.math.rutgers.edu/~zeilberg/tokhniot/BallsInBoxes\">BallsInBoxes.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jun 2011 22:11:05 GMT"}], "update_date": "2011-06-29", "authors_parsed": [["Ekhad", "Shalosh B.", ""], ["Zeilberger", "Doron", ""]]}, {"id": "1106.5547", "submitter": "Hanchao Wang", "authors": "Zheng-Yan Lin, Yu-Ping Song, Han-Chao Wang", "title": "Nonparametric Estimation of Second-Order Jump-Diffusion Model", "comments": "This paper has been withdrawn since there are many mistakes in the\n  proof", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the nonparametric estimators of the infinitesimal coefficients of\nthe second-order jump-diffusion models. Under the mild conditions, we obtain\nthe weak consistency and the asymptotic normalities of the estimators.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jun 2011 01:07:42 GMT"}, {"version": "v2", "created": "Mon, 30 Jan 2017 06:19:15 GMT"}], "update_date": "2017-07-07", "authors_parsed": [["Lin", "Zheng-Yan", ""], ["Song", "Yu-Ping", ""], ["Wang", "Han-Chao", ""]]}, {"id": "1106.5599", "submitter": "Christophe Giraud", "authors": "Christophe Giraud (CMAP)", "title": "A pseudo-RIP for multivariate regression", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a suitable RI-Property under which recent results for trace\nregression translate into strong risk bounds for multivariate regression. This\npseudo-RIP is compatible with the setting $n < p$.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jun 2011 09:07:07 GMT"}], "update_date": "2011-06-30", "authors_parsed": [["Giraud", "Christophe", "", "CMAP"]]}, {"id": "1106.5758", "submitter": "Russell Lyons", "authors": "Russell Lyons", "title": "Distance covariance in metric spaces", "comments": "Published in at http://dx.doi.org/10.1214/12-AOP803 the Annals of\n  Probability (http://www.imstat.org/aop/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Probability 2013, Vol. 41, No. 5, 3284-3305. Errata,\n  Ann. Probab. 46, no. 4 (2018), 2400--2405", "doi": "10.1214/12-AOP803", "report-no": "IMS-AOP-AOP803", "categories": "math.ST math.MG math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend the theory of distance (Brownian) covariance from Euclidean spaces,\nwhere it was introduced by Sz\\'{e}kely, Rizzo and Bakirov, to general metric\nspaces. We show that for testing independence, it is necessary and sufficient\nthat the metric space be of strong negative type. In particular, we show that\nthis holds for separable Hilbert spaces, which answers a question of Kosorok.\nInstead of the manipulations of Fourier transforms used in the original work,\nwe use elementary inequalities for metric spaces and embeddings in Hilbert\nspaces.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jun 2011 18:38:37 GMT"}, {"version": "v2", "created": "Fri, 8 Jul 2011 22:06:46 GMT"}, {"version": "v3", "created": "Sat, 22 Oct 2011 16:53:09 GMT"}, {"version": "v4", "created": "Thu, 3 Oct 2013 11:28:35 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Lyons", "Russell", ""]]}, {"id": "1106.5826", "submitter": "Ali Jalali", "authors": "Ali Jalali and Pradeep Ravikumar and Sujay Sanghavi", "title": "A Dirty Model for Multiple Sparse Regression", "comments": "The primary result is accepted to NIPS 2010 for Oral Presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse linear regression -- finding an unknown vector from linear\nmeasurements -- is now known to be possible with fewer samples than variables,\nvia methods like the LASSO. We consider the multiple sparse linear regression\nproblem, where several related vectors -- with partially shared support sets --\nhave to be recovered. A natural question in this setting is whether one can use\nthe sharing to further decrease the overall number of samples required. A line\nof recent research has studied the use of \\ell_1/\\ell_q norm\nblock-regularizations with q>1 for such problems; however these could actually\nperform worse in sample complexity -- vis a vis solving each problem separately\nignoring sharing -- depending on the level of sharing.\n  We present a new method for multiple sparse linear regression that can\nleverage support and parameter overlap when it exists, but not pay a penalty\nwhen it does not. A very simple idea: we decompose the parameters into two\ncomponents and regularize these differently. We show both theoretically and\nempirically, our method strictly and noticeably outperforms both \\ell_1 or\n\\ell_1/\\ell_q methods, over the entire range of possible overlaps (except at\nboundary cases, where we match the best method). We also provide theoretical\nguarantees that the method performs well under high-dimensional scaling.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jun 2011 00:53:15 GMT"}], "update_date": "2012-02-28", "authors_parsed": [["Jalali", "Ali", ""], ["Ravikumar", "Pradeep", ""], ["Sanghavi", "Sujay", ""]]}, {"id": "1106.5834", "submitter": "Johanna Hardin", "authors": "Johanna Hardin, Stephan Ramon Garcia, David Golan", "title": "A method for generating realistic correlation matrices", "comments": "Published in at http://dx.doi.org/10.1214/13-AOAS638 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2013, Vol. 7, No. 3, 1733-1762", "doi": "10.1214/13-AOAS638", "report-no": "IMS-AOAS-AOAS638", "categories": "math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simulating sample correlation matrices is important in many areas of\nstatistics. Approaches such as generating Gaussian data and finding their\nsample correlation matrix or generating random uniform $[-1,1]$ deviates as\npairwise correlations both have drawbacks. We develop an algorithm for adding\nnoise, in a highly controlled manner, to general correlation matrices. In many\ninstances, our method yields results which are superior to those obtained by\nsimply simulating Gaussian data. Moreover, we demonstrate how our general\nalgorithm can be tailored to a number of different correlation models. Using\nour results with a few different applications, we show that simulating\ncorrelation matrices can help assess statistical methodology.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jun 2011 02:26:57 GMT"}, {"version": "v2", "created": "Thu, 2 Aug 2012 13:14:39 GMT"}, {"version": "v3", "created": "Mon, 28 Jan 2013 14:26:29 GMT"}, {"version": "v4", "created": "Fri, 6 Dec 2013 09:51:00 GMT"}], "update_date": "2013-12-09", "authors_parsed": [["Hardin", "Johanna", ""], ["Garcia", "Stephan Ramon", ""], ["Golan", "David", ""]]}, {"id": "1106.6002", "submitter": "Ulrike Schneider", "authors": "Benedikt M. P\\\"otscher, Ulrike Schneider", "title": "Distributional Results for Thresholding Estimators in High-Dimensional\n  Gaussian Regression Models", "comments": "minor corrections", "journal-ref": "Electron. J. Statist. 5 (2011), 1876-1934", "doi": "10.1214/11-EJS659", "report-no": null, "categories": "math.ST stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the distribution of hard-, soft-, and adaptive soft-thresholding\nestimators within a linear regression model where the number of parameters k\ncan depend on sample size n and may diverge with n. In addition to the case of\nknown error-variance, we define and study versions of the estimators when the\nerror-variance is unknown. We derive the finite-sample distribution of each\nestimator and study its behavior in the large-sample limit, also investigating\nthe effects of having to estimate the variance when the degrees of freedom n-k\ndoes not tend to infinity or tends to infinity very slowly. Our analysis\nencompasses both the case where the estimators are tuned to perform consistent\nmodel selection and the case where the estimators are tuned to perform\nconservative model selection. Furthermore, we discuss consistency, uniform\nconsistency and derive the uniform convergence rate under either type of\ntuning.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jun 2011 17:06:24 GMT"}, {"version": "v2", "created": "Mon, 14 Nov 2011 14:57:35 GMT"}, {"version": "v3", "created": "Fri, 16 Dec 2011 18:46:33 GMT"}], "update_date": "2012-01-04", "authors_parsed": [["P\u00f6tscher", "Benedikt M.", ""], ["Schneider", "Ulrike", ""]]}, {"id": "1106.6104", "submitter": "Keqin Liu", "authors": "Sattar Vakili, Keqin Liu, Qing Zhao", "title": "Deterministic Sequencing of Exploration and Exploitation for Multi-Armed\n  Bandit Problems", "comments": "22 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.SY math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the Multi-Armed Bandit (MAB) problem, there is a given set of arms with\nunknown reward models. At each time, a player selects one arm to play, aiming\nto maximize the total expected reward over a horizon of length T. An approach\nbased on a Deterministic Sequencing of Exploration and Exploitation (DSEE) is\ndeveloped for constructing sequential arm selection policies. It is shown that\nfor all light-tailed reward distributions, DSEE achieves the optimal\nlogarithmic order of the regret, where regret is defined as the total expected\nreward loss against the ideal case with known reward models. For heavy-tailed\nreward distributions, DSEE achieves O(T^1/p) regret when the moments of the\nreward distributions exist up to the pth order for 1<p<=2 and O(T^1/(1+p/2))\nfor p>2. With the knowledge of an upperbound on a finite moment of the\nheavy-tailed reward distributions, DSEE offers the optimal logarithmic regret\norder. The proposed DSEE approach complements existing work on MAB by providing\ncorresponding results for general reward distributions. Furthermore, with a\nclearly defined tunable parameter-the cardinality of the exploration sequence,\nthe DSEE approach is easily extendable to variations of MAB, including MAB with\nvarious objectives, decentralized MAB with multiple players and incomplete\nreward observations under collisions, MAB with unknown Markov dynamics, and\ncombinatorial MAB with dependent arms that often arise in network optimization\nproblems such as the shortest path, the minimum spanning, and the dominating\nset problems under unknown random weights.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jun 2011 02:12:32 GMT"}, {"version": "v2", "created": "Sat, 10 Sep 2011 04:40:06 GMT"}, {"version": "v3", "created": "Sat, 9 Mar 2013 20:17:17 GMT"}], "update_date": "2013-03-12", "authors_parsed": [["Vakili", "Sattar", ""], ["Liu", "Keqin", ""], ["Zhao", "Qing", ""]]}, {"id": "1106.6251", "submitter": "Lorenzo Rosasco", "authors": "Mauricio A. Alvarez, Lorenzo Rosasco, Neil D. Lawrence", "title": "Kernels for Vector-Valued Functions: a Review", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kernel methods are among the most popular techniques in machine learning.\nFrom a frequentist/discriminative perspective they play a central role in\nregularization theory as they provide a natural choice for the hypotheses space\nand the regularization functional through the notion of reproducing kernel\nHilbert spaces. From a Bayesian/generative perspective they are the key in the\ncontext of Gaussian processes, where the kernel function is also known as the\ncovariance function. Traditionally, kernel methods have been used in supervised\nlearning problem with scalar outputs and indeed there has been a considerable\namount of work devoted to designing and learning kernels. More recently there\nhas been an increasing interest in methods that deal with multiple outputs,\nmotivated partly by frameworks like multitask learning. In this paper, we\nreview different methods to design or learn valid kernel functions for multiple\noutputs, paying particular attention to the connection between probabilistic\nand functional methods.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jun 2011 14:48:54 GMT"}, {"version": "v2", "created": "Mon, 16 Apr 2012 17:40:40 GMT"}], "update_date": "2012-04-17", "authors_parsed": [["Alvarez", "Mauricio A.", ""], ["Rosasco", "Lorenzo", ""], ["Lawrence", "Neil D.", ""]]}]