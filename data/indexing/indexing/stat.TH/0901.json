[{"id": "0901.0182", "submitter": "V\\'eronique Maume-Deschamps", "authors": "H. Cossette, E. Marceau, V. Maume-Deschamps", "title": "Adjustment coefficient for risk processes in some dependent contexts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Following an article by Muller and Pflug, we study the adjustment coefficient\nof ruin theory in a context of temporal dependency. We provide a consistent\nestimator of this coefficient, and perform some simulations.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jan 2009 16:13:27 GMT"}], "update_date": "2009-01-05", "authors_parsed": [["Cossette", "H.", ""], ["Marceau", "E.", ""], ["Maume-Deschamps", "V.", ""]]}, {"id": "0901.0264", "submitter": "Andre Mas", "authors": "Andr\\'e Mas (I3M)", "title": "Representation of small ball probabilities in Hilbert space and lower\n  bound in regression for functional data", "comments": null, "journal-ref": "Electronic Journal of Statistics (2012) 6, 1745-1778", "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $S=\\sum_{i=1}^{+\\infty}\\lambda_{i}Z_{i}$ where the $Z_{i}$'s are i.d.d.\npositive with $\\mathbb{E}\\| Z\\| ^{3}<+\\infty$ and\n$(\\lambda_{i})_{i\\in\\mathbb{N}}$ a positive nonincreasing sequence such that\n$\\sum\\lambda_{i}<+\\infty$. We study the small ball probability\n$\\mathbb{P}(S<\\epsilon) $ when $\\epsilon\\downarrow0$. We start from a result by\nLifshits (1997) who computed this probability by means of the Laplace transform\nof $S$. We prove that $\\mathbb{P}(S<\\cdot) $ belongs to a class of functions\nintroduced by de Haan, well-known in extreme value theory, the class of\nGamma-varying functions, for which an exponential-integral representation is\navailable. This approach allows to derive bounds for the rate in nonparametric\nregression for functional data at a fixed point $x_{0}$ :\n$\\mathbb{E}(y|X=x_{0}%) $ where $(y_{i},X_{i})_{1\\leq i\\leq n}$ is a sample in\n$(\\mathbb{R},\\mathcal{F}) $ and $\\mathcal{F}$ is some space of functions. It\nturns out that, in a general framework, the minimax lower bound for the risk is\nof order $(\\log n)^{-\\tau}$ for some $\\tau>0$ depending on the regularity of\nthe data and polynomial rates cannot be achieved.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jan 2009 18:07:35 GMT"}, {"version": "v2", "created": "Wed, 2 Mar 2011 14:46:25 GMT"}], "update_date": "2013-02-20", "authors_parsed": [["Mas", "Andr\u00e9", "", "I3M"]]}, {"id": "0901.0324", "submitter": "Nizar Demni", "authors": "Nizar Demni", "title": "Beta Jacobi processes", "comments": "the paper is accepted for publication in APAM", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define and study a multidimensional process that generalizes the\neigenvalues of matrix Jacobi processes on the one hand and whose stationary\ndistribution is given by the beta Jacobi ensemble on the other hand.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jan 2009 15:12:12 GMT"}, {"version": "v2", "created": "Tue, 6 Jan 2009 17:56:10 GMT"}, {"version": "v3", "created": "Mon, 13 Jul 2009 16:30:50 GMT"}], "update_date": "2009-07-13", "authors_parsed": [["Demni", "Nizar", ""]]}, {"id": "0901.0356", "submitter": "Mark Reid", "authors": "Mark D. Reid and Robert C. Williamson", "title": "Information, Divergence and Risk for Binary Experiments", "comments": "89 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We unify f-divergences, Bregman divergences, surrogate loss bounds (regret\nbounds), proper scoring rules, matching losses, cost curves, ROC-curves and\ninformation. We do this by systematically studying integral and variational\nrepresentations of these objects and in so doing identify their primitives\nwhich all are related to cost-sensitive binary classification. As well as\nclarifying relationships between generative and discriminative views of\nlearning, the new machinery leads to tight and more general surrogate loss\nbounds and generalised Pinsker inequalities relating f-divergences to\nvariational divergence. The new viewpoint illuminates existing algorithms: it\nprovides a new derivation of Support Vector Machines in terms of divergences\nand relates Maximum Mean Discrepancy to Fisher Linear Discriminants. It also\nsuggests new techniques for estimating f-divergences.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jan 2009 06:37:01 GMT"}], "update_date": "2009-01-06", "authors_parsed": [["Reid", "Mark D.", ""], ["Williamson", "Robert C.", ""]]}, {"id": "0901.0455", "submitter": "Charles J. Geyer", "authors": "Charles J. Geyer", "title": "Likelihood Inference in Exponential Families and Directions of Recession", "comments": "Submitted to the Electronic Journal of Statistics\n  (http://www.i-journals.org/ejs/) by the Institute of Mathematical Statistics\n  (http://www.imstat.org)", "journal-ref": null, "doi": null, "report-no": "IMS-EJS-EJS_2008_349", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When in a full exponential family the maximum likelihood estimate (MLE) does\nnot exist, the MLE may exist in the Barndorff-Nielsen completion of the family.\nWe propose a practical algorithm for finding the MLE in the completion based on\nrepeated linear programming using the R contributed package rcdd and illustrate\nit with two generalized linear model examples. When the MLE for the null\nhypothesis lies in the completion, likelihood ratio tests of model comparison\nare almost unchanged from the usual case. Only the degrees of freedom need to\nbe adjusted. When the MLE lies in the completion, confidence intervals are\nchanged much more from the usual case. The MLE of the natural parameter can be\nthought of as having gone to infinity in a certain direction, which we call a\ngeneric direction of recession. We propose a new one-sided confidence interval\nwhich says how close to infinity the natural parameter may be. This maps to\none-sided confidence intervals for mean values showing how close to the\nboundary of their support they may be.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jan 2009 10:08:08 GMT"}], "update_date": "2009-01-06", "authors_parsed": [["Geyer", "Charles J.", ""]]}, {"id": "0901.0463", "submitter": "Zhiwei Zhang", "authors": "Zhiwei Zhang", "title": "A Law of Likelihood for Composite Hypotheses", "comments": "Submitted to the Electronic Journal of Statistics\n  (http://www.i-journals.org/ejs/) by the Institute of Mathematical Statistics\n  (http://www.imstat.org)", "journal-ref": null, "doi": null, "report-no": "IMS-EJS-EJS_2009_351", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The law of likelihood underlies a general framework, known as the likelihood\nparadigm, for representing and interpreting statistical evidence. As stated,\nthe law applies only to simple hypotheses, and there have been reservations\nabout extending the law to composite hypotheses, despite their tremendous\nrelevance in statistical applications. This paper proposes a generalization of\nthe law of likelihood for composite hypotheses. The generalized law is\ndeveloped in an axiomatic fashion, illustrated with real examples, and examined\nin an asymptotic analysis. Previous concerns about including composite\nhypotheses in the likelihood paradigm are discussed in light of the new\ndevelopments. The generalized law of likelihood is compared with other\nlikelihood-based methods and its practical implications are noted. Lastly, a\ndiscussion is given on how to use the generalized law to interpret published\nresults of hypothesis tests as reduced data when the full data are not\navailable.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jan 2009 11:16:21 GMT"}], "update_date": "2009-01-06", "authors_parsed": [["Zhang", "Zhiwei", ""]]}, {"id": "0901.0655", "submitter": "Vladimir Spokoiny", "authors": "Yuri Golubev, Vladimir Spokoiny", "title": "Exponential bounds for minimum contrast estimators", "comments": "Submitted to the Electronic Journal of Statistics\n  (http://www.i-journals.org/ejs/) by the Institute of Mathematical Statistics\n  (http://www.imstat.org)", "journal-ref": null, "doi": null, "report-no": "IMS-EJS-EJS_2009_352", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper focuses on general properties of parametric minimum contrast\nestimators. The quality of estimation is measured in terms of the rate function\nrelated to the contrast, thus allowing to derive exponential risk bounds\ninvariant with respect to the detailed probabilistic structure of the model.\nThis approach works well for small or moderate samples and covers the case of a\nmisspecified parametric model. Another important feature of the presented\nbounds is that they may be used in the case when the parametric set is\nunbounded and non-compact. These bounds do not rely on the entropy or covering\nnumbers and can be easily computed. The most important statistical fact\nresulting from the exponential bonds is a concentration inequality which claims\nthat minimum contrast estimators concentrate with a large probability on the\nlevel set of the rate function. In typical situations, every such set is a\nroot-n neighborhood of the parameter of interest. We also show that the\nobtained bounds can help for bounding the estimation risk, constructing\nconfidence sets for the underlying parameters. Our general results are\nillustrated for the case of an i.i.d. sample. We also consider several popular\nexamples including least absolute deviation estimation and the problem of\nestimating the location of a change point. What we obtain in these examples\nslightly differs from the usual asymptotic results presented in statistical\nliterature. This difference is due to the unboundness of the parameter set and\na possible model misspecification.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jan 2009 14:31:27 GMT"}], "update_date": "2009-01-07", "authors_parsed": [["Golubev", "Yuri", ""], ["Spokoiny", "Vladimir", ""]]}, {"id": "0901.0751", "submitter": "Wei Biao Wu", "authors": "Xiaohong Chen, Wei Biao Wu, Yanping Yi", "title": "Efficient estimation of copula-based semiparametric Markov models", "comments": "Published in at http://dx.doi.org/10.1214/09-AOS719 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2009, Vol. 37, No. 6B, 4214-4253", "doi": "10.1214/09-AOS719", "report-no": "IMS-AOS-AOS719", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the efficient estimation of copula-based semiparametric\nstrictly stationary Markov models. These models are characterized by\nnonparametric invariant (one-dimensional marginal) distributions and parametric\nbivariate copula functions where the copulas capture temporal dependence and\ntail dependence of the processes. The Markov processes generated via tail\ndependent copulas may look highly persistent and are useful for financial and\neconomic applications. We first show that Markov processes generated via\nClayton, Gumbel and Student's $t$ copulas and their survival copulas are all\ngeometrically ergodic. We then propose a sieve maximum likelihood estimation\n(MLE) for the copula parameter, the invariant distribution and the conditional\nquantiles. We show that the sieve MLEs of any smooth functional is root-$n$\nconsistent, asymptotically normal and efficient and that their sieve likelihood\nratio statistics are asymptotically chi-square distributed. Monte Carlo studies\nindicate that, even for Markov models generated via tail dependent copulas and\nfat-tailed marginals, our sieve MLEs perform very well.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jan 2009 04:18:30 GMT"}, {"version": "v2", "created": "Thu, 12 Mar 2009 15:52:50 GMT"}, {"version": "v3", "created": "Thu, 12 Mar 2009 21:39:08 GMT"}, {"version": "v4", "created": "Fri, 20 Nov 2009 14:56:30 GMT"}], "update_date": "2009-11-20", "authors_parsed": [["Chen", "Xiaohong", ""], ["Wu", "Wei Biao", ""], ["Yi", "Yanping", ""]]}, {"id": "0901.1072", "submitter": "Fumio Hiai", "authors": "Fumio Hiai and Takuho Miyamoto", "title": "A new approach to mutual information. II", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new concept of mutual pressure is introduced for potential functions on\nboth continuous and discrete compound spaces via discrete micro-states of\npermutations, and its relations with the usual pressure and the mutual\ninformation are established. This paper is a continuation of the paper of Hiai\nand Petz in Banach Center Publications, Vol. 78.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jan 2009 15:49:16 GMT"}], "update_date": "2009-01-09", "authors_parsed": [["Hiai", "Fumio", ""], ["Miyamoto", "Takuho", ""]]}, {"id": "0901.1266", "submitter": "Yan Wang", "authors": "Yan Wang, Yajun Mei", "title": "Decentralized Two-Sided Sequential Tests for A Normal Mean", "comments": "5 pages, conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article is concerned with decentralized sequential testing of a normal\nmean $\\mu$ with two-sided alternatives. It is assumed that in a single-sensor\nnetwork system with limited local memory, i.i.d. normal raw observations are\nobserved at the local sensor, and quantized into binary messages that are sent\nto the fusion center, which makes a final decision between the null hypothesis\n$H_0: \\mu = 0$ and the alternative hypothesis $H_1: \\mu = \\pm 1.$ We propose a\ndecentralized sequential test using the idea of tandem quantizers (or\nequivalently, a one-shot feedback). Surprisingly, our proposed test only uses\nthe quantizers of the form $I(X_{n} \\ge \\lambda),$ but it is shown to be\nasymptotically Bayes. Moreover, by adopting the principle of invariance, we\nalso investigate decentralized invariant tests with the stationary quantizers\nof the form $I(|X_{n}| > \\lambda),$ and show that $\\lambda = 0.5$ only leads to\na suboptimal decentralized invariant sequential test. Numerical simulations are\nconducted to support our arguments.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jan 2009 16:30:43 GMT"}], "update_date": "2009-01-12", "authors_parsed": [["Wang", "Yan", ""], ["Mei", "Yajun", ""]]}, {"id": "0901.1342", "submitter": "Cosma Rohilla Shalizi", "authors": "Cosma Rohilla Shalizi", "title": "Dynamics of Bayesian Updating with Dependent Data and Misspecified\n  Models", "comments": "36 pages, 1 figure. v2: typo fixes, minor formatting changes. v3:\n  Improved notation, added references, new theorem on convergence rates. v4:\n  minor changes to text, added references. v5: Minor typo corrections; matches\n  journal version except for format details", "journal-ref": "_Electronic Journal of Statistics_, vol. 3 (2009): 1039--1074", "doi": "10.1214/09-EJS485", "report-no": null, "categories": "math.ST q-bio.PE stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much is now known about the consistency of Bayesian updating on\ninfinite-dimensional parameter spaces with independent or Markovian data.\nNecessary conditions for consistency include the prior putting enough weight on\nthe correct neighborhoods of the data-generating distribution; various\nsufficient conditions further restrict the prior in ways analogous to capacity\ncontrol in frequentist nonparametrics. The asymptotics of Bayesian updating\nwith mis-specified models or priors, or non-Markovian data, are far less well\nexplored. Here I establish sufficient conditions for posterior convergence when\nall hypotheses are wrong, and the data have complex dependencies. The main\ndynamical assumption is the asymptotic equipartition (Shannon-McMillan-Breiman)\nproperty of information theory. This, along with Egorov's Theorem on uniform\nconvergence, lets me build a sieve-like structure for the prior. The main\nstatistical assumption, also a form of capacity control, concerns the\ncompatibility of the prior and the data-generating process, controlling the\nfluctuations in the log-likelihood when averaged over the sieve-like sets. In\naddition to posterior convergence, I derive a kind of large deviations\nprinciple for the posterior measure, extending in some cases to rates of\nconvergence, and discuss the advantages of predicting using a combination of\nmodels known to be wrong. An appendix sketches connections between these\nresults and the replicator dynamics of evolutionary theory.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jan 2009 21:53:11 GMT"}, {"version": "v2", "created": "Sat, 24 Jan 2009 00:02:43 GMT"}, {"version": "v3", "created": "Mon, 7 Sep 2009 19:46:54 GMT"}, {"version": "v4", "created": "Fri, 16 Oct 2009 18:12:00 GMT"}, {"version": "v5", "created": "Fri, 13 Nov 2009 16:54:35 GMT"}], "update_date": "2010-04-21", "authors_parsed": [["Shalizi", "Cosma Rohilla", ""]]}, {"id": "0901.1365", "submitter": "Shuheng Zhou", "authors": "Shuheng Zhou, Katrina Ligett, Larry Wasserman", "title": "Differential Privacy with Compression", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work studies formal utility and privacy guarantees for a simple\nmultiplicative database transformation, where the data are compressed by a\nrandom linear or affine transformation, reducing the number of data records\nsubstantially, while preserving the number of original input variables. We\nprovide an analysis framework inspired by a recent concept known as\ndifferential privacy (Dwork 06). Our goal is to show that, despite the general\ndifficulty of achieving the differential privacy guarantee, it is possible to\npublish synthetic data that are useful for a number of common statistical\nlearning applications. This includes high dimensional sparse regression (Zhou\net al. 07), principal component analysis (PCA), and other statistical measures\n(Liu et al. 06) based on the covariance of the initial data.\n", "versions": [{"version": "v1", "created": "Sat, 10 Jan 2009 12:12:31 GMT"}], "update_date": "2009-01-13", "authors_parsed": [["Zhou", "Shuheng", ""], ["Ligett", "Katrina", ""], ["Wasserman", "Larry", ""]]}, {"id": "0901.1378", "submitter": "Yves F. Atchad\\'{e}", "authors": "Yves F. Atchad\\'e", "title": "A cautionary tale on the efficiency of some adaptive Monte Carlo schemes", "comments": "Published in at http://dx.doi.org/10.1214/09-AAP636 the Annals of\n  Applied Probability (http://www.imstat.org/aap/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Probability 2010, Vol. 20, No. 3, 841-868", "doi": "10.1214/09-AAP636", "report-no": "IMS-AAP-AAP636", "categories": "stat.CO math.PR math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a growing interest in the literature for adaptive Markov chain Monte\nCarlo methods based on sequences of random transition kernels $\\{P_n\\}$ where\nthe kernel $P_n$ is allowed to have an invariant distribution $\\pi_n$ not\nnecessarily equal to the distribution of interest $\\pi$ (target distribution).\nThese algorithms are designed such that as $n\\to\\infty$, $P_n$ converges to\n$P$, a kernel that has the correct invariant distribution $\\pi$. Typically, $P$\nis a kernel with good convergence properties, but one that cannot be directly\nimplemented. It is then expected that the algorithm will inherit the good\nconvergence properties of $P$. The equi-energy sampler of [Ann. Statist. 34\n(2006) 1581--1619] is an example of this type of adaptive MCMC. We show in this\npaper that the asymptotic variance of this type of adaptive MCMC is always at\nleast as large as the asymptotic variance of the Markov chain with transition\nkernel $P$. We also show by simulation that the difference can be substantial.\n", "versions": [{"version": "v1", "created": "Sat, 10 Jan 2009 14:16:39 GMT"}, {"version": "v2", "created": "Mon, 2 Nov 2009 01:00:29 GMT"}, {"version": "v3", "created": "Fri, 15 Oct 2010 07:07:56 GMT"}], "update_date": "2010-10-18", "authors_parsed": [["Atchad\u00e9", "Yves F.", ""]]}, {"id": "0901.1510", "submitter": "Mohd Bakri Adam", "authors": "Mohd Bakri Adam", "title": "Modification of Pickands' Dependence Function for the Simulate Ordered\n  Bivariate Extreme Data", "comments": "Submitted to the Electronic Journal of Statistics\n  (http://www.i-journals.org/ejs/) by the Institute of Mathematical Statistics\n  (http://www.imstat.org)", "journal-ref": null, "doi": null, "report-no": "IMS-EJS-EJS_2009_358", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the characteristics of the Pickands' dependence function for\nbivariate extreme distribution for minima, BEVM, when considering the\nstochastics ordering of the two variables. The existing Pickand's dependence\nfunction terminologies and theories are modified to suit the dependence\nfunctions of extreme cases. We successful implement and apply these functions\nto our simulate extreme data\n", "versions": [{"version": "v1", "created": "Mon, 12 Jan 2009 07:30:50 GMT"}], "update_date": "2009-01-13", "authors_parsed": [["Adam", "Mohd Bakri", ""]]}, {"id": "0901.1518", "submitter": "Johan Segers", "authors": "Jan Beirlant, Elisabeth Joossens, Johan Segers", "title": "Second-order refined peaks-over-threshold modelling for heavy-tailed\n  distributions", "comments": "to appear in the Journal of Statistical Planning and Inference", "journal-ref": null, "doi": null, "report-no": "Univ catholique de Louvain, Institut de statistique DP0824", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modelling excesses over a high threshold using the Pareto or generalized\nPareto distribution (PD/GPD) is the most popular approach in extreme value\nstatistics. This method typically requires high thresholds in order for the\n(G)PD to fit well and in such a case applies only to a small upper fraction of\nthe data. The extension of the (G)PD proposed in this paper is able to describe\nthe excess distribution for lower thresholds in case of heavy tailed\ndistributions. This yields a statistical model that can be fitted to a larger\nportion of the data. Moreover, estimates of tail parameters display stability\nfor a larger range of thresholds. Our findings are supported by asymptotic\nresults, simulations and a case study.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jan 2009 08:30:29 GMT"}], "update_date": "2009-01-13", "authors_parsed": [["Beirlant", "Jan", ""], ["Joossens", "Elisabeth", ""], ["Segers", "Johan", ""]]}, {"id": "0901.1911", "submitter": "Paul Kabaila", "authors": "Paul Kabaila and Khreshna Syuhada", "title": "The Asymptotic Efficiency of Improved Prediction Intervals", "comments": null, "journal-ref": "Statistics and Probability Letters, 80, 1348-1353 (2010)", "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Barndorff-Nielsen and Cox (1994, p.319) modify an estimative prediction limit\nto obtain an improved prediction limit with better coverage properties. Kabaila\nand Syuhada (2008) present a simulation-based approximation to this improved\nprediction limit, which avoids the extensive algebraic manipulations required\nfor this modification. We present a modification of an estimative prediction\ninterval, analogous to the Barndorff-Nielsen and Cox modification, to obtain an\nimproved prediction interval with better coverage properties. We also present\nan analogue, for the prediction interval context, of this simulation-based\napproximation. The parameter estimator on which the estimative and improved\nprediction limits and intervals are based is assumed to have the same\nasymptotic distribution as the (conditional) maximum likelihood estimator. The\nimproved prediction limit and interval depend on the asymptotic conditional\nbias of this estimator. This bias can be very sensitive to very small changes\nin the estimator. It may require considerable effort to find this bias. We\nshow, however, that the improved prediction limit and interval have asymptotic\nefficiencies that are functionally independent of this bias. Thus, improved\nprediction limits and intervals obtained using the Barndorff-Nielsen and Cox\ntype of methodology can conveniently be based on the (conditional) maximum\nlikelihood estimator, whose asymptotic conditional bias is given by the formula\nof Vidoni (2004, p.144). Also, improved prediction limits and intervals\nobtained using Kabaila and Syuhada type approximations have asymptotic\nefficiencies that are independent of the estimator on which these intervals are\nbased.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jan 2009 00:30:01 GMT"}], "update_date": "2011-09-27", "authors_parsed": [["Kabaila", "Paul", ""], ["Syuhada", "Khreshna", ""]]}, {"id": "0901.2044", "submitter": "Florentina Bunea", "authors": "Florentina Bunea, Alexandre B. Tsybakov, Marten H. Wegkamp, Adrian\n  Barbu", "title": "SPADES and mixture models", "comments": "Published in at http://dx.doi.org/10.1214/09-AOS790 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2010, Vol. 38, No. 4, 2525-2558", "doi": "10.1214/09-AOS790", "report-no": "IMS-AOS-AOS790", "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies sparse density estimation via $\\ell_1$ penalization\n(SPADES). We focus on estimation in high-dimensional mixture models and\nnonparametric adaptive density estimation. We show, respectively, that SPADES\ncan recover, with high probability, the unknown components of a mixture of\nprobability densities and that it yields minimax adaptive density estimates.\nThese results are based on a general sparsity oracle inequality that the SPADES\nestimates satisfy. We offer a data driven method for the choice of the tuning\nparameter used in the construction of SPADES. The method uses the generalized\nbisection method first introduced in \\citebb09. The suggested procedure\nbypasses the need for a grid search and offers substantial computational\nsavings. We complement our theoretical results with a simulation study that\nemploys this method for approximations of one and two-dimensional densities\nwith mixtures. The numerical results strongly support our theoretical findings.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jan 2009 15:34:13 GMT"}, {"version": "v2", "created": "Thu, 21 Oct 2010 13:30:14 GMT"}], "update_date": "2010-10-22", "authors_parsed": [["Bunea", "Florentina", ""], ["Tsybakov", "Alexandre B.", ""], ["Wegkamp", "Marten H.", ""], ["Barbu", "Adrian", ""]]}, {"id": "0901.2193", "submitter": "Zhigen Zhao", "authors": "Zhigen Zhao", "title": "Decision Approach and Empirical Bayes FCR-Controlling Interval for Mixed\n  Prior Model", "comments": "Submitted to the Electronic Journal of Statistics\n  (http://www.i-journals.org/ejs/) by the Institute of Mathematical Statistics\n  (http://www.imstat.org)", "journal-ref": null, "doi": null, "report-no": "IMS-EJS-EJS_2009_359", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, I apply the decision theory and empirical Bayesian approach to\nconstruct confidence intervals for selected populations when true parameters\nfollow a mixture prior distribution. A loss function with two tuning parameters\n$k_1$ and $k_2$ is coined to address the mixture prior. One specific choice of\n$k_2$ can lead to the procedure in Qiu and Hwang (2007); the other choice of\n$k_2$ provides an interval construction which controls the Bayes FCR. Both the\nanalytical and extensive numerical simulation studies demonstrate that the new\nempirical Bayesian FCR controlling approach enjoys great length reduction. At\nthe end, I apply different methods to a microarray data set. It turns out that\nthe average length of the new approach is only 57% of that of Qiu and Hwang's\nprocedure which controls the simultaneous non-coverage probability and 66% of\nthat of Benjamini and Yekutieli (2005)'s procedure which controls the\nfrequentist's FCR.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jan 2009 07:04:48 GMT"}], "update_date": "2009-01-16", "authors_parsed": [["Zhao", "Zhigen", ""]]}, {"id": "0901.2212", "submitter": "Nicolas Verzelen", "authors": "Nicolas Verzelen (LM-Orsay, INRIA Saclay - Ile de France)", "title": "Adaptive estimation of stationary Gaussian fields", "comments": null, "journal-ref": null, "doi": null, "report-no": "RR-6797", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the nonparametric covariance estimation of a stationary Gaussian\nfield X observed on a regular lattice. In the time series setting, some\nprocedures like AIC are proved to achieve optimal model selection among\nautoregressive models. However, there exists no such equivalent results of\nadaptivity in a spatial setting. By considering collections of Gaussian Markov\nrandom fields (GMRF) as approximation sets for the distribution of X, we\nintroduce a novel model selection procedure for spatial fields. For all\nneighborhoods m in a given collection M, this procedure first amounts to\ncomputing a covariance estimator of X within the GMRFs of neighborhood m. Then,\nit selects a neighborhood by applying a penalization strategy. The so-defined\nmethod satisfies a nonasymptotic oracle type inequality. If X is a GMRF, the\nprocedure is also minimax adaptive to the sparsity of its neighborhood. More\ngenerally, the procedure is adaptive to the rate of approximation of the true\ndistribution by GMRFs with growing neighborhoods.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jan 2009 10:02:15 GMT"}, {"version": "v2", "created": "Wed, 2 Sep 2009 06:32:06 GMT"}], "update_date": "2009-09-02", "authors_parsed": [["Verzelen", "Nicolas", "", "LM-Orsay, INRIA Saclay - Ile de France"]]}, {"id": "0901.2213", "submitter": "Nicolas Verzelen", "authors": "Nicolas Verzelen (LM-Orsay, INRIA Saclay - Ile de France)", "title": "Data-driven neighborhood selection of a Gaussian field", "comments": null, "journal-ref": null, "doi": null, "report-no": "RR-6798", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the nonparametric covariance estimation of a stationary Gaussian\nfield X observed on a lattice. To tackle this issue, a neighborhood selection\nprocedure has been recently introduced. This procedure amounts to selecting a\nneighborhood m by a penalization method and estimating the covariance of X in\nthe space of Gaussian Markov random fields (GMRFs) with neighborhood m. Such a\nstrategy is shown to satisfy oracle inequalities as well as minimax adaptive\nproperties. However, it suffers several drawbacks which make the method\ndifficult to apply in practice. On the one hand, the penalty depends on some\nunknown quantities. On the other hand, the procedure is only defined for\ntoroidal lattices. The present contribution is threefold. A data-driven\nalgorithm is proposed for tuning the penalty function. Moreover, the procedure\nis extended to non-toroidal lattices. Finally, numerical study illustrate the\nperformances of the method on simulated examples. These simulations suggest\nthat Gaussian Markov random field selection is often a good alternative to\nvariogram estimation.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jan 2009 10:09:56 GMT"}, {"version": "v2", "created": "Wed, 2 Sep 2009 06:31:22 GMT"}], "update_date": "2009-09-02", "authors_parsed": [["Verzelen", "Nicolas", "", "LM-Orsay, INRIA Saclay - Ile de France"]]}, {"id": "0901.2445", "submitter": "Louis H.Y. Chen", "authors": "Louis H.Y. Chen, Aihua Xia", "title": "Poisson process approximation for dependent superposition of point\n  processes", "comments": "Published in at http://dx.doi.org/10.3150/10-BEJ290 the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2011, Vol. 17, No. 2, 530-544", "doi": "10.3150/10-BEJ290", "report-no": "IMS-BEJ-BEJ290", "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although the study of weak convergence of superpositions of point processes\nto the Poisson process dates back to the work of Grigelionis in 1963, it was\nonly recently that Schuhmacher [Stochastic Process. Appl. 115 (2005)\n1819--1837] obtained error bounds for the weak convergence. Schuhmacher\nconsidered dependent superposition, truncated the individual point processes to\n0--1 point processes and then applied Stein's method to the latter. In this\npaper, we adopt a different approach to the problem by using Palm theory and\nStein's method, thereby expressing the error bounds in terms of the mean\nmeasures of the individual point processes, which is not possible with\nSchuhmacher's approach. We consider locally dependent superposition as a\ngeneralization of the locally dependent point process introduced in Chen and\nXia [Ann. Probab. 32 (2004) 2545--2569] and apply the main theorem to the\nsuperposition of thinned point processes and of renewal processes.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jan 2009 10:42:25 GMT"}, {"version": "v2", "created": "Sun, 11 Apr 2010 12:05:02 GMT"}, {"version": "v3", "created": "Mon, 9 May 2011 05:36:05 GMT"}], "update_date": "2011-05-10", "authors_parsed": [["Chen", "Louis H. Y.", ""], ["Xia", "Aihua", ""]]}, {"id": "0901.2503", "submitter": "Andre Mas", "authors": "Andr\\'e Mas (I3M), Besnik Pumo (INH)", "title": "Linear Processes for Functional Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linear processes on functional spaces were born about fifteen years ago. And\nthis original topic went through the same fast development as the other areas\nof functional data modeling such as PCA or regression. They aim at generalizing\nto random curves the classical ARMA models widely known in time series\nanalysis. They offer a wide spectrum of models suited to the statistical\ninference on continuous time stochastic processes within the paradigm of\nfunctional data. Essentially designed to improve the quality and the range of\nprediction, they give birth to challenging theoretical and applied problems. We\npropose here a state of the art which emphasizes recent advances and we present\nsome promising perspectives based on our experience in this area.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jan 2009 15:07:02 GMT"}], "update_date": "2009-09-30", "authors_parsed": [["Mas", "Andr\u00e9", "", "I3M"], ["Pumo", "Besnik", "", "INH"]]}, {"id": "0901.2593", "submitter": "Kjetil R{\\O}ysland", "authors": "Kjetil R{\\o}ysland", "title": "A martingale approach to continuous-time marginal structural models", "comments": "Published in at http://dx.doi.org/10.3150/10-BEJ303 the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2011, Vol. 17, No. 3, 895-915", "doi": "10.3150/10-BEJ303", "report-no": "IMS-BEJ-BEJ303", "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Marginal structural models were introduced in order to provide estimates of\ncausal effects from interventions based on observational studies in\nepidemiological research. The key point is that this can be understood in terms\nof Girsanov's change of measure. This offers a mathematical interpretation of\nmarginal structural models that has not been available before. We consider both\na model of an observational study and a model of a hypothetical randomized\ntrial. These models correspond to different martingale measures -- the\nobservational measure and the randomized trial measure -- on some underlying\nspace. We describe situations where the randomized trial measure is absolutely\ncontinuous with respect to the observational measure. The resulting\ncontinuous-time likelihood ratio process with respect to these two probability\nmeasures corresponds to the weights in discrete-time marginal structural\nmodels. In order to do inference for the hypothetical randomized trial, we can\nsimulate samples using observational data weighted by this likelihood ratio.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jan 2009 17:26:22 GMT"}, {"version": "v2", "created": "Mon, 23 Nov 2009 13:24:48 GMT"}, {"version": "v3", "created": "Fri, 30 Jul 2010 14:29:30 GMT"}, {"version": "v4", "created": "Thu, 14 Jul 2011 09:20:45 GMT"}], "update_date": "2011-07-15", "authors_parsed": [["R\u00f8ysland", "Kjetil", ""]]}, {"id": "0901.2735", "submitter": "Robert Grossman", "authors": "Robert L Grossman and Richard G Larson", "title": "State Space Realization Theorems For Data Mining", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML math.RA math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider formal series associated with events, profiles\nderived from events, and statistical models that make predictions about events.\nWe prove theorems about realizations for these formal series using the language\nand tools of Hopf algebras.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jan 2009 20:54:05 GMT"}], "update_date": "2009-01-20", "authors_parsed": [["Grossman", "Robert L", ""], ["Larson", "Richard G", ""]]}, {"id": "0901.2951", "submitter": "Jan Mandel", "authors": "Jan Mandel, Loren Cobb, and Jonathan D. Beezley", "title": "On the Convergence of the Ensemble Kalman Filter", "comments": "Revised, 8 pages", "journal-ref": "Applications of Mathematics 56, 533-541, 2011", "doi": "10.1007/s10492-011-0031-2", "report-no": "UCD CCM Report 278", "categories": "math.ST math.PR physics.ao-ph stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convergence of the ensemble Kalman filter in the limit for large ensembles to\nthe Kalman filter is proved. In each step of the filter, convergence of the\nensemble sample covariance follows from a weak law of large numbers for\nexchangeable random variables, the continuous mapping theorem gives convergence\nin probability of the ensemble members, and $L^p$ bounds on the ensemble then\ngive $L^p$ convergence.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jan 2009 00:42:41 GMT"}, {"version": "v2", "created": "Tue, 3 May 2011 13:16:11 GMT"}], "update_date": "2012-01-31", "authors_parsed": [["Mandel", "Jan", ""], ["Cobb", "Loren", ""], ["Beezley", "Jonathan D.", ""]]}, {"id": "0901.2962", "submitter": "Tong Zhang", "authors": "Junzhou Huang, Tong Zhang", "title": "The Benefit of Group Sparsity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper develops a theory for group Lasso using a concept called strong\ngroup sparsity. Our result shows that group Lasso is superior to standard Lasso\nfor strongly group-sparse signals. This provides a convincing theoretical\njustification for using group sparse regularization when the underlying group\nstructure is consistent with the data. Moreover, the theory predicts some\nlimitations of the group Lasso formulation that are confirmed by simulation\nstudies.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jan 2009 02:26:44 GMT"}, {"version": "v2", "created": "Tue, 17 Mar 2009 13:33:45 GMT"}], "update_date": "2009-03-17", "authors_parsed": [["Huang", "Junzhou", ""], ["Zhang", "Tong", ""]]}, {"id": "0901.3079", "submitter": "Elizaveta Levina", "authors": "Peter J. Bickel, Elizaveta Levina", "title": "Covariance regularization by thresholding", "comments": "Published in at http://dx.doi.org/10.1214/08-AOS600 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2008, Vol. 36, No. 6, 2577-2604", "doi": "10.1214/08-AOS600", "report-no": "IMS-AOS-AOS600", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers regularizing a covariance matrix of $p$ variables\nestimated from $n$ observations, by hard thresholding. We show that the\nthresholded estimate is consistent in the operator norm as long as the true\ncovariance matrix is sparse in a suitable sense, the variables are Gaussian or\nsub-Gaussian, and $(\\log p)/n\\to0$, and obtain explicit rates. The results are\nuniform over families of covariance matrices which satisfy a fairly natural\nnotion of sparsity. We discuss an intuitive resampling scheme for threshold\nselection and prove a general cross-validation result that justifies this\napproach. We also compare thresholding to other covariance estimators in\nsimulations and on an example from climate data.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jan 2009 15:40:35 GMT"}], "update_date": "2009-01-21", "authors_parsed": [["Bickel", "Peter J.", ""], ["Levina", "Elizaveta", ""]]}, {"id": "0901.3220", "submitter": "Noureddine El Karoui", "authors": "Noureddine El Karoui", "title": "Operator norm consistent estimation of large-dimensional sparse\n  covariance matrices", "comments": "Published in at http://dx.doi.org/10.1214/07-AOS559 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2008, Vol. 36, No. 6, 2717-2756", "doi": "10.1214/07-AOS559", "report-no": "IMS-AOS-AOS559", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating covariance matrices is a problem of fundamental importance in\nmultivariate statistics. In practice it is increasingly frequent to work with\ndata matrices $X$ of dimension $n\\times p$, where $p$ and $n$ are both large.\nResults from random matrix theory show very clearly that in this setting,\nstandard estimators like the sample covariance matrix perform in general very\npoorly. In this \"large $n$, large $p$\" setting, it is sometimes the case that\npractitioners are willing to assume that many elements of the population\ncovariance matrix are equal to 0, and hence this matrix is sparse. We develop\nan estimator to handle this situation. The estimator is shown to be consistent\nin operator norm, when, for instance, we have $p\\asymp n$ as $n\\to\\infty$. In\nother words the largest singular value of the difference between the estimator\nand the population covariance matrix goes to zero. This implies consistency of\nall the eigenvalues and consistency of eigenspaces associated to isolated\neigenvalues. We also propose a notion of sparsity for matrices, that is,\n\"compatible\" with spectral analysis and is independent of the ordering of the\nvariables.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jan 2009 10:03:58 GMT"}], "update_date": "2009-01-22", "authors_parsed": [["Karoui", "Noureddine El", ""]]}, {"id": "0901.3245", "submitter": "Boaz Nadler", "authors": "Boaz Nadler", "title": "Finite sample approximation results for principal component analysis: a\n  matrix perturbation approach", "comments": "Published in at http://dx.doi.org/10.1214/08-AOS618 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2008, Vol. 36, No. 6, 2791-2817", "doi": "10.1214/08-AOS618", "report-no": "IMS-AOS-AOS618", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Principal component analysis (PCA) is a standard tool for dimensional\nreduction of a set of $n$ observations (samples), each with $p$ variables. In\nthis paper, using a matrix perturbation approach, we study the nonasymptotic\nrelation between the eigenvalues and eigenvectors of PCA computed on a finite\nsample of size $n$, and those of the limiting population PCA as $n\\to\\infty$.\nAs in machine learning, we present a finite sample theorem which holds with\nhigh probability for the closeness between the leading eigenvalue and\neigenvector of sample PCA and population PCA under a spiked covariance model.\nIn addition, we also consider the relation between finite sample PCA and the\nasymptotic results in the joint limit $p,n\\to\\infty$, with $p/n=c$. We present\na matrix perturbation view of the \"phase transition phenomenon,\" and a simple\nlinear-algebra based derivation of the eigenvalue and eigenvector overlap in\nthis asymptotic limit. Moreover, our analysis also applies for finite $p,n$\nwhere we show that although there is no sharp phase transition as in the\ninfinite case, either as a function of noise level or as a function of sample\nsize $n$, the eigenvector of sample PCA may exhibit a sharp \"loss of tracking,\"\nsuddenly losing its relation to the (true) eigenvector of the population PCA\nmatrix. This occurs due to a crossover between the eigenvalue due to the signal\nand the largest eigenvalue due to noise, whose eigenvector points in a random\ndirection.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jan 2009 12:05:10 GMT"}], "update_date": "2009-01-22", "authors_parsed": [["Nadler", "Boaz", ""]]}, {"id": "0901.3267", "submitter": "H\\'el\\`ene Massam", "authors": "Bala Rajaratnam, H\\'el\\`ene Massam, Carlos M. Carvalho", "title": "Flexible covariance estimation in graphical Gaussian models", "comments": "Published in at http://dx.doi.org/10.1214/08-AOS619 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2008, Vol. 36, No. 6, 2818-2849", "doi": "10.1214/08-AOS619", "report-no": "IMS-AOS-AOS619", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a class of Bayes estimators for the covariance\nmatrix of graphical Gaussian models Markov with respect to a decomposable graph\n$G$. Working with the $W_{P_G}$ family defined by Letac and Massam [Ann.\nStatist. 35 (2007) 1278--1323] we derive closed-form expressions for Bayes\nestimators under the entropy and squared-error losses. The $W_{P_G}$ family\nincludes the classical inverse of the hyper inverse Wishart but has many more\nshape parameters, thus allowing for flexibility in differentially shrinking\nvarious parts of the covariance matrix. Moreover, using this family avoids\nrecourse to MCMC, often infeasible in high-dimensional problems. We illustrate\nthe performance of our estimators through a collection of numerical examples\nwhere we explore frequentist risk properties and the efficacy of graphs in the\nestimation of high-dimensional covariance structures.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jan 2009 13:13:37 GMT"}], "update_date": "2009-01-22", "authors_parsed": [["Rajaratnam", "Bala", ""], ["Massam", "H\u00e9l\u00e8ne", ""], ["Carvalho", "Carlos M.", ""]]}, {"id": "0901.3290", "submitter": "Armin Schwartzman", "authors": "Armin Schwartzman, Walter F. Mascarenhas, Jonathan E. Taylor", "title": "Inference for eigenvalues and eigenvectors of Gaussian symmetric\n  matrices", "comments": "Published in at http://dx.doi.org/10.1214/08-AOS628 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2008, Vol. 36, No. 6, 2886-2919", "doi": "10.1214/08-AOS628", "report-no": "IMS-AOS-AOS628", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article presents maximum likelihood estimators (MLEs) and log-likelihood\nratio (LLR) tests for the eigenvalues and eigenvectors of Gaussian random\nsymmetric matrices of arbitrary dimension, where the observations are\nindependent repeated samples from one or two populations. These inference\nproblems are relevant in the analysis of diffusion tensor imaging data and\npolarized cosmic background radiation data, where the observations are,\nrespectively, $3\\times3$ and $2\\times2$ symmetric positive definite matrices.\nThe parameter sets involved in the inference problems for eigenvalues and\neigenvectors are subsets of Euclidean space that are either affine subspaces,\nembedded submanifolds that are invariant under orthogonal transformations or\npolyhedral convex cones. We show that for a class of sets that includes the\nones considered in this paper, the MLEs of the mean parameter do not depend on\nthe covariance parameters if and only if the covariance structure is\northogonally invariant. Closed-form expressions for the MLEs and the associated\nLLRs are derived for this covariance structure.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jan 2009 15:14:50 GMT"}], "update_date": "2009-01-22", "authors_parsed": [["Schwartzman", "Armin", ""], ["Mascarenhas", "Walter F.", ""], ["Taylor", "Jonathan E.", ""]]}, {"id": "0901.3379", "submitter": "Yifeng Xue", "authors": "Fei Li and Yifeng Xue", "title": "Zonal polynomials and hypergeometric functions of quaternion matrix\n  argument", "comments": "22 pages. Communications in Statistics - Theory and Methods (appear)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define zonal polynomials of quaternion matrix argument and deduce some\nimportant formulae of zonal polynomials and hypergeometric functions of\nquaternion matrix argument. As an application, we give the distributions of the\nlargest and smallest eigenvalues of a quaternion central Wishart matrix\n$W\\sim\\mathbb{Q}W(n,\\Sigma)$, respectively.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jan 2009 23:22:03 GMT"}], "update_date": "2009-01-23", "authors_parsed": [["Li", "Fei", ""], ["Xue", "Yifeng", ""]]}, {"id": "0901.3471", "submitter": "Dragi Anevski", "authors": "Dragi Anevski, Philippe Soulier", "title": "Monotone spectral density estimation", "comments": "Published in at http://dx.doi.org/10.1214/10-AOS804 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2011, Vol. 39, No. 1, 418-438", "doi": "10.1214/10-AOS804", "report-no": "IMS-AOS-AOS804", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose two estimators of a monotone spectral density, that are based on\nthe periodogram. These are the isotonic regression of the periodogram and the\nisotonic regression of the log-periodogram. We derive pointwise limit\ndistribution results for the proposed estimators for short memory linear\nprocesses and long memory Gaussian processes and also that the estimators are\nrate optimal.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jan 2009 12:50:09 GMT"}, {"version": "v2", "created": "Fri, 29 Jan 2010 15:38:40 GMT"}, {"version": "v3", "created": "Wed, 9 Mar 2011 12:58:22 GMT"}], "update_date": "2011-03-10", "authors_parsed": [["Anevski", "Dragi", ""], ["Soulier", "Philippe", ""]]}, {"id": "0901.3749", "submitter": "Alexander Sch\\\"onhuth", "authors": "Alexander Schoenhuth", "title": "Equations for hidden Markov models", "comments": "28 pages; Results presented at the Workshop on Algebraic Statistics,\n  MSRI, UC Berkeley, Dec. 2008. Simplified arguments", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.AG stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We will outline novel approaches to derive model invariants for hidden Markov\nand related models. These approaches are based on a theoretical framework that\narises from viewing random processes as elements of the vector space of string\nfunctions. Theorems available from that framework then give rise to novel ideas\nto obtain model invariants for hidden Markov and related models.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jan 2009 18:50:54 GMT"}, {"version": "v2", "created": "Sun, 8 Feb 2009 01:19:42 GMT"}], "update_date": "2009-02-08", "authors_parsed": [["Schoenhuth", "Alexander", ""]]}, {"id": "0901.3795", "submitter": "Krzysztof J. Szajowski", "authors": "Krzysztof Szajowski", "title": "On a random number of disorders", "comments": "in Institute of Mathematics, Polish Academy of Science, Preprint no.\n  702, 25 references, 34 pages", "journal-ref": "Probability and Mathematical Statistics, vol. 31, Fasc. 1 (2011),\n  pp. 17-45", "doi": null, "report-no": null, "categories": "math.PR cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We register a random sequence which has the following properties: it has\nthree segments being the homogeneous Markov processes. Each segment has his own\none step transition probability law and the length of the segment is unknown\nand random. It means that at two random successive moments (they can be equal\nalso and equal zero too) the source of observations is changed and the first\nobservation in new segment is chosen according to new transition probability\nstarting from the last state of the previous segment. In effect the number of\nhomogeneous segments is random. The transition probabilities of each process\nare known and a priori distribution of the disorder moments is given. The\nformer research on such problem has been devoted to various questions\nconcerning the distribution changes. The random number of distributional\nsegments creates new problems in solutions with relation to analysis of the\nmodel with deterministic number of segments. Two cases are presented in\ndetails. In the first one the objectives is to stop on or between the disorder\nmoments while in the second one our objective is to find the strategy which\nimmediately detects the distribution changes. Both problems are reformulated to\noptimal stopping of the observed sequences. The detailed analysis of the\nproblem is presented to show the form of optimal decision function.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jan 2009 23:42:08 GMT"}, {"version": "v2", "created": "Tue, 7 Apr 2009 22:51:36 GMT"}, {"version": "v3", "created": "Tue, 26 Jan 2010 07:57:53 GMT"}], "update_date": "2011-11-21", "authors_parsed": [["Szajowski", "Krzysztof", ""]]}, {"id": "0901.4137", "submitter": "Marcus Hutter", "authors": "Marcus Hutter", "title": "Practical Robust Estimators for the Imprecise Dirichlet Model", "comments": "22 pages, 2 figures", "journal-ref": "International Journal of Approximate Reasoning, 50:2 (2009) pages\n  231-242", "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Walley's Imprecise Dirichlet Model (IDM) for categorical i.i.d. data extends\nthe classical Dirichlet model to a set of priors. It overcomes several\nfundamental problems which other approaches to uncertainty suffer from. Yet, to\nbe useful in practice, one needs efficient ways for computing the\nimprecise=robust sets or intervals. The main objective of this work is to\nderive exact, conservative, and approximate, robust and credible interval\nestimates under the IDM for a large class of statistical estimators, including\nthe entropy and mutual information.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jan 2009 23:05:06 GMT"}], "update_date": "2009-12-30", "authors_parsed": [["Hutter", "Marcus", ""]]}, {"id": "0901.4184", "submitter": "Clayton Scott", "authors": "Clayton Scott, Gowtham Bellala, Rebecca Willett", "title": "The False Discovery Rate for Statistical Pattern Recognition", "comments": "Submitted to the Electronic Journal of Statistics\n  (http://www.i-journals.org/ejs/) by the Institute of Mathematical Statistics\n  (http://www.imstat.org)", "journal-ref": null, "doi": null, "report-no": "IMS-EJS-EJS_2009_363", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The false discovery rate (FDR) and false nondiscovery rate (FNDR) have\nreceived considerable attention in the literature on multiple testing. These\nperformance measures are also appropriate for classification, and in this work\nwe develop generalization error analyses for FDR and FNDR when learning a\nclassifier from labeled training data. Unlike more conventional classification\nperformance measures, the empirical FDR and FNDR are not binomial random\nvariables but rather a ratio of binomials, which introduces challenges not\naddressed in conventional analyses. We develop distribution-free uniform\ndeviation bounds and apply these to obtain finite sample bounds and strong\nuniversal consistency.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jan 2009 07:01:51 GMT"}], "update_date": "2009-01-28", "authors_parsed": [["Scott", "Clayton", ""], ["Bellala", "Gowtham", ""], ["Willett", "Rebecca", ""]]}, {"id": "0901.4186", "submitter": "Denys Pommeret", "authors": "Denys Pommeret", "title": "Testing distribution in deconvolution problems", "comments": "Submitted to the Electronic Journal of Statistics\n  (http://www.i-journals.org/ejs/) by the Institute of Mathematical Statistics\n  (http://www.imstat.org)", "journal-ref": null, "doi": null, "report-no": "IMS-EJS-EJS_2009_364", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider a random variable $Y$ contamined by an independent\nadditive noise $Z$. We assume that $Z$ has known distribution. Our purpose is\nto test the distribution of the unobserved random variable $Y$. We propose a\ndata driven statistic based on a development of the density of $Y+Z$, which is\nvalid in the discrete case and in the continuous case. The test is illustrated\nin both cases.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jan 2009 07:24:08 GMT"}], "update_date": "2009-01-28", "authors_parsed": [["Pommeret", "Denys", ""]]}, {"id": "0901.4232", "submitter": "Jean-Luc Marichal", "authors": "Jean-Luc Marichal", "title": "Aggregation functions for decision making", "comments": null, "journal-ref": "D. Bouyssou, D. Dubois, M. Pirlot and H. Prade (eds.),\n  Decision-Making Process, Concepts and Methods (ISTE/John Wiley, 2009) pp.\n  673-721 [ISBN 978-1-84821-116-2]", "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aggregation functions are generally defined and used to combine several\nnumerical values into a single one, so that the final result of the aggregation\ntakes into account all the individual values in a given manner. Such functions\nare widely used in many well-known disciplines such as statistics, economics,\nfinance, and computer science. In this paper we confine ourselves to the use of\naggregation functions in decision making.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jan 2009 12:11:46 GMT"}], "update_date": "2009-06-22", "authors_parsed": [["Marichal", "Jean-Luc", ""]]}, {"id": "0901.4252", "submitter": "Michal Benko", "authors": "Michal Benko, Wolfgang H\\\"ardle, Alois Kneip", "title": "Common functional principal components", "comments": "Published in at http://dx.doi.org/10.1214/07-AOS516 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2009, Vol. 37, No. 1, 1-34", "doi": "10.1214/07-AOS516", "report-no": "IMS-AOS-AOS516", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Functional principal component analysis (FPCA) based on the\nKarhunen--Lo\\`{e}ve decomposition has been successfully applied in many\napplications, mainly for one sample problems. In this paper we consider common\nfunctional principal components for two sample problems. Our research is\nmotivated not only by the theoretical challenge of this data situation, but\nalso by the actual question of dynamics of implied volatility (IV) functions.\nFor different maturities the log-returns of IVs are samples of (smooth) random\nfunctions and the methods proposed here study the similarities of their\nstochastic behavior. First we present a new method for estimation of functional\nprincipal components from discrete noisy data. Next we present the two sample\ninference for FPCA and develop the two sample theory. We propose bootstrap\ntests for testing the equality of eigenvalues, eigenfunctions, and mean\nfunctions of two functional samples, illustrate the test-properties by\nsimulation study and apply the method to the IV analysis.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jan 2009 13:58:57 GMT"}], "update_date": "2009-01-28", "authors_parsed": [["Benko", "Michal", ""], ["H\u00e4rdle", "Wolfgang", ""], ["Kneip", "Alois", ""]]}, {"id": "0901.4266", "submitter": "Jan Johannes", "authors": "Jan Johannes", "title": "Nonparametric estimation in functional linear models with second order\n  stationary regressors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of estimating the slope parameter in functional\nlinear regression, where scalar responses Y1,...,Yn are modeled in dependence\nof second order stationary random functions X1,...,Xn. An orthogonal series\nestimator of the functional slope parameter with additional thresholding in the\nFourier domain is proposed and its performance is measured with respect to a\nwide range of weighted risks covering as examples the mean squared prediction\nerror and the mean integrated squared error for derivative estimation. In this\npaper the minimax optimal rate of convergence of the estimator is derived over\na large class of different regularity spaces for the slope parameter and of\ndifferent link conditions for the covariance operator. These general results\nare illustrated by the particular example of the well-known Sobolev space of\nperiodic functions as regularity space for the slope parameter and the case of\nfinitely or infinitely smoothing covariance operator.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jan 2009 17:36:10 GMT"}], "update_date": "2009-01-28", "authors_parsed": [["Johannes", "Jan", ""]]}, {"id": "0901.4321", "submitter": "Jean-Michel Loubes", "authors": "Jean-Michel Loubes (IMT), Cl\\'ement Marteau (IMT)", "title": "Oracle Inequality for Instrumental Variable Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We tackle the problem of estimating a regression function observed in an\ninstrumental regression framework. This model is an inverse problem with\nunknown operator. We provide a spectral cut-off estimation procedure which\nenables to derive oracle inequalities which warrants that our estimate, built\nwithout any prior knowledge, behaves as well as, up to $\\log$ term, if the best\nmodel were known.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jan 2009 19:51:01 GMT"}], "update_date": "2009-01-28", "authors_parsed": [["Loubes", "Jean-Michel", "", "IMT"], ["Marteau", "Cl\u00e9ment", "", "IMT"]]}, {"id": "0901.4392", "submitter": "Iain Johnstone", "authors": "Iain M Johnstone and Arthur Yu Lu", "title": "Sparse Principal Components Analysis", "comments": "This manuscript was written in late 2003; a much revised version is\n  to appear, with discussion and later references, in the Journal of the\n  American Statistical Association in 2009. The JASA revision cites this\n  archive version for the proof of inconsistency of PCA", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Principal components analysis (PCA) is a classical method for the reduction\nof dimensionality of data in the form of n observations (or cases) of a vector\nwith p variables. For a simple model of factor analysis type, it is proved that\nordinary PCA can produce a consistent (for n large) estimate of the principal\nfactor if and only if p(n) is asymptotically of smaller order than n.\n  There may be a basis in which typical signals have sparse representations:\nmost co-ordinates have small signal energies. If such a basis (e.g. wavelets)\nis used to represent the signals, then the variation in many coordinates is\nlikely to be small. Consequently, we study a simple \"sparse PCA\" algorithm:\nselect a subset of coordinates of largest variance, estimate eigenvectors from\nPCA on the selected subset, threshold and reexpress in the original basis. We\nillustrate the algorithm on some exercise ECG data, and prove that in a single\nfactor model, under an appropriate sparsity assumption, it yields consistent\nestimates of the principal factor.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jan 2009 02:40:50 GMT"}], "update_date": "2009-01-29", "authors_parsed": [["Johnstone", "Iain M", ""], ["Lu", "Arthur Yu", ""]]}, {"id": "0901.4456", "submitter": "Ivan Nourdin", "authors": "Jean-Christophe Breton (MIA), Ivan Nourdin (PMA), Giovanni Peccati\n  (MODAL'X)", "title": "Exact confidence intervals for the Hurst parameter of a fractional\n  Brownian motion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this short note, we show how to use concentration inequalities in order to\nbuild exact confidence intervals for the Hurst parameter associated with a\none-dimensional fractional Brownian motion\n", "versions": [{"version": "v1", "created": "Wed, 28 Jan 2009 13:35:15 GMT"}], "update_date": "2009-01-29", "authors_parsed": [["Breton", "Jean-Christophe", "", "MIA"], ["Nourdin", "Ivan", "", "PMA"], ["Peccati", "Giovanni", "", "MODAL'X"]]}, {"id": "0901.4628", "submitter": "Yuliya V. Martsynyuk", "authors": "Yuliya V. Martsynyuk", "title": "Functional asymptotic confidence intervals for a common mean of\n  independent random variables", "comments": "Published in at http://dx.doi.org/10.1214/08-EJS233 the Electronic\n  Journal of Statistics (http://www.i-journals.org/ejs/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Electronic Journal of Statistics 2009, Vol. 3, 25-40", "doi": "10.1214/08-EJS233", "report-no": "IMS-EJS-EJS_2008_233", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider independent random variables (r.v.'s) with a common mean $\\mu$\nthat either satisfy Lindeberg's condition, or are symmetric around $\\mu$.\nPresent forms of existing functional central limit theorems (FCLT's) for\nStudentized partial sums of such r.v.'s on $D[0,1]$ are seen to be of some use\nfor constructing asymptotic confidence intervals, or what we call functional\nasymptotic confidence intervals (FACI's), for $\\mu$. In this paper we establish\ncompletely data-based versions of these FCLT's and thus extend their\napplicability in this regard. Two special examples of new FACI's for $\\mu$ are\npresented.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jan 2009 09:21:51 GMT"}], "update_date": "2009-01-30", "authors_parsed": [["Martsynyuk", "Yuliya V.", ""]]}, {"id": "0901.4715", "submitter": "Tomonari Sei", "authors": "Tomonari Sei", "title": "A structural model on a hypercube represented by optimal transport", "comments": "28pages, 6figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a flexible statistical model for high-dimensional quantitative\ndata on a hypercube. Our model, called the structural gradient model (SGM), is\nbased on a one-to-one map on the hypercube that is a solution for an optimal\ntransport problem. As we show with many examples, SGM can describe various\ndependence structures including correlation and heteroscedasticity. The maximum\nlikelihood estimation of SGM is effectively solved by the\ndeterminant-maximization programming. In particular, a lasso-type estimation is\navailable by adding constraints. SGM is compared with graphical Gaussian models\nand mixture models.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jan 2009 16:25:19 GMT"}], "update_date": "2009-01-30", "authors_parsed": [["Sei", "Tomonari", ""]]}, {"id": "0901.4925", "submitter": "Yaozhong Hu", "authors": "Yaozhong Hu, David Nualart", "title": "Parameter estimation for fractional Ornstein-Uhlenbeck processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a least squares estimator $\\hat {\\theta}_T$ for the\nOrnstein-Uhlenbeck process, $dX_t=\\theta X_t dt+\\sigma dB^H_t$, driven by\nfractional Brownian motion $B^H$ with Hurst parameter $H\\ge \\frac12$. We prove\nthe strong consistence of $\\hat {\\theta}_T$ (the almost surely convergence of\n$\\hat {\\theta}_T$ to the true parameter ${% \\theta}$). We also obtain the rate\nof this convergence when $1/2\\le H<3/4$, applying a central limit theorem for\nmultiple Wiener integrals. This least squares estimator can be used to study\nother more simulation friendly estimators such as the estimator $\\tilde\n\\theta_T$ defined by (4.1).\n", "versions": [{"version": "v1", "created": "Fri, 30 Jan 2009 16:35:18 GMT"}], "update_date": "2009-02-02", "authors_parsed": [["Hu", "Yaozhong", ""], ["Nualart", "David", ""]]}]