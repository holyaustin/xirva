[{"id": "1003.0173", "submitter": "Carles Breto Martinez", "authors": "Carles Breto and Edward L. Ionides", "title": "Compound Markov counting processes and their applications to modeling\n  infinitesimally over-dispersed systems", "comments": "26 pages", "journal-ref": "Stochastic Processes and their Applications 2011, Vol. 121 (11),\n  2571-2591", "doi": "10.1016/j.spa.2011.07.005", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an infinitesimal dispersion index for Markov counting processes.\nWe show that, under standard moment existence conditions, a process is\ninfinitesimally (over-) equi-dispersed if, and only if, it is simple\n(compound), i.e. it increases in jumps of one (or more) unit(s), even though\ninfinitesimally equi-dispersed processes might be under-, equi- or\nover-dispersed using previously studied indices. Compound processes arise, for\nexample, when introducing continuous-time white noise to the rates of simple\nprocesses resulting in Levy-driven SDEs. We construct multivariate\ninfinitesimally over-dispersed compartment models and queuing networks,\nsuitable for applications where moment constraints inherent to simple processes\ndo not hold.\n", "versions": [{"version": "v1", "created": "Sun, 28 Feb 2010 11:02:20 GMT"}], "update_date": "2014-03-25", "authors_parsed": [["Breto", "Carles", ""], ["Ionides", "Edward L.", ""]]}, {"id": "1003.0205", "submitter": "Aarti Singh", "authors": "Aarti Singh, Robert D. Nowak and Robert Calderbank", "title": "Detecting Weak but Hierarchically-Structured Patterns in Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to detect weak distributed activation patterns in networks is\ncritical to several applications, such as identifying the onset of anomalous\nactivity or incipient congestion in the Internet, or faint traces of a\nbiochemical spread by a sensor network. This is a challenging problem since\nweak distributed patterns can be invisible in per node statistics as well as a\nglobal network-wide aggregate. Most prior work considers situations in which\nthe activation/non-activation of each node is statistically independent, but\nthis is unrealistic in many problems. In this paper, we consider structured\npatterns arising from statistical dependencies in the activation process. Our\ncontributions are three-fold. First, we propose a sparsifying transform that\nsuccinctly represents structured activation patterns that conform to a\nhierarchical dependency graph. Second, we establish that the proposed transform\nfacilitates detection of very weak activation patterns that cannot be detected\nwith existing methods. Third, we show that the structure of the hierarchical\ndependency graph governing the activation process, and hence the network\ntransform, can be learnt from very few (logarithmic in network size)\nindependent snapshots of network activity.\n", "versions": [{"version": "v1", "created": "Sun, 28 Feb 2010 18:23:11 GMT"}], "update_date": "2010-03-02", "authors_parsed": [["Singh", "Aarti", ""], ["Nowak", "Robert D.", ""], ["Calderbank", "Robert", ""]]}, {"id": "1003.0248", "submitter": "RadhaKrishna Ganti", "authors": "Riccardo Giacomelli and Radha Krishna Ganti and Martin Haenggi", "title": "Outage Probability of General Ad Hoc Networks in the High-Reliability\n  Regime", "comments": "Submitted to IEEE Transactions on Networking (Revision 2)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Outage probabilities in wireless networks depend on various factors: the node\ndistribution, the MAC scheme, and the models for path loss, fading and\ntransmission success. In prior work on outage characterization for networks\nwith randomly placed nodes, most of the emphasis was put on networks whose\nnodes are Poisson distributed and where ALOHA is used as the MAC protocol. In\nthis paper we provide a general framework for the analysis of outage\nprobabilities in the high-reliability regime. The outage probability\ncharacterization is based on two parameters: the intrinsic spatial contention\n$\\gamma$ of the network, introduced in [1], and the coordination level achieved\nby the MAC as measured by the interference scaling exponent $\\kappa$ introduced\nin this paper. We study outage probabilities under the signal-to-interference\nratio (SIR) model, Rayleigh fading, and power-law path loss, and explain how\nthe two parameters depend on the network model. The main result is that the\noutage probability approaches $\\gamma\\eta^{\\kappa}$ as the density of\ninterferers $\\eta$ goes to zero, and that $\\kappa$ assumes values in the range\n$1\\leq \\kappa\\leq \\alpha/2$ for all practical MAC protocols, where $\\alpha$ is\nthe path loss exponent. This asymptotic expression is valid for all\nmotion-invariant point processes. We suggest a novel and complete taxonomy of\nMAC protocols based mainly on the value of $\\kappa$. Finally, our findings\nsuggest a conjecture that tightly bounds the outage probability for all\ninterferer densities.\n", "versions": [{"version": "v1", "created": "Mon, 1 Mar 2010 04:37:34 GMT"}, {"version": "v2", "created": "Wed, 6 Oct 2010 21:34:32 GMT"}], "update_date": "2010-10-08", "authors_parsed": [["Giacomelli", "Riccardo", ""], ["Ganti", "Radha Krishna", ""], ["Haenggi", "Martin", ""]]}, {"id": "1003.0261", "submitter": "Jane-Ling Wang", "authors": "Ci-Ren Jiang, Jane-Ling Wang", "title": "Covariate adjusted functional principal components analysis for\n  longitudinal data", "comments": "Published in at http://dx.doi.org/10.1214/09-AOS742 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2010, Vol. 38, No. 2, 1194-1226", "doi": "10.1214/09-AOS742", "report-no": "IMS-AOS-AOS742", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical multivariate principal component analysis has been extended to\nfunctional data and termed functional principal component analysis (FPCA). Most\nexisting FPCA approaches do not accommodate covariate information, and it is\nthe goal of this paper to develop two methods that do. In the first approach,\nboth the mean and covariance functions depend on the covariate $Z$ and time\nscale $t$ while in the second approach only the mean function depends on the\ncovariate $Z$. Both new approaches accommodate additional measurement errors\nand functional data sampled at regular time grids as well as sparse\nlongitudinal data sampled at irregular time grids. The first approach to fully\nadjust both the mean and covariance functions adapts more to the data but is\ncomputationally more intensive than the approach to adjust the covariate\neffects on the mean function only. We develop general asymptotic theory for\nboth approaches and compare their performance numerically through simulation\nstudies and a data set.\n", "versions": [{"version": "v1", "created": "Mon, 1 Mar 2010 06:58:59 GMT"}], "update_date": "2010-03-02", "authors_parsed": [["Jiang", "Ci-Ren", ""], ["Wang", "Jane-Ling", ""]]}, {"id": "1003.0275", "submitter": "Denis Belomestny", "authors": "Denis Belomestny", "title": "Statistical inference for time-changed L\\'{e}vy processes via composite\n  characteristic function estimation", "comments": "Published in at http://dx.doi.org/10.1214/11-AOS901 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2011, Vol. 39, No. 4, 2205-2242", "doi": "10.1214/11-AOS901", "report-no": "IMS-AOS-AOS901", "categories": "stat.ME math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, the problem of semi-parametric inference on the parameters\nof a multidimensional L\\'{e}vy process $L_t$ with independent components based\non the low-frequency observations of the corresponding time-changed L\\'{e}vy\nprocess $L_{\\mathcal{T}(t)}$, where $\\mathcal{T}$ is a nonnegative,\nnondecreasing real-valued process independent of $L_t$, is studied. We show\nthat this problem is closely related to the problem of composite function\nestimation that has recently gotten much attention in statistical literature.\nUnder suitable identifiability conditions, we propose a consistent estimate for\nthe L\\'{e}vy density of $L_t$ and derive the uniform as well as the pointwise\nconvergence rates of the estimate proposed. Moreover, we prove that the rates\nobtained are optimal in a minimax sense over suitable classes of time-changed\nL\\'{e}vy models. Finally, we present a simulation study showing the performance\nof our estimation algorithm in the case of time-changed Normal Inverse Gaussian\n(NIG) L\\'{e}vy processes.\n", "versions": [{"version": "v1", "created": "Mon, 1 Mar 2010 08:45:30 GMT"}, {"version": "v2", "created": "Wed, 29 Dec 2010 14:14:12 GMT"}, {"version": "v3", "created": "Mon, 30 Jan 2012 14:32:55 GMT"}], "update_date": "2012-01-31", "authors_parsed": [["Belomestny", "Denis", ""]]}, {"id": "1003.0315", "submitter": "Aurore Delaigle", "authors": "Aurore Delaigle and Peter Hall", "title": "Kernel methods and minimum contrast estimators for empirical\n  deconvolution", "comments": "To appear in: Bingham, N. H., and Goldie, C. M. (eds), Probability\n  and Mathematical Genetics: Papers in Honour of Sir John Kingman. London Math.\n  Soc. Lecture Note Ser. Cambridge: Cambridge Univ. Press, 2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We survey classical kernel methods for providing nonparametric solutions to\nproblems involving measurement error. In particular we outline kernel-based\nmethodology in this setting, and discuss its basic properties. Then we point to\nclose connections that exist between kernel methods and much newer approaches\nbased on minimum contrast techniques. The connections are through use of the\nsinc kernel for kernel-based inference. This `infinite order' kernel is not\noften used explicitly for kernel-based deconvolution, although it has received\nattention in more conventional problems where measurement error is not an\nissue. We show that in a comparison between kernel methods for density\ndeconvolution, and their counterparts based on minimum contrast, the two\napproaches give identical results on a grid which becomes increasingly fine as\nthe bandwidth decreases. In consequence, the main numerical differences between\nthese two techniques are arguably the result of different approaches to\nchoosing smoothing parameters.\n", "versions": [{"version": "v1", "created": "Mon, 1 Mar 2010 11:33:37 GMT"}], "update_date": "2010-03-02", "authors_parsed": [["Delaigle", "Aurore", ""], ["Hall", "Peter", ""]]}, {"id": "1003.0428", "submitter": "Gabriel Stoltz", "authors": "Nicolas Chopin (CREST/Ensae), Tony Lelievre and Gabriel Stoltz\n  (CERMICS/Ecole des Ponts and Micmac, Inria)", "title": "Free Energy Methods for Bayesian Inference: Efficient Exploration of\n  Univariate Gaussian Mixture Posteriors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Because of their multimodality, mixture posterior distributions are difficult\nto sample with standard Markov chain Monte Carlo (MCMC) methods. We propose a\nstrategy to enhance the sampling of MCMC in this context, using a biasing\nprocedure which originates from computational Statistical Physics. The\nprinciple is first to choose a \"reaction coordinate\", that is, a \"direction\" in\nwhich the target distribution is multimodal. In a second step, the marginal\nlog-density of the reaction coordinate with respect to the posterior\ndistribution is estimated; minus this quantity is called \"free energy\" in the\ncomputational Statistical Physics literature. To this end, we use adaptive\nbiasing Markov chain algorithms which adapt their targeted invariant\ndistribution on the fly, in order to overcome sampling barriers along the\nchosen reaction coordinate. Finally, we perform an importance sampling step in\norder to remove the bias and recover the true posterior. The efficiency factor\nof the importance sampling step can easily be estimated \\emph{a priori} once\nthe bias is known, and appears to be rather large for the test cases we\nconsidered. A crucial point is the choice of the reaction coordinate. One\nstandard choice (used for example in the classical Wang-Landau algorithm) is\nminus the log-posterior density. We discuss other choices. We show in\nparticular that the hyper-parameter that determines the order of magnitude of\nthe variance of each component is both a convenient and an efficient reaction\ncoordinate. We also show how to adapt the method to compute the evidence\n(marginal likelihood) of a mixture model. We illustrate our approach by\nanalyzing two real data sets.\n", "versions": [{"version": "v1", "created": "Mon, 1 Mar 2010 19:24:16 GMT"}, {"version": "v2", "created": "Thu, 25 Mar 2010 20:12:08 GMT"}, {"version": "v3", "created": "Thu, 23 Sep 2010 05:21:51 GMT"}, {"version": "v4", "created": "Mon, 18 Apr 2011 13:00:46 GMT"}], "update_date": "2011-04-19", "authors_parsed": [["Chopin", "Nicolas", "", "CREST/Ensae"], ["Lelievre", "Tony", "", "CERMICS/Ecole des Ponts and Micmac, Inria"], ["Stoltz", "Gabriel", "", "CERMICS/Ecole des Ponts and Micmac, Inria"]]}, {"id": "1003.0747", "submitter": "Pierre Neuvial", "authors": "Pierre Neuvial (LPMA, SG)", "title": "Asymptotic Results on Adaptive False Discovery Rate Controlling\n  Procedures Based on Kernel Estimators", "comments": null, "journal-ref": "Journal of Machine Learning Research 14 (2013) 1423-1459", "doi": null, "report-no": null, "categories": "math.ST physics.data-an q-bio.QM stat.AP stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The False Discovery Rate (FDR) is a commonly used type I error rate in\nmultiple testing problems. It is defined as the expected False Discovery\nProportion (FDP), that is, the expected fraction of false positives among\nrejected hypotheses. When the hypotheses are independent, the\nBenjamini-Hochberg procedure achieves FDR control at any pre-specified level.\nBy construction, FDR control offers no guarantee in terms of power, or type II\nerror. A number of alternative procedures have been developed, including\nplug-in procedures that aim at gaining power by incorporating an estimate of\nthe proportion of true null hypotheses. In this paper, we study the asymptotic\nbehavior of a class of plug-in procedures based on kernel estimators of the\ndensity of the $p$-values, as the number $m$ of tested hypotheses grows to\ninfinity. In a setting where the hypotheses tested are independent, we prove\nthat these procedures are asymptotically more powerful in two respects: (i) a\ntighter asymptotic FDR control for any target FDR level and (ii) a broader\nrange of target levels yielding positive asymptotic power. We also show that\nthis increased asymptotic power comes at the price of slower, non-parametric\nconvergence rates for the FDP. These rates are of the form $m^{-k/(2k+1)}$,\nwhere $k$ is determined by the regularity of the density of the $p$-value\ndistribution, or, equivalently, of the test statistics distribution. These\nresults are applied to one- and two-sided tests statistics for Gaussian and\nLaplace location models, and for the Student model.\n", "versions": [{"version": "v1", "created": "Wed, 3 Mar 2010 08:17:28 GMT"}, {"version": "v2", "created": "Sat, 20 Apr 2013 08:47:22 GMT"}], "update_date": "2013-10-04", "authors_parsed": [["Neuvial", "Pierre", "", "LPMA, SG"]]}, {"id": "1003.0848", "submitter": "Niels Richard Hansen", "authors": "Niels Richard Hansen", "title": "Penalized maximum likelihood estimation for generalized linear point\n  processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A generalized linear point process is specified in terms of an intensity that\ndepends upon a linear predictor process through a fixed non-linear function. We\npresent a framework where the linear predictor is parametrized by a Banach\nspace and give results on Gateaux differentiability of the log-likelihood. Of\nparticular interest is when the intensity is expressed in terms of a linear\nfilter parametrized by a Sobolev space. Using that the Sobolev spaces are\nreproducing kernel Hilbert spaces we derive results on the representation of\nthe penalized maximum likelihood estimator in a special case and the gradient\nof the negative log-likelihood in general. The latter is used to develop a\ndescent algorithm in the Sobolev space. We conclude the paper by extensions to\nmultivariate and additive model specifications. The methods are implemented in\nthe R-package ppstat.\n", "versions": [{"version": "v1", "created": "Wed, 3 Mar 2010 16:30:56 GMT"}, {"version": "v2", "created": "Tue, 2 Apr 2013 15:39:36 GMT"}], "update_date": "2013-04-03", "authors_parsed": [["Hansen", "Niels Richard", ""]]}, {"id": "1003.0887", "submitter": "Bharath Sriperumbudur", "authors": "Bharath K. Sriperumbudur, Kenji Fukumizu and Gert R. G. Lanckriet", "title": "Universality, Characteristic Kernels and RKHS Embedding of Measures", "comments": "30 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Hilbert space embedding for probability measures has recently been\nproposed, wherein any probability measure is represented as a mean element in a\nreproducing kernel Hilbert space (RKHS). Such an embedding has found\napplications in homogeneity testing, independence testing, dimensionality\nreduction, etc., with the requirement that the reproducing kernel is\ncharacteristic, i.e., the embedding is injective.\n  In this paper, we generalize this embedding to finite signed Borel measures,\nwherein any finite signed Borel measure is represented as a mean element in an\nRKHS. We show that the proposed embedding is injective if and only if the\nkernel is universal. This therefore, provides a novel characterization of\nuniversal kernels, which are proposed in the context of achieving the Bayes\nrisk by kernel-based classification/regression algorithms. By exploiting this\nrelation between universality and the embedding of finite signed Borel measures\ninto an RKHS, we establish the relation between universal and characteristic\nkernels.\n", "versions": [{"version": "v1", "created": "Wed, 3 Mar 2010 20:30:07 GMT"}], "update_date": "2010-03-04", "authors_parsed": [["Sriperumbudur", "Bharath K.", ""], ["Fukumizu", "Kenji", ""], ["Lanckriet", "Gert R. G.", ""]]}, {"id": "1003.1146", "submitter": "Mathias Drton", "authors": "Mathias Drton, Rina Foygel, Seth Sullivant", "title": "Global identifiability of linear structural equation models", "comments": "Published in at http://dx.doi.org/10.1214/10-AOS859 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2011, Vol. 39, No. 2, 865-886", "doi": "10.1214/10-AOS859", "report-no": "IMS-AOS-AOS859", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Structural equation models are multivariate statistical models that are\ndefined by specifying noisy functional relationships among random variables. We\nconsider the classical case of linear relationships and additive Gaussian noise\nterms. We give a necessary and sufficient condition for global identifiability\nof the model in terms of a mixed graph encoding the linear structural equations\nand the correlation structure of the error terms. Global identifiability is\nunderstood to mean injectivity of the parametrization of the model and is\nfundamental in particular for applicability of standard statistical\nmethodology.\n", "versions": [{"version": "v1", "created": "Thu, 4 Mar 2010 21:53:45 GMT"}, {"version": "v2", "created": "Fri, 17 Sep 2010 23:15:07 GMT"}, {"version": "v3", "created": "Fri, 13 May 2011 09:15:00 GMT"}], "update_date": "2011-05-16", "authors_parsed": [["Drton", "Mathias", ""], ["Foygel", "Rina", ""], ["Sullivant", "Seth", ""]]}, {"id": "1003.1170", "submitter": "John Hartigan", "authors": "J.A.Hartigan", "title": "Asymptotic admissibility of priors and elliptic differential equations", "comments": "3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We evaluate priors by the second order asymptotic behavior of the\ncorresponding estimators.Under certain regularity conditions, the risk\ndifferences between efficient estimators of parameters taking values in a\ndomain D, an open connected subset of R^d, are asymptotically expressed as\nelliptic differential forms depending on the asymptotic covariance matrix V.\nEach efficient estimator has the same asymptotic risk as a 'local Bayes'\nestimate corresponding to a prior density p. The asymptotic decision theory of\nthe estimators identifies the smooth prior densities as admissible or\ninadmissible, according to the existence of solutions to certain elliptic\ndifferential equations. The prior p is admissible if the quantity pV is\nsufficiently small near the boundary of D. We exhibit the unique admissible\ninvariant prior for V=I,D=R^d-{0). A detailed example is given for a normal\nmixture model.\n", "versions": [{"version": "v1", "created": "Fri, 5 Mar 2010 01:00:31 GMT"}], "update_date": "2010-03-08", "authors_parsed": [["Hartigan", "J. A.", ""]]}, {"id": "1003.1189", "submitter": "Arnak Dalalyan S.", "authors": "Arnak S. Dalalyan (LIGM, CREST), Alexandre B. Tsybakov (CREST, LPMA)", "title": "Mirror averaging with sparsity priors", "comments": "Published in at http://dx.doi.org/10.3150/11-BEJ361 the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 18, 3 (2012) 914-944", "doi": "10.3150/11-BEJ361", "report-no": "IMS-BEJ-BEJ361", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of aggregating the elements of a possibly infinite\ndictionary for building a decision procedure that aims at minimizing a given\ncriterion. Along with the dictionary, an independent identically distributed\ntraining sample is available, on which the performance of a given procedure can\nbe tested. In a fairly general set-up, we establish an oracle inequality for\nthe Mirror Averaging aggregate with any prior distribution. By choosing an\nappropriate prior, we apply this oracle inequality in the context of prediction\nunder sparsity assumption for the problems of regression with random design,\ndensity estimation and binary classification.\n", "versions": [{"version": "v1", "created": "Fri, 5 Mar 2010 05:33:22 GMT"}, {"version": "v2", "created": "Thu, 25 Nov 2010 08:40:40 GMT"}, {"version": "v3", "created": "Fri, 27 Jul 2012 06:48:31 GMT"}, {"version": "v4", "created": "Fri, 17 Aug 2012 08:14:32 GMT"}], "update_date": "2013-03-25", "authors_parsed": [["Dalalyan", "Arnak S.", "", "LIGM, CREST"], ["Tsybakov", "Alexandre B.", "", "CREST, LPMA"]]}, {"id": "1003.1513", "submitter": "Ya'acov Ritov", "authors": "Ya'acov Ritov", "title": "On the trasductive arguments in statistics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper argues that a part of the current statistical discussion is not\nbased on the standard firm foundations of the field. Among the examples we\nconsider are prediction into the future, semi-supervised classification, and\ncausality inference based on observational data.\n", "versions": [{"version": "v1", "created": "Sun, 7 Mar 2010 18:59:16 GMT"}], "update_date": "2010-03-09", "authors_parsed": [["Ritov", "Ya'acov", ""]]}, {"id": "1003.1535", "submitter": "Justin Wishart", "authors": "Justin Wishart and Rafal Kulik", "title": "Kink estimation in stochastic regression with dependent errors and\n  predictors", "comments": "35 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we study the estimation of the location of jump points in the\nfirst derivative (referred to as kinks) of a regression function \\mu in two\nrandom design models with different long-range dependent (LRD) structures. The\nmethod is based on the zero-crossing technique and makes use of high-order\nkernels. The rate of convergence of the estimator is contingent on the level of\ndependence and the smoothness of the regression function \\mu. In one of the\nmodels, the convergence rate is the same as the minimax rate for kink\nestimation in the fixed design scenario with i.i.d. errors which suggests that\nthe method is optimal in the minimax sense.\n", "versions": [{"version": "v1", "created": "Mon, 8 Mar 2010 00:38:36 GMT"}], "update_date": "2010-03-09", "authors_parsed": [["Wishart", "Justin", ""], ["Kulik", "Rafal", ""]]}, {"id": "1003.1557", "submitter": "Jie Yang", "authors": "Abhyuday Mandal and Jie Yang and Dibyen Majumdar", "title": "Optimal Designs for Two-Level Factorial Experiments with Binary Response", "comments": "15 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of obtaining locally D-optimal designs for factorial\nexperiments with qualitative factors at two levels each with binary response.\nOur focus is primarily on the 2^2 experiment. In this paper, we derive analytic\nresults for some special cases and indicate how to handle the general case. The\nperformance of the uniform design in examined and we show that this design is\nhighly efficient in general. For the general 2^k case we show that the uniform\ndesign has a maximin property.\n", "versions": [{"version": "v1", "created": "Mon, 8 Mar 2010 05:41:36 GMT"}, {"version": "v2", "created": "Wed, 12 May 2010 04:25:13 GMT"}], "update_date": "2015-03-13", "authors_parsed": [["Mandal", "Abhyuday", ""], ["Yang", "Jie", ""], ["Majumdar", "Dibyen", ""]]}, {"id": "1003.1573", "submitter": "Guillermo Henry", "authors": "Wenceslao Gonzalez-Manteiga, Guillermo Henry and Daniela Rodriguez", "title": "Partially linear models on Riemannian manifolds", "comments": "7 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In partially linear models the dependence of the response y on (x^T,t) is\nmodeled through the relationship y=\\x^T \\beta+g(t)+\\epsilon where \\epsilon is\nindependent of (x^T,t). In this paper, estimators of \\beta and g are\nconstructed when the explanatory variables t take values on a Riemannian\nmanifold. Our proposal combine the flexibility of these models with the complex\nstructure of a set of explanatory variables. We prove that the resulting\nestimator of \\beta is asymptotically normal under the suitable conditions.\nThrough a simulation study, we explored the performance of the estimators.\nFinally, we applied the studied model to an example based on real dataset.\n", "versions": [{"version": "v1", "created": "Mon, 8 Mar 2010 09:12:05 GMT"}], "update_date": "2010-03-09", "authors_parsed": [["Gonzalez-Manteiga", "Wenceslao", ""], ["Henry", "Guillermo", ""], ["Rodriguez", "Daniela", ""]]}, {"id": "1003.1630", "submitter": "Philippe Rigollet", "authors": "Philippe Rigollet and Assaf Zeevi", "title": "Nonparametric Bandits with Covariates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a bandit problem which involves sequential sampling from two\npopulations (arms). Each arm produces a noisy reward realization which depends\non an observable random covariate. The goal is to maximize cumulative expected\nreward. We derive general lower bounds on the performance of any admissible\npolicy, and develop an algorithm whose performance achieves the order of said\nlower bound up to logarithmic terms. This is done by decomposing the global\nproblem into suitably \"localized\" bandit problems. Proofs blend ideas from\nnonparametric statistics and traditional methods used in the bandit literature.\n", "versions": [{"version": "v1", "created": "Mon, 8 Mar 2010 13:59:54 GMT"}], "update_date": "2010-03-09", "authors_parsed": [["Rigollet", "Philippe", ""], ["Zeevi", "Assaf", ""]]}, {"id": "1003.2289", "submitter": "Mireia Besal\\'{u}", "authors": "Mireia Besal\\'u, Carles Rovira", "title": "Stochastic delay equations with non-negativity constraints driven by\n  fractional Brownian motion", "comments": "Published in at http://dx.doi.org/10.3150/10-BEJ327 the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2012, Vol. 18, No. 1, 24-45", "doi": "10.3150/10-BEJ327", "report-no": "IMS-BEJ-BEJ327", "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this note we prove an existence and uniqueness result for the solution of\nmultidimensional stochastic delay differential equations with normal\nreflection. The equations are driven by a fractional Brownian motion with Hurst\nparameter $H>1/2$. The stochastic integral with respect to the fractional\nBrownian motion is a pathwise Riemann--Stieltjes integral.\n", "versions": [{"version": "v1", "created": "Thu, 11 Mar 2010 09:36:29 GMT"}, {"version": "v2", "created": "Fri, 2 Mar 2012 06:16:21 GMT"}], "update_date": "2012-03-05", "authors_parsed": [["Besal\u00fa", "Mireia", ""], ["Rovira", "Carles", ""]]}, {"id": "1003.2294", "submitter": "Jean-Baptiste Aubin", "authors": "Jean-Baptiste Aubin and Samuela Leoni-Aubin", "title": "A Simple Lack-of-Fit Test for Regression Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A simple test is proposed for examining the correctness of a given completely\nspecified response function against unspecified general alternatives in the\ncontext of univariate regression. The usual diagnostic tools based on residuals\nplots are useful but heuristic. We introduce a formal statistical test\nsupplementing the graphical analysis. Technically, the test statistic is the\nmaximum length of the sequences of ordered (with respect to the covariate)\nobservations that are consecutively overestimated or underestimated by the\ncandidate regression function. Note that the testing procedure can cope with\nheteroscedastic errors and no replicates. Recursive formulae allowing to\ncalculate the exact distribution of the test statistic under the null\nhypothesis and under a class of alternative hypotheses are given.\n", "versions": [{"version": "v1", "created": "Thu, 11 Mar 2010 09:59:27 GMT"}, {"version": "v2", "created": "Sun, 25 Apr 2010 11:14:38 GMT"}], "update_date": "2010-04-27", "authors_parsed": [["Aubin", "Jean-Baptiste", ""], ["Leoni-Aubin", "Samuela", ""]]}, {"id": "1003.2390", "submitter": "Babak Shahbaba", "authors": "Babak Shahbaba", "title": "Bayesian Nonparametric Variable Selection as an Exploratory Tool for\n  Finding Genes that Matter", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST q-bio.QM stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-throughput scientific studies involving no clear a'priori hypothesis are\ncommon. For example, a large-scale genomic study of a disease may examine\nthousands of genes without hypothesizing that any specific gene is responsible\nfor the disease. In these studies, the objective is to explore a large number\nof possible factors (e.g. genes) in order to identify a small number that will\nbe considered in follow-up studies that tend to be more thorough and on smaller\nscales. For large-scale studies, we propose a nonparametric Bayesian approach\nbased on random partition models. Our model thus divides the set of candidate\nfactors into several subgroups according to their degrees of relevance, or\npotential effect, in relation to the outcome of interest. The model allows for\na latent rank to be assigned to each factor according to the overall potential\nimportance of its corresponding group. The posterior expectation or mode of\nthese ranks is used to set up a threshold for selecting potentially relevant\nfactors. Using simulated data, we demonstrate that our approach could be quite\neffective in finding relevant genes compared to several alternative methods. We\napply our model to two large-scale studies. The first study involves\ntranscriptome analysis of infection by human cytomegalovirus (HCMV). The\nobjective of the second study is to identify differentially expressed genes\nbetween two types of leukemia.\n", "versions": [{"version": "v1", "created": "Thu, 11 Mar 2010 19:11:09 GMT"}, {"version": "v2", "created": "Tue, 20 Apr 2010 23:19:38 GMT"}, {"version": "v3", "created": "Thu, 1 Mar 2012 03:18:03 GMT"}], "update_date": "2012-03-02", "authors_parsed": [["Shahbaba", "Babak", ""]]}, {"id": "1003.2439", "submitter": "Paul Kabaila", "authors": "Paul Kabaila and Davide Farchione", "title": "The coverage probabililty of confidence intervals in regression after a\n  preliminary F test", "comments": null, "journal-ref": "The minimum coverage probability of confidence intervals in\n  regression after a preliminary F test. Journal of Statistical Planning and\n  Inference, 142, 956-964 (2012)", "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a linear regression model with regression parameter\nbeta=(beta_1,..., beta_p) and independent normal errors. Suppose the parameter\nof interest is theta = a^T beta, where a is specified. Define the s-dimensional\nparameter vector tau = C^T beta - t, where C and t are specified. Suppose that\nwe carry out a preliminary F test of the null hypothesis H_0: tau = 0 against\nthe alternative hypothesis H_1: tau not equal to 0. It is common statistical\npractice to then construct a confidence interval for theta with nominal\ncoverage 1-alpha, using the same data, based on the assumption that the\nselected model had been given to us a priori(as the true model). We call this\nthe naive 1-alpha confidence interval for theta. This assumption is false and\nit may lead to this confidence interval having minimum coverage probability far\nbelow 1-alpha, making it completely inadequate. Our aim is to compute this\nminimum coverage probability. It is straightforward to find an expression for\nthe coverage probability of this confidence interval that is a multiple\nintegral of dimension s+1. However, we derive a new elegant and\ncomputationally-convenient formula for this coverage probability. For s=2 this\nformula is a sum of a triple and a double integral and for all s>2 this formula\nis a sum of a quadruple and a double integral. This makes it easy to compute\nthe minimum coverage probability of the naive confidence interval, irrespective\nof how large s is. A very important practical application of this formula is to\nthe analysis of covariance. In this context, tau can be defined so that H_0\nexpresses the hypothesis of \"parallelism\". Applied statisticians commonly\nrecommend carrying out a preliminary F test of this hypothesis. We illustrate\nthe application of our formula with a real-life analysis of covariance data set\nand a preliminary F test for \"parallelism\". We show that the naive 0.95\nconfidence interval has minimum coverage probability 0.0846, showing that it is\ncompletely inadequate.\n", "versions": [{"version": "v1", "created": "Thu, 11 Mar 2010 22:50:55 GMT"}], "update_date": "2017-10-18", "authors_parsed": [["Kabaila", "Paul", ""], ["Farchione", "Davide", ""]]}, {"id": "1003.2556", "submitter": "Jean-Luc Marichal", "authors": "Jean-Luc Marichal, Pierre Mathonet", "title": "Measuring the influence of the k-th largest variable on functions over\n  the unit hypercube", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By considering a least squares approximation of a given square integrable\nfunction f:[0,1]^n --> R by a shifted L-statistic function (a shifted linear\ncombination of order statistics), we define an index which measures the global\ninfluence of the k-th largest variable on f. We show that this influence index\nhas appealing properties and we interpret it as an average value of the\ndifference quotient of f in the direction of the k-th largest variable or,\nunder certain natural conditions on f, as an average value of the derivative of\nf in the direction of the k-th largest variable. We also discuss a few\napplications of this index in statistics and aggregation theory.\n", "versions": [{"version": "v1", "created": "Fri, 12 Mar 2010 14:59:37 GMT"}], "update_date": "2010-03-15", "authors_parsed": [["Marichal", "Jean-Luc", ""], ["Mathonet", "Pierre", ""]]}, {"id": "1003.2619", "submitter": "Andrew Gelman", "authors": "Andrew Gelman", "title": "Causality and Statistical Learning", "comments": "A version of this article will appear in the American Journal of\n  Sociology.", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We review some approaches and philosophies of causal inference coming from\nsociology, economics, computer science, cognitive science, and statistics\n", "versions": [{"version": "v1", "created": "Fri, 12 Mar 2010 20:50:33 GMT"}], "update_date": "2010-04-02", "authors_parsed": [["Gelman", "Andrew", ""]]}, {"id": "1003.2654", "submitter": "Philippe Rigollet", "authors": "Philippe Rigollet and Alexandre Tsybakov", "title": "Exponential Screening and optimal rates of sparse estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In high-dimensional linear regression, the goal pursued here is to estimate\nan unknown regression function using linear combinations of a suitable set of\ncovariates. One of the key assumptions for the success of any statistical\nprocedure in this setup is to assume that the linear combination is sparse in\nsome sense, for example, that it involves only few covariates. We consider a\ngeneral, non necessarily linear, regression with Gaussian noise and study a\nrelated question that is to find a linear combination of approximating\nfunctions, which is at the same time sparse and has small mean squared error\n(MSE). We introduce a new estimation procedure, called Exponential Screening\nthat shows remarkable adaptation properties. It adapts to the linear\ncombination that optimally balances MSE and sparsity, whether the latter is\nmeasured in terms of the number of non-zero entries in the combination\n($\\ell_0$ norm) or in terms of the global weight of the combination ($\\ell_1$\nnorm). The power of this adaptation result is illustrated by showing that\nExponential Screening solves optimally and simultaneously all the problems of\naggregation in Gaussian regression that have been discussed in the literature.\nMoreover, we show that the performance of the Exponential Screening estimator\ncannot be improved in a minimax sense, even if the optimal sparsity is known in\nadvance. The theoretical and numerical superiority of Exponential Screening\ncompared to state-of-the-art sparse procedures is also discussed.\n", "versions": [{"version": "v1", "created": "Fri, 12 Mar 2010 23:08:10 GMT"}, {"version": "v2", "created": "Wed, 7 Apr 2010 21:49:49 GMT"}, {"version": "v3", "created": "Tue, 27 Jul 2010 19:51:53 GMT"}], "update_date": "2015-03-13", "authors_parsed": [["Rigollet", "Philippe", ""], ["Tsybakov", "Alexandre", ""]]}, {"id": "1003.2711", "submitter": "Satoshi Kuriki", "authors": "Satoshi Kuriki", "title": "Distributions of the largest singular values of skew-symmetric random\n  matrices and their applications to paired comparisons", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $A$ be a real skew-symmetric Gaussian random matrix whose upper\ntriangular elements are independently distributed according to the standard\nnormal distribution. We provide the distribution of the largest singular value\n$\\sigma_1$ of $A$. Moreover, by acknowledging the fact that the largest\nsingular value can be regarded as the maximum of a Gaussian field, we deduce\nthe distribution of the standardized largest singular value\n$\\sigma_1/\\sqrt{\\mathrm{tr}(A'A)/2}$. These distributional results are utilized\nin Scheff\\'{e}'s paired comparisons model. We propose tests for the hypothesis\nof subtractivity based on the largest singular value of the skew-symmetric\nresidual matrix. Professional baseball league data are analyzed as an\nillustrative example.\n", "versions": [{"version": "v1", "created": "Sat, 13 Mar 2010 14:58:51 GMT"}], "update_date": "2010-03-16", "authors_parsed": [["Kuriki", "Satoshi", ""]]}, {"id": "1003.2804", "submitter": "Francesco Bartolucci", "authors": "F. Bartolucci, A. Farcomeni, F. Pennoni", "title": "An overview of latent Markov models for longitudinal categorical data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a comprehensive overview of latent Markov (LM) models for the\nanalysis of longitudinal categorical data. The main assumption behind these\nmodels is that the response variables are conditionally independent given a\nlatent process which follows a first-order Markov chain. We first illustrate\nthe basic LM model in which the conditional distribution of each response\nvariable given the corresponding latent variable and the initial and transition\nprobabilities of the latent process are unconstrained. For this model we also\nillustrate in detail maximum likelihood estimation through the\nExpectation-Maximization algorithm, which may be efficiently implemented by\nrecursions known in the hidden Markov literature. We then illustrate several\nconstrained versions of the basic LM model, which make the model more\nparsimonious and allow us to include and test hypotheses of interest. These\nconstraints may be put on the conditional distribution of the response\nvariables given the latent process (measurement model) or on the distribution\nof the latent process (latent model). We also deal with extensions of LM model\nfor the inclusion of individual covariates and to multilevel data. Covariates\nmay affect the measurement or the latent model; we discuss the implications of\nthese two different approaches according to the context of application.\nFinally, we outline methods for obtaining standard errors for the parameter\nestimates, for selecting the number of states and for path prediction. Models\nand related inference are illustrated by the description of relevant\nsocio-economic applications available in the literature.\n", "versions": [{"version": "v1", "created": "Sun, 14 Mar 2010 18:16:15 GMT"}], "update_date": "2010-03-16", "authors_parsed": [["Bartolucci", "F.", ""], ["Farcomeni", "A.", ""], ["Pennoni", "F.", ""]]}, {"id": "1003.3128", "submitter": "Maik Schwarz", "authors": "Jan Johannes and Maik Schwarz", "title": "Partially adaptive nonparametric instrumental regression", "comments": null, "journal-ref": "Journal of the Indian Statistical Association (2011), Vol. 49,\n  p.149-176", "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of estimating the structural function in\nnonparametric instrumental regression, where in the presence of an instrument W\na response Y is modeled in dependence of an endogenous explanatory variable Z.\nThe proposed estimator is based on dimension reduction and additional\nthresholding. The minimax optimal rate of convergence of the estimator is\nderived assuming that the structural function belongs to some ellipsoids which\nare in a certain sense linked to the conditional expectation operator of Z\ngiven W. We illustrate these results by considering classical smoothness\nassumptions. However, the proposed estimator requires an optimal choice of a\ndimension parameter depending on certain characteristics of the unknown\nstructural function and the conditional expectation operator of Z given W,\nwhich are not known in practice. The main issue addressed in our work is an\nadaptive choice of this dimension parameter using a model selection approach\nunder the restriction that the conditional expectation operator of Z given W is\nsmoothing in a certain sense. In this situation we develop a penalized minimum\ncontrast estimator with randomized penalty and collection of models. We show\nthat this data-driven estimator can attain the lower risk bound up to a\nconstant over a wide range of smoothness classes for the structural function.\n", "versions": [{"version": "v1", "created": "Tue, 16 Mar 2010 11:32:36 GMT"}, {"version": "v2", "created": "Tue, 10 Apr 2012 11:51:08 GMT"}], "update_date": "2015-03-13", "authors_parsed": [["Johannes", "Jan", ""], ["Schwarz", "Maik", ""]]}, {"id": "1003.3259", "submitter": "Nanny Wermuth", "authors": "Nanny Wermuth", "title": "Probability distributions with summary graph structure", "comments": "Published in at http://dx.doi.org/10.3150/10-BEJ309 the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2011, Vol. 17, No. 3, 845-879", "doi": "10.3150/10-BEJ309", "report-no": "IMS-BEJ-BEJ309", "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A set of independence statements may define the independence structure of\ninterest in a family of joint probability distributions. This structure is\noften captured by a graph that consists of nodes representing the random\nvariables and of edges that couple node pairs. One important class contains\nregression graphs. Regression graphs are a type of so-called chain graph and\ndescribe stepwise processes, in which at each step single or joint responses\nare generated given the relevant explanatory variables in their past. For joint\ndensities that result after possible marginalising or conditioning, we\nintroduce summary graphs. These graphs reflect the independence structure\nimplied by the generating process for the reduced set of variables and they\npreserve the implied independences after additional marginalising and\nconditioning. They can identify generating dependences that remain unchanged\nand alert to possibly severe distortions due to direct and indirect\nconfounding. Operators for matrix representations of graphs are used to derive\nthese properties of summary graphs and to translate them into special types of\npaths in graphs.\n", "versions": [{"version": "v1", "created": "Tue, 16 Mar 2010 21:46:39 GMT"}, {"version": "v2", "created": "Thu, 14 Jul 2011 11:29:28 GMT"}], "update_date": "2011-07-15", "authors_parsed": [["Wermuth", "Nanny", ""]]}, {"id": "1003.3323", "submitter": "Klaus Frick", "authors": "Klaus Frick, Philipp Marnitz and Axel Munk", "title": "Shape Constrained Regularisation by Statistical Multiresolution for\n  Inverse Problems: Asymptotic Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is concerned with a novel regularisation technique for solving\nlinear ill-posed operator equations in Hilbert spaces from data that is\ncorrupted by white noise. We combine convex penalty functionals with\nextreme-value statistics of projections of the residuals on a given set of\nsub-spaces in the image-space of the operator. We prove general consistency and\nconvergence rate results in the framework of Bregman-divergences which allows\nfor a vast range of penalty functionals. Various examples that indicate the\napplicability of our approach will be discussed. We will illustrate in the\ncontext of signal and image processing that the presented method constitutes a\nlocally adaptive reconstruction method.\n", "versions": [{"version": "v1", "created": "Wed, 17 Mar 2010 08:45:54 GMT"}, {"version": "v2", "created": "Wed, 6 Oct 2010 16:00:00 GMT"}, {"version": "v3", "created": "Fri, 4 Mar 2011 15:33:47 GMT"}, {"version": "v4", "created": "Wed, 4 May 2011 07:02:28 GMT"}, {"version": "v5", "created": "Wed, 1 Jun 2011 06:45:01 GMT"}, {"version": "v6", "created": "Thu, 13 Oct 2011 12:49:30 GMT"}, {"version": "v7", "created": "Sat, 31 Mar 2012 06:45:49 GMT"}], "update_date": "2012-04-03", "authors_parsed": [["Frick", "Klaus", ""], ["Marnitz", "Philipp", ""], ["Munk", "Axel", ""]]}, {"id": "1003.3439", "submitter": "Jose A. Diaz-Garcia", "authors": "Jose A. Diaz-Garcia and Francisco J. Caro-Lopera", "title": "Shape Theory via QR decomposition", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work sets the non isotropic noncentral elliptical shape distributions\nvia QR decomposition in the context of zonal polynomials, avoiding the\ninvariant polynomials and the open problems for their computation. The new\nshape distributions are easily computable and then the inference procedure can\nbe studied under exact densities instead under the published approximations and\nasymptotic densities under isotropic models. An application in Biology is\nstudied under the classical gaussian approach and a two non gaussian models.\n", "versions": [{"version": "v1", "created": "Wed, 17 Mar 2010 19:47:01 GMT"}], "update_date": "2010-03-18", "authors_parsed": [["Diaz-Garcia", "Jose A.", ""], ["Caro-Lopera", "Francisco J.", ""]]}, {"id": "1003.3539", "submitter": "Yury Kutoyants", "authors": "Yury A. Kutoyants", "title": "On Identification of the Threshold Diffusion Processes", "comments": "34 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problems of parameter estimation for several models of\nthreshold ergodic diffusion processes in the asymptotics of large samples.\nThese models are the direct continuous time analogues of the well-known in time\nseries analysis threshold autoregressive (TAR) models. In such models the trend\nis switching when the observed process atteints some (unknown) values and the\nproblem is to estimate it or to test some hypotheses concerning these values.\nThe related statistical problems correspond to the singular estimation or\ntesting, for example, the rate of convergence of estimators is $T$ and not\n$\\sqrt{T}$ as in regular estimation problems. We study the asymptotic behavior\nof the maximum likelihood and bayesian estimators and discuss the possibility\nof the construction of the goodness of fit test for such models of observation.\n", "versions": [{"version": "v1", "created": "Thu, 18 Mar 2010 09:55:14 GMT"}], "update_date": "2010-03-19", "authors_parsed": [["Kutoyants", "Yury A.", ""]]}, {"id": "1003.3546", "submitter": "Reinhard  Hoepfner", "authors": "Reinhard Hoepfner, Yury Kutoyants", "title": "On LAN for parametrized continuous periodic signals in a time\n  inhomogeneous diffusion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a diffusion $(\\xi_t)_{t\\ge 0}$ whose drift involves a\n$T$-periodic signal. $T$ is fixed and known, whereas the signal depends on an\nunknown $d$-dimensional parameter $\\vartheta\\in\\Theta$. Assuming positive\nHarris recurrence of the grid chain $(\\xi_{kT})_{k\\in\\mathbb{N}_0}$ and\nexploiting the periodic structure of the semigroup, we work with path segments\nand limit theorems for certain functionals (more general than additive\nfunctionals) of the process to prove local asymptotic normality (LAN). Then we\nconsider several estimators for the unknown parameter.\n", "versions": [{"version": "v1", "created": "Thu, 18 Mar 2010 10:32:42 GMT"}], "update_date": "2010-03-19", "authors_parsed": [["Hoepfner", "Reinhard", ""], ["Kutoyants", "Yury", ""]]}, {"id": "1003.3800", "submitter": "Yury Kutoyants", "authors": "Ngai Hang Chan and Yury A. Kutoyants", "title": "On Parameter Estimation of Threshold Autoregressive Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the threshold estimation of a TAR model when the\nunderlying threshold parameter is a random variable. It is shown that the\nBayesian estimator is consistent and its limit distribution is expressed in\nterms of a limit likelihood ratio. Furthermore, convergence of moments of the\nestimators is also established. The limit distribution can be computed via\nexplicit simulations from which testing and inference for the threshold\nparameter can be conducted. The obtained results are illustrated with numerical\nsimulations.\n", "versions": [{"version": "v1", "created": "Thu, 18 Mar 2010 10:02:21 GMT"}], "update_date": "2010-03-22", "authors_parsed": [["Chan", "Ngai Hang", ""], ["Kutoyants", "Yury A.", ""]]}, {"id": "1003.4147", "submitter": "Mehdi Fhima", "authors": "Pierre R Bertrand (INRIA Saclay - Ile de France), Mehdi Fhima", "title": "Filtered derivative with p-value method for multiple change-points\n  detection", "comments": null, "journal-ref": "International Workshop in Sequential Methodologies, Troyes :\n  France (2009)", "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with off-line detection of change points for time series of\nindependent observations, when the number of change points is unknown. We\npropose a sequential analysis like method with linear time and memory\ncomplexity. Our method is based at first step, on Filtered Derivative method\nwhich detects the right change points but also false ones. We improve Filtered\nDerivative method by adding a second step in which we compute the p-values\nassociated to each potential change points. Then we eliminate as false alarms\nthe points which have p-value smaller than a given critical level. Next, our\nmethod is compared with the Penalized Least Square Criterion procedure on\nsimulated data sets. Eventually, we apply Filtered Derivative with p-Value\nmethod to segmentation of heartbeat time series.\n", "versions": [{"version": "v1", "created": "Mon, 22 Mar 2010 12:56:23 GMT"}], "update_date": "2015-03-13", "authors_parsed": [["Bertrand", "Pierre R", "", "INRIA Saclay - Ile de France"], ["Fhima", "Mehdi", ""]]}, {"id": "1003.4148", "submitter": "Mehdi Fhima", "authors": "Pierre R. Bertrand (INRIA Saclay - Ile de France), Mehdi Fhima, Arnaud\n  Guillin", "title": "Off-line detection of multiple change points with the Filtered\n  Derivative with p-Value method", "comments": null, "journal-ref": "Sequential Analysis (2010) 26", "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with off-line detection of change points for time series of\nindependent observations, when the number of change points is unknown. We\npropose a sequential analysis like method with linear time and memory\ncomplexity. Our method is based at first step, on Filtered Derivative method\nwhich detects the right change points but also false ones. We improve Filtered\nDerivative method by adding a second step in which we compute the p-values\nassociated to each potential change points. Then we eliminate as false alarms\nthe points which have p-value smaller than a given critical level. Next, our\nmethod is compared with the Penalized Least Square Criterion procedure on\nsimulated data sets. Eventually, we apply Filtered Derivative with p-Value\nmethod to segmentation of heartbeat time series, and detection of change points\nin the average daily volume of financial time series.\n", "versions": [{"version": "v1", "created": "Mon, 22 Mar 2010 13:01:30 GMT"}, {"version": "v2", "created": "Mon, 14 Feb 2011 13:25:17 GMT"}], "update_date": "2015-03-13", "authors_parsed": [["Bertrand", "Pierre R.", "", "INRIA Saclay - Ile de France"], ["Fhima", "Mehdi", ""], ["Guillin", "Arnaud", ""]]}, {"id": "1003.4156", "submitter": "Jean-Baptiste Aubin", "authors": "Jean-Baptiste Aubin, Samuela Leoni-Aubin", "title": "A longest run test for heteroscedasticity in univariate regression model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The scope of this paper is the presentation of a test that enables to detect\nheteroscedasticity in univariate regression model. The test is simple to\ncompute and very general since no hypothesis is made on the regularity of the\nresponse function or on the normality of errors. Simulations show that our test\nfairs well with respect to other less general nonparametric tests.\n", "versions": [{"version": "v1", "created": "Mon, 22 Mar 2010 13:44:42 GMT"}], "update_date": "2010-03-23", "authors_parsed": [["Aubin", "Jean-Baptiste", ""], ["Leoni-Aubin", "Samuela", ""]]}, {"id": "1003.4254", "submitter": "Susan Holmes", "authors": "Rabi Bhattacharya and Susan Holmes", "title": "An Exposition of G\\\"otze's Estimation of the Rate of Convergence in the\n  Multivariate Central Limit Theorem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide an explanation of the main ideas underlying G\\\"otze's main result\nin using Stein's method. We also provide detailed derivations of various\nintermediate estimates. Curiously, we are led to a different dimensional\ndependence of the constant than that given G\\\"otze's paper. We would like to\ndedicate this to Charles Stein on the occasion of his 90th birthday.\n", "versions": [{"version": "v1", "created": "Mon, 22 Mar 2010 19:50:48 GMT"}], "update_date": "2010-03-23", "authors_parsed": [["Bhattacharya", "Rabi", ""], ["Holmes", "Susan", ""]]}, {"id": "1003.4306", "submitter": "Jonathan C. Mattingly", "authors": "Jonathan C. Mattingly, Natesh S. Pillai, Andrew M. Stuart", "title": "Diffusion limits of the random walk Metropolis algorithm in high\n  dimensions", "comments": "Published in at http://dx.doi.org/10.1214/10-AAP754 the Annals of\n  Applied Probability (http://www.imstat.org/aap/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Probability 2012, Vol. 22, No. 3, 881-930", "doi": "10.1214/10-AAP754", "report-no": "IMS-AAP-AAP754", "categories": "math.PR math.ST stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diffusion limits of MCMC methods in high dimensions provide a useful\ntheoretical tool for studying computational complexity. In particular, they\nlead directly to precise estimates of the number of steps required to explore\nthe target measure, in stationarity, as a function of the dimension of the\nstate space. However, to date such results have mainly been proved for target\nmeasures with a product structure, severely limiting their applicability. The\npurpose of this paper is to study diffusion limits for a class of naturally\noccurring high-dimensional measures found from the approximation of measures on\na Hilbert space which are absolutely continuous with respect to a Gaussian\nreference measure. The diffusion limit of a random walk Metropolis algorithm to\nan infinite-dimensional Hilbert space valued SDE (or SPDE) is proved,\nfacilitating understanding of the computational complexity of the algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 22 Mar 2010 23:26:29 GMT"}, {"version": "v2", "created": "Sun, 14 Nov 2010 20:46:04 GMT"}, {"version": "v3", "created": "Wed, 9 Mar 2011 12:50:43 GMT"}, {"version": "v4", "created": "Thu, 4 Oct 2012 13:34:23 GMT"}], "update_date": "2012-10-05", "authors_parsed": [["Mattingly", "Jonathan C.", ""], ["Pillai", "Natesh S.", ""], ["Stuart", "Andrew M.", ""]]}, {"id": "1003.4650", "submitter": "Dario Span\\`o DR", "authors": "Robert C. Griffiths and Dario Spano`", "title": "Diffusion processes and coalescent trees", "comments": "22 pages", "journal-ref": "Chapter 15 of Probability and Mathematical Genetics: Papers in\n  Honour of Sir John Kingman, ed. N. H. Bingham and C. M. Goldie. London\n  Mathematical Society Lecture Notes Series, Cambridge University Press, 2010", "doi": null, "report-no": null, "categories": "math.PR math.ST q-bio.PE stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We dedicate this paper to Sir John Kingman on his 70th Birthday. In modern\nmathematical population genetics the ancestral history of a population of genes\nback in time is described by John Kingman's coalescent tree. Classical and\nmodern approaches model gene frequencies by diffusion processes. This paper,\nwhich is partly a review, discusses how coalescent processes are dual to\ndiffusion processes in an analytic and probabilistic sense. Bochner (1954) and\nGasper (1972) were interested in characterizations of processes with Beta\nstationary distributions and Jacobi polynomial eigenfunctions. We discuss the\nconnection with Wright--Fisher diffusions and the characterization of these\nprocesses. Subordinated Wright--Fisher diffusions are of this type. An Inverse\nGaussian subordinator is interesting and important in subordinated\nWright--Fisher diffusions and is related to the Jacobi Poisson Kernel in\northogonal polynomial theory. A related time-subordinated forest of non-mutant\nedges in the Kingman coalescent is novel.\n", "versions": [{"version": "v1", "created": "Wed, 24 Mar 2010 14:12:51 GMT"}], "update_date": "2010-03-25", "authors_parsed": [["Griffiths", "Robert C.", ""], ["Spano`", "Dario", ""]]}, {"id": "1003.4765", "submitter": "Emilio Seijo", "authors": "Emilio Seijo and Bodhisattva Sen", "title": "Nonparametric Least Squares Estimation of a Multivariate Convex\n  Regression Function", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with the consistency of the least squares estimator of a\nconvex regression function when the predictor is multidimensional. We\ncharacterize and discuss the computation of such an estimator via the solution\nof certain quadratic and linear programs. Mild sufficient conditions for the\nconsistency of this estimator and its subdifferentials in fixed and stochastic\ndesign regression settings are provided. We also consider a regression function\nwhich is known to be convex and componentwise nonincreasing and discuss the\ncharacterization, computation and consistency of its least squares estimator.\n", "versions": [{"version": "v1", "created": "Wed, 24 Mar 2010 22:21:59 GMT"}, {"version": "v2", "created": "Sat, 10 Jul 2010 23:05:35 GMT"}, {"version": "v3", "created": "Tue, 28 Feb 2012 19:28:22 GMT"}], "update_date": "2015-03-13", "authors_parsed": [["Seijo", "Emilio", ""], ["Sen", "Bodhisattva", ""]]}, {"id": "1003.4780", "submitter": "Jose A. Diaz-Garcia", "authors": "Jose A. Diaz-Garcia and Francisco J. Caro-Lopera", "title": "Shape theory via SVD decomposition I", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work finds the non isotropic noncentral elliptical shape distributions\nvia SVD decomposition in the context of zonal polynomials, avoiding the\ninvariant polynomials and the open problems for their computation. The new\nshape distributions are easily computable and then the inference procedure is\nbased on exact densities instead of the published approximations and asymptotic\ndensities of isotropic models. An application of the technique is illustrated\nwith a classical landmark data in Biology, for this, three models are proposed,\nthe usual Gaussian and two non Gaussian; the best one is chosen by using a\nmodified BIC criterion.\n", "versions": [{"version": "v1", "created": "Thu, 25 Mar 2010 01:58:29 GMT"}], "update_date": "2010-03-26", "authors_parsed": [["Diaz-Garcia", "Jose A.", ""], ["Caro-Lopera", "Francisco J.", ""]]}, {"id": "1003.4885", "submitter": "Mohamed Hebiri", "authors": "Mohamed Hebiri, Sara A. Van De Geer", "title": "The Smooth-Lasso and other $\\ell_1+\\ell_2$-penalized methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a linear regression problem in a high dimensional setting where\nthe number of covariates $p$ can be much larger than the sample size $n$. In\nsuch a situation, one often assumes sparsity of the regression vector, \\textit\ni.e., the regression vector contains many zero components. We propose a\nLasso-type estimator $\\hat{\\beta}^{Quad}$ (where '$Quad$' stands for quadratic)\nwhich is based on two penalty terms. The first one is the $\\ell_1$ norm of the\nregression coefficients used to exploit the sparsity of the regression as done\nby the Lasso estimator, whereas the second is a quadratic penalty term\nintroduced to capture some additional information on the setting of the\nproblem. We detail two special cases: the Elastic-Net $\\hat{\\beta}^{EN}$, which\ndeals with sparse problems where correlations between variables may exist; and\nthe Smooth-Lasso $\\hat{\\beta}^{SL}$, which responds to sparse problems where\nsuccessive regression coefficients are known to vary slowly (in some\nsituations, this can also be interpreted in terms of correlations between\nsuccessive variables). From a theoretical point of view, we establish variable\nselection consistency results and show that $\\hat{\\beta}^{Quad}$ achieves a\nSparsity Inequality, \\textit i.e., a bound in terms of the number of non-zero\ncomponents of the 'true' regression vector. These results are provided under a\nweaker assumption on the Gram matrix than the one used by the Lasso. In some\nsituations this guarantees a significant improvement over the Lasso.\nFurthermore, a simulation study is conducted and shows that the S-Lasso\n$\\hat{\\beta}^{SL}$ performs better than known methods as the Lasso, the\nElastic-Net $\\hat{\\beta}^{EN}$, and the Fused-Lasso with respect to the\nestimation accuracy. This is especially the case when the regression vector is\n'smooth', \\textit i.e., when the variations between successive coefficients of\nthe unknown parameter of the regression are small. The study also reveals that\nthe theoretical calibration of the tuning parameters and the one based on 10\nfold cross validation imply two S-Lasso solutions with close performance.\n", "versions": [{"version": "v1", "created": "Thu, 25 Mar 2010 13:35:02 GMT"}, {"version": "v2", "created": "Fri, 7 Oct 2011 15:10:59 GMT"}], "update_date": "2011-10-12", "authors_parsed": [["Hebiri", "Mohamed", ""], ["Van De Geer", "Sara A.", ""]]}, {"id": "1003.5089", "submitter": "Andre Mas", "authors": "G\\'erard Biau (LSTA, DMA), Andr\\'e Mas (I3M)", "title": "PCA-Kernel Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many statistical estimation techniques for high-dimensional or functional\ndata are based on a preliminary dimension reduction step, which consists in\nprojecting the sample $\\bX_1, \\hdots, \\bX_n$ onto the first $D$ eigenvectors of\nthe Principal Component Analysis (PCA) associated with the empirical projector\n$\\hat \\Pi_D$. Classical nonparametric inference methods such as kernel density\nestimation or kernel regression analysis are then performed in the (usually\nsmall) $D$-dimensional space. However, the mathematical analysis of this\ndata-driven dimension reduction scheme raises technical problems, due to the\nfact that the random variables of the projected sample $(\\hat\n\\Pi_D\\bX_1,\\hdots, \\hat \\Pi_D\\bX_n)$ are no more independent. As a reference\nfor further studies, we offer in this paper several results showing the\nasymptotic equivalencies between important kernel-related quantities based on\nthe empirical projector and its theoretical counterpart. As an illustration, we\nprovide an in-depth analysis of the nonparametric kernel regression case\n", "versions": [{"version": "v1", "created": "Fri, 26 Mar 2010 09:06:31 GMT"}], "update_date": "2010-04-26", "authors_parsed": [["Biau", "G\u00e9rard", "", "LSTA, DMA"], ["Mas", "Andr\u00e9", "", "I3M"]]}, {"id": "1003.5131", "submitter": "Robert C. Griffiths", "authors": "Robert C. Griffiths, Dario Span\\`o", "title": "Orthogonal polynomial kernels and canonical correlations for Dirichlet\n  measures", "comments": "Published in at http://dx.doi.org/10.3150/11-BEJ403 the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2013, Vol. 19, No. 2, 548-598", "doi": "10.3150/11-BEJ403", "report-no": "IMS-BEJ-BEJ403", "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a multivariate version of the so-called Lancaster problem of\ncharacterizing canonical correlation coefficients of symmetric bivariate\ndistributions with identical marginals and orthogonal polynomial expansions.\nThe marginal distributions examined in this paper are the Dirichlet and the\nDirichlet multinomial distribution, respectively, on the continuous and the\nN-discrete d-dimensional simplex. Their infinite-dimensional limit\ndistributions, respectively, the Poisson-Dirichlet distribution and Ewens's\nsampling formula, are considered as well. We study, in particular, the\npossibility of mapping canonical correlations on the d-dimensional continuous\nsimplex (i) to canonical correlation sequences on the d+1-dimensional simplex\nand/or (ii) to canonical correlations on the discrete simplex, and vice versa.\nDriven by this motivation, the first half of the paper is devoted to providing\na full characterization and probabilistic interpretation of n-orthogonal\npolynomial kernels (i.e., sums of products of orthogonal polynomials of the\nsame degree n) with respect to the mentioned marginal distributions. We\nestablish several identities and some integral representations which are\nmultivariate extensions of important results known for the case d=2 since the\n1970s. These results, along with a common interpretation of the mentioned\nkernels in terms of dependent Polya urns, are shown to be key features leading\nto several non-trivial solutions to Lancaster's problem, many of which can be\nextended naturally to the limit as $d\\rightarrow\\infty$.\n", "versions": [{"version": "v1", "created": "Fri, 26 Mar 2010 13:04:23 GMT"}, {"version": "v2", "created": "Wed, 20 Mar 2013 13:30:34 GMT"}], "update_date": "2013-03-21", "authors_parsed": [["Griffiths", "Robert C.", ""], ["Span\u00f2", "Dario", ""]]}, {"id": "1003.5165", "submitter": "Catherine Matias", "authors": "Christophe Ambroise and Catherine Matias", "title": "New consistent and asymptotically normal estimators for random graph\n  mixture models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random graph mixture models are now very popular for modeling real data\nnetworks. In these setups, parameter estimation procedures usually rely on\nvariational approximations, either combined with the expectation-maximisation\n(\\textsc{em}) algorithm or with Bayesian approaches. Despite good results on\nsynthetic data, the validity of the variational approximation is however not\nestablished. Moreover, the behavior of the maximum likelihood or of the maximum\na posteriori estimators approximated by these procedures is not known in these\nmodels, due to the dependency structure on the variables. In this work, we show\nthat in many different affiliation contexts (for binary or weighted graphs),\nestimators based either on moment equations or on the maximization of some\ncomposite likelihood are strongly consistent and $\\sqrt{n}$-convergent, where\n$n$ is the number of nodes. As a consequence, our result establishes that the\noverall structure of an affiliation model can be caught by the description of\nthe network in terms of its number of triads (order 3 structures) and edges\n(order 2 structures). We illustrate the efficiency of our method on simulated\ndata and compare its performances with other existing procedures. A data set of\ncross-citations among economics journals is also analyzed.\n", "versions": [{"version": "v1", "created": "Fri, 26 Mar 2010 15:36:55 GMT"}, {"version": "v2", "created": "Wed, 8 Dec 2010 17:23:18 GMT"}], "update_date": "2010-12-09", "authors_parsed": [["Ambroise", "Christophe", ""], ["Matias", "Catherine", ""]]}, {"id": "1003.5457", "submitter": "Amor Keziou", "authors": "Michel Broniatowski (LSTA), Amor Keziou (LSTA, LM-Reims)", "title": "Minimization of divergences on sets of signed measures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.OC math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the minimization problem of $\\phi$-divergences between a given\nprobability measure $P$ and subsets $\\Omega$ of the vector space\n$\\mathcal{M}_\\mathcal{F}$ of all signed finite measures which integrate a given\nclass $\\mathcal{F}$ of bounded or unbounded measurable functions. The vector\nspace $\\mathcal{M}_\\mathcal{F}$ is endowed with the weak topology induced by\nthe class $\\mathcal{F}\\cup \\mathcal{B}_b$ where $\\mathcal{B}_b$ is the class of\nall bounded measurable functions. We treat the problems of existence and\ncharacterization of the $\\phi$-projections of $P$ on $\\Omega$. We consider also\nthe dual equality and the dual attainment problems when $\\Omega$ is defined by\nlinear constraints.\n", "versions": [{"version": "v1", "created": "Mon, 29 Mar 2010 08:43:41 GMT"}], "update_date": "2010-04-26", "authors_parsed": [["Broniatowski", "Michel", "", "LSTA"], ["Keziou", "Amor", "", "LSTA, LM-Reims"]]}, {"id": "1003.5536", "submitter": "Larry Wasserman", "authors": "Christopher R. Genovese, Marco Perone-Pacifico, Isabella Verdinelli\n  and Larry Wasserman", "title": "The Geometry of Nonparametric Filament Estimation", "comments": "substantial revision", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST astro-ph.IM stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of estimating filamentary structure from planar point\nprocess data. We make some connections with computational geometry and we\ndevelop nonparametric methods for estimating the filaments. We show that, under\nweak conditions, the filaments have a simple geometric representation as the\nmedial axis of the data distribution's support. Our methods convert an\nestimator of the support's boundary into an estimator of the filaments. We also\nfind the rates of convergence of our estimators.\n", "versions": [{"version": "v1", "created": "Thu, 25 Mar 2010 16:07:26 GMT"}, {"version": "v2", "created": "Sun, 12 Dec 2010 15:34:35 GMT"}], "update_date": "2015-03-13", "authors_parsed": [["Genovese", "Christopher R.", ""], ["Perone-Pacifico", "Marco", ""], ["Verdinelli", "Isabella", ""], ["Wasserman", "Larry", ""]]}, {"id": "1003.5544", "submitter": "Christian P. Robert", "authors": "Christian P. Robert", "title": "An attempt at reading Keynes' Treatise on Probability", "comments": "Revised version, 18 pages, five pictures of Keynes", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.HO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The book A Treatise on Probability was published by John Maynard Keynes in\n1921. It contains a critical assessment of the foundations of probability and\nof the current statistical methodology. As a modern reader, we review here the\naspects that are most related with statistics, avoiding a neophyte's\nperspective on the philosophical issues. In particular, the book is quite\ncritical of the Bayesian approach and we examine the arguments provided by\nKeynes, as well as the alternative he proposes. This review does not subsume\nthe scholarly study of Aldrich (2008a) relating Keynes with the statistics\ncommunity of the time.\n", "versions": [{"version": "v1", "created": "Mon, 29 Mar 2010 14:08:11 GMT"}, {"version": "v2", "created": "Tue, 6 Apr 2010 08:38:19 GMT"}, {"version": "v3", "created": "Sun, 17 Oct 2010 11:25:14 GMT"}], "update_date": "2010-10-19", "authors_parsed": [["Robert", "Christian P.", ""]]}, {"id": "1003.6039", "submitter": "Adrian Roellin", "authors": "Louis H. Y. Chen and Adrian R\\\"ollin", "title": "Stein couplings for normal approximation", "comments": "54 pages; minor changes and corrections", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we propose a general framework for normal approximation using\nStein's method. We introduce the new concept of Stein couplings and we show\nthat it lies at the heart of popular approaches such as the local approach,\nexchangeable pairs, size biasing and many other approaches. We prove several\ntheorems with which normal approximation for the Wasserstein and Kolmogorov\nmetrics becomes routine once a Stein coupling is found. To illustrate the\nversatility of our framework we give applications in Hoeffding's combinatorial\ncentral limit theorem, functionals in the classic occupancy scheme,\nneighbourhood statistics of point patterns with fixed number of points and\nfunctionals of the components of randomly chosen vertices of sub-critical\nErdos-Renyi random graphs. In all these cases, we use new, non-standard\ncouplings.\n", "versions": [{"version": "v1", "created": "Wed, 31 Mar 2010 12:46:30 GMT"}, {"version": "v2", "created": "Tue, 26 Oct 2010 03:27:36 GMT"}], "update_date": "2010-10-27", "authors_parsed": [["Chen", "Louis H. Y.", ""], ["R\u00f6llin", "Adrian", ""]]}, {"id": "1003.6119", "submitter": "Hsien-Kuei Hwang", "authors": "Hsien-Kuei Hwang, Tsung-Hsi Tsai", "title": "Multivariate records based on dominance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider three types of multivariate records in this paper and derive the\nmean and the variance of their numbers for independent and uniform random\nsamples from two prototype regions: hypercubes $[0,1]^d$ and $d$-dimensional\nsimplex. Central limit theorems with convergence rates are established when the\nvariance tends to infinity. Effective numerical procedures are also provided\nfor computing the variance constants to high degree of precision.\n", "versions": [{"version": "v1", "created": "Tue, 30 Mar 2010 03:26:46 GMT"}], "update_date": "2010-04-01", "authors_parsed": [["Hwang", "Hsien-Kuei", ""], ["Tsai", "Tsung-Hsi", ""]]}]