[{"id": "1301.0294", "submitter": "Iosif Pinelis", "authors": "Iosif Pinelis", "title": "An optimal bound on the quantiles of a certain kind of distributions", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An optimal bound on the quantiles of a certain kind of distributions is\ngiven. Such a bound is used in applications to Berry--Esseen-type bounds for\nnonlinear statistics.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jan 2013 19:40:24 GMT"}], "update_date": "2013-01-03", "authors_parsed": [["Pinelis", "Iosif", ""]]}, {"id": "1301.0533", "submitter": "Matthias Troffaes", "authors": "Matthias C. M. Troffaes, Gero Walter, Dana Kelly", "title": "A robust Bayesian approach to modelling epistemic uncertainty in\n  common-cause failure models", "comments": "16 pages", "journal-ref": "Reliability Engineering and System Safety 125 (2014) 13-21", "doi": "10.1016/j.ress.2013.05.022", "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a standard Bayesian approach to the alpha-factor model for common-cause\nfailure, a precise Dirichlet prior distribution models epistemic uncertainty in\nthe alpha-factors. This Dirichlet prior is then updated with observed data to\nobtain a posterior distribution, which forms the basis for further inferences.\n  In this paper, we adapt the imprecise Dirichlet model of Walley to represent\nepistemic uncertainty in the alpha-factors. In this approach, epistemic\nuncertainty is expressed more cautiously via lower and upper expectations for\neach alpha-factor, along with a learning parameter which determines how quickly\nthe model learns from observed data. For this application, we focus on\nelicitation of the learning parameter, and find that values in the range of 1\nto 10 seem reasonable. The approach is compared with Kelly and Atwood's\nminimally informative Dirichlet prior for the alpha-factor model, which\nincorporated precise mean values for the alpha-factors, but which was otherwise\nquite diffuse.\n  Next, we explore the use of a set of Gamma priors to model epistemic\nuncertainty in the marginal failure rate, expressed via a lower and upper\nexpectation for this rate, again along with a learning parameter. As zero\ncounts are generally less of an issue here, we find that the choice of this\nlearning parameter is less crucial.\n  Finally, we demonstrate how both epistemic uncertainty models can be combined\nto arrive at lower and upper expectations for all common-cause failure rates.\nThereby, we effectively provide a full sensitivity analysis of common-cause\nfailure rates, properly reflecting epistemic uncertainty of the analyst on all\nlevels of the common-cause failure model.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jan 2013 19:41:18 GMT"}], "update_date": "2018-08-10", "authors_parsed": [["Troffaes", "Matthias C. M.", ""], ["Walter", "Gero", ""], ["Kelly", "Dana", ""]]}, {"id": "1301.0676", "submitter": "Yoshikazu Terada", "authors": "Yoshikazu Terada", "title": "Strong Consistency of Factorial K-means Clustering", "comments": "A revised version of this was accepted in Annals of the Institute of\n  Statistical Mathematics. Please refer to the accepted version of this. In the\n  accepted ver., I describe a new interesting fact that there exists some cases\n  in which reduced k-means clustering becomes equivalent to FKM clustering as n\n  goes to infinity and provide a rough large deviation inequality for FKM\n  clustering", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Factorial k-means (FKM) clustering is a method for clustering objects in a\nlow-dimensional subspace. The advantage of this method is that the partition of\nobjects and the low-dimensional subspace reflecting the cluster structure are\nobtained, simultaneously. Conditions that ensure the almost sure convergence of\nthe estimator of FKM clustering as the sample size increases unboundedly are\nderived. The result is proved for a more general model including FKM\nclustering.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jan 2013 05:55:48 GMT"}, {"version": "v2", "created": "Mon, 28 Jan 2013 07:55:53 GMT"}, {"version": "v3", "created": "Tue, 29 Jan 2013 06:54:55 GMT"}, {"version": "v4", "created": "Tue, 25 Jun 2013 16:48:47 GMT"}, {"version": "v5", "created": "Thu, 13 Feb 2014 13:45:19 GMT"}], "update_date": "2014-02-14", "authors_parsed": [["Terada", "Yoshikazu", ""]]}, {"id": "1301.0726", "submitter": "Henryk Z\\\"ahle", "authors": "Henryk Z\\\"ahle", "title": "Marcinkiewicz-Zygmund and ordinary strong laws for empirical\n  distribution functions and plug-in estimators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Both Marcinkiewicz-Zygmund strong laws of large numbers (MZ-SLLNs) and\nordinary strong laws of large numbers (SLLNs) for plug-in estimators of general\nstatistical functionals are derived. It is used that if a statistical\nfunctional is \"sufficiently regular\", then a (MZ-) SLLN for the estimator of\nthe unknown distribution function yields a (MZ-) SLLN for the corresponding\nplug-in estimator. It is in particular shown that many L-, V- and risk\nfunctionals are \"sufficiently regular\", and that known results on the strong\nconvergence of the empirical process of \\alpha-mixing random variables can be\nimproved. The presented approach does not only cover some known results but\nalso provides some new strong laws for plug-in estimators of particular\nstatistical functionals.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jan 2013 13:58:12 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["Z\u00e4hle", "Henryk", ""]]}, {"id": "1301.0768", "submitter": "Francois Portier", "authors": "Fran\\c{c}ois Portier (IRMAR), Bernard Delyon (IRMAR)", "title": "Bootstrap Testing of the Rank of a Matrix via Least Squared Constrained\n  Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to test if an unknown matrix has a given rank (null hypothesis), we\nconsider the family of statistics that are minimum squared distances between an\nestimator and the manifold of fixed-rank matrix. Under the null hypothesis,\nevery statistic of this family converges to a weighted chi-squared\ndistribution. In this paper, we introduce the constrained bootstrap to build\nbootstrap estimate of the law under the null hypothesis of such statistics. As\na result, the constrained bootstrap is employed to estimate the quantile for\ntesting the rank. We provide the consistency of the procedure and the\nsimulations shed light one the accuracy of the constrained bootstrap with\nrespect to the traditional asymptotic comparison. More generally, the results\nare extended to test if an unknown parameter belongs to a sub-manifold locally\nsmooth. Finally, the constrained bootstrap is easy to compute, it handles a\nlarge family of tests and it works under mild assumptions.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jan 2013 16:46:55 GMT"}], "update_date": "2013-01-09", "authors_parsed": [["Portier", "Fran\u00e7ois", "", "IRMAR"], ["Delyon", "Bernard", "", "IRMAR"]]}, {"id": "1301.0802", "submitter": "XuanLong Nguyen", "authors": "XuanLong Nguyen", "title": "Borrowing strengh in hierarchical Bayes: Posterior concentration of the\n  Dirichlet base measure", "comments": "Published at http://dx.doi.org/10.3150/15-BEJ703 in the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2016, Vol. 22, No. 3, 1535-1571", "doi": "10.3150/15-BEJ703", "report-no": "IMS-BEJ-BEJ703", "categories": "math.ST cs.LG math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies posterior concentration behavior of the base probability\nmeasure of a Dirichlet measure, given observations associated with the sampled\nDirichlet processes, as the number of observations tends to infinity. The base\nmeasure itself is endowed with another Dirichlet prior, a construction known as\nthe hierarchical Dirichlet processes (Teh et al. [J. Amer. Statist. Assoc. 101\n(2006) 1566-1581]). Convergence rates are established in transportation\ndistances (i.e., Wasserstein metrics) under various conditions on the geometry\nof the support of the true base measure. As a consequence of the theory, we\ndemonstrate the benefit of \"borrowing strength\" in the inference of multiple\ngroups of data - a powerful insight often invoked to motivate hierarchical\nmodeling. In certain settings, the gain in efficiency due to the latent\nhierarchy can be dramatic, improving from a standard nonparametric rate to a\nparametric rate of convergence. Tools developed include transportation\ndistances for nonparametric Bayesian hierarchies of random measures, the\nexistence of tests for Dirichlet measures, and geometric properties of the\nsupport of Dirichlet measures.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jan 2013 18:55:41 GMT"}, {"version": "v2", "created": "Sun, 3 Nov 2013 07:01:51 GMT"}, {"version": "v3", "created": "Thu, 29 Jan 2015 16:28:03 GMT"}, {"version": "v4", "created": "Thu, 24 Mar 2016 14:26:50 GMT"}], "update_date": "2016-03-25", "authors_parsed": [["Nguyen", "XuanLong", ""]]}, {"id": "1301.0877", "submitter": "Wei Gao", "authors": "Wei Gao, Ping Shing Chan, Hon Keung Tony Ng and Xiaolei Lu", "title": "Efficient Computational Algorithm for Optimal Allocation in Regression\n  Models", "comments": "17 pages and 2 tables, accepted by Journal of Computational and\n  Applied Mathematics in 2013 Journal of Computational and Applied Mathematics\n  2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we discuss the optimal allocation problem in an experiment\nwhen a regression model is used for statistical analysis. Monotonic convergence\nfor a general class of multiplicative algorithms for $D$-optimality has been\ndiscussed in the literature. Here, we provide an alternate proof of the\nmonotonic convergence for $D$-criterion with a simple computational algorithm\nand furthermore show it converges to the $D$-optimality. We also discuss an\nalgorithm as well as a conjecture of the monotonic convergence for\n$A$-criterion. Monte Carlo simulations are used to demonstrate the reliability,\nefficiency and usefulness of the proposed algorithms.\n", "versions": [{"version": "v1", "created": "Sat, 5 Jan 2013 06:39:29 GMT"}, {"version": "v2", "created": "Fri, 25 Oct 2013 15:18:13 GMT"}], "update_date": "2013-10-28", "authors_parsed": [["Gao", "Wei", ""], ["Chan", "Ping Shing", ""], ["Ng", "Hon Keung Tony", ""], ["Lu", "Xiaolei", ""]]}, {"id": "1301.0891", "submitter": "Yannis Yatracos", "authors": "Yannis G. Yatracos", "title": "Concerns on Monotonic Imbalance Bounding Matching Methods", "comments": null, "journal-ref": "On line supplement for the JASA paper by Iacus, King and Porro\n  (2011)", "doi": null, "report-no": null, "categories": "math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Concerns are expressed for the Monotonic Imbalance Bounding (MIB) property\n(Iacus et al. 2011) and for MIB matching because i) the definition of the MIB\nproperty leads to inconsistencies and the nature of the imbalance measure is\nnot clearly defined, ii) MIB property does not generalize Equal Percent Bias\nReducing (EPBR) property, iii) MIB matching does not provide statistical\ninformation available with EPBR matching.\n", "versions": [{"version": "v1", "created": "Sat, 5 Jan 2013 11:01:48 GMT"}], "update_date": "2013-01-08", "authors_parsed": [["Yatracos", "Yannis G.", ""]]}, {"id": "1301.0901", "submitter": "Florent Krzakala", "authors": "Florent Krzakala, Marc M\\'ezard and Lenka Zdeborov\\'a", "title": "Compressed Sensing under Matrix Uncertainty: Optimum Thresholds and\n  Robust Approximate Message Passing", "comments": "5 pages, 4 figures", "journal-ref": "Acoustics, Speech and Signal Processing (ICASSP), 2013 IEEE\n  International Conference on, pages 5519 - 5523", "doi": "10.1109/ICASSP.2013.6638719", "report-no": null, "categories": "cs.IT cond-mat.stat-mech math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In compressed sensing one measures sparse signals directly in a compressed\nform via a linear transform and then reconstructs the original signal. However,\nit is often the case that the linear transform itself is known only\napproximately, a situation called matrix uncertainty, and that the measurement\nprocess is noisy. Here we present two contributions to this problem: first, we\nuse the replica method to determine the mean-squared error of the Bayes-optimal\nreconstruction of sparse signals under matrix uncertainty. Second, we consider\na robust variant of the approximate message passing algorithm and demonstrate\nnumerically that in the limit of large systems, this algorithm matches the\noptimal performance in a large region of parameters.\n", "versions": [{"version": "v1", "created": "Sat, 5 Jan 2013 13:02:08 GMT"}], "update_date": "2013-11-13", "authors_parsed": [["Krzakala", "Florent", ""], ["M\u00e9zard", "Marc", ""], ["Zdeborov\u00e1", "Lenka", ""]]}, {"id": "1301.0958", "submitter": "Giuseppe Sanfilippo", "authors": "Angelo Gilio and Giuseppe Sanfilippo", "title": "Probabilistic entailment in the setting of coherence: The role of quasi\n  conjunction and inclusion relation", "comments": null, "journal-ref": "International Journal of Approximate Reasoning, vol. 54, no. 4,\n  pp. 513-525, 2013, http://dx.doi.org/10.1016/j.ijar.2012.11.001", "doi": "10.1016/j.ijar.2012.11.001", "report-no": null, "categories": "math.PR cs.AI math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, by adopting a coherence-based probabilistic approach to\ndefault reasoning, we focus the study on the logical operation of quasi\nconjunction and the Goodman-Nguyen inclusion relation for conditional events.\nWe recall that quasi conjunction is a basic notion for defining consistency of\nconditional knowledge bases. By deepening some results given in a previous\npaper we show that, given any finite family of conditional events F and any\nnonempty subset S of F, the family F p-entails the quasi conjunction C(S);\nthen, given any conditional event E|H, we analyze the equivalence between\np-entailment of E|H from F and p-entailment of E|H from C(S), where S is some\nnonempty subset of F. We also illustrate some alternative theorems related with\np-consistency and p-entailment. Finally, we deepen the study of the connections\nbetween the notions of p-entailment and inclusion relation by introducing for a\npair (F,E|H) the (possibly empty) class K of the subsets S of F such that C(S)\nimplies E|H. We show that the class K satisfies many properties; in particular\nK is additive and has a greatest element which can be determined by applying a\nsuitable algorithm.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jan 2013 01:04:50 GMT"}], "update_date": "2013-03-18", "authors_parsed": [["Gilio", "Angelo", ""], ["Sanfilippo", "Giuseppe", ""]]}, {"id": "1301.1208", "submitter": "Mark Tygert", "authors": "William Perkins, Mark Tygert, and Rachel Ward", "title": "Significance testing without truth", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A popular approach to significance testing proposes to decide whether the\ngiven hypothesized statistical model is likely to be true (or false).\nStatistical decision theory provides a basis for this approach by requiring\nevery significance test to make a decision about the truth of the\nhypothesis/model under consideration. Unfortunately, many interesting and\nuseful models are obviously false (that is, not exactly true) even before\nconsidering any data. Fortunately, in practice a significance test need only\ngauge the consistency (or inconsistency) of the observed data with the assumed\nhypothesis/model -- without enquiring as to whether the assumption is likely to\nbe true (or false), or whether some alternative is likely to be true (or\nfalse). In this practical formulation, a significance test rejects a\nhypothesis/model only if the observed data is highly improbable when\ncalculating the probability while assuming the hypothesis being tested; the\nsignificance test only gauges whether the observed data likely invalidates the\nassumed hypothesis, and cannot decide that the assumption -- however\nunmistakably false -- is likely to be false a priori, without any data.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jan 2013 14:40:38 GMT"}], "update_date": "2013-01-08", "authors_parsed": [["Perkins", "William", ""], ["Tygert", "Mark", ""], ["Ward", "Rachel", ""]]}, {"id": "1301.1499", "submitter": "Zbyn\\v{e}k Pawlas", "authors": "Daniel Hug, G\\\"unter Last, Zbyn\\v{e}k Pawlas and Wolfgang Weil", "title": "Statistics for Poisson models of overlapping spheres", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper considers the stationary Poisson Boolean model with spherical\ngrains and proposes a family of nonparametric estimators for the radius\ndistribution. These estimators are based on observed distances and radii,\nweighted in an appropriate way. They are ratio-unbiased and asymptotically\nconsistent for growing observation window. It is shown that the asymptotic\nvariance exists and is given by a fairly explicit integral expression.\nAsymptotic normality is established under a suitable integrability assumption\non the weight function. The paper also provides a short discussion of related\nestimators as well as a simulation study.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2013 11:36:30 GMT"}], "update_date": "2013-01-09", "authors_parsed": [["Hug", "Daniel", ""], ["Last", "G\u00fcnter", ""], ["Pawlas", "Zbyn\u011bk", ""], ["Weil", "Wolfgang", ""]]}, {"id": "1301.1717", "submitter": "Gunnar Taraldsen", "authors": "Gunnar Taraldsen, Bo Henry Lindqvist", "title": "Fiducial theory and optimal inference", "comments": "Published in at http://dx.doi.org/10.1214/13-AOS1083 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2013, Vol. 41, No. 1, 323-341", "doi": "10.1214/13-AOS1083", "report-no": "IMS-AOS-AOS1083", "categories": "math.ST math.GR math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is shown that the fiducial distribution in a group model, or more\ngenerally a quasigroup model, determines the optimal equivariant frequentist\ninference procedures. The proof does not rely on existence of invariant\nmeasures, and generalizes results corresponding to the choice of the right Haar\nmeasure as a Bayesian prior. Classical and more recent examples show that\nfiducial arguments can be used to give good candidates for exact or approximate\nconfidence distributions. It is here suggested that the fiducial algorithm can\nbe considered as an alternative to the Bayesian algorithm for the construction\nof good frequentist inference procedures more generally.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2013 23:23:01 GMT"}, {"version": "v2", "created": "Mon, 8 Apr 2013 12:30:46 GMT"}], "update_date": "2013-04-09", "authors_parsed": [["Taraldsen", "Gunnar", ""], ["Lindqvist", "Bo Henry", ""]]}, {"id": "1301.1898", "submitter": "Jean-Bernard Salomond", "authors": "Jean-Bernard Salomond", "title": "Concentration rate and consistency of the posterior under monotonicity\n  constraints", "comments": null, "journal-ref": null, "doi": "10.1214/14-EJS929", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the well known problem of estimating a density\nfunction under qualitative assumptions. More precisely, we estimate monotone\nnon increasing densities in a Bayesian setting and derive concentration rate\nfor the posterior distribution for a Dirichlet process and finite mixture\nprior. We prove that the posterior distribution based on both priors\nconcentrates at the rate $(n/\\log(n))^{-1/3}$, which is the minimax rate of\nestimation up to a \\log(n)$ factor. We also study the behaviour of the\nposterior for the point-wise loss at any fixed point of the support the density\nand for the sup norm. We prove that the posterior is consistent for both\nlosses.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jan 2013 15:55:12 GMT"}, {"version": "v2", "created": "Mon, 14 Jan 2013 11:04:07 GMT"}, {"version": "v3", "created": "Mon, 14 Apr 2014 09:49:56 GMT"}], "update_date": "2015-02-20", "authors_parsed": [["Salomond", "Jean-Bernard", ""]]}, {"id": "1301.2074", "submitter": "Markus Bibinger", "authors": "Markus Bibinger and Per A. Mykland", "title": "Inference for Multi-Dimensional High-Frequency Data: Equivalence of\n  Methods, Central Limit Theorems, and an Application to Conditional\n  Independence Testing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We find the asymptotic distribution of the multi-dimensional multi-scale and\nkernel estimators for high-frequency financial data with microstructure.\nSampling times are allowed to be asynchronous and endogenous. In the process,\nwe show that the classes of multi-scale and kernel estimators for smoothing\nnoise perturbation are asymptotically equivalent in the sense of having the\nsame asymptotic distribution for corresponding kernel and weight functions. The\ntheory leads to multi-dimensional stable central limit theorems and feasible\nversions. Hence they allow to draw statistical inference for a broad class of\nmultivariate models which paves the way to tests and confidence intervals in\nrisk measurement for arbitrary portfolios composed of high-frequently observed\nassets. As an application, we enhance the approach to construct a test for\ninvestigating hypotheses that correlated assets are independent conditional on\na common factor.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 10:30:52 GMT"}, {"version": "v2", "created": "Tue, 4 Nov 2014 13:19:27 GMT"}], "update_date": "2014-11-05", "authors_parsed": [["Bibinger", "Markus", ""], ["Mykland", "Per A.", ""]]}, {"id": "1301.2212", "submitter": "Maik Schwarz", "authors": "Maik Schwarz, Geurt Jongbloed, Ingrid Van Keilegom", "title": "On the identifiability of copulas in bivariate competing risks models", "comments": "16 pages, 3 figures", "journal-ref": "Canadian Journal of Statistics (2013), Volume 41, p. 291-303", "doi": "10.1002/cjs.11179", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In competing risks models, the joint distribution of the event times is not\nidentifiable even when the margins are fully known, which has been referred to\nas the \"identifiability crisis in competing risks analysis\" (Crowder, 1991). We\nmodel the dependence between the event times by an unknown copula and show that\nidentification is actually possible within many frequently used families of\ncopulas. The result is then extended to the case where one margin is unknown.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 18:42:54 GMT"}], "update_date": "2013-05-14", "authors_parsed": [["Schwarz", "Maik", ""], ["Jongbloed", "Geurt", ""], ["Van Keilegom", "Ingrid", ""]]}, {"id": "1301.2242", "submitter": "Alexei Kourbatov", "authors": "Alexei Kourbatov", "title": "Maximal gaps between prime k-tuples: a statistical approach", "comments": "24 pages, 5 figures, 4 tables. Ver.3: to appear in Journal of Integer\n  Sequences, vol.16 (2013)", "journal-ref": "Journal of Integer Sequences, 16 (2013), Article 13.5.2", "doi": null, "report-no": null, "categories": "math.NT math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Combining the Hardy-Littlewood k-tuple conjecture with a heuristic\napplication of extreme-value statistics, we propose a family of estimator\nformulas for predicting maximal gaps between prime k-tuples. Computations show\nthat the estimator a(log(x/a)-b) satisfactorily predicts the maximal gaps below\nx, where a is the expected average gap between the same type of k-tuples,\na=O(log^k x). Heuristics suggest that maximal gaps between prime k-tuples near\nx are approximately a*log(x/a), and thus have the order O(log^{k+1}x). The\ndistribution of maximal gaps around the trend curve a*log(x/a) is close to the\nGumbel distribution. We explore two implications of this model of gaps: record\ngaps between primes and Legendre-type conjectures for prime k-tuples.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 20:41:27 GMT"}, {"version": "v2", "created": "Wed, 23 Jan 2013 22:56:59 GMT"}, {"version": "v3", "created": "Sun, 14 Apr 2013 01:25:38 GMT"}], "update_date": "2013-05-14", "authors_parsed": [["Kourbatov", "Alexei", ""]]}, {"id": "1301.2534", "submitter": "Alice Cleynen", "authors": "Alice Cleynen and Emilie Lebarbier", "title": "Segmentation of the Poisson and negative binomial rate models: a\n  penalized estimator", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the segmentation problem of Poisson and negative binomial (i.e.\noverdispersed Poisson) rate distributions. In segmentation, an important issue\nremains the choice of the number of segments. To this end, we propose a\npenalized log-likelihood estimator where the penalty function is constructed in\na non-asymptotic context following the works of L. Birg\\'e and P. Massart. The\nresulting estimator is proved to satisfy an oracle inequality. The performances\nof our criterion is assessed using simulated and real datasets in the RNA-seq\ndata analysis context.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jan 2013 16:27:48 GMT"}, {"version": "v2", "created": "Sun, 17 Mar 2013 11:02:03 GMT"}], "update_date": "2013-03-19", "authors_parsed": [["Cleynen", "Alice", ""], ["Lebarbier", "Emilie", ""]]}, {"id": "1301.2603", "submitter": "Mahdi Soltanolkotabi", "authors": "Mahdi Soltanolkotabi, Ehsan Elhamifar, Emmanuel J. Cand\\`es", "title": "Robust subspace clustering", "comments": "Published in at http://dx.doi.org/10.1214/13-AOS1199 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2014, Vol. 42, No. 2, 669-699", "doi": "10.1214/13-AOS1199", "report-no": "IMS-AOS-AOS1199", "categories": "cs.LG cs.IT math.IT math.OC math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Subspace clustering refers to the task of finding a multi-subspace\nrepresentation that best fits a collection of points taken from a\nhigh-dimensional space. This paper introduces an algorithm inspired by sparse\nsubspace clustering (SSC) [In IEEE Conference on Computer Vision and Pattern\nRecognition, CVPR (2009) 2790-2797] to cluster noisy data, and develops some\nnovel theory demonstrating its correctness. In particular, the theory uses\nideas from geometric functional analysis to show that the algorithm can\naccurately recover the underlying subspaces under minimal requirements on their\norientation, and on the number of samples per subspace. Synthetic as well as\nreal data experiments complement our theoretical study, illustrating our\napproach and demonstrating its effectiveness.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jan 2013 21:05:23 GMT"}, {"version": "v2", "created": "Fri, 1 Feb 2013 00:39:13 GMT"}, {"version": "v3", "created": "Fri, 23 May 2014 13:19:54 GMT"}], "update_date": "2014-05-26", "authors_parsed": [["Soltanolkotabi", "Mahdi", ""], ["Elhamifar", "Ehsan", ""], ["Cand\u00e8s", "Emmanuel J.", ""]]}, {"id": "1301.2708", "submitter": "Jeffrey Miller", "authors": "Jeffrey W. Miller and Matthew T. Harrison", "title": "A simple example of Dirichlet process mixture inconsistency for the\n  number of components", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For data assumed to come from a finite mixture with an unknown number of\ncomponents, it has become common to use Dirichlet process mixtures (DPMs) not\nonly for density estimation, but also for inferences about the number of\ncomponents. The typical approach is to use the posterior distribution on the\nnumber of components occurring so far --- that is, the posterior on the number\nof clusters in the observed data. However, it turns out that this posterior is\nnot consistent --- it does not converge to the true number of components. In\nthis note, we give an elementary demonstration of this inconsistency in what is\nperhaps the simplest possible setting: a DPM with normal components of unit\nvariance, applied to data from a \"mixture\" with one standard normal component.\nFurther, we find that this example exhibits severe inconsistency: instead of\ngoing to 1, the posterior probability that there is one cluster goes to 0.\n", "versions": [{"version": "v1", "created": "Sat, 12 Jan 2013 19:32:00 GMT"}], "update_date": "2013-01-15", "authors_parsed": [["Miller", "Jeffrey W.", ""], ["Harrison", "Matthew T.", ""]]}, {"id": "1301.2725", "submitter": "Yudong Chen", "authors": "Yudong Chen, Constantine Caramanis, Shie Mannor", "title": "Robust High Dimensional Sparse Regression and Matching Pursuit", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider high dimensional sparse regression, and develop strategies able\nto deal with arbitrary -- possibly, severe or coordinated -- errors in the\ncovariance matrix $X$. These may come from corrupted data, persistent\nexperimental errors, or malicious respondents in surveys/recommender systems,\netc. Such non-stochastic error-in-variables problems are notoriously difficult\nto treat, and as we demonstrate, the problem is particularly pronounced in\nhigh-dimensional settings where the primary goal is {\\em support recovery} of\nthe sparse regressor. We develop algorithms for support recovery in sparse\nregression, when some number $n_1$ out of $n+n_1$ total covariate/response\npairs are {\\it arbitrarily (possibly maliciously) corrupted}. We are interested\nin understanding how many outliers, $n_1$, we can tolerate, while identifying\nthe correct support. To the best of our knowledge, neither standard outlier\nrejection techniques, nor recently developed robust regression algorithms (that\nfocus only on corrupted response variables), nor recent algorithms for dealing\nwith stochastic noise or erasures, can provide guarantees on support recovery.\nPerhaps surprisingly, we also show that the natural brute force algorithm that\nsearches over all subsets of $n$ covariate/response pairs, and all subsets of\npossible support coordinates in order to minimize regression error, is\nremarkably poor, unable to correctly identify the support with even $n_1 =\nO(n/k)$ corrupted points, where $k$ is the sparsity. This is true even in the\nbasic setting we consider, where all authentic measurements and noise are\nindependent and sub-Gaussian. In this setting, we provide a simple algorithm --\nno more computationally taxing than OMP -- that gives stronger performance\nguarantees, recovering the support with up to $n_1 = O(n/(\\sqrt{k} \\log p))$\ncorrupted points, where $p$ is the dimension of the signal to be recovered.\n", "versions": [{"version": "v1", "created": "Sat, 12 Jan 2013 22:39:56 GMT"}], "update_date": "2013-01-15", "authors_parsed": [["Chen", "Yudong", ""], ["Caramanis", "Constantine", ""], ["Mannor", "Shie", ""]]}, {"id": "1301.2732", "submitter": "June Huh", "authors": "June Huh", "title": "Varieties with maximum likelihood degree one", "comments": "14 pages, changed title, minor revision", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that algebraic varieties with maximum likelihood degree one are\nexactly the images of reduced A-discriminantal varieties under monomial maps\nwith finite fibers. The maximum likelihood estimator corresponding to such a\nvariety is Kapranov's Horn uniformization. This extends Kapranov's\ncharacterization of A-discriminantal hypersurfaces to varieties of arbitrary\ncodimension.\n", "versions": [{"version": "v1", "created": "Sat, 12 Jan 2013 23:16:34 GMT"}, {"version": "v2", "created": "Wed, 16 Jan 2013 02:49:48 GMT"}, {"version": "v3", "created": "Mon, 3 Feb 2014 19:14:58 GMT"}, {"version": "v4", "created": "Sat, 31 May 2014 08:38:04 GMT"}], "update_date": "2014-06-03", "authors_parsed": [["Huh", "June", ""]]}, {"id": "1301.3017", "submitter": "Angelina Roche", "authors": "Elodie Brunel (I3M), Andr\\'e Mas (I3M), Angelina Roche (I3M)", "title": "Non-asymptotic Adaptive Prediction in Functional Linear Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Functional linear regression has recently attracted considerable interest.\nMany works focus on asymptotic inference. In this paper we consider in a non\nasymptotic framework a simple estimation procedure based on functional\nPrincipal Regression. It revolves in the minimization of a least square\ncontrast coupled with a classical projection on the space spanned by the m\nfirst empirical eigenvectors of the covariance operator of the functional\nsample. The novelty of our approach is to select automatically the crucial\ndimension m by minimization of a penalized least square contrast. Our method is\nbased on model selection tools. Yet, since this kind of methods consists\nusually in projecting onto known non-random spaces, we need to adapt it to\nempirical eigenbasis made of data-dependent - hence random - vectors. The\nresulting estimator is fully adaptive and is shown to verify an oracle\ninequality for the risk associated to the prediction error and to attain\noptimal minimax rates of convergence over a certain class of ellipsoids. Our\nstrategy of model selection is finally compared numerically with\ncross-validation.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jan 2013 15:41:04 GMT"}], "update_date": "2013-01-16", "authors_parsed": [["Brunel", "Elodie", "", "I3M"], ["Mas", "Andr\u00e9", "", "I3M"], ["Roche", "Angelina", "", "I3M"]]}, {"id": "1301.3190", "submitter": "Jon A. Wellner", "authors": "Fadoua Balabdaoui and Simon Foucart and Jon A. Wellner", "title": "On the Hermite spline conjecture and its connection to k-monotone\n  densities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The k-monotone classes of densities defined on (0, \\infty) have been known in\nthe mathematical literature but were for the first time considered from a\nstatistical point of view by Balabdaoui and Wellner (2007, 2010). In these\nworks, the authors generalized the results established for monotone (k=1) and\nconvex (k=2) densities by giving a characterization of the Maximum Likelihood\nand Least Square estimators (MLE and LSE) and deriving minimax bounds for rates\nof convergence. For k strictly larger than 2, the pointwise asymptotic behavior\nof the MLE and LSE studied by Balabdaoui and Wellner (2007) would show that the\nMLE and LSE attain the minimax lower bounds in a local pointwise sense.\nHowever, the theory assumes that a certain conjecture about the approximation\nerror of a Hermite spline holds true. The main goal of the present note is to\nshow why such a conjecture cannot be true. We also suggest how to bypass the\nconjecture and rebuild the key proofs in the limit theory of the estimators.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2013 00:52:13 GMT"}], "update_date": "2013-01-16", "authors_parsed": [["Balabdaoui", "Fadoua", ""], ["Foucart", "Simon", ""], ["Wellner", "Jon A.", ""]]}, {"id": "1301.3289", "submitter": "Thomas Vareschi", "authors": "Thomas Vareschi", "title": "Application of second generation wavelets to blind spherical\n  deconvolution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We adress the problem of spherical deconvolution in a non parametric\nstatistical framework, where both the signal and the operator kernel are\nsubject to error measurements. After a preliminary treatment of the kernel, we\napply a thresholding procedure to the signal in a second generation wavelet\nbasis. Under standard assumptions on the kernel, we study the theoritical\nperformance of the resulting algorithm in terms of $L^p$ losses ($p\\geq 1$) on\nBesov spaces on the sphere. We hereby extend the application of second\ngeneration spherical wavelets to the blind deconvolution framework. The\nprocedure is furthermore adaptive with regard both to the target function\nsparsity and smoothness, and the kernel blurring effect. We end with the study\nof a concrete example, putting into evidence the improvement of our procedure\non the recent blockwise-SVD algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2013 10:20:38 GMT"}], "update_date": "2013-01-16", "authors_parsed": [["Vareschi", "Thomas", ""]]}, {"id": "1301.3321", "submitter": "Christopher Hillar", "authors": "Christopher Hillar, Andre Wibisono", "title": "Maximum entropy distributions on graphs", "comments": "36 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR q-bio.NC stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by applications to theories of coding and communication in networks\nof nervous tissue, we study maximum entropy distributions on weighted graphs\nwith a given expected degree sequence. These distributions are characterized by\nindependent edge weights parameterized by a shared vector of vertex potentials.\nUsing the general theory of exponential family distributions, we derive the\nexistence and uniqueness of the maximum likelihood estimator (MLE) of the\nvertex parameters. We also prove consistency of the MLE from a single sample in\nthe limit of large graphs, extending results of Chatterjee, Diaconis, and Sly\nin the unweighted case (the \"beta-model\" in statistics). Interestingly, our\nproofs require tight estimates on the norms of inverses of symmetric,\ndiagonally dominant positive matrices. Along the way, we derive analogues of\nthe Erdos-Gallai criterion of graphical degree sequences for weighted graphs.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2013 12:45:57 GMT"}, {"version": "v2", "created": "Fri, 23 Aug 2013 09:45:58 GMT"}, {"version": "v3", "created": "Sun, 16 Dec 2018 23:56:25 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Hillar", "Christopher", ""], ["Wibisono", "Andre", ""]]}, {"id": "1301.3451", "submitter": "Fanghu Dong", "authors": "Fanghu Dong", "title": "Eigenstructure of Maximum Likelihood from Counts Data", "comments": "The current article contains premature results which is refined in\n  another published articles. I want to withdraw it in order to reduce the\n  confusion", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.DS math.OC math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The MLE (Maximum Likelihood Estimate) for a multinomial model is proportional\nto the data. We call such estimate an eigenestimate and the relationship of it\nto the data as the eigenstructure. When the multinomial model is generalized to\ndeal with data arise from incomplete or censored categorical counts, we would\nnaturally look for this eigenstructure between MLE and data. The paper finds\nthe algebraic representation of the eigenstructure (put as Eqn (2.1)), with\nwhich the intuition is visualized geometrically (Figures 2.2 and 4.3) and\nelaborated in a theory (Section 4). The eigenestimate constructed from the\neigenstructure must be a stationary point of the likelihood, a result proved in\nTheorem 4.42. On the bridge between the algebraic definition of Eqn (2.1) and\nthe Proof of Theorem 4.42, we have exploited an elementary inequality (Lemma\n3.1) that governs the primitive cases, defined the thick objects of fragment\nand slice which can be assembled like mechanical parts (Definition 4.1), proved\na few intermediary results that help build up the intuition (Section 4),\nconjectured the universal existence of an eigenestimate (Conjecture 4.32),\nestablished a criterion for boundary regularity (Criterion 4.37), and paved way\n(the Trivial Slicing Algorithm (TSA)) for the derivation of the Weaver\nalgorithms (Section 5) that finds the eigenestimate by using it to reconstruct\nthe observed counts through the eigenstructure, the reconstruction is iterative\nbut derivative-free and matrix-inversion-free. As new addition to the current\nbody of algorithmic methods, the Weaver algorithms craftily tighten threads\nthat are weaved on a rectangular grid (Figure 2.3), and is one incarnation of\nthe TSA. Finally, we put our method in the context of some existing methods\n(Section 6). Softwares are pseudocoded and put online. Visit\nhttp://hku.hk/jdong/eigenstruct2013a.html for demonstrations and download.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2013 18:50:42 GMT"}, {"version": "v2", "created": "Sun, 22 Mar 2015 13:27:06 GMT"}, {"version": "v3", "created": "Mon, 1 Jan 2018 03:46:45 GMT"}], "update_date": "2018-01-03", "authors_parsed": [["Dong", "Fanghu", ""]]}, {"id": "1301.3558", "submitter": "Heng Peng", "authors": "Tao Huang, Heng Peng and Kun Zhang", "title": "Model Selection for Gaussian Mixture Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is concerned with an important issue in finite mixture modelling,\nthe selection of the number of mixing components. We propose a new penalized\nlikelihood method for model selection of finite multivariate Gaussian mixture\nmodels. The proposed method is shown to be statistically consistent in\ndetermining of the number of components. A modified EM algorithm is developed\nto simultaneously select the number of components and to estimate the mixing\nweights, i.e. the mixing probabilities, and unknown parameters of Gaussian\ndistributions. Simulations and a real data analysis are presented to illustrate\nthe performance of the proposed method.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 02:17:58 GMT"}], "update_date": "2013-01-17", "authors_parsed": [["Huang", "Tao", ""], ["Peng", "Heng", ""], ["Zhang", "Kun", ""]]}, {"id": "1301.3581", "submitter": "Jie Yang", "authors": "Jie Yang and Abhyuday Mandal", "title": "D-optimal Factorial Designs under Generalized Linear Models", "comments": "16 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generalized linear models (GLMs) have been used widely for modelling the mean\nresponse both for discrete and continuous random variables with an emphasis on\ncategorical response. Recently Yang, Mandal and Majumdar (2013) considered full\nfactorial and fractional factorial locally D-optimal designs for binary\nresponse and two-level experimental factors. In this paper, we extend their\nresults to a general setup with response belonging to a single-parameter\nexponential family and for multi-level predictors.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 04:38:57 GMT"}, {"version": "v2", "created": "Fri, 3 May 2013 13:46:55 GMT"}], "update_date": "2013-05-06", "authors_parsed": [["Yang", "Jie", ""], ["Mandal", "Abhyuday", ""]]}, {"id": "1301.3602", "submitter": "Josef Teichmann", "authors": "Christa Cuchiero and Josef Teichmann", "title": "Fourier transform methods for pathwise covariance estimation in the\n  presence of jumps", "comments": "revised and slightly shortened final version", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a new non-parametric Fourier procedure to estimate the trajectory\nof the instantaneous covariance process (from discrete observations of a\nmultidimensional price process) in the presence of jumps extending the seminal\nwork Malliavin and Mancino~\\cite{MM:02, MM:09}. Our approach relies on a\nmodification of (classical) jump-robust estimators of integrated realized\ncovariance to estimate the Fourier coefficients of the covariance trajectory.\nUsing Fourier-F\\'ejer inversion we reconstruct the path of the instantaneous\ncovariance. We prove consistency and central limit theorem (CLT) and in\nparticular that the asymptotic estimator variance is smaller by a factor $ 2/3$\nin comparison to classical local estimators.\n  The procedure is robust enough to allow for an iteration and we can show\ntheoretically and empirically how to estimate the integrated realized\ncovariance of the instantaneous stochastic covariance process. We apply these\ntechniques to robust calibration problems for multivariate modeling in finance,\ni.e., the selection of a pricing measure by using time series and derivatives'\nprice information simultaneously.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 07:02:24 GMT"}, {"version": "v2", "created": "Mon, 15 Jul 2013 09:00:29 GMT"}, {"version": "v3", "created": "Fri, 20 Jun 2014 15:36:07 GMT"}], "update_date": "2014-06-23", "authors_parsed": [["Cuchiero", "Christa", ""], ["Teichmann", "Josef", ""]]}, {"id": "1301.3617", "submitter": "Mike Ludkovski", "authors": "Junjing Lin and Michael Ludkovski", "title": "Sequential Bayesian Inference in Hidden Markov Stochastic Kinetic Models\n  with Application to Detection and Response to Seasonal Epidemics", "comments": "26 pages, 7 figures", "journal-ref": "Statistics and Computing, Volume 24, Issue 6 , pp 1047-1062 (2014)", "doi": "10.1007/s11222-013-9419-z", "report-no": null, "categories": "stat.CO math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study sequential Bayesian inference in stochastic kinetic models with\nlatent factors. Assuming continuous observation of all the reactions, our focus\nis on joint inference of the unknown reaction rates and the dynamic latent\nstates, modeled as a hidden Markov factor. Using insights from nonlinear\nfiltering of continuous-time jump Markov processes we develop a novel\nsequential Monte Carlo algorithm for this purpose. Our approach applies the\nideas of particle learning to minimize particle degeneracy and exploit the\nanalytical jump Markov structure. A motivating application of our methods is\nmodeling of seasonal infectious disease outbreaks represented through a\ncompartmental epidemic model. We demonstrate inference in such models with\nseveral numerical illustrations and also discuss predictive analysis of\nepidemic countermeasures using sequential Bayes estimates.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 08:05:04 GMT"}], "update_date": "2014-09-10", "authors_parsed": [["Lin", "Junjing", ""], ["Ludkovski", "Michael", ""]]}, {"id": "1301.4030", "submitter": "Arunangshu Biswas", "authors": "Gopal K. Basak, Arunangshu Biswas", "title": "Diffusive Limits for Adaptive MCMC for Normal Target densities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we apply the Diffusion approximation procedure to a discrete\ntime Adaptive Markov Chain Monte Carlo (AMCMC) method when the target\ndistribution is standard Normal. We show that the limiting distribution of the\ndiffusion admits a density which we identify as the standard Normal\ndistribution.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jan 2013 10:00:18 GMT"}, {"version": "v2", "created": "Fri, 28 Nov 2014 11:09:22 GMT"}], "update_date": "2014-12-01", "authors_parsed": [["Basak", "Gopal K.", ""], ["Biswas", "Arunangshu", ""]]}, {"id": "1301.4183", "submitter": "Eunho Yang", "authors": "Eunho Yang, Pradeep Ravikumar, Genevera I. Allen, Zhandong Liu", "title": "On Graphical Models via Univariate Exponential Family Distributions", "comments": "Journal of Machine Learning Research", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Undirected graphical models, or Markov networks, are a popular class of\nstatistical models, used in a wide variety of applications. Popular instances\nof this class include Gaussian graphical models and Ising models. In many\nsettings, however, it might not be clear which subclass of graphical models to\nuse, particularly for non-Gaussian and non-categorical data. In this paper, we\nconsider a general sub-class of graphical models where the node-wise\nconditional distributions arise from exponential families. This allows us to\nderive multivariate graphical model distributions from univariate exponential\nfamily distributions, such as the Poisson, negative binomial, and exponential\ndistributions. Our key contributions include a class of M-estimators to fit\nthese graphical model distributions; and rigorous statistical analysis showing\nthat these M-estimators recover the true graphical model structure exactly,\nwith high probability. We provide examples of genomic and proteomic networks\nlearned via instances of our class of graphical models derived from Poisson and\nexponential distributions.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jan 2013 18:38:52 GMT"}, {"version": "v2", "created": "Sat, 5 Sep 2015 13:37:10 GMT"}], "update_date": "2015-09-08", "authors_parsed": [["Yang", "Eunho", ""], ["Ravikumar", "Pradeep", ""], ["Allen", "Genevera I.", ""], ["Liu", "Zhandong", ""]]}, {"id": "1301.4240", "submitter": "Adel Javanmard", "authors": "Adel Javanmard and Andrea Montanari", "title": "Hypothesis Testing in High-Dimensional Regression under the Gaussian\n  Random Design Model: Asymptotic Theory", "comments": "63 pages, 10 figures, 11 tables, Section 5 and Theorem 4.5 are added.\n  Other modifications to improve presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.IT math.IT math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider linear regression in the high-dimensional regime where the number\nof observations $n$ is smaller than the number of parameters $p$. A very\nsuccessful approach in this setting uses $\\ell_1$-penalized least squares\n(a.k.a. the Lasso) to search for a subset of $s_0< n$ parameters that best\nexplain the data, while setting the other parameters to zero. Considerable\namount of work has been devoted to characterizing the estimation and model\nselection problems within this approach.\n  In this paper we consider instead the fundamental, but far less understood,\nquestion of \\emph{statistical significance}. More precisely, we address the\nproblem of computing p-values for single regression coefficients.\n  On one hand, we develop a general upper bound on the minimax power of tests\nwith a given significance level. On the other, we prove that this upper bound\nis (nearly) achievable through a practical procedure in the case of random\ndesign matrices with independent entries. Our approach is based on a debiasing\nof the Lasso estimator. The analysis builds on a rigorous characterization of\nthe asymptotic distribution of the Lasso estimator and its debiased version.\nOur result holds for optimal sample size, i.e., when $n$ is at least on the\norder of $s_0 \\log(p/s_0)$.\n  We generalize our approach to random design matrices with i.i.d. Gaussian\nrows $x_i\\sim N(0,\\Sigma)$. In this case we prove that a similar distributional\ncharacterization (termed `standard distributional limit') holds for $n$ much\nlarger than $s_0(\\log p)^2$.\n  Finally, we show that for optimal sample size, $n$ being at least of order\n$s_0 \\log(p/s_0)$, the standard distributional limit for general Gaussian\ndesigns can be derived from the replica heuristics in statistical physics.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jan 2013 21:16:49 GMT"}, {"version": "v2", "created": "Fri, 24 May 2013 07:02:40 GMT"}, {"version": "v3", "created": "Tue, 4 Feb 2014 04:05:41 GMT"}], "update_date": "2014-02-05", "authors_parsed": [["Javanmard", "Adel", ""], ["Montanari", "Andrea", ""]]}, {"id": "1301.4292", "submitter": "Mohammad Jafari Jozani", "authors": "Mohammad Jafari Jozani and Jafar Ahmadi", "title": "On uncertainty and information properties of ranked set samples", "comments": "15 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ranked set sampling is a sampling design which has a wide range of\napplications in industrial statistics, and environmental and ecological\nstudies, etc.. It is well known that ranked set samples provide more Fisher\ninformation than simple random samples of the same size about the unknown\nparameters of the underlying distribution in parametric inferences. In this\npaper, we consider the uncertainty and information content of ranked set\nsamples in both perfect and imperfect ranking scenarios in terms of Shannon\nentropy, R\\'enyi and Kullback-Leibler (KL) information measures. It is proved\nthat under these information measures, ranked set sampling design performs\nbetter than its simple random sampling counterpart of the same size. The\ninformation content is also a monotone function of the set size in ranked set\nsampling. Moreover, the effect of ranking error on the information content of\nthe data is investigated.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jan 2013 04:21:45 GMT"}], "update_date": "2013-01-21", "authors_parsed": [["Jozani", "Mohammad Jafari", ""], ["Ahmadi", "Jafar", ""]]}, {"id": "1301.4320", "submitter": "Fran\\c{c}ois Bachoc", "authors": "Fran\\c{c}ois Bachoc", "title": "Cross Validation and Maximum Likelihood estimations of hyper-parameters\n  of Gaussian processes with model misspecification", "comments": "A supplementary material (pdf) is available in the arXiv sources", "journal-ref": "Computational Statistics and Data Analysis (2013), pp. 55-69", "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Maximum Likelihood (ML) and Cross Validation (CV) methods for estimating\ncovariance hyper-parameters are compared, in the context of Kriging with a\nmisspecified covariance structure. A two-step approach is used. First, the case\nof the estimation of a single variance hyper-parameter is addressed, for which\nthe fixed correlation function is misspecified. A predictive variance based\nquality criterion is introduced and a closed-form expression of this criterion\nis derived. It is shown that when the correlation function is misspecified, the\nCV does better compared to ML, while ML is optimal when the model is\nwell-specified. In the second step, the results of the first step are extended\nto the case when the hyper-parameters of the correlation function are also\nestimated from data.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jan 2013 08:44:53 GMT"}, {"version": "v2", "created": "Thu, 14 Mar 2013 11:10:01 GMT"}, {"version": "v3", "created": "Fri, 31 May 2013 14:21:34 GMT"}], "update_date": "2013-06-03", "authors_parsed": [["Bachoc", "Fran\u00e7ois", ""]]}, {"id": "1301.4321", "submitter": "Fran\\c{c}ois Bachoc", "authors": "Fran\\c{c}ois Bachoc", "title": "Asymptotic analysis of the role of spatial sampling for covariance\n  parameter estimation of Gaussian processes", "comments": "47 pages. A supplementary material (pdf) is available in the arXiv\n  sources", "journal-ref": "Journal of Multivariate Analysis 125 (2014) 1-35", "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Covariance parameter estimation of Gaussian processes is analyzed in an\nasymptotic framework. The spatial sampling is a randomly perturbed regular grid\nand its deviation from the perfect regular grid is controlled by a single\nscalar regularity parameter. Consistency and asymptotic normality are proved\nfor the Maximum Likelihood and Cross Validation estimators of the covariance\nparameters. The asymptotic covariance matrices of the covariance parameter\nestimators are deterministic functions of the regularity parameter. By means of\nan exhaustive study of the asymptotic covariance matrices, it is shown that the\nestimation is improved when the regular grid is strongly perturbed. Hence, an\nasymptotic confirmation is given to the commonly admitted fact that using\ngroups of observation points with small spacing is beneficial to covariance\nfunction estimation. Finally, the prediction error, using a consistent\nestimator of the covariance parameters, is analyzed in details.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jan 2013 08:51:56 GMT"}, {"version": "v2", "created": "Thu, 26 Sep 2013 14:04:56 GMT"}, {"version": "v3", "created": "Tue, 7 Jan 2014 08:45:15 GMT"}, {"version": "v4", "created": "Mon, 8 Dec 2014 09:59:28 GMT"}], "update_date": "2014-12-09", "authors_parsed": [["Bachoc", "Fran\u00e7ois", ""]]}, {"id": "1301.4525", "submitter": "Jos\\'e A. D\\'iaz-Garc\\'ia", "authors": "Jos\\'e A. Diaz-Garcia", "title": "Distributions on symmetric cones II: Beta-Riesz distribution", "comments": "Several properties of q_{\\kappa} have been modified and their\n  consequences in the rest of the manuscript", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article derives several properties of the Riesz distributions, such as\ntheir corresponding Bartlett decompositions, the inverse Riesz distributions\nand the distribution of the generalised variance for real normed division\nalgebras. In addition, introduce a kind of generalised beta distribution termed\nbeta-Riesz distribution for real normed division algebras. Two versions of this\ndistributions are proposed and some properties are studied.\n", "versions": [{"version": "v1", "created": "Sat, 19 Jan 2013 00:55:44 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2015 02:06:45 GMT"}], "update_date": "2015-06-17", "authors_parsed": [["Diaz-Garcia", "Jos\u00e9 A.", ""]]}, {"id": "1301.4566", "submitter": "Aleksandr Aravkin", "authors": "Aleksandr Y. Aravkin and James V. Burke and Gianluigi Pillonetto", "title": "Sparse/Robust Estimation and Kalman Smoothing with Nonsmooth Log-Concave\n  Densities: Modeling, Computation, and Theory", "comments": "41 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML math.OC math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a class of quadratic support (QS) functions, many of which play\na crucial role in a variety of applications, including machine learning, robust\nstatistical inference, sparsity promotion, and Kalman smoothing. Well known\nexamples include the l2, Huber, l1 and Vapnik losses. We build on a dual\nrepresentation for QS functions using convex analysis, revealing the structure\nnecessary for a QS function to be interpreted as the negative log of a\nprobability density, and providing the foundation for statistical\ninterpretation and analysis of QS loss functions. For a subclass of QS\nfunctions called piecewise linear quadratic (PLQ) penalties, we also develop\nefficient numerical estimation schemes. These components form a flexible\nstatistical modeling framework for a variety of learning applications, together\nwith a toolbox of efficient numerical methods for inference. In particular, for\nPLQ densities, interior point (IP) methods can be used. IP methods solve\nnonsmooth optimization problems by working directly with smooth systems of\nequations characterizing their optimality. The efficiency of the IP approach\ndepends on the structure of particular applications. We consider the class of\ndynamic inverse problems using Kalman smoothing, where the aim is to\nreconstruct the state of a dynamical system with known process and measurement\nmodels starting from noisy output samples. In the classical case, Gaussian\nerrors are assumed in the process and measurement models. The extended\nframework allows arbitrary PLQ densities to be used, and the proposed IP\napproach solves the generalized Kalman smoothing problem while maintaining the\nlinear complexity in the size of the time series, just as in the Gaussian case.\nThis extends the computational efficiency of classic algorithms to a much\nbroader nonsmooth setting, and includes many recently proposed robust and\nsparse smoothers as special cases.\n", "versions": [{"version": "v1", "created": "Sat, 19 Jan 2013 14:46:29 GMT"}, {"version": "v2", "created": "Thu, 2 May 2013 10:38:22 GMT"}], "update_date": "2013-05-03", "authors_parsed": [["Aravkin", "Aleksandr Y.", ""], ["Burke", "James V.", ""], ["Pillonetto", "Gianluigi", ""]]}, {"id": "1301.4628", "submitter": "Mohammad Jafari Jozani", "authors": "Mohammad Jafari Jozani and Nahid Jafari Tabrizi", "title": "Intrinsic posterior regret gamma-minimax estimation for the exponential\n  family of distributions", "comments": "16 pages", "journal-ref": null, "doi": "10.1214/13-EJS828", "report-no": null, "categories": "math.ST stat.ME stat.OT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In practice, it is desired to have estimates that are invariant under\nreparameterization. The invariance property of the estimators helps to\nformulate a unified solution to the underlying estimation problem. In robust\nBayesian analysis, a frequent criticism is that the optimal estimators are not\ninvariant under smooth reparameterizations. This paper considers the problem of\nposterior regret gamma-minimax (PRGM) estimation of the natural parameter of\nthe exponential family of distributions under intrinsic loss functions. We show\nthat under the class of Jeffrey's Conjugate Prior (JCP) distributions, PRGM\nestimators are invariant to smooth one-to-one reparameterizations. We apply our\nresults to several distributions and different classes of JCP, as well as the\nusual conjugate prior distributions. We observe that, in many cases, invariant\nPRGM estimators in the class of JCP distributions can be obtained by some\nmodifications of PRGM estimators in the usual class of conjugate priors.\n  Moreover, when the class of priors are convex or dependant on a\nhyper-parameter belonging to a connected set, we show that the PRGM estimator\nunder the intrinsic loss function could be Bayes with respect to a prior\ndistribution in the original prior class. Theoretical results are supplemented\nwith several examples and illustrations.\n", "versions": [{"version": "v1", "created": "Sun, 20 Jan 2013 05:11:40 GMT"}], "update_date": "2014-04-24", "authors_parsed": [["Jozani", "Mohammad Jafari", ""], ["Tabrizi", "Nahid Jafari", ""]]}, {"id": "1301.4660", "submitter": "Cristina Butucea", "authors": "Cristina Butucea and Ghislaine Gayraud", "title": "Sharp detection of smooth signals in a high-dimensional sparse matrix\n  with indirect observations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a matrix-valued Gaussian sequence model, that is, we observe a\nsequence of high-dimensional $M \\times N$ matrices of heterogeneous Gaussian\nrandom variables $x_{ij,k}$ for $i \\in\\{1,...,M\\}$, $j \\in \\{1,...,N\\}$ and $k\n\\in \\mathbb{Z}$. The standard deviation of our observations is $\\ep k^s$ for\nsome $\\ep >0$ and $s \\geq 0$.\n  We give sharp rates for the detection of a sparse submatrix of size $m \\times\nn$ with active components. A component $(i,j)$ is said active if the sequence\n$\\{x_{ij,k}\\}_k$ have mean $\\{\\theta_{ij,k}\\}_k$ within a Sobolev ellipsoid of\nsmoothness $\\tau >0$ and total energy $\\sum_k \\theta^2_{ij,k} $ larger than\nsome $r^2_\\ep$. Our rates involve relationships between $m,\\, n, \\, M$ and $N$\ntending to infinity such that $m/M$, $n/N$ and $\\ep$ tend to 0, such that a\ntest procedure that we construct has asymptotic minimax risk tending to 0.\n  We prove corresponding lower bounds under additional assumptions on the\nrelative size of the submatrix in the large matrix of observations. Except for\nthese additional conditions our rates are asymptotically sharp. Lower bounds\nfor hypothesis testing problems mean that no test procedure can distinguish\nbetween the null hypothesis (no signal) and the alternative, i.e. the minimax\nrisk for testing tends to 1.\n", "versions": [{"version": "v1", "created": "Sun, 20 Jan 2013 14:14:27 GMT"}], "update_date": "2013-01-22", "authors_parsed": [["Butucea", "Cristina", ""], ["Gayraud", "Ghislaine", ""]]}, {"id": "1301.4679", "submitter": "Gerard Biau", "authors": "G\\'erard Biau (LPMA, LSTA, DMA, INRIA Paris - Rocquencourt), Luc\n  Devroye (SOCS)", "title": "Cellular Tree Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The cellular tree classifier model addresses a fundamental problem in the\ndesign of classifiers for a parallel or distributed computing world: Given a\ndata set, is it sufficient to apply a majority rule for classification, or\nshall one split the data into two or more parts and send each part to a\npotentially different computer (or cell) for further processing? At first\nsight, it seems impossible to define with this paradigm a consistent classifier\nas no cell knows the \"original data size\", $n$. However, we show that this is\nnot so by exhibiting two different consistent classifiers. The consistency is\nuniversal but is only shown for distributions with nonatomic marginals.\n", "versions": [{"version": "v1", "created": "Sun, 20 Jan 2013 20:01:54 GMT"}, {"version": "v2", "created": "Tue, 25 Jun 2013 06:17:24 GMT"}], "update_date": "2013-06-26", "authors_parsed": [["Biau", "G\u00e9rard", "", "LPMA, LSTA, DMA, INRIA Paris - Rocquencourt"], ["Devroye", "Luc", "", "SOCS"]]}, {"id": "1301.4804", "submitter": "Muneya Matsui", "authors": "Muneya Matsui, Zbynek Pawlas", "title": "Fractional absolute moments of heavy tailed distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several convenient methods for calculation of fractional absolute moments are\ngiven with application to heavy tailed distributions. We use techniques of\nfractional differentiation to obtain formulae for $E[|X-\\mu|^\\gamma]$ with\n$1<\\gamma<2$ and $\\mu\\in\\mathbb{R}$. The main focus is on heavy tailed\ndistributions, several examples are given with analytical expressions of\nfractional absolute moments. As applications, we calculate the fractional\nmoment errors for both prediction and parameter estimation problems.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2013 10:29:12 GMT"}, {"version": "v2", "created": "Tue, 3 Jun 2014 09:08:38 GMT"}], "update_date": "2014-06-04", "authors_parsed": [["Matsui", "Muneya", ""], ["Pawlas", "Zbynek", ""]]}, {"id": "1301.4807", "submitter": "Kengo Kato", "authors": "Victor Chernozhukov, Denis Chetverikov, Kengo Kato", "title": "Comparison and anti-concentration bounds for maxima of Gaussian random\n  vectors", "comments": "22 pages; discussions and references updated", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Slepian and Sudakov-Fernique type inequalities, which compare expectations of\nmaxima of Gaussian random vectors under certain restrictions on the covariance\nmatrices, play an important role in probability theory, especially in empirical\nprocess and extreme value theories. Here we give explicit comparisons of\nexpectations of smooth functions and distribution functions of maxima of\nGaussian random vectors without any restriction on the covariance matrices. We\nalso establish an anti-concentration inequality for the maximum of a Gaussian\nrandom vector, which derives a useful upper bound on the L\\'{e}vy concentration\nfunction for the Gaussian maximum. The bound is dimension-free and applies to\nvectors with arbitrary covariance matrices. This anti-concentration inequality\nplays a crucial role in establishing bounds on the Kolmogorov distance between\nmaxima of Gaussian random vectors. These results have immediate applications in\nmathematical statistics. As an example of application, we establish a\nconditional multiplier central limit theorem for maxima of sums of independent\nrandom vectors where the dimension of the vectors is possibly much larger than\nthe sample size.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2013 10:35:34 GMT"}, {"version": "v2", "created": "Tue, 22 Jan 2013 08:12:32 GMT"}, {"version": "v3", "created": "Tue, 19 Feb 2013 05:39:45 GMT"}, {"version": "v4", "created": "Sun, 13 Apr 2014 02:06:36 GMT"}], "update_date": "2014-04-15", "authors_parsed": [["Chernozhukov", "Victor", ""], ["Chetverikov", "Denis", ""], ["Kato", "Kengo", ""]]}, {"id": "1301.4867", "submitter": "Giulio Cottone", "authors": "Giulio Cottone and Mario Di Paola", "title": "On the use of fractional calculus for the probabilistic characterization\n  of random variables", "comments": null, "journal-ref": "Probabilistic Engineering Mechanics, Volume 24, Issue 3, 2009,\n  Pages 321-330, ISSN 0266-8920", "doi": "10.1016/j.probengmech.2008.08.002", "report-no": null, "categories": "math-ph math.MP math.ST physics.data-an stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the classical problem of the probabilistic characterization of\na random variable is re-examined. A random variable is usually described by the\nprobability density function (PDF) or by its Fourier transform, namely the\ncharacteristic function (CF). The CF can be further expressed by a Taylor\nseries involving the moments of the random variable. However, in some\ncircumstances, the moments do not exist and the Taylor expansion of the CF is\nuseless. This happens for example in the case of $\\alpha$--stable random\nvariables. Here, the problem of representing the CF or the PDF of random\nvariables (r.vs) is examined by introducing fractional calculus. Two very\nremarkable results are obtained. Firstly, it is shown that the fractional\nderivatives of the CF in zero coincide with fractional moments. This is true\nalso in case of CF not derivable in zero (like the CF of $\\alpha$--stable\nr.vs). Moreover, it is shown that the CF may be represented by a generalized\nTaylor expansion involving fractional moments. The generalized Taylor series\nproposed is also able to represent the PDF in a perfect dual representation to\nthat in terms of CF. The PDF representation in terms of fractional moments is\nespecially accurate in the tails and this is very important in engineering\nproblems, like estimating structural safety.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2013 13:42:31 GMT"}], "update_date": "2013-01-22", "authors_parsed": [["Cottone", "Giulio", ""], ["Di Paola", "Mario", ""]]}, {"id": "1301.4873", "submitter": "Bo Markussen", "authors": "Bo Markussen", "title": "Functional data analysis in an operator-based mixed-model framework", "comments": "Published in at http://dx.doi.org/10.3150/11-BEJ389 the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2013, Vol. 19, No. 1, 1-17", "doi": "10.3150/11-BEJ389", "report-no": "IMS-BEJ-BEJ389", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Functional data analysis in a mixed-effects model framework is done using\noperator calculus. In this approach the functional parameters are treated as\nserially correlated effects giving an alternative to the penalized likelihood\napproach, where the functional parameters are treated as fixed effects.\nOperator approximations for the necessary matrix computations are proposed, and\nsemi-explicit and numerically stable formulae of linear computational\ncomplexity are derived for likelihood analysis. The operator approach renders\nthe usage of a functional basis unnecessary and clarifies the role of the\nboundary conditions.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2013 14:20:06 GMT"}], "update_date": "2013-01-22", "authors_parsed": [["Markussen", "Bo", ""]]}, {"id": "1301.4954", "submitter": "Xiao Wang", "authors": "Xiao Wang and David Ruppert", "title": "Optimal Prediction in an Additive Functional Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The functional generalized additive model (FGAM) provides a more flexible\nnonlinear functional regression model than the well-studied functional linear\nregression model. This paper restricts attention to the FGAM with identity link\nand additive errors, which we will call the additive functional model, a\ngeneralization of the functional linear model. This paper studies the minimax\nrate of convergence of predictions from the additive functional model in the\nframework of reproducing kernel Hilbert space. It is shown that the optimal\nrate is determined by the decay rate of the eigenvalues of a specific kernel\nfunction, which in turn is determined by the reproducing kernel and the joint\ndistribution of any two points in the random predictor function. For the\nspecial case of the functional linear model, this kernel function is jointly\ndetermined by the covariance function of the predictor function and the\nreproducing kernel. The easily implementable roughness-regularized predictor is\nshown to achieve the optimal rate of convergence. Numerical studies are carried\nout to illustrate the merits of the predictor. Our simulations and real data\nexamples demonstrate a competitive performance against the existing approach.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2013 18:40:08 GMT"}], "update_date": "2013-01-22", "authors_parsed": [["Wang", "Xiao", ""], ["Ruppert", "David", ""]]}, {"id": "1301.5086", "submitter": "Rajesh  Singh", "authors": "Rajesh Singh, Mukesh Kumar, R. D. Singh, M. K. Chaudhry", "title": "Exponential Ratio Type Estimators In Stratified Random Sampling", "comments": "16 pages, 2 tables; Advances in Statistics and Optimization . Eds. A.\n  H. Khan and R. Khan, R. J. Enrerprises, New Delhi (2013). ISBN\n  978-81-924874-0-3", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kadilar and Cingi (2003) have introduced a family of estimators using\nauxiliary information in stratified random sampling. In this paper, we propose\nthe ratio estimator for the estimation of population mean in the stratified\nrandom sampling by using the estimators in Bahl and Tuteja (1991) and Kadilar\nand Cingi (2003). Obtaining the mean square error (MSE) equations of the\nproposed estimators, we find theoretical conditions that the proposed\nestimators are more efficient than the other estimators. These theoretical\nfindings are supported by a numerical example.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2013 06:52:39 GMT"}], "update_date": "2013-01-23", "authors_parsed": [["Singh", "Rajesh", ""], ["Kumar", "Mukesh", ""], ["Singh", "R. D.", ""], ["Chaudhry", "M. K.", ""]]}, {"id": "1301.5186", "submitter": "Ali Kinkhabwala", "authors": "Ali Kinkhabwala (Max Planck Institute of Molecular Physiology)", "title": "Maximum Fidelity", "comments": "66 pages, 32 figures, 7 tables, submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST astro-ph.IM hep-ex stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The most fundamental problem in statistics is the inference of an unknown\nprobability distribution from a finite number of samples. For a specific\nobserved data set, answers to the following questions would be desirable: (1)\nEstimation: Which candidate distribution provides the best fit to the observed\ndata?, (2) Goodness-of-fit: How concordant is this distribution with the\nobserved data?, and (3) Uncertainty: How concordant are other candidate\ndistributions with the observed data? A simple unified approach for univariate\ndata that addresses these traditionally distinct statistical notions is\npresented called \"maximum fidelity\". Maximum fidelity is a strict frequentist\napproach that is fundamentally based on model concordance with the observed\ndata. The fidelity statistic is a general information measure based on the\ncoordinate-independent cumulative distribution and critical yet previously\nneglected symmetry considerations. An approximation for the null distribution\nof the fidelity allows its direct conversion to absolute model concordance (p\nvalue). Fidelity maximization allows identification of the most concordant\nmodel distribution, generating a method for parameter estimation, with\nneighboring, less concordant distributions providing the \"uncertainty\" in this\nestimate. Maximum fidelity provides an optimal approach for parameter\nestimation (superior to maximum likelihood) and a generally optimal approach\nfor goodness-of-fit assessment of arbitrary models applied to univariate data.\nExtensions to binary data, binned data, multidimensional data, and classical\nparametric and nonparametric statistical tests are described. Maximum fidelity\nprovides a philosophically consistent, robust, and seemingly optimal foundation\nfor statistical inference. All findings are presented in an elementary way to\nbe immediately accessible to all researchers utilizing statistical analysis.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2013 13:58:42 GMT"}], "update_date": "2013-01-23", "authors_parsed": [["Kinkhabwala", "Ali", "", "Max Planck Institute of Molecular Physiology"]]}, {"id": "1301.5244", "submitter": "Arpad Baricz", "authors": "\\'Arp\\'ad Baricz", "title": "Remarks on a parameter estimation for von Mises--Fisher distributions", "comments": "3 pages", "journal-ref": "Computational Statistics 29 (2014) 891-894", "doi": "10.1007/s00180-014-0493-2", "report-no": null, "categories": "math.CA math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We point out an error in the proof of the main result of the paper of Tanabe\net al. (2007) concerning a parameter estimation for von Mises--Fisher\ndistributions, we correct the proof of the main result and we present a short\nalternative proof.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2013 17:12:43 GMT"}], "update_date": "2014-07-10", "authors_parsed": [["Baricz", "\u00c1rp\u00e1d", ""]]}, {"id": "1301.5254", "submitter": "Marianna Bolla CSc", "authors": "Marianna Bolla", "title": "Modularity spectra, eigen-subspaces, and structure of weighted graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.SP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The role of the normalized modularity matrix in finding homogeneous cuts will\nbe presented. We also discuss the testability of the structural eigenvalues and\nthat of the subspace spanned by the corresponding eigenvectors of this matrix.\nIn the presence of a spectral gap between the k-1 largest absolute value\neigenvalues and the remainder of the spectrum, this in turn implies the\ntestability of the sum of the inner variances of the k clusters that are\nobtained by applying the k-means algorithm for the appropriately chosen vertex\nrepresentatives.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2013 17:42:51 GMT"}], "update_date": "2013-01-23", "authors_parsed": [["Bolla", "Marianna", ""]]}, {"id": "1301.5259", "submitter": "Marianna Bolla CSc", "authors": "Marianna Bolla", "title": "SVD, discrepancy, and regular structure of contingency tables", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We will use the factors obtained by correspondence analysis to find\nbiclustering of a contingency table such that the row-column cluster pairs are\nregular, i.e., they have small discrepancy. In our main theorem, the constant\nof the so-called volume-regularity is related to the SVD of the normalized\ncontingency table. Our result is applicable to two-way cuts when both the rows\nand columns are divided into the same number of clusters, thus extending partly\nthe result of Butler estimating the discrepancy of a contingency table by the\nsecond largest singular value of the normalized table (one-cluster, rectangular\ncase), and partly a former result of the author for estimating the constant of\nvolume-regularity by the structural eigenvalues and the distances of the\ncorresponding eigen-subspaces of the normalized modularity matrix of an\nedge-weighted graph (several clusters, symmetric case).\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2013 18:03:43 GMT"}], "update_date": "2013-01-23", "authors_parsed": [["Bolla", "Marianna", ""]]}, {"id": "1301.5288", "submitter": "Aleksandr Aravkin", "authors": "Aleksandr Y. Aravkin and Bradley M. Bell and James V. Burke and\n  Gianluigi Pillonetto", "title": "The connection between Bayesian estimation of a Gaussian random field\n  and RKHS", "comments": "8 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reconstruction of a function from noisy data is often formulated as a\nregularized optimization problem over an infinite-dimensional reproducing\nkernel Hilbert space (RKHS). The solution describes the observed data and has a\nsmall RKHS norm. When the data fit is measured using a quadratic loss, this\nestimator has a known statistical interpretation. Given the noisy measurements,\nthe RKHS estimate represents the posterior mean (minimum variance estimate) of\na Gaussian random field with covariance proportional to the kernel associated\nwith the RKHS. In this paper, we provide a statistical interpretation when more\ngeneral losses are used, such as absolute value, Vapnik or Huber. Specifically,\nfor any finite set of sampling locations (including where the data were\ncollected), the MAP estimate for the signal samples is given by the RKHS\nestimate evaluated at these locations.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2013 19:19:38 GMT"}, {"version": "v2", "created": "Tue, 26 Feb 2013 13:24:41 GMT"}, {"version": "v3", "created": "Wed, 17 Jul 2013 15:11:46 GMT"}], "update_date": "2013-07-18", "authors_parsed": [["Aravkin", "Aleksandr Y.", ""], ["Bell", "Bradley M.", ""], ["Burke", "James V.", ""], ["Pillonetto", "Gianluigi", ""]]}, {"id": "1301.5328", "submitter": "Anatoli Juditsky", "authors": "Anatoli Juditsky, Arkadi Nemirovski", "title": "On detecting harmonic oscillations", "comments": "Published at http://dx.doi.org/10.3150/14-BEJ600 in the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2015, Vol. 21, No. 2, 1134-1165", "doi": "10.3150/14-BEJ600", "report-no": "IMS-BEJ-BEJ600", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we focus on the following testing problem: assume that we are\ngiven observations of a real-valued signal along the grid $0,1,\\ldots,N-1$,\ncorrupted by white Gaussian noise. We want to distinguish between two\nhypotheses: (a) the signal is a nuisance - a linear combination of $d_n$\nharmonic oscillations of known frequencies, and (b) signal is the sum of a\nnuisance and a linear combination of a given number $d_s$ of harmonic\noscillations with unknown frequencies, and such that the distance (measured in\nthe uniform norm on the grid) between the signal and the set of nuisances is at\nleast $\\rho>0$. We propose a computationally efficient test for distinguishing\nbetween (a) and (b) and show that its \"resolution\" (the smallest value of\n$\\rho$ for which (a) and (b) are distinguished with a given confidence\n$1-\\alpha$) is $\\mathrm{O}(\\sqrt{\\ln(N/\\alpha)/N})$, with the hidden factor\ndepending solely on $d_n$ and $d_s$ and independent of the frequencies in\nquestion. We show that this resolution, up to a factor which is polynomial in\n$d_n,d_s$ and logarithmic in $N$, is the best possible under circumstances. We\nfurther extend the outlined results to the case of nuisances and signals close\nto linear combinations of harmonic oscillations, and provide illustrative\nnumerical results.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2013 21:03:58 GMT"}, {"version": "v2", "created": "Mon, 1 Jun 2015 12:24:40 GMT"}], "update_date": "2015-06-02", "authors_parsed": [["Juditsky", "Anatoli", ""], ["Nemirovski", "Arkadi", ""]]}, {"id": "1301.5492", "submitter": "Laurent Demaret", "authors": "Laurent Demaret, Felix Friedrich, Volkmar Liebscher, Gerhard Winkler", "title": "Complexity $L^0$-penalized M-Estimation: Consistency in More Dimensions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the asymptotics in $L^2$ for complexity penalized least squares\nregression for the discrete approximation of finite-dimensional signals on\ncontinuous domains - e.g. images - by piecewise smooth functions.\n  We introduce a fairly general setting which comprises most of the presently\npopular partitions of signal- or image- domains like interval-, wedgelet- or\nrelated partitions, as well as Delaunay triangulations. Then we prove\nconsistency and derive convergence rates. Finally, we illustrate by way of\nrelevant examples that the abstract results are useful for many applications.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 13:15:26 GMT"}, {"version": "v2", "created": "Mon, 28 Jan 2013 21:43:41 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Demaret", "Laurent", ""], ["Friedrich", "Felix", ""], ["Liebscher", "Volkmar", ""], ["Winkler", "Gerhard", ""]]}, {"id": "1301.5579", "submitter": "Mindaugas Bloznelis", "authors": "Mindaugas Bloznelis and Michal Karonski", "title": "Random intersection graph process", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.CO math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a random intersection graph process aimed at modeling sparse\nevolving affiliation networks that admit tunable (power law) degree\ndistribution and assortativity and clustering coefficients. We show the\nasymptotic degree distribution and provide explicit asymptotic formulas for\nassortativity and clustering coefficients.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 17:38:08 GMT"}], "update_date": "2013-01-24", "authors_parsed": [["Bloznelis", "Mindaugas", ""], ["Karonski", "Michal", ""]]}, {"id": "1301.5722", "submitter": "Boris Brodsky E.", "authors": "Boris Brodsky, Boris Darkhovsky", "title": "Asymptotically Optimal Detection of Changes in Stochastic Models with\n  Switching Regimes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with the problem of asymptotically optimal detection of\nchanges in regime-switching stochastic models. We need to divide the whole\nobtained sample of data into several sub-samples with observations belonging to\ndifferent states of a stochastic models with switching regimes. For this\npurpose, the idea of reduction to a corresponding change-point detection\nproblem is used. Both univariate and multivariate switching models are\nconsidered. For the univariate case, we begin with the study of binary mixtures\nof probabilistic distributions. In theorems 1 and 2 we prove that type 1 and\ntype 2 errors of the proposed method converge to zero exponentially as the\nsample size tends to infinity. In theorem 3 we prove that the proposed method\nis asymptotically optimal by the rate of this convergence in the sense that the\nlower bound in the a priori informational inequality is attained for our\nmethod. Several generalizations to the case of multiple univariate mixtures of\nprobabilistic distributions are considered. For the multivariate case, we first\nstudy the general problem of classification of the whole array of data into\nseveral sub-arrays of observations from different regimes of a multivariate\nstochastic model with switching states. Then we consider regression models with\nabnormal observations and switching sets of regression coefficients. Results of\na detailed Monte Carlo study of the proposed method for different stochastic\nmodels with switching regimes are presented.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2013 07:41:04 GMT"}], "update_date": "2013-01-25", "authors_parsed": [["Brodsky", "Boris", ""], ["Darkhovsky", "Boris", ""]]}, {"id": "1301.5802", "submitter": "Christine Malot", "authors": "Laure Sansonnet (LM-Orsay), Christine Tuleau-Malot (JAD)", "title": "A model of Poissonian interactions and detection of dependence", "comments": "27 pages", "journal-ref": "Statistics and Computing (2013) 10.1007/s11222-013-9443-z", "doi": "10.1007/s11222-013-9443-z", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a model of interactions between two point processes,\nruled by a reproduction function h, which is considered as the intensity of a\nPoisson process. In particular, we focus on the context of neurosciences to\ndetect possible interactions in the cerebral activity associated with two\nneurons. To provide a mathematical answer to this specific problem of\nneurobiologists, we address so the question of testing the nullity of the\nintensity h. We construct a multiple testing procedure obtained by the\naggregation of single tests based on a wavelet thresholding method. This test\nhas good theoretical properties: it is possible to guarantee the level but also\nthe power under some assumptions and its uniform separation rate over weak\nBesov bodies is adaptive minimax. Then, some simulations are provided, showing\nthe good practical behavior of our testing procedure.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2013 14:47:19 GMT"}, {"version": "v2", "created": "Thu, 6 Mar 2014 14:41:39 GMT"}], "update_date": "2014-03-07", "authors_parsed": [["Sansonnet", "Laure", "", "LM-Orsay"], ["Tuleau-Malot", "Christine", "", "JAD"]]}, {"id": "1301.5873", "submitter": "Yohann De Castro", "authors": "Jean-Marc Azais (IMT), Yohann De Castro (LM-Orsay), Fabrice Gamboa\n  (IMT, - M\\'ethodes d'Analyse Stochastique des Codes et Traitements\n  Num\\'eriques)", "title": "Spike detection from inaccurate samplings", "comments": "Revised version, minor changes, 16pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article investigates the support detection problem using the LASSO\nestimator in the space of measures. More precisely, we study the recovery of a\ndiscrete measure (spike train) from few noisy observations (Fourier samples,\nmoments...) using an $\\ell_{1}$-regularization procedure. In particular, we\nprovide an explicit quantitative localization of the spikes.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2013 19:29:14 GMT"}, {"version": "v2", "created": "Fri, 25 Oct 2013 20:14:14 GMT"}, {"version": "v3", "created": "Wed, 26 Feb 2014 05:55:47 GMT"}], "update_date": "2014-02-27", "authors_parsed": [["Azais", "Jean-Marc", "", "IMT"], ["De Castro", "Yohann", "", "LM-Orsay"], ["Gamboa", "Fabrice", "", "IMT, - M\u00e9thodes d'Analyse Stochastique des Codes et Traitements\n  Num\u00e9riques"]]}, {"id": "1301.5874", "submitter": "Charles-Alban Deledalle", "authors": "Charles-Alban Deledalle (IMB), Gabriel Peyr\\'e (CEREMADE), Jalal\n  Fadili (GREYC)", "title": "Stein COnsistent Risk Estimator (SCORE) for hard thresholding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we construct a risk estimator for hard thresholding which can\nbe used as a basis to solve the difficult task of automatically selecting the\nthreshold. As hard thresholding is not even continuous, Stein's lemma cannot be\nused to get an unbiased estimator of degrees of freedom, hence of the risk. We\nprove that under a mild condition, our estimator of the degrees of freedom,\nalthough biased, is consistent. Numerical evidence shows that our estimator\noutperforms another biased risk estimator.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2013 19:29:49 GMT"}], "update_date": "2013-01-25", "authors_parsed": [["Deledalle", "Charles-Alban", "", "IMB"], ["Peyr\u00e9", "Gabriel", "", "CEREMADE"], ["Fadili", "Jalal", "", "GREYC"]]}, {"id": "1301.6080", "submitter": "Guillaume Lecu\\'{e}", "authors": "Guillaume Lecu\\'e, Philippe Rigollet", "title": "Optimal learning with $Q$-aggregation", "comments": "Published in at http://dx.doi.org/10.1214/13-AOS1190 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2014, Vol. 42, No. 1, 211-224", "doi": "10.1214/13-AOS1190", "report-no": "IMS-AOS-AOS1190", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a general supervised learning problem with strongly convex and\nLipschitz loss and study the problem of model selection aggregation. In\nparticular, given a finite dictionary functions (learners) together with the\nprior, we generalize the results obtained by Dai, Rigollet and Zhang [Ann.\nStatist. 40 (2012) 1878-1905] for Gaussian regression with squared loss and\nfixed design to this learning setup. Specifically, we prove that the\n$Q$-aggregation procedure outputs an estimator that satisfies optimal oracle\ninequalities both in expectation and with high probability. Our proof\ntechniques somewhat depart from traditional proofs by making most of the\nstandard arguments on the Laplace transform of the empirical process to be\ncontrolled.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2013 16:23:23 GMT"}, {"version": "v2", "created": "Wed, 30 Jan 2013 12:49:38 GMT"}, {"version": "v3", "created": "Thu, 27 Feb 2014 07:11:02 GMT"}], "update_date": "2014-02-28", "authors_parsed": [["Lecu\u00e9", "Guillaume", ""], ["Rigollet", "Philippe", ""]]}, {"id": "1301.6086", "submitter": "Aaron Smith", "authors": "Aaron Carl Smith", "title": "Benford-Newcomb Subsequences for Fraud Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Benford's law is frequently used to evaluate the likihood that data is\nmisrepresentative. Typically statistical tests measure the likihood. Another\nmethod of employing Benford's law is to compare the frequency of leading digits\nto the probabilities of leading digits over a subset of the natural numbers.\nThis paper proposes using the probabilities of leading digits from uniform,\nnatural numbers to establish interval criteria for when to look more closely\ninto the possibility of misrepresentative data.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2013 12:38:41 GMT"}], "update_date": "2013-01-28", "authors_parsed": [["Smith", "Aaron Carl", ""]]}, {"id": "1301.6256", "submitter": "Hailong Shi", "authors": "Hailong Shi and Hao Zhang", "title": "Tight is better: Performance Improvement of the Compressive Classifier\n  Using Equi-Norm Tight Frames", "comments": "6pages,Accepted by IEEE DSP/SPE 2013", "journal-ref": "Digital Signal Processing and Signal Processing Education Meeting\n  (DSP/SPE), 2013 IEEE , vol., no., pp.12,17, 11-14 Aug. 2013", "doi": "10.1109/DSP-SPE.2013.6642557", "report-no": null, "categories": "cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting or classifying already known sparse signals contaminated by\nGaussian noise from compressive measurements is different from reconstructing\nsparse signals, as its objective is to minimize the error probability which\ndescribes performance of the detectors or classifiers. This paper is concerned\nabout the performance improvement of a commonly used Compressive Classifier. We\nprove that when the arbitrary sensing matrices used to get the Compressive\nMeasurements are transformed into Equi-Norm Tight Frames, i.e. the matrices\nthat are row-orthogonal, The Compressive Classifier achieves better\nperformance. Although there are other proofs that among all Equi-Norm Tight\nFrames the Equiangular tight Frames (ETFs) bring best worst-case performance,\nthe existence and construction of ETFs on some dimensions is still an open\nproblem. As the construction of Equi-Norm Tight Frames from any arbitrary\nmatrices is very easy and practical compared with ETF matrices, the result of\nthis paper can also provide a practical method to design an improved sensing\nmatrix for Compressive Classification. We can conclude that: Tight is Better!\n", "versions": [{"version": "v1", "created": "Sat, 26 Jan 2013 13:59:26 GMT"}, {"version": "v2", "created": "Mon, 1 Jul 2013 14:31:12 GMT"}], "update_date": "2014-01-06", "authors_parsed": [["Shi", "Hailong", ""], ["Zhang", "Hao", ""]]}, {"id": "1301.6376", "submitter": "Georg Mainik", "authors": "Jan Beran, Georg Mainik", "title": "On estimating extremal dependence structures by parametric spectral\n  measures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimation of extreme value copulas is often required in situations where\navailable data are sparse. Parametric methods may then be the preferred\napproach. A possible way of defining parametric families that are simple and,\nat the same time, cover a large variety of multivariate extremal dependence\nstructures is to build models based on spectral measures. This approach is\nconsidered here. Parametric families of spectral measures are defined as convex\nhulls of suitable basis elements, and parameters are estimated by projecting an\ninitial nonparametric estimator on these finite-dimensional spaces. Asymptotic\ndistributions are derived for the estimated parameters and the resulting\nestimates of the spectral measure and the extreme value copula. Finite sample\nproperties are illustrated by a simulation study.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jan 2013 17:05:56 GMT"}], "update_date": "2013-01-29", "authors_parsed": [["Beran", "Jan", ""], ["Mainik", "Georg", ""]]}, {"id": "1301.6392", "submitter": "Yousri Slaoui", "authors": "Yousri Slaoui", "title": "Large and moderate deviation principles for recursive kernel density\n  estimators defined by stochastic approximation method", "comments": "18 pages. arXiv admin note: substantial text overlap with\n  arXiv:math/0601429 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we prove large and moderate deviations principles for the\nrecursive kernel estimators of a probability density function defined by the\nstochastic approximation algorithm introduced by Mokkadem et al. [2009. The\nstochastic approximation method for the estimation of a probability density. J.\nStatist. Plann. Inference 139, 2459-2478]. We show that the estimator\nconstructed using the stepsize which minimize the variance of the class of the\nrecursive estimators defined in Mokkadem et al. (2009) gives the same pointwise\nLDP and MDP as the Rosenblatt kernel estimator. We provide results both for the\npointwise and the uniform deviations.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jan 2013 19:51:48 GMT"}], "update_date": "2013-01-29", "authors_parsed": [["Slaoui", "Yousri", ""]]}, {"id": "1301.6413", "submitter": "Konstantinos Spiliopoulos", "authors": "Konstantinos Spiliopoulos, Alexandra Chronopoulou", "title": "Maximum likelihood estimation for small noise multiscale diffusions", "comments": null, "journal-ref": "Statistical Inference for Stochastic Processes,Volume 16, Issue 3,\n  2013, pp. 237-266", "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of parameter estimation for stochastic differential\nequations with small noise and fast oscillating parameters. Depending on how\nfast the intensity of the noise goes to zero relative to the homogenization\nparameter, we consider three different regimes. For each regime, we construct\nthe maximum likelihood estimator and we study its consistency and asymptotic\nnormality properties. A simulation study for the first order Langevin equation\nwith a two scale potential is also provided.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jan 2013 23:27:07 GMT"}, {"version": "v2", "created": "Wed, 29 May 2013 00:30:16 GMT"}, {"version": "v3", "created": "Fri, 25 Oct 2013 15:16:52 GMT"}, {"version": "v4", "created": "Wed, 18 Feb 2015 21:34:58 GMT"}], "update_date": "2015-02-20", "authors_parsed": [["Spiliopoulos", "Konstantinos", ""], ["Chronopoulou", "Alexandra", ""]]}, {"id": "1301.6465", "submitter": "Peter Harremo\\\"es", "authors": "Peter Harremo\\\"es", "title": "Extendable MDL", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we show that combination of the minimum description length\nprinciple and a exchange-ability condition leads directly to the use of\nJeffreys prior. This approach works in most cases even when Jeffreys prior\ncannot be normalized. Kraft's inequality links codes and distributions but a\ncloser look at this inequality demonstrates that this link only makes sense\nwhen sequences are considered as prefixes of potential longer sequences. For\ntechnical reasons only results for exponential families are stated. Results on\nwhen Jeffreys prior can be normalized after conditioning on a initializing\nstring are given. An exotic case where no initial string allow Jeffreys prior\nto be normalized is given and some way of handling such exotic cases are\ndiscussed.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2013 07:52:38 GMT"}, {"version": "v2", "created": "Sun, 19 May 2013 10:13:44 GMT"}], "update_date": "2013-05-21", "authors_parsed": [["Harremo\u00ebs", "Peter", ""]]}, {"id": "1301.6585", "submitter": "Patrick Rebeschini", "authors": "Patrick Rebeschini, Ramon van Handel", "title": "Can local particle filters beat the curse of dimensionality?", "comments": "Published at http://dx.doi.org/10.1214/14-AAP1061 in the Annals of\n  Applied Probability (http://www.imstat.org/aap/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Probability 2015, Vol. 25, No. 5, 2809-2866", "doi": "10.1214/14-AAP1061", "report-no": "IMS-AAP-AAP1061", "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The discovery of particle filtering methods has enabled the use of nonlinear\nfiltering in a wide array of applications. Unfortunately, the approximation\nerror of particle filters typically grows exponentially in the dimension of the\nunderlying model. This phenomenon has rendered particle filters of limited use\nin complex data assimilation problems. In this paper, we argue that it is often\npossible, at least in principle, to develop local particle filtering algorithms\nwhose approximation error is dimension-free. The key to such developments is\nthe decay of correlations property, which is a spatial counterpart of the much\nbetter understood stability property of nonlinear filters. For the simplest\npossible algorithm of this type, our results provide under suitable assumptions\nan approximation error bound that is uniform both in time and in the model\ndimension. More broadly, our results provide a framework for the investigation\nof filtering problems and algorithms in high dimension.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2013 16:04:20 GMT"}, {"version": "v2", "created": "Wed, 9 Sep 2015 10:31:09 GMT"}], "update_date": "2015-09-10", "authors_parsed": [["Rebeschini", "Patrick", ""], ["van Handel", "Ramon", ""]]}, {"id": "1301.6624", "submitter": "Robin J. Evans", "authors": "Robin J. Evans, Thomas S. Richardson", "title": "Markovian acyclic directed mixed graphs for discrete data", "comments": "Published in at http://dx.doi.org/10.1214/14-AOS1206 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2014, Vol. 42, No. 4, 1452-1482", "doi": "10.1214/14-AOS1206", "report-no": "IMS-AOS-AOS1206", "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Acyclic directed mixed graphs (ADMGs) are graphs that contain directed\n($\\rightarrow$) and bidirected ($\\leftrightarrow$) edges, subject to the\nconstraint that there are no cycles of directed edges. Such graphs may be used\nto represent the conditional independence structure induced by a DAG model\ncontaining hidden variables on its observed margin. The Markovian model\nassociated with an ADMG is simply the set of distributions obeying the global\nMarkov property, given via a simple path criterion (m-separation). We first\npresent a factorization criterion characterizing the Markovian model that\ngeneralizes the well-known recursive factorization for DAGs. For the case of\nfinite discrete random variables, we also provide a parameterization of the\nmodel in terms of simple conditional probabilities, and characterize its\nvariation dependence. We show that the induced models are smooth. Consequently,\nMarkovian ADMG models for discrete variables are curved exponential families of\ndistributions.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2013 17:49:56 GMT"}, {"version": "v2", "created": "Wed, 4 Dec 2013 10:27:00 GMT"}, {"version": "v3", "created": "Wed, 23 Apr 2014 14:17:08 GMT"}, {"version": "v4", "created": "Thu, 14 Aug 2014 06:12:21 GMT"}], "update_date": "2014-08-15", "authors_parsed": [["Evans", "Robin J.", ""], ["Richardson", "Thomas S.", ""]]}, {"id": "1301.6635", "submitter": "Jeffrey W. Miller", "authors": "Jeffrey W. Miller, Matthew T. Harrison", "title": "Exact sampling and counting for fixed-margin matrices", "comments": "Published in at http://dx.doi.org/10.1214/13-AOS1131 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org). arXiv admin note: text overlap with\n  arXiv:1104.0323", "journal-ref": "Annals of Statistics 2013, Vol. 41, No. 3, 1569-1592", "doi": "10.1214/13-AOS1131", "report-no": "IMS-AOS-AOS1131", "categories": "stat.CO math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The uniform distribution on matrices with specified row and column sums is\noften a natural choice of null model when testing for structure in two-way\ntables (binary or nonnegative integer). Due to the difficulty of sampling from\nthis distribution, many approximate methods have been developed. We will show\nthat by exploiting certain symmetries, exact sampling and counting is in fact\npossible in many nontrivial real-world cases. We illustrate with real datasets\nincluding ecological co-occurrence matrices and contingency tables.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2013 18:33:47 GMT"}, {"version": "v2", "created": "Tue, 13 Aug 2013 11:08:27 GMT"}], "update_date": "2013-08-14", "authors_parsed": [["Miller", "Jeffrey W.", ""], ["Harrison", "Matthew T.", ""]]}, {"id": "1301.6647", "submitter": "Tamara Broderick", "authors": "Tamara Broderick, Jim Pitman, Michael I. Jordan", "title": "Feature allocations, probability functions, and paintboxes", "comments": "37 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of inferring a clustering of a data set has been the subject of\nmuch research in Bayesian analysis, and there currently exists a solid\nmathematical foundation for Bayesian approaches to clustering. In particular,\nthe class of probability distributions over partitions of a data set has been\ncharacterized in a number of ways, including via exchangeable partition\nprobability functions (EPPFs) and the Kingman paintbox. Here, we develop a\ngeneralization of the clustering problem, called feature allocation, where we\nallow each data point to belong to an arbitrary, non-negative integer number of\ngroups, now called features or topics. We define and study an \"exchangeable\nfeature probability function\" (EFPF)---analogous to the EPPF in the clustering\nsetting---for certain types of feature models. Moreover, we introduce a\n\"feature paintbox\" characterization---analogous to the Kingman paintbox for\nclustering---of the class of exchangeable feature models. We provide a further\ncharacterization of the subclass of feature allocations that have EFPF\nrepresentations.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2013 19:07:21 GMT"}, {"version": "v2", "created": "Tue, 29 Jan 2013 19:09:59 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Broderick", "Tamara", ""], ["Pitman", "Jim", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1301.6921", "submitter": "Tyler J. VanderWeele", "authors": "Tyler J. VanderWeele, Thomas S. Richardson", "title": "General theory for interactions in sufficient cause models with\n  dichotomous exposures", "comments": "Published in at http://dx.doi.org/10.1214/12-AOS1019 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2012, Vol. 40, No. 4, 2128-2161", "doi": "10.1214/12-AOS1019", "report-no": "IMS-AOS-AOS1019", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The sufficient-component cause framework assumes the existence of sets of\nsufficient causes that bring about an event. For a binary outcome and an\narbitrary number of binary causes any set of potential outcomes can be\nreplicated by positing a set of sufficient causes; typically this\nrepresentation is not unique. A sufficient cause interaction is said to be\npresent if within all representations there exists a sufficient cause in which\ntwo or more particular causes are all present. A singular interaction is said\nto be present if for some subset of individuals there is a unique minimal\nsufficient cause. Empirical and counterfactual conditions are given for\nsufficient cause interactions and singular interactions between an arbitrary\nnumber of causes. Conditions are given for cases in which none, some or all of\na given set of causes affect the outcome monotonically. The relations between\nthese results, interactions in linear statistical models and Pearl's\nprobability of causation are discussed.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2013 13:45:57 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["VanderWeele", "Tyler J.", ""], ["Richardson", "Thomas S.", ""]]}, {"id": "1301.7026", "submitter": "Nicola Lunardon", "authors": "Nicola Lunardon", "title": "Prepivoting composite score statistics by weighted bootstrap iteration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The role played by the composite analogue of the log likelihood ratio in\nhypothesis testing and in setting confidence regions is not as prominent as it\nis in the canonical likelihood setting, since its asymptotic distribution\ndepends on the unknown parameter. Approximate pivots based on the composite log\nlikelihood ratio can be derived by using asymptotic arguments. However, the\nactual distribution of such pivots may differ considerably from the asymptotic\nreference, leading to tests and confidence regions whose levels are distant\nfrom the nominal ones. The use of bootstrap rather than asymptotic\ndistributions in the composite likelihood framework is explored. Prepivoted\ntests and confidence sets based on a suitable statistic turn out to be accurate\nand computationally appealing inferential tools.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2013 19:16:38 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Lunardon", "Nicola", ""]]}, {"id": "1301.7161", "submitter": "Richard Lockhart", "authors": "Richard Lockhart, Jonathan Taylor, Ryan J. Tibshirani, Robert\n  Tibshirani", "title": "A significance test for the lasso", "comments": "Published in at http://dx.doi.org/10.1214/13-AOS1175 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2014, Vol. 42, No. 2, 413-468", "doi": "10.1214/13-AOS1175", "report-no": "IMS-AOS-AOS1175", "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the sparse linear regression setting, we consider testing the significance\nof the predictor variable that enters the current lasso model, in the sequence\nof models visited along the lasso solution path. We propose a simple test\nstatistic based on lasso fitted values, called the covariance test statistic,\nand show that when the true model is linear, this statistic has an\n$\\operatorname {Exp}(1)$ asymptotic distribution under the null hypothesis (the\nnull being that all truly active variables are contained in the current lasso\nmodel). Our proof of this result for the special case of the first predictor to\nenter the model (i.e., testing for a single significant predictor variable\nagainst the global null) requires only weak assumptions on the predictor matrix\n$X$. On the other hand, our proof for a general step in the lasso path places\nfurther technical assumptions on $X$ and the generative model, but still allows\nfor the important high-dimensional case $p>n$, and does not necessarily require\nthat the current lasso model achieves perfect recovery of the truly active\nvariables. Of course, for testing the significance of an additional variable\nbetween two nested linear models, one typically uses the chi-squared test,\ncomparing the drop in residual sum of squares (RSS) to a $\\chi^2_1$\ndistribution. But when this additional variable is not fixed, and has been\nchosen adaptively or greedily, this test is no longer appropriate: adaptivity\nmakes the drop in RSS stochastically much larger than $\\chi^2_1$ under the null\nhypothesis. Our analysis explicitly accounts for adaptivity, as it must, since\nthe lasso builds an adaptive sequence of linear models as the tuning parameter\n$\\lambda$ decreases. In this analysis, shrinkage plays a key role: though\nadditional variables are chosen adaptively, the coefficients of lasso active\nvariables are shrunken due to the $\\ell_1$ penalty. Therefore, the test\nstatistic (which is based on lasso fitted values) is in a sense balanced by\nthese two opposing properties - adaptivity and shrinkage - and its null\ndistribution is tractable and asymptotically $\\operatorname {Exp}(1)$.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2013 08:35:55 GMT"}, {"version": "v2", "created": "Sun, 3 Mar 2013 21:07:34 GMT"}, {"version": "v3", "created": "Mon, 26 May 2014 05:22:25 GMT"}], "update_date": "2014-05-27", "authors_parsed": [["Lockhart", "Richard", ""], ["Taylor", "Jonathan", ""], ["Tibshirani", "Ryan J.", ""], ["Tibshirani", "Robert", ""]]}, {"id": "1301.7196", "submitter": "Vydas \\v{C}ekanavi\\v{c}ius", "authors": "V. \\v{C}ekanavi\\v{c}ius, P. Vellaisamy", "title": "Discrete approximations for sums of m-dependent random variables", "comments": "Revised and shortened version", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sums of of 1-dependent integer-valued random variables are approximated by\ncompound Poisson, negative binomial and Binomial distributions and signed\ncompound Poisson measures. Estimates are obtained for total variation and local\nmetrics. The results are then applied to statistics of $m$-dependent\n$(k_1,k_2)$ events and 2-runs. Heinrich's method and smoothing properties of\nconvolutions are used for the proofs.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2013 11:04:01 GMT"}, {"version": "v2", "created": "Fri, 25 Oct 2013 13:41:25 GMT"}, {"version": "v3", "created": "Wed, 4 Nov 2015 08:42:48 GMT"}], "update_date": "2015-11-05", "authors_parsed": [["\u010cekanavi\u010dius", "V.", ""], ["Vellaisamy", "P.", ""]]}, {"id": "1301.7212", "submitter": "Hannes Sieling", "authors": "Klaus Frick, Axel Munk and Hannes Sieling", "title": "Multiscale Change-Point Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new estimator SMUCE (simultaneous multiscale change-point\nestimator) for the change-point problem in exponential family regression. An\nunknown step function is estimated by minimizing the number of change-points\nover the acceptance region of a multiscale test at a level \\alpha. The\nprobability of overestimating the true number of change-points K is controlled\nby the asymptotic null distribution of the multiscale test statistic. Further,\nwe derive exponential bounds for the probability of underestimating K. By\nbalancing these quantities, \\alpha will be chosen such that the probability of\ncorrectly estimating K is maximized. All results are even non-asymptotic for\nthe normal case. Based on the aforementioned bounds, we construct\nasymptotically honest confidence sets for the unknown step function and its\nchange-points. At the same time, we obtain exponential bounds for estimating\nthe change-point locations which for example yield the minimax rate O(1/n) up\nto a log term. Finally, SMUCE asymptotically achieves the optimal detection\nrate of vanishing signals. We illustrate how dynamic programming techniques can\nbe employed for efficient computation of estimators and confidence regions. The\nperformance of the proposed multiscale approach is illustrated by simulations\nand in two cutting-edge applications from genetic engineering and photoemission\nspectroscopy.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2013 13:02:44 GMT"}, {"version": "v2", "created": "Tue, 12 Feb 2013 12:33:50 GMT"}, {"version": "v3", "created": "Mon, 12 Aug 2013 09:36:05 GMT"}], "update_date": "2013-08-13", "authors_parsed": [["Frick", "Klaus", ""], ["Munk", "Axel", ""], ["Sieling", "Hannes", ""]]}, {"id": "1301.7567", "submitter": "Frank van der Meulen", "authors": "Frank van der Meulen, Harry van Zanten", "title": "Consistent nonparametric Bayesian inference for discretely observed\n  scalar diffusions", "comments": "Published in at http://dx.doi.org/10.3150/11-BEJ385 the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2013, Vol. 19, No. 1, 44-63", "doi": "10.3150/11-BEJ385", "report-no": "IMS-BEJ-BEJ385", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study Bayes procedures for the problem of nonparametric drift estimation\nfor one-dimensional, ergodic diffusion models from discrete-time, low-frequency\ndata. We give conditions for posterior consistency and verify these conditions\nfor concrete priors, including priors based on wavelet expansions.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2013 10:02:15 GMT"}], "update_date": "2013-02-01", "authors_parsed": [["van der Meulen", "Frank", ""], ["van Zanten", "Harry", ""]]}, {"id": "1301.7625", "submitter": "Robert Keener", "authors": "Robert Keener", "title": "Improving Brownian approximations for boundary crossing problems", "comments": "Published in at http://dx.doi.org/10.3150/11-BEJ396 the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2013, Vol. 19, No. 1, 137-153", "doi": "10.3150/11-BEJ396", "report-no": "IMS-BEJ-BEJ396", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Donsker's theorem shows that random walks behave like Brownian motion in an\nasymptotic sense. This result can be used to approximate expectations\nassociated with the time and location of a random walk when it first crosses a\nnonlinear boundary. In this paper, correction terms are derived to improve the\naccuracy of these approximations.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2013 14:35:35 GMT"}], "update_date": "2013-02-01", "authors_parsed": [["Keener", "Robert", ""]]}, {"id": "1301.7644", "submitter": "Pierre Alquier", "authors": "P Alquier and K Meziani and G Peyr\\'e", "title": "Adaptive estimation of the density matrix in quantum homodyne tomography\n  with noisy data", "comments": null, "journal-ref": "Inverse Problems, vol. 29(7), pp. 075017, 2013", "doi": "10.1088/0266-5611/29/7/075017", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the framework of noisy quantum homodyne tomography with efficiency\nparameter $1/2 < \\eta \\leq 1$, we propose a novel estimator of a quantum state\nwhose density matrix elements $\\rho_{m,n}$ decrease like $Ce^{-B(m+n)^{r/ 2}}$,\nfor fixed $C\\geq 1$, $B>0$ and $0<r\\leq 2$. On the contrary to previous works,\nwe focus on the case where $r$, $C$ and $B$ are unknown. The procedure\nestimates the matrix coefficients by a projection method on the pattern\nfunctions, and then by soft-thresholding the estimated coefficients.\n  We prove that under the $\\mathbb{L}_2$ -loss our procedure is adaptive\nrate-optimal, in the sense that it achieves the same rate of conversgence as\nthe best possible procedure relying on the knowledge of $(r,B,C)$. Finite\nsample behaviour of our adaptive procedure are explored through numerical\nexperiments.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2013 15:25:51 GMT"}, {"version": "v2", "created": "Thu, 21 Mar 2013 10:23:08 GMT"}], "update_date": "2014-02-11", "authors_parsed": [["Alquier", "P", ""], ["Meziani", "K", ""], ["Peyr\u00e9", "G", ""]]}, {"id": "1301.7745", "submitter": "Justin Kinney", "authors": "Justin B. Kinney, Gurinder S. Atwal", "title": "Equitability, mutual information, and the maximal information\n  coefficient", "comments": null, "journal-ref": null, "doi": "10.1073/pnas.1309933111", "report-no": null, "categories": "q-bio.QM math.ST stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reshef et al. recently proposed a new statistical measure, the \"maximal\ninformation coefficient\" (MIC), for quantifying arbitrary dependencies between\npairs of stochastic quantities. MIC is based on mutual information, a\nfundamental quantity in information theory that is widely understood to serve\nthis need. MIC, however, is not an estimate of mutual information. Indeed, it\nwas claimed that MIC possesses a desirable mathematical property called\n\"equitability\" that mutual information lacks. This was not proven; instead it\nwas argued solely through the analysis of simulated data. Here we show that\nthis claim, in fact, is incorrect. First we offer mathematical proof that no\n(non-trivial) dependence measure satisfies the definition of equitability\nproposed by Reshef et al.. We then propose a self-consistent and more general\ndefinition of equitability that follows naturally from the Data Processing\nInequality. Mutual information satisfies this new definition of equitability\nwhile MIC does not. Finally, we show that the simulation evidence offered by\nReshef et al. was artifactual. We conclude that estimating mutual information\nis not only practical for many real-world applications, but also provides a\nnatural solution to the problem of quantifying associations in large data sets.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2013 20:44:28 GMT"}], "update_date": "2015-06-12", "authors_parsed": [["Kinney", "Justin B.", ""], ["Atwal", "Gurinder S.", ""]]}]