[{"id": "1010.0072", "submitter": "Jean-Yves Audibert", "authors": "Jean-Yves Audibert (INRIA Paris - Rocquencourt), Olivier Catoni (DMA,\n  INRIA Paris - Rocquencourt)", "title": "Linear regression through PAC-Bayesian truncation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of predicting as well as the best linear combination\nof d given functions in least squares regression under L^\\infty constraints on\nthe linear combination. When the input distribution is known, there already\nexists an algorithm having an expected excess risk of order d/n, where n is the\nsize of the training data. Without this strong assumption, standard results\noften contain a multiplicative log(n) factor, complex constants involving the\nconditioning of the Gram matrix of the covariates, kurtosis coefficients or\nsome geometric quantity characterizing the relation between L^2 and\nL^\\infty-balls and require some additional assumptions like exponential moments\nof the output. This work provides a PAC-Bayesian shrinkage procedure with a\nsimple excess risk bound of order d/n holding in expectation and in deviations,\nunder various assumptions. The common surprising factor of these results is\ntheir simplicity and the absence of exponential moment condition on the output\ndistribution while achieving exponential deviations. The risk bounds are\nobtained through a PAC-Bayesian analysis on truncated differences of losses. We\nalso show that these results can be generalized to other strongly convex loss\nfunctions.\n", "versions": [{"version": "v1", "created": "Fri, 1 Oct 2010 06:20:15 GMT"}, {"version": "v2", "created": "Mon, 12 Sep 2011 08:41:38 GMT"}], "update_date": "2011-09-14", "authors_parsed": [["Audibert", "Jean-Yves", "", "INRIA Paris - Rocquencourt"], ["Catoni", "Olivier", "", "DMA,\n  INRIA Paris - Rocquencourt"]]}, {"id": "1010.0074", "submitter": "Jean-Yves Audibert", "authors": "Jean-Yves Audibert, Olivier Catoni", "title": "Robust linear least squares regression", "comments": "Published in at http://dx.doi.org/10.1214/11-AOS918 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org). arXiv admin note: significant text\n  overlap with arXiv:0902.1733", "journal-ref": "Annals of Statistics 2011, Vol. 39, No. 5, 2766-2794", "doi": "10.1214/11-AOS918", "report-no": "IMS-AOS-AOS918", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of robustly predicting as well as the best linear\ncombination of $d$ given functions in least squares regression, and variants of\nthis problem including constraints on the parameters of the linear combination.\nFor the ridge estimator and the ordinary least squares estimator, and their\nvariants, we provide new risk bounds of order $d/n$ without logarithmic factor\nunlike some standard results, where $n$ is the size of the training data. We\nalso provide a new estimator with better deviations in the presence of\nheavy-tailed noise. It is based on truncating differences of losses in a\nmin--max framework and satisfies a $d/n$ risk bound both in expectation and in\ndeviations. The key common surprising factor of these results is the absence of\nexponential moment condition on the output distribution while achieving\nexponential deviations. All risk bounds are obtained through a PAC-Bayesian\nanalysis on truncated differences of losses. Experimental results strongly back\nup our truncated min--max estimator.\n", "versions": [{"version": "v1", "created": "Fri, 1 Oct 2010 06:20:59 GMT"}, {"version": "v2", "created": "Sun, 18 Sep 2011 18:06:15 GMT"}, {"version": "v3", "created": "Thu, 23 Feb 2012 07:55:39 GMT"}], "update_date": "2012-02-24", "authors_parsed": [["Audibert", "Jean-Yves", ""], ["Catoni", "Olivier", ""]]}, {"id": "1010.0311", "submitter": "Pradeep Ravikumar", "authors": "Pradeep Ravikumar, Martin J. Wainwright, John D. Lafferty", "title": "High-dimensional Ising model selection using ${\\ell_1}$-regularized\n  logistic regression", "comments": "Published in at http://dx.doi.org/10.1214/09-AOS691 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2010, Vol. 38, No. 3, 1287-1319", "doi": "10.1214/09-AOS691", "report-no": "IMS-AOS-AOS691", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of estimating the graph associated with a binary\nIsing Markov random field. We describe a method based on $\\ell_1$-regularized\nlogistic regression, in which the neighborhood of any given node is estimated\nby performing logistic regression subject to an $\\ell_1$-constraint. The method\nis analyzed under high-dimensional scaling in which both the number of nodes\n$p$ and maximum neighborhood size $d$ are allowed to grow as a function of the\nnumber of observations $n$. Our main results provide sufficient conditions on\nthe triple $(n,p,d)$ and the model parameters for the method to succeed in\nconsistently estimating the neighborhood of every node in the graph\nsimultaneously. With coherence conditions imposed on the population Fisher\ninformation matrix, we prove that consistent neighborhood selection can be\nobtained for sample sizes $n=\\Omega(d^3\\log p)$ with exponentially decaying\nerror. When these same conditions are imposed directly on the sample matrices,\nwe show that a reduced sample size of $n=\\Omega(d^2\\log p)$ suffices for the\nmethod to estimate neighborhoods consistently. Although this paper focuses on\nthe binary graphical models, we indicate how a generalization of the method of\nthe paper would apply to general discrete Markov random fields.\n", "versions": [{"version": "v1", "created": "Sat, 2 Oct 2010 08:55:02 GMT"}], "update_date": "2010-10-05", "authors_parsed": [["Ravikumar", "Pradeep", ""], ["Wainwright", "Martin J.", ""], ["Lafferty", "John D.", ""]]}, {"id": "1010.0312", "submitter": "Byeong U. Park", "authors": "Byeong U. Park, Seok-Oh Jeong, L\\'eopold Simar", "title": "Asymptotic distribution of conical-hull estimators of directional edges", "comments": "Published in at http://dx.doi.org/10.1214/09-AOS746 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2010, Vol. 38, No. 3, 1320-1340", "doi": "10.1214/09-AOS746", "report-no": "IMS-AOS-AOS746", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonparametric data envelopment analysis (DEA) estimators have been widely\napplied in analysis of productive efficiency. Typically they are defined in\nterms of convex-hulls of the observed combinations of\n$\\mathrm{inputs}\\times\\mathrm{outputs}$ in a sample of enterprises. The shape\nof the convex-hull relies on a hypothesis on the shape of the technology,\ndefined as the boundary of the set of technically attainable points in the\n$\\mathrm{inputs}\\times\\mathrm{outputs}$ space. So far, only the statistical\nproperties of the smallest convex polyhedron enveloping the data points has\nbeen considered which corresponds to a situation where the technology presents\nvariable returns-to-scale (VRS). This paper analyzes the case where the most\ncommon constant returns-to-scale (CRS) hypothesis is assumed. Here the DEA is\ndefined as the smallest conical-hull with vertex at the origin enveloping the\ncloud of observed points. In this paper we determine the asymptotic properties\nof this estimator, showing that the rate of convergence is better than for the\nVRS estimator. We derive also its asymptotic sampling distribution with a\npractical way to simulate it. This allows to define a bias-corrected estimator\nand to build confidence intervals for the frontier. We compare in a simulated\nexample the bias-corrected estimator with the original conical-hull estimator\nand show its superiority in terms of median squared error.\n", "versions": [{"version": "v1", "created": "Sat, 2 Oct 2010 09:01:12 GMT"}], "update_date": "2010-10-05", "authors_parsed": [["Park", "Byeong U.", ""], ["Jeong", "Seok-Oh", ""], ["Simar", "L\u00e9opold", ""]]}, {"id": "1010.0313", "submitter": "Yukun Liu", "authors": "Yukun Liu, Jiahua Chen", "title": "Adjusted empirical likelihood with high-order precision", "comments": "Published in at http://dx.doi.org/10.1214/09-AOS750 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2010, Vol. 38, No. 3, 1341-1362", "doi": "10.1214/09-AOS750", "report-no": "IMS-AOS-AOS750", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Empirical likelihood is a popular nonparametric or semi-parametric\nstatistical method with many nice statistical properties. Yet when the sample\nsize is small, or the dimension of the accompanying estimating function is\nhigh, the application of the empirical likelihood method can be hindered by low\nprecision of the chi-square approximation and by nonexistence of solutions to\nthe estimating equations. In this paper, we show that the adjusted empirical\nlikelihood is effective at addressing both problems. With a specific level of\nadjustment, the adjusted empirical likelihood achieves the high-order precision\nof the Bartlett correction, in addition to the advantage of a guaranteed\nsolution to the estimating equations. Simulation results indicate that the\nconfidence regions constructed by the adjusted empirical likelihood have\ncoverage probabilities comparable to or substantially more accurate than the\noriginal empirical likelihood enhanced by the Bartlett correction.\n", "versions": [{"version": "v1", "created": "Sat, 2 Oct 2010 09:05:54 GMT"}], "update_date": "2010-10-05", "authors_parsed": [["Liu", "Yukun", ""], ["Chen", "Jiahua", ""]]}, {"id": "1010.0320", "submitter": "Jiancheng Jiang", "authors": "Jiancheng Jiang, Yingying Fan, Jianqing Fan", "title": "Estimation in additive models with highly or nonhighly correlated\n  covariates", "comments": "Published in at http://dx.doi.org/10.1214/09-AOS753 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2010, Vol. 38, No. 3, 1403-1432", "doi": "10.1214/09-AOS753", "report-no": "IMS-AOS-AOS753", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by normalizing DNA microarray data and by predicting the interest\nrates, we explore nonparametric estimation of additive models with highly\ncorrelated covariates. We introduce two novel approaches for estimating the\nadditive components, integration estimation and pooled backfitting estimation.\nThe former is designed for highly correlated covariates, and the latter is\nuseful for nonhighly correlated covariates. Asymptotic normalities of the\nproposed estimators are established. Simulations are conducted to demonstrate\nfinite sample behaviors of the proposed estimators, and real data examples are\ngiven to illustrate the value of the methodology.\n", "versions": [{"version": "v1", "created": "Sat, 2 Oct 2010 10:17:27 GMT"}], "update_date": "2010-10-05", "authors_parsed": [["Jiang", "Jiancheng", ""], ["Fan", "Yingying", ""], ["Fan", "Jianqing", ""]]}, {"id": "1010.0324", "submitter": "Jose A. Diaz-Garcia", "authors": "Jose A. Diaz-Garcia and Ramon Gutierrez-Jaimez", "title": "An identity of Jack polynomials", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work it is propose an alterative proof of one of basic properties of\nthe zonal polynomials. This identity is generalised for the Jack polynomials.\n", "versions": [{"version": "v1", "created": "Sat, 2 Oct 2010 11:57:43 GMT"}], "update_date": "2010-10-05", "authors_parsed": [["Diaz-Garcia", "Jose A.", ""], ["Gutierrez-Jaimez", "Ramon", ""]]}, {"id": "1010.0328", "submitter": "C. Devon Lin", "authors": "C. Devon Lin, Derek Bingham, Randy R. Sitter, Boxin Tang", "title": "A new and flexible method for constructing designs for computer\n  experiments", "comments": "Published in at http://dx.doi.org/10.1214/09-AOS757 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2010, Vol. 38, No. 3, 1460-1477", "doi": "10.1214/09-AOS757", "report-no": "IMS-AOS-AOS757", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a new method for constructing \"good\" designs for computer\nexperiments. The method derives its power from its basic structure that builds\nlarge designs using small designs. We specialize the method for the\nconstruction of orthogonal Latin hypercubes and obtain many results along the\nway. In terms of run sizes, the existence problem of orthogonal Latin\nhypercubes is completely solved. We also present an explicit result showing how\nlarge orthogonal Latin hypercubes can be constructed using small orthogonal\nLatin hypercubes. Another appealing feature of our method is that it can easily\nbe adapted to construct other designs; we examine how to make use of the method\nto construct nearly orthogonal and cascading Latin hypercubes.\n", "versions": [{"version": "v1", "created": "Sat, 2 Oct 2010 12:24:36 GMT"}], "update_date": "2010-10-05", "authors_parsed": [["Lin", "C. Devon", ""], ["Bingham", "Derek", ""], ["Sitter", "Randy R.", ""], ["Tang", "Boxin", ""]]}, {"id": "1010.0335", "submitter": "Jean Jacod", "authors": "Jean Jacod, Mark Podolskij, Mathias Vetter", "title": "Limit theorems for moving averages of discretized processes plus noise", "comments": "Published in at http://dx.doi.org/10.1214/09-AOS756 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2010, Vol. 38, No. 3, 1478-1545", "doi": "10.1214/09-AOS756", "report-no": "IMS-AOS-AOS756", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents some limit theorems for certain functionals of moving\naverages of semimartingales plus noise which are observed at high frequency.\nOur method generalizes the pre-averaging approach (see [Bernoulli 15 (2009)\n634--658, Stochastic Process. Appl. 119 (2009) 2249--2276]) and provides\nconsistent estimates for various characteristics of general semimartingales.\nFurthermore, we prove the associated multidimensional (stable) central limit\ntheorems. As expected, we find central limit theorems with a convergence rate\n$n^{-1/4}$, if $n$ is the number of observations.\n", "versions": [{"version": "v1", "created": "Sat, 2 Oct 2010 13:22:39 GMT"}], "update_date": "2010-10-05", "authors_parsed": [["Jacod", "Jean", ""], ["Podolskij", "Mark", ""], ["Vetter", "Mathias", ""]]}, {"id": "1010.0426", "submitter": "Jean-Marc Bardet", "authors": "Jean-Marc Bardet (SAMM), B\\'echir Dola (SAMM)", "title": "Adaptive estimator of the memory parameter and goodness-of-fit test\n  using a multidimensional increment ratio statistic", "comments": "Journal of Multivariate Analysis (2011) 1-24", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increment ratio (IR) statistic was first defined and studied in Surgailis\n{\\it et al.} (2007) for estimating the memory parameter either of a stationary\nor an increment stationary Gaussian process. Here three extensions are proposed\nin the case of stationary processes. Firstly, a multidimensional central limit\ntheorem is established for a vector composed by several IR statistics.\nSecondly, a goodness-of-fit $\\chi^2$-type test can be deduced from this\ntheorem. Finally, this theorem allows to construct adaptive versions of the\nestimator and test which are studied in a general semiparametric frame. The\nadaptive estimator of the long-memory parameter is proved to follow an oracle\nproperty. Simulations attest of the interesting accuracies and robustness of\nthe estimator and test, even in the non Gaussian case.\n", "versions": [{"version": "v1", "created": "Sun, 3 Oct 2010 18:28:11 GMT"}, {"version": "v2", "created": "Thu, 22 Sep 2011 12:47:16 GMT"}], "update_date": "2011-09-26", "authors_parsed": [["Bardet", "Jean-Marc", "", "SAMM"], ["Dola", "B\u00e9chir", "", "SAMM"]]}, {"id": "1010.0427", "submitter": "Jeremie Bigot", "authors": "J\\'er\\'emie Bigot (IMT), Benjamin Charlier (IMT)", "title": "On the consistency of Fr\\'echet means in deformable models for curve and\n  image analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new class of statistical deformable models is introduced to study\nhigh-dimensional curves or images. In addition to the standard measurement\nerror term, these deformable models include an extra error term modeling the\nindividual variations in intensity around a mean pattern. It is shown that an\nappropriate tool for statistical inference in such models is the notion of\nsample Fr\\'echet means, which leads to estimators of the deformation parameters\nand the mean pattern. The main contribution of this paper is to study how the\nbehavior of these estimators depends on the number n of design points and the\nnumber J of observed curves (or images). Numerical experiments are given to\nillustrate the finite sample performances of the procedure.\n", "versions": [{"version": "v1", "created": "Sun, 3 Oct 2010 18:29:15 GMT"}, {"version": "v2", "created": "Tue, 15 Mar 2011 13:23:25 GMT"}, {"version": "v3", "created": "Fri, 18 Mar 2011 06:14:59 GMT"}, {"version": "v4", "created": "Mon, 22 Aug 2011 08:31:17 GMT"}], "update_date": "2011-08-24", "authors_parsed": [["Bigot", "J\u00e9r\u00e9mie", "", "IMT"], ["Charlier", "Benjamin", "", "IMT"]]}, {"id": "1010.0439", "submitter": "Rawane Samb", "authors": "Rawane Samb (University Pierre et Marie Curie, LSTA)", "title": "Nonparametric kernel estimation of the probability density function of\n  regression errors using estimated residuals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with the nonparametric density estimation of the regression\nerror term assuming its independence with the covariate. The difference between\nthe feasible estimator which uses the estimated residuals and the unfeasible\none using the true residuals is studied. An optimal choice of the bandwidth\nused to estimate the residuals is given. We also study the asymptotic normality\nof the feasible kernel estimator and its rate-optimality.\n", "versions": [{"version": "v1", "created": "Sun, 3 Oct 2010 19:57:54 GMT"}], "update_date": "2010-10-05", "authors_parsed": [["Samb", "Rawane", "", "University Pierre et Marie Curie, LSTA"]]}, {"id": "1010.0483", "submitter": "Tigran Markaryan", "authors": "Tigran Markaryan, William F. Rosenberger", "title": "Exact properties of Efron's biased coin randomization procedure", "comments": "Published in at http://dx.doi.org/10.1214/09-AOS758 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2010, Vol. 38, No. 3, 1546-1567", "doi": "10.1214/09-AOS758", "report-no": "IMS-AOS-AOS758", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efron [Biometrika 58 (1971) 403--417] developed a restricted randomization\nprocedure to promote balance between two treatment groups in a sequential\nclinical trial. He called this the biased coin design. He also introduced the\nconcept of accidental bias, and investigated properties of the procedure with\nrespect to both accidental and selection bias, balance, and randomization-based\ninference using the steady-state properties of the induced Markov chain. In\nthis paper we revisit this procedure, and derive closed-form expressions for\nthe exact properties of the measures derived asymptotically in Efron's paper.\nIn particular, we derive the exact distribution of the treatment imbalance and\nthe variance-covariance matrix of the treatment assignments. These results have\napplication in the design and analysis of clinical trials, by providing exact\nformulas to determine the role of the coin's bias probability in the context of\nselection and accidental bias, balancing properties and randomization-based\ninference.\n", "versions": [{"version": "v1", "created": "Mon, 4 Oct 2010 07:04:39 GMT"}], "update_date": "2010-10-05", "authors_parsed": [["Markaryan", "Tigran", ""], ["Rosenberger", "William F.", ""]]}, {"id": "1010.0490", "submitter": "Wing H. Wong", "authors": "Wing H. Wong, Li Ma", "title": "Optional P\\'{o}lya tree and Bayesian inference", "comments": "Published in at http://dx.doi.org/10.1214/09-AOS755 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2010, Vol. 38, No. 3, 1433-1459", "doi": "10.1214/09-AOS755", "report-no": "IMS-AOS-AOS755", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an extension of the P\\'olya tree approach for constructing\ndistributions on the space of probability measures. By using optional stopping\nand optional choice of splitting variables, the construction gives rise to\nrandom measures that are absolutely continuous with piecewise smooth densities\non partitions that can adapt to fit the data. The resulting \"optional P\\'{o}lya\ntree\" distribution has large support in total variation topology and yields\nposterior distributions that are also optional P\\'{o}lya trees with computable\nparameter values.\n", "versions": [{"version": "v1", "created": "Mon, 4 Oct 2010 07:42:46 GMT"}], "update_date": "2010-10-05", "authors_parsed": [["Wong", "Wing H.", ""], ["Ma", "Li", ""]]}, {"id": "1010.0499", "submitter": "G\\'{e}rard Biau", "authors": "G\\'erard Biau, Beno\\^it Cadre, Laurent Rouvi\\`ere", "title": "Statistical analysis of $k$-nearest neighbor collaborative\n  recommendation", "comments": "Published in at http://dx.doi.org/10.1214/09-AOS759 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2010, Vol. 38, No. 3, 1568-1592", "doi": "10.1214/09-AOS759", "report-no": "IMS-AOS-AOS759", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collaborative recommendation is an information-filtering technique that\nattempts to present information items that are likely of interest to an\nInternet user. Traditionally, collaborative systems deal with situations with\ntwo types of variables, users and items. In its most common form, the problem\nis framed as trying to estimate ratings for items that have not yet been\nconsumed by a user. Despite wide-ranging literature, little is known about the\nstatistical properties of recommendation systems. In fact, no clear\nprobabilistic model even exists which would allow us to precisely describe the\nmathematical forces driving collaborative filtering. To provide an initial\ncontribution to this, we propose to set out a general sequential stochastic\nmodel for collaborative recommendation. We offer an in-depth analysis of the\nso-called cosine-type nearest neighbor collaborative method, which is one of\nthe most widely used algorithms in collaborative filtering, and analyze its\nasymptotic performance as the number of users grows. We establish consistency\nof the procedure under mild assumptions on the model. Rates of convergence and\nexamples are also provided.\n", "versions": [{"version": "v1", "created": "Mon, 4 Oct 2010 08:23:54 GMT"}], "update_date": "2010-10-05", "authors_parsed": [["Biau", "G\u00e9rard", ""], ["Cadre", "Beno\u00eet", ""], ["Rouvi\u00e8re", "Laurent", ""]]}, {"id": "1010.0514", "submitter": "Yijian Huang", "authors": "Yijian Huang", "title": "Quantile calculus and censored regression", "comments": "Published in at http://dx.doi.org/10.1214/09-AOS771 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2010, Vol. 38, No. 3, 1607-1637", "doi": "10.1214/09-AOS771", "report-no": "IMS-AOS-AOS771", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantile regression has been advocated in survival analysis to assess\nevolving covariate effects. However, challenges arise when the censoring time\nis not always observed and may be covariate-dependent, particularly in the\npresence of continuously-distributed covariates. In spite of several recent\nadvances, existing methods either involve algorithmic complications or impose a\nprobability grid. The former leads to difficulties in the implementation and\nasymptotics, whereas the latter introduces undesirable grid dependence. To\nresolve these issues, we develop fundamental and general quantile calculus on\ncumulative probability scale in this article, upon recognizing that probability\nand time scales do not always have a one-to-one mapping given a survival\ndistribution. These results give rise to a novel estimation procedure for\ncensored quantile regression, based on estimating integral equations. A\nnumerically reliable and efficient Progressive Localized Minimization (PLMIN)\nalgorithm is proposed for the computation. This procedure reduces exactly to\nthe Kaplan--Meier method in the $k$-sample problem, and to standard uncensored\nquantile regression in the absence of censoring. Under regularity conditions,\nthe proposed quantile coefficient estimator is uniformly consistent and\nconverges weakly to a Gaussian process. Simulations show good statistical and\nalgorithmic performance. The proposal is illustrated in the application to a\nclinical study.\n", "versions": [{"version": "v1", "created": "Mon, 4 Oct 2010 09:24:59 GMT"}], "update_date": "2010-10-05", "authors_parsed": [["Huang", "Yijian", ""]]}, {"id": "1010.0520", "submitter": "Richard A. Olshen", "authors": "Richard A. Olshen, Bala Rajaratnam", "title": "Successive normalization of rectangular arrays", "comments": "Published in at http://dx.doi.org/10.1214/09-AOS743 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org). With Corrections", "journal-ref": "Annals of Statistics 2010, Vol. 38, No. 3, 1638-1664", "doi": "10.1214/09-AOS743", "report-no": "IMS-AOS-AOS743", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard statistical techniques often require transforming data to have mean\n$0$ and standard deviation $1$. Typically, this process of \"standardization\" or\n\"normalization\" is applied across subjects when each subject produces a single\nnumber. High throughput genomic and financial data often come as rectangular\narrays where each coordinate in one direction concerns subjects who might have\ndifferent status (case or control, say), and each coordinate in the other\ndesignates \"outcome\" for a specific feature, for example, \"gene,\" \"polymorphic\nsite\" or some aspect of financial profile. It may happen, when analyzing data\nthat arrive as a rectangular array, that one requires BOTH the subjects and the\nfeatures to be \"on the same footing.\" Thus there may be a need to standardize\nacross rows and columns of the rectangular matrix. There arises the question as\nto how to achieve this double normalization. We propose and investigate the\nconvergence of what seems to us a natural approach to successive normalization\nwhich we learned from our colleague Bradley Efron. We also study the\nimplementation of the method on simulated data and also on data that arose from\nscientific experimentation.\n", "versions": [{"version": "v1", "created": "Mon, 4 Oct 2010 09:48:16 GMT"}, {"version": "v2", "created": "Wed, 11 Dec 2013 12:51:40 GMT"}], "update_date": "2013-12-12", "authors_parsed": [["Olshen", "Richard A.", ""], ["Rajaratnam", "Bala", ""]]}, {"id": "1010.0581", "submitter": "Andriy Norets", "authors": "Andriy Norets", "title": "Approximation of conditional densities by smooth mixtures of regressions", "comments": "Published in at http://dx.doi.org/10.1214/09-AOS765 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2010, Vol. 38, No. 3, 1733-1766", "doi": "10.1214/09-AOS765", "report-no": "IMS-AOS-AOS765", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper shows that large nonparametric classes of conditional multivariate\ndensities can be approximated in the Kullback--Leibler distance by different\nspecifications of finite mixtures of normal regressions in which normal means\nand variances and mixing probabilities can depend on variables in the\nconditioning set (covariates). These models are a special case of models known\nas \"mixtures of experts\" in statistics and computer science literature.\nFlexible specifications include models in which only mixing probabilities,\nmodeled by multinomial logit, depend on the covariates and, in the univariate\ncase, models in which only means of the mixed normals depend flexibly on the\ncovariates. Modeling the variance of the mixed normals by flexible functions of\nthe covariates can weaken restrictions on the class of the approximable\ndensities. Obtained results can be generalized to mixtures of general location\nscale densities. Rates of convergence and easy to interpret bounds are also\nobtained for different model specifications. These approximation results can be\nuseful for proving consistency of Bayesian and maximum likelihood density\nestimators based on these models. The results also have interesting\nimplications for applied researchers.\n", "versions": [{"version": "v1", "created": "Mon, 4 Oct 2010 13:31:44 GMT"}], "update_date": "2010-10-05", "authors_parsed": [["Norets", "Andriy", ""]]}, {"id": "1010.0591", "submitter": "R. J. Samworth", "authors": "R. J. Samworth, M. P. Wand", "title": "Asymptotics and optimal bandwidth selection for highest density region\n  estimation", "comments": "Published in at http://dx.doi.org/10.1214/09-AOS766 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2010, Vol. 38, No. 3, 1767-1792", "doi": "10.1214/09-AOS766", "report-no": "IMS-AOS-AOS766", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study kernel estimation of highest-density regions (HDR). Our main\ncontributions are two-fold. First, we derive a uniform-in-bandwidth asymptotic\napproximation to a risk that is appropriate for HDR estimation. This\napproximation is then used to derive a bandwidth selection rule for HDR\nestimation possessing attractive asymptotic properties. We also present the\nresults of numerical studies that illustrate the benefits of our theory and\nmethodology.\n", "versions": [{"version": "v1", "created": "Mon, 4 Oct 2010 13:57:33 GMT"}], "update_date": "2010-10-05", "authors_parsed": [["Samworth", "R. J.", ""], ["Wand", "M. P.", ""]]}, {"id": "1010.0601", "submitter": "Gabriel Tucci", "authors": "Thomas L. Marzetta, Gabriel H. Tucci and Steven H. Simon", "title": "A Random Matrix--Theoretic Approach to Handling Singular Covariance\n  Estimates", "comments": "Submitted to Transactions on Information Theory", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.IT math.IT math.ST physics.data-an stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many practical situations we would like to estimate the covariance matrix\nof a set of variables from an insufficient amount of data. More specifically,\nif we have a set of $N$ independent, identically distributed measurements of an\n$M$ dimensional random vector the maximum likelihood estimate is the sample\ncovariance matrix. Here we consider the case where $N<M$ such that this\nestimate is singular and therefore fundamentally bad. We present a radically\nnew approach to deal with this situation. Let $X$ be the $M\\times N$ data\nmatrix, where the columns are the $N$ independent realizations of the random\nvector with covariance matrix $\\Sigma$. Without loss of generality, we can\nassume that the random variables have zero mean. We would like to estimate\n$\\Sigma$ from $X$. Let $K$ be the classical sample covariance matrix. Fix a\nparameter $1\\leq L\\leq N$ and consider an ensemble of $L\\times M$ random\nunitary matrices, $\\{\\Phi\\}$, having Haar probability measure. Pre and post\nmultiply $K$ by $\\Phi$, and by the conjugate transpose of $\\Phi$ respectively,\nto produce a non--singular $L\\times L$ reduced dimension covariance estimate. A\nnew estimate for $\\Sigma$, denoted by $\\mathrm{cov}_L(K)$, is obtained by a)\nprojecting the reduced covariance estimate out (to $M\\times M$) through pre and\npost multiplication by the conjugate transpose of $\\Phi$, and by $\\Phi$\nrespectively, and b) taking the expectation over the unitary ensemble. Another\nnew estimate (this time for $\\Sigma^{-1}$), $\\mathrm{invcov}_L(K)$, is obtained\nby a) inverting the reduced covariance estimate, b) projecting the inverse out\n(to $M\\times M$) through pre and post multiplication by the conjugate transpose\nof $\\Phi$, and by $\\Phi$ respectively, and c) taking the expectation over the\nunitary ensemble. We have a closed analytical expression for\n$\\mathrm{invcov}_L(K)$ and $\\mathrm{cov}_L(K)$ in terms of its eigenvalue\ndecomposition.\n", "versions": [{"version": "v1", "created": "Mon, 4 Oct 2010 14:25:59 GMT"}], "update_date": "2010-10-05", "authors_parsed": [["Marzetta", "Thomas L.", ""], ["Tucci", "Gabriel H.", ""], ["Simon", "Steven H.", ""]]}, {"id": "1010.0602", "submitter": "S. Satheesh", "authors": "S Satheesh and E Sandhya", "title": "A further generalization of random self-decomposability", "comments": "7 pages, submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The notion of random self-decomposability is generalized further. The notion\nis then extended to non-negative integer-valued distributions.\n", "versions": [{"version": "v1", "created": "Mon, 4 Oct 2010 14:30:23 GMT"}], "update_date": "2010-10-05", "authors_parsed": [["Satheesh", "S", ""], ["Sandhya", "E", ""]]}, {"id": "1010.0694", "submitter": "David R. Bickel", "authors": "David R. Bickel", "title": "Statistical inference optimized with respect to the observed sample for\n  single or multiple comparisons", "comments": "Typo in equation (7) of v2 corrected in equation (6) of v3; clarity\n  improved", "journal-ref": "Bickel, D. R. (2011). A predictive approach to measuring the\n  strength of statistical evidence for single and multiple comparisons.\n  Canadian Journal of Statistics, 39, 610-631", "doi": "10.1002/cjs.10109", "report-no": null, "categories": "math.ST cs.IT math.IT q-bio.BM stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The normalized maximum likelihood (NML) is a recent penalized likelihood that\nhas properties that justify defining the amount of discrimination information\n(DI) in the data supporting an alternative hypothesis over a null hypothesis as\nthe logarithm of an NML ratio, namely, the alternative hypothesis NML divided\nby the null hypothesis NML. The resulting DI, like the Bayes factor but unlike\nthe p-value, measures the strength of evidence for an alternative hypothesis\nover a null hypothesis such that the probability of misleading evidence\nvanishes asymptotically under weak regularity conditions and such that evidence\ncan support a simple null hypothesis. Unlike the Bayes factor, the DI does not\nrequire a prior distribution and is minimax optimal in a sense that does not\ninvolve averaging over outcomes that did not occur. Replacing a (possibly\npseudo-) likelihood function with its weighted counterpart extends the scope of\nthe DI to models for which the unweighted NML is undefined. The likelihood\nweights leverage side information, either in data associated with comparisons\nother than the comparison at hand or in the parameter value of a simple null\nhypothesis. Two case studies, one involving multiple populations and the other\ninvolving multiple biological features, indicate that the DI is robust to the\ntype of side information used when that information is assigned the weight of a\nsingle observation. Such robustness suggests that very little adjustment for\nmultiple comparisons is warranted if the sample size is at least moderate.\n", "versions": [{"version": "v1", "created": "Mon, 4 Oct 2010 20:21:49 GMT"}, {"version": "v2", "created": "Wed, 6 Oct 2010 21:46:59 GMT"}, {"version": "v3", "created": "Tue, 2 Nov 2010 10:33:12 GMT"}], "update_date": "2012-05-02", "authors_parsed": [["Bickel", "David R.", ""]]}, {"id": "1010.0745", "submitter": "Alessandro Rinaldo", "authors": "A. Rinaldo, S. Petrovi\\'c and S. E. Fienberg", "title": "On the Existence of the MLE for a Directed Random Graph Network Model\n  with Reciprocation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Holland and Leinhardt (1981) proposed a directed random graph model, the p1\nmodel, to describe dyadic interactions in a social network. In previous work\n(Petrovic et al., 2010), we studied the algebraic properties of the p1 model\nand showed that it is a toric model specified by a multi-homogeneous ideal. We\nconducted an extensive study of the Markov bases for p1 that incorporate\nexplicitly the constraint arising from multi-homogeneity. Here we consider the\nproperties of the corresponding toric variety and relate them to the conditions\nfor the existence of the maximum likelihood and extended maximum likelihood\nestimators or the model parameters. Our results are directly relevant to the\nestimation and conditional goodness-of-fit testing problems in p1 models.\n", "versions": [{"version": "v1", "created": "Tue, 5 Oct 2010 01:11:02 GMT"}], "update_date": "2010-10-06", "authors_parsed": [["Rinaldo", "A.", ""], ["Petrovi\u0107", "S.", ""], ["Fienberg", "S. E.", ""]]}, {"id": "1010.0792", "submitter": "Siegfried H\\\"{o}rmann", "authors": "Siegfried H\\\"ormann, Piotr Kokoszka", "title": "Weakly dependent functional data", "comments": "Published in at http://dx.doi.org/10.1214/09-AOS768 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2010, Vol. 38, No. 3, 1845-1884", "doi": "10.1214/09-AOS768", "report-no": "IMS-AOS-AOS768", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Functional data often arise from measurements on fine time grids and are\nobtained by separating an almost continuous time record into natural\nconsecutive intervals, for example, days. The functions thus obtained form a\nfunctional time series, and the central issue in the analysis of such data\nconsists in taking into account the temporal dependence of these functional\nobservations. Examples include daily curves of financial transaction data and\ndaily patterns of geophysical and environmental data. For scalar and vector\nvalued stochastic processes, a large number of dependence notions have been\nproposed, mostly involving mixing type distances between $\\sigma$-algebras. In\ntime series analysis, measures of dependence based on moments have proven most\nuseful (autocovariances and cumulants). We introduce a moment-based notion of\ndependence for functional time series which involves $m$-dependence. We show\nthat it is applicable to linear as well as nonlinear functional time series.\nThen we investigate the impact of dependence thus quantified on several\nimportant statistical procedures for functional data. We study the estimation\nof the functional principal components, the long-run covariance matrix, change\npoint detection and the functional linear model. We explain when temporal\ndependence affects the results obtained for i.i.d. functional observations and\nwhen these results are robust to weak dependence.\n", "versions": [{"version": "v1", "created": "Tue, 5 Oct 2010 08:08:17 GMT"}], "update_date": "2016-08-14", "authors_parsed": [["H\u00f6rmann", "Siegfried", ""], ["Kokoszka", "Piotr", ""]]}, {"id": "1010.0796", "submitter": "Myriam Vimond", "authors": "Myriam Vimond", "title": "Efficient estimation for a subclass of shape invariant models", "comments": "Published in at http://dx.doi.org/10.1214/07-AOS566 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2010, Vol. 38, No. 3, 1885-1912", "doi": "10.1214/07-AOS566", "report-no": "IMS-AOS-AOS566", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we observe a fixed number of unknown $2\\pi$-periodic functions\ndiffering from each other by both phases and amplitude. This semiparametric\nmodel appears in literature under the name \"shape invariant model.\" While the\ncommon shape is unknown, we introduce an asymptotically efficient estimator of\nthe finite-dimensional parameter (phases and amplitude) using the profile\nlikelihood and the Fourier basis. Moreover, this estimation method leads to a\nconsistent and asymptotically linear estimator for the common shape.\n", "versions": [{"version": "v1", "created": "Tue, 5 Oct 2010 08:33:16 GMT"}], "update_date": "2010-10-06", "authors_parsed": [["Vimond", "Myriam", ""]]}, {"id": "1010.0959", "submitter": "Anatoly Gordinsky", "authors": "Anatoly Gordinsky", "title": "Quasi-estimation as a Basis for Two-stage Solving of Regression Problem", "comments": "18 pages,6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An effective two-stage method for an estimation of parameters of the linear\nregression is considered. For this purpose we introduce a certain\nquasi-estimator that, in contrast to usual estimator, produces two alternative\nestimates. It is proved that, in comparison to the least squares estimate, one\nalternative has a significantly smaller quadratic risk, retaining at the same\ntime unbiasedness and consistency. These properties hold true for\none-dimensional, multi-dimensional, orthogonal and non-orthogonal problems.\nMoreover, a Monte-Carlo simulation confirms high robustness of the\nquasi-estimator to violations of the initial assumptions. Therefore, at the\nfirst stage of the estimation we calculate mentioned two alternative estimates.\nAt the second stage we choose the better estimate out of these alternatives. In\norder to do so we use additional information, among it but not exclusively of a\npriori nature. In case of two alternatives the volume of such information\nshould be minimal. Furthermore, the additional information is not built-in into\nthe quasi-estimator structure, so that any kind of information, even intuitive\none, can be used. These features, in combination with decrease of the quadratic\nrisk, provide a great advantage of our method. A variety of types of the\nadditional information for choosing the better estimate is considered. One\nexample is the successful processing of the famous experiment conducted by\nastronomers in 1919 to verify the General The-ory of Relativity of A. Einstein.\n", "versions": [{"version": "v1", "created": "Tue, 5 Oct 2010 17:59:22 GMT"}], "update_date": "2010-10-06", "authors_parsed": [["Gordinsky", "Anatoly", ""]]}, {"id": "1010.1049", "submitter": "Yuao Hu", "authors": "Yuao Hu", "title": "On the Convergence of Bayesian Regression Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider heteroscedastic nonparametric regression models, when both the\nmean function and variance function are unknown and to be estimated with\nnonparametric approaches. We derive convergence rates of posterior\ndistributions for this model with different priors, including splines and\nGaussian process priors. The results are based on the general ones on the rates\nof convergence of posterior distributions for independent, non-identically\ndistributed observations, and are established for both of the cases with random\ncovariates, and deterministic covariates. We also illustrate that the results\ncan be achieved for all levels of regularity, which means they are adaptive.\n", "versions": [{"version": "v1", "created": "Wed, 6 Oct 2010 02:24:13 GMT"}], "update_date": "2010-10-07", "authors_parsed": [["Hu", "Yuao", ""]]}, {"id": "1010.1445", "submitter": "Nicolas Verzelen", "authors": "Nicolas Verzelen (MISTEA)", "title": "Adaptive estimation of covariance matrices via Cholesky decomposition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the estimation of a large covariance matrix. We introduce\na novel procedure called ChoSelect based on the Cholesky factor of the inverse\ncovariance. This method uses a dimension reduction strategy by selecting the\npattern of zero of the Cholesky factor. Alternatively, ChoSelect can be\ninterpreted as a graph estimation procedure for directed Gaussian graphical\nmodels. Our approach is particularly relevant when the variables under study\nhave a natural ordering (e.g. time series) or more generally when the Cholesky\nfactor is approximately sparse. ChoSelect achieves non-asymptotic oracle\ninequalities with respect to the Kullback-Leibler entropy. Moreover, it\nsatisfies various adaptive properties from a minimax point of view. We also\nintroduce and study a two-stage procedure that combines ChoSelect with the\nLasso. This last method enables the practitioner to choose his own trade-off\nbetween statistical efficiency and computational complexity. Moreover, it is\nconsistent under weaker assumptions than the Lasso. The practical performances\nof the different procedures are assessed on numerical examples.\n", "versions": [{"version": "v1", "created": "Thu, 7 Oct 2010 14:39:40 GMT"}, {"version": "v2", "created": "Fri, 8 Oct 2010 11:31:51 GMT"}], "update_date": "2010-10-13", "authors_parsed": [["Verzelen", "Nicolas", "", "MISTEA"]]}, {"id": "1010.1601", "submitter": "Jeremie Bigot", "authors": "J\\'er\\'emie Bigot (IMT), Rolando Biscay (IMFAV-DEUV), Jean-Michel\n  Loubes (IMT), Lilian Muniz Alvarez (IMT)", "title": "Group Lasso estimation of high-dimensional covariance matrices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the Group Lasso estimator of the covariance matrix\nof a stochastic process corrupted by an additive noise. We propose to estimate\nthe covariance matrix in a high-dimensional setting under the assumption that\nthe process has a sparse representation in a large dictionary of basis\nfunctions. Using a matrix regression model, we propose a new methodology for\nhigh-dimensional covariance matrix estimation based on empirical contrast\nregularization by a group Lasso penalty. Using such a penalty, the method\nselects a sparse set of basis functions in the dictionary used to approximate\nthe process, leading to an approximation of the covariance matrix into a low\ndimensional space. Consistency of the estimator is studied in Frobenius and\noperator norms and an application to sparse PCA is proposed.\n", "versions": [{"version": "v1", "created": "Fri, 8 Oct 2010 06:06:49 GMT"}, {"version": "v2", "created": "Mon, 24 Oct 2011 09:35:27 GMT"}], "update_date": "2011-10-26", "authors_parsed": [["Bigot", "J\u00e9r\u00e9mie", "", "IMT"], ["Biscay", "Rolando", "", "IMFAV-DEUV"], ["Loubes", "Jean-Michel", "", "IMT"], ["Alvarez", "Lilian Muniz", "", "IMT"]]}, {"id": "1010.1625", "submitter": "Michael V. Boutsikas", "authors": "Michael V. Boutsikas, Eutichia Vaggelatou", "title": "A new method for obtaining sharp compound Poisson approximation error\n  estimates for sums of locally dependent random variables", "comments": "Published in at http://dx.doi.org/10.3150/09-BEJ201 the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2010, Vol. 16, No. 2, 301-330", "doi": "10.3150/09-BEJ201", "report-no": "IMS-BEJ-BEJ201", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $X_1,X_2,...,X_n$ be a sequence of independent or locally dependent\nrandom variables taking values in $\\mathbb{Z}_+$. In this paper, we derive\nsharp bounds, via a new probabilistic method, for the total variation distance\nbetween the distribution of the sum $\\sum_{i=1}^nX_i$ and an appropriate\nPoisson or compound Poisson distribution. These bounds include a factor which\ndepends on the smoothness of the approximating Poisson or compound Poisson\ndistribution. This \"smoothness factor\" is of order $\\mathrm{O}(\\sigma ^{-2})$,\naccording to a heuristic argument, where $\\sigma ^2$ denotes the variance of\nthe approximating distribution. In this way, we offer sharp error estimates for\na large range of values of the parameters. Finally, specific examples\nconcerning appearances of rare runs in sequences of Bernoulli trials are\npresented by way of illustration.\n", "versions": [{"version": "v1", "created": "Fri, 8 Oct 2010 08:29:25 GMT"}], "update_date": "2010-10-11", "authors_parsed": [["Boutsikas", "Michael V.", ""], ["Vaggelatou", "Eutichia", ""]]}, {"id": "1010.1639", "submitter": "Lancelot F. James", "authors": "Lancelot F. James", "title": "Dirichlet mean identities and laws of a class of subordinators", "comments": "Published in at http://dx.doi.org/10.3150/09-BEJ224 the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2010, Vol. 16, No. 2, 361-388", "doi": "10.3150/09-BEJ224", "report-no": "IMS-BEJ-BEJ224", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An interesting line of research is the investigation of the laws of random\nvariables known as Dirichlet means. However, there is not much information on\ninterrelationships between different Dirichlet means. Here, we introduce two\ndistributional operations, one of which consists of multiplying a mean\nfunctional by an independent beta random variable, the other being an operation\ninvolving an exponential change of measure. These operations identify\nrelationships between different means and their densities. This allows one to\nuse the often considerable analytic work on obtaining results for one Dirichlet\nmean to obtain results for an entire family of otherwise seemingly unrelated\nDirichlet means. Additionally, it allows one to obtain explicit densities for\nthe related class of random variables that have generalized gamma convolution\ndistributions and the finite-dimensional distribution of their associated\nL\\'{e}vy processes. The importance of this latter statement is that L\\'{e}vy\nprocesses now commonly appear in a variety of applications in probability and\nstatistics, but there are relatively few cases where the relevant densities\nhave been described explicitly. We demonstrate how the technique allows one to\nobtain the finite-dimensional distribution of several interesting subordinators\nwhich have recently appeared in the literature.\n", "versions": [{"version": "v1", "created": "Fri, 8 Oct 2010 09:50:33 GMT"}], "update_date": "2010-10-11", "authors_parsed": [["James", "Lancelot F.", ""]]}, {"id": "1010.1666", "submitter": "Christian Bender", "authors": "Christian Bender, Peter Parczewski", "title": "Approximating a geometric fractional Brownian motion and related\n  processes via discrete Wick calculus", "comments": "Published in at http://dx.doi.org/10.3150/09-BEJ223 the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2010, Vol. 16, No. 2, 389-417", "doi": "10.3150/09-BEJ223", "report-no": "IMS-BEJ-BEJ223", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We approximate the solution of some linear systems of SDEs driven by a\nfractional Brownian motion $B^H$ with Hurst parameter $H\\in(\\frac{1}{2},1)$ in\nthe Wick--It\\^{o} sense, including a geometric fractional Brownian motion. To\nthis end, we apply a Donsker-type approximation of the fractional Brownian\nmotion by disturbed binary random walks due to Sottinen. Moreover, we replace\nthe rather complicated Wick products by their discrete counterpart, acting on\nthe binary variables, in the corresponding systems of Wick difference\nequations. As the solutions of the SDEs admit series representations in terms\nof Wick powers, a key to the proof of our Euler scheme is an approximation of\nthe Hermite recursion formula for the Wick powers of $B^H$.\n", "versions": [{"version": "v1", "created": "Fri, 8 Oct 2010 11:34:30 GMT"}], "update_date": "2010-10-11", "authors_parsed": [["Bender", "Christian", ""], ["Parczewski", "Peter", ""]]}, {"id": "1010.1672", "submitter": "Peter Hall", "authors": "Peter Hall, Qiying Wang", "title": "Strong approximations of level exceedences related to multiple\n  hypothesis testing", "comments": "Published in at http://dx.doi.org/10.3150/09-BEJ220 the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2010, Vol. 16, No. 2, 418-434", "doi": "10.3150/09-BEJ220", "report-no": "IMS-BEJ-BEJ220", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Particularly in genomics, but also in other fields, it has become commonplace\nto undertake highly multiple Student's $t$-tests based on relatively small\nsample sizes. The literature on this topic is continually expanding, but the\nmain approaches used to control the family-wise error rate and false discovery\nrate are still based on the assumption that the tests are independent. The\nindependence condition is known to be false at the level of the joint\ndistributions of the test statistics, but that does not necessarily mean, for\nthe small significance levels involved in highly multiple hypothesis testing,\nthat the assumption leads to major errors. In this paper, we give conditions\nunder which the assumption of independence is valid. Specifically, we derive a\nstrong approximation that closely links the level exceedences of a dependent\n``studentized process'' to those of a process of independent random variables.\nVia this connection, it can be seen that in high-dimensional, low sample-size\ncases, provided the sample size diverges faster than the logarithm of the\nnumber of tests, the assumption of independent $t$-tests is often justified.\n", "versions": [{"version": "v1", "created": "Fri, 8 Oct 2010 11:52:49 GMT"}], "update_date": "2010-10-11", "authors_parsed": [["Hall", "Peter", ""], ["Wang", "Qiying", ""]]}, {"id": "1010.1688", "submitter": "Gareth O. Roberts", "authors": "Gareth O. Roberts, Laura M. Sangalli", "title": "Latent diffusion models for survival analysis", "comments": "Published in at http://dx.doi.org/10.3150/09-BEJ217 the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2010, Vol. 16, No. 2, 435-458", "doi": "10.3150/09-BEJ217", "report-no": "IMS-BEJ-BEJ217", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider Bayesian hierarchical models for survival analysis, where the\nsurvival times are modeled through an underlying diffusion process which\ndetermines the hazard rate. We show how these models can be efficiently treated\nby means of Markov chain Monte Carlo techniques.\n", "versions": [{"version": "v1", "created": "Fri, 8 Oct 2010 13:39:32 GMT"}], "update_date": "2010-10-11", "authors_parsed": [["Roberts", "Gareth O.", ""], ["Sangalli", "Laura M.", ""]]}, {"id": "1010.1799", "submitter": "Jose A. Diaz-Garcia", "authors": "Jose A. Diaz-Garcia and Ramon Gutierrez-Jaimez", "title": "On Wishart distribution", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a unified approach that enables the Wishart distribution\nto be studied simultaneously in the real, complex, quaternion and octonion\ncases. In particular, the noncentral generalised Wishart distribution, the\njoint density of the eigenvalues and the distribution of the maximum eigenvalue\nare obtained for real normed division algebras.\n", "versions": [{"version": "v1", "created": "Sat, 9 Oct 2010 01:29:45 GMT"}], "update_date": "2010-10-12", "authors_parsed": [["Diaz-Garcia", "Jose A.", ""], ["Gutierrez-Jaimez", "Ramon", ""]]}, {"id": "1010.1935", "submitter": "David Degras", "authors": "David Degras, Zhiwei Xu, Ting Zhang and Wei Biao Wu", "title": "Testing for Parallelism Between Trends in Multiple Time Series", "comments": "Submitted to IEEE Transactions on Signal Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the inference of trends in multiple, nonstationary time\nseries. To test whether trends are parallel to each other, we use a parallelism\nindex based on the L2-distances between nonparametric trend estimators and\ntheir average. A central limit theorem is obtained for the test statistic and\nthe test's consistency is established. We propose a simulation-based\napproximation to the distribution of the test statistic, which significantly\nimproves upon the normal approximation. The test is also applied to devise a\nclustering algorithm. Finally, the finite-sample properties of the test are\nassessed through simulations and the test methodology is illustrated with time\nseries from Motorola cell phone activity in the United States.\n", "versions": [{"version": "v1", "created": "Sun, 10 Oct 2010 16:23:23 GMT"}, {"version": "v2", "created": "Tue, 24 May 2011 15:37:13 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Degras", "David", ""], ["Xu", "Zhiwei", ""], ["Zhang", "Ting", ""], ["Wu", "Wei Biao", ""]]}, {"id": "1010.2043", "submitter": "Yaming Yu", "authors": "Yaming Yu", "title": "Relative log-concavity and a pair of triangle inequalities", "comments": "Published in at http://dx.doi.org/10.3150/09-BEJ216 the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2010, Vol. 16, No. 2, 459-470", "doi": "10.3150/09-BEJ216", "report-no": "IMS-BEJ-BEJ216", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The relative log-concavity ordering $\\leq_{\\mathrm{lc}}$ between probability\nmass functions (pmf's) on non-negative integers is studied. Given three pmf's\n$f,g,h$ that satisfy $f\\leq_{\\mathrm{lc}}g\\leq_{\\mathrm{lc}}h$, we present a\npair of (reverse) triangle inequalities: if $\\sum_iif_i=\\sum_iig_i<\\infty,$\nthen \\[D(f|h)\\geq D(f|g)+D(g|h)\\] and if $\\sum_iig_i=\\sum_iih_i<\\infty,$ then\n\\[D(h|f)\\geq D(h|g)+D(g|f),\\] where $D(\\cdot|\\cdot)$ denotes the\nKullback--Leibler divergence. These inequalities, interesting in themselves,\nare also applied to several problems, including maximum entropy\ncharacterizations of Poisson and binomial distributions and the best binomial\napproximation in relative entropy. We also present parallel results for\ncontinuous distributions and discuss the behavior of $\\leq_{\\mathrm{lc}}$ under\nconvolution.\n", "versions": [{"version": "v1", "created": "Mon, 11 Oct 2010 09:09:53 GMT"}], "update_date": "2010-10-12", "authors_parsed": [["Yu", "Yaming", ""]]}, {"id": "1010.2064", "submitter": "Xinyi Xu", "authors": "Xinyi Xu, Feng Liang", "title": "Asymptotic minimax risk of predictive density estimation for\n  non-parametric regression", "comments": "Published in at http://dx.doi.org/10.3150/09-BEJ222 the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2010, Vol. 16, No. 2, 543-560", "doi": "10.3150/09-BEJ222", "report-no": "IMS-BEJ-BEJ222", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of estimating the predictive density of future\nobservations from a non-parametric regression model. The density estimators are\nevaluated under Kullback--Leibler divergence and our focus is on establishing\nthe exact asymptotics of minimax risk in the case of Gaussian errors. We derive\nthe convergence rate and constant for minimax risk among Bayesian predictive\ndensities under Gaussian priors and we show that this minimax risk is\nasymptotically equivalent to that among all density estimators.\n", "versions": [{"version": "v1", "created": "Mon, 11 Oct 2010 11:13:59 GMT"}], "update_date": "2010-10-12", "authors_parsed": [["Xu", "Xinyi", ""], ["Liang", "Feng", ""]]}, {"id": "1010.2066", "submitter": "Carmen Sang\\\"{u}esa", "authors": "Carmen Sang\\\"uesa", "title": "Uniform error bounds for a continuous approximation of non-negative\n  random variables", "comments": "Published in at http://dx.doi.org/10.3150/09-BEJ209 the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2010, Vol. 16, No. 2, 561-584", "doi": "10.3150/09-BEJ209", "report-no": "IMS-BEJ-BEJ209", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we deal with approximations for distribution functions of\nnon-negative random variables. More specifically, we construct continuous\napproximants using an acceleration technique over a well-know inversion formula\nfor Laplace transforms. We give uniform error bounds using a representation of\nthese approximations in terms of gamma-type operators. We apply our results to\ncertain mixtures of Erlang distributions which contain the class of continuous\nphase-type distributions.\n", "versions": [{"version": "v1", "created": "Mon, 11 Oct 2010 11:29:11 GMT"}], "update_date": "2010-10-12", "authors_parsed": [["Sang\u00fcesa", "Carmen", ""]]}, {"id": "1010.2074", "submitter": "Yanyuan Ma", "authors": "Yanyuan Ma", "title": "A semiparametric efficient estimator in case-control studies", "comments": "Published in at http://dx.doi.org/10.3150/09-BEJ210 the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2010, Vol. 16, No. 2, 585-603", "doi": "10.3150/09-BEJ210", "report-no": "IMS-BEJ-BEJ210", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We construct a semiparametric estimator in case-control studies where the\ngene and the environment are assumed to be independent. A discrete or\ncontinuous parametric distribution of the genes is assumed in the model. A\ndiscrete distribution of the genes can be used to model the mutation or\npresence of certain group of genes. A continuous distribution allows the\ndistribution of the gene effects to be in a finite-dimensional parametric\nfamily and can hence be used to model the gene expression levels. We leave the\ndistribution of the environment totally unspecified. The estimator is derived\nthrough calculating the efficiency score function in a hypothetical setting\nwhere a close approximation to the samples is random. The resulting estimator\nis proved to be efficient in the hypothetical situation. The efficiency of the\nestimator is further demonstrated to hold in the case-control setting as well.\n", "versions": [{"version": "v1", "created": "Mon, 11 Oct 2010 11:49:56 GMT"}], "update_date": "2010-10-12", "authors_parsed": [["Ma", "Yanyuan", ""]]}, {"id": "1010.2265", "submitter": "Georg M. Goerg", "authors": "Georg M. Goerg", "title": "The Lambert Way to Gaussianize heavy tailed data with the inverse of\n  Tukey's h as a special case", "comments": "38 + 14 pages; 4 tables; 8 figures. Submitted for publication.\n  Keywords: Gaussianizing, family of heavy-tailed distributions, Tukey's $h$\n  distribution, Lambert W, kurtosis, transformation of random variables; latent\n  variables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  I present a parametric, bijective transformation to generate heavy tail\nversions Y of arbitrary RVs X ~ F. The tail behavior of the so-called 'heavy\ntail Lambert W x F' RV Y depends on a tail parameter delta >= 0: for delta = 0,\nY = X, for delta > 0 Y has heavier tails than X. For X being Gaussian, this\nmeta-family of heavy-tailed distributions reduces to Tukey's h distribution.\nLambert's W function provides an explicit inverse transformation, which can be\nestimated by maximum likelihood. This inverse can remove heavy tails from data,\nand also provide analytical expressions for the cumulative distribution (cdf)\nand probability density function (pdf). As a special case, these yield explicit\nformulas for Tukey's h pdf and cdf - to the author's knowledge for the first\ntime in the literature. Simulations and applications to S&P 500 log-returns and\nsolar flares data demonstrate the usefulness of the introduced methodology. The\nR package \"LambertW\" (cran.r-project.org/web/packages/LambertW) implementing\nthe presented methodology is publicly available at CRAN.\n", "versions": [{"version": "v1", "created": "Mon, 11 Oct 2010 23:42:41 GMT"}, {"version": "v2", "created": "Fri, 29 Oct 2010 02:13:03 GMT"}, {"version": "v3", "created": "Wed, 2 Feb 2011 23:51:41 GMT"}, {"version": "v4", "created": "Wed, 20 Jul 2011 22:45:13 GMT"}, {"version": "v5", "created": "Sun, 30 Dec 2012 21:02:18 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Goerg", "Georg M.", ""]]}, {"id": "1010.2334", "submitter": "Bertrand Iooss", "authors": "Benjamin Auder (CEA-DEN), Agnes De Crecy (CEA-DEN), Bertrand Iooss\n  (M\\'ethodes d'Analyse Stochastique des Codes et Traitements Num\\'eriques),\n  Michel Marques (CEA-DEN)", "title": "Screening and metamodeling of computer experiments with functional\n  outputs. Application to thermal-hydraulic computations", "comments": null, "journal-ref": "Reliability Engineering and System Safety 107 (2012) 122-131", "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To perform uncertainty, sensitivity or optimization analysis on scalar\nvariables calculated by a cpu time expensive computer code, a widely accepted\nmethodology consists in first identifying the most influential uncertain inputs\n(by screening techniques), and then in replacing the cpu time expensive model\nby a cpu inexpensive mathematical function, called a metamodel. This paper\nextends this methodology to the functional output case, for instance when the\nmodel output variables are curves. The screening approach is based on the\nanalysis of variance and principal component analysis of output curves. The\nfunctional metamodeling consists in a curve classification step, a dimension\nreduction step, then a classical metamodeling step. An industrial nuclear\nreactor application (dealing with uncertainties in the pressurized thermal\nshock analysis) illustrates all these steps.\n", "versions": [{"version": "v1", "created": "Tue, 12 Oct 2010 09:45:12 GMT"}, {"version": "v2", "created": "Thu, 3 Nov 2011 14:40:50 GMT"}], "update_date": "2013-05-28", "authors_parsed": [["Auder", "Benjamin", "", "CEA-DEN"], ["De Crecy", "Agnes", "", "CEA-DEN"], ["Iooss", "Bertrand", "", "M\u00e9thodes d'Analyse Stochastique des Codes et Traitements Num\u00e9riques"], ["Marques", "Michel", "", "CEA-DEN"]]}, {"id": "1010.2457", "submitter": "Yohann de Castro", "authors": "Yohann de Castro (LM-Orsay)", "title": "Optimal designs for Lasso and Dantzig selector using Expander Codes", "comments": "Last version with optimal bounds", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT math.IT math.PR stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the high-dimensional regression problem using adjacency\nmatrices of unbalanced expander graphs. In this frame, we prove that the\n$\\ell_{2}$-prediction error and the $\\ell_{1}$-risk of the lasso and the\nDantzig selector are optimal up to an explicit multiplicative constant. Thus we\ncan estimate a high-dimensional target vector with an error term similar to the\none obtained in a situation where one knows the support of the largest\ncoordinates in advance.\n  Moreover, we show that these design matrices have an explicit restricted\neigenvalue. Precisely, they satisfy the restricted eigenvalue assumption and\nthe compatibility condition with an explicit constant.\n  Eventually, we capitalize on the recent construction of unbalanced expander\ngraphs due to Guruswami, Umans, and Vadhan, to provide a deterministic\npolynomial time construction of these design matrices.\n", "versions": [{"version": "v1", "created": "Tue, 12 Oct 2010 18:03:23 GMT"}, {"version": "v2", "created": "Fri, 5 Nov 2010 10:43:31 GMT"}, {"version": "v3", "created": "Thu, 18 Nov 2010 09:19:54 GMT"}, {"version": "v4", "created": "Thu, 14 Apr 2011 09:57:04 GMT"}, {"version": "v5", "created": "Wed, 19 Jun 2013 15:07:26 GMT"}, {"version": "v6", "created": "Tue, 22 Jul 2014 08:56:44 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["de Castro", "Yohann", "", "LM-Orsay"]]}, {"id": "1010.2731", "submitter": "Sahand N. Negahban", "authors": "Sahand N. Negahban, Pradeep Ravikumar, Martin J. Wainwright, Bin Yu", "title": "A Unified Framework for High-Dimensional Analysis of M-Estimators with\n  Decomposable Regularizers", "comments": "Published in at http://dx.doi.org/10.1214/12-STS400 the Statistical\n  Science (http://www.imstat.org/sts/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Statistical Science 2012, Vol. 27, No. 4, 538-557", "doi": "10.1214/12-STS400", "report-no": "IMS-STS-STS400", "categories": "math.ST cs.IT math.IT stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-dimensional statistical inference deals with models in which the the\nnumber of parameters p is comparable to or larger than the sample size n. Since\nit is usually impossible to obtain consistent procedures unless\n$p/n\\rightarrow0$, a line of recent work has studied models with various types\nof low-dimensional structure, including sparse vectors, sparse and structured\nmatrices, low-rank matrices and combinations thereof. In such settings, a\ngeneral approach to estimation is to solve a regularized optimization problem,\nwhich combines a loss function measuring how well the model fits the data with\nsome regularization function that encourages the assumed structure. This paper\nprovides a unified framework for establishing consistency and convergence rates\nfor such regularized M-estimators under high-dimensional scaling. We state one\nmain theorem and show how it can be used to re-derive some existing results,\nand also to obtain a number of new results on consistency and convergence\nrates, in both $\\ell_2$-error and related norms. Our analysis also identifies\ntwo key properties of loss and regularization functions, referred to as\nrestricted strong convexity and decomposability, that ensure corresponding\nregularized M-estimators have fast convergence rates and which are optimal in\nmany well-studied cases.\n", "versions": [{"version": "v1", "created": "Wed, 13 Oct 2010 19:05:27 GMT"}, {"version": "v2", "created": "Wed, 14 Mar 2012 14:28:14 GMT"}, {"version": "v3", "created": "Tue, 12 Mar 2013 11:17:04 GMT"}], "update_date": "2013-03-13", "authors_parsed": [["Negahban", "Sahand N.", ""], ["Ravikumar", "Pradeep", ""], ["Wainwright", "Martin J.", ""], ["Yu", "Bin", ""]]}, {"id": "1010.2737", "submitter": "Victoria Zinde-Walsh", "authors": "Victoria Zinde-Walsh", "title": "Identification and well-posedness in a class of nonparametric problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is a companion note to Zinde-Walsh (2010), arXiv:1009.4217v1[MATH.ST],\nto clarify and extend results on identification in a number of problems that\nlead to a system of convolution equations. Examples include identification of\nthe distribution of mismeasured variables, of a nonparametric regression\nfunction under Berkson type measurement error, some nonparametric panel data\nmodels, etc. The reason that identification in different problems can be\nconsidered in one approach is that they lead to the same system of convolution\nequations; moreover the solution can be given under more general assumptions\nthan those usually considered, by examining these equations in spaces of\ngeneralized functions. An important issue that did not receive sufficient\nattention is that of well-posedness. This note gives conditions under which\nwell-posedness obtains, an example that demonstrates that when well-posedness\ndoes not hold functions that are far apart can give rise to observable\narbitrarily close functions and discusses misspecification and estimation from\nthe stand-point of well-posedness.\n", "versions": [{"version": "v1", "created": "Wed, 13 Oct 2010 19:19:49 GMT"}], "update_date": "2010-10-14", "authors_parsed": [["Zinde-Walsh", "Victoria", ""]]}, {"id": "1010.2895", "submitter": "Jean-Marc Bardet", "authors": "Jean-Marc Bardet (SAMM), Donatas Surgailis", "title": "Nonparametric estimation of the local Hurst function of multifractional\n  Gaussian processes", "comments": null, "journal-ref": "Stochastic Processes and their Applications (2012) 1-32", "doi": "10.1016/j.spa.2012.11.009", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new nonparametric estimator of the local Hurst function of a\nmultifractional Gaussian process based on the increment ratio (IR) statistic is\ndefined. In a general frame, the point-wise and uniform weak and strong\nconsistency and a multidimensional central limit theorem for this estimator are\nestablished. Similar results are obtained for a refinement of the generalized\nquadratic variations (QV) estimator. The example of the multifractional\nBrownian motion is studied in detail. A simulation study is included showing\nthat the IR-estimator is more accurate than the QV-estimator.\n", "versions": [{"version": "v1", "created": "Thu, 14 Oct 2010 13:06:51 GMT"}, {"version": "v2", "created": "Thu, 7 Jun 2012 12:35:43 GMT"}], "update_date": "2012-11-29", "authors_parsed": [["Bardet", "Jean-Marc", "", "SAMM"], ["Surgailis", "Donatas", ""]]}, {"id": "1010.3366", "submitter": "Serguei Pergamenchtchikov", "authors": "Victor Konev, Serguei Pergamenchtchikov (LMRS)", "title": "Efficient robust nonparametric estimation in a semimartingale regression\n  model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper considers the problem of robust estimating a periodic function in a\ncontinuous time regression model with dependent disturbances given by a general\nsquare integrable semimartingale with unknown distribution. An example of such\na noise is non-gaussian Ornstein-Uhlenbeck process with the L\\'evy process\nsubordinator, which is used to model the financial Black-Scholes type markets\nwith jumps. An adaptive model selection procedure, based on the weighted least\nsquare estimates, is proposed. Under general moment conditions on the noise\ndistribution, sharp non-asymptotic oracle inequalities for the robust risks\nhave been derived and the robust efficiency of the model selection procedure\nhas been shown.\n", "versions": [{"version": "v1", "created": "Sat, 16 Oct 2010 18:50:03 GMT"}], "update_date": "2010-10-20", "authors_parsed": [["Konev", "Victor", "", "LMRS"], ["Pergamenchtchikov", "Serguei", "", "LMRS"]]}, {"id": "1010.3390", "submitter": "James Scott", "authors": "Nicholas G. Polson and James G. Scott", "title": "Local shrinkage rules, Levy processes, and regularized regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use Levy processes to generate joint prior distributions, and therefore\npenalty functions, for a location parameter as p grows large. This generalizes\nthe class of local-global shrinkage rules based on scale mixtures of normals,\nilluminates new connections among disparate methods, and leads to new results\nfor computing posterior means and modes under a wide class of priors. We extend\nthis framework to large-scale regularized regression problems where p>n, and\nprovide comparisons with other methodologies.\n", "versions": [{"version": "v1", "created": "Sun, 17 Oct 2010 02:34:51 GMT"}, {"version": "v2", "created": "Sat, 23 Apr 2011 22:38:27 GMT"}], "update_date": "2011-04-26", "authors_parsed": [["Polson", "Nicholas G.", ""], ["Scott", "James G.", ""]]}, {"id": "1010.3425", "submitter": "Philip Dawid", "authors": "A. Philip Dawid and Vanessa Didelez", "title": "Identifying the consequences of dynamic treatment strategies: A\n  decision-theoretic overview", "comments": "49 pages, 15 figures", "journal-ref": "Statistics Surveys 2010, Vol. 4, 184-231", "doi": "10.1214/10-SS081", "report-no": null, "categories": "math.ST cs.AI stat.TH", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  We consider the problem of learning about and comparing the consequences of\ndynamic treatment strategies on the basis of observational data. We formulate\nthis within a probabilistic decision-theoretic framework. Our approach is\ncompared with related work by Robins and others: in particular, we show how\nRobins's 'G-computation' algorithm arises naturally from this\ndecision-theoretic perspective. Careful attention is paid to the mathematical\nand substantive conditions required to justify the use of this formula. These\nconditions revolve around a property we term stability, which relates the\nprobabilistic behaviours of observational and interventional regimes. We show\nhow an assumption of 'sequential randomization' (or 'no unmeasured\nconfounders'), or an alternative assumption of 'sequential irrelevance', can be\nused to infer stability. Probabilistic influence diagrams are used to simplify\nmanipulations, and their power and limitations are discussed. We compare our\napproach with alternative formulations based on causal DAGs or potential\nresponse models. We aim to show that formulating the problem of assessing\ndynamic treatment strategies as a problem of decision analysis brings clarity,\nsimplicity and generality.\n", "versions": [{"version": "v1", "created": "Sun, 17 Oct 2010 16:02:58 GMT"}], "update_date": "2010-11-16", "authors_parsed": [["Dawid", "A. Philip", ""], ["Didelez", "Vanessa", ""]]}, {"id": "1010.3430", "submitter": "Pavel Gapeev", "authors": "Pavel V. Gapeev and Albert N. Shiryaev", "title": "Bayesian quickest detection problems for some diffusion processes", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the Bayesian problems of detecting a change in the drift rate of an\nobservable diffusion process with linear and exponential penalty costs for a\ndetection delay. The optimal times of alarms are found as the first times at\nwhich the weighted likelihood ratios hit stochastic boundaries depending on the\ncurrent observations. The proof is based on the reduction of the initial\nproblems into appropriate three-dimensional optimal stopping problems and the\nanalysis of the associated parabolic-type free-boundary problems. We provide\nclosed form estimates for the value functions and the boundaries, under certain\nnontrivial relations between the coefficients of the observable diffusion.\n", "versions": [{"version": "v1", "created": "Sun, 17 Oct 2010 17:30:24 GMT"}, {"version": "v2", "created": "Sun, 6 Nov 2011 20:06:22 GMT"}], "update_date": "2011-11-08", "authors_parsed": [["Gapeev", "Pavel V.", ""], ["Shiryaev", "Albert N.", ""]]}, {"id": "1010.3566", "submitter": "Fabio Rapallo", "authors": "Cristiano Bocci, Enrico Carlini and Fabio Rapallo", "title": "Perturbation of matrices and non-negative rank with a view toward\n  statistical models", "comments": "13 pages, 3 figures. A theorem has been rewritten, and some\n  improvements in the presentations have been implemented", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO math.AC math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study how perturbing a matrix changes its non-negative rank.\nWe prove that the non-negative rank is upper-semicontinuos and we describe some\nspecial families of perturbations. We show how our results relate to Statistics\nin terms of the study of Maximum Likelihood Estimation for mixture models.\n", "versions": [{"version": "v1", "created": "Mon, 18 Oct 2010 11:51:54 GMT"}, {"version": "v2", "created": "Tue, 22 Feb 2011 18:04:24 GMT"}, {"version": "v3", "created": "Wed, 20 Jul 2011 14:33:08 GMT"}], "update_date": "2011-07-21", "authors_parsed": [["Bocci", "Cristiano", ""], ["Carlini", "Enrico", ""], ["Rapallo", "Fabio", ""]]}, {"id": "1010.3586", "submitter": "Pasquale Cirillo", "authors": "Pasquale Cirillo, J\\\"urg H\\\"usler and Pietro Muliere", "title": "A nonparametric urn-based approach to interacting failing systems with\n  an application to credit risk modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a new nonparametric approach to interacting failing\nsystems (FS), that is systems whose probability of failure is not negligible in\na fixed time horizon, a typical example being firms and financial bonds. The\nmain purpose when studying a FS is to calculate the probability of default and\nthe distribution of the number of failures that may occur during the\nobservation period. A model used to study a failing system is defined default\nmodel. In particular, we present a general recursive model constructed by the\nmeans of inter- acting urns. After introducing the theoretical model and its\nproperties we show a first application to credit risk modeling, showing how to\nassess the idiosyncratic probability of default of an obligor and the joint\nprobability of failure of a set of obligors in a portfolio of risks, that are\ndivided into reliability classes.\n", "versions": [{"version": "v1", "created": "Mon, 18 Oct 2010 13:05:31 GMT"}], "update_date": "2010-10-19", "authors_parsed": [["Cirillo", "Pasquale", ""], ["H\u00fcsler", "J\u00fcrg", ""], ["Muliere", "Pietro", ""]]}, {"id": "1010.3604", "submitter": "Angelika Rohde", "authors": "Angelika Rohde, Claudia Strauch", "title": "Uniform Central Limit Theorems for Multidimensional Diffusions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has recently been shown that there are substantial differences in the\nregularity behavior of the empirical process based on scalar diffusions as\ncompared to the classical empirical process, due to the existence of diffusion\nlocal time. Besides establishing strong parallels to classical theory such as\nOssiander's bracketing CLT and the general Gin\\'e-Zinn CLT for uniformly\nbounded families of functions, we find increased regularity also for\nmultivariate ergodic diffusions, assuming that the invariant measure is finite\nwith Lebesgue density $\\pi$. The effect is diminishing for growing dimension\nbut always present. The fine differences to the classical iid setting are\nworked out using exponential inequalities for martingales and additive\nfunctionals of continuous Markov processes as well as the characterization of\nthe sample path behavior of Gaussian processes by means of the generic chaining\nbound. To uncover the phenomenon, we study a smoothed version of the empirical\ndiffusion process. It turns out that uniform weak convergence of the smoothed\nempirical diffusion process under necessary and sufficient conditions can take\nplace with even exponentially small bandwidth in dimension $d=2$, and with\nstrongly undersmoothing bandwidth choice for parameters $\\beta > d/2$ in case\n$d\\geq 3$, assuming that the coordinates of drift and diffusion coefficient\nbelong to some H\\\"older ball with parameter $\\beta$.\n", "versions": [{"version": "v1", "created": "Mon, 18 Oct 2010 14:14:15 GMT"}, {"version": "v2", "created": "Mon, 25 Oct 2010 12:17:17 GMT"}, {"version": "v3", "created": "Tue, 24 May 2011 07:40:52 GMT"}], "update_date": "2011-05-25", "authors_parsed": [["Rohde", "Angelika", ""], ["Strauch", "Claudia", ""]]}, {"id": "1010.3619", "submitter": "Souvik Ghosh", "authors": "Souvik Ghosh and Soumyadip Ghosh", "title": "A strong law for the rate of growth of long latency periods in cloud\n  computing service", "comments": "22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud-computing shares a common pool of resources across customers at a scale\nthat is orders of magnitude larger than traditional multi-user systems.\nConstituent physical compute servers are allocated multiple \"virtual machines\"\n(VM) to serve simultaneously. Each VM user should ideally be unaffected by\nothers' demand. Naturally, this environment produces new challenges for the\nservice providers in meeting customer expectations while extracting an\nefficient utilization from server resources. We study a new cloud service\nmetric that measures prolonged latency or delay suffered by customers. We model\nthe workload process of a cloud server and analyze the process as the customer\npopulation grows. The capacity required to ensure that average workload does\nnot exceed a threshold over long segments is characterized. This can be used by\ncloud operators to provide service guarantees on avoiding long durations of\nlatency. As part of the analysis, we provide a uniform large-deviation\nprinciple for collections of random variables that is of independent interest.\n", "versions": [{"version": "v1", "created": "Fri, 15 Oct 2010 05:06:28 GMT"}], "update_date": "2010-10-19", "authors_parsed": [["Ghosh", "Souvik", ""], ["Ghosh", "Soumyadip", ""]]}, {"id": "1010.3821", "submitter": "El\\'{{\\i}}as Moreno", "authors": "El\\'ias Moreno, F. Javier Gir\\'on, George Casella", "title": "Consistency of objective Bayes factors as the model dimension grows", "comments": "Published in at http://dx.doi.org/10.1214/09-AOS754 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2010, Vol. 38, No. 4, 1937-1952", "doi": "10.1214/09-AOS754", "report-no": "IMS-AOS-AOS754", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the class of normal regression models with a finite number of regressors,\nand for a wide class of prior distributions, a Bayesian model selection\nprocedure based on the Bayes factor is consistent [Casella and Moreno J. Amer.\nStatist. Assoc. 104 (2009) 1261--1271]. However, in models where the number of\nparameters increases as the sample size increases, properties of the Bayes\nfactor are not totally understood. Here we study consistency of the Bayes\nfactors for nested normal linear models when the number of regressors increases\nwith the sample size. We pay attention to two successful tools for model\nselection [Schwarz Ann. Statist. 6 (1978) 461--464] approximation to the Bayes\nfactor, and the Bayes factor for intrinsic priors [Berger and Pericchi J. Amer.\nStatist. Assoc. 91 (1996) 109--122, Moreno, Bertolino and Racugno J. Amer.\nStatist. Assoc. 93 (1998) 1451--1460]. We find that the the Schwarz\napproximation and the Bayes factor for intrinsic priors are consistent when the\nrate of growth of the dimension of the bigger model is $O(n^b)$ for $b<1$. When\n$b=1$ the Schwarz approximation is always inconsistent under the alternative\nwhile the Bayes factor for intrinsic priors is consistent except for a small\nset of alternative models which is characterized.\n", "versions": [{"version": "v1", "created": "Tue, 19 Oct 2010 07:53:57 GMT"}], "update_date": "2010-10-20", "authors_parsed": [["Moreno", "El\u00edas", ""], ["Gir\u00f3n", "F. Javier", ""], ["Casella", "George", ""]]}, {"id": "1010.3825", "submitter": "Bodhisattva Sen", "authors": "Bodhisattva Sen, Moulinath Banerjee, Michael Woodroofe", "title": "Inconsistency of bootstrap: The Grenander estimator", "comments": "Published in at http://dx.doi.org/10.1214/09-AOS777 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2010, Vol. 38, No. 4, 1953-1977", "doi": "10.1214/09-AOS777", "report-no": "IMS-AOS-AOS777", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the (in)-consistency of different bootstrap\nmethods for constructing confidence intervals in the class of estimators that\nconverge at rate $n^{1/3}$. The Grenander estimator, the nonparametric maximum\nlikelihood estimator of an unknown nonincreasing density function $f$ on\n$[0,\\infty)$, is a prototypical example. We focus on this example and explore\ndifferent approaches to constructing bootstrap confidence intervals for\n$f(t_0)$, where $t_0\\in(0,\\infty)$ is an interior point. We find that the\nbootstrap estimate, when generating bootstrap samples from the empirical\ndistribution function $\\mathbb{F}_n$ or its least concave majorant\n$\\tilde{F}_n$, does not have any weak limit in probability. We provide a set of\nsufficient conditions for the consistency of any bootstrap method in this\nexample and show that bootstrapping from a smoothed version of $\\tilde{F}_n$\nleads to strongly consistent estimators. The $m$ out of $n$ bootstrap method is\nalso shown to be consistent while generating samples from $\\mathbb{F}_n$ and\n$\\tilde{F}_n$.\n", "versions": [{"version": "v1", "created": "Tue, 19 Oct 2010 08:28:30 GMT"}], "update_date": "2010-10-20", "authors_parsed": [["Sen", "Bodhisattva", ""], ["Banerjee", "Moulinath", ""], ["Woodroofe", "Michael", ""]]}, {"id": "1010.3836", "submitter": "T. Tony Cai", "authors": "Lawrence D. Brown, T. Tony Cai, Harrison H. Zhou", "title": "Nonparametric regression in exponential families", "comments": "Published in at http://dx.doi.org/10.1214/09-AOS762 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2010, Vol. 38, No. 4, 2005-2046", "doi": "10.1214/09-AOS762", "report-no": "IMS-AOS-AOS762", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most results in nonparametric regression theory are developed only for the\ncase of additive noise. In such a setting many smoothing techniques including\nwavelet thresholding methods have been developed and shown to be highly\nadaptive. In this paper we consider nonparametric regression in exponential\nfamilies with the main focus on the natural exponential families with a\nquadratic variance function, which include, for example, Poisson regression,\nbinomial regression and gamma regression. We propose a unified approach of\nusing a mean-matching variance stabilizing transformation to turn the\nrelatively complicated problem of nonparametric regression in exponential\nfamilies into a standard homoscedastic Gaussian regression problem. Then in\nprinciple any good nonparametric Gaussian regression procedure can be applied\nto the transformed data. To illustrate our general methodology, in this paper\nwe use wavelet block thresholding to construct the final estimators of the\nregression function. The procedures are easily implementable. Both theoretical\nand numerical properties of the estimators are investigated. The estimators are\nshown to enjoy a high degree of adaptivity and spatial adaptivity with\nnear-optimal asymptotic performance over a wide range of Besov spaces. The\nestimators also perform well numerically.\n", "versions": [{"version": "v1", "created": "Tue, 19 Oct 2010 09:30:57 GMT"}], "update_date": "2010-10-20", "authors_parsed": [["Brown", "Lawrence D.", ""], ["Cai", "T. Tony", ""], ["Zhou", "Harrison H.", ""]]}, {"id": "1010.3843", "submitter": "Tzee-Ming Huang", "authors": "Tzee-Ming Huang", "title": "Testing conditional independence using maximal nonlinear conditional\n  correlation", "comments": "Published in at http://dx.doi.org/10.1214/09-AOS770 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2010, Vol. 38, No. 4, 2047-2091", "doi": "10.1214/09-AOS770", "report-no": "IMS-AOS-AOS770", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the maximal nonlinear conditional correlation of two random\nvectors $X$ and $Y$ given another random vector $Z$, denoted by\n$\\rho_1(X,Y|Z)$, is defined as a measure of conditional association, which\nsatisfies certain desirable properties. When $Z$ is continuous, a test for\ntesting the conditional independence of $X$ and $Y$ given $Z$ is constructed\nbased on the estimator of a weighted average of the form\n$\\sum_{k=1}^{n_Z}f_Z(z_k)\\rho^2_1(X,Y|Z=z_k)$, where $f_Z$ is the probability\ndensity function of $Z$ and the $z_k$'s are some points in the range of $Z$.\nUnder some conditions, it is shown that the test statistic is asymptotically\nnormal under conditional independence, and the test is consistent.\n", "versions": [{"version": "v1", "created": "Tue, 19 Oct 2010 10:08:04 GMT"}], "update_date": "2010-10-20", "authors_parsed": [["Huang", "Tzee-Ming", ""]]}, {"id": "1010.3855", "submitter": "Pang Du", "authors": "Pang Du, Shuangge Ma, Hua Liang", "title": "Penalized variable selection procedure for Cox models with\n  semiparametric relative risk", "comments": "Published in at http://dx.doi.org/10.1214/09-AOS780 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2010, Vol. 38, No. 4, 2092-2117", "doi": "10.1214/09-AOS780", "report-no": "IMS-AOS-AOS780", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the Cox models with semiparametric relative risk, which can be\npartially linear with one nonparametric component, or multiple additive or\nnonadditive nonparametric components. A penalized partial likelihood procedure\nis proposed to simultaneously estimate the parameters and select variables for\nboth the parametric and the nonparametric parts. Two penalties are applied\nsequentially. The first penalty, governing the smoothness of the multivariate\nnonlinear covariate effect function, provides a smoothing spline ANOVA\nframework that is exploited to derive an empirical model selection tool for the\nnonparametric part. The second penalty, either the\nsmoothly-clipped-absolute-deviation (SCAD) penalty or the adaptive LASSO\npenalty, achieves variable selection in the parametric part. We show that the\nresulting estimator of the parametric part possesses the oracle property, and\nthat the estimator of the nonparametric part achieves the optimal rate of\nconvergence. The proposed procedures are shown to work well in simulation\nexperiments, and then applied to a real data example on sexually transmitted\ndiseases.\n", "versions": [{"version": "v1", "created": "Tue, 19 Oct 2010 11:16:40 GMT"}], "update_date": "2010-10-20", "authors_parsed": [["Du", "Pang", ""], ["Ma", "Shuangge", ""], ["Liang", "Hua", ""]]}, {"id": "1010.3866", "submitter": "T. Tony Cai", "authors": "T. Tony Cai, Cun-Hui Zhang, Harrison H. Zhou", "title": "Optimal rates of convergence for covariance matrix estimation", "comments": "Published in at http://dx.doi.org/10.1214/09-AOS752 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2010, Vol. 38, No. 4, 2118-2144", "doi": "10.1214/09-AOS752", "report-no": "IMS-AOS-AOS752", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Covariance matrix plays a central role in multivariate statistical analysis.\nSignificant advances have been made recently on developing both theory and\nmethodology for estimating large covariance matrices. However, a minimax theory\nhas yet been developed. In this paper we establish the optimal rates of\nconvergence for estimating the covariance matrix under both the operator norm\nand Frobenius norm. It is shown that optimal procedures under the two norms are\ndifferent and consequently matrix estimation under the operator norm is\nfundamentally different from vector estimation. The minimax upper bound is\nobtained by constructing a special class of tapering estimators and by studying\ntheir risk properties. A key step in obtaining the optimal rate of convergence\nis the derivation of the minimax lower bound. The technical analysis requires\nnew ideas that are quite different from those used in the more conventional\nfunction/sequence estimation problems.\n", "versions": [{"version": "v1", "created": "Tue, 19 Oct 2010 12:01:22 GMT"}], "update_date": "2010-10-20", "authors_parsed": [["Cai", "T. Tony", ""], ["Zhang", "Cun-Hui", ""], ["Zhou", "Harrison H.", ""]]}, {"id": "1010.3891", "submitter": "Zhou Zhou", "authors": "Zhou Zhou", "title": "Nonparametric inference of quantile curves for nonstationary time series", "comments": "Published in at http://dx.doi.org/10.1214/09-AOS769 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2010, Vol. 38, No. 4, 2187-2217", "doi": "10.1214/09-AOS769", "report-no": "IMS-AOS-AOS769", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper considers nonparametric specification tests of quantile curves for\na general class of nonstationary processes. Using Bahadur representation and\nGaussian approximation results for nonstationary time series, simultaneous\nconfidence bands and integrated squared difference tests are proposed to test\nvarious parametric forms of the quantile curves with asymptotically correct\ntype I error rates. A wild bootstrap procedure is implemented to alleviate the\nproblem of slow convergence of the asymptotic results. In particular, our\nresults can be used to test the trends of extremes of climate variables, an\nimportant problem in understanding climate change. Our methodology is applied\nto the analysis of the maximum speed of tropical cyclone winds. It was found\nthat an inhomogeneous upward trend for cyclone wind speeds is pronounced at\nhigh quantile values. However, there is no trend in the mean lifetime-maximum\nwind speed. This example shows the effectiveness of the quantile regression\ntechnique.\n", "versions": [{"version": "v1", "created": "Tue, 19 Oct 2010 13:04:20 GMT"}], "update_date": "2010-10-20", "authors_parsed": [["Zhou", "Zhou", ""]]}, {"id": "1010.3901", "submitter": "Hongjian Zhu", "authors": "Hongjian Zhu, Feifang Hu", "title": "Sequential monitoring of response-adaptive randomized clinical trials", "comments": "Published in at http://dx.doi.org/10.1214/10-AOS796 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2010, Vol. 38, No. 4, 2218-2241", "doi": "10.1214/10-AOS796", "report-no": "IMS-AOS-AOS796", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clinical trials are complex and usually involve multiple objectives such as\ncontrolling type I error rate, increasing power to detect treatment difference,\nassigning more patients to better treatment, and more. In literature, both\nresponse-adaptive randomization (RAR) procedures (by changing randomization\nprocedure sequentially) and sequential monitoring (by changing analysis\nprocedure sequentially) have been proposed to achieve these objectives to some\ndegree. In this paper, we propose to sequentially monitor response-adaptive\nrandomized clinical trial and study it's properties. We prove that the\nsequential test statistics of the new procedure converge to a Brownian motion\nin distribution. Further, we show that the sequential test statistics\nasymptotically satisfy the canonical joint distribution defined in Jennison and\nTurnbull (\\citeyearJT00). Therefore, type I error and other objectives can be\nachieved theoretically by selecting appropriate boundaries. These results open\na door to sequentially monitor response-adaptive randomized clinical trials in\npractice. We can also observe from the simulation studies that, the proposed\nprocedure brings together the advantages of both techniques, in dealing with\npower, total sample size and total failure numbers, while keeps the type I\nerror. In addition, we illustrate the characteristics of the proposed procedure\nby redesigning a well-known clinical trial of maternal-infant HIV transmission.\n", "versions": [{"version": "v1", "created": "Tue, 19 Oct 2010 13:23:23 GMT"}], "update_date": "2010-10-20", "authors_parsed": [["Zhu", "Hongjian", ""], ["Hu", "Feifang", ""]]}, {"id": "1010.3916", "submitter": "Clive G. Bowsher", "authors": "Clive G. Bowsher", "title": "Stochastic kinetic models: Dynamic independence, modularity and graphs", "comments": "Published in at http://dx.doi.org/10.1214/09-AOS779 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2010, Vol. 38, No. 4, 2242-2281", "doi": "10.1214/09-AOS779", "report-no": "IMS-AOS-AOS779", "categories": "math.ST q-bio.QM stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The dynamic properties and independence structure of stochastic kinetic\nmodels (SKMs) are analyzed. An SKM is a highly multivariate jump process used\nto model chemical reaction networks, particularly those in biochemical and\ncellular systems. We identify SKM subprocesses with the corresponding counting\nprocesses and propose a directed, cyclic graph (the kinetic independence graph\nor KIG) that encodes the local independence structure of their conditional\nintensities. Given a partition $[A,D,B]$ of the vertices, the graphical\nseparation $A\\perp B|D$ in the undirected KIG has an intuitive chemical\ninterpretation and implies that $A$ is locally independent of $B$ given $A\\cup\nD$. It is proved that this separation also results in global independence of\nthe internal histories of $A$ and $B$ conditional on a history of the jumps in\n$D$ which, under conditions we derive, corresponds to the internal history of\n$D$. The results enable mathematical definition of a modularization of an SKM\nusing its implied dynamics. Graphical decomposition methods are developed for\nthe identification and efficient computation of nested modularizations.\nApplication to an SKM of the red blood cell advances understanding of this\nbiochemical system.\n", "versions": [{"version": "v1", "created": "Tue, 19 Oct 2010 14:01:46 GMT"}], "update_date": "2010-10-20", "authors_parsed": [["Bowsher", "Clive G.", ""]]}, {"id": "1010.4115", "submitter": "Jian Huang", "authors": "Jian Huang, Joel L. Horowitz, Fengrong Wei", "title": "Variable selection in nonparametric additive models", "comments": "Published in at http://dx.doi.org/10.1214/09-AOS781 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2010, Vol. 38, No. 4, 2282-2313", "doi": "10.1214/09-AOS781", "report-no": "IMS-AOS-AOS781", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a nonparametric additive model of a conditional mean function in\nwhich the number of variables and additive components may be larger than the\nsample size but the number of nonzero additive components is \"small\" relative\nto the sample size. The statistical problem is to determine which additive\ncomponents are nonzero. The additive components are approximated by truncated\nseries expansions with B-spline bases. With this approximation, the problem of\ncomponent selection becomes that of selecting the groups of coefficients in the\nexpansion. We apply the adaptive group Lasso to select nonzero components,\nusing the group Lasso to obtain an initial estimator and reduce the dimension\nof the problem. We give conditions under which the group Lasso selects a model\nwhose number of components is comparable with the underlying model, and the\nadaptive group Lasso selects the nonzero components correctly with probability\napproaching one as the sample size increases and achieves the optimal rate of\nconvergence. The results of Monte Carlo experiments show that the adaptive\ngroup Lasso procedure works well with samples of moderate size. A data example\nis used to illustrate the application of the proposed method.\n", "versions": [{"version": "v1", "created": "Wed, 20 Oct 2010 07:13:50 GMT"}], "update_date": "2010-10-21", "authors_parsed": [["Huang", "Jian", ""], ["Horowitz", "Joel L.", ""], ["Wei", "Fengrong", ""]]}, {"id": "1010.4123", "submitter": "Min Hee Kim", "authors": "Min Hee Kim, Michael G. Akritas", "title": "Order thresholding", "comments": "Published in at http://dx.doi.org/10.1214/09-AOS782 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2010, Vol. 38, No. 4, 2314-2350", "doi": "10.1214/09-AOS782", "report-no": "IMS-AOS-AOS782", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new thresholding method, based on L-statistics and called order\nthresholding, is proposed as a technique for improving the power when testing\nagainst high-dimensional alternatives. The new method allows great flexibility\nin the choice of the threshold parameter. This results in improved power over\nthe soft and hard thresholding methods. Moreover, order thresholding is not\nrestricted to the normal distribution. An extension of the basic order\nthreshold statistic to high-dimensional ANOVA is presented. The performance of\nthe basic order threshold statistic and its extension is evaluated with\nextensive simulations.\n", "versions": [{"version": "v1", "created": "Wed, 20 Oct 2010 08:16:07 GMT"}], "update_date": "2010-10-21", "authors_parsed": [["Kim", "Min Hee", ""], ["Akritas", "Michael G.", ""]]}, {"id": "1010.4162", "submitter": "Hulin Wu", "authors": "Hongqi Xue, Hongyu Miao, Hulin Wu", "title": "Sieve estimation of constant and time-varying coefficients in nonlinear\n  ordinary differential equation models by considering both numerical error and\n  measurement error", "comments": "Published in at http://dx.doi.org/10.1214/09-AOS784 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2010, Vol. 38, No. 4, 2351-2387", "doi": "10.1214/09-AOS784", "report-no": "IMS-AOS-AOS784", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article considers estimation of constant and time-varying coefficients\nin nonlinear ordinary differential equation (ODE) models where analytic\nclosed-form solutions are not available. The numerical solution-based nonlinear\nleast squares (NLS) estimator is investigated in this study. A numerical\nalgorithm such as the Runge--Kutta method is used to approximate the ODE\nsolution. The asymptotic properties are established for the proposed estimators\nconsidering both numerical error and measurement error. The B-spline is used to\napproximate the time-varying coefficients, and the corresponding asymptotic\ntheories in this case are investigated under the framework of the sieve\napproach. Our results show that if the maximum step size of the $p$-order\nnumerical algorithm goes to zero at a rate faster than $n^{-1/(p\\wedge4)}$, the\nnumerical error is negligible compared to the measurement error. This result\nprovides a theoretical guidance in selection of the step size for numerical\nevaluations of ODEs. Moreover, we have shown that the numerical solution-based\nNLS estimator and the sieve NLS estimator are strongly consistent. The sieve\nestimator of constant parameters is asymptotically normal with the same\nasymptotic co-variance as that of the case where the true ODE solution is\nexactly known, while the estimator of the time-varying parameter has the\noptimal convergence rate under some regularity conditions. The theoretical\nresults are also developed for the case when the step size of the ODE numerical\nsolver does not go to zero fast enough or the numerical error is comparable to\nthe measurement error. We illustrate our approach with both simulation studies\nand clinical data on HIV viral dynamics.\n", "versions": [{"version": "v1", "created": "Wed, 20 Oct 2010 11:08:24 GMT"}], "update_date": "2010-10-21", "authors_parsed": [["Xue", "Hongqi", ""], ["Miao", "Hongyu", ""], ["Wu", "Hulin", ""]]}, {"id": "1010.4173", "submitter": "Pasquale Cirillo", "authors": "Pasquale Cirillo, J\\\"urg H\\\"usler", "title": "Generalized extreme shock models with a possibly increasing threshold", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a generalized extreme shock model with a possibly increasing\nfailure threshold. While standard models assume that the crucial threshold for\nthe system may only decrease over time, because of weakening shocks and\nobsolescence, we assume that, especially at the beginning of the system's life,\nsome strengthening shocks may increase the system tolerance to large shock.\nThis is for example the case of turbines' running-in in the field of\nengineering. On the basis of parametric assumptions, we provide theoretical\nresults and derive some exact and asymptotic univariate and multivariate\ndistributions for the model. In the last part of the paper we show how to link\nthis new model to some nonparametric approaches proposed in the literature.\n", "versions": [{"version": "v1", "created": "Wed, 20 Oct 2010 12:11:30 GMT"}], "update_date": "2010-10-21", "authors_parsed": [["Cirillo", "Pasquale", ""], ["H\u00fcsler", "J\u00fcrg", ""]]}, {"id": "1010.4182", "submitter": "Weidong Liu", "authors": "Weidong Liu, Wei Biao Wu", "title": "Simultaneous nonparametric inference of time series", "comments": "Published in at http://dx.doi.org/10.1214/09-AOS789 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2010, Vol. 38, No. 4, 2388-2421", "doi": "10.1214/09-AOS789", "report-no": "IMS-AOS-AOS789", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider kernel estimation of marginal densities and regression functions\nof stationary processes. It is shown that for a wide class of time series, with\nproper centering and scaling, the maximum deviations of kernel density and\nregression estimates are asymptotically Gumbel. Our results substantially\ngeneralize earlier ones which were obtained under independence or beta mixing\nassumptions. The asymptotic results can be applied to assess patterns of\nmarginal densities or regression functions via the construction of simultaneous\nconfidence bands for which one can perform goodness-of-fit tests. As an\napplication, we construct simultaneous confidence bands for drift and\nvolatility functions in a dynamic short-term rate model for the U.S. Treasury\nyield curve rates data.\n", "versions": [{"version": "v1", "created": "Wed, 20 Oct 2010 12:40:48 GMT"}], "update_date": "2010-10-21", "authors_parsed": [["Liu", "Weidong", ""], ["Wu", "Wei Biao", ""]]}, {"id": "1010.4202", "submitter": "Stephan F. Huckemann", "authors": "Stephan F. Huckemann, Peter T. Kim, Ja-Yong Koo, Axel Munk", "title": "M\\\"{o}bius deconvolution on the hyperbolic plane with application to\n  impedance density estimation", "comments": "Published in at http://dx.doi.org/10.1214/09-AOS783 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2010, Vol. 38, No. 4, 2465-2498", "doi": "10.1214/09-AOS783", "report-no": "IMS-AOS-AOS783", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider a novel statistical inverse problem on the\nPoincar\\'{e}, or Lobachevsky, upper (complex) half plane. Here the Riemannian\nstructure is hyperbolic and a transitive group action comes from the space of\n$2\\times2$ real matrices of determinant one via M\\\"{o}bius transformations. Our\napproach is based on a deconvolution technique which relies on the\nHelgason--Fourier calculus adapted to this hyperbolic space. This gives a\nminimax nonparametric density estimator of a hyperbolic density that is\ncorrupted by a random M\\\"{o}bius transform. A motivation for this work comes\nfrom the reconstruction of impedances of capacitors where the above scenario on\nthe Poincar\\'{e} plane exactly describes the physical system that is of\nstatistical interest.\n", "versions": [{"version": "v1", "created": "Wed, 20 Oct 2010 13:49:08 GMT"}], "update_date": "2010-10-21", "authors_parsed": [["Huckemann", "Stephan F.", ""], ["Kim", "Peter T.", ""], ["Koo", "Ja-Yong", ""], ["Munk", "Axel", ""]]}, {"id": "1010.4313", "submitter": "Souvik Ghosh", "authors": "Souvik Ghosh", "title": "A functional large and moderate deviation principle for infinitely\n  divisible processes driven by null-recurrent markov chains", "comments": "37 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Suppose $ E$ is a space with a null-recurrent Markov kernel $ P$.\nFurthermore, suppose there are infinite particles with variable weights on $ E$\nperforming a random walk following $ P$. Let $ X_{t}$ be a weighted functional\nof the position of particles at time $ t$. Under some conditions on the initial\ndistribution of the particles the process $ (X_{t})$ is stationary over time.\nNon-Gaussian infinitely divisible (ID) distributions turn out to be natural\ncandidates for the initial distribution and then the process $ (X_{t})$ is ID.\nWe prove a functional large and moderate deviation principle for the partial\nsums of the process $ (X_{t})$. The recurrence of the Markov Kernel $ P$\ninduces long memory in the process $ (X_{t})$ and that is reflected in the\nlarge deviation principle. It has been observed in certain short memory\nprocesses that the large deviation principle is very similar to that of an\ni.i.d. sequence. Whereas, if the process is long range dependent the large\ndeviations change dramatically. We show that a similar phenomenon is observed\nfor infinitely divisible processes driven by Markov chains. Processes of the\nform of $ (X_{t})$ gives us a rich class of non-Gaussian long memory models\nwhich may be useful in practice.\n", "versions": [{"version": "v1", "created": "Wed, 20 Oct 2010 20:22:21 GMT"}, {"version": "v2", "created": "Tue, 30 Nov 2010 06:23:34 GMT"}], "update_date": "2010-12-01", "authors_parsed": [["Ghosh", "Souvik", ""]]}, {"id": "1010.4345", "submitter": "Alexandre Belloni", "authors": "Alexandre Belloni, Daniel Chen, Victor Chernozhukov, Christian Hansen", "title": "Sparse Models and Methods for Optimal Instruments with an Application to\n  Eminent Domain", "comments": null, "journal-ref": "Econometrica 80, no. 6 (2012): 2369-2429", "doi": null, "report-no": null, "categories": "stat.ME econ.EM math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop results for the use of Lasso and Post-Lasso methods to form\nfirst-stage predictions and estimate optimal instruments in linear instrumental\nvariables (IV) models with many instruments, $p$. Our results apply even when\n$p$ is much larger than the sample size, $n$. We show that the IV estimator\nbased on using Lasso or Post-Lasso in the first stage is root-n consistent and\nasymptotically normal when the first-stage is approximately sparse; i.e. when\nthe conditional expectation of the endogenous variables given the instruments\ncan be well-approximated by a relatively small set of variables whose\nidentities may be unknown. We also show the estimator is semi-parametrically\nefficient when the structural error is homoscedastic. Notably our results allow\nfor imperfect model selection, and do not rely upon the unrealistic \"beta-min\"\nconditions that are widely used to establish validity of inference following\nmodel selection. In simulation experiments, the Lasso-based IV estimator with a\ndata-driven penalty performs well compared to recently advocated\nmany-instrument-robust procedures. In an empirical example dealing with the\neffect of judicial eminent domain decisions on economic outcomes, the\nLasso-based IV estimator outperforms an intuitive benchmark.\n  In developing the IV results, we establish a series of new results for Lasso\nand Post-Lasso estimators of nonparametric conditional expectation functions\nwhich are of independent theoretical and practical interest. We construct a\nmodification of Lasso designed to deal with non-Gaussian, heteroscedastic\ndisturbances which uses a data-weighted $\\ell_1$-penalty function. Using\nmoderate deviation theory for self-normalized sums, we provide convergence\nrates for the resulting Lasso and Post-Lasso estimators that are as sharp as\nthe corresponding rates in the homoscedastic Gaussian case under the condition\nthat $\\log p = o(n^{1/3})$.\n", "versions": [{"version": "v1", "created": "Thu, 21 Oct 2010 00:49:43 GMT"}, {"version": "v2", "created": "Wed, 27 Oct 2010 18:56:47 GMT"}, {"version": "v3", "created": "Thu, 26 Jul 2012 15:20:40 GMT"}, {"version": "v4", "created": "Sat, 8 Sep 2012 19:26:58 GMT"}, {"version": "v5", "created": "Sun, 19 Apr 2015 19:39:38 GMT"}], "update_date": "2017-10-05", "authors_parsed": [["Belloni", "Alexandre", ""], ["Chen", "Daniel", ""], ["Chernozhukov", "Victor", ""], ["Hansen", "Christian", ""]]}, {"id": "1010.4355", "submitter": "George Yanev", "authors": "George P. Yanev and M. Ahsanullah", "title": "Characterizations of Student's t-distribution via regressions of order\n  statistics", "comments": "To appear in \"Statistics\"", "journal-ref": null, "doi": "10.1080/02331888.2010.535904", "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Utilizing regression properties of order statistics, we characterize a family\nof distributions introduced by Akhundov, Balakrishnan, and Nevzorov (2004),\nthat includes the t-distribution with two degrees of freedom as one of its\nmembers. Then we extend this characterization result to t-distribution with\nmore than two degrees of freedom.\n", "versions": [{"version": "v1", "created": "Thu, 21 Oct 2010 03:06:44 GMT"}], "update_date": "2011-05-06", "authors_parsed": [["Yanev", "George P.", ""], ["Ahsanullah", "M.", ""]]}, {"id": "1010.4381", "submitter": "Ian W. McKeague", "authors": "Ian W. McKeague, Bodhisattva Sen", "title": "Fractals with point impact in functional linear regression", "comments": "Published in at http://dx.doi.org/10.1214/10-AOS791 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2010, Vol. 38, No. 4, 2559-2586", "doi": "10.1214/10-AOS791", "report-no": "IMS-AOS-AOS791", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper develops a point impact linear regression model in which the\ntrajectory of a continuous stochastic process, when evaluated at a sensitive\ntime point, is associated with a scalar response. The proposed model\ncomplements and is more interpretable than the functional linear regression\napproach that has become popular in recent years. The trajectories are assumed\nto have fractal (self-similar) properties in common with a fractional Brownian\nmotion with an unknown Hurst exponent. Bootstrap confidence intervals based on\nthe least-squares estimator of the sensitive time point are developed.\nMisspecification of the point impact model by a functional linear model is also\ninvestigated. Non-Gaussian limit distributions and rates of convergence\ndetermined by the Hurst exponent play an important role.\n", "versions": [{"version": "v1", "created": "Thu, 21 Oct 2010 07:27:51 GMT"}], "update_date": "2010-10-22", "authors_parsed": [["McKeague", "Ian W.", ""], ["Sen", "Bodhisattva", ""]]}, {"id": "1010.4504", "submitter": "Jose M. Pe\\~na", "authors": "Jose M. Pe\\~na", "title": "Reading Dependencies from Covariance Graphs", "comments": "Changes from v1 to v2: Minor cosmetic changes, plus the addition of\n  reference (Richardson and Spirtes, 2002) in page 8. Changes from v2 to v3:\n  Addition of some references; International Journal of Approximate Reasoning,\n  2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The covariance graph (aka bi-directed graph) of a probability distribution\n$p$ is the undirected graph $G$ where two nodes are adjacent iff their\ncorresponding random variables are marginally dependent in $p$. In this paper,\nwe present a graphical criterion for reading dependencies from $G$, under the\nassumption that $p$ satisfies the graphoid properties as well as weak\ntransitivity and composition. We prove that the graphical criterion is sound\nand complete in certain sense. We argue that our assumptions are not too\nrestrictive. For instance, all the regular Gaussian probability distributions\nsatisfy them.\n", "versions": [{"version": "v1", "created": "Thu, 21 Oct 2010 15:46:17 GMT"}, {"version": "v2", "created": "Thu, 13 Jan 2011 07:33:01 GMT"}, {"version": "v3", "created": "Tue, 26 Jun 2012 09:12:53 GMT"}], "update_date": "2012-06-27", "authors_parsed": [["Pe\u00f1a", "Jose M.", ""]]}, {"id": "1010.4515", "submitter": "Andrew Nobel", "authors": "Terrence M. Adams and Andrew B. Nobel", "title": "Uniform Approximation of Vapnik-Chervonenkis Classes", "comments": "13 pages, no figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For any family of measurable sets in a probability space, we show that either\n(i) the family has infinite Vapnik-Chervonenkis (VC) dimension or (ii) for\nevery epsilon > 0 there is a finite partition pi such the pi-boundary of each\nset has measure at most epsilon. Immediate corollaries include the fact that a\nfamily with finite VC dimension has finite bracketing numbers, and satisfies\nuniform laws of large numbers for every ergodic process. From these\ncorollaries, we derive analogous results for VC major and VC graph families of\nfunctions.\n", "versions": [{"version": "v1", "created": "Thu, 21 Oct 2010 16:22:37 GMT"}], "update_date": "2010-10-22", "authors_parsed": [["Adams", "Terrence M.", ""], ["Nobel", "Andrew B.", ""]]}, {"id": "1010.4751", "submitter": "Ignacio Ramirez", "authors": "Ignacio Ram\\'irez and Guillermo Sapiro (University of Minnesota)", "title": "Sparse coding and dictionary learning based on the MDL principle", "comments": "4 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The power of sparse signal coding with learned dictionaries has been\ndemonstrated in a variety of applications and fields, from signal processing to\nstatistical inference and machine learning. However, the statistical properties\nof these models, such as underfitting or overfitting given sets of data, are\nstill not well characterized in the literature. This work aims at filling this\ngap by means of the Minimum Description Length (MDL) principle -- a well\nestablished information-theoretic approach to statistical inference. The\nresulting framework derives a family of efficient sparse coding and modeling\n(dictionary learning) algorithms, which by virtue of the MDL principle, are\ncompletely parameter free. Furthermore, such framework allows to incorporate\nadditional prior information in the model, such as Markovian dependencies, in a\nnatural way. We demonstrate the performance of the proposed framework with\nresults for image denoising and classification tasks.\n", "versions": [{"version": "v1", "created": "Fri, 22 Oct 2010 16:31:01 GMT"}], "update_date": "2010-10-25", "authors_parsed": [["Ram\u00edrez", "Ignacio", "", "University of Minnesota"], ["Sapiro", "Guillermo", "", "University of Minnesota"]]}, {"id": "1010.4783", "submitter": "Matthieu Lerasle", "authors": "Matthieu Lerasle and Daniel Yasumasa Takahashi", "title": "An Oracle Approach for Interaction Neighborhood Estimation in Random\n  Fields", "comments": "36 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of interaction neighborhood estimation from the\npartial observation of a finite number of realizations of a random field. We\nintroduce a model selection rule to choose estimators of conditional\nprobabilities among natural candidates. Our main result is an oracle inequality\nsatisfied by the resulting estimator. We use then this selection rule in a\ntwo-step procedure to evaluate the interacting neighborhoods. The selection\nrule selects a small prior set of possible interacting points and a cutting\nstep remove from this prior set the irrelevant points. We also prove that the\nIsing models satisfy the assumptions of the main theorems, without restrictions\non the temperature, on the structure of the interacting graph or on the range\nof the interactions. It provides therefore a large class of applications for\nour results. We give a computationally efficient procedure in these models. We\nfinally show the practical efficiency of our approach in a simulation study.\n", "versions": [{"version": "v1", "created": "Fri, 22 Oct 2010 19:30:13 GMT"}], "update_date": "2010-10-25", "authors_parsed": [["Lerasle", "Matthieu", ""], ["Takahashi", "Daniel Yasumasa", ""]]}, {"id": "1010.4849", "submitter": "Mehdi Fhima", "authors": "Pierre R. Bertrand (INRIA Saclay - Ile de France), Mehdi Fhima, Arnaud\n  Guillin", "title": "Local estimation of the Hurst index of multifractional Brownian motion\n  by Increment Ratio Statistic method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate here the Central Limit Theorem of the Increment Ratio\nStatistic of a multifractional Brownian motion, leading to a CLT for the time\nvarying Hurst index. The proofs are quite simple relying on Breuer-Major\ntheorems and an original freezing of time strategy. A simulation study shows\nthe goodness of fit of this estimator.\n", "versions": [{"version": "v1", "created": "Sat, 23 Oct 2010 06:00:54 GMT"}], "update_date": "2010-10-27", "authors_parsed": [["Bertrand", "Pierre R.", "", "INRIA Saclay - Ile de France"], ["Fhima", "Mehdi", ""], ["Guillin", "Arnaud", ""]]}, {"id": "1010.5028", "submitter": "Pengsheng Ji", "authors": "Pengsheng Ji, Jiashun Jin", "title": "UPS delivers optimal phase diagram in high-dimensional variable\n  selection", "comments": "Published in at http://dx.doi.org/10.1214/11-AOS947 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2012, Vol. 40, No. 1, 73-103", "doi": "10.1214/11-AOS947", "report-no": "IMS-AOS-AOS947", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a linear model $Y=X\\beta+z$, $z\\sim N(0,I_n)$. Here, $X=X_{n,p}$,\nwhere both $p$ and $n$ are large, but $p>n$. We model the rows of $X$ as i.i.d.\nsamples from $N(0,\\frac{1}{n}\\Omega)$, where $\\Omega$ is a $p\\times p$\ncorrelation matrix, which is unknown to us but is presumably sparse. The vector\n$\\beta$ is also unknown but has relatively few nonzero coordinates, and we are\ninterested in identifying these nonzeros. We propose the Univariate\nPenalization Screeing (UPS) for variable selection. This is a screen and clean\nmethod where we screen with univariate thresholding and clean with penalized\nMLE. It has two important properties: sure screening and separable after\nscreening. These properties enable us to reduce the original regression problem\nto many small-size regression problems that can be fitted separately. The UPS\nis effective both in theory and in computation.\n", "versions": [{"version": "v1", "created": "Mon, 25 Oct 2010 01:28:18 GMT"}, {"version": "v2", "created": "Mon, 28 May 2012 10:47:01 GMT"}], "update_date": "2012-05-29", "authors_parsed": [["Ji", "Pengsheng", ""], ["Jin", "Jiashun", ""]]}, {"id": "1010.5105", "submitter": "Reinhard  Hoepfner", "authors": "Reinhard Hoepfner, Yury Kutoyants", "title": "Estimating a periodicity parameter in the drift of a time inhomogeneous\n  diffusion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a diffusion $(\\xi_t)_{t\\ge 0}$ whose drift contains some\ndeterministic periodic signal. Its shape being fixed and known, up to scaling\nin time, the periodicity of the signal is the unknown parameter $\\vartheta$ of\ninterest. We consider sequences of local models at $\\vartheta$, corresponding\nto continuous observation of the process $\\xi$ on the time interval $[0,n]$ as\n$n\\to\\infty$, with suitable choice of local scale at $\\vartheta$. Our tools\n--under an ergodicity condition-- are path segments of $\\xi$ corresponding to\nthe period $\\vartheta$, and limit theorems for certain functionals of the\nprocess $\\xi$ which are not additive functionals. When the signal is smooth,\nwith local scale $n^{-3/2}$ at $\\vartheta$, we have local asymptotic normality\n(LAN) in the sense of Le Cam (1969). When the signal has a finite number of\ndiscontinuities, with local scale $n^{-2}$ at $\\vartheta$, we obtain a limit\nexperiment of different type, studied by Ibragimov and Khasminskii (1981),\nwhere smoothness of the parametrization (in the sense of Hellinger distance) is\nH\\\"older $\\frac12$.\n", "versions": [{"version": "v1", "created": "Mon, 25 Oct 2010 12:56:15 GMT"}], "update_date": "2010-10-26", "authors_parsed": [["Hoepfner", "Reinhard", ""], ["Kutoyants", "Yury", ""]]}, {"id": "1010.5222", "submitter": "Veronique Letort", "authors": "Veronique Letort (MAS), Paul Mahe (MAS), Paul-Henry Courn\\`ede (MAS),\n  Philippe De Reffye (CIRAD), Brigitte Courtois (DAP)", "title": "Quantitative Genetics and Functional-Structural Plant Growth Models:\n  Simulation of Quantitative Trait Loci Detection for Model Parameters and\n  Application to Potential Yield Optimization", "comments": null, "journal-ref": "Annals of Botany 101, 8 (2008) 1243-1254", "doi": "10.1093/aob/mcm197", "report-no": null, "categories": "math.ST q-bio.PE stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background and Aims: Prediction of phenotypic traits from new genotypes under\nuntested environmental conditions is crucial to build simulations of breeding\nstrategies to improve target traits. Although the plant response to\nenvironmental stresses is characterized by both architectural and functional\nplasticity, recent attempts to integrate biological knowledge into genetics\nmodels have mainly concerned specific physiological processes or crop models\nwithout architecture, and thus may prove limited when studying genotype x\nenvironment interactions. Consequently, this paper presents a simulation study\nintroducing genetics into a functional-structural growth model, which gives\naccess to more fundamental traits for quantitative trait loci (QTL) detection\nand thus to promising tools for yield optimization. Methods: The GreenLab model\nwas selected as a reasonable choice to link growth model parameters to QTL.\nVirtual genes and virtual chromosomes were defined to build a simple genetic\nmodel that drove the settings of the species-specific parameters of the model.\nThe QTL Cartographer software was used to study QTL detection of simulated\nplant traits. A genetic algorithm was implemented to define the ideotype for\nyield maximization based on the model parameters and the associated allelic\ncombination. Key Results and Conclusions: By keeping the environmental factors\nconstant and using a virtual population with a large number of individuals\ngenerated by a Mendelian genetic model, results for an ideal case could be\nsimulated. Virtual QTL detection was compared in the case of phenotypic traits\n- such as cob weight - and when traits were model parameters, and was found to\nbe more accurate in the latter case. The practical interest of this approach is\nillustrated by calculating the parameters (and the corresponding genotype)\nassociated with yield optimization of a GreenLab maize model. The paper\ndiscusses the potentials of GreenLab to represent environment x genotype\ninteractions, in particular through its main state variable, the ratio of\nbiomass supply over demand.\n", "versions": [{"version": "v1", "created": "Mon, 25 Oct 2010 19:03:33 GMT"}], "update_date": "2010-10-27", "authors_parsed": [["Letort", "Veronique", "", "MAS"], ["Mahe", "Paul", "", "MAS"], ["Courn\u00e8de", "Paul-Henry", "", "MAS"], ["De Reffye", "Philippe", "", "CIRAD"], ["Courtois", "Brigitte", "", "DAP"]]}, {"id": "1010.5233", "submitter": "Jelena Bradic", "authors": "Jelena Bradic, Jianqing Fan, Jiancheng Jiang", "title": "Regularization for Cox's proportional hazards model with\n  NP-dimensionality", "comments": "Published in at http://dx.doi.org/10.1214/11-AOS911 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2011, Vol. 39, No. 6, 3092-3120", "doi": "10.1214/11-AOS911", "report-no": "IMS-AOS-AOS911", "categories": "math.ST stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High throughput genetic sequencing arrays with thousands of measurements per\nsample and a great amount of related censored clinical data have increased\ndemanding need for better measurement specific model selection. In this paper\nwe establish strong oracle properties of nonconcave penalized methods for\nnonpolynomial (NP) dimensional data with censoring in the framework of Cox's\nproportional hazards model. A class of folded-concave penalties are employed\nand both LASSO and SCAD are discussed specifically. We unveil the question\nunder which dimensionality and correlation restrictions can an oracle estimator\nbe constructed and grasped. It is demonstrated that nonconcave penalties lead\nto significant reduction of the \"irrepresentable condition\" needed for LASSO\nmodel selection consistency. The large deviation result for martingales,\nbearing interests of its own, is developed for characterizing the strong oracle\nproperty. Moreover, the nonconcave regularized estimator, is shown to achieve\nasymptotically the information bound of the oracle estimator. A coordinate-wise\nalgorithm is developed for finding the grid of solution paths for penalized\nhazard regression problems, and its performance is evaluated on simulated and\ngene association study examples.\n", "versions": [{"version": "v1", "created": "Mon, 25 Oct 2010 19:51:46 GMT"}, {"version": "v2", "created": "Tue, 26 Oct 2010 00:24:07 GMT"}, {"version": "v3", "created": "Fri, 25 May 2012 10:39:39 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Bradic", "Jelena", ""], ["Fan", "Jianqing", ""], ["Jiang", "Jiancheng", ""]]}, {"id": "1010.5605", "submitter": "Luis Fuentes Garcia", "authors": "Martin Egozcue, Luis Fuentes Garcia, Wing-Keung Wong, Ricardas Zitikis", "title": "Revisiting Gruss's inequality: covariance bounds,QDE but not QD copulas,\n  and central moments", "comments": "25 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since the pioneering work of Gerhard Gruss dating back to 1935, Gruss's\ninequality and, more generally, Gruss-type bounds for covariances have\nfascinated researchers and found numerous applications in areas such as\neconomics, insurance, reliability, and, more generally, decision making under\nuncertainly. Gruss-type bounds for covariances have been established mainly\nunder most general dependence structures, meaning no restrictions on the\ndependence structure between the two underlying random variables. Recent work\nin the area has revealed a potential for improving Gruss-type bounds, including\nthe original Gruss's bound, assuming dependence structures such as quadrant\ndependence (QD). In this paper we demonstrate that the relatively little\nexplored notion of `quadrant dependence in expectation' (QDE) is ideally suited\nin the context of bounding covariances, especially those that appear in the\naforementioned areas of application. We explore this research avenue in detail,\nestablish general Gruss-type bounds, and illustrate them with newly constructed\nexamples of bivariate distributions, which are not QD but, nevertheless, are\nQDE. The examples rely on specially devised copulas. We supplement the examples\nwith results concerning general copulas and their convex combinations. In the\nprocess of deriving Gruss-type bounds, we also establish new bounds for central\nmoments, whose optimality is demonstrated.\n", "versions": [{"version": "v1", "created": "Wed, 27 Oct 2010 08:36:54 GMT"}], "update_date": "2010-10-28", "authors_parsed": [["Egozcue", "Martin", ""], ["Garcia", "Luis Fuentes", ""], ["Wong", "Wing-Keung", ""], ["Zitikis", "Ricardas", ""]]}, {"id": "1010.5626", "submitter": "Johannes Lederer", "authors": "Johannes Christof Lederer", "title": "Bounds for Rademacher Processes via Chaining", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study Rademacher processes where the coefficients are functions evaluated\nat fixed, but arbitrary covariables. Specifically, we assume the function class\nunder consideration to be parametrized by the standard cocube in l dimensions\nand we are mainly interested in the high-dimensional, asymptotic situation,\nthat is, l as well the number of Rademacher variables n go to infinity with l\nmuch larger than n. We refine and apply classical entropy bounds and Majorizing\nMeasures, both going back to the well known idea of chaining. That way, we\nderive general upper bounds for Rademacher processes. In the linear case and\nunder high correlations, we further improve on these bounds. In particular, we\ngive bounds independent of l for highly correlated covariables.\n", "versions": [{"version": "v1", "created": "Wed, 27 Oct 2010 09:41:53 GMT"}, {"version": "v2", "created": "Tue, 9 Nov 2010 17:43:06 GMT"}], "update_date": "2010-11-10", "authors_parsed": [["Lederer", "Johannes Christof", ""]]}, {"id": "1010.6056", "submitter": "Xu Han", "authors": "Jianqing Fan, Xu Han and Weijie Gu", "title": "Estimating False Discovery Proportion Under Arbitrary Covariance\n  Dependence", "comments": "51 pages, 7 figures. arXiv admin note: substantial text overlap with\n  arXiv:1012.4397", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Multiple hypothesis testing is a fundamental problem in high dimensional\ninference, with wide applications in many scientific fields. In genome-wide\nassociation studies, tens of thousands of tests are performed simultaneously to\nfind if any SNPs are associated with some traits and those tests are\ncorrelated. When test statistics are correlated, false discovery control\nbecomes very challenging under arbitrary dependence. In the current paper, we\npropose a novel method based on principal factor approximation, which\nsuccessfully subtracts the common dependence and weakens significantly the\ncorrelation structure, to deal with an arbitrary dependence structure. We\nderive an approximate expression for false discovery proportion (FDP) in large\nscale multiple testing when a common threshold is used and provide a consistent\nestimate of realized FDP. This result has important applications in controlling\nFDR and FDP. Our estimate of realized FDP compares favorably with Efron\n(2007)'s approach, as demonstrated in the simulated examples. Our approach is\nfurther illustrated by some real data applications. We also propose a\ndependence-adjusted procedure, which is more powerful than the fixed threshold\nprocedure.\n", "versions": [{"version": "v1", "created": "Thu, 28 Oct 2010 19:11:55 GMT"}, {"version": "v2", "created": "Tue, 15 Nov 2011 05:05:50 GMT"}], "update_date": "2011-11-16", "authors_parsed": [["Fan", "Jianqing", ""], ["Han", "Xu", ""], ["Gu", "Weijie", ""]]}, {"id": "1010.6118", "submitter": "Nevena Maric", "authors": "Vanja Dukic and Nevena Maric", "title": "On minimum correlation in construction of multivariate distributions", "comments": "Major changes made compared to previous versions. Minimum\n  correlations and Multivariate methods added. 10 pages, 5 figures", "journal-ref": "Phys. Rev. E , Volume 87, Issue 3: 032114 (2013)", "doi": null, "report-no": null, "categories": "math.PR math.ST stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a method for exact generation of multivariate\nsamples with pre-specified marginal distributions and a given correlation\nmatrix, based on a mixture of Fr\\'echet-Hoeffding bounds and marginal products.\nThe bivariate algorithm can accommodate any among the theoretically possible\ncorrelation coefficients, and explicitly provides a connection between\nsimulation and the minimum correlation attainable for different distribution\nfamilies. We calculate the minimum correlations in several common\ndistributional examples, including in some that have not been looked at before.\nAs an illustration, we provide the details and results of implementing the\nalgorithm for generating three-dimensional negatively and positively correlated\nBeta random variables, making it the only non-copula algorithm for correlated\nBeta simulation in dimensions greater than two. This work has potential for\nimpact in a variety of fields where simulation of multivariate stochastic\ncomponents is desired.\n", "versions": [{"version": "v1", "created": "Fri, 29 Oct 2010 02:41:43 GMT"}, {"version": "v2", "created": "Thu, 23 Aug 2012 02:17:53 GMT"}, {"version": "v3", "created": "Tue, 19 Feb 2013 22:30:29 GMT"}], "update_date": "2013-03-18", "authors_parsed": [["Dukic", "Vanja", ""], ["Maric", "Nevena", ""]]}, {"id": "1010.6120", "submitter": "Jingchen Liu", "authors": "Jingchen Liu, Gongjun Xu, Zhiliang Ying", "title": "Theory of self-learning $Q$-matrix", "comments": "Published in at http://dx.doi.org/10.3150/12-BEJ430 the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2013, Vol. 19, No. 5A, 1790-1817", "doi": "10.3150/12-BEJ430", "report-no": "IMS-BEJ-BEJ430", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cognitive assessment is a growing area in psychological and educational\nmeasurement, where tests are given to assess mastery/deficiency of attributes\nor skills. A key issue is the correct identification of attributes associated\nwith items in a test. In this paper, we set up a mathematical framework under\nwhich theoretical properties may be discussed. We establish sufficient\nconditions to ensure that the attributes required by each item are learnable\nfrom the data.\n", "versions": [{"version": "v1", "created": "Fri, 29 Oct 2010 03:43:40 GMT"}, {"version": "v2", "created": "Fri, 8 Apr 2011 16:08:44 GMT"}, {"version": "v3", "created": "Tue, 10 Dec 2013 14:10:09 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Liu", "Jingchen", ""], ["Xu", "Gongjun", ""], ["Ying", "Zhiliang", ""]]}, {"id": "1010.6202", "submitter": "Ansgar Steland", "authors": "Ansgar Steland", "title": "Sequential Data-Adaptive Bandwidth Selection by Cross-Validation for\n  Nonparametric Prediction", "comments": "26 pages", "journal-ref": "Communications in Statistics - Simulation and Computation, Volume\n  41, 2012 - Issue 7, 1195-1219,", "doi": "10.1080/03610918.2012.625853", "report-no": null, "categories": "math.ST math.PR stat.AP stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of bandwidth selection by cross-validation from a\nsequential point of view in a nonparametric regression model. Having in mind\nthat in applications one often aims at estimation, prediction and change\ndetection simultaneously, we investigate that approach for sequential kernel\nsmoothers in order to base these tasks on a single statistic. We provide\nuniform weak laws of large numbers and weak consistency results for the\ncross-validated bandwidth. Extensions to weakly dependent error terms are\ndiscussed as well. The errors may be {\\alpha}-mixing or L2-near epoch\ndependent, which guarantees that the uniform convergence of the cross\nvalidation sum and the consistency of the cross-validated bandwidth hold true\nfor a large class of time series. The method is illustrated by analyzing\nphotovoltaic data.\n", "versions": [{"version": "v1", "created": "Fri, 29 Oct 2010 13:29:55 GMT"}], "update_date": "2018-03-20", "authors_parsed": [["Steland", "Ansgar", ""]]}, {"id": "1010.6209", "submitter": "Stephane Gaiffas", "authors": "Sylvain Delattre (PMA), St\\'ephane Ga\\\"iffas (LSTA)", "title": "Nonparametric regression with martingale increment errors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of adaptive estimation of the regression function in\na framework where we replace ergodicity assumptions (such as independence or\nmixing) by another structural assumption on the model. Namely, we propose\nadaptive upper bounds for kernel estimators with data-driven bandwidth\n(Lepski's selection rule) in a regression model where the noise is an increment\nof martingale. It includes, as very particular cases, the usual i.i.d.\nregression and auto-regressive models. The cornerstone tool for this study is a\nnew result for self-normalized martingales, called ``stability'', which is of\nindependent interest. In a first part, we only use the martingale increment\nstructure of the noise. We give an adaptive upper bound using a random rate,\nthat involves the occupation time near the estimation point. Thanks to this\napproach, the theoretical study of the statistical procedure is disconnected\nfrom usual ergodicity properties like mixing. Then, in a second part, we make a\nlink with the usual minimax theory of deterministic rates. Under a beta-mixing\nassumption on the covariates process, we prove that the random rate considered\nin the first part is equivalent, with large probability, to a deterministic\nrate which is the usual minimax adaptive one.\n", "versions": [{"version": "v1", "created": "Fri, 29 Oct 2010 13:53:19 GMT"}], "update_date": "2010-11-03", "authors_parsed": [["Delattre", "Sylvain", "", "PMA"], ["Ga\u00efffas", "St\u00e9phane", "", "LSTA"]]}, {"id": "1010.6227", "submitter": "Christine Malot", "authors": "Jean-Michel Poggi (LM-Orsay, INRIA Saclay - Ile de France), Christine\n  Tuleau (LM-Orsay)", "title": "Classification supervis\\'ee en grande dimension. Application \\`a\n  l'agr\\'ement de conduite automobile", "comments": null, "journal-ref": "Revue de Statistique Appliqu\\'ee LIV, 4 (2006) 41-60", "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work is motivated by a real work problem: objectivization. It consists\nin explaining the subjective drivability using physical criteria coming from\nsignals measured during experiments. We suggest an approach for the\ndiscriminant variables selection trying to take advantage of the functional\nnature of the data. The porblem is ill-posed, since the number of explanatory\nvariables is hugely greater than the sample size. The strategy proceeds in\nthree steps: a signal preprocessing including wavelet denoising and\nsynchronization, dimensionality reduction by compression using a common wavelet\nbasis, and finally the selection of useful variables using a stepwise strategy\ninvolving successive applications of the CART method.\n", "versions": [{"version": "v1", "created": "Fri, 29 Oct 2010 14:37:20 GMT"}], "update_date": "2010-11-03", "authors_parsed": [["Poggi", "Jean-Michel", "", "LM-Orsay, INRIA Saclay - Ile de France"], ["Tuleau", "Christine", "", "LM-Orsay"]]}]