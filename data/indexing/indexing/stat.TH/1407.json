[{"id": "1407.0013", "submitter": "Martin Sundin", "authors": "Martin Sundin, Saikat Chatterjee, Magnus Jansson and Cristian R. Rojas", "title": "Relevance Singular Vector Machine for low-rank matrix sensing", "comments": "International Conference on Signal Processing and Communications\n  (SPCOM), 5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we develop a new Bayesian inference method for low rank matrix\nreconstruction. We call the new method the Relevance Singular Vector Machine\n(RSVM) where appropriate priors are defined on the singular vectors of the\nunderlying matrix to promote low rank. To accelerate computations, a\nnumerically efficient approximation is developed. The proposed algorithms are\napplied to matrix completion and matrix reconstruction problems and their\nperformance is studied numerically.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jun 2014 12:19:17 GMT"}], "update_date": "2014-07-02", "authors_parsed": [["Sundin", "Martin", ""], ["Chatterjee", "Saikat", ""], ["Jansson", "Magnus", ""], ["Rojas", "Cristian R.", ""]]}, {"id": "1407.0067", "submitter": "Kamalika Chaudhuri", "authors": "Kamalika Chaudhuri and Sanjoy Dasgupta", "title": "Rates of Convergence for Nearest Neighbor Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nearest neighbor methods are a popular class of nonparametric estimators with\nseveral desirable properties, such as adaptivity to different distance scales\nin different regions of space. Prior work on convergence rates for nearest\nneighbor classification has not fully reflected these subtle properties. We\nanalyze the behavior of these estimators in metric spaces and provide\nfinite-sample, distribution-dependent rates of convergence under minimal\nassumptions. As a by-product, we are able to establish the universal\nconsistency of nearest neighbor in a broader range of data spaces than was\npreviously known. We illustrate our upper and lower bounds by introducing\nsmoothness classes that are customized for nearest neighbor classification.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jun 2014 22:00:57 GMT"}, {"version": "v2", "created": "Wed, 2 Jul 2014 00:44:29 GMT"}], "update_date": "2014-07-03", "authors_parsed": [["Chaudhuri", "Kamalika", ""], ["Dasgupta", "Sanjoy", ""]]}, {"id": "1407.0158", "submitter": "Masayo Yoshimori", "authors": "Masayo Yoshimori, Partha Lahiri", "title": "A second-order efficient empirical Bayes confidence interval", "comments": "Published in at http://dx.doi.org/10.1214/14-AOS1219 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics, Vol. 42, No. 4, 1233-1261 (2014)", "doi": "10.1214/14-AOS1219", "report-no": "IMS-AOS-AOS1219", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new adjusted residual maximum likelihood method (REML) in the\ncontext of producing an empirical Bayes (EB) confidence interval for a normal\nmean, a problem of great interest in different small area applications. Like\nother rival empirical Bayes confidence intervals such as the well-known\nparametric bootstrap empirical Bayes method, the proposed interval is\nsecond-order correct, that is, the proposed interval has a coverage error of\norder $O(m^{-{3}/{2}})$. Moreover, the proposed interval is carefully\nconstructed so that it always produces an interval shorter than the\ncorresponding direct confidence interval, a property not analytically proved\nfor other competing methods that have the same coverage error of order\n$O(m^{-{3}/{2}})$. The proposed method is not simulation-based and requires\nonly a fraction of computing time needed for the corresponding parametric\nbootstrap empirical Bayes confidence interval. A Monte Carlo simulation study\ndemonstrates the superiority of the proposed method over other competing\nmethods.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jul 2014 09:36:56 GMT"}, {"version": "v2", "created": "Thu, 28 Aug 2014 06:11:38 GMT"}], "update_date": "2014-08-29", "authors_parsed": [["Yoshimori", "Masayo", ""], ["Lahiri", "Partha", ""]]}, {"id": "1407.0185", "submitter": "Lilun Du", "authors": "Lilun Du, Chunming Zhang", "title": "Single-index modulated multiple testing", "comments": "Published in at http://dx.doi.org/10.1214/14-AOS1222 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2014, Vol. 42, No. 4, 1262-1311", "doi": "10.1214/14-AOS1222", "report-no": "IMS-AOS-AOS1222", "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of large-scale multiple testing, hypotheses are often\naccompanied with certain prior information. In this paper, we present a\nsingle-index modulated (SIM) multiple testing procedure, which maintains\ncontrol of the false discovery rate while incorporating prior information, by\nassuming the availability of a bivariate $p$-value, $(p_1,p_2)$, for each\nhypothesis, where $p_1$ is a preliminary $p$-value from prior information and\n$p_2$ is the primary $p$-value for the ultimate analysis. To find the optimal\nrejection region for the bivariate $p$-value, we propose a criteria based on\nthe ratio of probability density functions of $(p_1,p_2)$ under the true null\nand nonnull. This criteria in the bivariate normal setting further motivates us\nto project the bivariate $p$-value to a single-index, $p(\\theta)$, for a wide\nrange of directions $\\theta$. The true null distribution of $p(\\theta)$ is\nestimated via parametric and nonparametric approaches, leading to two\nprocedures for estimating and controlling the false discovery rate. To derive\nthe optimal projection direction $\\theta$, we propose a new approach based on\npower comparison, which is further shown to be consistent under some mild\nconditions. Simulation evaluations indicate that the SIM multiple testing\nprocedure improves the detection power significantly while controlling the\nfalse discovery rate. Analysis of a real dataset will be illustrated.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jul 2014 10:57:15 GMT"}], "update_date": "2014-07-02", "authors_parsed": [["Du", "Lilun", ""], ["Zhang", "Chunming", ""]]}, {"id": "1407.0204", "submitter": "Yuanzhen He", "authors": "Yuanzhen He, Boxin Tang", "title": "A characterization of strong orthogonal arrays of strength three", "comments": "Published in at http://dx.doi.org/10.1214/14-AOS1225 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics, Vol. 42, No. 4, 1347-1360 (2014)", "doi": "10.1214/14-AOS1225", "report-no": "IMS-AOS-AOS1225", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In an early paper, He and Tang [Biometrika 100 (2013) 254-260] introduced and\nstudied a new class of designs, strong orthogonal arrays, for computer\nexperiments, and characterized such arrays through generalized orthogonal\narrays. The current paper presents a simple characterization for strong\northogonal arrays of strength three. Besides being simple, this new\ncharacterization through a notion of semi-embeddability is more direct and\npenetrating in terms of revealing the structure of strong orthogonal arrays.\nSome other results on strong orthogonal arrays of strength three are also\nobtained along the way, and in particular, two $\\operatorname\n{SOA}(54,5,27,3)$'s are constructed.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jul 2014 11:52:27 GMT"}, {"version": "v2", "created": "Thu, 28 Aug 2014 06:28:57 GMT"}], "update_date": "2014-08-29", "authors_parsed": [["He", "Yuanzhen", ""], ["Tang", "Boxin", ""]]}, {"id": "1407.0215", "submitter": "Xian Chen", "authors": "Xian Chen, Zhi-Ming Ma, Ying Wang", "title": "Markov jump processes in modeling coalescent with recombination", "comments": "Published in at http://dx.doi.org/10.1214/14-AOS1227 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2014, Vol. 42, No. 4, 1361-1393", "doi": "10.1214/14-AOS1227", "report-no": "IMS-AOS-AOS1227", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Genetic recombination is one of the most important mechanisms that can\ngenerate and maintain diversity, and recombination information plays an\nimportant role in population genetic studies. However, the phenomenon of\nrecombination is extremely complex, and hence simulation methods are\nindispensable in the statistical inference of recombination. So far there are\nmainly two classes of simulation models practically in wide use: back-in-time\nmodels and spatially moving models. However, the statistical properties shared\nby the two classes of simulation models have not yet been theoretically\nstudied. Based on our joint research with CAS-MPG Partner Institute for\nComputational Biology and with Beijing Jiaotong University, in this paper we\nprovide for the first time a rigorous argument that the statistical properties\nof the two classes of simulation models are identical. That is, they share the\nsame probability distribution on the space of ancestral recombination graphs\n(ARGs). As a consequence, our study provides a unified interpretation for the\nalgorithms of simulating coalescent with recombination, and will facilitate the\nstudy of statistical inference on recombination.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jul 2014 12:37:16 GMT"}, {"version": "v2", "created": "Thu, 28 Aug 2014 06:58:22 GMT"}], "update_date": "2014-08-29", "authors_parsed": [["Chen", "Xian", ""], ["Ma", "Zhi-Ming", ""], ["Wang", "Ying", ""]]}, {"id": "1407.0241", "submitter": "Emmanuelle Cl\\'{e}ment", "authors": "Emmanuelle Cl\\'ement, Sylvain Delattre, Arnaud Gloter", "title": "Asymptotic lower bounds in estimating jumps", "comments": "Published in at http://dx.doi.org/10.3150/13-BEJ515 the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2014, Vol. 20, No. 3, 1059-1096", "doi": "10.3150/13-BEJ515", "report-no": "IMS-BEJ-BEJ515", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of the efficient estimation of the jumps for stochastic\nprocesses. We assume that the stochastic jump process $(X_t)_{t\\in[0,1]}$ is\nobserved discretely, with a sampling step of size $1/n$. In the spirit of\nHajek's convolution theorem, we show some lower bounds for the estimation error\nof the sequence of the jumps $(\\Delta X_{T_k})_k$. As an intermediate result,\nwe prove a LAMN property, with rate $\\sqrt{n}$, when the marks of the\nunderlying jump component are deterministic. We deduce then a convolution\ntheorem, with an explicit asymptotic minimal variance, in the case where the\nmarks of the jump component are random. To prove that this lower bound is\noptimal, we show that a threshold estimator of the sequence of jumps $(\\Delta\nX_{T_k})_k$ based on the discrete observations, reaches the minimal variance of\nthe previous convolution theorem.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jul 2014 13:52:16 GMT"}], "update_date": "2014-07-02", "authors_parsed": [["Cl\u00e9ment", "Emmanuelle", ""], ["Delattre", "Sylvain", ""], ["Gloter", "Arnaud", ""]]}, {"id": "1407.0249", "submitter": "Jean-Fran\\c{c}ois Coeurjolly", "authors": "Jean-Fran\\c{c}ois Coeurjolly, Jesper M{\\o}ller", "title": "Variational approach for spatial point process intensity estimation", "comments": "Published in at http://dx.doi.org/10.3150/13-BEJ516 the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2014, Vol. 20, No. 3, 1097-1125", "doi": "10.3150/13-BEJ516", "report-no": "IMS-BEJ-BEJ516", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new variational estimator for the intensity function of an\ninhomogeneous spatial point process with points in the $d$-dimensional\nEuclidean space and observed within a bounded region. The variational estimator\napplies in a simple and general setting when the intensity function is assumed\nto be of log-linear form $\\beta+{\\theta }^{\\top}z(u)$ where $z$ is a spatial\ncovariate function and the focus is on estimating ${\\theta }$. The variational\nestimator is very simple to implement and quicker than alternative estimation\nprocedures. We establish its strong consistency and asymptotic normality. We\nalso discuss its finite-sample properties in comparison with the maximum first\norder composite likelihood estimator when considering various inhomogeneous\nspatial point process models and dimensions as well as settings were $z$ is\ncompletely or only partially known.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jul 2014 14:16:51 GMT"}], "update_date": "2014-07-02", "authors_parsed": [["Coeurjolly", "Jean-Fran\u00e7ois", ""], ["M\u00f8ller", "Jesper", ""]]}, {"id": "1407.0335", "submitter": "Jean-Bernard Salomond", "authors": "Bartek Knapik and Jean-Bernard Salomond", "title": "A general approach to posterior contraction in nonparametric inverse\n  problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a general method to derive an upper bound for the\ncontraction rate of the posterior distribution for nonparametric inverse\nproblems. We present a general theorem that allows us to derive con- traction\nrates for the parameter of interest from contraction rates of the related\ndirect problem of estimating transformed parameter of interest. An interesting\naspect of this approach is that it allows us to derive con- traction rates for\npriors that are not related to the singular value decomposition of the\noperator. We apply our result to several examples of linear inverse problems,\nboth in the white noise sequence model and the nonparametric regression model,\nusing priors based on the singular value decomposition of the operator,\nlocation-mixture priors and splines prior, and recover minimax adaptive\ncontraction rates.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jul 2014 17:56:32 GMT"}, {"version": "v2", "created": "Fri, 22 May 2015 12:22:03 GMT"}, {"version": "v3", "created": "Mon, 23 Jan 2017 13:06:54 GMT"}], "update_date": "2017-01-24", "authors_parsed": [["Knapik", "Bartek", ""], ["Salomond", "Jean-Bernard", ""]]}, {"id": "1407.0381", "submitter": "Yihong Wu", "authors": "Yihong Wu and Pengkun Yang", "title": "Minimax rates of entropy estimation on large alphabets via best\n  polynomial approximation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider the problem of estimating the Shannon entropy of a distribution over\n$k$ elements from $n$ independent samples. We show that the minimax mean-square\nerror is within universal multiplicative constant factors of $$\\Big(\\frac{k }{n\n\\log k}\\Big)^2 + \\frac{\\log^2 k}{n}$$ if $n$ exceeds a constant factor of\n$\\frac{k}{\\log k}$; otherwise there exists no consistent estimator. This\nrefines the recent result of Valiant-Valiant \\cite{VV11} that the minimal\nsample size for consistent entropy estimation scales according to\n$\\Theta(\\frac{k}{\\log k})$. The apparatus of best polynomial approximation\nplays a key role in both the construction of optimal estimators and, via a\nduality argument, the minimax lower bound.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jul 2014 19:51:11 GMT"}, {"version": "v2", "created": "Sat, 31 Jan 2015 20:27:53 GMT"}, {"version": "v3", "created": "Thu, 18 Feb 2016 04:30:02 GMT"}], "update_date": "2016-02-19", "authors_parsed": [["Wu", "Yihong", ""], ["Yang", "Pengkun", ""]]}, {"id": "1407.0471", "submitter": "Taras Bodnar", "authors": "Taras Bodnar and Markus Reiss", "title": "Exact and Asymptotic Tests on a Factor Model in Low and Large Dimensions\n  with Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the paper, we suggest three tests on the validity of a factor model which\ncan be applied for both small dimensional and large dimensional data. Both the\nexact and asymptotic distributions of the resulting test statistics are derived\nunder classical and high-dimensional asymptotic regimes. It is shown that the\ncritical values of the proposed tests can be calibrated empirically by\ngenerating a sample from the inverse Wishart distribution with identity\nparameter matrix. The powers of the suggested tests are investigated by means\nof simulations. The results of the simulation study are consistent with the\ntheoretical findings and provide general recommendations about the application\nof each of the three tests. Finally, the theoretical results are applied to two\nreal data sets, which consist of returns on stocks from the DAX index and on\nstocks from the S&P 500 index. Our empirical results do not support the\nhypothesis that all linear dependencies between the returns can be entirely\ncaptured by the factors considered in the paper.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jul 2014 07:21:05 GMT"}, {"version": "v2", "created": "Wed, 21 Oct 2015 11:19:13 GMT"}, {"version": "v3", "created": "Thu, 23 Jun 2016 19:22:24 GMT"}], "update_date": "2016-06-24", "authors_parsed": [["Bodnar", "Taras", ""], ["Reiss", "Markus", ""]]}, {"id": "1407.0482", "submitter": "Antonio Lijoi", "authors": "Antonio Lijoi, Bernardo Nipoti, Igor Pr\\\"unster", "title": "Bayesian inference with dependent normalized completely random measures", "comments": "Published in at http://dx.doi.org/10.3150/13-BEJ521 the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2014, Vol. 20, No. 3, 1260-1291", "doi": "10.3150/13-BEJ521", "report-no": "IMS-BEJ-BEJ521", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The proposal and study of dependent prior processes has been a major research\nfocus in the recent Bayesian nonparametric literature. In this paper, we\nintroduce a flexible class of dependent nonparametric priors, investigate their\nproperties and derive a suitable sampling scheme which allows their concrete\nimplementation. The proposed class is obtained by normalizing dependent\ncompletely random measures, where the dependence arises by virtue of a suitable\nconstruction of the Poisson random measures underlying the completely random\nmeasures. We first provide general distributional results for the whole class\nof dependent completely random measures and then we specialize them to two\nspecific priors, which represent the natural candidates for concrete\nimplementation due to their analytic tractability: the bivariate Dirichlet and\nnormalized $\\sigma$-stable processes. Our analytical results, and in particular\nthe partially exchangeable partition probability function, form also the basis\nfor the determination of a Markov Chain Monte Carlo algorithm for drawing\nposterior inferences, which reduces to the well-known Blackwell--MacQueen\nP\\'{o}lya urn scheme in the univariate case. Such an algorithm can be used for\ndensity estimation and for analyzing the clustering structure of the data and\nis illustrated through a real two-sample dataset example.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jul 2014 08:42:33 GMT"}], "update_date": "2014-07-03", "authors_parsed": [["Lijoi", "Antonio", ""], ["Nipoti", "Bernardo", ""], ["Pr\u00fcnster", "Igor", ""]]}, {"id": "1407.0726", "submitter": "Yao Xie", "authors": "Yang Cao and Yao Xie", "title": "Fast Algorithm for Low-rank matrix recovery in Poisson noise", "comments": "Presented at IEEE GLOBALSIP2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a fast algorithm for recovering low-rank matrices from\ntheir linear measurements contaminated with Poisson noise: the Poisson noise\nMaximum Likelihood Singular Value thresholding (PMLSV) algorithm. We propose a\nconvex optimization formulation with a cost function consisting of the sum of a\nlikelihood function and a regularization function which the nuclear norm of the\nmatrix. Instead of solving the optimization problem directly by semi-definite\nprogram (SDP), we derive an iterative singular value thresholding algorithm by\nexpanding the likelihood function. We demonstrate the good performance of the\nproposed algorithm on recovery of solar flare images with Poisson noise: the\nalgorithm is more efficient than solving SDP using the interior-point algorithm\nand it generates a good approximate solution compared to that solved from SDP.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jul 2014 21:27:23 GMT"}, {"version": "v2", "created": "Fri, 19 Dec 2014 20:11:13 GMT"}], "update_date": "2014-12-22", "authors_parsed": [["Cao", "Yang", ""], ["Xie", "Yao", ""]]}, {"id": "1407.0731", "submitter": "Yao Xie", "authors": "Gabor Braun, Sebastian Pokutta, and Yao Xie", "title": "Info-Greedy sequential adaptive compressed sensing", "comments": "Preliminary results presented at Allerton Conference 2014. To appear\n  in IEEE Journal Selected Topics on Signal Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an information-theoretic framework for sequential adaptive\ncompressed sensing, Info-Greedy Sensing, where measurements are chosen to\nmaximize the extracted information conditioned on the previous measurements. We\nshow that the widely used bisection approach is Info-Greedy for a family of\n$k$-sparse signals by connecting compressed sensing and blackbox complexity of\nsequential query algorithms, and present Info-Greedy algorithms for Gaussian\nand Gaussian Mixture Model (GMM) signals, as well as ways to design sparse\nInfo-Greedy measurements. Numerical examples demonstrate the good performance\nof the proposed algorithms using simulated and real data: Info-Greedy Sensing\nshows significant improvement over random projection for signals with sparse\nand low-rank covariance matrices, and adaptivity brings robustness when there\nis a mismatch between the assumed and the true distributions.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jul 2014 22:03:28 GMT"}, {"version": "v2", "created": "Wed, 22 Oct 2014 03:34:11 GMT"}, {"version": "v3", "created": "Mon, 24 Nov 2014 02:20:52 GMT"}, {"version": "v4", "created": "Mon, 2 Feb 2015 08:10:38 GMT"}], "update_date": "2015-02-03", "authors_parsed": [["Braun", "Gabor", ""], ["Pokutta", "Sebastian", ""], ["Xie", "Yao", ""]]}, {"id": "1407.0743", "submitter": "Ali Akbar Jafari", "authors": "Ali Akbar Jafari, Saeid Tahmasebi, Morad Alizadeh", "title": "The Beta-Gompertz Distribution", "comments": "http://www.emis.de/journals/RCE/ingles/v37_1.html", "journal-ref": "Colombian Journal of Statistics (Revista Colombiana de\n  Estad\\'istica), 37(1), 139-157, 2014", "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a new four-parameter generalized version of the\nGompertz model which is called Beta-Gompertz (BG) distribution. It includes\nsome well-known lifetime distributions such as beta-exponential and generalized\nGompertz distributions as special sub-models. This new distribution is quite\nflexible and can be used effectively in modeling survival data and reliability\nproblems. It can have a decreasing, increasing, and bathtub-shaped failure rate\nfunction depending on its parameters. Some mathematical properties of the new\ndistribution, such as closed-form expressions for the density, cumulative\ndistribution, hazard rate function, the $k$th order moment, moment generating\nfunction, Shannon entropy, and the quantile measure are provided. We discuss\nmaximum likelihood estimation of the BG parameters from one observed sample and\nderive the observed Fisher's information matrix. A simulation study is\nperformed in order to investigate this proposed estimator for parameters. At\nthe end, in order to show the BG distribution flexibility, an application using\na real data set is presented.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jul 2014 23:03:44 GMT"}], "update_date": "2014-07-04", "authors_parsed": [["Jafari", "Ali Akbar", ""], ["Tahmasebi", "Saeid", ""], ["Alizadeh", "Morad", ""]]}, {"id": "1407.0836", "submitter": "Matthias Gorny", "authors": "Rapha\\\"el Cerf and Matthias Gorny", "title": "A Lower Bound on the Relative Entropy with Respect to a Symmetric\n  Probability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $\\rho$ and $\\mu$ be two probability measures on $\\mathbb{R}$ which are\nnot the Dirac mass at $0$. We denote by $H(\\mu|\\rho)$ the relative entropy of\n$\\mu$ with respect to $\\rho$. We prove that, if $\\rho$ is symmetric and $\\mu$\nhas a finite first moment, then \\[ H(\\mu|\\rho)\\geq\n\\frac{\\displaystyle{(\\int_{\\mathbb{R}}z\\,d\\mu(z))^2}}{\\displaystyle{2\\int_{\\mathbb{R}}z^2\\,d\\mu(z)}}\\,,\\]\nwith equality if and only if $\\mu=\\rho$.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jul 2014 09:41:39 GMT"}, {"version": "v2", "created": "Mon, 20 Oct 2014 12:47:00 GMT"}], "update_date": "2014-10-21", "authors_parsed": [["Cerf", "Rapha\u00ebl", ""], ["Gorny", "Matthias", ""]]}, {"id": "1407.0839", "submitter": "Matthias Gorny", "authors": "Rapha\\\"el Cerf and Matthias Gorny", "title": "An Exponential Inequality for Symmetric Random Variables", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove the following exponential inequality: Let $n\\geq 1$ and let\n$X_1,...,X_n$ be $n$ independent identically distributed symmetric real-valued\nrandom variables. For any $x,y>0$, we have \\[\\mathbb{P}\\big({X_1+...+X_n}\\geq\nx,\\, {X_1^2+...+X_n^2}\\leq y\\big)< \\exp(-\\frac{x^2}{2y})\\,.\\]\n", "versions": [{"version": "v1", "created": "Thu, 3 Jul 2014 09:50:20 GMT"}, {"version": "v2", "created": "Mon, 20 Oct 2014 12:58:00 GMT"}], "update_date": "2014-10-21", "authors_parsed": [["Cerf", "Rapha\u00ebl", ""], ["Gorny", "Matthias", ""]]}, {"id": "1407.0873", "submitter": "Denis Belomestny", "authors": "Denis Belomestny and John Schoenmakers", "title": "Statistical Skorohod embedding problem and its generalizations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a L\\'evy process $L$, we consider the so-called statistical Skorohod\nembedding problem of recovering the distribution of an independent random time\n$T$ based on i.i.d. sample from $L_{T}.$ Our approach is based on the genuine\nuse of the Mellin and Laplace transforms. We propose a consistent estimator for\nthe density of $T,$ derive its convergence rates and prove their optimality. It\nturns out that the convergence rates heavily depend on the decay of the Mellin\ntransform of $T.$ We also consider the application of our results to the\nproblem of statistical inference for variance-mean mixture models and for\ntime-changed L\\'evy processes.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jul 2014 11:40:34 GMT"}], "update_date": "2014-07-04", "authors_parsed": [["Belomestny", "Denis", ""], ["Schoenmakers", "John", ""]]}, {"id": "1407.1004", "submitter": "Despina Stasi", "authors": "Despina Stasi and Kayvan Sadeghi and Alessandro Rinaldo and Sonja\n  Petrovi\\'c and Stephen E. Fienberg", "title": "$\\beta$ models for random hypergraphs with a given degree sequence", "comments": "9 pages, 2 figures, Proceedings of 21st International Conference on\n  Computational Statistics (2014), to appear", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.SI stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the beta model for random hypergraphs in order to represent the\noccurrence of multi-way interactions among agents in a social network. This\nmodel builds upon and generalizes the well-studied beta model for random\ngraphs, which instead only considers pairwise interactions. We provide two\nalgorithms for fitting the model parameters, IPS (iterative proportional\nscaling) and fixed point algorithm, prove that both algorithms converge if\nmaximum likelihood estimator (MLE) exists, and provide algorithmic and\ngeometric ways of dealing the issue of MLE existence.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jul 2014 18:31:56 GMT"}], "update_date": "2014-07-04", "authors_parsed": [["Stasi", "Despina", ""], ["Sadeghi", "Kayvan", ""], ["Rinaldo", "Alessandro", ""], ["Petrovi\u0107", "Sonja", ""], ["Fienberg", "Stephen E.", ""]]}, {"id": "1407.1065", "submitter": "Mahdi Soltanolkotabi", "authors": "Emmanuel Candes, Xiaodong Li, Mahdi Soltanolkotabi", "title": "Phase Retrieval via Wirtinger Flow: Theory and Algorithms", "comments": "IEEE Transactions on Information Theory, Vol. 64 (4), Feb. 2015", "journal-ref": null, "doi": "10.1109/TIT.2015.2399924", "report-no": null, "categories": "cs.IT math.FA math.IT math.NA math.OC math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of recovering the phase from magnitude measurements;\nspecifically, we wish to reconstruct a complex-valued signal x of C^n about\nwhich we have phaseless samples of the form y_r = |< a_r,x >|^2, r = 1,2,...,m\n(knowledge of the phase of these samples would yield a linear system). This\npaper develops a non-convex formulation of the phase retrieval problem as well\nas a concrete solution algorithm. In a nutshell, this algorithm starts with a\ncareful initialization obtained by means of a spectral method, and then refines\nthis initial estimate by iteratively applying novel update rules, which have\nlow computational complexity, much like in a gradient descent scheme. The main\ncontribution is that this algorithm is shown to rigorously allow the exact\nretrieval of phase information from a nearly minimal number of random\nmeasurements. Indeed, the sequence of successive iterates provably converges to\nthe solution at a geometric rate so that the proposed scheme is efficient both\nin terms of computational and data resources. In theory, a variation on this\nscheme leads to a near-linear time algorithm for a physically realizable model\nbased on coded diffraction patterns. We illustrate the effectiveness of our\nmethods with various experiments on image data. Underlying our analysis are\ninsights for the analysis of non-convex optimization schemes that may have\nimplications for computational problems beyond phase retrieval.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jul 2014 21:14:47 GMT"}, {"version": "v2", "created": "Tue, 3 Feb 2015 08:31:04 GMT"}, {"version": "v3", "created": "Tue, 24 Nov 2015 07:03:41 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Candes", "Emmanuel", ""], ["Li", "Xiaodong", ""], ["Soltanolkotabi", "Mahdi", ""]]}, {"id": "1407.1114", "submitter": "Simon Rubinstein-Salzedo", "authors": "Susan Holmes, Simon Rubinstein-Salzedo, Christof Seiler", "title": "Curvature and Concentration of Hamiltonian Monte Carlo in High\n  Dimensions", "comments": "Comments welcome", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.DG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we analyze Hamiltonian Monte Carlo (HMC) by placing it in\nthe setting of Riemannian geometry using the Jacobi metric, so that each step\ncorresponds to a geodesic on a suitable Riemannian manifold. We then combine\nthe notion of curvature of a Markov chain due to Joulin and Ollivier with the\nclassical sectional curvature from Riemannian geometry to derive error bounds\nfor HMC in important cases, where we have positive curvature. These cases\ninclude several classical distributions such as multivariate Gaussians, and\nalso distributions arising in the study of Bayesian image registration. The\ntheoretical development suggests the sectional curvature as a new diagnostic\ntool for convergence for certain Markov chains.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jul 2014 02:53:57 GMT"}, {"version": "v2", "created": "Sat, 9 Aug 2014 13:38:58 GMT"}, {"version": "v3", "created": "Fri, 19 Sep 2014 22:21:03 GMT"}, {"version": "v4", "created": "Tue, 19 May 2015 22:04:19 GMT"}], "update_date": "2015-05-21", "authors_parsed": [["Holmes", "Susan", ""], ["Rubinstein-Salzedo", "Simon", ""], ["Seiler", "Christof", ""]]}, {"id": "1407.1195", "submitter": "Irene Gannaz", "authors": "Ir\\`ene Gannaz (ICJ, GIPSA-lab)", "title": "Classification of EEG recordings in auditory brain activity via a\n  logistic functional linear regression model", "comments": null, "journal-ref": "International Workshop on Functional and Operatorial Statistics,\n  Italy (2014)", "doi": null, "report-no": null, "categories": "stat.AP math.ST q-bio.NC stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We want to analyse EEG recordings in order to investigate the phonemic\ncategorization at a very early stage of auditory processing. This problem can\nbe modelled by a supervised classification of functional data. Discrimination\nis explored via a logistic functional linear model, using a wavelet\nrepresentation of the data. Different procedures are investigated, based on\npenalized likelihood and principal component reduction or partial least squares\nreduction.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jul 2014 11:33:46 GMT"}], "update_date": "2014-07-07", "authors_parsed": [["Gannaz", "Ir\u00e8ne", "", "ICJ, GIPSA-lab"]]}, {"id": "1407.1200", "submitter": "Christian Genest", "authors": "Christian Genest, Johanna G. Ne\\v{s}lehov\\'a, Bruno R\\'emillard", "title": "On the empirical multilinear copula process for count data", "comments": "Published in at http://dx.doi.org/10.3150/13-BEJ524 the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2014, Vol. 20, No. 3, 1344-1371", "doi": "10.3150/13-BEJ524", "report-no": "IMS-BEJ-BEJ524", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continuation refers to the operation by which the cumulative distribution\nfunction of a discontinuous random vector is made continuous through\nmultilinear interpolation. The copula that results from the application of this\ntechnique to the classical empirical copula is either called the multilinear or\nthe checkerboard copula. As shown by Genest and Ne\\v{s}lehov\\'{a} (Astin Bull.\n37 (2007) 475-515) and Ne\\v{s}lehov\\'{a} (J. Multivariate Anal. 98 (2007)\n544-567), this copula plays a central role in characterizing dependence\nconcepts in discrete random vectors. In this paper, the authors establish the\nasymptotic behavior of the empirical process associated with the multilinear\ncopula based on $d$-variate count data. This empirical process does not\ngenerally converge in law on the space $\\mathcal {C}([0,1]^d)$ of continuous\nfunctions on $[0,1]^d$, equipped with the uniform norm. However, the authors\nshow that the process converges in $\\mathcal{C}(K)$ for any compact\n$K\\subset\\mathcal{O}$, where $\\mathcal{O}$ is a dense open subset of $[0,1]^d$,\nwhose complement is the Cartesian product of the ranges of the marginal\ndistribution functions. This result is sufficient to deduce the weak limit of\nmany functionals of the process, including classical statistics for monotone\ntrend. It also leads to a powerful and consistent test of independence which is\napplicable even to sparse contingency tables whose dimension is sample size\ndependent.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jul 2014 11:52:15 GMT"}], "update_date": "2014-07-07", "authors_parsed": [["Genest", "Christian", ""], ["Ne\u0161lehov\u00e1", "Johanna G.", ""], ["R\u00e9millard", "Bruno", ""]]}, {"id": "1407.1212", "submitter": "Subhra Sankar Dhar", "authors": "Subhra Sankar Dhar, Biman Chakraborty, Probal Chaudhuri", "title": "Comparison of multivariate distributions using quantile-quantile plots\n  and related tests", "comments": "Published in at http://dx.doi.org/10.3150/13-BEJ530 the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2014, Vol. 20, No. 3, 1484-1506", "doi": "10.3150/13-BEJ530", "report-no": "IMS-BEJ-BEJ530", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The univariate quantile-quantile (Q-Q) plot is a well-known graphical tool\nfor examining whether two data sets are generated from the same distribution or\nnot. It is also used to determine how well a specified probability distribution\nfits a given sample. In this article, we develop and study a multivariate\nversion of the Q-Q plot based on the spatial quantile. The usefulness of the\nproposed graphical device is illustrated on different real and simulated data,\nsome of which have fairly large dimensions. We also develop certain statistical\ntests that are related to the proposed multivariate Q-Q plot and study their\nasymptotic properties. The performance of those tests are compared with that of\nsome other well-known tests for multivariate distributions available in the\nliterature.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jul 2014 13:03:27 GMT"}], "update_date": "2014-07-07", "authors_parsed": [["Dhar", "Subhra Sankar", ""], ["Chakraborty", "Biman", ""], ["Chaudhuri", "Probal", ""]]}, {"id": "1407.1225", "submitter": "Zhibiao Zhao", "authors": "Zhibiao Zhao, Ying Wei, Dennis K.J. Lin", "title": "Asymptotics of nonparametric L-1 regression models with dependent data", "comments": "Published in at http://dx.doi.org/10.3150/13-BEJ532 the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2014, Vol. 20, No. 3, 1532-1559", "doi": "10.3150/13-BEJ532", "report-no": "IMS-BEJ-BEJ532", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate asymptotic properties of least-absolute-deviation or median\nquantile estimates of the location and scale functions in nonparametric\nregression models with dependent data from multiple subjects. Under a general\ndependence structure that allows for longitudinal data and some spatially\ncorrelated data, we establish uniform Bahadur representations for the proposed\nmedian quantile estimates. The obtained Bahadur representations provide deep\ninsights into the asymptotic behavior of the estimates. Our main theoretical\ndevelopment is based on studying the modulus of continuity of kernel weighted\nempirical process through a coupling argument. Progesterone data is used for an\nillustration.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jul 2014 13:32:04 GMT"}], "update_date": "2014-07-07", "authors_parsed": [["Zhao", "Zhibiao", ""], ["Wei", "Ying", ""], ["Lin", "Dennis K. J.", ""]]}, {"id": "1407.1233", "submitter": "J\\\"{u}ri Lember", "authors": "J\\\"uri Lember, Heinrich Matzinger, Anna Vollmer", "title": "Optimal alignments of longest common subsequences and their path\n  properties", "comments": "Published in at http://dx.doi.org/10.3150/13-BEJ522 the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2014, Vol. 20, No. 3, 1292-1343", "doi": "10.3150/13-BEJ522", "report-no": "IMS-BEJ-BEJ522", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the behavior of optimal alignment paths for homologous\n(related) and independent random sequences. An alignment between two finite\nsequences is optimal if it corresponds to the longest common subsequence (LCS).\nWe prove the existence of lowest and highest optimal alignments and study their\ndifferences. High differences between the extremal alignments imply the high\nvariety of all optimal alignments. We present several simulations indicating\nthat the homologous (having the same common ancestor) sequences have typically\nthe distance between the extremal alignments of much smaller size than\nindependent sequences. In particular, the simulations suggest that for the\nhomologous sequences, the growth of the distance between the extremal\nalignments is logarithmical. The main theoretical results of the paper prove\nthat (under some assumptions) this is the case, indeed. The paper suggests that\nthe properties of the optimal alignment paths characterize the relatedness of\nthe sequences.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jul 2014 13:50:02 GMT"}], "update_date": "2014-07-07", "authors_parsed": [["Lember", "J\u00fcri", ""], ["Matzinger", "Heinrich", ""], ["Vollmer", "Anna", ""]]}, {"id": "1407.1347", "submitter": "Gael Martin Prof", "authors": "Gael M. Martin, Kanchana Nadarajah and D.S. Poskitt", "title": "Issues in the Estimation of Mis-Specified Models of Fractionally\n  Integrated Processes", "comments": "This is an extensive revision of an earlier paper with the same name", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a comprehensive set of new results on the impact of mis-specifying\nthe short run dynamics in fractionally integrated processes. We show that four\nalternative parametric estimators - frequency domain maximum likelihood,\nWhittle, time domain maximum likelihood and conditional sum of squares -\nconverge to the same pseudo-true value under common mis-specification, and that\nthey possess a common asymptotic distribution. The results are derived assuming\na completely general parametric specification for the short run dynamics of the\nestimated (mis-specified) fractional model, and with long memory, short memory\nand antipersistence in both the model and the true data generating process\naccommodated. As well as providing new theoretical insights, we undertake an\nextensive set of numerical explorations, beginning with the numerical\nevaluation, and implementation, of the (common) asymptotic distribution that\nholds under the most extreme form of mis-specification. Simulation experiments\nare then conducted to assess the relative finite sample performance of all four\nmis-specified estimators, initially under the assumption of a known mean, as\naccords with the theoretical derivations. The importance of the known mean\nassumption is illustrated via the production of an alternative set of bias and\nmean squared error results, in which the estimators are applied to demeaned\ndata. The paper concludes with a discussion of open problems.\n", "versions": [{"version": "v1", "created": "Sat, 5 Jul 2014 00:07:49 GMT"}, {"version": "v2", "created": "Fri, 19 Oct 2018 23:19:52 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Martin", "Gael M.", ""], ["Nadarajah", "Kanchana", ""], ["Poskitt", "D. S.", ""]]}, {"id": "1407.1517", "submitter": "Mark Girolami Prof.", "authors": "Tan Bui-Thanh and Mark Girolami", "title": "Solving Large-Scale PDE-constrained Bayesian Inverse Problems with\n  Riemann Manifold Hamiltonian Monte Carlo", "comments": "To Appear in IoP Inverse Problems", "journal-ref": null, "doi": "10.1088/0266-5611/30/11/114014", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the Riemann manifold Hamiltonian Monte Carlo (RMHMC) method for\nsolving statistical inverse problems governed by partial differential equations\n(PDEs). The power of the RMHMC method is that it exploits the geometric\nstructure induced by the PDE constraints of the underlying inverse problem.\nConsequently, each RMHMC posterior sample is almost independent from the others\nproviding statistically efficient Markov chain simulation. We reduce the cost\nof forming the Fisher information matrix by using a low rank approximation via\na randomized singular value decomposition technique. This is efficient since a\nsmall number of Hessian-vector products are required. The Hessian-vector\nproduct in turn requires only two extra PDE solves using the adjoint technique.\nThe results suggest RMHMC as a highly efficient simulation scheme for sampling\nfrom PDE induced posterior measures.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jul 2014 17:45:11 GMT"}], "update_date": "2015-06-22", "authors_parsed": [["Bui-Thanh", "Tan", ""], ["Girolami", "Mark", ""]]}, {"id": "1407.1662", "submitter": "Roland Marko", "authors": "Andr\\'as Kr\\'amli and Roland Mark\\'o", "title": "Lower threshold ground state energy and testability of minimal balanced\n  cut density", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lov\\'asz and his coauthors defined the notion of microcanonical ground state\nenergy $\\hat{\\mathcal{E}}_\\mathbb{a} (G,J)$ -- borrowed from the statistical\nphysics -- for weighted graphs $G$, where $\\mathbb{a}$ is a probability\ndistribution on $\\{1,...,q\\}$ and $J$ is a symmetric $q \\times q$ matrix with\nreal entries. We define a new version of the ground state energy,\n$\\hat{\\mathcal{E}}^c (G,J)=\\inf_{\\mathbb{a}\\in A_c}\\hat{\\mathcal{E}}_\\mathbb{a}\n(G,J)$, called lower threshold ground state energy, where $A_c = \\{\\mathbb{a}\n:\\, a_i\\ge c,\\,i=1,\\dots, q \\}$. Both types of energies can be extended for\ngraphons $W$, the limit objects of convergent sequences of simple graphs. In\nthe main result of the paper it is stated that if $0\\leq c_1<c_2 \\leq 1$, then\nthe convergence of the sequences $(\\hat{\\mathcal{E}}^{c_2/q} (G_n,J))$ for each\n$J$ implies convergence of the sequences $(\\hat{\\mathcal{E}}^{c_1/q} (G_n,J))$\nfor each $J$. As a byproduct one can derive in a natural way the testability of\nminimum balanced multiway cut densities, that is one of the fundamental\nproblems of cluster analysis.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jul 2014 11:01:00 GMT"}], "update_date": "2014-07-08", "authors_parsed": [["Kr\u00e1mli", "Andr\u00e1s", ""], ["Mark\u00f3", "Roland", ""]]}, {"id": "1407.1751", "submitter": "Marco Enea", "authors": "Marco Enea and Gianfranco Lovison", "title": "A penalized approach to the bivariate logistic regression model for the\n  association between ordinal responses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.AP stat.CO stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bivariate ordered logistic models (BOLMs) are appealing to jointly model the\nmarginal distribution of two ordered responses and their association, given a\nset of covariates. When the number of categories of the responses increases,\nthe number of global odds ratios (or their re-parametrizations) to be estimated\nalso increases and estimating the association structure becomes crucial for\nthis type of data. In fact, such data could be too \"rich\" to be fully modelled\nwith an ordinary BOLM while, sometimes, the well-known Dale's model could be\ntoo parsimonious to provide a good fit. In addition, when the cross-tabulation\nof the responses contains some zeros, for a number of model configurations,\nincluding the bivariate version of the partial proportional odds model (PPOM),\nestimation of a BOLM by the Fisher-scoring algorithm may either fail or\nestimate a too \"irregular\" association structure. In this work, we propose to\nuse a nonparametric approach for the maximum likelihood estimation of a BOLM.\nWe apply penalties to the differences between adjacent row and column effects.\nAs a result, estimation is less demanding than an ordinary BOLM, permitting the\nfit of PPOMs and/or the smoothing of the marginal and association parameters by\npolynomial curves and surfaces, with scores chosen by the data. Model selection\nis based on the penalized log-likelihood ratio, whose limiting distribution has\nbeen studied through simulations, and AIC. Our proposal is compared to the\nGoodman's model and the Dale's model, in terms of goodness-of-fit and\nparsimony, on a literature data set. Finally, an application on an original\ndata set of liver disease patients is proposed.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jul 2014 15:52:29 GMT"}], "update_date": "2014-07-08", "authors_parsed": [["Enea", "Marco", ""], ["Lovison", "Gianfranco", ""]]}, {"id": "1407.1831", "submitter": "Rajesh Singh", "authors": "Hemant K. Verma, Prayas Sharma and Rajesh Singh", "title": "Improved estimator of finite population mean using auxiliary attribute\n  in stratified random sampling", "comments": "10 pages, 2 tables", "journal-ref": "Journal of Scientific Research, BHU (2014), 58: 99-105", "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The present study discuss the problem of estimating the finite population\nmean using auxiliary attribute in stratified random sampling. In this paper\ntaking the advantage of point bi-serial correlation between the study variable\nand auxiliary attribute, we have improved the estimation of population mean in\nstratified random sampling. The expressions for Bias and Mean square error have\nbeen derived under stratified random sampling. In addition, an empirical study\nhas been carried out to examine the merits of the proposed estimator over the\nexisting estimators.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jul 2014 06:21:06 GMT"}, {"version": "v2", "created": "Tue, 12 Aug 2014 09:14:45 GMT"}], "update_date": "2014-08-13", "authors_parsed": [["Verma", "Hemant K.", ""], ["Sharma", "Prayas", ""], ["Singh", "Rajesh", ""]]}, {"id": "1407.1870", "submitter": "Ryota Tomioka", "authors": "Ryota Tomioka and Taiji Suzuki", "title": "Spectral norm of random tensors", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the spectral norm of a random $n_1\\times n_2\\times \\cdots \\times\nn_K$ tensor (or higher-order array) scales as\n$O\\left(\\sqrt{(\\sum_{k=1}^{K}n_k)\\log(K)}\\right)$ under some sub-Gaussian\nassumption on the entries. The proof is based on a covering number argument.\nSince the spectral norm is dual to the tensor nuclear norm (the tightest convex\nrelaxation of the set of rank one tensors), the bound implies that the convex\nrelaxation yields sample complexity that is linear in (the sum of) the number\nof dimensions, which is much smaller than other recently proposed convex\nrelaxations of tensor rank that use unfolding.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jul 2014 20:30:06 GMT"}], "update_date": "2014-07-09", "authors_parsed": [["Tomioka", "Ryota", ""], ["Suzuki", "Taiji", ""]]}, {"id": "1407.2176", "submitter": "Claudio Agostinelli", "authors": "Claudio Agostinelli and Victor J. Yohai", "title": "Composite Robust Estimators for Linear Mixed Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Classical Tukey-Huber Contamination Model (CCM) is a usual framework to\ndescribe the mechanism of outliers generation in robust statistics. In a data\nset with $n$ observations and $p$ variables, under the CCM, an outlier is a\nunit, even if only one or few values are corrupted. Classical robust procedures\nwere designed to cope with this setting and the impact of observations were\nlimited whenever necessary. Recently, a different mechanism of outliers\ngeneration, namely Independent Contamination Model (ICM), was introduced. In\nthis new setting each cell of the data matrix might be corrupted or not with a\nprobability independent on the status of the other cells. ICM poses new\nchallenge to robust statistics since the percentage of contaminated rows\ndramatically increase with $p$, often reaching more than $50\\%$. When this\nsituation appears, classical affine equivariant robust procedures do not work\nsince their breakdown point is $50\\%$. For this contamination model we propose\na new type of robust methods namely composite robust procedures which are\ninspired on the idea of composite likelihood, where low dimension likelihood,\nvery often the likelihood of pairs, are aggregate together in order to obtain\nan approximation of the full likelihood which is more tractable. Our composite\nrobust procedures are build over pairs of observations in order to gain\nrobustness in the independent contamination model. We propose composite S and\n$\\tau$-estimators for linear mixed models. Composite $\\tau$-estimators are\nproved to have an high breakdown point both in the CCM and ICM. A Monte Carlo\nstudy shows that our estimators compare favorably with respect to classical\nS-estimators under the CCM and outperform them under the ICM. One example based\non a real data set illustrates the new robust procedure.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jul 2014 17:08:28 GMT"}, {"version": "v2", "created": "Thu, 10 Jul 2014 16:11:48 GMT"}, {"version": "v3", "created": "Mon, 14 Jul 2014 19:09:33 GMT"}], "update_date": "2014-07-15", "authors_parsed": [["Agostinelli", "Claudio", ""], ["Yohai", "Victor J.", ""]]}, {"id": "1407.2724", "submitter": "Jonathan Rosenblatt", "authors": "Jonathan Rosenblatt, Boaz Nadler", "title": "On the Optimality of Averaging in Distributed Statistical Learning", "comments": "Major changes from previous version. Particularly on the second order\n  error approximation and implications", "journal-ref": null, "doi": "10.1093/imaiai/iaw013", "report-no": null, "categories": "stat.ML math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common approach to statistical learning with big-data is to randomly split\nit among $m$ machines and learn the parameter of interest by averaging the $m$\nindividual estimates. In this paper, focusing on empirical risk minimization,\nor equivalently M-estimation, we study the statistical error incurred by this\nstrategy. We consider two large-sample settings: First, a classical setting\nwhere the number of parameters $p$ is fixed, and the number of samples per\nmachine $n\\to\\infty$. Second, a high-dimensional regime where both\n$p,n\\to\\infty$ with $p/n \\to \\kappa \\in (0,1)$. For both regimes and under\nsuitable assumptions, we present asymptotically exact expressions for this\nestimation error. In the fixed-$p$ setting, under suitable assumptions, we\nprove that to leading order averaging is as accurate as the centralized\nsolution. We also derive the second order error terms, and show that these can\nbe non-negligible, notably for non-linear models. The high-dimensional setting,\nin contrast, exhibits a qualitatively different behavior: data splitting incurs\na first-order accuracy loss, which to leading order increases linearly with the\nnumber of machines. The dependence of our error approximations on the number of\nmachines traces an interesting accuracy-complexity tradeoff, allowing the\npractitioner an informed choice on the number of machines to deploy. Finally,\nwe confirm our theoretical analysis with several simulations.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jul 2014 08:25:49 GMT"}, {"version": "v2", "created": "Sat, 13 Jun 2015 15:14:47 GMT"}], "update_date": "2016-06-14", "authors_parsed": [["Rosenblatt", "Jonathan", ""], ["Nadler", "Boaz", ""]]}, {"id": "1407.2812", "submitter": "Ming Yuan", "authors": "T. Tony Cai and Ming Yuan", "title": "Rate-Optimal Detection of Very Short Signal Segments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by a range of applications in engineering and genomics, we consider\nin this paper detection of very short signal segments in three settings:\nsignals with known shape, arbitrary signals, and smooth signals. Optimal rates\nof detection are established for the three cases and rate-optimal detectors are\nconstructed. The detectors are easily implementable and are based on scanning\nwith linear and quadratic statistics. Our analysis reveals both similarities\nand differences in the strategy and fundamental difficulty of detection among\nthese three settings.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jul 2014 14:48:03 GMT"}], "update_date": "2014-07-11", "authors_parsed": [["Cai", "T. Tony", ""], ["Yuan", "Ming", ""]]}, {"id": "1407.2904", "submitter": "Paul Honeine", "authors": "Paul Honeine", "title": "An eigenanalysis of data centering in machine learning", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG math.SP math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many pattern recognition methods rely on statistical information from\ncentered data, with the eigenanalysis of an empirical central moment, such as\nthe covariance matrix in principal component analysis (PCA), as well as partial\nleast squares regression, canonical-correlation analysis and Fisher\ndiscriminant analysis. Recently, many researchers advocate working on\nnon-centered data. This is the case for instance with the singular value\ndecomposition approach, with the (kernel) entropy component analysis, with the\ninformation-theoretic learning framework, and even with nonnegative matrix\nfactorization. Moreover, one can also consider a non-centered PCA by using the\nsecond-order non-central moment.\n  The main purpose of this paper is to bridge the gap between these two\nviewpoints in designing machine learning methods. To provide a study at the\ncornerstone of kernel-based machines, we conduct an eigenanalysis of the inner\nproduct matrices from centered and non-centered data. We derive several results\nconnecting their eigenvalues and their eigenvectors. Furthermore, we explore\nthe outer product matrices, by providing several results connecting the largest\neigenvectors of the covariance matrix and its non-centered counterpart. These\nresults lay the groundwork to several extensions beyond conventional centering,\nwith the weighted mean shift, the rank-one update, and the multidimensional\nscaling. Experiments conducted on simulated and real data illustrate the\nrelevance of this work.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jul 2014 19:04:49 GMT"}], "update_date": "2014-07-11", "authors_parsed": [["Honeine", "Paul", ""]]}, {"id": "1407.3152", "submitter": "Tao Yu Dr", "authors": "Tao Yu, Pengfei Li and Jing Qin", "title": "Maximum Smoothed Likelihood Component Density Estimation in Mixture\n  Models with Known Mixing Proportions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a maximum smoothed likelihood method to estimate\nthe component density functions of mixture models, in which the mixing\nproportions are known and may differ among observations. The proposed estimates\nmaximize a smoothed log likelihood function and inherit all the important\nproperties of probability density functions. A majorization-minimization\nalgorithm is suggested to compute the proposed estimates numerically. In\ntheory, we show that starting from any initial value, this algorithm increases\nthe smoothed likelihood function and further leads to estimates that maximize\nthe smoothed likelihood function. This indicates the convergence of the\nalgorithm. Furthermore, we theoretically establish the asymptotic convergence\nrate of our proposed estimators. An adaptive procedure is suggested to choose\nthe bandwidths in our estimation procedure. Simulation studies show that the\nproposed method is more efficient than the existing method in terms of\nintegrated squared errors. A real data example is further analyzed.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jul 2014 13:30:14 GMT"}], "update_date": "2014-07-14", "authors_parsed": [["Yu", "Tao", ""], ["Li", "Pengfei", ""], ["Qin", "Jing", ""]]}, {"id": "1407.3206", "submitter": "Flore Harl\\'e", "authors": "Flore Harl\\'e, Florent Chatelain, C\\'edric Gouy-Pailler and Sophie\n  Achard", "title": "Bayesian Model for Multiple Change-points Detection in Multivariate Time\n  Series", "comments": "29 pages, 27 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the issue of detecting change-points in multivariate\ntime series. The proposed approach differs from existing counterparts by making\nonly weak assumptions on both the change-points structure across series, and\nthe statistical signal distributions. Specifically change-points are not\nassumed to occur at simultaneous time instants across series, and no specific\ndistribution is assumed on the individual signals. It relies on the combination\nof a local robust statistical test acting on individual time segments, with a\nglobal Bayesian framework able to optimize configurations from multiple local\nstatistics (from segments of a unique time series or multiple time series).\nUsing an extensive experimental set-up, our algorithm is shown to perform well\non Gaussian data, with the same results in term of recall and precision as\nclassical approaches, such as the fused lasso and the Bernoulli Gaussian model.\nFurthermore, it outperforms the reference models in the case of non normal data\nwith outliers. The control of the False Discovery Rate by an acceptance level\nis confirmed. In the case of multivariate data, the probabilities that\nsimultaneous change-points are shared by some specific time series are learned.\nWe finally illustrate our algorithm with real datasets from energy monitoring\nand genomic. Segmentations are compared to state-of-the-art approaches based on\nfused lasso and group fused lasso.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jul 2014 16:11:58 GMT"}], "update_date": "2014-07-14", "authors_parsed": [["Harl\u00e9", "Flore", ""], ["Chatelain", "Florent", ""], ["Gouy-Pailler", "C\u00e9dric", ""], ["Achard", "Sophie", ""]]}, {"id": "1407.3254", "submitter": "Zvi Rosen", "authors": "Kaie Kubjas and Zvi Rosen", "title": "Matrix Completion for the Independence Model", "comments": "21 pages, 4 figures, Related code at\n  https://www.math.upenn.edu/~zvihr/probCompletion.html. This version is edited\n  and reorganized", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.AG math.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the problem of completing partial matrices to rank-one\nmatrices in the standard simplex. The motivation for studying this problem\ncomes from statistics: A lack of eligible completion can provide a\nfalsification test for partial observations to come from the independence\nmodel. For each pattern of specified entries, we give equations and\ninequalities which are satisfied if and only if an eligible completion exists.\nWe also describe the set of valid completions, and we optimize over this set.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jul 2014 19:06:37 GMT"}, {"version": "v2", "created": "Thu, 28 Apr 2016 15:48:20 GMT"}], "update_date": "2016-04-29", "authors_parsed": [["Kubjas", "Kaie", ""], ["Rosen", "Zvi", ""]]}, {"id": "1407.3289", "submitter": "Stefan Wager", "authors": "Stefan Wager, William Fithian, Sida Wang, and Percy Liang", "title": "Altitude Training: Strong Bounds for Single-Layer Dropout", "comments": "Advances in Neural Information Processing Systems (NIPS), 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dropout training, originally designed for deep neural networks, has been\nsuccessful on high-dimensional single-layer natural language tasks. This paper\nproposes a theoretical explanation for this phenomenon: we show that, under a\ngenerative Poisson topic model with long documents, dropout training improves\nthe exponent in the generalization bound for empirical risk minimization.\nDropout achieves this gain much like a marathon runner who practices at\naltitude: once a classifier learns to perform reasonably well on training\nexamples that have been artificially corrupted by dropout, it will do very well\non the uncorrupted test set. We also show that, under similar conditions,\ndropout preserves the Bayes decision boundary and should therefore induce\nminimal bias in high dimensions.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jul 2014 20:32:34 GMT"}, {"version": "v2", "created": "Fri, 31 Oct 2014 18:30:18 GMT"}], "update_date": "2014-11-03", "authors_parsed": [["Wager", "Stefan", ""], ["Fithian", "William", ""], ["Wang", "Sida", ""], ["Liang", "Percy", ""]]}, {"id": "1407.3334", "submitter": "Marcus Hutter", "authors": "Marcus Hutter", "title": "Offline to Online Conversion", "comments": "20 LaTeX pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT math.ST stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of converting offline estimators into an online\npredictor or estimator with small extra regret. Formally this is the problem of\nmerging a collection of probability measures over strings of length 1,2,3,...\ninto a single probability measure over infinite sequences. We describe various\napproaches and their pros and cons on various examples. As a side-result we\ngive an elementary non-heuristic purely combinatoric derivation of Turing's\nfamous estimator. Our main technical contribution is to determine the\ncomputational complexity of online estimators with good guarantees in general.\n", "versions": [{"version": "v1", "created": "Sat, 12 Jul 2014 01:30:59 GMT"}], "update_date": "2014-07-15", "authors_parsed": [["Hutter", "Marcus", ""]]}, {"id": "1407.3395", "submitter": "Julien Hamonier", "authors": "Antoine Ayache, Julien Hamonier", "title": "Uniformly and strongly consistent estimation for the Hurst function of a\n  Linear Multifractional Stable Motion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since the middle of the 90's, multifractional processes have been introduced\nfor overcoming some limitations of the classical Fractional Brownian Motion\nmodel. In their context, the Hurst parameter becomes a H\u007folder continuous\nfunction H(?) of the time variable t. Linear Multifractional Stable Motion\n(LMSM) is the most known one of them with heavy-tailed distributions. Generally\nspeaking, global and local sample path roughness of a multifractional process\nare determined by values of its parameter $H(\\cdot)$; therefore, since about\ntwo decades, several authors have been interested in their statistical\nestimation, starting from discrete variations of the process. Because of\ncomplex dependence structures of variations, in order to show consistency of\nestimators one has to face challenging problems. The main goal of our article\nis to introduce, in the setting of the symmetric alpha-stable non-anticipative\nmoving average LMSM, where $\\alpha \\in (1; 2)$, a new strategy for dealing with\nsuch kind of problems. It can also be useful in other contexts. In contrast\nwith previously developed strategies, this new one does not require to look for\nsharp estimates of covariances related to functionals of variations. Roughly\nspeaking, it consists of expressing variations in such a way that they become\nindependent random variables up to negligible remainders. Thanks to it, we\nobtain, an almost surely and $L^p(\\Omega), p\\in(0; 4]$, consistent estimator of\nthe whole function $H(\\cdot)$, which converges, uniformly in t, and even for\nsome H\u007folder norms. Also, we obtain estimates for the rates of convergence.\nSuch kind of strong consistency results in uniform and H\u007folder norms are rather\nunusual in the literature on statistical estimation of functions.\n", "versions": [{"version": "v1", "created": "Sat, 12 Jul 2014 14:58:35 GMT"}, {"version": "v2", "created": "Thu, 28 May 2015 12:35:24 GMT"}], "update_date": "2015-05-29", "authors_parsed": [["Ayache", "Antoine", ""], ["Hamonier", "Julien", ""]]}, {"id": "1407.3397", "submitter": "Kolyan Ray", "authors": "Kolyan Ray", "title": "Adaptive Bernstein-von Mises theorems in Gaussian white noise", "comments": "48 pages, 5 figures", "journal-ref": "Ann. Statist. 45 (2017), 2511-2536", "doi": "10.1214/16-AOS1533", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate Bernstein-von Mises theorems for adaptive nonparametric\nBayesian procedures in the canonical Gaussian white noise model. We consider\nboth a Hilbert space and multiscale setting with applications in $L^2$ and\n$L^\\infty$ respectively. This provides a theoretical justification for plug-in\nprocedures, for example the use of certain credible sets for sufficiently\nsmooth linear functionals. We use this general approach to construct optimal\nfrequentist confidence sets based on the posterior distribution. We also\nprovide simulations to numerically illustrate our approach and obtain a visual\nrepresentation of the geometries involved.\n", "versions": [{"version": "v1", "created": "Sat, 12 Jul 2014 15:36:01 GMT"}, {"version": "v2", "created": "Tue, 28 Jul 2015 13:16:14 GMT"}, {"version": "v3", "created": "Mon, 19 Dec 2016 16:44:27 GMT"}], "update_date": "2017-12-21", "authors_parsed": [["Ray", "Kolyan", ""]]}, {"id": "1407.3410", "submitter": "Kezhi Li", "authors": "Kezhi Li, Martin Sundin, Cristian R. Rojas, Saikat Chatterjee, Magnus\n  Jansson", "title": "Alternating Strategies Are Good For Low-Rank Matrix Reconstruction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT math.IT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article focuses on the problem of reconstructing low-rank matrices from\nunderdetermined measurements using alternating optimization strategies. We\nendeavour to combine an alternating least-squares based estimation strategy\nwith ideas from the alternating direction method of multipliers (ADMM) to\nrecover structured low-rank matrices, such as Hankel structure. We show that\nmerging these two alternating strategies leads to a better performance than the\nexisting alternating least squares (ALS) strategy. The performance is evaluated\nvia numerical simulations.\n", "versions": [{"version": "v1", "created": "Sat, 12 Jul 2014 18:29:15 GMT"}], "update_date": "2014-07-15", "authors_parsed": [["Li", "Kezhi", ""], ["Sundin", "Martin", ""], ["Rojas", "Cristian R.", ""], ["Chatterjee", "Saikat", ""], ["Jansson", "Magnus", ""]]}, {"id": "1407.3491", "submitter": "Piet Groeneboom", "authors": "Piet Groeneboom and Geurt Jongbloed", "title": "Nonparametric confidence intervals for monotone functions", "comments": "31 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study nonparametric isotonic confidence intervals for monotone functions.\nIn Banerjee and Wellner (2001) pointwise confidence intervals, based on\nlikelihood ratio tests for the restricted and unrestricted MLE in the current\nstatus model, are introduced. We extend the method to the treatment of other\nmodels with monotone functions, and demonstrate our method by a new proof of\nthe results in Banerjee and Wellner (2001) and also by constructing confidence\nintervals for monotone densities, for which still theory had to be developed.\nFor the latter model we prove that the limit distribution of the LR test under\nthe null hypothesis is the same as in the current status model. We compare the\nconfidence intervals, so obtained, with confidence intervals using the smoothed\nmaximum likelihood estimator (SMLE), using bootstrap methods. The\n`Lagrange-modified' cusum diagrams, developed here, are an essential tool both\nfor the computation of the restricted MLEs and for the development of the\ntheory for the confidence intervals, based on the LR tests.\n", "versions": [{"version": "v1", "created": "Sun, 13 Jul 2014 17:29:49 GMT"}, {"version": "v2", "created": "Wed, 30 Jul 2014 08:57:18 GMT"}, {"version": "v3", "created": "Sat, 2 Aug 2014 08:58:04 GMT"}, {"version": "v4", "created": "Thu, 14 Aug 2014 13:11:26 GMT"}, {"version": "v5", "created": "Mon, 16 Feb 2015 09:56:10 GMT"}], "update_date": "2015-02-17", "authors_parsed": [["Groeneboom", "Piet", ""], ["Jongbloed", "Geurt", ""]]}, {"id": "1407.3495", "submitter": "Johanna  Kappus", "authors": "Johanna Kappus, Fabienne Comte", "title": "Density deconvolution from repeated measurements without symmetry\n  assumption on the errors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider deconvolution from repeated observations with unknown error\ndistribution. So far, this model has mostly been studied under the additional\nassumption that the errors are symmetric.\n  We construct an estimator for the non-symmetric error case and study its\ntheoretical properties and practical performance. It is interesting to note\nthat we can improve substantially upon the rates of convergence which have so\nfar been presented in the literature and, at the same time, dispose of most of\nthe extremely restrictive assumptions which have been imposed so far.\n", "versions": [{"version": "v1", "created": "Sun, 13 Jul 2014 17:35:22 GMT"}], "update_date": "2014-07-15", "authors_parsed": [["Kappus", "Johanna", ""], ["Comte", "Fabienne", ""]]}, {"id": "1407.3625", "submitter": "Leonid Torgovitski", "authors": "Leonid Torgovitski", "title": "A Darling-Erd\\H{o}s-type CUSUM-procedure for functional data II", "comments": "Correction of Theorem 4.1. Additional results on change-point\n  estimation in Theorem 3.8 and in Remark 3.9. (35 pages, 3 figures)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article considers testing for mean-level shifts in functional data. The\nclass of the famous Darling-Erd\\H{o}s-type cumulative sums (CUSUM) procedures\nis extended to functional time series under short range dependence conditions\nwhich are satisfied by functional analogues of many popular time series models\nincluding the linear functional AR and the non-linear functional ARCH. We\nfollow a data driven, projection-based approach where the lower-dimensional\nsubspace is determined by (long run) functional principal components which are\neigenfunctions of the long run covariance operator. This second-order structure\nis generally unknown and estimation is crucial - it plays an even more\nimportant role than in the classical univariate setup because it generates the\nfinite-dimensional subspaces. We discuss suitable estimates and demonstrate\nempirically that altogether this change-point procedure performs well under\nmoderate temporal dependence.\n  Moreover, Darling-Erd\\H{o}s-type change-point estimates based on (long run)\nfunctional principal components as well as the corresponding \"fully-functional\"\ncounterparts are provided and the testing procedure is finally applied to\npublicly accessible electricity data from a German power company.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jul 2014 12:45:06 GMT"}, {"version": "v2", "created": "Thu, 25 Feb 2016 08:23:09 GMT"}], "update_date": "2016-02-26", "authors_parsed": [["Torgovitski", "Leonid", ""]]}, {"id": "1407.3747", "submitter": "Luis Angel Rodr\\'iguez", "authors": "Lisandro Ferm\\'in, Ricardo R\\'ios, Luis-Angel Rodr\\'iguez", "title": "A Robbins Monro algorithm for nonparametric estimation of NAR process\n  with Markov-Switching: consistency", "comments": null, "journal-ref": null, "doi": "10.1111/jtsa.12237", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider nonparametric estimation for functional autoregressive processes\nwith Markov switching. First, we study the case where complete data is\navailable; i.e. when we observe the Markov switching regime. Then we estimate\nthe regression function in each regime using a Nadaraya-Watson type estimator.\nSecond, we introduce a nonparametric recursive algorithm in the case of hidden\nMarkov switching regime. Our algorithm restores the missing data by means of a\nMonte-Carlo step and estimate the regression function via a Robbins-Monro step.\nConsistency of the estimators are proved in both cases. Finally, we present\nsome numerical experiments on simulated data illustrating the performances of\nour nonparametric estimation procedure.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jul 2014 17:56:36 GMT"}, {"version": "v2", "created": "Wed, 23 Jul 2014 19:22:04 GMT"}, {"version": "v3", "created": "Mon, 1 Sep 2014 17:31:16 GMT"}, {"version": "v4", "created": "Wed, 19 Nov 2014 20:19:52 GMT"}, {"version": "v5", "created": "Tue, 16 Dec 2014 02:09:11 GMT"}, {"version": "v6", "created": "Tue, 17 Mar 2015 20:36:18 GMT"}], "update_date": "2017-04-25", "authors_parsed": [["Ferm\u00edn", "Lisandro", ""], ["R\u00edos", "Ricardo", ""], ["Rodr\u00edguez", "Luis-Angel", ""]]}, {"id": "1407.3774", "submitter": "Shuyang Bai", "authors": "Shuyang Bai, Murad S. Taqqu", "title": "Structure of the third moment of the generalized Rosenblatt distribution", "comments": null, "journal-ref": "Statistics and Probability Letters, Volume 94, November 2014,\n  Pages 144-152", "doi": "10.1016/j.spl.2014.07.012", "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Rosenblatt distribution appears as limit in non-central limit theorems.\nThe generalized Rosenblatt distribution is obtained by allowing different power\nexponents in the kernel that defines the usual Rosenblatt distribution. We\nderive an explicit formula for its third moment, correcting the one in\n\\citet{maejima:tudor:2012:selfsimilar} and \\citet{tudor:2013:analysis}.\nEvaluating this formula numerically, we are able to confirm that the class of\ngeneralized Hermite processes is strictly richer than the class of Hermite\nprocesses.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jul 2014 19:37:10 GMT"}], "update_date": "2015-05-15", "authors_parsed": [["Bai", "Shuyang", ""], ["Taqqu", "Murad S.", ""]]}, {"id": "1407.3939", "submitter": "Sylvain Arlot", "authors": "Sylvain Arlot (DI-ENS, INRIA Paris - Rocquencourt), Robin Genuer\n  (ISPED, INRIA Bordeaux - Sud-Ouest)", "title": "Analysis of purely random forests bias", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random forests are a very effective and commonly used statistical method, but\ntheir full theoretical analysis is still an open problem. As a first step,\nsimplified models such as purely random forests have been introduced, in order\nto shed light on the good performance of random forests. In this paper, we\nstudy the approximation error (the bias) of some purely random forest models in\na regression framework, focusing in particular on the influence of the number\nof trees in the forest. Under some regularity assumptions on the regression\nfunction, we show that the bias of an infinite forest decreases at a faster\nrate (with respect to the size of each tree) than a single tree. As a\nconsequence, infinite forests attain a strictly better risk rate (with respect\nto the sample size) than single trees. Furthermore, our results allow to derive\na minimum number of trees sufficient to reach the same rate as an infinite\nforest. As a by-product of our analysis, we also show a link between the bias\nof purely random forests and the bias of some kernel estimators.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jul 2014 11:12:54 GMT"}], "update_date": "2014-07-16", "authors_parsed": [["Arlot", "Sylvain", "", "DI-ENS, INRIA Paris - Rocquencourt"], ["Genuer", "Robin", "", "ISPED, INRIA Bordeaux - Sud-Ouest"]]}, {"id": "1407.3940", "submitter": "Bernard Bercu", "authors": "Bernard Bercu (IMB), Bruno Portier, Victor Vazquez (IMB)", "title": "A Durbin-Watson serial correlation test for ARX processes via excited\n  adaptive tracking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new statistical test for the residual autocorrelation in ARX\nadaptive tracking. The introduction of a persistent excitation in the adaptive\ntracking control allows us to build a bilateral statistical test based on the\nwell-known Durbin-Watson statistic. We establish the almost sure convergence\nand the asymptotic normality for the Durbin-Watson statistic leading to a\npowerful serial correlation test. Numerical experiments illustrate the good\nperformances of our statistical test procedure.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jul 2014 11:13:23 GMT"}], "update_date": "2014-07-16", "authors_parsed": [["Bercu", "Bernard", "", "IMB"], ["Portier", "Bruno", "", "IMB"], ["Vazquez", "Victor", "", "IMB"]]}, {"id": "1407.3961", "submitter": "Abhik Ghosh", "authors": "Avijit Maji, Abhik Ghosh, Ayanendranath Basu", "title": "The Logarithmic Super Divergence and its use in Statistical Inference", "comments": "Pre-print, under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a new superfamily of divergences that is similar in\nspirit to the S-divergence family introduced by Ghosh et al. (2013). This new\nfamily serves as an umbrella that contains the logarithmic power divergence\nfamily (Renyi, 1961; Maji, Chakraborty and Basu 2014) and the logarithmic\ndensity power divergence family (Jones et al., 2001) as special cases. Various\nproperties of this new family and the corresponding minimum distance procedures\nare discussed with particular emphasis on the robustness issue; these\nproperties are demonstrated through simulation studies. In particular the\nmethod demonstrates the limitation of the first order influence function in\nassessing the robustness of the corresponding minimum distance procedures.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jul 2014 12:33:27 GMT"}], "update_date": "2014-07-16", "authors_parsed": [["Maji", "Avijit", ""], ["Ghosh", "Abhik", ""], ["Basu", "Ayanendranath", ""]]}, {"id": "1407.3968", "submitter": "Trisha Maitra Mrs", "authors": "Trisha Maitra and Sourabh Bhattacharya", "title": "On Asymptotics Related to Classical Inference in Stochastic Differential\n  Equations with Random Effects", "comments": "This version appeared in Statistics and Probability Letters", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Delattre et al. (2013) considered n independent stochastic differential\nequations (SDEs), where in each case the drift term is associated with a random\neffect, the distribution of which depends upon unknown parameters. Assuming the\nindependent and identical (iid) situation the authors provide independent\nproofs of weak consistency and asymptotic normality of the maximum likelihood\nestimators (MLEs) of the hyper-parameters of their random effects parameters.\n  In this article, as an alternative route to proving consistency and\nasymptotic normality in the SDE set-up involving random effects, we verify the\nregularity conditions required by existing relevant theorems. In particular,\nthis approach allowed us to prove strong consistency under weaker assumption.\nBut much more importantly, we further consider the independent, but\nnon-identical set-up associated with the random effects based SDE framework,\nand prove asymptotic results associated with the MLEs.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jul 2014 12:53:33 GMT"}, {"version": "v2", "created": "Tue, 31 Mar 2015 11:37:09 GMT"}, {"version": "v3", "created": "Wed, 11 May 2016 09:16:41 GMT"}], "update_date": "2016-05-12", "authors_parsed": [["Maitra", "Trisha", ""], ["Bhattacharya", "Sourabh", ""]]}, {"id": "1407.3971", "submitter": "Trisha Maitra Mrs", "authors": "Trisha Maitra and Sourabh Bhattacharya", "title": "On Bayesian Asymptotics in Stochastic Differential Equations with Random\n  Effects", "comments": "This version appeared in Statistics and Probability Letters", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Delattre et al. (2013) investigated asymptotic properties of the maximum\nlikelihood estimator of the population parameters of the random effects\nassociated with n independent stochastic differential equations (SDEs) assuming\nthat the SDEs are independent and identical (iid).\n  In this article, we consider the Bayesian approach to learning about the\npopulation parameters, and prove consistency and asymptotic normality of the\ncorresponding posterior distribution in the iid set-up as well as when the SDEs\nare independent but non-identical.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jul 2014 13:00:12 GMT"}, {"version": "v2", "created": "Tue, 31 Mar 2015 11:31:42 GMT"}, {"version": "v3", "created": "Wed, 11 May 2016 09:10:11 GMT"}], "update_date": "2016-05-12", "authors_parsed": [["Maitra", "Trisha", ""], ["Bhattacharya", "Sourabh", ""]]}, {"id": "1407.4173", "submitter": "Robert Lindgren", "authors": "D. Michael Milder, Robert G. Lindgren, Morris M. Berman", "title": "Simultaneous Detection and Estimation, False Alarm Prediction for a\n  Continuous Family of Signals in Gaussian Noise", "comments": "19 pages. Submitted to IEEE Transactions on Information Theory", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  New problems arise when the standard theory of joint detection and estimation\nis applied to a set of signals drawn from a continuous family; decision\nthresholds must be determined as a function of the continuous parameter x\ncharacterizing the signals, and false alarms occur, not with a discrete\nprobability, but with a density in x. A Bayes decision structure over the\ndomain of signal parameters yields a state estimate of the signal parameter x\nas an integral part of a signal declaration. The decision criterion is\nconverted to a form in which detection and false alarm densities appear and\nfrom which is derived a relation between them for all x. The limiting case of\nadditive Gaussian noise and a high detection threshold allows a simplified\ndecision criterion and a state estimate of signal location in x that approaches\nthe Cramer-Rao bound. Also in this limit, an analytic form for the false alarm\nprobability density over x, a quantity not readily obtained in general, is\nevaluated here through its relation to the detection probability. The false\nalarm density expression and state accuracy prediction are tested through Monte\nCarlo simulations, and the comparison demonstrates excellent agreement.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jul 2014 00:28:39 GMT"}], "update_date": "2014-07-17", "authors_parsed": [["Milder", "D. Michael", ""], ["Lindgren", "Robert G.", ""], ["Berman", "Morris M.", ""]]}, {"id": "1407.4182", "submitter": "Leonid Sirota", "authors": "E. Ostrovsky, L. Sirota", "title": "Lower boundaries for parametric estimations in different norms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We establish some new non-asymptotical lower bounds for deviation of regular\nunbiased estimation of unknown parameter from its true value in different\nnorms, alike the classical Rao-Kramer's inequality.\n  We show that if the new norm is weaker that ordinary Hilbertian norm, that\nthe rate of convergence of arbitrary regular unbiased estimate does not exceed\n$ 1/\\sqrt{n}, $ and if the new norm is stronger that one, the rate of\nconvergence of the well-known Maximal Likelihood Estimate (MLE) is also equal\nto $ 1/\\sqrt{n}.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jul 2014 02:07:56 GMT"}], "update_date": "2014-07-17", "authors_parsed": [["Ostrovsky", "E.", ""], ["Sirota", "L.", ""]]}, {"id": "1407.4229", "submitter": "Markus Rei{\\ss}", "authors": "Markus Rei{\\ss} and Leonie Selk", "title": "Efficient estimation of functionals in nonparametric boundary models", "comments": "Corrected version", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For nonparametric regression with one-sided errors and a boundary curve model\nfor Poisson point processes we consider the problem of efficient estimation for\nlinear functionals. The minimax optimal rate is obtained by an unbiased\nestimation method which nevertheless depends on a H\\\"older condition or\nmonotonicity assumption for the underlying regression or boundary function.\n  We first construct a simple blockwise estimator and then build up a\nnonparametric maximum-likelihood approach for exponential noise variables and\nthe point process model. In that approach also non-asymptotic efficiency is\nobtained (UMVU: uniformly minimum variance among all unbiased estimators).The\nproofs rely essentially on martingale stopping arguments for counting processes\nand the point process geometry. The estimators are easily computable and a\nsmall simulation study confirms their applicability.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jul 2014 08:26:46 GMT"}, {"version": "v2", "created": "Mon, 22 Jun 2015 13:25:13 GMT"}, {"version": "v3", "created": "Thu, 24 Sep 2015 15:48:38 GMT"}], "update_date": "2015-09-25", "authors_parsed": [["Rei\u00df", "Markus", ""], ["Selk", "Leonie", ""]]}, {"id": "1407.4372", "submitter": "Jean-Francois Coeurjolly", "authors": "Marianne Clausel, Jean-Fran\\c{c}ois Coeurjolly, J\\'er\\^ome Lelong\n  (MATHRISK)", "title": "Stein estimation of the intensity of a spatial homogeneous Poisson point\n  process", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we revisit the original ideas of Stein and propose an\nestimator of the intensity parameter of a homogeneous Poisson point process\ndefined in $\\R^d$ and observed in a bounded window. The procedure is based on a\nnew general integration by parts formula for Poisson point processes. We show\nthat our Stein estimator outperforms the maximum likelihood estimator in terms\nof mean squared error. In particular, we show that in many practical situations\nwe have a gain larger than 30\\%.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jul 2014 16:21:45 GMT"}, {"version": "v2", "created": "Thu, 19 Mar 2015 17:31:13 GMT"}, {"version": "v3", "created": "Thu, 30 Jul 2015 11:47:08 GMT"}], "update_date": "2015-07-31", "authors_parsed": [["Clausel", "Marianne", "", "MATHRISK"], ["Coeurjolly", "Jean-Fran\u00e7ois", "", "MATHRISK"], ["Lelong", "J\u00e9r\u00f4me", "", "MATHRISK"]]}, {"id": "1407.4373", "submitter": "Gerard Biau", "authors": "G\\'erard Biau (LSTA, LPMA, DMA, INRIA Paris - Rocquencourt), Ryad\n  Zenine (LSTA)", "title": "Online Asynchronous Distributed Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed computing offers a high degree of flexibility to accommodate\nmodern learning constraints and the ever increasing size of datasets involved\nin massive data issues. Drawing inspiration from the theory of distributed\ncomputation models developed in the context of gradient-type optimization\nalgorithms, we present a consensus-based asynchronous distributed approach for\nnonparametric online regression and analyze some of its asymptotic properties.\nSubstantial numerical evidence involving up to 28 parallel processors is\nprovided on synthetic datasets to assess the excellent performance of our\nmethod, both in terms of computation time and prediction accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jul 2014 16:24:30 GMT"}], "update_date": "2014-07-17", "authors_parsed": [["Biau", "G\u00e9rard", "", "LSTA, LPMA, DMA, INRIA Paris - Rocquencourt"], ["Zenine", "Ryad", "", "LSTA"]]}, {"id": "1407.4376", "submitter": "Markus Bibinger", "authors": "Markus Bibinger and Lars Winkelmann", "title": "Common price and volatility jumps in noisy high-frequency data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a statistical test for simultaneous jumps in the price of a\nfinancial asset and its volatility process. The proposed test is based on\nhigh-frequency data and is robust to market microstructure frictions. For the\ntest, local estimators of volatility jumps at price jump arrival times are\ndesigned using a nonparametric spectral estimator of the spot volatility\nprocess. A simulation study and an empirical example with NASDAQ order book\ndata demonstrate the practicability of the proposed methods and highlight the\nimportant role played by price volatility co-jumps.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jul 2014 16:28:41 GMT"}, {"version": "v2", "created": "Sat, 26 Nov 2016 11:41:10 GMT"}, {"version": "v3", "created": "Mon, 11 Jun 2018 13:23:10 GMT"}], "update_date": "2018-06-12", "authors_parsed": [["Bibinger", "Markus", ""], ["Winkelmann", "Lars", ""]]}, {"id": "1407.4412", "submitter": "Fanni Ned\\'enyi", "authors": "Fanni Ned\\'enyi", "title": "A CUSUM type change detection test based on martingale differences", "comments": "Manuscript", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper is about detecting changes in the parameters of certain\nparameterized stochastic models. We apply CUSUM (Cumulated Sums) type test\nstatistics that are based on martingale difference sequences.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jul 2014 18:21:02 GMT"}, {"version": "v2", "created": "Sat, 19 Jul 2014 17:21:22 GMT"}], "update_date": "2014-07-22", "authors_parsed": [["Ned\u00e9nyi", "Fanni", ""]]}, {"id": "1407.4446", "submitter": "Weidong Han", "authors": "Weidong Han, Purnima Rajan, Peter I. Frazier, Bruno M. Jedynak", "title": "Probabilistic Group Testing under Sum Observations: A Parallelizable\n  2-Approximation for Entropy Loss", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT math.OC math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of group testing with sum observations and noiseless\nanswers, in which we aim to locate multiple objects by querying the number of\nobjects in each of a sequence of chosen sets. We study a probabilistic setting\nwith entropy loss, in which we assume a joint Bayesian prior density on the\nlocations of the objects and seek to choose the sets queried to minimize the\nexpected entropy of the Bayesian posterior distribution after a fixed number of\nquestions. We present a new non-adaptive policy, called the dyadic policy, show\nit is optimal among non-adaptive policies, and is within a factor of two of\noptimal among adaptive policies. This policy is quick to compute, its\nnonadaptive nature makes it easy to parallelize, and our bounds show it\nperforms well even when compared with adaptive policies. We also study an\nadaptive greedy policy, which maximizes the one-step expected reduction in\nentropy, and show that it performs at least as well as the dyadic policy,\noffering greater query efficiency but reduced parallelism. Numerical\nexperiments demonstrate that both procedures outperform a divide-and-conquer\nbenchmark policy from the literature, called sequential bifurcation, and show\nhow these procedures may be applied in a stylized computer vision problem.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jul 2014 19:55:51 GMT"}, {"version": "v2", "created": "Sat, 26 Jul 2014 15:28:35 GMT"}, {"version": "v3", "created": "Wed, 23 Sep 2015 03:32:33 GMT"}], "update_date": "2015-09-24", "authors_parsed": [["Han", "Weidong", ""], ["Rajan", "Purnima", ""], ["Frazier", "Peter I.", ""], ["Jedynak", "Bruno M.", ""]]}, {"id": "1407.4546", "submitter": "Jinyuan Chang", "authors": "Jinyuan Chang, Qi-Man Shao, Wen-Xin Zhou", "title": "Cram\\'{e}r-type moderate deviations for Studentized two-sample\n  $U$-statistics with applications", "comments": "Published at http://dx.doi.org/10.1214/15-AOS1375 in the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2016, Vol. 44, No. 5, 1931-1956", "doi": "10.1214/15-AOS1375", "report-no": "IMS-AOS-AOS1375", "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two-sample $U$-statistics are widely used in a broad range of applications,\nincluding those in the fields of biostatistics and econometrics. In this paper,\nwe establish sharp Cram\\'{e}r-type moderate deviation theorems for Studentized\ntwo-sample $U$-statistics in a general framework, including the two-sample\n$t$-statistic and Studentized Mann-Whitney test statistic as prototypical\nexamples. In particular, a refined moderate deviation theorem with second-order\naccuracy is established for the two-sample $t$-statistic. These results extend\nthe applicability of the existing statistical methodologies from the one-sample\n$t$-statistic to more general nonlinear statistics. Applications to two-sample\nlarge-scale multiple testing problems with false discovery rate control and the\nregularized bootstrap method are also discussed.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jul 2014 03:25:42 GMT"}, {"version": "v2", "created": "Tue, 2 Jun 2015 17:40:45 GMT"}, {"version": "v3", "created": "Tue, 18 Aug 2015 12:22:22 GMT"}, {"version": "v4", "created": "Mon, 14 Sep 2015 03:53:03 GMT"}, {"version": "v5", "created": "Fri, 13 Nov 2015 05:27:02 GMT"}, {"version": "v6", "created": "Sat, 17 Sep 2016 02:06:50 GMT"}, {"version": "v7", "created": "Wed, 28 Sep 2016 13:19:13 GMT"}], "update_date": "2016-09-29", "authors_parsed": [["Chang", "Jinyuan", ""], ["Shao", "Qi-Man", ""], ["Zhou", "Wen-Xin", ""]]}, {"id": "1407.4551", "submitter": "Jos\\'e A. D\\'iaz-Garc\\'ia", "authors": "Jose A. Diaz-Garcia and Francisco J. Caro-Lopera", "title": "Generalised matricvariate Pearson type II- distribution", "comments": "Several properties of q_{\\kappa} have been modified and their\n  consequences in the manuscript. arXiv admin note: substantial text overlap\n  with arXiv:1402.5178, arXiv:1402.4520, arXiv:1304.5292, arXiv:1301.4525,\n  arXiv:1211.1746. substantial text overlap with arXiv:1402.5178,\n  arXiv:1402.4520, arXiv:1301.4525, arXiv:1304.5292", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a generalisation of the Pearson type II distribution,\nwhich shall termed Pearson Type II-Riesz distribution, based in the Kotz-Riesz\ndistribution. Specifically, the central nonsingular matricvariate generalised\nPearson type II-Riesz distribution, beta-Riesz type I distributions and the\njoint density of the singular values for real normed division algebras are\nobtained.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jul 2014 03:57:59 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2015 01:11:21 GMT"}], "update_date": "2015-06-17", "authors_parsed": [["Diaz-Garcia", "Jose A.", ""], ["Caro-Lopera", "Francisco J.", ""]]}, {"id": "1407.4596", "submitter": "Shenglong Zhou", "authors": "Shenglong Zhou, Naihua Xiu, Ziyan Luo, Lingchen Kong", "title": "Sparse and Low-Rank Covariance Matrices Estimation", "comments": "arXiv admin note: text overlap with arXiv:1208.5702 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.OC stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  This paper aims at achieving a simultaneously sparse and low-rank estimator\nfrom the semidefinite population covariance matrices. We first benefit from a\nconvex optimization which develops $l_1$-norm penalty to encourage the sparsity\nand nuclear norm to favor the low-rank property. For the proposed estimator, we\nthen prove that with large probability, the Frobenious norm of the estimation\nrate can be of order $O(\\sqrt{s(\\log{r})/n})$ under a mild case, where $s$ and\n$r$ denote the number of sparse entries and the rank of the population\ncovariance respectively, $n$ notes the sample capacity. Finally an efficient\nalternating direction method of multipliers with global convergence is proposed\nto tackle this problem, and meantime merits of the approach are also\nillustrated by practicing numerical simulations.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jul 2014 08:28:57 GMT"}, {"version": "v2", "created": "Thu, 7 Aug 2014 01:51:01 GMT"}], "update_date": "2014-08-08", "authors_parsed": [["Zhou", "Shenglong", ""], ["Xiu", "Naihua", ""], ["Luo", "Ziyan", ""], ["Kong", "Lingchen", ""]]}, {"id": "1407.4905", "submitter": "Catherine Matias", "authors": "Pierre Andreoletti (MAPMO), Dasha Loukianova (LaMME), Catherine Matias\n  (LaMME, LPMA)", "title": "Parametric estimation of a one-dimensional ballistic random walk in a\n  Markov environment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We focus on the parametric estimation of the distribution of a Markov\nenvironment from the observation of a single trajectory of a one-dimensional\nnearest-neighbor path evolving in this random environment. In the ballistic\ncase, as the length of the path increases, we prove consistency, asymptotic\nnormality and efficiency of the maximum likelihood estimator. Our contribution\nis two-fold: we cast the problem into the one of parameter estimation in a\nhidden Markov model (HMM) and establish that the bivariate Markov chain\nunderlying this HMM is positive Harris recurrent. We provide different examples\nof setups in which our results apply, in particular that of DNA unzipping\nmodel, and we give a simple synthetic experiment to illustrate those results.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jul 2014 07:54:11 GMT"}, {"version": "v2", "created": "Tue, 14 Apr 2015 09:59:29 GMT"}], "update_date": "2015-04-15", "authors_parsed": [["Andreoletti", "Pierre", "", "MAPMO"], ["Loukianova", "Dasha", "", "LaMME"], ["Matias", "Catherine", "", "LaMME, LPMA"]]}, {"id": "1407.4909", "submitter": "Aurelie Muller-Gueudin", "authors": "Sandie Ferrigno (INRIA Lorraine / IECN, IECL), Bernard Foliguet,\n  Myriam Maumy-Bertrand (IRMA), Aur\\'elie Muller-Gueudin (INRIA Lorraine /\n  IECN, IECL)", "title": "Certainty bands for the conditional cumulative distribution function and\n  applications", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we establish uniform asymptotic certainty bands for the\nconditional cumulative distribution function. To this aim, we give exact rate\nof strong uniform consistency for the local linear estimator of this function.\nThe corollaries of this result are the asymptotic certainty bands for the\nquantiles and the regression function. We illustrate our results with\nsimulations and an application on fetopathologic data.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jul 2014 08:18:12 GMT"}], "update_date": "2014-07-21", "authors_parsed": [["Ferrigno", "Sandie", "", "INRIA Lorraine / IECN, IECL"], ["Foliguet", "Bernard", "", "IRMA"], ["Maumy-Bertrand", "Myriam", "", "IRMA"], ["Muller-Gueudin", "Aur\u00e9lie", "", "INRIA Lorraine /\n  IECN, IECL"]]}, {"id": "1407.4949", "submitter": "Marie du Roy de Chaumaray", "authors": "Marie du Roy de Chaumaray", "title": "Large deviations for the squared radial Ornstein-Uhlenbeck process", "comments": null, "journal-ref": "Teor. Veroyatnost. i Primenen, vol 61, issue 3, 2016", "doi": "10.4213/tvp5071", "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We establish large deviation principles for the couple of the maximum\nlikelihood estimators of dimensional and drift coefficients in the generalised\nsquared radial Ornstein-Uhlenbeck process. We focus our attention to the most\ntractable situation where the dimensional parameter $a>2$ and the drift\nparameter $b<0$. In contrast to the previous literature, we state large\ndeviation principles when both dimensional and drift coefficient are estimated\nsimultaneously.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jul 2014 10:55:00 GMT"}, {"version": "v2", "created": "Wed, 2 Sep 2015 13:06:26 GMT"}, {"version": "v3", "created": "Wed, 25 Nov 2015 15:11:50 GMT"}], "update_date": "2016-11-28", "authors_parsed": [["de Chaumaray", "Marie du Roy", ""]]}, {"id": "1407.5014", "submitter": "Yakov Nikitin", "authors": "M. Jovanovic, B. Milosevic, Ya. Yu. Nikitin, M. Obradovic, K. Yu.\n  Volkova", "title": "Tests of exponentiality based on Arnold-Villasenor characterization, and\n  their efficiencies", "comments": "25 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose two families of scale-free exponentiality tests based on the\nrecent characterization of exponentiality by Arnold and Villasenor. The test\nstatistics are based on suitable functionals of U-empirical distribution\nfunctions. The family of integral statistics can be reduced to V- or\nU-statistics with relatively simple non-degenerate kernels. They are\nasymptotically normal and have reasonably high local Bahadur efficiency under\ncommon alternatives. This efficiency is compared with simulated powers of new\ntests. On the other hand, the Kolmogorov type tests demonstrate very low local\nBahadur efficiency and rather moderate power for common alternatives,and can\nhardly be recommended to practitioners. We also explore the conditions of local\nasymptotic optimality of new tests and describe for both families special \"most\nfavorable\" alternatives for which the tests are fully efficient.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jul 2014 14:41:54 GMT"}], "update_date": "2014-07-21", "authors_parsed": [["Jovanovic", "M.", ""], ["Milosevic", "B.", ""], ["Nikitin", "Ya. Yu.", ""], ["Obradovic", "M.", ""], ["Volkova", "K. Yu.", ""]]}, {"id": "1407.5158", "submitter": "Jean-Philippe Vert", "authors": "Emile Richard, Guillaume Obozinski (LIGM), Jean-Philippe Vert (CBIO)", "title": "Tight convex relaxations for sparse matrix factorization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Based on a new atomic norm, we propose a new convex formulation for sparse\nmatrix factorization problems in which the number of nonzero elements of the\nfactors is assumed fixed and known. The formulation counts sparse PCA with\nmultiple factors, subspace clustering and low-rank sparse bilinear regression\nas potential applications. We compute slow rates and an upper bound on the\nstatistical dimension of the suggested norm for rank 1 matrices, showing that\nits statistical dimension is an order of magnitude smaller than the usual\n$\\ell\\_1$-norm, trace norm and their combinations. Even though our convex\nformulation is in theory hard and does not lead to provably polynomial time\nalgorithmic schemes, we propose an active set algorithm leveraging the\nstructure of the convex problem to solve it and show promising numerical\nresults.\n", "versions": [{"version": "v1", "created": "Sat, 19 Jul 2014 07:04:08 GMT"}, {"version": "v2", "created": "Thu, 4 Dec 2014 11:19:07 GMT"}], "update_date": "2014-12-05", "authors_parsed": [["Richard", "Emile", "", "LIGM"], ["Obozinski", "Guillaume", "", "LIGM"], ["Vert", "Jean-Philippe", "", "CBIO"]]}, {"id": "1407.5232", "submitter": "Eduard Belitser", "authors": "Eduard Belitser", "title": "On coverage and local radial rates of DDM-credible sets", "comments": "26 pages + supplement 18 pages", "journal-ref": "Ann. Stat., 45, 1124-1151 (2017)", "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For a general statistical model, we introduce the notion of data dependent\nmeasure (DDM) on the model parameter. Typical examples of DDM are the posterior\ndistributions. Like for posteriors, the quality of a DDM is characterized by\nthe contraction rate which we allow to be local, i.e., depending on the\nparameter. We construct confidence sets as DDM-credible sets and address the\nissue of optimality of such sets, via a trade-off between its \"size\" (the local\nradial rate) and its coverage probability. In the mildly ill-posed inverse\nsignal-in-white-noise model, we construct a DDM as empirical Bayes posterior\nwith respect to a certain prior, and define its (default) credible set. Then we\nintroduce 'excessive bias restriction' (EBR), more general than\n'self-similarity' and 'polished tail condition' recently studied in the\nliterature. Under EBR, we establish the confidence optimality of our credible\nset with some local (oracle) radial rate. We also derive the oracle estimation\ninequality and the oracle DDM-contraction rate, non-asymptotically and\nuniformly in $\\ell_2$. The obtained local results are more powerful than\nglobal: adaptive minimax results for a number of smoothness scales follow as\nconsequence, in particular, the ones considered by Szabo, van der Vaart and van\nZanten (2015).\n", "versions": [{"version": "v1", "created": "Sun, 20 Jul 2014 01:29:35 GMT"}, {"version": "v2", "created": "Tue, 28 Jul 2015 16:25:19 GMT"}, {"version": "v3", "created": "Wed, 29 Jul 2015 22:17:22 GMT"}, {"version": "v4", "created": "Thu, 13 Aug 2015 09:39:48 GMT"}, {"version": "v5", "created": "Tue, 20 Oct 2015 14:48:25 GMT"}], "update_date": "2019-04-01", "authors_parsed": [["Belitser", "Eduard", ""]]}, {"id": "1407.5241", "submitter": "Wanjie Wang", "authors": "Jiashun Jin and Wanjie Wang", "title": "Influential Feature PCA for high dimensional clustering", "comments": "62 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a clustering problem where we observe feature vectors $X_i \\in\nR^p$, $i = 1, 2, \\ldots, n$, from $K$ possible classes. The class labels are\nunknown and the main interest is to estimate them. We are primarily interested\nin the modern regime of $p \\gg n$, where classical clustering methods face\nchallenges.\n  We propose Influential Features PCA (IF-PCA) as a new clustering procedure.\nIn IF-PCA, we select a small fraction of features with the largest\nKolmogorov-Smirnov (KS) scores, where the threshold is chosen by adapting the\nrecent notion of Higher Criticism, obtain the first $(K-1)$ left singular\nvectors of the post-selection normalized data matrix, and then estimate the\nlabels by applying the classical k-means to these singular vectors. It can be\nseen that IF-PCA is a tuning free clustering method.\n  We apply IF-PCA to $10$ gene microarray data sets. The method has competitive\nperformance in clustering. Especially, in three of the data sets, the error\nrates of IF-PCA are only $29\\%$ or less of the error rates by other methods. We\nhave also rediscovered a phenomenon on empirical null by \\cite{Efron} on\nmicroarray data.\n  With delicate analysis, especially post-selection eigen-analysis, we derive\ntight probability bounds on the Kolmogorov-Smirnov statistics and show that\nIF-PCA yields clustering consistency in a broad context. The clustering problem\nis connected to the problems of sparse PCA and low-rank matrix recovery, but it\nis different in important ways. We reveal an interesting phase transition\nphenomenon associated with these problems and identify the range of interest\nfor each.\n", "versions": [{"version": "v1", "created": "Sun, 20 Jul 2014 03:41:25 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2015 20:24:28 GMT"}, {"version": "v3", "created": "Wed, 16 Dec 2015 04:05:06 GMT"}], "update_date": "2015-12-17", "authors_parsed": [["Jin", "Jiashun", ""], ["Wang", "Wanjie", ""]]}, {"id": "1407.5272", "submitter": "Omer Bobrowski", "authors": "Omer Bobrowski, Sayan Mukherjee, Jonathan E. Taylor", "title": "Topological consistency via kernel estimation", "comments": "Published at http://dx.doi.org/10.3150/15-BEJ744 in the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2017, Vol. 23, No. 1, 288-328", "doi": "10.3150/15-BEJ744", "report-no": "IMS-BEJ-BEJ744", "categories": "math.ST math.AT math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a consistent estimator for the homology (an algebraic structure\nrepresenting connected components and cycles) of level sets of both density and\nregression functions. Our method is based on kernel estimation. We apply this\nprocedure to two problems: (1) inferring the homology structure of manifolds\nfrom noisy observations, (2) inferring the persistent homology (a multi-scale\nextension of homology) of either density or regression functions. We prove\nconsistency for both of these problems. In addition to the theoretical results,\nwe demonstrate these methods on simulated data for binary regression and\nclustering applications.\n", "versions": [{"version": "v1", "created": "Sun, 20 Jul 2014 11:15:26 GMT"}, {"version": "v2", "created": "Fri, 26 Sep 2014 03:56:18 GMT"}, {"version": "v3", "created": "Wed, 22 Apr 2015 05:07:36 GMT"}, {"version": "v4", "created": "Thu, 29 Sep 2016 11:43:05 GMT"}], "update_date": "2016-09-30", "authors_parsed": [["Bobrowski", "Omer", ""], ["Mukherjee", "Sayan", ""], ["Taylor", "Jonathan E.", ""]]}, {"id": "1407.5341", "submitter": "In\\'es del Puerto", "authors": "M. Gonzalez, C. Minuesa, I. del Puerto", "title": "Maximum likelihood estimation and Expectation-Maximization algorithm for\n  controlled branching processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The controlled branching process is a generalization of the classical\nBienaym\\'e-Galton-Watson branching process. It is a useful model for describing\nthe evolution of populations in which the population size at each generation\nneeds to be controlled. The maximum likelihood estimation of the parameters of\ninterest for this process is addressed under various sample schemes. Firstly,\nassuming that the entire family tree can be observed, the corresponding\nestimators are obtained and their asymptotic properties investigated. Secondly,\nsince in practice it is not usual to observe such a sample, the maximum\nlikelihood estimation is initially considered using the sample given by the\ntotal number of individuals and progenitors of each generation, and then using\nthe sample given by only the generation sizes. Expectation-maximization\nalgorithms are developed to address these problems as incomplete data\nestimation problems. The accuracy of the procedures is illustrated by means of\na simulated example.\n", "versions": [{"version": "v1", "created": "Sun, 20 Jul 2014 21:54:25 GMT"}, {"version": "v2", "created": "Mon, 22 Sep 2014 21:29:29 GMT"}, {"version": "v3", "created": "Thu, 5 Feb 2015 22:18:24 GMT"}], "update_date": "2015-02-09", "authors_parsed": [["Gonzalez", "M.", ""], ["Minuesa", "C.", ""], ["del Puerto", "I.", ""]]}, {"id": "1407.5509", "submitter": "John Matthews", "authors": "J.N.S. Matthews and Nuri H. Badi", "title": "Inconsistent treatment estimates from mis-specified logistic regression\n  analyses of randomized trials", "comments": "18 pages, 1 figure, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When the difference between treatments in a clinical trial is estimated by a\ndifference in means, then it is well known that randomization ensures unbiassed\nestimation, even if no account is taken of important baseline covariates.\nHowever, when the treatment effect is assessed by other summaries, e.g. by an\nodds ratio if the outcome is binary, then bias can arise if some covariates are\nomitted, regardless of the use of randomization for treatment allocation or the\nsize of the trial. We present accurate closed-form approximations for this\nasymptotic bias when important Normally distributed covariates are omitted from\na logistic regression. We compare this approximation with ones in the\nliterature and derive more convenient forms for some of these existing results.\nThe expressions give insight into the form of the bias, which simulations show\nis usable for distributions other than the Normal. The key result applies even\nwhen there are additional binary covariates in the model.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jul 2014 14:30:56 GMT"}], "update_date": "2014-07-22", "authors_parsed": [["Matthews", "J. N. S.", ""], ["Badi", "Nuri H.", ""]]}, {"id": "1407.5565", "submitter": "Ea 2429 Laboratoire De Sciences Financiere Et D'Assurance", "authors": "Areski Cousin (SAF), Alexandre Janon (LM-Orsay, - M\\'ethodes d'Analyse\n  Stochastique des Codes et Traitements Num\\'eriques), V\\'eronique\n  Maume-Deschamps (ICJ), Ibrahima Niang (SAF)", "title": "On the consistency of Sobol indices with respect to stochastic ordering\n  of model parameters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the past decade, Sobol's variance decomposition have been used as a tool -\namong others - in risk management. We show some links between global\nsensitivity analysis and stochastic ordering theories. This gives an argument\nin favor of using Sobol's indices in uncertainty quantification, as one\nindicator among others.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jul 2014 16:49:53 GMT"}], "update_date": "2014-07-22", "authors_parsed": [["Cousin", "Areski", "", "SAF"], ["Janon", "Alexandre", "", "LM-Orsay, - M\u00e9thodes d'Analyse\n  Stochastique des Codes et Traitements Num\u00e9riques"], ["Maume-Deschamps", "V\u00e9ronique", "", "ICJ"], ["Niang", "Ibrahima", "", "SAF"]]}, {"id": "1407.5798", "submitter": "Peter Ruckdeschel", "authors": "Daria Pupashenko, Peter Ruckdeschel, Matthias Kohl", "title": "L_2 Differentiability of Generalized Linear Models", "comments": "10 pages", "journal-ref": null, "doi": "10.1016/j.spl.2014.11.020", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive conditions for $L_2$ differentiability of generalized linear models\nwith error distributions not necessarily belonging to exponential families,\ncovering both cases of stochastic and deterministic regressors. These\nconditions induce smoothness and integrability conditions for corresponding\nGLM-based time series models.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jul 2014 09:24:45 GMT"}, {"version": "v2", "created": "Mon, 24 Nov 2014 13:46:58 GMT"}], "update_date": "2014-12-01", "authors_parsed": [["Pupashenko", "Daria", ""], ["Ruckdeschel", "Peter", ""], ["Kohl", "Matthias", ""]]}, {"id": "1407.5978", "submitter": "Yao Xie", "authors": "David Marangoni-Simonsen and Yao Xie", "title": "Sequential Changepoint Approach for Online Community Detection", "comments": "Submitted to 2014 INFORMS Workshop on Data Mining and Analytics and\n  an IEEE journal", "journal-ref": null, "doi": "10.1109/LSP.2014.2381553", "report-no": null, "categories": "stat.ML cs.LG cs.SI math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present new algorithms for detecting the emergence of a community in large\nnetworks from sequential observations. The networks are modeled using\nErdos-Renyi random graphs with edges forming between nodes in the community\nwith higher probability. Based on statistical changepoint detection\nmethodology, we develop three algorithms: the Exhaustive Search (ES), the\nmixture, and the Hierarchical Mixture (H-Mix) methods. Performance of these\nmethods is evaluated by the average run length (ARL), which captures the\nfrequency of false alarms, and the detection delay. Numerical comparisons show\nthat the ES method performs the best; however, it is exponentially complex. The\nmixture method is polynomially complex by exploiting the fact that the size of\nthe community is typically small in a large network. However, it may react to a\ngroup of active edges that do not form a community. This issue is resolved by\nthe H-Mix method, which is based on a dendrogram decomposition of the network.\nWe present an asymptotic analytical expression for ARL of the mixture method\nwhen the threshold is large. Numerical simulation verifies that our\napproximation is accurate even in the non-asymptotic regime. Hence, it can be\nused to determine a desired threshold efficiently. Finally, numerical examples\nshow that the mixture and the H-Mix methods can both detect a community quickly\nwith a lower complexity than the ES method.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jul 2014 19:16:01 GMT"}, {"version": "v2", "created": "Wed, 23 Jul 2014 19:54:17 GMT"}, {"version": "v3", "created": "Thu, 24 Jul 2014 06:27:05 GMT"}], "update_date": "2015-06-22", "authors_parsed": [["Marangoni-Simonsen", "David", ""], ["Xie", "Yao", ""]]}, {"id": "1407.6092", "submitter": "Alexander Volfovsky", "authors": "Alexander Volfovsky and Edoardo Airoldi", "title": "Sharp Total Variation Bounds for Finitely Exchangeable Arrays", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we demonstrate the relationship between finitely exchangeable\narrays and finitely exchangeable sequences. We then derive sharp bounds on the\ntotal variation distance between distributions of finitely and infinitely\nexchangeable arrays.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jul 2014 02:39:05 GMT"}, {"version": "v2", "created": "Fri, 22 Aug 2014 05:08:13 GMT"}, {"version": "v3", "created": "Wed, 24 Feb 2016 16:13:50 GMT"}], "update_date": "2016-02-25", "authors_parsed": [["Volfovsky", "Alexander", ""], ["Airoldi", "Edoardo", ""]]}, {"id": "1407.6461", "submitter": "Robert Staudte", "authors": "R.G Staudte", "title": "Inference for Quantile Measures of Kurtosis, Peakedness and Tail-weight", "comments": "30 pages, 4 figures", "journal-ref": null, "doi": "10.1080/03610926.2015.1056366", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many measures of peakedness, heavy-tailedness and kurtosis have been proposed\nin the literature, mainly because kurtosis, as originally defined, is a complex\ncombination of the other two concepts. Insight into all three concepts can be\ngained by studying Ruppert's ratios of interquantile ranges. They are not only\nmonotone in Horn's measure of peakedness when applied to the central portion of\nthe population, but also monotone in the practical tail-index of Morgenthaler\nand Tukey, when applied to the tails. Distribution-free confidence intervals\nare found for Ruppert's ratios, and sample sizes required to obtain such\nintervals for a pre-specified relative width and level are provided. In\naddition, the empirical power of distribution-free tests for peakedness and\nbimodality are found for symmetric beta families and mixtures of $t$\ndistributions. An R script that computes the confidence intervals is provided\nin online supplementary material.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jul 2014 06:06:11 GMT"}], "update_date": "2017-02-01", "authors_parsed": [["Staudte", "R. G", ""]]}, {"id": "1407.6514", "submitter": "Fumiya Akashi", "authors": "Fumiya Akashi, Yan Liu, Masanobu Taniguchi", "title": "An empirical likelihood approach for symmetric $\\alpha$-stable processes", "comments": "Published at http://dx.doi.org/10.3150/14-BEJ636 in the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2015, Vol. 21, No. 4, 2093-2119", "doi": "10.3150/14-BEJ636", "report-no": "IMS-BEJ-BEJ636", "categories": "math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Empirical likelihood approach is one of non-parametric statistical methods,\nwhich is applied to the hypothesis testing or construction of confidence\nregions for pivotal unknown quantities. This method has been applied to the\ncase of independent identically distributed random variables and second order\nstationary processes. In recent years, we observe heavy-tailed data in many\nfields. To model such data suitably, we consider symmetric scalar and\nmultivariate $\\alpha$-stable linear processes generated by infinite variance\ninnovation sequence. We use a Whittle likelihood type estimating function in\nthe empirical likelihood ratio function and derive the asymptotic distribution\nof the empirical likelihood ratio statistic for $\\alpha$-stable linear\nprocesses. With the empirical likelihood statistic approach, the theory of\nestimation and testing for second order stationary processes is nicely extended\nto heavy-tailed data analyses, not straightforward, and applicable to a lot of\nfinancial statistical analyses.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jul 2014 10:08:42 GMT"}, {"version": "v2", "created": "Fri, 18 Sep 2015 07:31:01 GMT"}], "update_date": "2015-09-21", "authors_parsed": [["Akashi", "Fumiya", ""], ["Liu", "Yan", ""], ["Taniguchi", "Masanobu", ""]]}, {"id": "1407.7165", "submitter": "Margaritis Voliotis", "authors": "Clive G. Bowsher and Margaritis Voliotis", "title": "Mutual Information and Conditional Mean Prediction Error", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT math.PR math.ST physics.bio-ph physics.data-an stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mutual information is fundamentally important for measuring statistical\ndependence between variables and for quantifying information transfer by\nsignaling and communication mechanisms. It can, however, be challenging to\nevaluate for physical models of such mechanisms and to estimate reliably from\ndata. Furthermore, its relationship to better known statistical procedures is\nstill poorly understood. Here we explore new connections between mutual\ninformation and regression-based dependence measures, $\\nu^{-1}$, that utilise\nthe determinant of the second-moment matrix of the conditional mean prediction\nerror. We examine convergence properties as $\\nu\\rightarrow0$ and establish\nsharp lower bounds on mutual information and capacity of the form\n$\\mathrm{log}(\\nu^{-1/2})$. The bounds are tighter than lower bounds based on\nthe Pearson correlation and ones derived using average mean square-error rate\ndistortion arguments. Furthermore, their estimation is feasible using\ntechniques from nonparametric regression. As an illustration we provide\nbootstrap confidence intervals for the lower bounds which, through use of a\ncomposite estimator, substantially improve upon inference about mutual\ninformation based on $k$-nearest neighbour estimators alone.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jul 2014 22:48:38 GMT"}], "update_date": "2014-07-29", "authors_parsed": [["Bowsher", "Clive G.", ""], ["Voliotis", "Margaritis", ""]]}, {"id": "1407.7166", "submitter": "Andreas Hagemann", "authors": "Andreas Hagemann", "title": "Cluster-Robust Bootstrap Inference in Quantile Regression Models", "comments": "46 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper I develop a wild bootstrap procedure for cluster-robust\ninference in linear quantile regression models. I show that the bootstrap leads\nto asymptotically valid inference on the entire quantile regression process in\na setting with a large number of small, heterogeneous clusters and provides\nconsistent estimates of the asymptotic covariance function of that process. The\nproposed bootstrap procedure is easy to implement and performs well even when\nthe number of clusters is much smaller than the sample size. An application to\nProject STAR data is provided.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jul 2014 22:58:46 GMT"}, {"version": "v2", "created": "Fri, 15 Aug 2014 11:30:13 GMT"}, {"version": "v3", "created": "Thu, 5 Mar 2015 00:31:17 GMT"}, {"version": "v4", "created": "Tue, 14 Jul 2015 18:57:12 GMT"}], "update_date": "2015-07-15", "authors_parsed": [["Hagemann", "Andreas", ""]]}, {"id": "1407.7172", "submitter": "Ewa Nowakowska PhD", "authors": "Ewa Nowakowska, Jacek Koronacki, Stan Lipovetsky", "title": "Tractable Measure of Component Overlap for Gaussian Mixture Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.OT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to quantify distinctness of a cluster structure is fundamental\nfor certain simulation studies, in particular for those comparing performance\nof different classification algorithms. The intrinsic integral measure based on\nthe overlap of corresponding mixture components is often analytically\nintractable. This is also the case for Gaussian mixture models with unequal\ncovariance matrices when space dimension $d > 1$. In this work we focus on\nGaussian mixture models and at the sample level we assume the class assignments\nto be known. We derive a measure of component overlap based on eigenvalues of a\ngeneralized eigenproblem that represents Fisher's discriminant task. We explain\nrationale behind it and present simulation results that show how well it can\nreflect the behavior of the integral measure in its linear approximation. The\nanalyzed coefficient possesses the advantage of being analytically tractable\nand numerically computable even in complex setups.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jul 2014 00:30:58 GMT"}], "update_date": "2014-07-29", "authors_parsed": [["Nowakowska", "Ewa", ""], ["Koronacki", "Jacek", ""], ["Lipovetsky", "Stan", ""]]}, {"id": "1407.7194", "submitter": "Zhigang Bao", "authors": "Zhigang Bao, Jiang Hu, Guangming Pan, and Wang Zhou", "title": "Canonical correlation coefficients of high-dimensional normal vectors:\n  finite rank case", "comments": "Some typos were corrected", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a normal vector $\\mathbf{z}=(\\mathbf{x}',\\mathbf{y}')'$, consisting\nof two sub-vectors $\\mathbf{x}$ and $\\mathbf{y}$ with dimensions $p$ and $q$\nrespectively. With $n$ independent observations of $\\mathbf{z}$ at hand, we\nstudy the correlation between $\\mathbf{x}$ and $\\mathbf{y}$, from the\nperspective of the Canonical Correlation Analysis, under the high-dimensional\nsetting: both $p$ and $q$ are proportional to the sample size $n$. In this\npaper, we focus on the case that $\\Sigma_{\\mathbf{x}\\mathbf{y}}$ is of finite\nrank $k$, i.e. there are $k$ nonzero canonical correlation coefficients, whose\nsquares are denoted by $r_1\\geq\\cdots\\geq r_k>0$. Under the additional\nassumptions $(p+q)/n\\to y\\in (0,1)$ and $p/q\\not\\to 1$, we study the sample\ncounterparts of $r_i,i=1,\\ldots,k$, i.e. the largest k eigenvalues of the\nsample canonical correlation matrix\n$S_{\\mathbf{x}\\mathbf{x}}^{-1}S_{\\mathbf{x}\\mathbf{y}}S_{\\mathbf{y}\\mathbf{y}}^{-1}S_{\\mathbf{y}\\mathbf{x}}$,\nnamely $\\lambda_1\\geq\\cdots\\geq \\lambda_k$. We show that there exists a\nthreshold $r_c\\in(0,1)$, such that for each $i\\in\\{1,\\ldots,k\\}$, when $r_i\\leq\nr_c$, $\\lambda_i$ converges almost surely to the right edge of the limiting\nspectral distribution of the sample canonical correlation matrix, denoted by\n$d_r$. When $r_i>r_c$, $\\lambda_i$ possesses an almost sure limit in $(d_r,1]$,\nfrom which we can recover $r_i$ in turn, thus provide an estimate of the latter\nin the high-dimensional scenario.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jul 2014 07:17:30 GMT"}, {"version": "v2", "created": "Tue, 5 Aug 2014 07:16:29 GMT"}], "update_date": "2014-08-06", "authors_parsed": [["Bao", "Zhigang", ""], ["Hu", "Jiang", ""], ["Pan", "Guangming", ""], ["Zhou", "Wang", ""]]}, {"id": "1407.7811", "submitter": "Ewa Nowakowska PhD", "authors": "Ewa Nowakowska, Jacek Koronacki, Stan Lipovetsky", "title": "Dimension reduction for data of unknown cluster structure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For numerous reasons there raises a need for dimension reduction that\npreserves certain characteristics of data. In this work we focus on data coming\nfrom a mixture of Gaussian distributions and we propose a method that preserves\ndistinctness of clustering structure, although the structure is assumed to be\nyet unknown. The rationale behind the method is the following: (i) had one\nknown the clusters (classes) within the data, one could facilitate further\nanalysis and reduce space dimension by projecting the data to the Fisher's\nlinear subspace, which -- by definition -- preserves the structure of the given\nclasses best (ii) under some reasonable assumptions, this can be done, albeit\napproximately, without the prior knowledge of the clusters (classes). In the\npaper, we show how this approach works. We present a method of preliminary data\ntransformation that brings the directions of largest overall variability close\nto the directions of the best between-class separation. Hence, for the\ntransformed data, simple PCA provides an approximation to the Fisher's\nsubspace. We show that the transformation preserves distinctness of unknown\nstructure in the data to a great extent.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jul 2014 18:28:42 GMT"}], "update_date": "2014-07-30", "authors_parsed": [["Nowakowska", "Ewa", ""], ["Koronacki", "Jacek", ""], ["Lipovetsky", "Stan", ""]]}, {"id": "1407.7820", "submitter": "Rui Song", "authors": "Runchao Jiang, Wenbin Lu, Rui Song, and Marie Davidian", "title": "On Estimation of Optimal Treatment Regimes For Maximizing t-Year\n  Survival Probability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A treatment regime is a deterministic function that dictates personalized\ntreatment based on patients' individual prognostic information. There is a\nfast-growing interest in finding optimal treatment regimes to maximize expected\nlong-term clinical outcomes of patients for complex diseases, such as cancer\nand AIDS. For many clinical studies with survival time as a primary endpoint, a\nmain goal is to maximize patients' survival probabilities given treatments. In\nthis article, we first propose two nonparametric estimators for survival\nfunction of patients following a given treatment regime. Then, we derive the\nestimation of the optimal treatment regime based on a value-based searching\nalgorithm within a set of treatment regimes indexed by parameters. The\nasymptotic properties of the proposed estimators for survival probabilities\nunder derived optimal treatment regimes are established under suitable\nregularity conditions. Simulations are conducted to evaluate the numerical\nperformance of the proposed estimators under various scenarios. An application\nto an AIDS clinical trial data is also given to illustrate the methods.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jul 2014 18:38:47 GMT"}], "update_date": "2016-11-25", "authors_parsed": [["Jiang", "Runchao", ""], ["Lu", "Wenbin", ""], ["Song", "Rui", ""], ["Davidian", "Marie", ""]]}, {"id": "1407.8083", "submitter": "Robert McGibbon", "authors": "Robert T. McGibbon and Vijay S. Pande", "title": "Variational cross-validation of slow dynamical modes in molecular\n  kinetics", "comments": null, "journal-ref": "J. Chem. Phys. 142, 124105 (2015)", "doi": "10.1063/1.4916292", "report-no": null, "categories": "q-bio.BM math.ST physics.bio-ph physics.chem-ph stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Markov state models (MSMs) are a widely used method for approximating the\neigenspectrum of the molecular dynamics propagator, yielding insight into the\nlong-timescale statistical kinetics and slow dynamical modes of biomolecular\nsystems. However, the lack of a unified theoretical framework for choosing\nbetween alternative models has hampered progress, especially for non-experts\napplying these methods to novel biological systems. Here, we consider\ncross-validation with a new objective function for estimators of these slow\ndynamical modes, a generalized matrix Rayleigh quotient (GMRQ), which measures\nthe ability of a rank-$m$ projection operator to capture the slow subspace of\nthe system. It is shown that a variational theorem bounds the GMRQ from above\nby the sum of the first $m$ eigenvalues of the system's propagator, but that\nthis bound can be violated when the requisite matrix elements are estimated\nsubject to statistical uncertainty. This overfitting can be detected and\navoided through cross-validation. These result make it possible to construct\nMarkov state models for protein dynamics in a way that appropriately captures\nthe tradeoff between systematic and statistical errors.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jul 2014 15:22:09 GMT"}, {"version": "v2", "created": "Fri, 30 Jan 2015 19:53:55 GMT"}, {"version": "v3", "created": "Fri, 27 Mar 2015 18:39:51 GMT"}], "update_date": "2015-03-30", "authors_parsed": [["McGibbon", "Robert T.", ""], ["Pande", "Vijay S.", ""]]}, {"id": "1407.8225", "submitter": "Ryan Martin", "authors": "Chuanhai Liu and Ryan Martin", "title": "Frameworks for prior-free posterior probabilistic inference", "comments": "14 pages, 1 figure; to appear in WIREs Computational Statistics", "journal-ref": "WIREs Computational Statistics, volume 7, pages 77--85, 2015", "doi": "10.1002/wics.1329", "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The development of statistical methods for valid and efficient probabilistic\ninference without prior distributions has a long history. Fisher's fiducial\ninference is perhaps the most famous of these attempts. We argue that, despite\nits seemingly prior-free formulation, fiducial and its various extensions are\nnot prior-free and, therefore, do not meet the requirements for prior-free\nprobabilistic inference. In contrast, the inferential model (IM) framework is\ngenuinely prior-free and is shown to be a promising new method for generating\nboth valid and efficient probabilistic inference. With a brief introduction to\nthe two fundamental principles, namely, the validity and efficiency principles,\nthe three-step construction of the basic IM framework is discussed in the\ncontext of the validity principle. Efficient IM methods, based on conditioning\nand marginalization are illustrated with two benchmark examples, namely, the\nbivariate normal with unknown correlation coefficient and the Behrens--Fisher\nproblem.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jul 2014 21:51:27 GMT"}], "update_date": "2015-01-20", "authors_parsed": [["Liu", "Chuanhai", ""], ["Martin", "Ryan", ""]]}, {"id": "1407.8246", "submitter": "Deanna Needell", "authors": "Richard Baraniuk, Simon Foucart, Deanna Needell, Yaniv Plan, Mary\n  Wootters", "title": "Exponential decay of reconstruction error from binary measurements of\n  sparse signals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Binary measurements arise naturally in a variety of statistical and\nengineering applications. They may be inherent to the problem---e.g., in\ndetermining the relationship between genetics and the presence or absence of a\ndisease---or they may be a result of extreme quantization. In one-bit\ncompressed sensing it has recently been shown that the number of one-bit\nmeasurements required for signal estimation mirrors that of unquantized\ncompressed sensing. Indeed, $s$-sparse signals in $\\mathbb{R}^n$ can be\nestimated (up to normalization) from $\\Omega(s \\log (n/s))$ one-bit\nmeasurements. Nevertheless, controlling the precise accuracy of the error\nestimate remains an open challenge. In this paper, we focus on optimizing the\ndecay of the error as a function of the oversampling factor $\\lambda := m/(s\n\\log(n/s))$, where $m$ is the number of measurements. It is known that the\nerror in reconstructing sparse signals from standard one-bit measurements is\nbounded below by $\\Omega(\\lambda^{-1})$. Without adjusting the measurement\nprocedure, reducing this polynomial error decay rate is impossible. However, we\nshow that an adaptive choice of the thresholds used for quantization may lower\nthe error rate to $e^{-\\Omega(\\lambda)}$. This improves upon guarantees for\nother methods of adaptive thresholding as proposed in Sigma-Delta quantization.\nWe develop a general recursive strategy to achieve this exponential decay and\ntwo specific polynomial-time algorithms which fall into this framework, one\nbased on convex programming and one on hard thresholding. This work is inspired\nby the one-bit compressed sensing model, in which the engineer controls the\nmeasurement procedure. Nevertheless, the principle is extendable to signal\nreconstruction problems in a variety of binary statistical models as well as\nstatistical estimation problems like logistic regression.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jul 2014 00:41:18 GMT"}], "update_date": "2014-08-01", "authors_parsed": [["Baraniuk", "Richard", ""], ["Foucart", "Simon", ""], ["Needell", "Deanna", ""], ["Plan", "Yaniv", ""], ["Wootters", "Mary", ""]]}, {"id": "1407.8300", "submitter": "Ting Kam Leonard Wong", "authors": "Ting-Kam Leonard Wong", "title": "Optimization of relative arbitrage", "comments": "33 pages, 5 figures, 2 tables; revised version", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PM math.OC math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In stochastic portfolio theory, a relative arbitrage is an equity portfolio\nwhich is guaranteed to outperform a benchmark portfolio over a finite horizon.\nWhen the market is diverse and sufficiently volatile, and the benchmark is the\nmarket or a buy-and-hold portfolio, functionally generated portfolios\nintroduced by Fernholz provide a systematic way of constructing relative\narbitrages. In this paper we show that if the market portfolio is replaced by\nthe equal or entropy weighted portfolio among many others, no relative\narbitrages can be constructed under the same conditions using functionally\ngenerated portfolios. We also introduce and study a shaped-constrained\noptimization problem for functionally generated portfolios in the spirit of\nmaximum likelihood estimation of a log-concave density.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jul 2014 07:25:13 GMT"}, {"version": "v2", "created": "Tue, 5 Aug 2014 01:37:17 GMT"}, {"version": "v3", "created": "Mon, 24 Nov 2014 22:08:58 GMT"}], "update_date": "2014-11-26", "authors_parsed": [["Wong", "Ting-Kam Leonard", ""]]}, {"id": "1407.8375", "submitter": "Andrew Francis", "authors": "Andrew R. Francis, Milan Stehlik, Henry P. Wynn", "title": "\"Building\" exact confidence nets", "comments": "20 pages. To appear in Bernoulli", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.GR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Confidence nets, that is, collections of confidence intervals that fill out\nthe parameter space and whose exact parameter coverage can be computed, are\nfamiliar in nonparametric statistics. Here, the distributional assumptions are\nbased on invariance under the action of a finite reflection group. Exact\nconfidence nets are exhibited for a single parameter, based on the root system\nof the group. The main result is a formula for the generating function of the\ncoverage interval probabilities. The proof makes use of the theory of\n\"buildings\" and the Chevalley factorization theorem for the length distribution\non Cayley graphs of finite reflection groups.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jul 2014 12:16:36 GMT"}, {"version": "v2", "created": "Fri, 22 Aug 2014 01:44:46 GMT"}, {"version": "v3", "created": "Wed, 30 Dec 2015 04:52:25 GMT"}, {"version": "v4", "created": "Wed, 9 Mar 2016 23:41:52 GMT"}], "update_date": "2016-03-11", "authors_parsed": [["Francis", "Andrew R.", ""], ["Stehlik", "Milan", ""], ["Wynn", "Henry P.", ""]]}]