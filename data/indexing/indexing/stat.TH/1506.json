[{"id": "1506.00034", "submitter": "Charles R Doss", "authors": "Charles R. Doss", "title": "Bracketing numbers of convex and $m$-monotone functions on polytopes", "comments": "42 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study bracketing covering numbers for spaces of bounded convex functions\nin the $L_p$ norms. Bracketing numbers are crucial quantities for understanding\nasymptotic behavior for many statistical nonparametric estimators. Bracketing\nnumber upper bounds in the supremum distance are known for bounded classes that\nalso have a fixed Lipschitz constraint. However, in most settings of interest,\nthe classes that arise do not include Lipschitz constraints, and so standard\ntechniques based on known bracketing numbers cannot be used. In this paper, we\nfind upper bounds for bracketing numbers of classes of convex functions without\nLipschitz constraints on arbitrary polytopes. Our results are of particular\ninterest in many multidimensional estimation problems based on convexity shape\nconstraints.\n  Additionally, we show other applications of our proof methods; in particular\nwe define a new class of multivariate functions, the so-called $m$-monotone\nfunctions. Such functions have been considered mathematically and statistically\nin the univariate case but never in the multivariate case. We show how our\nproof for convex bracketing upper bounds also applies to the $m$-monotone case.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2015 21:34:24 GMT"}, {"version": "v2", "created": "Sat, 4 Nov 2017 20:51:22 GMT"}, {"version": "v3", "created": "Tue, 14 Apr 2020 18:28:40 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["Doss", "Charles R.", ""]]}, {"id": "1506.00054", "submitter": "Justin Kinney", "authors": "Gurinder S. Atwal and Justin B. Kinney", "title": "Learning quantitative sequence-function relationships from massively\n  parallel experiments", "comments": "35 pages, 8 figures. Revised manuscript currently under review for\n  publication", "journal-ref": null, "doi": "10.1007/s10955-015-1398-3", "report-no": null, "categories": "q-bio.QM math.ST physics.bio-ph physics.data-an stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fundamental aspect of biological information processing is the ubiquity of\nsequence-function relationships -- functions that map the sequence of DNA, RNA,\nor protein to a biochemically relevant activity. Most sequence-function\nrelationships in biology are quantitative, but only recently have experimental\ntechniques for effectively measuring these relationships been developed. The\nadvent of such \"massively parallel\" experiments presents an exciting\nopportunity for the concepts and methods of statistical physics to inform the\nstudy of biological systems. After reviewing these recent experimental\nadvances, we focus on the problem of how to infer parametric models of\nsequence-function relationships from the data produced by these experiments.\nSpecifically, we retrace and extend recent theoretical work showing that\ninference based on mutual information, not the standard likelihood-based\napproach, is often necessary for accurately learning the parameters of these\nmodels. Closely connected with this result is the emergence of \"diffeomorphic\nmodes\" -- directions in parameter space that are far less constrained by data\nthan likelihood-based inference would suggest. Analogous to Goldstone modes in\nphysics, diffeomorphic modes arise from an arbitrarily broken symmetry of the\ninference problem. An analytically tractable model of a massively parallel\nexperiment is then described, providing an explicit demonstration of these\nfundamental aspects of statistical inference. This paper concludes with an\noutlook on the theoretical and computational challenges currently facing\nstudies of quantitative sequence-function relationships.\n", "versions": [{"version": "v1", "created": "Sat, 30 May 2015 01:20:59 GMT"}, {"version": "v2", "created": "Tue, 22 Sep 2015 15:47:20 GMT"}], "update_date": "2016-03-23", "authors_parsed": [["Atwal", "Gurinder S.", ""], ["Kinney", "Justin B.", ""]]}, {"id": "1506.00088", "submitter": "Adam D. Bull", "authors": "Adam D. Bull", "title": "Semimartingale detection and goodness-of-fit tests", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST q-fin.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In quantitative finance, we often fit a parametric semimartingale model to\nasset prices. To ensure our model is correct, we must then perform\ngoodness-of-fit tests. In this paper, we give a new goodness-of-fit test for\nvolatility-like processes, which is easily applied to a variety of\nsemimartingale models. In each case, we reduce the problem to the detection of\na semimartingale observed under noise. In this setting, we then describe a\nwavelet-thresholding test, which obtains adaptive and near-optimal detection\nrates.\n", "versions": [{"version": "v1", "created": "Sat, 30 May 2015 07:45:06 GMT"}, {"version": "v2", "created": "Tue, 29 Sep 2015 11:37:56 GMT"}, {"version": "v3", "created": "Sun, 28 Feb 2016 15:25:53 GMT"}, {"version": "v4", "created": "Mon, 6 Jun 2016 18:12:46 GMT"}], "update_date": "2016-06-07", "authors_parsed": [["Bull", "Adam D.", ""]]}, {"id": "1506.00089", "submitter": "Guangming Pan", "authors": "X. Han, G. M. Pan and B. Zhang", "title": "The Tracy-Widom law for the Largest Eigenvalue of F Type Matrix", "comments": "50", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $\\mathbb{A}_p=\\frac{\\mathbb{Y}\\mathbb{Y}^*}{m}$ and\n$\\mathbb{B}_p=\\frac{\\mathbb{X}\\mathbb{X}^*}{n}$ be two independent random\nmatrices where $\\mathbb{X}=(X_{ij})_{p \\times n}$ and $\\mathbb{Y}=(Y_{ij})_{p\n\\times m}$ respectively consist of real (or complex) independent random\nvariables with $\\mathbb{E}X_{ij}=\\mathbb{E}Y_{ij}=0$,\n$\\mathbb{E}|X_{ij}|^2=\\mathbb{E}|Y_{ij}|^2=1$. Denote by $\\lambda_{1}$ the\nlargest root of the determinantal equation $\\det(\\lambda\n\\mathbb{A}_p-\\mathbb{B}_p)=0$. We establish the Tracy-Widom type universality\nfor $\\lambda_{1}$ under some moment conditions on $X_{ij}$ and $Y_{ij}$ when\n$p/m$ and $p/n$ approach positive constants as $p\\rightarrow\\infty$.\n", "versions": [{"version": "v1", "created": "Sat, 30 May 2015 08:00:14 GMT"}], "update_date": "2015-06-02", "authors_parsed": [["Han", "X.", ""], ["Pan", "G. M.", ""], ["Zhang", "B.", ""]]}, {"id": "1506.00414", "submitter": "Qing Huang", "authors": "Qing Huang, Rosemary Renaut", "title": "Functional partial canonical correlation", "comments": "Published at http://dx.doi.org/10.3150/14-BEJ597 in the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2015, Vol. 21, No. 2, 1047-1066", "doi": "10.3150/14-BEJ597", "report-no": "IMS-BEJ-BEJ597", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A rigorous derivation is provided for canonical correlations and partial\ncanonical correlations for certain Hilbert space indexed stochastic processes.\nThe formulation relies on a key congruence mapping between the space spanned by\na second order, $\\mathcal{H}$-valued, process and a particular Hilbert function\nspace deriving from the process' covariance operator. The main results are\nobtained via an application of methodology for constructing orthogonal direct\nsums from algebraic direct sums of closed subspaces.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2015 10:02:11 GMT"}], "update_date": "2015-06-02", "authors_parsed": [["Huang", "Qing", ""], ["Renaut", "Rosemary", ""]]}, {"id": "1506.00458", "submitter": "Binbin Chen", "authors": "Binbin Chen, Guangming Pan", "title": "CLT for linear spectral statistics of normalized sample covariance\n  matrices with the dimension much larger than the sample size", "comments": "Published at http://dx.doi.org/10.3150/14-BEJ599 in the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2015, Vol. 21, No. 2, 1089-1133", "doi": "10.3150/14-BEJ599", "report-no": "IMS-BEJ-BEJ599", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $\\mathbf{A}=\\frac{1}{\\sqrt{np}}(\\mathbf{X}^T\\mathbf{X}-p\\mathbf {I}_n)$\nwhere $\\mathbf{X}$ is a $p\\times n$ matrix, consisting of independent and\nidentically distributed (i.i.d.) real random variables $X_{ij}$ with mean zero\nand variance one. When $p/n\\to\\infty$, under fourth moment conditions a central\nlimit theorem (CLT) for linear spectral statistics (LSS) of $\\mathbf{A}$\ndefined by the eigenvalues is established. We also explore its applications in\ntesting whether a population covariance matrix is an identity matrix.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2015 11:58:43 GMT"}], "update_date": "2015-06-02", "authors_parsed": [["Chen", "Binbin", ""], ["Pan", "Guangming", ""]]}, {"id": "1506.00515", "submitter": "Jan van Waaij MSc", "authors": "Jan van Waaij, Harry van Zanten", "title": "Gaussian process methods for one-dimensional diffusions: optimal rates\n  and adaptation", "comments": null, "journal-ref": null, "doi": "10.1214/16-EJS1117", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the performance of nonparametric Bayes procedures for\none-dimensional diffusions with periodic drift. We improve existing convergence\nrate results for Gaussian process (GP) priors with fixed hyper parameters.\nMoreover, we exhibit several possibilities to achieve adaptation to smoothness.\nWe achieve this by considering hierarchical procedures that involve either a\nprior on a multiplicative scaling parameter, or a prior on the regularity\nparameter of the GP.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2015 14:45:45 GMT"}, {"version": "v2", "created": "Mon, 21 Sep 2015 10:11:44 GMT"}, {"version": "v3", "created": "Mon, 8 Feb 2016 10:43:37 GMT"}], "update_date": "2017-06-15", "authors_parsed": [["van Waaij", "Jan", ""], ["van Zanten", "Harry", ""]]}, {"id": "1506.00669", "submitter": "Roman Vershynin", "authors": "Can M. Le, Elizaveta Levina and Roman Vershynin", "title": "Concentration and regularization of random graphs", "comments": "21 pages. Elizaveta Levina is added as a co-author. Application to\n  community detection of networks is expanded", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.SI math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies how close random graphs are typically to their\nexpectations. We interpret this question through the concentration of the\nadjacency and Laplacian matrices in the spectral norm. We study inhomogeneous\nErd\\\"os-R\\'enyi random graphs on $n$ vertices, where edges form independently\nand possibly with different probabilities $p_{ij}$. Sparse random graphs whose\nexpected degrees are $o(\\log n)$ fail to concentrate; the obstruction is caused\nby vertices with abnormally high and low degrees. We show that concentration\ncan be restored if we regularize the degrees of such vertices, and one can do\nthis in various ways. As an example, let us reweight or remove enough edges to\nmake all degrees bounded above by $O(d)$ where $d=\\max np_{ij}$. Then we show\nthat the resulting adjacency matrix $A'$ concentrates with the optimal rate:\n$\\|A' - \\mathbb{E} A\\| = O(\\sqrt{d})$. Similarly, if we make all degrees\nbounded below by $d$ by adding weight $d/n$ to all edges, then the resulting\nLaplacian concentrates with the optimal rate: $\\|L(A') - L(\\mathbb{E} A')\\| =\nO(1/\\sqrt{d})$. Our approach is based on Grothendieck-Pietsch factorization,\nusing which we construct a new decomposition of random graphs. We illustrate\nthe concentration results with an application to the community detection\nproblem in the analysis of networks.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2015 20:42:28 GMT"}, {"version": "v2", "created": "Tue, 9 Aug 2016 18:48:47 GMT"}], "update_date": "2016-08-10", "authors_parsed": [["Le", "Can M.", ""], ["Levina", "Elizaveta", ""], ["Vershynin", "Roman", ""]]}, {"id": "1506.00671", "submitter": "Ludwig Schmidt", "authors": "Jayadev Acharya, Ilias Diakonikolas, Jerry Li, Ludwig Schmidt", "title": "Sample-Optimal Density Estimation in Nearly-Linear Time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.IT cs.LG math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We design a new, fast algorithm for agnostically learning univariate\nprobability distributions whose densities are well approximated by piecewise\npolynomial functions. Let $f$ be the density function of an arbitrary\nunivariate distribution, and suppose that $f$ is $\\mathrm{OPT}$-close in\n$L_1$-distance to an unknown piecewise polynomial function with $t$ interval\npieces and degree $d$. Our algorithm draws $n = O(t(d+1)/\\epsilon^2)$ samples\nfrom $f$, runs in time $\\tilde{O}(n \\cdot \\mathrm{poly}(d))$, and with\nprobability at least $9/10$ outputs an $O(t)$-piecewise degree-$d$ hypothesis\n$h$ that is $4 \\cdot \\mathrm{OPT} +\\epsilon$ close to $f$.\n  Our general algorithm yields (nearly) sample-optimal and nearly-linear time\nestimators for a wide range of structured distribution families over both\ncontinuous and discrete domains in a unified way. For most of our applications,\nthese are the first sample-optimal and nearly-linear time estimators in the\nliterature. As a consequence, our work resolves the sample and computational\ncomplexities of a broad class of inference tasks via a single \"meta-algorithm\".\nMoreover, we experimentally demonstrate that our algorithm performs very well\nin practice.\n  Our algorithm consists of three \"levels\": (i) At the top level, we employ an\niterative greedy algorithm for finding a good partition of the real line into\nthe pieces of a piecewise polynomial. (ii) For each piece, we show that the\nsub-problem of finding a good polynomial fit on the current interval can be\nsolved efficiently with a separation oracle method. (iii) We reduce the task of\nfinding a separating hyperplane to a combinatorial problem and give an\nefficient algorithm for this problem. Combining these three procedures gives a\ndensity estimation algorithm with the claimed guarantees.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2015 20:44:22 GMT"}], "update_date": "2015-06-03", "authors_parsed": [["Acharya", "Jayadev", ""], ["Diakonikolas", "Ilias", ""], ["Li", "Jerry", ""], ["Schmidt", "Ludwig", ""]]}, {"id": "1506.00673", "submitter": "Rahul Agarwal", "authors": "Rahul Agarwal, Pierre Sacre, and Sridevi V. Sarma", "title": "Mutual Dependence: A Novel Method for Computing Dependencies Between\n  Random Variables", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In data science, it is often required to estimate dependencies between\ndifferent data sources. These dependencies are typically calculated using\nPearson's correlation, distance correlation, and/or mutual information.\nHowever, none of these measures satisfy all the Granger's axioms for an \"ideal\nmeasure\". One such ideal measure, proposed by Granger himself, calculates the\nBhattacharyya distance between the joint probability density function (pdf) and\nthe product of marginal pdfs. We call this measure the mutual dependence.\nHowever, to date this measure has not been directly computable from data. In\nthis paper, we use our recently introduced maximum likelihood non-parametric\nestimator for band-limited pdfs, to compute the mutual dependence directly from\nthe data. We construct the estimator of mutual dependence and compare its\nperformance to standard measures (Pearson's and distance correlation) for\ndifferent known pdfs by computing convergence rates, computational complexity,\nand the ability to capture nonlinear dependencies. Our mutual dependence\nestimator requires fewer samples to converge to theoretical values, is faster\nto compute, and captures more complex dependencies than standard measures.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2015 20:53:45 GMT"}], "update_date": "2015-06-03", "authors_parsed": [["Agarwal", "Rahul", ""], ["Sacre", "Pierre", ""], ["Sarma", "Sridevi V.", ""]]}, {"id": "1506.00691", "submitter": "Chao Gao", "authors": "Mengjie Chen, Chao Gao, Zhao Ren", "title": "Robust Covariance and Scatter Matrix Estimation under Huber's\n  Contamination Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Covariance matrix estimation is one of the most important problems in\nstatistics. To accommodate the complexity of modern datasets, it is desired to\nhave estimation procedures that not only can incorporate the structural\nassumptions of covariance matrices, but are also robust to outliers from\narbitrary sources. In this paper, we define a new concept called matrix depth\nand then propose a robust covariance matrix estimator by maximizing the\nempirical depth function. The proposed estimator is shown to achieve minimax\noptimal rate under Huber's $\\epsilon$-contamination model for estimating\ncovariance/scatter matrices with various structures including bandedness and\nsparsity.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2015 22:08:52 GMT"}, {"version": "v2", "created": "Fri, 3 Jul 2015 16:06:57 GMT"}, {"version": "v3", "created": "Thu, 30 Jul 2015 19:38:24 GMT"}, {"version": "v4", "created": "Mon, 12 Jun 2017 15:58:11 GMT"}], "update_date": "2017-06-13", "authors_parsed": [["Chen", "Mengjie", ""], ["Gao", "Chao", ""], ["Ren", "Zhao", ""]]}, {"id": "1506.00748", "submitter": "Hisayuki Tsukuma", "authors": "Hisayuki Tsukuma", "title": "Estimation of a high-dimensional covariance matrix with the Stein loss", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of estimating a normal covariance matrix is considered from a\ndecision-theoretic point of view, where the dimension of the covariance matrix\nis larger than the sample size. This paper addresses not only the nonsingular\ncase but also the singular case in terms of the covariance matrix. Based on\nJames and Stein's minimax estimator and on an orthogonally invariant estimator,\nsome classes of estimators are unifiedly defined for any possible ordering on\nthe dimension, the sample size and the rank of the covariance matrix. Unified\ndominance results on such classes are provided under a Stein-type entropy loss.\nThe unified dominance results are applied to improving on an empirical Bayes\nestimator of a high-dimensional covariance matrix.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2015 04:53:38 GMT"}], "update_date": "2015-06-03", "authors_parsed": [["Tsukuma", "Hisayuki", ""]]}, {"id": "1506.00816", "submitter": "Carsten Jentsch", "authors": "Carsten Jentsch, Dimitris N. Politis", "title": "Covariance matrix estimation and linear process bootstrap for\n  multivariate time series of possibly increasing dimension", "comments": "Published at http://dx.doi.org/10.1214/14-AOS1301 in the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2015, Vol. 43, No. 3, 1117-1140", "doi": "10.1214/14-AOS1301", "report-no": "IMS-AOS-AOS1301", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multivariate time series present many challenges, especially when they are\nhigh dimensional. The paper's focus is twofold. First, we address the subject\nof consistently estimating the autocovariance sequence; this is a sequence of\nmatrices that we conveniently stack into one huge matrix. We are then able to\nshow consistency of an estimator based on the so-called flat-top tapers; most\nimportantly, the consistency holds true even when the time series dimension is\nallowed to increase with the sample size. Second, we revisit the linear process\nbootstrap (LPB) procedure proposed by McMurry and Politis [J. Time Series Anal.\n31 (2010) 471-482] for univariate time series. Based on the aforementioned\nstacked autocovariance matrix estimator, we are able to define a version of the\nLPB that is valid for multivariate time series. Under rather general\nassumptions, we show that our multivariate linear process bootstrap (MLPB) has\nasymptotic validity for the sample mean in two important cases: (a) when the\ntime series dimension is fixed and (b) when it is allowed to increase with\nsample size. As an aside, in case (a) we show that the MLPB works also for\nspectral density estimators which is a novel result even in the univariate\ncase. We conclude with a simulation study that demonstrates the superiority of\nthe MLPB in some important cases.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2015 09:52:27 GMT"}], "update_date": "2015-06-03", "authors_parsed": [["Jentsch", "Carsten", ""], ["Politis", "Dimitris N.", ""]]}, {"id": "1506.00827", "submitter": "Carsten Jentsch", "authors": "Carsten Jentsch, Markus Pauly", "title": "Testing equality of spectral densities using randomization techniques", "comments": "Published at http://dx.doi.org/10.3150/13-BEJ584 in the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2015, Vol. 21, No. 2, 697-739", "doi": "10.3150/13-BEJ584", "report-no": "IMS-BEJ-BEJ584", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the testing problem that the spectral density\nmatrices of several, not necessarily independent, stationary processes are\nequal. Based on an $L_2$-type test statistic, we propose a new nonparametric\napproach, where the critical values of the tests are calculated with the help\nof randomization methods. We analyze asymptotic exactness and consistency of\nthese randomization tests and show in simulation studies that the new\nprocedures posses very good size and power characteristics.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2015 10:24:28 GMT"}], "update_date": "2015-06-03", "authors_parsed": [["Jentsch", "Carsten", ""], ["Pauly", "Markus", ""]]}, {"id": "1506.00834", "submitter": "Yang Feng", "authors": "Yang Feng, Yuguo Chen, Xuming He", "title": "Bayesian quantile regression with approximate likelihood", "comments": "Published at http://dx.doi.org/10.3150/13-BEJ589 in the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2015, Vol. 21, No. 2, 832-850", "doi": "10.3150/13-BEJ589", "report-no": "IMS-BEJ-BEJ589", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantile regression is often used when a comprehensive relationship between a\nresponse variable and one or more explanatory variables is desired. The\ntraditional frequentists' approach to quantile regression has been well\ndeveloped around asymptotic theories and efficient algorithms. However, not\nmuch work has been published under the Bayesian framework. One challenging\nproblem for Bayesian quantile regression is that the full likelihood has no\nparametric forms. In this paper, we propose a Bayesian quantile regression\nmethod, the linearly interpolated density (LID) method, which uses a linear\ninterpolation of the quantiles to approximate the likelihood. Unlike most of\nthe existing methods that aim at tackling one quantile at a time, our proposed\nmethod estimates the joint posterior distribution of multiple quantiles,\nleading to higher global efficiency for all quantiles of interest. Markov chain\nMonte Carlo algorithms are developed to carry out the proposed method. We\nprovide convergence results that justify both the algorithmic convergence and\nstatistical approximations to an integrated-likelihood-based posterior. From\nthe simulation results, we verify that LID has a clear advantage over other\nexisting methods in estimating quantities that relate to two or more quantiles.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2015 10:54:09 GMT"}], "update_date": "2015-06-03", "authors_parsed": [["Feng", "Yang", ""], ["Chen", "Yuguo", ""], ["He", "Xuming", ""]]}, {"id": "1506.00847", "submitter": "Xianyang Zhang", "authors": "Xianyang Zhang, Xiaofeng Shao", "title": "Two sample inference for the second-order property of temporally\n  dependent functional data", "comments": "Published at http://dx.doi.org/10.3150/13-BEJ592 in the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2015, Vol. 21, No. 2, 909-929", "doi": "10.3150/13-BEJ592", "report-no": "IMS-BEJ-BEJ592", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the need to statistically quantify the difference between two\nspatio-temporal datasets that arise in climate downscaling studies, we propose\nnew tests to detect the differences of the covariance operators and their\nassociated characteristics of two functional time series. Our two sample tests\nare constructed on the basis of functional principal component analysis and\nself-normalization, the latter of which is a new studentization technique\nrecently developed for the inference of a univariate time series. Compared to\nthe existing tests, our SN-based tests allow for weak dependence within each\nsample and it is robust to the dependence between the two samples in the case\nof equal sample sizes. Asymptotic properties of the SN-based test statistics\nare derived under both the null and local alternatives. Through extensive\nsimulations, our SN-based tests are shown to outperform existing alternatives\nin size and their powers are found to be respectable. The tests are then\napplied to the gridded climate model outputs and interpolated observations to\ndetect the difference in their spatial dynamics.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2015 11:39:48 GMT"}], "update_date": "2015-06-03", "authors_parsed": [["Zhang", "Xianyang", ""], ["Shao", "Xiaofeng", ""]]}, {"id": "1506.00850", "submitter": "Yuqiang Li", "authors": "Yuqiang Li, Wensheng Wang, Yimin Xiao", "title": "Exact moduli of continuity for operator-scaling Gaussian random fields", "comments": "Published at http://dx.doi.org/10.3150/13-BEJ593 in the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2015, Vol. 21, No. 2, 930-956", "doi": "10.3150/13-BEJ593", "report-no": "IMS-BEJ-BEJ593", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $X=\\{X(t),t\\in\\mathrm{R}^N\\}$ be a centered real-valued operator-scaling\nGaussian random field with stationary increments, introduced by Bierm\\'{e},\nMeerschaert and Scheffler (Stochastic Process. Appl. 117 (2007) 312-332). We\nprove that $X$ satisfies a form of strong local nondeterminism and establish\nits exact uniform and local moduli of continuity. The main results are\nexpressed in terms of the quasi-metric $\\tau_E$ associated with the scaling\nexponent of $X$. Examples are provided to illustrate the subtle changes of the\nregularity properties.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2015 11:59:17 GMT"}], "update_date": "2015-06-03", "authors_parsed": [["Li", "Yuqiang", ""], ["Wang", "Wensheng", ""], ["Xiao", "Yimin", ""]]}, {"id": "1506.00859", "submitter": "Alexander Aue", "authors": "Alexander Aue, Christopher Dienes, Stefan Fremdt, Josef Steinebach", "title": "Reaction times of monitoring schemes for ARMA time series", "comments": "Published at http://dx.doi.org/10.3150/14-BEJ604 in the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2015, Vol. 21, No. 2, 1238-1259", "doi": "10.3150/14-BEJ604", "report-no": "IMS-BEJ-BEJ604", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is concerned with deriving the limit distributions of stopping\ntimes devised to sequentially uncover structural breaks in the parameters of an\nautoregressive moving average, ARMA, time series. The stopping rules are\ndefined as the first time lag for which detectors, based on CUSUMs and Page's\nCUSUMs for residuals, exceed the value of a prescribed threshold function. It\nis shown that the limit distributions crucially depend on a drift term induced\nby the underlying ARMA parameters. The precise form of the asymptotic is\ndetermined by an interplay between the location of the break point and the size\nof the change implied by the drift. The theoretical results are accompanied by\na simulation study and applications to electroencephalography, EEG, and IBM\ndata. The empirical results indicate a satisfactory behavior in finite samples.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2015 12:31:48 GMT"}], "update_date": "2015-06-03", "authors_parsed": [["Aue", "Alexander", ""], ["Dienes", "Christopher", ""], ["Fremdt", "Stefan", ""], ["Steinebach", "Josef", ""]]}, {"id": "1506.00970", "submitter": "Siegfried H\\\"ormann", "authors": "Cl\\'ement Cerovecki and Siegfried H\\\"ormann", "title": "On the CLT for discrete Fourier transforms of functional time series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a strictly stationary and ergodic sequence of random elements\ntaking values in some Hilbert space. Our target is to study the weak\nconvergence of the discrete Fourier transforms under sharp conditions. As a\nside-result we obtain the regular CLT for partial sums under mild assumptions.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2015 17:43:48 GMT"}, {"version": "v2", "created": "Fri, 4 Dec 2015 13:32:41 GMT"}], "update_date": "2015-12-07", "authors_parsed": [["Cerovecki", "Cl\u00e9ment", ""], ["H\u00f6rmann", "Siegfried", ""]]}, {"id": "1506.01338", "submitter": "Hossein Keshavarz", "authors": "Hossein Keshavarz, Clayton Scott, XuanLong Nguyen", "title": "Optimal change point detection in Gaussian processes", "comments": "42 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT cs.LG math.IT stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of detecting a change in the mean of one-dimensional\nGaussian process data. This problem is investigated in the setting of\nincreasing domain (customarily employed in time series analysis) and in the\nsetting of fixed domain (typically arising in spatial data analysis). We\npropose a detection method based on the generalized likelihood ratio test\n(GLRT), and show that our method achieves nearly asymptotically optimal rate in\nthe minimax sense, in both settings. The salient feature of the proposed method\nis that it exploits in an efficient way the data dependence captured by the\nGaussian process covariance structure. When the covariance is not known, we\npropose the plug-in GLRT method and derive conditions under which the method\nremains asymptotically near optimal. By contrast, the standard CUSUM method,\nwhich does not account for the covariance structure, is shown to be\nasymptotically optimal only in the increasing domain. Our algorithms and\naccompanying theory are applicable to a wide variety of covariance structures,\nincluding the Matern class, the powered exponential class, and others. The\nplug-in GLRT method is shown to perform well for maximum likelihood estimators\nwith a dense covariance matrix.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jun 2015 18:05:30 GMT"}, {"version": "v2", "created": "Sat, 8 Apr 2017 00:07:03 GMT"}], "update_date": "2017-04-11", "authors_parsed": [["Keshavarz", "Hossein", ""], ["Scott", "Clayton", ""], ["Nguyen", "XuanLong", ""]]}, {"id": "1506.01367", "submitter": "Ludwig Schmidt", "authors": "Jerry Li, Ludwig Schmidt", "title": "A Nearly Optimal and Agnostic Algorithm for Properly Learning a Mixture\n  of k Gaussians, for any Constant k", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.IT cs.LG math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning a Gaussian mixture model (GMM) is a fundamental problem in machine\nlearning, learning theory, and statistics. One notion of learning a GMM is\nproper learning: here, the goal is to find a mixture of $k$ Gaussians\n$\\mathcal{M}$ that is close to the density $f$ of the unknown distribution from\nwhich we draw samples. The distance between $\\mathcal{M}$ and $f$ is typically\nmeasured in the total variation or $L_1$-norm.\n  We give an algorithm for learning a mixture of $k$ univariate Gaussians that\nis nearly optimal for any fixed $k$. The sample complexity of our algorithm is\n$\\tilde{O}(\\frac{k}{\\epsilon^2})$ and the running time is $(k \\cdot\n\\log\\frac{1}{\\epsilon})^{O(k^4)} + \\tilde{O}(\\frac{k}{\\epsilon^2})$. It is\nwell-known that this sample complexity is optimal (up to logarithmic factors),\nand it was already achieved by prior work. However, the best known time\ncomplexity for proper learning a $k$-GMM was\n$\\tilde{O}(\\frac{1}{\\epsilon^{3k-1}})$. In particular, the dependence between\n$\\frac{1}{\\epsilon}$ and $k$ was exponential. We significantly improve this\ndependence by replacing the $\\frac{1}{\\epsilon}$ term with a $\\log\n\\frac{1}{\\epsilon}$ while only increasing the exponent moderately. Hence, for\nany fixed $k$, the $\\tilde{O} (\\frac{k}{\\epsilon^2})$ term dominates our\nrunning time, and thus our algorithm runs in time which is nearly-linear in the\nnumber of samples drawn. Achieving a running time of $\\textrm{poly}(k,\n\\frac{1}{\\epsilon})$ for proper learning of $k$-GMMs has recently been stated\nas an open problem by multiple researchers, and we make progress on this\nquestion.\n  Moreover, our approach offers an agnostic learning guarantee: our algorithm\nreturns a good GMM even if the distribution we are sampling from is not a\nmixture of Gaussians. To the best of our knowledge, our algorithm is the first\nagnostic proper learning algorithm for GMMs.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jun 2015 19:55:10 GMT"}], "update_date": "2015-06-04", "authors_parsed": [["Li", "Jerry", ""], ["Schmidt", "Ludwig", ""]]}, {"id": "1506.01391", "submitter": "Shaojun Guo", "authors": "Dong Li, Shaojun Guo and Ke Zhu", "title": "A Double AR Model Without Intercept: an Alternative to Modeling\n  Nonstationarity and Heteroscedasticity", "comments": "18 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a double AR model without intercept (DARWIN model) and\nprovides us a new way to study the non-stationary heteroskedastic time series.\nIt is shown that the DARWIN model is always non-stationary and heteroskedastic,\nand its sample properties depends on the Lyapunov exponent. An\neasy-to-implement estimator is proposed for the Lyapunov exponent, and it is\nunbiased, strongly consistent and asymptotically normal. Based on this\nestimator, a powerful test is constructed for testing the stability of the\nmodel. Moreover, this paper proposes the quasi-maximum likelihood estimator\n(QMLE) for the DARWIN model, which has an explicit form. The strong consistency\nand asymptotical normality of the QMLE are established regardless of the sign\nof the Lyapunov exponent. Simulation studies are conducted to assess the\nperformance of the estimation and testing and an empirical example is given for\nillustrating the usefulness of the DARWIN model.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jun 2015 20:21:03 GMT"}], "update_date": "2015-06-05", "authors_parsed": [["Li", "Dong", ""], ["Guo", "Shaojun", ""], ["Zhu", "Ke", ""]]}, {"id": "1506.01478", "submitter": "Jie Yen Fan", "authors": "Jie Yen Fan, Kais Hamza, Fima Klebaner", "title": "Mimicking self-similar processes", "comments": "Published at http://dx.doi.org/10.3150/13-BEJ588 in the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2015, Vol. 21, No. 3, 1341-1360", "doi": "10.3150/13-BEJ588", "report-no": "IMS-BEJ-BEJ588", "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We construct a family of self-similar Markov martingales with given marginal\ndistributions. This construction uses the self-similarity and Markov property\nof a reference process to produce a family of Markov processes that possess the\nsame marginal distributions as the original process. The resulting processes\nare also self-similar with the same exponent as the original process. They can\nbe chosen to be martingales under certain conditions. In this paper, we present\ntwo approaches to this construction, the transition-randomising approach and\nthe time-change approach. We then compute the infinitesimal generators and\nobtain some path properties of the resulting processes. We also give some\nexamples, including continuous Gaussian martingales as a generalization of\nBrownian motion, martingales of the squared Bessel process, stable L\\'{e}vy\nprocesses as well as an example of an artificial process having the marginals\nof $t^{\\kappa}V$ for some symmetric random variable $V$. At the end, we see how\nwe can mimic certain Brownian martingales which are non-Markovian.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2015 07:00:46 GMT"}], "update_date": "2015-06-05", "authors_parsed": [["Fan", "Jie Yen", ""], ["Hamza", "Kais", ""], ["Klebaner", "Fima", ""]]}, {"id": "1506.01495", "submitter": "Harry Crane", "authors": "Harry Crane", "title": "Lipschitz partition processes", "comments": "Published at http://dx.doi.org/10.3150/14-BEJ607 in the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2015, Vol. 21, No. 3, 1386-1411", "doi": "10.3150/14-BEJ607", "report-no": "IMS-BEJ-BEJ607", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a family of Markov processes on set partitions with a bounded\nnumber of blocks, called Lipschitz partition processes. We construct these\nprocesses explicitly by a Poisson point process on the space of Lipschitz\ncontinuous maps on partitions. By this construction, the Markovian consistency\nproperty is readily satisfied; that is, the finite restrictions of any\nLipschitz partition process comprise a compatible collection of finite state\nspace Markov chains. We further characterize the class of exchangeable\nLipschitz partition processes by a novel set-valued matrix operation.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2015 07:48:41 GMT"}], "update_date": "2015-06-05", "authors_parsed": [["Crane", "Harry", ""]]}, {"id": "1506.01557", "submitter": "Rania Zgheib", "authors": "Cristina Butucea, Rania Zgheib", "title": "Sharp minimax tests for large Toeplitz covariance matrices with repeated\n  observations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We observe a sample of $n$ independent $p$-dimensional Gaussian vectors with\nToeplitz covariance matrix $ \\Sigma = [\\sigma_{|i-j|}]_{1 \\leq i,j \\leq p}$ and\n$\\sigma_0=1$. We consider the problem of testing the hypothesis that $\\Sigma$\nis the identity matrix asymptotically when $n \\to \\infty$ and $p \\to \\infty$.\nWe suppose that the covariances $\\sigma_k$ decrease either polynomially\n($\\sum_{k \\geq 1} k^{2\\alpha} \\sigma^2_{k} \\leq L$ for $ \\alpha >1/4$ and\n$L>0$) or exponentially ($\\sum_{k \\geq 1} e^{2Ak} \\sigma^2_{k} \\leq L$ for $\nA,L>0$).\n  We consider a test procedure based on a weighted U-statistic of order 2, with\noptimal weights chosen as solution of an extremal problem. We give the\nasymptotic normality of the test statistic under the null hypothesis for fixed\n$n$ and $p \\to + \\infty$ and the asymptotic behavior of the type I error\nprobability of our test procedure. We also show that the maximal type II error\nprobability, either tend to $0$, or is bounded from above. In the latter case,\nthe upper bound is given using the asymptotic normality of our test statistic\nunder alternatives close to the separation boundary. Our assumptions imply mild\nconditions: $n=o(p^{2\\alpha - 1/2})$ (in the polynomial case), $n=o(e^p)$ (in\nthe exponential case).\n  We prove both rate optimality and sharp optimality of our results, for\n$\\alpha >1$ in the polynomial case and for any $A>0$ in the exponential case.\n  A simulation study illustrates the good behavior of our procedure, in\nparticular for small $n$, large $p$.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2015 12:04:59 GMT"}], "update_date": "2015-06-05", "authors_parsed": [["Butucea", "Cristina", ""], ["Zgheib", "Rania", ""]]}, {"id": "1506.01567", "submitter": "Felix Abramovich", "authors": "Felix Abramovich and Marianna Pensky", "title": "Classification with many classes: challenges and pluses", "comments": "25 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The objective of the paper is to study accuracy of multi-class classification\nin high-dimensional setting, where the number of classes is also large (\"large\n$L$, large $p$, small $n$\" model). While this problem arises in many practical\napplications and many techniques have been recently developed for its solution,\nto the best of our knowledge nobody provided a rigorous theoretical analysis of\nthis important setup. The purpose of the present paper is to fill in this gap.\n  We consider one of the most common settings, classification of\nhigh-dimensional normal vectors where, unlike standard assumptions, the number\nof classes could be large. We derive non-asymptotic conditions on effects of\nsignificant features, and the low and the upper bounds for distances between\nclasses required for successful feature selection and classification with a\ngiven accuracy. Furthermore, we study an asymptotic setup where the number of\nclasses is diverging with the dimension of feature space and while the number\nof samples per class is possibly limited. We point out on an interesting and,\nat first glance, somewhat counter-intuitive phenomenon that a large number of\nclasses may be a \"blessing\" rather than a \"curse\" since, in certain settings,\nthe precision of classification can improve as the number of classes grows.\nThis is due to more accurate feature selection since even weaker significant\nfeatures, which are not sufficiently strong to be manifested in a coarse\nclassification, being shared across the classes, have a stronger impact as the\nnumber of classes increases. We supplement our theoretical investigation by a\nsimulation study and a real data example where we again observe the above\nphenomenon.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2015 12:57:19 GMT"}, {"version": "v2", "created": "Wed, 29 Mar 2017 07:32:26 GMT"}, {"version": "v3", "created": "Sun, 12 Nov 2017 10:48:37 GMT"}, {"version": "v4", "created": "Wed, 17 Jul 2019 12:25:41 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["Abramovich", "Felix", ""], ["Pensky", "Marianna", ""]]}, {"id": "1506.01606", "submitter": "Christophe Ley", "authors": "Abdelkamel Alj, Christophe Ley and Guy M\\'elard", "title": "Asymptotic properties of QML estimators for VARMA models with\n  time-dependent coefficients: Part I", "comments": "40 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is about vector autoregressive-moving average (VARMA) models with\ntime-dependent coefficients to represent non-stationary time series. Contrarily\nto other papers in the univariate case, the coefficients depend on time but not\non the length of the series $n$. Under appropriate assumptions, it is shown\nthat a Gaussian quasi-maximum likelihood estimator is almost surely consistent\nand asymptotically normal. The theoretical results are illustrated by means of\ntwo examples of bivariate processes. It is shown that the assumptions\nunderlying the theoretical results apply. In the second example the innovations\nare also marginally heteroscedastic with a correlation ranging from -0.8 to\n0.8. In the two examples, the asymptotic information matrix is obtained in the\nGaussian case. Finally, the finite-sample behaviour is checked via a Monte\nCarlo simulation study for $n$ going from 25 to 400. The results confirm the\nvalidity of the asymptotic properties even for short series and reveal that the\nasymptotic information matrix deduced from the theory is correct.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2015 14:29:13 GMT"}], "update_date": "2015-06-05", "authors_parsed": [["Alj", "Abdelkamel", ""], ["Ley", "Christophe", ""], ["M\u00e9lard", "Guy", ""]]}, {"id": "1506.01648", "submitter": "Gabriela Ciuperca", "authors": "Gabriela Ciuperca", "title": "Model selection in high-dimensional quantile regression with seamless\n  $L_0$ penalty", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we are interested in parameters estimation of linear model when\nnumber of parameters increases with sample size. Without any assumption about\nmoments of the model error, we propose and study the seamless $L_0$ quantile\nestimator. For this estimator we first give the convergence rate. Afterwards,\nwe prove that it correctly distinguishes between zero and nonzero parameters\nand that the estimators of the nonzero parameters are asymptotically normal. A\nconsistent BIC criterion to select the tuning parameters is given.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2015 16:44:09 GMT"}], "update_date": "2015-06-05", "authors_parsed": [["Ciuperca", "Gabriela", ""]]}, {"id": "1506.01744", "submitter": "Kevin Chen", "authors": "Chicheng Zhang, Jimin Song, Kevin C Chen, Kamalika Chaudhuri", "title": "Spectral Learning of Large Structured HMMs for Comparative Epigenomics", "comments": "27 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST q-bio.GN stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a latent variable model and an efficient spectral algorithm\nmotivated by the recent emergence of very large data sets of chromatin marks\nfrom multiple human cell types. A natural model for chromatin data in one cell\ntype is a Hidden Markov Model (HMM); we model the relationship between multiple\ncell types by connecting their hidden states by a fixed tree of known\nstructure. The main challenge with learning parameters of such models is that\niterative methods such as EM are very slow, while naive spectral methods result\nin time and space complexity exponential in the number of cell types. We\nexploit properties of the tree structure of the hidden states to provide\nspectral algorithms that are more computationally efficient for current\nbiological datasets. We provide sample complexity bounds for our algorithm and\nevaluate it experimentally on biological data from nine human cell types.\nFinally, we show that beyond our specific model, some of our algorithmic ideas\ncan be applied to other graphical models.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2015 22:57:28 GMT"}], "update_date": "2015-06-09", "authors_parsed": [["Zhang", "Chicheng", ""], ["Song", "Jimin", ""], ["Chen", "Kevin C", ""], ["Chaudhuri", "Kamalika", ""]]}, {"id": "1506.01782", "submitter": "Xiangyu Wang", "authors": "Xiangyu Wang and Chenlei Leng", "title": "High-dimensional Ordinary Least-squares Projection for Screening\n  Variables", "comments": "To appear in JRSS-B", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variable selection is a challenging issue in statistical applications when\nthe number of predictors $p$ far exceeds the number of observations $n$. In\nthis ultra-high dimensional setting, the sure independence screening (SIS)\nprocedure was introduced to significantly reduce the dimensionality by\npreserving the true model with overwhelming probability, before a refined\nsecond stage analysis. However, the aforementioned sure screening property\nstrongly relies on the assumption that the important variables in the model\nhave large marginal correlations with the response, which rarely holds in\nreality. To overcome this, we propose a novel and simple screening technique\ncalled the high-dimensional ordinary least-squares projection (HOLP). We show\nthat HOLP possesses the sure screening property and gives consistent variable\nselection without the strong correlation assumption, and has a low\ncomputational complexity. A ridge type HOLP procedure is also discussed.\nSimulation study shows that HOLP performs competitively compared to many other\nmarginal correlation based methods. An application to a mammalian eye disease\ndata illustrates the attractiveness of HOLP.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2015 05:39:38 GMT"}], "update_date": "2015-06-08", "authors_parsed": [["Wang", "Xiangyu", ""], ["Leng", "Chenlei", ""]]}, {"id": "1506.01831", "submitter": "Tepmony Sim", "authors": "Randal Douc (CITI), Fran\\c{c}ois Roueff (LTCI), Tepmony Sim (LTCI)", "title": "Handy sufficient conditions for the convergence of the maximum\n  likelihood estimator in observation-driven models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper generalizes asymptotic properties obtained in the\nobservation-driven times series models considered by \\cite{dou:kou:mou:2013} in\nthe sense that the conditional law of each observation is also permitted to\ndepend on the parameter. The existence of ergodic solutions and the consistency\nof the Maximum Likelihood Estimator (MLE) are derived under easy-to-check\nconditions. The obtained conditions appear to apply for a wide class of models.\nWe illustrate our results with specific observation-driven times series,\nincluding the recently introduced NBIN-GARCH and NM-GARCH models, demonstrating\nthe consistency of the MLE for these two models.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2015 09:22:00 GMT"}], "update_date": "2015-06-08", "authors_parsed": [["Douc", "Randal", "", "CITI"], ["Roueff", "Fran\u00e7ois", "", "LTCI"], ["Sim", "Tepmony", "", "LTCI"]]}, {"id": "1506.01833", "submitter": "Reinhard Furrer", "authors": "R. Furrer, F. Bachoc and J. Du", "title": "Asymptotic properties of multivariate tapering for estimation and\n  prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parameter estimation for and prediction of spatially or spatio--temporally\ncorrelated random processes are used in many areas and often require the\nsolution of a large linear system based on the covariance matrix of the\nobservations. In recent years, the dataset sizes to which these methods are\napplied have steadily increased such that straightforward statistical tools are\ncomputationally too expensive to be used. In the univariate context, tapering,\ni.e., creating sparse approximate linear systems, has been shown to be an\nefficient tool in both the estimation and prediction settings. The asymptotic\nproperties are derived under an infill asymptotic setting. In this paper we use\na domain increasing framework for estimation and prediction using multivariate\ntapering. Under this asymptotic regime we prove that tapering (one-tapered\nform) preserves the consistency of the untapered maximum likelihood estimator\nand show that tapering has asymptotically the same mean squared prediction\nerror as using the corresponding untapered predictor. The theoretical results\nare illustrated with simulations.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2015 09:25:51 GMT"}], "update_date": "2015-06-08", "authors_parsed": [["Furrer", "R.", ""], ["Bachoc", "F.", ""], ["Du", "J.", ""]]}, {"id": "1506.01842", "submitter": "Adelaide Olivier", "authors": "Sim\\'eon Val\\`ere Bitseki Penda (CMAP), Ad\\'ela\\\"ide Olivier (MAMBA,\n  CEREMADE)", "title": "Autoregressive Functions Estimation in Nonlinear Bifurcating\n  Autoregressive Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bifurcating autoregressive processes, which can be seen as an adaptation of\nau-toregressive processes for a binary tree structure, have been extensively\nstudied during the last decade in a parametric context. In this work we do not\nspecify any a priori form for the two autoregressive functions and we use\nnonparametric techniques. We investigate both nonasymp-totic and asymptotic\nbehavior of the Nadaraya-Watson type estimators of the autoregressive\nfunctions. We build our estimators observing the process on a finite subtree\ndenoted by Tn, up to the depth n. Estimators achieve the classical rate |Tn|\n--$\\beta$/(2$\\beta$+1) in quadratic loss over H{\\\"o}lder classes of smoothness.\nWe prove almost sure convergence, asymptotic normality giving the bias\nexpression when choosing the optimal bandwidth and a moderate deviations\nprinciple. Our proofs rely on specific techniques used to study bifurcating\nMarkov chains. Finally, we address the question of asymmetry and develop an\nasymptotic test for the equality of the two autoregressive functions.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2015 09:48:12 GMT"}, {"version": "v2", "created": "Thu, 11 Feb 2016 19:35:56 GMT"}], "update_date": "2016-02-12", "authors_parsed": [["Penda", "Sim\u00e9on Val\u00e8re Bitseki", "", "CMAP"], ["Olivier", "Ad\u00e9la\u00efde", "", "MAMBA,\n  CEREMADE"]]}, {"id": "1506.01892", "submitter": "Nadia Morsli", "authors": "Nadia Morsli", "title": "Weak and Strong Consistency of non-parametric estimate of potential\n  function for stationary and isotropic pairwise interaction point process", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A method is proposed for estimating the potential function of a\nnon-parametric estimator for stationary and isotropic pairwise interaction\npoint process. The relation between a pair potential and the corresponding\nPapangelou conditional intensity is considered. Consistency and strong\nconsistency of non-parametric estimate are proved in case of finite-range\ninteraction potential.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2015 13:00:41 GMT"}], "update_date": "2015-06-08", "authors_parsed": [["Morsli", "Nadia", ""]]}, {"id": "1506.01894", "submitter": "Tom Rohmer", "authors": "Tom Rohmer", "title": "Some results on change-point detection in cross-sectional dependence of\n  multivariate data with changes in marginal distributions", "comments": "16 pages, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tests for break points detection in the law of random vectors have been\nproposed in several papers. Nevertheless, they have often little powers for\nalternatives involving a change in the dependence between components of\nvectors. Specific tests for detection of a change in the copula of random\nvectors have been proposed in recent papers, but they do not allow to conclude\nof a change in the dependence structure without condition that the margins are\nconstant. The goal of this article is to propose a test for detection of a\nbreak in the copula when a change in marginal distribution occurs at a known\ninstant. The performances of this test are illustrated by Monte Carlo\nsimulations.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2015 13:11:00 GMT"}, {"version": "v2", "created": "Fri, 25 Mar 2016 10:23:01 GMT"}], "update_date": "2016-03-28", "authors_parsed": [["Rohmer", "Tom", ""]]}, {"id": "1506.02084", "submitter": "Guido Imbens", "authors": "Susan Athey, Dean Eckles, Guido Imbens", "title": "Exact P-values for Network Interference", "comments": "40 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the calculation of exact p-values for a large class of non-sharp\nnull hypotheses about treatment effects in a setting with data from experiments\ninvolving members of a single connected network. The class includes null\nhypotheses that limit the effect of one unit's treatment status on another\naccording to the distance between units; for example, the hypothesis might\nspecify that the treatment status of immediate neighbors has no effect, or that\nunits more than two edges away have no effect. We also consider hypotheses\nconcerning the validity of sparsification of a network (for example based on\nthe strength of ties) and hypotheses restricting heterogeneity in peer effects\n(so that, for example, only the number or fraction treated among neighboring\nunits matters). Our general approach is to define an artificial experiment,\nsuch that the null hypothesis that was not sharp for the original experiment is\nsharp for the artificial experiment, and such that the randomization analysis\nfor the artificial experiment is validated by the design of the original\nexperiment.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2015 23:15:12 GMT"}], "update_date": "2015-06-09", "authors_parsed": [["Athey", "Susan", ""], ["Eckles", "Dean", ""], ["Imbens", "Guido", ""]]}, {"id": "1506.02155", "submitter": "Zoltan Szabo", "authors": "Bharath K. Sriperumbudur and Zoltan Szabo", "title": "Optimal Rates for Random Fourier Features", "comments": "To appear at NIPS-2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG math.FA stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kernel methods represent one of the most powerful tools in machine learning\nto tackle problems expressed in terms of function values and derivatives due to\ntheir capability to represent and model complex relations. While these methods\nshow good versatility, they are computationally intensive and have poor\nscalability to large data as they require operations on Gram matrices. In order\nto mitigate this serious computational limitation, recently randomized\nconstructions have been proposed in the literature, which allow the application\nof fast linear algorithms. Random Fourier features (RFF) are among the most\npopular and widely applied constructions: they provide an easily computable,\nlow-dimensional feature representation for shift-invariant kernels. Despite the\npopularity of RFFs, very little is understood theoretically about their\napproximation quality. In this paper, we provide a detailed finite-sample\ntheoretical analysis about the approximation quality of RFFs by (i)\nestablishing optimal (in terms of the RFF dimension, and growing set size)\nperformance guarantees in uniform norm, and (ii) presenting guarantees in $L^r$\n($1\\le r<\\infty$) norms. We also propose an RFF approximation to derivatives of\na kernel with a theoretical study on its approximation quality.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jun 2015 14:37:01 GMT"}, {"version": "v2", "created": "Wed, 4 Nov 2015 22:58:57 GMT"}], "update_date": "2015-11-06", "authors_parsed": [["Sriperumbudur", "Bharath K.", ""], ["Szabo", "Zoltan", ""]]}, {"id": "1506.02174", "submitter": "Chao Gao", "authors": "Chao Gao, Aad W. van der Vaart, Harrison H. Zhou", "title": "A General Framework for Bayes Structured Linear Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High dimensional statistics deals with the challenge of extracting structured\ninformation from complex model settings. Compared with the growing number of\nfrequentist methodologies, there are rather few theoretically optimal Bayes\nmethods that can deal with very general high dimensional models. In contrast,\nBayes methods have been extensively studied in various nonparametric settings\nand rate optimal posterior contraction results have been established. This\npaper provides a unified approach to both Bayes high dimensional statistics and\nBayes nonparametrics in a general framework of structured linear models. With\nthe proposed two-step model selection prior, we prove a general theorem of\nposterior contraction under an abstract setting. The main theorem can be used\nto derive new results on optimal posterior contraction under many complex model\nsettings including stochastic block model, graphon estimation and dictionary\nlearning. It can also be used to re-derive optimal posterior contraction for\nproblems such as sparse linear regression and nonparametric aggregation, which\nimprove upon previous Bayes results for these problems. The key of the success\nlies in the proposed two-step prior distribution. The prior on the parameters\nis an elliptical Laplace distribution that is capable to model signals with\nlarge magnitude, and the prior on the models involves an important correction\nfactor that compensates the effect of the normalizing constant of the\nelliptical Laplace distribution.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jun 2015 17:31:33 GMT"}, {"version": "v2", "created": "Sun, 19 Aug 2018 22:07:49 GMT"}], "update_date": "2018-08-21", "authors_parsed": [["Gao", "Chao", ""], ["van der Vaart", "Aad W.", ""], ["Zhou", "Harrison H.", ""]]}, {"id": "1506.02181", "submitter": "Christos Thrampoulidis", "authors": "Chrtistos Thrampoulidis, Ehsan Abbasi, Babak Hassibi", "title": "The LASSO with Non-linear Measurements is Equivalent to One With Linear\n  Measurements", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT math.IT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider estimating an unknown, but structured, signal $x_0\\in R^n$ from $m$\nmeasurement $y_i=g_i(a_i^Tx_0)$, where the $a_i$'s are the rows of a known\nmeasurement matrix $A$, and, $g$ is a (potentially unknown) nonlinear and\nrandom link-function. Such measurement functions could arise in applications\nwhere the measurement device has nonlinearities and uncertainties. It could\nalso arise by design, e.g., $g_i(x)=\\text{sign}(x+z_i)$, corresponds to noisy\n1-bit quantized measurements. Motivated by the classical work of Brillinger,\nand more recent work of Plan and Vershynin, we estimate $x_0$ via solving the\nGeneralized-LASSO for some regularization parameter $\\lambda>0$ and some\n(typically non-smooth) convex structure-inducing regularizer function. While\nthis approach seems to naively ignore the nonlinear function $g$, both\nBrillinger (in the non-constrained case) and Plan and Vershynin have shown\nthat, when the entries of $A$ are iid standard normal, this is a good estimator\nof $x_0$ up to a constant of proportionality $\\mu$, which only depends on $g$.\nIn this work, we considerably strengthen these results by obtaining explicit\nexpressions for the squared error, for the \\emph{regularized} LASSO, that are\nasymptotically \\emph{precise} when $m$ and $n$ grow large. A main result is\nthat the estimation performance of the Generalized LASSO with non-linear\nmeasurements is \\emph{asymptotically the same} as one whose measurements are\nlinear $y_i=\\mu a_i^Tx_0 + \\sigma z_i$, with $\\mu = E\\gamma g(\\gamma)$ and\n$\\sigma^2 = E(g(\\gamma)-\\mu\\gamma)^2$, and, $\\gamma$ standard normal. To the\nbest of our knowledge, the derived expressions on the estimation performance\nare the first-known precise results in this context. One interesting\nconsequence of our result is that the optimal quantizer of the measurements\nthat minimizes the estimation error of the LASSO is the celebrated Lloyd-Max\nquantizer.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jun 2015 18:55:24 GMT"}], "update_date": "2015-06-09", "authors_parsed": [["Thrampoulidis", "Chrtistos", ""], ["Abbasi", "Ehsan", ""], ["Hassibi", "Babak", ""]]}, {"id": "1506.02194", "submitter": "Patrick Rebeschini", "authors": "Patrick Rebeschini and Amin Karbasi", "title": "Fast Mixing for Discrete Point Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the systematic mechanism for designing fast mixing Markov\nchain Monte Carlo algorithms to sample from discrete point processes under the\nDobrushin uniqueness condition for Gibbs measures. Discrete point processes are\ndefined as probability distributions $\\mu(S)\\propto \\exp(\\beta f(S))$ over all\nsubsets $S\\in 2^V$ of a finite set $V$ through a bounded set function\n$f:2^V\\rightarrow \\mathbb{R}$ and a parameter $\\beta>0$. A subclass of discrete\npoint processes characterized by submodular functions (which include\nlog-submodular distributions, submodular point processes, and determinantal\npoint processes) has recently gained a lot of interest in machine learning and\nshown to be effective for modeling diversity and coverage. We show that if the\nset function (not necessarily submodular) displays a natural notion of decay of\ncorrelation, then, for $\\beta$ small enough, it is possible to design fast\nmixing Markov chain Monte Carlo methods that yield error bounds on marginal\napproximations that do not depend on the size of the set $V$. The sufficient\nconditions that we derive involve a control on the (discrete) Hessian of set\nfunctions, a quantity that has not been previously considered in the\nliterature. We specialize our results for submodular functions, and we discuss\ncanonical examples where the Hessian can be easily controlled.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jun 2015 21:19:21 GMT"}], "update_date": "2015-06-09", "authors_parsed": [["Rebeschini", "Patrick", ""], ["Karbasi", "Amin", ""]]}, {"id": "1506.02196", "submitter": "Patrick L. Combettes", "authors": "Michel Barlaud, Wafa Belhajali, Patrick L. Combettes, and Lionel\n  Fillatre", "title": "Classification and regression using an outer approximation\n  projection-gradient method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with sparse feature selection and grouping for\nclassification and regression. The classification or regression problems under\nconsideration consists in minimizing a convex empirical risk function subject\nto an $\\ell^1$ constraint, a pairwise $\\ell^\\infty$ constraint, or a pairwise\n$\\ell^1$ constraint. Existing work, such as the Lasso formulation, has focused\nmainly on Lagrangian penalty approximations, which often require ad hoc or\ncomputationally expensive procedures to determine the penalization parameter.\nWe depart from this approach and address the constrained problem directly via a\nsplitting method. The structure of the method is that of the classical\ngradient-projection algorithm, which alternates a gradient step on the\nobjective and a projection step onto the lower level set modeling the\nconstraint. The novelty of our approach is that the projection step is\nimplemented via an outer approximation scheme in which the constraint set is\napproximated by a sequence of simple convex sets consisting of the intersection\nof two half-spaces. Convergence of the iterates generated by the algorithm is\nestablished for a general smooth convex minimization problem with inequality\nconstraints. Experiments on both synthetic and biological data show that our\nmethod outperforms penalty methods.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jun 2015 21:47:02 GMT"}, {"version": "v2", "created": "Sat, 16 Jan 2016 03:33:13 GMT"}, {"version": "v3", "created": "Wed, 21 Sep 2016 01:05:21 GMT"}, {"version": "v4", "created": "Thu, 23 Mar 2017 19:08:37 GMT"}], "update_date": "2017-03-27", "authors_parsed": [["Barlaud", "Michel", ""], ["Belhajali", "Wafa", ""], ["Combettes", "Patrick L.", ""], ["Fillatre", "Lionel", ""]]}, {"id": "1506.02222", "submitter": "Xiangyu Wang", "authors": "Xiangyu Wang, David Dunson and Chenlei Leng", "title": "No penalty no tears: Least squares in high-dimensional linear models", "comments": "Added results for non-sparse models; Added results for elliptical\n  distribution; Added simulations for adaptive lasso", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ordinary least squares (OLS) is the default method for fitting linear models,\nbut is not applicable for problems with dimensionality larger than the sample\nsize. For these problems, we advocate the use of a generalized version of OLS\nmotivated by ridge regression, and propose two novel three-step algorithms\ninvolving least squares fitting and hard thresholding. The algorithms are\nmethodologically simple to understand intuitively, computationally easy to\nimplement efficiently, and theoretically appealing for choosing models\nconsistently. Numerical exercises comparing our methods with penalization-based\napproaches in simulations and data analyses illustrate the great potential of\nthe proposed algorithms.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jun 2015 05:45:24 GMT"}, {"version": "v2", "created": "Wed, 10 Jun 2015 03:31:06 GMT"}, {"version": "v3", "created": "Fri, 9 Oct 2015 21:30:39 GMT"}, {"version": "v4", "created": "Mon, 23 Nov 2015 09:21:37 GMT"}, {"version": "v5", "created": "Thu, 16 Jun 2016 07:13:40 GMT"}], "update_date": "2016-06-17", "authors_parsed": [["Wang", "Xiangyu", ""], ["Dunson", "David", ""], ["Leng", "Chenlei", ""]]}, {"id": "1506.02326", "submitter": "Daniel Vogel", "authors": "Herold Dehling, Roland Fried, Olimjon Sh. Sharipov, Daniel Vogel, Max\n  Wornowizki", "title": "Estimation of the variance of partial sums of dependent processes", "comments": null, "journal-ref": "Statistics and Probability Letters, 83(1), pages 141-147, January\n  2013,", "doi": "10.1016/j.spl.2012.08.012", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study subsampling estimators for the limit variance \\[\n  \\sigma^2=Var(X_1)+2 \\sum_{k=2}^\\infty Cov(X_1,X_k) \\] of partial sums of a\nstationary stochastic process $(X_k)_{k\\geq 1}$. We establish $L_2$-consistency\nof a non-overlapping block resampling method. Our results apply to processes\nthat can be represented as functionals of strongly mixing processes. Motivated\nby recent applications to rank tests, we also study estimators for the series\n$Var(F(X_1))+2 \\sum_{k=2}^\\infty Cov(F(X_1),F(X_k))$, where $F$ is the\ndistribution function of $X_1$. Simulations illustrate the usefulness of the\nproposed estimators and of a mean squared error optimal rule for the choice of\nthe block length.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jun 2015 23:45:46 GMT"}], "update_date": "2015-06-09", "authors_parsed": [["Dehling", "Herold", ""], ["Fried", "Roland", ""], ["Sharipov", "Olimjon Sh.", ""], ["Vogel", "Daniel", ""], ["Wornowizki", "Max", ""]]}, {"id": "1506.02360", "submitter": "Beih El-Desouky", "authors": "Beih S. El-Desouky and Rabab Gomaa", "title": "New Multivariate Discrete Distributions UGAT Distributions and Their\n  Applications in Reliability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a new multivariate discrete distribution which\ncalled multivariate unification of generalized Apostol type distribution\n(UGAT). Several prop- erties are studied as, moments, probability generating\nfunction and other properties. Also, reliability study of distribution are\nintroduced. Maximum likelihood method is used to estimate parameters and\nnumerical method is used to obtain (MLEs).\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2015 06:24:46 GMT"}], "update_date": "2015-06-09", "authors_parsed": [["El-Desouky", "Beih S.", ""], ["Gomaa", "Rabab", ""]]}, {"id": "1506.02578", "submitter": "Daniel Vogel", "authors": "Alexander D\\\"urre, Daniel Vogel", "title": "Asymptotics of the two-stage spatial sign correlation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The spatial sign correlation (D\\\"urre, Vogel and Fried, 2015) is a highly\nrobust and easy-to-compute, bivariate correlation estimator based on the\nspatial sign covariance matrix. Since the estimator is inefficient when the\nmarginal scales strongly differ, a two-stage version was proposed. In the first\nstep, the observations are marginally standardized by means of a robust scale\nestimator, and in the second step, the spatial sign correlation of the thus\ntransformed data set is computed. D\\\"urre et al. (2015) give some evidence that\nthe asymptotic distribution of the two-stage estimator equals that of the\nspatial sign correlation at equal marginal scales by comparing their influence\nfunctions and presenting simulation results, but give no formal proof. In the\npresent paper, we close this gap and establish the asymptotic normality of the\ntwo-stage spatial sign correlation and compute its asymptotic variance for\nelliptical population distributions. We further derive a variance-stabilizing\ntransformation, similar to Fisher's z-transform, and numerically compare the\nsmall-sample coverage probabilities of several confidence intervals.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2015 16:36:12 GMT"}], "update_date": "2015-06-09", "authors_parsed": [["D\u00fcrre", "Alexander", ""], ["Vogel", "Daniel", ""]]}, {"id": "1506.02676", "submitter": "Matthew Thorpe", "authors": "Matthew Thorpe, Adam M. Johansen", "title": "Convergence and Rates for Fixed-Interval Multiple-Track Smoothing Using\n  $k$-Means Type Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the task of estimating multiple trajectories from unlabeled data.\nThis problem arises in many settings, one could think of the construction of\nmaps of transport networks from passive observation of travellers, or the\nreconstruction of the behaviour of uncooperative vehicles from external\nobservations, for example. There are two coupled problems. The first is a data\nassociation problem: how to map data points onto individual trajectories. The\nsecond is, given a solution to the data association problem, to estimate those\ntrajectories. We construct estimators as a solution to a regularized\nvariational problem (to which approximate solutions can be obtained via the\nsimple, efficient and widespread $k$-means method) and show that, as the number\nof data points, $n$, increases, these estimators exhibit stable behaviour. More\nprecisely, we show that they converge in an appropriate Sobolev space in\nprobability and with rate $n^{-1/2}$.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2015 20:08:27 GMT"}, {"version": "v2", "created": "Wed, 4 May 2016 01:03:53 GMT"}, {"version": "v3", "created": "Thu, 3 Nov 2016 22:34:16 GMT"}], "update_date": "2016-11-07", "authors_parsed": [["Thorpe", "Matthew", ""], ["Johansen", "Adam M.", ""]]}, {"id": "1506.02811", "submitter": "Louigi Addario-Berry", "authors": "Louigi Addario-Berry, Shankar Bhamidi, S\\'ebastien Bubeck, Luc\n  Devroye, Gabor Lugosi, Roberto Imbuzeiro Oliveira", "title": "Exceptional rotations of random graphs: a VC theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.CO math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we explore maximal deviations of large random structures from\ntheir typical behavior. We introduce a model for a high-dimensional random\ngraph process and ask analogous questions to those of Vapnik and Chervonenkis\nfor deviations of averages: how \"rich\" does the process have to be so that one\nsees atypical behavior. In particular, we study a natural process of\nErd\\H{o}s-R\\'enyi random graphs indexed by unit vectors in $\\mathbb{R}^d$. We\ninvestigate the deviations of the process with respect to three fundamental\nproperties: clique number, chromatic number, and connectivity. In all cases we\nestablish upper and lower bounds for the minimal dimension $d$ that guarantees\nthe existence of \"exceptional directions\" in which the random graph behaves\natypically with respect to the property. For each of the three properties, four\ntheorems are established, to describe upper and lower bounds for the threshold\ndimension in the subcritical and supercritical regimes.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2015 07:50:16 GMT"}], "update_date": "2015-06-10", "authors_parsed": [["Addario-Berry", "Louigi", ""], ["Bhamidi", "Shankar", ""], ["Bubeck", "S\u00e9bastien", ""], ["Devroye", "Luc", ""], ["Lugosi", "Gabor", ""], ["Oliveira", "Roberto Imbuzeiro", ""]]}, {"id": "1506.02886", "submitter": "Angelina Roche", "authors": "Angelina Roche (MAP5, CEREMADE)", "title": "Local Optimization of Black-Box Function with High or\n  Infinite-Dimensional Inputs", "comments": null, "journal-ref": null, "doi": null, "report-no": "MAP5 2015-11", "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An adaptation of Response Surface Methodology (RSM) when the covariate is of\nhigh or infinite dimensional is proposed, providing a tool for black-box\noptimization in this context. We combine dimension reduction techniques with\nclassical multivariate Design of Experiments (DoE). We propose a method to\ngenerate experimental designs and extend usual properties (orthogonality,\nrotatability,...) of multivariate designs to general high or infinite\ndimensional contexts. Different dimension reduction basis are considered\n(including data-driven basis). The methodology is illustrated on simulated\nfunctional data and we discuss the choice of the different parameters, in\nparticular the dimension of the approximation space. The method is finally\napplied to a problem of nuclear safety.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2015 12:40:53 GMT"}, {"version": "v2", "created": "Fri, 12 Jun 2015 20:47:55 GMT"}, {"version": "v3", "created": "Wed, 18 Nov 2015 12:15:24 GMT"}], "update_date": "2015-11-19", "authors_parsed": [["Roche", "Angelina", "", "MAP5, CEREMADE"]]}, {"id": "1506.02887", "submitter": "Frederic Lavancier", "authors": "David Dereudre, Fr\\'ed\\'eric Lavancier (LMJL, SERPICO)", "title": "Consistency of likelihood estimation for Gibbs point processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Strong consistency of the maximum likelihood estimator (MLE) for parametric\nGibbs point process models is established. The setting is very general. It\nincludes pairwise pair potentials, finite and infinite multibody interactions\nand geometrical interactions, where the range can be finite or infinite. The\nGibbs interaction may depend linearly or non-linearly on the parameters, a\nparticular case being hardcore parameters and interaction range parameters. As\nimportant examples, we deduce the consistency of the MLE for all parameters of\nthe Strauss model, the hardcore Strauss model, the Lennard-Jones model and the\narea-interaction model.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2015 12:46:11 GMT"}, {"version": "v2", "created": "Tue, 26 Jan 2016 13:00:12 GMT"}], "update_date": "2016-01-27", "authors_parsed": [["Dereudre", "David", "", "LMJL, SERPICO"], ["Lavancier", "Fr\u00e9d\u00e9ric", "", "LMJL, SERPICO"]]}, {"id": "1506.02935", "submitter": "Gogi Pantsulaia", "authors": "M.Kintsurashvili, T.Kiria and G.Pantsulaia", "title": "On Moore-Yamasaki-Kharazishvili type measures and the infinite powers of\n  Borel diffused probability measures on ${\\bf R}", "comments": "12pages. arXiv admin note: text overlap with arXiv:1502.07463", "journal-ref": "Journal of Mathematical Sciences: Advances and Applications,\n  Volume 38, 2016, Pages 83-103", "doi": "10.18642/jmsaa_7100121637", "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  The paper contains a brief description of Yamasaki's remarkable investigation\n(1980) of the relationship between Moore-Yamasaki-Kharazishvili type measures\nand infinite powers of Borel diffused probability measures on ${\\bf R}$. More\nprecisely, we give Yamasaki's proof that no infinite power of the Borel\nprobability measure with a strictly positive density function on $R$ has an\nequivalent Moore-Yamasaki-Kharazishvili type measure. A certain modification of\nYamasaki's example is used for the construction of such a\nMoore-Yamasaki-Kharazishvili type measure that is equivalent to the product of\na certain infinite family of Borel probability measures with a strictly\npositive density function on $R$. By virtue of the properties of\nequidistributed sequences on the real axis, it is demonstrated that an\narbitrary family of infinite powers of Borel diffused probability measures with\nstrictly positive density functions on $R$ is strongly separated and,\naccordingly, has an infinite-sample well-founded estimator of the unknown\ndistribution function. This extends the main result established in [ Zerakidze\nZ., Pantsulaia G., Saatashvili G. On the separation problem for a family of\nBorel and Baire $G$-powers of shift-measures on $\\mathbb{R}$ // Ukrainian Math.\nJ. -2013.-65 (4).- P. 470--485 ].\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2015 16:16:49 GMT"}], "update_date": "2016-08-17", "authors_parsed": [["Kintsurashvili", "M.", ""], ["Kiria", "T.", ""], ["Pantsulaia", "G.", ""]]}, {"id": "1506.02984", "submitter": "Lionel Truquet", "authors": "Lionel Truquet", "title": "Parameter stability and semiparametric inference in time-varying ARCH\n  models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we develop a complete methodology for detecting\ntime-varying/non time-varying parameters in ARCH processes. For this purpose,\nwe estimate and test various semiparametric versions of the time-varying ARCH\nmodel (tv-ARCH) which include two well known non stationary ARCH type models\nintroduced in the econometric literature. Using kernel estimation, we show that\nnon time-varying parameters can be estimated at the usual parametric rate of\nconvergence and for a Gaussian noise, we construct estimates that are\nasymptotically efficient in a semiparametric sense. Then we introduce two\nstatistical tests which can be used for detecting non time-varying parameters\nor for testing the second order dynamic. An information criterion for selecting\nthe number of lags is also provided. We illustrate our methodology with several\nreal data sets.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2015 16:28:25 GMT"}, {"version": "v2", "created": "Thu, 3 Nov 2016 11:00:10 GMT"}], "update_date": "2016-11-04", "authors_parsed": [["Truquet", "Lionel", ""]]}, {"id": "1506.03113", "submitter": "Kshitij Khare", "authors": "James P. Hobert, Yeun Ji Jung, Kshitij Khare, Qian Qin", "title": "Convergence Analysis of the Data Augmentation Algorithm for Bayesian\n  Linear Regression with Non-Gaussian Errors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian errors are sometimes inappropriate in a multivariate linear\nregression setting because, for example, the data contain outliers. In such\nsituations, it is often assumed that the error density is a scale mixture of\nmultivariate normal densities that takes the form $f(\\varepsilon) =\n\\int_0^\\infty |\\Sigma|^{-\\frac{1}{2}} u^{\\frac{d}{2}} \\, \\phi_d \\big(\n\\Sigma^{-\\frac{1}{2}} \\sqrt{u} \\, \\varepsilon \\big) \\, h(u) \\, du$, where $d$\nis the dimension of the response, $\\phi_d(\\cdot)$ is the standard $d$-variate\nnormal density, $\\Sigma$ is an unknown $d \\times d$ positive definite scale\nmatrix, and $h(\\cdot)$ is some fixed mixing density. Combining this alternative\nregression model with a default prior on the unknown parameters results in a\nhighly intractable posterior density. Fortunately, there is a simple data\naugmentation (DA) algorithm and a corresponding Haar PX-DA algorithm that can\nbe used to explore this posterior. This paper provides conditions (on $h$) for\ngeometric ergodicity of the Markov chains underlying these Markov chain Monte\nCarlo (MCMC) algorithms. These results are extremely important from a practical\nstandpoint because geometric ergodicity guarantees the existence of the central\nlimit theorems that form the basis of all the standard methods of calculating\nvalid asymptotic standard errors for MCMC-based estimators. The main result is\nthat, if $h$ converges to 0 at the origin at an appropriate rate, and\n$\\int_0^\\infty u^{\\frac{d}{2}} \\, h(u) \\, du < \\infty$, then the DA and Haar\nPX-DA Markov chains are both geometrically ergodic. This result is quite\nfar-reaching. For example, it implies the geometric ergodicity of the DA and\nHaar PX-DA Markov chains whenever $h$ is generalized inverse Gaussian,\nlog-normal, inverted gamma (with shape parameter larger than $d/2$), or\nFr\\'{e}chet (with shape parameter larger than $d/2$).\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2015 21:50:14 GMT"}, {"version": "v2", "created": "Wed, 27 Jan 2016 11:44:23 GMT"}], "update_date": "2016-01-28", "authors_parsed": [["Hobert", "James P.", ""], ["Jung", "Yeun Ji", ""], ["Khare", "Kshitij", ""], ["Qin", "Qian", ""]]}, {"id": "1506.03131", "submitter": "Jan  Vrbik", "authors": "Yuhao Liu and Jan Vrbik", "title": "Formula to evaluate a limit related to AR(k) model of Statistics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computing moments of various parameter estimators related to an\nautoregressive model of Statistics, one needs to evaluate several expressions\nof the type mentioned in the title of this article. We proceed to derive the\ncorresponding formulas.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2015 23:18:40 GMT"}], "update_date": "2015-06-11", "authors_parsed": [["Liu", "Yuhao", ""], ["Vrbik", "Jan", ""]]}, {"id": "1506.03172", "submitter": "Manoj Gopalkrishnan", "authors": "Manoj Gopalkrishnan", "title": "A Scheme for Molecular Computation of Maximum Likelihood Estimators for\n  Log-Linear Models", "comments": "13 pages, no figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE math.ST q-bio.MN stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel molecular computing scheme for statistical inference. We\nfocus on the much-studied statistical inference problem of computing maximum\nlikelihood estimators for log-linear models. Our scheme takes log-linear models\nto reaction systems, and the observed data to initial conditions, so that the\ncorresponding equilibrium of each reaction system encodes the corresponding\nmaximum likelihood estimator. The main idea is to exploit the coincidence\nbetween thermodynamic entropy and statistical entropy. We map a Maximum Entropy\ncharacterization of the maximum likelihood estimator onto a Maximum Entropy\ncharacterization of the equilibrium concentrations for the reaction system.\nThis allows for an efficient encoding of the problem, and reveals that reaction\nnetworks are superbly suited to statistical inference tasks. Such a scheme may\nalso provide a template to understanding how in vivo biochemical signaling\npathways integrate extensive information about their environment and history.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2015 05:34:40 GMT"}, {"version": "v2", "created": "Fri, 10 Jun 2016 11:45:50 GMT"}], "update_date": "2016-06-13", "authors_parsed": [["Gopalkrishnan", "Manoj", ""]]}, {"id": "1506.03198", "submitter": "Vincent Brault", "authors": "V. Brault, M. Delattre, E. Lebarbier, T. Mary-Huard, C. L\\'evy-Leduc", "title": "Estimating the number of change-points in a two-dimensional segmentation\n  model without penalization", "comments": "30 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In computational biology, numerous recent studies have been dedicated to the\nanalysis of the chromatin structure within the cell by two-dimensional\nsegmentation methods. Motivated by this application, we consider the problem of\nretrieving the diagonal blocks in a matrix of observations. The theoretical\nproperties of the least-squares estimators of both the boundaries and the\nnumber of blocks proposed by L\\'evy-Leduc et al. [2014] are investigated. More\nprecisely, the contribution of the paper is to establish the consistency of\nthese estimators. A surprising consequence of our results is that, contrary to\nthe onedimensional case, a penalty is not needed for retrieving the true number\nof diagonal blocks. Finally, the results are illustrated on synthetic data.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2015 07:39:48 GMT"}, {"version": "v2", "created": "Fri, 11 Mar 2016 13:25:54 GMT"}], "update_date": "2016-03-14", "authors_parsed": [["Brault", "V.", ""], ["Delattre", "M.", ""], ["Lebarbier", "E.", ""], ["Mary-Huard", "T.", ""], ["L\u00e9vy-Leduc", "C.", ""]]}, {"id": "1506.03258", "submitter": "Nuria Torrado", "authors": "Subhash C. Kochar and Nuria Torrado", "title": "On stochastic comparisons of largest order statistics in the scale model", "comments": null, "journal-ref": "Communications in Statistics - Theory and Methods Volume 44, 2015\n  - Issue 19", "doi": "10.1080/03610926.2014.985839", "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $X_{\\lambda _{1}},X_{\\lambda _{2}},\\ldots ,X_{\\lambda _{n}}$ be\nindependent nonnegative random variables with $X_{\\lambda _{i}}\\sim F(\\lambda\n_{i}t)$, $i=1,\\ldots ,n$, where $\\lambda _{i}>0$, $i=1,\\ldots ,n$ and $F$ is an\nabsolutely continuous distribution. It is shown that, under some conditions,\none largest order statistic $X_{n:n}^{\\lambda }$ is smaller than another one\n$X_{n:n}^{\\theta }$ according to likelihood ratio ordering. Furthermore, we\napply these results when $F$ is a generalized gamma distribution which includes\nWeibull, gamma and exponential random variables as special cases.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2015 11:28:43 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Kochar", "Subhash C.", ""], ["Torrado", "Nuria", ""]]}, {"id": "1506.03313", "submitter": "Pierre Barbillon", "authors": "Pierre Barbillon, C\\'elia Barth\\'el\\'emy (POPIX), Adeline Samson (LJK)", "title": "Parametric estimation of complex mixed models based on meta-model\n  approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complex biological processes are usually experimented along time among a\ncollection of individuals. Longitudinal data are then available and the\nstatistical challenge is to better understand the underlying biological\nmechanisms. The standard statistical approach is mixed-effects model, with\nregression functions that are now highly-developed to describe precisely the\nbiological processes (solutions of multi-dimensional ordinary differential\nequations or of partial differential equation). When there is no analytical\nsolution, a classical estimation approach relies on the coupling of a\nstochastic version of the EM algorithm (SAEM) with a MCMC algorithm. This\nprocedure needs many evaluations of the regression function which is clearly\nprohibitive when a time-consuming solver is used for computing it. In this work\na meta-model relying on a Gaussian process emulator is proposed to replace this\nregression function. The new source of uncertainty due to this approximation\ncan be incorporated in the model which leads to what is called a mixed\nmeta-model. A control on the distance between the maximum likelihood estimates\nin this mixed meta-model and the maximum likelihood estimates obtained with the\nexact mixed model is guaranteed. Eventually, numerical simulations are\nperformed to illustrate the efficiency of this approach.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2015 14:08:52 GMT"}], "update_date": "2015-06-11", "authors_parsed": [["Barbillon", "Pierre", "", "POPIX"], ["Barth\u00e9l\u00e9my", "C\u00e9lia", "", "POPIX"], ["Samson", "Adeline", "", "LJK"]]}, {"id": "1506.03318", "submitter": "Francois Leonard", "authors": "Fran\\c{c}ois L\\'eonard (IREQ)", "title": "Noisy data clusters are hollow", "comments": "Ce sujet fut pr{\\'e}sent{\\'e} {\\`a} la conf{\\'e}rence Joint\n  Statistical Meetings 2015 {\\`a} Seattle. Ce documentest publi{\\'e} dans le\n  Compendium de la conf{\\'e}rence. in Joint Statistical Meetings 2015, Aug\n  2015, Seattle, United States. JSM 2015 Proceedings, 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new vision in multidimensional statistics is proposed impacting\nseveralareas of application. In these applications, a set of noisy\nmeasurementscharacterizing the repeatable response of a process is known as a\nrealizationand can be seen as a single point in $\\mathbb{R}^N$. The projections\nof thispoint on the N axes correspond to the N measurements. The contemporary\nvisionof a diffuse cloud of realizations distributed in $\\mathbb{R}^N$ is\nreplaced bya cloud in the shape of a shell surrounding a topological manifold.\nThismanifold corresponds to the process's stabilized-response domain\nobservedwithout the measurement noise. The measurement noise, which accumulates\noverseveral dimensions, distances each realization from the manifold.\nTheprobability density function (PDF) of the realization-to-manifold\ndistancecreates the shell. Considering the central limit theorem as the number\nofdimensions increases, the PDF tends toward the normal distribution\nN($\\mu$,$\\sigma$^2) where $\\mu$ fixes the center shell location and\n$\\sigma$fixes the shell thickness. In vision, the likelihood of a realization\nis afunction of the realization-to-shell distance rather than\ntherealization-to-manifold distance. The demonstration begins with the work\nofClaude Shannon followed by the introduction of the shell manifold and ends\nwithpractical applications to monitoring equipment.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2015 14:15:58 GMT"}, {"version": "v2", "created": "Fri, 16 Oct 2015 06:25:39 GMT"}, {"version": "v3", "created": "Thu, 10 Mar 2016 19:29:48 GMT"}], "update_date": "2016-03-11", "authors_parsed": [["L\u00e9onard", "Fran\u00e7ois", "", "IREQ"]]}, {"id": "1506.03345", "submitter": "Herold Dehling", "authors": "Herold Dehling, Roland Fried, and Martin Wendler", "title": "A Robust Method for Shift Detection in Time Series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a robust test for change-points in time series which is based on\nthe two-sample Hodges-Lehmann estimator. We develop new limit theory for a\nclass of statistics based on the two-sample U-quantile processes, in the case\nof short range dependent observations. Using this theory we can derive the\nasymptotic distribution of our test statistic under the null hypothesis. We\nstudy the finite sample properties of our test via a simulation study and\ncompare the test with the classical CUSUM test and a test based on the\nWilcoxon-Mann-Whitney statistic.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2015 15:00:27 GMT"}, {"version": "v2", "created": "Thu, 16 May 2019 14:15:23 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Dehling", "Herold", ""], ["Fried", "Roland", ""], ["Wendler", "Martin", ""]]}, {"id": "1506.03382", "submitter": "Xiaodong Li", "authors": "T. Tony Cai, Xiaodong Li, and Zongming Ma", "title": "Optimal Rates of Convergence for Noisy Sparse Phase Retrieval via\n  Thresholded Wirtinger Flow", "comments": "28 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT math.IT math.NA stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the noisy sparse phase retrieval problem: recovering a\nsparse signal $x \\in \\mathbb{R}^p$ from noisy quadratic measurements $y_j =\n(a_j' x )^2 + \\epsilon_j$, $j=1, \\ldots, m$, with independent sub-exponential\nnoise $\\epsilon_j$. The goals are to understand the effect of the sparsity of\n$x$ on the estimation precision and to construct a computationally feasible\nestimator to achieve the optimal rates. Inspired by the Wirtinger Flow [12]\nproposed for noiseless and non-sparse phase retrieval, a novel thresholded\ngradient descent algorithm is proposed and it is shown to adaptively achieve\nthe minimax optimal rates of convergence over a wide range of sparsity levels\nwhen the $a_j$'s are independent standard Gaussian random vectors, provided\nthat the sample size is sufficiently large compared to the sparsity of $x$.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2015 16:32:33 GMT"}], "update_date": "2015-06-11", "authors_parsed": [["Cai", "T. Tony", ""], ["Li", "Xiaodong", ""], ["Ma", "Zongming", ""]]}, {"id": "1506.03426", "submitter": "Ronaldo Dias", "authors": "Julian A. A. Collazos (Ronaldo Dias Department of Statistics - State\n  University of Campinas (UNICAMP)) and Adriano Z. Zambom (Department of\n  Statistics - Penn State University)", "title": "Consistent Variable Selection for Functional Regression Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The dual problem of testing the predictive significance of a particular\ncovariate, and identification of the set of relevant covariates is common in\napplied research and methodological investigations. To study this problem in\nthe context of functional linear regression models with predictor variables\nobserved over a grid and a scalar response, we consider basis expansions of the\nfunctional covariates and apply the likelihood ratio test. Based on p-values\nfrom testing each predictor, we propose a new variable selection method, which\nis consistent in selecting the relevant predictors from set of available\npredictors that is allowed to grow with the sample size n. Numerical\nsimulations suggest that the proposed variable selection procedure outperforms\nexisting methods found in the literature. A real dataset from weather stations\nin Japan is analyzed.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2015 18:43:21 GMT"}], "update_date": "2015-06-11", "authors_parsed": [["Collazos", "Julian A. A.", "", "Ronaldo Dias Department of Statistics - State\n  University of Campinas"], ["Zambom", "Adriano Z.", "", "Department of\n  Statistics - Penn State University"]]}, {"id": "1506.03430", "submitter": "Adityanand Guntuboyina", "authors": "Sabyasachi Chatterjee and Adityanand Guntuboyina and Bodhisattva Sen", "title": "On matrix estimation under monotonicity constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of estimating an unknown $n_1 \\times n_2$ matrix\n$\\mathbf{\\theta^*}$ from noisy observations under the constraint that\n$\\mathbf{\\theta}^*$ is nondecreasing in both rows and columns. We consider the\nleast squares estimator (LSE) in this setting and study its risk properties. We\nshow that the worst case risk of the LSE is $n^{-1/2}$, up to multiplicative\nlogarithmic factors, where $n = n_1 n_2$ and that the LSE is minimax rate\noptimal (up to logarithmic factors). We further prove that for some special\n$\\mathbf{\\theta}^*$, the risk of the LSE could be much smaller than $n^{-1/2}$;\nin fact, it could even be parametric i.e., $n^{-1}$ up to logarithmic factors.\nSuch parametric rates occur when the number of \"rectangular\" blocks of\n$\\mathbf{\\theta}^*$ is bounded from above by a constant. We derive, as a\nconsequence, an interesting adaptation property of the LSE which we term\nvariable adaptation -- the LSE performs as well as the oracle estimator when\nestimating a matrix that is constant along each row/column. Our proofs borrow\nideas from empirical process theory and convex geometry and are of independent\ninterest.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2015 19:07:50 GMT"}, {"version": "v2", "created": "Sun, 28 Jun 2015 18:07:04 GMT"}, {"version": "v3", "created": "Sun, 1 Nov 2015 22:31:40 GMT"}], "update_date": "2015-11-03", "authors_parsed": [["Chatterjee", "Sabyasachi", ""], ["Guntuboyina", "Adityanand", ""], ["Sen", "Bodhisattva", ""]]}, {"id": "1506.03481", "submitter": "Wentao Li", "authors": "Wentao Li and Paul Fearnhead", "title": "On the Asymptotic Efficiency of Approximate Bayesian Computation\n  Estimators", "comments": "Main text shortened and proof revised. To appear in Biometrika", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many statistical applications involve models for which it is difficult to\nevaluate the likelihood, but from which it is relatively easy to sample.\nApproximate Bayesian computation is a likelihood-free method for implementing\nBayesian inference in such cases. We present results on the asymptotic variance\nof estimators obtained using approximate Bayesian computation in a large-data\nlimit. Our key assumption is that the data are summarized by a\nfixed-dimensional summary statistic that obeys a central limit theorem. We\nprove asymptotic normality of the mean of the approximate Bayesian computation\nposterior. This result also shows that, in terms of asymptotic variance, we\nshould use a summary statistic that is the same dimension as the parameter\nvector, p; and that any summary statistic of higher dimension can be reduced,\nthrough a linear transformation, to dimension p in a way that can only reduce\nthe asymptotic variance of the posterior mean. We look at how the Monte Carlo\nerror of an importance sampling algorithm that samples from the approximate\nBayesian computation posterior affects the accuracy of estimators. We give\nconditions on the importance sampling proposal distribution such that the\nvariance of the estimator will be the same order as that of the maximum\nlikelihood estimator based on the summary statistics used. This suggests an\niterative importance sampling algorithm, which we evaluate empirically on a\nstochastic volatility model.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2015 21:05:59 GMT"}, {"version": "v2", "created": "Fri, 4 Mar 2016 13:34:12 GMT"}, {"version": "v3", "created": "Wed, 27 Jul 2016 12:01:30 GMT"}, {"version": "v4", "created": "Tue, 28 Nov 2017 10:23:09 GMT"}], "update_date": "2017-11-29", "authors_parsed": [["Li", "Wentao", ""], ["Fearnhead", "Paul", ""]]}, {"id": "1506.03486", "submitter": "Akshay Balsubramani", "authors": "Akshay Balsubramani, Aaditya Ramdas", "title": "Sequential Nonparametric Testing with the Law of the Iterated Logarithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new algorithmic framework for sequential hypothesis testing with\ni.i.d. data, which includes A/B testing, nonparametric two-sample testing, and\nindependence testing as special cases. It is novel in several ways: (a) it\ntakes linear time and constant space to compute on the fly, (b) it has the same\npower guarantee as a non-sequential version of the test with the same\ncomputational constraints up to a small factor, and (c) it accesses only as\nmany samples as are required - its stopping time adapts to the unknown\ndifficulty of the problem. All our test statistics are constructed to be\nzero-mean martingales under the null hypothesis, and the rejection threshold is\ngoverned by a uniform non-asymptotic law of the iterated logarithm (LIL). For\nthe case of nonparametric two-sample mean testing, we also provide a finite\nsample power analysis, and the first non-asymptotic stopping time calculations\nfor this class of problems. We verify our predictions for type I and II errors\nand stopping times using simulations.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2015 21:28:38 GMT"}, {"version": "v2", "created": "Wed, 2 Mar 2016 02:11:19 GMT"}], "update_date": "2016-03-03", "authors_parsed": [["Balsubramani", "Akshay", ""], ["Ramdas", "Aaditya", ""]]}, {"id": "1506.03521", "submitter": "Samet Oymak", "authors": "Samet Oymak, Benjamin Recht, Mahdi Soltanolkotabi", "title": "Isometric sketching of any set via the Restricted Isometry Property", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DS math.IT math.PR math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we show that for the purposes of dimensionality reduction\ncertain class of structured random matrices behave similarly to random Gaussian\nmatrices. This class includes several matrices for which matrix-vector multiply\ncan be computed in log-linear time, providing efficient dimensionality\nreduction of general sets. In particular, we show that using such matrices any\nset from high dimensions can be embedded into lower dimensions with near\noptimal distortion. We obtain our results by connecting dimensionality\nreduction of any set to dimensionality reduction of sparse vectors via a\nchaining argument.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2015 00:49:51 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2015 20:09:41 GMT"}], "update_date": "2015-10-08", "authors_parsed": [["Oymak", "Samet", ""], ["Recht", "Benjamin", ""], ["Soltanolkotabi", "Mahdi", ""]]}, {"id": "1506.03537", "submitter": "Eric Janofsky", "authors": "Eric Janofsky", "title": "Exponential Series Approaches for Nonparametric Graphical Models", "comments": "Thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This thesis studies high-dimensional, continuous-valued pairwise Markov\nRandom Fields. We are particularly interested in approximating pairwise\ndensities whose logarithm belongs to a Sobolev space. For this problem we\npropose the method of exponential series [Crain, 1974; Barron and Sheu, 1991],\nwhich approximates the log density by a finite- dimensional exponential family\nwith the number of sufficient statistics increasing with the sample size. We\nconsider two approaches to estimating these models. The first is regularized\nmaximum likelihood. This involves optimizing the sum of the log-likelihood of\nthe data and a sparsity-inducing regularizer. We provide consistency and edge\nselection guarantees for this method. We then propose a variational\napproximation to the likelihood based on tree- reweighted, nonparametric\nmessage passing.\n  We then consider estimation using regularized score matching. This approach\nuses an alternative scoring rule to the log-likelihood, which obviates the need\nto compute the normalizing constant of the distribution. For general\ncontinuous-valued exponential families, we provide parameter and edge\nconsistency results. We then describe results for model selection in the\nnonparametric pairwise model using exponential series. The regularized score\nmatching problem is shown to be a convex program; we provide scalable\nalgorithms based on consensus Alternating Direction Method of Multipliers\n(ADMM, [Boyd et al., 2011]) and Coordinate-wise Descent. We compare our method\nto others in the literature as well as the aforementioned TRW estimator using\nsimulated data.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2015 03:35:54 GMT"}], "update_date": "2015-06-12", "authors_parsed": [["Janofsky", "Eric", ""]]}, {"id": "1506.03620", "submitter": "Martin Genzel", "authors": "Tim Conrad, Martin Genzel, Nada Cvetkovic, Niklas Wulkow, Alexander\n  Leichtle, Jan Vybiral, Gitta Kutyniok, Christof Sch\\\"utte", "title": "Sparse Proteomics Analysis - A compressed sensing-based approach for\n  feature selection and classification of high-dimensional proteomics mass\n  spectrometry data", "comments": null, "journal-ref": "BMC Bioinform. 18 (2017), 160", "doi": "10.1186/s12859-017-1565-4", "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: High-throughput proteomics techniques, such as mass spectrometry\n(MS)-based approaches, produce very high-dimensional data-sets. In a clinical\nsetting one is often interested in how mass spectra differ between patients of\ndifferent classes, for example spectra from healthy patients vs. spectra from\npatients having a particular disease. Machine learning algorithms are needed to\n(a) identify these discriminating features and (b) classify unknown spectra\nbased on this feature set. Since the acquired data is usually noisy, the\nalgorithms should be robust against noise and outliers, while the identified\nfeature set should be as small as possible.\n  Results: We present a new algorithm, Sparse Proteomics Analysis (SPA), based\non the theory of compressed sensing that allows us to identify a minimal\ndiscriminating set of features from mass spectrometry data-sets. We show (1)\nhow our method performs on artificial and real-world data-sets, (2) that its\nperformance is competitive with standard (and widely used) algorithms for\nanalyzing proteomics data, and (3) that it is robust against random and\nsystematic noise. We further demonstrate the applicability of our algorithm to\ntwo previously published clinical data-sets.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2015 10:55:49 GMT"}, {"version": "v2", "created": "Tue, 6 Sep 2016 09:10:55 GMT"}, {"version": "v3", "created": "Sat, 26 Nov 2016 09:10:24 GMT"}], "update_date": "2017-06-14", "authors_parsed": [["Conrad", "Tim", ""], ["Genzel", "Martin", ""], ["Cvetkovic", "Nada", ""], ["Wulkow", "Niklas", ""], ["Leichtle", "Alexander", ""], ["Vybiral", "Jan", ""], ["Kutyniok", "Gitta", ""], ["Sch\u00fctte", "Christof", ""]]}, {"id": "1506.03621", "submitter": "Anindya Goswami Mr.", "authors": "Anindya Goswami and Sanket Nandan", "title": "Convergence of Estimated Option Price in a Regime switching Market", "comments": "11 pages, 2 figures", "journal-ref": "Indian Journal of Pure and Applied Mathematics, 47(2016), no. 2,\n  169-182", "doi": "10.1007/s13226-016-0182-7", "report-no": null, "categories": "q-fin.PR math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In an observed generalized semi-Markov regime, estimation of transition rate\nof regime switching leads towards calculation of locally risk minimizing option\nprice. Despite the uniform convergence of estimated step function of transition\nrate, to meet the existence of classical solution of the modified price\nequation, the estimator is approximated in the class of smooth functions and\nfurthermore, the convergence is established. Later, the existence of the\nsolution of the modified price equation is verified and the point-wise\nconvergence of such approximation of option price is proved to answer the\ntractability of its application in Finance. To demonstrate the consistency in\nresult a numerical experiment has been reported.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2015 10:59:55 GMT"}, {"version": "v2", "created": "Tue, 29 Mar 2016 08:37:29 GMT"}], "update_date": "2016-09-27", "authors_parsed": [["Goswami", "Anindya", ""], ["Nandan", "Sanket", ""]]}, {"id": "1506.03740", "submitter": "Javier Segura", "authors": "Javier Segura", "title": "Sharp bounds for cumulative distribution functions", "comments": null, "journal-ref": null, "doi": "10.1016/j.jmaa.2015.12.024", "report-no": null, "categories": "math.CA math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ratios of integrals can be bounded in terms of ratios of integrands under\ncertain monotonicity conditions. This result, related with L'H\\^{o}pital's\nmonotone rule, can be used to obtain sharp bounds for cumulative distribution\nfunctions. We consider the case of noncentral cumulative gamma and beta\ndistributions. Three different types of sharp bounds for the noncentral gamma\ndistributions (also called Marcum functions) are obtained in terms of modified\nBessel functions and one additional type of function: a second modified Bessel\nfunction, two error functions or one incomplete gamma function. For the\nnoncentral beta case the bounds are expressed in terms of Kummer functions and\none additional Kummer function or an incomplete beta function. These bounds\nimprove previous results with respect to their range of application and/or its\nsharpness.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2015 16:49:02 GMT"}], "update_date": "2016-06-08", "authors_parsed": [["Segura", "Javier", ""]]}, {"id": "1506.03762", "submitter": "Thibaut Le Gouic", "authors": "Thibaut Le Gouic (I2M, CS-HSE)", "title": "Recovering metric from full ordinal information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a geodesic space (E, d), we show that full ordinal knowledge on the\nmetric d-i.e. knowledge of the function D d : (w, x, y, z) $\\rightarrow$ 1\nd(w,x)$\\le$d(y,z) , determines uniquely-up to a constant factor-the metric d.\nFor a subspace En of n points of E, converging in Hausdorff distance to E, we\nconstruct a metric dn on En, based only on the knowledge of D d on En and\nestablish a sharp upper bound of the Gromov-Hausdorff distance between (En, dn)\nand (E, d).\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2015 18:11:48 GMT"}, {"version": "v2", "created": "Fri, 12 Jun 2015 08:11:29 GMT"}, {"version": "v3", "created": "Fri, 12 Feb 2016 19:12:46 GMT"}, {"version": "v4", "created": "Sat, 29 Dec 2018 17:50:38 GMT"}], "update_date": "2019-01-01", "authors_parsed": [["Gouic", "Thibaut Le", "", "I2M, CS-HSE"]]}, {"id": "1506.03765", "submitter": "Julien Worms", "authors": "Julien Worms (LM-Versailles), Rym Worms", "title": "Moment estimators of the extreme value index for randomly censored data\n  in the Weibull domain of attraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the problem of estimating the extreme value index in\npresence of random censoring for distributions in the Weibull domain of\nattraction. The methodologies introduced in [Worms (2014)], in the heavy-tailed\ncase, are adapted here to the negative extreme value index framework, leading\nto the definition of weighted versions of the popular moments of relative\nexcesses with arbitrary exponent. This leads to the definition of two families\nof estimators (with an adaptation of the so called Moment estimator as a\nparticular case), for which the consistency is proved under a first order\ncondition. Illustration of their performance, issued from an extensive\nsimulation study, are provided.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2015 18:22:20 GMT"}], "update_date": "2015-06-12", "authors_parsed": [["Worms", "Julien", "", "LM-Versailles"], ["Worms", "Rym", ""]]}, {"id": "1506.03832", "submitter": "Xiaohui Chen", "authors": "Xiaohui Chen, Mengyu Xu, Wei Biao Wu", "title": "Regularized estimation of linear functionals of precision matrices for\n  high-dimensional time series", "comments": "44 pages, 4 figures", "journal-ref": null, "doi": "10.1109/TSP.2016.2605079", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies a Dantzig-selector type regularized estimator for linear\nfunctionals of high-dimensional linear processes. Explicit rates of convergence\nof the proposed estimator are obtained and they cover the broad regime from\ni.i.d. samples to long-range dependent time series and from sub-Gaussian\ninnovations to those with mild polynomial moments. It is shown that the\nconvergence rates depend on the degree of temporal dependence and the moment\nconditions of the underlying linear processes. The Dantzig-selector estimator\nis applied to the sparse Markowitz portfolio allocation and the optimal linear\nprediction for time series, in which the ratio consistency when compared with\nan oracle estimator is established. The effect of dependence and innovation\nmoment conditions is further illustrated in the simulation study. Finally, the\nregularized estimator is applied to classify the cognitive states on a real\nfMRI dataset and to portfolio optimization on a financial dataset.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2015 20:56:20 GMT"}, {"version": "v2", "created": "Sat, 14 Nov 2015 05:48:47 GMT"}, {"version": "v3", "created": "Sat, 5 Dec 2015 20:38:16 GMT"}, {"version": "v4", "created": "Mon, 23 May 2016 09:33:27 GMT"}, {"version": "v5", "created": "Fri, 19 Aug 2016 15:54:53 GMT"}], "update_date": "2016-11-23", "authors_parsed": [["Chen", "Xiaohui", ""], ["Xu", "Mengyu", ""], ["Wu", "Wei Biao", ""]]}, {"id": "1506.03909", "submitter": "Xiaohui Chen", "authors": "Xiaohui Chen, Yifeng He", "title": "Inference of high-dimensional linear models with time-varying\n  coefficients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a pointwise inference algorithm for high-dimensional linear models\nwith time-varying coefficients. The method is based on a novel combination of\nthe nonparametric kernel smoothing technique and a Lasso bias-corrected ridge\nregression estimator. Due to the non-stationarity feature of the model, dynamic\nbias-variance decomposition of the estimator is obtained. With a\nbias-correction procedure, the local null distribution of the estimator of the\ntime-varying coefficient vector is characterized for iid Gaussian and\nheavy-tailed errors. The limiting null distribution is also established for\nGaussian process errors, and we show that the asymptotic properties differ\nbetween short-range and long-range dependent errors. Here, p-values are\nadjusted by a Bonferroni-type correction procedure to control the familywise\nerror rate (FWER) in the asymptotic sense at each time point. The finite sample\nsize performance of the proposed inference algorithm is illustrated with\nsynthetic data and an application to learn brain connectivity by using the\nresting-state fMRI data for Parkinson's disease.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2015 06:26:23 GMT"}, {"version": "v2", "created": "Mon, 12 Dec 2016 03:04:54 GMT"}, {"version": "v3", "created": "Thu, 16 Mar 2017 04:37:11 GMT"}], "update_date": "2017-03-17", "authors_parsed": [["Chen", "Xiaohui", ""], ["He", "Yifeng", ""]]}, {"id": "1506.04091", "submitter": "James Ridgway", "authors": "Pierre Alquier and James Ridgway and Nicolas Chopin", "title": "On the properties of variational approximations of Gibbs posteriors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The PAC-Bayesian approach is a powerful set of techniques to derive non-\nasymptotic risk bounds for random estimators. The corresponding optimal\ndistribution of estimators, usually called the Gibbs posterior, is\nunfortunately intractable. One may sample from it using Markov chain Monte\nCarlo, but this is often too slow for big datasets. We consider instead\nvariational approximations of the Gibbs posterior, which are fast to compute.\nWe undertake a general study of the properties of such approximations. Our main\nfinding is that such a variational approximation has often the same rate of\nconvergence as the original PAC-Bayesian procedure it approximates. We\nspecialise our results to several learning tasks (classification, ranking,\nmatrix completion),discuss how to implement a variational approximation in each\ncase, and illustrate the good properties of said approximation on real\ndatasets.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2015 18:06:30 GMT"}, {"version": "v2", "created": "Mon, 15 Jun 2015 08:11:01 GMT"}], "update_date": "2015-06-16", "authors_parsed": [["Alquier", "Pierre", ""], ["Ridgway", "James", ""], ["Chopin", "Nicolas", ""]]}, {"id": "1506.04133", "submitter": "Thierry Klein", "authors": "Fabrice Gamboa (IMT, ESP), Thierry Klein (IMT, ESP), Agn\\`es Lagnoux\n  (IMT, ESP)", "title": "Sensitivity analysis based on Cram{\\'e}r von Mises distance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we first study a new sensitivity index that is based on higher\nmoments and generalizes the so-called Sobol one. Further, following an idea of\nBorgonovo ([3]), we define and study a new sensitivity index based on the\nCram{\\'e}r von Mises distance. This new index appears to be more general than\nthe Sobol one as it takes into account, not only the variance, but the whole\ndistribution of the random variable. Furthermore, we study the statistical\nproperties of a Monte Carlo estimate of this new index.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2015 19:56:01 GMT"}, {"version": "v2", "created": "Thu, 30 Nov 2017 13:20:01 GMT"}], "update_date": "2017-12-01", "authors_parsed": [["Gamboa", "Fabrice", "", "IMT, ESP"], ["Klein", "Thierry", "", "IMT, ESP"], ["Lagnoux", "Agn\u00e8s", "", "IMT, ESP"]]}, {"id": "1506.04136", "submitter": "Thibaut Le Gouic", "authors": "Thibaut Le Gouic (I2M)", "title": "Mass localization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For a given class $\\mathcal{F}$ of closed sets of a measured metric space\n$(E,d,\\mu)$, we want to find the smallest element $B$ of the class\n$\\mathcal{F}$ such that $\\mu(B)\\geq 1-\\alpha$, for a given $0<\\alpha<1$. This\nset $B$ \\textit{localizes the mass} of $\\mu$. Replacing the measure $\\mu$ by\nthe empirical measure $\\mu_n$ gives an empirical smallest set $B_n$. The\narticle introduces a formal definition of small sets (and their size) and study\nthe convergence of the sets $B_n$ to $B$ and of their size.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2015 19:58:00 GMT"}], "update_date": "2015-06-15", "authors_parsed": [["Gouic", "Thibaut Le", "", "I2M"]]}, {"id": "1506.04153", "submitter": "Thibaut Le Gouic", "authors": "Thibaut Le Gouic (I2M), Jean-Michel Loubes (IMT)", "title": "Existence and Consistency of Wasserstein Barycenters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, based on the Fr{\\'e}chet mean, we define a notion of\nbarycenter corresponding to a usual notion of statistical mean. We prove the\nexistence of Wasserstein barycenters of random distributions defined on a\ngeodesic space (E, d). We also prove the consistency of this barycenter in a\ngeneral setting, that includes taking barycenters of empirical versions of the\ndistributions or of a growing set of distributions.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2015 20:01:26 GMT"}, {"version": "v2", "created": "Fri, 12 Feb 2016 19:10:05 GMT"}], "update_date": "2016-02-15", "authors_parsed": [["Gouic", "Thibaut Le", "", "I2M"], ["Loubes", "Jean-Michel", "", "IMT"]]}, {"id": "1506.04324", "submitter": "Daniel Vogel", "authors": "Dietmar Ferger and Daniel Vogel", "title": "Weak convergence of the empirical process and the rescaled empirical\n  distribution function in the Skorokhod product space", "comments": null, "journal-ref": "Theory of Probability and Its Applications, 54(4), p. 609-625,\n  2010", "doi": "10.1137/S0040585X97984486", "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove the asymptotic independence of the empirical process $\\alpha_n =\n\\sqrt{n}( F_n - F)$ and the rescaled empirical distribution function $\\beta_n =\nn (F_n(\\tau+\\frac{\\cdot}{n})-F_n(\\tau))$, where $F$ is an arbitrary cdf,\ndifferentiable at some point $\\tau$, and $F_n$ the corresponding empricial cdf.\nThis seems rather counterintuitive, since, for every $n \\in N$, there is a\ndeterministic correspondence between $\\alpha_n$ and $\\beta_n$. Precisely, we\nshow that the pair $(\\alpha_n,\\beta_n)$ converges in law to a limit having\nindependent components, namely a time-transformed Brownian bridge and a\ntwo-sided Poisson process. Since these processes have jumps, in particular if\n$F$ itself has jumps, the Skorokhod product space $D(R) \\times D(R)$ is the\nadequate choice for modeling this convergence in. We develop a short\nconvergence theory for $D(R) \\times D(R)$ by establishing the classical\nprinciple, devised by Yu. V. Prokhorov, that finite-dimensional convergence and\ntightness imply weak convergence. Several tightness criteria are given.\nFinally, the convergence of the pair $(\\alpha_n,\\beta_n)$ implies convergence\nof each of its components, thus, in passing, we provide a thorough proof of\nthese known convergence results in a very general setting. In fact, the\ncondition on $F$ to be differentiable in at least one point is only required\nfor $\\beta_n$ to converge and can be further weakened.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jun 2015 21:42:03 GMT"}], "update_date": "2015-06-16", "authors_parsed": [["Ferger", "Dietmar", ""], ["Vogel", "Daniel", ""]]}, {"id": "1506.04344", "submitter": "Nathan Baker", "authors": "Xiu Yang, Huan Lei, Nathan A. Baker, Guang Lin", "title": "Enhancing Sparsity of Hermite Polynomial Expansions by Iterative\n  Rotations", "comments": null, "journal-ref": null, "doi": "10.1016/j.jcp.2015.11.038", "report-no": null, "categories": "math.ST math.NA math.OC stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compressive sensing has become a powerful addition to uncertainty\nquantification in recent years. This paper identifies new bases for random\nvariables through linear mappings such that the representation of the quantity\nof interest is more sparse with new basis functions associated with the new\nrandom variables. This sparsity increases both the efficiency and accuracy of\nthe compressive sensing-based uncertainty quantification method. Specifically,\nwe consider rotation-based linear mappings which are determined iteratively for\nHermite polynomial expansions. We demonstrate the effectiveness of the new\nmethod with applications in solving stochastic partial differential equations\nand high-dimensional ($\\mathcal{O}(100)$) problems.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jun 2015 01:58:51 GMT"}, {"version": "v2", "created": "Mon, 16 Nov 2015 18:08:46 GMT"}], "update_date": "2016-03-08", "authors_parsed": [["Yang", "Xiu", ""], ["Lei", "Huan", ""], ["Baker", "Nathan A.", ""], ["Lin", "Guang", ""]]}, {"id": "1506.04430", "submitter": "Clement Dombry", "authors": "Cl\\'ement Dombry and Sebastian Engelke and Marco Oesting", "title": "Exact simulation of max-stable processes", "comments": "27 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Max-stable processes play an important role as models for spatial extreme\nevents. Their complex structure as the pointwise maximum over an infinite\nnumber of random functions makes simulation highly nontrivial. Algorithms based\non finite approximations that are used in practice are often not exact and\ncomputationally inefficient. We will present two algorithms for exact\nsimulation of a max-stable process at a finite number of locations. The first\nalgorithm generalizes the approach by \\citet{DM-2014} for Brown--Resnick\nprocesses and it is based on simulation from the spectral measure. The second\nalgorithm relies on the idea to simulate only the extremal functions, that is,\nthose functions in the construction of a max-stable process that effectively\ncontribute to the pointwise maximum. We study the complexity of both algorithms\nand prove that the second procedure is always more efficient. Moreover, we\nprovide closed expressions for their implementation that cover the most popular\nmodels for max-stable processes and extreme value copulas. For simulation on\ndense grids, an adaptive design of the second algorithm is proposed.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jun 2015 19:10:22 GMT"}], "update_date": "2015-06-16", "authors_parsed": [["Dombry", "Cl\u00e9ment", ""], ["Engelke", "Sebastian", ""], ["Oesting", "Marco", ""]]}, {"id": "1506.04525", "submitter": "Wanyang Dai", "authors": "Wanyang Dai", "title": "Unified Systems of FB-SPDEs/FB-SDEs with Jumps/Skew Reflections and\n  Stochastic Differential Games", "comments": "58 pages, 6 figures, invited talks and plenary talks at a number of\n  conferences and workshops", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.GT math-ph math.MP math.OC math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study four systems and their interactions. First, we formulate a unified\nsystem of coupled forward-backward stochastic partial differential equations\n(FB-SPDEs) with Levy jumps, whose drift, diffusion, and jump coefficients may\ninvolve partial differential operators. A solution to the FB-SPDEs is defined\nby a 4-tuple general dimensional random vector-field process evolving in time\ntogether with position parameters over a domain (e.g., a hyperbox or a\nmanifold). Under an infinite sequence of generalized local linear growth and\nLipschitz conditions, the well-posedness of an adapted 4-tuple strong solution\nis proved over a suitably constructed topological space. Second, we consider a\nunified system of FB-SDEs, a special form of the FB-SPDEs, however, with skew\nboundary reflections. Under randomized linear growth and Lipschitz conditions\ntogether with a general completely-S condition on reflections, we prove the\nwell-posedness of an adapted 6-tuple weak solution with boundary regulators to\nthe FB-SDEs by the Skorohod problem and an oscillation inequality.\nParticularly, if the spectral radii in some sense for reflection matrices are\nstrictly less than the unity, an adapted 6-tuple strong solution is concerned.\nThird, we formulate a stochastic differential game (SDG) with general number of\nplayers based on the FB-SDEs. By a solution to the FB-SPDEs, we get a solution\nto the FB-SDEs under a given control rule and then obtain a Pareto optimal Nash\nequilibrium policy process to the SDG. Fourth, we study the applications of the\nFB-SPDEs/FB-SDEs in queueing systems and quantum statistics while we use them\nto motivate the SDG.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2015 09:21:55 GMT"}, {"version": "v2", "created": "Thu, 27 Aug 2015 00:31:16 GMT"}, {"version": "v3", "created": "Mon, 14 Sep 2015 09:35:30 GMT"}], "update_date": "2015-09-15", "authors_parsed": [["Dai", "Wanyang", ""]]}, {"id": "1506.04576", "submitter": "Jean-Francois Coeurjolly", "authors": "Jean-Fran\\c{c}ois Coeurjolly (FIGAL), Jesper M{\\o}ller, Rasmus\n  Waagepetersen", "title": "Palm distributions for log Gaussian Cox processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper establishes a remarkable result regarding Palmdistributions for a\nlog Gaussian Cox process: the reduced Palmdistribution for a log Gaussian Cox\nprocess is itself a log Gaussian Coxprocess which only differs from the\noriginal log Gaussian Cox processin the intensity function. This new result is\nused to study functionalsummaries for log Gaussian Cox processes.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2015 12:53:48 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2015 09:28:56 GMT"}, {"version": "v3", "created": "Mon, 21 Dec 2015 16:49:48 GMT"}, {"version": "v4", "created": "Wed, 8 Jun 2016 07:48:20 GMT"}], "update_date": "2016-06-09", "authors_parsed": [["Coeurjolly", "Jean-Fran\u00e7ois", "", "FIGAL"], ["M\u00f8ller", "Jesper", ""], ["Waagepetersen", "Rasmus", ""]]}, {"id": "1506.04599", "submitter": "Joseph Skufca", "authors": "Joseph D. Skufca and Daniel ben-Avraham", "title": "Sampling with Costs", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of choosing the best of $n$ samples, out of a large\nrandom pool, when the sampling of each member is associated with a certain\ncost. The quality (worth) of the best sample clearly increases with $n$, but so\ndo the sampling costs, and one important question is how many to sample for\noptimal gain (worth minus costs). If, in addition, the assessment of worth for\neach sample is associated with some \"measurement error,\" the perceived best out\nof $n$ might not be the actual best, complicating the issue. Situations like\nthis are typical in mate selection, job hiring, and food foraging, to name just\na few. We tackle the problem by standard order statistics, yielding suggestions\nfor optimal strategies, as well as some unexpected insights.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2015 13:57:30 GMT"}], "update_date": "2015-06-16", "authors_parsed": [["Skufca", "Joseph D.", ""], ["ben-Avraham", "Daniel", ""]]}, {"id": "1506.04692", "submitter": "Nelo Magalhaes", "authors": "Lucien Birg\\'e (LPMA), Nelo Magalh\\~aes (LPMA, LM-Orsay, SELECT),\n  Pascal Massart (LM-Orsay, SELECT)", "title": "A new V-fold type procedure based on robust tests", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define a general V-fold cross-validation type method based on robust\ntests, which is an extension of the hold-out defined by Birg{\\'e} [7, Section\n9]. We give some theoretical results showing that, under some weak assumptions\non the considered statistical procedures, our selected estimator satisfies an\noracle type inequality. We also introduce a fast algorithm that implements our\nmethod. Moreover we show in our simulations that this V-fold performs generally\nwell for estimating a density for different sample sizes, and can handle\nwell-known problems, such as binwidth selection for histograms or bandwidth\nselection for kernels. We finally provide a comparison with other classical\nV-fold methods and study empirically the influence of the value of V on the\nrisk.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2015 18:20:34 GMT"}], "update_date": "2015-06-16", "authors_parsed": [["Birg\u00e9", "Lucien", "", "LPMA"], ["Magalh\u00e3es", "Nelo", "", "LPMA, LM-Orsay, SELECT"], ["Massart", "Pascal", "", "LM-Orsay, SELECT"]]}, {"id": "1506.04696", "submitter": "Yi-An Ma", "authors": "Yi-An Ma, Tianqi Chen and Emily B. Fox", "title": "A Complete Recipe for Stochastic Gradient MCMC", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many recent Markov chain Monte Carlo (MCMC) samplers leverage continuous\ndynamics to define a transition kernel that efficiently explores a target\ndistribution. In tandem, a focus has been on devising scalable variants that\nsubsample the data and use stochastic gradients in place of full-data gradients\nin the dynamic simulations. However, such stochastic gradient MCMC samplers\nhave lagged behind their full-data counterparts in terms of the complexity of\ndynamics considered since proving convergence in the presence of the stochastic\ngradient noise is non-trivial. Even with simple dynamics, significant physical\nintuition is often required to modify the dynamical system to account for the\nstochastic gradient noise. In this paper, we provide a general recipe for\nconstructing MCMC samplers--including stochastic gradient versions--based on\ncontinuous Markov processes specified via two matrices. We constructively prove\nthat the framework is complete. That is, any continuous Markov process that\nprovides samples from the target distribution can be written in our framework.\nWe show how previous continuous-dynamic samplers can be trivially \"reinvented\"\nin our framework, avoiding the complicated sampler-specific proofs. We likewise\nuse our recipe to straightforwardly propose a new state-adaptive sampler:\nstochastic gradient Riemann Hamiltonian Monte Carlo (SGRHMC). Our experiments\non simulated data and a streaming Wikipedia analysis demonstrate that the\nproposed SGRHMC sampler inherits the benefits of Riemann HMC, with the\nscalability of stochastic gradient methods.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2015 18:32:37 GMT"}, {"version": "v2", "created": "Sun, 1 Nov 2015 00:18:32 GMT"}], "update_date": "2015-11-03", "authors_parsed": [["Ma", "Yi-An", ""], ["Chen", "Tianqi", ""], ["Fox", "Emily B.", ""]]}, {"id": "1506.04709", "submitter": "Jere Koskela", "authors": "Jere Koskela, Dario Spano and Paul A. Jenkins", "title": "Consistency of Bayesian nonparametric inference for discretely observed\n  jump diffusions", "comments": "20 pages", "journal-ref": "Bernoulli 25(3):2183-2205, 2019", "doi": "10.3150/18-BEJ1050", "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce verifiable criteria for weak posterior consistency of\nidentifiable Bayesian nonparametric inference for jump diffusions with unit\ndiffusion coefficient and uniformly Lipschitz drift and jump coefficients in\narbitrary dimension. The criteria are expressed in terms of coefficients of the\nSDEs describing the process, and do not depend on intractable quantities such\nas transition densities. We also show that products of discrete net and\nDirichlet mixture model priors satisfy our conditions, again under an\nidentifiability assumption. This generalises known results by incorporating\njumps into previous work on unit diffusions with uniformly Lipschitz drift\ncoefficients.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2015 19:16:54 GMT"}, {"version": "v2", "created": "Sat, 14 Jan 2017 18:29:28 GMT"}, {"version": "v3", "created": "Wed, 15 Nov 2017 15:36:45 GMT"}, {"version": "v4", "created": "Fri, 14 Sep 2018 16:09:04 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Koskela", "Jere", ""], ["Spano", "Dario", ""], ["Jenkins", "Paul A.", ""]]}, {"id": "1506.04711", "submitter": "Joel Tropp", "authors": "Joel A. Tropp", "title": "The Expected Norm of a Sum of Independent Random Matrices: An Elementary\n  Approach", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In contemporary applied and computational mathematics, a frequent challenge\nis to bound the expectation of the spectral norm of a sum of independent random\nmatrices. This quantity is controlled by the norm of the expected square of the\nrandom matrix and the expectation of the maximum squared norm achieved by one\nof the summands; there is also a weak dependence on the dimension of the random\nmatrix. The purpose of this paper is to give a complete, elementary proof of\nthis important, but underappreciated, inequality.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2015 19:22:03 GMT"}, {"version": "v2", "created": "Fri, 16 Oct 2015 16:11:52 GMT"}], "update_date": "2015-10-19", "authors_parsed": [["Tropp", "Joel A.", ""]]}, {"id": "1506.04775", "submitter": "Igor Vladimirov", "authors": "Igor G. Vladimirov", "title": "A stochastic density matrix approach to approximation of probability\n  distributions and its application to nonlinear systems", "comments": "12 pages, 3 figures. A brief version of this paper will appear in the\n  proceedings of the IEEE Multi-Conference on Systems and Control, 21-23\n  September 2015, Sydney, Australia", "journal-ref": null, "doi": "10.1109/CCA.2015.7320758", "report-no": null, "categories": "math.PR cs.SY math.AP math.NA math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper outlines an approach to the approximation of probability density\nfunctions by quadratic forms of weighted orthonormal basis functions with\npositive semi-definite Hermitian matrices of unit trace. Such matrices are\ncalled stochastic density matrices in order to reflect an analogy with the\nquantum mechanical density matrices. The SDM approximation of a PDF satisfies\nthe normalization condition and is nonnegative everywhere in contrast to the\ntruncated Gram-Charlier and Edgeworth expansions. For bases with an algebraic\nstructure, such as the Hermite polynomial and Fourier bases, the SDM\napproximation can be chosen so as to satisfy given moment specifications and\ncan be optimized using a quadratic proximity criterion. We apply the SDM\napproach to the Fokker-Planck-Kolmogorov PDF dynamics of Markov diffusion\nprocesses governed by nonlinear stochastic differential equations. This leads\nto an ordinary differential equation for the SDM dynamics of the approximating\nPDF. As an example, we consider the Smoluchowski SDE on a multidimensional\ntorus.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2015 21:16:36 GMT"}, {"version": "v2", "created": "Mon, 10 Aug 2015 05:07:21 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Vladimirov", "Igor G.", ""]]}, {"id": "1506.04915", "submitter": "Bernardo Nipoti", "authors": "Julyan Arbel, Stefano Favaro, Bernardo Nipoti, Yee Whye Teh", "title": "Bayesian nonparametric inference for discovery probabilities: credible\n  intervals and large sample asymptotics", "comments": null, "journal-ref": "Statistica Sinica, 27:839--858, 2017", "doi": "10.5705/ss.202015.0250", "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a sample of size $n$ from a population of individuals belonging to\ndifferent species with unknown proportions, a popular problem of practical\ninterest consists in making inference on the probability $D_{n}(l)$ that the\n$(n+1)$-th draw coincides with a species with frequency $l$ in the sample, for\nany $l=0,1,\\ldots,n$. This paper contributes to the methodology of Bayesian\nnonparametric inference for $D_{n}(l)$. Specifically, under the general\nframework of Gibbs-type priors we show how to derive credible intervals for a\nBayesian nonparametric estimation of $D_{n}(l)$, and we investigate the large\n$n$ asymptotic behaviour of such an estimator. Of particular interest are\nspecial cases of our results obtained under the specification of the two\nparameter Poisson--Dirichlet prior and the normalized generalized Gamma prior,\nwhich are two of the most commonly used Gibbs-type priors. With respect to\nthese two prior specifications, the proposed results are illustrated through a\nsimulation study and a benchmark Expressed Sequence Tags dataset. To the best\nour knowledge, this illustration provides the first comparative study between\nthe two parameter Poisson--Dirichlet prior and the normalized generalized Gamma\nprior in the context of Bayesian nonparemetric inference for $D_{n}(l)$.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2015 11:02:18 GMT"}, {"version": "v2", "created": "Sat, 2 Jul 2016 10:44:11 GMT"}], "update_date": "2017-10-18", "authors_parsed": [["Arbel", "Julyan", ""], ["Favaro", "Stefano", ""], ["Nipoti", "Bernardo", ""], ["Teh", "Yee Whye", ""]]}, {"id": "1506.04989", "submitter": "V. J.  Vieland", "authors": "V.J Vieland, S-C. Seok", "title": "Statistical Evidence Measured on a Properly Calibrated Scale Across\n  Nested and Non-nested Hypothesis Comparisons", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical modeling is often used to measure the strength of evidence for or\nagainst hypotheses on given data. We have previously proposed an\ninformation-dynamic framework in support of a properly calibrated measurement\nscale for statistical evidence, borrowing some mathematics from thermodynamics,\nand showing how an evidential analogue of the ideal gas equation of state could\nbe used to measure evidence for a one-sided binomial hypothesis comparison\n(coin is fair versus coin is biased towards heads). Here we take three\nimportant steps forward in generalizing the framework beyond this simple\nexample. We (1) extend the scope of application to other forms of hypothesis\ncomparison in the binomial setting; (2) show that doing so requires only the\noriginal ideal gas equation plus one simple extension, which has the form of\nthe Van der Waals equation; (3) begin to develop the principles required to\nresolve a key constant, which enables us to calibrate the measurement scale\nacross applications, and which we find to be related to the familiar\nstatistical concept of degrees of freedom. This paper thus moves our\ninformation-dynamic theory substantially closer to the goal of producing a\npractical, properly calibrated measure of statistical evidence for use in\ngeneral applications.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2015 14:35:06 GMT"}], "update_date": "2015-06-17", "authors_parsed": [["Vieland", "V. J", ""], ["Seok", "S-C.", ""]]}, {"id": "1506.04991", "submitter": "Daniel Graham", "authors": "Daniel J. Graham, Emma J. McCoy, and David A. Stephens", "title": "Doubly robust dose-response estimation for continuous treatments via\n  generalized propensity score augmented outcome regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper constructs a doubly robust estimator for continuous dose-response\nestimation. An outcome regression model is augmented with a set of inverse\ngeneralized propensity score covariates to correct for potential\nmisspecification bias. From the augmented model we can obtain consistent\nestimates of mean average potential outcomes for distinct strata of the\ntreatment. A polynomial regression is then fitted to these point estimates to\nderive a Taylor approximation to the continuous dose-response function. The\nbootstrap is used for variance estimation. Analytical results and simulations\nshow that our approach can provide a good approximation to linear or nonlinear\ndose-response functions under various sources of misspecification of the\noutcome regression or propensity score models. Efficiency in finite samples is\ngood relative to minimum variance consistent estimators.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2015 14:37:10 GMT"}], "update_date": "2015-06-17", "authors_parsed": [["Graham", "Daniel J.", ""], ["McCoy", "Emma J.", ""], ["Stephens", "David A.", ""]]}, {"id": "1506.05192", "submitter": "Harm Derksen", "authors": "Harm Derksen, Arno van den Essen and Wenhua Zhao", "title": "The Gaussian Moments Conjecture and the Jacobian Conjecture", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AC math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We first propose what we call the Gaussian Moments Conjecture. We then show\nthat the Jacobian Conjecture follows from the Gaussian Moments Conjecture. We\nalso give a counter-example to a more general statement known as the Moments\nVanishing Conjecture .\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2015 03:10:48 GMT"}], "update_date": "2015-06-18", "authors_parsed": [["Derksen", "Harm", ""], ["Essen", "Arno van den", ""], ["Zhao", "Wenhua", ""]]}, {"id": "1506.05275", "submitter": "Sokbae Lee", "authors": "Le-Yu Chen, Sokbae Lee", "title": "Breaking the curse of dimensionality in conditional moment inequalities\n  for discrete choice models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies inference of preference parameters in semiparametric\ndiscrete choice models when these parameters are not point-identified and the\nidentified set is characterized by a class of conditional moment inequalities.\nExploring the semiparametric modeling restrictions, we show that the identified\nset can be equivalently formulated by moment inequalities conditional on only\ntwo continuous indexing variables. Such formulation holds regardless of the\ncovariate dimension, thereby breaking the curse of dimensionality for\nnonparametric inference based on the underlying conditional moment\ninequalities. We further apply this dimension reducing characterization\napproach to the monotone single index model and to a variety of semiparametric\nmodels under which the sign of conditional expectation of a certain\ntransformation of the outcome is the same as that of the indexing variable.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2015 10:48:46 GMT"}, {"version": "v2", "created": "Mon, 11 Apr 2016 11:50:20 GMT"}, {"version": "v3", "created": "Fri, 23 Nov 2018 16:19:34 GMT"}], "update_date": "2018-11-26", "authors_parsed": [["Chen", "Le-Yu", ""], ["Lee", "Sokbae", ""]]}, {"id": "1506.05319", "submitter": "Jan Vrbik", "authors": "Clarence Kalitsi and Jan Vrbik", "title": "Cumulants of products of Normally distributed random variables", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To find moments of various estimators related to Autoregressive models of\nStatistics, one first needs the cumulants of products of two Normally\ndistributed random variables. The purpose of this article is to derive the\ncorresponding formulas, and extend them to products of three or more such\nvariables.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2015 13:17:33 GMT"}], "update_date": "2015-06-18", "authors_parsed": [["Kalitsi", "Clarence", ""], ["Vrbik", "Jan", ""]]}, {"id": "1506.05337", "submitter": "Sokbae Lee", "authors": "Sokbae Lee, Kyungchul Song, Yoon-Jae Whang", "title": "Uniform Asymptotics for Nonparametric Quantile Regression with an\n  Application to Testing Monotonicity", "comments": "arXiv admin note: substantial text overlap with arXiv:1311.1595", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we establish a uniform error rate of a Bahadur representation\nfor local polynomial estimators of quantile regression functions. The error\nrate is uniform over a range of quantiles, a range of evaluation points in the\nregressors, and over a wide class of probabilities for observed random\nvariables. Most of the existing results on Bahadur representations for local\npolynomial quantile regression estimators apply to the fixed data generating\nprocess. In the context of testing monotonicity where the null hypothesis is of\na complex composite hypothesis, it is particularly relevant to establish\nBahadur expansions that hold uniformly over a large class of data generating\nprocesses. In addition, we establish the same error rate for bootstrap local\npolynomial estimators which can be useful for various bootstrap inference. As\nan illustration, we apply to testing monotonicity of quantile regression and\npresent Monte Carlo experiments based on this example.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2015 13:55:35 GMT"}, {"version": "v2", "created": "Wed, 26 Aug 2015 19:03:15 GMT"}], "update_date": "2015-08-27", "authors_parsed": [["Lee", "Sokbae", ""], ["Song", "Kyungchul", ""], ["Whang", "Yoon-Jae", ""]]}, {"id": "1506.05483", "submitter": "Janne V. Kujala", "authors": "Janne V. Kujala", "title": "Asymptotic optimality of myopic information-based strategies for\n  Bayesian adaptive estimation", "comments": "Published at http://dx.doi.org/10.3150/14-BEJ670 in the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2016, Vol. 22, No. 1, 615-651", "doi": "10.3150/14-BEJ670", "report-no": "IMS-BEJ-BEJ670", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a general asymptotic theory of sequential Bayesian\nestimation giving results for the strongest, almost sure convergence. We show\nthat under certain smoothness conditions on the probability model, the greedy\ninformation gain maximization algorithm for adaptive Bayesian estimation is\nasymptotically optimal in the sense that the determinant of the posterior\ncovariance in a certain neighborhood of the true parameter value is\nasymptotically minimal. Using this result, we also obtain an asymptotic\nexpression for the posterior entropy based on a novel definition of almost sure\nconvergence on \"most trials\" (meaning that the convergence holds on a fraction\nof trials that converges to one). Then, we extend the results to a recently\npublished framework, which generalizes the usual adaptive estimation setting by\nallowing different trial placements to be associated with different, random\ncosts of observation. For this setting, the author has proposed the heuristic\nof maximizing the expected information gain divided by the expected cost of\nthat placement. In this paper, we show that this myopic strategy satisfies an\nanalogous asymptotic optimality result when the convergence of the posterior\ndistribution is considered as a function of the total cost (as opposed to the\nnumber of observations).\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2015 20:18:46 GMT"}, {"version": "v2", "created": "Fri, 8 Jan 2016 06:42:29 GMT"}], "update_date": "2016-01-11", "authors_parsed": [["Kujala", "Janne V.", ""]]}, {"id": "1506.05536", "submitter": "Yu Xia", "authors": "Yu Xia, Farid Alizadeh", "title": "Second-Order Cone Programming for P-Spline Simulation Metamodeling", "comments": "Extended abstract appears in the Proceedings of the 2014 Winter\n  Simulation Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper approximates simulation models by B-splines with a penalty on\nhigh-order finite differences of the coefficients of adjacent B-splines. The\npenalty prevents overfitting. The simulation output is assumed to be\nnonnegative. The nonnegative spline simulation metamodel is casted as a\nsecond-order cone programming model, which can be solved efficiently by modern\noptimization techniques. The method is implemented in MATLAB/GNU Octave.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2015 02:32:53 GMT"}], "update_date": "2015-06-19", "authors_parsed": [["Xia", "Yu", ""], ["Alizadeh", "Farid", ""]]}, {"id": "1506.05539", "submitter": "Zijian Guo", "authors": "T. Tony Cai and Zijian Guo", "title": "Confidence Intervals for High-Dimensional Linear Regression: Minimax\n  Rates and Adaptivity", "comments": "31 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Confidence sets play a fundamental role in statistical inference. In this\npaper, we consider confidence intervals for high dimensional linear regression\nwith random design. We first establish the convergence rates of the minimax\nexpected length for confidence intervals in the oracle setting where the\nsparsity parameter is given. The focus is then on the problem of adaptation to\nsparsity for the construction of confidence intervals. Ideally, an adaptive\nconfidence interval should have its length automatically adjusted to the\nsparsity of the unknown regression vector, while maintaining a prespecified\ncoverage probability. It is shown that such a goal is in general not\nattainable, except when the sparsity parameter is restricted to a small region\nover which the confidence intervals have the optimal length of the usual\nparametric rate. It is further demonstrated that the lack of adaptivity is not\ndue to the conservativeness of the minimax framework, but is fundamentally\ncaused by the difficulty of learning the bias accurately.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2015 03:23:00 GMT"}, {"version": "v2", "created": "Fri, 27 Nov 2015 17:07:18 GMT"}], "update_date": "2015-11-30", "authors_parsed": [["Cai", "T. Tony", ""], ["Guo", "Zijian", ""]]}, {"id": "1506.05593", "submitter": "Thi To Nhu Dang", "authors": "Thi To Nhu Dang and Jacques Istas", "title": "Estimation of the Hurst and the stability indices of a $H$-self-similar\n  stable process", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we estimate both the Hurst and the stable indices of a\nH-self-similar stable process. More precisely, let $X$ be a $H$-sssi\n(self-similar stationary increments) symmetric $\\alpha$-stable process. The\nprocess $X$ is observed at points $\\frac{k}{n}$, $k=0,\\ldots,n$. Our estimate\nis based on $\\beta$-variations with $-\\frac{1}{2}<\\beta<0$. We obtain\nconsistent estimators, with rate of convergence, for several classical $H$-sssi\n$\\alpha$-stable processes (fractional Brownian motion, well-balanced linear\nfractional stable motion, Takenaka's processes, L\\'evy motion). Moreover, we\nobtain asymptotic normality of our estimators for fractional Brownian motion\nand L\\'evy motion.\n  Keywords: H-sssi processes; stable processes; self-similarity parameter\nestimator; stability parameter estimator.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2015 09:17:02 GMT"}, {"version": "v2", "created": "Thu, 3 Aug 2017 23:26:02 GMT"}, {"version": "v3", "created": "Wed, 18 Oct 2017 00:28:45 GMT"}], "update_date": "2017-10-19", "authors_parsed": [["Dang", "Thi To Nhu", ""], ["Istas", "Jacques", ""]]}, {"id": "1506.05750", "submitter": "Meitner Cadena", "authors": "Meitner Cadena", "title": "A simple estimator for the $\\mathcal{M}$-index of functions in\n  $\\mathcal{M}$", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An estimator for the $\\M$-index of functions of $\\mathcal{M}$, a larger class\nthan the class of regularly varying (RV) functions, is proposed. This index is\nthe tail index of RV functions and this estimator is thus a new one on the\nclass of RV functions. This estimator satisfies, assuming suitable conditions,\nstrong consistency. Asymptotic normality of this estimator is proved for a\nlarge class of RV functions, showing a better performance than some well-known\nestimators. Illustrations with simulated and real life datasets are provided.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2015 13:47:39 GMT"}, {"version": "v2", "created": "Mon, 7 Dec 2015 20:26:40 GMT"}], "update_date": "2015-12-08", "authors_parsed": [["Cadena", "Meitner", ""]]}, {"id": "1506.05779", "submitter": "Mayya Zhilova", "authors": "Mayya Zhilova", "title": "Simultaneous likelihood-based bootstrap confidence sets for a large\n  number of models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper studies a problem of constructing simultaneous likelihood-based\nconfidence sets. We consider a simultaneous multiplier bootstrap procedure for\nestimating the quantiles of the joint distribution of the likelihood ratio\nstatistics, and for adjusting the confidence level for multiplicity.\nTheoretical results state the bootstrap validity in the following setting: the\nsample size \\(n\\) is fixed, the maximal parameter dimension\n\\(p_{\\textrm{max}}\\) and the number of considered parametric models \\(K\\) are\ns.t. \\((\\log K)^{12}p_{\\max}^{3}/n\\) is small. We also consider the situation\nwhen the parametric models are misspecified. If the models' misspecification is\nsignificant, then the bootstrap critical values exceed the true ones and the\nsimultaneous bootstrap confidence set becomes conservative. Numerical\nexperiments for local constant and local quadratic regressions illustrate the\ntheoretical results.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2015 19:29:32 GMT"}], "update_date": "2015-06-19", "authors_parsed": [["Zhilova", "Mayya", ""]]}, {"id": "1506.05830", "submitter": "Maryam Sohrabi Dr", "authors": "Maryam Sohrabi and Mahmoud Zarepour", "title": "Asymptotic Theory for M-Estimates in Unstable AR(p) Processes with\n  Infinite Variance Innovations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present the asymptotic distribution of M-estimators for\nparameters in non-stationary AR(p) processes. The innovations are assumed to be\nin the domain of attraction of a stable law with index $0<\\alpha\\le2$. In\nparticular, when the model involves repeated unit roots or conjugate complex\nunit roots, M-estimators have a higher asymptotic rate of convergence compared\nto the least square estimators and the asymptotic results can be written as\nIt\\^{o} stochastic integrals.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2015 21:46:26 GMT"}, {"version": "v2", "created": "Mon, 12 Dec 2016 17:59:12 GMT"}], "update_date": "2016-12-13", "authors_parsed": [["Sohrabi", "Maryam", ""], ["Zarepour", "Mahmoud", ""]]}, {"id": "1506.06058", "submitter": "Steven Ellis", "authors": "Steven P. Ellis", "title": "Joining and Independence in Concurrence Topology", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  \"Concurrence topology\" (Ellis and Klein \\emph{Homology, Homotopy, and\nApplications,} \\textbf{16}) is a TDA method for binary data. The idea is to\nconstruct a filtration consisting of Dowker complexes then compute persistent\nhomology. Persistent classes correspond to a form of negative statistical\nassociation among the variables.\n  Suppose we have two groups of binary variables each displaying negative\nassociation, manifested in nontrivial concurrence homology in dimensions $p$\nand in one group and $q$ in the other \\emph{when the groups of variables are\nconsidered individually.} Suppose, however, that the two \\emph{groups} of\nvariables are statistically independent of each other. Now combine the two\ngroups of variables and suppose the sample size is large. Then representative\ncycles, one from each group of variables, will combine to produce a cycle in\ndimension $p+q+1$. This is a chain level phenomenon, but we show it has a\nsignature in homology. Looking for this signature can be used to study the\ndependence among groups of variables.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2015 15:39:23 GMT"}, {"version": "v2", "created": "Tue, 20 Jun 2017 17:59:57 GMT"}], "update_date": "2017-06-21", "authors_parsed": [["Ellis", "Steven P.", ""]]}, {"id": "1506.06162", "submitter": "Adam Smith", "authors": "Christian Borgs and Jennifer T. Chayes and Adam Smith", "title": "Private Graphon Estimation for Sparse Graphs", "comments": "36 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.CR cs.DS stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We design algorithms for fitting a high-dimensional statistical model to a\nlarge, sparse network without revealing sensitive information of individual\nmembers. Given a sparse input graph $G$, our algorithms output a\nnode-differentially-private nonparametric block model approximation. By\nnode-differentially-private, we mean that our output hides the insertion or\nremoval of a vertex and all its adjacent edges. If $G$ is an instance of the\nnetwork obtained from a generative nonparametric model defined in terms of a\ngraphon $W$, our model guarantees consistency, in the sense that as the number\nof vertices tends to infinity, the output of our algorithm converges to $W$ in\nan appropriate version of the $L_2$ norm. In particular, this means we can\nestimate the sizes of all multi-way cuts in $G$.\n  Our results hold as long as $W$ is bounded, the average degree of $G$ grows\nat least like the log of the number of vertices, and the number of blocks goes\nto infinity at an appropriate rate. We give explicit error bounds in terms of\nthe parameters of the model; in several settings, our bounds improve on or\nmatch known nonprivate results.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2015 21:29:52 GMT"}], "update_date": "2015-06-23", "authors_parsed": [["Borgs", "Christian", ""], ["Chayes", "Jennifer T.", ""], ["Smith", "Adam", ""]]}, {"id": "1506.06199", "submitter": "Taposh Banerjee", "authors": "Taposh Banerjee, Hamed Firouzi and Alfred O. Hero III", "title": "Non-parametric Quickest Change Detection for Large Scale Random Matrices", "comments": "Proc. of ISIT, Hong Kong, 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT math.IT stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of quickest detection of a change in the distribution of a\n$n\\times p$ random matrix based on a sequence of observations having a single\nunknown change point is considered. The forms of the pre- and post-change\ndistributions of the rows of the matrices are assumed to belong to the family\nof elliptically contoured densities with sparse dispersion matrices but are\notherwise unknown. We propose a non-parametric stopping rule that is based on a\nnovel summary statistic related to k-nearest neighbor correlation between\ncolumns of each observed random matrix. In the large scale regime of\n$p\\rightarrow \\infty$ and $n$ fixed we show that, among all functions of the\nproposed summary statistic, the proposed stopping rule is asymptotically\noptimal under a minimax quickest change detection (QCD) model.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jun 2015 03:45:15 GMT"}], "update_date": "2015-06-23", "authors_parsed": [["Banerjee", "Taposh", ""], ["Firouzi", "Hamed", ""], ["Hero", "Alfred O.", "III"]]}, {"id": "1506.06266", "submitter": "Ryan Tibshirani", "authors": "Ryan J. Tibshirani, Alessandro Rinaldo, Robert Tibshirani, Larry\n  Wasserman", "title": "Uniform Asymptotic Inference and the Bootstrap After Model Selection", "comments": "47 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, Tibshirani et al. (2016) proposed a method for making inferences\nabout parameters defined by model selection, in a typical regression setting\nwith normally distributed errors. Here, we study the large sample properties of\nthis method, without assuming normality. We prove that the test statistic of\nTibshirani et al. (2016) is asymptotically valid, as the number of samples n\ngrows and the dimension d of the regression problem stays fixed. Our asymptotic\nresult holds uniformly over a wide class of nonnormal error distributions. We\nalso propose an efficient bootstrap version of this test that is provably\n(asymptotically) conservative, and in practice, often delivers shorter\nintervals than those from the original normality-based approach. Finally, we\nprove that the test statistic of Tibshirani et al. (2016) does not enjoy\nuniform validity in a high-dimensional setting, when the dimension d is allowed\ngrow.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jun 2015 16:38:34 GMT"}, {"version": "v2", "created": "Wed, 24 Jun 2015 21:44:43 GMT"}, {"version": "v3", "created": "Wed, 9 Aug 2017 15:27:44 GMT"}], "update_date": "2017-08-10", "authors_parsed": [["Tibshirani", "Ryan J.", ""], ["Rinaldo", "Alessandro", ""], ["Tibshirani", "Robert", ""], ["Wasserman", "Larry", ""]]}, {"id": "1506.06322", "submitter": "Mohammad Jafari Jozani", "authors": "Saeid Amiri, Mohammad Jafari Jozani, Reza Modarres", "title": "Exponentially Titled Empirical Distribution Function for Ranked Set\n  Samples", "comments": "18 pages, 3 Figuers, 6 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study nonparametric estimation of the distribution function (DF) of a\ncontinuous random variable based on a ranked set sampling design using the\nexponentially tilted (ET) empirical likelihood method. We propose ET estimators\nof the DF and use them to construct new resampling algorithms for unbalanced\nranked set samples. We explore the properties of the proposed algorithms. For a\nhypothesis testing problem about the underlying population mean, we show that\nthe bootstrap tests based on the ET estimators of the DF are asymptotically\nnormal and exhibit a small bias of order $O(n^{-1})$. We illustrate the methods\nand evaluate the finite sample performance of the algorithms under both perfect\nand imperfect ranking schemes using a real data set and several Monte Carlo\nsimulation studies. We compare the performance of the test statistics based on\nthe ET estimators with those based on the empirical likelihood estimators.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jun 2015 05:11:06 GMT"}], "update_date": "2015-06-23", "authors_parsed": [["Amiri", "Saeid", ""], ["Jozani", "Mohammad Jafari", ""], ["Modarres", "Reza", ""]]}, {"id": "1506.06422", "submitter": "Justin Eldridge", "authors": "Justin Eldridge, Mikhail Belkin, Yusu Wang", "title": "Beyond Hartigan Consistency: Merge Distortion Metric for Hierarchical\n  Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hierarchical clustering is a popular method for analyzing data which\nassociates a tree to a dataset. Hartigan consistency has been used extensively\nas a framework to analyze such clustering algorithms from a statistical point\nof view. Still, as we show in the paper, a tree which is Hartigan consistent\nwith a given density can look very different than the correct limit tree.\nSpecifically, Hartigan consistency permits two types of undesirable\nconfigurations which we term over-segmentation and improper nesting. Moreover,\nHartigan consistency is a limit property and does not directly quantify\ndifference between trees.\n  In this paper we identify two limit properties, separation and minimality,\nwhich address both over-segmentation and improper nesting and together imply\n(but are not implied by) Hartigan consistency. We proceed to introduce a merge\ndistortion metric between hierarchical clusterings and show that convergence in\nour distance implies both separation and minimality. We also prove that uniform\nseparation and minimality imply convergence in the merge distortion metric.\nFurthermore, we show that our merge distortion metric is stable under\nperturbations of the density.\n  Finally, we demonstrate applicability of these concepts by proving\nconvergence results for two clustering algorithms. First, we show convergence\n(and hence separation and minimality) of the recent robust single linkage\nalgorithm of Chaudhuri and Dasgupta (2010). Second, we provide convergence\nresults on manifolds for topological split tree clustering.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jun 2015 23:19:37 GMT"}, {"version": "v2", "created": "Mon, 13 Jul 2015 18:01:07 GMT"}], "update_date": "2015-07-14", "authors_parsed": [["Eldridge", "Justin", ""], ["Belkin", "Mikhail", ""], ["Wang", "Yusu", ""]]}, {"id": "1506.06941", "submitter": "Katia Meziani", "authors": "Karim Lounici and Katia Meziani and Gabriel Peyr\\'e", "title": "Minimax and adaptive estimation of the Wigner function in quantum\n  homodyne tomography with noisy data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST quant-ph stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In quantum optics, the quantum state of a light beam is represented through\nthe Wigner function, a density on $\\mathbb R^2$ which may take negative values\nbut must respect intrinsic positivity constraints imposed by quantum physics.\nIn the framework of noisy quantum homodyne tomography with efficiency parameter\n$1/2 < \\eta \\leq 1$, we study the theoretical performance of a kernel estimator\nof the Wigner function. We prove that it is minimax efficient, up to a\nlogarithmic factor in the sample size, for the $\\mathbb L_\\infty$-risk over a\nclass of infinitely differentiable. We compute also the lower bound for the\n$\\mathbb L_2$-risk. We construct adaptive estimator, i.e. which does not depend\non the smoothness parameters, and prove that it attains the minimax rates for\nthe corresponding smoothness class functions. Finite sample behaviour of our\nadaptive procedure are explored through numerical experiments.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2015 11:05:13 GMT"}], "update_date": "2015-06-24", "authors_parsed": [["Lounici", "Karim", ""], ["Meziani", "Katia", ""], ["Peyr\u00e9", "Gabriel", ""]]}, {"id": "1506.07212", "submitter": "Rafael Frongillo", "authors": "Rafael Frongillo, Ian A. Kash", "title": "Elicitation Complexity of Statistical Properties", "comments": "This version fixes an error in the condition needed for the main\n  lower bound and adds an application to Range Value at Risk, along with a\n  substantial reorganization of the paper and numerous smaller changes. A\n  previous version appeared in Neural Information Processing Systems 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC math.ST q-fin.MF stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A property, or statistical functional, is said to be elicitable if it\nminimizes expected loss for some loss function. The study of which properties\nare elicitable sheds light on the capabilities and limitations of point\nestimation and empirical risk minimization. While recent work asks which\nproperties are elicitable, we instead advocate for a more nuanced question: how\nmany dimensions are required to indirectly elicit a given property? This number\nis called the elicitation complexity of the property. We lay the foundation for\na general theory of elicitation complexity, including several basic results\nabout how elicitation complexity behaves, and the complexity of standard\nproperties of interest. Building on this foundation, our main result gives\ntight complexity bounds for the broad class of Bayes risks. We apply these\nresults to several properties of interest, including variance, entropy, norms,\nand several classes of financial risk measures. We conclude with discussion and\nopen directions.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2015 23:22:05 GMT"}, {"version": "v2", "created": "Mon, 8 Oct 2018 00:45:54 GMT"}, {"version": "v3", "created": "Thu, 27 Aug 2020 20:42:55 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Frongillo", "Rafael", ""], ["Kash", "Ian A.", ""]]}, {"id": "1506.07296", "submitter": "Johannes Tewes", "authors": "Johannes Tewes", "title": "Change-point tests under local alternatives for long-range dependent\n  processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the change-point problem for the marginal distribution of\nsubordinated Gaussian processes that exhibit long-range dependence. The\nasymptotic distributions of Kolmogorov-Smirnov- and Cram\\'{e}r-von Mises type\nstatistics are investigated under local alternatives. By doing so we are able\nto compute the asymptotic relative efficiency of the mentioned tests and the\nCUSUM test. In the special case of a mean-shift in Gaussian data it is always\n$1$. Moreover our theory covers the scenario where the Hermite rank of the\nunderlying process changes.\n  In a small simulation study we show that the theoretical findings carry over\nto the finite sample performance of the tests.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2015 09:37:43 GMT"}, {"version": "v2", "created": "Thu, 16 Mar 2017 13:33:38 GMT"}], "update_date": "2017-03-17", "authors_parsed": [["Tewes", "Johannes", ""]]}, {"id": "1506.07368", "submitter": "Stefan Rass", "authors": "Stefan Rass", "title": "On Game-Theoretic Risk Management (Part One) -- Towards a Theory of\n  Games with Payoffs that are Probability-Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.GN math.ST q-fin.EC stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimal behavior in (competitive) situation is traditionally determined with\nthe help of utility functions that measure the payoff of different actions.\nGiven an ordering on the space of revenues (payoffs), the classical axiomatic\napproach of von Neumann and Morgenstern establishes the existence of suitable\nutility functions, and yields to game-theory as the most prominent\nmaterialization of a theory to determine optimal behavior. Although this\nappears to be a most natural approach to risk management too, applications in\ncritical infrastructures often violate the implicit assumption of actions\nleading to deterministic consequences. In that sense, the gameplay in a\ncritical infrastructure risk control competition is intrinsically random in the\nsense of actions having uncertain consequences. Mathematically, this takes us\nto utility functions that are probability-distribution-valued, in which case we\nloose the canonic (in fact every possible) ordering on the space of payoffs,\nand the original techniques of von Neumann and Morgenstern no longer apply.\n  This work introduces a new kind of game in which uncertainty applies to the\npayoff functions rather than the player's actions (a setting that has been\nwidely studied in the literature, yielding to celebrated notions like the\ntrembling hands equilibrium or the purification theorem). In detail, we show\nhow to fix the non-existence of a (canonic) ordering on the space of\nprobability distributions by only mildly restricting the full set to a subset\nthat can be totally ordered. Our vehicle to define the ordering and establish\nbasic game-theory is non-standard analysis and hyperreal numbers.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2015 14:00:41 GMT"}, {"version": "v2", "created": "Fri, 26 Jun 2015 10:34:15 GMT"}, {"version": "v3", "created": "Thu, 13 Aug 2015 10:46:49 GMT"}, {"version": "v4", "created": "Thu, 17 Sep 2015 11:58:18 GMT"}, {"version": "v5", "created": "Fri, 24 Apr 2020 11:02:52 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Rass", "Stefan", ""]]}, {"id": "1506.07404", "submitter": "Mathias Vetter", "authors": "Michael Hoffmann and Mathias Vetter", "title": "Weak convergence of the empirical truncated distribution function of the\n  L\\'evy measure of an It\\=o semimartingale", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given an It\\=o semimartingale with a time-homogeneous jump part observed at\nhigh frequency, we prove weak convergence of a normalized truncated empirical\ndistribution function of the L\\'evy measure to a Gaussian process. In contrast\nto competing procedures, our estimator works for processes with a non-vanishing\ndiffusion component and under simple assumptions on the jump process.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2015 14:58:20 GMT"}], "update_date": "2015-06-25", "authors_parsed": [["Hoffmann", "Michael", ""], ["Vetter", "Mathias", ""]]}, {"id": "1506.07446", "submitter": "Michel Miniconi", "authors": "Bernard Candelpergher (JAD), Michel Miniconi (JAD), Florian Pelgrin\n  (HEC)", "title": "Long-memory process and aggregation of AR(1) stochastic processes: A new\n  characterization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.CV math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contemporaneous aggregation of individual AR(1) random processes might lead\nto different properties of the limit aggregated time series, in particular,\nlong memory (Granger, 1980). We provide a new characterization of the series of\nautoregressive coefficients, which is defined from the Wold representation of\nthe limit of the aggregate stochastic process, in the presence of long-memory\nfeatures. Especially the infinite autoregressive stochastic process defined by\nthe almost sure representation of the aggregate process has a unit root in the\npresence of the long-memory property. Finally we discuss some examples using\nsome well-known probability density functions of the autoregressive random\nparameter in the aggregation literature. JEL Classification Code: C2, C13.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2015 06:07:35 GMT"}, {"version": "v2", "created": "Sat, 8 Aug 2015 17:24:46 GMT"}], "update_date": "2015-08-11", "authors_parsed": [["Candelpergher", "Bernard", "", "JAD"], ["Miniconi", "Michel", "", "JAD"], ["Pelgrin", "Florian", "", "HEC"]]}, {"id": "1506.07509", "submitter": "Jos\\'e A. D\\'iaz-Garc\\'ia", "authors": "Jose A. Diaz-Garcia and Ramon Gutierrez-Sanchez", "title": "Generalised matrix multivariate Pearson type II-distribution", "comments": "17 pages. arXiv admin note: substantial text overlap with\n  arXiv:1407.4551, arXiv:1402.5178, arXiv:1402.4520, arXiv:1301.4525,\n  arXiv:1304.5292", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matrix multivariate Pearson type II-Riesz distribution is defined and some of\nits properties are studied. In particular, the associated matrix multivariate\nbeta distribution type I is derived. Also the singular values and eigenvalues\ndistributions are obtained.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2015 19:39:01 GMT"}], "update_date": "2015-06-25", "authors_parsed": [["Diaz-Garcia", "Jose A.", ""], ["Gutierrez-Sanchez", "Ramon", ""]]}, {"id": "1506.07722", "submitter": "Romain Aza\\\"is", "authors": "Romain Aza\\\"is and Aur\\'elie Muller-Gueudin", "title": "Optimal choice among a class of nonparametric estimators of the jump\n  rate for piecewise-deterministic Markov processes", "comments": "36 pages, 18 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A piecewise-deterministic Markov process is a stochastic process whose\nbehavior is governed by an ordinary differential equation punctuated by random\njumps occurring at random times. We focus on the nonparametric estimation\nproblem of the jump rate for such a stochastic model observed within a long\ntime interval under an ergodicity condition. We introduce an uncountable class\n(indexed by the deterministic flow) of recursive kernel estimates of the jump\nrate and we establish their strong pointwise consistency as well as their\nasymptotic normality. We propose to choose among this class the estimator with\nthe minimal variance, which is unfortunately unknown and thus remains to be\nestimated. We also discuss the choice of the bandwidth parameters by\ncross-validation methods.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2015 12:24:56 GMT"}, {"version": "v2", "created": "Mon, 23 May 2016 18:58:44 GMT"}], "update_date": "2016-05-24", "authors_parsed": [["Aza\u00efs", "Romain", ""], ["Muller-Gueudin", "Aur\u00e9lie", ""]]}, {"id": "1506.07732", "submitter": "Marie Cottrell", "authors": "Nicolas Bourgeois (SAMM), Marie Cottrell (SAMM), Benjamin D\\'eruelle\n  (LAMOP), St\\'ephane Lamass\\'e (LAMOP), Patrick Letr\\'emy (SAMM)", "title": "How to improve robustness in Kohonen maps and display additional\n  information in Factorial Analysis: application to text mining", "comments": null, "journal-ref": "Neurocomputing, Elsevier, 2014, 147, pp.120-135", "doi": "10.1016/j.neucom.2013.12.057", "report-no": null, "categories": "math.ST cs.CL stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article is an extended version of a paper presented in the WSOM'2012\nconference [1]. We display a combination of factorial projections, SOM\nalgorithm and graph techniques applied to a text mining problem. The corpus\ncontains 8 medieval manuscripts which were used to teach arithmetic techniques\nto merchants. Among the techniques for Data Analysis, those used for\nLexicometry (such as Factorial Analysis) highlight the discrepancies between\nmanuscripts. The reason for this is that they focus on the deviation from the\nindependence between words and manuscripts. Still, we also want to discover and\ncharacterize the common vocabulary among the whole corpus. Using the properties\nof stochastic Kohonen maps, which define neighborhood between inputs in a\nnon-deterministic way, we highlight the words which seem to play a special role\nin the vocabulary. We call them fickle and use them to improve both Kohonen map\nrobustness and significance of FCA visualization. Finally we use graph\nalgorithmic to exploit this fickleness for classification of words.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2015 12:56:23 GMT"}], "update_date": "2015-06-26", "authors_parsed": [["Bourgeois", "Nicolas", "", "SAMM"], ["Cottrell", "Marie", "", "SAMM"], ["D\u00e9ruelle", "Benjamin", "", "LAMOP"], ["Lamass\u00e9", "St\u00e9phane", "", "LAMOP"], ["Letr\u00e9my", "Patrick", "", "SAMM"]]}, {"id": "1506.07974", "submitter": "Matthew Roughan", "authors": "Matthew Roughan and Jonathan Tuke and Eric Parsonage", "title": "Estimating the Parameters of the Waxman Random Graph", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Waxman random graph is a generalisation of the simple Erd\\H{o}s-R\\'enyi\nor Gilbert random graph. It is useful for modelling physical networks where the\nincreased cost of longer links means they are less likely to be built, and thus\nless numerous than shorter links. The model has been in continuous use for over\ntwo decades with many attempts to select parameters which match real networks.\nIn most the parameters have been arbitrarily selected, but there are a few\ncases where they have been calculated using a formal estimator. However, the\nperformance of the estimator was not evaluated in any of these cases. This\npaper presents both the first evaluation of formal estimators for the\nparameters of these graphs, and a new Maximum Likelihood Estimator with $O(n)$\ncomputational time complexity that requires only link lengths as input.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jun 2015 07:29:14 GMT"}, {"version": "v2", "created": "Mon, 29 Jun 2015 00:30:07 GMT"}], "update_date": "2015-06-30", "authors_parsed": [["Roughan", "Matthew", ""], ["Tuke", "Jonathan", ""], ["Parsonage", "Eric", ""]]}, {"id": "1506.08022", "submitter": "Alban Mbina Mbina", "authors": "Alban Mbina Mbina (URMI), Guy Martial Nkiet (URMI), Assi Nguessan\n  (LPP)", "title": "Variable selection in multiple regression with random design", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method for variable selection in multiple regression with random\npredictors. This method is based on a criterion that permits to reduce the\nvariable selection problem to a problem of estimating suitable permutation and\ndimensionality. Then, estimators for these parameters are proposed and the\nresulting method for selecting variables is shown to be consistent. A\nsimulation study that permits to gain understanding of the performances of the\nproposed approach and to compare it with an existing method is given.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jun 2015 10:39:31 GMT"}], "update_date": "2015-06-29", "authors_parsed": [["Mbina", "Alban Mbina", "", "URMI"], ["Nkiet", "Guy Martial", "", "URMI"], ["Nguessan", "Assi", "", "LPP"]]}, {"id": "1506.08047", "submitter": "Paul Ilhe", "authors": "Paul Ilhe (LTCI, LIST), Eric Moulines (LTCI), Fran\\c{c}ois Roueff\n  (LTCI), Antoine Souloumiac (LIST)", "title": "Nonparametric estimation of mark's distribution of an exponential\n  Shot-noise process", "comments": "Electronic Journal of Statistics, Institute of Mathematical\n  Statistics and Bernoulli Society, 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider a nonlinear inverse problem occurring in nuclear\nscience. Gamma rays randomly hit a semiconductor detector which produces an\nimpulse response of electric current. Because the sampling period of the\nmeasured current is larger than the mean inter arrival time of photons, the\nimpulse responses associated to different gamma rays can overlap: this\nphenomenon is known as pileup. In this work, it is assumed that the impulse\nresponse is an exponentially decaying function. We propose a novel method to\ninfer the distribution of gamma photon energies from the indirect measurements\nobtained from the detector. This technique is based on a formula linking the\ncharacteristic function of the photon density to a function involving the\ncharacteristic function and its derivative of the observations. We establish\nthat our estimator converges to the mark density in uniform norm at a\nlogarithmic rate. A limited Monte-Carlo experiment is provided to support our\nfindings.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jun 2015 12:57:35 GMT"}, {"version": "v2", "created": "Tue, 26 Jan 2016 13:15:21 GMT"}], "update_date": "2016-01-27", "authors_parsed": [["Ilhe", "Paul", "", "LTCI, LIST"], ["Moulines", "Eric", "", "LTCI"], ["Roueff", "Fran\u00e7ois", "", "LTCI"], ["Souloumiac", "Antoine", "", "LIST"]]}, {"id": "1506.08155", "submitter": "Chris Sherlock Dr.", "authors": "Chris Sherlock, Alexandre Thiery and Andrew Golightly", "title": "Efficiency of delayed-acceptance random walk Metropolis algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Delayed-acceptance Metropolis-Hastings and delayed-acceptance pseudo-marginal\nMetropolis-Hastings algorithms can be applied when it is computationally\nexpensive to calculate the true posterior or an unbiased stochastic\napproximation thereof, but a computationally cheap deterministic approximation\nis available. An initial accept-reject stage uses the cheap approximation for\ncomputing the Metropolis-Hastings ratio; proposals which are accepted at this\nstage are then subjected to a further accept-reject step which corrects for the\nerror in the approximation. Since the expensive posterior, or the approximation\nthereof, is only evaluated for proposals which are accepted at the first stage,\nthe cost of the algorithm is reduced and larger scalings may be used.\n  We focus on the random walk Metropolis (RWM) and consider the\ndelayed-acceptance RWM and the delayed-acceptance pseudo-marginal RWM. We\nprovide a framework for incorporating relatively general deterministic\napproximations into the theoretical analysis of high-dimensional targets.\nJustified by diffusion approximation arguments, we derive expressions for the\nlimiting efficiency and acceptance rates in high-dimensional settings. These\ntheoretical insights are finally leveraged to formulate practical guidelines\nfor the efficient tuning of the algorithms. The robustness of these guidelines\nand predicted properties are verified against simulation studies, all of which\nare strictly outside of the domain of validity of our limit results.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jun 2015 16:55:12 GMT"}, {"version": "v2", "created": "Wed, 3 Jul 2019 15:49:01 GMT"}, {"version": "v3", "created": "Tue, 23 Feb 2021 11:37:09 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Sherlock", "Chris", ""], ["Thiery", "Alexandre", ""], ["Golightly", "Andrew", ""]]}, {"id": "1506.08159", "submitter": "Sohail Bahmani", "authors": "Sohail Bahmani and Justin Romberg", "title": "Near-Optimal Estimation of Simultaneously Sparse and Low-Rank Matrices\n  from Nested Linear Measurements", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT math.IT math.OC stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider the problem of estimating simultaneously low-rank\nand row-wise sparse matrices from nested linear measurements where the linear\noperator consists of the product of a linear operator $\\mathcal{W}$ and a\nmatrix $\\mathbf{\\varPsi}$. Leveraging the nested structure of the measurement\noperator, we propose a computationally efficient two-stage algorithm for\nestimating the simultaneously structured target matrix. Assuming that\n$\\mathcal{W}$ is a restricted isometry for low-rank matrices and\n$\\mathbf{\\varPsi}$ is a restricted isometry for row-wise sparse matrices, we\nestablish an accuracy guarantee that holds uniformly for all sufficiently\nlow-rank and row-wise sparse matrices with high probability. Furthermore, using\nstandard tools from information theory, we establish a minimax lower bound for\nestimation of simultaneously low-rank and row-wise sparse matrices from linear\nmeasurements that need not be nested. The accuracy bounds established for the\nalgorithm, that also serve as a minimax upper bound, differ from the derived\nminimax lower bound merely by a polylogarithmic factor of the dimensions.\nTherefore, the proposed algorithm is nearly minimax optimal. We also discuss\nsome applications of the proposed observation model and evaluate our algorithm\nthrough numerical simulation.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jun 2015 17:07:01 GMT"}, {"version": "v2", "created": "Mon, 21 Mar 2016 12:40:24 GMT"}], "update_date": "2016-03-22", "authors_parsed": [["Bahmani", "Sohail", ""], ["Romberg", "Justin", ""]]}, {"id": "1506.08163", "submitter": "Yen-Huan  Li", "authors": "Yen-Huan Li and Ya-Ping Hsieh and Nissim Zerbib and Volkan Cevher", "title": "A Geometric View on Constrained M-Estimators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the estimation error of constrained M-estimators, and derive\nexplicit upper bounds on the expected estimation error determined by the\nGaussian width of the constraint set. Both of the cases where the true\nparameter is on the boundary of the constraint set (matched constraint), and\nwhere the true parameter is strictly in the constraint set (mismatched\nconstraint) are considered. For both cases, we derive novel universal\nestimation error bounds for regression in a generalized linear model with the\ncanonical link function. Our error bound for the mismatched constraint case is\nminimax optimal in terms of its dependence on the sample size, for Gaussian\nlinear regression by the Lasso.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jun 2015 17:16:12 GMT"}], "update_date": "2015-06-29", "authors_parsed": [["Li", "Yen-Huan", ""], ["Hsieh", "Ya-Ping", ""], ["Zerbib", "Nissim", ""], ["Cevher", "Volkan", ""]]}, {"id": "1506.08256", "submitter": "Daniel Cervone", "authors": "Daniel Cervone and Natesh S. Pillai", "title": "Gaussian Process Regression with Location Errors", "comments": "28 pages, 17 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate Gaussian process regression models where inputs\nare subject to measurement error. In spatial statistics, input measurement\nerrors occur when the geographical locations of observed data are not known\nexactly. Such sources of error are not special cases of \"nugget\" or microscale\nvariation, and require alternative methods for both interpolation and parameter\nestimation. Gaussian process models do not straightforwardly extend to\nincorporate input measurement error, and simply ignoring noise in the input\nspace can lead to poor performance for both prediction and parameter inference.\nWe review and extend existing theory on prediction and estimation in the\npresence of location errors, and show that ignoring location errors may lead to\nKriging that is not \"self-efficient\". We also introduce a Markov Chain Monte\nCarlo (MCMC) approach using the Hybrid Monte Carlo algorithm that obtains\noptimal (minimum MSE) predictions, and discuss situations that lead to\nmultimodality of the target distribution and/or poor chain mixing. Through\nsimulation study and analysis of global air temperature data, we show that\nappropriate methods for incorporating location measurement error are essential\nto valid inference in this regime.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jun 2015 04:24:10 GMT"}], "update_date": "2015-06-30", "authors_parsed": [["Cervone", "Daniel", ""], ["Pillai", "Natesh S.", ""]]}, {"id": "1506.08278", "submitter": "Francesco Bartolucci", "authors": "Francesco Bartolucci, Francesca Chiaromonte, Prabhani Kuruppumullage\n  Don, Bruce George Lindsay", "title": "Composite likelihood inference in a discrete latent variable model for\n  two-way \"clustering-by-segmentation\" problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a discrete latent variable model for two-way data arrays, which\nallows one to simultaneously produce clusters along one of the data dimensions\n(e.g. exchangeable observational units or features) and contiguous groups, or\nsegments, along the other (e.g. consecutively ordered times or locations). The\nmodel relies on a hidden Markov structure but, given its complexity, cannot be\nestimated by full maximum likelihood. We therefore introduce composite\nlikelihood methodology based on considering different subsets of the data. The\nproposed approach is illustrated by simulation, and with an application to\ngenomic data.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jun 2015 10:35:59 GMT"}], "update_date": "2016-10-31", "authors_parsed": [["Bartolucci", "Francesco", ""], ["Chiaromonte", "Francesca", ""], ["Don", "Prabhani Kuruppumullage", ""], ["Lindsay", "Bruce George", ""]]}, {"id": "1506.08450", "submitter": "Matthew Thorpe", "authors": "Matthew Thorpe and Adam M. Johansen", "title": "Pointwise Convergence in Probability of General Smoothing Splines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Establishing the convergence of splines can be cast as a variational problem\nwhich is amenable to a $\\Gamma$-convergence approach. We consider the case in\nwhich the regularization coefficient scales with the number of observations,\n$n$, as $\\lambda_n=n^{-p}$. Using standard theorems from the\n$\\Gamma$-convergence literature, we prove that the general spline model is\nconsistent in that estimators converge in a sense slightly weaker than weak\nconvergence in probability for $p\\leq \\frac{1}{2}$. Without further assumptions\nwe show this rate is sharp. This differs from rates for strong convergence\nusing Hilbert scales where one can often choose $p>\\frac{1}{2}$.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jun 2015 20:37:30 GMT"}, {"version": "v2", "created": "Sat, 11 Mar 2017 22:43:08 GMT"}], "update_date": "2017-03-14", "authors_parsed": [["Thorpe", "Matthew", ""], ["Johansen", "Adam M.", ""]]}, {"id": "1506.08504", "submitter": "Hock Peng Chan", "authors": "Hock Peng Chan", "title": "Optimal sequential detection in multi-stream data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a large number of detectors each generating a data stream. The task\nis to detect online, distribution changes in a small fraction of the data\nstreams. Previous approaches to this problem include the use of mixture\nlikelihood ratios and sum of CUSUMs. We provide here extensions and\nmodifications of these approaches that are optimal in detecting normal mean\nshifts. We show how the (optimal) detection delay depends on the fraction of\ndata streams undergoing distribution changes as the number of detectors goes to\ninfinity. There are three detection domains. In the first domain for moderately\nlarge fractions, immediate detection is possible. In the second domain for\nsmaller fractions, the detection delay grows logarithmically with the number of\ndetectors, with an asymptotic constant extending those in sparse normal mixture\ndetection. In the third domain for even smaller fractions, the detection delay\nlies in the framework of the classical detection delay formula of Lorden. We\nshow that the optimal detection delay is achieved by the sum of detectability\nscore transformations of either the partial scores or CUSUM scores of the data\nstreams.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2015 04:39:14 GMT"}, {"version": "v2", "created": "Tue, 19 Jan 2016 02:18:43 GMT"}], "update_date": "2016-01-20", "authors_parsed": [["Chan", "Hock Peng", ""]]}, {"id": "1506.08521", "submitter": "Yusuke Shimizu", "authors": "Yusuke Shimizu", "title": "Update estimation of diffusion parameter observed at high frequency", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an update estimation method for a diffusion parameter from\nhigh-frequency dependent data under a nuisance drift element. We ensure the\nasymptotic equivalence of the estimator to the corresponding quasi-MLE, which\nhas the asymptotic normality and the asymptotic efficiency. We give a\nsimulation example to illustrate the theory.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2015 06:58:27 GMT"}], "update_date": "2015-06-30", "authors_parsed": [["Shimizu", "Yusuke", ""]]}, {"id": "1506.08724", "submitter": "Pierre C. Bellec", "authors": "Pierre C. Bellec, Alexandre B. Tsybakov", "title": "Sharp oracle bounds for monotone and convex regression through\n  aggregation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive oracle inequalities for the problems of isotonic and convex\nregression using the combination of $Q$-aggregation procedure and sparsity\npattern aggregation. This improves upon the previous results including the\noracle inequalities for the constrained least squares estimator. One of the\nimprovements is that our oracle inequalities are sharp, i.e., with leading\nconstant 1. It allows us to obtain bounds for the minimax regret thus\naccounting for model misspecification, which was not possible based on the\nprevious results. Another improvement is that we obtain oracle inequalities\nboth with high probability and in expectation.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2015 16:38:34 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2015 22:18:23 GMT"}, {"version": "v3", "created": "Sat, 4 Jul 2015 16:54:33 GMT"}, {"version": "v4", "created": "Wed, 19 Aug 2015 10:27:56 GMT"}, {"version": "v5", "created": "Wed, 30 Sep 2015 13:46:26 GMT"}], "update_date": "2015-10-01", "authors_parsed": [["Bellec", "Pierre C.", ""], ["Tsybakov", "Alexandre B.", ""]]}, {"id": "1506.08826", "submitter": "Yen-Chi Chen", "authors": "Yen-Chi Chen, Christopher R. Genovese, Larry Wasserman", "title": "Statistical Inference using the Morse-Smale Complex", "comments": "45 pages, 13 figures. Accepted to Electronic Journal of Statistics", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Morse-Smale complex of a function $f$ decomposes the sample space into\ncells where $f$ is increasing or decreasing. When applied to nonparametric\ndensity estimation and regression, it provides a way to represent, visualize,\nand compare multivariate functions. In this paper, we present some statistical\nresults on estimating Morse-Smale complexes. This allows us to derive new\nresults for two existing methods: mode clustering and Morse-Smale regression.\nWe also develop two new methods based on the Morse-Smale complex: a\nvisualization technique for multivariate functions and a two-sample,\nmultivariate hypothesis test.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2015 20:00:40 GMT"}, {"version": "v2", "created": "Tue, 4 Apr 2017 02:18:58 GMT"}], "update_date": "2017-04-05", "authors_parsed": [["Chen", "Yen-Chi", ""], ["Genovese", "Christopher R.", ""], ["Wasserman", "Larry", ""]]}]