[{"id": "1911.00160", "submitter": "Yuta Koike", "authors": "Yuta Koike", "title": "Notes on the dimension dependence in high-dimensional central limit\n  theorems for hyperrectangles", "comments": "27 pages. Some mistakes in Sections 4.3-4.4 have been corrected. The\n  Statement of Theorem 2.1(b) and related results have slightly been\n  generalized", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $X_1,\\dots,X_n$ be independent centered random vectors in $\\mathbb{R}^d$.\nThis paper shows that, even when $d$ may grow with $n$, the probability\n$P(n^{-1/2}\\sum_{i=1}^nX_i\\in A)$ can be approximated by its Gaussian analog\nuniformly in hyperrectangles $A$ in $\\mathbb{R}^d$ as $n\\to\\infty$ under\nappropriate moment assumptions, as long as $(\\log d)^5/n\\to0$. This improves a\nresult of Chernozhukov, Chetverikov \\& Kato [\\textit{Ann. Probab.} \\textbf{45}\n(2017) 2309--2353] in terms of the dimension growth condition. When\n$n^{-1/2}\\sum_{i=1}^nX_i$ has a common factor across the components, this\ncondition can be further improved to $(\\log d)^3/n\\to0$. The corresponding\nbootstrap approximation results are also developed. These results serve as a\ntheoretical foundation of simultaneous inference for high-dimensional models.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 00:23:01 GMT"}, {"version": "v2", "created": "Mon, 23 Dec 2019 13:34:10 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Koike", "Yuta", ""]]}, {"id": "1911.00217", "submitter": "Jan Naudts", "authors": "Jan Naudts", "title": "Update of a conditional probability by minimal divergence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR physics.data-an quant-ph stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The present paper investigates the situation that two events which are\nbelieved to be independent become statistically dependent during a subsequent\nobservation or measurement. The situation is well-known in quantum statistics\nbut occurs in many other contexts as well. The optimal update is obtained by\nminimizing either the Hellinger distance or the quadratic Bregman divergence.\nThe results obtained by the two methods differ.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 06:12:15 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Naudts", "Jan", ""]]}, {"id": "1911.00469", "submitter": "Stefan B\\\"ohringer", "authors": "Stefan B\\\"ohringer and Dietmar Lohmann", "title": "Exact model comparisons in the plausibility framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.AP stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Plausibility is a formalization of exact tests for parametric models and\ngeneralizes procedures such as Fisher's exact test. The resulting tests are\nbased on cumulative probabilities of the probability density function and\nevaluate consistency with a parametric family while providing exact control of\nthe $\\alpha$ level for finite sample size. Model comparisons are inefficient in\nthis approach. We generalize plausibility by incorporating weighing which\nallows to perform model comparisons. We show that one weighing scheme is\nasymptotically equivalent to the likelihood ratio test (LRT) and has finite\nsample guarantees for the test size under the null hypothesis unlike the LRT.\nWe confirm theoretical properties in simulations that mimic the data set of our\ndata application. We apply the method to a retinoblastoma data set and\ndemonstrate a parent-of-origin effect. Weighted plausibility also has\napplications in high-dimensional data analysis and P-values for penalized\nregression models can be derived. We demonstrate superior performance as\ncompared to a data-splitting procedure in a simulation study. We apply weighted\nplausibility to a high-dimensional gene expression, case-control prostate\ncancer data set. We discuss the flexibility of the approach by relating\nweighted plausibility to targeted learning, the bootstrap, and sparsity\nselection.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 17:19:33 GMT"}, {"version": "v2", "created": "Mon, 12 Oct 2020 17:03:07 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["B\u00f6hringer", "Stefan", ""], ["Lohmann", "Dietmar", ""]]}, {"id": "1911.00493", "submitter": "Veit Elser", "authors": "Veit Elser", "title": "Learning Without Loss", "comments": "52 pages, 24 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore a new approach for training neural networks where all loss\nfunctions are replaced by hard constraints. The same approach is very\nsuccessful in phase retrieval, where signals are reconstructed from magnitude\nconstraints and general characteristics (sparsity, support, etc.). Instead of\ntaking gradient steps, the optimizer in the constraint based approach, called\nrelaxed-reflect-reflect (RRR), derives its steps from projections to local\nconstraints. In neural networks one such projection makes the minimal\nmodification to the inputs $x$, the associated weights $w$, and the\npre-activation value $y$ at each neuron, to satisfy the equation $x\\cdot w=y$.\nThese projections, along with a host of other local projections (constraining\npre- and post-activations, etc.) can be partitioned into two sets such that all\nthe projections in each set can be applied concurrently, across the network and\nacross all data in the training batch. This partitioning into two sets is\nanalogous to the situation in phase retrieval and the setting for which the\ngeneral purpose RRR optimizer was designed. Owing to the novelty of the method,\nthis paper also serves as a self-contained tutorial. Starting with a\nsingle-layer network that performs non-negative matrix factorization, and\nconcluding with a generative model comprising an autoencoder and classifier,\nall applications and their implementations by projections are described in\ncomplete detail. Although the new approach has the potential to extend the\nscope of neural networks (e.g. by defining activation not through functions but\nconstraint sets), most of the featured models are standard to allow comparison\nwith stochastic gradient descent.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 19:20:08 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Elser", "Veit", ""]]}, {"id": "1911.00538", "submitter": "Anderson Ye Zhang", "authors": "Matthias L\\\"offler, Anderson Y. Zhang, Harrison H. Zhou", "title": "Optimality of Spectral Clustering in the Gaussian Mixture Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG math.SP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spectral clustering is one of the most popular algorithms to group high\ndimensional data. It is easy to implement and computationally efficient.\nDespite its popularity and successful applications, its theoretical properties\nhave not been fully understood. In this paper, we show that spectral clustering\nis minimax optimal in the Gaussian Mixture Model with isotropic covariance\nmatrix, when the number of clusters is fixed and the signal-to-noise ratio is\nlarge enough. Spectral gap conditions are widely assumed in the literature to\nanalyze spectral clustering. On the contrary, these conditions are not needed\nto establish optimality of spectral clustering in this paper.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 18:24:36 GMT"}, {"version": "v2", "created": "Wed, 5 Aug 2020 21:20:55 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["L\u00f6ffler", "Matthias", ""], ["Zhang", "Anderson Y.", ""], ["Zhou", "Harrison H.", ""]]}, {"id": "1911.00730", "submitter": "Tengyuan Liang", "authors": "Tengyuan Liang", "title": "Estimating Certain Integral Probability Metric (IPM) is as Hard as\n  Estimating under the IPM", "comments": "15 pages. arXiv admin note: substantial text overlap with\n  arXiv:1908.10324", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the minimax optimal rates for estimating a range of Integral\nProbability Metrics (IPMs) between two unknown probability measures, based on\n$n$ independent samples from them. Curiously, we show that estimating the IPM\nitself between probability measures, is not significantly easier than\nestimating the probability measures under the IPM. We prove that the minimax\noptimal rates for these two problems are multiplicatively equivalent, up to a\n$\\log \\log (n)/\\log (n)$ factor.\n", "versions": [{"version": "v1", "created": "Sat, 2 Nov 2019 15:12:10 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Liang", "Tengyuan", ""]]}, {"id": "1911.00770", "submitter": "Daniel Oberski", "authors": "Daniel L. Oberski", "title": "Rank-deficiencies in a reduced information latent variable model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Latent variable models are well-known to suffer from rank deficiencies,\ncausing problems with convergence and stability. Such problems are compounded\nin the \"reduced-group split-ballot multitrait-multimethod model\", which omits a\nset of moments from the estimation through a planned missing data design. This\npaper demonstrates the existence of rank deficiencies in this model and give\nthe explicit null space. It also demonstrates that sample size and distance\nfrom the rank-deficient point interact in their effects on convergence, causing\nconvergence to improve or worsen depending on both factors simultaneously.\nFurthermore, it notes that the latent variable correlations in the uncorrelated\nmethods SB-MTMM model remain unaffected by the rank deficiency. I conclude that\nmethodological experiments should be careful to manipulate both distance to\nknown rank-deficiencies and sample size, and report all results, not only the\napparently converged ones. Practitioners may consider that, even in the\npresence of nonconvergence or so-called \"inadmissible\" estimates, a subset of\nparameter estimates may still be consistent and stable.\n", "versions": [{"version": "v1", "created": "Sat, 2 Nov 2019 19:15:55 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Oberski", "Daniel L.", ""]]}, {"id": "1911.00794", "submitter": "Kouakou Francois Domagni", "authors": "Francois K Domagni, A. S. Hedayat, Bikas Kumar Sinha", "title": "On The Study Of D-Optimal Saturated Designs For Mean, Main Effects and\n  $F_1$-Two-Factor Interactions For $2^k$-Factorial Experiments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of this paper is to develop methods for the construction of\nsaturated designs that include the mean, main effects and the two-factor\ninteractions of one factor with a subset of the remaining factors. If one\nfactor is interacting with all the remaining factors give a method for the\nconstruction of a d-optimal saturated design. If one factor is interacting with\na proper subset of the remaining factor we discuss the saturated d-optimal\ndesign for specific cases.\n", "versions": [{"version": "v1", "created": "Sat, 2 Nov 2019 22:30:01 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Domagni", "Francois K", ""], ["Hedayat", "A. S.", ""], ["Sinha", "Bikas Kumar", ""]]}, {"id": "1911.00813", "submitter": "Cheng-Der Fuh", "authors": "Cheng-Der Fuh and Chu-Lan Kao", "title": "Reply to on some problems in the article \"Efficient likelihood\n  estimation in state space models\" by Cheng-Der Fuh [Ann, Statist. 34 (2006)\n  2026-2068]", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This note replies Dr. Jensen (2010) comments on Problem 2.3, which was left\nin Fuh (2010). In the following, we use the same notations and definitions in\nFuh (2006) unless specified.\n", "versions": [{"version": "v1", "created": "Sun, 3 Nov 2019 03:09:22 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Fuh", "Cheng-Der", ""], ["Kao", "Chu-Lan", ""]]}, {"id": "1911.00915", "submitter": "Saptarshi Chakraborty", "authors": "Saptarshi Chakraborty, Suman K. Bhattacharya and Kshitij Khare", "title": "Estimating accuracy of the MCMC variance estimator: a central limit\n  theorem for batch means estimators", "comments": "28 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The batch means estimator of the MCMC variance is a simple and effective\nmeasure of accuracy for MCMC based ergodic averages. Under various regularity\nconditions, the estimator has been shown to be consistent for the true\nvariance. However, the estimator can be unstable in practice as it depends\ndirectly on the raw MCMC output. A measure of accuracy of the batch means\nestimator itself, ideally in the form of a confidence interval, is therefore\ndesirable. The asymptotic variance of the batch means estimator is known;\nhowever, without any knowledge of asymptotic distribution, asymptotic variances\nare in general insufficient to describe variability. In this article we prove a\ncentral limit theorem for the batch means estimator that allows for the\nconstruction of asymptotically accurate confidence intervals for the batch\nmeans estimator. Additionally, our results provide a Markov chain analogue of\nthe classical CLT for the sample variance parameter for i.i.d. observations.\nOur result assumes standard regularity conditions similar to the ones assumed\nin the literature for proving consistency. Simulated and real data examples are\nincluded as illustrations and applications of the CLT.\n", "versions": [{"version": "v1", "created": "Sun, 3 Nov 2019 15:51:44 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Chakraborty", "Saptarshi", ""], ["Bhattacharya", "Suman K.", ""], ["Khare", "Kshitij", ""]]}, {"id": "1911.00989", "submitter": "Kengne William", "authors": "Mamadou Lamine Diop and William Kengne", "title": "Piecewise autoregression for general integer-valued time series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a piecewise autoregression for general integer-valued\ntime series. The conditional mean of the process depends on a parameter which\nis piecewise constant over time. We derive an inference procedure based on a\npenalized contrast that is constructed from the Poisson quasi-maximum\nlikelihood of the model. The consistency of the proposed estimator is\nestablished. From practical applications, we derive a data-driven procedure\nbased on the slope heuristic to calibrate the penalty term of the contrast; and\nthe implementation is carried out through the dynamic programming algorithm,\nwhich leads to a procedure of $\\mathcal{O}(n^2)$ time complexity. Some\nsimulation results are provided, as well as the applications to the US\nrecession data and the number of trades in the stock of Technofirst.\n", "versions": [{"version": "v1", "created": "Sun, 3 Nov 2019 23:23:19 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Diop", "Mamadou Lamine", ""], ["Kengne", "William", ""]]}, {"id": "1911.01018", "submitter": "Chao Gao", "authors": "Chao Gao and Anderson Y. Zhang", "title": "Iterative Algorithm for Discrete Structure Recovery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.CO stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a general modeling and algorithmic framework for discrete\nstructure recovery that can be applied to a wide range of problems. Under this\nframework, we are able to study the recovery of clustering labels, ranks of\nplayers, signs of regression coefficients, cyclic shifts, and even group\nelements from a unified perspective. A simple iterative algorithm is proposed\nfor discrete structure recovery, which generalizes methods including Lloyd's\nalgorithm and the power method. A linear convergence result for the proposed\nalgorithm is established in this paper under appropriate abstract conditions on\nstochastic errors and initialization. We illustrate our general theory by\napplying it on several representative problems: (1) clustering in Gaussian\nmixture model, (2) approximate ranking, (3) sign recovery in compressed\nsensing, (4) multireference alignment, and (5) group synchronization, and show\nthat minimax rate is achieved in each case.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 03:11:10 GMT"}, {"version": "v2", "created": "Sun, 27 Sep 2020 05:49:35 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Gao", "Chao", ""], ["Zhang", "Anderson Y.", ""]]}, {"id": "1911.01040", "submitter": "Adel Javanmard", "authors": "Yash Deshpande, Adel Javanmard, Mohammad Mehrabi", "title": "Online Debiasing for Adaptively Collected High-dimensional Data with\n  Applications to Time Series Analysis", "comments": "66 pages, 2 tables, 11 figures; updated with minor fixes and\n  reorganization", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adaptive collection of data is commonplace in applications throughout science\nand engineering. From the point of view of statistical inference however,\nadaptive data collection induces memory and correlation in the samples, and\nposes significant challenge. We consider the high-dimensional linear\nregression, where the samples are collected adaptively, and the sample size $n$\ncan be smaller than $p$, the number of covariates. In this setting, there are\ntwo distinct sources of bias: the first due to regularization imposed for\nconsistent estimation, e.g. using the LASSO, and the second due to adaptivity\nin collecting the samples. We propose \"online debiasing\", a general procedure\nfor estimators such as the LASSO, which addresses both sources of bias. In two\nconcrete contexts $(i)$ time series analysis and $(ii)$ batched data\ncollection, we demonstrate that online debiasing optimally debiases the LASSO\nestimate when the underlying parameter $\\theta_0$ has sparsity of order\n$o(\\sqrt{n}/\\log p)$. In this regime, the debiased estimator can be used to\ncompute $p$-values and confidence intervals of optimal size.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 06:03:58 GMT"}, {"version": "v2", "created": "Wed, 18 Dec 2019 17:41:44 GMT"}, {"version": "v3", "created": "Tue, 5 May 2020 19:39:33 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Deshpande", "Yash", ""], ["Javanmard", "Adel", ""], ["Mehrabi", "Mohammad", ""]]}, {"id": "1911.01065", "submitter": "Marko Voutilainen", "authors": "Marko Voutilainen", "title": "Modeling and estimation of multivariate discrete and continuous time\n  stationary processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we give a AR$(1)$ type of characterization covering all\nmultivariate strictly stationary processes indexed by the set of integers.\nConsequently, we derive continuous time algebraic Riccati equations for the\nparameter matrix of the characterization providing us with a natural way to\ndefine the corresponding estimator under the assumption of square\nintegrability. In addition, we show that the estimator inherits consistency\nfrom autocovariances of the stationary process and furthermore, the limiting\ndistribution is given by a linear function of the limiting distribution of the\nautocovariances. We also present the corresponding existing results of the\ncontinuous time setting paralleling them to the discrete case.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 07:47:26 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Voutilainen", "Marko", ""]]}, {"id": "1911.01483", "submitter": "Yi Zhu", "authors": "Yi Zhu, Jing Dong", "title": "On Constructing Confidence Region for Model Parameters in Stochastic\n  Gradient Descent via Batch Means", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study a simple algorithm to construct asymptotically valid\nconfidence regions for model parameters using the batch means method. The main\nidea is to cancel out the covariance matrix which is hard/costly to estimate.\nIn the process of developing the algorithm, we establish process-level\nfunctional central limit theorem for Polyak-Ruppert averaging based stochastic\ngradient descent estimators. We also extend the batch means method to\naccommodate more general batch size specifications.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 20:48:30 GMT"}, {"version": "v2", "created": "Fri, 31 Jan 2020 15:13:19 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Zhu", "Yi", ""], ["Dong", "Jing", ""]]}, {"id": "1911.01525", "submitter": "Wei Han", "authors": "Wei Han, Yun Yang", "title": "Statistical Inference in Mean-Field Variational Bayes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.AP stat.CO stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We conduct non-asymptotic analysis on the mean-field variational inference\nfor approximating posterior distributions in complex Bayesian models that may\ninvolve latent variables. We show that the mean-field approximation to the\nposterior can be well-approximated relative to the Kullback-Leibler divergence\ndiscrepancy measure by a normal distribution whose center is the maximum\nlikelihood estimator (MLE). In particular, our results imply that the center of\nthe mean-field approximation matches the MLE up to higher-order terms and there\nis essentially no loss of efficiency in using it as a point estimator for the\nparameter in any regular parametric model with latent variables. We also\npropose a new class of variational weighted likelihood bootstrap (VWLB) methods\nfor quantifying the uncertainty in the mean-field variational inference. The\nproposed VWLB can be viewed as a new sampling scheme that produces independent\nsamples for approximating the posterior. Comparing with traditional sampling\nalgorithms such Markov Chain Monte Carlo, VWLB can be implemented in parallel\nand is free of tuning.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 23:08:49 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Han", "Wei", ""], ["Yang", "Yun", ""]]}, {"id": "1911.01544", "submitter": "Andrea Montanari", "authors": "Andrea Montanari and Feng Ruan and Youngtak Sohn and Jun Yan", "title": "The generalization error of max-margin linear classifiers:\n  High-dimensional asymptotics in the overparametrized regime", "comments": "73 pages; 12 pdf figures (Added formulas for wide asymptotics, and\n  distribution of the coordinates of the estimator)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern machine learning models are often so complex that they achieve\nvanishing classification error on the training set. Max-margin linear\nclassifiers are among the simplest classification methods that have zero\ntraining error (with linearly separable data). Despite their simplicity, their\nhigh-dimensional behavior is not yet completely understood. We assume to be\ngiven i.i.d. data $(y_i,{\\boldsymbol x}_i)$, $i\\le n$ with ${\\boldsymbol\nx}_i\\sim {\\sf N}(0,{\\boldsymbol \\Sigma})$ a $p$-dimensional feature vector, and\n$y_i \\in\\{+1,-1\\}$ a label whose distribution depends on a linear combination\nof the covariates $\\langle{\\boldsymbol\\theta}_*,{\\boldsymbol x}_i\\rangle$. We\nconsider the proportional asymptotics $n,p\\to\\infty$ with $p/n\\to \\psi$, and\nderive exact expressions for the limiting prediction error. Our asymptotic\nresults match simulations already when $n,p$ are of the order of a few\nhundreds.\n  We explore several choices for $({\\boldsymbol \\theta}_*,{\\boldsymbol\n\\Sigma})$, and show that the resulting generalization curve (test error error\nas a function of the overparametrization $\\psi=p/n$) is qualitatively\ndifferent, depending on this choice. In particular we consider a specific\nstructure of $({\\boldsymbol \\theta}_*,{\\boldsymbol\\Sigma})$ that captures the\nbehavior of nonlinear random feature models or, equivalently, two-layers neural\nnetworks with random first layer weights. In this case, we aim at classifying\ndata $(y_i,{\\boldsymbol x}_i)$ with ${\\boldsymbol x}_i\\in{\\mathbb R}^d$ but we\ndo so by first embedding them a $p$ dimensional feature space via ${\\boldsymbol\nx}_i\\mapsto\\sigma({\\boldsymbol W}{\\boldsymbol x}_i)$ and then finding a\nmax-margin classifier in this space. We derive exact formulas in the\nproportional asymptotics $p,n,d\\to\\infty$ with $p/d\\to\\psi_1$, $n/d\\to\\psi_2$\nand observe that the test error is minimized in the highly overparametrized\nregime $\\psi_1\\gg 0$.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 00:15:27 GMT"}, {"version": "v2", "created": "Fri, 17 Jul 2020 20:29:50 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Montanari", "Andrea", ""], ["Ruan", "Feng", ""], ["Sohn", "Youngtak", ""], ["Yan", "Jun", ""]]}, {"id": "1911.01583", "submitter": "Guanhua Fang", "authors": "Haochen Xu and Guanhua Fang and Zhiliang Ying", "title": "A Latent Topic Model with Markovian Transition for Process Data", "comments": "42 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.AP stat.TH", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We propose a latent topic model with a Markovian transition for process data,\nwhich consist of time-stamped events recorded in a log file. Such data are\nbecoming more widely available in computer-based educational assessment with\ncomplex problem solving items. The proposed model can be viewed as an extension\nof the hierarchical Bayesian topic model with a hidden Markov structure to\naccommodate the underlying evolution of an examinee's latent state. Using topic\ntransition probabilities along with response times enables us to capture\nexaminees' learning trajectories, making clustering/classification more\nefficient. A forward-backward variational expectation-maximization (FB-VEM)\nalgorithm is developed to tackle the challenging computational problem. Useful\ntheoretical properties are established under certain asymptotic regimes. The\nproposed method is applied to a complex problem solving item in 2012 Programme\nfor International Student Assessment (PISA 2012).\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 02:59:17 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Xu", "Haochen", ""], ["Fang", "Guanhua", ""], ["Ying", "Zhiliang", ""]]}, {"id": "1911.01596", "submitter": "Jos\\'e A. D\\'iaz-Garc\\'ia", "authors": "Jos\\'e A. D\\'iaz-Garc\\'ia and Francisco J. Caro-Lopera", "title": "Some comments about measures, Jacobians and Moore-Penrose inverse", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Some general problems of Jacobian computations in non-full rank matrices are\ndiscussed in this work. In particular, the Jacobian of the Moore-Penrose\ninverse derived via matrix differential calculus is revisited. Then the\nJacobian in the full rank case is derived under the simple and old theory of\nthe exterior product.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 03:35:14 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["D\u00edaz-Garc\u00eda", "Jos\u00e9 A.", ""], ["Caro-Lopera", "Francisco J.", ""]]}, {"id": "1911.01694", "submitter": "Nader Bshouty", "authors": "Nader H. Bshouty and George Haddad and Catherine A. Haddad-Zaknoon", "title": "Bounds for the Number of Tests in Non-Adaptive Randomized Algorithms for\n  Group Testing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the group testing problem with non-adaptive randomized algorithms.\nSeveral models have been discussed in the literature to determine how to\nrandomly choose the tests. For a model ${\\cal M}$, let $m_{\\cal M}(n,d)$ be the\nminimum number of tests required to detect at most $d$ defectives within $n$\nitems, with success probability at least $1-\\delta$, for some constant\n$\\delta$. In this paper, we study the measures $$c_{\\cal M}(d)=\\lim_{n\\to\n\\infty} \\frac{m_{\\cal M}(n,d)}{\\ln n} \\mbox{ and } c_{\\cal M}=\\lim_{d\\to\n\\infty} \\frac{c_{\\cal M}(d)}{d}.$$\n  In the literature, the analyses of such models only give upper bounds for\n$c_{\\cal M}(d)$ and $c_{\\cal M}$, and for some of them, the bounds are not\ntight. We give new analyses that yield tight bounds for $c_{\\cal M}(d)$ and\n$c_{\\cal M}$ for all the known models~${\\cal M}$.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 10:09:28 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Bshouty", "Nader H.", ""], ["Haddad", "George", ""], ["Haddad-Zaknoon", "Catherine A.", ""]]}, {"id": "1911.01716", "submitter": "Chao Zheng", "authors": "Chao Zheng, Idris A. Eckley and Paul Fearnhead", "title": "Consistency of a range of penalised cost approaches for detecting\n  multiple changepoints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common approach to detect multiple changepoints is to minimise a measure of\ndata fit plus a penalty that is linear in the number of changepoints. This\npaper shows that the general finite sample behaviour of such a method can be\nrelated to its behaviour when analysing data with either none or one\nchangepoint. This results in simpler conditions for verifying whether the\nmethod will consistently estimate the number and locations of the changepoints.\nWe apply and demonstrate the usefulness of this result for a range of\nchangepoint problems. Our new results include a weaker condition on the choice\nof penalty required to have consistency in a change-in-slope model; and the\nfirst results for the accuracy of recently-proposed methods for detecting\nspikes.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 11:22:07 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Zheng", "Chao", ""], ["Eckley", "Idris A.", ""], ["Fearnhead", "Paul", ""]]}, {"id": "1911.01876", "submitter": "Giovanni Pistone", "authors": "Giovanni Pistone", "title": "Information Geometry of the Probability Simplex: A Short Course", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This set of notes is intended for a short course aiming to provide an\n(almost) self-contained and (almost) elementary introduction to the topic of\nInformation Geometry (IG) of the probability simplex. Such a course can be\nconsidered an introduction to the original monograph by Amari and Nagaoka\n(2000), and to the recent monographs by Amari (2016} and by Ay et al. (2017).\nThe focus is on a non-parametric approach, that is, I consider the geometry of\nthe full probability simplex and compare the IG formalism with what is\nclassically done in Statistical Physics.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 15:31:08 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Pistone", "Giovanni", ""]]}, {"id": "1911.01979", "submitter": "Paavo Sattler", "authors": "Paavo Sattler", "title": "Manifold Asymptotics of Quadratic-Form-Based Inference in Repeated\n  Measures Designs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Split-Plot or Repeated Measures Designs with multiple groups occur naturally\nin sciences. Their analysis is usually based on the classical Repeated Measures\nANOVA. Roughly speaking, the latter can be shown to be asymptotically valid for\nlarge sample sizes $n_i$ assuming a fixed number of groups $a$ and time points\n$d$. However, for high-dimensional settings with $d>n_i$ this argument breaks\ndown and statistical tests are often based on (standardized) quadratic forms.\nFurthermore analysis of their limit behaviour is usually based on certain\nassumptions on how $d$ converges to $\\infty$ with respect to $n_i$. As this may\nbe hard to argue in practice, we do not want to make such restrictions.\nMoreover, sometimes also the number of groups $a$ may be large compared to $d$\nor $n_i$. To also have an impression about the behaviour of (standardized)\nquadratic forms as test statistic, we analyze their asymptotics under diverse\nsettings on $a$, $d$ and $n_i$. In fact, we combine all kind of combinations,\nwhere they diverge or are bounded in a unified framework. Studying the limit\ndistributions in detail, we follow Sattler and Pauly (2018) and propose an\napproximation to obtain critical values. The resulting test together with their\napproximation approach are investigated in an extensive simulation study with a\nfocus on the exceptional asymptotic frameworks which are the main focus of this\nwork.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 18:13:26 GMT"}, {"version": "v2", "created": "Mon, 9 Mar 2020 19:40:55 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Sattler", "Paavo", ""]]}, {"id": "1911.01985", "submitter": "Do Tran", "authors": "Do Tran", "title": "Behavior of Fr\\'echet mean and Central Limit Theorems on spheres", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We compute higher derivatives of the Fr\\'{e}chet function on spheres with an\nabsolutely continuous and rotationally symmetric probability distribution.\nConsequences include (i)~a practical condition to test if the mode of the\nsymmetric distribution is a local Fr\\'{e}chet mean; (ii)~a Central Limit\nTheorem on spheres with practical assumptions and an explicit limiting\ndistribution; and (iii)~an answer to the question of whether the smeary effect\ncan occur on spheres with absolutely continuous and rotationally symmetric\ndistributions: with the method presented here, it can in dimension at\nleast~$4$.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 18:25:15 GMT"}, {"version": "v2", "created": "Sat, 25 Apr 2020 00:06:47 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Tran", "Do", ""]]}, {"id": "1911.02010", "submitter": "Ping Li", "authors": "Fan Zhou and Ping Li", "title": "A Fourier Analytical Approach to Estimation of Smooth Functions in\n  Gaussian Shift Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT math.IT stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $\\mathbf{x}_j = \\mathbf{\\theta} + \\mathbf{\\epsilon}_j$, $j=1,\\dots,n$ be\ni.i.d. copies of a Gaussian random vector\n$\\mathbf{x}\\sim\\mathcal{N}(\\mathbf{\\theta},\\mathbf{\\Sigma})$ with unknown mean\n$\\mathbf{\\theta} \\in \\mathbb{R}^d$ and unknown covariance matrix\n$\\mathbf{\\Sigma}\\in \\mathbb{R}^{d\\times d}$. The goal of this article is to\nstudy the estimation of $f(\\mathbf{\\theta})$ where $f$ is a given smooth\nfunction of which smoothness is characterized by a Besov-type norm. The problem\nof interest resides in the high dimensional regime where the intrinsic\ndimension can grow with the sample size $n$. Inspired by the classical work of\nA. N. Kolmogorov on unbiased estimation and Littlewood-Paley theory, we develop\na new estimator based on a Fourier analytical approach that achieves effective\nbias reduction. Asymptotic normality and efficiency are proved when the\nsmoothness index of $f$ is above certain threshold which was discovered\nrecently by Koltchinskii et. al. (2018) for a H\\\"{o}lder type class. Numerical\nsimulations are presented to validate our analysis. The simplicity of\nimplementation and its superiority over the plug-in approach indicate the new\nestimator can be applied to a broad range of real world applications.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 03:16:24 GMT"}, {"version": "v2", "created": "Tue, 22 Dec 2020 05:50:56 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Zhou", "Fan", ""], ["Li", "Ping", ""]]}, {"id": "1911.02029", "submitter": "Yifan Cui", "authors": "Yifan Cui and Eric Tchetgen Tchetgen", "title": "Selective machine learning of doubly robust functionals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While model selection is a well-studied topic in parametric and nonparametric\nregression or density estimation, selection of possibly high-dimensional\nnuisance parameters in semiparametric problems is far less developed. In this\npaper, we propose a selective machine learning framework for making inferences\nabout a finite-dimensional functional defined on a semiparametric model, when\nthe latter admits a doubly robust estimating function and several candidate\nmachine learning algorithms are available for estimating the nuisance\nparameters. We introduce two new selection criteria for bias reduction in\nestimating the functional of interest, each based on a novel definition of\npseudo-risk for the functional that embodies the double robustness property and\nthus is used to select the pair of learners that is nearest to fulfilling this\nproperty. We establish an oracle property for a multi-fold cross-validation\nversion of the new selection criteria which states that our empirical criteria\nperform nearly as well as an oracle with a priori knowledge of the pseudo-risk\nfor each pair of candidate learners. We also describe a smooth approximation to\nthe selection criteria which allows for valid post-selection inference.\nFinally, we apply the approach to model selection of a semiparametric estimator\nof average treatment effect given an ensemble of candidate machine learners to\naccount for confounding in an observational study.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 19:00:03 GMT"}, {"version": "v2", "created": "Wed, 29 Apr 2020 03:35:30 GMT"}, {"version": "v3", "created": "Wed, 29 Jul 2020 17:49:49 GMT"}, {"version": "v4", "created": "Mon, 3 Aug 2020 18:43:09 GMT"}, {"version": "v5", "created": "Mon, 12 Apr 2021 17:10:30 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Cui", "Yifan", ""], ["Tchetgen", "Eric Tchetgen", ""]]}, {"id": "1911.02160", "submitter": "Akihiko Nishimura", "authors": "Akihiko Nishimura and Marc A. Suchard", "title": "Shrinkage with shrunken shoulders: inference via geometrically /\n  uniformly ergodic Gibbs sampler", "comments": "23 pages, 8 figures, (18 pages, 3 figures of Supplement). Code\n  available from https://github.com/aki-nishimura/bayes-bridge", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Use of continuous shrinkage priors -- with a \"spike\" near zero and\nheavy-tails towards infinity -- is an increasingly popular approach to induce\nsparsity in parameter estimates. When the parameters are only weakly identified\nby the likelihood, however, the posterior may end up with tails as heavy as the\nprior, jeopardizing robustness of inference. A natural solution is to \"shrink\nthe shoulders\" of a shrinkage prior by lightening up its tails beyond a\nreasonable parameter range, yielding the regularized version of the prior. We\ndevelop a regularization approach which, unlike previous proposals, preserves\ncomputationally attractive structures of original shrinkage priors. We study\ntheoretical properties of the Gibbs sampler on resulting posterior\ndistributions, with emphasis on convergence rates of the P{\\'o}lya-Gamma Gibbs\nsampler for sparse logistic regression. Our analysis shows that the proposed\nregularization leads to geometric ergodicity under a broad range of\nglobal-local shrinkage priors. Essentially, the only requirement is for the\nprior $\\pi_{\\rm local}$ on the local scale $\\lambda$ to satisfy $\\pi_{\\rm\nlocal}(0) < \\infty$. If $\\pi_{\\rm local}(\\cdot)$ further satisfies\n$\\lim_{\\lambda \\to 0} \\pi_{\\rm local}(\\lambda) / \\lambda^a < \\infty$ for $a >\n0$, as in the case of Bayesian bridge priors, we show the sampler to be\nuniformly ergodic.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 01:44:07 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 22:46:11 GMT"}, {"version": "v3", "created": "Tue, 14 Jul 2020 20:52:37 GMT"}, {"version": "v4", "created": "Mon, 25 Jan 2021 16:20:38 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Nishimura", "Akihiko", ""], ["Suchard", "Marc A.", ""]]}, {"id": "1911.02171", "submitter": "Xin Xing", "authors": "Xin Xing, Zuofeng Shang, Pang Du, Ping Ma, Wenxuan Zhong and Jun S.\n  Liu", "title": "Minimax Nonparametric Two-sample Test under Smoothing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.AP stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of comparing probability densities between two\ngroups. A new probabilistic tensor product smoothing spline framework is\ndeveloped to model the joint density of two variables. Under such a framework,\nthe probability density comparison is equivalent to testing the\npresence/absence of interactions. We propose a penalized likelihood ratio test\nfor such interaction testing and show that the test statistic is asymptotically\nchi-square distributed under the null hypothesis. Furthermore, we derive a\nsharp minimax testing rate based on the Bernstein width for nonparametric\ntwo-sample tests and show that our proposed test statistics is minimax optimal.\nIn addition, a data-adaptive tuning criterion is developed to choose the\npenalty parameter. Simulations and real applications demonstrate that the\nproposed test outperforms the conventional approaches under various scenarios.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 02:40:35 GMT"}, {"version": "v2", "created": "Fri, 8 Nov 2019 23:05:21 GMT"}, {"version": "v3", "created": "Sun, 5 Jan 2020 19:57:41 GMT"}, {"version": "v4", "created": "Mon, 11 Jan 2021 19:34:53 GMT"}], "update_date": "2021-01-13", "authors_parsed": [["Xing", "Xin", ""], ["Shang", "Zuofeng", ""], ["Du", "Pang", ""], ["Ma", "Ping", ""], ["Zhong", "Wenxuan", ""], ["Liu", "Jun S.", ""]]}, {"id": "1911.02192", "submitter": "Hang Li", "authors": "Hang Li, Enrique Del Castillo", "title": "Optimal Design of Experiments on Riemannian Manifolds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The theory of optimal design of experiments has been traditionally developed\non an Euclidean space. In this paper, new theoretical results and an algorithm\nfor finding the optimal design of an experiment located on a Riemannian\nmanifold are provided. It is shown that analogously to the results in Euclidean\nspaces, D-optimal and G-optimal designs are equivalent on manifolds, and we\nprovide a lower bound for the maximum prediction variance of the response\nevaluated over the manifold. In addition, a converging algorithm that finds the\noptimal experimental design on manifold data is proposed. Numerical experiments\ndemonstrate the importance of considering the manifold structure in a designed\nexperiment when present, and the superiority of the proposed algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 04:06:59 GMT"}, {"version": "v2", "created": "Fri, 5 Feb 2021 19:14:59 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Li", "Hang", ""], ["Del Castillo", "Enrique", ""]]}, {"id": "1911.02205", "submitter": "Richard Chen", "authors": "Richard Y. Chen", "title": "The Fourier Transform Method for Volatility Functional Inference by\n  Asynchronous Observations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST q-fin.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the volatility functional inference by Fourier transforms. This\nspectral framework is advantageous in that it harnesses the power of harmonic\nanalysis to handle missing data and asynchronous observations without any\nartificial time alignment nor data imputation. Under conditions, this spectral\napproach is consistent and we provide limit distributions using irregular and\nasynchronous observations. When observations are synchronous, the Fourier\ntransform method for volatility functionals attains both the optimal\nconvergence rate and the efficient bound in the sense of Le Cam and H\\'ajek.\nAnother finding is asynchronicity or missing data as a form of noise produces\n\"interference\" in the spectrum estimation and impacts on the convergence rate\nof volatility functional estimators. This new methodology extends previous\napplications of volatility functionals, including principal component analysis,\ngeneralized method of moments, continuous-time linear regression models et\ncetera, to high-frequency datasets of which asynchronicity is a prevailing\nfeature.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 05:14:53 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Chen", "Richard Y.", ""]]}, {"id": "1911.02389", "submitter": "Philippe Berthet", "authors": "Philippe Berthet and Jean-Claude Fort", "title": "Weak convergence of empirical Wasserstein type distances", "comments": "Submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We estimate contrasts $\\int_0 ^1 \\rho(F^{-1}(u)-G^{-1}(u))du$ between two\ncontinuous distributions $F$ and $G$ on $\\mathbb R$ such that the set $\\{F=G\\}$\nis a finite union of intervals, possibly empty or $\\mathbb{R}$. The\nnon-negative convex cost function $\\rho$ is not necessarily symmetric and the\nsample may come from any joint distribution $H$ on $\\mathbb{R}^2$ with\nmarginals $F$ and $G$ having light enough tails with respect to $\\rho$. The\nrates of weak convergence and the limiting distributions are derived in a wide\nclass of situations including the classical Wasserstein distances $W_1$ and\n$W_2$. The new phenomenon we describe in the case $F=G$ involves the behavior\nof $\\rho$ near $0$, which we assume to be regularly varying with index ranging\nfrom $1$ to $2$ and to satisfy a key relation with the behavior of $\\rho$ near\n$\\infty$ through the common tails. Rates are then also regularly varying with\npowers ranging from $1/2$ to $1$ also affecting the limiting distribution, in\naddition to $H$.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 13:53:37 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Berthet", "Philippe", ""], ["Fort", "Jean-Claude", ""]]}, {"id": "1911.02488", "submitter": "Florian Simatos", "authors": "Pierre Derennes and Jerome Morio and Florian Simatos", "title": "Simultaneous estimation of complementary moment independent sensitivity\n  measures for reliability analysis", "comments": "New version with a comparison to ROSA Sobol indices", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In reliability-based design, the estimation of the failure probability is a\ncrucial objective. However, focusing only on the occurrence of the failure\nevent may be insufficient to entirely characterize the reliability of the\nconsidered system. This paper provides a common estimation scheme of two\ncomplementary moment independent sensitivity measures, allowing to improve the\nunderstanding of the system's reliability. Numerical applications are performed\nin order to show the effectiveness of the proposed estimation procedure.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 16:56:16 GMT"}, {"version": "v2", "created": "Wed, 7 Oct 2020 10:27:54 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Derennes", "Pierre", ""], ["Morio", "Jerome", ""], ["Simatos", "Florian", ""]]}, {"id": "1911.02915", "submitter": "Bruno Scalzo Dees", "authors": "Bruno Scalzo Dees, Anh-Huy Phan, Danilo P. Mandic", "title": "A Statistically Identifiable Model for Tensor-Valued Gaussian Random\n  Variables", "comments": "13 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-world signals typically span across multiple dimensions, that is, they\nnaturally reside on multi-way data structures referred to as tensors. In\ncontrast to standard ``flat-view'' multivariate matrix models which are\nagnostic to data structure and only describe linear pairwise relationships, we\nintroduce the tensor-valued Gaussian distribution which caters for multilinear\ninteractions -- the linear relationship between fibers -- which is reflected by\nthe Kronecker separable structure of the mean and covariance. By virtue of the\nstatistical identifiability of the proposed distribution formulation, whereby\ndifferent parameter values strictly generate different probability\ndistributions, it is shown that the corresponding likelihood function can be\nmaximised analytically to yield the maximum likelihood estimator. For rigour,\nthe statistical consistency of the estimator is also demonstrated through\nnumerical simulations. The probabilistic framework is then generalised to\ndescribe the joint distribution of multiple tensor-valued random variables,\nwhereby the associated mean and covariance exhibit a Khatri-Rao separable\nstructure. The proposed models are shown to serve as a natural basis for\ngridded atmospheric climate modelling.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 14:09:29 GMT"}, {"version": "v2", "created": "Tue, 12 Nov 2019 18:04:29 GMT"}, {"version": "v3", "created": "Thu, 14 Nov 2019 18:47:32 GMT"}, {"version": "v4", "created": "Sun, 17 Nov 2019 12:28:44 GMT"}, {"version": "v5", "created": "Tue, 3 Dec 2019 16:17:33 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Dees", "Bruno Scalzo", ""], ["Phan", "Anh-Huy", ""], ["Mandic", "Danilo P.", ""]]}, {"id": "1911.03043", "submitter": "Holden Lee", "authors": "Rong Ge, Holden Lee, Jianfeng Lu", "title": "Estimating Normalizing Constants for Log-Concave Distributions:\n  Algorithms and Lower Bounds", "comments": "46 pages", "journal-ref": "Proceedings of the 52nd Annual ACM SIGACT Symposium on Theory of\n  Computing. 2020. p. 579-586", "doi": null, "report-no": null, "categories": "cs.DS cs.LG math.PR math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating the normalizing constant of an unnormalized probability\ndistribution has important applications in computer science, statistical\nphysics, machine learning, and statistics. In this work, we consider the\nproblem of estimating the normalizing constant $Z=\\int_{\\mathbb{R}^d}\ne^{-f(x)}\\,\\mathrm{d}x$ to within a multiplication factor of $1 \\pm\n\\varepsilon$ for a $\\mu$-strongly convex and $L$-smooth function $f$, given\nquery access to $f(x)$ and $\\nabla f(x)$. We give both algorithms and\nlowerbounds for this problem. Using an annealing algorithm combined with a\nmultilevel Monte Carlo method based on underdamped Langevin dynamics, we show\nthat $\\widetilde{\\mathcal{O}}\\Bigl(\\frac{d^{4/3}\\kappa +\nd^{7/6}\\kappa^{7/6}}{\\varepsilon^2}\\Bigr)$ queries to $\\nabla f$ are\nsufficient, where $\\kappa= L / \\mu$ is the condition number. Moreover, we\nprovide an information theoretic lowerbound, showing that at least\n$\\frac{d^{1-o(1)}}{\\varepsilon^{2-o(1)}}$ queries are necessary. This provides\na first nontrivial lowerbound for the problem.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 04:32:11 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2020 19:22:32 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Ge", "Rong", ""], ["Lee", "Holden", ""], ["Lu", "Jianfeng", ""]]}, {"id": "1911.03071", "submitter": "Fredrik S\\\"avje", "authors": "Christopher Harshaw and Fredrik S\\\"avje and Daniel Spielman and Peng\n  Zhang", "title": "Balancing covariates in randomized experiments with the Gram-Schmidt\n  Walk design", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.DS math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The design of experiments involves a compromise between covariate balance and\nrobustness. This paper introduces an experimental design that admits precise\ncontrol over this trade-off. The design is specified by a parameter that bounds\nthe worst-case mean square error of an estimator of the average treatment\neffect. Subject to the experimenter's desired level of robustness, the design\naims to simultaneously balance all linear functions of the covariates. The\nachieved level of balance is considerably better than what a fully random\nassignment would produce, and it is close to optimal given the desired level of\nrobustness. We show that the mean square error of the estimator is bounded by\nthe minimum of the loss function of a ridge regression of the potential\noutcomes on the covariates. One may thus interpret the approach as regression\nadjustment by design. Finally, we provide non-asymptotic tail bounds for the\nestimator, which facilitate the construction of conservative confidence\nintervals.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 06:09:36 GMT"}, {"version": "v2", "created": "Mon, 4 May 2020 21:10:43 GMT"}, {"version": "v3", "created": "Wed, 24 Feb 2021 02:32:30 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Harshaw", "Christopher", ""], ["S\u00e4vje", "Fredrik", ""], ["Spielman", "Daniel", ""], ["Zhang", "Peng", ""]]}, {"id": "1911.03105", "submitter": "Yi Hao", "authors": "Yi Hao, Alon Orlitsky", "title": "Unified Sample-Optimal Property Estimation in Near-Linear Time", "comments": "Appeared at NeurIPS 2019. Fixed a few typos and minor issues in\n  corner cases", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the fundamental learning problem of estimating properties of\ndistributions over large domains. Using a novel piecewise-polynomial\napproximation technique, we derive the first unified methodology for\nconstructing sample- and time-efficient estimators for all sufficiently smooth,\nsymmetric and non-symmetric, additive properties. This technique yields\nnear-linear-time computable estimators whose approximation values are\nasymptotically optimal and highly-concentrated, resulting in the first: 1)\nestimators achieving the $\\mathcal{O}(k/(\\varepsilon^2\\log k))$ min-max\n$\\varepsilon$-error sample complexity for all $k$-symbol Lipschitz properties;\n2) unified near-optimal differentially private estimators for a variety of\nproperties; 3) unified estimator achieving optimal bias and near-optimal\nvariance for five important properties; 4) near-optimal sample-complexity\nestimators for several important symmetric properties over both domain sizes\nand confidence levels. In addition, we establish a McDiarmid's inequality under\nPoisson sampling, which is of independent interest.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 07:46:47 GMT"}, {"version": "v2", "created": "Tue, 17 Mar 2020 17:43:02 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Hao", "Yi", ""], ["Orlitsky", "Alon", ""]]}, {"id": "1911.03467", "submitter": "Toma\\v{z} Ko\\v{s}ir", "authors": "Damjana Kokol Bukov\\v{s}ek, Toma\\v{z} Ko\\v{s}ir, Bla\\v{z}\n  Moj\\v{s}kerc, Matja\\v{z} Omladi\\v{c}", "title": "Relation between Blomqvist's beta and other measures of concordance of\n  copulas", "comments": "13 pages, 4 figures. arXiv admin note: substantial text overlap with\n  arXiv:1909.06648", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST q-fin.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An investigation is presented of how a comprehensive choice of four most\nimportant measures of concordance (namely Spearman's rho, Kendall's tau,\nSpearman's footrule, and Gini's gamma) relate to the fifth one, i.e., the\nBlomqvist's beta. In order to work out these results we present a novel method\nof estimating the values of the four measures of concordance on a family of\ncopulas with fixed value of beta. These results are primarily aimed at the\ncommunity of practitioners trying to find the right copula to be employed on\ntheir data. However, the proposed method as such may be of independent interest\nfrom theoretical point of view.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 14:10:42 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Bukov\u0161ek", "Damjana Kokol", ""], ["Ko\u0161ir", "Toma\u017e", ""], ["Moj\u0161kerc", "Bla\u017e", ""], ["Omladi\u010d", "Matja\u017e", ""]]}, {"id": "1911.03539", "submitter": "Soroosh Shafieezadeh-Abadeh", "authors": "Viet Anh Nguyen and Soroosh Shafieezadeh-Abadeh and Daniel Kuhn and\n  Peyman Mohajerin Esfahani", "title": "Bridging Bayesian and Minimax Mean Square Error Estimation via\n  Wasserstein Distributionally Robust Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a distributionally robust minimium mean square error estimation\nmodel with a Wasserstein ambiguity set to recover an unknown signal from a\nnoisy observation. The proposed model can be viewed as a zero-sum game between\na statistician choosing an estimator -- that is, a measurable function of the\nobservation -- and a fictitious adversary choosing a prior -- that is, a pair\nof signal and noise distributions ranging over independent Wasserstein balls --\nwith the goal to minimize and maximize the expected squared estimation error,\nrespectively. We show that if the Wasserstein balls are centered at normal\ndistributions, then the zero-sum game admits a Nash equilibrium, where the\nplayers' optimal strategies are given by an {\\em affine} estimator and a {\\em\nnormal} prior, respectively. We further prove that this Nash equilibrium can be\ncomputed by solving a tractable convex program. Finally, we develop a\nFrank-Wolfe algorithm that can solve this convex program orders of magnitude\nfaster than state-of-the-art general purpose solvers. We show that this\nalgorithm enjoys a linear convergence rate and that its direction-finding\nsubproblems can be solved in quasi-closed form.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 21:10:25 GMT"}, {"version": "v2", "created": "Wed, 27 Jan 2021 10:00:16 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Nguyen", "Viet Anh", ""], ["Shafieezadeh-Abadeh", "Soroosh", ""], ["Kuhn", "Daniel", ""], ["Esfahani", "Peyman Mohajerin", ""]]}, {"id": "1911.03553", "submitter": "Keyu Nie", "authors": "Keyu Nie, Yinfei Kong, Ted Tao Yuan, Pauline Berry Burke", "title": "Dealing With Ratio Metrics in A/B Testing at the Presence of Intra-User\n  Correlation and Segments", "comments": "A/B Testing, repeated measures, uniformly minimum-variance unbiased\n  estimator, stratification, sensitivity, variance reduction", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study ratio metrics in A/B testing at the presence of correlation among\nobservations coming from the same user and provides practical guidance\nespecially when two metrics contradict each other. We propose new estimating\nmethods to quantitatively measure the intra-user correlation (within segments).\nWith the accurately estimated correlation, a uniformly minimum-variance\nunbiased estimator of the population mean, called correlation-adjusted mean, is\nproposed to account for such correlation structure. It is proved theoretically\nand numerically better than the other two unbiased estimators, naive mean and\nnormalized mean (averaging within users first and then across users). The\ncorrelation-adjusted mean method is unbiased and has reduced variance so it\ngains additional power. Several simulation studies are designed to show the\nestimation accuracy of the correlation structure, effectiveness in reducing\nvariance, and capability of obtaining more power. An application to the eBay\ndata is conducted to conclude this paper.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 21:40:42 GMT"}, {"version": "v2", "created": "Thu, 23 Jul 2020 00:59:02 GMT"}], "update_date": "2020-07-24", "authors_parsed": [["Nie", "Keyu", ""], ["Kong", "Yinfei", ""], ["Yuan", "Ted Tao", ""], ["Burke", "Pauline Berry", ""]]}, {"id": "1911.03568", "submitter": "Sharif Rahman", "authors": "Sharif Rahman", "title": "A Spline Chaos Expansion", "comments": "28 pages, one table, seven figures; accepted by SIAM/ASA Journal on\n  Uncertainty Quantification", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A spline chaos expansion, referred to as SCE, is introduced for uncertainty\nquantification analysis. The expansion provides a means for representing an\noutput random variable of interest with respect to multivariate orthonormal\nbasis splines (B-splines) in input random variables. The multivariate B-splines\nare built from a whitening transformation to generate univariate orthonormal\nB-splines in each coordinate direction, followed by a tensor-product structure\nto produce the multivariate version. SCE, as it stems from compactly supported\nB-splines, tackles locally prominent responses more effectively than the\npolynomial chaos expansion (PCE). The approximation quality of the expansion is\ndemonstrated in terms of the modulus of smoothness of the output function,\nleading to the mean-square convergence of SCE to the correct limit. Analytical\nformulae are proposed to calculate the mean and variance of an SCE\napproximation for a general output variable in terms of the requisite expansion\ncoefficients. Numerical results indicate that a low-order SCE approximation\nwith an adequate mesh is markedly more accurate than a high-order PCE\napproximation in estimating the output variances and probability distributions\nof oscillatory, nonsmooth, and nearly discontinuous functions.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 22:42:12 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Rahman", "Sharif", ""]]}, {"id": "1911.03577", "submitter": "Gabriel Peyr\\'e", "authors": "Clarice Poon and Gabriel Peyr\\'e", "title": "Degrees of freedom for off-the-grid sparse estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A central question in modern machine learning and imaging sciences is to\nquantify the number of effective parameters of vastly over-parameterized\nmodels. The degrees of freedom is a mathematically convenient way to define\nthis number of parameters. Its computation and properties are well understood\nwhen dealing with discretized linear models, possibly regularized using\nsparsity. In this paper, we argue that this way of thinking is plagued when\ndealing with models having very large parameter spaces. In this case it makes\nmore sense to consider \"off-the-grid\" approaches, using a continuous parameter\nspace. This type of approach is the one favoured when training multi-layer\nperceptrons, and is also becoming popular to solve super-resolution problems in\nimaging. Training these off-the-grid models with a sparsity inducing prior can\nbe achieved by solving a convex optimization problem over the space of\nmeasures, which is often called the Beurling Lasso (Blasso), and is the\ncontinuous counterpart of the celebrated Lasso parameter selection method. In\nprevious works, the degrees of freedom for the Lasso was shown to coincide with\nthe size of the smallest solution support. Our main contribution is a proof of\na continuous counterpart to this result for the Blasso. Our findings suggest\nthat discretized methods actually vastly over-estimate the number of intrinsic\ncontinuous degrees of freedom. Our second contribution is a detailed study of\nthe case of sampling Fourier coefficients in 1D, which corresponds to a\nsuper-resolution problem. We show that our formula for the degrees of freedom\nis valid outside of a set of measure zero of observations, which in turn\njustifies its use to compute an unbiased estimator of the prediction risk using\nthe Stein Unbiased Risk Estimator (SURE).\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 23:29:52 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Poon", "Clarice", ""], ["Peyr\u00e9", "Gabriel", ""]]}, {"id": "1911.03685", "submitter": "Linda Altieri", "authors": "Linda Altieri, Daniela Cocchi and Giulia Roli", "title": "Estimation of entropy measures for categorical variables with spatial\n  correlation", "comments": "7 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entropy is a measure of heterogeneity widely used in applied sciences, often\nwhen data are collected over space. Recently, a number of approaches has been\nproposed to include spatial information in entropy. The aim of entropy is to\nsynthesize the observed data in a single, interpretable number. In other\nstudies the objective is, instead, to use data for entropy estimation; several\nproposals can be found in the literature, which basically are corrections of\nthe estimator based on substituting the involved probabilities with\nproportions. In this case, independence is assumed and spatial correlation is\nnot considered. We propose a path for spatial entropy estimation: instead of\ncorrecting the global entropy estimator, we focus on improving the estimation\nof its components, i.e. the probabilities, in order to account for spatial\neffects. Once probabilities are suitably evaluated, estimating entropy is\nstraightforward since it is a deterministic function of the distribution.\nFollowing a Bayesian approach, we derive the posterior probabilities of a\nmultinomial distribution for categorical variables, accounting for spatial\ncorrelation. A posterior distribution for entropy can be obtained, which may be\nsynthesized as wished and displayed as an entropy surface for the area under\nstudy.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 13:16:22 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Altieri", "Linda", ""], ["Cocchi", "Daniela", ""], ["Roli", "Giulia", ""]]}, {"id": "1911.03725", "submitter": "Waheed Bajwa", "authors": "Talal Ahmed, Haroon Raja, and Waheed U. Bajwa", "title": "Tensor Regression Using Low-rank and Sparse Tucker Decompositions", "comments": "28 pages, 5 figures, 2 tables; preprint of a journal paper published\n  in SIAM Journal on Mathematics of Data Science", "journal-ref": "SIAM J. Math. Data Science, vol. 2, no. 4, pp. 944-966, 2020", "doi": "10.1137/19M1299335", "report-no": null, "categories": "cs.LG eess.SP math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies a tensor-structured linear regression model with a scalar\nresponse variable and tensor-structured predictors, such that the regression\nparameters form a tensor of order $d$ (i.e., a $d$-fold multiway array) in\n$\\mathbb{R}^{n_1 \\times n_2 \\times \\cdots \\times n_d}$. It focuses on the task\nof estimating the regression tensor from $m$ realizations of the response\nvariable and the predictors where $m\\ll n = \\prod \\nolimits_{i} n_i$. Despite\nthe seeming ill-posedness of this problem, it can still be solved if the\nparameter tensor belongs to the space of sparse, low Tucker-rank tensors.\nAccordingly, the estimation procedure is posed as a non-convex optimization\nprogram over the space of sparse, low Tucker-rank tensors, and a tensor variant\nof projected gradient descent is proposed to solve the resulting non-convex\nproblem. In addition, mathematical guarantees are provided that establish the\nproposed method linearly converges to an appropriate solution under a certain\nset of conditions. Further, an upper bound on sample complexity of tensor\nparameter estimation for the model under consideration is characterized for the\nspecial case when the individual (scalar) predictors independently draw values\nfrom a sub-Gaussian distribution. The sample complexity bound is shown to have\na polylogarithmic dependence on $\\bar{n} = \\max \\big\\{n_i: i\\in \\{1,2,\\ldots,d\n\\} \\big\\}$ and, orderwise, it matches the bound one can obtain from a heuristic\nparameter counting argument. Finally, numerical experiments demonstrate the\nefficacy of the proposed tensor model and estimation method on a synthetic\ndataset and a collection of neuroimaging datasets pertaining to attention\ndeficit hyperactivity disorder. Specifically, the proposed method exhibits\nbetter sample complexities on both synthetic and real datasets, demonstrating\nthe usefulness of the model and the method in settings where $n \\gg m$.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 16:00:38 GMT"}, {"version": "v2", "created": "Tue, 21 Jul 2020 03:44:59 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Ahmed", "Talal", ""], ["Raja", "Haroon", ""], ["Bajwa", "Waheed U.", ""]]}, {"id": "1911.03744", "submitter": "Alex Dytso", "authors": "Alex Dytso and H. Vincent Poor", "title": "Estimation in Poisson Noise: Properties of the Conditional Mean\n  Estimator", "comments": "Updated version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT eess.SP math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers estimation of a random variable in Poisson noise with\nsignal scaling coefficient and dark current as explicit parameters of the noise\nmodel. Specifically, the paper focuses on properties of the conditional mean\nestimator as a function of the scaling coefficient, the dark current parameter,\nthe distribution of the input random variable and channel realizations. With\nrespect to the scaling coefficient and the dark current, several identities in\nterms of derivatives are established. For example, it is shown that the\ngradient of the conditional mean estimator with respect to the scaling\ncoefficient and dark current parameter is proportional to the conditional\nvariance. Moreover, a score function is proposed and a Tweedie-like formula for\nthe conditional expectation is recovered. With respect to the distribution,\nseveral regularity conditions are shown. For instance, it is shown that the\nconditional mean estimator uniquely determines the input distribution.\nMoreover, it is shown that if the conditional expectation is close to a linear\nfunction in terms of mean squared error, then the input distribution is\napproximately gamma in the L\\'evy distance. Furthermore, sufficient and\nnecessary conditions for linearity are found. Interestingly, it is shown that\nthe conditional mean estimator cannot be linear when the dark current parameter\nof the Poisson noise is non-zero.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 17:59:10 GMT"}, {"version": "v2", "created": "Tue, 31 Mar 2020 15:06:56 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Dytso", "Alex", ""], ["Poor", "H. Vincent", ""]]}, {"id": "1911.03783", "submitter": "Li Chen", "authors": "Li Chen, Jie Zhou, Lizhen Lin", "title": "Hypothesis testing for populations of networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has become an increasingly common practice for scientists in modern\nscience and engineering to collect samples of multiple network data in which a\nnetwork serves as a basic data object. The increasing prevalence of multiple\nnetwork data calls for developments of models and theory that can deal with\ninference problems for populations of networks. In this work, we propose a\ngeneral procedure for hypothesis testing of networks and in particular, for\ndifferentiating distributions of two samples of networks. We consider a very\ngeneral framework which allows us to perform tests on large and sparse\nnetworks. Our contribution is two-fold: (1) We propose a test statistics based\non the singular value of a generalized Wigner matrix. The asymptotic null\ndistribution of the statistics is shown to follow the Tracy--Widom distribution\nas the number of nodes tends to infinity. The test also yields asymptotic power\nguarantee with the power tending to one under the alternative; (2) The test\nprocedure is adapted for change-point detection in dynamic networks which is\nproven to be consistent in detecting the change-points. In addition to\ntheoretical guarantees, another appealing feature of this adapted procedure is\nthat it provides a principled and simple method for selecting the threshold\nthat is also allowed to vary with time. Extensive simulation studies and real\ndata analyses demonstrate the superior performance of our procedure with\ncompetitors.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 21:47:02 GMT"}, {"version": "v2", "created": "Fri, 3 Jul 2020 16:11:06 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Chen", "Li", ""], ["Zhou", "Jie", ""], ["Lin", "Lizhen", ""]]}, {"id": "1911.03804", "submitter": "Anru Zhang", "authors": "Anru Zhang, Yuetian Luo, Garvesh Raskutti, Ming Yuan", "title": "ISLET: Fast and Optimal Low-rank Tensor Regression via Importance\n  Sketching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NA math.NA math.ST stat.ME stat.TH", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In this paper, we develop a novel procedure for low-rank tensor regression,\nnamely \\emph{\\underline{I}mportance \\underline{S}ketching \\underline{L}ow-rank\n\\underline{E}stimation for \\underline{T}ensors} (ISLET). The central idea\nbehind ISLET is \\emph{importance sketching}, i.e., carefully designed sketches\nbased on both the responses and low-dimensional structure of the parameter of\ninterest. We show that the proposed method is sharply minimax optimal in terms\nof the mean-squared error under low-rank Tucker assumptions and under\nrandomized Gaussian ensemble design. In addition, if a tensor is low-rank with\ngroup sparsity, our procedure also achieves minimax optimality. Further, we\nshow through numerical study that ISLET achieves comparable or better\nmean-squared error performance to existing state-of-the-art methods while\nhaving substantial storage and run-time advantages including capabilities for\nparallel and distributed computing. In particular, our procedure performs\nreliable estimation with tensors of dimension $p = O(10^8)$ and is $1$ or $2$\norders of magnitude faster than baseline methods.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 23:36:13 GMT"}, {"version": "v2", "created": "Fri, 8 May 2020 05:36:30 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Zhang", "Anru", ""], ["Luo", "Yuetian", ""], ["Raskutti", "Garvesh", ""], ["Yuan", "Ming", ""]]}, {"id": "1911.03982", "submitter": "Ricardo Maronna", "authors": "Ricardo A. Maronna and Victor J. Yohai", "title": "Optimal robust estimators for families of distributions on the integers", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let F_{{\\theta}} be a family of distributions with support on the set of\nnonnegative integers Z_0. In this paper we derive the M-estimators with\nsmallest gross error sensitivity (GES). We start by defining the uniform median\nof a distribution F with support on Z_0 (umed(F)) as the median of x+u, where x\nand u are independent variables with distributions F and uniform in [-0.5,0.5]\nrespectively. Under some general conditions we prove that the estimator with\nsmallest GES satisfies umed(F_{n})=umed(F_{{\\theta}}), where F_{n} is the\nempirical distribution. The asymptotic distribution of these estimators is\nfound. This distribution is normal except when there is a positive integer k so\nthat F_{{\\theta}}(k)=0.5. In this last case, the asymptotic distribution\nbehaves as normal at each side of 0, but with different variances. A simulation\nMonte Carlo study compares, for the Poisson distribution, the efficiency and\nrobustness for finite sample sizes of this estimator with those of other robust\nestimators.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 19:13:40 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Maronna", "Ricardo A.", ""], ["Yohai", "Victor J.", ""]]}, {"id": "1911.04056", "submitter": "Quefeng Li", "authors": "Quefeng Li and Lexin Li", "title": "Integrative Factor Regression and Its Inference for Multimodal Data\n  Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multimodal data, where different types of data are collected from the same\nsubjects, are fast emerging in a large variety of scientific applications.\nFactor analysis is commonly used in integrative analysis of multimodal data,\nand is particularly useful to overcome the curse of high dimensionality and\nhigh correlations. However, there is little work on statistical inference for\nfactor analysis based supervised modeling of multimodal data. In this article,\nwe consider an integrative linear regression model that is built upon the\nlatent factors extracted from multimodal data. We address three important\nquestions: how to infer the significance of one data modality given the other\nmodalities in the model; how to infer the significance of a combination of\nvariables from one modality or across different modalities; and how to quantify\nthe contribution, measured by the goodness-of-fit, of one data modality given\nthe others. When answering each question, we explicitly characterize both the\nbenefit and the extra cost of factor analysis. Those questions, to our\nknowledge, have not yet been addressed despite wide use of factor analysis in\nintegrative multimodal analysis, and our proposal bridges an important gap. We\nstudy the empirical performance of our methods through simulations, and further\nillustrate with a multimodal neuroimaging analysis.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 03:24:47 GMT"}, {"version": "v2", "created": "Tue, 30 Mar 2021 02:45:51 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Li", "Quefeng", ""], ["Li", "Lexin", ""]]}, {"id": "1911.04151", "submitter": "Zhigang Bao", "authors": "Zhigang Bao, Yukun He", "title": "On Cram\\'{e}r-von Mises statistic for the spectral distribution of\n  random matrices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math-ph math.MP math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $F_N$ and $F$ be the empirical and limiting spectral distributions of an\n$N\\times N$ Wigner matrix. The Cram\\'{e}r-von Mises (CvM) statistic is a\nclassical goodness-of-fit statistic that characterizes the distance between\n$F_N$ and $F$ in $\\ell^2$-norm. In this paper, we consider a mesoscopic\napproximation of the CvM statistic for Wigner matrices, and derive its limiting\ndistribution. In the appendix, we also give the limiting distribution of the\nCvM statistic (without approximation) for the toy model CUE.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 09:27:03 GMT"}, {"version": "v2", "created": "Tue, 3 Dec 2019 10:30:22 GMT"}, {"version": "v3", "created": "Sat, 25 Jul 2020 02:36:52 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Bao", "Zhigang", ""], ["He", "Yukun", ""]]}, {"id": "1911.04212", "submitter": "Yasin Asar", "authors": "Yasin Asar and R. Arabi Belaghi", "title": "Estimation in Weibull Distribution Under Progressively Type-I Hybrid\n  Censored Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we consider the estimation of unknown parameters of Weibull\ndistribution when the lifetime data are observed in the presence of\nprogressively type-I hybrid censoring scheme. The Newton-Raphson algorithm,\nExpectation-Maximization (EM) algorithm and Stochastic EM (SEM) algorithm are\nutilized to derive the maximum likelihood estimates (MLEs) for the unknown\nparameters. Moreover, Bayesian estimators using Tierney-Kadane Method and\nMarkov Chain Monte Carlo (MCMC) method are obtained under three different loss\nfunctions, namely, squared error loss (SEL), linear-exponential (LINEX) and\ngeneralized entropy loss (GEL) functions. Also, the shrinkage pre-test\nestimators are derived. An extensive Monte Carlo simulation experiment is\nconducted under different schemes so that the performances of the listed\nestimators are compared using mean squared error, confidence interval length\nand coverage probabilities. Asymptotic normality and MCMC samples are used to\nobtain the confidence intervals and highest posterior density (HPD) intervals\nrespectively. Further, a real data example is presented to illustrate the\nmethods. Finally, some conclusive remarks are presented.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 12:32:38 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Asar", "Yasin", ""], ["Belaghi", "R. Arabi", ""]]}, {"id": "1911.04337", "submitter": "Samuel I. Berchuck", "authors": "Samuel I. Berchuck, Mark Janko, Felipe A. Medeiros, William Pan, Sayan\n  Mukherjee", "title": "Bayesian Non-Parametric Factor Analysis for Longitudinal Spatial\n  Surfaces", "comments": "This is a preprint of an article submitted for publication in the\n  Journal of the American Statistical Association. The article contains 35\n  pages, 5 figures and 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a Bayesian non-parametric spatial factor analysis model with\nspatial dependency induced through a prior on factor loadings. For each column\nof the loadings matrix, spatial dependency is encoded using a probit\nstick-breaking process (PSBP) and a multiplicative gamma process shrinkage\nprior is used across columns to adaptively determine the number of latent\nfactors. By encoding spatial information into the loadings matrix, meaningful\nfactors are learned that respect the observed neighborhood dependencies, making\nthem useful for assessing rates over space. Furthermore, the spatial PSBP prior\ncan be used for clustering temporal trends, allowing users to identify regions\nwithin the spatial domain with similar temporal trajectories, an important task\nin many applied settings. In the manuscript, we illustrate the model's\nperformance in simulated data, but also in two real-world examples:\nlongitudinal monitoring of glaucoma and malaria surveillance across the\nPeruvian Amazon. The R package spBFA, available on CRAN, implements the method.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 15:29:40 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Berchuck", "Samuel I.", ""], ["Janko", "Mark", ""], ["Medeiros", "Felipe A.", ""], ["Pan", "William", ""], ["Mukherjee", "Sayan", ""]]}, {"id": "1911.04341", "submitter": "Mathias M{\\o}rck Ljungdahl", "authors": "Mathias M{\\o}rck Ljungdahl and Mark Podolskij", "title": "A Minimal Contrast Estimator for the Linear Fractional Stable Motion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present an estimator for the three-dimensional parameter\n$(\\sigma, \\alpha, H)$ of the linear fractional stable motion, where $H$\nrepresents the self-similarity parameter, and $(\\sigma, \\alpha)$ are the\nscaling and stability parameters of the driving symmetric L\\'evy process $L$.\nOur approach is based upon a minimal contrast method associated with the\nempirical characteristic function combined with a ratio type estimator for the\nselfsimilarity parameter $H$. The main result investigates the strong\nconsistency and weak limit theorems for the resulting estimator. Furthermore,\nwe propose several ideas to obtain feasible confidence regions in various\nparameter settings. Our work is mainly related to [16, 18], in which parameter\nestimation for the linear fractional stable motion and related L\\'evy moving\naverage processes has been studied.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 15:58:43 GMT"}, {"version": "v2", "created": "Wed, 25 Mar 2020 08:34:23 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Ljungdahl", "Mathias M\u00f8rck", ""], ["Podolskij", "Mark", ""]]}, {"id": "1911.04377", "submitter": "Attila Lovas", "authors": "Attila Lovas and Mikl\\'os R\\'asonyi", "title": "Markov chains in random environment with applications in queueing theory\n  and machine learning", "comments": "34 pages, 3rd version, we extended the applicability of our theorems\n  to autoregressive processes in random environments", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST physics.data-an stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove the existence of limiting distributions for a large class of Markov\nchains on a general state space in a random environment. We assume suitable\nversions of the standard drift and minorization conditions. In particular, the\nsystem dynamics should be contractive on the average with respect to the\nLyapunov function and large enough small sets should exist with large enough\nminorization constants. We also establish that a law of large numbers holds for\nbounded functionals of the process. Applications to queuing systems, to machine\nlearning algorithms and to autoregressive processes are presented.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 16:39:58 GMT"}, {"version": "v2", "created": "Wed, 18 Dec 2019 17:26:47 GMT"}, {"version": "v3", "created": "Thu, 3 Dec 2020 12:35:38 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Lovas", "Attila", ""], ["R\u00e1sonyi", "Mikl\u00f3s", ""]]}, {"id": "1911.04436", "submitter": "Changxiao Cai", "authors": "Changxiao Cai, Gen Li, H. Vincent Poor, Yuxin Chen", "title": "Nonconvex Low-Rank Tensor Completion from Noisy Data", "comments": "Accepted to Operations Research", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT math.OC math.ST stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study a noisy tensor completion problem of broad practical interest,\nnamely, the reconstruction of a low-rank tensor from highly incomplete and\nrandomly corrupted observations of its entries. While a variety of prior work\nhas been dedicated to this problem, prior algorithms either are computationally\ntoo expensive for large-scale applications, or come with sub-optimal\nstatistical guarantees. Focusing on \"incoherent\" and well-conditioned tensors\nof a constant CP rank, we propose a two-stage nonconvex algorithm -- (vanilla)\ngradient descent following a rough initialization -- that achieves the best of\nboth worlds. Specifically, the proposed nonconvex algorithm faithfully\ncompletes the tensor and retrieves all individual tensor factors within nearly\nlinear time, while at the same time enjoying near-optimal statistical\nguarantees (i.e. minimal sample complexity and optimal estimation accuracy).\nThe estimation errors are evenly spread out across all entries, thus achieving\noptimal $\\ell_{\\infty}$ statistical accuracy. We have also discussed how to\nextend our approach to accommodate asymmetric tensors. The insight conveyed\nthrough our analysis of nonconvex optimization might have implications for\nother tensor estimation problems.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 18:21:26 GMT"}, {"version": "v2", "created": "Thu, 3 Jun 2021 03:32:06 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Cai", "Changxiao", ""], ["Li", "Gen", ""], ["Poor", "H. Vincent", ""], ["Chen", "Yuxin", ""]]}, {"id": "1911.05272", "submitter": "Kurt Riedel", "authors": "Kurt S. Riedel", "title": "Mean and Variance of Brownian Motion with Given Final Value, Maximum and\n  ArgMax: Extended Version", "comments": "31 pages, 29 figures", "journal-ref": "Stochastic Models, 2021", "doi": null, "report-no": null, "categories": "math.PR math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The conditional expectation and conditional variance of Brownian motion is\nconsidered given the argmax, B(t|argmax), as well as those with additional\ninformation: B(t|close, argmax), B(t|max, argmax), B(t|close, max, argmax)\nwhere the close is the final value: B(t=1)=c and t in [0,1]. We compute the\nexpectation and variance of a Brownian meander in time. By splicing together\ntwo Brownian meanders, the mean and variance of the constrained process are\ncalculated. Computational results displaying both the expectation and variance\nin time are presented. Comparison of the simulation with theoretical values are\nshown when the close and argmax are given.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 03:35:57 GMT"}, {"version": "v2", "created": "Wed, 19 Feb 2020 04:31:20 GMT"}, {"version": "v3", "created": "Wed, 2 Jun 2021 04:41:48 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Riedel", "Kurt S.", ""]]}, {"id": "1911.05280", "submitter": "Kurt Riedel", "authors": "Kurt S Riedel", "title": "The Value of the High, Low and Close in the Estimation of Brownian\n  Motion: Extended Version", "comments": "40 pages, 31 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The conditional density of Brownian motion is considered given the max,\nB(t|\\max), as well as those with additional information: B(t|close, max),\nB(t|close, max, min) and B(t|max, min) where the close is the final value:\nB(t=1)=c and t in [0,1]. The conditional expectation and conditional variance\nof Brownian motion are evaluated subject to one or more of the the close (final\nvalue), the high (maximum), the low (minimum). Computational results displaying\nboth the expectation and variance in time are presented and compared with the\ntheoretical values. We tabulate the time averaged variance of Brownian motion\nconditional on knowing various extremal properties of the motion. The final\ntable shows that knowing the high is more useful than knowing the final value\namong other results. Knowing the open, high, low and close reduces the time\naveraged variance to 42% of the value of knowing only the open and close\n(Brownian bridge).\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 04:09:25 GMT"}, {"version": "v2", "created": "Sun, 16 Feb 2020 02:34:45 GMT"}, {"version": "v3", "created": "Fri, 30 Oct 2020 19:53:05 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Riedel", "Kurt S", ""]]}, {"id": "1911.05401", "submitter": "Anthea Monod", "authors": "Wonjun Lee, Wuchen Li, Bo Lin, and Anthea Monod", "title": "Tropical Optimal Transport and Wasserstein Distances", "comments": "33 pages, 9 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC math.MG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of optimal transport in tropical geometry and define the\nWasserstein-$p$ distances in the continuous metric measure space setting of the\ntropical projective torus. We specify the tropical metric -- a combinatorial\nmetric that has been used to study of the tropical geometric space of\nphylogenetic trees -- as the ground metric and study the cases of $p=1,2$ in\ndetail. The case of $p=1$ gives an efficient computation of the infinitely-many\ngeodesics on the tropical projective torus, while the case of $p=2$ gives a\nform for Fr\\'{e}chet means and a general inner product structure. Our results\nalso provide theoretical foundations for geometric insight a statistical\nframework in a tropical geometric setting. We construct explicit algorithms for\nthe computation of the tropical Wasserstein-1 and 2 distances and prove their\nconvergence. Our results provide the first study of the Wasserstein distances\nand optimal transport in tropical geometry. Several numerical examples are\nprovided.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 11:16:06 GMT"}, {"version": "v2", "created": "Mon, 3 Aug 2020 11:19:18 GMT"}, {"version": "v3", "created": "Tue, 19 Jan 2021 16:21:28 GMT"}, {"version": "v4", "created": "Mon, 17 May 2021 13:43:23 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Lee", "Wonjun", ""], ["Li", "Wuchen", ""], ["Lin", "Bo", ""], ["Monod", "Anthea", ""]]}, {"id": "1911.05402", "submitter": "Biswarup Das", "authors": "Biswarup Das and Eugene. A. Golikov", "title": "Quadratic number of nodes is sufficient to learn a dataset via gradient\n  descent", "comments": "Machine learning using neural networks, gradient descent,\n  optimization, overparametrization regime", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that if an activation function satisfies some mild conditions and\nnumber of neurons in a two-layered fully connected neural network with this\nactivation function is beyond a certain threshold, then gradient descent on\nquadratic loss function finds the optimal weights of input layer for global\nminima in linear time. This threshold value is an improvement over previously\nobtained values. We hypothesise that this bound cannot be improved by the\nmethod we are using in this work.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 11:17:32 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Das", "Biswarup", ""], ["Golikov", "Eugene. A.", ""]]}, {"id": "1911.05422", "submitter": "Mohd Arshad", "authors": "Mohd. Arshad, Omer Abdalghani, Kalu Ram Meena", "title": "Estimation after selection from bivariate normal population using LINEX\n  loss function", "comments": "22 pages; 11 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $\\pi_1$ and $\\pi_2$ be two independent populations, where the population\n$\\pi_i$ follows a bivariate normal distribution with unknown mean vector\n$\\boldsymbol{\\theta}^{(i)}$ and common known variance-covariance matrix\n$\\Sigma$, $i=1,2$. The present paper is focused on estimating a characteristic\n$\\theta_{\\textnormal{y}}^S$ of the selected bivariate normal population, using\na LINEX loss function. A natural selection rule is used for achieving the aim\nof selecting the best bivariate normal population. Some natural-type estimators\nand Bayes estimator (using a conjugate prior) of $\\theta_{\\textnormal{y}}^S$\nare presented. An admissible subclass of equivariant estimators, using the\nLINEX loss function, is obtained. Further, a sufficient condition for improving\nthe competing estimators of $\\theta_{\\textnormal{y}}^S$ is derived. Using this\nsufficient condition, several estimators improving upon the proposed natural\nestimators are obtained. Further, a real data example is provided for\nillustration purpose. Finally, a comparative study on the competing estimators\nof $\\theta_{\\text{y}}^S$ is carried-out using simulation.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 12:29:15 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Arshad", "Mohd.", ""], ["Abdalghani", "Omer", ""], ["Meena", "Kalu Ram", ""]]}, {"id": "1911.05538", "submitter": "Frank R\\\"ottger", "authors": "Ulrike Gra{\\ss}hoff, Heinz Holling, Frank R\\\"ottger and Rainer Schwabe", "title": "Optimality regions for designs in multiple linear regression models with\n  correlated random coefficients", "comments": "16 pages, 7 figures", "journal-ref": "Journal of Statistical Planning and Inference (2020)", "doi": "10.1016/j.jspi.2020.04.004", "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies optimal designs for linear regression models with\ncorrelated effects for single responses. We introduce the concept of rhombic\ndesign to reduce the computational complexity and find a semi-algebraic\ndescription for the D-optimality of a rhombic design via the Kiefer-Wolfowitz\nequivalence theorem. Subsequently, we show that the structure of an optimal\nrhombic design depends directly on the correlation structure of the random\ncoefficients.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 15:17:34 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Gra\u00dfhoff", "Ulrike", ""], ["Holling", "Heinz", ""], ["R\u00f6ttger", "Frank", ""], ["Schwabe", "Rainer", ""]]}, {"id": "1911.05570", "submitter": "Wenjia Wang", "authors": "Rui Tuo and Wenjia Wang", "title": "Kriging prediction with isotropic Mat\\'ern correlations: Robustness and\n  experimental design", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work investigates the prediction performance of the kriging predictors.\nWe derive some error bounds for the prediction error in terms of non-asymptotic\nprobability under the uniform metric and $L_p$ metrics when the spectral\ndensities of both the true and the imposed correlation functions decay\nalgebraically. The Mat\\'ern family is a prominent class of correlation\nfunctions of this kind. Our analysis shows that, when the smoothness of the\nimposed correlation function exceeds that of the true correlation function, the\nprediction error becomes more sensitive to the space-filling property of the\ndesign points. In particular, the kriging predictor can still reach the optimal\nrate of convergence, if the experimental design scheme is quasi-uniform. Lower\nbounds of the kriging prediction error are also derived under the uniform\nmetric and $L_p$ metrics. An accurate characterization of this error is\nobtained, when an oversmoothed correlation function and a space-filling design\nis used.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 16:00:13 GMT"}, {"version": "v2", "created": "Mon, 23 Dec 2019 19:50:32 GMT"}, {"version": "v3", "created": "Sat, 5 Sep 2020 23:35:34 GMT"}, {"version": "v4", "created": "Tue, 8 Sep 2020 02:38:11 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Tuo", "Rui", ""], ["Wang", "Wenjia", ""]]}, {"id": "1911.05669", "submitter": "Han Cheng Lie", "authors": "Han Cheng Lie, T. J. Sullivan, Aretha Teckentrup", "title": "Error bounds for some approximate posterior measures in Bayesian\n  inference", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.NA math.NA stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In certain applications involving the solution of a Bayesian inverse problem,\nit may not be possible or desirable to evaluate the full posterior, e.g. due to\nthe high computational cost of doing so. This problem motivates the use of\napproximate posteriors that arise from approximating the data misfit or forward\nmodel. We review some error bounds for random and deterministic approximate\nposteriors that arise when the approximate data misfits and approximate forward\nmodels are random.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 17:47:24 GMT"}, {"version": "v2", "created": "Wed, 22 Apr 2020 14:14:17 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Lie", "Han Cheng", ""], ["Sullivan", "T. J.", ""], ["Teckentrup", "Aretha", ""]]}, {"id": "1911.05720", "submitter": "Ryan Christ", "authors": "Robert E. Gallagher, Louis J. M. Aslett, David Steinsaltz and Ryan R.\n  Christ", "title": "Improved Concentration Bounds for Gaussian Quadratic Forms", "comments": "12 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For a wide class of monotonic functions $f$, we develop a Chernoff-style\nconcentration inequality for quadratic forms $Q_f \\sim \\sum\\limits_{i=1}^n\nf(\\eta_i) (Z_i + \\delta_i)^2$, where $Z_i \\sim N(0,1)$. The inequality is\nexpressed in terms of traces that are rapid to compute, making it useful for\nbounding p-values in high-dimensional screening applications. The bounds we\nobtain are significantly tighter than those that have been previously\ndeveloped, which we illustrate with numerical examples.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 18:53:02 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Gallagher", "Robert E.", ""], ["Aslett", "Louis J. M.", ""], ["Steinsaltz", "David", ""], ["Christ", "Ryan R.", ""]]}, {"id": "1911.05865", "submitter": "Pulong Ma", "authors": "Pulong Ma and Anindya Bhadra", "title": "Beyond Mat\\'ern: On A Class of Interpretable Confluent Hypergeometric\n  Covariance Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Mat\\'ern covariance function is a popular choice for prediction in\nspatial statistics and uncertainty quantification literature. A key benefit of\nthe Mat\\'ern class is that it is possible to get precise control over the\ndegree of differentiability of the process realizations. However, the Mat\\'ern\nclass possesses exponentially decaying tails, and thus may not be suitable for\nmodeling polynomially decaying dependence. This problem can be remedied using\npolynomial covariances; however one loses control over the degree of\nmean-square differentiability of corresponding processes, in that the random\nprocesses with polynomial covariances are either infinitely mean-square\ndifferentiable or nowhere mean-square differentiable at all. We construct a new\nfamily of covariance functions called the \\emph{Confluent Hypergeometric} (CH)\nclass using a scale mixture representation of the Mat\\'ern class where one\nobtains the benefits of both Mat\\'ern and polynomial covariances. The resultant\ncovariance contains two parameters: one controls the degree of mean-square\ndifferentiability near the origin and the other controls the tail heaviness,\nindependently of each other. Using a spectral representation, we derive\ntheoretical properties of this new covariance including equivalent measures and\nasymptotic behavior of the maximum likelihood estimators under infill\nasymptotics. The improved theoretical properties of the CH class are verified\nvia extensive simulations. Application using NASA's Orbiting Carbon\nObservatory-2 satellite data confirms the advantage of the CH class over the\nMat\\'ern class, especially in extrapolative settings.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 00:01:07 GMT"}, {"version": "v2", "created": "Wed, 6 May 2020 17:38:46 GMT"}, {"version": "v3", "created": "Tue, 23 Jun 2020 14:09:33 GMT"}, {"version": "v4", "created": "Wed, 24 Feb 2021 03:05:12 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Ma", "Pulong", ""], ["Bhadra", "Anindya", ""]]}, {"id": "1911.05911", "submitter": "Ilias Diakonikolas", "authors": "Ilias Diakonikolas and Daniel M. Kane", "title": "Recent Advances in Algorithmic High-Dimensional Robust Statistics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning in the presence of outliers is a fundamental problem in statistics.\nUntil recently, all known efficient unsupervised learning algorithms were very\nsensitive to outliers in high dimensions. In particular, even for the task of\nrobust mean estimation under natural distributional assumptions, no efficient\nalgorithm was known. Recent work in theoretical computer science gave the first\nefficient robust estimators for a number of fundamental statistical tasks,\nincluding mean and covariance estimation. Since then, there has been a flurry\nof research activity on algorithmic high-dimensional robust estimation in a\nrange of settings. In this survey article, we introduce the core ideas and\nalgorithmic techniques in the emerging area of algorithmic high-dimensional\nrobust statistics with a focus on robust mean estimation. We also provide an\noverview of the approaches that have led to computationally efficient robust\nestimators for a range of broader statistical tasks and discuss new directions\nand opportunities for future work.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 02:56:56 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Diakonikolas", "Ilias", ""], ["Kane", "Daniel M.", ""]]}, {"id": "1911.06006", "submitter": "Seonghun Cho", "authors": "Taehyeon Koo, Seonghun Cho, Johan Lim", "title": "An Invariant Test for Equality of Two Large Scale Covariance Matrices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we are motivated by the recent work of Zhang et al. (2019) and\nstudy a new invariant test for equality of two large scale covariance matrices.\nTwo modified likelihood ratio tests (LRTs) by Zhang et al. (2019) are based on\nthe sum of log of eigenvalues (or 1- eigenvalues) of the Beta-matrix. However,\nas the dimension increases, many eigenvalues of the Beta-matrix are close to 0\nor 1 and the modified LRTs are greatly influenced by them. In this work,\ninstead, we consider the simple sum of the eigenvalues (of the Beta-matrix) and\ncompute its asymptotic normality when all $n_1, n_2, p$ increase at the same\nrate. We numerically show that our test has higher power than two modified\nlikelihood ratio tests by Zhang et al. (2019) in all cases both we and they\nconsider.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 09:16:37 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Koo", "Taehyeon", ""], ["Cho", "Seonghun", ""], ["Lim", "Johan", ""]]}, {"id": "1911.06177", "submitter": "Thomas Lee", "authors": "Suofei Wu, Jan Hannig and Thomas C. M. Lee", "title": "Uncertainty Quantification in Ensembles of Honest Regression Trees using\n  Generalized Fiducial Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to their accuracies, methods based on ensembles of regression trees are a\npopular approach for making predictions. Some common examples include Bayesian\nadditive regression trees, boosting and random forests. This paper focuses on\nhonest random forests, which add honesty to the original form of random forests\nand are proved to have better statistical properties. The main contribution is\na new method that quantifies the uncertainties of the estimates and predictions\nproduced by honest random forests. The proposed method is based on the\ngeneralized fiducial methodology, and provides a fiducial density function that\nmeasures how likely each single honest tree is the true model. With such a\ndensity function, estimates and predictions, as well as their\nconfidence/prediction intervals, can be obtained. The promising empirical\nproperties of the proposed method are demonstrated by numerical comparisons\nwith several state-of-the-art methods, and by applications to a few real data\nsets. Lastly, the proposed method is theoretically backed up by a strong\nasymptotic guarantee.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 15:33:07 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Wu", "Suofei", ""], ["Hannig", "Jan", ""], ["Lee", "Thomas C. M.", ""]]}, {"id": "1911.06190", "submitter": "Kostas Loumponias", "authors": "Kostas Loumponias, Nicholas Vretos, George Tsaklidis and Petros Daras", "title": "An Improved Tobit Kalman Filter with Adaptive Censoring Limits", "comments": "21 pages, 32 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CV math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with the Tobit Kalman filtering (TKF) process when the\nmeasurements are correlated and censored. The case of interval censoring, i.e.,\nthe case of measurements which belong to some interval with given censoring\nlimits, is considered. Two improvements of the standard TKF process are\nproposed, in order to estimate the hidden state vectors. Firstly, the exact\ncovariance matrix of the censored measurements is calculated by taking into\naccount the censoring limits. Secondly, the probability of a latent (normally\ndistributed) measurement to belong in or out of the uncensored region is\ncalculated by taking into account the Kalman residual. The designed algorithm\nis tested using both synthetic and real data sets. The real data set includes\nhuman skeleton joints' coordinates captured by the Microsoft Kinect II sensor.\nIn order to cope with certain real-life situations that cause problems in human\nskeleton tracking, such as (self)-occlusions, closely interacting persons etc.,\nadaptive censoring limits are used in the proposed TKF process. Experiments\nshow that the proposed method outperforms other filtering processes in\nminimizing the overall Root Mean Square Error (RMSE) for synthetic and real\ndata sets.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 15:45:06 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Loumponias", "Kostas", ""], ["Vretos", "Nicholas", ""], ["Tsaklidis", "George", ""], ["Daras", "Petros", ""]]}, {"id": "1911.06204", "submitter": "Gil Ariel", "authors": "Gil Ariel, Yoram Louzoun", "title": "Estimating differential entropy using recursive copula splitting", "comments": null, "journal-ref": null, "doi": "10.3390/e22020236", "report-no": null, "categories": "cond-mat.stat-mech math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A method for estimating the Shannon differential entropy of multidimensional\nrandom variables using independent samples is described. The method is based on\ndecomposing the distribution into a product of the marginal distributions and\nthe joint dependency, also known as the copula. The entropy of marginals is\nestimated using one-dimensional methods. The entropy of the copula, which\nalways has a compact support, is estimated recursively by splitting the data\nalong statistically dependent dimensions. Numerical examples demonstrate that\nthe method is accurate for distributions with compact and non-compact supports,\nwhich is imperative when the support is not known or of mixed type (in\ndifferent dimensions). At high dimensions (larger than 20), our method is not\nonly more accurate, but also significantly more efficient than existing\napproaches.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 15:57:49 GMT"}, {"version": "v2", "created": "Thu, 9 Jan 2020 10:19:34 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Ariel", "Gil", ""], ["Louzoun", "Yoram", ""]]}, {"id": "1911.06215", "submitter": "Huiming Zhang", "authors": "Xiaowei Yang, Huiming Zhang, Haoyu Wei, Shouzheng Zhang", "title": "Sparse Density Estimation with Measurement Errors", "comments": "34 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper aims to build an estimate of an unknown density of the data with\nmeasurement error as a linear combination of functions from a dictionary.\nInspired by the penalization approach, we propose the weighted Elastic-net\npenalized minimal $\\ell_2$-distance method for sparse coefficients estimation,\nwhere the adaptive weights come from sharp concentration inequalities. The\noptimal weighted tuning parameters are obtained by the first-order conditions\nholding with a high probability. Under local coherence or minimal eigenvalue\nassumptions, non-asymptotical oracle inequalities are derived. These\ntheoretical results are transposed to obtain the support recovery with a high\nprobability. Then, some numerical experiments for discrete and continuous\ndistributions confirm the significant improvement obtained by our procedure\nwhen compared with other conventional approaches. Finally, the application is\nperformed in a meteorology data set. It shows that our method has potency and\nsuperiority of detecting the shape of multi-mode density compared with other\nconventional approaches.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 16:13:11 GMT"}, {"version": "v2", "created": "Sat, 8 Feb 2020 15:56:39 GMT"}, {"version": "v3", "created": "Mon, 6 Jul 2020 13:33:06 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Yang", "Xiaowei", ""], ["Zhang", "Huiming", ""], ["Wei", "Haoyu", ""], ["Zhang", "Shouzheng", ""]]}, {"id": "1911.06225", "submitter": "Nilanjana Laha", "authors": "Nilanjana Laha", "title": "Location estimation for symmetric log-concave densities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We revisit the problem of estimating the center of symmetry $\\theta$ of an\nunknown symmetric density $f$. Although Stone (1975), Van Eden (1970), and\nSacks (1975) constructed adaptive estimators of $\\theta$ in this model, their\nestimators depend on tuning parameters. In an effort to circumvent the\ndependence on tuning parameters, we impose an additional assumption of\nlog-concavity on $f$. We show that in this shape-restricted model, the maximum\nlikelihood estimator (MLE) of $\\theta$ exists. We also study some truncated\none-step estimators and show that they are $\\sqrt{n}-$consistent, and nearly\nachieve the asymptotic efficiency bound. We also show that the rate of\nconvergence for the MLE is $O_p(n^{-2/5})$. Furthermore, we show that our\nestimators are robust with respect to the violation of the log-concavity\nassumption. In fact, we show that the one step estimators are still\n$\\sqrt{n}$-consistent under some mild conditions. These analytical conclusions\nare supported by simulation studies.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 16:36:03 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Laha", "Nilanjana", ""]]}, {"id": "1911.06385", "submitter": "Mengyu Xu", "authors": "Mengyu Xu, Xiaohui Chen, and Wei Biao Wu", "title": "Estimation of dynamic networks for high-dimensional nonstationary time\n  series", "comments": null, "journal-ref": null, "doi": "10.3390/e22010055", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is concerned with the estimation of time-varying networks for\nhigh-dimensional nonstationary time series. Two types of dynamic behaviors are\nconsidered: structural breaks (i.e., abrupt change points) and smooth changes.\nTo simultaneously handle these two types of time-varying features, a two-step\napproach is proposed: multiple change point locations are first identified\nbased on comparing the difference between the localized averages on sample\ncovariance matrices, and then graph supports are recovered based on a\nkernelized time-varying constrained $L_1$-minimization for inverse matrix\nestimation (CLIME) estimator on each segment. We derive the rates of\nconvergence for estimating the change points and precision matrices under mild\nmoment and dependence conditions. In particular, we show that this two-step\napproach is consistent in estimating the change points and the piecewise smooth\nprecision matrix function, under certain high-dimensional scaling limit. The\nmethod is applied to the analysis of network structure of the S\\&P 500 index\nbetween 2003 and 2008.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 21:11:42 GMT"}, {"version": "v2", "created": "Mon, 18 Nov 2019 02:19:13 GMT"}, {"version": "v3", "created": "Thu, 26 Dec 2019 03:27:36 GMT"}, {"version": "v4", "created": "Tue, 31 Dec 2019 04:33:52 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Xu", "Mengyu", ""], ["Chen", "Xiaohui", ""], ["Wu", "Wei Biao", ""]]}, {"id": "1911.06468", "submitter": "Dylan Foster", "authors": "Dylan J. Foster and Alexander Rakhlin", "title": "$\\ell_{\\infty}$ Vector Contraction for Rademacher Complexity", "comments": "Technical note", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the Rademacher complexity of any $\\mathbb{R}^{K}$-valued\nfunction class composed with an $\\ell_{\\infty}$-Lipschitz function is bounded\nby the maximum Rademacher complexity of the restriction of the function class\nalong each coordinate, times a factor of $\\tilde{O}(\\sqrt{K})$.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 04:04:55 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Foster", "Dylan J.", ""], ["Rakhlin", "Alexander", ""]]}, {"id": "1911.06545", "submitter": "Lei Qiao", "authors": "Lei Qiao and Dong Han", "title": "Optimal Sequential Tests for Detection of Changes under Finite measure\n  space for Finite Sequences of Networks", "comments": null, "journal-ref": "Communications in Statistics - Theory and Methods (2020)", "doi": "10.1080/03610926.2020.1864824", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the change-point problem for finite sequences of\nnetworks. To avoid the difficulty of computing the normalization coefficient,\nsuch as in Exponential random graphical models (ERGMs) and Markov networks, we\nconstruct a finite measure space with measure ratio statistics. A new\nperformance measure of detection delay is proposed to detect the changes in\ndistribution of the network. And an optimal sequential test is proposed under\nthe performance measure. The good performance of the optimal sequential test is\nillustrated numerically on ERGMs and Erdos-R\\'{e}nyi network sequences.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 10:04:36 GMT"}, {"version": "v2", "created": "Sun, 17 Jan 2021 06:42:48 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Qiao", "Lei", ""], ["Han", "Dong", ""]]}, {"id": "1911.06674", "submitter": "Juan Juan Cai", "authors": "Juan Juan Cai", "title": "A nonparametric estimator of the extremal index", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Clustering of extremes has a large societal impact. The extremal index, a\nnumber in the unit interval, is a key parameter in modelling the clustering of\nextremes. We build a connection between the extremal index and the stable tail\ndependence function, which enables us to compute the value of extremal indices\nfor some time series models. We also construct a nonparametric estimator of the\nextremal index and an estimation procedure to verify $D^{(d)}(u_n)$ condition,\na local dependence condition often assumed for studying the extremal index. We\nprove that the estimator is asymptotically normal. The simulation study which\ncompares our estimator to two existing methods shows that our method has better\nfinite sample properties. We apply our method to estimate the expected\ndurations of heatwaves in the Netherlands and in Greece.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 14:47:25 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Cai", "Juan Juan", ""]]}, {"id": "1911.06723", "submitter": "Chainarong Amornbunchornvej", "authors": "Chainarong Amornbunchornvej, Navaporn Surasvadi, Anon Plangprasopchok,\n  and Suttipong Thajchayapong", "title": "A nonparametric framework for inferring orders of categorical data from\n  category-real ordered pairs", "comments": "The R package can be found at https://github.com/DarkEyes/EDOIF", "journal-ref": "Heliyon, Volume 6, Issue 11, 2020, e05435", "doi": "10.1016/j.heliyon.2020.e05435", "report-no": null, "categories": "stat.ME cs.CY math.ST physics.data-an stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a dataset of careers and incomes, how large a difference of income\nbetween any pair of careers would be? Given a dataset of travel time records,\nhow long do we need to spend more when choosing a public transportation mode\n$A$ instead of $B$ to travel? In this paper, we propose a framework that is\nable to infer orders of categories as well as magnitudes of difference of real\nnumbers between each pair of categories using Estimation statistics framework.\nNot only reporting whether an order of categories exists, but our framework\nalso reports the magnitude of difference of each consecutive pairs of\ncategories in the order. In large dataset, our framework is scalable well\ncompared with the existing framework. The proposed framework has been applied\nto two real-world case studies: 1) ordering careers by incomes based on\ninformation of 350,000 households living in Khon Kaen province, Thailand, and\n2) ordering sectors by closing prices based on 1060 companies' closing prices\nof NASDAQ stock markets between years 2000 and 2016. The results of careers\nordering show income inequality among different careers. The stock market\nresults illustrate dynamics of sector domination that can change over time. Our\napproach is able to be applied in any research area that has category-real\nordered pairs. Our proposed \"Dominant-Distribution Network\" provides a novel\napproach to gain new insight of analyzing category orders. The software of this\nframework is available for researchers or practitioners within R package:\nEDOIF.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 16:10:27 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Amornbunchornvej", "Chainarong", ""], ["Surasvadi", "Navaporn", ""], ["Plangprasopchok", "Anon", ""], ["Thajchayapong", "Suttipong", ""]]}, {"id": "1911.06728", "submitter": "Aurelie Fischer", "authors": "Sylvain Delattre (LPSM UMR 8001), Aur\\'elie Fischer (LPSM UMR 8001)", "title": "Estimation via length-constrained generalized empirical principal curves\n  under small noise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a method to build a sequence of generalized\nempirical principal curves, with selected length, so that, in Hausdor distance,\nthe images of the estimating principal curves converge in probability to the\nimage of g.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 16:25:30 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Delattre", "Sylvain", "", "LPSM UMR 8001"], ["Fischer", "Aur\u00e9lie", "", "LPSM UMR 8001"]]}, {"id": "1911.06781", "submitter": "Bercu Bernard", "authors": "Bernard Bercu and Lucile Laulin", "title": "On the center of mass of the elephant random walk", "comments": "Improvement of the law of iterated logarithm in the diffusive and\n  critical regimes", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our goal is to investigate the asymptotic behavior of the center of mass of\nthe elephant random walk, which is a discrete-time random walk on integers with\na complete memory of its whole history. In the diffusive and critical regimes,\nwe establish the almost sure convergence, the law of iterated logarithm and the\nquadratric strong law for the center of mass of the elephant random walk. The\nasymptotic normality of the center of mass, properly normalized, is also\nprovided. Finally, we prove a strong limit theorem for the center of mass in\nthe superdiffusive regime. All our analysis relies on asymptotic results for\nmulti-dimensional martingales.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 20:19:52 GMT"}, {"version": "v2", "created": "Wed, 8 Apr 2020 18:15:26 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Bercu", "Bernard", ""], ["Laulin", "Lucile", ""]]}, {"id": "1911.06912", "submitter": "Dhruva Kartik", "authors": "Dhruva Kartik, Ashutosh Nayyar, Urbashi Mitra", "title": "Fixed-horizon Active Hypothesis Testing", "comments": "Submitted to IEEE Transactions on Automatic Control", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.IT cs.SY math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two active hypothesis testing problems are formulated. In these problems, the\nagent can perform a fixed number of experiments and then decide on one of the\nhypotheses. The agent is also allowed to declare its experiments inconclusive\nif needed. The first problem is an asymmetric formulation in which the the\nobjective is to minimize the probability of incorrectly declaring a particular\nhypothesis to be true while ensuring that the probability of correctly\ndeclaring that hypothesis is moderately high. This formulation can be seen as a\ngeneralization of the formulation in the classical Chernoff-Stein lemma to an\nactive setting. The second problem is a symmetric formulation in which the\nobjective is to minimize the probability of making an incorrect inference\n(misclassification probability) while ensuring that the true hypothesis is\ndeclared conclusively with moderately high probability. For these problems,\nlower and upper bounds on the optimal misclassification probabilities are\nderived and these bounds are shown to be asymptotically tight. Classical\napproaches for experiment selection suggest use of randomized and, in some\ncases, open-loop strategies. As opposed to these classical approaches, fully\ndeterministic and adaptive experiment selection strategies are provided. It is\nshown that these strategies are asymptotically optimal and further, using\nnumerical experiments, it is demonstrated that these novel experiment selection\nstrategies (coupled with appropriate inference strategies) have a significantly\nbetter performance in the non-asymptotic regime.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 23:30:01 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Kartik", "Dhruva", ""], ["Nayyar", "Ashutosh", ""], ["Mitra", "Urbashi", ""]]}, {"id": "1911.07087", "submitter": "Zhong Guan", "authors": "Zhong Guan", "title": "Maximum Approximate Likelihood Estimation in Accelerated Failure Time\n  Model for Interval-Censored Data", "comments": "20 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The approximate Bernstein polynomial model, a mixture of beta distributions,\nis applied to obtain maximum likelihood estimates of the regression\ncoefficients, and the baseline density and survival functions in an accelerated\nfailure time model based on interval censored data including current status\ndata. The rate of convergence of the proposed estimates are given under some\nconditions for uncensored and interval censored data. Simulation shows that the\nproposed method is better than its competitors. The proposed method is\nillustrated by fitting the Breast Cosmetic Data using the accelerated failure\ntime model.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2019 20:01:06 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Guan", "Zhong", ""]]}, {"id": "1911.07121", "submitter": "Ryan Kinnear Mr.", "authors": "R. J. Kinnear, R. R. Mazumdar", "title": "Graph Topological Aspects of Granger Causal Network Learning", "comments": "46 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST eess.SP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study Granger causality in the context of wide-sense stationary time\nseries, where our focus is on the topological aspects of the underlying\ncausality graph. We establish sufficient conditions (in particular, we develop\nthe notion of a \"strongly causal\" graph topology) under which the true\ncausality graph can be recovered via pairwise causality testing alone, and\nprovide examples from the gene regulatory network literature suggesting that\nour concept of a strongly causal graph may be applicable to this field. We\nimplement and detail finite-sample heuristics derived from our theory, and\nestablish through simulation the efficiency gains (both statistical and\ncomputational) which can be obtained (in comparison to LASSO-type algorithms)\nwhen structural assumptions are met.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 00:45:44 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Kinnear", "R. J.", ""], ["Mazumdar", "R. R.", ""]]}, {"id": "1911.07231", "submitter": "Francesco Ortelli", "authors": "Francesco Ortelli and Sara van de Geer", "title": "Adaptive Rates for Total Variation Image Denoising", "comments": "38 pages, 6 figures", "journal-ref": "Journal of Machine Learning Research, 21(247), 2020", "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the theoretical properties of image denoising via total variation\npenalized least-squares. We define the total vatiation in terms of the\ntwo-dimensional total discrete derivative of the image and show that it gives\nrise to denoised images that are piecewise constant on rectangular sets. We\nprove that, if the true image is piecewise constant on just a few rectangular\nsets, the denoised image converges to the true image at a parametric rate, up\nto a log factor. More generally, we show that the denoised image enjoys oracle\nproperties, that is, it is almost as good as if some aspects of the true image\nwere known. In other words, image denoising with total variation regularization\nleads to an adaptive reconstruction of the true image.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 13:09:50 GMT"}, {"version": "v2", "created": "Sat, 14 Dec 2019 13:38:22 GMT"}, {"version": "v3", "created": "Sun, 29 Mar 2020 19:31:19 GMT"}, {"version": "v4", "created": "Wed, 21 Oct 2020 09:01:02 GMT"}, {"version": "v5", "created": "Tue, 26 Jan 2021 10:21:02 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Ortelli", "Francesco", ""], ["van de Geer", "Sara", ""]]}, {"id": "1911.07357", "submitter": "Cl\\'ement Canonne", "authors": "Cl\\'ement L. Canonne, Xi Chen, Gautam Kamath, Amit Levi, Erik\n  Waingarten", "title": "Random Restrictions of High-Dimensional Distributions and Uniformity\n  Testing with Subcube Conditioning", "comments": "Added Remark 4.4, which discusses the time complexity (the algorithms\n  are polynomial-time, based on an observation from [CJLW20]); removing log log\n  log n factor for the Gaussian testing algorithm. These changes reflect those\n  included in the conference version (SODA'21)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.IT cs.LG math.IT math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a nearly-optimal algorithm for testing uniformity of distributions\nsupported on $\\{-1,1\\}^n$, which makes $\\tilde O (\\sqrt{n}/\\varepsilon^2)$\nqueries to a subcube conditional sampling oracle (Bhattacharyya and Chakraborty\n(2018)). The key technical component is a natural notion of random restriction\nfor distributions on $\\{-1,1\\}^n$, and a quantitative analysis of how such a\nrestriction affects the mean vector of the distribution. Along the way, we\nconsider the problem of mean testing with independent samples and provide a\nnearly-optimal algorithm.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 22:39:17 GMT"}, {"version": "v2", "created": "Thu, 4 Feb 2021 23:30:41 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Canonne", "Cl\u00e9ment L.", ""], ["Chen", "Xi", ""], ["Kamath", "Gautam", ""], ["Levi", "Amit", ""], ["Waingarten", "Erik", ""]]}, {"id": "1911.07428", "submitter": "Arman Arian", "authors": "Arman Arian and Ozgur Yilmaz", "title": "RIP constants for deterministic compressed sensing matrices-beyond\n  Gershgorin", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compressed sensing (CS) is a signal acquisition paradigm to simultaneously\nacquire and reduce dimension of signals that admit sparse representations. This\nis achieved by collecting linear, non-adaptive measurements of a signal, which\ncan be formalized as multiplying the signal with a \"measurement matrix\". If the\nmeasurement satisfies the so-called restricted isometry property (RIP), then it\nwill be appropriate to be used in compressed sensing. While a wide class of\nrandom matrices provably satisfy the RIP with high probability, explicit and\ndeterministic constructions have been shown (so far) to satisfy the RIP only in\na significantly suboptimal regime.\n  In this paper, we propose two novel approaches for improving the RIP constant\nestimates based on Gershgorin circle theorem for a specific deterministic\nconstruction based on Paley tight frames, obtaining an improvement over the\nGershgorin bound by a multiplicative constant. In one approach we use a recent\nresult on the spectra of the skew-adjacency matrices of oriented graphs. In the\nother approach, we use the so-called Dembo bounds on the extreme eigenvalues of\na positive semidefinite Hermitian matrix. We also generalize these bounds and\nwe combine the new bounds with a conjecture we make regarding the distribution\nof quadratic residues in a finite field to provide a potential path to break\nthe so-called \"square-root barrier\"-we provide a proof based on the assumption\nthat the conjecture holds.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 04:52:47 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Arian", "Arman", ""], ["Yilmaz", "Ozgur", ""]]}, {"id": "1911.07494", "submitter": "Yi Yu", "authors": "Oscar Hernan Madrid Padilla, Yi Yu and Carey E. Priebe", "title": "Change point localization in dependent dynamic nonparametric random dot\n  product graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the change point localization problem in a sequence\nof dependent nonparametric random dot product graphs. To be specific, assume\nthat at every time point, a network is generated from a nonparametric random\ndot product graph model (see e.g. Athreya et al., 2017), where the latent\npositions are generated from unknown underlying distributions. The underlying\ndistributions are piecewise constant in time and change at unknown locations,\ncalled change points. Most importantly, we allow for dependence among networks\ngenerated between two consecutive change points. This setting incorporates\nedge-dependence within networks and temporal dependence between networks, which\nis the most flexible setting in the published literature.\n  To accomplish the task of consistently localizing change points, we propose a\nnovel change point detection algorithm, consisting of two steps. First, we\nestimate the latent positions of the random dot product model, our theoretical\nresult being a refined version of the state-of-the-art results, allowing the\ndimension of the latent positions to grow unbounded. Subsequently, we construct\na nonparametric version of the CUSUM statistic (Page, 1954, Padilla et al.,\n2019) that allows for temporal dependence. Consistent localization is proved\ntheoretically and supported by extensive numerical experiments, which\nillustrate state-of-the-art performance. We also provide in depth discussion of\npossible extensions to give more understanding and insights.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 09:18:02 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2020 17:28:10 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Padilla", "Oscar Hernan Madrid", ""], ["Yu", "Yi", ""], ["Priebe", "Carey E.", ""]]}, {"id": "1911.07497", "submitter": "Arman Arian", "authors": "Arman Arian, Ozgur Yilmaz", "title": "Deterministic partial binary circulant compressed sensing matrices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compressed sensing (CS) is a signal acquisition paradigm to simultaneously\nacquire and reduce dimension of signals that admit sparse representation. This\nis achieved by collecting linear, non-adaptive measurements of a signal, which\ncan be formalized as multiplying the signal with a \"measurement matrix\". Most\nof matrices used in CS are random matrices as they satisfy the restricted\nisometry property (RIP) in an optimal regime of number of measurements with\nhigh probability. However, these matrices have their own caveats and for this\nreason, deterministic measurement matrices have been proposed. While there is a\nwide classes of deterministic matrices in the literature, we propose a novel\nclass of deterministic matrices using the Legendre symbol. This construction\nhas a simple structure, it enjoys being a binary matrix, and having a partial\ncirculant structure which provides a fast matrix-vector multiplication and a\nfast reconstruction algorithm. We will derive a bound on the sparsity level of\nsignals that can be measured (and be reconstructed) with this class of\nmatrices. We perform quantization using these matrices, and we verify the\nperformance of these matrices (and compare with other existing constructions)\nnumerically.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 09:35:01 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Arian", "Arman", ""], ["Yilmaz", "Ozgur", ""]]}, {"id": "1911.07522", "submitter": "Jakob Peterlin Institute for", "authors": "Rok Blagus, Jakob Peterlin, Janez Stare", "title": "Goodness-of-fit Testing in Linear Regression Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model checking plays an important role in linear regression as model\nmisspecification seriously affects the validity and efficiency of regression\nanalysis. In practice, model checking is often performed by subjectively\nevaluating the plot of the model's residuals. This approach is objectified by\nconstructing a random process from the model's residuals, however due to a very\ncomplex covariance function obtaining the exact distribution of the test\nstatistic is intractable. Several solutions to overcome this have been\nproposed, however the simulation and bootstrap based approaches are only\nasymptotically valid and can, with a limited sample size, yield tests which\nhave inappropriate size. We therefore propose to estimate the null distribution\nby using permutations. We show, under some mild assumptions, that with\nhomoscedastic random errors this yields consistent tests under the null and the\nalternative hypotheses. Small sample properties of the proposed tests are\nstudied in an extensive Monte Carlo simulation study, where it is demonstrated\nthat the proposed tests attain correct size, even with strongly non-normal\nrandom errors and a very small sample size, while being as powerful as the\nother available alternatives. The results are also illustrated on some real\ndata examples.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 10:08:45 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Blagus", "Rok", ""], ["Peterlin", "Jakob", ""], ["Stare", "Janez", ""]]}, {"id": "1911.07525", "submitter": "Arman Arian", "authors": "Arman Arian, Ozgur Yilmaz", "title": "On one-stage recovery for $\\Sigma \\Delta$-quantized compressed sensing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compressed sensing (CS) is a signal acquisition paradigm to simultaneously\nacquire and reduce dimension of signals that admit sparse representations. When\nsuch a signal is acquired according to the principles of CS, the measurements\nstill take on values in the continuum. In today's \"digital\" world, a subsequent\nquantization step, where these measurements are replaced with elements from a\nfinite set is crucial. We focus on one of the approaches that yield efficient\nquantizers for CS: $\\Sigma \\Delta$ quantization, followed by a one-stage\ntractable reconstruction method, which was developed by Saab et al. with\ntheoretical error guarantees in the case of sub-Gaussian matrices. We propose\ntwo alternative approaches that extend this result to a wider class of\nmeasurement matrices including (certain unitary transforms of) partial bounded\northonormal systems and deterministic constructions based on chirp sensing\nmatrices.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 10:19:33 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Arian", "Arman", ""], ["Yilmaz", "Ozgur", ""]]}, {"id": "1911.07580", "submitter": "Holger Dette", "authors": "Holger Dette, Tim Kutta", "title": "Detecting structural breaks in eigensystems of functional time series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting structural changes in functional data is a prominent topic in\nstatistical literature. However not all trends in the data are important in\napplications, but only those of large enough influence. In this paper we\naddress the problem of identifying relevant changes in the eigenfunctions and\neigenvalues of covariance kernels of $L^2[0,1]$-valued time series. By\nself-normalization techniques we derive pivotal, asymptotically consistent\ntests for relevant changes in these characteristics of the second order\nstructure and investigate their finite sample properties in a simulation study.\nThe applicability of our approach is demonstrated analyzing German annual\ntemperature data.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 12:20:47 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Dette", "Holger", ""], ["Kutta", "Tim", ""]]}, {"id": "1911.07694", "submitter": "Cl\\'emence Karmann Mrs", "authors": "G\\'egout-Petit Anne, Gueudin-Muller Aur\\'elie, Karmann Cl\\'emence", "title": "Graph estimation for Gaussian data zero-inflated by double truncation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of graph estimation in a zero-inflated Gaussian\nmodel. In this model, zero-inflation is obtained by double truncation (right\nand left) of a Gaussian vector. The goal is to recover the latent graph\nstructure of the Gaussian vector with observations of the zero-inflated\ntruncated vector. We propose a two step estimation procedure. The first step\nconsists in estimating each term of the covariance matrix by maximising the\ncorresponding bivariate marginal log-likelihood of the truncated vector. The\nsecond one uses the graphical lasso procedure to estimate the precision matrix\nsparsity, which encodes the graph structure. We then state some theoretical\nconvergence results about the convergence rate of the covariance matrix and\nprecision matrix estimators. These results allow us to establish consistency of\nour procedure with respect to graph structure recovery. We also present some\nsimulation studies to corroborate the efficiency of our procedure.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 15:19:28 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Anne", "G\u00e9gout-Petit", ""], ["Aur\u00e9lie", "Gueudin-Muller", ""], ["Cl\u00e9mence", "Karmann", ""]]}, {"id": "1911.07987", "submitter": "Mohamed Ndaoud", "authors": "Mohamed Ndaoud, Suzanne Sigalla, Alexandre B. Tsybakov", "title": "Improved clustering algorithms for the Bipartite Stochastic Block Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We establish sufficient conditions of exact and almost full recovery of the\nnode partition in Bipartite Stochastic Block Model (BSBM) using polynomial time\nalgorithms. First, we improve upon the known conditions of almost full recovery\nby spectral clustering algorithms in BSBM. Next, we propose a new\ncomputationally simple and fast procedure achieving exact recovery under milder\nconditions than the state of the art. Namely, if the vertex sets $V_1$ and\n$V_2$ in BSBM have sizes $n_1$ and $n_2$, we show that the condition $p =\n\\Omega\\left(\\max\\left(\\sqrt{\\frac{\\log{n_1}}{n_1n_2}},\\frac{\\log{n_1}}{n_2}\\right)\\right)$\non the edge intensity $p$ is sufficient for exact recovery witin $V_1$. This\ncondition exhibits an elbow at $n_{2} \\asymp n_1\\log{n_1}$ between the\nlow-dimensional and high-dimensional regimes. The suggested procedure is a\nvariant of Lloyd's iterations initialized with a well-chosen spectral estimator\nleading to what we expect to be the optimal condition for exact recovery in\nBSBM. {The optimality conjecture is supported by showing that, for a supervised\noracle procedure, such a condition is necessary to achieve exact recovery.} The\nkey elements of the proof techniques are different from classical community\ndetection tools on random graphs. Numerical studies confirm our theory, and\nshow that the suggested algorithm is both very fast and achieves {almost the\nsame} performance as the supervised oracle. Finally, using the connection\nbetween planted satisfiability problems and the BSBM, we improve upon the\nsufficient number of clauses to completely recover the planted assignment.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 22:36:30 GMT"}, {"version": "v2", "created": "Tue, 11 Aug 2020 18:17:40 GMT"}, {"version": "v3", "created": "Thu, 22 Apr 2021 19:29:47 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Ndaoud", "Mohamed", ""], ["Sigalla", "Suzanne", ""], ["Tsybakov", "Alexandre B.", ""]]}, {"id": "1911.08004", "submitter": "Dana Yang", "authors": "Jian Ding, Yihong Wu, Jiaming Xu, and Dana Yang", "title": "Consistent recovery threshold of hidden nearest neighbor graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG cs.SI math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by applications such as discovering strong ties in social networks\nand assembling genome subsequences in biology, we study the problem of\nrecovering a hidden $2k$-nearest neighbor (NN) graph in an $n$-vertex complete\ngraph, whose edge weights are independent and distributed according to $P_n$\nfor edges in the hidden $2k$-NN graph and $Q_n$ otherwise. The special case of\nBernoulli distributions corresponds to a variant of the Watts-Strogatz\nsmall-world graph. We focus on two types of asymptotic recovery guarantees as\n$n\\to \\infty$: (1) exact recovery: all edges are classified correctly with\nprobability tending to one; (2) almost exact recovery: the expected number of\nmisclassified edges is $o(nk)$. We show that the maximum likelihood estimator\nachieves (1) exact recovery for $2 \\le k \\le n^{o(1)}$ if $ \\liminf\n\\frac{2\\alpha_n}{\\log n}>1$; (2) almost exact recovery for $ 1 \\le k \\le\no\\left( \\frac{\\log n}{\\log \\log n} \\right)$ if $\\liminf\n\\frac{kD(P_n||Q_n)}{\\log n}>1$, where $\\alpha_n \\triangleq -2 \\log \\int \\sqrt{d\nP_n d Q_n}$ is the R\\'enyi divergence of order $\\frac{1}{2}$ and $D(P_n||Q_n)$\nis the Kullback-Leibler divergence. Under mild distributional assumptions,\nthese conditions are shown to be information-theoretically necessary for any\nalgorithm to succeed. A key challenge in the analysis is the enumeration of\n$2k$-NN graphs that differ from the hidden one by a given number of edges.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 23:44:54 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Ding", "Jian", ""], ["Wu", "Yihong", ""], ["Xu", "Jiaming", ""], ["Yang", "Dana", ""]]}, {"id": "1911.08061", "submitter": "Xin Li", "authors": "Xin Li, Dongya Wu, Chong Li, Jinhua Wang, Jen-Chih Yao", "title": "Sparse recovery via nonconvex regularized $M$-estimators over\n  $\\ell_q$-balls", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we analyse the recovery properties of nonconvex regularized\n$M$-estimators, under the assumption that the true parameter is of soft\nsparsity. In the statistical aspect, we establish the recovery bound for any\nstationary point of the nonconvex regularized $M$-estimator, under restricted\nstrong convexity and some regularity conditions on the loss function and the\nregularizer, respectively. In the algorithmic aspect, we slightly decompose the\nobjective function and then solve the nonconvex optimization problem via the\nproximal gradient method, which is proved to achieve a linear convergence rate.\nIn particular, we note that for commonly-used regularizers such as SCAD and\nMCP, a simpler decomposition is applicable thanks to our assumption on the\nregularizer, which helps to construct the estimator with better recovery\nperformance. Finally, we demonstrate our theoretical consequences and the\nadvantage of the assumption by several numerical experiments on the corrupted\nerrors-in-variables linear regression model. Simulation results show remarkable\nconsistency with our theory under high-dimensional scaling.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 02:56:35 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Li", "Xin", ""], ["Wu", "Dongya", ""], ["Li", "Chong", ""], ["Wang", "Jinhua", ""], ["Yao", "Jen-Chih", ""]]}, {"id": "1911.08063", "submitter": "Xin Li", "authors": "Xin Li, Dongya Wu", "title": "Minimax rates of $\\ell_p$-losses for high-dimensional linear regression\n  models with additive measurement errors over $\\ell_q$-balls", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study minimax rates for high-dimensional linear regression with additive\nerrors under the $\\ell_p\\ (1\\leq p<\\infty)$-losses, where the regression\nparameter is of weak sparsity. Our lower and upper bounds agree up to constant\nfactors, implying that the proposed estimator is minimax optimal.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 02:58:16 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Li", "Xin", ""], ["Wu", "Dongya", ""]]}, {"id": "1911.08100", "submitter": "Dan Cheng Mr.", "authors": "Dan Cheng and Armin Schwartzman", "title": "On critical points of Gaussian random fields under diffeomorphic\n  transformations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $\\{X(t), t\\in M\\}$ and $\\{Z(t'), t'\\in M'\\}$ be smooth Gaussian random\nfields parameterized on Riemannian manifolds $M$ and $M'$, respectively, such\nthat $X(t) = Z(f(t))$, where $f: M \\to M'$ is a diffeomorphic transformation.\nWe study the expected number and height distribution of the critical points of\n$X$ in connection with those of $Z$. As an important case, when $X$ is an\nanisotropic Gaussian random field, then we show that its expected number of\ncritical points becomes proportional to that of an isotropic field $Z$, while\nthe height distribution remains the same as that of $Z$.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 05:08:07 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Cheng", "Dan", ""], ["Schwartzman", "Armin", ""]]}, {"id": "1911.08171", "submitter": "Christophe Ley", "authors": "Sladana Babic and Laetitia Gelbgras and Marc Hallin and Christophe Ley", "title": "Optimal tests for elliptical symmetry: specified and unspecified\n  location", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although the assumption of elliptical symmetry is quite common in\nmultivariate analysis and widespread in a number of applications, the problem\nof testing the null hypothesis of ellipticity so far has not been addressed in\na fully satisfactory way. Most of the literature in the area indeed addresses\nthe null hypothesis of elliptical symmetry with specified location and actually\naddresses location rather than non-elliptical alternatives. In this paper, we\nare proposing new classes of testing procedures, both for specified and\nunspecified location. The backbone of our construction is Le Cam's asymptotic\ntheory of statistical experiments, and optimality is to be understood locally\nand asymptotically within the family of generalized skew-elliptical\ndistributions. The tests we are proposing are meeting all the desired\nproperties of a``good'' test of elliptical symmetry: they have a simple\nasymptotic distribution under the entire null hypothesis of elliptical symmetry\nwith unspecified radial density and shape parameter; they are affine-invariant,\ncomputationally fast, intuitively understandable, and not too demanding in\nterms of moments. While achieving optimality against generalized\nskew-elliptical alternatives, they remain quite powerful under a much broader\nclass of non-elliptical distributions and significantly outperform the\navailable competitors.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 09:27:59 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Babic", "Sladana", ""], ["Gelbgras", "Laetitia", ""], ["Hallin", "Marc", ""], ["Ley", "Christophe", ""]]}, {"id": "1911.08272", "submitter": "Lewis Bowen", "authors": "Dylan Airey, Lewis Bowen and Frank Lin", "title": "A topological dynamical system with two different positive sofic\n  entropies", "comments": "This new version corrects a number of minor errors in the previous\n  version", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.DS math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A sofic approximation to a countable group is a sequence of partial actions\non finite sets that asymptotically approximates the action of the group on\nitself by left-translations. A group is sofic if it admits a sofic\napproximation. Sofic entropy theory is a generalization of classical entropy\ntheory in dynamics to actions by sofic groups. However, the sofic entropy of an\naction may depend on a choice of sofic approximation. All previously known\nexamples showing this dependence rely on degenerate behavior. This paper\nexhibits an explicit example of a mixing subshift of finite type with two\ndifferent positive sofic entropies. The example is inspired by statistical\nphysics literature on 2-colorings of random hyper-graphs.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 14:06:47 GMT"}, {"version": "v2", "created": "Sat, 20 Mar 2021 21:28:23 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Airey", "Dylan", ""], ["Bowen", "Lewis", ""], ["Lin", "Frank", ""]]}, {"id": "1911.08412", "submitter": "Indranil SenGupta", "authors": "Michael Roberts and Indranil SenGupta", "title": "Infinitesimal generators for two-dimensional L\\'evy process-driven\n  hypothesis testing", "comments": null, "journal-ref": null, "doi": "10.1007/s10436-019-00355-y", "report-no": null, "categories": "math.ST q-fin.MF stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present the testing of four hypotheses on two streams of\nobservations that are driven by L\\'evy processes. This is applicable for\nsequential decision making on the state of two-sensor systems. In one case,\neach sensor receives or does not receive a signal obstructed by noise. In\nanother, each sensor receives data-driven by L\\'evy processes with large or\nsmall jumps. In either case, these give rise to four possibilities.\nInfinitesimal generators are presented and analyzed. Bounds for infinitesimal\ngenerators in terms of \\emph{super-solutions} and \\emph{sub-solutions} are\ncomputed. An application of this procedure for the stochastic model is also\npresented in relation to the financial market.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 16:26:44 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Roberts", "Michael", ""], ["SenGupta", "Indranil", ""]]}, {"id": "1911.08468", "submitter": "Wicher Bergsma", "authors": "Wicher Bergsma", "title": "Discussion contribution \"Functional models for time-varying random\n  objects'' by Dubey and M\\\"uller (to appear in JRSS-B)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In an inspiring paper Dubey and M\\\"uller (DM) extend PCA to the case that\nobservations are metric-valued functions. As an alternative, we develop a\nkernel PCA approach, which we show is closely related to the DM approach. While\nkernel principal components (kPCs) are simply defined, DM require added\ncomplexity in the form of \"object FPCs'' and \"Fr\\'echet scores\".\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 18:53:21 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Bergsma", "Wicher", ""]]}, {"id": "1911.08662", "submitter": "Kenichiro McAlinn", "authors": "K\\=osaku Takanashi and Kenichiro McAlinn", "title": "Predictions with dynamic Bayesian predictive synthesis are exact minimax", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST econ.EM stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the combination of multiple predictive distributions for time\nseries data when all forecasts are misspecified. We show that a specific\ndynamic form of Bayesian predictive synthesis -- a general and coherent\nBayesian framework for ensemble methods -- produces exact minimax predictive\ndensities with regard to Kullback-Leibler loss, providing theoretical support\nfor finite sample predictive performance over existing ensemble methods. A\nsimulation study that highlights this theoretical result is presented, showing\nthat dynamic Bayesian predictive synthesis is superior to other ensemble\nmethods using multiple metrics.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 01:46:24 GMT"}, {"version": "v2", "created": "Mon, 2 Dec 2019 05:35:43 GMT"}, {"version": "v3", "created": "Tue, 13 Oct 2020 05:16:37 GMT"}, {"version": "v4", "created": "Sat, 3 Jul 2021 15:13:26 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Takanashi", "K\u014dsaku", ""], ["McAlinn", "Kenichiro", ""]]}, {"id": "1911.09063", "submitter": "Yizhe Zhu", "authors": "Zhixin Zhou, Yizhe Zhu", "title": "Sparse random tensors: Concentration, regularization and applications", "comments": "24 pages", "journal-ref": "Electron. J. Statist. 15(1): 2483-2516 (2021)", "doi": "10.1214/21-EJS1838", "report-no": null, "categories": "math.PR math.CO math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove a non-asymptotic concentration inequality for the spectral norm of\nsparse inhomogeneous random tensors with Bernoulli entries. For an order-$k$\ninhomogeneous random tensor $T$ with sparsity $p_{\\max}\\geq \\frac{c\\log n}{n\n}$, we show that $\\|T-\\mathbb E T\\|=O(\\sqrt{n p_{\\max}}\\log^{k-2}(n))$ with\nhigh probability. The optimality of this bound up to polylog factors is\nprovided by an information theoretic lower bound. By tensor unfolding, we\nextend the range of sparsity to $p_{\\max}\\geq \\frac{c\\log n}{n^{m}}$ with\n$1\\leq m\\leq k-1$ and obtain concentration inequalities for different sparsity\nregimes. We also provide a simple way to regularize $T$ such that\n$O(\\sqrt{n^{m}p_{\\max}})$ concentration still holds down to sparsity\n$p_{\\max}\\geq \\frac{c}{n^{m}}$ with $k/2\\leq m\\leq k-1$. We present our\nconcentration and regularization results with two applications: (i) a\nrandomized construction of hypergraphs of bounded degrees with good expander\nmixing properties, (ii) concentration of sparsified tensors under uniform\nsampling.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 17:50:55 GMT"}, {"version": "v2", "created": "Fri, 22 Nov 2019 04:05:31 GMT"}, {"version": "v3", "created": "Mon, 2 Dec 2019 05:11:32 GMT"}, {"version": "v4", "created": "Mon, 23 Dec 2019 03:16:02 GMT"}, {"version": "v5", "created": "Tue, 23 Mar 2021 19:43:11 GMT"}, {"version": "v6", "created": "Sun, 28 Mar 2021 05:23:01 GMT"}, {"version": "v7", "created": "Tue, 4 May 2021 05:20:31 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Zhou", "Zhixin", ""], ["Zhu", "Yizhe", ""]]}, {"id": "1911.09260", "submitter": "Yifan Cui", "authors": "Yifan Cui, Eric Tchetgen Tchetgen", "title": "A semiparametric instrumental variable approach to optimal treatment\n  regimes under endogeneity", "comments": "To appear in Journal of the American Statistical Association", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a fast-growing literature on estimating optimal treatment regimes\nbased on randomized trials or observational studies under a key identifying\ncondition of no unmeasured confounding. Because confounding by unmeasured\nfactors cannot generally be ruled out with certainty in observational studies\nor randomized trials subject to noncompliance, we propose a general\ninstrumental variable approach to learning optimal treatment regimes under\nendogeneity. Specifically, we establish identification of both value function\n$E[Y_{\\mathcal{D}(L)}]$ for a given regime $\\mathcal{D}$ and optimal regimes\n$\\text{argmax}_{\\mathcal{D}} E[Y_{\\mathcal{D}(L)}]$ with the aid of a binary\ninstrumental variable, when no unmeasured confounding fails to hold. We also\nconstruct novel multiply robust classification-based estimators. Furthermore,\nwe propose to identify and estimate optimal treatment regimes among those who\nwould comply to the assigned treatment under a standard monotonicity\nassumption. In this latter case, we establish the somewhat surprising result\nthat complier optimal regimes can be consistently estimated without directly\ncollecting compliance information and therefore without the complier average\ntreatment effect itself being identified. Our approach is illustrated via\nextensive simulation studies and a data application on the effect of child\nrearing on labor participation.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 03:10:08 GMT"}, {"version": "v2", "created": "Thu, 6 Feb 2020 00:22:59 GMT"}, {"version": "v3", "created": "Mon, 13 Apr 2020 16:52:58 GMT"}, {"version": "v4", "created": "Thu, 21 May 2020 20:24:14 GMT"}, {"version": "v5", "created": "Fri, 12 Jun 2020 16:09:39 GMT"}, {"version": "v6", "created": "Thu, 25 Jun 2020 20:43:31 GMT"}, {"version": "v7", "created": "Sat, 4 Jul 2020 01:13:19 GMT"}, {"version": "v8", "created": "Mon, 10 Aug 2020 19:35:06 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Cui", "Yifan", ""], ["Tchetgen", "Eric Tchetgen", ""]]}, {"id": "1911.09620", "submitter": "Marco Bianucci", "authors": "Marco Bianucci and Mauro Bologna", "title": "About the foundation of the Kubo Generalized Cumulants theory. A\n  revisited and corrected approach", "comments": null, "journal-ref": null, "doi": "10.1088/1742-5468/ab7755", "report-no": null, "categories": "math-ph math.MP math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  More than fifty years ago, in a couple of seminal works Kubo introduced the\nimportant idea of generalized cumulants, extending to stochastic operators this\nconcept, implicitly introduced by Laplace in 1810. Kubo's idea has been applied\nin several branches of physics, where the result of the average process is a\nLioville operator or an effective time evolution operator for the density\nmatrix of spin systems or the reduced density matrix for boson-fermions etc.\nDespite this success, the theoretical developments in these Kubo works pose\nproblems that were highlighted many years ago by Fox and van Kampen and never\nsolved. These weaknesses and errors, in particular concerning the factorization\nproperty of exponentials of cumulants and the explicit expressions that give\ngeneralized cumulants in terms of generalized moments and vice-versa, caused\nsome perplexity (and confusion) about the possible application of this\nprocedure, limiting its use, in practice. In the present paper, we give a sound\nground to the approach to cumulant operators, working in a general framework\nthat shows the potentiality of the old Kubo's idea, today not yet fully\nexploited. It results that for the same moment operators, different definitions\nof generalized cumulants can be adopted. A general Kubo-Meeron closed-form\nformula giving cumulant operators in terms of moment operators cannot be\nobtained, but the reverse one, cumulants in terms of operators, is given and,\nnoticeably, formally it {\\em does not} depend on the specific nature of the\nmoments, but just on the definition of the generalized cumulants.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 17:28:50 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Bianucci", "Marco", ""], ["Bologna", "Mauro", ""]]}, {"id": "1911.09625", "submitter": "Lionel Barnett", "authors": "A. J. Gutknecht and L. Barnett", "title": "Sampling distribution for single-regression Granger causality estimators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show for the first time that, under the null hypothesis of vanishing\nGranger causality, the single-regression Granger-Geweke estimator converges to\na generalised $\\chi^2$ distribution, which may be well approximated by a\n$\\Gamma$ distribution. We show that this holds too for Geweke's spectral\ncausality averaged over a given frequency band, and derive explicit expressions\nfor the generalised $\\chi^2$ and $\\Gamma$-approximation parameters in both\ncases. We present an asymptotically valid Neyman-Pearson test based on the\nsingle-regression estimators, and discuss in detail how it may be usefully\nemployed in realistic scenarios where autoregressive model order is unknown or\ninfinite. We outline how our analysis may be extended to the conditional case,\npoint-frequency spectral Granger causality, state-space Granger causality, and\nthe Granger causality $F$-test statistic. Finally, we discuss approaches to\napproximating the distribution of the single-regression estimator under the\nalternative hypothesis.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 17:34:24 GMT"}, {"version": "v2", "created": "Thu, 25 Feb 2021 10:54:03 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Gutknecht", "A. J.", ""], ["Barnett", "L.", ""]]}, {"id": "1911.09680", "submitter": "Chandanie Navaratna", "authors": "Richard A. Lockhart and Chandanie W. Navaratna", "title": "On comparison of estimators for proportional error nonlinear regression\n  models in the limit of small measurement error", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we compare maximum likelihood (ML), quasi likelihood (QL) and\nweighted least squares (WLS) estimators for proportional error nonlinear\nregression models. Literature on thermoluminescence sedimentary dating revealed\nanother estimator similar to weighted least squares but observed responses used\nas weights. This estimator that we refer to as data weighted least squares\n(DWLS) is also included in the comparison. We show that on the order $\\sigma, $\nall four estimators behave similar to ordinary least squares estimators for\nstandard linear regression models. On the order of $\\sigma^2, $ the estimators\nhave biases. Formulae that are valid in the limit of small measurement error\nare derived for the biases and the variances of the four estimators. The\nmaximum likelihood estimator has less bias compared to the quasi likelihood\nestimator. Conditions are derived under which weighted least squares and\nmaximum likelihood estimators have similar biases. On the order of $\\sigma^ {2}\n$, all estimators have similar standard errors. On higher order of $\\sigma$,\nmaximum likelihood estimator has smaller variance compared to quasi likelihood\nestimator, provided that the random errors have the same first four moments as\nthe normal distribution. The maximum likelihood and quasi-likelihood estimating\nequations are unbiased. In large samples, these two estimators are distributed\nas multivariate normal. The estimating equations for weighted least squares and\ndata weighted least squares are biased. However, in the limit of $\\sigma \\to 0$\nand $n \\to \\infty, $ if $ n^ {1/2} \\sigma$ remains bounded, these two\nestimators are also distributed as multivariate normal. A simulation study\njustified the applicability of the derived formulae in the presence of\nmeasurement errors typical in sedimentary data. Results are illustrated with a\ndata set from thermoluminescence sedimentary dating.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 01:43:44 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Lockhart", "Richard A.", ""], ["Navaratna", "Chandanie W.", ""]]}, {"id": "1911.09714", "submitter": "Alden Green", "authors": "Alden Green, Sivaraman Balakrishnan, Ryan J. Tibshirani", "title": "Local Spectral Clustering of Density Upper Level Sets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the Personalized PageRank (PPR) algorithm, a local spectral method\nfor clustering, which extracts clusters using locally-biased random walks\naround a given seed node. In contrast to previous work, we adopt a classical\nstatistical learning setup, where we obtain samples from an unknown\ndistribution, and aim to identify connected regions of high-density (density\nclusters). We prove that PPR, run on a neighborhood graph, extracts\nsufficiently salient density clusters, that satisfy a set of natural geometric\nconditions. We also show a converse result, that PPR can fail to recover\ngeometrically poorly-conditioned density clusters, even asymptotically.\nFinally, we provide empirical support for our theory.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 19:25:36 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Green", "Alden", ""], ["Balakrishnan", "Sivaraman", ""], ["Tibshirani", "Ryan J.", ""]]}, {"id": "1911.09769", "submitter": "Arash Shaban-Nejad", "authors": "Eun Kyong Shin, Youngsang Kwon, Arash Shaban-Nejad", "title": "Geo-clustered chronic affinity: pathways from socio-economic\n  disadvantages to health disparities", "comments": null, "journal-ref": "JAMIA Open, Volume 2, Issue 3, October 2019, Pages 317-322", "doi": "10.1093/jamiaopen/ooz029", "report-no": null, "categories": "cs.CY math.ST stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Our objective was to develop and test a new concept (affinity) analogous to\nmultimorbidity of chronic conditions for individuals at census tract level in\nMemphis, TN. The use of affinity will improve the surveillance of multiple\nchronic conditions and facilitate the design of effective interventions. We\nused publicly available chronic condition data (Center for Disease Control and\nPrevention 500 Cities project), socio-demographic data (US Census Bureau), and\ndemographic data (Environmental Systems Research Institute). A geo-distinctive\npattern of clustered chronic affinity associated with socio-economic\ndeprivation wasobserved. Statistical results confirmed that neighborhoods with\nhigher rates of crime, poverty, and unemploy-ment were associated with an\nincreased likelihood of having a higher affinity among major chronic\nconditions.With the inclusion of smoking in the model, however, only the crime\nprevalence was statistically significantlyassociated with the chronic affinity.\nChronic affinity disadvantages were disproportionately accumulated in socially\ndisadvantagedareas. We showed links between commonly co-observed chronic\ndiseases at the population level and systemat-ically explored the complexity of\naffinity and socio-economic disparities. Our affinity score, based on\npubliclyavailable datasets, served as a surrogate for multimorbidity at the\npopulation level, which may assist policy-makers and public health planners to\nidentify urgent hot spots for chronic disease and allocate clinical, medicaland\nhealthcare resources efficiently.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 22:03:34 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Shin", "Eun Kyong", ""], ["Kwon", "Youngsang", ""], ["Shaban-Nejad", "Arash", ""]]}, {"id": "1911.09779", "submitter": "Melissa Humphries Dr", "authors": "Lachlann McArthur, Melissa A. Humphries", "title": "Multi-model mimicry for model selection according to generalised\n  goodness-of-fit criteria", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-model mimicry (MMM) is a flexible model selection technique for\ncomparison of multiple, non-nested models on any desired goodness-of-fit\ncriteria. Applicable to any set of candidate models that are 1) able to be fit\nto observed data, 2) can simulate new sets of data under the models, and 3)\nhave a metric by which a dataset's goodness-of-fit to the model can be\ncalculated, MMM has a much broader range of applicability than many standard\nmodel selection techniques. This manuscript highlights the previous literature\nwhilst presenting the theoretical framework underpinning MMM. The scope of\napplicability is broadened through presentation of generalised criteria for\ncomparison and the effectiveness of the method is demonstrated. Clear\ninstruction for the application of MMM and the classification techniques\nrequired for model selection are also included.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 23:04:35 GMT"}, {"version": "v2", "created": "Sun, 15 Dec 2019 23:48:44 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["McArthur", "Lachlann", ""], ["Humphries", "Melissa A.", ""]]}, {"id": "1911.09910", "submitter": "Monimoy Bujarbaruah", "authors": "Monimoy Bujarbaruah, Akhil Shetty, Kameshwar Poolla, Francesco\n  Borrelli", "title": "Learning Robustness with Bounded Failure: An Iterative MPC Approach", "comments": "Added GitHub link to all source codes", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.SY math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an approach to design a Model Predictive Controller (MPC) for\nconstrained Linear Time Invariant systems performing an iterative task. The\nsystem is subject to an additive disturbance, and the goal is to learn to\nsatisfy state and input constraints robustly. Using disturbance measurements\nafter each iteration, we construct Confidence Support sets, which contain the\ntrue support of the disturbance distribution with a given probability. As more\ndata is collected, the Confidence Supports converge to the true support of the\ndisturbance. This enables design of an MPC controller that avoids conservative\nestimate of the disturbance support, while simultaneously bounding the\nprobability of constraint violation. The efficacy of the proposed approach is\nthen demonstrated with a detailed numerical example.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 08:11:29 GMT"}, {"version": "v2", "created": "Mon, 4 May 2020 21:37:15 GMT"}, {"version": "v3", "created": "Tue, 30 Mar 2021 23:02:18 GMT"}, {"version": "v4", "created": "Mon, 12 Apr 2021 10:35:40 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Bujarbaruah", "Monimoy", ""], ["Shetty", "Akhil", ""], ["Poolla", "Kameshwar", ""], ["Borrelli", "Francesco", ""]]}, {"id": "1911.10114", "submitter": "Liam Solus", "authors": "Liam Solus", "title": "Distributional Invariances and Interventional Markov Equivalence for\n  Mixed Graph Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The invariance properties of interventional distributions relative to the\nobservational distribution, and how these properties allow us to refine Markov\nequivalence classes (MECs) of DAGs, is central to causal DAG discovery\nalgorithms that use both interventional and observational data. Here, we show\nhow the invariance properties of interventional DAG models, and the\ncorresponding refinement of MECs into interventional MECs, can be generalized\nto mixed graphical models that allow for latent cofounders and selection\nvariables. We first generalize interventional Markov equivalence to all formal\nindependence models associated to loopless mixed graphs. For ancestral graphs,\nwe prove the resulting interventional MECs admit a graphical characterization\ngeneralizing that of DAGs. We then define interventional distributions for\nacyclic directed mixed graph models, and prove that this generalization aligns\nwith the graphical generalization of interventional Markov equivalence given\nfor the formal independence models. This provides a framework for causal model\ndiscovery via observational and interventional data in the presence of latent\nconfounders that applies even when the interventions are uncontrolled.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 16:17:01 GMT"}, {"version": "v2", "created": "Sun, 7 Jun 2020 10:56:31 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Solus", "Liam", ""]]}, {"id": "1911.10251", "submitter": "Lohit Vandanapu", "authors": "Lohit Vandanapu, Michael D. Shields", "title": "3rd-order Spectral Representation Method: Part II -- Ergodic\n  Multi-variate random processes with fast Fourier transform", "comments": "43 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The second in a two-part series, this paper extends the 3rd-order Spectral\nRepresentation Method for simulation of ergodic multi-variate stochastic\nprocesses according to a prescribed cross power spectral density and cross\nbispectral density. The 2nd and 3rd order ensemble properties of the simulated\nstochastic vector processes are shown to satisfy the target cross correlation\nproperties in expectation. A multi-indexed frequency discretization is\nintroduced to ensure ergodicity of the sample functions. This is first shown\nfor uni-variate processes and then the simulation formula for multi-variate\nprocesses is provided. Ensemble properties and ergodicity of the sample\nfunctions are proven. Additionally, it is shown that the simulations can be\nimplemented efficiently with the Fast Fourier Transform, which greatly reduces\ncomputational effort. An example involving the simulation of turbulent wind\nvelocity fluctuations is presented to further highlight the features and\napplications of the algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 21:06:37 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Vandanapu", "Lohit", ""], ["Shields", "Michael D.", ""]]}, {"id": "1911.10387", "submitter": "Lixue Pang", "authors": "Geurt Jongbloed, Frank van der Meulen and Lixue Pang", "title": "Bayesian nonparametric estimation in the current status continuous mark\n  model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider the current status continuous mark model where, if\nthe event takes place before an inspection time $T$ a \"continuous mark\"\nvariable is observed as well.\n  A Bayesian nonparametric method is introduced for estimating the distribution\nfunction of the joint distribution of the event time ($X$) and mark ($Y$). We\nconsider a prior that is obtained by assigning a distribution on heights of\ncells, where cells are obtained from a partition of the support of the density\nof $(X, Y)$. As distribution on cell heights, we consider both a Dirichlet\nprior and a prior based on the graph-Laplacian on the specified partition. Our\nmain result shows that under appropriate conditions, the posterior distribution\nfunction contracts pointwisely at rate $\\left(n/\\log\nn\\right)^{-\\frac{\\rho}{3(\\rho+2)}}$, where $\\rho$ is the H\\\"older smoothness of\nthe true density. In addition to our theoretical results, we provide\ncomputational methods for drawing from the posterior using probabilistic\nprogramming. The performance of our computational methods is illustrated in two\nexamples.\n", "versions": [{"version": "v1", "created": "Sat, 23 Nov 2019 17:09:23 GMT"}, {"version": "v2", "created": "Sun, 14 Mar 2021 08:52:08 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Jongbloed", "Geurt", ""], ["van der Meulen", "Frank", ""], ["Pang", "Lixue", ""]]}, {"id": "1911.10604", "submitter": "Rong Ma", "authors": "Rong Ma, T. Tony Cai and Hongzhe Li", "title": "Optimal Permutation Recovery in Permuted Monotone Matrix Model", "comments": null, "journal-ref": "Journal of the American Statistical Association, 2020", "doi": "10.1080/01621459.2020.1713794", "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by recent research on quantifying bacterial growth dynamics based\non genome assemblies, we consider a permuted monotone matrix model\n$Y=\\Theta\\Pi+Z$, where the rows represent different samples, the columns\nrepresent contigs in genome assemblies and the elements represent log-read\ncounts after preprocessing steps and Guanine-Cytosine (GC) adjustment. In this\nmodel, $\\Theta$ is an unknown mean matrix with monotone entries for each row,\n$\\Pi$ is a permutation matrix that permutes the columns of $\\Theta$, and $Z$ is\na noise matrix. This paper studies the problem of estimation/recovery of $\\Pi$\ngiven the observed noisy matrix $Y$. We propose an estimator based on the best\nlinear projection, which is shown to be minimax rate-optimal for both exact\nrecovery, as measured by the 0-1 loss, and partial recovery, as quantified by\nthe normalized Kendall's tau distance. Simulation studies demonstrate the\nsuperior empirical performance of the proposed estimator over alternative\nmethods. We demonstrate the methods using a synthetic metagenomics dataset of\n45 closely related bacterial species and a real metagenomic dataset to compare\nthe bacterial growth dynamics between the responders and the non-responders of\nthe IBD patients after 8 weeks of treatment.\n", "versions": [{"version": "v1", "created": "Sun, 24 Nov 2019 20:36:42 GMT"}, {"version": "v2", "created": "Mon, 13 Jul 2020 21:30:45 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Ma", "Rong", ""], ["Cai", "T. Tony", ""], ["Li", "Hongzhe", ""]]}, {"id": "1911.10648", "submitter": "Jiaqi Yin", "authors": "Jiaqi Yin", "title": "A Note on Mixing in High Dimensional Time Series", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Various mixing conditions have been imposed on high dimensional time series,\nincluding the strong mixing ($\\alpha$-mixing), maximal correlation coefficient\n($\\rho$-mixing), absolute regularity ($\\beta$-mixing), and $\\phi$-mixing.\n$\\alpha$-mixing condition is a routine assumption when studying autoregression\nmodels. $\\rho$-mixing can lead to $\\alpha$-mixing. In this paper, we prove a\nway to verify $\\rho$-mixing under a high-dimensional triangular array time\nseries setting by using the Pearson's $\\phi^2$, mean square contingency. Vector\nautoregression model VAR(1) and vector autoregression moving average VARMA(1,1)\nare proved satisfying $\\rho$-mixing condition based on low rank setting.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 00:39:51 GMT"}, {"version": "v2", "created": "Tue, 26 Nov 2019 02:12:43 GMT"}, {"version": "v3", "created": "Sat, 7 Dec 2019 23:49:19 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Yin", "Jiaqi", ""]]}, {"id": "1911.10675", "submitter": "Ruriko Yoshida", "authors": "Robert Page and Leon Zhang and Ruriko Yoshida", "title": "Tropical principal component analysis on the space of ultrametrics", "comments": "26 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In 2019, Yoshida et al. introduced a notion of tropical principal component\nanalysis (PCA). The output is a tropical polytope with a fixed number of\nvertices that best fits the data. We here apply tropical PCA to dimension\nreduction and visualization of data sampled from the space of phylogenetic\ntrees. Our main results are twofold: the existence of a tropical cell\ndecomposition into regions of fixed tree topology and the development of a\nstochastic optimization method to estimate the tropical PCA using a Markov\nChain Monte Carlo (MCMC) approach. This method performs well with simulation\nstudies, and it is applied to three empirical datasets: Apicomplexa and African\ncoelacanth genomes as well as sequences of hemagglutinin for influenza from New\nYork.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 03:04:43 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Page", "Robert", ""], ["Zhang", "Leon", ""], ["Yoshida", "Ruriko", ""]]}, {"id": "1911.10682", "submitter": "Zhiqiang Tan", "authors": "Zhiqiang Tan", "title": "Analysis of odds, probability, and hazard ratios: From 2 by 2 tables to\n  two-sample survival data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analysis of 2 by 2 tables and two-sample survival data has been widely used.\nExact calculation is computational intractable for conditional likelihood\ninference in odds ratio models with large marginals in 2 by 2 tables, or\npartial likelihood inference in Cox's proportional hazards models with\nconsiderable tied event times. Approximate methods are often employed, but\ntheir statistical properties have not been formally studied while taking into\naccount the approximation involved. We develop new methods and theory by\nconstructing suitable estimating functions while leveraging knowledge from\nconditional or partial likelihood inference. We propose a weighted\nMantel--Haenszel estimator in an odds ratio model such as Cox's discrete-time\nproportional hazards model. Moreover, we consider a probability ratio model,\nand derive as a consistent estimator the Breslow--Peto estimator, which has\nbeen regarded as an approximation to partial likelihood estimation in the odds\nratio model. We study both model-based and model-robust variance estimation.\nFor the Breslow--Peto estimator, our new model-based variance estimator is no\ngreater than the commonly reported variance estimator. We present numerical\nstudies which support the theoretical findings.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 03:22:17 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Tan", "Zhiqiang", ""]]}, {"id": "1911.10955", "submitter": "Bruno Ebner", "authors": "Philip D\\\"orr, Bruno Ebner, Norbert Henze", "title": "A new test of multivariate normality by a double estimation in a\n  characterizing PDE", "comments": "16 pages, 1 figure, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with testing for nondegenerate normality of a $d$-variate\nrandom vector $X$ based on a random sample $X_1,\\ldots,X_n$ of $X$. The\nrationale of the test is that the characteristic function $\\psi(t) =\n\\exp(-\\|t\\|^2/2)$ of the standard normal distribution in $\\mathbb{R}^d$ is the\nonly solution of the partial differential equation $\\Delta f(t) =\n(\\|t\\|^2-d)f(t)$, $t \\in \\mathbb{R}^d$, subject to the condition $f(0) = 1$. By\ncontrast with a recent approach that bases a test for multivariate normality on\nthe difference $\\Delta \\psi_n(t)-(\\|t\\|^2-d)\\psi(t)$, where $\\psi_n(t)$ is the\nempirical characteristic function of suitably scaled residuals of\n$X_1,\\ldots,X_n$, we consider a weighted $L^2$-statistic that employs $\\Delta\n\\psi_n(t)-(\\|t\\|^2-d)\\psi_n(t)$. We derive asymptotic properties of the test\nunder the null hypothesis and alternatives. The test is affine invariant and\nconsistent against general alternatives, and it exhibits high power when\ncompared with prominent competitors.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 14:56:59 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["D\u00f6rr", "Philip", ""], ["Ebner", "Bruno", ""], ["Henze", "Norbert", ""]]}, {"id": "1911.11193", "submitter": "Lev B Klebanov", "authors": "Lev B. Klebanov and Zeev E. Vol'kovich", "title": "Some More Results on Characterization of the Exponential Distribution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are given characterizations of the exponential distribution by the\nproperties of the independence of linear forms with random coefficients.\nRelated results based on the constancy of regression of one statistic on a\nlinear form are obtained.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 19:54:54 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Klebanov", "Lev B.", ""], ["Vol'kovich", "Zeev E.", ""]]}, {"id": "1911.11199", "submitter": "Fran\\c{c}ois Bachoc", "authors": "Fran\\c{c}ois Bachoc, Jos\\'e B\\'etancourt, Reinhard Furrer, Thierry\n  Klein", "title": "Asymptotic properties of the maximum likelihood and cross validation\n  estimators for transformed Gaussian processes", "comments": "40 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The asymptotic analysis of covariance parameter estimation of Gaussian\nprocesses has been subject to intensive investigation. However, this asymptotic\nanalysis is very scarce for non-Gaussian processes. In this paper, we study a\nclass of non-Gaussian processes obtained by regular non-linear transformations\nof Gaussian processes. We provide the increasing-domain asymptotic properties\nof the (Gaussian) maximum likelihood and cross validation estimators of the\ncovariance parameters of a non-Gaussian process of this class. We show that\nthese estimators are consistent and asymptotically normal, although they are\ndefined as if the process was Gaussian. They do not need to model or estimate\nthe non-linear transformation. Our results can thus be interpreted as a\nrobustness of (Gaussian) maximum likelihood and cross validation towards\nnon-Gaussianity. Our proofs rely on two technical results that are of\nindependent interest for the increasing-domain asymptotic literature of spatial\nprocesses. First, we show that, under mild assumptions, coefficients of\ninverses of large covariance matrices decay at an inverse polynomial rate as a\nfunction of the corresponding observation location distances. Second, we\nprovide a general central limit theorem for quadratic forms obtained from\ntransformed Gaussian processes. Finally, our asymptotic results are illustrated\nby numerical simulations.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 20:05:12 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Bachoc", "Fran\u00e7ois", ""], ["B\u00e9tancourt", "Jos\u00e9", ""], ["Furrer", "Reinhard", ""], ["Klein", "Thierry", ""]]}, {"id": "1911.11202", "submitter": "Ilya Pavlyukevich", "authors": "Alexander Gushchin, Ilya Pavlyukevich and Marian Ritsch", "title": "Drift Estimation for a L\\'evy-Driven Ornstein-Uhlenbeck Process with\n  Heavy Tails", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of estimation of the drift parameter of an ergodic\nOrnstein--Uhlenbeck type process driven by a L\\'evy process with heavy tails.\nThe process is observed continuously on a long time interval $[0,T]$,\n$T\\to\\infty$. We prove that the statistical model is locally asymptotic mixed\nnormal and the maximum likelihood estimator is asymptotically efficient.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 20:09:36 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Gushchin", "Alexander", ""], ["Pavlyukevich", "Ilya", ""], ["Ritsch", "Marian", ""]]}, {"id": "1911.11345", "submitter": "Abhishek Chakrabortty", "authors": "Abhishek Chakrabortty, Jiarui Lu, T. Tony Cai and Hongzhe Li", "title": "High Dimensional M-Estimation with Missing Outcomes: A Semi-Parametric\n  Framework", "comments": "34 pages, 4 tables; (Supplement: 58 pages, 10 tables);", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider high dimensional $M$-estimation in settings where the response\n$Y$ is possibly missing at random and the covariates $\\mathbf{X} \\in\n\\mathbb{R}^p$ can be high dimensional compared to the sample size $n$. The\nparameter of interest $\\boldsymbol{\\theta}_0 \\in \\mathbb{R}^d$ is defined as\nthe minimizer of the risk of a convex loss, under a fully non-parametric model,\nand $\\boldsymbol{\\theta}_0$ itself is high dimensional which is a key\ndistinction from existing works. Standard high dimensional regression and\nseries estimation with possibly misspecified models and missing $Y$ are\nincluded as special cases, as well as their counterparts in causal inference\nusing 'potential outcomes'.\n  Assuming $\\boldsymbol{\\theta}_0$ is $s$-sparse ($s \\ll n$), we propose an\n$L_1$-regularized debiased and doubly robust (DDR) estimator of\n$\\boldsymbol{\\theta}_0$ based on a high dimensional adaptation of the\ntraditional double robust (DR) estimator's construction. Under mild tail\nassumptions and arbitrarily chosen (working) models for the propensity score\n(PS) and the outcome regression (OR) estimators, satisfying only some\nhigh-level conditions, we establish finite sample performance bounds for the\nDDR estimator showing its (optimal) $L_2$ error rate to be $\\sqrt{s (\\log d)/\nn}$ when both models are correct, and its consistency and DR properties when\nonly one of them is correct. Further, when both the models are correct, we\npropose a desparsified version of our DDR estimator that satisfies an\nasymptotic linear expansion and facilitates inference on low dimensional\ncomponents of $\\boldsymbol{\\theta}_0$. Finally, we discuss various of choices\nof high dimensional parametric/semi-parametric working models for the PS and OR\nestimators. All results are validated via detailed simulations.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 05:11:44 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Chakrabortty", "Abhishek", ""], ["Lu", "Jiarui", ""], ["Cai", "T. Tony", ""], ["Li", "Hongzhe", ""]]}, {"id": "1911.11422", "submitter": "Asaf Weinstein", "authors": "Asaf Weinstein", "title": "On Optimal Solutions to Compound Statistical Decision Problems", "comments": "The main result is, apparently, already known. See, e.g., Berger\n  (1985, Ch. 6), Greenshtein, E. & Ritov (2009)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a compound decision problem, consisting of $n$ statistically independent\ncopies of the same problem to be solved under the sum of the individual losses,\nany reasonable compound decision rule $\\delta$ satisfies a natural symmetry\nproperty, entailing that $\\delta(\\sigma(\\boldsymbol{y})) =\n\\sigma(\\delta(\\boldsymbol{y}))$ for any permutation $\\sigma$. We derive the\ngreatest lower bound on the risk of any such decision rule. The classical\nproblem of estimating the mean of a homoscedastic normal vector is used to\ndemonstrate the theory, but important extensions are presented as well in the\ncontext of Robbins's original ideas.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 09:42:44 GMT"}, {"version": "v2", "created": "Thu, 28 Nov 2019 10:12:05 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Weinstein", "Asaf", ""]]}, {"id": "1911.11470", "submitter": "Claudio Durastanti Dr.", "authors": "Alessia Caponera, Claudio Durastanti, and Anna Vidotto", "title": "LASSO estimation for spherical autoregressive processes", "comments": "32 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The purpose of the present paper is to investigate on a class of spherical\nfunctional autoregressive processes in order to introduce and study LASSO\n(Least Absolute Shrinkage and Selection Operator) type estimators for the\ncorresponding autoregressive kernels, defined in the harmonic domain by means\nof their spectral decompositions. Some crucial properties for these estimators\nare proved, in particular, consistency and oracle inequalities.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 11:44:37 GMT"}, {"version": "v2", "created": "Fri, 3 Jul 2020 07:55:01 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Caponera", "Alessia", ""], ["Durastanti", "Claudio", ""], ["Vidotto", "Anna", ""]]}, {"id": "1911.11562", "submitter": "Subhajit Goswami", "authors": "Sabyasachi Chatterjee and Subhajit Goswami", "title": "Adaptive Estimation of Multivariate Piecewise Polynomials and Bounded\n  Variation Functions by Optimal Decision Trees", "comments": "56 pages, 5 figures. The current version has been accepted for\n  publication in the Annals of Statistics", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Proposed by Donoho (1997), Dyadic CART is a nonparametric regression method\nwhich computes a globally optimal dyadic decision tree and fits piecewise\nconstant functions in two dimensions. In this article we define and study\nDyadic CART and a closely related estimator, namely Optimal Regression Tree\n(ORT), in the context of estimating piecewise smooth functions in general\ndimensions in the fixed design setup. More precisely, these optimal decision\ntree estimators fit piecewise polynomials of any given degree. Like Dyadic CART\nin two dimensions, we reason that these estimators can also be computed in\npolynomial time in the sample size $N$ via dynamic programming. We prove oracle\ninequalities for the finite sample risk of Dyadic CART and ORT which imply\ntight risk bounds for several function classes of interest. Firstly, they imply\nthat the finite sample risk of ORT of order $r \\geq 0$ is always bounded by $C\nk \\frac{\\log N}{N}$ whenever the regression function is piecewise polynomial of\ndegree $r$ on some reasonably regular axis aligned rectangular partition of the\ndomain with at most $k$ rectangles. Beyond the univariate case, such guarantees\nare scarcely available in the literature for computationally efficient\nestimators. Secondly, our oracle inequalities uncover minimax rate optimality\nand adaptivity of the Dyadic CART estimator for function spaces with bounded\nvariation. We consider two function spaces of recent interest where\nmultivariate total variation denoising and univariate trend filtering are the\nstate of the art methods. We show that Dyadic CART enjoys certain advantages\nover these estimators while still maintaining all their known guarantees.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 14:23:03 GMT"}, {"version": "v2", "created": "Sat, 14 Dec 2019 21:46:48 GMT"}, {"version": "v3", "created": "Thu, 14 Jan 2021 20:13:02 GMT"}], "update_date": "2021-01-18", "authors_parsed": [["Chatterjee", "Sabyasachi", ""], ["Goswami", "Subhajit", ""]]}, {"id": "1911.11581", "submitter": "Hanyuan Hang", "authors": "Hanyuan Hang", "title": "Histogram Transform Ensembles for Density Estimation", "comments": "arXiv admin note: text overlap with arXiv:1905.03729", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate an algorithm named histogram transform ensembles (HTE) density\nestimator whose effectiveness is supported by both solid theoretical analysis\nand significant experimental performance. On the theoretical side, by\ndecomposing the error term into approximation error and estimation error, we\nare able to conduct the following analysis: First of all, we establish the\nuniversal consistency under $L_1(\\mu)$-norm. Secondly, under the assumption\nthat the underlying density function resides in the H\\\"{o}lder space\n$C^{0,\\alpha}$, we prove almost optimal convergence rates for both single and\nensemble density estimators under $L_1(\\mu)$-norm and $L_{\\infty}(\\mu)$-norm\nfor different tail distributions, whereas in contrast, for its subspace\n$C^{1,\\alpha}$ consisting of smoother functions, almost optimal convergence\nrates can only be established for the ensembles and the lower bound of the\nsingle estimators illustrates the benefits of ensembles over single density\nestimators. In the experiments, we first carry out simulations to illustrate\nthat histogram transform ensembles surpass single histogram transforms, which\noffers powerful evidence to support the theoretical results in the space\n$C^{1,\\alpha}$. Moreover, to further exert the experimental performances, we\npropose an adaptive version of HTE and study the parameters by generating\nseveral synthetic datasets with diversities in dimensions and distributions.\nLast but not least, real data experiments with other state-of-the-art density\nestimators demonstrate the accuracy of the adaptive HTE algorithm.\n", "versions": [{"version": "v1", "created": "Sun, 24 Nov 2019 17:24:12 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Hang", "Hanyuan", ""]]}, {"id": "1911.11864", "submitter": "Paromita Dubey", "authors": "Paromita Dubey, Hans-Georg M\\\"uller", "title": "Fr\\'echet Change Point Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method to infer the presence and location of change-points in\nthe distribution of a sequence of independent data taking values in a general\nmetric space, where change-points are viewed as locations at which the\ndistribution of the data sequence changes abruptly in terms of either its\nFr\\'echet mean or Fr\\'echet variance or both. The proposed method is based on\ncomparisons of Fr\\'echet variances before and after putative change-point\nlocations and does not require a tuning parameter except for the specification\nof cut-off intervals near the endpoints where change-points are assumed not to\noccur. Our results include theoretical guarantees for consistency of the test\nunder contiguous alternatives when a change-point exists and also for\nconsistency of the estimated location of the change-point if it exists, where\nunder the null hypothesis of no change-point the limit distribution of the\nproposed scan function is the square of a standardized Brownian Bridge. These\nconsistency results are applicable for a broad class of metric spaces under\nmild entropy conditions. Examples include the space of univariate probability\ndistributions and the space of graph Laplacians for networks. Simulation\nstudies demonstrate the effectiveness of the proposed methods, both for\ninferring the presence of a change-point and estimating its location. We also\ndevelop theory that justifies bootstrap-based inference and illustrate the new\napproach with sequences of maternal fertility distributions and communication\nnetworks.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 22:20:39 GMT"}, {"version": "v2", "created": "Tue, 14 Jan 2020 03:47:40 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Dubey", "Paromita", ""], ["M\u00fcller", "Hans-Georg", ""]]}, {"id": "1911.11890", "submitter": "Soosan Beheshti", "authors": "Soosan Beheshti, Edward Nidoy, and Faizan Rahman", "title": "K-MACE and Kernel K-MACE Clustering", "comments": "13 pages, 4 Tables, 7 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.AP stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Determining the correct number of clusters (CNC) is an important task in data\nclustering and has a critical effect on finalizing the partitioning results.\nK-means is one of the popular methods of clustering that requires CNC. Validity\nindex methods use an additional optimization procedure to estimate the CNC for\nK-means. We propose an alternative validity index approach denoted by\nk-minimizing Average Central Error (KMACE). K-means is one of the popular\nmethods of clustering that requires CNC. Validity ACE is the average error\nbetween the true unavailable cluster center and the estimated cluster center\nfor each sample data. Kernel K-MACE is kernel K-means that is equipped with an\nefficient CNC estimator. In addition, kernel K_MACE includes the first\nautomatically tuned procedure for choosing the Gaussian kernel parameters.\nSimulation results for both synthetic and read data show superiority of K_MACE\nand kernel K-MACE over the conventional clustering methods not only in CNC\nestimation but also in the partitioning procedure.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 00:14:05 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Beheshti", "Soosan", ""], ["Nidoy", "Edward", ""], ["Rahman", "Faizan", ""]]}, {"id": "1911.12106", "submitter": "Ismael Castillo", "authors": "Isma\\\"el Castillo and Romain Mismer", "title": "Spike and Slab P\\'olya tree posterior distributions: adaptive inference", "comments": "40 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the density estimation model, the question of adaptive inference using\nP\\'olya tree-type prior distributions is considered. A class of prior densities\nhaving a tree structure, called spike-and-slab P\\'olya trees, is introduced.\nFor this class, two types of results are obtained: first, the Bayesian\nposterior distribution is shown to converge at the minimax rate for the\nsupremum norm in an adaptive way, for any H\\\"older regularity of the true\ndensity between $0$ and $1$, thereby providing adaptive counterparts to the\nresults for classical P\\'olya trees in Castillo (2017). Second, the question of\nuncertainty quantification is considered. An adaptive nonparametric\nBernstein-von Mises theorem is derived. Next, it is shown that, under a\nself-similarity condition on the true density, certain credible sets from the\nposterior distribution are adaptive confidence bands, having prescribed\ncoverage level and with a diameter shrinking at optimal rate in the minimax\nsense.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 12:30:58 GMT"}, {"version": "v2", "created": "Thu, 17 Sep 2020 13:05:26 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Castillo", "Isma\u00ebl", ""], ["Mismer", "Romain", ""]]}, {"id": "1911.12160", "submitter": "Abhik Ghosh PhD", "authors": "Tuhin Majumder, Ayanendranath Basu, Abhik Ghosh", "title": "On Robust Pseudo-Bayes Estimation for the Independent Non-homogeneous\n  Set-up", "comments": "Work in progress", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ordinary Bayes estimator based on the posterior density suffers from the\npotential problems of non-robustness under data contamination or outliers. In\nthis paper, we consider the general set-up of independent but non-homogeneous\n(INH) observations and study a robustified pseudo-posterior based estimation\nfor such parametric INH models. In particular, we focus on the\n$R^{(\\alpha)}$-posterior developed by Ghosh and Basu (2016) for IID data and\nlater extended by Ghosh and Basu (2017) for INH set-up, where its usefulness\nand desirable properties have been numerically illustrated. In this paper, we\ninvestigate the detailed theoretical properties of this robust pseudo Bayes\n$R^{(\\alpha)}$-posterior and associated $R^{(\\alpha)}$-Bayes estimate under the\ngeneral INH set-up with applications to fixed-design regressions. We derive a\nBernstein von-Mises types asymptotic normality results and Laplace type\nasymptotic expansion of the $R^{(\\alpha)}$-posterior as well as the asymptotic\ndistributions of the expected $R^{(\\alpha)}$-posterior estimators. The required\nconditions and the asymptotic results are simplified for linear regressions\nwith known or unknown error variance and logistic regression models with fixed\ncovariates. The robustness of the $R^{(\\alpha)}$-posterior and associated\nestimators are theoretically examined through appropriate influence function\nanalyses under general INH set-up; illustrations are provided for the case of\nlinear regression. A high breakdown point result is derived for the expected\n$R^{(\\alpha)}$-posterior estimators of the location parameter under a\nlocation-scale type model. Some interesting real life data examples illustrate\npossible applications.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 14:05:40 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Majumder", "Tuhin", ""], ["Basu", "Ayanendranath", ""], ["Ghosh", "Abhik", ""]]}, {"id": "1911.12198", "submitter": "Florencia Leonardi", "authors": "Florencia Leonardi, Rodrigo R.S. Carvalho and Iara M. Frondana", "title": "Strong structure recovery for partially observed discrete Markov random\n  fields on graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a penalized pseudo-likelihood criterion to estimate the graph of\nconditional dependencies in a discrete Markov random field that can be\npartially observed. We prove the convergence of the estimator in the case of a\nfinite or countable infinite set of variables. In the finite case the\nunderlying graph can be recovered with probability one, while in the countable\ninfinite case we can recover any finite sub-graph with probability one, by\nallowing the candidate neighborhoods to grow with the sample size n and\nprovided the penalizing constant is sufficiently large. Our method requires\nminimal assumptions on the probability distribution and contrary to other\napproaches in the literature, the usual positivity condition is not needed. We\nevaluate the performance of the estimator on simulated data and we apply the\nmethodology to a real dataset of stock index markets in different countries.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 14:56:51 GMT"}, {"version": "v2", "created": "Wed, 5 Aug 2020 12:09:04 GMT"}, {"version": "v3", "created": "Thu, 8 Jul 2021 19:29:58 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Leonardi", "Florencia", ""], ["Carvalho", "Rodrigo R. S.", ""], ["Frondana", "Iara M.", ""]]}, {"id": "1911.12400", "submitter": "Francisco Novoa Mu\\~noz", "authors": "Pablo Gonz\\'alez-Albornoz and Francisco Novoa-Mu\\~noz", "title": "Goodness-of-fit test for the bivariate Hermite distribution", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the goodness of fit test for the bivariate Hermite\ndistribution. Specifically, we propose and study a Cram\\'er-von Mises-type test\nbased on the empirical probability generation function. The bootstrap can be\nused to consistently estimate the null distribution of the test statistics. A\nsimulation study investigates the goodness of the bootstrap approach for finite\nsample sizes.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 19:53:12 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Gonz\u00e1lez-Albornoz", "Pablo", ""], ["Novoa-Mu\u00f1oz", "Francisco", ""]]}, {"id": "1911.12516", "submitter": "Rong Ma", "authors": "Rong Ma, T. Tony Cai and Hongzhe Li", "title": "Optimal Estimation of Bacterial Growth Rates Based on Permuted Monotone\n  Matrix", "comments": null, "journal-ref": "Biometrika (2020)", "doi": "10.1093/biomet/asaa082", "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the problem of estimating the bacterial growth rates for genome\nassemblies from shotgun metagenomic data, we consider the permuted monotone\nmatrix model $Y=\\Theta\\Pi+Z$, where $Y\\in \\mathbb{R}^{n\\times p}$ is observed,\n$\\Theta\\in \\mathbb{R}^{n\\times p}$ is an unknown approximately rank-one signal\nmatrix with monotone rows, $\\Pi \\in \\mathbb{R}^{p\\times p}$ is an unknown\npermutation matrix, and $Z\\in \\mathbb{R}^{n\\times p}$ is the noise matrix. This\npaper studies the estimation of the extreme values associated to the signal\nmatrix $\\Theta$, including its first and last columns, as well as their\ndifference. Treating these estimation problems as compound decision problems,\nminimax rate-optimal estimators are constructed using the spectral column\nsorting method. Numerical experiments through simulated and synthetic\nmicrobiome metagenomic data are presented, showing the superiority of the\nproposed methods over the alternatives. The methods are illustrated by\ncomparing the growth rates of gut bacteria between inflammatory bowel disease\npatients and normal controls.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 03:51:42 GMT"}, {"version": "v2", "created": "Wed, 26 Aug 2020 17:49:17 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Ma", "Rong", ""], ["Cai", "T. Tony", ""], ["Li", "Hongzhe", ""]]}, {"id": "1911.12568", "submitter": "Ramya Korlakai Vinayak", "authors": "Ramya Korlakai Vinayak, Weihao Kong, Sham M. Kakade", "title": "Optimal Estimation of Change in a Population of Parameters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Paired estimation of change in parameters of interest over a population plays\na central role in several application domains including those in the social\nsciences, epidemiology, medicine and biology. In these domains, the size of the\npopulation under study is often very large, however, the number of observations\navailable per individual in the population is very small (\\emph{sparse\nobservations}) which makes the problem challenging. Consider the setting with\n$N$ independent individuals, each with unknown parameters $(p_i, q_i)$ drawn\nfrom some unknown distribution on $[0, 1]^2$. We observe $X_i \\sim\n\\text{Bin}(t, p_i)$ before an event and $Y_i \\sim \\text{Bin}(t, q_i)$ after the\nevent. Provided these paired observations, $\\{(X_i, Y_i) \\}_{i=1}^N$, our goal\nis to accurately estimate the \\emph{distribution of the change in parameters},\n$\\delta_i := q_i - p_i$, over the population and properties of interest like\nthe \\emph{$\\ell_1$-magnitude of the change} with sparse observations ($t\\ll\nN$). We provide \\emph{information theoretic lower bounds} on the error in\nestimating the distribution of change and the $\\ell_1$-magnitude of change.\nFurthermore, we show that the following two step procedure achieves the optimal\nerror bounds: first, estimate the full joint distribution of the paired\nparameters using the maximum likelihood estimator (MLE) and then estimate the\ndistribution of change and the $\\ell_1$-magnitude of change using the joint\nMLE. Notably, and perhaps surprisingly, these error bounds are of the same\norder as the minimax optimal error bounds for learning the \\emph{full} joint\ndistribution itself (in Wasserstein-1 distance); in other words, estimating the\nmagnitude of the change of parameters over the population is, in a minimax\nsense, as difficult as estimating the full joint distribution itself.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 07:43:03 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Vinayak", "Ramya Korlakai", ""], ["Kong", "Weihao", ""], ["Kakade", "Sham M.", ""]]}, {"id": "1911.12612", "submitter": "Tanujit Chakraborty", "authors": "Swarup Chattopadhyay, Tanujit Chakraborty, Kuntal Ghosh, Asit K. das", "title": "Modified Lomax Model: A heavy-tailed distribution for fitting\n  large-scale real-world complex networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-world networks are generally claimed to be scale-free, meaning that the\ndegree distributions follow the classical power-law, at least asymptotically.\nYet, closer observation shows that the classical power-law distribution is\noften inadequate to meet the data characteristics due to the existence of a\nclearly identifiable non-linearity in the entire degree distribution in the\nlog-log scale. The present paper proposes a new variant of the popular\nheavy-tailed Lomax distribution which we named as the Modified Lomax (MLM)\ndistribution that can efficiently capture the crucial aspect of heavy-tailed\nbehavior of the entire degree distribution of real-world complex networks. The\nproposed MLM model, derived from a hierarchical family of Lomax distributions,\ncan efficiently fit the entire degree distribution of real-world networks\nwithout removing lower degree nodes as opposed to the classical power-law based\nfitting. The MLM distribution belongs to the maximum domain of attraction of\nthe Frechet distribution and is right tail equivalent to Pareto distribution.\nVarious statistical properties including characteristics of the maximum\nlikelihood estimates and asymptotic distributions have also been derived for\nthe proposed MLM model. Finally, the effectiveness of the proposed MLM model is\ndemonstrated through rigorous experiments over fifty real-world complex\nnetworks from diverse applied domains.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 09:35:29 GMT"}, {"version": "v2", "created": "Tue, 17 Dec 2019 06:41:21 GMT"}, {"version": "v3", "created": "Sun, 31 May 2020 05:29:08 GMT"}, {"version": "v4", "created": "Fri, 5 Jun 2020 11:48:09 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Chattopadhyay", "Swarup", ""], ["Chakraborty", "Tanujit", ""], ["Ghosh", "Kuntal", ""], ["das", "Asit K.", ""]]}, {"id": "1911.12732", "submitter": "Jun Jin", "authors": "Jun Jin, Chao Ying, Zhou Yu", "title": "Distributed estimation of principal support vector machines for\n  sufficient dimension reduction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The principal support vector machines method (Li et al., 2011) is a powerful\ntool for sufficient dimension reduction that replaces original predictors with\ntheir low-dimensional linear combinations without loss of information. However,\nthe computational burden of the principal support vector machines method\nconstrains its use for massive data. To address this issue, we in this paper\npropose two distributed estimation algorithms for fast implementation when the\nsample size is large. Both the two distributed sufficient dimension reduction\nestimators enjoy the same statistical efficiency as merging all the data\ntogether, which provides rigorous statistical guarantees for their application\nto large scale datasets. The two distributed algorithms are further adapt to\nprincipal weighted support vector machines (Shin et al., 2016) for sufficient\ndimension reduction in binary classification. The statistical accuracy and\ncomputational complexity of our proposed methods are examined through\ncomprehensive simulation studies and a real data application with more than\n600000 samples.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 14:42:18 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Jin", "Jun", ""], ["Ying", "Chao", ""], ["Yu", "Zhou", ""]]}, {"id": "1911.12754", "submitter": "Bohao Yao", "authors": "Bohao Yao and Robin Evans", "title": "Algebraic Properties of Gaussian HTC-identifiable Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we explore some algebraic properties of linear structural\nequation modelsthat can be represented by an HTC-identifiable graph. In\nparticular, we prove that all mixedgraphs are HTC-identifiable if and only if\nall the regression coefficients can be recovered fromthe covariance matrix\nusing straightforward linear algebra operations. We also find a set\nofpolynomials that generates the ideal that encompasses all the equality\nconstraints of the modelon the cone of positive definite matrices. We further\nprove that this set of polynomials are theminimal generators of said ideal for\na subset of HTC-identifiable graphs.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 15:40:54 GMT"}, {"version": "v2", "created": "Sun, 14 Mar 2021 11:53:18 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Yao", "Bohao", ""], ["Evans", "Robin", ""]]}, {"id": "1911.12794", "submitter": "Othmane Mazhar", "authors": "Boualem Djehiche, Othmane Mazhar and Cristian R. Rojas", "title": "Finite impulse response models: A non-asymptotic analysis of the least\n  squares estimator", "comments": "23 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a finite impulse response system with centered independent\nsub-Gaussian design covariates and noise components that are not necessarily\nidentically distributed. We derive non-asymptotic near-optimal estimation and\nprediction bounds for the least-squares estimator of the parameters. Our\nresults are based on two concentration inequalities on the norm of sums of\ndependent covariate vectors and on the singular values of their covariance\noperator that are of independent value on their own and where the dependence\narises from the time shift structure of the time series. These results\ngeneralize the known bounds for the independent case.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 17:11:13 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Djehiche", "Boualem", ""], ["Mazhar", "Othmane", ""], ["Rojas", "Cristian R.", ""]]}, {"id": "1911.12827", "submitter": "Joona Karjalainen", "authors": "Tommi Gr\\\"ohn and Joona Karjalainen and Lasse Leskel\\\"a", "title": "Clique and cycle frequencies in a sparse random graph model with\n  overlapping communities", "comments": "23 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.SI math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A statistical network model with overlapping communities can be generated as\na superposition of mutually independent random graphs of varying size. The\nmodel is parameterized by a number of nodes, number of communities,\ndistribution of community sizes, and the edge probability inside the\ncommunities. This model admits sparse parameter regimes with power-law limiting\ndegree distributions, and nonvanishing clustering coefficient. This article\npresents large-scale approximations of clique and cycle frequencies for graph\nsamples generated by this model, which are valid for regimes with bounded and\nunbounded number of overlapping communities. Our results reveal the growth\nrates of these subgraph frequencies and show that their theoretical densities\ncan be reliably estimated from data.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 18:57:03 GMT"}, {"version": "v2", "created": "Sat, 8 Aug 2020 11:20:11 GMT"}, {"version": "v3", "created": "Thu, 13 May 2021 09:09:38 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Gr\u00f6hn", "Tommi", ""], ["Karjalainen", "Joona", ""], ["Leskel\u00e4", "Lasse", ""]]}, {"id": "1911.13142", "submitter": "Mohammad Ghorbani Dr.", "authors": "Ottmar Cronie, Mohammad Ghorbani, Jorge Mateu and Jun Yu", "title": "Functional marked point processes -- A natural structure to unify\n  spatio-temporal frameworks and to analyse dependent functional data", "comments": "44 pages, 3 figures with 9 plots", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.CO stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper treats functional marked point processes (FMPPs), which are\ndefined as marked point processes where the marks are random elements in some\n(Polish) function space. Such marks may represent e.g. spatial paths or\nfunctions of time. To be able to consider e.g. multivariate FMPPs, we also\nattach an additional, Euclidean, mark to each point. We indicate how FMPPs\nquite naturally connect the point process framework with both the functional\ndata analysis framework and the geostatistical framework. We further show that\nvarious existing models fit well into the FMPP framework. In addition, we\nintroduce a new family of summary statistics, weighted marked reduced moment\nmeasures, together with their non-parametric estimators, in order to study\nfeatures of the functional marks. We further show how they generalise other\nsummary statistics and we finally apply these tools to analyse population\nstructures, such as demographic evolution and sex ratio over time, in Spanish\nprovinces.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 15:10:50 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Cronie", "Ottmar", ""], ["Ghorbani", "Mohammad", ""], ["Mateu", "Jorge", ""], ["Yu", "Jun", ""]]}, {"id": "1911.13143", "submitter": "Krzysztof Bogdan Mr", "authors": "Krzysztof Bogdan and Micha{\\l} Bosy and Tomasz Skalski", "title": "Maximum likelihood estimation for discrete exponential families and\n  random graphs", "comments": "21 pages, minor editorial changes, added connections to the criterion\n  of Barndorff-Nielsen and linear programming", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.CO math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We characterize the existence of the maximum likelihood estimator for\ndiscrete exponential families. Our criterion is simple to apply as we show in\nvarious settings, most notably for exponential models of random graphs. As an\napplication, we point out the size of independent identically distributed\nsamples for which the maximum likelihood estimator exists with high\nprobability.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 15:12:17 GMT"}, {"version": "v2", "created": "Sat, 28 Dec 2019 22:31:02 GMT"}, {"version": "v3", "created": "Sun, 21 Feb 2021 17:51:36 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Bogdan", "Krzysztof", ""], ["Bosy", "Micha\u0142", ""], ["Skalski", "Tomasz", ""]]}, {"id": "1911.13268", "submitter": "Xue Chen", "authors": "Pranjal Awasthi, Vaggos Chatziafratis, Xue Chen, Aravindan\n  Vijayaraghavan", "title": "Adversarially Robust Low Dimensional Representations", "comments": "68 pages including references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many machine learning systems are vulnerable to small perturbations made to\nthe input either at test time or at training time. This has received much\nrecent interest on the empirical front due to several applications where\nreliability and security are critical, and the emergence of paradigms such as\nlow precision machine learning. However our theoretical understanding of the\ndesign of adversarially robust algorithms for the above settings is limited.\n  In this work we focus on Principal Component Analysis (PCA), a ubiquitous\nalgorithmic primitive in machine learning. We formulate a natural robust\nvariant of PCA, where the goal is to find a low dimensional subspace to\nrepresent the given data with minimum projection error, and that is in addition\nrobust to small perturbations measured in $\\ell_q$ norm (say $q=\\infty$).\nUnlike PCA which is solvable in polynomial time, our formulation is\ncomputationally intractable to optimize as it captures the well-studied sparse\nPCA objective as a special case. We show various algorithmic and statistical\nresults including:\n  - Polynomial time algorithm that is constant factor competitive in the\nworst-case, with respect to the best subspace both in terms of the projection\nerror and the robustness criterion. We also show that our algorithmic\ntechniques can be made robust to corruptions in the training data as well, in\naddition to yielding representations that are robust at test time.\n  - We prove that our formulation (and algorithms) also enjoy significant\nstatistical benefits in terms of sample complexity over standard PCA on account\nof a ``regularization effect'', that is formalized using the well-studied\nspiked covariance model.\n  - We illustrate the broad applicability of our algorithmic techniques in\naddressing robustness to adversarial perturbations, both at training-time and\ntest-time.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 18:06:29 GMT"}, {"version": "v2", "created": "Mon, 28 Dec 2020 03:46:13 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Awasthi", "Pranjal", ""], ["Chatziafratis", "Vaggos", ""], ["Chen", "Xue", ""], ["Vijayaraghavan", "Aravindan", ""]]}, {"id": "1911.13277", "submitter": "Lexing Ying", "authors": "Jun Qin, Lexing Ying", "title": "Hierarchical Low-rank Structure of Parameterized Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This note shows that the matrix forms of several one-parameter distribution\nfamilies satisfy a hierarchical low-rank structure. Such families of\ndistributions include binomial, Poisson, and $\\chi^2$ distributions. The proof\nis based on a uniform relative bound of a related divergence function.\nNumerical results are provided to confirm the theoretical findings.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 18:23:00 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Qin", "Jun", ""], ["Ying", "Lexing", ""]]}]