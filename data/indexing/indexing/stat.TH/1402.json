[{"id": "1402.0092", "submitter": "Peter Harremo\\\"es", "authors": "Peter Harremo\\\"es", "title": "Mutual information of Contingency Tables and Related Inequalities", "comments": "A version without the appendix has been submitted to a conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT math.IT stat.TH", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  For testing independence it is very popular to use either the\n$\\chi^{2}$-statistic or $G^{2}$-statistics (mutual information). Asymptotically\nboth are $\\chi^{2}$-distributed so an obvious question is which of the two\nstatistics that has a distribution that is closest to the\n$\\chi^{2}$-distribution. Surprisingly the distribution of mutual information is\nmuch better approximated by a $\\chi^{2}$-distribution than the\n$\\chi^{2}$-statistic. For technical reasons we shall focus on the simplest case\nwith one degree of freedom. We introduce the signed log-likelihood and\ndemonstrate that its distribution function can be related to the distribution\nfunction of a standard Gaussian by inequalities. For the hypergeometric\ndistribution we formulate a general conjecture about how close the signed\nlog-likelihood is to a standard Gaussian, and this conjecture gives much more\naccurate estimates of the tail probabilities of this type of distribution than\npreviously published results. The conjecture has been proved numerically in all\ncases relevant for testing independence and further evidence of its validity is\ngiven.\n", "versions": [{"version": "v1", "created": "Sat, 1 Feb 2014 15:28:20 GMT"}], "update_date": "2014-02-04", "authors_parsed": [["Harremo\u00ebs", "Peter", ""]]}, {"id": "1402.0099", "submitter": "Louis Theran", "authors": "Franz J. Kir\\'aly, Martin Kreuzer, and Louis Theran", "title": "Dual-to-kernel learning with ideals", "comments": "15 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.AC math.AG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a theory which unifies kernel learning and symbolic\nalgebraic methods. We show that both worlds are inherently dual to each other,\nand we use this duality to combine the structure-awareness of algebraic methods\nwith the efficiency and generality of kernels. The main idea lies in relating\npolynomial rings to feature space, and ideals to manifolds, then exploiting\nthis generative-discriminative duality on kernel matrices. We illustrate this\nby proposing two algorithms, IPCA and AVICA, for simultaneous manifold and\nfeature learning, and test their accuracy on synthetic and real world data.\n", "versions": [{"version": "v1", "created": "Sat, 1 Feb 2014 16:38:59 GMT"}], "update_date": "2014-02-04", "authors_parsed": [["Kir\u00e1ly", "Franz J.", ""], ["Kreuzer", "Martin", ""], ["Theran", "Louis", ""]]}, {"id": "1402.0125", "submitter": "Frank Masci", "authors": "Frank J. Masci (1), Douglas I. Hoffman (2), Carl J. Grillmair (1) and\n  Roc M. Cutri (1) ((1) California Institute of Technology, (2) NASA Ames\n  Research Center)", "title": "Automated Classification of Periodic Variable Stars detected by the\n  Wide-field Infrared Survey Explorer", "comments": "48 pages, 17 figures, 1 table, accepted by AJ", "journal-ref": null, "doi": "10.1088/0004-6256/148/1/21", "report-no": null, "categories": "astro-ph.IM astro-ph.SR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a methodology to classify periodic variable stars identified\nusing photometric time-series measurements constructed from the Wide-field\nInfrared Survey Explorer (WISE) full-mission single-exposure Source Databases.\nThis will assist in the future construction of a WISE Variable Source Database\nthat assigns variables to specific science classes as constrained by the WISE\nobserving cadence with statistically meaningful classification probabilities.\nWe have analyzed the WISE light curves of 8273 variable stars identified in\nprevious optical variability surveys (MACHO, GCVS, and ASAS) and show that\nFourier decomposition techniques can be extended into the mid-IR to assist with\ntheir classification. Combined with other periodic light-curve features, this\nsample is then used to train a machine-learned classifier based on the random\nforest (RF) method. Consistent with previous classification studies of variable\nstars in general, the RF machine-learned classifier is superior to other\nmethods in terms of accuracy, robustness against outliers, and relative\nimmunity to features that carry little or redundant class information. For the\nthree most common classes identified by WISE: Algols, RR Lyrae, and W Ursae\nMajoris type variables, we obtain classification efficiencies of 80.7%, 82.7%,\nand 84.5% respectively using cross-validation analyses, with 95% confidence\nintervals of approximately +/-2%. These accuracies are achieved at purity (or\nreliability) levels of 88.5%, 96.2%, and 87.8% respectively, similar to that\nachieved in previous automated classification studies of periodic variable\nstars.\n", "versions": [{"version": "v1", "created": "Sat, 1 Feb 2014 21:23:38 GMT"}, {"version": "v2", "created": "Tue, 13 May 2014 16:45:03 GMT"}], "update_date": "2015-06-18", "authors_parsed": [["Masci", "Frank J.", ""], ["Hoffman", "Douglas I.", ""], ["Grillmair", "Carl J.", ""], ["Cutri", "Roc M.", ""]]}, {"id": "1402.0142", "submitter": "Peng Ding", "authors": "Peng Ding", "title": "A paradox from randomization-based causal inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Under the potential outcomes framework, causal effects are defined as\ncomparisons between potential outcomes under treatment and control. To infer\ncausal effects from randomized experiments, Neyman proposed to test the null\nhypothesis of zero average causal effect (Neyman's null), and Fisher proposed\nto test the null hypothesis of zero individual causal effect (Fisher's null).\nAlthough the subtle difference between Neyman's null and Fisher's null has\ncaused lots of controversies and confusions for both theoretical and practical\nstatisticians, a careful comparison between the two approaches has been lacking\nin the literature for more than eighty years. We fill in this historical gap by\nmaking a theoretical comparison between them and highlighting an intriguing\nparadox that has not been recognized by previous researchers. Logically,\nFisher's null implies Neyman's null. It is therefore surprising that, in actual\ncompletely randomized experiments, rejection of Neyman's null does not imply\nrejection of Fisher's null for many realistic situations, including the case\nwith constant causal effect. Furthermore, we show that this paradox also exists\nin other commonly-used experiments, such as stratified experiments,\nmatched-pair experiments, and factorial experiments. Asymptotic analyses,\nnumerical examples, and real data examples all support this surprising\nphenomenon. Besides its historical and theoretical importance, this paradox\nalso leads to useful practical implications for modern researchers.\n", "versions": [{"version": "v1", "created": "Sun, 2 Feb 2014 01:46:14 GMT"}, {"version": "v2", "created": "Tue, 4 Feb 2014 05:03:34 GMT"}, {"version": "v3", "created": "Mon, 17 Mar 2014 20:14:11 GMT"}, {"version": "v4", "created": "Thu, 23 Jun 2016 18:11:58 GMT"}], "update_date": "2016-06-24", "authors_parsed": [["Ding", "Peng", ""]]}, {"id": "1402.0182", "submitter": "Tibor Pogany K.", "authors": "Tibor K Pog\\'any", "title": "The exponentiated exponential Poisson distribution revisited", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main aim of this article is to characterize and investigate the three\nparameter exponentiated exponential Poisson probability distribution ${\\rm\nEEP}(\\alpha, \\beta, \\lambda)$ by giving explicit closed form expressions for\nits characteristic function $\\phi_\\xi(t)$ and moment generating function\n$M_\\xi(t)$, and finally, to show that the existing series and integral form\nexpressions for positive integer order moments $\\mathbb E\\xi^\\nu, \\nu \\in\n\\mathbb N$ are in fact valid for all $\\nu>1-\\alpha, \\alpha>0$.\n", "versions": [{"version": "v1", "created": "Sun, 2 Feb 2014 12:24:24 GMT"}], "update_date": "2014-02-04", "authors_parsed": [["Pog\u00e1ny", "Tibor K", ""]]}, {"id": "1402.0183", "submitter": "Vydas \\v{C}ekanavi\\v{c}ius", "authors": "V. Cekanavicius, P. Vellaisamy", "title": "A Compound Poisson Convergence Theorem for Sums of $m$-Dependent\n  Variables", "comments": "to appear in Journal of Theoretical Probability", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove the Simons-Johnson theorem for the sums $S_n$ of $m$-dependent\nrandom variables, with exponential weights and limiting compound Poisson\ndistribution $\\CP(s,\\lambda)$. More precisely, we give sufficient conditions\nfor $\\sum_{k=0}^\\infty\\ee^{hk}\\ab{P(S_n=k)-\\CP(s,\\lambda)\\{k\\}}\\to 0$ and\nprovide an estimate on the rate of convergence. It is shown that the\nSimons-Johnson theorem holds for weighted Wasserstein norm as well. %limiting\nsum of two Poisson variables defined on %different lattices. The results are\nthen illustrated for $N(n;k_1,k_2)$ and $k$-runs statistics.\n", "versions": [{"version": "v1", "created": "Sun, 2 Feb 2014 12:24:46 GMT"}], "update_date": "2014-02-04", "authors_parsed": [["Cekanavicius", "V.", ""], ["Vellaisamy", "P.", ""]]}, {"id": "1402.0248", "submitter": "Giovanni Mana", "authors": "Giovanni Mana and CArlo Palmisano", "title": "Interval estimations in metrology", "comments": "11 pages, 5 figures, submitted to Metrologia", "journal-ref": null, "doi": "10.1088/0026-1394/51/3/191", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates interval estimation for a measurand that is known to\nbe positive. Both the Neyman and Bayesian procedures are considered and the\ndifference between the two, not always perceived, is discussed in detail. A\nsolution is proposed to a paradox originated by the frequentist assessment of\nthe long-run success rate of Bayesian intervals.\n", "versions": [{"version": "v1", "created": "Sun, 2 Feb 2014 21:19:22 GMT"}], "update_date": "2015-06-18", "authors_parsed": [["Mana", "Giovanni", ""], ["Palmisano", "CArlo", ""]]}, {"id": "1402.0277", "submitter": "Sreenivasan Ravi Ph.D.", "authors": "Sreenivasan Ravi, Ali Saeb", "title": "On convergence of entropy of distribution functions in the max domain of\n  attraction of max stable laws", "comments": "9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Max stable laws are limit laws of linearly normalized partial maxima of\nindepen- dent, identically distributed (iid) random variables (rvs). These are\nanalogous to stable laws which are limit laws of normalized partial sums of iid\nrvs. In this paper, we study entropy limit theorems for distribution functions\nin the max domain of attraction of max stable laws under linear normalization.\nMore specifically, we study the problem of convergence of the Shannon entropy\nof linearly normalized partial maxima of iid rvs to the corresponding limit\nentropy when the linearly normalized partial maxima converges to some\nnondegenerate rv. We are able to show that the Shannon entropy not only\nconverges but, in fact, increases to the limit entropy in some cases. We\ndiscuss several examples. We also study analogous results for the k-th upper\nextremes.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2014 04:02:53 GMT"}], "update_date": "2016-11-25", "authors_parsed": [["Ravi", "Sreenivasan", ""], ["Saeb", "Ali", ""]]}, {"id": "1402.0302", "submitter": "Yuzo Maruyama", "authors": "Yuzo Maruyama", "title": "l_p-norm based James-Stein estimation with minimaxity and sparsity", "comments": "11 pages, A new section for unknown scale case is added and a minor\n  revision is done", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new class of minimax Stein-type shrinkage estimators of a multivariate\nnormal mean is studied where the shrinkage factor is based on an l_p norm. The\nproposed estimators allow some but not all coordinates to be estimated by 0\nthereby allow sparsity as well as minimaxity.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2014 08:15:35 GMT"}, {"version": "v2", "created": "Thu, 28 May 2015 10:07:54 GMT"}], "update_date": "2015-05-29", "authors_parsed": [["Maruyama", "Yuzo", ""]]}, {"id": "1402.0346", "submitter": "Audrone Virbickaite", "authors": "Audron\\.e Virbickait\\.e, M. Concepci\\'on Aus\\'in, Pedro Galeano", "title": "Bayesian Inference Methods for Univariate and Multivariate GARCH Models:\n  a Survey", "comments": "28 pages, 3 figures", "journal-ref": null, "doi": "10.1111/joes.12046", "report-no": null, "categories": "math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This survey reviews the existing literature on the most relevant Bayesian\ninference methods for univariate and multivariate GARCH models. The advantages\nand drawbacks of each procedure are outlined as well as the advantages of the\nBayesian approach versus classical procedures. The paper makes emphasis on\nrecent Bayesian non-parametric approaches for GARCH models that avoid imposing\narbitrary parametric distributional assumptions. These novel approaches\nimplicitly assume infinite mixture of Gaussian distributions on the\nstandardized returns which have been shown to be more flexible and describe\nbetter the uncertainty about future volatilities. Finally, the survey presents\nan illustration using real data to show the flexibility and usefulness of the\nnon-parametric approach.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2014 11:32:05 GMT"}], "update_date": "2014-02-04", "authors_parsed": [["Virbickait\u0117", "Audron\u0117", ""], ["Aus\u00edn", "M. Concepci\u00f3n", ""], ["Galeano", "Pedro", ""]]}, {"id": "1402.0357", "submitter": "Antoine Dematteo", "authors": "St\\'ephan Cl\\'emen\\c{c}on (LTCI), Antoine Dematteo (TSI)", "title": "On Tail Index Estimation based on Multivariate Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article is devoted to the study of tail index estimation based on i.i.d.\nmultivariate observations, drawn from a standard heavy-tailed distribution,\ni.e. of which 1-d Pareto-like marginals share the same tail index. A\nmultivariate Central Limit Theorem for a random vector, whose components\ncorrespond to (possibly dependent) Hill estimators of the common shape index\nalpha, is established under mild conditions. Motivated by the statistical\nanalysis of extremal spatial data in particular, we introduce the concept of\n(standard) heavy-tailed random field of tail index alpha and show how this\nlimit result can be used in order to build an estimator of alpha with small\nasymptotic mean squared error, through a proper convex linear combination of\nthe coordinates. Beyond asymptotic results, simulation experiments illustrating\nthe relevance of the approach promoted are also presented.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2014 12:15:45 GMT"}, {"version": "v2", "created": "Wed, 9 Apr 2014 09:27:55 GMT"}], "update_date": "2014-04-10", "authors_parsed": [["Cl\u00e9men\u00e7on", "St\u00e9phan", "", "LTCI"], ["Dematteo", "Antoine", "", "TSI"]]}, {"id": "1402.0369", "submitter": "Ferenc Balogh", "authors": "Ferenc Balogh and Eva Krauczi", "title": "Weighted quantile correlation test for the logistic family", "comments": "16 pages, 4 figures. Minor corrections", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We summarize the results of investigating the asymptotic behavior of the\nweighted quantile correlation tests for the location-scale family associated to\nthe logistic distribution. Explicit representations of the limiting\ndistribution are given in terms of integrals of weighted Brownian bridges or\nalternatively as infinite series of independent Gaussian random variables. The\npower of this test and the test for the location logistic family against some\nalternatives are demonstrated by numerical simulations.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2014 12:47:31 GMT"}, {"version": "v2", "created": "Wed, 2 Apr 2014 09:29:46 GMT"}], "update_date": "2014-04-03", "authors_parsed": [["Balogh", "Ferenc", ""], ["Krauczi", "Eva", ""]]}, {"id": "1402.0606", "submitter": "Shiro Ishikawa", "authors": "Shiro Ishikawa", "title": "ANOVA (analysis of variance) in the quantum linguistic formulation of\n  statistics", "comments": "arXiv admin note: text overlap with arXiv:1312.6757, arXiv:1401.2709", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, we proposed quantum language (or, measurement theory), which is\ncharacterized as the linguistic turn of the Copenhagen interpretation of\nquantum mechanics. We believe that this language has a great powet of\ndescription, and therefore, even statistics can be described by quantum\nlanguage. In this paper, we show that ANOVA (analysis of variance (one-way and\ntwo-way)) can be formulated in quantum language. Since quantum language is\nsuited for theoretical arguments, we believe that our results are visible and\nunderstandable. For example, we can answer the question \"What kind of role does\nKolmogorov's probability theory play in ANOVA?\" That is, the readers find that\nKolmogorov's probability theory is merely used in order to calculate\nmulti-dimenstional Gauss integrals, and thus, they can avoid to confuse the\nrelation between Kolmogorov's probability theory and statistics.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2014 03:36:35 GMT"}], "update_date": "2014-02-05", "authors_parsed": [["Ishikawa", "Shiro", ""]]}, {"id": "1402.0686", "submitter": "Emanuele  Giorgi", "authors": "Emanuele Giorgi and Alexander J. McNeil", "title": "On the Computation of Multivariate Scenario Sets for the Skew-t and\n  Generalized Hyperbolic Families", "comments": "Under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine the problem of computing multivariate scenarios sets for skewed\ndistributions. Our interest is motivated by the potential use of such sets in\nthe \"stress testing\" of insurance companies and banks whose solvency is\ndependent on changes in a set of financial \"risk factors\". We define\nmultivariate scenario sets based on the notion of half-space depth (HD) and\nalso introduce the notion of expectile depth (ED) where half-spaces are defined\nby expectiles rather than quantiles. We then use the HD and ED functions to\ndefine convex scenario sets that generalize the concepts of quantile and\nexpectile to higher dimensions. In the case of elliptical distributions these\nsets coincide with the regions encompassed by the contours of the density\nfunction. In the context of multivariate skewed distributions, the equivalence\nof depth contours and density contours does not hold in general. We consider\ntwo parametric families that account for skewness and heavy tails: the\ngeneralized hyperbolic and the skew-t distributions. By making use of a\ncanonical form representation, where skewness is completely absorbed by one\ncomponent, we show that the HD contours of these distributions are\n\"near-elliptical\" and, in the case of the skew-Cauchy distribution, we prove\nthat the HD contours are exactly elliptical. We propose a measure of\nmultivariate skewness as a deviation from angular symmetry and show that it can\nexplain the quality of the elliptical approximation for the HD contours.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2014 10:50:29 GMT"}], "update_date": "2014-02-05", "authors_parsed": [["Giorgi", "Emanuele", ""], ["McNeil", "Alexander J.", ""]]}, {"id": "1402.0699", "submitter": "Elena Villa", "authors": "Elena Villa", "title": "On the local approximation of mean densities of random closed sets", "comments": "Published in at http://dx.doi.org/10.3150/12-BEJ474 the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2014, Vol. 20, No. 1, 1-27", "doi": "10.3150/12-BEJ474", "report-no": "IMS-BEJ-BEJ474", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mean density of lower dimensional random closed sets, as well as the mean\nboundary density of full dimensional random sets, and their estimation are of\ngreat interest in many real applications. Only partial results are available so\nfar in current literature, under the assumption that the random set is either\nstationary, or it is a Boolean model, or it has convex grains. We consider here\nnon-stationary random closed sets (not necessarily Boolean models), whose\ngrains have to satisfy some general regularity conditions, extending previous\nresults. We address the open problem posed in (Bernoulli 15 (2009) 1222-1242)\nabout the approximation of the mean density of lower dimensional random sets by\na pointwise limit, and to the open problem posed by Matheron in (Random Sets\nand Integral Geometry (1975) Wiley) about the existence (and its value) of the\nso-called specific area of full dimensional random closed sets. The\nrelationship with the spherical contact distribution function, as well as some\nexamples and applications are also discussed.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2014 11:40:29 GMT"}], "update_date": "2014-02-05", "authors_parsed": [["Villa", "Elena", ""]]}, {"id": "1402.0722", "submitter": "Zhou Zhou", "authors": "Zhou Zhou", "title": "Nonparametric specification for non-stationary time series regression", "comments": "Published in at http://dx.doi.org/10.3150/12-BEJ477 the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2014, Vol. 20, No. 1, 78-108", "doi": "10.3150/12-BEJ477", "report-no": "IMS-BEJ-BEJ477", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the behavior of the Generalized Likelihood Ratio Test (GLRT)\n(Fan, Zhang and Zhang [Ann. Statist. 29 (2001) 153-193]) for time varying\ncoefficient models where the regressors and errors are non-stationary time\nseries and can be cross correlated. It is found that the GLRT retains the\nminimax rate of local alternative detection under weak dependence and\nnon-stationarity. However, in general, the Wilks phenomenon as well as the\nclassic residual bootstrap are sensitive to either conditional\nheteroscedasticity of the errors, non-stationarity or temporal dependence. An\naveraged test is suggested to alleviate the sensitivity of the test to the\nchoice of bandwidth and is shown to be more powerful than tests based on a\nsingle bandwidth. An alternative wild bootstrap method is proposed and shown to\nbe consistent when making inference of time varying coefficient models for\nnon-stationary time series.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2014 13:18:57 GMT"}], "update_date": "2014-02-05", "authors_parsed": [["Zhou", "Zhou", ""]]}, {"id": "1402.0743", "submitter": "Guang Cheng", "authors": "Guang Cheng, Lan Zhou, Jianhua Z. Huang", "title": "Efficient semiparametric estimation in generalized partially linear\n  additive models for longitudinal/clustered data", "comments": "Published in at http://dx.doi.org/10.3150/12-BEJ479 the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2014, Vol. 20, No. 1, 141-163", "doi": "10.3150/12-BEJ479", "report-no": "IMS-BEJ-BEJ479", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider efficient estimation of the Euclidean parameters in a generalized\npartially linear additive models for longitudinal/clustered data when multiple\ncovariates need to be modeled nonparametrically, and propose an estimation\nprocedure based on a spline approximation of the nonparametric part of the\nmodel and the generalized estimating equations (GEE). Although the model in\nconsideration is natural and useful in many practical applications, the\nliterature on this model is very limited because of challenges in dealing with\ndependent data for nonparametric additive models. We show that the proposed\nestimators are consistent and asymptotically normal even if the covariance\nstructure is misspecified. An explicit consistent estimate of the asymptotic\nvariance is also provided. Moreover, we derive the semiparametric efficiency\nscore and information bound under general moment conditions. By showing that\nour estimators achieve the semiparametric information bound, we effectively\nestablish their efficiency in a stronger sense than what is typically\nconsidered for GEE. The derivation of our asymptotic results relies heavily on\nthe empirical processes tools that we develop for the longitudinal/clustered\ndata. Numerical results are used to illustrate the finite sample performance of\nthe proposed estimators.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2014 14:29:38 GMT"}], "update_date": "2014-02-05", "authors_parsed": [["Cheng", "Guang", ""], ["Zhou", "Lan", ""], ["Huang", "Jianhua Z.", ""]]}, {"id": "1402.0830", "submitter": "Sourav Chatterjee", "authors": "Sourav Chatterjee", "title": "A new perspective on least squares under convex constraint", "comments": "Published in at http://dx.doi.org/10.1214/14-AOS1254 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2014, Vol. 42, No. 6, 2340-2381", "doi": "10.1214/14-AOS1254", "report-no": "IMS-AOS-AOS1254", "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider the problem of estimating the mean of a Gaussian random vector when\nthe mean vector is assumed to be in a given convex set. The most natural\nsolution is to take the Euclidean projection of the data vector on to this\nconvex set; in other words, performing \"least squares under a convex\nconstraint.\" Many problems in modern statistics and statistical signal\nprocessing theory are special cases of this general situation. Examples include\nthe lasso and other high-dimensional regression techniques, function estimation\nproblems, matrix estimation and completion, shape-restricted regression,\nconstrained denoising, linear inverse problems, etc. This paper presents three\ngeneral results about this problem, namely, (a) an exact computation of the\nmain term in the estimation error by relating it to expected maxima of Gaussian\nprocesses (existing results only give upper bounds), (b) a theorem showing that\nthe least squares estimator is always admissible up to a universal constant in\nany problem of the above kind and (c) a counterexample showing that least\nsquares estimator may not always be minimax rate-optimal. The result from part\n(a) is then used to compute the error of the least squares estimator in two\nexamples of contemporary interest.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2014 18:53:47 GMT"}, {"version": "v2", "created": "Wed, 5 Feb 2014 18:48:21 GMT"}, {"version": "v3", "created": "Mon, 10 Feb 2014 19:54:42 GMT"}, {"version": "v4", "created": "Thu, 17 Jul 2014 23:35:37 GMT"}, {"version": "v5", "created": "Thu, 20 Nov 2014 09:00:30 GMT"}], "update_date": "2014-11-21", "authors_parsed": [["Chatterjee", "Sourav", ""]]}, {"id": "1402.0844", "submitter": "Luo Xiao", "authors": "Luo Xiao and Florentina Bunea", "title": "On the theoretic and practical merits of the banding estimator for large\n  covariance matrices", "comments": "19 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the banding estimator proposed in Bickel and Levina\n(2008) for estimation of large covariance matrices. We prove that the banding\nestimator achieves rate-optimality under the operator norm, for a class of\napproximately banded covariance matrices, improving the existing results in\nBickel and Levina (2008). In addition, we propose a Stein's unbiased risk\nestimate (Sure)-type approach for selecting the bandwidth for the banding\nestimator. Simulations indicate that the Sure-tuned banding estimator\noutperforms competing estimators.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2014 19:52:46 GMT"}], "update_date": "2014-02-05", "authors_parsed": [["Xiao", "Luo", ""], ["Bunea", "Florentina", ""]]}, {"id": "1402.0845", "submitter": "Art Owen", "authors": "Art B. Owen, Paul A. Roediger", "title": "The sign of the logistic regression coefficient", "comments": "9 pages, 0 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let Y be a binary random variable and X a scalar. Let $\\hat\\beta$ be the\nmaximum likelihood estimate of the slope in a logistic regression of Y on X\nwith intercept. Further let $\\bar x_0$ and $\\bar x_1$ be the average of sample\nx values for cases with y=0 and y=1, respectively. Then under a condition that\nrules out separable predictors, we show that sign($\\hat\\beta$) = sign($\\bar\nx_1-\\bar x_0$). More generally, if $x_i$ are vector valued then we show that\n$\\hat\\beta=0$ if and only if $\\bar x_1=\\bar x_0$. This holds for logistic\nregression and also for more general binary regressions with inverse link\nfunctions satisfying a log-concavity condition. Finally, when $\\bar x_1\\ne \\bar\nx_0$ then the angle between $\\hat\\beta$ and $\\bar x_1-\\bar x_0$ is less than\nninety degrees in binary regressions satisfying the log-concavity condition and\nthe separation condition, when the design matrix has full rank.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2014 19:58:19 GMT"}], "update_date": "2014-02-05", "authors_parsed": [["Owen", "Art B.", ""], ["Roediger", "Paul A.", ""]]}, {"id": "1402.0958", "submitter": "Zudi Lu", "authors": "Zudi Lu, Qingguo Tang, Longsheng Cheng", "title": "Estimating spatial quantile regression with functional coefficients: A\n  robust semiparametric framework", "comments": "Published in at http://dx.doi.org/10.3150/12-BEJ480 the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2014, Vol. 20, No. 1, 164-189", "doi": "10.3150/12-BEJ480", "report-no": "IMS-BEJ-BEJ480", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers an estimation of semiparametric functional\n(varying)-coefficient quantile regression with spatial data. A general robust\nframework is developed that treats quantile regression for spatial data in a\nnatural semiparametric way. The local M-estimators of the unknown\nfunctional-coefficient functions are proposed by using local linear\napproximation, and their asymptotic distributions are then established under\nweak spatial mixing conditions allowing the data processes to be either\nstationary or nonstationary with spatial trends. Application to a soil data set\nis demonstrated with interesting findings that go beyond traditional analysis.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2014 07:41:40 GMT"}], "update_date": "2014-02-06", "authors_parsed": [["Lu", "Zudi", ""], ["Tang", "Qingguo", ""], ["Cheng", "Longsheng", ""]]}, {"id": "1402.0966", "submitter": "Qiying Wang", "authors": "Qiying Wang, Nigel Chan", "title": "Uniform convergence rates for a class of martingales with application in\n  non-linear cointegrating regression", "comments": "Published in at http://dx.doi.org/10.3150/12-BEJ482 the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2014, Vol. 20, No. 1, 207-230", "doi": "10.3150/12-BEJ482", "report-no": "IMS-BEJ-BEJ482", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For a class of martingales, this paper provides a framework on the uniform\nconsistency with broad applicability. The main condition imposed is only\nrelated to the conditional variance of the martingale, which holds true for\nstationary mixing time series, stationary iterated random function, Harris\nrecurrent Markov chains and $I(1)$ processes with innovations being a linear\nprocess. Using the established results, this paper investigates the uniform\nconvergence of the Nadaraya-Watson estimator in a non-linear cointegrating\nregression model. Our results not only provide sharp convergence rate, but also\nthe optimal range for the uniform convergence to be held. This paper also\nconsiders the uniform upper and lower bound estimates for a functional of\nHarris recurrent Markov chain, which are of independent interests.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2014 08:16:23 GMT"}], "update_date": "2014-02-06", "authors_parsed": [["Wang", "Qiying", ""], ["Chan", "Nigel", ""]]}, {"id": "1402.1004", "submitter": "Natalia Ermolova Dr.", "authors": "Natalia Y. Ermolova and Olav Tirkkonen", "title": "Laplace Transform of Product of Generalized Marcum Q, Bessel I, and\n  Power Functions with Applications", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The evaluation of integral transforms of special functions is required in\ndifferent research and practical areas. Analyzing the $\\kappa$-$\\mu$ fading\ndistribution also khown as the generalized Rician distribution, we find out\nthat the assessment of a few different performance metrics, such as the\nprobability of energy detection of unknown signals and outage probability under\nco-channel interference, involves the evaluation of an infinite-range integral,\nwhich has the form of Laplace transform of product of Marcum Q, Bessel I, and\npower functions. We evaluate this integral in a closed-form and present\nnumerical estimates.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2014 10:43:21 GMT"}], "update_date": "2014-02-06", "authors_parsed": [["Ermolova", "Natalia Y.", ""], ["Tirkkonen", "Olav", ""]]}, {"id": "1402.1267", "submitter": "Jiaming Xu", "authors": "Yudong Chen, Jiaming Xu", "title": "Statistical-Computational Tradeoffs in Planted Problems and Submatrix\n  Localization with a Growing Number of Clusters and Submatrices", "comments": "We updated the statements for Theorems 2.1 and 2.3. Partial results\n  appeared at the International Conference on Machine Learning (ICML) 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider two closely related problems: planted clustering and submatrix\nlocalization. The planted clustering problem assumes that a random graph is\ngenerated based on some underlying clusters of the nodes; the task is to\nrecover these clusters given the graph. The submatrix localization problem\nconcerns locating hidden submatrices with elevated means inside a large\nreal-valued random matrix. Of particular interest is the setting where the\nnumber of clusters/submatrices is allowed to grow unbounded with the problem\nsize. These formulations cover several classical models such as planted clique,\nplanted densest subgraph, planted partition, planted coloring, and stochastic\nblock model, which are widely used for studying community detection and\nclustering/bi-clustering.\n  For both problems, we show that the space of the model parameters\n(cluster/submatrix size, cluster density, and submatrix mean) can be\npartitioned into four disjoint regions corresponding to decreasing statistical\nand computational complexities: (1) the \\emph{impossible} regime, where all\nalgorithms fail; (2) the \\emph{hard} regime, where the computationally\nexpensive Maximum Likelihood Estimator (MLE) succeeds; (3) the \\emph{easy}\nregime, where the polynomial-time convexified MLE succeeds; (4) the\n\\emph{simple} regime, where a simple counting/thresholding procedure succeeds.\nMoreover, we show that each of these algorithms provably fails in the previous\nharder regimes.\n  Our theorems establish the minimax recovery limit, which are tight up to\nconstants and hold with a growing number of clusters/submatrices, and provide a\nstronger performance guarantee than previously known for polynomial-time\nalgorithms. Our study demonstrates the tradeoffs between statistical and\ncomputational considerations, and suggests that the minimax recovery limit may\nnot be achievable by polynomial-time algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2014 07:58:38 GMT"}, {"version": "v2", "created": "Mon, 17 Feb 2014 18:17:32 GMT"}, {"version": "v3", "created": "Fri, 13 Mar 2015 19:54:55 GMT"}], "update_date": "2015-03-16", "authors_parsed": [["Chen", "Yudong", ""], ["Xu", "Jiaming", ""]]}, {"id": "1402.1380", "submitter": "Julien Stoehr", "authors": "Julien Stoehr (I3M), Pierre Pudlo (I3M), Lionel Cucala (I3M)", "title": "Adaptive ABC model choice and geometric summary statistics for hidden\n  Gibbs random fields", "comments": null, "journal-ref": "Statistics and Computing (2015) 25:129-141", "doi": "10.1007/s11222-014-9514-9", "report-no": null, "categories": "math.ST stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Selecting between different dependency structures of hidden Markov random\nfield can be very challenging, due to the intractable normalizing constant in\nthe likelihood. We answer this question with approximate Bayesian computation\n(ABC) which provides a model choice method in the Bayesian paradigm. This comes\nafter the work of Grelaud et al. (2009) who exhibited sufficient statistics on\ndirectly observed Gibbs random fields. But when the random field is latent, the\nsufficiency falls and we complement the set with geometric summary statistics.\nThe general approach to construct these intuitive statistics relies on a\nclustering analysis of the sites based on the observed colors and plausible\nlatent graphs. The efficiency of ABC model choice based on these statistics is\nevaluated via a local error rate which may be of independent interest. As a\nbyproduct we derived an ABC algorithm that adapts the dimension of the summary\nstatistics to the dataset without distorting the model selection.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2014 15:41:50 GMT"}, {"version": "v2", "created": "Wed, 16 Jul 2014 16:20:13 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Stoehr", "Julien", "", "I3M"], ["Pudlo", "Pierre", "", "I3M"], ["Cucala", "Lionel", "", "I3M"]]}, {"id": "1402.1700", "submitter": "Arnak Dalalyan S.", "authors": "Arnak S. Dalalyan and Mohamed Hebiri, and Johannes Lederer", "title": "On the Prediction Performance of the Lasso", "comments": null, "journal-ref": "Bernoulli 23(1), 2017, 552-581", "doi": "10.3150/15-BEJ756", "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although the Lasso has been extensively studied, the relationship between its\nprediction performance and the correlations of the covariates is not fully\nunderstood. In this paper, we give new insights into this relationship in the\ncontext of multiple linear regression. We show, in particular, that the\nincorporation of a simple correlation measure into the tuning parameter can\nlead to a nearly optimal prediction performance of the Lasso even for highly\ncorrelated covariates. However, we also reveal that for moderately correlated\ncovariates, the prediction performance of the Lasso can be mediocre\nirrespective of the choice of the tuning parameter. We finally show that our\nresults also lead to near-optimal rates for the least-squares estimator with\ntotal variation penalty.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2014 17:23:32 GMT"}, {"version": "v2", "created": "Tue, 8 Nov 2016 12:47:26 GMT"}], "update_date": "2016-11-09", "authors_parsed": [["Dalalyan", "Arnak S.", ""], ["Hebiri", "Mohamed", ""], ["Lederer", "Johannes", ""]]}, {"id": "1402.1754", "submitter": "Zoltan Szabo", "authors": "Zoltan Szabo, Arthur Gretton, Barnabas Poczos, Bharath Sriperumbudur", "title": "Two-stage Sampled Learning Theory on Distributions", "comments": "v6: accepted at AISTATS-2015 for oral presentation; final version;\n  code: https://bitbucket.org/szzoli/ite/; extension to the misspecified and\n  vector-valued case: http://arxiv.org/abs/1411.2066", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG math.FA stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We focus on the distribution regression problem: regressing to a real-valued\nresponse from a probability distribution. Although there exist a large number\nof similarity measures between distributions, very little is known about their\ngeneralization performance in specific learning tasks. Learning problems\nformulated on distributions have an inherent two-stage sampled difficulty: in\npractice only samples from sampled distributions are observable, and one has to\nbuild an estimate on similarities computed between sets of points. To the best\nof our knowledge, the only existing method with consistency guarantees for\ndistribution regression requires kernel density estimation as an intermediate\nstep (which suffers from slow convergence issues in high dimensions), and the\ndomain of the distributions to be compact Euclidean. In this paper, we provide\ntheoretical guarantees for a remarkably simple algorithmic alternative to solve\nthe distribution regression problem: embed the distributions to a reproducing\nkernel Hilbert space, and learn a ridge regressor from the embeddings to the\noutputs. Our main contribution is to prove the consistency of this technique in\nthe two-stage sampled setting under mild conditions (on separable, topological\ndomains endowed with kernels). For a given total number of observations, we\nderive convergence rates as an explicit function of the problem difficulty. As\na special case, we answer a 15-year-old open question: we establish the\nconsistency of the classical set kernel [Haussler, 1999; Gartner et. al, 2002]\nin regression, and cover more recent kernels on distributions, including those\ndue to [Christmann and Steinwart, 2010].\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2014 20:37:59 GMT"}, {"version": "v2", "created": "Mon, 21 Apr 2014 11:35:58 GMT"}, {"version": "v3", "created": "Sun, 4 May 2014 19:29:36 GMT"}, {"version": "v4", "created": "Sat, 7 Jun 2014 17:42:06 GMT"}, {"version": "v5", "created": "Sat, 25 Oct 2014 21:03:01 GMT"}, {"version": "v6", "created": "Mon, 26 Jan 2015 22:20:59 GMT"}], "update_date": "2015-01-28", "authors_parsed": [["Szabo", "Zoltan", ""], ["Gretton", "Arthur", ""], ["Poczos", "Barnabas", ""], ["Sriperumbudur", "Bharath", ""]]}, {"id": "1402.1860", "submitter": "Abraao D. C. Nacimento", "authors": "Alejandro C. Frery, Renato J. Cintra, Abra\\~ao D. C. Nascimento", "title": "Contrast Measures based on the Complex Correlation Coefficient for\n  PolSAR Imagery", "comments": "4 pages, 3 figures, Asia-Pacific Conference on Synthetic Aperture\n  Radar (APSAR)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive contrast measures which involve the number of looks and the complex\ncorrelation coefficient between polarization channels in PolSAR imagery. Using\nasymptotic results which characterize the behavior of these measures, we derive\nstatistical regions of confidence which lead to test of hypothesis. An\napplication to real data is performed, confirming the importance of the\nproposals.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2014 15:55:00 GMT"}], "update_date": "2014-02-11", "authors_parsed": [["Frery", "Alejandro C.", ""], ["Cintra", "Renato J.", ""], ["Nascimento", "Abra\u00e3o D. C.", ""]]}, {"id": "1402.1876", "submitter": "Abraao D. C. Nacimento", "authors": "A. C. Frery, A. D. C. Nascimento, R. J. Cintra", "title": "Information Theory and Image Understanding: An Application to\n  Polarimetric SAR Imagery", "comments": "15 pages, 11 figures", "journal-ref": "Chilean Journal of Statistics, Vol. 2, No. 2, September 2011,\n  81-100", "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents a comprehensive examination of the use of information\ntheory for understanding Polarimetric Synthetic Aperture Radar (PolSAR) images\nby means of contrast measures that can be used as test statistics. Due to the\nphenomenon called `speckle', common to all images obtained with coherent\nillumination such as PolSAR imagery, accurate modelling is required in their\nprocessing and analysis. The scaled multilook complex Wishart distribution has\nproven to be a successful approach for modelling radar backscatter from forest\nand pasture areas. Classification, segmentation, and image analysis techniques\nwhich depend on this model have been devised, and many of them employ some kind\nof dissimilarity measure. Specifically, we introduce statistical tests for\nanalyzing contrast in such images. These tests are based on the chi-square,\nKullback-Leibler, R\\'enyi, Bhattacharyya, and Hellinger distances. Results\nobtained by Monte Carlo experiments reveal the Kullback-Leibler distance as the\nbest one with respect to the empirical test sizes under several situations\nwhich include pure and contaminated data. The proposed methodology was applied\nto actual data, obtained by an E-SAR sensor over surroundings of\nWe$\\beta$ssling, Bavaria, Germany.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2014 18:08:48 GMT"}], "update_date": "2014-02-11", "authors_parsed": [["Frery", "A. C.", ""], ["Nascimento", "A. D. C.", ""], ["Cintra", "R. J.", ""]]}, {"id": "1402.1905", "submitter": "Shogo Kato Ph.D.", "authors": "Shogo Kato and Peter McCullagh", "title": "A characterization of a Cauchy family on the complex space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is shown that a family of distributions on the complex space is\ncharacterized as the only family such that the orbit of one distribution under\na certain group of transformations on the complex space is the same as that\nunder the group of affine transformations. The resulting family is compared\nwith some existing families.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2014 01:40:02 GMT"}], "update_date": "2014-02-11", "authors_parsed": [["Kato", "Shogo", ""], ["McCullagh", "Peter", ""]]}, {"id": "1402.1918", "submitter": "Yuchen Zhang", "authors": "Yuchen Zhang, Martin J. Wainwright, Michael I. Jordan", "title": "Lower bounds on the performance of polynomial-time algorithms for sparse\n  linear regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.CC stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Under a standard assumption in complexity theory (NP not in P/poly), we\ndemonstrate a gap between the minimax prediction risk for sparse linear\nregression that can be achieved by polynomial-time algorithms, and that\nachieved by optimal algorithms. In particular, when the design matrix is\nill-conditioned, the minimax prediction loss achievable by polynomial-time\nalgorithms can be substantially greater than that of an optimal algorithm. This\nresult is the first known gap between polynomial and optimal algorithms for\nsparse linear regression, and does not depend on conjectures in average-case\ncomplexity.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2014 06:02:29 GMT"}, {"version": "v2", "created": "Wed, 21 May 2014 05:41:06 GMT"}], "update_date": "2014-05-22", "authors_parsed": [["Zhang", "Yuchen", ""], ["Wainwright", "Martin J.", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1402.1920", "submitter": "Ryan Tibshirani", "authors": "Ryan J. Tibshirani", "title": "Degrees of Freedom and Model Search", "comments": "24 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Degrees of freedom is a fundamental concept in statistical modeling, as it\nprovides a quantitative description of the amount of fitting performed by a\ngiven procedure. But, despite this fundamental role in statistics, its behavior\nnot completely well-understood, even in some fairly basic settings. For\nexample, it may seem intuitively obvious that the best subset selection fit\nwith subset size k has degrees of freedom larger than k, but this has not been\nformally verified, nor has is been precisely studied. In large part, the\ncurrent paper is motivated by this particular problem, and we derive an exact\nexpression for the degrees of freedom of best subset selection in a restricted\nsetting (orthogonal predictor variables). Along the way, we develop a concept\nthat we name \"search degrees of freedom\"; intuitively, for adaptive regression\nprocedures that perform variable selection, this is a part of the (total)\ndegrees of freedom that we attribute entirely to the model selection mechanism.\nFinally, we establish a modest extension of Stein's formula to cover\ndiscontinuous functions, and discuss its potential role in degrees of freedom\nand search degrees of freedom calculations.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2014 06:43:53 GMT"}, {"version": "v2", "created": "Fri, 28 Nov 2014 13:23:03 GMT"}], "update_date": "2014-12-01", "authors_parsed": [["Tibshirani", "Ryan J.", ""]]}, {"id": "1402.1937", "submitter": "Heejoon Han", "authors": "Heejoon Han, Oliver Linton, Tatsushi Oka, Yoon-Jae Whang", "title": "The Cross-Quantilogram: Measuring Quantile Dependence and Testing\n  Directional Predictability between Time Series", "comments": null, "journal-ref": "Journal of Econometrics, 2016, 193, 251-270", "doi": null, "report-no": null, "categories": "math.ST stat.AP stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes the cross-quantilogram to measure the quantile dependence\nbetween two time series. We apply it to test the hypothesis that one time\nseries has no directional predictability to another time series. We establish\nthe asymptotic distribution of the cross quantilogram and the corresponding\ntest statistic. The limiting distributions depend on nuisance parameters. To\nconstruct consistent confidence intervals we employ the stationary bootstrap\nprocedure; we show the consistency of this bootstrap. Also, we consider the\nself-normalized approach, which is shown to be asymptotically pivotal under the\nnull hypothesis of no predictability. We provide simulation studies and two\nempirical applications. First, we use the cross-quantilogram to detect\npredictability from stock variance to excess stock return. Compared to existing\ntools used in the literature of stock return predictability, our method\nprovides a more complete relationship between a predictor and stock return.\nSecond, we investigate the systemic risk of individual financial institutions,\nsuch as JP Morgan Chase, Goldman Sachs and AIG. This article has supplementary\nmaterials online.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2014 11:30:20 GMT"}, {"version": "v2", "created": "Sun, 21 Jan 2018 04:46:31 GMT"}], "update_date": "2018-01-23", "authors_parsed": [["Han", "Heejoon", ""], ["Linton", "Oliver", ""], ["Oka", "Tatsushi", ""], ["Whang", "Yoon-Jae", ""]]}, {"id": "1402.2043", "submitter": "Gilles Stoltz", "authors": "Shie Mannor (EE-Technion), Vianney Perchet, Gilles Stoltz (GREGH)", "title": "Approachability in unknown games: Online learning meets multi-objective\n  optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the standard setting of approachability there are two players and a target\nset. The players play repeatedly a known vector-valued game where the first\nplayer wants to have the average vector-valued payoff converge to the target\nset which the other player tries to exclude it from this set. We revisit this\nsetting in the spirit of online learning and do not assume that the first\nplayer knows the game structure: she receives an arbitrary vector-valued reward\nvector at every round. She wishes to approach the smallest (\"best\") possible\nset given the observed average payoffs in hindsight. This extension of the\nstandard setting has implications even when the original target set is not\napproachable and when it is not obvious which expansion of it should be\napproached instead. We show that it is impossible, in general, to approach the\nbest target set in hindsight and propose achievable though ambitious\nalternative goals. We further propose a concrete strategy to approach these\ngoals. Our method does not require projection onto a target set and amounts to\nswitching between scalar regret minimization algorithms that are performed in\nepisodes. Applications to global cost minimization and to approachability under\nsample path constraints are considered.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2014 05:44:40 GMT"}, {"version": "v2", "created": "Fri, 17 Jun 2016 06:52:49 GMT"}], "update_date": "2016-06-20", "authors_parsed": [["Mannor", "Shie", "", "EE-Technion"], ["Perchet", "Vianney", "", "GREGH"], ["Stoltz", "Gilles", "", "GREGH"]]}, {"id": "1402.2044", "submitter": "Gilles Stoltz", "authors": "Pierre Gaillard (GREGH), Gilles Stoltz (GREGH), Tim Van Erven (INRIA\n  Saclay - Ile de France)", "title": "A Second-order Bound with Excess Losses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study online aggregation of the predictions of experts, and first show new\nsecond-order regret bounds in the standard setting, which are obtained via a\nversion of the Prod algorithm (and also a version of the polynomially weighted\naverage algorithm) with multiple learning rates. These bounds are in terms of\nexcess losses, the differences between the instantaneous losses suffered by the\nalgorithm and the ones of a given expert. We then demonstrate the interest of\nthese bounds in the context of experts that report their confidences as a\nnumber in the interval [0,1] using a generic reduction to the standard setting.\nWe conclude by two other applications in the standard setting, which improve\nthe known bounds in case of small excess losses and show a bounded regret\nagainst i.i.d. sequences of losses.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2014 05:45:29 GMT"}], "update_date": "2014-02-11", "authors_parsed": [["Gaillard", "Pierre", "", "GREGH"], ["Stoltz", "Gilles", "", "GREGH"], ["Van Erven", "Tim", "", "INRIA\n  Saclay - Ile de France"]]}, {"id": "1402.2094", "submitter": "George Iliopoulos", "authors": "Narayanaswamy Balakrishnan, Erhard Cramer and George Iliopoulos", "title": "On the method of pivoting the CDF for exact confidence intervals with\n  illustration for exponential mean under life-test with time constraints", "comments": null, "journal-ref": "Statist. Probab. Lett. 89 (2014) 124-130", "doi": "10.1016/j.spl.2014.02.022", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two requirements for pivoting a cumulative distribution function (CDF) in\norder to construct exact confidence intervals or bounds for a real-valued\nparameter $\\theta$ are the monotonicity of this CDF with respect to $\\theta$\nand the existence of solutions of some pertinent equations for $\\theta$. The\nsecond requirement is not fulfilled by the CDF of the maximum likelihood\nestimator of the exponential scale parameter when the data come from some\nlife-testing scenarios such as type-I censoring, hybrid type-I censoring, and\nprogressive type-I censoring that are subject to time constraints. However, the\nmethod has been used in these cases probably because the non-existence of the\nsolution usually happens only with small probability. Here, we illustrate the\nproblem by giving formal details in the case of type-I censoring and by\nproviding some further examples. We also present a suitable extension of the\nbasic pivoting method which is applicable in situations wherein the considered\nequations have no solution.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2014 10:43:44 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2014 23:51:48 GMT"}], "update_date": "2014-03-27", "authors_parsed": [["Balakrishnan", "Narayanaswamy", ""], ["Cramer", "Erhard", ""], ["Iliopoulos", "George", ""]]}, {"id": "1402.2209", "submitter": "Dennis Dobler", "authors": "Dennis Dobler and Markus Pauly", "title": "Approximative Tests for the Equality of Two Cumulative Incidence\n  Functions of a Competing Risk", "comments": "Aalen-Johansen Estimator; Approximation Techniques; Wild Bootstrap;\n  Competing Risk; Counting Processes; Cumulative Incidence Function;\n  Left-Truncation; Right-Censoring", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of the widely used competing risks set-up we discuss different\ninference procedures for testing equality of two cumulative incidence\nfunctions, where the data may be subject to independent right-censoring or\nleft-truncation. To this end we compare two-sample Kolmogorov-Smirnov- and\nCramer-von Mises-type test statistics. Since, in general, their corresponding\nasymptotic limit distributions depend on unknown quantities, we utilize wild\nbootstrap resampling as well as approximation techniques to construct adequate\ntest decisions. Here the latter procedures are motivated from testing\nprocedures for heteroscedastic factorial designs but have not yet been proposed\nin the survival context. A simulation study shows the performance of all\nconsidered tests under various settings and finally a real data example about\nbloodstream infection during neutropenia is used to illustrate their\napplication.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2014 16:57:14 GMT"}, {"version": "v2", "created": "Thu, 25 Jun 2015 12:53:31 GMT"}, {"version": "v3", "created": "Mon, 12 Oct 2015 12:05:44 GMT"}], "update_date": "2015-10-13", "authors_parsed": [["Dobler", "Dennis", ""], ["Pauly", "Markus", ""]]}, {"id": "1402.2238", "submitter": "Yash Deshpande", "authors": "Yash Deshpande, Andrea Montanari", "title": "Information-theoretically Optimal Sparse PCA", "comments": "5 pages, 1 figure, conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT math.ST stat.TH", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Sparse Principal Component Analysis (PCA) is a dimensionality reduction\ntechnique wherein one seeks a low-rank representation of a data matrix with\nadditional sparsity constraints on the obtained representation. We consider two\nprobabilistic formulations of sparse PCA: a spiked Wigner and spiked Wishart\n(or spiked covariance) model. We analyze an Approximate Message Passing (AMP)\nalgorithm to estimate the underlying signal and show, in the high dimensional\nlimit, that the AMP estimates are information-theoretically optimal. As an\nimmediate corollary, our results demonstrate that the posterior expectation of\nthe underlying signal, which is often intractable to compute, can be obtained\nusing a polynomial-time scheme. Our results also effectively provide a\nsingle-letter characterization of the sparse PCA problem.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2014 19:10:37 GMT"}, {"version": "v2", "created": "Sat, 3 May 2014 22:14:10 GMT"}], "update_date": "2014-05-06", "authors_parsed": [["Deshpande", "Yash", ""], ["Montanari", "Andrea", ""]]}, {"id": "1402.2243", "submitter": "Pierre Vandekerkhove Diaz", "authors": "Cristina Butucea, Rodrigue Ngueyep Tzoumpe and Pierre Vandekerkhove", "title": "Semiparametric topographical mixture models with symmetric errors", "comments": "19 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the analysis of a Positron Emission Tomography (PET) imaging\ndata considered in Bowen et al. (2012), we introduce a semiparametric\ntopographical mixture model able to capture the characteristics of dichotomous\nshifted response-type experiments. We propose a local estimation procedure,\nbased on the symmetry of the local noise, for the proportion and locations\nfunctions involved in the proposed model. We establish under mild conditions\nthe minimax properties and asymptotic normality of our estimators when Monte\nCarlo simulations are conducted to examine their finite sample performance.\nFinally a statistical analysis of the PET imaging data in Bowen et al. (2012)\nis illustrated for the proposed method.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2014 19:24:29 GMT"}], "update_date": "2014-02-11", "authors_parsed": [["Butucea", "Cristina", ""], ["Tzoumpe", "Rodrigue Ngueyep", ""], ["Vandekerkhove", "Pierre", ""]]}, {"id": "1402.2255", "submitter": "Youssef  Mroueh", "authors": "Youssef Mroueh", "title": "Robust Phase Retrieval and Super-Resolution from One Bit Coded\n  Diffraction Patterns", "comments": "fixed notations", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study a realistic setup for phase retrieval, where the\nsignal of interest is modulated or masked and then for each modulation or mask\na diffraction pattern is collected, producing a coded diffraction pattern (CDP)\n[CLM13]. We are interested in the setup where the resolution of the collected\nCDP is limited by the Fraunhofer diffraction limit of the imaging system.\n  We investigate a novel approach based on a geometric quantization scheme of\nphase-less linear measurements into (one-bit) coded diffraction patterns, and a\ncorresponding recovery scheme. The key novelty in this approach consists in\ncomparing pairs of coded diffractions patterns across frequencies: the one bit\nmeasurements obtained rely on the order statistics of the un-quantized\nmeasurements rather than their values . This results in a robust phase\nrecovery, and unlike currently available methods, allows to efficiently perform\nphase recovery from measurements affected by severe (possibly unknown) non\nlinear, rank preserving perturbations, such as distortions. Another important\nfeature of this approach consists in the fact that it enables also\nsuper-resolution and blind-deconvolution, beyond the diffraction limit of a\ngiven imaging system.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2014 20:19:53 GMT"}, {"version": "v2", "created": "Mon, 24 Mar 2014 13:11:16 GMT"}], "update_date": "2014-03-25", "authors_parsed": [["Mroueh", "Youssef", ""]]}, {"id": "1402.2365", "submitter": "Yves Atchade F", "authors": "Yves F. Atchade, Gersende Fort and Eric Moulines", "title": "On perturbed proximal gradient algorithms", "comments": "33 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.OC stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a version of the proximal gradient algorithm for which the gradient\nis intractable and is approximated by Monte Carlo methods (and in particular\nMarkov Chain Monte Carlo). We derive conditions on the step size and the Monte\nCarlo batch size under which convergence is guaranteed: both increasing batch\nsize and constant batch size are considered. We also derive non-asymptotic\nbounds for an averaged version. Our results cover both the cases of biased and\nunbiased Monte Carlo approximation. To support our findings, we discuss the\ninference of a sparse generalized linear model with random effect and the\nproblem of learning the edge structure and parameters of sparse undirected\ngraphical models.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2014 04:09:53 GMT"}, {"version": "v2", "created": "Fri, 30 Jan 2015 02:17:37 GMT"}, {"version": "v3", "created": "Fri, 24 Jun 2016 21:13:41 GMT"}, {"version": "v4", "created": "Sat, 19 Nov 2016 19:54:29 GMT"}], "update_date": "2016-11-22", "authors_parsed": [["Atchade", "Yves F.", ""], ["Fort", "Gersende", ""], ["Moulines", "Eric", ""]]}, {"id": "1402.2424", "submitter": "Miklos Z. Racz", "authors": "Junhyong Kim, Elchanan Mossel, Mikl\\'os Z. R\\'acz, Nathan Ross", "title": "Can one hear the shape of a population history?", "comments": "22 pages, 7 figures; v2 is significantly revised from v1", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reconstructing past population size from present day genetic data is a major\ngoal of population genetics. Recent empirical studies infer population size\nhistory using coalescent-based models applied to a small number of individuals.\nHere we provide tight bounds on the amount of exact coalescence time data\nneeded to recover the population size history of a single, panmictic population\nat a certain level of accuracy. In practice, coalescence times are estimated\nfrom sequence data and so our lower bounds should be taken as rather\nconservative.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2014 10:26:06 GMT"}, {"version": "v2", "created": "Mon, 29 Sep 2014 18:16:23 GMT"}], "update_date": "2014-09-30", "authors_parsed": [["Kim", "Junhyong", ""], ["Mossel", "Elchanan", ""], ["R\u00e1cz", "Mikl\u00f3s Z.", ""], ["Ross", "Nathan", ""]]}, {"id": "1402.2468", "submitter": "Ansgar Steland", "authors": "Ansgar Steland", "title": "Sampling Plans for Control-Inspection Schemes Under Independent and\n  Dependent Sampling Designs With Applications to Photovoltaics", "comments": null, "journal-ref": "Frontiers in Statistical Quality Control 11 - 2015, pp 287-317", "doi": "10.1007/978-3-319-12355-4_18", "report-no": null, "categories": "math.ST stat.AP stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The evaluation of produced items at the time of delivery is, in practice,\nusually amended by at least one inspection at later time points. We extend the\nmethodology of acceptance sampling for variables for arbitrary unknown\ndistributions when additional sampling infor- mation is available to such\nsettings. Based on appropriate approximations of the operating characteristic,\nwe derive new acceptance sampling plans that control the overall operating\ncharacteristic. The results cover the case of independent sampling as well as\nthe case of dependent sampling. In particular, we study a modified panel\nsampling design and the case of spatial batch sampling. The latter is advisable\nin photovoltaic field monitoring studies, since it allows to detect and analyze\nlocal clusters of degraded or damaged modules. Some finite sample properties\nare examined by a simulation study, focusing on the accuracy of estimation.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2014 12:17:50 GMT"}], "update_date": "2018-03-20", "authors_parsed": [["Steland", "Ansgar", ""]]}, {"id": "1402.2594", "submitter": "Alexander Rakhlin", "authors": "Alexander Rakhlin, Karthik Sridharan", "title": "Online Nonparametric Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We establish optimal rates for online regression for arbitrary classes of\nregression functions in terms of the sequential entropy introduced in (Rakhlin,\nSridharan, Tewari, 2010). The optimal rates are shown to exhibit a phase\ntransition analogous to the i.i.d./statistical learning case, studied in\n(Rakhlin, Sridharan, Tsybakov 2013). In the frequently encountered situation\nwhen sequential entropy and i.i.d. empirical entropy match, our results point\nto the interesting phenomenon that the rates for statistical learning with\nsquared loss and online nonparametric regression are the same.\n  In addition to a non-algorithmic study of minimax regret, we exhibit a\ngeneric forecaster that enjoys the established optimal rates. We also provide a\nrecipe for designing online regression algorithms that can be computationally\nefficient. We illustrate the techniques by deriving existing and new\nforecasters for the case of finite experts and for online linear regression.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2014 18:36:11 GMT"}], "update_date": "2014-02-12", "authors_parsed": [["Rakhlin", "Alexander", ""], ["Sridharan", "Karthik", ""]]}, {"id": "1402.2620", "submitter": "Enkelejd Hashorva", "authors": "Enkelejd Hashorva and Yuliya Mishura", "title": "Boundary Non-Crossings of Additive Wiener Fields", "comments": "14 pages", "journal-ref": "Lithuanian Math. J., 54(3), 277-289 (2014)", "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $W_i=\\{W_i(t), t\\in \\mathbb{R}_+\\}, i=1,2$ be two Wiener processes and\n$W_3=\\{W_3(\\mathbf{t}), \\mathbf{t}\\in \\mathbb{R}_+^2\\}$ be a two-parameter\nBrownian sheet, all three processes being mutually independent. We derive upper\nand lower bounds for the boundary non-crossing probability\n$$P_f=P\\{W_1(t_1)+W_2(t_2)+W_3(\\mathbf{t})+h(\\mathbf{t})\\leq u(\\mathbf{t}),\n\\mathbf{t}\\in\\mathbb{R}_+^2\\},$$ where $h, u: \\mathbb{R}_+^2\\rightarrow\n\\mathbb{R}_+$ are two measurable functions. We show further that for large\ntrend functions $\\gamma f>0$ asymptotically when $\\gamma \\to \\infty$ we have\nthat $\\ln P_{\\gamma f}$ is the same as $\\ln P_{\\gamma \\underline{f}}$ where\n$\\underline{f}$ is the projection of $f$ on some closed convex set of the\nreproducing kernel Hilbert Space of $W$. It turns out that our approach is\napplicable also for the additive Brownian pillow.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2014 20:13:09 GMT"}, {"version": "v2", "created": "Wed, 25 Jun 2014 17:28:59 GMT"}], "update_date": "2014-10-08", "authors_parsed": [["Hashorva", "Enkelejd", ""], ["Mishura", "Yuliya", ""]]}, {"id": "1402.2628", "submitter": "Enkelejd Hashorva", "authors": "Peng Liu, Enkelejd Hashorva, Lanpeng Ji", "title": "On the gamma-reflected processes with fBm input", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Define a $\\gamma$-reflected process\n$W_\\gamma(t)=Y_H(t)-\\gamma\\inf_{s\\in[0,t]}Y_H(s)$, $t\\ge0$ with input process\n$\\{Y_H(t), t\\ge 0\\}$ which is a fractional Brownian motion with Hurst index\n$H\\in (0,1)$ and a negative linear trend. In risk theory\n$R_\\gamma(t)=u-W_\\gamma(t), t\\ge0$ is referred to as the risk process with tax\nof a loss-carry-forward type, whereas in queueing theory $W_1$ is referred to\nas the queue length process. In this paper, we investigate the ruin probability\nand the ruin time of the risk process $R_\\gamma, \\gamma \\in [0,1]$ over a\nsurplus dependent time interval $[0, T_u]$.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2014 20:21:09 GMT"}], "update_date": "2014-02-12", "authors_parsed": [["Liu", "Peng", ""], ["Hashorva", "Enkelejd", ""], ["Ji", "Lanpeng", ""]]}, {"id": "1402.2703", "submitter": "Jeffrey Tsang", "authors": "Jeffrey Tsang, Rajesh Pereira", "title": "Taking all positive eigenvectors is suboptimal in classical\n  multidimensional scaling", "comments": "13 pages, 1 figure, 1 table, 1 supplementary file", "journal-ref": "SIAM Journal on Optimization 26(4):2080-2090, 2016", "doi": "10.1137/15M102602X", "report-no": null, "categories": "math.ST cs.NA math.OC stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is hard to overstate the importance of multidimensional scaling as an\nanalysis technique in the broad sciences. Classical, or Torgerson\nmultidimensional scaling is one of the main variants, with the advantage that\nit has a closed-form analytic solution. However, this solution is exact if and\nonly if the distances are Euclidean. Conversely, there has been comparatively\nlittle discussion on what to do in the presence of negative eigenvalues: the\nintuitive solution, prima facie justifiable in least-squares terms, is to take\nevery positive eigenvector as a dimension. We show that this, minimizing\nleast-squares to the centred distances instead of the true distances, is\nsuboptimal - throwing away positive eigenvectors can decrease the error even as\nwe project to fewer dimensions. We provide provably better methods for handling\nthis common case.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2014 00:29:37 GMT"}], "update_date": "2017-06-13", "authors_parsed": [["Tsang", "Jeffrey", ""], ["Pereira", "Rajesh", ""]]}, {"id": "1402.2755", "submitter": "Alessio Benavoli", "authors": "Alessio Benavoli, Francesca Mangili, Fabrizio Ruggeri and Marco\n  Zaffalon", "title": "Imprecise Dirichlet Process with application to the hypothesis test on\n  the probability that X< Y", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Dirichlet process (DP) is one of the most popular Bayesian nonparametric\nmodels. An open problem with the DP is how to choose its infinite dimensional\nparameter (base measure) in case of lack of prior information. In this work we\npresent the Imprecise DP (IDP) -- a prior near-ignorance DP-based model that\ndoes not require any choice of this probability measure. It consists of a class\nof DPs obtained by letting the normalized base measure of the DP vary in the\nset of all probability measures. We discuss the tight connections of this\napproach with Bayesian robustness and in particular prior near-ignorance\nmodeling via sets of probabilities. We use this model to perform a Bayesian\nhypothesis test on the probability P(X<Y). We study the theoretical properties\nof the IDP test (e.g., asymptotic consistency), and compare it with the\nfrequentist Mann-Whitney-Wilcoxon rank test that is commonly employed as a test\non P(X< Y). In particular we will show that our method is more robust, in the\nsense that it is able to isolate instances in which the aforementioned test is\nvirtually guessing at random.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2014 08:05:17 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2014 10:19:16 GMT"}], "update_date": "2014-02-21", "authors_parsed": [["Benavoli", "Alessio", ""], ["Mangili", "Francesca", ""], ["Ruggeri", "Fabrizio", ""], ["Zaffalon", "Marco", ""]]}, {"id": "1402.2786", "submitter": "Anirvan Chakraborty Mr.", "authors": "Anirvan Chakraborty and Probal Chaudhuri (Indian Statistical\n  Institute, Kolkata, India)", "title": "The deepest point for distributions in infinite dimensional spaces", "comments": "17 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": "R5/2012, Stat. Math. Unit", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identification of the center of a data cloud is one of the basic problems in\nstatistics. One popular choice for such a center is the median, and several\nversions of median in finite dimensional spaces have been studied in the\nliterature. In particular, medians based on different notions of data depth\nhave been extensively studied by many researchers, who defined median as the\npoint, where the depth function attains its maximum value. In other words, the\nmedian is the deepest point in the sample space according to that definition.\nIn this paper, we investigate the deepest point for probability distributions\nin infinite dimensional spaces. We show that for some well-known depth\nfunctions like the band depth and the half-region depth in function spaces,\nthere may not be any meaningful deepest point for many well-known and commonly\nused probability models. On the other hand, certain modified versions of those\ndepth functions as well as the spatial depth function, which can be defined in\nany Hilbert space, lead to some useful notions of the deepest point with nice\ngeometric and statistical properties. The empirical versions of those deepest\npoints can be conveniently computed for functional data, and we demonstrate\nthis using some simulated and real data sets.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2014 11:05:03 GMT"}], "update_date": "2014-02-13", "authors_parsed": [["Chakraborty", "Anirvan", "", "Indian Statistical\n  Institute, Kolkata, India"], ["Chaudhuri", "Probal", "", "Indian Statistical\n  Institute, Kolkata, India"]]}, {"id": "1402.2823", "submitter": "Davy Paindaveine", "authors": "Christophe Ley, Davy Paindaveine, Thomas Verdebout", "title": "High-dimensional tests for spherical location and spiked covariance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rotationally symmetric distributions on the p-dimensional unit hypersphere,\nextremely popular in directional statistics, involve a location parameter theta\nthat indicates the direction of the symmetry axis. The most classical way of\naddressing the spherical location problem H_0:theta=theta_0, with theta_0 a\nfixed location, is the so-called Watson test, which is based on the sample mean\nof the observations. This test enjoys many desirable properties, but its\nimplementation requires the sample size n to be large compared to the dimension\np. This is a severe limitation, since more and more problems nowadays involve\nhigh-dimensional directional data (e.g., in genetics or text mining). In this\nwork, we therefore introduce a modified Watson statistic that can cope with\nhigh-dimensionality. We derive its asymptotic null distribution as both n and p\ngo to infinity. This is achieved in a universal asymptotic framework that\nallows p to go to infinity arbitrarily fast (or slowly) as a function of n. We\nfurther show that our results also provide high-dimensional tests for a problem\nthat has recently attracted much attention, namely that of testing that the\ncovariance matrix of a multinormal distribution has a \"theta_0-spiked\"\nstructure. Finally, a Monte Carlo simulation study corroborates our asymptotic\nresults.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2014 13:56:55 GMT"}], "update_date": "2014-02-13", "authors_parsed": [["Ley", "Christophe", ""], ["Paindaveine", "Davy", ""], ["Verdebout", "Thomas", ""]]}, {"id": "1402.2918", "submitter": "Lutz Duembgen", "authors": "Lutz Duembgen and Jon A. Wellner", "title": "Confidence Bands for Distribution Functions: A New Look at the Law of\n  the Iterated Logarithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a general law of the iterated logarithm for stochastic processes\non the open unit interval having subexponential tails in a locally uniform\nfashion. It applies to standard Brownian bridge but also to suitably\nstandardized empirical distribution functions. This leads to new\ngoodness-of-fit tests and confidence bands which refine the procedures of Berk\nand Jones (1979) and Owen (1995). Roughly speaking, the high power and accuracy\nof the latter procedures in the tail regions of distributions are essentially\npreserved while gaining considerably in the central region.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2014 18:17:56 GMT"}, {"version": "v2", "created": "Wed, 19 Mar 2014 17:19:40 GMT"}], "update_date": "2014-03-20", "authors_parsed": [["Duembgen", "Lutz", ""], ["Wellner", "Jon A.", ""]]}, {"id": "1402.2966", "submitter": "Akshay Krishnamurthy", "authors": "Akshay Krishnamurthy, Kirthevasan Kandasamy, Barnabas Poczos, Larry\n  Wasserman", "title": "Nonparametric Estimation of Renyi Divergence and Friends", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider nonparametric estimation of $L_2$, Renyi-$\\alpha$ and\nTsallis-$\\alpha$ divergences between continuous distributions. Our approach is\nto construct estimators for particular integral functionals of two densities\nand translate them into divergence estimators. For the integral functionals,\nour estimators are based on corrections of a preliminary plug-in estimator. We\nshow that these estimators achieve the parametric convergence rate of\n$n^{-1/2}$ when the densities' smoothness, $s$, are both at least $d/4$ where\n$d$ is the dimension. We also derive minimax lower bounds for this problem\nwhich confirm that $s > d/4$ is necessary to achieve the $n^{-1/2}$ rate of\nconvergence. We validate our theoretical guarantees with a number of\nsimulations.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2014 20:35:11 GMT"}, {"version": "v2", "created": "Mon, 12 May 2014 12:47:52 GMT"}], "update_date": "2014-05-13", "authors_parsed": [["Krishnamurthy", "Akshay", ""], ["Kandasamy", "Kirthevasan", ""], ["Poczos", "Barnabas", ""], ["Wasserman", "Larry", ""]]}, {"id": "1402.2986", "submitter": "Eric Schmitt", "authors": "Eric Schmitt, Viktoria Oellerer, Kaveh Vakili", "title": "Finite Sample Breakdown of PCS", "comments": "14 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Projection Congruent Subset (PCS) is new method for finding multivariate\noutliers. PCS returns an outlyingness index which can be used to construct\naffine equivariant estimates of multivariate location and scatter. In this\nnote, we derive the finite sample breakdown point of these estimators.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2014 21:20:39 GMT"}, {"version": "v2", "created": "Sun, 16 Feb 2014 19:42:15 GMT"}, {"version": "v3", "created": "Tue, 29 Jul 2014 11:00:52 GMT"}], "update_date": "2014-07-30", "authors_parsed": [["Schmitt", "Eric", ""], ["Oellerer", "Viktoria", ""], ["Vakili", "Kaveh", ""]]}, {"id": "1402.2997", "submitter": "Niels Richard Hansen", "authors": "Niels Richard Hansen and Alexander Sokol", "title": "Degrees of freedom for nonlinear least squares estimation", "comments": "26 pages, 6 figures, 10 pages supplement", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a general result on the effective degrees of freedom for nonlinear\nleast squares estimation, which relates the degrees of freedom to the\ndivergence of the estimator. We show that in a general framework, the\ndivergence of the least squares estimator is a well defined but potentially\nnegatively biased estimate of the degrees of freedom, and we give an exact\nrepresentation of the bias. This implies that if we use the divergence as a\nplug-in estimate of the degrees of freedom in Stein's unbiased risk estimate\n(SURE), we generally underestimate the true risk. Our result applies, for\ninstance, to model searching problems, yielding a finite sample\ncharacterization of how much the search contributes to the degrees of freedom.\nMotivated by the problem of fitting ODE models in systems biology, the general\nresults are illustrated by the estimation of systems of linear ODEs. In this\nexample the divergence turns out to be a useful estimate of degrees of freedom\nfor $\\ell_1$-constrained models.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2014 22:14:42 GMT"}, {"version": "v2", "created": "Sun, 16 Nov 2014 00:24:14 GMT"}, {"version": "v3", "created": "Fri, 12 Dec 2014 09:20:57 GMT"}], "update_date": "2014-12-15", "authors_parsed": [["Hansen", "Niels Richard", ""], ["Sokol", "Alexander", ""]]}, {"id": "1402.3093", "submitter": "Julyan Arbel", "authors": "Julyan Arbel, Kerrie Mengersen, Judith Rousseau", "title": "Bayesian nonparametric dependent model for partially replicated data:\n  the influence of fuel spills on species diversity", "comments": "Main Paper: 22 pages, 6 figures. Supplementary Material: 11 pages, 1\n  figure", "journal-ref": "Annals of Applied Statistics, 10(3):1496--1516, 2016", "doi": "10.1214/16-AOAS944", "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a dependent Bayesian nonparametric model for the probabilistic\nmodeling of membership of subgroups in a community based on partially\nreplicated data. The focus here is on species-by-site data, i.e. community data\nwhere observations at different sites are classified in distinct species. Our\naim is to study the impact of additional covariates, for instance environmental\nvariables, on the data structure, and in particular on the community diversity.\nTo that purpose, we introduce dependence a priori across the covariates, and\nshow that it improves posterior inference. We use a dependent version of the\nGriffiths-Engen-McCloskey distribution defined via the stick-breaking\nconstruction. This distribution is obtained by transforming a Gaussian process\nwhose covariance function controls the desired dependence. The resulting\nposterior distribution is sampled by Markov chain Monte Carlo. We illustrate\nthe application of our model to a soil microbial dataset acquired across a\nhydrocarbon contamination gradient at the site of a fuel spill in Antarctica.\nThis method allows for inference on a number of quantities of interest in\necotoxicology, such as diversity or effective concentrations, and is broadly\napplicable to the general problem of communities response to environmental\nvariables.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2014 11:29:45 GMT"}, {"version": "v2", "created": "Mon, 27 Jul 2015 13:30:45 GMT"}], "update_date": "2017-10-18", "authors_parsed": [["Arbel", "Julyan", ""], ["Mengersen", "Kerrie", ""], ["Rousseau", "Judith", ""]]}, {"id": "1402.3230", "submitter": "Mercedes Richards", "authors": "Mercedes T. Richards, Donald St. P. Richards, Elizabeth Martinez-Gomez", "title": "Interpreting the Distance Correlation Results for the COMBO-17 Survey", "comments": "5 pages, 2 tables, 3 figures; published in Astrophysical Journal\n  Letters, 784, L34 (2014)", "journal-ref": null, "doi": "10.1088/2041-8205/784/2/L34", "report-no": null, "categories": "astro-ph.CO math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The accurate classification of galaxies in large-sample astrophysical\ndatabases of galaxy clusters depends sensitively on the ability to distinguish\nbetween morphological types, especially at higher redshifts. This capability\ncan be enhanced through a new statistical measure of association and\ncorrelation, called the {\\it distance correlation coefficient}, which has more\nstatistical power to detect associations than does the classical Pearson\nmeasure of linear relationships between two variables. The distance correlation\nmeasure offers a more precise alternative to the classical measure since it is\ncapable of detecting nonlinear relationships that may appear in astrophysical\napplications. We showed recently that the comparison between the distance and\nPearson correlation coefficients can be used effectively to isolate potential\noutliers in various galaxy datasets, and this comparison has the ability to\nconfirm the level of accuracy associated with the data. In this work, we\nelucidate the advantages of distance correlation when applied to large\ndatabases. We illustrate how the distance correlation measure can be used\neffectively as a tool to confirm nonlinear relationships between various\nvariables in the COMBO-17 database, including the lengths of the major and\nminor axes, and the alternative redshift distribution. For these outlier pairs,\nthe distance correlation coefficient is routinely higher than the Pearson\ncoefficient since it is easier to detect nonlinear relationships with distance\ncorrelation. The V-shaped scatterplots of Pearson versus distance correlation\ncoefficients also reveal the patterns with increasing redshift and the\ncontributions of different galaxy types within each redshift range.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2014 17:31:24 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2014 12:52:58 GMT"}, {"version": "v3", "created": "Thu, 20 Mar 2014 11:06:05 GMT"}], "update_date": "2014-03-21", "authors_parsed": [["Richards", "Mercedes T.", ""], ["Richards", "Donald St. P.", ""], ["Martinez-Gomez", "Elizabeth", ""]]}, {"id": "1402.3514", "submitter": "Kaveh Vakili", "authors": "E. Schmitt and K. Vakili", "title": "Robust PCA with FastHCS", "comments": "14 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.AP stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Principal component analysis (PCA) is widely used to analyze high-dimensional\ndata, but it is very sensitive to outliers. Robust PCA methods seek fits that\nare unaffected by the outliers and can therefore be trusted to reveal them.\nFastHCS (High-dimensional Congruent Subsets) is a robust PCA algorithm suitable\nfor high-dimensional applications, including cases where the number of\nvariables exceeds the number of observations. After detailing the FastHCS\nalgorithm, we carry out an extensive simulation study and three real data\napplications, the results of which show that FastHCS is systematically more\nrobust to outliers than state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2014 16:13:21 GMT"}, {"version": "v2", "created": "Wed, 19 Feb 2014 09:51:42 GMT"}, {"version": "v3", "created": "Tue, 15 Jul 2014 06:20:07 GMT"}, {"version": "v4", "created": "Tue, 16 Dec 2014 20:28:59 GMT"}, {"version": "v5", "created": "Fri, 19 Dec 2014 04:23:59 GMT"}, {"version": "v6", "created": "Mon, 18 May 2015 09:48:48 GMT"}, {"version": "v7", "created": "Thu, 24 Sep 2015 11:24:08 GMT"}], "update_date": "2015-09-25", "authors_parsed": [["Schmitt", "E.", ""], ["Vakili", "K.", ""]]}, {"id": "1402.3535", "submitter": "Jukka Kiukas", "authors": "Madalin Guta and Jukka Kiukas", "title": "Equivalence classes and local asymptotic normality in system\n  identification for quantum Markov chains", "comments": "21 pages, 1 figure", "journal-ref": null, "doi": "10.1007/s00220-014-2253-0", "report-no": null, "categories": "quant-ph math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problems of identifying and estimating dynamical parameters\nof an ergodic quantum Markov chain, when only the stationary output is\naccessible for measurements. On the identifiability question, we show that the\nknowledge of the output state completely fixes the dynamics up to a `coordinate\ntransformation' consisting of a multiplication by a phase and a unitary\nconjugation of the Kraus operators. When the dynamics depends on an unknown\nparameter, we show that the latter can be estimated at the `standard' rate\n$n^{-1/2}$, and give an explicit expression of the (asymptotic) quantum Fisher\ninformation of the output, which is proportional to the Markov variance of a\ncertain `generator'. More generally, we show that the output is locally\nasymptotically normal, i.e. it can be approximated by a simple quantum Gaussian\nmodel consisting of a coherent state whose mean is related to the unknown\nparameter. As a consistency check we prove that a parameter related to the\n`coordinate transformation' unitaries, has zero quantum Fisher information.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2014 17:29:25 GMT"}], "update_date": "2015-06-18", "authors_parsed": [["Guta", "Madalin", ""], ["Kiukas", "Jukka", ""]]}, {"id": "1402.3695", "submitter": "Lucien Birg\\'e", "authors": "Lucien Birg\\'e", "title": "About the non-asymptotic behaviour of Bayes estimators", "comments": "Extended version of a talk given in June 2013 at BNP9 Conference in\n  Amsterdam - 17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the {\\em nonasymptotic} properties of Bayes\nprocedures for estimating an unknown distribution from $n$ i.i.d.\\\nobservations. We assume that the prior is supported by a model $(\\scr{S},h)$\n(where $h$ denotes the Hellinger distance) with suitable metric properties\ninvolving the number of small balls that are needed to cover larger ones. We\nalso require that the prior put enough probability on small balls.\n  We consider two different situations. The simplest case is the one of a\nparametric model containing the target density for which we show that the\nposterior concentrates around the true distribution at rate $1/\\sqrt{n}$. In\nthe general situation, we relax the parametric assumption and take into account\na possible mispecification of the model. Provided that the Kullback-Leibler\nInformation between the true distribution and $\\scr{S}$ is finite, we establish\nrisk bounds for the Bayes estimators.\n", "versions": [{"version": "v1", "created": "Sat, 15 Feb 2014 14:26:04 GMT"}, {"version": "v2", "created": "Fri, 31 Oct 2014 08:59:27 GMT"}], "update_date": "2014-11-03", "authors_parsed": [["Birg\u00e9", "Lucien", ""]]}, {"id": "1402.3748", "submitter": "Shifeng Xiong Doc", "authors": "Shifeng Xiong", "title": "Better Solution Principle: A Facet of Concordance between Optimization\n  and Statistics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many statistical methods require solutions to optimization problems. When the\nglobal solution is hard to attain, statisticians always use the better if there\nare two solutions for chosen, where the word \"better\" is understood in the\nsense of optimization. This seems reasonable in that the better solution is\nmore likely to be the global solution, whose statistical properties of interest\nusually have been well established. From the statistical perspective, we use\nthe better solution because we intuitively believe the principle, called better\nsolution principle (BSP) in this paper, that a better solution to a statistical\noptimization problem also has better statistical properties of interest. BSP\ndisplays some concordance between optimization and statistics, and is expected\nto widely hold. Since theoretical study on BSP seems to be neglected by\nstatisticians, this paper aims to establish a framework for discussing BSP in\nvarious statistical optimization problems. We demonstrate several simple but\neffective comparison theorems as the key results of this paper, and apply them\nto verify BSP in commonly encountered statistical optimization problems,\nincluding maximum likelihood estimation, best subsample selection, and best\nsubset regression. It can be seen that BSP for these problems holds under\nreasonable conditions, i.e., a better solution indeed has better statistical\nproperties of interest. In addition, guided by the BSP theory, we develop a new\nbest subsample selection method that performs well when there are clustered\noutliers.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2014 02:43:51 GMT"}, {"version": "v2", "created": "Sat, 3 May 2014 13:13:13 GMT"}, {"version": "v3", "created": "Thu, 8 May 2014 03:04:39 GMT"}, {"version": "v4", "created": "Fri, 23 May 2014 00:13:37 GMT"}, {"version": "v5", "created": "Wed, 16 Jan 2019 02:11:32 GMT"}], "update_date": "2019-01-17", "authors_parsed": [["Xiong", "Shifeng", ""]]}, {"id": "1402.3835", "submitter": "Cl\\'ement Canonne", "authors": "Cl\\'ement Canonne and Ronitt Rubinfeld", "title": "Testing probability distributions underlying aggregated data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we analyze and study a hybrid model for testing and learning\nprobability distributions. Here, in addition to samples, the testing algorithm\nis provided with one of two different types of oracles to the unknown\ndistribution $D$ over $[n]$. More precisely, we define both the dual and\ncumulative dual access models, in which the algorithm $A$ can both sample from\n$D$ and respectively, for any $i\\in[n]$,\n  - query the probability mass $D(i)$ (query access); or\n  - get the total mass of $\\{1,\\dots,i\\}$, i.e. $\\sum_{j=1}^i D(j)$ (cumulative\naccess)\n  These two models, by generalizing the previously studied sampling and query\noracle models, allow us to bypass the strong lower bounds established for a\nnumber of problems in these settings, while capturing several interesting\naspects of these problems -- and providing new insight on the limitations of\nthe models. Finally, we show that while the testing algorithms can be in most\ncases strictly more efficient, some tasks remain hard even with this additional\npower.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2014 20:00:00 GMT"}], "update_date": "2014-02-18", "authors_parsed": [["Canonne", "Cl\u00e9ment", ""], ["Rubinfeld", "Ronitt", ""]]}, {"id": "1402.3921", "submitter": "Rajesh  Singh", "authors": "Prayas Sharma and Rajesh Singh", "title": "Improved ratio type estimator using two auxiliary variables under second\n  order approximation", "comments": "16 pages,1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we have proposed a new Ratio Type Estimator using auxiliary\ninformation on two auxiliary variables based on Simple random sampling without\nreplacement (SRSWOR). The proposed estimator is found to be more efficient than\nthe estimators constructed by Olkin (1958), Singh (1965), Lu (2010) and Singh\nand Kumar (2012) in terms of second order mean square error.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2014 08:03:27 GMT"}], "update_date": "2014-02-18", "authors_parsed": [["Sharma", "Prayas", ""], ["Singh", "Rajesh", ""]]}, {"id": "1402.4296", "submitter": "Catherine Matias", "authors": "Catherine Matias (LaMME, LPMA), St\\'ephane Robin", "title": "Modeling heterogeneity in random graphs through latent space models: a\n  selective review", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a selective review on probabilistic modeling of heterogeneity in\nrandom graphs. We focus on latent space models and more particularly on\nstochastic block models and their extensions that have undergone major\ndevelopments in the last five years.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2014 11:16:44 GMT"}, {"version": "v2", "created": "Thu, 25 Sep 2014 16:56:13 GMT"}], "update_date": "2014-09-26", "authors_parsed": [["Matias", "Catherine", "", "LaMME, LPMA"], ["Robin", "St\u00e9phane", ""]]}, {"id": "1402.4316", "submitter": "Ali Saeb Dr.", "authors": "Ali Saeb", "title": "Rates of convergence for Renyi entropy in extreme value theory", "comments": "arXiv admin note: text overlap with arXiv:1402.0947", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Max stable laws are limit laws of linearly normalized partial maxima of\nindependent identically distributed random variables. Saeb (2014) proves that\nthe Renyi entropy of order b (b > 1) of linear normalized maximum of iid random\nvariables with continuous differentiable density is convergent to the Renyi\nentropy of order b of the max stable laws. In this paper, we study the rate of\nconvergence result for Renyi entropy for linearly normalized partial maxima.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2014 12:57:38 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2014 12:49:05 GMT"}], "update_date": "2014-02-27", "authors_parsed": [["Saeb", "Ali", ""]]}, {"id": "1402.4520", "submitter": "Jos\\'e A. D\\'iaz-Garc\\'ia", "authors": "Jose A. Diaz-Garcia and Ramon Gutierrez-Sanchez", "title": "Generalised matrix multivariate $T$-distribution", "comments": "Several properties of q_{\\kappa} have been modified. arXiv admin\n  note: substantial text overlap with arXiv:1304.5292, arXiv:1301.4525,\n  arXiv:1211.1746. substantial text overlap with arXiv:1301.4525,\n  arXiv:1304.5292", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supposing Kotz-Riesz type I and II distributions and their corresponding\nindependent univariate Riesz distributions the associated generalised matrix\nmultivariate T distributions, termed matrix multivariate T-Riesz distributions\nare obtained. In addition, its various properties are studied. All these\nresults are obtained for real normed division algebras.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2014 22:47:28 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2015 17:07:07 GMT"}], "update_date": "2015-06-17", "authors_parsed": [["Diaz-Garcia", "Jose A.", ""], ["Gutierrez-Sanchez", "Ramon", ""]]}, {"id": "1402.4577", "submitter": "Alain Durmus", "authors": "Alain Durmus (LTCI), Gersende Fort (LTCI), Eric Moulines (LTCI)", "title": "Subgeometric rates of convergence in Wasserstein distance for Markov\n  chains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we provide sufficient conditions for the existence of the\ninvariant distribution and for subgeometric rates of convergence in Wasserstein\ndistance for general state-space Markov chains which are (possibly) not\nirreducible. Compared to previous work, our approach is based on a purely\nprobabilistic coupling construction which allows to retrieve rates of\nconvergence matching those previously reported for convergence in total\nvariation. Our results are applied to establish the subgeometric ergodicity in\nWasserstein distance of non-linear autoregressive models and of the\npre-conditioned Crank-Nicolson Markov chain Monte Carlo algorithm in Hilbert\nspace.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2014 07:52:33 GMT"}, {"version": "v2", "created": "Tue, 6 Jan 2015 17:42:00 GMT"}, {"version": "v3", "created": "Tue, 14 Jul 2015 14:20:48 GMT"}], "update_date": "2015-07-15", "authors_parsed": [["Durmus", "Alain", "", "LTCI"], ["Fort", "Gersende", "", "LTCI"], ["Moulines", "Eric", "", "LTCI"]]}, {"id": "1402.4773", "submitter": "Clement Marteau", "authors": "Yuri I. Ingster (LETI), B\\'eatrice Laurent (IMT, INSA Toulouse),\n  Cl\\'ement Marteau (IMT)", "title": "Signal detection for inverse problems in a multidimensional framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is devoted to multi-dimensional inverse problems. In this setting,\nwe address a goodness-of-fit testing problem. We investigate the separation\nrates associated to different kinds of smoothness assumptions and different\ndegrees of ill-posedness.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2014 19:16:56 GMT"}], "update_date": "2014-02-20", "authors_parsed": [["Ingster", "Yuri I.", "", "LETI"], ["Laurent", "B\u00e9atrice", "", "IMT, INSA Toulouse"], ["Marteau", "Cl\u00e9ment", "", "IMT"]]}, {"id": "1402.5107", "submitter": "Donatello Telesca", "authors": "David Rossell and Donatello Telesca", "title": "Non-Local Priors for High-Dimensional Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simultaneously achieving parsimony and good predictive power in high\ndimensions is a main challenge in statistics. Non-local priors (NLPs) possess\nappealing properties for high-dimensional model choice, but their use for\nestimation has not been studied in detail. We show that, for regular models,\nBayesian model averaging (BMA) estimates based on NLPs shrink spurious\nparameters either at fast polynomial or quasi-exponential rates as the sample\nsize $n$ increases (depending on the chosen prior density). Non-spurious\nparameter estimates only differ from the oracle MLE by a factor of $n^{-1}$. We\nextend some results to linear models with dimension $p$ growing with $n$.\n  Coupled with our theoretical investigations, we outline the constructive\nrepresentation of NLPs as mixtures of truncated distributions. From a\npractitioners' perspective, our work enables simple posterior sampling and\nextending NLPs beyond previous proposals. Our results show notable\nhigh-dimensional estimation for linear models with $p>>n$ at reduced\ncomputational cost. NLPs provided lower estimation error than benchmark and\nhyper-g priors, SCAD and LASSO in simulations, and in gene expression data\nachieved higher cross-validated $R^2$ with an order of magnitude less\npredictors. Remarkably, these results were obtained without the need to\npre-screen predictors. Our findings contribute to the debate of whether\ndifferent priors should be used for estimation and model selection, showing\nthat selection priors may actually be desirable for high-dimensional\nestimation.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2014 19:20:49 GMT"}, {"version": "v2", "created": "Wed, 16 Apr 2014 18:41:29 GMT"}, {"version": "v3", "created": "Wed, 21 Jan 2015 01:37:19 GMT"}], "update_date": "2015-01-22", "authors_parsed": [["Rossell", "David", ""], ["Telesca", "Donatello", ""]]}, {"id": "1402.5178", "submitter": "Jos\\'e A. D\\'iaz-Garc\\'ia", "authors": "Jose A. Diaz-Garcia and Ramon Gutierrez-Sanchez", "title": "Generalised matricvariate $T$-distribution", "comments": "Several properties of q_{\\kappa} have been modified and their\n  consequences in the manuscript. arXiv admin note: substantial text overlap\n  with arXiv:1402.4520, arXiv:1304.5292, arXiv:1301.4525, arXiv:1211.1746.\n  substantial text overlap with arXiv:1402.4520, arXiv:1301.4525,\n  arXiv:1304.5292", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Assuming Kotz-Riesz type I and II distributions and their corresponding\nindependent Riesz distributions the associated generalised matricvariate T\ndistributions, termed matricvariate T-Riesz distributions for real normed\ndivision algebras are obtained with respect to the Lebesgue measure. In\naddition some of their properties are also studied.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2014 01:36:32 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2015 01:07:37 GMT"}], "update_date": "2015-06-17", "authors_parsed": [["Diaz-Garcia", "Jose A.", ""], ["Gutierrez-Sanchez", "Ramon", ""]]}, {"id": "1402.5297", "submitter": "Felix Lucka", "authors": "Martin Burger and Felix Lucka", "title": "Maximum-A-Posteriori Estimates in Linear Inverse Problems with\n  Log-concave Priors are Proper Bayes Estimators", "comments": null, "journal-ref": null, "doi": "10.1088/0266-5611/30/11/114004", "report-no": null, "categories": "math.ST math.NA math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A frequent matter of debate in Bayesian inversion is the question, which of\nthe two principle point-estimators, the maximum-a-posteriori (MAP) or the\nconditional mean (CM) estimate is to be preferred. As the MAP estimate\ncorresponds to the solution given by variational regularization techniques,\nthis is also a constant matter of debate between the two research areas.\nFollowing a theoretical argument - the Bayes cost formalism - the CM estimate\nis classically preferred for being the Bayes estimator for the mean squared\nerror cost while the MAP estimate is classically discredited for being only\nasymptotically the Bayes estimator for the uniform cost function. In this\narticle we present recent theoretical and computational observations that\nchallenge this point of view, in particular for high-dimensional\nsparsity-promoting Bayesian inversion. Using Bregman distances, we present new,\nproper convex Bayes cost functions for which the MAP estimator is the Bayes\nestimator. We complement this finding by results that correct further common\nmisconceptions about MAP estimates. In total, we aim to rehabilitate MAP\nestimates in linear inverse problems with log-concave priors as proper Bayes\nestimators.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2014 13:53:54 GMT"}, {"version": "v2", "created": "Mon, 2 Jun 2014 08:26:04 GMT"}], "update_date": "2015-06-18", "authors_parsed": [["Burger", "Martin", ""], ["Lucka", "Felix", ""]]}, {"id": "1402.5431", "submitter": "Paul McNicholas", "authors": "Adelchi Azzalini, Ryan P. Browne, Marc G. Genton and Paul D.\n  McNicholas", "title": "On nomenclature for, and the relative merits of, two formulations of\n  skew distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine some distributions used extensively within the model-based\nclustering literature in recent years, paying special attention to} claims that\nhave been made about their relative efficacy. Theoretical arguments are\nprovided as well as real data examples.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2014 21:40:10 GMT"}, {"version": "v2", "created": "Tue, 1 Jul 2014 17:33:14 GMT"}, {"version": "v3", "created": "Thu, 3 Dec 2015 22:53:41 GMT"}], "update_date": "2015-12-07", "authors_parsed": [["Azzalini", "Adelchi", ""], ["Browne", "Ryan P.", ""], ["Genton", "Marc G.", ""], ["McNicholas", "Paul D.", ""]]}, {"id": "1402.5584", "submitter": "Divyanshu Vats", "authors": "Divyanshu Vats, Richard G. Baraniuk", "title": "Path Thresholding: Asymptotically Tuning-Free High-Dimensional Sparse\n  Regression", "comments": "AISTATS 2014", "journal-ref": "Proceedings of the 17th International Conference on Artificial\n  Intelligence and Statistics (AISTATS) 2014, Reykjavik, Iceland. JMLR: W&CP\n  volume 33", "doi": null, "report-no": null, "categories": "math.ST cs.IT math.IT stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we address the challenging problem of selecting tuning\nparameters for high-dimensional sparse regression. We propose a simple and\ncomputationally efficient method, called path thresholding (PaTh), that\ntransforms any tuning parameter-dependent sparse regression algorithm into an\nasymptotically tuning-free sparse regression algorithm. More specifically, we\nprove that, as the problem size becomes large (in the number of variables and\nin the number of observations), PaTh performs accurate sparse regression, under\nappropriate conditions, without specifying a tuning parameter. In\nfinite-dimensional settings, we demonstrate that PaTh can alleviate the\ncomputational burden of model selection algorithms by significantly reducing\nthe search space of tuning parameters.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2014 07:23:39 GMT"}], "update_date": "2014-02-25", "authors_parsed": [["Vats", "Divyanshu", ""], ["Baraniuk", "Richard G.", ""]]}, {"id": "1402.5596", "submitter": "Jason Lee", "authors": "Jason D Lee and Jonathan E Taylor", "title": "Exact Post Model Selection Inference for Marginal Screening", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a framework for post model selection inference, via marginal\nscreening, in linear regression. At the core of this framework is a result that\ncharacterizes the exact distribution of linear functions of the response $y$,\nconditional on the model being selected (``condition on selection\" framework).\nThis allows us to construct valid confidence intervals and hypothesis tests for\nregression coefficients that account for the selection procedure. In contrast\nto recent work in high-dimensional statistics, our results are exact\n(non-asymptotic) and require no eigenvalue-like assumptions on the design\nmatrix $X$. Furthermore, the computational cost of marginal regression,\nconstructing confidence intervals and hypothesis testing is negligible compared\nto the cost of linear regression, thus making our methods particularly suitable\nfor extremely large datasets. Although we focus on marginal screening to\nillustrate the applicability of the condition on selection framework, this\nframework is much more broadly applicable. We show how to apply the proposed\nframework to several other selection procedures including orthogonal matching\npursuit, non-negative least squares, and marginal screening+Lasso.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2014 10:30:21 GMT"}, {"version": "v2", "created": "Fri, 28 Feb 2014 00:28:21 GMT"}], "update_date": "2014-03-03", "authors_parsed": [["Lee", "Jason D", ""], ["Taylor", "Jonathan E", ""]]}, {"id": "1402.5609", "submitter": "Rajesh  Singh", "authors": "Prayas Sharma and Rajesh Singh", "title": "Efficient class of estimators for population median using auxiliary\n  information", "comments": "16 pages, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article suggests an efficient class of estimators of population median\nof the study variable using an auxiliary variable. Asymptotic expressions of\nbias and mean square error of the proposed class of estimators have been\nobtained. Asymptotic optimum estimator has been investigated along with its\napproximate mean square error. We have shown that proposed class of estimator\nis more efficient than estimator considered by Srivastava (1967), Gross (1980),\nKuk and Mak (1989) Singh et al. (2003b), Al and Chingi (2009) and Singh and\nSolanki (2013). In addition theoretical findings are supported by an empirical\nstudy based on two populations to show the superiority of the constructed\nestimators over others.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2014 14:08:24 GMT"}], "update_date": "2014-02-25", "authors_parsed": [["Sharma", "Prayas", ""], ["Singh", "Rajesh", ""]]}, {"id": "1402.5662", "submitter": "Yohann De Castro", "authors": "Yohann De Castro, Guillaume Mijoule", "title": "Non-uniform spline recovery from small degree polynomial approximation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.NA stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the sparse spikes deconvolution problem onto spaces of\nalgebraic polynomials. Our framework encompasses the measure reconstruction\nproblem from a combination of noiseless and noisy moment measurements. We study\na TV-norm regularization procedure to localize the support and estimate the\nweights of a target discrete measure in this frame. Furthermore, we derive\nquantitative bounds on the support recovery and the amplitudes errors under a\nChebyshev-type minimal separation condition on its support. Incidentally, we\nstudy the localization of the knots of non-uniform splines when a Gaussian\nperturbation of their inner-products with a known polynomial basis is observed\n(i.e. a small degree polynomial approximation is known) and the boundary\nconditions are known. We prove that the knots can be recovered in a grid-free\nmanner using semidefinite programming.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2014 20:11:50 GMT"}, {"version": "v2", "created": "Wed, 27 May 2015 07:16:34 GMT"}], "update_date": "2015-05-28", "authors_parsed": [["De Castro", "Yohann", ""], ["Mijoule", "Guillaume", ""]]}, {"id": "1402.5693", "submitter": "Reza Parseh", "authors": "Reza Parseh, Kimmo Kansanen", "title": "On Estimation Error Outage for Scalar Gauss-Markov Signals Sent Over\n  Fading Channels", "comments": "21 pages, 5 figures, conference version at EUSIPCO 2014, accepted for\n  publication in IEEE Transactions on Signal Processing", "journal-ref": null, "doi": "10.1109/TSP.2014.2360820", "report-no": null, "categories": "cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Measurements of a scalar linear Gauss-Markov process are sent over a fading\nchannel. The fading channel is modeled as independent and identically\ndistributed random variables with known realization at the receiver. The\noptimal estimator at the receiver is the Kalman filter. In contrast to the\nclassical Kalman filter theory, given a random channel, the Kalman gain and the\nerror covariance become random. Then the probability distribution function of\nexpected estimation error and its outage probability can be chosen for\nestimation quality assessment. In this paper and in order to get the estimation\nerror outage, we provide means to characterize the stationary probability\ndensity function of the random expected estimation error. Furthermore and for\nthe particular case of the i.i.d. Rayleigh fading channels, upper and lower\nbounds for the outage probability are derived which provide insight and simpler\nmeans for design purposes. We also show that the bounds are tight for the high\nSNR regime, and that the outage probability decreases linearly with the inverse\nof the average channel SNR.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2014 00:23:05 GMT"}, {"version": "v2", "created": "Fri, 25 Apr 2014 10:16:06 GMT"}, {"version": "v3", "created": "Fri, 17 Oct 2014 09:53:23 GMT"}], "update_date": "2014-10-20", "authors_parsed": [["Parseh", "Reza", ""], ["Kansanen", "Kimmo", ""]]}, {"id": "1402.5731", "submitter": "Cem Aksoylar", "authors": "Cem Aksoylar and Venkatesh Saligrama", "title": "Information-Theoretic Bounds for Adaptive Sparse Recovery", "comments": "Accepted to IEEE ISIT 2014. Better presentation and fixed errors\n  compared to the previous version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive an information-theoretic lower bound for sample complexity in\nsparse recovery problems where inputs can be chosen sequentially and\nadaptively. This lower bound is in terms of a simple mutual information\nexpression and unifies many different linear and nonlinear observation models.\nUsing this formula we derive bounds for adaptive compressive sensing (CS),\ngroup testing and 1-bit CS problems. We show that adaptivity cannot decrease\nsample complexity in group testing, 1-bit CS and CS with linear sparsity. In\ncontrast, we show there might be mild performance gains for CS in the sublinear\nregime. Our unified analysis also allows characterization of gains due to\nadaptivity from a wider perspective on sparse problems.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2014 06:20:34 GMT"}, {"version": "v2", "created": "Tue, 29 Apr 2014 19:18:08 GMT"}], "update_date": "2014-04-30", "authors_parsed": [["Aksoylar", "Cem", ""], ["Saligrama", "Venkatesh", ""]]}, {"id": "1402.5763", "submitter": "Guillaume Lecu\\'{e}", "authors": "Guillaume Lecu\\'e, Shahar Mendelson", "title": "Performance of empirical risk minimization in linear aggregation", "comments": "Published at http://dx.doi.org/10.3150/15-BEJ701 in the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2016, Vol. 22, No. 3, 1520-1534", "doi": "10.3150/15-BEJ701", "report-no": "IMS-BEJ-BEJ701", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study conditions under which, given a dictionary $F=\\{f_1,\\ldots ,f_M\\}$\nand an i.i.d. sample $(X_i,Y_i)_{i=1}^N$, the empirical minimizer in\n$\\operatorname {span}(F)$ relative to the squared loss, satisfies that with\nhigh probability\n\\[R\\bigl(\\tilde{f}^{\\mathrm{ERM}}\\bigr)\\leq\\inf_{f\\in\\operatorname\n{span}(F)}R(f)+r_N(M),\\] where $R(\\cdot)$ is the squared risk and $r_N(M)$ is\nof the order of $M/N$. Among other results, we prove that a uniform small-ball\nestimate for functions in $\\operatorname {span}(F)$ is enough to achieve that\ngoal when the noise is independent of the design.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2014 09:46:46 GMT"}, {"version": "v2", "created": "Mon, 2 Feb 2015 08:19:19 GMT"}, {"version": "v3", "created": "Thu, 17 Mar 2016 14:31:39 GMT"}], "update_date": "2016-03-18", "authors_parsed": [["Lecu\u00e9", "Guillaume", ""], ["Mendelson", "Shahar", ""]]}, {"id": "1402.6257", "submitter": "Christian P. Robert", "authors": "Kaniav Kamary (CEREMADE, Universit\\'e Paris-Dauphine) and Christian P.\n  Robert (CEREMADE, Universit\\'e Paris-Dauphine and University of Warwick)", "title": "Reflecting about Selecting Noninformative Priors", "comments": "15 pages, 8 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Following the critical review of Seaman et al. (2012), we reflect on what is\npresumably the most essential aspect of Bayesian statistics, namely the\nselection of a prior density. In some cases, Bayesian inference remains fairly\nstable under a large range of noninformative prior distributions. However, as\ndiscussed by \\citet{Hd}, there may also be unintended consequences of a choice\nof a noninformative prior and, these authors consider this problem ignored in\nBayesian studies. As they based their argumentation on four examples, we\nreassess these examples and their Bayesian processing via different prior\nchoices. Our conclusion is to lower the degree of worry about the impact of the\nprior, exhibiting an overall stability of the posterior distributions. We thus\nconsider that the warnings of Seaman et al. (2012), while commendable, do not\njeopardize the use of most noninformative priors.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2014 17:53:54 GMT"}, {"version": "v2", "created": "Fri, 14 Mar 2014 11:32:31 GMT"}, {"version": "v3", "created": "Tue, 22 Jul 2014 09:31:31 GMT"}], "update_date": "2014-07-23", "authors_parsed": [["Kamary", "Kaniav", "", "CEREMADE, Universit\u00e9 Paris-Dauphine"], ["Robert", "Christian P.", "", "CEREMADE, Universit\u00e9 Paris-Dauphine and University of Warwick"]]}, {"id": "1402.6305", "submitter": "Stephane Boucheron", "authors": "Boucheron Stephane and Elisabeth Gassiat and Mesrob I. Ohannessian", "title": "About Adaptive Coding on Countable Alphabets: Max-Stable Envelope\n  Classes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of lossless universal source coding for\nstationary memoryless sources on countably infinite alphabets. This task is\ngenerally not achievable without restricting the class of sources over which\nuniversality is desired. Building on our prior work, we propose natural\nfamilies of sources characterized by a common dominating envelope. We\nparticularly emphasize the notion of adaptivity, which is the ability to\nperform as well as an oracle knowing the envelope, without actually knowing it.\nThis is closely related to the notion of hierarchical universal source coding,\nbut with the important difference that families of envelope classes are not\ndiscretely indexed and not necessarily nested.\n  Our contribution is to extend the classes of envelopes over which adaptive\nuniversal source coding is possible, namely by including max-stable\n(heavy-tailed) envelopes which are excellent models in many applications, such\nas natural language modeling. We derive a minimax lower bound on the redundancy\nof any code on such envelope classes, including an oracle that knows the\nenvelope. We then propose a constructive code that does not use knowledge of\nthe envelope. The code is computationally efficient and is structured to use an\n{E}xpanding {T}hreshold for {A}uto-{C}ensoring, and we therefore dub it the\n\\textsc{ETAC}-code. We prove that the \\textsc{ETAC}-code achieves the lower\nbound on the minimax redundancy within a factor logarithmic in the sequence\nlength, and can be therefore qualified as a near-adaptive code over families of\nheavy-tailed envelopes. For finite and light-tailed envelopes the penalty is\neven less, and the same code follows closely previous results that explicitly\nmade the light-tailed assumption. Our technical results are founded on methods\nfrom regular variation theory and concentration of measure.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2014 20:33:56 GMT"}, {"version": "v2", "created": "Fri, 17 Apr 2015 14:20:25 GMT"}], "update_date": "2015-04-20", "authors_parsed": [["Stephane", "Boucheron", ""], ["Gassiat", "Elisabeth", ""], ["Ohannessian", "Mesrob I.", ""]]}, {"id": "1402.6409", "submitter": "Leonid Sirota", "authors": "E.Ostrovsky, L.Sirota, A.Zeldin", "title": "Rate of convergence in the maximum likelihood estimation for partial\n  discrete parameter, with applications to the cluster analysis and philology", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of estimation of the distribution parameters on the sample when\nthe part of these parameters are discrete (e.g. integer) is considered. We\nprove that the rate of convergence of MLE estimates under the natural\nconditions on the distribution density is exponentially fast.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2014 04:55:37 GMT"}], "update_date": "2014-02-27", "authors_parsed": [["Ostrovsky", "E.", ""], ["Sirota", "L.", ""], ["Zeldin", "A.", ""]]}, {"id": "1402.6419", "submitter": "Damien Passemier", "authors": "Damien Passemier (ECE), Matthew R. Mckay (ECE), Yang Chen", "title": "Asymptotic Linear Spectral Statistics for Spiked Hermitian Random Matrix\n  Models", "comments": null, "journal-ref": null, "doi": "10.1007/s10955-015-1233-x", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using the Coulomb Fluid method, this paper derives central limit theorems\n(CLTs) for linear spectral statistics of three \"spiked\" Hermitian random matrix\nensembles. These include Johnstone's spiked model (i.e., central Wishart with\nspiked correlation), non-central Wishart with rank-one non-centrality, and a\nrelated class of non-central $F$ matrices. For a generic linear statistic, we\nderive simple and explicit CLT expressions as the matrix dimensions grow large.\nFor all three ensembles under consideration, we find that the primary effect of\nthe spike is to introduce an $O(1)$ correction term to the asymptotic mean of\nthe linear spectral statistic, which we characterize with simple formulas. The\nutility of our proposed framework is demonstrated through application to three\ndifferent linear statistics problems: the classical likelihood ratio test for a\npopulation covariance, the capacity analysis of multi-antenna wireless\ncommunication systems with a line-of-sight transmission path, and a classical\nmultiple sample significance testing problem.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2014 05:51:22 GMT"}], "update_date": "2015-06-18", "authors_parsed": [["Passemier", "Damien", "", "ECE"], ["Mckay", "Matthew R.", "", "ECE"], ["Chen", "Yang", ""]]}, {"id": "1402.6550", "submitter": "Jushan Bai", "authors": "Jushan Bai, Kunpeng Li", "title": "Theory and methods of panel data models with interactive effects", "comments": "Published in at http://dx.doi.org/10.1214/13-AOS1183 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2014, Vol. 42, No. 1, 142-170", "doi": "10.1214/13-AOS1183", "report-no": "IMS-AOS-AOS1183", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the maximum likelihood estimation of panel data models\nwith interactive effects. Motivated by applications in economics and other\nsocial sciences, a notable feature of the model is that the explanatory\nvariables are correlated with the unobserved effects. The usual within-group\nestimator is inconsistent. Existing methods for consistent estimation are\neither designed for panel data with short time periods or are less efficient.\nThe maximum likelihood estimator has desirable properties and is easy to\nimplement, as illustrated by the Monte Carlo simulations. This paper develops\nthe inferential theory for the maximum likelihood estimator, including\nconsistency, rate of convergence and the limiting distributions. We further\nextend the model to include time-invariant regressors and common regressors\n(cross-section invariant). The regression coefficients for the time-invariant\nregressors are time-varying, and the coefficients for the common regressors are\ncross-sectionally varying.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2014 14:16:17 GMT"}], "update_date": "2014-02-27", "authors_parsed": [["Bai", "Jushan", ""], ["Li", "Kunpeng", ""]]}, {"id": "1402.6769", "submitter": "Jay Bartroff", "authors": "Jay Bartroff, Larry Goldstein and \\\"Umit I\\c{s}lak", "title": "Bounded size biased couplings, log concave distributions and\n  concentration of measure for occupancy models", "comments": "35 pages. Version 2 is the result of a major revision, including\n  corrections and significant clarifications in particular as regards Lemmas\n  2.6 and 2.7, and the introduction and use of Property (B,*) in Definition\n  2.2. Version 3 added some references and removed Theorem 1.1", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Threshold-type counts based on multivariate occupancy models with log concave\nmarginals admit bounded size biased couplings under weak conditions, leading to\nnew concentration of measure results for random graphs, germ-grain models in\nstochastic geometry, multinomial allocation models and multivariate\nhypergeometric sampling. The work generalizes and improves upon previous\nresults in a number of directions.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2014 02:21:37 GMT"}, {"version": "v2", "created": "Tue, 21 Jul 2015 21:48:24 GMT"}, {"version": "v3", "created": "Tue, 23 May 2017 23:30:05 GMT"}], "update_date": "2017-05-25", "authors_parsed": [["Bartroff", "Jay", ""], ["Goldstein", "Larry", ""], ["I\u015flak", "\u00dcmit", ""]]}, {"id": "1402.6806", "submitter": "Xingdong Feng", "authors": "Xingdong Feng, Xuming He", "title": "Statistical inference based on robust low-rank data matrix approximation", "comments": "Published in at http://dx.doi.org/10.1214/13-AOS1186 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2014, Vol. 42, No. 1, 190-210", "doi": "10.1214/13-AOS1186", "report-no": "IMS-AOS-AOS1186", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The singular value decomposition is widely used to approximate data matrices\nwith lower rank matrices. Feng and He [Ann. Appl. Stat. 3 (2009) 1634-1654]\ndeveloped tests on dimensionality of the mean structure of a data matrix based\non the singular value decomposition. However, the first singular values and\nvectors can be driven by a small number of outlying measurements. In this\npaper, we consider a robust alternative that moderates the effect of outliers\nin low-rank approximations. Under the assumption of random row effects, we\nprovide the asymptotic representations of the robust low-rank approximation.\nThese representations may be used in testing the adequacy of a low-rank\napproximation. We use oligonucleotide gene microarray data to demonstrate how\nrobust singular value decomposition compares with the its traditional\ncounterparts. Examples show that the robust methods often lead to a more\nmeaningful assessment of the dimensionality of gene intensity data matrices.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2014 07:06:45 GMT"}], "update_date": "2014-02-28", "authors_parsed": [["Feng", "Xingdong", ""], ["He", "Xuming", ""]]}]