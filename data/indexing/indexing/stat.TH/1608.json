[{"id": "1608.00032", "submitter": "Michael Trosset", "authors": "Michael W. Trosset, Mingyue Gao, Carey E. Priebe", "title": "On the Power of Likelihood Ratio Tests in Dimension-Restricted Submodels", "comments": "21 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Likelihood ratio tests are widely used to test statistical hypotheses about\nparametric families of probability distributions. If interest is restricted to\na subfamily of distributions, then it is natural to inquire if the restricted\nLRT is superior to the unrestricted LRT. Marden's general LRT conjecture posits\nthat any restriction placed on the alternative hypothesis will increase power.\nThe only published counterexample to this conjecture is rather technical and\ninvolves a restriction that maintains the dimension of the alternative. We\nformulate the dimension-restricted LRT conjecture, which posits that any\nrestriction that replaces a parametric family with a subfamily of lower\ndimension will increase power. Under standard regularity conditions, we then\ndemonstrate that the restricted LRT is asymptotically more powerful than the\nunrestricted LRT for local alternatives. Remarkably, however, even the\ndimension-restricted LRT conjecture fails in the case of finite samples. Our\ncounterexamples involve subfamilies of multinomial distributions. In\nparticular, our study of the Hardy-Weinberg subfamily of trinomial\ndistributions provides a simple and elegant demonstration that restrictions may\nnot increase power.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jul 2016 21:23:39 GMT"}], "update_date": "2016-08-02", "authors_parsed": [["Trosset", "Michael W.", ""], ["Gao", "Mingyue", ""], ["Priebe", "Carey E.", ""]]}, {"id": "1608.00033", "submitter": "Whitney Newey", "authors": "Victor Chernozhukov, Juan Carlos Escanciano, Hidehiko Ichimura,\n  Whitney K. Newey, James M. Robins", "title": "Locally Robust Semiparametric Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST econ.EM stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many economic and causal parameters depend on nonparametric or high\ndimensional first steps. We give a general construction of locally\nrobust/orthogonal moment functions for GMM, where moment conditions have zero\nderivative with respect to first steps. We show that orthogonal moment\nfunctions can be constructed by adding to identifying moments the nonparametric\ninfluence function for the effect of the first step on identifying moments.\nOrthogonal moments reduce model selection and regularization bias, as is very\nimportant in many applications, especially for machine learning first steps.\n  We give debiased machine learning estimators of functionals of high\ndimensional conditional quantiles and of dynamic discrete choice parameters\nwith high dimensional state variables. We show that adding to identifying\nmoments the nonparametric influence function provides a general construction of\northogonal moments, including regularity conditions, and show that the\nnonparametric influence function is robust to additional unknown functions on\nwhich it depends. We give a general approach to estimating the unknown\nfunctions in the nonparametric influence function and use it to automatically\ndebias estimators of functionals of high dimensional conditional location\nlearners. We give a variety of new doubly robust moment equations and\ncharacterize double robustness. We give general and simple regularity\nconditions and apply these for asymptotic inference on functionals of high\ndimensional regression quantiles and dynamic discrete choice parameters with\nhigh dimensional state variables.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jul 2016 21:32:27 GMT"}, {"version": "v2", "created": "Thu, 31 May 2018 22:08:06 GMT"}, {"version": "v3", "created": "Tue, 21 Jul 2020 04:29:14 GMT"}, {"version": "v4", "created": "Mon, 3 Aug 2020 16:19:39 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Chernozhukov", "Victor", ""], ["Escanciano", "Juan Carlos", ""], ["Ichimura", "Hidehiko", ""], ["Newey", "Whitney K.", ""], ["Robins", "James M.", ""]]}, {"id": "1608.00088", "submitter": "M Rauf Ahmad Dr", "authors": "M. Rauf Ahmad and Tatjana Pavlenko", "title": "A $U$-classifier for high-dimensional data under non-normality", "comments": "24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A classifier for two or more samples is proposed when the data are\nhigh-dimensional and the underlying distributions may be non-normal. The\nclassifier is constructed as a linear combination of two easily computable and\ninterpretable components, the $U$-component and the $P$-component. The\n$U$-component is a linear combination of $U$-statistics which are averages of\nbilinear forms of pairwise distinct vectors from two independent samples. The\n$P$-component is the discriminant score and is a function of the projection of\nthe $U$-component on the observation to be classified. Combined, the two\ncomponents constitute an inherently bias-adjusted classifier valid for\nhigh-dimensional data. The simplicity of the classifier helps conveniently\nstudy its properties, including its asymptotic normal limit, and extend it to\nmulti-sample case. The classifier is linear but its linearity does not rest on\nthe assumption of homoscedasticity. Probabilities of misclassification and\nasymptotic properties of their empirical versions are discussed in detail.\nSimulation results are used to show the accuracy of the proposed classifier for\nsample sizes as small as 5 or 7 and any large dimensions. Applications on real\ndata sets are also demonstrated.\n", "versions": [{"version": "v1", "created": "Sat, 30 Jul 2016 08:01:00 GMT"}], "update_date": "2016-08-02", "authors_parsed": [["Ahmad", "M. Rauf", ""], ["Pavlenko", "Tatjana", ""]]}, {"id": "1608.00107", "submitter": "Scott Sisson", "authors": "Xin Zhang and Boris Beranger and Scott A. Sisson", "title": "Constructing Likelihood Functions for Interval-valued Random Variables", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a growing need for the ability to analyse interval-valued data.\nHowever, existing descriptive frameworks to achieve this ignore the process by\nwhich interval-valued data are typically constructed; namely by the aggregation\nof real-valued data generated from some underlying process. In this article we\ndevelop the foundations of likelihood based statistical inference for random\nintervals that directly incorporates the underlying generative procedure into\nthe analysis. That is, it permits the direct fitting of models for the\nunderlying real-valued data given only the random interval-valued summaries.\nThis generative approach overcomes several problems associated with existing\nmethods, including the rarely satisfied assumption of within-interval\nuniformity. The new methods are illustrated by simulated and real data\nanalyses.\n", "versions": [{"version": "v1", "created": "Sat, 30 Jul 2016 12:03:33 GMT"}, {"version": "v2", "created": "Thu, 7 Mar 2019 00:19:52 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["Zhang", "Xin", ""], ["Beranger", "Boris", ""], ["Sisson", "Scott A.", ""]]}, {"id": "1608.00264", "submitter": "Mingyuan Zhou", "authors": "Mingyuan Zhou, Stefano Favaro, Stephen G Walker", "title": "Frequency of Frequencies Distributions and Size Dependent Exchangeable\n  Random Partitions", "comments": "To appear in the Journal of the American Statistical Association\n  (Theory and Methods). 26 pages + 17 page supplement, 19 figures. arXiv admin\n  note: text overlap with arXiv:1410.3155", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the fundamental problem of modeling the frequency of frequencies\n(FoF) distribution, this paper introduces the concept of a cluster structure to\ndefine a probability function that governs the joint distribution of a random\ncount and its exchangeable random partitions. A cluster structure, naturally\narising from a completely random measure mixed Poisson process, allows the\nprobability distribution of the random partitions of a subset of a population\nto be dependent on the population size, a distinct and motivated feature that\nmakes it more flexible than a partition structure. This allows it to model an\nentire FoF distribution whose structural properties change as the population\nsize varies. A FoF vector can be simulated by drawing an infinite number of\nPoisson random variables, or by a stick-breaking construction with a finite\nrandom number of steps. A generalized negative binomial process model is\nproposed to generate a cluster structure, where in the prior the number of\nclusters is finite and Poisson distributed, and the cluster sizes follow a\ntruncated negative binomial distribution. We propose a simple Gibbs sampling\nalgorithm to extrapolate the FoF vector of a population given the FoF vector of\na sample taken without replacement from the population. We illustrate our\nresults and demonstrate the advantages of the proposed models through the\nanalysis of real text, genomic, and survey data.\n", "versions": [{"version": "v1", "created": "Sun, 31 Jul 2016 21:26:50 GMT"}], "update_date": "2016-08-02", "authors_parsed": [["Zhou", "Mingyuan", ""], ["Favaro", "Stefano", ""], ["Walker", "Stephen G", ""]]}, {"id": "1608.00485", "submitter": "Benedikt Funke", "authors": "Benedikt Funke and Masayuki Hirukawa", "title": "Nonparametric Estimation and Testing on Discontinuity of Positive\n  Supported Densities: A Kernel Truncation Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discontinuity in density functions is of economic importance and interest.\nFor instance, in studies on regression discontinuity designs, discontinuity in\nthe density of a running variable suggests violation of the no-manipulation\nassumption. In this paper we develop estimation and testing procedures on\ndiscontinuity in densities with positive support. Our approach is built on\nsplitting the gamma kernel (Chen, 2000) into two parts at a given\n(dis)continuity point and constructing two truncated kernels. The jump-size\nmagnitude of the density at the point can be estimated nonparametrically by two\nkernels and a multiplicative bias correction method. The estimator is easy to\nimplement, and its convergence properties are delivered by various\napproximation techniques on incomplete gamma functions. Based on the jump-size\nestimator, two versions of test statistics for the null of continuity at a\ngiven point are also proposed. Moreover, estimation theory of the entire\ndensity in the presence of a discontinuity point is explored. Monte Carlo\nsimulations confirm nice finite-sample properties of the jump-size estimator\nand the test statistics.\n", "versions": [{"version": "v1", "created": "Mon, 1 Aug 2016 16:33:01 GMT"}], "update_date": "2016-08-02", "authors_parsed": [["Funke", "Benedikt", ""], ["Hirukawa", "Masayuki", ""]]}, {"id": "1608.00512", "submitter": "Giovanni Migliorati", "authors": "Albert Cohen, Giovanni Migliorati", "title": "Optimal weighted least-squares methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of reconstructing an unknown bounded function $u$\ndefined on a domain $X\\subset \\mathbb{R}^d$ from noiseless or noisy samples of\n$u$ at $n$ points $(x^i)_{i=1,\\dots,n}$. We measure the reconstruction error in\na norm $L^2(X,d\\rho)$ for some given probability measure $d\\rho$. Given a\nlinear space $V_m$ with ${\\rm dim}(V_m)=m\\leq n$, we study in general terms the\nweighted least-squares approximations from the spaces $V_m$ based on\nindependent random samples. The contribution of the present paper is twofold.\nFrom the theoretical perspective, we establish results in expectation and in\nprobability for weighted least squares in general approximation spaces $V_m$.\nThese results show that for an optimal choice of sampling measure $d\\mu$ and\nweight $w$, which depends on the space $V_m$ and on the measure $d\\rho$,\nstability and optimal accuracy are achieved under the mild condition that $n$\nscales linearly with $m$ up to an additional logarithmic factor. The present\nanalysis covers also cases where the function $u$ and its approximants from\n$V_m$ are unbounded, which might occur for instance in the relevant case where\n$X=\\mathbb{R}^d$ and $d\\rho$ is the Gaussian measure. From the numerical\nperspective, we propose a sampling method which allows one to generate\nindependent and identically distributed samples from the optimal measure\n$d\\mu$. This method becomes of interest in the multivariate setting where\n$d\\mu$ is generally not of tensor product type. We illustrate this for\nparticular examples of approximation spaces $V_m$ of polynomial type, where the\ndomain $X$ is allowed to be unbounded and high or even infinite dimensional,\nmotivated by certain applications to parametric and stochastic PDEs.\n", "versions": [{"version": "v1", "created": "Mon, 1 Aug 2016 18:16:54 GMT"}], "update_date": "2016-08-02", "authors_parsed": [["Cohen", "Albert", ""], ["Migliorati", "Giovanni", ""]]}, {"id": "1608.00524", "submitter": "Yao Xie", "authors": "Yang Cao, Vincent Guigues, Anatoli Juditsky, Arkadi Nemirovski, Yao\n  Xie", "title": "Change Detection via Affine and Quadratic Detectors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of the paper is to develop a specific application of the convex\noptimization based hypothesis testing techniques developed in A. Juditsky, A.\nNemirovski, \"Hypothesis testing via affine detectors,\" Electronic Journal of\nStatistics 10:2204--2242, 2016. Namely, we consider the Change Detection\nproblem as follows: given an evolving in time noisy observations of outputs of\na discrete-time linear dynamical system, we intend to decide, in a sequential\nfashion, on the null hypothesis stating that the input to the system is a\nnuisance, vs. the alternative stating that the input is a \"nontrivial signal,\"\nwith both the nuisances and the nontrivial signals modeled as inputs belonging\nto finite unions of some given convex sets. Assuming the observation noises\nzero mean sub-Gaussian, we develop \"computation-friendly\" sequential decision\nrules and demonstrate that in our context these rules are provably\nnear-optimal.\n", "versions": [{"version": "v1", "created": "Mon, 1 Aug 2016 18:57:49 GMT"}, {"version": "v2", "created": "Sat, 1 Oct 2016 01:11:06 GMT"}, {"version": "v3", "created": "Thu, 6 Oct 2016 16:09:33 GMT"}, {"version": "v4", "created": "Tue, 22 Nov 2016 23:31:55 GMT"}, {"version": "v5", "created": "Thu, 15 Jun 2017 15:43:08 GMT"}, {"version": "v6", "created": "Wed, 16 Aug 2017 18:53:06 GMT"}, {"version": "v7", "created": "Thu, 16 Nov 2017 00:05:57 GMT"}, {"version": "v8", "created": "Sun, 7 Jan 2018 19:24:03 GMT"}], "update_date": "2018-01-09", "authors_parsed": [["Cao", "Yang", ""], ["Guigues", "Vincent", ""], ["Juditsky", "Anatoli", ""], ["Nemirovski", "Arkadi", ""], ["Xie", "Yao", ""]]}, {"id": "1608.00624", "submitter": "Johannes Lederer", "authors": "Johannes Lederer, Lu Yu, Irina Gaynanova", "title": "Oracle Inequalities for High-dimensional Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The abundance of high-dimensional data in the modern sciences has generated\ntremendous interest in penalized estimators such as the lasso, scaled lasso,\nsquare-root lasso, elastic net, and many others. In this paper, we establish a\ngeneral oracle inequality for prediction in high-dimensional linear regression\nwith such methods. Since the proof relies only on convexity and continuity\narguments, the result holds irrespective of the design matrix and applies to a\nwide range of penalized estimators. Overall, the bound demonstrates that\ngeneric estimators can provide consistent prediction with any design matrix.\nFrom a practical point of view, the bound can help to identify the potential of\nspecific estimators, and they can help to get a sense of the prediction\naccuracy in a given application.\n", "versions": [{"version": "v1", "created": "Mon, 1 Aug 2016 21:42:55 GMT"}, {"version": "v2", "created": "Tue, 13 Mar 2018 12:58:57 GMT"}], "update_date": "2018-03-14", "authors_parsed": [["Lederer", "Johannes", ""], ["Yu", "Lu", ""], ["Gaynanova", "Irina", ""]]}, {"id": "1608.00696", "submitter": "Noureddine El Karoui", "authors": "Noureddine El Karoui and Elizabeth Purdom", "title": "Can we trust the bootstrap in high-dimension?", "comments": null, "journal-ref": null, "doi": null, "report-no": "Tech-report 824", "categories": "stat.ME math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the performance of the bootstrap in high-dimensions for the\nsetting of linear regression, where $p<n$ but $p/n$ is not close to zero. We\nconsider ordinary least-squares as well as robust regression methods and adopt\na minimalist performance requirement: can the bootstrap give us good confidence\nintervals for a single coordinate of $\\beta$? (where $\\beta$ is the true\nregression vector).\n  We show through a mix of numerical and theoretical work that the bootstrap is\nfraught with problems. Both of the most commonly used methods of bootstrapping\nfor regression -- residual bootstrap and pairs bootstrap -- give very poor\ninference on $\\beta$ as the ratio $p/n$ grows. We find that the residuals\nbootstrap tend to give anti-conservative estimates (inflated Type I error),\nwhile the pairs bootstrap gives very conservative estimates (severe loss of\npower) as the ratio $p/n$ grows. We also show that the jackknife resampling\ntechnique for estimating the variance of $\\hat{\\beta}$ severely overestimates\nthe variance in high dimensions.\n  We contribute alternative bootstrap procedures based on our theoretical\nresults that mitigate these problems. However, the corrections depend on\nassumptions regarding the underlying data-generation model, suggesting that in\nhigh-dimensions it may be difficult to have universal, robust bootstrapping\ntechniques.\n", "versions": [{"version": "v1", "created": "Tue, 2 Aug 2016 05:10:39 GMT"}], "update_date": "2016-08-03", "authors_parsed": [["Karoui", "Noureddine El", ""], ["Purdom", "Elizabeth", ""]]}, {"id": "1608.00733", "submitter": "Matteo Ruggiero", "authors": "Matteo Ruggiero and Matteo Sordello", "title": "Clustering dynamics in a class of normalised generalised gamma dependent\n  priors", "comments": "To appear in the Annals of the Institute of Statistical Mathematics", "journal-ref": null, "doi": "10.1007/s10463-016-0583-8", "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Normalised generalised gamma processes are random probability measures that\ninduce nonparametric prior distributions widely used in Bayesian statistics,\nparticularly for mixture modelling. We construct a class of dependent\nnormalised generalised gamma priors induced by a stationary population model of\nMoran type, which exploits a generalised P\\'olya urn scheme associated with the\nprior. We study the asymptotic scaling for the dynamics of the number of\nclusters in the sample, which in turn provides a dynamic measure of diversity\nin the underlying population. The limit is formalised to be a positive\nnonstationary diffusion process which falls outside well known families, with\nunbounded drift and an entrance boundary at the origin. We also introduce a new\nclass of stationary positive diffusions, whose invariant measures are explicit\nand have power law tails, which approximate weakly the scaling limit.\n", "versions": [{"version": "v1", "created": "Tue, 2 Aug 2016 08:47:32 GMT"}, {"version": "v2", "created": "Fri, 4 Nov 2016 08:27:03 GMT"}], "update_date": "2016-11-07", "authors_parsed": [["Ruggiero", "Matteo", ""], ["Sordello", "Matteo", ""]]}, {"id": "1608.00757", "submitter": "Gabor Lugosi", "authors": "Gabor Lugosi and Shahar Mendelson", "title": "Risk minimization by median-of-means tournaments", "comments": "40 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the classical statistical learning/regression problem, when the\nvalue of a real random variable Y is to be predicted based on the observation\nof another random variable X. Given a class of functions F and a sample of\nindependent copies of (X, Y ), one needs to choose a function f from F such\nthat f(X) approximates Y as well as possible, in the mean-squared sense. We\nintroduce a new procedure, the so-called median-of-means tournament, that\nachieves the optimal tradeoff between accuracy and confidence under minimal\nassumptions, and in particular outperforms classical methods based on empirical\nrisk minimization.\n", "versions": [{"version": "v1", "created": "Tue, 2 Aug 2016 10:18:37 GMT"}], "update_date": "2016-08-03", "authors_parsed": [["Lugosi", "Gabor", ""], ["Mendelson", "Shahar", ""]]}, {"id": "1608.00948", "submitter": "Noureddine El Karoui", "authors": "Noureddine El Karoui and Elizabeth Purdom", "title": "The bootstrap, covariance matrices and PCA in moderate and\n  high-dimensions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the properties of the bootstrap as a tool for inference\nconcerning the eigenvalues of a sample covariance matrix computed from an\n$n\\times p$ data matrix $X$. We focus on the modern framework where $p/n$ is\nnot close to 0 but remains bounded as $n$ and $p$ tend to infinity.\n  Through a mix of numerical and theoretical considerations, we show that the\nbootstrap is not in general a reliable inferential tool in the setting we\nconsider. However, in the case where the population covariance matrix is\nwell-approximated by a finite rank matrix, the bootstrap performs as it does in\nfinite dimension.\n", "versions": [{"version": "v1", "created": "Tue, 2 Aug 2016 19:31:49 GMT"}], "update_date": "2016-08-03", "authors_parsed": [["Karoui", "Noureddine El", ""], ["Purdom", "Elizabeth", ""]]}, {"id": "1608.01118", "submitter": "Julien Bect", "authors": "Julien Bect (L2S, GdR MASCOT-NUM), Fran\\c{c}ois Bachoc (IMT), David\n  Ginsbourger (IMSV)", "title": "A supermartingale approach to Gaussian process based sequential design\n  of experiments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian process (GP) models have become a well-established frameworkfor the\nadaptive design of costly experiments, and notably of computerexperiments.\nGP-based sequential designs have been found practicallyefficient for various\nobjectives, such as global optimization(estimating the global maximum or\nmaximizer(s) of a function),reliability analysis (estimating a probability of\nfailure) or theestimation of level sets and excursion sets. In this paper, we\nstudythe consistency of an important class of sequential designs, known\nasstepwise uncertainty reduction (SUR) strategies. Our approach relieson the\nkey observation that the sequence of residual uncertaintymeasures, in SUR\nstrategies, is generally a supermartingale withrespect to the filtration\ngenerated by the observations. Thisobservation enables us to establish generic\nconsistency results for abroad class of SUR strategies. The consistency of\nseveral popularsequential design strategies is then obtained by means of this\ngeneralresult. Notably, we establish the consistency of two SUR\nstrategiesproposed by Bect, Ginsbourger, Li, Picheny and Vazquez (Stat.\nComp.,2012)---to the best of our knowledge, these are the first proofs\nofconsistency for GP-based sequential design algorithms dedicated to\ntheestimation of excursion sets and their measure. We also establish anew, more\ngeneral proof of consistency for the expected improvementalgorithm for global\noptimization which, unlike previous results inthe literature, applies to any GP\nwith continuous sample paths.\n", "versions": [{"version": "v1", "created": "Wed, 3 Aug 2016 09:01:07 GMT"}, {"version": "v2", "created": "Thu, 27 Jul 2017 08:03:25 GMT"}, {"version": "v3", "created": "Thu, 30 Aug 2018 13:13:49 GMT"}], "update_date": "2018-08-31", "authors_parsed": [["Bect", "Julien", "", "L2S, GdR MASCOT-NUM"], ["Bachoc", "Fran\u00e7ois", "", "IMT"], ["Ginsbourger", "David", "", "IMSV"]]}, {"id": "1608.01133", "submitter": "Pingjin Deng", "authors": "Pingjin Deng", "title": "The boundary non-Crossing probabilities for Slepian process", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST q-fin.MF q-fin.RM stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this contribution we derive an explicit formula for the boundary\nnon-crossing probabilities for Slepian processes associated with the piecewise\nlinear boundary function. This formula is used to develop an approximation\nformula to the boundary non-crossing probabilities for general continuous\nboundaries. The formulas we developed are easy to implement in calculation the\nboundary non-crossing probabilities.\n", "versions": [{"version": "v1", "created": "Wed, 3 Aug 2016 10:04:25 GMT"}], "update_date": "2016-08-04", "authors_parsed": [["Deng", "Pingjin", ""]]}, {"id": "1608.01364", "submitter": "Lin Liu", "authors": "Lin Liu, Rajarshi Mukherjee, James Robins, Eric Tchetgen Tchetgen", "title": "Adaptive Estimation of Nonparametric Functionals", "comments": "61 pages, polished writing and added some discussion on numerical\n  issues of wavelets and potential connections to deep neural networks", "journal-ref": "Journal of Machine Learning Research, 2021, 22", "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide general adaptive upper bounds for estimating nonparametric\nfunctionals based on second order U-statistics arising from finite dimensional\napproximation of the infinite dimensional models. We then provide examples of\nfunctionals for which the theory produces rate optimally matching adaptive\nupper and lower bounds. Our results are automatically adaptive in both\nparametric and nonparametric regimes of estimation and are automatically\nadaptive and semiparametric efficient in the regime of parametric convergence\nrate.\n", "versions": [{"version": "v1", "created": "Wed, 3 Aug 2016 21:29:00 GMT"}, {"version": "v2", "created": "Fri, 5 Aug 2016 08:29:09 GMT"}, {"version": "v3", "created": "Thu, 5 Oct 2017 05:15:11 GMT"}, {"version": "v4", "created": "Sun, 2 Jun 2019 15:38:38 GMT"}, {"version": "v5", "created": "Fri, 4 Jun 2021 01:49:03 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Liu", "Lin", ""], ["Mukherjee", "Rajarshi", ""], ["Robins", "James", ""], ["Tchetgen", "Eric Tchetgen", ""]]}, {"id": "1608.01787", "submitter": "Peng Ding", "authors": "Peng Ding, Tirthankar Dasgupta", "title": "A randomization-based perspective of analysis of variance: a test\n  statistic robust to treatment effect heterogeneity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fisher randomization tests for Neyman's null hypothesis of no average\ntreatment effects are considered in a finite population setting associated with\ncompletely randomized experiments with more than two treatments. The\nconsequences of using the $F$ statistic to conduct such a test are examined\nboth theoretically and computationally, and it is argued that under treatment\neffect heterogeneity, use of the $F$ statistic in the Fisher randomization test\ncan severely inflate the type I error under Neyman's null hypothesis. An\nalternative test statistic is proposed, its asymptotic distributions under\nFisher's and Neyman's null hypotheses are derived, and its advantages\ndemonstrated.\n", "versions": [{"version": "v1", "created": "Fri, 5 Aug 2016 07:41:54 GMT"}, {"version": "v2", "created": "Mon, 24 Jul 2017 23:26:55 GMT"}], "update_date": "2017-07-26", "authors_parsed": [["Ding", "Peng", ""], ["Dasgupta", "Tirthankar", ""]]}, {"id": "1608.01801", "submitter": "Rajarshi Mukherjee", "authors": "Rajarshi Mukherjee, Sumit Mukherjee, Subhabrata Sen", "title": "Detection Thresholds for the $\\beta$-Model on Sparse Graphs", "comments": "37 pages, 2 figures, minor corrections", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study sharp thresholds for detecting sparse signals in\n$\\beta$-models for potentially sparse random graphs. The results demonstrate\ninteresting interplay between graph sparsity, signal sparsity, and signal\nstrength. In regimes of moderately dense signals, irrespective of graph\nsparsity, the detection thresholds mirror corresponding results in independent\nGaussian sequence problems. For sparser signals, extreme graph sparsity implies\nthat all tests are asymptotically powerless, irrespective of the signal\nstrength. On the other hand, sharp detection thresholds are obtained, up to\nmatching constants, on denser graphs. The phase transition mentioned above are\nsharp. As a crucial ingredient, we study a version of the Higher Criticism Test\nwhich is provably sharp up to optimal constants in the regime of sparse\nsignals. The theoretical results are further verified by numerical simulations.\n", "versions": [{"version": "v1", "created": "Fri, 5 Aug 2016 08:27:20 GMT"}, {"version": "v2", "created": "Sat, 27 May 2017 23:29:56 GMT"}], "update_date": "2017-05-30", "authors_parsed": [["Mukherjee", "Rajarshi", ""], ["Mukherjee", "Sumit", ""], ["Sen", "Subhabrata", ""]]}, {"id": "1608.01824", "submitter": "Johannes Schmidt-Hieber", "authors": "Kolyan Ray and Johannes Schmidt-Hieber", "title": "The Le Cam distance between density estimation, Poisson processes and\n  Gaussian white noise", "comments": "Some results from an earlier version of this preprint have been moved\n  to arXiv:1802.03425", "journal-ref": "Math. Stat. Learn. 1 (2018), 101-170", "doi": "10.4171/MSL/1-2-1", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well-known that density estimation on the unit interval is\nasymptotically equivalent to a Gaussian white noise experiment, provided the\ndensities have H\\\"older smoothness larger than $1/2$ and are uniformly bounded\naway from zero. We derive matching lower and constructive upper bounds for the\nLe Cam deficiencies between these experiments, with explicit dependence on both\nthe sample size and the size of the densities in the parameter space. As a\nconsequence, we derive sharp conditions on how small the densities can be for\nasymptotic equivalence to hold. The related case of Poisson intensity\nestimation is also treated.\n", "versions": [{"version": "v1", "created": "Fri, 5 Aug 2016 10:06:00 GMT"}, {"version": "v2", "created": "Wed, 12 Apr 2017 09:17:53 GMT"}, {"version": "v3", "created": "Sat, 14 Apr 2018 15:23:43 GMT"}], "update_date": "2018-10-29", "authors_parsed": [["Ray", "Kolyan", ""], ["Schmidt-Hieber", "Johannes", ""]]}, {"id": "1608.01894", "submitter": "Angel Baigorri R.", "authors": "Angel Rodolfo Baigorri", "title": "A New Approach to Inverse Local Times", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In 1981 F. Knight published an article with a partial solution to a problem\nproposed by Ito-McKean see [Ito,[p.217]]. In this paper Knight, see [Knight],\ncharacterized the Levy measures of gap diffusions also known as\nquasi-diffusions. The proof is very elegant but it uses quite a lot functional\nanalysis, more specifically spectral Krein Theory. We present a new proof of\nKnight's Theorem, defined at the beginning of the Introduction as well as the\nnew proof of the same theorem referred as Theorem 2.6 in Section 2.\n", "versions": [{"version": "v1", "created": "Fri, 5 Aug 2016 14:22:20 GMT"}], "update_date": "2016-08-08", "authors_parsed": [["Baigorri", "Angel Rodolfo", ""]]}, {"id": "1608.01895", "submitter": "Mikkel Bennedsen", "authors": "Mikkel Bennedsen", "title": "Semiparametric inference on the fractal index of Gaussian and\n  conditionally Gaussian time series data", "comments": null, "journal-ref": null, "doi": "10.1080/07474938.2020.1721832", "report-no": null, "categories": "math.ST q-fin.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a well-known estimator of the fractal index of a stochastic process.\nOur framework is very general and encompasses many models of interest; we show\nhow to extend the theory of the estimator to a large class of non-Gaussian\nprocesses. Particular focus is on clarity and ease of implementation of the\nestimator and the associated asymptotic results, making it easy for\npractitioners to apply the methods. We additionally show how measurement noise\nin the observations will bias the estimator, potentially resulting in the\npractitioner erroneously finding evidence of fractal characteristics in a time\nseries. We propose a new estimator which is robust to such noise and construct\na formal hypothesis test for the presence of noise in the observations.\nFinally, the methods are illustrated on two empirical data sets; one of\nturbulent velocity flows and one of financial prices.\n", "versions": [{"version": "v1", "created": "Fri, 5 Aug 2016 14:29:37 GMT"}, {"version": "v2", "created": "Thu, 12 Oct 2017 11:07:41 GMT"}, {"version": "v3", "created": "Fri, 9 Mar 2018 13:26:38 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Bennedsen", "Mikkel", ""]]}, {"id": "1608.01903", "submitter": "Axel B\\\"ucher", "authors": "Betina Berghaus and Axel B\\\"ucher", "title": "Weak convergence of a pseudo maximum likelihood estimator for the\n  extremal index", "comments": "26 pages + 37 pages of supplement, 17 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The extremes of a stationary time series typically occur in clusters. A\nprimary measure for this phenomenon is the extremal index, representing the\nreciprocal of the expected cluster size. Both a disjoint and a sliding blocks\nestimator for the extremal index are analyzed in detail. In contrast to many\ncompetitors, the estimators only depend on the choice of one parameter\nsequence. We derive an asymptotic expansion, prove asymptotic normality and\nshow consistency of an estimator for the asymptotic variance. Explicit\ncalculations in certain models and a finite-sample Monte Carlo simulation study\nreveal that the sliding blocks estimator outperforms other blocks estimators,\nand that it is competitive to runs- and inter-exceedance estimators in various\nmodels. The methods are applied to a variety of financial time series.\n", "versions": [{"version": "v1", "created": "Fri, 5 Aug 2016 15:00:54 GMT"}, {"version": "v2", "created": "Thu, 13 Jul 2017 15:06:20 GMT"}], "update_date": "2017-07-14", "authors_parsed": [["Berghaus", "Betina", ""], ["B\u00fccher", "Axel", ""]]}, {"id": "1608.02143", "submitter": "Minwoo Chae", "authors": "Minwoo Chae, Lizhen Lin, David B. Dunson", "title": "Bayesian Sparse Linear Regression with Unknown Symmetric Error", "comments": "35 pages", "journal-ref": null, "doi": "10.1093/imaiai/iay022", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study full Bayesian procedures for sparse linear regression when errors\nhave a symmetric but otherwise unknown distribution. The unknown error\ndistribution is endowed with a symmetrized Dirichlet process mixture of\nGaussians. For the prior on regression coefficients, a mixture of point masses\nat zero and continuous distributions is considered. We study behavior of the\nposterior with diverging number of predictors. Conditions are provided for\nconsistency in the mean Hellinger distance. The compatibility and restricted\neigenvalue conditions yield the minimax convergence rate of the regression\ncoefficients in $\\ell_1$- and $\\ell_2$-norms, respectively. The convergence\nrate is adaptive to both the unknown sparsity level and the unknown symmetric\nerror density under compatibility conditions. In addition, strong model\nselection consistency and a semi-parametric Bernstein-von Mises theorem are\nproven under slightly stronger conditions.\n", "versions": [{"version": "v1", "created": "Sat, 6 Aug 2016 18:57:09 GMT"}, {"version": "v2", "created": "Fri, 22 Mar 2019 20:11:42 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Chae", "Minwoo", ""], ["Lin", "Lizhen", ""], ["Dunson", "David B.", ""]]}, {"id": "1608.02161", "submitter": "Gleb Oshanin", "authors": "O. Benichou, P. L. Krapivsky, C. Mejia-Monasterio, G. Oshanin", "title": "Joint distributions of partial and global maxima of a Brownian Bridge", "comments": "13 pages, 7 figures", "journal-ref": "J. Phys. A: Math. Theor. 49 335002 (2016)", "doi": "10.1088/1751-8113/49/33/335002", "report-no": null, "categories": "cond-mat.stat-mech math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the joint distributions and temporal correlations between the\npartial maximum $m$ and the global maximum $M$ achieved by a Brownian Bridge on\nthe subinterval $[0,t_1]$ and on the entire interval $[0,t]$, respectively. We\ndetermine three probability distribution functions: The joint distribution\n$P(m,M)$ of both maxima; the distribution $P(m)$ of the partial maximum; and\nthe distribution $\\Pi(G)$ of the gap between the maxima, $G = M-m$. We present\nexact results for the moments of these distributions and quantify the temporal\ncorrelations between $m$ and $M$ by calculating the Pearson correlation\ncoefficient.\n", "versions": [{"version": "v1", "created": "Sat, 6 Aug 2016 22:57:13 GMT"}], "update_date": "2016-08-09", "authors_parsed": [["Benichou", "O.", ""], ["Krapivsky", "P. L.", ""], ["Mejia-Monasterio", "C.", ""], ["Oshanin", "G.", ""]]}, {"id": "1608.02199", "submitter": "Arabin Kumar Dey", "authors": "Arabin Kumar Dey, Biplab Paul and Debasis Kundu", "title": "An EM algorithm for absolutely continuous Marshall-Olkin bivariate\n  Pareto distribution with location and scale", "comments": "17 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently \\cite{AsimitFurmanVernic:2016} used EM algorithm to estimate\nsingular Marshall-Olkin bivariate Pareto distribution. We describe\n\\textbf{absolutely continuous} version of this distribution. We study\nestimation of the parameters by EM algorithm both in presence and without\npresence of location and scale parameters. Some innovative solutions are\nprovided for different problems arised during implementation of EM algorithm. A\nreal-life data analysis is also shown for illustrative purpose.\n", "versions": [{"version": "v1", "created": "Sun, 7 Aug 2016 09:39:13 GMT"}, {"version": "v2", "created": "Sun, 18 Jun 2017 19:17:40 GMT"}, {"version": "v3", "created": "Thu, 22 Jun 2017 13:05:11 GMT"}, {"version": "v4", "created": "Sun, 18 Mar 2018 03:51:30 GMT"}], "update_date": "2018-03-20", "authors_parsed": [["Dey", "Arabin Kumar", ""], ["Paul", "Biplab", ""], ["Kundu", "Debasis", ""]]}, {"id": "1608.02241", "submitter": "Yaakov Malinovsky", "authors": "Gregory Haber, Yaakov Malinovsky, and Paul Albert", "title": "Sequential estimation in the group testing problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimation using pooled sampling has long been an area of interest in the\ngroup testing literature. Such research has focused primarily on the assumed\nuse of fixed sampling plans (i), although some recent papers have suggested\nalternative sequential designs that sample until a predetermined number of\npositive tests (ii). One major consideration, including in the new work on\nsequential plans, is the construction of debiased estimators which either\nreduce or keep the mean square error from inflating. Whether, however, under\nthe above or other sampling designs unbiased estimation is in fact possible has\nyet to be established in the literature. In this paper, we introduce a design\nwhich samples until a fixed number of negatives (iii), and show that an\nunbiased estimator exists under this model, while unbiased estimation is not\npossible for either of the preceding designs (i) and (ii). We present new\nestimators under the different sampling plans that are either unbiased or that\nhave reduced bias relative to those already in use as well as generally improve\non the mean square error. Numerical studies are done in order to compare\ndesigns in terms of bias and mean square error under practical situations with\nsmall and medium sample sizes.\n", "versions": [{"version": "v1", "created": "Sun, 7 Aug 2016 16:45:42 GMT"}, {"version": "v2", "created": "Thu, 6 Oct 2016 15:53:52 GMT"}, {"version": "v3", "created": "Fri, 24 Mar 2017 13:01:11 GMT"}], "update_date": "2017-03-27", "authors_parsed": [["Haber", "Gregory", ""], ["Malinovsky", "Yaakov", ""], ["Albert", "Paul", ""]]}, {"id": "1608.02251", "submitter": "Kengo Kato", "authors": "Kengo Kato and Yuya Sasaki", "title": "Uniform confidence bands in deconvolution with unknown error\n  distribution", "comments": "50 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper develops a method to construct uniform confidence bands in\ndeconvolution when the error distribution is unknown. We mainly focus on the\nbaseline setting where an auxiliary sample from the error distribution is\navailable and the error density is ordinary smooth. The auxiliary sample may\ndirectly come from validation data, or can be constructed from panel data with\na symmetric error distribution. We also present extensions of the results on\nconfidence bands to the case of super-smooth error densities. Simulation\nstudies demonstrate the performance of the multiplier bootstrap confidence band\nin the finite sample. We apply our method to the Outer Continental Shelf (OCS)\nAuction Data and draw confidence bands for the density of common values of\nmineral rights on oil and gas tracts. Finally, we present an application of our\nmain theoretical result specifically to additive fixed-effect panel data\nmodels. As an empirical illustration of the panel data analysis, we draw\nconfidence bands for the density of the total factor productivity in a\nmanufacturing industry in Chile.\n", "versions": [{"version": "v1", "created": "Sun, 7 Aug 2016 18:12:49 GMT"}, {"version": "v2", "created": "Mon, 5 Sep 2016 10:53:51 GMT"}, {"version": "v3", "created": "Sat, 22 Jul 2017 14:00:31 GMT"}], "update_date": "2017-07-25", "authors_parsed": [["Kato", "Kengo", ""], ["Sasaki", "Yuya", ""]]}, {"id": "1608.02743", "submitter": "Julia Benditkis", "authors": "Julia Benditkis and Arnold Janssen", "title": "Finite sample bounds for expected number of false rejections under\n  martingale dependence with applications to FDR", "comments": "22 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much effort has been made to improve the famous step up test of Benjamini and\nHochberg given by linear critical values $\\frac{i\\alpha}{n}$. It is pointed out\nby Gavrilov, Benjamini and Sarkar that step down multiple tests based on the\ncritical values $\\beta_i=\\frac{i\\alpha}{n+1-i(1-\\alpha)}$ still control the\nfalse discovery rate (FDR) at the upper bound $\\alpha$ under basic independence\nassumptions. Since that result in not longer true for step up tests or\ndependent single tests, a big discussion about the corresponding FDR starts in\nthe literature. The present paper establishes finite sample formulas and bounds\nfor the FDR and the expected number of false rejections for multiple tests\nusing critical values $\\beta_i$ under martingale and reverse martingale\ndependence models. It is pointed out that martingale methods are natural tools\nfor the treatment of local FDR estimators which are closely connected to the\npresent coefficients $\\beta_i.$ The martingale approach also yields new results\nand further inside for the special basic independence model.\n", "versions": [{"version": "v1", "created": "Tue, 9 Aug 2016 09:43:50 GMT"}], "update_date": "2016-08-10", "authors_parsed": [["Benditkis", "Julia", ""], ["Janssen", "Arnold", ""]]}, {"id": "1608.02801", "submitter": "Ben Berckmoes", "authors": "Ben Berckmoes and Geert Molenberghs", "title": "On the asymptotic normality and the construction of confidence intervals\n  for estimators after sampling with probabilistic and deterministic stopping\n  rules", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key feature of a sequential study is that the actual sample size is a\nrandom variable that typically depends on the outcomes collected. While\nhypothesis testing theory for sequential designs is well established, parameter\nand precision estimation is less well understood. Even though earlier work has\nestablished a number of ad hoc estimators to overcome alleged bias in the\nordinary sample average, recent work has shown the sample average to be\nconsistent. Building upon these results, by providing a rate of convergence for\nthe total variation distance, it is established that the asympotic distribution\nof the sample average is normal, in almost all cases, except in a very specific\none where the stopping rule is deterministic and the true population mean\ncoincides with the cut-off between stopping and continuing. For this\npathological case, the Kolmogorov distance with the normal is found to equal\n0.125. While noticeable in the asymptotic distribution, simulations show that\nthere fortunately are no consequences for the coverage of normally-based\nconfidence intervals.\n", "versions": [{"version": "v1", "created": "Tue, 9 Aug 2016 13:41:18 GMT"}, {"version": "v2", "created": "Mon, 12 Sep 2016 08:09:51 GMT"}, {"version": "v3", "created": "Mon, 19 Sep 2016 17:29:02 GMT"}, {"version": "v4", "created": "Wed, 20 Dec 2017 08:45:14 GMT"}], "update_date": "2017-12-21", "authors_parsed": [["Berckmoes", "Ben", ""], ["Molenberghs", "Geert", ""]]}, {"id": "1608.02902", "submitter": "Ashwin Pananjady", "authors": "Ashwin Pananjady, Martin J. Wainwright, Thomas A. Courtade", "title": "Linear Regression with an Unknown Permutation: Statistical and\n  Computational Limits", "comments": "To appear in part at the 2016 Allerton Conference on Control,\n  Communication and Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT math.IT stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a noisy linear observation model with an unknown permutation, based\non observing $y = \\Pi^* A x^* + w$, where $x^* \\in \\mathbb{R}^d$ is an unknown\nvector, $\\Pi^*$ is an unknown $n \\times n$ permutation matrix, and $w \\in\n\\mathbb{R}^n$ is additive Gaussian noise. We analyze the problem of permutation\nrecovery in a random design setting in which the entries of the matrix $A$ are\ndrawn i.i.d. from a standard Gaussian distribution, and establish sharp\nconditions on the SNR, sample size $n$, and dimension $d$ under which $\\Pi^*$\nis exactly and approximately recoverable. On the computational front, we show\nthat the maximum likelihood estimate of $\\Pi^*$ is NP-hard to compute, while\nalso providing a polynomial time algorithm when $d =1$.\n", "versions": [{"version": "v1", "created": "Tue, 9 Aug 2016 18:24:50 GMT"}], "update_date": "2016-08-10", "authors_parsed": [["Pananjady", "Ashwin", ""], ["Wainwright", "Martin J.", ""], ["Courtade", "Thomas A.", ""]]}, {"id": "1608.02990", "submitter": "Carlo Berzuini Professor", "authors": "Carlo Berzuini, Hui Guo, Stephen Burgess and Luisa Bernardinelli", "title": "Bayesian Mendelian Randomization", "comments": "21 pages, 6 figures and 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our Bayesian approach to Mendelian Randomisation uses multiple instruments to\nassess the putative causal effect of an exposure on an outcome. The approach is\nrobust to violations of the (untestable) Exclusion Restriction condition, and\nhence it does not require instruments to be independent of the outcome\nconditional on the exposure and on the confounders of the exposure-outcome\nrelationship. The Bayesian approach offers a rigorous handling of the\nuncertainty (e.g. about the estimated instrument-exposure associations),\nfreedom from asymptotic approximations of the null distribution and the\npossibility to elaborate the model in any direction of scientific relevance. We\nillustrate the last feature with the aid of a study of the metabolic mediators\nof the disease-inducing effects of obesity, where we elaborate the model to\ninvestigate whether the causal effect of interest interacts with a covariate.\nThe proposed model contains a vector of unidentifiable parameters, $\\beta$,\nwhose $j$th element represents the pleiotropic (i.e., not mediated by the\nexposure) component of the association of instrument $j$ with the outcome. We\ndeal with the incomplete identifiability by assuming that the pleiotropic\neffect of some instruments is null, or nearly so, formally by imposing on\n$\\beta$ Carvalho's horseshoe shrinkage prior, in such a way that different\ncomponents of $\\beta$ are subjected to different degrees of shrinking,\nadaptively and in accord with the compatibility of each individual instrument\nwith the hypothesis of no pleiotropy. This prior requires a minimal input from\nthe user. We present the results of a simulation study into the performance of\nthe proposed method under different types of pleiotropy and sample sizes.\nComparisons with the performance of the weighted median estimator are made.\nChoice of the prior and inference via Markov chain Monte Carlo are discussed.\n", "versions": [{"version": "v1", "created": "Tue, 9 Aug 2016 22:11:46 GMT"}, {"version": "v2", "created": "Thu, 20 Oct 2016 15:15:53 GMT"}, {"version": "v3", "created": "Tue, 31 Jan 2017 15:28:25 GMT"}], "update_date": "2017-02-01", "authors_parsed": [["Berzuini", "Carlo", ""], ["Guo", "Hui", ""], ["Burgess", "Stephen", ""], ["Bernardinelli", "Luisa", ""]]}, {"id": "1608.03032", "submitter": "Xiao Fang", "authors": "Xiao Fang, Jian Li and David Siegmund", "title": "Segmentation and Estimation of Change-point Models: False Positive\n  Control and Confidence Regions", "comments": "48 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To segment a sequence of independent random variables at an unknown number of\nchange-points, we introduce new procedures that are based on thresholding the\nlikelihood ratio statistic. We also study confidence regions based on the\nlikelihood ratio statistic for the change-points and joint confidence regions\nfor the change-points and the parameter values. Applications to segment array\nCGH data are discussed.\n", "versions": [{"version": "v1", "created": "Wed, 10 Aug 2016 03:10:02 GMT"}, {"version": "v2", "created": "Fri, 23 Mar 2018 02:19:38 GMT"}, {"version": "v3", "created": "Mon, 15 Oct 2018 08:04:37 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Fang", "Xiao", ""], ["Li", "Jian", ""], ["Siegmund", "David", ""]]}, {"id": "1608.03045", "submitter": "Matey Neykov", "authors": "Matey Neykov, Junwei Lu, Han Liu", "title": "Combinatorial Inference for Graphical Models", "comments": "78 pages, 18 figures, 2 tables; to appear in the Annals of Statistics", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new family of combinatorial inference problems for graphical\nmodels. Unlike classical statistical inference where the main interest is point\nestimation or parameter testing, combinatorial inference aims at testing the\nglobal structure of the underlying graph. Examples include testing the graph\nconnectivity, the presence of a cycle of certain size, or the maximum degree of\nthe graph. To begin with, we develop a unified theory for the fundamental\nlimits of a large family of combinatorial inference problems. We propose new\nconcepts including structural packing and buffer entropies to characterize how\nthe complexity of combinatorial graph structures impacts the corresponding\nminimax lower bounds. On the other hand, we propose a family of novel and\npractical structural testing algorithms to match the lower bounds. We provide\nthorough numerical results on both synthetic graphical models and brain\nnetworks to illustrate the usefulness of these proposed methods.\n", "versions": [{"version": "v1", "created": "Wed, 10 Aug 2016 04:47:29 GMT"}, {"version": "v2", "created": "Thu, 18 Aug 2016 02:24:27 GMT"}, {"version": "v3", "created": "Tue, 13 Feb 2018 00:57:32 GMT"}], "update_date": "2018-02-14", "authors_parsed": [["Neykov", "Matey", ""], ["Lu", "Junwei", ""], ["Liu", "Han", ""]]}, {"id": "1608.03081", "submitter": "Xian Zhou Dr.", "authors": "Xianyi Wu and Xian Zhou", "title": "On Hodges' Superefficiency and Merits of Oracle Property in Model\n  Selection", "comments": "29 pages, 1 fiture", "journal-ref": "Annals of the Institute of Statistical Mathematics, 2018", "doi": "10.1007/s10463-018-0670-0", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The oracle property of model selection procedures has attracted a large\nvolume of favorable publications in the literature, but also faced criticisms\nof being ineffective and misleading in applications. In this paper, we\nintroduce a class of estimators that can easily produce model selection\nprocedures possessing the oracle property and discuss the merits of the oracle\nproperty by analyzing the performance of such estimators in finite sample size\ntheoretically.\n  Specifically, we propose a new type of Hodges' estimators capable of reducing\nthe asymptotic variance of any given estimator over a multi-dimensional\nsubspace of the parameter space, which can easily produce model selection\nprocedures with the oracle and some other desired properties. This new type of\noracle estimators, however, perform poorly at some values of the parameters for\nestimation, and there is no convincing reason to declare that oracle estimators\nare better than the traditional estimators such as the MLE and LSE.\nConsequently, the merits of the oracle property for model selection as claimed\nin the literature are probably grossly overstated, and the criticisms of the\noracle property are justifiable.\n", "versions": [{"version": "v1", "created": "Wed, 10 Aug 2016 08:33:59 GMT"}, {"version": "v2", "created": "Thu, 17 May 2018 00:04:44 GMT"}], "update_date": "2018-07-12", "authors_parsed": [["Wu", "Xianyi", ""], ["Zhou", "Xian", ""]]}, {"id": "1608.03310", "submitter": "Leonid Sirota", "authors": "E.Ostrovsky, L.Sirota", "title": "Uniform Limit Theorem and tail estimates for parametric u-statistics", "comments": "arXiv admin note: text overlap with arXiv:1602.00175", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We deduce in this paper the sufficient conditions for weak convergence of\ncentered and normed deviation of the u-statistics with values in the space of\nthe real valued continuous function defined on some compact metric space.\n  We obtain also a non-asymptotic and non-improvable up to multiplicative\nconstant moment and exponential tail estimates for distribution for the uniform\nnorm of centered and naturally normed deviation of u-statistics by means of its\nmartingale representation.\n  Our results are formulated in a very popular and natural terms of metric\nentropy in the distance (distances) generated by the introduced random\nprocesses (fields).\n", "versions": [{"version": "v1", "created": "Wed, 10 Aug 2016 23:01:02 GMT"}], "update_date": "2016-08-12", "authors_parsed": [["Ostrovsky", "E.", ""], ["Sirota", "L.", ""]]}, {"id": "1608.03384", "submitter": "Oscar Hernan Madrid Padilla", "authors": "Oscar Hernan Madrid Padilla, James G. Scott, James Sharpnack, Ryan J.\n  Tibshirani", "title": "The DFS Fused Lasso: Linear-Time Denoising over General Graphs", "comments": null, "journal-ref": "Journal of Machine Learning Research, Vol. 18, No. 176, 1-36, 2018", "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The fused lasso, also known as (anisotropic) total variation denoising, is\nwidely used for piecewise constant signal estimation with respect to a given\nundirected graph. The fused lasso estimate is highly nontrivial to compute when\nthe underlying graph is large and has an arbitrary structure. But for a special\ngraph structure, namely, the chain graph, the fused lasso---or simply, 1d fused\nlasso---can be computed in linear time. In this paper, we establish a\nsurprising connection between the total variation of a generic signal defined\nover an arbitrary graph, and the total variation of this signal over a chain\ngraph induced by running depth-first search (DFS) over the nodes of the graph.\nSpecifically, we prove that for any signal, its total variation over the\ninduced chain graph is no more than twice its total variation over the original\ngraph. This connection leads to several interesting theoretical and\ncomputational conclusions. Denoting by $m$ and $n$ the number of edges and\nnodes, respectively, of the graph in question, our result implies that for an\nunderlying signal with total variation $t$ over the graph, the fused lasso\nachieves a mean squared error rate of \\smash{$t^{2/3} n^{-2/3}$}. Moreover,\nprecisely the same mean squared error rate is achieved by running the 1d fused\nlasso on the induced chain graph from running DFS. Importantly, the latter\nestimator is simple and computationally cheap, requiring only $O(m)$ operations\nfor constructing the DFS-induced chain and $O(n)$ operations for computing the\n1d fused lasso solution over this chain. Further, for trees that have bounded\nmax degree, the error rate of \\smash{$t^{2/3} n^{-2/3}$} cannot be improved, in\nthe sense that it is the minimax rate for signals that have total variation $t$\nover the tree.\n", "versions": [{"version": "v1", "created": "Thu, 11 Aug 2016 06:52:19 GMT"}, {"version": "v2", "created": "Sun, 30 Oct 2016 20:38:51 GMT"}, {"version": "v3", "created": "Wed, 1 Mar 2017 22:42:18 GMT"}], "update_date": "2018-08-01", "authors_parsed": [["Padilla", "Oscar Hernan Madrid", ""], ["Scott", "James G.", ""], ["Sharpnack", "James", ""], ["Tibshirani", "Ryan J.", ""]]}, {"id": "1608.03703", "submitter": "Loic Devilliers", "authors": "Lo\\\"ic Devilliers (ASCLEPIOS), St\\'ephanie Allassonni\\`ere (CRC),\n  Alain Trouv\\'e (CMLA), Xavier Pennec (ASCLEPIOS)", "title": "Template estimation in computational anatomy: Fr\\'echet means in top and\n  quotient spaces are not consistent", "comments": "SIAM Journal on Imaging Sciences, Society for Industrial and Applied\n  Mathematics, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we study the consistency of the template estimation with the\nFr\\'echet mean in quotient spaces. The Fr\\'echet mean in quotient spaces is\noften used when the observations are deformed or transformed by a group action.\nWe show that in most cases this estimator is actually inconsistent. We exhibit\na sufficient condition for this inconsistency, which amounts to the folding of\nthe distribution of the noisy template when it is projected to the quotient\nspace. This condition appears to be fulfilled as soon as the support of the\nnoise is large enough. To quantify this inconsistency we provide lower and\nupper bounds of the bias as a function of the variability (the noise level).\nThis shows that the consistency bias cannot be neglected when the variability\nincreases.\n", "versions": [{"version": "v1", "created": "Fri, 12 Aug 2016 08:00:36 GMT"}, {"version": "v2", "created": "Wed, 26 Apr 2017 09:17:19 GMT"}], "update_date": "2017-04-27", "authors_parsed": [["Devilliers", "Lo\u00efc", "", "ASCLEPIOS"], ["Allassonni\u00e8re", "St\u00e9phanie", "", "CRC"], ["Trouv\u00e9", "Alain", "", "CMLA"], ["Pennec", "Xavier", "", "ASCLEPIOS"]]}, {"id": "1608.03784", "submitter": "Han Cheng Lie", "authors": "Han Cheng Lie and T. J. Sullivan", "title": "Cameron-Martin theorems for sequences of symmetric Cauchy-distributed\n  random variables", "comments": "This paper has been withdrawn by the author because it is superseded\n  by the article \"Quasi-invariance of countable products of Cauchy measures\n  under translations and non-unitary dilations\" (arXiv:1611.10289)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a sequence of Cauchy-distributed random variables defined by a sequence\nof location parameters and a sequence of scale parameters, we consider another\nsequence of random variables that is obtained by perturbing the location or\nscale parameter sequences. Using a result of Kakutani on equivalence of\ninfinite product measures, we provide sufficient conditions for the equivalence\nof laws of the two sequences.\n", "versions": [{"version": "v1", "created": "Fri, 12 Aug 2016 13:12:13 GMT"}, {"version": "v2", "created": "Thu, 1 Dec 2016 12:42:03 GMT"}], "update_date": "2016-12-02", "authors_parsed": [["Lie", "Han Cheng", ""], ["Sullivan", "T. J.", ""]]}, {"id": "1608.03860", "submitter": "Dominique Guillot", "authors": "Peter Diao, Dominique Guillot, Apoorva Khare, Bala Rajaratnam", "title": "Model-free consistency of graph partitioning", "comments": "33 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO math.SP math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we exploit the theory of dense graph limits to provide a new\nframework to study the stability of graph partitioning methods, which we call\nstructural consistency. Both stability under perturbation as well as asymptotic\nconsistency (i.e., convergence with probability $1$ as the sample size goes to\ninfinity under a fixed probability model) follow from our notion of structural\nconsistency. By formulating structural consistency as a continuity result on\nthe graphon space, we obtain robust results that are completely independent of\nthe data generating mechanism. In particular, our results apply in settings\nwhere observations are not independent, thereby significantly generalizing the\ncommon probabilistic approach where data are assumed to be i.i.d.\n  In order to make precise the notion of structural consistency of graph\npartitioning, we begin by extending the theory of graph limits to include\nvertex colored graphons. We then define continuous node-level statistics and\nprove that graph partitioning based on such statistics is consistent. Finally,\nwe derive the structural consistency of commonly used clustering algorithms in\na general model-free setting. These include clustering based on local graph\nstatistics such as homomorphism densities, as well as the popular spectral\nclustering using the normalized Laplacian.\n  We posit that proving the continuity of clustering algorithms in the graph\nlimit topology can stand on its own as a more robust form of model-free\nconsistency. We also believe that the mathematical framework developed in this\npaper goes beyond the study of clustering algorithms, and will guide the\ndevelopment of similar model-free frameworks to analyze other procedures in the\nbroader mathematical sciences.\n", "versions": [{"version": "v1", "created": "Fri, 12 Aug 2016 17:57:53 GMT"}], "update_date": "2016-08-15", "authors_parsed": [["Diao", "Peter", ""], ["Guillot", "Dominique", ""], ["Khare", "Apoorva", ""], ["Rajaratnam", "Bala", ""]]}, {"id": "1608.03864", "submitter": "Marco Guerriero", "authors": "Gabriel M. Lipsa and Marco Guerriero", "title": "A geometrical look at MOSPA Estimation using Transportation Theory", "comments": null, "journal-ref": null, "doi": "10.1109/LSP.2016.2614774", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It was shown in [6] that the Wasserstein distance is equivalent to the Mean\nOptimal Sub-Pattern Assignment (MOSPA) measure for empirical probability\ndensity functions. A more recent paper [7], extends on it by drawing new\nconnections between the MOSPA concept, which is getting a foothold in the\nmulti-target tracking community, and the Wasserstein distance, a metric widely\nused in theoretical statistics. However, the comparison between the two\nconcepts has been overlooked. In this letter we prove that the equivalence of\nWasserstein distance with the MOSPA measure holds for general types of\nprobability density function. This non trivial result allows us to leverage one\nrecent finding in the computational geometry literature to show that the\nMinimum MOPSA (MMOSPA) estimates are the centroids of additive weighted Voronoi\nregions with a specific choice of the weights.\n", "versions": [{"version": "v1", "created": "Fri, 12 Aug 2016 18:16:43 GMT"}], "update_date": "2016-12-21", "authors_parsed": [["Lipsa", "Gabriel M.", ""], ["Guerriero", "Marco", ""]]}, {"id": "1608.03913", "submitter": "William Weimin Yoo", "authors": "William Weimin Yoo, Subhashis Ghosal", "title": "Bayesian mode and maximum estimation and accelerated rates of\n  contraction", "comments": "34 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of estimating the mode and maximum of an unknown\nregression function in the presence of noise. We adopt the Bayesian approach by\nusing tensor-product B-splines and endowing the coefficients with Gaussian\npriors. In the usual fixed-in-advanced sampling plan, we establish posterior\ncontraction rates for mode and maximum and show that they coincide with the\nminimax rates for this problem. To quantify estimation uncertainty, we\nconstruct credible sets for these two quantities that have high coverage\nprobabilities with optimal sizes. If one is allowed to collect data\nsequentially, we further propose a Bayesian two-stage estimation procedure,\nwhere a second stage posterior is built based on samples collected within a\ncredible set constructed from a first stage posterior. Under appropriate\nconditions on the radius of this credible set, we can accelerate optimal\ncontraction rates from the fixed-in-advanced setting to the minimax sequential\nrates. A simulation experiment shows that our Bayesian two-stage procedure\noutperforms single-stage procedure and also slightly improves upon a\nnon-Bayesian two-stage procedure.\n", "versions": [{"version": "v1", "created": "Fri, 12 Aug 2016 21:43:59 GMT"}, {"version": "v2", "created": "Mon, 3 Jul 2017 23:16:48 GMT"}, {"version": "v3", "created": "Sat, 12 Aug 2017 14:26:30 GMT"}, {"version": "v4", "created": "Thu, 15 Mar 2018 15:53:16 GMT"}], "update_date": "2018-03-16", "authors_parsed": [["Yoo", "William Weimin", ""], ["Ghosal", "Subhashis", ""]]}, {"id": "1608.03979", "submitter": "Nigel J. Newton", "authors": "Nigel J. Newton", "title": "Manifolds of Differentiable Densities", "comments": "Version 3: 27 pages. Introduction expanded to discuss applications.\n  Concluding Remarks section added. Improved definition of tangent space (space\n  of signed measures). Discussion of Bayesian data fusion expanded. Discussion\n  of normal charts for the $\\alpha$ covariant derivatives added. New references\n  added. No change to results. To appear in ESAIM:Probability and Statistics\n  www.esaim-ps.org", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.IT math.DG math.FA math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a family of infinite-dimensional (non-parametric) manifolds of\nprobability measures. The latter are defined on underlying Banach spaces, and\nhave densities of class $C_b^k$ with respect to appropriate reference measures.\nThe case $k=\\infty$, in which the manifolds are modelled on Fr\\'{e}chet spaces,\nis included. The manifolds admit the Fisher-Rao metric and, unusually for the\nnon-parametric setting, Amari's $\\alpha$-covariant derivatives for all\n$\\alpha\\in R$. By construction, they are $C^\\infty$-embedded submanifolds of\nparticular manifolds of finite measures. The statistical manifolds are dually\n($\\alpha=\\pm 1$) flat, and admit mixture and exponential representations as\ncharts. Their curvatures with respect to the $\\alpha$-covariant derivatives are\nderived. The likelihood function associated with a finite sample is a\ncontinuous function on each of the manifolds, and the $\\alpha$-divergences are\nof class $C^\\infty$.\n", "versions": [{"version": "v1", "created": "Sat, 13 Aug 2016 12:24:39 GMT"}, {"version": "v2", "created": "Thu, 20 Apr 2017 14:28:27 GMT"}, {"version": "v3", "created": "Sat, 9 Jun 2018 12:12:17 GMT"}], "update_date": "2018-06-12", "authors_parsed": [["Newton", "Nigel J.", ""]]}, {"id": "1608.04001", "submitter": "Shahab Asoodeh", "authors": "Shahab Asoodeh, Fady Alajaji, and Tamas Linder", "title": "Almost Perfect Privacy for Additive Gaussian Privacy Filters", "comments": "20 pages. To appear in Springer-Verlag", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the maximal mutual information about a random variable $Y$\n(representing non-private information) displayed through an additive Gaussian\nchannel when guaranteeing that only $\\epsilon$ bits of information is leaked\nabout a random variable $X$ (representing private information) that is\ncorrelated with $Y$. Denoting this quantity by $g_\\epsilon(X,Y)$, we show that\nfor perfect privacy, i.e., $\\epsilon=0$, one has $g_0(X,Y)=0$ for any pair of\nabsolutely continuous random variables $(X,Y)$ and then derive a second-order\napproximation for $g_\\epsilon(X,Y)$ for small $\\epsilon$. This approximation is\nshown to be related to the strong data processing inequality for mutual\ninformation under suitable conditions on the joint distribution $P_{XY}$. Next,\nmotivated by an operational interpretation of data privacy, we formulate the\nprivacy-utility tradeoff in the same setup using estimation-theoretic\nquantities and obtain explicit bounds for this tradeoff when $\\epsilon$ is\nsufficiently small using the approximation formula derived for\n$g_\\epsilon(X,Y)$.\n", "versions": [{"version": "v1", "created": "Sat, 13 Aug 2016 16:30:03 GMT"}], "update_date": "2016-08-16", "authors_parsed": [["Asoodeh", "Shahab", ""], ["Alajaji", "Fady", ""], ["Linder", "Tamas", ""]]}, {"id": "1608.04120", "submitter": "Philip Ernst", "authors": "Philip Ernst, Larry Shepp, and Abraham Wyner", "title": "Yule's \"Nonsense Correlation\" Solved!", "comments": "23 pages, 1 figure, Annals of Statistics (2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we resolve a longstanding open statistical problem. The\nproblem is to mathematically confirm Yule's 1926 empirical finding of \"nonsense\ncorrelation\" (\\cite{Yule}). We do so by analytically determining the second\nmoment of the empirical correlation coefficient\n  \\beqn \\theta := \\frac{\\int_0^1W_1(t)W_2(t) dt - \\int_0^1W_1(t) dt \\int_0^1\nW_2(t) dt}{\\sqrt{\\int_0^1 W^2_1(t) dt - \\parens{\\int_0^1W_1(t) dt}^2}\n\\sqrt{\\int_0^1 W^2_2(t) dt - \\parens{\\int_0^1W_2(t) dt}^2}}, \\eeqn of two {\\em\nindependent} Wiener processes, $W_1,W_2$. Using tools from Fred- holm integral\nequation theory, we successfully calculate the second moment of $\\theta$ to\nobtain a value for the standard deviation of $\\theta$ of nearly .5. The\n\"nonsense\" correlation, which we call \"volatile\" correlation, is volatile in\nthe sense that its distribution is heavily dispersed and is frequently large in\nabsolute value. It is induced because each Wiener process is \"self-correlated\"\nin time. This is because a Wiener process is an integral of pure noise and thus\nits values at different time points are correlated. In addition to providing an\nexplicit formula for the second moment of $\\theta$, we offer implicit formulas\nfor higher moments of $\\theta$.\n", "versions": [{"version": "v1", "created": "Sun, 14 Aug 2016 17:46:08 GMT"}, {"version": "v2", "created": "Tue, 30 Aug 2016 04:44:48 GMT"}], "update_date": "2016-08-31", "authors_parsed": [["Ernst", "Philip", ""], ["Shepp", "Larry", ""], ["Wyner", "Abraham", ""]]}, {"id": "1608.04167", "submitter": "Promit Ghosal Mr.", "authors": "Promit Ghosal and Bodhisattva Sen", "title": "On Univariate Convex Regression", "comments": "35 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We find the local rate of convergence of the least squares estimator (LSE) of\na one dimensional convex regression function when (a) a certain number of\nderivatives vanish at the point of interest, and (b) the true regression\nfunction is locally affine. In each case we derive the limiting distribution of\nthe LSE and its derivative. The pointwise limiting distributions depend on the\nsecond and third derivatives at 0 of the \"invelope function\" of the integral of\na two-sided Brownian motion with polynomial drifts. We also investigate the\ninconsistency of the LSE and the unboundedness of its derivative at the\nboundary of the domain of the covariate space. An estimator of the argmin of\nthe convex regression function is proposed and its asymptotic distribution is\nderived. Further, we present some new results on the characterization of the\nconvex LSE that may be of independent interest.\n", "versions": [{"version": "v1", "created": "Mon, 15 Aug 2016 01:34:17 GMT"}, {"version": "v2", "created": "Mon, 29 Aug 2016 16:00:21 GMT"}, {"version": "v3", "created": "Tue, 13 Sep 2016 20:03:47 GMT"}, {"version": "v4", "created": "Wed, 16 Nov 2016 01:47:33 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Ghosal", "Promit", ""], ["Sen", "Bodhisattva", ""]]}, {"id": "1608.04242", "submitter": "St\\'ephanie van der Pas", "authors": "St\\'ephanie van der Pas and Aad van der Vaart", "title": "Bayesian Community Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a Bayesian estimator of the underlying class structure in the\nstochastic block model, when the number of classes is known. The estimator is\nthe posterior mode corresponding to a Dirichlet prior on the class proportions,\na generalized Bernoulli prior on the class labels, and a beta prior on the edge\nprobabilities. We show that this estimator is strongly consistent when the\nexpected degree is at least of order $\\log^2{n}$, where $n$ is the number of\nnodes in the network.\n", "versions": [{"version": "v1", "created": "Mon, 15 Aug 2016 11:41:02 GMT"}], "update_date": "2016-08-16", "authors_parsed": [["van der Pas", "St\u00e9phanie", ""], ["van der Vaart", "Aad", ""]]}, {"id": "1608.04244", "submitter": "Weiyu Li", "authors": "Marian Hristache, Weiyu Li and Valentin Patilea", "title": "A semiparametric single-index estimator for a class of estimating\n  equation models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a two-step pseudo-maximum likelihood procedure for semiparametric\nsingle-index regression models where the conditional variance is a known\nfunction of the regression and an additional parameter. The Poisson\nsingle-index regression with multiplicative unobserved heterogeneity is an\nexample of such models. Our procedure is based on linear exponential densities\nwith nuisance parameter. The pseudo-likelihood criterion we use contains a\nnonparametric estimate of the index regression and therefore a rule for\nchoosing the smoothing parameter is needed. We propose an automatic and natural\nrule based on the joint maximization of the pseudo-likelihood with respect to\nthe index parameter and the smoothing parameter. We derive the asymptotic\nproperties of the semiparametric estimator of the index parameter and the\nasymptotic behavior of our `optimal' smoothing parameter. The finite sample\nperformances of our methodology are analyzed using simulated and real data.\n", "versions": [{"version": "v1", "created": "Mon, 15 Aug 2016 11:41:42 GMT"}, {"version": "v2", "created": "Wed, 26 Apr 2017 04:14:35 GMT"}], "update_date": "2017-04-27", "authors_parsed": [["Hristache", "Marian", ""], ["Li", "Weiyu", ""], ["Patilea", "Valentin", ""]]}, {"id": "1608.04457", "submitter": "Lixing Zhu", "authors": "Xuehu Zhu, Tao Wang and Lixing Zhu", "title": "Dimensionality determination: a thresholding double ridge ratio\n  criterion", "comments": "51 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Popularly used eigendecomposition-based criteria such as BIC type, ratio\nestimation and principal component-based criterion often underdetermine model\ndimensionality for regressions or the number of factors for factor models. This\nlongstanding problem is caused by the existence of one or two dominating\neigenvalues compared to other nonzero eigenvalues. To alleviate this\ndifficulty, we propose a thresholding double ridge ratio criterion such that\nthe true dimension can be better identified and is less underdetermined. Unlike\nall existing eigendecomposition-based criteria, this criterion can define\nconsistent estimate without requiring the uniqueness of minimum and can then\nhandle possible multiple local minima scenarios. This generic strategy would be\nreadily applied to other dimensionality or order determination problems. In\nthis paper, we systematically investigate, for general sufficient dimension\nreduction theory, the dimensionality determination with fixed and divergent\ndimensions; for local alternative models that converge to its limiting model\nwith fewer projected covariates, discuss when the number of projected\ncovariates can be consistently estimated, when cannot; and for ultra-high\ndimensional factor models, study the estimation consistency for the number of\ncommon factors. Numerical studies are conducted to examine the finite sample\nperformance of the method.\n", "versions": [{"version": "v1", "created": "Tue, 16 Aug 2016 01:42:58 GMT"}], "update_date": "2016-08-17", "authors_parsed": [["Zhu", "Xuehu", ""], ["Wang", "Tao", ""], ["Zhu", "Lixing", ""]]}, {"id": "1608.04507", "submitter": "Gogi Pantsulaia", "authors": "Levan Labadze and Gogi Pantsulaia", "title": "Estimation of the parameters of the Ornstein-Uhlenbeck's stochastic\n  process", "comments": "17 pages, 1 figure, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is considered Ornstein-Uhlenbeck process $ x_t = x_0 e^{-\\theta t} + \\mu\n(1-e^{-\\theta t}) + \\sigma \\int_0^t e^{-\\theta (t-s)} dW_s$, where $x_0 \\in R$,\n$\\theta>0$, $ \\mu \\in R$ and $\\sigma > 0$ are parameters. By use values\n$(z_k)_{k \\in N}$ of corresponding trajectories at a fixed positive moment $t$,\na consistent estimate of each unknown parameter of the Ornstein-Uhlenbeck's\nstochastic process is constructed under assumption that all another parameters\nare known.\n", "versions": [{"version": "v1", "created": "Tue, 16 Aug 2016 07:52:42 GMT"}, {"version": "v2", "created": "Thu, 18 Aug 2016 15:01:44 GMT"}, {"version": "v3", "created": "Sun, 28 Aug 2016 07:17:43 GMT"}], "update_date": "2016-08-30", "authors_parsed": [["Labadze", "Levan", ""], ["Pantsulaia", "Gogi", ""]]}, {"id": "1608.04861", "submitter": "Olga Klopp", "authors": "Alexandra Carpentier, Olga Klopp (CREST, MODAL'X), Matthias L\\\"offler,\n  Richard Nickl", "title": "Adaptive confidence sets for matrix completion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the present paper we study the problem of existence of honest and adaptive\nconfidence sets for matrix completion. We consider two statistical models: the\ntrace regression model and the Bernoulli model. In the trace regression model,\nwe show that honest confidence sets that adapt to the unknown rank of the\nmatrix exist even when the error variance is unknown. Contrary to this, we\nprove that in the Bernoulli model, honest and adaptive confidence sets exist\nonly when the error variance is known a priori. In the course of our proofs we\nobtain bounds for the minimax rates of certain composite hypothesis testing\nproblems arising in low rank inference.\n", "versions": [{"version": "v1", "created": "Wed, 17 Aug 2016 06:00:11 GMT"}, {"version": "v2", "created": "Mon, 6 Feb 2017 16:23:08 GMT"}], "update_date": "2017-02-07", "authors_parsed": [["Carpentier", "Alexandra", "", "CREST, MODAL'X"], ["Klopp", "Olga", "", "CREST, MODAL'X"], ["L\u00f6ffler", "Matthias", ""], ["Nickl", "Richard", ""]]}, {"id": "1608.05002", "submitter": "Kevin He", "authors": "Drew Fudenberg, Kevin He, and Lorens Imhof", "title": "Bayesian Posteriors For Arbitrarily Rare Events", "comments": null, "journal-ref": "Proceedings of the National Academy of Sciences 114(19):4925-4929,\n  May 2017", "doi": "10.1073/pnas.1618780114", "report-no": null, "categories": "math.ST q-fin.EC stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study how much data a Bayesian observer needs to correctly infer the\nrelative likelihoods of two events when both events are arbitrarily rare. Each\nperiod, either a blue die or a red die is tossed. The two dice land on side $1$\nwith unknown probabilities $p_1$ and $q_1$, which can be arbitrarily low. Given\na data-generating process where $p_1\\ge c q_1$, we are interested in how much\ndata is required to guarantee that with high probability the observer's\nBayesian posterior mean for $p_1$ exceeds $(1-\\delta)c$ times that for $q_1$.\nIf the prior densities for the two dice are positive on the interior of the\nparameter space and behave like power functions at the boundary, then for every\n$\\epsilon>0,$ there exists a finite $N$ so that the observer obtains such an\ninference after $n$ periods with probability at least $1-\\epsilon$ whenever\n$np_1\\ge N$. The condition on $n$ and $p_1$ is the best possible. The result\ncan fail if one of the prior densities converges to zero exponentially fast at\nthe boundary.\n", "versions": [{"version": "v1", "created": "Wed, 17 Aug 2016 15:33:53 GMT"}, {"version": "v2", "created": "Fri, 28 Oct 2016 01:55:36 GMT"}, {"version": "v3", "created": "Fri, 24 Feb 2017 23:01:46 GMT"}, {"version": "v4", "created": "Sat, 22 Apr 2017 17:11:48 GMT"}], "update_date": "2017-05-11", "authors_parsed": [["Fudenberg", "Drew", ""], ["He", "Kevin", ""], ["Imhof", "Lorens", ""]]}, {"id": "1608.05122", "submitter": "Alexander Kukush", "authors": "Alexander Kukush, Yaroslav Tsaregorodtsev", "title": "Goodness-of-fit test in a multivariate errors-in-variables model $AX=B$", "comments": "Published at http://dx.doi.org/10.15559/16-VMSTA67 in the Modern\n  Stochastics: Theory and Applications (https://www.i-journals.org/vtxpp/VMSTA)\n  by VTeX (http://www.vtex.lt/)", "journal-ref": "Modern Stochastics: Theory and Applications 2016, Vol. 3, No. 4,\n  287-302", "doi": "10.15559/16-VMSTA67", "report-no": "VTeX-VMSTA-VMSTA67", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a multivariable functional errors-in-variables model $AX\\approx\nB$, where the data matrices $A$ and $B$ are observed with errors, and a matrix\nparameter $X$ is to be estimated. A goodness-of-fit test is constructed based\non the total least squares estimator. The proposed test is asymptotically\nchi-squared under null hypothesis. The power of the test under local\nalternatives is discussed.\n", "versions": [{"version": "v1", "created": "Wed, 17 Aug 2016 22:58:17 GMT"}, {"version": "v2", "created": "Mon, 29 Aug 2016 07:27:25 GMT"}, {"version": "v3", "created": "Tue, 10 Jan 2017 14:37:37 GMT"}], "update_date": "2017-01-11", "authors_parsed": [["Kukush", "Alexander", ""], ["Tsaregorodtsev", "Yaroslav", ""]]}, {"id": "1608.05670", "submitter": "Michal Pe\\v{s}ta PhD", "authors": "Barbora Pe\\v{s}tov\\'a and Michal Pe\\v{s}ta", "title": "Change Point in Panel Data with Small Fixed Panel Size: Ratio and\n  Non-Ratio Test Statistics", "comments": "arXiv admin note: substantial text overlap with arXiv:1509.01291", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main goal is to develop and, consequently, compare stochastic methods for\ndetection whether a structural change in panel data occurred at some unknown\ntime or not. Panel data of our interest consist of a moderate or relatively\nlarge number of panels, while the panels contain a small number of\nobservations. Testing procedures to detect a possible common change in means of\nthe panels are established. Ratio and non-ratio type test statistics are\nconsidered. Their asymptotic distributions under the no change null hypothesis\nare derived. Moreover, we prove the consistency of the tests under the\nalternative. The main advantage of the ratio type statistics compared to the\nnon-ratio ones is that the variance of the observations neither has to be known\nnor estimated. A simulation study reveals that the proposed ratio statistic\noutperforms the non-ratio one by keeping the significance level under the null,\nmainly when stronger dependence within the panel is taken into account.\nHowever, the non-ratio statistic rejects the null in the simulations more often\nthan it should, which yields higher power compared to the ratio statistic.\n", "versions": [{"version": "v1", "created": "Fri, 19 Aug 2016 16:55:06 GMT"}], "update_date": "2016-08-22", "authors_parsed": [["Pe\u0161tov\u00e1", "Barbora", ""], ["Pe\u0161ta", "Michal", ""]]}, {"id": "1608.05679", "submitter": "Emilie Dufresne", "authors": "Emilie Dufresne, Heather A. Harrington, Dhruva V. Raman", "title": "The geometry of sloppiness", "comments": "31 pages, 5 figures, Small changes throughout the paper. A table\n  summary of the main examples now appears as appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.MG math.DS math.ST physics.data-an q-bio.QM stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of mathematical models in the sciences often involves the estimation\nof unknown parameter values from data. Sloppiness provides information about\nthe uncertainty of this task. In this paper, we develop a precise mathematical\nfoundation for sloppiness and define rigorously its key concepts, such as\n`model manifold', in relation to concepts of structural identifiability. We\nredefine sloppiness conceptually as a comparison between the premetric on\nparameter space induced by measurement noise and a reference metric. This opens\nup the possibility of alternative quantification of sloppiness, beyond the\nstandard use of the Fisher Information Matrix, which assumes that parameter\nspace is equipped with the usual Euclidean metric and the measurement error is\ninfinitesimal. Applications include parametric statistical models, explicit\ntime dependent models, and ordinary differential equation models.\n", "versions": [{"version": "v1", "created": "Fri, 19 Aug 2016 17:47:45 GMT"}, {"version": "v2", "created": "Sat, 1 Apr 2017 16:53:15 GMT"}, {"version": "v3", "created": "Wed, 14 Mar 2018 14:24:09 GMT"}], "update_date": "2018-03-15", "authors_parsed": [["Dufresne", "Emilie", ""], ["Harrington", "Heather A.", ""], ["Raman", "Dhruva V.", ""]]}, {"id": "1608.05749", "submitter": "Xinyang Yi", "authors": "Xinyang Yi, Constantine Caramanis, Sujay Sanghavi", "title": "Solving a Mixture of Many Random Linear Equations by Tensor\n  Decomposition and Alternating Minimization", "comments": "39 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of solving mixed random linear equations with $k$\ncomponents. This is the noiseless setting of mixed linear regression. The goal\nis to estimate multiple linear models from mixed samples in the case where the\nlabels (which sample corresponds to which model) are not observed. We give a\ntractable algorithm for the mixed linear equation problem, and show that under\nsome technical conditions, our algorithm is guaranteed to solve the problem\nexactly with sample complexity linear in the dimension, and polynomial in $k$,\nthe number of components. Previous approaches have required either exponential\ndependence on $k$, or super-linear dependence on the dimension. The proposed\nalgorithm is a combination of tensor decomposition and alternating\nminimization. Our analysis involves proving that the initialization provided by\nthe tensor method allows alternating minimization, which is equivalent to EM in\nour setting, to converge to the global optimum at a linear rate.\n", "versions": [{"version": "v1", "created": "Fri, 19 Aug 2016 22:10:46 GMT"}], "update_date": "2016-08-23", "authors_parsed": [["Yi", "Xinyang", ""], ["Caramanis", "Constantine", ""], ["Sanghavi", "Sujay", ""]]}, {"id": "1608.05810", "submitter": "Kayvan Sadeghi", "authors": "Steffen Lauritzen and Kayvan Sadeghi", "title": "Unifying Markov Properties for Graphical Models", "comments": "31 Pages, 6 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.OT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several types of graphs with different conditional independence\ninterpretations --- also known as Markov properties --- have been proposed and\nused in graphical models. In this paper we unify these Markov properties by\nintroducing a class of graphs with four types of edges --- lines, arrows, arcs,\nand dotted lines --- and a single separation criterion. We show that\nindependence structures defined by this class specialize to each of the\npreviously defined cases, when suitable subclasses of graphs are considered. In\naddition, we define a pairwise Markov property for the subclass of chain mixed\ngraphs which includes chain graphs with the LWF interpretation, as well as\nsummary graphs (and consequently ancestral graphs). We prove the equivalence of\nthis pairwise Markov property to the global Markov property for compositional\ngraphoid independence models.\n", "versions": [{"version": "v1", "created": "Sat, 20 Aug 2016 11:25:08 GMT"}, {"version": "v2", "created": "Sun, 28 Aug 2016 19:14:58 GMT"}, {"version": "v3", "created": "Sun, 30 Apr 2017 16:53:35 GMT"}, {"version": "v4", "created": "Tue, 11 Jul 2017 17:38:11 GMT"}], "update_date": "2017-07-12", "authors_parsed": [["Lauritzen", "Steffen", ""], ["Sadeghi", "Kayvan", ""]]}, {"id": "1608.05985", "submitter": "Subrata Chakraborty", "authors": "Laba Handique and Subrata Chakraborty", "title": "The Beta Generalized Marshall-Olkin-G Family of Distributions", "comments": "36 pages, 5 figures, 3 Tables, Version-I. arXiv admin note:\n  substantial text overlap with arXiv:1608.05987; text overlap with\n  arXiv:1603.00634, arXiv:1509.08108, arXiv:1510.08401", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a new family of distribution considering Generalized\nMarshal-Olkin distribution as the base line distribution in the Beta-G family\nof Construction. The new family includes Beta-G (Eugene et al. 2002 and Jones,\n2004) and (Jayakumar and Mathew, 2008) families as particular cases.\nProbability density function (pdf) and the cumulative distribution function\n(cdf) are expressed as mixture of the Marshal-Olkin (Marshal and Olkin, 1997)\ndistribution. Series expansions of pdf of the order statistics are also\nobtained. Moments, moment generating function, R\\'enyi entropies, quantile\npower series, random sample generation and asymptotes are also investigated.\nParameter estimation by method of maximum likelihood and method of moment are\nalso presented. Finally proposed model is compared to the Generalized\nMarshall-Olkin Kumaraswamy extended family (Handique and Chakraborty, 2015) by\nconsidering three data fitting examples with real life data sets.\n", "versions": [{"version": "v1", "created": "Sun, 21 Aug 2016 19:08:59 GMT"}], "update_date": "2016-09-16", "authors_parsed": [["Handique", "Laba", ""], ["Chakraborty", "Subrata", ""]]}, {"id": "1608.05987", "submitter": "Subrata Chakraborty", "authors": "Laba Handique and Subrata Chakraborty", "title": "The Kumaraswamy Generalized Marshall-Olkin-G family of distributions", "comments": "40 pages, 6 Figures, 4 Tables, Version-I. arXiv admin note:\n  substantial text overlap with arXiv:1608.05985; text overlap with\n  arXiv:1510.08401, arXiv:1509.08108, arXiv:1603.00634", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Another new family of continuous probability distribution is proposed by\nusing Generalized Marshal-Olkin distribution as the base line distribution in\nthe Kumaraswamy-G distribution. This family includes (Cordeiro and de Castro,\n2011) and (Jayakumar and Mathew, 2008) families special case besides a under of\nother distributions. The probability density function (pdf) and the survival\nfunction (sf) are expressed as series to observe as a mixture of the\nGeneralized Marshal-Olkin distribution. Series expansions pdf of order\nstatistics are also obtained. Moments, moment generating function, R\\'enyi\nentropies, quantile function, random sample generation and asymptotes are also\ninvestigated. Parameter estimation by method of maximum likelihood and method\nof moment are also presented. Finally the proposed model is compared to the\nGeneralized Marshall-Olkin Kumaraswamy extended family (Handique and\nChakraborty, 2015) by considering four examples of real life data modeling.\n", "versions": [{"version": "v1", "created": "Sun, 21 Aug 2016 19:14:13 GMT"}], "update_date": "2016-09-16", "authors_parsed": [["Handique", "Laba", ""], ["Chakraborty", "Subrata", ""]]}, {"id": "1608.05994", "submitter": "Richard Lockhart", "authors": "Richard A Lockhart", "title": "Inefficient Best Invariant Tests", "comments": "Originally written in 1992. Savagely reviewed (say I) at the Annals\n  and I lacked the courage to submit it anywhere else. It is, though, limit law\n  in models with many parameters and so may have some relevance today, I feel", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Test statistics which are invariant under various subgroups of the orthogonal\ngroup are shown to provide tests whose powers are asymptotically equal to their\nlevel against the usual type of contiguous alternative in models where the\nnumber of parameters is allowed to grow as the sample size increases. The\nresult is applied to the usual analysis of variance test in the Neyman-Scott\nmany means problem and to an analogous problem in exponential families. Proofs\nare based on a method used by Cibisov(1961) to study spacings statistics in a\ngoodness-of-fit problem. We review the scope of the technique in this context.\n", "versions": [{"version": "v1", "created": "Sun, 21 Aug 2016 20:19:01 GMT"}], "update_date": "2016-08-23", "authors_parsed": [["Lockhart", "Richard A", ""]]}, {"id": "1608.06412", "submitter": "Benjamin Guedj", "authors": "Alain Celisse and Benjamin Guedj", "title": "Stability revisited: new generalisation bounds for the Leave-one-Out", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML math.ST stat.TH", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The present paper provides a new generic strategy leading to non-asymptotic\ntheoretical guarantees on the Leave-one-Out procedure applied to a broad class\nof learning algorithms. This strategy relies on two main ingredients: the new\nnotion of $L^q$ stability, and the strong use of moment inequalities. $L^q$\nstability extends the ongoing notion of hypothesis stability while remaining\nweaker than the uniform stability. It leads to new PAC exponential\ngeneralisation bounds for Leave-one-Out under mild assumptions. In the\nliterature, such bounds are available only for uniform stable algorithms under\nboundedness for instance. Our generic strategy is applied to the Ridge\nregression algorithm as a first step.\n", "versions": [{"version": "v1", "created": "Tue, 23 Aug 2016 08:11:29 GMT"}], "update_date": "2016-08-24", "authors_parsed": [["Celisse", "Alain", ""], ["Guedj", "Benjamin", ""]]}, {"id": "1608.06536", "submitter": "Zacharie Naulet", "authors": "Zacharie Naulet and Judith Rousseau", "title": "Tails assumptions and posterior concentration rates for mixtures of\n  Gaussians", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays in density estimation, posterior rates of convergence for location\nand location-scale mixtures of Gaussians are only known under light-tail\nassumptions; with better rates achieved by location mixtures. It is\nconjectured, but not proved, that the situation should be reversed under heavy\ntails assumptions. The conjecture is based on the feeling that there is no need\nto achieve a good order of approximation in regions with few data (say, in the\ntails), favoring location-scale mixtures which allow for spatially varying\norder of approximation. Here we test the previous argument on the Gaussian\nerrors mean regression model with random design, for which the light tail\nassumption is not required for proofs. Although we cannot invalidate the\nconjecture due to the lack of lower bound, we find that even with heavy tails\nassumptions, location-scale mixtures apparently perform always worst than\nlocation mixtures. However, the proofs suggest to introduce hybrid\nlocation-scale mixtures that are find to outperform both location and\nlocation-scale mixtures, whatever the nature of the tails. Finally, we show\nthat all tails assumptions can be released at the price of making the prior\ndistribution covariate dependent.\n", "versions": [{"version": "v1", "created": "Tue, 23 Aug 2016 15:09:50 GMT"}], "update_date": "2016-08-24", "authors_parsed": [["Naulet", "Zacharie", ""], ["Rousseau", "Judith", ""]]}, {"id": "1608.06541", "submitter": "Jade Giguelay", "authors": "Jade Giguelay", "title": "Estimation of a discrete probability under constraint of k-monotony", "comments": "53 pages, 35 figures", "journal-ref": "Electronic Journal of Statistics, Volume 11, Number 1 (2017), 1-49", "doi": "10.1214/16-EJS1220", "report-no": null, "categories": "math.ST stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose two least-squares estimators of a discrete probability under the\nconstraint of k-monotony and study their statistical properties. We give a\ncharacterization of these estimators based on the decomposition on a spline\nbasis of k-monotone sequences. We develop an algorithm derived from the Support\nReduction Algorithm and we finally present a simulation study to illustrate\ntheir properties.\n", "versions": [{"version": "v1", "created": "Tue, 23 Aug 2016 15:17:19 GMT"}, {"version": "v2", "created": "Thu, 25 Aug 2016 12:28:22 GMT"}], "update_date": "2017-08-30", "authors_parsed": [["Giguelay", "Jade", ""]]}, {"id": "1608.06740", "submitter": "Robin Genuer", "authors": "Marie Chavent (CQFD), Robin Genuer (SISTM), Jerome Saracco (CQFD)", "title": "Combining clustering of variables and feature selection using random\n  forests", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard approaches to tackle high-dimensional supervised classification\nproblem often include variable selection and dimension reduction procedures.\nThe novel methodology proposed in this paper combines clustering of variables\nand feature selection. More precisely, hierarchical clustering of variables\nprocedure allows to build groups of correlated variables in order to reduce the\nredundancy of information and summarizes each group by a synthetic numerical\nvariable. Originality is that the groups of variables (and the number of\ngroups) are unknown a priori. Moreover the clustering approach used can deal\nwith both numerical and categorical variables (i.e. mixed dataset). Among all\nthe possible partitions resulting from dendrogram cuts, the most relevant\nsynthetic variables (i.e. groups of variables) are selected with a variable\nselection procedure using random forests. Numerical performances of the\nproposed approach are compared with direct applications of random forests and\nvariable selection using random forests on the original p variables.\nImprovements obtained with the proposed methodology are illustrated on two\nsimulated mixed datasets (cases n>p and n<p, where n is the sample size) and on\na real proteomic dataset. Via the selection of groups of variables (based on\nthe synthetic variables), interpretability of the results becomes easier.\n", "versions": [{"version": "v1", "created": "Wed, 24 Aug 2016 07:59:35 GMT"}, {"version": "v2", "created": "Tue, 6 Nov 2018 09:10:34 GMT"}], "update_date": "2018-11-07", "authors_parsed": [["Chavent", "Marie", "", "CQFD"], ["Genuer", "Robin", "", "SISTM"], ["Saracco", "Jerome", "", "CQFD"]]}, {"id": "1608.06758", "submitter": "Hiroki Masuda", "authors": "Hiroki Masuda", "title": "Non-Gaussian quasi-likelihood estimation of SDE driven by locally stable\n  L\\'evy process", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address estimation of parametric coefficients of a pure-jump L\\'evy driven\nunivariate stochastic differential equation (SDE) model, which is observed at\nhigh frequency over a fixed time period. It is known from the previous study\nMasuda (2013) that adopting the conventional Gaussian quasi-maximum likelihood\nestimator then leads to an inconsistent estimator. In this paper, under the\nassumption that the driving L\\'evy process is locally stable, we extend the\nGaussian framework into a non-Gaussian counterpart, by introducing a novel\nquasi-likelihood function formally based on the small-time stable approximation\nof the unknown transition density. The resulting estimator turns out to be\nasymptotically mixed normally distributed without ergodicity and finite moments\nfor a wide range of the driving pure-jump L\\'evy process, showing much better\ntheoretical performance compared with the Gaussian quasi-maximum likelihood\nestimator. Extensive simulations are carried out to show good estimation\naccuracy. The case of large-time asymptotics under ergodicity is briefly\nmentioned as well, where we can deduce an analogous asymptotic normality\nresult.\n", "versions": [{"version": "v1", "created": "Wed, 24 Aug 2016 09:09:31 GMT"}, {"version": "v2", "created": "Thu, 27 Oct 2016 00:37:29 GMT"}, {"version": "v3", "created": "Thu, 8 Jun 2017 15:38:21 GMT"}, {"version": "v4", "created": "Tue, 17 Apr 2018 05:34:59 GMT"}], "update_date": "2018-04-18", "authors_parsed": [["Masuda", "Hiroki", ""]]}, {"id": "1608.06851", "submitter": "Jimmy Olsson Dr", "authors": "Randal Douc, Jimmy Olsson, Francois Roueff", "title": "Posterior consistency for partially observed Markov models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we establish the posterior consistency for a parametrized family\nof partially observed, fully dominated Markov models. As a main assumption, we\nsuppose that the prior distribution assigns positive probability to all\nneighborhoods of the true parameter, for a distance induced by the expected\nKullback-Leibler divergence between the family members' Markov transition\ndensities. This assumption is easily checked in general. In addition, under\nsome additional, mild assumptions we show that the posterior consistency is\nimplied by the consistency of the maximum likelihood estimator. The latter has\nrecently been established also for models with non-compact state space. The\nresult is then extended to possibly non-compact parameter spaces and\nnon-stationary observations. Finally, we check our assumptions on examples\nincluding the partially observed Gaussian linear model with correlated noise\nand a widely used stochastic volatility model.\n", "versions": [{"version": "v1", "created": "Wed, 24 Aug 2016 14:52:50 GMT"}, {"version": "v2", "created": "Thu, 25 Aug 2016 05:51:02 GMT"}], "update_date": "2016-09-01", "authors_parsed": [["Douc", "Randal", ""], ["Olsson", "Jimmy", ""], ["Roueff", "Francois", ""]]}, {"id": "1608.06977", "submitter": "Johannes Heiny", "authors": "Johannes Heiny and Thomas Mikosch", "title": "Eigenvalues and eigenvectors of heavy-tailed sample covariance matrices\n  with general growth rates: the iid case", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study the joint distributional convergence of the largest\neigenvalues of the sample covariance matrix of a $p$-dimensional time series\nwith iid entries when $p$ converges to infinity together with the sample size\n$n$. We consider only heavy-tailed time series in the sense that the entries\nsatisfy some regular variation condition which ensures that their fourth moment\nis infinite. In this case, Soshnikov [31, 32] and Auffinger et al. [2] proved\nthe weak convergence of the point processes of the normalized eigenvalues of\nthe sample covariance matrix towards an inhomogeneous Poisson process which\nimplies in turn that the largest eigenvalue converges in distribution to a\nFr\\'echet distributed random variable. They proved these results under the\nassumption that $p$ and $n$ are proportional to each other. In this paper we\nshow that the aforementioned results remain valid if $p$ grows at any\npolynomial rate. The proofs are different from those in [2, 31, 32]; we employ\nlarge deviation techniques to achieve them. The proofs reveal that only the\ndiagonal of the sample covariance matrix is relevant for the asymptotic\nbehavior of the largest eigenvalues and the corresponding eigenvectors which\nare close to the canonical basis vectors. We also discuss extensions of the\nresults to sample autocovariance matrices.\n", "versions": [{"version": "v1", "created": "Wed, 24 Aug 2016 22:09:09 GMT"}], "update_date": "2016-08-26", "authors_parsed": [["Heiny", "Johannes", ""], ["Mikosch", "Thomas", ""]]}, {"id": "1608.07014", "submitter": "Yanglei Song", "authors": "Yanglei Song, Georgios Fellouris", "title": "Sequential multiple testing with generalized error control: an\n  asymptotic optimality theory", "comments": "Accepted in Annals of Statistics", "journal-ref": "the Annals of Statistics 2019, Vol. 47, No. 3, 1776-1803", "doi": "10.1214/18-AOS1737", "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The sequential multiple testing problem is considered under two generalized\nerror metrics. Under the first one, the probability of at least $k$ mistakes,\nof any kind, is controlled. Under the second, the probabilities of at least\n$k_1$ false positives and at least $k_2$ false negatives are simultaneously\ncontrolled. For each formulation, the optimal expected sample size is\ncharacterized, to a first-order asymptotic approximation as the error\nprobabilities go to 0, and a novel multiple testing procedure is proposed and\nshown to be asymptotically efficient under every signal configuration. These\nresults are established when the data streams for the various hypotheses are\nindependent and each local log-likelihood ratio statistic satisfies a certain\nStrong Law of Large Numbers. In the special case of i.i.d. observations in each\nstream, the gains of the proposed sequential procedures over fixed-sample size\nschemes are quantified.\n", "versions": [{"version": "v1", "created": "Thu, 25 Aug 2016 04:08:15 GMT"}, {"version": "v2", "created": "Fri, 15 Dec 2017 00:38:33 GMT"}, {"version": "v3", "created": "Sat, 14 Apr 2018 13:06:21 GMT"}, {"version": "v4", "created": "Mon, 18 Jun 2018 13:40:41 GMT"}], "update_date": "2019-02-18", "authors_parsed": [["Song", "Yanglei", ""], ["Fellouris", "Georgios", ""]]}, {"id": "1608.07186", "submitter": "Abhishek Pal Majumder", "authors": "Abhishek Pal Majumder, Jan Hannig", "title": "Higher order asymptotics of Generalized Fiducial Distribution", "comments": "Initially submitted to a Journal on 5th October", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generalized Fiducial Inference (GFI) is motivated by R.A. Fisher's approach\nof obtaining posterior-like distributions when there is no prior information\navailable for the unknown parameter. Without the use of Bayes' theorem GFI\nproposes a distribution on the parameter space using a technique called\nincreasing precision asymptotics \\cite{hannig2013generalized}. In this article\nwe analyzed the regularity conditions under which the Generalized Fiducial\nDistribution (GFD) will be first and second order exact in a frequentist sense.\nWe used a modification of an ingenious technique named \"Shrinkage method\"\n\\cite{bickel1990decomposition}, which has been extensively used in the\nprobability matching prior contexts, to find the higher order expansion of the\nfrequentist coverage of Fiducial quantile. We identified when the higher order\nterms of one-sided coverage of Fiducial quantile will vanish and derived a\nworkable recipe for obtaining such GFDs. These ideas are demonstrated on\nseveral examples.\n", "versions": [{"version": "v1", "created": "Thu, 25 Aug 2016 15:04:02 GMT"}], "update_date": "2016-08-26", "authors_parsed": [["Majumder", "Abhishek Pal", ""], ["Hannig", "Jan", ""]]}, {"id": "1608.07630", "submitter": "Daniel Hsu", "authors": "Ji Xu, Daniel Hsu, Arian Maleki", "title": "Global analysis of Expectation Maximization for mixtures of two\n  Gaussians", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.CO stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Expectation Maximization (EM) is among the most popular algorithms for\nestimating parameters of statistical models. However, EM, which is an iterative\nalgorithm based on the maximum likelihood principle, is generally only\nguaranteed to find stationary points of the likelihood objective, and these\npoints may be far from any maximizer. This article addresses this disconnect\nbetween the statistical principles behind EM and its algorithmic properties.\nSpecifically, it provides a global analysis of EM for specific models in which\nthe observations comprise an i.i.d. sample from a mixture of two Gaussians.\nThis is achieved by (i) studying the sequence of parameters from idealized\nexecution of EM in the infinite sample limit, and fully characterizing the\nlimit points of the sequence in terms of the initial parameters; and then (ii)\nbased on this convergence analysis, establishing statistical consistency (or\nlack thereof) for the actual sequence of parameters produced by EM.\n", "versions": [{"version": "v1", "created": "Fri, 26 Aug 2016 23:53:43 GMT"}], "update_date": "2016-08-30", "authors_parsed": [["Xu", "Ji", ""], ["Hsu", "Daniel", ""], ["Maleki", "Arian", ""]]}, {"id": "1608.07681", "submitter": "Guillaume Lecu\\'e", "authors": "Guillaume Lecu\\'e and Shahar Mendelson", "title": "Regularization and the small-ball method II: complexity dependent error\n  rates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For a convex class of functions $F$, a regularization functions $\\Psi(\\cdot)$\nand given the random data $(X_i, Y_i)_{i=1}^N$, we study estimation properties\nof regularization procedures of the form \\begin{equation*}\n  \\hat f \\in {\\rm argmin}_{f\\in\n  F}\\Big(\\frac{1}{N}\\sum_{i=1}^N\\big(Y_i-f(X_i)\\big)^2+\\lambda \\Psi(f)\\Big)\n\\end{equation*} for some well chosen regularization parameter $\\lambda$.\n  We obtain bounds on the $L_2$ estimation error rate that depend on the\ncomplexity of the \"true model\" $F^*:=\\{f\\in F: \\Psi(f)\\leq\\Psi(f^*)\\}$, where\n$f^*\\in {\\rm argmin}_{f\\in F}\\mathbb{E}(Y-f(X))^2$ and the $(X_i,Y_i)$'s are\nindependent and distributed as $(X,Y)$. Our estimate holds under weak\nstochastic assumptions -- one of which being a small-ball condition satisfied\nby $F$ -- and for rather flexible choices of regularization functions\n$\\Psi(\\cdot)$. Moreover, the result holds in the learning theory framework: we\ndo not assume any a-priori connection between the output $Y$ and the input $X$.\n  As a proof of concept, we apply our general estimation bound to various\nchoices of $\\Psi$, for example, the $\\ell_p$ and $S_p$-norms (for $p\\geq1$),\nweak-$\\ell_p$, atomic norms, max-norm and SLOPE. In many cases, the estimation\nrate almost coincides with the minimax rate in the class $F^*$.\n", "versions": [{"version": "v1", "created": "Sat, 27 Aug 2016 09:11:02 GMT"}], "update_date": "2016-08-30", "authors_parsed": [["Lecu\u00e9", "Guillaume", ""], ["Mendelson", "Shahar", ""]]}, {"id": "1608.07839", "submitter": "Jordan Frecon", "authors": "Jordan Frecon, Gustavo Didier, Nelly Pustelnik, and Patrice Abry", "title": "Non-Linear Wavelet Regression and Branch & Bound Optimization for the\n  Full Identification of Bivariate Operator Fractional Brownian Motion", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2016.2551695", "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-similarity is widely considered the reference framework for modeling the\nscaling properties of real-world data. However, most theoretical studies and\ntheir practical use have remained univariate. Operator Fractional Brownian\nMotion (OfBm) was recently proposed as a multivariate model for\nself-similarity. Yet it has remained seldom used in applications because of\nserious issues that appear in the joint estimation of its numerous parameters.\nWhile the univariate fractional Brownian motion requires the estimation of two\nparameters only, its mere bivariate extension already involves 7 parameters\nwhich are very different in nature. The present contribution proposes a method\nfor the full identification of bivariate OfBm (i.e., the joint estimation of\nall parameters) through an original formulation as a non-linear wavelet\nregression coupled with a custom-made Branch & Bound numerical scheme. The\nestimation performance (consistency and asymptotic normality) is mathematically\nestablished and numerically assessed by means of Monte Carlo experiments. The\nimpact of the parameters defining OfBm on the estimation performance as well as\nthe associated computational costs are also thoroughly investigated.\n", "versions": [{"version": "v1", "created": "Sun, 28 Aug 2016 17:55:36 GMT"}], "update_date": "2016-09-07", "authors_parsed": [["Frecon", "Jordan", ""], ["Didier", "Gustavo", ""], ["Pustelnik", "Nelly", ""], ["Abry", "Patrice", ""]]}, {"id": "1608.08285", "submitter": "Ting-Li Chen", "authors": "Ting-Li Chen, Dawei D. Chang, Su-Yun Huang, Hung Chen, Chienyao Lin,\n  Weichung Wang", "title": "Integrating multiple random sketches for singular value decomposition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The singular value decomposition (SVD) of large-scale matrices is a key tool\nin data analytics and scientific computing. The rapid growth in the size of\nmatrices further increases the need for developing efficient large-scale SVD\nalgorithms. Randomized SVD based on one-time sketching has been studied, and\nits potential has been demonstrated for computing a low-rank SVD. Instead of\nexploring different single random sketching techniques, we propose a Monte\nCarlo type integrated SVD algorithm based on multiple random sketches. The\nproposed integration algorithm takes multiple random sketches and then\nintegrates the results obtained from the multiple sketched subspaces. So that\nthe integrated SVD can achieve higher accuracy and lower stochastic variations.\nThe main component of the integration is an optimization problem with a matrix\nStiefel manifold constraint. The optimization problem is solved using\nKolmogorov-Nagumo-type averages. Our theoretical analyses show that the\nsingular vectors can be induced by population averaging and ensure the\nconsistencies between the computed and true subspaces and singular vectors.\nStatistical analysis further proves a strong Law of Large Numbers and gives a\nrate of convergence by the Central Limit Theorem. Preliminary numerical results\nsuggest that the proposed integrated SVD algorithm is promising.\n", "versions": [{"version": "v1", "created": "Mon, 29 Aug 2016 23:34:53 GMT"}], "update_date": "2016-08-31", "authors_parsed": [["Chen", "Ting-Li", ""], ["Chang", "Dawei D.", ""], ["Huang", "Su-Yun", ""], ["Chen", "Hung", ""], ["Lin", "Chienyao", ""], ["Wang", "Weichung", ""]]}, {"id": "1608.08348", "submitter": "Daniel Paulin", "authors": "Daniel Paulin, Ajay Jasra, Dan Crisan and Alexandros Beskos", "title": "On Concentration Properties of Partially Observed Chaotic Systems", "comments": "49 pages, 4 figures. Minor changes and some references added in this\n  version", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.DS stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article presents results on the concentration properties of the\nsmoothing and filtering distributions of some partially observed chaotic\ndynamical systems. We show that, rather surprisingly, for the geometric model\nof the Lorenz equations, as well as some other chaotic dynamical systems, the\nsmoothing and filtering distributions do not concentrate around the true\nposition of the signal, as the number of observations tends to infinity.\nInstead, under various assumptions on the observation noise, we show that the\nexpected value of the diameter of the support of the smoothing and filtering\ndistributions remains lower bounded by a constant times the standard deviation\nof the noise, independently of the number of observations. Conversely, under\nrather general conditions, the diameter of the support of the smoothing and\nfiltering distributions are upper bounded by a constant times the standard\ndeviation of the noise. To some extent, applications to the three dimensional\nLorenz 63' model and to the Lorenz 96' model of arbitrarily large dimension are\nconsidered.\n", "versions": [{"version": "v1", "created": "Tue, 30 Aug 2016 07:31:05 GMT"}, {"version": "v2", "created": "Mon, 29 Jan 2018 09:34:33 GMT"}], "update_date": "2018-01-30", "authors_parsed": [["Paulin", "Daniel", ""], ["Jasra", "Ajay", ""], ["Crisan", "Dan", ""], ["Beskos", "Alexandros", ""]]}, {"id": "1608.08367", "submitter": "Stephane Boucheron", "authors": "Anna Ben-Hamou, Stephane Boucheron, Elisabeth Gassiat", "title": "Pattern Coding Meets Censoring: (almost) Adaptive Coding on Countable\n  Alphabets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adaptive coding faces the following problem: given a collection of source\nclasses such that each class in the collection has non-trivial minimax\nredundancy rate, can we design a single code which is asymptotically minimax\nover each class in the collection? In particular, adaptive coding makes sense\nwhen there is no universal code on the union of classes in the collection. In\nthis paper, we deal with classes of sources over an infinite alphabet, that are\ncharacterized by a dominating envelope. We provide asymptotic equivalents for\nthe redundancy of envelope classes enjoying a regular variation property. We\nfinally construct a computationally efficient online prefix code, which\ninterleaves the encoding of the so-called pattern of the message and the\nencoding of the dictionary of discovered symbols. This code is shown to be\nadaptive, within a $\\log\\log n$ factor, over the collection of regularly\nvarying envelope classes. The code is both simpler and less redundant than\npreviously described contenders. In contrast with previous attempts, it also\ncovers the full range of slowly varying envelope classes.\n", "versions": [{"version": "v1", "created": "Tue, 30 Aug 2016 08:46:56 GMT"}, {"version": "v2", "created": "Thu, 1 Sep 2016 13:16:46 GMT"}], "update_date": "2016-09-02", "authors_parsed": [["Ben-Hamou", "Anna", ""], ["Boucheron", "Stephane", ""], ["Gassiat", "Elisabeth", ""]]}, {"id": "1608.08482", "submitter": "Vladica Stojanovic", "authors": "Vladica Stojanovi\\'c, Gradimir V. Milovanovi\\'c, Gordana Jeli\\'c", "title": "Distributional properties and parameters estimation of GSB Process: An\n  approach based on characteristic functions", "comments": "26 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A general type of a Split-BREAK process with Gaussian innovations\n(henceforth, Gaussian Split-BREAK or GSB process) is considered. The basic\nstochastic properties of the model are studied and its characteristic function\nderived. A procedure to estimate the parameter of the GSB model based on the\nEmpirical Characteristic Function (ECF) is proposed. Our simulations suggest\nthat the proposed method performs well compared to a Method of Moment procedure\nused as benchmark. The empirical use of the GSB model is illustrated with an\napplication to the time series of total values of shares traded at Belgrade\nStock Exchange.\n", "versions": [{"version": "v1", "created": "Tue, 30 Aug 2016 14:52:17 GMT"}], "update_date": "2016-08-31", "authors_parsed": [["Stojanovi\u0107", "Vladica", ""], ["Milovanovi\u0107", "Gradimir V.", ""], ["Jeli\u0107", "Gordana", ""]]}, {"id": "1608.08535", "submitter": "Shovan Chowdhury Shovan Chowdhury", "authors": "Amarjit Kundu and Shovan Chowdhury", "title": "Ordering properties of sample minimum from Kumaraswamy-G random\n  variables", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we compare the minimums of two independent and heterogeneous\nsamples each following Kumaraswamy-G distribution with the same and the\ndifferent parent distribution functions. The comparisons are carried out with\nrespect to usual stochastic ordering and hazard rate ordering with majorized\nshape parameters of the distributions. The likelihood ratio ordering between\nthe minimum order statistics is established for heterogeneous multiple outlier\nKumaraswamy-G random variables with the same parent distribution function\n", "versions": [{"version": "v1", "created": "Tue, 30 Aug 2016 16:13:00 GMT"}], "update_date": "2016-08-31", "authors_parsed": [["Kundu", "Amarjit", ""], ["Chowdhury", "Shovan", ""]]}, {"id": "1608.08717", "submitter": "Marco Carone", "authors": "Marco Carone, Alexander R. Luedtke, Mark J. van der Laan", "title": "Toward computerized efficient estimation in infinite-dimensional models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the risk of misspecification they are tied to, parametric models\ncontinue to be used in statistical practice because they are accessible to all.\nIn particular, efficient estimation procedures in parametric models are simple\nto describe and implement. Unfortunately, the same cannot be said of\nsemiparametric and nonparametric models. While the latter often reflect the\nlevel of available scientific knowledge more appropriately, performing\nefficient inference in these models is generally challenging. The efficient\ninfluence function is a key analytic object from which the construction of\nasymptotically efficient estimators can potentially be streamlined. However,\nthe theoretical derivation of the efficient influence function requires\nspecialized knowledge and is often a difficult task, even for experts. In this\npaper, we propose and discuss a numerical procedure for approximating the\nefficient influence function. The approach generalizes the simple nonparametric\nprocedures described recently by Frangakis et al. (2015) and Luedtke et al.\n(2015) to arbitrary models. We present theoretical results to support our\nproposal, and also illustrate the method in the context of two examples. The\nproposed approach is an important step toward automating efficient estimation\nin general statistical models, thereby rendering the use of realistic models in\nstatistical analyses much more accessible.\n", "versions": [{"version": "v1", "created": "Wed, 31 Aug 2016 03:13:39 GMT"}], "update_date": "2016-09-01", "authors_parsed": [["Carone", "Marco", ""], ["Luedtke", "Alexander R.", ""], ["van der Laan", "Mark J.", ""]]}, {"id": "1608.08783", "submitter": "Mohamed Hebiri", "authors": "Christophe Denis (LAMA), Mohamed Hebiri (LAMA)", "title": "Confidence sets with expected sizes for Multiclass Classification", "comments": null, "journal-ref": "Journal of Machine Learning Research, Journal of Machine Learning\n  Research, 2017", "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiclass classification problems such as image annotation can involve a\nlarge number of classes. In this context, confusion between classes can occur,\nand single label classification may be misleading. We provide in the present\npaper a general device that, given an unlabeled dataset and a score function\ndefined as the minimizer of some empirical and convex risk, outputs a set of\nclass labels, instead of a single one. Interestingly, this procedure does not\nrequire that the unlabeled dataset explores the whole classes. Even more, the\nmethod is calibrated to control the expected size of the output set while\nminimizing the classification risk. We show the statistical optimality of the\nprocedure and establish rates of convergence under the Tsybakov margin\ncondition. It turns out that these rates are linear on the number of labels. We\napply our methodology to convex aggregation of confidence sets based on the\nV-fold cross validation principle also known as the superlearning principle. We\nillustrate the numerical performance of the procedure on real data and\ndemonstrate in particular that with moderate expected size, w.r.t. the number\nof labels, the procedure provides significant improvement of the classification\nrisk.\n", "versions": [{"version": "v1", "created": "Wed, 31 Aug 2016 09:22:58 GMT"}, {"version": "v2", "created": "Mon, 18 Dec 2017 08:06:34 GMT"}], "update_date": "2017-12-19", "authors_parsed": [["Denis", "Christophe", "", "LAMA"], ["Hebiri", "Mohamed", "", "LAMA"]]}, {"id": "1608.08789", "submitter": "Mariusz Grz\\k{a}dziel PhD", "authors": "Mariusz Grzadziel", "title": "On the maximum likelihood degree of linear mixed models with two\n  variance components", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend the results concerning the upper bounds for the maximum likelihood\ndegree and the REML degree of the one-way random effects model presented in\nGross et al. [Electron. J. Stat. 6 (2012), pp. 993-1016] to the case of the\nnormal linear mixed model with two variance components. Then we prove that both\nparts of Conjecture 1 in the paper of Gross et al., which concerns a certain\nextension of the one-way random effects model, are true under fairly mild\nconditions.\n", "versions": [{"version": "v1", "created": "Wed, 31 Aug 2016 09:44:09 GMT"}, {"version": "v2", "created": "Sat, 22 Oct 2016 19:47:25 GMT"}], "update_date": "2016-10-25", "authors_parsed": [["Grzadziel", "Mariusz", ""]]}, {"id": "1608.08825", "submitter": "Nikolai Dokuchaev", "authors": "Nikolai Dokuchaev, Lin-Yee Hin", "title": "On predictability of ultra short AR(1) sequences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses short term forecast of ultra short AR(1) sequences (4 to\n6 terms only) with a single structural break at an unknown time and of unknown\nsign and magnitude. As prediction of autoregressive processes requires\nestimated coefficients, the efficiency of which relies on the large sample\nproperties of the estimator, it is a common perception that prediction is\npractically impossible for such short series with structural break. However, we\nobtain a heuristic result that some universal predictors represented in the\nfrequency domain allow certain predictability based on these ultra short\nsequences. The predictors that we use are universal in a sense that they are\nnot oriented on particular types of autoregressions and do not require explicit\nmodelling of structural break. The shorter the sequence, the better the\none-step-ahead forecast performance of the smoothed predicting kernel. If the\nstructural break entails a model parameter switch from negative to positive\nvalue, the forecast performance of the smoothed predicting kernel is better\nthan that of the linear predictor that utilize AR(1) coefficient estimated from\nthe ultra short sequence without taking the structural break into account\nregardless whether the innovation terms in the learning sequences are\nconstructed from independent and identically distributed random Gaussian or\nGamma variables, scaled pseudo-uniform variables, or first-order\nauto-correlated Gaussian process.\n", "versions": [{"version": "v1", "created": "Wed, 31 Aug 2016 12:39:28 GMT"}], "update_date": "2016-09-04", "authors_parsed": [["Dokuchaev", "Nikolai", ""], ["Hin", "Lin-Yee", ""]]}, {"id": "1608.08852", "submitter": "Martin Genzel", "authors": "Martin Genzel and Gitta Kutyniok", "title": "A Mathematical Framework for Feature Selection from Real-World Data with\n  Non-Linear Observations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the challenge of feature selection based on a\nrelatively small collection of sample pairs $\\{(x_i, y_i)\\}_{1 \\leq i \\leq m}$.\nThe observations $y_i \\in \\mathbb{R}$ are thereby supposed to follow a noisy\nsingle-index model, depending on a certain set of signal variables. A major\ndifficulty is that these variables usually cannot be observed directly, but\nrather arise as hidden factors in the actual data vectors $x_i \\in\n\\mathbb{R}^d$ (feature variables). We will prove that a successful variable\nselection is still possible in this setup, even when the applied estimator does\nnot have any knowledge of the underlying model parameters and only takes the\n'raw' samples $\\{(x_i, y_i)\\}_{1 \\leq i \\leq m}$ as input. The model\nassumptions of our results will be fairly general, allowing for non-linear\nobservations, arbitrary convex signal structures as well as strictly convex\nloss functions. This is particularly appealing for practical purposes, since in\nmany applications, already standard methods, e.g., the Lasso or logistic\nregression, yield surprisingly good outcomes. Apart from a general discussion\nof the practical scope of our theoretical findings, we will also derive a\nrigorous guarantee for a specific real-world problem, namely sparse feature\nextraction from (proteomics-based) mass spectrometry data.\n", "versions": [{"version": "v1", "created": "Wed, 31 Aug 2016 13:53:09 GMT"}], "update_date": "2016-12-28", "authors_parsed": [["Genzel", "Martin", ""], ["Kutyniok", "Gitta", ""]]}]