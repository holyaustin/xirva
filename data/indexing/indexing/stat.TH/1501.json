[{"id": "1501.00046", "submitter": "Sohail Bahmani", "authors": "Sohail Bahmani and Justin Romberg", "title": "Lifting for Blind Deconvolution in Random Mask Imaging: Identifiability\n  and Convex Relaxation", "comments": null, "journal-ref": "SIAM J. Imaging Sci. 8(4):2203--2238, 2015", "doi": "10.1137/141002165", "report-no": null, "categories": "cs.IT math.FA math.IT math.NA math.OC math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we analyze the blind deconvolution of an image and an unknown\nblur in a coded imaging system. The measurements consist of subsampled\nconvolution of an unknown blurring kernel with multiple random binary\nmodulations (coded masks) of the image. To perform the deconvolution, we\nconsider a standard lifting of the image and the blurring kernel that\ntransforms the measurements into a set of linear equations of the matrix formed\nby their outer product. Any rank-one solution to this system of equation\nprovides a valid pair of an image and a blur.\n  We first express the necessary and sufficient conditions for the uniqueness\nof a rank-one solution under some additional assumptions (uniform subsampling\nand no limit on the number of coded masks). These conditions are special case\nof a previously established result regarding identifiability in the matrix\ncompletion problem. We also characterize a low-dimensional subspace model for\nthe blur kernel that is sufficient to guarantee identifiability, including the\ninteresting instance of \"bandpass\"` blur kernels.\n  Next, assuming the bandpass model for the blur kernel, we show that the image\nand the blur kernel can be found using nuclear norm minimization. Our main\nresults show that recovery is achieved (with high probability) when the number\nof masks is on the order of\n$\\mu\\log^{2}L\\,\\log\\frac{Le}{\\mu}\\,\\log\\log\\left(N+1\\right)$ where $\\mu$ is the\n\\emph{coherence} of the blur, $L$ is the dimension of the image, and $N$ is the\nnumber of measured samples per mask.\n", "versions": [{"version": "v1", "created": "Tue, 30 Dec 2014 23:32:07 GMT"}, {"version": "v2", "created": "Mon, 6 Apr 2015 16:39:27 GMT"}], "update_date": "2015-10-27", "authors_parsed": [["Bahmani", "Sohail", ""], ["Romberg", "Justin", ""]]}, {"id": "1501.00049", "submitter": "Ning Hao", "authors": "Ning Hao, Yang Feng and Hao Helen Zhang", "title": "Model Selection for High Dimensional Quadratic Regression via\n  Regularization", "comments": "37 pages, 1 figure with supplementary material", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quadratic regression (QR) models naturally extend linear models by\nconsidering interaction effects between the covariates. To conduct model\nselection in QR, it is important to maintain the hierarchical model structure\nbetween main effects and interaction effects. Existing regularization methods\ngenerally achieve this goal by solving complex optimization problems, which\nusually demands high computational cost and hence are not feasible for high\ndimensional data. This paper focuses on scalable regularization methods for\nmodel selection in high dimensional QR. We first consider two-stage\nregularization methods and establish theoretical properties of the two-stage\nLASSO. Then, a new regularization method, called Regularization Algorithm under\nMarginality Principle (RAMP), is proposed to compute a hierarchy-preserving\nregularization solution path efficiently. Both methods are further extended to\nsolve generalized QR models. Numerical results are also shown to demonstrate\nperformance of the methods.\n", "versions": [{"version": "v1", "created": "Wed, 31 Dec 2014 00:06:25 GMT"}, {"version": "v2", "created": "Thu, 14 Jul 2016 19:24:23 GMT"}], "update_date": "2016-07-15", "authors_parsed": [["Hao", "Ning", ""], ["Feng", "Yang", ""], ["Zhang", "Hao Helen", ""]]}, {"id": "1501.00177", "submitter": "Leonid Torgovitski", "authors": "Leonid Torgovitski", "title": "Panel data segmentation under finite time horizon", "comments": "Most important changes and corrections are explained at the beginning\n  of the .tex file", "journal-ref": "Journal of Statistical Planning and Inference, Volume 167,\n  December 2015, Pages 69-89, ISSN 0378-3758", "doi": "10.1016/j.jspi.2015.05.007", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the nonparametric change point estimation for common changes in the\nmeans of panel data. The consistency of estimates is investigated when the\nnumber of panels tends to infinity but the sample size remains finite. Our\nfocus is on weighted denoising estimates, involving the group fused LASSO, and\non the weighted CUSUM estimates. Due to the fixed sample size, the common\nweighting schemes do not guarantee consistency under (serial) dependence and\nmost typical weightings do not even provide consistency in the i.i.d. setting\nwhen the noise is too dominant. Hence, on the one hand, we propose a consistent\ncovariance-based extension of existing weighting schemes and discuss\nstraightforward estimates of those weighting schemes. The performance will be\ndemonstrated empirically in a simulation study. On the other hand, we derive\nsharp bounds on the change to noise ratio that ensure consistency in the i.i.d.\nsetting for classical weightings.\n", "versions": [{"version": "v1", "created": "Wed, 31 Dec 2014 17:31:30 GMT"}, {"version": "v2", "created": "Mon, 16 Feb 2015 18:38:27 GMT"}, {"version": "v3", "created": "Tue, 20 Oct 2015 14:51:36 GMT"}], "update_date": "2015-10-21", "authors_parsed": [["Torgovitski", "Leonid", ""]]}, {"id": "1501.00208", "submitter": "Daniel Roy", "authors": "Daniel M. Roy", "title": "The continuum-of-urns scheme, generalized beta and Indian buffet\n  processes, and hierarchies thereof", "comments": "40 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe the combinatorial stochastic process underlying a sequence of\nconditionally independent Bernoulli processes with a shared beta process hazard\nmeasure. As shown by Thibaux and Jordan [TJ07], in the special case when the\nunderlying beta process has a constant concentration function and a finite and\nnonatomic mean, the combinatorial structure is that of the Indian buffet\nprocess (IBP) introduced by Griffiths and Ghahramani [GG05]. By reinterpreting\nthe beta process introduced by Hjort [Hjo90] as a measurable family of\nDirichlet processes, we obtain a simple predictive rule for the general case,\nwhich can be thought of as a continuum of Blackwell-MacQueen urn schemes (or\nequivalently, one-parameter Hoppe urn schemes). The corresponding measurable\nfamily of Perman-Pitman-Yor processes leads to a continuum of two-parameter\nHoppe urn schemes, whose ordinary component is the three-parameter IBP\nintroduced by Teh and G\\\"or\\\"ur [TG09], which exhibits power-law behavior, as\nfurther studied by Broderick, Jordan, and Pitman [BJP12]. The idea extends to\narbitrary measurable families of exchangeable partition probability functions\nand gives rise to generalizations of the beta process with matching buffet\nprocesses. Finally, in the same way that hierarchies of Dirichlet processes\nwere given Chinese restaurant franchise representations by Teh, Jordan, Beal,\nand Blei [Teh+06], one can construct representations of sequences of Bernoulli\nprocesses directed by hierarchies of beta processes (and their generalizations)\nusing the stochastic process we uncover.\n", "versions": [{"version": "v1", "created": "Wed, 31 Dec 2014 21:07:33 GMT"}], "update_date": "2015-01-05", "authors_parsed": [["Roy", "Daniel M.", ""]]}, {"id": "1501.00312", "submitter": "Po-Ling Loh", "authors": "Po-Ling Loh", "title": "Statistical consistency and asymptotic normality for high-dimensional\n  robust M-estimators", "comments": "56 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT math.IT stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study theoretical properties of regularized robust M-estimators,\napplicable when data are drawn from a sparse high-dimensional linear model and\ncontaminated by heavy-tailed distributions and/or outliers in the additive\nerrors and covariates. We first establish a form of local statistical\nconsistency for the penalized regression estimators under fairly mild\nconditions on the error distribution: When the derivative of the loss function\nis bounded and satisfies a local restricted curvature condition, all stationary\npoints within a constant radius of the true regression vector converge at the\nminimax rate enjoyed by the Lasso with sub-Gaussian errors. When an appropriate\nnonconvex regularizer is used in place of an l_1-penalty, we show that such\nstationary points are in fact unique and equal to the local oracle solution\nwith the correct support---hence, results on asymptotic normality in the\nlow-dimensional case carry over immediately to the high-dimensional setting.\nThis has important implications for the efficiency of regularized nonconvex\nM-estimators when the errors are heavy-tailed. Our analysis of the local\ncurvature of the loss function also has useful consequences for optimization\nwhen the robust regression function and/or regularizer is nonconvex and the\nobjective function possesses stationary points outside the local region. We\nshow that as long as a composite gradient descent algorithm is initialized\nwithin a constant radius of the true regression vector, successive iterates\nwill converge at a linear rate to a stationary point within the local region.\nFurthermore, the global optimum of a convex regularized robust regression\nfunction may be used to obtain a suitable initialization. The result is a novel\ntwo-step procedure that uses a convex M-estimator to achieve consistency and a\nnonconvex M-estimator to increase efficiency.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jan 2015 20:52:30 GMT"}], "update_date": "2015-01-05", "authors_parsed": [["Loh", "Po-Ling", ""]]}, {"id": "1501.00438", "submitter": "Sebastian Vollmer", "authors": "Sebastian J. Vollmer and Konstantinos C. Zygalakis and and Yee Whye\n  Teh", "title": "(Non-) asymptotic properties of Stochastic Gradient Langevin Dynamics", "comments": "42 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Applying standard Markov chain Monte Carlo (MCMC) algorithms to large data\nsets is computationally infeasible. The recently proposed stochastic gradient\nLangevin dynamics (SGLD) method circumvents this problem in three ways: it\ngenerates proposed moves using only a subset of the data, it skips the\nMetropolis-Hastings accept-reject step, and it uses sequences of decreasing\nstep sizes. In \\cite{TehThierryVollmerSGLD2014}, we provided the mathematical\nfoundations for the decreasing step size SGLD, including consistency and a\ncentral limit theorem. However, in practice the SGLD is run for a relatively\nsmall number of iterations, and its step size is not decreased to zero. The\npresent article investigates the behaviour of the SGLD with fixed step size. In\nparticular we characterise the asymptotic bias explicitly, along with its\ndependence on the step size and the variance of the stochastic gradient. On\nthat basis a modified SGLD which removes the asymptotic bias due to the\nvariance of the stochastic gradients up to first order in the step size is\nderived. Moreover, we are able to obtain bounds on the finite-time bias,\nvariance and mean squared error (MSE). The theory is illustrated with a\nGaussian toy model for which the bias and the MSE for the estimation of moments\ncan be obtained explicitly. For this toy model we study the gain of the SGLD\nover the standard Euler method in the limit of large data sets.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jan 2015 17:18:56 GMT"}, {"version": "v2", "created": "Mon, 21 Sep 2015 11:00:30 GMT"}], "update_date": "2015-09-22", "authors_parsed": [["Vollmer", "Sebastian J.", ""], ["Zygalakis", "Konstantinos C.", ""], ["Teh", "and Yee Whye", ""]]}, {"id": "1501.00442", "submitter": "Emilie Devijver", "authors": "Emilie Devijver (KU Leuven)", "title": "Joint rank and variable selection for parsimonious estimation in a\n  high-dimensional finite mixture regression model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a dimensionality reduction technique for finite mixtures of\nhigh-dimensional multivariate response regression models. Both the dimension of\nthe response and the number of predictors are allowed to exceed the sample\nsize. We consider predictor selection and rank reduction to obtain\nlower-dimensional approximations. A class of estimators with a fast rate of\nconvergence is introduced. We apply this result to a specific procedure,\nintroduced in [11], where the relevant predictors are selected by the\nGroup-Lasso.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jan 2015 17:33:09 GMT"}, {"version": "v2", "created": "Thu, 16 Feb 2017 14:14:48 GMT"}], "update_date": "2017-02-17", "authors_parsed": [["Devijver", "Emilie", "", "KU Leuven"]]}, {"id": "1501.00478", "submitter": "Anders Bredahl Kock", "authors": "Anders Bredahl Kock and Haihan Tang", "title": "Uniform Inference in High-dimensional Dynamic Panel Data Models", "comments": "54 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We establish oracle inequalities for a version of the Lasso in\nhigh-dimensional fixed effects dynamic panel data models. The inequalities are\nvalid for the coefficients of the dynamic and exogenous regressors. Separate\noracle inequalities are derived for the fixed effects. Next, we show how one\ncan conduct uniformly valid simultaneous inference on the parameters of the\nmodel and construct a uniformly valid estimator of the asymptotic covariance\nmatrix which is robust to conditional heteroskedasticity in the error terms.\nAllowing for conditional heteroskedasticity is important in dynamic models as\nthe conditional error variance may be non-constant over time and depend on the\ncovariates. Furthermore, our procedure allows for inference on high-dimensional\nsubsets of the parameter vector of an increasing cardinality. We show that the\nconfidence bands resulting from our procedure are asymptotically honest and\ncontract at the optimal rate. This rate is different for the fixed effects than\nfor the remaining parts of the parameter vector.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jan 2015 20:37:00 GMT"}, {"version": "v2", "created": "Tue, 6 Jan 2015 12:18:39 GMT"}, {"version": "v3", "created": "Tue, 9 Jun 2015 15:32:38 GMT"}, {"version": "v4", "created": "Mon, 4 Jan 2016 15:57:58 GMT"}], "update_date": "2016-01-05", "authors_parsed": [["Kock", "Anders Bredahl", ""], ["Tang", "Haihan", ""]]}, {"id": "1501.00518", "submitter": "Souvik Ghosh", "authors": "Bikramjit Das and Souvik Ghosh", "title": "Detecting tail behavior: mean excess plots with confidence bounds", "comments": "19 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many practical situations exploratory plots are helpful in understanding\ntail behavior of sample data. The Mean Excess plot is often applied in practice\nto understand the right tail behavior of a data set. It is known that if the\nunderlying distribution of a data sample is in the domain of attraction of a\nFrechet, Gumbel or Weibull distributions then the ME plot of the data tend to a\nstraight line in an appropriate sense, with positive, zero or negative slopes\nrespectively. In this paper we construct confidence intervals around the ME\nplots which assist us in ascertaining which particular maximum domain of\nattraction the data set comes from. We recall weak limit results for the\nFrechet domain of attraction, already obtained in Das and Ghosh (2013) and\nderive weak limits for the Gumbel and Weibull domains in order to construct\nconfidence bounds. We test our methods on both simulated and real data sets.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jan 2015 01:43:47 GMT"}], "update_date": "2015-01-06", "authors_parsed": [["Das", "Bikramjit", ""], ["Ghosh", "Souvik", ""]]}, {"id": "1501.00537", "submitter": "He Kun", "authors": "Kun He, Yan Fu, Wen-Feng Zeng, Lan Luo, Hao Chi, Chao Liu, Lai-Yun\n  Qing, Rui-Xiang Sun, and Si-Min He", "title": "A theoretical foundation of the target-decoy search strategy for false\n  discovery rate control in proteomics", "comments": "7 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivation: Target-decoy search (TDS) is currently the most popular strategy\nfor estimating and controlling the false discovery rate (FDR) of peptide\nidentifications in mass spectrometry-based shotgun proteomics. While this\nstrategy is very useful in practice and has been intensively studied\nempirically, its theoretical foundation has not yet been well established.\nResult: In this work, we systematically analyze the TDS strategy in a rigorous\nstatistical sense. We prove that the commonly used concatenated TDS provides a\nconservative estimate of the FDR for any given score threshold, but it cannot\nrigorously control the FDR. We prove that with a slight modification to the\ncommonly used formula for FDR estimation, the peptide-level FDR can be\nrigorously controlled based on the concatenated TDS. We show that the\nspectrum-level FDR control is difficult. We verify the theoretical conclusions\nwith real mass spectrometry data.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jan 2015 07:20:05 GMT"}], "update_date": "2015-01-06", "authors_parsed": [["He", "Kun", ""], ["Fu", "Yan", ""], ["Zeng", "Wen-Feng", ""], ["Luo", "Lan", ""], ["Chi", "Hao", ""], ["Liu", "Chao", ""], ["Qing", "Lai-Yun", ""], ["Sun", "Rui-Xiang", ""], ["He", "Si-Min", ""]]}, {"id": "1501.00599", "submitter": "Muhyiddin Izadi", "authors": "Muhyiddin Izadi, Baha-Eldin Khaledi, Chin-Diew Lai", "title": "On testing More IFRA Ordering-II", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.OT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Suppose F and G are two life distribution functions. It is said that F is\nmore IFRA than G (written by F<_* G) if G^(-1) F(x) is starshaped on (0,infty).\nIn this paper, the problem of testing H_0:F=_* G against H_1:F<_* G and F\n\\neq_* G is considered in both cases when G is known and when G is unknown. We\npropose a new test based on U-statistics and obtain the asymptotic distribution\nof the test statistics. The new test is compared with some well known tests in\nthe literature. In addition, we apply our test to a real data set in the\ncontext of reliability.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jan 2015 20:15:05 GMT"}], "update_date": "2015-01-06", "authors_parsed": [["Izadi", "Muhyiddin", ""], ["Khaledi", "Baha-Eldin", ""], ["Lai", "Chin-Diew", ""]]}, {"id": "1501.00622", "submitter": "Zizhuo Wang", "authors": "Yichen Chen, Dongdong Ge, Mengdi Wang, Zizhuo Wang, Yinyu Ye, Hao Yin", "title": "Strong NP-Hardness for Sparse Optimization with Concave Penalty\n  Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CC math.ST stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider the regularized sparse minimization problem, which involves\nempirical sums of loss functions for $n$ data points (each of dimension $d$)\nand a nonconvex sparsity penalty. We prove that finding an\n$\\mathcal{O}(n^{c_1}d^{c_2})$-optimal solution to the regularized sparse\noptimization problem is strongly NP-hard for any $c_1, c_2\\in [0,1)$ such that\n$c_1+c_2<1$. The result applies to a broad class of loss functions and sparse\npenalty functions. It suggests that one cannot even approximately solve the\nsparse optimization problem in polynomial time, unless P $=$ NP.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jan 2015 01:38:23 GMT"}, {"version": "v2", "created": "Sat, 24 Jan 2015 16:00:11 GMT"}, {"version": "v3", "created": "Tue, 21 Jun 2016 14:38:24 GMT"}, {"version": "v4", "created": "Mon, 19 Jun 2017 01:46:43 GMT"}], "update_date": "2017-06-20", "authors_parsed": [["Chen", "Yichen", ""], ["Ge", "Dongdong", ""], ["Wang", "Mengdi", ""], ["Wang", "Zizhuo", ""], ["Ye", "Yinyu", ""], ["Yin", "Hao", ""]]}, {"id": "1501.00625", "submitter": "Akihiko Inoue", "authors": "Akihiko Inoue, Yukio Kasahara, and Mohsen Pourahmadi", "title": "The intersection of past and future for multivariate stationary\n  processes", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider an intersection of past and future property of multivariate\nstationary processes which is the key to deriving various representation\ntheorems for their linear predictor coefficient matrices. We extend useful\nspectral characterizations for this property from univariate processes to\nmultivariate processes.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jan 2015 02:28:38 GMT"}, {"version": "v2", "created": "Sat, 23 May 2015 16:38:14 GMT"}], "update_date": "2015-05-26", "authors_parsed": [["Inoue", "Akihiko", ""], ["Kasahara", "Yukio", ""], ["Pourahmadi", "Mohsen", ""]]}, {"id": "1501.00811", "submitter": "Vygantas Paulauskas", "authors": "Vygantas Paulauskas and Marijus Vai\\v{c}iulis", "title": "Several new tail index estimators", "comments": "submitted for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the paper we propose some new class of functions which is used to\nconstruct tail index estimators. Functions from this new class is non-monotone\nin general, but presents a product of two monotone functions: the power\nfunction and the logarithmic function, which plays essential role in the\nclassical Hill estimator. Introduced new estimators have better asymptotic\nperformance comparing with the Hill estimator and other popular estimators over\nall range of the parameters present in the second order regular variation\ncondition. Asymptotic normality of the introduced estimators is proved, and\ncomparison (using asymptotic mean square error) with other estimators of the\ntail index is provided. Some preliminary simulation results are presented.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jan 2015 10:40:43 GMT"}], "update_date": "2015-01-06", "authors_parsed": [["Paulauskas", "Vygantas", ""], ["Vai\u010diulis", "Marijus", ""]]}, {"id": "1501.00868", "submitter": "Mansi Garg", "authors": "Mansi Garg and Isha Dewan", "title": "On asymptotic behavior of U-statistics for associated random variables", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let ${X_n, n \\ge 1}$ be a sequence of stationary associated random variables.\nFor such a sequence, we discuss the limiting behavior of U-statistics based on\nkernels which are of bounded Hardy-Krause variation.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jan 2015 13:58:21 GMT"}, {"version": "v2", "created": "Fri, 19 Jun 2015 05:50:36 GMT"}], "update_date": "2015-06-22", "authors_parsed": [["Garg", "Mansi", ""], ["Dewan", "Isha", ""]]}, {"id": "1501.01136", "submitter": "Jean-Francois Petiot", "authors": "Jean-Christophe Turlot (LMAP), Jean Fran\\c{c}ois Petiot", "title": "Intervalles de confiance pour une proportion : lesquels doit-on\n  enseigner ?", "comments": "in French in Colloque Francophone International sur l'Enseignement de\n  la Statistique -CFIES 2015, Jan 2015, Bordeaux, France", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The most frequently taught confidence intervals for a proportion are the\nclassical Wald (Ws) and the Clopper-Pearson (CP) ones because of the simplicity\nof their definition. However, their actual coverage probability of the\nparameter p is erratic, often quite far from the nominal probability which is\naimed at. Other confidence intervals are clearly preferable to the former, but\ntheir expression is generally complex and they are difficult to interpret. But\nnevertheless, through a simple modification of the definition of the Ws and CP\nintervals, we obtain some confidence intervals with much better coverage\nprobabilities. Namely, these confidence intervals are the Agresti-Coull and\nMid-P intervals that we present here. We highly recommend them in a basic\nStatistics course.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jan 2015 10:39:52 GMT"}], "update_date": "2015-01-07", "authors_parsed": [["Turlot", "Jean-Christophe", "", "LMAP"], ["Petiot", "Jean Fran\u00e7ois", ""]]}, {"id": "1501.01208", "submitter": "Viktoria \\\"Ollerer", "authors": "Viktoria \\\"Ollerer, Christophe Croux and Andreas Alfons", "title": "The Influence Function of Penalized Regression Estimators", "comments": "appears in Statistics: A Journal of Theoretical and Applied\n  Statistics, 2014", "journal-ref": null, "doi": "10.1080/02331888.2014.922563", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To perform regression analysis in high dimensions, lasso or ridge estimation\nare a common choice. However, it has been shown that these methods are not\nrobust to outliers. Therefore, alternatives as penalized M-estimation or the\nsparse least trimmed squares (LTS) estimator have been proposed. The robustness\nof these regression methods can be measured with the influence function. It\nquantifies the effect of infinitesimal perturbations in the data. Furthermore\nit can be used to compute the asymptotic variance and the mean squared error.\nIn this paper we compute the influence function, the asymptotic variance and\nthe mean squared error for penalized M-estimators and the sparse LTS estimator.\nThe asymptotic biasedness of the estimators make the calculations nonstandard.\nWe show that only M-estimators with a loss function with a bounded derivative\nare robust against regression outliers. In particular, the lasso has an\nunbounded influence function.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jan 2015 15:46:44 GMT"}], "update_date": "2015-01-07", "authors_parsed": [["\u00d6llerer", "Viktoria", ""], ["Croux", "Christophe", ""], ["Alfons", "Andreas", ""]]}, {"id": "1501.01271", "submitter": "Moritz Jirak", "authors": "Moritz Jirak", "title": "Optimal eigen expansions and uniform bounds", "comments": "corrected some typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $\\bigl\\{X_k\\bigr\\}_{k \\in \\mathbb{Z}} \\in \\mathbb{L}^2(\\mathcal{T})$ be a\nstationary process with associated lag operators ${\\boldsymbol{\\cal C}}_h$.\nUniform asymptotic expansions of the corresponding empirical eigenvalues and\neigenfunctions are established under almost optimal conditions on the lag\noperators in terms of the eigenvalues (spectral gap). In addition, the\nunderlying dependence assumptions are optimal, including both short and long\nmemory processes. This allows us to study the relative maximum deviation of the\nempirical eigenvalues under very general conditions. Among other things, we\nshow convergence to an extreme value distribution, giving rise to the\nconstruction of simultaneous confidence sets. We also discuss how the\nasymptotic expansions transfer to the long-run covariance operator\n${\\boldsymbol{\\cal G}}$ in a general framework.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jan 2015 20:25:38 GMT"}, {"version": "v2", "created": "Wed, 8 Apr 2015 21:40:16 GMT"}, {"version": "v3", "created": "Thu, 27 Aug 2015 21:32:24 GMT"}, {"version": "v4", "created": "Thu, 3 Sep 2015 20:21:48 GMT"}, {"version": "v5", "created": "Fri, 18 Sep 2015 14:21:14 GMT"}, {"version": "v6", "created": "Fri, 23 Oct 2015 10:16:05 GMT"}, {"version": "v7", "created": "Sun, 14 Feb 2016 21:58:51 GMT"}], "update_date": "2016-02-16", "authors_parsed": [["Jirak", "Moritz", ""]]}, {"id": "1501.01320", "submitter": "Matthew Thorpe", "authors": "Matthew Thorpe, Florian Theil, Adam M. Johansen and Neil Cade", "title": "Convergence of the $k$-Means Minimization Problem using\n  $\\Gamma$-Convergence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.FA math.OC stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The $k$-means method is an iterative clustering algorithm which associates\neach observation with one of $k$ clusters. It traditionally employs cluster\ncenters in the same space as the observed data. By relaxing this requirement,\nit is possible to apply the $k$-means method to infinite dimensional problems,\nfor example multiple target tracking and smoothing problems in the presence of\nunknown data association. Via a $\\Gamma$-convergence argument, the associated\noptimization problem is shown to converge in the sense that both the $k$-means\nminimum and minimizers converge in the large data limit to quantities which\ndepend upon the observed data only through its distribution. The theory is\nsupplemented with two examples to demonstrate the range of problems now\naccessible by the $k$-means method. The first example combines a non-parametric\nsmoothing problem with unknown data association. The second addresses tracking\nusing sparse data from a network of passive sensors.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jan 2015 21:19:46 GMT"}, {"version": "v2", "created": "Fri, 3 Apr 2015 16:05:11 GMT"}], "update_date": "2015-04-06", "authors_parsed": [["Thorpe", "Matthew", ""], ["Theil", "Florian", ""], ["Johansen", "Adam M.", ""], ["Cade", "Neil", ""]]}, {"id": "1501.01366", "submitter": "Georgios Fellouris Dr.", "authors": "Shiyu Wang, Georgios Fellouris and Hua-Hua Chang", "title": "Sequential Design for Computerized Adaptive Testing that Allows for\n  Response Revision", "comments": "32 pages,2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.AP stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In computerized adaptive testing (CAT), items (questions) are selected in\nreal time based on the already observed responses, so that the ability of the\nexaminee can be estimated as accurately as possible. This is typically\nformulated as a non-linear, sequential, experimental design problem with binary\nobservations that correspond to the true or false responses. However, most\nitems in practice are multiple-choice and dichotomous models do not make full\nuse of the available data. Moreover, CAT has been heavily criticized for not\nallowing test-takers to review and revise their answers. In this work, we\npropose a novel CAT design that is based on the polytomous nominal response\nmodel and in which test-takers are allowed to revise their responses at any\ntime during the test. We show that as the number of administered items goes to\ninfinity, the proposed estimator is (i) strongly consistent for any item\nselection and revision strategy and (ii) asymptotically normal when the items\nare selected to maximize the Fisher information at the current ability estimate\nand the number of revisions is smaller than the number of items. We also\npresent the findings of a simulation study that supports our asymptotic\nresults.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jan 2015 04:07:02 GMT"}], "update_date": "2015-01-08", "authors_parsed": [["Wang", "Shiyu", ""], ["Fellouris", "Georgios", ""], ["Chang", "Hua-Hua", ""]]}, {"id": "1501.01525", "submitter": "Andreas Andresen", "authors": "Andreas Andresen and Vladimir Spokoiny", "title": "Two convergence results for an alternation maximization procedure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Andresen and Spokoiny's (2013) ``critical dimension in semiparametric\nestimation`` provide a technique for the finite sample analysis of profile\nM-estimators. This paper uses very similar ideas to derive two convergence\nresults for the alternating procedure to approximate the maximizer of random\nfunctionals such as the realized log likelihood in MLE estimation. We manage to\nshow that the sequence attains the same deviation properties as shown for the\nprofile M-estimator in Andresen and Spokoiny (2013), i.e. a finite sample Wilks\nand Fisher theorem. Further under slightly stronger smoothness constraints on\nthe random functional we can show nearly linear convergence to the global\nmaximizer if the starting point for the procedure is well chosen.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jan 2015 15:42:46 GMT"}], "update_date": "2015-01-08", "authors_parsed": [["Andresen", "Andreas", ""], ["Spokoiny", "Vladimir", ""]]}, {"id": "1501.01561", "submitter": "Natalia Markovich M", "authors": "Natalia Markovich", "title": "Hitting times of threshold exceedances and their distributions", "comments": "6 pages, International Conference on Risk Analysis ICRA 6 / RISK 2015\n  Barcelona, May 26 - 29, 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate exceedances of the process over a sufficiently high threshold.\nThe exceedances determine the risk of hazardous events like climate\ncatastrophes, huge insurance claims, the loss and delay in telecommunication\nnetworks.\n  Due to dependence such exceedances tend to occur in clusters. Cluster\nstructure of social networks is caused by dependence (social relationships and\ninterests) between nodes and possibly heavy-tailed distributions of the node\ndegrees. A minimal time to reach a large node determines the first hitting\ntime. We derive asymptotically equivalent distribution and a limit expectation\nof the first hitting time to exceed the threshold $u_n$ as sample size $n$\ntends to infinity. The results can be extended to the second and, generally, to\n$k$th ($k>2$) hitting times.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jan 2015 17:03:25 GMT"}], "update_date": "2015-01-08", "authors_parsed": [["Markovich", "Natalia", ""]]}, {"id": "1501.01617", "submitter": "Lucy Xia", "authors": "Jianqing Fan, Yang Feng, Lucy Xia", "title": "A Projection Based Conditional Dependence Measure with Applications to\n  High-dimensional Undirected Graphical Models", "comments": "39 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.AP stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Measuring conditional dependence is an important topic in statistics with\nbroad applications including graphical models. Under a factor model setting, a\nnew conditional dependence measure based on projection is proposed. The\ncorresponding conditional independence test is developed with the asymptotic\nnull distribution unveiled where the number of factors could be\nhigh-dimensional. It is also shown that the new test has control over the\nasymptotic significance level and can be calculated efficiently. A generic\nmethod for building dependency graphs without Gaussian assumption using the new\ntest is elaborated. Numerical results and real data analysis show the\nsuperiority of the new method.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jan 2015 20:43:14 GMT"}, {"version": "v2", "created": "Thu, 8 Jan 2015 20:08:35 GMT"}, {"version": "v3", "created": "Wed, 23 Nov 2016 04:50:55 GMT"}, {"version": "v4", "created": "Tue, 14 Feb 2017 20:33:54 GMT"}, {"version": "v5", "created": "Fri, 11 Jan 2019 07:36:17 GMT"}], "update_date": "2019-01-14", "authors_parsed": [["Fan", "Jianqing", ""], ["Feng", "Yang", ""], ["Xia", "Lucy", ""]]}, {"id": "1501.01732", "submitter": "Dennis Leung", "authors": "Dennis Leung, Mathias Drton", "title": "Testing independence in high dimensions with sums of rank correlations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We treat the problem of testing independence between m continuous variables\nwhen m can be larger than the available sample size n. We consider three types\nof test statistics that are constructed as sums or sums of squares of pairwise\nrank correlations. In the asymptotic regime where both m and n tend to\ninfinity, a martingale central limit theorem is applied to show that the null\ndistributions of these statistics converge to Gaussian limits, which are valid\nwith no specific distributional or moment assumptions on the data. Using the\nframework of U-statistics, our result covers a variety of rank correlations\nincluding Kendall's tau and a dominating term of Spearman's rank correlation\ncoefficient (rho), but also degenerate U-statistics such as Hoeffding's $D$, or\nthe $\\tau^*$ of Bergsma and Dassios (2014). As in the classical theory for\nU-statistics, the test statistics need to be scaled differently when the rank\ncorrelations used to construct them are degenerate U-statistics. The power of\nthe considered tests is explored in rate-optimality theory under Gaussian\nequicorrelation alternatives as well as in numerical experiments for specific\ncases of more general alternatives.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jan 2015 05:45:00 GMT"}, {"version": "v2", "created": "Fri, 16 Oct 2015 03:00:38 GMT"}, {"version": "v3", "created": "Fri, 2 Dec 2016 08:51:56 GMT"}], "update_date": "2016-12-05", "authors_parsed": [["Leung", "Dennis", ""], ["Drton", "Mathias", ""]]}, {"id": "1501.01840", "submitter": "Ryan Martin", "authors": "Nick Syring and Ryan Martin", "title": "Gibbs posterior inference on the minimum clinically important difference", "comments": "17 pages, 1 figure, 2 tables", "journal-ref": "Journal of Statistical Planning and Inference, volume 187, pages\n  67--77, 2017", "doi": "10.1016/j.jspi.2017.03.001", "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  IIt is known that a statistically significant treatment may not be clinically\nsignificant. A quantity that can be used to assess clinical significance is\ncalled the minimum clinically important difference (MCID), and inference on the\nMCID is an important and challenging problem. Modeling for the purpose of\ninference on the MCID is non-trivial, and concerns about bias from a\nmisspecified parametric model or inefficiency from a nonparametric model\nmotivate an alternative approach to balance robustness and efficiency. In\nparticular, a recently proposed representation of the MCID as the minimizer of\na suitable risk function makes it possible to construct a Gibbs posterior\ndistribution for the MCID without specifying a model. We establish the\nposterior convergence rate and show, numerically, that an appropriately scaled\nversion of this Gibbs posterior yields interval estimates for the MCID which\nare both valid and efficient even for relatively small sample sizes.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jan 2015 13:37:50 GMT"}, {"version": "v2", "created": "Fri, 4 Sep 2015 18:36:22 GMT"}, {"version": "v3", "created": "Sat, 3 Sep 2016 17:23:29 GMT"}, {"version": "v4", "created": "Mon, 26 Jun 2017 19:19:13 GMT"}], "update_date": "2017-06-28", "authors_parsed": [["Syring", "Nick", ""], ["Martin", "Ryan", ""]]}, {"id": "1501.02103", "submitter": "Robin Evans", "authors": "Robin J. Evans", "title": "Margins of discrete Bayesian networks", "comments": "41 pages", "journal-ref": "Annals of Statistics 2018, Vol. 46, No. 6A, 2623-2656", "doi": "10.1214/17-AOS1631", "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian network models with latent variables are widely used in statistics\nand machine learning. In this paper we provide a complete algebraic\ncharacterization of Bayesian network models with latent variables when the\nobserved variables are discrete and no assumption is made about the state-space\nof the latent variables. We show that it is algebraically equivalent to the\nso-called nested Markov model, meaning that the two are the same up to\ninequality constraints on the joint probabilities. In particular these two\nmodels have the same dimension. The nested Markov model is therefore the best\npossible description of the latent variable model that avoids consideration of\ninequalities, which are extremely complicated in general. A consequence of this\nis that the constraint finding algorithm of Tian and Pearl (UAI 2002,\npp519-527) is complete for finding equality constraints.\n  Latent variable models suffer from difficulties of unidentifiable parameters\nand non-regular asymptotics; in contrast the nested Markov model is fully\nidentifiable, represents a curved exponential family of known dimension, and\ncan easily be fitted using an explicit parameterization.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jan 2015 11:04:03 GMT"}, {"version": "v2", "created": "Mon, 30 Jan 2017 16:56:36 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Evans", "Robin J.", ""]]}, {"id": "1501.02151", "submitter": "Marie-Annick Guillemer", "authors": "Dominique Dehay", "title": "Limiting distributions for explosive PAR(1) time series with strongly\n  mixing innovation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work deals with the limiting distribution of the least squares\nestimators of the coefficients a r of an explosive periodic autoregressive of\norder 1 (PAR(1)) time series X r = a r X r--1 +u r when the innovation {u k }\nis strongly mixing. More precisely {a r } is a periodic sequence of real\nnumbers with period P \\textgreater{} 0 and such that P r=1 |a r |\n\\textgreater{} 1. The time series {u r } is periodically distributed with the\nsame period P and satisfies the strong mixing property, so the random variables\nu r can be correlated.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jan 2015 14:28:16 GMT"}], "update_date": "2015-01-12", "authors_parsed": [["Dehay", "Dominique", ""]]}, {"id": "1501.02201", "submitter": "Ali Akbar Jafari", "authors": "Ali Akbar Jafari, Hojatollah Zakerzadeh", "title": "Inference on the Parameters of the Weibull Distribution Using Records", "comments": "Accepted for publication in SORT", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Weibull distribution is a very applicable model for the lifetime data. In\nthis paper, we have investigated inference on the parameters of Weibull\ndistribution based on record values. We first propose a simple and exact test\nand a confidence interval for the shape parameter. Then, in addition to a\ngeneralized confidence interval, a generalized test variable is derived for the\nscale parameter when the shape parameter is unknown. The paper presents a\nsimple and exact joint confidence region as well. %for the scale and shape\nparameters. In all cases, simulation studies show that the proposed approaches\nare more satisfactory and reliable than previous methods. All proposed\napproaches are illustrated using a real example.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jan 2015 17:22:37 GMT"}], "update_date": "2015-01-12", "authors_parsed": [["Jafari", "Ali Akbar", ""], ["Zakerzadeh", "Hojatollah", ""]]}, {"id": "1501.02241", "submitter": "Mohamed Eliwa", "authors": "M. A. EL-Damcese, Abdelfattah Mustafa, and M. S. Eliwa", "title": "Bivariate Exponentaited Generalized Weibull-Gompertz Distribution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a bivariate exponentaited generalized\nWeibull-Gompertz distribution. The model introduced here is of Marshall-Olkin\ntype. Several properties are studied such as bivariate probability density\nfunction and it is marginal, moments, maximum likelihood estimation, joint\nreversed (hazard) function and joint mean waiting time and it is marginal. A\nreal data set is analyzed and it is observed that the present distribution can\nprovide a better fit than some other very well-known distributions.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jan 2015 19:40:31 GMT"}, {"version": "v2", "created": "Fri, 16 Jan 2015 12:05:26 GMT"}], "update_date": "2015-01-19", "authors_parsed": [["EL-Damcese", "M. A.", ""], ["Mustafa", "Abdelfattah", ""], ["Eliwa", "M. S.", ""]]}, {"id": "1501.02247", "submitter": "Maria D. Ruiz-Medina MDRM", "authors": "N.N. Leonenko, M.D. Ruiz-Medina and M.S. Taqqu", "title": "Rosenblatt distribution subordinated to gaussian random fields with\n  long-range dependence", "comments": "This paper has 40 pages and it has already been submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Karhunen-Lo\\`eve expansion and the Fredholm determinant formula are used\nto derive an asymptotic Rosenblatt-type distribution of a sequence of integrals\nof quadratic functions of Gaussian stationary random fields on R^d displaying\nlong-range dependence. This distribution reduces to the usual Rosenblatt\ndistribution when d=1. Several properties of this new distribution are\nobtained. Specifically, its series representation in terms of independent\nchi-squared random variables is given, the asymptotic behavior of the\neigenvalues, its L\\`evy-Khintchine representation, as well as its membership to\nthe Thorin subclass of self-decomposable distributions. The existence and\nboundedness of its probability density is then a direct consequence.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jan 2015 19:50:58 GMT"}, {"version": "v2", "created": "Mon, 26 Oct 2015 16:53:33 GMT"}, {"version": "v3", "created": "Mon, 9 Nov 2015 09:27:57 GMT"}, {"version": "v4", "created": "Wed, 8 Jun 2016 08:31:10 GMT"}], "update_date": "2016-06-09", "authors_parsed": [["Leonenko", "N. N.", ""], ["Ruiz-Medina", "M. D.", ""], ["Taqqu", "M. S.", ""]]}, {"id": "1501.02320", "submitter": "Po-Ling Loh", "authors": "Varun Jog and Po-Ling Loh", "title": "On model misspecification and KL separation for Gaussian graphical\n  models", "comments": "Accepted to ISIT 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We establish bounds on the KL divergence between two multivariate Gaussian\ndistributions in terms of the Hamming distance between the edge sets of the\ncorresponding graphical models. We show that the KL divergence is bounded below\nby a constant when the graphs differ by at least one edge; this is essentially\nthe tightest possible bound, since classes of graphs exist for which the edge\ndiscrepancy increases but the KL divergence remains bounded above by a\nconstant. As a natural corollary to our KL lower bound, we also establish a\nsample size requirement for correct model selection via maximum likelihood\nestimation. Our results rigorize the notion that it is essential to estimate\nthe edge structure of a Gaussian graphical model accurately in order to\napproximate the true distribution to close precision.\n", "versions": [{"version": "v1", "created": "Sat, 10 Jan 2015 08:50:57 GMT"}, {"version": "v2", "created": "Fri, 3 Apr 2015 19:13:27 GMT"}], "update_date": "2015-04-06", "authors_parsed": [["Jog", "Varun", ""], ["Loh", "Po-Ling", ""]]}, {"id": "1501.02382", "submitter": "Fang Han", "authors": "Jianqing Fan, Fang Han, Han Liu, Byron Vickers", "title": "Robust Inference of Risks of Large Portfolios", "comments": "45 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST q-fin.PM stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a bootstrap-based robust high-confidence level upper bound (Robust\nH-CLUB) for assessing the risks of large portfolios. The proposed approach\nexploits rank-based and quantile-based estimators, and can be viewed as a\nrobust extension of the H-CLUB method (Fan et al., 2015). Such an extension\nallows us to handle possibly misspecified models and heavy-tailed data. Under\nmixing conditions, we analyze the proposed approach and demonstrate its\nadvantage over the H-CLUB. We further provide thorough numerical results to\nback up the developed theory. We also apply the proposed method to analyze a\nstock market dataset.\n", "versions": [{"version": "v1", "created": "Sat, 10 Jan 2015 18:49:32 GMT"}], "update_date": "2015-01-13", "authors_parsed": [["Fan", "Jianqing", ""], ["Han", "Fang", ""], ["Liu", "Han", ""], ["Vickers", "Byron", ""]]}, {"id": "1501.02389", "submitter": "Peng Ding", "authors": "Peng Ding and Tirthankar Dasgupta", "title": "A Potential Tale of Two by Two Tables from Completely Randomized\n  Experiments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal inference in completely randomized treatment-control studies with\nbinary outcomes is discussed from Fisherian, Neymanian and Bayesian\nperspectives, using the potential outcomes framework. A randomization-based\njustification of Fisher's exact test is provided. Arguing that the crucial\nassumption of constant causal effect is often unrealistic, and holds only for\nextreme cases, some new asymptotic and Bayesian inferential procedures are\nproposed. The proposed procedures exploit the intrinsic non-additivity of\nunit-level causal effects, can be applied to linear and non-linear estimands,\nand dominate the existing methods, as verified theoretically and also through\nsimulation studies.\n", "versions": [{"version": "v1", "created": "Sat, 10 Jan 2015 20:31:02 GMT"}], "update_date": "2015-01-13", "authors_parsed": [["Ding", "Peng", ""], ["Dasgupta", "Tirthankar", ""]]}, {"id": "1501.02414", "submitter": "Samira Sadeghi", "authors": "Michael A. Kouritzin and Samira Sadeghi", "title": "Convergence Rates and Decoupling in Linear Stochastic Approximation\n  Algorithms", "comments": "27 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Almost sure convergence rates for linear algorithms $h_{k+1} = h_k\n+\\frac{1}{k^\\chi} (b_k-A_kh_k)$ are studied, where $\\chi\\in(0,1)$,\n$\\{A_{k}\\}_{k=1}^\\infty$ are symmetric, positive semidefinite random matrices\nand $\\{b_{k}\\}_{k=1}^\\infty$ are random vectors. It is shown that $|h_n-\nA^{-1}b|=o(n^{-\\gamma})$ a.s. for the $\\gamma\\in[0,\\chi)$, positive definite\n$A$ and vector $b$ such that $\\frac{1}{n^{\\chi-\\gamma}}\\sum\\limits_{k=1}^n\n(A_{k}- A)\\to 0$ and $\\frac{1}{n^{\\chi-\\gamma}}\\sum\\limits_{k=1}^n (b_k-b)\\to\n0$ a.s. When $\\chi-\\gamma\\in\\left(\\frac12,1\\right)$, these assumptions are\nimplied by the Marcinkiewicz strong law of large numbers, which allows the\n$\\{A_k\\}$ and $\\{b_k\\}$ to have heavy-tails, long-range dependence or both.\nFinally, corroborating experimental outcomes and decreasing-gain design\nconsiderations are provided.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jan 2015 04:11:11 GMT"}], "update_date": "2015-01-13", "authors_parsed": [["Kouritzin", "Michael A.", ""], ["Sadeghi", "Samira", ""]]}, {"id": "1501.02415", "submitter": "Samira Sadeghi", "authors": "Michael A. Kouritzin and Samira Sadeghi", "title": "Marcinkiewicz Law of Large Numbers for Outer-products of Heavy-tailed,\n  Long-range Dependent Data", "comments": "23 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Marcinkiewicz Strong Law,\n$\\displaystyle\\lim_{n\\to\\infty}\\frac{1}{n^{\\frac1p}}\\sum_{k=1}^n (D_{k}- D)=0$\na.s. with $p\\in(1,2)$, is studied for outer products $D_k=X_k\\overline{X}_k^T$,\nwhere $\\{X_k\\},\\{\\overline{X}_k\\}$ are both two-sided (multivariate) linear\nprocesses ( with coefficient matrices $(C_l), (\\overline{C}_l)$ and i.i.d.\\\nzero-mean innovations $\\{\\Xi\\}$, $\\{\\overline{\\Xi}\\}$). Matrix sequences $C_l$\nand $\\overline{C}_l$ can decay slowly enough (as $|l|\\to\\infty$) that\n$\\{X_k,\\overline{X}_k\\}$ have long-range dependence while $\\{D_k\\}$ can have\nheavy tails. In particular, the heavy-tail and long-range-dependence phenomena\nfor $\\{D_k\\}$ are handled simultaneously and a new decoupling property is\nproved that shows the convergence rate is determined by the worst of the\nheavy-tails or the long-range dependence, but not the combination. The main\nresult is applied to obtain Marcinkiewicz Strong Law of Large Numbers for\nstochastic approximation, non-linear functions forms and autocovariances.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jan 2015 04:21:41 GMT"}], "update_date": "2015-01-13", "authors_parsed": [["Kouritzin", "Michael A.", ""], ["Sadeghi", "Samira", ""]]}, {"id": "1501.02497", "submitter": "Nhat Ho", "authors": "Nhat Ho and XuanLong Nguyen", "title": "Identifiability and optimal rates of convergence for parameters of\n  multiple types in finite mixtures", "comments": "95 pages, 17 figures, Technical report 536, Department of Statistics,\n  University of Michigan, Ann Arbor", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies identifiability and convergence behaviors for parameters\nof multiple types in finite mixtures, and the effects of model fitting with\nextra mixing components. First, we present a general theory for strong\nidentifiability, which extends from the previous work of Nguyen [2013] and Chen\n[1995] to address a broad range of mixture models and to handle matrix-variate\nparameters. These models are shown to share the same Wasserstein distance based\noptimal rates of convergence for the space of mixing distributions ---\n$n^{-1/2}$ under $W_1$ for the exact-fitted and $n^{-1/4}$ under $W_2$ for the\nover-fitted setting, where $n$ is the sample size. This theory, however, is not\napplicable to several important model classes, including location-scale\nmultivariate Gaussian mixtures, shape-scale Gamma mixtures and\nlocation-scale-shape skew-normal mixtures. The second part of this work is\ndevoted to demonstrating that for these \"weakly identifiable\" classes,\nalgebraic structures of the density family play a fundamental role in\ndetermining convergence rates of the model parameters, which display a very\nrich spectrum of behaviors. For instance, the optimal rate of parameter\nestimation in an over-fitted location-covariance Gaussian mixture is precisely\ndetermined by the order of a solvable system of polynomial equations --- these\nrates deteriorate rapidly as more extra components are added to the model. The\nestablished rates for a variety of settings are illustrated by a simulation\nstudy.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jan 2015 21:00:07 GMT"}], "update_date": "2015-01-13", "authors_parsed": [["Ho", "Nhat", ""], ["Nguyen", "XuanLong", ""]]}, {"id": "1501.02513", "submitter": "Marcin Pitera", "authors": "Piotr Jaworski and Marcin Pitera", "title": "The 20-60-20 Rule", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST q-fin.EC stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we discuss an empirical phenomena known as the 20-60-20 rule.\nIt says that if we split the population into three groups, according to some\narbitrary benchmark criterion, then this particular ratio implies some sort of\nbalance. From practical point of view, this feature often leads to efficient\nmanagement or control. We provide a mathematical illustration, justifying the\noccurrence of this rule in many real world situations. We show that for any\npopulation, which could be described using multivariate normal vector, this\nfixed ratio leads to a global equilibrium state, when dispersion and linear\ndependance measurement is considered.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jan 2015 00:41:49 GMT"}, {"version": "v2", "created": "Thu, 20 Aug 2015 04:15:01 GMT"}], "update_date": "2015-08-21", "authors_parsed": [["Jaworski", "Piotr", ""], ["Pitera", "Marcin", ""]]}, {"id": "1501.02559", "submitter": "Amir Sepehri", "authors": "Amir Sepehri and Naftali Harris", "title": "The Accessible Lasso Models", "comments": "To appear in Statistics: A Journal of Theoretical and Applied\n  Statistics", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new line of research on the lasso exploits the beautiful geometric fact\nthat the lasso fit is the residual from projecting the response vector $y$ onto\na certain convex polytope. This geometric picture also allows an exact\ngeometric description of the set of accessible lasso models for a given design\nmatrix, that is, which configurations of the signs of the coefficients it is\npossible to realize with some choice of $y$. In particular, the accessible\nlasso models are those that correspond to a face of the convex hull of all the\nfeature vectors together with their negations. This convex hull representation\nthen permits the enumeration and bounding of the number of accessible lasso\nmodels, which in turn provides a direct proof of model selection inconsistency\nwhen the size of the true model is greater than half the number of\nobservations.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jan 2015 07:53:39 GMT"}, {"version": "v2", "created": "Tue, 8 Mar 2016 22:39:22 GMT"}, {"version": "v3", "created": "Thu, 9 Jun 2016 16:30:09 GMT"}], "update_date": "2016-06-10", "authors_parsed": [["Sepehri", "Amir", ""], ["Harris", "Naftali", ""]]}, {"id": "1501.02861", "submitter": "Ery Arias-Castro", "authors": "Ery Arias-Castro", "title": "Some theory for ordinal embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by recent work on ordinal embedding (Kleindessner and von Luxburg,\n2014), we derive large sample consistency results and rates of convergence for\nthe problem of embedding points based on triple or quadruple distance\ncomparisons. We also consider a variant of this problem where only local\ncomparisons are provided. Finally, inspired by (Jamieson and Nowak, 2011), we\nbound the number of such comparisons needed to achieve consistency.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jan 2015 01:49:16 GMT"}, {"version": "v2", "created": "Wed, 4 May 2016 16:10:31 GMT"}], "update_date": "2016-05-05", "authors_parsed": [["Arias-Castro", "Ery", ""]]}, {"id": "1501.03013", "submitter": "Piotr Zwiernik", "authors": "Piotr Zwiernik and Jan Draisma", "title": "Automorphism groups of Gaussian chain graph models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we extend earlier work on groups acting on Gaussian graphical\nmodels to Gaussian Bayesian networks and more general Gaussian models defined\nby chain graphs. We discuss the maximal group which leaves a given model\ninvariant and provide basic statistical applications of this result. This\nincludes equivariant estimation, maximal invariants and robustness. The\ncomputation of the group requires finding the essential graph. However, by\napplying Studeny's theory of imsets we show that computations for DAGs can be\nperformed efficiently without building the essential graph. In our proof we\nderive simple necessary and sufficient conditions on vanishing sub-minors of\nthe concentration matrix in the model.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jan 2015 14:14:49 GMT"}], "update_date": "2015-01-14", "authors_parsed": [["Zwiernik", "Piotr", ""], ["Draisma", "Jan", ""]]}, {"id": "1501.03059", "submitter": "Ingo Steinwart", "authors": "H. Hang and I. Steinwart", "title": "A Bernstein-type Inequality for Some Mixing Processes and Dynamical\n  Systems with an Application to Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We establish a Bernstein-type inequality for a class of stochastic processes\nthat include the classical geometrically $\\phi$-mixing processes, Rio's\ngeneralization of these processes, as well as many time-discrete dynamical\nsystems. Modulo a logarithmic factor and some constants, our Bernstein-type\ninequality coincides with the classical Bernstein inequality for i.i.d.~data.\nWe further use this new Bernstein-type inequality to derive an oracle\ninequality for generic regularized empirical risk minimization algorithms and\ndata generated by such processes. Applying this oracle inequality to support\nvector machines using the Gaussian kernels for both least squares and quantile\nregression, it turns out that the resulting learning rates match, up to some\narbitrarily small extra term in the exponent, the optimal rates for\ni.i.d.~processes.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jan 2015 16:04:23 GMT"}], "update_date": "2015-01-14", "authors_parsed": [["Hang", "H.", ""], ["Steinwart", "I.", ""]]}, {"id": "1501.03136", "submitter": "Micha{\\l} Boczek", "authors": "Micha{\\l} Boczek, Marek Kaluszka", "title": "Convergence theorems for seminormed fuzzy integrals: Solutions to\n  Hutn\\`ik's open problems", "comments": "3 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this note, we give solutions to Problems $9.4$ and $9.5,$ which were\npresented by Mesiar and Stup\\v{n}anov\\'{a} [{\\it Open problems from the 12th\nInternational Conference on Fuzzy Set Theory and Its Applications}, Fuzzy Sets\nand Systems 261 (2015)] and by Borzov\\'a-Moln\\'arov\\'a, Hal\\u{c}inov\\'a and\nHutn\\'ik, in [{\\it The smallest semicopula-based universal integrals I:\nproperties and characterizations,} Fuzzy Sets and Systems (2014),\nhttp://dx.doi.org/ 10.1016/j.fss.2014.09.024].\n", "versions": [{"version": "v1", "created": "Sat, 10 Jan 2015 22:39:24 GMT"}], "update_date": "2015-01-14", "authors_parsed": [["Boczek", "Micha\u0142", ""], ["Kaluszka", "Marek", ""]]}, {"id": "1501.03430", "submitter": "Victor Chernozhukov", "authors": "Victor Chernozhukov and Christian Hansen and Martin Spindler", "title": "Valid Post-Selection and Post-Regularization Inference: An Elementary,\n  General Approach", "comments": "47 pages", "journal-ref": "Annual Review of Economics, Vol. 7: 649-688 (August 2015)", "doi": "10.1146/annurev-economics-012315-015826", "report-no": null, "categories": "math.ST econ.EM stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Here we present an expository, general analysis of valid post-selection or\npost-regularization inference about a low-dimensional target parameter,\n$\\alpha$, in the presence of a very high-dimensional nuisance parameter,\n$\\eta$, which is estimated using modern selection or regularization methods.\nOur analysis relies on high-level, easy-to-interpret conditions that allow one\nto clearly see the structures needed for achieving valid post-regularization\ninference. Simple, readily verifiable sufficient conditions are provided for a\nclass of affine-quadratic models. We focus our discussion on estimation and\ninference procedures based on using the empirical analog of theoretical\nequations $$M(\\alpha, \\eta)=0$$ which identify $\\alpha$. Within this structure,\nwe show that setting up such equations in a manner such that the\northogonality/immunization condition $$\\partial_\\eta M(\\alpha, \\eta) = 0$$ at\nthe true parameter values is satisfied, coupled with plausible conditions on\nthe smoothness of $M$ and the quality of the estimator $\\hat \\eta$, guarantees\nthat inference on for the main parameter $\\alpha$ based on testing or point\nestimation methods discussed below will be regular despite selection or\nregularization biases occurring in estimation of $\\eta$. In particular, the\nestimator of $\\alpha$ will often be uniformly consistent at the root-$n$ rate\nand uniformly asymptotically normal even though estimators $\\hat \\eta$ will\ngenerally not be asymptotically linear and regular. The uniformity holds over\nlarge classes of models that do not impose highly implausible \"beta-min\"\nconditions. We also show that inference can be carried out by inverting tests\nformed from Neyman's $C(\\alpha)$ (orthogonal score) statistics.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jan 2015 18:06:26 GMT"}, {"version": "v2", "created": "Thu, 15 Jan 2015 02:49:57 GMT"}, {"version": "v3", "created": "Tue, 18 Aug 2015 15:05:24 GMT"}], "update_date": "2017-10-03", "authors_parsed": [["Chernozhukov", "Victor", ""], ["Hansen", "Christian", ""], ["Spindler", "Martin", ""]]}, {"id": "1501.03528", "submitter": "Mahmoud Elmorshedy", "authors": "A. El-Gohary and M. El-Morshedy", "title": "Bivariate Exponentiated Modified Weibull Extension", "comments": "14", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a new bivariate distribution we called it\nbivariate expo- nentiated modified Weibull extension distribution (BEMWE). The\nmodel introduced here is of Marshall-Olkin type. The marginals of the new\nbivariate distribution have exponentiated modified Weibull extension\ndistribution which proposed by Sarhan et al.(2013). The joint probability\ndensity function and the joint cumulative distribu- tion function are in closed\nforms. Several properties of this distribution have been discussed.The maximum\nlikelihood estimators of the parameters are derived. One real data set are\nanalyzed using the new bivariate distribution, which show that the new\nbivariate distribution can be used quite effectively in fitting and analyzing\nreal lifetime data\n", "versions": [{"version": "v1", "created": "Wed, 14 Jan 2015 22:19:41 GMT"}], "update_date": "2015-01-16", "authors_parsed": [["El-Gohary", "A.", ""], ["El-Morshedy", "M.", ""]]}, {"id": "1501.03588", "submitter": "Xiaoying Tian", "authors": "Xiaoying Tian, Jonathan Taylor", "title": "Asymptotics of selective inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we seek to establish asymptotic results for selective\ninference procedures removing the assumption of Gaussianity. The class of\nselection procedures we consider are determined by affine inequalities, which\nwe refer to as affine selection procedures. Examples of affine selection\nprocedures include post-selection inference along the solution path of the\nLASSO, as well as post-selection inference after fitting the LASSO at a fixed\nvalue of the regularization parameter. We also consider some tests in penalized\ngeneralized linear models. Our method of proof adapts a method of Chatterjee\n(2005).\n", "versions": [{"version": "v1", "created": "Thu, 15 Jan 2015 06:47:36 GMT"}, {"version": "v2", "created": "Thu, 4 Aug 2016 17:59:23 GMT"}], "update_date": "2016-08-05", "authors_parsed": [["Tian", "Xiaoying", ""], ["Taylor", "Jonathan", ""]]}, {"id": "1501.03659", "submitter": "Azzimonti Dario", "authors": "Dario Azzimonti (IMSV), Julien Bect (GdR MASCOT-NUM, L2S), Cl\\'ement\n  Chevalier (UNINE), David Ginsbourger (Idiap, IMSV)", "title": "Quantifying uncertainties on excursion sets under a Gaussian random\n  field prior", "comments": null, "journal-ref": "SIAM/ASA Journal on Uncertainty Quantification, 4(1):850-874, 2016", "doi": "10.1137/141000749", "report-no": null, "categories": "math.ST stat.CO stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We focus on the problem of estimating and quantifying uncertainties on the\nexcursion set of a function under a limited evaluation budget. We adopt a\nBayesian approach where the objective function is assumed to be a realization\nof a Gaussian random field. In this setting, the posterior distribution on the\nobjective function gives rise to a posterior distribution on excursion sets.\nSeveral approaches exist to summarize the distribution of such sets based on\nrandom closed set theory. While the recently proposed Vorob'ev approach\nexploits analytical formulae, further notions of variability require Monte\nCarlo estimators relying on Gaussian random field conditional simulations. In\nthe present work we propose a method to choose Monte Carlo simulation points\nand obtain quasi-realizations of the conditional field at fine designs through\naffine predictors. The points are chosen optimally in the sense that they\nminimize the posterior expected distance in measure between the excursion set\nand its reconstruction. The proposed method reduces the computational costs due\nto Monte Carlo simulations and enables the computation of quasi-realizations on\nfine designs in large dimensions. We apply this reconstruction approach to\nobtain realizations of an excursion set on a fine grid which allow us to give a\nnew measure of uncertainty based on the distance transform of the excursion\nset. Finally we present a safety engineering test case where the simulation\nmethod is employed to compute a Monte Carlo estimate of a contour line.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jan 2015 12:58:28 GMT"}, {"version": "v2", "created": "Wed, 13 Apr 2016 11:24:30 GMT"}], "update_date": "2017-08-02", "authors_parsed": [["Azzimonti", "Dario", "", "IMSV"], ["Bect", "Julien", "", "GdR MASCOT-NUM, L2S"], ["Chevalier", "Cl\u00e9ment", "", "UNINE"], ["Ginsbourger", "David", "", "Idiap, IMSV"]]}, {"id": "1501.03664", "submitter": "Gyula Pap", "authors": "J\\'anos Marcell Benke and Gyula Pap", "title": "Local asymptotic quadraticity of statistical experiments connected with\n  a Heston model", "comments": "29 pages", "journal-ref": "Acta Sci. Math. (Szeged) 83:1-2(2017), 313-344", "doi": "10.14232/actasm-016-506-x", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study local asymptotic properties of likelihood ratios of certain Heston\nmodels. We distinguish three cases: subcritical, critical and supercritical\nmodels. For the drift parameters, local asymptotic normality is proved in the\nsubcritical case, only local asymptotic quadraticity is shown in the critical\ncase, while in the supercritical case not even local asymptotic quadraticity\nholds. For certain submodels, local asymptotic normality is proved in the\ncritical case, and local asymptotic mixed normality is shown in the\nsupercritical case. As a consequence, asymptotically optimal (randomized) tests\nare constructed in cases of local asymptotic normality. Moreover, local\nasymptotic minimax bound, and hence, asymptotic efficiency in the convolution\ntheorem sense are concluded for the maximum likelihood estimators in cases of\nlocal asymptotic mixed normality.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jan 2015 13:13:09 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Benke", "J\u00e1nos Marcell", ""], ["Pap", "Gyula", ""]]}, {"id": "1501.03694", "submitter": "Stephan Haug", "authors": "Stephan Haug, Claudia Kl\\\"uppelberg, German Straub", "title": "Fractionally integrated COGARCH processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We construct fractionally integrated continuous-time GARCH models, which\ncapture the observed long range dependence of squared volatility in\nhigh-frequency data. Since the usual Molchan-Golosov and Mandelbrot-van-Ness\nfractional kernels lead to problems in the definition of the model, we resort\nto moderately long memory processes by choosing a fractional parameter\n$d\\in(-0.5,0)$ and remove the singularities of the kernel to obtain\nnon-pathological sample paths. The volatility of the new fractional COGARCH\nprocess has positive features like stationarity, and its covariance function\nshows an algebraic decay, which make it applicable to econometric\nhigh-frequency data. In an empirical application the model is fitted to\nexchange rate data using a simulation-based version of the generalised method\nof moments.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jan 2015 14:35:11 GMT"}, {"version": "v2", "created": "Fri, 15 May 2015 12:53:14 GMT"}, {"version": "v3", "created": "Fri, 29 Dec 2017 14:30:42 GMT"}], "update_date": "2018-01-01", "authors_parsed": [["Haug", "Stephan", ""], ["Kl\u00fcppelberg", "Claudia", ""], ["Straub", "German", ""]]}, {"id": "1501.03704", "submitter": "Le Zheng", "authors": "Le Zheng, Arian Maleki, Haolei Weng, Xiaodong Wang, Teng Long", "title": "Does $\\ell_p$-minimization outperform $\\ell_1$-minimization?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many application areas we are faced with the following question: Can we\nrecover a sparse vector $x_o \\in \\mathbb{R}^N$ from its undersampled set of\nnoisy observations $y \\in \\mathbb{R}^n$, $y=A x_o+w$. The last decade has\nwitnessed a surge of algorithms and theoretical results addressing this\nquestion. One of the most popular algorithms is the $\\ell_p$-regularized least\nsquares (LPLS) given by the following formulation: \\[ \\hat{x}(\\gamma,p )\\in\n\\arg\\min_x \\frac{1}{2}\\|y - Ax\\|_2^2+\\gamma\\|x\\|_p^p, \\] where $p \\in [0,1]$.\nDespite the non-convexity of these problems for $p<1$, they are still appealing\nbecause of the following folklores in compressed sensing: (i) $\\hat{x}(\\gamma,p\n)$ is closer to $x_o$ than $\\hat{x}(\\gamma,1)$. (ii) If we employ iterative\nmethods that aim to converge to a local minima of LPLS, then under good\ninitialization these algorithms converge to a solution that is closer to $x_o$\nthan $\\hat{x}(\\gamma,1)$. In spite of the existence of plenty of empirical\nresults that support these folklore theorems, the theoretical progress to\nestablish them has been very limited.\n  This paper aims to study the above folklore theorems and establish their\nscope of validity. Starting with approximate message passing algorithm as a\nheuristic method for solving LPLS, we study the impact of initialization on the\nperformance of AMP. Then, we employ the replica analysis to show the connection\nbetween the solution of AMP and $\\hat{x}(\\gamma, p)$ in the asymptotic\nsettings. This enables us to compare the accuracy of $\\hat{x}(\\gamma,p)$ for $p\n\\in [0,1]$. In particular, we will characterize the phase transition and noise\nsensitivity of LPLS for every $0\\leq p\\leq 1$ accurately. Our results in the\nnoiseless setting confirm that LPLS exhibits the same phase transition for\nevery $0\\leq p <1$ and this phase transition is much higher than that of LASSO.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jan 2015 14:54:10 GMT"}, {"version": "v2", "created": "Fri, 10 Jun 2016 23:25:44 GMT"}], "update_date": "2016-06-14", "authors_parsed": [["Zheng", "Le", ""], ["Maleki", "Arian", ""], ["Weng", "Haolei", ""], ["Wang", "Xiaodong", ""], ["Long", "Teng", ""]]}, {"id": "1501.04070", "submitter": "Ernest Fokoue", "authors": "Ernest Fokoue and Necla Gunduz", "title": "An Information-Theoretic Alternative to the Cronbach's Alpha Coefficient\n  of Item Reliability", "comments": "8 pages, 2 tables, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an information-theoretic alternative to the popular Cronbach alpha\ncoefficient of reliability. Particularly suitable for contexts in which\ninstruments are scored on a strictly nonnumeric scale, our proposed index is\nbased on functions of the entropy of the distributions of defined on the sample\nspace of responses. Our reliability index tracks the Cronbach alpha coefficient\nuniformly while offering several other advantages discussed in great details in\nthis paper.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jan 2015 18:01:31 GMT"}], "update_date": "2015-01-19", "authors_parsed": [["Fokoue", "Ernest", ""], ["Gunduz", "Necla", ""]]}, {"id": "1501.04206", "submitter": "Carlos Tenreiro", "authors": "Carlos Tenreiro", "title": "A note on boundary kernels for distribution function estimation", "comments": "15 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of second order boundary kernels for distribution function estimation\nwas recently addressed in the literature (C. Tenreiro, 2013, Boundary kernels\nfor distribution function estimation, REVSTAT-Statistical Journal, 11,\n169-190). In this note we return to the subject by considering an enlarged\nclass of boundary kernels that shows it self to be especially performing when\nthe classical kernel distribution function estimator suffers from severe\nboundary problems.\n", "versions": [{"version": "v1", "created": "Sat, 17 Jan 2015 16:02:04 GMT"}, {"version": "v2", "created": "Wed, 4 Feb 2015 09:11:21 GMT"}], "update_date": "2015-02-05", "authors_parsed": [["Tenreiro", "Carlos", ""]]}, {"id": "1501.04308", "submitter": "Enea Giuseppe Bongiorno", "authors": "Enea Bongiorno and Aldo Goia", "title": "Some Insights About the Small Ball Probability Factorization for Hilbert\n  Random Elements", "comments": "27 pages, 1 figure, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.AP stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Asymptotic factorizations for the small-ball probability (SmBP) of a Hilbert\nvalued random element $X$ are rigorously established and discussed. In\nparticular, given the first $d$ principal components (PCs) and as the radius\n$\\varepsilon$ of the ball tends to zero, the SmBP is asymptotically\nproportional to (a) the joint density of the first $d$ PCs, (b) the volume of\nthe $d$-dimensional ball with radius $\\varepsilon$, and (c) a correction factor\nweighting the use of a truncated version of the process expansion. Moreover,\nunder suitable assumptions on the spectrum of the covariance operator of $X$\nand as $d$ diverges to infinity when $\\varepsilon$ vanishes, some\nsimplifications occur. In particular, the SmBP factorizes asymptotically as the\nproduct of the joint density of the first $d$ PCs and a pure volume parameter.\nAll the provided factorizations allow to define a surrogate intensity of the\nSmBP that, in some cases, leads to a genuine intensity. To operationalize the\nstated results, a non-parametric estimator for the surrogate intensity is\nintroduced and it is proved that the use of estimated PCs, instead of the true\nones, does not affect the rate of convergence. Finally, as an illustration,\nsimulations in controlled frameworks are provided.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jan 2015 14:48:30 GMT"}, {"version": "v2", "created": "Tue, 29 Mar 2016 08:31:19 GMT"}], "update_date": "2016-03-30", "authors_parsed": [["Bongiorno", "Enea", ""], ["Goia", "Aldo", ""]]}, {"id": "1501.04663", "submitter": "Victor Solo", "authors": "Victor Solo", "title": "State Space Methods for Granger-Geweke Causality Measures", "comments": "These results have been presented in a number of invited talks. HBM\n  Conference, Quebec City, June 2011; Dept. Biostat., UNC, Chapel Hill, April\n  2012; Dept. Biostatistics, Emory U, Atlanta, April 2012; Satellite Workshop\n  of HBM Conference, Xian, China, June 2012. Dept Radiology, UC San Francisco,\n  Oct 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  At least two recent developments have put the spotlight on some significant\ngaps in the theory of multivariate time series. The recent interest in the\ndynamics of networks; and the advent, across a range of applications, of\nmeasuring modalities that operate on different temporal scales. Fundamental to\nthe description of network dynamics is the direction of interaction between\nnodes, accompanied by a measure of the strength of such interactions. Granger\ncausality (GC) and its associated frequency domain strength measures (GEMs)\n(due to Geweke) provide a framework for the formulation and analysis of these\nissues. In pursuing this setup, three significant unresolved issues emerge.\nFirstly computing GEMs involves computing submodels of vector time series mod-\nels, for which reliable methods do not exist; Secondly the impact of filtering\non GEMs has never been definitively established. Thirdly the impact of\ndownsampling on GEMs has never been established. In this work, using state\nspace methods, we resolve all these issues and illustrate the results with some\nsimulations. Our discussion is motivated by some problems in (fMRI) brain\nimaging but is of general applicability.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jan 2015 22:51:23 GMT"}], "update_date": "2015-01-21", "authors_parsed": [["Solo", "Victor", ""]]}, {"id": "1501.04712", "submitter": "Andriy Olenko", "authors": "R.M. Espejo, N.N. Leonenko, A. Olenko, M.D. Ruiz-Medina", "title": "On a class of minimum contrast estimators for Gegenbauer random fields", "comments": "23 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The article introduces spatial long-range dependent models based on the\nfractional difference operators associated with the Gegenbauer polynomials. The\nresults on consistency and asymptotic normality of a class of minimum contrast\nestimators of long-range dependence parameters of the models are obtained. A\nmethodology to verify assumptions for consistency and asymptotic normality of\nminimum contrast estimators is developed. Numerical results are presented to\nconfirm the theoretical findings.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jan 2015 04:44:04 GMT"}], "update_date": "2015-01-21", "authors_parsed": [["Espejo", "R. M.", ""], ["Leonenko", "N. N.", ""], ["Olenko", "A.", ""], ["Ruiz-Medina", "M. D.", ""]]}, {"id": "1501.04787", "submitter": "Yohann De Castro", "authors": "Yohann De Castro (LM-Orsay), \\'Elisabeth Gassiat (LM-Orsay), Claire\n  Lacour (LM-Orsay)", "title": "Minimax adaptive estimation of nonparametric hidden Markov models", "comments": "The nonparametric spectral method is independently studied in the\n  arXiv preprint arXiv:1507.06510", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider stationary hidden Markov models with finite state space and\nnonparametric modeling of the emission distributions. It has remained unknown\nuntil very recently that such models are identifiable. In this paper, we\npropose a new penalized least-squares esti-mator for the emission distributions\nwhich is statistically optimal and practically tractable. We prove a non\nasymptotic oracle inequality for our nonparametric estimator of the emission\ndistributions. A consequence is that this new estimator is rate minimax\nadaptive up to a logarithmic term. Our methodology is based on projections of\nthe emission distributions onto nested subspaces of increasing complexity. The\npopular spectral estimators are unable to achieve the optimal rate but may be\nused as initial points in our procedure. Simulations are given that show the\nimprovement obtained when applying the least-squares minimization consecutively\nto the spectral estimation.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jan 2015 12:50:20 GMT"}, {"version": "v2", "created": "Fri, 24 Jul 2015 15:20:39 GMT"}, {"version": "v3", "created": "Sun, 27 Dec 2015 17:29:12 GMT"}], "update_date": "2015-12-29", "authors_parsed": [["De Castro", "Yohann", "", "LM-Orsay"], ["Gassiat", "\u00c9lisabeth", "", "LM-Orsay"], ["Lacour", "Claire", "", "LM-Orsay"]]}, {"id": "1501.04970", "submitter": "Khalifa Es-Sebaiy", "authors": "Khalifa Es-Sebaiy, Frederi G. Viens", "title": "Parameter estimation for SDEs related to stationary Gaussian processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study central and non-central limit theorems for partial\nsum of functionals of general stationary Gaussian fields. We apply our result\nto study drift parameter estimation problems for some stochastic differential\nequations related to stationary Gaussian processes.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jan 2015 21:03:00 GMT"}], "update_date": "2015-01-22", "authors_parsed": [["Es-Sebaiy", "Khalifa", ""], ["Viens", "Frederi G.", ""]]}, {"id": "1501.04972", "submitter": "Khalifa Es-Sebaiy", "authors": "Brahim El Onsy, Khalifa Es-Sebaiy, Frederi G. Viens", "title": "Parameter Estimation for a partially observed Ornstein-Uhlenbeck process\n  with long-memory noise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  \\noindent \\textbf{Abstract}: We consider the parameter estimation problem for\nthe Ornstein-Uhlenbeck process $X$ driven by a fractional Ornstein-Uhlenbeck\nprocess $V$, i.e. the pair of processes defined by the non-Markovian\ncontinuous-time long-memory dynamics $dX_{t}=-\\theta X_{t}dt+dV_{t};\\ t\\geq 0$,\nwith $dV_{t}=-\\rho V_{t}dt+dB_{t}^{H};\\ t\\geq 0$, where $\\theta >0$ and $\\rho\n>0$ are unknown parameters, and $B^{H}$ is a fractional Brownian motion of\nHurst index $H\\in (\\frac{1}{2},1)$. We study the strong consistency as well as\nthe asymptotic normality of the joint least squares estimator\n$(\\hat{\\theta}_{T},\\widehat{\\rho }% _{T}) $ of the pair $( \\theta ,\\rho) $,\nbased either on continuous or discrete observations of $\\{X_{s};\\ s\\in \\lbrack\n0,T]\\}$ as the horizon $T$ increases to +$\\infty $. Both cases qualify formally\nas partial-hbobservation questions since $V$ is unobserved. In the latter case,\nseveral discretization options are considered. Our proofs of asymptotic\nnormality based on discrete data, rely on increasingly strict restrictions on\nthe sampling frequency as one reduces the extent of sources of observation. The\nstrategy for proving the asymptotic properties is to study the case of\ncontinuous-time observations using the Malliavin calculus, and then to exploit\nthe fact that each discrete-data estimator can be considered as a perturbation\nof the continuous one in a mathematically precise way, despite the fact that\nthe implementation of the discrete-time estimators is distant from the\ncontinuous estimator. In this sense, we contend that the continuous-time\nestimator cannot be implemented in practice in any na\\\"ive way, and serves only\nas a mathematical tool in the study of the discrete-time estimators'\nasymptotics.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jan 2015 21:06:43 GMT"}, {"version": "v2", "created": "Wed, 12 Oct 2016 22:26:48 GMT"}], "update_date": "2016-10-14", "authors_parsed": [["Onsy", "Brahim El", ""], ["Es-Sebaiy", "Khalifa", ""], ["Viens", "Frederi G.", ""]]}, {"id": "1501.05071", "submitter": "Kevin Judd", "authors": "Kevin Judd", "title": "Non-probabilistic odds and forecasting with imperfect models", "comments": "30 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probability forecasts are intended to account for the uncertainties inherent\nin forecasting. It is suggested that from an end-user's point of view\nprobability is not necessarily sufficient to reflect uncertainties that are not\nsimply the result of complexity or randomness, for example, probability\nforecasts may not adequately account for uncertainties due to model error. It\nis suggested that an alternative forecast product is to issue non-probabilistic\nodds forecasts, which may be as useful to end-users, and give a less distorted\naccount of the uncertainties of a forecast. Our analysis of odds forecasts\nderives from game theory using the principle that if forecasters truly believe\ntheir forecasts, then they should take bets at the odds they offer and not\nexpect to be bankrupted. Despite this game theoretic approach, it is not a\nmarket or economic evaluation; it is intended to be a scientific evaluation.\nIllustrative examples are given of the calculation of odds forecasts and their\napplication to investment, loss mitigation and ensemble weather forecasting.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jan 2015 06:48:26 GMT"}], "update_date": "2015-01-22", "authors_parsed": [["Judd", "Kevin", ""]]}, {"id": "1501.05242", "submitter": "Bertrand Iooss", "authors": "Micha\\\"el Baudin, Anne Dutfoy (EDF R&D), Bertrand Iooss (M\\'ethodes\n  d'Analyse Stochastique des Codes et Traitements Num\\'eriques), Anne-Laure\n  Popelin", "title": "Open TURNS: An industrial software for uncertainty quantification in\n  simulation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The needs to assess robust performances for complex systems and to answer\ntighter regulatory processes (security, safety, environmental control, and\nhealth impacts, etc.) have led to the emergence of a new industrial simulation\nchallenge: to take uncertainties into account when dealing with complex\nnumerical simulation frameworks. Therefore, a generic methodology has emerged\nfrom the joint effort of several industrial companies and academic\ninstitutions. EDF R&D, Airbus Group and Phimeca Engineering started a\ncollaboration at the beginning of 2005, joined by IMACS in 2014, for the\ndevelopment of an Open Source software platform dedicated to uncertainty\npropagation by probabilistic methods, named OpenTURNS for Open source Treatment\nof Uncertainty, Risk 'N Statistics. OpenTURNS addresses the specific industrial\nchallenges attached to uncertainties, which are transparency, genericity,\nmodularity and multi-accessibility. This paper focuses on OpenTURNS and\npresents its main features: openTURNS is an open source software under the LGPL\nlicense, that presents itself as a C++ library and a Python TUI, and which\nworks under Linux and Windows environment. All the methodological tools are\ndescribed in the different sections of this paper: uncertainty quantification,\nuncertainty propagation, sensitivity analysis and metamodeling. A section also\nexplains the generic wrappers way to link openTURNS to any external code. The\npaper illustrates as much as possible the methodological tools on an\neducational example that simulates the height of a river and compares it to the\nheight of a dyke that protects industrial facilities. At last, it gives an\noverview of the main developments planned for the next few years.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jan 2015 17:38:33 GMT"}, {"version": "v2", "created": "Fri, 5 Jun 2015 08:28:36 GMT"}], "update_date": "2015-06-08", "authors_parsed": [["Baudin", "Micha\u00ebl", "", "EDF R&D"], ["Dutfoy", "Anne", "", "EDF R&D"], ["Iooss", "Bertrand", "", "M\u00e9thodes\n  d'Analyse Stochastique des Codes et Traitements Num\u00e9riques"], ["Popelin", "Anne-Laure", ""]]}, {"id": "1501.05467", "submitter": "James A. Duffy", "authors": "James A. Duffy", "title": "A uniform law for convergence to the local times of linear fractional\n  stable motions", "comments": "Published at http://dx.doi.org/10.1214/14-AAP1085 in the Annals of\n  Applied Probability (http://www.imstat.org/aap/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Probability 2016, Vol. 26, No. 1, 45-72", "doi": "10.1214/14-AAP1085", "report-no": "IMS-AAP-AAP1085", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a uniform law for the weak convergence of additive functionals of\npartial sum processes to the local times of linear fractional stable motions,\nin a setting sufficiently general for statistical applications. Our results are\nfundamental to the analysis of the global properties of nonparametric\nestimators of nonlinear statistical models that involve such processes as\ncovariates.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jan 2015 11:44:37 GMT"}, {"version": "v2", "created": "Mon, 1 Feb 2016 13:38:48 GMT"}], "update_date": "2016-02-02", "authors_parsed": [["Duffy", "James A.", ""]]}, {"id": "1501.05471", "submitter": "Farkhondeh Sajadi Dr.", "authors": "Ali Rejali and Farkhondeh Sajadi", "title": "Asymptotic Normality of the Chromatic Number of a Random Graph", "comments": "This paper has been withdrawn by the author due to some error in the\n  proof of theorem", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we prove that the limiting distribution of the Chromatic number\nof a random graph $\\mathcal{G}_{n,p}$, with fixed edge-probability $p$, after\nappropriate centering and scaling is Normal, when the number of vertices $n$,\ngoes to infinity.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jan 2015 12:04:29 GMT"}, {"version": "v2", "created": "Mon, 10 Aug 2015 08:20:42 GMT"}], "update_date": "2015-08-11", "authors_parsed": [["Rejali", "Ali", ""], ["Sajadi", "Farkhondeh", ""]]}, {"id": "1501.05836", "submitter": "Luiz Baccal\\'a", "authors": "Luiz A. Baccal\\'a, Daniel Y. Takahashi, Koichi Sameshima", "title": "Consolidating a Link Centered Neural Connectivity Framework with\n  Directed Transfer Function Asymptotics", "comments": "12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a unified mathematical derivation of the asymptotic behaviour of\nthree of the main forms of \\textit{directed transfer function} (DTF)\ncomplementing recent partial directed coherence (PDC) results\n\\cite{Baccala2013}. Based on these results and numerical examples we argue for\na new directed `link' centered neural connectivity framework to replace the\nwidespread correlation based effective/functional network concepts so that\ndirected network influences between structures become classified as to whether\nlinks are \\textit{active} in a \\textit{direct} or in an \\textit{indirect} way\nthereby leading to the new notions of \\textit{Granger connectivity} and\n\\textit{Granger influenciability} which are more descriptive than speaking of\nGranger causality alone.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jan 2015 15:39:55 GMT"}], "update_date": "2015-01-26", "authors_parsed": [["Baccal\u00e1", "Luiz A.", ""], ["Takahashi", "Daniel Y.", ""], ["Sameshima", "Koichi", ""]]}, {"id": "1501.05870", "submitter": "Michael Fauss", "authors": "Michael Fauss and Abdelhak M. Zoubir", "title": "A Linear Programming Approach to Sequential Hypothesis Testing", "comments": "25 pages, 4 figures, accepted for publication in Sequential Analysis", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Under some mild Markov assumptions it is shown that the problem of designing\noptimal sequential tests for two simple hypotheses can be formulated as a\nlinear program. The result is derived by investigating the Lagrangian dual of\nthe sequential testing problem, which is an unconstrained optimal stopping\nproblem, depending on two unknown Lagrangian multipliers. It is shown that the\nderivative of the optimal cost function with respect to these multipliers\ncoincides with the error probabilities of the corresponding sequential test.\nThis property is used to formulate an optimization problem that is jointly\nlinear in the cost function and the Lagrangian multipliers and an be solved for\nboth with off-the-shelf algorithms. To illustrate the procedure, optimal\nsequential tests for Gaussian random sequences with different dependency\nstructures are derived, including the Gaussian AR(1) process.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jan 2015 16:53:33 GMT"}, {"version": "v2", "created": "Mon, 23 Feb 2015 16:41:09 GMT"}], "update_date": "2015-02-24", "authors_parsed": [["Fauss", "Michael", ""], ["Zoubir", "Abdelhak M.", ""]]}, {"id": "1501.06094", "submitter": "Gustavo Didier", "authors": "Patrice Abry and Gustavo Didier", "title": "Wavelet estimation for operator fractional Brownian motion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Operator fractional Brownian motion (OFBM) is the natural vector-valued\nextension of the univariate fractional Brownian motion. Instead of a scalar\nparameter, the law of an OFBM scales according to a Hurst matrix that affects\nevery component of the process. In this paper, we develop the wavelet analysis\nof OFBM, as well as a new estimator for the Hurst matrix of bivariate OFBM. For\nOFBM, the univariate-inspired approach of analyzing the entry-wise behavior of\nthe wavelet spectrum as a function of the (wavelet) scales is fraught with\ndifficulties stemming from mixtures of power laws. The proposed approach\nconsists of considering the evolution along scales of the eigenstructure of the\nwavelet spectrum. This is shown to yield consistent and asymptotically normal\nestimators of the Hurst eigenvalues, and also of the coordinate system itself\nunder assumptions. A simulation study is included to demonstrate the good\nperformance of the estimators under finite sample sizes.\n", "versions": [{"version": "v1", "created": "Sat, 24 Jan 2015 23:26:10 GMT"}, {"version": "v2", "created": "Tue, 15 Sep 2015 23:29:21 GMT"}], "update_date": "2015-09-17", "authors_parsed": [["Abry", "Patrice", ""], ["Didier", "Gustavo", ""]]}, {"id": "1501.06202", "submitter": "Yanwei  Fu", "authors": "Yanwei Fu, Timothy M. Hospedales, Tao Xiang, Jiechao Xiong, Shaogang\n  Gong, Yizhou Wang, and Yuan Yao", "title": "Robust Subjective Visual Property Prediction from Crowdsourced Pairwise\n  Labels", "comments": "14 pages, accepted by IEEE TPAMI", "journal-ref": null, "doi": "10.1109/TPAMI.2015.2456887", "report-no": null, "categories": "cs.CV cs.LG cs.MM cs.SI math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of estimating subjective visual properties from image and video\nhas attracted increasing interest. A subjective visual property is useful\neither on its own (e.g. image and video interestingness) or as an intermediate\nrepresentation for visual recognition (e.g. a relative attribute). Due to its\nambiguous nature, annotating the value of a subjective visual property for\nlearning a prediction model is challenging. To make the annotation more\nreliable, recent studies employ crowdsourcing tools to collect pairwise\ncomparison labels because human annotators are much better at ranking two\nimages/videos (e.g. which one is more interesting) than giving an absolute\nvalue to each of them separately. However, using crowdsourced data also\nintroduces outliers. Existing methods rely on majority voting to prune the\nannotation outliers/errors. They thus require large amount of pairwise labels\nto be collected. More importantly as a local outlier detection method, majority\nvoting is ineffective in identifying outliers that can cause global ranking\ninconsistencies. In this paper, we propose a more principled way to identify\nannotation outliers by formulating the subjective visual property prediction\ntask as a unified robust learning to rank problem, tackling both the outlier\ndetection and learning to rank jointly. Differing from existing methods, the\nproposed method integrates local pairwise comparison labels together to\nminimise a cost that corresponds to global inconsistency of ranking order. This\nnot only leads to better detection of annotation outliers but also enables\nlearning with extremely sparse annotations. Extensive experiments on various\nbenchmark datasets demonstrate that our new approach significantly outperforms\nstate-of-the-arts alternatives.\n", "versions": [{"version": "v1", "created": "Sun, 25 Jan 2015 20:02:45 GMT"}, {"version": "v2", "created": "Fri, 30 Jan 2015 05:13:45 GMT"}, {"version": "v3", "created": "Fri, 24 Jul 2015 18:40:56 GMT"}, {"version": "v4", "created": "Mon, 27 Jul 2015 14:42:17 GMT"}], "update_date": "2015-07-28", "authors_parsed": [["Fu", "Yanwei", ""], ["Hospedales", "Timothy M.", ""], ["Xiang", "Tao", ""], ["Xiong", "Jiechao", ""], ["Gong", "Shaogang", ""], ["Wang", "Yizhou", ""], ["Yao", "Yuan", ""]]}, {"id": "1501.06241", "submitter": "Yao Xie", "authors": "Ruiyang Song, Yao Xie, Sebastian Pokutta", "title": "Sequential Sensing with Model Mismatch", "comments": "Submitted to IEEE for publication", "journal-ref": null, "doi": "10.1109/ISIT.2015.7282736", "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We characterize the performance of sequential information guided sensing,\nInfo-Greedy Sensing, when there is a mismatch between the true signal model and\nthe assumed model, which may be a sample estimate. In particular, we consider a\nsetup where the signal is low-rank Gaussian and the measurements are taken in\nthe directions of eigenvectors of the covariance matrix in a decreasing order\nof eigenvalues. We establish a set of performance bounds when a mismatched\ncovariance matrix is used, in terms of the gap of signal posterior entropy, as\nwell as the additional amount of power required to achieve the same signal\nrecovery precision. Based on this, we further study how to choose an\ninitialization for Info-Greedy Sensing using the sample covariance matrix, or\nusing an efficient covariance sketching scheme.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jan 2015 02:51:13 GMT"}, {"version": "v2", "created": "Mon, 16 Mar 2015 22:38:33 GMT"}], "update_date": "2016-11-18", "authors_parsed": [["Song", "Ruiyang", ""], ["Xie", "Yao", ""], ["Pokutta", "Sebastian", ""]]}, {"id": "1501.06260", "submitter": "Yuzo Maruyama", "authors": "Yuzo Maruyama", "title": "An alternative to Moran's I for spatial autocorrelation", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Moran's I statistic, a popular measure of spatial autocorrelation, is\nrevisited. The exact range of Moran's I is given as a function of spatial\nweights matrix. We demonstrate that some spatial weights matrices lead the\nabsolute value of upper (lower) bound larger than 1 and that others lead the\nlower bound larger than -0.5. Thus Moran's I is unlike Pearson's correlation\ncoefficient. It is also pointed out that some spatial weights matrices do not\nallow Moran's I to take positive values regardless of observations. An\nalternative measure with exact range [-1,1] is proposed through a monotone\ntransformation of Moran's I.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jan 2015 06:02:13 GMT"}], "update_date": "2015-01-27", "authors_parsed": [["Maruyama", "Yuzo", ""]]}, {"id": "1501.06299", "submitter": "Subrata Chakraborty", "authors": "Subrata Chakraborty and Dhrubajyoti Chakravarty", "title": "A Discrete Power Distribution", "comments": "14 pages, 8 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new discrete distribution has been proposed as a discrete analogue of the\ntwo sided power distribution [Van Drop, J. R. and Kotz, S. (2002a). A novel\nextension of the triangular distribution and its parameter estimation, Journal\nof the Royal Statistical Society, Series D (The Statistician), 51, 1: 63-79].\nThis probability mass function and hazard rate function of this distribution\ncan assume a variety of shapes including bath tub, rectangular, trapezoidal,\ntriangular, J, inverse J, U inverse U, strictly decreasing and strictly\nincreasing shapes. Its moment and reliability properties along with parameter\nestimation have been investigated.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jan 2015 09:47:09 GMT"}], "update_date": "2015-01-27", "authors_parsed": [["Chakraborty", "Subrata", ""], ["Chakravarty", "Dhrubajyoti", ""]]}, {"id": "1501.06502", "submitter": "Lionel Barnett", "authors": "Lionel Barnett and Anil K. Seth", "title": "Granger causality for state space models", "comments": "13 pages, 4 figures", "journal-ref": "Phys. Rev. E 91, 040101 (2015)", "doi": "10.1103/PhysRevE.91.040101", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Granger causality, a popular method for determining causal influence between\nstochastic processes, is most commonly estimated via linear autoregressive\nmodeling. However, this approach has a serious drawback: if the process being\nmodeled has a moving average component, then the autoregressive model order is\ntheoretically infinite, and in finite sample large empirical model orders may\nbe necessary, resulting in weak Granger-causal inference. This is particularly\nrelevant when the process has been filtered, downsampled, or observed with\n(additive) noise - all of which induce a moving average component and are\ncommonplace in application domains as diverse as econometrics and the\nneurosciences. By contrast, the class of autoregressive moving average models -\nor, equivalently, linear state space models - is closed under digital\nfiltering, downsampling (and other forms of aggregation) as well as additive\nobservational noise. Here, we show how Granger causality, conditional and\nunconditional, in both time and frequency domains, may be calculated simply and\ndirectly from state space model parameters, via solution of a discrete\nalgebraic Riccati equation. Numerical simulations demonstrate that Granger\ncausality estimators thus derived have greater statistical power and smaller\nbias than pure autoregressive estimators. We conclude that the state space\napproach should be the default for (linear) Granger causality estimation.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jan 2015 18:02:49 GMT"}, {"version": "v2", "created": "Thu, 5 Feb 2015 16:25:51 GMT"}], "update_date": "2016-06-29", "authors_parsed": [["Barnett", "Lionel", ""], ["Seth", "Anil K.", ""]]}, {"id": "1501.06783", "submitter": "Cl\\'ement Canonne", "authors": "Cl\\'ement L. Canonne", "title": "Big Data on the Rise: Testing monotonicity of distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The field of property testing of probability distributions, or distribution\ntesting, aims to provide fast and (most likely) correct answers to questions\npertaining to specific aspects of very large datasets. In this work, we\nconsider a property of particular interest, monotonicity of distributions. We\nfocus on the complexity of monotonicity testing across different models of\naccess to the distributions; and obtain results in these new settings that\ndiffer significantly from the known bounds in the standard sampling model.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jan 2015 15:02:35 GMT"}, {"version": "v2", "created": "Thu, 23 Apr 2015 20:58:39 GMT"}], "update_date": "2015-04-27", "authors_parsed": [["Canonne", "Cl\u00e9ment L.", ""]]}, {"id": "1501.06930", "submitter": "Herv\\'e Cardot", "authors": "Herv\\'e Cardot, Peggy C\\'enac and Antoine Godichon", "title": "Online estimation of the geometric median in Hilbert spaces : non\n  asymptotic confidence balls", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimation procedures based on recursive algorithms are interesting and\npowerful techniques that are able to deal rapidly with (very) large samples of\nhigh dimensional data. The collected data may be contaminated by noise so that\nrobust location indicators, such as the geometric median, may be preferred to\nthe mean. In this context, an estimator of the geometric median based on a fast\nand efficient averaged non linear stochastic gradient algorithm has been\ndeveloped by Cardot, C\\'enac and Zitt (2013). This work aims at studying more\nprecisely the non asymptotic behavior of this algorithm by giving non\nasymptotic confidence balls. This new result is based on the derivation of\nimproved $L^2$ rates of convergence as well as an exponential inequality for\nthe martingale terms of the recursive non linear Robbins-Monro algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jan 2015 21:27:07 GMT"}], "update_date": "2015-01-29", "authors_parsed": [["Cardot", "Herv\u00e9", ""], ["C\u00e9nac", "Peggy", ""], ["Godichon", "Antoine", ""]]}, {"id": "1501.06943", "submitter": "Robin Pemantle", "authors": "Ville Satop\\\"a\\\"a and Robin Pemantle and Lyle Ungar", "title": "Combining Probability Forecasts and Understanding Probability\n  Extremizing through Information Diversity", "comments": "This paper has been withdrawn because it was meant to be a revision\n  to arXiv:1406.2148, not an independent submission. This was discovered on 27\n  May, 2015, when preparing a replacement version to arXiv:1406.2148. This\n  replacement will supersede both that version and the one withdrawn here", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Randomness in scientific estimation is generally assumed to arise from\nunmeasured or uncontrolled factors. However, when combining subjective\nprobability estimates, heterogeneity stemming from people's cognitive or\ninformation diversity is often more important than measurement noise. This\npaper presents a novel framework that uses partially overlapping information\nsources. A specific model is proposed within that framework and applied to the\ntask of aggregating the probabilities given by a group of forecasters who\npredict whether an event will occur or not. Our model describes the\ndistribution of information across forecasters in terms of easily interpretable\nparameters and shows how the optimal amount of extremizing of the average\nprobability forecast (shifting it closer to its nearest extreme) varies as a\nfunction of the forecasters' information overlap. Our model thus gives a more\nprincipled understanding of the historically ad hoc practice of extremizing\naverage forecasts.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jan 2015 21:55:03 GMT"}, {"version": "v2", "created": "Wed, 27 May 2015 18:19:21 GMT"}], "update_date": "2015-05-28", "authors_parsed": [["Satop\u00e4\u00e4", "Ville", ""], ["Pemantle", "Robin", ""], ["Ungar", "Lyle", ""]]}, {"id": "1501.07091", "submitter": "Hilmar Mai", "authors": "Christian Bayer, Hilmar Mai, John Schoenmakers", "title": "Forward-reverse EM algorithm for Markov chains: convergence and\n  numerical analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.NA stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a forward-reverse EM (FREM) algorithm for estimating parameters\nthat determine the dynamics of a discrete time Markov chain evolving through a\ncertain measurable state space. As a key tool for the construction of the FREM\nmethod we develop forward-reverse representations for Markov chains conditioned\non a certain terminal state. These representations may be considered as an\nextension of the earlier work Bayer and Schoenmakers [2013] on conditional\ndiffusions. We proof almost sure convergence of our algorithm for a Markov\nchain model with curved exponential family structure. On the numerical side we\ngive a complexity analysis of the forward-reverse algorithm by deriving its\nexpected cost. Two application examples are discuss to demonstrate the scope of\npossible applications ranging from models based on continuous time processes to\ndiscrete time Markov chain models.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jan 2015 13:01:37 GMT"}], "update_date": "2015-01-29", "authors_parsed": [["Bayer", "Christian", ""], ["Mai", "Hilmar", ""], ["Schoenmakers", "John", ""]]}, {"id": "1501.07440", "submitter": "Jonathan Scarlett", "authors": "Jonathan Scarlett and Volkan Cevher", "title": "Limits on Support Recovery with Probabilistic Models: An\n  Information-Theoretic Framework", "comments": "Accepted to IEEE Transactions on Information Theory; presented in\n  part at ISIT 2015 and SODA 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The support recovery problem consists of determining a sparse subset of a set\nof variables that is relevant in generating a set of observations, and arises\nin a diverse range of settings such as compressive sensing, and subset\nselection in regression, and group testing. In this paper, we take a unified\napproach to support recovery problems, considering general probabilistic models\nrelating a sparse data vector to an observation vector. We study the\ninformation-theoretic limits of both exact and partial support recovery, taking\na novel approach motivated by thresholding techniques in channel coding. We\nprovide general achievability and converse bounds characterizing the trade-off\nbetween the error probability and number of measurements, and we specialize\nthese to the linear, 1-bit, and group testing models. In several cases, our\nbounds not only provide matching scaling laws in the necessary and sufficient\nnumber of measurements, but also sharp thresholds with matching constant\nfactors. Our approach has several advantages over previous approaches: For the\nachievability part, we obtain sharp thresholds under broader scalings of the\nsparsity level and other parameters (e.g., signal-to-noise ratio) compared to\nseveral previous works, and for the converse part, we not only provide\nconditions under which the error probability fails to vanish, but also\nconditions under which it tends to one.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jan 2015 13:04:11 GMT"}, {"version": "v2", "created": "Wed, 11 Feb 2015 15:59:31 GMT"}, {"version": "v3", "created": "Tue, 30 Aug 2016 10:47:09 GMT"}], "update_date": "2016-08-31", "authors_parsed": [["Scarlett", "Jonathan", ""], ["Cevher", "Volkan", ""]]}, {"id": "1501.07761", "submitter": "Hui Guo", "authors": "Hui Guo, Philip Dawid and Giovanni Berzuini", "title": "Sufficient Covariate, Propensity Variable and Doubly Robust Estimation", "comments": null, "journal-ref": "In Statistical Causal Inferences and Their Applications in Public\n  Health Research, edited by Hua He, Pan Wu and Ding-Geng Chen. Springer\n  (2016), 49-89", "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical causal inference from observational studies often requires\nadjustment for a possibly multi-dimensional variable, where dimension reduction\nis crucial. The propensity score, first introduced by Rosenbaum and Rubin, is a\npopular approach to such reduction. We address causal inference within Dawid's\ndecision-theoretic framework, where it is essential to pay attention to\nsufficient covariates and their properties. We examine the role of a propensity\nvariable in a normal linear model. We investigate both population-based and\nsample-based linear regressions, with adjustments for a multivariate covariate\nand for a propensity variable. In addition, we study the augmented inverse\nprobability weighted estimator, involving a combination of a response model and\na propensity model. In a linear regression with homoscedasticity, a propensity\nvariable is proved to provide the same estimated causal effect as multivariate\nadjustment. An estimated propensity variable may, but need not, yield better\nprecision than the true propensity variable. The augmented inverse probability\nweighted estimator is doubly robust and can improve precision if the propensity\nmodel is correctly specified.\n", "versions": [{"version": "v1", "created": "Fri, 30 Jan 2015 13:11:09 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Guo", "Hui", ""], ["Dawid", "Philip", ""], ["Berzuini", "Giovanni", ""]]}, {"id": "1501.07858", "submitter": "Alexander Schnurr", "authors": "Alexander Schnurr and Herold Dehling", "title": "Testing for Structural Breaks via Ordinal Pattern Dependence", "comments": "32 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose new concepts in order to analyze and model the dependence\nstructure between two time series. Our methods rely exclusively on the order\nstructure of the data points. Hence, the methods are stable under monotone\ntransformations of the time series and robust against small perturbations or\nmeasurement errors. Ordinal pattern dependence can be characterized by four\nparameters. We propose estimators for these parameters, and we calculate their\nasymptotic distributions. Furthermore, we derive a test for structural breaks\nwithin the dependence structure. All results are supplemented by simulation\nstudies and empirical examples.\n  For three consecutive data points attaining different values, there are six\npossibilities how their values can be ordered. These possibilities are called\nordinal patterns. Our first idea is simply to count the number of coincidences\nof patterns in both time series, and to compare this with the expected number\nin the case of independence. If we detect a lot of coincident patterns, this\nmeans that the up-and-down behavior is similar. Hence, our concept can be seen\nas a way to measure non-linear `correlation'. We show in the last section, how\nto generalize the concept in order to capture various other kinds of\ndependence.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jan 2015 14:48:28 GMT"}], "update_date": "2015-02-02", "authors_parsed": [["Schnurr", "Alexander", ""], ["Dehling", "Herold", ""]]}]