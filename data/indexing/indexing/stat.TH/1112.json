[{"id": "1112.0100", "submitter": "Nikolai Dokuchaev", "authors": "Nikolai Dokuchaev", "title": "On predictors for band-limited and high-frequency time series", "comments": "10 pages. arXiv admin note: text overlap with arXiv:0708.0347", "journal-ref": "Signal Processing 92, iss. 10, pp. 2571-2575 (2012)", "doi": "10.1016/j.sigpro.2012.04.006", "report-no": null, "categories": "math.OC math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pathwise predictability and predictors for discrete time processes are\nstudied in deterministic setting. It is suggested to approximate convolution\nsums over future times by convolution sums over past time. It is shown that all\nband-limited processes are predictable in this sense, as well as high-frequency\nprocesses with zero energy at low frequencies. In addition, a process of mixed\ntype still can be predicted if an ideal low-pass filter exists for this\nprocess.\n", "versions": [{"version": "v1", "created": "Thu, 1 Dec 2011 08:01:28 GMT"}, {"version": "v2", "created": "Thu, 15 Mar 2012 03:01:05 GMT"}, {"version": "v3", "created": "Thu, 3 May 2012 02:18:41 GMT"}], "update_date": "2012-05-04", "authors_parsed": [["Dokuchaev", "Nikolai", ""]]}, {"id": "1112.0311", "submitter": "Arian Maleki", "authors": "Arian Maleki, Manjari Narayan, Richard G. Baraniuk", "title": "Anisotropic Nonlocal Means Denoising", "comments": "Accepted for publication in Applied and Computational Harmonic\n  Analysis (ACHA)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT math.IT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has recently been proved that the popular nonlocal means (NLM) denoising\nalgorithm does not optimally denoise images with sharp edges. Its weakness lies\nin the isotropic nature of the neighborhoods it uses to set its smoothing\nweights. In response, in this paper we introduce several theoretical and\npractical anisotropic nonlocal means (ANLM) algorithms and prove that they are\nnear minimax optimal for edge-dominated images from the Horizon class. On\nreal-world test images, an ANLM algorithm that adapts to the underlying image\ngradients outperforms NLM by a significant margin.\n", "versions": [{"version": "v1", "created": "Wed, 30 Nov 2011 23:37:49 GMT"}, {"version": "v2", "created": "Sat, 1 Dec 2012 02:56:04 GMT"}], "update_date": "2012-12-04", "authors_parsed": [["Maleki", "Arian", ""], ["Narayan", "Manjari", ""], ["Baraniuk", "Richard G.", ""]]}, {"id": "1112.0391", "submitter": "Nam Nguyen Hoai", "authors": "Nam H. Nguyen and Trac D. Tran", "title": "Robust Lasso with missing and grossly corrupted observations", "comments": "19 pages, 3 figures. Partial of this work is presented at NIPS 2011\n  conference in Granda, Spain, December 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT math.IT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the problem of accurately recovering a sparse vector\n$\\beta^{\\star}$ from highly corrupted linear measurements $y = X \\beta^{\\star}\n+ e^{\\star} + w$ where $e^{\\star}$ is a sparse error vector whose nonzero\nentries may be unbounded and $w$ is a bounded noise. We propose a so-called\nextended Lasso optimization which takes into consideration sparse prior\ninformation of both $\\beta^{\\star}$ and $e^{\\star}$. Our first result shows\nthat the extended Lasso can faithfully recover both the regression as well as\nthe corruption vector. Our analysis relies on the notion of extended restricted\neigenvalue for the design matrix $X$. Our second set of results applies to a\ngeneral class of Gaussian design matrix $X$ with i.i.d rows $\\oper N(0,\n\\Sigma)$, for which we can establish a surprising result: the extended Lasso\ncan recover exact signed supports of both $\\beta^{\\star}$ and $e^{\\star}$ from\nonly $\\Omega(k \\log p \\log n)$ observations, even when the fraction of\ncorruption is arbitrarily close to one. Our analysis also shows that this\namount of observations required to achieve exact signed support is indeed\noptimal.\n", "versions": [{"version": "v1", "created": "Fri, 2 Dec 2011 05:51:23 GMT"}, {"version": "v2", "created": "Tue, 6 Dec 2011 05:45:04 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Nguyen", "Nam H.", ""], ["Tran", "Trac D.", ""]]}, {"id": "1112.0504", "submitter": "Kalyani Krishnamurthy", "authors": "Kalyani Krishnamurthy, Rebecca Willett and Maxim Raginsky", "title": "Target Detection Performance Bounds in Compressive Imaging", "comments": "Submitted to the EURASIP Journal on Advances in Signal Processing", "journal-ref": null, "doi": "10.1186/1687-6180-2012-205", "report-no": null, "categories": "math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes computationally efficient approaches and associated\ntheoretical performance guarantees for the detection of known targets and\nanomalies from few projection measurements of the underlying signals. The\nproposed approaches accommodate signals of different strengths contaminated by\na colored Gaussian background, and perform detection without reconstructing the\nunderlying signals from the observations. The theoretical performance bounds of\nthe target detector highlight fundamental tradeoffs among the number of\nmeasurements collected, amount of background signal present, signal-to-noise\nratio, and similarity among potential targets coming from a known dictionary.\nThe anomaly detector is designed to control the number of false discoveries.\nThe proposed approach does not depend on a known sparse representation of\ntargets; rather, the theoretical performance bounds exploit the structure of a\nknown dictionary of targets and the distance preservation property of the\nmeasurement matrix. Simulation experiments illustrate the practicality and\neffectiveness of the proposed approaches.\n", "versions": [{"version": "v1", "created": "Fri, 2 Dec 2011 16:54:40 GMT"}, {"version": "v2", "created": "Tue, 14 Aug 2012 16:28:52 GMT"}], "update_date": "2015-06-03", "authors_parsed": [["Krishnamurthy", "Kalyani", ""], ["Willett", "Rebecca", ""], ["Raginsky", "Maxim", ""]]}, {"id": "1112.0528", "submitter": "Nikolai Sinitsyn", "authors": "Vladimir Y. Chernyak, John R. Klein, Nikolai A. Sinitsyn", "title": "Quantization and Fractional Quantization of Currents in Periodically\n  Driven Stochastic Systems II: Full Counting Statistics", "comments": "18 pages, 5 figures", "journal-ref": "J. Chem. Phys. 136, 154108 (2012)", "doi": "10.1063/1.3703329", "report-no": null, "categories": "cond-mat.mes-hall cond-mat.stat-mech math.AT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study Markovian stochastic motion on a graph with finite number of nodes\nand adiabatically periodically driven transition rates. We show that, under\ngeneral conditions, the quantized currents that appear at low temperatures are\na manifestation of topological invariants in the counting statistics of\ncurrents. This observation provides an approach for classification of\ntopological properties of the counting statistics, as well as for extensions of\nthe phenomenon of the robust quantization of currents at low temperatures to\nthe properties of the counting statistics which persist to finite temperatures.\n", "versions": [{"version": "v1", "created": "Fri, 2 Dec 2011 18:09:44 GMT"}, {"version": "v2", "created": "Thu, 22 Mar 2012 23:09:56 GMT"}], "update_date": "2015-06-03", "authors_parsed": [["Chernyak", "Vladimir Y.", ""], ["Klein", "John R.", ""], ["Sinitsyn", "Nikolai A.", ""]]}, {"id": "1112.0529", "submitter": "Nikolai Sinitsyn", "authors": "Vladimir Y. Chernyak, John R. Klein, Nikolai A. Sinitsyn", "title": "Quantization and Fractional Quantization of Currents in Periodically\n  Driven Stochastic Systems I: Average Currents", "comments": "22 pages, 7 figures", "journal-ref": "J. Chem. Phys. 136, 154107 (2012)", "doi": "10.1063/1.3703328", "report-no": null, "categories": "cond-mat.mes-hall cond-mat.soft math.AT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article studies Markovian stochastic motion of a particle on a graph\nwith finite number of nodes and periodically time-dependent transition rates\nthat satisfy the detailed balance condition at any time. We show that under\ngeneral conditions, the currents in the system on average become quantized or\nfractionally quantized for adiabatic driving at sufficiently low temperature.\nWe develop the quantitative theory of this quantization and interpret it in\nterms of topological invariants. By implementing the celebrated Kirchhoff\ntheorem we derive a general and explicit formula for the average generated\ncurrent that plays a role of an efficient tool for treating the current\nquantization effects.\n", "versions": [{"version": "v1", "created": "Fri, 2 Dec 2011 18:10:34 GMT"}, {"version": "v2", "created": "Thu, 22 Mar 2012 23:08:06 GMT"}], "update_date": "2015-06-03", "authors_parsed": [["Chernyak", "Vladimir Y.", ""], ["Klein", "John R.", ""], ["Sinitsyn", "Nikolai A.", ""]]}, {"id": "1112.0669", "submitter": "Ronen Eldan", "authors": "Ronen Eldan", "title": "An efficiency upper bound for inverse covariance estimation", "comments": "7 Pages", "journal-ref": null, "doi": "10.1007/s11856-015-1169-5", "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive an upper bound for the efficiency of estimating entries in the\ninverse covariance matrix of a high dimensional distribution. We show that in\norder to approximate an off-diagonal entry of the density matrix of a\n$d$-dimensional Gaussian random vector, one needs at least a number of samples\nproportional to $d$. Furthermore, we show that with $n \\ll d$ samples, the\nhypothesis that two given coordinates are fully correlated, when all other\ncoordinates are conditioned to be zero, cannot be told apart from the\nhypothesis that the two are uncorrelated.\n", "versions": [{"version": "v1", "created": "Sat, 3 Dec 2011 15:55:14 GMT"}, {"version": "v2", "created": "Fri, 25 Jan 2013 10:42:31 GMT"}, {"version": "v3", "created": "Mon, 11 Feb 2013 19:19:37 GMT"}], "update_date": "2015-05-06", "authors_parsed": [["Eldan", "Ronen", ""]]}, {"id": "1112.0708", "submitter": "Adel Javanmard", "authors": "David L. Donoho, Adel Javanmard and Andrea Montanari", "title": "Information-Theoretically Optimal Compressed Sensing via Spatial\n  Coupling and Approximate Message Passing", "comments": "60 pages, 7 figures, Sections 3,5 and Appendices A,B are added. The\n  stability constant is quantified (cf Theorem 1.7)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cond-mat.stat-mech math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the compressed sensing reconstruction problem for a broad class of\nrandom, band-diagonal sensing matrices. This construction is inspired by the\nidea of spatial coupling in coding theory. As demonstrated heuristically and\nnumerically by Krzakala et al. \\cite{KrzakalaEtAl}, message passing algorithms\ncan effectively solve the reconstruction problem for spatially coupled\nmeasurements with undersampling rates close to the fraction of non-zero\ncoordinates.\n  We use an approximate message passing (AMP) algorithm and analyze it through\nthe state evolution method. We give a rigorous proof that this approach is\nsuccessful as soon as the undersampling rate $\\delta$ exceeds the (upper)\nR\\'enyi information dimension of the signal, $\\uRenyi(p_X)$. More precisely,\nfor a sequence of signals of diverging dimension $n$ whose empirical\ndistribution converges to $p_X$, reconstruction is with high probability\nsuccessful from $\\uRenyi(p_X)\\, n+o(n)$ measurements taken according to a band\ndiagonal matrix.\n  For sparse signals, i.e., sequences of dimension $n$ and $k(n)$ non-zero\nentries, this implies reconstruction from $k(n)+o(n)$ measurements. For\n`discrete' signals, i.e., signals whose coordinates take a fixed finite set of\nvalues, this implies reconstruction from $o(n)$ measurements. The result is\nrobust with respect to noise, does not apply uniquely to random signals, but\nrequires the knowledge of the empirical distribution of the signal $p_X$.\n", "versions": [{"version": "v1", "created": "Sun, 4 Dec 2011 01:27:08 GMT"}, {"version": "v2", "created": "Sat, 19 Jan 2013 01:13:21 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Donoho", "David L.", ""], ["Javanmard", "Adel", ""], ["Montanari", "Andrea", ""]]}, {"id": "1112.0712", "submitter": "Lixing Zhu", "authors": "Lu Lin, Lixing Zhu and Yujie Gai", "title": "Estimation and inference for high-dimensional non-sparse models", "comments": "This is a substantial revision of the manuscript Adaptive\n  post-Dantzig estimation and prediction for non-sparse \"large $p$ and small\n  $n$\" models [arXiv:1008.1345]", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To successfully work on variable selection, sparse model structure has become\na basic assumption for all existing methods. However, this assumption is\nquestionable as it is hard to hold in most of cases and none of existing\nmethods may provide consistent estimation and accurate model prediction in\nnons-parse scenarios. In this paper, we propose semiparametric re-modeling and\ninference when the linear regression model under study is possibly non-sparse.\nAfter an initial working model is selected by a method such as the Dantzig\nselector adopted in this paper, we re-construct a globally unbiased\nsemiparametric model by use of suitable instrumental variables and\nnonparametric adjustment. The newly defined model is identifiable, and the\nestimator of parameter vector is asymptotically normal. The consistency,\ntogether with the re-built model, promotes model prediction. This method\nnaturally works when the model is indeed sparse and thus is of robustness\nagainst non-sparseness in certain sense. Simulation studies show that the new\napproach has, particularly when $p$ is much larger than $n$, significant\nimprovement of estimation and prediction accuracies over the Gaussian Dantzig\nselector and other classical methods. Even when the model under study is\nsparse, our method is also comparable to the existing methods designed for\nsparse models.\n", "versions": [{"version": "v1", "created": "Sun, 4 Dec 2011 02:23:05 GMT"}], "update_date": "2011-12-06", "authors_parsed": [["Lin", "Lu", ""], ["Zhu", "Lixing", ""], ["Gai", "Yujie", ""]]}, {"id": "1112.0716", "submitter": "Surya Tokdar Surya Tokdar", "authors": "Surya T. Tokdar", "title": "Dimension adaptability of Gaussian process models with variable\n  selection and projection", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is now known that an extended Gaussian process model equipped with\nrescaling can adapt to different smoothness levels of a function valued\nparameter in many nonparametric Bayesian analyses, offering a posterior\nconvergence rate that is optimal (up to logarithmic factors) for the smoothness\nclass the true function belongs to. This optimal rate also depends on the\ndimension of the function's domain and one could potentially obtain a faster\nrate of convergence by casting the analysis in a lower dimensional subspace\nthat does not amount to any loss of information about the true function. In\ngeneral such a subspace is not known a priori but can be explored by equipping\nthe model with variable selection or linear projection. We demonstrate that for\nnonparametric regression, classification, density estimation and density\nregression, a rescaled Gaussian process model equipped with variable selection\nor linear projection offers a posterior convergence rate that is optimal (up to\nlogarithmic factors) for the lowest dimension in which the analysis could be\ncast without any loss of information about the true function. Theoretical\nexploration of such dimension reduction features appears novel for Bayesian\nnonparametric models with or without Gaussian processes.\n", "versions": [{"version": "v1", "created": "Sun, 4 Dec 2011 04:35:07 GMT"}], "update_date": "2011-12-06", "authors_parsed": [["Tokdar", "Surya T.", ""]]}, {"id": "1112.0818", "submitter": "Fumiyasu Komaki", "authors": "Fumiyasu Komaki", "title": "Asymptotically minimax Bayesian predictive densities for multinomial\n  models", "comments": null, "journal-ref": "Electron. J. Statist. 6: 934-957 (2012)", "doi": "10.1214/12-EJS700", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One-step ahead prediction for the multinomial model is considered. The\nperformance of a predictive density is evaluated by the average\nKullback-Leibler divergence from the true density to the predictive density.\nAsymptotic approximations of risk functions of Bayesian predictive densities\nbased on Dirichlet priors are obtained. It is shown that a Bayesian predictive\ndensity based on a specific Dirichlet prior is asymptotically minimax. The\nasymptotically minimax prior is different from known objective priors such as\nthe Jeffreys prior or the uniform prior.\n", "versions": [{"version": "v1", "created": "Mon, 5 Dec 2011 01:30:15 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Komaki", "Fumiyasu", ""]]}, {"id": "1112.0840", "submitter": "Pavel N. Krivitsky", "authors": "Pavel N. Krivitsky, Eric D. Kolaczyk", "title": "On the Question of Effective Sample Size in Network Modeling: An\n  Asymptotic Inquiry", "comments": "Published at http://dx.doi.org/10.1214/14-STS502 in the Statistical\n  Science (http://www.imstat.org/sts/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Statistical Science 2015, Vol. 30, No. 2, 184-198", "doi": "10.1214/14-STS502", "report-no": "IMS-STS-STS502", "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The modeling and analysis of networks and network data has seen an explosion\nof interest in recent years and represents an exciting direction for potential\ngrowth in statistics. Despite the already substantial amount of work done in\nthis area to date by researchers from various disciplines, however, there\nremain many questions of a decidedly foundational nature - natural analogues of\nstandard questions already posed and addressed in more classical areas of\nstatistics - that have yet to even be posed, much less addressed. Here we raise\nand consider one such question in connection with network modeling.\nSpecifically, we ask, \"Given an observed network, what is the sample size?\"\nUsing simple, illustrative examples from the class of exponential random graph\nmodels, we show that the answer to this question can very much depend on basic\nproperties of the networks expected under the model, as the number of vertices\n$n_V$ in the network grows. In particular, adopting the (asymptotic) scaling of\nthe variance of the maximum likelihood parameter estimates as a notion of\neffective sample size ($n_{\\mathrm{eff}}$), we show that when modeling the\noverall propensity to have ties and the propensity to reciprocate ties, whether\nthe networks are sparse or not under the model (i.e., having a constant or an\nincreasing number of ties per vertex, respectively) is sufficient to yield an\norder of magnitude difference in $n_{\\mathrm{eff}}$, from $O(n_V)$ to\n$O(n^2_V)$. In addition, we report simulation study results that suggest\nsimilar properties for models for triadic (friend-of-a-friend) effects. We then\nexplore some practical implications of this result, using both simulation and\ndata on food-sharing from Lamalera, Indonesia.\n", "versions": [{"version": "v1", "created": "Mon, 5 Dec 2011 05:53:34 GMT"}, {"version": "v2", "created": "Thu, 16 Feb 2012 04:40:58 GMT"}, {"version": "v3", "created": "Sun, 21 Oct 2012 23:27:50 GMT"}, {"version": "v4", "created": "Wed, 5 Aug 2015 06:08:02 GMT"}], "update_date": "2015-08-06", "authors_parsed": [["Krivitsky", "Pavel N.", ""], ["Kolaczyk", "Eric D.", ""]]}, {"id": "1112.0867", "submitter": "Francesca Collet", "authors": "Francesca Collet, Fabrizio Leisen, Fabio Spizzichino and Florentina\n  Suter", "title": "Exchangeable Occupancy Models and Discrete Processes with the\n  Generalized Uniform Order Statistics Property", "comments": "27 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work focuses on Exchangeable Occupancy Models (EOM) and their relations\nwith the Uniform Order Statistics Property (UOSP) for point processes in\ndiscrete time. As our main purpose, we show how definitions and results\npresented in Shaked, Spizzichino and Suter (2004) can be unified and\ngeneralized in the frame of occupancy models. We first show some general facts\nabout EOM's. Then we introduce a class of EOM's, called\n$\\mathcal{M}^{(a)}$-models, and a concept of generalized Uniform Order\nStatistics Property in discrete time. For processes with this property, we\nprove a general characterization result in terms of $\\mathcal{M}^{(a)}$-models.\nOur interest is also focused on properties of closure w.r.t. some natural\ntransformations of EOM's.\n", "versions": [{"version": "v1", "created": "Mon, 5 Dec 2011 09:48:25 GMT"}, {"version": "v2", "created": "Sat, 5 Jan 2013 14:12:42 GMT"}], "update_date": "2013-01-08", "authors_parsed": [["Collet", "Francesca", ""], ["Leisen", "Fabrizio", ""], ["Spizzichino", "Fabio", ""], ["Suter", "Florentina", ""]]}, {"id": "1112.0905", "submitter": "John H. J. Einmahl", "authors": "John H. J. Einmahl, Andrea Krajina, Johan Segers", "title": "An M-estimator for tail dependence in arbitrary dimensions", "comments": "Published in at http://dx.doi.org/10.1214/12-AOS1023 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2012, Vol. 40, No. 3, 1764-1793", "doi": "10.1214/12-AOS1023", "report-no": "IMS-AOS-AOS1023", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a random sample in the max-domain of attraction of a multivariate\nextreme value distribution such that the dependence structure of the attractor\nbelongs to a parametric model. A new estimator for the unknown parameter is\ndefined as the value that minimizes the distance between a vector of weighted\nintegrals of the tail dependence function and their empirical counterparts. The\nminimization problem has, with probability tending to one, a unique, global\nsolution. The estimator is consistent and asymptotically normal. The spectral\nmeasures of the tail dependence models to which the method applies can be\ndiscrete or continuous. Examples demonstrate the applicability and the\nperformance of the method.\n", "versions": [{"version": "v1", "created": "Mon, 5 Dec 2011 12:30:43 GMT"}, {"version": "v2", "created": "Tue, 10 Apr 2012 13:27:00 GMT"}, {"version": "v3", "created": "Thu, 4 Oct 2012 06:16:47 GMT"}], "update_date": "2012-10-05", "authors_parsed": [["Einmahl", "John H. J.", ""], ["Krajina", "Andrea", ""], ["Segers", "Johan", ""]]}, {"id": "1112.0906", "submitter": "Sari Lasanen", "authors": "Sari Lasanen", "title": "Posterior convergence for approximated unknowns in non-Gaussian\n  statistical inverse problems", "comments": "69 pages", "journal-ref": null, "doi": "10.3934/ipi.2012.6.267", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The statistical inverse problem of estimating the probability distribution of\nan infinite-dimensional unknown given its noisy indirect observation is studied\nin the Bayesian framework. In practice, one often considers only\nfinite-dimensional unknowns and investigates numerically their probabilities.\nAs many unknowns are function-valued, it is of interest to know whether the\nestimated probabilities converge when the finite-dimensional approximations of\nthe unknown are refined. In this work, the generalized Bayes formula is shown\nto be a powerful tool in the convergence studies. With the help of the\ngeneralized Bayes formula, the question of convergence of the posterior\ndistributions is returned to the convergence of the finite-dimensional (or any\nother) approximations of the unknown. The approach allows many prior\ndistributions while the restrictions are mainly for the noise model and the\ndirect theory. Three modes of convergence of posterior distributions are\nconsidered -- weak convergence, setwise convergence and convergence in\nvariation. The convergence of conditional mean estimates is studied. Several\nexamples of applicable infinite-dimensional non-Gaussian noise models are\nprovided, including a generalization of the Cameron-Martin formula for certain\nnon-Gaussian measures. Also, the well-posedness of Bayesian statistical inverse\nproblems is studied.\n", "versions": [{"version": "v1", "created": "Mon, 5 Dec 2011 12:36:36 GMT"}], "update_date": "2017-11-21", "authors_parsed": [["Lasanen", "Sari", ""]]}, {"id": "1112.0939", "submitter": "Markus Bibinger", "authors": "Markus Bibinger and Markus Rei{\\ss}", "title": "Spectral covolatility estimation from noisy observations using local\n  weights", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose localized spectral estimators for the quadratic covariation and\nthe spot covolatility of diffusion processes which are observed discretely with\nadditive observation noise. The eligibility of this approach to lead to an\nappropriate estimation for time-varying volatilities stems from an asymptotic\nequivalence of the underlying statistical model to a white noise model with\ncorrelation and volatility processes being constant over small intervals. The\nasymptotic equivalence of the continuous-time and the discrete-time experiments\nare proved by a construction with linear interpolation in one direction and\nlocal means for the other. The new estimator outperforms earlier nonparametric\napproaches in the considered model. We investigate its finite sample size\ncharacteristics in simulations and draw a comparison between the various\nproposed methods.\n", "versions": [{"version": "v1", "created": "Mon, 5 Dec 2011 14:33:27 GMT"}, {"version": "v2", "created": "Fri, 30 Dec 2011 15:03:21 GMT"}, {"version": "v3", "created": "Thu, 23 May 2013 13:14:39 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Bibinger", "Markus", ""], ["Rei\u00df", "Markus", ""]]}, {"id": "1112.1241", "submitter": "Alexander Walsh", "authors": "Alexander Walsh", "title": "Stochastic integration with respect to additive functionals of zero\n  quadratic variation", "comments": "Published in at http://dx.doi.org/10.3150/12-BEJ457 the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2013, Vol. 19, No. 5B, 2414-2436", "doi": "10.3150/12-BEJ457", "report-no": "IMS-BEJ-BEJ457", "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a Markov process $X$ associated to a nonnecessarily symmetric\nDirichlet form $\\mathcal{E}$. We define a stochastic integral with respect to a\nclass of additive functionals of zero quadratic variation and then we obtain an\nIt\\^{o} formula for the process $u(X)$, when $u$ is locally in the domain of\n$\\mathcal{E}$.\n", "versions": [{"version": "v1", "created": "Tue, 6 Dec 2011 11:41:52 GMT"}, {"version": "v2", "created": "Fri, 16 Dec 2011 09:28:18 GMT"}, {"version": "v3", "created": "Tue, 17 Dec 2013 09:22:16 GMT"}], "update_date": "2013-12-18", "authors_parsed": [["Walsh", "Alexander", ""]]}, {"id": "1112.1392", "submitter": "Martin Hairer", "authors": "Martin Hairer, Andrew M. Stuart, Sebastian J. Vollmer", "title": "Spectral gaps for a Metropolis-Hastings algorithm in infinite dimensions", "comments": "Published in at http://dx.doi.org/10.1214/13-AAP982 the Annals of\n  Applied Probability (http://www.imstat.org/aap/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Probability 2014, Vol. 24, No. 6, 2455-2490", "doi": "10.1214/13-AAP982", "report-no": "IMS-AAP-AAP982", "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of sampling high and infinite dimensional target\nmeasures arising in applications such as conditioned diffusions and inverse\nproblems. We focus on those that arise from approximating measures on Hilbert\nspaces defined via a density with respect to a Gaussian reference measure. We\nconsider the Metropolis-Hastings algorithm that adds an accept-reject mechanism\nto a Markov chain proposal in order to make the chain reversible with respect\nto the target measure. We focus on cases where the proposal is either a\nGaussian random walk (RWM) with covariance equal to that of the reference\nmeasure or an Ornstein-Uhlenbeck proposal (pCN) for which the reference measure\nis invariant. Previous results in terms of scaling and diffusion limits\nsuggested that the pCN has a convergence rate that is independent of the\ndimension while the RWM method has undesirable dimension-dependent behaviour.\nWe confirm this claim by exhibiting a dimension-independent Wasserstein\nspectral gap for pCN algorithm for a large class of target measures. In our\nsetting this Wasserstein spectral gap implies an $L^2$-spectral gap. We use\nboth spectral gaps to show that the ergodic average satisfies a strong law of\nlarge numbers, the central limit theorem and nonasymptotic bounds on the mean\nsquare error, all dimension independent. In contrast we show that the spectral\ngap of the RWM algorithm applied to the reference measures degenerates as the\ndimension tends to infinity.\n", "versions": [{"version": "v1", "created": "Tue, 6 Dec 2011 20:18:55 GMT"}, {"version": "v2", "created": "Fri, 8 Feb 2013 11:56:35 GMT"}, {"version": "v3", "created": "Tue, 26 Nov 2013 23:03:12 GMT"}, {"version": "v4", "created": "Mon, 22 Sep 2014 07:51:17 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Hairer", "Martin", ""], ["Stuart", "Andrew M.", ""], ["Vollmer", "Sebastian J.", ""]]}, {"id": "1112.1450", "submitter": "Maxim Raginsky", "authors": "Maxim Raginsky, Jorge Silva, Svetlana Lazebnik and Rebecca Willett", "title": "A recursive procedure for density estimation on the binary hypercube", "comments": "revision submitted to Electronic Journal of Statistics", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a recursive estimation procedure for multivariate binary\ndensities (probability distributions of vectors of Bernoulli random variables)\nusing orthogonal expansions. For $d$ covariates, there are $2^d$ basis\ncoefficients to estimate, which renders conventional approaches computationally\nprohibitive when $d$ is large. However, for a wide class of densities that\nsatisfy a certain sparsity condition, our estimator runs in probabilistic\npolynomial time and adapts to the unknown sparsity of the underlying density in\ntwo key ways: (1) it attains near-minimax mean-squared error for moderate\nsample sizes, and (2) the computational complexity is lower for sparser\ndensities. Our method also allows for flexible control of the trade-off between\nmean-squared error and computational complexity.\n", "versions": [{"version": "v1", "created": "Wed, 7 Dec 2011 00:30:17 GMT"}, {"version": "v2", "created": "Fri, 30 Nov 2012 01:35:32 GMT"}], "update_date": "2012-12-03", "authors_parsed": [["Raginsky", "Maxim", ""], ["Silva", "Jorge", ""], ["Lazebnik", "Svetlana", ""], ["Willett", "Rebecca", ""]]}, {"id": "1112.1478", "submitter": "Nikolai Dokuchaev", "authors": "Nikolai Dokuchaev", "title": "Predictors for discrete time processes with energy decay on higher\n  frequencies", "comments": "5 pages", "journal-ref": "IEEE Transactions on Signal Processing (2012) 60, No. 11,\n  6027-6030", "doi": "10.1109/TSP.2012.2212436", "report-no": null, "categories": "math.OC math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The predictability of discrete-time processes is studied in a deterministic\nsetting. A family of one-step-ahead predictors is suggested for processes of\nwhich the energy decays at higher frequencies. For such processes, the\nprediction error can be made arbitrarily small. The predictions can be robust\nwith respect to the noise contamination at higher frequencies.\n", "versions": [{"version": "v1", "created": "Wed, 7 Dec 2011 05:45:37 GMT"}, {"version": "v2", "created": "Fri, 23 Dec 2011 08:07:31 GMT"}, {"version": "v3", "created": "Wed, 30 May 2012 07:30:42 GMT"}, {"version": "v4", "created": "Tue, 7 Aug 2012 07:04:45 GMT"}, {"version": "v5", "created": "Tue, 21 Aug 2018 04:46:05 GMT"}], "update_date": "2018-08-22", "authors_parsed": [["Dokuchaev", "Nikolai", ""]]}, {"id": "1112.1490", "submitter": "Marta Ferreira", "authors": "Helena Ferreira and Marta Ferreira", "title": "Fragility Index of block tailed vectors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Financial crises are a recurrent phenomenon with important effects on the\nreal economy. The financial system is inherently fragile and it is therefore of\ngreat importance to be able to measure and characterize its systemic stability.\nMultivariate extreme value theory provide us such a framework through the\n\\emph{fragility index} (Geluk \\cite{gel+}, \\emph{et al.}, 2007; Falk and Tichy,\n\\cite{falk+tichy1,falk+tichy2} 2010, 2011). Here we generalize this concept and\ncontribute to the modeling of the stability of a stochastic system divided into\nblocks. We will find several relations with well-known tail dependence measures\nin literature, which will provide us immediate estimators. We end with an\napplication to financial data.\n", "versions": [{"version": "v1", "created": "Wed, 7 Dec 2011 07:43:54 GMT"}], "update_date": "2011-12-08", "authors_parsed": [["Ferreira", "Helena", ""], ["Ferreira", "Marta", ""]]}, {"id": "1112.1529", "submitter": "Michael Nussbaum", "authors": "Michael Nussbaum, Arleta Szko{\\l}a", "title": "An asymptotic error bound for testing multiple quantum hypotheses", "comments": "Published in at http://dx.doi.org/10.1214/11-AOS933 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2011, Vol. 39, No. 6, 3211-3233", "doi": "10.1214/11-AOS933", "report-no": "IMS-AOS-AOS933", "categories": "quant-ph math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of detecting the true quantum state among $r$\npossible ones, based of measurements performed on $n$ copies of a\nfinite-dimensional quantum system. A special case is the problem of\ndiscriminating between $r$ probability measures on a finite sample space, using\n$n$ i.i.d. observations. In this classical setting, it is known that the\naveraged error probability decreases exponentially with exponent given by the\nworst case binary Chernoff bound between any possible pair of the $r$\nprobability measures. Define analogously the multiple quantum Chernoff bound,\nconsidering all possible pairs of states. Recently, it has been shown that this\nasymptotic error bound is attainable in the case of $r$ pure states, and that\nit is unimprovable in general. Here we extend the attainability result to a\nlarger class of $r$-tuples of states which are possibly mixed, but pairwise\nlinearly independent. We also construct a quantum detector which universally\nattains the multiple quantum Chernoff bound up to a factor 1/3.\n", "versions": [{"version": "v1", "created": "Wed, 7 Dec 2011 11:40:15 GMT"}, {"version": "v2", "created": "Fri, 11 May 2012 12:21:44 GMT"}], "update_date": "2012-05-14", "authors_parsed": [["Nussbaum", "Michael", ""], ["Szko\u0142a", "Arleta", ""]]}, {"id": "1112.1768", "submitter": "Keqin Liu", "authors": "Keqin Liu, Qing Zhao", "title": "Extended UCB Policy for Multi-Armed Bandit with Light-Tailed Reward\n  Distributions", "comments": "9 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the multi-armed bandit problems in which a player aims to accrue\nreward by sequentially playing a given set of arms with unknown reward\nstatistics. In the classic work, policies were proposed to achieve the optimal\nlogarithmic regret order for some special classes of light-tailed reward\ndistributions, e.g., Auer et al.'s UCB1 index policy for reward distributions\nwith finite support. In this paper, we extend Auer et al.'s UCB1 index policy\nto achieve the optimal logarithmic regret order for all light-tailed (or\nequivalently, locally sub-Gaussian) reward distributions defined by the (local)\nexistence of the moment-generating function.\n", "versions": [{"version": "v1", "created": "Thu, 8 Dec 2011 05:53:35 GMT"}], "update_date": "2011-12-09", "authors_parsed": [["Liu", "Keqin", ""], ["Zhao", "Qing", ""]]}, {"id": "1112.1788", "submitter": "Fabrice Gamboa", "authors": "Ga\\\"elle Chastaing (M\\'ethodes d'Analyse Stochastique des Codes et\n  Traitements Num\\'eriques, INRIA Grenoble Rh\\^one-Alpes / LJK Laboratoire Jean\n  Kuntzmann), Fabrice Gamboa (M\\'ethodes d'Analyse Stochastique des Codes et\n  Traitements Num\\'eriques, IMT), Cl\\'ementine Prieur (M\\'ethodes d'Analyse\n  Stochastique des Codes et Traitements Num\\'eriques, INRIA Grenoble\n  Rh\\^one-Alpes / LJK Laboratoire Jean Kuntzmann)", "title": "Generalized Hoeffding-Sobol Decomposition for Dependent Variables\n  -Application to Sensitivity Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider a regression model built on dependent variables.\nThis regression modelizes an input output relationship. Under boundedness\nassumptions on the joint distribution function of the input variables, we show\nthat a generalized Hoeffding-Sobol decomposition is available. This leads to\nnew indices measuring the sensitivity of the output with respect to the input\nvariables. We also study and discuss the estimation of these new indices.\n", "versions": [{"version": "v1", "created": "Thu, 8 Dec 2011 09:18:04 GMT"}, {"version": "v2", "created": "Fri, 16 Dec 2011 07:41:47 GMT"}, {"version": "v3", "created": "Sun, 11 Mar 2012 19:35:51 GMT"}], "update_date": "2012-03-14", "authors_parsed": [["Chastaing", "Ga\u00eblle", "", "M\u00e9thodes d'Analyse Stochastique des Codes et\n  Traitements Num\u00e9riques, INRIA Grenoble Rh\u00f4ne-Alpes / LJK Laboratoire Jean\n  Kuntzmann"], ["Gamboa", "Fabrice", "", "M\u00e9thodes d'Analyse Stochastique des Codes et\n  Traitements Num\u00e9riques, IMT"], ["Prieur", "Cl\u00e9mentine", "", "M\u00e9thodes d'Analyse\n  Stochastique des Codes et Traitements Num\u00e9riques, INRIA Grenoble\n  Rh\u00f4ne-Alpes / LJK Laboratoire Jean Kuntzmann"]]}, {"id": "1112.1868", "submitter": "Matthias Troffaes", "authors": "Matthias C. M. Troffaes and John Paul Gosling", "title": "Robust detection of exotic infectious diseases in animal herds: A\n  comparative study of three decision methodologies under severe uncertainty", "comments": "14 pages, 5 figures, 4 tables; v2: 15 pages, minor corrections,\n  references added", "journal-ref": "International Journal of Approximate Reasoning 53 (2012) 1271-1281", "doi": "10.1016/j.ijar.2012.06.020", "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When animals are transported and pass through customs, some of them may have\ndangerous infectious diseases. Typically, due to the cost of testing, not all\nanimals are tested: a reasonable selection must be made. How to test\neffectively whilst avoiding costly disease outbreaks? First, we extend a model\nproposed in the literature for the detection of invasive species to suit our\npurpose. Secondly, we explore and compare three decision methodologies on the\nproblem at hand, namely, Bayesian statistics, info-gap theory and imprecise\nprobability theory, all of which are designed to handle severe uncertainty. We\nshow that, under rather general conditions, every info-gap solution is maximal\nwith respect to a suitably chosen imprecise probability model, and that\ntherefore, perhaps surprisingly, the set of maximal options can be inferred at\nleast partly---and sometimes entirely---from an info-gap analysis.\n", "versions": [{"version": "v1", "created": "Thu, 8 Dec 2011 16:12:03 GMT"}, {"version": "v2", "created": "Mon, 5 Mar 2012 11:29:10 GMT"}], "update_date": "2013-01-04", "authors_parsed": [["Troffaes", "Matthias C. M.", ""], ["Gosling", "John Paul", ""]]}, {"id": "1112.1977", "submitter": "Tucker S. McElroy", "authors": "Tucker S. McElroy, Scott H. Holan", "title": "Asymptotic theory of cepstral random fields", "comments": "Published in at http://dx.doi.org/10.1214/13-AOS1180 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2014, Vol. 42, No. 1, 64-86", "doi": "10.1214/13-AOS1180", "report-no": "IMS-AOS-AOS1180", "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random fields play a central role in the analysis of spatially correlated\ndata and, as a result, have a significant impact on a broad array of scientific\napplications. This paper studies the cepstral random field model, providing\nrecursive formulas that connect the spatial cepstral coefficients to an\nequivalent moving-average random field, which facilitates easy computation of\nthe autocovariance matrix. We also provide a comprehensive treatment of the\nasymptotic theory for two-dimensional random field models: we establish\nasymptotic results for Bayesian, maximum likelihood and quasi-maximum\nlikelihood estimation of random field parameters and regression parameters. The\ntheoretical results are presented generally and are of independent interest,\npertaining to a wide class of random field models. The results for the cepstral\nmodel facilitate model-building: because the cepstral coefficients are\nunconstrained in practice, numerical optimization is greatly simplified, and we\nare always guaranteed a positive definite covariance matrix. We show that\ninference for individual coefficients is possible, and one can refine models in\na disciplined manner. Our results are illustrated through simulation and the\nanalysis of straw yield data in an agricultural field experiment.\n", "versions": [{"version": "v1", "created": "Thu, 8 Dec 2011 22:39:02 GMT"}, {"version": "v2", "created": "Fri, 18 May 2012 21:07:08 GMT"}, {"version": "v3", "created": "Thu, 14 Mar 2013 19:26:50 GMT"}, {"version": "v4", "created": "Thu, 16 Jan 2014 12:09:11 GMT"}], "update_date": "2014-01-17", "authors_parsed": [["McElroy", "Tucker S.", ""], ["Holan", "Scott H.", ""]]}, {"id": "1112.2078", "submitter": "Madalin Guta", "authors": "Richard D. Gill and Madalin Guta", "title": "On Asymptotic Quantum Statistical Inference", "comments": "34 pages. to appear in `From Probability to Statistics and Back:\n  High-Dimensional Models and Processes'. A Festschrift in Honor of Jon\n  Wellner. Edited by Banerjee, M., Bunea, F., Huang, J., Maathuis, M. and\n  Koltchinskii, V. extension of a previous paper arXiv:math/0512443", "journal-ref": "IMS Collections (9) 105-127, 2013 (From Probability to Statistics\n  and Back: High-Dimensional Models and Processes A Festschrift in Honor of Jon\n  A. Wellner Banerjee, M., Bunea, F., Huang, J., Koltchinskii, V., and\n  Maathuis, M. H., Editors)", "doi": null, "report-no": null, "categories": "quant-ph math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study asymptotically optimal statistical inference concerning the unknown\nstate of $N$ identical quantum systems, using two complementary approaches: a\n\"poor man's approach\" based on the van Trees inequality, and a rather more\nsophisticated approach using the recently developed quantum form of LeCam's\ntheory of Local Asymptotic Normality.\n", "versions": [{"version": "v1", "created": "Fri, 9 Dec 2011 11:47:27 GMT"}, {"version": "v2", "created": "Thu, 26 Jan 2012 22:44:43 GMT"}], "update_date": "2013-03-22", "authors_parsed": [["Gill", "Richard D.", ""], ["Guta", "Madalin", ""]]}, {"id": "1112.2080", "submitter": "Madalin Guta", "authors": "Catalin Catana, Merlijn van Horssen and Madalin Guta", "title": "Asymptotic inference in system identification for the atom maser", "comments": "20pages, 3 figures", "journal-ref": "Phil. Trans. R. Soc. A (370) 5308-5323, 2012", "doi": "10.1098/rsta.2011.0528", "report-no": null, "categories": "quant-ph math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  System identification is an integrant part of control theory and plays an\nincreasing role in quantum engineering. In the quantum set-up, system\nidentification is usually equated to process tomography, i.e. estimating a\nchannel by probing it repeatedly with different input states. However for\nquantum dynamical systems like quantum Markov processes, it is more natural to\nconsider the estimation based on continuous measurements of the output, with a\ngiven input which may be stationary. We address this problem using asymptotic\nstatistics tools, for the specific example of estimating the Rabi frequency of\nan atom maser. We compute the Fisher information of different measurement\nprocesses as well as the quantum Fisher information of the atom maser, and\nestablish the local asymptotic normality of these statistical models. The\nstatistical notions can be expressed in terms of spectral properties of certain\ndeformed Markov generators and the connection to large deviations is briefly\ndiscussed.\n", "versions": [{"version": "v1", "created": "Fri, 9 Dec 2011 12:18:03 GMT"}], "update_date": "2012-11-27", "authors_parsed": [["Catana", "Catalin", ""], ["van Horssen", "Merlijn", ""], ["Guta", "Madalin", ""]]}, {"id": "1112.2093", "submitter": "Peter K\\\"oves\\'arki", "authors": "Peter Kovesarki, Ian C. Brock and A. Elizabeth Nuncio Quiroz", "title": "Green's function based unparameterised multi-dimensional kernel density\n  and likelihood ratio estimator", "comments": "7 pages, 4 figures. JPCS accepted it as a proceedings to the ACAT\n  workshop", "journal-ref": null, "doi": "10.1088/1742-6596/368/1/012041", "report-no": null, "categories": "stat.ML math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a probability density estimator based on Green's\nfunction identities. A density model is constructed under the sole assumption\nthat the probability density is differentiable. The method is implemented as a\nbinary likelihood estimator for classification purposes, so issues such as\nmis-modeling and overtraining are also discussed. The identity behind the\ndensity estimator can be interpreted as a real-valued, non-scalar kernel method\nwhich is able to reconstruct differentiable density functions.\n", "versions": [{"version": "v1", "created": "Fri, 9 Dec 2011 13:16:05 GMT"}, {"version": "v2", "created": "Wed, 18 Apr 2012 11:11:04 GMT"}], "update_date": "2012-08-22", "authors_parsed": [["Kovesarki", "Peter", ""], ["Brock", "Ian C.", ""], ["Quiroz", "A. Elizabeth Nuncio", ""]]}, {"id": "1112.2271", "submitter": "Krzysztof Szajowski", "authors": "Anna Karpowicz and Krzysztof Szajowski", "title": "Anglers' fishing problem", "comments": "23 pages + index", "journal-ref": null, "doi": null, "report-no": "Report PRE44, Institute of Mathematics and Computer Science, 2011", "categories": "math.PR cs.GT cs.SY math.OC math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The considered model will be formulated as related to \"the fishing problem\"\neven if the other applications of it are much more obvious. The angler goes\nfishing. He uses various techniques and he has at most two fishing rods. He\nbuys a fishing ticket for a fixed time. The fishes are caught with the use of\ndifferent methods according to the renewal processes. The fishes' value and the\ninter arrival times are given by the sequences of independent, identically\ndistributed (i.i.d.) random variables with the known distribution functions. It\nforms the marked renewal--reward process. The angler's measure of satisfaction\nis given by the difference between the utility function, depending on the value\nof the fishes caught, and the cost function connected with the time of fishing.\nIn this way, the angler's relative opinion about the methods of fishing is\nmodelled. The angler's aim is to have as much satisfaction as possible and\nadditionally he has to leave the lake before a fixed moment. Therefore his goal\nis to find two optimal stopping times in order to maximize his satisfaction. At\nthe first moment, he changes the technique of fishing, e.g. by excluding one\nrod and intensifying on the rest. Next, he decides when he should stop the\nexpedition. These stopping times have to be shorter than the fixed time of\nfishing. The dynamic programming methods have been used to find these two\noptimal stopping times and to specify the expected satisfaction of the angler\nat these times.\n", "versions": [{"version": "v1", "created": "Sat, 10 Dec 2011 12:09:21 GMT"}], "update_date": "2011-12-13", "authors_parsed": [["Karpowicz", "Anna", ""], ["Szajowski", "Krzysztof", ""]]}, {"id": "1112.2381", "submitter": "Natesh S. Pillai", "authors": "Natesh S. Pillai, Jun Yin", "title": "Edge universality of correlation matrices", "comments": "Published in at http://dx.doi.org/10.1214/12-AOS1022 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2012, Vol. 40, No. 3, 1737-1763", "doi": "10.1214/12-AOS1022", "report-no": "IMS-AOS-AOS1022", "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $\\widetilde{X}_{M\\times N}$ be a rectangular data matrix with independent\nreal-valued entries $[\\widetilde{x}_{ij}]$ satisfying $\\mathbb\n{E}\\widetilde{x}_{ij}=0$ and $\\mathbb {E}\\widetilde{x}^2_{ij}=\\frac{1}{M}$,\n$N,M\\to\\infty$. These entries have a subexponential decay at the tails. We will\nbe working in the regime $N/M=d_N,\\lim_{N\\to\\infty}d_N\\neq0,1,\\infty$. In this\npaper we prove the edge universality of correlation matrices ${X}^{\\dagger}X$,\nwhere the rectangular matrix $X$ (called the standardized matrix) is obtained\nby normalizing each column of the data matrix $\\widetilde{X}$ by its Euclidean\nnorm. Our main result states that asymptotically the $k$-point ($k\\geq1$)\ncorrelation functions of the extreme eigenvalues (at both edges of the\nspectrum) of the correlation matrix ${X}^{\\dagger}X$ converge to those of the\nGaussian correlation matrix, that is, Tracy-Widom law, and, thus, in\nparticular, the largest and the smallest eigenvalues of ${X}^{\\dagger}X$ after\nappropriate centering and rescaling converge to the Tracy-Widom distribution.\nThe asymptotic distribution of extreme eigenvalues of the Gaussian correlation\nmatrix has been worked out only recently. As a corollary of the main result in\nthis paper, we also obtain that the extreme eigenvalues of Gaussian correlation\nmatrices are asymptotically distributed according to the Tracy-Widom law. The\nproof is based on the comparison of Green functions, but the key obstacle to be\nsurmounted is the strong dependence of the entries of the correlation matrix.\nWe achieve this via a novel argument which involves comparing the moments of\nproduct of the entries of the standardized data matrix to those of the raw data\nmatrix. Our proof strategy may be extended for proving the edge universality of\nother random matrix ensembles with dependent entries and hence is of\nindependent interest.\n", "versions": [{"version": "v1", "created": "Sun, 11 Dec 2011 18:27:08 GMT"}, {"version": "v2", "created": "Sat, 14 Jan 2012 07:54:55 GMT"}, {"version": "v3", "created": "Tue, 19 Jun 2012 16:53:41 GMT"}, {"version": "v4", "created": "Thu, 4 Oct 2012 05:19:56 GMT"}], "update_date": "2012-10-05", "authors_parsed": [["Pillai", "Natesh S.", ""], ["Yin", "Jun", ""]]}, {"id": "1112.2432", "submitter": "Zongming Ma", "authors": "Zongming Ma", "title": "Sparse principal component analysis and iterative thresholding", "comments": "Published in at http://dx.doi.org/10.1214/13-AOS1097 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2013, Vol. 41, No. 2, 772-801", "doi": "10.1214/13-AOS1097", "report-no": "IMS-AOS-AOS1097", "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Principal component analysis (PCA) is a classical dimension reduction method\nwhich projects data onto the principal subspace spanned by the leading\neigenvectors of the covariance matrix. However, it behaves poorly when the\nnumber of features p is comparable to, or even much larger than, the sample\nsize n. In this paper, we propose a new iterative thresholding approach for\nestimating principal subspaces in the setting where the leading eigenvectors\nare sparse. Under a spiked covariance model, we find that the new approach\nrecovers the principal subspace and leading eigenvectors consistently, and even\noptimally, in a range of high-dimensional sparse settings. Simulated examples\nalso demonstrate its competitive performance.\n", "versions": [{"version": "v1", "created": "Mon, 12 Dec 2011 03:47:59 GMT"}, {"version": "v2", "created": "Fri, 24 May 2013 10:35:26 GMT"}], "update_date": "2013-05-27", "authors_parsed": [["Ma", "Zongming", ""]]}, {"id": "1112.2502", "submitter": "Li Wang", "authors": "Li Wang, Xiang Liu, Hua Liang, Raymond J. Carroll", "title": "Estimation and variable selection for generalized additive partial\n  linear models", "comments": "Published in at http://dx.doi.org/10.1214/11-AOS885 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2011, Vol. 39, No. 4, 1827-1851", "doi": "10.1214/11-AOS885", "report-no": "IMS-AOS-AOS885", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study generalized additive partial linear models, proposing the use of\npolynomial spline smoothing for estimation of nonparametric functions, and\nderiving quasi-likelihood based estimators for the linear parameters. We\nestablish asymptotic normality for the estimators of the parametric components.\nThe procedure avoids solving large systems of equations as in kernel-based\nprocedures and thus results in gains in computational simplicity. We further\ndevelop a class of variable selection procedures for the linear parameters by\nemploying a nonconcave penalized quasi-likelihood, which is shown to have an\nasymptotic oracle property. Monte Carlo simulations and an empirical example\nare presented for illustration.\n", "versions": [{"version": "v1", "created": "Mon, 12 Dec 2011 10:31:55 GMT"}], "update_date": "2011-12-13", "authors_parsed": [["Wang", "Li", ""], ["Liu", "Xiang", ""], ["Liang", "Hua", ""], ["Carroll", "Raymond J.", ""]]}, {"id": "1112.2509", "submitter": "Fabienne Comte", "authors": "Fabienne Comte, Jan Johannes", "title": "Adaptive functional linear regression", "comments": "Published in at http://dx.doi.org/10.1214/12-AOS1050 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2012, Vol. 40, No. 6, 2765-2797", "doi": "10.1214/12-AOS1050", "report-no": "IMS-AOS-AOS1050", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the estimation of the slope function in functional linear\nregression, where scalar responses are modeled in dependence of random\nfunctions. Cardot and Johannes [J. Multivariate Anal. 101 (2010) 395-408] have\nshown that a thresholded projection estimator can attain up to a constant\nminimax-rates of convergence in a general framework which allows us to cover\nthe prediction problem with respect to the mean squared prediction error as\nwell as the estimation of the slope function and its derivatives. This\nestimation procedure, however, requires an optimal choice of a tuning parameter\nwith regard to certain characteristics of the slope function and the covariance\noperator associated with the functional regressor. As this information is\nusually inaccessible in practice, we investigate a fully data-driven choice of\nthe tuning parameter which combines model selection and Lepski's method. It is\ninspired by the recent work of Goldenshluger and Lepski [Ann. Statist. 39\n(2011) 1608-1632]. The tuning parameter is selected as minimizer of a\nstochastic penalized contrast function imitating Lepski's method among a random\ncollection of admissible values. This choice of the tuning parameter depends\nonly on the data and we show that within the general framework the resulting\ndata-driven thresholded projection estimator can attain minimax-rates up to a\nconstant over a variety of classes of slope functions and covariance operators.\nThe results are illustrated considering different configurations which cover in\nparticular the prediction problem as well as the estimation of the slope and\nits derivatives. A simulation study shows the reasonable performance of the\nfully data-driven estimation procedure.\n", "versions": [{"version": "v1", "created": "Mon, 12 Dec 2011 10:57:10 GMT"}, {"version": "v2", "created": "Mon, 18 Feb 2013 13:57:47 GMT"}], "update_date": "2013-02-19", "authors_parsed": [["Comte", "Fabienne", ""], ["Johannes", "Jan", ""]]}, {"id": "1112.2682", "submitter": "Hailin Sang", "authors": "Hailin Sang and Yan Sun", "title": "Simultaneous sparse model selection and coefficient estimation for\n  heavy-tailed autoregressive processes", "comments": "to appear in Statistics; 26 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a sparse coefficient estimation and automated model selection\nprocedure for autoregressive (AR) processes with heavy-tailed innovations based\non penalized conditional maximum likelihood. Under mild moment conditions on\nthe innovation processes, the penalized conditional maximum likelihood\nestimator (PCMLE) satisfies a strong consistency, $O_P(N^{-1/2})$ consistency,\nand the oracle properties, where N is the sample size. We have the freedom in\nchoosing penalty functions based on the weak conditions on them. Two penalty\nfunctions, least absolute shrinkage and selection operator (LASSO) and smoothly\nclipped average deviation (SCAD), are compared. The proposed method provides a\ndistribution-based penalized inference to AR models, which is especially useful\nwhen the other estimation methods fail or under perform for AR processes with\nheavy-tailed innovations (see \\cite{Resnick}). A simulation study confirms our\ntheoretical results. At the end, we apply our method to a historical price data\nof the US Industrial Production Index for consumer goods, and obtain very\npromising results.\n", "versions": [{"version": "v1", "created": "Mon, 12 Dec 2011 20:20:24 GMT"}, {"version": "v2", "created": "Wed, 2 May 2012 02:14:48 GMT"}, {"version": "v3", "created": "Sat, 21 Sep 2013 04:06:08 GMT"}], "update_date": "2013-09-24", "authors_parsed": [["Sang", "Hailin", ""], ["Sun", "Yan", ""]]}, {"id": "1112.2751", "submitter": "Magda Peligrad", "authors": "Martial Longla, Costel Peligrad, Magda Peligrad", "title": "On Functional CLT for Reversible Markov Chains with nonlinear growth of\n  the Variance", "comments": "20 pages, Functional CLT, Reversible Markov chains,\n  Metropolis-Hastings", "journal-ref": "Journal of Applied Probability 49, 1091-1105 (December 2012)", "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study the functional central limit theorem for stationary\nMarkov chains with self-adjoint operator and general state space. We\ninvestigate the case when the variance of the partial sum is not asymptotically\nlinear in n; and establish that conditional convergence in distribution of\npartial sums implies functional CLT. The main tools are maximal inequalities\nthat are further exploited to derive conditions for tightness and convergence\nto the Brownian motion.\n", "versions": [{"version": "v1", "created": "Tue, 13 Dec 2011 00:03:08 GMT"}, {"version": "v2", "created": "Thu, 24 May 2012 20:57:37 GMT"}, {"version": "v3", "created": "Wed, 8 May 2013 21:21:15 GMT"}], "update_date": "2013-05-10", "authors_parsed": [["Longla", "Martial", ""], ["Peligrad", "Costel", ""], ["Peligrad", "Magda", ""]]}, {"id": "1112.2759", "submitter": "Junbum Lee", "authors": "Junbum Lee and Suhasini Subba Rao", "title": "The quantile spectral density and comparison based tests for nonlinear\n  time series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider tests for nonlinear time series, which are\nmotivated by the notion of serial dependence. The proposed tests are based on\ncomparisons with the quantile spectral density, which can be considered as a\nquantile version of the usual spectral density function. The quantile spectral\ndensity 'measures' sequential dependence structure of a time series, and is\nwell defined under relatively weak mixing conditions. We propose an estimator\nfor the quantile spectral density and derive its asympototic sampling\nproperties. We use the quantile spectral density to construct a goodness of fit\ntest for time series and explain how this test can also be used for comparing\nthe sequential dependence structure of two time series. The method is\nillustrated with simulations and some real data examples.\n", "versions": [{"version": "v1", "created": "Tue, 13 Dec 2011 00:28:37 GMT"}, {"version": "v2", "created": "Sat, 10 Mar 2012 00:49:34 GMT"}], "update_date": "2012-03-13", "authors_parsed": [["Lee", "Junbum", ""], ["Rao", "Suhasini Subba", ""]]}, {"id": "1112.2815", "submitter": "Zehua Chen", "authors": "Shan Luo and Zehua Chen", "title": "Selection Consistency of EBIC for GLIM with Non-canonical Links and\n  Diverging Number of Parameters", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we investigate the properties of the EBIC in variable\nselection for generalized linear models with non-canonical links and diverging\nnumber of parameters in ultra-high dimensional feature space. The selection\nconsistency of the EBIC in this situation is established under moderate\nconditions. The finite sample performance of the EBIC coupled with a forward\nselection procedure is demonstrated through simulation studies and a real data\nanalysis.\n", "versions": [{"version": "v1", "created": "Tue, 13 Dec 2011 08:10:29 GMT"}], "update_date": "2011-12-14", "authors_parsed": [["Luo", "Shan", ""], ["Chen", "Zehua", ""]]}, {"id": "1112.2855", "submitter": "Jan Johannes", "authors": "Jan Johannes and Rudolf Schenk", "title": "Adaptive estimation of linear functionals in functional linear models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the estimation of the value of a linear functional of the slope\nparameter in functional linear regression, where scalar responses are modeled\nin dependence of random functions. In Johannes and Schenk [2010] it has been\nshown that a plug-in estimator based on dimension reduction and additional\nthresholding can attain minimax optimal rates of convergence up to a constant.\nHowever, this estimation procedure requires an optimal choice of a tuning\nparameter with regard to certain characteristics of the slope function and the\ncovariance operator associated with the functional regressor. As these are\nunknown in practice, we investigate a fully data-driven choice of the tuning\nparameter based on a combination of model selection and Lepski's method, which\nis inspired by the recent work of Goldenshluger and Lepski [2011]. The tuning\nparameter is selected as the minimizer of a stochastic penalized contrast\nfunction imitating Lepski's method among a random collection of admissible\nvalues. We show that this adaptive procedure attains the lower bound for the\nminimax risk up to a logarithmic factor over a wide range of classes of slope\nfunctions and covariance operators. In particular, our theory covers point-wise\nestimation as well as the estimation of local averages of the slope parameter.\n", "versions": [{"version": "v1", "created": "Tue, 13 Dec 2011 10:47:33 GMT"}], "update_date": "2011-12-14", "authors_parsed": [["Johannes", "Jan", ""], ["Schenk", "Rudolf", ""]]}, {"id": "1112.2868", "submitter": "Gilles Guillot", "authors": "Gilles Guillot and Alexandra Carpentier-Skandalis", "title": "On the informativeness of dominant and co-dominant genetic markers for\n  Bayesian supervised clustering", "comments": null, "journal-ref": "The Open Statistics & Probability Journal, 2011, 3, 7-12", "doi": "10.2174/1876527001103010007", "report-no": null, "categories": "q-bio.PE math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the accuracy of Bayesian supervised method used to cluster\nindividuals into genetically homogeneous groups on the basis of dominant or\ncodominant molecular markers. We provide a formula relating an error criterion\nthe number of loci used and the number of clusters. This formula is exact and\nholds for arbitrary number of clusters and markers. Our work suggests that\ndominant markers studies can achieve an accuracy similar to that of codominant\nmarkers studies if the number of markers used in the former is about 1.7 times\nlarger than in the latter.\n", "versions": [{"version": "v1", "created": "Tue, 13 Dec 2011 12:17:33 GMT"}], "update_date": "2011-12-14", "authors_parsed": [["Guillot", "Gilles", ""], ["Carpentier-Skandalis", "Alexandra", ""]]}, {"id": "1112.3055", "submitter": "Olga Klopp", "authors": "Olga Klopp (CREST, MODAL'X), St\\'ephane Gaiffas (CMAP)", "title": "High dimensional matrix estimation with unknown variance of the noise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new pivotal method for estimating high-dimensional matrices.\nAssume that we observe a small set of entries or linear combinations of entries\nof an unknown matrix $A\\_0$ corrupted by noise. We propose a new method for\nestimating $A\\_0$ which does not rely on the knowledge or an estimation of the\nstandard deviation of the noise $\\sigma$. Our estimator achieves, up to a\nlogarithmic factor, optimal rates of convergence under the Frobenius risk and,\nthus, has the same prediction performance as previously proposed estimators\nwhich rely on the knowledge of $\\sigma$. Our method is based on the solution of\na convex optimization problem which makes it computationally attractive.\n", "versions": [{"version": "v1", "created": "Tue, 13 Dec 2011 21:48:28 GMT"}, {"version": "v2", "created": "Thu, 9 Feb 2012 10:59:24 GMT"}, {"version": "v3", "created": "Sat, 31 Jan 2015 18:47:27 GMT"}], "update_date": "2015-02-03", "authors_parsed": [["Klopp", "Olga", "", "CREST, MODAL'X"], ["Gaiffas", "St\u00e9phane", "", "CMAP"]]}, {"id": "1112.3149", "submitter": "Robert L. Wolpert", "authors": "Robert L. Wolpert, Merlise A. Clyde, Chong Tu", "title": "Stochastic expansions using continuous dictionaries: L\\'{e}vy adaptive\n  regression kernels", "comments": "Published in at http://dx.doi.org/10.1214/11-AOS889 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2011, Vol. 39, No. 4, 1916-1962", "doi": "10.1214/11-AOS889", "report-no": "IMS-AOS-AOS889", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article describes a new class of prior distributions for nonparametric\nfunction estimation. The unknown function is modeled as a limit of weighted\nsums of kernels or generator functions indexed by continuous parameters that\ncontrol local and global features such as their translation, dilation,\nmodulation and shape. L\\'{e}vy random fields and their stochastic integrals are\nemployed to induce prior distributions for the unknown functions or,\nequivalently, for the number of kernels and for the parameters governing their\nfeatures. Scaling, shape, and other features of the generating functions are\nlocation-specific to allow quite different function properties in different\nparts of the space, as with wavelet bases and other methods employing\novercomplete dictionaries. We provide conditions under which the stochastic\nexpansions converge in specified Besov or Sobolev norms. Under a Gaussian error\nmodel, this may be viewed as a sparse regression problem, with regularization\ninduced via the L\\'{e}vy random field prior distribution. Posterior inference\nfor the unknown functions is based on a reversible jump Markov chain Monte\nCarlo algorithm. We compare the L\\'{e}vy Adaptive Regression Kernel (LARK)\nmethod to wavelet-based methods using some of the standard test functions, and\nillustrate its flexibility and adaptability in nonstationary applications.\n", "versions": [{"version": "v1", "created": "Wed, 14 Dec 2011 09:28:43 GMT"}], "update_date": "2011-12-15", "authors_parsed": [["Wolpert", "Robert L.", ""], ["Clyde", "Merlise A.", ""], ["Tu", "Chong", ""]]}, {"id": "1112.3228", "submitter": "Peter McCullagh", "authors": "Peter McCullagh, Han Han", "title": "On Bayes' theorem for improper mixtures", "comments": "Published in at http://dx.doi.org/10.1214/11-AOS892 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2011, Vol. 39, No. 4, 2007-2020", "doi": "10.1214/11-AOS892", "report-no": "IMS-AOS-AOS892", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although Bayes's theorem demands a prior that is a probability distribution\non the parameter space, the calculus associated with Bayes's theorem sometimes\ngenerates sensible procedures from improper priors, Pitman's estimator being a\ngood example. However, improper priors may also lead to Bayes procedures that\nare paradoxical or otherwise unsatisfactory, prompting some authors to insist\nthat all priors be proper. This paper begins with the observation that an\nimproper measure on Theta satisfying Kingman's countability condition is in\nfact a probability distribution on the power set. We show how to extend a model\nin such a way that the extended parameter space is the power set. Under an\nadditional finiteness condition, which is needed for the existence of a\nsampling region, the conditions for Bayes's theorem are satisfied by the\nextension. Lack of interference ensures that the posterior distribution in the\nextended space is compatible with the original parameter space. Provided that\nthe key finiteness condition is satisfied, this probabilistic analysis of the\nextended model may be interpreted as a vindication of improper Bayes procedures\nderived from the original model.\n", "versions": [{"version": "v1", "created": "Wed, 14 Dec 2011 14:17:23 GMT"}], "update_date": "2011-12-15", "authors_parsed": [["McCullagh", "Peter", ""], ["Han", "Han", ""]]}, {"id": "1112.3427", "submitter": "Karthik Bharath", "authors": "Karthik Bharath, Vladimir Pozdnyakov and Dipak Dey", "title": "Asymptotics of the Empirical Cross-over Function", "comments": "Submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a combination of heavily trimmed sums and sample quantiles which\narises when examining properties of clustering criteria and prove limit\ntheorems. The object of interest, which we call the Empirical Cross-over\nFunction, is an L-statistic whose weights do not comply with the requisite\nregularity conditions for usage of ex- isting limit results. The law of large\nnumbers, CLT and a functional CLT are proven.\n", "versions": [{"version": "v1", "created": "Thu, 15 Dec 2011 05:38:55 GMT"}, {"version": "v2", "created": "Sat, 28 Jan 2012 15:49:54 GMT"}, {"version": "v3", "created": "Sat, 5 May 2012 23:50:53 GMT"}, {"version": "v4", "created": "Mon, 11 Feb 2013 22:57:00 GMT"}], "update_date": "2013-02-13", "authors_parsed": [["Bharath", "Karthik", ""], ["Pozdnyakov", "Vladimir", ""], ["Dey", "Dipak", ""]]}, {"id": "1112.3450", "submitter": "Jian Huang", "authors": "Jian Huang, Shuangge Ma, Hongzhe Li, Cun-Hui Zhang", "title": "The sparse Laplacian shrinkage estimator for high-dimensional regression", "comments": "Published in at http://dx.doi.org/10.1214/11-AOS897 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2011, Vol. 39, No. 4, 2021-2046", "doi": "10.1214/11-AOS897", "report-no": "IMS-AOS-AOS897", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new penalized method for variable selection and estimation that\nexplicitly incorporates the correlation patterns among predictors. This method\nis based on a combination of the minimax concave penalty and Laplacian\nquadratic associated with a graph as the penalty function. We call it the\nsparse Laplacian shrinkage (SLS) method. The SLS uses the minimax concave\npenalty for encouraging sparsity and Laplacian quadratic penalty for promoting\nsmoothness among coefficients associated with the correlated predictors. The\nSLS has a generalized grouping property with respect to the graph represented\nby the Laplacian quadratic. We show that the SLS possesses an oracle property\nin the sense that it is selection consistent and equal to the oracle Laplacian\nshrinkage estimator with high probability. This result holds in sparse,\nhigh-dimensional settings with p >> n under reasonable conditions. We derive a\ncoordinate descent algorithm for computing the SLS estimates. Simulation\nstudies are conducted to evaluate the performance of the SLS method and a real\ndata example is used to illustrate its application.\n", "versions": [{"version": "v1", "created": "Thu, 15 Dec 2011 08:48:02 GMT"}], "update_date": "2011-12-16", "authors_parsed": [["Huang", "Jian", ""], ["Ma", "Shuangge", ""], ["Li", "Hongzhe", ""], ["Zhang", "Cun-Hui", ""]]}, {"id": "1112.3729", "submitter": "Farida Enikeeva", "authors": "Farida Enikeeva", "title": "On two estimates related to the change-point problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of estimating a smooth functional of an unknown\nsignal with discontinuity from Gaussian observations. The signal is a known\nfunction that depends on an unknown parameter. This problem is closely related\nto the famous change-point problem. We obtain an asymptotic likelihood ratio\nprocess for the noise level tending to 0. Bayesian and maximum likelihood\nestimates are constructed and their relative efficiency is studied. Some\nsimulation results and conclusions on non-asymptotic behavior of these\nestimates are presented.\n", "versions": [{"version": "v1", "created": "Fri, 16 Dec 2011 07:55:22 GMT"}], "update_date": "2011-12-19", "authors_parsed": [["Enikeeva", "Farida", ""]]}, {"id": "1112.3745", "submitter": "Beno\\^ite de Saporta", "authors": "Beno\\^ite de Saporta and Anne G\\'egout-Petit and Laurence Marsalle", "title": "Asymmetry tests for Bifurcating Auto-Regressive Processes with missing\n  data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present symmetry tests for bifurcating autoregressive processes (BAR) when\nsome data are missing. BAR processes typically model cell division data. Each\ncell can be of one of two types \\emph{odd} or \\emph{even}. The goal of this\npaper is to study the possible asymmetry between odd and even cells in a single\nobserved lineage. We first derive asymmetry tests for the lineage itself,\nmodeled by a two-type Galton-Watson process, and then derive tests for the\nobserved BAR process. We present applications on both simulated and real data.\n", "versions": [{"version": "v1", "created": "Fri, 16 Dec 2011 09:43:36 GMT"}], "update_date": "2011-12-19", "authors_parsed": [["de Saporta", "Beno\u00eete", ""], ["G\u00e9gout-Petit", "Anne", ""], ["Marsalle", "Laurence", ""]]}, {"id": "1112.3777", "submitter": "Alexandre Brouste", "authors": "Alexandre Brouste and Stefano M. Iacus", "title": "Parameter estimation for the discretely observed fractional\n  Ornstein-Uhlenbeck process and the Yuima R package", "comments": "15 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO math.ST stat.OT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes consistent and asymptotically Gaussian estimators for the\ndrift, the diffusion coefficient and the Hurst exponent of the discretely\nobserved fractional Ornstein-Uhlenbeck process. For the estimation of the\ndrift, the results are obtained only in the case when 1/2 < H < 3/4. This paper\nalso provides ready-to-use software for the R statistical environment based on\nthe YUIMA package.\n", "versions": [{"version": "v1", "created": "Fri, 16 Dec 2011 12:22:29 GMT"}], "update_date": "2011-12-19", "authors_parsed": [["Brouste", "Alexandre", ""], ["Iacus", "Stefano M.", ""]]}, {"id": "1112.3914", "submitter": "Matthieu Lerasle", "authors": "M. Lerasle and R. I. Oliveira", "title": "Robust empirical mean Estimators", "comments": "47 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study robust estimators of the mean of a probability measure $P$, called\nrobust empirical mean estimators. This elementary construction is then used to\nrevisit a problem of aggregation and a problem of estimator selection,\nextending these methods to not necessarily bounded collections of previous\nestimators. We consider then the problem of robust $M$-estimation. We propose a\nslightly more complicated construction to handle this problem and, as examples\nof applications, we apply our general approach to least-squares density\nestimation, to density estimation with K\\\"ullback loss and to a non-Gaussian,\nunbounded, random design and heteroscedastic regression problem. Finally, we\nshow that our strategy can be used when the data are only assumed to be mixing.\n", "versions": [{"version": "v1", "created": "Fri, 16 Dec 2011 18:36:11 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Lerasle", "M.", ""], ["Oliveira", "R. I.", ""]]}, {"id": "1112.3982", "submitter": "George Yanev", "authors": "M. Ahsanullah, George P. Yanev and Constantin Onica", "title": "Characterizations of Logistic Distribution through Order Statistics with\n  Independent Exponential Shifts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper presents some distributional properties of logistic order\nstatistics subject to independent exponential one-sided and two-sided shifts.\nUtilizing these properties, we extend several known results and obtain some new\ncharacterizations of the logistic distribution.\n", "versions": [{"version": "v1", "created": "Fri, 16 Dec 2011 21:58:03 GMT"}], "update_date": "2011-12-20", "authors_parsed": [["Ahsanullah", "M.", ""], ["Yanev", "George P.", ""], ["Onica", "Constantin", ""]]}, {"id": "1112.4258", "submitter": "Mahdi Soltanolkotabi", "authors": "Mahdi Soltanolkotabi, Emmanuel J. Cand\\'es", "title": "A geometric analysis of subspace clustering with outliers", "comments": "Published in at http://dx.doi.org/10.1214/12-AOS1034 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2012, Vol. 40, No. 4, 2195-2238", "doi": "10.1214/12-AOS1034", "report-no": "IMS-AOS-AOS1034", "categories": "cs.IT cs.LG math.IT math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the problem of clustering a collection of unlabeled data\npoints assumed to lie near a union of lower-dimensional planes. As is common in\ncomputer vision or unsupervised learning applications, we do not know in\nadvance how many subspaces there are nor do we have any information about their\ndimensions. We develop a novel geometric analysis of an algorithm named sparse\nsubspace clustering (SSC) [In IEEE Conference on Computer Vision and Pattern\nRecognition, 2009. CVPR 2009 (2009) 2790-2797. IEEE], which significantly\nbroadens the range of problems where it is provably effective. For instance, we\nshow that SSC can recover multiple subspaces, each of dimension comparable to\nthe ambient dimension. We also prove that SSC can correctly cluster data points\neven when the subspaces of interest intersect. Further, we develop an extension\nof SSC that succeeds when the data set is corrupted with possibly\noverwhelmingly many outliers. Underlying our analysis are clear geometric\ninsights, which may bear on other sparse recovery problems. A numerical study\ncomplements our theoretical analysis and demonstrates the effectiveness of\nthese methods.\n", "versions": [{"version": "v1", "created": "Mon, 19 Dec 2011 07:42:21 GMT"}, {"version": "v2", "created": "Thu, 19 Jan 2012 19:01:38 GMT"}, {"version": "v3", "created": "Mon, 9 Jul 2012 20:30:16 GMT"}, {"version": "v4", "created": "Wed, 11 Jul 2012 14:12:49 GMT"}, {"version": "v5", "created": "Wed, 30 Jan 2013 14:20:53 GMT"}], "update_date": "2013-01-31", "authors_parsed": [["Soltanolkotabi", "Mahdi", ""], ["Cand\u00e9s", "Emmanuel J.", ""]]}, {"id": "1112.4310", "submitter": "Mitsunori Ogawa", "authors": "Mitsunori Ogawa, Akimichi Takemura", "title": "Markov Bases for Typical Block Effect Models of Two-way Contingency\n  Tables", "comments": "16 pages", "journal-ref": "Journal of Multivariate Analysis 112 (2012) 219--229", "doi": null, "report-no": null, "categories": "math.ST math.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Markov basis for statistical model of contingency tables gives a useful tool\nfor performing the conditional test of the model via Markov chain Monte Carlo\nmethod. In this paper we derive explicit forms of Markov bases for change point\nmodels and block diagonal effect models, which are typical block-wise effect\nmodels of two-way contingency tables, and perform conditional tests with some\nreal data sets.\n", "versions": [{"version": "v1", "created": "Mon, 19 Dec 2011 11:31:41 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Ogawa", "Mitsunori", ""], ["Takemura", "Akimichi", ""]]}, {"id": "1112.4413", "submitter": "Mathieu Rosenbaum", "authors": "Mathieu Rosenbaum and Alexandre B. Tsybakov", "title": "Improved Matrix Uncertainty Selector", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the regression model with observation error in the design:\ny=X\\theta* + e, Z=X+N. Here the random vector y in R^n and the random n*p\nmatrix Z are observed, the n*p matrix X is unknown, N is an n*p random noise\nmatrix, e in R^n is a random noise vector, and \\theta* is a vector of unknown\nparameters to be estimated. We consider the setting where the dimension p can\nbe much larger than the sample size n and \\theta* is sparse. Because of the\npresence of the noise matrix N, the commonly used Lasso and Dantzig selector\nare unstable. An alternative procedure called the Matrix Uncertainty (MU)\nselector has been proposed in Rosenbaum and Tsybakov (2010) in order to account\nfor the noise. The properties of the MU selector have been studied in Rosenbaum\nand Tsybakov (2010) for sparse \\theta* under the assumption that the noise\nmatrix N is deterministic and its values are small. In this paper, we propose a\nmodification of the MU selector when N is a random matrix with zero-mean\nentries having the variances that can be estimated. This is, for example, the\ncase in the model where the entries of X are missing at random. We show both\ntheoretically and numerically that, under these conditions, the new estimator\ncalled the Compensated MU selector achieves better accuracy of estimation than\nthe original MU selector.\n", "versions": [{"version": "v1", "created": "Mon, 19 Dec 2011 17:32:15 GMT"}], "update_date": "2011-12-20", "authors_parsed": [["Rosenbaum", "Mathieu", ""], ["Tsybakov", "Alexandre B.", ""]]}, {"id": "1112.4434", "submitter": "Joseph  Salmon", "authors": "Ery Arias-Castro, Joseph Salmon, and Rebecca Willett", "title": "Oracle inequalities and minimax rates for non-local means and related\n  adaptive kernel-based methods", "comments": "49 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.CV cs.IT math.IT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a novel theoretical characterization of the performance\nof non-local means (NLM) for noise removal. NLM has proven effective in a\nvariety of empirical studies, but little is understood fundamentally about how\nit performs relative to classical methods based on wavelets or how various\nparameters (e.g., patch size) should be chosen. For cartoon images and images\nwhich may contain thin features and regular textures, the error decay rates of\nNLM are derived and compared with those of linear filtering, oracle estimators,\nvariable-bandwidth kernel methods, Yaroslavsky's filter and wavelet\nthresholding estimators. The trade-off between global and local search for\nmatching patches is examined, and the bias reduction associated with the local\npolynomial regression version of NLM is analyzed. The theoretical results are\nvalidated via simulations for 2D images corrupted by additive white Gaussian\nnoise.\n", "versions": [{"version": "v1", "created": "Mon, 19 Dec 2011 18:55:22 GMT"}, {"version": "v2", "created": "Thu, 26 Apr 2012 00:09:35 GMT"}], "update_date": "2012-04-27", "authors_parsed": [["Arias-Castro", "Ery", ""], ["Salmon", "Joseph", ""], ["Willett", "Rebecca", ""]]}, {"id": "1112.4519", "submitter": "Djalel Eddine Meskaldji", "authors": "Djalel Eddine Meskaldji and Dimitri Van De Ville and Jean-Philippe\n  Thiran and Stephan Morgenthaler", "title": "A comprehensive error rate for multiple testing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The higher criticism of a family of tests starts with the individual\nuncorrected p-values of each test. It then requires a procedure for deciding\nwhether the collection of p-values indicates the presence of a real effect and\nif possible selects the ones that deserve closer scrutiny. This paper\ninvestigates procedures in which the ordered p-values are compared to an\narbitrary positive and non-decreasing threshold sequence.\n", "versions": [{"version": "v1", "created": "Mon, 19 Dec 2011 22:24:31 GMT"}, {"version": "v2", "created": "Wed, 2 May 2012 15:34:18 GMT"}, {"version": "v3", "created": "Tue, 12 Mar 2013 17:45:09 GMT"}, {"version": "v4", "created": "Wed, 10 Jul 2013 15:41:30 GMT"}, {"version": "v5", "created": "Tue, 23 Feb 2016 11:54:19 GMT"}], "update_date": "2016-02-24", "authors_parsed": [["Meskaldji", "Djalel Eddine", ""], ["Van De Ville", "Dimitri", ""], ["Thiran", "Jean-Philippe", ""], ["Morgenthaler", "Stephan", ""]]}, {"id": "1112.4530", "submitter": "Reason Machete", "authors": "Reason Lesego Machete", "title": "Contrasting Probabilistic Scoring Rules", "comments": "17 pages, 0 figures", "journal-ref": null, "doi": null, "report-no": "MPS-2011-15", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are several scoring rules that one can choose from in order to score\nprobabilistic forecasting models or estimate model parameters. Whilst it is\ngenerally agreed that proper scoring rules are preferable, there is no clear\ncriterion for preferring one proper scoring rule above another. This manuscript\ncompares and contrasts some commonly used proper scoring rules and provides\nguidance on scoring rule selection. In particular, it is shown that the\nlogarithmic scoring rule prefers erring with more uncertainty, the spherical\nscoring rule prefers erring with lower uncertainty, whereas the other scoring\nrules are indifferent to either option.\n", "versions": [{"version": "v1", "created": "Mon, 19 Dec 2011 23:43:20 GMT"}, {"version": "v2", "created": "Mon, 19 Mar 2012 12:50:31 GMT"}, {"version": "v3", "created": "Thu, 19 Jul 2012 12:44:46 GMT"}, {"version": "v4", "created": "Tue, 24 Jul 2012 14:57:16 GMT"}], "update_date": "2012-07-25", "authors_parsed": [["Machete", "Reason Lesego", ""]]}, {"id": "1112.4554", "submitter": "Sergiy Koshkin", "authors": "Sergiy Koshkin and Yunwei Cui", "title": "Binomial ARMA count series from renewal processes", "comments": "11 pages, no figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a new method for generating stationary integer-valued\ntime series from renewal processes. We prove that if the lifetime distribution\nof renewal processes is nonlattice and the probability generating function is\nrational, then the generated time series satisfy causal and invertible ARMA\ntype stochastic difference equations. The result provides an easy method for\ngenerating integer-valued time series with ARMA type autocovariance functions.\nExamples of generating binomial ARMA(p,p-1) series from lifetime distributions\nwith constant hazard rates after lag p are given as an illustration. An\nestimation method is developed for the AR(p) cases.\n", "versions": [{"version": "v1", "created": "Tue, 20 Dec 2011 03:33:24 GMT"}], "update_date": "2011-12-21", "authors_parsed": [["Koshkin", "Sergiy", ""], ["Cui", "Yunwei", ""]]}, {"id": "1112.4565", "submitter": "Arlene K.H. Kim", "authors": "Arlene K.H. Kim", "title": "Minimax bounds for estimation of normal mixtures", "comments": "Published in at http://dx.doi.org/10.3150/13-BEJ542 the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2014, Vol. 20, No. 4, 1802-1818", "doi": "10.3150/13-BEJ542", "report-no": "IMS-BEJ-BEJ542", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with minimax rates of convergence for estimation of density\nfunctions on the real line. The densities are assumed to be location mixtures\nof normals, a global regularity requirement that creates subtle difficulties\nfor the application of standard minimax lower bound methods. Using novel\nFourier and Hermite polynomial techniques, we determine the minimax optimal\nrate - slightly larger than the parametric rate - under squared error loss. For\nHellinger loss, we provide a minimax lower bound using ideas modified from the\nsquared error loss case.\n", "versions": [{"version": "v1", "created": "Tue, 20 Dec 2011 04:19:42 GMT"}, {"version": "v2", "created": "Thu, 18 Oct 2012 08:48:37 GMT"}, {"version": "v3", "created": "Sat, 22 Jun 2013 12:02:50 GMT"}, {"version": "v4", "created": "Tue, 21 Oct 2014 11:10:48 GMT"}], "update_date": "2014-10-22", "authors_parsed": [["Kim", "Arlene K. H.", ""]]}, {"id": "1112.4735", "submitter": "Jean-Michel Loubes", "authors": "H\\'el\\`ene Lescornel (IMT), Jean-Michel Loubes (IMT), Claudie Chabriac\n  (IMT)", "title": "Unbiased risk estimation method for covariance estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a model selection estimator of the covariance of a random\nprocess. Using the Unbiased Risk Estimation (URE) method, we build an estimator\nof the risk which allows to select an estimator in a collection of model. Then,\nwe present an oracle inequality which ensures that the risk of the selected\nestimator is close to the risk of the oracle. Simulations show the efficiency\nof this methodology.\n", "versions": [{"version": "v1", "created": "Tue, 20 Dec 2011 15:35:35 GMT"}], "update_date": "2011-12-22", "authors_parsed": [["Lescornel", "H\u00e9l\u00e8ne", "", "IMT"], ["Loubes", "Jean-Michel", "", "IMT"], ["Chabriac", "Claudie", "", "IMT"]]}, {"id": "1112.4951", "submitter": "Takumi Saegusa", "authors": "Takumi Saegusa, Jon A. Wellner", "title": "Weighted likelihood estimation under two-phase sampling", "comments": "Published in at http://dx.doi.org/10.1214/12-AOS1073 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2013, Vol. 41, No. 1, 269-295", "doi": "10.1214/12-AOS1073", "report-no": "IMS-AOS-AOS1073", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop asymptotic theory for weighted likelihood estimators (WLE) under\ntwo-phase stratified sampling without replacement. We also consider several\nvariants of WLEs involving estimated weights and calibration. A set of\nempirical process tools are developed including a Glivenko-Cantelli theorem, a\ntheorem for rates of convergence of M-estimators, and a Donsker theorem for the\ninverse probability weighted empirical processes under two-phase sampling and\nsampling without replacement at the second phase. Using these general results,\nwe derive asymptotic distributions of the WLE of a finite-dimensional parameter\nin a general semiparametric model where an estimator of a nuisance parameter is\nestimable either at regular or nonregular rates. We illustrate these results\nand methods in the Cox model with right censoring and interval censoring. We\ncompare the methods via their asymptotic variances under both sampling without\nreplacement and the more usual (and easier to analyze) assumption of Bernoulli\nsampling at the second phase.\n", "versions": [{"version": "v1", "created": "Wed, 21 Dec 2011 08:40:37 GMT"}, {"version": "v2", "created": "Wed, 18 Jan 2012 12:40:07 GMT"}, {"version": "v3", "created": "Mon, 8 Apr 2013 12:13:16 GMT"}], "update_date": "2013-04-09", "authors_parsed": [["Saegusa", "Takumi", ""], ["Wellner", "Jon A.", ""]]}, {"id": "1112.4988", "submitter": "Martien van Zuijlen", "authors": "Martien C. A. van Zuijlen", "title": "On a conjecture concerning the sum of independent Rademacher random\n  variables", "comments": "12 pages, 3 references, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is shown that at least 50% of the probability mass of a sum of independent\nRademacher random variables is within one standard deviation from its mean.\nThis lower bound is sharp, it is much better than for instance the bound that\ncan be obtained from application of the Chebishev inequality and the bound will\nhave nice applications in finite sampling theory and in random walk theory.\nThis old conjecture is of interest in itself, but has also an appealing\nreformulation in probability theory and in geometry.\n", "versions": [{"version": "v1", "created": "Wed, 21 Dec 2011 11:08:51 GMT"}], "update_date": "2011-12-22", "authors_parsed": [["van Zuijlen", "Martien C. A.", ""]]}, {"id": "1112.5123", "submitter": "Giovanni Pistone", "authors": "Giovanni Pistone", "title": "Marginal Polytope of a Deformed Exponential Family", "comments": "Submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A deformed logarithm function called $q$-logarithm has received considerable\nattention by physicist after its introduction by C. Tsallis. J. Naudts has\nproposed a generalization called $\\phi$-logarithm and he has derived the basic\nproperties of $\\phi$-exponential families. In this paper we study the related\nnotion of marginal polytope in the case of a finite state space.\n", "versions": [{"version": "v1", "created": "Wed, 21 Dec 2011 18:27:25 GMT"}], "update_date": "2011-12-22", "authors_parsed": [["Pistone", "Giovanni", ""]]}, {"id": "1112.5389", "submitter": "Loic Le Gratiet", "authors": "Loic Le Gratiet (LPMA, - M\\'ethodes d'Analyse Stochastique des Codes\n  et Traitements Num\\'eriques)", "title": "Bayesian analysis of hierarchical multi-fidelity codes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with the Gaussian process based approximation of a code\nwhich can be run at different levels of accuracy. This method, which is a\nparticular case of co-kriging, allows us to improve a surrogate model of a\ncomplex computer code using fast approximations of it. In particular, we focus\non the case of a large number of code levels on the one hand and on a Bayesian\napproach when we have two levels on the other hand. The main results of this\npaper are a new approach to estimate the model parameters which provides a\nclosed form expression for an important parameter of the model (the scale\nfactor), a reduction of the numerical complexity by simplifying the covariance\nmatrix inversion, and a new Bayesian modelling that gives an explicit\nrepresentation of the joint distribution of the parameters and that is not\ncomputationally expensive. A thermodynamic example is used to illustrate the\ncomparison between 2-level and 3-level co-kriging.\n", "versions": [{"version": "v1", "created": "Thu, 22 Dec 2011 17:08:15 GMT"}, {"version": "v2", "created": "Mon, 24 Sep 2012 19:34:06 GMT"}], "update_date": "2012-09-25", "authors_parsed": [["Gratiet", "Loic Le", "", "LPMA, - M\u00e9thodes d'Analyse Stochastique des Codes\n  et Traitements Num\u00e9riques"]]}, {"id": "1112.5448", "submitter": "Stanislav Minsker", "authors": "Stanislav Minsker", "title": "On Some Extensions of Bernstein's Inequality for Self-adjoint Operators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present some extensions of Bernstein's concentration inequality for random\nmatrices. This inequality has become a useful and powerful tool for many\nproblems in statistics, signal processing and theoretical computer science. The\nmain feature of our bounds is that, unlike the majority of previous related\nresults, they do not depend on the dimension $d$ of the ambient space. Instead,\nthe dimension factor is replaced by the \"effective rank\" associated with the\nunderlying distribution that is bounded from above by $d$. In particular, this\nmakes an extension to the infinite-dimensional setting possible. Our\ninequalities refine earlier results in this direction obtained by D. Hsu, S. M.\nKakade and T. Zhang.\n", "versions": [{"version": "v1", "created": "Thu, 22 Dec 2011 20:44:42 GMT"}, {"version": "v2", "created": "Tue, 12 Mar 2013 16:23:46 GMT"}, {"version": "v3", "created": "Fri, 14 Apr 2017 18:26:35 GMT"}], "update_date": "2017-04-18", "authors_parsed": [["Minsker", "Stanislav", ""]]}, {"id": "1112.5506", "submitter": "Joshua Vogelstein", "authors": "Joshua T. Vogelstein and Carey E. Priebe", "title": "Shuffled Graph Classification: Theory and Connectome Applications", "comments": "12 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a formalism to address statistical pattern recognition of graph\nvalued data. Of particular interest is the case of all graphs having the same\nnumber of uniquely labeled vertices. When the vertex labels are latent, such\ngraphs are called shuffled graphs. Our formalism provides insight to trivially\nanswer a number of open statistical questions including: (i) under what\nconditions does shuffling the vertices degrade classification performance and\n(ii) do universally consistent graph classifiers exist? The answers to these\nquestions lead to practical heuristic algorithms with state-of-the-art finite\nsample performance, in agreement with our theoretical asymptotics.\n", "versions": [{"version": "v1", "created": "Fri, 23 Dec 2011 02:47:31 GMT"}, {"version": "v2", "created": "Tue, 16 Oct 2012 09:57:12 GMT"}], "update_date": "2012-10-17", "authors_parsed": [["Vogelstein", "Joshua T.", ""], ["Priebe", "Carey E.", ""]]}, {"id": "1112.5634", "submitter": "Mathieu Sart", "authors": "Mathieu Sart", "title": "Model selection for Poisson processes with covariates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We observe $n$ inhomogeneous Poisson processes with covariates and aim at\nestimating their intensities. We assume that the intensity of each Poisson\nprocess is of the form $s (\\cdot, x)$ where $x$ is the covariate and where $s$\nis an unknown function. We propose a model selection approach where the models\nare used to approximate the multivariate function $s$. We show that our\nestimator satisfies an oracle-type inequality under very weak assumptions both\non the intensities and the models. By using an Hellinger-type loss, we\nestablish non-asymptotic risk bounds and specify them under several kind of\nassumptions on the target function $s$ such as being smooth or a product\nfunction. Besides, we show that our estimation procedure is robust with respect\nto these assumptions.\n", "versions": [{"version": "v1", "created": "Fri, 23 Dec 2011 18:53:55 GMT"}, {"version": "v2", "created": "Thu, 13 Jun 2013 16:15:23 GMT"}], "update_date": "2013-06-14", "authors_parsed": [["Sart", "Mathieu", ""]]}, {"id": "1112.5635", "submitter": "Rina Foygel", "authors": "Rina Foygel and Mathias Drton", "title": "Bayesian model choice and information criteria in sparse generalized\n  linear models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider Bayesian model selection in generalized linear models that are\nhigh-dimensional, with the number of covariates p being large relative to the\nsample size n, but sparse in that the number of active covariates is small\ncompared to p. Treating the covariates as random and adopting an asymptotic\nscenario in which p increases with n, we show that Bayesian model selection\nusing certain priors on the set of models is asymptotically equivalent to\nselecting a model using an extended Bayesian information criterion. Moreover,\nwe prove that the smallest true model is selected by either of these methods\nwith probability tending to one. Having addressed random covariates, we are\nalso able to give a consistency result for pseudo-likelihood approaches to\nhigh-dimensional sparse graphical modeling. Experiments on real data\ndemonstrate good performance of the extended Bayesian information criterion for\nregression and for graphical models.\n", "versions": [{"version": "v1", "created": "Fri, 23 Dec 2011 18:54:37 GMT"}], "update_date": "2011-12-26", "authors_parsed": [["Foygel", "Rina", ""], ["Drton", "Mathias", ""]]}, {"id": "1112.5659", "submitter": "Ilias Diakonikolas", "authors": "Constantinos Daskalakis, Ilias Diakonikolas, Rocco A. Servedio,\n  Gregory Valiant, Paul Valiant", "title": "Testing $k$-Modal Distributions: Optimal Algorithms via Reductions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give highly efficient algorithms, and almost matching lower bounds, for a\nrange of basic statistical problems that involve testing and estimating the L_1\ndistance between two k-modal distributions $p$ and $q$ over the discrete domain\n$\\{1,\\dots,n\\}$. More precisely, we consider the following four problems: given\nsample access to an unknown k-modal distribution $p$,\n  Testing identity to a known or unknown distribution:\n  1. Determine whether $p = q$ (for an explicitly given k-modal distribution\n$q$) versus $p$ is $\\eps$-far from $q$;\n  2. Determine whether $p=q$ (where $q$ is available via sample access) versus\n$p$ is $\\eps$-far from $q$;\n  Estimating $L_1$ distance (\"tolerant testing'') against a known or unknown\ndistribution:\n  3. Approximate $d_{TV}(p,q)$ to within additive $\\eps$ where $q$ is an\nexplicitly given k-modal distribution $q$;\n  4. Approximate $d_{TV}(p,q)$ to within additive $\\eps$ where $q$ is available\nvia sample access.\n  For each of these four problems we give sub-logarithmic sample algorithms,\nthat we show are tight up to additive $\\poly(k)$ and multiplicative\n$\\polylog\\log n+\\polylog k$ factors. Thus our bounds significantly improve the\nprevious results of \\cite{BKR:04}, which were for testing identity of\ndistributions (items (1) and (2) above) in the special cases k=0 (monotone\ndistributions) and k=1 (unimodal distributions) and required $O((\\log n)^3)$\nsamples.\n  As our main conceptual contribution, we introduce a new reduction-based\napproach for distribution-testing problems that lets us obtain all the above\nresults in a unified way. Roughly speaking, this approach enables us to\ntransform various distribution testing problems for k-modal distributions over\n$\\{1,\\dots,n\\}$ to the corresponding distribution testing problems for\nunrestricted distributions over a much smaller domain $\\{1,\\dots,\\ell\\}$ where\n$\\ell = O(k \\log n).$\n", "versions": [{"version": "v1", "created": "Fri, 23 Dec 2011 20:50:05 GMT"}], "update_date": "2011-12-26", "authors_parsed": [["Daskalakis", "Constantinos", ""], ["Diakonikolas", "Ilias", ""], ["Servedio", "Rocco A.", ""], ["Valiant", "Gregory", ""], ["Valiant", "Paul", ""]]}, {"id": "1112.5806", "submitter": "Tomasz Suslo", "authors": "Tomasz Suslo", "title": "Complex-Valued Best Linear Unbiased Estimator of an Unknown Constant\n  Mean of White Noise", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper the complex-valued best linear unbiased estimator of an unknown\nconstant mean of white noise was derived the ordinary least-squares estimator\nof an unknown constant mean of random field (arithmetic mean) charged by an\nimaginary error.\n", "versions": [{"version": "v1", "created": "Mon, 26 Dec 2011 02:54:49 GMT"}], "update_date": "2011-12-30", "authors_parsed": [["Suslo", "Tomasz", ""]]}, {"id": "1112.5854", "submitter": "Mohamed Cherfi", "authors": "Mohamed Cherfi", "title": "On Bayesian Estimation via Divergences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this Note we introduce a new methodology for Bayesian inference through\nthe use of $\\phi$-divergences and the duality technique. The asymptotic laws of\nthe estimates are established.\n", "versions": [{"version": "v1", "created": "Mon, 26 Dec 2011 13:04:36 GMT"}], "update_date": "2011-12-30", "authors_parsed": [["Cherfi", "Mohamed", ""]]}, {"id": "1112.5890", "submitter": "Yuri Golubev", "authors": "Yuri Golubev", "title": "Adaptive spectral regularizations of high dimensional linear models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on recovering an unknown vector $\\beta$ from the noisy\ndata $Y=X\\beta +\\sigma\\xi$, where $X$ is a known $n\\times p$-matrix, $\\xi $ is\na standard white Gaussian noise, and $\\sigma$ is an unknown noise level. In\norder to estimate $\\beta$, a spectral regularization method is used, and our\ngoal is to choose its regularization parameter with the help of the data $Y$.\nIn this paper, we deal solely with regularization methods based on the\nso-called ordered smoothers and provide some oracle inequalities in the case,\nwhere the noise level is unknown.\n", "versions": [{"version": "v1", "created": "Mon, 26 Dec 2011 20:33:29 GMT"}], "update_date": "2011-12-30", "authors_parsed": [["Golubev", "Yuri", ""]]}, {"id": "1112.6151", "submitter": "Robert J. Adler", "authors": "Robert J. Adler, Eliran Subag, Jonathan E. Taylor", "title": "Rotation and scale space random fields and the Gaussian kinematic\n  formula", "comments": "Published in at http://dx.doi.org/10.1214/12-AOS1055 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2012, Vol. 40, No. 6, 2910-2942", "doi": "10.1214/12-AOS1055", "report-no": "IMS-AOS-AOS1055", "categories": "math.PR math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a new approach, along with extensions, to results in two important\npapers of Worsley, Siegmund and coworkers closely tied to the statistical\nanalysis of fMRI (functional magnetic resonance imaging) brain data. These\npapers studied approximations for the exceedence probabilities of scale and\nrotation space random fields, the latter playing an important role in the\nstatistical analysis of fMRI data. The techniques used there came either from\nthe Euler characteristic heuristic or via tube formulae, and to a large extent\nwere carefully attuned to the specific examples of the paper. This paper treats\nthe same problem, but via calculations based on the so-called Gaussian\nkinematic formula. This allows for extensions of the Worsley-Siegmund results\nto a wide class of non-Gaussian cases. In addition, it allows one to obtain\nresults for rotation space random fields in any dimension via reasonably\nstraightforward Riemannian geometric calculations. Previously only the\ntwo-dimensional case could be covered, and then only via computer algebra. By\nadopting this more structured approach to this particular problem, a solution\npath for other, related problems becomes clearer.\n", "versions": [{"version": "v1", "created": "Wed, 28 Dec 2011 17:13:01 GMT"}, {"version": "v2", "created": "Tue, 19 Feb 2013 08:31:42 GMT"}], "update_date": "2013-02-20", "authors_parsed": [["Adler", "Robert J.", ""], ["Subag", "Eliran", ""], ["Taylor", "Jonathan E.", ""]]}, {"id": "1112.6235", "submitter": "Ery Arias-Castro", "authors": "Ery Arias-Castro", "title": "Detecting a Vector Based on Linear Measurements", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT math.IT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a situation where the state of a system is represented by a\nreal-valued vector. Under normal circumstances, the vector is zero, while an\nevent manifests as non-zero entries in this vector, possibly few. Our interest\nis in the design of algorithms that can reliably detect events (i.e., test\nwhether the vector is zero or not) with the least amount of information. We\nplace ourselves in a situation, now common in the signal processing literature,\nwhere information about the vector comes in the form of noisy linear\nmeasurements. We derive information bounds in an active learning setup and\nexhibit some simple near-optimal algorithms. In particular, our results show\nthat the task of detection within this setting is at once much easier, simpler\nand different than the tasks of estimation and support recovery.\n", "versions": [{"version": "v1", "created": "Thu, 29 Dec 2011 06:22:40 GMT"}], "update_date": "2011-12-30", "authors_parsed": [["Arias-Castro", "Ery", ""]]}, {"id": "1112.6363", "submitter": "Cun-Hui Zhang", "authors": "Jian Huang and Cun-Hui Zhang", "title": "Estimation And Selection Via Absolute Penalized Convex Minimization And\n  Its Multistage Adaptive Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The $\\ell_1$-penalized method, or the Lasso, has emerged as an important tool\nfor the analysis of large data sets. Many important results have been obtained\nfor the Lasso in linear regression which have led to a deeper understanding of\nhigh-dimensional statistical problems. In this article, we consider a class of\nweighted $\\ell_1$-penalized estimators for convex loss functions of a general\nform, including the generalized linear models. We study the estimation,\nprediction, selection and sparsity properties of the weighted\n$\\ell_1$-penalized estimator in sparse, high-dimensional settings where the\nnumber of predictors $p$ can be much larger than the sample size $n$. Adaptive\nLasso is considered as a special case. A multistage method is developed to\napply an adaptive Lasso recursively. We provide $\\ell_q$ oracle inequalities, a\ngeneral selection consistency theorem, and an upper bound on the dimension of\nthe Lasso estimator. Important models including the linear regression, logistic\nregression and log-linear models are used throughout to illustrate the\napplications of the general results.\n", "versions": [{"version": "v1", "created": "Thu, 29 Dec 2011 18:17:35 GMT"}], "update_date": "2011-12-30", "authors_parsed": [["Huang", "Jian", ""], ["Zhang", "Cun-Hui", ""]]}, {"id": "1112.6411", "submitter": "Ali Jalali", "authors": "Christopher C. Johnson, Ali Jalali and Pradeep Ravikumar", "title": "High-dimensional Sparse Inverse Covariance Estimation using Greedy\n  Methods", "comments": "Accepted to AI STAT 2012 for Oral Presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider the task of estimating the non-zero pattern of the\nsparse inverse covariance matrix of a zero-mean Gaussian random vector from a\nset of iid samples. Note that this is also equivalent to recovering the\nunderlying graph structure of a sparse Gaussian Markov Random Field (GMRF). We\npresent two novel greedy approaches to solving this problem. The first\nestimates the non-zero covariates of the overall inverse covariance matrix\nusing a series of global forward and backward greedy steps. The second\nestimates the neighborhood of each node in the graph separately, again using\ngreedy forward and backward steps, and combines the intermediate neighborhoods\nto form an overall estimate. The principal contribution of this paper is a\nrigorous analysis of the sparsistency, or consistency in recovering the\nsparsity pattern of the inverse covariance matrix. Surprisingly, we show that\nboth the local and global greedy methods learn the full structure of the model\nwith high probability given just $O(d\\log(p))$ samples, which is a\n\\emph{significant} improvement over state of the art $\\ell_1$-regularized\nGaussian MLE (Graphical Lasso) that requires $O(d^2\\log(p))$ samples. Moreover,\nthe restricted eigenvalue and smoothness conditions imposed by our greedy\nmethods are much weaker than the strong irrepresentable conditions required by\nthe $\\ell_1$-regularization based methods. We corroborate our results with\nextensive simulations and examples, comparing our local and global greedy\nmethods to the $\\ell_1$-regularized Gaussian MLE as well as the Neighborhood\nGreedy method to that of nodewise $\\ell_1$-regularized linear regression\n(Neighborhood Lasso).\n", "versions": [{"version": "v1", "created": "Thu, 29 Dec 2011 20:35:40 GMT"}], "update_date": "2012-02-28", "authors_parsed": [["Johnson", "Christopher C.", ""], ["Jalali", "Ali", ""], ["Ravikumar", "Pradeep", ""]]}]