[{"id": "1411.0081", "submitter": "Guangming Pan", "authors": "Jiti Gao, Xiao Han, Guangming Pan and Yanrong Yang", "title": "High Dimensional Correlation Matrices: CLT and Its Applications", "comments": "78 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical inferences for sample correlation matrices are important in high\ndimensional data analysis. Motivated by this, this paper establishes a new\ncentral limit theorem (CLT) for a linear spectral statistic (LSS) of high\ndimensional sample correlation matrices for the case where the dimension p and\nthe sample size $n$ are comparable. This result is of independent interest in\nlarge dimensional random matrix theory. Meanwhile, we apply the linear spectral\nstatistic to an independence test for $p$ random variables, and then an\nequivalence test for p factor loadings and $n$ factors in a factor model. The\nfinite sample performance of the proposed test shows its applicability and\neffectiveness in practice. An empirical application to test the independence of\nhousehold incomes from different cities in China is also conducted.\n", "versions": [{"version": "v1", "created": "Sat, 1 Nov 2014 07:56:34 GMT"}], "update_date": "2014-11-04", "authors_parsed": [["Gao", "Jiti", ""], ["Han", "Xiao", ""], ["Pan", "Guangming", ""], ["Yang", "Yanrong", ""]]}, {"id": "1411.0169", "submitter": "Ilias Diakonikolas", "authors": "Siu-On Chan, Ilias Diakonikolas, Rocco A. Servedio, Xiaorui Sun", "title": "Near-Optimal Density Estimation in Near-Linear Time Using Variable-Width\n  Histograms", "comments": "conference version appears in NIPS 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $p$ be an unknown and arbitrary probability distribution over $[0,1)$. We\nconsider the problem of {\\em density estimation}, in which a learning algorithm\nis given i.i.d. draws from $p$ and must (with high probability) output a\nhypothesis distribution that is close to $p$. The main contribution of this\npaper is a highly efficient density estimation algorithm for learning using a\nvariable-width histogram, i.e., a hypothesis distribution with a piecewise\nconstant probability density function.\n  In more detail, for any $k$ and $\\epsilon$, we give an algorithm that makes\n$\\tilde{O}(k/\\epsilon^2)$ draws from $p$, runs in $\\tilde{O}(k/\\epsilon^2)$\ntime, and outputs a hypothesis distribution $h$ that is piecewise constant with\n$O(k \\log^2(1/\\epsilon))$ pieces. With high probability the hypothesis $h$\nsatisfies $d_{\\mathrm{TV}}(p,h) \\leq C \\cdot \\mathrm{opt}_k(p) + \\epsilon$,\nwhere $d_{\\mathrm{TV}}$ denotes the total variation distance (statistical\ndistance), $C$ is a universal constant, and $\\mathrm{opt}_k(p)$ is the smallest\ntotal variation distance between $p$ and any $k$-piecewise constant\ndistribution. The sample size and running time of our algorithm are optimal up\nto logarithmic factors. The \"approximation factor\" $C$ in our result is\ninherent in the problem, as we prove that no algorithm with sample size bounded\nin terms of $k$ and $\\epsilon$ can achieve $C<2$ regardless of what kind of\nhypothesis distribution it uses.\n", "versions": [{"version": "v1", "created": "Sat, 1 Nov 2014 21:03:59 GMT"}], "update_date": "2014-11-04", "authors_parsed": [["Chan", "Siu-On", ""], ["Diakonikolas", "Ilias", ""], ["Servedio", "Rocco A.", ""], ["Sun", "Xiaorui", ""]]}, {"id": "1411.0183", "submitter": "Taposh Banerjee", "authors": "Taposh Banerjee and Venugopal V. Veeravalli", "title": "Data-Efficient Quickest Outlying Sequence Detection in Sensor Networks", "comments": "Submitted to IEEE Transactions on Signal Processing, Nov 2014. arXiv\n  admin note: text overlap with arXiv:1408.4747", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT math.IT math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A sensor network is considered where at each sensor a sequence of random\nvariables is observed. At each time step, a processed version of the\nobservations is transmitted from the sensors to a common node called the fusion\ncenter. At some unknown point in time the distribution of observations at an\nunknown subset of the sensor nodes changes. The objective is to detect the\noutlying sequences as quickly as possible, subject to constraints on the false\nalarm rate, the cost of observations taken at each sensor, and the cost of\ncommunication between the sensors and the fusion center. Minimax formulations\nare proposed for the above problem and algorithms are proposed that are shown\nto be asymptotically optimal for the proposed formulations, as the false alarm\nrate goes to zero. It is also shown, via numerical studies, that the proposed\nalgorithms perform significantly better than those based on fractional\nsampling, in which the classical algorithms from the literature are used and\nthe constraint on the cost of observations is met by using the outcome of a\nsequence of biased coin tosses, independent of the observation process.\n", "versions": [{"version": "v1", "created": "Sat, 1 Nov 2014 23:27:12 GMT"}, {"version": "v2", "created": "Tue, 4 Nov 2014 11:11:45 GMT"}], "update_date": "2014-11-05", "authors_parsed": [["Banerjee", "Taposh", ""], ["Veeravalli", "Venugopal V.", ""]]}, {"id": "1411.0229", "submitter": "M\\'elanie Blazere", "authors": "M\\'elanie Blaz\\`ere, Fabrice Gamboa and Jean-Michel Loubes", "title": "A unified framework for the study of the PLS estimator's properties", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a new approach to study the properties of the\nPartial Least Squares (PLS) estimator. This approach relies on the link between\nPLS and discrete orthogonal polynomials. Indeed many important PLS objects can\nbe expressed in terms of some specific discrete orthogonal polynomials, called\nthe residual polynomials. Based on the explicit analytical expression we have\nstated for these polynomials in terms of signal and noise, we provide a new\nframework for the study of PLS. Furthermore, we show that this new approach\nallows to simplify and retreive independent proofs of many classical results\n(proved earlier by different authors using various approaches and tools). This\ngeneral and unifying approach also sheds new light on PLS and helps to gain\ninsight on its properties.\n", "versions": [{"version": "v1", "created": "Sun, 2 Nov 2014 09:00:17 GMT"}], "update_date": "2014-11-04", "authors_parsed": [["Blaz\u00e8re", "M\u00e9lanie", ""], ["Gamboa", "Fabrice", ""], ["Loubes", "Jean-Michel", ""]]}, {"id": "1411.0288", "submitter": "Eunho Yang", "authors": "Eunho Yang, Pradeep Ravikumar, Genevera I. Allen, Yulia Baker,\n  Ying-Wooi Wan, Zhandong Liu", "title": "A General Framework for Mixed Graphical Models", "comments": "40 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  \"Mixed Data\" comprising a large number of heterogeneous variables (e.g.\ncount, binary, continuous, skewed continuous, among other data types) are\nprevalent in varied areas such as genomics and proteomics, imaging genetics,\nnational security, social networking, and Internet advertising. There have been\nlimited efforts at statistically modeling such mixed data jointly, in part\nbecause of the lack of computationally amenable multivariate distributions that\ncan capture direct dependencies between such mixed variables of different\ntypes. In this paper, we address this by introducing a novel class of Block\nDirected Markov Random Fields (BDMRFs). Using the basic building block of\nnode-conditional univariate exponential families from Yang et al. (2012), we\nintroduce a class of mixed conditional random field distributions, that are\nthen chained according to a block-directed acyclic graph to form our class of\nBlock Directed Markov Random Fields (BDMRFs). The Markov independence graph\nstructure underlying a BDMRF thus has both directed and undirected edges. We\nintroduce conditions under which these distributions exist and are\nnormalizable, study several instances of our models, and propose scalable\npenalized conditional likelihood estimators with statistical guarantees for\nrecovering the underlying network structure. Simulations as well as an\napplication to learning mixed genomic networks from next generation sequencing\nexpression data and mutation data demonstrate the versatility of our methods.\n", "versions": [{"version": "v1", "created": "Sun, 2 Nov 2014 18:12:12 GMT"}], "update_date": "2014-11-04", "authors_parsed": [["Yang", "Eunho", ""], ["Ravikumar", "Pradeep", ""], ["Allen", "Genevera I.", ""], ["Baker", "Yulia", ""], ["Wan", "Ying-Wooi", ""], ["Liu", "Zhandong", ""]]}, {"id": "1411.0393", "submitter": "Hohsuk Noh", "authors": "Natalie Neumeyer, Hohsuk Noh and Ingrid Van Keilegom", "title": "Heteroscedastic semiparametric transformation models: estimation and\n  testing for validity", "comments": "33 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider a heteroscedastic transformation model, where the\ntransformation belongs to a parametric family of monotone transformations, the\nregression and variance function are modelled nonparametrically and the error\nis independent of the multidimensional covariates. In this model, we first\nconsider the estimation of the unknown components of the model, namely the\ntransformation parameter, regression and variance function and the distribution\nof the error. We show the asymptotic normality of the proposed estimators.\nSecond, we propose tests for the validity of the model, and establish the\nlimiting distribution of the test statistics under the null hypothesis. A\nbootstrap procedure is proposed to approximate the critical values of the\ntests. Finally, we carry out a simulation study to verify the small sample\nbehavior of the proposed estimators and tests.\n", "versions": [{"version": "v1", "created": "Mon, 3 Nov 2014 08:48:37 GMT"}, {"version": "v2", "created": "Thu, 27 Nov 2014 02:18:07 GMT"}], "update_date": "2014-12-01", "authors_parsed": [["Neumeyer", "Natalie", ""], ["Noh", "Hohsuk", ""], ["Van Keilegom", "Ingrid", ""]]}, {"id": "1411.0515", "submitter": "L.I. Galtchouk", "authors": "L.I. Galtchouk, S.M. Pergamenshchikov", "title": "Efficient pointwise estimation based on discrete data in ergodic\n  nonparametric diffusions", "comments": "Published at http://dx.doi.org/10.3150/14-BEJ655 in the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2015, Vol. 21, No. 4, 2569-2594", "doi": "10.3150/14-BEJ655", "report-no": "IMS-BEJ-BEJ655", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A truncated sequential procedure is constructed for estimating the drift\ncoefficient at a given state point based on discrete data of ergodic diffusion\nprocess. A nonasymptotic upper bound is obtained for a pointwise absolute error\nrisk. The optimal convergence rate and a sharp constant in the bounds are found\nfor the asymptotic pointwise minimax risk. As a consequence, the efficiency is\nobtained of the proposed sequential procedure.\n", "versions": [{"version": "v1", "created": "Mon, 3 Nov 2014 15:05:22 GMT"}, {"version": "v2", "created": "Mon, 11 May 2015 06:58:07 GMT"}, {"version": "v3", "created": "Fri, 18 Sep 2015 13:30:38 GMT"}], "update_date": "2015-09-21", "authors_parsed": [["Galtchouk", "L. I.", ""], ["Pergamenshchikov", "S. M.", ""]]}, {"id": "1411.0793", "submitter": "Prithwish Bhaumik", "authors": "Prithwish Bhaumik and Subhashis Ghosal", "title": "Bayesian two-step estimation in differential equation models", "comments": "arXiv admin note: substantial text overlap with arXiv:1403.0609", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ordinary differential equations (ODEs) are used to model dynamic systems\nappearing in engineering, physics, biomedical sciences and many other fields.\nThese equations contain unknown parameters, say $\\bm\\theta$ of physical\nsignificance which have to be estimated from the noisy data. Often there is no\nclosed form analytic solution of the equations and hence we cannot use the\nusual non-linear least squares technique to estimate the unknown parameters.\nThere is a two-step approach to solve this problem, where the first step\ninvolves fitting the data nonparametrically. In the second step the parameter\nis estimated by minimizing the distance between the nonparametrically estimated\nderivative and the derivative suggested by the system of ODEs. The statistical\naspects of this approach have been studied under the frequentist framework. We\nconsider this two-step estimation under the Bayesian framework. The response\nvariable is allowed to be multidimensional and the true mean function of it is\nnot assumed to be in the model. We induce a prior on the regression function\nusing a random series based on the B-spline basis functions. We establish the\nBernstein-von Mises theorem for the posterior distribution of the parameter of\ninterest. Interestingly, even though the posterior distribution of the\nregression function based on splines converges at a rate slower than\n$n^{-1/2}$, the parameter vector $\\bm\\theta$ is nevertheless estimated at\n$n^{-1/2}$ rate.\n", "versions": [{"version": "v1", "created": "Tue, 4 Nov 2014 05:55:27 GMT"}], "update_date": "2014-11-05", "authors_parsed": [["Bhaumik", "Prithwish", ""], ["Ghosal", "Subhashis", ""]]}, {"id": "1411.0800", "submitter": "Ying  Zhu", "authors": "Ying Zhu", "title": "High-Dimensional Semiparametric Selection Models: Estimation Theory with\n  an Application to the Retail Gasoline Market", "comments": "3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a multi-stage projection-based Lasso procedure for the\nsemiparametric sample selection model in high-dimensional settings under a weak\nnonparametric restriction on the selection correction. In particular, the\nnumber of regressors in the main equation, p, and the number of regressors in\nthe selection equation, d, can grow with and exceed the sample size n. The\nanalysis considers the exact sparsity case and the approximate sparsity case.\nThe main theoretical results are finite-sample bounds from which sufficient\nscaling conditions on the sample size for estimation consistency and\nvariable-selection consistency are established. Statistical efficiency of the\nproposed estimators is studied via lower bounds on minimax risks and the result\nshows that, for a family of models with exactly sparse structure on the\ncoefficient vector in the main equation, one of the proposed estimators attains\nthe smallest estimation error up to the (n,d,p)-scaling among a class of\nprocedures in worst-case scenarios. Inference procedures for the coefficients\nof the main equation, one based on a pivotal Dantzig selector to construct\nnon-asymptotic confidence sets and one based on a post-selection strategy, are\ndiscussed. Other theoretical contributions include establishing the\nnon-asymptotic counterpart of the familiar asymptotic oracle results from\nprevious literature: the estimator of the coefficients in the main equation\nbehaves as if the unknown nonparametric component were known, provided the\nnonparametric component is sufficiently smooth. Small-sample performance of the\nhigh-dimensional multi-stage estimation procedure is evaluated by Monte-Carlo\nsimulations and illustrated with an empirical application to the retail\ngasoline market in the Greater Saint Louis area.\n", "versions": [{"version": "v1", "created": "Tue, 4 Nov 2014 06:33:36 GMT"}], "update_date": "2014-11-13", "authors_parsed": [["Zhu", "Ying", ""]]}, {"id": "1411.0839", "submitter": "Peter Binev", "authors": "Peter Binev, Albert Cohen, Wolfgang Dahmen, Ronald DeVore", "title": "Classification algorithms using adaptive partitioning", "comments": "Published in at http://dx.doi.org/10.1214/14-AOS1234 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2014, Vol. 42, No. 6, 2141-2163", "doi": "10.1214/14-AOS1234", "report-no": "IMS-AOS-AOS1234", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithms for binary classification based on adaptive tree partitioning are\nformulated and analyzed for both their risk performance and their friendliness\nto numerical implementation. The algorithms can be viewed as generating a set\napproximation to the Bayes set and thus fall into the general category of set\nestimators. In contrast with the most studied tree-based algorithms, which\nutilize piecewise constant approximation on the generated partition [IEEE\nTrans. Inform. Theory 52 (2006) 1335-1353; Mach. Learn. 66 (2007) 209-242], we\nconsider decorated trees, which allow us to derive higher order methods.\nConvergence rates for these methods are derived in terms the parameter $\\alpha$\nof margin conditions and a rate $s$ of best approximation of the Bayes set by\ndecorated adaptive partitions. They can also be expressed in terms of the Besov\nsmoothness $\\beta$ of the regression function that governs its approximability\nby piecewise polynomials on adaptive partition. The execution of the algorithms\ndoes not require knowledge of the smoothness or margin conditions. Besov\nsmoothness conditions are weaker than the commonly used H\\\"{o}lder conditions,\nwhich govern approximation by nonadaptive partitions, and therefore for a given\nregression function can result in a higher rate of convergence. This in turn\nmitigates the compatibility conflict between smoothness and margin parameters.\n", "versions": [{"version": "v1", "created": "Tue, 4 Nov 2014 09:55:40 GMT"}], "update_date": "2014-11-05", "authors_parsed": [["Binev", "Peter", ""], ["Cohen", "Albert", ""], ["Dahmen", "Wolfgang", ""], ["DeVore", "Ronald", ""]]}, {"id": "1411.0858", "submitter": "Piotr Fryzlewicz", "authors": "Piotr Fryzlewicz", "title": "Wild binary segmentation for multiple change-point detection", "comments": "Published in at http://dx.doi.org/10.1214/14-AOS1245 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2014, Vol. 42, No. 6, 2243-2281", "doi": "10.1214/14-AOS1245", "report-no": "IMS-AOS-AOS1245", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new technique, called wild binary segmentation (WBS), for\nconsistent estimation of the number and locations of multiple change-points in\ndata. We assume that the number of change-points can increase to infinity with\nthe sample size. Due to a certain random localisation mechanism, WBS works even\nfor very short spacings between the change-points and/or very small jump\nmagnitudes, unlike standard binary segmentation. On the other hand, despite its\nuse of localisation, WBS does not require the choice of a window or span\nparameter, and does not lead to a significant increase in computational\ncomplexity. WBS is also easy to code. We propose two stopping criteria for WBS:\none based on thresholding and the other based on what we term the `strengthened\nSchwarz information criterion'. We provide default recommended values of the\nparameters of the procedure and show that it offers very good practical\nperformance in comparison with the state of the art. The WBS methodology is\nimplemented in the R package wbs, available on CRAN. In addition, we provide a\nnew proof of consistency of binary segmentation with improved rates of\nconvergence, as well as a corresponding result for WBS.\n", "versions": [{"version": "v1", "created": "Tue, 4 Nov 2014 10:56:45 GMT"}], "update_date": "2014-11-05", "authors_parsed": [["Fryzlewicz", "Piotr", ""]]}, {"id": "1411.0862", "submitter": "R. A. Bailey", "authors": "R. A. Bailey, P. Druilhet", "title": "Optimal cross-over designs for full interaction models", "comments": "Published in at http://dx.doi.org/10.1214/14-AOS1247 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2014, Vol. 42, No. 6, 2282-2300", "doi": "10.1214/14-AOS1247", "report-no": "IMS-AOS-AOS1247", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider repeated measurement designs when a residual or carry-over effect\nmay be present in at most one later period. Since assuming an additive model\nmay be unrealistic for some applications and leads to biased estimation of\ntreatment effects, we consider a model with interactions between carry-over and\ndirect treatment effects. When the aim of the experiment is to study the\neffects of a treatment used alone, we obtain universally optimal approximate\ndesigns. We also propose some efficient designs with a reduced number of\nsubjects.\n", "versions": [{"version": "v1", "created": "Tue, 4 Nov 2014 11:17:16 GMT"}, {"version": "v2", "created": "Wed, 19 Nov 2014 07:31:23 GMT"}], "update_date": "2014-11-20", "authors_parsed": [["Bailey", "R. A.", ""], ["Druilhet", "P.", ""]]}, {"id": "1411.0877", "submitter": "Laurent Callot", "authors": "Laurent Callot and Johannes Tang Kristensen", "title": "Vector Autoregressions with Parsimoniously Time Varying Parameters and\n  an Application to Monetary Policy", "comments": "This paper has been withdrawn by the author due to an error in\n  assumption 4,ii", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a parsimoniously time varying parameter vector\nautoregressive model (with exogenous variables, VARX) and studies the\nproperties of the Lasso and adaptive Lasso as estimators of this model. The\nparameters of the model are assumed to follow parsimonious random walks, where\nparsimony stems from the assumption that increments to the parameters have a\nnon-zero probability of being exactly equal to zero. By varying the degree of\nparsimony our model can accommodate constant parameters, an unknown number of\nstructural breaks, or parameters with a high degree of variation.\n  We characterize the finite sample properties of the Lasso by deriving upper\nbounds on the estimation and prediction errors that are valid with high\nprobability; and asymptotically we show that these bounds tend to zero with\nprobability tending to one if the number of non zero increments grows slower\nthan $\\sqrt{T}$.\n  By simulation experiments we investigate the properties of the Lasso and the\nadaptive Lasso in settings where the parameters are stable, experience\nstructural breaks, or follow a parsimonious random walk. We use our model to\ninvestigate the monetary policy response to inflation and business cycle\nfluctuations in the US by estimating a parsimoniously time varying parameter\nTaylor rule. We document substantial changes in the policy response of the Fed\nin the 1980s and since 2008.\n", "versions": [{"version": "v1", "created": "Tue, 4 Nov 2014 12:22:47 GMT"}, {"version": "v2", "created": "Thu, 20 Nov 2014 14:47:44 GMT"}], "update_date": "2014-11-21", "authors_parsed": [["Callot", "Laurent", ""], ["Kristensen", "Johannes Tang", ""]]}, {"id": "1411.0894", "submitter": "Sebastien Gadat", "authors": "S\\'ebastien Gadat, Thierry Klein, Cl\\'ement Marteau", "title": "Classification with the nearest neighbor rule in general finite\n  dimensional spaces: necessary and sufficient conditions", "comments": "53 Pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://creativecommons.org/licenses/publicdomain/", "abstract": "  Given an $n$-sample of random vectors $(X_i,Y_i)_{1 \\leq i \\leq n}$ whose\njoint law is unknown, the long-standing problem of supervised classification\naims to \\textit{optimally} predict the label $Y$ of a given a new observation\n$X$. In this context, the nearest neighbor rule is a popular flexible and\nintuitive method in non-parametric situations.\n  Even if this algorithm is commonly used in the machine learning and\nstatistics communities, less is known about its prediction ability in general\nfinite dimensional spaces, especially when the support of the density of the\nobservations is $\\mathbb{R}^d$. This paper is devoted to the study of the\nstatistical properties of the nearest neighbor rule in various situations. In\nparticular, attention is paid to the marginal law of $X$, as well as the\nsmoothness and margin properties of the \\textit{regression function} $\\eta(X) =\n\\mathbb{E}[Y | X]$. We identify two necessary and sufficient conditions to\nobtain uniform consistency rates of classification and to derive sharp\nestimates in the case of the nearest neighbor rule. Some numerical experiments\nare proposed at the end of the paper to help illustrate the discussion.\n", "versions": [{"version": "v1", "created": "Tue, 4 Nov 2014 13:05:08 GMT"}, {"version": "v2", "created": "Wed, 5 Nov 2014 06:17:03 GMT"}], "update_date": "2014-11-06", "authors_parsed": [["Gadat", "S\u00e9bastien", ""], ["Klein", "Thierry", ""], ["Marteau", "Cl\u00e9ment", ""]]}, {"id": "1411.0900", "submitter": "Krikamol Muandet", "authors": "Krikamol Muandet, Bharath Sriperumbudur, Bernhard Sch\\\"olkopf", "title": "Kernel Mean Estimation via Spectral Filtering", "comments": "To appear at the 28th Annual Conference on Neural Information\n  Processing Systems (NIPS 2014). 16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of estimating the kernel mean in a reproducing kernel Hilbert\nspace (RKHS) is central to kernel methods in that it is used by classical\napproaches (e.g., when centering a kernel PCA matrix), and it also forms the\ncore inference step of modern kernel methods (e.g., kernel-based non-parametric\ntests) that rely on embedding probability distributions in RKHSs. Muandet et\nal. (2014) has shown that shrinkage can help in constructing \"better\"\nestimators of the kernel mean than the empirical estimator. The present paper\nstudies the consistency and admissibility of the estimators in Muandet et al.\n(2014), and proposes a wider class of shrinkage estimators that improve upon\nthe empirical estimator by considering appropriate basis functions. Using the\nkernel PCA basis, we show that some of these estimators can be constructed\nusing spectral filtering algorithms which are shown to be consistent under some\ntechnical assumptions. Our theoretical analysis also reveals a fundamental\nconnection to the kernel-based supervised learning framework. The proposed\nestimators are simple to implement and perform well in practice.\n", "versions": [{"version": "v1", "created": "Tue, 4 Nov 2014 13:27:57 GMT"}], "update_date": "2014-11-05", "authors_parsed": [["Muandet", "Krikamol", ""], ["Sriperumbudur", "Bharath", ""], ["Sch\u00f6lkopf", "Bernhard", ""]]}, {"id": "1411.0947", "submitter": "Emanuele Dolera", "authors": "Emanuele Dolera and Andrea Bulgarelli", "title": "Asymptotic behavior of the joint distribution of a vector of\n  stochastically dependent likelihood ratios", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides a generalization of a classical result obtained by Wilks\nabout the asymptotic behavior of the likelihood ratio. The new results deal\nwith the asymptotic behavior of the joint distribution of a vector of\nlikelihood ratios which turn out to be stochastically dependent.\n", "versions": [{"version": "v1", "created": "Tue, 4 Nov 2014 15:52:26 GMT"}], "update_date": "2014-11-05", "authors_parsed": [["Dolera", "Emanuele", ""], ["Bulgarelli", "Andrea", ""]]}, {"id": "1411.0980", "submitter": "Subrata Chakraborty", "authors": "Subrata Chakraborty and S. H. Ong", "title": "Mittag - Leffler function distribution - A new generalization of\n  hyper-Poisson distribution", "comments": "24 pages, 11 figures, 9 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper a new generalization of the hyper-Poisson distribution is\nproposed using the Mittag-Leffler function. The hyper-Poisson, displaced\nPoisson, Poisson and geometric distributions among others are seen as\nparticular cases. This Mittag-Leffler function distribution (MLFD) belongs to\nthe generalized hypergeometric and generalized power series families and also\narises as weighted Poison distributions. MLFD is a flexible distribution with\nvarying shapes like non-increasing with unique mode at zero, unimodal with one\n/ two non-zero modes. It can be under, equi or over dispersed. Various\ndistributional properties like recurrence relation for pmf, cumulative\ndistribution function, generating functions, formulae for different type of\nmoments, their recurrence relations, index of dispersion, its classification,\nlog-concavity, reliability properties like survival, increasing failure rate,\nunimodality, and stochastic ordering with respect to hyper-Poisson distribution\nhave been discussed. The distribution has been found to fare well when compared\nwith the hyper-Poisson distributions in its suitability in empirical modeling\nof differently dispersed count data. It is therefore expected that proposed\nMLFD with its interesting features and flexibility, will be a useful addition\nas a model for count data.\n", "versions": [{"version": "v1", "created": "Tue, 4 Nov 2014 17:39:49 GMT"}], "update_date": "2014-11-05", "authors_parsed": [["Chakraborty", "Subrata", ""], ["Ong", "S. H.", ""]]}, {"id": "1411.1015", "submitter": "Edsel Pena", "authors": "Edsel A. Pena, Wensong Wu, Walter Piegorsch, Ronald W. West, Lingling\n  An", "title": "Model Selection and Estimation with Quantal-Response Data in Benchmark\n  Risk Assessment", "comments": "44 pages including many figures", "journal-ref": "Journal of Risk Analysis, 2014", "doi": "10.1111/risa.12644", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes several approaches for estimating the benchmark dose\n(BMD) in a risk assessment study with quantal dose-response data and when there\nare competing model classes for the dose-response function. Strategies\ninvolving a two-step approach, a model-averaging approach, a focused-inference\napproach, and a nonparametric approach based on a PAVA-based estimator of the\ndose-response function are described and compared. Attention is raised to the\nperils involved in data \"double-dipping\" and the need to adjust for the\nmodel-selection stage in the estimation procedure. Simulation results are\npresented comparing the performance of five model selectors and eight BMD\nestimators. An illustration using a real quantal-response data set from a\ncarcinogenecity study is provided.\n", "versions": [{"version": "v1", "created": "Tue, 4 Nov 2014 19:37:42 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Pena", "Edsel A.", ""], ["Wu", "Wensong", ""], ["Piegorsch", "Walter", ""], ["West", "Ronald W.", ""], ["An", "Lingling", ""]]}, {"id": "1411.1144", "submitter": "Demian Pouzo", "authors": "Xiaohong Chen and Demian Pouzo", "title": "Sieve Wald and QLR Inferences on Semi/nonparametric Conditional Moment\n  Models", "comments": "Accepted for publication in Econometrica. Minor typos corrected", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST econ.EM stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers inference on functionals of semi/nonparametric\nconditional moment restrictions with possibly nonsmooth generalized residuals,\nwhich include all of the (nonlinear) nonparametric instrumental variables (IV)\nas special cases. These models are often ill-posed and hence it is difficult to\nverify whether a (possibly nonlinear) functional is root-$n$ estimable or not.\nWe provide computationally simple, unified inference procedures that are\nasymptotically valid regardless of whether a functional is root-$n$ estimable\nor not. We establish the following new useful results: (1) the asymptotic\nnormality of a plug-in penalized sieve minimum distance (PSMD) estimator of a\n(possibly nonlinear) functional; (2) the consistency of simple sieve variance\nestimators for the plug-in PSMD estimator, and hence the asymptotic chi-square\ndistribution of the sieve Wald statistic; (3) the asymptotic chi-square\ndistribution of an optimally weighted sieve quasi likelihood ratio (QLR) test\nunder the null hypothesis; (4) the asymptotic tight distribution of a\nnon-optimally weighted sieve QLR statistic under the null; (5) the consistency\nof generalized residual bootstrap sieve Wald and QLR tests; (6) local power\nproperties of sieve Wald and QLR tests and of their bootstrap versions; (7)\nasymptotic properties of sieve Wald and SQLR for functionals of increasing\ndimension. Simulation studies and an empirical illustration of a nonparametric\nquantile IV regression are presented.\n", "versions": [{"version": "v1", "created": "Wed, 5 Nov 2014 04:31:59 GMT"}, {"version": "v2", "created": "Fri, 20 Mar 2015 05:17:02 GMT"}], "update_date": "2018-01-04", "authors_parsed": [["Chen", "Xiaohong", ""], ["Pouzo", "Demian", ""]]}, {"id": "1411.1166", "submitter": "Prithwish Bhaumik", "authors": "Prithwish Bhaumik, Subhashis Ghosal", "title": "Efficient Bayesian estimation and uncertainty quantification in ordinary\n  differential equation models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Often the regression function is specified by a system of ordinary\ndifferential equations (ODEs) involving some unknown parameters. Typically\nanalytical solution of the ODEs is not available, and hence likelihood\nevaluation at many parameter values by numerical solution of equations may be\ncomputationally prohibitive. Bhaumik and Ghosal (2015) considered a Bayesian\ntwo-step approach by embedding the model in a larger nonparametric regression\nmodel, where a prior is put through a random series based on B-spline basis\nfunctions. A posterior on the parameter is induced from the regression function\nby minimizing an integrated weighted squared distance between the derivative of\nthe regression function and the derivative suggested by the ODEs. Although this\napproach is computationally fast, the Bayes estimator is not asymptotically\nefficient. In this paper we suggest a modification of the two-step method by\ndirectly considering the distance between the function in the nonparametric\nmodel and that obtained from a four stage Runge-Kutta (RK4) method. We also\nstudy the asymptotic behavior of the posterior distribution of the parameter\nbased on an approximate likelihood obtained from an RK4 numerical solution of\nthe ODEs. We establish a Bernstein-von Mises theorem for both methods which\nassures that Bayesian uncertainty quantification matches with the frequentist\none and the Bayes estimator is asymptotically efficient.\n", "versions": [{"version": "v1", "created": "Wed, 5 Nov 2014 06:44:45 GMT"}, {"version": "v2", "created": "Mon, 22 Feb 2016 20:32:19 GMT"}], "update_date": "2016-02-23", "authors_parsed": [["Bhaumik", "Prithwish", ""], ["Ghosal", "Subhashis", ""]]}, {"id": "1411.1312", "submitter": "Donald Richards", "authors": "Johannes Dueck, Dominic Edelmann, and Donald Richards", "title": "A Generalization of an Integral Arising in the Theory of Distance\n  Correlation", "comments": "7 pages; to appear in Statistics and Probability Letters, 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We generalize an integral which arises in several areas in probability and\nstatistics and which is at the core of the field of distance correlation, a\nconcept developed by Sz\\'ekely, Rizzo and Bakirov (2007) to measure dependence\nbetween random variables. Let $m$ be a positive integer and let ${\\cos_m}(u)$,\n$u \\in \\mathbb{R}$, be the truncated Maclaurin expansion of ${\\cos}(u)$, where\nthe expansion is truncated at the $m$th summand. For $t, x \\in \\mathbb{R}^d$,\nlet $\\langle t,x\\rangle$ and $\\|x\\|$ denote the standard Euclidean inner\nproduct and norm, respectively. We establish the integral formula: For $\\alpha\n\\in \\mathbb{C}$ and $x \\in \\mathbb{R}^d$, $\\int_{{\\mathbb{R}}^d}\n[\\cos_m(\\langle t,x\\rangle) - \\cos(\\langle t,x\\rangle)] \\,{\\rm\nd}t/{\\|t\\|^{d+\\alpha}} = C(d,\\alpha) \\, \\|x\\|^{\\alpha}$, with absolute\nconvergence if and only if $2(m-1) < \\Re(\\alpha) < 2m$. Moreover, the constant\n$C(d,\\alpha)$ does not depend on $m$.\n", "versions": [{"version": "v1", "created": "Wed, 5 Nov 2014 16:25:59 GMT"}, {"version": "v2", "created": "Fri, 14 Nov 2014 03:49:50 GMT"}, {"version": "v3", "created": "Sun, 30 Nov 2014 21:47:02 GMT"}], "update_date": "2014-12-02", "authors_parsed": [["Dueck", "Johannes", ""], ["Edelmann", "Dominic", ""], ["Richards", "Donald", ""]]}, {"id": "1411.1329", "submitter": "Mahdis Azadbakhsh", "authors": "Mahdis Azadbakhsh, Xin Gao and Hanna Jankowski", "title": "Multiple Comparisons using Composite Likelihood in Clustered Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of multiple hypothesis testing for multidimensional data\nwhen inter-correlations are present. The problem of multiple comparisons is\ncommon in many applications. When the data is multivariate and correlated,\nexisting multiple comparisons procedures based on maximum likelihood estimation\ncould be prohibitively computationally intensive. We propose to construct\nmultiple comparisons procedures based on composite likelihood statistics. We\nfocus on data arising in three ubiquitous cases: multivariate Gaussian, probit,\nand quadratic exponential models. To help practitioners assess the quality of\nour proposed methods, we assess their empirical performance via Monte Carlo\nsimulations. It is shown that composite likelihood based procedures maintain\ngood control of the familywise type I error rate in the presence of\nintra-cluster correlation, whereas ignoring the correlation leads to erratic\nperformance. Using data arising from a diabetic nephropathy study, we show how\nour composite likelihood approach makes an otherwise intractable analysis\npossible.\n", "versions": [{"version": "v1", "created": "Wed, 5 Nov 2014 17:16:26 GMT"}, {"version": "v2", "created": "Fri, 29 May 2015 20:46:22 GMT"}], "update_date": "2015-06-02", "authors_parsed": [["Azadbakhsh", "Mahdis", ""], ["Gao", "Xin", ""], ["Jankowski", "Hanna", ""]]}, {"id": "1411.1350", "submitter": "Dena Asta", "authors": "Dena Asta, Cosma Rohilla Shalizi", "title": "Geometric Network Comparison", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network analysis has a crucial need for tools to compare networks and assess\nthe significance of differences between networks. We propose a principled\nstatistical approach to network comparison that approximates networks as\nprobability distributions on negatively curved manifolds. We outline the\ntheory, as well as implement the approach on simulated networks.\n", "versions": [{"version": "v1", "created": "Wed, 5 Nov 2014 18:32:58 GMT"}], "update_date": "2015-07-27", "authors_parsed": [["Asta", "Dena", ""], ["Shalizi", "Cosma Rohilla", ""]]}, {"id": "1411.1437", "submitter": "Jian Li", "authors": "Jian Li, David Siegmund", "title": "Higher criticism: $p$-values and criticism", "comments": "Published at http://dx.doi.org/10.1214/15-AOS1312 in the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2015, Vol. 43, No. 3, 1323-1350", "doi": "10.1214/15-AOS1312", "report-no": "IMS-AOS-AOS1312", "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper compares the higher criticism statistic (Donoho and Jin [Ann.\nStatist. 32 (2004) 962-994]), a modification of the higher criticism statistic\nalso suggested by Donoho and Jin, and two statistics of the Berk-Jones [Z.\nWahrsch. Verw. Gebiete 47 (1979) 47-59] type. New approximations to the\nsignificance levels of the statistics are derived, and their accuracy is\nstudied by simulations. By numerical examples it is shown that over a broad\nrange of sample sizes the Berk-Jones statistics have a better power function\nthan the higher criticism statistics to detect sparse mixtures. The\napplications suggested by Meinshausen and Rice [Ann. Statist. 34 (2006)\n373-393], to find lower confidence bounds for the number of false hypotheses,\nand by Jeng, Cai and Li [Biometrika 100 (2013) 157-172], to detect copy number\nvariants, are also studied.\n", "versions": [{"version": "v1", "created": "Wed, 5 Nov 2014 22:41:12 GMT"}, {"version": "v2", "created": "Sat, 28 Mar 2015 06:20:28 GMT"}, {"version": "v3", "created": "Wed, 3 Jun 2015 07:30:45 GMT"}], "update_date": "2015-06-04", "authors_parsed": [["Li", "Jian", ""], ["Siegmund", "David", ""]]}, {"id": "1411.1469", "submitter": "Jing Lei", "authors": "Jing Lei and Lingxue Zhu", "title": "A Generic Sample Splitting Approach for Refined Community Recovery in\n  Stochastic Block Models", "comments": "19 pages", "journal-ref": "Statistica Sinica 27 (2017), 1639-1659", "doi": "10.5705/ss.202015.0279", "report-no": null, "categories": "stat.ML math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose and analyze a generic method for community recovery in stochastic\nblock models and degree corrected block models. This approach can exactly\nrecover the hidden communities with high probability when the expected node\ndegrees are of order $\\log n$ or higher. Starting from a roughly correct\ncommunity partition given by some conventional community recovery algorithm,\nthis method refines the partition in a cross clustering step. Our results\nsimplify and extend some of the previous work on exact community recovery,\ndiscovering the key role played by sample splitting. The proposed method is\nsimple and can be implemented with many practical community recovery\nalgorithms.\n", "versions": [{"version": "v1", "created": "Thu, 6 Nov 2014 01:34:26 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Lei", "Jing", ""], ["Zhu", "Lingxue", ""]]}, {"id": "1411.1477", "submitter": "Richard Brent", "authors": "Richard P. Brent, Hideyuki Ohtsuka, Judy-anne H. Osborn, Helmut\n  Prodinger", "title": "Some binomial sums involving absolute values", "comments": "15 pages, 19 references", "journal-ref": "Journal of Integer Sequences 19 (2016), article 16.3.7, 14 pp", "doi": null, "report-no": null, "categories": "math.CO math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider several families of binomial sum identities whose definition\ninvolves the absolute value function. In particular, we consider centered\ndouble sums of the form \\[S_{\\alpha,\\beta}(n) :=\n\\sum_{k,\\;\\ell}\\binom{2n}{n+k}\\binom{2n}{n+\\ell}\n|k^\\alpha-\\ell^\\alpha|^\\beta,\\] obtaining new results in the cases $\\alpha = 1,\n2$. We show that there is a close connection between these double sums in the\ncase $\\alpha=1$ and the single centered binomial sums considered by Tuenter.\n", "versions": [{"version": "v1", "created": "Thu, 6 Nov 2014 02:41:45 GMT"}, {"version": "v2", "created": "Sun, 31 Jan 2016 04:24:56 GMT"}], "update_date": "2016-05-26", "authors_parsed": [["Brent", "Richard P.", ""], ["Ohtsuka", "Hideyuki", ""], ["Osborn", "Judy-anne H.", ""], ["Prodinger", "Helmut", ""]]}, {"id": "1411.1609", "submitter": "Halim Zeghdoudi", "authors": "Halim Zeghdoudi, Meriem Bouhadjar and Mohamed Riad Remita", "title": "On Stochastic Orders and its applications : Policy limits and\n  Deductibles", "comments": "This paper has been withdrawn by the author due to a crucial sign\n  errors in typing and mathematical formulas", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST q-fin.RM stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on stochastic orders and its applications : policy limits\nand deductibles. Further, many applications and some examples are given :\ncomparison of two families of copulas, individual and collective risk model,\nreinsurance contracts and dependent portfolios increase risk. More precisely,\nwe propose a new model for insurance risks while we give some properties. To\nthis end, we obtain the ordering of the optimal allocation of policy limits and\ndeductibles for this model.\n", "versions": [{"version": "v1", "created": "Thu, 6 Nov 2014 13:42:53 GMT"}, {"version": "v2", "created": "Mon, 26 Jan 2015 22:04:00 GMT"}], "update_date": "2015-01-28", "authors_parsed": [["Zeghdoudi", "Halim", ""], ["Bouhadjar", "Meriem", ""], ["Remita", "Mohamed Riad", ""]]}, {"id": "1411.1660", "submitter": "Marianna Pensky", "authors": "Marianna Pensky", "title": "Minimax theory of estimation of linear functionals of the deconvolution\n  density with or without sparsity", "comments": "40 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The present paper considers a problem of estimating a linear functional\n$\\Phi=\\int_{-\\infty}^\\infty \\varphi(x) f(x)dx$ of an unknown deconvolution\ndensity $f$ on the basis of i.i.d. observations $Y_i = \\theta_i + \\xi_i$ where\n$\\xi_i$ has a known pdf $g$ and $f$ is the pdf of $\\theta_i$. Although various\naspects and particular cases of this problem have been treated by a number of\nauthors, there are still many gaps. In particular, there are no minimax lower\nbounds for an estimator of $\\Phi$ for an arbitrary function $\\varphi$. The\ngeneral upper risk bounds cover only the case when the Fourier transform of\n$\\varphi$ exists. Moreover, no theory exists for estimating $\\Phi$ when vector\nof observations is sparse. In addition, until now, the related problem of\nestimation of functionals $\\Phi_n = n^{-1} \\sum_{i=1}^n \\varphi(\\theta_i)$ in\nindirect observations have been treated as a separate problem with no\nconnection to estimation of $\\Phi$. The objective of the present paper is to\nfill in the gaps and develop the general minimax theory of estimation of $\\Phi$\nand $\\Phi_n$. We offer a general approach to estimation of $\\Phi$ (and\n$\\Phi_n$) and provide the upper and the minimax lower risk bounds in the case\nwhen function $\\varphi$ is square integrable. Furthermore, we extend the theory\nto the case when Fourier transform of $\\varphi$ does not exist and $\\Phi$ can\nbe presented as a linear functional of the Fourier transform of $f$ and its\nderivatives. Finally, we generalize our results to handle the situation when\nvector $\\theta$ is sparse. As a direct application of the proposed theory, we\nobtain multiple new results and automatically recover existing ones for a\nvariety of problems such as estimation of the $(2M+1)$-th absolute moment or a\ngeneralized moment of the deconvolution density, estimation of the mixing cdf\nor estimation of the mixing pdf with classical and Berkson errors.\n", "versions": [{"version": "v1", "created": "Thu, 6 Nov 2014 16:48:21 GMT"}, {"version": "v2", "created": "Thu, 11 Dec 2014 02:03:31 GMT"}, {"version": "v3", "created": "Fri, 15 May 2015 21:09:16 GMT"}], "update_date": "2015-05-19", "authors_parsed": [["Pensky", "Marianna", ""]]}, {"id": "1411.1805", "submitter": "John Lafferty", "authors": "Min Xu, Minhua Chen and John Lafferty", "title": "Faithful Variable Screening for High-Dimensional Convex Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of variable selection in convex nonparametric\nregression. Under the assumption that the true regression function is convex\nand sparse, we develop a screening procedure to select a subset of variables\nthat contains the relevant variables. Our approach is a two-stage quadratic\nprogramming method that estimates a sum of one-dimensional convex functions,\nfollowed by one-dimensional concave regression fits on the residuals. In\ncontrast to previous methods for sparse additive models, the optimization is\nfinite dimensional and requires no tuning parameters for smoothness. Under\nappropriate assumptions, we prove that the procedure is faithful in the\npopulation setting, yielding no false negatives. We give a finite sample\nstatistical analysis, and introduce algorithms for efficiently carrying out the\nrequired quadratic programs. The approach leads to computational and\nstatistical advantages over fitting a full model, and provides an effective,\npractical approach to variable screening in convex regression.\n", "versions": [{"version": "v1", "created": "Fri, 7 Nov 2014 01:09:40 GMT"}, {"version": "v2", "created": "Tue, 18 Nov 2014 01:13:30 GMT"}], "update_date": "2014-11-19", "authors_parsed": [["Xu", "Min", ""], ["Chen", "Minhua", ""], ["Lafferty", "John", ""]]}, {"id": "1411.2066", "submitter": "Zoltan Szabo", "authors": "Zoltan Szabo, Bharath Sriperumbudur, Barnabas Poczos, Arthur Gretton", "title": "Learning Theory for Distribution Regression", "comments": "Final version appeared at JMLR, with supplement. Code:\n  https://bitbucket.org/szzoli/ite/. arXiv admin note: text overlap with\n  arXiv:1402.1754", "journal-ref": "Journal of Machine Learning Research, 17(152):1-40, 2016", "doi": null, "report-no": null, "categories": "math.ST cs.LG math.FA stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We focus on the distribution regression problem: regressing to vector-valued\noutputs from probability measures. Many important machine learning and\nstatistical tasks fit into this framework, including multi-instance learning\nand point estimation problems without analytical solution (such as\nhyperparameter or entropy estimation). Despite the large number of available\nheuristics in the literature, the inherent two-stage sampled nature of the\nproblem makes the theoretical analysis quite challenging, since in practice\nonly samples from sampled distributions are observable, and the estimates have\nto rely on similarities computed between sets of points. To the best of our\nknowledge, the only existing technique with consistency guarantees for\ndistribution regression requires kernel density estimation as an intermediate\nstep (which often performs poorly in practice), and the domain of the\ndistributions to be compact Euclidean. In this paper, we study a simple,\nanalytically computable, ridge regression-based alternative to distribution\nregression, where we embed the distributions to a reproducing kernel Hilbert\nspace, and learn the regressor from the embeddings to the outputs. Our main\ncontribution is to prove that this scheme is consistent in the two-stage\nsampled setup under mild conditions (on separable topological domains enriched\nwith kernels): we present an exact computational-statistical efficiency\ntrade-off analysis showing that our estimator is able to match the one-stage\nsampled minimax optimal rate [Caponnetto and De Vito, 2007; Steinwart et al.,\n2009]. This result answers a 17-year-old open question, establishing the\nconsistency of the classical set kernel [Haussler, 1999; Gaertner et. al, 2002]\nin regression. We also cover consistency for more recent kernels on\ndistributions, including those due to [Christmann and Steinwart, 2010].\n", "versions": [{"version": "v1", "created": "Sat, 8 Nov 2014 01:16:44 GMT"}, {"version": "v2", "created": "Sat, 6 Dec 2014 23:49:00 GMT"}, {"version": "v3", "created": "Tue, 19 Jan 2016 22:03:20 GMT"}, {"version": "v4", "created": "Fri, 21 Oct 2016 15:46:35 GMT"}], "update_date": "2016-10-24", "authors_parsed": [["Szabo", "Zoltan", ""], ["Sriperumbudur", "Bharath", ""], ["Poczos", "Barnabas", ""], ["Gretton", "Arthur", ""]]}, {"id": "1411.2158", "submitter": "Norbert Binkiewicz", "authors": "Norbert Binkiewicz, Joshua T. Vogelstein, and Karl Rohe", "title": "Covariate-assisted spectral clustering", "comments": "28 pages, 4 figures, includes substantial changes to theoretical\n  results", "journal-ref": "Biometrika, Volume 104, Issue 2, 1 June 2017, Pages 361-377", "doi": "10.1093/biomet/asx008", "report-no": null, "categories": "stat.ML cs.LG math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Biological and social systems consist of myriad interacting units. The\ninteractions can be represented in the form of a graph or network. Measurements\nof these graphs can reveal the underlying structure of these interactions,\nwhich provides insight into the systems that generated the graphs. Moreover, in\napplications such as connectomics, social networks, and genomics, graph data\nare accompanied by contextualizing measures on each node. We utilize these node\ncovariates to help uncover latent communities in a graph, using a modification\nof spectral clustering. Statistical guarantees are provided under a joint\nmixture model that we call the node-contextualized stochastic blockmodel,\nincluding a bound on the mis-clustering rate. The bound is used to derive\nconditions for achieving perfect clustering. For most simulated cases,\ncovariate-assisted spectral clustering yields results superior to regularized\nspectral clustering without node covariates and to an adaptation of canonical\ncorrelation analysis. We apply our clustering method to large brain graphs\nderived from diffusion MRI data, using the node locations or neurological\nregion membership as covariates. In both cases, covariate-assisted spectral\nclustering yields clusters that are easier to interpret neurologically.\n", "versions": [{"version": "v1", "created": "Sat, 8 Nov 2014 20:14:59 GMT"}, {"version": "v2", "created": "Thu, 4 Jun 2015 19:14:01 GMT"}, {"version": "v3", "created": "Tue, 22 Dec 2015 04:51:04 GMT"}, {"version": "v4", "created": "Thu, 3 Mar 2016 04:07:22 GMT"}, {"version": "v5", "created": "Sun, 30 Oct 2016 04:22:47 GMT"}], "update_date": "2017-10-25", "authors_parsed": [["Binkiewicz", "Norbert", ""], ["Vogelstein", "Joshua T.", ""], ["Rohe", "Karl", ""]]}, {"id": "1411.2232", "submitter": "Matyas Barczy", "authors": "Matyas Barczy, Krist\\'of K\\\"ormendi, Gyula Pap", "title": "Statistical inference for critical continuous state and continuous time\n  branching processes with immigration", "comments": "26 pages. In Section 2 and in Appendices we recall some notions and\n  statements from arXiv:1403.0245 and arXiv:1404.2242. arXiv admin note:\n  substantial text overlap with arXiv:1406.3325", "journal-ref": "Metrika 79 (7), 2016, 789-816", "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study asymptotic behavior of conditional least squares estimators for\ncritical continuous state and continuous time branching processes with\nimmigration based on discrete time (low frequency) observations.\n", "versions": [{"version": "v1", "created": "Sun, 9 Nov 2014 13:33:09 GMT"}, {"version": "v2", "created": "Mon, 23 Mar 2015 07:35:24 GMT"}], "update_date": "2018-01-19", "authors_parsed": [["Barczy", "Matyas", ""], ["K\u00f6rmendi", "Krist\u00f3f", ""], ["Pap", "Gyula", ""]]}, {"id": "1411.2309", "submitter": "Akimichi Takemura", "authors": "Toshifumi Fujiyama and Chihiro Matsui and Akimichi Takemura", "title": "A power-law decay model with autocorrelation for posting data to social\n  networking services", "comments": null, "journal-ref": "PLoS ONE 11(8): e0160592. 2016", "doi": "10.1371/journal.pone.0160592", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a power-law decay model with autocorrelation for posting data to\nsocial networking services concerning particular events such as national\nholidays or major sport events. In these kinds of events we observe people's\ninterest both before and after the events. In our model the number of postings\nhas a Poisson distribution whose expected value decays as a power law. Our\nmodel also incorporates autocorrelations by autoregressive specification of the\nexpected value. We show that our proposed model well fits the data from social\nnetworking services.\n", "versions": [{"version": "v1", "created": "Mon, 10 Nov 2014 01:56:29 GMT"}], "update_date": "2016-08-11", "authors_parsed": [["Fujiyama", "Toshifumi", ""], ["Matsui", "Chihiro", ""], ["Takemura", "Akimichi", ""]]}, {"id": "1411.2391", "submitter": "Andreas Anastasiou", "authors": "Andreas Anastasiou, Gesine Reinert", "title": "Bounds for the normal approximation of the maximum likelihood estimator", "comments": "Published at http://dx.doi.org/10.3150/15-BEJ741 in the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2017, Vol. 23, No. 1, 191-218", "doi": "10.3150/15-BEJ741", "report-no": "IMS-BEJ-BEJ741", "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While the asymptotic normality of the maximum likelihood estimator under\nregularity conditions is long established, this paper derives explicit bounds\nfor the bounded Wasserstein distance between the distribution of the maximum\nlikelihood estimator (MLE) and the normal distribution. For this task, we\nemploy Stein's method. We focus on independent and identically distributed\nrandom variables, covering both discrete and continuous distributions as well\nas exponential and non-exponential families. In particular, a closed form\nexpression of the MLE is not required. We also use a perturbation method to\ntreat cases where the MLE has positive probability of being on the boundary of\nthe parameter space.\n", "versions": [{"version": "v1", "created": "Mon, 10 Nov 2014 11:57:59 GMT"}, {"version": "v2", "created": "Fri, 24 Apr 2015 14:34:24 GMT"}, {"version": "v3", "created": "Wed, 28 Sep 2016 13:30:08 GMT"}], "update_date": "2016-09-29", "authors_parsed": [["Anastasiou", "Andreas", ""], ["Reinert", "Gesine", ""]]}, {"id": "1411.2482", "submitter": "Alejandro  Cholaquidis", "authors": "Catherine Aaron, Alejandro Cholaquidis, Ricardo Fraiman", "title": "A Generalization of the maximal-spacings in several dimensions and a\n  convexity test", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The notion of maximal-spacing in several dimensions was introduced and\nstudied by Deheuvels (1983) for data uniformly distributed on the unit cube.\nLater on, Janson (1987) extended the results to data uniformly distributed on\nany bounded set, and obtained a very fine result, namely, he derived the\nasymptotic distribution of different maximal-spacings notions. These results\nhave been very useful in many statistical applications. We extend Janson's\nresults to the case where the data are generated from a H\\\"older continuous\ndensity that is bounded from below and whose support is bounded. As an\napplication, we develop a convexity test for the support of a distribution.\n", "versions": [{"version": "v1", "created": "Mon, 10 Nov 2014 16:09:12 GMT"}, {"version": "v2", "created": "Thu, 5 May 2016 15:16:09 GMT"}], "update_date": "2016-05-06", "authors_parsed": [["Aaron", "Catherine", ""], ["Cholaquidis", "Alejandro", ""], ["Fraiman", "Ricardo", ""]]}, {"id": "1411.2566", "submitter": "Stephen Portnoy", "authors": "Stephen Portnoy", "title": "Exact Probability Bounds under Moment-matching Restrictions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lindsay and Basak (2000) posed the question of how far from normality could a\ndistribution be if it matches $k$ normal moments. They provided a bound on the\nmaximal difference in c.d.f.'s, and implied that these bounds were attained. It\nwill be shown here that in fact the bound is not attained if the number of even\nmoments matched is odd. An explicit solution is developed as a symmetric\ndistribution with a finite number of mass points when the number of even\nmoments matched is even, and this bound for the even case is shown to hold as\nan explicit limit for the subsequent odd case.\n", "versions": [{"version": "v1", "created": "Mon, 10 Nov 2014 20:12:59 GMT"}, {"version": "v2", "created": "Thu, 16 Apr 2015 18:37:55 GMT"}], "update_date": "2015-04-17", "authors_parsed": [["Portnoy", "Stephen", ""]]}, {"id": "1411.2571", "submitter": "Henrik Singmann", "authors": "Karl Christoph Klauer, Henrik Singmann, and David Kellen", "title": "Parametric Order Constraints in Multinomial Processing Tree Models: An\n  Extension of Knapp and Batchelder (2004)", "comments": "author submitted version accepted for publication in \"Journal of\n  Mathematical Psychology\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP math.ST stat.OT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multinomial processing tree (MPT) models are tools for disentangling the\ncontributions of latent cognitive processes in a given experimental paradigm.\nThe present note analyzes MPT models subject to order constraints on subsets of\nits parameters. The constraints that we consider frequently arise in cases\nwhere the response categories are ordered in some sense such as in\nconfidence-rating data, Likert scale data, where graded guessing tendencies or\nresponse biases are created via base-rate or payoff manipulations, in the\nanalysis of contingency tables with order constraints, and in many other cases.\nWe show how to construct an MPT model without order constraints that is\nstatistically equivalent to the MPT model with order constraints. This new\nclosure result extends the mathematical analysis of the MPT class, and it\noffers an approach to order-restricted inference that extends the approaches\ndiscussed by Knapp and Batchelder (2004). The usefulness of the method is\nillustrated by means of an analysis of an order-constrained version of the\ntwo-high-threshold model for confidence ratings.\n", "versions": [{"version": "v1", "created": "Mon, 10 Nov 2014 20:25:04 GMT"}], "update_date": "2014-11-11", "authors_parsed": [["Klauer", "Karl Christoph", ""], ["Singmann", "Henrik", ""], ["Kellen", "David", ""]]}, {"id": "1411.2636", "submitter": "Philip Dawid", "authors": "A. P. Dawid, R. Murtas and M. Musio", "title": "Bounding the Probability of Causation in Mediation Analysis", "comments": "9 pages, 1 figure, 3 tables", "journal-ref": "In Topics on Methodological and Applied Statistical Inference,\n  edited by T. Di Battista, E. Moreno and W. Racugno. Springer (2016), 75-84", "doi": null, "report-no": null, "categories": "math.ST cs.AI stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given empirical evidence for the dependence of an outcome variable on an\nexposure variable, we can typically only provide bounds for the \"probability of\ncausation\" in the case of an individual who has developed the outcome after\nbeing exposed. We show how these bounds can be adapted or improved if further\ninformation becomes available. In addition to reviewing existing work on this\ntopic, we provide a new analysis for the case where a mediating variable can be\nobserved. In particular we show how the probability of causation can be bounded\nwhen there is no direct effect and no confounding.\n  Keywords: Causal inference, Mediation Analysis, Probability of Causation\n", "versions": [{"version": "v1", "created": "Mon, 10 Nov 2014 21:48:56 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Dawid", "A. P.", ""], ["Murtas", "R.", ""], ["Musio", "M.", ""]]}, {"id": "1411.2681", "submitter": "Alejandro  Cholaquidis", "authors": "Alejandro Cholaquidis, Antonio Cuevas, Ricardo Fraiman", "title": "On visual distances for spectrum-type functional data", "comments": null, "journal-ref": null, "doi": "10.1007/s11634-015-0217-7", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A functional distance ${\\mathbb H}$, based on the Hausdorff metric between\nthe function hypographs, is proposed for the space ${\\mathcal E}$ of\nnon-negative real upper semicontinuous functions on a compact interval. The\nmain goal of the paper is to show that the space $({\\mathcal E},{\\mathbb H})$\nis particularly suitable in some statistical problems with functional data\nwhich involve functions with very wiggly graphs and narrow, sharp peaks. A\ntypical example is given by spectrograms, either obtained by magnetic resonance\nor by mass spectrometry. On the theoretical side, we show that $({\\mathcal\nE},{\\mathbb H})$ is a complete, separable locally compact space and that the\n${\\mathbb H}$-convergence of a sequence of functions implies the convergence of\nthe respective maximum values of these functions. The probabilistic and\nstatistical implications of these results are discussed in particular,\nregarding the consistency of $k$-NN classifiers for supervised classification\nproblems with functional data in ${\\mathbb H}$. On the practical side, we\nprovide the results of a small simulation study and check also the performance\nof our method in two real data problems of supervised classification involving\nmass spectra.\n", "versions": [{"version": "v1", "created": "Tue, 11 Nov 2014 01:59:01 GMT"}, {"version": "v2", "created": "Tue, 15 Sep 2015 18:09:36 GMT"}], "update_date": "2015-09-17", "authors_parsed": [["Cholaquidis", "Alejandro", ""], ["Cuevas", "Antonio", ""], ["Fraiman", "Ricardo", ""]]}, {"id": "1411.2687", "submitter": "Alejandro  Cholaquidis", "authors": "Alejandro Cholaquidis, Ricardo Fraiman, Juan Kalemkerian, Pamela Llop", "title": "An optimal aggregation type classifier", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a nonlinear aggregation type classifier for functional data\ndefined on a separable and complete metric space. The new rule is built up from\na collection of $M$ arbitrary training classifiers. If the classifiers are\nconsistent, then so is the aggregation rule. Moreover, asymptotically the\naggregation rule behaves as well as the best of the $M$ classifiers. The\nresults of a small si\\-mu\\-lation are reported both, for high dimensional and\nfunctional data.\n", "versions": [{"version": "v1", "created": "Tue, 11 Nov 2014 02:56:44 GMT"}], "update_date": "2014-11-12", "authors_parsed": [["Cholaquidis", "Alejandro", ""], ["Fraiman", "Ricardo", ""], ["Kalemkerian", "Juan", ""], ["Llop", "Pamela", ""]]}, {"id": "1411.2701", "submitter": "Demian Pouzo", "authors": "Demian Pouzo", "title": "Bootstrap Consistency for Quadratic Forms of Sample Averages with\n  Increasing Dimension", "comments": "70 pages. Added a numerical simulation", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST econ.EM math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper establishes consistency of the weighted bootstrap for quadratic\nforms $\\left( n^{-1/2} \\sum_{i=1}^{n} Z_{i,n} \\right)^{T}\\left( n^{-1/2}\n\\sum_{i=1}^{n} Z_{i,n} \\right)$ where $(Z_{i,n})_{i=1}^{n}$ are mean zero,\nindependent $\\mathbb{R}^{d}$-valued random variables and $d=d(n)$ is allowed to\ngrow with the sample size $n$, slower than $n^{1/4}$. The proof relies on an\nadaptation of Lindeberg interpolation technique whereby we simplify the\noriginal problem to a Gaussian approximation problem. We apply our bootstrap\nresults to model-specification testing problems when the number of moments is\nallowed to grow with the sample size.\n", "versions": [{"version": "v1", "created": "Tue, 11 Nov 2014 04:58:55 GMT"}, {"version": "v2", "created": "Mon, 17 Nov 2014 23:54:14 GMT"}, {"version": "v3", "created": "Wed, 24 Dec 2014 07:33:20 GMT"}, {"version": "v4", "created": "Mon, 17 Aug 2015 04:15:51 GMT"}], "update_date": "2018-01-04", "authors_parsed": [["Pouzo", "Demian", ""]]}, {"id": "1411.2732", "submitter": "Michel Valadier", "authors": "Michel Valadier", "title": "Quantiles as minimizers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A real random variable admits median(s) and quantiles. These values minimize\nconvex functions on $\\mathbb R$. We show by \"Convex Analysis\" arguments that\nthe function to be minimized is very natural. The relationship with some\nnotions about functions of bounded variation developed by J.J.~Moreau is\nemphasized.\n", "versions": [{"version": "v1", "created": "Tue, 11 Nov 2014 09:05:49 GMT"}], "update_date": "2014-11-12", "authors_parsed": [["Valadier", "Michel", ""]]}, {"id": "1411.2907", "submitter": "Wenxin Jiang", "authors": "Wenxin Jiang", "title": "Some Simple Formulas for Posterior Convergence Rates", "comments": "8 pages", "journal-ref": "International Scholarly Research Notices, Volume 2014 (2014),\n  Article ID 469340, 8 pages", "doi": "10.1155/2014/469340", "report-no": null, "categories": "math.ST stat.TH", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  We derive some simple relations that demonstrate how the posterior\nconvergence rate is related to two driving factors: a \"penalized divergence\" of\nthe prior, which measures the ability of the prior distribution to propose a\nnonnegligible set of working models to approximate the true model and a \"norm\ncomplexity\" of the prior, which measures the complexity of the prior support,\nweighted by the prior probability masses. These formulas are explicit and\ninvolve no essential assumptions and are easy to apply. We apply this approach\nto the case with model averaging and derive some useful oracle inequalities\nthat can optimize the performance adaptively without knowing the true model.\n", "versions": [{"version": "v1", "created": "Tue, 11 Nov 2014 18:17:02 GMT"}], "update_date": "2014-11-12", "authors_parsed": [["Jiang", "Wenxin", ""]]}, {"id": "1411.2936", "submitter": "Lancelot F. James", "authors": "Lancelot F. James", "title": "Poisson Latent Feature Calculus for Generalized Indian Buffet Processes", "comments": "This version provides more details for the multivariate extensions in\n  section 5. We highlight the case of a simple multinomial distribution and\n  showcase a multivariate Levy process prior we call a stable-Beta Dirichlet\n  process. Section 4.1.1 expanded", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The purpose of this work is to describe a unified, and indeed simple,\nmechanism for non-parametric Bayesian analysis, construction and generative\nsampling of a large class of latent feature models which one can describe as\ngeneralized notions of Indian Buffet Processes(IBP). This is done via the\nPoisson Process Calculus as it now relates to latent feature models. The IBP\nwas ingeniously devised by Griffiths and Ghahramani in (2005) and its\ngenerative scheme is cast in terms of customers entering sequentially an Indian\nBuffet restaurant and selecting previously sampled dishes as well as new\ndishes. In this metaphor dishes corresponds to latent features, attributes,\npreferences shared by individuals. The IBP, and its generalizations, represent\nan exciting class of models well suited to handle high dimensional statistical\nproblems now common in this information age. The IBP is based on the usage of\nconditionally independent Bernoulli random variables, coupled with completely\nrandom measures acting as Bayesian priors, that are used to create sparse\nbinary matrices. This Bayesian non-parametric view was a key insight due to\nThibaux and Jordan (2007). One way to think of generalizations is to to use\nmore general random variables. Of note in the current literature are models\nemploying Poisson and Negative-Binomial random variables. However, unlike their\nclosely related counterparts, generalized Chinese restaurant processes, the\nability to analyze IBP models in a systematic and general manner is not yet\navailable. The limitations are both in terms of knowledge about the effects of\ndifferent priors and in terms of models based on a wider choice of random\nvariables. This work will not only provide a thorough description of the\nproperties of existing models but also provide a simple template to devise and\nanalyze new models.\n", "versions": [{"version": "v1", "created": "Tue, 11 Nov 2014 19:38:45 GMT"}, {"version": "v2", "created": "Mon, 17 Nov 2014 20:18:54 GMT"}, {"version": "v3", "created": "Sat, 20 Dec 2014 02:29:27 GMT"}], "update_date": "2014-12-23", "authors_parsed": [["James", "Lancelot F.", ""]]}, {"id": "1411.2944", "submitter": "Yue Zhao", "authors": "Yue Zhao and Marten Wegkamp", "title": "Semiparametric Gaussian copula classification", "comments": "55 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the binary classification of two distributions with the\nsame Gaussian copula in high dimensions. Under this semiparametric Gaussian\ncopula setting, we derive an accurate semiparametric estimator of the log\ndensity ratio, which leads to our empirical decision rule and a bound on its\nassociated excess risk. Our estimation procedure takes advantage of the\npotential sparsity as well as the low noise condition in the problem, which\nallows us to achieve faster convergence rate of the excess risk than is\npossible in the existing literature on semiparametric Gaussian copula\nclassification. We demonstrate the efficiency of our empirical decision rule by\nshowing that the bound on the excess risk nearly achieves a convergence rate of\n$n^{-1/2}$ in the simple setting of Gaussian distribution classification.\n", "versions": [{"version": "v1", "created": "Tue, 11 Nov 2014 20:03:45 GMT"}], "update_date": "2014-11-12", "authors_parsed": [["Zhao", "Yue", ""], ["Wegkamp", "Marten", ""]]}, {"id": "1411.3083", "submitter": "Mansi Garg", "authors": "Mansi Garg and Isha Dewan", "title": "On limiting distribution of U-statistics based on associated random\n  variables", "comments": "Changes in sections 3 and 4; Section 5 removed", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $\\{X_n, n \\ge 1\\}$ be a sequence of stationary associated random\nvariables. We discuss another set of conditions under which a central limit\ntheorem for U-statistics based on $\\{X_n, n \\ge 1\\}$ holds. We look at\nU-statistics based on differentiable kernels of degree 2 and above. We also\ndiscuss some applications.\n", "versions": [{"version": "v1", "created": "Wed, 12 Nov 2014 06:20:43 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2015 10:06:25 GMT"}, {"version": "v3", "created": "Tue, 19 Sep 2017 07:58:35 GMT"}], "update_date": "2017-09-20", "authors_parsed": [["Garg", "Mansi", ""], ["Dewan", "Isha", ""]]}, {"id": "1411.3145", "submitter": "Alejandro  Cholaquidis", "authors": "Jos\\'e R. Berrendero, Alejandro Cholaquidis, Antonio Cuevas, Ricardo\n  Fraiman", "title": "A geometrically motivated parametric model in manifold estimation,", "comments": "Statistics: A Journal of Theoretical and Applied Statistics, 2013", "journal-ref": null, "doi": "10.1080/02331888.2013.800264", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The general aim of manifold estimation is reconstructing, by statistical\nmethods, an $m$-dimensional compact manifold $S$ on ${\\mathbb R}^d$ (with\n$m\\leq d$) or estimating some relevant quantities related to the geometric\nproperties of $S$. We will assume that the sample data are given by the\ndistances to the $(d-1)$-dimensional manifold $S$ from points randomly chosen\non a band surrounding $S$, with $d=2$ and $d=3$. The point in this paper is to\nshow that, if $S$ belongs to a wide class of compact sets (which we call \\it\nsets with polynomial volume\\rm), the proposed statistical model leads to a\nrelatively simple parametric formulation. In this setup, standard methodologies\n(method of moments, maximum likelihood) can be used to estimate some\ninteresting geometric parameters, including curvatures and Euler\ncharacteristic. We will particularly focus on the estimation of the\n$(d-1)$-dimensional boundary measure (in Minkowski's sense) of $S$.\n  It turns out, however, that the estimation problem is not straightforward\nsince the standard estimators show a remarkably pathological behavior: while\nthey are consistent and asymptotically normal, their expectations are infinite.\nThe theoretical and practical consequences of this fact are discussed in some\ndetail.\n", "versions": [{"version": "v1", "created": "Wed, 12 Nov 2014 11:25:25 GMT"}], "update_date": "2014-11-13", "authors_parsed": [["Berrendero", "Jos\u00e9 R.", ""], ["Cholaquidis", "Alejandro", ""], ["Cuevas", "Antonio", ""], ["Fraiman", "Ricardo", ""]]}, {"id": "1411.3317", "submitter": "Sebastien Bubeck", "authors": "S\\'ebastien Bubeck, Luc Devroye, G\\'abor Lugosi", "title": "Finding Adam in random growing trees", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.DM cs.SI math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate algorithms to find the first vertex in large trees generated\nby either the uniform attachment or preferential attachment model. We require\nthe algorithm to output a set of $K$ vertices, such that, with probability at\nleast $1-\\epsilon$, the first vertex is in this set. We show that for any\n$\\epsilon$, there exist such algorithms with $K$ independent of the size of the\ninput tree. Moreover, we provide almost tight bounds for the best value of $K$\nas a function of $\\epsilon$. In the uniform attachment case we show that the\noptimal $K$ is subpolynomial in $1/\\epsilon$, and that it has to be at least\nsuperpolylogarithmic. On the other hand, the preferential attachment case is\nexponentially harder, as we prove that the best $K$ is polynomial in\n$1/\\epsilon$. We conclude the paper with several open problems.\n", "versions": [{"version": "v1", "created": "Wed, 12 Nov 2014 20:50:31 GMT"}, {"version": "v2", "created": "Tue, 1 Dec 2015 17:33:50 GMT"}], "update_date": "2015-12-02", "authors_parsed": [["Bubeck", "S\u00e9bastien", ""], ["Devroye", "Luc", ""], ["Lugosi", "G\u00e1bor", ""]]}, {"id": "1411.3390", "submitter": "Deepak Nag Ayyala", "authors": "Deepak Nag Ayyala, Junyong Park and Anindya Roy", "title": "Mean vector testing for high dimensional dependent observations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When testing for the mean vector in a high dimensional setting, it is\ngenerally assumed that the observations are independently and identically\ndistributed. However if the data are dependent, the existing test procedures\nfail to preserve type I error at a given nominal significance level. We propose\na new test for the mean vector when the dimension increases linearly with\nsample size and the data is a realization of an M -dependent stationary\nprocess. The order M is also allowed to increase with the sample size.\nAsymptotic normality of the test statistic is derived by extending the central\nlimit theorem result for M -dependent processes using two dimensional\ntriangular arrays. Finite sample simulation results indicate the cost of\nignoring dependence amongst observations.\n", "versions": [{"version": "v1", "created": "Wed, 12 Nov 2014 23:03:58 GMT"}, {"version": "v2", "created": "Fri, 14 Nov 2014 15:31:03 GMT"}], "update_date": "2014-11-17", "authors_parsed": [["Ayyala", "Deepak Nag", ""], ["Park", "Junyong", ""], ["Roy", "Anindya", ""]]}, {"id": "1411.3427", "submitter": "Luai Al Labadi Dr.", "authors": "Luai Al Labadi, Emad Masuadi, Mahmoud Zarepour", "title": "Two-sample Bayesian nonparametric goodness-of-fit test", "comments": "25 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, Bayesian nonparametric statistics has gathered extraordinary\nattention. Nonetheless, a relatively little amount of work has been expended on\nBayesian nonparametric hypothesis testing. In this paper, a novel Bayesian\nnonparametric approach to the two-sample problem is established. Precisely,\ngiven two samples $\\mathbf{X}=X_1,\\ldots,X_{m_1}$ $\\overset {i.i.d.} \\sim F$\nand $\\mathbf{Y}=Y_1,\\ldots,Y_{m_2} \\overset {i.i.d.} \\sim G$, with $F$ and $G$\nbeing unknown continuous cumulative distribution functions, we wish to test the\nnull hypothesis $\\mathcal{H}_0:~F=G$. The method is based on the Kolmogorov\ndistance and approximate samples from the Dirichlet process centered at the\nstandard normal distribution and a concentration parameter 1. It is\ndemonstrated that the proposed test is robust with respect to any prior\nspecification of the Dirichlet process. A power comparison with several\nwell-known tests is incorporated. In particular, the proposed test dominates\nthe standard Kolmogorov-Smirnov test in all the cases examined in the paper.\n", "versions": [{"version": "v1", "created": "Thu, 13 Nov 2014 02:51:05 GMT"}, {"version": "v2", "created": "Thu, 7 May 2015 12:10:51 GMT"}], "update_date": "2015-05-08", "authors_parsed": [["Labadi", "Luai Al", ""], ["Masuadi", "Emad", ""], ["Zarepour", "Mahmoud", ""]]}, {"id": "1411.3434", "submitter": "Luai Al Labadi Dr.", "authors": "Luai Al Labadi, Mahmoud Zarepour", "title": "On Approximations of the Beta Process in Latent Feature Models", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The beta process has recently been widely used as a nonparametric prior for\ndifferent models in machine learning, including latent feature models. In this\npaper, we prove the asymptotic consistency of the finite dimensional\napproximation of the beta process due to Paisley \\& Carin (2009). In addition,\nwe derive an almost sure approximation of the beta process. This approximation\nprovides a direct method to efficiently simulate the beta process. A simulated\nexample, illustrating the work of the method and comparing its performance to\nseveral existing algorithms, is also included.\n", "versions": [{"version": "v1", "created": "Thu, 13 Nov 2014 03:06:37 GMT"}], "update_date": "2014-11-14", "authors_parsed": [["Labadi", "Luai Al", ""], ["Zarepour", "Mahmoud", ""]]}, {"id": "1411.3486", "submitter": "Nero Budur", "authors": "Nero Budur and Botong Wang", "title": "Bounding the maximum likelihood degree", "comments": "v2: final version, to appear in Math. Res. Lett", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Maximum likelihood estimation is a fundamental computational problem in\nstatistics. In this note, we give a bound for the maximum likelihood degree of\nalgebraic statistical models for discrete data. As usual, such models are\nidentified with special very affine varieties. Using earlier work of Franecki\nand Kapranov, we prove that the maximum likelihood degree is always less or\nequal to the signed intersection-cohomology Euler characteristic. We construct\ncounterexamples to a bound in terms of the usual Euler characteristic\nconjectured by Huh and Sturmfels.\n", "versions": [{"version": "v1", "created": "Thu, 13 Nov 2014 10:16:58 GMT"}, {"version": "v2", "created": "Fri, 17 Apr 2015 18:46:03 GMT"}], "update_date": "2015-04-20", "authors_parsed": [["Budur", "Nero", ""], ["Wang", "Botong", ""]]}, {"id": "1411.3488", "submitter": "Zu-Guo Yu", "authors": "Long Shi, Zu-Guo Yu, Hai-Lan Huang, Zhi Mao and Ai-Guo Xiao", "title": "The subordinated processes controlled by a family of subordinators and\n  corresponding Fokker-Planck type equations", "comments": "11 pages, accepted by J. Stat. Mech.: Theor. Exp", "journal-ref": "J. Stat. Mech.: Theor. Exp., 2014: P12002", "doi": "10.1088/1742-5468/2014/12/P12002", "report-no": null, "categories": "cond-mat.stat-mech math.ST stat.TH", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  In this work, we consider subordinated processes controlled by a family of\nsubordinators which consist of a power function of time variable and a negative\npower function of $\\alpha-$stable random variable. The effect of parameters in\nthe subordinators on the subordinated process is discussed. By suitable\nvariable substitutions and Laplace transform technique, the corresponding\nfractional Fokker-Planck-type equations are derived. We also compute their mean\nsquare displacements in a free force field. By choosing suitable ranges of\nparameters, the resulting subordinated processes may be subdiffusive, normal\ndiffusive or superdiffusive.\n", "versions": [{"version": "v1", "created": "Thu, 13 Nov 2014 10:18:52 GMT"}], "update_date": "2015-02-11", "authors_parsed": [["Shi", "Long", ""], ["Yu", "Zu-Guo", ""], ["Huang", "Hai-Lan", ""], ["Mao", "Zhi", ""], ["Xiao", "Ai-Guo", ""]]}, {"id": "1411.3609", "submitter": "Jana Jure\\v{c}kov\\'{a}", "authors": "Jana Jure\\v{c}kov\\'a, Hira L. Koul, Radim Navr\\'atil, Jan Picek", "title": "Behavior of R-estimators under measurement errors", "comments": "Published at http://dx.doi.org/10.3150/14-BEJ687 in the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2016, Vol. 22, No. 2, 1093-1112", "doi": "10.3150/14-BEJ687", "report-no": "IMS-BEJ-BEJ687", "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As was shown recently, the measurement errors in regressors affect only the\npower of the rank test, but not its critical region. Noting that, we study the\neffect of measurement errors on R-estimators in linear model. It is\ndemonstrated that while an R-estimator admits a local asymptotic bias, its bias\nsurprisingly depends only on the precision of measurements and does neither\ndepend on the chosen rank test score-generating function nor on the regression\nmodel error distribution. The R-estimators are numerically illustrated and\ncompared with the LSE and $L_1$ estimators in this situation.\n", "versions": [{"version": "v1", "created": "Thu, 13 Nov 2014 16:39:47 GMT"}, {"version": "v2", "created": "Fri, 5 Feb 2016 08:04:36 GMT"}], "update_date": "2016-02-08", "authors_parsed": [["Jure\u010dkov\u00e1", "Jana", ""], ["Koul", "Hira L.", ""], ["Navr\u00e1til", "Radim", ""], ["Picek", "Jan", ""]]}, {"id": "1411.3686", "submitter": "Guang Cheng", "authors": "Zuofeng Shang and Guang Cheng", "title": "Gaussian Approximation of General Nonparametric Posterior Distributions", "comments": "To Appear in Information and Inference. In Memory of Prof. Jayanta\n  Ghosh", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a general class of Bayesian nonparametric models, we prove that the\nposterior distribution can be asymptotically approximated by a Gaussian\nprocess. Our results apply to nonparametric exponential family that contains\nboth Gaussian and non-Gaussian regression, and also hold for both efficient\n(root-n) and inefficient (non root-n) estimation. Our general approximation\ntheorem does not rely on posterior conjugacy, and can be verified in a class of\nGaussian process priors that has a smoothing spline interpretation [59, 44]. In\nparticular, the limiting posterior measure becomes prior-free under a Bayesian\nversion of \"under-smoothing\" condition. Finally, we apply our approximation\ntheorem to examine the asymptotic frequentist properties of Bayesian procedures\nsuch as credible regions and credible intervals.\n", "versions": [{"version": "v1", "created": "Thu, 13 Nov 2014 19:57:55 GMT"}, {"version": "v2", "created": "Thu, 16 Jul 2015 02:42:17 GMT"}, {"version": "v3", "created": "Tue, 15 Nov 2016 15:09:03 GMT"}, {"version": "v4", "created": "Tue, 31 Oct 2017 00:08:58 GMT"}], "update_date": "2017-11-01", "authors_parsed": [["Shang", "Zuofeng", ""], ["Cheng", "Guang", ""]]}, {"id": "1411.3800", "submitter": "Ajay Jasra", "authors": "Hock Peng Chan, Pierre Del Moral, Ajay Jasra", "title": "A Sharp First Order Analysis of Feynman-Kac Particle Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article provides a new theory for the analysis of forward and backward\nparticle approximations of Feynman-Kac models. Such formulae are found in a\nwide variety of applications and their numerical (particle) approximation are\nrequired due to their intractability. Under mild assumptions, we provide sharp\nand non-asymptotic first order expansions of these particle methods,\npotentially on path space and for possibly unbounded functions. These\nexpansions allows one to consider upper and lower bound bias type estimates for\na given time horizon $n$ and particle number $N$; these non-asymptotic\nestimates are of order $\\mathcal{O}(n/N)$. Our approach is extended to tensor\nproducts of particle density profiles, leading to new sharp and non-asymptotic\npropagation of chaos estimates. The resulting upper and lower bound propagation\nof chaos estimates seems to be the first result of this kind for mean field\nparticle models. As a by-product of our results, we also provide some analysis\nof the particle Gibbs sampler, providing first order expansions of the kernel\nand minorization estimates.\n", "versions": [{"version": "v1", "created": "Fri, 14 Nov 2014 05:42:32 GMT"}], "update_date": "2014-11-17", "authors_parsed": [["Chan", "Hock Peng", ""], ["Del Moral", "Pierre", ""], ["Jasra", "Ajay", ""]]}, {"id": "1411.3825", "submitter": "Kayvan Sadeghi", "authors": "Kayvan Sadeghi and Alessandro Rinaldo", "title": "Statistical Models for Degree Distributions of Networks", "comments": "13 pages. 4 figures, a shorter version to be presented at NIPS\n  workshop 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define and study the statistical models in exponential family form whose\nsufficient statistics are the degree distributions and the bi-degree\ndistributions of undirected labelled simple graphs. Graphs that are constrained\nby the joint degree distributions are called $dK$-graphs in the computer\nscience literature and this paper attempts to provide the first statistically\ngrounded analysis of this type of models. In addition to formalizing these\nmodels, we provide some preliminary results for the parameter estimation and\nthe asymptotic behaviour of the model for degree distribution, and discuss the\nparameter estimation for the model for bi-degree distribution.\n", "versions": [{"version": "v1", "created": "Fri, 14 Nov 2014 08:30:53 GMT"}], "update_date": "2014-11-17", "authors_parsed": [["Sadeghi", "Kayvan", ""], ["Rinaldo", "Alessandro", ""]]}, {"id": "1411.3875", "submitter": "Alexei Onatski", "authors": "Prathapasinghe Dharmawansa, Iain M. Johnstone, and Alexei Onatski", "title": "Local Asymptotic Normality of the spectrum of high-dimensional spiked\n  F-ratios", "comments": "42 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider two types of spiked multivariate F distributions: a scaled\ndistribution with the scale matrix equal to a rank-one perturbation of the\nidentity, and a distribution with trivial scale, but rank-one non-centrality.\nThe norm of the rank-one matrix (spike) parameterizes the joint distribution of\nthe eigenvalues of the corresponding F matrix. We show that, for a spike\nlocated above a phase transition threshold, the asymptotic behavior of the log\nratio of the joint density of the eigenvalues of the F matrix to their joint\ndensity under a local deviation from this value depends only on the largest\neigenvalue $\\lambda_{1}$. Furthermore, $\\lambda_{1}$ is asymptotically normal,\nand the statistical experiment of observing all the eigenvalues of the F matrix\nconverges in the Le Cam sense to a Gaussian shift experiment that depends on\nthe asymptotic mean and variance of $\\lambda_{1}$. In particular, the best\nstatistical inference about a sufficiently large spike in the local asymptotic\nregime is based on the largest eigenvalue only. As a by-product of our\nanalysis, we establish joint asymptotic normality of a few of the largest\neigenvalues of the multi-spiked F matrix when the corresponding spikes are\nabove the phase transition threshold.\n", "versions": [{"version": "v1", "created": "Fri, 14 Nov 2014 11:56:28 GMT"}], "update_date": "2014-11-17", "authors_parsed": [["Dharmawansa", "Prathapasinghe", ""], ["Johnstone", "Iain M.", ""], ["Onatski", "Alexei", ""]]}, {"id": "1411.3984", "submitter": "Clint Scovel", "authors": "Houman Owhadi and Clint Scovel", "title": "Qualitative Robustness in Bayesian Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The practical implementation of Bayesian inference requires numerical\napproximation when closed-form expressions are not available. What types of\naccuracy (convergence) of the numerical approximations guarantee robustness and\nwhat types do not? In particular, is the recursive application of Bayes' rule\nrobust when subsequent data or posteriors are approximated? When the prior is\nthe push forward of a distribution by the map induced by the solution of a PDE,\nin which norm should that solution be approximated? Motivated by such\nquestions, we investigate the sensitivity of the distribution of posterior\ndistributions (i.e. posterior distribution-valued random variables, randomized\nthrough the data) with respect to perturbations of the prior and data\ngenerating distributions in the limit when the number of data points grows\ntowards infinity.\n", "versions": [{"version": "v1", "created": "Fri, 14 Nov 2014 17:36:02 GMT"}, {"version": "v2", "created": "Tue, 9 Dec 2014 14:57:16 GMT"}, {"version": "v3", "created": "Wed, 20 Apr 2016 17:22:12 GMT"}], "update_date": "2016-04-21", "authors_parsed": [["Owhadi", "Houman", ""], ["Scovel", "Clint", ""]]}, {"id": "1411.4040", "submitter": "Dena Asta", "authors": "Dena Marie Asta", "title": "Kernel Density Estimation on Symmetric Spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We construct and prove the existence of a kernel density estimator on\nsymmetric spaces of non-compact type with minimax convergence rate. Symmetric\nspaces of non-compact type include hyperboloids of constant curvature -1 and\nspaces of symmetric positive definite matrices. This paper obtains a simplified\nformula in the special case when the symmetric space is the space of normal\ndistributions, a 2-dimensional hyperboloid.\n", "versions": [{"version": "v1", "created": "Fri, 14 Nov 2014 20:54:43 GMT"}, {"version": "v2", "created": "Tue, 1 Oct 2019 19:34:54 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["Asta", "Dena Marie", ""]]}, {"id": "1411.4074", "submitter": "Mark Huber", "authors": "Mark Huber", "title": "Improving Monte Carlo randomized approximation schemes", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.CC math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a central problem in randomized approximation schemes that use a\nMonte Carlo approach. Given a sequence of independent, identically distributed\nrandom variables $X_1,X_2,\\ldots$ with mean $\\mu$ and standard deviation at\nmost $c \\mu$, where $c$ is a known constant, and $\\epsilon,\\delta > 0$, create\nan estimate $\\hat \\mu$ for $\\mu$ such that $\\text{P}(|\\hat \\mu - \\mu| >\n\\epsilon \\mu) \\leq \\delta$. This technique has been used for building\nrandomized approximation schemes for the volume of a convex body, the permanent\nof a nonnegative matrix, the number of linear extensions of a poset, the\npartition function of the Ising model and many other problems. Existing methods\nuse (to the leading order) $19.35 (c/\\epsilon)^2 \\ln(\\delta^{-1})$ samples.\nThis is the best possible number up to the constant factor, and it is an open\nquestion as to what is the best constant possible. This work gives an easy to\napply estimate that only uses $6.96 (c/\\epsilon)^2 \\ln(\\delta^{-1})$ samples in\nthe leading order.\n", "versions": [{"version": "v1", "created": "Fri, 14 Nov 2014 22:40:04 GMT"}], "update_date": "2014-11-18", "authors_parsed": [["Huber", "Mark", ""]]}, {"id": "1411.4086", "submitter": "Hongwei Li", "authors": "Hongwei Li and Bin Yu", "title": "Error Rate Bounds and Iterative Weighted Majority Voting for\n  Crowdsourcing", "comments": "Journal Submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.HC cs.LG math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Crowdsourcing has become an effective and popular tool for human-powered\ncomputation to label large datasets. Since the workers can be unreliable, it is\ncommon in crowdsourcing to assign multiple workers to one task, and to\naggregate the labels in order to obtain results of high quality. In this paper,\nwe provide finite-sample exponential bounds on the error rate (in probability\nand in expectation) of general aggregation rules under the Dawid-Skene\ncrowdsourcing model. The bounds are derived for multi-class labeling, and can\nbe used to analyze many aggregation methods, including majority voting,\nweighted majority voting and the oracle Maximum A Posteriori (MAP) rule. We\nshow that the oracle MAP rule approximately optimizes our upper bound on the\nmean error rate of weighted majority voting in certain setting. We propose an\niterative weighted majority voting (IWMV) method that optimizes the error rate\nbound and approximates the oracle MAP rule. Its one step version has a provable\ntheoretical guarantee on the error rate. The IWMV method is intuitive and\ncomputationally simple. Experimental results on simulated and real data show\nthat IWMV performs at least on par with the state-of-the-art methods, and it\nhas a much lower computational cost (around one hundred times faster) than the\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sat, 15 Nov 2014 00:02:34 GMT"}], "update_date": "2014-11-18", "authors_parsed": [["Li", "Hongwei", ""], ["Yu", "Bin", ""]]}, {"id": "1411.4138", "submitter": "Piotr Szulc", "authors": "Piotr Szulc", "title": "Consistency of modified versions of Bayesian Information Criterion in\n  sparse linear regression with subgaussian errors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a sparse linear regression model, when the number of available\npredictors, $p$, is much larger than the sample size, $n$, and the number of\nnon-zero coefficients, $p_0$, is small. To choose the regression model in this\nsituation, we cannot use classical model selection criteria. In recent years,\nspecial methods have been proposed to deal with this type of problem, for\nexample modified versions of Bayesian Information Criterion, like mBIC or\nmBIC2. It was shown that these criteria are consistent under the assumption\nthat both $n$ and $p$ as well as $p_0$ tend to infinity and the error term is\nnormally distributed. In this article we prove the consistency of mBIC and\nmBIC2 under the assumption that the error term is a subgaussian random\nvariable.\n", "versions": [{"version": "v1", "created": "Sat, 15 Nov 2014 11:52:06 GMT"}, {"version": "v2", "created": "Tue, 29 May 2018 20:14:16 GMT"}], "update_date": "2018-05-31", "authors_parsed": [["Szulc", "Piotr", ""]]}, {"id": "1411.4226", "submitter": "Prathapasinghe Dharmawansa", "authors": "Prathapasinghe Dharmawansa, Boaz Nadler, and Ofer Shwartz", "title": "Roy's largest root under rank-one alternatives:The complex valued case\n  and applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT math.IT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The largest eigenvalue of a Wishart matrix, known as Roy's largest root\n(RLR), plays an important role in a variety of applications. Most works to date\nderived approximations to its distribution under various asymptotic regimes,\nsuch as degrees of freedom, dimension, or both tending to infinity. However,\nseveral applications involve finite and relative small parameters, for which\nthe above approximations may be inaccurate. Recently, via a small noise\nperturbation approach with fixed dimension and degrees of freedom, Johnstone\nand Nadler derived simple yet accurate stochastic approximations to the\ndistribution of Roy's largest root in the real valued case, under a rank-one\nalternative. In this paper, we extend their results to the complex valued case.\nFurthermore, we analyze the behavior of the leading eigenvector by developing\nnew stochastic approximations. Specifically, we derive simple stochastic\napproximations to the distribution of the largest eigenvalue under five common\ncomplex single-matrix and double-matrix scenarios. We then apply these results\nto investigate several problems in signal detection and communications. In\nparticular, we analyze the performance of RLR detector in cognitive radio\nspectrum sensing and constant modulus signal detection in the high\nsignal-to-noise ratio (SNR) regime. Moreover, we address the problem of\ndetermining the optimal transmit-receive antenna configuration (here optimality\nis in the sense of outage minimization) for rank-one multiple-input\nmultiple-output Rician Fading channels at high SNR.\n", "versions": [{"version": "v1", "created": "Sun, 16 Nov 2014 08:14:49 GMT"}], "update_date": "2014-11-18", "authors_parsed": [["Dharmawansa", "Prathapasinghe", ""], ["Nadler", "Boaz", ""], ["Shwartz", "Ofer", ""]]}, {"id": "1411.4281", "submitter": "Kammoun Abla", "authors": "Nadhir Ben Rached and Abla Kammoun and Mohamed-Slim Alouini and Raul\n  Tempone", "title": "An Improved Hazard Rate Twisting Approach for the Statistic of the Sum\n  of Subexponential Variates (Extended Version)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this letter, we present an improved hazard rate twisting technique for the\nestimation of the probability that a sum of independent but not necessarily\nidentically distributed subexponential Random Variables (RVs) exceeds a given\nthreshold. Instead of twisting all the components in the summation, we propose\nto twist only the RVs which have the biggest impact on the right-tail of the\nsum distribution and keep the other RVs unchanged. A minmax approach is\nperformed to determine the optimal twisting parameter which leads to an\nasymptotic optimality criterion. Moreover, we show through some selected\nsimulation results that our proposed approach results in a variance reduction\ncompared to the technique where all the components are twisted.\n", "versions": [{"version": "v1", "created": "Sun, 16 Nov 2014 17:26:37 GMT"}, {"version": "v2", "created": "Thu, 9 Apr 2015 11:19:23 GMT"}], "update_date": "2015-04-10", "authors_parsed": [["Rached", "Nadhir Ben", ""], ["Kammoun", "Abla", ""], ["Alouini", "Mohamed-Slim", ""], ["Tempone", "Raul", ""]]}, {"id": "1411.4626", "submitter": "Yining Chen", "authors": "Yining Chen and Jon A. Wellner", "title": "On Convex Least Squares Estimation when the Truth is Linear", "comments": "35 pages, 5 figures", "journal-ref": "Electronic Journal of Statistics, 2016, 10(1):171-209", "doi": "10.1214/15-EJS1098", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that the convex least squares estimator (LSE) attains a $n^{-1/2}$\npointwise rate of convergence in any region where the truth is linear. In\naddition, the asymptotic distribution can be characterized by a modified\ninvelope process. Analogous results hold when one uses the derivative of the\nconvex LSE to perform derivative estimation. These asymptotic results\nfacilitate a new consistent testing procedure on the linearity against a convex\nalternative. Moreover, we show that the convex LSE adapts to the optimal rate\nat the boundary points of the region where the truth is linear, up to a log-log\nfactor. These conclusions are valid in the context of both density estimation\nand regression function estimation.\n", "versions": [{"version": "v1", "created": "Mon, 17 Nov 2014 20:25:22 GMT"}, {"version": "v2", "created": "Mon, 9 Nov 2015 21:17:32 GMT"}], "update_date": "2018-01-30", "authors_parsed": [["Chen", "Yining", ""], ["Wellner", "Jon A.", ""]]}, {"id": "1411.4681", "submitter": "Surajit Ray", "authors": "Chong Liu, Surajit Ray and Giles Hooker", "title": "Functional Principal Components Analysis of Spatially Correlated Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on the analysis of spatially correlated functional data.\nThe between-curve correlation is modeled by correlating functional principal\ncomponent scores of the functional data. We propose a Spatial Principal\nAnalysis by Conditional Expectation framework to explicitly estimate spatial\ncorrelations and reconstruct individual curves. This approach works even when\nthe observed data per curve are sparse. Assuming spatial stationarity,\nempirical spatial correlations are calculated as the ratio of eigenvalues of\nthe smoothed covariance surface $Cov(X_i(s),X_i(t))$ and cross-covariance\nsurface $Cov(X_i(s), X_j(t))$ at locations indexed by $i$ and $j$. Then a\nanisotropy Mat\\'ern spatial correlation model is fit to empirical correlations.\nFinally, principal component scores are estimated to reconstruct the sparsely\nobserved curves. This framework can naturally accommodate arbitrary covariance\nstructures, but there is an enormous reduction in computation if one can assume\nthe separability of temporal and spatial components. We propose hypothesis\ntests to examine the separability as well as the isotropy effect of spatial\ncorrelation. Simulation studies and applications of empirical data show\nimprovements in the curve reconstruction using our framework over the method\nwhere curves are assumed to be independent. In addition, we show that the\nasymptotic properties of estimates in uncorrelated case still hold in our case\nif 'mild' spatial correlation is assumed.\n", "versions": [{"version": "v1", "created": "Mon, 17 Nov 2014 21:46:58 GMT"}], "update_date": "2014-11-19", "authors_parsed": [["Liu", "Chong", ""], ["Ray", "Surajit", ""], ["Hooker", "Giles", ""]]}, {"id": "1411.4686", "submitter": "Roman Vershynin", "authors": "Olivier Gu\\'edon and Roman Vershynin", "title": "Community detection in sparse networks via Grothendieck's inequality", "comments": "This is the final version, incorporating the referee's comments", "journal-ref": "Probability Theory and Related Fields 165 (2016), 1025--1049", "doi": null, "report-no": null, "categories": "math.ST cs.SI stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a simple and flexible method to prove consistency of semidefinite\noptimization problems on random graphs. The method is based on Grothendieck's\ninequality. Unlike the previous uses of this inequality that lead to constant\nrelative accuracy, we achieve any given relative accuracy by leveraging\nrandomness. We illustrate the method with the problem of community detection in\nsparse networks, those with bounded average degrees. We demonstrate that even\nin this regime, various simple and natural semidefinite programs can be used to\nrecover the community structure up to an arbitrarily small fraction of\nmisclassified vertices. The method is general; it can be applied to a variety\nof stochastic models of networks and semidefinite programs.\n", "versions": [{"version": "v1", "created": "Mon, 17 Nov 2014 22:07:29 GMT"}, {"version": "v2", "created": "Tue, 25 Nov 2014 18:48:02 GMT"}, {"version": "v3", "created": "Tue, 9 Jun 2015 18:15:51 GMT"}, {"version": "v4", "created": "Fri, 21 Aug 2015 12:56:26 GMT"}], "update_date": "2016-12-23", "authors_parsed": [["Gu\u00e9don", "Olivier", ""], ["Vershynin", "Roman", ""]]}, {"id": "1411.4688", "submitter": "Stilian Stoev", "authors": "Hans-Peter Scheffler and Stilian Stoev", "title": "Implicit Extremes and Implicit Max-Stable Laws", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $X_1,...,X_n$ be iid random vectors and $f\\ge 0$ be a non-negative\nfunction. Let also $k(n) = {\\rm Argmax}_{i=1,...,n} f(X_i)$. We are interested\nin the distribution of $X_{k(n)}$ and their limit theorems. In other words,\nwhat is the distribution the random vector where a function of its components\nis extreme? This question is motivated by a kind of inverse problem where one\nwants to determine the extremal behavior of $X$ when only explicitly observing\n$f(X)$. We shall refer to such types of results as to implicit extremes. It\nturns out that, as in the usual case of explicit extremes, all limit implicit\nextreme value laws are implicit max-stable. We characterize the regularly\nvarying implicit max-stable laws in terms of their spectral and stochastic\nrepresentations. We also establish the asymptotic behavior of implicit order\nstatistics relative to a given homogeneous loss and conclude with several\nexamples drawing connections to prior work involving regular variation on\ngeneral cones.\n", "versions": [{"version": "v1", "created": "Mon, 17 Nov 2014 22:24:52 GMT"}], "update_date": "2014-11-19", "authors_parsed": [["Scheffler", "Hans-Peter", ""], ["Stoev", "Stilian", ""]]}, {"id": "1411.4691", "submitter": "Yiyuan She", "authors": "Yiyuan She, Zhifeng Wang and He Jiang", "title": "Group Regularized Estimation under Structural Hierarchy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.CO stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variable selection for models including interactions between explanatory\nvariables often needs to obey certain hierarchical constraints. The weak or\nstrong structural hierarchy requires that the existence of an interaction term\nimplies at least one or both associated main effects to be present in the\nmodel. Lately, this problem has attracted a lot of attention, but existing\ncomputational algorithms converge slow even with a moderate number of\npredictors. Moreover, in contrast to the rich literature on ordinary variable\nselection, there is a lack of statistical theory to show reasonably low error\nrates of hierarchical variable selection.\n  This work investigates a new class of estimators that make use of multiple\ngroup penalties to capture structural parsimony. We give the minimax lower\nbounds for strong and weak hierarchical variable selection and show that the\nproposed estimators enjoy sharp rate oracle inequalities. A general-purpose\nalgorithm is developed with guaranteed convergence and global optimality.\nSimulations and real data experiments demonstrate the efficiency and efficacy\nof the proposed approach.\n", "versions": [{"version": "v1", "created": "Mon, 17 Nov 2014 23:03:11 GMT"}, {"version": "v2", "created": "Thu, 20 Oct 2016 03:51:40 GMT"}, {"version": "v3", "created": "Tue, 8 Nov 2016 21:00:25 GMT"}], "update_date": "2016-11-10", "authors_parsed": [["She", "Yiyuan", ""], ["Wang", "Zhifeng", ""], ["Jiang", "He", ""]]}, {"id": "1411.4708", "submitter": "Charles R Doss", "authors": "Fadoua Balabdaoui and Charles R. Doss", "title": "Inference for a Two-Component Mixture of Symmetric Distributions under\n  Log-Concavity", "comments": "47 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we revisit the problem of estimating the unknown\nzero-symmetric distribution in a two-component location mixture model,\nconsidered in previous works, now under the assumption that the zero-symmetric\ndistribution has a log-concave density. When consistent estimators for the\nshift locations and mixing probability are used, we show that the nonparametric\nlog-concave Maximum Likelihood estimator (MLE) of both the mixed density and\nthat of the unknown zero-symmetric component are consistent in the Hellinger\ndistance. In case the estimators for the shift locations and mixing probability\nare $\\sqrt n$-consistent, we establish that these MLE's converge to the truth\nat the rate $n^{-2/5}$ in the $L_1$ distance. To estimate the shift locations\nand mixing probability, we use the estimators proposed by\n\\cite{hunteretal2007}. The unknown zero-symmetric density is efficiently\ncomputed using the \\proglang{R} package \\pkg{logcondens.mode}.\n", "versions": [{"version": "v1", "created": "Tue, 18 Nov 2014 01:29:01 GMT"}, {"version": "v2", "created": "Sun, 7 Feb 2016 21:54:18 GMT"}, {"version": "v3", "created": "Fri, 6 May 2016 02:41:49 GMT"}], "update_date": "2016-05-09", "authors_parsed": [["Balabdaoui", "Fadoua", ""], ["Doss", "Charles R.", ""]]}, {"id": "1411.4944", "submitter": "Matteo Ruggiero", "authors": "Omiros Papaspiliopoulos, Matteo Ruggiero and Dario Span\\`o", "title": "Filtering hidden Markov measures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning two families of time-evolving random\nmeasures from indirect observations. In the first model, the signal is a\nFleming--Viot diffusion, which is reversible with respect to the law of a\nDirichlet process, and the data is a sequence of random samples from the state\nat discrete times. In the second model, the signal is a Dawson--Watanabe\ndiffusion, which is reversible with respect to the law of a gamma random\nmeasure, and the data is a sequence of Poisson point configurations whose\nintensity is given by the state at discrete times. A common methodology is\ndeveloped to obtain the filtering distributions in a computable form, which is\nbased on the projective properties of the signals and duality properties of\ntheir projections. The filtering distributions take the form of mixtures of\nDirichlet processes and gamma random measures for each of the two families\nrespectively, and an explicit algorithm is provided to compute the parameters\nof the mixtures. Hence, our results extend classic characterisations of the\nposterior distribution under Dirichlet process and gamma random measures priors\nto a dynamic framework.\n", "versions": [{"version": "v1", "created": "Tue, 18 Nov 2014 18:06:41 GMT"}], "update_date": "2014-11-19", "authors_parsed": [["Papaspiliopoulos", "Omiros", ""], ["Ruggiero", "Matteo", ""], ["Span\u00f2", "Dario", ""]]}, {"id": "1411.5159", "submitter": "Hacene Djellout", "authors": "Hac\\`ene Djellout, Arnaud Guillin, Yacouba Samoura", "title": "Large deviations of the realized (co-)volatility vector", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST q-fin.GN stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Realized statistics based on high frequency returns have become very popular\nin financial economics. In recent years, different non-parametric estimators of\nthe variation of a log-price process have appeared. These were developed by\nmany authors and were motivated by the existence of complete records of price\ndata. Among them are the realized quadratic (co-)variation which is perhaps the\nmost well known example, providing a consistent estimator of the integrated\n(co-)volatility when the logarithmic price process is continuous. Limit results\nsuch as the weak law of large numbers or the central limit theorem have been\nproved in different contexts. In this paper, we propose to study the large\ndeviation properties of realized (co-)volatility (i.e., when the number of high\nfrequency observations in a fixed time interval increases to infinity. More\nspecifically, we consider a bivariate model with synchronous observation\nschemes and correlated Brownian motions of the following form: $dX\\_{\\ell,t} =\n\\sigma\\_{\\ell,t}dB\\_{\\ell,t}+b\\_{\\ell}(t,\\omega)dt$ for $\\ell=1,2$, where\n$X\\_{\\ell}$ denotes the log-price, we are concerned with the large deviation\nestimation of the vector $V\\_t^n(X)=(Q\\_{1,t}^n(X), Q\\_{2,t}^n(X),\nC\\_{t}^n(X))$ where $Q\\_{\\ell,t}^n(X)$ and $C\\_{t}^n(X)$ represente the\nestimator of the quadratic variational processes\n$Q\\_{\\ell,t}=\\int\\_0^t\\sigma\\_{\\ell,s}^2ds$ and the integrated covariance\n$C\\_t=\\int\\_0^t\\sigma\\_{1,s}\\sigma\\_{2,s}\\rho\\_sds$ respectively, with\n$\\rho\\_t=cov(B\\_{1,t}, B\\_{2,t})$. Our main motivation is to improve upon the\nexisting limit theorems. Our large deviations results can be used to evaluate\nand approximate tail probabilities of realized (co-)volatility. As an\napplication we provide the large deviation for the standard dependence measures\nbetween the two assets returns such as the realized regression coefficients up\nto time $t$, or the realized correlation. Our study should contribute to the\nrecent trend of research on the (co-)variance estimation problems, which are\nquite often discussed in high-frequency financial data analysis.\n", "versions": [{"version": "v1", "created": "Wed, 19 Nov 2014 09:42:49 GMT"}], "update_date": "2014-11-20", "authors_parsed": [["Djellout", "Hac\u00e8ne", ""], ["Guillin", "Arnaud", ""], ["Samoura", "Yacouba", ""]]}, {"id": "1411.5305", "submitter": "Jan  Vrbik", "authors": "Hao Yuan Zhang and Jan Vrbik", "title": "Accurate distribution of X^{T}X with singular, idempotent\n  variance-covariance matrix", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Assume that X is a set of sample statistics which follow a special case\nCentral Limit Theorem, namely: as the sample size n increases the corresponding\ndistribution becomes multivariate Normal with the mean (of each X) equal to\nzero and with an idempotent variance-covariance matrix V. It is well known that\nX^{T}X has (in the same limit), a chi-squared distribution with degrees of\nfreedom equal to the trace of V. In this article we extend the above result to\ninclude the corresponding (1/n)-proportional corrections, making the new\napproximation substantially more accurate and extending its range of\napplicability to small-size samples.\n", "versions": [{"version": "v1", "created": "Wed, 19 Nov 2014 18:28:32 GMT"}, {"version": "v2", "created": "Thu, 20 Nov 2014 17:47:46 GMT"}], "update_date": "2014-11-21", "authors_parsed": [["Zhang", "Hao Yuan", ""], ["Vrbik", "Jan", ""]]}, {"id": "1411.5310", "submitter": "BaoLuo Sun", "authors": "BaoLuo Sun and Eric J. Tchetgen Tchetgen", "title": "On Inverse Probability Weighting for Nonmonotone Missing at Random Data", "comments": null, "journal-ref": "Journal of the American Statistical Association 113(2018) 369-379", "doi": "10.1080/01621459.2016.1256814", "report-no": null, "categories": "stat.ME math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The development of coherent missing data models to account for nonmonotone\nmissing at random (MAR) data by inverse probability weighting (IPW) remains to\ndate largely unresolved. As a consequence, IPW has essentially been restricted\nfor use only in monotone missing data settings. We propose a class of models\nfor nonmonotone missing data mechanisms that spans the MAR model, while\nallowing the underlying full data law to remain unrestricted. For parametric\nspecifications within the proposed class, we introduce an unconstrained maximum\nlikelihood estimator for estimating the missing data probabilities which can be\neasily implemented using existing software. To circumvent potential convergence\nissues with this procedure, we also introduce a Bayesian constrained approach\nto estimate the missing data process which is guaranteed to yield inferences\nthat respect all model restrictions. The efficiency of the standard IPW\nestimator is improved by incorporating information from incomplete cases\nthrough an augmented estimating equation which is optimal within a large class\nof estimating equations. We investigate the finite-sample properties of the\nproposed estimators in a simulation study and illustrate the new methodology in\nan application evaluating key correlates of preterm delivery for infants born\nto HIV infected mothers in Botswana, Africa.\n", "versions": [{"version": "v1", "created": "Wed, 19 Nov 2014 18:38:20 GMT"}, {"version": "v2", "created": "Sat, 17 Oct 2015 18:54:27 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Sun", "BaoLuo", ""], ["Tchetgen", "Eric J. Tchetgen", ""]]}, {"id": "1411.5383", "submitter": "Zeyuan Allen-Zhu", "authors": "Zeyuan Allen-Zhu, Rati Gelashvili, Silvio Micali, Nir Shavit", "title": "Johnson-Lindenstrauss Compression with Neuroscience-Based Constraints", "comments": "A shorter version of this paper has appeared in the Proceedings of\n  the National Academy of Sciences", "journal-ref": null, "doi": "10.1073/pnas.1419100111", "report-no": null, "categories": "q-bio.NC cs.DS math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Johnson-Lindenstrauss (JL) matrices implemented by sparse random synaptic\nconnections are thought to be a prime candidate for how convergent pathways in\nthe brain compress information. However, to date, there is no complete\nmathematical support for such implementations given the constraints of real\nneural tissue. The fact that neurons are either excitatory or inhibitory\nimplies that every so implementable JL matrix must be sign-consistent (i.e.,\nall entries in a single column must be either all non-negative or all\nnon-positive), and the fact that any given neuron connects to a relatively\nsmall subset of other neurons implies that the JL matrix had better be sparse.\n  We construct sparse JL matrices that are sign-consistent, and prove that our\nconstruction is essentially optimal. Our work answers a mathematical question\nthat was triggered by earlier work and is necessary to justify the existence of\nJL compression in the brain, and emphasizes that inhibition is crucial if\nneurons are to perform efficient, correlation-preserving compression.\n", "versions": [{"version": "v1", "created": "Wed, 19 Nov 2014 21:12:12 GMT"}], "update_date": "2014-11-21", "authors_parsed": [["Allen-Zhu", "Zeyuan", ""], ["Gelashvili", "Rati", ""], ["Micali", "Silvio", ""], ["Shavit", "Nir", ""]]}, {"id": "1411.5713", "submitter": "Miklos Z. Racz", "authors": "S\\'ebastien Bubeck, Jian Ding, Ronen Eldan, Mikl\\'os R\\'acz", "title": "Testing for high-dimensional geometry in random graphs", "comments": "28 pages; v2 contains minor changes", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.SI math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of detecting the presence of an underlying\nhigh-dimensional geometric structure in a random graph. Under the null\nhypothesis, the observed graph is a realization of an Erd\\H{o}s-R\\'enyi random\ngraph $G(n,p)$. Under the alternative, the graph is generated from the\n$G(n,p,d)$ model, where each vertex corresponds to a latent independent random\nvector uniformly distributed on the sphere $\\mathbb{S}^{d-1}$, and two vertices\nare connected if the corresponding latent vectors are close enough. In the\ndense regime (i.e., $p$ is a constant), we propose a near-optimal and\ncomputationally efficient testing procedure based on a new quantity which we\ncall signed triangles. The proof of the detection lower bound is based on a new\nbound on the total variation distance between a Wishart matrix and an\nappropriately normalized GOE matrix. In the sparse regime, we make a conjecture\nfor the optimal detection boundary. We conclude the paper with some preliminary\nsteps on the problem of estimating the dimension in $G(n,p,d)$.\n", "versions": [{"version": "v1", "created": "Thu, 20 Nov 2014 22:30:40 GMT"}, {"version": "v2", "created": "Sun, 22 Nov 2015 03:32:16 GMT"}], "update_date": "2015-11-24", "authors_parsed": [["Bubeck", "S\u00e9bastien", ""], ["Ding", "Jian", ""], ["Eldan", "Ronen", ""], ["R\u00e1cz", "Mikl\u00f3s", ""]]}, {"id": "1411.5715", "submitter": "Walter Dempsey", "authors": "Walter Dempsey and Peter McCullagh", "title": "Weak continuity of predictive distribution for Markov survival processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the concept of a consistent exchangeable survival process - a\njoint distribution of survival times in which the risk set evolves as a\ncontinuous-time Markov process with homogeneous transition rates. We show a\ncorrespondence with the de Finetti approach of constructing an exchangeable\nsurvival process by generating iid survival times conditional on a completely\nindependent hazard measure. We describe several specific processes, showing how\nthe number of blocks of tied failure times grows asymptotically with the number\nof individuals in each case. In particular, we show that the set of Markov\nsurvival processes with weakly continuous predictive distributions can be\ncharacterized by a two-dimensional family called the harmonic process. We end\nby applying these methods to data, showing how they can be easily extended to\nhandle censoring.\n", "versions": [{"version": "v1", "created": "Thu, 20 Nov 2014 22:57:45 GMT"}, {"version": "v2", "created": "Wed, 3 Dec 2014 20:59:52 GMT"}, {"version": "v3", "created": "Thu, 11 Dec 2014 17:11:41 GMT"}, {"version": "v4", "created": "Thu, 6 Aug 2015 20:35:06 GMT"}], "update_date": "2015-08-10", "authors_parsed": [["Dempsey", "Walter", ""], ["McCullagh", "Peter", ""]]}, {"id": "1411.5720", "submitter": "Tatsunori Hashimoto", "authors": "Tatsunori B. Hashimoto, Yi Sun, Tommi S. Jaakkola", "title": "Metric recovery from directed unweighted graphs", "comments": "Poster at NIPS workshop on networks. Submitted to AISTATS 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.SI math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze directed, unweighted graphs obtained from $x_i\\in \\mathbb{R}^d$ by\nconnecting vertex $i$ to $j$ iff $|x_i - x_j| < \\epsilon(x_i)$. Examples of\nsuch graphs include $k$-nearest neighbor graphs, where $\\epsilon(x_i)$ varies\nfrom point to point, and, arguably, many real world graphs such as\nco-purchasing graphs. We ask whether we can recover the underlying Euclidean\nmetric $\\epsilon(x_i)$ and the associated density $p(x_i)$ given only the\ndirected graph and $d$.\n  We show that consistent recovery is possible up to isometric scaling when the\nvertex degree is at least $\\omega(n^{2/(2+d)}\\log(n)^{d/(d+2)})$. Our estimator\nis based on a careful characterization of a random walk over the directed graph\nand the associated continuum limit. As an algorithm, it resembles the PageRank\ncentrality metric. We demonstrate empirically that the estimator performs well\non simulated examples as well as on real-world co-purchasing graphs even with a\nsmall number of points and degree scaling as low as $\\log(n)$.\n", "versions": [{"version": "v1", "created": "Thu, 20 Nov 2014 23:16:09 GMT"}], "update_date": "2014-11-24", "authors_parsed": [["Hashimoto", "Tatsunori B.", ""], ["Sun", "Yi", ""], ["Jaakkola", "Tommi S.", ""]]}, {"id": "1411.5883", "submitter": "Fran\\c{c}ois Bachoc", "authors": "Fran\\c{c}ois Bachoc and Lionel Len\\^otre and Achref Bachouch", "title": "Hastings-Metropolis algorithm on Markov chains for small-probability\n  estimation", "comments": "33 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Shielding studies in neutron transport, with Monte Carlo codes, yield\nchallenging problems of small-probability estimation. The particularity of\nthese studies is that the small probability to estimate is formulated in terms\nof the distribution of a Markov chain, instead of that of a random vector in\nmore classical cases. Thus, it is not straightforward to adapt classical\nstatistical methods, for estimating small probabilities involving random\nvectors, to these neutron-transport problems. A recent interacting-particle\nmethod for small-probability estimation, relying on the Hastings-Metropolis\nalgorithm, is presented. It is shown how to adapt the Hastings-Metropolis\nalgorithm when dealing with Markov chains. A convergence result is also shown.\nThen, the practical implementation of the resulting method for\nsmall-probability estimation is treated in details, for a Monte Carlo shielding\nstudy. Finally, it is shown, for this study, that the proposed\ninteracting-particle method considerably outperforms a simple-Monte Carlo\nmethod, when the probability to estimate is small.\n", "versions": [{"version": "v1", "created": "Fri, 21 Nov 2014 14:18:01 GMT"}], "update_date": "2014-11-24", "authors_parsed": [["Bachoc", "Fran\u00e7ois", ""], ["Len\u00f4tre", "Lionel", ""], ["Bachouch", "Achref", ""]]}, {"id": "1411.5888", "submitter": "Axel B\\\"ucher", "authors": "Axel B\\\"ucher and Betina Berghaus and Stanislav Volgushev", "title": "Weak convergence of the empirical copula process with respect to\n  weighted metrics", "comments": "39 pages + 7 pages of supplementary material, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The empirical copula process plays a central role in the asymptotic analysis\nof many statistical procedures which are based on copulas or ranks. Among other\napplications, results regarding its weak convergence can be used to develop\nasymptotic theory for estimators of dependence measures or copula densities,\nthey allow to derive tests for stochastic independence or specific copula\nstructures, or they may serve as a fundamental tool for the analysis of\nmultivariate rank statistics. In the present paper, we establish weak\nconvergence of the empirical copula process (for observations that are allowed\nto be serially dependent) with respect to weighted supremum distances. The\nusefulness of our results is illustrated by applications to general bivariate\nrank statistics and to estimation procedures for the Pickands dependence\nfunction arising in multivariate extreme-value theory.\n", "versions": [{"version": "v1", "created": "Fri, 21 Nov 2014 14:35:34 GMT"}], "update_date": "2014-11-24", "authors_parsed": [["B\u00fccher", "Axel", ""], ["Berghaus", "Betina", ""], ["Volgushev", "Stanislav", ""]]}, {"id": "1411.6149", "submitter": "Andrea Montanari", "authors": "Andrea Montanari, Daniel Reichman, Ofer Zeitouni", "title": "On the limitation of spectral methods: From the Gaussian hidden clique\n  problem to rank one perturbations of Gaussian tensors", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.DM cs.IT math.IT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the following detection problem: given a realization of a\nsymmetric matrix ${\\mathbf{X}}$ of dimension $n$, distinguish between the\nhypothesis that all upper triangular variables are i.i.d. Gaussians variables\nwith mean 0 and variance $1$ and the hypothesis where ${\\mathbf{X}}$ is the sum\nof such matrix and an independent rank-one perturbation.\n  This setup applies to the situation where under the alternative, there is a\nplanted principal submatrix ${\\mathbf{B}}$ of size $L$ for which all upper\ntriangular variables are i.i.d. Gaussians with mean $1$ and variance $1$,\nwhereas all other upper triangular elements of ${\\mathbf{X}}$ not in\n${\\mathbf{B}}$ are i.i.d. Gaussians variables with mean 0 and variance $1$. We\nrefer to this as the `Gaussian hidden clique problem.'\n  When $L=(1+\\epsilon)\\sqrt{n}$ ($\\epsilon>0$), it is possible to solve this\ndetection problem with probability $1-o_n(1)$ by computing the spectrum of\n${\\mathbf{X}}$ and considering the largest eigenvalue of ${\\mathbf{X}}$. We\nprove that this condition is tight in the following sense: when\n$L<(1-\\epsilon)\\sqrt{n}$ no algorithm that examines only the eigenvalues of\n${\\mathbf{X}}$ can detect the existence of a hidden Gaussian clique, with error\nprobability vanishing as $n\\to\\infty$.\n  We prove this result as an immediate consequence of a more general result on\nrank-one perturbations of $k$-dimensional Gaussian tensors. In this context we\nestablish a lower bound on the critical signal-to-noise ratio below which a\nrank-one signal cannot be detected.\n", "versions": [{"version": "v1", "created": "Sat, 22 Nov 2014 17:42:45 GMT"}], "update_date": "2014-11-25", "authors_parsed": [["Montanari", "Andrea", ""], ["Reichman", "Daniel", ""], ["Zeitouni", "Ofer", ""]]}, {"id": "1411.6160", "submitter": "Martin Copenhaver", "authors": "Dimitris Bertsimas and Martin S. Copenhaver", "title": "Characterization of the equivalence of robustification and\n  regularization in linear and matrix regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG math.OC stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The notion of developing statistical methods in machine learning which are\nrobust to adversarial perturbations in the underlying data has been the subject\nof increasing interest in recent years. A common feature of this work is that\nthe adversarial robustification often corresponds exactly to regularization\nmethods which appear as a loss function plus a penalty. In this paper we deepen\nand extend the understanding of the connection between robustification and\nregularization (as achieved by penalization) in regression problems.\nSpecifically, (a) in the context of linear regression, we characterize\nprecisely under which conditions on the model of uncertainty used and on the\nloss function penalties robustification and regularization are equivalent, and\n(b) we extend the characterization of robustification and regularization to\nmatrix regression problems (matrix completion and Principal Component\nAnalysis).\n", "versions": [{"version": "v1", "created": "Sat, 22 Nov 2014 19:59:32 GMT"}, {"version": "v2", "created": "Sat, 25 Feb 2017 17:58:26 GMT"}], "update_date": "2017-02-28", "authors_parsed": [["Bertsimas", "Dimitris", ""], ["Copenhaver", "Martin S.", ""]]}, {"id": "1411.6265", "submitter": "Ivan Nourdin", "authors": "Larry Goldstein, Ivan Nourdin and Giovanni Peccati", "title": "Gaussian Phase Transitions and Conic Intrinsic Volumes: Steining the\n  Steiner Formula", "comments": "42 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intrinsic volumes of convex sets are natural geometric quantities that also\nplay important roles in applications, such as linear inverse problems with\nconvex constraints, and constrained statistical inference. It is a well-known\nfact that, given a closed convex cone $C\\subset \\mathbb{R}^d$, its conic\nintrinsic volumes determine a probability measure on the finite set\n$\\{0,1,...d\\}$, customarily denoted by $\\mathcal{L}(V_C)$. The aim of the\npresent paper is to provide a Berry-Esseen bound for the normal approximation\nof ${\\cal L}(V_C)$, implying a general quantitative central limit theorem (CLT)\nfor sequences of (correctly normalised) discrete probability measures of the\ntype $\\mathcal{L}(V_{C_n})$, $n\\geq 1$. This bound shows that, in the\nhigh-dimensional limit, most conic intrinsic volumes encountered in\napplications can be approximated by a suitable Gaussian distribution. Our\napproach is based on a variety of techniques, namely: (1) Steiner formulae for\nclosed convex cones, (2) Stein's method and second order Poincar\\'e inequality,\n(3) concentration estimates, and (4) Fourier analysis. Our results explicitly\nconnect the sharp phase transitions, observed in many regularised linear\ninverse problems with convex constraints, with the asymptotic Gaussian\nfluctuations of the intrinsic volumes of the associated descent cones. In\nparticular, our findings complete and further illuminate the recent\nbreakthrough discoveries by Amelunxen, Lotz, McCoy and Tropp (2014) and McCoy\nand Tropp (2014) about the concentration of conic intrinsic volumes and its\nconnection with threshold phenomena. As an additional outgrowth of our work we\ndevelop total variation bounds for normal approximations of the lengths of\nprojections of Gaussian vectors on closed convex sets.\n", "versions": [{"version": "v1", "created": "Sun, 23 Nov 2014 16:51:50 GMT"}], "update_date": "2014-11-25", "authors_parsed": [["Goldstein", "Larry", ""], ["Nourdin", "Ivan", ""], ["Peccati", "Giovanni", ""]]}, {"id": "1411.6314", "submitter": "Aaditya Ramdas", "authors": "Aaditya Ramdas, Sashank J. Reddi, Barnabas Poczos, Aarti Singh, Larry\n  Wasserman", "title": "On the High-dimensional Power of Linear-time Kernel Two-Sample Testing\n  under Mean-difference Alternatives", "comments": "25 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.AI cs.IT cs.LG math.IT stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonparametric two sample testing deals with the question of consistently\ndeciding if two distributions are different, given samples from both, without\nmaking any parametric assumptions about the form of the distributions. The\ncurrent literature is split into two kinds of tests - those which are\nconsistent without any assumptions about how the distributions may differ\n(\\textit{general} alternatives), and those which are designed to specifically\ntest easier alternatives, like a difference in means (\\textit{mean-shift}\nalternatives).\n  The main contribution of this paper is to explicitly characterize the power\nof a popular nonparametric two sample test, designed for general alternatives,\nunder a mean-shift alternative in the high-dimensional setting. Specifically,\nwe explicitly derive the power of the linear-time Maximum Mean Discrepancy\nstatistic using the Gaussian kernel, where the dimension and sample size can\nboth tend to infinity at any rate, and the two distributions differ in their\nmeans. As a corollary, we find that if the signal-to-noise ratio is held\nconstant, then the test's power goes to one if the number of samples increases\nfaster than the dimension increases. This is the first explicit power\nderivation for a general nonparametric test in the high-dimensional setting,\nand also the first analysis of how tests designed for general alternatives\nperform when faced with easier ones.\n", "versions": [{"version": "v1", "created": "Sun, 23 Nov 2014 23:32:02 GMT"}], "update_date": "2014-11-25", "authors_parsed": [["Ramdas", "Aaditya", ""], ["Reddi", "Sashank J.", ""], ["Poczos", "Barnabas", ""], ["Singh", "Aarti", ""], ["Wasserman", "Larry", ""]]}, {"id": "1411.6419", "submitter": "Jakob S\\\"ohl", "authors": "Jakob S\\\"ohl", "title": "Uniform central limit theorems for the Grenander estimator", "comments": "17 pages", "journal-ref": "Electron. J. Stat. 9 (2015) 1404-1423", "doi": "10.1214/15-EJS1043", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the Grenander estimator that is the maximum likelihood estimator\nfor non-increasing densities. We prove uniform central limit theorems for\ncertain subclasses of bounded variation functions and for H\\\"older balls of\nsmoothness s>1/2. We do not assume that the density is differentiable or\ncontinuous. The proof can be seen as an adaptation of the method for the\nparametric maximum likelihood estimator to the nonparametric setting. Since\nnonparametric maximum likelihood estimators lie on the boundary, the derivative\nof the likelihood cannot be expected to equal zero as in the parametric case.\nNevertheless, our proofs rely on the fact that the derivative of the likelihood\ncan be shown to be small at the maximum likelihood estimator.\n", "versions": [{"version": "v1", "created": "Mon, 24 Nov 2014 11:52:16 GMT"}, {"version": "v2", "created": "Fri, 17 Apr 2015 16:40:56 GMT"}, {"version": "v3", "created": "Fri, 19 Jun 2015 10:30:38 GMT"}, {"version": "v4", "created": "Fri, 26 Jun 2015 14:55:16 GMT"}], "update_date": "2015-06-29", "authors_parsed": [["S\u00f6hl", "Jakob", ""]]}, {"id": "1411.6428", "submitter": "Luc Pronzato", "authors": "Luc Pronzato, Henry Wynn, Anatoly Zhigljavsky", "title": "An extended Generalised Variance, with Applications", "comments": "Corrected references and typos Added figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a measure $\\psi$ k of dispersion which extends the notion of\nWilk's generalised variance, or entropy, for a d-dimensional distribution, and\nis based on the mean squared volume of simplices of dimension k $\\le$ d formed\nby k + 1 independent copies. We show how $\\psi$ k can be expressed in terms of\nthe eigenvalues of the covariance matrix of the distribution, also when a\nn-point sample is used for its estimation, and prove its concavity when raised\nat a suitable power. Some properties of entropy-maximising distributions are\nderived, including a necessary and sufficient condition for optimality.\nFinally, we show how this measure of dispersion can be used for the design of\noptimal experiments, with equivalence to A and D-optimal design for k = 1 and k\n= d respectively. Simple illustrative examples are presented.\n", "versions": [{"version": "v1", "created": "Mon, 24 Nov 2014 12:32:41 GMT"}, {"version": "v2", "created": "Fri, 26 Jun 2015 10:10:16 GMT"}], "update_date": "2015-06-29", "authors_parsed": [["Pronzato", "Luc", ""], ["Wynn", "Henry", ""], ["Zhigljavsky", "Anatoly", ""]]}, {"id": "1411.6471", "submitter": "Hitoshi Koyano", "authors": "Hitoshi Koyano, Morihiro Hayashida, and Tatsuya Akutsu", "title": "Optimal string clustering based on a Laplace-like mixture and EM\n  algorithm on a set of strings", "comments": "56 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, we address the problem of clustering string data in an\nunsupervised manner by developing a theory of a mixture model and an EM\nalgorithm for string data based on probability theory on a topological monoid\nof strings developed in our previous studies. We first construct a parametric\ndistribution on a set of strings in the motif of the Laplace distribution on a\nset of real numbers and reveal its basic properties. This Laplace-like\ndistribution has two parameters: a string that represents the location of the\ndistribution and a positive real number that represents the dispersion. It is\ndifficult to explicitly write maximum likelihood estimators of the parameters\nbecause their log likelihood function is a complex function, the variables of\nwhich include a string; however, we construct estimators that almost surely\nconverge to the maximum likelihood estimators as the number of observed strings\nincreases and demonstrate that the estimators strongly consistently estimate\nthe parameters. Next, we develop an iteration algorithm for estimating the\nparameters of the mixture model of the Laplace-like distributions and\ndemonstrate that the algorithm almost surely converges to the EM algorithm for\nthe Laplace-like mixture and strongly consistently estimates its parameters as\nthe numbers of observed strings and iterations increase. Finally, we derive a\nprocedure for unsupervised string clustering from the Laplace-like mixture that\nis asymptotically optimal in the sense that the posterior probability of making\ncorrect classifications is maximized.\n", "versions": [{"version": "v1", "created": "Mon, 24 Nov 2014 14:48:17 GMT"}, {"version": "v2", "created": "Thu, 2 Jul 2015 02:01:24 GMT"}, {"version": "v3", "created": "Wed, 7 Oct 2015 09:22:21 GMT"}], "update_date": "2015-10-08", "authors_parsed": [["Koyano", "Hitoshi", ""], ["Hayashida", "Morihiro", ""], ["Akutsu", "Tatsuya", ""]]}, {"id": "1411.6590", "submitter": "Dejan Slep\\v{c}ev", "authors": "Nicolas Garcia Trillos, Dejan Slepcev, James von Brecht, Thomas\n  Laurent and Xavier Bresson", "title": "Consistency of Cheeger and Ratio Graph Cuts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper establishes the consistency of a family of graph-cut-based\nalgorithms for clustering of data clouds. We consider point clouds obtained as\nsamples of a ground-truth measure. We investigate approaches to clustering\nbased on minimizing objective functionals defined on proximity graphs of the\ngiven sample. Our focus is on functionals based on graph cuts like the Cheeger\nand ratio cuts. We show that minimizers of the these cuts converge as the\nsample size increases to a minimizer of a corresponding continuum cut (which\npartitions the ground truth measure). Moreover, we obtain sharp conditions on\nhow the connectivity radius can be scaled with respect to the number of sample\npoints for the consistency to hold. We provide results for two-way and for\nmultiway cuts. Furthermore we provide numerical experiments that illustrate the\nresults and explore the optimality of scaling in dimension two.\n", "versions": [{"version": "v1", "created": "Mon, 24 Nov 2014 19:55:09 GMT"}], "update_date": "2014-11-25", "authors_parsed": [["Trillos", "Nicolas Garcia", ""], ["Slepcev", "Dejan", ""], ["von Brecht", "James", ""], ["Laurent", "Thomas", ""], ["Bresson", "Xavier", ""]]}, {"id": "1411.6622", "submitter": "Osonde Osoba Ph.D.", "authors": "Osonde Adekorede Osoba", "title": "Noise Benefits in Expectation-Maximization Algorithms", "comments": "A Dissertation Presented to The Faculty of The USC Graduate School\n  University of Southern California In Partial Fulfillment of the Requirements\n  for the Degree Doctor of Philosophy (Electrical Engineering) August 2013.\n  (252 pages, 45 figures), Online:\n  http://digitallibrary.usc.edu/cdm/ref/collection/p15799coll3/id/294341", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This dissertation shows that careful injection of noise into sample data can\nsubstantially speed up Expectation-Maximization algorithms.\nExpectation-Maximization algorithms are a class of iterative algorithms for\nextracting maximum likelihood estimates from corrupted or incomplete data. The\nconvergence speed-up is an example of a noise benefit or \"stochastic resonance\"\nin statistical signal processing. The dissertation presents derivations of\nsufficient conditions for such noise-benefits and demonstrates the speed-up in\nsome ubiquitous signal-processing algorithms. These algorithms include\nparameter estimation for mixture models, the $k$-means clustering algorithm,\nthe Baum-Welch algorithm for training hidden Markov models, and backpropagation\nfor training feedforward artificial neural networks. This dissertation also\nanalyses the effects of data and model corruption on the more general Bayesian\ninference estimation framework. The main finding is a theorem guaranteeing that\nuniform approximators for Bayesian model functions produce uniform\napproximators for the posterior pdf via Bayes theorem. This result also applies\nto hierarchical and multidimensional Bayesian models.\n", "versions": [{"version": "v1", "created": "Mon, 24 Nov 2014 17:30:57 GMT"}], "update_date": "2014-11-26", "authors_parsed": [["Osoba", "Osonde Adekorede", ""]]}, {"id": "1411.6669", "submitter": "Michael Betancourt", "authors": "M.J. Betancourt, Simon Byrne, and Mark Girolami", "title": "Optimizing The Integrator Step Size for Hamiltonian Monte Carlo", "comments": "36 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hamiltonian Monte Carlo can provide powerful inference in complex statistical\nproblems, but ultimately its performance is sensitive to various tuning\nparameters. In this paper we use the underlying geometry of Hamiltonian Monte\nCarlo to construct a universal optimization criteria for tuning the step size\nof the symplectic integrator crucial to any implementation of the algorithm as\nwell as diagnostics to monitor for any signs of invalidity. An immediate\noutcome of this result is that the suggested target average acceptance\nprobability of 0.651 can be relaxed to $0.6 \\lesssim a \\lesssim 0.9$ with\nlarger values more robust in practice.\n", "versions": [{"version": "v1", "created": "Mon, 24 Nov 2014 22:13:53 GMT"}, {"version": "v2", "created": "Mon, 2 Feb 2015 16:27:20 GMT"}], "update_date": "2015-02-03", "authors_parsed": [["Betancourt", "M. J.", ""], ["Byrne", "Simon", ""], ["Girolami", "Mark", ""]]}, {"id": "1411.6716", "submitter": "William Weimin Yoo", "authors": "William Weimin Yoo and Subhashis Ghosal", "title": "Supremum Norm Posterior Contraction and Credible Sets for Nonparametric\n  Multivariate Regression", "comments": "36 pages, 2 figures, uses imsart.sty", "journal-ref": "Ann. Statist. Volume 44, Number 3 (2016), 1069-1102", "doi": "10.1214/15-AOS1398", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the setting of nonparametric multivariate regression with unknown error\nvariance, we study asymptotic properties of a Bayesian method for estimating a\nregression function f and its mixed partial derivatives. We use a random series\nof tensor product of B-splines with normal basis coefficients as a prior for f,\nand the error variance is either estimated using the empirical Bayes approach\nor is endowed with a suitable prior in a hierarchical Bayes approach. We\nestablish pointwise, L2 and supremum norm posterior contraction rates for f and\nits mixed partial derivatives, and show that they coincide with the minimax\nrates. Our results cover even the anisotropic situation, where the true\nregression function may have different smoothness in different directions.\nUsing the convergence bounds, we show that pointwise, L2 and supremum norm\ncredible sets for f and its mixed partial derivatives have guaranteed\nfrequentist coverage with optimal size. New results on tensor products of\nB-splines are also obtained in the course.\n", "versions": [{"version": "v1", "created": "Tue, 25 Nov 2014 03:18:52 GMT"}, {"version": "v2", "created": "Wed, 27 May 2015 18:16:36 GMT"}, {"version": "v3", "created": "Thu, 24 Sep 2015 00:31:44 GMT"}], "update_date": "2016-04-13", "authors_parsed": [["Yoo", "William Weimin", ""], ["Ghosal", "Subhashis", ""]]}, {"id": "1411.6719", "submitter": "Dionysios Kalogerias", "authors": "Dionysios S. Kalogerias, Athina P. Petropulu", "title": "Asymptotically Optimal Discrete Time Nonlinear Filters From\n  Stochastically Convergent State Process Approximations", "comments": "EXTENDED version of an original paper published in the IEEE\n  Transactions on Signal Processing; 37 pages", "journal-ref": null, "doi": "10.1109/TSP.2015.2428220", "report-no": null, "categories": "math.ST cs.SY math.OC stat.AP stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of approximating optimal in the Minimum Mean Squared\nError (MMSE) sense nonlinear filters in a discrete time setting, exploiting\nproperties of stochastically convergent state process approximations. More\nspecifically, we consider a class of nonlinear, partially observable stochastic\nsystems, comprised by a (possibly nonstationary) hidden stochastic process (the\nstate), observed through another conditionally Gaussian stochastic process (the\nobservations). Under general assumptions, we show that, given an approximating\nprocess which, for each time step, is stochastically convergent to the state\nprocess, an approximate filtering operator can be defined, which converges to\nthe true optimal nonlinear filter of the state in a strong and well defined\nsense. In particular, the convergence is compact in time and uniform in a\ncompletely characterized measurable set of probability measure almost unity,\nalso providing a purely quantitative justification of Egoroff's Theorem for the\nproblem at hand. The results presented in this paper can form a common basis\nfor the analysis and characterization of a number of heuristic approaches for\napproximating optimal nonlinear filters, such as approximate grid based\ntechniques, known to perform well in a variety of applications.\n", "versions": [{"version": "v1", "created": "Tue, 25 Nov 2014 03:49:25 GMT"}, {"version": "v2", "created": "Sun, 25 Jan 2015 11:26:47 GMT"}, {"version": "v3", "created": "Sun, 1 May 2016 18:30:16 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Kalogerias", "Dionysios S.", ""], ["Petropulu", "Athina P.", ""]]}, {"id": "1411.6860", "submitter": "Paulo Serra", "authors": "Paulo Serra, Tatyana Krivobokova", "title": "Adaptive empirical Bayesian smoothing splines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we develop and study adaptive empirical Bayesian smoothing\nsplines. These are smoothing splines with both smoothing parameter and penalty\norder determined via the empirical Bayes method from the marginal likelihood of\nthe model. The selected order and smoothing parameter are used to construct\nadaptive credible sets with good frequentist coverage for the underlying\nregression function. We use these credible sets as a proxy to show the superior\nperformance of adaptive empirical Bayesian smoothing splines compared to\nfrequentist smoothing splines.\n", "versions": [{"version": "v1", "created": "Tue, 25 Nov 2014 13:28:43 GMT"}, {"version": "v2", "created": "Tue, 17 Nov 2015 09:17:06 GMT"}], "update_date": "2015-11-18", "authors_parsed": [["Serra", "Paulo", ""], ["Krivobokova", "Tatyana", ""]]}, {"id": "1411.7049", "submitter": "Benjamin Haaland", "authors": "Benjamin Haaland, Wenjia Wang, and Vaibhav Maheshwari", "title": "A Framework for Controlling Sources of Inaccuracy in Gaussian Process\n  Emulation of Deterministic Computer Experiments", "comments": "35 pages, 4 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computer experiments have become ubiquitous in science and engineering.\nCommonly, runs of these simulations demand considerable time and computing,\nmaking experimental design extremely important in gaining high quality\ninformation with limited time and resources. Principles of experimental design\nare proposed and justified which ensure high nominal, numeric, and parameter\nestimation accuracy for Gaussian process emulation of deterministic\nsimulations. The space-filling properties \"small fill distance\" and \"large\nseparation distance\" are only weakly conflicting and ensure well-controlled\nnominal, numeric, and parameter estimation error, while non-stationarity\nrequires a greater density of experimental inputs in regions of the input space\nwith more quickly decaying correlation. This work will provide scientists and\nengineers with robust, rigorously justified, and practically useful overarching\nprinciples for selecting combinations of simulation inputs with high\ninformation content.\n", "versions": [{"version": "v1", "created": "Tue, 25 Nov 2014 21:36:36 GMT"}, {"version": "v2", "created": "Thu, 4 Feb 2016 21:52:57 GMT"}, {"version": "v3", "created": "Thu, 11 May 2017 22:21:50 GMT"}], "update_date": "2017-05-15", "authors_parsed": [["Haaland", "Benjamin", ""], ["Wang", "Wenjia", ""], ["Maheshwari", "Vaibhav", ""]]}, {"id": "1411.7060", "submitter": "Donald Richards", "authors": "Tomoya Yamada, Megan M. Romer, and Donald St. P. Richards", "title": "Kurtosis Tests for Multivariate Normality with Monotone Incomplete Data", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of testing multivariate normality when the data\nconsists of a random sample of two-step monotone incomplete observations. We\ndefine for such data a generalization of Mardia's statistic for measuring\nkurtosis, derive the asymptotic non-null distribution of the statistic under\ncertain regularity conditions and against a broad class of alternatives, and\ngive an application to a well-known data set on cholesterol measurements.\n", "versions": [{"version": "v1", "created": "Tue, 25 Nov 2014 22:50:07 GMT"}], "update_date": "2014-11-27", "authors_parsed": [["Yamada", "Tomoya", ""], ["Romer", "Megan M.", ""], ["Richards", "Donald St. P.", ""]]}, {"id": "1411.7324", "submitter": "Sirin Nitinawarat", "authors": "Yun Li, Sirin Nitinawarat and Venugopal V. Veeravalli", "title": "Universal Sequential Outlier Hypothesis Testing", "comments": "Proc. of the Asilomar Conference on Signals, Systems, and Computers,\n  2014. To appear", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Universal outlier hypothesis testing is studied in a sequential setting.\nMultiple observation sequences are collected, a small subset of which are\noutliers. A sequence is considered an outlier if the observations in that\nsequence are generated by an \"outlier\" distribution, distinct from a common\n\"typical\" distribution governing the majority of the sequences. Apart from\nbeing distinct, the outlier and typical distributions can be arbitrarily close.\nThe goal is to design a universal test to best discern all the outlier\nsequences. A universal test with the flavor of the repeated significance test\nis proposed and its asymptotic performance is characterized under various\nuniversal settings. The proposed test is shown to be universally consistent.\nFor the model with identical outliers, the test is shown to be asymptotically\noptimal universally when the number of outliers is the largest possible and\nwith the typical distribution being known, and its asymptotic performance\notherwise is also characterized. An extension of the findings to the model with\nmultiple distinct outliers is also discussed. In all cases, it is shown that\nthe asymptotic performance guarantees for the proposed test when neither the\noutlier nor typical distribution is known converge to those when the typical\ndistribution is known.\n", "versions": [{"version": "v1", "created": "Wed, 26 Nov 2014 18:36:52 GMT"}], "update_date": "2014-11-27", "authors_parsed": [["Li", "Yun", ""], ["Nitinawarat", "Sirin", ""], ["Veeravalli", "Venugopal V.", ""]]}, {"id": "1411.7334", "submitter": "Deborah Schneider-Luftman Ms", "authors": "A. T. Walden and D. Schneider-Luftman", "title": "Random Matrix Derived Shrinkage of Spectral Precision Matrices", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2015.2443726", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much research has been carried out on shrinkage methods for real-valued\ncovariance matrices. In spectral analysis of $p$-vector-valued time series\nthere is often a need for good shrinkage methods too, most notably when the\ncomplex-valued spectral matrix is singular. The equivalent of the Ledoit-Wolf\n(LW) covariance matrix estimator for spectral matrices can be improved on using\na Rao-Blackwell estimator, and using random matrix theory we derive its form.\nSuch estimators can be used to better estimate inverse spectral (precision)\nmatrices too, and a random matrix method has previously been proposed and\nimplemented via extensive simulations. We describe the method, but carry out\ncomputations entirely analytically, and suggest a way of selecting an important\nparameter using a predictive risk approach. We show that both the Rao-Blackwell\nestimator and the random matrix estimator of the precision matrix can\nsubstantially outperform the inverse of the LW estimator in a time series\nsetting. Our new methodology is applied to EEG-derived time series data where\nit is seen to work well and deliver substantial improvements for precision\nmatrix estimation.\n", "versions": [{"version": "v1", "created": "Wed, 26 Nov 2014 19:11:02 GMT"}], "update_date": "2015-10-28", "authors_parsed": [["Walden", "A. T.", ""], ["Schneider-Luftman", "D.", ""]]}, {"id": "1411.7346", "submitter": "Gautam Kamath", "authors": "Jayadev Acharya, Cl\\'ement L. Canonne, Gautam Kamath", "title": "A Chasm Between Identity and Equivalence Testing with Conditional\n  Queries", "comments": "39 pages. To appear in Theory of Computing. Preliminary version\n  appeared in RANDOM 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.LG math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A recent model for property testing of probability distributions (Chakraborty\net al., ITCS 2013, Canonne et al., SICOMP 2015) enables tremendous savings in\nthe sample complexity of testing algorithms, by allowing them to condition the\nsampling on subsets of the domain. In particular, Canonne, Ron, and Servedio\n(SICOMP 2015) showed that, in this setting, testing identity of an unknown\ndistribution $D$ (whether $D=D^\\ast$ for an explicitly known $D^\\ast$) can be\ndone with a constant number of queries, independent of the support size $n$ --\nin contrast to the required $\\Omega(\\sqrt{n})$ in the standard sampling model.\nIt was unclear whether the same stark contrast exists for the case of testing\nequivalence, where both distributions are unknown. While Canonne et al.\nestablished a $\\mathrm{poly}(\\log n)$-query upper bound for equivalence\ntesting, very recently brought down to $\\tilde O(\\log\\log n)$ by Falahatgar et\nal. (COLT 2015), whether a dependence on the domain size $n$ is necessary was\nstill open, and explicitly posed by Fischer at the Bertinoro Workshop on\nSublinear Algorithms (2014). We show that any testing algorithm for equivalence\nmust make $\\Omega(\\sqrt{\\log\\log n})$ queries in the conditional sampling\nmodel. This demonstrates a gap between identity and equivalence testing, absent\nin the standard sampling model (where both problems have sampling complexity\n$n^{\\Theta(1)}$).\n  We also obtain results on the query complexity of uniformity testing and\nsupport-size estimation with conditional samples. We answer a question of\nChakraborty et al. (ITCS 2013) showing that non-adaptive uniformity testing\nindeed requires $\\Omega(\\log n)$ queries in the conditional model. For the\nrelated problem of support-size estimation, we provide both adaptive and\nnon-adaptive algorithms, with query complexities $\\mathrm{poly}(\\log\\log n)$\nand $\\mathrm{poly}(\\log n)$, respectively.\n", "versions": [{"version": "v1", "created": "Wed, 26 Nov 2014 19:44:12 GMT"}, {"version": "v2", "created": "Sat, 18 Apr 2015 23:37:46 GMT"}, {"version": "v3", "created": "Fri, 7 Dec 2018 01:30:55 GMT"}], "update_date": "2018-12-10", "authors_parsed": [["Acharya", "Jayadev", ""], ["Canonne", "Cl\u00e9ment L.", ""], ["Kamath", "Gautam", ""]]}, {"id": "1411.7420", "submitter": "Debdeep Pati", "authors": "Debdeep Pati, Anirban Bhattacharya, Guang Cheng", "title": "Optimal Bayesian estimation in random covariate design with a rescaled\n  Gaussian process prior", "comments": "To appear in the Journal of Machine Learning Research", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Bayesian nonparametric models, Gaussian processes provide a popular prior\nchoice for regression function estimation. Existing literature on the\ntheoretical investigation of the resulting posterior distribution almost\nexclusively assume a fixed design for covariates. The only random design result\nwe are aware of (van der Vaart & van Zanten, 2011) assumes the assigned\nGaussian process to be supported on the smoothness class specified by the true\nfunction with probability one. This is a fairly restrictive assumption as it\nessentially rules out the Gaussian process prior with a squared exponential\nkernel when modeling rougher functions. In this article, we show that an\nappropriate rescaling of the above Gaussian process leads to a rate-optimal\nposterior distribution even when the covariates are independently realized from\na known density on a compact set. The proofs are based on deriving sharp\nconcentration inequalities for frequentist kernel estimators; the results might\nbe of independent interest.\n", "versions": [{"version": "v1", "created": "Wed, 26 Nov 2014 23:07:06 GMT"}, {"version": "v2", "created": "Thu, 5 Mar 2015 00:44:04 GMT"}], "update_date": "2015-03-06", "authors_parsed": [["Pati", "Debdeep", ""], ["Bhattacharya", "Anirban", ""], ["Cheng", "Guang", ""]]}, {"id": "1411.7565", "submitter": "Jesse Hemerik", "authors": "Jesse Hemerik, Jelle Goeman", "title": "Exact testing with random permutations", "comments": null, "journal-ref": "Test, 2017 (Online First version)", "doi": "10.1007/s11749-017-0571-1", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When permutation methods are used in practice, often a limited number of\nrandom permutations are used to decrease the computational burden. However,\nmost theoretical literature assumes that the whole permutation group is used,\nand methods based on random permutations tend to be seen as approximate. There\nexists a very limited amount of literature on exact testing with random\npermutations and only recently a thorough proof of exactness was given. In this\npaper we provide an alternative proof, viewing the test as a \"conditional Monte\nCarlo test\" as it has been called in the literature. We also provide extensions\nof the result. Importantly, our results can be used to prove properties of\nvarious multiple testing procedures based on random permutations.\n", "versions": [{"version": "v1", "created": "Thu, 27 Nov 2014 12:05:10 GMT"}, {"version": "v2", "created": "Tue, 26 Jul 2016 09:58:46 GMT"}, {"version": "v3", "created": "Fri, 17 Aug 2018 08:40:30 GMT"}], "update_date": "2018-08-20", "authors_parsed": [["Hemerik", "Jesse", ""], ["Goeman", "Jelle", ""]]}, {"id": "1411.7581", "submitter": "Inga Samonenko", "authors": "Inga Samonenko, John Robinson", "title": "A new permutation test statistic for complete block designs", "comments": "Published in at http://dx.doi.org/10.1214/14-AOS1266 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2015, Vol. 43, No. 1, 90-101", "doi": "10.1214/14-AOS1266", "report-no": "IMS-AOS-AOS1266", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a nonparametric test statistic for the permutation test in\ncomplete block designs. We find the region in which the statistic exists and\nconsider particularly its properties on the boundary of the region. Further, we\nprove that saddlepoint approximations for tail probabilities can be obtained\ninside the interior of this region. Finally, numerical examples are given\nshowing that both accuracy and power of the new statistic improves on these\nproperties of the classical $F$-statistic under some non-Gaussian models and\nequals them for the Gaussian case.\n", "versions": [{"version": "v1", "created": "Thu, 27 Nov 2014 13:19:01 GMT"}], "update_date": "2014-12-01", "authors_parsed": [["Samonenko", "Inga", ""], ["Robinson", "John", ""]]}, {"id": "1411.7601", "submitter": "Linwei Hu", "authors": "Linwei Hu, Min Yang, John Stufken", "title": "Saturated locally optimal designs under differentiable optimality\n  criteria", "comments": "Published in at http://dx.doi.org/10.1214/14-AOS1263 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2015, Vol. 43, No. 1, 30-56", "doi": "10.1214/14-AOS1263", "report-no": "IMS-AOS-AOS1263", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop general theory for finding locally optimal designs in a class of\nsingle-covariate models under any differentiable optimality criterion. Yang and\nStufken [Ann. Statist. 40 (2012) 1665-1681] and Dette and Schorning [Ann.\nStatist. 41 (2013) 1260-1267] gave complete class results for optimal designs\nunder such models. Based on their results, saturated optimal designs exist;\nhowever, how to find such designs has not been addressed. We develop tools to\nfind saturated optimal designs, and also prove their uniqueness under mild\nconditions.\n", "versions": [{"version": "v1", "created": "Thu, 27 Nov 2014 13:49:05 GMT"}], "update_date": "2014-12-01", "authors_parsed": [["Hu", "Linwei", ""], ["Yang", "Min", ""], ["Stufken", "John", ""]]}, {"id": "1411.7650", "submitter": "Florencia Leonardi", "authors": "Sandro Gallo and Florencia Leonardi", "title": "Nonparametric statistical inference for the context tree of a stationary\n  ergodic process", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of estimating the context tree of a stationary\nergodic process with finite alphabet without imposing additional conditions on\nthe process. As a starting point we introduce a Hamming metric in the space of\nirreducible context trees and we use the properties of the weak topology in the\nspace of ergodic stationary processes to prove that if the Hamming metric is\nunbounded, there exist no consistent estimators for the context tree. Even in\nthe bounded case we show that there exist no two-sided confidence bounds.\nHowever we prove that one-sided inference is possible in this general setting\nand we construct a consistent estimator that is a lower bound for the context\ntree of the process with an explicit formula for the coverage probability. We\ndevelop an efficient algorithm to compute the lower bound and we apply the\nmethod to test a linguistic hypothesis about the context tree of codified\nwritten texts in European Portuguese.\n", "versions": [{"version": "v1", "created": "Thu, 27 Nov 2014 17:15:10 GMT"}, {"version": "v2", "created": "Thu, 20 Aug 2015 09:58:48 GMT"}], "update_date": "2015-08-21", "authors_parsed": [["Gallo", "Sandro", ""], ["Leonardi", "Florencia", ""]]}, {"id": "1411.7687", "submitter": "Paula Saavedra-Nieves", "authors": "A. Rodr\\'iguez-Casal and P. Saavedra-Nieves", "title": "A fully data-driven method for estimating density level sets", "comments": "49 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Density level sets can be estimated using plug-in methods, excess mass\nalgorithms or a hybrid of the two previous methodologies. The plug-in\nalgorithms are based on replacing the unknown density by some nonparametric\nestimator, usually the kernel. Thus, the bandwidth selection is a fundamental\nproblem from an applied perspective. However, if some a priori information\nabout the geometry of the level set is available, then excess mass algorithms\ncould be useful. Hybrid methods such that granulometric smoothing algorithm\nassume a mild geometric restriction on the level set and it requires a pilot\nnonparametric estimator of the density. In this work, a new hybrid algorithm is\nproposed under the assumption that the level set is r-convex. The main problem\nin practice is that r is an unknown geometric characteristic of the set. A\nstochastic algorithm is proposed for selecting its optimal value. The resulting\ndata-driven reconstruction of the level set is able to achieve the same\nconvergence rates as the granulometric smoothing method. However, they do no\ndepend on any penalty term because, although the value of the shape index r is\na priori unknown, it is estimated in a data-driven way from the sample points.\nThe practical performance of the estimator proposed is illustrated through a\nreal data example.\n", "versions": [{"version": "v1", "created": "Thu, 27 Nov 2014 19:32:25 GMT"}], "update_date": "2016-11-26", "authors_parsed": [["Rodr\u00edguez-Casal", "A.", ""], ["Saavedra-Nieves", "P.", ""]]}, {"id": "1411.7713", "submitter": "Sebastian Vollmer", "authors": "Sergios Agapiou and Gareth O. Roberts and Sebastian J. Vollmer", "title": "Unbiased Monte Carlo: posterior estimation for\n  intractable/infinite-dimensional models", "comments": "74pages, 9 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a general methodology for unbiased estimation for intractable\nstochastic models. We consider situations where the target distribution can be\nwritten as an appropriate limit of distributions, and where conventional\napproaches require truncation of such a representation leading to a systematic\nbias. For example, the target distribution might be representable as the\n$L^2$-limit of a basis expansion in a suitable Hilbert space; or alternatively\nthe distribution of interest might be representable as the weak limit of a\nsequence of random variables, as in MCMC. Our main motivation comes from\ninfinite-dimensional models which can be parame- terised in terms of a series\nexpansion of basis functions (such as that given by a Karhunen-Loeve\nexpansion). We consider schemes for direct unbiased estimation along such an\nexpansion, as well as those based on MCMC schemes which, due to their\ndimensionality, cannot be directly imple- mented, but which can be effectively\nestimated unbiasedly. For all our methods we give theory to justify the\nnumerical stability for robust Monte Carlo implementation, and in some cases we\nillustrate using simulations. Interestingly the computational efficiency of our\nmethods is usually comparable to simpler methods which are biased. Crucial to\nthe effectiveness of our proposed methodology is the construction of\nappropriate couplings, many of which resonate strongly with the Monte Carlo\nconstructions used in the coupling from the past algorithm and its variants.\n", "versions": [{"version": "v1", "created": "Thu, 27 Nov 2014 22:36:34 GMT"}], "update_date": "2014-12-01", "authors_parsed": [["Agapiou", "Sergios", ""], ["Roberts", "Gareth O.", ""], ["Vollmer", "Sebastian J.", ""]]}, {"id": "1411.7817", "submitter": "Franz J. Kir\\'aly", "authors": "Franz J. Kir\\'aly, Andreas Ziehe, Klaus-Robert M\\\"uller", "title": "Learning with Algebraic Invariances, and the Invariant Kernel Trick", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When solving data analysis problems it is important to integrate prior\nknowledge and/or structural invariances. This paper contributes by a novel\nframework for incorporating algebraic invariance structure into kernels. In\nparticular, we show that algebraic properties such as sign symmetries in data,\nphase independence, scaling etc. can be included easily by essentially\nperforming the kernel trick twice. We demonstrate the usefulness of our theory\nin simulations on selected applications such as sign-invariant spectral\nclustering and underdetermined ICA.\n", "versions": [{"version": "v1", "created": "Fri, 28 Nov 2014 11:20:48 GMT"}], "update_date": "2014-12-01", "authors_parsed": [["Kir\u00e1ly", "Franz J.", ""], ["Ziehe", "Andreas", ""], ["M\u00fcller", "Klaus-Robert", ""]]}, {"id": "1411.7920", "submitter": "Samuel Rodriques", "authors": "Samuel G. Rodriques", "title": "Probability Theory without Bayes' Rule", "comments": "12 pages, no figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.AI math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Within the Kolmogorov theory of probability, Bayes' rule allows one to\nperform statistical inference by relating conditional probabilities to\nunconditional probabilities. As we show here, however, there is a continuous\nset of alternative inference rules that yield the same results, and that may\nhave computational or practical advantages for certain problems. We formulate\ngeneralized axioms for probability theory, according to which the reverse\nconditional probability distribution P(B|A) is not specified by the forward\nconditional probability distribution P(A|B) and the marginals P(A) and P(B).\nThus, in order to perform statistical inference, one must specify an additional\n\"inference axiom,\" which relates P(B|A) to P(A|B), P(A), and P(B). We show that\nwhen Bayes' rule is chosen as the inference axiom, the axioms are equivalent to\nthe classical Kolmogorov axioms. We then derive consistency conditions on the\ninference axiom, and thereby characterize the set of all possible rules for\ninference. The set of \"first-order\" inference axioms, defined as the set of\naxioms in which P(B|A) depends on the first power of P(A|B), is found to be a\n1-simplex, with Bayes' rule at one of the extreme points. The other extreme\npoint, the \"inversion rule,\" is studied in depth.\n", "versions": [{"version": "v1", "created": "Fri, 28 Nov 2014 15:59:44 GMT"}, {"version": "v2", "created": "Thu, 4 Dec 2014 01:20:30 GMT"}], "update_date": "2014-12-05", "authors_parsed": [["Rodriques", "Samuel G.", ""]]}]