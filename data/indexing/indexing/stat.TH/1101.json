[{"id": "1101.0140", "submitter": "Martin Ehler", "authors": "Martin Ehler and Kasso A. Okoudjou", "title": "Minimization of the Probabilistic p-frame Potential", "comments": null, "journal-ref": null, "doi": "10.1016/j.jspi.2011.09.001", "report-no": null, "categories": "math.FA math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the optimal configurations of n points on the unit sphere for\na class of potential functions. In particular, we characterize these optimal\nconfigurations in terms of their approximation properties within frame theory.\nFurthermore, we consider similar optimal configurations in terms of random\ndistributions of points on the sphere. In this probabilistic setting, we\ncharacterize these optimal distributions by means of special classes of\nprobabilistic frames. Our work also indicates some connections between\nstatistical shape analysis and frame theory.\n", "versions": [{"version": "v1", "created": "Thu, 30 Dec 2010 19:29:42 GMT"}, {"version": "v2", "created": "Wed, 20 Apr 2011 15:36:22 GMT"}], "update_date": "2017-09-04", "authors_parsed": [["Ehler", "Martin", ""], ["Okoudjou", "Kasso A.", ""]]}, {"id": "1101.0255", "submitter": "Reza Hosseini", "authors": "Reza Hosseini", "title": "Conditional information and definition of neighbor in categorical random\n  fields", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the definition of neighbor in Markov random fields as defined by\nBesag (1974) when the joint distribution of the sites is not positive is not\nwell-defined. In a random field with finite number of sites we study the\nconditions under which giving the value at extra sites will change the belief\nof an agent about one site. Also the conditions under which the information\nfrom some sites is equivalent to giving the value at all other sites is\nstudied. These concepts provide an alternative to the concept of neighbor for\ngeneral case where the positivity condition of the joint does not hold.\n", "versions": [{"version": "v1", "created": "Fri, 31 Dec 2010 13:33:14 GMT"}], "update_date": "2011-01-04", "authors_parsed": [["Hosseini", "Reza", ""]]}, {"id": "1101.0305", "submitter": "David R. Bickel", "authors": "David R. Bickel", "title": "Measuring support for a hypothesis about a random parameter without\n  estimating its unknown prior", "comments": "Errors in the first version were corrected, and the methodology is\n  now applied to more interesting data", "journal-ref": "D. R. Bickel, Minimax-optimal strength of statistical evidence for\n  a composite alternative hypothesis, International Statistical Review 81,\n  188-206 (2013)", "doi": "10.1111/insr.12008", "report-no": null, "categories": "math.ST cs.IT math.IT q-bio.QM stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For frequentist settings in which parameter randomness represents variability\nrather than uncertainty, the ideal measure of the support for one hypothesis\nover another is the difference in the posterior and prior log odds. For\nsituations in which the prior distribution cannot be accurately estimated, that\nideal support may be replaced by another measure of support, which may be any\npredictor of the ideal support that, on a per-observation basis, is\nasymptotically unbiased. Two qualifying measures of support are defined. The\nfirst is minimax optimal with respect to the population and is equivalent to a\nparticular Bayes factor. The second is worst-sample minimax optimal and is\nequivalent to the normalized maximum likelihood. It has been extended by\nlikelihood weights for compatibility with more general models.\n  One such model is that of two independent normal samples, the standard\nsetting for gene expression microarray data analysis. Applying that model to\nproteomics data indicates that support computed from data for a single protein\ncan closely approximate the estimated difference in posterior and prior odds\nthat would be available with the data for 20 proteins. This suggests the\napplicability of random-parameter models to other situations in which the\nparameter distribution cannot be reliably estimated.\n", "versions": [{"version": "v1", "created": "Fri, 31 Dec 2010 22:32:51 GMT"}, {"version": "v2", "created": "Sat, 2 Apr 2011 20:29:05 GMT"}], "update_date": "2013-09-03", "authors_parsed": [["Bickel", "David R.", ""]]}, {"id": "1101.0344", "submitter": "Robin Genuer", "authors": "Robin Genuer (LM-Orsay, INRIA Saclay - Ile de France), Isabelle\n  Morlais, Wilson Toussile (LM-Orsay)", "title": "Gametocytes infectiousness to mosquitoes: variable selection using\n  random forests, and zero inflated models", "comments": null, "journal-ref": null, "doi": null, "report-no": "RR-7497", "categories": "math.ST q-bio.PE q-bio.QM stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Malaria control strategies aiming at reducing disease transmission intensity\nmay impact both oocyst intensity and infection prevalence in the mosquito\nvector. Thus far, mathematical models failed to identify a clear relationship\nbetween Plasmodium falciparum gametocytes and their infectiousness to\nmosquitoes. Natural isolates of gametocytes are genetically diverse and\nbiologically complex. Infectiousness to mosquitoes relies on multiple\nparameters such as density, sex-ratio, maturity, parasite genotypes and host\nimmune factors. In this article, we investigated how density and genetic\ndiversity of gametocytes impact on the success of transmission in the mosquito\nvector. We analyzed data for which the number of covariates plus attendant\ninteractions is at least of order of the sample size, precluding usage of\nclassical models such as general linear models. We then considered the variable\nimportance from random forests to address the problem of selecting the most\ninfluent variables. The selected covariates were assessed in the zero inflated\nnegative binomial model which accommodates both over-dispersion and the sources\nof non infected mosquitoes. We found that the most important covariates related\nto infection prevalence and parasite intensity are gametocyte density and\nmultiplicity of infection.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jan 2011 15:02:14 GMT"}, {"version": "v2", "created": "Tue, 4 Jan 2011 15:27:42 GMT"}, {"version": "v3", "created": "Tue, 22 Feb 2011 07:23:13 GMT"}], "update_date": "2011-02-24", "authors_parsed": [["Genuer", "Robin", "", "LM-Orsay, INRIA Saclay - Ile de France"], ["Morlais", "Isabelle", "", "LM-Orsay"], ["Toussile", "Wilson", "", "LM-Orsay"]]}, {"id": "1101.0434", "submitter": "Stephane Chretien", "authors": "St\\'ephane Chr\\'etien and S\\'ebastien Darses", "title": "Sparse recovery with unknown variance: a LASSO-type approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the issue of estimating the regression vector $\\beta$ in the\ngeneric $s$-sparse linear model $y = X\\beta+z$, with $\\beta\\in\\R^{p}$,\n$y\\in\\R^{n}$, $z\\sim\\mathcal N(0,\\sg^2 I)$ and $p> n$ when the variance\n$\\sg^{2}$ is unknown. We study two LASSO-type methods that jointly estimate\n$\\beta$ and the variance. These estimators are minimizers of the $\\ell_1$\npenalized least-squares functional, where the relaxation parameter is tuned\naccording to two different strategies. In the first strategy, the relaxation\nparameter is of the order $\\ch{\\sigma} \\sqrt{\\log p}$, where $\\ch{\\sigma}^2$ is\nthe empirical variance. %The resulting optimization problem can be solved by\nrunning only a few successive LASSO instances with %recursive updating of the\nrelaxation parameter. In the second strategy, the relaxation parameter is\nchosen so as to enforce a trade-off between the fidelity and the penalty terms\nat optimality. For both estimators, our assumptions are similar to the ones\nproposed by Cand\\`es and Plan in {\\it Ann. Stat. (2009)}, for the case where\n$\\sg^{2}$ is known. We prove that our estimators ensure exact recovery of the\nsupport and sign pattern of $\\beta$ with high probability. We present\nsimulations results showing that the first estimator enjoys nearly the same\nperformances in practice as the standard LASSO (known variance case) for a wide\nrange of the signal to noise ratio. Our second estimator is shown to outperform\nboth in terms of false detection, when the signal to noise ratio is low.\n", "versions": [{"version": "v1", "created": "Sun, 2 Jan 2011 21:40:26 GMT"}, {"version": "v2", "created": "Tue, 15 Mar 2011 22:57:33 GMT"}, {"version": "v3", "created": "Thu, 12 May 2011 22:30:22 GMT"}, {"version": "v4", "created": "Sat, 28 Jan 2012 00:06:14 GMT"}, {"version": "v5", "created": "Mon, 5 Nov 2012 15:37:51 GMT"}], "update_date": "2012-11-06", "authors_parsed": [["Chr\u00e9tien", "St\u00e9phane", ""], ["Darses", "S\u00e9bastien", ""]]}, {"id": "1101.0689", "submitter": "Christine Tuleau-Malot", "authors": "Marie Sauv\\'e and Christine Tuleau-Malot", "title": "Variable selection through CART", "comments": "33 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with variable selection in the regression and binary\nclassification frameworks. It proposes an automatic and exhaustive procedure\nwhich relies on the use of the CART algorithm and on model selection via\npenalization. This work, of theoretical nature, aims at determining adequate\npenalties, i.e. penalties which allow to get oracle type inequalities\njustifying the performance of the proposed procedure. Since the exhaustive\nprocedure can not be executed when the number of variables is too big, a more\npractical procedure is also proposed and still theoretically validated. A\nsimulation study completes the theoretical results.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jan 2011 10:07:55 GMT"}], "update_date": "2011-01-05", "authors_parsed": [["Sauv\u00e9", "Marie", ""], ["Tuleau-Malot", "Christine", ""]]}, {"id": "1101.0736", "submitter": "Bernard Bercu", "authors": "Bernard Bercu, Philippe Fraysse", "title": "A Robbins-Monro procedure for estimation in semiparametric regression\n  models", "comments": "Published in at http://dx.doi.org/10.1214/12-AOS969 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2012, Vol. 40, No. 2, 666-693", "doi": "10.1214/12-AOS969", "report-no": "IMS-AOS-AOS969", "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is devoted to the parametric estimation of a shift together with\nthe nonparametric estimation of a regression function in a semiparametric\nregression model. We implement a very efficient and easy to handle\nRobbins-Monro procedure. On the one hand, we propose a stochastic algorithm\nsimilar to that of Robbins-Monro in order to estimate the shift parameter. A\npreliminary evaluation of the regression function is not necessary to estimate\nthe shift parameter. On the other hand, we make use of a recursive\nNadaraya-Watson estimator for the estimation of the regression function. This\nkernel estimator takes into account the previous estimation of the shift\nparameter. We establish the almost sure convergence for both Robbins-Monro and\nNadaraya--Watson estimators. The asymptotic normality of our estimates is also\nprovided. Finally, we illustrate our semiparametric estimation procedure on\nsimulated and real data.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jan 2011 15:16:37 GMT"}, {"version": "v2", "created": "Mon, 4 Jun 2012 13:01:38 GMT"}], "update_date": "2012-06-05", "authors_parsed": [["Bercu", "Bernard", ""], ["Fraysse", "Philippe", ""]]}, {"id": "1101.0933", "submitter": "Antoine Lejay", "authors": "Antoine Lejay and Ernesto Mordecki and Soledad Torres", "title": "Is a Brownian skew?", "comments": "26 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the asymptotic behavior of the maximum likelihood estimator\ncorresponding to the observation of a trajectory of a Skew Brownian motion,\nthrough a uniform time discretization. We characterize the speed of convergence\nand the limiting distribution when the step size goes to zero, which in this\ncase are non-classical, under the null hypothesis of the Skew Brownian motion\nbeing an usual Brownian motion. This allows to design a test on the skewness\nparameter. We show that numerical simulations that can be easily performed to\nestimate the skewness parameter, and provide an application in Biology.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jan 2011 10:40:37 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Lejay", "Antoine", ""], ["Mordecki", "Ernesto", ""], ["Torres", "Soledad", ""]]}, {"id": "1101.1001", "submitter": "Prathapasinghe Dharmawansa", "authors": "Prathapasinghe Dharmawansa and Matthew R. McKay", "title": "Extreme Eigenvalue Distributions of Some Complex Correlated Non-Central\n  Wishart and Gamma-Wishart Random Matrices", "comments": "Accepted for publication in Journal of Multivariate Analysis", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT math.IT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $\\mathbf{W}$ be a correlated complex non-central Wishart matrix defined\nthrough $\\mathbf{W}=\\mathbf{X}^H\\mathbf{X}$, where $\\mathbf{X}$ is $n\\times m\n\\, (n\\geq m)$ complex Gaussian with non-zero mean $\\boldsymbol{\\Upsilon}$ and\nnon-trivial covariance $\\boldsymbol{\\Sigma}$. We derive exact expressions for\nthe cumulative distribution functions (c.d.f.s) of the extreme eigenvalues\n(i.e., maximum and minimum) of $\\mathbf{W}$ for some particular cases. These\nresults are quite simple, involving rapidly converging infinite series, and\napply for the practically important case where $\\boldsymbol{\\Upsilon}$ has rank\none. We also derive analogous results for a certain class of gamma-Wishart\nrandom matrices, for which $\\boldsymbol{\\Upsilon}^H\\boldsymbol{\\Upsilon}$\nfollows a matrix-variate gamma distribution. The eigenvalue distributions in\nthis paper have various applications to wireless communication systems, and\narise in other fields such as econometrics, statistical physics, and\nmultivariate statistics.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jan 2011 15:12:45 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Dharmawansa", "Prathapasinghe", ""], ["McKay", "Matthew R.", ""]]}, {"id": "1101.1032", "submitter": "Emilio Seijo", "authors": "Emilio Seijo, Bodhisattva Sen", "title": "Change-point in stochastic design regression and the bootstrap", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study the consistency of different bootstrap procedures for\nconstructing confidence intervals (CIs) for the unique jump discontinuity\n(change-point) in an otherwise smooth regression function in a stochastic\ndesign setting. This problem exhibits nonstandard asymptotics and we argue that\nthe standard bootstrap procedures in regression fail to provide valid\nconfidence intervals for the change-point. We propose a version of smoothed\nbootstrap, illustrate its remarkable finite sample performance in our\nsimulation study, and prove the consistency of the procedure. The $m$ out of\n$n$ bootstrap procedure is also considered and shown to be consistent. We also\nprovide sufficient conditions for any bootstrap procedure to be consistent in\nthis scenario.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jan 2011 17:17:36 GMT"}], "update_date": "2011-01-06", "authors_parsed": [["Seijo", "Emilio", ""], ["Sen", "Bodhisattva", ""]]}, {"id": "1101.1057", "submitter": "Sebastien Gerchinovitz", "authors": "S\\'ebastien Gerchinovitz (DMA, INRIA Paris - Rocquencourt)", "title": "Sparsity regret bounds for individual sequences in online linear\n  regression", "comments": "Published in Journal of Machine Learning Research at\n  http://www.jmlr.org/papers/volume14/gerchinovitz13a/gerchinovitz13a.pdf", "journal-ref": "Journal of Machine Learning Research 14 (2011) 729-769", "doi": null, "report-no": "RR-7504", "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of online linear regression on arbitrary\ndeterministic sequences when the ambient dimension d can be much larger than\nthe number of time rounds T. We introduce the notion of sparsity regret bound,\nwhich is a deterministic online counterpart of recent risk bounds derived in\nthe stochastic setting under a sparsity scenario. We prove such regret bounds\nfor an online-learning algorithm called SeqSEW and based on exponential\nweighting and data-driven truncation. In a second part we apply a\nparameter-free version of this algorithm to the stochastic setting (regression\nmodel with random design). This yields risk bounds of the same flavor as in\nDalalyan and Tsybakov (2011) but which solve two questions left open therein.\nIn particular our risk bounds are adaptive (up to a logarithmic factor) to the\nunknown variance of the noise if the latter is Gaussian. We also address the\nregression model with fixed design.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jan 2011 19:43:37 GMT"}, {"version": "v2", "created": "Sun, 18 Mar 2012 06:52:57 GMT"}, {"version": "v3", "created": "Fri, 12 Apr 2013 10:33:39 GMT"}], "update_date": "2013-04-17", "authors_parsed": [["Gerchinovitz", "S\u00e9bastien", "", "DMA, INRIA Paris - Rocquencourt"]]}, {"id": "1101.1359", "submitter": "Pavel  Krivitsky", "authors": "Pavel N. Krivitsky (Department of Statistics, Pennsylvania State\n  University, University Park)", "title": "Exponential-Family Random Graph Models for Valued Networks", "comments": "42 pages, including 2 appendixes (3 pages total), 5 figures, 2\n  tables, 1 algorithm listing; a substantial revision and reorganization: major\n  changes include focus shifted to counts in particular, sections added on\n  modeling actor heterogeneity, a subsection on degeneracy, another example,\n  and an appendix on non-steepness of the CMP distribution", "journal-ref": "Electron. J. Statist. 6 (2012) 1100-1128", "doi": "10.1214/12-EJS696", "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exponential-family random graph models (ERGMs) provide a principled and\nflexible way to model and simulate features common in social networks, such as\npropensities for homophily, mutuality, and friend-of-a-friend triad closure,\nthrough choice of model terms (sufficient statistics). However, those ERGMs\nmodeling the more complex features have, to date, been limited to binary data:\npresence or absence of ties. Thus, analysis of valued networks, such as those\nwhere counts, measurements, or ranks are observed, has necessitated\ndichotomizing them, losing information and introducing biases.\n  In this work, we generalize ERGMs to valued networks. Focusing on modeling\ncounts, we formulate an ERGM for networks whose ties are counts and discuss\nissues that arise when moving beyond the binary case. We introduce model terms\nthat generalize and model common social network features for such data and\napply these methods to a network dataset whose values are counts of\ninteractions.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jan 2011 06:26:49 GMT"}, {"version": "v2", "created": "Thu, 19 Jan 2012 07:10:54 GMT"}], "update_date": "2012-08-01", "authors_parsed": [["Krivitsky", "Pavel N.", "", "Department of Statistics, Pennsylvania State\n  University, University Park"]]}, {"id": "1101.1597", "submitter": "Bernd Sturmfels", "authors": "Bernd Sturmfels and Volkmar Welker", "title": "Commutative Algebra of Statistical Ranking", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AC cs.DM math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A model for statistical ranking is a family of probability distributions\nwhose states are orderings of a fixed finite set of items. We represent the\norderings as maximal chains in a graded poset. The most widely used ranking\nmodels are parameterized by rational function in the model parameters, so they\ndefine algebraic varieties. We study these varieties from the perspective of\ncombinatorial commutative algebra. One of our models, the Plackett-Luce model,\nis non-toric. Five others are toric: the Birkhoff model, the ascending model,\nthe Csiszar model, the inversion model, and the Bradley-Terry model. For these\nmodels we examine the toric algebra, its lattice polytope, and its Markov\nbasis.\n", "versions": [{"version": "v1", "created": "Sat, 8 Jan 2011 15:09:35 GMT"}, {"version": "v2", "created": "Mon, 5 Dec 2011 14:25:32 GMT"}], "update_date": "2011-12-06", "authors_parsed": [["Sturmfels", "Bernd", ""], ["Welker", "Volkmar", ""]]}, {"id": "1101.1715", "submitter": "Jose M. Pe\\~na", "authors": "Jose M. Pe\\~na", "title": "Finding Consensus Bayesian Network Structures", "comments": "Changes from v3 to v4: Section 1 has been extended with more\n  motivation and a review of the literature. Theorem 3 proves that CONSENSUS is\n  not only NP-hard but NP-complete. A flaw in Theorem 4 has been fixed. The\n  proof of Theorem 5 has been re-written from scratch. Now, it is\n  self-contained, i.e. it does not rely upon the algorithm by Chickering (2004)", "journal-ref": "Journal of Artificial Intelligence Research, 42, 661-687, 2011", "doi": null, "report-no": null, "categories": "stat.ML cs.AI math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Suppose that multiple experts (or learning algorithms) provide us with\nalternative Bayesian network (BN) structures over a domain, and that we are\ninterested in combining them into a single consensus BN structure.\nSpecifically, we are interested in that the consensus BN structure only\nrepresents independences all the given BN structures agree upon and that it has\nas few parameters associated as possible. In this paper, we prove that there\nmay exist several non-equivalent consensus BN structures and that finding one\nof them is NP-hard. Thus, we decide to resort to heuristics to find an\napproximated consensus BN structure. In this paper, we consider the heuristic\nproposed in\n\\citep{MatzkevichandAbramson1992,MatzkevichandAbramson1993a,MatzkevichandAbramson1993b}.\nThis heuristic builds upon two algorithms, called Methods A and B, for\nefficiently deriving the minimal directed independence map of a BN structure\nrelative to a given node ordering. Methods A and B are claimed to be correct\nalthough no proof is provided (a proof is just sketched). In this paper, we\nshow that Methods A and B are not correct and propose a correction of them.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jan 2011 07:41:50 GMT"}, {"version": "v2", "created": "Mon, 24 Jan 2011 16:54:15 GMT"}, {"version": "v3", "created": "Sat, 26 Feb 2011 22:15:07 GMT"}, {"version": "v4", "created": "Mon, 11 Jul 2011 15:57:34 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Pe\u00f1a", "Jose M.", ""]]}, {"id": "1101.2121", "submitter": "Romain Aza\\\"is", "authors": "Aza\\\"is Romain, G\\'egout-Petit Anne and Saracco J\\'er\\^ome", "title": "Optimal quantization applied to Sliced Inverse Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider a semiparametric regression model involving a\n$d$-dimensional quantitative explanatory variable $X$ and including a dimension\nreduction of $X$ via an index $\\beta'X$. In this model, the main goal is to\nestimate the euclidean parameter $\\beta$ and to predict the real response\nvariable $Y$ conditionally to $X$. Our approach is based on sliced inverse\nregression (SIR) method and optimal quantization in $\\mathbf{L}^p$-norm. We\nobtain the convergence of the proposed estimators of $\\beta$ and of the\nconditional distribution. Simulation studies show the good numerical behavior\nof the proposed estimators for finite sample size.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jan 2011 13:10:14 GMT"}, {"version": "v2", "created": "Wed, 12 Jan 2011 09:27:06 GMT"}], "update_date": "2011-01-13", "authors_parsed": [["Romain", "Aza\u00efs", ""], ["Anne", "G\u00e9gout-Petit", ""], ["J\u00e9r\u00f4me", "Saracco", ""]]}, {"id": "1101.2481", "submitter": "Art Owen", "authors": "Justin S. Dyer, Art B. Owen", "title": "Correct ordering in the Zipf-Poisson ensemble", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a Zipf--Poisson ensemble in which $X_i\\sim\\poi(Ni^{-\\alpha})$ for\n$\\alpha>1$ and $N>0$ and integers $i\\ge 1$. As $N\\to\\infty$ the first $n'(N)$\nrandom variables have their proper order $X_1>X_2>...>X_{n'}$ relative to each\nother, with probability tending to 1 for $n'$ up to\n$(AN/\\log(N))^{1/(\\alpha+2)}$ for an explicit constant $A(\\alpha)\\ge 3/4$. The\nrate $N^{1/(\\alpha+2)}$ cannot be achieved. The ordering of the first $n'(N)$\nentities does not preclude $X_m>X_{n'}$ for some interloping $m>n'$. The first\n$n\"$ random variables are correctly ordered exclusive of any interlopers, with\nprobability tending to 1 if $n\"\\le (BN/\\log(N))^{1/(\\alpha+2)}$ for $B<A$. For\na Zipf--Poisson model of the British National Corpus, which has a total word\ncount of $100{,}000{,}000$, our result estimates that the 72 words with the\nhighest counts are properly ordered.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jan 2011 03:17:01 GMT"}], "update_date": "2011-01-14", "authors_parsed": [["Dyer", "Justin S.", ""], ["Owen", "Art B.", ""]]}, {"id": "1101.2576", "submitter": "Alexander Mishchenko", "authors": "V.K.Bozhenko, A.O.Ivanov, A.S.Mishchenko, A.A.Tuzhilin, A.M.Shishkin", "title": "Determination of Different Biological Factors on the Base of Dried Blood\n  Spot Technology", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST physics.med-ph stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well-known that distinct biological indices (analytes) have distinct\nvariability. We try to use some mathematical algorithms to pick out a set of\nblood parameters which give an opportunity to retrieve the initial volume of\nthe blood spotted, and use it to calculate exact concentrations of analyts\ninteresting to a physician. For our analysis we used the database of\nbiochemical blood parameters obtained in Russian Scientific Center of\nRoentgen-Radiology during 1995-2000, which includes more than 30000 of\npatients.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jan 2011 15:04:42 GMT"}], "update_date": "2011-01-14", "authors_parsed": [["Bozhenko", "V. K.", ""], ["Ivanov", "A. O.", ""], ["Mishchenko", "A. S.", ""], ["Tuzhilin", "A. A.", ""], ["Shishkin", "A. M.", ""]]}, {"id": "1101.3229", "submitter": "Pierre Alquier", "authors": "Pierre Alquier (LPMA, CREST), G\\'erard Biau (LPMA, LSTA, DMA)", "title": "Sparse single-index model", "comments": null, "journal-ref": "Journal of Machine Learning Research 14 (2013) 243-280", "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $(\\bX, Y)$ be a random pair taking values in $\\mathbb R^p \\times \\mathbb\nR$. In the so-called single-index model, one has $Y=f^{\\star}(\\theta^{\\star\nT}\\bX)+\\bW$, where $f^{\\star}$ is an unknown univariate measurable function,\n$\\theta^{\\star}$ is an unknown vector in $\\mathbb R^d$, and $W$ denotes a\nrandom noise satisfying $\\mathbb E[\\bW|\\bX]=0$. The single-index model is known\nto offer a flexible way to model a variety of high-dimensional real-world\nphenomena. However, despite its relative simplicity, this dimension reduction\nscheme is faced with severe complications as soon as the underlying dimension\nbecomes larger than the number of observations (\"$p$ larger than $n$\"\nparadigm). To circumvent this difficulty, we consider the single-index model\nestimation problem from a sparsity perspective using a PAC-Bayesian approach.\nOn the theoretical side, we offer a sharp oracle inequality, which is more\npowerful than the best known oracle inequalities for other common procedures of\nsingle-index recovery. The proposed method is implemented by means of the\nreversible jump Markov chain Monte Carlo technique and its performance is\ncompared with that of standard procedures.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jan 2011 14:36:55 GMT"}, {"version": "v2", "created": "Thu, 6 Oct 2011 19:23:14 GMT"}], "update_date": "2013-06-18", "authors_parsed": [["Alquier", "Pierre", "", "LPMA, CREST"], ["Biau", "G\u00e9rard", "", "LPMA, LSTA, DMA"]]}, {"id": "1101.3286", "submitter": "Iosif Pinelis", "authors": "Iosif Pinelis", "title": "On the Berry-Esseen bound for the Student statistic", "comments": "A few minor changes made", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  New Berry--Esseen-type bounds, with explicit constant factors, for the\ndistribution of the Student statistic and, equivalently, for that of the\nself-normalized sum of independent zero-mean random variables are obtained.\nThese bounds are compared with the corresponding existing results.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jan 2011 18:25:37 GMT"}, {"version": "v2", "created": "Wed, 23 May 2012 19:40:50 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Pinelis", "Iosif", ""]]}, {"id": "1101.3289", "submitter": "Iosif Pinelis", "authors": "Iosif Pinelis", "title": "Monotone tail and moment ratio properties of Student's family of\n  distributions", "comments": "8 pages; corollaries on the monotonicity of (generalized) moments and\n  ratios thereof are added; the title and abstract are modified accordingly", "journal-ref": "Math. Methods Statist., 24(1):74--79 (2015)", "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let G_p denote the tail function of Student's distribution with p degrees of\nfreedom. It is shown that the ratio G_q(x)/G_p(x) is decreasing in x>0 for any\np and q such that 0<p<q\\le\\infty. Therefore, G_q(x)<G_p(x) for all such p and q\nand all x>0. Corollaries on the monotonicity of (generalized) moments and\nratios thereof are also given.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jan 2011 19:01:04 GMT"}, {"version": "v2", "created": "Wed, 6 Jun 2012 22:10:47 GMT"}], "update_date": "2017-01-17", "authors_parsed": [["Pinelis", "Iosif", ""]]}, {"id": "1101.3306", "submitter": "Piet Groeneboom", "authors": "Piet Groeneboom and Geurt Jongbloed", "title": "Isotonic L_2-projection test for local monotonicity of a hazard", "comments": "15 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new test statistic for testing the null hypothesis that the\nsampling distribution has an increasing hazard rate on a specified interval\n[0,a]. It is based on a comparison of the empirical distribution function with\nan isotonic estimate, using the restriction that the hazard is increasing, and\nmeasures the excursions of the empirical distribution above the isotonic\nestimate, due to local non-monotonicity. It is proved in the companion paper\nGroeneboom and Jongbloed (2011a) that the test statistic is asymptotically\nnormal if the hazard is strictly increasing on the interval [0,a] and certain\nregularity conditions are satisfied. We discuss a bootstrap method for\ncomputing the critical values and compare the test, thus obtained, with other\nproposals in a simulation study.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jan 2011 20:58:05 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Groeneboom", "Piet", ""], ["Jongbloed", "Geurt", ""]]}, {"id": "1101.3328", "submitter": "Iosif Pinelis", "authors": "Iosif Pinelis", "title": "Exact bounds on the closeness between the Student and standard normal\n  distributions", "comments": "Comparisons with the corresponding results by Shimizu; Cacoullos,\n  Papathanasiou, and Utev; and Bourguin and Tudor are added", "journal-ref": "ESAIM: Probability and Statistics, 19:24--27 (2015)", "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Upper bounds on the Kolmogorov distance (and, equivalently in this case, on\nthe total variation distance) between the Student distribution with p degrees\nof freedom (SD_p) and the standard normal distribution are obtained. These\nbounds are in a certain sense best possible, and the corresponding relative\nerrors are small even for moderate values of p. The same bounds hold on the\ncloseness between SD_p and SD_q with q>p.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jan 2011 21:04:53 GMT"}, {"version": "v2", "created": "Wed, 20 Feb 2013 22:37:13 GMT"}], "update_date": "2017-01-17", "authors_parsed": [["Pinelis", "Iosif", ""]]}, {"id": "1101.3333", "submitter": "Piet Groeneboom", "authors": "Piet Groeneboom and Geurt Jongbloed", "title": "Testing monotonicity of a hazard: asymptotic distribution theory", "comments": "28 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two new test statistics are introduced to test the null hypotheses that the\nsampling distribution has an increasing hazard rate on a specified interval\n[0,a]. These statistics are empirical L_1-type distances between the isotonic\nestimates, which use the monotonicity constraint, and either the empirical\ndistribution function or the empirical cumulative hazard. They measure the\nexcursions of the empirical estimates with respect to the isotonic estimates,\ndue to local non-monotonicity. Asymptotic normality of the test statistics, if\nthe hazard is strictly increasing on [0,a], is established under mild\nconditions. This is done by first approximating the global empirical distance\nby an distance with respect to the underlying distribution function. The\nresulting integral is treated as sum of increasingly many local integrals to\nwhich a CLT can be applied. The behavior of the local integrals is determined\nby a canonical process: the difference between the stochastic process x ->\nW(x)+x^2 where W is standard two-sided Brownian Motion, and its greatest convex\nminorant.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jan 2011 21:11:21 GMT"}, {"version": "v2", "created": "Wed, 26 Oct 2011 13:33:37 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Groeneboom", "Piet", ""], ["Jongbloed", "Geurt", ""]]}, {"id": "1101.3412", "submitter": "John Kent", "authors": "Reman Abu-Shanab and John T. Kent and William E. Strawderman", "title": "Shrinkage estimation with a matrix loss function", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider estimating the n by p matrix of means of an n by p matrix of\nindependent normally distributed observations with constant variance, where the\nperformance of an estimator is judged using a p by p matrix quadratic error\nloss function. A matrix version of the James-Stein estimator is proposed,\ndepending on a tuning constant. It is shown to dominate the usual maximum\nlikelihood estimator for some choices of of the tuning constant when n is\ngreater than or equal to 3. This result also extends to other shrinkage\nestimators and settings.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jan 2011 09:42:44 GMT"}], "update_date": "2011-01-19", "authors_parsed": [["Abu-Shanab", "Reman", ""], ["Kent", "John T.", ""], ["Strawderman", "William E.", ""]]}, {"id": "1101.3501", "submitter": "Adam D. Bull", "authors": "Adam D. Bull", "title": "Convergence rates of efficient global optimization algorithms", "comments": null, "journal-ref": "Journal of Machine Learning Research 12:2879-2904, 2011", "doi": null, "report-no": null, "categories": "stat.ML math.OC math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient global optimization is the problem of minimizing an unknown\nfunction f, using as few evaluations f(x) as possible. It can be considered as\na continuum-armed bandit problem, with noiseless data and simple regret.\nExpected improvement is perhaps the most popular method for solving this\nproblem; the algorithm performs well in experiments, but little is known about\nits theoretical properties. Implementing expected improvement requires a choice\nof Gaussian process prior, which determines an associated space of functions,\nits reproducing-kernel Hilbert space (RKHS). When the prior is fixed, expected\nimprovement is known to converge on the minimum of any function in the RKHS. We\nbegin by providing convergence rates for this procedure. The rates are optimal\nfor functions of low smoothness, and we modify the algorithm to attain optimal\nrates for smoother functions. For practitioners, however, these results are\nsomewhat misleading. Priors are typically not held fixed, but depend on\nparameters estimated from the data. For standard estimators, we show this\nprocedure may never discover the minimum of f. We then propose alternative\nestimators, chosen to minimize the constants in the rate of convergence, and\nshow these estimators retain the convergence rates of a fixed prior.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jan 2011 17:04:18 GMT"}, {"version": "v2", "created": "Tue, 15 Feb 2011 15:06:22 GMT"}, {"version": "v3", "created": "Sat, 22 Oct 2011 10:35:49 GMT"}], "update_date": "2013-02-19", "authors_parsed": [["Bull", "Adam D.", ""]]}, {"id": "1101.3690", "submitter": "Kazuya Okamura", "authors": "Izumi Ojima and Kazuya Okamura", "title": "Large Deviation Strategy for Inverse Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph math-ph math.MP math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Taken traditionally as a no-go theorem against the theorization of inductive\nprocesses, Duhem-Quine thesis may interfere with the essence of statistical\ninference. This difficulty can be resolved by Micro-Macro duality \\cite{Oj03,\nOj05} which clarifies the importance of specifying the pertinent aspects and\naccuracy relevant to concrete contexts of scientific discussions and which\nensures the matching between what to be described and what to describe in the\nform of the validity of duality relations. This consolidates the foundations of\nthe inverse problem, induction method, and statistical inference crucial for\nthe sound relations between theory and experiments. To achieve the purpose, we\npropose here Large Deviation Strategy (LDS for short) on the basis of\nMicro-Macro duality, quadrality scheme, and large deviation principle.\nAccording to the quadrality scheme emphasizing the basic roles played by the\ndynamics, algebra of observables together with its representations and\nuniversal notion of classifying space, LDS consists of four levels and we\ndiscuss its first and second levels in detail, aiming at establishing\nstatistical inference concerning observables and states. By efficient use of\nthe central measure, we will establish a quantum version of Sanov's theorem,\nthe Bayesian escort predictive state and the widely applicable information\ncriteria for quantum states in LDS second level. Finally, these results are\nreexamined in the context of quantum estimation theory, and organized as\nquantum model selection, i.e., a quantum version of model selection.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jan 2011 14:03:40 GMT"}, {"version": "v2", "created": "Sat, 12 Feb 2011 04:45:31 GMT"}, {"version": "v3", "created": "Wed, 27 Jul 2011 10:48:05 GMT"}], "update_date": "2011-07-28", "authors_parsed": [["Ojima", "Izumi", ""], ["Okamura", "Kazuya", ""]]}, {"id": "1101.3709", "submitter": "Helene Gehrmann", "authors": "Helene Gehrmann, Steffen L. Lauritzen", "title": "Estimation of means in graphical Gaussian models with symmetries", "comments": "Published in at http://dx.doi.org/10.1214/12-AOS991 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2012, Vol. 40, No. 2, 1061-1073", "doi": "10.1214/12-AOS991", "report-no": "IMS-AOS-AOS991", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of estimability of means in undirected graphical\nGaussian models with symmetry restrictions represented by a colored graph.\nFollowing on from previous studies, we partition the variables into sets of\nvertices whose corresponding means are restricted to being identical. We find a\nnecessary and sufficient condition on the partition to ensure equality between\nthe maximum likelihood and least-squares estimators of the mean.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jan 2011 15:42:33 GMT"}, {"version": "v2", "created": "Fri, 7 Oct 2011 16:43:23 GMT"}, {"version": "v3", "created": "Mon, 23 Jul 2012 09:23:00 GMT"}], "update_date": "2012-07-24", "authors_parsed": [["Gehrmann", "Helene", ""], ["Lauritzen", "Steffen L.", ""]]}, {"id": "1101.3712", "submitter": "Alexander Sch\\\"onhuth", "authors": "Alexander Sch\\\"onhuth", "title": "Generic identification of binary-valued hidden Markov processes", "comments": "28 pages", "journal-ref": "Journal of Algebraic Statistics, 5(1), 72-99, 2014", "doi": null, "report-no": null, "categories": "math.ST math.AG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The generic identification problem is to decide whether a stochastic process\n$(X_t)$ is a hidden Markov process and if yes to infer its parameters for all\nbut a subset of parametrizations that form a lower-dimensional subvariety in\nparameter space. Partial answers so far available depend on extra assumptions\non the processes, which are usually centered around stationarity. Here we\npresent a general solution for binary-valued hidden Markov processes. Our\napproach is rooted in algebraic statistics hence it is geometric in nature. We\nfind that the algebraic varieties associated with the probability distributions\nof binary-valued hidden Markov processes are zero sets of determinantal\nequations which draws a connection to well-studied objects from algebra. As a\nconsequence, our solution allows for algorithmic implementation based on\nelementary (linear) algebraic routines.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jan 2011 15:57:58 GMT"}, {"version": "v2", "created": "Mon, 24 Jan 2011 16:27:38 GMT"}, {"version": "v3", "created": "Fri, 11 Feb 2011 14:03:15 GMT"}, {"version": "v4", "created": "Fri, 2 Sep 2011 12:58:30 GMT"}, {"version": "v5", "created": "Mon, 6 Feb 2012 11:40:00 GMT"}, {"version": "v6", "created": "Tue, 22 Oct 2013 15:20:17 GMT"}], "update_date": "2015-01-14", "authors_parsed": [["Sch\u00f6nhuth", "Alexander", ""]]}, {"id": "1101.3838", "submitter": "Alexander Jung", "authors": "Alexander Jung, Sebastian Schmutzhard, Franz Hlawatsch, Alfred O. Hero\n  III", "title": "Performance Bounds for Sparse Parametric Covariance Estimation in\n  Gaussian Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider estimation of a sparse parameter vector that determines the\ncovariance matrix of a Gaussian random vector via a sparse expansion into known\n\"basis matrices\". Using the theory of reproducing kernel Hilbert spaces, we\nderive lower bounds on the variance of estimators with a given mean function.\nThis includes unbiased estimation as a special case. We also present a\nnumerical comparison of our lower bounds with the variance of two standard\nestimators (hard-thresholding estimator and maximum likelihood estimator).\n", "versions": [{"version": "v1", "created": "Thu, 20 Jan 2011 08:22:20 GMT"}], "update_date": "2011-01-21", "authors_parsed": [["Jung", "Alexander", ""], ["Schmutzhard", "Sebastian", ""], ["Hlawatsch", "Franz", ""], ["Hero", "Alfred O.", "III"]]}, {"id": "1101.3902", "submitter": "Benedikt M. P\\\"otscher", "authors": "Benedikt M. P\\\"otscher", "title": "On the Order of Magnitude of Sums of Negative Powers of Integrated\n  Processes", "comments": null, "journal-ref": "Econometric Theory 29, 2013, 642-658", "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The asymptotic behavior of expressions of the form $%\n\\sum_{t=1}^{n}f(r_{n}x_{t})$ where $x_{t}$ is an integrated process, $r_{n}$ is\na sequence of norming constants, and $f$ is a measurable function has been the\nsubject of a number of articles in recent years. We mention Borodin and\nIbragimov (1995), Park and Phillips (1999), de Jong (2004), Jeganathan (2004),\nP\\\"{o}tscher (2004), de Jong and Whang (2005), Berkes and Horvath (2006), and\nChristopeit (2009) which study weak convergence results for such expressions\nunder various conditions on $x_{t}$ and the function $f$. Of course, these\nresults also provide information on the order of magnitude of $%\n\\sum_{t=1}^{n}f(r_{n}x_{t})$. However, to the best of our knowledge no result\nis available for the case where $f$ is non-integrable with respect to\nLebesgue-measure in a neighborhood of a given point, say $x=0$. In this paper\nwe are interested in bounds on the order of magnitude of $%\n\\sum_{t=1}^{n}|x_{t}| ^{-\\alpha}$ when $\\alpha \\geq 1$, a case where the\nimplied function $f$ is not integrable in any neighborhood of zero. More\ngenerally, we shall also obtain bounds on the order of magnitude for\n$\\sum_{t=1}^{n}v_{t}|x_{t}| ^{-\\alpha}$ where $v_{t}$ are random variables\nsatisfying certain conditions.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jan 2011 13:43:55 GMT"}, {"version": "v2", "created": "Tue, 20 Dec 2011 15:42:47 GMT"}, {"version": "v3", "created": "Wed, 11 Jul 2012 16:28:48 GMT"}], "update_date": "2014-12-03", "authors_parsed": [["P\u00f6tscher", "Benedikt M.", ""]]}, {"id": "1101.4038", "submitter": "Enrico Bibbona", "authors": "Enrico Bibbona, Alessandro Rubba", "title": "Boundary crossing Random Walks, clinical trials and multinomial\n  sequential estimation", "comments": null, "journal-ref": "Sequential Analysis, 31 (1) 2012, pp. 99-107", "doi": "10.1080/07474946.2012.652014", "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A sufficient condition for the uniqueness of multinomial sequential unbiased\nestimators is provided generalizing a classical result for binomial samples.\nUnbiased estimators are applied to infer the parameters of multidimensional or\nmultinomial Random Walks which are observed until they reach a boundary. An\napplication to clinical trials is presented.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jan 2011 22:10:19 GMT"}, {"version": "v2", "created": "Fri, 13 May 2011 11:38:35 GMT"}], "update_date": "2014-03-06", "authors_parsed": [["Bibbona", "Enrico", ""], ["Rubba", "Alessandro", ""]]}, {"id": "1101.4316", "submitter": "Pierre-Andre Zitt", "authors": "Herv\\'e Cardot (IMB), Peggy C\\'enac (IMB), Pierre-Andr\\'e Zitt (IMB)", "title": "Efficient and fast estimation of the geometric median in Hilbert spaces\n  with an averaged stochastic gradient algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the progress of measurement apparatus and the development of automatic\nsensors it is not unusual anymore to get thousands of samples of observations\ntaking values in high dimension spaces such as functional spaces. In such large\nsamples of high dimensional data, outlying curves may not be uncommon and even\na few individuals may corrupt simple statistical indicators such as the mean\ntrajectory. We focus here on the estimation of the geometric median which is a\ndirect generalization of the real median and has nice robustness properties.\nThe geometric median being defined as the minimizer of a simple convex\nfunctional that is differentiable everywhere when the distribution has no\natoms, it is possible to estimate it with online gradient algorithms. Such\nalgorithms are very fast and can deal with large samples. Furthermore they also\ncan be simply updated when the data arrive sequentially. We state the almost\nsure consistency and the L2 rates of convergence of the stochastic gradient\nestimator as well as the asymptotic normality of its averaged version. We get\nthat the asymptotic distribution of the averaged version of the algorithm is\nthe same as the classic estimators which are based on the minimization of the\nempirical loss function. The performances of our averaged sequential estimator,\nboth in terms of computation speed and accuracy of the estimations, are\nevaluated with a small simulation study. Our approach is also illustrated on a\nsample of more 5000 individual television audiences measured every second over\na period of 24 hours.\n", "versions": [{"version": "v1", "created": "Sat, 22 Jan 2011 20:01:58 GMT"}, {"version": "v2", "created": "Fri, 20 May 2011 09:15:30 GMT"}], "update_date": "2011-05-25", "authors_parsed": [["Cardot", "Herv\u00e9", "", "IMB"], ["C\u00e9nac", "Peggy", "", "IMB"], ["Zitt", "Pierre-Andr\u00e9", "", "IMB"]]}, {"id": "1101.4335", "submitter": "Ebrahim Al Safadi", "authors": "Ebrahim B. Al-Safadi and Tareq Y. Al-Naffouri", "title": "Peak Reduction and Clipping Mitigation by Compressive Sensing", "comments": "Submitted to IEEE Transactions on Signal Processing", "journal-ref": null, "doi": "10.1109/TSP.2012.2193396", "report-no": null, "categories": "cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work establishes the design, analysis, and fine-tuning of a\nPeak-to-Average-Power-Ratio (PAPR) reducing system, based on compressed sensing\nat the receiver of a peak-reducing sparse clipper applied to an OFDM signal at\nthe transmitter. By exploiting the sparsity of the OFDM signal in the time\ndomain relative to a pre-defined clipping threshold, the method depends on\npartially observing the frequency content of extremely simple sparse clippers\nto recover the locations, magnitudes, and phases of the clipped coefficients of\nthe peak-reduced signal. We claim that in the absence of optimization\nalgorithms at the transmitter that confine the frequency support of clippers to\na predefined set of reserved-tones, no other tone-reservation method can\nreliably recover the original OFDM signal with such low complexity.\n  Afterwards we focus on designing different clipping signals that can embed a\npriori information regarding the support and phase of the peak-reducing signal\nto the receiver, followed by modified compressive sensing techniques for\nenhanced recovery. This includes data-based weighted {\\ell} 1 minimization for\nenhanced support recovery and phase-augmention for homogeneous clippers\nfollowed by Bayesian techniques.\n  We show that using such techniques for a typical OFDM signal of 256\nsubcarriers and 20% reserved tones, the PAPR can be reduced by approximately\n4.5 dB with a significant increase in capacity compared to a system which uses\nall its tones for data transmission and clips to such levels. The design is\nhence appealing from both capacity and PAPR reduction aspects.\n", "versions": [{"version": "v1", "created": "Sat, 22 Jan 2011 23:50:01 GMT"}], "update_date": "2015-05-27", "authors_parsed": [["Al-Safadi", "Ebrahim B.", ""], ["Al-Naffouri", "Tareq Y.", ""]]}, {"id": "1101.4352", "submitter": "Michel Broniatowski", "authors": "Michel Broniatowski (LSTA), Giorgio Celant, Marco Di Battista, Samuela\n  Leoni-Aubin", "title": "Upper bounds for the error in some interpolation and extrapolation\n  designs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with probabilistic upper bounds for the error in functional\nestimation defined on some interpolation and extrapolation designs, when the\nfunction to estimate is supposed to be analytic. The error pertaining to the\nestimate may depend on various factors: the frequency of observations on the\nknots, the position and number of the knots, and also on the error committed\nwhen approximating the function through its Taylor expansion. When the number\nof observations is fixed, then all these parameters are determined by the\nchoice of the design and by the choice estimator of the unknown function. The\nscope of the paper is therefore to determine a rule for the minimal number of\nobservation required to achieve an upper bound of the error on the estimate\nwith a given maximal probability.\n", "versions": [{"version": "v1", "created": "Sun, 23 Jan 2011 09:23:25 GMT"}], "update_date": "2011-01-26", "authors_parsed": [["Broniatowski", "Michel", "", "LSTA"], ["Celant", "Giorgio", ""], ["Di Battista", "Marco", ""], ["Leoni-Aubin", "Samuela", ""]]}, {"id": "1101.4353", "submitter": "Michel Broniatowski", "authors": "Michel Broniatowski (LSTA), Samantha Leorato (SEFeMeQ)", "title": "An estimation method for the chi-square divergence with application to\n  test of hypotheses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new definition of the chi-square divergence between\ndistributions. Based on convexity properties and duality, this version of the\n{\\chi}^2 is well suited both for the classical applications of the {\\chi}^2 for\nthe analysis of contingency tables and for the statistical tests for parametric\nmodels, for which it has been advocated to be robust against inliers. We\npresent two applications in testing. In the first one we deal with tests for\nfinite and infinite numbers of linear constraints, while, in the second one, we\napply {\\chi}^2-methodology for parametric testing against contamination.\n", "versions": [{"version": "v1", "created": "Sun, 23 Jan 2011 09:23:50 GMT"}], "update_date": "2011-01-26", "authors_parsed": [["Broniatowski", "Michel", "", "LSTA"], ["Leorato", "Samantha", "", "SEFeMeQ"]]}, {"id": "1101.4607", "submitter": "Wicher Bergsma", "authors": "Wicher Bergsma", "title": "Nonparametric testing of conditional independence by means of the\n  partial copula", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new method to test conditional independence of two real random\nvariables $Y$ and $Z$ conditionally on an arbitrary third random variable $X$.\n%with $F_{.|.}$ representing conditional distribution functions, The partial\ncopula is introduced, defined as the joint distribution of $U=F_{Y|X}(Y|X)$ and\n$V=F_{Z|X}(Z|X)$. We call this transformation of $(Y,Z)$ into $(U,V)$ the\npartial copula transform. It is easy to show that if $Y$ and $Z$ are continuous\nfor any given value of $X$, then $Y\\ind Z|X$ implies $U\\ind V$. Conditional\nindependence can then be tested by (i) applying the partial copula transform to\nthe data points and (ii) applying a test of ordinary independence to the\ntransformed data. In practice, $F_{Y|X}$ and $F_{Z|X}$ will need to be\nestimated, which can be done by, e.g., standard kernel methods. We show that\nunder easily satisfied conditions, and for a very large class of test\nstatistics for independence which includes the covariance, Kendall's tau, and\nHoeffding's test statistic, the effect of this estimation vanishes\nasymptotically. Thus, for large samples, the estimation can be ignored and we\nhave a simple method which can be used to apply a wide range of tests of\nindependence, including ones with consistency for arbitrary alternatives, to\ntest for conditional independence. A simulation study indicates good small\nsample performance. Advantages of the partial copula approach compared to\ncompetitors seem to be simplicity and generality.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jan 2011 18:05:28 GMT"}], "update_date": "2011-01-25", "authors_parsed": [["Bergsma", "Wicher", ""]]}, {"id": "1101.4616", "submitter": "Wicher Bergsma", "authors": "Wicher Bergsma", "title": "A note on the distribution of the partial correlation coefficient with\n  nonparametrically estimated marginal regressions", "comments": "There is an error in the manuscript", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been much interest in the nonparametric testing of conditional\nindependence in the econometric and statistical literature, but the simplest\nand potentially most useful method, based on the sample partial correlation,\nseems to have been overlooked, its distribution only having been investigated\nin some simple parametric instances. The present note shows that an easy to\napply permutation test based on the sample partial correlation with\nnonparametrically estimated marginal regressions has good large and small\nsample properties.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jan 2011 18:27:13 GMT"}, {"version": "v2", "created": "Tue, 26 May 2020 10:46:02 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Bergsma", "Wicher", ""]]}, {"id": "1101.4657", "submitter": "Peter Orbanz", "authors": "Peter Orbanz", "title": "Projective Limit Random Probabilities on Polish Spaces", "comments": "20 pages, 3 figures. Published in the Electronic Journal of\n  Statistics by the Institute of Mathematical Statistics", "journal-ref": "Electronic Journal of Statistics 2011, Vol. 5, 1354-1373", "doi": "10.1214/11-EJS641", "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A pivotal problem in Bayesian nonparametrics is the construction of prior\ndistributions on the space M(V) of probability measures on a given domain V. In\nprinciple, such distributions on the infinite-dimensional space M(V) can be\nconstructed from their finite-dimensional marginals---the most prominent\nexample being the construction of the Dirichlet process from finite-dimensional\nDirichlet distributions. This approach is both intuitive and applicable to the\nconstruction of arbitrary distributions on M(V), but also hamstrung by a number\nof technical difficulties. We show how these difficulties can be resolved if\nthe domain V is a Polish topological space, and give a representation theorem\ndirectly applicable to the construction of any probability distribution on M(V)\nwhose first moment measure is well-defined. The proof draws on a projective\nlimit theorem of Bochner, and on properties of set functions on Polish spaces\nto establish countable additivity of the resulting random probabilities.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jan 2011 21:03:11 GMT"}, {"version": "v2", "created": "Mon, 4 Apr 2011 18:26:39 GMT"}, {"version": "v3", "created": "Wed, 19 Oct 2011 11:00:46 GMT"}], "update_date": "2011-10-20", "authors_parsed": [["Orbanz", "Peter", ""]]}, {"id": "1101.4659", "submitter": "Prof. A. Plastino", "authors": "S. P. Flego, A. Plastino, and A. R. Plastino", "title": "Inferring an optimal Fisher measure", "comments": null, "journal-ref": null, "doi": "10.1016/j.physa.2011.06.050", "report-no": null, "categories": "math.ST quant-ph stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well known that a suggestive relation exists that links Schr\\\"odinger's\nequation (SE) to the information-optimizing principle based on Fisher's\ninformation measure (FIM). We explore here an approach that will allow one to\ninfer the optimal FIM compatible with a given amount of prior information\nwithout explicitly solving first the associated SE. This technique is based on\nthe virial theorem and it provides analytic solutions for the physically\nrelevant FIM, that which is minimal subject to the constraints posed by the\nprior information.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jan 2011 21:04:10 GMT"}, {"version": "v2", "created": "Wed, 4 May 2011 20:19:13 GMT"}], "update_date": "2015-05-27", "authors_parsed": [["Flego", "S. P.", ""], ["Plastino", "A.", ""], ["Plastino", "A. R.", ""]]}, {"id": "1101.4873", "submitter": "George Yanev", "authors": "George P. Yanev", "title": "Characterization of exponential distribution via regression of one\n  record value on two non-adjacent record values", "comments": "To appear in Metrika", "journal-ref": null, "doi": "10.1007/s00184-011-0350-z", "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We characterize the exponential distribution as the only one which satisfies\na regression condition. This condition involves the regression function of a\nfixed record value given two other record values, one of them being previous\nand the other next to the fixed record value, and none of them are adjacent. In\nparticular, it turns out that the underlying distribution is exponential if and\nonly if given the first and last record values, the expected value of the\nmedian in a sample of record values equals the sample midrange.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jan 2011 17:07:35 GMT"}], "update_date": "2011-05-06", "authors_parsed": [["Yanev", "George P.", ""]]}, {"id": "1101.4903", "submitter": "Yaming Yu", "authors": "Yaming Yu", "title": "Prior Ordering and Monotonicity in Dirichlet Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of two independent stochastic processes (arms) are to be selected at each\nof n stages. The selection is sequential and depends on past observations as\nwell as the prior information. Observations from arm i are independent given a\ndistribution P_i, and, following Clayton and Berry (1985), P_i's have\nindependent Dirichlet process priors. The objective is to maximize the expected\nfuture-discounted sum of the n observations. We study structural properties of\nthe bandit, in particular how the maximum expected payoff and the optimal\nstrategy vary with the Dirichlet process priors. The main results are (i) for a\nparticular arm and a fixed prior weight, the maximum expected payoff increases\nas the mean of the Dirichlet process prior becomes larger in the increasing\nconvex order; (ii) for a fixed prior mean, the maximum expected payoff\ndecreases as the prior weight increases. Specializing to the one-armed bandit,\nthe second result captures the intuition that, given the same immediate payoff,\nthe more is known about an arm, the less desirable it becomes because there is\nless to learn when selecting that arm. This extends some results of Gittins and\nWang (1992) on Bernoulli bandits and settles a conjecture of Clayton and Berry\n(1985).\n", "versions": [{"version": "v1", "created": "Tue, 25 Jan 2011 19:27:49 GMT"}], "update_date": "2011-01-26", "authors_parsed": [["Yu", "Yaming", ""]]}, {"id": "1101.5011", "submitter": "Matthew Parry", "authors": "Matthew Parry, A. Philip Dawid, Steffen Lauritzen", "title": "Proper local scoring rules", "comments": "Published in at http://dx.doi.org/10.1214/12-AOS971 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2012, Vol. 40, No. 1, 561-592", "doi": "10.1214/12-AOS971", "report-no": "IMS-AOS-AOS971", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate proper scoring rules for continuous distributions on the real\nline. It is known that the log score is the only such rule that depends on the\nquoted density only through its value at the outcome that materializes. Here we\nallow further dependence on a finite number $m$ of derivatives of the density\nat the outcome, and describe a large class of such $m$-local proper scoring\nrules: these exist for all even $m$ but no odd $m$. We further show that for\n$m\\geq2$ all such $m$-local rules can be computed without knowledge of the\nnormalizing constant of the distribution.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jan 2011 09:14:15 GMT"}, {"version": "v2", "created": "Tue, 17 Jan 2012 23:41:05 GMT"}, {"version": "v3", "created": "Tue, 24 Jan 2012 13:49:28 GMT"}, {"version": "v4", "created": "Thu, 31 May 2012 05:30:52 GMT"}], "update_date": "2015-03-18", "authors_parsed": [["Parry", "Matthew", ""], ["Dawid", "A. Philip", ""], ["Lauritzen", "Steffen", ""]]}, {"id": "1101.5195", "submitter": "Yizao Wang", "authors": "Yizao Wang and Michael Woodroofe", "title": "A New Condition for the Invariance Principle for Stationary Random\n  Fields", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We establish a central limit theorem and an invariance principle for\nstationary random fields, with projective-type conditions. Our result is\nobtained via an m-dependent approximation method. As applications, we establish\ninvariance principles for orthomartingales and functionals of linear random\nfields.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jan 2011 02:04:51 GMT"}, {"version": "v2", "created": "Wed, 11 Apr 2012 01:56:28 GMT"}], "update_date": "2012-04-12", "authors_parsed": [["Wang", "Yizao", ""], ["Woodroofe", "Michael", ""]]}, {"id": "1101.5248", "submitter": "Markus Rei{\\ss}", "authors": "Alexander Meister and Markus Rei{\\ss}", "title": "Asymptotic Equivalence for Nonparametric Regression with Non-Regular\n  Errors", "comments": "2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Asymptotic equivalence in Le Cam's sense for nonparametric regression\nexperiments is extended to the case of non-regular error densities, which have\njump discontinuities at their endpoints. We prove asymptotic equivalence of\nsuch regression models and the observation of two independent Poisson point\nprocesses which contain the target curve as the support boundary of its\nintensity function. The intensity of the point processes is of order of the\nsample size $n$ and involves the jump sizes as well as the design density. The\nstatistical model significantly differs from regression problems with Gaussian\nor regular errors, which are known to be asymptotically equivalent to Gaussian\nwhite noise models.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jan 2011 10:21:11 GMT"}], "update_date": "2011-01-28", "authors_parsed": [["Meister", "Alexander", ""], ["Rei\u00df", "Markus", ""]]}, {"id": "1101.5461", "submitter": "Paul Kabaila", "authors": "Paul Kabaila and Matthew Vicendese", "title": "The performance of a two-stage analysis of ABAB/BABA crossover trials", "comments": "The exposition has been improved", "journal-ref": "The performance of a two-stage analysis of ABAB/BABA crossover\n  trials. Biometrical Journal, 54, 361-369 (2012)", "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Freeman has considered the following two-stage procedure for finding a\nconfidence interval for the treatment difference theta, using data from an\nAB/BA crossover trial. In the first stage, a preliminary test of the null\nhypothesis that the differential carryover is zero, is carried out. If this\nhypothesis is accepted then the confidence interval for theta is constructed\nassuming that the differential carryover is zero. If, on the other hand, this\nhypothesis is rejected then this confidence interval is constructed using only\ndata from the first period. Freeman has shown that this confidence interval has\nminimum coverage probability far below nominal. He therefore concludes that\nthis confidence interval should not be used. In the present paper, we analyse\nthe performance of a similar two-stage procedure for an ABAB/BABA crossover\ntrial. This trial differs in very significant ways from an AB/BA crossover\ntrial, including the fact that for an ABAB/BABA crossover trial there is an\nunbiased estimator of the differential carryover that is unaffected by\nbetween-subject variation. Despite these great differences, we arrive at the\nsame conclusion as Freeman. Namely, that the confidence interval resulting from\nthe two-stage procedure should not be used.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jan 2011 06:18:17 GMT"}, {"version": "v2", "created": "Mon, 26 Sep 2011 06:43:37 GMT"}], "update_date": "2017-10-18", "authors_parsed": [["Kabaila", "Paul", ""], ["Vicendese", "Matthew", ""]]}, {"id": "1101.5783", "submitter": "Richard J. Samworth", "authors": "Richard J. Samworth", "title": "Optimal weighted nearest neighbour classifiers", "comments": "Published in at http://dx.doi.org/10.1214/12-AOS1049 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2012, Vol. 40, No. 5, 2733-2763", "doi": "10.1214/12-AOS1049", "report-no": "IMS-AOS-AOS1049", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive an asymptotic expansion for the excess risk (regret) of a weighted\nnearest-neighbour classifier. This allows us to find the asymptotically optimal\nvector of nonnegative weights, which has a rather simple form. We show that the\nratio of the regret of this classifier to that of an unweighted k-nearest\nneighbour classifier depends asymptotically only on the dimension d of the\nfeature vectors, and not on the underlying populations. The improvement is\ngreatest when d=4, but thereafter decreases as $d\\rightarrow\\infty$. The\npopular bagged nearest neighbour classifier can also be regarded as a weighted\nnearest neighbour classifier, and we show that its corresponding weights are\nsomewhat suboptimal when d is small (in particular, worse than those of the\nunweighted k-nearest neighbour classifier when d=1), but are close to optimal\nwhen d is large. Finally, we argue that improvements in the rate of convergence\nare possible under stronger smoothness assumptions, provided we allow negative\nweights. Our findings are supported by an empirical performance comparison on\nboth simulated and real data sets.\n", "versions": [{"version": "v1", "created": "Sun, 30 Jan 2011 16:49:41 GMT"}, {"version": "v2", "created": "Tue, 15 Nov 2011 17:19:19 GMT"}, {"version": "v3", "created": "Mon, 18 Feb 2013 13:04:25 GMT"}], "update_date": "2013-02-19", "authors_parsed": [["Samworth", "Richard J.", ""]]}, {"id": "1101.5790", "submitter": "Ivan Nourdin", "authors": "Khalifa Es-Sebaiy (IMB), Ivan Nourdin (IECN)", "title": "Parameter estimation for alpha-fractional bridges", "comments": "21 pages. To appear in the Festschrift in Honor of David Nualart, a\n  volume to be published by Springer in the Proceedings in Mathematics Series", "journal-ref": null, "doi": null, "report-no": "Pr\\'epublication IECN 2011/6", "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let alpha,T>0. We study the asymptotic properties of a least squares\nestimator for the parameter alpha of a fractional bridge defined as\ndX_t=-alpha*X_t/(T-t)dt+dB_t, with t in [0,T) and where B is a fractional\nBrownian motion of Hurst index H>1/2. Depending on the value of alpha, we prove\nthat we may have strong consistency or not as t tends to T. When we have\nconsistency, we obtain the rate of this convergence as well. Also, we compare\nour results to the (known) case where B is replaced by a standard Brownian\nmotion W.\n", "versions": [{"version": "v1", "created": "Sun, 30 Jan 2011 17:46:22 GMT"}, {"version": "v2", "created": "Fri, 16 Sep 2011 07:00:37 GMT"}, {"version": "v3", "created": "Sat, 3 Aug 2013 09:48:55 GMT"}], "update_date": "2013-08-06", "authors_parsed": [["Es-Sebaiy", "Khalifa", "", "IMB"], ["Nourdin", "Ivan", "", "IECN"]]}, {"id": "1101.5960", "submitter": "Kengne William Charky", "authors": "Kengne William Charky", "title": "Testing for parameter constancy in general causal time series models", "comments": "18 pages ; two figures ; Submitted to the JTSA", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a process $ X= (X_t)_{t\\in \\Z}$ belonging to a large class of\ncausal models including AR($\\infty$), ARCH($\\infty$), TARCH($\\infty$),...\nmodels.\n  We assume that the model depends on a parameter $\\theta_0 \\in \\R^d$ and\nconsider the problem of testing for change in the parameter. Two statistics\n$\\hat{Q}^{(1)}_n$ and $ \\hat{Q}^{(2)}_n$ are constructed using quasi-likelihood\nestimator (QLME) of the parameter. Under the null hypothesis that there is no\nchange, it is shown that each of these two statistics weakly converges to the\nsupremum of the sum of the squares of independent Brownian bridges.\n  Under the local alternative that there is one change, we show that the test\nstatistic $\\hat{Q}_n=\\text{max} \\big(\\hat{Q}^{(1)}_n, \\hat{Q}^{(2)}_n \\big) $\ndiverges to infinity.\n  Some simulation results for AR(1), ARCH(1) and GARCH(1,1) models are reported\nto show the applicability and the performance of our procedure with comparisons\nto some other approaches.\n", "versions": [{"version": "v1", "created": "Mon, 31 Jan 2011 13:33:14 GMT"}, {"version": "v2", "created": "Sat, 2 Jul 2011 08:50:02 GMT"}], "update_date": "2011-07-05", "authors_parsed": [["Charky", "Kengne William", ""]]}, {"id": "1101.5978", "submitter": "Prof. A. Plastino", "authors": "S. Abdel-Khalek, A. Plastino, A-S F. Obada", "title": "Dynamics of the intensity-dependent Jaynes-Cummings model analyzed via\n  Fisher information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The dynamics of the Buck and Sukumar model [B. Buck and C.V. Sukumar, Phys.\nLett. A 81 (1981) 132] are investigated using different semi-classical\ninformation-theory tools. Interesting aspects of the periodicity inherent to\nthe model are revealed and somewhat unexpected features are revealed that seem\nto be related to the classical-quantum transition.\n", "versions": [{"version": "v1", "created": "Mon, 31 Jan 2011 14:25:50 GMT"}], "update_date": "2015-03-18", "authors_parsed": [["Abdel-Khalek", "S.", ""], ["Plastino", "A.", ""], ["Obada", "A-S F.", ""]]}, {"id": "1101.6037", "submitter": "Christian Schafer", "authors": "Christian Sch\\\"afer (CREST, CEREMADE), Nicolas Chopin (CREST, ENSAE)", "title": "Sequential Monte Carlo on large binary sampling spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.CO stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Monte Carlo algorithm is said to be adaptive if it automatically calibrates\nits current proposal distribution using past simulations. The choice of the\nparametric family that defines the set of proposal distributions is critical\nfor good performance. In this paper, we present such a parametric family for\nadaptive sampling on high-dimensional binary spaces. A practical motivation for\nthis problem is variable selection in a linear regression context. We want to\nsample from a Bayesian posterior distribution on the model space using an\nappropriate version of Sequential Monte Carlo. Raw versions of Sequential Monte\nCarlo are easily implemented using binary vectors with independent components.\nFor high-dimensional problems, however, these simple proposals do not yield\nsatisfactory results. The key to an efficient adaptive algorithm are binary\nparametric families which take correlations into account, analogously to the\nmultivariate normal distribution on continuous spaces. We provide a review of\nmodels for binary data and make one of them work in the context of Sequential\nMonte Carlo sampling. Computational studies on real life data with about a\nhundred covariates suggest that, on difficult instances, our Sequential Monte\nCarlo approach clearly outperforms standard techniques based on Markov chain\nexploration.\n", "versions": [{"version": "v1", "created": "Mon, 31 Jan 2011 17:47:32 GMT"}, {"version": "v2", "created": "Thu, 3 Feb 2011 16:47:02 GMT"}, {"version": "v3", "created": "Wed, 2 Nov 2011 17:23:41 GMT"}, {"version": "v4", "created": "Wed, 9 Nov 2011 09:04:40 GMT"}], "update_date": "2011-11-11", "authors_parsed": [["Sch\u00e4fer", "Christian", "", "CREST, CEREMADE"], ["Chopin", "Nicolas", "", "CREST, ENSAE"]]}]