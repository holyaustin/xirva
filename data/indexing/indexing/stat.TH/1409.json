[{"id": "1409.0055", "submitter": "Carlos Martins-Filho", "authors": "Carlos Martins-Filho and Paulo Saraiva", "title": "On Asymptotic Normality of the Local Polynomial Regression Estimator\n  with Stochastic Bandwidths", "comments": "18 pages, 2 figures", "journal-ref": "Communications in Statistics - Theory and Methods, volume 41,\n  issue 6, pages 1052-1068, 2012", "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonparametric density and regression estimators commonly depend on a\nbandwidth. The asymptotic properties of these estimators have been widely\nstudied when bandwidths are nonstochastic. In practice, however, in order to\nimprove finite sample performance of these estimators, bandwidths are selected\nby data driven methods, such as cross-validation or plug-in procedures. As a\nresult nonparametric estimators are usually constructed using stochastic\nbandwidths. In this paper we establish the asymptotic equivalence in\nprobability of local polynomial regression estimators under stochastic and\nnonstochastic bandwidths. Our result extends previous work by Boente and\nFraiman (1995) and Ziegler (2004).\n", "versions": [{"version": "v1", "created": "Fri, 29 Aug 2014 23:07:26 GMT"}], "update_date": "2014-09-02", "authors_parsed": [["Martins-Filho", "Carlos", ""], ["Saraiva", "Paulo", ""]]}, {"id": "1409.0292", "submitter": "Hiroki Masuda", "authors": "Hiroki Masuda", "title": "Parametric estimation of L\\'evy processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main purpose of this chapter is to present some theoretical aspects of\nparametric estimation of L\\'evy processes based on high-frequency sampling,\nwith a focus on infinite activity pure-jump models. Asymptotics for several\nclasses of explicit estimating functions are discussed. In addition to the\nasymptotic normality at several rates of convergence, a uniform\ntail-probability estimate for statistical random fields is given. As specific\ncases, we discuss method of moments for the stable L\\'evy processes in much\ngreater detail, with briefly mentioning locally stable L\\'evy processes too.\nAlso discussed is, due to its theoretical importance, a brief review of how the\nclassical likelihood approach works or does not, beyond the fact that the\nlikelihood function is not explicit.\n", "versions": [{"version": "v1", "created": "Mon, 1 Sep 2014 05:20:51 GMT"}], "update_date": "2014-09-02", "authors_parsed": [["Masuda", "Hiroki", ""]]}, {"id": "1409.0727", "submitter": "Rui Song", "authors": "Rui Song, Moulinath Banerjee, Michael R. Kosorok", "title": "Asymptotics for change-point models under varying degrees of\n  mis-specification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Change-point models are widely used by statisticians to model drastic changes\nin the pattern of observed data. Least squares/maximum likelihood based\nestimation of change-points leads to curious asymptotic phenomena. When the\nchange-point model is correctly specified, such estimates generally converge at\na fast rate ($n$) and are asymptotically described by minimizers of jump\nprocess. Under complete mis-specification by a smooth curve, i.e. when a\nchange-point model is fitted to data described by a smooth curve, the rate of\nconvergence slows down to $n^{1/3}$ and the limit distribution changes to that\nof the minimizer of a continuous Gaussian process. In this paper we provide a\nbridge between these two extreme scenarios by studying the limit behavior of\nchange-point estimates under varying degrees of model mis-specification by\nsmooth curves, which can be viewed as local alternatives. We find that the\nlimiting regime depends on how quickly the alternatives approach a change-point\nmodel. We unravel a family of `intermediate' limits that can transition, at\nleast qualitatively, to the limits in the two extreme scenarios.\n", "versions": [{"version": "v1", "created": "Tue, 2 Sep 2014 14:33:12 GMT"}, {"version": "v2", "created": "Sun, 18 Oct 2015 23:39:02 GMT"}], "update_date": "2015-10-20", "authors_parsed": [["Song", "Rui", ""], ["Banerjee", "Moulinath", ""], ["Kosorok", "Michael R.", ""]]}, {"id": "1409.0733", "submitter": "Bernard Delyon", "authors": "Bernard Delyon, Fran\\c{c}ois Portier", "title": "Integral approximation by kernel smoothing", "comments": "Published at http://dx.doi.org/10.3150/15-BEJ725 in the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm). arXiv admin\n  note: text overlap with arXiv:1312.4497", "journal-ref": "Bernoulli 2016, Vol. 22, No. 4, 2177-2208", "doi": "10.3150/15-BEJ725", "report-no": "IMS-BEJ-BEJ725", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $(X_1,\\ldots,X_n)$ be an i.i.d. sequence of random variables in\n$\\mathbb{R}^d$, $d\\geq 1$. We show that, for any function $\\varphi\n:\\mathbb{R}^d\\rightarrow\\mathbb{R}$, under regularity conditions, \\[n^\n{1/2}\\Biggl(n^{-1}\\sum_{i=1}^n\\frac{\\varphi(X_i)}{\\widehat{f}^(X_i)}- \\int\n\\varphi(x)\\,dx\\Biggr)\\stackrel{\\mathbb{P}}{\\longrightarrow}0,\\] where\n$\\widehat{f}$ is the classical kernel estimator of the density of $X_1$. This\nresult is striking because it speeds up traditional rates, in root $n$, derived\nfrom the central limit theorem when $\\widehat{f}=f$. Although this paper\nhighlights some applications, we mainly address theoretical issues related to\nthe later result. We derive upper bounds for the rate of convergence in\nprobability. These bounds depend on the regularity of the functions $\\varphi$\nand $f$, the dimension $d$ and the bandwidth of the kernel estimator\n$\\widehat{f}$. Moreover, they are shown to be accurate since they are used as\nrenormalizing sequences in two central limit theorems each reflecting different\ndegrees of smoothness of $\\varphi$. As an application to regression modelling\nwith random design, we provide the asymptotic normality of the estimation of\nthe linear functionals of a regression function. As a consequence of the above\nresult, the asymptotic variance does not depend on the regression function.\nFinally, we debate the choice of the bandwidth for integral approximation and\nwe highlight the good behavior of our procedure through simulations.\n", "versions": [{"version": "v1", "created": "Tue, 2 Sep 2014 14:47:03 GMT"}, {"version": "v2", "created": "Mon, 6 Jun 2016 07:17:14 GMT"}], "update_date": "2016-06-07", "authors_parsed": [["Delyon", "Bernard", ""], ["Portier", "Fran\u00e7ois", ""]]}, {"id": "1409.0752", "submitter": "Fran\\c{c}ois Portier", "authors": "Fran\\c{c}ois Portier", "title": "Continuous inverse regression", "comments": "22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide new theoretical results in the field of inverse regression methods\nfor dimension reduction. Our approach is based on the study of some empirical\nprocesses that lie close to a certain dimension reduction subspace, called the\ncentral subspace. The study of these processes essentially includes weak\nconvergence results and the consistency of some general bootstrap procedures.\nWhile such properties are used to obtain new results about sliced inverse\nregression, they mainly allow to define a natural family of methods for\ndimension reduction. First the estimation methods are shown to have root $n$\nrates and the bootstrap is proved to be valid. Second, we describe a family of\nCram\\'er-von Mises test statistics that can be used in testing structural\nproperties of the central subspace or the significancy of some sets of\npredictors. We show that the quantiles of those tests could be computed by\nbootstrap. Most of the existing methods related to inverse regression involve a\nslicing of the response that is difficult to select in practice. While our\napproach guarantee a comprehensive estimation, the slicing is no longer needed.\n", "versions": [{"version": "v1", "created": "Tue, 2 Sep 2014 15:22:22 GMT"}, {"version": "v2", "created": "Mon, 1 Jun 2015 12:22:14 GMT"}], "update_date": "2015-06-02", "authors_parsed": [["Portier", "Fran\u00e7ois", ""]]}, {"id": "1409.0912", "submitter": "Milan Stehlik", "authors": "Milan Stehlik and Philipp Hermann", "title": "Letter to the Editor of Annals of Applied Statistics", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is \"Letter to the Editor\" of Annals of Applied Statistics, addressing\nthe paper by Goerg G. M. (2011) \"Lambert W random variables-a new family of\ngeneralized skewed distributions with applications to risk estimation\".\n", "versions": [{"version": "v1", "created": "Tue, 2 Sep 2014 22:53:36 GMT"}, {"version": "v2", "created": "Sat, 27 Jun 2015 15:09:33 GMT"}], "update_date": "2015-06-30", "authors_parsed": [["Stehlik", "Milan", ""], ["Hermann", "Philipp", ""]]}, {"id": "1409.1012", "submitter": "Chang-Yun Lin", "authors": "Po Yang and Chang-Yun Lin", "title": "Minimum Contamination and $\\beta$-Aberration Criteria for Screening\n  Quantitative Factors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tang and Xu [Biometrika 101 (2014) 333-350] applied the minimum\n$\\beta$-aberration criterion to selecting optimal designs for screening\nquantitative factors. They provided a statistical justification showing that\nminimum $\\beta$-aberration criterion minimizes contamination of nonnegligible\n$k$th-order effects on the estimation of linear effects for $k=2,\\cdots,r$,\nwhere $r$ is the strength of a design. Unfortunately, this result does not hold\nfor $k>r$. In this paper, we provide a complete mathematical connection between\n$\\beta$-wordlength patterns and contaminations (on the estimation of linear\neffects) and reveal that the minimum $\\beta$-aberration criterion is not\nnecessarily equivalent to the minimum contamination criterion for ranking\ndesigns. We prove that they are equivalent only when the number of factors of a\ndesign equals the strength plus one. We emphasize that the minimum\n$\\beta$-aberration criterion, in fact, sequentially minimizes the contamination\nof nonnegligible $k$th-order effects on the estimation of the general mean, not\non the estimation of linear effects. Therefore, the minimum contamination\ncriterion should be more appropriate than the minimum $\\beta$-aberration\ncriterion for selecting optimal designs for screening quantitative factors.\n", "versions": [{"version": "v1", "created": "Wed, 3 Sep 2014 09:55:07 GMT"}], "update_date": "2014-09-04", "authors_parsed": [["Yang", "Po", ""], ["Lin", "Chang-Yun", ""]]}, {"id": "1409.1025", "submitter": "Gaby Schneider Gaby Schneider", "authors": "Michael Messer and Gaby Schneider", "title": "The Shark Fin Function - Asymptotic Behavior of the Filtered Derivative\n  for Point Processes in Case of Change Points", "comments": "Manuscript revised", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A multiple filter test (MFT) for the analysis and detection of rate change\npoints in point processes on the line has been proposed recently. The\nunderlying statistical test investigates the null hypothesis of constant rate.\nFor that purpose, multiple filtered derivative processes are observed\nsimultaneously. Under the null hypothesis, each process $G$ asymptotically\ntakes the form \\begin{align*} G \\sim L, \\end{align*} while $L$ is a zero-mean\nGaussian process with unit variance. This result is used to derive a rejection\nthreshold for statistical hypothesis testing.\n  The purpose of this paper is to describe the behavior of $G$ under the\nalternative hypothesis of rate changes and potential simultaneous variance\nchanges. We derive the approximation \\begin{align*} G \\sim \\Delta\n\\cdot\\left(\\Lambda + L\\right), \\end{align*} with deterministic functions\n$\\Delta$ and $\\Lambda$. The function $\\Lambda$ accounts for the systematic\ndeviation of $G$ in the neighborhood of a change point. When only the rate\nchanges, $\\Lambda$ is hat shaped. When also the variance changes, $\\Lambda$\ntakes the form of a shark's fin. In addition, the parameter estimates required\nin practical application are not consistent in the neighborhood of a change\npoint. Therefore, we derive the factor $\\Delta$ termed here the distortion\nfunction. It accounts for the lack in consistency and describes the local\nparameter estimating process relative to the true scaling of the filtered\nderivative process.\n", "versions": [{"version": "v1", "created": "Wed, 3 Sep 2014 10:30:10 GMT"}, {"version": "v2", "created": "Tue, 22 Dec 2015 19:51:09 GMT"}, {"version": "v3", "created": "Tue, 17 May 2016 12:34:21 GMT"}], "update_date": "2016-05-18", "authors_parsed": [["Messer", "Michael", ""], ["Schneider", "Gaby", ""]]}, {"id": "1409.1331", "submitter": "Emilie Devijver", "authors": "Emilie Devijver (LM-Orsay)", "title": "Finite mixture regression: A sparse variable selection by model\n  selection for clustering", "comments": "20 pages. arXiv admin note: text overlap with arXiv:1103.2021 by\n  other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a finite mixture of Gaussian regression model for high-\ndimensional data, where the number of covariates may be much larger than the\nsample size. We propose to estimate the unknown conditional mixture density by\na maximum likelihood estimator, restricted on relevant variables selected by an\n1-penalized maximum likelihood estimator. We get an oracle inequality satisfied\nby this estimator with a Jensen-Kullback-Leibler type loss. Our oracle\ninequality is deduced from a general model selection theorem for maximum\nlikelihood estimators with a random model collection. We can derive the penalty\nshape of the criterion, which depends on the complexity of the random model\ncollection.\n", "versions": [{"version": "v1", "created": "Thu, 4 Sep 2014 06:19:27 GMT"}], "update_date": "2014-09-05", "authors_parsed": [["Devijver", "Emilie", "", "LM-Orsay"]]}, {"id": "1409.1333", "submitter": "Emilie Devijver", "authors": "Emilie Devijver (LM-Orsay)", "title": "Model-based regression clustering for high-dimensional data. Application\n  to functional data", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finite mixture regression models are useful for modeling the relationship\nbetween response and predictors, arising from different subpopulations. In this\narticle, we study high-dimensional predic- tors and high-dimensional response,\nand propose two procedures to deal with this issue. We propose to use the Lasso\nestimator to take into account the sparsity, and a penalty on the rank, to take\ninto account the matrix structure. Then, we extend these procedures to the\nfunctional case, where predictors and responses are functions. For this\npurpose, we use a wavelet-based approach. Finally, for each situation, we\nprovide algorithms, and apply and evaluate our methods both on simulations and\nreal datasets.\n", "versions": [{"version": "v1", "created": "Thu, 4 Sep 2014 06:21:33 GMT"}, {"version": "v2", "created": "Wed, 6 Jan 2016 11:35:05 GMT"}], "update_date": "2016-01-07", "authors_parsed": [["Devijver", "Emilie", "", "LM-Orsay"]]}, {"id": "1409.1386", "submitter": "Sebastian Schweer", "authors": "Sebastian Schweer and Cornelia Wichelhaus", "title": "Nonparametric Estimation of the Service Time Distribution in the\n  Discrete-Time $GI/G/\\infty$ Queue with Partial Information", "comments": "Accepted for publication in: Stochastic Processes and their\n  Applications", "journal-ref": null, "doi": "10.1016/j.spa.2014.09.003", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimation of the service time distribution in the discrete-time\n$GI/G/\\infty$-queue based solely on information on the arrival and departure\nprocesses is considered. The focus is put on the estimation approach via the so\ncalled \"sequence of differences\". Existing results for this approach are\nsubstantially extended by proving a functional central limit theorem for the\nresultant estimator. Here, the underlying function space is taken to be the\nspace of sequences converging to zero. The moving block bootstrap technique is\nconsidered for the estimation of the resultant covariance kernel and is shown\nto be applicable under mild additional conditions.\n", "versions": [{"version": "v1", "created": "Thu, 4 Sep 2014 09:57:28 GMT"}], "update_date": "2014-09-19", "authors_parsed": [["Schweer", "Sebastian", ""], ["Wichelhaus", "Cornelia", ""]]}, {"id": "1409.1388", "submitter": "Mohammad Arashi", "authors": "A. Bekker and M. Arashi", "title": "Kernel Oriented Generator Distribution", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matrix variate beta (MVB) distributions are used in different fields of\nhypothesis testing, multivariate correlation analysis, zero regression,\ncanonical correlation analysis and etc. In this approach a unified methodology\nis proposed to generate matrix variate distributions by combining the kernel of\nMVB distributions of different types with an unknown Borel measurable function\nof trace operator over matrix space, called generator component. The latter\ncomponent is a principal element of these newly defined generator type matrix\nvariate distributions. The matrix variate Kummer beta distribution is amongst\nothers a special case. Several statistical properties of this newly defined\nfamily of distributions are derived. In the conclusion other extensions and\ndevelopments are discussed.\n", "versions": [{"version": "v1", "created": "Thu, 4 Sep 2014 10:08:43 GMT"}], "update_date": "2014-09-05", "authors_parsed": [["Bekker", "A.", ""], ["Arashi", "M.", ""]]}, {"id": "1409.1419", "submitter": "David Preinerstorfer", "authors": "David Preinerstorfer", "title": "Finite Sample Properties of Tests Based on Prewhitened Nonparametric\n  Covariance Estimators", "comments": "Some material added", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analytically investigate size and power properties of a popular family of\nprocedures for testing linear restrictions on the coefficient vector in a\nlinear regression model with temporally dependent errors. The tests considered\nare autocorrelation-corrected F-type tests based on prewhitened nonparametric\ncovariance estimators that possibly incorporate a data-dependent bandwidth\nparameter, e.g., estimators as considered in Andrews and Monahan (1992), Newey\nand West (1994), or Rho and Shao (2013). For design matrices that are generic\nin a measure theoretic sense we prove that these tests either suffer from\nextreme size distortions or from strong power deficiencies. Despite this\nnegative result we demonstrate that a simple adjustment procedure based on\nartificial regressors can often resolve this problem.\n", "versions": [{"version": "v1", "created": "Thu, 4 Sep 2014 12:12:58 GMT"}, {"version": "v2", "created": "Sat, 9 May 2015 12:52:39 GMT"}], "update_date": "2015-05-12", "authors_parsed": [["Preinerstorfer", "David", ""]]}, {"id": "1409.1429", "submitter": "Rania Zgheib", "authors": "Cristina Butucea, Rania Zgheib", "title": "Sharp minimax tests for large covariance matrices and adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the detection problem of correlations in a $p$-dimensional\nGaussian vector, when we observe $n$ independent, identically distributed\nrandom vectors, for $n$ and $p$ large. We assume that the covariance matrix\nvaries in some ellipsoid with parameter $\\alpha >1/2$ and total energy bounded\nby $L>0$. We propose a test procedure based on a U-statistic of order 2 which\nis weighted in an optimal way. The weights are the solution of an optimization\nproblem, they are constant on each diagonal and non-null only for the $T$ first\ndiagonals, where $T=o(p)$. We show that this test statistic is asymptotically\nGaussian distributed under the null hypothesis and also under the alternative\nhypothesis for matrices close to the detection boundary. We prove upper bounds\nfor the total error probability of our test procedure, for $\\alpha>1/2$ and\nunder the assumption $T=o(p)$ which implies that $n=o(p^{ 2 \\alpha})$. We\nillustrate via a numerical study the behavior of our test procedure. Moreover,\nwe prove lower bounds for the maximal type II error and the total error\nprobabilities. Thus we obtain the asymptotic and the sharp asymptotically\nminimax separation rate $\\tilde{\\varphi} = (C(\\alpha, L) n^2 p )^{- \\alpha/(4\n\\alpha + 1)}$, for $\\alpha>3/2$ and for $\\alpha >1$ together with the\nadditional assumption $p= o(n^{4 \\alpha -1})$, respectively. We deduce rate\nasymptotic minimax results for testing the inverse of the covariance matrix. We\nconstruct an adaptive test procedure with respect to the parameter $\\alpha$ and\nshow that it attains the rate $\\tilde{\\psi}= ( n^2 p / \\ln\\ln(n\n\\displaystyle\\sqrt{p}) )^{- \\alpha/(4 \\alpha + 1)}$.\n", "versions": [{"version": "v1", "created": "Thu, 4 Sep 2014 13:02:34 GMT"}, {"version": "v2", "created": "Tue, 26 Jan 2016 17:55:09 GMT"}], "update_date": "2016-01-27", "authors_parsed": [["Butucea", "Cristina", ""], ["Zgheib", "Rania", ""]]}, {"id": "1409.1620", "submitter": "Yevgeniy Kovchegov", "authors": "Yevgeniy Kovchegov, Nese Yildiz", "title": "Orthogonal Polynomials for Seminonparametric Instrumental Variables\n  Model", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST q-fin.EC stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop an approach that resolves a {\\it polynomial basis problem} for a\nclass of models with discrete endogenous covariate, and for a class of\neconometric models considered in the work of Newey and Powell (2003), where the\nendogenous covariate is continuous. Suppose $X$ is a $d$-dimensional endogenous\nrandom variable, $Z_1$ and $Z_2$ are the instrumental variables (vectors), and\n$Z=\\left(\\begin{array}{c}Z_1 \\\\Z_2\\end{array}\\right)$. Now, assume that the\nconditional distributions of $X$ given $Z$ satisfy the conditions sufficient\nfor solving the identification problem as in Newey and Powell (2003) or as in\nProposition 1.1 of the current paper. That is, for a function $\\pi(z)$ in the\nimage space there is a.s. a unique function $g(x,z_1)$ in the domain space such\nthat $$E[g(X,Z_1)~|~Z]=\\pi(Z) \\qquad Z-a.s.$$ In this paper, for a class of\nconditional distributions $X|Z$, we produce an orthogonal polynomial basis\n$Q_j(x,z_1)$ such that for a.e. $Z_1=z_1$, and for all $j \\in \\mathbb{Z}_+^d$,\nand a certain $\\mu(Z)$, $$P_j(\\mu(Z))=E[Q_j(X, Z_1)~|~Z ],$$ where $P_j$ is a\npolynomial of degree $j$. This is what we call solving the {\\it polynomial\nbasis problem}.\n  Assuming the knowledge of $X|Z$ and an inference of $\\pi(z)$, our approach\nprovides a natural way of estimating the structural function of interest\n$g(x,z_1)$. Our polynomial basis approach is naturally extended to Pearson-like\nand Ord-like families of distributions.\n", "versions": [{"version": "v1", "created": "Thu, 4 Sep 2014 21:43:29 GMT"}], "update_date": "2014-09-08", "authors_parsed": [["Kovchegov", "Yevgeniy", ""], ["Yildiz", "Nese", ""]]}, {"id": "1409.1771", "submitter": "John Aston", "authors": "John A. D. Aston and Claudia Kirch", "title": "Efficiency of change point tests in high dimensional settings", "comments": "37 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While there is considerable work on change point analysis in univariate time\nseries, more and more data being collected comes from high dimensional\nmultivariate settings. This paper introduces the asymptotic concept of high\ndimensional efficiency which quantifies the detection power of different\nstatistics in such situations. While being related to classic asymptotic\nrelative efficiency, it is different in that it provides the rate at which the\nchange can get smaller with dimension while still being detectable. This also\nallows for comparisons of different methods with different null asymptotics as\nis for example the case in high-dimensional change point settings. Based on\nthis new concept we investigate change point detection procedures using\nprojections and develop asymptotic theory for how full panel (multivariate)\ntests compare with both oracle and random projections. Furthermore, for each\ngiven projection we can quantify a cone such that the corresponding projection\nstatistic yields better power behavior if the true change direction is within\nthis cone. The effect of misspecification of the covariance on the power of the\ntests is investigated, because in many high dimensional situations estimation\nof the full dependency (covariance) between the multivariate observations in\nthe panel is often either computationally or even theoretically infeasible. It\nturns out that the projection statistic is much more robust in this respect in\nterms of size and somewhat more robust in terms of power. The theoretic\nquantification by the theory is accompanied by simulation results which confirm\nthe theoretic (asymptotic) findings for surprisingly small samples. This shows\nin particular that the concept of high dimensional efficiency is indeed\nsuitable to describe small sample power, and this is demonstrated in a\nmultivariate example of market index data.\n", "versions": [{"version": "v1", "created": "Fri, 5 Sep 2014 12:56:42 GMT"}, {"version": "v2", "created": "Sat, 25 Jun 2016 07:47:38 GMT"}], "update_date": "2016-06-28", "authors_parsed": [["Aston", "John A. D.", ""], ["Kirch", "Claudia", ""]]}, {"id": "1409.1787", "submitter": "Sebastian Krumscheid", "authors": "Serafim Kalliadasis and Sebastian Krumscheid and Grigorios A.\n  Pavliotis", "title": "A new framework for extracting coarse-grained models from time series\n  with multiscale structure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many applications it is desirable to infer coarse-grained models from\nobservational data. The observed process often corresponds only to a few\nselected degrees of freedom of a high-dimensional dynamical system with\nmultiple time scales. In this work we consider the inference problem of\nidentifying an appropriate coarse-grained model from a single time series of a\nmultiscale system. It is known that estimators such as the maximum likelihood\nestimator or the quadratic variation of the path estimator can be strongly\nbiased in this setting. Here we present a novel parametric inference\nmethodology for problems with linear parameter dependency that does not suffer\nfrom this drawback. Furthermore, we demonstrate through a wide spectrum of\nexamples that our methodology can be used to derive appropriate coarse-grained\nmodels from time series of partial observations of a multiscale system in an\neffective and systematic fashion.\n", "versions": [{"version": "v1", "created": "Fri, 5 Sep 2014 13:35:52 GMT"}, {"version": "v2", "created": "Tue, 5 May 2015 16:46:19 GMT"}], "update_date": "2015-05-06", "authors_parsed": [["Kalliadasis", "Serafim", ""], ["Krumscheid", "Sebastian", ""], ["Pavliotis", "Grigorios A.", ""]]}, {"id": "1409.2051", "submitter": "Mike Steel Prof.", "authors": "Sebastien Roch and Mike Steel", "title": "Likelihood-based tree reconstruction on a concatenation of alignments\n  can be positively misleading", "comments": "16 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE cs.CE math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The reconstruction of a species tree from genomic data faces a double hurdle.\nFirst, the (gene) tree describing the evolution of each gene may differ from\nthe species tree, for instance, due to incomplete lineage sorting. Second, the\naligned genetic sequences at the leaves of each gene tree provide merely an\nimperfect estimate of the topology of the gene tree. In this note, we\ndemonstrate formally that a basic statistical problem arises if one tries to\navoid accounting for these two processes and analyses the genetic data directly\nvia a concatenation approach. More precisely, we show that, under the\nmulti-species coalescent with a standard site substitution model, maximum\nlikelihood estimation on sequence data that has been concatenated across genes\nand performed under the incorrect assumption that all sites have evolved\nindependently and identically on a fixed tree is a statistically inconsistent\nestimator of the species tree. Our results provide a formal justification of\nsimulation results described of Kubatko and Degnan (2007) and others, and\ncomplements recent theoretical results by DeGorgio and Degnan (2010) and\nChifman and Kubtako (2014).\n", "versions": [{"version": "v1", "created": "Sat, 6 Sep 2014 19:51:05 GMT"}], "update_date": "2017-07-24", "authors_parsed": [["Roch", "Sebastien", ""], ["Steel", "Mike", ""]]}, {"id": "1409.2090", "submitter": "Erwan Scornet", "authors": "Erwan Scornet (LSTA)", "title": "On the asymptotics of random forests", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The last decade has witnessed a growing interest in random forest models\nwhich are recognized to exhibit good practical performance, especially in\nhigh-dimensional settings. On the theoretical side, however, their predictive\npower remains largely unexplained, thereby creating a gap between theory and\npractice. The aim of this paper is twofold. Firstly, we provide theoretical\nguarantees to link finite forests used in practice (with a finite number M of\ntrees) to their asymptotic counterparts. Using empirical process theory, we\nprove a uniform central limit theorem for a large class of random forest\nestimates, which holds in particular for Breiman's original forests. Secondly,\nwe show that infinite forest consistency implies finite forest consistency and\nthus, we state the consistency of several infinite forests. In particular, we\nprove that q quantile forests---close in spirit to Breiman's forests but easier\nto study---are able to combine inconsistent trees to obtain a final consistent\nprediction, thus highlighting the benefits of random forests compared to single\ntrees.\n", "versions": [{"version": "v1", "created": "Sun, 7 Sep 2014 06:42:51 GMT"}], "update_date": "2014-09-09", "authors_parsed": [["Scornet", "Erwan", "", "LSTA"]]}, {"id": "1409.2121", "submitter": "Ningning Xia", "authors": "Ningning Xia and Xinghua Zheng", "title": "On the inference about the spectra of high-dimensional covariance matrix\n  based on noisy observations-with applications to integrated covolatility\n  matrix inference in the presence of microstructure noise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In practice, observations are often contaminated by noise, making the\nresulting sample covariance matrix to be an information-plus-noise-type\ncovariance matrix. Aiming to make inferences about the spectra of the\nunderlying true covariance matrix under such a situation, we establish an\nasymptotic relationship that describes how the limiting spectral distribution\nof (true) sample covariance matrices depends on that of\ninformation-plus-noise-type sample covariance matrices. As an application, we\nconsider the inference about the spectra of integrated covolatility (ICV)\nmatrices of high-dimensional diffusion processes based on high-frequency data\nwith microstructure noise. The (slightly modified) pre-averaging estimator is\nan information-plus-noise-type covariance matrix, and the aforementioned\nresult, together with a (generalized) connection between the spectral\ndistribution of true sample covariance matrices and that of the population\ncovariance matrix, enables us to propose a two-step procedure to estimate the\nspectral distribution of ICV for a class of diffusion processes. An alternative\nestimator is further proposed, which possesses two desirable properties: it\neliminates the impact of microstructure noise, and its limiting spectral\ndistribution depends only on that of the ICV through the standard\nMar\\v{c}enko-Pastur equation. Numerical studies demonstrate that our proposed\nmethods can be used to estimate the spectra of the underlying covariance matrix\nbased on noisy observations.\n", "versions": [{"version": "v1", "created": "Sun, 7 Sep 2014 13:43:24 GMT"}, {"version": "v2", "created": "Sat, 22 Aug 2015 12:49:25 GMT"}], "update_date": "2015-08-25", "authors_parsed": [["Xia", "Ningning", ""], ["Zheng", "Xinghua", ""]]}, {"id": "1409.2177", "submitter": "Kamalika Chaudhuri", "authors": "Kamalika Chaudhuri and Daniel Hsu and Shuang Song", "title": "The Large Margin Mechanism for Differentially Private Maximization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A basic problem in the design of privacy-preserving algorithms is the private\nmaximization problem: the goal is to pick an item from a universe that\n(approximately) maximizes a data-dependent function, all under the constraint\nof differential privacy. This problem has been used as a sub-routine in many\nprivacy-preserving algorithms for statistics and machine-learning.\n  Previous algorithms for this problem are either range-dependent---i.e., their\nutility diminishes with the size of the universe---or only apply to very\nrestricted function classes. This work provides the first general-purpose,\nrange-independent algorithm for private maximization that guarantees\napproximate differential privacy. Its applicability is demonstrated on two\nfundamental tasks in data mining and machine learning.\n", "versions": [{"version": "v1", "created": "Sun, 7 Sep 2014 23:51:00 GMT"}], "update_date": "2014-09-09", "authors_parsed": [["Chaudhuri", "Kamalika", ""], ["Hsu", "Daniel", ""], ["Song", "Shuang", ""]]}, {"id": "1409.2262", "submitter": "Henrik Nyman", "authors": "Henrik Nyman, Johan Pensar, Jukka Corander", "title": "Stratified Gaussian Graphical Models", "comments": "23 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian graphical models represent the backbone of the statistical toolbox\nfor analyzing continuous multivariate systems. However, due to the intrinsic\nproperties of the multivariate normal distribution, use of this model family\nmay hide certain forms of context-specific independence that are natural to\nconsider from an applied perspective. Such independencies have been earlier\nintroduced to generalize discrete graphical models and Bayesian networks into\nmore flexible model families. Here we adapt the idea of context-specific\nindependence to Gaussian graphical models by introducing a stratification of\nthe Euclidean space such that a conditional independence may hold in certain\nsegments but be absent elsewhere. It is shown that the stratified models define\na curved exponential family, which retains considerable tractability for\nparameter estimation and model selection.\n", "versions": [{"version": "v1", "created": "Mon, 8 Sep 2014 10:10:25 GMT"}], "update_date": "2014-09-09", "authors_parsed": [["Nyman", "Henrik", ""], ["Pensar", "Johan", ""], ["Corander", "Jukka", ""]]}, {"id": "1409.2344", "submitter": "Avanti Athreya", "authors": "Minh Tang and Avanti Athreya and Daniel L. Sussman and Vince Lyzinski\n  and Carey E. Priebe", "title": "A nonparametric two-sample hypothesis testing problem for random dot\n  product graphs", "comments": "24 pages, 1 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of testing whether two finite-dimensional random dot\nproduct graphs have generating latent positions that are independently drawn\nfrom the same distribution, or distributions that are related via scaling or\nprojection. We propose a test statistic that is a kernel-based function of the\nadjacency spectral embedding for each graph. We obtain a limiting distribution\nfor our test statistic under the null and we show that our test procedure is\nconsistent across a broad range of alternatives.\n", "versions": [{"version": "v1", "created": "Mon, 8 Sep 2014 13:48:20 GMT"}, {"version": "v2", "created": "Thu, 12 Nov 2015 16:47:31 GMT"}], "update_date": "2015-11-13", "authors_parsed": [["Tang", "Minh", ""], ["Athreya", "Avanti", ""], ["Sussman", "Daniel L.", ""], ["Lyzinski", "Vince", ""], ["Priebe", "Carey E.", ""]]}, {"id": "1409.2767", "submitter": "Shota Gugushvili", "authors": "Shota Gugushvili and Peter Spreij", "title": "Posterior contraction rate for non-parametric Bayesian estimation of the\n  dispersion coefficient of a stochastic differential equation", "comments": "11 pages", "journal-ref": "ESAIM: Probability and Statistics 20 (2016), 143-153", "doi": "10.1051/ps/2016008", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive the posteror contraction rate for non-parametric Bayesian\nestimation of a deterministic dispersion coefficient of a linear stochastic\ndifferential equation.\n", "versions": [{"version": "v1", "created": "Tue, 9 Sep 2014 15:02:29 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Gugushvili", "Shota", ""], ["Spreij", "Peter", ""]]}, {"id": "1409.2830", "submitter": "Donata Puplinskait\\.e", "authors": "Donata Puplinskaite, Donatas Surgailis", "title": "Scaling transition for long-range dependent Gaussian random fields", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Puplinskaite and Surgailis (2014) we introduced the notion of scaling\ntransition for stationary random fields $X$ on $\\mathbb{Z}^2$ in terms of\npartial sums limits, or scaling limits, of $X$ over rectangles whose sides grow\nat possibly different rate. The present paper establishes the existence of\nscaling transition for a natural class of stationary Gaussian random fields on\n$\\mathbb{Z}^2$ with long-range dependence. The scaling limits of such random\nfields are identified and characterized by dependence properties of rectangular\nincrements.\n", "versions": [{"version": "v1", "created": "Tue, 9 Sep 2014 18:19:23 GMT"}, {"version": "v2", "created": "Sat, 6 Dec 2014 18:51:17 GMT"}], "update_date": "2014-12-09", "authors_parsed": [["Puplinskaite", "Donata", ""], ["Surgailis", "Donatas", ""]]}, {"id": "1409.3301", "submitter": "Shiqiong Huang", "authors": "Shiqiong Huang, Jiashun Jin and Zhigang Yao", "title": "Partial Correlation Screening for Estimating Large Precision Matrices,\n  with Applications to Classification", "comments": "47 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Partial Correlation Screening (PCS) as a new row-by-row approach\nto estimating a large precision matrix $\\Omega$. To estimate the $i$-th row of\n$\\Omega$, $1 \\leq i \\leq p$, PCS uses a Screen step and a Clean step. In the\nScreen step, PCS recruits a (small) subset of indices using a stage-wise\nalgorithm, where in each stage, the algorithm updates the set of recruited\nindices by adding the index $j$ that has the largest (in magnitude) empirical\npartial correlation with $i$. In the Clean step, PCS re-investigates all\nrecruited indices and use them to reconstruct the $i$-th row of $\\Omega$.\n  PCS is computationally efficient and modest in memory use: to estimate a row\nof $\\Omega$, it only needs a few rows (determined sequentially) of the\nempirical covariance matrix. This enables PCS to execute the estimation of a\nlarge precision matrix (e.g., $p=10K$) in a few minutes, and open doors to\nestimating much larger precision matrices.\n  We use PCS for classification. Higher Criticism Thresholding (HCT) is a\nrecent classifier that enjoys optimality, but to exploit its full potential in\npractice, one needs a good estimate of the precision matrix $\\Omega$. Combining\nHCT with any approach to estimating $\\Omega$ gives a new classifier: examples\ninclude HCT-PCS and HCT-glasso. We have applied HCT-PCS to two large microarray\ndata sets ($p = 8K$ and $10K$) for classification, where it not only\nsignificantly outperforms HCT-glasso, but also is competitive to the Support\nVector Machine (SVM) and Random Forest (RF). The results suggest that PCS gives\nmore useful estimates of $\\Omega$ than the glasso.\n  We set up a general theoretical framework and show that in a broad context,\nPCS fully recovers the support of $\\Omega$ and HCT-PCS yields optimal\nclassification behavior. Our proofs shed interesting light on the behavior of\nstage-wise procedures.\n", "versions": [{"version": "v1", "created": "Thu, 11 Sep 2014 02:43:37 GMT"}], "update_date": "2014-09-12", "authors_parsed": [["Huang", "Shiqiong", ""], ["Jin", "Jiashun", ""], ["Yao", "Zhigang", ""]]}, {"id": "1409.3601", "submitter": "James Scott", "authors": "Nicholas G. Polson and James G. Scott", "title": "Vertical-likelihood Monte Carlo", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this review, we address the use of Monte Carlo methods for approximating\ndefinite integrals of the form $Z = \\int L(x) d P(x)$, where $L$ is a target\nfunction (often a likelihood) and $P$ a finite measure. We present\nvertical-likelihood Monte Carlo, which is an approach for designing the\nimportance function $g(x)$ used in importance sampling. Our approach exploits a\nduality between two random variables: the random draw $X \\sim g$, and the\ncorresponding random likelihood ordinate $Y\\equiv L(X)$ of the draw. It is\nnatural to specify $g(x)$ and ask: what is the the implied distribution of $Y$?\nIn this paper, we take up the opposite question: what should the distribution\nof $Y$ be so that the implied importance function $g(x)$ is good for\napproximating $Z$? Our answer turns out to unite seven seemingly disparate\nclasses of algorithms under the vertical-likelihood perspective: importance\nsampling, slice sampling, simulated annealing/tempering, the harmonic-mean\nestimator, the vertical-density sampler, nested sampling, and energy-level\nsampling (a suite of related methods from statistical physics). In particular,\nwe give an alterate presentation of nested sampling, paying special attention\nto the connection between this method and the vertical-likelihood perspective\narticulated here. As an alternative to nested sampling, we describe an MCMC\nmethod based on re-weighted slice sampling. This method's convergence\nproperties are studied, and two examples demonstrate the promise of the overall\napproach.\n", "versions": [{"version": "v1", "created": "Thu, 11 Sep 2014 21:24:46 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2015 15:02:15 GMT"}], "update_date": "2015-06-24", "authors_parsed": [["Polson", "Nicholas G.", ""], ["Scott", "James G.", ""]]}, {"id": "1409.3642", "submitter": "Wei Wu", "authors": "Xiaohong Chen, Qi-Man Shao, Wei Biao Wu", "title": "Self-normalized Cram\\'er Type Moderate Deviations under Dependence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We establish a Cram\\'er-type moderate deviation result for self-normalized\nsums of weakly dependent random variables, where the moment requirement is much\nweaker than the non-self-normalized counterpart. The range of the moderate\ndeviation is shown to depend on the moment condition and the degree of\ndependence of the underlying processes. We consider two types of\nself-normalization: the big-block-small-block scheme and the interlacing or\nequal-block scheme. Simulation study shows that the latter can have a better\nfinite-sample performance. Our result is applied to multiple testing and\nconstruction of simultaneous confidence intervals for high-dimensional time\nseries mean vectors.\n", "versions": [{"version": "v1", "created": "Fri, 12 Sep 2014 03:10:54 GMT"}], "update_date": "2014-09-15", "authors_parsed": [["Chen", "Xiaohong", ""], ["Shao", "Qi-Man", ""], ["Wu", "Wei Biao", ""]]}, {"id": "1409.4160", "submitter": "Ajay Jasra", "authors": "Hock Peng Chan, Chiang Wee Heng, Ajay Jasra", "title": "Theory of Parallel Particle Filters for Hidden Markov Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The objective of this article is to study the asymptotic behavior of a new\nparticle filtering approach in the context of hidden Markov models (HMMs). In\nparticular, we develop an algorithm where the latent-state sequence is\nsegmented into multiple shorter portions, with an estimation technique based\nupon a separate particle filter in each portion. The partitioning facilitates\nthe use of parallel processing. Based upon this approach, we introduce new\nestimators of the latent states and likelihood which have similar or better\nvariance properties compared to estimators derived from standard particle\nfilters. Moreover due to parallelization there is less wall-clock computational\ntime. We show that the likelihood function estimator is unbiased, prove central\nlimit theorem convergences of estimators, and provide consistent in-sample\nestimation of the asymptotic variances. The theoretical analyses, supported by\na numerical study, show that the segmentation reduces the variances in smoothed\nlatent-state estimators, in addition to the savings in wall-clock time.\n", "versions": [{"version": "v1", "created": "Mon, 15 Sep 2014 05:35:44 GMT"}], "update_date": "2014-09-16", "authors_parsed": [["Chan", "Hock Peng", ""], ["Heng", "Chiang Wee", ""], ["Jasra", "Ajay", ""]]}, {"id": "1409.4274", "submitter": "Henryk Z\\\"ahle", "authors": "Dominic Schuhmacher, Anja Sturm, Henryk Z\\\"ahle", "title": "On qualitative robustness of the Lotka--Nagaev estimator for the\n  offspring mean of a supercritical Galton--Watson process", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We characterize the sets of offspring laws on which the Lotka--Nagaev\nestimator for the mean of a supercritical Galton--Watson process is\nqualitatively robust. These are exactly the locally uniformly integrating sets\nof offspring laws, which may be quite large. If the corresponding global\nproperty is assumed instead, we obtain uniform robustness as well. We\nillustrate both results with a number of concrete examples. As a by-product of\nthe proof we obtain that the Lotka--Nagaev estimator is [locally] uniformly\nweakly consistent on the respective sets of offspring laws, conditionally on\nnon-extinction.\n", "versions": [{"version": "v1", "created": "Mon, 15 Sep 2014 14:30:16 GMT"}, {"version": "v2", "created": "Fri, 13 Feb 2015 15:25:06 GMT"}], "update_date": "2016-02-22", "authors_parsed": [["Schuhmacher", "Dominic", ""], ["Sturm", "Anja", ""], ["Z\u00e4hle", "Henryk", ""]]}, {"id": "1409.4317", "submitter": "Theofanis Sapatinas", "authors": "Efstathios Paparoditis and Theofanis Sapatinas", "title": "Bootstrap-Based K-Sample Testing For Functional Data", "comments": "38 pages, 4 figures, 6 tables. [A shorter version of the paper has\n  been published as: Paparoditis, E. & Sapatinas, T. (2016). Bootstrap-based\n  testing of equality of mean functions or equality of covariance operators for\n  functional data. Biometrika, Vol. 103, 727-733.]", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate properties of a bootstrap-based methodology for testing\nhypotheses about equality of certain characteristics of the distributions\nbetween different populations in the context of functional data. The suggested\ntesting methodology is simple and easy to implement. It resamples the original\ndataset in such a way that the null hypothesis of interest is satisfied and it\ncan be potentially applied to a wide range of testing problems and test\nstatistics of interest. Furthermore, it can be utilized to the case where more\nthan two populations of functional data are considered. We illustrate the\nbootstrap procedure by considering the important problems of testing the\nequality of mean functions or the equality of covariance functions (resp.\ncovariance operators) between two populations. Theoretical results that justify\nthe validity of the suggested bootstrap-based procedure are established.\nFurthermore, simulation results demonstrate very good size and power\nperformances in finite sample situations, including the case of testing\nproblems and/or sample sizes where asymptotic considerations do not lead to\nsatisfactory approximations. A real-life dataset analyzed in the literature is\nalso examined.\n", "versions": [{"version": "v1", "created": "Mon, 15 Sep 2014 16:44:57 GMT"}, {"version": "v2", "created": "Fri, 10 Jul 2015 14:27:46 GMT"}, {"version": "v3", "created": "Tue, 31 May 2016 06:56:45 GMT"}, {"version": "v4", "created": "Wed, 28 Sep 2016 06:20:27 GMT"}], "update_date": "2016-09-29", "authors_parsed": [["Paparoditis", "Efstathios", ""], ["Sapatinas", "Theofanis", ""]]}, {"id": "1409.4398", "submitter": "Jaehyung Choi", "authors": "Jaehyung Choi, Andrew P. Mullhaupt", "title": "Application of K\\\"ahler manifold to signal processing and Bayesian\n  inference", "comments": "8 pages, submitted to the Proceedings of MaxEnt 14", "journal-ref": "AIP Conf. Proc. 1641, 113 (2015)", "doi": "10.1063/1.4905970", "report-no": null, "categories": "math.DG cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We review the information geometry of linear systems and its application to\nBayesian inference, and the simplification available in the K\\\"ahler manifold\ncase. We find conditions for the information geometry of linear systems to be\nK\\\"ahler, and the relation of the K\\\"ahler potential to information geometric\nquantities such as $\\alpha $-divergence, information distance and the dual\n$\\alpha $-connection structure. The K\\\"ahler structure simplifies the\ncalculation of the metric tensor, connection, Ricci tensor and scalar\ncurvature, and the $\\alpha $-generalization of the geometric objects. The\nLaplace--Beltrami operator is also simplified in the K\\\"ahler geometry. One of\nthe goals in information geometry is the construction of Bayesian priors\noutperforming the Jeffreys prior, which we use to demonstrate the utility of\nthe K\\\"ahler structure.\n", "versions": [{"version": "v1", "created": "Mon, 15 Sep 2014 19:55:35 GMT"}, {"version": "v2", "created": "Wed, 14 Jan 2015 20:38:49 GMT"}], "update_date": "2015-01-15", "authors_parsed": [["Choi", "Jaehyung", ""], ["Mullhaupt", "Andrew P.", ""]]}, {"id": "1409.4553", "submitter": "Muzaffar Rahmatullaev M", "authors": "Muzaffar Rahmatullaev", "title": "On new weakly periodic Gibbs measures of Ising model on a Cayley tree", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://creativecommons.org/licenses/publicdomain/", "abstract": "  We consider the Ising model on a Cayley tree . For the Ising model found new\nweakly periodic measures corresponding normal subgroups of index 2 of the group\nrepresentation of the tree Cayley.\n", "versions": [{"version": "v1", "created": "Tue, 16 Sep 2014 09:39:57 GMT"}], "update_date": "2014-09-17", "authors_parsed": [["Rahmatullaev", "Muzaffar", ""]]}, {"id": "1409.4642", "submitter": "Jianhua Shi", "authors": "Jianhua Shi, Xiaoping Chen, and Yong Zhou", "title": "The strong representation for the nonparametric estimation of\n  length-biased and right-censored data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we consider a useful product-limit estimator of distribution\nfunction proposed by Huang & Qin(2011) when the observations are subject to\nlength-biased and right-censored data. The estimator retains the simple\nclosed-form expression of the truncation product-limit estimator with some good\nproperties. An almost sure representation for the estimator is obtained which\ncan be used to derive many properties of functional statistics based on this\nproduct-limit estimator. The rate for the remainder in the representation is of\norder $O(n^{-3/4}(\\log(n)^{3/4}) $ a.s.\n", "versions": [{"version": "v1", "created": "Tue, 16 Sep 2014 13:53:13 GMT"}, {"version": "v2", "created": "Wed, 2 Aug 2017 14:13:38 GMT"}], "update_date": "2017-08-03", "authors_parsed": [["Shi", "Jianhua", ""], ["Chen", "Xiaoping", ""], ["Zhou", "Yong", ""]]}, {"id": "1409.4685", "submitter": "Sebastian Krumscheid", "authors": "Sebastian Krumscheid", "title": "Perturbation-based inference for diffusion processes: Obtaining\n  effective models from multiscale data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the inference problem for parameters in stochastic differential\nequation models from discrete time observations (e.g. experimental or\nsimulation data). Specifically, we study the case where one does not have\naccess to observations of the model itself, but only to a perturbed version\nwhich converges weakly to the solution of the model. Motivated by this\nperturbation argument, we study the convergence of estimation procedures from a\nnumerical analysis point of view. More precisely, we introduce appropriate\nconsistency, stability, and convergence concepts and study their connection. It\nturns out that standard statistical techniques, such as the maximum likelihood\nestimator, are not convergent methodologies in this setting, since they fail to\nbe stable. Due to this shortcoming, we introduce and analyse a novel inference\nprocedure for parameters in stochastic differential equation models which turns\nout to be convergent. As such, the method is particularly suited for the\nestimation of parameters in effective (i.e. coarse-grained) models from\nobservations of the corresponding multiscale process. We illustrate these\ntheoretical findings via several numerical examples.\n", "versions": [{"version": "v1", "created": "Tue, 16 Sep 2014 16:21:51 GMT"}, {"version": "v2", "created": "Tue, 4 Jul 2017 12:42:00 GMT"}, {"version": "v3", "created": "Mon, 9 Apr 2018 15:33:27 GMT"}], "update_date": "2018-04-10", "authors_parsed": [["Krumscheid", "Sebastian", ""]]}, {"id": "1409.4857", "submitter": "Ricardo P\\'erez Marco", "authors": "Ricardo P\\'erez-Marco", "title": "A simple dynamical model leading to Pareto wealth distribution and\n  stability", "comments": "10 pages. Formulas corrected from version 1. Results unchanged", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.EC math.DS math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a simple dynamical model of wealth evolution. The invariant\ndistributions are of Pareto type and are dynamically stable as conjectured by\nPareto.\n", "versions": [{"version": "v1", "created": "Wed, 17 Sep 2014 03:11:36 GMT"}, {"version": "v2", "created": "Fri, 3 Oct 2014 17:11:20 GMT"}], "update_date": "2014-10-06", "authors_parsed": [["P\u00e9rez-Marco", "Ricardo", ""]]}, {"id": "1409.4979", "submitter": "Kevin Schnelli", "authors": "Ji Oon Lee, Kevin Schnelli", "title": "Tracy-Widom Distribution for the Largest Eigenvalue of Real Sample\n  Covariance Matrices with General Population", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider sample covariance matrices of the form\n$\\mathcal{Q}=(\\Sigma^{1/2}X)(\\Sigma^{1/2} X)^*$, where the sample $X$ is an\n$M\\times N$ random matrix whose entries are real independent random variables\nwith variance $1/N$ and where $\\Sigma$ is an $M\\times M$ positive-definite\ndeterministic matrix. We analyze the asymptotic fluctuations of the largest\nrescaled eigenvalue of $\\mathcal{Q}$ when both $M$ and $N$ tend to infinity\nwith $N/M\\to d\\in(0,\\infty)$. For a large class of populations $\\Sigma$ in the\nsub-critical regime, we show that the distribution of the largest rescaled\neigenvalue of $\\mathcal{Q}$ is given by the type-1 Tracy-Widom distribution\nunder the additional assumptions that (1) either the entries of $X$ are i.i.d.\nGaussians or (2) that $\\Sigma$ is diagonal and that the entries of $X$ have a\nsubexponential decay.\n", "versions": [{"version": "v1", "created": "Wed, 17 Sep 2014 13:00:09 GMT"}, {"version": "v2", "created": "Tue, 9 Jun 2015 10:43:16 GMT"}], "update_date": "2015-06-10", "authors_parsed": [["Lee", "Ji Oon", ""], ["Schnelli", "Kevin", ""]]}, {"id": "1409.5009", "submitter": "Ming Yuan", "authors": "Luwan Zhang, Grace Wahba and Ming Yuan", "title": "Distance Shrinkage and Euclidean Embedding via Regularized Kernel\n  Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although recovering an Euclidean distance matrix from noisy observations is a\ncommon problem in practice, how well this could be done remains largely\nunknown. To fill in this void, we study a simple distance matrix estimate based\nupon the so-called regularized kernel estimate. We show that such an estimate\ncan be characterized as simply applying a constant amount of shrinkage to all\nobserved pairwise distances. This fact allows us to establish risk bounds for\nthe estimate implying that the true distances can be estimated consistently in\nan average sense as the number of objects increases. In addition, such a\ncharacterization suggests an efficient algorithm to compute the distance matrix\nestimator, as an alternative to the usual second order cone programming known\nnot to scale well for large problems. Numerical experiments and an application\nin visualizing the diversity of Vpu protein sequences from a recent HIV-1 study\nfurther demonstrate the practical merits of the proposed method.\n", "versions": [{"version": "v1", "created": "Wed, 17 Sep 2014 14:42:28 GMT"}], "update_date": "2014-09-18", "authors_parsed": [["Zhang", "Luwan", ""], ["Wahba", "Grace", ""], ["Yuan", "Ming", ""]]}, {"id": "1409.5015", "submitter": "Binish Fatimah", "authors": "Binish Fatimah and S. D. Joshi", "title": "Exact Least Squares Algorithm for Signal Matched Multirate Whitening\n  Filter Bank: Part I", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we define a concept of signal matched multirate whitening\nfilter bank which provides an optimum coding gain. This is achieved by\nwhitening the outputs, of the analysis filter bank, within as well as across\nthe channels, by solving a constrained projection problem. We also present a\nfast time and order recursive least squares algorithm to obtain the vector\noutput of the proposed analysis filter bank. The recursive algorithm, developed\nhere, gives rise to a lattice-like structure. Since the proposed signal matched\nanalysis filter bank coefficients are not available directly, an order\nrecursive algorithm is also presented for estimating these from the lattice\nparameters. Simulation results are presented to validate the theory. It is also\nobserved that the proposed algorithm can be used to whiten\nGaussian/non-Gaussian processes with minimum as well as non-minimum phase.\n", "versions": [{"version": "v1", "created": "Wed, 17 Sep 2014 14:56:01 GMT"}], "update_date": "2014-09-18", "authors_parsed": [["Fatimah", "Binish", ""], ["Joshi", "S. D.", ""]]}, {"id": "1409.5085", "submitter": "Rajesh Singh", "authors": "Prayas Sharma, Hemant K.Verma and Rajesh Singh", "title": "Generalized class of estimators for finite population mean when study\n  variable is qualitative in nature", "comments": "15 pages, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper suggests a generalized class of estimators for population mean of\nthe qualitative study variable in simple random sampling using information on\nan auxiliary variable. Asymptotic expressions of bias and mean square error of\nthe proposed class of estimators have been obtained. Asymptotic optimum\nestimator has been investigated along with its approximate mean square error.\nIt has been shown that proposed generalized class of estimators are more\nefficient than all the estimators considered by Singh et al. (2010) in case of\nqualitative study variable. In addition theoretical findings are supported by\nan empirical study based on real population to show the superiority of the\nconstructed estimators over others.\n", "versions": [{"version": "v1", "created": "Tue, 16 Sep 2014 08:12:23 GMT"}], "update_date": "2014-09-18", "authors_parsed": [["Sharma", "Prayas", ""], ["Verma", "Hemant K.", ""], ["Singh", "Rajesh", ""]]}, {"id": "1409.5099", "submitter": "Binish Fatimah", "authors": "Binish Fatimah and S. D. Joshi", "title": "Exact Least Squares Algorithm for Signal Matched Synthesis Filter Bank:\n  Part II", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the companion paper, we proposed a concept of signal matched whitening\nfilter bank and developed a time and order recursive, fast least squares\nalgorithm for the same. Objective of part II of the paper is two fold: first is\nto define a concept of signal matched synthesis filter bank, hence combining\ndefinitions of part I and part II we obtain a filter bank matched to a given\nsignal. We also develop a fast time and order recursive, least squares\nalgorithm for obtaining the same. The synthesis filters, obtained here,\nreconstruct the given signal only and not every signal from the finite energy\nsignal space (i.e. belonging to L^2(R)), as is usually done. The recursions, so\nobtained, result in a lattice-like structure. Since the filter parameters are\nnot directly available, we also present an order recursive algorithm for the\ncomputation of signal matched synthesis filter bank coefficients from the\nlattice parameters. The second objective is to explore the possibility of using\nsynthesis side for modeling of a given stochastic process. Simulation results\nhave also been presented to validate the theory.\n", "versions": [{"version": "v1", "created": "Tue, 16 Sep 2014 16:02:02 GMT"}], "update_date": "2014-09-18", "authors_parsed": [["Fatimah", "Binish", ""], ["Joshi", "S. D.", ""]]}, {"id": "1409.5103", "submitter": "Harry van Zanten", "authors": "Alisa Kirichenko and Harry van Zanten", "title": "Optimality of Poisson processes intensity learning with Gaussian\n  processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we provide theoretical support for the so-called \"Sigmoidal\nGaussian Cox Process\" approach to learning the intensity of an inhomogeneous\nPoisson process on a $d$-dimensional domain. This method was proposed by Adams,\nMurray and MacKay (ICML, 2009), who developed a tractable computational\napproach and showed in simulation and real data experiments that it can work\nquite satisfactorily. The results presented in the present paper provide\ntheoretical underpinning of the method. In particular, we show how to tune the\npriors on the hyper parameters of the model in order for the procedure to\nautomatically adapt to the degree of smoothness of the unknown intensity and to\nachieve optimal convergence rates.\n", "versions": [{"version": "v1", "created": "Wed, 17 Sep 2014 19:06:50 GMT"}, {"version": "v2", "created": "Mon, 2 Mar 2015 12:02:17 GMT"}], "update_date": "2015-03-03", "authors_parsed": [["Kirichenko", "Alisa", ""], ["van Zanten", "Harry", ""]]}, {"id": "1409.5291", "submitter": "A. Philip Dawid", "authors": "A. Philip Dawid, Monica Musio", "title": "Bayesian Model Selection Based on Proper Scoring Rules", "comments": "Published at http://dx.doi.org/10.1214/15-BA942 in the Bayesian\n  Analysis (http://projecteuclid.org/euclid.ba) by the International Society of\n  Bayesian Analysis (http://bayesian.org/)", "journal-ref": "Bayesian Analysis 2015, Vol. 10, No. 2, 479-499", "doi": "10.1214/15-BA942", "report-no": "VTeX-BA-BA942", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian model selection with improper priors is not well-defined because of\nthe dependence of the marginal likelihood on the arbitrary scaling constants of\nthe within-model prior densities. We show how this problem can be evaded by\nreplacing marginal log-likelihood by a homogeneous proper scoring rule, which\nis insensitive to the scaling constants. Suitably applied, this will typically\nenable consistent selection of the true model.\n", "versions": [{"version": "v1", "created": "Thu, 18 Sep 2014 12:58:14 GMT"}, {"version": "v2", "created": "Fri, 8 May 2015 08:04:07 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Dawid", "A. Philip", ""], ["Musio", "Monica", ""]]}, {"id": "1409.5353", "submitter": "Stojan Jovanovi\\\"A", "authors": "Stojan Jovanovi\\'c, John Hertz and Stefan Rotter", "title": "Cumulants of Hawkes point processes", "comments": "11 pages, 4 figures", "journal-ref": "Phys. Rev. E 91, 042802 (2015)", "doi": "10.1103/PhysRevE.91.042802", "report-no": null, "categories": "math.ST physics.bio-ph q-bio.NC stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive explicit, closed-form expressions for the cumulant densities of a\nmultivariate, self-exciting Hawkes point process, generalizing a result of\nHawkes in his earlier work on the covariance density and Bartlett spectrum of\nsuch processes. To do this, we represent the Hawkes process in terms of a\nPoisson cluster process and show how the cumulant density formulas can be\nderived by enumerating all possible \"family trees\", representing complex\ninteractions between point events. We also consider the problem of computing\nthe integrated cumulants, characterizing the average measure of correlated\nactivity between events of different types, and derive the relevant equations.\n", "versions": [{"version": "v1", "created": "Thu, 18 Sep 2014 16:02:03 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2015 15:47:00 GMT"}], "update_date": "2016-08-08", "authors_parsed": [["Jovanovi\u0107", "Stojan", ""], ["Hertz", "John", ""], ["Rotter", "Stefan", ""]]}, {"id": "1409.5640", "submitter": "Eric Kolaczyk", "authors": "Prakash Balachandran, Eric D. Kolaczyk, and Weston Viles", "title": "On the Propagation of Low-Rate Measurement Error to Subgraph Counts in\n  Large Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our work in this paper is inspired by a statistical observation that is both\nelementary and broadly relevant to network analysis in practice -- that the\nuncertainty in approximating some true network graph $G=(V,E)$ by some\nestimated graph $\\hat{G}=(V,\\hat{E})$ manifests as errors in the status of\n(non)edges that must necessarily propagate to any estimates of network\nsummaries $\\eta(G)$ we seek. Motivated by the common practice of using plug-in\nestimates $\\eta(\\hat{G})$ as proxies for $\\eta(G)$, our focus is on the problem\nof characterizing the distribution of the discrepancy $D=\\eta(\\hat{G}) -\n\\eta(G)$, in the case where $\\eta(\\cdot)$ is a subgraph count. Specifically, we\nstudy the fundamental case where the statistic of interest is $|E|$, the number\nof edges in $G$. Our primary contribution in this paper is to show that in the\nempirically relevant setting of large graphs with low-rate measurement errors,\nthe distribution of $D_E=|\\hat{E}| - |E|$ is well-characterized by a Skellam\ndistribution, when the errors are independent or weakly dependent. Under an\nassumption of independent errors, we are able to further show conditions under\nwhich this characterization is strictly better than that of an appropriate\nnormal distribution. These results derive from our formulation of a general\nresult, quantifying the accuracy with which the difference of two sums of\ndependent Bernoulli random variables may be approximated by the difference of\ntwo independent Poisson random variables, i.e., by a Skellam distribution. This\ngeneral result is developed through the use of Stein's method, and may be of\nsome general interest. We finish with a discussion of possible extension of our\nwork to subgraph counts $\\eta(G)$ of higher order.\n", "versions": [{"version": "v1", "created": "Fri, 19 Sep 2014 13:10:02 GMT"}, {"version": "v2", "created": "Fri, 8 Jan 2016 17:25:19 GMT"}, {"version": "v3", "created": "Sat, 8 Oct 2016 00:47:57 GMT"}], "update_date": "2016-10-11", "authors_parsed": [["Balachandran", "Prakash", ""], ["Kolaczyk", "Eric D.", ""], ["Viles", "Weston", ""]]}, {"id": "1409.5658", "submitter": "Keiji Matsumoto", "authors": "Keiji Matsumoto", "title": "An example of a quantum statistical model which cannot be mapped to a\n  less informative one by any trace preserving positive map", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Comparison of statistical models (experiments) is an important branch of\nmathematical statistics, which gives deep insights in many aspects of\nfoundation of statistics. So far, there are two quantum versions of the\nconcept: Comparison with respect to classical tasks and full quantum tasks. In\nthe latter version, a quantum statistical model is more informative than\nanother if and only if a trace preserving positive map sends the former to the\nlatter. On the other hand, in the former version, the existence of a trace\npreserving positive map sending the former to the latter is a useful sufficient\ncondition. A natural question is whether this is necessary or not. We resolve\nthis question negatively by giving a counter example.\n", "versions": [{"version": "v1", "created": "Fri, 19 Sep 2014 13:45:45 GMT"}], "update_date": "2014-09-22", "authors_parsed": [["Matsumoto", "Keiji", ""]]}, {"id": "1409.5924", "submitter": "Steven N. Evans", "authors": "Steven N. Evans and Ronald L. Rivest and Philip B. Stark", "title": "Leading the field: Fortune favors the bold in Thurstonian choice models", "comments": "Revised to take into account referees' comments. Mention of the\n  regression effect has been removed to concentrate on the small schools\n  phenomenon as a concrete illustration of our results", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Schools with the highest average student performance are often the smallest\nschools; localities with the highest rates of some cancers are frequently small\nand the effects observed in clinical trials are likely to be largest for the\nsmallest numbers of subjects. Informal explanations of this \"small-schools\nphenomenon\" point to the fact that the sample means of smaller samples have\nhigher variances. But this cannot be a complete explanation: If we draw two\nsamples from a diffuse distribution that is symmetric about some point, then\nthe chance that the smaller sample has larger mean is 50\\%. A particular\nconsequence of results proved below is that if one draws three or more samples\nof different sizes from the same normal distribution, then the sample mean of\nthe smallest sample is most likely to be highest, the sample mean of the second\nsmallest sample is second most likely to be highest, and so on; this is true\neven though for any pair of samples, each one of the pair is equally likely to\nhave the larger sample mean.\n  Our conclusions are relevant to certain stochastic choice models including\nthe following generalization of Thurstone's Law of Comparative Judgment. There\nare $n$ items. Item $i$ is preferred to item $j$ if $Z_i < Z_j$, where $Z$ is a\nrandom $n$-vector of preference scores. Suppose $\\mathbb{P}\\{Z_i = Z_j\\} = 0$\nfor $i \\ne j$, so there are no ties. Item $k$ is the favorite if $Z_k <\n\\min_{i\\ne k} Z_i$. Let $p_i$ denote the chance that item $i$ is the favorite.\nWe characterize a large class of distributions for $Z$ for which $p_1 > p_2 >\n\\cdots > p_n$. Our results are most surprising when $\\mathbb{P}\\{Z_i < Z_j\\} =\n\\mathbb{P}\\{Z_i > Z_j\\} = \\frac{1}{2}$ for $i \\ne j$, so neither of any two\nitems is likely to be preferred over the other in a pairwise comparison.\n", "versions": [{"version": "v1", "created": "Sat, 20 Sep 2014 22:59:38 GMT"}, {"version": "v2", "created": "Tue, 6 Dec 2016 00:47:52 GMT"}], "update_date": "2016-12-07", "authors_parsed": [["Evans", "Steven N.", ""], ["Rivest", "Ronald L.", ""], ["Stark", "Philip B.", ""]]}, {"id": "1409.5928", "submitter": "Alexis Decurninge", "authors": "Alexis Decurninge and Michel Broniatowski", "title": "Estimation for models defined by conditions on their L-moments", "comments": "35 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper extends the empirical minimum divergence approach for models which\nsatisfy linear constraints with respect to the probability measure of the\nunderlying variable (moment constraints) to the case where such constraints\npertain to its quantile measure (called here semi parametric quantile models).\nThe case when these constraints describe shape conditions as handled by the\nL-moments is considered and both the description of these models as well as the\nresulting non classical minimum divergence procedures are presented. These\nmodels describe neighborhoods of classical models used mainly for their tail\nbehavior, for example neighborhoods of Pareto or Weibull distributions, with\nwhich they may share the same first L-moments. A parallel is drawn with similar\nproblems held in elasticity theory and in optimal transport problems. The\nproperties of the resulting estimators are illustrated by simulated examples\ncomparing Maximum Likelihood estimators on Pareto and Weibull models to the\nminimum Chi-square empirical divergence approach on semi parametric quantile\nmodels, and others.\n", "versions": [{"version": "v1", "created": "Sun, 21 Sep 2014 01:29:00 GMT"}, {"version": "v2", "created": "Tue, 13 Jan 2015 09:20:31 GMT"}, {"version": "v3", "created": "Thu, 19 Feb 2015 10:47:58 GMT"}], "update_date": "2015-02-20", "authors_parsed": [["Decurninge", "Alexis", ""], ["Broniatowski", "Michel", ""]]}, {"id": "1409.6008", "submitter": "David Ginsbourger", "authors": "David Ginsbourger (IMSV, - M\\'ethodes d'Analyse Stochastique des Codes\n  et Traitements Num\\'eriques), Olivier Roustant (- M\\'ethodes d'Analyse\n  Stochastique des Codes et Traitements Num\\'eriques, DEMO-ENSMSE), Dominic\n  Schuhmacher, Nicolas Durrande (DEMO-ENSMSE), Nicolas Lenz (IMSV)", "title": "On ANOVA decompositions of kernels and Gaussian random field paths", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The FANOVA (or \"Sobol'-Hoeffding\") decomposition of multivariate functions\nhas been used for high-dimensional model representation and global sensitivity\nanalysis. When the objective function f has no simple analytic form and is\ncostly to evaluate, a practical limitation is that computing FANOVA terms may\nbe unaffordable due to numerical integration costs. Several approximate\napproaches relying on random field models have been proposed to alleviate these\ncosts, where f is substituted by a (kriging) predictor or by conditional\nsimulations. In the present work, we focus on FANOVA decompositions of Gaussian\nrandom field sample paths, and we notably introduce an associated kernel\ndecomposition (into 2^{2d} terms) called KANOVA. An interpretation in terms of\ntensor product projections is obtained, and it is shown that projected kernels\ncontrol both the sparsity of Gaussian random field sample paths and the\ndependence structure between FANOVA effects. Applications on simulated data\nshow the relevance of the approach for designing new classes of covariance\nkernels dedicated to high-dimensional kriging.\n", "versions": [{"version": "v1", "created": "Sun, 21 Sep 2014 16:10:15 GMT"}, {"version": "v2", "created": "Thu, 2 Oct 2014 19:43:42 GMT"}], "update_date": "2014-10-03", "authors_parsed": [["Ginsbourger", "David", "", "IMSV, - M\u00e9thodes d'Analyse Stochastique des Codes\n  et Traitements Num\u00e9riques"], ["Roustant", "Olivier", "", "- M\u00e9thodes d'Analyse\n  Stochastique des Codes et Traitements Num\u00e9riques, DEMO-ENSMSE"], ["Schuhmacher", "Dominic", "", "DEMO-ENSMSE"], ["Durrande", "Nicolas", "", "DEMO-ENSMSE"], ["Lenz", "Nicolas", "", "IMSV"]]}, {"id": "1409.6013", "submitter": "Alexis Decurninge", "authors": "Alexis Decurninge", "title": "Multivariate quantiles and multivariate L-moments", "comments": "45 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Univariate L-moments are expressed as projections of the quantile function\nonto an orthogonal basis of polynomials in $L_2([0;1],\\mathbb{R})$. We present\nmultivariate versions of L-moments expressed as collections of orthogonal\nprojections of a multivariate quantile function on a basis of multivariate\npolynomials in $L_2([0;1]^d,\\mathbb{R})$. We propose to consider quantile\nfunctions defined as transport from the uniform distribution on $[0;1]^d$ onto\nthe distribution of interest. In particular, we present the quantiles defined\nby the transport of Rosenblatt and the optimal transport and the properties of\nthe subsequent L-moments.\n", "versions": [{"version": "v1", "created": "Sun, 21 Sep 2014 16:40:32 GMT"}, {"version": "v2", "created": "Tue, 13 Jan 2015 09:26:58 GMT"}], "update_date": "2015-01-14", "authors_parsed": [["Decurninge", "Alexis", ""]]}, {"id": "1409.6019", "submitter": "Antonio Punzo", "authors": "Antonio Punzo and Paul D. McNicholas", "title": "Robust Clustering in Regression Analysis via the Contaminated Gaussian\n  Cluster-Weighted Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Gaussian cluster-weighted model (CWM) is a mixture of regression models\nwith random covariates that allows for flexible clustering of a random vector\ncomposed of response variables and covariates. In each mixture component, it\nadopts a Gaussian distribution for both the covariates and the responses given\nthe covariates. To robustify the approach with respect to possible elliptical\nheavy tailed departures from normality, due to the presence of atypical\nobservations, the contaminated Gaussian CWM is here introduced. In addition to\nthe parameters of the Gaussian CWM, each mixture component of our contaminated\nCWM has a parameter controlling the proportion of outliers, one controlling the\nproportion of leverage points, one specifying the degree of contamination with\nrespect to the response variables, and one specifying the degree of\ncontamination with respect to the covariates. Crucially, these parameters do\nnot have to be specified a priori, adding flexibility to our approach.\nFurthermore, once the model is estimated and the observations are assigned to\nthe groups, a finer intra-group classification in typical points, outliers,\ngood leverage points, and bad leverage points - concepts of primary importance\nin robust regression analysis - can be directly obtained. Relations with other\nmixture-based contaminated models are analyzed, identifiability conditions are\nprovided, an expectation-conditional maximization algorithm is outlined for\nparameter estimation, and various implementation and operational issues are\ndiscussed. Properties of the estimators of the regression coefficients are\nevaluated through Monte Carlo experiments and compared to the estimators from\nthe Gaussian CWM. A sensitivity study is also conducted based on a real data\nset.\n", "versions": [{"version": "v1", "created": "Sun, 21 Sep 2014 17:31:35 GMT"}], "update_date": "2014-09-23", "authors_parsed": [["Punzo", "Antonio", ""], ["McNicholas", "Paul D.", ""]]}, {"id": "1409.6203", "submitter": "Mark Transtrum", "authors": "Mark K. Transtrum, Gus Hart, Peng Qiu", "title": "Information topology identifies emergent model classes", "comments": "17 pages, 20 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.data-an cond-mat.mtrl-sci math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a language for describing the relationship among observations,\nmathematical models, and the underlying principles from which they are derived.\nUsing Information Geometry, we consider geometric properties of statistical\nmodels for different observations. As observations are varied, the model\nmanifold may be stretched, compressed, or even collapsed. Observations that\npreserve the structural identifiability of the parameters also preserve certain\ntopological features (such as edges and corners) that characterize the model's\nunderlying physical principles. We introduce Information Topology in analogy\nwith information geometry as characterizing the \"abstract model\" of which\nstatistical models are realizations. Observations that change the topology,\ni.e., \"manifold collapse,\" require a modification of the abstract model in\norder to construct identifiable statistical models. Often, the essential\ntopological feature is a hierarchical structure of boundaries (faces, edges,\ncorners, etc.) which we represent as a hierarchical graph known as a Hasse\ndiagram. Low-dimensional elements of this diagram are simple models that\ndescribe the dominant behavioral modes, what we call emergent model classes.\nObservations that preserve the Hasse diagram are diffeomorphically related and\nform a group, the collection of which form a partially ordered set. All\npossible observations have a semi-group structure. For hierarchical models, we\nconsider how the topology of simple models is embedded in that of larger\nmodels. When emergent model classes are unstable to the introduction of new\nparameters, we classify the new parameters as relevant. Conversely, the\nemergent model classes are stable to the introduction of irrelevant parameters.\nIn this way, information topology provides a general language for exploring\nrepresentations of physical systems and their relationships to observations.\n", "versions": [{"version": "v1", "created": "Mon, 22 Sep 2014 15:36:36 GMT"}, {"version": "v2", "created": "Wed, 13 Jul 2016 19:20:35 GMT"}], "update_date": "2016-07-14", "authors_parsed": [["Transtrum", "Mark K.", ""], ["Hart", "Gus", ""], ["Qiu", "Peng", ""]]}, {"id": "1409.6219", "submitter": "Christophe Ley", "authors": "Christophe Ley", "title": "Flexible modelling in statistics: past, present and future", "comments": "27 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In times where more and more data become available and where the data exhibit\nrather complex structures (significant departure from symmetry, heavy or light\ntails), flexible modelling has become an essential task for statisticians as\nwell as researchers and practitioners from domains such as economics, finance\nor environmental sciences. This is reflected by the wealth of existing\nproposals for flexible distributions; well-known examples are Azzalini's\nskew-normal, Tukey's $g$-and-$h$, mixture and two-piece distributions, to cite\nbut these. My aim in the present paper is to provide an introduction to this\nresearch field, intended to be useful both for novices and professionals of the\ndomain. After a description of the research stream itself, I will narrate the\ngripping history of flexible modelling, starring emblematic heroes from the\npast such as Edgeworth and Pearson, then depict three of the most used flexible\nfamilies of distributions, and finally provide an outlook on future flexible\nmodelling research by posing challenging open questions.\n", "versions": [{"version": "v1", "created": "Mon, 22 Sep 2014 15:59:26 GMT"}], "update_date": "2014-09-23", "authors_parsed": [["Ley", "Christophe", ""]]}, {"id": "1409.6230", "submitter": "Stephane Girard", "authors": "Alexander Nazin (ICS), Stephane Girard (INRIA Grenoble Rh\\^one-Alpes /\n  LJK Laboratoire Jean Kuntzmann)", "title": "L1-optimal linear programming estimatorfor periodic frontier functions\n  with Holder continuous derivative", "comments": "arXiv admin note: text overlap with arXiv:1103.5913", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new estimator based on a linear programming method for smooth\nfrontiers of sample points. The derivative of the frontier function is supposed\nto be Holder continuous.The estimator is defined as a linear combination of\nkernel functions being sufficiently regular, covering all the points and whose\nassociated support is of smallest surface. The coefficients of the linear\ncombination are computed by solving a linear programming problem. The L1- error\nbetween the estimated and the true frontier functionsis shown to be almost\nsurely converging to zero, and the rate of convergence is proved to be optimal.\n", "versions": [{"version": "v1", "created": "Mon, 22 Sep 2014 16:34:20 GMT"}], "update_date": "2014-09-23", "authors_parsed": [["Nazin", "Alexander", "", "ICS"], ["Girard", "Stephane", "", "INRIA Grenoble Rh\u00f4ne-Alpes /\n  LJK Laboratoire Jean Kuntzmann"]]}, {"id": "1409.6276", "submitter": "Xinjia Chen", "authors": "Xinjia Chen", "title": "Concentration Inequalities from Likelihood Ratio Method", "comments": "43 pages, no figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the applications of our previously established likelihood-ratio\nmethod for deriving concentration inequalities for a wide variety of univariate\nand multivariate distributions. New concentration inequalities for various\ndistributions are developed without the idea of minimizing moment generating\nfunctions.\n", "versions": [{"version": "v1", "created": "Mon, 1 Sep 2014 17:03:06 GMT"}], "update_date": "2014-09-23", "authors_parsed": [["Chen", "Xinjia", ""]]}, {"id": "1409.6337", "submitter": "Anna Mikusheva", "authors": "Isaiah Andrews and Anna Mikusheva", "title": "Conditional Inference with a Functional Nuisance Parameter", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper shows that the problem of testing hypotheses in moment condition\nmodels without any assumptions about identification may be considered as a\nproblem of testing with an infinite-dimensional nuisance parameter. We\nintroduce a sufficient statistic for this nuisance parameter and propose\nconditional tests. These conditional tests have uniformly correct asymptotic\nsize for a large class of models and test statistics. We apply our approach to\nconstruct tests based on quasi-likelihood ratio statistics, which we show are\nefficient in strongly identified models and perform well relative to existing\nalternatives in two examples.\n", "versions": [{"version": "v1", "created": "Mon, 22 Sep 2014 20:39:35 GMT"}], "update_date": "2014-09-24", "authors_parsed": [["Andrews", "Isaiah", ""], ["Mikusheva", "Anna", ""]]}, {"id": "1409.6447", "submitter": "Francisco Javier Rubio Dr.", "authors": "F. J. Rubio", "title": "On the propriety of the posterior of hierarchical linear mixed models\n  with flexible random effects distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of improper priors in the context of Bayesian hierarchical linear\nmixed models has been studied under the assumption of normality of the random\neffects. We study the propriety of the posterior under more flexible\ndistributional assumptions and general improper prior structures.\n", "versions": [{"version": "v1", "created": "Tue, 23 Sep 2014 08:33:47 GMT"}], "update_date": "2014-09-24", "authors_parsed": [["Rubio", "F. J.", ""]]}, {"id": "1409.6495", "submitter": "Xu He", "authors": "Xu He, Peter Z. G. Qian", "title": "A central limit theorem for general orthogonal array based space-filling\n  designs", "comments": "Published in at http://dx.doi.org/10.1214/14-AOS1231 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2014, Vol. 42, No. 5, 1725-1750", "doi": "10.1214/14-AOS1231", "report-no": "IMS-AOS-AOS1231", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Orthogonal array based space-filling designs (Owen [Statist. Sinica 2 (1992a)\n439-452]; Tang [J. Amer. Statist. Assoc. 88 (1993) 1392-1397]) have become\npopular in computer experiments, numerical integration, stochastic optimization\nand uncertainty quantification. As improvements of ordinary Latin hypercube\ndesigns, these designs achieve stratification in multi-dimensions. If the\nunderlying orthogonal array has strength $t$, such designs achieve uniformity\nup to $t$ dimensions. Existing central limit theorems are limited to these\ndesigns with only two-dimensional stratification based on strength two\northogonal arrays. We develop a new central limit theorem for these designs\nthat possess stratification in arbitrary multi-dimensions associated with\northogonal arrays of general strength. This result is useful for building\nconfidence statements for such designs in various statistical applications.\n", "versions": [{"version": "v1", "created": "Tue, 23 Sep 2014 11:32:48 GMT"}], "update_date": "2014-09-24", "authors_parsed": [["He", "Xu", ""], ["Qian", "Peter Z. G.", ""]]}, {"id": "1409.6496", "submitter": "Sergios Agapiou", "authors": "Sergios Agapiou and Peter Math\\'e", "title": "Preconditioning the prior to overcome saturation in Bayesian inverse\n  problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study Bayesian inference in statistical linear inverse problems with\nGaussian noise and priors in Hilbert space. We focus our interest on the\nposterior contraction rate in the small noise limit. Existing results suffer\nfrom a certain saturation phenomenon, when the data generating element is too\nsmooth compared to the smoothness inherent in the prior. We show how to\novercome this saturation in an empirical Bayesian framework by using a\nnon-centered data-dependent prior. The center is obtained from a\npreconditioning regularization step, which provides us with additional\ninformation to be used in the Bayesian framework. We use general techniques\nknown from regularization theory. To highlight the significance of the findings\nwe provide several examples. In particular, our approach allows to obtain and,\nusing preconditioning improve after saturation, minimax rates of contraction\nestablished in previous studies. We also establish minimax contraction rates in\ncases which have not been considered so far.\n", "versions": [{"version": "v1", "created": "Tue, 23 Sep 2014 11:35:15 GMT"}], "update_date": "2014-09-24", "authors_parsed": [["Agapiou", "Sergios", ""], ["Math\u00e9", "Peter", ""]]}, {"id": "1409.6779", "submitter": "Vladislav Kargin", "authors": "Vladislav Kargin", "title": "On estimation in the reduced-rank regression with a large number of\n  responses and predictors", "comments": "31 page", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a multivariate linear response regression in which the number of\nresponses and predictors is large and comparable with the number of\nobservations, and the rank of the matrix of regression coefficients is assumed\nto be small. We study the distribution of singular values for the matrix of\nregression coefficients and for the matrix of predicted responses. For both\nmatrices, it is found that the limit distribution of the largest singular value\nis a rescaling of the Tracy-Widom distribution. Based on this result, we\nsuggest algorithms for the model rank selection and compare them with the\nalgorithm suggested by Bunea, She and Wegkamp. Next, we design two consistent\nestimators for the singular values of the coefficient matrix, compare them, and\nderive the asymptotic distribution for one of these estimators..\n", "versions": [{"version": "v1", "created": "Wed, 24 Sep 2014 00:07:05 GMT"}, {"version": "v2", "created": "Wed, 12 Nov 2014 18:10:15 GMT"}, {"version": "v3", "created": "Mon, 1 Jun 2015 17:45:50 GMT"}], "update_date": "2015-06-02", "authors_parsed": [["Kargin", "Vladislav", ""]]}, {"id": "1409.6833", "submitter": "John Lafferty", "authors": "Yuancheng Zhu and John Lafferty", "title": "Quantized Estimation of Gaussian Sequence Models in Euclidean Balls", "comments": "Appearing at NIPS 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A central result in statistical theory is Pinsker's theorem, which\ncharacterizes the minimax rate in the normal means model of nonparametric\nestimation. In this paper, we present an extension to Pinsker's theorem where\nestimation is carried out under storage or communication constraints. In\nparticular, we place limits on the number of bits used to encode an estimator,\nand analyze the excess risk in terms of this constraint, the signal size, and\nthe noise level. We give sharp upper and lower bounds for the case of a\nEuclidean ball, which establishes the Pareto-optimal minimax tradeoff between\nstorage and risk in this setting.\n", "versions": [{"version": "v1", "created": "Wed, 24 Sep 2014 05:35:12 GMT"}], "update_date": "2014-09-25", "authors_parsed": [["Zhu", "Yuancheng", ""], ["Lafferty", "John", ""]]}, {"id": "1409.6854", "submitter": "Dennis Dobler", "authors": "Jens Bendel and Dennis Dobler and Arnold Janssen", "title": "Exponent dependence measures of survival functions and correlated\n  frailty models", "comments": "40 pages, 25 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The present article studies survival analytic aspects of semiparametric\ncopula dependence models with arbitrary univariate marginals. The underlying\nsurvival functions admit a representation via exponent measures which have an\ninterpretation within the context of hazard functions. In particular,\ncorrelated frailty survival models are linked to copulas. Additionally, the\nrelation to exponent measures of minumum-infinitely divisible distributions as\nwell as to the L\\'evy measure of the L\\'evy-Khintchine formula is pointed out.\nThe semiparametric character of the current analyses and the construction of\nsurvival times with dependencies of higher order are carried out in detail.\nMany examples including graphics give multifarious illustrations.\n", "versions": [{"version": "v1", "created": "Wed, 24 Sep 2014 08:27:32 GMT"}], "update_date": "2014-09-25", "authors_parsed": [["Bendel", "Jens", ""], ["Dobler", "Dennis", ""], ["Janssen", "Arnold", ""]]}, {"id": "1409.6885", "submitter": "Reza Hosseini", "authors": "Reza Hosseini, Akimichi Takemura", "title": "An objective look at obtaining the plotting positions for QQ-plots", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Choosing the plotting positions for the QQ-plot has been a subject of much\ndebate in the statistical and engineering literature. This paper looks at this\nproblem objectively by considering three frameworks: distribution-theoretic;\ndecision-theoretic; game-theoretic. In each framework, we derive the plotting\npositions and show that there are more than one legitimate solution depending\non the practitioner's objective. This work clarifies the choice of the plotting\npositions by allowing one to easily find the mathematical equivalent of their\nview and choose the corresponding solution. This work also discusses\napproximations to the plotting positions when no closed form is available.\n", "versions": [{"version": "v1", "created": "Wed, 24 Sep 2014 10:18:09 GMT"}], "update_date": "2014-09-25", "authors_parsed": [["Hosseini", "Reza", ""], ["Takemura", "Akimichi", ""]]}, {"id": "1409.7127", "submitter": "James Sharpnack", "authors": "James Sharpnack, Ery Arias-Castro", "title": "Exact Asymptotics for the Scan Statistic and Fast Alternatives", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of detecting a rectangle of activation in a grid of\nsensors in d-dimensions with noisy measurements. This has applications to\nmassive surveillance projects and anomaly detection in large datasets in which\none detects anomalously high measurements over rectangular regions, or more\ngenerally, blobs. Recently, the asymptotic distribution of a multiscale scan\nstatistic was established in (Kabluchko, 2011) under the null hypothesis, using\nnon-constant boundary crossing probabilities for locally-stationary Gaussian\nrandom fields derived in (Chan and Lai, 2006). Using a similar approach, we\nderive the exact asymptotic level and power of four variants of the scan\nstatistic: an oracle scan that knows the dimensions of the activation\nrectangle; the multiscale scan statistic just mentioned; an adaptive variant;\nand an epsilon-net approximation to the latter, in the spirit of (Arias-Castro,\n2005). This approximate scan runs in time near-linear in the size of the grid\nand achieves the same asymptotic power as the adaptive scan. We complement our\ntheory with some numerical experiments.\n", "versions": [{"version": "v1", "created": "Thu, 25 Sep 2014 00:27:04 GMT"}], "update_date": "2014-09-26", "authors_parsed": [["Sharpnack", "James", ""], ["Arias-Castro", "Ery", ""]]}, {"id": "1409.7441", "submitter": "Paulo Angelo Alves Resende", "authors": "Paulo Angelo Alves Resende, Chang Chung Yu Dorea", "title": "Model identification using the Efficient Determination Criterion", "comments": "27 pages", "journal-ref": "Journal of Multivariate Analysis, Volume 150, September 2016,\n  Pages 229-244", "doi": "10.1016/j.jmva.2016.06.002", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the realm of the model selection context, Akaike's and Schwarz's\ninformation criteria, AIC and BIC, have been applied successfully for decades\nfor model order identification. The Efficient Determination Criterion (EDC) is\na generalization of these criteria, proposed originally to define a strongly\nconsistent class of estimators for the dependency order of a multiple Markov\nchain. In this work, the EDC is generalized to partially nested models, which\nencompass many other order identification problems. Based on some assumptions,\na class of strongly consistent estimators is established in this general\nenvironment. This framework is applied to BEKK multivariate GARCH models and,\nin particular, the strong consistency of the order estimator based on BIC is\nestablished for these models.\n", "versions": [{"version": "v1", "created": "Thu, 25 Sep 2014 23:55:42 GMT"}, {"version": "v2", "created": "Sun, 5 Oct 2014 20:53:34 GMT"}], "update_date": "2016-07-20", "authors_parsed": [["Resende", "Paulo Angelo Alves", ""], ["Dorea", "Chang Chung Yu", ""]]}, {"id": "1409.7482", "submitter": "Bent J{\\o}rgensen", "authors": "Bent J{\\o}rgensen and C\\'elestin C. Kokonendji", "title": "Discrete Dispersion Models and Their Tweedie Asymptotics", "comments": "29 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a class of two-parameter discrete dispersion models, obtained by\ncombining convolution with a factorial tilting operation, similar to\nexponential dispersion models which combine convolution and exponential\ntilting. The equidispersed Poisson model has a special place in this approach,\nwhereas several overdispersed discrete distributions, such as the Neyman Type\nA, P\\'olya-Aeppli, negative binomial and Poisson-inverse Gaussian, turn out to\nbe Poisson-Tweedie factorial dispersion models with power dispersion functions,\nanalogous to ordinary Tweedie exponential dispersion models with power variance\nfunctions. Using the factorial cumulant generating function as tool, we\nintroduce a dilation operation as a discrete analogue of scaling, generalizing\nbinomial thinning. The Poisson-Tweedie factorial dispersion models are closed\nunder dilation, which in turn leads to a Poisson-Tweedie asymptotic framework\nwhere Poisson-Tweedie models appear as dilation limits. This unifies many\ndiscrete convergence results and leads to Poisson and Hermite convergence\nresults, similar to the law of large numbers and the central limit theorem,\nrespectively. The dilation operator also leads to a duality transformation\nwhich in some cases transforms overdispersion into underdispersion and\nvice-versa. Many of the results have multivariate analogues, and in particular\nwe consider a class of multivariate Poisson-Tweedie models, a multivariate\nnotion of over- and underdispersion, and a multivariate zero-inflation index.\n", "versions": [{"version": "v1", "created": "Fri, 26 Sep 2014 06:50:22 GMT"}], "update_date": "2014-09-29", "authors_parsed": [["J\u00f8rgensen", "Bent", ""], ["Kokonendji", "C\u00e9lestin C.", ""]]}, {"id": "1409.7548", "submitter": "Walid Hachem", "authors": "Walid Hachem, Adrien Hardy, Jamal Najim", "title": "Large complex correlated Wishart matrices: Fluctuations and asymptotic\n  independence at the edges", "comments": "Published at http://dx.doi.org/10.1214/15-AOP1022 in the Annals of\n  Probability (http://www.imstat.org/aop/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Probability 2016, Vol. 44, No. 3, 2264-2348", "doi": "10.1214/15-AOP1022", "report-no": "IMS-AOP-AOP1022", "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the asymptotic behavior of eigenvalues of large complex correlated\nWishart matrices at the edges of the limiting spectrum. In this setting, the\nsupport of the limiting eigenvalue distribution may have several connected\ncomponents. Under mild conditions for the population matrices, we show that for\nevery generic positive edge of that support, there exists an extremal\neigenvalue which converges almost surely toward that edge and fluctuates\naccording to the Tracy-Widom law at the scale $N^{2/3}$. Moreover, given\nseveral generic positive edges, we establish that the associated extremal\neigenvalue fluctuations are asymptotically independent. Finally, when the\nleftmost edge is the origin (hard edge), the fluctuations of the smallest\neigenvalue are described by mean of the Bessel kernel at the scale $N^2$.\n", "versions": [{"version": "v1", "created": "Fri, 26 Sep 2014 12:01:42 GMT"}, {"version": "v2", "created": "Mon, 6 Jun 2016 05:57:22 GMT"}], "update_date": "2016-06-07", "authors_parsed": [["Hachem", "Walid", ""], ["Hardy", "Adrien", ""], ["Najim", "Jamal", ""]]}, {"id": "1409.7559", "submitter": "Hans J. Haubold", "authors": "A.M. Mathai", "title": "Evaluation of Matrix-variate Gamma and Beta Integrals as Multiple\n  Integrals and Kober Fractional Integral Operators in the Complex Matrix\n  Variate Case", "comments": "13 pages, LaTeX", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explicit evaluations of matrix-variate gamma and beta integrals in the\ncomplex domain by using conventional procedures is extremely difficult. Such an\nevaluation will reveal the structure of these matrix-variate integrals. In this\narticle, explicit evaluations of matrix-variate gamma and beta integrals in the\ncomplex domain for the order of the matrix p = 1; 2 are given. Then fractional\nintegral operators of the Kober type are given for some specific cases of the\narbitrary function. A formal definition of fractional integrals in the complex\nmatrix-variate case was given by the author earlier as the M-convolution of\nproducts and ratios, where Kober operators become a special class of fractional\nintegral operators.\n", "versions": [{"version": "v1", "created": "Fri, 26 Sep 2014 12:50:25 GMT"}], "update_date": "2014-09-29", "authors_parsed": [["Mathai", "A. M.", ""]]}, {"id": "1409.7561", "submitter": "Hans J. Haubold", "authors": "A.M. Mathai", "title": "Explicit Evaluations of Matrix-variate Gamma and Beta Integrals in the\n  Real and Complex Cases", "comments": "17 pages, LaTeX", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matrix transformations in terms of triangular matrices is the easiest method\nof evaluating matrix-variate gamma and beta integrals in the real and complex\ncases. Here we give several procedures of explicit evaluation of gamma and beta\nintegrals in the general real and complex situations. The procedure also\nreveals the structure of these matrix-variate integrals. Apart from the\nevaluation of matrix-variate gamma and beta integrals, the procedure can also\nbe applied to evaluate such integrals explicitly in similar situations. Various\nmethods described here will be useful to those who are working on integrals\ninvolving real-valued scalar functions of matrix argument in general and gamma\nand beta integrals in particular.\n", "versions": [{"version": "v1", "created": "Fri, 26 Sep 2014 13:02:53 GMT"}], "update_date": "2014-09-29", "authors_parsed": [["Mathai", "A. M.", ""]]}, {"id": "1409.7602", "submitter": "Megan Owen", "authors": "Dennis Barden, Huiling Le, Megan Owen", "title": "Limiting Behaviour of Fr\\'echet Means in the Space of Phylogenetic Trees", "comments": "29 pages; improved exposition", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.MG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As demonstrated in our previous work on ${\\boldsymbol T}_{4}$, the space of\nphylogenetic trees with four leaves, the global, as well as the local,\ntopological structure of the space plays an important role in the non-classical\nlimiting behaviour of the sample Fr\\'echet means of a probability distribution\non ${\\boldsymbol T}_{4}$. Nevertheless, the techniques used in that paper were\nspecific to ${\\boldsymbol T}_{4}$ and cannot be adapted to analyse Fr\\'echet\nmeans in the space ${\\boldsymbol T}_{m}$ of phylogenetic trees with\n$m(\\geqslant5)$ leaves. To investigate the latter, this paper first studies the\nlog map of ${\\boldsymbol T}_{m}$, a generalisation of the inverse of the\nexponential map on a Riemannian manifold. Then, in terms of a modified version\nof the log map, we characterise Fr\\'echet means in ${\\boldsymbol T}_{m}$ that\nlie in top-dimensional or co-dimension one strata. We derive the limiting\ndistributions for the corresponding sample Fr\\'echet means, generalising our\nprevious results. In particular, the results show that, although they are\nrelated to the Gaussian distribution, the forms taken by the limiting\ndistributions depend on the co-dimensions of the strata in which the Fr\\'echet\nmeans lie.\n", "versions": [{"version": "v1", "created": "Fri, 26 Sep 2014 15:30:52 GMT"}, {"version": "v2", "created": "Sun, 2 Aug 2015 03:24:17 GMT"}, {"version": "v3", "created": "Thu, 4 Aug 2016 23:30:56 GMT"}], "update_date": "2016-08-08", "authors_parsed": [["Barden", "Dennis", ""], ["Le", "Huiling", ""], ["Owen", "Megan", ""]]}, {"id": "1409.7675", "submitter": "Mauricio Romero", "authors": "Mauricio Romero and Alvaro Riascos and Diego Jara", "title": "A derivation of the optimal answer-copying index and some applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiple-choice exams are frequently used as an efficient and objective\nmethod to assess learning but they are more vulnerable to answer-copying than\ntests based on open questions. Several statistical tests (known as indices in\nthe literature) have been proposed to detect cheating; however, to the best of\nour knowledge they all lack mathematical support that guarantees optimality in\nany sense. We partially fill this void by deriving the uniform most powerful\n(UMP) under the assumption that the response distribution is known. In\npractice, however, we must estimate a behavioral model that yields a response\ndistribution for each question. We calculate the empirical type-I and type-II\nerror rates for several indices that assume different behavioral models using\nsimulations based on real data from twelve nationwide multiple-choice exams\ntaken by 5th and 9th graders in Colombia. We find that the index with the\nhighest power among those studied, subject to the restriction of preserving the\ntype-I error, is one based on the work of Wollack (1997) and Linden and\nSotaridona (2006) and is superior to the indices studied and developed by\nWesolowsky (2000) and Frary, Tideman, and Watts (1977). We compare the results\nof applying this index to all 12 exams and find that examination rooms with\nstricter proctoring have a lower level of copying. Finally, a Bonferroni\ncorrection to control for the false positive rate is proposed to detect massive\ncheating.\n", "versions": [{"version": "v1", "created": "Fri, 26 Sep 2014 19:36:09 GMT"}], "update_date": "2014-09-29", "authors_parsed": [["Romero", "Mauricio", ""], ["Riascos", "Alvaro", ""], ["Jara", "Diego", ""]]}, {"id": "1409.7685", "submitter": "Miklos Z. Racz", "authors": "S\\'ebastien Bubeck, Ronen Eldan, Elchanan Mossel, Mikl\\'os Z. R\\'acz", "title": "From trees to seeds: on the inference of the seed from large trees in\n  the uniform attachment model", "comments": "26 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.DM cs.SI math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the influence of the seed in random trees grown according to the\nuniform attachment model, also known as uniform random recursive trees. We show\nthat different seeds lead to different distributions of limiting trees from a\ntotal variation point of view. To do this, we construct statistics that\nmeasure, in a certain well-defined sense, global \"balancedness\" properties of\nsuch trees. Our paper follows recent results on the same question for the\npreferential attachment model.\n", "versions": [{"version": "v1", "created": "Fri, 26 Sep 2014 19:53:26 GMT"}, {"version": "v2", "created": "Tue, 21 Oct 2014 03:37:52 GMT"}], "update_date": "2014-10-22", "authors_parsed": [["Bubeck", "S\u00e9bastien", ""], ["Eldan", "Ronen", ""], ["Mossel", "Elchanan", ""], ["R\u00e1cz", "Mikl\u00f3s Z.", ""]]}, {"id": "1409.7776", "submitter": "Wei Gao", "authors": "Wei Gao, Wicher Bergsma and Qiwei Yao", "title": "Estimation for Dynamic and Static Panel Probit Models with Large\n  Individual Effects", "comments": "22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For discrete panel data, the dynamic relationship between successive\nobservations is often of interest. We consider a dynamic probit model for short\npanel data. A problem with estimating the dynamic parameter of interest is that\nthe model contains a large number of nuisance parameters, one for each\nindividual. Heckman proposed to use maximum likelihood estimation of the\ndynamic parameter, which, however, does not perform well if the individual\neffects are large. We suggest new estimators for the dynamic parameter, based\non the assumption that the individual parameters are random and possibly large.\nTheoretical properties of our estimators are derived and a simulation study\nshows they have some advantages compared to Heckman's estimator.\n", "versions": [{"version": "v1", "created": "Sat, 27 Sep 2014 07:25:19 GMT"}], "update_date": "2014-09-30", "authors_parsed": [["Gao", "Wei", ""], ["Bergsma", "Wicher", ""], ["Yao", "Qiwei", ""]]}, {"id": "1409.8047", "submitter": "Hien Nguyen", "authors": "Hien D. Nguyen and Ian A. Wood", "title": "Asymptotic Normality of the Maximum Pseudolikelihood Estimator for Fully\n  Visible Boltzmann Machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Boltzmann machines (BMs) are a class of binary neural networks for which\nthere have been numerous proposed methods of estimation. Recently, it has been\nshown that in the fully visible case of the BM, the method of maximum\npseudolikelihood estimation (MPLE) results in parameter estimates which are\nconsistent in the probabilistic sense. In this article, we investigate the\nproperties of MPLE for the fully visible BMs further, and prove that MPLE also\nyields an asymptotically normal parameter estimator. These results can be used\nto construct confidence intervals and to test statistical hypotheses. We\nsupport our theoretical results by showing that the estimator behaves as\nexpected in a simulation study.\n", "versions": [{"version": "v1", "created": "Mon, 29 Sep 2014 09:35:46 GMT"}], "update_date": "2014-09-30", "authors_parsed": [["Nguyen", "Hien D.", ""], ["Wood", "Ian A.", ""]]}, {"id": "1409.8150", "submitter": "Adam D. Bull", "authors": "Adam D. Bull", "title": "Near-optimal estimation of jump activity in semimartingales", "comments": "Published at http://dx.doi.org/10.1214/15-AOS1349 in the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2016, Vol. 44, No. 1, 58-86", "doi": "10.1214/15-AOS1349", "report-no": "IMS-AOS-AOS1349", "categories": "math.ST q-fin.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In quantitative finance, we often model asset prices as semimartingales, with\ndrift, diffusion and jump components. The jump activity index measures the\nstrength of the jumps at high frequencies, and is of interest both in model\nselection and fitting, and in volatility estimation. In this paper, we give a\nnovel estimate of the jump activity, together with corresponding confidence\nintervals. Our estimate improves upon previous work, achieving near-optimal\nrates of convergence, and good finite-sample performance in Monte-Carlo\nexperiments.\n", "versions": [{"version": "v1", "created": "Mon, 29 Sep 2014 15:18:31 GMT"}, {"version": "v2", "created": "Fri, 20 Mar 2015 11:03:58 GMT"}, {"version": "v3", "created": "Tue, 12 Jan 2016 12:46:58 GMT"}], "update_date": "2016-01-13", "authors_parsed": [["Bull", "Adam D.", ""]]}, {"id": "1409.8269", "submitter": "Noel Erp van", "authors": "H.R.N. van Erp, R.O. Linger, and P.H.A.J.M. van Gelder", "title": "Fact Sheet Research on Bayesian Decision Theory", "comments": "The first and third authors are affiliated with the Faculty of\n  Technology, Policy and Management, TU Delft. The second author is affiliated\n  with the Faculty of Clinical Epidemiology, RUG UMCG", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST q-fin.GN stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this fact sheet we give some preliminary research results on the Bayesian\nDecision Theory. This theory has been under construction for the past two\nyears. But what started as an intuitive enough idea, now seems to have the\nmakings of something more fundamental.\n", "versions": [{"version": "v1", "created": "Fri, 26 Sep 2014 18:39:02 GMT"}, {"version": "v2", "created": "Tue, 4 Nov 2014 17:11:32 GMT"}, {"version": "v3", "created": "Mon, 12 Jan 2015 16:01:23 GMT"}, {"version": "v4", "created": "Mon, 26 Jan 2015 09:29:17 GMT"}], "update_date": "2015-01-27", "authors_parsed": [["van Erp", "H. R. N.", ""], ["Linger", "R. O.", ""], ["van Gelder", "P. H. A. J. M.", ""]]}, {"id": "1409.8363", "submitter": "Gael Martin Prof", "authors": "Gael M. Martin, Brendan P.M. McCabe, Worapree Maneesoonthorn and\n  Christian P. Robert", "title": "Approximate Bayesian Computation in State Space Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.CO stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new approach to inference in state space models is proposed, based on\napproximate Bayesian computation (ABC). ABC avoids evaluation of the likelihood\nfunction by matching observed summary statistics with statistics computed from\ndata simulated from the true process; exact inference being feasible only if\nthe statistics are sufficient. With finite sample sufficiency unattainable in\nthe state space setting, we seek asymptotic sufficiency via the maximum\nlikelihood estimator (MLE) of the parameters of an auxiliary model. We prove\nthat this auxiliary model-based approach achieves Bayesian consistency, and\nthat - in a precise limiting sense - the proximity to (asymptotic) sufficiency\nyielded by the MLE is replicated by the score. In multiple parameter settings a\nseparate treatment of scalar parameters, based on integrated likelihood\ntechniques, is advocated as a way of avoiding the curse of dimensionality. Some\nattention is given to a structure in which the state variable is driven by a\ncontinuous time process, with exact inference typically infeasible in this case\nas a result of intractable transitions. The ABC method is demonstrated using\nthe unscented Kalman filter as a fast and simple way of producing an\napproximation in this setting, with a stochastic volatility model for financial\nreturns used for illustration.\n", "versions": [{"version": "v1", "created": "Tue, 30 Sep 2014 02:11:25 GMT"}], "update_date": "2014-10-01", "authors_parsed": [["Martin", "Gael M.", ""], ["McCabe", "Brendan P. M.", ""], ["Maneesoonthorn", "Worapree", ""], ["Robert", "Christian P.", ""]]}, {"id": "1409.8491", "submitter": "Felix Abramovich", "authors": "Felix Abramovich and Vadim Grinshtein", "title": "Model selection and minimax estimation in generalized linear models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider model selection in generalized linear models (GLM) for\nhigh-dimensional data and propose a wide class of model selection criteria\nbased on penalized maximum likelihood with a complexity penalty on the model\nsize. We derive a general nonasymptotic upper bound for the expected\nKullback-Leibler divergence between the true distribution of the data and that\ngenerated by a selected model, and establish the corresponding minimax lower\nbounds for sparse GLM. For the properly chosen (nonlinear) penalty, the\nresulting penalized maximum likelihood estimator is shown to be asymptotically\nminimax and adaptive to the unknown sparsity. We discuss also possible\nextensions of the proposed approach to model selection in GLM under additional\nstructural constraints and aggregation.\n", "versions": [{"version": "v1", "created": "Tue, 30 Sep 2014 11:25:39 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2015 10:11:50 GMT"}, {"version": "v3", "created": "Wed, 30 Mar 2016 08:20:50 GMT"}], "update_date": "2016-03-31", "authors_parsed": [["Abramovich", "Felix", ""], ["Grinshtein", "Vadim", ""]]}, {"id": "1409.8502", "submitter": "Juho Kokkala", "authors": "Juho Kokkala and Simo S\\\"arkk\\\"a", "title": "Combining Particle MCMC with Rao-Blackwellized Monte Carlo Data\n  Association for Parameter Estimation in Multiple Target Tracking", "comments": "Revised version. 43 pages, 4 figures", "journal-ref": null, "doi": "10.1016/j.dsp.2015.04.004", "report-no": null, "categories": "stat.ME math.DS math.ST stat.AP stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider state and parameter estimation in multiple target tracking\nproblems with data association uncertainties and unknown number of targets. We\nshow how the problem can be recast into a conditionally linear Gaussian\nstate-space model with unknown parameters and present an algorithm for\ncomputationally efficient inference on the resulting model. The proposed\nalgorithm is based on combining the Rao-Blackwellized Monte Carlo data\nassociation algorithm with particle Markov chain Monte Carlo algorithms to\njointly estimate both parameters and data associations. Both particle marginal\nMetropolis-Hastings and particle Gibbs variants of particle MCMC are\nconsidered. We demonstrate the performance of the method both using simulated\ndata and in a real-data case study of using multiple target tracking to\nestimate the brown bear population in Finland.\n", "versions": [{"version": "v1", "created": "Tue, 30 Sep 2014 11:59:41 GMT"}, {"version": "v2", "created": "Fri, 20 Feb 2015 21:03:46 GMT"}], "update_date": "2015-10-05", "authors_parsed": [["Kokkala", "Juho", ""], ["S\u00e4rkk\u00e4", "Simo", ""]]}, {"id": "1409.8542", "submitter": "Gerko Vink", "authors": "Gerko Vink and Stef van Buuren", "title": "Pooling multiple imputations when the sample happens to be the\n  population", "comments": "6 pages, 1 figure, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current pooling rules for multiply imputed data assume infinite populations.\nIn some situations this assumption is not feasible as every unit in the\npopulation has been observed, potentially leading to over-covered population\nestimates. We simplify the existing pooling rules for situations where the\nsampling variance is not of interest. We compare these rules to the\nconventional pooling rules and demonstrate their use in a situation where there\nis no sampling variance. Using the standard pooling rules in situations where\nsampling variance should not be considered, leads to overestimation of the\nvariance of the estimates of interest, especially when the amount of\nmissingness is not very large. As a result, populations estimates are\nover-covered, which may lead to a loss of statistical power. We conclude that\nthe theory of multiple imputation can be extended to the situation where the\nsample happens to be the population. The simplified pooling rules can be easily\nimplemented to obtain valid inference in cases where we have observed\nessentially all units and in simulation studies addressing the missingness\nmechanism only.\n", "versions": [{"version": "v1", "created": "Tue, 30 Sep 2014 13:43:14 GMT"}], "update_date": "2014-10-01", "authors_parsed": [["Vink", "Gerko", ""], ["van Buuren", "Stef", ""]]}, {"id": "1409.8557", "submitter": "Sara van de Geer", "authors": "Sara van de Geer", "title": "Statistical Theory for High-Dimensional Models", "comments": "35 pages, lecture notes", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  These lecture notes consist of three chapters. In the first chapter we\npresent oracle inequalities for the prediction error of the Lasso and\nsquare-root Lasso and briefly describe the scaled Lasso. In the second chapter\nwe establish asymptotic linearity of a de-sparsified Lasso. This implies\nasymptotic normality under certain conditions and therefore can be used to\nconstruct confidence intervals for parameters of interest. A similar line of\nreasoning can be invoked to derive bounds in sup-norm for the Lasso and\nasymptotic linearity of de-sparsified estimators of a precision matrix. In the\nthird chapter we consider chaining and the more general generic chaining method\ndeveloped by Talagrand. This allows one to bound suprema of random processes.\nConcentration inequalities are refined probability inequalities, mostly again\nfor suprema of random processes. We combine the two. We prove a deviation\ninequality directly using (generic) chaining.\n", "versions": [{"version": "v1", "created": "Tue, 30 Sep 2014 14:17:02 GMT"}], "update_date": "2014-10-01", "authors_parsed": [["van de Geer", "Sara", ""]]}, {"id": "1409.8565", "submitter": "Zongming Ma", "authors": "Chao Gao, Zongming Ma, Harrison H. Zhou", "title": "Sparse CCA: Adaptive Estimation and Computational Barriers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Canonical correlation analysis is a classical technique for exploring the\nrelationship between two sets of variables. It has important applications in\nanalyzing high dimensional datasets originated from genomics, imaging and other\nfields. This paper considers adaptive minimax and computationally tractable\nestimation of leading sparse canonical coefficient vectors in high dimensions.\nFirst, we establish separate minimax estimation rates for canonical coefficient\nvectors of each set of random variables under no structural assumption on\nmarginal covariance matrices. Second, we propose a computationally feasible\nestimator to attain the optimal rates adaptively under an additional sample\nsize condition. Finally, we show that a sample size condition of this kind is\nneeded for any randomized polynomial-time estimator to be consistent, assuming\nhardness of certain instances of the Planted Clique detection problem. The\nresult is faithful to the Gaussian models used in the paper. As a byproduct, we\nobtain the first computational lower bounds for sparse PCA under the Gaussian\nsingle spiked covariance model.\n", "versions": [{"version": "v1", "created": "Tue, 30 Sep 2014 14:36:15 GMT"}, {"version": "v2", "created": "Mon, 1 Dec 2014 14:12:51 GMT"}, {"version": "v3", "created": "Fri, 9 Jan 2015 21:58:24 GMT"}, {"version": "v4", "created": "Mon, 4 Apr 2016 18:37:29 GMT"}], "update_date": "2016-04-05", "authors_parsed": [["Gao", "Chao", ""], ["Ma", "Zongming", ""], ["Zhou", "Harrison H.", ""]]}, {"id": "1409.8571", "submitter": "Guangyu Yang", "authors": "Hui Jiang, Mingming Yu, Guangyu Yang", "title": "Asymptotic distributions related to mildly-explosive second order\n  autoregressive models", "comments": "27pages,10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the normalized least squares estimator of the\nparameter in a mildly-explosive first-order autoregressive model with dependent\nerrors which are modeled as a mildly-explosive AR(1) process. We prove that the\nestimator has a Cauchy limit law which provides a bridge between moderate\ndeviation asymptotics and the earlier results on the local to unity and\nexplosive autoregressive models. In particular, the results can be applied to\nunderstand the near-integrated second order autoregressive processes.\nSimulation studies are also carried out to assess the performance of least\nsquares estimation in finite samples.\n", "versions": [{"version": "v1", "created": "Tue, 30 Sep 2014 14:48:28 GMT"}], "update_date": "2014-10-01", "authors_parsed": [["Jiang", "Hui", ""], ["Yu", "Mingming", ""], ["Yang", "Guangyu", ""]]}, {"id": "1409.8621", "submitter": "Christian Palmes", "authors": "Christian Palmes", "title": "Copula Relations in Compound Poisson Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate in multidimensional compound Poisson processes (CPP) the\nrelation between the dependence structure of the jump distribution and the\ndependence structure of the respective components of the CPP itself. For this\npurpose the asymptotic $\\lambda t\\to \\infty$ is considered, where $\\lambda$\ndenotes the intensity and $t$ the time point of the CPP. For modeling the\ndependence structures we are using the concept of copulas. We prove that the\ncopula of a CPP converges under quite general assumptions to a specific\nGaussian copula, depending on the underlying jump distribution.\n  Let $F$ be a $d$-dimensional jump distribution $(d\\geq 2)$, $\\lambda>0$ and\nlet $\\Psi(\\lambda,F)$ be the distribution of the corresponding CPP with\nintensity $\\lambda$ at the time point $1$. Further, denote the operator which\nmaps a $d$-dimensional distribution on its copula as $\\mathcal{T}$. The\nstarting point of our investigation was the validity of the equation\n\\begin{equation} \\label{marFreeEq}\n\\mathcal{T}(\\Psi(\\lambda,F))=\\mathcal{T}(\\Psi(\\lambda,\\mathcal{T}F)).\n\\end{equation} Our asymptotic theory implies that this equation is, in general,\nnot true.\n  A simulation study that confirms our theoretical results is given in the last\nsection.\n", "versions": [{"version": "v1", "created": "Tue, 30 Sep 2014 16:33:29 GMT"}], "update_date": "2014-10-01", "authors_parsed": [["Palmes", "Christian", ""]]}, {"id": "1409.8627", "submitter": "Christian Palmes", "authors": "Christian Palmes", "title": "Low Frequency L\\'evy Copula Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $X$ be a $d$-dimensional L\\'evy process with L\\'evy triplet\n$(\\Sigma,\\nu,\\alpha)$ and $d\\geq 2$. Given the low frequency observations\n$(X_t)_{t=1,\\ldots,n}$, the dependence structure of the jumps of $X$ is\nestimated. The L\\'evy measure $\\nu$ describes the average jump behavior in a\ntime unit. Thus, the aim is to estimate the dependence structure of $\\nu$ by\nestimating the L\\'evy copula $\\mathfrak{C}$ of $\\nu$, cf. Kallsen and Tankov\n\\cite{KalTan}.\n  We use the low frequency techniques presented in a one dimensional setting in\nNeumann and Rei{\\ss} \\cite{NeuRei} and Nickl and Rei{\\ss} \\cite{NicRei} to\nconstruct a L\\'evy copula estimator $\\widehat{\\mathfrak{C}}_n$ based on the\nabove $n$ observations. In doing so we prove $$\\widehat{\\mathfrak{C}}_n\\to\n\\mathfrak{C},\\quad n\\to\\infty$$ uniformly on compact sets bounded away from\nzero with the convergence rate $\\sqrt{\\log n}$. This convergence holds under\nquite general assumptions, which also include L\\'evy triplets with $\\Sigma\\neq\n0$ and $\\nu$ of arbitrary Blumenthal-Getoor index $0\\leq\\beta\\leq 2$. Note that\nin a low frequency observation scheme, it is statistically difficult to\ndistinguish between infinitely many small jumps and a Brownian motion part.\nHence, the rather slow convergence rate $\\sqrt{\\log n}$ is not surprising.\n  In the complementary case of a compound Poisson process (CPP), an estimator\n$\\widehat{C}_n$ for the copula $C$ of the jump distribution of the CPP is\nconstructed under the same observation scheme. This copula $C$ is the analogue\nto the L\\'evy copula $\\mathfrak{C}$ in the finite jump activity case, i.e. the\nCPP case. Here we establish $$\\widehat{C}_n \\to C,\\quad n\\to\\infty$$ with the\nconvergence rate $\\sqrt{n}$ uniformly on compact sets bounded away from zero.\n  Both convergence rates are optimal in the sense of Neumann and Rei{\\ss}.\n", "versions": [{"version": "v1", "created": "Tue, 30 Sep 2014 16:50:46 GMT"}], "update_date": "2014-10-01", "authors_parsed": [["Palmes", "Christian", ""]]}]