[{"id": "1901.00226", "submitter": "Alexandra Suvorikova", "authors": "Alexey Kroshnin, Vladimir Spokoiny and Alexandra Suvorikova", "title": "Statistical inference for Bures-Wasserstein barycenters", "comments": "37 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we introduce the concept of Bures-Wasserstein barycenter $Q_*$,\nthat is essentially a Fr\\'echet mean of some distribution $\\mathbb{P}$\nsupported on a subspace of positive semi-definite Hermitian operators\n$\\mathbb{H}_{+}(d)$. We allow a barycenter to be restricted to some affine\nsubspace of $\\mathbb{H}_{+}(d)$ and provide conditions ensuring its existence\nand uniqueness. We also investigate convergence and concentration properties of\nan empirical counterpart of $Q_*$ in both Frobenius norm and Bures-Wasserstein\ndistance, and explain, how obtained results are connected to optimal\ntransportation theory and can be applied to statistical inference in quantum\nmechanics.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jan 2019 00:58:31 GMT"}, {"version": "v2", "created": "Mon, 11 Feb 2019 12:16:42 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Kroshnin", "Alexey", ""], ["Spokoiny", "Vladimir", ""], ["Suvorikova", "Alexandra", ""]]}, {"id": "1901.00304", "submitter": "Dong Xia", "authors": "Dong Xia", "title": "Normal Approximation and Confidence Region of Singular Subspaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT math.IT stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is on the normal approximation of singular subspaces when the\nnoise matrix has i.i.d. entries. Our contributions are three-fold. First, we\nderive an explicit representation formula of the empirical spectral projectors.\nThe formula is neat and holds for deterministic matrix perturbations. Second,\nwe calculate the expected projection distance between the empirical singular\nsubspaces and true singular subspaces. Our method allows obtaining arbitrary\n$k$-th order approximation of the expected projection distance. Third, we prove\nthe non-asymptotical normal approximation of the projection distance with\ndifferent levels of bias corrections. By the $\\lceil \\log(d_1+d_2)\\rceil$-th\norder bias corrections, the asymptotical normality holds under optimal\nsignal-to-noise ration (SNR) condition where $d_1$ and $d_2$ denote the matrix\nsizes. In addition, it shows that higher order approximations are unnecessary\nwhen $|d_1-d_2|=O((d_1+d_2)^{1/2})$. Finally, we provide comprehensive\nsimulation results to merit our theoretic discoveries.\n  Unlike the existing results, our approach is non-asymptotical and the\nconvergence rates are established. Our method allows the rank $r$ to diverge as\nfast as $o((d_1+d_2)^{1/3})$. Moreover, our method requires no eigen-gap\ncondition (except the SNR) and no constraints between $d_1$ and $d_2$.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jan 2019 09:23:50 GMT"}, {"version": "v2", "created": "Mon, 10 Jun 2019 08:54:16 GMT"}, {"version": "v3", "created": "Fri, 5 Jul 2019 13:27:26 GMT"}, {"version": "v4", "created": "Fri, 26 Jul 2019 03:05:24 GMT"}], "update_date": "2019-07-29", "authors_parsed": [["Xia", "Dong", ""]]}, {"id": "1901.00331", "submitter": "Maciej  Skorski", "authors": "Maciej Skorski", "title": "Kernel Density Estimation Bias under Minimal Assumptions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kernel Density Estimation is a very popular technique of approximating a\ndensity function from samples. The accuracy is generally well-understood and\ndepends, roughly speaking, on the kernel decay and local smoothness of the true\ndensity. However concrete statements in the literature are often invoked in\nvery specific settings (simplified or overly conservative assumptions) or miss\nimportant but subtle points (e.g. it is common to heuristically apply Taylor's\nexpansion globally without referring to compactness). The contribution of this\npaper is twofold (a) we demonstrate that, when the bandwidth is an arbitrary\ninvertible matrix going to zero, it is necessary to keep a certain balance\nbetween the \\emph{kernel decay} and \\emph{magnitudes of bandwidth eigenvalues};\nin fact, without the sufficient decay the estimates may not be even bounded (b)\nwe give a rigorous derivation of bounds with explicit constants for the bias,\nunder possibly minimal assumptions. This connects the kernel decay, bandwidth\nnorm, bandwidth determinant and density smoothness. It has been folklore that\nthe issue with Taylor's formula can be fixed with more complicated assumptions\non the density (for example p. 95 of \"Kernel Smoothing\" by Wand and Jones); we\nshow that this is actually not necessary and can be handled by the kernel decay\nalone.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jan 2019 12:09:21 GMT"}], "update_date": "2019-01-03", "authors_parsed": [["Skorski", "Maciej", ""]]}, {"id": "1901.00359", "submitter": "Davy Paindaveine", "authors": "Davy Paindaveine and Thomas Verdebout", "title": "Inference for spherical location under high concentration", "comments": "51 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the fact that circular or spherical data are often much\nconcentrated around a location $\\pmb\\theta$, we consider inference about\n$\\pmb\\theta$ under \"high concentration\" asymptotic scenarios for which the\nprobability of any fixed spherical cap centered at $\\pmb\\theta$ converges to\none as the sample size $n$ diverges to infinity. Rather than restricting to\nFisher-von Mises-Langevin distributions, we consider a much broader,\nsemiparametric, class of rotationally symmetric distributions indexed by the\nlocation parameter $\\pmb\\theta$, a scalar concentration parameter $\\kappa$ and\na functional nuisance $f$. We determine the class of distributions for which\nhigh concentration is obtained as $\\kappa$ diverges to infinity. For such\ndistributions, we then consider inference (point estimation, confidence zone\nestimation, hypothesis testing) on $\\pmb\\theta$ in asymptotic scenarios where\n$\\kappa_n$ diverges to infinity at an arbitrary rate with the sample size $n$.\nOur asymptotic investigation reveals that, interestingly, optimal inference\nprocedures on $\\pmb\\theta$ show consistency rates that depend on $f$. Using\nasymptotics \"\\`a la Le Cam\", we show that the spherical mean is, at any $f$, a\nparametrically super-efficient estimator of $\\pmb\\theta$ and that the Watson\nand Wald tests for $\\mathcal{H}_0:{\\pmb\\theta}={\\pmb\\theta}_0$ enjoy similar,\nnon-standard, optimality properties. We illustrate our results through\nsimulations and treat a real data example. On a technical point of view, our\nasymptotic derivations require challenging expansions of rotationally symmetric\nfunctionals for large arguments of $f$.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jan 2019 13:50:49 GMT"}, {"version": "v2", "created": "Sun, 9 Jun 2019 08:44:38 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Paindaveine", "Davy", ""], ["Verdebout", "Thomas", ""]]}, {"id": "1901.00555", "submitter": "Jonathan Scarlett", "authors": "Jonathan Scarlett and Volkan Cevher", "title": "An Introductory Guide to Fano's Inequality with Applications in\n  Statistical Estimation", "comments": "Chapter in upcoming book \"Information-Theoretic Methods in Data\n  Science\" (Cambridge University Press) edited by Yonina Eldar and Miguel\n  Rodrigues. (v2 & v3) Minor corrections and edits", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information theory plays an indispensable role in the development of\nalgorithm-independent impossibility results, both for communication problems\nand for seemingly distinct areas such as statistics and machine learning. While\nnumerous information-theoretic tools have been proposed for this purpose, the\noldest one remains arguably the most versatile and widespread: Fano's\ninequality. In this chapter, we provide a survey of Fano's inequality and its\nvariants in the context of statistical estimation, adopting a versatile\nframework that covers a wide range of specific problems. We present a variety\nof key tools and techniques used for establishing impossibility results via\nthis approach, and provide representative examples covering group testing,\ngraphical model selection, sparse linear regression, density estimation, and\nconvex optimization.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jan 2019 23:56:10 GMT"}, {"version": "v2", "created": "Fri, 16 Aug 2019 03:54:52 GMT"}, {"version": "v3", "created": "Mon, 25 Nov 2019 05:34:42 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Scarlett", "Jonathan", ""], ["Cevher", "Volkan", ""]]}, {"id": "1901.00578", "submitter": "Zheng Zhang", "authors": "Jiali Luan and Zheng Zhang", "title": "Prediction of multi-dimensional spatial variation data via Bayesian\n  tensor completion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.CO stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a multi-dimensional computational method to predict the\nspatial variation data inside and across multiple dies of a wafer. This\ntechnique is based on tensor computation. A tensor is a high-dimensional\ngeneralization of a matrix or a vector. By exploiting the hidden low-rank\nproperty of a high-dimensional data array, the large amount of unknown\nvariation testing data may be predicted from a few random measurement samples.\nThe tensor rank, which decides the complexity of a tensor representation, is\ndecided by an available variational Bayesian approach. Our approach is\nvalidated by a practical chip testing data set, and it can be easily\ngeneralized to characterize the process variations of multiple wafers. Our\napproach is more efficient than the previous virtual probe techniques in terms\nof memory and computational cost when handling high-dimensional chip testing\ndata.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jan 2019 02:25:30 GMT"}], "update_date": "2019-01-04", "authors_parsed": [["Luan", "Jiali", ""], ["Zhang", "Zheng", ""]]}, {"id": "1901.00833", "submitter": "Marcos Matabuena", "authors": "Marcos Matabuena", "title": "Energy distance and kernel mean embedding for two sample survival test", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this article a new family of tests is proposed for the comparison problem\nof the equality of distribution of two-sample under right censoring scheme. The\ntests are based on energy distance and kernels mean embedding, are calibrated\nby permutations and are consistent against all alternatives. The good\nperformance of the new tests in real situations with finite samples is\nestablished with a simulation study.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jan 2019 18:05:57 GMT"}], "update_date": "2019-01-04", "authors_parsed": [["Matabuena", "Marcos", ""]]}, {"id": "1901.00880", "submitter": "Maurilio Gutzeit", "authors": "Maurilio Gutzeit", "title": "Minimax $L_2$-Separation Rate in Testing the Sobolev-Type Regularity of\n  a function", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study the problem of testing if an $L_2-$function $f$\nbelonging to a certain $l_2$-Sobolev-ball $B_t(R)$ of radius $R>0$ with\nsmoothness level $t>0$ indeed exhibits a higher smoothness level $s>t$, that\nis, belongs to $B_s(R)$. We assume that only a perturbed version of $f$ is\navailable, where the noise is governed by a standard Brownian motion scaled by\n$\\frac{1}{\\sqrt{n}}$. More precisely, considering a testing problem of the form\n$$H_0:~f\\in B_s(R)~~\\mathrm{vs.}~~H_1:~f\\in B_t(R),~\\inf_{h\\in B_s}\\Vert\nf-h\\Vert_{L_2}>\\rho$$ for some $\\rho>0$, we approach the task of identifying\nthe smallest value for $\\rho$, denoted $\\rho^\\ast$, enabling the existence of a\ntest $\\varphi$ with small error probability in a minimax sense. By deriving\nlower and upper bounds on $\\rho^\\ast$, we expose its precise dependence on $n$:\n$$\\rho^\\ast\\sim n^{-\\frac{t}{2t+1/2}}.$$ As a remarkable aspect of this\ncomposite-composite testing problem, it turns out that the rate does not depend\non $s$ and is equal to the rate in signal-detection, i.e. the case of a simple\nnull hypothesis.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jan 2019 19:09:34 GMT"}, {"version": "v2", "created": "Wed, 16 Jan 2019 14:01:53 GMT"}, {"version": "v3", "created": "Mon, 17 Feb 2020 19:52:26 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Gutzeit", "Maurilio", ""]]}, {"id": "1901.00914", "submitter": "Teng Zhang", "authors": "Teng Zhang", "title": "Element-wise estimation error of a total variation regularized estimator\n  for change point detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work studies the total variation regularized $\\ell_2$ estimator (fused\nlasso) in the setting of a change point detection problem. Compared with\nexisting works that focus on the sum of squared estimation errors, we give\nbound on the element-wise estimation error. Our bound is nearly optimal in the\nsense that the sum of squared error matches the best existing result, up to a\nlogarithmic factor. This analysis of the element-wise estimation error allows a\nscreening method that can approximately detect all the change points. We also\ngeneralize this method to the muitivariate setting, i.e., to the problem of\ngroup fused lasso.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jan 2019 21:06:15 GMT"}], "update_date": "2019-01-07", "authors_parsed": [["Zhang", "Teng", ""]]}, {"id": "1901.01026", "submitter": "Markus Bibinger", "authors": "Markus Bibinger and Mathias Trabs", "title": "On central limit theorems for power variations of the solution to the\n  stochastic heat equation", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the stochastic heat equation whose solution is observed\ndiscretely in space and time. An asymptotic analysis of power variations is\npresented including the proof of a central limit theorem. It generalizes the\ntheory from arXiv:1710.03519 in several directions.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jan 2019 09:13:37 GMT"}, {"version": "v2", "created": "Fri, 15 Mar 2019 10:09:27 GMT"}], "update_date": "2019-03-18", "authors_parsed": [["Bibinger", "Markus", ""], ["Trabs", "Mathias", ""]]}, {"id": "1901.01077", "submitter": "Lorenzo Trapani", "authors": "Lorenzo Trapani", "title": "Testing for strict stationarity in a random coefficient autoregressive\n  model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a procedure to decide between the null hypothesis of (strict)\nstationarity and the alternative of non-stationarity, in the context of a\nRandom Coefficient AutoRegression (RCAR). The procedure is based on randomising\na diagnostic which diverges to positive infinity under the null, and drifts to\nzero under the alternative. Thence, we propose a randomised test which can be\nused directly and - building on it - a decision rule to discern between the\nnull and the alternative. The procedure can be applied under very general\ncircumstances: albeit developed for an RCAR model, it can be used in the case\nof a standard AR(1) model, without requiring any modifications or prior\nknowledge. Also, the test works (again with no modification or prior knowledge\nbeing required) in the presence of infinite variance, and in general requires\nminimal assumptions on the existence of moments.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jan 2019 12:53:45 GMT"}], "update_date": "2019-01-07", "authors_parsed": [["Trapani", "Lorenzo", ""]]}, {"id": "1901.01137", "submitter": "Rui She", "authors": "Rui She, Shanyun Liu, Pingyi Fan", "title": "Information Measure Similarity Theory: Message Importance Measure via\n  Shannon Entropy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rare events attract more attention and interests in many scenarios of big\ndata such as anomaly detection and security systems. To characterize the rare\nevents importance from probabilistic perspective, the message importance\nmeasure (MIM) is proposed as a kind of semantics analysis tool. Similar to\nShannon entropy, the MIM has its special functional on information processing,\nin which the parameter $\\varpi$ of MIM plays a vital role. Actually, the\nparameter $\\varpi$ dominates the properties of MIM, based on which the MIM has\nthree work regions where the corresponding parameters satisfy $ 0 \\le \\varpi\n\\le 2/\\max\\{p(x_i)\\}$, $\\varpi > 2/\\max\\{p(x_i)\\}$ and $\\varpi < 0$\nrespectively. Furthermore, in the case $ 0 \\le \\varpi \\le 2/\\max\\{p(x_i)\\}$,\nthere are some similarity between the MIM and Shannon entropy in the\ninformation compression and transmission, which provide a new viewpoint for\ninformation theory. This paper first constructs a system model with message\nimportance measure and proposes the message importance loss to enrich the\ninformation processing strategies. Moreover, we propose the message importance\nloss capacity to measure the information importance harvest in a transmission.\nFurthermore, the message importance distortion function is presented to give an\nupper bound of information compression based on message importance measure.\nAdditionally, the bitrate transmission constrained by the message importance\nloss is investigated to broaden the scope for Shannon information theory.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jan 2019 14:36:04 GMT"}], "update_date": "2019-01-07", "authors_parsed": [["She", "Rui", ""], ["Liu", "Shanyun", ""], ["Fan", "Pingyi", ""]]}, {"id": "1901.01163", "submitter": "Yanglei Song", "authors": "Yanglei Song, Xiaohui Chen, Kengo Kato", "title": "Approximating high-dimensional infinite-order $U$-statistics:\n  statistical and computational guarantees", "comments": null, "journal-ref": "Electronic Journal of Statistics 2019, Vol. 13, No. 2, 4794-4848", "doi": "10.1214/19-EJS1643", "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of distributional approximations to high-dimensional\nnon-degenerate $U$-statistics with random kernels of diverging orders.\nInfinite-order $U$-statistics (IOUS) are a useful tool for constructing\nsimultaneous prediction intervals that quantify the uncertainty of ensemble\nmethods such as subbagging and random forests. A major obstacle in using the\nIOUS is their computational intractability when the sample size and/or order\nare large. In this article, we derive non-asymptotic Gaussian approximation\nerror bounds for an incomplete version of the IOUS with a random kernel. We\nalso study data-driven inferential methods for the incomplete IOUS via\nbootstraps and develop their statistical and computational guarantees.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jan 2019 14:59:48 GMT"}, {"version": "v2", "created": "Sat, 26 Jan 2019 15:29:29 GMT"}, {"version": "v3", "created": "Fri, 15 Nov 2019 14:50:28 GMT"}], "update_date": "2019-12-11", "authors_parsed": [["Song", "Yanglei", ""], ["Chen", "Xiaohui", ""], ["Kato", "Kengo", ""]]}, {"id": "1901.01375", "submitter": "Adel Javanmard", "authors": "Adel Javanmard, Marco Mondelli, Andrea Montanari", "title": "Analysis of a Two-Layer Neural Network via Displacement Convexity", "comments": "70 pages, 28 pdf figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fitting a function by using linear combinations of a large number $N$ of\n`simple' components is one of the most fruitful ideas in statistical learning.\nThis idea lies at the core of a variety of methods, from two-layer neural\nnetworks to kernel regression, to boosting. In general, the resulting risk\nminimization problem is non-convex and is solved by gradient descent or its\nvariants. Unfortunately, little is known about global convergence properties of\nthese approaches.\n  Here we consider the problem of learning a concave function $f$ on a compact\nconvex domain $\\Omega\\subseteq {\\mathbb R}^d$, using linear combinations of\n`bump-like' components (neurons). The parameters to be fitted are the centers\nof $N$ bumps, and the resulting empirical risk minimization problem is highly\nnon-convex. We prove that, in the limit in which the number of neurons\ndiverges, the evolution of gradient descent converges to a Wasserstein gradient\nflow in the space of probability distributions over $\\Omega$. Further, when the\nbump width $\\delta$ tends to $0$, this gradient flow has a limit which is a\nviscous porous medium equation. Remarkably, the cost function optimized by this\ngradient flow exhibits a special property known as displacement convexity,\nwhich implies exponential convergence rates for $N\\to\\infty$, $\\delta\\to 0$.\n  Surprisingly, this asymptotic theory appears to capture well the behavior for\nmoderate values of $\\delta, N$. Explaining this phenomenon, and understanding\nthe dependence on $\\delta,N$ in a quantitative manner remains an outstanding\nchallenge.\n", "versions": [{"version": "v1", "created": "Sat, 5 Jan 2019 07:16:51 GMT"}, {"version": "v2", "created": "Sat, 17 Aug 2019 19:21:08 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Javanmard", "Adel", ""], ["Mondelli", "Marco", ""], ["Montanari", "Andrea", ""]]}, {"id": "1901.01624", "submitter": "Dmitriy Drusvyatskiy", "authors": "Vasileios Charisopoulos, Damek Davis, Mateo D\\'iaz, Dmitriy\n  Drusvyatskiy", "title": "Composite optimization for robust blind deconvolution", "comments": "60 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The blind deconvolution problem seeks to recover a pair of vectors from a set\nof rank one bilinear measurements. We consider a natural nonsmooth formulation\nof the problem and show that under standard statistical assumptions, its moduli\nof weak convexity, sharpness, and Lipschitz continuity are all dimension\nindependent. This phenomenon persists even when up to half of the measurements\nare corrupted by noise. Consequently, standard algorithms, such as the\nsubgradient and prox-linear methods, converge at a rapid dimension-independent\nrate when initialized within constant relative error of the solution. We then\ncomplete the paper with a new initialization strategy, complementing the local\nsearch algorithms. The initialization procedure is both provably efficient and\nrobust to outlying measurements. Numerical experiments, on both simulated and\nreal data, illustrate the developed theory and methods.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jan 2019 23:08:47 GMT"}, {"version": "v2", "created": "Fri, 18 Jan 2019 17:11:40 GMT"}], "update_date": "2019-01-21", "authors_parsed": [["Charisopoulos", "Vasileios", ""], ["Davis", "Damek", ""], ["D\u00edaz", "Mateo", ""], ["Drusvyatskiy", "Dmitriy", ""]]}, {"id": "1901.01645", "submitter": "Zhonglei Wang", "authors": "Zhonglei Wang, Jae Kwang Kim, Liuhua Peng", "title": "Bootstrap inference for the finite population total under complex\n  sampling designs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bootstrap is a useful tool for making statistical inference, but it may\nprovide erroneous results under complex survey sampling. Most studies about\nbootstrap-based inference are developed under simple random sampling and\nstratified random sampling. In this paper, we propose a unified bootstrap\nmethod applicable to some complex sampling designs, including Poisson sampling\nand probability-proportional-to-size sampling. Two main features of the\nproposed bootstrap method are that studentization is used to make inference,\nand the finite population is bootstrapped based on a multinomial distribution\nby incorporating the sampling information. We show that the proposed bootstrap\nmethod is second-order accurate using the Edgeworth expansion. Two simulation\nstudies are conducted to compare the proposed bootstrap method with the\nWald-type method, which is widely used in survey sampling. Results show that\nthe proposed bootstrap method is better in terms of coverage rate especially\nwhen sample size is limited.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jan 2019 02:14:36 GMT"}], "update_date": "2019-01-08", "authors_parsed": [["Wang", "Zhonglei", ""], ["Kim", "Jae Kwang", ""], ["Peng", "Liuhua", ""]]}, {"id": "1901.01793", "submitter": "Idir Arab", "authors": "Idir Arab, Milto Hadjikyriakou, and Paulo Eduardo Oliveira", "title": "On the limit behavior of iterated equilibrium distributions for the\n  Gamma and Weibull families", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the evolution of iterated equilibrium distributions\nfor the Gamma and Weibull families of distributions as the iteration step\nincreases. We characterize their moments and the pointwise limit of the\ndistribution functions corresponding to the iterated distributions. As a\nbyproduct, we obtain approximations for higher order moments of the residual\nlifetime.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jan 2019 13:28:04 GMT"}], "update_date": "2019-01-08", "authors_parsed": [["Arab", "Idir", ""], ["Hadjikyriakou", "Milto", ""], ["Oliveira", "Paulo Eduardo", ""]]}, {"id": "1901.01981", "submitter": "Abhik Ghosh PhD", "authors": "Abhik Ghosh and Ayanendranath Basu", "title": "A Scale-invariant Generalization of the R\\'{e}nyi Entropy, Associated\n  Divergences and their Optimizations under Tsallis' Nonextensive Framework", "comments": null, "journal-ref": "IEEE Transactions on Information Theory. Volume: 67, Issue: 4,\n  April 2021", "doi": "10.1109/TIT.2021.3054980", "report-no": null, "categories": "math.ST cs.IT math.IT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entropy and relative or cross entropy measures are two very fundamental\nconcepts in information theory and are also widely used for statistical\ninference across disciplines. The related optimization problems, in particular\nthe maximization of the entropy and the minimization of the cross entropy or\nrelative entropy (divergence), are essential for general logical inference in\nour physical world. In this paper, we discuss a two parameter generalization of\nthe popular R\\'{e}nyi entropy and associated optimization problems. We derive\nthe desired entropic characteristics of the new generalized entropy measure\nincluding its positivity, expandability, extensivity and generalized\n(sub-)additivity. More importantly, when considered over the class of\nsub-probabilities, our new family turns out to be scale-invariant. We also\npropose the corresponding cross entropy and relative entropy measures and\ndiscuss their geometric properties including generalized Pythagorean results\nover $\\beta$-convex sets. The maximization of the new entropy and the\nminimization of the corresponding cross or relative entropy measures are\ncarried out explicitly under the non-extensive (`third-choice') constraints\ngiven by the Tsallis' normalized $q$ expectations which also correspond to the\n$\\beta$-linear family of probability distributions. Important properties of the\nassociated forward and reverse projection rules are discussed along with their\nexistence and uniqueness. In this context, we have come up with, for the first\ntime, a class of entropy measures -- a subfamily of our two-parameter\ngeneralization -- that leads to the classical (extensive) exponential family of\nMaxEnt distributions under the non-extensive constraints. Other members of the\nnew entropy family, however, lead to the power-law type generalized\n$q$-exponential MaxEnt distributions which is in conformity with Tsallis'\nnonextensive theory.\n", "versions": [{"version": "v1", "created": "Sat, 5 Jan 2019 18:50:32 GMT"}, {"version": "v2", "created": "Thu, 17 Jun 2021 16:24:04 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Ghosh", "Abhik", ""], ["Basu", "Ayanendranath", ""]]}, {"id": "1901.02058", "submitter": "Manuele Leonelli", "authors": "Manuele Leonelli and Eva Riccomagno", "title": "A geometric characterisation of sensitivity analysis in monomial models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.AI stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sensitivity analysis in probabilistic discrete graphical models is usually\nconducted by varying one probability value at a time and observing how this\naffects output probabilities of interest. When one probability is varied then\nothers are proportionally covaried to respect the sum-to-one condition of\nprobability laws. The choice of proportional covariation is justified by a\nvariety of optimality conditions, under which the original and the varied\ndistributions are as close as possible under different measures of closeness.\nFor variations of more than one parameter at a time proportional covariation is\njustified in some special cases only. In this work, for the large class of\ndiscrete statistical models entertaining a regular monomial parametrisation, we\ndemonstrate the optimality of newly defined proportional multi-way schemes with\nrespect to an optimality criterion based on the notion of I-divergence. We\ndemonstrate that there are varying parameters choices for which proportional\ncovariation is not optimal and identify the sub-family of model distributions\nwhere the distance between the original distribution and the one where\nprobabilities are covaried proportionally is minimum. This is shown by adopting\na new formal, geometric characterization of sensitivity analysis in monomial\nmodels, which include a wide array of probabilistic graphical models. We also\ndemonstrate the optimality of proportional covariation for multi-way analyses\nin Naive Bayes classifiers.\n", "versions": [{"version": "v1", "created": "Tue, 18 Dec 2018 11:21:53 GMT"}, {"version": "v2", "created": "Wed, 13 Jan 2021 17:27:45 GMT"}], "update_date": "2021-01-14", "authors_parsed": [["Leonelli", "Manuele", ""], ["Riccomagno", "Eva", ""]]}, {"id": "1901.02062", "submitter": "Manuele Leonelli", "authors": "Manuele Leonelli", "title": "Sensitivity analysis beyond linearity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A wide array of graphical models can be parametrised to have atomic\nprobabilities represented by monomial functions. Such monomial structure has\nproven very useful when studying robustness under the assumption of a\nmultilinear model where all monomial have either zero or one exponents.\nRobustness in probabilistic graphical models is usually investigated by varying\nsome of the input probabilities and observing the effects of these on output\nprobabilities of interest. Here the assumption of multilinearity is relaxed and\na general approach for sensitivity analysis in non-multilinear models is\npresented. It is shown that in non-multilinear models sensitivity functions\nhave a polynomial form, conversely to multilinear models where these are simply\nlinear. The form of various divergences and distances under different\ncovariation schemes is also formally derived. Proportional covariation is\nproven to be optimal in non-multilinear models under some specific choices of\nvaried parameters. The methodology is illustrated throughout by an educational\napplication.\n", "versions": [{"version": "v1", "created": "Thu, 20 Dec 2018 16:32:34 GMT"}], "update_date": "2019-01-09", "authors_parsed": [["Leonelli", "Manuele", ""]]}, {"id": "1901.02104", "submitter": "Hanie Sedghi", "authors": "Philip M. Long and Hanie Sedghi", "title": "On the effect of the activation function on the distribution of hidden\n  nodes in a deep network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the joint probability distribution on the lengths of the vectors\nof hidden variables in different layers of a fully connected deep network, when\nthe weights and biases are chosen randomly according to Gaussian distributions,\nand the input is in $\\{ -1, 1\\}^N$. We show that, if the activation function\n$\\phi$ satisfies a minimal set of assumptions, satisfied by all activation\nfunctions that we know that are used in practice, then, as the width of the\nnetwork gets large, the `length process' converges in probability to a length\nmap that is determined as a simple function of the variances of the random\nweights and biases, and the activation function $\\phi$. We also show that this\nconvergence may fail for $\\phi$ that violate our assumptions.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jan 2019 23:33:14 GMT"}], "update_date": "2019-01-09", "authors_parsed": [["Long", "Philip M.", ""], ["Sedghi", "Hanie", ""]]}, {"id": "1901.02157", "submitter": "Siyang Tao", "authors": "Nariankadu D. Shyamalkumar and Siyang Tao", "title": "On Tail Dependence Matrices -- The Realization Problem for Parametric\n  Families", "comments": "39 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Among bivariate tail dependence measures, the tail dependence coefficient has\nemerged as the popular choice. Akin to the correlation matrix, a multivariate\ndependence measure is constructed using these bivariate measures, and this is\nreferred to in the literature as the tail dependence matrix (TDM). While the\nproblem of determining whether a given ${d\\times d}$ matrix is a correlation\nmatrix is of the order $O(d^3)$ in complexity, determining if a matrix is a TDM\n(the realization problem) is believed to be non-polynomial in complexity. Using\na linear programming (LP) formulation, we show that the combinatorial structure\nof the constraints is related to the intractable max-cut problem in a weighted\ngraph. This connection provides an avenue for constructing parametric classes\nadmitting a polynomial in $d$ algorithm for determining membership in its\nconstraint polytope. The complexity of the general realization problem is\njustifiably of much theoretical interest. Since in practice one resorts to\nlower dimensional parametrization of the TDMs, we posit that it is rather the\ncomplexity of the realization problem restricted to parametric classes of TDMs,\nand algorithms for it, that are more practically relevant. In this paper, we\nshow how the inherent symmetry and sparsity in a parametrization can be\nexploited to achieve a significant reduction in the LP formulation, which can\nlead to polynomial complexity of such realization problems - some\nparametrizations even resulting in the constraint polytope being independent of\n$d$. We also explore the use of a probabilistic viewpoint on TDMs to derive the\nconstraint polytopes.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2019 05:12:45 GMT"}, {"version": "v2", "created": "Thu, 1 Aug 2019 04:47:44 GMT"}], "update_date": "2019-08-02", "authors_parsed": [["Shyamalkumar", "Nariankadu D.", ""], ["Tao", "Siyang", ""]]}, {"id": "1901.02201", "submitter": "Jianfeng Yao", "authors": "Yuyang Xu and Jianfeng Yao", "title": "On Laplacian spectrum of dendrite trees", "comments": "18 pages, 5 figures and 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For dendrite graphs from biological experiments on mouse's retinal ganglion\ncells, a paper by Nakatsukasa, Saito and Woei reveals a mysterious phase\ntransition phenomenon in the spectra of the corresponding graph Laplacian\nmatrices. While the bulk of the spectrum can be well understood by structures\nresembling starlike trees, mysteries about the spikes, that is, isolated\neigenvalues outside the bulk spectrum, remain unexplained. In this paper, we\nbring new insights on these mysteries by considering a class of uniform trees.\nExact relationships between the number of such spikes and the number of\nT-junctions are analyzed in function of the number of vertices separating the\nT-junctions. Using these theoretic results, predictions are proposed for the\nnumber of spikes observed in real-life dendrite graphs. Interestingly enough,\nthese predictions match well the observed numbers of spikes, thus confirm the\npractical meaningness of our theoretical results.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2019 08:22:52 GMT"}, {"version": "v2", "created": "Fri, 3 Jan 2020 02:46:54 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Xu", "Yuyang", ""], ["Yao", "Jianfeng", ""]]}, {"id": "1901.02375", "submitter": "Frank R\\\"ottger", "authors": "Thomas Kahle and Frank R\\\"ottger and Rainer Schwabe", "title": "The semi-algebraic geometry of saturated optimal designs for the\n  Bradley-Terry model", "comments": "18 pages, 5 figures, v2: Improved after referee comments, v3: Final\n  version as in Algebraic Statistics", "journal-ref": "Alg. Stat. 12 (2021) 97-114", "doi": "10.2140/astat.2021.12.97", "report-no": null, "categories": "math.ST math.OC stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimal design theory for nonlinear regression studies local optimality on a\ngiven design space. We identify designs for the Bradley--Terry paired\ncomparison model with small undirected graphs and prove that every saturated\nD-optimal design is represented by a path. We discuss the case of four\nalternatives in detail and derive explicit polynomial inequality descriptions\nfor optimality regions in parameter space. Using these regions, for each point\nin parameter space we can prescribe a D-optimal design.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2019 15:44:13 GMT"}, {"version": "v2", "created": "Thu, 4 Jun 2020 12:56:58 GMT"}, {"version": "v3", "created": "Wed, 16 Jun 2021 09:51:55 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Kahle", "Thomas", ""], ["R\u00f6ttger", "Frank", ""], ["Schwabe", "Rainer", ""]]}, {"id": "1901.02398", "submitter": "Alexandre Moesching", "authors": "Alexandre M\\\"osching and Lutz Duembgen", "title": "Monotone Least Squares and Isotonic Quantiles", "comments": null, "journal-ref": null, "doi": "10.1214/19-EJS1659", "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider bivariate observations $(X_1,Y_1), \\ldots, (X_n,Y_n)$ such that,\nconditional on the $X_i$, the $Y_i$ are independent random variables with\ndistribution functions $F_{X_i}$, where $(F_x)_x$ is an unknown family of\ndistribution functions. Under the sole assumption that $x \\mapsto F_x$ is\nisotonic with respect to stochastic order, one can estimate $(F_x)_x$ in two\nways:\n  (i) For any fixed $y$ one estimates the antitonic function $x \\mapsto F_x(y)$\nvia nonparametric monotone least squares, replacing the responses $Y_i$ with\nthe indicators $1_{[Y_i \\le y]}$.\n  (ii) For any fixed $\\beta \\in (0,1)$ one estimates the isotonic quantile\nfunction $x \\mapsto F_x^{-1}(\\beta)$ via a nonparametric version of regression\nquantiles.\n  We show that these two approaches are closely related, with (i) being more\nflexible than (ii). Then, under mild regularity conditions, we establish rates\nof convergence for the resulting estimators $\\hat{F}_x(y)$ and\n$\\hat{F}_x^{-1}(\\beta)$, uniformly over $(x,y)$ and $(x,\\beta)$ in certain\nrectangles as well as uniformly in $y$ or $\\beta$ for a fixed $x$.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2019 16:48:50 GMT"}, {"version": "v2", "created": "Tue, 6 Aug 2019 14:13:11 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["M\u00f6sching", "Alexandre", ""], ["Duembgen", "Lutz", ""]]}, {"id": "1901.02419", "submitter": "Gordon Chavez", "authors": "Gordon V. Chavez", "title": "Dynamic tail inference with log-Laplace volatility", "comments": "Preprint, 27 pages, 7 figures, 3 tables", "journal-ref": "Extremes 23, 287-315 (2020)", "doi": "10.1007/s10687-019-00368-w", "report-no": null, "categories": "stat.ME econ.EM math.ST q-fin.RM q-fin.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a family of models that enable predictive estimation of\ntime-varying extreme event probabilities in heavy-tailed and nonlinearly\ndependent time series. The models are a white noise process with conditionally\nlog-Laplace stochastic volatility. In contrast to other, similar stochastic\nvolatility formalisms, this process has analytic expressions for its\nconditional probabilistic structure that enable straightforward estimation of\ndynamically changing extreme event probabilities. The process and volatility\nare conditionally Pareto-tailed, with tail exponent given by the reciprocal of\nthe log-volatility's mean absolute innovation. This formalism can accommodate a\nwide variety of nonlinear dependence, as well as conditional power law-tail\nbehavior ranging from weakly non-Gaussian to Cauchy-like tails. We provide a\ncomputationally straightforward estimation procedure that uses an asymptotic\napproximation of the process' dynamic large deviation probabilities. We\ndemonstrate the estimator's utility with a simulation study. We then show the\nmethod's predictive capabilities on a simulated nonlinear time series where the\nvolatility is driven by the chaotic Lorenz system. Lastly we provide an\nempirical application, which shows that this simple modeling method can be\neffectively used for dynamic and predictive tail inference in financial time\nseries.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2019 17:43:38 GMT"}, {"version": "v2", "created": "Tue, 5 Feb 2019 18:23:26 GMT"}, {"version": "v3", "created": "Tue, 26 Feb 2019 18:17:24 GMT"}, {"version": "v4", "created": "Thu, 28 Mar 2019 17:20:59 GMT"}, {"version": "v5", "created": "Wed, 31 Jul 2019 16:46:56 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Chavez", "Gordon V.", ""]]}, {"id": "1901.02471", "submitter": "Alexis Akira Toda", "authors": "Alexis Akira Toda and Yulong Wang", "title": "Efficient Minimum Distance Estimation of Pareto Exponent from Top Income\n  Shares", "comments": null, "journal-ref": null, "doi": "10.1002/jae.2788", "report-no": null, "categories": "math.ST econ.GN q-fin.EC stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an efficient estimation method for the income Pareto exponent when\nonly certain top income shares are observable. Our estimator is based on the\nasymptotic theory of weighted sums of order statistics and the efficient\nminimum distance estimator. Simulations show that our estimator has excellent\nfinite sample properties. We apply our estimation method to U.S. top income\nshare data and find that the Pareto exponent has been stable at around 1.5\nsince 1985, suggesting that the rise in inequality during the last three\ndecades is mainly driven by redistribution between the rich and poor, not among\nthe rich.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2019 19:06:05 GMT"}, {"version": "v2", "created": "Fri, 21 Feb 2020 16:31:51 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Toda", "Alexis Akira", ""], ["Wang", "Yulong", ""]]}, {"id": "1901.02744", "submitter": "Charl Pretorius", "authors": "Marie Hu\\v{s}kov\\'a (1), Simos G. Meintanis (2), Charl Pretorius (1\n  and 2) ((1) Charles University, Prague, Czech Republic, (2) North-West\n  University, Potchefstroom, South Africa)", "title": "Tests for validity of the semiparametric heteroskedastic transformation\n  model", "comments": null, "journal-ref": null, "doi": "10.1016/j.csda.2019.106895", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There exist a number of tests for assessing the nonparametric heteroscedastic\nlocation-scale assumption. Here we consider a goodness-of-fit test for the more\ngeneral hypothesis of the validity of this model under a parametric functional\ntransformation on the response variable. Specifically we consider testing for\nindependence between the regressors and the errors in a model where the\ntransformed response is just a location/scale shift of the error. Our criteria\nuse the familiar factorization property of the joint characteristic function of\nthe covariates under independence. The difficulty is that the errors are\nunobserved and hence one needs to employ properly estimated residuals in their\nplace. We study the limit distribution of the test statistics under the null\nhypothesis as well as under alternatives, and also suggest a resampling\nprocedure in order to approximate the critical values of the tests. This\nresampling is subsequently employed in a series of Monte Carlo experiments that\nillustrate the finite-sample properties of the new test. We also investigate\nthe performance of related test statistics for normality and symmetry of\nerrors, and apply our methods on real data sets.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jan 2019 13:45:40 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Hu\u0161kov\u00e1", "Marie", "", "1\n  and 2"], ["Meintanis", "Simos G.", "", "1\n  and 2"], ["Pretorius", "Charl", "", "1\n  and 2"]]}, {"id": "1901.02976", "submitter": "Art Owen", "authors": "Art B. Owen and Yi Zhou", "title": "The square root rule for adaptive importance sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In adaptive importance sampling, and other contexts, we have $K>1$ unbiased\nand uncorrelated estimates $\\hat\\mu_k$ of a common quantity $\\mu$. The optimal\nunbiased linear combination weights them inversely to their variances but those\nweights are unknown and hard to estimate. A simple deterministic square root\nrule based on a working model that $\\mathrm{Var}(\\hat\\mu_k)\\propto k^{-1/2}$\ngives an unbisaed estimate of $\\mu$ that is nearly optimal under a wide range\nof alternative variance patterns. We show that if\n$\\mathrm{Var}(\\hat\\mu_k)\\propto k^{-y}$ for an unknown rate parameter $y\\in\n[0,1]$ then the square root rule yields the optimal variance rate with a\nconstant that is too large by at most $9/8$ for any $0\\le y\\le 1$ and any\nnumber $K$ of estimates. Numerical work shows that rule is similarly robust to\nsome other patterns with mildly decreasing variance as $k$ increases.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2019 00:15:29 GMT"}, {"version": "v2", "created": "Fri, 29 Mar 2019 02:15:35 GMT"}], "update_date": "2019-04-01", "authors_parsed": [["Owen", "Art B.", ""], ["Zhou", "Yi", ""]]}, {"id": "1901.03036", "submitter": "Zixiang Guan", "authors": "Zixiang Guan, Gemai Chen", "title": "Nonparametric Multiple Change Point Detection for Non-Stationary Times\n  Series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article considers a nonparametric method for detecting change points in\nnon-stationary time series. The proposed method will divide the time series\ninto several segments so that between two adjacent segments, the normalized\nspectral density functions are different. The theory is based on the assumption\nthat within each segment, time series is a linear process, which means that our\nmethod works not only for classic time series models, e.g., causal and\ninvertible ARMA process, but also preserves good performance for non-invertible\nmoving average process. We show that our estimations for change points are\nconsistent. Also, a Bayesian information criterion is applied to estimate the\nmember of change points consistently. Simulation results as well as empirical\nresults will be presented.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2019 06:48:43 GMT"}, {"version": "v2", "created": "Fri, 11 Jan 2019 04:00:37 GMT"}, {"version": "v3", "created": "Wed, 4 Nov 2020 17:10:03 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Guan", "Zixiang", ""], ["Chen", "Gemai", ""]]}, {"id": "1901.03039", "submitter": "Tetsunao Matsuta", "authors": "Tetsunao Matsuta, Tomohiko Uyematsu", "title": "On the Distance Between the Rumor Source and Its Optimal Estimate in a\n  Regular Tree", "comments": "fixed typos and proofs, 16 pages, 2 figures, a short version of this\n  paper has been submitted to the 2019 IEEE International Symposium on\n  Information Theory (ISIT 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.SI math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the rumor source identification problem, where the goal\nis to find the origin node of a rumor in a network among a given set of nodes\nwith the rumor. In this paper, we focus on a network represented by a regular\ntree which does not have any cycle and in which all nodes have the same number\nof edges connected to a node. For this network, we clarify that, with quite\nhigh probability, the origin node is within the distance 3 from the node\nselected by the optimal estimator, where the distance is the number of edges of\nthe unique path connecting two nodes. This is clarified by the probability\ndistribution of the distance between the origin and the selected node.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2019 07:09:33 GMT"}, {"version": "v2", "created": "Tue, 22 Jan 2019 02:19:26 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Matsuta", "Tetsunao", ""], ["Uyematsu", "Tomohiko", ""]]}, {"id": "1901.03059", "submitter": "Johannes Rauh", "authors": "Oliver Clarke, Fatemeh Mohammadi and Johannes Rauh", "title": "Conditional independence ideals with hidden variables", "comments": "20 pages, 1 figure, 4 tables", "journal-ref": "Advances in Applied Mathematics, volume 117, 2020, 102029", "doi": "10.1016/j.aam.2020.102029", "report-no": null, "categories": "math.AC math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a class of determinantal ideals that are related to conditional\nindependence (CI) statements with hidden variables. Such CI statements\ncorrespond to determinantal conditions on a matrix whose entries are\nprobabilities of events involving the observed random variables. We focus on an\nexample that generalizes the CI ideals of the intersection axiom. In this\nexample, the minimal primes are again determinantal ideals, which is not true\nin general.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2019 08:51:06 GMT"}, {"version": "v2", "created": "Sat, 14 Mar 2020 22:44:58 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Clarke", "Oliver", ""], ["Mohammadi", "Fatemeh", ""], ["Rauh", "Johannes", ""]]}, {"id": "1901.03269", "submitter": "Anna Liu", "authors": "Jian Shi, Jiahui Yu, Anna Liu, and Yuedong Wang", "title": "Smoothing Spline Semiparametric Density Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Density estimation plays a fundamental role in many areas of statistics and\nmachine learning. Parametric, nonparametric and semiparametric density\nestimation methods have been proposed in the literature. Semiparametric density\nmodels are flexible in incorporating domain knowledge and uncertainty regarding\nthe shape of the density function. Existing literature on semiparametric\ndensity models is scattered and lacks a systematic framework. In this paper, we\nconsider a unified framework based on the reproducing kernel Hilbert space for\nmodeling, estimation, computation and theory. We propose general semiparametric\ndensity models for both a single sample and multiple samples which include many\nexisting semiparametric density models as special cases. We develop penalized\nlikelihood based estimation methods and computational methods under different\nsituations. We establish joint consistency and derive convergence rates of the\nproposed estimators for both the finite dimensional Euclidean parameters and an\ninfinite-dimensional functional parameter. We validate our estimation methods\nempirically through simulations and an application.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2019 16:56:09 GMT"}], "update_date": "2019-01-11", "authors_parsed": [["Shi", "Jian", ""], ["Yu", "Jiahui", ""], ["Liu", "Anna", ""], ["Wang", "Yuedong", ""]]}, {"id": "1901.03348", "submitter": "Vydas \\v{C}ekanavi\\v{c}ius", "authors": "Vydas \\v{C}ekanavi\\v{c}ius and Palaniappan Vellaisamy", "title": "On large deviations for sums of discrete m-dependent random variables", "comments": "To appear in \"Stochastics\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ratio $P(S_n=x)/P(Z_n=x)$ is investigated for three cases: (a) when $S_n$\nis a sum of 1-dependent non-negative integer-valued random variables (rvs),\nsatisfying some moment conditions, and $Z_n$ is Poisson rv; (b) when $S_n$ is a\nstatistic of 2-runs and $Z_n$ is negative binomial rv; and (c) when $S_n$ is\nstatistic of $N(1,1)$-events and $Z_n$ is a binomial r.v. We also consider the\napproximation of $P(S_n\\geqslant x)$ by Poisson distribution with parameter\ndepending on $x$.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2019 19:02:02 GMT"}], "update_date": "2019-01-14", "authors_parsed": [["\u010cekanavi\u010dius", "Vydas", ""], ["Vellaisamy", "Palaniappan", ""]]}, {"id": "1901.03556", "submitter": "Steffen Lauritzen", "authors": "Nadine Gissibl and Claudia Kl\\\"uppelberg and Steffen Lauritzen", "title": "Identifiability and estimation of recursive max-linear models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the identifiablity and estimation of recursive max-linear\nstructural equation models represented by an edge weighted directed acyclic\ngraph (DAG). Such models are generally unidentifiable and we identify the whole\nclass of DAGs and edge weights corresponding to a given observational\ndistribution. For estimation, standard likelihood theory cannot be applied\nbecause the corresponding families of distributions are not dominated. Given\nthe underlying DAG, we present an estimator for the class of edge weights and\nshow that it can be considered a generalized maximum likelihood estimator. In\naddition, we develop a simple method for identifying the structures of the\nDAGs. With probability tending to one at an exponential rate with the number of\nobservations, this method correctly identifies the class of DAGs and,\nsimilarly, exactly identifies the possible edge weights.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jan 2019 11:24:44 GMT"}, {"version": "v2", "created": "Mon, 7 Oct 2019 09:16:20 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Gissibl", "Nadine", ""], ["Kl\u00fcppelberg", "Claudia", ""], ["Lauritzen", "Steffen", ""]]}, {"id": "1901.03719", "submitter": "Khashayar Khosravi", "authors": "Khashayar Khosravi, Greg Lewis, Vasilis Syrgkanis", "title": "Non-Parametric Inference Adaptive to Intrinsic Dimension", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG econ.EM math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider non-parametric estimation and inference of conditional moment\nmodels in high dimensions. We show that even when the dimension $D$ of the\nconditioning variable is larger than the sample size $n$, estimation and\ninference is feasible as long as the distribution of the conditioning variable\nhas small intrinsic dimension $d$, as measured by locally low doubling\nmeasures. Our estimation is based on a sub-sampled ensemble of the $k$-nearest\nneighbors ($k$-NN) $Z$-estimator. We show that if the intrinsic dimension of\nthe covariate distribution is equal to $d$, then the finite sample estimation\nerror of our estimator is of order $n^{-1/(d+2)}$ and our estimate is\n$n^{1/(d+2)}$-asymptotically normal, irrespective of $D$. The sub-sampling size\nrequired for achieving these results depends on the unknown intrinsic dimension\n$d$. We propose an adaptive data-driven approach for choosing this parameter\nand prove that it achieves the desired rates. We discuss extensions and\napplications to heterogeneous treatment effect estimation.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jan 2019 19:22:48 GMT"}, {"version": "v2", "created": "Tue, 26 Feb 2019 07:48:02 GMT"}, {"version": "v3", "created": "Tue, 18 Jun 2019 00:18:22 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Khosravi", "Khashayar", ""], ["Lewis", "Greg", ""], ["Syrgkanis", "Vasilis", ""]]}, {"id": "1901.03849", "submitter": "Jean Abi Rizk", "authors": "Jean Rizk, Kevin Burke, Cathal Walsh", "title": "On the Non-uniqueness of Representations of Coxian Phase-Type\n  Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parameter estimation in Coxian phase-type models can be challenging due to\ntheir non-unique representation leading to a multi-modal likelihood. Since each\nrepresentation corresponds to a different underlying data-generating mechanism,\nit is of interest to identify those supported by given data (i.e., find all\nlikelihood modes). The standard approach is to simply refit using various\ninitial values, but this has no guarantee of working. Thus, we develop new\nproperties specific to this class of models, and employ these to determine all\nthe equivalent model representations. The proposed approach only requires\nfitting the model once, and is guaranteed to find all representations.\n", "versions": [{"version": "v1", "created": "Sat, 12 Jan 2019 11:05:03 GMT"}, {"version": "v2", "created": "Tue, 23 Jul 2019 11:00:41 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Rizk", "Jean", ""], ["Burke", "Kevin", ""], ["Walsh", "Cathal", ""]]}, {"id": "1901.03890", "submitter": "YiMing Yu", "authors": "YiMing Yu, Cyrill B. Muratov, and Richard O. Moore", "title": "Importance sampling for thermally induced switching and non-switching\n  probabilities in spin-torque magnetic nanodevices", "comments": "11 pages, 14 figures", "journal-ref": null, "doi": "10.1109/TMAG.2019.2914993", "report-no": null, "categories": "cond-mat.mes-hall math.PR math.ST physics.app-ph stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spin-transfer torque magnetoresistive random access memory is a potentially\ntransformative technology in the non-volatile memory market. Its viability\ndepends, in part, on one's ability to predictably induce or prevent switching;\nhowever, thermal fluctuations cause small but important errors in both the\nwriting and reading processes. Computing these very small probabilities for\nmagnetic nanodevices using naive Monte Carlo simulations is essentially\nimpossible due to their slow statistical convergence, but variance reduction\ntechniques can offer an effective way to improve their efficiency. Here, we\nprovide an illustration of how importance sampling can be efficiently used to\nestimate low read and write soft error rates of macrospin and coupled-spin\nsystems.\n", "versions": [{"version": "v1", "created": "Sat, 12 Jan 2019 18:23:57 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Yu", "YiMing", ""], ["Muratov", "Cyrill B.", ""], ["Moore", "Richard O.", ""]]}, {"id": "1901.03920", "submitter": "Artyom Kovalevskii", "authors": "Artyom Kovalevskii", "title": "Asymptotics of an empirical bridge of regression on induced order\n  statistics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a class of tests for linear regression on concomitants (induced\norder statistics). These tests are based on sequential sums of regression\nresiduals. We self-center and self-normalize these sums. The resulting process\nis called an empirical bridge. We prove weak convergence of the empirical\nbridge in uniform metrics to a centered Gaussian process. The proposed tests\nare of chi-square type.\n", "versions": [{"version": "v1", "created": "Sun, 13 Jan 2019 00:50:25 GMT"}, {"version": "v2", "created": "Sat, 13 Apr 2019 05:18:09 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Kovalevskii", "Artyom", ""]]}, {"id": "1901.03986", "submitter": "Norbert Henze", "authors": "Norbert Henze, Jaco Visagie", "title": "Testing for normality in any dimension based on a partial differential\n  equation involving the moment generating function", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use a system of first-order partial differential equations that\ncharacterize the moment generating function of the $d$-variate standard normal\ndistribution to construct a class of affine invariant tests for normality in\nany dimension. We derive the limit null distribution of the resulting test\nstatistics, and we prove consistency of the tests against general alternatives.\nIn the case $d > 1$, a certain limit of these tests is connected with two\nmeasures of multivariate skewness. The new tests show strong power performance\nwhen compared to well-known competitors, especially against heavy-tailed\ndistributions, and they are illustrated by means of a real data set.\n", "versions": [{"version": "v1", "created": "Sun, 13 Jan 2019 14:06:04 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Henze", "Norbert", ""], ["Visagie", "Jaco", ""]]}, {"id": "1901.03989", "submitter": "Ali Ghaderi Ph.D", "authors": "Ali Ghaderi", "title": "On the method of likelihood-induced priors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT math.IT math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate that the functional form of the likelihood contains a\nsufficient amount of information for constructing a prior for the unknown\nparameters. We develop a four-step algorithm by invoking the information\nentropy as the measure of uncertainty and show how the information gained from\ncoarse-graining and resolving power of the likelihood can be used to construct\nthe likelihood-induced priors. As a consequence, we show that if the data model\ndensity belongs to the exponential family, the likelihood-induced prior is the\nconjugate prior to the corresponding likelihood.\n", "versions": [{"version": "v1", "created": "Sun, 13 Jan 2019 14:20:34 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Ghaderi", "Ali", ""]]}, {"id": "1901.04127", "submitter": "Xuejun Wang Wang X.J.", "authors": "Wenzhi Yang, Shuhe Hu and Xuejun Wang", "title": "The Bahadur representation for sample quantiles under dependent sequence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  On the one hand, we investigate the Bahadur representation for sample\nquantiles under $\\varphi$-mixing sequence with $\\varphi(n)=O(n^{-3})$ and\nobtain a rate as $O(n^{-\\frac{3}{4}}\\log n)$, $a.s.$. On the other hand, by\nrelaxing the condition of mixing coefficients to\n$\\sum\\nolimits_{n=1}^\\infty\\varphi^{1/2}(n)<\\infty$, a rate $O(n^{-1/2}(\\log\nn)^{1/2})$, $a.s.$, is also obtained.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jan 2019 04:46:39 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Yang", "Wenzhi", ""], ["Hu", "Shuhe", ""], ["Wang", "Xuejun", ""]]}, {"id": "1901.04134", "submitter": "Debdeep Pati", "authors": "Yabo Niu, Debdeep Pati, Bani Mallick", "title": "Bayesian Graph Selection Consistency Under Model Misspecification", "comments": "43 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian graphical models are a popular tool to learn the dependence\nstructure in the form of a graph among variables of interest. Bayesian methods\nhave gained in popularity in the last two decades due to their ability to\nsimultaneously learn the covariance and the graph and characterize uncertainty\nin the selection. For scalability of the Markov chain Monte Carlo algorithms,\ndecomposability is commonly imposed on the graph space. A wide variety of\ngraphical conjugate priors are proposed jointly on the covariance matrix and\nthe graph with improved algorithms to search along the space of decomposable\ngraphs, rendering the methods extremely popular in the context of multivariate\ndependence modeling. {\\it An open problem} in Bayesian decomposable structure\nlearning is whether the posterior distribution is able to select a meaningful\ndecomposable graph that it is ``close'' in an appropriate sense to the true\nnon-decomposable graph, when the dimension of the variables increases with the\nsample size. In this article, we explore specific conditions on the true\nprecision matrix and the graph which results in an affirmative answer to this\nquestion using a commonly used hyper-inverse Wishart prior on the covariance\nmatrix and a suitable complexity prior on the graph space, both in the\nwell-specified and misspecified settings. In absence of structural sparsity\nassumptions, our strong selection consistency holds in a high dimensional\nsetting where $p = O(n^{\\alpha})$ for $\\alpha < 1/3$. We show when the true\ngraph is non-decomposable, the posterior distribution on the graph concentrates\non a set of graphs that are {\\it minimal triangulations} of the true graph.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jan 2019 05:24:55 GMT"}, {"version": "v2", "created": "Mon, 1 Apr 2019 01:22:14 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Niu", "Yabo", ""], ["Pati", "Debdeep", ""], ["Mallick", "Bani", ""]]}, {"id": "1901.04183", "submitter": "Yaakov Malinovsky", "authors": "Alexander Goldenshluger, Yaakov Malinovsky, Assaf Zeevi", "title": "A Unified Approach for Solving Sequential Selection Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we develop a unified approach for solving a wide class of\nsequential selection problems. This class includes, but is not limited to,\nselection problems with no-information, rank-dependent rewards, and considers\nboth fixed as well as random problem horizons. The proposed framework is based\non a reduction of the original selection problem to one of optimal stopping for\na sequence of judiciously constructed independent random variables. We\ndemonstrate that our approach allows exact and efficient computation of optimal\npolicies and various performance metrics thereof for a variety of sequential\nselection problems, several of which have not been solved to date.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jan 2019 08:41:50 GMT"}, {"version": "v2", "created": "Thu, 17 Jan 2019 12:57:16 GMT"}, {"version": "v3", "created": "Fri, 25 Jan 2019 13:25:26 GMT"}, {"version": "v4", "created": "Mon, 27 May 2019 18:35:14 GMT"}, {"version": "v5", "created": "Thu, 23 Jan 2020 21:52:48 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Goldenshluger", "Alexander", ""], ["Malinovsky", "Yaakov", ""], ["Zeevi", "Assaf", ""]]}, {"id": "1901.04691", "submitter": "Gabriela Ciuperca", "authors": "Gabriela Ciuperca and Mat\\'u\\v{s} Maciak", "title": "Change-point Detection by the Quantile LASSO Method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A simultaneous change-point detection and estimation in a piece-wise constant\nmodel is a common task in modern statistics. If, in addition, the whole\nestimation can be performed automatically, in just one single step without\ngoing through any hypothesis tests for non-identifiable models, or unwieldy\nclassical a-posterior methods, it becomes an interesting, but also challenging\nidea. In this paper we introduce the estimation method based on the quantile\nLASSO approach. Unlike standard LASSO approaches, our method does not rely on\ntypical assumptions usually required for the model errors, such as sub-Gaussian\nor Normal distribution. The proposed quantile LASSO method can effectively\nhandle heavy-tailed random error distributions, and, in general, it offers a\nmore complex view of the data as one can obtain any conditional quantile of the\ntarget distribution, not just the conditional mean. It is proved that under\nsome reasonable assumptions the number of change-points is not underestimated\nwith probability tenting to one, and, in addition, when the number of\nchange-points is estimated correctly, the change-point estimates provided by\nthe quantile LASSO are consistent. Numerical simulations are used to\ndemonstrate these results and to illustrate the empirical performance robust\nfavor of the proposed quantile LASSO method.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2019 07:32:06 GMT"}], "update_date": "2019-01-16", "authors_parsed": [["Ciuperca", "Gabriela", ""], ["Maciak", "Mat\u00fa\u0161", ""]]}, {"id": "1901.04861", "submitter": "Zheng Fang", "authors": "Qihui Chen and Zheng Fang", "title": "Inference on Functionals under First Order Degeneracy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a unified second order asymptotic framework for\nconducting inference on parameters of the form $\\phi(\\theta_0)$, where\n$\\theta_0$ is unknown but can be estimated by $\\hat\\theta_n$, and $\\phi$ is a\nknown map that admits null first order derivative at $\\theta_0$. For a large\nnumber of examples in the literature, the second order Delta method reveals a\nnondegenerate weak limit for the plug-in estimator $\\phi(\\hat\\theta_n)$. We\nshow, however, that the `standard' bootstrap is consistent if and only if the\nsecond order derivative $\\phi_{\\theta_0}''=0$ under regularity conditions,\ni.e., the standard bootstrap is inconsistent if $\\phi_{\\theta_0}''\\neq 0$, and\nprovides degenerate limits unhelpful for inference otherwise. We thus identify\na source of bootstrap failures distinct from that in Fang and Santos (2018)\nbecause the problem (of consistently bootstrapping a \\textit{nondegenerate}\nlimit) persists even if $\\phi$ is differentiable. We show that the correction\nprocedure in Babu (1984) can be extended to our general setup. Alternatively, a\nmodified bootstrap is proposed when the map is \\textit{in addition} second\norder nondifferentiable. Both are shown to provide local size control under\nsome conditions. As an illustration, we develop a test of common conditional\nheteroskedastic (CH) features, a setting with both degeneracy and\nnondifferentiability -- the latter is because the Jacobian matrix is degenerate\nat zero and we allow the existence of multiple common CH features.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2019 14:40:27 GMT"}], "update_date": "2019-01-16", "authors_parsed": [["Chen", "Qihui", ""], ["Fang", "Zheng", ""]]}, {"id": "1901.04885", "submitter": "Jelle Goeman", "authors": "Jelle Goeman, Jesse Hemerik, Aldo Solari", "title": "Only Closed Testing Procedures are Admissible for Controlling False\n  Discovery Proportions", "comments": null, "journal-ref": null, "doi": "10.1214/20-AOS1999", "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the class of all multiple testing methods controlling tail\nprobabilities of the false discovery proportion, either for one random set or\nsimultaneously for many such sets. This class encompasses methods controlling\nfamilywise error rate, generalized familywise error rate, false discovery\nexceedance, joint error rate, simultaneous control of all false discovery\nproportions, and others, as well as seemingly unrelated methods such as gene\nset testing in genomics and cluster inference methods in neuroimaging. We show\nthat all such methods are either equivalent to a closed testing method, or are\nuniformly improved by one. Moreover, we show that a closed testing method is\nadmissible as a method controlling tail probabilities of false discovery\nproportions if and only if all its local tests are admissible. This implies\nthat, when designing such methods, it is sufficient to restrict attention to\nclosed testing methods only. We demonstrate the practical usefulness of this\ndesign principle by constructing a uniform improvement of a recently proposed\nmethod.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2019 15:41:38 GMT"}, {"version": "v2", "created": "Tue, 5 Feb 2019 15:51:14 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Goeman", "Jelle", ""], ["Hemerik", "Jesse", ""], ["Solari", "Aldo", ""]]}, {"id": "1901.04953", "submitter": "Stefan Steinerberger", "authors": "Stefan Steinerberger", "title": "A forgotten Theorem of Schoenberg on one-sided integral averages", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CA math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $f:\\mathbb{R} \\rightarrow \\mathbb{R}$ be a function for which we want to\ntake local averages. Assuming we cannot look into the future, the 'average' at\ntime $t$ can only use $f(s)$ for $s \\leq t$. A natural way to do so is via a\nweight $\\phi$ and $$ g(t) = \\int_{0}^{\\infty}{f(t-s) \\phi(s) ds}.$$ We would\nlike that (1) constant functions, $f(t) \\equiv \\mbox{const}$, are mapped to\nthemselves and (2) $\\phi$ to be monotonically decreasing (the more recent past\nshould weigh more heavily than the distant past). Moreover, we want that (3) if\n$f(t)$ crosses a certain threshold $n$ times, then $g(t)$ should not cross the\nsame threshold more than $n$ times (if $f(t)$ is the outside wind speed and\ncrosses the Tornado threshold at two points in time, we would like the averaged\nwind speed to cross the Tornado threshold at most twice). A Theorem implicit in\nthe work of Schonberg is that these three conditions characterize a unique\nweight that is given by the exponential distribution $$ \\phi(s) = \\lambda^{}\ne^{-\\lambda s} \\qquad \\mbox{for some} \\quad \\lambda > 0.$$\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2019 17:53:38 GMT"}, {"version": "v2", "created": "Sun, 3 Feb 2019 22:36:48 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Steinerberger", "Stefan", ""]]}, {"id": "1901.05078", "submitter": "Aritra Guha", "authors": "Aritra Guha, Nhat Ho and XuanLong Nguyen", "title": "On posterior contraction of parameters and interpretability in Bayesian\n  mixture modeling", "comments": "53 pages; 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study posterior contraction behaviors for parameters of interest in the\ncontext of Bayesian mixture modeling, where the number of mixing components is\nunknown while the model itself may or may not be correctly specified. Two\nrepresentative types of prior specification will be considered: one requires\nexplicitly a prior distribution on the number of mixture components, while the\nother places a nonparametric prior on the space of mixing distributions. The\nformer is shown to yield an optimal rate of posterior contraction on the model\nparameters under minimal conditions, while the latter can be utilized to\nconsistently recover the unknown number of mixture components, with the help of\na fast probabilistic post-processing procedure. We then turn the study of these\nBayesian procedures to the realistic settings of model misspecification. It\nwill be shown that the modeling choice of kernel density functions plays\nperhaps the most impactful roles in determining the posterior contraction rates\nin the misspecified situations. Drawing on concrete posterior contraction rates\nestablished in this paper we wish to highlight some aspects about the\ninteresting tradeoffs between model expressiveness and interpretability that a\nstatistical modeler must negotiate in the rich world of mixture modeling.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2019 22:41:56 GMT"}], "update_date": "2019-01-17", "authors_parsed": [["Guha", "Aritra", ""], ["Ho", "Nhat", ""], ["Nguyen", "XuanLong", ""]]}, {"id": "1901.05166", "submitter": "Long Yu", "authors": "Jun Wen, Jiahui Xie, Long Yu and Wang Zhou", "title": "Tracy-Widom limit for the largest eigenvalue of high-dimensional\n  covariance matrices in elliptical distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $X$ be an $M\\times N$ random matrix consisting of independent $M$-variate\nelliptically distributed column vectors $\\mathbf{x}_{1},\\dots,\\mathbf{x}_{N}$\nwith general population covariance matrix $\\Sigma$. In the literature, the\nquantity $XX^{*}$ is referred to as the sample covariance matrix after scaling,\nwhere $X^{*}$ is the transpose of $X$. In this article, we prove that the\nlimiting behavior of the scaled largest eigenvalue of $XX^{*}$ is universal for\na wide class of elliptical distributions, namely, the scaled largest eigenvalue\nconverges weakly to the same limit regardless of the distributions that\n$\\mathbf{x}_{1},\\dots,\\mathbf{x}_{N}$ follow as $M,N\\to\\infty$ with\n$M/N\\to\\phi_0>0$ if the weak fourth moment of the radius of $\\mathbf{x}_{1}$\nexists . In particular, via comparing the Green function with that of the\nsample covariance matrix of multivariate normally distributed data, we conclude\nthat the limiting distribution of the scaled largest eigenvalue is the\ncelebrated Tracy-Widom law.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2019 07:47:48 GMT"}, {"version": "v2", "created": "Wed, 2 Jun 2021 05:57:22 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Wen", "Jun", ""], ["Xie", "Jiahui", ""], ["Yu", "Long", ""], ["Zhou", "Wang", ""]]}, {"id": "1901.05367", "submitter": "Jean-Fran\\c{c}ois Coeurjolly", "authors": "Jean-Fran\\c{c}ois Coeurjolly, Jo\\\"elle Rousseau-Tr\\'epanier", "title": "The median of a jittered Poisson distribution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $N_\\lambda$ and $U$ be two independent random variables respectively\ndistributed as a Poisson distribution with parameter $\\lambda >0$ and a uniform\ndistribution on $(0,1)$. This paper establishes that the median, say $M$, of\n$N_\\lambda+U$ is close to $\\lambda +1/3$ and more precisely that\n$M-\\lambda-1/3=o(\\lambda^{-1})$ as $\\lambda\\to \\infty$. This result is used to\nconstrut a very simple robust estimator of $\\lambda$ which is consistent and\nasymptotically normal. Compared to known robust estimates, this one can still\nbe used with large datasets ($n\\simeq 10^9$).\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2019 16:15:03 GMT"}], "update_date": "2019-01-17", "authors_parsed": [["Coeurjolly", "Jean-Fran\u00e7ois", ""], ["Rousseau-Tr\u00e9panier", "Jo\u00eblle", ""]]}, {"id": "1901.05380", "submitter": "Vytaut\\.e Pilipauskait\\.e", "authors": "Vytaut\\.e Pilipauskait\\.e, Viktor Skorniakov, Donatas Surgailis", "title": "Joint temporal and contemporaneous aggregation of random-coefficient\n  AR(1) processes with infinite variance", "comments": null, "journal-ref": "Advances in Applied Probability, Volume 52, Issue 1 (2020),\n  237-265", "doi": "10.1017/apr.2019.59", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss joint temporal and contemporaneous aggregation of $N$ independent\ncopies of random-coefficient AR(1) process driven by i.i.d. innovations in the\ndomain of normal attraction of an $\\alpha$-stable distribution, $0< \\alpha \\le\n2$, as both $N$ and the time scale $n$ tend to infinity, possibly at a\ndifferent rate. Assuming that the tail distribution function of the random\nautoregressive coefficient regularly varies at the unit root with exponent\n$\\beta > 0$, we show that, for $\\beta < \\max (\\alpha, 1)$, the joint aggregate\ndisplays a variety of stable and non-stable limit behaviors with stability\nindex depending on $\\alpha$, $\\beta$ and the mutual increase rate of $N$ and\n$n$. The paper extends the results of Pilipauskait\\.e and Surgailis (2014) from\n$\\alpha = 2$ to $0 < \\alpha < 2$.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2019 16:45:10 GMT"}, {"version": "v2", "created": "Fri, 8 Nov 2019 19:20:31 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Pilipauskait\u0117", "Vytaut\u0117", ""], ["Skorniakov", "Viktor", ""], ["Surgailis", "Donatas", ""]]}, {"id": "1901.05410", "submitter": "Juozas Vaicenavicius", "authors": "Erik Ekstr\\\"om, Ioannis Karatzas, Juozas Vaicenavicius", "title": "Bayesian sequential least-squares estimation for the drift of a Wiener\n  process", "comments": "20 pages, an updated version (typos fixed, improved presentation)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a Wiener process with unknown and unobservable drift, we try to\nestimate this drift as effectively but also as quickly as possible, in the\npresence of a quadratic penalty for the estimation error and of a fixed,\npositive cost per unit of observation time. In a Bayesian framework, where the\nunobservable drift is assumed to have a known \"prior\" distribution, this\nquestion reduces to choosing judiciously a stopping time for an appropriate\ndiffusion process in natural scale. We establish structural properties of the\nsolution for the corresponding problem of optimal stopping. In particular, we\nshow that, regardless of the prior distribution, the continuation region is\nmonotonically shrinking in time; and provide conditions on the prior\ndistribution guaranteeing a one-sided stopping region. Finally, we illustrate\nthe theoretical results through a detailed study of some concrete prior\ndistributions.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2019 17:51:06 GMT"}, {"version": "v2", "created": "Thu, 23 May 2019 06:12:06 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Ekstr\u00f6m", "Erik", ""], ["Karatzas", "Ioannis", ""], ["Vaicenavicius", "Juozas", ""]]}, {"id": "1901.05501", "submitter": "Holger Drees", "authors": "Holger Drees, Miran Knezevic", "title": "Peak-over-Threshold Estimators for Spectral Tail Processes: Random vs\n  Deterministic Thresholds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The extreme value dependence of regularly varying stationary time series can\nbe described by the spectral tail process. Drees, Segers and Warchol [Extremes\n18(3): 369--402, 2015] proposed estimators of the marginal distributions of\nthis process based on exceedances over high deterministic thresholds and\nanalyzed their asymptotic behavior. In practice, however, versions of the\nestimators are applied which use exceedances over random thresholds like\nintermediate order statistics. We prove that these modified estimators have the\nsame limit distributions. This finding is corroborated in a simulation study,\nbut the version using order statistics performs a bit better for finite\nsamples.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2019 19:21:47 GMT"}, {"version": "v2", "created": "Mon, 22 Jul 2019 09:11:47 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Drees", "Holger", ""], ["Knezevic", "Miran", ""]]}, {"id": "1901.05507", "submitter": "Lukasz Szpruch LS", "authors": "H. AlRachid, Mireille Bossy, Cristiano Ricci, Lukasz Szpruch", "title": "New particle representations for ergodic McKean-Vlasov SDEs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of this paper is to introduce several new particle representations\nfor \\textit{ergodic} McKean-Vlasov SDEs. We construct new algorithms by\nleveraging recent progress in weak convergence analysis of interacting particle\nsystem. We present detailed analysis of errors and associated costs of various\nestimators, highlighting key differences between long-time simulations of\nlinear (classical SDEs) versus non-linear (Mckean-Vlasov SDEs) process.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2019 19:37:05 GMT"}], "update_date": "2019-01-18", "authors_parsed": [["AlRachid", "H.", ""], ["Bossy", "Mireille", ""], ["Ricci", "Cristiano", ""], ["Szpruch", "Lukasz", ""]]}, {"id": "1901.05543", "submitter": "Florent Benaych-Georges", "authors": "Florent Benaych-Georges, Jean-Philippe Bouchaud, Marc Potters", "title": "Optimal cleaning for singular values of cross-covariance matrices", "comments": "34 pages, 6 figures. In v2: details added in some proofs and remark\n  about estimator convergence added in the Optimality section (Sect. 1.3). In\n  v3: added details about the global effect of error in estimating ideally\n  cleaned singular values", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a new algorithm for the estimation of the cross-covariance matrix\n$\\mathbb{E} XY'$ of two large dimensional signals $X\\in\\mathbb{R}^n$,\n$Y\\in\\mathbb{R}^p$ in the context where the number $T$ of observations of the\npair $(X,Y)$ is itself large, but with $n,p$ non negligible with respect to\n$T$. This algorithm is optimal among rotationally invariant estimators, i.e.\nestimators derived from the empirical estimator by cleaning the singular\nvalues, while letting singular vectors unchanged. We give an interpretation of\nthe singular value cleaning in terms of overfitting ratios.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2019 21:56:32 GMT"}, {"version": "v2", "created": "Sat, 25 Jan 2020 13:38:22 GMT"}, {"version": "v3", "created": "Fri, 18 Dec 2020 00:28:20 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Benaych-Georges", "Florent", ""], ["Bouchaud", "Jean-Philippe", ""], ["Potters", "Marc", ""]]}, {"id": "1901.05547", "submitter": "Hamid El Maroufy", "authors": "M. El Omari, H. El Maroufy and C. Fuchs", "title": "Nonparametric estimation for fractional diffusion processes with random\n  effects", "comments": "19 pages, 24 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a nonparametric estimation for a class of fractional stochastic\ndifferential equations (FSDE) with random effects. We precisely consider\ngeneral linear fractional stochastic differential equations with drift\ndepending on random effects and non-random diffusion. We build ordinary kernel\nestimators and histogram estimators and study their Lp-risk (p =1 or 2), when\nH>1/2. Asymptotic results are evaluated as both T = T(N) and N tend to\ninfinity.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2019 22:17:14 GMT"}], "update_date": "2019-01-18", "authors_parsed": [["Omari", "M. El", ""], ["Maroufy", "H. El", ""], ["Fuchs", "C.", ""]]}, {"id": "1901.05595", "submitter": "Yanqing Yin", "authors": "Yanqing Yin", "title": "Model-Free Tests for Series Correlation in Multivariate Linear\n  Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Testing for series correlation among error terms is a basic problem in linear\nregression model diagnostics. The famous Durbin-Watson test and Durbin's h-test\nrely on certain model assumptions about the response and regressor variables.\nThe present paper proposes simple tests for series correlation that are\napplicable in both fixed and random design linear regression models. The test\nstatistics are based on the regression residuals and design matrix. The test\nprocedures are robust under different distributions of random errors. The\nasymptotic distributions of the proposed statistics are derived via a newly\nestablished joint central limit theorem for several general quadratic forms and\nthe delta method. Good performance of the proposed tests is demonstrated by\nsimulation results.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jan 2019 02:52:00 GMT"}], "update_date": "2019-01-18", "authors_parsed": [["Yin", "Yanqing", ""]]}, {"id": "1901.05764", "submitter": "Jianhua Shi", "authors": "Jianhua Shi, Jiansen Xu", "title": "Strong Asymptotic Properties of Kernel Smooth Density and Hazard\n  Function Estimation for Right Censoring NA Random Variable", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most studies for NA random variable is under complete sampling setting, which\nis actually an relatively ideal condition in application. The paper relaxes\nthis condition to the censoring incomplete sampling data and considers the\ntopic for kernel estimation of the density function together with the hazard\nfunction based on the Kaplan-Meier estimator. The strong asymptotic properties\nfor the two estimators are firstly established.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jan 2019 12:40:55 GMT"}, {"version": "v2", "created": "Wed, 23 Jan 2019 15:00:50 GMT"}, {"version": "v3", "created": "Thu, 24 Jan 2019 14:34:18 GMT"}, {"version": "v4", "created": "Mon, 11 Feb 2019 04:50:43 GMT"}, {"version": "v5", "created": "Sat, 6 Feb 2021 11:55:01 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Shi", "Jianhua", ""], ["Xu", "Jiansen", ""]]}, {"id": "1901.06386", "submitter": "Fabian Telschow J. E.", "authors": "Fabian J.E. Telschow and Armin Schwartzman", "title": "Simultaneous Confidence Bands for Functional Data Using the Gaussian\n  Kinematic Formula", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article constructs simultaneous confidence bands (SCBs) for functional\nparameters using the Gaussian Kinematic formula of $t$-processes (tGKF).\nAlthough the tGKF relies on Gaussianity, we show that a central limit theorem\n(CLT) for the parameter of interest is enough to obtain asymptotically precise\ncovering rates even for non-Gaussian processes. As a proof of concept we study\nthe functional signal-plus-noise model and derive a CLT for an estimator of the\nLipschitz-Killing curvatures, the only data dependent quantities in the tGKF\nSCBs. Extensions to discrete sampling with additive observation noise are\ndiscussed using scale space ideas from regression analysis. Here we provide\nsufficient conditions on the processes and kernels to obtain convergence of the\nfunctional scale space surface.\n  The theoretical work is accompanied by a simulation study comparing different\nmethods to construct SCBs for the population mean. We show that the tGKF works\nwell even for small sample sizes and only a Rademacher multiplier-$t$ bootstrap\nperforms similarily well. For larger sample sizes the tGKF often outperforms\nthe bootstrap methods and is computational faster. We apply the method to\ndiffusion tensor imaging (DTI) fibers using a scale space approach for the\ndifference of population means. R code is available in our Rpackage SCBfda.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jan 2019 16:29:10 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Telschow", "Fabian J. E.", ""], ["Schwartzman", "Armin", ""]]}, {"id": "1901.06418", "submitter": "Francesco Ortelli", "authors": "Francesco Ortelli and Sara van de Geer", "title": "Synthesis and analysis in total variation regularization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We generalize the bridge between analysis and synthesis estimators by Elad,\nMilanfar and Rubinstein (2007) to rank deficient cases. This is a starting\npoint for the study of the connection between analysis and synthesis for total\nvariation regularized estimators. In particular, the case of first order total\nvariation regularized estimators over general graphs and their synthesis form\nare studied.\n  We give a definition of the discrete graph derivative operator based on the\nnotion of line graph and provide examples of the synthesis form of\n$k^{\\text{th}}$ order total variation regularized estimators over a range of\ngraphs.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jan 2019 21:30:19 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Ortelli", "Francesco", ""], ["van de Geer", "Sara", ""]]}, {"id": "1901.06462", "submitter": "Jingchen Hu", "authors": "Jingchen Hu, Terrance D. Savitsky", "title": "Bayesian Pseudo Posterior Synthesis for Data Privacy Protection", "comments": "This is to replace arXiv:1908.07639", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.AP stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical agencies utilize models to synthesize respondent-level data for\nrelease to the general public as an alternative to the actual data records. A\nBayesian model synthesizer encodes privacy protection by employing a\nhierarchical prior construction that induces smoothing of the real data\ndistribution. Synthetic respondent-level data records are often preferred to\nsummary data tables due to the many possible uses by researchers and data\nanalysts. Agencies balance a trade-off between utility of the synthetic data\nversus disclosure risks and hold a specific target threshold for disclosure\nrisk before releasing synthetic datasets. We introduce a pseudo posterior\nlikelihood that exponentiates each contribution by an observation\nrecord-indexed weight in (0, 1), defined to be inversely proportional to the\ndisclosure risk for that record in the synthetic data. Our use of a vector of\nweights allows more precise downweighting of high risk records in a fashion\nthat better preserves utility as compared with using a scalar weight. We\nillustrate our method with a simulation study and an application to the\nConsumer Expenditure Survey of the U.S. Bureau of Labor Statistics. We\ndemonstrate how the frequentist consistency and uncertainty quantification are\naffected by the inverse risk-weighting.\n", "versions": [{"version": "v1", "created": "Sat, 19 Jan 2019 03:29:28 GMT"}, {"version": "v2", "created": "Tue, 23 Jul 2019 16:02:25 GMT"}, {"version": "v3", "created": "Fri, 15 May 2020 21:03:42 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Hu", "Jingchen", ""], ["Savitsky", "Terrance D.", ""]]}, {"id": "1901.06478", "submitter": "Pan Shang", "authors": "Pan Shang, Lingchen Kong", "title": "Tuning parameter selection rules for nuclear norm regularized\n  multivariate linear regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the tuning parameter selection rules for nuclear norm regularized\nmultivariate linear regression (NMLR) in high-dimensional setting.\nHigh-dimensional multivariate linear regression is widely used in statistics\nand machine learning, and regularization technique is commonly applied to deal\nwith the special structures in high-dimensional data. As we know, how to select\nthe tuning parameter is an essential issue for regularization approach and it\ndirectly affects the model estimation performance. To the best of our\nknowledge, there are no rules about the tuning parameter selection for NMLR\nfrom the point of view of optimization. In order to establish such rules, we\nstudy the duality theory of NMLR. Then, we claim the choice of tuning parameter\nfor NMLR is based on the sample data and the solution of NMLR dual problem,\nwhich is a projection on a nonempty, closed and convex set. Moreover, based on\nthe (firm) nonexpansiveness and the idempotence of the projection operator, we\nbuild four tuning parameter selection rules PSR, PSRi, PSRfn and PSR+.\nFurthermore, we give a sequence of tuning parameters and the corresponding\nintervals for every rule, which states that the rank of the estimation\ncoefficient matrix is no more than a fixed number for the tuning parameter in\nthe given interval. The relationships between these rules are also discussed\nand PSR+ is the most efficient one to select the tuning parameter. Finally, the\nnumerical results are reported on simulation and real data, which show that\nthese four tuning parameter selection rules are valuable.\n", "versions": [{"version": "v1", "created": "Sat, 19 Jan 2019 07:52:33 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Shang", "Pan", ""], ["Kong", "Lingchen", ""]]}, {"id": "1901.06750", "submitter": "Samuel Orso", "authors": "St\\'ephane Guerrier, Mucyo Karemera, Samuel Orso, Maria-Pia\n  Victoria-Feser", "title": "A simple recipe for making accurate parametric inference in finite\n  sample", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Constructing tests or confidence regions that control over the error rates in\nthe long-run is probably one of the most important problem in statistics. Yet,\nthe theoretical justification for most methods in statistics is asymptotic. The\nbootstrap for example, despite its simplicity and its widespread usage, is an\nasymptotic method. There are in general no claim about the exactness of\ninferential procedures in finite sample. In this paper, we propose an\nalternative to the parametric bootstrap. We setup general conditions to\ndemonstrate theoretically that accurate inference can be claimed in finite\nsample.\n", "versions": [{"version": "v1", "created": "Sun, 20 Jan 2019 23:37:11 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Guerrier", "St\u00e9phane", ""], ["Karemera", "Mucyo", ""], ["Orso", "Samuel", ""], ["Victoria-Feser", "Maria-Pia", ""]]}, {"id": "1901.06795", "submitter": "Dhruva Kartik", "authors": "Dhruva Kartik, Ashutosh Nayyar, Urbashi Mitra", "title": "Active Hypothesis Testing: Beyond Chernoff-Stein", "comments": "Submitted to 2019 IEEE International Symposium on Information Theory\n  (ISIT)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An active hypothesis testing problem is formulated. In this problem, the\nagent can perform a fixed number of experiments and then decide on one of the\nhypotheses. The agent is also allowed to declare its experiments inconclusive\nif needed. The objective is to minimize the probability of making an incorrect\ninference (misclassification probability) while ensuring that the true\nhypothesis is declared conclusively with moderately high probability. For this\nproblem, lower and upper bounds on the optimal misclassification probability\nare derived and these bounds are shown to be asymptotically tight. In the\nanalysis, a sub-problem, which can be viewed as a generalization of the\nChernoff-Stein lemma, is formulated and analyzed. A heuristic approach to\nstrategy design is proposed and its relationship with existing heuristic\nstrategies is discussed.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2019 05:50:23 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Kartik", "Dhruva", ""], ["Nayyar", "Ashutosh", ""], ["Mitra", "Urbashi", ""]]}, {"id": "1901.06976", "submitter": "Amitabh Basu", "authors": "Amitabh Basu, Tu Nguyen, Ao Sun", "title": "Admissibility of solution estimators for stochastic optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We look at stochastic optimization problems through the lens of statistical\ndecision theory. In particular, we address admissibility, in the statistical\ndecision theory sense, of the natural sample average estimator for a stochastic\noptimization problem (which is also known as the empirical risk minimization\n(ERM) rule in learning literature). It is well known that for some simple\nstochastic optimization problems, the sample average estimator may not be\nadmissible. This is known as {\\em Stein's paradox} in the statistics\nliterature. We show in this paper that for optimizing stochastic linear\nfunctions over compact sets, the sample average estimator is admissible.\nMoreover, we study problems with convex quadratic objectives subject to box\nconstraints. Stein's paradox holds when there are no constraints and the\ndimension of the problem is at least three. We show that in the presence of box\nconstraints, admissibility is recovered for dimensions 3 and 4.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2019 15:55:13 GMT"}, {"version": "v2", "created": "Wed, 23 Jan 2019 17:33:57 GMT"}, {"version": "v3", "created": "Sat, 5 Oct 2019 18:27:08 GMT"}, {"version": "v4", "created": "Sat, 23 May 2020 19:18:56 GMT"}, {"version": "v5", "created": "Fri, 18 Sep 2020 19:26:54 GMT"}, {"version": "v6", "created": "Wed, 21 Oct 2020 20:56:58 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Basu", "Amitabh", ""], ["Nguyen", "Tu", ""], ["Sun", "Ao", ""]]}, {"id": "1901.07090", "submitter": "Subhadeep Mukhopadhyay", "authors": "Subhadeep Mukhopadhyay and Kaijun Wang", "title": "Spectral Graph Analysis: A Unified Explanation and Modern Perspectives", "comments": "The first draft of the paper was written in June 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complex networks or graphs are ubiquitous in sciences and engineering:\nbiological networks, brain networks, transportation networks, social networks,\nand the World Wide Web, to name a few. Spectral graph theory provides a set of\nuseful techniques and models for understanding `patterns of interconnectedness'\nin a graph. Our prime focus in this paper is on the following question: Is\nthere a unified explanation and description of the fundamental spectral graph\nmethods? There are at least two reasons to be interested in this question.\nFirstly, to gain a much deeper and refined understanding of the basic\nfoundational principles, and secondly, to derive rich consequences with\npractical significance for algorithm design. However, despite half a century of\nresearch, this question remains one of the most formidable open issues, if not\nthe core problem in modern network science. The achievement of this paper is to\ntake a step towards answering this question by discovering a simple, yet\nuniversal statistical logic of spectral graph analysis. The prescribed\nviewpoint appears to be good enough to accommodate almost all existing spectral\ngraph techniques as a consequence of just one single formalism and algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2019 21:41:52 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Mukhopadhyay", "Subhadeep", ""], ["Wang", "Kaijun", ""]]}, {"id": "1901.07114", "submitter": "Tengyuan Liang", "authors": "Xialiang Dou, Tengyuan Liang", "title": "Training Neural Networks as Learning Data-adaptive Kernels: Provable\n  Representation and Approximation Benefits", "comments": "38 pages, 5 figures", "journal-ref": "Journal of the American Statistical Association (2020)", "doi": "10.1080/01621459.2020.1745812", "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider the problem: given the data pair $(\\mathbf{x}, \\mathbf{y})$ drawn\nfrom a population with $f_*(x) = \\mathbf{E}[\\mathbf{y} | \\mathbf{x} = x]$,\nspecify a neural network model and run gradient flow on the weights over time\nuntil reaching any stationarity. How does $f_t$, the function computed by the\nneural network at time $t$, relate to $f_*$, in terms of approximation and\nrepresentation? What are the provable benefits of the adaptive representation\nby neural networks compared to the pre-specified fixed basis representation in\nthe classical nonparametric literature? We answer the above questions via a\ndynamic reproducing kernel Hilbert space (RKHS) approach indexed by the\ntraining process of neural networks. Firstly, we show that when reaching any\nlocal stationarity, gradient flow learns an adaptive RKHS representation and\nperforms the global least-squares projection onto the adaptive RKHS,\nsimultaneously. Secondly, we prove that as the RKHS is data-adaptive and\ntask-specific, the residual for $f_*$ lies in a subspace that is potentially\nmuch smaller than the orthogonal complement of the RKHS. The result formalizes\nthe representation and approximation benefits of neural networks. Lastly, we\nshow that the neural network function computed by gradient flow converges to\nthe kernel ridgeless regression with an adaptive kernel, in the limit of\nvanishing regularization. The adaptive kernel viewpoint provides new angles of\nstudying the approximation, representation, generalization, and optimization\nadvantages of neural networks.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2019 23:15:16 GMT"}, {"version": "v2", "created": "Tue, 23 Jul 2019 15:03:28 GMT"}], "update_date": "2020-07-27", "authors_parsed": [["Dou", "Xialiang", ""], ["Liang", "Tengyuan", ""]]}, {"id": "1901.07277", "submitter": "Sylvain Arlot", "authors": "Sylvain Arlot (LMO, CELESTE)", "title": "Minimal penalties and the slope heuristics: a survey", "comments": null, "journal-ref": "Journal de la Societe Fran{\\c c}aise de Statistique, Societe\n  Fran{\\c c}aise de Statistique et Societe Mathematique de France, 2019,\n  Minimal penalties and the slope heuristics: a survey, 160 (3), pp.1-106", "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Birg{\\'e} and Massart proposed in 2001 the slope heuristics as a way to\nchoose optimally from data an unknown multiplicative constant in front of a\npenalty. It is built upon the notion of minimal penalty, and it has been\ngeneralized since to some \"minimal-penalty algorithms\". This paper reviews the\ntheoretical results obtained for such algorithms, with a self-contained proof\nin the simplest framework, precise proof ideas for further generalizations, and\na few new results. Explicit connections are made with residual-variance\nestimators-with an original contribution on this topic, showing that for this\ntask the slope heuristics performs almost as well as a residual-based estimator\nwith the best model choice-and some classical algorithms such as L-curve or\nelbow heuristics, Mallows' C p , and Akaike's FPE. Practical issues are also\naddressed, including two new practical definitions of minimal-penalty\nalgorithms that are compared on synthetic data to previously-proposed\ndefinitions. Finally, several conjectures and open problems are suggested as\nfuture research directions.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2019 11:58:12 GMT"}, {"version": "v2", "created": "Fri, 25 Oct 2019 12:41:53 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Arlot", "Sylvain", "", "LMO, CELESTE"]]}, {"id": "1901.07318", "submitter": "Xin Tong Thomson", "authors": "Nan Chen and Andrew J. Majda and Xin T. Tong", "title": "Spatial localization for nonlinear dynamical stochastic models for\n  excitable media", "comments": "34 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonlinear dynamical stochastic models are ubiquitous in different areas.\nExcitable media models are typical examples with large state dimensions. Their\nstatistical properties are often of great interest but are also very\nchallenging to compute. In this article, a theoretical framework to understand\nthe spatial localization for a large class of stochastically coupled nonlinear\nsystems in high dimensions is developed. Rigorous mathematical theories show\nthe covariance decay behavior due to both local and nonlocal effects, which\nresult from the diffusion and the mean field interaction, respectively. The\nanalysis is based on a comparison with an appropriate linear surrogate model,\nof which the covariance propagation can be computed explicitly. Two important\napplications of these theoretical results are discussed. They are the spatial\naveraging strategy for efficiently sampling the covariance matrix and the\nlocalization technique in data assimilation. Test examples of a surrogate\nlinear model and a stochastically coupled FitzHugh-Nagumo model for excitable\nmedia are adopted to validate the theoretical results. The latter is also used\nfor a systematical study of the spatial averaging strategy in efficiently\nsampling the covariance matrix in different dynamical regimes.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jan 2019 20:35:35 GMT"}, {"version": "v2", "created": "Sat, 26 Jan 2019 05:52:54 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Chen", "Nan", ""], ["Majda", "Andrew J.", ""], ["Tong", "Xin T.", ""]]}, {"id": "1901.07377", "submitter": "Dan Li", "authors": "Dan Li and Sonia Martinez", "title": "Data assimilation and online optimization with performance guarantees", "comments": "IEEE Transactions on Automatic Control. A preliminary work appeared\n  in 10.1109/CDC.2018.8619159 and arxiv:1803.07984", "journal-ref": null, "doi": "10.1109/TAC.2020.3005681", "report-no": null, "categories": "math.OC cs.SY eess.SP eess.SY math.ST stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers a class of real-time stochastic optimization problems\ndependent on an unknown probability distribution. In the considered scenario,\ndata is streaming frequently while trying to reach a decision. Thus, we aim to\ndevise a procedure that incorporates samples (data) of the distribution\nsequentially and adjusts decisions accordingly. We approach this problem in a\ndistributionally robust optimization framework and propose a novel Online Data\nAssimilation Algorithm (ONDA Algorithm) for this purpose. This algorithm\nguarantees out-of-sample performance of decisions with high probability, and\ngradually improves the quality of the decisions by incorporating the streaming\ndata. We show that the ONDA Algorithm converges under a sufficiently slow data\nstreaming rate, and provide a criteria for its termination after certain number\nof data have been collected. Simulations illustrate the results.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jan 2019 22:16:09 GMT"}, {"version": "v2", "created": "Sat, 28 Mar 2020 19:34:26 GMT"}, {"version": "v3", "created": "Tue, 30 Jun 2020 23:58:16 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Li", "Dan", ""], ["Martinez", "Sonia", ""]]}, {"id": "1901.07618", "submitter": "Alfredo Alegr\\'ia", "authors": "Alfredo Alegr\\'ia", "title": "Modelling and simulation of multifractal star-shaped particles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of constructing flexible stochastic models to describe the\nvariability in shape of solid particles is challenging. Natural objects often\nexhibit mono- or multi-fractal features, i.e. irregular shapes and self-similar\npatterns. This paper presents a general framework for modelling\nthree-dimensional star-shaped particles with a locally variable Hausdorff (or\nfractal) dimension. In our approach, the radial function of the particle is\nrepresented by an anisotropic Gaussian random field on the sphere. We\nadditionally derive a simulation algorithm being parenthetical to the spectral\nturning bands method proposed in Euclidean spaces. We illustrate the use of our\nproposal through numerical examples, including a multifractal simulated version\nof the Earth topography.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2019 21:29:26 GMT"}], "update_date": "2019-01-24", "authors_parsed": [["Alegr\u00eda", "Alfredo", ""]]}, {"id": "1901.07693", "submitter": "Nian Si", "authors": "Jose Blanchet, Nian Si", "title": "Optimal Uncertainty Size in Distributionally Robust Inverse Covariance\n  Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.OC stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a recent paper, Nguyen, Kuhn, and Esfahani (2018) built a distributionally\nrobust estimator for the precision matrix of the Gaussian distribution. The\ndistributional uncertainty size is a key ingredient in the construction of this\nestimator. We develop a statistical theory which shows how to optimally choose\nthe uncertainty size to minimize the associated Stein loss. Surprisingly,\nrather than the expected canonical square-root scaling rate, the optimal\nuncertainty size scales linearly with the sample size.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 02:29:06 GMT"}, {"version": "v2", "created": "Wed, 24 Apr 2019 18:16:13 GMT"}, {"version": "v3", "created": "Thu, 10 Oct 2019 01:40:57 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Blanchet", "Jose", ""], ["Si", "Nian", ""]]}, {"id": "1901.07746", "submitter": "Yanqing Yin", "authors": "Huiqin Li, Yanqing Yin and Shurong Zheng", "title": "Central limit theorem for linear spectral statistics of general\n  separable sample covariance matrices with applications", "comments": "66 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the separable covariance model, which plays an\nimportant role in wireless communications and spatio-temporal statistics and\ndescribes a process where the time correlation does not depend on the spatial\nlocation and the spatial correlation does not depend on time. We established a\ncentral limit theorem for linear spectral statistics of general separable\nsample covariance matrices in the form of $\\mathbf S_n=\\frac1n\\mathbf\nT_{1n}\\mathbf X_n\\mathbf T_{2n}\\mathbf X_n^*\\mathbf T_{1n}^*$ where $\\mathbf\nX_n=(x_{jk})$ is of $m_1\\times m_2$ dimension, the entries $\\{x_{jk},\nj=1,...,m_1, k=1,...,m_2\\}$ are independent and identically distributed complex\nvariables with zero means and unit variances, $\\mathbf T_{1n}$ is a $p\\times\nm_1 $ complex matrix and $\\mathbf T_{2n}$ is an $m_2\\times m_2$ Hermitian\nmatrix. We then apply this general central limit theorem to the problem of\ntesting white noise in time series.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 06:42:36 GMT"}], "update_date": "2019-01-24", "authors_parsed": [["Li", "Huiqin", ""], ["Yin", "Yanqing", ""], ["Zheng", "Shurong", ""]]}, {"id": "1901.07991", "submitter": "Madalin Guta", "authors": "Anirudh Acharya, Theodore Kypraios and Madalin Guta", "title": "A comparative study of estimation methods in quantum tomography", "comments": "40 pages, 11 figures", "journal-ref": null, "doi": "10.1088/1751-8121/ab1958", "report-no": null, "categories": "quant-ph math-ph math.MP math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As quantum tomography is becoming a key component of the quantum engineering\ntoolbox, there is a need for a deeper understanding of the multitude of\nestimation methods available. Here we investigate and compare several such\nmethods: maximum likelihood, least squares, generalised least squares, positive\nleast squares, thresholded least squares and projected least squares. The\ncommon thread of the analysis is that each estimator projects the measurement\ndata onto a parameter space with respect to a specific metric, thus allowing us\nto study the relationships between different estimators.\n  The asymptotic behaviour of the least squares and the projected least squares\nestimators is studied in detail for the case of the covariant measurement and a\nfamily of states of varying ranks. This gives insight into the rank-dependent\nrisk reduction for the projected estimator, and uncovers an interesting\nnon-monotonic behaviour of the Bures risk. These asymptotic results complement\nrecent non-asymptotic concentration bounds of \\cite{GutaKahnKungTropp} which\npoint to strong optimality properties, and high computational efficiency of the\nprojected linear estimators.\n  To illustrate the theoretical methods we present results of an extensive\nsimulation study. An app running the different estimators has been made\navailable online.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 16:43:17 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Acharya", "Anirudh", ""], ["Kypraios", "Theodore", ""], ["Guta", "Madalin", ""]]}, {"id": "1901.08015", "submitter": "Tiancheng Li", "authors": "Tiancheng Li, Hongqi Fan, Jes\\'us G. Herrero and Juan M Corchado", "title": "Second Order Statistics Analysis and Comparison between Arithmetic and\n  Geometric Average Fusion", "comments": "17 pages, 8 figures", "journal-ref": "Information Fusion, 2019", "doi": "10.1016/j.inffus.2019.02.009", "report-no": null, "categories": "cs.SY cs.MA math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two fundamental approaches to information averaging are based on linear and\nlogarithmic combination, yielding the arithmetic average (AA) and geometric\naverage (GA) of the fusing initials, respectively. In the context of target\ntracking, the two most common formats of data to be fused are random variables\nand probability density functions, namely $v$-fusion and $f$-fusion,\nrespectively. In this work, we analyze and compare the second order statistics\n(including variance and mean square error) of AA and GA in terms of both\n$v$-fusion and $f$-fusion. The case of weighted Gaussian mixtures representing\nmultitarget densities in the presence of false alarms and misdetection (whose\nweight sums are not necessarily unit) is also considered, the result of which\nappears significantly different from that for a single target. In addition to\nexact derivation, exemplifying analysis and illustrations are provided.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 17:24:19 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Li", "Tiancheng", ""], ["Fan", "Hongqi", ""], ["Herrero", "Jes\u00fas G.", ""], ["Corchado", "Juan M", ""]]}, {"id": "1901.08135", "submitter": "Sunder Sethuraman", "authors": "Zach Dietz, William Lippitt, Sunder Sethuraman", "title": "Stick-breaking processes, clumping, and Markov chain occupation laws", "comments": "35 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the connections among `clumped' residual allocation models\n(RAMs), a general class of stick-breaking processes including Dirichlet\nprocesses, and the occupation laws of certain discrete space time-inhomogeneous\nMarkov chains related to simulated annealing and other applications. An\nintermediate structure is introduced in a given RAM, where proportions between\nsuccessive indices in a list are added or clumped together to form another RAM.\nIn particular, when the initial RAM is a Griffiths-Engen-McCloskey (GEM)\nsequence and the indices are given by the random times that an auxiliary Markov\nchain jumps away from its current state, the joint law of the intermediate RAM\nand the locations visited in the sojourns is given in terms of a `disordered'\nGEM sequence, and an induced Markov chain. Through this joint law, we identify\na large class of `stick breaking' processes as the limits of empirical\noccupation measures for associated time-inhomogeneous Markov chains.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 21:28:24 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Dietz", "Zach", ""], ["Lippitt", "William", ""], ["Sethuraman", "Sunder", ""]]}, {"id": "1901.08232", "submitter": "James Allen Fill", "authors": "James Allen Fill", "title": "Breaking Bivariate Records", "comments": "1 table and 1 figure", "journal-ref": "Combinator. Probab. Comp. 30 (2021) 105-123", "doi": "10.1017/S0963548320000309", "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We establish a fundamental property of bivariate Pareto records for\nindependent observations uniformly distributed in the unit square. We prove\nthat the asymptotic conditional distribution of the number of records broken by\nan observation given that the observation sets a record is Geometric with\nparameter 1/2.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 04:46:35 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Fill", "James Allen", ""]]}, {"id": "1901.08235", "submitter": "Tingran Gao", "authors": "Tingran Gao, Zhizhen Zhao", "title": "Multi-Frequency Phase Synchronization", "comments": "12 pages, 9 figures. ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DS math.IT math.OC math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel formulation for phase synchronization -- the statistical\nproblem of jointly estimating alignment angles from noisy pairwise comparisons\n-- as a nonconvex optimization problem that enforces consistency among the\npairwise comparisons in multiple frequency channels. Inspired by harmonic\nretrieval in signal processing, we develop a simple yet efficient two-stage\nalgorithm that leverages the multi-frequency information. We demonstrate in\ntheory and practice that the proposed algorithm significantly outperforms\nstate-of-the-art phase synchronization algorithms, at a mild computational\ncosts incurred by using the extra frequency channels. We also extend our\nalgorithmic framework to general synchronization problems over compact Lie\ngroups.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 04:52:20 GMT"}, {"version": "v2", "created": "Sun, 14 Apr 2019 15:30:27 GMT"}, {"version": "v3", "created": "Tue, 14 May 2019 03:28:59 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Gao", "Tingran", ""], ["Zhao", "Zhizhen", ""]]}, {"id": "1901.08237", "submitter": "Liu Liu", "authors": "Liu Liu, Tianyang Li, Constantine Caramanis", "title": "High Dimensional Robust $M$-Estimation: Arbitrary Corruption and Heavy\n  Tails", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of sparsity-constrained $M$-estimation when both\nexplanatory and response variables have heavy tails (bounded 4-th moments), or\na fraction of arbitrary corruptions. We focus on the $k$-sparse,\nhigh-dimensional regime where the number of variables $d$ and the sample size\n$n$ are related through $n \\sim k \\log d$. We define a natural condition we\ncall the Robust Descent Condition (RDC), and show that if a gradient estimator\nsatisfies the RDC, then Robust Hard Thresholding (IHT using this gradient\nestimator), is guaranteed to obtain good statistical rates. The contribution of\nthis paper is in showing that this RDC is a flexible enough concept to recover\nknown results, and obtain new robustness results. Specifically, new results\ninclude: (a) For $k$-sparse high-dimensional linear- and logistic-regression\nwith heavy tail (bounded 4-th moment) explanatory and response variables, a\nlinear-time-computable median-of-means gradient estimator satisfies the RDC,\nand hence Robust Hard Thresholding is minimax optimal; (b) When instead of\nheavy tails we have $O(1/\\sqrt{k}\\log(nd))$-fraction of arbitrary corruptions\nin explanatory and response variables, a near linear-time computable trimmed\ngradient estimator satisfies the RDC, and hence Robust Hard Thresholding is\nminimax optimal. We demonstrate the effectiveness of our approach in sparse\nlinear, logistic regression, and sparse precision matrix estimation on\nsynthetic and real-world US equities data.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 05:20:29 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 19:02:20 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Liu", "Liu", ""], ["Li", "Tianyang", ""], ["Caramanis", "Constantine", ""]]}, {"id": "1901.08434", "submitter": "George Moustakides", "authors": "George V. Moustakides", "title": "Detecting Changes in Hidden Markov Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of sequential detection of a change in the\nstatistical behavior of a hidden Markov model. By adopting a worst-case\nanalysis with respect to the time of change and by taking into account the data\nthat can be accessed by the change-imposing mechanism we offer alternative\nformulations of the problem. For each formulation we derive the optimum\nShewhart test that maximizes the worst-case detection probability while\nguaranteeing infrequent false alarms.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 14:41:14 GMT"}, {"version": "v2", "created": "Sat, 26 Jan 2019 15:02:20 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Moustakides", "George V.", ""]]}, {"id": "1901.08491", "submitter": "Maria Mohr", "authors": "Maria Mohr and Natalie Neumeyer", "title": "Consistent nonparametric change point detection combining CUSUM and\n  marked empirical processes", "comments": "35 pages (including 5 pages of supplementary material), 4 figures, 2\n  tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A weakly dependent time series regression model with multivariate covariates\nand univariate observations is considered, for which we develop a procedure to\ndetect whether the nonparametric conditional mean function is stable in time\nagainst change point alternatives. Our proposal is based on a modified CUSUM\ntype test procedure, which uses a sequential marked empirical process of\nresiduals. We show weak convergence of the considered process to a centered\nGaussian process under the null hypothesis of no change in the mean function\nand a stationarity assumption. This requires some sophisticated arguments for\nsequential empirical processes of weakly dependent variables. As a consequence\nwe obtain convergence of Kolmogorov-Smirnov and Cram\\'er-von Mises type test\nstatistics. The proposed procedure acquires a very simple limiting distribution\nand nice consistency properties, features from which related tests are lacking.\nWe moreover suggest a bootstrap version of the procedure and discuss its\napplicability in the case of unstable variances.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 16:39:23 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Mohr", "Maria", ""], ["Neumeyer", "Natalie", ""]]}, {"id": "1901.08519", "submitter": "Mickael Albertus", "authors": "Mickael Albertus", "title": "Raking-ratio empirical process with auxiliary information learning", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The raking-ratio method is a statistical and computational method which\nadjusts the empirical measure to match the true probability of sets of a finite\npartition. We study the asymptotic behavior of the raking-ratio empirical\nprocess indexed by a class of functions when the auxiliary information is given\nby estimates. We suppose that these estimates result from the learning of the\nprobability of sets of partitions from another sample larger than the sample of\nthe statistician, as in the case of two-stage sampling surveys. Under some\nmetric entropy hypothesis and conditions on the size of the information source\nsample, we establish the strong approximation of this process and show in this\ncase that the weak convergence is the same as the classical raking-ratio\nempirical process. We also give possible statistical applications of these\nresults like the strengthening of the $Z$-test and the chi-square goodness of\nfit test.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 17:27:49 GMT"}, {"version": "v2", "created": "Mon, 6 May 2019 17:39:11 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Albertus", "Mickael", ""]]}, {"id": "1901.08535", "submitter": "Theofanis Sapatinas", "authors": "Dimitrios Pilavakis, Efstathios Paparoditis, Theofanis Sapatinas", "title": "Testing Equality of Autocovariance Operators for Functional Time Series", "comments": "23 Pages, 2 Figures, 1 Table (To appear in the Journal of Time Series\n  Analysis)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider strictly stationary stochastic processes of Hilbert space-valued\nrandom variables and focus on fully functional tests for the equality of the\nlag-zero autocovariance operators of several independent functional time\nseries. A moving block bootstrap-based testing procedure is proposed which\ngenerates pseudo random elements that satisfy the null hypothesis of interest.\nIt is based on directly bootstrapping the time series of tensor products which\novercomes some common difficulties associated with applications of the\nbootstrap to related testing problems. The suggested methodology can be\npotentially applied to a broad range of test statistics of the hypotheses of\ninterest. As an example, we establish validity for approximating the\ndistribution under the null of a test statistic based on the Hilbert-Schmidt\ndistance of the corresponding sample lag-zero autocovariance operators, and\nshow consistency under the alternative. As a prerequisite, we prove a central\nlimit theorem for the moving block bootstrap procedure applied to the sample\nautocovariance operator which is of interest on its own. The finite sample size\nand power performance of the suggested moving block bootstrap-based testing\nprocedure is illustrated through simulations and an application to a real-life\ndataset is discussed.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 17:55:15 GMT"}, {"version": "v2", "created": "Tue, 5 Feb 2019 13:40:18 GMT"}, {"version": "v3", "created": "Sun, 5 Apr 2020 09:41:11 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Pilavakis", "Dimitrios", ""], ["Paparoditis", "Efstathios", ""], ["Sapatinas", "Theofanis", ""]]}, {"id": "1901.08571", "submitter": "Ruiqi Liu", "authors": "Ruiqi Liu, Ganggang Xu, Zuofeng Shang", "title": "Optimal Nonparametric Inference under Quantization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical inference based on lossy or incomplete samples is of fundamental\nimportance in research areas such as signal/image processing, medical image\nstorage, remote sensing, signal transmission. In this paper, we propose a\nnonparametric testing procedure based on quantized samples. In contrast to the\nclassic nonparametric approach, our method lives on a coarse grid of sample\ninformation and are simple-to-use. Under mild technical conditions, we\nestablish the asymptotic properties of the proposed procedures including\nasymptotic null distribution of the quantization test statistic as well as its\nminimax power optimality. Concrete quantizers are constructed for achieving the\nminimax optimality in practical use. Simulation results and a real data\nanalysis are provided to demonstrate the validity and effectiveness of the\nproposed test. Our work bridges the classical nonparametric inference to modern\nlossy data setting.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 18:43:16 GMT"}, {"version": "v2", "created": "Fri, 25 Jan 2019 02:57:14 GMT"}], "update_date": "2019-01-28", "authors_parsed": [["Liu", "Ruiqi", ""], ["Xu", "Ganggang", ""], ["Shang", "Zuofeng", ""]]}, {"id": "1901.08606", "submitter": "Steve Huntsman", "authors": "Steve Huntsman", "title": "Fast Markov Chain Monte Carlo Algorithms via Lie Groups", "comments": "Accepted to AISTATS 2020; proofs included here as an appendix (but\n  relegated to supplementary info in conference version)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.GR math.RA stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  From basic considerations of the Lie group that preserves a target\nprobability measure, we derive the Barker, Metropolis, and ensemble Markov\nchain Monte Carlo (MCMC) algorithms, as well as variants of waste-recycling\nMetropolis-Hastings and an altogether new MCMC algorithm. We illustrate these\nconstructions with explicit numerical computations, and we empirically\ndemonstrate on a spin glass that the new algorithm converges more quickly than\nits siblings.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 19:01:13 GMT"}, {"version": "v2", "created": "Mon, 27 Jan 2020 20:56:58 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Huntsman", "Steve", ""]]}, {"id": "1901.08641", "submitter": "Kevin McGoff", "authors": "Kevin McGoff, Sayan Mukherjee, Andrew Nobel", "title": "Gibbs posterior convergence and the thermodynamic formalism", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.DS math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider a Bayesian framework for making inferences about\ndynamical systems from ergodic observations. The proposed Bayesian procedure is\nbased on the Gibbs posterior, a decision theoretic generalization of standard\nBayesian inference. We place a prior over a model class consisting of a\nparametrized family of Gibbs measures on a mixing shift of finite type. This\nmodel class generalizes (hidden) Markov chain models by allowing for long range\ndependencies, including Markov chains of arbitrarily large orders. We\ncharacterize the asymptotic behavior of the Gibbs posterior distribution on the\nparameter space as the number of observations tends to infinity. In particular,\nwe define a limiting variational problem over the space of joinings of the\nmodel system with the observed system, and we show that the Gibbs posterior\ndistributions concentrate around the solution set of this variational problem.\nIn the case of properly specified models our convergence results may be used to\nestablish posterior consistency. This work establishes tight connections\nbetween Gibbs posterior inference and the thermodynamic formalism, which may\ninspire new proof techniques in the study of Bayesian posterior consistency for\ndependent processes.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 20:51:46 GMT"}], "update_date": "2019-01-28", "authors_parsed": [["McGoff", "Kevin", ""], ["Mukherjee", "Sayan", ""], ["Nobel", "Andrew", ""]]}, {"id": "1901.08736", "submitter": "Pierre C. Bellec", "authors": "Pierre C Bellec", "title": "Concentration of quadratic forms under a Bernstein moment assumption", "comments": "This short note presents a result that initially appeared in\n  arXiv:1410.0346v1 (see Assumption 3.3). The result was later removed from\n  arXiv:1410.0346 and the published version\n  https://projecteuclid.org/euclid.aos/1519268423 due to space constraints", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A concentration result for quadratic form of independent subgaussian random\nvariables is derived. If the moments of the random variables satisfy a\n\"Bernstein condition\", then the variance term of the Hanson-Wright inequality\ncan be improved. The Bernstein condition is satisfied, for instance, by all\nlog-concave subgaussian distributions.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2019 04:47:10 GMT"}], "update_date": "2019-01-28", "authors_parsed": [["Bellec", "Pierre C", ""]]}, {"id": "1901.08802", "submitter": "Nicolas Verzelen", "authors": "Alexandra Carpentier and Nicolas Verzelen", "title": "Optimal Sparsity Testing in Linear regression Model", "comments": "50 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of sparsity testing in the high-dimensional linear\nregression model. The problem is to test whether the number of non-zero\ncomponents (aka the sparsity) of the regression parameter $\\theta^*$ is less\nthan or equal to $k_0$. We pinpoint the minimax separation distances for this\nproblem, which amounts to quantifying how far a $k_1$-sparse vector $\\theta^*$\nhas to be from the set of $k_0$-sparse vectors so that a test is able to reject\nthe null hypothesis with high probability. Two scenarios are considered. In the\nindependent scenario, the covariates are i.i.d. normally distributed and the\nnoise level is known. In the general scenario, both the covariance matrix of\nthe covariates and the noise level are unknown. Although the minimax separation\ndistances differ in these two scenarios, both of them actually depend on $k_0$\nand $k_1$ illustrating that for this composite-composite testing problem both\nthe size of the null and of the alternative hypotheses play a key role.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2019 09:56:11 GMT"}, {"version": "v2", "created": "Thu, 23 Apr 2020 08:11:48 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Carpentier", "Alexandra", ""], ["Verzelen", "Nicolas", ""]]}, {"id": "1901.08826", "submitter": "Tobias Fissler", "authors": "Tobias Fissler and Johanna F. Ziegel", "title": "Supplement to \"Erratum: Higher Order Elicitability and Osband's\n  Principle\"", "comments": "12 pages, 1 figure, to appear as a supplement in the Annals of\n  Statistics", "journal-ref": "Ann. Statist., Volume 49, Number 1 (2021), 614", "doi": "10.1214/20-AOS2014", "report-no": null, "categories": "math.ST q-fin.MF q-fin.RM stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This note corrects conditions in Proposition 3.4 and Theorem 5.2(ii) and\ncomments on imprecisions in Propositions 4.2 and 4.4 in Fissler and Ziegel\n(2016).\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2019 11:01:26 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 14:31:12 GMT"}], "update_date": "2021-02-01", "authors_parsed": [["Fissler", "Tobias", ""], ["Ziegel", "Johanna F.", ""]]}, {"id": "1901.08845", "submitter": "Alexander Kolnogorov", "authors": "Alexander Kolnogorov", "title": "Gaussian One-Armed Bandit and Optimization of Batch Data Processing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the minimax setup for Gaussian one-armed bandit problem, i.e. the\ntwo-armed bandit problem with Gaussian distributions of incomes and known\ndistribution corresponding to the first arm. This setup naturally arises when\nthe optimization of batch data processing is considered and there are two\nalternative processing methods available with a priori known efficiency of the\nfirst method. One should estimate the efficiency of the second method and\nprovide predominant usage of the most efficient of both them. According to the\nmain theorem of the theory of games minimax strategy and minimax risk are\nsearched for as Bayesian ones corresponding to the worst-case prior\ndistribution. As a result, we obtain the recursive integro-difference equation\nand the second order partial differential equation in the limiting case as the\nnumber of batches goes to infinity. This makes it possible to determine minimax\nrisk and minimax strategy by numerical methods. If the number of batches is\nlarge enough we show that batch data processing almost does not influence the\ncontrol performance, i.e. the value of the minimax risk. Moreover, in case of\nBernoulli incomes and large number of batches, batch data processing provides\nalmost the same minimax risk as the optimal one-by-one data processing.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2019 11:57:13 GMT"}], "update_date": "2019-01-28", "authors_parsed": [["Kolnogorov", "Alexander", ""]]}, {"id": "1901.09036", "submitter": "Dylan Foster", "authors": "Dylan J. Foster and Vasilis Syrgkanis", "title": "Orthogonal Statistical Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG econ.EM stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide non-asymptotic excess risk guarantees for statistical learning in\na setting where the population risk with respect to which we evaluate the\ntarget parameter depends on an unknown nuisance parameter that must be\nestimated from data. We analyze a two-stage sample splitting meta-algorithm\nthat takes as input two arbitrary estimation algorithms: one for the target\nparameter and one for the nuisance parameter. We show that if the population\nrisk satisfies a condition called Neyman orthogonality, the impact of the\nnuisance estimation error on the excess risk bound achieved by the\nmeta-algorithm is of second order. Our theorem is agnostic to the particular\nalgorithms used for the target and nuisance and only makes an assumption on\ntheir individual performance. This enables the use of a plethora of existing\nresults from statistical learning and machine learning to give new guarantees\nfor learning with a nuisance component. Moreover, by focusing on excess risk\nrather than parameter estimation, we can give guarantees under weaker\nassumptions than in previous works and accommodate settings in which the target\nparameter belongs to a complex nonparametric class. We provide conditions on\nthe metric entropy of the nuisance and target classes such that oracle\nrates---rates of the same order as if we knew the nuisance parameter---are\nachieved. We also derive new rates for specific estimation algorithms such as\nvariance-penalized empirical risk minimization, neural network estimation and\nsparse high-dimensional linear model estimation. We highlight the applicability\nof our results in four settings of central importance: 1) heterogeneous\ntreatment effect estimation, 2) offline policy optimization, 3) domain\nadaptation, and 4) learning with missing data.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2019 02:21:24 GMT"}, {"version": "v2", "created": "Mon, 11 Mar 2019 03:12:45 GMT"}, {"version": "v3", "created": "Thu, 24 Sep 2020 00:11:30 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Foster", "Dylan J.", ""], ["Syrgkanis", "Vasilis", ""]]}, {"id": "1901.09100", "submitter": "Uri Hadar", "authors": "Uri Hadar, Jingbo Liu, Yury Polyanskiy and Ofer Shayevitz", "title": "Communication Complexity of Estimating Correlations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We characterize the communication complexity of the following distributed\nestimation problem. Alice and Bob observe infinitely many iid copies of\n$\\rho$-correlated unit-variance (Gaussian or $\\pm1$ binary) random variables,\nwith unknown $\\rho\\in[-1,1]$. By interactively exchanging $k$ bits, Bob wants\nto produce an estimate $\\hat\\rho$ of $\\rho$. We show that the best possible\nperformance (optimized over interaction protocol $\\Pi$ and estimator $\\hat\n\\rho$) satisfies $\\inf_{\\Pi \\hat\\rho}\\sup_\\rho \\mathbb{E} [|\\rho-\\hat\\rho|^2] =\n\\tfrac{1}{k} (\\frac{1}{2 \\ln 2} + o(1))$. Curiously, the number of samples in\nour achievability scheme is exponential in $k$; by contrast, a naive scheme\nexchanging $k$ samples achieves the same $\\Omega(1/k)$ rate but with a\nsuboptimal prefactor. Our protocol achieving optimal performance is one-way\n(non-interactive). We also prove the $\\Omega(1/k)$ bound even when $\\rho$ is\nrestricted to any small open sub-interval of $[-1,1]$ (i.e. a local minimax\nlower bound). Our proof techniques rely on symmetric strong data-processing\ninequalities and various tensorization techniques from information-theoretic\ninteractive common-randomness extraction. Our results also imply an $\\Omega(n)$\nlower bound on the information complexity of the Gap-Hamming problem, for which\nwe show a direct information-theoretic proof.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2019 22:05:20 GMT"}, {"version": "v2", "created": "Thu, 18 Apr 2019 10:32:05 GMT"}], "update_date": "2019-04-19", "authors_parsed": [["Hadar", "Uri", ""], ["Liu", "Jingbo", ""], ["Polyanskiy", "Yury", ""], ["Shayevitz", "Ofer", ""]]}, {"id": "1901.09188", "submitter": "Julyan Arbel", "authors": "Julyan Arbel, Olivier Marchal and Hien D. Nguyen", "title": "On strict sub-Gaussianity, optimal proxy variance and symmetry for\n  bounded random variables", "comments": "23 pages, 5 figures", "journal-ref": "ESAIM: Probability & Statistics, 2019", "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the sub-Gaussian property for almost surely bounded random\nvariables. If sub-Gaussianity per se is de facto ensured by the bounded support\nof said random variables, then exciting research avenues remain open. Among\nthese questions is how to characterize the optimal sub-Gaussian proxy variance?\nAnother question is how to characterize strict sub-Gaussianity, defined by a\nproxy variance equal to the (standard) variance? We address the questions in\nproposing conditions based on the study of functions variations. A particular\nfocus is given to the relationship between strict sub-Gaussianity and symmetry\nof the distribution. In particular, we demonstrate that symmetry is neither\nsufficient nor necessary for strict sub-Gaussianity. In contrast, simple\nnecessary conditions on the one hand, and simple sufficient conditions on the\nother hand, for strict sub-Gaussianity are provided. These results are\nillustrated via various applications to a number of bounded random variables,\nincluding Bernoulli, beta, binomial, uniform, Kumaraswamy, and triangular\ndistributions.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jan 2019 09:50:35 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Arbel", "Julyan", ""], ["Marchal", "Olivier", ""], ["Nguyen", "Hien D.", ""]]}, {"id": "1901.09214", "submitter": "Pedro Ramos", "authors": "Francisco Louzada, Pedro Luiz Ramos, Hayala C. C. Souza, Gleici da\n  Silva Castro Perdona", "title": "On the unified zero-inflated cure-rate survival models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a unified version for survival models that includes\nzero-inflation and cure rate proportions, and allows different distributions\nfor the unknown competitive causes. Our model has as particular cases several\nusual cure rate survival models.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jan 2019 13:47:19 GMT"}, {"version": "v2", "created": "Mon, 18 May 2020 15:21:54 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Louzada", "Francisco", ""], ["Ramos", "Pedro Luiz", ""], ["Souza", "Hayala C. C.", ""], ["Perdona", "Gleici da Silva Castro", ""]]}, {"id": "1901.09303", "submitter": "Muneya Matsui", "authors": "Muneya Matsui", "title": "Asymptotics of maximum likelihood estimation for stable law with\n  continuous parameterization", "comments": "16 pages, 2 tables, original article", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Asymptotics of maximum likelihood estimation for $\\alpha$-stable law are\nanalytically investigated with a continuous parameterization. The consistency\nand asymptotic normality are shown on the interior of the whole parameter\nspace. Although these asymptotics have been provided with Zolotarev's $(B)$\nparameterization, there are several gaps between. Especially in the latter, the\ndensity, so that scores and their derivatives are discontinuous at $\\alpha=1$\nfor $\\beta\\neq 0$ and usual asymptotics are impossible. This is considerable\ninconvenience for applications. By showing that these quantities are smooth in\nthe continuous form, we fill gaps between and provide a convenient theory. We\nnumerically approximate the Fisher information matrix around the Cauchy law\n$(\\alpha,\\beta)=(1,0)$. The results exhibit continuity at $\\alpha=1,\\,\\beta\\neq\n0$ and this secures the accuracy of our calculations.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jan 2019 02:35:05 GMT"}, {"version": "v2", "created": "Mon, 4 Feb 2019 04:38:03 GMT"}, {"version": "v3", "created": "Thu, 28 Feb 2019 00:33:33 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["Matsui", "Muneya", ""]]}, {"id": "1901.09555", "submitter": "Feriel Bouhadjera", "authors": "Bouhadjera Feriel (LMPA, UBMA), Ould Sa\\\"id (LMPA), Mohamed Remita\n  (UBMA)", "title": "Nonparametric relative error estimation of the regression function for\n  censored data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $ (T_i)_i$ be a sequence of independent identically distributed (i.i.d.)\nrandom variables (r.v.) of interest distributed as $ T$ and $(X_i)_i$ be a\ncorresponding vector of covariates taking values on $ \\mathbb{R}^d$. In\ncensorship models the r.v. $T$ is subject to random censoring by another r.v.\n$C$. In this paper we built a new kernel estimator based on the so-called\nsynthetic data of the mean squared relative error for the regression function.\nWe establish the uniform almost sure convergence with rate over a compact set\nand its asymptotic normality. The asymptotic variance is explicitly given and\nas product we give a confidence bands. A simulation study has been conducted to\ncomfort our theoretical results\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2019 08:59:44 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Feriel", "Bouhadjera", "", "LMPA, UBMA"], ["Sa\u00efd", "Ould", "", "LMPA"], ["Remita", "Mohamed", "", "UBMA"]]}, {"id": "1901.09607", "submitter": "Matus Maciak", "authors": "Gabriela Ciuperca and Matus Maciak", "title": "Change-point detection in a linear model by adaptive fused quantile\n  method", "comments": "40 pages; 2 figures;", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel approach to quantile estimation in multivariate linear regression\nmodels with change-points is proposed: the change-point detection and the model\nestimation are both performed automatically, by adopting either the quantile\nfused penalty or the adaptive version of the quantile fused penalty. These two\nmethods combine the idea of the check function used for the quantile estimation\nand the $L_1$ penalization principle known from the signal processing and,\nunlike some standard approaches, the presented methods go beyond typical\nassumptions usually required for the model errors, such as sub-Gaussian or\nNormal distribution. They can effectively handle heavy-tailed random error\ndistributions, and, in general, they offer a more complex view on the data as\none can obtain any conditional quantile of the target distribution, not just\nthe conditional mean. The consistency of detection is proved and proper\nconvergence rates for the parameter estimates are derived. The empirical\nperformance is investigated via an extensive comparative simulation study and\npractical utilization is demonstrated using a real data example.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2019 11:25:58 GMT"}, {"version": "v2", "created": "Tue, 9 Apr 2019 09:43:30 GMT"}], "update_date": "2019-04-10", "authors_parsed": [["Ciuperca", "Gabriela", ""], ["Maciak", "Matus", ""]]}, {"id": "1901.09665", "submitter": "Annalisa Cerquetti", "authors": "Annalisa Cerquetti", "title": "Exact Good-Turing characterization of the two-parameter\n  Poisson-Dirichlet superpopulation model", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Large sample size equivalence between the celebrated {\\it approximated}\nGood-Turing estimator of the probability to discover a species already observed\na certain number of times (Good, 1953) and the modern Bayesian nonparametric\ncounterpart has been recently established by virtue of a particular smoothing\nrule based on the two-parameter Poisson-Dirichlet model. Here we improve on\nthis result showing that, for any finite sample size, when the population\nfrequencies are assumed to be selected from a superpopulation with\ntwo-parameter Poisson-Dirichlet distribution, then Bayesian nonparametric\nestimation of the discovery probabilities corresponds to Good-Turing {\\it\nexact} estimation. Moreover under general superpopulation hypothesis the\nGood-Turing solution admits an interpretation as a modern Bayesian\nnonparametric estimator under partial information.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2019 14:19:16 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Cerquetti", "Annalisa", ""]]}, {"id": "1901.09798", "submitter": "Danica Ommen", "authors": "Danica M. Ommen and Christopher P. Saunders", "title": "Reconciling the Bayes Factor and Likelihood Ratio for Two Non-Nested\n  Model Selection Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In statistics, there are a variety of methods for performing model selection\nthat all stem from slightly different paradigms of statistical inference. The\nreasons for choosing one particular method over another seem to be based\nentirely on philosophical preferences. In the case of non-nested model\nselection, two of the prevailing techniques are the Bayes Factor and the\nlikelihood ratio. This article focuses on reconciling the likelihood ratio and\nthe Bayes Factor for comparing a pair of non-nested models under two different\nproblem frameworks typical in forensic science, the common-source and the\nspecific-source problem. We show that the Bayes Factor can be expressed as the\nexpected value of the corresponding likelihood ratio function with respect to\nthe posterior distribution for the parameters given the entire set of data\nwhere the set(s) of unknown-source observations has been generated according to\nthe second model. This expression leads to a number of useful theoretic and\npractical results relating the two statistical approaches. This relationship is\nquite meaningful in many scientific applications where there is a general\nconfusion between the various statistical methods, and particularly in the case\nof forensic science.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2019 16:46:33 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Ommen", "Danica M.", ""], ["Saunders", "Christopher P.", ""]]}, {"id": "1901.09911", "submitter": "Agnes Lagnoux", "authors": "Thierry Klein (IMT), A Lagnoux (IMT), P Petit (IMT)", "title": "A conditional Berry-Esseen inequality", "comments": "arXiv admin note: text overlap with arXiv:1603.02235", "journal-ref": "Journal of Applied Probability, Applied Probability Trust, 2019", "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As an extension of a central limit theorem established by Svante Janson, we\nprove a Berry-Esseen inequality for a sum of independent and identically\ndistributed random variables conditioned by a sum of independent and\nidentically distributed integer-valued random variables.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2019 10:36:57 GMT"}, {"version": "v2", "created": "Mon, 18 Jan 2021 09:09:47 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Klein", "Thierry", "", "IMT"], ["Lagnoux", "A", "", "IMT"], ["Petit", "P", "", "IMT"]]}, {"id": "1901.10089", "submitter": "Nicolas Garcia Trillos", "authors": "Nicolas Garcia Trillos, Ryan Murray", "title": "A maximum principle argument for the uniform convergence of graph\n  Laplacian regressors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.AP math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the use of methods from partial differential\nequations and the Calculus of variations to study learning problems that are\nregularized using graph Laplacians. Graph Laplacians are a powerful, flexible\nmethod for capturing local and global geometry in many classes of learning\nproblems, and the techniques developed in this paper help to broaden the\nmethodology of studying such problems. In particular, we develop the use of\nmaximum principle arguments to establish asymptotic consistency guarantees\nwithin the context of noise corrupted, non-parametric regression with samples\nliving on an unknown manifold embedded in $\\mathbb{R}^d$. The maximum principle\narguments provide a new technical tool which informs parameter selection by\ngiving concrete error estimates in terms of various regularization parameters.\nA review of learning algorithms which utilize graph Laplacians, as well as\nprevious developments in the use of differential equation and variational\ntechniques to study those algorithms, is given. In addition, new connections\nare drawn between Laplacian methods and other machine learning techniques, such\nas kernel regression and k-nearest neighbor methods.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 03:51:26 GMT"}, {"version": "v2", "created": "Tue, 26 Feb 2019 01:41:33 GMT"}, {"version": "v3", "created": "Sat, 27 Jun 2020 11:30:48 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Trillos", "Nicolas Garcia", ""], ["Murray", "Ryan", ""]]}, {"id": "1901.10166", "submitter": "Nathalie Krell", "authors": "Nathalie Krell (IRMAR), Emeline Schmisser (LPP)", "title": "Nonparametric estimation of jump rates for a specific class of Piecewise\n  Deterministic Markov Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider a piecewise deterministic Markov process (PDMP),\nwith known flow and deterministic transition measure, and unknown jump rate\n$\\lambda$. To estimate nonparametrically the jump rate, we first construct an\nadaptive estimator of the stationary density, then we derive a quotient\nestimator $\\hat{\\lambda}_n$ of $\\lambda$. We provide uniform bounds for the\nrisk of these estimators, and prove that the estimator of the jump rate is\nnearly minimax (up to a $\\ln^2(n)$ factor). Simulations illustrate the behavior\nof our estimator.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 08:33:19 GMT"}, {"version": "v2", "created": "Tue, 8 Dec 2020 15:38:16 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Krell", "Nathalie", "", "IRMAR"], ["Schmisser", "Emeline", "", "LPP"]]}, {"id": "1901.10269", "submitter": "Michael Choi", "authors": "Michael C.H. Choi", "title": "An improved variant of simulated annealing that converges under fast\n  cooling", "comments": "25 pages, 1 figure. To appear Markov Process. Related Fields", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.OC math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a target function $U$ to minimize on a finite state space\n$\\mathcal{X}$, a proposal chain with generator $Q$ and a cooling schedule\n$T(t)$ that depends on time $t$, in this paper we study two types of simulated\nannealing (SA) algorithms with generators $M_{1,t}(Q,U,T(t))$ and\n$M_{2,t}(Q,U,T(t))$ respectively. While $M_{1,t}$ is the classical SA\nalgorithm, we introduce a simple and improved variant that we call $M_{2,t}$\nwhich provably converges faster. When $T(t) > c_{M_2}/\\log(t+1)$ follows the\nlogarithmic cooling schedule, our proposed algorithm is strongly ergodic both\nin total variation and in relative entropy, and converges to the set of global\nminima, where $c_{M_2}$ is a constant that we explicitly identify. If $c_{M_1}$\nis the optimal hill-climbing constant that appears in logarithmic cooling of\n$M_{1,t}$, we show that $c_{M_1} \\geq c_{M_2}$ and give simple conditions under\nwhich $c_{M_1} > c_{M_2}$. Our proposed $M_{2,t}$ thus converges under a faster\nlogarithmic cooling in this regime. The other situation that we investigate\ncorresponds to $c_{M_1} > c_{M_2} = 0$, where we give a class of fast and\nnon-logarithmic cooling schedule that works for $M_{2,t}$ (but not for\n$M_{1,t}$). In addition to these asymptotic convergence results, we compare and\nanalyze finite-time behaviour between these two annealing algorithms as well.\nFinally, we present two algorithms to simulate $M_{2,t}$.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 13:22:31 GMT"}, {"version": "v2", "created": "Fri, 30 Aug 2019 07:27:41 GMT"}, {"version": "v3", "created": "Wed, 23 Oct 2019 06:30:12 GMT"}, {"version": "v4", "created": "Sat, 28 Dec 2019 10:26:25 GMT"}, {"version": "v5", "created": "Mon, 30 Mar 2020 06:45:26 GMT"}, {"version": "v6", "created": "Sat, 18 Jul 2020 07:30:07 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Choi", "Michael C. H.", ""]]}, {"id": "1901.10296", "submitter": "David Hirshberg", "authors": "David A. Hirshberg and Arian Maleki and Jose R. Zubizarreta", "title": "Minimax Linear Estimation of the Retargeted Mean", "comments": "25 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evaluating treatments received by one population for application to a\ndifferent target population of scientific interest is a central problem in\ncausal inference from observational studies. We study the minimax linear\nestimator of the treatment-specific mean outcome on a target population and\nprovide a theoretical basis for inference based on it. In particular, we\nprovide a justification for the common practice of ignoring bias when building\nconfidence intervals with these linear estimators. Focusing on the case that\nthe class of the unknown outcome function is the unit ball of a reproducing\nkernel Hilbert space, we show that the resulting linear estimator is\nasymptotically optimal under conditions only marginally stronger than those\nused with augmented estimators. We establish bounds attesting to the\nestimator's good finite sample properties. In an extensive simulation study, we\nobserve promising performance of the estimator throughout a wide range of\nsample sizes, noise levels, and levels of overlap between the covariate\ndistributions of the treated and target populations.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jan 2019 04:01:58 GMT"}, {"version": "v2", "created": "Fri, 26 Feb 2021 12:47:22 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Hirshberg", "David A.", ""], ["Maleki", "Arian", ""], ["Zubizarreta", "Jose R.", ""]]}, {"id": "1901.10549", "submitter": "Weiming Li", "authors": "Weiming Li, Qinwen Wang, Jianfeng Yao and Wang Zhou", "title": "On eigenvalues of a high-dimensional spatial-sign covariance matrix", "comments": "Text partially overlap with arXiv:1705.06427", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates limiting properties of eigenvalues of multivariate\nsample spatial-sign covariance matrices when both the number of variables and\nthe sample size grow to infinity. The underlying p-variate populations are\ngeneral enough to include the popular independent components model and the\nfamily of elliptical distributions. A first result of the paper establishes\nthat the distribution of the eigenvalues converges to a deterministic limit\nthat belongs to the family of generalized Marcenko-Pastur distributions.\nFurthermore, a new central limit theorem is established for a class of linear\nspectral statistics. We develop two applications of these results to robust\nstatistics for a high-dimensional shape matrix. First, two statistics are\nproposed for testing the sphericity. Next, a spectrum-corrected estimator using\nthe sample spatial-sign covariance matrix is proposed. Simulation experiments\nshow that in high dimension, the sample spatial-sign covariance matrix provides\na valid and robust tool for mitigating influence of outliers.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2019 04:52:51 GMT"}, {"version": "v2", "created": "Sat, 24 Aug 2019 08:49:50 GMT"}, {"version": "v3", "created": "Fri, 22 Jan 2021 12:11:17 GMT"}], "update_date": "2021-01-25", "authors_parsed": [["Li", "Weiming", ""], ["Wang", "Qinwen", ""], ["Yao", "Jianfeng", ""], ["Zhou", "Wang", ""]]}, {"id": "1901.10560", "submitter": "Salah Abid", "authors": "Salah H. Abid and Uday J. Quaez", "title": "Capacity of Control for Stochastic Dynamical Systems Perturbed by Mixed\n  Fractional Brownian Motion with Delay in Control", "comments": "17 pages, 2 examples", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we discuss the relationships between capacity of control in\nentropy theory and intrinsic properties in control theory for a class of finite\ndimensional stochastic dynamical systems described by a linear stochastic\ndifferential equations driven by mixed fractional Brownian motion with delay in\ncontrol. Stochastic dynamical systems can be described as an information\nchannel between the space of control signals and the state space. We study this\ncontrol to state information capacity of this channel in continuous time. We\nturned out that, the capacity of control depends on the time of final state in\ndynamical systems. By using the analysis and representation of fractional\nGaussian process, the closed form of continuous optimal control law is derived.\nThe reached optimal control law maximizes the mutual information between\ncontrol signals and future state over a finite time horizon. The results\nobtained here are motivated by control to state information capacity for linear\nsystems in both types deterministic and stochastic models that are widely used\nto understand information flows in wireless network information theory.\n  The contribution of this paper is that we propose some new relationships\nbetween control theory and entropy theoretic properties of stochastic dynamical\nsystems with delay in control. Finally, we present an example that serve to\nillustrate the relationships between capacity of control and intrinsic\nproperties in control theory.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 21:18:50 GMT"}], "update_date": "2019-01-31", "authors_parsed": [["Abid", "Salah H.", ""], ["Quaez", "Uday J.", ""]]}, {"id": "1901.10569", "submitter": "Salah Abid", "authors": "Salah H. Abid and Uday J. Quaez", "title": "Renyi and Shannon Entropies of Finite Mixtures of Multivariate Skew\n  t-distributions", "comments": "16 pages, e examples, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Shannon and Renyi entropies are quantitative measures of uncertainty in a\ndata set. They are developed by Renyi in the context of entropy theory. These\nmeasures have been studied in the case of the multivariate t-distributions. We\nextend these tools to the class of multivariate skew t-distributions and then\nto more families of finite mixture of multivariate skew t distributions. In\nparticular, by using generalized Holder inequality and some properties of\nmultinomial theorem, we find upper and lower bounds of entropies for these\nfamilies. An approximate value of these entropies can be calculated. In\naddition, an asymptotic expression for Renyi entropy is given by approximation\nand by using some inequalities and properties of Lp spaces. Finally, we give a\nreal data examples to illustrate the behavior of entropy of the mixture model\nunder consideration.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 21:40:25 GMT"}], "update_date": "2019-01-31", "authors_parsed": [["Abid", "Salah H.", ""], ["Quaez", "Uday J.", ""]]}, {"id": "1901.11052", "submitter": "Andrey Gorshenin", "authors": "Victor Korolev, Andrey Gorshenin", "title": "Improved mathematical models of statistical regularities in\n  precipitation", "comments": "16 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper presents improved mathematical models and methods for statistical\nregularities in the behavior of some important characteristics of\nprecipitation: duration of a wet period, maximum daily and total precipitation\nvolumes within a such period. The asymptotic approximations are deduced using\nlimit theorems for statistics constructed from samples with random sizes having\nthe generalized negative binomial (GNB) distribution. It demonstrates excellent\nconcordance with the empirical distribution of the duration of wet periods\nmeasured in days. The asymptotic distribution of the maximum daily\nprecipitation volume within a wet period turns out to be a tempered scale\nmixture of the gamma distribution with the scale factor having the Weibull\ndistribution, whereas the asymptotic approximation to the total precipitation\nvolume for a wet period turns out to be the generalized gamma (GG)\ndistribution. Two approaches to the definition of abnormally extremal\nprecipitation are presented. The first approach is based on an excess of a\ncertain quantile of the asymptotic distribution of the maximum daily\nprecipitation. The second approach is based on the GG model for the total\nprecipitation volume. The corresponding statistical test is compared with a\npreviously proposed one based on tha classical gamma distribution using real\nprecipitation data.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2019 19:17:33 GMT"}], "update_date": "2019-02-01", "authors_parsed": [["Korolev", "Victor", ""], ["Gorshenin", "Andrey", ""]]}, {"id": "1901.11143", "submitter": "Tijana Zrnic", "authors": "Tijana Zrnic, Moritz Hardt", "title": "Natural Analysts in Adaptive Data Analysis", "comments": "22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adaptive data analysis is frequently criticized for its pessimistic\ngeneralization guarantees. The source of these pessimistic bounds is a model\nthat permits arbitrary, possibly adversarial analysts that optimally use\ninformation to bias results. While being a central issue in the field, still\nlacking are notions of natural analysts that allow for more optimistic bounds\nfaithful to the reality that typical analysts aren't adversarial.\n  In this work, we propose notions of natural analysts that smoothly\ninterpolate between the optimal non-adaptive bounds and the best-known adaptive\ngeneralization bounds. To accomplish this, we model the analyst's knowledge as\nevolving according to the rules of an unknown dynamical system that takes in\nrevealed information and outputs new statistical queries to the data. This\nallows us to restrict the analyst through different natural control-theoretic\nnotions. One such notion corresponds to a recency bias, formalizing an\ninability to arbitrarily use distant information. Another complementary notion\nformalizes an anchoring bias, a tendency to weight initial information more\nstrongly. Both notions come with quantitative parameters that smoothly\ninterpolate between the non-adaptive case and the fully adaptive case, allowing\nfor a rich spectrum of intermediate analysts that are neither non-adaptive nor\nadversarial.\n  Natural not only from a cognitive perspective, we show that our notions also\ncapture standard optimization methods, like gradient descent in various\nsettings. This gives a new interpretation to the fact that gradient descent\ntends to overfit much less than its adaptive nature might suggest.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2019 23:26:01 GMT"}, {"version": "v2", "created": "Sun, 12 May 2019 01:28:51 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Zrnic", "Tijana", ""], ["Hardt", "Moritz", ""]]}]