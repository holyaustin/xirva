[{"id": "0905.0436", "submitter": "Radu Craiu Dr", "authors": "Fang Yao, Radu V. Craiu and Benjamin Reiser", "title": "Nonparametric Covariate Adjustment for Receiver Operating Characteristic\n  Curves", "comments": null, "journal-ref": "Canadian Journal of Statistics, vol 38, No. 1, p 27-46, 2010", "doi": "10.1002/cjs.10044", "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The accuracy of a diagnostic test is typically characterised using the\nreceiver operating characteristic (ROC) curve. Summarising indexes such as the\narea under the ROC curve (AUC) are used to compare different tests as well as\nto measure the difference between two populations. Often additional information\nis available on some of the covariates which are known to influence the\naccuracy of such measures. We propose nonparametric methods for covariate\nadjustment of the AUC. Models with normal errors and non-normal errors are\ndiscussed and analysed separately. Nonparametric regression is used for\nestimating mean and variance functions in both scenarios. In the general noise\ncase we propose a covariate-adjusted Mann-Whitney estimator for AUC estimation\nwhich effectively uses available data to construct working samples at any\ncovariate value of interest and is computationally efficient for\nimplementation. This provides a generalisation of the Mann-Whitney approach for\ncomparing two populations by taking covariate effects into account. We derive\nasymptotic properties for the AUC estimators in both settings, including\nasymptotic normality, optimal strong uniform convergence rates and MSE\nconsistency. The usefulness of the proposed methods is demonstrated through\nsimulated and real data examples.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2009 17:43:22 GMT"}], "update_date": "2010-12-30", "authors_parsed": [["Yao", "Fang", ""], ["Craiu", "Radu V.", ""], ["Reiser", "Benjamin", ""]]}, {"id": "0905.0483", "submitter": "Zachary Harmany", "authors": "Zachary T. Harmany, Roummel F. Marcia, and Rebecca M. Willett", "title": "Sparse Poisson Intensity Reconstruction Algorithms", "comments": "4 pages, 4 figures, PDFLaTeX, Submitted to IEEE Workshop on\n  Statistical Signal Processing, 2009", "journal-ref": null, "doi": "10.1109/SSP.2009.5278495", "report-no": null, "categories": "math.OC math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The observations in many applications consist of counts of discrete events,\nsuch as photons hitting a dector, which cannot be effectively modeled using an\nadditive bounded or Gaussian noise model, and instead require a Poisson noise\nmodel. As a result, accurate reconstruction of a spatially or temporally\ndistributed phenomenon (f) from Poisson data (y) cannot be accomplished by\nminimizing a conventional l2-l1 objective function. The problem addressed in\nthis paper is the estimation of f from y in an inverse problem setting, where\n(a) the number of unknowns may potentially be larger than the number of\nobservations and (b) f admits a sparse approximation in some basis. The\noptimization formulation considered in this paper uses a negative Poisson\nlog-likelihood objective function with nonnegativity constraints (since Poisson\nintensities are naturally nonnegative). This paper describes computational\nmethods for solving the constrained sparse Poisson inverse problem. In\nparticular, the proposed approach incorporates key ideas of using quadratic\nseparable approximations to the objective function at each iteration and\ncomputationally efficient partition-based multiscale estimation methods.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2009 20:26:07 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Harmany", "Zachary T.", ""], ["Marcia", "Roummel F.", ""], ["Willett", "Rebecca M.", ""]]}, {"id": "0905.0642", "submitter": "Martin Wainwright", "authors": "S. Negahban, M. J. Wainwright", "title": "Simultaneous support recovery in high dimensions: Benefits and perils of\n  block $\\ell_1/\\ell_\\infty$-regularization", "comments": "Presented in part at NIPS 2008 conference, Vancouver, Canada,\n  December 2008", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT math.IT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider the use of $\\ell_{1}/\\ell_{\\infty}$-regularized regression for joint\nestimation of a $\\pdim \\times \\numreg$ matrix of regression coefficients. We\nanalyze the high-dimensional scaling of $\\ell_1/\\ell_\\infty$-regularized\nquadratic programming, considering both consistency in $\\ell_\\infty$-norm, and\nvariable selection. We begin by establishing bounds on the $\\ell_\\infty$-error\nas well sufficient conditions for exact variable selection for fixed and random\ndesigns. Our second set of results applies to $\\numreg = 2$ linear regression\nproblems with standard Gaussian designs whose supports overlap in a fraction\n$\\alpha \\in [0,1]$ of their entries: for this problem class, we prove that the\n$\\ell_{1}/\\ell_{\\infty}$-regularized method undergoes a phase transition--that\nis, a sharp change from failure to success--characterized by the rescaled\nsample size $\\theta_{1,\\infty}(n, p, s, \\alpha) = n/\\{(4 - 3 \\alpha) s\n\\log(p-(2- \\alpha) s)\\}$. An implication of this threshold is that use of\n$\\ell_1 / \\ell_{\\infty}$-regularization yields improved statistical efficiency\nif the overlap parameter is large enough ($\\alpha > 2/3$), but has \\emph{worse}\nstatistical efficiency than a naive Lasso-based approach for moderate to small\noverlap ($\\alpha < 2/3$). These results indicate that some caution needs to be\nexercised in the application of $\\ell_1/\\ell_\\infty$ block regularization: if\nthe data does not match its structure closely enough, it can impair statistical\nperformance relative to computationally less expensive schemes.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2009 16:28:50 GMT"}], "update_date": "2009-05-12", "authors_parsed": [["Negahban", "S.", ""], ["Wainwright", "M. J.", ""]]}, {"id": "0905.0884", "submitter": "Erwan Le Pennec", "authors": "Karine Bertin (CIMFAV), Erwan Le Pennec (PMA), Vincent Rivoirard\n  (LM-Orsay, DMA)", "title": "Adaptive Dantzig density estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with the problem of density estimation. We aim at building\nan estimate of an unknown density as a linear combination of functions of a\ndictionary. Inspired by Cand\\`es and Tao's approach, we propose an\n$\\ell_1$-minimization under an adaptive Dantzig constraint coming from sharp\nconcentration inequalities. This allows to consider a wide class of\ndictionaries. Under local or global coherence assumptions, oracle inequalities\nare derived. These theoretical results are also proved to be valid for the\nnatural Lasso estimate associated with our Dantzig procedure. Then, the issue\nof calibrating these procedures is studied from both theoretical and practical\npoints of view. Finally, a numerical study shows the significant improvement\nobtained by our procedures when compared with other classical procedures.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2009 18:30:47 GMT"}], "update_date": "2009-05-07", "authors_parsed": [["Bertin", "Karine", "", "CIMFAV"], ["Pennec", "Erwan Le", "", "PMA"], ["Rivoirard", "Vincent", "", "LM-Orsay, DMA"]]}, {"id": "0905.0989", "submitter": "Beatrice Laurent", "authors": "M. Fromont, B. Laurent, P. Reynaud-Bouret", "title": "Adaptive tests of homogeneity for a Poisson process", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose to test the homogeneity of a Poisson process observed on a finite\ninterval. In this framework, we first provide lower bounds for the uniform\nseparation rates in $\\mathbb{L}^2$ norm over classical Besov bodies and weak\nBesov bodies. Surprisingly, the obtained lower bounds over weak Besov bodies\ncoincide with the minimax estimation rates over such classes. Then we construct\nnon asymptotic and nonparametric testing procedures that are adaptive in the\nsense that they achieve, up to a possible logarithmic factor, the optimal\nuniform separation rates over various Besov bodies simultaneously. These\nprocedures are based on model selection and thresholding methods. We finally\ncomplete our theoretical study with a Monte Carlo evaluation of the power of\nour tests under various alternatives.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2009 10:29:16 GMT"}], "update_date": "2009-05-08", "authors_parsed": [["Fromont", "M.", ""], ["Laurent", "B.", ""], ["Reynaud-Bouret", "P.", ""]]}, {"id": "0905.1215", "submitter": "Dominik Seethaler", "authors": "Dominik Seethaler, Joakim Jald\\'en, Christoph Studer, and Helmut\n  B\\\"olcskei", "title": "Tail Behavior of Sphere-Decoding Complexity in Random Lattices", "comments": "To be presented at IEEE ISIT 2009, Seoul, Korea", "journal-ref": null, "doi": "10.1109/ISIT.2009.5205679", "report-no": null, "categories": "cs.IT cs.CC math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the (computational) complexity distribution of sphere-decoding\n(SD) for random infinite lattices. In particular, we show that under fairly\ngeneral assumptions on the statistics of the lattice basis matrix, the tail\nbehavior of the SD complexity distribution is solely determined by the inverse\nvolume of a fundamental region of the underlying lattice. Particularizing this\nresult to NxM, N>=M, i.i.d. Gaussian lattice basis matrices, we find that the\ncorresponding complexity distribution is of Pareto-type with tail exponent\ngiven by N-M+1. We furthermore show that this tail exponent is not improved by\nlattice-reduction, which includes layer-sorting as a special case.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2009 09:41:58 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Seethaler", "Dominik", ""], ["Jald\u00e9n", "Joakim", ""], ["Studer", "Christoph", ""], ["B\u00f6lcskei", "Helmut", ""]]}, {"id": "0905.1419", "submitter": "Khalifa Es-Sebaiy", "authors": "Es-Sebaiy Khalifa (SAMOS), Idir Ouassou, Youssef Ouknine", "title": "Estimation of the drift of fractional Brownian motion", "comments": null, "journal-ref": "Statistics & Probability Letters (2009) 8", "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of efficient estimation for the drift of fractional\nBrownian motion $B^H:=(B^H_t)_{t\\in[0,T]}$ with hurst parameter $H$ less than\n1/2. We also construct superefficient James-Stein type estimators which\ndominate, under the usual quadratic risk, the natural maximum likelihood\nestimator.\n", "versions": [{"version": "v1", "created": "Sat, 9 May 2009 17:55:05 GMT"}], "update_date": "2009-05-12", "authors_parsed": [["Khalifa", "Es-Sebaiy", "", "SAMOS"], ["Ouassou", "Idir", ""], ["Ouknine", "Youssef", ""]]}, {"id": "0905.1437", "submitter": "Andrey Novikov", "authors": "Andrey Novikov, Petr Novikov", "title": "Locally most powerful sequential tests of a simple hypothesis vs\n  one-sided alternatives", "comments": "30 pages", "journal-ref": "Journal of Statistical Planning and Inference, v. 140 (2010), no.\n  3, 750--765", "doi": "10.1016/j.jspi.2009.09.004", "report-no": null, "categories": "math.ST math.PR stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $X_1,X_2,...$ be a discrete-time stochastic process with a distribution\n$P_\\theta$, $\\theta\\in\\Theta$, where $\\Theta$ is an open subset of the real\nline. We consider the problem of testing a simple hypothesis $H_0:$\n$\\theta=\\theta_0$ versus a composite alternative $H_1:$ $\\theta>\\theta_0$,\nwhere $\\theta_0\\in\\Theta$ is some fixed point. The main goal of this article is\nto characterize the structure of locally most powerful sequential tests in this\nproblem.\n  For any sequential test $(\\psi,\\phi)$ with a (randomized) stopping rule\n$\\psi$ and a (randomized) decision rule $\\phi$ let $\\alpha(\\psi,\\phi)$ be the\ntype I error probability, $\\dot \\beta_0(\\psi,\\phi)$ the derivative, at\n$\\theta=\\theta_0$, of the power function, and $\\mathscr N(\\psi)$ an average\nsample number of the test $(\\psi,\\phi)$. Then we are concerned with the problem\nof maximizing $\\dot \\beta_0(\\psi,\\phi)$ in the class of all sequential tests\nsuch that $$ \\alpha(\\psi,\\phi)\\leq \\alpha\\quad{and}\\quad \\mathscr N(\\psi)\\leq\n\\mathscr N, $$ where $\\alpha\\in[0,1]$ and $\\mathscr N\\geq 1$ are some\nrestrictions. It is supposed that $\\mathscr N(\\psi)$ is calculated under some\nfixed (not necessarily coinciding with one of $P_\\theta$) distribution of the\nprocess $X_1,X_2...$.\n  The structure of optimal sequential tests is characterized.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2009 12:23:53 GMT"}], "update_date": "2009-12-23", "authors_parsed": [["Novikov", "Andrey", ""], ["Novikov", "Petr", ""]]}, {"id": "0905.1486", "submitter": "Yannick Baraud", "authors": "Yannick Baraud", "title": "Estimator selection with respect to Hellinger-type risks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We observe a random measure $N$ and aim at estimating its intensity $s$. This\nstatistical framework allows to deal simultaneously with the problems of\nestimating a density, the marginals of a multivariate distribution, the mean of\na random vector with nonnegative components and the intensity of a Poisson\nprocess. Our estimation strategy is based on estimator selection. Given a\nfamily of estimators of $s$ based on the observation of $N$, we propose a\nselection rule, based on $N$ as well, in view of selecting among these. Little\nassumption is made on the collection of estimators. The procedure offers the\npossibility to perform model selection and also to select among estimators\nassociated to different model selection strategies. Besides, it provides an\nalternative to the $T$-estimators as studied recently in Birg\\'e (2006). For\nillustration, we consider the problems of estimation and (complete) variable\nselection in various regression settings.\n", "versions": [{"version": "v1", "created": "Sun, 10 May 2009 16:18:00 GMT"}], "update_date": "2009-05-12", "authors_parsed": [["Baraud", "Yannick", ""]]}, {"id": "0905.1673", "submitter": "Vladimir Vovk", "authors": "Vladimir Vovk", "title": "Prequential probability: game-theoretic = measure theoretic", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article continues study of the prequential framework for evaluating a\nprobability forecaster. Testing the hypothesis that the sequence of forecasts\nissued by the forecaster is in agreement with the observed outcomes can be done\nusing prequential notions of probability. It turns out that there are two\nnatural notions of probability in the prequential framework: game-theoretic,\nwhose idea goes back to von Mises and Ville, and measure-theoretic, whose idea\ngoes back to Kolmogorov. The main result of this article is that, in the case\nof predicting binary outcomes, the two notions of probability in fact coincide\non the analytic sets (in particular, on the Borel sets).\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2009 18:49:49 GMT"}], "update_date": "2009-05-12", "authors_parsed": [["Vovk", "Vladimir", ""]]}, {"id": "0905.2078", "submitter": "Vladimir Koltchinskii", "authors": "Vladimir Koltchinskii", "title": "Sparse recovery in convex hulls via entropy penalization", "comments": "Published in at http://dx.doi.org/10.1214/08-AOS621 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2009, Vol. 37, No. 3, 1332-1359", "doi": "10.1214/08-AOS621", "report-no": "IMS-AOS-AOS621", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $(X,Y)$ be a random couple in $S\\times T$ with unknown distribution $P$\nand $(X_1,Y_1),...,(X_n,Y_n)$ be i.i.d. copies of $(X,Y).$ Denote $P_n$ the\nempirical distribution of $(X_1,Y_1),...,(X_n,Y_n).$ Let $h_1,...,h_N:S\\mapsto\n[-1,1]$ be a dictionary that consists of $N$ functions. For $\\lambda \\in\n{\\mathbb{R}}^N,$ denote $f_{\\lambda}:=\\sum_{j=1}^N\\lambda_jh_j.$ Let\n$\\ell:T\\times {\\mathbb{R}}\\mapsto {\\mathbb{R}}$ be a given loss function and\nsuppose it is convex with respect to the second variable. Let $(\\ell \\bullet\nf)(x,y):=\\ell(y;f(x)).$ Finally, let $\\Lambda \\subset {\\mathbb{R}}^N$ be the\nsimplex of all probability distributions on $\\{1,...,N\\}.$ Consider the\nfollowing penalized empirical risk minimization problem\n\\begin{eqnarray*}\\hat{\\lambda}^{\\varepsilon}:={\\mathop {argmin}_{\\lambda\\in\n\\Lambda}}\\Biggl[P_n(\\ell \\bullet f_{\\lambda})+\\varepsilon\n\\sum_{j=1}^N\\lambda_j\\log \\lambda_j\\Biggr]\\end{eqnarray*} along with its\ndistribution dependent version \\begin{eqnarray*}\\lambda^{\\varepsilon}:={\\mathop\n{argmin}_{\\lambda\\in \\Lambda}}\\Biggl[P(\\ell \\bullet f_{\\lambda})+\\varepsilon\n\\sum_{j=1}^N\\lambda_j\\log \\lambda_j\\Biggr],\\end{eqnarray*} where\n$\\varepsilon\\geq 0$ is a regularization parameter. It is proved that the\n``approximate sparsity'' of $\\lambda^{\\varepsilon}$ implies the ``approximate\nsparsity'' of $\\hat{\\lambda}^{\\varepsilon}$ and the impact of ``sparsity'' on\nbounding the excess risk of the empirical solution is explored. Similar results\nare also discussed in the case of entropy penalized density estimation.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2009 11:54:39 GMT"}], "update_date": "2009-05-14", "authors_parsed": [["Koltchinskii", "Vladimir", ""]]}, {"id": "0905.2171", "submitter": "Adrian Barbu", "authors": "Florentina Bunea, Adrian Barbu", "title": "Dimension reduction and variable selection in case control studies via\n  regularized likelihood optimization", "comments": "32 pages, 5 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dimension reduction and variable selection are performed routinely in\ncase-control studies, but the literature on the theoretical aspects of the\nresulting estimates is scarce. We bring our contribution to this literature by\nstudying estimators obtained via L1 penalized likelihood optimization. We show\nthat the optimizers of the L1 penalized retrospective likelihood coincide with\nthe optimizers of the L1 penalized prospective likelihood. This extends the\nresults of Prentice and Pyke (1979), obtained for non-regularized likelihoods.\nWe establish both the sup-norm consistency of the odds ratio, after model\nselection, and the consistency of subset selection of our estimators. The\nnovelty of our theoretical results consists in the study of these properties\nunder the case-control sampling scheme. Our results hold for selection\nperformed over a large collection of candidate variables, with cardinality\nallowed to depend and be greater than the sample size. We complement our\ntheoretical results with a novel approach of determining data driven tuning\nparameters, based on the bisection method. The resulting procedure offers\nsignificant computational savings when compared with grid search based methods.\nAll our numerical experiments support strongly our theoretical findings.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2009 19:02:43 GMT"}, {"version": "v2", "created": "Fri, 20 Nov 2009 22:19:32 GMT"}], "update_date": "2009-11-21", "authors_parsed": [["Bunea", "Florentina", ""], ["Barbu", "Adrian", ""]]}, {"id": "0905.2524", "submitter": "Dalia Chakrabarty Dr.", "authors": "Dalia Chakrabarty", "title": "CHASSIS - Inverse Modelling of Relaxed Dynamical Systems", "comments": "7 pages, 2 figures, 1 paged abstract - shorter version of the\n  abstract presented here, accepted after review for publication in the\n  proceedings of the 18th IMACS World Congress - MODSIM09 International\n  Congress on Modelling and Simulation, Cairns, Australia, 2009", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST astro-ph.IM stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The state of a non-relativistic gravitational dynamical system is known at\nany time $t$ if the dynamical rule, i.e. Newton's equations of motion, can be\nsolved; this requires specification of the gravitational potential. The\nevolution of a bunch of phase space coordinates ${\\bf w}$ is deterministic,\nthough generally non-linear. We discuss the novel Bayesian non-parametric\nalgorithm CHASSIS that gives phase space $pdf$ $f({\\bf w})$ and potential\n$\\Phi({\\bf x})$ of a relaxed gravitational system. CHASSIS is undemanding in\nterms of input requirements in that it is viable given incomplete,\nsingle-component velocity information of system members. Here ${\\bf x}$ is the\n3-D spatial coordinate and ${\\bf w}={\\bf x+v}$ where ${\\bf v}$ is the 3-D\nvelocity vector. CHASSIS works with a 2-integral $f=f(E, L)$ where energy\n$E=\\Phi + v^2/2, \\: v^2 = \\sum_{i=1}^{3}{v_i^2}$ and the angular momentum is $L\n= |{\\bf r}\\times{\\bf v}|$, where ${\\bf r}$ is the spherical spatial vector.\nAlso, we assume spherical symmetry. CHASSIS obtains the $f(\\cdot)$ from which\nthe kinematic data is most likely to have been drawn, in the best choice for\n$\\Phi(\\cdot)$, using an MCMC optimiser (Metropolis-Hastings). The likelihood\nfunction ${\\cal{L}}$ is defined in terms of the projections of $f(\\cdot)$ into\nthe space of observables and the maximum in ${\\cal{L}}$ is sought by the\noptimiser.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2009 11:16:13 GMT"}], "update_date": "2009-05-18", "authors_parsed": [["Chakrabarty", "Dalia", ""]]}, {"id": "0905.2639", "submitter": "Narayana Santhanam", "authors": "Narayana Santhanam and Martin J. Wainwright", "title": "Information-theoretic limits of selecting binary graphical models in\n  high dimensions", "comments": "27 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of graphical model selection is to correctly estimate the graph\nstructure of a Markov random field given samples from the underlying\ndistribution. We analyze the information-theoretic limitations of the problem\nof graph selection for binary Markov random fields under high-dimensional\nscaling, in which the graph size $p$ and the number of edges $k$, and/or the\nmaximal node degree $d$ are allowed to increase to infinity as a function of\nthe sample size $n$. For pairwise binary Markov random fields, we derive both\nnecessary and sufficient conditions for correct graph selection over the class\n$\\mathcal{G}_{p,k}$ of graphs on $p$ vertices with at most $k$ edges, and over\nthe class $\\mathcal{G}_{p,d}$ of graphs on $p$ vertices with maximum degree at\nmost $d$. For the class $\\mathcal{G}_{p, k}$, we establish the existence of\nconstants $c$ and $c'$ such that if $\\numobs < c k \\log p$, any method has\nerror probability at least 1/2 uniformly over the family, and we demonstrate a\ngraph decoder that succeeds with high probability uniformly over the family for\nsample sizes $\\numobs > c' k^2 \\log p$. Similarly, for the class\n$\\mathcal{G}_{p,d}$, we exhibit constants $c$ and $c'$ such that for $n < c d^2\n\\log p$, any method fails with probability at least 1/2, and we demonstrate a\ngraph decoder that succeeds with high probability for $n > c' d^3 \\log p$.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2009 00:41:30 GMT"}], "update_date": "2009-05-19", "authors_parsed": [["Santhanam", "Narayana", ""], ["Wainwright", "Martin J.", ""]]}, {"id": "0905.2646", "submitter": "Yaming Yu", "authors": "Yaming Yu", "title": "Monotonic convergence of a general algorithm for computing optimal\n  designs", "comments": "Published in at http://dx.doi.org/10.1214/09-AOS761 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2010, Vol. 38, No. 3, 1593-1606", "doi": "10.1214/09-AOS761", "report-no": "IMS-AOS-AOS761", "categories": "stat.CO math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monotonic convergence is established for a general class of multiplicative\nalgorithms introduced by Silvey, Titterington and Torsney [Comm. Statist.\nTheory Methods 14 (1978) 1379--1389] for computing optimal designs. A\nconjecture of Titterington [Appl. Stat. 27 (1978) 227--234] is confirmed as a\nconsequence. Optimal designs for logistic regression are used as an\nillustration.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2009 18:53:53 GMT"}, {"version": "v2", "created": "Tue, 19 May 2009 06:54:14 GMT"}, {"version": "v3", "created": "Fri, 15 Jan 2010 18:13:54 GMT"}, {"version": "v4", "created": "Tue, 5 Oct 2010 07:24:29 GMT"}], "update_date": "2010-10-06", "authors_parsed": [["Yu", "Yaming", ""]]}, {"id": "0905.2761", "submitter": "Yves Atchade F", "authors": "Yves F. Atchade", "title": "A strong law of large numbers for martingale arrays", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove a martingale triangular array generalization of the\nChow-Birnbaum-Marshall's inequality. The result is used to derive a strong law\nof large numbers for martingale triangular arrays whose rows are asymptotically\nstable in a certain sense. To illustrate, we derive a simple proof, based on\nmartingale arguments, of the consistency of kernel regression with dependent\ndata. Another application can be found in \\cite{atchadeetfort08} where the new\ninequality is used to prove a strong law of large numbers for adaptive Markov\nChain Monte Carlo methods.\n", "versions": [{"version": "v1", "created": "Sun, 17 May 2009 18:43:49 GMT"}], "update_date": "2009-05-19", "authors_parsed": [["Atchade", "Yves F.", ""]]}, {"id": "0905.2776", "submitter": "Akimichi Takemura", "authors": "Junya Honda and Akimichi Takemura", "title": "An Asymptotically Optimal Policy for Finite Support Models in the\n  Multiarmed Bandit Problem", "comments": null, "journal-ref": "Machine Learning 85 (2011) 361--391", "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose minimum empirical divergence (MED) policy for the multiarmed\nbandit problem. We prove asymptotic optimality of the proposed policy for the\ncase of finite support models. In our setting, Burnetas and Katehakis has\nalready proposed an asymptotically optimal policy. For choosing an arm our\npolicy uses a criterion which is dual to the quantity used in Burnetas and\nKatehakis. Our criterion is easily computed by a convex optimization technique\nand has an advantage in practical implementation. We confirm by simulations\nthat MED policy demonstrates good performance in finite time in comparison to\nother currently popular policies.\n", "versions": [{"version": "v1", "created": "Sun, 17 May 2009 23:27:55 GMT"}, {"version": "v2", "created": "Tue, 16 Feb 2010 11:22:00 GMT"}, {"version": "v3", "created": "Wed, 17 Feb 2010 02:46:08 GMT"}], "update_date": "2011-11-21", "authors_parsed": [["Honda", "Junya", ""], ["Takemura", "Akimichi", ""]]}, {"id": "0905.2944", "submitter": "Iosif Pinelis", "authors": "Iosif Pinelis", "title": "Exponential deficiency of convolutions of densities", "comments": "12 pages, one figure", "journal-ref": "ESAIM Probab. Stat., 16:86--96 (2012)", "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  If a probability density p(\\x) (\\x\\in\\R^k) is bounded and R(t) := \\int\n\\exp(t\\ell(\\x)) \\d\\x < \\infty for some linear functional \\ell and all\nt\\in(0,1), then, for each t\\in(0,1) and all large enough n, the n-fold\nconvolution of the t-tilted density p_t(\\x) := \\exp(t\\ell(\\x)) p(\\x)/R(t) is\nbounded. This is a corollary of a general, \"non-i.i.d.\" result, which is also\nshown to enjoy a certain optimality property. Such results are useful for\nsaddle-point approximations.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2009 18:08:30 GMT"}], "update_date": "2017-01-17", "authors_parsed": [["Pinelis", "Iosif", ""]]}, {"id": "0905.3310", "submitter": "Giacomo Aletti", "authors": "Giacomo Aletti, Caterina May and Piercesare Secchi", "title": "A functional equation whose unknown is P([0,1]) valued", "comments": "31 pages, pre-galleys version of accepted paper", "journal-ref": "Journal of Theoretical Probability, December 2012, Volume 25,\n  Issue 4, pp 1207-1232", "doi": "10.1007/s10959-011-0399-7", "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a functional equation whose unknown maps a Euclidean space into the\nspace of probability distributions on [0,1]. We prove existence and uniqueness\nof its solution under suitable regularity and boundary conditions, we show that\nit depends continuously on the boundary datum, and we characterize solutions\nthat are diffuse on [0,1]. A canonical solution is obtained by means of a\nRandomly Reinforced Urn with different reinforcement distributions having equal\nmeans. The general solution to the functional equation defines a new parametric\ncollection of distributions on [0,1] generalizing the Beta family.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2009 13:24:52 GMT"}, {"version": "v2", "created": "Tue, 7 Jul 2009 10:01:24 GMT"}, {"version": "v3", "created": "Wed, 23 Nov 2011 22:02:08 GMT"}], "update_date": "2012-11-12", "authors_parsed": [["Aletti", "Giacomo", ""], ["May", "Caterina", ""], ["Secchi", "Piercesare", ""]]}, {"id": "0905.3321", "submitter": "Aleksandar Mijatovic", "authors": "Aleksandar Mijatovi\\'c, Paul Schneider", "title": "Globally optimal parameter estimates for nonlinear diffusions", "comments": "Published in at http://dx.doi.org/10.1214/09-AOS710 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2010, Vol. 38, No. 1, 215-245", "doi": "10.1214/09-AOS710", "report-no": "IMS-AOS-AOS710", "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies an approximation method for the log-likelihood function of\na nonlinear diffusion process using the bridge of the diffusion. The main\nresult (Theorem \\refthm:approx) shows that this approximation converges\nuniformly to the unknown likelihood function and can therefore be used\nefficiently with any algorithm for sampling from the law of the bridge. We also\nintroduce an expected maximum likelihood (EML) algorithm for inferring the\nparameters of discretely observed diffusion processes. The approach is\napplicable to a subclass of nonlinear SDEs with constant volatility and drift\nthat is linear in the model parameters. In this setting, globally optimal\nparameters are obtained in a single step by solving a linear system. Simulation\nstudies to test the EML algorithm show that it performs well when compared with\nalgorithms based on the exact maximum likelihood as well as closed-form\nlikelihood expansions.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2009 14:24:13 GMT"}, {"version": "v2", "created": "Mon, 11 Jan 2010 13:01:52 GMT"}], "update_date": "2010-01-11", "authors_parsed": [["Mijatovi\u0107", "Aleksandar", ""], ["Schneider", "Paul", ""]]}, {"id": "0905.3573", "submitter": "Jinchi Lv", "authors": "Jinchi Lv, Yingying Fan", "title": "A unified approach to model selection and sparse recovery using\n  regularized least squares", "comments": "Published in at http://dx.doi.org/10.1214/09-AOS683 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2009, Vol. 37, No. 6A, 3498-3528", "doi": "10.1214/09-AOS683", "report-no": "IMS-AOS-AOS683", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model selection and sparse recovery are two important problems for which many\nregularization methods have been proposed. We study the properties of\nregularization methods in both problems under the unified framework of\nregularized least squares with concave penalties. For model selection, we\nestablish conditions under which a regularized least squares estimator enjoys a\nnonasymptotic property, called the weak oracle property, where the\ndimensionality can grow exponentially with sample size. For sparse recovery, we\npresent a sufficient condition that ensures the recoverability of the sparsest\nsolution. In particular, we approach both problems by considering a family of\npenalties that give a smooth homotopy between $L_0$ and $L_1$ penalties. We\nalso propose the sequentially and iteratively reweighted squares (SIRS)\nalgorithm for sparse recovery. Numerical studies support our theoretical\nresults and demonstrate the advantage of our new methods for model selection\nand sparse recovery.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2009 22:12:25 GMT"}, {"version": "v2", "created": "Thu, 3 Sep 2009 06:19:03 GMT"}], "update_date": "2009-09-03", "authors_parsed": [["Lv", "Jinchi", ""], ["Fan", "Yingying", ""]]}, {"id": "0905.3619", "submitter": "Anne Gegout-Petit", "authors": "Anne G\\'egout-Petit (IMB, INRIA Bordeaux - Sud-Ouest), Daniel\n  Commenges (ISPED)", "title": "A general definition of influence between stochastic processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend the study of weak local conditional independence (WCLI) based on a\nmeasurability condition made by Commenges and G\\'egout-Petit (2009) to a larger\nclass of processes that we call D'. We also give a definition related to the\nsame concept based on certain likelihood processes, using the Girsanov theorem.\nUnder certain conditions, the two definitions coincide on D'. These results may\nbe used in causal models in that we define what may be the largest class of\nprocesses in which influences of one component of a stochastic process on\nanother can be described without ambiguity. From WCLI we can contruct a concept\nof strong local conditional independence (SCLI). When WCLI does not hold, there\nis a direct influence while when SCLI does not hold there is direct or indirect\ninfluence. We investigate whether WCLI and SCLI can be defined via conventional\nindependence conditions and find that this is the case for the latter but not\nfor the former. Finally we recall that causal interpretation does not follow\nfrom mere mathematical definitions, but requires working with a good system and\nwith the true probability.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2009 07:20:31 GMT"}], "update_date": "2009-05-25", "authors_parsed": [["G\u00e9gout-Petit", "Anne", "", "IMB, INRIA Bordeaux - Sud-Ouest"], ["Commenges", "Daniel", "", "ISPED"]]}, {"id": "0905.3959", "submitter": "Saeid Rezakhah", "authors": "N. Modarresi and S. Rezakhah", "title": "Characterization of Discrete Time Scale Invariant Markov Sequences", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By considering special sampling of discrete scale invariant (DSI) processes\nwe provide a sequence which is in correspondence to multi-dimensional\nself-similar process. By imposing Markov property we show that the covariance\nfunctions of such discrete scale invariant Markov (DSIM) sequences are\ncharacterized by variance, and covariance of adjacent samples in the first\nscale interval. We also provide a theoretical method for estimating spectral\ndensity matrix of corresponding multi-dimensional self-similar Markov process.\nSome examples such as simple Brownian motion with drift and scale invariant\nautoregressive model of order one are presented and these properties are\ninvestigated. By simulating DSIM sequences we provide visualization of their\nbehavior and investigate these results. Finally we present a new method to\nestimate Hurst parameter of DSI processes and show that it has much better\nperformance than maximum likelihood method for simulated data.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2009 07:06:17 GMT"}, {"version": "v2", "created": "Wed, 1 Jul 2009 12:51:32 GMT"}, {"version": "v3", "created": "Sat, 3 Oct 2009 12:55:40 GMT"}, {"version": "v4", "created": "Mon, 20 Sep 2010 17:00:25 GMT"}, {"version": "v5", "created": "Sat, 8 Feb 2014 10:14:47 GMT"}], "update_date": "2014-02-11", "authors_parsed": [["Modarresi", "N.", ""], ["Rezakhah", "S.", ""]]}, {"id": "0905.4131", "submitter": "Iuliana Teodorescu", "authors": "Iuliana Teodorescu", "title": "Maximum Likelihood Estimation for Markov Chains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new approach for optimal estimation of Markov chains with sparse transition\nmatrices is presented.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2009 08:20:50 GMT"}], "update_date": "2009-05-27", "authors_parsed": [["Teodorescu", "Iuliana", ""]]}, {"id": "0905.4221", "submitter": "Nikolai Gagunashvili", "authors": "N.D. Gagunashvili", "title": "Chi-Square Tests for Comparing Weighted Histograms", "comments": "26 pages, 8 figures", "journal-ref": "Nucl.Instrum.Meth.A614:287-296,2010", "doi": "10.1016/j.nima.2009.12.037", "report-no": null, "categories": "physics.data-an math.ST physics.ins-det stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Weighted histograms in Monte Carlo simulations are often used for the\nestimation of probability density functions. They are obtained as a result of\nrandom experiments with random events that have weights. In this paper, the bin\ncontents of a weighted histogram are considered as a sum of random variables\nwith a random number of terms. Generalizations of the classical chi-square test\nfor comparing weighted histograms was proposed. Numerical examples illustrate\nan application of the tests for the histograms with different statistics of\nevents and different weighted functions. The proposed tests can be used for the\ncomparison of experimental data histograms with simulated data histograms, as\nwell as for the two simulated data histograms.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2009 15:11:02 GMT"}, {"version": "v2", "created": "Mon, 12 Oct 2009 16:36:32 GMT"}, {"version": "v3", "created": "Tue, 15 Dec 2009 17:12:16 GMT"}], "update_date": "2010-03-02", "authors_parsed": [["Gagunashvili", "N. D.", ""]]}, {"id": "0905.4247", "submitter": "Sherzod Mirakhmedov", "authors": "Saidbek S.Mirakhmedov and Sherzod M.Mirakhmedov", "title": "On Asymptotic Expansion in the Random Allocation of Particles by Sets", "comments": "15 pages", "journal-ref": null, "doi": "10.1007/s10959-009-02257", "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a scheme of equiprobable allocation of particles into cells by\nsets. The Edgeworth type asymptotic expansion in the local central limit\ntheorem for a number of empty cells left after allocation of all sets of\nparticles is derived.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2009 17:09:00 GMT"}], "update_date": "2009-05-27", "authors_parsed": [["Mirakhmedov", "Saidbek S.", ""], ["Mirakhmedov", "Sherzod M.", ""]]}, {"id": "0905.4334", "submitter": "R. Liptser", "authors": "R. Liptser", "title": "Large Deviations Application to Billingsley's Example", "comments": "60F10, 60J27", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a classical model related to an empirical distribution function $\nF_n(t)=\\frac{1}{n}\\sum_{k=1}^nI_{\\{\\xi_k\\le t\\}}$ of $(\\xi_k)_{i\\ge 1}$ --\ni.i.d. sequence of random variables, supported on the interval $[0,1]$, with\ncontinuous distribution function $F(t)=\\mathsf{P}(\\xi_1\\le t)$. Applying\n``Stopping Time Techniques'', we give a proof of Kolmogorov's exponential bound\n$$ \\mathsf{P}\\big(\\sup_{t\\in[0,1]}|F_n(t)-F(t)|\\ge \\varepsilon\\big)\\le\n\\text{const.}e^{-n\\delta_\\varepsilon} $$ conjectured by Kolmogorov in 1943.\nUsing this bound we establish a best possible logarithmic asymptotic of $$\n\\mathsf{P}\\big(\\sup_{t\\in[0,1]}n^\\alpha|F_n(t)-F(t)|\\ge \\varepsilon\\big) $$\nwith rate $ \\frac{1}{n^{1-2\\alpha}} $ slower than $\\frac{1}{n}$ for any\n$\\alpha\\in\\big(0,{1/2}\\big)$.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2009 04:52:24 GMT"}, {"version": "v2", "created": "Wed, 24 Jun 2009 07:25:52 GMT"}], "update_date": "2009-06-24", "authors_parsed": [["Liptser", "R.", ""]]}, {"id": "0905.4378", "submitter": "Zvika Ben-Haim", "authors": "Zvika Ben-Haim and Yonina C. Eldar", "title": "The Cramer-Rao Bound for Sparse Estimation", "comments": "11 pages, 2 figures. Submitted to IEEE Transactions on Signal\n  Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT math.IT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of this paper is to characterize the best achievable performance for\nthe problem of estimating an unknown parameter having a sparse representation.\nSpecifically, we consider the setting in which a sparsely representable\ndeterministic parameter vector is to be estimated from measurements corrupted\nby Gaussian noise, and derive a lower bound on the mean-squared error (MSE)\nachievable in this setting. To this end, an appropriate definition of bias in\nthe sparse setting is developed, and the constrained Cramer-Rao bound (CRB) is\nobtained. This bound is shown to equal the CRB of an estimator with knowledge\nof the support set, for almost all feasible parameter values. Consequently, in\nthe unbiased case, our bound is identical to the MSE of the oracle estimator.\nCombined with the fact that the CRB is achieved at high signal-to-noise ratios\nby the maximum likelihood technique, our result provides a new interpretation\nfor the common practice of using the oracle estimator as a gold standard\nagainst which practical approaches are compared.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2009 11:02:54 GMT"}, {"version": "v2", "created": "Mon, 8 Jun 2009 10:02:22 GMT"}, {"version": "v3", "created": "Tue, 9 Jun 2009 08:09:14 GMT"}, {"version": "v4", "created": "Tue, 29 Sep 2009 08:56:07 GMT"}], "update_date": "2009-09-29", "authors_parsed": [["Ben-Haim", "Zvika", ""], ["Eldar", "Yonina C.", ""]]}, {"id": "0905.4602", "submitter": "Piero Barone", "authors": "Piero Barone", "title": "A black box method for solving the complex exponentials approximation\n  problem", "comments": "43 pages, 10 figures", "journal-ref": "Digital Signal Processing (2012)", "doi": "10.1016/j.dsp.2012.09.005", "report-no": null, "categories": "stat.CO math.NA math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common problem, arising in many different applied contexts, consists in\nestimating the number of exponentially damped sinusoids whose weighted sum best\nfits a finite set of noisy data and in estimating their parameters. Many\ndifferent methods exist to this purpose. The best of them are based on\napproximate Maximum Likelihood estimators, assuming to know the number of\ndamped sinusoids, which can then be estimated by an order selection procedure.\nAs the problem can be severely ill posed, a stochastic perturbation method is\nproposed which provides better results than Maximum Likelihood based methods\nwhen the signal-to-noise ratio is low. The method depends on some\nhyperparameters which turn out to be essentially independent of the\napplication. Therefore they can be fixed once and for all, giving rise to a\nblack box method.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2009 10:21:19 GMT"}, {"version": "v2", "created": "Wed, 2 May 2012 13:04:56 GMT"}], "update_date": "2012-09-28", "authors_parsed": [["Barone", "Piero", ""]]}, {"id": "0905.4841", "submitter": "Ruriko Yoshida", "authors": "Fabio Rapallo and Ruriko Yoshida", "title": "Markov bases and subbases for bounded contingency tables", "comments": "22 pages. It will appear in the Annals of the Institution of\n  Statistical Mathematics", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study the computation of Markov bases for contingency tables\nwhose cell entries have an upper bound. In general a Markov basis for unbounded\ncontingency table under a certain model differs from a Markov basis for bounded\ntables. Rapallo, (2007) applied Lawrence lifting to compute a Markov basis for\ncontingency tables whose cell entries are bounded. However, in the process, one\nhas to compute the universal Gr\\\"obner basis of the ideal associated with the\ndesign matrix for a model which is, in general, larger than any reduced\nGr\\\"obner basis. Thus, this is also infeasible in small- and medium-sized\nproblems. In this paper we focus on bounded two-way contingency tables under\nindependence model and show that if these bounds on cells are positive, i.e.,\nthey are not structural zeros, the set of basic moves of all $2 \\times 2$\nminors connects all tables with given margins. We end this paper with an open\nproblem that if we know the given margins are positive, we want to find the\nnecessary and sufficient condition on the set of structural zeros so that the\nset of basic moves of all $2 \\times 2$ minors connects all incomplete\ncontingency tables with given margins.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2009 12:17:47 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2009 15:19:57 GMT"}, {"version": "v3", "created": "Tue, 19 Jan 2010 20:43:43 GMT"}], "update_date": "2010-01-19", "authors_parsed": [["Rapallo", "Fabio", ""], ["Yoshida", "Ruriko", ""]]}, {"id": "0905.4937", "submitter": "Daniil Ryabko", "authors": "Daniil Ryabko (INRIA Futurs, LIFL, INRIA Lille - Nord Europe)", "title": "A criterion for hypothesis testing for stationary processes", "comments": "part or this report appeared as: Test, vol. 21(2), pp. 317-329, 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT math.IT math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a finite-valued sample $X_1,...,X_n$ we wish to test whether it was\ngenerated by a stationary ergodic process belonging to a family $H_0$, or it\nwas generated by a stationary ergodic process outside $H_0$. We require the\nType I error of the test to be uniformly bounded, while the type II error has\nto be mande not more than a finite number of times with probability 1. For this\nnotion of consistency we provide necessary and sufficient conditions on the\nfamily $H_0$ for the existence of a consistent test. This criterion is\nillustrated with applications to testing for a membership to parametric\nfamilies, generalizing some existing results. In addition, we analyze a\nstronger notion of consistency, which requires finite-sample guarantees on\nerror of both types, and provide some necessary and some sufficient conditions\nfor the existence of a consistent test. We emphasize that no assumption on the\nprocess distributions are made beyond stationarity and ergodicity.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2009 18:20:24 GMT"}, {"version": "v2", "created": "Sat, 30 May 2009 09:34:36 GMT"}, {"version": "v3", "created": "Mon, 19 Oct 2009 09:59:10 GMT"}, {"version": "v4", "created": "Sat, 27 Dec 2014 00:10:22 GMT"}], "update_date": "2014-12-30", "authors_parsed": [["Ryabko", "Daniil", "", "INRIA Futurs, LIFL, INRIA Lille - Nord Europe"]]}]