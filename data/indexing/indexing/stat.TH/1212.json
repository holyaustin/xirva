[{"id": "1212.0243", "submitter": "Edith Cohen", "authors": "Edith Cohen", "title": "Estimation for Monotone Sampling: Competitiveness and Customization", "comments": "28 pages; Improved write up, presentation in the context of the more\n  general monotone sampling formulation (instead of coordinated sampling).\n  Bounds on universal ratio removed to make the paper more focused, since it is\n  mainly of theoretical interest", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.DB stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random samples are lossy summaries which allow queries posed over the data to\nbe approximated by applying an appropriate estimator to the sample. The\neffectiveness of sampling, however, hinges on estimator selection. The choice\nof estimators is subjected to global requirements, such as unbiasedness and\nrange restrictions on the estimate value, and ideally, we seek estimators that\nare both efficient to derive and apply and {\\em admissible} (not dominated, in\nterms of variance, by other estimators). Nevertheless, for a given data domain,\nsampling scheme, and query, there are many admissible estimators. We study the\nchoice of admissible nonnegative and unbiased estimators for monotone sampling\nschemes. Monotone sampling schemes are implicit in many applications of massive\ndata set analysis. Our main contribution is general derivations of admissible\nestimators with desirable properties. We present a construction of {\\em\norder-optimal} estimators, which minimize variance according to {\\em any}\nspecified priorities over the data domain. Order-optimality allows us to\ncustomize the derivation to common patterns that we can learn or observe in the\ndata. When we prioritize lower values (e.g., more similar data sets when\nestimating difference), we obtain the L$^*$ estimator, which is the unique\nmonotone admissible estimator. We show that the L$^*$ estimator is\n4-competitive and dominates the classic Horvitz-Thompson estimator. These\nproperties make the L$^*$ estimator a natural default choice. We also present\nthe U$^*$ estimator, which prioritizes large values (e.g., less similar data\nsets). Our estimator constructions are both easy to apply and possess desirable\nproperties, allowing us to make the most from our summarized data.\n", "versions": [{"version": "v1", "created": "Sun, 2 Dec 2012 20:46:37 GMT"}, {"version": "v2", "created": "Fri, 2 Aug 2013 18:23:59 GMT"}, {"version": "v3", "created": "Wed, 5 Feb 2014 15:32:57 GMT"}, {"version": "v4", "created": "Wed, 9 Apr 2014 00:01:30 GMT"}], "update_date": "2014-04-10", "authors_parsed": [["Cohen", "Edith", ""]]}, {"id": "1212.0325", "submitter": "Gourab Mukherjee", "authors": "Gourab Mukherjee, Iain M. Johnstone", "title": "On the within-family Kullback-Leibler risk in Gaussian Predictive models", "comments": "This work is based on Chapter 3 of G.M.'s Ph.D. thesis (to be\n  submitted) and was titled as `On efficient quadratic approximations of the\n  predictive log-likelihood in a Gaussian sequence model' in previous preprints", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider estimating the predictive density under Kullback-Leibler loss in\na high-dimensional Gaussian model. Decision theoretic properties of the\nwithin-family prediction error -- the minimal risk among estimates in the class\n$\\mathcal{G}$ of all Gaussian densities are discussed. We show that in sparse\nmodels, the class $\\mathcal{G}$ is minimax sub-optimal. We produce\nasymptotically sharp upper and lower bounds on the within-family prediction\nerrors for various subfamilies of $\\mathcal{G}$. Under mild regularity\nconditions, in the sub-family where the covariance structure is represented by\na single data dependent parameter $\\Shat=\\dhat \\cdot I$, the Kullback-Leiber\nrisk has a tractable decomposition which can be subsequently minimized to yield\noptimally flattened predictive density estimates. The optimal predictive risk\ncan be explicitly expressed in terms of the corresponding mean square error of\nthe location estimate, and so, the role of shrinkage in the predictive regime\ncan be determined based on point estimation theory results. Our results\ndemonstrate that some of the decision theoretic parallels between predictive\ndensity estimation and point estimation regimes can be explained by second\nmoment based concentration properties of the quadratic loss.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2012 09:13:02 GMT"}], "update_date": "2012-12-04", "authors_parsed": [["Mukherjee", "Gourab", ""], ["Johnstone", "Iain M.", ""]]}, {"id": "1212.0463", "submitter": "Daniel McDonald", "authors": "Daniel J. McDonald and Cosma Rohilla Shalizi and Mark Schervish", "title": "Nonparametric risk bounds for time-series forecasting", "comments": "34 pages, 3 figures", "journal-ref": "Journal of Machine Learning Research. (2017). Vol 18. p. 1-40", "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive generalization error bounds for traditional time-series forecasting\nmodels. Our results hold for many standard forecasting tools including\nautoregressive models, moving average models, and, more generally, linear\nstate-space models. These non-asymptotic bounds need only weak assumptions on\nthe data-generating process, yet allow forecasters to select among competing\nmodels and to guarantee, with high probability, that their chosen model will\nperform well. We motivate our techniques with and apply them to standard\neconomic and financial forecasting tools---a GARCH model for predicting equity\nvolatility and a dynamic stochastic general equilibrium model (DSGE), the\nstandard tool in macroeconomic forecasting. We demonstrate in particular how\nour techniques can aid forecasters and policy makers in choosing models which\nbehave well under uncertainty and mis-specification.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2012 17:42:45 GMT"}, {"version": "v2", "created": "Sat, 10 Sep 2016 20:05:05 GMT"}], "update_date": "2017-07-25", "authors_parsed": [["McDonald", "Daniel J.", ""], ["Shalizi", "Cosma Rohilla", ""], ["Schervish", "Mark", ""]]}, {"id": "1212.0478", "submitter": "Po-Ling Loh", "authors": "Po-Ling Loh, Martin J. Wainwright", "title": "Structure estimation for discrete graphical models: Generalized\n  covariance matrices and their inverses", "comments": "Published in at http://dx.doi.org/10.1214/13-AOS1162 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2013, Vol. 41, No. 6, 3022-3049", "doi": "10.1214/13-AOS1162", "report-no": "IMS-AOS-AOS1162", "categories": "stat.ML math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the relationship between the structure of a discrete graphical\nmodel and the support of the inverse of a generalized covariance matrix. We\nshow that for certain graph structures, the support of the inverse covariance\nmatrix of indicator variables on the vertices of a graph reflects the\nconditional independence structure of the graph. Our work extends results that\nhave previously been established only in the context of multivariate Gaussian\ngraphical models, thereby addressing an open question about the significance of\nthe inverse covariance matrix of a non-Gaussian distribution. The proof\nexploits a combination of ideas from the geometry of exponential families,\njunction tree theory and convex analysis. These population-level results have\nvarious consequences for graph selection methods, both known and novel,\nincluding a novel method for structure estimation for missing or corrupted\nobservations. We provide nonasymptotic guarantees for such methods and\nillustrate the sharpness of these predictions via simulations.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2012 18:20:35 GMT"}, {"version": "v2", "created": "Mon, 6 Jan 2014 07:01:20 GMT"}], "update_date": "2014-01-07", "authors_parsed": [["Loh", "Po-Ling", ""], ["Wainwright", "Martin J.", ""]]}, {"id": "1212.0634", "submitter": "Shifeng Xiong Doc", "authors": "Shifeng Xiong", "title": "Better subset regression", "comments": "24 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.CO stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To find efficient screening methods for high dimensional linear regression\nmodels, this paper studies the relationship between model fitting and screening\nperformance. Under a sparsity assumption, we show that a subset that includes\nthe true submodel always yields smaller residual sum of squares (i.e., has\nbetter model fitting) than all that do not in a general asymptotic setting.\nThis indicates that, for screening important variables, we could follow a\n\"better fitting, better screening\" rule, i.e., pick a \"better\" subset that has\nbetter model fitting. To seek such a better subset, we consider the\noptimization problem associated with best subset regression. An EM algorithm,\ncalled orthogonalizing subset screening, and its accelerating version are\nproposed for searching for the best subset. Although the two algorithms cannot\nguarantee that a subset they yield is the best, their monotonicity property\nmakes the subset have better model fitting than initial subsets generated by\npopular screening methods, and thus the subset can have better screening\nperformance asymptotically. Simulation results show that our methods are very\ncompetitive in high dimensional variable screening even for finite sample\nsizes.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2012 07:49:48 GMT"}, {"version": "v2", "created": "Tue, 19 Mar 2013 02:58:03 GMT"}], "update_date": "2013-03-20", "authors_parsed": [["Xiong", "Shifeng", ""]]}, {"id": "1212.0707", "submitter": "Rodrigo Silva", "authors": "Marcelo Bourguignon, Rodrigo B. Silva and Gauss M. Cordeiro", "title": "A new class of fatigue life distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce the Birnbaum-Saunders power series class of\ndistributions which is obtained by compounding Birnbaum-Saunders and power\nseries distributions. The new class of distributions has as a particular case\nthe two-parameter Birnbaum-Saunders distribution. The hazard rate function of\nthe proposed class can be increasing and upside-down bathtub shaped. We provide\nimportant mathematical properties such as moments, order statistics, estimation\nof the parameters and inference for large sample. Three special cases of the\nnew class are investigated with some details. We illustrate the usefulness of\nthe new distributions by means of two applications to real data sets.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2012 12:58:50 GMT"}, {"version": "v2", "created": "Thu, 6 Dec 2012 17:26:06 GMT"}], "update_date": "2012-12-07", "authors_parsed": [["Bourguignon", "Marcelo", ""], ["Silva", "Rodrigo B.", ""], ["Cordeiro", "Gauss M.", ""]]}, {"id": "1212.0757", "submitter": "Jean-Claude Fort", "authors": "Jean-Marc Azais (IMT), Jean-Claude Fort (MAP5)", "title": "Remark on the finite-dimensional character of certain results of\n  functional statistics", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": "MAP5 2012-34", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This note shows that some assumption on small balls probability, frequently\nused in the domain of functional statistics, implies that the considered\nfunctional space is of finite dimension. To complete this result an example of\nL2 process is given that does not fulfill this assumption.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2012 15:19:20 GMT"}], "update_date": "2012-12-06", "authors_parsed": [["Azais", "Jean-Marc", "", "IMT"], ["Fort", "Jean-Claude", "", "MAP5"]]}, {"id": "1212.0945", "submitter": "Allon G. Percus", "authors": "Cristina Garcia-Cardona, Arjuna Flenner and Allon G. Percus", "title": "Multiclass Diffuse Interface Models for Semi-Supervised Learning on\n  Graphs", "comments": "9 pages, to appear in Proceedings of the 2nd International Conference\n  on Pattern Recognition Applications and Methods (ICPRAM 2013)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST physics.data-an stat.TH", "license": "http://creativecommons.org/licenses/publicdomain/", "abstract": "  We present a graph-based variational algorithm for multiclass classification\nof high-dimensional data, motivated by total variation techniques. The energy\nfunctional is based on a diffuse interface model with a periodic potential. We\naugment the model by introducing an alternative measure of smoothness that\npreserves symmetry among the class labels. Through this modification of the\nstandard Laplacian, we construct an efficient multiclass method that allows for\nsharp transitions between classes. The experimental results demonstrate that\nour approach is competitive with the state of the art among other graph-based\nalgorithms.\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2012 07:13:54 GMT"}], "update_date": "2012-12-06", "authors_parsed": [["Garcia-Cardona", "Cristina", ""], ["Flenner", "Arjuna", ""], ["Percus", "Allon G.", ""]]}, {"id": "1212.1076", "submitter": "Stephane Girard", "authors": "L. Gardes (IRMA), S. Girard (INRIA Grenoble Rh\\^one-Alpes / LJK\n  Laboratoire Jean Kuntzmann)", "title": "Functional kernel estimators of conditional extreme quantiles", "comments": "arXiv admin note: text overlap with arXiv:1107.2261", "journal-ref": "Recent advances in functional data analysis and related topics\n  (2011) 135--140", "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the estimation of \"extreme\" conditional quantiles i.e. when their\norder converges to one as the sample size increases. Conditions on the rate of\nconvergence of their order to one are provided to obtain asymptotically\nGaussian distributed kernel estimators. A Weissman-type estimator and kernel\nestimators of the conditional tail-index are derived, permitting to estimate\nextreme conditional quantiles of arbitrary order.\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2012 16:06:21 GMT"}], "update_date": "2012-12-07", "authors_parsed": [["Gardes", "L.", "", "IRMA"], ["Girard", "S.", "", "INRIA Grenoble Rh\u00f4ne-Alpes / LJK\n  Laboratoire Jean Kuntzmann"]]}, {"id": "1212.1182", "submitter": "Minh Tang", "authors": "Minh Tang, Daniel L. Sussman, Carey E. Priebe", "title": "Universally consistent vertex classification for latent positions graphs", "comments": "Published in at http://dx.doi.org/10.1214/13-AOS1112 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2013, Vol. 41, No. 3, 1406-1430", "doi": "10.1214/13-AOS1112", "report-no": "IMS-AOS-AOS1112", "categories": "stat.ML math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we show that, using the eigen-decomposition of the adjacency\nmatrix, we can consistently estimate feature maps for latent position graphs\nwith positive definite link function $\\kappa$, provided that the latent\npositions are i.i.d. from some distribution F. We then consider the\nexploitation task of vertex classification where the link function $\\kappa$\nbelongs to the class of universal kernels and class labels are observed for a\nnumber of vertices tending to infinity and that the remaining vertices are to\nbe classified. We show that minimization of the empirical $\\varphi$-risk for\nsome convex surrogate $\\varphi$ of 0-1 loss over a class of linear classifiers\nwith increasing complexities yields a universally consistent classifier, that\nis, a classification rule with error converging to Bayes optimal for any\ndistribution F.\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2012 21:24:11 GMT"}, {"version": "v2", "created": "Wed, 13 Mar 2013 22:55:09 GMT"}, {"version": "v3", "created": "Tue, 13 Aug 2013 07:38:44 GMT"}], "update_date": "2013-08-14", "authors_parsed": [["Tang", "Minh", ""], ["Sussman", "Daniel L.", ""], ["Priebe", "Carey E.", ""]]}, {"id": "1212.1200", "submitter": "John Rhodes", "authors": "Elizabeth S. Allman, John A. Rhodes, Amelia Taylor", "title": "A semialgebraic description of the general Markov model on phylogenetic\n  trees", "comments": "29 pages, 0 figures; Mittag-Leffler Institute, Spring 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE math.AG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many of the stochastic models used in inference of phylogenetic trees from\nbiological sequence data have polynomial parameterization maps. The image of\nsuch a map --- the collection of joint distributions for a model --- forms the\nmodel space. Since the parameterization is polynomial, the Zariski closure of\nthe model space is an algebraic variety which is typically much larger than the\nmodel space, but has been usefully studied with algebraic methods. Of ultimate\ninterest, however, is not the full variety, but only the model space. Here we\ndevelop complete semialgebraic descriptions of the model space arising from the\nk-state general Markov model on a tree, with slightly restricted parameters.\nOur approach depends upon both recently-formulated analogs of Cayley's\nhyperdeterminant, and the construction of certain quadratic forms from the\njoint distribution whose positive (semi-)definiteness encodes information about\nparameter values. We additionally investigate the use of Sturm sequences for\nobtaining similar results.\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2012 23:03:29 GMT"}], "update_date": "2012-12-07", "authors_parsed": [["Allman", "Elizabeth S.", ""], ["Rhodes", "John A.", ""], ["Taylor", "Amelia", ""]]}, {"id": "1212.1247", "submitter": "Sourav Chatterjee", "authors": "Sourav Chatterjee", "title": "Matrix estimation by Universal Singular Value Thresholding", "comments": "Published in at http://dx.doi.org/10.1214/14-AOS1272 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2015, Vol. 43, No. 1, 177-214", "doi": "10.1214/14-AOS1272", "report-no": "IMS-AOS-AOS1272", "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider the problem of estimating the entries of a large matrix, when the\nobserved entries are noisy versions of a small random fraction of the original\nentries. This problem has received widespread attention in recent times,\nespecially after the pioneering works of Emmanuel Cand\\`{e}s and collaborators.\nThis paper introduces a simple estimation procedure, called Universal Singular\nValue Thresholding (USVT), that works for any matrix that has \"a little bit of\nstructure.\" Surprisingly, this simple estimator achieves the minimax error rate\nup to a constant factor. The method is applied to solve problems related to low\nrank matrix estimation, blockmodels, distance matrix completion, latent space\nmodels, positive definite matrix completion, graphon estimation and generalized\nBradley--Terry models for pairwise comparison.\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2012 06:56:02 GMT"}, {"version": "v2", "created": "Fri, 7 Dec 2012 17:07:34 GMT"}, {"version": "v3", "created": "Wed, 12 Dec 2012 17:54:22 GMT"}, {"version": "v4", "created": "Fri, 28 Dec 2012 05:36:06 GMT"}, {"version": "v5", "created": "Thu, 4 Jul 2013 19:48:22 GMT"}, {"version": "v6", "created": "Mon, 15 Sep 2014 02:41:47 GMT"}, {"version": "v7", "created": "Tue, 30 Dec 2014 06:33:24 GMT"}], "update_date": "2014-12-31", "authors_parsed": [["Chatterjee", "Sourav", ""]]}, {"id": "1212.1384", "submitter": "Jos\\'e Enrique Chac\\'on", "authors": "Jos\\'e E. Chac\\'on", "title": "Clusters and water flows: a novel approach to modal clustering through\n  Morse theory", "comments": "25 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.DG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of finding groups in data (cluster analysis) has been extensively\nstudied by researchers from the fields of Statistics and Computer Science,\namong others. However, despite its popularity it is widely recognized that the\ninvestigation of some theoretical aspects of clustering has been relatively\nsparse. One of the main reasons for this lack of theoretical results is surely\nthe fact that, unlike the situation with other statistical problems as\nregression or classification, for some of the cluster methodologies it is quite\ndifficult to specify a population goal to which the data-based clustering\nalgorithms should try to get close. This paper aims to provide some insight\ninto the theoretical foundations of the usual nonparametric approach to\nclustering, which understands clusters as regions of high density, by\npresenting an explicit formulation for the ideal population clustering.\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2012 17:20:43 GMT"}, {"version": "v2", "created": "Thu, 10 Jan 2013 19:17:33 GMT"}], "update_date": "2013-10-10", "authors_parsed": [["Chac\u00f3n", "Jos\u00e9 E.", ""]]}, {"id": "1212.1788", "submitter": "Juan Carlos Jimenez", "authors": "J.C. Jimenez", "title": "Approximate discrete-time schemes for the estimation of diffusion\n  processes from complete observations", "comments": "The new version corrects some typos and provides extra information\n  that might contribute to clarify some aspects. A new assertion in Theorem 1\n  was added, and a new convergence result was included (current Theorem 2)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC math.ST stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a modification of the conventional approximations to the\nquasi-maximum likelihood method is introduced for the parameter estimation of\ndiffusion processes from discrete observations. This is based on a convergent\napproximation to the first two conditional moments of the diffusion process\nthrough discrete-time schemes. It is shown that, for finite samples, the\nresulting approximate estimators converge to the quasi-maximum likelihood one\nwhen the error between the discrete-time approximation and the diffusion\nprocess decreases. For an increasing number of observations, the approximate\nestimators are asymptotically normal distributed and their bias decreases when\nthe mentioned error does it. A simulation study is provided to illustrate the\nperformance of the new estimators. The results show that, with respect to the\nconventional approximate estimators, the new ones significantly enhance the\nparameter estimation of the test equations. The proposed estimators are\nintended for the recurrent practical situation where a nonlinear stochastic\nsystem should be identified from a reduced number of complete observations\ndistant in time.\n", "versions": [{"version": "v1", "created": "Sat, 8 Dec 2012 13:21:42 GMT"}, {"version": "v2", "created": "Wed, 18 Dec 2013 01:12:45 GMT"}], "update_date": "2013-12-19", "authors_parsed": [["Jimenez", "J. C.", ""]]}, {"id": "1212.1791", "submitter": "James Tucker", "authors": "J. Derek Tucker, Wei Wu, and Anuj Srivastava", "title": "Generative Models for Functional Data using Phase and Amplitude\n  Separation", "comments": "19 Pages, accepted for publication to Computational Statistics and\n  Data Analysis (Dec 2012)", "journal-ref": null, "doi": "10.1016/j.csda.2012.12.001", "report-no": null, "categories": "stat.CO math.ST stat.TH", "license": "http://creativecommons.org/licenses/publicdomain/", "abstract": "  Constructing generative models for functional observations is an important\ntask in statistical functional analysis. In general, functional data contains\nboth phase (or x or horizontal) and amplitude (or y or vertical) variability.\nTradi- tional methods often ignore the phase variability and focus solely on\nthe amplitude variation, using cross-sectional techniques such as fPCA for\ndimensional reduction and data modeling. Ignoring phase variability leads to a\nloss of structure in the data and inefficiency in data models. This paper\npresents an approach that relies on separating the phase (x-axis) and amplitude\n(y-axis), then modeling these components using joint distributions. This\nseparation, in turn, is performed using a technique called elastic shape\nanalysis of curves that involves a new mathematical representation of\nfunctional data. Then, using individual fPCAs, one each for phase and amplitude\ncomponents, while respecting the nonlinear geometry of the phase representation\nspace; impose joint probability models on principal coefficients of these\ncomponents. These ideas are demonstrated using random sampling, for models\nestimated from simulated and real datasets, and show their superiority over\nmodels that ignore phase-amplitude separation. Furthermore, the generative\nmodels are applied to classification of functional data and achieve high\nperformance in applications involv- ing SONAR signals of underwater objects,\nhandwritten signatures, and periodic body movements recorded by smart phones.\n", "versions": [{"version": "v1", "created": "Sat, 8 Dec 2012 13:41:50 GMT"}, {"version": "v2", "created": "Tue, 18 Dec 2012 15:27:57 GMT"}], "update_date": "2019-04-26", "authors_parsed": [["Tucker", "J. Derek", ""], ["Wu", "Wei", ""], ["Srivastava", "Anuj", ""]]}, {"id": "1212.1885", "submitter": "Marta Ferreira", "authors": "Marta Ferreira and Helena Ferreira", "title": "Extremes of multivariate ARMAX processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define a new multivariate time series model by generalizing the ARMAX\nprocess in a multivariate way. We give conditions on stationarity and analyze\nlocal dependence and domains of attraction. As a consequence of the obtained\nresult, we derive a new method of construction of multivariate extreme value\ncopulas. We characterize the extremal dependence by computing the multivariate\nextremal index and bivariate upper tail dependence coefficients. An estimation\nprocedure for the multivariate extremal index shall be presented. We also\naddress the marginal estimation and propose a new estimator for the ARMAX\nautoregressive parameter.\n", "versions": [{"version": "v1", "created": "Sun, 9 Dec 2012 12:26:14 GMT"}], "update_date": "2012-12-11", "authors_parsed": [["Ferreira", "Marta", ""], ["Ferreira", "Helena", ""]]}, {"id": "1212.1949", "submitter": "Jairo Fuquene", "authors": "Jairo Fuquene", "title": "A Semiparametric Bayesian Approach for Extreme Values Using Dirichlet\n  Process Mixture of Gamma and Generalized Pareto Densities", "comments": "New version", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For extreme value estimation we propose to use a model with a Dirichlet\nprocess mixture of gamma densities in the center and generalized Pareto\ndensities for the tails. Due to the randomness in the center and a heavy tailed\ndensity in the tails density estimation and posterior inference for high\nquantiles are possible. The approach can be used in a \"default\" manner on the\npositive reals because it works when prior information is unavailable. The\nproposed model can be easy to implement and a sensitivity analysis is provided.\nWe applied the proposed model for simulated and real data sets.\n", "versions": [{"version": "v1", "created": "Mon, 10 Dec 2012 01:38:19 GMT"}, {"version": "v2", "created": "Thu, 13 Dec 2012 11:49:50 GMT"}, {"version": "v3", "created": "Wed, 16 Jan 2013 10:54:46 GMT"}, {"version": "v4", "created": "Thu, 28 Mar 2013 22:36:29 GMT"}], "update_date": "2013-04-01", "authors_parsed": [["Fuquene", "Jairo", ""]]}, {"id": "1212.2562", "submitter": "Jeremie Bigot", "authors": "J\\'er\\'emie Bigot (1), Thierry Klein (2, 3) ((1) IMB, (2) IMT, (3)\n  ENAC)", "title": "Characterization of barycenters in the Wasserstein space by averaging\n  optimal transport maps", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is concerned by the study of barycenters for random probability\nmeasures in the Wasserstein space. Using a duality argument, we give a precise\ncharacterization of the population barycenter for various parametric classes of\nrandom probability measures with compact support. In particular, we make a\nconnection between averaging in the Wasserstein space as introduced in Agueh\nand Carlier (2011), and taking the expectation of optimal transport maps with\nrespect to a fixed reference measure. We also discuss the usefulness of this\napproach in statistics for the analysis of deformable models in signal and\nimage processing. In this setting, the problem of estimating a population\nbarycenter from n independent and identically distributed random probability\nmeasures is also considered.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2012 17:58:28 GMT"}, {"version": "v2", "created": "Thu, 5 Dec 2013 07:37:44 GMT"}, {"version": "v3", "created": "Mon, 17 Mar 2014 18:33:37 GMT"}, {"version": "v4", "created": "Mon, 9 Mar 2015 17:23:33 GMT"}, {"version": "v5", "created": "Fri, 17 Jul 2015 16:14:10 GMT"}, {"version": "v6", "created": "Wed, 29 Nov 2017 15:07:20 GMT"}], "update_date": "2017-11-30", "authors_parsed": [["Bigot", "J\u00e9r\u00e9mie", ""], ["Klein", "Thierry", ""]]}, {"id": "1212.2800", "submitter": "Bercu Bernard", "authors": "Bernard Bercu, Frederic Proia, Nicolas Savy", "title": "On Ornstein-Uhlenbeck driven by Ornstein-Uhlenbeck processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the asymptotic behavior of the maximum likelihood estimators\nof the unknown parameters of positive recurrent Ornstein-Uhlenbeck processes\ndriven by Ornstein-Uhlenbeck processes.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 12:56:19 GMT"}], "update_date": "2012-12-13", "authors_parsed": [["Bercu", "Bernard", ""], ["Proia", "Frederic", ""], ["Savy", "Nicolas", ""]]}, {"id": "1212.2882", "submitter": "Harrison Zhou", "authors": "T. Tony Cai, Weidong Liu and Harrison H. Zhou", "title": "Estimating Sparse Precision Matrix: Optimal Rates of Convergence and\n  Adaptive Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Precision matrix is of significant importance in a wide range of applications\nin multivariate analysis. This paper considers adaptive minimax estimation of\nsparse precision matrices in the high dimensional setting. Optimal rates of\nconvergence are established for a range of matrix norm losses. A fully data\ndriven estimator based on adaptive constrained $\\ell_1$ minimization is\nproposed and its rate of convergence is obtained over a collection of parameter\nspaces. The estimator, called ACLIME, is easy to implement and performs well\nnumerically.\n  A major step in establishing the minimax rate of convergence is the\nderivation of a rate-sharp lower bound. A \"two-directional\" lower bound\ntechnique is applied to obtain the minimax lower bound. The upper and lower\nbounds together yield the optimal rates ofconvergence for sparse precision\nmatrix estimation and show that the ACLIME estimator is adaptively minimax rate\noptimal for a collection of parameter spaces and a range of matrix norm losses\nsimultaneously.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 16:56:25 GMT"}], "update_date": "2012-12-13", "authors_parsed": [["Cai", "T. Tony", ""], ["Liu", "Weidong", ""], ["Zhou", "Harrison H.", ""]]}, {"id": "1212.3111", "submitter": "Stephane Girard", "authors": "Stephane Girard (INRIA Grenoble Rh\\^one-Alpes / LJK Laboratoire Jean\n  Kuntzmann), Armelle Guillou (IRMA), Gilles Stupfler (CERGAM)", "title": "Uniform strong consistency of a frontier estimator using kernel\n  regression on high order moments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the high order moments estimator of the frontier of a random pair\nintroduced by Girard, S., Guillou, A., Stupfler, G. (2012). {\\it Frontier\nestimation with kernel regression on high order moments}. In the present paper,\nwe show that this estimator is strongly uniformly consistent on compact sets\nand its rate of convergence is given when the conditional cumulative\ndistribution function belongs to the Hall class of distribution functions.\n", "versions": [{"version": "v1", "created": "Thu, 13 Dec 2012 10:15:46 GMT"}, {"version": "v2", "created": "Tue, 16 Jul 2013 19:59:43 GMT"}], "update_date": "2013-07-17", "authors_parsed": [["Girard", "Stephane", "", "INRIA Grenoble Rh\u00f4ne-Alpes / LJK Laboratoire Jean\n  Kuntzmann"], ["Guillou", "Armelle", "", "IRMA"], ["Stupfler", "Gilles", "", "CERGAM"]]}, {"id": "1212.3151", "submitter": "Sergei Zuyev", "authors": "Maryam Zolghadr and Sergei Zuyev", "title": "Optimal design of dilution experiments under volume constraints", "comments": "29 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.OC stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper develops methods to construct a one-stage optimal design of\ndilution experiments under the total available volume constraint typical for\nbio-medical applications. We consider various design criteria based on the\nFisher information both is Bayesian and non-Bayasian settings and show that the\noptimal design is typically one-atomic meaning that all the dilutions should be\nof the same size. The main tool is variational analysis of functions of a\nmeasure and the corresponding steepest descent type numerical methods. Our\napproach is generic in the sense that it allows for inclusion of additional\nconstraints and cost components, like the cost of materials and of the\nexperiment itself.\n", "versions": [{"version": "v1", "created": "Thu, 13 Dec 2012 12:39:23 GMT"}, {"version": "v2", "created": "Tue, 7 May 2013 15:04:57 GMT"}], "update_date": "2013-05-08", "authors_parsed": [["Zolghadr", "Maryam", ""], ["Zuyev", "Sergei", ""]]}, {"id": "1212.3267", "submitter": "Yuan Liao", "authors": "Yuan Liao, Anna Simoni", "title": "Semi-parametric Bayesian Partially Identified Models based on Support\n  Function", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME econ.EM math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a comprehensive semi-parametric study of Bayesian partially\nidentified econometric models. While the existing literature on Bayesian\npartial identification has mostly focused on the structural parameter, our\nprimary focus is on Bayesian credible sets (BCS's) of the unknown identified\nset and the posterior distribution of its support function. We construct a\n(two-sided) BCS based on the support function of the identified set. We prove\nthe Bernstein-von Mises theorem for the posterior distribution of the support\nfunction. This powerful result in turn infers that, while the BCS and the\nfrequentist confidence set for the partially identified parameter are\nasymptotically different, our constructed BCS for the identified set has an\nasymptotically correct frequentist coverage probability. Importantly, we\nillustrate that the constructed BCS for the identified set does not require a\nprior on the structural parameter. It can be computed efficiently for subset\ninference, especially when the target of interest is a sub-vector of the\npartially identified parameter, where projecting to a low-dimensional subset is\noften required. Hence, the proposed methods are useful in many applications.\n  The Bayesian partial identification literature has been assuming a known\nparametric likelihood function. However, econometric models usually only\nidentify a set of moment inequalities, and therefore using an incorrect\nlikelihood function may result in misleading inferences. In contrast, with a\nnonparametric prior on the unknown likelihood function, our proposed Bayesian\nprocedure only requires a set of moment conditions, and can efficiently make\ninference about both the partially identified parameter and its identified set.\nThis makes it widely applicable in general moment inequality models. Finally,\nthe proposed method is illustrated in a financial asset pricing problem.\n", "versions": [{"version": "v1", "created": "Thu, 13 Dec 2012 18:58:43 GMT"}, {"version": "v2", "created": "Fri, 22 Nov 2013 16:30:34 GMT"}], "update_date": "2017-09-29", "authors_parsed": [["Liao", "Yuan", ""], ["Simoni", "Anna", ""]]}, {"id": "1212.3524", "submitter": "Nicolas  Tremblay", "authors": "Nicolas Tremblay, Alain Barrat, Cary Forest, Mark Nornberg,\n  Jean-Fran\\c{c}ois Pinton, Pierre Borgnat", "title": "Bootstrapping under constraint for the assessment of group behavior in\n  human contact networks", "comments": null, "journal-ref": "Phys. Rev. E 88, 052812 (2013)", "doi": "10.1103/PhysRevE.88.052812", "report-no": null, "categories": "physics.soc-ph cs.SI math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing availability of time --and space-- resolved data describing\nhuman activities and interactions gives insights into both static and dynamic\nproperties of human behavior. In practice, nevertheless, real-world datasets\ncan often be considered as only one realisation of a particular event. This\nhighlights a key issue in social network analysis: the statistical significance\nof estimated properties. In this context, we focus here on the assessment of\nquantitative features of specific subset of nodes in empirical networks. We\npresent a method of statistical resampling based on bootstrapping groups of\nnodes under constraints within the empirical network. The method enables us to\ndefine acceptance intervals for various Null Hypotheses concerning relevant\nproperties of the subset of nodes under consideration, in order to characterize\nby a statistical test its behavior as ``normal'' or not. We apply this method\nto a high resolution dataset describing the face-to-face proximity of\nindividuals during two co-located scientific conferences. As a case study, we\nshow how to probe whether co-locating the two conferences succeeded in bringing\ntogether the two corresponding groups of scientists.\n", "versions": [{"version": "v1", "created": "Fri, 14 Dec 2012 16:48:12 GMT"}, {"version": "v2", "created": "Fri, 8 Nov 2013 12:06:21 GMT"}], "update_date": "2013-11-27", "authors_parsed": [["Tremblay", "Nicolas", ""], ["Barrat", "Alain", ""], ["Forest", "Cary", ""], ["Nornberg", "Mark", ""], ["Pinton", "Jean-Fran\u00e7ois", ""], ["Borgnat", "Pierre", ""]]}, {"id": "1212.3556", "submitter": "Giacomo Aletti", "authors": "Giacomo Aletti (1), Caterina May (2), Chiara Tommasi (1) ((1)\n  Universit\\`a degli Studi di Milano, (2) Universit\\`a del Piemonte Orientale)", "title": "KL-optimum designs: theoretical properties and practical computation", "comments": "The final publication is available at Springer via\n  http://dx.doi.org/10.1007/s11222-014-9515-8", "journal-ref": "Stat Comput (2016) 26: 107-117", "doi": "10.1007/s11222-014-9515-8", "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper some new properties and computational tools for finding\nKL-optimum designs are provided. KL-optimality is a general criterion useful to\nselect the best experimental conditions to discriminate between statistical\nmodels. A KL-optimum design is obtained from a minimax optimization problem,\nwhich is defined on a infinite-dimensional space. In particular, continuity of\nthe KL-optimality criterion is proved under mild conditions; as a consequence,\nthe first-order algorithm converges to the set of KL-optimum designs for a\nlarge class of models. It is also shown that KL-optimum designs are invariant\nto any scale-position transformation. Some examples are given and discussed,\ntogether with some practical implications for numerical computation purposes.\n", "versions": [{"version": "v1", "created": "Fri, 14 Dec 2012 18:17:15 GMT"}, {"version": "v2", "created": "Fri, 7 Jun 2013 12:03:08 GMT"}, {"version": "v3", "created": "Thu, 23 Jan 2014 17:02:30 GMT"}, {"version": "v4", "created": "Mon, 29 Sep 2014 06:31:29 GMT"}], "update_date": "2018-01-04", "authors_parsed": [["Aletti", "Giacomo", ""], ["May", "Caterina", ""], ["Tommasi", "Chiara", ""]]}, {"id": "1212.3603", "submitter": "Alexander Sakhnovich", "authors": "Lev Sakhnovich", "title": "Convolution type form of the Ito representation of the infinitesimal\n  generator for Levy processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CA math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the present paper we show that the Ito representation of the infinitesimal\ngenerator $L$ for Levy processes can be written in a convolution type form.\nUsing the obtained convolution form and the theory of integral equations with\ndifference kernels we study the properties of Levy processes.\n", "versions": [{"version": "v1", "created": "Fri, 14 Dec 2012 15:50:41 GMT"}], "update_date": "2012-12-18", "authors_parsed": [["Sakhnovich", "Lev", ""]]}, {"id": "1212.3647", "submitter": "Justin Kinney", "authors": "Justin B. Kinney, Gurinder S. Atwal", "title": "Parametric inference in the large data limit using maximally informative\n  models", "comments": "To appear in Neural Computation", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM math.ST q-bio.MN q-bio.NC stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by data-rich experiments in transcriptional regulation and sensory\nneuroscience, we consider the following general problem in statistical\ninference. When exposed to a high-dimensional signal S, a system of interest\ncomputes a representation R of that signal which is then observed through a\nnoisy measurement M. From a large number of signals and measurements, we wish\nto infer the \"filter\" that maps S to R. However, the standard method for\nsolving such problems, likelihood-based inference, requires perfect a priori\nknowledge of the \"noise function\" mapping R to M. In practice such noise\nfunctions are usually known only approximately, if at all, and using an\nincorrect noise function will typically bias the inferred filter. Here we show\nthat, in the large data limit, this need for a pre-characterized noise function\ncan be circumvented by searching for filters that instead maximize the mutual\ninformation I[M;R] between observed measurements and predicted representations.\nMoreover, if the correct filter lies within the space of filters being\nexplored, maximizing mutual information becomes equivalent to simultaneously\nmaximizing every dependence measure that satisfies the Data Processing\nInequality. It is important to note that maximizing mutual information will\ntypically leave a small number of directions in parameter space unconstrained.\nWe term these directions \"diffeomorphic modes\" and present an equation that\nallows these modes to be derived systematically. The presence of diffeomorphic\nmodes reflects a fundamental and nontrivial substructure within parameter\nspace, one that is obscured by standard likelihood-based inference.\n", "versions": [{"version": "v1", "created": "Sat, 15 Dec 2012 01:29:33 GMT"}, {"version": "v2", "created": "Tue, 20 Aug 2013 04:03:31 GMT"}, {"version": "v3", "created": "Fri, 25 Oct 2013 17:54:28 GMT"}, {"version": "v4", "created": "Fri, 13 Dec 2013 14:53:44 GMT"}], "update_date": "2013-12-16", "authors_parsed": [["Kinney", "Justin B.", ""], ["Atwal", "Gurinder S.", ""]]}, {"id": "1212.3709", "submitter": "Mikhail Zhitlukhin", "authors": "A. N. Shiryaev, M. V. Zhitlukhin", "title": "Optimal stopping problems for a Brownian motion with a disorder on a\n  finite interval", "comments": "10 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider optimal stopping problems for a Brownian motion and a geometric\nBrownian motion with a \"disorder\", assuming that the moment of a disorder is\nuniformly distributed on a finite interval. Optimal stopping rules are found as\nthe first hitting times of some Markov process (the Shiryaev-Roberts statistic)\nto time-dependent boundaries, which are characterized by certain Volterra\nintegral equations. The problems considered are related to mathematical finance\nand can be applied in questions of choosing the optimal time to sell an asset\nwith changing trend.\n", "versions": [{"version": "v1", "created": "Sat, 15 Dec 2012 17:47:40 GMT"}], "update_date": "2012-12-18", "authors_parsed": [["Shiryaev", "A. N.", ""], ["Zhitlukhin", "M. V.", ""]]}, {"id": "1212.3721", "submitter": "Juan Carlos Jimenez", "authors": "J.C. Jimenez", "title": "Approximate continuous-discrete filters for the estimation of diffusion\n  processes from partial and noisy observations", "comments": "The new version corrects some typos and provides extra information\n  that might contribute to clarify some aspects. A new assertion in Theorem 1\n  was added, and a new convergence result was included (current Theorem 2).\n  arXiv admin note: substantial text overlap with arXiv:1212.1788", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC math.ST stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, an alternative approximation to the innovation method is\nintroduced for the parameter estimation of diffusion processes from partial and\nnoisy observations. This is based on a convergent approximation to the first\ntwo conditional moments of the innovation process through approximate\ncontinuous-discrete filters of minimum variance. It is shown that, for finite\nsamples, the resulting approximate estimators converge to the exact one when\nthe error of the approximate filters decreases. For an increasing number of\nobservations, the estimators are asymptotically normal distributed and their\nbias decreases when the above mentioned error does it. A simulation study is\nprovided to illustrate the performance of the new estimators. The results show\nthat, with respect to the conventional approximate estimators, the new ones\nsignificantly enhance the parameter estimation of the test equations. The\nproposed estimators are intended for the recurrent practical situation where a\nnonlinear stochastic system should be identified from a reduced number of\npartial and noisy observations distant in time.\n", "versions": [{"version": "v1", "created": "Sat, 15 Dec 2012 20:34:08 GMT"}, {"version": "v2", "created": "Wed, 18 Dec 2013 01:51:36 GMT"}], "update_date": "2013-12-19", "authors_parsed": [["Jimenez", "J. C.", ""]]}, {"id": "1212.3866", "submitter": "Narayana Santhanam", "authors": "Narayana Santhanam and Venkat Anantharam", "title": "Agnostic insurability of model classes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT math.IT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by problems in insurance, our task is to predict finite upper\nbounds on a future draw from an unknown distribution $p$ over the set of\nnatural numbers. We can only use past observations generated independently and\nidentically distributed according to $p$. While $p$ is unknown, it is known to\nbelong to a given collection ${\\cal P}$ of probability distributions on the\nnatural numbers.\n  The support of the distributions $p \\in {\\cal P}$ may be unbounded, and the\nprediction game goes on for \\emph{infinitely} many draws. We are allowed to\nmake observations without predicting upper bounds for some time. But we must,\nwith probability 1, start and then continue to predict upper bounds after a\nfinite time irrespective of which $p \\in {\\cal P}$ governs the data.\n  If it is possible, without knowledge of $p$ and for any prescribed confidence\nhowever close to 1, to come up with a sequence of upper bounds that is never\nviolated over an infinite time window with confidence at least as big as\nprescribed, we say the model class ${\\cal P}$ is \\emph{insurable}.\n  We completely characterize the insurability of any class ${\\cal P}$ of\ndistributions over natural numbers by means of a condition on how the\nneighborhoods of distributions in ${\\cal P}$ should be, one that is both\nnecessary and sufficient.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2012 03:26:17 GMT"}, {"version": "v2", "created": "Wed, 30 Jan 2013 09:36:50 GMT"}, {"version": "v3", "created": "Tue, 30 Apr 2013 21:09:01 GMT"}], "update_date": "2013-05-02", "authors_parsed": [["Santhanam", "Narayana", ""], ["Anantharam", "Venkat", ""]]}, {"id": "1212.3888", "submitter": "Jeremy Sumner", "authors": "Jeremy G. Sumner, Peter D. Jarvis, and Barbara R. Holland", "title": "A tensorial approach to the inversion of group-based phylogenetic models", "comments": "24 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using a tensorial approach, we show how to construct a one-one correspondence\nbetween pattern probabilities and edge parameters for any group-based model.\nThis is a generalisation of the \"Hadamard conjugation\" and is equivalent to\nstandard results that use Fourier analysis. In our derivation we focus on the\nconnections to group representation theory and emphasize that the inversion is\npossible because, under their usual definition, group-based models are defined\nfor abelian groups only. We also argue that our approach is elementary in the\nsense that it can be understood as simple matrix multiplication where matrices\nare rectangular and indexed by ordered-partitions of varying sizes.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2012 05:09:34 GMT"}], "update_date": "2012-12-18", "authors_parsed": [["Sumner", "Jeremy G.", ""], ["Jarvis", "Peter D.", ""], ["Holland", "Barbara R.", ""]]}, {"id": "1212.4093", "submitter": "David Choi", "authors": "David Choi, Patrick J. Wolfe", "title": "Co-clustering separately exchangeable network data", "comments": "Published in at http://dx.doi.org/10.1214/13-AOS1173 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2014, Vol. 42, No. 1, 29-63", "doi": "10.1214/13-AOS1173", "report-no": "IMS-AOS-AOS1173", "categories": "math.ST cs.SI math.CO stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article establishes the performance of stochastic blockmodels in\naddressing the co-clustering problem of partitioning a binary array into\nsubsets, assuming only that the data are generated by a nonparametric process\nsatisfying the condition of separate exchangeability. We provide oracle\ninequalities with rate of convergence $\\mathcal{O}_P(n^{-1/4})$ corresponding\nto profile likelihood maximization and mean-square error minimization, and show\nthat the blockmodel can be interpreted in this setting as an optimal\npiecewise-constant approximation to the generative nonparametric model. We also\nshow for large sample sizes that the detection of co-clusters in such data\nindicates with high probability the existence of co-clusters of equal size and\nasymptotically equivalent connectivity in the underlying generative process.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2012 18:31:53 GMT"}, {"version": "v2", "created": "Tue, 18 Dec 2012 03:33:51 GMT"}, {"version": "v3", "created": "Sun, 26 May 2013 22:20:43 GMT"}, {"version": "v4", "created": "Fri, 20 Sep 2013 11:12:57 GMT"}, {"version": "v5", "created": "Thu, 16 Jan 2014 11:52:25 GMT"}], "update_date": "2014-01-17", "authors_parsed": [["Choi", "David", ""], ["Wolfe", "Patrick J.", ""]]}, {"id": "1212.4239", "submitter": "Yu Hu", "authors": "Yu Hu, James Trousdale, Kre\\v{s}imir Josi\\'c and Eric Shea-Brown", "title": "Local paths to global coherence: cutting networks down to size", "comments": "34 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC math-ph math.DS math.MP math.ST q-bio.QM stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How does connectivity impact network dynamics? We address this question by\nlinking network characteristics on two scales. On the global scale we consider\nthe coherence of overall network dynamics. We show that such \\emph{global\ncoherence} in activity can often be predicted from the \\emph{local structure}\nof the network. To characterize local network structure we use \"motif\ncumulants,\" a measure of the deviation of pathway counts from those expected in\na minimal probabilistic network model.\n  We extend previous results in three ways. First, we give a new combinatorial\nformulation of motif cumulants that relates to the allied concept in\nprobability theory. Second, we show that the link between global network\ndynamics and local network architecture is strongly affected by heterogeneity\nin network connectivity. However, we introduce a network-partitioning method\nthat recovers a tight relationship between architecture and dynamics. Third,\nfor a particular set of models we generalize the underlying theory to treat\ndynamical coherence at arbitrary orders (i.e. triplet correlations, and\nbeyond). We show that at any order only a highly restricted set of motifs\nimpact dynamical correlations.\n", "versions": [{"version": "v1", "created": "Tue, 18 Dec 2012 06:36:34 GMT"}, {"version": "v2", "created": "Sat, 24 Aug 2013 06:00:09 GMT"}, {"version": "v3", "created": "Wed, 11 Dec 2013 23:05:11 GMT"}], "update_date": "2013-12-13", "authors_parsed": [["Hu", "Yu", ""], ["Trousdale", "James", ""], ["Josi\u0107", "Kre\u0161imir", ""], ["Shea-Brown", "Eric", ""]]}, {"id": "1212.4457", "submitter": "Ana Karina Fermin", "authors": "Ana Karina Fermin, Carenne Lude\\~na", "title": "Probability bounds for active learning in the regression problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we consider the problem of choosing an optimal sampling\nscheme for the regression problem simultaneously with that of model selection.\nWe consider a batch type approach and an on-line approach following algorithms\nrecently developed for the classification problem. Our main tools are\nconcentration-type inequalities which allow us to bound the supremum of the\ndeviations of the sampling scheme corrected by an appropriate weight function.\n", "versions": [{"version": "v1", "created": "Tue, 18 Dec 2012 18:54:45 GMT"}, {"version": "v2", "created": "Mon, 29 Jan 2018 18:28:23 GMT"}], "update_date": "2018-01-30", "authors_parsed": [["Fermin", "Ana Karina", ""], ["Lude\u00f1a", "Carenne", ""]]}, {"id": "1212.4899", "submitter": "Pingyi Fan Prof.", "authors": "Pingyi Fan", "title": "New inequalities of Mill's ratio and Its Application to The Inverse\n  Q-function Approximation", "comments": "12 pages, 4 figures; Submitted to IEEE Trans. Information Theory Dec.\n  2012", "journal-ref": "Australian Journal of Mathematical Analysis and Applications,\n  (AJMAA), Vol.10, No. 1 pp. articale-11, 2013", "doi": null, "report-no": null, "categories": "cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the Mill's ratio estimation problem and get two\nnew inequalities. Compared to the well known results obtained by Gordon, they\nbecomes tighter. Furthermore, we also discuss the inverse Q-function\napproximation problem and present some useful results on the inverse solution.\nNumerical results confirm the validness of our theoretical analysis. In\naddition, we also present a conjecture on the bounds of inverse solution on\nQ-function.\n", "versions": [{"version": "v1", "created": "Thu, 20 Dec 2012 01:14:35 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Fan", "Pingyi", ""]]}, {"id": "1212.4906", "submitter": "James Dowty", "authors": "James G. Dowty", "title": "SMML estimators for 1-dimensional continuous data", "comments": "10 pages, 2 tables and 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A method is given for calculating the strict minimum message length (SMML)\nestimator for 1-dimensional exponential families with continuous sufficient\nstatistics. A set of $n$ equations are found that the $n$ cut-points of the\nSMML estimator must satisfy. These equations can be solved using Newton's\nmethod and this approach is used to produce new results and to replicate\nresults that C. S. Wallace obtained using his boundary rules for the SMML\nestimator. A rigorous proof is also given that, despite being composed of step\nfunctions, the posterior probability corresponding to the SMML estimator is a\ncontinuous function of the data.\n", "versions": [{"version": "v1", "created": "Thu, 20 Dec 2012 01:54:03 GMT"}], "update_date": "2012-12-21", "authors_parsed": [["Dowty", "James G.", ""]]}, {"id": "1212.4911", "submitter": "Teppei Ogihara", "authors": "Teppei Ogihara and Nakahiro Yoshida", "title": "Quasi-Likelihood Analysis for Stochastic Regression Models with\n  Nonsynchronous Observations", "comments": "46 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider nonsynchronous sampling of parameterized stochastic regression\nmodels, which contain stochastic differential equations. Constructing a\nquasi-likelihood function, we prove that the quasi-maximum likelihood estimator\nand the Bayes type estimator are consistent and asymptotically mixed normal\nwhen the sampling frequency of the nonsynchronous data becomes large.\n", "versions": [{"version": "v1", "created": "Thu, 20 Dec 2012 03:02:02 GMT"}], "update_date": "2012-12-21", "authors_parsed": [["Ogihara", "Teppei", ""], ["Yoshida", "Nakahiro", ""]]}, {"id": "1212.4942", "submitter": "Yoshikazu Terada", "authors": "Yoshikazu Terada", "title": "Strong Consistency of Reduced K-means Clustering", "comments": "A revised version of this was accepted in Scandinavian Journal of\n  Statistics. Please refer to the accepted ver", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reduced k-means clustering is a method for clustering objects in a\nlow-dimensional subspace. The advantage of this method is that both clustering\nof objects and low-dimensional subspace reflecting the cluster structure are\nsimultaneously obtained. In this paper, the relationship between conventional\nk-means clustering and reduced k-means clustering is discussed. Conditions\nensuring almost sure convergence of the estimator of reduced k-means clustering\nas unboundedly increasing sample size have been presented. The results for a\nmore general model considering conventional k-means clustering and reduced\nk-means clustering are provided in this paper. Moreover, a new criterion and\nits consistent estimator are proposed to determine the optimal dimension number\nof a subspace, given the number of clusters.\n", "versions": [{"version": "v1", "created": "Thu, 20 Dec 2012 07:46:35 GMT"}, {"version": "v2", "created": "Sun, 6 Jan 2013 17:51:48 GMT"}, {"version": "v3", "created": "Tue, 5 Feb 2013 14:20:15 GMT"}, {"version": "v4", "created": "Thu, 13 Feb 2014 13:44:50 GMT"}], "update_date": "2014-02-14", "authors_parsed": [["Terada", "Yoshikazu", ""]]}, {"id": "1212.4966", "submitter": "Vladimir Vovk", "authors": "Vladimir Vovk and Ruodu Wang", "title": "Combining p-values via averaging", "comments": "35 pages, 3 tables, 3 figures; the main changes: correcting minor\n  mistakes and improving the presentation", "journal-ref": null, "doi": null, "report-no": "21", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes general methods for the problem of multiple testing of a\nsingle hypothesis, with a standard goal of combining a number of p-values\nwithout making any assumptions about their dependence structure. An old result\nby R\\\"uschendorf and, independently, Meng implies that the p-values can be\ncombined by scaling up their arithmetic mean by a factor of 2 (and no smaller\nfactor is sufficient in general). A similar result about the geometric mean\n(Mattner) replaces 2 by $e$. Based on more recent developments in mathematical\nfinance, specifically, robust risk aggregation techniques, we extend these\nresults to generalized means; in particular, we show that $K$ p-values can be\ncombined by scaling up their harmonic mean by a factor of $\\ln K$\n(asymptotically as $K\\to\\infty$). This leads to a generalized version of the\nBonferroni-Holm procedure. We also explore methods using weighted averages of\np-values. Finally, we discuss the efficiency of various methods of combining\np-values and how to choose a suitable method in light of data and prior\ninformation.\n", "versions": [{"version": "v1", "created": "Thu, 20 Dec 2012 10:30:22 GMT"}, {"version": "v2", "created": "Sat, 22 Dec 2012 08:51:57 GMT"}, {"version": "v3", "created": "Mon, 27 Nov 2017 13:13:12 GMT"}, {"version": "v4", "created": "Sat, 21 Apr 2018 06:44:03 GMT"}, {"version": "v5", "created": "Tue, 8 Oct 2019 17:40:09 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Vovk", "Vladimir", ""], ["Wang", "Ruodu", ""]]}, {"id": "1212.5156", "submitter": "Christopher R. Genovese", "authors": "Christopher R. Genovese, Marco Perone-Pacifico, Isabella Verdinelli,\n  Larry Wasserman", "title": "Nonparametric ridge estimation", "comments": "Published in at http://dx.doi.org/10.1214/14-AOS1218 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics, Vol. 42, No. 4, 1511-1545 (2014)", "doi": "10.1214/14-AOS1218", "report-no": "IMS-AOS-AOS1218", "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of estimating the ridges of a density function. Ridge\nestimation is an extension of mode finding and is useful for understanding the\nstructure of a density. It can also be used to find hidden structure in point\ncloud data. We show that, under mild regularity conditions, the ridges of the\nkernel density estimator consistently estimate the ridges of the true density.\nWhen the data are noisy measurements of a manifold, we show that the ridges are\nclose and topologically similar to the hidden manifold. To find the estimated\nridges in practice, we adapt the modified mean-shift algorithm proposed by\nOzertem and Erdogmus [J. Mach. Learn. Res. 12 (2011) 1249-1286]. Some numerical\nexperiments verify that the algorithm is accurate.\n", "versions": [{"version": "v1", "created": "Thu, 20 Dec 2012 17:41:23 GMT"}, {"version": "v2", "created": "Thu, 21 Aug 2014 12:10:31 GMT"}, {"version": "v3", "created": "Thu, 28 Aug 2014 08:28:48 GMT"}], "update_date": "2014-08-29", "authors_parsed": [["Genovese", "Christopher R.", ""], ["Perone-Pacifico", "Marco", ""], ["Verdinelli", "Isabella", ""], ["Wasserman", "Larry", ""]]}, {"id": "1212.5203", "submitter": "Michael Larsen", "authors": "Michael D. Larsen", "title": "An Experiment with Hierarchical Bayesian Record Linkage", "comments": "14 pages, 0 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.AP stat.CO stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In record linkage (RL), or exact file matching, the goal is to identify the\nlinks between entities with information on two or more files. RL is an\nimportant activity in areas including counting the population, enhancing survey\nframes and data, and conducting epidemiological and follow-up studies. RL is\nchallenging when files are very large, no accurate personal identification (ID)\nnumber is present on all files for all units, and some information is recorded\nwith error. Without an unique ID number one must rely on comparisons of names,\naddresses, dates, and other information to find the links. Latent class models\ncan be used to automatically score the value of information for determining\nmatch status. Data for fitting models come from comparisons made within groups\nof units that pass initial file blocking requirements. Data distributions can\nvary across blocks. This article examines the use of prior information and\nhierarchical latent class models in the context of RL.\n", "versions": [{"version": "v1", "created": "Thu, 20 Dec 2012 19:37:25 GMT"}], "update_date": "2012-12-21", "authors_parsed": [["Larsen", "Michael D.", ""]]}, {"id": "1212.5311", "submitter": "Jeremy Sumner", "authors": "Jeremy G. Sumner", "title": "Lie geometry of 2x2 Markov matrices", "comments": "5 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST q-bio.PE stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent work discussing model choice for continuous-time Markov chains, we\nhave argued that it is important that the Markov matrices that define the model\nare closed under matrix multiplication (Sumner 2012a, 2012b). The primary\nrequirement is then that the associated set of rate matrices form a Lie\nalgebra. For the generic case, this connection to Lie theory seems to have\nfirst been made by Johnson (1985), with applications for specific models given\nin Bashford (2004) and House (2012). Here we take a different perspective:\ngiven a model that forms a Lie algebra, we apply existing Lie theory to gain\nadditional insight into the geometry of the associated Markov matrices. In this\nshort note, we present the simplest case possible of 2x2 Markov matrices. The\nmain result is a novel decomposition of 2x2 Markov matrices that parameterises\nthe general Markov model as a perturbation away from the binary-symmetric\nmodel. This alternative parameterisation provides a useful tool for visualising\nthe binary-symmetric model as a submodel of the general Markov model.\n", "versions": [{"version": "v1", "created": "Fri, 21 Dec 2012 01:34:07 GMT"}], "update_date": "2012-12-27", "authors_parsed": [["Sumner", "Jeremy G.", ""]]}, {"id": "1212.5321", "submitter": "Florentina Bunea", "authors": "Florentina Bunea, Luo Xiao", "title": "On the sample covariance matrix estimator of reduced effective rank\n  population matrices, with applications to fPCA", "comments": "Published at http://dx.doi.org/10.3150/14-BEJ602 in the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2015, Vol. 21, No. 2, 1200-1230", "doi": "10.3150/14-BEJ602", "report-no": "IMS-BEJ-BEJ602", "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work provides a unified analysis of the properties of the sample\ncovariance matrix $\\Sigma_n$ over the class of $p\\times p$ population\ncovariance matrices $\\Sigma$ of reduced effective rank $r_e(\\Sigma)$. This\nclass includes scaled factor models and covariance matrices with decaying\nspectrum. We consider $r_e(\\Sigma)$ as a measure of matrix complexity, and\nobtain sharp minimax rates on the operator and Frobenius norm of\n$\\Sigma_n-\\Sigma$, as a function of $r_e(\\Sigma)$ and $\\|\\Sigma\\|_2$, the\noperator norm of $\\Sigma$. With guidelines offered by the optimal rates, we\ndefine classes of matrices of reduced effective rank over which $\\Sigma_n$ is\nan accurate estimator. Within the framework of these classes, we perform a\ndetailed finite sample theoretical analysis of the merits and limitations of\nthe empirical scree plot procedure routinely used in PCA. We show that\nidentifying jumps in the empirical spectrum that consistently estimate jumps in\nthe spectrum of $\\Sigma$ is not necessarily informative for other goals, for\ninstance for the selection of those sample eigenvalues and eigenvectors that\nare consistent estimates of their population counterparts. The scree plot\nmethod can still be used for selecting consistent eigenvalues, for appropriate\nthreshold levels. We provide a threshold construction and also give a rule for\nchecking the consistency of the corresponding sample eigenvectors. We\nspecialize these results and analysis to population covariance matrices with\npolynomially decaying spectra, and extend it to covariance operators with\npolynomially decaying spectra. An application to fPCA illustrates how our\nresults can be used in functional data analysis.\n", "versions": [{"version": "v1", "created": "Fri, 21 Dec 2012 03:13:35 GMT"}, {"version": "v2", "created": "Mon, 15 Jul 2013 19:19:01 GMT"}, {"version": "v3", "created": "Tue, 14 Jan 2014 01:36:51 GMT"}, {"version": "v4", "created": "Mon, 1 Jun 2015 13:01:33 GMT"}], "update_date": "2015-06-02", "authors_parsed": [["Bunea", "Florentina", ""], ["Xiao", "Luo", ""]]}, {"id": "1212.5332", "submitter": "Yingying Fan", "authors": "Yingying Fan, Jiashun Jin, Zhigang Yao", "title": "Optimal classification in sparse Gaussian graphic model", "comments": "Published in at http://dx.doi.org/10.1214/13-AOS1163 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2013, Vol. 41, No. 5, 2537-2571", "doi": "10.1214/13-AOS1163", "report-no": "IMS-AOS-AOS1163", "categories": "stat.ML math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a two-class classification problem where the number of features is\nmuch larger than the sample size. The features are masked by Gaussian noise\nwith mean zero and covariance matrix $\\Sigma$, where the precision matrix\n$\\Omega=\\Sigma^{-1}$ is unknown but is presumably sparse. The useful features,\nalso unknown, are sparse and each contributes weakly (i.e., rare and weak) to\nthe classification decision. By obtaining a reasonably good estimate of\n$\\Omega$, we formulate the setting as a linear regression model. We propose a\ntwo-stage classification method where we first select features by the method of\nInnovated Thresholding (IT), and then use the retained features and Fisher's\nLDA for classification. In this approach, a crucial problem is how to set the\nthreshold of IT. We approach this problem by adapting the recent innovation of\nHigher Criticism Thresholding (HCT). We find that when useful features are rare\nand weak, the limiting behavior of HCT is essentially just as good as the\nlimiting behavior of ideal threshold, the threshold one would choose if the\nunderlying distribution of the signals is known (if only). Somewhat\nsurprisingly, when $\\Omega$ is sufficiently sparse, its off-diagonal\ncoordinates usually do not have a major influence over the classification\ndecision. Compared to recent work in the case where $\\Omega$ is the identity\nmatrix [Proc. Natl. Acad. Sci. USA 105 (2008) 14790-14795; Philos. Trans. R.\nSoc. Lond. Ser. A Math. Phys. Eng. Sci. 367 (2009) 4449-4470], the current\nsetting is much more general, which needs a new approach and much more\nsophisticated analysis. One key component of the analysis is the intimate\nrelationship between HCT and Fisher's separation. Another key component is the\ntight large-deviation bounds for empirical processes for data with\nunconventional correlation structures, where graph theory on vertex coloring\nplays an important role.\n", "versions": [{"version": "v1", "created": "Fri, 21 Dec 2012 04:25:12 GMT"}, {"version": "v2", "created": "Wed, 20 Nov 2013 09:33:09 GMT"}], "update_date": "2013-11-21", "authors_parsed": [["Fan", "Yingying", ""], ["Jin", "Jiashun", ""], ["Yao", "Zhigang", ""]]}, {"id": "1212.5397", "submitter": "Ayokunle Osuntuyi Mr", "authors": "Monica Billio, Roberto Casarin, Anthony Osuntuyi", "title": "Efficient Gibbs Sampling for Markov Switching GARCH Models", "comments": "38 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop efficient simulation techniques for Bayesian inference on\nswitching GARCH models. Our contribution to existing literature is manifold.\nFirst, we discuss different multi-move sampling techniques for Markov Switching\n(MS) state space models with particular attention to MS-GARCH models. Our\nmulti-move sampling strategy is based on the Forward Filtering Backward\nSampling (FFBS) applied to an approximation of MS-GARCH. Another important\ncontribution is the use of multi-point samplers, such as the Multiple-Try\nMetropolis (MTM) and the Multiple trial Metropolize Independent Sampler, in\ncombination with FFBS for the MS-GARCH process. In this sense we ex- tend to\nthe MS state space models the work of So [2006] on efficient MTM sampler for\ncontinuous state space models. Finally, we suggest to further improve the\nsampler efficiency by introducing the antithetic sampling of Craiu and Meng\n[2005] and Craiu and Lemieux [2007] within the FFBS. Our simulation experiments\non MS-GARCH model show that our multi-point and multi-move strategies allow the\nsampler to gain efficiency when compared with single-move Gibbs sampling.\n", "versions": [{"version": "v1", "created": "Fri, 21 Dec 2012 11:13:48 GMT"}], "update_date": "2012-12-24", "authors_parsed": [["Billio", "Monica", ""], ["Casarin", "Roberto", ""], ["Osuntuyi", "Anthony", ""]]}, {"id": "1212.5429", "submitter": "Sebastien Gadat", "authors": "Dominique Bontemps (IMT), S\\'ebastien Gadat (IMT)", "title": "Bayesian posterior consistency in the functional randomly shifted curves\n  model", "comments": "arXiv admin note: substantial text overlap with arXiv:1302.2043,\n  arXiv:1302.2044", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the so-called Shape Invariant Model which stands\nfor the estimation of a function $f^0$ submitted to a random translation of law\n$g^0$ in a white noise model. We are interested in such a model when the law of\nthe deformations is unknown. We aim to recover the law of the process\n$\\PP_{f^0,g^0}$ as well as $f^0$ and $g^0$. In this perspective, we adopt a\nBayesian point of view and find prior on $f$ and $g$ such that the posterior\ndistribution concentrates around $\\PP_{f^0,g^0}$ at a polynomial rate when $n$\ngoes to $+\\infty$. We obtain a logarithmic posterior contraction rate for the\nshape $f^0$ and the distribution $g^0$. We also derive logarithmic lower bounds\nfor the estimation of $f^0$ and $g^0$ in a frequentist paradigm.\n", "versions": [{"version": "v1", "created": "Fri, 21 Dec 2012 13:40:36 GMT"}, {"version": "v2", "created": "Tue, 12 Mar 2013 21:17:15 GMT"}], "update_date": "2013-03-14", "authors_parsed": [["Bontemps", "Dominique", "", "IMT"], ["Gadat", "S\u00e9bastien", "", "IMT"]]}, {"id": "1212.5490", "submitter": "Mark Podolskij", "authors": "Jean Jacod and Mark Podolskij", "title": "A test for the rank of the volatility process: the random perturbation\n  approach", "comments": "30 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a test for the maximal rank of the matrix-valued\nvolatility process in the continuous Ito semimartingale framework. Our idea is\nbased upon a random perturbation of the original high frequency observations of\nan Ito semimartingale, which opens the way for rank testing. We develop the\ncomplete limit theory for the test statistic and apply it to various null and\nalternative hypotheses. Finally, we demonstrate a homoscedasticity test for the\nrank process.\n", "versions": [{"version": "v1", "created": "Fri, 21 Dec 2012 15:33:07 GMT"}], "update_date": "2012-12-24", "authors_parsed": [["Jacod", "Jean", ""], ["Podolskij", "Mark", ""]]}, {"id": "1212.5627", "submitter": "Paul Schrimpf", "authors": "Arun Chandrasekhar, Victor Chernozhukov, Francesca Molinari, Paul\n  Schrimpf", "title": "Inference for best linear approximations to set identified functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides inference methods for best linear approximations to\nfunctions which are known to lie within a band. It extends the partial\nidentification literature by allowing the upper and lower functions defining\nthe band to be any functions, including ones carrying an index, which can be\nestimated parametrically or non-parametrically. The identification region of\nthe parameters of the best linear approximation is characterized via its\nsupport function, and limit theory is developed for the latter. We prove that\nthe support function approximately converges to a Gaussian process and\nestablish validity of the Bayesian bootstrap. The paper nests as special cases\nthe canonical examples in the literature: mean regression with interval valued\noutcome data and interval valued regressor data. Because the bounds may carry\nan index, the paper covers problems beyond mean regression; the framework is\nextremely versatile. Applications include quantile and distribution regression\nwith interval valued data, sample selection problems, as well as mean,\nquantile, and distribution treatment effects. Moreover, the framework can\naccount for the availability of instruments. An application is carried out,\nstudying female labor force participation along the lines of Mulligan and\nRubinstein (2008).\n", "versions": [{"version": "v1", "created": "Fri, 21 Dec 2012 22:56:22 GMT"}], "update_date": "2012-12-27", "authors_parsed": [["Chandrasekhar", "Arun", ""], ["Chernozhukov", "Victor", ""], ["Molinari", "Francesca", ""], ["Schrimpf", "Paul", ""]]}, {"id": "1212.5715", "submitter": "Nakahiro Yoshida", "authors": "Masayuki Uchida and Nakahiro Yoshida", "title": "Nondegeneracy of Random Field and Estimation of Diffusion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We construct a quasi likelihood analysis for diffusions under the\nhigh-frequency sampling over a finite time interval. For this, we prove a\npolynomial type large deviation inequality for the quasi likelihood random\nfield. Then it becomes crucial to prove nondegeneracy of a key index chi_0. By\nnature of the sampling setting, chi_0 is random. This makes it difficult to\napply a naive sufficient condition, and requires a new machinery. In order to\nestablish a quasi likelihood analysis, we need quantitative estimate of the\nnondegeneracy of chi_0. The existence of a nondegenerate local section of a\ncertain tensor bundle associated with the statistical random field solves this\nproblem.\n", "versions": [{"version": "v1", "created": "Sat, 22 Dec 2012 19:16:45 GMT"}], "update_date": "2012-12-27", "authors_parsed": [["Uchida", "Masayuki", ""], ["Yoshida", "Nakahiro", ""]]}, {"id": "1212.5860", "submitter": "Shenghuo Zhu", "authors": "Shenghuo Zhu", "title": "A short note on the tail bound of Wishart distribution", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the tail bound of the emperical covariance of multivariate normal\ndistribution. Following the work of (Gittens & Tropp, 2011), we provide a tail\nbound with a small constant.\n", "versions": [{"version": "v1", "created": "Mon, 24 Dec 2012 03:31:15 GMT"}], "update_date": "2012-12-27", "authors_parsed": [["Zhu", "Shenghuo", ""]]}, {"id": "1212.6088", "submitter": "Debdeep Pati", "authors": "Anirban Bhattacharya, Debdeep Pati, Natesh S. Pillai, David B. Dunson", "title": "Bayesian shrinkage", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Penalized regression methods, such as $L_1$ regularization, are routinely\nused in high-dimensional applications, and there is a rich literature on\noptimality properties under sparsity assumptions. In the Bayesian paradigm,\nsparsity is routinely induced through two-component mixture priors having a\nprobability mass at zero, but such priors encounter daunting computational\nproblems in high dimensions. This has motivated an amazing variety of\ncontinuous shrinkage priors, which can be expressed as global-local scale\nmixtures of Gaussians, facilitating computation. In sharp contrast to the\ncorresponding frequentist literature, very little is known about the properties\nof such priors. Focusing on a broad class of shrinkage priors, we provide\nprecise results on prior and posterior concentration. Interestingly, we\ndemonstrate that most commonly used shrinkage priors, including the Bayesian\nLasso, are suboptimal in high-dimensional settings. A new class of Dirichlet\nLaplace (DL) priors are proposed, which are optimal and lead to efficient\nposterior computation exploiting results from normalized random measure theory.\nFinite sample performance of Dirichlet Laplace priors relative to alternatives\nis assessed in simulations.\n", "versions": [{"version": "v1", "created": "Tue, 25 Dec 2012 22:02:47 GMT"}], "update_date": "2012-12-27", "authors_parsed": [["Bhattacharya", "Anirban", ""], ["Pati", "Debdeep", ""], ["Pillai", "Natesh S.", ""], ["Dunson", "David B.", ""]]}, {"id": "1212.6232", "submitter": "Wei Lin", "authors": "Wei Lin and Jinchi Lv", "title": "High-Dimensional Sparse Additive Hazards Regression", "comments": "41 pages, 3 figures, to appear in Journal of the American Statistical\n  Association (http://www.tandfonline.com/r/JASA)", "journal-ref": "Journal of the American Statistical Association (2013), 108,\n  247-264", "doi": "10.1080/01621459.2012.746068", "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-dimensional sparse modeling with censored survival data is of great\npractical importance, as exemplified by modern applications in high-throughput\ngenomic data analysis and credit risk analysis. In this article, we propose a\nclass of regularization methods for simultaneous variable selection and\nestimation in the additive hazards model, by combining the nonconcave penalized\nlikelihood approach and the pseudoscore method. In a high-dimensional setting\nwhere the dimensionality can grow fast, polynomially or nonpolynomially, with\nthe sample size, we establish the weak oracle property and oracle property\nunder mild, interpretable conditions, thus providing strong performance\nguarantees for the proposed methodology. Moreover, we show that the regularity\nconditions required by the $L_1$ method are substantially relaxed by a certain\nclass of sparsity-inducing concave penalties. As a result, concave penalties\nsuch as the smoothly clipped absolute deviation (SCAD), minimax concave penalty\n(MCP), and smooth integration of counting and absolute deviation (SICA) can\nsignificantly improve on the $L_1$ method and yield sparser models with better\nprediction performance. We present a coordinate descent algorithm for efficient\nimplementation and rigorously investigate its convergence properties. The\npractical utility and effectiveness of the proposed methods are demonstrated by\nsimulation studies and a real data example.\n", "versions": [{"version": "v1", "created": "Wed, 26 Dec 2012 19:31:41 GMT"}], "update_date": "2014-03-19", "authors_parsed": [["Lin", "Wei", ""], ["Lv", "Jinchi", ""]]}, {"id": "1212.6549", "submitter": "Guillaume Lepage", "authors": "Guillaume Lepage", "title": "Maximum Likelihood Estimation for Conditionally Heteroscedastic Models\n  when the Innovation Process is in the Domain of Attraction of a Stable Law", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove the strong consistency and the asymptotic normality of the maximum\nlikelihood estimator of the parameters of a general conditionally\nheteroscedastic model with $\\alpha$-stable innovations. Then, we relax the\nassumptions and only suppose that the innovation process converges in\ndistribution toward a stable process. Using a pseudo maximum likelihood\nestimator with a stable density, we also obtain the strong consistency and the\nasymptotic normality of the estimator. This framework seems relevant for\nfinancial data exhibiting heavy tails. We apply this method to several\nfinancial index and compute stable Value-at-Risk.\n", "versions": [{"version": "v1", "created": "Fri, 28 Dec 2012 18:29:00 GMT"}], "update_date": "2013-01-01", "authors_parsed": [["Lepage", "Guillaume", ""]]}, {"id": "1212.6757", "submitter": "Denis Chetverikov", "authors": "Denis Chetverikov", "title": "Testing Regression Monotonicity in Econometric Models", "comments": null, "journal-ref": "Econom. Theory 35 (2019) 729-776", "doi": "10.1017/S0266466618000282", "report-no": null, "categories": "math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monotonicity is a key qualitative prediction of a wide array of economic\nmodels derived via robust comparative statics. It is therefore important to\ndesign effective and practical econometric methods for testing this prediction\nin empirical analysis. This paper develops a general nonparametric framework\nfor testing monotonicity of a regression function. Using this framework, a\nbroad class of new tests is introduced, which gives an empirical researcher a\nlot of flexibility to incorporate ex ante information she might have. The paper\nalso develops new methods for simulating critical values, which are based on\nthe combination of a bootstrap procedure and new selection algorithms. These\nmethods yield tests that have correct asymptotic size and are asymptotically\nnonconservative. It is also shown how to obtain an adaptive rate optimal test\nthat has the best attainable rate of uniform consistency against models whose\nregression function has Lipschitz-continuous first-order derivatives and that\nautomatically adapts to the unknown smoothness of the regression function.\nSimulations show that the power of the new tests in many cases significantly\nexceeds that of some prior tests, e.g. that of Ghosal, Sen, and Van der Vaart\n(2000). An application of the developed procedures to the dataset of Ellison\nand Ellison (2011) shows that there is some evidence of strategic entry\ndeterrence in pharmaceutical industry where incumbents may use strategic\ninvestment to prevent generic entries when their patents expire.\n", "versions": [{"version": "v1", "created": "Sun, 30 Dec 2012 17:59:23 GMT"}, {"version": "v2", "created": "Tue, 3 Dec 2013 19:25:17 GMT"}], "update_date": "2019-07-10", "authors_parsed": [["Chetverikov", "Denis", ""]]}, {"id": "1212.6788", "submitter": "Zuofeng Shang", "authors": "Zuofeng Shang, Guang Cheng", "title": "Local and global asymptotic inference in smoothing spline models", "comments": "Published in at http://dx.doi.org/10.1214/13-AOS1164 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2013, Vol. 41, No. 5, 2608-2638", "doi": "10.1214/13-AOS1164", "report-no": "IMS-AOS-AOS1164", "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article studies local and global inference for smoothing spline\nestimation in a unified asymptotic framework. We first introduce a new\ntechnical tool called functional Bahadur representation, which significantly\ngeneralizes the traditional Bahadur representation in parametric models, that\nis, Bahadur [Ann. Inst. Statist. Math. 37 (1966) 577-580]. Equipped with this\ntool, we develop four interconnected procedures for inference: (i) pointwise\nconfidence interval; (ii) local likelihood ratio testing; (iii) simultaneous\nconfidence band; (iv) global likelihood ratio testing. In particular, our\nconfidence intervals are proved to be asymptotically valid at any point in the\nsupport, and they are shorter on average than the Bayesian confidence intervals\nproposed by Wahba [J. R. Stat. Soc. Ser. B Stat. Methodol. 45 (1983) 133-150]\nand Nychka [J. Amer. Statist. Assoc. 83 (1988) 1134-1143]. We also discuss a\nversion of the Wilks phenomenon arising from local/global likelihood ratio\ntesting. It is also worth noting that our simultaneous confidence bands are the\nfirst ones applicable to general quasi-likelihood models. Furthermore, issues\nrelating to optimality and efficiency are carefully addressed. As a by-product,\nwe discover a surprising relationship between periodic and nonperiodic\nsmoothing splines in terms of inference.\n", "versions": [{"version": "v1", "created": "Sun, 30 Dec 2012 22:34:28 GMT"}, {"version": "v2", "created": "Wed, 28 Aug 2013 03:55:58 GMT"}, {"version": "v3", "created": "Tue, 26 Nov 2013 11:56:08 GMT"}], "update_date": "2013-11-27", "authors_parsed": [["Shang", "Zuofeng", ""], ["Cheng", "Guang", ""]]}, {"id": "1212.6885", "submitter": "Kengo Kato", "authors": "Victor Chernozhukov, Denis Chetverikov, Kengo Kato", "title": "Gaussian approximation of suprema of empirical processes", "comments": "This is the full version of the paper published in at\n  http://dx.doi.org/10.1214/14-AOS1230 the Annals of Statistics\n  (http://www.imstat.org/aos/) by the Institute of Mathematical Statistics\n  (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2014, Vol. 42, No. 4, 1564-1597", "doi": "10.1214/14-AOS1230", "report-no": "IMS-AOS-AOS1230", "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper develops a new direct approach to approximating suprema of general\nempirical processes by a sequence of suprema of Gaussian processes, without\ntaking the route of approximating whole empirical processes in the sup-norm. We\nprove an abstract approximation theorem applicable to a wide variety of\nstatistical problems, such as construction of uniform confidence bands for\nfunctions. Notably, the bound in the main approximation theorem is\nnonasymptotic and the theorem allows for functions that index the empirical\nprocess to be unbounded and have entropy divergent with the sample size. The\nproof of the approximation theorem builds on a new coupling inequality for\nmaxima of sums of random vectors, the proof of which depends on an effective\nuse of Stein's method for normal approximation, and some new empirical process\ntechniques. We study applications of this approximation theorem to local and\nseries empirical processes arising in nonparametric estimation via kernel and\nseries methods, where the classes of functions change with the sample size and\nare non-Donsker. Importantly, our new technique is able to prove the Gaussian\napproximation for the supremum type statistics under weak regularity\nconditions, especially concerning the bandwidth and the number of series\nfunctions, in those examples.\n", "versions": [{"version": "v1", "created": "Mon, 31 Dec 2012 13:03:45 GMT"}, {"version": "v2", "created": "Tue, 5 Feb 2013 08:46:36 GMT"}, {"version": "v3", "created": "Fri, 17 May 2013 17:23:25 GMT"}, {"version": "v4", "created": "Wed, 25 Sep 2013 21:43:57 GMT"}, {"version": "v5", "created": "Thu, 14 Aug 2014 07:54:11 GMT"}, {"version": "v6", "created": "Sun, 17 Aug 2014 07:00:57 GMT"}], "update_date": "2014-08-19", "authors_parsed": [["Chernozhukov", "Victor", ""], ["Chetverikov", "Denis", ""], ["Kato", "Kengo", ""]]}, {"id": "1212.6906", "submitter": "Denis Chetverikov", "authors": "Victor Chernozhukov, Denis Chetverikov, Kengo Kato", "title": "Gaussian approximations and multiplier bootstrap for maxima of sums of\n  high-dimensional random vectors", "comments": "A minor typo has been corrected (last line, page 22, where \\max_{j\n  \\in w} was missing)", "journal-ref": "Annals of Statistics 2013, Vol. 41, No. 6, 2786-2819", "doi": "10.1214/13-AOS1161", "report-no": "IMS-AOS-AOS1161", "categories": "math.ST econ.EM math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive a Gaussian approximation result for the maximum of a sum of\nhigh-dimensional random vectors. Specifically, we establish conditions under\nwhich the distribution of the maximum is approximated by that of the maximum of\na sum of the Gaussian random vectors with the same covariance matrices as the\noriginal vectors. This result applies when the dimension of random vectors\n($p$) is large compared to the sample size ($n$); in fact, $p$ can be much\nlarger than $n$, without restricting correlations of the coordinates of these\nvectors. We also show that the distribution of the maximum of a sum of the\nrandom vectors with unknown covariance matrices can be consistently estimated\nby the distribution of the maximum of a sum of the conditional Gaussian random\nvectors obtained by multiplying the original vectors with i.i.d. Gaussian\nmultipliers. This is the Gaussian multiplier (or wild) bootstrap procedure.\nHere too, $p$ can be large or even much larger than $n$. These distributional\napproximations, either Gaussian or conditional Gaussian, yield a high-quality\napproximation to the distribution of the original maximum, often with\napproximation error decreasing polynomially in the sample size, and hence are\nof interest in many applications. We demonstrate how our Gaussian\napproximations and the multiplier bootstrap can be used for modern\nhigh-dimensional estimation, multiple hypothesis testing, and adaptive\nspecification testing. All these results contain nonasymptotic bounds on\napproximation errors.\n", "versions": [{"version": "v1", "created": "Mon, 31 Dec 2012 15:14:12 GMT"}, {"version": "v2", "created": "Mon, 21 Jan 2013 20:35:38 GMT"}, {"version": "v3", "created": "Wed, 23 Jan 2013 21:10:04 GMT"}, {"version": "v4", "created": "Wed, 18 Dec 2013 11:35:50 GMT"}, {"version": "v5", "created": "Mon, 30 Dec 2013 21:09:59 GMT"}, {"version": "v6", "created": "Tue, 23 Jan 2018 00:02:56 GMT"}], "update_date": "2018-01-24", "authors_parsed": [["Chernozhukov", "Victor", ""], ["Chetverikov", "Denis", ""], ["Kato", "Kengo", ""]]}]