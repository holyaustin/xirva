[{"id": "1206.0068", "submitter": "XuanLong Nguyen", "authors": "XuanLong Nguyen", "title": "Posterior contraction of the population polytope in finite admixture\n  models", "comments": "Published at http://dx.doi.org/10.3150/13-BEJ582 in the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2015, Vol. 21, No. 1, 618-646", "doi": "10.3150/13-BEJ582", "report-no": "IMS-BEJ-BEJ582", "categories": "math.ST cs.LG stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the posterior contraction behavior of the latent population\nstructure that arises in admixture models as the amount of data increases. We\nadopt the geometric view of admixture models - alternatively known as topic\nmodels - as a data generating mechanism for points randomly sampled from the\ninterior of a (convex) population polytope, whose extreme points correspond to\nthe population structure variables of interest. Rates of posterior contraction\nare established with respect to Hausdorff metric and a minimum matching\nEuclidean metric defined on polytopes. Tools developed include posterior\nasymptotics of hierarchical models and arguments from convex geometry.\n", "versions": [{"version": "v1", "created": "Fri, 1 Jun 2012 02:26:58 GMT"}, {"version": "v2", "created": "Tue, 4 Dec 2012 20:53:14 GMT"}, {"version": "v3", "created": "Wed, 15 Apr 2015 05:10:35 GMT"}], "update_date": "2015-04-16", "authors_parsed": [["Nguyen", "XuanLong", ""]]}, {"id": "1206.0262", "submitter": "Felix Lucka", "authors": "Felix Lucka (Institute for Computational and Applied Mathematics,\n  Institute for Biomagnetism and Biosignalanalysis, University of M\\\"unster,\n  Germany)", "title": "Fast Markov chain Monte Carlo sampling for sparse Bayesian inference in\n  high-dimensional inverse problems using L1-type priors", "comments": "33 pages, 14 figures", "journal-ref": "Inverse Problems 28 (2012) 125012", "doi": "10.1088/0266-5611/28/12/125012", "report-no": null, "categories": "math.NA math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparsity has become a key concept for solving of high-dimensional inverse\nproblems using variational regularization techniques. Recently, using similar\nsparsity-constraints in the Bayesian framework for inverse problems by encoding\nthem in the prior distribution has attracted attention. Important questions\nabout the relation between regularization theory and Bayesian inference still\nneed to be addressed when using sparsity promoting inversion. A practical\nobstacle for these examinations is the lack of fast posterior sampling\nalgorithms for sparse, high-dimensional Bayesian inversion: Accessing the full\nrange of Bayesian inference methods requires being able to draw samples from\nthe posterior probability distribution in a fast and efficient way. This is\nusually done using Markov chain Monte Carlo (MCMC) sampling algorithms. In this\narticle, we develop and examine a new implementation of a single component\nGibbs MCMC sampler for sparse priors relying on L1-norms. We demonstrate that\nthe efficiency of our Gibbs sampler increases when the level of sparsity or the\ndimension of the unknowns is increased. This property is contrary to the\nproperties of the most commonly applied Metropolis-Hastings (MH) sampling\nschemes: We demonstrate that the efficiency of MH schemes for L1-type priors\ndramatically decreases when the level of sparsity or the dimension of the\nunknowns is increased. Practically, Bayesian inversion for L1-type priors using\nMH samplers is not feasible at all. As this is commonly believed to be an\nintrinsic feature of MCMC sampling, the performance of our Gibbs sampler also\nchallenges common beliefs about the applicability of sample based Bayesian\ninference.\n", "versions": [{"version": "v1", "created": "Fri, 1 Jun 2012 17:49:39 GMT"}, {"version": "v2", "created": "Mon, 24 Sep 2012 13:59:01 GMT"}], "update_date": "2014-11-18", "authors_parsed": [["Lucka", "Felix", "", "Institute for Computational and Applied Mathematics,\n  Institute for Biomagnetism and Biosignalanalysis, University of M\u00fcnster,\n  Germany"]]}, {"id": "1206.0304", "submitter": "Samer Abdallah", "authors": "Samer A. Abdallah and Mark D. Plumbley", "title": "Predictive Information Rate in Discrete-time Gaussian Processes", "comments": "8 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive expressions for the predicitive information rate (PIR) for the\nclass of autoregressive Gaussian processes AR(N), both in terms of the\nprediction coefficients and in terms of the power spectral density. The latter\nresult suggests a duality between the PIR and the multi-information rate for\nprocesses with mutually inverse power spectra (i.e. with poles and zeros of the\ntransfer function exchanged). We investigate the behaviour of the PIR in\nrelation to the multi-information rate for some simple examples, which suggest,\nsomewhat counter-intuitively, that the PIR is maximised for very `smooth' AR\nprocesses whose power spectra have multiple poles at zero frequency. We also\nobtain results for moving average Gaussian processes which are consistent with\nthe duality conjectured earlier. One consequence of this is that the PIR is\nunbounded for MA(N) processes.\n", "versions": [{"version": "v1", "created": "Fri, 1 Jun 2012 20:36:32 GMT"}, {"version": "v2", "created": "Tue, 14 Aug 2012 11:49:30 GMT"}], "update_date": "2012-08-15", "authors_parsed": [["Abdallah", "Samer A.", ""], ["Plumbley", "Mark D.", ""]]}, {"id": "1206.0313", "submitter": "Ryan Tibshirani", "authors": "Ryan J. Tibshirani", "title": "The Lasso Problem and Uniqueness", "comments": "25 pages, 0 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The lasso is a popular tool for sparse linear regression, especially for\nproblems in which the number of variables p exceeds the number of observations\nn. But when p>n, the lasso criterion is not strictly convex, and hence it may\nnot have a unique minimum. An important question is: when is the lasso solution\nwell-defined (unique)? We review results from the literature, which show that\nif the predictor variables are drawn from a continuous probability\ndistribution, then there is a unique lasso solution with probability one,\nregardless of the sizes of n and p. We also show that this result extends\neasily to $\\ell_1$ penalized minimization problems over a wide range of loss\nfunctions.\n  A second important question is: how can we deal with the case of\nnon-uniqueness in lasso solutions? In light of the aforementioned result, this\ncase really only arises when some of the predictor variables are discrete, or\nwhen some post-processing has been performed on continuous predictor\nmeasurements. Though we certainly cannot claim to provide a complete answer to\nsuch a broad question, we do present progress towards understanding some\naspects of non-uniqueness. First, we extend the LARS algorithm for computing\nthe lasso solution path to cover the non-unique case, so that this path\nalgorithm works for any predictor matrix. Next, we derive a simple method for\ncomputing the component-wise uncertainty in lasso solutions of any given\nproblem instance, based on linear programming. Finally, we review results from\nthe literature on some of the unifying properties of lasso solutions, and also\npoint out particular forms of solutions that have distinctive properties.\n", "versions": [{"version": "v1", "created": "Fri, 1 Jun 2012 21:34:10 GMT"}, {"version": "v2", "created": "Sun, 4 Nov 2012 20:16:58 GMT"}], "update_date": "2012-11-06", "authors_parsed": [["Tibshirani", "Ryan J.", ""]]}, {"id": "1206.0399", "submitter": "Ferkan Yilmaz", "authors": "Ferkan Yilmaz and Hina Tabassum and Mohamed-Slim Alouini", "title": "On the Computation of the Higher-Order Statistics of the Channel\n  Capacity for Amplify-and-Forward Multihop Transmission", "comments": "Two Figures, one table, ad submitted to a possible publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Higher-order statistics (HOS) of the channel capacity provide useful\ninformation regarding the level of reliability of the signal transmission at a\nparticular rate. We propose in this letter a novel and unified analysis, which\nis based on the moment-generating function (MGF) approach, to efficiently and\naccurately compute the HOS of the channel capacity for amplify-and-forward\nmultihop transmission over generalized fading channels. More precisely, our\nmathematical formulism is easy-to-use and tractable specifically requiring only\nthe reciprocal MGFs of the instantaneous signal-to-noise ratio distributions of\nthe transmission hops. Numerical and simulation results, performed to exemplify\nthe usefulness of the proposed MGF-based analysis, are shown to be in perfect\nagreement.\n", "versions": [{"version": "v1", "created": "Sat, 2 Jun 2012 19:27:23 GMT"}, {"version": "v2", "created": "Mon, 20 Aug 2012 12:55:22 GMT"}], "update_date": "2012-08-21", "authors_parsed": [["Yilmaz", "Ferkan", ""], ["Tabassum", "Hina", ""], ["Alouini", "Mohamed-Slim", ""]]}, {"id": "1206.0406", "submitter": "Ruriko Yoshida", "authors": "Jing Xi and Ruriko Yoshida", "title": "The characteristic imset polytope of Bayesian networks with ordered\n  nodes", "comments": "23 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In 2010, M. Studen\\'y, R. Hemmecke, and S. Linder explored a new algebraic\ndescription of graphical models, called characteristic imsets. Compare with\nstandard imsets, characteristic imsets have several advantages: they are still\nunique vector representative of conditional independence structures, they are\n0-1 vectors, and they are more intuitive in terms of graphs than standard\nimsets. After defining a characteristic imset polytope (cim-polytope) as the\nconvex hull of all characteristic imsets with a given set of nodes, they also\nshowed that a model selection in graphical models, which maximizes a quality\ncriterion, can be converted into a linear programming problem over the\ncim-polytope. However, in general, for a fixed set of nodes, the cim-polytope\ncan have exponentially many vertices over an exponentially high dimension.\nTherefore, in this paper, we focus on the family of directed acyclic graphs\n(DAGs) whose nodes have a fixed order. This family includes diagnosis models\nwhich can be described by Bipartite graphs with a set of $m$ nodes and a set of\n$n$ nodes for any $m, n \\in \\Z_+$. In this paper, we first consider\ncim-polytopes for all diagnosis models and show that these polytopes are direct\nproducts of simplices. Then we give a combinatorial description of all edges\nand all facets of these polytopes. Finally, we generalize these results to the\ncim-polytopes for all Bayesian networks with a fixed underlying ordering of\nnodes with or without fixed (or forbidden) edges.\n", "versions": [{"version": "v1", "created": "Sat, 2 Jun 2012 21:49:49 GMT"}, {"version": "v2", "created": "Fri, 3 Aug 2012 09:09:41 GMT"}, {"version": "v3", "created": "Mon, 19 Aug 2013 19:59:22 GMT"}], "update_date": "2013-08-20", "authors_parsed": [["Xi", "Jing", ""], ["Yoshida", "Ruriko", ""]]}, {"id": "1206.0457", "submitter": "Richard Samworth", "authors": "Richard J. Samworth and Ming Yuan", "title": "Independent component analysis via nonparametric maximum likelihood\n  estimation", "comments": "28 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Independent Component Analysis (ICA) models are very popular semiparametric\nmodels in which we observe independent copies of a random vector $X = AS$,\nwhere $A$ is a non-singular matrix and $S$ has independent components. We\npropose a new way of estimating the unmixing matrix $W = A^{-1}$ and the\nmarginal distributions of the components of $S$ using nonparametric maximum\nlikelihood. Specifically, we study the projection of the empirical distribution\nonto the subset of ICA distributions having log-concave marginals. We show\nthat, from the point of view of estimating the unmixing matrix, it makes no\ndifference whether or not the log-concavity is correctly specified. The\napproach is further justified by both theoretical results and a simulation\nstudy.\n", "versions": [{"version": "v1", "created": "Sun, 3 Jun 2012 15:38:03 GMT"}], "update_date": "2012-06-05", "authors_parsed": [["Samworth", "Richard J.", ""], ["Yuan", "Ming", ""]]}, {"id": "1206.0459", "submitter": "Dominique Picard B", "authors": "Ismael Castillo, Gerard Kerkyacharian and Dominique Picard", "title": "Thomas Bayes' walk on manifolds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convergence of the Bayes posterior measure is considered in canonical\nstatistical settings where observations sit on a geometrical object such as a\ncompact manifold, or more generally on a compact metric space verifying some\nconditions. A natural geometric prior based on randomly rescaled solutions of\nthe heat equation is considered. Upper and lower bound posterior contraction\nrates are derived.\n", "versions": [{"version": "v1", "created": "Sun, 3 Jun 2012 16:25:37 GMT"}], "update_date": "2012-06-05", "authors_parsed": [["Castillo", "Ismael", ""], ["Kerkyacharian", "Gerard", ""], ["Picard", "Dominique", ""]]}, {"id": "1206.0576", "submitter": "Alessandro Baldi Antognini", "authors": "Alessandro Baldi Antognini, Maroussa Zagoraiou", "title": "Multi-objective optimal designs in comparative clinical trials with\n  covariates: The reinforced doubly adaptive biased coin design", "comments": "Published in at http://dx.doi.org/10.1214/12-AOS1007 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2012, Vol. 40, No. 3, 1315-1345", "doi": "10.1214/12-AOS1007", "report-no": "IMS-AOS-AOS1007", "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The present paper deals with the problem of allocating patients to two\ncompeting treatments in the presence of covariates or prognostic factors in\norder to achieve a good trade-off among ethical concerns, inferential precision\nand randomness in the treatment allocations. In particular we suggest a\nmultipurpose design methodology that combines efficiency and ethical gain when\nthe linear homoscedastic model with both treatment/covariate interactions and\ninteractions among covariates is adopted. The ensuing compound optimal\nallocations of the treatments depend on the covariates and their distribution\non the population of interest, as well as on the unknown parameters of the\nmodel. Therefore, we introduce the reinforced doubly adaptive biased coin\ndesign, namely a general class of covariate-adjusted response-adaptive\nprocedures that includes both continuous and discontinuous randomization\nfunctions, aimed to target any desired allocation proportion. The properties of\nthis proposal are described both theoretically and through simulations.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jun 2012 10:38:11 GMT"}, {"version": "v2", "created": "Thu, 16 Aug 2012 11:02:41 GMT"}], "update_date": "2012-08-17", "authors_parsed": [["Antognini", "Alessandro Baldi", ""], ["Zagoraiou", "Maroussa", ""]]}, {"id": "1206.0613", "submitter": "Clifford Lam", "authors": "Clifford Lam, Qiwei Yao", "title": "Factor modeling for high-dimensional time series: Inference for the\n  number of factors", "comments": "Published in at http://dx.doi.org/10.1214/12-AOS970 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2012, Vol. 40, No. 2, 694-726", "doi": "10.1214/12-AOS970", "report-no": "IMS-AOS-AOS970", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with the factor modeling for high-dimensional time series\nbased on a dimension-reduction viewpoint. Under stationary settings, the\ninference is simple in the sense that both the number of factors and the factor\nloadings are estimated in terms of an eigenanalysis for a nonnegative definite\nmatrix, and is therefore applicable when the dimension of time series is on the\norder of a few thousands. Asymptotic properties of the proposed method are\ninvestigated under two settings: (i) the sample size goes to infinity while the\ndimension of time series is fixed; and (ii) both the sample size and the\ndimension of time series go to infinity together. In particular, our estimators\nfor zero-eigenvalues enjoy faster convergence (or slower divergence) rates,\nhence making the estimation for the number of factors easier. In particular,\nwhen the sample size and the dimension of time series go to infinity together,\nthe estimators for the eigenvalues are no longer consistent. However, our\nestimator for the number of the factors, which is based on the ratios of the\nestimated eigenvalues, still works fine. Furthermore, this estimation shows the\nso-called \"blessing of dimensionality\" property in the sense that the\nperformance of the estimation may improve when the dimension of time series\nincreases. A two-step procedure is investigated when the factors are of\ndifferent degrees of strength. Numerical illustration with both simulated and\nreal data is also reported.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jun 2012 13:37:12 GMT"}], "update_date": "2012-06-05", "authors_parsed": [["Lam", "Clifford", ""], ["Yao", "Qiwei", ""]]}, {"id": "1206.0648", "submitter": "Rui M. Castro", "authors": "Rui M. Castro", "title": "Adaptive sensing performance lower bounds for sparse signal detection\n  and support estimation", "comments": "Published in at http://dx.doi.org/10.3150/13-BEJ555 the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2014, Vol. 20, No. 4, 2217-2246", "doi": "10.3150/13-BEJ555", "report-no": "IMS-BEJ-BEJ555", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper gives a precise characterization of the fundamental limits of\nadaptive sensing for diverse estimation and testing problems concerning sparse\nsignals. We consider in particular the setting introduced in (IEEE Trans.\nInform. Theory 57 (2011) 6222-6235) and show necessary conditions on the\nminimum signal magnitude for both detection and estimation: if ${\\mathbf\n{x}}\\in \\mathbb{R}^n$ is a sparse vector with $s$ non-zero components then it\ncan be reliably detected in noise provided the magnitude of the non-zero\ncomponents exceeds $\\sqrt{2/s}$. Furthermore, the signal support can be exactly\nidentified provided the minimum magnitude exceeds $\\sqrt{2\\log s}$. Notably\nthere is no dependence on $n$, the extrinsic signal dimension. These results\nshow that the adaptive sensing methodologies proposed previously in the\nliterature are essentially optimal, and cannot be substantially improved. In\naddition, these results provide further insights on the limits of adaptive\ncompressive sensing.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jun 2012 15:27:43 GMT"}, {"version": "v2", "created": "Wed, 19 Sep 2012 12:40:15 GMT"}, {"version": "v3", "created": "Tue, 19 Mar 2013 12:14:04 GMT"}, {"version": "v4", "created": "Wed, 15 Oct 2014 11:06:21 GMT"}], "update_date": "2014-10-16", "authors_parsed": [["Castro", "Rui M.", ""]]}, {"id": "1206.0677", "submitter": "Xiaojun Zhou", "authors": "Xiaojun Zhou, Chunhua Yang, Weihua Gui", "title": "Nonlinear system identification and control using state transition\n  algorithm", "comments": "20 pages, 18 figures", "journal-ref": "Applied Mathematics and Computation 226:169--179, 2014", "doi": "10.1016/j.amc.2013.09.055", "report-no": null, "categories": "math.OC math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By transforming identification and control for nonlinear system into\noptimization problems, a novel optimization method named state transition\nalgorithm (STA) is introduced to solve the problems. In the proposed STA, a\nsolution to a optimization problem is considered as a state, and the updating\nof a solution equates to a state transition, which makes it easy to understand\nand convenient to implement. First, the STA is applied to identify the optimal\nparameters of the estimated system with previously known structure. With the\naccurate estimated model, an off-line PID controller is then designed optimally\nby using the STA as well. Experimental results have demonstrated the validity\nof the methodology, and comparisons to STA with other optimization algorithms\nhave testified that STA is a promising alternative method for system\nidentification and control due to its stronger search ability, faster\nconvergence rate and more stable performance.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jun 2012 16:50:34 GMT"}, {"version": "v2", "created": "Sat, 16 Nov 2013 01:37:11 GMT"}, {"version": "v3", "created": "Tue, 17 Nov 2015 03:32:32 GMT"}], "update_date": "2015-11-18", "authors_parsed": [["Zhou", "Xiaojun", ""], ["Yang", "Chunhua", ""], ["Gui", "Weihua", ""]]}, {"id": "1206.0710", "submitter": "Marius Kwemou", "authors": "Marius Kwemou (SG, LERSTAD)", "title": "Non-asymptotic Oracle Inequalities for the Lasso and Group Lasso in high\n  dimensional logistic model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of estimating a function $f\\_{0}$ in logistic\nregression model. We propose to estimate this function $f\\_{0}$ by a sparse\napproximation build as a linear combination of elements of a given dictionary\nof $p$ functions. This sparse approximation is selected by the Lasso or Group\nLasso procedure. In this context, we state non asymptotic oracle inequalities\nfor Lasso and Group Lasso under restricted eigenvalues assumption as introduced\nin \\cite{BRT}.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jun 2012 19:22:49 GMT"}, {"version": "v2", "created": "Wed, 3 Oct 2012 12:12:08 GMT"}, {"version": "v3", "created": "Fri, 14 Dec 2012 20:14:54 GMT"}, {"version": "v4", "created": "Wed, 20 May 2015 14:19:54 GMT"}], "update_date": "2015-05-21", "authors_parsed": [["Kwemou", "Marius", "", "SG, LERSTAD"]]}, {"id": "1206.0773", "submitter": "James Sharpnack", "authors": "James Sharpnack, Alessandro Rinaldo, Aarti Singh", "title": "Changepoint Detection over Graphs with the Spectral Scan Statistic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT math.IT stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the change-point detection problem of deciding, based on noisy\nmeasurements, whether an unknown signal over a given graph is constant or is\ninstead piecewise constant over two connected induced subgraphs of relatively\nlow cut size. We analyze the corresponding generalized likelihood ratio (GLR)\nstatistics and relate it to the problem of finding a sparsest cut in a graph.\nWe develop a tractable relaxation of the GLR statistic based on the\ncombinatorial Laplacian of the graph, which we call the spectral scan\nstatistic, and analyze its properties. We show how its performance as a testing\nprocedure depends directly on the spectrum of the graph, and use this result to\nexplicitly derive its asymptotic properties on few significant graph\ntopologies. Finally, we demonstrate both theoretically and by simulations that\nthe spectral scan statistic can outperform naive testing procedures based on\nedge thresholding and $\\chi^2$ testing.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jun 2012 21:34:40 GMT"}], "update_date": "2012-06-06", "authors_parsed": [["Sharpnack", "James", ""], ["Rinaldo", "Alessandro", ""], ["Singh", "Aarti", ""]]}, {"id": "1206.0823", "submitter": "Yudong Chen", "authors": "Yudong Chen, Constantine Caramanis", "title": "Orthogonal Matching Pursuit with Noisy and Missing Data: Low and High\n  Dimensional Results", "comments": "Minor revision. Appeared at ICML 2013 under the title \"Noisy and\n  Missing Data Regression: Distribution-Oblivious Support Recovery\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT math.IT stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many models for sparse regression typically assume that the covariates are\nknown completely, and without noise. Particularly in high-dimensional\napplications, this is often not the case. This paper develops efficient\nOMP-like algorithms to deal with precisely this setting. Our algorithms are as\nefficient as OMP, and improve on the best-known results for missing and noisy\ndata in regression, both in the high-dimensional setting where we seek to\nrecover a sparse vector from only a few measurements, and in the classical\nlow-dimensional setting where we recover an unstructured regressor. In the\nhigh-dimensional setting, our support-recovery algorithm requires no knowledge\nof even the statistics of the noise. Along the way, we also obtain improved\nperformance guarantees for OMP for the standard sparse regression problem with\nGaussian noise.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jun 2012 05:51:33 GMT"}, {"version": "v2", "created": "Mon, 30 Mar 2015 18:02:48 GMT"}], "update_date": "2015-03-31", "authors_parsed": [["Chen", "Yudong", ""], ["Caramanis", "Constantine", ""]]}, {"id": "1206.0825", "submitter": "Qiying Wang", "authors": "Qiying Wang, Peter C. B. Phillips", "title": "A specification test for nonlinear nonstationary models", "comments": "Published in at http://dx.doi.org/10.1214/12-AOS975 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2012, Vol. 40, No. 2, 727-758", "doi": "10.1214/12-AOS975", "report-no": "IMS-AOS-AOS975", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a limit theory for a general class of kernel smoothed U-statistics\nthat may be used for specification testing in time series regression with\nnonstationary data. The test framework allows for linear and nonlinear models\nwith endogenous regressors that have autoregressive unit roots or near unit\nroots. The limit theory for the specification test depends on the\nself-intersection local time of a Gaussian process. A new weak convergence\nresult is developed for certain partial sums of functions involving\nnonstationary time series that converges to the intersection local time\nprocess. This result is of independent interest and is useful in other\napplications. Simulations examine the finite sample performance of the test.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jun 2012 06:10:59 GMT"}], "update_date": "2012-06-06", "authors_parsed": [["Wang", "Qiying", ""], ["Phillips", "Peter C. B.", ""]]}, {"id": "1206.0827", "submitter": "Bing-Yi Jing", "authors": "Bing-Yi Jing, Xin-Bing Kong, Zhi Liu", "title": "Modeling high-frequency financial data by pure jump processes", "comments": "Published in at http://dx.doi.org/10.1214/12-AOS977 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2012, Vol. 40, No. 2, 759-784", "doi": "10.1214/12-AOS977", "report-no": "IMS-AOS-AOS977", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is generally accepted that the asset price processes contain jumps. In\nfact, pure jump models have been widely used to model asset prices and/or\nstochastic volatilities. The question is: is there any statistical evidence\nfrom the high-frequency financial data to support using pure jump models alone?\nThe purpose of this paper is to develop such a statistical test against the\nnecessity of a diffusion component. The test is very simple to use and yet\neffective. Asymptotic properties of the proposed test statistic will be\nstudied. Simulation studies and some real-life examples are included to\nillustrate our results.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jun 2012 06:55:52 GMT"}], "update_date": "2012-06-06", "authors_parsed": [["Jing", "Bing-Yi", ""], ["Kong", "Xin-Bing", ""], ["Liu", "Zhi", ""]]}, {"id": "1206.0847", "submitter": "Jun Shao", "authors": "Jun Shao, Xinwei Deng", "title": "Estimation in high-dimensional linear models with deterministic design\n  matrices", "comments": "Published in at http://dx.doi.org/10.1214/12-AOS982 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2012, Vol. 40, No. 2, 812-831", "doi": "10.1214/12-AOS982", "report-no": "IMS-AOS-AOS982", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Because of the advance in technologies, modern statistical studies often\nencounter linear models with the number of explanatory variables much larger\nthan the sample size. Estimation and variable selection in these\nhigh-dimensional problems with deterministic design points is very different\nfrom those in the case of random covariates, due to the identifiability of the\nhigh-dimensional regression parameter vector. We show that a reasonable\napproach is to focus on the projection of the regression parameter vector onto\nthe linear space generated by the design matrix. In this work, we consider the\nridge regression estimator of the projection vector and propose to threshold\nthe ridge regression estimator when the projection vector is sparse in the\nsense that many of its components are small. The proposed estimator has an\nexplicit form and is easy to use in application. Asymptotic properties such as\nthe consistency of variable selection and estimation and the convergence rate\nof the prediction mean squared error are established under some sparsity\nconditions on the projection vector. A simulation study is also conducted to\nexamine the performance of the proposed estimator.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jun 2012 09:05:01 GMT"}], "update_date": "2012-06-06", "authors_parsed": [["Shao", "Jun", ""], ["Deng", "Xinwei", ""]]}, {"id": "1206.0867", "submitter": "Jian-feng Yao", "authors": "Z. Bai and D. Jiang and J. Yao and S. Zheng", "title": "Testing linear hypotheses in high-dimensional regressions", "comments": "Accepted 02/2012 for publication in \"Statistics\". 20 pages, 2 pages\n  and 2 tables", "journal-ref": "Statistics: A Journal of Theoretical and Applied Statistics\n  47(6):1207-1223, June 2013,", "doi": "10.1080/02331888.2012.708031", "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For a multivariate linear model, Wilk's likelihood ratio test (LRT)\nconstitutes one of the cornerstone tools. However, the computation of its\nquantiles under the null or the alternative requires complex analytic\napproximations and more importantly, these distributional approximations are\nfeasible only for moderate dimension of the dependent variable, say $p\\le 20$.\nOn the other hand, assuming that the data dimension $p$ as well as the number\n$q$ of regression variables are fixed while the sample size $n$ grows, several\nasymptotic approximations are proposed in the literature for Wilk's $\\bLa$\nincluding the widely used chi-square approximation. In this paper, we consider\nnecessary modifications to Wilk's test in a high-dimensional context,\nspecifically assuming a high data dimension $p$ and a large sample size $n$.\nBased on recent random matrix theory, the correction we propose to Wilk's test\nis asymptotically Gaussian under the null and simulations demonstrate that the\ncorrected LRT has very satisfactory size and power, surely in the large $p$ and\nlarge $n$ context, but also for moderately large data dimensions like $p=30$ or\n$p=50$. As a byproduct, we give a reason explaining why the standard chi-square\napproximation fails for high-dimensional data. We also introduce a new\nprocedure for the classical multiple sample significance test in MANOVA which\nis valid for high-dimensional data.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jun 2012 10:05:09 GMT"}], "update_date": "2018-01-23", "authors_parsed": [["Bai", "Z.", ""], ["Jiang", "D.", ""], ["Yao", "J.", ""], ["Zheng", "S.", ""]]}, {"id": "1206.0871", "submitter": "Guillaume Lecu\\'{e}", "authors": "Guillaume Lecu\\'e, Shahar Mendelson", "title": "General nonexact oracle inequalities for classes with a subexponential\n  envelope", "comments": "Published in at http://dx.doi.org/10.1214/11-AOS965 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2012, Vol. 40, No. 2, 832-860", "doi": "10.1214/11-AOS965", "report-no": "IMS-AOS-AOS965", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that empirical risk minimization procedures and regularized empirical\nrisk minimization procedures satisfy nonexact oracle inequalities in an\nunbounded framework, under the assumption that the class has a subexponential\nenvelope function. The main novelty, in addition to the boundedness assumption\nfree setup, is that those inequalities can yield fast rates even in situations\nin which exact oracle inequalities only hold with slower rates. We apply these\nresults to show that procedures based on $\\ell_1$ and nuclear norms\nregularization functions satisfy oracle inequalities with a residual term that\ndecreases like $1/n$ for every $L_q$-loss functions ($q\\geq2$), while only\nassuming that the tail behavior of the input and output variables are well\nbehaved. In particular, no RIP type of assumption or \"incoherence condition\"\nare needed to obtain fast residual terms in those setups. We also apply these\nresults to the problems of convex aggregation and model selection.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jun 2012 10:22:09 GMT"}], "update_date": "2012-06-06", "authors_parsed": [["Lecu\u00e9", "Guillaume", ""], ["Mendelson", "Shahar", ""]]}, {"id": "1206.0897", "submitter": "Yu Tang", "authors": "Yu Tang, Hongquan Xu, Dennis K. J. Lin", "title": "Uniform fractional factorial designs", "comments": "Published in at http://dx.doi.org/10.1214/12-AOS987 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2012, Vol. 40, No. 2, 891-907", "doi": "10.1214/12-AOS987", "report-no": "IMS-AOS-AOS987", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The minimum aberration criterion has been frequently used in the selection of\nfractional factorial designs with nominal factors. For designs with\nquantitative factors, however, level permutation of factors could alter their\ngeometrical structures and statistical properties. In this paper uniformity is\nused to further distinguish fractional factorial designs, besides the minimum\naberration criterion. We show that minimum aberration designs have low\ndiscrepancies on average. An efficient method for constructing uniform minimum\naberration designs is proposed and optimal designs with 27 and 81 runs are\nobtained for practical use. These designs have good uniformity and are\neffective for studying quantitative factors.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jun 2012 12:17:15 GMT"}], "update_date": "2012-06-06", "authors_parsed": [["Tang", "Yu", ""], ["Xu", "Hongquan", ""], ["Lin", "Dennis K. J.", ""]]}, {"id": "1206.0916", "submitter": "Romain Guy", "authors": "Romain Guy, Catherine Laredo and Elisabeta Vergu", "title": "Parametric inference for discretely observed multidimensional diffusions\n  with small diffusion coefficient", "comments": "31 pages, 2 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a multidimensional diffusion X with drift coefficient\nb({\\alpha},X(t)) and diffusion coefficient {\\epsilon}{\\sigma}({\\beta},X(t)).\nThe diffusion is discretely observed at times t_k=k{\\Delta} for k=1..n on a\nfixed interval [0,T]. We study minimum contrast estimators derived from the\nGaussian process approximating X for small {\\epsilon}. We obtain consistent and\nasymptotically normal estimators of {\\alpha} for fixed {\\Delta} and\n{\\epsilon}\\rightarrow0 and of ({\\alpha},{\\beta}) for {\\Delta}\\rightarrow0 and\n{\\epsilon}\\rightarrow0. We compare the estimators obtained with various methods\nand for various magnitudes of {\\Delta} and {\\epsilon} based on simulation\nstudies. Finally, we investigate the interest of using such methods in an\nepidemiological framework.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jun 2012 13:06:43 GMT"}, {"version": "v2", "created": "Thu, 16 May 2013 12:59:43 GMT"}], "update_date": "2013-05-17", "authors_parsed": [["Guy", "Romain", ""], ["Laredo", "Catherine", ""], ["Vergu", "Elisabeta", ""]]}, {"id": "1206.0917", "submitter": "Jun Li", "authors": "Jun Li, Song Xi Chen", "title": "Two sample tests for high-dimensional covariance matrices", "comments": "Published in at http://dx.doi.org/10.1214/12-AOS993 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2012, Vol. 40, No. 2, 908-940", "doi": "10.1214/12-AOS993", "report-no": "IMS-AOS-AOS993", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose two tests for the equality of covariance matrices between two\nhigh-dimensional populations. One test is on the whole variance--covariance\nmatrices, and the other is on off-diagonal sub-matrices, which define the\ncovariance between two nonoverlapping segments of the high-dimensional random\nvectors. The tests are applicable (i) when the data dimension is much larger\nthan the sample sizes, namely the \"large $p$, small $n$\" situations and (ii)\nwithout assuming parametric distributions for the two populations. These two\naspects surpass the capability of the conventional likelihood ratio test. The\nproposed tests can be used to test on covariances associated with gene ontology\nterms.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jun 2012 13:10:07 GMT"}], "update_date": "2012-06-06", "authors_parsed": [["Li", "Jun", ""], ["Chen", "Song Xi", ""]]}, {"id": "1206.0937", "submitter": "James Sharpnack", "authors": "James Sharpnack, Akshay Krishnamurthy, Aarti Singh", "title": "Detecting Activations over Graphs using Spanning Tree Wavelet Bases", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the detection of activations over graphs under Gaussian noise,\nwhere signals are piece-wise constant over the graph. Despite the wide\napplicability of such a detection algorithm, there has been little success in\nthe development of computationally feasible methods with proveable theoretical\nguarantees for general graph topologies. We cast this as a hypothesis testing\nproblem, and first provide a universal necessary condition for asymptotic\ndistinguishability of the null and alternative hypotheses. We then introduce\nthe spanning tree wavelet basis over graphs, a localized basis that reflects\nthe topology of the graph, and prove that for any spanning tree, this approach\ncan distinguish null from alternative in a low signal-to-noise regime. Lastly,\nwe improve on this result and show that using the uniform spanning tree in the\nbasis construction yields a randomized test with stronger theoretical\nguarantees that in many cases matches our necessary conditions. Specifically,\nwe obtain near-optimal performance in edge transitive graphs, $k$-nearest\nneighbor graphs, and $\\epsilon$-graphs.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jun 2012 14:07:40 GMT"}, {"version": "v2", "created": "Wed, 11 Jul 2012 14:45:21 GMT"}, {"version": "v3", "created": "Thu, 12 Jul 2012 14:14:05 GMT"}], "update_date": "2012-07-13", "authors_parsed": [["Sharpnack", "James", ""], ["Krishnamurthy", "Akshay", ""], ["Singh", "Aarti", ""]]}, {"id": "1206.0963", "submitter": "Piero Barone", "authors": "Piero Barone", "title": "Kernel density estimation via diffusion and the complex exponentials\n  approximation problem", "comments": "20 pages, 4 figures", "journal-ref": "Quarterly of Applied Mathematics, vol.72, pp.291-310, 2014", "doi": "10.1090/S0033-569X-2014-01333-4", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A kernel method is proposed to estimate the condensed density of the\ngeneralized eigenvalues of pencils of Hankel matrices whose elements have a\njoint noncentral Gaussian distribution with nonidentical covariance. These\npencils arise when the complex exponentials approximation problem is considered\nin Gaussian noise. Several moments problems can be formulated in this framework\nand the estimation of the condensed density above is the main critical step for\ntheir solution. It is shown that the condensed density satisfies approximately\na diffusion equation, which allows to estimate an optimal bandwidth. It is\nproved by simulation that good results can be obtained even when the\nsignal-to-noise ratio is so small that other methods fail.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jun 2012 15:33:52 GMT"}], "update_date": "2015-10-02", "authors_parsed": [["Barone", "Piero", ""]]}, {"id": "1206.1024", "submitter": "Emre Barut", "authors": "Emre Barut, Jianqing Fan, Anneleen Verhasselt", "title": "Conditional Sure Independence Screening", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Independence screening is a powerful method for variable selection for `Big\nData' when the number of variables is massive. Commonly used independence\nscreening methods are based on marginal correlations or variations of it. In\nmany applications, researchers often have some prior knowledge that a certain\nset of variables is related to the response. In such a situation, a natural\nassessment on the relative importance of the other predictors is the\nconditional contributions of the individual predictors in presence of the known\nset of variables. This results in conditional sure independence screening\n(CSIS). Conditioning helps for reducing the false positive and the false\nnegative rates in the variable selection process. In this paper, we propose and\nstudy CSIS in the context of generalized linear models. For\nultrahigh-dimensional statistical problems, we give conditions under which sure\nscreening is possible and derive an upper bound on the number of selected\nvariables. We also spell out the situation under which CSIS yields model\nselection consistency. Moreover, we provide two data-driven methods to select\nthe thresholding parameter of conditional screening. The utility of the\nprocedure is illustrated by simulation studies and analysis of two real data\nsets.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jun 2012 19:06:58 GMT"}, {"version": "v2", "created": "Wed, 31 Oct 2012 23:49:12 GMT"}], "update_date": "2012-11-02", "authors_parsed": [["Barut", "Emre", ""], ["Fan", "Jianqing", ""], ["Verhasselt", "Anneleen", ""]]}, {"id": "1206.1194", "submitter": "Nicolas Verzelen", "authors": "Nadine Hilgert (MISTEA), Andr\\'e Mas (I3M), Nicolas Verzelen (MISTEA)", "title": "Minimax adaptive tests for the Functional Linear model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce two novel procedures to test the nullity of the slope function\nin the functional linear model with real output. The test statistics combine\nmultiple testing ideas and random projections of the input data through\nfunctional Principal Component Analysis. Interestingly, the procedures are\ncompletely data-driven and do not require any prior knowledge on the smoothness\nof the slope nor on the smoothness of the covariate functions. The levels and\npowers against local alternatives are assessed in a nonasymptotic setting. This\nallows us to prove that these procedures are minimax adaptive (up to an\nunavoidable \\log\\log n multiplicative term) to the unknown regularity of the\nslope. As a side result, the minimax separation distances of the slope are\nderived for a large range of regularity classes. A numerical study illustrates\nthese theoretical results.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jun 2012 12:05:30 GMT"}, {"version": "v2", "created": "Mon, 11 Feb 2013 19:45:25 GMT"}], "update_date": "2013-02-12", "authors_parsed": [["Hilgert", "Nadine", "", "MISTEA"], ["Mas", "Andr\u00e9", "", "I3M"], ["Verzelen", "Nicolas", "", "MISTEA"]]}, {"id": "1206.1228", "submitter": "Cec\\'ilia Fonseca", "authors": "C. Fonseca, H. Ferreira, L. Pereira A.P. and Martins", "title": "Stability and contagion measures for spatial extreme value analyses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As part of global climate change an accelerated hydrologic cycle (including\nan increase in heavy precipitation) is anticipated. So, it is of great\nimportance to be able to quantify high-impact hydrologic relationships, for\nexample, the impact that an extreme precipitation (or temperature) in a\nlocation has on a surrounding region. Building on the Multivariate Extreme\nValue Theory we propose a contagion index and a stability index. The contagion\nindex makes it possible to quantify the effect that an exceedance above a high\nthreshold can have on a region. The stability index reflects the expected\nnumber of crossings of a high threshold in a region associated to a specific\nlocation i, given the occurrence of at least one crossing at that location. We\nwill find some relations with well-known extremal dependence measures found in\nthe literature, which will provide immediate estimators. For these estimators\nan application to the annual maxima precipitation in Portuguese regions is\npresented.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jun 2012 13:57:44 GMT"}], "update_date": "2012-06-07", "authors_parsed": [["Fonseca", "C.", ""], ["Ferreira", "H.", ""], ["P.", "L. Pereira A.", ""], ["Martins", "", ""]]}, {"id": "1206.1365", "submitter": "Michael Lesnick", "authors": "Michael Lesnick", "title": "Multidimensional Interleavings and Applications to Topological Inference", "comments": "Late stage draft of Ph.D. thesis. 176 pages. Expands upon content in\n  arXiv:1106.5305", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AT cs.CG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work concerns the theoretical foundations of persistence-based\ntopological data analysis. We develop theory of topological inference in the\nmultidimensional persistence setting, and directly at the (topological) level\nof filtrations rather than only at the (algebraic) level of persistent homology\nmodules.\n  Our main mathematical objects of study are interleavings. These are tools for\nquantifying the similarity between two multidimensional filtrations or\npersistence modules. They were introduced for 1-D filtrations and persistence\nmodules by Chazal, Cohen-Steiner, Glisse, Guibas, and Oudot. We introduce\ngeneralizations of the definitions of interleavings given by Chazal et al. and\nuse these to define pseudometrics, called interleaving distances, on\nmultidimensional filtrations and multidimensional persistence modules.\n  We present an in-depth study of interleavings and interleaving distances. We\nthen use them to formulate and prove several multidimensional analogues of a\ntopological inference theorem of Chazal, Guibas, Oudot, and Skraba. These\nresults hold directly at the level of filtrations; they yield as corollaries\ncorresponding results at the module level.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jun 2012 22:38:19 GMT"}], "update_date": "2012-06-08", "authors_parsed": [["Lesnick", "Michael", ""]]}, {"id": "1206.1379", "submitter": "Sergey V. Lototsky", "authors": "Ning Lin and Sergey V. Lototsky", "title": "Second-order continuous-time non-stationary Gaussian autoregression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The objective of the paper is to identify and investigate all possible types\nof asymptotic behavior for the maximum likelihood estimators of the unknown\nparameters in the second-order linear stochastic ordinary differential equation\ndriven by Gaussian white noise. The emphasis is on the non-ergodic case, when\nthe roots of the corresponding characteristic equation are not both in the left\nhalf-plane.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jun 2012 01:08:26 GMT"}], "update_date": "2012-06-08", "authors_parsed": [["Lin", "Ning", ""], ["Lototsky", "Sergey V.", ""]]}, {"id": "1206.1395", "submitter": "Olivier Wintenberger", "authors": "Thomas Mikosch, Olivier Wintenberger (CEREMADE)", "title": "Precise large deviations for dependent regularly varying sequences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a precise large deviation principle for a stationary regularly\nvarying sequence of random variables. This principle extends the classical\nresults of A.V. Nagaev (1969) and S.V. Nagaev (1979) for iid regularly varying\nsequences. The proof uses an idea of Jakubowski (1993,1997) in the context of\ncentra limit theorems with infinite variance stable limits. We illustrate the\nprinciple for \\sv\\ models, functions of a Markov chain satisfying a polynomial\ndrift condition and solutions of linear and non-linear stochastic recurrence\nequations.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jun 2012 04:33:29 GMT"}], "update_date": "2012-06-11", "authors_parsed": [["Mikosch", "Thomas", "", "CEREMADE"], ["Wintenberger", "Olivier", "", "CEREMADE"]]}, {"id": "1206.1401", "submitter": "Jesus Fernandez", "authors": "Jes\\'us Fern\\'andez-S\\'anchez, Jeremy G. Sumner, Peter D. Jarvis, and\n  Michael D. Woodhams", "title": "Lie Markov models with purine/pyrimidine symmetry", "comments": "32 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE math.GR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continuous-time Markov chains are a standard tool in phylogenetic inference.\nIf homogeneity is assumed, the chain is formulated by specifying\ntime-independent rates of substitutions between states in the chain. In\napplications, there are usually extra constraints on the rates, depending on\nthe situation. If a model is formulated in this way, it is possible to\ngeneralise it and allow for an inhomogeneous process, with time-dependent rates\nsatisfying the same constraints. It is then useful to require that there exists\na homogeneous average of this inhomogeneous process within the same model. This\nleads to the definition of \"Lie Markov models\", which are precisely the class\nof models where such an average exists. These models form Lie algebras and\nhence concepts from Lie group theory are central to their derivation. In this\npaper, we concentrate on applications to phylogenetics and nucleotide\nevolution, and derive the complete hierarchy of Lie Markov models that respect\nthe grouping of nucleotides into purines and pyrimidines -- that is, models\nwith purine/pyrimidine symmetry. We also discuss how to handle the subtleties\nof applying Lie group methods, most naturally defined over the complex field,\nto the stochastic case of a Markov process, where parameter values are\nrestricted to be real and positive. In particular, we explore the geometric\nembedding of the cone of stochastic rate matrices within the ambient space of\nthe associated complex Lie algebra.\n  The whole list of Lie Markov models with purine/pyrimidine symmetry is\navailable at http://www.pagines.ma1.upc.edu/~jfernandez/LMNR.pdf.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jun 2012 05:08:38 GMT"}, {"version": "v2", "created": "Tue, 25 Jun 2013 15:14:45 GMT"}], "update_date": "2013-06-26", "authors_parsed": [["Fern\u00e1ndez-S\u00e1nchez", "Jes\u00fas", ""], ["Sumner", "Jeremy G.", ""], ["Jarvis", "Peter D.", ""], ["Woodhams", "Michael D.", ""]]}, {"id": "1206.1459", "submitter": "Mikhail  Ermakov s", "authors": "Mikhail Ermakov", "title": "A moderate deviation principle for empirical bootstrap measure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove two Large deviations principles (LDP) in the zone of moderate\ndeviation probabilities. First we establish LDP for the conditional\ndistributions of moderate deviations of empirical bootstrap measures given\nempirical probability measures. Second we establish LDP for the joint\ndistributions of empirical measure and bootstrap empirical measures. Using\nthese LDPs, similar LDPs for statistical differentiable functionals can be\nestablished. The LDPs for moderate deviations of empirical quantile processes\nand empirical bootstrap copula function are provided as illustration of these\nresults.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jun 2012 11:55:27 GMT"}, {"version": "v2", "created": "Wed, 21 May 2014 06:29:26 GMT"}], "update_date": "2014-05-22", "authors_parsed": [["Ermakov", "Mikhail", ""]]}, {"id": "1206.1465", "submitter": "Mikhail  Ermakov s", "authors": "Mikhail Ermakov", "title": "The Sharp Lower Bound of Asymptotic Efficiency of Estimators in the Zone\n  of Moderate Deviation Probabilities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For the zone of moderate deviation probabilities the local asymptotic minimax\nlower bound of asymptotic efficiency of estimators is established. The\nestimation parameter is multidimensional. The lower bound admits the\ninterpretation as the lower bound of asymptotic efficiency in confidence\nestimation.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jun 2012 12:15:08 GMT"}], "update_date": "2012-06-08", "authors_parsed": [["Ermakov", "Mikhail", ""]]}, {"id": "1206.1675", "submitter": "Axel B\\\"ucher", "authors": "Axel B\\\"ucher and Martin Ruppert", "title": "Consistent testing for a constant copula under strong mixing based on\n  the tapered block multiplier technique", "comments": "34 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Considering multivariate strongly mixing time series, nonparametric tests for\na constant copula with specified or unspecified change point (candidate) are\nderived; the tests are consistent against general alternatives. A tapered block\nmultiplier technique based on serially dependent multiplier random variables is\nprovided to estimate p-values of the test statistics. Size and power of the\ntests in finite samples are evaluated with Monte Carlo simulations. The block\nmultiplier technique might have several other applications for statistical\ninference on copulas of serially dependent data.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jun 2012 06:55:32 GMT"}], "update_date": "2012-06-11", "authors_parsed": [["B\u00fccher", "Axel", ""], ["Ruppert", "Martin", ""]]}, {"id": "1206.1708", "submitter": "Christian P. Robert", "authors": "Christian P. Robert (Universite Paris-Dauphine, IUF, and CREST)", "title": "Comments on \"Confidence distribution, the frequentist distribution\n  estimator of a parameter --- a review\" by Min-ge Xie and Kesar Singh", "comments": "5 pages, two figures, to appear in International Statistical Review", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This note is a discussion of the paper \"Confidence distribution\" by Min-ge\nXie and Kesar Singh, to appear in the International Statistical Review.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jun 2012 09:17:14 GMT"}], "update_date": "2012-06-11", "authors_parsed": [["Robert", "Christian P.", "", "Universite Paris-Dauphine, IUF, and CREST"]]}, {"id": "1206.1711", "submitter": "Pierre Alquier", "authors": "Pierre Alquier, Cristina Butucea (CREST, LAMA), Mohamed Hebiri (LAMA),\n  Katia Meziani (CEREMADE), Morimae Tomoyuki", "title": "Rank penalized estimation of a quantum system", "comments": null, "journal-ref": null, "doi": "10.1103/PhysRevA.88.032113", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new method to reconstruct the density matrix $\\rho$ of a\nsystem of $n$-qubits and estimate its rank $d$ from data obtained by quantum\nstate tomography measurements repeated $m$ times. The procedure consists in\nminimizing the risk of a linear estimator $\\hat{\\rho}$ of $\\rho$ penalized by\ngiven rank (from 1 to $2^n$), where $\\hat{\\rho}$ is previously obtained by the\nmoment method. We obtain simultaneously an estimator of the rank and the\nresulting density matrix associated to this rank. We establish an upper bound\nfor the error of penalized estimator, evaluated with the Frobenius norm, which\nis of order $dn(4/3)^n /m$ and consistency for the estimator of the rank. The\nproposed methodology is computationaly efficient and is illustrated with some\nexample states and real experimental data sets.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jun 2012 09:43:25 GMT"}, {"version": "v2", "created": "Tue, 19 Jun 2012 15:17:33 GMT"}, {"version": "v3", "created": "Thu, 26 Sep 2013 06:33:58 GMT"}], "update_date": "2015-06-05", "authors_parsed": [["Alquier", "Pierre", "", "CREST, LAMA"], ["Butucea", "Cristina", "", "CREST, LAMA"], ["Hebiri", "Mohamed", "", "LAMA"], ["Meziani", "Katia", "", "CEREMADE"], ["Tomoyuki", "Morimae", ""]]}, {"id": "1206.1753", "submitter": "Daniel Commenges", "authors": "Daniel Commenges, C\\'ecile Proust-Lima, C\\'ecilia Samieri, Benoit\n  Liquet", "title": "A universal approximate cross-validation criterion and its asymptotic\n  distribution", "comments": "23 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A general framework is that the estimators of a distribution are obtained by\nminimizing a function (the estimating function) and they are assessed through\nanother function (the assessment function). The estimating and assessment\nfunctions generally estimate risks. A classical case is that both functions\nestimate an information risk (specifically cross entropy); in that case Akaike\ninformation criterion (AIC) is relevant. In more general cases, the assessment\nrisk can be estimated by leave-one-out crossvalidation. Since leave-one-out\ncrossvalidation is computationally very demanding, an approximation formula can\nbe very useful. A universal approximate crossvalidation criterion (UACV) for\nthe leave-one-out crossvalidation is given. This criterion can be adapted to\ndifferent types of estimators, including penalized likelihood and maximum a\nposteriori estimators, and of assessment risk functions, including information\nrisk functions and continuous rank probability score (CRPS). This formula\nreduces to Takeuchi information criterion (TIC) when cross entropy is the risk\nfor both estimation and assessment. The asymptotic distribution of UACV and of\na difference of UACV is given. UACV can be used for comparing estimators of the\ndistributions of ordered categorical data derived from threshold models and\nmodels based on continuous approximations. A simulation study and an analysis\nof real psychometric data are presented.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jun 2012 13:26:13 GMT"}], "update_date": "2012-06-11", "authors_parsed": [["Commenges", "Daniel", ""], ["Proust-Lima", "C\u00e9cile", ""], ["Samieri", "C\u00e9cilia", ""], ["Liquet", "Benoit", ""]]}, {"id": "1206.1831", "submitter": "Arfon Smith", "authors": "Edwin Simpson, Stephen Roberts, Ioannis Psorakis, Arfon Smith", "title": "Dynamic Bayesian Combination of Multiple Imperfect Classifiers", "comments": "35 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST astro-ph.IM stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classifier combination methods need to make best use of the outputs of\nmultiple, imperfect classifiers to enable higher accuracy classifications. In\nmany situations, such as when human decisions need to be combined, the base\ndecisions can vary enormously in reliability. A Bayesian approach to such\nuncertain combination allows us to infer the differences in performance between\nindividuals and to incorporate any available prior knowledge about their\nabilities when training data is sparse. In this paper we explore Bayesian\nclassifier combination, using the computationally efficient framework of\nvariational Bayesian inference. We apply the approach to real data from a large\ncitizen science project, Galaxy Zoo Supernovae, and show that our method far\noutperforms other established approaches to imperfect decision combination. We\ngo on to analyse the putative community structure of the decision makers, based\non their inferred decision making strategies, and show that natural groupings\nare formed. Finally we present a dynamic Bayesian classifier combination\napproach and investigate the changes in base classifier performance over time.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jun 2012 18:14:58 GMT"}], "update_date": "2012-06-11", "authors_parsed": [["Simpson", "Edwin", ""], ["Roberts", "Stephen", ""], ["Psorakis", "Ioannis", ""], ["Smith", "Arfon", ""]]}, {"id": "1206.1874", "submitter": "Bin Dai", "authors": "Bin Dai, Shilin Ding, Grace Wahba", "title": "Multivariate Bernoulli distribution", "comments": "Published in at http://dx.doi.org/10.3150/12-BEJSP10 the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2013, Vol. 19, No. 4, 1465-1483", "doi": "10.3150/12-BEJSP10", "report-no": "IMS-BEJ-BEJSP10", "categories": "stat.AP math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the multivariate Bernoulli distribution as a model\nto estimate the structure of graphs with binary nodes. This distribution is\ndiscussed in the framework of the exponential family, and its statistical\nproperties regarding independence of the nodes are demonstrated. Importantly\nthe model can estimate not only the main effects and pairwise interactions\namong the nodes but also is capable of modeling higher order interactions,\nallowing for the existence of complex clique effects. We compare the\nmultivariate Bernoulli model with existing graphical inference models - the\nIsing model and the multivariate Gaussian model, where only the pairwise\ninteractions are considered. On the other hand, the multivariate Bernoulli\ndistribution has an interesting property in that independence and\nuncorrelatedness of the component random variables are equivalent. Both the\nmarginal and conditional distributions of a subset of variables in the\nmultivariate Bernoulli distribution still follow the multivariate Bernoulli\ndistribution. Furthermore, the multivariate Bernoulli logistic model is\ndeveloped under generalized linear model theory by utilizing the canonical link\nfunction in order to include covariate information on the nodes, edges and\ncliques. We also consider variable selection techniques such as LASSO in the\nlogistic model to impose sparsity structure on the graph. Finally, we discuss\nextending the smoothing spline ANOVA approach to the multivariate Bernoulli\nlogistic model to enable estimation of non-linear effects of the predictor\nvariables.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jun 2012 20:49:42 GMT"}, {"version": "v2", "created": "Tue, 12 Nov 2013 11:03:31 GMT"}], "update_date": "2013-11-13", "authors_parsed": [["Dai", "Bin", ""], ["Ding", "Shilin", ""], ["Wahba", "Grace", ""]]}, {"id": "1206.1898", "submitter": "Pedro Alejandro Ortega", "authors": "Pedro A. Ortega, Jordi Grau-Moya, Tim Genewein, David Balduzzi, Daniel\n  A. Braun", "title": "A Nonparametric Conjugate Prior Distribution for the Maximizing Argument\n  of a Noisy Function", "comments": "9 pages, 5 figures", "journal-ref": "Neural Information Processing Systems (NIPS) 2012", "doi": null, "report-no": null, "categories": "stat.ML cs.AI math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel Bayesian approach to solve stochastic optimization\nproblems that involve finding extrema of noisy, nonlinear functions. Previous\nwork has focused on representing possible functions explicitly, which leads to\na two-step procedure of first, doing inference over the function space and\nsecond, finding the extrema of these functions. Here we skip the representation\nstep and directly model the distribution over extrema. To this end, we devise a\nnon-parametric conjugate prior based on a kernel regressor. The resulting\nposterior distribution directly captures the uncertainty over the maximum of\nthe unknown function. We illustrate the effectiveness of our model by\noptimizing a noisy, high-dimensional, non-convex objective function.\n", "versions": [{"version": "v1", "created": "Sat, 9 Jun 2012 01:57:02 GMT"}, {"version": "v2", "created": "Sat, 10 Nov 2012 18:09:17 GMT"}], "update_date": "2012-11-13", "authors_parsed": [["Ortega", "Pedro A.", ""], ["Grau-Moya", "Jordi", ""], ["Genewein", "Tim", ""], ["Balduzzi", "David", ""], ["Braun", "Daniel A.", ""]]}, {"id": "1206.1904", "submitter": "Despina Stasi", "authors": "Sonja Petrovi\\'c and Despina Stasi", "title": "Toric algebra of hypergraphs", "comments": "Section 3 is new: it explains connections to log-linear models in\n  algebraic statistics and to combinatorial discrepancy. Section 6 (open\n  problems) has been moderately revised", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AC math.CO math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The edges of any hypergraph parametrize a monomial algebra called the edge\nsubring of the hypergraph. We study presentation ideals of these edge subrings,\nand describe their generators in terms of balanced walks on hypergraphs. Our\nresults generalize those for the defining ideals of edge subrings of graphs,\nwhich are well-known in the commutative algebra community, and popular in the\nalgebraic statistics community. One of the motivations for studying toric\nideals of hypergraphs comes from algebraic statistics, where generators of the\ntoric ideal give a basis for random walks on fibers of the statistical model\nspecified by the hypergraph. Further, understanding the structure of the\ngenerators gives insight into the model geometry.\n", "versions": [{"version": "v1", "created": "Sat, 9 Jun 2012 04:15:16 GMT"}, {"version": "v2", "created": "Wed, 20 Jun 2012 17:57:58 GMT"}, {"version": "v3", "created": "Wed, 3 Apr 2013 17:46:19 GMT"}], "update_date": "2013-04-23", "authors_parsed": [["Petrovi\u0107", "Sonja", ""], ["Stasi", "Despina", ""]]}, {"id": "1206.1998", "submitter": "Hazhir Homei", "authors": "H. Homei", "title": "Two-Sided Power Random Variables", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a well-known problem concerning a random variable $Z$ uniformly\ndistributed between two independent random variables. Two different extensions,\nconditionally directed power distribution and conditionally undirected power\ndistribution, have been introduced for this problem. For the second method,\ntwo-sided power random variables have been defined.\n", "versions": [{"version": "v1", "created": "Sun, 10 Jun 2012 06:43:43 GMT"}], "update_date": "2012-06-12", "authors_parsed": [["Homei", "H.", ""]]}, {"id": "1206.2206", "submitter": "Artur Lemonte", "authors": "Tiago M. Vargas, Silvia L. P. Ferrari, Artur J. Lemonte", "title": "Gradient statistic: higher-order asymptotics and Bartlett-type\n  correction", "comments": "Submitted for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We obtain an asymptotic expansion for the null distribution function of\nthegradient statistic for testing composite null hypotheses in the presence of\nnuisance parameters. The expansion is derived using a Bayesian route based on\nthe shrinkage argument described in Ghosh and Mukerjee (1991). Using this\nexpansion, we propose a Bartlett-type corrected gradient statistic with\nchi-square distribution up to an error of order o(n^{-1}) under the null\nhypothesis. Further, we also use the expansion to modify the percentage points\nof the large sample reference chi-square distribution. A small Monte Carlo\nexperiment and various examples are presented and discussed.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jun 2012 13:57:44 GMT"}], "update_date": "2012-06-12", "authors_parsed": [["Vargas", "Tiago M.", ""], ["Ferrari", "Silvia L. P.", ""], ["Lemonte", "Artur J.", ""]]}, {"id": "1206.2380", "submitter": "Karl Rohe", "authors": "Karl Rohe, Tai Qin, Haoyang Fan", "title": "The Highest Dimensional Stochastic Blockmodel with a Regularized\n  Estimator", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the high dimensional Stochastic Blockmodel for a random network, the\nnumber of clusters (or blocks) K grows with the number of nodes N. Two previous\nstudies have examined the statistical estimation performance of spectral\nclustering and the maximum likelihood estimator under the high dimensional\nmodel; neither of these results allow K to grow faster than N^{1/2}. We study a\nmodel where, ignoring log terms, K can grow proportionally to N. Since the\nnumber of clusters must be smaller than the number of nodes, no reasonable\nmodel allows K to grow faster; thus, our asymptotic results are the \"highest\"\ndimensional. To push the asymptotic setting to this extreme, we make additional\nassumptions that are motivated by empirical observations in physical\nanthropology (Dunbar, 1992), and an in depth study of massive empirical\nnetworks (Leskovec et al 2008). Furthermore, we develop a regularized maximum\nlikelihood estimator that leverages these insights and we prove that, under\ncertain conditions, the proportion of nodes that the regularized estimator\nmisclusters converges to zero. This is the first paper to explicitly introduce\nand demonstrate the advantages of statistical regularization in a parametric\nform for network analysis.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jun 2012 21:02:48 GMT"}, {"version": "v2", "created": "Thu, 1 Aug 2013 16:25:09 GMT"}], "update_date": "2013-08-02", "authors_parsed": [["Rohe", "Karl", ""], ["Qin", "Tai", ""], ["Fan", "Haoyang", ""]]}, {"id": "1206.2385", "submitter": "Andreas Hagemann", "authors": "Andreas Hagemann", "title": "Stochastic Equicontinuity in Nonlinear Time Series Models", "comments": "10 pages", "journal-ref": "Econometrics Journal 17(1), pp. 188-196, February 2014", "doi": "10.1111/ectj.12013", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper I provide simple and easily verifiable conditions under which a\nstrong form of stochastic equicontinuity holds in a wide variety of modern time\nseries models. In contrast to most results currently available in the\nliterature, my methods avoid mixing conditions. I discuss several applications\nin detail.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jun 2012 21:33:53 GMT"}, {"version": "v2", "created": "Tue, 11 Jun 2013 17:01:01 GMT"}], "update_date": "2014-02-20", "authors_parsed": [["Hagemann", "Andreas", ""]]}, {"id": "1206.2425", "submitter": "Alessandro Sarnaglia M.Sc.", "authors": "V. A. Reisen, A. J. Q Sarnaglia, N. C. Reis Jr, C. L\\'evy-Leduc, J. M.\n  Santos", "title": "Modeling and forecasting daily average PM$_{10}$ concentrations by a\n  seasonal ARFIMA model with volatility", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the possibility that the daily average Particulate\nMatter (PM$_{10}$) concentration is a seasonal fractionally integrated process\nwith time-dependent variance (volatility). In this context, one convenient\nextension is to consider the SARFIMA model (Reisen, et al, 2006a,b) with GARCH\ntype innovations. The model is theoretically justified and its usefulness is\ncorroborated with the application to PM$_{10}$ concentration in the city of\nCariacica-ES (Brazil). The model adjusted was able to capture the dynamics in\nthe series. The out-of-sample forecast intervals were improved by considering\nheteroscedastic errors and they were able to identify the periods of more\nvolatility.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jun 2012 02:40:57 GMT"}], "update_date": "2012-06-13", "authors_parsed": [["Reisen", "V. A.", ""], ["Sarnaglia", "A. J. Q", ""], ["Reis", "N. C.", "Jr"], ["L\u00e9vy-Leduc", "C.", ""], ["Santos", "J. M.", ""]]}, {"id": "1206.2459", "submitter": "Tim van Erven", "authors": "Tim van Erven and Peter Harremo\\\"es", "title": "R\\'enyi Divergence and Kullback-Leibler Divergence", "comments": "To appear in IEEE Transactions on Information Theory", "journal-ref": null, "doi": "10.1109/TIT.2014.2320500", "report-no": null, "categories": "cs.IT math.IT math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  R\\'enyi divergence is related to R\\'enyi entropy much like Kullback-Leibler\ndivergence is related to Shannon's entropy, and comes up in many settings. It\nwas introduced by R\\'enyi as a measure of information that satisfies almost the\nsame axioms as Kullback-Leibler divergence, and depends on a parameter that is\ncalled its order. In particular, the R\\'enyi divergence of order 1 equals the\nKullback-Leibler divergence.\n  We review and extend the most important properties of R\\'enyi divergence and\nKullback-Leibler divergence, including convexity, continuity, limits of\n$\\sigma$-algebras and the relation of the special order 0 to the Gaussian\ndichotomy and contiguity. We also show how to generalize the Pythagorean\ninequality to orders different from 1, and we extend the known equivalence\nbetween channel capacity and minimax redundancy to continuous channel inputs\n(for all orders) and present several other minimax results.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jun 2012 08:34:47 GMT"}, {"version": "v2", "created": "Thu, 24 Apr 2014 09:15:51 GMT"}], "update_date": "2014-04-25", "authors_parsed": [["van Erven", "Tim", ""], ["Harremo\u00ebs", "Peter", ""]]}, {"id": "1206.2493", "submitter": "Dave Zachariah", "authors": "Dave Zachariah, Martin Sundin, Magnus Jansson and Saikat Chatterjee", "title": "Alternating Least-Squares for Low-Rank Matrix Reconstruction", "comments": "4 pages, 2 figures", "journal-ref": "IEEE Signal Processing Letters, April 2012, Vol. 19, No. 4, pages\n  231-234", "doi": "10.1109/LSP.2012.2188026", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For reconstruction of low-rank matrices from undersampled measurements, we\ndevelop an iterative algorithm based on least-squares estimation. While the\nalgorithm can be used for any low-rank matrix, it is also capable of exploiting\na-priori knowledge of matrix structure. In particular, we consider linearly\nstructured matrices, such as Hankel and Toeplitz, as well as positive\nsemidefinite matrices. The performance of the algorithm, referred to as\nalternating least-squares (ALS), is evaluated by simulations and compared to\nthe Cram\\'er-Rao bounds.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jun 2012 11:33:07 GMT"}], "update_date": "2012-06-13", "authors_parsed": [["Zachariah", "Dave", ""], ["Sundin", "Martin", ""], ["Jansson", "Magnus", ""], ["Chatterjee", "Saikat", ""]]}, {"id": "1206.2496", "submitter": "Dave Zachariah", "authors": "Dave Zachariah, Saikat Chatterjee and Magnus Jansson", "title": "Dynamic Iterative Pursuit", "comments": "6 pages, 7 figures. Accepted for publication in IEEE Transactions on\n  Signal Processing", "journal-ref": "IEEE Transactions on Signal Processing, 2012, Vol. 60, No. 9,\n  pages 4967-4972", "doi": "10.1109/TSP.2012.2203813", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For compressive sensing of dynamic sparse signals, we develop an iterative\npursuit algorithm. A dynamic sparse signal process is characterized by varying\nsparsity patterns over time/space. For such signals, the developed algorithm is\nable to incorporate sequential predictions, thereby providing better\ncompressive sensing recovery performance, but not at the cost of high\ncomplexity. Through experimental evaluations, we observe that the new algorithm\nexhibits a graceful degradation at deteriorating signal conditions while\ncapable of yielding substantial performance gains as conditions improve.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jun 2012 11:37:39 GMT"}], "update_date": "2012-10-15", "authors_parsed": [["Zachariah", "Dave", ""], ["Chatterjee", "Saikat", ""], ["Jansson", "Magnus", ""]]}, {"id": "1206.2557", "submitter": "Ivan Kojadinovic", "authors": "Axel B\\\"ucher, Ivan Kojadinovic, Tom Rohmer and Johan Segers", "title": "Detecting changes in cross-sectional dependence in multivariate time\n  series", "comments": "32 pages, 6 tables", "journal-ref": "Journal of Multivariate Analysis 132, pages 111-128, 2014", "doi": "10.1016/j.jmva.2014.07.012", "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical and more recent tests for detecting distributional changes in\nmultivariate time series often lack power against alternatives that involve\nchanges in the cross-sectional dependence structure. To be able to detect such\nchanges better, a test is introduced based on a recently studied variant of the\nsequential empirical copula process. In contrast to earlier attempts, ranks are\ncomputed with respect to relevant subsamples, with beneficial consequences for\nthe sensitivity of the test. For the computation of p-values we propose a\nmultiplier resampling scheme that takes the serial dependence into account. The\nlarge-sample theory for the test statistic and the resampling scheme is\ndeveloped. The finite-sample performance of the procedure is assessed by Monte\nCarlo simulations. Two case studies involving time series of financial returns\nare presented as well.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jun 2012 14:59:34 GMT"}, {"version": "v2", "created": "Mon, 11 Feb 2013 21:54:18 GMT"}, {"version": "v3", "created": "Fri, 6 Dec 2013 13:29:20 GMT"}, {"version": "v4", "created": "Wed, 21 May 2014 13:36:09 GMT"}], "update_date": "2014-09-16", "authors_parsed": [["B\u00fccher", "Axel", ""], ["Kojadinovic", "Ivan", ""], ["Rohmer", "Tom", ""], ["Segers", "Johan", ""]]}, {"id": "1206.2620", "submitter": "Emeline Schmisser", "authors": "Emeline Schmisser (LPP)", "title": "Non-parametric adaptive estimation of the drift for a jump diffusion\n  process", "comments": null, "journal-ref": null, "doi": null, "report-no": "Pub. IRMA Lille, 72-I, 2012", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we consider a jump diffusion process (X_t)observed at\ndiscrete times t=0,Delta,...,nDelta. The sampling interval Delta tends to 0 and\nnDelta tends to infinity. We assume that (X_t) is ergodic, strictly stationary\nand exponentially \\beta-mixing. We use a penalized least-square approach to\ncompute two adaptive estimators of the drift function b. We provide bounds for\nthe risks of the two estimators.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jun 2012 18:59:42 GMT"}, {"version": "v2", "created": "Thu, 26 Sep 2013 17:50:32 GMT"}], "update_date": "2013-09-27", "authors_parsed": [["Schmisser", "Emeline", "", "LPP"]]}, {"id": "1206.2662", "submitter": "Godfrey Charles-Cadogan", "authors": "Godfrey Charles-Cadogan", "title": "Alpha Representation For Active Portfolio Management and High Frequency\n  Trading In Seemingly Efficient Markets", "comments": "15 pages, 0 figures", "journal-ref": "In Proceedings of Joint Statistical Meeting (JSM), Business and\n  Economic Statistics Section, Alexandria, VA: American Statistical\n  Association. 673-687, 2011", "doi": null, "report-no": null, "categories": "q-fin.RM math.PR math.ST q-fin.PM stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a trade strategy representation theorem for performance\nmeasurement and portable alpha in high frequency trading, by embedding a robust\ntrading algorithm that describe portfolio manager market timing behavior, in a\ncanonical multifactor asset pricing model. First, we present a spectral test\nfor market timing based on behavioral transformation of the hedge factors\ndesign matrix. Second, we find that the typical trade strategy process is a\nlocal martingale with a background driving Brownian bridge that mimics\nportfolio manager price reversal strategies. Third, we show that equilibrium\nasset pricing models like the CAPM exists on a set with P-measure zero. So that\nexcess returns, i.e. positive alpha, relative to a benchmark index is robust to\nno arbitrage pricing in turbulent capital markets. Fourth, the path properties\nof alpha are such that it is positive between suitably chosen stopping times\nfor trading. Fifth, we demonstrate how, and why, econometric tests of portfolio\nperformance tend to under report positive alpha.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jun 2012 20:27:14 GMT"}], "update_date": "2012-06-21", "authors_parsed": [["Charles-Cadogan", "Godfrey", ""]]}, {"id": "1206.2700", "submitter": "Judson Locke", "authors": "Judson B. Locke and Adrian M. Peter", "title": "Multiwavelet density estimation", "comments": "Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate density estimation methodologies play an integral role in a variety\nof scientific disciplines, with applications including simulation models,\ndecision support tools, and exploratory data analysis. In the past, histograms\nand kernel density estimators have been the predominant tools of choice,\nprimarily due to their ease of use and mathematical simplicity. More recently,\nthe use of wavelets for density estimation has gained in popularity due to\ntheir ability to approximate a large class of functions, including those with\nlocalized, abrupt variations. However, a well-known attribute of wavelet bases\nis that they can not be simultaneously symmetric, orthogonal, and compactly\nsupported. Multiwavelets-a more general, vector-valued, construction of\nwavelets-overcome this disadvantage, making them natural choices for estimating\ndensity functions, many of which exhibit local symmetries around features such\nas a mode. We extend the methodology of wavelet density estimation to use\nmultiwavelet bases and illustrate several empirical results where multiwavelet\nestimators outperform their wavelet counterparts at coarser resolution levels.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2012 02:08:12 GMT"}], "update_date": "2012-06-14", "authors_parsed": [["Locke", "Judson B.", ""], ["Peter", "Adrian M.", ""]]}, {"id": "1206.2729", "submitter": "Gabriela Ciuperca", "authors": "Gabriela Ciuperca", "title": "Two tests for sequential detection of a change-point in a nonlinear\n  model", "comments": "37 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, two tests, based on CUSUM of the residuals and least squares\nestimation, are studied to detect in real time a change-point in a nonlinear\nmodel. A first test statistic is proposed by extension of a method already used\nin the literature but for the linear models. It is tested the null hypothesis,\nat each sequential observation, that there is no change in the model against a\nchange presence. The asymptotic distribution of the test statistic under the\nnull hypothesis is given and its convergence in probability to infinity is\nproved when a change occurs. These results will allow to build an asymptotic\ncritical region. Next, in order to decrease the type I error probability, a\nbootstrapped critical value is proposed and a modified test is studied in a\nsimilar way. Simulation results, using Monte-Carlo technique, for nonlinear\nmodels which have numerous applications, investigate the properties of the two\nstatistic tests.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2012 06:48:59 GMT"}, {"version": "v2", "created": "Wed, 27 Feb 2013 17:23:30 GMT"}], "update_date": "2013-02-28", "authors_parsed": [["Ciuperca", "Gabriela", ""]]}, {"id": "1206.2743", "submitter": "Katharina Proksch", "authors": "Katharina Proksch, Nicolai Bissantz, Holger Dette", "title": "Confidence bands for multivariate and time dependent inverse regression\n  models", "comments": "Published at http://dx.doi.org/10.3150/13-BEJ563 in the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2015, Vol. 21, No. 1, 144-175", "doi": "10.3150/13-BEJ563", "report-no": "IMS-BEJ-BEJ563", "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uniform asymptotic confidence bands for a multivariate regression function in\nan inverse regression model with a convolution-type operator are constructed.\nThe results are derived using strong approximation methods and a limit theorem\nfor the supremum of a stationary Gaussian field over an increasing system of\nsets. As a particular application, asymptotic confidence bands for a time\ndependent regression function $f_t(x)$ ($x\\in \\mathbb {R}^d,t\\in \\mathbb {R}$)\nin a convolution-type inverse regression model are obtained. Finally, we\ndemonstrate the practical feasibility of our proposed methods in a simulation\nstudy and an application to the estimation of the luminosity profile of the\nelliptical galaxy NGC5017. To the best knowledge of the authors, the results\npresented in this paper are the first which provide uniform confidence bands\nfor multivariate nonparametric function estimation in inverse problems.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2012 08:23:54 GMT"}, {"version": "v2", "created": "Tue, 7 Apr 2015 07:04:49 GMT"}], "update_date": "2015-04-08", "authors_parsed": [["Proksch", "Katharina", ""], ["Bissantz", "Nicolai", ""], ["Dette", "Holger", ""]]}, {"id": "1206.2790", "submitter": "Katharine Turner", "authors": "Katharine Turner and Yuriy Mileyko and Sayan Mukherjee and John Harer", "title": "Fr\\'echet Means for Distributions of Persistence diagrams", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.GN math.MG stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a distribution $\\rho$ on persistence diagrams and observations\n$X_1,...X_n \\stackrel{iid}{\\sim} \\rho$ we introduce an algorithm in this paper\nthat estimates a Fr\\'echet mean from the set of diagrams $X_1,...X_n$. If the\nunderlying measure $\\rho$ is a combination of Dirac masses $\\rho = \\frac{1}{m}\n\\sum_{i=1}^m \\delta_{Z_i}$ then we prove the algorithm converges to a local\nminimum and a law of large numbers result for a Fr\\'echet mean computed by the\nalgorithm given observations drawn iid from $\\rho$. We illustrate the\nconvergence of an empirical mean computed by the algorithm to a population mean\nby simulations from Gaussian random fields.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2012 13:17:02 GMT"}, {"version": "v2", "created": "Wed, 20 Mar 2013 15:28:46 GMT"}], "update_date": "2013-03-21", "authors_parsed": [["Turner", "Katharine", ""], ["Mileyko", "Yuriy", ""], ["Mukherjee", "Sayan", ""], ["Harer", "John", ""]]}, {"id": "1206.2966", "submitter": "Ivan Fernandez-Val", "authors": "Ivan Fernandez-Val and Joonhwah Lee", "title": "Panel Data Models with Nonadditive Unobserved Heterogeneity: Estimation\n  and Inference", "comments": "51 pages, 4 tables, 1 figure, it includes supplementary appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME econ.EM math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers fixed effects estimation and inference in linear and\nnonlinear panel data models with random coefficients and endogenous regressors.\nThe quantities of interest -- means, variances, and other moments of the random\ncoefficients -- are estimated by cross sectional sample moments of GMM\nestimators applied separately to the time series of each individual. To deal\nwith the incidental parameter problem introduced by the noise of the\nwithin-individual estimators in short panels, we develop bias corrections.\nThese corrections are based on higher-order asymptotic expansions of the GMM\nestimators and produce improved point and interval estimates in moderately long\npanels. Under asymptotic sequences where the cross sectional and time series\ndimensions of the panel pass to infinity at the same rate, the uncorrected\nestimator has an asymptotic bias of the same order as the asymptotic variance.\nThe bias corrections remove the bias without increasing variance. An empirical\nexample on cigarette demand based on Becker, Grossman and Murphy (1994) shows\nsignificant heterogeneity in the price effect across U.S. states.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2012 23:10:58 GMT"}, {"version": "v2", "created": "Fri, 11 Oct 2013 22:03:17 GMT"}], "update_date": "2018-01-16", "authors_parsed": [["Fernandez-Val", "Ivan", ""], ["Lee", "Joonhwah", ""]]}, {"id": "1206.3125", "submitter": "Stanislav Volgushev", "authors": "Stanislav Volgushev, Melanie Birke, Holger Dette, Natalie Neumeyer", "title": "Significance testing in quantile regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of testing significance of predictors in multivariate\nnonparametric quantile regression. A stochastic process is proposed, which is\nbased on a comparison of the responses with a nonparametric quantile regression\nestimate under the null hypothesis. It is demonstrated that under the null\nhypothesis this process converges weakly to a centered Gaussian process and the\nasymptotic properties of the test under fixed and local alternatives are also\ndiscussed. In particular we show, that - in contrast to the nonparametric\napproach based on estimation of $L^2$-distances - the new test is able to\ndetect local alternatives which converge to the null hypothesis with any rate\n$a_n \\to 0$ such that $a_n \\sqrt{n} \\to \\infty$ (here $n$ denotes the sample\nsize). We also present a small simulation study illustrating the finite sample\nproperties of a bootstrap version of the the corresponding Kolmogorov-Smirnov\ntest.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jun 2012 14:51:29 GMT"}], "update_date": "2012-06-15", "authors_parsed": [["Volgushev", "Stanislav", ""], ["Birke", "Melanie", ""], ["Dette", "Holger", ""], ["Neumeyer", "Natalie", ""]]}, {"id": "1206.3245", "submitter": "Philip Dawid", "authors": "Philip Dawid, Vanessa Didelez", "title": "Identifying Optimal Sequential Decisions", "comments": "Appears in Proceedings of the Twenty-Fourth Conference on Uncertainty\n  in Artificial Intelligence (UAI2008)", "journal-ref": "In Proc. 24th Annual Conference on Uncertainty in Artificial\n  Intelligence (2008), edited by D. McAllester and P. Myllymaki. AUAI Press,\n  113-120", "doi": null, "report-no": "UAI-P-2008-PG-113-120", "categories": "cs.AI math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider conditions that allow us to find an optimal strategy for\nsequential decisions from a given data situation. For the case where all\ninterventions are unconditional (atomic), identifiability has been discussed by\nPearl & Robins (1995). We argue here that an optimal strategy must be\nconditional, i.e. take the information available at each decision point into\naccount. We show that the identification of an optimal sequential decision\nstrategy is more restrictive, in the sense that conditional interventions might\nnot always be identified when atomic interventions are. We further demonstrate\nthat a simple graphical criterion for the identifiability of an optimal\nstrategy can be given.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2012 15:06:54 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Dawid", "Philip", ""], ["Didelez", "Vanessa", ""]]}, {"id": "1206.3381", "submitter": "Tilmann Gneiting", "authors": "Tilmann Gneiting", "title": "On the Cover-Hart Inequality: What's a Sample of Size One Worth?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT math.IT stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bob predicts a future observation based on a sample of size one. Alice can\ndraw a sample of any size before issuing her prediction. How much better can\nshe do than Bob? Perhaps surprisingly, under a large class of loss functions,\nwhich we refer to as the Cover-Hart family, the best Alice can do is to halve\nBob's risk. In this sense, half the information in an infinite sample is\ncontained in a sample of size one. The Cover-Hart family is a convex cone that\nincludes metrics and negative definite functions, subject to slight regularity\nconditions. These results may help explain the small relative differences in\nempirical performance measures in applied classification and forecasting\nproblems, as well as the success of reasoning and learning by analogy in\ngeneral, and nearest neighbor techniques in particular.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jun 2012 07:19:07 GMT"}], "update_date": "2012-06-18", "authors_parsed": [["Gneiting", "Tilmann", ""]]}, {"id": "1206.3422", "submitter": "Felix Abramovich", "authors": "Felix Abramovich and Vadim Grinshtein", "title": "Model selection in regression under structural constraints", "comments": "arXiv admin note: text overlap with arXiv:0912.4387", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper considers model selection in regression under the additional\nstructural constraints on admissible models where the number of potential\npredictors might be even larger than the available sample size. We develop a\nBayesian formalism as a natural tool for generating a wide class of model\nselection criteria based on penalized least squares estimation with various\ncomplexity penalties associated with a prior on a model size. The resulting\ncriteria are adaptive to structural constraints. We establish the upper bound\nfor the quadratic risk of the resulting MAP estimator and the corresponding\nlower bound for the minimax risk over a set of admissible models of a given\nsize. We then specify the class of priors (and, therefore, the class of\ncomplexity penalties) where for the \"nearly-orthogonal\" design the MAP\nestimator is asymptotically at least nearly-minimax (up to a log-factor)\nsimultaneously over an entire range of sparse and dense setups. Moreover, when\nthe numbers of admissible models are \"small\" (e.g., ordered variable selection)\nor, on the opposite, for the case of complete variable selection, the proposed\nestimator achieves the exact minimax rates.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jun 2012 11:02:42 GMT"}, {"version": "v2", "created": "Sun, 17 Feb 2013 09:46:19 GMT"}], "update_date": "2013-02-19", "authors_parsed": [["Abramovich", "Felix", ""], ["Grinshtein", "Vadim", ""]]}, {"id": "1206.3520", "submitter": "Sebastian Roch", "authors": "Sebastien Roch and Sagi Snir", "title": "Recovering the tree-like trend of evolution despite extensive lateral\n  genetic transfer: A probabilistic analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.CE cs.DS math.ST q-bio.PE stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lateral gene transfer (LGT) is a common mechanism of non-vertical evolution\nwhere genetic material is transferred between two more or less distantly\nrelated organisms. It is particularly common in bacteria where it contributes\nto adaptive evolution with important medical implications. In evolutionary\nstudies, LGT has been shown to create widespread discordance between gene trees\nas genomes become mosaics of gene histories. In particular, the Tree of Life\nhas been questioned as an appropriate representation of bacterial evolutionary\nhistory. Nevertheless a common hypothesis is that prokaryotic evolution is\nprimarily tree-like, but that the underlying trend is obscured by LGT.\nExtensive empirical work has sought to extract a common tree-like signal from\nconflicting gene trees. Here we give a probabilistic perspective on the problem\nof recovering the tree-like trend despite LGT. Under a model of randomly\ndistributed LGT, we show that the species phylogeny can be reconstructed even\nin the presence of surprisingly many (almost linear number of) LGT events per\ngene tree. Our results, which are optimal up to logarithmic factors, are based\non the analysis of a robust, computationally efficient reconstruction method\nand provides insight into the design of such methods. Finally we show that our\nresults have implications for the discovery of highways of gene sharing.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jun 2012 17:19:42 GMT"}], "update_date": "2012-06-18", "authors_parsed": [["Roch", "Sebastien", ""], ["Snir", "Sagi", ""]]}, {"id": "1206.3543", "submitter": "V. J.  Vieland", "authors": "V. J. Vieland, J. Das, S. E. Hodge, S.-C. Seok", "title": "Measurement of statistical evidence on an absolute scale following\n  thermodynamic principles", "comments": "Final version of manuscript as published in Theory in Biosciences\n  (2013)", "journal-ref": "Theory Biosci 132:181-194 (2013)", "doi": "10.1007/s12064-013-0180-9", "report-no": null, "categories": "math.ST cs.IT math.IT physics.data-an q-bio.QM stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical analysis is used throughout biomedical research and elsewhere to\nassess strength of evidence. We have previously argued that typical outcome\nstatistics (including p-values and maximum likelihood ratios) have poor\nmeasure-theoretic properties: they can erroneously indicate decreasing evidence\nas data supporting an hypothesis accumulate; and they are not amenable to\ncalibration, necessary for meaningful comparison of evidence across different\nstudy designs, data types, and levels of analysis. We have also previously\nproposed that thermodynamic theory, which allowed for the first time derivation\nof an absolute measurement scale for temperature (T), could be used to derive\nan absolute scale for evidence (E). Here we present a novel\nthermodynamically-based framework in which measurement of E on an absolute\nscale, for which \"one degree\" always means the same thing, becomes possible for\nthe first time. The new framework invites us to think about statistical\nanalyses in terms of the flow of (evidential) information, placing this work in\nthe context of a growing literature on connections among physics, information\ntheory, and statistics.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jun 2012 18:55:38 GMT"}, {"version": "v2", "created": "Wed, 12 Sep 2012 16:41:15 GMT"}, {"version": "v3", "created": "Mon, 30 Sep 2013 21:15:24 GMT"}], "update_date": "2013-10-02", "authors_parsed": [["Vieland", "V. J.", ""], ["Das", "J.", ""], ["Hodge", "S. E.", ""], ["Seok", "S. -C.", ""]]}, {"id": "1206.3627", "submitter": "Debdeep Pati", "authors": "Debdeep Pati, Anirban Bhattacharya, Natesh S. Pillai, David Dunson", "title": "Posterior contraction in sparse Bayesian factor models for massive\n  covariance matrices", "comments": "Published in at http://dx.doi.org/10.1214/14-AOS1215 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2014, Vol. 42, No. 3, 1102-1130", "doi": "10.1214/14-AOS1215", "report-no": "IMS-AOS-AOS1215", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse Bayesian factor models are routinely implemented for parsimonious\ndependence modeling and dimensionality reduction in high-dimensional\napplications. We provide theoretical understanding of such Bayesian procedures\nin terms of posterior convergence rates in inferring high-dimensional\ncovariance matrices where the dimension can be larger than the sample size.\nUnder relevant sparsity assumptions on the true covariance matrix, we show that\ncommonly-used point mass mixture priors on the factor loadings lead to\nconsistent estimation in the operator norm even when $p\\gg n$. One of our major\ncontributions is to develop a new class of continuous shrinkage priors and\nprovide insights into their concentration around sparse vectors. Using such\npriors for the factor loadings, we obtain similar rate of convergence as\nobtained with point mass mixture priors. To obtain the convergence rates, we\nconstruct test functions to separate points in the space of high-dimensional\ncovariance matrices using insights from random matrix theory; the tools\ndeveloped may be of independent interest. We also derive minimax rates and show\nthat the Bayesian posterior rates of convergence coincide with the minimax\nrates upto a $\\sqrt{\\log n}$ term.\n", "versions": [{"version": "v1", "created": "Sat, 16 Jun 2012 03:38:20 GMT"}, {"version": "v2", "created": "Sat, 7 Jul 2012 12:40:46 GMT"}, {"version": "v3", "created": "Sun, 1 Dec 2013 00:00:26 GMT"}, {"version": "v4", "created": "Mon, 2 Jun 2014 07:52:28 GMT"}], "update_date": "2014-06-03", "authors_parsed": [["Pati", "Debdeep", ""], ["Bhattacharya", "Anirban", ""], ["Pillai", "Natesh S.", ""], ["Dunson", "David", ""]]}, {"id": "1206.3911", "submitter": "Fabio Rapallo", "authors": "Roberto Fontana, Fabio Rapallo and Maria Piera Rogantin", "title": "Saturated fractions of two-factor designs", "comments": "18 pages, 4 figures. Some figures have been removed and some\n  sentences have been rewritten", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study saturated fractions of a two-factor design under the\nsimple effect model. In particular, we define a criterion to check whether a\ngiven fraction is saturated or not, and we compute the number of saturated\nfractions. All proofs are constructive and can be used as actual methods to\nbuild saturated fractions. Moreover, we show how the theory of Markov bases for\ncontingency tables can be applied to two-factor designs for moving between the\ndesigns with given margins.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jun 2012 12:48:24 GMT"}, {"version": "v2", "created": "Thu, 12 Jul 2012 09:56:34 GMT"}], "update_date": "2012-07-13", "authors_parsed": [["Fontana", "Roberto", ""], ["Rapallo", "Fabio", ""], ["Rogantin", "Maria Piera", ""]]}, {"id": "1206.4000", "submitter": "Krzysztof A. Meissner", "authors": "Krzysztof A. Meissner", "title": "A Tail Sensitive Test for Cumulative Distribution Functions", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a simple way of testing whether a given set of observations can\ncome from a given theoretical cumulative distribution. In the test more weight\nis attached to the tails of the distribution than in the usual Kolmogorov or\nSmirnov tests. The respective probability distribution is derived.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jun 2012 17:40:34 GMT"}, {"version": "v2", "created": "Mon, 8 Apr 2013 17:11:53 GMT"}], "update_date": "2013-04-09", "authors_parsed": [["Meissner", "Krzysztof A.", ""]]}, {"id": "1206.4007", "submitter": "Xinjia Chen", "authors": "Xinjia Chen", "title": "Consecutive Sequential Probability Ratio Tests of Multiple Statistical\n  Hypotheses", "comments": "29 pages, no figure; The main results of this paper have appeared in\n  Proceedings of SPIE Conferences, Baltimore, Maryland, April 24-27, 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we develop a simple approach for testing multiple statistical\nhypotheses based on the observations of a number of probability ratios\nenumerated consecutively with respect to the index of hypotheses. Explicit and\ntight bounds for the probability of making wrong decisions are obtained for\nchoosing appropriate parameters for the proposed tests. In the special case of\ntesting two hypotheses, our tests reduce to Wald's sequential probability ratio\ntests.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jun 2012 18:02:43 GMT"}], "update_date": "2012-06-19", "authors_parsed": [["Chen", "Xinjia", ""]]}, {"id": "1206.4091", "submitter": "Ryan Martin", "authors": "Ryan Martin and Chuanhai Liu", "title": "Inferential models: A framework for prior-free posterior probabilistic\n  inference", "comments": "29 pages with 3 figures. Main text is the same as the published\n  version. Appendix B is an addition, not in the published version, that\n  contains some corrections and extensions of two of the main theorems", "journal-ref": "Journal of the American Statistical Association, 2013, Vol. 108,\n  Number 501, pages 301-313", "doi": "10.1080/01621459.2012.747960", "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Posterior probabilistic statistical inference without priors is an important\nbut so far elusive goal. Fisher's fiducial inference, Dempster-Shafer theory of\nbelief functions, and Bayesian inference with default priors are attempts to\nachieve this goal but, to date, none has given a completely satisfactory\npicture. This paper presents a new framework for probabilistic inference, based\non inferential models (IMs), which not only provides data-dependent\nprobabilistic measures of uncertainty about the unknown parameter, but does so\nwith an automatic long-run frequency calibration property. The key to this new\napproach is the identification of an unobservable auxiliary variable associated\nwith observable data and unknown parameter, and the prediction of this\nauxiliary variable with a random set before conditioning on data. Here we\npresent a three-step IM construction, and prove a frequency-calibration\nproperty of the IM's belief function under mild conditions. A corresponding\noptimality theory is developed, which helps to resolve the non-uniqueness\nissue. Several examples are presented to illustrate this new approach.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jun 2012 22:31:42 GMT"}, {"version": "v2", "created": "Tue, 2 Oct 2012 15:49:38 GMT"}, {"version": "v3", "created": "Sat, 23 Mar 2013 13:34:19 GMT"}], "update_date": "2013-03-26", "authors_parsed": [["Martin", "Ryan", ""], ["Liu", "Chuanhai", ""]]}, {"id": "1206.4285", "submitter": "Yuri Golubev", "authors": "Yu. Golubev", "title": "Exponential weighting and oracle inequalities for projection methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of recovering an unknown vector from noisy data with\nthe help of projection estimates. The goal is to find a convex combination of\nthese estimates with the minimal risk. We study an aggregation method based on\nthe so-called exponential weighting and provide a new upper bound for the mean\nsquare risk of this method.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jun 2012 18:30:39 GMT"}], "update_date": "2012-06-20", "authors_parsed": [["Golubev", "Yu.", ""]]}, {"id": "1206.4340", "submitter": "Marianna Pensky", "authors": "Marianna Pensky", "title": "Spatially inhomogeneous linear inverse problems with possible\n  singularities", "comments": "Published in at http://dx.doi.org/10.1214/13-AOS1166 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2013, Vol. 41, No. 5, 2668-2697", "doi": "10.1214/13-AOS1166", "report-no": "IMS-AOS-AOS1166", "categories": "math.ST math.FA stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The objective of the present paper is to introduce the concept of a spatially\ninhomogeneous linear inverse problem where the degree of ill-posedness of\noperator $Q$ depends not only on the scale but also on location. In this case,\nthe rates of convergence are determined by the interaction of four parameters,\nthe smoothness and spatial homogeneity of the unknown function $f$ and degrees\nof ill-posedness and spatial inhomogeneity of operator $Q$. Estimators obtained\nin the paper are based either on wavelet-vaguelette decomposition (if the norms\nof all vaguelettes are finite) or on a hybrid of wavelet-vaguelette\ndecomposition and Galerkin method (if vaguelettes in the neighborhood of the\nsingularity point have infinite norms). The hybrid estimator is a combination\nof a linear part in the vicinity of the singularity point and the nonlinear\nblock thresholding wavelet estimator elsewhere. To attain adaptivity, an\noptimal resolution level for the linear, singularity affected, portion of the\nestimator is obtained using Lepski [Theory Probab. Appl. 35 (1990) 454-466 and\n36 (1991) 682-697] method and is used subsequently as the lowest resolution\nlevel for the nonlinear wavelet estimator. We show that convergence rates of\nthe hybrid estimator lie within a logarithmic factor of the optimal minimax\nconvergence rates. The theory presented in the paper is supplemented by\nexamples of deconvolution with a spatially inhomogeneous kernel and\ndeconvolution in the presence of locally extreme noise or extremely\ninhomogeneous design. The first two problems are examined via a limited\nsimulation study which demonstrates advantages of the hybrid estimator when the\ndegree of spatial inhomogeneity is high. In addition, we apply the technique to\nrecovery of a convolution signal transmitted via amplitude modulation.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jun 2012 20:56:56 GMT"}, {"version": "v2", "created": "Sun, 21 Oct 2012 17:36:26 GMT"}, {"version": "v3", "created": "Thu, 31 Jan 2013 23:53:02 GMT"}, {"version": "v4", "created": "Thu, 23 May 2013 18:31:54 GMT"}, {"version": "v5", "created": "Wed, 4 Dec 2013 06:33:19 GMT"}], "update_date": "2013-12-05", "authors_parsed": [["Pensky", "Marianna", ""]]}, {"id": "1206.4615", "submitter": "Yingjian Wang", "authors": "Yingjian Wang (Duke University), Lawrence Carin (Duke University)", "title": "Levy Measure Decompositions for the Beta and Gamma Processes", "comments": "ICML2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop new representations for the Levy measures of the beta and gamma\nprocesses. These representations are manifested in terms of an infinite sum of\nwell-behaved (proper) beta and gamma distributions. Further, we demonstrate how\nthese infinite sums may be truncated in practice, and explicitly characterize\ntruncation errors. We also perform an analysis of the characteristics of\nposterior distributions, based on the proposed decompositions. The\ndecompositions provide new insights into the beta and gamma processes (and\ntheir generalizations), and we demonstrate how the proposed representation\nunifies some properties of the two. This paper is meant to provide a rigorous\nfoundation for and new perspectives on Levy processes, as these are of\nincreasing importance in machine learning.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jun 2012 15:01:58 GMT"}], "update_date": "2012-06-22", "authors_parsed": [["Wang", "Yingjian", "", "Duke University"], ["Carin", "Lawrence", "", "Duke University"]]}, {"id": "1206.4680", "submitter": "Mikhail Bilenko", "authors": "Hoyt Koepke (University of Washington), Mikhail Bilenko (Microsoft\n  Research)", "title": "Fast Prediction of New Feature Utility", "comments": "ICML2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the new feature utility prediction problem: statistically testing\nwhether adding a new feature to the data representation can improve predictive\naccuracy on a supervised learning task. In many applications, identifying new\ninformative features is the primary pathway for improving performance. However,\nevaluating every potential feature by re-training the predictor with it can be\ncostly. The paper describes an efficient, learner-independent technique for\nestimating new feature utility without re-training based on the current\npredictor's outputs. The method is obtained by deriving a connection between\nloss reduction potential and the new feature's correlation with the loss\ngradient of the current predictor. This leads to a simple yet powerful\nhypothesis testing procedure, for which we prove consistency. Our theoretical\nanalysis is accompanied by empirical evaluation on standard benchmarks and a\nlarge-scale industrial dataset.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jun 2012 15:38:18 GMT"}], "update_date": "2012-06-22", "authors_parsed": [["Koepke", "Hoyt", "", "University of Washington"], ["Bilenko", "Mikhail", "", "Microsoft\n  Research"]]}, {"id": "1206.4682", "submitter": "Barnabas Poczos", "authors": "Barnabas Poczos (Carnegie Mellon University), Zoubin Ghahramani\n  (University of Cambridge), Jeff Schneider (Carnegie Mellon University)", "title": "Copula-based Kernel Dependency Measures", "comments": "ICML2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper presents a new copula based method for measuring dependence between\nrandom variables. Our approach extends the Maximum Mean Discrepancy to the\ncopula of the joint distribution. We prove that this approach has several\nadvantageous properties. Similarly to Shannon mutual information, the proposed\ndependence measure is invariant to any strictly increasing transformation of\nthe marginal variables. This is important in many applications, for example in\nfeature selection. The estimator is consistent, robust to outliers, and uses\nrank statistics only. We derive upper bounds on the convergence rate and\npropose independence tests too. We illustrate the theoretical contributions\nthrough a series of experiments in feature selection and low-dimensional\nembedding of distributions.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jun 2012 15:40:32 GMT"}], "update_date": "2019-08-15", "authors_parsed": [["Poczos", "Barnabas", "", "Carnegie Mellon University"], ["Ghahramani", "Zoubin", "", "University of Cambridge"], ["Schneider", "Jeff", "", "Carnegie Mellon University"]]}, {"id": "1206.4762", "submitter": "Xiaotong Shen", "authors": "Charles J. Geyer", "title": "Asymptotics of Maximum Likelihood without the LLN or CLT or Sample Size\n  Going to Infinity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  If the log likelihood is approximately quadratic with constant Hessian, then\nthe maximum likelihood estimator (MLE) is approximately normally distributed.\nNo other assumptions are required. We do not need independent and identically\ndistributed data. We do not need the law of large numbers (LLN) or the central\nlimit theorem (CLT). We do not need sample size going to infinity or anything\ngoing to infinity. Presented here is a combination of Le Cam style theory\ninvolving local asymptotic normality (LAN) and local asymptotic mixed normality\n(LAMN) and Cram\\'er style theory involving derivatives and Fisher information.\nThe main tool is convergence in law of the log likelihood function and its\nderivatives considered as random elements of a Polish space of continuous\nfunctions with the metric of uniform convergence on compact sets. We obtain\nresults for both one-step-Newton estimators and Newton-iterated-to-convergence\nestimators.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jun 2012 02:22:27 GMT"}, {"version": "v2", "created": "Fri, 29 Jun 2012 20:23:26 GMT"}, {"version": "v3", "created": "Wed, 4 Jul 2012 21:26:13 GMT"}], "update_date": "2012-07-06", "authors_parsed": [["Geyer", "Charles J.", ""]]}, {"id": "1206.4765", "submitter": "Xiaotong Shen", "authors": "Yindeng Jiang and Michael D. Perlman", "title": "Reverse Exchangeability and Extreme Order Statistics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For a bivariate random vector (X,Y), symmetry conditions are presented that\nyield stochastic orderings among |X|, |Y|, |max(X,Y)|, and | min(X, Y)|.\nPartial extensions of these results for multivariate random vectors (X1,...,Xn)\nare also given.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jun 2012 03:01:31 GMT"}], "update_date": "2012-06-22", "authors_parsed": [["Jiang", "Yindeng", ""], ["Perlman", "Michael D.", ""]]}, {"id": "1206.4766", "submitter": "Xiaotong Shen", "authors": "Takeaki Kariya", "title": "A CB (corporate bond) pricing probabilities and recovery rates model for\n  deriving default probabilities and recovery rates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we formulate a corporate bond (CB) pricing model for deriving\nthe term structure of default probabilities (TSDP) and the recovery rate (RR)\nfor each pair of industry factor and credit rating grade, and these derived\nTSDP and RR are regarded as what investors imply in forming CB prices in the\nmarket at each time. A unique feature of this formulation is that the model\nallows each firm to run several business lines corresponding to some industry\ncategories, which is typical in reality. In fact, treating all the\ncross-sectional CB prices simultaneously under a credit correlation structure\nat each time makes it possible to sort out the overlapping business lines of\nthe firms which issued CBs and to extract the TSDPs for each pair of individual\nindustry factor and rating grade together with the RRs. The result is applied\nto a valuation of CDS (credit default swap) and a loan portfolio management in\nbanking business.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jun 2012 03:06:55 GMT"}, {"version": "v2", "created": "Wed, 4 Jul 2012 21:40:36 GMT"}], "update_date": "2012-07-06", "authors_parsed": [["Kariya", "Takeaki", ""]]}, {"id": "1206.4768", "submitter": "Xiaotong Shen", "authors": "Ronald C. Neath", "title": "On Convergence Properties of the Monte Carlo EM Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Expectation-Maximization (EM) algorithm (Dempster, Laird and Rubin, 1977)\nis a popular method for computing maximum likelihood estimates (MLEs) in\nproblems with missing data. Each iteration of the al- gorithm formally consists\nof an E-step: evaluate the expected complete-data log-likelihood given the\nobserved data, with expectation taken at current pa- rameter estimate; and an\nM-step: maximize the resulting expression to find the updated estimate.\nConditions that guarantee convergence of the EM se- quence to a unique MLE were\nfound by Boyles (1983) and Wu (1983). In complicated models for\nhigh-dimensional data, it is common to encounter an intractable integral in the\nE-step. The Monte Carlo EM algorithm of Wei and Tanner (1990) works around this\ndifficulty by maximizing instead a Monte Carlo approximation to the appropriate\nconditional expectation. Convergence properties of Monte Carlo EM have been\nstudied, most notably, by Chan and Ledolter (1995) and Fort and Moulines\n(2003). The goal of this review paper is to provide an accessible but rigorous\nin- troduction to the convergence properties of EM and Monte Carlo EM. No\nprevious knowledge of the EM algorithm is assumed. We demonstrate the im-\nplementation of EM and Monte Carlo EM in two simple but realistic examples. We\nshow that if the EM algorithm converges it converges to a stationary point of\nthe likelihood, and that the rate of convergence is linear at best. For Monte\nCarlo EM we present a readable proof of the main result of Chan and Ledolter\n(1995), and state without proof the conclusions of Fort and Moulines (2003). An\nimportant practical implication of Fort and Moulines's (2003) result relates to\nthe determination of Monte Carlo sample sizes in MCEM; we provide a brief\nreview of the literature (Booth and Hobert, 1999; Caffo, Jank and Jones, 2005)\non that problem.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jun 2012 03:14:11 GMT"}], "update_date": "2012-06-22", "authors_parsed": [["Neath", "Ronald C.", ""]]}, {"id": "1206.4769", "submitter": "Xiaotong Shen", "authors": "Eugenio Regazzini", "title": "The origins of de Finetti's critique of countable additivity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bruno de Finetti was one of the most convinced advocates of finitely additive\nprobabilities. The present work describes the intellectual pro- cess that led\nhim to support that stance and provides a detailed account both of the first\npaper by de Finetti on the subject and of the ensuing correspondence with\nMaurice Fr\\'echet. Moreover, the analysis is supplemented by a useful picture\nof de Finetti's interactions with the international scientific community at\nthat time, when he elaborated his subjectivistic conception of probability.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jun 2012 03:16:47 GMT"}], "update_date": "2012-06-22", "authors_parsed": [["Regazzini", "Eugenio", ""]]}, {"id": "1206.4770", "submitter": "Xiaotong Shen", "authors": "Aixin Tan and Galin L. Jones and James P. Hobert", "title": "On the Geometric Ergodicity of Two-Variable Gibbs Samplers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Markov chain is geometrically ergodic if it converges to its in- variant\ndistribution at a geometric rate in total variation norm. We study geo- metric\nergodicity of deterministic and random scan versions of the two-variable Gibbs\nsampler. We give a sufficient condition which simultaneously guarantees both\nversions are geometrically ergodic. We also develop a method for simul-\ntaneously establishing that both versions are subgeometrically ergodic. These\ngeneral results allow us to characterize the convergence rate of two-variable\nGibbs samplers in a particular family of discrete bivariate distributions.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jun 2012 03:19:20 GMT"}], "update_date": "2012-06-22", "authors_parsed": [["Tan", "Aixin", ""], ["Jones", "Galin L.", ""], ["Hobert", "James P.", ""]]}, {"id": "1206.4981", "submitter": "Shota Gugushvili", "authors": "Shota Gugushvili and Peter Spreij", "title": "Non-parametric Bayesian drift estimation for stochastic differential\n  equations", "comments": "27 pages", "journal-ref": "Lithuanian Mathematical Journal 54(2) 127-141 (2014)", "doi": "10.1007/s10986-014-9232-1", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider non-parametric Bayesian estimation of the drift coefficient of a\none-dimensional stochastic differential equation from discrete-time\nobservations on the solution of this equation. Under suitable regularity\nconditions that are weaker than those previosly suggested in the literature, we\nestablish posterior consistency in this context. Furthermore, we show that\nposterior consistency extends to the multidimensional setting as well, which,\nto the best of our knowledge, is a new result in this setting.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jun 2012 19:11:24 GMT"}, {"version": "v2", "created": "Mon, 25 Feb 2013 20:41:34 GMT"}], "update_date": "2014-07-15", "authors_parsed": [["Gugushvili", "Shota", ""], ["Spreij", "Peter", ""]]}, {"id": "1206.5057", "submitter": "Qinghuai Gao", "authors": "Qinghuai Gao", "title": "The Robustness and Super-Robustness of L^p Estimation, when p < 1", "comments": "In v4, fix the issues in the proof of the general cases: proof the\n  strict robustness on translation when di has general or uniform distribution.\n  Format changes in v5", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.TH", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  In robust statistics, the breakdown point of an estimator is the percentage\nof outliers with which an estimator still generates reliable estimation. The\nupper bound of breakdown point is 50%, which means it is not possible to\ngenerate reliable estimation with more than half outliers.\n  In this paper, it is shown that for majority of experiences, when the\noutliers exceed 50%, but if they are distributed randomly enough, it is still\npossible to generate a reliable estimation from minority good observations. The\nphenomenal of that the breakdown point is larger than 50% is named as super\nrobustness. And, in this paper, a robust estimator is called strict robust if\nit generates a perfect estimation when all the good observations are perfect.\n  More specifically, the super robustness of the maximum likelihood estimator\nof the exponential power distribution, or L^p estimation, where p<1, is\ninvestigated. This paper starts with proving that L^p (p<1) is a strict robust\nlocation estimator. Further, it is proved that L^p (p < 1)has the property of\nstrict super-robustness on translation, rotation, scaling transformation and\nrobustness on Euclidean transform.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jun 2012 05:29:48 GMT"}, {"version": "v2", "created": "Sun, 8 Jul 2012 19:30:40 GMT"}, {"version": "v3", "created": "Tue, 10 Jul 2012 06:07:54 GMT"}, {"version": "v4", "created": "Thu, 9 Aug 2012 03:55:32 GMT"}, {"version": "v5", "created": "Thu, 11 Oct 2012 16:01:22 GMT"}], "update_date": "2012-10-12", "authors_parsed": [["Gao", "Qinghuai", ""]]}, {"id": "1206.5070", "submitter": "Dominik Wied", "authors": "Dominik Wied and Herold Dehling and Maarten van Kampen and Daniel\n  Vogel", "title": "A fluctuation test for constant Spearman's rho with nuisance-free limit\n  distribution", "comments": null, "journal-ref": null, "doi": "10.1016/j.csda.2013.03.005", "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A CUSUM type test for constant correlation that goes beyond a previously\nsuggested correlation constancy test by considering Spearman's rho in arbitrary\ndimensions is proposed. Since the new test does not require the existence of\nany moments, the applicability on usually heavy-tailed financial data is\ngreatly improved. The asymptotic null distribution is calculated using an\ninvariance principle for the sequential empirical copula process. The limit\ndistribution is free of nuisance parameters and critical values can be obtained\nwithout bootstrap techniques. A local power result and an analysis of the\nbehavior of the test in small samples is provided.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jun 2012 07:12:15 GMT"}, {"version": "v2", "created": "Thu, 30 Jan 2014 09:13:11 GMT"}], "update_date": "2014-01-31", "authors_parsed": [["Wied", "Dominik", ""], ["Dehling", "Herold", ""], ["van Kampen", "Maarten", ""], ["Vogel", "Daniel", ""]]}, {"id": "1206.5449", "submitter": "Tom Fischer Prof. Dr.", "authors": "Tom Fischer", "title": "Existence, uniqueness, and minimality of the Jordan measure\n  decomposition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is a note of purely didactical purpose as the proof of the Jordan\nmeasure decomposition is often omitted in the related literature. Elementary\nproofs are provided for the existence, the uniqueness, and the minimality\nproperty of the Jordan decomposition for a finite signed measure.\n", "versions": [{"version": "v1", "created": "Sat, 23 Jun 2012 22:58:54 GMT"}, {"version": "v2", "created": "Wed, 27 Jun 2012 15:15:34 GMT"}], "update_date": "2012-06-28", "authors_parsed": [["Fischer", "Tom", ""]]}, {"id": "1206.5628", "submitter": "Sarah Lemler", "authors": "Sarah Lemler (SG)", "title": "Oracle inequalities for the Lasso in the high-dimensional Aalen\n  multiplicative intensity model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a general counting process setting, we consider the problem of obtaining a\nprognostic on the survival time adjusted on covariates in high-dimension.\nTowards this end, we construct an estimator of the whole conditional intensity.\nWe estimate it by the best Cox proportional hazards model given two\ndictionaries of functions. The first dictionary is used to construct an\napproximation of the logarithm of the baseline hazard function and the second\nto approximate the relative risk. We introduce a new data-driven weighted Lasso\nprocedure to estimate the unknown parameters of the best Cox model\napproximating the intensity. We provide non-asymptotic oracle inequalities for\nour procedure in terms of an appropriate empirical Kullback divergence. Our\nresults rely on an empirical Bernstein's inequality for martingales with jumps\nand properties of modified self-concordant functions.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jun 2012 09:52:54 GMT"}, {"version": "v2", "created": "Tue, 27 Nov 2012 08:27:59 GMT"}, {"version": "v3", "created": "Wed, 19 Jun 2013 10:18:15 GMT"}, {"version": "v4", "created": "Mon, 14 Oct 2013 06:26:48 GMT"}], "update_date": "2013-10-15", "authors_parsed": [["Lemler", "Sarah", "", "SG"]]}, {"id": "1206.5637", "submitter": "Edith Cohen", "authors": "Edith Cohen and Haim Kaplan", "title": "What you can do with Coordinated Samples", "comments": "4 figures, 21 pages, Extended Abstract appeared in RANDOM 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sample coordination, where similar instances have similar samples, was\nproposed by statisticians four decades ago as a way to maximize overlap in\nrepeated surveys. Coordinated sampling had been since used for summarizing\nmassive data sets.\n  The usefulness of a sampling scheme hinges on the scope and accuracy within\nwhich queries posed over the original data can be answered from the sample. We\naim here to gain a fundamental understanding of the limits and potential of\ncoordination. Our main result is a precise characterization, in terms of simple\nproperties of the estimated function, of queries for which estimators with\ndesirable properties exist. We consider unbiasedness, nonnegativity, finite\nvariance, and bounded estimates.\n  Since generally a single estimator can not be optimal (minimize variance\nsimultaneously) for all data, we propose {\\em variance competitiveness}, which\nmeans that the expectation of the square on any data is not too far from the\nminimum one possible for the data. Surprisingly perhaps, we show how to\nconstruct, for any function for which an unbiased nonnegative estimator exists,\na variance competitive estimator.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jun 2012 10:35:28 GMT"}, {"version": "v2", "created": "Thu, 28 Jun 2012 07:14:14 GMT"}, {"version": "v3", "created": "Fri, 30 Nov 2012 06:42:00 GMT"}, {"version": "v4", "created": "Wed, 12 Jun 2013 11:04:47 GMT"}, {"version": "v5", "created": "Wed, 24 Jul 2013 18:27:33 GMT"}, {"version": "v6", "created": "Fri, 2 Aug 2013 17:24:24 GMT"}], "update_date": "2013-08-05", "authors_parsed": [["Cohen", "Edith", ""], ["Kaplan", "Haim", ""]]}, {"id": "1206.5687", "submitter": "Silvia Bianconcini", "authors": "Silvia Bianconcini", "title": "Asymptotic properties of adaptive maximum likelihood estimators in\n  latent variable models", "comments": "Published in at http://dx.doi.org/10.3150/13-BEJ531 the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2014, Vol. 20, No. 3, 1507-1531", "doi": "10.3150/13-BEJ531", "report-no": "IMS-BEJ-BEJ531", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Latent variable models have been widely applied in different fields of\nresearch in which the constructs of interest are not directly observable, so\nthat one or more latent variables are required to reduce the complexity of the\ndata. In these cases, problems related to the integration of the likelihood\nfunction of the model arise since analytical solutions do not exist. In the\nrecent literature, a numerical technique that has been extensively applied to\nestimate latent variable models is the adaptive Gauss-Hermite quadrature. It\nprovides a good approximation of the integral, and it is more feasible than\nclassical numerical techniques in presence of many latent variables and/or\nrandom effects. In this paper, we formally investigate the properties of\nmaximum likelihood estimators based on adaptive quadratures used to perform\ninference in generalized linear latent variable models.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jun 2012 14:11:02 GMT"}, {"version": "v2", "created": "Fri, 29 Jun 2012 10:53:56 GMT"}, {"version": "v3", "created": "Mon, 22 Jul 2013 08:59:55 GMT"}, {"version": "v4", "created": "Fri, 4 Jul 2014 13:21:31 GMT"}], "update_date": "2014-07-07", "authors_parsed": [["Bianconcini", "Silvia", ""]]}, {"id": "1206.5761", "submitter": "Mathias Vetter", "authors": "Mathias Vetter", "title": "Estimation of integrated volatility of volatility with applications to\n  goodness-of-fit testing", "comments": "Published at http://dx.doi.org/10.3150/14-BEJ648 in the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2015, Vol. 21, No. 4, 2393-2418", "doi": "10.3150/14-BEJ648", "report-no": "IMS-BEJ-BEJ648", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we are concerned with nonparametric inference on the\nvolatility of volatility process in stochastic volatility models. We construct\nseveral estimators for its integrated version in a high-frequency setting, all\nbased on increments of spot volatility estimators. Some of those are positive\nby construction, others are bias corrected in order to attain the optimal rate\n$n^{-1/4}$. Associated central limit theorems are proven which can be widely\nused in practice, as they are the key to essentially all tools in model\nvalidation for stochastic volatility models. As an illustration we give a brief\nidea on a goodness-of-fit test in order to check for a certain parametric form\nof volatility of volatility.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jun 2012 18:32:24 GMT"}, {"version": "v2", "created": "Tue, 29 Sep 2015 09:14:14 GMT"}], "update_date": "2015-09-30", "authors_parsed": [["Vetter", "Mathias", ""]]}, {"id": "1206.5862", "submitter": "Tamara Broderick", "authors": "Tamara Broderick, Michael I. Jordan, Jim Pitman", "title": "Cluster and Feature Modeling from Combinatorial Stochastic Processes", "comments": "Published in at http://dx.doi.org/10.1214/13-STS434 the Statistical\n  Science (http://www.imstat.org/sts/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Statistical Science 2013, Vol. 28, No. 3, 289-312", "doi": "10.1214/13-STS434", "report-no": "IMS-STS-STS434", "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the focal points of the modern literature on Bayesian nonparametrics\nhas been the problem of clustering, or partitioning, where each data point is\nmodeled as being associated with one and only one of some collection of groups\ncalled clusters or partition blocks. Underlying these Bayesian nonparametric\nmodels are a set of interrelated stochastic processes, most notably the\nDirichlet process and the Chinese restaurant process. In this paper we provide\na formal development of an analogous problem, called feature modeling, for\nassociating data points with arbitrary nonnegative integer numbers of groups,\nnow called features or topics. We review the existing combinatorial stochastic\nprocess representations for the clustering problem and develop analogous\nrepresentations for the feature modeling problem. These representations include\nthe beta process and the Indian buffet process as well as new representations\nthat provide insight into the connections between these processes. We thereby\nbring the same level of completeness to the treatment of Bayesian nonparametric\nfeature modeling that has previously been achieved for Bayesian nonparametric\nclustering.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jun 2012 00:08:50 GMT"}, {"version": "v2", "created": "Tue, 1 Oct 2013 07:33:31 GMT"}], "update_date": "2013-10-02", "authors_parsed": [["Broderick", "Tamara", ""], ["Jordan", "Michael I.", ""], ["Pitman", "Jim", ""]]}, {"id": "1206.6053", "submitter": "Le-Yu Chen", "authors": "Le-Yu Chen and Jerzy Szroeter", "title": "Testing Multiple Inequality Hypotheses : A Smoothed Indicator Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a class of origin-smooth approximators of indicators\nunderlying the sum-of-negative-part statistic for testing multiple\ninequalities. The need for simulation or bootstrap to obtain test critical\nvalues is thereby obviated. A simple procedure is enabled using fixed critical\nvalues. The test is shown to have correct asymptotic size in the uniform sense\nthat supremum finite-sample rejection probability over null-restricted data\ndistributions tends asymptotically to nominal significance level. This applies\nunder weak assumptions allowing for estimator covariance singularity. The test\nis unbiased for a wide class of local alternatives. A new theorem establishes\ndirections in which the test is locally most powerful. The proposed procedure\nis compared with predominant existing tests in structure, theory and\nsimulation.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jun 2012 17:11:38 GMT"}], "update_date": "2012-06-27", "authors_parsed": [["Chen", "Le-Yu", ""], ["Szroeter", "Jerzy", ""]]}, {"id": "1206.6128", "submitter": "Daniel McDonald", "authors": "Darren Homrighausen and Daniel J. McDonald", "title": "Leave-one-out cross-validation is risk consistent for lasso", "comments": "15 pages, 0 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The lasso procedure is ubiquitous in the statistical and signal processing\nliterature, and as such, is the target of substantial theoretical and applied\nresearch. While much of this research focuses on the desirable properties that\nlasso possesses---predictive risk consistency, sign consistency, correct model\nselection---all of it has assumes that the tuning parameter is chosen in an\noracle fashion. Yet, this is impossible in practice. Instead, data analysts\nmust use the data twice, once to choose the tuning parameter and again to\nestimate the model. But only heuristics have ever justified such a procedure.\nTo this end, we give the first definitive answer about the risk consistency of\nlasso when the smoothing parameter is chosen via cross-validation. We show that\nunder some restrictions on the design matrix, the lasso estimator is still risk\nconsistent with an empirically chosen tuning parameter.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jun 2012 21:42:46 GMT"}, {"version": "v2", "created": "Sun, 4 Aug 2013 13:43:44 GMT"}], "update_date": "2013-08-06", "authors_parsed": [["Homrighausen", "Darren", ""], ["McDonald", "Daniel J.", ""]]}, {"id": "1206.6367", "submitter": "Mark Tygert", "authors": "Jacob Carruth, Mark Tygert, and Rachel Ward", "title": "A comparison of the discrete Kolmogorov-Smirnov statistic and the\n  Euclidean distance", "comments": "15 pages, 6 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Goodness-of-fit tests gauge whether a given set of observations is consistent\n(up to expected random fluctuations) with arising as independent and\nidentically distributed (i.i.d.) draws from a user-specified probability\ndistribution known as the \"model.\" The standard gauges involve the discrepancy\nbetween the model and the empirical distribution of the observed draws. Some\nmeasures of discrepancy are cumulative; others are not. The most popular\ncumulative measure is the Kolmogorov-Smirnov statistic; when all probability\ndistributions under consideration are discrete, a natural noncumulative measure\nis the Euclidean distance between the model and the empirical distributions. In\nthe present paper, both mathematical analysis and its illustration via various\ndata sets indicate that the Kolmogorov-Smirnov statistic tends to be more\npowerful than the Euclidean distance when there is a natural ordering for the\nvalues that the draws can take -- that is, when the data is ordinal -- whereas\nthe Euclidean distance is more reliable and more easily understood than the\nKolmogorov-Smirnov statistic when there is no natural ordering (or partial\norder) -- that is, when the data is nominal.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 19:15:25 GMT"}], "update_date": "2012-06-28", "authors_parsed": [["Carruth", "Jacob", ""], ["Tygert", "Mark", ""], ["Ward", "Rachel", ""]]}, {"id": "1206.6378", "submitter": "Mark Tygert", "authors": "William Perkins, Gary Simon, and Mark Tygert", "title": "Computing the asymptotic power of a Euclidean-distance test for\n  goodness-of-fit", "comments": "14 pages, 1 figure, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A natural (yet unconventional) test for goodness-of-fit measures the\ndiscrepancy between the model and empirical distributions via their Euclidean\ndistance (or, equivalently, via its square). The present paper characterizes\nthe statistical power of such a test against a family of alternative\ndistributions, in the limit that the number of observations is large, with\nevery alternative departing from the model in the same direction. Specifically,\nthe paper provides an efficient numerical method for evaluating the cumulative\ndistribution function (cdf) of the square of the Euclidean distance between the\nmodel and empirical distributions under the alternatives, in the limit that the\nnumber of observations is large. The paper illustrates the scheme by plotting\nthe asymptotic power (as a function of the significance level) for several\nexamples.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 19:56:14 GMT"}], "update_date": "2012-06-28", "authors_parsed": [["Perkins", "William", ""], ["Simon", "Gary", ""], ["Tygert", "Mark", ""]]}, {"id": "1206.6536", "submitter": "Li Zhang", "authors": "Li Zhang", "title": "Nearly optimal minimax estimator for high-dimensional sparse linear\n  regression", "comments": "Published in at http://dx.doi.org/10.1214/13-AOS1141 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2013, Vol. 41, No. 4, 2149-2175", "doi": "10.1214/13-AOS1141", "report-no": "IMS-AOS-AOS1141", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present estimators for a well studied statistical estimation problem: the\nestimation for the linear regression model with soft sparsity constraints\n($\\ell_q$ constraint with $0<q\\leq1$) in the high-dimensional setting. We first\npresent a family of estimators, called the projected nearest neighbor estimator\nand show, by using results from Convex Geometry, that such estimator is within\na logarithmic factor of the optimal for any design matrix. Then by utilizing a\nsemi-definite programming relaxation technique developed in [SIAM J. Comput. 36\n(2007) 1764-1776], we obtain an approximation algorithm for computing the\nminimax risk for any such estimation task and also a polynomial time nearly\noptimal estimator for the important case of $\\ell_1$ sparsity constraint. Such\nresults were only known before for special cases, despite decades of studies on\nthis problem. We also extend the method to the adaptive case when the parameter\nradius is unknown.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 22:54:47 GMT"}, {"version": "v2", "created": "Thu, 23 May 2013 00:50:28 GMT"}, {"version": "v3", "created": "Fri, 8 Nov 2013 13:07:10 GMT"}], "update_date": "2013-11-11", "authors_parsed": [["Zhang", "Li", ""]]}, {"id": "1206.6658", "submitter": "Luai Al Labadi", "authors": "Luai Al Labadi, Mahmoud Zarepour", "title": "On Some Asymptotic Properties and an Almost Sure Approximation of the\n  Normalized Inverse-Gaussian Process", "comments": "25", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present some asymptotic properties of the normalized\ninverse-Gaussian process. In particular, when the concentration parameter is\nlarge, we establish an analogue of the empirical functional central limit\ntheorem, the strong law of large numbers and the Glivenko-Cantelli theorem for\nthe normalized inverse-Gaussian process and its corresponding quantile process.\nWe also derive a finite sum-representation that converges almost surely to the\nFerguson and Klass representation of the normalized inverse-Gaussian process.\nThis almost sure approximation can be used to simulate efficiently the\nnormalized inverse-Gaussian process.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jun 2012 12:30:38 GMT"}], "update_date": "2012-06-29", "authors_parsed": [["Labadi", "Luai Al", ""], ["Zarepour", "Mahmoud", ""]]}, {"id": "1206.6721", "submitter": "Sara van de Geer", "authors": "Sara van de Geer, Patric M\\\"uller", "title": "Quasi-Likelihood and/or Robust Estimation in High Dimensions", "comments": "Published in at http://dx.doi.org/10.1214/12-STS397 the Statistical\n  Science (http://www.imstat.org/sts/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Statistical Science 2012, Vol. 27, No. 4, 469-480", "doi": "10.1214/12-STS397", "report-no": "IMS-STS-STS397", "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the theory for the high-dimensional generalized linear model with\nthe Lasso. After a short review on theoretical results in literature, we\npresent an extension of the oracle results to the case of quasi-likelihood\nloss. We prove bounds for the prediction error and $\\ell_1$-error. The results\nare derived under fourth moment conditions on the error distribution. The case\nof robust loss is also given. We moreover show that under an irrepresentable\ncondition, the $\\ell_1$-penalized quasi-likelihood estimator has no false\npositives.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jun 2012 15:09:16 GMT"}, {"version": "v2", "created": "Fri, 4 Jan 2013 14:13:32 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["van de Geer", "Sara", ""], ["M\u00fcller", "Patric", ""]]}, {"id": "1206.6904", "submitter": "Javier L\\'opez Pe\\~na", "authors": "Javier L\\'opez Pe\\~na and Hugo Touchette", "title": "A network theory analysis of football strategies", "comments": "6 pages, 1 figure, 5 tables", "journal-ref": "In C. Clanet (ed.), Sports Physics: Proc. 2012 Euromech Physics of\n  Sports Conference, p. 517-528, \\'Editions de l'\\'Ecole Polytechnique,\n  Palaiseau, 2013. (ISBN 978-2-7302-1615-9)", "doi": null, "report-no": null, "categories": "math.CO math.ST physics.soc-ph stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We showcase in this paper the use of some tools from network theory to\ndescribe the strategy of football teams. Using passing data made available by\nFIFA during the 2010 World Cup, we construct for each team a weighted and\ndirected network in which nodes correspond to players and arrows to passes. The\nresulting network or graph provides a direct visual inspection of a team's\nstrategy, from which we can identify play pattern, determine hot-spots on the\nplay and localize potential weaknesses. Using different centrality measures, we\ncan also determine the relative importance of each player in the game, the\n`popularity' of a player, and the effect of removing players from the game.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jun 2012 21:34:09 GMT"}], "update_date": "2013-12-03", "authors_parsed": [["Pe\u00f1a", "Javier L\u00f3pez", ""], ["Touchette", "Hugo", ""]]}, {"id": "1206.6913", "submitter": "Xiaotong Shen", "authors": "Persi Diaconis, Susan Holmes and Mehrdad Shahshahani", "title": "Sampling From A Manifold", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop algorithms for sampling from a probability distribution on a\nsubmanifold embedded in Rn. Applications are given to the evaluation of\nalgorithms in 'Topological Statistics'; to goodness of fit tests in exponential\nfamilies and to Neyman's smooth test. This article is partially expository,\ngiving an introduction to the tools of geometric measure theory.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jun 2012 23:04:51 GMT"}, {"version": "v2", "created": "Wed, 4 Jul 2012 21:36:23 GMT"}], "update_date": "2012-07-06", "authors_parsed": [["Diaconis", "Persi", ""], ["Holmes", "Susan", ""], ["Shahshahani", "Mehrdad", ""]]}, {"id": "1206.6927", "submitter": "Cheryl Brooks", "authors": "Cheryl J. Flynn, Patrick O. Perry", "title": "Profile Likelihood Biclustering", "comments": "40 pages, 11 figures; R package in development at\n  https://github.com/patperry/biclustpl", "journal-ref": "Electron. J. Statist., Volume 14, Number 1 (2020), 731-768", "doi": "10.1214/19-EJS1667", "report-no": null, "categories": "stat.ME math.ST stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Biclustering, the process of simultaneously clustering the rows and columns\nof a data matrix, is a popular and effective tool for finding structure in a\nhigh-dimensional dataset. Many biclustering procedures appear to work well in\npractice, but most do not have associated consistency guarantees. To address\nthis shortcoming, we propose a new biclustering procedure based on profile\nlikelihood. The procedure applies to a broad range of data modalities,\nincluding binary, count, and continuous observations. We prove that the\nprocedure recovers the true row and column classes when the dimensions of the\ndata matrix tend to infinity, even if the functional form of the data\ndistribution is misspecified. The procedure requires computing a combinatorial\nsearch, which can be expensive in practice. Rather than performing this search\ndirectly, we propose a new heuristic optimization procedure based on the\nKernighan-Lin heuristic, which has nice computational properties and performs\nwell in simulations. We demonstrate our procedure with applications to\ncongressional voting records, and microarray analysis.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jun 2012 01:19:35 GMT"}, {"version": "v2", "created": "Fri, 4 Jan 2013 19:49:59 GMT"}, {"version": "v3", "created": "Fri, 8 Jan 2016 17:16:09 GMT"}, {"version": "v4", "created": "Tue, 2 Jun 2020 18:48:47 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Flynn", "Cheryl J.", ""], ["Perry", "Patrick O.", ""]]}, {"id": "1206.6951", "submitter": "Michel Broniatowski", "authors": "Michel Broniatowski (LSTA), Zhansheng Cao (LSTA)", "title": "A conditional limit theorem for random walks under extreme deviation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores a conditional Gibbs theorem for a random walkinduced by\ni.i.d. (X_{1},..,X_{n}) conditioned on an extreme deviation of its sum\n(S_{1}^{n}=na_{n}) or (S_{1}^{n}>na_{n}) where a_{n}\\rightarrow\\infty. It is\nproved that when the summands have light tails with some additional regulatity\nproperty, then the asymptotic conditional distribution of X_{1} can be\napproximated in variation norm by the tilted distribution at point a_{n},\nextending therefore the classical LDP case.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jun 2012 06:40:27 GMT"}], "update_date": "2012-07-04", "authors_parsed": [["Broniatowski", "Michel", "", "LSTA"], ["Cao", "Zhansheng", "", "LSTA"]]}, {"id": "1206.6961", "submitter": "Yoichi Nishiyama", "authors": "Ilia Negri and Yoichi Nishiyama", "title": "Moment convergence of $Z$-estimators and $Z$-process method for change\n  point problems", "comments": "28 pages", "journal-ref": null, "doi": null, "report-no": "Research Memorandum 1158, The Institute of Statistical Mathematics,\n  Tokyo", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem to establish not only the asymptotic distribution results for\nstatistical estimators but also the moment convergence of the estimators has\nbeen recognized as an important issue in advanced theories of statistics. One\nof the main goals of this paper is to present a metod to derive the moment\nconvergence of $Z$-estimators as it has been done for $M$-estimators. Another\ngoal of this paper is to develop a general, unified approach, based on some\npartial estimation functions which we call \"$Z$-process\", to the change point\nproblems for ergodic models as well as some models where the Fisher information\nmatrix is random and inhomogeneous in time. Applications to some diffusion\nprocess models and Cox's regression model are also discussed.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jun 2012 08:34:58 GMT"}], "update_date": "2012-07-02", "authors_parsed": [["Negri", "Ilia", ""], ["Nishiyama", "Yoichi", ""]]}, {"id": "1206.7020", "submitter": "Alberto Hernando", "authors": "A. Hernando, A. Plastino", "title": "The thermodynamics of urban population flows", "comments": null, "journal-ref": null, "doi": "10.1103/PhysRevE.86.066105", "report-no": null, "categories": "physics.soc-ph math.ST stat.TH", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Orderliness, reflected via mathematical laws, is encountered in different\nframeworks involving social groups. Here we show that a thermodynamics can be\nconstructed that macroscopically describes urban population flows. Microscopic\ndynamic equations and simulations with random walkers underlie the macroscopic\napproach. Our results might be regarded, via suitable analogies, as a step\ntowards building an explicit social thermodynamics.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jun 2012 13:35:50 GMT"}], "update_date": "2015-04-30", "authors_parsed": [["Hernando", "A.", ""], ["Plastino", "A.", ""]]}, {"id": "1206.7101", "submitter": "Mahendra Mariadassou", "authors": "Mahendra Mariadassou, Catherine Matias", "title": "Convergence of the groups posterior distribution in latent or stochastic\n  block models", "comments": "Published at http://dx.doi.org/10.3150/13-BEJ579 in the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2015, Vol. 21, No. 1, 537-573", "doi": "10.3150/13-BEJ579", "report-no": "IMS-BEJ-BEJ579", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a unified framework for studying both latent and stochastic block\nmodels, which are used to cluster simultaneously rows and columns of a data\nmatrix. In this new framework, we study the behaviour of the groups posterior\ndistribution, given the data. We characterize whether it is possible to\nasymptotically recover the actual groups on the rows and columns of the matrix,\nrelying on a consistent estimate of the parameter. In other words, we establish\nsufficient conditions for the groups posterior distribution to converge (as the\nsize of the data increases) to a Dirac mass located at the actual (random)\ngroups configuration. In particular, we highlight some cases where the model\nassumes symmetries in the matrix of connection probabilities that prevents\nrecovering the original groups. We also discuss the validity of these results\nwhen the proportion of non-null entries in the data matrix converges to zero.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jun 2012 18:53:34 GMT"}, {"version": "v2", "created": "Sat, 10 Aug 2013 07:34:26 GMT"}, {"version": "v3", "created": "Tue, 14 Apr 2015 10:41:50 GMT"}], "update_date": "2015-04-15", "authors_parsed": [["Mariadassou", "Mahendra", ""], ["Matias", "Catherine", ""]]}]