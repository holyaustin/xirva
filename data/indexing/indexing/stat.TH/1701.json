[{"id": "1701.00056", "submitter": "Eftychios A. Pnevmatikakis", "authors": "Eftychios A. Pnevmatikakis", "title": "Compressed sensing and optimal denoising of monotone signals", "comments": "To appear in the 42nd IEEE International Conference on Acoustics,\n  Speech and Signal Processing ICASSP2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT math.IT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problems of compressed sensing and optimal denoising for\nsignals $\\mathbf{x_0}\\in\\mathbb{R}^N$ that are monotone, i.e.,\n$\\mathbf{x_0}(i+1) \\geq \\mathbf{x_0}(i)$, and sparsely varying, i.e.,\n$\\mathbf{x_0}(i+1) > \\mathbf{x_0}(i)$ only for a small number $k$ of indices\n$i$. We approach the compressed sensing problem by minimizing the total\nvariation norm restricted to the class of monotone signals subject to equality\nconstraints obtained from a number of measurements $A\\mathbf{x_0}$. For random\nGaussian sensing matrices $A\\in\\mathbb{R}^{m\\times N}$ we derive a closed form\nexpression for the number of measurements $m$ required for successful\nreconstruction with high probability. We show that the probability undergoes a\nphase transition as $m$ varies, and depends not only on the number of change\npoints, but also on their location. For denoising we regularize with the same\nnorm and derive a formula for the optimal regularizer weight that depends only\nmildly on $\\mathbf{x_0}$. We obtain our results using the statistical dimension\ntool.\n", "versions": [{"version": "v1", "created": "Sat, 31 Dec 2016 03:53:47 GMT"}], "update_date": "2017-01-03", "authors_parsed": [["Pnevmatikakis", "Eftychios A.", ""]]}, {"id": "1701.00311", "submitter": "Yun Yang", "authors": "Yun Yang and Debdeep Pati", "title": "Bayesian model selection consistency and oracle inequality with\n  intractable marginal likelihood", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we investigate large sample properties of model selection\nprocedures in a general Bayesian framework when a closed form expression of the\nmarginal likelihood function is not available or a local asymptotic quadratic\napproximation of the log-likelihood function does not exist. Under appropriate\nidentifiability assumptions on the true model, we provide sufficient conditions\nfor a Bayesian model selection procedure to be consistent and obey the Occam's\nrazor phenomenon, i.e., the probability of selecting the \"smallest\" model that\ncontains the truth tends to one as the sample size goes to infinity. In order\nto show that a Bayesian model selection procedure selects the smallest model\ncontaining the truth, we impose a prior anti-concentration condition, requiring\nthe prior mass assigned by large models to a neighborhood of the truth to be\nsufficiently small. In a more general setting where the strong model\nidentifiability assumption may not hold, we introduce the notion of local\nBayesian complexity and develop oracle inequalities for Bayesian model\nselection procedures. Our Bayesian oracle inequality characterizes a trade-off\nbetween the approximation error and a Bayesian characterization of the local\ncomplexity of the model, illustrating the adaptive nature of averaging-based\nBayesian procedures towards achieving an optimal rate of posterior convergence.\nSpecific applications of the model selection theory are discussed in the\ncontext of high-dimensional nonparametric regression and density regression\nwhere the regression function or the conditional density is assumed to depend\non a fixed subset of predictors. As a result of independent interest, we\npropose a general technique for obtaining upper bounds of certain small ball\nprobability of stationary Gaussian processes.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jan 2017 03:55:55 GMT"}, {"version": "v2", "created": "Mon, 9 Jan 2017 14:47:23 GMT"}], "update_date": "2017-01-10", "authors_parsed": [["Yang", "Yun", ""], ["Pati", "Debdeep", ""]]}, {"id": "1701.00652", "submitter": "David Gross", "authors": "Aditya Kela, Kai von Prillwitz, Johan Aberg, Rafael Chaves, David\n  Gross", "title": "Semidefinite tests for latent causal structures", "comments": "25 pages, 7 figures", "journal-ref": "IEEE Transactions on Information Theory 66, 339 (2019)", "doi": "10.1109/TIT.2019.2935755", "report-no": null, "categories": "stat.ML math.ST quant-ph stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Testing whether a probability distribution is compatible with a given\nBayesian network is a fundamental task in the field of causal inference, where\nBayesian networks model causal relations. Here we consider the class of causal\nstructures where all correlations between observed quantities are solely due to\nthe influence from latent variables. We show that each model of this type\nimposes a certain signature on the observable covariance matrix in terms of a\nparticular decomposition into positive semidefinite components. This signature,\nand thus the underlying hypothetical latent structure, can be tested in a\ncomputationally efficient manner via semidefinite programming. This stands in\nstark contrast with the algebraic geometric tools required if the full\nobservable probability distribution is taken into account. The semidefinite\ntest is compared with tests based on entropic inequalities.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jan 2017 11:12:18 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Kela", "Aditya", ""], ["von Prillwitz", "Kai", ""], ["Aberg", "Johan", ""], ["Chaves", "Rafael", ""], ["Gross", "David", ""]]}, {"id": "1701.00858", "submitter": "Thibault Lesieur", "authors": "Thibault Lesieur, Florent Krzakala and Lenka Zdeborov\\'a", "title": "Constrained Low-rank Matrix Estimation: Phase Transitions, Approximate\n  Message Passing and Applications", "comments": "64 pages, 12 figures", "journal-ref": "J. Stat. Mech. 7 (2017) 073403", "doi": "10.1088/1742-5468/aa7284", "report-no": null, "categories": "math.ST cond-mat.stat-mech cs.IT math.IT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article is an extended version of previous work of the authors [40, 41]\non low-rank matrix estimation in the presence of constraints on the factors\ninto which the matrix is factorized. Low-rank matrix factorization is one of\nthe basic methods used in data analysis for unsupervised learning of relevant\nfeatures and other types of dimensionality reduction. We present a framework to\nstudy the constrained low-rank matrix estimation for a general prior on the\nfactors, and a general output channel through which the matrix is observed. We\ndraw a paralel with the study of vector-spin glass models - presenting a\nunifying way to study a number of problems considered previously in separate\nstatistical physics works. We present a number of applications for the problem\nin data analysis. We derive in detail a general form of the low-rank\napproximate message passing (Low- RAMP) algorithm, that is known in statistical\nphysics as the TAP equations. We thus unify the derivation of the TAP equations\nfor models as different as the Sherrington-Kirkpatrick model, the restricted\nBoltzmann machine, the Hopfield model or vector (xy, Heisenberg and other) spin\nglasses. The state evolution of the Low-RAMP algorithm is also derived, and is\nequivalent to the replica symmetric solution for the large class of vector-spin\nglass models. In the section devoted to result we study in detail phase\ndiagrams and phase transitions for the Bayes-optimal inference in low-rank\nmatrix estimation. We present a typology of phase transitions and their\nrelation to performance of algorithms such as the Low-RAMP or commonly used\nspectral methods.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jan 2017 22:50:47 GMT"}, {"version": "v2", "created": "Fri, 10 Feb 2017 14:16:30 GMT"}, {"version": "v3", "created": "Tue, 18 Jul 2017 22:26:49 GMT"}], "update_date": "2017-08-28", "authors_parsed": [["Lesieur", "Thibault", ""], ["Krzakala", "Florent", ""], ["Zdeborov\u00e1", "Lenka", ""]]}, {"id": "1701.00888", "submitter": "Shih-Hao Huang", "authors": "Shih-Hao Huang, Mong-Na Lo Huang, Kerby Shedden and Weng Kee Wong", "title": "Optimal group testing designs for estimating prevalence with uncertain\n  testing errors", "comments": null, "journal-ref": null, "doi": "10.1111/rssb.12223", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We construct optimal designs for group testing experiments where the goal is\nto estimate the prevalence of a trait by using a test with uncertain\nsensitivity and specificity. Using optimal design theory for approximate\ndesigns, we show that the most efficient design for simultaneously estimating\nthe prevalence, sensitivity and specificity requires three different group\nsizes with equal frequencies. However, if estimating prevalence as accurately\nas possible is the only focus, the optimal strategy is to have three group\nsizes with unequal frequencies. On the basis of a chlamydia study in the\nU.S.A., we compare performances of competing designs and provide insights into\nhow the unknown sensitivity and specificity of the test affect the performance\nof the prevalence estimator. We demonstrate that the locally D- and Ds-optimal\ndesigns proposed have high efficiencies even when the prespecified values of\nthe parameters are moderately misspecified.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jan 2017 02:50:15 GMT"}], "update_date": "2017-01-05", "authors_parsed": [["Huang", "Shih-Hao", ""], ["Huang", "Mong-Na Lo", ""], ["Shedden", "Kerby", ""], ["Wong", "Weng Kee", ""]]}, {"id": "1701.01199", "submitter": "Jiwoong Kim", "authors": "Jiwoong Kim", "title": "Generalized Minimum Distance Estimators in Linear Regression with\n  Dependent Errors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper discusses minimum distance estimation method in the linear\nregression model with dependent errors which are strongly mixing. The\nregression parameters are estimated through the minimum distance estimation\nmethod, and asymptotic distributional properties of the estimators are\ndiscussed. A simulation study compares the performance of the minimum distance\nestimator with other well celebrated estimator. This simulation study shows the\nsuperiority of the minimum distance estimator over another estimator. KoulMde\n(R package) which was used for the simulation study is available online. See\nsection 4 for the detail.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jan 2017 03:05:21 GMT"}], "update_date": "2017-01-06", "authors_parsed": [["Kim", "Jiwoong", ""]]}, {"id": "1701.01340", "submitter": "Marta Ferreira", "authors": "Helena Ferreira and Marta Ferreira", "title": "Multidimensional extremal dependence coefficients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extreme values modeling has attracting the attention of researchers in\ndiverse areas such as the environment, engineering, or finance. Multivariate\nextreme value distributions are particularly suitable to model the tails of\nmultidimensional phenomena. The analysis of the dependence among multivariate\nmaxima is useful to evaluate risk. Here we present new multivariate extreme\nvalue models, as well as, coefficients to assess multivariate extremal\ndependence.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jan 2017 15:02:46 GMT"}, {"version": "v2", "created": "Fri, 13 Jan 2017 14:34:48 GMT"}], "update_date": "2017-01-16", "authors_parsed": [["Ferreira", "Helena", ""], ["Ferreira", "Marta", ""]]}, {"id": "1701.01395", "submitter": "Mauricio Sadinle", "authors": "Mauricio Sadinle, Jerome P. Reiter", "title": "Sequential identification of nonignorable missing data mechanisms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With nonignorable missing data, likelihood-based inference should be based on\nthe joint distribution of the study variables and their missingness indicators.\nThese joint models cannot be estimated from the data alone, thus requiring the\nanalyst to impose restrictions that make the models uniquely obtainable from\nthe distribution of the observed data. We present an approach for constructing\nclasses of identifiable nonignorable missing data models. The main idea is to\nuse a sequence of carefully set up identifying assumptions, whereby we specify\npotentially different missingness mechanisms for different blocks of variables.\nWe show that the procedure results in models with the desirable property of\nbeing non-parametric saturated.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jan 2017 17:34:25 GMT"}], "update_date": "2017-01-06", "authors_parsed": [["Sadinle", "Mauricio", ""], ["Reiter", "Jerome P.", ""]]}, {"id": "1701.01579", "submitter": "Peter Jupp", "authors": "R. Arnold, P. E. Jupp, H. Schaeben", "title": "Statistics of ambiguous rotations", "comments": "20 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The orientation of a rigid object can be described by a rotation that\ntransforms it into a standard position. For a symmetrical object the rotation\nis known only up to multiplication by an element of the symmetry group. Such\nambiguous rotations arise in biomechanics, crystallography and seismology. We\ndevelop methods for analyzing data of this form. A test of uniformity is given.\nParametric models for ambiguous rotations are presented, tests of location are\nconsidered, and a regression model is proposed. A brief illustrative example\ninvolving orientations of diopside crystals is given.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jan 2017 09:07:49 GMT"}], "update_date": "2017-01-09", "authors_parsed": [["Arnold", "R.", ""], ["Jupp", "P. E.", ""], ["Schaeben", "H.", ""]]}, {"id": "1701.01893", "submitter": "Viktor Benes", "authors": "Viktor Benes, Jakub Vecera, Milan Pultar", "title": "Planar segment processes with reference mark distributions, modeling and\n  estimation", "comments": "18 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper deals with planar segment processes given by a density with respect\nto the Poisson process. Parametric models involve reference distributions of\ndirections and/or lengths of segments. These distributions generally do not\ncoincide with the corresponding observed distributions. Statistical methods are\npresented which first estimate scalar parameters by known approaches and then\nthe reference distribution is estimated non-parametrically. Besides a general\ntheory we offer two models, first a Gibbs type segment process with reference\ndirectional distribution and secondly an inhomogeneous process with reference\nlength distribution. The estimation is demonstrated in simulation studies where\nthe variability of estimators is presented graphically.\n", "versions": [{"version": "v1", "created": "Sat, 7 Jan 2017 23:16:29 GMT"}, {"version": "v2", "created": "Mon, 28 Aug 2017 21:12:31 GMT"}], "update_date": "2017-08-30", "authors_parsed": [["Benes", "Viktor", ""], ["Vecera", "Jakub", ""], ["Pultar", "Milan", ""]]}, {"id": "1701.01956", "submitter": "Ting Hu", "authors": "Ting Hu, Yuan Yao", "title": "Learning Rates of Regression with q-norm Loss and Threshold", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies some robust regression problems associated with the\n$q$-norm loss ($q\\ge1$) and the $\\epsilon$-insensitive $q$-norm loss in the\nreproducing kernel Hilbert space. We establish a variance-expectation bound\nunder a priori noise condition on the conditional distribution, which is the\nkey technique to measure the error bound. Explicit learning rates will be given\nunder the approximation ability assumptions on the reproducing kernel Hilbert\nspace.\n", "versions": [{"version": "v1", "created": "Sun, 8 Jan 2017 13:14:00 GMT"}], "update_date": "2017-01-10", "authors_parsed": [["Hu", "Ting", ""], ["Yao", "Yuan", ""]]}, {"id": "1701.01961", "submitter": "Guillaume Lecu\\'e", "authors": "Lecu\\'e Guillaume and Lerasle Matthieu", "title": "Learning from MOM's principles: Le Cam's approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We obtain estimation error rates for estimators obtained by aggregation of\nregularized median-of-means tests, following a construction of Le Cam. The\nresults hold with exponentially large probability -- as in the gaussian\nframework with independent noise- under only weak moments assumptions on data\nand without assuming independence between noise and design. Any norm may be\nused for regularization. When it has some sparsity inducing power we recover\nsparse rates of convergence.\n  The procedure is robust since a large part of data may be corrupted, these\noutliers have nothing to do with the oracle we want to reconstruct. Our general\nrisk bound is of order \\begin{equation*} \\max\\left(\\mbox{minimax rate in the\ni.i.d. setup}, \\frac{\\text{number of outliers}}{\\text{number of\nobservations}}\\right) \\enspace. \\end{equation*}In particular, the number of\noutliers may be as large as (number of data) $\\times$(minimax rate) without\naffecting this rate. The other data do not have to be identically distributed\nbut should only have equivalent $L^1$ and $L^2$ moments.\n  For example, the minimax rate $s \\log(ed/s)/N$ of recovery of a $s$-sparse\nvector in $\\mathbb{R}^d$ is achieved with exponentially large probability by a\nmedian-of-means version of the LASSO when the noise has $q_0$ moments for some\n$q_0>2$, the entries of the design matrix should have $C_0\\log(ed)$ moments and\nthe dataset can be corrupted up to $C_1 s \\log(ed/s)$ outliers.\n", "versions": [{"version": "v1", "created": "Sun, 8 Jan 2017 14:21:24 GMT"}, {"version": "v2", "created": "Tue, 18 Jul 2017 14:04:15 GMT"}], "update_date": "2017-07-19", "authors_parsed": [["Guillaume", "Lecu\u00e9", ""], ["Matthieu", "Lerasle", ""]]}, {"id": "1701.01974", "submitter": "Igal Sason", "authors": "Igal Sason and Sergio Verd\\'u", "title": "Arimoto-R\\'enyi Conditional Entropy and Bayesian $M$-ary Hypothesis\n  Testing", "comments": "To appear in the IEEE Trans. on Information Theory, vol. 64, no. 1,\n  January 2018 (22 pages in two columns)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper gives upper and lower bounds on the minimum error probability of\nBayesian $M$-ary hypothesis testing in terms of the Arimoto-R\\'enyi conditional\nentropy of an arbitrary order $\\alpha$. The improved tightness of these bounds\nover their specialized versions with the Shannon conditional entropy\n($\\alpha=1$) is demonstrated. In particular, in the case where $M$ is finite,\nwe show how to generalize Fano's inequality under both the conventional and\nlist-decision settings. As a counterpart to the generalized Fano's inequality,\nallowing $M$ to be infinite, a lower bound on the Arimoto-R\\'enyi conditional\nentropy is derived as a function of the minimum error probability. Explicit\nupper and lower bounds on the minimum error probability are obtained as a\nfunction of the Arimoto-R\\'enyi conditional entropy for both positive and\nnegative $\\alpha$. Furthermore, we give upper bounds on the minimum error\nprobability as functions of the R\\'enyi divergence. In the setup of discrete\nmemoryless channels, we analyze the exponentially vanishing decay of the\nArimoto-R\\'enyi conditional entropy of the transmitted codeword given the\nchannel output when averaged over a random coding ensemble.\n", "versions": [{"version": "v1", "created": "Sun, 8 Jan 2017 15:49:22 GMT"}, {"version": "v2", "created": "Wed, 24 May 2017 16:17:58 GMT"}, {"version": "v3", "created": "Mon, 25 Sep 2017 06:45:40 GMT"}, {"version": "v4", "created": "Tue, 7 Nov 2017 07:11:42 GMT"}, {"version": "v5", "created": "Tue, 5 Dec 2017 09:43:38 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["Sason", "Igal", ""], ["Verd\u00fa", "Sergio", ""]]}, {"id": "1701.02129", "submitter": "Paolo Pigato", "authors": "Antoine Lejay, Paolo Pigato", "title": "Statistical estimation of the Oscillating Brownian Motion", "comments": "31 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the asymptotic behavior of estimators of a two-valued, discontinuous\ndiffusion coefficient in a Stochastic Differential Equation, called an\nOscillating Brownian Motion. Using the relation of the latter process with the\nSkew Brownian Motion, we propose two natural consistent estimators, which are\nvariants of the integrated volatility estimator and take the occupation times\ninto account. We show the stable convergence of the renormalized errors'\nestimations toward some Gaussian mixture, possibly corrected by a term that\ndepends on the local time. These limits stem from the lack of ergodicity as\nwell as the behavior of the local time at zero of the process. We test both\nestimators on simulated processes, finding a complete agreement with the\ntheoretical predictions.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jan 2017 10:58:43 GMT"}], "update_date": "2017-01-10", "authors_parsed": [["Lejay", "Antoine", ""], ["Pigato", "Paolo", ""]]}, {"id": "1701.02265", "submitter": "Xingye Qiao", "authors": "Chong Zhang, Wenbo Wang, and Xingye Qiao", "title": "On Reject and Refine Options in Multicategory Classification", "comments": "A revised version of this paper was accepted for publication in the\n  Journal of the American Statistical Association Theory and Methods Section.\n  52 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML math.ST stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many real applications of statistical learning, a decision made from\nmisclassification can be too costly to afford; in this case, a reject option,\nwhich defers the decision until further investigation is conducted, is often\npreferred. In recent years, there has been much development for binary\nclassification with a reject option. Yet, little progress has been made for the\nmulticategory case. In this article, we propose margin-based multicategory\nclassification methods with a reject option. In addition, and more importantly,\nwe introduce a new and unique refine option for the multicategory problem,\nwhere the class of an observation is predicted to be from a set of class\nlabels, whose cardinality is not necessarily one. The main advantage of both\noptions lies in their capacity of identifying error-prone observations.\nMoreover, the refine option can provide more constructive information for\nclassification by effectively ruling out implausible classes. Efficient\nimplementations have been developed for the proposed methods. On the\ntheoretical side, we offer a novel statistical learning theory and show a fast\nconvergence rate of the excess $\\ell$-risk of our methods with emphasis on\ndiverging dimensionality and number of classes. The results can be further\nimproved under a low noise assumption. A set of comprehensive simulation and\nreal data studies has shown the usefulness of the new learning tools compared\nto regular multicategory classifiers. Detailed proofs of theorems and extended\nnumerical results are included in the supplemental materials available online.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jan 2017 17:19:45 GMT"}], "update_date": "2017-01-10", "authors_parsed": [["Zhang", "Chong", ""], ["Wang", "Wenbo", ""], ["Qiao", "Xingye", ""]]}, {"id": "1701.02271", "submitter": "Carina Gerstenberger", "authors": "Carina Gerstenberger", "title": "Robust Estimation of Change-Point Location", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a robust estimator of the location parameter for the\nchange-point in the mean based on the Wilcoxon statistic and establish its\nconsistency for $L_1$ near epoch dependent processes. It is shown that the\nconsistency rate depends on the magnitude of change. A simulation study is\nperformed to evaluate finite sample properties of the Wilcoxon-type estimator\nin standard cases, as well as under heavy-tailed distributions and disturbances\nby outliers, and to compare it with a CUSUM-type estimator. It shows that the\nWilcoxon-type estimator is equivalent to the CUSUM-type estimator in standard\ncases, but outperforms the CUSUM-type estimator in presence of heavy tails or\noutliers in the data.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jan 2017 17:27:25 GMT"}], "update_date": "2017-01-10", "authors_parsed": [["Gerstenberger", "Carina", ""]]}, {"id": "1701.02373", "submitter": "Bertrand Iooss", "authors": "G\\'eraud Blatman (EDF R\\&D), Thibault Delage (EDF R\\&D), Bertrand\n  Iooss (EDF R\\&D, IMT, GdR MASCOT-NUM), Nadia P\\'erot (GdR MASCOT-NUM, DER)", "title": "Probabilistic risk bounds for the characterization of radiological\n  contamination", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The radiological characterization of contaminated elements (walls, grounds,\nobjects) from nuclear facilities often suffers from a too small number of\nmeasurements. In order to determine risk prediction bounds on the level of\ncontamination, some classic statistical methods may then reveal unsuited as\nthey rely upon strong assumptions (e.g. that the underlying distribution is\nGaussian) which cannot be checked. Considering that a set of measurements or\ntheir average value arise from a Gaussian distribution can sometimes lead to\nerroneous conclusion, possibly underconservative. This paper presents several\nalternative statistical approaches which are based on much weaker hypotheses\nthan Gaussianity. They result from general probabilistic inequalities and\norder-statistics based formula. Given a data sample, these inequalities make it\npossible to derive prediction intervals for a random variable, which can be\ndirectly interpreted as probabilistic risk bounds. For the sake of validation,\nthey are first applied to synthetic data samples generated from several known\ntheoretical distributions. In a second time, the proposed methods are applied\nto two data sets obtained from real radiological contamination measurements.\n", "versions": [{"version": "v1", "created": "Mon, 12 Dec 2016 14:33:57 GMT"}, {"version": "v2", "created": "Sat, 27 May 2017 10:31:47 GMT"}], "update_date": "2017-05-30", "authors_parsed": [["Blatman", "G\u00e9raud", "", "EDF R\\&D"], ["Delage", "Thibault", "", "EDF R\\&D"], ["Iooss", "Bertrand", "", "EDF R\\&D, IMT, GdR MASCOT-NUM"], ["P\u00e9rot", "Nadia", "", "GdR MASCOT-NUM, DER"]]}, {"id": "1701.02424", "submitter": "Joshua Chang", "authors": "Aaron Heuser, Minh Huynh and Joshua C. Chang", "title": "Asymptotic convergence in distribution of the area bounded by\n  prevalence-weighted Kaplan-Meier curves using empirical process modeling", "comments": "Major revision in review by RSOS. Includes fixes to Theorem 1 as well\n  as numerical results", "journal-ref": "R. Soc. open sci, 2018, 5(180496)", "doi": "10.1098/rsos.180496", "report-no": null, "categories": "stat.ME math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Kaplan-Meier product-limit estimator is a simple and powerful tool in\ntime to event analysis. An extension exists for populations stratified into\ncohorts where a population survival curve is generated by weighted averaging of\ncohort-level survival curves. For making population-level comparisons using\nthis statistic, we analyze the statistics of the area between two such weighted\nsurvival curves. We derive the large sample behavior of this statistic based on\nan empirical process of product-limit estimators. This estimator was used by an\ninterdisciplinary NIH-SSA team in the identification of medical conditions to\nprioritize for adjudication in disability benefits processing.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jan 2017 03:06:10 GMT"}, {"version": "v2", "created": "Mon, 7 Aug 2017 20:20:42 GMT"}, {"version": "v3", "created": "Tue, 21 Aug 2018 16:20:28 GMT"}, {"version": "v4", "created": "Tue, 2 Oct 2018 05:23:30 GMT"}], "update_date": "2018-11-12", "authors_parsed": [["Heuser", "Aaron", ""], ["Huynh", "Minh", ""], ["Chang", "Joshua C.", ""]]}, {"id": "1701.03326", "submitter": "Sara van de Geer", "authors": "Sara van de Geer", "title": "Some exercises with the Lasso and its compatibility constant", "comments": "34 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the Lasso for a noiseless experiment where one has observations\n$X \\beta^0$ and uses the penalized version of basis pursuit. We compute for\nsome special designs the compatibility constant, a quantity closely related to\nthe restricted eigenvalue. We moreover show the dependence of the (penalized)\nprediction error on this compatibility constant. This exercise illustrates that\ncompatibility is necessarily entering into the bounds for the (penalized)\nprediction error and that the bounds in the literature therefore are - up to\nconstants - tight. We also give conditions that show that in the noisy case the\ndominating term for the prediction error is given by the prediction error of\nthe noiseless case.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jan 2017 12:51:03 GMT"}], "update_date": "2017-01-13", "authors_parsed": [["van de Geer", "Sara", ""]]}, {"id": "1701.03769", "submitter": "Valentin Patilea", "authors": "Valentin Patilea and Ingrid Van Keilegom", "title": "A General Approach for Cure Models in Survival Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In survival analysis it often happens that some subjects under study do not\nexperience the event of interest; they are considered to be `cured'. The\npopulation is thus a mixture of two subpopulations: the one of cured subjects,\nand the one of `susceptible' subjects. When covariates are present, a so-called\nmixture cure model can be used to model the conditional survival function of\nthe population. It depends on two components: the probability of being cured\nand the conditional survival function of the susceptible subjects. In this\npaper we propose a novel approach to estimate a mixture cure model when the\ndata are subject to random right censoring. We work with a parametric model for\nthe cure proportion (like e.g. a logistic model), while the conditional\nsurvival function of the uncured subjects is unspecified. The approach is based\non an inversion which allows to write the survival function as a function of\nthe distribution of the observable random variables. This leads to a very\ngeneral class of models, which allows a flexible and rich modeling of the\nconditional survival function. We show the identifiability of the proposed\nmodel, as well as the weak consistency and the asymptotic normality of the\nmodel parameters. We also consider in more detail the case where kernel\nestimators are used for the nonparametric part of the model. The new estimators\nare compared with the estimators from a Cox mixture cure model via finite\nsample simulations. Finally, we apply the new model and estimation procedure on\ntwo medical data sets.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jan 2017 18:31:58 GMT"}], "update_date": "2017-01-16", "authors_parsed": [["Patilea", "Valentin", ""], ["Van Keilegom", "Ingrid", ""]]}, {"id": "1701.03772", "submitter": "Binhuan Wang", "authors": "Binhuan Wang, Yixin Fang, Heng Lian, Hua Liang", "title": "Additive Partially Linear Models for Massive Heterogeneous Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider an additive partially linear framework for modelling massive\nheterogeneous data. The major goal is to extract multiple common features\nsimultaneously across all sub-populations while exploring heterogeneity of each\nsub-population. We propose an aggregation type of estimators for the\ncommonality parameters that possess the asymptotic optimal bounds and the\nasymptotic distributions as if there were no heterogeneity. This oracle result\nholds when the number of sub-populations does not grow too fast and the tuning\nparameters are selected carefully. A plug-in estimator for the heterogeneity\nparameter is further constructed, and shown to possess the asymptotic\ndistribution as if the commonality information were available. Furthermore, we\ndevelop a heterogeneity test for the linear components and a homogeneity test\nfor the non-linear components accordingly. The performance of the proposed\nmethods is evaluated via simulation studies and an application to the Medicare\nProvider Utilization and Payment data.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jan 2017 18:42:42 GMT"}, {"version": "v2", "created": "Fri, 28 Dec 2018 19:46:21 GMT"}], "update_date": "2019-01-01", "authors_parsed": [["Wang", "Binhuan", ""], ["Fang", "Yixin", ""], ["Lian", "Heng", ""], ["Liang", "Hua", ""]]}, {"id": "1701.03892", "submitter": "Huiming Zhang", "authors": "Huiming Zhang, Bo Li, G. Jay Kerns", "title": "A characterization of signed discrete infinitely divisible distributions", "comments": "Accepted for publication in Studia Scientiarum Mathematicarum, 10\n  October 2016", "journal-ref": "Studia Scientiarum Mathematicarum Hungarica, 2017, 54(4), 446-470", "doi": "10.1556/012.2017.54.4.1377", "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we give some reviews concerning negative probabilities model\nand quasi-infinitely divisible at the beginning. We next extend Feller's\ncharacterization of discrete infinitely divisible distributions to signed\ndiscrete infinitely divisible distributions, which are discrete pseudo compound\nPoisson (DPCP) distributions with connections to the L\\'evy-Wiener theorem.\nThis is a special case of an open problem which is proposed by Sato(2014),\nChaumont and Yor(2012). An analogous result involving characteristic functions\nis shown for signed integer-valued infinitely divisible distributions. We show\nthat many distributions are DPCP by the non-zero p.g.f. property, such as the\nmixed Poisson distribution and fractional Poisson process. DPCP has some\nbizarre properties, and one is that the parameter $\\lambda $ in the DPCP class\ncannot be arbitrarily small.\n", "versions": [{"version": "v1", "created": "Sat, 14 Jan 2017 08:42:54 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Zhang", "Huiming", ""], ["Li", "Bo", ""], ["Kerns", "G. Jay", ""]]}, {"id": "1701.04006", "submitter": "Jon Cockayne", "authors": "Jon Cockayne, Chris Oates, Tim Sullivan, Mark Girolami", "title": "Probabilistic Numerical Methods for PDE-constrained Bayesian Inverse\n  Problems", "comments": null, "journal-ref": null, "doi": "10.1063/1.4985359", "report-no": null, "categories": "stat.ME cs.NA math.NA math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper develops meshless methods for probabilistically describing\ndiscretisation error in the numerical solution of partial differential\nequations. This construction enables the solution of Bayesian inverse problems\nwhile accounting for the impact of the discretisation of the forward problem.\nIn particular, this drives statistical inferences to be more conservative in\nthe presence of significant solver error. Theoretical results are presented\ndescribing rates of convergence for the posteriors in both the forward and\ninverse problems. This method is tested on a challenging inverse problem with a\nnonlinear forward model.\n", "versions": [{"version": "v1", "created": "Sun, 15 Jan 2017 08:50:06 GMT"}], "update_date": "2017-12-20", "authors_parsed": [["Cockayne", "Jon", ""], ["Oates", "Chris", ""], ["Sullivan", "Tim", ""], ["Girolami", "Mark", ""]]}, {"id": "1701.04028", "submitter": "Boris Ryabko", "authors": "Boris Ryabko, Andrey Guskov, Irina Selivanova", "title": "Using data-compressors for statistical analysis of problems on\n  homogeneity testing and classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays data compressors are applied to many problems of text analysis, but\nmany such applications are developed outside of the framework of mathematical\nstatistics. In this paper we overcome this obstacle and show how several\nmethods of classical mathematical statistics can be developed based on\napplications of the data compressors.\n", "versions": [{"version": "v1", "created": "Sun, 15 Jan 2017 11:51:46 GMT"}], "update_date": "2017-01-17", "authors_parsed": [["Ryabko", "Boris", ""], ["Guskov", "Andrey", ""], ["Selivanova", "Irina", ""]]}, {"id": "1701.04112", "submitter": "Gabor Lugosi", "authors": "G\\'abor Lugosi and Shahar Mendelson", "title": "Regularization, sparse recovery, and median-of-means tournaments", "comments": "28 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A regularized risk minimization procedure for regression function estimation\nis introduced that achieves near optimal accuracy and confidence under general\nconditions, including heavy-tailed predictor and response variables. The\nprocedure is based on median-of-means tournaments, introduced by the authors in\n[8]. It is shown that the new procedure outperforms standard regularized\nempirical risk minimization procedures such as lasso or slope in heavy-tailed\nproblems.\n", "versions": [{"version": "v1", "created": "Sun, 15 Jan 2017 21:14:22 GMT"}, {"version": "v2", "created": "Wed, 29 Nov 2017 15:09:54 GMT"}], "update_date": "2017-11-30", "authors_parsed": [["Lugosi", "G\u00e1bor", ""], ["Mendelson", "Shahar", ""]]}, {"id": "1701.04176", "submitter": "Masayo Hirose", "authors": "Masayo Yoshimori Hirose and Partha Lahiri", "title": "A New Model Variance Estimator for an Area Level Small Area Model to\n  Solve Multiple Problems Simultaneously", "comments": "27 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The two-level normal hierarchical model (NHM) has played a critical role in\nthe theory of small area estimation (SAE), one of the growing areas in\nstatistics with numerous applications in different disciplines. In this paper,\nwe address major well-known shortcomings associated with the empirical best\nlinear unbiased prediction (EBLUP) of a small area mean and its mean squared\nerror (MSE) estimation by considering an appropriate model variance estimator\nthat satisfies multiple properties. The proposed model variance estimator\nsimultaneously (i) improves on the estimation of the related shrinkage factors,\n(ii) protects EBLUP from the common overshrinkage problem, (iii) avoids complex\nbias correction in generating strictly positive second-order unbiased mean\nsquare error (MSE) estimator either by the Taylor series or single parametric\nbootstrap method. The idea of achieving multiple desirable properties in an\nEBLUP method through a suitably devised model variance estimator is the first\nof its kind and holds promise in providing good inferences for small area means\nunder the classical linear mixed model prediction framework. The proposed\nmethodology is also evaluated using a Monte Carlo simulation study and real\ndata analysis.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jan 2017 05:57:39 GMT"}], "update_date": "2017-01-17", "authors_parsed": [["Hirose", "Masayo Yoshimori", ""], ["Lahiri", "Partha", ""]]}, {"id": "1701.04177", "submitter": "Peng Ding", "authors": "Peng Ding, Tyler VanderWeele, James Robins", "title": "Instrumental variables as bias amplifiers with general outcome and\n  confounding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Drawing causal inference with observational studies is the central pillar of\nmany disciplines. One sufficient condition for identifying the causal effect is\nthat the treatment-outcome relationship is unconfounded conditional on the\nobserved covariates. It is often believed that the more covariates we condition\non, the more plausible this unconfoundedness assumption is. This belief has had\na huge impact on practical causal inference, suggesting that we should adjust\nfor all pretreatment covariates. However, when there is unmeasured confounding\nbetween the treatment and outcome, estimators adjusting for some pretreatment\ncovariate might have greater bias than estimators without adjusting for this\ncovariate. This kind of covariate is called a bias amplifier, and includes\ninstrumental variables that are independent of the confounder, and affect the\noutcome only through the treatment. Previously, theoretical results for this\nphenomenon have been established only for linear models. We fill in this gap in\nthe literature by providing a general theory, showing that this phenomenon\nhappens under a wide class of models satisfying certain monotonicity\nassumptions. We further show that when the treatment follows an additive or\nmultiplicative model conditional on the instrumental variable and the\nconfounder, these monotonicity assumptions can be interpreted as the signs of\nthe arrows of the causal diagrams.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jan 2017 06:00:36 GMT"}], "update_date": "2017-01-17", "authors_parsed": [["Ding", "Peng", ""], ["VanderWeele", "Tyler", ""], ["Robins", "James", ""]]}, {"id": "1701.04188", "submitter": "Johannes Krebs", "authors": "Johannes T. N. Krebs", "title": "A Bernstein Inequality For Exponentially Growing Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we present a Bernstein inequality for sums of random\nvariables which are defined on a graphical network whose nodes grow at an\nexponential rate. The inequality can be used to derive concentration\ninequalities in highly-connected networks. It can be useful to obtain\nconsistency properties for nonparametric estimators of conditional expectation\nfunctions which are derived from such networks.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jan 2017 06:43:23 GMT"}, {"version": "v2", "created": "Tue, 19 Sep 2017 05:45:20 GMT"}], "update_date": "2017-09-20", "authors_parsed": [["Krebs", "Johannes T. N.", ""]]}, {"id": "1701.04366", "submitter": "Herwig Wendt", "authors": "Herwig Wendt and Gustavo Didier and S\\'ebastien Combrexelle and\n  Patrice Abry", "title": "Multivariate Hadamard self-similarity: testing fractal connectivity", "comments": null, "journal-ref": null, "doi": "10.1016/j.physd.2017.07.001", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While scale invariance is commonly observed in each component of real world\nmultivariate signals, it is also often the case that the inter-component\ncorrelation structure is not fractally connected, i.e., its scaling behavior is\nnot determined by that of the individual components. To model this situation in\na versatile manner, we introduce a class of multivariate Gaussian stochastic\nprocesses called Hadamard fractional Brownian motion (HfBm). Its theoretical\nstudy sheds light on the issues raised by the joint requirement of entry-wise\nscaling and departures from fractal connectivity. An asymptotically normal\nwavelet-based estimator for its scaling parameter, called the Hurst matrix, is\nproposed, as well as asymptotically valid confidence intervals. The latter are\naccompanied by original finite sample procedures for computing confidence\nintervals and testing fractal connectivity from one single and finite size\nobservation. Monte Carlo simulation studies are used to assess the estimation\nperformance as a function of the (finite) sample size, and to quantify the\nimpact of omitting wavelet cross-correlation terms. The simulation studies are\nshown to validate the use of approximate confidence intervals, together with\nthe significance level and power of the fractal connectivity test. The test\nperformance and properties are further studied as functions of the HfBm\nparameters.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jan 2017 17:40:59 GMT"}], "update_date": "2017-09-13", "authors_parsed": [["Wendt", "Herwig", ""], ["Didier", "Gustavo", ""], ["Combrexelle", "S\u00e9bastien", ""], ["Abry", "Patrice", ""]]}, {"id": "1701.04367", "submitter": "C\\'ecile Durot", "authors": "Fadoua Balabdaoui, C\\'ecile Durot and Fran\\c{c}ois Koladjo", "title": "Testing convexity of a discrete distribution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Based on the convex least-squares estimator, we propose two different\nprocedures for testing convexity of a probability mass function supported on N\nwith an unknown finite support. The procedures are shown to be asymptotically\ncalibrated.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jan 2017 17:43:48 GMT"}], "update_date": "2017-01-17", "authors_parsed": [["Balabdaoui", "Fadoua", ""], ["Durot", "C\u00e9cile", ""], ["Koladjo", "Fran\u00e7ois", ""]]}, {"id": "1701.04455", "submitter": "David Gamarnik", "authors": "David Gamarnik and Ilias Zadik", "title": "High-Dimensional Regression with Binary Coefficients. Estimating Squared\n  Error and a Phase Transition", "comments": "36 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a sparse linear regression model Y=X\\beta^{*}+W where X has a\nGaussian entries, W is the noise vector with mean zero Gaussian entries, and\n\\beta^{*} is a binary vector with support size (sparsity) k. Using a novel\nconditional second moment method we obtain a tight up to a multiplicative\nconstant approximation of the optimal squared error\n\\min_{\\beta}\\|Y-X\\beta\\|_{2}, where the minimization is over all k-sparse\nbinary vectors \\beta. The approximation reveals interesting structural\nproperties of the underlying regression problem. In particular, a) We establish\nthat n^*=2k\\log p/\\log (2k/\\sigma^{2}+1) is a phase transition point with the\nfollowing \"all-or-nothing\" property. When n exceeds n^{*},\n(2k)^{-1}\\|\\beta_{2}-\\beta^*\\|_0\\approx 0, and when n is below n^{*},\n(2k)^{-1}\\|\\beta_{2}-\\beta^*\\|_0\\approx 1, where \\beta_2 is the optimal\nsolution achieving the smallest squared error. With this we prove that n^{*} is\nthe asymptotic threshold for recovering \\beta^* information theoretically. b)\nWe compute the squared error for an intermediate problem\n\\min_{\\beta}\\|Y-X\\beta\\|_{2} where minimization is restricted to vectors \\beta\nwith \\|\\beta-\\beta^{*}\\|_0=2k \\zeta, for \\zeta\\in [0,1]. We show that a lower\nbound part \\Gamma(\\zeta) of the estimate, which corresponds to the estimate\nbased on the first moment method, undergoes a phase transition at three\ndifferent thresholds, namely n_{\\text{inf,1}}=\\sigma^2\\log p, which is\ninformation theoretic bound for recovering \\beta^* when k=1 and \\sigma is\nlarge, then at n^{*} and finally at n_{\\text{LASSO/CS}}. c) We establish a\ncertain Overlap Gap Property (OGP) on the space of all binary vectors \\beta\nwhen n\\le ck\\log p for sufficiently small constant c. We conjecture that OGP is\nthe source of algorithmic hardness of solving the minimization problem\n\\min_{\\beta}\\|Y-X\\beta\\|_{2} in the regime n<n_{\\text{LASSO/CS}}.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jan 2017 20:44:36 GMT"}, {"version": "v2", "created": "Sun, 23 Jul 2017 15:35:54 GMT"}, {"version": "v3", "created": "Wed, 25 Sep 2019 06:08:51 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Gamarnik", "David", ""], ["Zadik", "Ilias", ""]]}, {"id": "1701.04582", "submitter": "Sebastian Fuchs", "authors": "Sebastian Fuchs and Klaus D. Schmidt", "title": "Estimators for a Class of Bivariate Measures of Concordance for Copulas", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the present paper we propose and study estimators for a wide class of\nbivariate measures of concordance for copulas. These measures of concordance\nare generated by a copula and generalize Spearman's rho and Gini's gamma. In\nthe case of Spearman's rho and Gini's gamma the estimators turn out to be the\nusual sample versions of these measures of concordance.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jan 2017 09:14:14 GMT"}], "update_date": "2017-01-18", "authors_parsed": [["Fuchs", "Sebastian", ""], ["Schmidt", "Klaus D.", ""]]}, {"id": "1701.04671", "submitter": "Marie-Luce Taupin", "authors": "Sylvie Huet (LaMME, MaIAGE), Marie-Luce Taupin (LaMME)", "title": "Metamodel construction for sensitivity analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose to estimate a metamodel and the sensitivity indices of a complex\nmodel m in the Gaussian regression framework. Our approach combines methods for\nsensitivity analysis of complex models and statistical tools for sparse\nnon-parametric estimation in multivariate Gaussian regression model. It rests\non the construction of a metamodel for aproximating the Hoeffding-Sobol\ndecomposition of m. This metamodel belongs to a reproducing kernel Hilbert\nspace constructed as a direct sum of Hilbert spaces leading to a functional\nANOVA decomposition. The estimation of the metamodel is carried out via a\npenalized least-squares minimization allowing to select the subsets of\nvariables that contribute to predict the output. It allows to estimate the\nsensitivity indices of m. We establish an oracle-type inequality for the risk\nof the estimator, describe the procedure for estimating the metamodel and the\nsensitivity indices, and assess the performances of the procedure via a\nsimulation study.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jan 2017 13:54:18 GMT"}, {"version": "v2", "created": "Mon, 18 Nov 2019 16:23:51 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Huet", "Sylvie", "", "LaMME, MaIAGE"], ["Taupin", "Marie-Luce", "", "LaMME"]]}, {"id": "1701.04682", "submitter": "Ahmed Elsawah", "authors": "M.A. Abd Elgawad, A.M.Elsawah, Hong Qin and Ting Yan", "title": "Asymptotic generalized bivariate extreme with random index", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many biological, agricultural, military activity problems and in some\nquality control problems, it is almost impossible to have a fixed sample size,\nbecause some observations are always lost for various reasons. Therefore, the\nsample size itself is considered frequently to be a random variable (rv). The\nclass of limit distribution functions (df's) of the random bivariate extreme\ngeneralized order statistics (GOS) from independent and identically distributed\nRV's are fully characterized. When the random sample size is assumed to be\nindependent of the basic variables and its df is assumed to converge weakly to\na non-degenerate limit, the necessary and sufficient conditions for the weak\nconvergence of the random bivariate extreme GOS are obtained. Furthermore, when\nthe interrelation of the random size and the basic rv's is not restricted,\nsufficient conditions for the convergence and the forms of the limit df's are\ndeduced. Illustrative examples are given which lend further support to our\ntheoretical results.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jan 2017 14:06:40 GMT"}], "update_date": "2017-01-24", "authors_parsed": [["Elgawad", "M. A. Abd", ""], ["Elsawah", "A. M.", ""], ["Qin", "Hong", ""], ["Yan", "Ting", ""]]}, {"id": "1701.04880", "submitter": "Meitner Cadena", "authors": "Meitner Cadena", "title": "A New Family of Asymmetric Distributions for Modeling Light-Tailed and\n  Right-Skewed Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new three-parameter cumulative distribution function defined on\n$(\\alpha,\\infty)$, for some $\\alpha\\geq0$, with asymmetric probability density\nfunction and showing exponential decays at its both tails, is introduced. The\nnew distribution is near to familiar distributions like the gamma and\nlog-normal distributions, but this new one shows own elements and thus does not\ngeneralize neither of these distributions. Hence, the new distribution\nconstitutes a new alternative to fit values showing light-tailed behaviors.\nFurther, this new distribution shows great flexibility to fit the bulk of data\nby tuning some parameters. We refer to this new distribution as the generalized\nexponential log-squared distribution (GEL-S). Statistical properties of the\nGEL-S distribution are discussed. The maximum likelihood method is proposed for\nestimating the model parameters, but incorporating adaptations in computational\nprocedures due to difficulties in the manipulation of the parameters. The\nperfomance of the new distribution is studied using simulations. Applications\nto real data sets coming from different domains are showed.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jan 2017 21:44:01 GMT"}, {"version": "v2", "created": "Mon, 27 Mar 2017 14:10:00 GMT"}], "update_date": "2017-03-28", "authors_parsed": [["Cadena", "Meitner", ""]]}, {"id": "1701.04889", "submitter": "Abhishek Chakrabortty", "authors": "Abhishek Chakrabortty and Tianxi Cai", "title": "Efficient and Adaptive Linear Regression in Semi-Supervised Settings", "comments": "51 pages; Revised version - to appear in The Annals of Statistics", "journal-ref": "The Annals of Statistics 2018, Vol. 46, No. 4, 1541-1572", "doi": "10.1214/17-AOS1594", "report-no": null, "categories": "stat.ME math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the linear regression problem under semi-supervised settings\nwherein the available data typically consists of: (i) a small or moderate sized\n'labeled' data, and (ii) a much larger sized 'unlabeled' data. Such data arises\nnaturally from settings where the outcome, unlike the covariates, is expensive\nto obtain, a frequent scenario in modern studies involving large databases like\nelectronic medical records (EMR). Supervised estimators like the ordinary least\nsquares (OLS) estimator utilize only the labeled data. It is often of interest\nto investigate if and when the unlabeled data can be exploited to improve\nestimation of the regression parameter in the adopted linear model.\n  In this paper, we propose a class of 'Efficient and Adaptive Semi-Supervised\nEstimators' (EASE) to improve estimation efficiency. The EASE are two-step\nestimators adaptive to model mis-specification, leading to improved (optimal in\nsome cases) efficiency under model mis-specification, and equal (optimal)\nefficiency under a linear model. This adaptive property, often unaddressed in\nthe existing literature, is crucial for advocating 'safe' use of the unlabeled\ndata. The construction of EASE primarily involves a flexible\n'semi-non-parametric' imputation, including a smoothing step that works well\neven when the number of covariates is not small; and a follow up 'refitting'\nstep along with a cross-validation (CV) strategy both of which have useful\npractical as well as theoretical implications towards addressing two important\nissues: under-smoothing and over-fitting. We establish asymptotic results\nincluding consistency, asymptotic normality and the adaptive properties of\nEASE. We also provide influence function expansions and a 'double' CV strategy\nfor inference. The results are further validated through extensive simulations,\nfollowed by application to an EMR study on auto-immunity.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jan 2017 22:29:22 GMT"}, {"version": "v2", "created": "Sat, 19 Aug 2017 18:15:39 GMT"}], "update_date": "2018-07-02", "authors_parsed": [["Chakrabortty", "Abhishek", ""], ["Cai", "Tianxi", ""]]}, {"id": "1701.04921", "submitter": "Robert Staudte", "authors": "Robert Staudte and Aihua Xia", "title": "Divergence from, and Convergence to, Uniformity of Probability Density\n  Quantiles", "comments": "13 pages, 2 figures. arXiv admin note: substantial text overlap with\n  arXiv:1605.00189", "journal-ref": null, "doi": "10.3390/e20050317", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The probability density quantile (pdQ) carries essential information\nregarding shape and tail behavior of a location-scale family. Convergence of\nrepeated applications of the pdQ mapping to the uniform distribution is\ninvestigated and new fixed point theorems are established. The Kullback-Leibler\ndivergences from uniformity of these pdQs are mapped and found to be\ningredients in power functions of optimal tests for uniformity against\nalternative shapes.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jan 2017 01:36:46 GMT"}, {"version": "v2", "created": "Wed, 21 Feb 2018 05:37:47 GMT"}, {"version": "v3", "created": "Thu, 15 Mar 2018 01:27:41 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Staudte", "Robert", ""], ["Xia", "Aihua", ""]]}, {"id": "1701.04970", "submitter": "Martin Burger", "authors": "Felix Lucka, Katharina Proksch, Christoph Brune, Nicolai Bissantz,\n  Martin Burger, Holger Dette, Frank W\\\"ubbeling", "title": "Risk Estimators for Choosing Regularization Parameters in Ill-Posed\n  Problems - Properties and Limitations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.NA math.OC stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper discusses the properties of certain risk estimators recently\nproposed to choose regularization parameters in ill-posed problems. A simple\napproach is Stein's unbiased risk estimator (SURE), which estimates the risk in\nthe data space, while a recent modification (GSURE) estimates the risk in the\nspace of the unknown variable. It seems intuitive that the latter is more\nappropriate for ill-posed problems, since the properties in the data space do\nnot tell much about the quality of the reconstruction. We provide theoretical\nstudies of both estimators for linear Tikhonov regularization in a finite\ndimensional setting and estimate the quality of the risk estimators, which also\nleads to asymptotic convergence results as the dimension of the problem tends\nto infinity. Unlike previous papers, who studied image processing problems with\na very low degree of ill-posedness, we are interested in the behavior of the\nrisk estimators for increasing ill-posedness. Interestingly, our theoretical\nresults indicate that the quality of the GSURE risk can deteriorate\nasymptotically for ill-posed problems, which is confirmed by a detailed\nnumerical study. The latter shows that in many cases the GSURE estimator leads\nto extremely small regularization parameters, which obviously cannot stabilize\nthe reconstruction. Similar but less severe issues with respect to robustness\nalso appear for the SURE estimator, which in comparison to the rather\nconservative discrepancy principle leads to the conclusion that regularization\nparameter choice based on unbiased risk estimation is not a reliable procedure\nfor ill-posed problems. A similar numerical study for sparsity regularization\ndemonstrates that the same issue appears in nonlinear variational\nregularization approaches.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jan 2017 06:55:51 GMT"}, {"version": "v2", "created": "Tue, 10 Oct 2017 21:25:54 GMT"}], "update_date": "2017-10-12", "authors_parsed": [["Lucka", "Felix", ""], ["Proksch", "Katharina", ""], ["Brune", "Christoph", ""], ["Bissantz", "Nicolai", ""], ["Burger", "Martin", ""], ["Dette", "Holger", ""], ["W\u00fcbbeling", "Frank", ""]]}, {"id": "1701.05009", "submitter": "Arnak Dalalyan S.", "authors": "Arnak S. Dalalyan and Mehdi Sebbar", "title": "Optimal Kullback-Leibler Aggregation in Mixture Density Estimation by\n  Maximum Likelihood", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the maximum likelihood estimator of density of $n$ independent\nobservations, under the assumption that it is well approximated by a mixture\nwith a large number of components. The main focus is on statistical properties\nwith respect to the Kullback-Leibler loss. We establish risk bounds taking the\nform of sharp oracle inequalities both in deviation and in expectation. A\nsimple consequence of these bounds is that the maximum likelihood estimator\nattains the optimal rate $((\\log K)/n)^{1/2}$, up to a possible logarithmic\ncorrection, in the problem of convex aggregation when the number $K$ of\ncomponents is larger than $n^{1/2}$. More importantly, under the additional\nassumption that the Gram matrix of the components satisfies the compatibility\ncondition, the obtained oracle inequalities yield the optimal rate in the\nsparsity scenario. That is, if the weight vector is (nearly) $D$-sparse, we get\nthe rate $(D\\log K)/n$. As a natural complement to our oracle inequalities, we\nintroduce the notion of nearly-$D$-sparse aggregation and establish matching\nlower bounds for this type of aggregation.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jan 2017 11:07:42 GMT"}], "update_date": "2017-01-19", "authors_parsed": [["Dalalyan", "Arnak S.", ""], ["Sebbar", "Mehdi", ""]]}, {"id": "1701.05065", "submitter": "Jean-Michel Loubes", "authors": "Marina Antol\\'in, Eustasio Del Barrio, Jean-Michel Loubes (IMT)", "title": "A data driven trimming procedure for robust classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classification rules can be severely affected by the presence of disturbing\nobservations in the training sample. Looking for an optimal classifier with\nsuch data may lead to unnecessarily complex rules. So, simpler effective\nclassification rules could be achieved if we relax the goal of fitting a good\nrule for the whole training sample but only consider a fraction of the data. In\nthis paper we introduce a new method based on trimming to produce\nclassification rules with guaranteed performance on a significant fraction of\nthe data. In particular, we provide an automatic way of determining the right\ntrimming proportion and obtain in this setting oracle bounds for the\nclassification error on the new data set.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jan 2017 14:03:14 GMT"}], "update_date": "2017-01-19", "authors_parsed": [["Antol\u00edn", "Marina", "", "IMT"], ["Del Barrio", "Eustasio", "", "IMT"], ["Loubes", "Jean-Michel", "", "IMT"]]}, {"id": "1701.05091", "submitter": "Olivier Wintenberger", "authors": "Rasmus Pedersen, Olivier Wintenberger (LSTA, University of Copenhagen)", "title": "On the tail behavior of a class of multivariate conditionally\n  heteroskedastic processes", "comments": "Extremes, Springer Verlag (Germany), A Para\\^itre", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR q-fin.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conditions for geometric ergodicity of multivariate autoregressive\nconditional heteroskedasticity (ARCH) processes, with the so-called BEKK (Baba,\nEngle, Kraft, and Kroner) parametrization, are considered. We show for a class\nof BEKK-ARCH processes that the invariant distribution is regularly varying. In\norder to account for the possibility of different tail indices of the\nmarginals, we consider the notion of vector scaling regular variation, in the\nspirit of Perfekt (1997, Advances in Applied Probability, 29, pp. 138-164). The\ncharacterization of the tail behavior of the processes is used for deriving the\nasymptotic properties of the sample covariance matrices.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jan 2017 15:15:21 GMT"}, {"version": "v2", "created": "Fri, 3 Feb 2017 07:27:42 GMT"}, {"version": "v3", "created": "Tue, 5 Dec 2017 16:29:38 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["Pedersen", "Rasmus", "", "LSTA, University of Copenhagen"], ["Wintenberger", "Olivier", "", "LSTA, University of Copenhagen"]]}, {"id": "1701.05146", "submitter": "Espen Bernton", "authors": "Espen Bernton (Harvard University), Pierre E. Jacob (Harvard\n  University), Mathieu Gerber (University of Bristol), Christian P. Robert\n  (Universit\\'e Paris-Dauphine, PSL and University of Warwick)", "title": "On parameter estimation with the Wasserstein distance", "comments": "29 pages (+18 pages of appendices), 6 figures. To appear in\n  Information and Inference: A Journal of the IMA. A previous version of this\n  paper contained work on approximate Bayesian computation with the Wasserstein\n  distance, which can now be found at arxiv:1905.03747", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical inference can be performed by minimizing, over the parameter\nspace, the Wasserstein distance between model distributions and the empirical\ndistribution of the data. We study asymptotic properties of such minimum\nWasserstein distance estimators, complementing results derived by Bassetti,\nBodini and Regazzini in 2006. In particular, our results cover the misspecified\nsetting, in which the data-generating process is not assumed to be part of the\nfamily of distributions described by the model. Our results are motivated by\nrecent applications of minimum Wasserstein estimators to complex generative\nmodels. We discuss some difficulties arising in the approximation of these\nestimators and illustrate their behavior in several numerical experiments. Two\nof our examples are taken from the literature on approximate Bayesian\ncomputation and have likelihood functions that are not analytically tractable.\nTwo other examples involve misspecified models.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jan 2017 16:59:55 GMT"}, {"version": "v2", "created": "Fri, 11 Aug 2017 22:47:12 GMT"}, {"version": "v3", "created": "Fri, 10 May 2019 02:03:12 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Bernton", "Espen", "", "Harvard University"], ["Jacob", "Pierre E.", "", "Harvard\n  University"], ["Gerber", "Mathieu", "", "University of Bristol"], ["Robert", "Christian P.", "", "Universit\u00e9 Paris-Dauphine, PSL and University of Warwick"]]}, {"id": "1701.05230", "submitter": "Abhishek Chakrabortty", "authors": "Abhishek Chakrabortty, Matey Neykov, Raymond Carroll and Tianxi Cai", "title": "Surrogate Aided Unsupervised Recovery of Sparse Signals in Single Index\n  Models for Binary Outcomes", "comments": "50 pages, 3 tables, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the recovery of regression coefficients, denoted by\n$\\boldsymbol{\\beta}_0$, for a single index model (SIM) relating a binary\noutcome $Y$ to a set of possibly high dimensional covariates $\\boldsymbol{X}$,\nbased on a large but 'unlabeled' dataset $\\mathcal{U}$, with $Y$ never\nobserved. On $\\mathcal{U}$, we fully observe $\\boldsymbol{X}$ and additionally,\na surrogate $S$ which, while not being strongly predictive of $Y$ throughout\nthe entirety of its support, can forecast it with high accuracy when it assumes\nextreme values. Such datasets arise naturally in modern studies involving large\ndatabases such as electronic medical records (EMR) where $Y$, unlike\n$(\\boldsymbol{X}, S)$, is difficult and/or expensive to obtain. In EMR studies,\nan example of $Y$ and $S$ would be the true disease phenotype and the count of\nthe associated diagnostic codes respectively. Assuming another SIM for $S$\ngiven $\\boldsymbol{X}$, we show that under sparsity assumptions, we can recover\n$\\boldsymbol{\\beta}_0$ proportionally by simply fitting a least squares LASSO\nestimator to the subset of the observed data on $(\\boldsymbol{X}, S)$\nrestricted to the extreme sets of $S$, with $Y$ imputed using the surrogacy of\n$S$. We obtain sharp finite sample performance bounds for our estimator,\nincluding deterministic deviation bounds and probabilistic guarantees. We\ndemonstrate the effectiveness of our approach through multiple simulation\nstudies, as well as by application to real data from an EMR study conducted at\nthe Partners HealthCare Systems.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jan 2017 20:51:27 GMT"}, {"version": "v2", "created": "Sat, 19 Aug 2017 17:59:30 GMT"}, {"version": "v3", "created": "Sun, 1 Jul 2018 01:09:51 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Chakrabortty", "Abhishek", ""], ["Neykov", "Matey", ""], ["Carroll", "Raymond", ""], ["Cai", "Tianxi", ""]]}, {"id": "1701.05325", "submitter": "Gian-Andrea Thanei", "authors": "Gian-Andrea Thanei, Christina Heinze, Nicolai Meinshausen", "title": "Random Projections For Large-Scale Regression", "comments": "13 pages, 3 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fitting linear regression models can be computationally very expensive in\nlarge-scale data analysis tasks if the sample size and the number of variables\nare very large. Random projections are extensively used as a dimension\nreduction tool in machine learning and statistics. We discuss the applications\nof random projections in linear regression problems, developed to decrease\ncomputational costs, and give an overview of the theoretical guarantees of the\ngeneralization error. It can be shown that the combination of random\nprojections with least squares regression leads to similar recovery as ridge\nregression and principal component regression. We also discuss possible\nimprovements when averaging over multiple random projections, an approach that\nlends itself easily to parallel implementation.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jan 2017 08:14:38 GMT"}], "update_date": "2017-01-20", "authors_parsed": [["Thanei", "Gian-Andrea", ""], ["Heinze", "Christina", ""], ["Meinshausen", "Nicolai", ""]]}, {"id": "1701.05380", "submitter": "Johannes Krebs", "authors": "Johannes T. N. Krebs", "title": "A Large Deviation Inequality for $\\beta$-mixing Time Series and its\n  Applications to the Functional Kernel Regression Model", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a new large deviation inequality for sums of random variables of the\nform $Z_k = f(X_k,X_t)$ for $k,t\\in \\mathbb{N}$, $t$ fixed, where the\nunderlying process $X$ is $\\beta$-mixing. The inequality can be used to derive\nconcentration inequalities. We demonstrate its usefulness in the functional\nkernel regression model of Ferraty et al. (2007) where we study the consistency\nof dynamic forecasts.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jan 2017 12:00:18 GMT"}, {"version": "v2", "created": "Tue, 11 Apr 2017 13:32:54 GMT"}, {"version": "v3", "created": "Tue, 4 Jul 2017 20:07:35 GMT"}], "update_date": "2017-07-06", "authors_parsed": [["Krebs", "Johannes T. N.", ""]]}, {"id": "1701.05387", "submitter": "Enkelejd Hashorva", "authors": "L. Bai, K. Debicki, E. Hashorva, L. Ji", "title": "Extremes of threshold-dependent Gaussian processes", "comments": "28 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this contribution we are concerned with the asymptotic behaviour as $u\\to\n\\infty$ of $\\mathbb{P}\\{\\sup_{t\\in [0,T]} X_u(t)> u\\}$, where $X_u(t),t\\in\n[0,T],u>0$ is a family of centered Gaussian processes with continuous\ntrajectories. A key application of our findings concerns\n$\\mathbb{P}\\{\\sup_{t\\in [0,T]} (X(t)+ g(t))> u\\}$ as $u\\to\\infty$, for $X$ a\ncentered Gaussian process and $g$ some measurable trend function. Further\napplications include the approximation of both the ruin time and the ruin\nprobability of the Brownian motion risk model with constant force of interest.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jan 2017 12:21:16 GMT"}], "update_date": "2017-01-20", "authors_parsed": [["Bai", "L.", ""], ["Debicki", "K.", ""], ["Hashorva", "E.", ""], ["Ji", "L.", ""]]}, {"id": "1701.05458", "submitter": "Rym Worms", "authors": "Julien Worms (LM-Versailles), Rym Worms (LAMA)", "title": "Extreme value statistics for censored data with heavy tails under\n  competing risks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the problem of estimating, in the presence of random\ncensoring as well as competing risks, the extreme value index of the\n(sub)-distribution function associated to one particular cause, in the\nheavy-tail case. Asymptotic normality of the proposed estimator (which has the\nform of an Aalen-Johansen integral, and is the first estimator proposed in this\ncontext) is established. A small simulation study exhibits its performances for\nfinite samples. Estimation of extreme quantiles of the cumulative incidence\nfunction is also addressed.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jan 2017 15:08:20 GMT"}], "update_date": "2017-01-20", "authors_parsed": [["Worms", "Julien", "", "LM-Versailles"], ["Worms", "Rym", "", "LAMA"]]}, {"id": "1701.05677", "submitter": "Shujaat Khan Engr", "authors": "Jawwad Ahmad, Muhammad Usman, Shujaat Khan, Imran Naseem and Hassan\n  Jamil Syed", "title": "RVP-FLMS : A Robust Variable Power Fractional LMS Algorithm", "comments": "IEEE International Conference on Control System, Computing and\n  Engineering (ICCSCE). IEEE, 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose an adaptive framework for the variable power of the\nfractional least mean square (FLMS) algorithm. The proposed algorithm named as\nrobust variable power FLMS (RVP-FLMS) dynamically adapts the fractional power\nof the FLMS to achieve high convergence rate with low steady state error. For\nthe evaluation purpose, the problems of system identification and channel\nequalization are considered. The experiments clearly show that the proposed\napproach achieves better convergence rate and lower steady-state error compared\nto the FLMS. The MATLAB code for the related simulation is available online at\nhttps://goo.gl/dGTGmP.\n", "versions": [{"version": "v1", "created": "Fri, 20 Jan 2017 04:00:07 GMT"}], "update_date": "2017-02-07", "authors_parsed": [["Ahmad", "Jawwad", ""], ["Usman", "Muhammad", ""], ["Khan", "Shujaat", ""], ["Naseem", "Imran", ""], ["Syed", "Hassan Jamil", ""]]}, {"id": "1701.05833", "submitter": "Romain Poncet", "authors": "Romain Poncet (CMAP)", "title": "Generalized and hybrid Metropolis-Hastings overdamped Langevin\n  algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been shown that the nonreversible overdamped Langevin dynamics enjoy\nbetter convergence properties in terms of spectral gap and asymptotic variance\nthan the reversible one. In this article we propose a variance reduction method\nfor the Metropolis-Hastings Adjusted Langevin Algorithm (MALA) that makes use\nof the good behaviour of the these nonreversible dynamics. It consists in\nconstructing a nonreversible Markov chain (with respect to the target invariant\nmeasure) by using a Generalized Metropolis-Hastings adjustment on a lifted\nstate space. We present two variations of this method and we discuss the\nimportance of a well-chosen proposal distribution in terms of average rejection\nprobability. We conclude with numerical experimentations to compare our\nalgorithms with the MALA, and show variance reduction of several order of\nmagnitude in some favourable toy cases.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jan 2017 14:05:55 GMT"}], "update_date": "2017-01-23", "authors_parsed": [["Poncet", "Romain", "", "CMAP"]]}, {"id": "1701.05911", "submitter": "Mehmet Caner", "authors": "Mehmet Caner", "title": "Delta Theorem in the Age of High Dimensions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a new version of delta theorem, that takes into account of high\ndimensional parameter estimation. We show that depending on the structure of\nthe function, the limits of functions of estimators have faster or slower rate\nof convergence than the limits of estimators. We illustrate this via two\nexamples. First, we use it for testing in high dimensions, and second in\nestimating large portfolio risk. Our theorem works in the case of larger number\nof parameters, $p$, than the sample size, $n$: $p>n$.\n", "versions": [{"version": "v1", "created": "Fri, 20 Jan 2017 19:26:52 GMT"}], "update_date": "2017-01-24", "authors_parsed": [["Caner", "Mehmet", ""]]}, {"id": "1701.05994", "submitter": "Hidehiko Kamiya", "authors": "Hidehiko Kamiya", "title": "Estimation of the shape of the density contours of star-shaped\n  distributions", "comments": "10 pages, 2 figures", "journal-ref": "Communications in Statistics---Theory and Methods, Vol. 48, No.\n  12, pp.3092--3104 (2019)", "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Elliptically contoured distributions generalize the multivariate normal\ndistributions in such a way that the density generators need not be\nexponential. However, as the name suggests, elliptically contoured\ndistributions remain to be restricted in that the similar density contours\nought to be elliptical. Kamiya, Takemura and Kuriki [Star-shaped distributions\nand their generalizations, Journal of Statistical Planning and Inference 138\n(2008), 3429--3447] proposed star-shaped distributions, for which the density\ncontours are allowed to be boundaries of arbitrary similar star-shaped sets. In\nthe present paper, we propose a nonparametric estimator of the shape of the\ndensity contours of star-shaped distributions, and prove its strong consistency\nwith respect to the Hausdorff distance. We illustrate our estimator by\nsimulation.\n", "versions": [{"version": "v1", "created": "Sat, 21 Jan 2017 07:52:40 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Kamiya", "Hidehiko", ""]]}, {"id": "1701.06009", "submitter": "Qian Lin", "authors": "Qian Lin, Xinran Li, Dongming Huang, Jun S. Liu", "title": "On the optimality of sliced inverse regression in high dimensions", "comments": "40 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The central subspace of a pair of random variables $(y,x) \\in\n\\mathbb{R}^{p+1}$ is the minimal subspace $\\mathcal{S}$ such that $y \\perp\n\\hspace{-2mm} \\perp x\\mid P_{\\mathcal{S}}x$. In this paper, we consider the\nminimax rate of estimating the central space of the multiple index models\n$y=f(\\beta_{1}^{\\tau}x,\\beta_{2}^{\\tau}x,...,\\beta_{d}^{\\tau}x,\\epsilon)$ with\nat most $s$ active predictors where $x \\sim N(0,I_{p})$. We first introduce a\nlarge class of models depending on the smallest non-zero eigenvalue $\\lambda$\nof $var(\\mathbb{E}[x|y])$, over which we show that an aggregated estimator\nbased on the SIR procedure converges at rate\n$d\\wedge((sd+s\\log(ep/s))/(n\\lambda))$. We then show that this rate is optimal\nin two scenarios: the single index models; and the multiple index models with\nfixed central dimension $d$ and fixed $\\lambda$. By assuming a technical\nconjecture, we can show that this rate is also optimal for multiple index\nmodels with bounded dimension of the central space. We believe that these\n(conditional) optimal rate results bring us meaningful insights of general SDR\nproblems in high dimensions.\n", "versions": [{"version": "v1", "created": "Sat, 21 Jan 2017 11:08:12 GMT"}, {"version": "v2", "created": "Tue, 24 Jan 2017 02:15:27 GMT"}], "update_date": "2017-01-25", "authors_parsed": [["Lin", "Qian", ""], ["Li", "Xinran", ""], ["Huang", "Dongming", ""], ["Liu", "Jun S.", ""]]}, {"id": "1701.06010", "submitter": "Alfredo Alegr\\'ia", "authors": "Alfredo Alegr\\'ia, Emilio Porcu, Reinhard Furrer, Jorge Mateu", "title": "Covariance Functions for Multivariate Gaussian Fields Evolving\n  Temporally over Planet Earth", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The construction of valid and flexible cross-covariance functions is a\nfundamental task for modeling multivariate space-time data arising from\nclimatological and oceanographical phenomena. Indeed, a suitable specification\nof the covariance structure allows to capture both the space-time dependencies\nbetween the observations and the development of accurate predictions. For data\nobserved over large portions of planet Earth it is necessary to take into\naccount the curvature of the planet. Hence the need for random field models\ndefined over spheres across time. In particular, the associated covariance\nfunction should depend on the geodesic distance, which is the most natural\nmetric over the spherical surface. In this work, we propose a flexible\nparametric family of matrix-valued covariance functions, with both marginal and\ncross structure being of the Gneiting type. We additionally introduce a\ndifferent multivariate Gneiting model based on the adaptation of the latent\ndimension approach to the spherical context. Finally, we assess the performance\nof our models through the study of a bivariate space-time data set of surface\nair temperatures and precipitations.\n", "versions": [{"version": "v1", "created": "Sat, 21 Jan 2017 11:18:54 GMT"}, {"version": "v2", "created": "Tue, 21 Nov 2017 23:20:09 GMT"}], "update_date": "2017-11-23", "authors_parsed": [["Alegr\u00eda", "Alfredo", ""], ["Porcu", "Emilio", ""], ["Furrer", "Reinhard", ""], ["Mateu", "Jorge", ""]]}, {"id": "1701.06088", "submitter": "Shih-Kang Chao", "authors": "Stanislav Volgushev and Shih-Kang Chao and Guang Cheng", "title": "Distributed inference for quantile regression processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increased availability of massive data sets provides a unique opportunity\nto discover subtle patterns in their distributions, but also imposes\noverwhelming computational challenges. To fully utilize the information\ncontained in big data, we propose a two-step procedure: (i) estimate\nconditional quantile functions at different levels in a parallel computing\nenvironment; (ii) construct a conditional quantile regression process through\nprojection based on these estimated quantile curves. Our general quantile\nregression framework covers both linear models with fixed or growing dimension\nand series approximation models. We prove that the proposed procedure does not\nsacrifice any statistical inferential accuracy provided that the number of\ndistributed computing units and quantile levels are chosen properly. In\nparticular, a sharp upper bound for the former and a sharp lower bound for the\nlatter are derived to capture the minimal computational cost from a statistical\nperspective. As an important application, the statistical inference on\nconditional distribution functions is considered. Moreover, we propose\ncomputationally efficient approaches to conducting inference in the distributed\nestimation setting described above. Those approaches directly utilize the\navailability of estimators from sub-samples and can be carried out at almost no\nadditional computational cost. Simulations confirm our statistical inferential\ntheory.\n", "versions": [{"version": "v1", "created": "Sat, 21 Jan 2017 21:32:34 GMT"}, {"version": "v2", "created": "Fri, 24 Nov 2017 16:38:35 GMT"}, {"version": "v3", "created": "Tue, 10 Apr 2018 18:13:27 GMT"}], "update_date": "2018-04-12", "authors_parsed": [["Volgushev", "Stanislav", ""], ["Chao", "Shih-Kang", ""], ["Cheng", "Guang", ""]]}, {"id": "1701.06140", "submitter": "Ulrich Faigle", "authors": "Ulrich Faigle and Gerhard Gierz", "title": "Markovian Statistics on Evolving Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel framework for the analysis of observation statistics on time discrete\nlinear evolutions in Banach space is presented. The model differs from\ntraditional models for stochastic processes and, in particular, clearly\ndistinguishes between the deterministic evolution of a system and the\nstochastic nature of observations on the evolving system. General Markov chains\nare defined in this context and it is shown how typical traditional models of\nclassical or quantum random walks and Markov processes fit into the framework\nand how a theory of quantum statistics ({\\it sensu} Barndorff-Nielsen, Gill and\nJupp) may be developed from it. The framework permits a general theory of joint\nobservability of two or more observation variables which may be viewed as an\nextension of the Heisenberg uncertainty principle and, in particular, offers a\nnovel mathematical perspective on the violation of Bell's inequalities in\nquantum models. Main results include a general sampling theorem relative to\nRiesz evolution operators in the spirit of von Neumann's mean ergodic theorem\nfor normal operators in Hilbert space.\n", "versions": [{"version": "v1", "created": "Sun, 22 Jan 2017 09:21:23 GMT"}], "update_date": "2017-01-24", "authors_parsed": [["Faigle", "Ulrich", ""], ["Gierz", "Gerhard", ""]]}, {"id": "1701.06381", "submitter": "Kazuto Fukuchi", "authors": "Kazuto Fukuchi and Jun Sakuma", "title": "Minimax Optimal Estimators for Additive Scalar Functionals of Discrete\n  Distributions", "comments": "39 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider estimators for an additive functional of $\\phi$,\nwhich is defined as $\\theta(P;\\phi)=\\sum_{i=1}^k\\phi(p_i)$, from $n$ i.i.d.\nrandom samples drawn from a discrete distribution $P=(p_1,...,p_k)$ with\nalphabet size $k$. We propose a minimax optimal estimator for the estimation\nproblem of the additive functional. We reveal that the minimax optimal rate is\ncharacterized by the divergence speed of the fourth derivative of $\\phi$ if the\ndivergence speed is high. As a result, we show there is no consistent estimator\nif the divergence speed of the fourth derivative of $\\phi$ is larger than\n$p^{-4}$. Furthermore, if the divergence speed of the fourth derivative of\n$\\phi$ is $p^{4-\\alpha}$ for $\\alpha \\in (0,1)$, the minimax optimal rate is\nobtained within a universal multiplicative constant as $\\frac{k^2}{(n\\ln\nn)^{2\\alpha}} + \\frac{k^{2-2\\alpha}}{n}$.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jan 2017 13:35:24 GMT"}, {"version": "v2", "created": "Wed, 21 Jun 2017 06:00:22 GMT"}, {"version": "v3", "created": "Thu, 7 Dec 2017 02:49:16 GMT"}], "update_date": "2017-12-08", "authors_parsed": [["Fukuchi", "Kazuto", ""], ["Sakuma", "Jun", ""]]}, {"id": "1701.06501", "submitter": "Victor-Emmanuel Brunel", "authors": "Victor-Emmanuel Brunel, Ankur Moitra, Philippe Rigollet, John Urschel", "title": "Maximum likelihood estimation of determinantal point processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Determinantal point processes (DPPs) have wide-ranging applications in\nmachine learning, where they are used to enforce the notion of diversity in\nsubset selection problems. Many estimators have been proposed, but surprisingly\nthe basic properties of the maximum likelihood estimator (MLE) have received\nlittle attention. The difficulty is that it is a non-concave maximization\nproblem, and such functions are notoriously difficult to understand in high\ndimensions, despite their importance in modern machine learning. Here we study\nboth the local and global geometry of the expected log-likelihood function. We\nprove several rates of convergence for the MLE and give a complete\ncharacterization of the case where these are parametric. We also exhibit a\npotential curse of dimensionality where the asymptotic variance of the MLE\nscales exponentially with the dimension of the problem. Moreover, we exhibit an\nexponential number of saddle points, and give evidence that these may be the\nonly critical points.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jan 2017 17:01:26 GMT"}, {"version": "v2", "created": "Fri, 3 Mar 2017 19:36:58 GMT"}, {"version": "v3", "created": "Fri, 21 Jul 2017 20:28:05 GMT"}], "update_date": "2017-07-25", "authors_parsed": [["Brunel", "Victor-Emmanuel", ""], ["Moitra", "Ankur", ""], ["Rigollet", "Philippe", ""], ["Urschel", "John", ""]]}, {"id": "1701.06642", "submitter": "Lev B Klebanov", "authors": "Lev B. Klebanov, Jaromir Antoch, Andrea Karlova and Ashot V. Kakosyan", "title": "Outliers and related problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define outliers as a set of observations which contradicts the proposed\nmathematical (statistical) model and we discuss the frequently observed types\nof the outliers. Further we explore what changes in the model have to be made\nin order to avoid the occurance of the outliers. We observe that some variants\nof the outliers lead to classical results in probability, such as the law of\nlarge numbers and the concept of heavy tailed distributions.\n  Key words: outlier; the law of large numbers; heavy tailed distributions;\nmodel rejection.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jan 2017 21:42:31 GMT"}], "update_date": "2017-01-25", "authors_parsed": [["Klebanov", "Lev B.", ""], ["Antoch", "Jaromir", ""], ["Karlova", "Andrea", ""], ["Kakosyan", "Ashot V.", ""]]}, {"id": "1701.06836", "submitter": "Klaus Nordhausen", "authors": "Klaus Nordhausen, Hannu Oja, David E. Tyler, Joni Virta", "title": "Asymptotic and bootstrap tests for the dimension of the non-Gaussian\n  subspace", "comments": null, "journal-ref": "Signal Processing Letters, Vol 24, 887-891 (2017)", "doi": "10.1109/LSP.2017.2696880", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dimension reduction is often a preliminary step in the analysis of large data\nsets. The so-called non-Gaussian component analysis searches for a projection\nonto the non-Gaussian part of the data, and it is then important to know the\ncorrect dimension of the non-Gaussian signal subspace. In this paper we develop\nasymptotic as well as bootstrap tests for the dimension based on the popular\nfourth order blind identification (FOBI) method.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jan 2017 12:29:29 GMT"}], "update_date": "2017-06-16", "authors_parsed": [["Nordhausen", "Klaus", ""], ["Oja", "Hannu", ""], ["Tyler", "David E.", ""], ["Virta", "Joni", ""]]}, {"id": "1701.06876", "submitter": "Yoav Zemel", "authors": "Yoav Zemel and Victor M. Panaretos", "title": "Fr\\'echet Means and Procrustes Analysis in Wasserstein Space", "comments": "45 pages, 10 figures; to appear in Bernoulli Journal. Added\n  references, mainly from computer science literature", "journal-ref": "Bernoulli 25(2):932-976, 2019", "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider two statistical problems at the intersection of functional and\nnon-Euclidean data analysis: the determination of a Fr\\'echet mean in the\nWasserstein space of multivariate distributions; and the optimal registration\nof deformed random measures and point processes. We elucidate how the two\nproblems are linked, each being in a sense dual to the other. We first study\nthe finite sample version of the problem in the continuum. Exploiting the\ntangent bundle structure of Wasserstein space, we deduce the Fr\\'echet mean via\ngradient descent. We show that this is equivalent to a Procrustes analysis for\nthe registration maps, thus only requiring successive solutions to pairwise\noptimal coupling problems. We then study the population version of the problem,\nfocussing on inference and stability: in practice, the data are i.i.d.\nrealisations from a law on Wasserstein space, and indeed their observation is\ndiscrete, where one observes a proxy finite sample or point process. We\nconstruct regularised nonparametric estimators, and prove their consistency for\nthe population mean, and uniform consistency for the population Procrustes\nregistration maps.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jan 2017 14:00:19 GMT"}, {"version": "v2", "created": "Wed, 17 Jan 2018 15:45:31 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Zemel", "Yoav", ""], ["Panaretos", "Victor M.", ""]]}, {"id": "1701.06926", "submitter": "Yongcheng Qi", "authors": "Shuhua Chang and Yongcheng Qi", "title": "Empirical Distribution of Scaled Eigenvalues for Product of Matrices\n  from the Spherical Ensemble", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider the product of $m$ independent $n\\times n$ random matrices from the\nspherical ensemble for $m\\ge 1$. The empirical distribution based on the $n$\neigenvalues of the product is called the empirical spectral distribution. Two\nrecent papers by G\\\"otze, K\\\"osters and Tikhomirov (2015) and Zeng (2016)\nobtain the limit of the empirical spectral distribution for the product when\n$m$ is a fixed integer. In this paper, we investigate the limiting empirical\ndistribution of scaled eigenvalues for the product of $m$ independent matrices\nfrom the spherical ensemble in the case when $m$ changes with $n$, that is,\n$m=m_n$ is an arbitrary sequence of positive integers.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jan 2017 15:26:54 GMT"}, {"version": "v2", "created": "Wed, 5 Apr 2017 03:16:03 GMT"}], "update_date": "2017-04-06", "authors_parsed": [["Chang", "Shuhua", ""], ["Qi", "Yongcheng", ""]]}, {"id": "1701.07195", "submitter": "Fetze Pijlman", "authors": "Fetze Pijlman", "title": "Equal confidence weighted expectation value estimates", "comments": "10 pages, feedback is welcome", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article the issues are discussed with the Bayesian approach,\nleast-square fits, and most-likely fits. Trying to counter these issues, a\nmethod, based on weighted confidence, is proposed for estimating probabilities\nand other observables. This method sums over different model parameter\ncombinations but does not require the need for making assumptions on priors or\nunderlying probability functions. Moreover, by construction the results are\ninvariant under reparametrization of the model parameters. In one case the\nresult appears similar as in Bayesian statistics but in general there is no\nagreement. The binomial distribution is also studied which turns out to be\nuseful for making predictions on production processes without the need to make\nfurther assumptions. In the last part, the case of a simple linear fit (a\nmulti-variate example) is studied using the standard approaches and the\nconfidence weighted approach.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jan 2017 07:52:14 GMT"}], "update_date": "2017-01-26", "authors_parsed": [["Pijlman", "Fetze", ""]]}, {"id": "1701.07249", "submitter": "Dennis Leung", "authors": "Dennis Leung, Qi-Man Shao", "title": "Asymptotic power of Rao's score test for independence in high dimensions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let ${\\bf R}$ be the Pearson correlation matrix of $m$ normal random\nvariables. The Rao's score test for the independence hypothesis $H_0 : {\\bf R}\n= {\\bf I}_m$, where ${\\bf I}_m$ is the identity matrix of dimension $m$, was\nfirst considered by Schott (2005) in the high dimensional setting. In this\npaper, we study the asymptotic minimax power function of this test, under an\nasymptotic regime in which both $m$ and the sample size $n$ tend to infinity\nwith the ratio $m/n$ upper bounded by a constant. In particular, our result\nimplies that the Rao's score test is rate-optimal for detecting the dependency\nsignal $\\|{\\bf R} - {\\bf I}_m\\|_F$ of order $\\sqrt{m/n}$, where $\\|\\cdot\\|_F$\nis the matrix Frobenius norm.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jan 2017 10:36:23 GMT"}, {"version": "v2", "created": "Sun, 10 Dec 2017 00:10:04 GMT"}], "update_date": "2017-12-12", "authors_parsed": [["Leung", "Dennis", ""], ["Shao", "Qi-Man", ""]]}, {"id": "1701.07308", "submitter": "Promit Ghosal Mr.", "authors": "Promit Ghosal", "title": "Hall-Littlewood-PushTASEP and its KPZ limit", "comments": "71 Pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math-ph math.MP math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a new model of interactive particle systems which we call the\nrandomly activated cascading exclusion process (RACEP). Particles wake up\naccording to exponential clocks and then take a geometric number of steps. If\nanother particle is encountered during these steps, the first particle goes to\nsleep at that location and the second is activated and proceeds accordingly. We\nconsider a totally asymmetric version of this model which we refer as\nHall-Littlewood-PushTASEP (HL-PushTASEP) on $\\mathbb{Z}_{\\geq 0}$ lattice where\nparticles only move right and where initially particles are distributed\naccording to Bernoulli product measure on $\\mathbb{Z}_{\\geq 0}$. We prove\nKPZ-class limit theorems for the height function fluctuations. Under a\nparticular weak scaling, we also prove convergence to the solution of the KPZ\nequation.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jan 2017 13:48:10 GMT"}], "update_date": "2017-01-26", "authors_parsed": [["Ghosal", "Promit", ""]]}, {"id": "1701.07402", "submitter": "Santosh Kumar", "authors": "Santosh Kumar, Bharath Sambasivam and Shashank Anand", "title": "Smallest eigenvalue density for regular or fixed-trace complex\n  Wishart-Laguerre ensemble and entanglement in coupled kicked tops", "comments": "Published version", "journal-ref": "Journal of Physics A: Mathematical and Theoretical, Volume 50,\n  Number 34, Page - 345201, Year 2017", "doi": "10.1088/1751-8121/aa7d0e", "report-no": null, "categories": "math-ph cond-mat.stat-mech math.MP math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The statistical behaviour of the smallest eigenvalue has important\nimplications for systems which can be modeled using a Wishart-Laguerre\nensemble, the regular one or the fixed trace one. For example, the density of\nthe smallest eigenvalue of the Wishart-Laguerre ensemble plays a crucial role\nin characterizing multiple channel telecommunication systems. Similarly, in the\nquantum entanglement problem, the smallest eigenvalue of the fixed trace\nensemble carries information regarding the nature of entanglement.\n  For real Wishart-Laguerre matrices, there exists an elegant recurrence scheme\nsuggested by Edelman to directly obtain the exact expression for the smallest\neigenvalue density. In the case of complex Wishart-Laguerre matrices, for\nfinding exact and explicit expressions for the smallest eigenvalue density,\nexisting results based on determinants become impractical when the determinants\ninvolve large-size matrices. In this work, we derive a recurrence scheme for\nthe complex case which is analogous to that of Edelman's for the real case.\nThis is used to obtain exact results for the smallest eigenvalue density for\nboth the regular, and the fixed trace complex Wishart-Laguerre ensembles. We\nvalidate our analytical results using Monte Carlo simulations. We also study\nscaled Wishart-Laguerre ensemble and investigate its efficacy in approximating\nthe fixed-trace ensemble. Eventually, we apply our result for the fixed-trace\nensemble to investigate the behaviour of the smallest eigenvalue in the\nparadigmatic system of coupled kicked tops.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jan 2017 17:47:32 GMT"}, {"version": "v2", "created": "Sat, 29 Jul 2017 08:28:53 GMT"}], "update_date": "2017-08-01", "authors_parsed": [["Kumar", "Santosh", ""], ["Sambasivam", "Bharath", ""], ["Anand", "Shashank", ""]]}, {"id": "1701.07535", "submitter": "Radislav Vaisman", "authors": "Radislav Vaisman, Robert Salomone, Dirk P. Kroese", "title": "Stratified Splitting for Efficient Monte Carlo Integration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The efficient evaluation of high-dimensional integrals is of importance in\nboth theoretical and practical fields of science, such as data science,\nstatistical physics, and machine learning. However, exact computation methods\nsuffer from the curse of dimensionality. However, due to the curse of\ndimensionality, deterministic numerical methods are inefficient in\nhigh-dimensional settings. Consequentially, for many practical problems, one\nmust resort to Monte Carlo estimation. In this paper, we introduce a novel\nSequential Monte Carlo technique called Stratified Splitting. The method\nprovides unbiased estimates and can handle various integrand types including\nindicator functions, which are used in rare-event probability estimation\nproblems. Moreover, we demonstrate that a variant of the algorithm can achieve\npolynomial complexity. The results of our numerical experiments suggest that\nthe Stratified Splitting method is capable of delivering accurate results for a\nvariety of integration problems.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jan 2017 01:20:36 GMT"}, {"version": "v2", "created": "Thu, 14 Dec 2017 08:18:02 GMT"}], "update_date": "2017-12-15", "authors_parsed": [["Vaisman", "Radislav", ""], ["Salomone", "Robert", ""], ["Kroese", "Dirk P.", ""]]}, {"id": "1701.07568", "submitter": "Yong Chen", "authors": "Yong Chen, Yaozhong Hu and Zhi Wang", "title": "Parameter Estimation of Complex Fractional Ornstein-Uhlenbeck Processes\n  with Fractional Noise", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We obtain strong consistency and asymptotic normality of a least squares\nestimator of the drift coefficient for complex-valued Ornstein-Uhlenbeck\nprocesses disturbed by fractional noise, extending the result of Y. Hu and D.\nNualart, [Statist. Probab. Lett., 80 (2010), 1030-1038] to a special\n2-dimensions. The strategy is to exploit the Garsia-Rodemich-Rumsey inequality\nand complex fourth moment theorems. The main ingredients of this paper are the\nsample path regularity of a multiple Wiener-Ito integral and two equivalent\nconditions of complex fourth moment theorems in terms of the contractions of\nintegral kernels and complex Malliavin derivatives.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jan 2017 03:40:57 GMT"}], "update_date": "2017-01-27", "authors_parsed": [["Chen", "Yong", ""], ["Hu", "Yaozhong", ""], ["Wang", "Zhi", ""]]}, {"id": "1701.07572", "submitter": "Shuang Zhou", "authors": "Shuang Zhou, Debdeep Pati, Anirban Bhattacharya, David Dunson", "title": "Adaptive posterior convergence rates in non-linear latent variable\n  models", "comments": "arXiv admin note: substantial text overlap with arXiv:1109.5000", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-linear latent variable models have become increasingly popular in a\nvariety of applications. However, there has been little study on theoretical\nproperties of these models. In this article, we study rates of posterior\ncontraction in univariate density estimation for a class of non-linear latent\nvariable models where unobserved U(0,1) latent variables are related to the\nresponse variables via a random non-linear regression with an additive error.\nOur approach relies on characterizing the space of densities induced by the\nabove model as kernel convolutions with a general class of continuous mixing\nmeasures. The literature on posterior rates of contraction in density\nestimation almost entirely focuses on finite or countably infinite mixture\nmodels. We develop approximation results for our class of continuous mixing\nmeasures. Using an appropriate Gaussian process prior on the unknown regression\nfunction, we obtain the optimal frequentist rate up to a logarithmic factor\nunder standard regularity conditions on the true density.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jan 2017 04:20:05 GMT"}], "update_date": "2017-01-27", "authors_parsed": [["Zhou", "Shuang", ""], ["Pati", "Debdeep", ""], ["Bhattacharya", "Anirban", ""], ["Dunson", "David", ""]]}, {"id": "1701.07736", "submitter": "Hiroshi Nagaoka", "authors": "Hiroshi Nagaoka", "title": "Information-geometrical characterization of statistical models which are\n  statistically equivalent to probability simplexes", "comments": "Submitted to IEEE ISIT 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The probability simplex is the set of all probability distributions on a\nfinite set and is the most fundamental object in the finite probability theory.\nIn this paper we give a characterization of statistical models on finite sets\nwhich are statistically equivalent to probability simplexes in terms of\n$\\alpha$-families including exponential families and mixture families. The\nsubject has a close relation to some fundamental aspects of information\ngeometry such as $\\alpha$-connections and autoparallelity.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jan 2017 15:17:20 GMT"}, {"version": "v2", "created": "Wed, 8 Feb 2017 01:44:23 GMT"}], "update_date": "2017-02-09", "authors_parsed": [["Nagaoka", "Hiroshi", ""]]}, {"id": "1701.07796", "submitter": "Venkat Anantharam", "authors": "Venkat Anantharam", "title": "A Variational Characterization of R\\'enyi Divergences", "comments": "EECS Department, University of California, Berkeley CA 94720", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Atar, Chowdhary and Dupuis have recently exhibited a variational formula for\nexponential integrals of bounded measurable functions in terms of R\\'enyi\ndivergences. We develop a variational characterization of the R\\'enyi\ndivergences between two probability distributions on a measurable sace in terms\nof relative entropies. When combined with the elementary variational formula\nfor exponential integrals of bounded measurable functions in terms of relative\nentropy, this yields the variational formula of Atar, Chowdhary and Dupuis as a\ncorollary. We also develop an analogous variational characterization of the\nR\\'enyi divergence rates between two stationary finite state Markov chains in\nterms of relative entropy rates. When combined with Varadhan's variational\ncharacterization of the spectral radius of square matrices with nonnegative\nentries in terms of relative entropy, this yields an analog of the variational\nformula of Atar, Chowdary and Dupuis in the framework of finite state Markov\nchains.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jan 2017 18:06:21 GMT"}], "update_date": "2017-01-27", "authors_parsed": [["Anantharam", "Venkat", ""]]}, {"id": "1701.08010", "submitter": "L\\'eo Miolane", "authors": "Thibault Lesieur, L\\'eo Miolane, Marc Lelarge, Florent Krzakala and\n  Lenka Zdeborov\\'a", "title": "Statistical and computational phase transitions in spiked tensor\n  estimation", "comments": "17 pages, 3 figures, 1 table", "journal-ref": "IEEE International Symposium on Information Theory (ISIT), pp.\n  511-515 (2017)", "doi": "10.1109/ISIT.2017.8006580", "report-no": null, "categories": "math.ST cond-mat.dis-nn cs.IT math.IT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider tensor factorizations using a generative model and a Bayesian\napproach. We compute rigorously the mutual information, the Minimal Mean\nSquared Error (MMSE), and unveil information-theoretic phase transitions. In\naddition, we study the performance of Approximate Message Passing (AMP) and\nshow that it achieves the MMSE for a large set of parameters, and that\nfactorization is algorithmically \"easy\" in a much wider region than previously\nbelieved. It exists, however, a \"hard\" region where AMP fails to reach the MMSE\nand we conjecture that no polynomial algorithm will improve on AMP.\n", "versions": [{"version": "v1", "created": "Fri, 27 Jan 2017 10:50:43 GMT"}, {"version": "v2", "created": "Sat, 16 Dec 2017 14:28:39 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Lesieur", "Thibault", ""], ["Miolane", "L\u00e9o", ""], ["Lelarge", "Marc", ""], ["Krzakala", "Florent", ""], ["Zdeborov\u00e1", "Lenka", ""]]}, {"id": "1701.08083", "submitter": "Kevin Moon", "authors": "Kevin R. Moon, Kumar Sricharan, Alfred O. Hero III", "title": "Ensemble Estimation of Generalized Mutual Information with Applications\n  to Genomics", "comments": "Published in IEEE Transactions on Information Theory in 2021; 42\n  pages, 3 figures; a shorter version of this paper was published at IEEE ISIT\n  2017 under the title \"Ensemble estimation of mutual information\"", "journal-ref": null, "doi": "10.1109/TIT.2021.3100108", "report-no": null, "categories": "cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mutual information is a measure of the dependence between random variables\nthat has been used successfully in myriad applications in many fields.\nGeneralized mutual information measures that go beyond classical Shannon mutual\ninformation have also received much interest in these applications. We derive\nthe mean squared error convergence rates of kernel density-based plug-in\nestimators of general mutual information measures between two multidimensional\nrandom variables $\\mathbf{X}$ and $\\mathbf{Y}$ for two cases: 1) $\\mathbf{X}$\nand $\\mathbf{Y}$ are continuous; 2) $\\mathbf{X}$ and $\\mathbf{Y}$ may have any\nmixture of discrete and continuous components. Using the derived rates, we\npropose an ensemble estimator of these information measures called GENIE by\ntaking a weighted sum of the plug-in estimators with varied bandwidths. The\nresulting ensemble estimators achieve the $1/N$ parametric mean squared error\nconvergence rate when the conditional densities of the continuous variables are\nsufficiently smooth. To the best of our knowledge, this is the first\nnonparametric mutual information estimator known to achieve the parametric\nconvergence rate for the mixture case, which frequently arises in applications\n(e.g. variable selection in classification). The estimator is simple to\nimplement and it uses the solution to an offline convex optimization problem\nand simple plug-in estimators. A central limit theorem is also derived for the\nensemble estimators and minimax rates are derived for the continuous case. We\ndemonstrate the ensemble estimator for the mixed case on simulated data and\napply the proposed estimator to analyze gene relationships in single cell data.\n", "versions": [{"version": "v1", "created": "Fri, 27 Jan 2017 15:38:01 GMT"}, {"version": "v2", "created": "Thu, 5 Sep 2019 22:29:26 GMT"}, {"version": "v3", "created": "Wed, 30 Jun 2021 05:26:00 GMT"}, {"version": "v4", "created": "Thu, 29 Jul 2021 17:40:42 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Moon", "Kevin R.", ""], ["Sricharan", "Kumar", ""], ["Hero", "Alfred O.", "III"]]}, {"id": "1701.08149", "submitter": "Brendan Beare", "authors": "Brendan K. Beare and Won-Ki Seo", "title": "Representation of I(1) and I(2) autoregressive Hilbertian processes", "comments": "47 pages", "journal-ref": "Econom. Theory 36 (2020) 773-802", "doi": "10.1017/S0266466619000276", "report-no": null, "categories": "math.ST econ.EM stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend the Granger-Johansen representation theorems for I(1) and I(2)\nvector autoregressive processes to accommodate processes that take values in an\narbitrary complex separable Hilbert space. This more general setting is of\ncentral relevance for statistical applications involving functional time\nseries. We first obtain a range of necessary and sufficient conditions for a\npole in the inverse of a holomorphic index-zero Fredholm operator pencil to be\nof first or second order. Those conditions form the basis for our development\nof I(1) and I(2) representations of autoregressive Hilbertian processes.\nCointegrating and attractor subspaces are characterized in terms of the\nbehavior of the autoregressive operator pencil in a neighborhood of one.\n", "versions": [{"version": "v1", "created": "Fri, 27 Jan 2017 18:49:53 GMT"}, {"version": "v2", "created": "Mon, 2 Apr 2018 23:01:36 GMT"}, {"version": "v3", "created": "Wed, 20 Mar 2019 14:58:58 GMT"}, {"version": "v4", "created": "Fri, 6 Sep 2019 12:08:01 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Beare", "Brendan K.", ""], ["Seo", "Won-Ki", ""]]}, {"id": "1701.08185", "submitter": "Jan Mandel", "authors": "Marie Tur\\v{c}i\\v{c}ov\\'a, Jan Mandel, and Kry\\v{s}tof Eben", "title": "Multilevel maximum likelihood estimation with application to covariance\n  matrices", "comments": "18 pages, 6 figures; better resolution images", "journal-ref": "Communications in Statistics - Theory and Methods (2018)", "doi": "10.1080/03610926.2017.1422755", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The asymptotic variance of the maximum likelihood estimate is proved to\ndecrease when the maximization is restricted to a subspace that contains the\ntrue parameter value. Maximum likelihood estimation allows a systematic fitting\nof covariance models to the sample, which is important in data assimilation.\nThe hierarchical maximum likelihood approach is applied to the spectral\ndiagonal covariance model with different parameterizations of eigenvalue decay,\nand to the sparse inverse covariance model with specified parameter values on\ndifferent sets of nonzero entries. It is shown computationally that using\nsmaller sets of parameters can decrease the sampling noise in high dimension\nsubstantially.\n", "versions": [{"version": "v1", "created": "Fri, 27 Jan 2017 20:29:22 GMT"}, {"version": "v2", "created": "Sat, 16 Sep 2017 17:48:01 GMT"}, {"version": "v3", "created": "Fri, 12 Jan 2018 03:10:49 GMT"}], "update_date": "2018-01-31", "authors_parsed": [["Tur\u010di\u010dov\u00e1", "Marie", ""], ["Mandel", "Jan", ""], ["Eben", "Kry\u0161tof", ""]]}, {"id": "1701.08284", "submitter": "Mareile Gro{\\ss}e Ruse", "authors": "Mareile Gro{\\ss}e Ruse, Adeline Samson and Susanne Ditlevsen", "title": "Multivariate inhomogeneous diffusion models with covariates and mixed\n  effects", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling of longitudinal data often requires diffusion models that\nincorporate overall time-dependent, nonlinear dynamics of multiple components\nand provide sufficient flexibility for subject-specific modeling. This\ncomplexity challenges parameter inference and approximations are inevitable. We\npropose a method for approximate maximum-likelihood parameter estimation in\nmultivariate time-inhomogeneous diffusions, where subject-specific flexibility\nis accounted for by incorporation of multidimensional mixed effects and\ncovariates. We consider $N$ multidimensional independent diffusions $X^i =\n(X^i_t)_{0\\leq t\\leq T^i}, 1\\leq i\\leq N$, with common overall model structure\nand unknown fixed-effects parameter $\\mu$. Their dynamics differ by the\nsubject-specific random effect $\\phi^i$ in the drift and possibly by (known)\ncovariate information, different initial conditions and observation times and\nduration. The distribution of $\\phi^i$ is parametrized by an unknown\n$\\vartheta$ and $\\theta = (\\mu, \\vartheta)$ is the target of statistical\ninference. Its maximum likelihood estimator is derived from the continuous-time\nlikelihood. We prove consistency and asymptotic normality of $\\hat{\\theta}_N$\nwhen the number $N$ of subjects goes to infinity using standard techniques and\nconsider the more general concept of local asymptotic normality for less\nregular models. The bias induced by time-discretization of sufficient\nstatistics is investigated. We discuss verification of conditions and\ninvestigate parameter estimation and hypothesis testing in simulations.\n", "versions": [{"version": "v1", "created": "Sat, 28 Jan 2017 11:37:37 GMT"}], "update_date": "2017-01-31", "authors_parsed": [["Ruse", "Mareile Gro\u00dfe", ""], ["Samson", "Adeline", ""], ["Ditlevsen", "Susanne", ""]]}, {"id": "1701.08338", "submitter": "Azam Asanjarani", "authors": "Azam Asanjarani, Yoni Nazarathy, and Philip K. Pollett", "title": "Parameter and State Estimation in Queues and Related Stochastic Models:\n  A Bibliography", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.PF stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is an annotated bibliography on estimation and inference results for\nqueues and related stochastic models. The purpose of this document is to\ncollect and categorise works in the field, allowing for researchers and\npractitioners to explore the various types of results that exist. This\nbibliography attempts to include all known works that satisfy both of these\nrequirements: -Works that deal with queueing models. -Works that contain\ncontributions related to the methodology of parameter estimation, state\nestimation, hypothesis testing, confidence interval and/or actual datasets of\napplication areas. Our attempt is to make this bibliography exhaustive, yet\nthere are possibly some papers that we have missed. As it is updated\ncontinuously, additions and comments are welcomed. The sections below\ncategorise the works based on several categories. A single paper may appear in\nseveral categories simultaneously. The final section lists all works in\nchronological order along with short descriptions of the contributions. This\nbibliography is maintained at\nhttp://www.maths.uq.edu.au/~pkp/papers/Qest/Qest.html and may be cited as such.\nWe welcome additions and corrections.\n", "versions": [{"version": "v1", "created": "Sun, 29 Jan 2017 00:21:07 GMT"}], "update_date": "2017-01-31", "authors_parsed": [["Asanjarani", "Azam", ""], ["Nazarathy", "Yoni", ""], ["Pollett", "Philip K.", ""]]}, {"id": "1701.08366", "submitter": "Kayvan Sadeghi", "authors": "Kayvan Sadeghi", "title": "Faithfulness of Probability Distributions and Graphs", "comments": "29 pages, 3 figures", "journal-ref": "Journal of Machine Learning Research, 18(148), 1--29, 2017", "doi": null, "report-no": null, "categories": "math.ST stat.OT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A main question in graphical models and causal inference is whether, given a\nprobability distribution $P$ (which is usually an underlying distribution of\ndata), there is a graph (or graphs) to which $P$ is faithful. The main goal of\nthis paper is to provide a theoretical answer to this problem. We work with\ngeneral independence models, which contain probabilistic independence models as\na special case. We exploit a generalization of ordering, called preordering, of\nthe nodes of (mixed) graphs. This allows us to provide sufficient conditions\nfor a given independence model to be Markov to a graph with the minimum\npossible number of edges, and more importantly, necessary and sufficient\nconditions for a given probability distribution to be faithful to a graph. We\npresent our results for the general case of mixed graphs, but specialize the\ndefinitions and results to the better-known subclasses of undirected\n(concentration) and bidirected (covariance) graphs as well as directed acyclic\ngraphs.\n", "versions": [{"version": "v1", "created": "Sun, 29 Jan 2017 11:49:54 GMT"}, {"version": "v2", "created": "Thu, 2 Nov 2017 17:11:08 GMT"}], "update_date": "2018-01-30", "authors_parsed": [["Sadeghi", "Kayvan", ""]]}, {"id": "1701.08420", "submitter": "Steffen Lauritzen", "authors": "Steffen Lauritzen and Alessandro Rinaldo and Kayvan Sadeghi", "title": "Random Networks, Graphical Models, and Exchangeability", "comments": "To appear in JRSSB", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study conditional independence relationships for random networks and their\ninterplay with exchangeability. We show that, for finitely exchangeable network\nmodels, the empirical subgraph densities are maximum likelihood estimates of\ntheir theoretical counterparts. We then characterize all possible Markov\nstructures for finitely exchangeable random graphs, thereby identifying a new\nclass of Markov network models corresponding to bidirected Kneser graphs. In\nparticular, we demonstrate that the fundamental property of dissociatedness\ncorresponds to a Markov property for exchangeable networks described by\nbidirected line graphs. Finally we study those exchangeable models that are\nalso summarized in the sense that the probability of a network only depends\nonthe degree distribution, and identify a class of models that is dual to the\nMarkov graphs of Frank and Strauss (1986). Particular emphasis is placed on\nstudying consistency properties of network models under the process of forming\nsubnetworks and we show that the only consistent systems of Markov properties\ncorrespond to the empty graph, the bidirected line graph of the complete graph,\nand the complete graph.\n", "versions": [{"version": "v1", "created": "Sun, 29 Jan 2017 19:23:45 GMT"}, {"version": "v2", "created": "Tue, 21 Nov 2017 13:34:41 GMT"}], "update_date": "2017-11-22", "authors_parsed": [["Lauritzen", "Steffen", ""], ["Rinaldo", "Alessandro", ""], ["Sadeghi", "Kayvan", ""]]}, {"id": "1701.08697", "submitter": "Xianyang Zhang", "authors": "Xianyang Zhang, Shun Yao and Xiaofeng Shao", "title": "Conditional Mean and Quantile Dependence Testing in High Dimension", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by applications in biological science, we propose a novel test to\nassess the conditional mean dependence of a response variable on a large number\nof covariates. Our procedure is built on the martingale difference divergence\nrecently proposed in Shao and Zhang (2014), and it is able to detect a certain\ntype of departure from the null hypothesis of conditional mean independence\nwithout making any specific model assumptions. Theoretically, we establish the\nasymptotic normality of the proposed test statistic under suitable assumption\non the eigenvalues of a Hermitian operator, which is constructed based on the\ncharacteristic function of the covariates. These conditions can be simplified\nunder banded dependence structure on the covariates or Gaussian design. To\naccount for heterogeneity within the data, we further develop a testing\nprocedure for conditional quantile independence at a given quantile level and\nprovide an asymptotic justification. Empirically, our test of conditional mean\nindependence delivers comparable results to the competitor, which was\nconstructed under the linear model framework, when the underlying model is\nlinear. It significantly outperforms the competitor when the conditional mean\nadmits a nonlinear form.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jan 2017 16:44:51 GMT"}], "update_date": "2017-01-31", "authors_parsed": [["Zhang", "Xianyang", ""], ["Yao", "Shun", ""], ["Shao", "Xiaofeng", ""]]}, {"id": "1701.08895", "submitter": "James Dowty", "authors": "James G. Dowty", "title": "Chentsov's theorem for exponential families", "comments": "Minor wording changes", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT math.DG math.IT math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chentsov's theorem characterizes the Fisher information metric on statistical\nmodels as essentially the only Riemannian metric that is invariant under\nsufficient statistics. This implies that each statistical model is naturally\nequipped with a geometry, so Chentsov's theorem explains why many statistical\nproperties can be described in geometric terms. However, despite being one of\nthe foundational theorems of statistics, Chentsov's theorem has only been\nproved previously in very restricted settings or under relatively strong\nregularity and invariance assumptions. We therefore prove a version of this\ntheorem for the important case of exponential families. In particular, we\ncharacterise the Fisher information metric as the only Riemannian metric (up to\nrescaling) on an exponential family and its derived families that is invariant\nunder independent and identically distributed extensions and canonical\nsufficient statistics. Our approach is based on the central limit theorem, so\nit gives a unified proof for both discrete and continuous exponential families,\nand it is less technical than previous approaches.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jan 2017 02:41:19 GMT"}, {"version": "v2", "created": "Mon, 22 May 2017 07:28:34 GMT"}], "update_date": "2017-05-23", "authors_parsed": [["Dowty", "James G.", ""]]}, {"id": "1701.09108", "submitter": "Florian Wisheckel", "authors": "Michael Falk, Florian Wisheckel", "title": "Asymptotic Independence of Bivariate Order Statistics", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well known that an extreme order statistic and a central order\nstatistic (os) as well as an intermediate os and a central os from a sample of\niid univariate random variables get asymptotically independent as the sample\nsize increases. We extend this result to bivariate random variables, where the\nos are taken componentwise. An explicit representation of the conditional\ndistribution of bivariate os turns out to be a powerful tool.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jan 2017 16:12:39 GMT"}], "update_date": "2017-02-01", "authors_parsed": [["Falk", "Michael", ""], ["Wisheckel", "Florian", ""]]}, {"id": "1701.09120", "submitter": "Pierre C. Bellec", "authors": "Pierre C. Bellec, Guillaume Lecu\\'e, Alexandre B. Tsybakov", "title": "Towards the study of least squares estimators with convex penalty", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Penalized least squares estimation is a popular technique in high-dimensional\nstatistics. It includes such methods as the LASSO, the group LASSO, and the\nnuclear norm penalized least squares. The existing theory of these methods is\nnot fully satisfying since it allows one to prove oracle inequalities with\nfixed high probability only for the estimators depending on this probability.\nFurthermore, the control of compatibility factors appearing in the oracle\nbounds is often not explicit. Some very recent developments suggest that the\ntheory of oracle inequalities can be revised in an improved way. In this paper,\nwe provide an overview of ideas and tools leading to such an improved theory.\nWe show that, along with overcoming the disadvantages mentioned above, the\nmethodology extends to the hilbertian framework and it applies to a large class\nof convex penalties. This paper is partly expository. In particular, we provide\nadapted proofs of some results from other recent work.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jan 2017 16:34:01 GMT"}, {"version": "v2", "created": "Fri, 7 Jul 2017 14:59:07 GMT"}], "update_date": "2017-07-10", "authors_parsed": [["Bellec", "Pierre C.", ""], ["Lecu\u00e9", "Guillaume", ""], ["Tsybakov", "Alexandre B.", ""]]}, {"id": "1701.09160", "submitter": "Przemys{\\l}aw Spurek", "authors": "Przemys{\\l}aw Spurek, Jacek Tabor, Przemys{\\l}aw Rola, Micha{\\l}\n  Ociepka", "title": "ICA based on the data asymmetry", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Independent Component Analysis (ICA) - one of the basic tools in data\nanalysis - aims to find a coordinate system in which the components of the data\nare independent. Most of existing methods are based on the minimization of the\nfunction of fourth-order moment (kurtosis). Skewness (third-order moment) has\nreceived much less attention.\n  In this paper we present a competitive approach to ICA based on the Split\nGaussian distribution, which is well adapted to asymmetric data. Consequently,\nwe obtain a method which works better than the classical approaches, especially\nin the case when the underlying density is not symmetric, which is a typical\nsituation in the color distribution in images.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jan 2017 18:08:14 GMT"}], "update_date": "2017-02-01", "authors_parsed": [["Spurek", "Przemys\u0142aw", ""], ["Tabor", "Jacek", ""], ["Rola", "Przemys\u0142aw", ""], ["Ociepka", "Micha\u0142", ""]]}]