[{"id": "1806.00040", "submitter": "Ilias Diakonikolas", "authors": "Ilias Diakonikolas, Weihao Kong, Alistair Stewart", "title": "Efficient Algorithms and Lower Bounds for Robust Linear Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC cs.DS math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of high-dimensional linear regression in a robust model\nwhere an $\\epsilon$-fraction of the samples can be adversarially corrupted. We\nfocus on the fundamental setting where the covariates of the uncorrupted\nsamples are drawn from a Gaussian distribution $\\mathcal{N}(0, \\Sigma)$ on\n$\\mathbb{R}^d$. We give nearly tight upper bounds and computational lower\nbounds for this problem. Specifically, our main contributions are as follows:\n  For the case that the covariance matrix is known to be the identity, we give\na sample near-optimal and computationally efficient algorithm that outputs a\ncandidate hypothesis vector $\\widehat{\\beta}$ which approximates the unknown\nregression vector $\\beta$ within $\\ell_2$-norm $O(\\epsilon \\log(1/\\epsilon)\n\\sigma)$, where $\\sigma$ is the standard deviation of the random observation\nnoise. An error of $\\Omega (\\epsilon \\sigma)$ is information-theoretically\nnecessary, even with infinite sample size. Prior work gave an algorithm for\nthis problem with sample complexity $\\tilde{\\Omega}(d^2/\\epsilon^2)$ whose\nerror guarantee scales with the $\\ell_2$-norm of $\\beta$.\n  For the case of unknown covariance, we show that we can efficiently achieve\nthe same error guarantee as in the known covariance case using an additional\n$\\tilde{O}(d^2/\\epsilon^2)$ unlabeled examples. On the other hand, an error of\n$O(\\epsilon \\sigma)$ can be information-theoretically attained with\n$O(d/\\epsilon^2)$ samples. We prove a Statistical Query (SQ) lower bound\nproviding evidence that this quadratic tradeoff in the sample size is inherent.\nMore specifically, we show that any polynomial time SQ learning algorithm for\nrobust linear regression (in Huber's contamination model) with estimation\ncomplexity $O(d^{2-c})$, where $c>0$ is an arbitrarily small constant, must\nincur an error of $\\Omega(\\sqrt{\\epsilon} \\sigma)$.\n", "versions": [{"version": "v1", "created": "Thu, 31 May 2018 18:23:29 GMT"}], "update_date": "2018-06-04", "authors_parsed": [["Diakonikolas", "Ilias", ""], ["Kong", "Weihao", ""], ["Stewart", "Alistair", ""]]}, {"id": "1806.00118", "submitter": "Yihong Wu", "authors": "Yihong Wu and Jiaming Xu", "title": "Statistical Problems with Planted Structures: Information-Theoretical\n  and Computational Limits", "comments": "Chapter in \"Information-Theoretic Methods in Data Science\". Edited by\n  Yonina Eldar and Miguel Rodrigues, Cambridge University Press, forthcoming", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT math.IT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past few years, insights from computer science, statistical physics,\nand information theory have revealed phase transitions in a wide array of\nhigh-dimensional statistical problems at two distinct thresholds: One is the\ninformation-theoretical (IT) threshold below which the observation is too noisy\nso that inference of the ground truth structure is impossible regardless of the\ncomputational cost; the other is the computational threshold above which\ninference can be performed efficiently, i.e., in time that is polynomial in the\ninput size. In the intermediate regime, inference is information-theoretically\npossible, but conjectured to be computationally hard.\n  This article provides a survey of the common techniques for determining the\nsharp IT and computational limits, using community detection and submatrix\ndetection as illustrating examples. For IT limits, we discuss tools including\nthe first and second moment method for analyzing the maximum likelihood\nestimator, information-theoretic methods for proving impossibility results\nusing mutual information and rate-distortion theory, and methods originated\nfrom statistical physics such as interpolation method. To investigate\ncomputational limits, we describe a common recipe to construct a randomized\npolynomial-time reduction scheme that approximately maps instances of the\nplanted clique problem to the problem of interest in total variation distance.\n", "versions": [{"version": "v1", "created": "Thu, 31 May 2018 22:07:52 GMT"}, {"version": "v2", "created": "Sun, 12 Aug 2018 23:12:45 GMT"}], "update_date": "2018-08-14", "authors_parsed": [["Wu", "Yihong", ""], ["Xu", "Jiaming", ""]]}, {"id": "1806.00320", "submitter": "Jan Draisma", "authors": "Jan Draisma", "title": "Partial correlation hypersurfaces in Gaussian graphical models", "comments": "9 pages, 5 figures, added Example 13, some minor further edits", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.AG math.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive a combinatorial sufficient condition for a partial correlation\nhypersurface in the parameter space of a directed Gaussian graphical model to\nbe nonsingular, and speculate on whether this condition can be used in\nalgorithms for learning the graph. Since the condition is fulfilled in the case\nof a complete DAG on any number of vertices, the result implies an affirmative\nanswer to a question raised by Lin-Uhler-Sturmfels-B\\\"uhlmann.\n", "versions": [{"version": "v1", "created": "Fri, 1 Jun 2018 12:48:32 GMT"}, {"version": "v2", "created": "Fri, 21 Sep 2018 18:58:18 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Draisma", "Jan", ""]]}, {"id": "1806.00381", "submitter": "Ilya Chevyrev", "authors": "Ilya Chevyrev, Vidit Nanda, Harald Oberhauser", "title": "Persistence paths and signature features in topological data analysis", "comments": "Additional experiment and further details. To appear in IEEE\n  Transactions on Pattern Analysis and Machine Intelligence", "journal-ref": "IEEE TPAMI (2020) Volume: 42, Issue: 1, pp. 192 - 202", "doi": "10.1109/TPAMI.2018.2885516", "report-no": null, "categories": "stat.ML cs.LG math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new feature map for barcodes that arise in persistent homology\ncomputation. The main idea is to first realize each barcode as a path in a\nconvenient vector space, and to then compute its path signature which takes\nvalues in the tensor algebra of that vector space. The composition of these two\noperations - barcode to path, path to tensor series - results in a feature map\nthat has several desirable properties for statistical learning, such as\nuniversality and characteristicness, and achieves state-of-the-art results on\ncommon classification benchmarks.\n", "versions": [{"version": "v1", "created": "Fri, 1 Jun 2018 14:54:25 GMT"}, {"version": "v2", "created": "Wed, 12 Dec 2018 12:24:04 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Chevyrev", "Ilya", ""], ["Nanda", "Vidit", ""], ["Oberhauser", "Harald", ""]]}, {"id": "1806.00385", "submitter": "Mohamed-Salem Ahmed", "authors": "Mohamed-Salem Ahmed, Mamadou N'diaye, Mohammed Kadi Attouch, Sophie\n  Dabo-Niang", "title": "k-nearest neighbors prediction and classification for spatial data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a nonparametric predictor and a supervised classification based on\nthe regression function estimate of a spatial real variable using k-nearest\nneighbors method (k-NN). Under some assumptions, we establish almost complete\nor sure convergence of the proposed estimates which incorporate a spatial\nproximity between observations. Numerical results on simulated and real fish\ndata illustrate the behavior of the given predictor and classification method.\n", "versions": [{"version": "v1", "created": "Fri, 1 Jun 2018 15:07:08 GMT"}], "update_date": "2018-06-04", "authors_parsed": [["Ahmed", "Mohamed-Salem", ""], ["N'diaye", "Mamadou", ""], ["Attouch", "Mohammed Kadi", ""], ["Dabo-Niang", "Sophie", ""]]}, {"id": "1806.00519", "submitter": "Christian Clason", "authors": "Christian Clason, Tapio Helin, Remo Kretschmann, Petteri Piiroinen", "title": "Generalized modes in Bayesian inverse problems", "comments": null, "journal-ref": "SIAM/ASA J. Uncertainty Quantification 7 (2019), 652-684", "doi": "10.1137/18M1191804", "report-no": null, "categories": "math.ST math.OC stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uncertainty quantification requires efficient summarization of high- or even\ninfinite-dimensional (i.e., non-parametric) distributions based on, e.g.,\nsuitable point estimates (modes) for posterior distributions arising from\nmodel-specific prior distributions. In this work, we consider non-parametric\nmodes and MAP estimates for priors that do not admit continuous densities, for\nwhich previous approaches based on small ball probabilities fail. We propose a\nnovel definition of generalized modes based on the concept of approximating\nsequences, which reduce to the classical mode in certain situations that\ninclude Gaussian priors but also exist for a more general class of priors. The\nlatter includes the case of priors that impose strict bounds on the admissible\nparameters and in particular of uniform priors. For uniform priors defined by\nrandom series with uniformly distributed coefficients, we show that generalized\nMAP estimates -- but not classical MAP estimates -- can be characterized as\nminimizers of a suitable functional that plays the role of a generalized\nOnsager--Machlup functional. This is then used to show consistency of nonlinear\nBayesian inverse problems with uniform priors and Gaussian noise.\n", "versions": [{"version": "v1", "created": "Fri, 1 Jun 2018 19:36:53 GMT"}, {"version": "v2", "created": "Mon, 14 Jan 2019 11:51:22 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Clason", "Christian", ""], ["Helin", "Tapio", ""], ["Kretschmann", "Remo", ""], ["Piiroinen", "Petteri", ""]]}, {"id": "1806.00558", "submitter": "Rida Benhaddou", "authors": "Rida Benhaddou", "title": "Minimax adaptive wavelet estimator for the simultaneous blind\n  deconvolution with fractional Gaussian noise", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We construct an adaptive wavelet estimator that attains minimax near-optimal\nrates in a wide range of Besov balls. The convergence rates are affected only\nby the weakest dependence amongst the channels, and take into account both\nnoise sources.\n", "versions": [{"version": "v1", "created": "Fri, 1 Jun 2018 22:57:43 GMT"}, {"version": "v2", "created": "Tue, 19 Jun 2018 02:04:02 GMT"}], "update_date": "2018-06-20", "authors_parsed": [["Benhaddou", "Rida", ""]]}, {"id": "1806.00584", "submitter": "Felix Leopoldo Rios", "authors": "Jimmy Olsson, Tetyana Pavlenko and Felix L. Rios", "title": "Sequential sampling of junction trees for decomposable graphs", "comments": "27 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.DM math.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The junction-tree representation provides an attractive structural property\nfor organizing a decomposable graph. In this study, we present two novel\nstochastic algorithms, which we call the junction-tree expander and\njunction-tree collapser for sequential sampling of junction trees for\ndecomposable graphs. We show that recursive application of the junction-tree\nexpander, expanding incrementally the underlying graph with one vertex at a\ntime, has full support on the space of junction trees with any given number of\nunderlying vertices. On the other hand, the junction-tree collapser provides a\ncomplementary operation for removing vertices in the underlying decomposable\ngraph of a junction tree, while maintaining the junction tree property. A\ndirect application of our suggested algorithms is demonstrated in a\nsequential-Monte-Carlo setting designed for sampling from distributions on\nspaces of decomposable graphs. Numerical studies illustrate the utility of the\nproposed algorithms for combinatorial computations on decomposable graphs and\njunction trees. All the methods proposed in the paper are implemented in the\nPython library trilearn.\n", "versions": [{"version": "v1", "created": "Sat, 2 Jun 2018 05:43:03 GMT"}, {"version": "v2", "created": "Fri, 29 Nov 2019 15:56:38 GMT"}, {"version": "v3", "created": "Tue, 14 Jan 2020 18:19:09 GMT"}, {"version": "v4", "created": "Mon, 15 Feb 2021 08:14:43 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Olsson", "Jimmy", ""], ["Pavlenko", "Tetyana", ""], ["Rios", "Felix L.", ""]]}, {"id": "1806.00989", "submitter": "Fran\\c{c}ois Portier", "authors": "Bernard Delyon and Fran\\c{c}ois Portier", "title": "Asymptotic optimality of adaptive importance sampling", "comments": "19 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.CO stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adaptive importance sampling (AIS) uses past samples to update the\n\\textit{sampling policy} $q_t$ at each stage $t$. Each stage $t$ is formed with\ntwo steps : (i) to explore the space with $n_t$ points according to $q_t$ and\n(ii) to exploit the current amount of information to update the sampling\npolicy. The very fundamental question raised in this paper concerns the\nbehavior of empirical sums based on AIS. Without making any assumption on the\nallocation policy $n_t$, the theory developed involves no restriction on the\nsplit of computational resources between the explore (i) and the exploit (ii)\nstep. It is shown that AIS is asymptotically optimal : the asymptotic behavior\nof AIS is the same as some \"oracle\" strategy that knows the targeted sampling\npolicy from the beginning. From a practical perspective, weighted AIS is\nintroduced, a new method that allows to forget poor samples from early stages.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jun 2018 07:20:07 GMT"}, {"version": "v2", "created": "Wed, 3 Oct 2018 08:02:54 GMT"}], "update_date": "2018-10-04", "authors_parsed": [["Delyon", "Bernard", ""], ["Portier", "Fran\u00e7ois", ""]]}, {"id": "1806.01009", "submitter": "Francesco Ortelli", "authors": "Francesco Ortelli, Sara van de Geer", "title": "On the total variation regularized estimator over a class of tree graphs", "comments": "42 pages", "journal-ref": "Electronic Journal of Statistics, 12, 2018, 4517-4570", "doi": "10.1214/18-EJS1519", "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We generalize to tree graphs obtained by connecting path graphs an oracle\nresult obtained for the Fused Lasso over the path graph. Moreover we show that\nit is possible to substitute in the oracle inequality the minimum of the\ndistances between jumps by their harmonic mean. In doing so we prove a lower\nbound on the compatibility constant for the total variation penalty. Our\nanalysis leverages insights obtained for the path graph with one branch to\nunderstand the case of more general tree graphs.\n  As a side result, we get insights into the irrepresentable condition for such\ntree graphs.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jun 2018 08:41:49 GMT"}, {"version": "v2", "created": "Mon, 11 Jun 2018 14:30:27 GMT"}, {"version": "v3", "created": "Sat, 16 Jun 2018 16:14:05 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Ortelli", "Francesco", ""], ["van de Geer", "Sara", ""]]}, {"id": "1806.01082", "submitter": "Fran\\c{c}ois Portier", "authors": "Fran\\c{c}ois Portier, Ingrid Van Keilegom and Anouar El Ghouch", "title": "On an extension of the promotion time cure model", "comments": "41 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of estimating the distribution of time-to-event data\nthat are subject to censoring and for which the event of interest might never\noccur, i.e., some subjects are cured. To model this kind of data in the\npresence of covariates, one of the leading semiparametric models is the\npromotion time cure model \\citep{yakovlev1996}, which adapts the Cox model to\nthe presence of cured subjects. Estimating the conditional distribution results\nin a complicated constrained optimization problem, and inference is difficult\nas no closed-formula for the variance is available. We propose a new model,\ninspired by the Cox model, that leads to a simple estimation procedure and that\npresents a closed formula for the variance. We derive some asymptotic\nproperties of the estimators and we show the practical behaviour of our\nprocedure by means of simulations. We also apply our model and estimation\nmethod to a breast cancer data set.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jun 2018 12:51:03 GMT"}], "update_date": "2018-06-05", "authors_parsed": [["Portier", "Fran\u00e7ois", ""], ["Van Keilegom", "Ingrid", ""], ["Ghouch", "Anouar El", ""]]}, {"id": "1806.01229", "submitter": "Yubo Tao", "authors": "Yubo Tao", "title": "Limit Theory for Moderate Deviation from Integrated GARCH Processes", "comments": "13 pages", "journal-ref": "Statistics & Probability Letters Volume 150, July 2019, Pages\n  126-136", "doi": "10.1016/j.spl.2019.03.001", "report-no": null, "categories": "math.ST econ.EM stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper develops the limit theory of the GARCH(1,1) process that\nmoderately deviates from IGARCH process towards both stationary and explosive\nregimes. The GARCH(1,1) process is defined by equations $u_t = \\sigma_t\n\\varepsilon_t$, $\\sigma_t^2 = \\omega + \\alpha_n u_{t-1}^2 +\n\\beta_n\\sigma_{t-1}^2$ and $\\alpha_n + \\beta_n$ approaches to unity as sample\nsize goes to infinity. The asymptotic theory developed in this paper extends\nBerkes et al. (2005) by allowing the parameters to have a slower convergence\nrate. The results can be applied to unit root test for processes with\nmildly-integrated GARCH innovations (e.g. Boswijk (2001), Cavaliere and Taylor\n(2007, 2009)) and deriving limit theory of estimators for models involving\nmildly-integrated GARCH processes (e.g. Jensen and Rahbek (2004), Francq and\nZako\\\"ian (2012, 2013)).\n", "versions": [{"version": "v1", "created": "Mon, 4 Jun 2018 17:16:56 GMT"}, {"version": "v2", "created": "Tue, 5 Jun 2018 18:38:40 GMT"}, {"version": "v3", "created": "Thu, 20 Dec 2018 13:48:07 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Tao", "Yubo", ""]]}, {"id": "1806.01431", "submitter": "Kyungchul Song", "authors": "Kyungchul Song", "title": "A Uniform-in-$P$ Edgeworth Expansion under Weak Cram\\'{e}r Conditions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides a finite sample bound for the error term in the Edgeworth\nexpansion for a sum of independent, potentially discrete, nonlattice random\nvectors, using a uniform-in-$P$ version of the weaker Cram\\'{e}r condition in\nAngst and Poly (2017). This finite sample bound can be used to derive an\nEdgeworth expansion that is uniform over the distributions of the random\nvectors. Using this result, we derive a uniform-in-$P$ higher order expansion\nof resampling-based distributions.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jun 2018 23:32:17 GMT"}, {"version": "v2", "created": "Tue, 13 Aug 2019 00:49:53 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Song", "Kyungchul", ""]]}, {"id": "1806.01458", "submitter": "Jacob Parsons", "authors": "Jacob Parsons and Le Bao", "title": "The Value of Information in Retrospect", "comments": "23 pages, 3 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the course of any statistical analysis, it is necessary to consider issues\nof data quality and model appropriateness. Value of information methods were\ninitially put forward in the middle of the twentieth century in order to\nprovide a framework for choosing between potential sources of information.\nHowever, since their genesis, value of information methods have been largely\nneglected by statisticians. In this paper we review and extend existing value\nof information methods and recommend the use of three quantities for\nidentifying influential and outlying data: an influence measure previously\nsuggested by \\cite{kempthorne1986}, a related quantity known as the expected\nvalue of sample information that is used to gauge how much influence we would\nexpect a portion of the data to have, and the ratio of these two quantities\nwhich serves as a comparison between observed influence and expected influence.\n  We study the basic theoretical properties of those quantities and illustrate\nour proposed approach using two datasets. A data set containing employment\nrates and other economic factors in U.S. first presented by \\cite{longley} is\nused to provide an example in the case of linear regression. HIV surveillance\ndata collected from prenatal clinics have been the main source of information\nfor monitoring the HIV epidemic in low and middle income countries. A data set\nproviding information about HIV prevalence in Swaziland is used as an example\nin the case of generalized linear mixed models.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jun 2018 01:37:10 GMT"}, {"version": "v2", "created": "Sat, 20 Oct 2018 17:16:54 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Parsons", "Jacob", ""], ["Bao", "Le", ""]]}, {"id": "1806.01558", "submitter": "Thomas Romary", "authors": "Thomas Romary (GEOSCIENCES), Nicolas Desassis", "title": "Combining covariance tapering and lasso driven low rank decomposition\n  for the kriging of large spatial datasets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large spatial datasets are becoming ubiquitous in environmental sciences with\nthe explosion in the amount of data produced by sensors that monitor and\nmeasure the Earth system. Consequently, the geostatistical analysis of these\ndata requires adequate methods. Richer datasets lead to more complex modeling\nbut may also prevent from using classical techniques. Indeed, the kriging\npredictor is not straightforwarldly available as it requires the inversion of\nthe covariance matrix of the data. The challenge of handling such datasets is\ntherefore to extract the maximum of information they contain while ensuring the\nnumerical tractability of the associated inference and prediction algorithms.\nThe different approaches that have been developed in the literature to address\nthis problem can be classified into two families, both aiming at making the\ninversion of the covariance matrix computationally feasible. The covariance\ntapering approach circumvents the problem by enforcing the sparsity of the\ncovariance matrix, making it invertible in a reasonable computation time. The\nsecond available approach assumes a low rank representation of the covariance\nfunction. While both approaches have their drawbacks, we propose a way to\ncombine them and benefit from their advantages. The covariance model is assumed\nto have the form low rank plus sparse. The choice of the basis functions\nsustaining the low rank component is data driven and is achieved through a\nselection procedure, thus alleviating the computational burden of the low rank\npart. This model expresses as a spatial random effects model and the estimation\nof the parameters is conducted through a step by step approach treating each\nscale separately. The resulting model can account for second order non\nstationarity and handle large volumes of data.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jun 2018 08:44:44 GMT"}], "update_date": "2018-06-06", "authors_parsed": [["Romary", "Thomas", "", "GEOSCIENCES"], ["Desassis", "Nicolas", ""]]}, {"id": "1806.01888", "submitter": "Denis Chetverikov", "authors": "Alexandre Belloni, Victor Chernozhukov, Denis Chetverikov, Christian\n  Hansen, and Kengo Kato", "title": "High-Dimensional Econometrics and Regularized GMM", "comments": "104 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST econ.EM stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This chapter presents key concepts and theoretical results for analyzing\nestimation and inference in high-dimensional models. High-dimensional models\nare characterized by having a number of unknown parameters that is not\nvanishingly small relative to the sample size. We first present results in a\nframework where estimators of parameters of interest may be represented\ndirectly as approximate means. Within this context, we review fundamental\nresults including high-dimensional central limit theorems, bootstrap\napproximation of high-dimensional limit distributions, and moderate deviation\ntheory. We also review key concepts underlying inference when many parameters\nare of interest such as multiple testing with family-wise error rate or false\ndiscovery rate control. We then turn to a general high-dimensional minimum\ndistance framework with a special focus on generalized method of moments\nproblems where we present results for estimation and inference about model\nparameters. The presented results cover a wide array of econometric\napplications, and we discuss several leading special cases including\nhigh-dimensional linear regression and linear instrumental variables models to\nillustrate the general results.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jun 2018 18:46:12 GMT"}, {"version": "v2", "created": "Sun, 10 Jun 2018 15:21:13 GMT"}], "update_date": "2018-06-12", "authors_parsed": [["Belloni", "Alexandre", ""], ["Chernozhukov", "Victor", ""], ["Chetverikov", "Denis", ""], ["Hansen", "Christian", ""], ["Kato", "Kengo", ""]]}, {"id": "1806.01928", "submitter": "Ted Westling", "authors": "Ted Westling and Marco Carone", "title": "A unified study of nonparametric inference for monotone functions", "comments": "Substantial revisions made to the manuscript", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of nonparametric inference on a monotone function has been\nextensively studied in many particular cases. Estimators considered have often\nbeen of so-called Grenander type, being representable as the left derivative of\nthe greatest convex minorant or least concave majorant of an estimator of a\nprimitive function. In this paper, we provide general conditions for\nconsistency and pointwise convergence in distribution of a class of generalized\nGrenander-type estimators of a monotone function. This broad class allows the\nminorization or majoratization operation to be performed on a data-dependent\ntransformation of the domain, possibly yielding benefits in practice.\nAdditionally, we provide simpler conditions and more concrete distributional\ntheory in the important case that the primitive estimator and data-dependent\ntransformation function are asymptotically linear. We use our general results\nin the context of various well-studied problems, and show that we readily\nrecover classical results established separately in each case. More\nimportantly, we show that our results allow us to tackle more challenging\nproblems involving parameters for which the use of flexible learning strategies\nappears necessary. In particular, we study inference on monotone density and\nhazard functions using informatively right-censored data, extending the\nclassical work on independent censoring, and on a covariate-marginalized\nconditional mean function, extending the classical work on monotone regression\nfunctions. In addition to a theoretical study, we present numerical evidence\nsupporting our large-sample results.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jun 2018 20:27:41 GMT"}, {"version": "v2", "created": "Sat, 9 Jun 2018 16:32:36 GMT"}, {"version": "v3", "created": "Thu, 29 Nov 2018 20:21:49 GMT"}], "update_date": "2018-12-03", "authors_parsed": [["Westling", "Ted", ""], ["Carone", "Marco", ""]]}, {"id": "1806.01956", "submitter": "Thuong Nguyen", "authors": "Thuong Nguyen", "title": "Distribution free goodness of fit tests for regularly varying tail\n  distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss in this paper a possibility of constructing a whole class of\nasymptotic distribution-free tests for testing regularly varying tail\ndistributions. The idea is that we treat the tails of distributions as members\nof a parametric family and using MLE to estimate the exponent. No matter what\nthe exponent's estimator is, we are able to transform the whole class into a\nspecific distribution with a prefix exponent so that we are free from choosing\nany functional of the tail empirical process as a distribution-free test\nstatistic. The asymptotic behavior of some new tests, as examples from the\nwhole class of new tests, are demonstrated as well.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jun 2018 22:53:21 GMT"}], "update_date": "2018-06-07", "authors_parsed": [["Nguyen", "Thuong", ""]]}, {"id": "1806.02020", "submitter": "Teresa Ledwina", "authors": "Inglot Tadeusz, Ledwina Teresa, \\'Cmiel Bogdan", "title": "Intermediate efficiency in nonparametric testing problems with an\n  application to some weighted statistics", "comments": "41 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The basic motivation and primary goal of this paper is a qualitative\nevaluation of the performance of a new weighted statistic for a nonparametric\ntest for stochastic dominance based on two samples, which was introduced in\nLedwina and Wy{\\l}upek (2012). For this purpose, we elaborate a useful variant\nof Kallenberg's notion of intermediate efficiency. This variant is general\nenough to be applicable to other nonparametric problems. We provide a formal\ndefnition of the proposed variant of intermediate efficiency, describe the\ntechnical tools used in its calculation, and provide proofs of related\nasymptotic results. Next, we apply this approach to calculating the\nintermediate efficiency of the new test with respect to the classical one-sided\nKolmogorov-Smirnov test, which is a recognized standard for this problem. It\nturns out that for a very large class of convergent alternatives the new test\nis more efficient than the classical one. We also report the results of an\nextensive simulation study on the powers of the tests considered, which shows\nthat the new variant of intermediate efficiency reflects the exact behavior of\nthe power well.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jun 2018 06:12:35 GMT"}], "update_date": "2018-06-07", "authors_parsed": [["Tadeusz", "Inglot", ""], ["Teresa", "Ledwina", ""], ["Bogdan", "\u0106miel", ""]]}, {"id": "1806.02107", "submitter": "Fran\\c{c}ois Portier", "authors": "Patrice Bertail and Fran\\c{c}ois Portier", "title": "Rademacher complexity for Markov chains : Applications to kernel\n  smoothing and Metropolis-Hasting", "comments": "22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Following the seminal approach by Talagrand, the concept of Rademacher\ncomplexity for independent sequences of random variables is extended to Markov\nchains. The proposed notion of \"block Rademacher complexity\" (of a class of\nfunctions) follows from renewal theory and allows to control the expected\nvalues of suprema (over the class of functions) of empirical processes based on\nHarris Markov chains as well as the excess probability. For classes of\nVapnik-Chervonenkis type, bounds on the \"block Rademacher complexity\" are\nestablished. These bounds depend essentially on the sample size and the\nprobability tails of the regeneration times. The proposed approach is employed\nto obtain convergence rates for the kernel density estimator of the stationary\nmeasure and to derive concentration inequalities for the Metropolis-Hasting\nalgorithm.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jun 2018 10:40:18 GMT"}, {"version": "v2", "created": "Fri, 6 Jul 2018 07:11:49 GMT"}], "update_date": "2018-07-09", "authors_parsed": [["Bertail", "Patrice", ""], ["Portier", "Fran\u00e7ois", ""]]}, {"id": "1806.02194", "submitter": "Pratyay Datta", "authors": "Pratyay Datta, Bodhisattva Sen (Columbia University)", "title": "Optimal Inference with a Multidimensional Multiscale Statistic", "comments": "39 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We observe a stochastic process $Y$ on $[0,1]^d$ ($d\\geq 1$) satisfying\n$dY(t)=n^{1/2}f(t)dt$ + $dW(t)$, $t \\in [0,1]^d$, where $n \\geq 1$ is a given\nscale parameter (`sample size'), $W$ is the standard Brownian sheet on\n$[0,1]^d$ and $f \\in L_1([0,1]^d)$ is the unknown function of interest. We\npropose a multivariate multiscale statistic in this setting and prove its\nalmost sure finiteness; this extends the work of D\\\"umbgen and Spokoiny (2001)\nwho proposed the analogous statistic for $d=1$. We use the proposed multiscale\nstatistic to construct optimal tests for testing $f=0$ versus (i) appropriate\nH\\\"{o}lder classes of functions, and (ii) alternatives of the form $f=\\mu_n\n\\mathbb{I}_{B_n}$, where $B_n$ is an axis-aligned hyperrectangle in $[0,1]^d$\nand $\\mu_n \\in \\mathbb{R}$; $\\mu_n$ and $B_n$ unknown. In the process we\ngeneralize Theorem 6.1 of D\\\"umbgen and Spokoiny (2001) about stochastic\nprocesses with sub-Gaussian increments on a pseudometric space, which is of\nindependent interest.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jun 2018 14:08:32 GMT"}], "update_date": "2018-06-07", "authors_parsed": [["Datta", "Pratyay", "", "Columbia University"], ["Sen", "Bodhisattva", "", "Columbia University"]]}, {"id": "1806.02314", "submitter": "Giorgos Afendras", "authors": "Georgios Afendras, Nickos Papadatos, Violetta Piperigou", "title": "On the limiting distribution of sample central moments", "comments": "26 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the limiting behavior of sample central moments, examining the\nspecial cases where the limiting (as the sample size tends to infinity)\ndistribution is degenerate. Parent (non-degenerate) distributions with this\nproperty are called \\emph{singular}, and we show in this article that the\nsingular distributions contain at most three supporting points. Moreover, using\nthe \\emph{delta}-method, we show that the (second order) limiting distribution\nof sample central moments from a singular distribution is either a multiple, or\na difference of two multiples of independent chi-square random variables with\none degree of freedom. Finally, we present a new characterization of normality\nthrough the asymptotic independence of the sample mean and all sample central\nmoments.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jun 2018 17:27:39 GMT"}], "update_date": "2018-06-07", "authors_parsed": [["Afendras", "Georgios", ""], ["Papadatos", "Nickos", ""], ["Piperigou", "Violetta", ""]]}, {"id": "1806.02485", "submitter": "Mason A. Porter", "authors": "Zachary M. Boyd, Mason A. Porter, and Andrea L. Bertozzi", "title": "Stochastic Block Models are a Discrete Surface Tension", "comments": "to appear in Journal of Nonlinear Science", "journal-ref": null, "doi": "10.1007/s00332-019-09541-8", "report-no": null, "categories": "cs.SI cond-mat.stat-mech math.ST nlin.AO stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Networks, which represent agents and interactions between them, arise in\nmyriad applications throughout the sciences, engineering, and even the\nhumanities. To understand large-scale structure in a network, a common task is\nto cluster a network's nodes into sets called \"communities\", such that there\nare dense connections within communities but sparse connections between them. A\npopular and statistically principled method to perform such clustering is to\nuse a family of generative models known as stochastic block models (SBMs). In\nthis paper, we show that maximum likelihood estimation in an SBM is a network\nanalog of a well-known continuum surface-tension problem that arises from an\napplication in metallurgy. To illustrate the utility of this relationship, we\nimplement network analogs of three surface-tension algorithms, with which we\nsuccessfully recover planted community structure in synthetic networks and\nwhich yield fascinating insights on empirical networks that we construct from\nhyperspectral videos.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jun 2018 01:56:03 GMT"}, {"version": "v2", "created": "Mon, 25 Mar 2019 03:19:29 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Boyd", "Zachary M.", ""], ["Porter", "Mason A.", ""], ["Bertozzi", "Andrea L.", ""]]}, {"id": "1806.02594", "submitter": "Eric Marchand", "authors": "\\'Eric Marchand and Theodoros Nicoleris", "title": "Inference for a constrained parameter in presence of an uncertain\n  constraint", "comments": "10 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a hierarchical Bayesian approach for inference about a parameter\n$\\theta$ lower-bounded by $\\alpha$ with uncertain $\\alpha$, derive some basic\nidentities for posterior analysis about $(\\theta,\\alpha)$, and provide\nillustrations for normal and Poisson models. For the normal case with unknown\nmean $\\theta$ and known variance $\\sigma^2$, we obtain Bayes estimators of\n$\\theta$ that take values on $\\mathbb{R}$, but that are equally adapted to a\nlower-bound constraint in being minimax under squared error loss for the\nconstrained problem.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jun 2018 10:04:11 GMT"}], "update_date": "2018-06-08", "authors_parsed": [["Marchand", "\u00c9ric", ""], ["Nicoleris", "Theodoros", ""]]}, {"id": "1806.02600", "submitter": "Eric Marchand", "authors": "Aziz L'Moudden and \\'Eric Marchand", "title": "On Predictive Density Estimation under $\\alpha$-divergence Loss", "comments": "19 pages, 5 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Based on $X \\sim N_d(\\theta, \\sigma^2_X I_d)$, we study the efficiency of\npredictive densities under $\\alpha-$divergence loss $L_{\\alpha}$ for estimating\nthe density of $Y \\sim N_d(\\theta, \\sigma^2_Y I_d)$. We identify a large number\nof cases where improvement on a plug-in density are obtainable by expanding the\nvariance, thus extending earlier findings applicable to Kullback-Leibler loss.\nThe results and proofs are unified with respect to the dimension $d$, the\nvariances $\\sigma^2_X$ and $\\sigma^2_Y$, the choice of loss $L_{\\alpha}$;\n$\\alpha \\in (-1,1)$. The findings also apply to a large number of plug-in\ndensities, as well as for restricted parameter spaces with $\\theta \\in \\Theta\n\\subset \\mathbb{R}^d$. The theoretical findings are accompanied by various\nobservations, illustrations, and implications dealing for instance with\nrobustness with respect to the model variances and simultaneous dominance with\nrespect to the loss.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jun 2018 10:18:33 GMT"}], "update_date": "2018-06-08", "authors_parsed": [["L'Moudden", "Aziz", ""], ["Marchand", "\u00c9ric", ""]]}, {"id": "1806.02740", "submitter": "Thibaut Le Gouic", "authors": "Adil Ahidar-Coutrix, Thibaut Le Gouic, Quentin Paris", "title": "Convergence rates for empirical barycenters in metric spaces: curvature,\n  convexity and extendible geodesics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.MG math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides rates of convergence for empirical (generalised)\nbarycenters on compact geodesic metric spaces under general conditions using\nempirical processes techniques. Our main assumption is termed a variance\ninequality and provides a strong connection between usual assumptions in the\nfield of empirical processes and central concepts of metric geometry. We study\nthe validity of variance inequalities in spaces of non-positive and\nnon-negative Aleksandrov curvature. In this last scenario, we show that\nvariance inequalities hold provided geodesics, emanating from a barycenter, can\nbe extended by a constant factor. We also relate variance inequalities to\nstrong geodesic convexity. While not restricted to this setting, our results\nare largely discussed in the context of the $2$-Wasserstein space.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jun 2018 15:56:20 GMT"}, {"version": "v2", "created": "Mon, 23 Jul 2018 15:44:57 GMT"}, {"version": "v3", "created": "Fri, 31 May 2019 14:42:05 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Ahidar-Coutrix", "Adil", ""], ["Gouic", "Thibaut Le", ""], ["Paris", "Quentin", ""]]}, {"id": "1806.03135", "submitter": "Agnes Lagnoux", "authors": "Jean-Marc Aza\\\"is (IMT), Fran\\c{c}ois Bachoc (IMT), Agn\\`es Lagnoux\n  (IMT), Thi Mong Ngoc Nguyen (VNU-HCM)", "title": "Semi-parametric estimation of the variogram of a Gaussian process with\n  stationary increments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the semi-parametric estimation of a scale parameter of a\none-dimensional Gaussian process with known smoothness. We suggest an estimator\nbased on quadratic variations and on the moment method. We provide asymptotic\napproximations of the mean and variance of this estimator, together with\nasymptotic normality results, for a large class of Gaussian processes. We allow\nfor general mean functions and study the aggregation of several estimators\nbased on various variation sequences. In extensive simulation studies, we show\nthat the asymptotic results accurately depict thefinite-sample situations\nalready for small to moderate sample sizes. We also compare various variation\nsequences and highlight the efficiency of the aggregation procedure.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jun 2018 13:12:13 GMT"}, {"version": "v2", "created": "Mon, 20 Jan 2020 15:40:22 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Aza\u00efs", "Jean-Marc", "", "IMT"], ["Bachoc", "Fran\u00e7ois", "", "IMT"], ["Lagnoux", "Agn\u00e8s", "", "IMT"], ["Nguyen", "Thi Mong Ngoc", "", "VNU-HCM"]]}, {"id": "1806.03195", "submitter": "Jean Michel Loubes", "authors": "Eustasio del Barrio and Fabrice Gamboa and Paula Gordaliza and\n  Jean-Michel Loubes", "title": "Obtaining fairness using optimal transport theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical algorithms are usually helping in making decisions in many\naspects of our lives. But, how do we know if these algorithms are biased and\ncommit unfair discrimination of a particular group of people, typically a\nminority? \\textit{Fairness} is generally studied in a probabilistic framework\nwhere it is assumed that there exists a protected variable, whose use as an\ninput of the algorithm may imply discrimination. There are different\ndefinitions of Fairness in the literature. In this paper we focus on two of\nthem which are called Disparate Impact (DI) and Balanced Error Rate (BER). Both\nare based on the outcome of the algorithm across the different groups\ndetermined by the protected variable. The relationship between these two\nnotions is also studied. The goals of this paper are to detect when a binary\nclassification rule lacks fairness and to try to fight against the potential\ndiscrimination attributable to it. This can be done by modifying either the\nclassifiers or the data itself. Our work falls into the second category and\nmodifies the input data using optimal transport theory.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jun 2018 14:42:29 GMT"}, {"version": "v2", "created": "Wed, 18 Jul 2018 07:09:46 GMT"}], "update_date": "2018-07-19", "authors_parsed": [["del Barrio", "Eustasio", ""], ["Gamboa", "Fabrice", ""], ["Gordaliza", "Paula", ""], ["Loubes", "Jean-Michel", ""]]}, {"id": "1806.03227", "submitter": "Enric Boix", "authors": "Emmanuel Abbe, Enric Boix", "title": "An Information-Percolation Bound for Spin Synchronization on General\n  Graphs", "comments": "The results of this paper are from Enric Boix's undergraduate senior\n  thesis, advised by Emmanuel Abbe. The results were presented at the Workshop\n  on Combinatorial Statistics, Montreal, May 2018", "journal-ref": null, "doi": "10.1214/19-AAP1523", "report-no": null, "categories": "math.PR cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the problem of reconstructing $n$ independent uniform\nspins $X_1,\\dots,X_n$ living on the vertices of an $n$-vertex graph $G$, by\nobserving their interactions on the edges of the graph. This captures instances\nof models such as (i) broadcasting on trees, (ii) block models, (iii)\nsynchronization on grids, (iv) spiked Wigner models. The paper gives an\nupper-bound on the mutual information between two vertices in terms of a bond\npercolation estimate. Namely, the information between two vertices' spins is\nbounded by the probability that these vertices are connected in a bond\npercolation model, where edges are opened with a probability that \"emulates\"\nthe edge-information. Both the information and the open-probability are based\non the Chi-squared mutual information. The main results allow us to re-derive\nknown results for information-theoretic non-reconstruction in models (i)-(iv),\nwith more direct or improved bounds in some cases, and to obtain new results,\nsuch as for a spiked Wigner model on grids. The main result also implies a new\nsubadditivity property for the Chi-squared mutual information for symmetric\nchannels and general graphs, extending the subadditivity property obtained by\nEvans-Kenyon-Peres-Schulman [EKPS00] for trees.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jun 2018 15:48:22 GMT"}, {"version": "v2", "created": "Mon, 11 Jun 2018 21:48:26 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Abbe", "Emmanuel", ""], ["Boix", "Enric", ""]]}, {"id": "1806.03440", "submitter": "Nicolas Bousquet", "authors": "Nicolas Bousquet and M\\'elanie Blaz\\`ere and Thomas Cerbelaud", "title": "Prior constraints of well-posedness in stochastic inversion problems of\n  computer models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic inversion problems are typically encountered when it is wanted to\nquantify the uncertainty affecting the inputs of computer models. They consist\nin estimating input distributions from noisy, observable outputs, and such\nproblems are increasingly examined in Bayesian contexts where the targeted\ninputs are affected by a mixture of aleatory and epistemic uncertainties. While\nthey are characterized by identifiability conditions, well-posedness\nconstraints of \"signal to noise\" have to be took into account within the\ndefinition of the model, prior to inference. In addition to numeric\nconditioning notions and regularization techniques used in inverse problems,\nthis article proposes and investigates a novel interpretation of\nwell-posedness, in the context of parametric uncertainty quantification and\nglobal sensitivity analysis, based on the degradation of Fisher information. It\noffers an explicitation of such prior constraints considering linear or\nlinearizable operators, this linearization being either local (based on\ndifferentiability) or variational. Simulated experiments indicate that, when\ninjected into the modeling process, these constraints can limit the influence\nof measurement or process noise on the estimation of the input distribution,\nand let hope for future extensions in a full non-linear framework, for example\nthrough the use of linear Gaussian mixtures.\n", "versions": [{"version": "v1", "created": "Sat, 9 Jun 2018 08:40:17 GMT"}, {"version": "v2", "created": "Sun, 28 Jun 2020 15:40:23 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Bousquet", "Nicolas", ""], ["Blaz\u00e8re", "M\u00e9lanie", ""], ["Cerbelaud", "Thomas", ""]]}, {"id": "1806.03467", "submitter": "Zhiwei Steven Wu", "authors": "Miruna Oprescu, Vasilis Syrgkanis, Zhiwei Steven Wu", "title": "Orthogonal Random Forest for Causal Inference", "comments": "This paper appeared in the Proceedings of the 36th International\n  Conference on Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG econ.EM math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the orthogonal random forest, an algorithm that combines\nNeyman-orthogonality to reduce sensitivity with respect to estimation error of\nnuisance parameters with generalized random forests (Athey et al., 2017)--a\nflexible non-parametric method for statistical estimation of conditional moment\nmodels using random forests. We provide a consistency rate and establish\nasymptotic normality for our estimator. We show that under mild assumptions on\nthe consistency rate of the nuisance estimator, we can achieve the same error\nrate as an oracle with a priori knowledge of these nuisance parameters. We show\nthat when the nuisance functions have a locally sparse parametrization, then a\nlocal $\\ell_1$-penalized regression achieves the required rate. We apply our\nmethod to estimate heterogeneous treatment effects from observational data with\ndiscrete treatments or continuous treatments, and we show that, unlike prior\nwork, our method provably allows to control for a high-dimensional set of\nvariables under standard sparsity conditions. We also provide a comprehensive\nempirical evaluation of our algorithm on both synthetic and real data.\n", "versions": [{"version": "v1", "created": "Sat, 9 Jun 2018 12:14:25 GMT"}, {"version": "v2", "created": "Thu, 12 Jul 2018 13:43:43 GMT"}, {"version": "v3", "created": "Thu, 21 Feb 2019 05:06:04 GMT"}, {"version": "v4", "created": "Wed, 25 Sep 2019 20:03:10 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Oprescu", "Miruna", ""], ["Syrgkanis", "Vasilis", ""], ["Wu", "Zhiwei Steven", ""]]}, {"id": "1806.03665", "submitter": "De Wen Soh", "authors": "De Wen Soh, Sekhar Tatikonda", "title": "Identifiability in Gaussian Graphical Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In high-dimensional graph learning problems, some topological properties of\nthe graph, such as bounded node degree or tree structure, are typically assumed\nto hold so that the sample complexity of recovering the graph structure can be\nreduced. With bounded degree or separability assumptions, quantified by a\nmeasure $k$, a $p$-dimensional Gaussian graphical model (GGM) can be learnt\nwith sample complexity $\\Omega (k \\: \\text{log} \\: p)$. Our work in this paper\naims to do away with these assumptions by introducing an algorithm that can\nidentify whether a GGM indeed has these topological properties without any\ninitial topological assumptions. We show that we can check whether a GGM has\nnode degree bounded by $k$ with sample complexity $\\Omega (k \\: \\text{log} \\:\np)$. More generally, we introduce the notion of a strongly K-separable GGM, and\nshow that our algorithm can decide whether a GGM is strongly $k$-separable or\nnot, with sample complexity $\\Omega (k \\: \\text{log} \\: p)$. We introduce the\nnotion of a generalized feedback vertex set (FVS), an extension of the typical\nFVS, and show that we can use this identification technique to learn GGMs with\ngeneralized FVSs.\n", "versions": [{"version": "v1", "created": "Sun, 10 Jun 2018 14:29:05 GMT"}], "update_date": "2018-06-12", "authors_parsed": [["Soh", "De Wen", ""], ["Tatikonda", "Sekhar", ""]]}, {"id": "1806.03666", "submitter": "Andreas Anastasiou Dr", "authors": "Andreas Anastasiou and Gesine Reinert", "title": "Bounds for the asymptotic distribution of the likelihood ratio", "comments": "27 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we give an explicit bound on the distance to chisquare for the\nlikelihood ratio statistic when the data are realisations of independent and\nidentically distributed random elements. To our knowledge this is the first\nexplicit bound which is available in the literature. The bound depends on the\nnumber of samples as well as on the dimension of the parameter space. We\nillustrate the bound with three examples: samples from an exponential\ndistribution, samples from a normal distribution, and logistic regression.\n", "versions": [{"version": "v1", "created": "Sun, 10 Jun 2018 14:35:09 GMT"}], "update_date": "2018-06-12", "authors_parsed": [["Anastasiou", "Andreas", ""], ["Reinert", "Gesine", ""]]}, {"id": "1806.03729", "submitter": "Johannes Martini", "authors": "Johannes W R Martini and Francisco Rosales and Ngoc-Thuy Ha and Thomas\n  Kneib and Johannes Heise and Valentin Wimmer", "title": "Lost in translation: On the impact of data coding on penalized\n  regression with interactions", "comments": null, "journal-ref": "G3 (2019) https://doi.org/10.1534/g3.118.200961", "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Penalized regression approaches are standard tools in quantitative genetics.\nIt is known that the fit of an \\emph{ordinary least squares} (OLS) regression\nis independent of certain transformations of the coding of the predictor\nvariables, and that the standard mixed model \\emph{ridge regression best linear\nunbiased prediction} (RRBLUP) is neither affected by translations of the\nvariable coding, nor by global scaling. However, it has been reported that an\nextended version of this mixed model, which incorporates interactions by\nproducts of markers as additional predictor variables is affected by\ntranslations of the marker coding. In this work, we identify the cause of this\nloss of invariance in a general context of penalized regression on polynomials\nin the predictor variables. We show that in most cases, translating the coding\nof the predictor variables has an impact on effect estimates, with an exception\nwhen only the size of the coefficients of monomials of highest total degree are\npenalized. The invariance of RRBLUP can thus be considered as a special case of\nthis setting, with a polynomial of total degree 1, where the size of the fixed\neffect (total degree 0) is not penalized but all coefficients of monomials of\ntotal degree 1 are. The extended RRBLUP, which includes interactions, is not\ninvariant to translations because it does not only penalize interactions (total\ndegree 2), but also additive effects (total degree 1). Our observations are not\nrestricted to ridge regression, but generally valid for penalized regressions,\nfor instance also for the $\\ell_1$ penalty of LASSO.\n", "versions": [{"version": "v1", "created": "Sun, 10 Jun 2018 21:46:41 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Martini", "Johannes W R", ""], ["Rosales", "Francisco", ""], ["Ha", "Ngoc-Thuy", ""], ["Kneib", "Thomas", ""], ["Heise", "Johannes", ""], ["Wimmer", "Valentin", ""]]}, {"id": "1806.03801", "submitter": "Lifeng Lai", "authors": "Lifeng Lai and Erhan Bayraktar", "title": "On the adversarial robustness of robust estimators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by recent data analytics applications, we study the adversarial\nrobustness of robust estimators. Instead of assuming that only a fraction of\nthe data points are outliers as considered in the classic robust estimation\nsetup, in this paper, we consider an adversarial setup in which an attacker can\nobserve the whole dataset and can modify all data samples in an adversarial\nmanner so as to maximize the estimation error caused by his attack. We\ncharacterize the attacker's optimal attack strategy, and further introduce\nadversarial influence function (AIF) to quantify an estimator's sensitivity to\nsuch adversarial attacks. We provide an approach to characterize AIF for any\ngiven robust estimator, and then design optimal estimator that minimizes AIF,\nwhich implies it is least sensitive to adversarial attacks and hence is most\nrobust against adversarial attacks. From this characterization, we identify a\ntradeoff between AIF (i.e., robustness against adversarial attack) and\ninfluence function, a quantity used in classic robust estimators to measure\nrobustness against outliers, and design estimators that strike a desirable\ntradeoff between these two quantities.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jun 2018 04:29:55 GMT"}, {"version": "v2", "created": "Tue, 31 Mar 2020 01:47:01 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Lai", "Lifeng", ""], ["Bayraktar", "Erhan", ""]]}, {"id": "1806.03948", "submitter": "Abbas Alhakim", "authors": "Abbas Alhakim", "title": "Hadamard Matrices, Quaternions, and the Pearson Chi-square Statistic", "comments": "19 pages, 2 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a symbolic decomposition of the Pearson chi-square statistic with\nunequal cell probabilities, by presenting Hadamard-type matrices whose columns\nare eigenvectors of the variance-covariance matrix of the cell counts. All of\nthe eigenvectors have non-zero values so each component test uses all cell\nprobabilities in a way that makes it intuitively interpretable. When all cell\nprobabilities are distinct and unrelated we establish that such decomposition\nis only possible when the number of multinomial cells is a small power of 2.\nFor higher powers of 2, we show, using the theory of orthogonal designs, that\nthe targeted decomposition is possible when appropriate relations are imposed\non the cell probabilities, the simplest of which is when the probabilities are\nequal and the decomposition is reduced to the one obtained by Hadamard\nmatrices. Simulations are given to illustrate the sensitivity of various\ncomponents to changes in location, scale skewness and tail probability, as well\nas to illustrate the potential improvement in power when the cell probabilities\nare changed.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jun 2018 10:09:29 GMT"}], "update_date": "2018-06-12", "authors_parsed": [["Alhakim", "Abbas", ""]]}, {"id": "1806.04028", "submitter": "Dmitrii Ostrovskii", "authors": "Zaid Harchaoui, Anatoli Juditsky, Arkadi Nemirovski, Dmitrii\n  Ostrovskii", "title": "Adaptive Denoising of Signals with Local Shift-Invariant Structure", "comments": "39 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss the problem of adaptive discrete-time signal denoising in the\nsituation where the signal to be recovered admits a \"linear oracle\" -- an\nunknown linear estimate that takes the form of convolution of observations with\na time-invariant filter. It was shown by Juditsky and Nemirovski (2009) that\nwhen the $\\ell_2$-norm of the oracle filter is small enough, such oracle can be\n\"mimicked\" by an efficiently computable adaptive estimate of the same structure\nwith an observation-driven filter. The filter in question was obtained as a\nsolution to the optimization problem in which the $\\ell_\\infty$-norm of the\nDiscrete Fourier Transform (DFT) of the estimation residual is minimized under\nconstraint on the $\\ell_1$-norm of the filter DFT. In this paper, we discuss a\nnew family of adaptive estimates which rely upon minimizing the $\\ell_2$-norm\nof the estimation residual. We show that such estimators possess better\nstatistical properties than those based on $\\ell_\\infty$-fit; in particular, we\nprove oracle inequalities for their $\\ell_2$-loss and improved bounds for\n$\\ell_2$- and pointwise losses. The oracle inequalities rely on the\n\"approximate shift-invariance\" assumption stating that the signal to be\nrecovered is close to an (unknown) shift-invariant subspace. We also study the\nrelationship of the approximate shift-invariance assumption with the \"signal\nsimplicity\" assumption introduced in Juditsky and Nemirovski (2009) and discuss\nthe application of the proposed approach to harmonic oscillations denoising.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jun 2018 14:51:11 GMT"}, {"version": "v2", "created": "Fri, 12 Feb 2021 02:12:26 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Harchaoui", "Zaid", ""], ["Juditsky", "Anatoli", ""], ["Nemirovski", "Arkadi", ""], ["Ostrovskii", "Dmitrii", ""]]}, {"id": "1806.04059", "submitter": "Chaoran Hu", "authors": "Chaoran Hu and Vladimir Pozdnyakov and Jun Yan", "title": "Density and Distribution Evaluation for Convolution of Independent Gamma\n  Variables", "comments": null, "journal-ref": "Computational Statistics 35 (2020) 327-342", "doi": "10.1007/s00180-019-00924-9", "report-no": null, "categories": "stat.CO math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several numerical evaluations of the density and distribution of convolution\nof independent gamma variables are compared in their accuracy and speed. In\napplication to renewal processes, an efficient formula is derived for the\nprobability mass function of the event count.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jun 2018 15:37:11 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Hu", "Chaoran", ""], ["Pozdnyakov", "Vladimir", ""], ["Yan", "Jun", ""]]}, {"id": "1806.04071", "submitter": "David Rossell", "authors": "David Rossell", "title": "Concentration of posterior probabilities and normalized L0 criteria", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study frequentist properties of Bayesian and $L_0$ model selection, with a\nfocus on (potentially non-linear) high-dimensional regression. We propose a\nconstruction to study how posterior probabilities and normalized $L_0$ criteria\nconcentrate on the (Kullback-Leibler) optimal model and other subsets of the\nmodel space. When such concentration occurs, one also bounds the frequentist\nprobabilities of selecting the correct model, type I and type II errors. These\nresults hold generally, and help validate the use of posterior probabilities\nand $L_0$ criteria to control frequentist error probabilities associated to\nmodel selection and hypothesis tests. Regarding regression, we help understand\nthe effect of the sparsity imposed by the prior or the $L_0$ penalty, and of\nproblem characteristics such as the sample size, signal-to-noise, dimension and\ntrue sparsity. A particular finding is that one may use less sparse\nformulations than would be asymptotically optimal, but still attain consistency\nand often also significantly better finite-sample performance. We also prove\nnew results related to misspecifying the mean or covariance structures, and\ngive tighter rates for certain non-local priors than currently available.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jun 2018 15:52:16 GMT"}, {"version": "v2", "created": "Fri, 20 Jul 2018 16:08:17 GMT"}, {"version": "v3", "created": "Thu, 22 Nov 2018 09:09:56 GMT"}, {"version": "v4", "created": "Mon, 26 Nov 2018 08:54:11 GMT"}, {"version": "v5", "created": "Thu, 12 Sep 2019 16:35:13 GMT"}, {"version": "v6", "created": "Fri, 13 Mar 2020 14:46:34 GMT"}, {"version": "v7", "created": "Tue, 2 Mar 2021 13:44:56 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Rossell", "David", ""]]}, {"id": "1806.04106", "submitter": "Bernhard Spangl", "authors": "Bernhard Spangl", "title": "Robust test statistics for the two-way MANOVA based on the minimum\n  covariance determinant estimator", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robust test statistics for the two-way MANOVA based on the minimum covariance\ndeterminant (MCD) estimator are proposed as alternatives to the classical\nWilks' Lambda test statistics which are well known to be very sensitive to\noutliers as they are based on classical normal theory estimates of generalized\nvariances. The classical Wilks' Lambda statistics are robustified by replacing\nthe classical estimates by highly robust and efficient reweighted MCD\nestimates. Further, Monte Carlo simulations are used to evaluate the\nperformance of the new test statistics under various designs by investigating\ntheir finite sample accuracy, power, and robustness against outliers. Finally,\nthese robust test statistics are applied to a real data example.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jun 2018 16:56:02 GMT"}], "update_date": "2018-06-12", "authors_parsed": [["Spangl", "Bernhard", ""]]}, {"id": "1806.04119", "submitter": "Arun Kuchibhotla", "authors": "Arun Kumar Kuchibhotla, Lawrence D. Brown, Andreas Buja, Edward I.\n  George and Linda Zhao", "title": "Valid Post-selection Inference in Assumption-lean Linear Regression", "comments": "49 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Construction of valid statistical inference for estimators based on\ndata-driven selection has received a lot of attention in the recent times. Berk\net al. (2013) is possibly the first work to provide valid inference for\nGaussian homoscedastic linear regression with fixed covariates under arbitrary\ncovariate/variable selection. The setting is unrealistic and is extended by\nBachoc et al. (2016) by relaxing the distributional assumptions. A major\ndrawback of the aforementioned works is that the construction of valid\nconfidence regions is computationally intensive. In this paper, we first prove\nthat post-selection inference is equivalent to simultaneous inference and then\nconstruct valid post-selection confidence regions which are computationally\nsimple. Our construction is based on deterministic inequalities and apply to\nindependent as well as dependent random variables without the requirement of\ncorrect distributional assumptions. Finally, we compare the volume of our\nconfidence regions with the existing ones and show that under non-stochastic\ncovariates, our regions are much smaller.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jun 2018 17:39:37 GMT"}], "update_date": "2018-06-12", "authors_parsed": [["Kuchibhotla", "Arun Kumar", ""], ["Brown", "Lawrence D.", ""], ["Buja", "Andreas", ""], ["George", "Edward I.", ""], ["Zhao", "Linda", ""]]}, {"id": "1806.04195", "submitter": "Yury Polyanskiy", "authors": "Yury Polyanskiy and Yihong Wu", "title": "Application of information-percolation method to reconstruction problems\n  on graphs", "comments": null, "journal-ref": "Math. Stat. Learn., vol. 2, no. 1, pp. 1--24, 2019", "doi": null, "report-no": null, "categories": "cs.IT math.IT math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a method of proving impossibility results based on\napplying strong data-processing inequalities to estimate mutual information\nbetween sets of variables forming certain Markov random fields. The end result\nis that mutual information between two \"far away\" (as measured by the graph\ndistance) variables is bounded by the probability of the existence of an open\npath in a bond-percolation problem on the same graph. Furthermore, stronger\nbounds can be obtained by establishing mutual information comparison results\nwith an erasure model on the same graph, with erasure probabilities given by\nthe contraction coefficients.\n  As applications, we show that our method gives sharp threshold for partially\nrecovering a rank-one perturbation of a random Gaussian matrix (spiked Wigner\nmodel), yields the best known upper bound on the noise level for group\nsynchronization (obtained concurrently by Abbe and Boix), and establishes new\nimpossibility result for community detection on the stochastic block model with\n$k$ communities.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jun 2018 19:06:10 GMT"}, {"version": "v2", "created": "Thu, 21 May 2020 10:34:14 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Polyanskiy", "Yury", ""], ["Wu", "Yihong", ""]]}, {"id": "1806.04303", "submitter": "Panpan Zhang", "authors": "Hosam M. Mahmoud and Panpan Zhang", "title": "Distributions in the constant-differentials P\\'olya process", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a class of unbalanced constant-differentials P\\'olya processes on\nwhite and blue balls. We show that the number of white balls, the number of\nblue balls, and the total number of balls, when appropriately scaled, all\nconverge in distribution to a gamma random variables with parameters depending\non the differential index and the amount of ball addition at the epochs, but\nnot on the initial conditions. The result is obtained by an analytic approach\nutilizing partial differential equations.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jun 2018 02:32:38 GMT"}, {"version": "v2", "created": "Sun, 26 Aug 2018 03:19:59 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Mahmoud", "Hosam M.", ""], ["Zhang", "Panpan", ""]]}, {"id": "1806.04343", "submitter": "L\\'eo Miolane", "authors": "L\\'eo Miolane", "title": "Phase transitions in spiked matrix estimation: information-theoretic\n  analysis", "comments": "These notes present in a unified manner recent results (as well as\n  new developments) on the information-theoretic limits in spiked matrix\n  estimation", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study here the so-called spiked Wigner and Wishart models, where one\nobserves a low-rank matrix perturbed by some Gaussian noise. These models\nencompass many classical statistical tasks such as sparse PCA, submatrix\nlocalization, community detection or Gaussian mixture clustering. The goal of\nthese notes is to present in a unified manner recent results (as well as new\ndevelopments) on the information-theoretic limits of these spiked matrix\nmodels. We compute the minimal mean squared error for the estimation of the\nlow-rank signal and compare it to the performance of spectral estimators and\nmessage passing algorithms. Phase transition phenomena are observed: depending\non the noise level it is either impossible, easy (i.e. using polynomial-time\nestimators) or hard (information-theoretically possible, but no efficient\nalgorithm is known to succeed) to recover the signal.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jun 2018 05:56:46 GMT"}, {"version": "v2", "created": "Mon, 24 Sep 2018 14:53:58 GMT"}, {"version": "v3", "created": "Mon, 24 Jun 2019 09:44:37 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Miolane", "L\u00e9o", ""]]}, {"id": "1806.04823", "submitter": "Vira Semenova", "authors": "Denis Nekipelov, Vira Semenova, Vasilis Syrgkanis", "title": "Regularized Orthogonal Machine Learning for Nonlinear Semiparametric\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG econ.EM stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a Lasso-type estimator for a high-dimensional sparse\nparameter identified by a single index conditional moment restriction (CMR). In\naddition to this parameter, the moment function can also depend on a nuisance\nfunction, such as the propensity score or the conditional choice probability,\nwhich we estimate by modern machine learning tools. We first adjust the moment\nfunction so that the gradient of the future loss function is insensitive\n(formally, Neyman-orthogonal) with respect to the first-stage regularization\nbias, preserving the single index property. We then take the loss function to\nbe an indefinite integral of the adjusted moment function with respect to the\nsingle index. The proposed Lasso estimator converges at the oracle rate, where\nthe oracle knows the nuisance function and solves only the parametric problem.\nWe demonstrate our method by estimating the short-term heterogeneous impact of\nConnecticut's Jobs First welfare reform experiment on women's welfare\nparticipation decision.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2018 02:22:51 GMT"}, {"version": "v2", "created": "Tue, 19 Jun 2018 15:34:02 GMT"}, {"version": "v3", "created": "Sat, 30 Jun 2018 21:20:53 GMT"}, {"version": "v4", "created": "Sun, 20 Oct 2019 16:29:49 GMT"}, {"version": "v5", "created": "Wed, 30 Sep 2020 02:51:52 GMT"}, {"version": "v6", "created": "Sat, 17 Oct 2020 13:14:04 GMT"}, {"version": "v7", "created": "Wed, 16 Jun 2021 02:38:45 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Nekipelov", "Denis", ""], ["Semenova", "Vira", ""], ["Syrgkanis", "Vasilis", ""]]}, {"id": "1806.04896", "submitter": "Djihad Benelmadani", "authors": "D. Benelmadani, K. Benhenni and S. Louhichi", "title": "Trapezoidal rule and sampling designs for the nonparametric estimation\n  of the regression function in models with correlated errors", "comments": "36 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of estimating the regression function in a fixed design models\nwith correlated observations is considered. Such observations are obtained from\nseveral experimental units, each of them forms a time series. Based on the\ntrapezoidal rule, we propose a simple kernel estimator and we derive the\nasymptotic expression of its integrated mean squared error IMSE and its\nasymptotic normality. The problems of the optimal bandwidth and the optimal\ndesign with respect to the asymptotic IMSE are also investigated. Finally, a\nsimulation study is conducted to study the performance of the new estimator and\nto compare it with the classical estimator of Gasser and M\\\"uller in a finite\nsample set. In addition, we study the robustness of the optimal design with\nrespect to the misspecification of the autocovariance function.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2018 08:50:54 GMT"}, {"version": "v2", "created": "Wed, 12 Jun 2019 09:15:36 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Benelmadani", "D.", ""], ["Benhenni", "K.", ""], ["Louhichi", "S.", ""]]}, {"id": "1806.04999", "submitter": "Ricardo Carrizo Vergara", "authors": "Ricardo Carrizo Vergara, Denis Allard, Nicolas Desassis", "title": "A general framework for SPDE-based stationary random fields", "comments": "Corrected typos and style. Corrected mistakes in references (verified\n  the cross cite, added new references and erasing non-used ones).\n  Reorganization of the Section 6 in order to obtain a \"general to particular\"\n  exposition. Appendix E is erased, its content is now present in the corpus.\n  Some clarifications to proofs in Appendix B are added", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents theoretical advances in the application of the Stochastic\nPartial Differential Equation (SPDE) approach in geostatistics. We show a\ngeneral approach to construct stationary models related to a wide class of\nlinear SPDEs, with applications to spatio-temporal models having non-trivial\nproperties. Within the framework of Generalized Random Fields, a criterion for\nexistence and uniqueness of stationary solutions for this class of SPDEs is\nproposed and proven. Their covariance are then obtained through their spectral\nmeasure. We present a result relating the covariance in the case of a White\nNoise source term with that of a generic case through convolution. Then, we\nobtain a variety of SPDE-based stationary random fields. In particular,\nwell-known results regarding the Mat\\'ern Model and Markovian models are\nrecovered. A new relationship between the Stein model and a particular SPDE is\nobtained. New spatio-temporal models obtained from evolution SPDEs of arbitrary\ntemporal derivative order are then obtained, for which properties of\nseparability and symmetry can be controlled. We also obtain results concerning\nstationary solutions for physically inspired models, such as solutions to the\nheat equation, the advection-diffusion equation, some Langevin's equations and\nthe wave equation.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2018 12:58:36 GMT"}, {"version": "v2", "created": "Fri, 27 Jul 2018 17:53:43 GMT"}], "update_date": "2018-07-30", "authors_parsed": [["Vergara", "Ricardo Carrizo", ""], ["Allard", "Denis", ""], ["Desassis", "Nicolas", ""]]}, {"id": "1806.05077", "submitter": "Yuta Koike", "authors": "Yuta Koike", "title": "Mixed-normal limit theorems for multiple Skorohod integrals in\n  high-dimensions, with application to realized covariance", "comments": "67 pages, 1 figure. Simulation results have been changed slightly due\n  to a mistake in the original program. To appear in the Electronic Journal of\n  Statistics", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper develops mixed-normal approximations for probabilities that\nvectors of multiple Skorohod integrals belong to random convex polytopes when\nthe dimensions of the vectors possibly diverge to infinity. We apply the\ndeveloped theory to establish the asymptotic mixed normality of the realized\ncovariance matrix of a high-dimensional continuous semimartingale observed at a\nhigh-frequency, where the dimension can be much larger than the sample size. We\nalso present an application of this result to testing the residual sparsity of\na high-dimensional continuous-time factor model.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2018 14:21:20 GMT"}, {"version": "v2", "created": "Thu, 16 Aug 2018 08:59:55 GMT"}, {"version": "v3", "created": "Mon, 1 Apr 2019 02:16:36 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Koike", "Yuta", ""]]}, {"id": "1806.05095", "submitter": "Nickos Papadatos D", "authors": "Nickos Papadatos", "title": "Optimal moment inequalities for order statistics from nonnegative random\n  variables", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We obtain the best possible upper bounds for the moments of a single order\nstatistic from independent, non-negative random variables, in terms of the\npopulation mean. The main result covers the independent identically distributed\ncase. Furthermore, the case of the sample minimum for merely independent (not\nnecessarily identically distributed) random variables is treated in detail.\n  Key-words and phrases: order statistics; optimal moment bounds; nonnegative\nrandom variables; sample minimum; reliability systems.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2018 14:53:36 GMT"}], "update_date": "2018-06-14", "authors_parsed": [["Papadatos", "Nickos", ""]]}, {"id": "1806.05137", "submitter": "Laura Dumitrescu", "authors": "Laura Dumitrescu and Estate V. Khmaladze", "title": "Asymptotic hypothesis testing for the colour blind problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the classical two-sample problem, the conventional approach for testing\ndistributions equality is based on the difference between the two marginal\nempirical distribution functions, whereas a test for independence is based on\nthe contrast between the bivariate and the product of the marginal empirical\ndistribution functions. In this article we consider the problem of testing\nindependence and distributions equality when the observer is \"colour blind\" so\nhe cannot distinguish the distribution which has generated each of the two\nmeasurements. Within a nonparametric framework, we propose an empirical process\nfor this problem and find the linear statistic which is asymptotically optimal\nfor testing the equality of the marginal distributions against a specific form\nof contiguous alternatives.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2018 16:35:03 GMT"}], "update_date": "2018-06-14", "authors_parsed": [["Dumitrescu", "Laura", ""], ["Khmaladze", "Estate V.", ""]]}, {"id": "1806.05139", "submitter": "Carson Eisenach", "authors": "Carson Eisenach, Florentina Bunea, Yang Ning, Claudiu Dinicu", "title": "High-Dimensional Inference for Cluster-Based Graphical Models", "comments": null, "journal-ref": "Journal of Machine Learning Research 21 (2020) 1-55", "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Motivated by modern applications in which one constructs graphical models\nbased on a very large number of features, this paper introduces a new class of\ncluster-based graphical models, in which variable clustering is applied as an\ninitial step for reducing the dimension of the feature space. We employ model\nassisted clustering, in which the clusters contain features that are similar to\nthe same unobserved latent variable. Two different cluster-based Gaussian\ngraphical models are considered: the latent variable graph, corresponding to\nthe graphical model associated with the unobserved latent variables, and the\ncluster-average graph, corresponding to the vector of features averaged over\nclusters. Our study reveals that likelihood based inference for the latent\ngraph, not analyzed previously, is analytically intractable. Our main\ncontribution is the development and analysis of alternative estimation and\ninference strategies, for the precision matrix of an unobservable latent vector\n$Z$. We replace the likelihood of the data by an appropriate class of empirical\nrisk functions, that can be specialized to the latent graphical model and to\nthe simpler, but under-analyzed, cluster-average graphical model. The\nestimators thus derived can be used for inference on the graph structure, for\ninstance on edge strength or pattern recovery. Inference is based on the\nasymptotic limits of the entry-wise estimates of the precision matrices\nassociated with the conditional independence graphs under consideration. While\ntaking the uncertainty induced by the clustering step into account, we\nestablish Berry-Esseen central limit theorems for the proposed estimators. It\nis noteworthy that, although the clusters are estimated adaptively from the\ndata, the central limit theorems regarding the entries of the estimated graphs\nare proved under the same conditions one would use if the clusters were\nknown....\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2018 16:37:34 GMT"}, {"version": "v2", "created": "Mon, 8 Jun 2020 14:57:30 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Eisenach", "Carson", ""], ["Bunea", "Florentina", ""], ["Ning", "Yang", ""], ["Dinicu", "Claudiu", ""]]}, {"id": "1806.05273", "submitter": "Justin Khim", "authors": "Justin Khim and Po-Ling Loh", "title": "A theory of maximum likelihood for weighted infection graphs", "comments": "47 pages, 1 figure, 12 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of parameter estimation based on infection data from an\nepidemic outbreak on a graph. We assume that successive infections occur via\ncontagion; i.e., transmissions can only spread across existing directed edges\nin the graph. Our stochastic spreading model allows individual nodes to be\ninfected more than once, and the probability of the transmission spreading\nacross a particular edge is proportional to both the cumulative number of times\nthe source nodes has been infected in previous stages of the epidemic and the\nweight parameter of the edge. We propose a maximum likelihood estimator for\ninferring the unknown edge weights when full information is available\nconcerning the order and identity of successive edge transmissions. When the\nweights take a particular form as exponential functions of a linear combination\nof known edge covariates, we show that maximum likelihood estimation amounts to\noptimizing a convex function, and produces a solution that is both consistent\nand asymptotically normal. Our proofs are based on martingale convergence\ntheorems and the theory of weighted P\\'{o}lya urns. We also show how our theory\nmay be generalized to settings where the weights are not exponential. Finally,\nwe analyze the case where the available infection data comes in the form of an\nunordered set of edge transmissions. We propose two algorithms for weight\nparameter estimation in this setting and derive corresponding theoretical\nguarantees. Our methods are validated using both synthetic data and real-world\ndata from the Ebola spread in West Africa.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2018 21:24:25 GMT"}], "update_date": "2018-06-15", "authors_parsed": [["Khim", "Justin", ""], ["Loh", "Po-Ling", ""]]}, {"id": "1806.05287", "submitter": "Emmanuel Caron", "authors": "Emmanuel Caron", "title": "Asymptotic distribution of least square estimators for linear models\n  with dependent errors", "comments": "18 pages, 2 figures", "journal-ref": "Statistics, 53:4, (2019), 885-902", "doi": "10.1080/02331888.2019.1593987", "report-no": null, "categories": "math.ST math.PR stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the usual linear regression model in the case\nwhere the error process is assumed strictly stationary. We use a result from\nHannan (1973), who proved a Central Limit Theorem for the usual least square\nestimator under general conditions on the design and on the error process.\nWhatever the design satisfying Hannan's conditions, we define an estimator of\nthe covariance matrix and we prove its consistency under very mild conditions.\nAs an application, we show how to modify the usual tests on the linear model in\nthis dependent context, in such a way that the type-I error rate remains\nasymptotically correct, and we illustrate the performance of this procedure\nthrough different sets of simulations.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2018 22:12:46 GMT"}, {"version": "v2", "created": "Sat, 15 Jun 2019 16:22:36 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Caron", "Emmanuel", ""]]}, {"id": "1806.05379", "submitter": "Bikramjit Das", "authors": "Bikramjit Das, Anulekha Dhara and Karthik Natarajan", "title": "On the heavy-tail behavior of the distributionally robust newsvendor", "comments": "42 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since the seminal work of Scarf (1958) [A min-max solution of an inventory\nproblem, Studies in the Mathematical Theory of Inventory and Production, pages\n201-209] on the newsvendor problem with ambiguity in the demand distribution,\nthere has been a growing interest in the study of the distributionally robust\nnewsvendor problem. The model is criticized at times for being overly\nconservative since the worst-case distribution is discrete with a few support\npoints. However, it is the order quantity prescribed from the model that is of\npractical relevance. A simple calculation shows that the optimal order quantity\nin Scarf's model with known first and second moment is also optimal for a\ncensored student-t distribution with parameter 2. In this paper, we generalize\nthis \"heavy-tail optimality\" property of the distributionally robust newsvendor\nto an ambiguity set where information on the first and the $\\alpha$th moment is\nknown, for any real number $\\alpha > 1$. We show that the optimal order\nquantity for the distributionally robust newsvendor problem is also optimal for\na regularly varying distribution with roughly a power law tail with tail index\n$\\alpha$. We illustrate the usefulness of the model in the high service level\nregime with numerical experiments, by showing that when a standard distribution\nsuch as the exponential or lognormal distribution is contaminated with a\nheavy-tailed (regularly varying) distribution, the distributionally robust\noptimal order quantity outperforms the optimal order quantity of the original\ndistribution, even with a small amount of contamination.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jun 2018 06:18:25 GMT"}, {"version": "v2", "created": "Mon, 19 Aug 2019 01:16:22 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Das", "Bikramjit", ""], ["Dhara", "Anulekha", ""], ["Natarajan", "Karthik", ""]]}, {"id": "1806.05419", "submitter": "Raja Giryes", "authors": "Tal Levy and Alireza Vahid and Raja Giryes", "title": "Ranking Recovery from Limited Comparisons using Low-Rank Matrix\n  Completion", "comments": "10 Pages, 9 figures. A prediction table for 2018 FIFA soccer world\n  cup is included", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NA math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a new method for solving the well-known rank aggregation\nproblem from pairwise comparisons using the method of low-rank matrix\ncompletion. The partial and noisy data of pairwise comparisons is transformed\ninto a matrix form. We then use tools from matrix completion, which has served\nas a major component in the low-rank completion solution of the Netflix\nchallenge, to construct the preference of the different objects. In our\napproach, the data of multiple comparisons is used to create an estimate of the\nprobability of object i to win (or be chosen) over object j, where only a\npartial set of comparisons between N objects is known. The data is then\ntransformed into a matrix form for which the noiseless solution has a known\nrank of one. An alternating minimization algorithm, in which the target matrix\ntakes a bilinear form, is then used in combination with maximum likelihood\nestimation for both factors. The reconstructed matrix is used to obtain the\ntrue underlying preference intensity. This work demonstrates the improvement of\nour proposed algorithm over the current state-of-the-art in both simulated\nscenarios and real data.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jun 2018 09:01:46 GMT"}], "update_date": "2018-06-15", "authors_parsed": [["Levy", "Tal", ""], ["Vahid", "Alireza", ""], ["Giryes", "Raja", ""]]}, {"id": "1806.05756", "submitter": "Feng Ruan", "authors": "John C. Duchi and Feng Ruan", "title": "The Right Complexity Measure in Locally Private Estimation: It is not\n  the Fisher Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT math.IT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We identify fundamental tradeoffs between statistical utility and privacy\nunder local models of privacy in which data is kept private even from the\nstatistician, providing instance-specific bounds for private estimation and\nlearning problems by developing the \\emph{local minimax risk}. In contrast to\napproaches based on worst-case (minimax) error, which are conservative, this\nallows us to evaluate the difficulty of individual problem instances and\ndelineate the possibilities for adaptation in private estimation and inference.\nOur main results show that the local modulus of continuity of the estimand with\nrespect to the variation distance---as opposed to the Hellinger distance\ncentral to classical statistics---characterizes rates of convergence under\nlocally private estimation for many notions of privacy, including differential\nprivacy and its relaxations. As consequences of these results, we identify an\nalternative to the Fisher information for private estimation, giving a more\nnuanced understanding of the challenges of adaptivity and optimality.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jun 2018 22:25:04 GMT"}, {"version": "v2", "created": "Sun, 13 Sep 2020 23:58:18 GMT"}, {"version": "v3", "created": "Tue, 29 Sep 2020 22:09:34 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Duchi", "John C.", ""], ["Ruan", "Feng", ""]]}, {"id": "1806.05830", "submitter": "Gildas Mazo", "authors": "Gildas Mazo (MaIAGE), Fran\\c{c}ois Portier", "title": "Parametric versus nonparametric: the fitness coefficient", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The fitness coefficient, introduced in this paper, results from a competition\nbetween parametric and nonparametric density estimators within the likelihood\nof the data. As illustrated on several real datasets, the fitness coefficient\ngenerally agrees with p-values but is easier to compute and interpret. Namely,\nthe fitness coefficient can be interpreted as the proportion of data coming\nfrom the parametric model. Moreover, the fitness coefficient can be used to\nbuild a semiparamteric compromise which improves inference over the parametric\nand nonparametric approaches. From a theoretical perspective, the fitness\ncoefficient is shown to converge in probability to one if the model is true and\nto zero if the model is false. From a practical perspective, the utility of the\nfitness coefficient is illustrated on real and simulated datasets.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jun 2018 07:16:00 GMT"}], "update_date": "2018-06-18", "authors_parsed": [["Mazo", "Gildas", "", "MaIAGE"], ["Portier", "Fran\u00e7ois", ""]]}, {"id": "1806.05839", "submitter": "Antoine Havet", "authors": "Antoine Havet (CMAP), Matthieu Lerasle (LMO, CMAP, SELECT), \\'Eric\n  Moulines (CMAP, XPOP)", "title": "Density estimation for RWRE", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of non-parametric density estimation of a random\nenvironment from the observation of a single trajectory of a random walk in\nthis environment. We first construct a density estimator using the\nbeta-moments. We then show that the Goldenshluger-Lepski method can be used to\nselect the beta-moment. We prove non-asymptotic bounds for the supremum norm of\nthese estimators for both the recurrent and the transient to the right cases. A\nsimulation study supports our theoretical findings.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jun 2018 07:38:54 GMT"}], "update_date": "2018-06-18", "authors_parsed": [["Havet", "Antoine", "", "CMAP"], ["Lerasle", "Matthieu", "", "LMO, CMAP, SELECT"], ["Moulines", "\u00c9ric", "", "CMAP, XPOP"]]}, {"id": "1806.05910", "submitter": "Arnaud Poinas", "authors": "Arnaud Poinas", "title": "A bound of the $\\beta$-mixing coefficient for point processes in terms\n  of their intensity functions", "comments": null, "journal-ref": null, "doi": "10.1016/j.spl.2018.12.007", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove a general inequality on $\\beta$-mixing coefficients of point\nprocesses depending uniquely on their $n$-th order intensity functions. We\napply this inequality in the case of determinantal point processes and show\nthat the rate of decay of the $\\beta$-mixing coefficients of a wide class of\nDPPs is optimal.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jun 2018 11:26:54 GMT"}, {"version": "v2", "created": "Mon, 31 Aug 2020 08:46:11 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Poinas", "Arnaud", ""]]}, {"id": "1806.06012", "submitter": "Debasis Kundu Professor", "authors": "Deepak Prajapati, Sharmistha Mitra, Debasis Kundu", "title": "A New Decision Theoretic Sampling Plan for Exponential Distribution\n  under Type-I Censoring", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper a new decision theoretic sampling plan (DSP) is proposed for\nType-I censored exponential distribution. The proposed DSP is based on a new\nestimator of the expected lifetime of an exponential distribution which always\nexists, unlike the usual maximum likelihood estimator. The DSP is a\nmodification of the Bayesian variable sampling plan of \\cite{Lam:1994}. An\noptimum DSP is derived in the sense that it minimizes the Bayes risk. In terms\nof the Bayes risks, it performs better than Lam's sampling plan and its\nperformance is as good as the Bayesian sampling plan of \\cite{LLH:2002},\nalthough implementation of the DSP is very simple. Analytically it is more\ntractable than the Bayesian sampling plan of \\cite{LLH:2002}, and it can be\neasily generalized for any other loss functions also. A finite algorithm is\nprovided to obtain the optimal plan and the corresponding minimum Bayes risk is\ncalculated. Extensive numerical comparisons with the optimal Bayesian sampling\nplan proposed by \\cite{LLH:2002} are made. The results have been extended for\nthree degree polynomial loss function and for Type-I hybrid censoring scheme.\n", "versions": [{"version": "v1", "created": "Sat, 2 Jun 2018 18:27:37 GMT"}], "update_date": "2018-06-18", "authors_parsed": [["Prajapati", "Deepak", ""], ["Mitra", "Sharmistha", ""], ["Kundu", "Debasis", ""]]}, {"id": "1806.06028", "submitter": "Bruno Ebner", "authors": "Steffen Betsch and Bruno Ebner", "title": "A new characterization of the Gamma distribution and associated goodness\n  of fit tests", "comments": null, "journal-ref": "Metrika, Volume 82, Issue 7, pages 779-806, (2019)", "doi": "10.1007/s00184-019-00708-7", "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a class of weighted $L_2$-type tests of fit to the Gamma\ndistribution. Our novel procedure is based on a fixed point property of a new\ntransformation connected to a Steinian characterization of the family of Gamma\ndistributions. We derive the weak limits of the statistic under the null\nhypothesis and under contiguous alternatives. Further, we establish the global\nconsistency of the tests and apply a parametric bootstrap technique in a Monte\nCarlo simulation study to show the competitiveness to existing procedures.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jun 2018 15:56:58 GMT"}, {"version": "v2", "created": "Mon, 18 Jun 2018 15:57:28 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Betsch", "Steffen", ""], ["Ebner", "Bruno", ""]]}, {"id": "1806.06111", "submitter": "Andzhey Koziuk", "authors": "Andzhey Koziuk and Vladimir Spokoiny", "title": "Instrumental variables regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  IV regression in the context of a re-sampling is considered in the work.\nComparatively, the contribution in the development is a structural\nidentification in the IV model. The work also contains a multiplier-bootstrap\njustification.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jun 2018 20:07:04 GMT"}], "update_date": "2018-06-19", "authors_parsed": [["Koziuk", "Andzhey", ""], ["Spokoiny", "Vladimir", ""]]}, {"id": "1806.06153", "submitter": "Somabha Mukherjee", "authors": "Arun Kumar Kuchibhotla, Somabha Mukherjee and Debapratim Banerjee", "title": "High-dimensional CLT: Improvements, Non-uniform Extensions and Large\n  Deviations", "comments": "76 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Central limit theorems (CLTs) for high-dimensional random vectors with\ndimension possibly growing with the sample size have received a lot of\nattention in the recent times. Chernozhukov et al. (2017) proved a\nBerry--Esseen type result for high-dimensional averages for the class of\nhyperrectangles and they proved that the rate of convergence can be upper\nbounded by $n^{-1/6}$ upto a polynomial factor of $\\log p$ (where $n$\nrepresents the sample size and $p$ denotes the dimension). Convergence to zero\nof the bound requires $\\log^7p = o(n)$. We improve upon their result which only\nrequires $\\log^4p = o(n)$ (in the best case). This improvement is made possible\nby a sharper dimension-free anti-concentration inequality for Gaussian process\non a compact metric space. In addition, we prove two non-uniform variants of\nthe high-dimensional CLT based on the large deviation and non-uniform CLT\nresults for random variables in a Banach space by Bentkus, Ra{\\v c}kauskas, and\nPaulauskas. We apply our results in the context of post-selection inference in\nlinear regression and of empirical processes.\n", "versions": [{"version": "v1", "created": "Sat, 16 Jun 2018 00:08:10 GMT"}, {"version": "v2", "created": "Fri, 17 May 2019 20:36:31 GMT"}, {"version": "v3", "created": "Mon, 24 Jun 2019 18:40:14 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Kuchibhotla", "Arun Kumar", ""], ["Mukherjee", "Somabha", ""], ["Banerjee", "Debapratim", ""]]}, {"id": "1806.06179", "submitter": "Zijian Guo", "authors": "T. Tony Cai, Zijian Guo", "title": "Semi-supervised Inference for Explained Variance in High-dimensional\n  Linear Regression and Its Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers statistical inference for the explained variance\n$\\beta^{\\intercal}\\Sigma \\beta$ under the high-dimensional linear model\n$Y=X\\beta+\\epsilon$ in the semi-supervised setting, where $\\beta$ is the\nregression vector and $\\Sigma$ is the design covariance matrix. A calibrated\nestimator, which efficiently integrates both labelled and unlabelled data, is\nproposed. It is shown that the estimator achieves the minimax optimal rate of\nconvergence in the general semi-supervised framework. The optimality result\ncharacterizes how the unlabelled data contributes to the estimation accuracy.\nMoreover, the limiting distribution for the proposed estimator is established\nand the unlabelled data has also proven useful in reducing the length of the\nconfidence interval for the explained variance. The proposed method is extended\nto the semi-supervised inference for the unweighted quadratic functional,\n$\\|\\beta\\|_2^2$. The obtained inference results are then applied to a range of\nhigh-dimensional statistical problems, including signal detection and global\ntesting, prediction accuracy evaluation, and confidence ball construction. The\nnumerical improvement of incorporating the unlabelled data is demonstrated\nthrough simulation studies and an analysis of estimating heritability for a\nyeast segregant data set with multiple traits.\n", "versions": [{"version": "v1", "created": "Sat, 16 Jun 2018 04:39:14 GMT"}, {"version": "v2", "created": "Mon, 30 Nov 2020 13:46:16 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Cai", "T. Tony", ""], ["Guo", "Zijian", ""]]}, {"id": "1806.06231", "submitter": "Frederic Lavancier", "authors": "Fr\\'ed\\'eric Lavancier and Arnaud Poinas and Rasmus Waagepetersen", "title": "Adaptive estimating function inference for non-stationary determinantal\n  point processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating function inference is indispensable for many common point process\nmodels where the joint intensities are tractable while the likelihood function\nis not. In this paper we establish asymptotic normality of estimating function\nestimators in a very general setting of non-stationary point processes. We then\nadapt this result to the case of non-stationary determinantal point processes\nwhich are an important class of models for repulsive point patterns. In\npractice often first and second order estimating functions are used. For the\nlatter it is common practice to omit contributions for pairs of points\nseparated by a distance larger than some truncation distance which is usually\nspecified in an ad hoc manner. We suggest instead a data-driven approach where\nthe truncation distance is adapted automatically to the point process being\nfitted and where the approach integrates seamlessly with our asymptotic\nframework. The good performance of the adaptive approach is illustrated via\nsimulation studies for non-stationary determinantal point processes and by an\napplication to a real dataset.\n", "versions": [{"version": "v1", "created": "Sat, 16 Jun 2018 12:19:51 GMT"}, {"version": "v2", "created": "Fri, 15 Nov 2019 10:14:05 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Lavancier", "Fr\u00e9d\u00e9ric", ""], ["Poinas", "Arnaud", ""], ["Waagepetersen", "Rasmus", ""]]}, {"id": "1806.06233", "submitter": "Gabor Lugosi", "authors": "G\\'abor Lugosi and Shahar Mendelson", "title": "Near-optimal mean estimators with respect to general norms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of estimating the mean of a random vector in\n$\\mathbb{R}^d$ based on an i.i.d.\\ sample, when the accuracy of the estimator\nis measured by a general norm on $\\mathbb{R}^d$. We construct an estimator\n(that depends on the norm) that achieves an essentially optimal\naccuracy/confidence tradeoff under the only assumption that the random vector\nhas a well-defined covariance matrix. The estimator is based on the\nconstruction of a uniform median-of-means estimator in a class of real valued\nfunctions that may be of independent interest.\n", "versions": [{"version": "v1", "created": "Sat, 16 Jun 2018 12:27:36 GMT"}], "update_date": "2018-06-19", "authors_parsed": [["Lugosi", "G\u00e1bor", ""], ["Mendelson", "Shahar", ""]]}, {"id": "1806.06377", "submitter": "Zhigen Zhao", "authors": "Yeil Kwon and Zhigen Zhao", "title": "On F-Modelling based Empirical Bayes Estimation of Variances", "comments": "28 pages, 11 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of empirical Bayes estimation of multiple variances\n$\\sigma_i^2$'s when provided with sample variances $s_i^2$'s. Assuming an\narbitrary prior on $\\sigma_i^2$'s, we derive different versions of the Bayes\nestimators using different loss functions. For one particular loss function,\nthe resultant Bayes estimator relies on $F(s^2)$, the marginal cumulative\ndistribution function of the sample variances only. When replacing it with the\nempirical distribution function $F_N(s^2)$, we obtain an empirical Bayes\nversion called {\\bf F}-modeling based {\\bf E}mpirical {\\bf B}ayes estimator of\n{\\bf V}ariances (F-EBV). It is shown theoretically that F-EBV converges to the\ncorresponding Bayes version {\\it uniformly} over a large set. It can be used\nfor post-selection estimation and the {\\it finite Bayes} inference problem. We\nhave demonstrated the advantages of F-EBV through extensive simulations and\nreal data analysis.\n", "versions": [{"version": "v1", "created": "Sun, 17 Jun 2018 12:49:31 GMT"}, {"version": "v2", "created": "Wed, 6 Nov 2019 17:30:21 GMT"}, {"version": "v3", "created": "Fri, 14 May 2021 15:49:03 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Kwon", "Yeil", ""], ["Zhao", "Zhigen", ""]]}, {"id": "1806.06378", "submitter": "Yury Kutoyants", "authors": "Ali S. Dabye, Alix A. Gounoung and Yury A. Kutoyants", "title": "Method of Moments Estimators and Multu-step MLE for Poisson Processes", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce two types of estimators of the finite-dimensional parameters in\nthe case of observations of inhomogeneous Poisson processes. These are the\nestimators of the method of moments and multi-step MLE. It is shown that the\nestimators of the method of moments are consistent and asymptotically normal\nand the multi-step MLE are consistent and asymptotically efficient. The\nconstruction of multi-step MLE-process is done in two steps. First we construct\na consistent estimator by the observations on some learning interval and then\nthis estimator is used for construction of one-step and two-step MLEs. The main\nadvantage of the proposed approach is its computational simplicity.\n", "versions": [{"version": "v1", "created": "Sun, 17 Jun 2018 13:08:47 GMT"}], "update_date": "2018-06-19", "authors_parsed": [["Dabye", "Ali S.", ""], ["Gounoung", "Alix A.", ""], ["Kutoyants", "Yury A.", ""]]}, {"id": "1806.06381", "submitter": "Yury Kutoyants", "authors": "Christian Farinetto, Yury A. Kutoyants and Alioune Top", "title": "Poisson Source Localization on the Plane. Change-Point Case", "comments": "26 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a detection problem where several spatially distributed sensors\nobserve Poisson signals emitted from a single source of unknown position. The\nmeasurements at each sensor are modeled by independent inhomogeneous Poisson\nprocesses. A method based on Bayesian change-point estimation is proposed to\nidentify the location of the source's coordinates. The asymptotic behavior of\nthe Bayesian estimator is studied. In particular the consistency and the\nasymptotic efficiency of the estimator are shown. The limit distribution and\nthe convergence of the moments are also described. The similar statistical\nmodel could be used in GPS localization problems.\n", "versions": [{"version": "v1", "created": "Sun, 17 Jun 2018 13:21:44 GMT"}], "update_date": "2018-06-19", "authors_parsed": [["Farinetto", "Christian", ""], ["Kutoyants", "Yury A.", ""], ["Top", "Alioune", ""]]}, {"id": "1806.06382", "submitter": "Yury Kutoyants", "authors": "Oleg V. Chernoyarov and Yury A. Kutoyants", "title": "Poisson Source Localization on the Plane. Smooth Case", "comments": "26 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of localization of Poisson source by the observations\nof inhomogeneous Poisson processes. We suppose that there are $k$ detectors on\nthe plane and each detector provides the observations of Poisson processes\nwhose intensity functions depend on the position of the emitter. We describe\nthe properties of the maximum likelihood and Bayesian estimators. We show that\nunder regularity conditions these estimators are consistent, asymptotically\nnormal and asymptotically efficient. Then we propose some simple consistent\nestimators and this estimators are further used to construct asymptotically\nefficient One-step MLE-process.\n", "versions": [{"version": "v1", "created": "Sun, 17 Jun 2018 13:31:46 GMT"}], "update_date": "2018-06-19", "authors_parsed": [["Chernoyarov", "Oleg V.", ""], ["Kutoyants", "Yury A.", ""]]}, {"id": "1806.06383", "submitter": "Yury Kutoyants", "authors": "Yury A. Kutoyants", "title": "On Cusp Location Estimation for Perturbed Dynamical Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of parameter estimation in the case of observation of\nthe trajectory of diffusion process. We suppose that the drift coefficient has\na singularity of cusp-type and the unknown parameter corresponds to the\nposition of the point of the cusp. The asymptotic properties of the maximum\nlikelihood estimator and Bayesian estimators are described in the asymptotics\nof {\\it small noise}, i.e., as the diffusion coefficient tends to zero. The\nconsistency, limit distributions and the convergence of moments of these\nestimators are established.\n", "versions": [{"version": "v1", "created": "Sun, 17 Jun 2018 13:37:51 GMT"}], "update_date": "2018-06-19", "authors_parsed": [["Kutoyants", "Yury A.", ""]]}, {"id": "1806.06400", "submitter": "Yury Kutoyants", "authors": "O.V. Chernoyarov, S. Dachian and Yu.A. Kutoyants", "title": "Poisson Source Localization on the Plane. Cusp Case", "comments": "20 pages, 2 figures. arXiv admin note: text overlap with\n  arXiv:1806.06382", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work is devoted to the problem of estimation of the localization of\nPoisson source. The observations are inhomogeneous Poisson processes registered\nby the $k\\geq 3$ detectors on the plane. We study the behavior of the Bayes\nestimators in the asymptotic of large intensities. It is supposed that the\nintensity functions of the signals arriving in the detectors have cusp-type\nsingularity. We show the consistency, limit distributions and the convergence\nof moments of these estimators.\n", "versions": [{"version": "v1", "created": "Sun, 17 Jun 2018 15:52:39 GMT"}], "update_date": "2018-06-20", "authors_parsed": [["Chernoyarov", "O. V.", ""], ["Dachian", "S.", ""], ["Kutoyants", "Yu. A.", ""]]}, {"id": "1806.06405", "submitter": "Yury Kutoyants", "authors": "A.S. Dabye, Yu.A. Kutoyants and E.D. Tanguep", "title": "On APF Test for Poisson Process with Shift and Scale Parameters", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the goodness of fit test for inhomogeneous Poisson processes with\nunknown scale and shift parameters. A test statistic of Cramer-von Mises type\nis proposed and its asymptotic behavior is studied. We show that under null\nhypothesis the limit distribution of this statistic does not depend on unknown\nparameters.\n", "versions": [{"version": "v1", "created": "Sun, 17 Jun 2018 16:13:28 GMT"}], "update_date": "2018-06-19", "authors_parsed": [["Dabye", "A. S.", ""], ["Kutoyants", "Yu. A.", ""], ["Tanguep", "E. D.", ""]]}, {"id": "1806.06761", "submitter": "HaiYing Wang", "authors": "Mingyao Ai, Jun Yu, Huiming Zhang and HaiYing Wang", "title": "Optimal Subsampling Algorithms for Big Data Regressions", "comments": null, "journal-ref": "Statist Sinica, 2021, 31(2), 749-772", "doi": "10.5705/ss.202018.0439", "report-no": "http://www3.stat.sinica.edu.tw/statistica/J31N2/j31n208/j31n208.html", "categories": "stat.ME math.ST stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To fast approximate maximum likelihood estimators with massive data, this\npaper studies the Optimal Subsampling Method under the A-optimality Criterion\n(OSMAC) for generalized linear models. The consistency and asymptotic normality\nof the estimator from a general subsampling algorithm are established, and\noptimal subsampling probabilities under the A- and L-optimality criteria are\nderived. Furthermore, using Frobenius norm matrix concentration inequalities,\nfinite sample properties of the subsample estimator based on optimal\nsubsampling probabilities are also derived. Since the optimal subsampling\nprobabilities depend on the full data estimate, an adaptive two-step algorithm\nis developed. Asymptotic normality and optimality of the estimator from this\nadaptive algorithm are established. The proposed methods are illustrated and\nevaluated through numerical experiments on simulated and real datasets.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jun 2018 15:15:41 GMT"}, {"version": "v2", "created": "Wed, 26 Jun 2019 09:05:27 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Ai", "Mingyao", ""], ["Yu", "Jun", ""], ["Zhang", "Huiming", ""], ["Wang", "HaiYing", ""]]}, {"id": "1806.06887", "submitter": "Abbas Mehrabian", "authors": "Luc Devroye, Abbas Mehrabian, Tommy Reddad", "title": "The Minimax Learning Rates of Normal and Ising Undirected Graphical\n  Models", "comments": "Accepted in the Electronic Journal of Statistics; 24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $G$ be an undirected graph with $m$ edges and $d$ vertices. We show that\n$d$-dimensional Ising models on $G$ can be learned from $n$ i.i.d. samples\nwithin expected total variation distance some constant factor of $\\min\\{1,\n\\sqrt{(m + d)/n}\\}$, and that this rate is optimal. We show that the same rate\nholds for the class of $d$-dimensional multivariate normal undirected graphical\nmodels with respect to $G$. We also identify the optimal rate of $\\min\\{1,\n\\sqrt{m/n}\\}$ for Ising models with no external magnetic field.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jun 2018 18:46:15 GMT"}, {"version": "v2", "created": "Fri, 22 May 2020 00:46:14 GMT"}, {"version": "v3", "created": "Wed, 3 Jun 2020 12:43:33 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Devroye", "Luc", ""], ["Mehrabian", "Abbas", ""], ["Reddad", "Tommy", ""]]}, {"id": "1806.06945", "submitter": "Xueyu Mao", "authors": "Xueyu Mao, Purnamrita Sarkar, Deepayan Chakrabarti", "title": "Overlapping Clustering Models, and One (class) SVM to Bind Them All", "comments": "In NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  People belong to multiple communities, words belong to multiple topics, and\nbooks cover multiple genres; overlapping clusters are commonplace. Many\nexisting overlapping clustering methods model each person (or word, or book) as\na non-negative weighted combination of \"exemplars\" who belong solely to one\ncommunity, with some small noise. Geometrically, each person is a point on a\ncone whose corners are these exemplars. This basic form encompasses the widely\nused Mixed Membership Stochastic Blockmodel of networks (Airoldi et al., 2008)\nand its degree-corrected variants (Jin et al., 2017), as well as topic models\nsuch as LDA (Blei et al., 2003). We show that a simple one-class SVM yields\nprovably consistent parameter inference for all such models, and scales to\nlarge datasets. Experimental results on several simulated and real datasets\nshow our algorithm (called SVM-cone) is both accurate and scalable.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jun 2018 21:00:00 GMT"}, {"version": "v2", "created": "Mon, 5 Nov 2018 18:00:01 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Mao", "Xueyu", ""], ["Sarkar", "Purnamrita", ""], ["Chakrabarti", "Deepayan", ""]]}, {"id": "1806.06959", "submitter": "Carsten Chong", "authors": "Carsten Chong", "title": "High-frequency analysis of parabolic stochastic PDEs", "comments": "Including supplementary material; accepted for publication in the\n  Annals of Statistics", "journal-ref": "The Annals of Statistics, Vol. 48, No. 2, 1143-1167, 2020", "doi": "10.1214/19-AOS1841", "report-no": null, "categories": "math.ST math.PR stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of estimating stochastic volatility for a class of\nsecond-order parabolic stochastic PDEs. Assuming that the solution is observed\nat a high temporal frequency, we use limit theorems for multipower variations\nand related functionals to construct consistent nonparametric estimators and\nasymptotic confidence bounds for the integrated volatility process. As a\nbyproduct of our analysis, we also obtain feasible estimators for the\nregularity of the spatial covariance function of the noise.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jun 2018 21:30:57 GMT"}, {"version": "v2", "created": "Thu, 4 Oct 2018 15:38:16 GMT"}, {"version": "v3", "created": "Fri, 25 Jan 2019 19:11:08 GMT"}, {"version": "v4", "created": "Mon, 25 Mar 2019 11:52:40 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Chong", "Carsten", ""]]}, {"id": "1806.07066", "submitter": "Guido F.  Montufar", "authors": "Guido Montufar", "title": "Restricted Boltzmann Machines: Introduction and Review", "comments": "40 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT math.PR math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The restricted Boltzmann machine is a network of stochastic units with\nundirected interactions between pairs of visible and hidden units. This model\nwas popularized as a building block of deep learning architectures and has\ncontinued to play an important role in applied and theoretical machine\nlearning. Restricted Boltzmann machines carry a rich structure, with\nconnections to geometry, applied algebra, probability, statistics, machine\nlearning, and other areas. The analysis of these models is attractive in its\nown right and also as a platform to combine and generalize mathematical tools\nfor graphical models with hidden variables. This article gives an introduction\nto the mathematical analysis of restricted Boltzmann machines, reviews recent\nresults on the geometry of the sets of probability distributions representable\nby these models, and suggests a few directions for further investigation.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jun 2018 06:53:15 GMT"}], "update_date": "2018-06-20", "authors_parsed": [["Montufar", "Guido", ""]]}, {"id": "1806.07144", "submitter": "Jonas Brehmer", "authors": "Jonas Brehmer and Tilmann Gneiting", "title": "Properization: Constructing Proper Scoring Rules via Bayes Acts", "comments": null, "journal-ref": "Annals of the Institute of Statistical Mathematics, Volume 72 (3),\n  2020, 659-673", "doi": "10.1007/s10463-019-00705-7", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scoring rules serve to quantify predictive performance. A scoring rule is\nproper if truth telling is an optimal strategy in expectation. Subject to\ncustomary regularity conditions, every scoring rule can be made proper, by\napplying a special case of the Bayes act construction studied by Gr\\\"unwald and\nDawid (2004) and Dawid (2007), to which we refer as properization. We discuss\nexamples from the recent literature and apply the construction to create new\ntypes, and reinterpret existing forms, of proper scoring rules and consistent\nscoring functions. In an abstract setting, we formulate sufficient conditions\nunder which Bayes acts exist and scoring rules can be made proper.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jun 2018 10:17:27 GMT"}, {"version": "v2", "created": "Thu, 16 Aug 2018 14:48:52 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Brehmer", "Jonas", ""], ["Gneiting", "Tilmann", ""]]}, {"id": "1806.07244", "submitter": "Philippe Regnault", "authors": "Justine Lequesne, and Philippe Regnault", "title": "vsgoftest: An Package for Goodness-of-Fit Testing Based on\n  Kullback-Leibler Divergence", "comments": "25 pages, 3 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The R-package vsgoftest performs goodness-of-fit (GOF) tests, based on\nShannon entropy and Kullback-Leibler divergence, developed by Vasicek (1976)\nand Song (2002), of various classical families of distributions. The\ntheoretical framework of the so-called Vasicek-Song (VS) tests is summarized\nand followed by a detailed description of the different features of the\npackage. The power and computational time performances of VS tests are studied\nthrough their comparison with other GOF tests. Application to real datasets\nillustrates the easy-to-use functionalities of the vsgoftest package.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jun 2018 13:59:29 GMT"}], "update_date": "2018-06-20", "authors_parsed": [["Lequesne", "Justine", ""], ["Regnault", "Philippe", ""]]}, {"id": "1806.07357", "submitter": "Ghurumuruhan Ganesan", "authors": "Ghurumuruhan Ganesan", "title": "Records from partial comparisons and discrete approximations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study records obtained from partial comparisons within a\nsequence of independent and identically distributed (i.i.d.) random variables,\nindexed by positive integers, with a common density~\\(f.\\) Our main result is\nthat if the comparison sets along a subsequence of the indices satisfy a\ncertain compatibility property, then the corresponding record events are\nindependent. Moreover, the record event probabilities do not depend on the\ndensity~\\(f\\) and we obtain closed form expressions for the distribution\nof~\\(r^{th}\\) record value for any integer~\\(r \\geq 1.\\)\n  Our proof techniques extend to the discrete case as well and we estimate the\ndifference in record event probabilities associated with a continuous random\nvariable~\\(X\\) and its discrete approximations.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jun 2018 17:40:07 GMT"}], "update_date": "2018-06-20", "authors_parsed": [["Ganesan", "Ghurumuruhan", ""]]}, {"id": "1806.07484", "submitter": "Andriy Norets", "authors": "Andriy Norets and Justinas Pelenis", "title": "Adaptive Bayesian Estimation of Mixed Discrete-Continuous Distributions\n  under Smoothness and Sparsity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST econ.EM stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider nonparametric estimation of a mixed discrete-continuous\ndistribution under anisotropic smoothness conditions and possibly increasing\nnumber of support points for the discrete part of the distribution. For these\nsettings, we derive lower bounds on the estimation rates in the total variation\ndistance. Next, we consider a nonparametric mixture of normals model that uses\ncontinuous latent variables for the discrete part of the observations. We show\nthat the posterior in this model contracts at rates that are equal to the\nderived lower bounds up to a log factor. Thus, Bayesian mixture of normals\nmodels can be used for optimal adaptive estimation of mixed discrete-continuous\ndistributions.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jun 2018 22:22:38 GMT"}], "update_date": "2018-06-21", "authors_parsed": [["Norets", "Andriy", ""], ["Pelenis", "Justinas", ""]]}, {"id": "1806.07508", "submitter": "Matthew Brennan", "authors": "Matthew Brennan, Guy Bresler, Wasim Huleihel", "title": "Reducibility and Computational Lower Bounds for Problems with Planted\n  Sparse Structure", "comments": "116 pages, accepted for presentation at Conference on Learning Theory\n  (COLT) 2018, small typos fixed in latest version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The prototypical high-dimensional statistics problem entails finding a\nstructured signal in noise. Many of these problems exhibit an intriguing\nphenomenon: the amount of data needed by all known computationally efficient\nalgorithms far exceeds what is needed for inefficient algorithms that search\nover all possible structures. A line of work initiated by Berthet and Rigollet\nin 2013 has aimed to explain these statistical-computational gaps by reducing\nfrom conjecturally hard average-case problems in computer science. However, the\ndelicate nature of average-case reductions has limited the applicability of\nthis approach. In this work we introduce several new techniques to give a web\nof average-case reductions showing strong computational lower bounds based on\nthe planted clique conjecture using natural problems as intermediates. These\ninclude tight lower bounds for Planted Independent Set, Planted Dense Subgraph,\nSparse Spiked Wigner, Sparse PCA, a subgraph variant of the Stochastic Block\nModel and a biased variant of Sparse PCA. We also give algorithms matching our\nlower bounds and identify the information-theoretic limits of the models we\nconsider.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jun 2018 23:48:25 GMT"}, {"version": "v2", "created": "Mon, 18 Nov 2019 16:17:41 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Brennan", "Matthew", ""], ["Bresler", "Guy", ""], ["Huleihel", "Wasim", ""]]}, {"id": "1806.07585", "submitter": "Lihua Lei", "authors": "Lihua Lei and Peng Ding", "title": "Regression adjustment in completely randomized experiments with a\n  diverging number of covariates", "comments": "Accepted by Biometrika; 59 pages", "journal-ref": null, "doi": "10.1093/biomet/asaa103", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Randomized experiments have become important tools in empirical research. In\na completely randomized treatment-control experiment, the simple difference in\nmeans of the outcome is unbiased for the average treatment effect, and\ncovariate adjustment can further improve the efficiency without assuming a\ncorrectly specified outcome model. In modern applications, experimenters often\nhave access to many covariates, motivating the need for a theory of covariate\nadjustment under the asymptotic regime with a diverging number of covariates.\nWe study the asymptotic properties of covariate adjustment under the potential\noutcomes model and propose a bias-corrected estimator that is consistent and\nasymptotically normal under weaker conditions. Our theory is purely\nrandomization-based without imposing any parametric outcome model assumptions.\nTo prove the theoretical results, we develop novel vector and matrix\nconcentration inequalities for sampling without replacement.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2018 07:26:00 GMT"}, {"version": "v2", "created": "Tue, 7 Aug 2018 05:05:00 GMT"}, {"version": "v3", "created": "Tue, 5 Mar 2019 04:29:17 GMT"}, {"version": "v4", "created": "Thu, 31 Dec 2020 07:58:21 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Lei", "Lihua", ""], ["Ding", "Peng", ""]]}, {"id": "1806.07870", "submitter": "Hossein Keshavarz", "authors": "Hossein Keshavarz, George Michailidis, Yves Atchade", "title": "Sequential change-point detection in high-dimensional Gaussian graphical\n  models", "comments": "47 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High dimensional piecewise stationary graphical models represent a versatile\nclass for modelling time varying networks arising in diverse application areas,\nincluding biology, economics, and social sciences. There has been recent work\nin offline detection and estimation of regime changes in the topology of sparse\ngraphical models. However, the online setting remains largely unexplored,\ndespite its high relevance to applications in sensor networks and other\nengineering monitoring systems, as well as financial markets. To that end, this\nwork introduces a novel scalable online algorithm for detecting an unknown\nnumber of abrupt changes in the inverse covariance matrix of sparse Gaussian\ngraphical models with small delay. The proposed algorithm is based upon\nmonitoring the conditional log-likelihood of all nodes in the network and can\nbe extended to a large class of continuous and discrete graphical models. We\nalso investigate asymptotic properties of our procedure under certain mild\nregularity conditions on the graph size, sparsity level, number of samples, and\npre- and post-changes in the topology of the network. Numerical works on both\nsynthetic and real data illustrate the good performance of the proposed\nmethodology both in terms of computational and statistical efficiency across\nnumerous experimental settings.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2018 17:54:49 GMT"}], "update_date": "2018-06-21", "authors_parsed": [["Keshavarz", "Hossein", ""], ["Michailidis", "George", ""], ["Atchade", "Yves", ""]]}, {"id": "1806.08160", "submitter": "Marie du Roy de Chaumaray", "authors": "marie du Roy de Chaumaray", "title": "Sharp large deviations for the drift parameter of the explosive\n  Cox-Ingersoll-Ross process", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a non-stationary Cox-Ingersoll-Ross process. We establish a sharp\nlarge deviation principle for the maximum likelihood estimator of its drift\nparameter.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jun 2018 10:32:51 GMT"}], "update_date": "2018-06-22", "authors_parsed": [["de Chaumaray", "marie du Roy", ""]]}, {"id": "1806.08307", "submitter": "Luis Ernesto Salasar Bueno", "authors": "Rafael de Carvalho Ceregatti, Rafael Izbicki and Luis Ernesto Bueno\n  Salasar", "title": "WIKS: A general Bayesian nonparametric index for quantifying differences\n  between two populations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of deciding whether two samples arise from the same distribution\nis often the question of interest in many research investigations. Numerous\nstatistical methods have been devoted to this issue, but only few of them have\nconsidered a Bayesian nonparametric approach. We propose a nonparametric\nBayesian index (WIKS) which has the goal of quantifying the difference between\ntwo populations $P_1$ and $P_2$ based on samples from them. The WIKS index is\ndefined by a weighted posterior expectation of the Kolmogorov-Smirnov distance\nbetween $P_1$ and $P_2$ and, differently from most existing approaches, can be\neasily computed using any prior distribution over $(P_1,P_2)$. Moreover, WIKS\nis fast to compute and can be justified under a Bayesian decision-theoretic\nframework. We present a simulation study that indicates that the WIKS method is\nmore powerful than competing approaches in several settings, even in\nmultivariate settings. We also prove that WIKS is a consistent procedure and\ncontrols the level of significance uniformly over the null hypothesis. Finally,\nwe apply WIKS to a data set of scale measurements of three different groups of\npatients submitted to a questionnaire for Alzheimer diagnostic.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jun 2018 16:17:34 GMT"}, {"version": "v2", "created": "Fri, 22 Jun 2018 03:23:41 GMT"}], "update_date": "2018-06-25", "authors_parsed": [["Ceregatti", "Rafael de Carvalho", ""], ["Izbicki", "Rafael", ""], ["Salasar", "Luis Ernesto Bueno", ""]]}, {"id": "1806.08458", "submitter": "Jonathan Mitchell", "authors": "Jonathan D. Mitchell, Elizabeth S. Allman and John A. Rhodes", "title": "Hypothesis testing near singularities and boundaries", "comments": "32 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST q-bio.PE stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The likelihood ratio statistic, with its asymptotic $\\chi^2$ distribution at\nregular model points, is often used for hypothesis testing. At model\nsingularities and boundaries, however, the asymptotic distribution may not be\n$\\chi^2$, as highlighted by recent work of Drton. Indeed, poor behavior of a\n$\\chi^2$ for testing near singularities and boundaries is apparent in\nsimulations, and can lead to conservative or anti-conservative tests. Here we\ndevelop a new distribution designed for use in hypothesis testing near\nsingularities and boundaries, which asymptotically agrees with that of the\nlikelihood ratio statistic. For two example trinomial models, arising in the\ncontext of inference of evolutionary trees, we show the new distributions\noutperform a $\\chi^2$.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jun 2018 00:20:20 GMT"}], "update_date": "2018-06-25", "authors_parsed": [["Mitchell", "Jonathan D.", ""], ["Allman", "Elizabeth S.", ""], ["Rhodes", "John A.", ""]]}, {"id": "1806.08542", "submitter": "C\\'ecile Durot", "authors": "Moulinath Banerjee and Cecile Durot", "title": "Removing the Curse of Superefficiency: an Effective Strategy For\n  Distributed Computing in Isotonic Regression", "comments": "38 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a strategy for computing the isotonic least-squares estimate of a\nmonotone function in a general regression setting where the data are\ndistributed across different servers and the observations across servers,\nthough independent, can come from heterogeneous sub-populations, thereby\nviolating the identically distributed assumption. Our strategy fixes the\nsuper-efficiency phenomenon observed in prior work on distributed computing in\nthe isotonic regression framework, where averaging several isotonic estimates\n(each computed at a local server) on a central server produces super-efficient\nestimates that do not replicate the properties of the global isotonic\nestimator, i.e. the isotonic estimate that would be constructed by transferring\nall the data to a single server. The new estimator proposed in this paper works\nby smoothing the data on each local server, communicating the smoothed\nsummaries to the central server, and then computing an isotonic estimate at the\ncentral server, and is shown to replicate the asymptotic properties of the\nglobal estimator, and also overcome the super-efficiency phenomenon exhibited\nby earlier estimators. For data on $N$ observations, the new estimator can be\nconstructed by transferring data just over order $N^{1/3}$ across servers [as\ncompared to transferring data of order $N$ to compute the global isotonic\nestimator], and requires the same order of computing time as the global\nestimator.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jun 2018 08:05:50 GMT"}], "update_date": "2018-06-25", "authors_parsed": [["Banerjee", "Moulinath", ""], ["Durot", "Cecile", ""]]}, {"id": "1806.09048", "submitter": "Alexis Derumigny", "authors": "Alexis Derumigny and Jean-David Fermanian", "title": "A classification point-of-view about conditional Kendall's tau", "comments": "30 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO math.ST stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how the problem of estimating conditional Kendall's tau can be\nrewritten as a classification task. Conditional Kendall's tau is a conditional\ndependence parameter that is a characteristic of a given pair of random\nvariables. The goal is to predict whether the pair is concordant (value of $1$)\nor discordant (value of $-1$) conditionally on some covariates. We prove the\nconsistency and the asymptotic normality of a family of penalized approximate\nmaximum likelihood estimators, including the equivalent of the logit and probit\nregressions in our framework. Then, we detail specific algorithms adapting\nusual machine learning techniques, including nearest neighbors, decision trees,\nrandom forests and neural networks, to the setting of the estimation of\nconditional Kendall's tau. Finite sample properties of these estimators and\ntheir sensitivities to each component of the data-generating process are\nassessed in a simulation study. Finally, we apply all these estimators to a\ndataset of European stock indices.\n", "versions": [{"version": "v1", "created": "Sat, 23 Jun 2018 22:03:10 GMT"}, {"version": "v2", "created": "Tue, 31 Jul 2018 15:10:28 GMT"}, {"version": "v3", "created": "Mon, 26 Nov 2018 10:35:28 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Derumigny", "Alexis", ""], ["Fermanian", "Jean-David", ""]]}, {"id": "1806.09086", "submitter": "Jos\\'e A. D\\'iaz-Garc\\'ia", "authors": "Jose. A. Diaz-Garcia, Francisco J. Caro-Lopera and Fredy O. Perez\n  Ramirez", "title": "Multivector variate distributions: An application in Finance", "comments": "23 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new family of multivariate distributions, which shall be termed multivector\nvariate distributions, based in the family of the multivariate contoured\nelliptically distribution is proposed. Several particular cases of multivector\nvariate distributions are obtained and a number of published multivariate\ndistributions in another contexts are found as simple corollaries. An\napplication of interest in finance is full derived and compared with the\ntraditional methods.\n", "versions": [{"version": "v1", "created": "Sun, 24 Jun 2018 05:21:42 GMT"}], "update_date": "2018-06-26", "authors_parsed": [["Diaz-Garcia", "Jose. A.", ""], ["Caro-Lopera", "Francisco J.", ""], ["Ramirez", "Fredy O. Perez", ""]]}, {"id": "1806.09087", "submitter": "Dan Mikulincer", "authors": "Ronen Eldan, Dan Mikulincer, Alex Zhai", "title": "The CLT in high dimensions: quantitative bounds via martingale embedding", "comments": "37 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new method for obtaining quantitative convergence rates for\nthe central limit theorem (CLT) in a high dimensional setting. Using our\nmethod, we obtain several new bounds for convergence in transportation distance\nand entropy, and in particular: (a) We improve the best known bound, obtained\nby the third named author, for convergence in quadratic Wasserstein\ntransportation distance for bounded random vectors; (b) We derive the first\nnon-asymptotic convergence rate for the entropic CLT in arbitrary dimension,\nfor general log-concave random vectors; (c) We give an improved bound for\nconvergence in transportation distance under a log-concavity assumption and\nimprovements for both metrics under the assumption of strong log-concavity. Our\nmethod is based on martingale embeddings and specifically on the Skorokhod\nembedding constructed by the first named author.\n", "versions": [{"version": "v1", "created": "Sun, 24 Jun 2018 05:32:50 GMT"}, {"version": "v2", "created": "Wed, 29 Aug 2018 05:54:07 GMT"}, {"version": "v3", "created": "Mon, 7 Sep 2020 09:12:32 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Eldan", "Ronen", ""], ["Mikulincer", "Dan", ""], ["Zhai", "Alex", ""]]}, {"id": "1806.09369", "submitter": "Muneya Matsui", "authors": "Herold Dehling, Muneya Matsui, Thomas Mikosch, Gennady Samorodnitsky\n  and Laleh Tafakori", "title": "Distance covariance for discretized stochastic processes", "comments": "41 pages, original article", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given an iid sequence of pairs of stochastic processes on the unit interval\nwe construct a measure of independence for the components of the pairs. We\ndefine distance covariance and distance correlation based on approximations of\nthe component processes at finitely many discretization points. Assuming that\nthe mesh of the discretization converges to zero as a suitable function of the\nsample size, we show that the sample distance covariance and correlation\nconverge to limits which are zero if and only if the component processes are\nindependent. To construct a test for independence of the discretized component\nprocesses we show consistency of the bootstrap for the corresponding sample\ndistance covariance/correlation.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jun 2018 10:29:48 GMT"}, {"version": "v2", "created": "Tue, 26 Jun 2018 08:06:48 GMT"}, {"version": "v3", "created": "Thu, 22 Nov 2018 08:48:40 GMT"}, {"version": "v4", "created": "Thu, 29 Nov 2018 11:15:52 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["Dehling", "Herold", ""], ["Matsui", "Muneya", ""], ["Mikosch", "Thomas", ""], ["Samorodnitsky", "Gennady", ""], ["Tafakori", "Laleh", ""]]}, {"id": "1806.09401", "submitter": "Shogo Nakakita", "authors": "Shogo H. Nakakita, Masayuki Uchida", "title": "Quasi-likelihood analysis of an ergodic diffusion plus noise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider adaptive maximum-likelihood-type estimators and adaptive\nBayes-type ones for discretely observed ergodic diffusion processes with\nobservation noise whose variance is constant. The quasi-likelihood functions\nfor the diffusion and drift parameters are introduced and the polynomial-type\nlarge deviation inequalities for those quasi-likelihoods are shown to see the\nconvergence of moments for those estimators.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jun 2018 12:00:56 GMT"}, {"version": "v2", "created": "Tue, 3 Jul 2018 15:44:52 GMT"}, {"version": "v3", "created": "Wed, 29 Aug 2018 17:27:30 GMT"}, {"version": "v4", "created": "Tue, 2 Apr 2019 02:25:02 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["Nakakita", "Shogo H.", ""], ["Uchida", "Masayuki", ""]]}, {"id": "1806.09405", "submitter": "Arnak Dalalyan S.", "authors": "Arnak S. Dalalyan", "title": "Exponential weights in multivariate regression and a low-rankness\n  favoring prior", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We establish theoretical guarantees for the expected prediction error of the\nexponential weighting aggregate in the case of multivariate regression that is\nwhen the label vector is multidimensional. We consider the regression model\nwith fixed design and bounded noise. The first new feature uncovered by our\nguarantees is that it is not necessary to require independence of the\nobservations: a symmetry condition on the noise distribution alone suffices to\nget a sharp risk bound. This result needs the regression vectors to be bounded.\nA second curious finding concerns the case of unbounded regression vectors but\nindependent noise. It turns out that applying exponential weights to the label\nvectors perturbed by a uniform noise leads to an estimator satisfying a sharp\noracle inequality. The last contribution is the instantiation of the proposed\noracle inequalities to problems in which the unknown parameter is a matrix. We\npropose a low-rankness favoring prior and show that it leads to an estimator\nthat is optimal under weak assumptions.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jun 2018 12:01:33 GMT"}], "update_date": "2018-06-26", "authors_parsed": [["Dalalyan", "Arnak S.", ""]]}, {"id": "1806.09471", "submitter": "Alexander Rakhlin", "authors": "Mikhail Belkin and Alexander Rakhlin and Alexandre B. Tsybakov", "title": "Does data interpolation contradict statistical optimality?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that learning methods interpolating the training data can achieve\noptimal rates for the problems of nonparametric regression and prediction with\nsquare loss.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jun 2018 14:04:44 GMT"}], "update_date": "2018-06-26", "authors_parsed": [["Belkin", "Mikhail", ""], ["Rakhlin", "Alexander", ""], ["Tsybakov", "Alexandre B.", ""]]}, {"id": "1806.09517", "submitter": "Florian Gunsilius", "authors": "Florian Gunsilius", "title": "Non-testability of instrument validity under continuous endogenous\n  variables", "comments": "25 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This note presents a proof of the conjecture in \\citet*{pearl1995testability}\nabout testing the validity of an instrumental variable in hidden variable\nmodels. It implies that instrument validity cannot be tested in the case where\nthe endogenous treatment is continuously distributed. This stands in contrast\nto the classical testability results for instrument validity when the treatment\nis discrete. However, imposing weak structural assumptions on the model, such\nas continuity between the observable variables, can re-establish theoretical\ntestability in the continuous setting.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jun 2018 15:05:22 GMT"}, {"version": "v2", "created": "Mon, 21 Oct 2019 16:53:14 GMT"}, {"version": "v3", "created": "Wed, 25 Nov 2020 22:08:14 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Gunsilius", "Florian", ""]]}, {"id": "1806.09529", "submitter": "Zhou Fan", "authors": "Zhou Fan and Iain M. Johnstone and Yi Sun", "title": "Spiked covariances and principal components analysis in high-dimensional\n  random effects models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study principal components analyses in multivariate random and mixed\neffects linear models, assuming a spherical-plus-spikes structure for the\ncovariance matrix of each random effect. We characterize the behavior of\noutlier sample eigenvalues and eigenvectors of MANOVA variance components\nestimators in such models under a high-dimensional asymptotic regime. Our\nresults show that an aliasing phenomenon may occur in high dimensions, in which\neigenvalues and eigenvectors of the MANOVA estimate for one variance component\nmay be influenced by the other components. We propose an alternative procedure\nfor estimating the true principal eigenvalues and eigenvectors that\nasymptotically corrects for this aliasing problem.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jun 2018 15:35:10 GMT"}], "update_date": "2018-06-26", "authors_parsed": [["Fan", "Zhou", ""], ["Johnstone", "Iain M.", ""], ["Sun", "Yi", ""]]}, {"id": "1806.09544", "submitter": "Cheng Mao", "authors": "Cheng Mao, Ashwin Pananjady, Martin J. Wainwright", "title": "Towards Optimal Estimation of Bivariate Isotonic Matrices with Unknown\n  Permutations", "comments": "60 pages, 1 figure. This paper is a longer version of the paper\n  arXiv:1802.09963 v3, which appeared in part as a 4-page extended abstract at\n  Conference on Learning Theory (COLT) 2018. This paper studies the problem in\n  more general settings and in another error metric. This version corrects a\n  statement in Theorem 2 of v1", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many applications, including rank aggregation, crowd-labeling, and graphon\nestimation, can be modeled in terms of a bivariate isotonic matrix with unknown\npermutations acting on its rows and/or columns. We consider the problem of\nestimating an unknown matrix in this class, based on noisy observations of\n(possibly, a subset of) its entries. We design and analyze polynomial-time\nalgorithms that improve upon the state of the art in two distinct metrics,\nshowing, in particular, that minimax optimal, computationally efficient\nestimation is achievable in certain settings. Along the way, we prove matching\nupper and lower bounds on the minimax radii of certain cone testing problems,\nwhich may be of independent interest.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jun 2018 15:55:10 GMT"}, {"version": "v2", "created": "Sun, 27 Oct 2019 03:55:16 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Mao", "Cheng", ""], ["Pananjady", "Ashwin", ""], ["Wainwright", "Martin J.", ""]]}, {"id": "1806.09571", "submitter": "Vladislav Z. B. Tadi\\'c", "authors": "Vladislav Z.B. Tadic and Arnaud Doucet", "title": "Asymptotic Properties of Recursive Maximum Likelihood Estimation in\n  Non-Linear State-Space Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.OC stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using stochastic gradient search and the optimal filter derivative, it is\npossible to perform recursive (i.e., online) maximum likelihood estimation in a\nnon-linear state-space model. As the optimal filter and its derivative are\nanalytically intractable for such a model, they need to be approximated\nnumerically. In [Poyiadjis, Doucet and Singh, Biometrika 2018], a recursive\nmaximum likelihood algorithm based on a particle approximation to the optimal\nfilter derivative has been proposed and studied through numerical simulations.\nHere, this algorithm and its asymptotic behavior are analyzed theoretically. We\nshow that the algorithm accurately estimates maxima to the underlying (average)\nlog-likelihood when the number of particles is sufficiently large. We also\nderive (relatively) tight bounds on the estimation error. The obtained results\nhold under (relatively) mild conditions and cover several classes of non-linear\nstate-space models met in practice.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jun 2018 17:12:53 GMT"}, {"version": "v2", "created": "Wed, 1 Aug 2018 15:28:05 GMT"}, {"version": "v3", "created": "Sat, 2 Jan 2021 23:04:01 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Tadic", "Vladislav Z. B.", ""], ["Doucet", "Arnaud", ""]]}, {"id": "1806.09588", "submitter": "Ahmed El Alaoui", "authors": "Ahmed El Alaoui, Florent Krzakala, Michael I. Jordan", "title": "Fundamental limits of detection in the spiked Wigner model", "comments": "Substantial text overlap with arXiv:1710.02903. This manuscript\n  focuses on the LR fluctuations and the detection problem. The result is\n  strengthened and the proof (execution of the interpolation and cavity\n  methods) substantially simplified. Reflects more accurately the version to be\n  published", "journal-ref": "Ann. Statist., Volume 48, Number 2 (2020), 863-885", "doi": "10.1214/19-AOS1826", "report-no": null, "categories": "math.PR math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the fundamental limits of detecting the presence of an additive\nrank-one perturbation, or spike, to a Wigner matrix. When the spike comes from\na prior that is i.i.d. across coordinates, we prove that the log-likelihood\nratio of the spiked model against the non-spiked one is asymptotically normal\nbelow a certain reconstruction threshold which is not necessarily of a\n\"spectral\" nature, and that it is degenerate above. This establishes the\nmaximal region of contiguity between the planted and null models. It is known\nthat this threshold also marks a phase transition for estimating the spike: the\nlatter task is possible above the threshold and impossible below. Therefore,\nboth estimation and detection undergo the same transition in this random matrix\nmodel. We also provide further information about the performance of the optimal\ntest. Our proofs are based on Gaussian interpolation methods and a rigorous\nincarnation of the cavity method, as devised by Guerra and Talagrand in their\nstudy of the Sherrington--Kirkpatrick spin-glass model.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jun 2018 17:35:06 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Alaoui", "Ahmed El", ""], ["Krzakala", "Florent", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1806.09589", "submitter": "Vladislav Tadi\\'c Z. B.", "authors": "Vladislav Z.B. Tadic and Arnaud Doucet", "title": "Analyticity of Entropy Rates of Continuous-State Hidden Markov Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The analyticity of the entropy and relative entropy rates of continuous-state\nhidden Markov models is studied here. Using the analytic continuation principle\nand the stability properties of the optimal filter, the analyticity of these\nrates is shown for analytically parameterized models. The obtained results hold\nunder relatively mild conditions and cover several classes of hidden Markov\nmodels met in practice. These results are relevant for several (theoretically\nand practically) important problems arising in statistical inference, system\nidentification and information theory.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jun 2018 17:36:35 GMT"}, {"version": "v2", "created": "Wed, 1 Aug 2018 15:22:48 GMT"}, {"version": "v3", "created": "Thu, 29 Aug 2019 20:37:08 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Tadic", "Vladislav Z. B.", ""], ["Doucet", "Arnaud", ""]]}, {"id": "1806.09590", "submitter": "Vladislav Z. B. Tadi\\'c", "authors": "Vladislav Z.B. Tadic and Arnaud Doucet", "title": "Bias of Particle Approximations to Optimal Filter Derivative", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.OC stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many applications, a state-space model depends on a parameter which needs\nto be inferred from a data set. Quite often, it is necessary to perform the\nparameter inference online. In the maximum likelihood approach, this can be\ndone using stochastic gradient search and the optimal filter derivative.\nHowever, the optimal filter and its derivative are not analytically tractable\nfor a non-linear state-space model and need to be approximated numerically. In\n[Poyiadjis, Doucet and Singh, Biometrika 2011], a particle approximation to the\noptimal filter derivative has been proposed, while the corresponding $L_{p}$\nerror bonds and the central limit theorem have been provided in [Del Moral,\nDoucet and Singh, SIAM Journal on Control and Optimization 2015]. Here, the\nbias of this particle approximation is analyzed. We derive (relatively) tight\nbonds on the bias in terms of the number of particles. Under (strong) mixing\nconditions, the bounds are uniform in time and inversely proportional to the\nnumber of particles. The obtained results apply to a (relatively) broad class\nof state-space models met in practice.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jun 2018 17:38:26 GMT"}, {"version": "v2", "created": "Wed, 1 Aug 2018 15:17:50 GMT"}, {"version": "v3", "created": "Wed, 19 Sep 2018 13:24:44 GMT"}, {"version": "v4", "created": "Fri, 27 Dec 2019 15:57:20 GMT"}, {"version": "v5", "created": "Sat, 2 Jan 2021 22:52:51 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Tadic", "Vladislav Z. B.", ""], ["Doucet", "Arnaud", ""]]}, {"id": "1806.09595", "submitter": "Vladislav Tadi\\'c Z. B.", "authors": "Vladislav Z.B. Tadic and Arnaud Doucet", "title": "Stability of Optimal Filter Higher-Order Derivatives", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.OC math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many scenarios, a state-space model depends on a parameter which needs to\nbe inferred from data. Using stochastic gradient search and the optimal filter\n(first-order) derivative, the parameter can be estimated online. To analyze the\nasymptotic behavior of online methods for parameter estimation in non-linear\nstate-space models, it is necessary to establish results on the existence and\nstability of the optimal filter higher-order derivatives. The existence and\nstability properties of these derivatives are studied here. We show that the\noptimal filter higher-order derivatives exist and forget initial conditions\nexponentially fast. We also show that the optimal filter higher-order\nderivatives are geometrically ergodic. The obtained results hold under\n(relatively) mild conditions and apply to state-space models met in practice.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jun 2018 17:44:54 GMT"}, {"version": "v2", "created": "Wed, 1 Aug 2018 15:11:43 GMT"}, {"version": "v3", "created": "Fri, 20 Dec 2019 16:27:47 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Tadic", "Vladislav Z. B.", ""], ["Doucet", "Arnaud", ""]]}, {"id": "1806.09611", "submitter": "Yijun Zuo", "authors": "Yijun Zuo", "title": "Robustness of deepest projection regression functional", "comments": "arXiv admin note: substantial text overlap with arXiv:1805.02046", "journal-ref": null, "doi": "10.1007/s00362-019-01129-4", "report-no": "26 pages, 3 figures", "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Depth notions in regression have been systematically proposed and examined in\nZuo (2018). One of the prominent advantages of notion of depth is that it can\nbe directly utilized to introduce median-type deepest estimating functionals\n(or estimators in empirical distribution case) for location or regression\nparameters in a multi-dimensional setting.\n  Regression depth shares the advantage. Depth induced deepest estimating\nfunctionals are expected to inherit desirable and inherent robustness\nproperties ( e.g. bounded maximum bias and influence function and high\nbreakdown point) as their univariate location counterpart does. Investigating\nand verifying the robustness of the deepest projection estimating functional\n(in terms of maximum bias, asymptotic and finite sample breakdown point, and\ninfluence function) is the major goal of this article.\n  It turns out that the deepest projection estimating functional possesses a\nbounded influence function and the best possible asymptotic breakdown point as\nwell as the best finite sample breakdown point with robust choice of its\nunivariate regression and scale component.\n", "versions": [{"version": "v1", "created": "Sun, 24 Jun 2018 13:47:57 GMT"}, {"version": "v2", "created": "Sun, 16 Sep 2018 01:07:35 GMT"}, {"version": "v3", "created": "Tue, 18 Sep 2018 14:03:54 GMT"}, {"version": "v4", "created": "Fri, 2 Aug 2019 18:41:31 GMT"}, {"version": "v5", "created": "Mon, 12 Aug 2019 11:44:02 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Zuo", "Yijun", ""]]}, {"id": "1806.09673", "submitter": "Yuliy Baryshnikov", "authors": "Yuliy Baryshnikov and Robert Ghrist", "title": "Minimal Unimodal Decompositions on Trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AT math.ST stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The decomposition of a density function on a domain into a minimal sum of\nunimodal components is a fundamental problem in statistics, leading to the\ntopological invariant of unimodal category of a density. This paper gives an\nefficient algorithm for the construction of a minimal unimodal decomposition of\na tame density function on a finite metric tree.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jun 2018 19:23:56 GMT"}], "update_date": "2018-06-27", "authors_parsed": [["Baryshnikov", "Yuliy", ""], ["Ghrist", "Robert", ""]]}, {"id": "1806.09712", "submitter": "Stefano Favaro", "authors": "Fadhel Ayed, Marco Battiston, Federico Camerlenghi, Stefano Favaro", "title": "On consistent estimation of the missing mass", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given $n$ samples from a population of individuals belonging to different\ntypes with unknown proportions, how do we estimate the probability of\ndiscovering a new type at the $(n+1)$-th draw? This is a classical problem in\nstatistics, commonly referred to as the missing mass estimation problem. Recent\nresults by Ohannessian and Dahleh \\citet{Oha12} and Mossel and Ohannessian\n\\citet{Mos15} showed: i) the impossibility of estimating (learning) the missing\nmass without imposing further structural assumptions on the type proportions;\nii) the consistency of the Good-Turing estimator for the missing mass under the\nassumption that the tail of the type proportions decays to zero as a regularly\nvarying function with parameter $\\alpha\\in(0,1)$. In this paper we rely on\ntools from Bayesian nonparametrics to provide an alternative, and simpler,\nproof of the impossibility of a distribution-free estimation of the missing\nmass. Up to our knowledge, the use of Bayesian ideas to study large sample\nasymptotics for the missing mass is new, and it could be of independent\ninterest. Still relying on Bayesian nonparametric tools, we then show that\nunder regularly varying type proportions the convergence rate of the\nGood-Turing estimator is the best rate that any estimator can achieve, up to a\nslowly varying function, and that minimax rate must be at least\n$n^{-\\alpha/2}$. We conclude with a discussion of our results, and by\nconjecturing that the Good-Turing estimator is an rate optimal minimax\nestimator under regularly varying type proportions.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jun 2018 22:02:35 GMT"}], "update_date": "2018-06-27", "authors_parsed": [["Ayed", "Fadhel", ""], ["Battiston", "Marco", ""], ["Camerlenghi", "Federico", ""], ["Favaro", "Stefano", ""]]}, {"id": "1806.09762", "submitter": "Yichen Zhou", "authors": "Yichen Zhou, Giles Hooker", "title": "Boulevard: Regularized Stochastic Gradient Boosted Trees and Their\n  Limiting Distribution", "comments": "45 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper examines a novel gradient boosting framework for regression. We\nregularize gradient boosted trees by introducing subsampling and employ a\nmodified shrinkage algorithm so that at every boosting stage the estimate is\ngiven by an average of trees. The resulting algorithm, titled Boulevard, is\nshown to converge as the number of trees grows. We also demonstrate a central\nlimit theorem for this limit, allowing a characterization of uncertainty for\npredictions. A simulation study and real world examples provide support for\nboth the predictive accuracy of the model and its limiting behavior.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jun 2018 02:22:13 GMT"}, {"version": "v2", "created": "Wed, 15 Aug 2018 15:11:58 GMT"}, {"version": "v3", "created": "Fri, 13 Sep 2019 04:11:02 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Zhou", "Yichen", ""], ["Hooker", "Giles", ""]]}, {"id": "1806.09948", "submitter": "Spencer Wheatley Dr.", "authors": "Spencer Wheatley, Michael Schatz and Didier Sornette", "title": "The ARMA Point Process and its Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the ARMA (autoregressive-moving-average) point process, which is\na Hawkes process driven by a Neyman-Scott process with Poisson immigration. It\ncontains both the Hawkes and Neyman-Scott process as special cases and\nnaturally combines self-exciting and shot-noise cluster mechanisms, useful in a\nvariety of applications. The name ARMA is used because the ARMA point process\nis an appropriate analogue of the ARMA time series model for integer-valued\nseries. As such, the ARMA point process framework accommodates a flexible\nfamily of models sharing methodological and mathematical similarities with ARMA\ntime series. We derive an estimation procedure for ARMA point processes, as\nwell as the integer ARMA models, based on an MCEM (Monte Carlo Expectation\nMaximization) algorithm. This powerful framework for estimation accommodates\ntrends in immigration, multiple parametric specifications of excitement\nfunctions, as well as cases where marks and immigrants are not observed.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jun 2018 12:47:17 GMT"}], "update_date": "2018-06-27", "authors_parsed": [["Wheatley", "Spencer", ""], ["Schatz", "Michael", ""], ["Sornette", "Didier", ""]]}, {"id": "1806.10008", "submitter": "David Azriel", "authors": "David Azriel", "title": "The conditionality principle in high-dimensional regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a high-dimensional linear regression problem, where the number of\ncovariates is larger than the number of observations and the interest is in\nestimating the conditional variance of the response variable given the\ncovariates. A conditional and unconditioned framework are considered, where\nconditioning is with respect to the covariates, which are ancillary to the\nparameter of interest. In recent papers, a consistent estimator was developed\nin the unconditional framework when the marginal distribution of the covariates\nis normal with known mean and variance. In the present work, a certain Bayesian\nhypothesis test is formulated under the conditional framework, and it is shown\nthat the Bayes risk is a constant. This implies that no consistent estimator\nexists in the conditional framework. However, when the marginal distribution of\nthe covariates is normal, the conditional error of the above consistent\nestimator converges to zero, with probability converging to one. It follows\nthat even in the conditional setting, information about the marginal\ndistribution of an ancillary statistic may have a significant impact on\nstatistical inference. The practical implication in the context of\nhigh-dimensional regression models is that additional observations, where only\nthe covariates are given, are potentially very useful and should not be\nignored. This finding is most relevant to semi-supervised learning problems\nwhere covariate information is easy to obtain.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jun 2018 14:02:48 GMT"}, {"version": "v2", "created": "Wed, 5 Dec 2018 08:55:02 GMT"}, {"version": "v3", "created": "Wed, 27 Mar 2019 19:37:47 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Azriel", "David", ""]]}, {"id": "1806.10120", "submitter": "Elina Robeva", "authors": "Elina Robeva, Bernd Sturmfels, Ngoc Tran, and Caroline Uhler", "title": "Maximum Likelihood Estimation for Totally Positive Log-Concave Densities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study nonparametric maximum likelihood estimation for two classes of\nmultivariate distributions that imply strong forms of positive dependence;\nnamely log-supermodular (MTP$_2$) distributions and log-$L^\\#$-concave (LLC)\ndistributions. In both cases we also assume log-concavity in order to ensure\nboundedness of the likelihood function. Given $n$ independent and identically\ndistributed random vectors in $\\mathbb R^d$ from one of our distributions, the\nmaximum likelihood estimator (MLE) exists a.s. and is unique a.e. with\nprobability one when $n\\geq 3$. This holds independently of the ambient\ndimension $d$. We conjecture that the MLE is always the exponential of a tent\nfunction. We prove this result for samples in $\\{0,1\\}^d$ or in $\\mathbb{R}^2$\nunder MTP$_2$, and for samples in $\\mathbb{Q}^d$ under LLC. Finally, we provide\na conditional gradient algorithm for computing the maximum likelihood estimate.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jun 2018 17:34:10 GMT"}, {"version": "v2", "created": "Wed, 8 May 2019 21:20:22 GMT"}, {"version": "v3", "created": "Wed, 8 Jul 2020 21:16:54 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Robeva", "Elina", ""], ["Sturmfels", "Bernd", ""], ["Tran", "Ngoc", ""], ["Uhler", "Caroline", ""]]}, {"id": "1806.10196", "submitter": "Johannes Krebs", "authors": "Johannes T. N. Krebs", "title": "The bootstrap in kernel regression for stationary ergodic data when both\n  response and predictor are functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the double functional nonparametric regression model\n$Y=r(X)+\\epsilon$, where the response variable $Y$ is Hilbert space-valued and\nthe covariate $X$ takes values in a pseudometric space. The data satisfy an\nergodicity criterion which dates back to Laib and Louani (2010) and are\narranged in a triangular array. So our model also applies to samples obtained\nfrom spatial processes, e.g., stationary random fields indexed by the regular\nlattice $\\mathbb{Z}^N$ for some $N\\in\\mathbb{N}_+$. We consider a kernel\nestimator of the Nadaraya--Watson type for the regression operator $r$ and\nstudy its limiting law which is a Gaussian operator on the Hilbert space.\nMoreover, we investigate both a naive and a wild bootstrap procedure in the\ndouble functional setting and demonstrate their asymptotic validity. This is\nquite useful as building confidence sets based on an asymptotic Gaussian\ndistribution is often difficult.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jun 2018 20:10:02 GMT"}], "update_date": "2018-06-28", "authors_parsed": [["Krebs", "Johannes T. N.", ""]]}, {"id": "1806.10273", "submitter": "Helio M. de Oliveira", "authors": "H. M. de Oliveira and F. Chaves", "title": "von Mises Tapering: A Circular Data Windowing", "comments": "5 pages, 5 figures", "journal-ref": "XXXVI SIMPOSIO BRASILEIRO DE TELECOMUNICACOES E PROCESSAMENTO DE\n  SINAIS-SBrT2018", "doi": "10.14209/SBRT.2018.179", "report-no": null, "categories": "eess.SP cs.NA math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continuous standard windowing is revisited and a new taper shape is\nintroduced, which is based on the normal circular distribution by von Mises.\nContinuous-time windows are considered and their spectra obtained. A brief\ncomparison with classical window families is performed in terms of their\nspectral properties. These windows can be used as an alternative in spectral\nanalysis.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2018 02:30:34 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["de Oliveira", "H. M.", ""], ["Chaves", "F.", ""]]}, {"id": "1806.10357", "submitter": "Atsushi Iwasaki", "authors": "Atsushi Iwasaki", "title": "Deriving the Variance of the Discrete Fourier Transform Test Using\n  Parseval's Theorem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The discrete Fourier transform test is a randomness test included in NIST\nSP800-22. However, the variance of the test statistic is smaller than expected\nand the theoretical value of the variance is not known. Hitherto, the mechanism\nexplaining why the former variance is smaller than expected has been\nqualitatively explained based on Parseval's theorem. In this paper, we explore\nthis quantitatively and derive the variance using Parseval's theorem under\nparticular assumptions. Numerical experiments are then used to show that this\nderived variance is robust.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2018 09:11:09 GMT"}, {"version": "v2", "created": "Mon, 9 Jul 2018 05:26:05 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Iwasaki", "Atsushi", ""]]}, {"id": "1806.10404", "submitter": "Matthias Troffaes", "authors": "Matthias C. M. Troffaes", "title": "Imprecise Monte Carlo simulation and iterative importance sampling for\n  the estimation of lower previsions", "comments": "24 pages, 5 tables", "journal-ref": "International Journal of Approximate Reasoning 101 (2018) 31-48", "doi": "10.1016/j.ijar.2018.06.009", "report-no": null, "categories": "stat.CO math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a theoretical framework for studying numerical estimation of lower\nprevisions, generally applicable to two-level Monte Carlo methods, importance\nsampling methods, and a wide range of other sampling methods one might devise.\nWe link consistency of these estimators to Glivenko-Cantelli classes, and for\nthe sub-Gaussian case we show how the correlation structure of this process can\nbe used to bound the bias and prove consistency. We also propose a new upper\nestimator, which can be used along with the standard lower estimator, in order\nto provide a simple confidence interval. As a case study of this framework, we\nthen discuss how importance sampling can be exploited to provide accurate\nnumerical estimates of lower previsions. We propose an iterative importance\nsampling method to drastically improve the performance of imprecise importance\nsampling. We demonstrate our results on the imprecise Dirichlet model.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2018 10:46:52 GMT"}], "update_date": "2018-07-12", "authors_parsed": [["Troffaes", "Matthias C. M.", ""]]}, {"id": "1806.10493", "submitter": "Thi Thien Trang Bui", "authors": "Thi Thien Trang Bui (IMT), J-M Loubes (IMT), Laurent Risser (IMT),\n  Patricia Balaresque (AMIS)", "title": "Distribution regression model with a Reproducing Kernel Hilbert Space\n  approach", "comments": "27 pages, 9 figures. Communications in Statistics - Theory and\n  Methods (2019)", "journal-ref": null, "doi": "10.1080/03610926.2019.1658782", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a new distribution regression model for\nprobability distributions. This model is based on a Reproducing Kernel Hilbert\nSpace (RKHS) regression framework, where universal kernels are built using\nWasserstein distances for distributions belonging to W 2 ($\\Omega$) and\n$\\Omega$ is a compact subspace of R. We prove the universal kernel property of\nsuch kernels and use this setting to perform regressions on functions.\nDifferent regression models are first compared with the proposed one on\nsimulated functional data. We then apply our regression model to transient\nevoked otoascoutic emission (TEOAE) distribution responses and real predictors\nof the age.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2018 14:07:15 GMT"}, {"version": "v2", "created": "Fri, 4 Oct 2019 07:14:41 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Bui", "Thi Thien Trang", "", "IMT"], ["Loubes", "J-M", "", "IMT"], ["Risser", "Laurent", "", "IMT"], ["Balaresque", "Patricia", "", "AMIS"]]}, {"id": "1806.10648", "submitter": "Jonathan Weed", "authors": "Philippe Rigollet and Jonathan Weed", "title": "Uncoupled isotonic regression via minimum Wasserstein deconvolution", "comments": "To appear in Information and Inference: a Journal of the IMA", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Isotonic regression is a standard problem in shape-constrained estimation\nwhere the goal is to estimate an unknown nondecreasing regression function $f$\nfrom independent pairs $(x_i, y_i)$ where $\\mathbb{E}[y_i]=f(x_i), i=1, \\ldots\nn$. While this problem is well understood both statistically and\ncomputationally, much less is known about its uncoupled counterpart where one\nis given only the unordered sets $\\{x_1, \\ldots, x_n\\}$ and $\\{y_1, \\ldots,\ny_n\\}$. In this work, we leverage tools from optimal transport theory to derive\nminimax rates under weak moments conditions on $y_i$ and to give an efficient\nalgorithm achieving optimal rates. Both upper and lower bounds employ\nmoment-matching arguments that are also pertinent to learning mixtures of\ndistributions and deconvolution.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2018 19:10:56 GMT"}, {"version": "v2", "created": "Sun, 24 Mar 2019 11:29:07 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Rigollet", "Philippe", ""], ["Weed", "Jonathan", ""]]}, {"id": "1806.10661", "submitter": "Peter Orbanz", "authors": "Morgane Austern and Peter Orbanz", "title": "Limit theorems for invariant distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider random processes whose distribution satisfies a symmetry\nproperty. Examples of such properties include exchangeability, stationarity,\nand various others. We show that, under a suitable mixing condition, estimates\ncomputed as ergodic averages of such processes satisfy a central limit theorem,\na Berry-Esseen bound, and a concentration inequality. These are generalized\nfurther to triangular arrays, to a class of generalized U-statistics, and to a\nform of random censoring. As applications, we obtain new results on\nexchangeability, and on estimation in random fields and certain network models;\nextend results on graphon models to stochastic block models with a growing\nnumber of classes; give a simpler proof of a recent central limit theorem for\nmarked point processes; and establish asymptotic normality of the empirical\nentropy of a large class of processes. In certain special cases, we recover\nwell-known properties, which can hence be interpreted as a direct consequence\nof symmetry. The proofs adapt Stein's method.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2018 20:02:11 GMT"}], "update_date": "2018-06-29", "authors_parsed": [["Austern", "Morgane", ""], ["Orbanz", "Peter", ""]]}, {"id": "1806.10760", "submitter": "Yao Xie", "authors": "Liyan Xie, George V. Moustakides, Yao Xie", "title": "First-order optimal sequential subspace change-point detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the sequential change-point detection problem of detecting\nchanges that are characterized by a subspace structure. Such changes are\nfrequent in high-dimensional streaming data altering the form of the\ncorresponding covariance matrix. In this work we present a Subspace-CUSUM\nprocedure and demonstrate its first-order asymptotic optimality properties for\nthe case where the subspace structure is unknown and needs to be simultaneously\nestimated. To achieve this goal we develop a suitable analytical methodology\nthat includes a proper parameter optimization for the proposed detection\nscheme. Numerical simulations corroborate our theoretical findings.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jun 2018 04:03:07 GMT"}], "update_date": "2018-06-29", "authors_parsed": [["Xie", "Liyan", ""], ["Moustakides", "George V.", ""], ["Xie", "Yao", ""]]}, {"id": "1806.10816", "submitter": "Jean-Michel Loubes", "authors": "Jean-Michel Loubes (IMT), M Andrea Arias-Serna, Francisco Caro-Lopera", "title": "Risk Measures and Credit Risk Under the Beta-Kotz Distribution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the use for Value-at-Risk computations of the so-called\nBeta-Kotz distribution based on a general family of distributions including the\nclassical Gaussian model. Actually, this work develops a new method for\nestimating the Value-at-Risk, the Conditional Value-at-Risk and the Economic\nCapital when the underlying risk factors follow a Beta-Kotz distribution. After\nestimating the parameters of the distribution of the loss random variable, both\nanalytical for some particular values of the parameters and numerical\napproaches are provided for computing these mentioned measures. The proposed\nrisk measures are finally applied for quantifying the potential risk of\neconomic losses in Credit Risk.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jun 2018 08:14:31 GMT"}], "update_date": "2018-06-29", "authors_parsed": [["Loubes", "Jean-Michel", "", "IMT"], ["Arias-Serna", "M Andrea", ""], ["Caro-Lopera", "Francisco", ""]]}, {"id": "1806.10867", "submitter": "Julyan Arbel", "authors": "Julyan Arbel, Pierpaolo De Blasi, Igor Pruenster", "title": "Stochastic approximations to the Pitman-Yor process", "comments": "19 pages", "journal-ref": "Bayesian Analysis, 14(3):753--771, 2019", "doi": "10.1214/18-BA1127", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider approximations to the popular Pitman-Yor process\nobtained by truncating the stick-breaking representation. The truncation is\ndetermined by a random stopping rule that achieves an almost sure control on\nthe approximation error in total variation distance. We derive the asymptotic\ndistribution of the random truncation point as the approximation error epsilon\ngoes to zero in terms of a polynomially tilted positive stable distribution.\nThe practical usefulness and effectiveness of this theoretical result is\ndemonstrated by devising a sampling algorithm to approximate functionals of the\nepsilon-version of the Pitman-Yor process.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jun 2018 10:26:57 GMT"}, {"version": "v2", "created": "Wed, 10 Oct 2018 15:22:00 GMT"}, {"version": "v3", "created": "Sat, 13 Jul 2019 15:05:37 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Arbel", "Julyan", ""], ["De Blasi", "Pierpaolo", ""], ["Pruenster", "Igor", ""]]}, {"id": "1806.11178", "submitter": "Giuseppe Sanfilippo", "authors": "Frank Lad and Giuseppe Sanfilippo", "title": "Scoring Alternative Forecast Distributions: Completing the Kullback\n  Distance Complex", "comments": null, "journal-ref": "Global and Local Economic Review, vol. 22, no. 02, pp. 63-90, 2018", "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop two surprising new results regarding the use of proper scoring\nrules for evaluating the predictive quality of two alternative sequential\nforecast distributions. Both of the proponents prefer to be awarded a score\nderived from the other's distribution rather than a score awarded on the basis\nof their own. A Pareto optimal exchange of their scoring outcomes provides the\nbasis for a comparison of forecast quality that is preferred by both\nforecasters, and also evades a feature of arbitrariness inherent in using the\nforecasters' own achieved scores. The well-known Kullback divergence, used as a\nmeasure of information, is evaluated via the entropies in the two forecast\ndistributions and the two cross-entropies between them. We show that Kullback's\nsymmetric measure needs to be appended by three component measures if it is to\ncharacterise completely the information content of the two asserted probability\nforecasts. Two of these do not involve entropies at all. The resulting\n'Kullback complex' supported by the 4-dimensional measure is isomorphic to an\nequivalent vector measure generated by the forecasters' expectations of their\nscores, each for one's own score and for the other's score. We foreshadow the\nresults of a sophisticated application of the Pareto relative scoring procedure\nfor actual sequentional observations, and we propose a standard format for\nevaluation.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jun 2018 20:42:59 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Lad", "Frank", ""], ["Sanfilippo", "Giuseppe", ""]]}, {"id": "1806.11194", "submitter": "Abbas Kazemipour", "authors": "Abbas Kazemipour", "title": "Compressed Sensing Beyond the IID and Static Domains: Theory, Algorithms\n  and Applications", "comments": "PhD Dissertation, University of Maryland", "journal-ref": null, "doi": "10.13016/M22Z5T", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparsity is a ubiquitous feature of many real world signals such as natural\nimages and neural spiking activities. Conventional compressed sensing utilizes\nsparsity to recover low dimensional signal structures in high ambient\ndimensions using few measurements, where i.i.d measurements are at disposal.\nHowever real world scenarios typically exhibit non i.i.d and dynamic structures\nand are confined by physical constraints, preventing applicability of the\ntheoretical guarantees of compressed sensing and limiting its applications. In\nthis thesis we develop new theory, algorithms and applications for non i.i.d\nand dynamic compressed sensing by considering such constraints. In the first\npart of this thesis we derive new optimal sampling-complexity tradeoffs for two\ncommonly used processes used to model dependent temporal structures: the\nautoregressive processes and self-exciting generalized linear models. Our\ntheoretical results successfully recovered the temporal dependencies in neural\nactivities, financial data and traffic data. Next, we develop a new framework\nfor studying temporal dynamics by introducing compressible state-space models,\nwhich simultaneously utilize spatial and temporal sparsity. We develop a fast\nalgorithm for optimal inference on such models and prove its optimal recovery\nguarantees. Our algorithm shows significant improvement in detecting sparse\nevents in biological applications such as spindle detection and calcium\ndeconvolution. Finally, we develop a sparse Poisson image reconstruction\ntechnique and the first compressive two-photon microscope which uses lines of\nexcitation across the sample at multiple angles. We recovered\ndiffraction-limited images from relatively few incoherently multiplexed\nmeasurements, at a rate of 1.5 billion voxels per second.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jun 2018 21:12:13 GMT"}], "update_date": "2018-07-02", "authors_parsed": [["Kazemipour", "Abbas", ""]]}, {"id": "1806.11466", "submitter": "Alexandre Belloni", "authors": "Alexandre Belloni, Federico Bugni and Victor Chernozhukov", "title": "Subvector Inference in Partially Identified Models with Many Moment\n  Inequalities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST econ.EM stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers inference for a function of a parameter vector in a\npartially identified model with many moment inequalities. This framework allows\nthe number of moment conditions to grow with the sample size, possibly at\nexponential rates. Our main motivating application is subvector inference,\ni.e., inference on a single component of the partially identified parameter\nvector associated with a treatment effect or a policy variable of interest.\n  Our inference method compares a MinMax test statistic (minimum over\nparameters satisfying $H_0$ and maximum over moment inequalities) against\ncritical values that are based on bootstrap approximations or analytical\nbounds. We show that this method controls asymptotic size uniformly over a\nlarge class of data generating processes despite the partially identified many\nmoment inequality setting. The finite sample analysis allows us to obtain\nexplicit rates of convergence on the size control. Our results are based on\ncombining non-asymptotic approximations and new high-dimensional central limit\ntheorems for the MinMax of the components of random matrices. Unlike the\nprevious literature on functional inference in partially identified models, our\nresults do not rely on weak convergence results based on Donsker's class\nassumptions and, in fact, our test statistic may not even converge in\ndistribution. Our bootstrap approximation requires the choice of a tuning\nparameter sequence that can avoid the excessive concentration of our test\nstatistic. To this end, we propose an asymptotically valid data-driven method\nto select this tuning parameter sequence. This method generalizes the selection\nof tuning parameter sequences to problems outside the Donsker's class\nassumptions and may also be of independent interest. Our procedures based on\nself-normalized moderate deviation bounds are relatively more conservative but\neasier to implement.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jun 2018 15:15:26 GMT"}], "update_date": "2018-07-02", "authors_parsed": [["Belloni", "Alexandre", ""], ["Bugni", "Federico", ""], ["Chernozhukov", "Victor", ""]]}]