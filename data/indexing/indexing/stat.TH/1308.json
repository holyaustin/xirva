[{"id": "1308.0346", "submitter": "Ery Arias-Castro", "authors": "Ery Arias-Castro and Meng Wang", "title": "Distribution-Free Tests for Sparse Heterogeneous Mixtures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of detecting sparse heterogeneous mixtures from a\nnonparametric perspective, and develop distribution-free tests when all effects\nhave the same sign. Specifically, we assume that the null distribution is\nsymmetric about zero, while the true effects have positive median. We evaluate\nthe precise performance of classical tests for the median (t-test, sign test)\nand classical tests for symmetry (signed-rank, Smirnov, total number of runs,\nlongest run tests) showing that none of them is asymptotically optimal for the\nnormal mixture model in all sparsity regimes. We then suggest two new tests.\nThe main one is a form of Higher Criticism, or Anderson-Darling, test for\nsymmetry. It is shown to be asymptotically optimal for the normal mixture\nmodel, and other generalized Gaussian mixture models, in all sparsity regimes.\nOur numerical experiments confirm our theoretical findings.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2013 20:31:46 GMT"}, {"version": "v2", "created": "Fri, 15 Nov 2013 18:20:33 GMT"}], "update_date": "2013-11-18", "authors_parsed": [["Arias-Castro", "Ery", ""], ["Wang", "Meng", ""]]}, {"id": "1308.0417", "submitter": "C\\'ecile Durot", "authors": "C\\'ecile Durot and Hendrik P. Lopuha\\\"a", "title": "A Kiefer-Wolfowitz type of result in a general setting, with an\n  application to smooth monotone estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider Grenander type estimators for monotone functions $f$ in a very\ngeneral setting, which includes estimation of monotone regression curves,\nmonotone densities, and monotone failure rates. These estimators are defined as\nthe left-hand slope of the least concave majorant $\\hat{F}_n$ of a naive\nestimator $F_n$ of the integrated curve $F$ corresponding to $f$. We prove that\nthe supremum distance between $\\hat{F}_n$ and $F_n$ is of the order\n$O_p(n^{-1}\\log n)^{2/(4-\\tau)}$, for some $\\tau\\in[0,4)$ that characterizes\nthe tail probabilities of an approximating process for $F_n$. In typical\nexamples, the approximating process is Gaussian and $\\tau=1$, in which case the\nconvergence rate is $n^{-2/3}(\\log n)^{2/3}$ is in the same spirit as the one\nobtained by Kiefer and Wolfowitz (1976) for the special case of estimating a\ndecreasing density. We also obtain a similar result for the primitive of $F_n$,\nin which case $\\tau=2$, leading to a faster rate $n^{-1}\\log n$, also found by\nWang and Woodfroofe (2007). As an application in our general setup, we show\nthat a smoothed Grenander type estimator and its derivative are asymptotically\nequivalent to the ordinary kernel estimator and its derivative in first order.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2013 07:01:06 GMT"}, {"version": "v2", "created": "Wed, 8 Oct 2014 13:46:52 GMT"}], "update_date": "2014-10-09", "authors_parsed": [["Durot", "C\u00e9cile", ""], ["Lopuha\u00e4", "Hendrik P.", ""]]}, {"id": "1308.0447", "submitter": "Valentin Amrhein", "authors": "Valentin Amrhein, Tobias Roth, Fraenzi Korner-Nievergelt", "title": "Comment on \"Bayes' Theorem in the 21st Century\" by Bradley Efron", "comments": "3 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a Perspectives article in Science, Bradley Efron concludes that Bayesian\ncalculations cannot be uncritically accepted when using uninformative priors.\nWe argue that this conclusion is problematic because Efron's example does not\nuse data, hence it is not Bayesian statistics; his priors make little sense and\nare not uninformative; and using the available data point and an uninformative\nprior actually leads to a reasonable posterior distribution.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2013 09:41:22 GMT"}], "update_date": "2013-08-05", "authors_parsed": [["Amrhein", "Valentin", ""], ["Roth", "Tobias", ""], ["Korner-Nievergelt", "Fraenzi", ""]]}, {"id": "1308.0641", "submitter": "Subhadeep Mukhopadhyay", "authors": "Emanuel Parzen, Subhadeep Mukhopadhyay", "title": "United Statistical Algorithm, Small and Big Data: Future OF Statistician", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article provides the role of big idea statisticians in future of Big\nData Science. We describe the `United Statistical Algorithms' framework for\ncomprehensive unification of traditional and novel statistical methods for\nmodeling Small Data and Big Data, especially mixed data (discrete, continuous).\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2013 23:54:44 GMT"}], "update_date": "2016-11-26", "authors_parsed": [["Parzen", "Emanuel", ""], ["Mukhopadhyay", "Subhadeep", ""]]}, {"id": "1308.0642", "submitter": "Subhadeep Mukhopadhyay", "authors": "Subhadeep Mukhopadhyay and Emanuel Parzen", "title": "Nonlinear Time Series Modeling: A Unified Perspective, Algorithm, and\n  Application", "comments": "Major restructuring has been done", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.AP stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new comprehensive approach to nonlinear time series analysis and modeling\nis developed in the present paper. We introduce novel data-specific\nmid-distribution based Legendre Polynomial (LP) like nonlinear transformations\nof the original time series Y(t) that enables us to adapt all the existing\nstationary linear Gaussian time series modeling strategy and made it applicable\nfor non-Gaussian and nonlinear processes in a robust fashion. The emphasis of\nthe present paper is on empirical time series modeling via the algorithm\nLPTime. We demonstrate the effectiveness of our theoretical framework using\ndaily S&P 500 return data between Jan/2/1963 - Dec/31/2009. Our proposed LPTime\nalgorithm systematically discovers all the `stylized facts' of the financial\ntime series automatically all at once, which were previously noted by many\nresearchers one at a time.\n", "versions": [{"version": "v1", "created": "Sat, 3 Aug 2013 00:04:00 GMT"}, {"version": "v2", "created": "Tue, 3 Sep 2013 18:59:35 GMT"}, {"version": "v3", "created": "Wed, 26 Apr 2017 23:03:40 GMT"}, {"version": "v4", "created": "Sun, 24 Dec 2017 01:40:19 GMT"}], "update_date": "2017-12-27", "authors_parsed": [["Mukhopadhyay", "Subhadeep", ""], ["Parzen", "Emanuel", ""]]}, {"id": "1308.0764", "submitter": "Rajarshi Mukherjee", "authors": "Rajarshi Mukherjee, Natesh S. Pillai, Xihong Lin", "title": "Hypothesis testing for high-dimensional sparse binary regression", "comments": "Published in at http://dx.doi.org/10.1214/14-AOS1279 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2015, Vol. 43, No. 1, 352-381", "doi": "10.1214/14-AOS1279", "report-no": "IMS-AOS-AOS1279", "categories": "math.ST stat.CO stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the detection boundary for minimax hypothesis testing\nin the context of high-dimensional, sparse binary regression models. Motivated\nby genetic sequencing association studies for rare variant effects, we\ninvestigate the complexity of the hypothesis testing problem when the design\nmatrix is sparse. We observe a new phenomenon in the behavior of detection\nboundary which does not occur in the case of Gaussian linear regression. We\nderive the detection boundary as a function of two components: a design matrix\nsparsity index and signal strength, each of which is a function of the sparsity\nof the alternative. For any alternative, if the design matrix sparsity index is\ntoo high, any test is asymptotically powerless irrespective of the magnitude of\nsignal strength. For binary design matrices with the sparsity index that is not\ntoo high, our results are parallel to those in the Gaussian case. In this\ncontext, we derive detection boundaries for both dense and sparse regimes. For\nthe dense regime, we show that the generalized likelihood ratio is rate\noptimal; for the sparse regime, we propose an extended Higher Criticism Test\nand show it is rate optimal and sharp. We illustrate the finite sample\nproperties of the theoretical results using simulation studies.\n", "versions": [{"version": "v1", "created": "Sun, 4 Aug 2013 01:06:15 GMT"}, {"version": "v2", "created": "Mon, 28 Jul 2014 02:42:31 GMT"}, {"version": "v3", "created": "Thu, 5 Mar 2015 10:30:23 GMT"}], "update_date": "2015-03-06", "authors_parsed": [["Mukherjee", "Rajarshi", ""], ["Pillai", "Natesh S.", ""], ["Lin", "Xihong", ""]]}, {"id": "1308.0810", "submitter": "Daniel McDonald", "authors": "Darren Homrighausen and Daniel J. McDonald", "title": "Risk-consistency of cross-validation with lasso-type procedures", "comments": "25 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The lasso and related sparsity inducing algorithms have been the target of\nsubstantial theoretical and applied research. Correspondingly, many results are\nknown about their behavior for a fixed or optimally chosen tuning parameter\nspecified up to unknown constants. In practice, however, this oracle tuning\nparameter is inaccessible so one must use the data to select one. Common\nstatistical practice is to use a variant of cross-validation for this task.\nHowever, little is known about the theoretical properties of the resulting\npredictions with such data-dependent methods. We consider the high-dimensional\nsetting with random design wherein the number of predictors $p$ grows with the\nnumber of observations $n$. Under typical assumptions on the data generating\nprocess, similar to those in the literature, we recover oracle rates up to a\nlog factor when choosing the tuning parameter with cross-validation. Under\nweaker conditions, when the true model is not necessarily linear, we show that\nthe lasso remains risk consistent relative to its linear oracle. We also\ngeneralize these results to the group lasso and square-root lasso and\ninvestigate the predictive and model selection performance of cross-validation\nvia simulation.\n", "versions": [{"version": "v1", "created": "Sun, 4 Aug 2013 13:51:29 GMT"}, {"version": "v2", "created": "Mon, 12 Jan 2015 21:48:15 GMT"}, {"version": "v3", "created": "Tue, 21 Jun 2016 22:43:11 GMT"}], "update_date": "2016-06-23", "authors_parsed": [["Homrighausen", "Darren", ""], ["McDonald", "Daniel J.", ""]]}, {"id": "1308.0931", "submitter": "Nestor Parolya Dr.", "authors": "Taras Bodnar, Arjun K. Gupta and Nestor Parolya", "title": "Optimal Linear Shrinkage Estimator for Large Dimensional Precision\n  Matrix", "comments": "26 pages, 5 figures. This version includes the case c>1 with the\n  generalized inverse of the sample covariance matrix. The abstract was updated\n  accordingly", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR q-fin.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we construct an optimal shrinkage estimator for the precision\nmatrix in high dimensions. We consider the general asymptotics when the number\nof variables $p\\rightarrow\\infty$ and the sample size $n\\rightarrow\\infty$ so\nthat $p/n\\rightarrow c\\in (0, +\\infty)$. The precision matrix is estimated\ndirectly, without inverting the corresponding estimator for the covariance\nmatrix. The recent results from the random matrix theory allow us to find the\nasymptotic deterministic equivalents of the optimal shrinkage intensities and\nestimate them consistently. The resulting distribution-free estimator has\nalmost surely the minimum Frobenius loss. Additionally, we prove that the\nFrobenius norms of the inverse and of the pseudo-inverse sample covariance\nmatrices tend almost surely to deterministic quantities and estimate them\nconsistently. At the end, a simulation is provided where the suggested\nestimator is compared with the estimators for the precision matrix proposed in\nthe literature. The optimal shrinkage estimator shows significant improvement\nand robustness even for non-normally distributed data.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2013 10:38:13 GMT"}, {"version": "v2", "created": "Sun, 23 Mar 2014 15:40:24 GMT"}, {"version": "v3", "created": "Tue, 25 Mar 2014 12:21:06 GMT"}], "update_date": "2014-07-01", "authors_parsed": [["Bodnar", "Taras", ""], ["Gupta", "Arjun K.", ""], ["Parolya", "Nestor", ""]]}, {"id": "1308.1147", "submitter": "Alexander Rakhlin", "authors": "Alexander Rakhlin, Karthik Sridharan, Alexandre B. Tsybakov", "title": "Empirical entropy, minimax regret and minimax risk", "comments": "Published at http://dx.doi.org/10.3150/14-BEJ679 in the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2017, Vol. 23, No. 2, 789-824", "doi": "10.3150/14-BEJ679", "report-no": "IMS-BEJ-BEJ679", "categories": "math.ST cs.LG stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the random design regression model with square loss. We propose a\nmethod that aggregates empirical minimizers (ERM) over appropriately chosen\nrandom subsets and reduces to ERM in the extreme case, and we establish sharp\noracle inequalities for its risk. We show that, under the $\\varepsilon^{-p}$\ngrowth of the empirical $\\varepsilon$-entropy, the excess risk of the proposed\nmethod attains the rate $n^{-2/(2+p)}$ for $p\\in(0,2)$ and $n^{-1/p}$ for $p>2$\nwhere $n$ is the sample size. Furthermore, for $p\\in(0,2)$, the excess risk\nrate matches the behavior of the minimax risk of function estimation in\nregression problems under the well-specified model. This yields a conclusion\nthat the rates of statistical estimation in well-specified models (minimax\nrisk) and in misspecified models (minimax regret) are equivalent in the regime\n$p\\in(0,2)$. In other words, for $p\\in(0,2)$ the problem of statistical\nlearning enjoys the same minimax rate as the problem of statistical estimation.\nOn the contrary, for $p>2$ we show that the rates of the minimax regret are, in\ngeneral, slower than for the minimax risk. Our oracle inequalities also imply\nthe $v\\log(n/v)/n$ rates for Vapnik-Chervonenkis type classes of dimension $v$\nwithout the usual convexity assumption on the class; we show that these rates\nare optimal. Finally, for a slightly modified method, we derive a bound on the\nexcess risk of $s$-sparse convex aggregation improving that of Lounici [Math.\nMethods Statist. 16 (2007) 246-259] and providing the optimal rate.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2013 01:05:52 GMT"}, {"version": "v2", "created": "Fri, 30 Jun 2017 13:21:04 GMT"}, {"version": "v3", "created": "Mon, 3 Jul 2017 13:29:39 GMT"}], "update_date": "2017-07-04", "authors_parsed": [["Rakhlin", "Alexander", ""], ["Sridharan", "Karthik", ""], ["Tsybakov", "Alexandre B.", ""]]}, {"id": "1308.1195", "submitter": "Justin Wishart", "authors": "Rafal Kulik, Theofanis Sapatinas, Justin Rory Wishart", "title": "Multichannel Deconvolution with Long Range Dependence: Upper bounds on\n  the $L^p$-risk $(1 \\le p < \\infty)$", "comments": null, "journal-ref": null, "doi": "10.1016/j.acha.2014.04.004", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider multichannel deconvolution in a periodic setting with long-memory\nerrors under three different scenarios for the convolution operators, i.e.,\nsuper-smooth, regular-smooth and box-car convolutions. We investigate global\nperformances of linear and hard-thresholded non-linear wavelet estimators for\nfunctions over a wide range of Besov spaces and for a variety of loss functions\ndefining the risk. In particular, we obtain upper bounds on convergence rates\nusing the $L^p$-risk $(1 \\le p < \\infty)$. Contrary to the case where the\nerrors follow independent Brownian motions, it is demonstrated that\nmultichannel deconvolution with errors that follow independent fractional\nBrownian motions with different Hurst parameters results in a much more\ninvolved situation. An extensive finite-sample numerical study is performed to\nsupplement the theoretical findings.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2013 07:09:36 GMT"}, {"version": "v2", "created": "Tue, 6 May 2014 02:39:25 GMT"}], "update_date": "2014-05-07", "authors_parsed": [["Kulik", "Rafal", ""], ["Sapatinas", "Theofanis", ""], ["Wishart", "Justin Rory", ""]]}, {"id": "1308.1211", "submitter": "Mate Manfay", "authors": "Laszlo Gerencser and Mate Manfay", "title": "Identification of Finite Dimensional Linear Systems Driven by Levy\n  processes", "comments": "arXiv admin note: text overlap with arXiv:1302.5221", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Levy processes are widely used in financial mathematics, telecommunication,\neconomics, queueing theory and natural sciences for modelling. A typical model\nis obtained by considering finite dimensional linear stochastic SISO systems\ndriven by a Levy process. In this paper we consider a discrete-time version of\nthis model driven by the increments of a Levy process, such a system will be\ncalled Levy system. We focus on the problem of identifying the dynamics and the\nnoise characteristics of such a Levy system. The special feature of this\nproblem is that the statistical description of the noise is given by the\ncharacteristic function (c.f.) of the driving noise not by its density\nfunction. As an alternative to the maximum likelihood (ML) method we develop\nand analyze a novel identification method by adapting the so-called empirical\ncharacteristic function method (ECF) originally devised for estimating\nparameters of c.f.-s from i.i.d. samples. Precise characterization of the\nerrors of these estimators will be given, and their asymptotic covariance\nmatrices will be obtained. We also demonstrate that the arguments implying\nasymptotic efficiency for the i.i.d. case can be adapted for the present case.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2013 09:19:26 GMT"}, {"version": "v2", "created": "Mon, 6 Jan 2014 13:10:44 GMT"}], "update_date": "2014-01-07", "authors_parsed": [["Gerencser", "Laszlo", ""], ["Manfay", "Mate", ""]]}, {"id": "1308.1263", "submitter": "Bas Kleijn", "authors": "B. J. K. Kleijn, Y. Y. Zhao", "title": "Criteria for posterior consistency", "comments": "39 pages, no figures; successive revisions incorporate referees'\n  suggestions", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Frequentist conditions for asymptotic suitability of Bayesian procedures\nfocus on lower bounds for prior mass in Kullback-Leibler neighbourhoods of the\ndata distribution. The goal of this paper is to investigate the flexibility in\ncriteria for posterior consistency with i.i.d. data. We formulate a versatile\nposterior consistency theorem that applies both to well- and mis-specified\nmodels and which we use to re-derive Schwartz's theorem, consider\nKullback-Leibler consistency and formulate consistency theorems in which priors\ncharge metric balls. It is generalized to sieved models with Barron's\nnegligible prior mass condition and to separable models with variations on\nWalker's consistency theorem. Results also apply to marginal semi-parametric\nconsistency: support boundary estimation is considered explicitly and\nconsistency is proved in a model for which Kullback-Leibler priors do not\nexist. Other examples include consistent density estimation in mixture models\nwith Dirichlet or Gibbs-type priors of full weak support. Regarding posterior\nconvergence at a rate, it is shown that under a mild integrability condition,\nthe second-order Ghosal-Ghosh-van der Vaart prior mass condition can be relaxed\nto a lower bound to the prior mass in Schwartz's Kullback-Leibler\nneighbourhoods. The posterior rate of convergence is derived in a simple,\nparametric model for heavy-tailed distributions in which the Ghosal-Ghosh-van\nder Vaart condition cannot be satisfied by any prior.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2013 13:09:49 GMT"}, {"version": "v2", "created": "Wed, 22 Jul 2015 15:14:19 GMT"}, {"version": "v3", "created": "Fri, 13 May 2016 13:35:26 GMT"}, {"version": "v4", "created": "Thu, 11 May 2017 11:01:34 GMT"}, {"version": "v5", "created": "Fri, 16 Mar 2018 11:24:40 GMT"}], "update_date": "2018-03-19", "authors_parsed": [["Kleijn", "B. J. K.", ""], ["Zhao", "Y. Y.", ""]]}, {"id": "1308.1269", "submitter": "Rajen Shah", "authors": "Rajen D. Shah and Nicolai Meinshausen", "title": "On b-bit min-wise hashing for large-scale regression and classification\n  with sparse data", "comments": "40 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale regression problems where both the number of variables, $p$, and\nthe number of observations, $n$, may be large and in the order of millions or\nmore, are becoming increasingly more common. Typically the data are sparse:\nonly a fraction of a percent of the entries in the design matrix are non-zero.\nNevertheless, often the only computationally feasible approach is to perform\ndimension reduction to obtain a new design matrix with far fewer columns and\nthen work with this compressed data.\n  $b$-bit min-wise hashing (Li and Konig, 2011) is a promising dimension\nreduction scheme for sparse matrices which produces a set of random features\nsuch that regression on the resulting design matrix approximates a kernel\nregression with the resemblance kernel. In this work, we derive bounds on the\nprediction error of such regressions. For both linear and logistic models we\nshow that the average prediction error vanishes asymptotically as long as $q\n\\|\\beta^*\\|_2^2 /n \\rightarrow 0$, where $q$ is the average number of non-zero\nentries in each row of the design matrix and $\\beta^*$ is the coefficient of\nthe linear predictor.\n  We also show that ordinary least squares or ridge regression applied to the\nreduced data can in fact allow us fit more flexible models. We obtain\nnon-asymptotic prediction error bounds for interaction models and for models\nwhere an unknown row normalisation must be applied in order for the signal to\nbe linear in the predictors.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2013 13:42:24 GMT"}, {"version": "v2", "created": "Thu, 7 May 2015 17:28:02 GMT"}, {"version": "v3", "created": "Sat, 30 Apr 2016 07:34:37 GMT"}, {"version": "v4", "created": "Mon, 26 Feb 2018 17:26:13 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Shah", "Rajen D.", ""], ["Meinshausen", "Nicolai", ""]]}, {"id": "1308.1334", "submitter": "Stanislav Minsker", "authors": "Stanislav Minsker", "title": "Geometric median and robust estimation in Banach spaces", "comments": "Published at http://dx.doi.org/10.3150/14-BEJ645 in the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2015, Vol. 21, No. 4, 2308-2335", "doi": "10.3150/14-BEJ645", "report-no": "IMS-BEJ-BEJ645", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many real-world applications, collected data are contaminated by noise\nwith heavy-tailed distribution and might contain outliers of large magnitude.\nIn this situation, it is necessary to apply methods which produce reliable\noutcomes even if the input contains corrupted measurements. We describe a\ngeneral method which allows one to obtain estimators with tight concentration\naround the true parameter of interest taking values in a Banach space.\nSuggested construction relies on the fact that the geometric median of a\ncollection of independent \"weakly concentrated\" estimators satisfies a much\nstronger deviation bound than each individual element in the collection. Our\napproach is illustrated through several examples, including sparse linear\nregression and low-rank matrix recovery problems.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2013 16:29:20 GMT"}, {"version": "v2", "created": "Mon, 19 Aug 2013 17:03:05 GMT"}, {"version": "v3", "created": "Wed, 2 Oct 2013 14:44:34 GMT"}, {"version": "v4", "created": "Wed, 20 Nov 2013 16:40:24 GMT"}, {"version": "v5", "created": "Mon, 1 Sep 2014 03:18:13 GMT"}, {"version": "v6", "created": "Tue, 29 Sep 2015 08:07:36 GMT"}], "update_date": "2015-09-30", "authors_parsed": [["Minsker", "Stanislav", ""]]}, {"id": "1308.1359", "submitter": "David Ginsbourger", "authors": "David Ginsbourger (IMSV), Olivier Roustant (- M\\'ethodes d'Analyse\n  Stochastique des Codes et Traitements Num\\'eriques, DEMO-ENSMSE), Nicolas\n  Durrande", "title": "Invariances of random fields paths, with applications in Gaussian\n  Process Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study pathwise invariances of centred random fields that can be controlled\nthrough the covariance. A result involving composition operators is obtained in\nsecond-order settings, and we show that various path properties including\nadditivity boil down to invariances of the covariance kernel. These results are\nextended to a broader class of operators in the Gaussian case, via the Lo\\`eve\nisometry. Several covariance-driven pathwise invariances are illustrated,\nincluding fields with symmetric paths, centred paths, harmonic paths, or sparse\npaths. The proposed approach delivers a number of promising results and\nperspectives in Gaussian process regression.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2013 17:56:52 GMT"}], "update_date": "2013-08-07", "authors_parsed": [["Ginsbourger", "David", "", "IMSV"], ["Roustant", "Olivier", "", "- M\u00e9thodes d'Analyse\n  Stochastique des Codes et Traitements Num\u00e9riques, DEMO-ENSMSE"], ["Durrande", "Nicolas", ""]]}, {"id": "1308.1766", "submitter": "Lili Wang", "authors": "Lili Wang and Debashis Paul", "title": "Limiting spectral distribution of renormalized separable sample\n  covariance matrices when $p/n\\to 0$", "comments": "42 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are concerned with the behavior of the eigenvalues of renormalized sample\ncovariance matrices of the form\nC_n=\\sqrt{\\frac{n}{p}}\\left(\\frac{1}{n}A_{p}^{1/2}X_{n}B_{n}X_{n}^{*}A_{p}^{1/2}-\\frac{1}{n}\\tr(B_{n})A_{p}\\right)\nas $p,n\\to \\infty$ and $p/n\\to 0$, where $X_{n}$ is a $p\\times n$ matrix with\ni.i.d. real or complex valued entries $X_{ij}$ satisfying $E(X_{ij})=0$,\n$E|X_{ij}|^2=1$ and having finite fourth moment. $A_{p}^{1/2}$ is a square-root\nof the nonnegative definite Hermitian matrix $A_{p}$, and $B_{n}$ is an\n$n\\times n$ nonnegative definite Hermitian matrix. We show that the empirical\nspectral distribution (ESD) of $C_n$ converges a.s. to a nonrandom limiting\ndistribution under some assumptions. The probability density function of the\nLSD of $C_{n}$ is derived and it is shown that it depends on the LSD of $A_{p}$\nand the limiting value of $n^{-1}\\tr(B_{n}^2)$. We propose a computational\nalgorithm for evaluating this limiting density when the LSD of $A_{p}$ is a\nmixture of point masses. In addition, when the entries of $X_{n}$ are\nsub-Gaussian, we derive the limiting empirical distribution of\n$\\{\\sqrt{n/p}(\\lambda_j(S_n) - n^{-1}\\tr(B_n) \\lambda_j(A_{p}))\\}_{j=1}^p$\nwhere $S_n := n^{-1} A_{p}^{1/2}X_{n}B_{n}X_{n}^{*}A_{p}^{1/2}$ is the sample\ncovariance matrix and $\\lambda_j$ denotes the $j$-th largest eigenvalue, when\n$F^A$ is a finite mixture of point masses. These results are utilized to\npropose a test for the covariance structure of the data where the null\nhypothesis is that the joint covariance matrix is of the form $A_{p} \\otimes\nB_n$ for $\\otimes$ denoting the Kronecker product, as well as $A_{p}$ and the\nfirst two spectral moments of $B_n$ are specified. The performance of this test\nis illustrated through a simulation study.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2013 06:33:05 GMT"}, {"version": "v2", "created": "Sun, 17 Nov 2013 20:15:57 GMT"}], "update_date": "2013-11-19", "authors_parsed": [["Wang", "Lili", ""], ["Paul", "Debashis", ""]]}, {"id": "1308.1768", "submitter": "Ting Yan", "authors": "Ting Yan, Yunpeng Zhao, Hong Qin", "title": "Asymptotic normality in the maximum entropy models on graphs with an\n  increasing number of parameters", "comments": "Minor revision. Submitted for publication", "journal-ref": "Journal of Multivariate Analysis. 2015, Volume 133, 61-76", "doi": "10.1016/j.jmva.2014.08.013", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Maximum entropy models, motivated by applications in neuron science, are\nnatural generalizations of the $\\beta$-model to weighted graphs. Similar to the\n$\\beta$-model, each vertex in maximum entropy models is assigned a potential\nparameter, and the degree sequence is the natural sufficient statistic. Hillar\nand Wibisono (2013) has proved the consistency of the maximum likelihood\nestimators. In this paper, we further establish the asymptotic normality for\nany finite number of the maximum likelihood estimators in the maximum entropy\nmodels with three types of edge weights, when the total number of parameters\ngoes to infinity. Simulation studies are provided to illustrate the asymptotic\nresults.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2013 06:46:09 GMT"}, {"version": "v2", "created": "Sun, 23 Mar 2014 01:53:35 GMT"}, {"version": "v3", "created": "Fri, 8 Aug 2014 01:04:33 GMT"}], "update_date": "2014-10-28", "authors_parsed": [["Yan", "Ting", ""], ["Zhao", "Yunpeng", ""], ["Qin", "Hong", ""]]}, {"id": "1308.1815", "submitter": "Mohammad Jafari Jozani", "authors": "Mohammad Jafari Jozani, Alexandre Leblanc and Eric Marchand", "title": "On continuous distribution functions, minimax and best invariant\n  estimators, and integrated balanced loss functions", "comments": "22pages, 3 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of estimating a continuous distribution function $F$,\nas well as meaningful functions $\\tau(F)$ under a large class of loss\nfunctions. We obtain best invariant estimators and establish their minimaxity\nfor H\\\"{o}lder continuous $\\tau$'s and strict bowl-shaped losses with a bounded\nderivative. We also introduce and motivate the use of integrated balanced loss\nfunctions which combine the criteria of an integrated distance between a\ndecision $d$ and $F$, with the proximity of $d$ with a target estimator $d_0$.\nMoreover, we show how the risk analysis of procedures under such an integrated\nbalanced loss relates to a dual risk analysis under an \"unbalanced\" loss, and\nwe derive best invariant estimators, minimax estimators, risk comparisons,\ndominance and inadmissibility results. Finally, we expand on various\nillustrations and applications relative to maxima-nomination sampling,\nmedian-nomination sampling, and a case study related to bilirubin levels in the\nblood of babies suffering from jaundice.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2013 11:10:43 GMT"}], "update_date": "2013-08-09", "authors_parsed": [["Jozani", "Mohammad Jafari", ""], ["Leblanc", "Alexandre", ""], ["Marchand", "Eric", ""]]}, {"id": "1308.1900", "submitter": "Igor Cialenco", "authors": "Igor Cialenco and Liaosha Xu", "title": "Hypothesis testing for stochastic PDEs driven by additive noise", "comments": null, "journal-ref": "Stochastic Processes and their Applications, vol. 125, Issue 3,\n  March 2015, pp. 819-866", "doi": "10.1016/j.spa.2014.09.022", "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the simple hypothesis testing problem for the drift coefficient for\nstochastic fractional heat equation driven by additive noise. We introduce the\nnotion of asymptotically the most powerful test, and find explicit forms of\nsuch tests in two asymptotic regimes: large time asymptotics, and increasing\nnumber of Fourier modes. The proposed statistics are derived based on Maximum\nLikelihood Ratio. Additionally, we obtain a series of important technical\nresults of independent interest: we find the cumulant generating function of\nthe log-likelihood ratio; obtain sharp large deviation type results for\n$T\\to\\infty$ and $N\\to\\infty$.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2013 16:30:07 GMT"}, {"version": "v2", "created": "Thu, 22 May 2014 23:35:39 GMT"}], "update_date": "2014-12-22", "authors_parsed": [["Cialenco", "Igor", ""], ["Xu", "Liaosha", ""]]}, {"id": "1308.2403", "submitter": "Subhadeep Mukhopadhyay", "authors": "Subhadeep Mukhopadhyay", "title": "CDfdr: A Comparison Density Approach to Local False Discovery Rate\n  Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.AP stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efron et al. (2001) proposed empirical Bayes formulation of the frequentist\nBenjamini and Hochbergs False Discovery Rate method (Benjamini and\nHochberg,1995). This article attempts to unify the `two cultures' using\nconcepts of comparison density and distribution function. We have also shown\nhow almost all of the existing local fdr methods can be viewed as proposing\nvarious model specification for comparison density - unifies the vast\nliterature of false discovery methods under one concept and notation.\n", "versions": [{"version": "v1", "created": "Sun, 11 Aug 2013 15:46:36 GMT"}], "update_date": "2013-08-13", "authors_parsed": [["Mukhopadhyay", "Subhadeep", ""]]}, {"id": "1308.2408", "submitter": "Melanie Blazere", "authors": "M\\'elanie Blaz\\`ere (IMT), Jean-Michel Loubes (IMT), Fabrice Gamboa\n  (IMT)", "title": "Group Lasso for generalized linear models in high dimension", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays an increasing amount of data is available and we have to deal with\nmodels in high dimension (number of covariates much larger than the sample\nsize). Under sparsity assumption it is reasonable to hope that we can make a\ngood estimation of the regression parameter. This sparsity assumption as well\nas a block structuration of the covariates into groups with similar modes of\nbehavior is for example quite natural in genomics. A huge amount of scientific\nliterature exists for Gaussian linear models including the Lasso estimator and\nalso the Group Lasso estimator which promotes group sparsity under an a priori\nknowledge of the groups. We extend this Group Lasso procedure to generalized\nlinear models and we study the properties of this estimator for sparse\nhigh-dimensional generalized linear models to find convergence rates. We\nprovide oracle inequalities for the prediction and estimation error under\nassumptions on the covariables and under a condition on the design matrix. We\nshow the ability of this estimator to recover good sparse approximation of the\ntrue model. At last we extend these results to the case of an Elastic net\npenalty and we apply them to the so-called Poisson regression case which has\nnot been studied in this context contrary to the logistic regression.\n", "versions": [{"version": "v1", "created": "Sun, 11 Aug 2013 17:00:11 GMT"}, {"version": "v2", "created": "Mon, 16 Sep 2013 06:16:33 GMT"}, {"version": "v3", "created": "Wed, 22 Jan 2014 13:10:22 GMT"}], "update_date": "2014-01-23", "authors_parsed": [["Blaz\u00e8re", "M\u00e9lanie", "", "IMT"], ["Loubes", "Jean-Michel", "", "IMT"], ["Gamboa", "Fabrice", "", "IMT"]]}, {"id": "1308.2608", "submitter": "Nestor Parolya Jun.-Prof. Dr.", "authors": "Taras Bodnar, Arjun K. Gupta and Nestor Parolya", "title": "On the Strong Convergence of the Optimal Linear Shrinkage Estimator for\n  Large Dimensional Covariance Matrix", "comments": "21 pages, 2 figures. arXiv admin note: text overlap with\n  arXiv:1308.0931, revised version (Journal of Multivariate Analysis)", "journal-ref": "Journal of Multivariate Analysis, Volume 132, 2014, pp. 215-228", "doi": "10.1016/j.jmva.2014.08.006", "report-no": null, "categories": "math.ST math.PR q-fin.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we construct an optimal linear shrinkage estimator for the\ncovariance matrix in high dimensions. The recent results from the random matrix\ntheory allow us to find the asymptotic deterministic equivalents of the optimal\nshrinkage intensities and estimate them consistently. The developed\ndistribution-free estimators obey almost surely the smallest Frobenius loss\nover all linear shrinkage estimators for the covariance matrix. The case we\nconsider includes the number of variables $p\\rightarrow\\infty$ and the sample\nsize $n\\rightarrow\\infty$ so that $p/n\\rightarrow c\\in (0, +\\infty)$.\nAdditionally, we prove that the Frobenius norm of the sample covariance matrix\ntends almost surely to a deterministic quantity which can be consistently\nestimated.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2013 16:11:44 GMT"}, {"version": "v2", "created": "Wed, 25 Jun 2014 09:21:00 GMT"}], "update_date": "2014-10-28", "authors_parsed": [["Bodnar", "Taras", ""], ["Gupta", "Arjun K.", ""], ["Parolya", "Nestor", ""]]}, {"id": "1308.2764", "submitter": "Chenxu Li", "authors": "Chenxu Li", "title": "Maximum-likelihood estimation for diffusion processes via closed-form\n  density expansions", "comments": "Published in at http://dx.doi.org/10.1214/13-AOS1118 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2013, Vol. 41, No. 3, 1350-1380", "doi": "10.1214/13-AOS1118", "report-no": "IMS-AOS-AOS1118", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a widely applicable method of approximate\nmaximum-likelihood estimation for multivariate diffusion process from\ndiscretely sampled data. A closed-form asymptotic expansion for transition\ndensity is proposed and accompanied by an algorithm containing only basic and\nexplicit calculations for delivering any arbitrary order of the expansion. The\nlikelihood function is thus approximated explicitly and employed in statistical\nestimation. The performance of our method is demonstrated by Monte Carlo\nsimulations from implementing several examples, which represent a wide range of\ncommonly used diffusion models. The convergence related to the expansion and\nthe estimation method are theoretically justified using the theory of Watanabe\n[Ann. Probab. 15 (1987) 1-39] and Yoshida [J. Japan Statist. Soc. 22 (1992)\n139-159] on analysis of the generalized random variables under some standard\nsufficient conditions.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2013 06:19:03 GMT"}], "update_date": "2013-08-14", "authors_parsed": [["Li", "Chenxu", ""]]}, {"id": "1308.2765", "submitter": "Aur\\'elie Boisbunon", "authors": "Aur\\'elie Boisbunon (CSIS), Yuzo Maruyama (CSIS)", "title": "Inadmissibility of the best equivariant predictive density in the\n  unknown variance case", "comments": "title changed and some minor modification in the file", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we are concerned with the estimation of the predictive density\nof a Gaussian random vector where both the mean and the variance are unknown.\nIn such a context, we prove the inadmissibility of the best equivariant\npredictive density under the Kullback-Leibler risk in a nonasymptotic\nframework. Our result stands whatever the dimension d of the vector is, even\nwhen d<=2, which can be somewhat surprising compared to the known variance\nsetting. We also propose a class of priors leading to a Bayesian predictive\ndensity that dominates the best equivariant one. Throughout the article, we\ngive several elements that we believe are useful for establishing the parallel\nbetween the prediction and the estimation problems, as it was done in the known\nvariance framework.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2013 06:27:03 GMT"}, {"version": "v2", "created": "Fri, 16 Aug 2013 01:52:52 GMT"}, {"version": "v3", "created": "Sat, 24 May 2014 13:54:50 GMT"}], "update_date": "2014-05-27", "authors_parsed": [["Boisbunon", "Aur\u00e9lie", "", "CSIS"], ["Maruyama", "Yuzo", "", "CSIS"]]}, {"id": "1308.2766", "submitter": "Aur\\'elie Boisbunon", "authors": "Aur\\'elie Boisbunon (CSIS), Stephane Canu (LITIS), Dominique\n  Fourdrinier (LITIS), William Strawderman, Martin T. Wells", "title": "AIC, Cp and estimators of loss for elliptically symmetric distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we develop a modern perspective on Akaike's Information\nCriterion and Mallows' Cp for model selection. Despite the diff erences in\ntheir respective motivation, they are equivalent in the special case of\nGaussian linear regression. In this case they are also equivalent to a third\ncriterion, an unbiased estimator of the quadratic prediction loss, derived from\nloss estimation theory. Our first contribution is to provide an explicit link\nbetween loss estimation and model selection through a new oracle inequality. We\nthen show that the form of the unbiased estimator of the quadratic prediction\nloss under a Gaussian assumption still holds under a more general\ndistributional assumption, the family of spherically symmetric distributions.\nOne of the features of our results is that our criterion does not rely on the\nspeci ficity of the distribution, but only on its spherical symmetry. Also this\nfamily of laws o ffers some dependence property between the observations, a\ncase not often studied.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2013 06:27:51 GMT"}, {"version": "v2", "created": "Sat, 24 May 2014 14:59:09 GMT"}], "update_date": "2014-05-27", "authors_parsed": [["Boisbunon", "Aur\u00e9lie", "", "CSIS"], ["Canu", "Stephane", "", "LITIS"], ["Fourdrinier", "Dominique", "", "LITIS"], ["Strawderman", "William", ""], ["Wells", "Martin T.", ""]]}, {"id": "1308.2791", "submitter": "Nicholas Lewis", "authors": "Nicholas Lewis", "title": "Modification of Bayesian Updating where Continuous Parameters have\n  Differing Relationships with New and Existing Data", "comments": "25 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian analyses are often performed using so-called noninformative priors,\nwith a view to achieving objective inference about unknown parameters on which\navailable data depends. Noninformative priors depend on the relationship of the\ndata to the parameters over the sample space. Combining Bayesian updating -\nmultiplying an existing posterior density for parameters being estimated by a\nlikelihood function derived from independent new data that depend on those\nparameters and renormalizing - with use of noninformative priors gives rise to\ninconsistency where existing and new data depend on continuous parameters in\ndifferent ways. In such cases, noninformative priors for inference from only\nthe existing and from only the new data would differ, so Bayesian updating\nwould give different final posterior densities depending on which set of data\nwas used to derive an initial posterior and which was used to update that\nposterior. I propose a revised Bayesian updating method, which resolves this\ninconsistency by updating the prior as well as the likelihood function, and\ninvolves only a single application of Bayes' theorem. The revised method is\nalso applicable where actual prior information as to parameter values exists\nand inference that objectively reflects the existing information as well as new\ndata is sought. I demonstrate by numerical testing the probability-matching\nsuperiority of the proposed revised updating method, in two cases.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2013 09:08:10 GMT"}], "update_date": "2013-08-14", "authors_parsed": [["Lewis", "Nicholas", ""]]}, {"id": "1308.2809", "submitter": "Sam Efromovich", "authors": "Sam Efromovich", "title": "Nonparametric regression with the scale depending on auxiliary variable", "comments": "Published in at http://dx.doi.org/10.1214/13-AOS1126 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2013, Vol. 41, No. 3, 1542-1568", "doi": "10.1214/13-AOS1126", "report-no": "IMS-AOS-AOS1126", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper is devoted to the problem of estimation of a univariate component\nin a heteroscedastic nonparametric multiple regression under the mean\nintegrated squared error (MISE) criteria. The aim is to understand how the\nscale function should be used for estimation of the univariate component. It is\nknown that the scale function does not affect the rate of the MISE convergence,\nand as a result sharp constants are explored. The paper begins with developing\na sharp-minimax theory for a pivotal model\n$Y=f(X)+\\sigma(X,\\mathbf{Z})\\varepsilon$, where $\\varepsilon$ is standard\nnormal and independent of the predictor X and the auxiliary vector-covariate\n$\\mathbf{Z}$. It is shown that if the scale $\\sigma(x,\\mathbf{z})$ depends on\nthe auxiliary variable, then a special estimator, which uses the scale (or its\nestimate), is asymptotically sharp minimax and adaptive to unknown smoothness\nof f(x). This is an interesting conclusion because if the scale does not depend\non the auxiliary covariate $\\mathbf{Z}$, then ignoring the heteroscedasticity\ncan yield a sharp minimax estimation. The pivotal model serves as a natural\nbenchmark for a general additive model\n$Y=f(X)+g(\\mathbf{Z})+\\sigma(X,\\mathbf{Z})\\varepsilon$, where $\\varepsilon$ may\ndepend on $(X,\\mathbf{Z})$ and have only a finite fourth moment. It is shown\nthat for this model a data-driven estimator can perform as well as for the\nbenchmark. Furthermore, the estimator, suggested for continuous responses, can\nbe also used for the case of discrete responses. Bernoulli and Poisson\nregressions, that are inherently heteroscedastic, are particular considered\nexamples for which sharp minimax lower bounds are obtained as well. A numerical\nstudy shows that the asymptotic theory sheds light on small samples.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2013 10:07:11 GMT"}], "update_date": "2013-08-14", "authors_parsed": [["Efromovich", "Sam", ""]]}, {"id": "1308.2830", "submitter": "Hiroki Masuda", "authors": "Hiroki Masuda", "title": "Convergence of Gaussian quasi-likelihood random fields for ergodic\n  L\\'{e}vy driven SDE observed at high frequency", "comments": "Published in at http://dx.doi.org/10.1214/13-AOS1121 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2013, Vol. 41, No. 3, 1593-1641", "doi": "10.1214/13-AOS1121", "report-no": "IMS-AOS-AOS1121", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the Gaussian quasi-likelihood estimation of an\nexponentially ergodic multidimensional Markov process, which is expressed as a\nsolution to a L\\'{e}vy driven stochastic differential equation whose\ncoefficients are known except for the finite-dimensional parameters to be\nestimated, where the diffusion coefficient may be degenerate or even null. We\nsuppose that the process is discretely observed under the rapidly increasing\nexperimental design with step size $h_n$. By means of the polynomial-type large\ndeviation inequality, convergence of the corresponding statistical random\nfields is derived in a mighty mode, which especially leads to the asymptotic\nnormality at rate $\\sqrt{nh_n}$ for all the target parameters, and also to the\nconvergence of their moments. As our Gaussian quasi-likelihood solely looks at\nthe local-mean and local-covariance structures, efficiency loss would be large\nin some instances. Nevertheless, it has the practically important advantages:\nfirst, the computation of estimates does not require any fine tuning, and hence\nit is straightforward; second, the estimation procedure can be adopted without\nfull specification of the L\\'{e}vy measure.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2013 11:58:12 GMT"}], "update_date": "2013-08-14", "authors_parsed": [["Masuda", "Hiroki", ""]]}, {"id": "1308.2836", "submitter": "Susanne M. Schennach", "authors": "Susanne M. Schennach", "title": "Regressions with Berkson errors in covariates - A nonparametric approach", "comments": "Published in at http://dx.doi.org/10.1214/13-AOS1122 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2013, Vol. 41, No. 3, 1642-1668", "doi": "10.1214/13-AOS1122", "report-no": "IMS-AOS-AOS1122", "categories": "math.ST q-fin.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper establishes that so-called instrumental variables enable the\nidentification and the estimation of a fully nonparametric regression model\nwith Berkson-type measurement error in the regressors. An estimator is proposed\nand proven to be consistent. Its practical performance and feasibility are\ninvestigated via Monte Carlo simulations as well as through an epidemiological\napplication investigating the effect of particulate air pollution on\nrespiratory health. These examples illustrate that Berkson errors can clearly\nnot be neglected in nonlinear regression models and that the proposed method\nrepresents an effective remedy.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2013 12:26:44 GMT"}], "update_date": "2013-08-15", "authors_parsed": [["Schennach", "Susanne M.", ""]]}, {"id": "1308.2845", "submitter": "Jiahua Chen", "authors": "Jiahua Chen, Yukun Liu", "title": "Quantile and quantile-function estimations under density ratio model", "comments": "Published in at http://dx.doi.org/10.1214/13-AOS1129 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2013, Vol. 41, No. 3, 1669-1692", "doi": "10.1214/13-AOS1129", "report-no": "IMS-AOS-AOS1129", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Population quantiles and their functions are important parameters in many\napplications. For example, the lower quantiles often serve as crucial quality\nindices for forestry products. Given several independent samples from\npopulations satisfying the density ratio model, we investigate the properties\nof empirical likelihood (EL) based inferences. The induced EL quantile\nestimators are shown to admit a Bahadur representation that leads to\nasymptotically valid confidence intervals for functions of quantiles. We\nrigorously prove that EL quantiles based on all the samples are more efficient\nthan empirical quantiles based on individual samples. A simulation study shows\nthat the EL quantiles and their functions have superior performance when the\ndensity ratio model assumption is satisfied and when it is mildly violated. An\nexample is used to demonstrate the new method and the potential cost savings.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2013 12:55:26 GMT"}], "update_date": "2013-08-14", "authors_parsed": [["Chen", "Jiahua", ""], ["Liu", "Yukun", ""]]}, {"id": "1308.2853", "submitter": "Animashree Anandkumar", "authors": "Animashree Anandkumar, Daniel Hsu, Majid Janzamin, Sham Kakade", "title": "When are Overcomplete Topic Models Identifiable? Uniqueness of Tensor\n  Tucker Decompositions with Structured Sparsity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR math.NA math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Overcomplete latent representations have been very popular for unsupervised\nfeature learning in recent years. In this paper, we specify which overcomplete\nmodels can be identified given observable moments of a certain order. We\nconsider probabilistic admixture or topic models in the overcomplete regime,\nwhere the number of latent topics can greatly exceed the size of the observed\nword vocabulary. While general overcomplete topic models are not identifiable,\nwe establish generic identifiability under a constraint, referred to as topic\npersistence. Our sufficient conditions for identifiability involve a novel set\nof \"higher order\" expansion conditions on the topic-word matrix or the\npopulation structure of the model. This set of higher-order expansion\nconditions allow for overcomplete models, and require the existence of a\nperfect matching from latent topics to higher order observed words. We\nestablish that random structured topic models are identifiable w.h.p. in the\novercomplete regime. Our identifiability results allows for general\n(non-degenerate) distributions for modeling the topic proportions, and thus, we\ncan handle arbitrarily correlated topics in our framework. Our identifiability\nresults imply uniqueness of a class of tensor decompositions with structured\nsparsity which is contained in the class of Tucker decompositions, but is more\ngeneral than the Candecomp/Parafac (CP) decomposition.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2013 13:16:10 GMT"}], "update_date": "2013-08-14", "authors_parsed": [["Anandkumar", "Animashree", ""], ["Hsu", "Daniel", ""], ["Janzamin", "Majid", ""], ["Kakade", "Sham", ""]]}, {"id": "1308.2927", "submitter": "Mathieu Sart", "authors": "Mathieu Sart", "title": "Robust estimation on a parametric model via testing", "comments": "Published at http://dx.doi.org/10.3150/15-BEJ706 in the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2016, Vol. 22, No. 3, 1617-1670", "doi": "10.3150/15-BEJ706", "report-no": "IMS-BEJ-BEJ706", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are interested in the problem of robust parametric estimation of a density\nfrom $n$ i.i.d. observations. By using a practice-oriented procedure based on\nrobust tests, we build an estimator for which we establish non-asymptotic risk\nbounds with respect to the Hellinger distance under mild assumptions on the\nparametric model. We show that the estimator is robust even for models for\nwhich the maximum likelihood method is bound to fail. A numerical simulation\nillustrates its robustness properties. When the model is true and regular\nenough, we prove that the estimator is very close to the maximum likelihood\none, at least when the number of observations $n$ is large. In particular, it\ninherits its efficiency. Simulations show that these two estimators are almost\nequal with large probability, even for small values of $n$ when the model is\nregular enough and contains the true density.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2013 17:51:00 GMT"}, {"version": "v2", "created": "Mon, 9 Sep 2013 16:24:51 GMT"}, {"version": "v3", "created": "Wed, 30 Mar 2016 10:56:48 GMT"}], "update_date": "2016-03-31", "authors_parsed": [["Sart", "Mathieu", ""]]}, {"id": "1308.2955", "submitter": "Nicolas Verzelen", "authors": "Ery Arias-Castro (Math Dept, UCSD), Nicolas Verzelen (MISTEA)", "title": "Community Detection in Sparse Random Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of detecting a tight community in a sparse random\nnetwork. This is formalized as testing for the existence of a dense random\nsubgraph in a random graph. Under the null hypothesis, the graph is a\nrealization of an Erd\\\"os-R\\'enyi graph on $N$ vertices and with connection\nprobability $p_0$; under the alternative, there is an unknown subgraph on $n$\nvertices where the connection probability is p1 > p0. In Arias-Castro and\nVerzelen (2012), we focused on the asymptotically dense regime where p0 is\nlarge enough that np0>(n/N)^{o(1)}. We consider here the asymptotically sparse\nregime where p0 is small enough that np0<(n/N)^{c0} for some c0>0. As before,\nwe derive information theoretic lower bounds, and also establish the\nperformance of various tests. Compared to our previous work, the arguments for\nthe lower bounds are based on the same technology, but are substantially more\ntechnical in the details; also, the methods we study are different: besides a\nvariant of the scan statistic, we study other statistics such as the size of\nthe largest connected component, the number of triangles, the eigengap of the\nadjacency matrix, etc. Our detection bounds are sharp, except in the Poisson\nregime where we were not able to fully characterize the constant arising in the\nbound.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2013 19:39:48 GMT"}, {"version": "v2", "created": "Thu, 25 Sep 2014 17:07:14 GMT"}], "update_date": "2014-09-26", "authors_parsed": [["Arias-Castro", "Ery", "", "Math Dept, UCSD"], ["Verzelen", "Nicolas", "", "MISTEA"]]}, {"id": "1308.3089", "submitter": "Dmitry Ivanenko Alexandrovich", "authors": "Dmytro Ivanenko, Alexey Kulik", "title": "LAN property for families of distributions of solutions to Levy driven\n  SDE's", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  The LAN property is proved in the statistical model based on discrete-time\nobservations of a solution to a L\\'{e}vy driven SDE. The proof is based on a\ngeneral sufficient condition for a statistical model based on a discrete\nobservations of a Markov process to possess the LAN property, and involves\nsubstantially the Malliavin calculus-based integral representations for\nderivatives of log-likelihood of the model.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2013 11:33:00 GMT"}, {"version": "v2", "created": "Mon, 19 Aug 2013 18:07:35 GMT"}, {"version": "v3", "created": "Mon, 7 Apr 2014 13:19:28 GMT"}], "update_date": "2014-04-08", "authors_parsed": [["Ivanenko", "Dmytro", ""], ["Kulik", "Alexey", ""]]}, {"id": "1308.3201", "submitter": "Ulrike Schneider", "authors": "Ulrike Schneider", "title": "Confidence Sets Based on Thresholding Estimators in High-Dimensional\n  Gaussian Regression Models", "comments": "Section 1 and 2 rewritten, small numerical study added, minor\n  corrections", "journal-ref": "Economet. Rev. 35 (2016), 1412-1455", "doi": "10.1080/07474938.2015.1092798", "report-no": null, "categories": "math.ST stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study confidence intervals based on hard-thresholding, soft-thresholding,\nand adaptive soft-thresholding in a linear regression model where the number of\nregressors $k$ may depend on and diverge with sample size $n$. In addition to\nthe case of known error variance, we define and study versions of the\nestimators when the error variance is unknown. In the known variance case, we\nprovide an exact analysis of the coverage properties of such intervals in\nfinite samples. We show that these intervals are always larger than the\nstandard interval based on the least-squares estimator. Asymptotically, the\nintervals based on the thresholding estimators are larger even by an order of\nmagnitude when the estimators are tuned to perform consistent variable\nselection. For the unknown-variance case, we provide non-trivial lower bounds\nfor the coverage probabilities in finite samples and conduct an asymptotic\nanalysis where the results from the known-variance case can be shown to carry\nover asymptotically if the number of degrees of freedom $n-k$ tends to infinity\nfast enough in relation to the thresholding parameter.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2013 18:25:49 GMT"}, {"version": "v2", "created": "Tue, 5 Aug 2014 15:00:44 GMT"}], "update_date": "2018-10-08", "authors_parsed": [["Schneider", "Ulrike", ""]]}, {"id": "1308.3304", "submitter": "Timothy Wallstrom", "authors": "Timothy C. Wallstrom", "title": "On the application of McDiarmid's inequality to complex systems", "comments": null, "journal-ref": null, "doi": null, "report-no": "LA-UR-13-25882", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  McDiarmid's inequality has recently been proposed as a tool for setting\nmargin requirements for complex systems. If $F$ is the bounded output of a\ncomplex system, depending on a vector of $n$ bounded inputs, this inequality\nprovides a bound $B_F(\\epsilon)$, such that the probability of a deviation\nexceeding $B_F(\\epsilon)$ is less than $\\epsilon$. I compare this bound with\nthe absolute bound, based on the range of $F$. I show that when $n_{eff}$, the\neffective number of independent variates, is small, and when $\\epsilon$ is\nsmall, the absolute bound is smaller than $B_F(\\epsilon)$, while also providing\na smaller probability of exceeding the bound, i.e., zero instead of $\\epsilon$.\nThus, for $B_F(\\epsilon)$ to be useful, the number of inputs must be large,\nwith a small dependence on any single input, which is consistent with the usual\nguidance for application of concentration-of-measure results. When the number\nof inputs is small, or when a small number of inputs account for much of the\nuncertainty, the absolute bounds will provide better results. The use of\nabsolute bounds is equivalent to the original formulation of the method of\nQuantification of Margins and Uncertainties (QMU).\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2013 04:57:12 GMT"}], "update_date": "2013-08-16", "authors_parsed": [["Wallstrom", "Timothy C.", ""]]}, {"id": "1308.3374", "submitter": "Dave Zachariah", "authors": "Dave Zachariah, Magnus Jansson, Mats Bengtsson", "title": "Utilization of Noise-Only Samples in Array Processing With Prior\n  Knowledge", "comments": null, "journal-ref": "IEEE Signal Processing Letters, Sept. 2013, Vol. 20, No. 9, pages\n  865-868", "doi": "10.1109/LSP.2013.2271515", "report-no": null, "categories": "math.ST cs.IT math.IT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For array processing, we consider the problem of estimating signals of\ninterest, and their directions of arrival (DOA), in unknown colored noise\nfields. We develop an estimator that efficiently utilizes a set of noise-only\nsamples and, further, can incorporate prior knowledge of the DOAs with varying\ndegrees of certainty. The estimator is compared with state of the art\nestimators that utilize noise-only samples, and the Cram\\'{e}r-Rao bound,\nexhibiting improved performance for smaller sample sets and in poor signal\nconditions.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2013 12:26:53 GMT"}], "update_date": "2013-08-16", "authors_parsed": [["Zachariah", "Dave", ""], ["Jansson", "Magnus", ""], ["Bengtsson", "Mats", ""]]}, {"id": "1308.3568", "submitter": "Camille Charbonnier", "authors": "Camille Charbonnier, Nicolas Verzelen (MISTEA), Fanny Villers (LPMA)", "title": "A Global Homogeneity Test for High-Dimensional Linear Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.AP stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is motivated by the comparison of genetic networks based on\nmicroarray samples. The aim is to test whether the differences observed between\ntwo inferred Gaussian graphical models come from real differences or arise from\nestimation uncertainties. Adopting a neighborhood approach, we consider a\ntwo-sample linear regression model with random design and propose a procedure\nto test whether these two regressions are the same. Relying on multiple testing\nand variable selection strategies, we develop a testing procedure that applies\nto high-dimensional settings where the number of covariates $p$ is larger than\nthe number of observations $n_1$ and $n_2$ of the two samples. Both type I and\ntype II errors are explicitely controlled from a non-asymptotic perspective and\nthe test is proved to be minimax adaptive to the sparsity. The performances of\nthe test are evaluated on simulated data. Moreover, we illustrate how this\nprocedure can be used to compare genetic networks on Hess \\emph{et al} breast\ncancer microarray dataset.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2013 07:39:52 GMT"}, {"version": "v2", "created": "Thu, 19 Jun 2014 19:10:35 GMT"}], "update_date": "2014-06-20", "authors_parsed": [["Charbonnier", "Camille", "", "MISTEA"], ["Verzelen", "Nicolas", "", "MISTEA"], ["Villers", "Fanny", "", "LPMA"]]}, {"id": "1308.3602", "submitter": "Nigel J. Newton", "authors": "Nigel J. Newton", "title": "Infinite-dimensional statistical manifolds based on a balanced chart", "comments": "Published at http://dx.doi.org/10.3150/14-BEJ673 in the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2016, Vol. 22, No. 2, 711-731", "doi": "10.3150/14-BEJ673", "report-no": "IMS-BEJ-BEJ673", "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a family of infinite-dimensional Banach manifolds of measures on\nan abstract measurable space, employing charts that are \"balanced\" between the\ndensity and log-density functions. The manifolds,\n$(\\tilde{M}_{\\lambda},\\lambda\\in [2,\\infty))$, retain many of the features of\nfinite-dimensional information geometry; in particular, the\n$\\alpha$-divergences are of class $C^{\\lceil\\lambda\\rceil-1}$, enabling the\ndefinition of the Fisher metric and $\\alpha$-derivatives of particular classes\nof vector fields. Manifolds of probability measures, $(M_{\\lambda},\\lambda\\in\n[2,\\infty))$, based on centred versions of the charts are shown to be\n$C^{\\lceil\\lambda \\rceil-1}$-embedded submanifolds of the\n$\\tilde{M}_{\\lambda}$. The Fisher metric is a pseudo-Riemannian metric on\n$\\tilde{M}_{\\lambda}$. However, when restricted to finite-dimensional embedded\nsubmanifolds it becomes a Riemannian metric, allowing the full development of\nthe geometry of $\\alpha$-covariant derivatives. $\\tilde{M}_{\\lambda}$ and\n$M_{\\lambda}$ provide natural settings for the study and comparison of\napproximations to posterior distributions in problems of Bayesian estimation.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2013 11:10:55 GMT"}, {"version": "v2", "created": "Tue, 9 Feb 2016 08:58:47 GMT"}], "update_date": "2016-02-10", "authors_parsed": [["Newton", "Nigel J.", ""]]}, {"id": "1308.3728", "submitter": "Christopher Fox", "authors": "Christopher J. Fox, Andreas K\\\"aufl, Mathias Drton", "title": "On the causal interpretation of acyclic mixed graphs under multivariate\n  normality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In multivariate statistics, acyclic mixed graphs with directed and bidirected\nedges are widely used for compact representation of dependence structures that\ncan arise in the presence of hidden (i.e., latent or unobserved) variables.\nIndeed, under multivariate normality, every mixed graph corresponds to a set of\ncovariance matrices that contains as a full-dimensional subset the covariance\nmatrices associated with a causally interpretable acyclic digraph. This digraph\ngenerally has some of its nodes corresponding to hidden variables. We seek to\nclarify for which mixed graphs there exists an acyclic digraph whose hidden\nvariable model coincides with the mixed graph model. Restricting to the\ntractable setting of chain graphs and multivariate normality, we show that\ndecomposability of the bidirected part of the chain graph is necessary and\nsufficient for equality between the mixed graph model and some hidden variable\nmodel given by an acyclic digraph.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2013 21:54:57 GMT"}], "update_date": "2013-08-20", "authors_parsed": [["Fox", "Christopher J.", ""], ["K\u00e4ufl", "Andreas", ""], ["Drton", "Mathias", ""]]}, {"id": "1308.3861", "submitter": "Yun Yang", "authors": "Yun Yang and David B. Dunson", "title": "Sequential Markov Chain Monte Carlo", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a sequential Markov chain Monte Carlo (SMCMC) algorithm to sample\nfrom a sequence of probability distributions, corresponding to posterior\ndistributions at different times in on-line applications. SMCMC proceeds as in\nusual MCMC but with the stationary distribution updated appropriately each time\nnew data arrive. SMCMC has advantages over sequential Monte Carlo (SMC) in\navoiding particle degeneracy issues. We provide theoretical guarantees for the\nmarginal convergence of SMCMC under various settings, including parametric and\nnonparametric models. The proposed approach is compared to competitors in a\nsimulation study. We also consider an application to on-line nonparametric\nregression.\n", "versions": [{"version": "v1", "created": "Sun, 18 Aug 2013 14:34:38 GMT"}], "update_date": "2013-08-20", "authors_parsed": [["Yang", "Yun", ""], ["Dunson", "David B.", ""]]}, {"id": "1308.3890", "submitter": "Damien Passemier", "authors": "Damien Passemier (ECE), Zhaoyuan Li (DSAS), Jian-Feng Yao (DSAS)", "title": "On estimation of the noise variance in high-dimensional probabilistic\n  principal component analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we develop new statistical theory for probabilistic principal\ncomponent analysis models in high dimensions. The focus is the estimation of\nthe noise variance, which is an important and unresolved issue when the number\nof variables is large in comparison with the sample size. We first unveil the\nreasons of a widely observed downward bias of the maximum likelihood estimator\nof the variance when the data dimension is high. We then propose a\nbias-corrected estimator using random matrix theory and establish its\nasymptotic normality. The superiority of the new (bias-corrected) estimator\nover existing alternatives is first checked by Monte-Carlo experiments with\nvarious combinations of $(p, n)$ (dimension and sample size). In order to\ndemonstrate further potential benefits from the results of the paper to general\nprobability PCA analysis, we provide evidence of net improvements in two\npopular procedures (Ulfarsson and Solo, 2008; Bai and Ng, 2002) for determining\nthe number of principal components when the respective variance estimator\nproposed by these authors is replaced by the bias-corrected estimator. The new\nestimator is also used to derive new asymptotics for the related\ngoodness-of-fit statistic under the high-dimensional scheme.\n", "versions": [{"version": "v1", "created": "Sun, 18 Aug 2013 19:34:50 GMT"}, {"version": "v2", "created": "Fri, 20 Jun 2014 14:01:50 GMT"}], "update_date": "2014-06-23", "authors_parsed": [["Passemier", "Damien", "", "ECE"], ["Li", "Zhaoyuan", "", "DSAS"], ["Yao", "Jian-Feng", "", "DSAS"]]}, {"id": "1308.3925", "submitter": "Mercedes Richards", "authors": "Elizabeth Martinez-Gomez, Mercedes T. Richards, Donald St. P. Richards", "title": "Distance Correlation Methods for Discovering Associations in Large\n  Astrophysical Databases", "comments": "11 pages, 6 figures, 4 tables; Astrophysical Journal, accepted, in\n  press", "journal-ref": null, "doi": "10.1088/0004-637X/781/1/39", "report-no": null, "categories": "astro-ph.CO math.ST stat.AP stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-dimensional, large-sample astrophysical databases of galaxy clusters,\nsuch as the Chandra Deep Field South COMBO-17 database, provide measurements on\nmany variables for thousands of galaxies and a range of redshifts. Current\nunderstanding of galaxy formation and evolution rests sensitively on\nrelationships between different astrophysical variables; hence an ability to\ndetect and verify associations or correlations between variables is important\nin astrophysical research. In this paper, we apply a recently defined\nstatistical measure called the distance correlation coefficient which can be\nused to identify new associations and correlations between astrophysical\nvariables. The distance correlation coefficient applies to variables of any\ndimension; it can be used to determine smaller sets of variables that provide\nequivalent astrophysical information; it is zero only when variables are\nindependent; and it is capable of detecting nonlinear associations that are\nundetectable by the classical Pearson correlation coefficient. Hence, the\ndistance correlation coefficient provides more information than the Pearson\ncoefficient. We analyze numerous pairs of variables in the COMBO-17 database\nwith the distance correlation method and with the maximal information\ncoefficient. We show that the Pearson coefficient can be estimated with higher\naccuracy from the corresponding distance correlation coefficient than from the\nmaximal information coefficient. For given values of the Pearson coefficient,\nthe distance correlation method has a greater ability than the maximal\ninformation coefficient to resolve astrophysical data into highly concentrated\nV-shapes, which enhances classification and pattern identification. These\nresults are observed over a range of redshifts beyond the local universe and\nfor galaxies from elliptical to spiral.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2013 05:27:09 GMT"}, {"version": "v2", "created": "Tue, 3 Dec 2013 20:47:20 GMT"}], "update_date": "2015-06-16", "authors_parsed": [["Martinez-Gomez", "Elizabeth", ""], ["Richards", "Mercedes T.", ""], ["Richards", "Donald St. P.", ""]]}, {"id": "1308.4077", "submitter": "Morteza Ibrahimi", "authors": "Jose Bento, and Morteza Ibrahimi", "title": "Support Recovery for the Drift Coefficient of High-Dimensional\n  Diffusions", "comments": "24 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider the problem of learning the drift coefficient of a $p$-dimensional\nstochastic differential equation from a sample path of length $T$. We assume\nthat the drift is parametrized by a high-dimensional vector, and study the\nsupport recovery problem when both $p$ and $T$ can tend to infinity. In\nparticular, we prove a general lower bound on the sample-complexity $T$ by\nusing a characterization of mutual information as a time integral of\nconditional variance, due to Kadota, Zakai, and Ziv. For linear stochastic\ndifferential equations, the drift coefficient is parametrized by a $p\\times p$\nmatrix which describes which degrees of freedom interact under the dynamics. In\nthis case, we analyze a $\\ell_1$-regularized least squares estimator and prove\nan upper bound on $T$ that nearly matches the lower bound on specific classes\nof sparse matrices.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2013 17:12:40 GMT"}, {"version": "v2", "created": "Tue, 20 Aug 2013 03:36:59 GMT"}], "update_date": "2013-08-21", "authors_parsed": [["Bento", "Jose", ""], ["Ibrahimi", "Morteza", ""]]}, {"id": "1308.4117", "submitter": "Ramon Van Handel", "authors": "Patrick Rebeschini and Ramon van Handel", "title": "Comparison Theorems for Gibbs Measures", "comments": "55 pages", "journal-ref": "J. Stat. Phys. 157, 234-281 (2014)", "doi": "10.1007/s10955-014-1087-7", "report-no": null, "categories": "math.PR math-ph math.MP math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Dobrushin comparison theorem is a powerful tool to bound the difference\nbetween the marginals of high-dimensional probability distributions in terms of\ntheir local specifications. Originally introduced to prove uniqueness and decay\nof correlations of Gibbs measures, it has been widely used in statistical\nmechanics as well as in the analysis of algorithms on random fields and\ninteracting Markov chains. However, the classical comparison theorem requires\nvalidity of the Dobrushin uniqueness criterion, essentially restricting its\napplicability in most models to a small subset of the natural parameter space.\nIn this paper we develop generalized Dobrushin comparison theorems in terms of\ninfluences between blocks of sites, in the spirit of Dobrushin-Shlosman and\nWeitz, that substantially extend the range of applicability of the classical\ncomparison theorem. Our proofs are based on the analysis of an associated\nfamily of Markov chains. We develop in detail an application of our main\nresults to the analysis of sequential Monte Carlo algorithms for filtering in\nhigh dimension.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2013 19:56:56 GMT"}], "update_date": "2015-02-04", "authors_parsed": [["Rebeschini", "Patrick", ""], ["van Handel", "Ramon", ""]]}, {"id": "1308.4123", "submitter": "Xinjia Chen", "authors": "Xinjia Chen", "title": "A Likelihood Ratio Approach for Probabilistic Inequalities", "comments": "38 pages, no figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new approach for deriving probabilistic inequalities based on\nbounding likelihood ratios. We demonstrate that this approach is more general\nand powerful than the classical method frequently used for deriving\nconcentration inequalities such as Chernoff bounds. We discover that the\nproposed approach is inherently related to statistical concepts such as\nmonotone likelihood ratio, maximum likelihood, and the method of moments for\nparameter estimation. A connection between the proposed approach and the large\ndeviation theory is also established. We show that, without using moment\ngenerating functions, tightest possible concentration inequalities may be\nreadily derived by the proposed approach. We have derived new concentration\ninequalities using the proposed approach, which cannot be obtained by the\nclassical approach based on moment generating functions.\n", "versions": [{"version": "v1", "created": "Sun, 18 Aug 2013 22:40:41 GMT"}], "update_date": "2013-11-21", "authors_parsed": [["Chen", "Xinjia", ""]]}, {"id": "1308.4180", "submitter": "Eli Ben-Naim", "authors": "P.W. Miller and E. Ben-Naim", "title": "Scaling Exponent for Incremental Records", "comments": "7 pages, 8 figures", "journal-ref": "J. Stat. Mech. P10025 (2013)", "doi": "10.1088/1742-5468/2013/10/P10025", "report-no": null, "categories": "cond-mat.stat-mech math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate records in a growing sequence of identical and independently\ndistributed random variables. The record equals the largest value in the\nsequence, and our focus is on the increment, defined as the difference between\ntwo successive records. We investigate sequences in which all increments\ndecrease monotonically, and find that the fraction I_N of sequences that\nexhibit this property decays algebraically with sequence length N, namely I_N ~\nN^{-nu} as N --> infinity. We analyze the case where the random variables are\ndrawn from a uniform distribution with compact support, and obtain the exponent\nnu = 0.317621... using analytic methods. We also study the record distribution\nand the increment distribution. Whereas the former is a narrow distribution\nwith an exponential tail, the latter is broad and has a power-law tail\ncharacterized by the exponent nu. Empirical analysis of records in the sequence\nof waiting times between successive earthquakes is consistent with the\ntheoretical results.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2013 21:35:07 GMT"}], "update_date": "2014-01-03", "authors_parsed": [["Miller", "P. W.", ""], ["Ben-Naim", "E.", ""]]}, {"id": "1308.4194", "submitter": "Joel Zinn", "authors": "James Kuelbs and Joel Zinn", "title": "Empirical Quantile CLTs For Some Self-Similar Processes", "comments": "24 pages. arXiv admin note: text overlap with arXiv:1111.4591", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a paper of Jason Swanson, a CLT for the sample median of independent\nBrownian motions with value 0 at 0 was proved. Here we extend this result in\ntwo ways. We prove such a result for a collection of self-similar processes\nwhich include the fractional Brownian motions, all stationary, independent\nincrement symmetric stable processes tied down at 0 as well as iterated and\nintegrated Brownian motions. Second, our results hold uniformly over all\nquantiles in a compact sub-interval of (0,1). We also examine sample function\nproperties connected with these CLTs.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2013 00:17:15 GMT"}], "update_date": "2013-08-21", "authors_parsed": [["Kuelbs", "James", ""], ["Zinn", "Joel", ""]]}, {"id": "1308.4295", "submitter": "Mikhail  Ermakov s", "authors": "Mikhail Ermakov", "title": "On distinguishability of hypotheses", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problems of hypothesis testing on a probability measure of\nindependent sample, on solution of ill-posed problem, on deconvolution problem\nand on Poisson mean measure. For all these setups necessary conditions and\nsufficient conditions are given for distinguishability of sets of hypothesis.\nIn the case of hypothesis testing on a probability measure and on Poisson mean\nmeasure the results are given in terms of weak topology and topology of weak\nconvergence on all Borel sets.\n  The problem of discernibility of hypothesis is also studied. In other cases\nthe necessary and sufficient conditions of distinguishability are given if the\nsets of hypotheses are bounded sets in $L_2$.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2013 13:10:35 GMT"}, {"version": "v2", "created": "Thu, 22 Aug 2013 07:42:33 GMT"}, {"version": "v3", "created": "Wed, 23 Oct 2013 10:02:09 GMT"}], "update_date": "2013-10-24", "authors_parsed": [["Ermakov", "Mikhail", ""]]}, {"id": "1308.4385", "submitter": "Gael Varoquaux", "authors": "P. Ciuciu (LNAO), G. Varoquaux, P. Abry, S. Sadaghiani, A.\n  Kleinschmidt", "title": "Scale-Free and Multifractal Time Dynamics of fMRI Signals during Rest\n  and Task", "comments": null, "journal-ref": "Frontiers in Physiology 3, 1 (2012) 186", "doi": "10.3389/fphys.2012.00186", "report-no": null, "categories": "math.ST q-bio.NC stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scaling temporal dynamics in functional MRI (fMRI) signals have been\nevidenced for a decade as intrinsic characteristics of ongoing brain activity\n(Zarahn et al., 1997). Recently, scaling properties were shown to fluctuate\nacross brain networks and to be modulated between rest and task (He, 2011):\nnotably, Hurst exponent, quantifying long memory, decreases under task in\nactivating and deactivating brain regions. In most cases, such results were\nobtained: First, from univariate (voxelwise or regionwise) analysis, hence\nfocusing on specific cognitive systems such as Resting-State Networks (RSNs)\nand raising the issue of the specificity of this scale-free dynamics modulation\nin RSNs. Second, using analysis tools designed to measure a single scaling\nexponent related to the second order statistics of the data, thus relying on\nmodels that either implicitly or explicitly assume Gaussianity and (asymptotic)\nself-similarity, while fMRI signals may significantly depart from those either\nof those two assumptions (Ciuciu et al., 2008; Wink et al., 2008). To address\nthese issues, the present contribution elaborates on the analysis of the\nscaling properties of fMRI temporal dynamics by proposing two significant\nvariations. First, scaling properties are technically investigated using the\nrecently introduced Wavelet Leader-based Multifractal formalism (WLMF; Wendt et\nal., 2007). This measures a collection of scaling exponents, thus enables a\nricher and more versatile description of scale invariance (beyond correlation\nand Gaussianity), referred to as multifractality. Also, it benefits from\nimproved estimation performance compared to tools previously used in the\nliterature. Second, scaling properties are investigated in both RSN and non-RSN\nstructures (e.g., artifacts), at a broader spatial scale than the voxel one,\nusing a multivariate approach, namely the Multi-Subject Dictionary Learning\n(MSDL) algorithm (Varoquaux et al., 2011) that produces a set of spatial\ncomponents that appear more sparse than their Independent Component Analysis\n(ICA) counterpart. These tools are combined and applied to a fMRI dataset\ncomprising 12 subjects with resting-state and activation runs (Sadaghiani et\nal., 2009). Results stemming from those analysis confirm the already reported\ntask-related decrease of long memory in functional networks, but also show that\nit occurs in artifacts, thus making this feature not specific to functional\nnetworks. Further, results indicate that most fMRI signals appear multifractal\nat rest except in non-cortical regions. Task-related modulation of\nmultifractality appears only significant in functional networks and thus can be\nconsidered as the key property disentangling functional networks from\nartifacts. These finding are discussed in the light of the recent literature\nreporting scaling dynamics of EEG microstate sequences at rest and addressing\nnon-stationarity issues in temporally independent fMRI modes.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2013 19:21:53 GMT"}], "update_date": "2013-08-21", "authors_parsed": [["Ciuciu", "P.", "", "LNAO"], ["Varoquaux", "G.", ""], ["Abry", "P.", ""], ["Sadaghiani", "S.", ""], ["Kleinschmidt", "A.", ""]]}, {"id": "1308.5036", "submitter": "Yang Feng", "authors": "Yang Feng, Tengfei Li, Zhiliang Ying", "title": "Likelihood Adaptively Modified Penalties", "comments": "42 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new family of penalty functions, adaptive to likelihood, is introduced for\nmodel selection in general regression models. It arises naturally through\nassuming certain types of prior distribution on the regression parameters. To\nstudy stability properties of the penalized maximum likelihood estimator, two\ntypes of asymptotic stability are defined. Theoretical properties, including\nthe parameter estimation consistency, model selection consistency, and\nasymptotic stability, are established under suitable regularity conditions. An\nefficient coordinate-descent algorithm is proposed. Simulation results and real\ndata analysis show that the proposed method has competitive performance in\ncomparison with existing ones.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2013 03:30:31 GMT"}], "update_date": "2013-08-26", "authors_parsed": [["Feng", "Yang", ""], ["Li", "Tengfei", ""], ["Ying", "Zhiliang", ""]]}, {"id": "1308.5256", "submitter": "Afonso S. Bandeira", "authors": "Afonso S. Bandeira and Moses Charikar and Amit Singer and Andy Zhu", "title": "Multireference Alignment using Semidefinite Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The multireference alignment problem consists of estimating a signal from\nmultiple noisy shifted observations. Inspired by existing Unique-Games\napproximation algorithms, we provide a semidefinite program (SDP) based\nrelaxation which approximates the maximum likelihood estimator (MLE) for the\nmultireference alignment problem. Although we show that the MLE problem is\nUnique-Games hard to approximate within any constant, we observe that our\npoly-time approximation algorithm for the MLE appears to perform quite well in\ntypical instances, outperforming existing methods. In an attempt to explain\nthis behavior we provide stability guarantees for our SDP under a random noise\nmodel on the observations. This case is more challenging to analyze than\ntraditional semi-random instances of Unique-Games: the noise model is on\nvertices of a graph and translates into dependent noise on the edges.\nInterestingly, we show that if certain positivity constraints in the SDP are\ndropped, its solution becomes equivalent to performing phase correlation, a\npopular method used for pairwise alignment in imaging applications. Finally, we\nshow how symmetry reduction techniques from matrix representation theory can\nsimplify the analysis and computation of the SDP, greatly decreasing its\ncomputational cost.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2013 22:19:33 GMT"}], "update_date": "2013-08-27", "authors_parsed": [["Bandeira", "Afonso S.", ""], ["Charikar", "Moses", ""], ["Singer", "Amit", ""], ["Zhu", "Andy", ""]]}, {"id": "1308.5312", "submitter": "Giovanni Pistone", "authors": "Giovanni Pistone", "title": "Examples of Application of Nonparametric Information Geometry to\n  Statistical Physics", "comments": "24 pages", "journal-ref": null, "doi": "10.3390/e15104042", "report-no": null, "categories": "math.ST math-ph math.MP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We review a nonparametric version of Amari's Information Geometry in which\nthe set of positive probability densities on a given sample space is endowed\nwith an atlas of charts to form a differentiable manifold modeled on Orlicz\nBanach spaces. This nonparametric setting is used to discuss the setting of\ntypical problems in Machine Learning and Statistical Physics, such as relaxed\noptimization, Kullback-Leibler divergence, Boltzmann entropy, Boltzmann\nequation\n", "versions": [{"version": "v1", "created": "Sat, 24 Aug 2013 09:43:00 GMT"}], "update_date": "2015-06-17", "authors_parsed": [["Pistone", "Giovanni", ""]]}, {"id": "1308.5343", "submitter": "Hazhir Homei", "authors": "Hazhir Homei", "title": "A Novel Extension of Randomly Weighted Average", "comments": "10 pages 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a well-known problem concerning a random variable $Z$ uniformly\ndistributed between two independent random variables. A new extension has been\nintroduced for this problem and fairly large classes of randomly weighted\naverage distributions are identified by their generalized Stieltjes transforms.\nIn this article we employ the Schwartz distribution theory for finding\ndistributions of this extension; we also study some of their properties.\n", "versions": [{"version": "v1", "created": "Sat, 24 Aug 2013 15:41:36 GMT"}], "update_date": "2013-08-27", "authors_parsed": [["Homei", "Hazhir", ""]]}, {"id": "1308.5427", "submitter": "Debdeep Pati", "authors": "Abhra Sarkar, Debdeep Pati, Bani K. Mallick, Raymond J. Carroll", "title": "Adaptive Posterior Convergence Rates in Bayesian Density Deconvolution\n  with Supersmooth Errors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian density deconvolution using nonparametric prior distributions is a\nuseful alternative to the frequentist kernel based deconvolution estimators due\nto its potentially wide range of applicability, straightforward uncertainty\nquantification and generalizability to more sophisticated models. This article\nis the first substantive effort to theoretically quantify the behavior of the\nposterior in this recent line of research. In particular, assuming a known\nsupersmooth error density, a Dirichlet process mixture of Normals on the true\ndensity leads to a posterior convergence rate same as the minimax rate $(\\log\nn)^{-\\eta/\\beta}$ adaptively over the smoothness $\\eta$ of an appropriate\nH\\\"{o}lder space of densities, where $\\beta$ is the degree of smoothness of the\nerror distribution. Our main contribution is achieving adaptive minimax rates\nwith respect to the $L_p$ norm for $2 \\leq p \\leq \\infty$ under mild regularity\nconditions on the true density. En route, we develop tight concentration bounds\nfor a class of kernel based deconvolution estimators which might be of\nindependent interest.\n", "versions": [{"version": "v1", "created": "Sun, 25 Aug 2013 17:20:59 GMT"}, {"version": "v2", "created": "Mon, 9 Sep 2013 14:38:26 GMT"}], "update_date": "2013-09-10", "authors_parsed": [["Sarkar", "Abhra", ""], ["Pati", "Debdeep", ""], ["Mallick", "Bani K.", ""], ["Carroll", "Raymond J.", ""]]}, {"id": "1308.5534", "submitter": "Frederic Utzet", "authors": "Armengol Gasull, Jos\\'e A. L\\'opez-Salcedo, Frederic Utzet", "title": "Maxima of Weibull-like distributions and the Lambert W function", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Weibull--like distributions form a large class of probability\ndistributions that belong to the domain of attraction for the maxima of the\nGumbel law. Besides the Weibull distribution, it includes important\ndistributions as the Gamma laws and, in particular, the $\\chi^2$ distributions.\nIn order to have explicit expressions of the norming constants for the maxima\nit is necessary to solve asymptotically a nonlinear equation; however, for some\nmembers of that family, numerical and simulation studies show that the\nconstants that are usual suggested are inaccurate for moderate or even large\nsample sizes. In this paper we propose other norming constants computed with\nthe asymptotics of the Lambert W function that significantly improve the\naccuracy of the approximation to the Gumbel law. These results are applied to\nthe computation of the constants for the maxima of Gamma random variables that\nappear in some applied problems.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2013 10:20:22 GMT"}], "update_date": "2013-08-27", "authors_parsed": [["Gasull", "Armengol", ""], ["L\u00f3pez-Salcedo", "Jos\u00e9 A.", ""], ["Utzet", "Frederic", ""]]}, {"id": "1308.5624", "submitter": "Davide Faranda", "authors": "Davide Faranda and Sandro Vaienti", "title": "Extreme Value laws for dynamical systems under observational noise", "comments": null, "journal-ref": null, "doi": "10.1016/j.physd.2014.04.011", "report-no": null, "categories": "math.DS math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we prove the existence of Extreme Value Laws for dynamical\nsystems perturbed by instrument-like-error, also called observational noise. An\norbit perturbed with observational noise mimics the behavior of an\ninstrumentally recorded time series. Instrument characteristics - defined as\nprecision and accuracy - act both by truncating and randomly displacing the\nreal value of a measured observable. Here we analyze both these effects from a\ntheoretical and numerical point of view. First we show that classical extreme\nvalue laws can be found for orbits of dynamical systems perturbed with\nobservational noise. Then we present numerical experiments to support the\ntheoretical findings and give an indication of the order of magnitude of the\ninstrumental perturbations which cause relevant deviations from the extreme\nvalue laws observed in deterministic dynamical systems. Finally, we show that\nthe observational noise preserves the structure of the deterministic attractor.\nThis goes against the common assumption that random transformations cause the\norbits asymptotically fill the ambient space with a loss of information about\nany fractal structures present on the attractor.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2013 16:13:33 GMT"}, {"version": "v2", "created": "Wed, 19 Feb 2014 14:45:07 GMT"}], "update_date": "2015-06-17", "authors_parsed": [["Faranda", "Davide", ""], ["Vaienti", "Sandro", ""]]}, {"id": "1308.5626", "submitter": "Arash Ghasemi", "authors": "A. Ghasemi and L. K. Taylor", "title": "A Progressive Statistical Method for Preconditioning Matrix-Free\n  Solution of High-Order Discretization of Linear Time-Dependent Problems", "comments": null, "journal-ref": "Procedia Computer Science, Volume 80, Pages 2266-2270, 2016", "doi": "10.1016/j.procs.2016.05.406", "report-no": "UTC-CECS-SimCenter-2013-02", "categories": "math.ST cs.NA math.NA stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Preconditioning of a linear system obtained from spectral discretization of\ntime-dependent PDEs often results in a full matrix which is expensive to\ncompute and store specially when the problem size increases. A matrix-free\nimplementation is usually applied to resolve this issue. In this framework,\npreconditioning is typically challenging since the entries of the matrix are\nnot explicitly available. In this short note, we propose a statistical approach\nto gradually create a preconditioner matrix by collecting the information\nobtained from matrix-vector product in the Arnoldi loop of an unpreconditioned\nKrylov subspace algorithm. The gathered information are then correlated using a\nmultiple regressors estimate where the error is assumed to be normally\ndistributed. This procedure yields a banded diagonal matrix which is then used\nas a preconditioner in the next iterative solve. This is repeated between\niterative solves until a good preconditioner is constructed on fly. This\nstatistically iterative procedure is progressive since the fidelity of the\npreconditioning matrix improves by adding more data obtained from matrix-vector\nproduct during the entire solution procedure. The proposed algorithm is\nvalidated for a sample implementation.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2013 16:17:32 GMT"}], "update_date": "2016-06-09", "authors_parsed": [["Ghasemi", "A.", ""], ["Taylor", "L. K.", ""]]}, {"id": "1308.5732", "submitter": "Jinyuan Chang", "authors": "Jinyuan Chang and Song Xi Chen and Xiaohong Chen", "title": "High dimensional generalized empirical likelihood for moment\n  restrictions with dependent data", "comments": null, "journal-ref": "Journal of Econometrics 2015, Vol. 185, No. 1, 283-304", "doi": "10.1016/j.jeconom.2014.10.011", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the maximum generalized empirical likelihood (GEL)\nestimation and inference on parameters identified by high dimensional moment\nrestrictions with weakly dependent data when the dimensions of the moment\nrestrictions and the parameters diverge along with the sample size. The\nconsistency with rates and the asymptotic normality of the GEL estimator are\nobtained by properly restricting the growth rates of the dimensions of the\nparameters and the moment restrictions, as well as the degree of data\ndependence. It is shown that even in the high dimensional time series setting,\nthe GEL ratio can still behave like a chi-square random variable\nasymptotically. A consistent test for the over-identification is proposed. A\npenalized GEL method is also provided for estimation under sparsity setting.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2013 01:22:03 GMT"}, {"version": "v2", "created": "Thu, 6 Mar 2014 02:13:07 GMT"}, {"version": "v3", "created": "Tue, 27 Jan 2015 11:25:00 GMT"}], "update_date": "2015-01-28", "authors_parsed": [["Chang", "Jinyuan", ""], ["Chen", "Song Xi", ""], ["Chen", "Xiaohong", ""]]}, {"id": "1308.5738", "submitter": "Yuan Wang", "authors": "Yuan Wang and Yajun Mei", "title": "Large-Scale Multi-Stream Quickest Change Detection via Shrinkage\n  Post-Change Estimation", "comments": "This is the final version of paper appeared in IEEE on Information\n  Theory", "journal-ref": "Information Theory, IEEE Transactions on 61.12 (2015): 6926-6938", "doi": "10.1109/TIT.2015.2495361", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The quickest change detection problem is considered in the context of\nmonitoring large-scale independent normal distributed data streams with\npossible changes in some of the means. It is assumed that for each individual\nlocal data stream, either there are no local changes, or there is a \"big\" local\nchange that is larger than a pre-specified lower bound. Two different kinds of\nscenarios are studied: one is the sparse post-change case when the unknown\nnumber of affected data streams is much smaller than the total number of data\nstreams, and the other is when all local data streams are affected\nsimultaneously although not necessarily identically. We propose a systematic\napproach to develop efficient global monitoring schemes for quickest change\ndetection by combining hard thresholding with linear shrinkage estimators to\nestimating all post-change parameters simultaneously. Our theoretical analysis\ndemonstrates that the shrinkage estimation can balance the tradeoff between the\nfirst-order and second-order terms of the asymptotic expression on the\ndetection delays, and our numerical simulation studies illustrate the\nusefulness of shrinkage estimation and the challenge of Monte Carlo simulation\nof the average run length to false alarm in the context of online monitoring\nlarge-scale data streams.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2013 02:13:29 GMT"}, {"version": "v2", "created": "Wed, 2 Oct 2013 23:28:23 GMT"}, {"version": "v3", "created": "Wed, 16 Mar 2016 20:13:25 GMT"}], "update_date": "2016-03-18", "authors_parsed": [["Wang", "Yuan", ""], ["Mei", "Yajun", ""]]}, {"id": "1308.5771", "submitter": "Rajesh  Singh", "authors": "Rajesh Singh, Mukesh Kumar and Manoj K. Chaudhary", "title": "Improved Family of Estimators of Population Mean in Simple Random\n  Sampling", "comments": "16 pages, 2 tables", "journal-ref": "WASJ 13(10), 2131-2136", "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a procedure is given for estimating the population mean in\nsimple random sampling without replacement in the presence of auxiliary\ninformation. The mean squared error expressions of the proposed estimators have\nbeen derived under large sample approximation. We have compared the\nperformances of the proposed estimators with several existing estimators. Both\ntheoretical and empirical findings are encouraging and support the soundness of\nthe proposed procedure for mean estimation.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2013 07:08:23 GMT"}], "update_date": "2013-08-28", "authors_parsed": [["Singh", "Rajesh", ""], ["Kumar", "Mukesh", ""], ["Chaudhary", "Manoj K.", ""]]}, {"id": "1308.5773", "submitter": "Rajesh  Singh", "authors": "Rajesh Singh and Florentin Smarandache", "title": "On Improvement in Estimating Population Parameter(s) Using Auxiliary\n  Information", "comments": "63 pages, 8 tables. Educational Publishing & Journal of Matter\n  Regularity (Beijing)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The purpose of writing this book is to suggest some improved estimators using\nauxiliary information in sampling schemes like simple random sampling and\nsystematic sampling.\n  This volume is a collection of five papers. The following problems have been\ndiscussed in the book:\n  In chapter one an estimator in systematic sampling using auxiliary\ninformation is studied in the presence of non-response. In second chapter some\nimproved estimators are suggested using auxiliary information. In third chapter\nsome improved ratio-type estimators are suggested and their properties are\nstudied under second order of approximation.\n  In chapter four and five some estimators are proposed for estimating unknown\npopulation parameter(s) and their properties are studied.\n  This book will be helpful for the researchers and students who are working in\nthe field of finite population estimation.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2013 07:14:04 GMT"}], "update_date": "2013-08-28", "authors_parsed": [["Singh", "Rajesh", ""], ["Smarandache", "Florentin", ""]]}, {"id": "1308.5830", "submitter": "Anthony Cousien", "authors": "St\\'ephan Cl\\'emen\\c{c}on (LTCI), Anthony Cousien (ATIP-Avenir\n  Inserm), Miraine D\\'avila Felipe (LTCI, CIRB), Viet Chi Tran (LPP)", "title": "On Computer-Intensive Simulation and Estimation Methods for Rare Event\n  Analysis in Epidemic Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article focuses, in the context of epidemic models, on rare events that\nmay possibly correspond to crisis situations from the perspective of Public\nHealth. In general, no close analytic form for their occurrence probabilities\nis available and crude Monte-Carlo procedures fail. We show how recent\nintensive computer simulation techniques, such as interacting branching\nparticle methods, can be used for estimation purposes, as well as for\ngenerating model paths that correspond to realizations of such events.\nApplications of these simulation-based methods to several epidemic models are\nalso considered and discussed thoroughly.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2013 11:42:04 GMT"}], "update_date": "2013-08-28", "authors_parsed": [["Cl\u00e9men\u00e7on", "St\u00e9phan", "", "LTCI"], ["Cousien", "Anthony", "", "ATIP-Avenir\n  Inserm"], ["Felipe", "Miraine D\u00e1vila", "", "LTCI, CIRB"], ["Tran", "Viet Chi", "", "LPP"]]}, {"id": "1308.5875", "submitter": "Isambi Mbalawata", "authors": "Isambi S. Mbalawata, Simo S\\\"arkk\\\"a, Matti Vihola and Heikki Haario", "title": "Adaptive Metropolis Algorithm Using Variational Bayesian Adaptive Kalman\n  Filter", "comments": "Research paper: 30 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Markov chain Monte Carlo (MCMC) methods are powerful computational tools for\nanalysis of complex statistical problems. However, their computational\nefficiency is highly dependent on the chosen proposal distribution, which is\ngenerally difficult to find. One way to solve this problem is to use adaptive\nMCMC algorithms which automatically tune the statistics of a proposal\ndistribution during the MCMC run. A new adaptive MCMC algorithm, called the\nvariational Bayesian adaptive Metropolis (VBAM) algorithm, is developed. The\nVBAM algorithm updates the proposal covariance matrix using the variational\nBayesian adaptive Kalman filter (VB-AKF). A strong law of large numbers for the\nVBAM algorithm is proven. The empirical convergence results for three simulated\nexamples and for two real data examples are also provided.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2013 13:54:40 GMT"}, {"version": "v2", "created": "Thu, 19 Jun 2014 04:56:13 GMT"}, {"version": "v3", "created": "Wed, 1 Oct 2014 13:28:05 GMT"}], "update_date": "2014-10-02", "authors_parsed": [["Mbalawata", "Isambi S.", ""], ["S\u00e4rkk\u00e4", "Simo", ""], ["Vihola", "Matti", ""], ["Haario", "Heikki", ""]]}, {"id": "1308.6221", "submitter": "Noemi Petra", "authors": "Noemi Petra, James Martin, Georg Stadler, Omar Ghattas", "title": "A computational framework for infinite-dimensional Bayesian inverse\n  problems: Part II. Stochastic Newton MCMC with application to ice sheet flow\n  inverse problems", "comments": "31 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.NA math.OC math.ST stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the numerical solution of infinite-dimensional inverse problems in\nthe framework of Bayesian inference. In the Part I companion to this paper\n(arXiv.org:1308.1313), we considered the linearized infinite-dimensional\ninverse problem. Here in Part II, we relax the linearization assumption and\nconsider the fully nonlinear infinite-dimensional inverse problem using a\nMarkov chain Monte Carlo (MCMC) sampling method. To address the challenges of\nsampling high-dimensional pdfs arising from Bayesian inverse problems governed\nby PDEs, we build on the stochastic Newton MCMC method. This method exploits\nproblem structure by taking as a proposal density a local Gaussian\napproximation of the posterior pdf, whose construction is made tractable by\ninvoking a low-rank approximation of its data misfit component of the Hessian.\nHere we introduce an approximation of the stochastic Newton proposal in which\nwe compute the low-rank-based Hessian at just the MAP point, and then reuse\nthis Hessian at each MCMC step. We compare the performance of the proposed\nmethod to the original stochastic Newton MCMC method and to an independence\nsampler. The comparison of the three methods is conducted on a synthetic ice\nsheet inverse problem. For this problem, the stochastic Newton MCMC method with\na MAP-based Hessian converges at least as rapidly as the original stochastic\nNewton MCMC method, but is far cheaper since it avoids recomputing the Hessian\nat each step. On the other hand, it is more expensive per sample than the\nindependence sampler; however, its convergence is significantly more rapid, and\nthus overall it is much cheaper. Finally, we present extensive analysis and\ninterpretation of the posterior distribution, and classify directions in\nparameter space based on the extent to which they are informed by the prior or\nthe observations.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2013 17:14:29 GMT"}, {"version": "v2", "created": "Fri, 11 Apr 2014 15:40:14 GMT"}], "update_date": "2014-04-14", "authors_parsed": [["Petra", "Noemi", ""], ["Martin", "James", ""], ["Stadler", "Georg", ""], ["Ghattas", "Omar", ""]]}, {"id": "1308.6306", "submitter": "Houman Owhadi", "authors": "Houman Owhadi, Clint Scovel, Tim Sullivan", "title": "On the Brittleness of Bayesian Inference", "comments": "20 pages, 2 figures. To appear in SIAM Review (Research Spotlights).\n  arXiv admin note: text overlap with arXiv:1304.6772", "journal-ref": "SIAM Rev. 57(4):566--582, 2015", "doi": "10.1137/130938633", "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advent of high-performance computing, Bayesian methods are\nincreasingly popular tools for the quantification of uncertainty throughout\nscience and industry. Since these methods impact the making of sometimes\ncritical decisions in increasingly complicated contexts, the sensitivity of\ntheir posterior conclusions with respect to the underlying models and prior\nbeliefs is a pressing question for which there currently exist positive and\nnegative results. We report new results suggesting that, although Bayesian\nmethods are robust when the number of possible outcomes is finite or when only\na finite number of marginals of the data-generating distribution are unknown,\nthey could be generically brittle when applied to continuous systems (and their\ndiscretizations) with finite information on the data-generating distribution.\nIf closeness is defined in terms of the total variation metric or the matching\nof a finite system of generalized moments, then (1) two practitioners who use\narbitrarily close models and observe the same (possibly arbitrarily large\namount of) data may reach opposite conclusions; and (2) any given prior and\nmodel can be slightly perturbed to achieve any desired posterior conclusions.\nThe mechanism causing brittlenss/robustness suggests that learning and\nrobustness are antagonistic requirements and raises the question of a missing\nstability condition for using Bayesian Inference in a continuous world under\nfinite information.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2013 20:43:55 GMT"}, {"version": "v2", "created": "Thu, 24 Jul 2014 15:23:50 GMT"}, {"version": "v3", "created": "Fri, 10 Apr 2015 17:28:06 GMT"}], "update_date": "2016-05-20", "authors_parsed": [["Owhadi", "Houman", ""], ["Scovel", "Clint", ""], ["Sullivan", "Tim", ""]]}, {"id": "1308.6379", "submitter": "Mun-Chol Kim", "authors": "Mun-Chol Kim and Chol-Kyu Pak", "title": "Backward stochastic differential equations with stopping time as time\n  horizon", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": "KISU-MATH-2013-E-R-026", "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a new method for study on backward stochastic\ndifferential equations with stopping time as time horizon. And using this, we\nshow that some results on backward stochastic differential equations with\nconstant time horizon are generalized to the case of random time horizon.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2013 06:52:45 GMT"}], "update_date": "2013-08-30", "authors_parsed": [["Kim", "Mun-Chol", ""], ["Pak", "Chol-Kyu", ""]]}, {"id": "1308.6392", "submitter": "Chol-Rim Min Mr", "authors": "Chol-Ho Kim and Gwang-Ryong Han", "title": "Minimum survival probabilities in a two-dimensional risk model perturbed\n  by diffusion", "comments": null, "journal-ref": null, "doi": null, "report-no": "KISU-MATH-2013-E-R-011", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider the finite time minimum survival probability and\nultimate minimum survival probability in a two ? dimensional risk modal\nperturbed by diffusion Using some properties of the minimum survival\nprobability we obtain the equation of the finite time minimum survival\nprobability and ultimate minimum survival probability that they are satisfied\nand, the explicit expressions for ultimate minimum survival probability are\ngiven in a special case.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2013 08:14:40 GMT"}], "update_date": "2013-08-30", "authors_parsed": [["Kim", "Chol-Ho", ""], ["Han", "Gwang-Ryong", ""]]}, {"id": "1308.6394", "submitter": "Johanna  Kappus", "authors": "Johanna Kappus", "title": "Adaptive nonparametric estimation for L\\'evy processes observed at low\n  frequency", "comments": "to appear in: Stochastic Processes and their Applications", "journal-ref": "Stochastic Processes and their Applications Volume 124, Issue 1,\n  January 2014, Pages 730--758", "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article deals with adaptive nonparametric estimation for L\\'evy\nprocesses observed at low frequency. For general linear functionals of the\nL\\'evy measure, we construct kernel estimators, provide upper risk bounds and\nderive rates of convergence under regularity assumptions. Our focus lies on the\nadaptive choice of the bandwidth, using model selection techniques. We face\nhere a non-standard problem of model selection with unknown variance. A new\napproach towards this problem is proposed, which also allows a straightforward\ngeneralization to a classical density deconvolution framework.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2013 08:27:22 GMT"}], "update_date": "2014-07-15", "authors_parsed": [["Kappus", "Johanna", ""]]}, {"id": "1308.6443", "submitter": "Mikhail  Ermakov s", "authors": "Mikhail Ermakov", "title": "On asymptotically efficient statistical inference on a signal parameter", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problems of confidence estimation and hypothesis testing on a\nparameter of signal observed in Gaussian white noise. For these problems we\npoint out lower bounds of asymptotic efficiency in the zone of moderate\ndeviation probabilities. These lower bounds are versions of local asymptotic\nminimax Hajek-Le Cam lower bound in estimation and the lower bound for Pitman\nefficiency in hypothesis testing. The lower bounds were obtained for both\nlogarithmic and sharp asymptotic of moderate deviation probabilities.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2013 12:04:38 GMT"}, {"version": "v2", "created": "Sat, 24 Jan 2015 01:58:18 GMT"}], "update_date": "2015-01-27", "authors_parsed": [["Ermakov", "Mikhail", ""]]}, {"id": "1308.6626", "submitter": "Guido Giussani", "authors": "Yanina Gimenez and Guido Giussani", "title": "Searching for the core variables in principal components analysis", "comments": "26 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we introduce a procedure for selecting variables in\nprincipal components analysis. The procedure was developed to identify a small\nsubset of the original variables that best explain the principal components\nthrough nonparametric relationships. There are usually some noisy uninformative\nvariables in a dataset, and some variables that are strongly related to each\nother because of their general interdependence. The procedure is designed to be\nused following the satisfactory initial use of a principal components analysis\nwith all variables, and its aim is to help to interpret underlying structures.\nWe analyze the asymptotic behavior of the method and provide some examples.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2013 23:23:13 GMT"}, {"version": "v2", "created": "Wed, 11 Mar 2015 19:14:02 GMT"}, {"version": "v3", "created": "Wed, 13 Apr 2016 15:56:22 GMT"}, {"version": "v4", "created": "Mon, 30 Jan 2017 18:00:42 GMT"}], "update_date": "2017-01-31", "authors_parsed": [["Gimenez", "Yanina", ""], ["Giussani", "Guido", ""]]}, {"id": "1308.6761", "submitter": "Mark Schervish", "authors": "Mark J. Schervish, Teddy Seidenfeld, Joseph B. Kadane", "title": "Infinite Previsions and Finitely Additive Expectations", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give an extension of de Finetti's concept of coherence to unbounded (but\nreal-valued) random variables that allows for gambling in the presence of\ninfinite previsions. We present a finitely additive extension of the Daniell\nintegral to unbounded random variables that we believe has advantages over\nLebesgue-style integrals in the finitely additive setting. We also give a\ngeneral version of the Fundamental Theorem of Prevision to deal with\nconditional previsions and unbounded random variables.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2013 14:51:27 GMT"}], "update_date": "2013-09-02", "authors_parsed": [["Schervish", "Mark J.", ""], ["Seidenfeld", "Teddy", ""], ["Kadane", "Joseph B.", ""]]}, {"id": "1308.6780", "submitter": "Leonhard Held", "authors": "Leonhard Held, Daniel Saban\\'es Bov\\'e, Isaac Gravestock", "title": "Approximate Bayesian Model Selection with the Deviance Statistic", "comments": "Published at http://dx.doi.org/10.1214/14-STS510 in the Statistical\n  Science (http://www.imstat.org/sts/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Statistical Science 2015, Vol. 30, No. 2, 242-257", "doi": "10.1214/14-STS510", "report-no": "IMS-STS-STS510", "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian model selection poses two main challenges: the specification of\nparameter priors for all models, and the computation of the resulting Bayes\nfactors between models. There is now a large literature on automatic and\nobjective parameter priors in the linear model. One important class are\n$g$-priors, which were recently extended from linear to generalized linear\nmodels (GLMs). We show that the resulting Bayes factors can be approximated by\ntest-based Bayes factors (Johnson [Scand. J. Stat. 35 (2008) 354-368]) using\nthe deviance statistics of the models. To estimate the hyperparameter $g$, we\npropose empirical and fully Bayes approaches and link the former to minimum\nBayes factors and shrinkage estimates from the literature. Furthermore, we\ndescribe how to approximate the corresponding posterior distribution of the\nregression coefficients based on the standard GLM output. We illustrate the\napproach with the development of a clinical prediction model for 30-day\nsurvival in the GUSTO-I trial using logistic regression.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2013 15:51:43 GMT"}, {"version": "v2", "created": "Tue, 8 Jul 2014 08:20:23 GMT"}, {"version": "v3", "created": "Tue, 18 Aug 2015 04:57:55 GMT"}], "update_date": "2016-08-11", "authors_parsed": [["Held", "Leonhard", ""], ["Bov\u00e9", "Daniel Saban\u00e9s", ""], ["Gravestock", "Isaac", ""]]}]