[{"id": "0712.0179", "submitter": "Florence Merlevede", "authors": "J\\'er\\^ome Dedecker (LSTA), Florence Merlev\\`ede (PMA), Emmanuel Rio\n  (LM-Versailles)", "title": "Rates of convergence for minimal distances in the central limit theorem\n  under projective criteria", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": null, "abstract": "  In this paper, we give estimates of ideal or minimal distances between the\ndistribution of the normalized partial sum and the limiting Gaussian\ndistribution for stationary martingale difference sequences or stationary\nsequences satisfying projective criteria. Applications to functions of linear\nprocesses and to functions of expanding maps of the interval are given.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2007 19:20:44 GMT"}], "update_date": "2007-12-04", "authors_parsed": [["Dedecker", "J\u00e9r\u00f4me", "", "LSTA"], ["Merlev\u00e8de", "Florence", "", "PMA"], ["Rio", "Emmanuel", "", "LM-Versailles"]]}, {"id": "0712.0285", "submitter": "Eric Moulines", "authors": "Randal Douc (SAMOVAR), Eric Moulines (LTCI), Ya'Acov Ritov", "title": "Forgetting of the initial condition for the filter in general\n  state-space hidden Markov chain: a coupling approach", "comments": "21", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": null, "abstract": "  We give simple conditions that ensure exponential forgetting of the initial\nconditions of the filter for general state-space hidden Markov chain. The\nproofs are based on the coupling argument applied to the posterior Markov\nkernels. These results are useful both for filtering hidden Markov models using\napproximation methods (e.g., particle filters) and for proving asymptotic\nproperties of estimators. The results are general enough to cover models like\nthe Gaussian state space model, without using the special structure that\npermits the application of the Kalman filter.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2007 13:28:04 GMT"}], "update_date": "2007-12-04", "authors_parsed": [["Douc", "Randal", "", "SAMOVAR"], ["Moulines", "Eric", "", "LTCI"], ["Ritov", "Ya'Acov", ""]]}, {"id": "0712.0576", "submitter": "Thomas Mikosch", "authors": "Martin Jacobsen, Thomas Mikosch, Jan Rosi\\'nski, Gennady Samorodnitsky", "title": "Inverse problems for regular variation of linear filters, a cancellation\n  property for $\\sigma$-finite measures and identification of stable laws", "comments": "Published in at http://dx.doi.org/10.1214/08-AAP540 the Annals of\n  Applied Probability (http://www.imstat.org/aap/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Probability 2009, Vol. 19, No. 1, 210-242", "doi": "10.1214/08-AAP540", "report-no": "IMS-AAP-AAP540", "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider certain $\\sigma$-finite measures which can be\ninterpreted as the output of a linear filter. We assume that these measures\nhave regularly varying tails and study whether the input to the linear filter\nmust have regularly varying tails as well. This turns out to be related to the\npresence of a particular cancellation property in $\\sigma$-finite measures,\nwhich in turn, is related to the uniqueness of the solution of certain\nfunctional equations. The techniques we develop are applied to weighted sums of\ni.i.d. random variables, to products of independent random variables, and to\nstochastic integrals with respect to L\\'evy motions.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2007 17:03:03 GMT"}, {"version": "v2", "created": "Wed, 4 Mar 2009 07:39:20 GMT"}], "update_date": "2009-03-04", "authors_parsed": [["Jacobsen", "Martin", ""], ["Mikosch", "Thomas", ""], ["Rosi\u0144ski", "Jan", ""], ["Samorodnitsky", "Gennady", ""]]}, {"id": "0712.0679", "submitter": "Jean-Marc Bardet", "authors": "Jean-Marc Bardet (CES, Matisse, Samos), Olivier Wintenberger (CES,\n  Matisse, Samos)", "title": "Asymptotic normality of the Quasi Maximum Likelihood Estimator for\n  multidimensional causal processes", "comments": null, "journal-ref": "The Annals of Statistics (2009) 1-32", "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": null, "abstract": "  Strong consistency and asymptotic normality of the Quasi-Maximum Likelihood\nEstimator (QMLE) are given for a general class of multidimensional causal\nprocesses. For particular cases already studied in the literature (for instance\nunivariate or multivariate GARCH, ARCH, ARMA-GARCH processes) the assumptions\nrequired for establishing these results are often weaker than existing\nconditions. The QMLE asymptotic behavior is also given for numerous new\nexamples of univariate or multivariate processes (for instance TARCH or NLARCH\nprocesses).\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2007 10:21:16 GMT"}], "update_date": "2009-01-09", "authors_parsed": [["Bardet", "Jean-Marc", "", "CES, Matisse, Samos"], ["Wintenberger", "Olivier", "", "CES,\n  Matisse, Samos"]]}, {"id": "0712.0721", "submitter": "Jay Bartroff", "authors": "Jay Bartroff", "title": "Asymptotically optimal multistage tests of simple hypotheses", "comments": "Published in at http://dx.doi.org/10.1214/009053607000000235 the\n  Annals of Statistics (http://www.imstat.org/aos/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2007, Vol. 35, No. 5, 2075-2105", "doi": "10.1214/009053607000000235", "report-no": "IMS-AOS-AOS0260", "categories": "math.ST stat.TH", "license": null, "abstract": "  A family of variable stage size multistage tests of simple hypotheses is\ndescribed, based on efficient multistage sampling procedures. Using a loss\nfunction that is a linear combination of sampling costs and error\nprobabilities, these tests are shown to minimize the integrated risk to second\norder as the costs per stage and per observation approach zero. A numerical\nstudy shows significant improvement over group sequential tests in a binomial\ntesting problem.\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2007 13:50:08 GMT"}], "update_date": "2009-09-29", "authors_parsed": [["Bartroff", "Jay", ""]]}, {"id": "0712.0775", "submitter": "Sylvain Arlot", "authors": "Sylvain Arlot, Gilles Blanchard, Etienne Roquain", "title": "Some nonasymptotic results on resampling in high dimension, I:\n  Confidence regions, II: Multiple tests", "comments": "Published in at http://dx.doi.org/10.1214/08-AOS667;\n  http://dx.doi.org/10.1214/08-AOS668 the Annals of Statistics\n  (http://www.imstat.org/aos/) by the Institute of Mathematical Statistics\n  (http://www.imstat.org)", "journal-ref": "The Annals of Statistics 38, 1 (2010) 51-99", "doi": "10.1214/08-AOS667; 10.1214/08-AOS668", "report-no": "IMS-AOS-AOS667; IMS-AOS-AOS668", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study generalized bootstrap confidence regions for the mean of a random\nvector whose coordinates have an unknown dependency structure. The random\nvector is supposed to be either Gaussian or to have a symmetric and bounded\ndistribution. The dimensionality of the vector can possibly be much larger than\nthe number of observations and we focus on a nonasymptotic control of the\nconfidence level, following ideas inspired by recent results in learning\ntheory. We consider two approaches, the first based on a concentration\nprinciple (valid for a large class of resampling weights) and the second on a\nresampled quantile, specifically using Rademacher weights. Several intermediate\nresults established in the approach based on concentration principles are of\ninterest in their own right. We also discuss the question of accuracy when\nusing Monte Carlo approximations of the resampled quantities.\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2007 16:38:59 GMT"}, {"version": "v2", "created": "Mon, 6 Jul 2009 09:30:13 GMT"}, {"version": "v3", "created": "Mon, 11 Jan 2010 10:31:49 GMT"}], "update_date": "2010-07-02", "authors_parsed": [["Arlot", "Sylvain", ""], ["Blanchard", "Gilles", ""], ["Roquain", "Etienne", ""]]}, {"id": "0712.0814", "submitter": "Eric Moulines", "authors": "Valderio Reisen (UFES), Eric Moulines (LTCI), Philippe Soulier\n  (MODAL'X), Glaura Franco", "title": "Log-average periodogram estimator of the memory parameter", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": null, "abstract": "  This paper introduces a semiparametric regression estimator of the memory\nparameter for long-memory time series process. It is based on the regression in\na neighborhood of the zero-frequency of the periodogram averaged over epochs.\nThe proposed estimator is theoretically justified and empirical Monte Carlo\ninvestigation gives evidence that the method is very promising to estimate the\nlong-memory parameter.\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2007 20:10:03 GMT"}], "update_date": "2007-12-06", "authors_parsed": [["Reisen", "Valderio", "", "UFES"], ["Moulines", "Eric", "", "LTCI"], ["Soulier", "Philippe", "", "MODAL'X"], ["Franco", "Glaura", ""]]}, {"id": "0712.0881", "submitter": "Hui Zou", "authors": "Hui Zou, Trevor Hastie, Robert Tibshirani", "title": "On the \"degrees of freedom\" of the lasso", "comments": "Published in at http://dx.doi.org/10.1214/009053607000000127 the\n  Annals of Statistics (http://www.imstat.org/aos/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2007, Vol. 35, No. 5, 2173-2192", "doi": "10.1214/009053607000000127", "report-no": "IMS-AOS-AOS0248", "categories": "math.ST stat.TH", "license": null, "abstract": "  We study the effective degrees of freedom of the lasso in the framework of\nStein's unbiased risk estimation (SURE). We show that the number of nonzero\ncoefficients is an unbiased estimate for the degrees of freedom of the lasso--a\nconclusion that requires no special assumption on the predictors. In addition,\nthe unbiased estimator is shown to be asymptotically consistent. With these\nresults on hand, various model selection criteria--$C_p$, AIC and BIC--are\navailable, which, along with the LARS algorithm, provide a principled and\nefficient approach to obtaining the optimal lasso fit with the computational\neffort of a single ordinary least-squares fit.\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2007 07:22:35 GMT"}], "update_date": "2007-12-18", "authors_parsed": [["Zou", "Hui", ""], ["Hastie", "Trevor", ""], ["Tibshirani", "Robert", ""]]}, {"id": "0712.0892", "submitter": "Bing Li", "authors": "Bing Li, Xiangrong Yin", "title": "On surrogate dimension reduction for measurement error regression: An\n  invariance law", "comments": "Published in at http://dx.doi.org/10.1214/009053607000000172 the\n  Annals of Statistics (http://www.imstat.org/aos/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2007, Vol. 35, No. 5, 2143-2172", "doi": "10.1214/009053607000000172", "report-no": "IMS-AOS-AOS0263", "categories": "math.ST stat.TH", "license": null, "abstract": "  We consider a general nonlinear regression problem where the predictors\ncontain measurement error. It has been recently discovered that several\nwell-known dimension reduction methods, such as OLS, SIR and pHd, can be\nperformed on the surrogate regression problem to produce consistent estimates\nfor the original regression problem involving the unobserved true predictor. In\nthis paper we establish a general invariance law between the surrogate and the\noriginal dimension reduction spaces, which implies that, at least at the\npopulation level, the two dimension reduction problems are in fact equivalent.\nConsequently we can apply all existing dimension reduction methods to\nmeasurement error regression problems. The equivalence holds exactly for\nmultivariate normal predictors, and approximately for arbitrary predictors. We\nalso characterize the rate of convergence for the surrogate dimension reduction\nestimators. Finally, we apply several dimension reduction methods to real and\nsimulated data sets involving measurement error to compare their performances.\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2007 09:06:20 GMT"}], "update_date": "2009-09-29", "authors_parsed": [["Li", "Bing", ""], ["Yin", "Xiangrong", ""]]}, {"id": "0712.0894", "submitter": "Leila Mohammadi", "authors": "Franz Merkl, Leila Mohammadi", "title": "Optimal third root asymptotic bounds in the statistical estimation of\n  thresholds", "comments": "Published in at http://dx.doi.org/10.1214/009053607000000325 the\n  Annals of Statistics (http://www.imstat.org/aos/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2007, Vol. 35, No. 5, 2193-2218", "doi": "10.1214/009053607000000325", "report-no": "IMS-AOS-AOS0271", "categories": "math.ST stat.TH", "license": null, "abstract": "  This paper is concerned with estimating the intersection point of two\ndensities, given a sample of both of the densities. This problem arises in\nclassification theory. The main results provide lower bounds for the\nprobability of the estimation errors to be large on a scale determined by the\ninverse cube root of the sample size. As corollaries, we obtain probabilistic\nbounds for the prediction error in a classification problem. The key to the\nproof is an entropy estimate. The lower bounds are based on bounds for general\nestimators, which are applicable in other contexts as well. Furthermore, we\nintroduce a class of optimal estimators whose errors asymptotically meet the\nborder permitted by the lower bounds.\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2007 09:33:04 GMT"}], "update_date": "2007-12-18", "authors_parsed": [["Merkl", "Franz", ""], ["Mohammadi", "Leila", ""]]}, {"id": "0712.0898", "submitter": "M. Levine", "authors": "Lawrence D. Brown, M. Levine", "title": "Variance estimation in nonparametric regression via the difference\n  sequence method", "comments": "Published in at http://dx.doi.org/10.1214/009053607000000145 the\n  Annals of Statistics (http://www.imstat.org/aos/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2007, Vol. 35, No. 5, 2219-2232", "doi": "10.1214/009053607000000145", "report-no": "IMS-AOS-AOS0252", "categories": "math.ST stat.TH", "license": null, "abstract": "  Consider a Gaussian nonparametric regression problem having both an unknown\nmean function and unknown variance function. This article presents a class of\ndifference-based kernel estimators for the variance function. Optimal\nconvergence rates that are uniform over broad functional classes and bandwidths\nare fully characterized, and asymptotic normality is also established. We also\nshow that for suitable asymptotic formulations our estimators achieve the\nminimax rate.\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2007 09:57:53 GMT"}], "update_date": "2009-09-29", "authors_parsed": [["Brown", "Lawrence D.", ""], ["Levine", "M.", ""]]}, {"id": "0712.0901", "submitter": "Jiming Jiang", "authors": "Jiming Jiang, Yihui Luan, You-Gan Wang", "title": "Iterative estimating equations: Linear convergence and asymptotic\n  properties", "comments": "Published in at http://dx.doi.org/10.1214/009053607000000208 the\n  Annals of Statistics (http://www.imstat.org/aos/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2007, Vol. 35, No. 5, 2233-2260", "doi": "10.1214/009053607000000208", "report-no": "IMS-AOS-AOS0264", "categories": "math.ST stat.TH", "license": null, "abstract": "  We propose an iterative estimating equations procedure for analysis of\nlongitudinal data. We show that, under very mild conditions, the probability\nthat the procedure converges at an exponential rate tends to one as the sample\nsize increases to infinity. Furthermore, we show that the limiting estimator is\nconsistent and asymptotically efficient, as expected. The method applies to\nsemiparametric regression models with unspecified covariances among the\nobservations. In the special case of linear models, the procedure reduces to\niterative reweighted least squares. Finite sample performance of the procedure\nis studied by simulations, and compared with other methods. A numerical example\nfrom a medical study is considered to illustrate the application of the method.\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2007 10:24:50 GMT"}], "update_date": "2007-12-18", "authors_parsed": [["Jiang", "Jiming", ""], ["Luan", "Yihui", ""], ["Wang", "You-Gan", ""]]}, {"id": "0712.0904", "submitter": "Felix Abramovich", "authors": "Felix Abramovich, Vadim Grinshtein, Marianna Pensky", "title": "On optimality of Bayesian testimation in the normal means problem", "comments": "Published in at http://dx.doi.org/10.1214/009053607000000226 the\n  Annals of Statistics (http://www.imstat.org/aos/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2007, Vol. 35, No. 5, 2261-2286", "doi": "10.1214/009053607000000226", "report-no": "IMS-AOS-AOS0254", "categories": "math.ST stat.TH", "license": null, "abstract": "  We consider a problem of recovering a high-dimensional vector $\\mu$ observed\nin white noise, where the unknown vector $\\mu$ is assumed to be sparse. The\nobjective of the paper is to develop a Bayesian formalism which gives rise to a\nfamily of $l_0$-type penalties. The penalties are associated with various\nchoices of the prior distributions $\\pi_n(\\cdot)$ on the number of nonzero\nentries of $\\mu$ and, hence, are easy to interpret. The resulting Bayesian\nestimators lead to a general thresholding rule which accommodates many of the\nknown thresholding and model selection procedures as particular cases\ncorresponding to specific choices of $\\pi_n(\\cdot)$. Furthermore, they achieve\noptimality in a rather general setting under very mild conditions on the prior.\nWe also specify the class of priors $\\pi_n(\\cdot)$ for which the resulting\nestimator is adaptively optimal (in the minimax sense) for a wide range of\nsparse sequences and consider several examples of such priors.\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2007 10:50:15 GMT"}], "update_date": "2007-12-18", "authors_parsed": [["Abramovich", "Felix", ""], ["Grinshtein", "Vadim", ""], ["Pensky", "Marianna", ""]]}, {"id": "0712.0939", "submitter": "Vladimir Spokoiny", "authors": "Denis Belomestny, Vladimir Spokoiny", "title": "Spatial aggregation of local likelihood estimates with applications to\n  classification", "comments": "Published in at http://dx.doi.org/10.1214/009053607000000271 the\n  Annals of Statistics (http://www.imstat.org/aos/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2007, Vol. 35, No. 5, 2287-2311", "doi": "10.1214/009053607000000271", "report-no": "IMS-AOS-AOS0274", "categories": "math.ST stat.TH", "license": null, "abstract": "  This paper presents a new method for spatially adaptive local (constant)\nlikelihood estimation which applies to a broad class of nonparametric models,\nincluding the Gaussian, Poisson and binary response models. The main idea of\nthe method is, given a sequence of local likelihood estimates (``weak''\nestimates), to construct a new aggregated estimate whose pointwise risk is of\norder of the smallest risk among all ``weak'' estimates. We also propose a new\napproach toward selecting the parameters of the procedure by providing the\nprescribed behavior of the resulting estimate in the simple parametric\nsituation. We establish a number of important theoretical results concerning\nthe optimality of the aggregated estimate. In particular, our ``oracle'' result\nclaims that its risk is, up to some logarithmic multiplier, equal to the\nsmallest risk for the given family of estimates. The performance of the\nprocedure is illustrated by application to the classification problem. A\nnumerical study demonstrates its reasonable performance in simulated and\nreal-life examples.\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2007 13:53:29 GMT"}], "update_date": "2007-12-18", "authors_parsed": [["Belomestny", "Denis", ""], ["Spokoiny", "Vladimir", ""]]}, {"id": "0712.1157", "submitter": "Jean-Marc Bardet", "authors": "Jean-Marc Bardet (CES, Matisse, Samos), Imen Kammoun (CES, Matisse,\n  Samos)", "title": "Detecting changes in the fluctuations of a Gaussian process and an\n  application to heartbeat time series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": null, "abstract": "  The aim of this paper is first the detection of multiple abrupt changes of\nthe long-range dependence (respectively self-similarity, local fractality)\nparameters from a sample of a Gaussian stationary times series (respectively\ntime series, continuous-time process having stationary increments). The\nestimator of the $m$ change instants (the number $m$ is supposed to be known)\nis proved to satisfied a limit theorem with an explicit convergence rate.\nMoreover, a central limit theorem is established for an estimator of each\nlong-range dependence (respectively self-similarity, local fractality)\nparameter. Finally, a goodness-of-fit test is also built in each time domain\nwithout change and proved to asymptotically follow a Khi-square distribution.\nSuch statistics are applied to heart rate data of marathon's runners and lead\nto interesting conclusions.\n", "versions": [{"version": "v1", "created": "Fri, 7 Dec 2007 15:19:36 GMT"}], "update_date": "2007-12-10", "authors_parsed": [["Bardet", "Jean-Marc", "", "CES, Matisse, Samos"], ["Kammoun", "Imen", "", "CES, Matisse,\n  Samos"]]}, {"id": "0712.1372", "submitter": "Kshitij Khare", "authors": "Kshitij Khare", "title": "Dynkin's Isomorphism with Sign Structure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": null, "abstract": "  The Dynkin isomorphism associates a Gaussian field to a Markov chain. These\nGaussian fields can be used as priors for prediction and time series analysis.\nDynkin's construction gives Gaussian fields with all non-negative covariances.\nWe extend Dynkin's construction (by introducing a sign structure on the Markov\nchain) to allow general covariance sign patterns.\n", "versions": [{"version": "v1", "created": "Sun, 9 Dec 2007 21:51:19 GMT"}], "update_date": "2007-12-11", "authors_parsed": [["Khare", "Kshitij", ""]]}, {"id": "0712.1456", "submitter": "Imen Kammoun", "authors": "Jean-Marc Bardet (SAMOS, Ces), Imen Kammoun (SAMOS, Ces)", "title": "Detecting abrupt changes of the long-range dependence or the\n  self-similarity of a Gaussian process", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": null, "abstract": "  In this paper, an estimator of $m$ instants ($m$ is known) of abrupt changes\nof the parameter of long-range dependence or self-similarity is proved to\nsatisfy a limit theorem with an explicit convergence rate for a sample of a\nGaussian process. In each estimated zone where the parameter is supposed not to\nchange, a central limit theorem is established for the parameter's (of\nlong-range dependence, self-similarity) estimator and a goodness-of-fit test is\nalso built. {\\it To cite this article: J.M. Bardet, I. Kammoun, C. R. Acad.\nSci. Paris, Ser. I 340 (2007).}\n", "versions": [{"version": "v1", "created": "Mon, 10 Dec 2007 12:27:16 GMT"}, {"version": "v2", "created": "Mon, 28 Apr 2008 06:12:36 GMT"}], "update_date": "2008-04-28", "authors_parsed": [["Bardet", "Jean-Marc", "", "SAMOS, Ces"], ["Kammoun", "Imen", "", "SAMOS, Ces"]]}, {"id": "0712.1654", "submitter": "Lukas Meier", "authors": "Lukas Meier, Peter B\\\"uhlmann", "title": "Smoothing $\\ell_1$-penalized estimators for high-dimensional time-course\n  data", "comments": "Published in at http://dx.doi.org/10.1214/07-EJS103 the Electronic\n  Journal of Statistics (http://www.i-journals.org/ejs/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Electronic Journal of Statistics 2007, Vol. 1, 597-615", "doi": "10.1214/07-EJS103", "report-no": "IMS-EJS-EJS_2007_103", "categories": "math.ST stat.TH", "license": null, "abstract": "  When a series of (related) linear models has to be estimated it is often\nappropriate to combine the different data-sets to construct more efficient\nestimators. We use $\\ell_1$-penalized estimators like the Lasso or the Adaptive\nLasso which can simultaneously do parameter estimation and model selection. We\nshow that for a time-course of high-dimensional linear models the convergence\nrates of the Lasso and of the Adaptive Lasso can be improved by combining the\ndifferent time-points in a suitable way. Moreover, the Adaptive Lasso still\nenjoys oracle properties and consistent variable selection. The finite sample\nproperties of the proposed methods are illustrated on simulated data and on a\nreal problem of motif finding in DNA sequences.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2007 07:00:43 GMT"}], "update_date": "2007-12-18", "authors_parsed": [["Meier", "Lukas", ""], ["B\u00fchlmann", "Peter", ""]]}, {"id": "0712.1673", "submitter": "Joseph Ngatchou-Wandji", "authors": "Joseph Ngatchou-Wandji", "title": "Estimation in a class of nonlinear heteroscedastic time series models", "comments": "Published in at http://dx.doi.org/10.1214/07-EJS157 the Electronic\n  Journal of Statistics (http://www.i-journals.org/ejs/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Electronic Journal of Statistics 2008, Vol. 2, 40-62", "doi": "10.1214/07-EJS157", "report-no": "IMS-EJS-EJS_2007_157", "categories": "math.ST stat.TH", "license": null, "abstract": "  Parameter estimation in a class of heteroscedastic time series models is\ninvestigated. The existence of conditional least-squares and conditional\nlikelihood estimators is proved. Their consistency and their asymptotic\nnormality are established. Kernel estimators of the noise's density and its\nderivatives are defined and shown to be uniformly consistent. A simulation\nexperiment conducted shows that the estimators perform well for large sample\nsize.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2007 10:17:30 GMT"}, {"version": "v2", "created": "Fri, 1 Feb 2008 07:57:08 GMT"}], "update_date": "2008-02-08", "authors_parsed": [["Ngatchou-Wandji", "Joseph", ""]]}, {"id": "0712.1698", "submitter": "Pierre Alquier", "authors": "Pierre Alquier (PMA, Crest)", "title": "PAC-Bayesian Bounds for Randomized Empirical Risk Minimizers", "comments": null, "journal-ref": "Mathematical Methods of Statistics 17, 4 (2008) 279-304", "doi": "10.3103/S1066530708040017", "report-no": null, "categories": "stat.ML math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of this paper is to generalize the PAC-Bayesian theorems proved by\nCatoni in the classification setting to more general problems of statistical\ninference. We show how to control the deviations of the risk of randomized\nestimators. A particular attention is paid to randomized estimators drawn in a\nsmall neighborhood of classical estimators, whose study leads to control the\nrisk of the latter. These results allow to bound the risk of very general\nestimation procedures, as well as to perform model selection.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2007 12:40:41 GMT"}, {"version": "v2", "created": "Tue, 4 Nov 2008 10:37:52 GMT"}, {"version": "v3", "created": "Fri, 9 Jan 2009 15:13:19 GMT"}], "update_date": "2009-01-09", "authors_parsed": [["Alquier", "Pierre", "", "PMA, Crest"]]}, {"id": "0712.1922", "submitter": "Fanny Godet", "authors": "Fanny Godet (LMJL)", "title": "Prediction of long memory processes on same-realisation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": null, "abstract": "  For the class of stationary Gaussian long memory processes, we study some\nproperties of the least-squares predictor of X_{n+1} based on (X_n, ..., X_1).\nThe predictor is obtained by projecting X_{n+1} onto the finite past and the\ncoefficients of the predictor are estimated on the same realisation. First we\nprove moment bounds for the inverse of the empirical covariance matrix. Then we\ndeduce an asymptotic expression of the mean-squared error. In particular we\ngive a relation between the number of terms used to estimate the coefficients\nand the number of past terms used for prediction, which ensures the L^2-sense\nconvergence of the predictor. Finally we prove a central limit theorem when our\npredictor converges to the best linear predictor based on all the past.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2007 13:00:35 GMT"}, {"version": "v2", "created": "Thu, 14 Feb 2008 14:32:21 GMT"}], "update_date": "2008-02-14", "authors_parsed": [["Godet", "Fanny", "", "LMJL"]]}, {"id": "0712.1936", "submitter": "Fabrice Gamboa", "authors": "Fabrice Gamboa, Jean-Michel Loubes, Elie Maza", "title": "Semi-parametric estimation of shifts", "comments": "Published in at http://dx.doi.org/10.1214/07-EJS026 the Electronic\n  Journal of Statistics (http://www.i-journals.org/ejs/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Electronic Journal of Statistics 2007, Vol. 1, 616-640", "doi": "10.1214/07-EJS026", "report-no": "IMS-EJS-EJS_2007_26", "categories": "math.ST stat.TH", "license": null, "abstract": "  We observe a large number of functions differing from each other only by a\ntranslation parameter. While the main pattern is unknown, we propose to\nestimate the shift parameters using $M$-estimators. Fourier transform enables\nto transform this statistical problem into a semi-parametric framework. We\nstudy the convergence of the estimator and provide its asymptotic behavior.\nMoreover, we use the method in the applied case of velocity curve forecasting.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2007 13:37:41 GMT"}], "update_date": "2007-12-18", "authors_parsed": [["Gamboa", "Fabrice", ""], ["Loubes", "Jean-Michel", ""], ["Maza", "Elie", ""]]}, {"id": "0712.2881", "submitter": "Denes Petz", "authors": "Denes Petz, V.E. Sandor Szabo", "title": "From quasi-entropy to skew information", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.FA math-ph math.MP math.ST stat.TH", "license": null, "abstract": "  This paper gives an overview about particular quasi-entropies, generalized\nquantum covariances, quantum Fisher informations, skew-informations and their\nrelations. The point is the dependence on operator monotone functions. It is\nproven that a skew-information is the Hessian of a quasi-entropy. The\nskew-information and some inequalities are extended to a von Neumann algebra\nsetting.\n", "versions": [{"version": "v1", "created": "Tue, 18 Dec 2007 05:30:21 GMT"}], "update_date": "2007-12-19", "authors_parsed": [["Petz", "Denes", ""], ["Szabo", "V. E. Sandor", ""]]}, {"id": "0712.2912", "submitter": "Jonas Kahn", "authors": "Jonas Kahn", "title": "Model selection for quantum homodyne tomography", "comments": "40 pages, 2 figures, submitted to ESAIM: Probability and Statistics", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": null, "abstract": "  This paper deals with a non-parametric problem coming from physics, namely\nquantum tomography. That consists in determining the quantum state of a mode of\nlight through a homodyne measurement. We apply several model selection\nprocedures: penalized projection estimators, where we may use pattern functions\nor wavelets, and penalized maximum likelihood estimators. In all these cases,\nwe get oracle inequalities. In the former we also have a polynomial rate of\nconvergence for the non-parametric problem. We finish the paper with\napplications of similar ideas to the calibration of a photocounter, a\nmeasurement apparatus counting the number of photons in a beam. Here the\nmathematical problem reduces similarly to a non-parametric missing data\nproblem. We again get oracle inequalities, and better speed if the photocounter\nis good.\n", "versions": [{"version": "v1", "created": "Tue, 18 Dec 2007 09:56:03 GMT"}], "update_date": "2007-12-19", "authors_parsed": [["Kahn", "Jonas", ""]]}, {"id": "0712.3056", "submitter": "Alicia Johnson", "authors": "Alicia A. Johnson and Galin L. Jones", "title": "Gibbs Sampling for a Bayesian Hierarchical General Linear Model", "comments": "20 pages, 1 figure, submitted to Electronic Journal of Statistics", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a Bayesian hierarchical version of the normal theory general\nlinear model which is practically relevant in the sense that it is general\nenough to have many applications and it is not straightforward to sample\ndirectly from the corresponding posterior distribution. Thus we study a block\nGibbs sampler that has the posterior as its invariant distribution. In\nparticular, we establish that the Gibbs sampler converges at a geometric rate.\nThis allows us to establish conditions for a central limit theorem for the\nergodic averages used to estimate features of the posterior. Geometric\nergodicity is also a key component for using batch means methods to\nconsistently estimate the variance of the asymptotic normal distribution.\nTogether, our results give practitioners the tools to be as confident in\ninferences based on the observations from the Gibbs sampler as they would be\nwith inferences based on random samples from the posterior. Our theoretical\nresults are illustrated with an application to data on the cost of health plans\nissued by health maintenance organizations.\n", "versions": [{"version": "v1", "created": "Tue, 18 Dec 2007 21:12:02 GMT"}, {"version": "v2", "created": "Thu, 15 May 2008 15:10:31 GMT"}, {"version": "v3", "created": "Mon, 27 Oct 2008 16:37:29 GMT"}, {"version": "v4", "created": "Sat, 17 Oct 2009 19:53:46 GMT"}, {"version": "v5", "created": "Thu, 21 Jan 2010 23:04:50 GMT"}], "update_date": "2010-01-22", "authors_parsed": [["Johnson", "Alicia A.", ""], ["Jones", "Galin L.", ""]]}, {"id": "0712.3231", "submitter": "Olivier Wintenberger", "authors": "Paul Doukhan (CREST, CES), Olivier Wintenberger (CES, SAMOS)", "title": "Weakly dependent chains with infinite memory", "comments": "Stochastic Processes and their Applications (2008) accept\\'e", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": null, "abstract": "  We prove the existence of a weakly dependent strictly stationary solution of\nthe equation $ X_t=F(X_{t-1},X_{t-2},X_{t-3},...;\\xi_t)$ called {\\em chain with\ninfinite memory}. Here the {\\em innovations} $\\xi_t$ constitute an independent\nand identically distributed sequence of random variables. The function $F$\ntakes values in some Banach space and satisfies a Lipschitz-type condition. We\nalso study the interplay between the existence of moments and the rate of decay\nof the Lipschitz coefficients of the function $F$. With the help of the weak\ndependence properties, we derive Strong Laws of Large Number, a Central Limit\nTheorem and a Strong Invariance Principle.\n", "versions": [{"version": "v1", "created": "Wed, 19 Dec 2007 16:47:55 GMT"}], "update_date": "2007-12-20", "authors_parsed": [["Doukhan", "Paul", "", "CREST, CES"], ["Wintenberger", "Olivier", "", "CES, SAMOS"]]}, {"id": "0712.3432", "submitter": "M. Nikulin", "authors": "V. Bagdonavi\\v{c}ius, I. Masiulaityt\\.e, M. Nikulin", "title": "Statistical analysis of redundant systems with \"warm\" stand-by units", "comments": "To appear in a Special Volume of Stochastics: An International\n  Journal of Probability and Stochastic Processes\n  (http://www.informaworld.com/openurl?genre=journal%26issn=1744-2508) edited\n  by N.H. Bingham and I.V. Evstigneev which will be reprinted as Volume 57 of\n  the IMS Lecture Notes Monograph Series\n  (http://imstat.org/publications/lecnotes.htm)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": null, "abstract": "  Mathematical formulation of fluent switching from \"warm\" to \"hot\" conditions\nof standby units is given using the well known Sedyakin's and accelerated\nfailure time (AFT) models. Non-parametric estimators of cumulative distribution\nfunction and mean failure time of a redundant system with several stand-by\nunits are proposed. Goodness-of-fit tests for two given models are given.\n", "versions": [{"version": "v1", "created": "Thu, 20 Dec 2007 14:22:17 GMT"}], "update_date": "2008-01-03", "authors_parsed": [["Bagdonavi\u010dius", "V.", ""], ["Masiulaityt\u0117", "I.", ""], ["Nikulin", "M.", ""]]}, {"id": "0712.3451", "submitter": "Wolfgang Wefelmeyer", "authors": "Ursula U. M\\\"uller, Anton Schick, Wolfgang Wefelmeyer", "title": "Optimality of estimators for misspecified semi-Markov models", "comments": "To appear in a Special Volume of Stochastics: An International\n  Journal of Probability and Stochastic Processes\n  (http://www.informaworld.com/openurl?genre=journal%26issn=1744-2508) edited\n  by N.H. Bingham and I.V. Evstigneev which will be reprinted as Volume 57 of\n  the IMS Lecture Notes Monograph Series\n  (http://imstat.org/publications/lecnotes.htm)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": null, "abstract": "  Suppose we observe a geometrically ergodic semi-Markov process and have a\nparametric model for the transition distribution of the embedded Markov chain,\nfor the conditional distribution of the inter-arrival times, or for both. The\nfirst two models for the process are semiparametric, and the parameters can be\nestimated by conditional maximum likelihood estimators. The third model for the\nprocess is parametric, and the parameter can be estimated by an unconditional\nmaximum likelihood estimator. We determine heuristically the asymptotic\ndistributions of these estimators and show that they are asymptotically\nefficient. If the parametric models are not correct, the (conditional) maximum\nlikelihood estimators estimate the parameter that maximizes the\nKullback--Leibler information. We show that they remain asymptotically\nefficient in a nonparametric sense.\n", "versions": [{"version": "v1", "created": "Thu, 20 Dec 2007 15:11:03 GMT"}], "update_date": "2007-12-21", "authors_parsed": [["M\u00fcller", "Ursula U.", ""], ["Schick", "Anton", ""], ["Wefelmeyer", "Wolfgang", ""]]}, {"id": "0712.3618", "submitter": "Aiyou Chen", "authors": "Aiyou Chen, Jin Cao, and Tian Bu", "title": "Network Tomography: Identifiability and Fourier Domain Estimation", "comments": "21 pages", "journal-ref": "IEEE INFOCOM 2007, p.1875-1883", "doi": "10.1109/INFCOM.2007.218", "report-no": null, "categories": "stat.ME math.ST stat.AP stat.CO stat.TH", "license": null, "abstract": "  The statistical problem for network tomography is to infer the distribution\nof $\\mathbf{X}$, with mutually independent components, from a measurement model\n$\\mathbf{Y}=A\\mathbf{X}$, where $A$ is a given binary matrix representing the\nrouting topology of a network under consideration. The challenge is that the\ndimension of $\\mathbf{X}$ is much larger than that of $\\mathbf{Y}$ and thus the\nproblem is often called ill-posed. This paper studies some statistical aspects\nof network tomography. We first address the identifiability issue and prove\nthat the $\\mathbf{X}$ distribution is identifiable up to a shift parameter\nunder mild conditions. We then use a mixture model of characteristic functions\nto derive a fast algorithm for estimating the distribution of $\\mathbf{X}$\nbased on the General method of Moments. Through extensive model simulation and\nreal Internet trace driven simulation, the proposed approach is shown to be\nfavorable comparing to previous methods using simple discretization for\ninferring link delays in a heterogeneous network.\n", "versions": [{"version": "v1", "created": "Fri, 21 Dec 2007 03:47:28 GMT"}], "update_date": "2007-12-24", "authors_parsed": [["Chen", "Aiyou", ""], ["Cao", "Jin", ""], ["Bu", "Tian", ""]]}, {"id": "0712.3735", "submitter": "Fabienne Comte", "authors": "Fabienne Comte (MAP5), Valentine Genon-Catalot (MAP5), Yves Rozenholc\n  (MAP5)", "title": "Nonparametric estimation for a stochastic volatility model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": null, "abstract": "  Consider discrete time observations (X_{\\ell\\delta})_{1\\leq \\ell \\leq n+1}$\nof the process $X$ satisfying $dX_t= \\sqrt{V_t} dB_t$, with $V_t$ a\none-dimensional positive diffusion process independent of the Brownian motion\n$B$. For both the drift and the diffusion coefficient of the unobserved\ndiffusion $V$, we propose nonparametric least square estimators, and provide\nbounds for theirrisk. Estimators are chosen among a collection of functions\nbelonging to a finite dimensional space whose dimension is selected by a data\ndriven procedure. Implementation on simulated data illustrates how the method\nworks.\n", "versions": [{"version": "v1", "created": "Fri, 21 Dec 2007 16:17:25 GMT"}], "update_date": "2007-12-25", "authors_parsed": [["Comte", "Fabienne", "", "MAP5"], ["Genon-Catalot", "Valentine", "", "MAP5"], ["Rozenholc", "Yves", "", "MAP5"]]}, {"id": "0712.4250", "submitter": "Nikolai Gagunashvili", "authors": "N. D. Gagunashvili", "title": "Goodness of fit tests for weighted histograms", "comments": "15 pages, 5 figures, changed content", "journal-ref": "Nuclear Instruments and Methods in Physics Research A 596 (2008)\n  439-445", "doi": "10.1016/j.nima.2008.08.144", "report-no": null, "categories": "physics.data-an math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Weighted histogram in Monte-Carlo simulations is often used for the\nestimation of a probability density function. It is obtained as a result of\nrandom experiment with random events that have weights. In this paper the bin\ncontents of weighted histogram are considered as a sum of random variables with\nrandom number of terms. Goodness of fit tests for weighted histograms and for\nweighted histograms with unknown normalization are proposed. Sizes and powers\nof the tests are investigated numerically.\n", "versions": [{"version": "v1", "created": "Thu, 27 Dec 2007 16:38:04 GMT"}, {"version": "v2", "created": "Thu, 19 Jun 2008 10:11:03 GMT"}], "update_date": "2008-11-28", "authors_parsed": [["Gagunashvili", "N. D.", ""]]}, {"id": "0712.4276", "submitter": "Robert Adler", "authors": "Robert J. Adler, Gennady Samorodnitsky, Jonathan E. Taylor", "title": "Excursion sets of stable random fields", "comments": "35 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": null, "abstract": "  Studying the geometry generated by Gaussian and Gaussian- related random\nfields via their excursion sets is now a well developed and well understood\nsubject. The purely non-Gaussian scenario has, however, not been studied at\nall. In this paper we look at three classes of stable random fields, and obtain\nasymptotic formulae for the mean values of various geometric characteristics of\ntheir excursion sets over high levels.\n  While the formulae are asymptotic, they contain enough information to show\nthat not only do stable random fields exhibit geometric behaviour very\ndifferent from that of Gaussian fields, but they also differ significantly\namong themselves.\n", "versions": [{"version": "v1", "created": "Thu, 27 Dec 2007 20:05:54 GMT"}], "update_date": "2007-12-28", "authors_parsed": [["Adler", "Robert J.", ""], ["Samorodnitsky", "Gennady", ""], ["Taylor", "Jonathan E.", ""]]}, {"id": "0712.4323", "submitter": "Bent J{\\o}rgensen", "authors": "Bent J{\\o}rgensen, Yuri Goegebeur and Jos\\'e Ra\\'ul Mart\\'inez", "title": "Dispersion Models for Extremes", "comments": "23 pages. Abstract submitted to the 56th Session of the ISI, Lisboa,\n  2007", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": null, "abstract": "  We propose extreme value analogues of natural exponential families and\nexponential dispersion models, and introduce the slope function as an analogue\nof the variance function. The set of quadratic and power slope functions\ncharacterize well-known families such as the Rayleigh, Gumbel, power, Pareto,\nlogistic, negative exponential, Weibull and Fr\\'echet. We show a convergence\ntheorem for slope functions, by which we may express the classical extreme\nvalue convergence results in terms of asymptotics for extreme dispersion\nmodels. The main idea is to explore the parallels between location families and\nnatural exponential families, and between the convolution and minimum\noperations.\n", "versions": [{"version": "v1", "created": "Fri, 28 Dec 2007 09:56:24 GMT"}], "update_date": "2007-12-31", "authors_parsed": [["J\u00f8rgensen", "Bent", ""], ["Goegebeur", "Yuri", ""], ["Mart\u00ednez", "Jos\u00e9 Ra\u00fal", ""]]}]