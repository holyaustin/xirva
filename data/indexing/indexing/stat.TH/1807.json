[{"id": "1807.00070", "submitter": "Tobias Schwedes", "authors": "Tobias Schwedes, Ben Calderhead", "title": "Quasi Markov Chain Monte Carlo Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quasi-Monte Carlo (QMC) methods for estimating integrals are attractive since\nthe resulting estimators typically converge at a faster rate than pseudo-random\nMonte Carlo. However, they can be difficult to set up on arbitrary posterior\ndensities within the Bayesian framework, in particular for inverse problems. We\nintroduce a general parallel Markov chain Monte Carlo (MCMC) framework, for\nwhich we prove a law of large numbers and a central limit theorem. In that\ncontext, non-reversible transitions are investigated. We then extend this\napproach to the use of adaptive kernels and state conditions, under which\nergodicity holds. As a further extension, an importance sampling estimator is\nderived, for which asymptotic unbiasedness is proven. We consider the use of\ncompletely uniformly distributed (CUD) numbers within the above mentioned\nalgorithms, which leads to a general parallel quasi-MCMC (QMCMC) methodology.\nWe prove consistency of the resulting estimators and demonstrate numerically\nthat this approach scales close to $n^{-2}$ as we increase parallelisation,\ninstead of the usual $n^{-1}$ that is typical of standard MCMC algorithms. In\npractical statistical models we observe multiple orders of magnitude\nimprovement compared with pseudo-random methods.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jun 2018 21:11:50 GMT"}, {"version": "v2", "created": "Wed, 5 Sep 2018 12:41:36 GMT"}, {"version": "v3", "created": "Tue, 2 Oct 2018 11:15:19 GMT"}], "update_date": "2018-10-03", "authors_parsed": [["Schwedes", "Tobias", ""], ["Calderhead", "Ben", ""]]}, {"id": "1807.00305", "submitter": "Olivier Binette", "authors": "Olivier Binette and Simon Guillotte", "title": "Bayesian Nonparametrics for Directional Statistics", "comments": "29 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a density basis of the trigonometric polynomials that is\nsuitable to mixture modelling. Statistical and geometric properties are\nderived, suggesting it as a circular analogue to the Bernstein polynomial\ndensities. Nonparametric priors are constructed using this basis and a\nsimulation study shows that the use of the resulting Bayes estimator may\nprovide gains over comparable circular density estimators previously suggested\nin the literature. From a theoretical point of view, we propose a general prior\nspecification framework for density estimation on compact metric space using\nsieve priors. This is tailored to density bases such as the one considered\nherein and may also be used to exploit their particular shape-preserving\nproperties. Furthermore, strong posterior consistency is shown to hold under\nnotably weak regularity assumptions and adaptative convergence rates are\nobtained in terms of the approximation properties of positive linear operators\ngenerating our models.\n", "versions": [{"version": "v1", "created": "Sun, 1 Jul 2018 10:12:38 GMT"}, {"version": "v2", "created": "Wed, 16 Jan 2019 19:09:19 GMT"}, {"version": "v3", "created": "Mon, 25 Feb 2019 16:48:54 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Binette", "Olivier", ""], ["Guillotte", "Simon", ""]]}, {"id": "1807.00337", "submitter": "Simone Padoan PhD", "authors": "Michael Falk, Amir Khorrami and Simone A. Padoan", "title": "Records for Some Stationary Dependent Sequences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For a zero-mean, unit-variance second-order stationary univariate Gaussian\nprocess we derive the probability that a record at the time $n$, say $X_n$,\ntakes place and derive its distribution function. We study the joint\ndistribution of the arrival time process of records and the distribution of the\nincrements between the first and second record, and the third and second record\nand we compute the expected number of records. We also consider two consecutive\nand non-consecutive records, one at time $j$ and one at time $n$ and we derive\nthe probability that the joint records $(X_j,X_n)$ occur as well as their\ndistribution function. The probability that the records $X_n$ and $(X_j,X_n)$\ntake place and the arrival time of the $n$-th record, are independent of the\nmarginal distribution function, provided that it is continuous. These results\nactually hold for a second-order stationary process with Gaussian copulas. We\nextend some of these results to the case of a multivariate Gaussian process.\nFinally, for a strictly stationary process satisfying some mild conditions on\nthe tail behavior of the common marginal distribution function $F$ and the\nlong-range dependence of the extremes of the process, we derive the asymptotic\nprobability that the record $X_n$ occurs and derive its distribution function.\n", "versions": [{"version": "v1", "created": "Sun, 1 Jul 2018 14:43:08 GMT"}, {"version": "v2", "created": "Tue, 7 Aug 2018 11:44:08 GMT"}], "update_date": "2018-08-08", "authors_parsed": [["Falk", "Michael", ""], ["Khorrami", "Amir", ""], ["Padoan", "Simone A.", ""]]}, {"id": "1807.00347", "submitter": "Edgar Dobriban", "authors": "Edgar Dobriban, Weijie J. Su", "title": "Robust Inference Under Heteroskedasticity via the Hadamard Estimator", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Drawing statistical inferences from large datasets in a model-robust way is\nan important problem in statistics and data science. In this paper, we propose\nmethods that are robust to large and unequal noise in different observational\nunits (i.e., heteroskedasticity) for statistical inference in linear\nregression. We leverage the Hadamard estimator, which is unbiased for the\nvariances of ordinary least-squares regression. This is in contrast to the\npopular White's sandwich estimator, which can be substantially biased in high\ndimensions. We propose to estimate the signal strength, noise level,\nsignal-to-noise ratio, and mean squared error via the Hadamard estimator. We\ndevelop a new degrees of freedom adjustment that gives more accurate confidence\nintervals than variants of White's sandwich estimator. Moreover, we provide\nconditions ensuring the estimator is well-defined, by studying a new random\nmatrix ensemble in which the entries of a random orthogonal projection matrix\nare squared. We also show approximate normality, using the second-order\nPoincare inequality. Our work provides improved statistical theory and methods\nfor linear regression in high dimensions.\n", "versions": [{"version": "v1", "created": "Sun, 1 Jul 2018 15:55:25 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Dobriban", "Edgar", ""], ["Su", "Weijie J.", ""]]}, {"id": "1807.00891", "submitter": "Alexander Wein", "authors": "Amelia Perry and Alexander S. Wein and Afonso S. Bandeira and Ankur\n  Moitra", "title": "Optimality and Sub-optimality of PCA I: Spiked Random Matrix Models", "comments": "67 pages, 3 figures. This is the journal version of part I of\n  arXiv:1609.05573, accepted to the Annals of Statistics. This version includes\n  the supplementary material as appendices", "journal-ref": "Ann. Statist., Volume 46, Number 5 (2018), 2416-2451", "doi": "10.1214/17-AOS1625", "report-no": null, "categories": "math.ST cs.DS cs.IT math.IT math.PR stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A central problem of random matrix theory is to understand the eigenvalues of\nspiked random matrix models, introduced by Johnstone, in which a prominent\neigenvector (or \"spike\") is planted into a random matrix. These distributions\nform natural statistical models for principal component analysis (PCA) problems\nthroughout the sciences. Baik, Ben Arous and Peche showed that the spiked\nWishart ensemble exhibits a sharp phase transition asymptotically: when the\nspike strength is above a critical threshold, it is possible to detect the\npresence of a spike based on the top eigenvalue, and below the threshold the\ntop eigenvalue provides no information. Such results form the basis of our\nunderstanding of when PCA can detect a low-rank signal in the presence of\nnoise. However, under structural assumptions on the spike, not all information\nis necessarily contained in the spectrum. We study the statistical limits of\ntests for the presence of a spike, including non-spectral tests. Our results\nleverage Le Cam's notion of contiguity, and include:\n  i) For the Gaussian Wigner ensemble, we show that PCA achieves the optimal\ndetection threshold for certain natural priors for the spike.\n  ii) For any non-Gaussian Wigner ensemble, PCA is sub-optimal for detection.\nHowever, an efficient variant of PCA achieves the optimal threshold (for\nnatural priors) by pre-transforming the matrix entries.\n  iii) For the Gaussian Wishart ensemble, the PCA threshold is optimal for\npositive spikes (for natural priors) but this is not always the case for\nnegative spikes.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2018 21:11:57 GMT"}, {"version": "v2", "created": "Fri, 13 Jul 2018 03:30:03 GMT"}], "update_date": "2018-08-29", "authors_parsed": [["Perry", "Amelia", ""], ["Wein", "Alexander S.", ""], ["Bandeira", "Afonso S.", ""], ["Moitra", "Ankur", ""]]}, {"id": "1807.00915", "submitter": "Anastasia Papavasiliou", "authors": "Theodoros Manikas and Anastasia Papavasiliou", "title": "Diffusion Parameter Estimation for the Homogenized Equation", "comments": "25 pages, 2 figures. Based on the PhD thesis of T. Manikas\n  (Department of Statistics, University of Warwick)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We construct a novel estimator for the diffusion coefficient of the limiting\nhomogenized equation, when observing the slow dynamics of a multiscale model,\nin the case when the slow dynamics are of bounded variation. Previous research\nsuggests subsampling the data on fixed intervals and computing the\ncorresponding quadratic variation. However, to achieve optimality, this\napproach requires knowledge of scale separation variable $\\epsilon$. Instead,\nwe suggest computing the quadratic variation corresponding to the local extrema\nof the slow process. Our approach results to a natural subsampling and avoids\nthe issue of choosing a subsampling rate. We prove that the estimator is\nasymptotically unbiased and we numerically demonstrate that its $L_2$-error is\nof order ${\\mathcal O}(\\epsilon^2)$.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2018 22:17:15 GMT"}], "update_date": "2018-07-04", "authors_parsed": [["Manikas", "Theodoros", ""], ["Papavasiliou", "Anastasia", ""]]}, {"id": "1807.01251", "submitter": "Zhiqin Xu", "authors": "Zhi-Qin John Xu, Yaoyu Zhang, Yanyang Xiao", "title": "Training behavior of deep neural network in frequency domain", "comments": "To appear in 2019 26th-International conference of neural information\n  processing (ICONIP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IT math.IT math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Why deep neural networks (DNNs) capable of overfitting often generalize well\nin practice is a mystery [#zhang2016understanding]. To find a potential\nmechanism, we focus on the study of implicit biases underlying the training\nprocess of DNNs. In this work, for both real and synthetic datasets, we\nempirically find that a DNN with common settings first quickly captures the\ndominant low-frequency components, and then relatively slowly captures the\nhigh-frequency ones. We call this phenomenon Frequency Principle (F-Principle).\nThe F-Principle can be observed over DNNs of various structures, activation\nfunctions, and training algorithms in our experiments. We also illustrate how\nthe F-Principle help understand the effect of early-stopping as well as the\ngeneralization of DNNs. This F-Principle potentially provides insights into a\ngeneral principle underlying DNN optimization and generalization.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2018 15:50:41 GMT"}, {"version": "v2", "created": "Tue, 21 Aug 2018 17:53:43 GMT"}, {"version": "v3", "created": "Sat, 3 Nov 2018 05:54:32 GMT"}, {"version": "v4", "created": "Mon, 8 Apr 2019 21:46:34 GMT"}, {"version": "v5", "created": "Fri, 7 Jun 2019 07:26:27 GMT"}, {"version": "v6", "created": "Fri, 1 Nov 2019 02:21:14 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Xu", "Zhi-Qin John", ""], ["Zhang", "Yaoyu", ""], ["Xiao", "Yanyang", ""]]}, {"id": "1807.01296", "submitter": "Fabrizio Antenucci", "authors": "Fabrizio Antenucci, Florent Krzakala, Pierfrancesco Urbani and Lenka\n  Zdeborov\\'a", "title": "Approximate Survey Propagation for Statistical Inference", "comments": "37 pages, 14 figures", "journal-ref": "J. Stat. Mech. (2019) 023401", "doi": "10.1088/1742-5468/aafa7d", "report-no": null, "categories": "cond-mat.dis-nn cond-mat.stat-mech cs.IT math.IT math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Approximate message passing algorithm enjoyed considerable attention in the\nlast decade. In this paper we introduce a variant of the AMP algorithm that\ntakes into account glassy nature of the system under consideration. We coin\nthis algorithm as the approximate survey propagation (ASP) and derive it for a\nclass of low-rank matrix estimation problems. We derive the state evolution for\nthe ASP algorithm and prove that it reproduces the one-step replica symmetry\nbreaking (1RSB) fixed-point equations, well-known in physics of disordered\nsystems. Our derivation thus gives a concrete algorithmic meaning to the 1RSB\nequations that is of independent interest. We characterize the performance of\nASP in terms of convergence and mean-squared error as a function of the free\nParisi parameter s. We conclude that when there is a model mismatch between the\ntrue generative model and the inference model, the performance of AMP rapidly\ndegrades both in terms of MSE and of convergence, while ASP converges in a\nlarger regime and can reach lower errors. Among other results, our analysis\nleads us to a striking hypothesis that whenever s (or other parameters) can be\nset in such a way that the Nishimori condition $M=Q>0$ is restored, then the\ncorresponding algorithm is able to reach mean-squared error as low as the\nBayes-optimal error obtained when the model and its parameters are known and\nexactly matched in the inference procedure.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2018 17:28:01 GMT"}], "update_date": "2019-02-07", "authors_parsed": [["Antenucci", "Fabrizio", ""], ["Krzakala", "Florent", ""], ["Urbani", "Pierfrancesco", ""], ["Zdeborov\u00e1", "Lenka", ""]]}, {"id": "1807.01470", "submitter": "Guillermo Durand", "authors": "Guillermo Durand (LPSM UMR 8001), Gilles Blanchard, Pierre Neuvial\n  (IMT), Etienne Roquain (LPSM UMR 8001)", "title": "Post hoc false positive control for spatially structured hypotheses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a high dimensional multiple testing framework, we present new confidence\nbounds on the false positives contained in subsets S of selected null\nhypotheses. The coverage probability holds simultaneously over all subsets S,\nwhich means that the obtained confidence bounds are post hoc. Therefore, S can\nbe chosen arbitrarily, possibly by using the data set several times. We focus\nin this paper specifically on the case where the null hypotheses are spatially\nstructured. Our method is based on recent advances in post hoc inference and\nparticularly on the general methodology of Blanchard et al. (2017); we build\nconfidence bounds for some pre-specified forest-structured subsets {R k , k\n$\\in$ K}, called the reference family, and then we deduce a bound for any\nsubset S by interpolation. The proposed bounds are shown to improve\nsubstantially previous ones when the signal is locally structured. Our findings\nare supported both by theoretical results and numerical experiments. Moreover,\nwe show that our bound can be obtained by a low-complexity algorithm, which\nmakes our approach completely operational for a practical use. The proposed\nbounds are implemented in the open-source R package sansSouci.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2018 07:42:33 GMT"}, {"version": "v2", "created": "Wed, 19 Sep 2018 09:52:06 GMT"}], "update_date": "2018-09-20", "authors_parsed": [["Durand", "Guillermo", "", "LPSM UMR 8001"], ["Blanchard", "Gilles", "", "IMT"], ["Neuvial", "Pierre", "", "IMT"], ["Roquain", "Etienne", "", "LPSM UMR 8001"]]}, {"id": "1807.01666", "submitter": "Sheng Wu", "authors": "Sheng Wu, Yi Zhang, Jun Zhao, Liming Shen", "title": "Conditional Tail-Related Risk Estimation Using Composite Asymmetric\n  Least Squares and Empirical Likelihood", "comments": "41 pages, 5 tables, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, by using composite asymmetric least squares (CALS) and\nempirical likelihood, we propose a two-step procedure to estimate the\nconditional value at risk (VaR) and conditional expected shortfall (ES) for the\nGARCH series. First, we perform asymmetric least square regressions at several\nsignificance levels to model the volatility structure and separate it from the\ninnovation process in the GARCH model. Note that expectile can serve as a bond\nto make up the gap from VaR estimation to ES estimation because there exists a\nbijective mapping from expectiles to specific quantile, and ES can be induced\nby expectile through a simple formula. Then, we introduce the empirical\nlikelihood method to determine the relation above; this method is data-driven\nand distribution-free. Theoretical studies guarantee the asymptotic properties,\nsuch as consistency and the asymptotic normal distribution of the estimator\nobtained by our proposed method. A Monte Carlo experiment and an empirical\napplication are conducted to evaluate the performance of the proposed method.\nThe results indicate that our proposed estimation method is competitive with\nsome alternative existing tail-related risk estimation methods.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2018 16:13:36 GMT"}], "update_date": "2018-07-05", "authors_parsed": [["Wu", "Sheng", ""], ["Zhang", "Yi", ""], ["Zhao", "Jun", ""], ["Shen", "Liming", ""]]}, {"id": "1807.02003", "submitter": "Stefan Roth", "authors": "Jochen Gl\\\"uck, Stefan Roth, Evgeny Spodarev", "title": "A solution to a linear integral equation with an application to\n  statistics of infinitely divisible moving averages", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For a stationary moving average random field, a non-parametric low frequency\nestimator of the L\\'evy density of its infinitely divisible independently\nscattered integrator measure is given. The plug-in estimate is based on the\nsolution $w$ of the linear integral equation $v(x) = \\int_{\\mathbb{R}^d} g(s)\nw(h(s)x)ds$, where $g,h:\\mathbb{R}^d \\rightarrow \\mathbb{R}$ are given\nmeasurable functions and $v$ is a (weighted) $L^2$-function on $\\mathbb{R}$. We\ninvestigate conditions for the existence and uniqueness of this solution and\ngive $L^2$-error bounds for the resulting estimates. An application to pure\njump moving averages and a simulation study round off the paper.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jul 2018 13:44:25 GMT"}, {"version": "v2", "created": "Fri, 7 Sep 2018 08:20:46 GMT"}, {"version": "v3", "created": "Wed, 20 Feb 2019 06:31:41 GMT"}, {"version": "v4", "created": "Wed, 5 Feb 2020 18:01:14 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Gl\u00fcck", "Jochen", ""], ["Roth", "Stefan", ""], ["Spodarev", "Evgeny", ""]]}, {"id": "1807.02038", "submitter": "Miguel del \\'Alamo", "authors": "Miguel del \\'Alamo, Housen Li, Axel Munk", "title": "Frame-constrained Total Variation Regularization for White Noise\n  Regression", "comments": "27 pages main text, 7 pages appendix, 2 figures. In this updated\n  version we have simplied the proof of the upper bound and extended the\n  convergence to the complete range $q\\in[1,\\infty)$ of $L^q$ risks, rather\n  than the range $q\\in(1,1+2/d]$ that we had in the first version. Further, the\n  rates in the extended range are shown to be minimax optimal", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the popularity and practical success of total variation (TV)\nregularization for function estimation, surprisingly little is known about its\ntheoretical performance in a statistical setting. While TV regularization has\nbeen known for quite some time to be minimax optimal for denoising\none-dimensional signals, for higher dimensions this remains elusive until\ntoday. In this paper we consider frame-constrained TV estimators including many\nwell-known (overcomplete) frames in a white noise regression model, and prove\ntheir minimax optimality w.r.t. $L^q$-risk ($1\\leq q<\\infty$) up to a\nlogarithmic factor in any dimension $d\\geq 1$. Overcomplete frames are an\nestablished tool in mathematical imaging and signal recovery, and their\ncombination with TV regularization has been shown to give excellent results in\npractice, which our theory now confirms. Our results rely on a novel connection\nbetween frame-constraints and certain Besov norms, and on an interpolation\ninequality to relate them to the risk functional.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jul 2018 14:58:00 GMT"}, {"version": "v2", "created": "Mon, 6 May 2019 09:38:13 GMT"}, {"version": "v3", "created": "Thu, 9 May 2019 07:36:03 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["del \u00c1lamo", "Miguel", ""], ["Li", "Housen", ""], ["Munk", "Axel", ""]]}, {"id": "1807.02363", "submitter": "Pablo Gregori", "authors": "Ahmed Arafat, Pablo Gregori and Emilio Porcu", "title": "Schoenberg coefficients and curvature at the origin of continuous\n  isotropic positive definite kernels on spheres", "comments": "18 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.FA stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the class $\\Psi_d$ of continuous functions $\\psi \\colon [0,\\pi]\n\\to \\mathbb{R}$, with $\\psi(0)=1$ such that the associated isotropic kernel\n$C(\\xi,\\eta)= \\psi(\\theta(\\xi,\\eta))$ ---with $\\xi,\\eta \\in \\mathbb{S}^d$ and\n$\\theta$ the geodesic distance--- is positive definite on the product of two\n$d$-dimensional spheres $\\mathbb{S}^d$. We face Problems 1 and 3 proposed in\nthe essay Gneiting (2013b). We have considered an extension that encompasses\nthe solution of Problem 1 solved in Fiedler (2013), regarding the expression of\nthe $d$-Schoenberg coefficients of members of $\\Psi_d$ as combinations of\n$1$-Schoenberg coefficients. We also give expressions for the computation of\nSchoenberg coefficients of the exponential and Askey families for all even\ndimensions through recurrence formula. Problem 3 regards the curvature at the\norigin of members of $\\Psi_d$ of local support. We have improved the current\nbounds for determining this curvature, which is of applied interest at least\nfor $d=2$.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jul 2018 11:37:09 GMT"}], "update_date": "2018-07-09", "authors_parsed": [["Arafat", "Ahmed", ""], ["Gregori", "Pablo", ""], ["Porcu", "Emilio", ""]]}, {"id": "1807.03141", "submitter": "Juan Carlos Cort\\'es J.-C. Cort\\'es", "authors": "J. Calatayud, J.-C. Cort\\'es, M. Jornet", "title": "Improving the approximation of the first and second order statistics of\n  the response process to the random Legendre differential equation", "comments": "13 pages; 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we deal with uncertainty quantification for the random\nLegendre differential equation, with input coefficient $A$ and initial\nconditions $X_0$ and $X_1$. In a previous study [Calbo G. et al, Comput. Math.\nAppl., 61(9), 2782--2792 (2011)], a mean square convergent power series\nsolution on $(-1/e,1/e)$ was constructed, under the assumptions of mean fourth\nintegrability of $X_0$ and $X_1$, independence, and at most exponential growth\nof the absolute moments of $A$. In this paper, we relax these conditions to\nconstruct an $\\mathrm{L}^p$ solution ($1\\leq p\\leq\\infty$) to the random\nLegendre differential equation on the whole domain $(-1,1)$, as in its\ndeterministic counterpart. Our hypotheses assume no independence and less\nintegrability of $X_0$ and $X_1$. Moreover, the growth condition on the moments\nof $A$ is characterized by the boundedness of $A$, which simplifies the proofs\nsignificantly. We also provide approximations of the expectation and variance\nof the response process. The numerical experiments show the wide applicability\nof our findings. A comparison with Monte Carlo simulations and gPC expansions\nis performed.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2018 19:12:06 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Calatayud", "J.", ""], ["Cort\u00e9s", "J. -C.", ""], ["Jornet", "M.", ""]]}, {"id": "1807.03184", "submitter": "Emeline Perthame", "authors": "Emilie Devijver and Emeline Perthame", "title": "Prediction regions through Inverse Regression", "comments": "25 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predict a new response from a covariate is a challenging task in regression,\nwhich raises new question since the era of high-dimensional data. In this\npaper, we are interested in the inverse regression method from a theoretical\nviewpoint. Theoretical results have already been derived for the well-known\nlinear model, but recently, the curse of dimensionality has increased the\ninterest of practitioners and theoreticians into generalization of those\nresults for various estimators, calibrated for the high-dimension context. To\ndeal with high-dimensional data, inverse regression is used in this paper. It\nis known to be a reliable and efficient approach when the number of features\nexceeds the number of observations. Indeed, under some conditions, dealing with\nthe inverse regression problem associated to a forward regression problem\ndrastically reduces the number of parameters to estimate and make the problem\ntractable. When both the responses and the covariates are multivariate,\nestimators constructed by the inverse regression are studied in this paper, the\nmain result being explicit asymptotic prediction regions for the response. The\nperformances of the proposed estimators and prediction regions are also\nanalyzed through a simulation study and compared with usual estimators.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jul 2018 14:15:11 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Devijver", "Emilie", ""], ["Perthame", "Emeline", ""]]}, {"id": "1807.03234", "submitter": "Dominik Reinhard", "authors": "Dominik Reinhard, Michael Fauss, Abdelhak M. Zoubir", "title": "Bayesian Sequential Joint Detection and Estimation", "comments": "35 pages, 2 figures, accepted for publication in Sequential Analysis", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Joint detection and estimation refers to deciding between two or more\nhypotheses and, depending on the test outcome, simultaneously estimating the\nunknown parameters of the underlying distribution. This problem is investigated\nin a sequential framework under mild assumptions on the underlying random\nprocess. We formulate an unconstrained sequential decision problem, whose cost\nfunction is the weighted sum of the expected run-length and the\ndetection/estimation errors. Then, a strong connection between the derivatives\nof the cost function with respect to the weights, which can be interpreted as\nLagrange multipliers, and the detection/estimation errors of the underlying\nscheme is shown. This property is used to characterize the solution of a\nclosely related sequential decision problem, whose objective function is the\nexpected run-length under constraints on the average detection/estimation\nerrors. We show that the solution of the constrained problem coincides with the\nsolution of the unconstrained problem with suitably chosen weights. These\nweights are characterized as the solution of a linear program, which can be\nsolved using efficient off-the-shelf solvers. The theoretical results are\nillustrated with two example problems, for which optimal sequential schemes are\ndesigned numerically and whose performance is validated via Monte Carlo\nsimulations.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jul 2018 15:34:21 GMT"}, {"version": "v2", "created": "Thu, 15 Nov 2018 17:45:26 GMT"}, {"version": "v3", "created": "Mon, 26 Nov 2018 11:09:35 GMT"}, {"version": "v4", "created": "Thu, 18 Apr 2019 10:08:41 GMT"}], "update_date": "2019-04-19", "authors_parsed": [["Reinhard", "Dominik", ""], ["Fauss", "Michael", ""], ["Zoubir", "Abdelhak M.", ""]]}, {"id": "1807.03439", "submitter": "Bo Ning", "authors": "Bo Ning, Seonghyun Jeong and Subhashis Ghosal", "title": "Bayesian Linear Regression for Multivariate Responses Under Group\n  Sparsity", "comments": "36 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We study frequentist properties of a Bayesian high-dimensional multivariate\nlinear regression model with correlated responses. The predictors are separated\ninto many groups and the group structure is pre-determined. Two features of the\nmodel are unique: (i) group sparsity is imposed on the predictors. (ii) the\ncovariance matrix is unknown and its dimensions can also be high. We choose a\nproduct of independent spike-and-slab priors on the regression coefficients and\na new prior on the covariance matrix based on its eigendecomposition. Each\nspike-and-slab prior is a mixture of a point mass at zero and a multivariate\ndensity involving a $\\ell_{2,1}$-norm. We first obtain the posterior\ncontraction rate, the bounds on the effective dimension of the model with high\nposterior probabilities. We then show that the multivariate regression\ncoefficients can be recovered under certain compatibility conditions. Finally,\nwe quantify the uncertainty for the regression coefficients with frequentist\nvalidity through a Bernstein-von Mises type theorem. The result leads to\nselection consistency for the Bayesian method. We derive the posterior\ncontraction rate using the general theory by constructing a suitable test from\nthe first principle using moment bounds for certain likelihood ratios. This\nleads to posterior concentration around the truth with respect to the average\nR\\'enyi divergence of order 1/2. This technique of obtaining the required tests\nfor posterior contraction rate could be useful in many other problems.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2018 01:26:52 GMT"}, {"version": "v2", "created": "Wed, 25 Jul 2018 22:38:54 GMT"}, {"version": "v3", "created": "Tue, 11 Jun 2019 21:53:48 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Ning", "Bo", ""], ["Jeong", "Seonghyun", ""], ["Ghosal", "Subhashis", ""]]}, {"id": "1807.03469", "submitter": "Yang Feng", "authors": "Sihan Huang and Yang Feng", "title": "Pairwise Covariates-adjusted Block Model for Community Detection", "comments": "41 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.AP stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most fundamental problems in network study is community detection.\nThe stochastic block model (SBM) is one widely used model for network data with\ndifferent estimation methods developed with their community detection\nconsistency results unveiled. However, the SBM is restricted by the strong\nassumption that all nodes in the same community are stochastically equivalent,\nwhich may not be suitable for practical applications. We introduce a pairwise\ncovariates-adjusted stochastic block model (PCABM), a generalization of SBM\nthat incorporates pairwise covariate information. We study the maximum\nlikelihood estimates of the coefficients for the covariates as well as the\ncommunity assignments. It is shown that both the coefficient estimates of the\ncovariates and the community assignments are consistent under suitable sparsity\nconditions. Spectral clustering with adjustment (SCWA) is introduced to\nefficiently solve PCABM. Under certain conditions, we derive the error bound of\ncommunity estimation under SCWA and show that it is community detection\nconsistent. PCABM compares favorably with the SBM or degree-corrected\nstochastic block model (DCBM) under a wide range of simulated and real networks\nwhen covariate information is accessible.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2018 03:37:55 GMT"}, {"version": "v2", "created": "Sat, 20 Jun 2020 18:01:26 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Huang", "Sihan", ""], ["Feng", "Yang", ""]]}, {"id": "1807.03482", "submitter": "Xingguang Chen", "authors": "Xingguang Chen", "title": "Generalized uncertain theory: concepts and fundamental principles", "comments": "10 pages,2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although there are many mathematical theories to address uncertain phenomena\nhowever, these theories are presented under implicit presupposition that\nuncertainty of objects is accurately measurable while not considering that the\nmeasure of uncertainty itself may be inaccurate. Considering this evident but\ncritical overlook, on the basis of reviewing and commenting several widely used\nmathematical theories of uncertainty, the fundamental concepts and axiomatic\nsystem of generalized uncertain theory (GUT)are proposed for the purpose of\ndescribing and analyzing that imprecision of objects has inaccurate attributes.\nWe show that current main stream theories of studying uncertain phenomena, such\nas probability theory, fuzzy mathematics, etc., are the special cases of\ngeneralized uncertain theory. So the generalized uncertain theory could cover\nprevious main stream theories of studying uncertainty. Further research\ndirections and possible application realms are discussed. It may be a\nbeneficial endeavor for enriching and developing current uncertainty\nmathematical theories.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2018 05:12:35 GMT"}, {"version": "v2", "created": "Sat, 21 Jul 2018 14:11:14 GMT"}, {"version": "v3", "created": "Wed, 25 Jul 2018 02:31:58 GMT"}, {"version": "v4", "created": "Mon, 1 Oct 2018 09:04:20 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Chen", "Xingguang", ""]]}, {"id": "1807.03527", "submitter": "Joris Mooij", "authors": "Thijs van Ommen, Joris M. Mooij", "title": "Algebraic Equivalence of Linear Structural Equation Models", "comments": "Published in (online) Proceedings of the 33rd Annual Conference on\n  Uncertainty in Artificial Intelligence (UAI-17)", "journal-ref": "Proceedings of the 33rd Annual Conference on Uncertainty in\n  Artificial Intelligence, 2017", "doi": null, "report-no": null, "categories": "math.ST cs.AI cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite their popularity, many questions about the algebraic constraints\nimposed by linear structural equation models remain open problems. For causal\ndiscovery, two of these problems are especially important: the enumeration of\nthe constraints imposed by a model, and deciding whether two graphs define the\nsame statistical model. We show how the half-trek criterion can be used to make\nprogress in both of these problems. We apply our theoretical results to a\nsmall-scale model selection problem, and find that taking the additional\nalgebraic constraints into account may lead to significant improvements in\nmodel selection accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2018 08:38:37 GMT"}], "update_date": "2018-07-11", "authors_parsed": [["van Ommen", "Thijs", ""], ["Mooij", "Joris M.", ""]]}, {"id": "1807.03706", "submitter": "Xiaohong Lan", "authors": "Xiaohong Lan and Yimin Xiao", "title": "H\\\"older Conditions of Local Times and Exact Moduli of\n  non-differentiability for Spherical Gaussian fields", "comments": "23 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigate the local times and modulus of nondifferentiability of\nthe spherical Gaussian random fields. We extend the methods for studying the\nlocal times of Gaussian to the spherical setting. The new main ingredient is\nthe property of strong local nondeterminism established recently in Lan et al\n(2018).\n", "versions": [{"version": "v1", "created": "Sun, 8 Jul 2018 14:47:24 GMT"}], "update_date": "2018-07-11", "authors_parsed": [["Lan", "Xiaohong", ""], ["Xiao", "Yimin", ""]]}, {"id": "1807.03829", "submitter": "Mengyang Gu", "authors": "Mengyang Gu, Fangzheng Xie and Long Wang", "title": "A theoretical framework of the scaled Gaussian stochastic process in\n  prediction and calibration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model calibration or data inversion is one of fundamental tasks in\nuncertainty quantification. In this work, we study the theoretical properties\nof the scaled Gaussian stochastic process (S-GaSP), to model the discrepancy\nbetween reality and imperfect mathematical models. We establish the explicit\nconnection between Gaussian stochastic process (GaSP) and S-GaSP through the\northogonal series representation. The predictive mean estimator in the S-GaSP\ncalibration model converges to the reality at the same rate as the GaSP with a\nsuitable choice of the regularization and scaling parameters. We also show the\ncalibrated mathematical model in the S-GaSP calibration converges to the one\nthat minimizes the $L_2$ loss between the reality and mathematical model,\nwhereas the GaSP model with other widely used covariance functions does not\nhave this property. Numerical examples confirm the excellent finite sample\nperformance of our approaches compared to a few recent approaches.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2018 19:02:30 GMT"}, {"version": "v2", "created": "Sun, 2 Aug 2020 16:40:12 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Gu", "Mengyang", ""], ["Xie", "Fangzheng", ""], ["Wang", "Long", ""]]}, {"id": "1807.03981", "submitter": "Robert Gaunt", "authors": "Robert E. Gaunt", "title": "A note on the distribution of the product of zero mean correlated normal\n  random variables", "comments": "4 pages. To appear in Statistica Neerlandica, 2018+", "journal-ref": "Statistica Neerlandica 73 (2019), pp. 176-179", "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of finding an explicit formula for the probability density\nfunction of two zero mean correlated normal random variables dates back to\n1936. Perhaps surprisingly, this problem was not resolved until 2016. This is\nall the more surprising given that a very simple proof is available, which is\nthe subject of this note; we identify the product of two zero mean correlated\nnormal random variables as a variance-gamma random variable, from which an\nexplicit formula for probability density function is immediate.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2018 07:59:24 GMT"}], "update_date": "2019-04-05", "authors_parsed": [["Gaunt", "Robert E.", ""]]}, {"id": "1807.03997", "submitter": "Luc Lehericy", "authors": "Luc Leh\\'ericy (JAD)", "title": "Nonasymptotic control of the MLE for misspecified nonparametric hidden\n  Markov models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finite state space hidden Markov models are flexible tools to model phenomena\nwith complex time dependencies: any process distribution can be approximated by\na hidden Markov model with enough hidden states.We consider the problem of\nestimating an unknown process distribution using nonparametric hidden Markov\nmodels in the misspecified setting, that is when the data-generating process\nmay not be a hidden Markov model.We show that when the true distribution is\nexponentially mixing and satisfies a forgetting assumption, the maximum\nlikelihood estimator recovers the best approximation of the true distribution.\nWe prove a finite sample bound on the resulting error and show that it is\noptimal in the minimax sense--up to logarithmic factors--when the model is well\nspecified.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2018 08:36:01 GMT"}, {"version": "v2", "created": "Mon, 15 Feb 2021 09:09:54 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Leh\u00e9ricy", "Luc", "", "JAD"]]}, {"id": "1807.04021", "submitter": "Remi Gribonval", "authors": "R\\'emi Gribonval (PANAMA), Mila Nikolova (CMLA)", "title": "On bayesian estimation and proximity operators", "comments": "This work and the companion paper [10] are dedicated to the memory of\n  Mila Nikolova, who passed away prematurely in June 2018. Mila dedicated much\n  of her energy to bring the technical content to completion during the spring\n  of 2018. The first author did his best to finalize the papers as Mila would\n  have wished. He should be held responsible for any possible imperfection in\n  the final manuscript", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are two major routes to address the ubiquitous family of inverse\nproblems appearing in signal and image processing, such as denoising or\ndeblurring. A first route relies on Bayesian modeling, where prior\nprobabilities are used to embody models of both the distribution of the unknown\nvariables and their statistical dependence with the observed data. The\nestimation process typically relies on the minimization of an expected loss\n(e.g. minimum mean squared error, or MMSE). The second route has received much\nattention in the context of sparse regularization and compressive sensing: it\nconsists in designing (often convex) optimization problems involving the sum of\na data fidelity term and a penalty term promoting certain types of unknowns\n(e.g., sparsity, promoted through an 1 norm). Well known relations between\nthese two approaches have lead to some widely spread misconceptions. In\nparticular, while the so-called Maximum A Posterori (MAP) estimate with a\nGaussian noise model does lead to an optimization problem with a quadratic\ndata-fidelity term, we disprove through explicit examples the common belief\nthat the converse would be true. It has already been shown [7, 9] that for\ndenoising in the presence of additive Gaussian noise, for any prior probability\non the unknowns, MMSE estimation can be expressed as a penalized least squares\nproblem, with the apparent characteristics of a MAP estimation problem with\nGaussian noise and a (generally) different prior on the unknowns. In other\nwords, the variational approach is rich enough to build all possible MMSE\nestimators associated to additive Gaussian noise via a well chosen penalty. We\ngeneralize these results beyond Gaussian denoising and characterize noise\nmodels for which the same phenomenon occurs. In particular, we prove that with\n(a variant of) Poisson noise and any prior probability on the unknowns, MMSE\nestimation can again be expressed as the solution of a penalized least squares\noptimization problem. For additive scalar denois-ing the phenomenon holds if\nand only if the noise distribution is log-concave. In particular, Laplacian\ndenoising can (perhaps surprisingly) be expressed as the solution of a\npenalized least squares problem. In the multivariate case, the same phenomenon\noccurs when the noise model belongs to a particular subset of the exponential\nfamily. For multivariate additive denoising, the phenomenon holds if and only\nif the noise is white and Gaussian.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2018 09:22:11 GMT"}, {"version": "v2", "created": "Thu, 12 Jul 2018 08:00:18 GMT"}], "update_date": "2018-07-13", "authors_parsed": [["Gribonval", "R\u00e9mi", "", "PANAMA"], ["Nikolova", "Mila", "", "CMLA"]]}, {"id": "1807.04209", "submitter": "Weijie J. Su", "authors": "Cynthia Dwork and Weijie J. Su and Li Zhang", "title": "Differentially Private False Discovery Rate Control", "comments": "To appear in The Journal of Privacy and Confidentiality", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differential privacy provides a rigorous framework for privacy-preserving\ndata analysis. This paper proposes the first differentially private procedure\nfor controlling the false discovery rate (FDR) in multiple hypothesis testing.\nInspired by the Benjamini-Hochberg procedure (BHq), our approach is to first\nrepeatedly add noise to the logarithms of the $p$-values to ensure differential\nprivacy and to select an approximately smallest $p$-value serving as a\npromising candidate at each iteration; the selected $p$-values are further\nsupplied to the BHq and our private procedure releases only the rejected ones.\nMoreover, we develop a new technique that is based on a backward submartingale\nfor proving FDR control of a broad class of multiple testing procedures,\nincluding our private procedure, and both the BHq step-up and step-down\nprocedures. As a novel aspect, the proof works for arbitrary dependence between\nthe true null and false null test statistics, while FDR control is maintained\nup to a small multiplicative factor.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2018 15:53:09 GMT"}, {"version": "v2", "created": "Sat, 3 Jul 2021 16:24:37 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Dwork", "Cynthia", ""], ["Su", "Weijie J.", ""], ["Zhang", "Li", ""]]}, {"id": "1807.04211", "submitter": "Johannes Wiesel", "authors": "Jan Obloj, Johannes Wiesel", "title": "Robust estimation of superhedging prices", "comments": "This work will appear in the Annals of Statistics. The above version\n  merges the main paper to appear in print and its online supplement", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider statistical estimation of superhedging prices using historical\nstock returns in a frictionless market with d traded assets. We introduce a\nplugin estimator based on empirical measures and show it is consistent but\nlacks suitable robustness. To address this we propose novel estimators which\nuse a larger set of martingale measures defined through a tradeoff between the\nradius of Wasserstein balls around the empirical measure and the allowed norm\nof martingale densities. We establish consistency and robustness of these\nestimators and argue that they offer a superior performance relative to the\nplugin estimator. We generalise the results by replacing the superhedging\ncriterion with acceptance relative to a risk measure. We further extend our\nstudy, in part, to the case of markets with traded options, to a multiperiod\nsetting and to settings with model uncertainty. We also study convergence rates\nof estimators and convergence of superhedging strategies.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2018 15:53:59 GMT"}, {"version": "v2", "created": "Mon, 6 Apr 2020 14:50:52 GMT"}, {"version": "v3", "created": "Tue, 7 Apr 2020 04:54:50 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Obloj", "Jan", ""], ["Wiesel", "Johannes", ""]]}, {"id": "1807.04272", "submitter": "Philip White", "authors": "Philip White, Emilio Porcu", "title": "Towards a Complete Picture of Stationary Covariance Functions on Spheres\n  Cross Time", "comments": null, "journal-ref": "The Electronic Journal of Statistics, 13(2), 2566-2594, (2019)", "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advent of wide-spread global and continental-scale spatiotemporal\ndatasets, increased attention has been given to covariance functions on spheres\nover time. This paper provides results for stationary covariance functions of\nrandom fields defined over $d$-dimensional spheres cross time. Specifically, we\nprovide a bridge between the characterization in \\cite{berg-porcu} for\ncovariance functions on spheres cross time and Gneiting's lemma\n\\citep{gneiting2002} that deals with planar surfaces.\n  We then prove that there is a valid class of covariance functions similar in\nform to the Gneiting class of space-time covariance functions\n\\citep{gneiting2002} that replaces the squared Euclidean distance with the\ngreat circle distance. Notably, the provided class is shown to be positive\ndefinite on every $d$-dimensional sphere cross time, while the Gneiting class\nis positive definite over $\\R^d \\times \\R$ for fixed $d$ only.\n  In this context, we illustrate the value of our adapted Gneiting class by\ncomparing examples from this class to currently established nonseparable\ncovariance classes using out-of-sample predictive criteria. These comparisons\nare carried out on two climate reanalysis datasets from the National Centers\nfor Environmental Prediction and National Center for Atmospheric Research. For\nthese datasets, we show that examples from our covariance class have better\npredictive performance than competing models.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2018 13:26:02 GMT"}, {"version": "v2", "created": "Thu, 13 Jun 2019 17:17:59 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["White", "Philip", ""], ["Porcu", "Emilio", ""]]}, {"id": "1807.04426", "submitter": "Mingao Yuan", "authors": "Mingao Yuan, Yang Feng and Zuofeng Shang", "title": "A likelihood-ratio type test for stochastic block models with bounded\n  degrees", "comments": "In this new submission, we add a comment in introduction stating that\n  > the classic test based on counting the $k_n$-cycles with >\n  $k_n=\\log^{1/4}{n}$ is unrealistic in practice, which is also the >\n  motivation of our regularized LR test", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fundamental problem in network data analysis is to test Erd\\\"{o}s-R\\'{e}nyi\nmodel $\\mathcal{G}\\left(n,\\frac{a+b}{2n}\\right)$ versus a bisection stochastic\nblock model $\\mathcal{G}\\left(n,\\frac{a}{n},\\frac{b}{n}\\right)$, where $a,b>0$\nare constants that represent the expected degrees of the graphs and $n$ denotes\nthe number of nodes. This problem serves as the foundation of many other\nproblems such as testing-based methods for determining the number of\ncommunities (\\cite{BS16,L16}) and community detection (\\cite{MS16}). Existing\nwork has been focusing on growing-degree regime $a,b\\to\\infty$\n(\\cite{BS16,L16,MS16,BM17,B18,GL17a,GL17b}) while leaving the bounded-degree\nregime untreated. In this paper, we propose a likelihood-ratio (LR) type\nprocedure based on regularization to test stochastic block models with bounded\ndegrees. We derive the limit distributions as power Poisson laws under both\nnull and alternative hypotheses, based on which the limit power of the test is\ncarefully analyzed. We also examine a Monte-Carlo method that partly resolves\nthe computational cost issue. The proposed procedures are examined by both\nsimulated and real-world data. The proof depends on a contiguity theory\ndeveloped by Janson \\cite{J95}.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2018 05:05:09 GMT"}, {"version": "v2", "created": "Fri, 23 Nov 2018 02:21:09 GMT"}], "update_date": "2018-11-26", "authors_parsed": [["Yuan", "Mingao", ""], ["Feng", "Yang", ""], ["Shang", "Zuofeng", ""]]}, {"id": "1807.04429", "submitter": "Miles Lopes", "authors": "Miles E. Lopes, Zhenhua Lin, Hans-Georg Mueller", "title": "Bootstrapping Max Statistics in High Dimensions: Near-Parametric Rates\n  Under Weak Variance Decay and Application to Functional and Multinomial Data", "comments": "64 pages; to appear in The Annals of Statistics, 2019+", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, bootstrap methods have drawn attention for their ability to\napproximate the laws of \"max statistics\" in high-dimensional problems. A\nleading example of such a statistic is the coordinate-wise maximum of a sample\naverage of $n$ random vectors in $\\mathbb{R}^p$. Existing results for this\nstatistic show that the bootstrap can work when $n\\ll p$, and rates of\napproximation (in Kolmogorov distance) have been obtained with only logarithmic\ndependence in $p$. Nevertheless, one of the challenging aspects of this setting\nis that established rates tend to scale like $n^{-1/6}$ as a function of $n$.\n  The main purpose of this paper is to demonstrate that improvement in rate is\npossible when extra model structure is available. Specifically, we show that if\nthe coordinate-wise variances of the observations exhibit decay, then a nearly\n$n^{-1/2}$ rate can be achieved, independent of $p$. Furthermore, a surprising\naspect of this dimension-free rate is that it holds even when the decay is very\nweak. Lastly, we provide examples showing how these ideas can be applied to\ninference problems dealing with functional and multinomial data.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2018 05:25:41 GMT"}, {"version": "v2", "created": "Sat, 20 Jul 2019 02:16:33 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Lopes", "Miles E.", ""], ["Lin", "Zhenhua", ""], ["Mueller", "Hans-Georg", ""]]}, {"id": "1807.04431", "submitter": "Yen-Chi Chen", "authors": "Yen-Chi Chen", "title": "Statistical Inference with Local Optima", "comments": "66 page, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.ML stat.TH", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  We study the statistical properties of an estimator derived by applying a\ngradient ascent method with multiple initializations to a multi-modal\nlikelihood function. We derive the population quantity that is the target of\nthis estimator and study the properties of confidence intervals (CIs)\nconstructed from asymptotic normality and the bootstrap approach. In\nparticular, we analyze the coverage deficiency due to finite number of random\ninitializations. We also investigate the CIs by inverting the likelihood ratio\ntest, the score test, and the Wald test, and we show that the resulting CIs may\nbe very different. We provide a summary of the uncertainties that we need to\nconsider while making inference about the population. Note that we do not\nprovide a solution to the problem of multiple local maxima; instead, our goal\nis to investigate the effect from local maxima on the behavior of our\nestimator. In addition, we analyze the performance of the EM algorithm under\nrandom initializations and derive the coverage of a CI with a finite number of\ninitializations. Finally, we extend our analysis to a nonparametric mode\nhunting problem.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2018 06:08:33 GMT"}], "update_date": "2018-07-13", "authors_parsed": [["Chen", "Yen-Chi", ""]]}, {"id": "1807.04711", "submitter": "Eric Marchand", "authors": "Dominique Fourdrinier, \\'Eric Marchand and William E. Strawderman", "title": "On efficient prediction and predictive density estimation for\n  spherically symmetric models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $X,U,Y$ be spherically symmetric distributed having density $$\\eta^{d\n+k/2} \\, f\\left(\\eta(\\|x-\\theta|^2+ \\|u\\|^2 + \\|y-c\\theta\\|^2 ) \\right)\\,,$$\nwith unknown parameters $\\theta \\in \\mathbb{R}^d$ and $\\eta>0$, and with known\ndensity $f$ and constant $c >0$. Based on observing $X=x,U=u$, we consider the\nproblem of obtaining a predictive density $\\hat{q}(y;x,u)$ for $Y$ as measured\nby the expected Kullback-Leibler loss. A benchmark procedure is the minimum\nrisk equivariant density $\\hat{q}_{mre}$, which is Generalized Bayes with\nrespect to the prior $\\pi(\\theta, \\eta) = \\eta^{-1}$. For $d \\geq 3$, we obtain\nimprovements on $\\hat{q}_{mre}$, and further show that the dominance holds\nsimultaneously for all $f$ subject to finite moments and finite risk\nconditions. We also obtain that the Bayes predictive density with respect to\nthe harmonic prior $\\pi_h(\\theta, \\eta) =\\eta^{-1} \\|\\theta\\|^{2-d}$ dominates\n$\\hat{q}_{mre}$ simultaneously for all scale mixture of normals $f$.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2018 16:28:37 GMT"}], "update_date": "2018-07-13", "authors_parsed": [["Fourdrinier", "Dominique", ""], ["Marchand", "\u00c9ric", ""], ["Strawderman", "William E.", ""]]}, {"id": "1807.04751", "submitter": "Pavlina Jordanova", "authors": "Pavlina Jordanova and Monika Peteva", "title": "Tails and probabilities for extreme outliers", "comments": "Tenth Jubilee Conference of the Euro-American Consortium for\n  Promoting the Application of Mathematics in Technical and Natural Sciences,\n  Albena, Bulgaria, June 20-25, 2018", "journal-ref": null, "doi": "10.1063/1.5064880", "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The task of estimation of the tails of probability distributions having small\nsamples seems to be still opened and almost unsolvable. The paper tries to make\na step in filling this gap. In 2017 Jordanova et al. introduce six new\ncharacteristics of the heaviness of the tails of theoretical distributions.\nThey rely on the probability to observe {\\color{blue}mild or} extreme outliers.\nThe main their advantage is that they always exist. This work presents some new\nproperties of these characteristics. Using them six distribution sensitive\nestimators of the extremal index are defined. A brief simulation study compares\ntheir quality with the quality of Hill, t-Hill, Pickands and Deckers-Einmahl-de\nHaan estimators.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2018 08:05:37 GMT"}], "update_date": "2018-11-14", "authors_parsed": [["Jordanova", "Pavlina", ""], ["Peteva", "Monika", ""]]}, {"id": "1807.05405", "submitter": "Thomas Berrett", "authors": "Thomas B. Berrett, Yi Wang, Rina Foygel Barber and Richard J. Samworth", "title": "The conditional permutation test for independence while controlling for\n  confounders", "comments": "31 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a general new method, the conditional permutation test, for\ntesting the conditional independence of variables $X$ and $Y$ given a\npotentially high-dimensional random vector $Z$ that may contain confounding\nfactors. The proposed test permutes entries of $X$ non-uniformly, so as to\nrespect the existing dependence between $X$ and $Z$ and thus account for the\npresence of these confounders. Like the conditional randomization test of\nCand\\`es et al. (2018), our test relies on the availability of an approximation\nto the distribution of $X \\mid Z$. While Cand\\`es et al. (2018)'s test uses\nthis estimate to draw new $X$ values, for our test we use this approximation to\ndesign an appropriate non-uniform distribution on permutations of the $X$\nvalues already seen in the true data. We provide an efficient Markov Chain\nMonte Carlo sampler for the implementation of our method, and establish bounds\non the Type I error in terms of the error in the approximation of the\nconditional distribution of $X\\mid Z$, finding that, for the worst case test\nstatistic, the inflation in Type I error of the conditional permutation test is\nno larger than that of the conditional randomization test. We validate these\ntheoretical results with experiments on simulated data and on the Capital\nBikeshare data set.\n", "versions": [{"version": "v1", "created": "Sat, 14 Jul 2018 15:03:24 GMT"}, {"version": "v2", "created": "Tue, 7 May 2019 15:25:23 GMT"}], "update_date": "2019-05-08", "authors_parsed": [["Berrett", "Thomas B.", ""], ["Wang", "Yi", ""], ["Barber", "Rina Foygel", ""], ["Samworth", "Richard J.", ""]]}, {"id": "1807.05410", "submitter": "Yannick Baraud", "authors": "Yannick Baraud", "title": "About the lower bounds for the multiple testing problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given an observed random variable, consider the problem of recovering its\ndistribution among a family of candidate ones. The two-point inequality, Fano's\nlemma and more recently an inequality due to Venkataramanan and Johnson (2018)\nallow to bound the maximal probability of error over the family from below. The\naim of this paper is to give a very short and simple proof of all these results\nsimultaneously and improve in passing the inequality of Venkataramanan and\nJohnson.\n", "versions": [{"version": "v1", "created": "Sat, 14 Jul 2018 15:32:42 GMT"}], "update_date": "2018-07-17", "authors_parsed": [["Baraud", "Yannick", ""]]}, {"id": "1807.05444", "submitter": "Behrooz Tahmasebi", "authors": "Behrooz Tahmasebi, Seyed Abolfazl Motahari, Mohammad Ali Maddah-Ali", "title": "On the Identifiability of Finite Mixtures of Finite Product Measures", "comments": "This paper has been presented in part at IEEE International Symposium\n  on Information Theory (ISIT) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of identifiability of finite mixtures of finite product measures\nis studied. A mixture model with $K$ mixture components and $L$ observed\nvariables is considered, where each variable takes its value in a finite set\nwith cardinality $M$.The variables are independent in each mixture component.\nThe identifiability of a mixture model means the possibility of attaining the\nmixture components parameters by observing its mixture distribution. In this\npaper, we investigate fundamental relations between the identifiability of\nmixture models and the separability of their observed variables by introducing\ntwo types of separability: strongly and weakly separable variables. Roughly\nspeaking, a variable is said to be separable, if and only if it has some\ndifferences among its probability distributions in different mixture\ncomponents. We prove that mixture models are identifiable if the number of\nstrongly separable variables is greater than or equal to $2K-1$, independent\nform $M$. This fundamental threshold is shown to be tight, where a family of\nnon-identifiable mixture models with less than $2K-1$ strongly separable\nvariables is provided. We also show that mixture models are identifiable if\nthey have at least $2K$ weakly separable variables. To prove these theorems, we\nintroduce a particular polynomial, called characteristic polynomial, which\ntranslates the identifiability conditions to identity of polynomials and allows\nus to construct an inductive proof.\n", "versions": [{"version": "v1", "created": "Sat, 14 Jul 2018 20:56:41 GMT"}], "update_date": "2018-07-17", "authors_parsed": [["Tahmasebi", "Behrooz", ""], ["Motahari", "Seyed Abolfazl", ""], ["Maddah-Ali", "Mohammad Ali", ""]]}, {"id": "1807.05504", "submitter": "Marc Ditzhaus", "authors": "Marc Ditzhaus and Sarah Friedrich", "title": "More powerful logrank permutation tests for two-sample survival data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Weighted logrank tests are a popular tool for analyzing right censored\nsurvival data from two independent samples. Each of these tests is optimal\nagainst a certain hazard alternative, for example the classical logrank test\nfor proportional hazards. But which weight function should be used in practical\napplications? We address this question by a flexible combination idea leading\nto a testing procedure with broader power. Beside the test's asymptotic\nexactness and consistency its power behaviour under local alternatives is\nderived. All theoretical properties can be transferred to a permutation version\nof the test, which is even finitely exact under exchangeability and showed a\nbetter finite sample performance in our simulation study. The procedure is\nillustrated in a real data example.\n", "versions": [{"version": "v1", "created": "Sun, 15 Jul 2018 07:39:19 GMT"}], "update_date": "2018-07-17", "authors_parsed": [["Ditzhaus", "Marc", ""], ["Friedrich", "Sarah", ""]]}, {"id": "1807.05801", "submitter": "Imma Valentina Curato Dr", "authors": "Imma Valentina Curato and Robert Stelzer", "title": "Weak dependence and GMM estimation of supOU and mixed moving average\n  processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a mixed moving average (MMA) process X driven by a L\\'evy basis\nand prove that it is weakly dependent with rates computable in terms of the\nmoving average kernel and the characteristic quadruple of the L\\'evy basis.\nUsing this property, we show conditions ensuring that sample mean and\nautocovariances of X have a limiting normal distribution. We extend these\nresults to stochastic volatility models and then investigate a Generalized\nMethod of Moments estimator for the supOU process and the supOU stochastic\nvolatility model after choosing a suitable distribution for the mean reversion\nparameter. For these estimators, we analyze the asymptotic behavior in detail.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2018 11:43:23 GMT"}, {"version": "v2", "created": "Fri, 28 Dec 2018 09:19:40 GMT"}], "update_date": "2018-12-31", "authors_parsed": [["Curato", "Imma Valentina", ""], ["Stelzer", "Robert", ""]]}, {"id": "1807.05985", "submitter": "Vincent Vu", "authors": "Vincent Q. Vu", "title": "Group Invariance and Computational Sufficiency", "comments": "Fixed mistakes in Theorem 2 and proof of Corollary 2; added\n  Proposition 1; corrected typos (particularly in definition of computational\n  sufficiency); added references; revised for readability and clarity", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical sufficiency formalizes the notion of data reduction. In the\ndecision theoretic interpretation, once a model is chosen all inferences should\nbe based on a sufficient statistic. However, suppose we start with a set of\nprocedures rather than a specific model. Is it possible to reduce the data and\nyet still be able to compute all of the procedures? In other words, what\nfunctions of the data contain all of the information sufficient for computing\nthese procedures? This article presents some progress towards a theory of\n\"computational sufficiency\" and shows that strong reductions can be made for\nlarge classes of penalized $M$-estimators by exploiting hidden symmetries in\nthe underlying optimization problems. These reductions can (1) reveal hidden\nconnections between seemingly disparate methods, (2) enable efficient\ncomputation, (3) give a different perspective on understanding procedures in a\nmodel-free setting. As a main example, the theory provides a surprising answer\nto the following question: \"What do the Graphical Lasso, sparse PCA,\nsingle-linkage clustering, and L1 penalized Ising model selection all have in\ncommon?\"\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2018 17:30:53 GMT"}, {"version": "v2", "created": "Tue, 31 Jul 2018 10:30:55 GMT"}], "update_date": "2018-08-01", "authors_parsed": [["Vu", "Vincent Q.", ""]]}, {"id": "1807.06133", "submitter": "Florian Puchhammer", "authors": "Amal Ben Abdellah, Pierre L'Ecuyer, Art B. Owen, Florian Puchhammer", "title": "Density estimation by Randomized Quasi-Monte Carlo", "comments": "22 pages, 6 figures, 4 tables; We are thankful to the anonymous\n  referees, whose comments were considered in this submission", "journal-ref": null, "doi": "10.1137/19M1259213", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of estimating the density of a random variable $X$\nthat can be sampled exactly by Monte Carlo (MC). We investigate the\neffectiveness of replacing MC by randomized quasi Monte Carlo (RQMC) or by\nstratified sampling over the unit cube, to reduce the integrated variance (IV)\nand the mean integrated square error (MISE) for kernel density estimators. We\nshow theoretically and empirically that the RQMC and stratified estimators can\nachieve substantial reductions of the IV and the MISE, and even faster\nconvergence rates than MC in some situations, while leaving the bias unchanged.\nWe also show that the variance bounds obtained via a traditional\nKoksma-Hlawka-type inequality for RQMC are much too loose to be useful when the\ndimension of the problem exceeds a few units. We describe an alternative way to\nestimate the IV, a good bandwidth, and the MISE, under RQMC or stratification,\nand we show empirically that in some situations, the MISE can be reduced\nsignificantly even in high-dimensional settings.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2018 22:14:07 GMT"}, {"version": "v2", "created": "Fri, 10 Aug 2018 20:56:07 GMT"}, {"version": "v3", "created": "Tue, 28 May 2019 19:21:00 GMT"}, {"version": "v4", "created": "Thu, 26 Nov 2020 17:08:45 GMT"}], "update_date": "2021-03-12", "authors_parsed": [["Abdellah", "Amal Ben", ""], ["L'Ecuyer", "Pierre", ""], ["Owen", "Art B.", ""], ["Puchhammer", "Florian", ""]]}, {"id": "1807.06168", "submitter": "Gautam Kamath", "authors": "Gautam Kamath, Christos Tzamos", "title": "Anaconda: A Non-Adaptive Conditional Sampling Algorithm for Distribution\n  Testing", "comments": "SODA 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.IT cs.LG math.IT math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate distribution testing with access to non-adaptive conditional\nsamples. In the conditional sampling model, the algorithm is given the\nfollowing access to a distribution: it submits a query set $S$ to an oracle,\nwhich returns a sample from the distribution conditioned on being from $S$. In\nthe non-adaptive setting, all query sets must be specified in advance of\nviewing the outcomes.\n  Our main result is the first polylogarithmic-query algorithm for equivalence\ntesting, deciding whether two unknown distributions are equal to or far from\neach other. This is an exponential improvement over the previous best upper\nbound, and demonstrates that the complexity of the problem in this model is\nintermediate to the the complexity of the problem in the standard sampling\nmodel and the adaptive conditional sampling model. We also significantly\nimprove the sample complexity for the easier problems of uniformity and\nidentity testing. For the former, our algorithm requires only $\\tilde O(\\log\nn)$ queries, matching the information-theoretic lower bound up to a $O(\\log\n\\log n)$-factor.\n  Our algorithm works by reducing the problem from $\\ell_1$-testing to\n$\\ell_\\infty$-testing, which enjoys a much cheaper sample complexity.\nNecessitated by the limited power of the non-adaptive model, our algorithm is\nvery simple to state. However, there are significant challenges in the\nanalysis, due to the complex structure of how two arbitrary distributions may\ndiffer.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 01:12:23 GMT"}, {"version": "v2", "created": "Mon, 5 Nov 2018 18:47:27 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Kamath", "Gautam", ""], ["Tzamos", "Christos", ""]]}, {"id": "1807.06338", "submitter": "Anna Mikusheva", "authors": "Stanislav Anatolyev and Anna Mikusheva", "title": "Limit Theorems for Factor Models", "comments": null, "journal-ref": null, "doi": "10.1017/S0266466620000468", "report-no": null, "categories": "econ.EM math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper establishes the central limit theorems and proposes how to perform\nvalid inference in factor models. We consider a setting where many\ncounties/regions/assets are observed for many time periods, and when estimation\nof a global parameter includes aggregation of a cross-section of heterogeneous\nmicro-parameters estimated separately for each entity. The central limit\ntheorem applies for quantities involving both cross-sectional and time series\naggregation, as well as for quadratic forms in time-aggregated errors. The\npaper studies the conditions when one can consistently estimate the asymptotic\nvariance, and proposes a bootstrap scheme for cases when one cannot. A small\nsimulation study illustrates performance of the asymptotic and bootstrap\nprocedures. The results are useful for making inferences in two-step estimation\nprocedures related to factor models, as well as in other related contexts. Our\ntreatment avoids structural modeling of cross-sectional dependence but imposes\ntime-series independence.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 10:56:52 GMT"}, {"version": "v2", "created": "Tue, 28 Apr 2020 12:07:32 GMT"}, {"version": "v3", "created": "Wed, 23 Sep 2020 13:45:42 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Anatolyev", "Stanislav", ""], ["Mikusheva", "Anna", ""]]}, {"id": "1807.06362", "submitter": "Jean Michel Loubes", "authors": "Philippe Besse and Eustasio del Barrio and Paula Gordaliza and\n  Jean-Michel Loubes", "title": "Confidence Intervals for Testing Disparate Impact in Fair Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide the asymptotic distribution of the major indexes used in the\nstatistical literature to quantify disparate treatment in machine learning. We\naim at promoting the use of confidence intervals when testing the so-called\ngroup disparate impact. We illustrate on some examples the importance of using\nconfidence intervals and not a single value.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 11:48:19 GMT"}], "update_date": "2018-07-18", "authors_parsed": [["Besse", "Philippe", ""], ["del Barrio", "Eustasio", ""], ["Gordaliza", "Paula", ""], ["Loubes", "Jean-Michel", ""]]}, {"id": "1807.06402", "submitter": "Luciano Perez", "authors": "Luciano Perez", "title": "Modularity Classes and Boundary Effects in Multivariate Stochastic\n  Dominance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hadar and Russell (1974) and Levy and Paroush (1974) presented sufficient\nconditions for multivariate stochastic dominance when the distributions\ninvolved are continuous with compact support. Further generalizations involved\neither independence assumptions (Sacarsini (1988)) or the introduction of new\nconcepts like 'correlation increasing transformation' (Epstein and Tanny\n(1980), Tchen (1980), Mayer (2013)). In this paper, we present a direct proof\nthat extends the original results to the general case where the involved\ndistributions are only assumed to have compact support. This result has in turn\nproven useful for statistical tests of dominance without the assumption of\nabsolute continuity. The first section introduces several concepts used\nthroughout the paper. In the second section we recall the classic result as\npresented in Atkinson and Bourguignon (1982), with a slightly lighter proof\nusing the general integration by parts formula for n dimensional\nLebesgue-Stieljes integrals. In the third section we present our proof of the\ngeneral result, using Riemman-Stieljes partial sums in a direct fashion that\nhelps to clarify the role of modularity conditions and boundary effects in the\nsufficiency of the conditions. The last section discusses the relevance of the\nresult and concludes.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 13:12:02 GMT"}, {"version": "v2", "created": "Sun, 26 Aug 2018 00:44:01 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Perez", "Luciano", ""]]}, {"id": "1807.06470", "submitter": "Hanan Ahmed", "authors": "Hanan Ahmed, John H.J. Einmahl", "title": "Improved estimation of the extreme value index using related variables", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Heavy tailed phenomena are naturally analyzed by extreme value statistics. A\ncrucial step in such an analysis is the estimation of the extreme value index,\nwhich describes the tail heaviness of the underlying probability distribution.\nWe consider the situation where we have next to the $n$ observations of\ninterest another $n+m$ observations of one or more related variables, like,\ne.g., financial losses due to earthquakes and the related amounts of energy\nreleased, for a longer period than that of the losses. Based on such a data\nset, we present an adapted version of the Hill estimator that shows greatly\nimproved behavior and we establish the asymptotic normality of this estimator.\nFor this adaptation the tail dependence between the variable of interest and\nthe related variable(s) plays an important role. A simulation study confirms\nthe substantially improved performance of our adapted estimator relative to the\nHill estimator. We also present an application to the aforementioned earthquake\nlosses.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 14:32:00 GMT"}], "update_date": "2018-07-18", "authors_parsed": [["Ahmed", "Hanan", ""], ["Einmahl", "John H. J.", ""]]}, {"id": "1807.06635", "submitter": "Jos\\'e A. D\\'iaz-Garc\\'ia", "authors": "Jos\\'e A. D\\'iaz-Garc\\'ia and Frencisco J. Caro-Lopera", "title": "Multimatricvariate distribution under elliptical models", "comments": "13pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new family of matrix variate distributions indexed by elliptical models are\nproposed in this work. The so called \\emph{multimatricvariate distributions}\nemerge as a generalization of the bimatrix variate distributions based on\nmatrix variate gamma distributions and independence. Some properties and\nspecial cases of the multimatricvariate distributions are also derived. Two new\ninteresting Jacobians in the area are also provided. Finally, an application\nfor time dependent data of DNA molecules is studied.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 19:33:49 GMT"}], "update_date": "2018-07-19", "authors_parsed": [["D\u00edaz-Garc\u00eda", "Jos\u00e9 A.", ""], ["Caro-Lopera", "Frencisco J.", ""]]}, {"id": "1807.06693", "submitter": "Krishnakumar Balasubramanian", "authors": "Krishnakumar Balasubramanian, Jianqing Fan, Zhuoran Yang", "title": "Tensor Methods for Additive Index Models under Discordance and\n  Heterogeneity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the sampling problems and heterogeneity issues common in high-\ndimensional big datasets, we consider a class of discordant additive index\nmodels. We propose method of moments based procedures for estimating the\nindices of such discordant additive index models in both low and\nhigh-dimensional settings. Our estimators are based on factorizing certain\nmoment tensors and are also applicable in the overcomplete setting, where the\nnumber of indices is more than the dimensionality of the datasets. Furthermore,\nwe provide rates of convergence of our estimator in both high and\nlow-dimensional setting. Establishing such results requires deriving tensor\noperator norm concentration inequalities that might be of independent interest.\nFinally, we provide simulation results supporting our theory. Our contributions\nextend the applicability of tensor methods for novel models in addition to\nmaking progress on understanding theoretical properties of such tensor methods.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 22:28:43 GMT"}], "update_date": "2018-07-19", "authors_parsed": [["Balasubramanian", "Krishnakumar", ""], ["Fan", "Jianqing", ""], ["Yang", "Zhuoran", ""]]}, {"id": "1807.06796", "submitter": "Jean Michel Loubes", "authors": "Eustasio del Barrio and Paula Gordaliza and Jean-Michel Loubes", "title": "A Central Limit Theorem for $L_p$ transportation cost with applications\n  to Fairness Assessment in Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a Central Limit Theorem for the Monge-Kantorovich distance between\ntwo empirical distributions with size $n$ and $m$, $W_p(P_n,Q_m)$ for $p>1$ for\nobservations on the real line, using a minimal amount of assumptions. We\nprovide an estimate of the asymptotic variance which enables to build a two\nsample test to assess the similarity between two distributions. This test is\nthen used to provide a new criterion to assess the notion of fairness of a\nclassification algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2018 07:02:08 GMT"}], "update_date": "2018-07-19", "authors_parsed": [["del Barrio", "Eustasio", ""], ["Gordaliza", "Paula", ""], ["Loubes", "Jean-Michel", ""]]}, {"id": "1807.06911", "submitter": "Marcel Ausloos", "authors": "Marcel Ausloos (U. Leicester) and Roy Cerqueti (U. Macerata)", "title": "Intriguing yet simple skewness - kurtosis relation in economic and\n  demographic data distributions; pointing to preferential attachment processes", "comments": "29 pages, 5 tables, 10 figures, 56 references", "journal-ref": "Journal of Applied Statistics, 45:12, 2202-2218 (2018)", "doi": "10.1080/02664763.2017.1413077", "report-no": null, "categories": "stat.AP math.ST physics.soc-ph stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose that relations between high order moments of data\ndistributions, for example between the skewness (S) and kurtosis (K), allow to\npoint to theoretical models with understandable structural parameters. The\nillustrative data concerns two cases: (i) the distribution of income taxes and\n(ii) that of inhabitants, after aggregation over each city in each province of\nItaly in 2011. Moreover, from the rank-size relationship, for either S or K, in\nboth cases, it is shown that one obtains the parameters of the underlying\n(hypothetical) modeling distribution: in the present cases, the 2-parameter\nBeta function, - itself related to the Yule-Simon distribution function, whence\nsuggesting a growth model based on the preferential attachment process.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2018 13:15:57 GMT"}], "update_date": "2018-07-19", "authors_parsed": [["Ausloos", "Marcel", "", "U. Leicester"], ["Cerqueti", "Roy", "", "U. Macerata"]]}, {"id": "1807.06976", "submitter": "Christos Thrampoulidis", "authors": "Christos Thrampoulidis, Ankit Singh Rawat", "title": "The Generalized Lasso for Sub-gaussian Measurements with Dithered\n  Quantization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT eess.SP math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the problem of structured signal recovery from high-dimensional linear\nobservations, it is commonly assumed that full-precision measurements are\navailable. Under this assumption, the recovery performance of the popular\nGeneralized Lasso (G-Lasso) is by now well-established. In this paper, we\nextend these types of results to the practically relevant settings with\nquantized measurements. We study two extremes of the quantization schemes,\nnamely, uniform and one-bit quantization; the former imposes no limit on the\nnumber of quantization bits, while the second only allows for one bit. In the\npresence of a uniform dithering signal and when measurement vectors are\nsub-gaussian, we show that the same algorithm (i.e., the G-Lasso) has favorable\nrecovery guarantees for both uniform and one-bit quantization schemes. Our\ntheoretical results, shed light on the appropriate choice of the range of\nvalues of the dithering signal and accurately capture the error dependence on\nthe problem parameters. For example, our error analysis shows that the G-Lasso\nwith one-bit uniformly dithered measurements leads to only a logarithmic rate\nloss compared to the full-precision measurements.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2018 14:37:49 GMT"}], "update_date": "2018-07-19", "authors_parsed": [["Thrampoulidis", "Christos", ""], ["Rawat", "Ankit Singh", ""]]}, {"id": "1807.07013", "submitter": "Phil Long", "authors": "Anindya De, Philip M. Long and Rocco A. Servedio", "title": "Learning Sums of Independent Random Variables with Sparse Collective\n  Support", "comments": "Conference version in FOCS'18; Journal version to appear in JMLR", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the learnability of sums of independent integer random variables\ngiven a bound on the size of the union of their supports. For $\\mathcal{A}\n\\subset \\mathbf{Z}_{+}$, a sum of independent random variables with collective\nsupport $\\mathcal{A}$} (called an $\\mathcal{A}$-sum in this paper) is a\ndistribution $\\mathbf{S} = \\mathbf{X}_1 + \\cdots + \\mathbf{X}_N$ where the\n$\\mathbf{X}_i$'s are mutually independent (but not necessarily identically\ndistributed) integer random variables with $\\cup_i \\mathsf{supp}(\\mathbf{X}_i)\n\\subseteq \\mathcal{A}.$ We give two main algorithmic results for learning such\ndistributions:\n  1. For the case $| \\mathcal{A} | = 3$, we give an algorithm for learning\n$\\mathcal{A}$-sums to accuracy $\\epsilon$ that uses $\\mathsf{poly}(1/\\epsilon)$\nsamples and runs in time $\\mathsf{poly}(1/\\epsilon)$, independent of $N$ and of\nthe elements of $\\mathcal{A}$.\n  2. For an arbitrary constant $k \\geq 4$, if $\\mathcal{A} = \\{ a_1,...,a_k\\}$\nwith $0 \\leq a_1 < ... < a_k$, we give an algorithm that uses\n$\\mathsf{poly}(1/\\epsilon) \\cdot \\log \\log a_k$ samples (independent of $N$)\nand runs in time $\\mathsf{poly}(1/\\epsilon, \\log a_k).$\n  We prove an essentially matching lower bound: if $|\\mathcal{A}| = 4$, then\nany algorithm must use $\\Omega(\\log \\log a_4) $ samples even for learning to\nconstant accuracy. We also give similar-in-spirit (but quantitatively very\ndifferent) algorithmic results, and essentially matching lower bounds, for the\ncase in which $\\mathcal{A}$ is not known to the learner.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2018 16:02:35 GMT"}, {"version": "v2", "created": "Thu, 12 Nov 2020 18:14:33 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["De", "Anindya", ""], ["Long", "Philip M.", ""], ["Servedio", "Rocco A.", ""]]}, {"id": "1807.07095", "submitter": "Wuchen Li", "authors": "Wuchen Li, Guido Montufar", "title": "Ricci curvature for parametric statistics via optimal transport", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT math.IT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We elaborate the notion of a Ricci curvature lower bound for parametrized\nstatistical models. Following the seminal ideas of Lott-Strum-Villani, we\ndefine this notion based on the geodesic convexity of the Kullback-Leibler\ndivergence in a Wasserstein statistical manifold, that is, a manifold of\nprobability distributions endowed with a Wasserstein metric tensor structure.\nWithin these definitions, the Ricci curvature is related to both, information\ngeometry and Wasserstein geometry. These definitions allow us to formulate\nbounds on the convergence rate of Wasserstein gradient flows and information\nfunctional inequalities in parameter space. We discuss examples of Ricci\ncurvature lower bounds and convergence rates in exponential family models.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2018 18:23:04 GMT"}, {"version": "v2", "created": "Sun, 28 Jun 2020 23:14:29 GMT"}, {"version": "v3", "created": "Thu, 31 Dec 2020 22:41:51 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Li", "Wuchen", ""], ["Montufar", "Guido", ""]]}, {"id": "1807.07237", "submitter": "Pengkun Yang", "authors": "Yihong Wu and Pengkun Yang", "title": "Optimal estimation of Gaussian mixtures via denoised method of moments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Method of Moments [Pea94] is one of the most widely used methods in\nstatistics for parameter estimation, by means of solving the system of\nequations that match the population and estimated moments. However, in practice\nand especially for the important case of mixture models, one frequently needs\nto contend with the difficulties of non-existence or non-uniqueness of\nstatistically meaningful solutions, as well as the high computational cost of\nsolving large polynomial systems. Moreover, theoretical analysis of the method\nof moments are mainly confined to asymptotic normality style of results\nestablished under strong assumptions.\n  This paper considers estimating a $k$-component Gaussian location mixture\nwith a common (possibly unknown) variance parameter. To overcome the\naforementioned theoretic and algorithmic hurdles, a crucial step is to denoise\nthe moment estimates by projecting to the truncated moment space (via\nsemidefinite programming) before solving the method of moments equations. Not\nonly does this regularization ensures existence and uniqueness of solutions, it\nalso yields fast solvers by means of Gauss quadrature. Furthermore, by proving\nnew moment comparison theorems in the Wasserstein distance via polynomial\ninterpolation and majorization techniques, we establish the statistical\nguarantees and adaptive optimality of the proposed procedure, as well as oracle\ninequality in misspecified models. These results can also be viewed as provable\nalgorithms for Generalized Method of Moments [Han82] which involves non-convex\noptimization and lacks theoretical guarantees.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jul 2018 04:47:21 GMT"}, {"version": "v2", "created": "Sat, 13 Apr 2019 19:36:54 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Wu", "Yihong", ""], ["Yang", "Pengkun", ""]]}, {"id": "1807.07547", "submitter": "Christophe Giraud", "authors": "Christophe Giraud and Nicolas Verzelen", "title": "Partial recovery bounds for clustering with the relaxed $K$means", "comments": "39 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the clustering performances of the relaxed $K$means in the\nsetting of sub-Gaussian Mixture Model (sGMM) and Stochastic Block Model (SBM).\nAfter identifying the appropriate signal-to-noise ratio (SNR), we prove that\nthe misclassification error decay exponentially fast with respect to this SNR.\nThese partial recovery bounds for the relaxed $K$means improve upon results\ncurrently known in the sGMM setting. In the SBM setting, applying the relaxed\n$K$means SDP allows to handle general connection probabilities whereas other\nSDPs investigated in the literature are restricted to the assortative case\n(where within group probabilities are larger than between group probabilities).\nAgain, this partial recovery bound complements the state-of-the-art results.\nAll together, these results put forward the versatility of the relaxed\n$K$means.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jul 2018 17:33:30 GMT"}, {"version": "v2", "created": "Mon, 4 Mar 2019 15:53:02 GMT"}, {"version": "v3", "created": "Fri, 19 Apr 2019 15:48:07 GMT"}], "update_date": "2019-04-22", "authors_parsed": [["Giraud", "Christophe", ""], ["Verzelen", "Nicolas", ""]]}, {"id": "1807.07561", "submitter": "Elina Robeva Massachusetts Institute of Technology", "authors": "Mathias Drton, Elina Robeva, and Luca Weihs", "title": "Nested Covariance Determinants and Restricted Trek Separation in\n  Gaussian Graphical Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Directed graphical models specify noisy functional relationships among a\ncollection of random variables. In the Gaussian case, each such model\ncorresponds to a semi-algebraic set of positive definite covariance matrices.\nThe set is given via parametrization, and much work has gone into obtaining an\nimplicit description in terms of polynomial (in-)equalities. Implicit\ndescriptions shed light on problems such as parameter identification, model\nequivalence, and constraint-based statistical inference. For models given by\ndirected acyclic graphs, which represent settings where all relevant variables\nare observed, there is a complete theory: All conditional independence\nrelations can be found via graphical $d$-separation and are sufficient for an\nimplicit description. The situation is far more complicated, however, when some\nof the variables are hidden (or in other words, unobserved or latent). We\nconsider models associated to mixed graphs that capture the effects of hidden\nvariables through correlated error terms. The notion of trek separation\nexplains when the covariance matrix in such a model has submatrices of low rank\nand generalizes $d$-separation. However, in many cases, such as the infamous\nVerma graph, the polynomials defining the graphical model are not\ndeterminantal, and hence cannot be explained by $d$-separation or\ntrek-separation. In this paper, we show that these constraints often correspond\nto the vanishing of nested determinants and can be graphically explained by a\nnotion of restricted trek separation.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jul 2018 17:59:10 GMT"}], "update_date": "2018-07-20", "authors_parsed": [["Drton", "Mathias", ""], ["Robeva", "Elina", ""], ["Weihs", "Luca", ""]]}, {"id": "1807.07615", "submitter": "Guilherme Ost", "authors": "Guilherme Ost and Patricia Reynaud-Bouret", "title": "Sparse space-time models: Concentration Inequalities and Lasso", "comments": "40 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Inspired by Kalikow-type decompositions, we introduce a new stochastic model\nof infinite neuronal networks, for which we establish sharp oracle inequalities\nfor Lasso methods and restricted eigenvalue properties for the associated Gram\nmatrix with high probability. These results hold even if the network is only\npartially observed. The main argument rely on the fact that concentration\ninequalities can easily be derived whenever the transition probabilities of the\nunderlying process admit a sparse space-time representation.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jul 2018 19:12:28 GMT"}, {"version": "v2", "created": "Thu, 4 Oct 2018 17:39:46 GMT"}, {"version": "v3", "created": "Mon, 12 Aug 2019 14:07:51 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Ost", "Guilherme", ""], ["Reynaud-Bouret", "Patricia", ""]]}, {"id": "1807.07670", "submitter": "Yuichi Hirose", "authors": "Yuichi Hirose and Ivy Liu", "title": "Statistical generalized derivative applied to the profile likelihood\n  estimation in a mixture of semiparametric models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a difficulty in finding an estimate of variance of the profile\nlikelihood estimator in the joint model of longitudinal and survival data. We\nsolve the difficulty by introducing the ``statistical generalized derivative''.\nThe derivative is used to show the asymptotic normality of the estimator\nwithout assuming the second derivative of the density function in the model\nexists.\n", "versions": [{"version": "v1", "created": "Fri, 20 Jul 2018 00:09:47 GMT"}], "update_date": "2018-07-23", "authors_parsed": [["Hirose", "Yuichi", ""], ["Liu", "Ivy", ""]]}, {"id": "1807.08336", "submitter": "Veronika Rockova", "authors": "Marilena Barbieri, James O. Berger, Edward I. George and Veronika\n  Rockova", "title": "The Median Probability Model and Correlated Variables", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The median probability model (MPM) Barbieri and Berger (2004) is defined as\nthe model consisting of those variables whose marginal posterior probability of\ninclusion is at least 0.5. The MPM rule yields the best single model for\nprediction in orthogonal and nested correlated designs. This result was\noriginally conceived under a specific class of priors, such as the point mass\nmixtures of non-informative and g-type priors. The MPM rule, however, has\nbecome so very popular that it is now being deployed for a wider variety of\npriors and under correlated designs, where the properties of MPM are not yet\ncompletely understood. The main thrust of this work is to shed light on\nproperties of MPM in these contexts by (a) characterizing situations when MPM\nis still safe under correlated designs, (b) providing significant\ngeneralizations of MPM to a broader class of priors (such as continuous\nspike-and-slab priors). We also provide new supporting evidence for the\nsuitability of g-priors, as opposed to independent product priors, using new\npredictive matching arguments. Furthermore, we emphasize the importance of\nprior model probabilities and highlight the merits of non-uniform prior\nprobability assignments using the notion of model aggregates.\n", "versions": [{"version": "v1", "created": "Sun, 22 Jul 2018 18:33:02 GMT"}, {"version": "v2", "created": "Fri, 17 Aug 2018 15:10:23 GMT"}], "update_date": "2018-08-20", "authors_parsed": [["Barbieri", "Marilena", ""], ["Berger", "James O.", ""], ["George", "Edward I.", ""], ["Rockova", "Veronika", ""]]}, {"id": "1807.08365", "submitter": "Yulong Lu", "authors": "Anning Liu, Jian-Guo Liu and Yulong Lu", "title": "On the rate of convergence of empirical measure in $\\infty-$Wasserstein\n  distance for unbounded density function", "comments": "Theorem 1.1 is simplified", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a sequence of identically independently distributed random\nsamples from an absolutely continuous probability measure in one dimension with\nunbounded density. We establish a new rate of convergence of the\n$\\infty-$Wasserstein distance between the empirical measure of the samples and\nthe true distribution, which extends the previous convergence result by\nTrilllos and Slep\\v{c}ev to the case that the true distribution has an\nunbounded density.\n", "versions": [{"version": "v1", "created": "Sun, 22 Jul 2018 20:57:17 GMT"}, {"version": "v2", "created": "Thu, 2 Aug 2018 01:17:57 GMT"}], "update_date": "2018-08-03", "authors_parsed": [["Liu", "Anning", ""], ["Liu", "Jian-Guo", ""], ["Lu", "Yulong", ""]]}, {"id": "1807.08386", "submitter": "Sagar Pandhare Mr", "authors": "S.C.Pandhare and T.V.Ramanathan", "title": "The Focused Information Criterion for Stochastic Model Selection\n  Problems Using $M$-Estimators", "comments": "24 pages, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Claeskens and Hjort (2003) constructed the focused information criterion\n(FIC) and developed frequentist model averaging methods using maximum\nlikelihood estimators assuming the observations to be independent and\nidentically distributed. Towards the immediate extensions and generalizations\nof these results, the present article is aimed at providing the focused model\nselection and model averaging methods using general maximum likelihood type\nestimators, popularly known as $M$-estimators. The necessary asymptotic theory\nis derived in a setup of stationary and strong mixing stochastic processes\nemploying von Mises functional calculus of empirical processes and Le Cam's\ncontiguity lemmas. We illustrate the proposed focused stochastic modeling\nmethods using three well-known spacial cases of $M$-estimators, namely,\nconditional maximum likelihood estimators, conditional least square estimators\nand estimators based on method of moments. For the sake of simulation\nexercises, we consider two simple applications of FIC. The first application\ndiscusses the simultaneous selection of order of autoregression and symmetry of\ninnovations in asymmetric Laplace autoregressive models. The second application\ndemonstrates the FIC based choice between general scale-shape Gamma density and\nexponential density with shape being unity. We observe that in terms of the\ncorrect selections, FIC outperforms classical Akaike's information criterion\nAIC and performs at par with Bayesian information criterion BIC.\n", "versions": [{"version": "v1", "created": "Sun, 22 Jul 2018 23:42:29 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Pandhare", "S. C.", ""], ["Ramanathan", "T. V.", ""]]}, {"id": "1807.08489", "submitter": "Luciano Perez", "authors": "Luciano Alejo Perez", "title": "Nonparametric Tests for Bivariate Stochastic Dominance without\n  Continuity Assumptions", "comments": null, "journal-ref": "Int. Journal App. Math. Stat. 59(4)(2020): 43-65", "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of Kolmogorov-Smirnov-type statistics for testing stochastic\ndominance goes back to McFadden (1989). In this paper we extend the approach of\nBarret and Donald (2003) to the bivariate case, without the assumption of\nabsolute continuity for the underlying distributions. Using empirical processes\ntheory and bootstrap techniques we obtain consis- tent nonparametric tests for\nbivariate first and second order stochastic dominance, over several modularity\nclasses of test functions. This tests are in turn useful tools in applied\nfields such as multidimensional eco- nomic inequality as shown by Perez (2015).\n", "versions": [{"version": "v1", "created": "Mon, 23 Jul 2018 09:04:09 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Perez", "Luciano Alejo", ""]]}, {"id": "1807.08715", "submitter": "Lev B Klebanov", "authors": "Lev B. Klebanov and Irina Volchenkova", "title": "Outliers and The Ostensibly Heavy Tails", "comments": "arXiv admin note: text overlap with arXiv:1701.06642", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of the paper is to show that the presence of one possible type of\noutliers is not connected to that of heavy tails of the distribution. In\ncontrary, typical situation for outliers appearance is the case of compact\nsupported distributions.\n  Key words: outliers; heavy tailed distributions; compact support\n", "versions": [{"version": "v1", "created": "Mon, 23 Jul 2018 16:49:07 GMT"}], "update_date": "2018-07-25", "authors_parsed": [["Klebanov", "Lev B.", ""], ["Volchenkova", "Irina", ""]]}, {"id": "1807.08965", "submitter": "Arnaud Gloter", "authors": "Chiara Amorino (LaMME), Arnaud Gloter (LaMME)", "title": "Contrast function estimation for the drift parameter of ergodic jump\n  diffusion process", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider an ergodic diffusion process with jumps whose drift\ncoefficient depends on an unknown parameter $\\theta$. We suppose that the\nprocess is discretely observed at the instants (t n i)i=0,...,n with $\\Delta$n\n= sup i=0,...,n--1 (t n i+1 -- t n i) $\\rightarrow$ 0. We introduce an\nestimator of $\\theta$, based on a contrast function, which is efficient without\nrequiring any conditions on the rate at which $\\Delta$n $\\rightarrow$ 0, and\nwhere we allow the observed process to have non summable jumps. This extends\nearlier results where the condition n$\\Delta$ 3 n $\\rightarrow$ 0 was needed\n(see [10],[24]) and where the process was supposed to have summable jumps.\nMoreover, in the case of a finite jump activity, we propose explicit\napproximations of the contrast function, such that the efficient estimation of\n$\\theta$ is feasible under the condition that n$\\Delta$ k n $\\rightarrow$ 0\nwhere k > 0 can be arbitrarily large. This extends the results obtained by\nKessler [15] in the case of continuous processes. L{\\'e}vy-driven SDE,\nefficient drift estimation, high frequency data, ergodic properties,\nthresholding methods.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jul 2018 08:56:20 GMT"}, {"version": "v2", "created": "Thu, 12 Sep 2019 12:24:08 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Amorino", "Chiara", "", "LaMME"], ["Gloter", "Arnaud", "", "LaMME"]]}, {"id": "1807.08971", "submitter": "Alexander Tartakovsky", "authors": "Alexander Tartakovsky", "title": "Asymptotically Optimal Quickest Change Detection In Multistream Data -\n  Part 1: General Stochastic Models", "comments": "32 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Assume that there are multiple data streams (channels, sensors) and in each\nstream the process of interest produces generally dependent and non-identically\ndistributed observations. When the process is in a normal mode (in-control),\nthe (pre-change) distribution is known, but when the process becomes abnormal\nthere is a parametric uncertainty, i.e., the post-change (out-of-control)\ndistribution is known only partially up to a parameter. Both the change point\nand the post-change parameter are unknown. Moreover, the change affects an\nunknown subset of streams, so that the number of affected streams and their\nlocation are unknown in advance. A good changepoint detection procedure should\ndetect the change as soon as possible after its occurrence while controlling\nfor a risk of false alarms. We consider a Bayesian setup with a given prior\ndistribution of the change point and propose two sequential mixture-based\nchange detection rules, one mixes a Shiryaev-type statistic over both the\nunknown subset of affected streams and the unknown post-change parameter and\nanother mixes a Shiryaev-Roberts-type statistic. These rules generalize the\nmixture detection procedures studied by Tartakovsky (2018) in a single-stream\ncase. We provide sufficient conditions under which the proposed multistream\nchange detection procedures are first-order asymptotically optimal with respect\nto moments of the delay to detection as the probability of false alarm\napproaches zero.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jul 2018 09:01:53 GMT"}], "update_date": "2018-07-25", "authors_parsed": [["Tartakovsky", "Alexander", ""]]}, {"id": "1807.08980", "submitter": "Alexander Tartakovsky", "authors": "Alexander G. Tartakovsky", "title": "Asymptotic Optimality of Mixture Rules for Detecting Changes in General\n  Stochastic Models", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The paper addresses a sequential changepoint detection problem for a general\nstochastic model, assuming that the observed data may be non-i.i.d. (i.e.,\ndependent and non-identically distributed) and the prior distribution of the\nchange point is arbitrary. Tartakovsky and Veeravalli (2005), Baron and\nTartakovsky (2006), and, more recently, Tartakovsky (2017) developed a general\nasymptotic theory of changepoint detection for non-i.i.d.\\ stochastic models,\nassuming the certain stability of the log-likelihood ratio process, in the case\nof simple hypotheses when both pre-change and post-change models are completely\nspecified. However, in most applications, the post-change distribution is not\ncompletely known. In the present paper, we generalize previous results to the\ncase of parametric uncertainty, assuming the parameter of the post-change\ndistribution is unknown. We introduce two detection rules based on mixtures --\nthe Mixture Shiryaev rule and the Mixture Shiryaev--Roberts rule -- and study\ntheir asymptotic properties in the Bayesian context. In particular, we provide\nsufficient conditions under which these rules are first-order asymptotically\noptimal, minimizing moments of the delay to detection as the probability of\nfalse alarm approaches zero.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jul 2018 09:15:01 GMT"}], "update_date": "2018-07-25", "authors_parsed": [["Tartakovsky", "Alexander G.", ""]]}, {"id": "1807.08988", "submitter": "Fran\\c{c}ois Bachoc", "authors": "Fran\\c{c}ois Bachoc (IMT, GdR MASCOT-NUM), Moreno Bevilacqua, Daira\n  Velandia", "title": "Composite likelihood estimation for a gaussian process under fixed\n  domain asymptotics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of estimating the covariance parameters of a\none-dimensional Gaussian process with exponential covariance function under\nfixed-domain asymptotics. We show that the weighted pairwise maximum likelihood\nestimator of the microergodic parameter can be consistent or inconsistent. This\ndepends on the range of admissible parameter values in the likelihood\noptimization. On the other hand, the weighted pairwise conditional maximum\nlikelihood estimator is always consistent. Both estimators are also\nasymptotically Gaussian when they are consistent. Their asymptotic variances\nare larger or strictly larger than that of the maximum likelihood estimator. A\nsimulation study is presented in order to compare the finite sample behavior of\nthe pairwise likelihood estimators with their asymptotic distributions. For\nmore general covariance functions, an additional inconsistency result is\nprovided, for the weighted pairwise maximum likelihood estimator of a variance\nparameter.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jul 2018 09:33:21 GMT"}, {"version": "v2", "created": "Thu, 16 Aug 2018 08:12:10 GMT"}, {"version": "v3", "created": "Fri, 12 Jul 2019 15:06:42 GMT"}], "update_date": "2019-07-15", "authors_parsed": [["Bachoc", "Fran\u00e7ois", "", "IMT, GdR MASCOT-NUM"], ["Bevilacqua", "Moreno", ""], ["Velandia", "Daira", ""]]}, {"id": "1807.09076", "submitter": "Mikhail  Ermakov s", "authors": "Mikhail Ermakov", "title": "On consistency and inconsistency of nonparametric tests", "comments": "arXiv admin note: text overlap with arXiv:1708.04985", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For $\\chi^2-$tests with increasing number of cells, Cramer-von Mises tests,\ntests generated $\\mathbb{L}_2$- norms of kernel estimators and tests generated\nquadratic forms of estimators of Fourier coefficients, we find necessary and\nsufficient conditions of consistency and inconsistency for sequences of\nalternatives having a given rate of convergence to hypothesis in\n$\\mathbb{L}_2$-norm. We provide transparent interpretations of these conditions\nallowing to understand the structure of such consistent sequences. For problem\nof signal detection in Gaussian white noise we show that, if set of\nalternatives is bounded closed center-symmetric convex set $U$ with deleted\n\"small\" $\\mathbb{L}_2$ -- ball, then compactness of set $U$ is necessary\ncondition for existence of consistent tests.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jul 2018 13:00:13 GMT"}, {"version": "v2", "created": "Sun, 2 Sep 2018 13:14:14 GMT"}, {"version": "v3", "created": "Mon, 12 Nov 2018 16:56:23 GMT"}, {"version": "v4", "created": "Sat, 30 Mar 2019 12:21:48 GMT"}, {"version": "v5", "created": "Wed, 11 Sep 2019 20:34:24 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Ermakov", "Mikhail", ""]]}, {"id": "1807.09077", "submitter": "Rianne de Heide", "authors": "Allard Hendriksen, Rianne de Heide, Peter Gr\\\"unwald", "title": "Optional Stopping with Bayes Factors: a categorization and extension of\n  folklore results, with an application to invariant situations", "comments": "29 pages", "journal-ref": null, "doi": "10.1214/20-BA1234", "report-no": null, "categories": "math.ST cs.LG stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is often claimed that Bayesian methods, in particular Bayes factor methods\nfor hypothesis testing, can deal with optional stopping. We first give an\noverview, using elementary probability theory, of three different mathematical\nmeanings that various authors give to this claim: (1) stopping rule\nindependence, (2) posterior calibration and (3) (semi-) frequentist robustness\nto optional stopping. We then prove theorems to the effect that these claims do\nindeed hold in a general measure-theoretic setting. For claims of type (2) and\n(3), such results are new. By allowing for non-integrable measures based on\nimproper priors, we obtain particularly strong results for the practically\nimportant case of models with nuisance parameters satisfying a group invariance\n(such as location or scale). We also discuss the practical relevance of\n(1)--(3), and conclude that whether Bayes factor methods actually perform well\nunder optional stopping crucially depends on details of models, priors and the\ngoal of the analysis.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jul 2018 13:01:34 GMT"}, {"version": "v2", "created": "Sat, 21 Dec 2019 12:17:00 GMT"}, {"version": "v3", "created": "Wed, 29 Apr 2020 09:43:48 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Hendriksen", "Allard", ""], ["de Heide", "Rianne", ""], ["Gr\u00fcnwald", "Peter", ""]]}, {"id": "1807.09382", "submitter": "Arnak Dalalyan S.", "authors": "Arnak S.Dalalyan and Lionel Riou-Durand", "title": "On sampling from a log-concave density using kinetic Langevin diffusions", "comments": "In this version, the bound in Theorem 3 is better than in previous\n  versions, in terms of its dependence on the condition number", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Langevin diffusion processes and their discretizations are often used for\nsampling from a target density. The most convenient framework for assessing the\nquality of such a sampling scheme corresponds to smooth and strongly\nlog-concave densities defined on $\\mathbb R^p$. The present work focuses on\nthis framework and studies the behavior of Monte Carlo algorithms based on\ndiscretizations of the kinetic Langevin diffusion. We first prove the geometric\nmixing property of the kinetic Langevin diffusion with a mixing rate that is,\nin the overdamped regime, optimal in terms of its dependence on the condition\nnumber. We then use this result for obtaining improved guarantees of sampling\nusing the kinetic Langevin Monte Carlo method, when the quality of sampling is\nmeasured by the Wasserstein distance. We also consider the situation where the\nHessian of the log-density of the target distribution is Lipschitz-continuous.\nIn this case, we introduce a new discretization of the kinetic Langevin\ndiffusion and prove that this leads to a substantial improvement of the upper\nbound on the sampling error measured in Wasserstein distance.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jul 2018 23:04:49 GMT"}, {"version": "v2", "created": "Sat, 28 Jul 2018 10:15:13 GMT"}, {"version": "v3", "created": "Fri, 31 Aug 2018 13:31:53 GMT"}, {"version": "v4", "created": "Mon, 5 Nov 2018 17:42:34 GMT"}, {"version": "v5", "created": "Fri, 16 Nov 2018 16:54:48 GMT"}, {"version": "v6", "created": "Wed, 26 Dec 2018 10:28:42 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Dalalyan", "Arnak S.", ""], ["Riou-Durand", "Lionel", ""]]}, {"id": "1807.09613", "submitter": "Alexander Tartakovsky", "authors": "Serguei Pergamenchtchikov and Alexander G. Tartakovsky", "title": "Asymptotically Optimal Pointwise and Minimax Change-point Detection for\n  General Stochastic Models With a Composite Post-Change Hypothesis", "comments": "21 pages. arXiv admin note: text overlap with arXiv:1510.02903", "journal-ref": "Journal of Multivariate Analysis, 2019", "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A weighted Shiryaev-Roberts change detection procedure is shown to\napproximately minimize the expected delay to detection as well as higher\nmoments of the detection delay among all change-point detection procedures with\nthe given low maximal local probability of a false alarm within a window of a\nfixed length in pointwise and minimax settings for general non-i.i.d. data\nmodels and for the composite post-change hypothesis when the post-change\nparameter is unknown. We establish very general conditions for the models under\nwhich the weighted Shiryaev-Roberts procedure is asymptotically optimal. These\nconditions are formulated in terms of the rate of convergence in the strong law\nof large numbers for the log-likelihood ratios between the \"change\" and\n\"no-change\" hypotheses, and we also provide sufficient conditions for a large\nclass of ergodic Markov processes. Examples, where these conditions hold, are\ngiven.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jul 2018 08:48:33 GMT"}, {"version": "v2", "created": "Tue, 20 Nov 2018 13:54:49 GMT"}, {"version": "v3", "created": "Mon, 2 Sep 2019 09:00:59 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Pergamenchtchikov", "Serguei", ""], ["Tartakovsky", "Alexander G.", ""]]}, {"id": "1807.09633", "submitter": "Lutz Duembgen", "authors": "Lutz Duembgen and Laurie Davies", "title": "Connecting model-based and model-free approaches to linear least squares\n  regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a regression setting with response vector $\\mathbf{y} \\in \\mathbb{R}^n$\nand given regressor vectors $\\mathbf{x}_1,\\ldots,\\mathbf{x}_p \\in\n\\mathbb{R}^n$, a typical question is to what extent $\\mathbf{y}$ is related to\nthese regressor vectors, specifically, how well can $\\mathbf{y}$ be\napproximated by a linear combination of them. Classical methods for this\nquestion are based on statistical models for the conditional distribution of\n$\\mathbf{y}$, given the regressor vectors $\\mathbf{x}_j$. Davies and Duembgen\n(2020) proposed a model-free approach in which all observation vectors\n$\\mathbf{y}$ and $\\mathbf{x}_j$ are viewed as fixed, and the quality of the\nleast squares fit of $\\mathbf{y}$ is quantified by comparing it with the least\nsquares fit resulting from $p$ independent white noise regressor vectors. The\npurpose of the present note is to explain in a general context why the\nmodel-based and model-free approach yield the same p-values, although the\ninterpretation of the latter is different under the two paradigms.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jul 2018 14:36:48 GMT"}, {"version": "v2", "created": "Tue, 8 Sep 2020 08:29:55 GMT"}, {"version": "v3", "created": "Wed, 16 Sep 2020 15:22:05 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Duembgen", "Lutz", ""], ["Davies", "Laurie", ""]]}, {"id": "1807.09678", "submitter": "Wei Ma", "authors": "Wei Ma, Yichen Qin, Yang Li, Feifang Hu", "title": "Statistical Inference for Covariate-Adaptive Randomization Procedures", "comments": "Updated to the published version", "journal-ref": "Journal of the American Statistical Association, 115:531,\n  1488-1497 (2020)", "doi": "10.1080/01621459.2019.1635483", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Covariate-adaptive randomization (CAR) procedures are frequently used in\ncomparative studies to increase the covariate balance across treatment groups.\nHowever, because randomization inevitably uses the covariate information when\nforming balanced treatment groups, the validity of classical statistical\nmethods after such randomization is often unclear. In this article, we derive\nthe theoretical properties of statistical methods based on general CAR under\nthe linear model framework. More importantly, we explicitly unveil the\nrelationship between covariate-adaptive and inference properties by deriving\nthe asymptotic representations of the corresponding estimators. We apply the\nproposed general theory to various randomization procedures such as complete\nrandomization, rerandomization, pairwise sequential randomization, and\nAtkinson's $D_A$-biased coin design and compare their performance analytically.\nBased on the theoretical results, we then propose a new approach to obtain\nvalid and more powerful tests. These results open a door to understand and\nanalyze experiments based on CAR. Simulation studies provide further evidence\nof the advantages of the proposed framework and the theoretical results.\nSupplementary materials for this article are available online.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jul 2018 15:52:08 GMT"}, {"version": "v2", "created": "Mon, 7 Sep 2020 06:52:13 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Ma", "Wei", ""], ["Qin", "Yichen", ""], ["Li", "Yang", ""], ["Hu", "Feifang", ""]]}, {"id": "1807.09737", "submitter": "Hans Kersting", "authors": "Hans Kersting, T. J. Sullivan, Philipp Hennig", "title": "Convergence Rates of Gaussian ODE Filters", "comments": "26 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA math.ST stat.CO stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A recently-introduced class of probabilistic (uncertainty-aware) solvers for\nordinary differential equations (ODEs) applies Gaussian (Kalman) filtering to\ninitial value problems. These methods model the true solution $x$ and its first\n$q$ derivatives \\emph{a priori} as a Gauss--Markov process $\\boldsymbol{X}$,\nwhich is then iteratively conditioned on information about $\\dot{x}$. This\narticle establishes worst-case local convergence rates of order $q+1$ for a\nwide range of versions of this Gaussian ODE filter, as well as global\nconvergence rates of order $q$ in the case of $q=1$ and an integrated Brownian\nmotion prior, and analyses how inaccurate information on $\\dot{x}$ coming from\napproximate evaluations of $f$ affects these rates. Moreover, we show that, in\nthe globally convergent case, the posterior credible intervals are well\ncalibrated in the sense that they globally contract at the same rate as the\ntruncation error. We illustrate these theoretical results by numerical\nexperiments which might indicate their generalizability to $q \\in\n\\{2,3,\\dots\\}$.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jul 2018 17:33:55 GMT"}, {"version": "v2", "created": "Sun, 30 Jun 2019 18:11:45 GMT"}, {"version": "v3", "created": "Fri, 17 Jul 2020 16:54:44 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Kersting", "Hans", ""], ["Sullivan", "T. J.", ""], ["Hennig", "Philipp", ""]]}, {"id": "1807.09895", "submitter": "Mahmoud El-Morshedy", "authors": "M. El-Morshedy, M. S. Eliwa, and H. Nagy", "title": "Exponentiated Discrete Lindley Distribution: Properties and Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, the exponentiated discrete Lindley distribution is presented\nand studied. Some important distributional properties are discussed. Using the\nmaximum likelihood method, estimation of the model parameters is investigated.\nFurthermore, simulation study is performed to observe the performance of the\nestimates. Finally, the model with two real data sets is examined.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jul 2018 22:58:42 GMT"}], "update_date": "2018-07-27", "authors_parsed": [["El-Morshedy", "M.", ""], ["Eliwa", "M. S.", ""], ["Nagy", "H.", ""]]}, {"id": "1807.10042", "submitter": "Maryna Prus", "authors": "Maryna Prus", "title": "Optimal Designs in Multiple Group Random Coefficient Regression Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The subject of this work is multiple group random coefficients regression\nmodels with several treatments and one control group. Such models are often\nused for studies with cluster randomized trials. We investigate A-, D- and\nE-optimal designs for estimation and prediction of fixed and random treatment\neffects, respectively, and illustrate the obtained results by numerical\nexamples.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jul 2018 09:55:49 GMT"}], "update_date": "2018-07-27", "authors_parsed": [["Prus", "Maryna", ""]]}, {"id": "1807.10100", "submitter": "Matias Cattaneo", "authors": "Matias D. Cattaneo, Michael Jansson, Xinwei Ma", "title": "Two-Step Estimation and Inference with Possibly Many Included Covariates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the implications of including many covariates in a first-step\nestimate entering a two-step estimation procedure. We find that a first order\nbias emerges when the number of \\textit{included} covariates is \"large\"\nrelative to the square-root of sample size, rendering standard inference\nprocedures invalid. We show that the jackknife is able to estimate this \"many\ncovariates\" bias consistently, thereby delivering a new automatic\nbias-corrected two-step point estimator. The jackknife also consistently\nestimates the standard error of the original two-step point estimator. For\ninference, we develop a valid post-bias-correction bootstrap approximation that\naccounts for the additional variability introduced by the jackknife\nbias-correction. We find that the jackknife bias-corrected point estimator and\nthe bootstrap post-bias-correction inference perform excellent in simulations,\noffering important improvements over conventional two-step point estimators and\ninference procedures, which are not robust to including many covariates. We\napply our results to an array of distinct treatment effect, policy evaluation,\nand other applied microeconomics settings. In particular, we discuss production\nfunction and marginal treatment effect estimation in detail.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jul 2018 12:53:58 GMT"}], "update_date": "2018-07-27", "authors_parsed": [["Cattaneo", "Matias D.", ""], ["Jansson", "Michael", ""], ["Ma", "Xinwei", ""]]}, {"id": "1807.10375", "submitter": "Kun Chen", "authors": "Gen Li, Xiaokang Liu and Kun Chen", "title": "Integrative Multi-View Reduced-Rank Regression: Bridging Group-Sparse\n  and Low-Rank Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-view data have been routinely collected in various fields of science\nand engineering. A general problem is to study the predictive association\nbetween multivariate responses and multi-view predictor sets, all of which can\nbe of high dimensionality. It is likely that only a few views are relevant to\nprediction, and the predictors within each relevant view contribute to the\nprediction collectively rather than sparsely. We cast this new problem under\nthe familiar multivariate regression framework and propose an integrative\nreduced-rank regression (iRRR), where each view has its own low-rank\ncoefficient matrix. As such, latent features are extracted from each view in a\nsupervised fashion. For model estimation, we develop a convex composite nuclear\nnorm penalization approach, which admits an efficient algorithm via alternating\ndirection method of multipliers. Extensions to non-Gaussian and incomplete data\nare discussed. Theoretically, we derive non-asymptotic oracle bounds of iRRR\nunder a restricted eigenvalue condition. Our results recover oracle bounds of\nseveral special cases of iRRR including Lasso, group Lasso and nuclear norm\npenalized regression. Therefore, iRRR seamlessly bridges group-sparse and\nlow-rank methods and can achieve substantially faster convergence rate under\nrealistic settings of multi-view learning. Simulation studies and an\napplication in the Longitudinal Studies of Aging further showcase the efficacy\nof the proposed methods.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jul 2018 21:42:17 GMT"}], "update_date": "2018-07-30", "authors_parsed": [["Li", "Gen", ""], ["Liu", "Xiaokang", ""], ["Chen", "Kun", ""]]}, {"id": "1807.10678", "submitter": "Dennis Dobler", "authors": "Dennis Dobler and Markus Pauly", "title": "Survival of the Fittest Group: Factorial Analyses of Treatment Effects\n  under Independent Right-Censoring", "comments": "16 pages, 4 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces new effect parameters for factorial survival designs\nwith possibly right-censored time-to-event data. In the special case of a\ntwo-sample design it coincides with the concordance or Wilcoxon parameter in\nsurvival analysis. More generally, the new parameters describe treatment or\ninteraction effects and we develop estimates and tests to infer their presence.\nWe rigorously study the asymptotic properties by means of empirical process\ntechniques and additionally suggest wild bootstrapping for a consistent and\ndistribution-free application of the inference procedures. The small sample\nperformance is discussed based on simulation results. The practical usefulness\nof the developed methodology is exemplified on a data example about patients\nwith colon cancer by conducting one- and two-factorial analyses.\n", "versions": [{"version": "v1", "created": "Fri, 27 Jul 2018 15:19:03 GMT"}], "update_date": "2018-07-30", "authors_parsed": [["Dobler", "Dennis", ""], ["Pauly", "Markus", ""]]}, {"id": "1807.10763", "submitter": "Mahmoud Selim", "authors": "Mahmoud Ali Selim", "title": "The Generalized Power Generalized Weibull Distribution: Properties and\n  Applications", "comments": "15 pages, 7 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a new generalization of the power generalized Weibull\ndistribution called the generalized power generalized Weibull distribution.\nThis distribution can also be considered as a generalization of Weibull\ndistribution. The hazard rate function of the new model has nice and flexible\nproperties and it can take various shapes, including increasing, decreasing,\nupside-down bathtub and bathtub shapes. Some of the statistical properties of\nthe new model, including quantile function, moment generating function,\nreliability function, hazard function and the reverse hazard function are\nobtained. The moments, incomplete moments, mean deviations and Bonferroni and\nLorenz curves and the order statistics densities are also derived. The model\nparameters are estimated by the maximum likelihood method. The usefulness of\nthe proposed model is illustrated by using two applications of real-life data.\n", "versions": [{"version": "v1", "created": "Fri, 27 Jul 2018 17:01:22 GMT"}, {"version": "v2", "created": "Mon, 15 Oct 2018 07:04:23 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Selim", "Mahmoud Ali", ""]]}, {"id": "1807.10785", "submitter": "Ery Arias-Castro", "authors": "Ery Arias-Castro and Rong Huang", "title": "The Sparse Variance Contamination Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a Gaussian contamination (i.e., mixture) model where the\ncontamination manifests itself as a change in variance. We study this model in\nvarious asymptotic regimes, in parallel with the work of Ingster (1997) and\nDonoho and Jin (2004), who considered a similar model where the contamination\nwas in the mean instead.\n", "versions": [{"version": "v1", "created": "Fri, 27 Jul 2018 18:34:40 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Arias-Castro", "Ery", ""], ["Huang", "Rong", ""]]}, {"id": "1807.10797", "submitter": "Holger Dette", "authors": "H. Dette, G. M. Pan, Q. Yang", "title": "Estimating a change point in a sequence of very high-dimensional\n  covariance matrices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the problem of estimating a change point in the\ncovariance matrix in a sequence of high-dimensional vectors, where the\ndimension is substantially larger than the sample size. A two-stage approach is\nproposed to efficiently estimate the location of the change point. The first\nstep consists of a reduction of the dimension to identify elements of the\ncovariance matrices corresponding to significant changes. In a second step we\nuse the components after dimension reduction to determine the position of the\nchange point. Theoretical properties are developed for both steps and numerical\nstudies are conducted to support the new methodology.\n", "versions": [{"version": "v1", "created": "Fri, 27 Jul 2018 18:56:10 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Dette", "H.", ""], ["Pan", "G. M.", ""], ["Yang", "Q.", ""]]}, {"id": "1807.10801", "submitter": "Georg Hahn", "authors": "Georg Hahn", "title": "On the expected runtime of multiple testing algorithms with bounded\n  error", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider testing multiple hypotheses in the setting where the p-values of all\nhypotheses are unknown and thus have to be approximated using Monte Carlo\nsimulations. One class of algorithms published in the literature for this\nscenario provides guarantees on the correctness of their testing result through\nthe computation of confidence statements on all approximated p-values. This\narticle focuses on the expected runtime of such algorithms and derives a\nvariety of finite and infinite expected runtime results.\n", "versions": [{"version": "v1", "created": "Fri, 27 Jul 2018 19:01:02 GMT"}, {"version": "v2", "created": "Mon, 28 Jan 2019 17:31:13 GMT"}, {"version": "v3", "created": "Wed, 19 Feb 2020 22:23:33 GMT"}, {"version": "v4", "created": "Fri, 12 Jun 2020 20:49:10 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Hahn", "Georg", ""]]}, {"id": "1807.10902", "submitter": "Lourens  Waldorp", "authors": "Lourens Waldorp and Maarten Marsman and Gunter Maris", "title": "Logistic regression and Ising networks: prediction and estimation when\n  violating lasso assumptions", "comments": "to appear, Behaviormetrika, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Ising model was originally developed to model magnetisation of solids in\nstatistical physics. As a network of binary variables with the probability of\nbecoming 'active' depending only on direct neighbours, the Ising model appears\nappropriate for many other processes. For instance, it was recently applied in\npsychology to model co-occurrences of mental disorders. It has been shown that\nthe connections between the variables (nodes) in the Ising network can be\nestimated with a series of logistic regressions. This naturally leads to\nquestions of how well such a model predicts new observations and how well\nparameters of the Ising model can be estimated using logistic regressions. Here\nwe focus on the high-dimensional setting with more parameters than observations\nand consider violations of assumptions of the lasso. In particular, we\ndetermine the consequences for both prediction and estimation when the sparsity\nand restricted eigenvalue assumptions are not satisfied. We explain by using\nthe idea of connected copies (extreme multicollinearity) the fact that\nprediction becomes better when either sparsity or multicollinearity is not\nsatisfied. We illustrate these results with simulations.\n", "versions": [{"version": "v1", "created": "Sat, 28 Jul 2018 06:55:20 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Waldorp", "Lourens", ""], ["Marsman", "Maarten", ""], ["Maris", "Gunter", ""]]}, {"id": "1807.11027", "submitter": "Yuan Zhang", "authors": "Yuan Zhang", "title": "Consistent polynomial-time unseeded graph matching for Lipschitz\n  graphons", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CC cs.LG math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a consistent polynomial-time method for the unseeded node matching\nproblem for networks with smooth underlying structures. Despite widely\nconjectured by the research community that the structured graph matching\nproblem to be significantly easier than its worst case counterpart, well-known\nto be NP-hard, the statistical version of the problem has stood a challenge\nthat resisted any solution both provable and polynomial-time. The closest\nexisting work requires quasi-polynomial time. Our method is based on the latest\nadvances in graphon estimation techniques and analysis on the concentration of\nempirical Wasserstein distances. Its core is a simple yet unconventional\nsampling-and-matching scheme that reduces the problem from unseeded to seeded.\nOur method allows flexible efficiencies, is convenient to analyze and\npotentially can be extended to more general settings. Our work enables a rich\nvariety of subsequent estimations and inferences.\n", "versions": [{"version": "v1", "created": "Sun, 29 Jul 2018 09:25:37 GMT"}], "update_date": "2018-08-24", "authors_parsed": [["Zhang", "Yuan", ""]]}, {"id": "1807.11066", "submitter": "Reyhaneh Hosseini", "authors": "Reyhaneh Hosseini and Mahmoud Zarepour", "title": "A Note on Bayesian Nonparametric Inference for Spherically Symmetric\n  Distribution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we describe a Bayesian nonparametric approach to make\ninference for a bivariate spherically symmetric distribution. We consider a\nDirichlet invariant process prior on the set of all bivariate spherically\nsymmetric distributions and we derive the Dirichlet invariant process\nposterior. Indeed, our approach is an extension of Dirichlet invariant process\nfor the symmetric distributions on the real line to a bivariate spherically\nsymmetric distribution where the underlying distribution is invariant under a\nfinite group of rotations. Moreover, we obtain the Dirichlet invariant process\nposterior for the infinite transformation group and we prove that it approaches\nto Dirichlet process.\n", "versions": [{"version": "v1", "created": "Sun, 29 Jul 2018 15:06:30 GMT"}, {"version": "v2", "created": "Tue, 31 Jul 2018 18:35:40 GMT"}], "update_date": "2018-08-02", "authors_parsed": [["Hosseini", "Reyhaneh", ""], ["Zarepour", "Mahmoud", ""]]}, {"id": "1807.11260", "submitter": "Gerard Letac G.", "authors": "G\\'erard Letac", "title": "Cumulative distribution functions for the five simplest natural\n  exponential families", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Suppose that the distribution of $X_a$ belongs to a natural exponential\nfamily concentrated on the nonegative integers and is such that\n$\\E(z^{X_a})=f(az)/f(a)$. Assume that $\\Pr(X_a\\leq k)$ has the form $c_k\\int_a\n^{\\infty}u^k\\mu(du)$ for some number $c_k$ and some positive measure $\\mu,$\nboth independent of $a.$ We show that this asumption implies that the\nexponential family is either a binomial, or the Poisson, or a negative binomial\nfamily. Next, we study an analogous property for continuous distributions and\nwe find that it is satisfied if and only the families are either Gaussian or\nGamma. Ultimately, the proofs rely on the fact that only Moebius functions\npreserve the cross ratio,\n  \\textsc{Keywords:} Binomial, Poisson and negative binomial distributions.\nGaussian and Gamma distributions. Moebius transforms. Cross ratio.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jul 2018 09:55:47 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Letac", "G\u00e9rard", ""]]}, {"id": "1807.11331", "submitter": "Claudia Strauch", "authors": "Cathrine Aeckerle-Willems, Claudia Strauch", "title": "Concentration of scalar ergodic diffusions and some statistical\n  implications", "comments": "Consideration of more general diffusion coefficients in Section 4 and\n  5", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive uniform concentration inequalities for continuous-time analogues of\nempirical processes and related stochastic integrals of scalar ergodic\ndiffusion processes. Thereby, we lay the foundation typically required for the\nstudy of sup-norm properties of estimation procedures for a large class of\ndiffusion processes. In the classical i.i.d. context, a key device for the\nstatistical sup-norm analysis is provided by Talagrand-type concentration\ninequalities. Aiming for a parallel substitute in the diffusion framework, we\npresent a systematic, self-contained approach to such uniform concentration\ninequalities via martingale approximation and moment bounds obtained by the\ngeneric chaining method. The developed machinery is of independent\nprobabilistic interest and can serve as a starting point for investigations of\nother processes such as more general Markov processes, in particular\nmultivariate or discretely observed diffusions. As a first concrete statistical\napplication, we analyse the sup-norm error of estimating the invariant density\nof an ergodic diffusion via the natural local time estimator and the classical\nnonparametric kernel density estimator, respectively.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jul 2018 13:07:30 GMT"}, {"version": "v2", "created": "Fri, 12 Jul 2019 14:55:08 GMT"}], "update_date": "2019-07-15", "authors_parsed": [["Aeckerle-Willems", "Cathrine", ""], ["Strauch", "Claudia", ""]]}, {"id": "1807.11408", "submitter": "Rina Friedberg", "authors": "Rina Friedberg, Julie Tibshirani, Susan Athey, Stefan Wager", "title": "Local Linear Forests", "comments": "Forthcoming in the Journal of Computational and Graphical Statistics", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG econ.EM math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random forests are a powerful method for non-parametric regression, but are\nlimited in their ability to fit smooth signals, and can show poor predictive\nperformance in the presence of strong, smooth effects. Taking the perspective\nof random forests as an adaptive kernel method, we pair the forest kernel with\na local linear regression adjustment to better capture smoothness. The\nresulting procedure, local linear forests, enables us to improve on asymptotic\nrates of convergence for random forests with smooth signals, and provides\nsubstantial gains in accuracy on both real and simulated data. We prove a\ncentral limit theorem valid under regularity conditions on the forest and\nsmoothness constraints, and propose a computationally efficient construction\nfor confidence intervals. Moving to a causal inference application, we discuss\nthe merits of local regression adjustments for heterogeneous treatment effect\nestimation, and give an example on a dataset exploring the effect word choice\nhas on attitudes to the social safety net. Last, we include simulation results\non real and generated data.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jul 2018 16:01:53 GMT"}, {"version": "v2", "created": "Thu, 8 Nov 2018 03:24:46 GMT"}, {"version": "v3", "created": "Thu, 20 Jun 2019 16:19:08 GMT"}, {"version": "v4", "created": "Fri, 4 Sep 2020 23:50:48 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Friedberg", "Rina", ""], ["Tibshirani", "Julie", ""], ["Athey", "Susan", ""], ["Wager", "Stefan", ""]]}, {"id": "1807.11863", "submitter": "Jiaying Gu", "authors": "Antonio F. Galvao, Jiaying Gu, Stanislav Volgushev", "title": "On the Unbiased Asymptotic Normality of Quantile Regression with Fixed\n  Effects", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonlinear panel data models with fixed individual effects provide an\nimportant set of tools for describing microeconometric data. In a large class\nof such models (including probit, proportional hazard and quantile regression\nto name just a few) it is impossible to difference out individual effects, and\ninference is usually justified in a `large n large T' asymptotic framework.\nHowever, there is a considerable gap in the type of assumptions that are\ncurrently imposed in models with smooth score functions (such as probit, and\nproportional hazard) and quantile regression. In the present paper we show that\nthis gap can be bridged and establish asymptotic unbiased normality for\nquantile regression panels under conditions on n,T that are very close to what\nis typically assumed in standard nonlinear panels. Our results considerably\nimprove upon existing theory and show that quantile regression is applicable to\nthe same type of panel data (in terms of n,T) as other commonly used nonlinear\npanel data models. Thorough numerical experiments confirm our theoretical\nfindings.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jul 2018 15:17:56 GMT"}, {"version": "v2", "created": "Thu, 6 Feb 2020 15:25:43 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Galvao", "Antonio F.", ""], ["Gu", "Jiaying", ""], ["Volgushev", "Stanislav", ""]]}]