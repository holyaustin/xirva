[{"id": "1702.00001", "submitter": "Emilie Kaufmann", "authors": "Emilie Kaufmann (SEQUEL, CRIStAL, CNRS), Aur\\'elien Garivier (IMT)", "title": "Learning the distribution with largest mean: two bandit frameworks", "comments": null, "journal-ref": "ESAIM: Proceedings and Surveys, EDP Sciences, A Para{\\^i}tre,\n  2017, pp.1 - 10", "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past few years, the multi-armed bandit model has become increasingly\npopular in the machine learning community, partly because of applications\nincluding online content optimization. This paper reviews two different\nsequential learning tasks that have been considered in the bandit literature ;\nthey can be formulated as (sequentially) learning which distribution has the\nhighest mean among a set of distributions, with some constraints on the\nlearning process. For both of them (regret minimization and best arm\nidentification) we present recent, asymptotically optimal algorithms. We\ncompare the behaviors of the sampling rule of each algorithm as well as the\ncomplexity terms associated to each problem.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jan 2017 07:45:32 GMT"}, {"version": "v2", "created": "Fri, 24 Mar 2017 07:30:56 GMT"}, {"version": "v3", "created": "Tue, 7 Nov 2017 07:06:06 GMT"}], "update_date": "2017-11-08", "authors_parsed": [["Kaufmann", "Emilie", "", "SEQUEL, CRIStAL, CNRS"], ["Garivier", "Aur\u00e9lien", "", "IMT"]]}, {"id": "1702.00111", "submitter": "Ranjan Maitra", "authors": "Israel Almod\\'ovar-Rivera and Ranjan Maitra", "title": "FAST Adaptive Smoothing and Thresholding for Improved Activation\n  Detection in Low-Signal fMRI", "comments": "26 pages, 2 tables, 19 figures. Accepted for publication in IEEE\n  Transactions on Medical Imaging", "journal-ref": null, "doi": "10.1109/TMI.2019.2915052", "report-no": null, "categories": "stat.ME math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Functional Magnetic Resonance Imaging is a noninvasive tool for studying\ncerebral function. Many factors challenge activation detection, especially in\nlow-signal scenarios that arise in the performance of high-level cognitive\ntasks. We provide a fully automated fast adaptive smoothing and thresholding\n(FAST) algorithm that uses smoothing and extreme value theory on correlated\nstatistical parametric maps for thresholding. Performance on experiments\nspanning a range of low-signal settings is very encouraging. The methodology\nalso performs well in a study to identify the cerebral regions that perceive\nonly-auditory-reliable or only-visual-reliable speech stimuli.\n", "versions": [{"version": "v1", "created": "Wed, 1 Feb 2017 03:17:50 GMT"}, {"version": "v2", "created": "Thu, 2 Feb 2017 03:12:48 GMT"}, {"version": "v3", "created": "Tue, 30 Oct 2018 18:08:37 GMT"}, {"version": "v4", "created": "Sun, 5 May 2019 04:55:49 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Almod\u00f3var-Rivera", "Israel", ""], ["Maitra", "Ranjan", ""]]}, {"id": "1702.00141", "submitter": "Pradip Kundu", "authors": "Pradip Kundu and Asok K. Nanda", "title": "Reliability study of proportional odds family of discrete distributions", "comments": null, "journal-ref": "Communications in Statistics - Theory and Methods 47(5) (2018)\n  1091-1103", "doi": "10.1080/03610926.2017.1316397", "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The proportional odds model gives a method of generating new family of\ndistributions by adding a parameter, called tilt parameter, to expand an\nexisting family of distributions. The new family of distributions so obtained\nis known as Marshall-Olkin family of distributions or Marshall-Olkin extended\ndistributions. In this paper, we consider Marshall-Olkin family of\ndistributions in discrete case with fixed tilt parameter. We study different\nageing properties, as well as different stochastic orderings of this family of\ndistributions. All the results of this paper are supported by several examples.\n", "versions": [{"version": "v1", "created": "Wed, 1 Feb 2017 06:01:39 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Kundu", "Pradip", ""], ["Nanda", "Asok K.", ""]]}, {"id": "1702.00378", "submitter": "Mehmet Niyazi Cankaya mehmetn", "authors": "Mehmet Niyazi Cankaya and Olcay Arslan", "title": "M-Estimation Method Based Asymmetric Objective Function", "comments": "31 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The asymmetric objective function is proposed as an alternative to Huber\nobjective function to model skewness and obtain robust estimators for the\nlocation, scale and skewness parameters. The robustness and asymptotic\nproperties of the asymmetric M-estimators are explored. A simulation study and\nreal data examples are given to illustrate the performance of proposed\nasymmetric M-estimation method over the symmetric M-estimation method. It is\nobserved from the simulation results that the asymmetric M-estimators perform\nbetter than Huber M-estimators when the data have skewness. The application on\nregression is also considered.\n", "versions": [{"version": "v1", "created": "Wed, 1 Feb 2017 18:10:30 GMT"}], "update_date": "2017-02-02", "authors_parsed": [["Cankaya", "Mehmet Niyazi", ""], ["Arslan", "Olcay", ""]]}, {"id": "1702.00482", "submitter": "Gabor Lugosi", "authors": "G\\'abor Lugosi and Shahar Mendelson", "title": "Sub-Gaussian estimators of the mean of a random vector", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of estimating the mean of a random vector $X$ given a\nsample of $N$ independent, identically distributed points. We introduce a new\nestimator that achieves a purely sub-Gaussian performance under the only\ncondition that the second moment of $X$ exists. The estimator is based on a\nnovel concept of a multivariate median.\n", "versions": [{"version": "v1", "created": "Wed, 1 Feb 2017 22:33:36 GMT"}], "update_date": "2017-02-03", "authors_parsed": [["Lugosi", "G\u00e1bor", ""], ["Mendelson", "Shahar", ""]]}, {"id": "1702.00556", "submitter": "Shravan Vasishth", "authors": "Shravan Vasishth and Andrew Gelman", "title": "The statistical significance filter leads to overconfident expectations\n  of replicability", "comments": "6 pages, 3 figures. Submitted to the conference Cognitive Science\n  2017, London, UK", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that publishing results using the statistical significance\nfilter---publishing only when the p-value is less than 0.05---leads to a\nvicious cycle of overoptimistic expectation of the replicability of results.\nFirst, we show analytically that when true statistical power is relatively low,\ncomputing power based on statistically significant results will lead to\noverestimates of power. Then, we present a case study using 10 experimental\ncomparisons drawn from a recently published meta-analysis in psycholinguistics\n(J\\\"ager et al., 2017). We show that the statistically significant results\nyield an illusion of replicability. This illusion holds even if the researcher\ndoesn't conduct any formal power analysis but just uses statistical\nsignificance to informally assess robustness (i.e., replicability) of results.\n", "versions": [{"version": "v1", "created": "Thu, 2 Feb 2017 07:14:21 GMT"}, {"version": "v2", "created": "Sun, 14 May 2017 06:24:02 GMT"}], "update_date": "2017-05-16", "authors_parsed": [["Vasishth", "Shravan", ""], ["Gelman", "Andrew", ""]]}, {"id": "1702.00628", "submitter": "Fatma Zehra Do\\u{g}ru", "authors": "Fatma Zehra Do\\u{g}ru, Y. Murat Bulut and Olcay Arslan", "title": "Finite Mixtures of Multivariate Skew Laplace Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose finite mixtures of multivariate skew Laplace\ndistributions to model both skewness and heavy-tailedness in the heterogeneous\ndata sets. The maximum likelihood estimators for the parameters of interest are\nobtained by using the EM algorithm. We give a small simulation study and a real\ndata example to illustrate the performance of the proposed mixture model.\n", "versions": [{"version": "v1", "created": "Thu, 2 Feb 2017 11:39:48 GMT"}], "update_date": "2017-02-03", "authors_parsed": [["Do\u011fru", "Fatma Zehra", ""], ["Bulut", "Y. Murat", ""], ["Arslan", "Olcay", ""]]}, {"id": "1702.00633", "submitter": "James Barrett", "authors": "James E. Barrett, Andrew Feber, Javier Herrero, Miljana Tanic, Gareth\n  Wilson, Charles Swanton, Stephan Beck", "title": "Quantification of tumour evolution and heterogeneity via Bayesian\n  epiallele detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM math.ST q-bio.GN stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivation: Epigenetic heterogeneity within a tumour can play an important\nrole in tumour evolution and the emergence of resistance to treatment. It is\nincreasingly recognised that the study of DNA methylation (DNAm) patterns along\nthe genome -- so-called `epialleles' -- offers greater insight into epigenetic\ndynamics than conventional analyses which examine DNAm marks individually.\n  Results: We have developed a Bayesian model to infer which epialleles are\npresent in multiple regions of the same tumour. We apply our method to reduced\nrepresentation bisulfite sequencing (RRBS) data from multiple regions of one\nlung cancer tumour and a matched normal sample. The model borrows information\nfrom all tumour regions to leverage greater statistical power. The total number\nof epialleles, the epiallele DNAm patterns, and a noise hyperparameter are all\nautomatically inferred from the data. Uncertainty as to which epiallele an\nobserved sequencing read originated from is explicitly incorporated by\nmarginalising over the appropriate posterior densities. The degree to which\ntumour samples are contaminated with normal tissue can be estimated and\ncorrected for. By tracing the distribution of epialleles throughout the tumour\nwe can infer the phylogenetic history of the tumour, identify epialleles that\ndiffer between normal and cancer tissue, and define a measure of global\nepigenetic disorder.\n", "versions": [{"version": "v1", "created": "Thu, 2 Feb 2017 12:00:08 GMT"}, {"version": "v2", "created": "Mon, 20 Feb 2017 16:26:20 GMT"}], "update_date": "2017-02-21", "authors_parsed": [["Barrett", "James E.", ""], ["Feber", "Andrew", ""], ["Herrero", "Javier", ""], ["Tanic", "Miljana", ""], ["Wilson", "Gareth", ""], ["Swanton", "Charles", ""], ["Beck", "Stephan", ""]]}, {"id": "1702.00662", "submitter": "Robert Phillips", "authors": "Robert F. Phillips", "title": "Quasi Maximum-Likelihood Estimation of Dynamic Panel Data Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper establishes the almost sure convergence and asymptotic normality\nof levels and differenced quasi maximum-likelihood (QML) estimators of dynamic\npanel data models. The QML estimators are robust with respect to initial\nconditions, conditional and time-series heteroskedasticity, and\nmisspecification of the log-likelihood. The paper also provides an ECME\nalgorithm for calculating levels QML estimates. Finally, it uses Monte Carlo\nexperiments to compare the finite sample performance of levels and differenced\nQML estimators, the differenced GMM estimator, and the system GMM estimator. In\nthese experiments the QML estimators usually have smaller --- typically\nsubstantially smaller --- bias and root mean squared errors than the panel data\nGMM estimators.\n", "versions": [{"version": "v1", "created": "Thu, 2 Feb 2017 13:14:21 GMT"}], "update_date": "2017-02-03", "authors_parsed": [["Phillips", "Robert F.", ""]]}, {"id": "1702.00708", "submitter": "Anil Aswani", "authors": "Anil Aswani", "title": "Statistics with Set-Valued Functions: Applications to Inverse\n  Approximate Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much of statistics relies upon four key elements: a law of large numbers, a\ncalculus to operationalize stochastic convergence, a central limit theorem, and\na framework for constructing local approximations. These elements are\nwell-understood for objects in a vector space (e.g., points or functions);\nhowever, much statistical theory does not directly translate to sets because\nthey do not form a vector space. Building on probability theory for random\nsets, this paper uses variational analysis to develop operational tools for\nstatistics with set-valued functions. These tools are first applied to\nnonparametric estimation (kernel regression of set-valued functions). The\nsecond application is to the problem of inverse approximate optimization, in\nwhich approximate solutions (corrupted by noise) to an optimization problem are\nobserved and then used to estimate the amount of suboptimality of the solutions\nand the parameters of the optimization problem that generated the solutions. We\nshow that previous approaches to this problem are statistically inconsistent\nwhen the data is corrupted by noise, whereas our approach is consistent under\nmild conditions.\n", "versions": [{"version": "v1", "created": "Thu, 2 Feb 2017 14:57:43 GMT"}, {"version": "v2", "created": "Mon, 8 Jan 2018 17:12:10 GMT"}], "update_date": "2018-01-09", "authors_parsed": [["Aswani", "Anil", ""]]}, {"id": "1702.00836", "submitter": "Myung Hwan Seo", "authors": "Javier Hidalgo, Jungyoon Lee, Myung Hwan Seo", "title": "Robust inference for threshold regression models", "comments": "56 pages, 3 figures", "journal-ref": "Journal of Econometrics (2019), 210 (2), 291-309", "doi": "10.1016/j.jeconom.2019.01.008", "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is concerned with inference in threshold regression models when\nthe practitioners do not know whether at the threshold point the true\nspecification has a kink or a jump. We nest previous works that assume either\ncontinuity or discontinuity at the threshold point and develop robust inference\nmethods on the parameters of the model, which are valid under both\nspecifications. In particular, we found that the parameter values under the\nkink restriction are irregular points of the Hessian matrix of the expected\nGaussian quasi-likelihood. This irregularity destroys the asymptotic normality\nand induces the non-standard cube root convergence rate for the threshold\nestimate. However, it also enables us to obtain the same asymptotic\ndistribution as in Hansen (2000) for the quasi-likelihood ratio statistic for\nthe unknown threshold up to an unknown scale parameter. We show that this scale\nparameter can be consistently estimated by a kernel method as long as no higher\norder kernel is used. Furthermore, we propose to construct confidence intervals\nfor the unknown threshold by bootstrap test inversion, also known as grid\nbootstrap. Finite sample performances of the grid bootstrap confidence\nintervals are examined through Monte Carlo simulations. We also implement our\nprocedure to an economic empirical application.\n", "versions": [{"version": "v1", "created": "Thu, 2 Feb 2017 21:38:47 GMT"}, {"version": "v2", "created": "Mon, 12 Nov 2018 15:18:43 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Hidalgo", "Javier", ""], ["Lee", "Jungyoon", ""], ["Seo", "Myung Hwan", ""]]}, {"id": "1702.00842", "submitter": "Yaroslav Tsaregorodtsev", "authors": "Yaroslav Tsaregorodtsev", "title": "Asymptotic normality of element-wise weighted total least squares\n  estimator in a multivariate errors-in-variables model", "comments": "Inaccuracies were corrected. In the score function appeared a new\n  factor that independent of observations. All theorems remained unchanged.\n  There were no new restrictions on the model", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A multivariable measurement error model $AX \\approx B$ is considered. Here\n$A$ and $B$ are input and output matrices of measurements and $X$ is a\nrectangular matrix of fixed size to be estimated. The errors in $[A,B]$ are\nrow-wise independent, but within each row the errors may be correlated. Some of\nthe columns are observed without errors and the error covariance matrices may\ndiffer from row to row. The total covariance structure of the errors is known\nup to a scalar factor. The fully weighted total least squares estimator of $X$\nis studied. We give conditions for asymptotic normality of the estimator, as\nthe number of rows in $A$ is increasing. We provide that the covariance\nstructure of the limiting Gaussian random matrix is nonsingular.\n", "versions": [{"version": "v1", "created": "Thu, 2 Feb 2017 22:06:39 GMT"}, {"version": "v2", "created": "Wed, 15 Mar 2017 19:35:47 GMT"}], "update_date": "2017-03-17", "authors_parsed": [["Tsaregorodtsev", "Yaroslav", ""]]}, {"id": "1702.00908", "submitter": "Yuma Uehara", "authors": "Yuma Uehara", "title": "Statistical inference for misspecified ergodic L\\'evy driven stochastic\n  differential equation models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with the estimation problem of misspecified ergodic L\\'evy\ndriven stochastic differential equation models based on high-frequency samples.\nWe utilize the widely applicable and tractable Gaussian quasi-likelihood\napproach which focuses on (conditional) mean and variance structure. It is\nshown that the corresponding Gaussian quasi-likelihood estimators of drift and\nscale parameters satisfy tail probability estimates and asymptotic normality at\nthe same rate as correctly specified case. In this process, extended Poisson\nequation for time-homogeneous Feller Markov processes plays an important role\nto handle misspecification effect. Our result confirms the practical usefulness\nof the Gaussian quasi-likelihood approach for SDE models, more firmly.\n", "versions": [{"version": "v1", "created": "Fri, 3 Feb 2017 05:10:56 GMT"}, {"version": "v2", "created": "Mon, 3 Apr 2017 05:37:14 GMT"}, {"version": "v3", "created": "Tue, 10 Jul 2018 01:01:31 GMT"}], "update_date": "2018-07-11", "authors_parsed": [["Uehara", "Yuma", ""]]}, {"id": "1702.00925", "submitter": "Veronique Maume-Deschamps", "authors": "V\\'eronique Maume-Deschamps (ICJ), Ibrahima Niang", "title": "Estimation of quantile oriented sensitivity indices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper concerns quantile oriented sensitivity analysis. We rewrite the\ncorresponding indices using the Conditional Tail Expectation risk measure.\nThen, we use this new expression to built estimators.\n", "versions": [{"version": "v1", "created": "Fri, 3 Feb 2017 07:34:31 GMT"}], "update_date": "2017-02-06", "authors_parsed": [["Maume-Deschamps", "V\u00e9ronique", "", "ICJ"], ["Niang", "Ibrahima", ""]]}, {"id": "1702.00931", "submitter": "Antoine Godichon-Baggioni", "authors": "Antoine Godichon-Baggioni", "title": "Online estimation of the asymptotic variance for averaged stochastic\n  gradient algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic gradient algorithms are more and more studied since they can deal\nefficiently and online with large samples in high dimensional spaces. In this\npaper, we first establish a Central Limit Theorem for these estimates as well\nas for their averaged version in general Hilbert spaces. Moreover, since having\nthe asymptotic normality of estimates is often unusable without an estimation\nof the asymptotic variance, we introduce a new recursive algorithm for\nestimating this last one, and we establish its almost sure rate of convergence\nas well as its rate of convergence in quadratic mean. Finally, two examples\nconsisting in estimating the parameters of the logistic regression and\nestimating geometric quantiles are given.\n", "versions": [{"version": "v1", "created": "Fri, 3 Feb 2017 08:16:48 GMT"}, {"version": "v2", "created": "Mon, 16 Oct 2017 11:50:39 GMT"}], "update_date": "2017-10-17", "authors_parsed": [["Godichon-Baggioni", "Antoine", ""]]}, {"id": "1702.01081", "submitter": "Dennis Dobler", "authors": "Dennis Dobler", "title": "A Discontinuity Adjustment for Subdistribution Function Confidence Bands\n  Applied to Right-Censored Competing Risks Data", "comments": "32 pages, 14 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The wild bootstrap is the resampling method of choice in survival analytic\napplications. Theoretic justifications rely on the assumption of existing\nintensity functions which is equivalent to an exclusion of ties among the event\ntimes. However, such ties are omnipresent in practical studies. It turns out\nthat the wild bootstrap should only be applied in a modified manner that\ncorrects for altered limit variances and emerging dependencies. This again\nensures the asymptotic exactness of inferential procedures. An analogous\nnecessity is the use of the Greenwood-type variance estimator for Nelson-Aalen\nestimators which is particularly preferred in tied data regimes. All theoretic\narguments are transferred to bootstrapping Aalen-Johansen estimators for\ncumulative incidence functions in competing risks. An extensive simulation\nstudy as well as an application to real competing risks data of male intensive\ncare unit patients suffering from pneumonia illustrate the practicability of\nthe proposed technique.\n", "versions": [{"version": "v1", "created": "Fri, 3 Feb 2017 17:13:11 GMT"}], "update_date": "2017-02-06", "authors_parsed": [["Dobler", "Dennis", ""]]}, {"id": "1702.01164", "submitter": "Jose Figueroa-Lopez", "authors": "Jose E. Figueroa-Lopez and K. Lee", "title": "Estimation of a noisy subordinated Brownian Motion via two-scales power\n  variations", "comments": "2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST q-fin.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High frequency based estimation methods for a semiparametric pure-jump\nsubordinated Brownian motion exposed to a small additive microstructure noise\nare developed building on the two-scales realized variations approach\noriginally developed by Zhang et. al. (2005) for the estimation of the\nintegrated variance of a continuous Ito process. The proposed estimators are\nshown to be robust against the noise and, surprisingly, to attain better rates\nof convergence than their precursors, method of moment estimators, even in the\nabsence of microstructure noise. Our main results give approximate optimal\nvalues for the number K of regular sparse subsamples to be used, which is an\nimportant tune-up parameter of the method. Finally, a data-driven plug-in\nprocedure is devised to implement the proposed estimators with the optimal\nK-value. The developed estimators exhibit superior performance as illustrated\nby Monte Carlo simulations and a real high-frequency data application.\n", "versions": [{"version": "v1", "created": "Fri, 3 Feb 2017 21:22:43 GMT"}], "update_date": "2017-02-07", "authors_parsed": [["Figueroa-Lopez", "Jose E.", ""], ["Lee", "K.", ""]]}, {"id": "1702.01185", "submitter": "Jerrad Hampton", "authors": "Jerrad Hampton, Alireza Doostan", "title": "Basis Adaptive Sample Efficient Polynomial Chaos (BASE-PC)", "comments": null, "journal-ref": null, "doi": "10.1016/j.jcp.2018.03.035", "report-no": null, "categories": "stat.CO math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For a large class of orthogonal basis functions, there has been a recent\nidentification of expansion methods for computing accurate, stable\napproximations of a quantity of interest. This paper presents, within the\ncontext of uncertainty quantification, a practical implementation using basis\nadaptation, and coherence motivated sampling, which under assumptions has\nsatisfying guarantees. This implementation is referred to as Basis Adaptive\nSample Efficient Polynomial Chaos (BASE-PC). A key component of this is the use\nof anisotropic polynomial order which admits evolving global bases for\napproximation in an efficient manner, leading to consistently stable\napproximation for a practical class of smooth functionals. This fully adaptive,\nnon-intrusive method, requires no a priori information of the solution, and has\nsatisfying theoretical guarantees of recovery. A key contribution to stability\nis the use of a presented correction sampling for coherence-optimal sampling in\norder to improve stability and accuracy within the adaptive basis scheme.\nTheoretically, the method may dramatically reduce the impact of dimensionality\nin function approximation, and numerically the method is demonstrated to\nperform well on problems with dimension up to 1000.\n", "versions": [{"version": "v1", "created": "Fri, 3 Feb 2017 22:07:37 GMT"}], "update_date": "2018-06-13", "authors_parsed": [["Hampton", "Jerrad", ""], ["Doostan", "Alireza", ""]]}, {"id": "1702.01225", "submitter": "Taposh Banerjee", "authors": "Taposh Banerjee and Alfred O. Hero III", "title": "Quickest Hub Discovery in Correlation Graphs", "comments": "Asilomar 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT math.IT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A sequential test is proposed for detection and isolation of hubs in a\ncorrelation graph. Hubs in a correlation graph of a random vector are variables\n(nodes) that have a strong correlation edge. It is assumed that the random\nvectors are high-dimensional and are multivariate Gaussian distributed. The\ntest employs a family of novel local and global summary statistics generated\nfrom small samples of the random vectors. Delay and false alarm analysis of the\ntest is obtained and numerical results are provided to show that the test is\nconsistent in identifying hubs, as the false alarm rate goes to zero.\n", "versions": [{"version": "v1", "created": "Sat, 4 Feb 2017 02:19:38 GMT"}], "update_date": "2017-02-07", "authors_parsed": [["Banerjee", "Taposh", ""], ["Hero", "Alfred O.", "III"]]}, {"id": "1702.01330", "submitter": "Guang Cheng", "authors": "Yun Yang and Zuofeng Shang and Guang Cheng", "title": "Non-asymptotic theory for nonparametric testing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider nonparametric testing in a non-asymptotic framework. Our\nstatistical guarantees are exact in the sense that Type I and II errors are\ncontrolled for any finite sample size. Meanwhile, one proposed test is shown to\nachieve minimax optimality in the asymptotic sense. An important consequence of\nthis non-asymptotic theory is a new and practically useful formula for\nselecting the optimal smoothing parameter in nonparametric testing. The leading\nexample in this paper is smoothing spline models under Gaussian errors. The\nresults obtained therein can be further generalized to the kernel ridge\nregression framework under possibly non-Gaussian errors. Simulations\ndemonstrate that our proposed test improves over the conventional asymptotic\ntest when sample size is small to moderate.\n", "versions": [{"version": "v1", "created": "Sat, 4 Feb 2017 19:39:07 GMT"}], "update_date": "2017-02-07", "authors_parsed": [["Yang", "Yun", ""], ["Shang", "Zuofeng", ""], ["Cheng", "Guang", ""]]}, {"id": "1702.01400", "submitter": "Alfredo Alegr\\'ia", "authors": "Alfredo Alegr\\'ia, Emilio Porcu", "title": "Space-Time Geostatistical Models with both Linear and Seasonal\n  Structures in the Temporal Components", "comments": "The model that we propose has some counterintuitive properties", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a novel approach to model space-time random fields where the\ntemporal argument is decomposed into two parts. The former captures the linear\nargument, which is related, for instance, to the annual evolution of the field.\nThe latter is instead a circular variable describing, for instance, monthly\nobservations. The basic intuition behind this construction is to consider a\nrandom field defined over space (a compact set of the $d$-dimensional Euclidean\nspace) across time, which is considered as the product space $\\mathbb{R} \\times\n\\mathbb{S}^1$, with $\\mathbb{S}^1$ being the unit circle. Under such framework,\nwe derive new parametric families of covariance functions. In particular, we\nfocus on two classes of parametric families. The former being parenthetical to\nthe Gneiting class of covariance functions. The latter is instead obtained by\nproposing a new Lagrangian framework for the space-time domain considered in\nthe manuscript. Our findings are illustrated through a real dataset of surface\nair temperatures. We show that the incorporation of both temporal variables can\nproduce significant improvements in the predictive performances of the model.\nWe also discuss the extension of this approach for fields defined spatially on\na sphere, which allows to model space-time phenomena over large portions of\nplanet Earth.\n", "versions": [{"version": "v1", "created": "Sun, 5 Feb 2017 13:23:16 GMT"}, {"version": "v2", "created": "Mon, 13 Feb 2017 03:38:16 GMT"}, {"version": "v3", "created": "Wed, 17 Jan 2018 12:23:29 GMT"}], "update_date": "2018-01-18", "authors_parsed": [["Alegr\u00eda", "Alfredo", ""], ["Porcu", "Emilio", ""]]}, {"id": "1702.01402", "submitter": "Guillaume Lecu\\'e", "authors": "Pierre Alquier, Vincent Cottet, Guillaume Lecu\\'e", "title": "Estimation bounds and sharp oracle inequalities of regularized\n  procedures with Lipschitz loss functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We obtain estimation error rates and sharp oracle inequalities for\nregularization procedures of the form \\begin{equation*}\n  \\hat f \\in argmin_{f\\in\n  F}\\left(\\frac{1}{N}\\sum_{i=1}^N\\ell(f(X_i), Y_i)+\\lambda \\|f\\|\\right)\n\\end{equation*} when $\\|\\cdot\\|$ is any norm, $F$ is a convex class of\nfunctions and $\\ell$ is a Lipschitz loss function satisfying a Bernstein\ncondition over $F$. We explore both the bounded and subgaussian stochastic\nframeworks for the distribution of the $f(X_i)$'s, with no assumption on the\ndistribution of the $Y_i$'s. The general results rely on two main objects: a\ncomplexity function, and a sparsity equation, that depend on the specific\nsetting in hand (loss $\\ell$ and norm $\\|\\cdot\\|$).\n  As a proof of concept, we obtain minimax rates of convergence in the\nfollowing problems: 1) matrix completion with any Lipschitz loss function,\nincluding the hinge and logistic loss for the so-called 1-bit matrix completion\ninstance of the problem, and quantile losses for the general case, which\nenables to estimate any quantile on the entries of the matrix; 2) logistic\nLASSO and variants such as the logistic SLOPE; 3) kernel methods, where the\nloss is the hinge loss, and the regularization function is the RKHS norm.\n", "versions": [{"version": "v1", "created": "Sun, 5 Feb 2017 14:06:23 GMT"}, {"version": "v2", "created": "Tue, 7 Feb 2017 15:38:01 GMT"}], "update_date": "2017-02-08", "authors_parsed": [["Alquier", "Pierre", ""], ["Cottet", "Vincent", ""], ["Lecu\u00e9", "Guillaume", ""]]}, {"id": "1702.01591", "submitter": "Robin Ince", "authors": "Robin A. A. Ince", "title": "The Partial Entropy Decomposition: Decomposing multivariate entropy and\n  mutual information via pointwise common surprisal", "comments": "Added Section 3.7 (Quantifying source vs mechanistic redundancy) and\n  Section 3.8 (Shared entropy as a measure of dependence: pure mutual\n  information) and updated abstract, results, and discussion accordingly", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT math.ST q-bio.NC q-bio.QM stat.ME stat.TH", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Obtaining meaningful quantitative descriptions of the statistical dependence\nwithin multivariate systems is a difficult open problem. Recently, the Partial\nInformation Decomposition (PID) was proposed to decompose mutual information\n(MI) about a target variable into components which are redundant, unique and\nsynergistic within different subsets of predictor variables. Here, we propose\nto apply the elegant formalism of the PID to multivariate entropy, resulting in\na Partial Entropy Decomposition (PED). We implement the PED with an entropy\nredundancy measure based on pointwise common surprisal; a natural definition\nwhich is closely related to the definition of MI. We show how this approach can\nreveal the dyadic vs triadic generative structure of multivariate systems that\nare indistinguishable with classical Shannon measures. The entropy perspective\nalso shows that misinformation is synergistic entropy and hence that MI itself\nincludes both redundant and synergistic effects. We show the relationships\nbetween the PED and MI in two predictors, and derive two alternative\ninformation decompositions which we illustrate on several example systems. This\nreveals that in entropy terms, univariate predictor MI is not a proper subset\nof the joint MI, and we suggest this previously unrecognised fact explains in\npart why obtaining a consistent PID has proven difficult. The PED also allows\nseparate quantification of mechanistic redundancy (related to the function of\nthe system) versus source redundancy (arising from dependencies between\ninputs); an important distinction which no existing methods can address. The\nnew perspective provided by the PED helps to clarify some of the difficulties\nencountered with the PID approach and the resulting decompositions provide\nuseful tools for practical data analysis across a wide range of application\nareas.\n", "versions": [{"version": "v1", "created": "Mon, 6 Feb 2017 12:28:27 GMT"}, {"version": "v2", "created": "Mon, 20 Feb 2017 16:11:20 GMT"}], "update_date": "2017-02-21", "authors_parsed": [["Ince", "Robin A. A.", ""]]}, {"id": "1702.01696", "submitter": "Marta Ferreira", "authors": "Helena Ferreira and Marta Ferreira", "title": "Dissecting the multivariate extremal index and tail dependence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A central issue in the theory of extreme values focuses on suitable\nconditions such that the well-known results for the limiting distributions of\nthe maximum of i.i.d. sequences can be applied to stationary ones. In this\ncontext, the extremal index appears as a key parameter to capture the effect of\ntemporal dependence on the limiting distribution of the maxima. The\nmultivariate extremal index corresponds to a generalization of this concept to\na multivariate context and affects the tail dependence structure within the\nmarginal sequences and between them. As it is a function, the inference becomes\nmore difficult, and it is therefore important to obtain characterizations,\nnamely bounds based on the marginal dependence that are easier to estimate. In\nthis work we present two decompositions that emphasize different types of\ninformation contained in the multivariate extremal index, an upper limit better\nthan those found in the literature and we analyze its role in dependence on the\nlimiting model of the componentwise maxima of a stationary sequence. We will\nillustrate the results with examples of recognized interest in applications.\n", "versions": [{"version": "v1", "created": "Mon, 6 Feb 2017 16:40:41 GMT"}], "update_date": "2017-02-07", "authors_parsed": [["Ferreira", "Helena", ""], ["Ferreira", "Marta", ""]]}, {"id": "1702.01736", "submitter": "Abdollah Jalilian", "authors": "Abdollah Jalilian, Yongtao Guan and Rasmus Waagepetersen", "title": "Orthogonal series estimation of the pair correlation function of a\n  spatial point process", "comments": null, "journal-ref": null, "doi": "10.5705/ss.202017.0112", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The pair correlation function is a fundamental spatial point process\ncharacteristic that, given the intensity function, determines second order\nmoments of the point process. Non-parametric estimation of the pair correlation\nfunction is a typical initial step of a statistical analysis of a spatial point\npattern. Kernel estimators are popular but especially for clustered point\npatterns suffer from bias for small spatial lags. In this paper we introduce a\nnew orthogonal series estimator. The new estimator is consistent and\nasymptotically normal according to our theoretical and simulation results. Our\nsimulations further show that the new estimator can outperform the kernel\nestimators in particular for Poisson and clustered point processes.\n", "versions": [{"version": "v1", "created": "Mon, 6 Feb 2017 18:45:26 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Jalilian", "Abdollah", ""], ["Guan", "Yongtao", ""], ["Waagepetersen", "Rasmus", ""]]}, {"id": "1702.01777", "submitter": "Konstantinos Spiliopoulos", "authors": "Michela Ottobre, Natesh S. Pillai and Konstantinos Spiliopoulos", "title": "Optimal Scaling of the MALA algorithm with Irreversible Proposals for\n  Gaussian targets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well known in many settings that reversible Langevin diffusions in\nconfining potentials converge to equilibrium exponentially fast. Adding\nirreversible perturbations to the drift of a Langevin diffusion that maintain\nthe same invariant measure accelerates its convergence to stationarity. Many\nexisting works thus advocate the use of such non-reversible dynamics for\nsampling. When implementing Markov Chain Monte Carlo algorithms (MCMC) using\ntime discretisations of such Stochastic Differential Equations (SDEs), one can\nappend the discretization with the usual Metropolis-Hastings accept-reject step\nand this is often done in practice because the accept--reject step eliminates\nbias. On the other hand, such a step makes the resulting chain reversible. It\nis not known whether adding the accept-reject step preserves the faster mixing\nproperties of the non-reversible dynamics. In this paper, we address this gap\nbetween theory and practice by analyzing the optimal scaling of MCMC algorithms\nconstructed from proposal moves that are time-step Euler discretisations of an\nirreversible SDE, for high dimensional Gaussian target measures. We call the\nresulting algorithm the \\imala, in comparison to the classical MALA algorithm\n(here {\\em ip} is for irreversible proposal). In order to quantify how the cost\nof the algorithm scales with the dimension $N$, we prove invariance principles\nfor the appropriately rescaled chain. In contrast to the usual MALA algorithm,\nwe show that there could be two regimes asymptotically: (i) a diffusive regime,\nas in the MALA algorithm and (ii) a ``fluid\" regime where the limit is an\nordinary differential equation. We provide concrete examples where the limit is\na diffusion, as in the standard MALA, but with provably higher limiting\nacceptance probabilities. Numerical results are also given corroborating the\ntheory.\n", "versions": [{"version": "v1", "created": "Mon, 6 Feb 2017 19:59:33 GMT"}, {"version": "v2", "created": "Mon, 27 Nov 2017 14:43:57 GMT"}, {"version": "v3", "created": "Mon, 1 Jul 2019 15:06:32 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Ottobre", "Michela", ""], ["Pillai", "Natesh S.", ""], ["Spiliopoulos", "Konstantinos", ""]]}, {"id": "1702.01812", "submitter": "Jonathan Stewart", "authors": "Michael Schweinberger and Jonathan Stewart", "title": "Concentration and consistency results for canonical and curved\n  exponential-family models of random graphs", "comments": null, "journal-ref": "The Annals of Statistics 2020, Vol. 48, No. 1, 374-396", "doi": "10.1214/19-AOS1810", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical inference for exponential-family models of random graphs with\ndependent edges is challenging. We stress the importance of additional\nstructure and show that additional structure facilitates statistical inference.\nA simple example of a random graph with additional structure is a random graph\nwith neighborhoods and local dependence within neighborhoods. We develop the\nfirst concentration and consistency results for maximum likelihood and\n$M$-estimators of a wide range of canonical and curved exponential-family\nmodels of random graphs with local dependence. All results are non-asymptotic\nand applicable to random graphs with finite populations of nodes, although\nasymptotic consistency results can be obtained as well. In addition, we show\nthat additional structure can facilitate subgraph-to-graph estimation, and\npresent concentration results for subgraph-to-graph estimators. As an\napplication, we consider popular curved exponential-family models of random\ngraphs, with local dependence induced by transitivity and parameter vectors\nwhose dimensions depend on the number of nodes.\n", "versions": [{"version": "v1", "created": "Mon, 6 Feb 2017 22:36:30 GMT"}, {"version": "v2", "created": "Thu, 13 Jul 2017 18:22:39 GMT"}, {"version": "v3", "created": "Sat, 3 Feb 2018 23:11:33 GMT"}, {"version": "v4", "created": "Mon, 17 Dec 2018 22:23:08 GMT"}, {"version": "v5", "created": "Mon, 24 Dec 2018 19:49:53 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Schweinberger", "Michael", ""], ["Stewart", "Jonathan", ""]]}, {"id": "1702.01906", "submitter": "Yong Zhang", "authors": "Yong Zhang, Xiaodi Qian, Hong Qin, Ting Yan", "title": "Affiliation networks with an increasing degree sequence", "comments": "24 pages,2 figures,4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Affiliation network is one kind of two-mode social network with two different\nsets of nodes (namely, a set of actors and a set of social events) and edges\nrepresenting the affiliation of the actors with the social events. Although a\nnumber of statistical models are proposed to analyze affiliation networks, the\nasymptotic behaviors of the estimator are still unknown or have not been\nproperly explored. In this paper, we study an affiliation model with the degree\nsequence as the exclusively natural sufficient statistic in the exponential\nfamily distributions. We establish the uniform consistency and asymptotic\nnormality of the maximum likelihood estimator when the numbers of actors and\nevents both go to infinity. Simulation studies and a real data example\ndemonstrate our theoretical results.\n", "versions": [{"version": "v1", "created": "Tue, 7 Feb 2017 07:26:41 GMT"}], "update_date": "2017-02-08", "authors_parsed": [["Zhang", "Yong", ""], ["Qian", "Xiaodi", ""], ["Qin", "Hong", ""], ["Yan", "Ting", ""]]}, {"id": "1702.02023", "submitter": "Johannes Krebs", "authors": "Eduardo Valenzuela-Dom\\'inguez, Johannes T. N. Krebs and J\\\"urgen E.\n  Franke", "title": "A Bernstein Inequality For Spatial Lattice Processes", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we present a Bernstein inequality for sums of random\nvariables which are defined on a spatial lattice structure. The inequality can\nbe used to derive concentration inequalities. It can be useful to obtain\nconsistency properties for nonparametric estimators of conditional expectation\nfunctions.\n", "versions": [{"version": "v1", "created": "Tue, 7 Feb 2017 14:04:40 GMT"}, {"version": "v2", "created": "Tue, 5 Dec 2017 02:17:04 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["Valenzuela-Dom\u00ednguez", "Eduardo", ""], ["Krebs", "Johannes T. N.", ""], ["Franke", "J\u00fcrgen E.", ""]]}, {"id": "1702.02049", "submitter": "Sophia Sulis", "authors": "Sophia Sulis, David Mary, Lionel Bigot", "title": "A study of periodograms standardized using training data sets and\n  application to exoplanet detection", "comments": "14 pages, Accepted in IEEE Transactions on Signal Processing", "journal-ref": "IEEE Transactions on Signal Processing , vol.PP, no.99, pp.1-1,\n  2017", "doi": "10.1109/TSP.2017.2652391", "report-no": null, "categories": "math.ST astro-ph.EP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When the noise affecting time series is colored with unknown statistics, a\ndifficulty for sinusoid detection is to control the true significance level of\nthe test outcome. This paper investigates the possibility of using training\ndata sets of the noise to improve this control. Specifically, we analyze the\nperformances of various detectors {applied to} periodograms standardized using\ntraining data sets. Emphasis is put on sparse detection in the Fourier domain\nand on the limitation posed by the necessarily finite size of the training sets\navailable in practice. We study the resulting false alarm and detection rates\nand show that standardization leads in some cases to powerful constant false\nalarm rate tests. The study is both analytical and numerical. Although\nanalytical results are derived in an asymptotic regime, numerical results show\nthat theory accurately describes the tests' behaviour for moderately large\nsample sizes. Throughout the paper, an application of the considered\nperiodogram standardization is presented for exoplanet detection in radial\nvelocity data.\n", "versions": [{"version": "v1", "created": "Tue, 7 Feb 2017 14:55:08 GMT"}], "update_date": "2017-02-08", "authors_parsed": [["Sulis", "Sophia", ""], ["Mary", "David", ""], ["Bigot", "Lionel", ""]]}, {"id": "1702.02268", "submitter": "Kok Haur Ng", "authors": "Kok-Haur Ng, Shelton Peiris, Jennifer So-kuen-Chan, David Allen,\n  Kooi-Huat Ng", "title": "Efficient Modelling & Forecasting with range based volatility models and\n  application", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers an alternative method for fitting CARR models using\ncombined estimating functions (CEF) by showing its usefulness in applications\nin economics and quantitative finance. The associated information matrix for\ncorresponding new estimates is derived to calculate the standard errors. A\nsimulation study is carried out to demonstrate its superiority relative to\nother two competitors: linear estimating functions (LEF) and the maximum\nlikelihood (ML). Results show that CEF estimates are more efficient than LEF\nand ML estimates when the error distribution is mis-specified. Taking a real\ndata set from financial economics, we illustrate the usefulness and\napplicability of the CEF method in practice and report reliable forecast values\nto minimize the risk in the decision making process.\n", "versions": [{"version": "v1", "created": "Wed, 8 Feb 2017 03:56:00 GMT"}], "update_date": "2017-02-09", "authors_parsed": [["Ng", "Kok-Haur", ""], ["Peiris", "Shelton", ""], ["So-kuen-Chan", "Jennifer", ""], ["Allen", "David", ""], ["Ng", "Kooi-Huat", ""]]}, {"id": "1702.02502", "submitter": "Philip Dawid", "authors": "A. Philip Dawid and Julia Mortera", "title": "A Note on Prediction Markets", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": "Working paper 215-2017, Dipartimento di Economia dell'Universit\\`a\n  degli studi Roma Tre", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a prediction market, individuals can sequentially place bets on the\noutcome of a future event. This leaves a trail of personal probabilities for\nthe event, each being conditional on the current individual's private\nbackground knowledge and on the previously announced probabilities of other\nindividuals, which give partial information about their private knowledge. By\nmeans of theory and examples, we revisit some results in this area. In\nparticular, we consider the case of two individuals, who start with the same\noverall probability distribution but different private information, and then\ntake turns in updating their probabilities. We note convergence of the\nannounced probabilities to a limiting value, which may or may not be the same\nas that based on pooling their private information.\n", "versions": [{"version": "v1", "created": "Wed, 8 Feb 2017 16:36:13 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Dawid", "A. Philip", ""], ["Mortera", "Julia", ""]]}, {"id": "1702.02643", "submitter": "Michael Vogt", "authors": "Michael Vogt and Matthias Schmid", "title": "Clustering with Statistical Error Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a clustering approach that allows for rigorous\nstatistical error control similar to a statistical test. We develop estimators\nfor both the unknown number of clusters and the clusters themselves. The\nestimators depend on a tuning parameter alpha which is similar to the\nsignificance level of a statistical hypothesis test. By choosing alpha, one can\ncontrol the probability of overestimating the true number of clusters, while\nthe probability of underestimation is asymptotically negligible. In addition,\nthe probability that the estimated clusters differ from the true ones is\ncontrolled. In the theoretical part of the paper, formal versions of these\nstatements on statistical error control are derived in a standard model setting\nwith convex clusters. A simulation study and two applications to temperature\nand gene expression microarray data complement the theoretical analysis.\n", "versions": [{"version": "v1", "created": "Wed, 8 Feb 2017 22:43:47 GMT"}, {"version": "v2", "created": "Wed, 12 Jul 2017 07:50:35 GMT"}], "update_date": "2017-07-13", "authors_parsed": [["Vogt", "Michael", ""], ["Schmid", "Matthias", ""]]}, {"id": "1702.02670", "submitter": "Stefan Steinerberger", "authors": "Uri Shaham, Stefan Steinerberger", "title": "Stochastic Neighbor Embedding separates well-separated clusters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic Neighbor Embedding and its variants are widely used dimensionality\nreduction techniques -- despite their popularity, no theoretical results are\nknown. We prove that the optimal SNE embedding of well-separated clusters from\nhigh dimensions to any Euclidean space R^d manages to successfully separate the\nclusters in a quantitative way. The result also applies to a larger family of\nmethods including a variant of t-SNE.\n", "versions": [{"version": "v1", "created": "Thu, 9 Feb 2017 01:30:53 GMT"}, {"version": "v2", "created": "Wed, 22 Feb 2017 19:10:35 GMT"}], "update_date": "2017-02-24", "authors_parsed": [["Shaham", "Uri", ""], ["Steinerberger", "Stefan", ""]]}, {"id": "1702.02815", "submitter": "Pierre-Alexandre Mattei", "authors": "Pierre-Alexandre Mattei (MAP5)", "title": "Multiplying a Gaussian Matrix by a Gaussian Vector", "comments": null, "journal-ref": "Statistics and Probability Letters, Elsevier, 2017", "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a new and simple characterization of the multivariate generalized\nLaplace distribution. In particular, this result implies that the product of a\nGaussian matrix with independent and identically distributed columns by an\nindependent isotropic Gaussian vector follows a symmetric multivariate\ngeneralized Laplace distribution.\n", "versions": [{"version": "v1", "created": "Thu, 9 Feb 2017 12:55:13 GMT"}, {"version": "v2", "created": "Wed, 5 Apr 2017 15:06:03 GMT"}], "update_date": "2017-04-06", "authors_parsed": [["Mattei", "Pierre-Alexandre", "", "MAP5"]]}, {"id": "1702.02826", "submitter": "Masaru Shintani", "authors": "Masaru Shintani and Ken Umeno", "title": "Super Generalized Central Limit Theorem: Limit distributions for sums of\n  non-identical random variables with power-laws", "comments": "4pages,1figure", "journal-ref": null, "doi": "10.7566/JPSJ.87.043003", "report-no": null, "categories": "math.ST math-ph math.MP q-fin.EC stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In nature or societies, the power-law is present ubiquitously, and then it is\nimportant to investigate the mathematical characteristics of power-laws in the\nrecent era of big data. In this paper we prove the superposition of\nnon-identical stochastic processes with power-laws converges in density to a\nunique stable distribution. This property can be used to explain the\nuniversality of stable laws such that the sums of the logarithmic return of\nnon-identical stock price fluctuations follow stable distributions.\n", "versions": [{"version": "v1", "created": "Thu, 9 Feb 2017 13:23:17 GMT"}, {"version": "v2", "created": "Fri, 10 Feb 2017 08:07:52 GMT"}, {"version": "v3", "created": "Fri, 17 Feb 2017 06:28:00 GMT"}, {"version": "v4", "created": "Wed, 22 Feb 2017 05:27:11 GMT"}, {"version": "v5", "created": "Fri, 24 Mar 2017 06:41:26 GMT"}, {"version": "v6", "created": "Mon, 21 Aug 2017 20:33:27 GMT"}], "update_date": "2018-04-18", "authors_parsed": [["Shintani", "Masaru", ""], ["Umeno", "Ken", ""]]}, {"id": "1702.02838", "submitter": "Claire Br\\'echeteau", "authors": "Claire Br\\'echeteau", "title": "The DTM-signature for a geometric comparison of metric-measure spaces\n  from samples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce the notion of DTM-signature, a measure on R +\nthat can be associated to any metric-measure space. This signature is based on\nthe distance to a measure (DTM) introduced by Chazal, Cohen-Steiner and\nM\\'erigot. It leads to a pseudo-metric between metric-measure spaces,\nupper-bounded by the Gromov-Wasserstein distance. Under some geometric\nassumptions, we derive lower bounds for this pseudo-metric. Given two\nN-samples, we also build an asymptotic statistical test based on the\nDTM-signature, to reject the hypothesis of equality of the two underlying\nmetric-measure spaces, up to a measure-preserving isometry. We give strong\ntheoretical justifications for this test and propose an algorithm for its\nimplementation.\n", "versions": [{"version": "v1", "created": "Thu, 9 Feb 2017 14:04:20 GMT"}], "update_date": "2017-02-10", "authors_parsed": [["Br\u00e9cheteau", "Claire", ""]]}, {"id": "1702.02896", "submitter": "Stefan Wager", "authors": "Susan Athey and Stefan Wager", "title": "Policy Learning with Observational Data", "comments": "Forthcoming in Econometrica. Original title: Efficient Policy\n  Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG econ.EM stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many areas, practitioners seek to use observational data to learn a\ntreatment assignment policy that satisfies application-specific constraints,\nsuch as budget, fairness, simplicity, or other functional form constraints. For\nexample, policies may be restricted to take the form of decision trees based on\na limited set of easily observable individual characteristics. We propose a new\napproach to this problem motivated by the theory of semiparametrically\nefficient estimation. Our method can be used to optimize either binary\ntreatments or infinitesimal nudges to continuous treatments, and can leverage\nobservational data where causal effects are identified using a variety of\nstrategies, including selection on observables and instrumental variables.\nGiven a doubly robust estimator of the causal effect of assigning everyone to\ntreatment, we develop an algorithm for choosing whom to treat, and establish\nstrong guarantees for the asymptotic utilitarian regret of the resulting\npolicy.\n", "versions": [{"version": "v1", "created": "Thu, 9 Feb 2017 17:03:01 GMT"}, {"version": "v2", "created": "Sun, 1 Oct 2017 22:20:23 GMT"}, {"version": "v3", "created": "Tue, 9 Oct 2018 11:04:03 GMT"}, {"version": "v4", "created": "Tue, 4 Dec 2018 23:51:38 GMT"}, {"version": "v5", "created": "Mon, 16 Sep 2019 22:46:50 GMT"}, {"version": "v6", "created": "Fri, 4 Sep 2020 21:45:04 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Athey", "Susan", ""], ["Wager", "Stefan", ""]]}, {"id": "1702.02982", "submitter": "Danica J. Sutherland", "authors": "Danica J. Sutherland", "title": "Fixing an error in Caponnetto and de Vito (2007)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The seminal paper of Caponnetto and de Vito (2007) provides minimax-optimal\nrates for kernel ridge regression in a very general setting. Its proof,\nhowever, contains an error in its bound on the effective dimensionality. In\nthis note, we explain the mistake, provide a correct bound, and show that the\nmain theorem remains true.\n", "versions": [{"version": "v1", "created": "Thu, 9 Feb 2017 21:01:52 GMT"}, {"version": "v2", "created": "Thu, 14 Jan 2021 06:10:33 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Sutherland", "Danica J.", ""]]}, {"id": "1702.03098", "submitter": "Takaaki Koike", "authors": "Takaaki Koike, Mihoko Minami", "title": "Estimation of Risk Contributions with MCMC", "comments": "31 pages, 1 table, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM math.ST q-fin.CP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Determining risk contributions of unit exposures to portfolio-wide economic\ncapital is an important task in financial risk management. Computing risk\ncontributions involves difficulties caused by rare-event simulations. In this\nstudy, we address the problem of estimating risk contributions when the total\nrisk is measured by value-at-risk (VaR). Our proposed estimator of VaR\ncontributions is based on the Metropolis-Hasting (MH) algorithm, which is one\nof the most prevalent Markov chain Monte Carlo (MCMC) methods. Unlike existing\nestimators, our MH-based estimator consists of samples from conditional loss\ndistribution given a rare event of interest. This feature enhances sample\nefficiency compared with the crude Monte Carlo method. Moreover, our method has\nthe consistency and asymptotic normality, and is widely applicable to various\nrisk models having joint loss density. Our numerical experiments based on\nsimulation and real-world data demonstrate that in various risk models, even\nthose having high-dimensional (approximately 500) inhomogeneous margins, our MH\nestimator has smaller bias and mean squared error compared with existing\nestimators.\n", "versions": [{"version": "v1", "created": "Fri, 10 Feb 2017 08:49:04 GMT"}, {"version": "v2", "created": "Thu, 17 Jan 2019 04:58:34 GMT"}], "update_date": "2019-01-18", "authors_parsed": [["Koike", "Takaaki", ""], ["Minami", "Mihoko", ""]]}, {"id": "1702.03166", "submitter": "Christophe Chesneau", "authors": "Tung Duy Luu, Jalal Fadili and Christophe Chesneau", "title": "Sharp Oracle Inequalities for Low-complexity Priors", "comments": "hal-01422476 version available 26 Dec. 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper,we consider a high-dimensional statistical estimation problem\nin which the the number of parameters is comparable or larger than the sample\nsize. We present a unified analysis of the performance guarantees of\nexponential weighted aggregation and penalized estimators with a general class\nof data losses and priors which encourage objects which conform to some notion\nof simplicity/complexity. More precisely, we show that these two estimators\nsatisfy sharp oracle inequalities for prediction ensuring their good\ntheoretical performances. We also highlight the differences between them. When\nthe noise is random, we provide oracle inequalities in probability using\nconcentration inequalities. These results are then applied to several instances\nincluding the Lasso, the group Lasso, their analysis-type counterparts, the\n$\\ell_\\infty$ and the nuclear norm penalties. All our estimators can be\nefficiently implemented using proximal splitting algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 10 Feb 2017 13:43:48 GMT"}, {"version": "v2", "created": "Fri, 24 Feb 2017 13:35:33 GMT"}, {"version": "v3", "created": "Fri, 1 Sep 2017 12:35:16 GMT"}, {"version": "v4", "created": "Tue, 3 Oct 2017 14:46:11 GMT"}], "update_date": "2017-10-04", "authors_parsed": [["Luu", "Tung Duy", ""], ["Fadili", "Jalal", ""], ["Chesneau", "Christophe", ""]]}, {"id": "1702.03377", "submitter": "Kengo Kato", "authors": "Kengo Kato and Yuya Sasaki", "title": "Uniform confidence bands for nonparametric errors-in-variables\n  regression", "comments": "59 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper develops a method to construct uniform confidence bands for a\nnonparametric regression function where a predictor variable is subject to a\nmeasurement error. We allow for the distribution of the measurement error to be\nunknown, but assume the availability of validation data or repeated\nmeasurements on the latent predictor variable. The proposed confidence band\nbuilds on the deconvolution kernel estimation and a novel application of the\nmultiplier bootstrap method. We establish asymptotic validity of the proposed\nconfidence band. To our knowledge, this is the first paper to derive\nasymptotically valid uniform confidence bands for nonparametric\nerrors-in-variables regression.\n", "versions": [{"version": "v1", "created": "Sat, 11 Feb 2017 03:23:44 GMT"}, {"version": "v2", "created": "Mon, 20 Feb 2017 14:56:57 GMT"}, {"version": "v3", "created": "Fri, 24 Feb 2017 14:02:50 GMT"}, {"version": "v4", "created": "Thu, 13 Jun 2019 20:12:36 GMT"}], "update_date": "2019-06-17", "authors_parsed": [["Kato", "Kengo", ""], ["Sasaki", "Yuya", ""]]}, {"id": "1702.03464", "submitter": "Nicolas Garcia Trillos", "authors": "Nicolas Garcia Trillos", "title": "Gromov-Hausdorff limit of Wasserstein spaces on point clouds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.MG math.AP math.PR math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a point cloud $X_n := \\{ x_1, \\dots, x_n \\}$ uniformly\ndistributed on the flat torus $\\mathbb{T}^d : = \\mathbb{R}^d / \\mathbb{Z}^d $,\nand construct a geometric graph on the cloud by connecting points that are\nwithin distance $\\varepsilon$ of each other. We let $\\mathcal{P}(X_n)$ be the\nspace of probability measures on $X_n$ and endow it with a discrete Wasserstein\ndistance $W_n$ as introduced independently by Chow et al, Maas, and Mielke for\ngeneral finite Markov chains. We show that as long as $\\varepsilon=\n\\varepsilon_n$ decays towards zero slower than an explicit rate depending on\nthe level of uniformity of $X_n$, then the space $(\\mathcal{P}(X_n), W_n)$\nconverges in the Gromov-Hausdorff sense towards the space of probability\nmeasures on $\\mathbb{T}^d$ endowed with the Wasserstein distance. The analysis\npresented in this paper is a first step in the study of stability of evolution\nequations defined over random point clouds as the number of points grows to\ninfinity.\n", "versions": [{"version": "v1", "created": "Sat, 11 Feb 2017 22:29:06 GMT"}, {"version": "v2", "created": "Thu, 13 Apr 2017 13:04:51 GMT"}, {"version": "v3", "created": "Fri, 24 May 2019 09:03:07 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Trillos", "Nicolas Garcia", ""]]}, {"id": "1702.03476", "submitter": "Stefan Haufe", "authors": "Irene Dowding and Stefan Haufe", "title": "Powerful statistical inference for nested data using sufficient summary\n  statistics", "comments": "17 pages, 5 figures", "journal-ref": "Dowding, I., & Haufe, S. (2018). Powerful Statistical Inference\n  for Nested Data Using Sufficient Summary Statistics. Frontiers in human\n  neuroscience, 12, 103", "doi": "10.3389/fnhum.2018.00103", "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hierarchically-organized data arise naturally in many psychology and\nneuroscience studies. As the standard assumption of independent and identically\ndistributed samples does not hold for such data, two important problems are to\naccurately estimate group-level effect sizes, and to obtain powerful\nstatistical tests against group-level null hypotheses. A common approach is to\nsummarize subject-level data by a single quantity per subject, which is often\nthe mean or the difference between class means, and treat these as samples in a\ngroup-level t-test. This 'naive' approach is, however, suboptimal in terms of\nstatistical power, as it ignores information about the intra-subject variance.\nTo address this issue, we review several approaches to deal with nested data,\nwith a focus on methods that are easy to implement. With what we call the\nsufficient-summary-statistic approach, we highlight a computationally efficient\ntechnique that can improve statistical power by taking into account\nwithin-subject variances, and we provide step-by-step instructions on how to\napply this approach to a number of frequently-used measures of effect size. The\nproperties of the reviewed approaches and the potential benefits over a\ngroup-level t-test are quantitatively assessed on simulated data and\ndemonstrated on EEG data from a simulated-driving experiment.\n", "versions": [{"version": "v1", "created": "Sun, 12 Feb 2017 01:25:56 GMT"}, {"version": "v2", "created": "Thu, 30 Aug 2018 20:15:36 GMT"}], "update_date": "2018-09-03", "authors_parsed": [["Dowding", "Irene", ""], ["Haufe", "Stefan", ""]]}, {"id": "1702.03530", "submitter": "Liam Solus", "authors": "Liam Solus, Yuhao Wang, and Caroline Uhler", "title": "Consistency Guarantees for Greedy Permutation-Based Causal Inference\n  Algorithms", "comments": "37 pages, 15 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Directed acyclic graphical models, or DAG models, are widely used to\nrepresent complex causal systems. Since the basic task of learning such a model\nfrom data is NP-hard, a standard approach is greedy search over the space of\ndirected acyclic graphs or Markov equivalence classes of directed acyclic\ngraphs. As the space of directed acyclic graphs on $p$ nodes and the associated\nspace of Markov equivalence classes are both much larger than the space of\npermutations, it is desirable to consider permutation-based greedy searches.\nHere, we provide the first consistency guarantees, both uniform and\nhigh-dimensional, of a greedy permutation-based search. This search corresponds\nto a simplex-like algorithm operating over the edge-graph of a sub-polytope of\nthe permutohedron, called a DAG associahedron. Every vertex in this polytope is\nassociated with a directed acyclic graph, and hence with a collection of\npermutations that are consistent with the directed acyclic graph ordering. A\nwalk is performed on the edges of the polytope maximizing the sparsity of the\nassociated directed acyclic graphs. We show via simulated and real data that\nthis permutation search is competitive with current approaches.\n", "versions": [{"version": "v1", "created": "Sun, 12 Feb 2017 14:11:09 GMT"}, {"version": "v2", "created": "Mon, 24 Jul 2017 07:11:48 GMT"}, {"version": "v3", "created": "Sat, 11 Jan 2020 12:47:33 GMT"}, {"version": "v4", "created": "Tue, 8 Jun 2021 12:44:10 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Solus", "Liam", ""], ["Wang", "Yuhao", ""], ["Uhler", "Caroline", ""]]}, {"id": "1702.03557", "submitter": "Abhik Ghosh", "authors": "Abhik Ghosh and Ayanendranath Basu", "title": "Improvements in the Small Sample Efficiency of the Minimum\n  $S$-Divergence Estimators under Discrete Models", "comments": "25 pages, pre-print, submitted to Journal", "journal-ref": "Journal of Statistical Computation and Simulation (2018) Volume\n  88, Issue 3", "doi": "10.1080/00949655.2017.1397150", "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the problem of inliers and empty cells and the resulting\nissue of relative inefficiency in estimation under pure samples from a discrete\npopulation when the sample size is small. Many minimum divergence estimators in\nthe $S$-divergence family, although possessing very strong outlier stability\nproperties, often have very poor small sample efficiency in the presence of\ninliers and some are not even defined in the presence of a single empty cell;\nthis limits the practical applicability of these estimators, in spite of their\notherwise sound robustness properties and high asymptotic efficiency. Here, we\nwill study a penalized version of the $S$-divergences such that the resulting\nminimum divergence estimators are free from these issues without altering their\nrobustness properties and asymptotic efficiencies. We will give a general proof\nfor the asymptotic properties of these minimum penalized $S$-divergence\nestimators. This provides a significant addition to the literature as the\nasymptotics of penalized divergences which are not finitely defined are\ncurrently unavailable in the literature. The small sample advantages of the\nminimum penalized $S$-divergence estimators are examined through an extensive\nsimulation study and some empirical suggestions regarding the choice of the\nrelevant underlying tuning parameters are also provided.\n", "versions": [{"version": "v1", "created": "Sun, 12 Feb 2017 18:44:58 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["Ghosh", "Abhik", ""], ["Basu", "Ayanendranath", ""]]}, {"id": "1702.03618", "submitter": "Tatsushi Oka", "authors": "Brantly Callaway, Tong Li, Tatsushi Oka", "title": "Quantile Treatment Effects in Difference in Differences Models under\n  Dependence Restrictions and with only Two Time Periods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper shows that the Conditional Quantile Treatment Effect on the\nTreated can be identified using a combination of (i) a conditional\nDistributional Difference in Differences assumption and (ii) an assumption on\nthe conditional dependence between the change in untreated potential outcomes\nand the initial level of untreated potential outcomes for the treated group.\nThe second assumption recovers the unknown dependence from the observed\ndependence for the untreated group. We also consider estimation and inference\nin the case where all of the covariates are discrete. We propose a uniform\ninference procedure based on the exchangeable bootstrap and show its validity.\nWe conclude the paper by estimating the effect of state-level changes in the\nminimum wage on the distribution of earnings for subgroups defined by race,\ngender, and education.\n", "versions": [{"version": "v1", "created": "Mon, 13 Feb 2017 03:30:57 GMT"}], "update_date": "2017-02-14", "authors_parsed": [["Callaway", "Brantly", ""], ["Li", "Tong", ""], ["Oka", "Tatsushi", ""]]}, {"id": "1702.03656", "submitter": "Andre Wibisono", "authors": "Andre Wibisono, Varun Jog, Po-Ling Loh", "title": "Information and estimation in Fokker-Planck channels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the relationship between information- and estimation-theoretic\nquantities in time-evolving systems. We focus on the Fokker-Planck channel\ndefined by a general stochastic differential equation, and show that the time\nderivatives of entropy, KL divergence, and mutual information are characterized\nby estimation-theoretic quantities involving an appropriate generalization of\nthe Fisher information. Our results vastly extend De Bruijn's identity and the\nclassical I-MMSE relation.\n", "versions": [{"version": "v1", "created": "Mon, 13 Feb 2017 07:14:35 GMT"}], "update_date": "2017-02-14", "authors_parsed": [["Wibisono", "Andre", ""], ["Jog", "Varun", ""], ["Loh", "Po-Ling", ""]]}, {"id": "1702.03673", "submitter": "Jon Cockayne", "authors": "Jon Cockayne, Chris Oates, Tim Sullivan, Mark Girolami", "title": "Bayesian Probabilistic Numerical Methods", "comments": null, "journal-ref": "SIAM Review 61(4):756--789, 2019", "doi": "10.1137/17M1139357", "report-no": null, "categories": "stat.ME cs.NA math.NA math.ST stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The emergent field of probabilistic numerics has thus far lacked clear\nstatistical principals. This paper establishes Bayesian probabilistic numerical\nmethods as those which can be cast as solutions to certain inverse problems\nwithin the Bayesian framework. This allows us to establish general conditions\nunder which Bayesian probabilistic numerical methods are well-defined,\nencompassing both non-linear and non-Gaussian models. For general computation,\na numerical approximation scheme is proposed and its asymptotic convergence\nestablished. The theoretical development is then extended to pipelines of\ncomputation, wherein probabilistic numerical methods are composed to solve more\nchallenging numerical tasks. The contribution highlights an important research\nfrontier at the interface of numerical analysis and uncertainty quantification,\nwith a challenging industrial application presented.\n", "versions": [{"version": "v1", "created": "Mon, 13 Feb 2017 08:52:58 GMT"}, {"version": "v2", "created": "Fri, 7 Jul 2017 13:58:53 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Cockayne", "Jon", ""], ["Oates", "Chris", ""], ["Sullivan", "Tim", ""], ["Girolami", "Mark", ""]]}, {"id": "1702.03698", "submitter": "St\\'ephanie van der Pas", "authors": "St\\'ephanie van der Pas and Botond Szab\\'o and Aad van der Vaart", "title": "Adaptive posterior contraction rates for the horseshoe", "comments": "arXiv admin note: substantial text overlap with arXiv:1607.01892", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the frequentist properties of Bayesian procedures for\nestimation based on the horseshoe prior in the sparse multivariate normal means\nmodel. Previous theoretical results assumed that the sparsity level, that is,\nthe number of signals, was known. We drop this assumption and characterize the\nbehavior of the maximum marginal likelihood estimator (MMLE) of a key parameter\nof the horseshoe prior. We prove that the MMLE is an effective estimator of the\nsparsity level, in the sense that it leads to (near) minimax optimal estimation\nof the underlying mean vector generating the data. Besides this empirical Bayes\nprocedure, we consider the hierarchical Bayes method of putting a prior on the\nunknown sparsity level as well. We show that both Bayesian techniques lead to\nrate-adaptive optimal posterior contraction, which implies that the horseshoe\nposterior is a good candidate for generating rate-adaptive credible sets.\n", "versions": [{"version": "v1", "created": "Mon, 13 Feb 2017 10:12:23 GMT"}], "update_date": "2017-02-14", "authors_parsed": [["van der Pas", "St\u00e9phanie", ""], ["Szab\u00f3", "Botond", ""], ["van der Vaart", "Aad", ""]]}, {"id": "1702.03760", "submitter": "Maurilio Gutzeit", "authors": "Gilles Blanchard, Alexandra Carpentier, Maurilio Gutzeit", "title": "Minimax Euclidean Separation Rates for Testing Convex Hypotheses in\n  $\\mathbb{R}^d$", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider composite-composite testing problems for the expectation in the\nGaussian sequence model where the null hypothesis corresponds to a convex\nsubset $\\mathcal{C}$ of $\\mathbb{R}^d$. We adopt a minimax point of view and\nour primary objective is to describe the smallest Euclidean distance between\nthe null and alternative hypotheses such that there is a test with small total\nerror probability. In particular, we focus on the dependence of this distance\non the dimension $d$ and the sample size/variance parameter $n$ giving rise to\nthe minimax separation rate. In this paper we discuss lower and upper bounds on\nthis rate for different smooth and non- smooth choices for $\\mathcal{C}$.\n", "versions": [{"version": "v1", "created": "Mon, 13 Feb 2017 13:15:35 GMT"}, {"version": "v2", "created": "Thu, 23 Aug 2018 07:42:49 GMT"}], "update_date": "2018-08-24", "authors_parsed": [["Blanchard", "Gilles", ""], ["Carpentier", "Alexandra", ""], ["Gutzeit", "Maurilio", ""]]}, {"id": "1702.03884", "submitter": "Luca Weihs", "authors": "Luca Weihs, Bill Robinson, Emilie Dufresne, Jennifer Kenkel, Kaie\n  Kubjas, Reginald L. McGee II, Nhan Nguyen, Elina Robeva, Mathias Drton", "title": "Determinantal Generalizations of Instrumental Variables", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linear structural equation models relate the components of a random vector\nusing linear interdependencies and Gaussian noise. Each such model can be\nnaturally associated with a mixed graph whose vertices correspond to the\ncomponents of the random vector. The graph contains directed edges that\nrepresent the linear relationships between components, and bidirected edges\nthat encode unobserved confounding. We study the problem of generic\nidentifiability, that is, whether a generic choice of linear and confounding\neffects can be uniquely recovered from the joint covariance matrix of the\nobserved random vector. An existing combinatorial criterion for establishing\ngeneric identifiability is the half-trek criterion (HTC), which uses the\nexistence of trek systems in the mixed graph to iteratively discover\ngenerically invertible linear equation systems in polynomial time. By focusing\non edges one at a time, we establish new sufficient and necessary conditions\nfor generic identifiability of edge effects extending those of the HTC. In\nparticular, we show how edge coefficients can be recovered as quotients of\nsubdeterminants of the covariance matrix, which constitutes a determinantal\ngeneralization of formulas obtained when using instrumental variables for\nidentification.\n", "versions": [{"version": "v1", "created": "Mon, 13 Feb 2017 17:14:58 GMT"}], "update_date": "2017-02-14", "authors_parsed": [["Weihs", "Luca", ""], ["Robinson", "Bill", ""], ["Dufresne", "Emilie", ""], ["Kenkel", "Jennifer", ""], ["Kubjas", "Kaie", ""], ["McGee", "Reginald L.", "II"], ["Nguyen", "Nhan", ""], ["Robeva", "Elina", ""], ["Drton", "Mathias", ""]]}, {"id": "1702.04031", "submitter": "Caroline Uhler", "authors": "Steffen Lauritzen, Caroline Uhler, and Piotr Zwiernik", "title": "Maximum likelihood estimation in Gaussian models under total positivity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the problem of maximum likelihood estimation for Gaussian\ndistributions that are multivariate totally positive of order two (MTP2). By\nexploiting connections to phylogenetics and single-linkage clustering, we give\na simple proof that the maximum likelihood estimator (MLE) for such\ndistributions exists based on at least 2 observations, irrespective of the\nunderlying dimension. Slawski and Hein, who first proved this result, also\nprovided empirical evidence showing that the MTP2 constraint serves as an\nimplicit regularizer and leads to sparsity in the estimated inverse covariance\nmatrix, determining what we name the ML graph. We show that we can find an\nupper bound for the ML graph by adding edges corresponding to correlations in\nexcess of those explained by the maximum weight spanning forest of the\ncorrelation matrix. Moreover, we provide globally convergent coordinate descent\nalgorithms for calculating the MLE under the MTP2 constraint which are\nstructurally similar to iterative proportional scaling. We conclude the paper\nwith a discussion of signed MTP2 distributions.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2017 00:34:06 GMT"}, {"version": "v2", "created": "Fri, 27 Apr 2018 07:31:07 GMT"}, {"version": "v3", "created": "Sat, 26 May 2018 12:26:42 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Lauritzen", "Steffen", ""], ["Uhler", "Caroline", ""], ["Zwiernik", "Piotr", ""]]}, {"id": "1702.04065", "submitter": "Salha Mamane", "authors": "Piotr Graczyk, Hideyuki Ishi and Salha Mamane", "title": "Wishart exponential families on cones related to An graphs", "comments": "30 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let G = An be the graph corresponding to the graphical model of nearest\nneighbour interaction in a Gaussian character. We study Natural Exponential\nFamilies( NEF) ofWishart distributions on convex cones QG and PG, where PG is\nthe cone of positive definite real symmetric matrices with obligatory zeros\nprescribed by G, and QG is the dual cone of PG. The Wishart NEF that we\nconstruct include Wishart distributions considered earlier by Lauritzen (1996)\nand Letac and Massam (2007) for models based on decomposable graphs. Our\napproach is however different and allows us to study the basic objects\nofWishart NEF on the cones QG and PG.We determine Riesz measures generating\nWishart exponential families on QG and PG, and we give the quadratic\nconstruction of these Riesz measures and exponential families. The mean,\ninverse-mean, covariance and variance functions, as well as moments of higher\norder are studied and their explicit formulas are given.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2017 03:45:37 GMT"}], "update_date": "2017-02-15", "authors_parsed": [["Graczyk", "Piotr", ""], ["Ishi", "Hideyuki", ""], ["Mamane", "Salha", ""]]}, {"id": "1702.04477", "submitter": "Elizabeth Gross", "authors": "Elizabeth Gross, Sonja Petrovi\\'c, Donald Richards, and Despina Stasi", "title": "The Multiple Roots Phenomenon in Maximum Likelihood Estimation for\n  Factor Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiple root estimation problems in statistical inference arise in many\ncontexts in the literature. In the context of maximum likelihood estimation,\nthe existence of multiple roots causes uncertainty in the computation of\nmaximum likelihood estimators using hill-climbing algorithms, and consequent\ndifficulties in the resulting statistical inference.\n  In this paper, we study the multiple roots phenomenon in maximum likelihood\nestimation for factor analysis. We prove that the corresponding likelihood\nequations have uncountably many feasible solutions even in the simplest cases.\nFor the case in which the observed data are two-dimensional and the unobserved\nfactor scores are one-dimensional, we prove that the solutions to the\nlikelihood equations form a one-dimensional real curve.\n", "versions": [{"version": "v1", "created": "Wed, 15 Feb 2017 06:53:03 GMT"}], "update_date": "2017-02-16", "authors_parsed": [["Gross", "Elizabeth", ""], ["Petrovi\u0107", "Sonja", ""], ["Richards", "Donald", ""], ["Stasi", "Despina", ""]]}, {"id": "1702.04656", "submitter": "Chao Gao", "authors": "Chao Gao", "title": "Robust Regression via Mutivariate Regression Depth", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies robust regression in the settings of Huber's\n$\\epsilon$-contamination models. We consider estimators that are maximizers of\nmultivariate regression depth functions. These estimators are shown to achieve\nminimax rates in the settings of $\\epsilon$-contamination models for various\nregression problems including nonparametric regression, sparse linear\nregression, reduced rank regression, etc. We also discuss a general notion of\ndepth function for linear operators that has potential applications in robust\nfunctional linear regression.\n", "versions": [{"version": "v1", "created": "Wed, 15 Feb 2017 15:48:30 GMT"}], "update_date": "2017-02-16", "authors_parsed": [["Gao", "Chao", ""]]}, {"id": "1702.04665", "submitter": "Rajesh Sharma", "authors": "R. Sharma, A. Sharma, R. Saini and G. Kapoor", "title": "Means Moments and Newton's Inequalities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is shown that Newton's inequalities and the related Maclaurin's\ninequalities provide several refinements of the fundamental Arithmetic mean -\nGeometric mean - Harmonic mean inequality in terms of the means and variance of\npositive real numbers. We also obtain some inequalities involving third and\nfourth central moments of real numbers.\n", "versions": [{"version": "v1", "created": "Wed, 15 Feb 2017 16:07:34 GMT"}], "update_date": "2017-02-16", "authors_parsed": [["Sharma", "R.", ""], ["Sharma", "A.", ""], ["Saini", "R.", ""], ["Kapoor", "G.", ""]]}, {"id": "1702.04672", "submitter": "Joakim And\\'en", "authors": "Joakim And\\'en and Amit Singer", "title": "Factor Analysis for Spectral Estimation", "comments": "5 pages, 3 figures; 12th International Conference Sampling Theory and\n  Applications, July 3-7, 2017, Tallinn, Estonia", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Power spectrum estimation is an important tool in many applications, such as\nthe whitening of noise. The popular multitaper method enjoys significant\nsuccess, but fails for short signals with few samples. We propose a statistical\nmodel where a signal is given by a random linear combination of fixed, yet\nunknown, stochastic sources. Given multiple such signals, we estimate the\nsubspace spanned by the power spectra of these fixed sources. Projecting\nindividual power spectrum estimates onto this subspace increases estimation\naccuracy. We provide accuracy guarantees for this method and demonstrate it on\nsimulated and experimental data from cryo-electron microscopy.\n", "versions": [{"version": "v1", "created": "Wed, 15 Feb 2017 16:31:15 GMT"}, {"version": "v2", "created": "Mon, 8 May 2017 23:29:21 GMT"}], "update_date": "2018-12-10", "authors_parsed": [["And\u00e9n", "Joakim", ""], ["Singer", "Amit", ""]]}, {"id": "1702.05063", "submitter": "Adrien Saumard", "authors": "Adrien Saumard", "title": "A concentration inequality for the excess risk in least-squares\n  regression with random design and heteroscedastic noise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove a new and general concentration inequality for the excess risk in\nleast-squares regression with random design and heteroscedastic noise. No\nspecific structure is required on the model, except the existence of a suitable\nfunction that controls the local suprema of the empirical process. So far, only\nthe case of linear contrast estimation was tackled in the literature with this\nlevel of generality on the model. We solve here the case of a quadratic\ncontrast, by separating the behavior of a linearized empirical process and the\nempirical process driven by the squares of functions of models.\n", "versions": [{"version": "v1", "created": "Thu, 16 Feb 2017 17:35:06 GMT"}, {"version": "v2", "created": "Fri, 9 Mar 2018 14:25:00 GMT"}], "update_date": "2018-03-12", "authors_parsed": [["Saumard", "Adrien", ""]]}, {"id": "1702.05066", "submitter": "Carlos Am\\'endola", "authors": "Carlos Am\\'endola and Alexander Engstr\\\"om and Christian Haase", "title": "Maximum Number of Modes of Gaussian Mixtures", "comments": "14 pages, 5 figures. Final version, to appear in Information and\n  Inference", "journal-ref": null, "doi": "10.1093/imaiai/iaz013", "report-no": null, "categories": "math.ST math.OC math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian mixture models are widely used in Statistics. A fundamental aspect\nof these distributions is the study of the local maxima of the density, or\nmodes. In particular, it is not known how many modes a mixture of $k$ Gaussians\nin $d$ dimensions can have. We give a brief account of this problem's history.\nThen, we give improved lower bounds and the first upper bound on the maximum\nnumber of modes, provided it is finite.\n", "versions": [{"version": "v1", "created": "Thu, 16 Feb 2017 17:53:07 GMT"}, {"version": "v2", "created": "Mon, 30 Oct 2017 16:53:27 GMT"}, {"version": "v3", "created": "Thu, 18 Apr 2019 16:02:06 GMT"}], "update_date": "2019-07-22", "authors_parsed": [["Am\u00e9ndola", "Carlos", ""], ["Engstr\u00f6m", "Alexander", ""], ["Haase", "Christian", ""]]}, {"id": "1702.05113", "submitter": "Adityanand Guntuboyina", "authors": "Adityanand Guntuboyina, Donovan Lieu, Sabyasachi Chatterjee and\n  Bodhisattva Sen", "title": "Adaptive Risk Bounds in Univariate Total Variation Denoising and Trend\n  Filtering", "comments": "110 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study trend filtering, a relatively recent method for univariate\nnonparametric regression. For a given positive integer $r$, the $r$-th order\ntrend filtering estimator is defined as the minimizer of the sum of squared\nerrors when we constrain (or penalize) the sum of the absolute $r$-th order\ndiscrete derivatives of the fitted function at the design points. For $r=1$,\nthe estimator reduces to total variation regularization which has received much\nattention in the statistics and image processing literature. In this paper, we\nstudy the performance of the trend filtering estimator for every positive\ninteger $r$, both in the constrained and penalized forms. Our main results show\nthat in the strong sparsity setting when the underlying function is a\n(discrete) spline with few \"knots\", the risk (under the global squared error\nloss) of the trend filtering estimator (with an appropriate choice of the\ntuning parameter) achieves the parametric $n^{-1}$ rate, up to a logarithmic\n(multiplicative) factor. Our results therefore provide support for the use of\ntrend filtering, for every $r$, in the strong sparsity setting.\n", "versions": [{"version": "v1", "created": "Thu, 16 Feb 2017 19:14:54 GMT"}, {"version": "v2", "created": "Sun, 24 Jun 2018 23:22:21 GMT"}], "update_date": "2018-06-26", "authors_parsed": [["Guntuboyina", "Adityanand", ""], ["Lieu", "Donovan", ""], ["Chatterjee", "Sabyasachi", ""], ["Sen", "Bodhisattva", ""]]}, {"id": "1702.05193", "submitter": "Alejandro  Cholaquidis", "authors": "Catherine Aaron, Alejandro Cholaquidis, Antonio Cuevas", "title": "Detection of low dimensionality and data denoising via set estimation\n  techniques", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work is closely related to the theories of set estimation and manifold\nestimation.\n  Our object of interest is a, possibly lower-dimensional, compact set $S\n  \\subset {\\mathbb R}^d$.\n  The general aim is to identify (via stochastic procedures) some qualitative\nor quantitative features of $S$, of geometric or topological character. The\navailable information is just a random sample of points drawn on $S$.\n  The term \"to identify\" means here to achieve a correct answer almost surely\n(a.s.) when the sample size tends to infinity. More specifically the paper aims\nat giving some partial answers to the following questions: is $S$ full\ndimensional? Is $S$ \"close to a lower dimensional set\" $\\mathcal{M}$? If so,\ncan we estimate $\\mathcal{M}$ or some functionals of $\\mathcal{M}$ (in\nparticular, the Minkowski content of $\\mathcal{M}$)? As an important auxiliary\ntool in the answers of these questions, a denoising procedure is proposed in\norder to partially remove the noise in the original data. The theoretical\nresults are complemented with some simulations and graphical illustrations.\n", "versions": [{"version": "v1", "created": "Fri, 17 Feb 2017 00:12:24 GMT"}, {"version": "v2", "created": "Fri, 3 Nov 2017 13:25:41 GMT"}], "update_date": "2017-11-06", "authors_parsed": [["Aaron", "Catherine", ""], ["Cholaquidis", "Alejandro", ""], ["Cuevas", "Antonio", ""]]}, {"id": "1702.05315", "submitter": "Alessio Sancetta", "authors": "Alessio Sancetta", "title": "Estimation for the Prediction of Point Processes with Many Covariates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST q-fin.TR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimation of the intensity of a point process is considered within a\nnonparametric framework. The intensity measure is unknown and depends on\ncovariates, possibly many more than the observed number of jumps. Only a single\ntrajectory of the counting process is observed. Interest lies in estimating the\nintensity conditional on the covariates. The impact of the covariates is\nmodelled by an additive model where each component can be written as a linear\ncombination of possibly unknown functions. The focus is on prediction as\nopposed to variable screening. Conditions are imposed on the coefficients of\nthis linear combination in order to control the estimation error. The rates of\nconvergence are optimal when the number of active covariates is large. As an\napplication, the intensity of the buy and sell trades of the New Zealand dollar\nfutures is estimated and a test for forecast evaluation is presented. A\nsimulation is included to provide some finite sample intuition on the model and\nasymptotic properties.\n", "versions": [{"version": "v1", "created": "Fri, 17 Feb 2017 12:06:48 GMT"}], "update_date": "2017-02-20", "authors_parsed": [["Sancetta", "Alessio", ""]]}, {"id": "1702.05443", "submitter": "Andreas Loukas", "authors": "Andreas Loukas", "title": "How close are the eigenvectors and eigenvalues of the sample and actual\n  covariance matrices?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How many samples are sufficient to guarantee that the eigenvectors and\neigenvalues of the sample covariance matrix are close to those of the actual\ncovariance matrix? For a wide family of distributions, including distributions\nwith finite second moment and distributions supported in a centered Euclidean\nball, we prove that the inner product between eigenvectors of the sample and\nactual covariance matrices decreases proportionally to the respective\neigenvalue distance. Our findings imply non-asymptotic concentration bounds for\neigenvectors, eigenspaces, and eigenvalues. They also provide conditions for\ndistinguishing principal components based on a constant number of samples.\n", "versions": [{"version": "v1", "created": "Fri, 17 Feb 2017 17:15:23 GMT"}], "update_date": "2017-02-20", "authors_parsed": [["Loukas", "Andreas", ""]]}, {"id": "1702.05462", "submitter": "Fabrizio Leisen", "authors": "Laurentiu Hinoveanu, Fabrizio Leisen and Cristiano Villa", "title": "Objective Bayesian Analysis for Change Point Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.AP stat.CO stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a loss-based approach to change point analysis. In\nparticular, we look at the problem from two perspectives. The first focuses on\nthe definition of a prior when the number of change points is known a priori.\nThe second contribution aims to estimate the number of change points by using a\nloss-based approach recently introduced in the literature. The latter considers\nchange point estimation as a model selection exercise. We show the performance\nof the proposed approach on simulated data and real data sets.\n", "versions": [{"version": "v1", "created": "Fri, 17 Feb 2017 18:06:27 GMT"}, {"version": "v2", "created": "Sun, 7 Jan 2018 13:58:48 GMT"}], "update_date": "2018-01-09", "authors_parsed": [["Hinoveanu", "Laurentiu", ""], ["Leisen", "Fabrizio", ""], ["Villa", "Cristiano", ""]]}, {"id": "1702.05545", "submitter": "Stephen Portnoy", "authors": "Stephen Portnoy", "title": "Some Theorems on Optimality of a Single Observation Confidence Interval\n  for the Mean of a Normal Distribution", "comments": "21 pages, 1 figure, dedicated to the memory of Charles Stein (2910 -\n  2016)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of finding a proper confidence interval for the mean\nbased on a single observation from a normal distribution with both mean and\nvariance unknown. Portnoy (2017) characterizes the scale-sign invariant rules\nand shows that the Hunt-Stein construction provides a randomized invariant rule\nthat improves on any given randomized rule in the sense that it has greater\nminimal coverage among all procedures with a fixed expected length.\nMathematical results here provide a specific mixture of two non-randomized\ninvariant rules that achieve the minimax optimality. A multivariate confidence\nset based on a single observation vector is also developed.\n", "versions": [{"version": "v1", "created": "Sat, 18 Feb 2017 00:04:15 GMT"}, {"version": "v2", "created": "Mon, 14 May 2018 15:54:52 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Portnoy", "Stephen", ""]]}, {"id": "1702.05574", "submitter": "Yury Polyanskiy", "authors": "Yury Polyanskiy, Ananda Theertha Suresh and Yihong Wu", "title": "Sample complexity of population recovery", "comments": "Earlier versions (incl. the one in proceedings) had a mistake in\n  Prop. 9 that propagated to Theorem 1 (lower bound) and Lemma 12. This version\n  (v3) fixes those", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT math.IT stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of population recovery refers to estimating a distribution based\non incomplete or corrupted samples. Consider a random poll of sample size $n$\nconducted on a population of individuals, where each pollee is asked to answer\n$d$ binary questions. We consider one of the two polling impediments: (a) in\nlossy population recovery, a pollee may skip each question with probability\n$\\epsilon$, (b) in noisy population recovery, a pollee may lie on each question\nwith probability $\\epsilon$. Given $n$ lossy or noisy samples, the goal is to\nestimate the probabilities of all $2^d$ binary vectors simultaneously within\naccuracy $\\delta$ with high probability.\n  This paper settles the sample complexity of population recovery. For lossy\nmodel, the optimal sample complexity is\n$\\tilde\\Theta(\\delta^{-2\\max\\{\\frac{\\epsilon}{1-\\epsilon},1\\}})$, improving the\nstate of the art by Moitra and Saks in several ways: a lower bound is\nestablished, the upper bound is improved and the result depends at most on the\nlogarithm of the dimension. Surprisingly, the sample complexity undergoes a\nphase transition from parametric to nonparametric rate when $\\epsilon$ exceeds\n$1/2$. For noisy population recovery, the sharp sample complexity turns out to\nbe more sensitive to dimension and scales as $\\exp(\\Theta(d^{1/3}\n\\log^{2/3}(1/\\delta)))$ except for the trivial cases of $\\epsilon=0,1/2$ or\n$1$.\n  For both models, our estimators simply compute the empirical mean of a\ncertain function, which is found by pre-solving a linear program (LP).\nCuriously, the dual LP can be understood as Le Cam's method for lower-bounding\nthe minimax risk, thus establishing the statistical optimality of the proposed\nestimators. The value of the LP is determined by complex-analytic methods.\n", "versions": [{"version": "v1", "created": "Sat, 18 Feb 2017 06:11:25 GMT"}, {"version": "v2", "created": "Mon, 5 Jun 2017 01:56:29 GMT"}, {"version": "v3", "created": "Wed, 29 Apr 2020 09:23:13 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Polyanskiy", "Yury", ""], ["Suresh", "Ananda Theertha", ""], ["Wu", "Yihong", ""]]}, {"id": "1702.05599", "submitter": "Jonathan Rougier", "authors": "Jonathan Rougier", "title": "A representation theorem for stochastic processes with separable\n  covariance functions, and its implications for emulation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many applications require stochastic processes specified on two- or\nhigher-dimensional domains; spatial or spatial-temporal modelling, for example.\nIn these applications it is attractive, for conceptual simplicity and\ncomputational tractability, to propose a covariance function that is separable;\ne.g., the product of a covariance function in space and one in time. This paper\npresents a representation theorem for such a proposal, and shows that all\nprocesses with continuous separable covariance functions are second-order\nidentical to the product of second-order uncorrelated processes. It discusses\nthe implications of separable or nearly separable prior covariances for the\nstatistical emulation of complicated functions such as computer codes, and\ncritically reexamines the conventional wisdom concerning emulator structure,\nand size of design.\n", "versions": [{"version": "v1", "created": "Sat, 18 Feb 2017 10:58:00 GMT"}], "update_date": "2017-02-21", "authors_parsed": [["Rougier", "Jonathan", ""]]}, {"id": "1702.05641", "submitter": "Igor Rodionov V.", "authors": "Igor Vladimirovich Rodionov", "title": "On discrimination between two close distribution tails", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goodness-of-fit test for discrimination of two tail distribution using\nhigher order statistics is proposed. The consistency of proposed test is proved\nfor two different alternatives. We do not assume belonging the corresponding\ndistribution function to a maximum domain of attraction.\n", "versions": [{"version": "v1", "created": "Sat, 18 Feb 2017 18:23:38 GMT"}], "update_date": "2017-02-21", "authors_parsed": [["Rodionov", "Igor Vladimirovich", ""]]}, {"id": "1702.05910", "submitter": "Karthik Bharath", "authors": "H. N. Nagaraja and Karthik Bharath and Fangyuan Zhang", "title": "Spacings Around An Order Statistic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We determine the joint limiting distribution of adjacent spacings around a\ncentral, intermediate, or an extreme order statistic $X_{k:n}$ of a random\nsample of size $n$ from a continuous distribution $F$. For central and\nintermediate cases, normalized spacings in the left and right neighborhoods are\nasymptotically i.i.d. exponential random variables. The associated independent\nPoisson arrival processes are independent of $X_{k:n}$. For an extreme\n$X_{k:n}$, the asymptotic independence property of spacings fails for $F$ in\nthe domain of attraction of Fr\\'{e}chet and Weibull ($\\alpha \\neq 1$)\ndistributions. This work also provides additional insight into the limiting\ndistribution for the number of observations around $X_{k:n}$ for all three\ncases.\n", "versions": [{"version": "v1", "created": "Mon, 20 Feb 2017 09:51:03 GMT"}], "update_date": "2017-02-21", "authors_parsed": [["Nagaraja", "H. N.", ""], ["Bharath", "Karthik", ""], ["Zhang", "Fangyuan", ""]]}, {"id": "1702.05933", "submitter": "Katharina Strohriegl", "authors": "Katharina Strohriegl", "title": "Qualitative robustness for bootstrap approximations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important property of statistical estimators is qualitative robustness,\nthat is small changes in the distribution of the data only result in small\nchances of the distribution of the estimator. Moreover, in practice, the\ndistribution of the data is commonly unknown, therefore bootstrap\napproximations can be used to approximate the distribution of the estimator.\nHence qualitative robustness of the statistical estimator under the bootstrap\napproximation is a desirable property. Currently most theoretical\ninvestigations on qualitative robustness assume independent and identically\ndistributed pairs of random variables. However, in practice this assumption is\nnot fulfilled. Therefore, we examine the qualitative robustness of bootstrap\napproximations for non-i.i.d. random variables, for example $\\alpha$-mixing and\nweakly dependent processes. In the i.i.d. case qualitative robustness is\nensured via the continuity of the statistical operator, representing the\nestimator, see Hampel (1971) and Cuevas and Romo (1993). We show, that\nqualitative robustness of the bootstrap approximation is still ensured under\nthe assumption that the statistical operator is continuous and under an\nadditional assumption on the stochastic process. In particular, we require a\nconvergence condition of the empirical measure of the underlying process, the\nso called Varadarajan property.\n", "versions": [{"version": "v1", "created": "Mon, 20 Feb 2017 11:40:47 GMT"}, {"version": "v2", "created": "Mon, 22 Jan 2018 13:26:13 GMT"}], "update_date": "2018-01-23", "authors_parsed": [["Strohriegl", "Katharina", ""]]}, {"id": "1702.05960", "submitter": "Jun Fan", "authors": "Yunlong Feng, Jun Fan, and Johan A.K. Suykens", "title": "A Statistical Learning Approach to Modal Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the nonparametric modal regression problem systematically\nfrom a statistical learning view. Originally motivated by pursuing a\ntheoretical understanding of the maximum correntropy criterion based regression\n(MCCR), our study reveals that MCCR with a tending-to-zero scale parameter is\nessentially modal regression. We show that nonparametric modal regression\nproblem can be approached via the classical empirical risk minimization. Some\nefforts are then made to develop a framework for analyzing and implementing\nmodal regression. For instance, the modal regression function is described, the\nmodal regression risk is defined explicitly and its \\textit{Bayes} rule is\ncharacterized; for the sake of computational tractability, the surrogate modal\nregression risk, which is termed as the generalization risk in our study, is\nintroduced. On the theoretical side, the excess modal regression risk, the\nexcess generalization risk, the function estimation error, and the relations\namong the above three quantities are studied rigorously. It turns out that\nunder mild conditions, function estimation consistency and convergence may be\npursued in modal regression as in vanilla regression protocols, such as mean\nregression, median regression, and quantile regression. However, it outperforms\nthese regression models in terms of robustness as shown in our study from a\nre-descending M-estimation view. This coincides with and in return explains the\nmerits of MCCR on robustness. On the practical side, the implementation issues\nof modal regression including the computational algorithm and the tuning\nparameters selection are discussed. Numerical assessments on modal regression\nare also conducted to verify our findings empirically.\n", "versions": [{"version": "v1", "created": "Mon, 20 Feb 2017 13:31:39 GMT"}, {"version": "v2", "created": "Wed, 8 Mar 2017 18:22:26 GMT"}, {"version": "v3", "created": "Thu, 16 Jan 2020 06:39:00 GMT"}, {"version": "v4", "created": "Fri, 17 Jan 2020 05:29:25 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["Feng", "Yunlong", ""], ["Fan", "Jun", ""], ["Suykens", "Johan A. K.", ""]]}, {"id": "1702.05985", "submitter": "Gilles Stoltz", "authors": "Sebastien Gerchinovitz (IMT), Pierre M\\'enard (IMT), Gilles Stoltz\n  (GREGHEC, LMO)", "title": "Fano's inequality for random variables", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT math.IT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend Fano's inequality, which controls the average probability of events\nin terms of the average of some $f$--divergences, to work with arbitrary events\n(not necessarily forming a partition) and even with arbitrary $[0,1]$--valued\nrandom variables, possibly in continuously infinite number. We provide two\napplications of these extensions, in which the consideration of random\nvariables is particularly handy: we offer new and elegant proofs for existing\nlower bounds, on Bayesian posterior concentration (minimax or\ndistribution-dependent) rates and on the regret in non-stochastic sequential\nlearning.\n", "versions": [{"version": "v1", "created": "Mon, 20 Feb 2017 14:34:46 GMT"}, {"version": "v2", "created": "Wed, 19 Sep 2018 09:27:20 GMT"}, {"version": "v3", "created": "Mon, 10 Jun 2019 18:31:10 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Gerchinovitz", "Sebastien", "", "IMT"], ["M\u00e9nard", "Pierre", "", "IMT"], ["Stoltz", "Gilles", "", "GREGHEC, LMO"]]}, {"id": "1702.06055", "submitter": "Enrico Scalas", "authors": "J. M. Chen, A. G. Hawkes, E. Scalas, M. Trinh", "title": "Performance of information criteria used for model selection of Hawkes\n  process models of financial data", "comments": "28 pages, 1 figure, submitted to a special issue of Quantitative\n  Finance. Some typos in the previous version have been now corrected", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We test three common information criteria (IC) for selecting the order of a\nHawkes process with an intensity kernel that can be expressed as a mixture of\nexponential terms. These processes find application in high-frequency financial\ndata modelling. The information criteria are Akaike's information criterion\n(AIC), the Bayesian information criterion (BIC) and the Hannan-Quinn criterion\n(HQ). Since we work with simulated data, we are able to measure the performance\nof model selection by the success rate of the IC in selecting the model that\nwas used to generate the data. In particular, we are interested in the relation\nbetween correct model selection and underlying sample size. The analysis\nincludes realistic sample sizes and parameter sets from recent literature where\nparameters were estimated using empirical financial intra-day data. We compare\nour results to theoretical predictions and similar empirical findings on the\nasymptotic distribution of model selection for consistent and inconsistent IC.\n", "versions": [{"version": "v1", "created": "Mon, 20 Feb 2017 16:40:45 GMT"}, {"version": "v2", "created": "Tue, 4 Apr 2017 13:31:30 GMT"}], "update_date": "2017-04-05", "authors_parsed": [["Chen", "J. M.", ""], ["Hawkes", "A. G.", ""], ["Scalas", "E.", ""], ["Trinh", "M.", ""]]}, {"id": "1702.06488", "submitter": "Kaizheng Wang", "authors": "Jianqing Fan, Dong Wang, Kaizheng Wang, Ziwei Zhu", "title": "Distributed Estimation of Principal Eigenspaces", "comments": "47 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Principal component analysis (PCA) is fundamental to statistical machine\nlearning. It extracts latent principal factors that contribute to the most\nvariation of the data. When data are stored across multiple machines, however,\ncommunication cost can prohibit the computation of PCA in a central location\nand distributed algorithms for PCA are thus needed. This paper proposes and\nstudies a distributed PCA algorithm: each node machine computes the top $K$\neigenvectors and transmits them to the central server; the central server then\naggregates the information from all the node machines and conducts a PCA based\non the aggregated information. We investigate the bias and variance for the\nresulting distributed estimator of the top $K$ eigenvectors. In particular, we\nshow that for distributions with symmetric innovation, the empirical top\neigenspaces are unbiased and hence the distributed PCA is \"unbiased\". We derive\nthe rate of convergence for distributed PCA estimators, which depends\nexplicitly on the effective rank of covariance, eigen-gap, and the number of\nmachines. We show that when the number of machines is not unreasonably large,\nthe distributed PCA performs as well as the whole sample PCA, even without full\naccess of whole data. The theoretical results are verified by an extensive\nsimulation study. We also extend our analysis to the heterogeneous case where\nthe population covariance matrices are different across local machines but\nshare similar top eigen-structures.\n", "versions": [{"version": "v1", "created": "Tue, 21 Feb 2017 17:38:26 GMT"}, {"version": "v2", "created": "Thu, 23 Feb 2017 19:01:53 GMT"}, {"version": "v3", "created": "Wed, 12 Apr 2017 18:24:30 GMT"}, {"version": "v4", "created": "Wed, 10 Jan 2018 14:53:30 GMT"}], "update_date": "2018-01-11", "authors_parsed": [["Fan", "Jianqing", ""], ["Wang", "Dong", ""], ["Wang", "Kaizheng", ""], ["Zhu", "Ziwei", ""]]}, {"id": "1702.06972", "submitter": "Azadeh Khaleghi", "authors": "Steffen Grunewalder and Azadeh Khaleghi", "title": "Approximations of the Restless Bandit Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG math.PR stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The multi-armed restless bandit problem is studied in the case where the\npay-off distributions are stationary $\\varphi$-mixing. This version of the\nproblem provides a more realistic model for most real-world applications, but\ncannot be optimally solved in practice, since it is known to be PSPACE-hard.\nThe objective of this paper is to characterize a sub-class of the problem where\n{\\em good} approximate solutions can be found using tractable approaches.\nSpecifically, it is shown that under some conditions on the $\\varphi$-mixing\ncoefficients, a modified version of UCB can prove effective. The main challenge\nis that, unlike in the i.i.d. setting, the distributions of the sampled\npay-offs may not have the same characteristics as those of the original bandit\narms. In particular, the $\\varphi$-mixing property does not necessarily carry\nover. This is overcome by carefully controlling the effect of a sampling policy\non the pay-off distributions. Some of the proof techniques developed in this\npaper can be more generally used in the context of online sampling under\ndependence. Proposed algorithms are accompanied with corresponding regret\nanalysis.\n", "versions": [{"version": "v1", "created": "Wed, 22 Feb 2017 19:22:55 GMT"}, {"version": "v2", "created": "Thu, 5 Jul 2018 17:17:14 GMT"}, {"version": "v3", "created": "Fri, 28 Dec 2018 14:21:04 GMT"}], "update_date": "2018-12-31", "authors_parsed": [["Grunewalder", "Steffen", ""], ["Khaleghi", "Azadeh", ""]]}, {"id": "1702.06975", "submitter": "Xiucai Ding", "authors": "Xiucai Ding", "title": "High dimensional deformed rectangular matrices with applications in\n  matrix denoising", "comments": null, "journal-ref": "Bernoulli, 2019", "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the recovery of a low rank $M \\times N$ matrix $S$ from its noisy\nobservation $\\tilde{S}$ in two different regimes. Under the assumption that $M$\nis comparable to $N$, we propose two consistent estimators for $S$. Our\nanalysis relies on the local behavior of the large dimensional rectangular\nmatrices with finite rank perturbation. We also derive the convergent limits\nand rates for the singular values and vectors of such matrices.\n", "versions": [{"version": "v1", "created": "Wed, 22 Feb 2017 19:25:29 GMT"}, {"version": "v2", "created": "Sat, 22 Apr 2017 15:38:59 GMT"}, {"version": "v3", "created": "Tue, 23 Apr 2019 16:26:41 GMT"}], "update_date": "2019-04-24", "authors_parsed": [["Ding", "Xiucai", ""]]}, {"id": "1702.07027", "submitter": "Yen-Chi Chen", "authors": "Gang Cheng, Yen-Chi Chen", "title": "Nonparametric Inference via Bootstrapping the Debiased Estimator", "comments": "Accepted to the Electronic Journal of Statistics. 64 pages, 6 tables,\n  11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose to construct confidence bands by bootstrapping the\ndebiased kernel density estimator (for density estimation) and the debiased\nlocal polynomial regression estimator (for regression analysis). The idea of\nusing a debiased estimator was recently employed by Calonico et al. (2018b) to\nconstruct a confidence interval of the density function (and regression\nfunction) at a given point by explicitly estimating stochastic variations. We\nextend their ideas of using the debiased estimator and further propose a\nbootstrap approach for constructing simultaneous confidence bands. This\nmodified method has an advantage that we can easily choose the smoothing\nbandwidth from conventional bandwidth selectors and the confidence band will be\nasymptotically valid. We prove the validity of the bootstrap confidence band\nand generalize it to density level sets and inverse regression problems.\nSimulation studies confirm the validity of the proposed confidence bands/sets.\nWe apply our approach to an Astronomy dataset to show its applicability\n", "versions": [{"version": "v1", "created": "Wed, 22 Feb 2017 22:21:05 GMT"}, {"version": "v2", "created": "Sun, 26 Feb 2017 20:06:00 GMT"}, {"version": "v3", "created": "Tue, 4 Jun 2019 22:30:55 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Cheng", "Gang", ""], ["Chen", "Yen-Chi", ""]]}, {"id": "1702.07082", "submitter": "Zheyang Wu", "authors": "Hong Zhang, Jiashun Jin, Zheyang Wu", "title": "Distributions and Statistical Power of Optimal Signal-Detection Methods\n  In Finite Cases", "comments": "37 pages, 9 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In big data analysis for detecting rare and weak signals among $n$ features,\nsome grouping-test methods such as Higher Criticism test (HC), Berk-Jones test\n(B-J), and $\\phi$-divergence test share the similar asymptotical optimality\nwhen $n \\rightarrow \\infty$. However, in practical data analysis $n$ is\nfrequently small and moderately large at most. In order to properly apply these\noptimal tests and wisely choose them for practical studies, it is important to\nknow how to get the p-values and statistical power of them. To address this\nproblem in an even broader context, this paper provides analytical solutions\nfor a general family of goodness-of-fit (GOF) tests, which covers these optimal\ntests. For any given i.i.d. and continuous distributions of the input test\nstatistics of the $n$ features, both p-value and statistical power of such a\nGOF test can be calculated. By calculation we compared the finite-sample\nperformances of asymptotically optimal tests under the normal mixture\nalternative. Results show that HC is the best choice when signals are rare,\nwhile B-J is more robust over various signal patterns. In the application to a\nreal genome-wide association study, results illustrate that the p-value\ncalculation works well, and the optimal tests have potentials for detecting\nnovel disease genes with weak genetic effects. The calculations have been\nimplemented in an R package SetTest and published on the CRAN.\n", "versions": [{"version": "v1", "created": "Thu, 23 Feb 2017 03:31:22 GMT"}], "update_date": "2017-02-24", "authors_parsed": [["Zhang", "Hong", ""], ["Jin", "Jiashun", ""], ["Wu", "Zheyang", ""]]}, {"id": "1702.07118", "submitter": "Salem Said", "authors": "Salem Said and Yannick Berthoumieu", "title": "Warped metrics for location-scale models", "comments": "preprint of a submission to GSI 2017 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.DG stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper argues that a class of Riemannian metrics, called warped metrics,\nplays a fundamental role in statistical problems involving location-scale\nmodels. The paper reports three new results : i) the Rao-Fisher metric of any\nlocation-scale model is a warped metric, provided that this model satisfies a\nnatural invariance condition, ii) the analytic expression of the sectional\ncurvature of this metric, iii) the exact analytic solution of the geodesic\nequation of this metric. The paper applies these new results to several\nexamples of interest, where it shows that warped metrics turn location-scale\nmodels into complete Riemannian manifolds of negative sectional curvature. This\nis a very suitable situation for developing algorithms which solve problems of\nclassification and on-line estimation. Thus, by revealing the connection\nbetween warped metrics and location-scale models, the present paper paves the\nway to the introduction of new efficient statistical algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 23 Feb 2017 07:22:32 GMT"}], "update_date": "2017-02-24", "authors_parsed": [["Said", "Salem", ""], ["Berthoumieu", "Yannick", ""]]}, {"id": "1702.07211", "submitter": "Pierre Menard", "authors": "Pierre M\\'enard (1), Aur\\'elien Garivier (1) ((1) IMT)", "title": "A minimax and asymptotically optimal algorithm for stochastic bandits", "comments": null, "journal-ref": "Algorithmic Learning Theory, Springer, 2017, 2017 Algorithmic\n  Learning Theory Conference 76", "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the kl-UCB ++ algorithm for regret minimization in stochastic\nbandit models with exponential families of distributions. We prove that it is\nsimultaneously asymptotically optimal (in the sense of Lai and Robbins' lower\nbound) and minimax optimal. This is the first algorithm proved to enjoy these\ntwo properties at the same time. This work thus merges two different lines of\nresearch with simple and clear proofs.\n", "versions": [{"version": "v1", "created": "Thu, 23 Feb 2017 13:49:57 GMT"}, {"version": "v2", "created": "Wed, 20 Sep 2017 14:26:03 GMT"}], "update_date": "2017-09-21", "authors_parsed": [["M\u00e9nard", "Pierre", "", "IMT"], ["Garivier", "Aur\u00e9lien", "", "IMT"]]}, {"id": "1702.07448", "submitter": "Kyoungjae Lee", "authors": "Kyoungjae Lee and Jaeyong Lee", "title": "Optimal Bayesian Minimax Rates for Unconstrained Large Covariance\n  Matrices", "comments": "45 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We obtain the optimal Bayesian minimax rate for the unconstrained large\ncovariance matrix of multivariate normal sample with mean zero, when both the\nsample size, n, and the dimension, p, of the covariance matrix tend to\ninfinity. Traditionally the posterior convergence rate is used to compare the\nfrequentist asymptotic performance of priors, but defining the optimality with\nit is elusive. We propose a new decision theoretic framework for prior\nselection and define Bayesian minimax rate. Under the proposed framework, we\nobtain the optimal Bayesian minimax rate for the spectral norm for all rates of\np. We also considered Frobenius norm, Bregman divergence and squared\nlog-determinant loss and obtain the optimal Bayesian minimax rate under certain\nrate conditions on p. A simulation study is conducted to support the\ntheoretical results.\n", "versions": [{"version": "v1", "created": "Fri, 24 Feb 2017 02:09:04 GMT"}, {"version": "v2", "created": "Mon, 22 May 2017 18:57:32 GMT"}, {"version": "v3", "created": "Thu, 30 Nov 2017 20:48:56 GMT"}], "update_date": "2017-12-04", "authors_parsed": [["Lee", "Kyoungjae", ""], ["Lee", "Jaeyong", ""]]}, {"id": "1702.07795", "submitter": "Roberto Molinari Mr", "authors": "Haotian Xu, St\\'ephane Guerrier, Roberto Molinari and Yuming Zhang", "title": "A Study of the Allan Variance for Constant-Mean Non-Stationary Processes", "comments": null, "journal-ref": null, "doi": "10.1109/LSP.2017.2722222", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Allan Variance (AV) is a widely used quantity in areas focusing on error\nmeasurement as well as in the general analysis of variance for autocorrelated\nprocesses in domains such as engineering and, more specifically, metrology. The\nform of this quantity is widely used to detect noise patterns and indications\nof stability within signals. However, the properties of this quantity are not\nknown for commonly occurring processes whose covariance structure is\nnon-stationary and, in these cases, an erroneous interpretation of the AV could\nlead to misleading conclusions. This paper generalizes the theoretical form of\nthe AV to some non-stationary processes while at the same time being valid also\nfor weakly stationary processes. Some simulation examples show how this new\nform can help to understand the processes for which the AV is able to\ndistinguish these from the stationary cases and hence allow for a better\ninterpretation of this quantity in applied cases.\n", "versions": [{"version": "v1", "created": "Fri, 24 Feb 2017 22:55:56 GMT"}, {"version": "v2", "created": "Wed, 1 Mar 2017 00:17:04 GMT"}, {"version": "v3", "created": "Thu, 22 Jun 2017 14:42:24 GMT"}], "update_date": "2017-08-02", "authors_parsed": [["Xu", "Haotian", ""], ["Guerrier", "St\u00e9phane", ""], ["Molinari", "Roberto", ""], ["Zhang", "Yuming", ""]]}, {"id": "1702.07801", "submitter": "Michael Schweinberger", "authors": "Michael Schweinberger", "title": "Consistent structure estimation of exponential-family random graph\n  models with block structure", "comments": null, "journal-ref": "Bernoulli 2020, Vol. 26, No. 2, 1205-1233", "doi": "10.3150/19-BEJ1153", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the challenging problem of statistical inference for\nexponential-family random graph models based on a single observation of a\nrandom graph with complex dependence. To facilitate statistical inference, we\nconsider random graphs with additional structure in the form of block\nstructure. We have shown elsewhere that when the block structure is known, it\nfacilitates consistency results for $M$-estimators of canonical and curved\nexponential-family random graph models with complex dependence, such as\ntransitivity. In practice, the block structure is known in some applications\n(e.g., multilevel networks), but is unknown in others. When the block structure\nis unknown, the first and foremost question is whether it can be recovered with\nhigh probability based on a single observation of a random graph with complex\ndependence. The main consistency results of the paper show that it is possible\nto do so under weak dependence and smoothness conditions. These results confirm\nthat exponential-family random graph models with block structure constitute a\npromising direction of statistical network analysis.\n", "versions": [{"version": "v1", "created": "Fri, 24 Feb 2017 23:31:04 GMT"}, {"version": "v2", "created": "Tue, 6 Mar 2018 15:17:14 GMT"}, {"version": "v3", "created": "Mon, 4 Mar 2019 02:06:06 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Schweinberger", "Michael", ""]]}, {"id": "1702.07803", "submitter": "Shashank Singh", "authors": "Shashank Singh, Barnab\\'as P{\\o}czos", "title": "Nonparanormal Information Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT math.IT stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of using i.i.d. samples from an unknown multivariate\nprobability distribution $p$ to estimate the mutual information of $p$. This\nproblem has recently received attention in two settings: (1) where $p$ is\nassumed to be Gaussian and (2) where $p$ is assumed only to lie in a large\nnonparametric smoothness class. Estimators proposed for the Gaussian case\nconverge in high dimensions when the Gaussian assumption holds, but are\nbrittle, failing dramatically when $p$ is not Gaussian. Estimators proposed for\nthe nonparametric case fail to converge with realistic sample sizes except in\nvery low dimensions. As a result, there is a lack of robust mutual information\nestimators for many realistic data. To address this, we propose estimators for\nmutual information when $p$ is assumed to be a nonparanormal (a.k.a., Gaussian\ncopula) model, a semiparametric compromise between Gaussian and nonparametric\nextremes. Using theoretical bounds and experiments, we show these estimators\nstrike a practical balance between robustness and scaling with dimensionality.\n", "versions": [{"version": "v1", "created": "Fri, 24 Feb 2017 23:43:06 GMT"}], "update_date": "2017-02-28", "authors_parsed": [["Singh", "Shashank", ""], ["P\u00f8czos", "Barnab\u00e1s", ""]]}, {"id": "1702.07899", "submitter": "Rui Castro", "authors": "Rui M. Castro and Ervin T\\'anczos", "title": "Are there needles in a moving haystack? Adaptive sensing for detection\n  of dynamically evolving signals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we investigate the problem of detecting dynamically evolving\nsignals. We model the signal as an $n$ dimensional vector that is either zero\nor has $s$ non-zero components. At each time step $t\\in \\mathbb{N}$ the\nnon-zero components change their location independently with probability $p$.\nThe statistical problem is to decide whether the signal is a zero vector or in\nfact it has non-zero components. This decision is based on $m$ noisy\nobservations of individual signal components collected at times $t=1,\\ldots,m$.\nWe consider two different sensing paradigms, namely adaptive and non-adaptive\nsensing. For non-adaptive sensing the choice of components to measure has to be\ndecided before the data collection process started, while for adaptive sensing\none can adjust the sensing process based on observations collected earlier. We\ncharacterize the difficulty of this detection problem in both sensing paradigms\nin terms of the aforementioned parameters, with special interest to the speed\nof change of the active components. In addition we provide an adaptive sensing\nalgorithm for this problem and contrast its performance to that of non-adaptive\ndetection algorithms.\n", "versions": [{"version": "v1", "created": "Sat, 25 Feb 2017 14:53:53 GMT"}, {"version": "v2", "created": "Tue, 14 Nov 2017 12:14:23 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Castro", "Rui M.", ""], ["T\u00e1nczos", "Ervin", ""]]}, {"id": "1702.08109", "submitter": "Johannes Royset", "authors": "Johannes O. Royset and Roger J-B Wets", "title": "Variational Analysis of Constrained M-Estimators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a unified framework for establishing existence of nonparametric\nM-estimators, computing the corresponding estimates, and proving their strong\nconsistency when the class of functions is exceptionally rich. In particular,\nthe framework addresses situations where the class of functions is complex\ninvolving information and assumptions about shape, pointwise bounds, location\nof modes, height at modes, location of level-sets, values of moments, size of\nsubgradients, continuity, distance to a \"prior\" function, multivariate total\npositivity, and any combination of the above. The class might be engineered to\nperform well in a specific setting even in the presence of little data. The\nframework views the class of functions as a subset of a particular metric space\nof upper semicontinuous functions under the Attouch-Wets distance. In addition\nto allowing a systematic treatment of numerous M-estimators, the framework\nyields consistency of plug-in estimators of modes of densities, maximizers of\nregression functions, level-sets of classifiers, and related quantities, and\nalso enables computation by means of approximating parametric classes. We\nestablish consistency through a one-sided law of large numbers, here extended\nto sieves, that relaxes assumptions of uniform laws, while ensuring global\napproximations even under model misspecification.\n", "versions": [{"version": "v1", "created": "Sun, 26 Feb 2017 22:59:02 GMT"}, {"version": "v2", "created": "Mon, 22 May 2017 18:07:32 GMT"}, {"version": "v3", "created": "Fri, 9 Jun 2017 17:14:22 GMT"}, {"version": "v4", "created": "Thu, 31 May 2018 16:54:30 GMT"}, {"version": "v5", "created": "Mon, 9 Sep 2019 21:28:09 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Royset", "Johannes O.", ""], ["Wets", "Roger J-B", ""]]}, {"id": "1702.08211", "submitter": "Sebastien Gerchinovitz", "authors": "Nicol\\`o Cesa-Bianchi, Pierre Gaillard (SIERRA), Claudio Gentile,\n  S\\'ebastien Gerchinovitz (IMT)", "title": "Algorithmic Chaining and the Role of Partial Feedback in Online\n  Nonparametric Learning", "comments": "This document is the full version of an extended abstract accepted\n  for presentation at COLT 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate contextual online learning with nonparametric (Lipschitz)\ncomparison classes under different assumptions on losses and feedback\ninformation. For full information feedback and Lipschitz losses, we design the\nfirst explicit algorithm achieving the minimax regret rate (up to log factors).\nIn a partial feedback model motivated by second-price auctions, we obtain\nalgorithms for Lipschitz and semi-Lipschitz losses with regret bounds improving\non the known bounds for standard bandit feedback. Our analysis combines novel\nresults for contextual second-price auctions with a novel algorithmic approach\nbased on chaining. When the context space is Euclidean, our chaining approach\nis efficient and delivers an even better regret bound.\n", "versions": [{"version": "v1", "created": "Mon, 27 Feb 2017 10:01:36 GMT"}, {"version": "v2", "created": "Fri, 30 Jun 2017 08:19:49 GMT"}], "update_date": "2017-07-03", "authors_parsed": [["Cesa-Bianchi", "Nicol\u00f2", "", "SIERRA"], ["Gaillard", "Pierre", "", "SIERRA"], ["Gentile", "Claudio", "", "IMT"], ["Gerchinovitz", "S\u00e9bastien", "", "IMT"]]}, {"id": "1702.08546", "submitter": "Jonathan Weed", "authors": "Afonso S. Bandeira, Philippe Rigollet, Jonathan Weed", "title": "Optimal rates of estimation for multi-reference alignment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we establish optimal rates of adaptive estimation of a vector\nin the multi-reference alignment model, a problem with important applications\nin fields such as signal processing, image processing, and computer vision,\namong others. We describe how this model can be viewed as a multivariate\nGaussian mixture model under the constraint that the centers belong to the\norbit of a group. This enables us to derive matching upper and lower bounds\nthat feature an interesting dependence on the signal-to-noise ratio of the\nmodel. Both upper and lower bounds are articulated around a tight local control\nof Kullback-Leibler divergences that showcases the central role of moment\ntensors in this problem.\n", "versions": [{"version": "v1", "created": "Mon, 27 Feb 2017 21:52:17 GMT"}, {"version": "v2", "created": "Sun, 20 May 2018 16:34:48 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Bandeira", "Afonso S.", ""], ["Rigollet", "Philippe", ""], ["Weed", "Jonathan", ""]]}, {"id": "1702.08615", "submitter": "Peng Ding", "authors": "Peng Ding, Xinran Li, Luke W. Miratrix", "title": "Bridging Finite and Super Population Causal Inference", "comments": null, "journal-ref": "Journal of Causal Inference, 2017", "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are two general views in causal analysis of experimental data: the\nsuper population view that the units are an independent sample from some\nhypothetical infinite populations, and the finite population view that the\npotential outcomes of the experimental units are fixed and the randomness comes\nsolely from the physical randomization of the treatment assignment. These two\nviews differs conceptually and mathematically, resulting in different sampling\nvariances of the usual difference-in-means estimator of the average causal\neffect. Practically, however, these two views result in identical variance\nestimators. By recalling a variance decomposition and exploiting a\ncompleteness-type argument, we establish a connection between these two views\nin completely randomized experiments. This alternative formulation could serve\nas a template for bridging finite and super population causal inference in\nother scenarios.\n", "versions": [{"version": "v1", "created": "Tue, 28 Feb 2017 02:54:56 GMT"}], "update_date": "2017-03-01", "authors_parsed": [["Ding", "Peng", ""], ["Li", "Xinran", ""], ["Miratrix", "Luke W.", ""]]}, {"id": "1702.08787", "submitter": "Ester Mariucci", "authors": "C\\'eline Duval (MAP5), Ester Mariucci", "title": "Spectral-free estimation of L\\'evy densities in high-frequency regime", "comments": "33 pages. Several improvements made on the generality of the results", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We construct an estimator of the L\\'evy density of a pure jump L\\'evy\nprocess, possibly of infinite variation, from the discrete observation of one\ntrajectory at high frequency. The novelty of our procedure is that we directly\nestimate the L\\'evy density relying on a pathwise strategy, whereas existing\nprocedures rely on spectral techniques. By taking advantage of a compound\nPoisson approximation, we circumvent the use of spectral techniques and in\nparticular of the L\\'evy--Khintchine formula. A linear wavelet estimator is\nbuilt and its performance is studied in terms of $L_p$ loss functions, $p\\geq\n1$, over Besov balls. We recover classical nonparametric rates for finite\nvariation L\\'evy processes and for a large nonparametric class of symmetric\ninfinite variation L\\'evy processes. We show that the procedure is robust when\nthe estimation set gets close to the critical value 0 and also discuss its\nrobustness to the presence of a Brownian part.\n", "versions": [{"version": "v1", "created": "Tue, 28 Feb 2017 13:50:56 GMT"}, {"version": "v2", "created": "Thu, 18 May 2017 17:39:37 GMT"}, {"version": "v3", "created": "Thu, 24 Jan 2019 20:26:21 GMT"}, {"version": "v4", "created": "Fri, 3 Apr 2020 11:44:12 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Duval", "C\u00e9line", "", "MAP5"], ["Mariucci", "Ester", ""]]}, {"id": "1702.08895", "submitter": "Daniel McDonald", "authors": "Daniel J. McDonald", "title": "Minimax density estimation for growing dimension", "comments": "10 pages; accepted at The 20th International Conference on Artificial\n  Intelligence and Statistics (AISTATS)", "journal-ref": "Proceedings of the 20th International Conference on Artificial\n  Intelligence and Statistics, PMLR 54:194-203, 2017", "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents minimax rates for density estimation when the data\ndimension $d$ is allowed to grow with the number of observations $n$ rather\nthan remaining fixed as in previous analyses. We prove a non-asymptotic lower\nbound which gives the worst-case rate over standard classes of smooth\ndensities, and we show that kernel density estimators achieve this rate. We\nalso give oracle choices for the bandwidth and derive the fastest rate $d$ can\ngrow with $n$ to maintain estimation consistency.\n", "versions": [{"version": "v1", "created": "Tue, 28 Feb 2017 18:28:07 GMT"}], "update_date": "2017-08-16", "authors_parsed": [["McDonald", "Daniel J.", ""]]}, {"id": "1702.08900", "submitter": "Aleksey Polunchenko", "authors": "Aleksey S. Polunchenko", "title": "Asymptotic Exponentiality of the First Exit Time of the Shiryaev-Roberts\n  Diffusion with Constant Positive Drift", "comments": "14 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the first exit time of a Shiryaev-Roberts diffusion with constant\npositive drift from the interval $[0,A]$ where $A>0$. We show that the moment\ngenerating function (Laplace transform) of a suitably standardized version of\nthe first exit time converges to that of the unit-mean exponential distribution\nas $A\\to+\\infty$. The proof is explicit in that the moment generating function\nof the first exit time is first expressed analytically and in a closed form,\nand then the desired limit as $A\\to+\\infty$ is evaluated directly. The result\nis of importance in the area of quickest change-point detection, and its\ndiscrete-time counterpart has been previously established - although in a\ndifferent manner - by Pollak and Tartakovsky (2009).\n", "versions": [{"version": "v1", "created": "Tue, 28 Feb 2017 18:39:32 GMT"}, {"version": "v2", "created": "Mon, 6 Mar 2017 15:19:31 GMT"}], "update_date": "2017-03-07", "authors_parsed": [["Polunchenko", "Aleksey S.", ""]]}]