[{"id": "1612.00136", "submitter": "Tao Huang", "authors": "Lixia Hu, Tao Huang and Jinhong You", "title": "Estimation and Model Identification of Locally Stationary\n  Varying-Coefficient Additive Models", "comments": "36 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonparametric regression models with locally stationary covariates have\nreceived increasing interest in recent years. As a nice relief of \"curse of\ndimensionality\" induced by large dimension of covariates, additive regression\nmodel is commonly used. However, in locally stationary context, to catch the\ndynamic nature of regression function, we adopt a flexible varying-coefficient\nadditive model where the regression function has the form\n$\\alpha_{0}\\left(u\\right)+\\sum_{k=1}^{p}\\alpha_{k}\\left(u\\right)\\beta_{k}\\left(x_{k}\\right).$\nFor this model, we propose a three-step spline estimation method for each\nunivariate nonparametric function, and show its consistency and $L_{2}$ rate of\nconvergence. Furthermore, based upon the three-step estimators, we develop a\ntwo-stage penalty procedure to identify pure additive terms and\nvarying-coefficient terms in varying-coefficient additive model. As expected,\nwe demonstrate that the proposed identification procedure is consistent, and\nthe penalized estimators achieve the same $L_{2}$ rate of convergence as the\npolynomial spline estimators. Simulation studies are presented to illustrate\nthe finite sample performance of the proposed three-step spline estimation\nmethod and two-stage model selection procedure.\n", "versions": [{"version": "v1", "created": "Thu, 1 Dec 2016 04:13:05 GMT"}], "update_date": "2016-12-02", "authors_parsed": [["Hu", "Lixia", ""], ["Huang", "Tao", ""], ["You", "Jinhong", ""]]}, {"id": "1612.00196", "submitter": "Dragi Anevski", "authors": "Dragi Anevski and Vladimir M. Pastukhov", "title": "Estimating a monotone probability mass function with known flat regions", "comments": "16 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new estimator of a discrete monotone probability mass function\nwith known flat regions. We analyse its asymptotic properties and compare its\nperformance to the Grenander estimator and to the monotone rearrangement\nestimator.\n", "versions": [{"version": "v1", "created": "Thu, 1 Dec 2016 10:41:41 GMT"}, {"version": "v2", "created": "Sat, 3 Dec 2016 17:46:31 GMT"}, {"version": "v3", "created": "Tue, 6 Dec 2016 18:13:05 GMT"}, {"version": "v4", "created": "Sun, 11 Dec 2016 16:49:09 GMT"}], "update_date": "2016-12-13", "authors_parsed": [["Anevski", "Dragi", ""], ["Pastukhov", "Vladimir M.", ""]]}, {"id": "1612.00328", "submitter": "Holger Dette", "authors": "Holger Dette, Roman Guchenko, Viatcheslav Melas, Weng Kee Wong", "title": "Optimal discrimination designs for semi-parametric models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much of the work in the literature on optimal discrimination designs assumes\nthat the models of interest are fully specified, apart from unknown parameters\nin some models. Recent work allows errors in the models to be non-normally\ndistributed but still requires the specification of the mean structures. This\nresearch is motivated by the interesting work of Otsu (2008) to discriminate\namong semi-parametric models by generalizing the KL-optimality criterion\nproposed by L\\'opez-Fidalgo et al. (2007) and Tommasi and L\\'opez-Fidalgo\n(2010). In our work we provide further important insights in this interesting\noptimality criterion. In particular, we propose a practical strategy for\nfinding optimal discrimination designs among semi-parametric models that can\nalso be verified using an equivalence theorem. In addition, we study properties\nof such optimal designs and identify important cases where the proposed\nsemi-parametric optimal discrimination designs coincide with the celebrated T\n-optimal designs.\n", "versions": [{"version": "v1", "created": "Thu, 1 Dec 2016 16:07:18 GMT"}], "update_date": "2016-12-06", "authors_parsed": [["Dette", "Holger", ""], ["Guchenko", "Roman", ""], ["Melas", "Viatcheslav", ""], ["Wong", "Weng Kee", ""]]}, {"id": "1612.00571", "submitter": "Pradip Kundu", "authors": "Pradip Kundu, Nil Kamal Hazra and Asok K. Nanda", "title": "Reliability study of series and parallel systems of heterogeneous\n  component lifetimes under proportional odds model", "comments": "30 pages, 7 figures", "journal-ref": "Statistics 54(2) (2020) 375-401", "doi": "10.1080/02331888.2020.1722670", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate various stochastic orderings for series and\nparallel systems with independent and heterogeneous components having lifetimes\nfollowing the proportional odds model. We also investigate comparisons between\nsystem with heterogeneous components and that with homogeneous components. This\npaper also studies relative ageing orders for two systems in the framework of\ncomponents having lifetimes following the proportional odds model.\n", "versions": [{"version": "v1", "created": "Fri, 2 Dec 2016 05:26:20 GMT"}, {"version": "v2", "created": "Sat, 25 Jul 2020 06:56:52 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Kundu", "Pradip", ""], ["Hazra", "Nil Kamal", ""], ["Nanda", "Asok K.", ""]]}, {"id": "1612.00843", "submitter": "Matteo Smerlak", "authors": "Matteo Smerlak, Ahmed Youssef", "title": "Universal statistics of selected values", "comments": "6 pages, 4 figures", "journal-ref": null, "doi": "10.1209/0295-5075/117/50003", "report-no": null, "categories": "q-bio.PE cond-mat.stat-mech math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Selection, the tendency of some traits to become more frequent than others in\na population under the influence of some (natural or artificial) agency, is a\nkey component of Darwinian evolution and countless other natural and social\nphenomena. Yet a general theory of selection, analogous to the\nFisher-Tippett-Gnedenko theory of extreme events, is lacking. Here we introduce\na probabilistic definition of selection and show that selected values are\nattracted to a universal family of limiting distributions. The universality\nclasses and scaling exponents are determined by the tail thickness of the\nrandom variable under selection. Our results are supported by data from\nmolecular biology, agriculture and sport.\n", "versions": [{"version": "v1", "created": "Fri, 2 Dec 2016 15:21:47 GMT"}], "update_date": "2017-05-24", "authors_parsed": [["Smerlak", "Matteo", ""], ["Youssef", "Ahmed", ""]]}, {"id": "1612.00877", "submitter": "Antik Chakraborty", "authors": "Antik Chakraborty, Anirban Bhattacharya, Bani K. Mallick", "title": "Bayesian sparse multiple regression for simultaneous rank reduction and\n  variable selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a Bayesian methodology aimed at simultaneously estimating low-rank\nand row-sparse matrices in a high-dimensional multiple-response linear\nregression model. We consider a carefully devised shrinkage prior on the matrix\nof regression coefficients which obviates the need to specify a prior on the\nrank, and shrinks the regression matrix towards low-rank and row-sparse\nstructures. We provide theoretical support to the proposed methodology by\nproving minimax optimality of the posterior mean under the prediction risk in\nultra-high dimensional settings where the number of predictors can grow\nsub-exponentially relative to the sample size. A one-step post-processing\nscheme induced by group lasso penalties on the rows of the estimated\ncoefficient matrix is proposed for variable selection, with default choices of\ntuning parameters. We additionally provide an estimate of the rank using a\nnovel optimization function achieving dimension reduction in the covariate\nspace. We exhibit the performance of the proposed methodology in an extensive\nsimulation study and a real data example.\n", "versions": [{"version": "v1", "created": "Fri, 2 Dec 2016 22:16:37 GMT"}, {"version": "v2", "created": "Wed, 20 Sep 2017 06:09:45 GMT"}, {"version": "v3", "created": "Thu, 21 Sep 2017 05:32:55 GMT"}, {"version": "v4", "created": "Tue, 9 Apr 2019 03:29:36 GMT"}], "update_date": "2019-04-10", "authors_parsed": [["Chakraborty", "Antik", ""], ["Bhattacharya", "Anirban", ""], ["Mallick", "Bani K.", ""]]}, {"id": "1612.01046", "submitter": "Shankar C. Venkataramani", "authors": "Juan M. Restrepo and Shankar C. Venkataramani", "title": "Stochastic Longshore Current Dynamics", "comments": "19 Pages, 12 figures, this article supersedes arxiv:1307.0584", "journal-ref": "Advances in Water Resources, Vol. 98, December 2016, pp. 186-197", "doi": "10.1016/j.advwatres.2016.11.002", "report-no": null, "categories": "physics.data-an math.ST physics.ao-ph stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a stochastic parametrization, based on a `simple' deterministic\nmodel for the dynamics of steady longshore currents, that produces ensembles\nthat are statistically consistent with field observations of these currents.\nUnlike deterministic models, stochastic parameterization incorporates\nrandomness and hence can only match the observations in a statistical sense.\nUnlike statistical emulators, in which the model is tuned to the statistical\nstructure of the observation, stochastic parametrization are not directly tuned\nto match the statistics of the observations. Rather, stochastic\nparameterization combines deterministic, i.e physics based models with\nstochastic models for the \"missing physics\" to create hybrid models, that are\nstochastic, but yet can be used for making predictions, especially in the\ncontext of data assimilation. We introduce a novel measure of the utility of\nstochastic models of complex processes, that we call {\\em consistency of\nsensitivity}. We show, in the context of data assimilation, the stochastic\nparametrization of longshore currents achieves good results in capturing the\nstatistics of observation {\\em that were not used} in tuning the model.\n", "versions": [{"version": "v1", "created": "Sun, 4 Dec 2016 01:30:28 GMT"}], "update_date": "2016-12-06", "authors_parsed": [["Restrepo", "Juan M.", ""], ["Venkataramani", "Shankar C.", ""]]}, {"id": "1612.01129", "submitter": "Carlos Am\\'endola", "authors": "Carlos Am\\'endola, Kristian Ranestad and Bernd Sturmfels", "title": "Algebraic Identifiability of Gaussian Mixtures", "comments": "18 pages, to appear in International Mathematics Research Notices", "journal-ref": null, "doi": "10.1093/imrn/rnx090", "report-no": null, "categories": "math.AG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that all moment varieties of univariate Gaussian mixtures have the\nexpected dimension. Our approach rests on intersection theory and Terracini's\nclassification of defective surfaces. The analogous identifiability result is\nshown to be false for mixtures of Gaussians in dimension three and higher.\nTheir moments up to third order define projective varieties that are defective.\nOur geometric study suggests an extension of the Alexander-Hirschowitz Theorem\nfor Veronese varieties to the Gaussian setting.\n", "versions": [{"version": "v1", "created": "Sun, 4 Dec 2016 15:19:23 GMT"}, {"version": "v2", "created": "Tue, 4 Apr 2017 19:53:30 GMT"}], "update_date": "2019-04-19", "authors_parsed": [["Am\u00e9ndola", "Carlos", ""], ["Ranestad", "Kristian", ""], ["Sturmfels", "Bernd", ""]]}, {"id": "1612.01159", "submitter": "Andee Kaplan", "authors": "Andee Kaplan, Daniel Nordman, and Stephen Vardeman", "title": "On the instability and degeneracy of deep learning models", "comments": "28 pages, 1 figure", "journal-ref": null, "doi": "10.1093/imaiai/iaz022", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A probability model exhibits instability if small changes in a data outcome\nresult in large, and often unanticipated, changes in probability. This\ninstability is a property of the probability model, given by a distributional\nform and a given configuration of parameters. For correlated data structures\nfound in several application areas, there is increasing interest in identifying\nsuch sensitivity in model probability structure. We consider the problem of\nquantifying instability for general probability models defined on sequences of\nobservations, where each sequence of length N has a finite number of possible\nvalues that can be taken at each point. A sequence of probability models\nresults, indexed by N, and an associated parameter sequence, that accommodates\ndata of expanding dimension. Model instability is formally shown to occur when\na certain log-probability ratio under such models grows faster than N. In this\ncase, a one component change in the data sequence can shift probability by\norders of magnitude. Also, as instability becomes more extreme, the resulting\nprobability models are shown to tend to degeneracy, placing all their\nprobability on potentially small portions of the sample space. These results on\ninstability apply to large classes of models commonly used in random graphs,\nnetwork analysis, and machine learning contexts.\n", "versions": [{"version": "v1", "created": "Sun, 4 Dec 2016 18:17:24 GMT"}, {"version": "v2", "created": "Tue, 7 Nov 2017 13:47:31 GMT"}, {"version": "v3", "created": "Tue, 10 Sep 2019 20:26:36 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Kaplan", "Andee", ""], ["Nordman", "Daniel", ""], ["Vardeman", "Stephen", ""]]}, {"id": "1612.01210", "submitter": "Rajeshwari Majumdar", "authors": "Rajeshwari Majumdar and Suman Majumdar", "title": "On the regular conditional distribution of a multivariate Normal given a\n  linear transformation", "comments": "After this paper was uploaded in December 2016, we made substantial\n  progress on the problem of approximating the conditional distribution given a\n  continuously differentiable transformation. That has triggered a change in\n  the perspective we had about this paper. As such, we are replacing it with\n  arXiv:1710.09285", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the orthogonal projection operator onto the range of the adjoint\nof a linear operator T can be represented as UT, where U is an invertible\nlinear operator. Using this representation we obtain a decomposition of a\nmultivariate Normal random variable Y as the sum of a linear transformation of\nY that is independent of TY and an affine transformation of TY. We then use\nthis decomposition to prove that the regular conditional distribution of a\nmultivariate Normal random variable Y given a linear transformation TY is again\na multivariate Normal distribution. This result is equivalent to the well-known\nresult that given a k-dimensional component of a n-dimensional multivariate\nNormal random variable, where k < n, the regular conditional distribution of\nthe remaining (n - k)-dimensional component is a (n - k)-dimensional\nmultivariate Normal distribution.\n", "versions": [{"version": "v1", "created": "Mon, 5 Dec 2016 00:11:17 GMT"}, {"version": "v2", "created": "Thu, 26 Oct 2017 16:28:24 GMT"}], "update_date": "2017-10-27", "authors_parsed": [["Majumdar", "Rajeshwari", ""], ["Majumdar", "Suman", ""]]}, {"id": "1612.01464", "submitter": "Cambyse Rouze", "authors": "Cambyse Rouze, Nilanjana Datta", "title": "Finite blocklength and moderate deviation analysis of hypothesis testing\n  of correlated quantum states and application to classical-quantum channels\n  with memory", "comments": "47 pages, 1 figure. This paper supersedes our previous paper\n  (arXiv:1612.01464), in which hypothesis testing of sequences of correlated\n  states, and analysis of classical-quantum channels with memory, were not done", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Martingale concentration inequalities constitute a powerful mathematical tool\nin the analysis of problems in a wide variety of fields ranging from\nprobability and statistics to information theory and machine learning. Here we\napply techniques borrowed from this field to quantum hypothesis testing, which\nis the problem of discriminating quantum states belonging to two different\nsequences $\\{\\rho_n\\}_{n}$ and $\\{\\sigma_n\\}_n$. We obtain upper bounds on the\nfinite blocklength type II Stein- and Hoeffding errors, which, for i.i.d.\nstates, are in general tighter than the corresponding bounds obtained by\nAudenaert, Mosonyi and Verstraete [Journal of Mathematical Physics, 53(12),\n2012]. We also derive finite blocklength bounds and moderate deviation results\nfor pairs of sequences of correlated states satisfying a (non-homogeneous)\nfactorization property. Examples of such sequences include Gibbs states of spin\nchains with translation-invariant finite range interaction, as well as finitely\ncorrelated quantum states. We apply our results to find bounds on the capacity\nof a certain class of classical-quantum channels with memory, which satisfy a\nso-called channel factorization property- both in the finite blocklength and\nmoderate deviation regimes.\n", "versions": [{"version": "v1", "created": "Mon, 5 Dec 2016 18:35:56 GMT"}, {"version": "v2", "created": "Sun, 5 Mar 2017 18:04:42 GMT"}], "update_date": "2017-03-07", "authors_parsed": [["Rouze", "Cambyse", ""], ["Datta", "Nilanjana", ""]]}, {"id": "1612.01504", "submitter": "Shanshan Cao", "authors": "Shanshan Cao, Yao Xie", "title": "Dynamic change-point detection using similarity networks", "comments": "appeared in Asilomar Conference 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  From a sequence of similarity networks, with edges representing certain\nsimilarity measures between nodes, we are interested in detecting a\nchange-point which changes the statistical property of the networks. After the\nchange, a subset of anomalous nodes which compares dissimilarly with the normal\nnodes. We study a simple sequential change detection procedure based on\nnode-wise average similarity measures, and study its theoretical property.\nSimulation and real-data examples demonstrate such a simply stopping procedure\nhas reasonably good performance. We further discuss the faulty sensor isolation\n(estimating anomalous nodes) using community detection.\n", "versions": [{"version": "v1", "created": "Mon, 5 Dec 2016 20:27:29 GMT"}], "update_date": "2016-12-06", "authors_parsed": [["Cao", "Shanshan", ""], ["Xie", "Yao", ""]]}, {"id": "1612.01508", "submitter": "Arkadi Nemirovski", "authors": "Anatoli Juditsky and Arkadi Nemirovski", "title": "Estimating Linear and Quadratic forms via Indirect Observations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we further develop the approach, originating in [14\n(arXiv:1311.6765),20 (arXiv:1604.02576)], to \"computation-friendly\" hypothesis\ntesting and statistical estimation via Convex Programming. Specifically, we\nfocus on estimating a linear or quadratic form of an unknown \"signal,\" known to\nbelong to a given convex compact set, via noisy indirect observations of the\nsignal. Most of the existing theoretical results on the subject deal with\nprecisely stated statistical models and aim at designing statistical inferences\nand quantifying their performance in a closed analytic form. In contrast to\nthis descriptive (and highly instructive) traditional framework, the approach\nwe promote here can be qualified as operational -- the estimation routines and\ntheir risks are yielded by an efficient computation. All we know in advance is\nthat under favorable circumstances to be specified below, the risk of the\nresulting estimate, whether high or low, is provably near-optimal under the\ncircumstances. As a compensation for the lack of \"explanatory power,\" this\napproach is applicable to a much wider family of observation schemes than those\nwhere \"closed form descriptive analysis\" is possible.\n  The paper is a follow-up to our paper [20 (arXiv:1604.02576)] dealing with\nhypothesis testing, in what follows, we apply the machinery developed in this\nreference to estimating linear and quadratic forms.\n", "versions": [{"version": "v1", "created": "Mon, 5 Dec 2016 20:36:38 GMT"}, {"version": "v2", "created": "Wed, 22 Mar 2017 21:31:25 GMT"}, {"version": "v3", "created": "Thu, 15 Jun 2017 15:23:01 GMT"}, {"version": "v4", "created": "Thu, 12 Apr 2018 15:29:59 GMT"}, {"version": "v5", "created": "Fri, 13 Apr 2018 16:14:23 GMT"}], "update_date": "2018-04-16", "authors_parsed": [["Juditsky", "Anatoli", ""], ["Nemirovski", "Arkadi", ""]]}, {"id": "1612.01520", "submitter": "Holger Dette", "authors": "Fumiya Akashi, Holger Dette, Yan Liu", "title": "Change point detection in autoregressive models with no moment\n  assumptions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider the problem of detecting a change in the parameters\nof an autoregressive process, where the moments of the innovation process do\nnot necessarily exist. An empirical likelihood ratio test for the existence of\na change point is proposed and its asymptotic properties are studied. In\ncontrast to other work on change point tests using empirical likelihood, we do\nnot assume knowledge of the location of the change point. In particular, we\nprove that the maximizer of the empirical likelihood is a consistent estimator\nfor the parameters of the autoregressive model in the case of no change point\nand derive the limiting distribution of the corresponding test statistic under\nthe null hypothesis. We also establish consistency of the new test. A nice\nfeature of the method consists in the fact that the resulting test is\nasymptotically distribution free and does not require an estimate of the long\nrun variance. The asymptotic properties of the test are investigated by means\nof a small simulation study, which demonstrates good finite sample properties\nof the proposed method.\n", "versions": [{"version": "v1", "created": "Sun, 4 Dec 2016 11:35:55 GMT"}], "update_date": "2016-12-07", "authors_parsed": [["Akashi", "Fumiya", ""], ["Dette", "Holger", ""], ["Liu", "Yan", ""]]}, {"id": "1612.01668", "submitter": "Rajeshwari Majumdar", "authors": "Rajeshwari Majumdar and Suman Majumdar", "title": "Necessary and Sufficient Condition for Asymptotic Standard Normality of\n  the Two Sample Pivot", "comments": "The intended focus of this paper was the asymptotic distribution of\n  the two sample pivot. To obtain that distribution, we had to develop CLT\n  results that ended up constituting about two-thirds of the paper. This caused\n  some dilution of the intended focus and the CLT results got buried. To\n  enhance wider dissemination of the results, we are replacing it by\n  arXiv:1710.07275 and arXiv:1710.08051", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The asymptotic solution to the problem of comparing the means of two\nheteroscedastic populations, based on two random samples from the populations,\nhinges on the pivot underpinning the construction of the confidence interval\nand the test statistic being asymptotically standard Normal. The pivot is known\nto converge to the standard Normal distribution if the two samples are\nindependent and the ratio of the sample sizes converges to a finite positive\nnumber. We show, without any restriction on the asymptotic behavior of the\nratio of the sample sizes, that Cesaro convergence of the sequence of cross\nsample correlation coefficients to 0 is necessary and sufficient for the\naforesaid pivotal convergence. We also obtain, without any assumption on the\ncross sample dependence structure, that both iterated limits of the pivot are\nstandard Normal and if the joint distribution of the standardized sample means\nconverges to a spherically symmetric distribution, then that distribution must\nbe bivariate standard Normal.\n", "versions": [{"version": "v1", "created": "Tue, 6 Dec 2016 05:22:16 GMT"}, {"version": "v2", "created": "Sun, 18 Dec 2016 06:13:40 GMT"}, {"version": "v3", "created": "Sun, 6 Aug 2017 17:39:12 GMT"}, {"version": "v4", "created": "Fri, 22 Sep 2017 23:55:22 GMT"}, {"version": "v5", "created": "Wed, 25 Oct 2017 01:33:57 GMT"}], "update_date": "2017-10-26", "authors_parsed": [["Majumdar", "Rajeshwari", ""], ["Majumdar", "Suman", ""]]}, {"id": "1612.01882", "submitter": "Piero Veronese", "authors": "Piero Veronese and Eugenio Melilli", "title": "Fiducial, confidence and objective Bayesian posterior distributions for\n  a multidimensional parameter", "comments": "37 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a way to construct fiducial distributions for a multidimensional\nparameter using a step-by-step conditional procedure related to the inferential\nimportance of the components of the parameter. For discrete models, in which\nthe non-uniqueness of the fiducial distribution is well known, we propose to\nuse the geometric mean of the \"extreme cases\" and show its good behavior with\nrespect to the more traditional arithmetic mean. Connections with the\ngeneralized fiducial inference approach developed by Hannig and with confidence\ndistributions are also analyzed. The suggested procedure strongly simplifies\nwhen the statistical model belongs to a subclass of the natural exponential\nfamily, called conditionally reducible, which includes the multinomial and the\nnegative-multinomial models. Furthermore, because fiducial inference and\nobjective Bayesian analysis are both attempts to derive distributions for an\nunknown parameter without any prior information, it is natural to discuss their\nrelationships. In particular, the reference posteriors, which also depend on\nthe importance ordering of the parameters are the natural terms of comparison.\nWe show that fiducial and reference posterior distributions coincide in the\nlocation-scale models, and we characterize the conditionally reducible natural\nexponential families for which this happens. The discussion of some classical\nexamples closes the paper.\n", "versions": [{"version": "v1", "created": "Tue, 6 Dec 2016 15:56:17 GMT"}], "update_date": "2016-12-07", "authors_parsed": [["Veronese", "Piero", ""], ["Melilli", "Eugenio", ""]]}, {"id": "1612.01934", "submitter": "Vladimir Pastukhov", "authors": "Dragi Anevski, Richard Hall-Wilton, Kalliopi Kanaki, Vladimir\n  Pastukhov", "title": "A stochastic process approach to multilayer neutron detectors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The sparsity of the isotope Helium-3, ongoing since 2009, has initiated a new\ngeneration of neutron detectors. One particularly promising development line\nfor detectors is the multilayer gaseous detector. In this paper, a stochastic\nprocess approach is used to determine the neutron's energy from the additional\ndata afforded by the multilayer nature of these novel detectors.\n  The data from a multi-layer detector consists of counts of the number of\nabsorbed neutrons along the sequence of the detector's layers, in which the\nneutron absorption probability is unknown. We study the Maximum Likelihood\nestimator for the intensity and absorption probability, show its consistency\nand asymptotic normality, as the experiment time (or the number of incoming\nneutrons) goes to infinity. We combine these results with known results on the\nrelation between the absorption probability and the wavelength to derive an\nestimator of the wavelength and to show consistency and asymptotic normality\nfor the estimator.\n", "versions": [{"version": "v1", "created": "Tue, 6 Dec 2016 18:12:55 GMT"}, {"version": "v2", "created": "Sat, 14 Oct 2017 14:06:31 GMT"}, {"version": "v3", "created": "Sat, 9 Jun 2018 21:29:27 GMT"}, {"version": "v4", "created": "Wed, 7 Nov 2018 22:57:54 GMT"}], "update_date": "2018-11-09", "authors_parsed": [["Anevski", "Dragi", ""], ["Hall-Wilton", "Richard", ""], ["Kanaki", "Kalliopi", ""], ["Pastukhov", "Vladimir", ""]]}, {"id": "1612.02024", "submitter": "Marinho Bertanha", "authors": "Marinho Bertanha and Marcelo J. Moreira", "title": "Impossible Inference in Econometrics: Theory and Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST q-fin.EC stat.AP stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies models in which hypothesis tests have trivial power, that\nis, power smaller than size. This testing impossibility, or impossibility type\nA, arises when any alternative is not distinguishable from the null. We also\nstudy settings in which it is impossible to have almost surely bounded\nconfidence sets for a parameter of interest. This second type of impossibility\n(type B) occurs under a condition weaker than the condition for type A\nimpossibility: the parameter of interest must be nearly unidentified. Our\ntheoretical framework connects many existing publications on impossible\ninference that rely on different notions of topologies to show models are not\ndistinguishable or nearly unidentified. We also derive both types of\nimpossibility using the weak topology induced by convergence in distribution.\nImpossibility in the weak topology is often easier to prove, it is applicable\nfor many widely-used tests, and it is useful for robust hypothesis testing. We\nconclude by demonstrating impossible inference in multiple economic\napplications of models with discontinuity and time-series models.\n", "versions": [{"version": "v1", "created": "Tue, 6 Dec 2016 21:15:33 GMT"}, {"version": "v2", "created": "Fri, 9 Dec 2016 03:35:34 GMT"}, {"version": "v3", "created": "Wed, 21 Feb 2018 16:42:39 GMT"}, {"version": "v4", "created": "Fri, 16 Nov 2018 15:10:42 GMT"}, {"version": "v5", "created": "Mon, 17 Feb 2020 21:38:24 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Bertanha", "Marinho", ""], ["Moreira", "Marcelo J.", ""]]}, {"id": "1612.02099", "submitter": "Yu Lu", "authors": "Yu Lu and Harrison H. Zhou", "title": "Statistical and Computational Guarantees of Lloyd's Algorithm and its\n  Variants", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering is a fundamental problem in statistics and machine learning.\nLloyd's algorithm, proposed in 1957, is still possibly the most widely used\nclustering algorithm in practice due to its simplicity and empirical\nperformance. However, there has been little theoretical investigation on the\nstatistical and computational guarantees of Lloyd's algorithm. This paper is an\nattempt to bridge this gap between practice and theory. We investigate the\nperformance of Lloyd's algorithm on clustering sub-Gaussian mixtures. Under an\nappropriate initialization for labels or centers, we show that Lloyd's\nalgorithm converges to an exponentially small clustering error after an order\nof $\\log n$ iterations, where $n$ is the sample size. The error rate is shown\nto be minimax optimal. For the two-mixture case, we only require the\ninitializer to be slightly better than random guess.\n  In addition, we extend the Lloyd's algorithm and its analysis to community\ndetection and crowdsourcing, two problems that have received a lot of attention\nrecently in statistics and machine learning. Two variants of Lloyd's algorithm\nare proposed respectively for community detection and crowdsourcing. On the\ntheoretical side, we provide statistical and computational guarantees of the\ntwo algorithms, and the results improve upon some previous signal-to-noise\nratio conditions in literature for both problems. Experimental results on\nsimulated and real data sets demonstrate competitive performance of our\nalgorithms to the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Wed, 7 Dec 2016 02:35:54 GMT"}], "update_date": "2016-12-08", "authors_parsed": [["Lu", "Yu", ""], ["Zhou", "Harrison H.", ""]]}, {"id": "1612.02315", "submitter": "Adam Kapelner", "authors": "Abba M. Krieger, David Azriel and Adam Kapelner", "title": "Nearly Random Designs with Greatly Improved Balance", "comments": "21 pages, 3 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new experimental design procedure that divides a set of\nexperimental units into two groups so that the two groups are balanced on a\nprespecified set of covariates and being almost as random as complete\nrandomization. Under complete randomization, the difference in covariate\nbalance as measured by the standardized average between treatment and control\nwill be $O_p(n^{-1/2})$. If the sample size is not too large this may be\nmaterial. In this article, we present an algorithm which greedily switches\nassignment pairs. Resultant designs produce balance of the much lower order\n$O_p(n^{-3})$ for one covariate. However, our algorithm creates assignments\nwhich are, strictly speaking, non-random. We introduce two metrics which\ncapture departures from randomization: one in the style of entropy and one in\nthe style of standard error and demonstrate our assignments are nearly as\nrandom as complete randomization in terms of both measures. The results are\nextended to more than one covariate, simulations are provided to illustrate the\nresults and statistical inference under our design is discussed. We provide an\nopen source R package available on CRAN called GreedyExperimentalDesign which\ngenerates designs according to our algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 7 Dec 2016 16:25:29 GMT"}], "update_date": "2016-12-08", "authors_parsed": [["Krieger", "Abba M.", ""], ["Azriel", "David", ""], ["Kapelner", "Adam", ""]]}, {"id": "1612.02391", "submitter": "David Azriel", "authors": "David Azriel, Lawrence D. Brown, Michael Sklar, Richard Berk, Andreas\n  Buja and Linda Zhao", "title": "Semi-Supervised linear regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study a regression problem where for some part of the data we observe both\nthe label variable ($Y$) and the predictors (${\\bf X}$), while for other part\nof the data only the predictors are given. Such a problem arises, for example,\nwhen observations of the label variable are costly and may require a skilled\nhuman agent. When the conditional expectation $E[Y | {\\bf X}]$ is not exactly\nlinear, one can consider the best linear approximation to the conditional\nexpectation, which can be estimated consistently by the least squares estimates\n(LSE). The latter depends only on the labeled data. We suggest improved\nalternative estimates to the LSE that use also the unlabeled data. Our\nestimation method can be easily implemented and has simply described asymptotic\nproperties.The new estimates asymptotically dominate the usual standard\nprocedures under certain non-linearity condition of $E[Y | {\\bf X}]$;\notherwise, they are asymptotically equivalent.The performance of the new\nestimator for small sample size is investigated in an extensive simulation\nstudy. A real data example of inferring homeless population is used to\nillustrate the new methodology.\n", "versions": [{"version": "v1", "created": "Wed, 7 Dec 2016 19:52:55 GMT"}, {"version": "v2", "created": "Sun, 16 Sep 2018 07:16:20 GMT"}, {"version": "v3", "created": "Sun, 4 Apr 2021 11:23:40 GMT"}, {"version": "v4", "created": "Tue, 13 Apr 2021 07:40:58 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Azriel", "David", ""], ["Brown", "Lawrence D.", ""], ["Sklar", "Michael", ""], ["Berk", "Richard", ""], ["Buja", "Andreas", ""], ["Zhao", "Linda", ""]]}, {"id": "1612.02536", "submitter": "Anastasia Papavasiliou", "authors": "Anastasia Papavasiliou and Kasia B. Taylor", "title": "Approximate Likelihood Construction for Rough Differential Equations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper is split in two parts: in the first part, we construct the exact\nlikelihood for a discretely observed rough differential equation, driven by a\npiecewise linear path. In the second part, we use this likelihood in order to\nconstruct an approximation of the likelihood for a discretely observed\ndifferential equation driven by a general class of rough paths. Finally, we\nstudy the behaviour of the approximate likelihood when the sampling frequency\ntends to infinity.\n", "versions": [{"version": "v1", "created": "Thu, 8 Dec 2016 05:58:24 GMT"}, {"version": "v2", "created": "Mon, 9 Jul 2018 10:00:03 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Papavasiliou", "Anastasia", ""], ["Taylor", "Kasia B.", ""]]}, {"id": "1612.02542", "submitter": "Vincent Tan", "authors": "Masahito Hayashi and Vincent Y. F. Tan", "title": "Minimum Rates of Approximate Sufficient Statistics", "comments": "To appear in the IEEE Transactions on Information Theory", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a sufficient statistic for a parametric family of distributions, one\ncan estimate the parameter without access to the data. However, the memory or\ncode size for storing the sufficient statistic may nonetheless still be\nprohibitive. Indeed, for $n$ independent samples drawn from a $k$-nomial\ndistribution with $d=k-1$ degrees of freedom, the length of the code scales as\n$d\\log n+O(1)$. In many applications, we may not have a useful notion of\nsufficient statistics (e.g., when the parametric family is not an exponential\nfamily) and we also may not need to reconstruct the generating distribution\nexactly. By adopting a Shannon-theoretic approach in which we allow a small\nerror in estimating the generating distribution, we construct various {\\em\napproximate sufficient statistics} and show that the code length can be reduced\nto $\\frac{d}{2}\\log n+O(1)$. We consider errors measured according to the\nrelative entropy and variational distance criteria. For the code constructions,\nwe leverage Rissanen's minimum description length principle, which yields a\nnon-vanishing error measured according to the relative entropy. For the\nconverse parts, we use Clarke and Barron's formula for the relative entropy of\na parametrized distribution and the corresponding mixture distribution.\nHowever, this method only yields a weak converse for the variational distance.\nWe develop new techniques to achieve vanishing errors and we also prove strong\nconverses. The latter means that even if the code is allowed to have a\nnon-vanishing error, its length must still be at least $\\frac{d}{2}\\log n$.\n", "versions": [{"version": "v1", "created": "Thu, 8 Dec 2016 06:26:26 GMT"}, {"version": "v2", "created": "Thu, 16 Nov 2017 14:48:51 GMT"}], "update_date": "2017-11-17", "authors_parsed": [["Hayashi", "Masahito", ""], ["Tan", "Vincent Y. F.", ""]]}, {"id": "1612.02794", "submitter": "Piotr Kokoszka Piotr Kokoszka", "authors": "Tomasz Gorecki and Lajos Horvath and Piotr Kokoszka", "title": "Change point detection in heteroscedastic time series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many time series exhibit changes both in level and in variability. Generally,\nit is more important to detect a change in the level, and changing or smoothly\nevolving variability can confound existing tests. This paper develops a\nframework for testing for shifts in the level of a series which accommodates\nthe possibility of changing variability. The resulting tests are robust both to\nheteroskedasticity and serial dependence. They rely on a new functional central\nlimit theorem for dependent random variables whose variance can change or trend\nin a substantial way. This new result is of independent interest as it can be\napplied in many inferential contexts applicable to time series. Its application\nto change point tests relies on a new approach which utilizes\nKarhunen--Lo{\\'e}ve expansions of the limit Gaussian processes. After\npresenting the theory in the most commonly encountered setting of the detection\nof a change point in the mean, we show how it can be extended to linear and\nnonlinear regression. Finite sample performance is examined by means of a\nsimulation study and an application to yields on US treasury bonds.\n", "versions": [{"version": "v1", "created": "Thu, 8 Dec 2016 20:17:03 GMT"}], "update_date": "2016-12-09", "authors_parsed": [["Gorecki", "Tomasz", ""], ["Horvath", "Lajos", ""], ["Kokoszka", "Piotr", ""]]}, {"id": "1612.02989", "submitter": "Lassi Roininen", "authors": "Lassi Roininen, Mark Girolami, Sari Lasanen and Markku Markkanen", "title": "Hyperpriors for Mat\\'ern fields with applications in Bayesian inversion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce non-stationary Mat\\'ern field priors with stochastic partial\ndifferential equations, and construct correlation length-scaling with\nhyperpriors. We model both the hyperprior and the Mat\\'ern prior as\ncontinuous-parameter random fields. As hypermodels, we use Cauchy and Gaussian\nrandom fields, which we map suitably to a desired correlation length-scaling\nrange. For computations, we discretise the models with finite difference\nmethods. We consider the convergence of the discretised prior and posterior to\nthe discretisation limit. We apply the developed methodology to certain\ninterpolation and numerical differentiation problems, and show numerically that\nwe can make Bayesian inversion which promotes competing constraints of\nsmoothness and edge-preservation. For computing the conditional mean estimator\nof the posterior distribution, we use a combination of Gibbs and\nMetropolis-within-Gibbs sampling algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 9 Dec 2016 12:01:36 GMT"}], "update_date": "2016-12-12", "authors_parsed": [["Roininen", "Lassi", ""], ["Girolami", "Mark", ""], ["Lasanen", "Sari", ""], ["Markkanen", "Markku", ""]]}, {"id": "1612.03147", "submitter": "Gautam Kamath", "authors": "Constantinos Daskalakis, Nishanth Dikkala, Gautam Kamath", "title": "Testing Ising Models", "comments": "Appeared SODA 2018. Final version to appear in IEEE Transactions on\n  Information Theory", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.IT cs.LG math.IT math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given samples from an unknown multivariate distribution $p$, is it possible\nto distinguish whether $p$ is the product of its marginals versus $p$ being far\nfrom every product distribution? Similarly, is it possible to distinguish\nwhether $p$ equals a given distribution $q$ versus $p$ and $q$ being far from\neach other? These problems of testing independence and goodness-of-fit have\nreceived enormous attention in statistics, information theory, and theoretical\ncomputer science, with sample-optimal algorithms known in several interesting\nregimes of parameters. Unfortunately, it has also been understood that these\nproblems become intractable in large dimensions, necessitating exponential\nsample complexity.\n  Motivated by the exponential lower bounds for general distributions as well\nas the ubiquity of Markov Random Fields (MRFs) in the modeling of\nhigh-dimensional distributions, we initiate the study of distribution testing\non structured multivariate distributions, and in particular the prototypical\nexample of MRFs: the Ising Model. We demonstrate that, in this structured\nsetting, we can avoid the curse of dimensionality, obtaining sample and time\nefficient testers for independence and goodness-of-fit. One of the key\ntechnical challenges we face along the way is bounding the variance of\nfunctions of the Ising model.\n", "versions": [{"version": "v1", "created": "Fri, 9 Dec 2016 20:04:56 GMT"}, {"version": "v2", "created": "Thu, 15 Dec 2016 05:34:14 GMT"}, {"version": "v3", "created": "Fri, 7 Apr 2017 15:06:28 GMT"}, {"version": "v4", "created": "Mon, 30 Oct 2017 20:34:46 GMT"}, {"version": "v5", "created": "Tue, 5 Feb 2019 16:33:20 GMT"}, {"version": "v6", "created": "Wed, 10 Jul 2019 22:02:20 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Daskalakis", "Constantinos", ""], ["Dikkala", "Nishanth", ""], ["Kamath", "Gautam", ""]]}, {"id": "1612.03156", "submitter": "Cl\\'ement Canonne", "authors": "Clement Canonne, Ilias Diakonikolas, Daniel Kane, Alistair Stewart", "title": "Testing Bayesian Networks", "comments": "To appear in IEEE Transactions on Information Theory", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.IT cs.LG math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work initiates a systematic investigation of testing high-dimensional\nstructured distributions by focusing on testing Bayesian networks -- the\nprototypical family of directed graphical models. A Bayesian network is defined\nby a directed acyclic graph, where we associate a random variable with each\nnode. The value at any particular node is conditionally independent of all the\nother non-descendant nodes once its parents are fixed. Specifically, we study\nthe properties of identity testing and closeness testing of Bayesian networks.\nOur main contribution is the first non-trivial efficient testing algorithms for\nthese problems and corresponding information-theoretic lower bounds. For a wide\nrange of parameter settings, our testing algorithms have sample complexity\nsublinear in the dimension and are sample-optimal, up to constant factors.\n", "versions": [{"version": "v1", "created": "Fri, 9 Dec 2016 20:34:40 GMT"}, {"version": "v2", "created": "Sat, 25 Jan 2020 02:49:37 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Canonne", "Clement", ""], ["Diakonikolas", "Ilias", ""], ["Kane", "Daniel", ""], ["Stewart", "Alistair", ""]]}, {"id": "1612.03164", "submitter": "Constantinos Daskalakis", "authors": "Constantinos Daskalakis, Qinxuan Pan", "title": "Square Hellinger Subadditivity for Bayesian Networks and its\n  Applications to Identity Testing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT math.PR math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the square Hellinger distance between two Bayesian networks on\nthe same directed graph, $G$, is subadditive with respect to the neighborhoods\nof $G$. Namely, if $P$ and $Q$ are the probability distributions defined by two\nBayesian networks on the same DAG, our inequality states that the square\nHellinger distance, $H^2(P,Q)$, between $P$ and $Q$ is upper bounded by the\nsum, $\\sum_v H^2(P_{\\{v\\} \\cup \\Pi_v}, Q_{\\{v\\} \\cup \\Pi_v})$, of the square\nHellinger distances between the marginals of $P$ and $Q$ on every node $v$ and\nits parents $\\Pi_v$ in the DAG. Importantly, our bound does not involve the\nconditionals but the marginals of $P$ and $Q$. We derive a similar inequality\nfor more general Markov Random Fields.\n  As an application of our inequality, we show that distinguishing whether two\nBayesian networks $P$ and $Q$ on the same (but potentially unknown) DAG satisfy\n$P=Q$ vs $d_{\\rm TV}(P,Q)>\\epsilon$ can be performed from\n$\\tilde{O}(|\\Sigma|^{3/4(d+1)} \\cdot n/\\epsilon^2)$ samples, where $d$ is the\nmaximum in-degree of the DAG and $\\Sigma$ the domain of each variable of the\nBayesian networks. If $P$ and $Q$ are defined on potentially different and\npotentially unknown trees, the sample complexity becomes\n$\\tilde{O}(|\\Sigma|^{4.5} n/\\epsilon^2)$, whose dependence on $n, \\epsilon$ is\noptimal up to logarithmic factors. Lastly, if $P$ and $Q$ are product\ndistributions over $\\{0,1\\}^n$ and $Q$ is known, the sample complexity becomes\n$O(\\sqrt{n}/\\epsilon^2)$, which is optimal up to constant factors.\n", "versions": [{"version": "v1", "created": "Fri, 9 Dec 2016 20:58:12 GMT"}], "update_date": "2016-12-12", "authors_parsed": [["Daskalakis", "Constantinos", ""], ["Pan", "Qinxuan", ""]]}, {"id": "1612.03180", "submitter": "Esra Russell Dr.", "authors": "Esra Russell and Jean-Renaud Pycke (NYU Abu Dhabi)", "title": "Lognormal Distribution of Cosmic Voids in Simulations and Mocks", "comments": "11 pages, 6 figures, accepted to ApJ main journal", "journal-ref": null, "doi": "10.3847/1538-4357/835/1/69", "report-no": null, "categories": "astro-ph.CO math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Following up on previous studies, we here complete a full analysis of the\nvoid size distributions of the Cosmic Void Catalog (CVC) based on three\ndifferent simulation and mock catalogs; dark matter, haloes and galaxies. Based\non this analysis, we attempt to answer two questions: Is a 3-parameter\nlog-normal distribution a good candidate to satisfy the void size distributions\nobtained from different types of environments? Is there a direct relation\nbetween the shape parameters of the void size distribution and the\nenvironmental effects? In an attempt to answer these questions, we here find\nthat all void size distributions of these data samples satisfy the 3-parameter\nlog-normal distribution whether the environment is dominated by dark matter,\nhaloes or galaxies. In addition, the shape parameters of the 3-parameter\nlog-normal void size distribution seem highly affected by environment,\nparticularly existing substructures. Therefore, we show two quantitative\nrelations given by linear equations between the skewness and the maximum tree\ndepth, and variance of the void size distribution and the maximum tree depth\ndirectly from the simulated data. In addition to this, we find that the\npercentage of the voids with nonzero central density in the data sets has a\ncritical importance. If the number of voids with nonzero central densities\nreaches greater and or equal to 3.84 percentage in a simulation/mock sample,\nthen a second population is observed in the void size distributions. This\nsecond population emerges as a second peak in the log-normal void size\ndistribution at larger radius.\n", "versions": [{"version": "v1", "created": "Fri, 9 Dec 2016 21:00:10 GMT"}], "update_date": "2017-01-25", "authors_parsed": [["Russell", "Esra", "", "NYU Abu Dhabi"], ["Pycke", "Jean-Renaud", "", "NYU Abu Dhabi"]]}, {"id": "1612.03233", "submitter": "Amir Sepehri", "authors": "Amir Sepehri", "title": "New Tests of Uniformity on the Compact Classical Groups as Diagnostics\n  for Weak-star Mixing of Markov Chains", "comments": "Accepted for publication in Bernoulli", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.NA math.RT stat.CO stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces two new families of non-parametric tests of\ngoodness-of-fit on the compact classical groups. One of them is a family of\ntests for the eigenvalue distribution induced by the uniform distribution,\nwhich is consistent against all fixed alternatives. The other is a family of\ntests for the uniform distribution on the entire group, which is again\nconsistent against all fixed alternatives. We find the asymptotic distribution\nunder the null and general alternatives. The tests are proved to be\nasymptotically admissible. Local power is derived and the global properties of\nthe power function against local alternatives are explored.\n  The new tests are validated on two random walks for which the mixing-time is\nstudied in the literature. The new tests, and several others, are applied to\nthe Markov chain sampler proposed by \\cite{jones2011randomized}, providing\nstrong evidence supporting the claim that the sampler mixes quickly.\n", "versions": [{"version": "v1", "created": "Sat, 10 Dec 2016 01:07:20 GMT"}, {"version": "v2", "created": "Sun, 25 Feb 2018 07:50:15 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Sepehri", "Amir", ""]]}, {"id": "1612.03257", "submitter": "Andreas Buja", "authors": "Andreas Buja, Lawrence Brown, Arun Kumar Kuchibhotla, Richard Berk, Ed\n  George, Linda Zhao", "title": "Models as Approximations II: A Model-Free Theory of Parametric\n  Regression", "comments": "Submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a model-free theory of general types of parametric regression for\niid observations. The theory replaces the parameters of parametric models with\nstatistical functionals, to be called \"regression functionals'', defined on\nlarge non-parametric classes of joint $\\xy$ distributions, without assuming a\ncorrect model. Parametric models are reduced to heuristics to suggest plausible\nobjective functions. An example of a regression functional is the vector of\nslopes of linear equations fitted by OLS to largely arbitrary $\\xy$\ndistributions, without assuming a linear model (see Part~I). More generally,\nregression functionals can be defined by minimizing objective functions or\nsolving estimating equations at joint $\\xy$ distributions. In this framework it\nis possible to achieve the following: (1)~define a notion of well-specification\nfor regression functionals that replaces the notion of correct specification of\nmodels, (2)~propose a well-specification diagnostic for regression functionals\nbased on reweighting distributions and data, (3)~decompose sampling variability\nof regression functionals into two sources, one due to the conditional response\ndistribution\n  and another due to the regressor distribution interacting with\nmisspecification, both of order $N^{-1/2}$, (4)~exhibit plug-in/sandwich\nestimators of standard error as limit cases of $\\xy$ bootstrap estimators, and\n(5)~provide theoretical heuristics to indicate that $\\xy$ bootstrap standard\nerrors may generally be more stable than sandwich estimators.\n", "versions": [{"version": "v1", "created": "Sat, 10 Dec 2016 05:53:13 GMT"}, {"version": "v2", "created": "Sat, 6 Jul 2019 19:34:22 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Buja", "Andreas", ""], ["Brown", "Lawrence", ""], ["Kuchibhotla", "Arun Kumar", ""], ["Berk", "Richard", ""], ["George", "Ed", ""], ["Zhao", "Linda", ""]]}, {"id": "1612.03341", "submitter": "Alfredo Alegr\\'ia", "authors": "Alfredo Alegr\\'ia, Sandra Caro, Moreno Bevilacqua, Emilio Porcu and\n  Jorge Clarke", "title": "Estimating covariance functions of multivariate skew-Gaussian random\n  fields on the sphere", "comments": null, "journal-ref": null, "doi": "10.1016/j.spasta.2017.07.009", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers a multivariate spatial random field, with each component\nhaving univariate marginal distributions of the skew-Gaussian type. We assume\nthat the field is defined spatially on the unit sphere embedded in\n$\\mathbb{R}^3$, allowing for modeling data available over large portions of\nplanet Earth. This model admits explicit expressions for the marginal and cross\ncovariances. However, the $n$-dimensional distributions of the field are\ndifficult to evaluate, because it requires the sum of $2^n$ terms involving the\ncumulative and probability density functions of a $n$-dimensional Gaussian\ndistribution. Since in this case inference based on the full likelihood is\ncomputationally unfeasible, we propose a composite likelihood approach based on\npairs of spatial observations. This last being possible thanks to the fact that\nwe have a closed form expression for the bivariate distribution. We illustrate\nthe effectiveness of the method through simulation experiments and the analysis\nof a real data set of minimum and maximum temperatures.\n", "versions": [{"version": "v1", "created": "Sat, 10 Dec 2016 20:54:51 GMT"}, {"version": "v2", "created": "Wed, 14 Jun 2017 16:54:41 GMT"}, {"version": "v3", "created": "Wed, 26 Jul 2017 04:49:33 GMT"}], "update_date": "2017-10-05", "authors_parsed": [["Alegr\u00eda", "Alfredo", ""], ["Caro", "Sandra", ""], ["Bevilacqua", "Moreno", ""], ["Porcu", "Emilio", ""], ["Clarke", "Jorge", ""]]}, {"id": "1612.03375", "submitter": "Pengkun Yang", "authors": "Yihong Wu, Pengkun Yang", "title": "Sample complexity of the distinct elements problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the distinct elements problem, where the goal is to estimate the\nnumber of distinct colors in an urn containing $ k $ balls based on $n$ samples\ndrawn with replacements. Based on discrete polynomial approximation and\ninterpolation, we propose an estimator with additive error guarantee that\nachieves the optimal sample complexity within $O(\\log\\log k)$ factors, and in\nfact within constant factors for most cases. The estimator can be computed in\n$O(n)$ time for an accurate estimation. The result also applies to sampling\nwithout replacement provided the sample size is a vanishing fraction of the urn\nsize.\n  One of the key auxiliary results is a sharp bound on the minimum singular\nvalues of a real rectangular Vandermonde matrix, which might be of independent\ninterest.\n", "versions": [{"version": "v1", "created": "Sun, 11 Dec 2016 06:17:40 GMT"}, {"version": "v2", "created": "Mon, 15 Jan 2018 03:03:03 GMT"}], "update_date": "2018-01-16", "authors_parsed": [["Wu", "Yihong", ""], ["Yang", "Pengkun", ""]]}, {"id": "1612.03599", "submitter": "Yuval Peres", "authors": "Fedor Nazarov and Yuval Peres", "title": "Trace reconstruction with $\\exp( O( n^{1/3} ) )$ samples", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the trace reconstruction problem, an unknown bit string $x \\in \\{0,1\\}^n$\nis observed through the deletion channel, which deletes each bit of $x$ with\nsome constant probability $q$, yielding a contracted string $\\widetilde{x}$.\nHow many independent copies of $\\widetilde{x}$ are needed to reconstruct $x$\nwith high probability? Prior to this work, the best upper bound, due to\nHolenstein, Mitzenmacher, Panigrahy, and Wieder (2008), was\n$\\exp(\\widetilde{O}(n^{1/2}))$. We improve this bound to $\\exp(O(n^{1/3}))$\nusing statistics of individual bits in the output and show that this bound is\nsharp in the restricted model where this is the only information used. Our\nmethod, that uses elementary complex analysis, can also handle insertions.\n", "versions": [{"version": "v1", "created": "Mon, 12 Dec 2016 10:30:13 GMT"}], "update_date": "2016-12-13", "authors_parsed": [["Nazarov", "Fedor", ""], ["Peres", "Yuval", ""]]}, {"id": "1612.03689", "submitter": "Olivier Roustant", "authors": "Olivier Roustant (FAYOL-EMSE, GdR MASCOT-NUM), Franck Barthe (IMT),\n  Bertrand Iooss (GdR MASCOT-NUM, IMT)", "title": "Poincar\\'e inequalities on intervals -- application to sensitivity\n  analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The development of global sensitivity analysis of numerical model outputs has\nrecently raised new issues on 1-dimensional Poincar\\'e inequalities. Typically\ntwo kind of sensitivity indices are linked by a Poincar\\'e type inequality,\nwhich provide upper bounds of the most interpretable index by using the other\none, cheaper to compute. This allows performing a low-cost screening of\nunessential variables. The efficiency of this screening then highly depends on\nthe accuracy of the upper bounds in Poincar\\'e inequalities. The novelty in the\nquestions concern the wide range of probability distributions involved, which\nare often truncated on intervals. After providing an overview of the existing\nknowledge and techniques, we add some theory about Poincar\\'e constants on\nintervals, with improvements for symmetric intervals. Then we exploit the\nspectral interpretation for computing exact value of Poincar\\'e constants of\nany admissible distribution on a given interval. We give semi-analytical\nresults for some frequent distributions (truncated exponential, triangular,\ntruncated normal), and present a numerical method in the general case. Finally,\nan application is made to a hydrological problem, showing the benefits of the\nnew results in Poincar\\'e inequalities to sensitivity analysis.\n", "versions": [{"version": "v1", "created": "Mon, 12 Dec 2016 14:08:54 GMT"}], "update_date": "2016-12-13", "authors_parsed": [["Roustant", "Olivier", "", "FAYOL-EMSE, GdR MASCOT-NUM"], ["Barthe", "Franck", "", "IMT"], ["Iooss", "Bertrand", "", "GdR MASCOT-NUM, IMT"]]}, {"id": "1612.03880", "submitter": "Piyush Srivastava", "authors": "Quentin Berthet, Philippe Rigollet, Piyush Srivastava", "title": "Exact recovery in the Ising blockmodel", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.DS stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem associated to recovering the block structure of an\nIsing model given independent observations on the binary hypercube. This new\nmodel, called the Ising blockmodel, is a perturbation of the mean field\napproximation of the Ising model known as the Curie-Weiss model: the sites are\npartitioned into two blocks of equal size and the interaction between those of\nthe same block is stronger than across blocks, to account for more order within\neach block. We study probabilistic, statistical and computational aspects of\nthis model in the high-dimensional case when the number of sites may be much\nlarger than the sample size.\n", "versions": [{"version": "v1", "created": "Mon, 12 Dec 2016 20:15:54 GMT"}, {"version": "v2", "created": "Thu, 2 Feb 2017 18:28:36 GMT"}], "update_date": "2017-02-03", "authors_parsed": [["Berthet", "Quentin", ""], ["Rigollet", "Philippe", ""], ["Srivastava", "Piyush", ""]]}, {"id": "1612.03904", "submitter": "Gogi Pantsulaia", "authors": "Levan Labadze, Zurab Kvatadze, Gogi Pantsulaia", "title": "On a consistent estimator of a useful signal in Ornstein-Uhlenbeck model\n  in $\\mathbb{C}[-l,l[$", "comments": "20 pages, 5 figues", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  ~It is considered a transmittion process of a useful signal in\nOrnstein-Uhlenbeck model in $\\mathbb{C}[-l,l[$ defined by the stochastic\ndifferential equation $$ d\\Psi(t,x,\\omega)=\\sum_{n=0}^{2m}\nA_n\\frac{\\partial^{n}}{\\partial x^{n}}\\Psi(t,x,\\omega)dt +\\sigma d W(t,\\omega)\n$$ with initial condition $$\\Psi(0,x,\\omega)=\\Psi_0(x) \\in FD^{(0)}[-l,l[, $$\nwhere $m \\ge 1$, $(A_n)_{0 \\le n \\le 2m} \\in \\mathbb{R}^+\\times\n\\mathbb{R}^{2m-1}$,$~((t,x,\\omega) \\in [0,+\\infty[\\times [-l,l[ \\times\n\\Omega)$, $\\sigma \\in \\mathbb{R}^+$, $\\mathbb{C}[-l,l[$ is Banach space of all\nreal-valued bounded continuous functions on $[-l,l[$, $FD^{(0)}[-l,l[ \\subset\n\\mathbb{C}[-l,l[ $ is class of all real-valued bounded continuous functions on\n$[-l,l[$ whose Fourier series converges to himself everywhere on $[-l,l[$,\n$(W(t,\\omega))_{t \\ge 0}$ is a Wiener process and $\\Psi_0(x)$ is a useful\nsignal.\n  By use a sequence of transformed signals $(Z_k)_{k \\in\nN}=(\\Psi(t_0,x,\\omega_k))_{k \\in N}$ at moment $t_0>0$, consistent and\ninfinite-sample consistent estimations of the useful signal $\\Psi_0$ is\nconstructed under assumption that parameters $(A_n)_{0 \\le n \\le 2m}$ and\n$\\sigma$ are known. Animation and simulation of the Ornstein-Uhlenbeck process\nin $\\mathbb{C}[-l,l[$ and an estimation of a useful signal are also presented.\n", "versions": [{"version": "v1", "created": "Sat, 10 Dec 2016 08:49:11 GMT"}, {"version": "v2", "created": "Sat, 17 Dec 2016 09:15:48 GMT"}], "update_date": "2016-12-20", "authors_parsed": [["Labadze", "Levan", ""], ["Kvatadze", "Zurab", ""], ["Pantsulaia", "Gogi", ""]]}, {"id": "1612.04025", "submitter": "Masayo Hirose", "authors": "Masayo Yoshimori Hirose", "title": "Second-order unbiased naive estimator of mean squared error for EBLUP in\n  small-area estimation", "comments": "13 pages, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An empirical best linear unbiased prediction (EBLUP) estimator is utilized\nfor efficient inference in small-area estimation. To measure its uncertainty,\nwe need to estimate its mean squared error (MSE) since the true MSE cannot\ngenerally be derived in a closed form. The \"naive MSE estimator\", one of the\nestimators available for small-area inference, is unlikely to be chosen, since\nit does not achieve the desired asymptotic property, namely second-order\nunbiasedness, although it maintains strict positivity and tractability.\nTherefore, users tend to choose the second-order unbiased MSE estimator. In\nthis paper, we seek a new adjusted maximum-likelihood method to obtain a naive\nMSE estimator that achieves the required asymptotic property. To obtain the\nresult, we also reveal the relationship between the general adjusted\nmaximum-likelihood method for the model variance parameter and the general\nfunctional form of the second-order unbiased, and strictly positive, MSE\nestimator. We also compare the performance of the new method with that of the\nexisting naive estimator through a Monte Carlo simulation study. The results\nshow that the new method remedies the underestimation associated with the\nexisting naive estimator.\n", "versions": [{"version": "v1", "created": "Tue, 13 Dec 2016 04:33:54 GMT"}], "update_date": "2016-12-14", "authors_parsed": [["Hirose", "Masayo Yoshimori", ""]]}, {"id": "1612.04059", "submitter": "Oliver Lang", "authors": "Oliver Lang, Michael Lunglmayr and Mario Huemer", "title": "Parameter Estimation Under Model Uncertainties by Iterative Covariance\n  Approximation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT math.IT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel iterative algorithm for estimating a deterministic but\nunknown parameter vector in the presence of model uncertainties. This iterative\nalgorithm is based on a system model where an overall noise term describes\nboth, the measurement noise and the noise resulting from the model\nuncertainties. This overall noise term is a function of the true parameter\nvector, allowing for an iterative algorithm. The proposed algorithm can be\napplied on structured as well as unstructured models and it outperforms prior\nart algorithms for a broad range of applications.\n", "versions": [{"version": "v1", "created": "Tue, 13 Dec 2016 08:22:54 GMT"}, {"version": "v2", "created": "Thu, 23 Nov 2017 07:05:16 GMT"}], "update_date": "2017-11-27", "authors_parsed": [["Lang", "Oliver", ""], ["Lunglmayr", "Michael", ""], ["Huemer", "Mario", ""]]}, {"id": "1612.04060", "submitter": "Oliver Lang", "authors": "Oliver Lang and Mario Huemer", "title": "Best Widely Linear Unbiased Estimator for Real Valued Parameter Vectors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For classical estimation with an underlying linear model the best linear\nunbiased estimator (BLUE) is usually utilized for estimating the deterministic\nbut unknown parameter vector. In the case of real valued parameter vectors but\ncomplex valued measurement matrices and noise vectors, the BLUE results in\ncomplex valued estimates, introducing a systematic error. In recent years\nwidely linear estimators have been investigated for complex estimation. In this\nwork a novel widely linear classical estimator is derived which incorporates\nthe knowledge that the parameter vector is real valued. The proposed estimator\nis unbiased in the classical sense and it outperforms the BLUE and the best\nwidely linear unbiased estimator (BWLUE) in terms of the variances of the\nvector estimator's elements.\n", "versions": [{"version": "v1", "created": "Tue, 13 Dec 2016 08:23:57 GMT"}], "update_date": "2016-12-14", "authors_parsed": [["Lang", "Oliver", ""], ["Huemer", "Mario", ""]]}, {"id": "1612.04112", "submitter": "Naoki Hayashi", "authors": "Naoki Hayashi, Sumio Watanabe", "title": "Upper Bound of Bayesian Generalization Error in Non-negative Matrix\n  Factorization", "comments": "21 pages, 1 table. / Neurocomputing Vol. 266. / ERRATA: Proof of\n  Lemma 3.3 and Discussion is corrected", "journal-ref": "Neurocomputing, Volume 266C, 29 November 2017, pp.21-28", "doi": "10.1016/j.neucom.2017.04.068", "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-negative matrix factorization (NMF) is a new knowledge discovery method\nthat is used for text mining, signal processing, bioinformatics, and consumer\nanalysis. However, its basic property as a learning machine is not yet\nclarified, as it is not a regular statistical model, resulting that theoretical\noptimization method of NMF has not yet established. In this paper, we study the\nreal log canonical threshold of NMF and give an upper bound of the\ngeneralization error in Bayesian learning. The results show that the\ngeneralization error of the matrix factorization can be made smaller than\nregular statistical models if Bayesian learning is applied.\n", "versions": [{"version": "v1", "created": "Tue, 13 Dec 2016 12:02:24 GMT"}, {"version": "v2", "created": "Wed, 15 Feb 2017 07:24:03 GMT"}, {"version": "v3", "created": "Wed, 22 Feb 2017 10:30:36 GMT"}, {"version": "v4", "created": "Fri, 16 Jun 2017 03:54:56 GMT"}, {"version": "v5", "created": "Sun, 1 Oct 2017 03:41:30 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Hayashi", "Naoki", ""], ["Watanabe", "Sumio", ""]]}, {"id": "1612.04288", "submitter": "Piero Veronese", "authors": "Piero Veronese and Eugenio Melilli", "title": "Some Asymptotic Results for Fiducial and Confidence Distributions", "comments": "New examples are added to compare our results with traditional MLE\n  inference, with emphasis on coverage probabilities. New references are added", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Under standard regularity assumptions, we provide simple approximations for\nspecific classes of fiducial and confidence distributions and discuss their\nconnections with objective Bayesian posteriors. For a real parameter the\napproximations are accurate at least to order O(1/n). For the mean parameter of\na multivariate exponential family, our fiducial distribution is asymptotically\nnormal and invariant to the importance ordering of the components of the mean\nparameter.\n", "versions": [{"version": "v1", "created": "Tue, 13 Dec 2016 17:13:42 GMT"}, {"version": "v2", "created": "Tue, 17 Oct 2017 14:16:26 GMT"}], "update_date": "2017-10-18", "authors_parsed": [["Veronese", "Piero", ""], ["Melilli", "Eugenio", ""]]}, {"id": "1612.04330", "submitter": "Ir\\`ene Waldspurger", "authors": "Ir\\`ene Waldspurger", "title": "Phase retrieval with random Gaussian sensing vectors by alternating\n  projections", "comments": "Short version of arXiv:1609.03088v1", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a phase retrieval problem, where we want to reconstruct a\n$n$-dimensional vector from its phaseless scalar products with $m$ sensing\nvectors, independently sampled from complex normal distributions. We show that,\nwith a suitable initalization procedure, the classical algorithm of alternating\nprojections succeeds with high probability when $m\\geq Cn$, for some $C>0$. We\nconjecture that this result is still true when no special initialization\nprocedure is used, and present numerical experiments that support this\nconjecture.\n", "versions": [{"version": "v1", "created": "Tue, 13 Dec 2016 19:46:27 GMT"}, {"version": "v2", "created": "Tue, 16 Apr 2019 13:32:56 GMT"}], "update_date": "2019-04-17", "authors_parsed": [["Waldspurger", "Ir\u00e8ne", ""]]}, {"id": "1612.04467", "submitter": "Wenge Guo", "authors": "Gavin Lynch, Wenge Guo", "title": "On Procedures Controlling the FDR for Testing Hierarchically Ordered\n  Hypotheses", "comments": "34 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complex large-scale studies, such as those related to microarray data and\nfMRI studies, often involve testing multiple hierarchically ordered hypotheses.\nHowever, most existing false discovery rate (FDR) controlling procedures do not\nexploit the inherent hierarchical structure among the tested hypotheses. In\nthis paper, we first present a generalized stepwise procedure which generalizes\nthe usual stepwise procedure to the case where each hypothesis is tested with a\ndifferent set of critical constants. This procedure is helpful in creating a\ngeneral framework under which our hierarchical testing procedures are\ndeveloped. Then, we present several hierarchical testing procedures which\ncontrol the FDR under various forms of dependence such as positive dependence\nand block dependence. Our simulation studies show that these proposed methods\ncan be more powerful in some situations than alternative methods such as\nYekutieli's hierarchical testing procedure (Yekutieli, \\emph{JASA} \\textbf{103}\n(2008) 309-316). Finally, we apply our proposed procedures to a real data set\ninvolving abundances of microbes in different ecological environments.\n", "versions": [{"version": "v1", "created": "Wed, 14 Dec 2016 03:08:16 GMT"}], "update_date": "2016-12-15", "authors_parsed": [["Lynch", "Gavin", ""], ["Guo", "Wenge", ""]]}, {"id": "1612.04507", "submitter": "Jose Figueroa-Lopez", "authors": "Jos\\'e E. Figueroa-L\\'opez and Cheng Li", "title": "Optimal Kernel Estimation of Spot Volatility of Stochastic Differential\n  Equations", "comments": "1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST q-fin.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kernel Estimation is one of the most widely used estimation methods in\nnon-parametric Statistics, having a wide-range of applications, including spot\nvolatility estimation of stochastic processes. The selection of bandwidth and\nkernel function is of great importance, especially for the finite sample\nsettings commonly encountered in econometric applications. In the context of\nspot volatility estimation, most of the proposed selection methods are either\nlargely heuristic or just formally stated without any feasible implementation.\nIn this work, an objective method of bandwidth and kernel selection is\nproposed, under some mild conditions on the volatility, which not only cover\nclassical Brownian motion driven dynamics but also some processes driven by\nlong-memory fractional Brownian motions or other Gaussian processes. We\ncharacterize the leading order terms of the Mean Squared Error, which are also\nratified by central limit theorems for the estimation error. As a byproduct, an\napproximated optimal bandwidth is then obtained in closed form. This result\nallows us to develop a feasible plug-in type bandwidth selection procedure, for\nwhich, as a sub-problem, we propose a new estimator of the volatility of\nvolatility. The optimal selection of kernel function is also discussed. For\nBrownian Motion type volatilities, the optimal kernel function is proved to be\nthe exponential kernel. For fractional Brownian motion type volatilities,\nnumerical results to compute the optimal kernel are devised and, for the\ndeterministic volatility case, explicit optimal kernel functions of different\norders are derived. Simulation studies further confirm the good performance of\nthe proposed methods.\n", "versions": [{"version": "v1", "created": "Wed, 14 Dec 2016 06:25:51 GMT"}], "update_date": "2016-12-15", "authors_parsed": [["Figueroa-L\u00f3pez", "Jos\u00e9 E.", ""], ["Li", "Cheng", ""]]}, {"id": "1612.04636", "submitter": "J. Martin van Zyl", "authors": "J. Martin van Zyl", "title": "The sample fraction in peaks-over-threshold problems where the\n  second-order expansion is valid with specific reference to the generalized\n  Pareto distribution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In samples from a heavy-tailed distribution a second-order approximation is\noften use to approximate the tail function. Based on the parameters of the\napproximation, an optimal sample fraction can be estimated which is then used\nto estimate the index. Given that the observations are above a threshold and\nhas an approximate generalized Pareto distribution, an expression is derived\nfor the percentile above which the second-order approximation is valid\n", "versions": [{"version": "v1", "created": "Wed, 14 Dec 2016 13:50:07 GMT"}], "update_date": "2016-12-15", "authors_parsed": [["van Zyl", "J. Martin", ""]]}, {"id": "1612.04740", "submitter": "Damien Garreau", "authors": "Damien Garreau and Sylvain Arlot", "title": "Consistent change-point detection with kernels", "comments": "41 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study the kernel change-point algorithm (KCP) proposed by\nArlot, Celisse and Harchaoui (2012), which aims at locating an unknown number\nof change-points in the distribution of a sequence of independent data taking\nvalues in an arbitrary set. The change-points are selected by model selection\nwith a penalized kernel empirical criterion. We provide a non-asymptotic result\nshowing that, with high probability, the KCP procedure retrieves the correct\nnumber of change-points, provided that the constant in the penalty is\nwell-chosen; in addition, KCP estimates the change-points location at the\noptimal rate. As a consequence, when using a characteristic kernel, KCP detects\nall kinds of change in the distribution (not only changes in the mean or the\nvariance), and it is able to do so for complex structured data (not necessarily\nin $\\mathbb{R}^d$). Most of the analysis is conducted assuming that the kernel\nis bounded; part of the results can be extended when we only assume a finite\nsecond-order moment.\n", "versions": [{"version": "v1", "created": "Wed, 14 Dec 2016 17:28:17 GMT"}, {"version": "v2", "created": "Wed, 28 Jun 2017 14:15:11 GMT"}, {"version": "v3", "created": "Thu, 29 Jun 2017 08:03:38 GMT"}], "update_date": "2017-06-30", "authors_parsed": [["Garreau", "Damien", ""], ["Arlot", "Sylvain", ""]]}, {"id": "1612.04838", "submitter": "Sebastian D\\\"ohler", "authors": "Sebastian D\\\"ohler", "title": "A discrete modification of the Benjamini-Yekutieli procedure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.AP stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Benjamini-Yekutieli procedure is a multiple testing method that controls\nthe false discovery rate under arbitrary dependence of the $p$-values. A\nmodification of this and related procedures is proposed for the case when the\ntest statistics are discrete. It is shown that taking discreteness into account\ncan improve upon known procedures. The performance of this new procedure is\nevaluated for pharmacovigilance data and in a simulation study.\n", "versions": [{"version": "v1", "created": "Wed, 14 Dec 2016 21:05:20 GMT"}], "update_date": "2016-12-16", "authors_parsed": [["D\u00f6hler", "Sebastian", ""]]}, {"id": "1612.04932", "submitter": "Demian Pouzo", "authors": "Demian Pouzo, Zacharias Psaradakis, Martin Sola", "title": "Maximum Likelihood Estimation in Possibly Misspecified Dynamic Models\n  with Time-Inhomogeneous Markov Regimes", "comments": "50 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST econ.EM stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers maximum likelihood (ML) estimation in a large class of\nmodels with hidden Markov regimes. We investigate consistency and local\nasymptotic normality of the ML estimator under general conditions which allow\nfor autoregressive dynamics in the observable process, time-inhomogeneous\nMarkov regime sequences, and possible model misspecification. A Monte Carlo\nstudy examines the finite-sample properties of the ML estimator. An empirical\napplication is also discussed.\n", "versions": [{"version": "v1", "created": "Thu, 15 Dec 2016 05:24:01 GMT"}, {"version": "v2", "created": "Thu, 10 May 2018 01:06:59 GMT"}], "update_date": "2018-05-11", "authors_parsed": [["Pouzo", "Demian", ""], ["Psaradakis", "Zacharias", ""], ["Sola", "Martin", ""]]}, {"id": "1612.04969", "submitter": "Olivier Scaillet", "authors": "Olivier Scaillet", "title": "On ill-posedness of nonparametric instrumental variable regression with\n  convexity constraints", "comments": null, "journal-ref": "The Econometrics Journal Volume 19, Issue 2 June 2016 Pages\n  232-236", "doi": "10.1111/ectj.12071", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This note shows that adding monotonicity or convexity constraints on the\nregression function does not restore well-posedness in nonparametric\ninstrumental variable regression. The minimum distance problem without\nregularisation is still locally ill-posed.\n", "versions": [{"version": "v1", "created": "Thu, 15 Dec 2016 08:37:47 GMT"}], "update_date": "2016-12-16", "authors_parsed": [["Scaillet", "Olivier", ""]]}, {"id": "1612.04996", "submitter": "Pramita Bagchi", "authors": "Pramita Bagchi, Vaidotas Characiejus, Holger Dette", "title": "A simple test for white noise in functional time series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new procedure for white noise testing of a functional time\nseries. Our approach is based on an explicit representation of the\n$L^2$-distance between the spectral density operator and its best\n($L^2$-)approximation by a spectral density operator corresponding to a white\nnoise process. The estimation of this distance can be easily accomplished by\nsums of periodogram kernels and it is shown that an appropriately standardized\nversion of the estimator is asymptotically normal distributed under the null\nhypothesis (of functional white noise) and under the alternative. As a\nconsequence we obtain a very simple test (using the quantiles of the normal\ndistribution) for the hypothesis of a white noise functional process. In\nparticular the test does neither require the estimation of a long run variance\n(including a fourth order cumulant) nor resampling procedures to calculate\ncritical values. Moreover, in contrast to all other methods proposed in the\nliterature our approach also allows to test for \"relevant\" deviations from\nwhite noise and to construct confidence intervals for a measure which measures\nthe discrepancy of the underlying process from a functional white noise\nprocess.\n", "versions": [{"version": "v1", "created": "Thu, 15 Dec 2016 09:50:20 GMT"}, {"version": "v2", "created": "Tue, 5 Sep 2017 11:18:00 GMT"}], "update_date": "2017-09-06", "authors_parsed": [["Bagchi", "Pramita", ""], ["Characiejus", "Vaidotas", ""], ["Dette", "Holger", ""]]}, {"id": "1612.05072", "submitter": "Olivier Scaillet", "authors": "Lorenzo Camponovo, Olivier Scaillet and Fabio Trojani", "title": "Predictability Hidden by Anomalous Observations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Testing procedures for predictive regressions with lagged autoregressive\nvariables imply a suboptimal inference in presence of small violations of ideal\nassumptions. We propose a novel testing framework resistant to such violations,\nwhich is consistent with nearly integrated regressors and applicable to\nmulti-predictor settings, when the data may only approximately follow a\npredictive regression model. The Monte Carlo evidence demonstrates large\nimprovements of our approach, while the empirical analysis produces a strong\nrobust evidence of market return predictability hidden by anomalous\nobservations, both in- and out-of-sample, using predictive variables such as\nthe dividend yield or the volatility risk premium.\n", "versions": [{"version": "v1", "created": "Thu, 15 Dec 2016 14:12:17 GMT"}], "update_date": "2016-12-16", "authors_parsed": [["Camponovo", "Lorenzo", ""], ["Scaillet", "Olivier", ""], ["Trojani", "Fabio", ""]]}, {"id": "1612.05124", "submitter": "Jan van Waaij MSc", "authors": "Frank van der Meulen, Moritz Schauer, Jan van Waaij", "title": "Adaptive nonparametric drift estimation for diffusion processes using\n  Faber-Schauder expansions", "comments": null, "journal-ref": "J. Stat Inference Stoch Process (2018) 21: 603", "doi": "10.1007/s11203-017-9163-7", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of nonparametric estimation of the drift of a\ncontinuously observed one-dimensional diffusion with periodic drift. Motivated\nby computational considerations, van der Meulen e.a. (2014) defined a prior on\nthe drift as a randomly truncated and randomly scaled Faber-Schauder series\nexpansion with Gaussian coefficients. We study the behaviour of the posterior\nobtained from the prior from a frequentist asymptotic point of view. If the\ntrue data generating drift is smooth, it is proved that the posterior is\nadaptive with posterior contraction rates for the $L_2$-norm that are optimal\nup to a log factor. Moreover, contraction rates in $L_p$-norms with $p\\in\n(2,\\infty]$ are derived as well.\n", "versions": [{"version": "v1", "created": "Thu, 15 Dec 2016 16:10:29 GMT"}, {"version": "v2", "created": "Wed, 7 Jun 2017 08:54:52 GMT"}], "update_date": "2019-02-04", "authors_parsed": [["van der Meulen", "Frank", ""], ["Schauer", "Moritz", ""], ["van Waaij", "Jan", ""]]}, {"id": "1612.05178", "submitter": "Marco Oesting", "authors": "Clement Dombry and Sebastian Engelke and Marco Oesting", "title": "Asymptotic properties of the maximum likelihood estimator for\n  multivariate extreme value distributions", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Max-stable distributions and processes are important models for extreme\nevents and the assessment of tail risks. The full, multivariate likelihood of a\nparametric max-stable distribution is complicated and only recent advances\nenable its use. The asymptotic properties of the maximum likelihood estimator\nin multivariate extremes are mostly unknown. In this paper we provide natural\nconditions on the exponent function and the angular measure of the max-stable\ndistribution that ensure asymptotic normality of the estimator. We show the\neffectiveness of this result by applying it to popular parametric models in\nmultivariate extreme value statistics and to the most commonly used families of\nspatial max-stable processes.\n", "versions": [{"version": "v1", "created": "Thu, 15 Dec 2016 18:16:38 GMT"}, {"version": "v2", "created": "Mon, 7 Aug 2017 08:04:43 GMT"}], "update_date": "2017-08-08", "authors_parsed": [["Dombry", "Clement", ""], ["Engelke", "Sebastian", ""], ["Oesting", "Marco", ""]]}, {"id": "1612.05330", "submitter": "David Asher Levin", "authors": "David A. Levin and Yuval Peres", "title": "Estimating the Spectral Gap of a Reversible Markov Chain from a Short\n  Trajectory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The spectral gap $\\gamma$ of an ergodic and reversible Markov chain is an\nimportant parameter measuring the asymptotic rate of convergence. In\napplications, the transition matrix $P$ may be unknown, yet one sample of the\nchain up to a fixed time $t$ may be observed. Hsu, Kontorovich, and Szepesvari\n(2015) considered the problem of estimating $\\gamma$ from this data. Let $\\pi$\nbe the stationary distribution of $P$, and $\\pi_\\star = \\min_x \\pi(x)$. They\nshowed that, if $t = \\tilde{O}\\bigl(\\frac{1}{\\gamma^3 \\pi_\\star}\\bigr)$, then\n$\\gamma$ can be estimated to within multiplicative constants with high\nprobability. They also proved that $\\tilde{\\Omega}\\bigl(\\frac{n}{\\gamma}\\bigr)$\nsteps are required for precise estimation of $\\gamma$. We show that\n$\\tilde{O}\\bigl(\\frac{1}{\\gamma \\pi_\\star}\\bigr)$ steps of the chain suffice to\nestimate $\\gamma$ up to multiplicative constants with high probability. When\n$\\pi$ is uniform, this matches (up to logarithmic corrections) the lower bound\nof Hsu, Kontorovich, and Szepesvari.\n", "versions": [{"version": "v1", "created": "Fri, 16 Dec 2016 01:28:41 GMT"}], "update_date": "2016-12-19", "authors_parsed": [["Levin", "David A.", ""], ["Peres", "Yuval", ""]]}, {"id": "1612.05368", "submitter": "Anup Aprem", "authors": "Anup Aprem, Vikram Krishnamurthy", "title": "Utility Change Point Detection in Online Social Media: A Revealed\n  Preference Framework", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2016.2646667", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with change detection of utility maximization behaviour in\nonline social media. Such changes occur due to the effect of marketing,\nadvertising, or changes in ground truth. First, we use the revealed preference\nframework to detect the unknown time point (change point) at which the utility\nfunction changed. We derive necessary and sufficient conditions for detecting\nthe change point. Second, in the presence of noisy measurements, we propose a\nmethod to detect the change point and construct a decision test. Also, an\noptimization criteria is provided to recover the linear perturbation\ncoefficients. Finally, to reduce the computational cost, a dimensionality\nreduction algorithm using Johnson-Lindenstrauss transform is presented. The\nresults developed are illustrated on two real datasets: Yahoo! Tech Buzz\ndataset and Youstatanalyzer dataset. By using the results developed in the\npaper, several useful insights can be gleaned from these data sets. First, the\nchanges in ground truth affecting the utility of the agent can be detected by\nutility maximization behaviour in online search. Second, the recovered utility\nfunctions satisfy the single crossing property indicating strategic substitute\nbehaviour in online search. Third, due to the large number of videos in\nYouTube, the utility maximization behaviour was verified through the\ndimensionality reduction algorithm. Finally, using the utility function\nrecovered in the lower dimension, we devise an algorithm to predict total\ntraffic in YouTube.\n", "versions": [{"version": "v1", "created": "Fri, 16 Dec 2016 05:04:14 GMT"}], "update_date": "2017-04-05", "authors_parsed": [["Aprem", "Anup", ""], ["Krishnamurthy", "Vikram", ""]]}, {"id": "1612.05445", "submitter": "Joni Virta", "authors": "Joni Virta, Klaus Nordhausen, Hannu Oja", "title": "Projection Pursuit for non-Gaussian Independent Components", "comments": "47 pages, 11 figures. This work is partially based on the unpublished\n  manuscript \"Joint Use of Third and Fourth Cumulants in Independent Component\n  Analysis\", Virta et al. (2015), available as an arXiv preprint,\n  https://arxiv.org/abs/1505.02613", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In independent component analysis it is assumed that the observed random\nvariables are linear combinations of latent, mutually independent random\nvariables called the independent components. Our model further assumes that\nonly the non-Gaussian independent components are of interest, the Gaussian\ncomponents being treated as noise. In this paper projection pursuit is used to\nextract the non-Gaussian components and to separate the corresponding signal\nand noise subspaces. Our choice for the projection index is a convex\ncombination of squared third and fourth cumulants and we estimate the\nnon-Gaussian components either one-by-one (deflation-based approach) or\nsimultaneously (symmetric approach). The properties of both estimates are\nconsidered in detail through the corresponding optimization problems,\nestimating equations, algorithms and asymptotic properties. Various comparisons\nof the estimates show that the two approaches separate the signal and noise\nsubspaces equally well but the symmetric one is generally better in extracting\nthe individual non-Gaussian components.\n", "versions": [{"version": "v1", "created": "Fri, 16 Dec 2016 12:41:53 GMT"}], "update_date": "2016-12-19", "authors_parsed": [["Virta", "Joni", ""], ["Nordhausen", "Klaus", ""], ["Oja", "Hannu", ""]]}, {"id": "1612.05612", "submitter": "Feng Ruan", "authors": "John Duchi and Feng Ruan", "title": "Asymptotic Optimality in Stochastic Optimization", "comments": null, "journal-ref": "Annals of Statistics 2019", "doi": null, "report-no": null, "categories": "math.ST math.OC stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study local complexity measures for stochastic convex optimization\nproblems, providing a local minimax theory analogous to that of H\\'{a}jek and\nLe Cam for classical statistical problems. We give complementary optimality\nresults, developing fully online methods that adaptively achieve optimal\nconvergence guarantees. Our results provide function-specific lower bounds and\nconvergence results that make precise a correspondence between statistical\ndifficulty and the geometric notion of tilt-stability from optimization. As\npart of this development, we show how variants of Nesterov's dual averaging---a\nstochastic gradient-based procedure---guarantee finite time identification of\nconstraints in optimization problems, while stochastic gradient procedures\nfail. Additionally, we highlight a gap between problems with linear and\nnonlinear constraints: standard stochastic-gradient-based procedures are\nsuboptimal even for the simplest nonlinear constraints, necessitating the\ndevelopment of asymptotically optimal Riemannian stochastic gradient methods.\n", "versions": [{"version": "v1", "created": "Fri, 16 Dec 2016 19:54:22 GMT"}, {"version": "v2", "created": "Wed, 2 Aug 2017 09:08:42 GMT"}, {"version": "v3", "created": "Thu, 3 Aug 2017 02:32:45 GMT"}, {"version": "v4", "created": "Fri, 2 Nov 2018 09:10:18 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Duchi", "John", ""], ["Ruan", "Feng", ""]]}, {"id": "1612.05906", "submitter": "Guang Cheng", "authors": "Zhuqing Yu, Michael Levine, Guang Cheng", "title": "Minimax Optimal Estimation in Partially Linear Additive Models under\n  High Dimension", "comments": "To Appear in Bernoulli", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we derive minimax rates for estimating both parametric and\nnonparametric components in partially linear additive models with high\ndimensional sparse vectors and smooth functional components. The minimax lower\nbound for Euclidean components is the typical sparse estimation rate that is\nindependent of nonparametric smoothness indices. However, the minimax lower\nbound for each component function exhibits an interplay between the\ndimensionality and sparsity of the parametric component and the smoothness of\nthe relevant nonparametric component. Indeed, the minimax risk for smooth\nnonparametric estimation can be slowed down to the sparse estimation rate\nwhenever the smoothness of the nonparametric component or dimensionality of the\nparametric component is suffciently large. In the above setting, we demonstrate\nthat penalized least square estimators can nearly achieve minimax lower bounds.\n", "versions": [{"version": "v1", "created": "Sun, 18 Dec 2016 12:34:18 GMT"}, {"version": "v2", "created": "Fri, 16 Jun 2017 19:03:36 GMT"}, {"version": "v3", "created": "Sun, 14 Jan 2018 01:14:46 GMT"}], "update_date": "2018-01-16", "authors_parsed": [["Yu", "Zhuqing", ""], ["Levine", "Michael", ""], ["Cheng", "Guang", ""]]}, {"id": "1612.05951", "submitter": "Ezequiel Smucler", "authors": "Ezequiel Smucler", "title": "Asymptotic Statistical Properties of Redescending M-estimators in Linear\n  Models with Increasing Dimension", "comments": "32 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with the asymptotic statistical properties of a class of\nredescending M-estimators in linear models with increasing dimension. This\nclass is wide enough to include popular high breakdown point estimators such as\nS-estimators and MM-estimators, which were not covered by existing results in\nthe literature. We prove consistency assuming only that $p/n \\rightarrow 0$ and\nasymptotic normality essentially if $p^{3}/n \\rightarrow 0$, where $p$ is the\nnumber of covariates and $n$ is the sample size.\n", "versions": [{"version": "v1", "created": "Sun, 18 Dec 2016 17:15:55 GMT"}], "update_date": "2016-12-20", "authors_parsed": [["Smucler", "Ezequiel", ""]]}, {"id": "1612.05994", "submitter": "Mathias Drton", "authors": "Mathias Drton", "title": "Algebraic Problems in Structural Equation Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper gives an overview of recent advances in structural equation\nmodeling. A structural equation model is a multivariate statistical model that\nis determined by a mixed graph, also known as a path diagram. Our focus is on\nthe covariance matrices of linear structural equation models. In the linear\ncase, each covariance is a rational function of parameters that are associated\nto the edges and nodes of the graph. We statistically motivate algebraic\nproblems concerning the rational map that parametrizes the covariance matrix.\nWe review combinatorial tools such as the trek rule, projection to ancestral\nsets, and a graph decomposition due to Jin Tian. Building on these tools, we\ndiscuss advances in parameter identification, i.e., the study of (generic)\ninjectivity of the parametrization, and explain recent results on determinantal\nrelations among the covariances. The paper is based on lectures given at the\n8th Mathematical Society of Japan Seasonal Institute.\n", "versions": [{"version": "v1", "created": "Sun, 18 Dec 2016 21:31:46 GMT"}], "update_date": "2016-12-20", "authors_parsed": [["Drton", "Mathias", ""]]}, {"id": "1612.06040", "submitter": "Sonja Petrovic", "authors": "Vishesh Karwa, Debdeep Pati, Sonja Petrovi\\'c, Liam Solus, Nikita\n  Alexeev, Mateja Rai\\v{c}, Dane Wilburne, Robert Williams, Bowei Yan", "title": "Exact tests for stochastic block models", "comments": "30 pages, several figures, Discussion", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a finite-sample goodness-of-fit test for \\emph{latent-variable}\nblock models for networks and test it on simulated and real data sets. The main\nbuilding block for the latent block assignment model test is the exact test for\nthe model with observed blocks assignment. The latter is implemented using\nalgebraic statistics. While we focus on three variants of the stochastic block\nmodel, the methodology extends to any mixture of log-linear models on discrete\ndata.\n", "versions": [{"version": "v1", "created": "Mon, 19 Dec 2016 04:05:57 GMT"}], "update_date": "2016-12-20", "authors_parsed": [["Karwa", "Vishesh", ""], ["Pati", "Debdeep", ""], ["Petrovi\u0107", "Sonja", ""], ["Solus", "Liam", ""], ["Alexeev", "Nikita", ""], ["Rai\u010d", "Mateja", ""], ["Wilburne", "Dane", ""], ["Williams", "Robert", ""], ["Yan", "Bowei", ""]]}, {"id": "1612.06109", "submitter": "Daisuke Kurisu", "authors": "Daisuke Kurisu", "title": "Discretization of Self-Exciting Peaks Over Threshold Models", "comments": "This paper has been withdrawn by the author due to a crucial error in\n  the proof of Theorem 1", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a framework on a discrete observation of (marked) point\nprocesses under the high-frequency observation is developed. Based on this\nframework, we first clarify the relation between random coefficient\ninteger-valued autoregressive process with infinite order (RCINAR($\\infty$))\nand i.i.d.-marked self-exciting process, known as marked Hawkes process. For\nthis purpose, we show that the point process constructed of the sum of a\nRCINAR($\\infty$) converge weakly to a marked Hawkes process. This limit theorem\nestablish that RCINAR($\\infty$) processes can be seen as a discretely observed\nmarked Hawkes processes when the observation frequency increases and thus build\na bridge between discrete-time series analysis and the analysis of\ncontinuous-time stochastic process and give a new perspective in the point\nprocess approach in extreme value theory. Second, we give a necessary and\nsufficient condition of the stationarity of RCINAR($\\infty$) process and give\nits random coefficient autoregressive (RCAR) representation. Finally, as an\napplication of our results, we establish a rigorous theoretical justification\nof self-exciting peaks over threshold (SEPOT) model, which is a well-known as a\n(marked) Hawkes process model for the empirical analysis of extremal events in\nfinancial econometrics and of which, however, the theoretical validity have\nrarely discussed. Simulation results of the asymptotic properties of\nRCINAR($\\infty$) shows some interesting implications for statistical\napplications.\n", "versions": [{"version": "v1", "created": "Mon, 19 Dec 2016 10:28:57 GMT"}, {"version": "v2", "created": "Tue, 20 Dec 2016 08:46:09 GMT"}, {"version": "v3", "created": "Sun, 9 Apr 2017 11:05:45 GMT"}], "update_date": "2017-04-11", "authors_parsed": [["Kurisu", "Daisuke", ""]]}, {"id": "1612.06127", "submitter": "Benedikt M. P\\\"otscher", "authors": "Benedikt M. P\\\"otscher and David Preinerstorfer", "title": "Controlling the Size of Autocorrelation Robust Tests", "comments": "Minor changes including correction of a minor error", "journal-ref": "Journal of Econometrics 207 (2018), 406-431", "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autocorrelation robust tests are notorious for suffering from size\ndistortions and power problems. We investigate under which conditions the size\nof autocorrelation robust tests can be controlled by an appropriate choice of\ncritical value.\n", "versions": [{"version": "v1", "created": "Mon, 19 Dec 2016 11:21:09 GMT"}, {"version": "v2", "created": "Wed, 28 Mar 2018 13:30:37 GMT"}, {"version": "v3", "created": "Tue, 4 Sep 2018 13:56:25 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["P\u00f6tscher", "Benedikt M.", ""], ["Preinerstorfer", "David", ""]]}, {"id": "1612.06149", "submitter": "Marcelo Pereyra", "authors": "Marcelo Pereyra", "title": "Revisiting maximum-a-posteriori estimation in log-concave models", "comments": "Accepted for publication in SIAM Imaging Sciences", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Maximum-a-posteriori (MAP) estimation is the main Bayesian estimation\nmethodology in imaging sciences, where high dimensionality is often addressed\nby using Bayesian models that are log-concave and whose posterior mode can be\ncomputed efficiently by convex optimisation. Despite its success and wide\nadoption, MAP estimation is not theoretically well understood yet. The\nprevalent view in the community is that MAP estimation is not proper Bayesian\nestimation in a decision-theoretic sense because it does not minimise a\nmeaningful expected loss function (unlike the minimum mean squared error (MMSE)\nestimator that minimises the mean squared loss). This paper addresses this\ntheoretical gap by presenting a decision-theoretic derivation of MAP estimation\nin Bayesian models that are log-concave. A main novelty is that our analysis is\nbased on differential geometry, and proceeds as follows. First, we use the\nunderlying convex geometry of the Bayesian model to induce a Riemannian\ngeometry on the parameter space. We then use differential geometry to identify\nthe so-called natural or canonical loss function to perform Bayesian point\nestimation in that Riemannian manifold. For log-concave models, this canonical\nloss is the Bregman divergence associated with the negative log posterior\ndensity. We then show that the MAP estimator is the only Bayesian estimator\nthat minimises the expected canonical loss, and that the posterior mean or MMSE\nestimator minimises the dual canonical loss. We also study the question of MAP\nand MSSE estimation performance in large scales and establish a universal bound\non the expected canonical error as a function of dimension, offering new\ninsights into the good performance observed in convex problems. These results\nprovide a new understanding of MAP and MMSE estimation in log-concave settings,\nand of the multiple roles that convex geometry plays in imaging problems.\n", "versions": [{"version": "v1", "created": "Mon, 19 Dec 2016 12:16:26 GMT"}, {"version": "v2", "created": "Wed, 21 Dec 2016 14:49:10 GMT"}, {"version": "v3", "created": "Mon, 23 Jan 2017 13:08:42 GMT"}, {"version": "v4", "created": "Fri, 18 Jan 2019 14:22:16 GMT"}], "update_date": "2019-01-21", "authors_parsed": [["Pereyra", "Marcelo", ""]]}, {"id": "1612.06358", "submitter": "Lihua Lei", "authors": "Lihua Lei, Peter J. Bickel, and Noureddine El Karoui", "title": "Asymptotics For High Dimensional Regression M-Estimates: Fixed Design\n  Results", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the asymptotic distributions of coordinates of regression\nM-estimates in the moderate $p/n$ regime, where the number of covariates $p$\ngrows proportionally with the sample size $n$. Under appropriate regularity\nconditions, we establish the coordinate-wise asymptotic normality of regression\nM-estimates assuming a fixed-design matrix. Our proof is based on the\nsecond-order Poincar\\'{e} inequality (Chatterjee, 2009) and leave-one-out\nanalysis (El Karoui et al., 2011). Some relevant examples are indicated to show\nthat our regularity conditions are satisfied by a broad class of design\nmatrices. We also show a counterexample, namely the ANOVA-type design, to\nemphasize that the technical assumptions are not just artifacts of the proof.\nFinally, the numerical experiments confirm and complement our theoretical\nresults.\n", "versions": [{"version": "v1", "created": "Mon, 19 Dec 2016 20:52:35 GMT"}], "update_date": "2016-12-20", "authors_parsed": [["Lei", "Lihua", ""], ["Bickel", "Peter J.", ""], ["Karoui", "Noureddine El", ""]]}, {"id": "1612.06571", "submitter": "Samuel Rosa", "authors": "Samuel Rosa", "title": "Optimal designs for treatment comparisons represented by graphs", "comments": "5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider an experiment consisting of a set of independent trials for\ncomparing a set of treatments. In each trial, one treatment is chosen and the\nmean response of the trial is equal to the effect of the chosen treatment. We\nexamine the optimal approximate designs for the estimation of a system of\ntreatment contrasts under such model. These approximate treatment designs can\nbe used to provide optimal treatment proportions for designs in more general\nmodels with nuisance effects (e.g., time trend, effects of blocks). For any\nsystem of pairwise treatment comparisons, we propose to represent such system\nby a graph. In particular, we represent the treatment designs for these sets of\ncontrasts by the inverses of the vertex weights in the corresponding graph G.\nWe show that then the positive eigenvalues of the information matrix of a\ntreatment design are inverse to the positive eigenvalues of the vertex-weighted\nLaplacian of G. Note that such representation of treatment designs differs from\nthe well known graph representation of block designs, which are represented by\nedges. We provide a graph-theoretic interpretation of the D-, A- and\nE-optimality for estimating sets of pairwise comparisons; as well as some\noptimality results for both the systems of pairwise comparisons and the general\nsystems of treatment contrasts. Moreover, we provide a class of 'symmetric'\nsystems of treatment contrasts for which the uniform treatment design is\noptimal with respect to a wide range of optimality criteria.\n", "versions": [{"version": "v1", "created": "Tue, 20 Dec 2016 09:50:11 GMT"}], "update_date": "2016-12-21", "authors_parsed": [["Rosa", "Samuel", ""]]}, {"id": "1612.06599", "submitter": "Milan Studeny", "authors": "Milan Studeny", "title": "Basic facts concerning supermodular functions", "comments": "research report: the Institute of Information Theory and Automation,\n  December 2016, 37 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO math.OC math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Elementary facts and observations on the cone of supermodular set functions\nare recalled. The manuscript deals with such operations with set functions\nwhich preserve supermodularity and the emphasis is put on those such operations\nwhich even preserve extremality (of a supermodular function). These involve a\nfew self-transformations of the cone of supermodular set functions. Moreover,\nprojections to the (less-dimensional) linear space of set functions for a\nsubset of the variable set are discussed. Finally, several extensions to the\n(more-dimensional) linear space of set functions for a superset of the variable\nset are shown to be both preserving supermodularity and extremality.\n", "versions": [{"version": "v1", "created": "Tue, 20 Dec 2016 10:40:58 GMT"}], "update_date": "2016-12-21", "authors_parsed": [["Studeny", "Milan", ""]]}, {"id": "1612.06601", "submitter": "Bruno Ebner", "authors": "Bruno Ebner and Norbert Henze and Joseph E. Yukich", "title": "Multivariate goodness-of-fit on flat and curved spaces via nearest\n  neighbor distances", "comments": "22 pages, 1 figure, 9 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a unified approach to goodness-of-fit testing in $\\mathbb{R}^d$\nand on lower-dimensional manifolds embedded in $\\mathbb{R}^d$ based on sums of\npowers of weighted volumes of $k$-th nearest neighbor spheres. We prove\nasymptotic normality of a class of test statistics under the null hypothesis\nand under fixed alternatives. Under such alternatives, scaled versions of the\ntest statistics converge to the $\\alpha$-entropy between probability\ndistributions. A simulation study shows that the procedures are serious\ncompetitors to established goodness-of-fit tests.\n", "versions": [{"version": "v1", "created": "Tue, 20 Dec 2016 10:55:51 GMT"}], "update_date": "2016-12-21", "authors_parsed": [["Ebner", "Bruno", ""], ["Henze", "Norbert", ""], ["Yukich", "Joseph E.", ""]]}, {"id": "1612.06618", "submitter": "Robert Gaunt", "authors": "Robert E. Gaunt, Satish Iyengar, Adri B. Olde Daalhuis, Burcin Simsek", "title": "An asymptotic expansion for the normalizing constant of the\n  Conway-Maxwell-Poisson distribution", "comments": "16 pages, to appear in Annals of the Institute of Statistical\n  Mathematics, 2017+", "journal-ref": "Annals of the Institute of Statistical Mathematics 71 (2019), pp.\n  163-180", "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Conway-Maxwell-Poisson distribution is a two-parameter generalisation of\nthe Poisson distribution that can be used to model data that is under- or\nover-dispersed relative to the Poisson distribution. The normalizing constant\n$Z(\\lambda,\\nu)$ is given by an infinite series that in general has no closed\nform, although several papers have derived approximations for this sum. In this\nwork, we start by using probabilistic argument to obtain the leading term in\nthe asymptotic expansion of $Z(\\lambda,\\nu)$ in the limit\n$\\lambda\\rightarrow\\infty$ that holds for all $\\nu>0$. We then use an integral\nrepresentation to obtain the entire asymptotic series and give explicit\nformulas for the first eight coefficients. We apply this asymptotic series to\nobtain approximations for the mean, variance, cumulants, skweness, excess\nkurtosis and raw moments of CMP random variables. Numerical results confirm\nthat these correction terms yield more accurate estimates than those obtained\nusing just the leading order term.\n", "versions": [{"version": "v1", "created": "Tue, 20 Dec 2016 11:48:50 GMT"}, {"version": "v2", "created": "Mon, 16 Oct 2017 08:12:25 GMT"}], "update_date": "2019-04-05", "authors_parsed": [["Gaunt", "Robert E.", ""], ["Iyengar", "Satish", ""], ["Daalhuis", "Adri B. Olde", ""], ["Simsek", "Burcin", ""]]}, {"id": "1612.06647", "submitter": "Eni Musta", "authors": "Hendrik P. Lopuha\\\"a and Eni Musta", "title": "A central limit theorem for the Hellinger loss of Grenander type\n  estimators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider Grenander type estimators for a monotone function\n$\\lambda:[0,1]\\to\\mathbb{R}$, obtained as the slope of a concave (convex)\nestimate of the primitive of $\\lambda$. Our main result is a central limit\ntheorem for the Hellinger loss, which applies to statistical models that\nsatisfy the setup in Durot (2007). This includes estimation of a monotone\ndensity, for which the limiting variance of the Hellinger loss turns out to be\nindependent of $\\lambda$.\n", "versions": [{"version": "v1", "created": "Tue, 20 Dec 2016 13:21:28 GMT"}], "update_date": "2016-12-21", "authors_parsed": [["Lopuha\u00e4", "Hendrik P.", ""], ["Musta", "Eni", ""]]}, {"id": "1612.06661", "submitter": "Roman Vershynin", "authors": "Roman Vershynin", "title": "Four lectures on probabilistic methods for data science", "comments": "Lectures given at 2016 PCMI Graduate Summer School in Mathematics of\n  Data. Some typos, inaccuracies fixed", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.DS cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Methods of high-dimensional probability play a central role in applications\nfor statistics, signal processing theoretical computer science and related\nfields. These lectures present a sample of particularly useful tools of\nhigh-dimensional probability, focusing on the classical and matrix Bernstein's\ninequality and the uniform matrix deviation inequality. We illustrate these\ntools with applications for dimension reduction, network analysis, covariance\nestimation, matrix completion and sparse signal recovery. The lectures are\ngeared towards beginning graduate students who have taken a rigorous course in\nprobability but may not have any experience in data science applications.\n", "versions": [{"version": "v1", "created": "Tue, 20 Dec 2016 13:44:34 GMT"}, {"version": "v2", "created": "Sat, 4 Nov 2017 21:37:30 GMT"}], "update_date": "2017-11-07", "authors_parsed": [["Vershynin", "Roman", ""]]}, {"id": "1612.06737", "submitter": "Jan Draisma", "authors": "Jan Draisma and Florian M. Oosterhof", "title": "Markov random fields and iterated toric fibre products", "comments": "several improvements, final version", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AC math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that iterated toric fibre products from a finite collection of toric\nvarieties are defined by binomials of uniformly bounded degree. This implies\nthat Markov random fields built up from a finite collection of finite graphs\nhave uniformly bounded Markov degree.\n", "versions": [{"version": "v1", "created": "Tue, 20 Dec 2016 16:23:07 GMT"}, {"version": "v2", "created": "Wed, 7 Feb 2018 17:49:35 GMT"}], "update_date": "2018-02-08", "authors_parsed": [["Draisma", "Jan", ""], ["Oosterhof", "Florian M.", ""]]}, {"id": "1612.06967", "submitter": "Ximing Xu", "authors": "Ximing Xu, Nancy Reid and Libai Xu", "title": "Note on information bias and efficiency of composite likelihood", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Does the asymptotic variance of the maximum composite likelihood estimator of\na parameter of interest always decrease when the nuisance parameters are known?\nWill a composite likelihood necessarily become more efficient by incorporating\naddi- tional independent component likelihoods, or by using component\nlikelihoods with higher dimension? In this note we show through illustrative\nexamples that the an- swer to both questions is no, and indeed the opposite\ndirection might be observed. The role of information bias is highlighted to\nunderstand the occurrence of these paradoxical phenomenon.\n", "versions": [{"version": "v1", "created": "Wed, 21 Dec 2016 04:16:28 GMT"}], "update_date": "2016-12-22", "authors_parsed": [["Xu", "Ximing", ""], ["Reid", "Nancy", ""], ["Xu", "Libai", ""]]}, {"id": "1612.07030", "submitter": "Alexander Meister", "authors": "Friedrich Liese, Alexander Meister, Johanna Kappus", "title": "Strong Gaussian approximation of the mixture Rasch model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the famous Rasch model, which is applied to psychometric surveys\nwhen n persons under test answer m questions. The score is given by a\nrealization of a random binary (n,m)-matrix. Its (j,k)th component indicates\nwhether or not the answer of the jth person to the kth question is correct. In\nthe mixture Rasch model one assumes that the persons are chosen randomly from a\npopulation. We prove that the mixture Rasch model is asymptotically equivalent\nto a Gaussian observation scheme in Le Cam's sense as n tends to infinity and m\nis allowed to increase slowly in n. For that purpose we show a general result\non strong Gaussian approximation of the sum of independent high-dimensional\nbinary random vectors. As a first application we construct an asymptotic\nconfidence region for the difficulty parameters of the questions.\n", "versions": [{"version": "v1", "created": "Wed, 21 Dec 2016 09:46:43 GMT"}], "update_date": "2016-12-22", "authors_parsed": [["Liese", "Friedrich", ""], ["Meister", "Alexander", ""], ["Kappus", "Johanna", ""]]}, {"id": "1612.07197", "submitter": "Tung Pham Dr", "authors": "Tung Pham and Victor Panaretos", "title": "Methodology and Convergence Rates for Functional Time Series Regression", "comments": "41 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The functional linear model extends the notion of linear regression to the\ncase where the response and covariates are iid elements of an infinite\ndimensional Hilbert space. The unknown to be estimated is a Hilbert-Schmidt\noperator, whose inverse is by definition unbounded, rendering the problem of\ninference ill-posed. In this paper, we consider the more general context where\nthe sample of response/covariate pairs forms a weakly dependent stationary\nprocess in the respective product Hilbert space: simply stated, the case where\nwe have a regression between functional time series. We consider a general\nframework of potentially nonlinear processes, exploiting recent advances in the\nspectral analysis of time series. Our main result is the establishment of the\nrate of convergence for the corresponding estimators of the regression\ncoefficients, the latter forming a summable sequence in the space of\nHilbert-Schmidt operators. In a sense, our main result can be seen as a\ngeneralisation of the classical functional linear model rates, to the case of\ntime series, and rests only upon cumulant mixing conditions. While the analysis\nbecomes considerably more involved in the dependent case, the rates are\nstrikingly comparable to those of the i.i.d. case, but at the expense of an\nadditional factor caused by the necessity to estimate the spectral density\noperator at a nonparametric rate, as opposed to the parametric rate for\ncovariance operator estimation.\n", "versions": [{"version": "v1", "created": "Wed, 21 Dec 2016 15:43:02 GMT"}], "update_date": "2016-12-22", "authors_parsed": [["Pham", "Tung", ""], ["Panaretos", "Victor", ""]]}, {"id": "1612.07216", "submitter": "Housen Li", "authors": "Housen Li, Axel Munk, Hannes Sieling, Guenther Walther", "title": "The Essential Histogram", "comments": "Extension to discrete data is included. A R-package \"essHist\" is\n  available from https://CRAN.R-project.org/package=essHist", "journal-ref": "Biometrika, 2020", "doi": "10.1093/biomet/asz081", "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The histogram is widely used as a simple, exploratory display of data, but it\nis usually not clear how to choose the number and size of bins. We construct a\nconfidence set of distribution functions that optimally address the two main\ntasks of the histogram: estimating probabilities and detecting features such as\nincreases and modes in the distribution. We define the essential histogram as\nthe histogram in the confidence set with the fewest bins. Thus the essential\nhistogram is the simplest visualization of the data that optimally achieves the\nmain tasks of the histogram. The only assumption we make is that the data are\nindependent and identically distributed. We provide a fast algorithm for the\nessential histogram, and illustrate our methodology with examples. An R-package\nis available on CRAN.\n", "versions": [{"version": "v1", "created": "Wed, 21 Dec 2016 16:14:11 GMT"}, {"version": "v2", "created": "Wed, 25 Jul 2018 22:13:31 GMT"}, {"version": "v3", "created": "Tue, 28 May 2019 08:38:10 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Li", "Housen", ""], ["Munk", "Axel", ""], ["Sieling", "Hannes", ""], ["Walther", "Guenther", ""]]}, {"id": "1612.07269", "submitter": "Lamine Mili Dr.", "authors": "Mohsen Ben Hassine, Lamine Mili, Kiran Karra", "title": "A Copula Statistic for Measuring Nonlinear Multivariate Dependence", "comments": "35 pages, 16 figures, 12 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new index based on empirical copulas, termed the Copula Statistic (CoS), is\nintroduced for assessing the strength of multivariate dependence and for\ntesting statistical independence. New properties of the copulas are proved.\nThey allow us to define the CoS in terms of a relative distance function\nbetween the empirical copula, the Fr\\'echet-Hoeffding bounds and the\nindependence copula. Monte Carlo simulations reveal that for large sample\nsizes, the CoS is approximately normal. This property is utilised to develop a\nCoS-based statistical test of independence against various noisy functional\ndependencies. It is shown that this test exhibits higher statistical power than\nthe Total Information Coefficient (TICe), the Distance Correlation (dCor), the\nRandomized Dependence Coefficient (RDC), and the Copula Correlation (Ccor) for\nmonotonic and circular functional dependencies. Furthermore, the\nR2-equitability of the CoS is investigated for estimating the strength of a\ncollection of functional dependencies with additive Gaussian noise. Finally,\nthe CoS is applied to a real stock market data set from which we infer that a\nbivariate analysis is insufficient to unveil multivariate dependencies and to\ntwo gene expression data sets of the Yeast and of the E. Coli, which allow us\nto demonstrate the good performance of the CoS.\n", "versions": [{"version": "v1", "created": "Wed, 21 Dec 2016 18:46:16 GMT"}], "update_date": "2016-12-22", "authors_parsed": [["Hassine", "Mohsen Ben", ""], ["Mili", "Lamine", ""], ["Karra", "Kiran", ""]]}, {"id": "1612.07349", "submitter": "Alexis Derumigny", "authors": "Alexis Derumigny and Jean-David Fermanian", "title": "About tests of the \"simplifying\" assumption for conditional copulas", "comments": "48 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss the so-called \"simplifying assumption\" of conditional copulas in a\ngeneral framework. We introduce several tests of the latter assumption for non-\nand semiparametric copula models. Some related test procedures based on\nconditioning subsets instead of point-wise events are proposed. The limiting\ndistribution of such test statistics under the null are approximated by several\nbootstrap schemes, most of them being new. We prove the validity of a\nparticular semiparametric bootstrap scheme. Some simulations illustrate the\nrelevance of our results.\n", "versions": [{"version": "v1", "created": "Wed, 21 Dec 2016 21:45:37 GMT"}, {"version": "v2", "created": "Thu, 4 May 2017 14:06:03 GMT"}], "update_date": "2017-05-05", "authors_parsed": [["Derumigny", "Alexis", ""], ["Fermanian", "Jean-David", ""]]}, {"id": "1612.07408", "submitter": "Giorgos Afendras", "authors": "Marianthi Markatou, Yang Chen, Georgios Afendras and Bruce G. Lindsay", "title": "Statistical Distances and Their Role in Robustness", "comments": "23 pages", "journal-ref": "New Advances in Statistics and Data Science 2017, 3-26", "doi": "10.1007/978-3-319-69416-0_1", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical distances, divergences, and similar quantities have a large\nhistory and play a fundamental role in statistics, machine learning and\nassociated scientific disciplines. However, within the statistical literature,\nthis extensive role has too often been played out behind the scenes, with other\naspects of the statistical problems being viewed as more central, more\ninteresting, or more important. The behind the scenes role of statistical\ndistances shows up in estimation, where we often use estimators based on\nminimizing a distance, explicitly or implicitly, but rarely studying how the\nproperties of a distance determine the properties of the estimators. Distances\nare also prominent in goodness-of-fit, but the usual question we ask is \"how\npowerful is this method against a set of interesting alternatives\" not \"what\naspect of the distance between the hypothetical model and the alternative are\nwe measuring?\"\n  Our focus is on describing the statistical properties of some of the distance\nmeasures we have found to be most important and most visible. We illustrate the\nrobust nature of Neyman's chi-squared and the non-robust nature of Pearson's\nchi-squared statistics and discuss the concept of discretization robustness.\n", "versions": [{"version": "v1", "created": "Thu, 22 Dec 2016 01:20:27 GMT"}], "update_date": "2018-06-08", "authors_parsed": [["Markatou", "Marianthi", ""], ["Chen", "Yang", ""], ["Afendras", "Georgios", ""], ["Lindsay", "Bruce G.", ""]]}, {"id": "1612.07490", "submitter": "Masaaki Imaizumi", "authors": "Masaaki Imaizumi, Kengo Kato", "title": "A simple method to construct confidence bands in functional linear\n  regression", "comments": "29 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper develops a simple method to construct confidence bands, centered\nat a principal component analysis (PCA) based estimator, for the slope function\nin a functional linear regression model with a scalar response variable and a\nfunctional predictor variable. The PCA-based estimator is a series estimator\nwith estimated basis functions, and so construction of valid confidence bands\nfor it is a non-trivial challenge. We propose a confidence band that aims at\ncovering the slope function at \"most\" of points with a prespecified probability\n(level), and prove its asymptotic validity under suitable regularity\nconditions. Importantly, this is the first paper that derives confidence bands\nhaving theoretical justifications for the PCA-based estimator. We also propose\na practical method to choose the cut-off level used in PCA-based estimation,\nand conduct numerical studies to verify the finite sample performance of the\nproposed confidence band. Finally, we apply our methodology to spectrometric\ndata, and discuss extensions of our methodology to cases where additional\nvector-valued regressors are present.\n", "versions": [{"version": "v1", "created": "Thu, 22 Dec 2016 08:52:48 GMT"}, {"version": "v2", "created": "Fri, 23 Dec 2016 04:13:23 GMT"}, {"version": "v3", "created": "Mon, 1 May 2017 08:26:09 GMT"}], "update_date": "2017-05-02", "authors_parsed": [["Imaizumi", "Masaaki", ""], ["Kato", "Kengo", ""]]}, {"id": "1612.07583", "submitter": "Nick Whiteley Dr", "authors": "Christophe Andrieu, James Ridgway and Nick Whiteley", "title": "Sampling normalizing constants in high dimensions using inhomogeneous\n  diffusions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the task of computing normalizing constants and importance\nsampling in high dimensions, we study the dimension dependence of fluctuations\nfor additive functionals of time-inhomogeneous Langevin-type diffusions on\n$\\mathbb{R}^{d}$. The main results are nonasymptotic variance and bias bounds,\nand a central limit theorem in the $d\\to\\infty$ regime. We demonstrate that a\ntemporal discretization inherits the fluctuation properties of the underlying\ndiffusion, which are controlled at a computational cost growing at most\npolynomially with $d$. The key steps include establishing Poincar\\'e\ninequalities for time-marginal distributions of the diffusion and nonasymptotic\nbounds on deviation from Gaussianity in a martingale central limit theorem.\n", "versions": [{"version": "v1", "created": "Thu, 22 Dec 2016 12:53:20 GMT"}, {"version": "v2", "created": "Thu, 6 Sep 2018 08:45:23 GMT"}], "update_date": "2018-09-07", "authors_parsed": [["Andrieu", "Christophe", ""], ["Ridgway", "James", ""], ["Whiteley", "Nick", ""]]}, {"id": "1612.07670", "submitter": "Giorgos Afendras", "authors": "Georgios Afendras and Marianthi Markatou", "title": "The out-of-source error in multi-source cross validation-type procedures", "comments": "16 pages, 4 tables", "journal-ref": "New Advances in Statistics and Data Science 2017, 27-44", "doi": "10.1007/978-3-319-69416-0_2", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A scientific phenomenon under study may often be manifested by data arising\nfrom processes, i.e. sources, that may describe this phenomenon. In this contex\nof multi-source data, we define the \"out-of-source\" error, that is the error\ncommitted when a new observation of unknown source origin is allocated to one\nof the sources using a rule that is trained on the known labeled data. We\npresent an unbiased estimator of this error, and discuss its variance. We\nderive natural and easily verifiable assumptions under which the consistency of\nour estimator is guaranteed for a broad class of loss functions and data\ndistributions. Finally, we evaluate our theoretical results via a simulation\nstudy.\n", "versions": [{"version": "v1", "created": "Thu, 22 Dec 2016 16:02:25 GMT"}], "update_date": "2018-06-08", "authors_parsed": [["Afendras", "Georgios", ""], ["Markatou", "Marianthi", ""]]}, {"id": "1612.07704", "submitter": "Gian-Andrea Thanei", "authors": "Fadoua Balabdaoui and Gian-Andrea Thanei", "title": "Linear regression estimation in non-linear single index models", "comments": "The authors were made aware that a similar result already exists in\n  the literature: \"A generalized linear model with Gaussian regressor\n  variables\" (Brillinger, 1983)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we consider the problem of estimating the index parameter\n$\\alpha_0$ in the single index model $E[Y |X] = f_0(\\alpha_0^T X)$ with $f_0$\nthe unknown ridge function defined on $\\mathbb{R}$, $X$ a d-dimensional\ncovariate and $Y$ the response. We show that when $X$ is Gaussian, then\n$\\alpha_0$ can be consistently estimated by regressing the observed responses\n$Y_i$, $i = 1, . . ., n$ on the covariates $X_1, . . ., X_n$ after centering\nand rescaling. The method works without any additional smoothness assumptions\non $f_0$ and only requires that $cov(f_0(\\alpha_0^T X),\\alpha_0^TX) \\neq 0$,\nwhich is always satisfied by monotone and non-constant functions $f_0$. We show\nthat our estimator is asymptotically normal and give the expression with its\nasymptotic variance. The approach is illustrated through a simulation study.\n", "versions": [{"version": "v1", "created": "Thu, 22 Dec 2016 17:10:20 GMT"}, {"version": "v2", "created": "Sun, 17 Dec 2017 23:08:13 GMT"}], "update_date": "2017-12-19", "authors_parsed": [["Balabdaoui", "Fadoua", ""], ["Thanei", "Gian-Andrea", ""]]}, {"id": "1612.07728", "submitter": "Alexander Wein", "authors": "Amelia Perry and Alexander S. Wein and Afonso S. Bandeira", "title": "Statistical limits of spiked tensor models", "comments": "39 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.IT math.IT math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the statistical limits of both detecting and estimating a rank-one\ndeformation of a symmetric random Gaussian tensor. We establish upper and lower\nbounds on the critical signal-to-noise ratio, under a variety of priors for the\nplanted vector: (i) a uniformly sampled unit vector, (ii) i.i.d. $\\pm 1$\nentries, and (iii) a sparse vector where a constant fraction $\\rho$ of entries\nare i.i.d. $\\pm 1$ and the rest are zero. For each of these cases, our upper\nand lower bounds match up to a $1+o(1)$ factor as the order $d$ of the tensor\nbecomes large. For sparse signals (iii), our bounds are also asymptotically\ntight in the sparse limit $\\rho \\to 0$ for any fixed $d$ (including the $d=2$\ncase of sparse PCA). Our upper bounds for (i) demonstrate a phenomenon\nreminiscent of the work of Baik, Ben Arous and P\\'ech\\'e: an `eigenvalue' of a\nperturbed tensor emerges from the bulk at a strictly lower signal-to-noise\nratio than when the perturbation itself exceeds the bulk; we quantify the size\nof this effect. We also provide some general results for larger classes of\npriors. In particular, the large $d$ asymptotics of the threshold location\ndiffers between problems with discrete priors versus continuous priors.\nFinally, for priors (i) and (ii) we carry out the replica prediction from\nstatistical physics, which is conjectured to give the exact\ninformation-theoretic threshold for any fixed $d$.\n  Of independent interest, we introduce a new improvement to the second moment\nmethod for contiguity, on which our lower bounds are based. Our technique\nconditions away from rare `bad' events that depend on interactions between the\nsignal and noise. This enables us to close $\\sqrt{2}$-factor gaps present in\nseveral previous works.\n", "versions": [{"version": "v1", "created": "Thu, 22 Dec 2016 18:04:30 GMT"}, {"version": "v2", "created": "Tue, 24 Jan 2017 18:50:28 GMT"}], "update_date": "2017-01-25", "authors_parsed": [["Perry", "Amelia", ""], ["Wein", "Alexander S.", ""], ["Bandeira", "Afonso S.", ""]]}, {"id": "1612.07866", "submitter": "Nike Sun", "authors": "Andrea Montanari and Nike Sun", "title": "Spectral algorithms for tensor completion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the tensor completion problem, one seeks to estimate a low-rank tensor\nbased on a random sample of revealed entries. In terms of the required sample\nsize, earlier work revealed a large gap between estimation with unbounded\ncomputational resources (using, for instance, tensor nuclear norm minimization)\nand polynomial-time algorithms. Among the latter, the best statistical\nguarantees have been proved, for third-order tensors, using the sixth level of\nthe sum-of-squares (SOS) semidefinite programming hierarchy (Barak and Moitra,\n2014). However, the SOS approach does not scale well to large problem\ninstances. By contrast, spectral methods --- based on unfolding or matricizing\nthe tensor --- are attractive for their low complexity, but have been believed\nto require a much larger sample size.\n  This paper presents two main contributions. First, we propose a new\nunfolding-based method, which outperforms naive ones for symmetric $k$-th order\ntensors of rank $r$. For this result we make a study of singular space\nestimation for partially revealed matrices of large aspect ratio, which may be\nof independent interest. For third-order tensors, our algorithm matches the SOS\nmethod in terms of sample size (requiring about $rd^{3/2}$ revealed entries),\nsubject to a worse rank condition ($r\\ll d^{3/4}$ rather than $r\\ll d^{3/2}$).\nWe complement this result with a different spectral algorithm for third-order\ntensors in the overcomplete ($r\\ge d$) regime. Under a random model, this\nsecond approach succeeds in estimating tensors of rank $d\\le r \\ll d^{3/2}$\nfrom about $rd^{3/2}$ revealed entries.\n", "versions": [{"version": "v1", "created": "Fri, 23 Dec 2016 03:59:29 GMT"}], "update_date": "2016-12-26", "authors_parsed": [["Montanari", "Andrea", ""], ["Sun", "Nike", ""]]}, {"id": "1612.07901", "submitter": "Martin Kroll", "authors": "Martin Kroll", "title": "Concentration inequalities for Poisson point processes with application\n  to adaptive intensity estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive concentration inequalities for maxima of empirical processes\nassociated with Poisson point processes. The proofs are based on a careful\napplication of Ledoux's entropy method. We demonstrate the utility of the\nobtained concentration inequalities by application to adaptive intensity\nestimation.\n", "versions": [{"version": "v1", "created": "Fri, 23 Dec 2016 08:25:02 GMT"}, {"version": "v2", "created": "Wed, 18 Jul 2018 08:06:47 GMT"}], "update_date": "2018-07-19", "authors_parsed": [["Kroll", "Martin", ""]]}, {"id": "1612.07946", "submitter": "Christopher Ferrie", "authors": "Christopher Ferrie and Robin Blume-Kohout", "title": "Bayes estimator for multinomial parameters and Bhattacharyya distances", "comments": "Code available at\n  https://gist.github.com/csferrie/d7a9dcbf10c5667348613dfe5980e543", "journal-ref": null, "doi": null, "report-no": "SAND2016-12817 J", "categories": "math.ST quant-ph stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive the Bayes estimator for the parameters of a multinomial\ndistribution under two loss functions ($1-B$ and $1-B^2$) that are based on the\nBhattacharyya coefficient $B(\\vec{p},\\vec{q}) = \\sum{\\sqrt{p_kq_k}}$. We\nformulate a non-commutative generalization relevant to quantum probability\ntheory as an open problem. As an example application, we use our solution to\nfind minimax estimators for a binomial parameter under Bhattacharyya loss\n($1-B^2$).\n", "versions": [{"version": "v1", "created": "Fri, 23 Dec 2016 12:02:45 GMT"}], "update_date": "2016-12-26", "authors_parsed": [["Ferrie", "Christopher", ""], ["Blume-Kohout", "Robin", ""]]}, {"id": "1612.08113", "submitter": "Jan Vrbik", "authors": "Emmanuel Nkingi and Jan Vrbik", "title": "Confidence Regions for Parameters of Negative Binomial Distribution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a general method for the construction of a confidence region for\nthe two parameters of the Negative Binomial Distribution. This is achieved by\nexpanding the sampling distribution of Method-of-Moments estimators, using the\nCentral Limit Theorem.\n", "versions": [{"version": "v1", "created": "Fri, 23 Dec 2016 23:31:33 GMT"}], "update_date": "2016-12-28", "authors_parsed": [["Nkingi", "Emmanuel", ""], ["Vrbik", "Jan", ""]]}, {"id": "1612.08246", "submitter": "Xiaodong Yan", "authors": "Nian-Sheng Tang, Xiao-Dong Yan and Pu-Ying Zhao", "title": "Exponentially tilted likelihood inference on growing dimensional\n  unconditional moment models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Growing-dimensional data with likelihood unavailable are often encountered in\nvarious fields. This paper presents a penalized exponentially tilted likelihood\n(PETL) for variable selection and parameter estimation for growing dimensional\nunconditional moment models in the presence of correlation among variables and\nmodel misspecifica- tion. Under some regularity conditions, we investigate the\nconsistent and oracle proper- ties of the PETL estimators of parameters, and\nshow that the constrainedly PETL ratio statistic for testing contrast\nhypothesis asymptotically follows the central chi-squared distribution.\nTheoretical results reveal that the PETL approach is robust to model mis-\nspecification. We also study high-order asymptotic properties of the proposed\nPETL estimators. Simulation studies are conducted to investigate the finite\nperformance of the proposed methodologies. An example from the Boston Housing\nStudy is illustrated.\n", "versions": [{"version": "v1", "created": "Sun, 25 Dec 2016 08:06:34 GMT"}, {"version": "v2", "created": "Fri, 6 Jan 2017 07:35:17 GMT"}], "update_date": "2017-01-09", "authors_parsed": [["Tang", "Nian-Sheng", ""], ["Yan", "Xiao-Dong", ""], ["Zhao", "Pu-Ying", ""]]}, {"id": "1612.08261", "submitter": "Annika  Betken", "authors": "Annika Betken", "title": "Change point estimation based on Wilcoxon tests in the presence of\n  long-range dependence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider an estimator for the location of a shift in the mean of\nlong-range dependent sequences. The estimation is based on the two-sample\nWilcoxon statistic. Consistency and the rate of convergence for the estimated\nchange point are established. In the case of a constant shift height, the $1/n$\nconvergence rate (with $n$ denoting the number of observations), which is\ntypical under the assumption of independent observations, is also achieved for\nlong memory sequences. It is proved that if the change point height decreases\nto $0$ with a certain rate, the suitably standardized estimator converges in\ndistribution to a functional of a fractional Brownian motion. The estimator is\ntested on two well-known data sets. Finite sample behaviors are investigated in\na Monte Carlo simulation study.\n", "versions": [{"version": "v1", "created": "Sun, 25 Dec 2016 11:15:47 GMT"}], "update_date": "2016-12-28", "authors_parsed": [["Betken", "Annika", ""]]}, {"id": "1612.08280", "submitter": "Veronique Maume-Deschamps", "authors": "M Ahmed (ICJ), V Maume-Deschamps (ICJ), P Ribereau (ICJ), C\\'eline\n  Vial (ICJ)", "title": "Spatial risk measure for gaussian processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the quantitative behavior of a spatial risk measure\ncorresponding to a damage function and a region, taking into account the\nspatial dependence of the underlying process. This kind of risk measure has\nalready been introduced and studied for some max-stable processes in\n[Koch2015]. In this paper, we consider isotropic Gaussian processes and the\nexcess damage function over a threshold. We performed a simulation study and a\nreal data study.\n", "versions": [{"version": "v1", "created": "Sun, 25 Dec 2016 17:54:27 GMT"}, {"version": "v2", "created": "Fri, 30 Dec 2016 08:44:21 GMT"}], "update_date": "2017-01-02", "authors_parsed": [["Ahmed", "M", "", "ICJ"], ["Maume-Deschamps", "V", "", "ICJ"], ["Ribereau", "P", "", "ICJ"], ["Vial", "C\u00e9line", "", "ICJ"]]}, {"id": "1612.08321", "submitter": "Nathan Kallus", "authors": "Nathan Kallus", "title": "Generalized Optimal Matching Methods for Causal Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML math.OC math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop an encompassing framework for matching, covariate balancing, and\ndoubly-robust methods for causal inference from observational data called\ngeneralized optimal matching (GOM). The framework is given by generalizing a\nnew functional-analytical formulation of optimal matching, giving rise to the\nclass of GOM methods, for which we provide a single unified theory to analyze\ntractability, consistency, and efficiency. Many commonly used existing methods\nare included in GOM and, using their GOM interpretation, can be extended to\noptimally and automatically trade off balance for variance and outperform their\nstandard counterparts. As a subclass, GOM gives rise to kernel optimal matching\n(KOM), which, as supported by new theoretical and empirical results, is notable\nfor combining many of the positive properties of other methods in one. KOM,\nwhich is solved as a linearly-constrained convex-quadratic optimization\nproblem, inherits both the interpretability and model-free consistency of\nmatching but can also achieve the $\\sqrt{n}$-consistency of well-specified\nregression and the efficiency and robustness of doubly robust methods. In\nsettings of limited overlap, KOM enables a very transparent method for interval\nestimation for partial identification and robust coverage. We demonstrate these\nbenefits in examples with both synthetic and real data\n", "versions": [{"version": "v1", "created": "Mon, 26 Dec 2016 03:58:42 GMT"}, {"version": "v2", "created": "Thu, 15 Jun 2017 17:50:00 GMT"}, {"version": "v3", "created": "Fri, 27 Oct 2017 14:29:37 GMT"}], "update_date": "2017-10-30", "authors_parsed": [["Kallus", "Nathan", ""]]}, {"id": "1612.08365", "submitter": "Xiaodong Yan", "authors": "Yan Xiao-Dong and Zhao Xing-Qiu", "title": "Optimal Model Averaging Estimation in High-dimensional Censored Linear\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article considers ultrahigh dimensional prediction problems with\ncensored response vari- ables. We propose a two-step model averaging procedure\nfor improving prediction accuracy of the true conditional mean of a censored\nresponse variable. The first step is to construct a class of candidate models,\neach with low-dimensional covariates. For this, a feature screening procedure\nis developed to separate the active and inactive predictors through a fused\nmean- variance index and group covariates with similar size of index together\nto form regression models with censored response variables. The new model-free\nscreening method can easi- ly deal with many types of predictors and response\nvariables, such as discrete, categorical and continuous variables, still works\nwell when predictors have heavy-tailed distributions or strongly dependend on\neach other, and enjoys rank consistency properties under mild regularity\nconditions. The second step is to find the optimal model weights for averaging\nby adapting a delete-one Mallows criterion, where the standard constraint that\nweights sum to one is removed. The theoretical results show that the delete-one\nMallows criterion achieves the lowest possible prediction loss asymptotically.\nNumerical studies demonstrate the su- perior performance of the proposed\nvariable screening and model averaging procedures over existing methods.\n", "versions": [{"version": "v1", "created": "Mon, 26 Dec 2016 11:13:35 GMT"}, {"version": "v2", "created": "Tue, 20 Jun 2017 05:32:51 GMT"}, {"version": "v3", "created": "Wed, 21 Jun 2017 04:34:51 GMT"}], "update_date": "2017-06-22", "authors_parsed": [["Xiao-Dong", "Yan", ""], ["Xing-Qiu", "Zhao", ""]]}, {"id": "1612.08368", "submitter": "Cecilia Jarne", "authors": "C. Jarne, M. Caruso", "title": "Markovian simulation for ancestors trees", "comments": null, "journal-ref": null, "doi": "10.1016/j.cnsns.2018.12.004", "report-no": null, "categories": "q-bio.PE math.ST physics.bio-ph stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a computational model to reconstruct trees of ancestors for\nanimals with sexual reproduction. Through a recursive algorithm combined with a\nrandom number generator, it is possible to reproduce the number of ancestors\nfor each generation and use it to constraint the maximum number of the\nfollowing generation. This new model allows to consider the reproductive\npreferences of particular species and combine several trees to simulate the\nbehavior of a population. It is also possible to obtain a description\nanalytically, considering the simulation as a theoretical stochastic process.\nSuch process can be generalized in order to use an algorithm associated with it\nto simulate other similar processes of stochastic nature. The simulation is\nbased in the theoretical model previously presented before.\n", "versions": [{"version": "v1", "created": "Mon, 26 Dec 2016 12:14:24 GMT"}, {"version": "v2", "created": "Thu, 9 Mar 2017 17:03:11 GMT"}, {"version": "v3", "created": "Tue, 17 Jul 2018 13:39:44 GMT"}], "update_date": "2019-08-19", "authors_parsed": [["Jarne", "C.", ""], ["Caruso", "M.", ""]]}, {"id": "1612.08506", "submitter": "Mihailo Stojnic", "authors": "Mihailo Stojnic", "title": "Generic and lifted probabilistic comparisons -- max replaces minmax", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce a collection of powerful statistical comparison\nresults. We first present the results that we obtained while developing a\ngeneral comparison concept. After that we introduce a separate lifting\nprocedure that is a comparison concept on its own. We then show how in certain\nscenarios the lifting procedure basically represents a substantial upgrade over\nthe general strategy. We complement the introduced results with a fairly large\ncollection of numerical experiments that are in an overwhelming agreement with\nwhat the theory predicts. We also show how many well known comparison results\n(e.g. Slepian's max and Gordon's minmax principle) can be obtained as special\ncases. Moreover, it turns out that the minmax principle can be viewed as a\nsingle max principle as well. The range of applications is enormous. It starts\nwith revisiting many of the results we created in recent years in various\nmathematical fields and recognizing that they are fully self-contained as their\nstarting blocks are specialized variants of the concepts introduced here.\nFurther upgrades relate to core comparison extensions on the one side and more\npractically oriented modifications on the other. Those that we deem the most\nimportant we discuss in several separate companion papers to ensure preserving\nthe introductory elegance and simplicity of what is presented here.\n", "versions": [{"version": "v1", "created": "Tue, 27 Dec 2016 06:21:07 GMT"}], "update_date": "2016-12-28", "authors_parsed": [["Stojnic", "Mihailo", ""]]}, {"id": "1612.08516", "submitter": "Mihailo Stojnic", "authors": "Mihailo Stojnic", "title": "Fully bilinear generic and lifted random processes comparisons", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In our companion paper \\cite{Stojnicgscomp16} we introduce a collection of\nfairly powerful statistical comparison results. They relate to a general\ncomparison concept and its an upgrade that we call lifting procedure. Here we\nprovide a different generic principle (which we call fully bilinear) that in\ncertain cases turns out to be stronger than the corresponding one from\n\\cite{Stojnicgscomp16}. Moreover, we also show how the principle that we\nintroduce here can also be pushed through the lifting machinery of\n\\cite{Stojnicgscomp16}. Finally, as was the case in \\cite{Stojnicgscomp16},\nhere we also show how the well known Slepian's max and Gordon's minmax\ncomparison principles can be obtained as special cases of the mechanisms that\nwe present here. We also create their lifted upgrades which happen to be\nstronger than the corresponding ones in \\cite{Stojnicgscomp16}. A fairly large\ncollection of results obtained through numerical experiments is also provided.\nIt is observed that these results are in an excellent agreement with what the\ntheory predicts.\n", "versions": [{"version": "v1", "created": "Tue, 27 Dec 2016 07:03:29 GMT"}], "update_date": "2016-12-28", "authors_parsed": [["Stojnic", "Mihailo", ""]]}, {"id": "1612.08526", "submitter": "Yuta Koike", "authors": "Yuta Koike, Zhi Liu", "title": "Asymptotic properties of the realized skewness and related statistics", "comments": "40 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent empirical work of Amaya et al. (2015) has pointed out that the\nrealized skewness, which is the sample skewness of intraday high-frequency\nreturns of a financial asset, serves as forecasting future returns in the\ncross-section. Theoretically, the realized skewness is interpreted as the\nsample skewness of returns of a discretely observed semimartingale in a fixed\ninterval. The aim of this paper is to investigate the asymptotic property of\nthe realized skewness in such a framework. We also develop an estimation theory\nfor the limiting characteristic of the realized skewness in a situation where\nmeasurement errors are present and sampling times are stochastic.\n", "versions": [{"version": "v1", "created": "Tue, 27 Dec 2016 07:58:52 GMT"}, {"version": "v2", "created": "Fri, 19 Jan 2018 10:35:49 GMT"}], "update_date": "2018-01-22", "authors_parsed": [["Koike", "Yuta", ""], ["Liu", "Zhi", ""]]}, {"id": "1612.08586", "submitter": "Norbert Henze", "authors": "Norbert Henze, Stefan Koch", "title": "On a test of normality based on the empirical moment generating function", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide the lacking theory for a test of normality based on the empirical\nmoment generating function.\n", "versions": [{"version": "v1", "created": "Tue, 27 Dec 2016 11:58:10 GMT"}], "update_date": "2016-12-28", "authors_parsed": [["Henze", "Norbert", ""], ["Koch", "Stefan", ""]]}, {"id": "1612.08804", "submitter": "Dane Taylor", "authors": "Dane Taylor, Juan G. Restrepo and Francois G. Meyer", "title": "Ensemble-based estimates of eigenvector error for empirical covariance\n  matrices", "comments": "24 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cond-mat.dis-nn math.PR stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Covariance matrices are fundamental to the analysis and forecast of economic,\nphysical and biological systems. Although the eigenvalues $\\{\\lambda_i\\}$ and\neigenvectors $\\{{\\bf u}_i\\}$ of a covariance matrix are central to such\nendeavors, in practice one must inevitably approximate the covariance matrix\nbased on data with finite sample size $n$ to obtain empirical eigenvalues\n$\\{\\tilde{\\lambda}_i\\}$ and eigenvectors $\\{\\tilde{{\\bf u}}_i\\}$, and therefore\nunderstanding the error so introduced is of central importance. We analyze\neigenvector error $\\|{\\bf u}_i - \\tilde{{\\bf u}}_i \\|^2$ while leveraging the\nassumption that the true covariance matrix having size $p$ is drawn from a\nmatrix ensemble with known spectral properties---particularly, we assume the\ndistribution of population eigenvalues weakly converges as $p\\to\\infty$ to a\nspectral density $\\rho(\\lambda)$ and that the spacing between population\neigenvalues is similar to that for the Gaussian orthogonal ensemble. Our\napproach complements previous analyses of eigenvector error that require the\nfull set of eigenvalues to be known, which can be computationally infeasible\nwhen $p$ is large. To provide a scalable approach for uncertainty\nquantification of eigenvector error, we consider a fixed eigenvalue $\\lambda$\nand approximate the distribution of the expected square error $r=\n\\mathbb{E}\\left[\\| {\\bf u}_i - \\tilde{{\\bf u}}_i \\|^2\\right]$ across the matrix\nensemble for all ${\\bf u}_i$ associated with $\\lambda_i=\\lambda$. We find, for\nexample, that for sufficiently large matrix size $p$ and sample size $n>p$, the\nprobability density of $r$ scales as $1/nr^2$. This power-law scaling implies\nthat eigenvector error is extremely heterogeneous---even if $r$ is very small\nfor most eigenvectors, it can be large for others with non-negligible\nprobability. We support this and further results with numerical experiments.\n", "versions": [{"version": "v1", "created": "Wed, 28 Dec 2016 05:04:35 GMT"}, {"version": "v2", "created": "Wed, 28 Feb 2018 19:40:23 GMT"}], "update_date": "2018-03-02", "authors_parsed": [["Taylor", "Dane", ""], ["Restrepo", "Juan G.", ""], ["Meyer", "Francois G.", ""]]}, {"id": "1612.08859", "submitter": "Vladimir Vovk", "authors": "Vladimir Vovk", "title": "On the concept of Bernoulliness", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The first part of this paper is another English translation of a 1986 note.\nIt gives a natural definition of a finite Bernoulli sequence (i.e., a typical\nrealization of a finite sequence of binary IID trials) and compares it with the\nKolmogorov--Martin-Lof definition, which is interpreted as defining\nexchangeable sequences. The appendix gives the historical background and\nproofs.\n", "versions": [{"version": "v1", "created": "Wed, 28 Dec 2016 11:40:55 GMT"}], "update_date": "2016-12-30", "authors_parsed": [["Vovk", "Vladimir", ""]]}, {"id": "1612.08923", "submitter": "Luis Mendo", "authors": "Luis Mendo", "title": "An asymptotically optimal Bernoulli factory for certain functions that\n  can be expressed as power series", "comments": "Minor corrections; format", "journal-ref": null, "doi": "10.1016/j.spa.2018.11.017", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a sequence of independent Bernoulli variables with unknown parameter\n$p$, and a function $f$ expressed as a power series with non-negative\ncoefficients that sum to at most $1$, an algorithm is presented that produces a\nBernoulli variable with parameter $f(p)$. In particular, the algorithm can\nsimulate $f(p)=p^a$, $a\\in(0,1)$. For functions with a derivative growing at\nleast as $f(p)/p$ for $p\\rightarrow 0$, the average number of inputs required\nby the algorithm is asymptotically optimal among all simulations that are fast\nin the sense of Nacu and Peres. A non-randomized version of the algorithm is\nalso given. Some extensions are discussed.\n", "versions": [{"version": "v1", "created": "Wed, 28 Dec 2016 16:43:13 GMT"}, {"version": "v2", "created": "Fri, 10 Feb 2017 13:26:11 GMT"}, {"version": "v3", "created": "Tue, 14 Feb 2017 00:53:28 GMT"}, {"version": "v4", "created": "Thu, 6 Sep 2018 14:01:14 GMT"}, {"version": "v5", "created": "Tue, 18 Dec 2018 11:37:14 GMT"}], "update_date": "2018-12-19", "authors_parsed": [["Mendo", "Luis", ""]]}, {"id": "1612.09004", "submitter": "Cheikh Tidiane Seck", "authors": "Cheikh Tidiane Seck, Diam Ba, Gane Samb Lo", "title": "Uniform in bandwidth consistency for the transformation kernel estimator\n  of copulas", "comments": "arXiv admin note: text overlap with arXiv:1611.05420", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we establish the uniform in bandwidth consistency for the\ntransformation kernel estimator of copulas introduced in [Omelka et al.(2009)].\nTo this end, we first prove a uniform in bandwidth law of the iterated\nlogarithm for the maximal deviation of this estimator from its expectation. We\nthen show that, as n goes to infinity, the bias of the estimator converges to\nzero uniformly in the bandwidth h, varying over a suitable interval. A\npractical method of selecting the optimal bandwidth is also presented. Finally,\nwe make conclusive simulation experiments showing the performance of the\nestimator in finite samples.\n", "versions": [{"version": "v1", "created": "Wed, 28 Dec 2016 23:16:27 GMT"}], "update_date": "2016-12-30", "authors_parsed": [["Seck", "Cheikh Tidiane", ""], ["Ba", "Diam", ""], ["Lo", "Gane Samb", ""]]}, {"id": "1612.09252", "submitter": "Galen Reeves", "authors": "Galen Reeves", "title": "Conditional Central Limit Theorems for Gaussian Projections", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the question of when projections of a high-dimensional\nrandom vector are approximately Gaussian. This problem has been studied\npreviously in the context of high-dimensional data analysis, where the focus is\non low-dimensional projections of high-dimensional point clouds. The focus of\nthis paper is on the typical behavior when the projections are generated by an\ni.i.d. Gaussian projection matrix. The main results are bounds on the deviation\nbetween the conditional distribution of the projections and a Gaussian\napproximation, where the conditioning is on the projection matrix. The bounds\nare given in terms of the quadratic Wasserstein distance and relative entropy\nand are stated explicitly as a function of the number of projections and\ncertain key properties of the random vector. The proof uses Talagrand's\ntransportation inequality and a general integral-moment inequality for mutual\ninformation. Applications to random linear estimation and compressed sensing\nare discussed.\n", "versions": [{"version": "v1", "created": "Thu, 29 Dec 2016 19:18:29 GMT"}, {"version": "v2", "created": "Fri, 30 Dec 2016 15:31:06 GMT"}], "update_date": "2017-01-02", "authors_parsed": [["Reeves", "Galen", ""]]}, {"id": "1612.09265", "submitter": "Lev B Klebanov", "authors": "Lev B. Klebanov, Ashot V. Kakosyan and Andrea Karlova", "title": "Outliers, the Law of Large Numbers, Index of Stability and Heavy Tails", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are trying to give a mathematically correct definition of outliers. Our\napproach is based on the distance between two last order statistics and appears\nto be connected to the law of large numbers. Key words: outliers, law of large\nnumbers, heavy tails, stability index.\n", "versions": [{"version": "v1", "created": "Thu, 29 Dec 2016 19:46:57 GMT"}], "update_date": "2016-12-30", "authors_parsed": [["Klebanov", "Lev B.", ""], ["Kakosyan", "Ashot V.", ""], ["Karlova", "Andrea", ""]]}, {"id": "1612.09305", "submitter": "Daniel Roy", "authors": "Haosui Duanmu and Daniel M. Roy", "title": "On Extended Admissible Procedures and their Nonstandard Bayes Risk", "comments": "45 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.LO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For finite parameter spaces under finite loss, every Bayes procedure derived\nfrom a prior with full support is admissible, and every admissible procedure is\nBayes. This relationship already breaks down once we move to finite-dimensional\nEuclidean parameter spaces. Compactness and strong regularity conditions\nsuffice to repair the relationship, but without these conditions, admissible\nprocedures need not be Bayes. Under strong regularity conditions, admissible\nprocedures can be shown to be the limits of Bayes procedures. Under even\nstricter conditions, they are generalized Bayes, i.e., they minimize the Bayes\nrisk with respect to an improper prior. In both these cases, one must venture\nbeyond the strict confines of Bayesian analysis. Using methods from\nmathematical logic and nonstandard analysis, we introduce the class of\nnonstandard Bayes decision procedures---namely, those whose Bayes risk with\nrespect to some prior is within an infinitesimal of the optimal Bayes risk.\nAmong procedures with finite risk functions, we show that a decision procedure\nis extended admissible if and only if its nonstandard extension is nonstandard\nBayes. For problems with continuous risk functions defined on metric parameter\nspaces, we derive a nonstandard analogue of Blyth's method that can be used to\nestablish the admissibility of a procedure. We also apply the nonstandard\ntheory to derive a purely standard theorem: when risk functions are continuous\non a compact Hausdorff parameter space, a procedure is extended admissible if\nand only if it is Bayes.\n", "versions": [{"version": "v1", "created": "Thu, 29 Dec 2016 21:00:55 GMT"}, {"version": "v2", "created": "Mon, 13 Feb 2017 17:22:04 GMT"}], "update_date": "2017-02-17", "authors_parsed": [["Duanmu", "Haosui", ""], ["Roy", "Daniel M.", ""]]}, {"id": "1612.09415", "submitter": "Ryan Tibshirani", "authors": "Ryan J. Tibshirani, Saharon Rosset", "title": "Excess Optimism: How Biased is the Apparent Error of an Estimator Tuned\n  by SURE?", "comments": "39 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nearly all estimators in statistical prediction come with an associated\ntuning parameter, in one way or another. Common practice, given data, is to\nchoose the tuning parameter value that minimizes a constructed estimate of the\nprediction error of the estimator; we focus on Stein's unbiased risk estimator,\nor SURE (Stein, 1981; Efron, 1986) which forms an unbiased estimate of the\nprediction error by augmenting the observed training error with an estimate of\nthe degrees of freedom of the estimator. Parameter tuning via SURE minimization\nhas been advocated by many authors, in a wide variety of problem settings, and\nin general, it is natural to ask: what is the prediction error of the\nSURE-tuned estimator? An obvious strategy would be simply use the apparent\nerror estimate as reported by SURE, i.e., the value of the SURE criterion at\nits minimum, to estimate the prediction error of the SURE-tuned estimator. But\nthis is no longer unbiased; in fact, we would expect that the minimum of the\nSURE criterion is systematically biased downwards for the true prediction\nerror. In this paper, we formally describe and study this bias.\n", "versions": [{"version": "v1", "created": "Fri, 30 Dec 2016 08:07:51 GMT"}, {"version": "v2", "created": "Sun, 15 Jan 2017 03:04:25 GMT"}], "update_date": "2017-01-17", "authors_parsed": [["Tibshirani", "Ryan J.", ""], ["Rosset", "Saharon", ""]]}, {"id": "1612.09434", "submitter": "Frederic Chazal", "authors": "Fr\\'ed\\'eric Chazal (DATASHAPE), Ilaria Giulini (DATASHAPE), Bertrand\n  Michel (LSTA)", "title": "Data driven estimation of Laplace-Beltrami operator", "comments": null, "journal-ref": "30th Conference on Neural Information Processing Systems (NIPS\n  2016), Dec 2016, Barcelona, Spain. 30th Conference on Neural Information\n  Processing Systems (NIPS 2016), Barcelona, Spain., 2016", "doi": null, "report-no": null, "categories": "cs.CG cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Approximations of Laplace-Beltrami operators on manifolds through graph\nLapla-cians have become popular tools in data analysis and machine learning.\nThese discretized operators usually depend on bandwidth parameters whose tuning\nremains a theoretical and practical problem. In this paper, we address this\nproblem for the unnormalized graph Laplacian by establishing an oracle\ninequality that opens the door to a well-founded data-driven procedure for the\nbandwidth selection. Our approach relies on recent results by Lacour and\nMassart [LM15] on the so-called Lepski's method.\n", "versions": [{"version": "v1", "created": "Fri, 30 Dec 2016 09:33:07 GMT"}], "update_date": "2017-01-02", "authors_parsed": [["Chazal", "Fr\u00e9d\u00e9ric", "", "DATASHAPE"], ["Giulini", "Ilaria", "", "DATASHAPE"], ["Michel", "Bertrand", "", "LSTA"]]}]