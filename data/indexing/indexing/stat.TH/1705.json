[{"id": "1705.00048", "submitter": "Julyan Arbel", "authors": "Olivier Marchal (Universit\\'e de Lyon) and Julyan Arbel (Inria\n  Grenoble)", "title": "On the sub-Gaussianity of the Beta and Dirichlet distributions", "comments": "13 pages, 2 figures", "journal-ref": "Electronic Communications in Probability 2017, Vol. 22, paper no.\n  54, 1-14", "doi": "10.1214/17-ECP92", "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We obtain the optimal proxy variance for the sub-Gaussianity of Beta\ndistribution, thus proving upper bounds recently conjectured by Elder (2016).\nWe provide different proof techniques for the symmetrical (around its mean)\ncase and the non-symmetrical case. The technique in the latter case relies on\nstudying the ordinary differential equation satisfied by the Beta\nmoment-generating function known as the confluent hypergeometric function. As a\nconsequence, we derive the optimal proxy variance for the Dirichlet\ndistribution, which is apparently a novel result. We also provide a new proof\nof the optimal proxy variance for the Bernoulli distribution, and discuss in\nthis context the proxy variance relation to log-Sobolev inequalities and\ntransport inequalities.\n", "versions": [{"version": "v1", "created": "Fri, 28 Apr 2017 19:34:41 GMT"}, {"version": "v2", "created": "Mon, 25 Sep 2017 11:04:46 GMT"}], "update_date": "2017-10-18", "authors_parsed": [["Marchal", "Olivier", "", "Universit\u00e9 de Lyon"], ["Arbel", "Julyan", "", "Inria\n  Grenoble"]]}, {"id": "1705.00083", "submitter": "Kevin Yang", "authors": "Kevin Yang", "title": "Bulk Eigenvalue Correlation Statistics of Random Biregular Bipartite\n  Graphs", "comments": "26 pages; includes minor revision", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.CO math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is the second chapter of three of the author's undergraduate\nthesis. In this paper, we consider the random matrix ensemble given by $(d_b,\nd_w)$-regular graphs on $M$ black vertices and $N$ white vertices, where $d_b\n\\in [N^{\\gamma}, N^{2/3 - \\gamma}]$ for any $\\gamma > 0$. We simultaneously\nprove that the bulk eigenvalue correlation statistics for both normalized\nadjacency matrices and their corresponding covariance matrices are stable for\nshort times. Combined with an ergodicity analysis of the Dyson Brownian motion\nin another paper, this proves universality of bulk eigenvalue correlation\nstatistics, matching normalized adjacency matrices with the GOE and the\ncorresponding covariance matrices with the Gaussian Wishart Ensemble.\n", "versions": [{"version": "v1", "created": "Fri, 28 Apr 2017 21:41:12 GMT"}, {"version": "v2", "created": "Mon, 15 Jan 2018 10:00:43 GMT"}, {"version": "v3", "created": "Tue, 16 Jan 2018 20:20:46 GMT"}], "update_date": "2018-01-18", "authors_parsed": [["Yang", "Kevin", ""]]}, {"id": "1705.00126", "submitter": "Kevin Yang", "authors": "Kevin Yang", "title": "Local Correlation and Gap Statistics under Dyson Brownian Motion for\n  Covariance Matrices", "comments": "32 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is the third chapter of three of the author's undergraduate\nthesis. In this paper, we study the convergence of local bulk statistics for\nlinearized covariance matrices under Dyson's Brownian motion. We consider\ndeterministic initial data $V$ approximate the Dyson Brownian motion for\nlinearized covariance matrices by the Wigner flow. Using universality results\nfor the Wigner flow, we deduce universality for the linearized covariance\nmatrices. We deduce bulk universality of averaged bulk correlation functions\nfor both biregular bipartite graphs and honest covariance matrices. We also\ndeduce a weak level repulsion estimate for the Dyson Brownian motion of\nlinearized covariance matrices.\n", "versions": [{"version": "v1", "created": "Sat, 29 Apr 2017 03:55:13 GMT"}], "update_date": "2017-05-02", "authors_parsed": [["Yang", "Kevin", ""]]}, {"id": "1705.00136", "submitter": "Seyoung Yun", "authors": "Milan Vojnovic and Se-Young Yun", "title": "Parameter Estimation for Thurstone Choice Models", "comments": "55 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the estimation accuracy of individual strength parameters of a\nThurstone choice model when each input observation consists of a choice of one\nitem from a set of two or more items (so called top-1 lists). This model\naccommodates the well-known choice models such as the Luce choice model for\ncomparison sets of two or more items and the Bradley-Terry model for pair\ncomparisons.\n  We provide a tight characterization of the mean squared error of the maximum\nlikelihood parameter estimator. We also provide similar characterizations for\nparameter estimators defined by a rank-breaking method, which amounts to\ndeducing one or more pair comparisons from a comparison of two or more items,\nassuming independence of these pair comparisons, and maximizing a likelihood\nfunction derived under these assumptions. We also consider a related binary\nclassification problem where each individual parameter takes value from a set\nof two possible values and the goal is to correctly classify all items within a\nprescribed classification error.\n", "versions": [{"version": "v1", "created": "Sat, 29 Apr 2017 06:15:54 GMT"}], "update_date": "2017-05-02", "authors_parsed": [["Vojnovic", "Milan", ""], ["Yun", "Se-Young", ""]]}, {"id": "1705.00163", "submitter": "Iickho Song", "authors": "Iickho Song", "title": "A Proof of the Explicit Formula for Product Moments of Multivariate\n  Gaussian Random Variables", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A detailed proof of a recent result on explicit formulae for the product\nmoments $E \\left \\{ X_1^{a_1} X_2^{a_2} \\cdots X_n^{a_n}\\right \\}$ of\nmultivariate Gaussian random variables is provided in this note.\n", "versions": [{"version": "v1", "created": "Sat, 29 Apr 2017 09:53:59 GMT"}], "update_date": "2017-05-02", "authors_parsed": [["Song", "Iickho", ""]]}, {"id": "1705.00170", "submitter": "Nikolas Nuesken", "authors": "A. B. Duncan, N. Nuesken, G. A. Pavliotis", "title": "Using Perturbed Underdamped Langevin Dynamics to Efficiently Sample from\n  Probability Distributions", "comments": "45 pages, 4 figures", "journal-ref": null, "doi": "10.1007/s10955-017-1906-8", "report-no": null, "categories": "math.PR math-ph math.MP math.NA math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce and analyse Langevin samplers that consist of\nperturbations of the standard underdamped Langevin dynamics. The perturbed\ndynamics is such that its invariant measure is the same as that of the\nunperturbed dynamics. We show that appropriate choices of the perturbations can\nlead to samplers that have improved properties, at least in terms of reducing\nthe asymptotic variance. We present a detailed analysis of the new Langevin\nsampler for Gaussian target distributions. Our theoretical results are\nsupported by numerical experiments with non-Gaussian target measures.\n", "versions": [{"version": "v1", "created": "Sat, 29 Apr 2017 11:32:46 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["Duncan", "A. B.", ""], ["Nuesken", "N.", ""], ["Pavliotis", "G. A.", ""]]}, {"id": "1705.00231", "submitter": "Marcelo Moreira", "authors": "Marcelo J. Moreira, Geert Ridder", "title": "Optimal Invariant Tests in an Instrumental Variables Regression With\n  Heteroskedastic and Autocorrelated Errors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST econ.EM stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper uses model symmetries in the instrumental variable (IV) regression\nto derive an invariant test for the causal structural parameter. Contrary to\npopular belief, we show there exist model symmetries when equation errors are\nheteroskedastic and autocorrelated (HAC). Our theory is consistent with\nexisting results for the homoskedastic model (Andrews, Moreira and Stock(2006}\nand Chamberlain (2007}), but in general uses information on the structural\nparameter beyond the Anderson-Rubin, score, and rank statistics. This suggests\nthat tests based only the Anderson-Rubin and score statistics discard\ninformation on the causal parameter of interest. We apply our theory to\nconstruct designs in which these tests indeed have power arbitrarily close to\nsize. Other tests, including other adaptations to the CLR test, do not suffer\nthe same deficiencies. Finally, we use the model symmetries to propose novel\nweighted-average power tests for the HAC-IV model.\n", "versions": [{"version": "v1", "created": "Sat, 29 Apr 2017 20:04:51 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Moreira", "Marcelo J.", ""], ["Ridder", "Geert", ""]]}, {"id": "1705.00252", "submitter": "Jon A. Wellner", "authors": "Nilanjana Laha and Jon A. Wellner", "title": "Bi-$s^*$-concave distributions", "comments": "30 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new shape-constrained class of distribution functions on R,\nthe bi-$s^*$-concave class. In parallel to results of D\\\"umbgen, Kolesnyk, and\nWilke (2017) for what they called the class of bi-log-concave distribution\nfunctions, we show that every s-concave density f has a bi-$s^*$-concave\ndistribution function $F$ and that every bi-$s^*$-concave distribution function\nsatisfies $\\gamma (F) \\le 1/(1+s)$ where finiteness of $$ \\gamma (F) \\equiv\n\\sup_{x} F(x) (1-F(x)) \\frac{| f' (x)|}{f^2 (x)}, $$ the Cs\\\"org\\H{o} -\nR\\'ev\\'esz constant of F, plays an important role in the theory of quantile\nprocesses on $R$.\n", "versions": [{"version": "v1", "created": "Sat, 29 Apr 2017 23:35:14 GMT"}, {"version": "v2", "created": "Wed, 10 May 2017 22:47:31 GMT"}], "update_date": "2017-05-12", "authors_parsed": [["Laha", "Nilanjana", ""], ["Wellner", "Jon A.", ""]]}, {"id": "1705.00395", "submitter": "Lingzhou Xue", "authors": "Wei Luo, Lingzhou Xue, Jiawei Yao and Xiufan Yu", "title": "Inverse Moment Methods for Sufficient Forecasting using High-Dimensional\n  Predictors", "comments": "21 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.AP stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider forecasting a single time series using a large number of\npredictors in the presence of a possible nonlinear forecast function. Assuming\nthat the predictors affect the response through the latent factors, we propose\nto first conduct factor analysis and then apply sufficient dimension reduction\non the estimated factors, to derive the reduced data for subsequent\nforecasting. Using directional regression and the inverse third-moment method\nin the stage of sufficient dimension reduction, the proposed methods can\ncapture the non-monotone effect of factors on the response. We also allow a\ndiverging number of factors and only impose general regularity conditions on\nthe distribution of factors, avoiding the undesired time reversibility of the\nfactors by the latter. These make the proposed methods fundamentally more\napplicable than the sufficient forecasting method in Fan et al. (2017). The\nproposed methods are demonstrated in both simulation studies and an empirical\nstudy of forecasting monthly macroeconomic data from 1959 to 2016. Also, our\ntheory contributes to the literature of sufficient dimension reduction, as it\nincludes an invariance result, a path to perform sufficient dimension reduction\nunder the high-dimensional setting without assuming sparsity, and the\ncorresponding order-determination procedure.\n", "versions": [{"version": "v1", "created": "Mon, 1 May 2017 01:10:35 GMT"}, {"version": "v2", "created": "Wed, 21 Apr 2021 04:56:25 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Luo", "Wei", ""], ["Xue", "Lingzhou", ""], ["Yao", "Jiawei", ""], ["Yu", "Xiufan", ""]]}, {"id": "1705.00465", "submitter": "Ana Ferreira", "authors": "Cl\\'ement Dombry and Ana Ferreira", "title": "Maximum likelihood estimators based on the block maxima method", "comments": "29 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The extreme value index is a fundamental parameter in univariate Extreme\nValue Theory (EVT). It captures the tail behavior of a distribution and is\ncentral in the extrapolation beyond observed data. Among other semi-parametric\nmethods (such as the popular Hill's estimator), the Block Maxima (BM) and\nPeaks-Over-Threshold (POT) methods are widely used for assessing the extreme\nvalue index and related normalizing constants. We provide asymptotic theory for\nthe maximum likelihood estimators (MLE) based on the BM method. Our main result\nis the asymptotic normality of the MLE with a non-trivial bias depending on the\nextreme value index and on the so-called second order parameter. Our approach\ncombines asymptotic expansions of the likelihood process and of the empirical\nquantile process of block maxima. The results permit to complete the comparison\nof most common semi-parametric estimators in EVT (MLE and probability weighted\nmoment estimators based on the POT or BM methods) through their asymptotic\nvariances, biases and optimal mean square errors.\n", "versions": [{"version": "v1", "created": "Mon, 1 May 2017 10:43:41 GMT"}], "update_date": "2017-05-02", "authors_parsed": [["Dombry", "Cl\u00e9ment", ""], ["Ferreira", "Ana", ""]]}, {"id": "1705.00586", "submitter": "Daisuke Kurisu", "authors": "Kengo Kato and Daisuke Kurisu", "title": "Bootstrap confidence bands for spectral estimation of L\\'evy densities\n  under high-frequency observations", "comments": "50pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper develops bootstrap methods to construct uniform confidence bands\nfor nonparametric spectral estimation of L\\'{e}vy densities under\nhigh-frequency observations. We assume that we observe $n$ discrete\nobservations at frequency $1/\\Delta > 0$, and work with the high-frequency\nsetup where $\\Delta = \\Delta_{n} \\to 0$ and $n\\Delta \\to \\infty$ as $n \\to\n\\infty$. We employ a spectral (or Fourier-based) estimator of the L\\'{e}vy\ndensity, and develop novel implementations of Gaussian multiplier (or wild) and\nempirical (or Efron's) bootstraps to construct confidence bands for the\nspectral estimator on a compact set that does not intersect the origin. We\nprovide conditions under which the proposed confidence bands are asymptotically\nvalid. Our confidence bands are shown to be asymptotically valid for a wide\nclass of L\\'{e}vy processes. We also develop a practical method for bandwidth\nselection, and conduct simulation studies to investigate the finite sample\nperformance of the proposed confidence bands.\n", "versions": [{"version": "v1", "created": "Mon, 1 May 2017 16:48:58 GMT"}, {"version": "v2", "created": "Mon, 15 May 2017 05:41:45 GMT"}, {"version": "v3", "created": "Wed, 17 May 2017 06:03:14 GMT"}, {"version": "v4", "created": "Mon, 29 May 2017 04:09:15 GMT"}], "update_date": "2017-05-30", "authors_parsed": [["Kato", "Kengo", ""], ["Kurisu", "Daisuke", ""]]}, {"id": "1705.00807", "submitter": "Jiantao Jiao", "authors": "Jiantao Jiao, Yanjun Han, Tsachy Weissman", "title": "Minimax Estimation of the $L_1$ Distance", "comments": "to appear on IEEE Transactions on Information Theory", "journal-ref": null, "doi": "10.1109/TIT.2018.2846245", "report-no": null, "categories": "math.ST cs.IT math.IT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of estimating the $L_1$ distance between two discrete\nprobability measures $P$ and $Q$ from empirical data in a nonasymptotic and\nlarge alphabet setting. When $Q$ is known and one obtains $n$ samples from $P$,\nwe show that for every $Q$, the minimax rate-optimal estimator with $n$ samples\nachieves performance comparable to that of the maximum likelihood estimator\n(MLE) with $n\\ln n$ samples. When both $P$ and $Q$ are unknown, we construct\nminimax rate-optimal estimators whose worst case performance is essentially\nthat of the known $Q$ case with $Q$ being uniform, implying that $Q$ being\nuniform is essentially the most difficult case. The \\emph{effective sample size\nenlargement} phenomenon, identified in Jiao \\emph{et al.} (2015), holds both in\nthe known $Q$ case for every $Q$ and the $Q$ unknown case. However, the\nconstruction of optimal estimators for $\\|P-Q\\|_1$ requires new techniques and\ninsights beyond the approximation-based method of functional estimation in Jiao\n\\emph{et al.} (2015).\n", "versions": [{"version": "v1", "created": "Tue, 2 May 2017 06:03:06 GMT"}, {"version": "v2", "created": "Wed, 24 May 2017 02:23:57 GMT"}, {"version": "v3", "created": "Mon, 17 Jul 2017 08:32:15 GMT"}, {"version": "v4", "created": "Tue, 18 Jul 2017 02:15:06 GMT"}, {"version": "v5", "created": "Sun, 10 Sep 2017 18:23:00 GMT"}, {"version": "v6", "created": "Mon, 14 May 2018 11:51:28 GMT"}, {"version": "v7", "created": "Sat, 23 Jun 2018 17:33:10 GMT"}], "update_date": "2018-06-26", "authors_parsed": [["Jiao", "Jiantao", ""], ["Han", "Yanjun", ""], ["Weissman", "Tsachy", ""]]}, {"id": "1705.00951", "submitter": "Nicholas Horton", "authors": "Ian R. White and James Carpenter and Nicholas J. Horton", "title": "A mean score method for sensitivity analysis to departures from the\n  missing at random assumption in randomised trials", "comments": "pre-publication (author version) in press, Statistica Sinica", "journal-ref": null, "doi": "10.5705/ss.202016.0308", "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most analyses of randomised trials with incomplete outcomes make untestable\nassumptions and should therefore be subjected to sensitivity analyses. However,\nmethods for sensitivity analyses are not widely used. We propose a mean score\napproach for exploring global sensitivity to departures from missing at random\nor other assumptions about incomplete outcome data in a randomised trial. We\nassume a single outcome analysed under a generalised linear model. One or more\nsensitivity parameters, specified by the user, measure the degree of departure\nfrom missing at random in a pattern mixture model. Advantages of our method are\nthat its sensitivity parameters are relatively easy to interpret and so can be\nelicited from subject matter experts; it is fast and non-stochastic; and its\npoint estimate, standard error and confidence interval agree perfectly with\nstandard methods when particular values of the sensitivity parameters make\nthose standard methods appropriate. We illustrate the method using data from a\nmental health trial.\n", "versions": [{"version": "v1", "created": "Tue, 2 May 2017 13:15:46 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["White", "Ian R.", ""], ["Carpenter", "James", ""], ["Horton", "Nicholas J.", ""]]}, {"id": "1705.00989", "submitter": "Clement Levrard", "authors": "Eddie Aamari (DATASHAPE, SELECT, LM-Orsay), Cl\\'ement Levrard (UPD7)", "title": "Non-Asymptotic Rates for Manifold, Tangent Space, and Curvature\n  Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given an $n$-sample drawn on a submanifold $M \\subset \\mathbb{R}^D$, we\nderive optimal rates for the estimation of tangent spaces $T\\_X M$, the second\nfundamental form $II\\_X^M$, and the submanifold $M$.After motivating their\nstudy, we introduce a quantitative class of $\\mathcal{C}^k$-submanifolds in\nanalogy with H{\\\"o}lder classes.The proposed estimators are based on local\npolynomials and allow to deal simultaneously with the three problems at stake.\nMinimax lower bounds are derived using a conditional version of Assouad's lemma\nwhen the base point $X$ is random.\n", "versions": [{"version": "v1", "created": "Tue, 2 May 2017 14:15:03 GMT"}, {"version": "v2", "created": "Mon, 5 Feb 2018 09:11:16 GMT"}], "update_date": "2018-02-06", "authors_parsed": [["Aamari", "Eddie", "", "DATASHAPE, SELECT, LM-Orsay"], ["Levrard", "Cl\u00e9ment", "", "UPD7"]]}, {"id": "1705.00998", "submitter": "Yixin Wang", "authors": "Yixin Wang, Jos\\'e R. Zubizarreta", "title": "Minimal Dispersion Approximately Balancing Weights: Asymptotic\n  Properties and Practical Considerations", "comments": "41 pages", "journal-ref": null, "doi": "10.1093/biomet/asz050", "report-no": null, "categories": "stat.ME math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Weighting methods are widely used to adjust for covariates in observational\nstudies, sample surveys, and regression settings. In this paper, we study a\nclass of recently proposed weighting methods which find the weights of minimum\ndispersion that approximately balance the covariates. We call these weights\n\"minimal weights\" and study them under a common optimization framework. The key\nobservation is the connection between approximate covariate balance and\nshrinkage estimation of the propensity score. This connection leads to both\ntheoretical and practical developments. From a theoretical standpoint, we\ncharacterize the asymptotic properties of minimal weights and show that, under\nstandard smoothness conditions on the propensity score function, minimal\nweights are consistent estimates of the true inverse probability weights. Also,\nwe show that the resulting weighting estimator is consistent, asymptotically\nnormal, and semiparametrically efficient. From a practical standpoint, we\npresent a finite sample oracle inequality that bounds the loss incurred by\nbalancing more functions of the covariates than strictly needed. This\ninequality shows that minimal weights implicitly bound the number of active\ncovariate balance constraints. We finally provide a tuning algorithm for\nchoosing the degree of approximate balance in minimal weights. We conclude the\npaper with four empirical studies that suggest approximate balance is\npreferable to exact balance, especially when there is limited overlap in\ncovariate distributions. In these studies, we show that the root mean squared\nerror of the weighting estimator can be reduced by as much as a half with\napproximate balance.\n", "versions": [{"version": "v1", "created": "Tue, 2 May 2017 14:31:32 GMT"}, {"version": "v2", "created": "Tue, 13 Feb 2018 03:37:40 GMT"}, {"version": "v3", "created": "Thu, 25 Apr 2019 02:35:11 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Wang", "Yixin", ""], ["Zubizarreta", "Jos\u00e9 R.", ""]]}, {"id": "1705.01024", "submitter": "Yinchu Zhu", "authors": "Yinchu Zhu and Jelena Bradic", "title": "A projection pursuit framework for testing general high-dimensional\n  hypothesis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.CO stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article develops a framework for testing general hypothesis in\nhigh-dimensional models where the number of variables may far exceed the number\nof observations. Existing literature has considered less than a handful of\nhypotheses, such as testing individual coordinates of the model parameter.\nHowever, the problem of testing general and complex hypotheses remains widely\nopen. We propose a new inference method developed around the hypothesis\nadaptive projection pursuit framework, which solves the testing problems in the\nmost general case. The proposed inference is centered around a new class of\nestimators defined as $l_1$ projection of the initial guess of the unknown onto\nthe space defined by the null. This projection automatically takes into account\nthe structure of the null hypothesis and allows us to study formal inference\nfor a number of long-standing problems. For example, we can directly conduct\ninference on the sparsity level of the model parameters and the minimum signal\nstrength. This is especially significant given the fact that the former is a\nfundamental condition underlying most of the theoretical development in\nhigh-dimensional statistics, while the latter is a key condition used to\nestablish variable selection properties. Moreover, the proposed method is\nasymptotically exact and has satisfactory power properties for testing very\ngeneral functionals of the high-dimensional parameters. The simulation studies\nlend further support to our theoretical claims and additionally show excellent\nfinite-sample size and power properties of the proposed test.\n", "versions": [{"version": "v1", "created": "Tue, 2 May 2017 15:30:54 GMT"}], "update_date": "2017-08-16", "authors_parsed": [["Zhu", "Yinchu", ""], ["Bradic", "Jelena", ""]]}, {"id": "1705.01064", "submitter": "Alexander Ly", "authors": "Alexander Ly, Maarten Marsman, Josine Verhagen, Raoul Grasman and\n  Eric-Jan Wagenmakers", "title": "A Tutorial on Fisher Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In many statistical applications that concern mathematical psychologists, the\nconcept of Fisher information plays an important role. In this tutorial we\nclarify the concept of Fisher information as it manifests itself across three\ndifferent statistical paradigms. First, in the frequentist paradigm, Fisher\ninformation is used to construct hypothesis tests and confidence intervals\nusing maximum likelihood estimators; second, in the Bayesian paradigm, Fisher\ninformation is used to define a default prior; lastly, in the minimum\ndescription length paradigm, Fisher information is used to measure model\ncomplexity.\n", "versions": [{"version": "v1", "created": "Tue, 2 May 2017 16:45:13 GMT"}, {"version": "v2", "created": "Tue, 17 Oct 2017 14:41:46 GMT"}], "update_date": "2017-10-18", "authors_parsed": [["Ly", "Alexander", ""], ["Marsman", "Maarten", ""], ["Verhagen", "Josine", ""], ["Grasman", "Raoul", ""], ["Wagenmakers", "Eric-Jan", ""]]}, {"id": "1705.01109", "submitter": "Nicolas Tessore", "authors": "Nicolas Tessore", "title": "An unbiased estimator for the ellipticity from image moments", "comments": "4 pages, accepted by MNRASL; v2 contains explicit covariance matrix\n  for moments", "journal-ref": null, "doi": "10.1093/mnrasl/slx100", "report-no": null, "categories": "astro-ph.CO math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An unbiased estimator for the ellipticity of an object in a noisy image is\ngiven in terms of the image moments. Three assumptions are made: i) the pixel\nnoise is normally distributed, although with arbitrary covariance matrix, ii)\nthe image moments are taken about a fixed centre, and iii) the point-spread\nfunction is known. The relevant combinations of image moments are then jointly\nnormal and their covariance matrix can be computed. A particular estimator for\nthe ratio of the means of jointly normal variates is constructed and used to\nprovide the unbiased estimator for the ellipticity. Furthermore, an unbiased\nestimate of the covariance of the new estimator is also given.\n", "versions": [{"version": "v1", "created": "Tue, 2 May 2017 18:00:27 GMT"}, {"version": "v2", "created": "Wed, 14 Jun 2017 11:11:03 GMT"}], "update_date": "2017-08-09", "authors_parsed": [["Tessore", "Nicolas", ""]]}, {"id": "1705.01166", "submitter": "Michael Abbott", "authors": "Henry H. Mattingly, Mark K. Transtrum, Michael C. Abbott, Benjamin B.\n  Machta", "title": "Maximizing the information learned from finite data selects a simple\n  model", "comments": "9 pages, 8 figures. v3 has improved discussion and adds an appendix\n  about MDL and Bayes factors, and matches version to appear in PNAS (modulo\n  comma placement). Title changed from \"Rational Ignorance: Simpler Models\n  Learn More Information from Finite Data\"", "journal-ref": "PNAS February 2018", "doi": "10.1073/pnas.1715306115", "report-no": null, "categories": "physics.data-an cond-mat.stat-mech cs.IT math.IT math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use the language of uninformative Bayesian prior choice to study the\nselection of appropriately simple effective models. We advocate for the prior\nwhich maximizes the mutual information between parameters and predictions,\nlearning as much as possible from limited data. When many parameters are poorly\nconstrained by the available data, we find that this prior puts weight only on\nboundaries of the parameter manifold. Thus it selects a lower-dimensional\neffective theory in a principled way, ignoring irrelevant parameter directions.\nIn the limit where there is sufficient data to tightly constrain any number of\nparameters, this reduces to Jeffreys prior. But we argue that this limit is\npathological when applied to the hyper-ribbon parameter manifolds generic in\nscience, because it leads to dramatic dependence on effects invisible to\nexperiment.\n", "versions": [{"version": "v1", "created": "Tue, 2 May 2017 20:27:14 GMT"}, {"version": "v2", "created": "Fri, 1 Sep 2017 13:55:26 GMT"}, {"version": "v3", "created": "Wed, 14 Feb 2018 15:24:36 GMT"}], "update_date": "2018-02-16", "authors_parsed": [["Mattingly", "Henry H.", ""], ["Transtrum", "Mark K.", ""], ["Abbott", "Michael C.", ""], ["Machta", "Benjamin B.", ""]]}, {"id": "1705.01287", "submitter": "Alexander Novikov", "authors": "Nino Kordzakhia, Yury Kutoyants, Alex Novikov, Lin-Yee Hin", "title": "On a representation of fractional Brownian motion and the limit\n  distributions of statistics arising in cusp statistical models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss some extensions of results from the recent paper by Chernoyarov et\nal. (Ann. Inst. Stat. Math., October 2016) concerning limit distributions of\nBayesian and maximum likelihood estimators in the model \"signal plus white\nnoise\" with irregular cusp-type signals. Using a new representation of\nfractional Brownian motion (fBm) in terms of cusp functions we show that as the\nnoise intensity tends to zero, the limit distributions are expressed in terms\nof fBm for the full range of asymmetric cusp-type signals correspondingly with\nthe Hurst parameter H, 0<H<1. Simulation results for the densities and\nvariances of the limit distributions of Bayesian and maximum likelihood\nestimators are also provided.\n", "versions": [{"version": "v1", "created": "Wed, 3 May 2017 07:47:25 GMT"}, {"version": "v2", "created": "Sun, 21 May 2017 04:11:25 GMT"}], "update_date": "2017-05-23", "authors_parsed": [["Kordzakhia", "Nino", ""], ["Kutoyants", "Yury", ""], ["Novikov", "Alex", ""], ["Hin", "Lin-Yee", ""]]}, {"id": "1705.01299", "submitter": "Jean-Michel Loubes", "authors": "Eustasio Del Barrio (UVa), Jean-Michel Loubes (IMT)", "title": "Central Limit Theorem for empirical transportation cost in general\n  dimension", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of optimal transportation with quadratic cost between\na empirical measure and a general target probability on R d , with d $\\ge$ 1.\nWe provide new results on the uniqueness and stability of the associated\noptimal transportation potentials , namely, the minimizers in the dual\nformulation of the optimal transportation problem. As a consequence, we show\nthat a CLT holds for the empirical transportation cost under mild moment and\nsmoothness requirements. The limiting distributions are Gaussian and admit a\nsimple description in terms of the optimal transportation potentials.\n", "versions": [{"version": "v1", "created": "Wed, 3 May 2017 08:27:50 GMT"}, {"version": "v2", "created": "Wed, 31 May 2017 09:04:15 GMT"}, {"version": "v3", "created": "Fri, 9 Mar 2018 14:46:17 GMT"}], "update_date": "2018-03-12", "authors_parsed": [["Del Barrio", "Eustasio", "", "UVa"], ["Loubes", "Jean-Michel", "", "IMT"]]}, {"id": "1705.01327", "submitter": "Chengshi Liu", "authors": "Cheng-shi Liu", "title": "The geometrical origins of some distributions and the complete\n  concentration of measure phenomenon for mean-values of functionals", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math-ph math.FA math.MP math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive out naturally some important distributions such as high order\nnormal distributions and high order exponent distributions and the Gamma\ndistribution from a geometrical way. Further, we obtain the exact mean-values\nof integral form functionals in the balls of continuous functions space with\n$p-$norm, and show the complete concentration of measure phenomenon which means\nthat a functional takes its average on a ball with probability 1, from which we\nhave nonlinear exchange formula of expectation.\n", "versions": [{"version": "v1", "created": "Wed, 3 May 2017 09:35:38 GMT"}], "update_date": "2017-05-04", "authors_parsed": [["Liu", "Cheng-shi", ""]]}, {"id": "1705.01340", "submitter": "Fabio Rapallo", "authors": "Fabio Rapallo and Maria Piera Rogantin", "title": "Algebraic characterization of regular fractions under level permutations", "comments": "23 pages, including two appendices", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study the behavior of the fractions of a factorial design\nunder permutations of the factor levels. We focus on the notion of regular\nfraction and we introduce methods to check whether a given symmetric orthogonal\narray can or can not be transformed into a regular fraction by means of\nsuitable permutations of the factor levels. The proposed techniques take\nadvantage of the complex coding of the factor levels and of some tools from\npolynomial algebra. Several examples are described, mainly involving factors\nwith five levels.\n", "versions": [{"version": "v1", "created": "Wed, 3 May 2017 10:07:15 GMT"}], "update_date": "2017-05-04", "authors_parsed": [["Rapallo", "Fabio", ""], ["Rogantin", "Maria Piera", ""]]}, {"id": "1705.01372", "submitter": "Vincent Wens", "authors": "Vincent Wens", "title": "Brownian forgery of statistical dependences", "comments": "13 pages, 2 figures, formatting based on revtex4; v2: revised proof\n  of extended forgery and minor changes; v3: additional discussion on practical\n  implementation and minor edits, published version", "journal-ref": "Front. Appl. Math. Stat. 4:19 (2018)", "doi": "10.3389/fams.2018.00019", "report-no": null, "categories": "cond-mat.stat-mech math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The balance held by Brownian motion between temporal regularity and\nrandomness is embodied in a remarkable way by Levy's forgery of continuous\nfunctions. Here we describe how this property can be extended to forge\narbitrary dependences between two statistical systems, and then establish a new\nBrownian independence test based on fluctuating random paths. We also argue\nthat this result allows revisiting the theory of Brownian covariance from a\nphysical perspective and opens the possibility of engineering nonlinear\ncorrelation measures from more general functional integrals.\n", "versions": [{"version": "v1", "created": "Wed, 3 May 2017 11:55:31 GMT"}, {"version": "v2", "created": "Mon, 11 Sep 2017 13:25:13 GMT"}, {"version": "v3", "created": "Fri, 8 Jun 2018 08:39:16 GMT"}], "update_date": "2018-06-11", "authors_parsed": [["Wens", "Vincent", ""]]}, {"id": "1705.01654", "submitter": "Andrii Babii", "authors": "Andrii Babii and Jean-Pierre Florens", "title": "Are Unobservables Separable?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST econ.EM stat.AP stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is common to assume in empirical research that observables and\nunobservables are additively separable, especially, when the former are\nendogenous. This is done because it is widely recognized that identification\nand estimation challenges arise when interactions between the two are allowed\nfor. Starting from a nonseparable IV model, where the instrumental variable is\nindependent of unobservables, we develop a novel nonparametric test of\nseparability of unobservables. The large-sample distribution of the test\nstatistics is nonstandard and relies on a novel Donsker-type central limit\ntheorem for the empirical distribution of nonparametric IV residuals, which may\nbe of independent interest. Using a dataset drawn from the 2015 US Consumer\nExpenditure Survey, we find that the test rejects the separability in Engel\ncurves for most of the commodities.\n", "versions": [{"version": "v1", "created": "Wed, 3 May 2017 23:33:34 GMT"}, {"version": "v2", "created": "Tue, 7 Jan 2020 18:22:41 GMT"}, {"version": "v3", "created": "Tue, 28 Jan 2020 23:20:43 GMT"}, {"version": "v4", "created": "Thu, 1 Apr 2021 02:54:33 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Babii", "Andrii", ""], ["Florens", "Jean-Pierre", ""]]}, {"id": "1705.01715", "submitter": "Ting Yan", "authors": "Ting Yan", "title": "Directed Networks with a Differentially Private Bi-degree Sequence", "comments": "21 pages, 3 figures, minor revision", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although a lot of approaches are developed to release network data with a\ndifferentially privacy guarantee, inference using noisy data in many network\nmodels is still unknown or not properly explored. In this paper, we release the\nbi-degree sequences of directed networks using the Laplace mechanism and use\nthe $p_0$ model for inferring the degree parameters. The $p_0$ model is an\nexponential random graph model with the bi-degree sequence as its exclusively\nsufficient statistic. We show that the estimator of the parameter without the\ndenoised process is asymptotically consistent and normally distributed. This is\ncontrast sharply with some known results that valid inference such as the\nexistence and consistency of the estimator needs the denoised process. Along\nthe way, a new phenomenon is revealed in which an additional variance factor\nappears in the asymptotic variance of the estimator when the noise becomes\nlarge. Further, we propose an efficient algorithm for finding the closet point\nlying in the set of all graphical bi-degree sequences under the global $L_1$\noptimization problem. Numerical studies demonstrate our theoretical findings.\n", "versions": [{"version": "v1", "created": "Thu, 4 May 2017 06:47:30 GMT"}, {"version": "v2", "created": "Fri, 26 May 2017 09:29:18 GMT"}, {"version": "v3", "created": "Thu, 23 Aug 2018 07:35:26 GMT"}, {"version": "v4", "created": "Tue, 17 Sep 2019 02:16:07 GMT"}, {"version": "v5", "created": "Fri, 29 Nov 2019 03:14:29 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Yan", "Ting", ""]]}, {"id": "1705.02162", "submitter": "Michael Muma", "authors": "Jasin Machkour, Michael Muma, Bastian Alt, Abdelhak M. Zoubir", "title": "A New Sparse and Robust Adaptive Lasso Estimator for the Independent\n  Contamination Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many problems in signal processing require finding sparse solutions to\nunder-determined, or ill-conditioned, linear systems of equations. When dealing\nwith real-world data, the presence of outliers and impulsive noise must also be\naccounted for. In past decades, the vast majority of robust linear regression\nestimators has focused on robustness against rowwise contamination. Even so\ncalled `high breakdown' estimators rely on the assumption that a majority of\nrows of the regression matrix is not affected by outliers. Only very recently,\nthe first cellwise robust regression estimation methods have been developed. In\nthis paper, we define robust oracle properties, which an estimator must have in\norder to perform robust model selection for under-determined, or\nill-conditioned linear regression models that are contaminated by cellwise\noutliers in the regression matrix. We propose and analyze a robustly weighted\nand adaptive Lasso type regularization term which takes into account cellwise\noutliers for model selection. The proposed regularization term is integrated\ninto the objective function of the MM-estimator, which yields the proposed\nMM-Robust Weighted Adaptive Lasso (MM-RWAL), for which we prove that at least\nthe weak robust oracle properties hold. A performance comparison to existing\nrobust Lasso estimators is provided using Monte Carlo experiments. Further, the\nMM-RWAL is applied to determine the temporal releases of the European Tracer\nExperiment (ETEX) at the source location. This ill-conditioned linear inverse\nproblem contains cellwise and rowwise outliers and is sparse both in the\nregression matrix and the parameter vector. The proposed RWAL penalty is not\nlimited to the MM-estimator but can easily be integrated into the objective\nfunction of other robust estimators.\n", "versions": [{"version": "v1", "created": "Fri, 5 May 2017 10:39:29 GMT"}], "update_date": "2017-05-08", "authors_parsed": [["Machkour", "Jasin", ""], ["Muma", "Michael", ""], ["Alt", "Bastian", ""], ["Zoubir", "Abdelhak M.", ""]]}, {"id": "1705.02212", "submitter": "Michel Besserve", "authors": "Michel Besserve, Naji Shajarisales, Bernhard Sch\\\"olkopf and Dominik\n  Janzing", "title": "Group invariance principles for causal generative models", "comments": "16 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The postulate of independence of cause and mechanism (ICM) has recently led\nto several new causal discovery algorithms. The interpretation of independence\nand the way it is utilized, however, varies across these methods. Our aim in\nthis paper is to propose a group theoretic framework for ICM to unify and\ngeneralize these approaches. In our setting, the cause-mechanism relationship\nis assessed by comparing it against a null hypothesis through the application\nof random generic group transformations. We show that the group theoretic view\nprovides a very general tool to study the structure of data generating\nmechanisms with direct applications to machine learning.\n", "versions": [{"version": "v1", "created": "Fri, 5 May 2017 13:34:16 GMT"}], "update_date": "2017-05-08", "authors_parsed": [["Besserve", "Michel", ""], ["Shajarisales", "Naji", ""], ["Sch\u00f6lkopf", "Bernhard", ""], ["Janzing", "Dominik", ""]]}, {"id": "1705.02276", "submitter": "Arnaud Poinas", "authors": "Arnaud Poinas, Bernard Delyon, Fr\\'ed\\'eric Lavancier", "title": "Mixing properties and central limit theorem for associated point\n  processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Positively (resp. negatively) associated point processes are a class of point\nprocesses that induce attraction (resp. inhibition) between the points. As an\nimportant example, determinantal point processes (DPPs) are negatively\nassociated. We prove $\\alpha$-mixing properties for associated spatial point\nprocesses by controlling their $\\alpha$-coefficients in terms of the first two\nintensity functions. A central limit theorem for functionals of associated\npoint processes is deduced, using both the association and the $\\alpha$-mixing\nproperties. We discuss in detail the case of DPPs, for which we obtain the\nlimiting distribution of sums, over subsets of close enough points of the\nprocess, of any bounded function of the DPP. As an application, we get the\nasymptotic properties of the parametric two-step estimator of some\ninhomogeneous DPPs.\n", "versions": [{"version": "v1", "created": "Fri, 5 May 2017 15:48:43 GMT"}, {"version": "v2", "created": "Wed, 27 Sep 2017 16:20:57 GMT"}, {"version": "v3", "created": "Mon, 19 Feb 2018 13:08:18 GMT"}], "update_date": "2018-02-20", "authors_parsed": [["Poinas", "Arnaud", ""], ["Delyon", "Bernard", ""], ["Lavancier", "Fr\u00e9d\u00e9ric", ""]]}, {"id": "1705.02294", "submitter": "Vince Lyzinski", "authors": "Vince Lyzinski, Daniel L. Sussman", "title": "Matchability of heterogeneous networks pairs", "comments": "44 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.SI stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of graph matchability in non-identically distributed\nnetworks. In a general class of edge-independent networks, we demonstrate that\ngraph matchability can be lost with high probability when matching the networks\ndirectly. We further demonstrate that under mild model assumptions,\nmatchability is almost perfectly recovered by centering the networks using\nUniversal Singular Value Thresholding before matching. These theoretical\nresults are then demonstrated in both real and synthetic simulation settings.\nWe also recover analogous core-matchability results in a very general core-junk\nnetwork model, wherein some vertices do not correspond between the graph pair.\n", "versions": [{"version": "v1", "created": "Fri, 5 May 2017 16:40:44 GMT"}, {"version": "v2", "created": "Tue, 6 Mar 2018 21:37:50 GMT"}, {"version": "v3", "created": "Wed, 20 Mar 2019 19:19:56 GMT"}], "update_date": "2019-03-22", "authors_parsed": [["Lyzinski", "Vince", ""], ["Sussman", "Daniel L.", ""]]}, {"id": "1705.02356", "submitter": "Feng Ruan", "authors": "John C. Duchi and Feng Ruan", "title": "Solving (most) of a set of quadratic equalities: Composite optimization\n  for robust phase retrieval", "comments": "55 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT math.IT math.OC stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop procedures, based on minimization of the composition $f(x) =\nh(c(x))$ of a convex function $h$ and smooth function $c$, for solving random\ncollections of quadratic equalities, applying our methodology to phase\nretrieval problems. We show that the prox-linear algorithm we develop can solve\nphase retrieval problems---even with adversarially faulty measurements---with\nhigh probability as soon as the number of measurements $m$ is a constant factor\nlarger than the dimension $n$ of the signal to be recovered. The algorithm\nrequires essentially no tuning---it consists of solving a sequence of convex\nproblems---and it is implementable without any particular assumptions on the\nmeasurements taken. We provide substantial experiments investigating our\nmethods, indicating the practical effectiveness of the procedures and showing\nthat they succeed with high probability as soon as $m / n \\ge 2$ when the\nsignal is real-valued.\n", "versions": [{"version": "v1", "created": "Fri, 5 May 2017 18:21:40 GMT"}, {"version": "v2", "created": "Sun, 22 Apr 2018 23:15:24 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Duchi", "John C.", ""], ["Ruan", "Feng", ""]]}, {"id": "1705.02679", "submitter": "Adam Kashlak", "authors": "Adam B Kashlak, Linglong Kong", "title": "Nonasymptotic estimation and support recovery for high dimensional\n  sparse covariance matrices", "comments": "33 pages, 3 figures, 6 tables", "journal-ref": "Stat (2020) e316", "doi": "10.1002/sta4.316", "report-no": null, "categories": "stat.ME math.ST stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a general framework for nonasymptotic covariance matrix estimation\nmaking use of concentration inequality-based confidence sets. We specify this\nframework for the estimation of large sparse covariance matrices through\nincorporation of past thresholding estimators with key emphasis on support\nrecovery. This technique goes beyond past results for thresholding estimators\nby allowing for a wide range of distributional assumptions beyond merely\nsub-Gaussian tails. This methodology can furthermore be adapted to a wide range\nof other estimators and settings. The usage of nonasymptotic dimension-free\nconfidence sets yields good theoretical performance. Through extensive\nsimulations, it is demonstrated to have superior performance when compared with\nother such methods. In the context of support recovery, we are able to specify\na false positive rate and optimize to maximize the true recoveries.\n", "versions": [{"version": "v1", "created": "Sun, 7 May 2017 18:47:49 GMT"}, {"version": "v2", "created": "Fri, 27 Apr 2018 23:05:09 GMT"}, {"version": "v3", "created": "Tue, 26 Mar 2019 15:56:34 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Kashlak", "Adam B", ""], ["Kong", "Linglong", ""]]}, {"id": "1705.02761", "submitter": "Koji Tsukuda", "authors": "Koji Tsukuda, Hiroshi Kurata", "title": "Covariance structure associated with an equality between two general\n  ridge estimators", "comments": "16 pages. This is a pre-print of an article published in Statistical\n  Papers. The final authenticated version is available online at:\n  https://doi.org/10.1007/s00362-017-0975-8", "journal-ref": null, "doi": "10.1007/s00362-017-0975-8", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a general linear model, this paper derives a necessary and sufficient\ncondition under which two general ridge estimators coincide with each other.\nThe condition is given as a structure of the dispersion matrix of the error\nterm. Since the class of estimators considered here contains linear unbiased\nestimators such as the ordinary least squares estimator and the best linear\nunbiased estimator, our result can be viewed as a generalization of the\nwell-known theorems on the equality between these two estimators, which have\nbeen fully studied in the literature. Two related problems are also considered:\nequality between two residual sums of squares, and classification of dispersion\nmatrices by a perturbation approach.\n", "versions": [{"version": "v1", "created": "Mon, 8 May 2017 07:04:21 GMT"}, {"version": "v2", "created": "Thu, 21 Dec 2017 04:54:39 GMT"}], "update_date": "2017-12-22", "authors_parsed": [["Tsukuda", "Koji", ""], ["Kurata", "Hiroshi", ""]]}, {"id": "1705.02826", "submitter": "Nestor Parolya Jun.-Prof. Dr.", "authors": "Taras Bodnar, Stepan Mazur, Edward Ngailo and Nestor Parolya", "title": "Discriminant analysis in small and large dimensions", "comments": "27 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the distributional properties of the linear discriminant function\nunder the assumption of normality by comparing two groups with the same\ncovariance matrix but different mean vectors. A stochastic representation for\nthe discriminant function coefficients is derived which is then used to obtain\ntheir asymptotic distribution under the high-dimensional asymptotic regime. We\ninvestigate the performance of the classification analysis based on the\ndiscriminant function in both small and large dimensions. A stochastic\nrepresentation is established which allows to compute the error rate in an\nefficient way. We further compare the calculated error rate with the optimal\none obtained under the assumption that the covariance matrix and the two mean\nvectors are known. Finally, we present an analytical expression of the error\nrate calculated in the high-dimensional asymptotic regime. The finite-sample\nproperties of the derived theoretical results are assessed via an extensive\nMonte Carlo study.\n", "versions": [{"version": "v1", "created": "Mon, 8 May 2017 11:07:47 GMT"}], "update_date": "2017-05-09", "authors_parsed": [["Bodnar", "Taras", ""], ["Mazur", "Stepan", ""], ["Ngailo", "Edward", ""], ["Parolya", "Nestor", ""]]}, {"id": "1705.02973", "submitter": "Chiheon Kim", "authors": "Chiheon Kim, Afonso S. Bandeira and Michel X. Goemans", "title": "Community Detection in Hypergraphs, Spiked Tensor Models, and\n  Sum-of-Squares", "comments": "In proceedings of 2017 International Conference on Sampling Theory\n  and Applications (SampTA)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.SI math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of community detection in hypergraphs under a stochastic\nblock model. Similarly to how the stochastic block model in graphs suggests\nstudying spiked random matrices, our model motivates investigating statistical\nand computational limits of exact recovery in a certain spiked tensor model. In\ncontrast with the matrix case, the spiked model naturally arising from\ncommunity detection in hypergraphs is different from the one arising in the\nso-called tensor Principal Component Analysis model. We investigate the\neffectiveness of algorithms in the Sum-of-Squares hierarchy on these models.\nInterestingly, our results suggest that these two apparently similar models\nexhibit significantly different computational to statistical gaps.\n", "versions": [{"version": "v1", "created": "Mon, 8 May 2017 17:07:50 GMT"}, {"version": "v2", "created": "Tue, 3 Jul 2018 22:04:40 GMT"}], "update_date": "2018-07-05", "authors_parsed": [["Kim", "Chiheon", ""], ["Bandeira", "Afonso S.", ""], ["Goemans", "Michel X.", ""]]}, {"id": "1705.03181", "submitter": "Zhijian He", "authors": "Zhijian He and Lingjiong Zhu", "title": "Asymptotic Normality of Extensible Grid Sampling", "comments": null, "journal-ref": "Statistics and Computing, 2019, Volume 29, Issue 1, pp 53-65", "doi": "10.1007/s11222-017-9794-y", "report-no": null, "categories": "math.NA math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, He and Owen (2016) proposed the use of Hilbert's space filling\ncurve (HSFC) in numerical integration as a way of reducing the dimension from\n$d>1$ to $d=1$. This paper studies the asymptotic normality of the HSFC-based\nestimate when using scrambled van der Corput sequence as input. We show that\nthe estimate has an asymptotic normal distribution for functions in\n$C^1([0,1]^d)$, excluding the trivial case of constant functions. The\nasymptotic normality also holds for discontinuous functions under mild\nconditions. It was previously known only that scrambled $(0,m,d)$-net\nquadratures enjoy the asymptotic normality for smooth enough functions, whose\nmixed partial gradients satisfy a H\\\"older condition. As a by-product, we find\nlower bounds for the variance of the HSFC-based estimate. Particularly, for\nnontrivial functions in $C^1([0,1]^d)$, the low bound is of order $n^{-1-2/d}$,\nwhich matches the rate of the upper bound established in He and Owen (2016).\n", "versions": [{"version": "v1", "created": "Tue, 9 May 2017 05:26:57 GMT"}], "update_date": "2019-03-13", "authors_parsed": [["He", "Zhijian", ""], ["Zhu", "Lingjiong", ""]]}, {"id": "1705.03286", "submitter": "Tapio Helin", "authors": "Sergios Agapiou, Martin Burger, Masoumeh Dashti and Tapio Helin", "title": "Sparsity-promoting and edge-preserving maximum a posteriori estimators\n  in non-parametric Bayesian inverse problems", "comments": "36 pages, some typos corrected, acknowledgements added", "journal-ref": null, "doi": "10.1088/1361-6420/aaacac", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the inverse problem of recovering an unknown functional parameter\n$u$ in a separable Banach space, from a noisy observation $y$ of its image\nthrough a known possibly non-linear ill-posed map ${\\mathcal G}$. The data $y$\nis finite-dimensional and the noise is Gaussian. We adopt a Bayesian approach\nto the problem and consider Besov space priors (see Lassas et al. 2009), which\nare well-known for their edge-preserving and sparsity-promoting properties and\nhave recently attracted wide attention especially in the medical imaging\ncommunity.\n  Our key result is to show that in this non-parametric setup the maximum a\nposteriori (MAP) estimates are characterized by the minimizers of a generalized\nOnsager--Machlup functional of the posterior. This is done independently for\nthe so-called weak and strong MAP estimates, which as we show coincide in our\ncontext. In addition, we prove a form of weak consistency for the MAP\nestimators in the infinitely informative data limit. Our results are remarkable\nfor two reasons: first, the prior distribution is non-Gaussian and does not\nmeet the smoothness conditions required in previous research on non-parametric\nMAP estimates. Second, the result analytically justifies existing uses of the\nMAP estimate in finite but high dimensional discretizations of Bayesian inverse\nproblems with the considered Besov priors.\n", "versions": [{"version": "v1", "created": "Tue, 9 May 2017 11:54:50 GMT"}, {"version": "v2", "created": "Tue, 23 May 2017 07:03:00 GMT"}], "update_date": "2018-03-14", "authors_parsed": [["Agapiou", "Sergios", ""], ["Burger", "Martin", ""], ["Dashti", "Masoumeh", ""], ["Helin", "Tapio", ""]]}, {"id": "1705.03439", "submitter": "Yixin Wang", "authors": "Yixin Wang, David M. Blei", "title": "Frequentist Consistency of Variational Bayes", "comments": null, "journal-ref": "Journal of the American Statistical Association 114.527 (2019):\n  1147-1161", "doi": "10.1080/01621459.2018.1473776", "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key challenge for modern Bayesian statistics is how to perform scalable\ninference of posterior distributions. To address this challenge, variational\nBayes (VB) methods have emerged as a popular alternative to the classical\nMarkov chain Monte Carlo (MCMC) methods. VB methods tend to be faster while\nachieving comparable predictive performance. However, there are few theoretical\nresults around VB. In this paper, we establish frequentist consistency and\nasymptotic normality of VB methods. Specifically, we connect VB methods to\npoint estimates based on variational approximations, called frequentist\nvariational approximations, and we use the connection to prove a variational\nBernstein-von Mises theorem. The theorem leverages the theoretical\ncharacterizations of frequentist variational approximations to understand\nasymptotic properties of VB. In summary, we prove that (1) the VB posterior\nconverges to the Kullback-Leibler (KL) minimizer of a normal distribution,\ncentered at the truth and (2) the corresponding variational expectation of the\nparameter is consistent and asymptotically normal. As applications of the\ntheorem, we derive asymptotic properties of VB posteriors in Bayesian mixture\nmodels, Bayesian generalized linear mixed models, and Bayesian stochastic block\nmodels. We conduct a simulation study to illustrate these theoretical results.\n", "versions": [{"version": "v1", "created": "Tue, 9 May 2017 17:30:16 GMT"}, {"version": "v2", "created": "Thu, 24 May 2018 14:41:19 GMT"}, {"version": "v3", "created": "Thu, 8 Jul 2021 01:16:04 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Wang", "Yixin", ""], ["Blei", "David M.", ""]]}, {"id": "1705.03445", "submitter": "Cristina Butucea", "authors": "Cristina Butucea, Madalin Guta, Michael Nussbaum", "title": "Local asymptotic equivalence of pure quantum states ensembles and\n  quantum Gaussian white noise", "comments": null, "journal-ref": null, "doi": "10.1214/17-AOS1672", "report-no": null, "categories": "math.ST math-ph math.MP quant-ph stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum technology is increasingly relying on specialised statistical\ninference methods for analysing quantum measurement data. This motivates the\ndevelopment of \"quantum statistics\", a field that is shaping up at the overlap\nof quantum physics and \"classical\" statistics. One of the less investigated\ntopics to date is that of statistical inference for infinite dimensional\nquantum systems, which can be seen as quantum counterpart of non-parametric\nstatistics. In this paper we analyse the asymptotic theory of quantum\nstatistical models consisting of ensembles of quantum systems which are\nidentically prepared in a pure state. In the limit of large ensembles we\nestablish the local asymptotic equivalence (LAE) of this i.i.d. model to a\nquantum Gaussian white noise model. We use the LAE result in order to establish\nminimax rates for the estimation of pure states belonging to Hermite-Sobolev\nclasses of wave functions. Moreover, for quadratic functional estimation of the\nsame states we note an elbow effect in the rates, whereas for testing a pure\nstate a sharp parametric rate is attained over the nonparametric\nHermite-Sobolev class.\n", "versions": [{"version": "v1", "created": "Tue, 9 May 2017 17:48:40 GMT"}], "update_date": "2019-01-04", "authors_parsed": [["Butucea", "Cristina", ""], ["Guta", "Madalin", ""], ["Nussbaum", "Michael", ""]]}, {"id": "1705.03496", "submitter": "Alvaro Cordero Franco", "authors": "W. J. Conover, Victor G. Tercero and Alvaro E. Cordero-Franco", "title": "The Sequential Normal Scores Transformation", "comments": "39 pages, 8 figures", "journal-ref": null, "doi": "10.1080/07474946.2017.1360091", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The sequential analysis of series often requires nonparametric procedures,\nwhere the most powerful ones frequently use rank transformations. Re-ranking\nthe data sequence after each new observation can become too intensive\ncomputationally. This led to the idea of sequential ranks, where only the most\nrecent observation is ranked. However, difficulties finding, or approximating,\nthe null distribution of the statistics may have contributed to the lack of\npopularity of these methods. In this paper, we propose transforming the\nsequential ranks into sequential normal scores which are independent, and\nasymptotically standard normal random variables. Thus original methods based on\nthe normality assumption may be used.\n  A novel approach permits the inclusion of a priori information in the form of\nquantiles. It is developed as a strategy to increase the sensitivity of the\nscoring statistic. The result is a powerful convenient method to analyze\nnon-normal data sequences. Also, four variations of sequential normal scores\nare presented using examples from the literature. Researchers and practitioners\nmight find this approach useful to develop nonparametric procedures to address\nnew problems extending the use of parametric procedures when distributional\nassumptions are not met. These methods are especially useful with large data\nstreams where efficient computational methods are required.\n", "versions": [{"version": "v1", "created": "Tue, 9 May 2017 19:17:15 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Conover", "W. J.", ""], ["Tercero", "Victor G.", ""], ["Cordero-Franco", "Alvaro E.", ""]]}, {"id": "1705.03510", "submitter": "Didier Ch\\'etelat", "authors": "Didier Ch\\'etelat and Martin T. Wells", "title": "The middle-scale asymptotics of Wishart matrices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the behavior of a real $p$-dimensional Wishart random matrix with\n$n$ degrees of freedom when $n,p\\rightarrow\\infty$ but $p/n\\rightarrow 0$. We\nestablish the existence of phase transitions when $p$ grows at the order\n$n^{(K+1)/(K+3)}$ for every $k\\in\\mathbb{N}$, and derive expressions for\napproximating densities between every two phase transitions. To do this, we\nmake use of a novel tool we call the G-transform of a distribution, which is\nclosely related to the characteristic function. We also derive an extension of\nthe $t$-distribution to the real symmetric matrices, which naturally appears as\nthe conjugate distribution to the Wishart under a G-transformation, and show\nits empirical spectral distribution obeys a semicircle law when $p/n\\rightarrow\n0$. Finally, we discuss how the phase transitions of the Wishart distribution\nmight originate from changes in rates of convergence of symmetric $t$\nstatistics.\n", "versions": [{"version": "v1", "created": "Tue, 9 May 2017 19:47:57 GMT"}], "update_date": "2017-05-11", "authors_parsed": [["Ch\u00e9telat", "Didier", ""], ["Wells", "Martin T.", ""]]}, {"id": "1705.03533", "submitter": "Haolei Weng", "authors": "Haolei Weng and Arian Maleki", "title": "Low noise sensitivity analysis of Lq-minimization in oversampled systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT math.IT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The class of Lq-regularized least squares (LQLS) are considered for\nestimating a p-dimensional vector \\b{eta} from its n noisy linear observations\ny = X\\b{eta}+w. The performance of these schemes are studied under the\nhigh-dimensional asymptotic setting in which p grows linearly with n. In this\nasymptotic setting, phase transition diagrams (PT) are often used for comparing\nthe performance of different estimators. Although phase transition analysis is\nshown to provide useful information for compressed sensing, the fact that it\nignores the measurement noise not only limits its applicability in many\napplication areas, but also may lead to misunderstandings. For instance,\nconsider a linear regression problem in which n > p and the signal is not\nexactly sparse. If the measurement noise is ignored in such systems,\nregularization techniques, such as LQLS, seem to be irrelevant since even the\nordinary least squares (OLS) returns the exact solution. However, it is\nwell-known that if n is not much larger than p then the regularization\ntechniques improve the performance of OLS. In response to this limitation of PT\nanalysis, we consider the low-noise sensitivity analysis. We show that this\nanalysis framework (i) reveals the advantage of LQLS over OLS, (ii) captures\nthe difference between different LQLS estimators even when n > p, and (iii)\nprovides a fair comparison among different estimators in high signal-to-noise\nratios. As an application of this framework, we will show that under mild\nconditions LASSO outperforms other LQLS even when the signal is dense. Finally,\nby a simple transformation we connect our low-noise sensitivity framework to\nthe classical asymptotic regime in which n/p goes to infinity and characterize\nhow and when regularization techniques offer improvements over ordinary least\nsquares, and which regularizer gives the most improvement when the sample size\nis large.\n", "versions": [{"version": "v1", "created": "Tue, 9 May 2017 20:38:38 GMT"}, {"version": "v2", "created": "Sun, 18 Feb 2018 12:36:39 GMT"}], "update_date": "2018-02-20", "authors_parsed": [["Weng", "Haolei", ""], ["Maleki", "Arian", ""]]}, {"id": "1705.03584", "submitter": "Chengshi Liu", "authors": "Cheng-shi Liu", "title": "Lectures on the mean values of functionals -- An elementary introduction\n  to infinite-dimensional probability", "comments": "57", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math-ph math.FA math.MP math.ST physics.comp-ph stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is an elementary introduction to infinite-dimensional probability. In\nthe lectures, we compute the exact mean values of some functionals on C[0,1]\nand L[0,1] by considering these functionals as infinite-dimensional random\nvariables. The results show that there exist the complete concentration of\nmeasure phenomenon for these mean values since the variances are all zeroes.\n", "versions": [{"version": "v1", "created": "Wed, 10 May 2017 02:21:03 GMT"}], "update_date": "2017-05-11", "authors_parsed": [["Liu", "Cheng-shi", ""]]}, {"id": "1705.03659", "submitter": "Luca Rossini", "authors": "Roberto Casarin and Lorenzo Frattarolo and Luca Rossini", "title": "Discussion on \"Random-projection ensemble classification\" by T. Cannings\n  and R. Samworth", "comments": "2 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discussion on \"Random-projection ensemble classification\" by T. Cannings and\nR. Samworth. We believe that the proposed approach can find many applications\nin economics such as credit scoring (e.g. Altman (1968)) and can be extended to\nmore general type of classifiers. In this discussion we would like to draw\nauthors attention to the copula-based discriminant analysis (Han et al. (2013)\nand He et al. (2016)).\n", "versions": [{"version": "v1", "created": "Wed, 10 May 2017 08:40:18 GMT"}], "update_date": "2017-05-11", "authors_parsed": [["Casarin", "Roberto", ""], ["Frattarolo", "Lorenzo", ""], ["Rossini", "Luca", ""]]}, {"id": "1705.03830", "submitter": "Alexander Krei{\\ss}", "authors": "Alexander Krei{\\ss} and Enno Mammen and Wolfgang Polonik", "title": "Nonparametric inference for continuous-time event counting and\n  link-based dynamic network models", "comments": null, "journal-ref": "Electron. J. Statist. 13 (2) 2764 - 2829, 2019", "doi": "10.1214/19-EJS1588", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A flexible approach for modeling both dynamic event counting and dynamic\nlink-based networks based on counting processes is proposed, and estimation in\nthese models is studied. We consider nonparametric likelihood based estimation\nof parameter functions via kernel smoothing. The asymptotic behavior of these\nestimators is rigorously analyzed by allowing the number of nodes to tend to\ninfinity. The finite sample performance of the estimators is illustrated\nthrough an empirical analysis of bike share data.\n", "versions": [{"version": "v1", "created": "Wed, 10 May 2017 15:50:38 GMT"}, {"version": "v2", "created": "Tue, 4 Jul 2017 08:54:10 GMT"}, {"version": "v3", "created": "Wed, 2 May 2018 14:12:54 GMT"}, {"version": "v4", "created": "Fri, 24 Aug 2018 07:22:46 GMT"}, {"version": "v5", "created": "Tue, 28 May 2019 08:33:13 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Krei\u00df", "Alexander", ""], ["Mammen", "Enno", ""], ["Polonik", "Wolfgang", ""]]}, {"id": "1705.04219", "submitter": "Pierre Carmier Ph.D.", "authors": "Pierre Carmier, Olexiy Kyrgyzov, Paul-Henry Courn\\`ede", "title": "A critical analysis of resampling strategies for the regularized\n  particle filter", "comments": "14 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the performance of different resampling strategies for the\nregularized particle filter regarding parameter estimation. We show in\nparticular, building on analytical insight obtained in the linear Gaussian\ncase, that resampling systematically can prevent the filtered density from\nconverging towards the true posterior distribution. We discuss several means to\novercome this limitation, including kernel bandwidth modulation, and provide\nevidence that the resulting particle filter clearly outperforms traditional\nbootstrap particle filters. Our results are supported by numerical simulations\non a linear textbook example, the logistic map and a non-linear plant growth\nmodel.\n", "versions": [{"version": "v1", "created": "Thu, 11 May 2017 14:47:30 GMT"}], "update_date": "2017-05-12", "authors_parsed": [["Carmier", "Pierre", ""], ["Kyrgyzov", "Olexiy", ""], ["Courn\u00e8de", "Paul-Henry", ""]]}, {"id": "1705.04241", "submitter": "Yang Kang", "authors": "Jose Blanchet and Yang Kang", "title": "Distributionally Robust Groupwise Regularization Estimator", "comments": "21 Pages, 1 Figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regularized estimators in the context of group variables have been applied\nsuccessfully in model and feature selection in order to preserve\ninterpretability. We formulate a Distributionally Robust Optimization (DRO)\nproblem which recovers popular estimators, such as Group Square Root Lasso\n(GSRL). Our DRO formulation allows us to interpret GSRL as a game, in which we\nlearn a regression parameter while an adversary chooses a perturbation of the\ndata. We wish to pick the parameter to minimize the expected loss under any\nplausible model chosen by the adversary - who, on the other hand, wishes to\nincrease the expected loss. The regularization parameter turns out to be\nprecisely determined by the amount of perturbation on the training data allowed\nby the adversary. In this paper, we introduce a data-driven (statistical)\ncriterion for the optimal choice of regularization, which we evaluate\nasymptotically, in closed form, as the size of the training set increases. Our\neasy-to-evaluate regularization formula is compared against cross-validation,\nshowing good (sometimes superior) performance.\n", "versions": [{"version": "v1", "created": "Thu, 11 May 2017 15:27:16 GMT"}], "update_date": "2017-05-12", "authors_parsed": [["Blanchet", "Jose", ""], ["Kang", "Yang", ""]]}, {"id": "1705.04357", "submitter": "Leonardo Rojas Nandayapa", "authors": "Mogens Bladt, Leonardo Rojas-Nandayapa", "title": "Fitting phase--type scale mixtures to heavy--tailed data and\n  distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the fitting of heavy tailed data and distribution with a special\nattention to distributions with a non--standard shape in the \"body\" of the\ndistribution. To this end we consider a dense class of heavy tailed\ndistributions introduced recently, employing an EM algorithm for the the\nmaximum likelihood estimates of its parameters. We present methods for fitting\nto observed data, histograms, censored data, as well as to theoretical\ndistributions. Numerical examples are provided with simulated data and a\nbenchmark reinsurance dataset. We empirically demonstrate that our model can\nprovide excellent fits to heavy--tailed data/distributions with minimal\nassumptions\n", "versions": [{"version": "v1", "created": "Thu, 11 May 2017 19:19:13 GMT"}], "update_date": "2017-05-15", "authors_parsed": [["Bladt", "Mogens", ""], ["Rojas-Nandayapa", "Leonardo", ""]]}, {"id": "1705.04545", "submitter": "Svenja Fischer", "authors": "Svenja Fischer", "title": "Generalized linear statistics for near epoch dependent processes with\n  application to EGARCH-processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The class of Generalized $L$-statistics ($GL$-statistics) unifies a broad\nclass of different estimators, for example scale estimators based on\nmultivariate kernels. $GL$-statistics are functionals of $U$-quantiles and\ntherefore the dimension of the kernel of the $U$-quantiles determines the\nkernel dimension of the estimator. Up to now only few results for multivariate\nkernels are known. Additionally, most theory was established under independence\nor for short range dependent processes. In this paper we establish a central\nlimit theorem for $GL$-statistics of functionals of short range dependent data,\nin particular near epoch dependent sequences on absolutely regular processes,\nand arbitrary dimension of the underlying kernel. This limit theorem is based\non the theory of $U$-statistics and $U$-processes, for which we show a central\nlimit theorem as well as an invariance principle. The use of near epoch\ndependent processes admits us to consider functionals of short range dependent\nprocesses and therefore models like the EGARCH-model. We also develop a\nconsistent estimator of the asymptotic variance of $GL$-statistics.\n", "versions": [{"version": "v1", "created": "Fri, 12 May 2017 12:58:38 GMT"}], "update_date": "2017-05-15", "authors_parsed": [["Fischer", "Svenja", ""]]}, {"id": "1705.04565", "submitter": "Eddie Aamari", "authors": "Eddie Aamari (LPSM UMR 8001, CNRS), Jisu Kim (DATASHAPE), Fr\\'ed\\'eric\n  Chazal (DATASHAPE), Bertrand Michel (ECN, LMJL), Alessandro Rinaldo, Larry\n  Wasserman", "title": "Estimating the Reach of a Manifold", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.DG stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Various problems in manifold estimation make use of a quantity called the\nreach, denoted by $\\tau\\_M$, which is a measure of the regularity of the\nmanifold. This paper is the first investigation into the problem of how to\nestimate the reach. First, we study the geometry of the reach through an\napproximation perspective. We derive new geometric results on the reach for\nsubmanifolds without boundary. An estimator $\\hat{\\tau}$ of $\\tau\\_{M}$ is\nproposed in a framework where tangent spaces are known, and bounds assessing\nits efficiency are derived. In the case of i.i.d. random point cloud\n$\\mathbb{X}\\_{n}$, $\\hat{\\tau}(\\mathbb{X}\\_{n})$ is showed to achieve uniform\nexpected loss bounds over a $\\mathcal{C}^3$-like model. Finally, we obtain\nupper and lower bounds on the minimax rate for estimating the reach.\n", "versions": [{"version": "v1", "created": "Fri, 12 May 2017 13:43:45 GMT"}, {"version": "v2", "created": "Thu, 1 Feb 2018 07:25:03 GMT"}, {"version": "v3", "created": "Mon, 8 Apr 2019 14:42:42 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Aamari", "Eddie", "", "LPSM UMR 8001, CNRS"], ["Kim", "Jisu", "", "DATASHAPE"], ["Chazal", "Fr\u00e9d\u00e9ric", "", "DATASHAPE"], ["Michel", "Bertrand", "", "ECN, LMJL"], ["Rinaldo", "Alessandro", ""], ["Wasserman", "Larry", ""]]}, {"id": "1705.04770", "submitter": "M. Amin Rahimian", "authors": "Jan H\\k{a}z{\\l}a, Ali Jadbabaie, Elchanan Mossel, M. Amin Rahimian", "title": "Bayesian Decision Making in Groups is Hard", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.CC cs.LG cs.MA cs.SI stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the computations that Bayesian agents undertake when exchanging\nopinions over a network. The agents act repeatedly on their private information\nand take myopic actions that maximize their expected utility according to a\nfully rational posterior belief. We show that such computations are NP-hard for\ntwo natural utility functions: one with binary actions, and another where\nagents reveal their posterior beliefs. In fact, we show that distinguishing\nbetween posteriors that are concentrated on different states of the world is\nNP-hard. Therefore, even approximating the Bayesian posterior beliefs is hard.\nWe also describe a natural search algorithm to compute agents' actions, which\nwe call elimination of impossible signals, and show that if the network is\ntransitive, the algorithm can be modified to run in polynomial time.\n", "versions": [{"version": "v1", "created": "Fri, 12 May 2017 23:38:35 GMT"}, {"version": "v2", "created": "Thu, 19 Oct 2017 20:16:31 GMT"}, {"version": "v3", "created": "Sat, 14 Jul 2018 05:35:09 GMT"}, {"version": "v4", "created": "Sat, 27 Jul 2019 17:27:23 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["H\u0105z\u0142a", "Jan", ""], ["Jadbabaie", "Ali", ""], ["Mossel", "Elchanan", ""], ["Rahimian", "M. Amin", ""]]}, {"id": "1705.04867", "submitter": "Dogyoon Song", "authors": "Yihua Li, Devavrat Shah, Dogyoon Song and Christina Lee Yu", "title": "Nearest Neighbors for Matrix Estimation Interpreted as Blind Regression\n  for Latent Variable Model", "comments": "27 pages, 3 figures. To appear in IEEE Transactions on Information\n  Theory", "journal-ref": null, "doi": "10.1109/TIT.2019.2950299", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the setup of nonparametric {\\em blind regression} for estimating\nthe entries of a large $m \\times n$ matrix, when provided with a small, random\nfraction of noisy measurements. We assume that all rows $u \\in [m]$ and columns\n$i \\in [n]$ of the matrix are associated to latent features $x_{\\text{row}}(u)$\nand $x_{\\text{col}}(i)$ respectively, and the $(u,i)$-th entry of the matrix,\n$A(u, i)$ is equal to $f(x_{\\text{row}}(u), x_{\\text{col}}(i))$ for a latent\nfunction $f$. Given noisy observations of a small, random subset of the matrix\nentries, our goal is to estimate the unobserved entries of the matrix as well\nas to \"de-noise\" the observed entries. As the main result of this work, we\nintroduce a nearest-neighbor-based estimation algorithm, and establish its\nconsistency when the underlying latent function $f$ is Lipschitz, the\nunderlying latent space is a bounded diameter Polish space, and the random\nfraction of observed entries in the matrix is at least $\\max \\left( m^{-1 +\n\\delta}, n^{-1/2 + \\delta} \\right)$, for any $\\delta > 0$. As an important\nbyproduct, our analysis sheds light into the performance of the classical\ncollaborative filtering algorithm for matrix completion, which has been widely\nutilized in practice. Experiments with the MovieLens and Netflix datasets\nsuggest that our algorithm provides a principled improvement over basic\ncollaborative filtering and is competitive with matrix factorization methods.\nOur algorithm has a natural extension to the setting of tensor completion via\nflattening the tensor to matrix. When applied to the setting of image\nin-painting, which is a $3$-order tensor, we find that our approach is\ncompetitive with respect to state-of-art tensor completion algorithms across\nbenchmark images.\n", "versions": [{"version": "v1", "created": "Sat, 13 May 2017 18:01:50 GMT"}, {"version": "v2", "created": "Thu, 27 Jun 2019 13:47:41 GMT"}, {"version": "v3", "created": "Thu, 31 Oct 2019 18:38:51 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Li", "Yihua", ""], ["Shah", "Devavrat", ""], ["Song", "Dogyoon", ""], ["Yu", "Christina Lee", ""]]}, {"id": "1705.04974", "submitter": "Davy Paindaveine", "authors": "Davy Paindaveine, Germain Van Bever", "title": "On the maximal halfspace depth of permutation-invariant distributions on\n  the simplex", "comments": "14 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We compute the maximal halfspace depth for a class of permutation-invariant\ndistributions on the probability simplex. The derivations are based on\nstochastic ordering results that so far were only showed to be relevant for the\nBehrens-Fisher problem.\n", "versions": [{"version": "v1", "created": "Sun, 14 May 2017 15:17:36 GMT"}, {"version": "v2", "created": "Wed, 21 Jun 2017 08:40:27 GMT"}], "update_date": "2017-06-22", "authors_parsed": [["Paindaveine", "Davy", ""], ["Van Bever", "Germain", ""]]}, {"id": "1705.05305", "submitter": "Zongming Ma", "authors": "Debapratim Banerjee, Zongming Ma", "title": "Optimal hypothesis testing for stochastic block models with growing\n  degrees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.SI math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The present paper considers testing an Erdos--Renyi random graph model\nagainst a stochastic block model in the asymptotic regime where the average\ndegree of the graph grows with the graph size n. Our primary interest lies in\nthose cases in which the signal-to-noise ratio is at a constant level. Focusing\non symmetric two block alternatives, we first derive joint central limit\ntheorems for linear spectral statistics of power functions for properly\nrescaled graph adjacency matrices under both the null and local alternative\nhypotheses. The powers in the linear spectral statistics are allowed to grow to\ninfinity together with the graph size. In addition, we show that linear\nspectral statistics of Chebyshev polynomials are closely connected to signed\ncycles of growing lengths that determine the asymptotic likelihood ratio test\nfor the hypothesis testing problem of interest. This enables us to construct a\nsequence of test statistics that achieves the exact optimal asymptotic power\nwithin $O(n^3 \\log n)$ time complexity in the contiguous regime when $n^2\np_{n,av}^3 \\to\\infty$ where $p_{n,av}$ is the average connection probability.\nWe further propose a class of adaptive tests that are computationally tractable\nand completely data-driven. They achieve nontrivial powers in the contiguous\nregime and consistency in the singular regime whenever $n p_{n,av} \\to\\infty$.\nThese tests remain powerful when the alternative becomes a more general\nstochastic block model with more than two blocks.\n", "versions": [{"version": "v1", "created": "Mon, 15 May 2017 15:49:08 GMT"}, {"version": "v2", "created": "Thu, 10 Aug 2017 19:12:38 GMT"}], "update_date": "2017-08-14", "authors_parsed": [["Banerjee", "Debapratim", ""], ["Ma", "Zongming", ""]]}, {"id": "1705.05312", "submitter": "Isabel Schlangen", "authors": "Isabel Schlangen, Daniel E. Clark and Emmanuel D. Delande", "title": "Single-cluster PHD filter methods for joint multi-object filtering and\n  parameter estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many multi-object estimation problems require additional estimation of model\nor sensor parameters that are either common to all objects or related to\nunknown characterisation of one or more sensors. Important examples of these\ninclude registration of multiple sensors, estimating clutter profiles, and\nrobot localisation. Often these parameters are estimated separately to the\nmulti-object estimation process, which can lead to systematic errors or\noverconfidence in the estimates. These parameters can be estimated jointly with\nthe multi-object process based only on the sensor data using a single-cluster\npoint process model. This paper presents novel results for joint parameter\nestimation and multi-object filtering based on a single-cluster second-order\nProbability Hypothesis Density (PHD) and Cardinalised PHD (CPHD) filter.\nExperiments provide a comparison between the discussed approaches using\ndifferent likelihood functions.\n", "versions": [{"version": "v1", "created": "Mon, 15 May 2017 16:10:17 GMT"}], "update_date": "2017-05-16", "authors_parsed": [["Schlangen", "Isabel", ""], ["Clark", "Daniel E.", ""], ["Delande", "Emmanuel D.", ""]]}, {"id": "1705.05391", "submitter": "Maxim Rabinovich", "authors": "Maxim Rabinovich, Aaditya Ramdas, Michael I. Jordan, Martin J.\n  Wainwright", "title": "Optimal Rates and Tradeoffs in Multiple Testing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.AP stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiple hypothesis testing is a central topic in statistics, but despite\nabundant work on the false discovery rate (FDR) and the corresponding Type-II\nerror concept known as the false non-discovery rate (FNR), a fine-grained\nunderstanding of the fundamental limits of multiple testing has not been\ndeveloped. Our main contribution is to derive a precise non-asymptotic tradeoff\nbetween FNR and FDR for a variant of the generalized Gaussian sequence model.\nOur analysis is flexible enough to permit analyses of settings where the\nproblem parameters vary with the number of hypotheses $n$, including various\nsparse and dense regimes (with $o(n)$ and $\\mathcal{O}(n)$ signals). Moreover,\nwe prove that the Benjamini-Hochberg algorithm as well as the Barber-Cand\\`{e}s\nalgorithm are both rate-optimal up to constants across these regimes.\n", "versions": [{"version": "v1", "created": "Mon, 15 May 2017 18:00:25 GMT"}], "update_date": "2017-05-17", "authors_parsed": [["Rabinovich", "Maxim", ""], ["Ramdas", "Aaditya", ""], ["Jordan", "Michael I.", ""], ["Wainwright", "Martin J.", ""]]}, {"id": "1705.05543", "submitter": "Sen Zhao", "authors": "Sen Zhao, Daniela Witten, Ali Shojaie", "title": "In Defense of the Indefensible: A Very Naive Approach to\n  High-Dimensional Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A great deal of interest has recently focused on conducting inference on the\nparameters in a high-dimensional linear model.\n  In this paper, we consider a simple and very na\\\"{i}ve two-step procedure for\nthis task, in which we (i) fit a lasso model in order to obtain a subset of the\nvariables, and (ii) fit a least squares model on the lasso-selected set.\nConventional statistical wisdom tells us that we cannot make use of the\nstandard statistical inference tools for the resulting least squares model\n(such as confidence intervals and $p$-values), since we peeked at the data\ntwice: once in running the lasso, and again in fitting the least squares model.\nHowever, in this paper, we show that under a certain set of assumptions, with\nhigh probability, the set of variables selected by the lasso is identical to\nthe one selected by the noiseless lasso and is hence deterministic.\nConsequently, the na\\\"{i}ve two-step approach can yield asymptotically valid\ninference. We utilize this finding to develop the \\emph{na\\\"ive confidence\ninterval}, which can be used to draw inference on the regression coefficients\nof the model selected by the lasso, as well as the \\emph{na\\\"ive score test},\nwhich can be used to test the hypotheses regarding the full-model regression\ncoefficients.\n", "versions": [{"version": "v1", "created": "Tue, 16 May 2017 06:05:18 GMT"}, {"version": "v2", "created": "Thu, 7 Dec 2017 21:06:24 GMT"}, {"version": "v3", "created": "Wed, 1 Jul 2020 03:16:30 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Zhao", "Sen", ""], ["Witten", "Daniela", ""], ["Shojaie", "Ali", ""]]}, {"id": "1705.05677", "submitter": "Pierre-Andr\\'e Maugis", "authors": "Pierre-Andr\\'e G. Maugis and Sofia C. Olhede and Patrick J. Wolfe", "title": "Topology reveals universal features for network comparison", "comments": "95 pages, 10 figures, 2 algorithms", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.SI math.CO math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The topology of any complex system is key to understanding its structure and\nfunction. Fundamentally, algebraic topology guarantees that any system\nrepresented by a network can be understood through its closed paths. The length\nof each path provides a notion of scale, which is vitally important in\ncharacterizing dominant modes of system behavior. Here, by combining topology\nwith scale, we prove the existence of universal features which reveal the\ndominant scales of any network. We use these features to compare several\ncanonical network types in the context of a social media discussion which\nevolves through the sharing of rumors, leaks and other news. Our analysis\nenables for the first time a universal understanding of the balance between\nloops and tree-like structure across network scales, and an assessment of how\nthis balance interacts with the spreading of information online. Crucially, our\nresults allow networks to be quantified and compared in a purely model-free way\nthat is theoretically sound, fully automated, and inherently scalable.\n", "versions": [{"version": "v1", "created": "Tue, 16 May 2017 12:28:13 GMT"}], "update_date": "2017-05-17", "authors_parsed": [["Maugis", "Pierre-Andr\u00e9 G.", ""], ["Olhede", "Sofia C.", ""], ["Wolfe", "Patrick J.", ""]]}, {"id": "1705.05777", "submitter": "Dominic Edelmann", "authors": "Dominic Edelmann, Donald Richards and Daniel Vogel", "title": "The Distance Standard Deviation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The distance standard deviation, which arises in distance correlation\nanalysis of multivariate data, is studied as a measure of spread. The\nasymptotic distribution of the empirical distance standard deviation is derived\nunder the assumption of finite second moments. Applications are provided to\nhypothesis testing on a data set from materials science and to multivariate\nstatistical quality control. The distance standard deviation is compared to\nclassical scale measures for inference on the spread of heavy-tailed\ndistributions. Inequalities for the distance variance are derived, proving that\nthe distance standard deviation is bounded above by the classical standard\ndeviation and by Gini's mean difference. New expressions for the distance\nstandard deviation are obtained in terms of Gini's mean difference and the\nmoments of spacings of order statistics. It is also shown that the distance\nstandard deviation satisfies the axiomatic properties of a measure of spread.\n", "versions": [{"version": "v1", "created": "Tue, 16 May 2017 15:52:31 GMT"}, {"version": "v2", "created": "Wed, 11 Dec 2019 11:26:36 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Edelmann", "Dominic", ""], ["Richards", "Donald", ""], ["Vogel", "Daniel", ""]]}, {"id": "1705.06040", "submitter": "Masahito Hayashi", "authors": "Masahito Hayashi", "title": "Information Geometry Approach to Parameter Estimation in Hidden Markov\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT math.IT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the estimation of the transition matrix of a hidden Markovian\nprocess by using information geometry with respect to transition matrices. In\nthis paper, only the histogram of $k$-memory data is used for the estimation.\nTo establish our method, we focus on a partial observation model with the\nMarkovian process and we propose an efficient estimator whose asymptotic\nestimation error is given as the inverse of projective Fisher information of\ntransition matrices. This estimator is applied to the estimation of the\ntransition matrix of the hidden Markovian process. In this application, we\ncarefully discuss the equivalence problem for hidden Markovian process on the\ntangent space.\n", "versions": [{"version": "v1", "created": "Wed, 17 May 2017 08:16:16 GMT"}, {"version": "v2", "created": "Mon, 2 Apr 2018 06:53:42 GMT"}, {"version": "v3", "created": "Tue, 16 Mar 2021 07:26:17 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Hayashi", "Masahito", ""]]}, {"id": "1705.06226", "submitter": "Xiongtao Dai", "authors": "Xiongtao Dai, Hans-Georg M\\\"uller", "title": "Principal Component Analysis for Functional Data on Riemannian Manifolds\n  and Spheres", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Functional data analysis on nonlinear manifolds has drawn recent interest.\nSphere-valued functional data, which are encountered for example as movement\ntrajectories on the surface of the earth, are an important special case. We\nconsider an intrinsic principal component analysis for smooth Riemannian\nmanifold-valued functional data and study its asymptotic properties. Riemannian\nfunctional principal component analysis (RFPCA) is carried out by first mapping\nthe manifold-valued data through Riemannian logarithm maps to tangent spaces\naround the time-varying Fr\\'echet mean function, and then performing a\nclassical multivariate functional principal component analysis on the linear\ntangent spaces. Representations of the Riemannian manifold-valued functions and\nthe eigenfunctions on the original manifold are then obtained with exponential\nmaps. The tangent-space approximation through functional principal component\nanalysis is shown to be well-behaved in terms of controlling the residual\nvariation if the Riemannian manifold has nonnegative curvature. Specifically,\nwe derive a central limit theorem for the mean function, as well as root-$n$\nuniform convergence rates for other model components, including the covariance\nfunction, eigenfunctions, and functional principal component scores. Our\napplications include a novel framework for the analysis of longitudinal\ncompositional data, achieved by mapping longitudinal compositional data to\ntrajectories on the sphere, illustrated with longitudinal fruit fly behavior\npatterns. RFPCA is shown to be superior in terms of trajectory recovery in\ncomparison to an unrestricted functional principal component analysis in\napplications and simulations and is also found to produce principal component\nscores that are better predictors for classification compared to traditional\nfunctional functional principal component scores.\n", "versions": [{"version": "v1", "created": "Wed, 17 May 2017 16:02:17 GMT"}, {"version": "v2", "created": "Tue, 24 Oct 2017 04:48:29 GMT"}], "update_date": "2017-10-25", "authors_parsed": [["Dai", "Xiongtao", ""], ["M\u00fcller", "Hans-Georg", ""]]}, {"id": "1705.06386", "submitter": "Chao Gao", "authors": "Chao Gao, Fang Han, Cun-Hui Zhang", "title": "On Estimation of Isotonic Piecewise Constant Signals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a sequence of real data points $X_1,\\ldots, X_n$ with underlying\nmeans $\\theta^*_1,\\dots,\\theta^*_n$. This paper starts from studying the\nsetting that $\\theta^*_i$ is both piecewise constant and monotone as a function\nof the index $i$. For this, we establish the exact minimax rate of estimating\nsuch monotone functions, and thus give a non-trivial answer to an open problem\nin the shape-constrained analysis literature. The minimax rate involves an\ninteresting iterated logarithmic dependence on the dimension, a phenomenon that\nis revealed through characterizing the interplay between the isotonic shape\nconstraint and model selection complexity. We then develop a penalized\nleast-squares procedure for estimating the vector\n$\\theta^*=(\\theta^*_1,\\dots,\\theta^*_n)^T$. This estimator is shown to achieve\nthe derived minimax rate adaptively. For the proposed estimator, we further\nallow the model to be misspecified and derive oracle inequalities with the\noptimal rates, and show there exists a computationally efficient algorithm to\ncompute the exact solution.\n", "versions": [{"version": "v1", "created": "Thu, 18 May 2017 01:36:02 GMT"}, {"version": "v2", "created": "Mon, 26 Jun 2017 17:02:04 GMT"}, {"version": "v3", "created": "Sun, 15 Jul 2018 05:30:11 GMT"}, {"version": "v4", "created": "Fri, 2 Aug 2019 04:41:06 GMT"}], "update_date": "2019-08-05", "authors_parsed": [["Gao", "Chao", ""], ["Han", "Fang", ""], ["Zhang", "Cun-Hui", ""]]}, {"id": "1705.06427", "submitter": "Wang Zhou", "authors": "Weiming Li, Wang Zhou", "title": "On spectral properties of high-dimensional spatial-sign covariance\n  matrices in elliptical distributions with applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spatial-sign covariance matrix (SSCM) is an important substitute of sample\ncovariance matrix (SCM) in robust statistics. This paper investigates the SSCM\non its asymptotic spectral behaviors under high-dimensional elliptical\npopulations, where both the dimension $p$ of observations and the sample size\n$n$ tend to infinity with their ratio $p/n\\to c\\in (0, \\infty)$. The empirical\nspectral distribution of this nonparametric scatter matrix is shown to converge\nin distribution to a generalized Mar\\v{c}enko-Pastur law. Beyond this, a new\ncentral limit theorem (CLT) for general linear spectral statistics of the SSCM\nis also established. For polynomial spectral statistics, explicit formulae of\nthe limiting mean and covarance functions in the CLT are provided. The derived\nresults are then applied to an estimation procedure and a test procedure for\nthe spectrum of the shape component of population covariance matrices.\n", "versions": [{"version": "v1", "created": "Thu, 18 May 2017 06:26:26 GMT"}], "update_date": "2017-05-19", "authors_parsed": [["Li", "Weiming", ""], ["Zhou", "Wang", ""]]}, {"id": "1705.06533", "submitter": "Nestor Parolya Jun.-Prof. Dr.", "authors": "David Bauder, Taras Bodnar, Nestor Parolya and Wolfgang Schmid", "title": "Bayesian Inference of the Multi-Period Optimal Portfolio for an\n  Exponential Utility", "comments": "38 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST q-fin.PM q-fin.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the estimation of the multi-period optimal portfolio obtained by\nmaximizing an exponential utility. Employing Jeffreys' non-informative prior\nand the conjugate informative prior, we derive stochastic representations for\nthe optimal portfolio weights at each time point of portfolio reallocation.\nThis provides a direct access not only to the posterior distribution of the\nportfolio weights but also to their point estimates together with uncertainties\nand their asymptotic distributions. Furthermore, we present the posterior\npredictive distribution for the investor's wealth at each time point of the\ninvestment period in terms of a stochastic representation for the future wealth\nrealization. This in turn makes it possible to use quantile-based risk measures\nor to calculate the probability of default. We apply the suggested Bayesian\napproach to assess the uncertainty in the multi-period optimal portfolio by\nconsidering assets from the FTSE 100 in the weeks after the British referendum\nto leave the European Union. The behaviour of the novel portfolio estimation\nmethod in a precarious market situation is illustrated by calculating the\npredictive wealth, the risk associated with the holding portfolio, and the\ndefault probability in each period.\n", "versions": [{"version": "v1", "created": "Thu, 18 May 2017 11:41:04 GMT"}], "update_date": "2017-05-19", "authors_parsed": [["Bauder", "David", ""], ["Bodnar", "Taras", ""], ["Parolya", "Nestor", ""], ["Schmid", "Wolfgang", ""]]}, {"id": "1705.06615", "submitter": "Martin Royer", "authors": "Martin Royer (LMO)", "title": "Adaptive Clustering through Semidefinite Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the clustering problem through a flexible probabilistic model that\naims to identify an optimal partition on the sample X 1 , ..., X n. We perform\nexact clustering with high probability using a convex semidefinite estimator\nthat interprets as a corrected, relaxed version of K-means. The estimator is\nanalyzed through a non-asymptotic framework and showed to be optimal or\nnear-optimal in recovering the partition. Furthermore, its performances are\nshown to be adaptive to the problem's effective dimension, as well as to K the\nunknown number of groups in this partition. We illustrate the method's\nperformances in comparison to other classical clustering algorithms with\nnumerical experiments on simulated data.\n", "versions": [{"version": "v1", "created": "Thu, 18 May 2017 14:25:13 GMT"}], "update_date": "2017-05-19", "authors_parsed": [["Royer", "Martin", "", "LMO"]]}, {"id": "1705.06924", "submitter": "Johan Segers", "authors": "Betina Berghaus, Johan Segers", "title": "Weak convergence of the weighted empirical beta copula process", "comments": "19 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The empirical copula has proved to be useful in the construction and\nunderstanding of many statistical procedures related to dependence within\nrandom vectors. The empirical beta copula is a smoothed version of the\nempirical copula that enjoys better finite-sample properties. At the core lie\nfundamental results on the weak convergence of the empirical copula and\nempirical beta copula processes. Their scope of application can be increased by\nconsidering weighted versions of these processes. In this paper we show weak\nconvergence for the weighted empirical beta copula process. The weak\nconvergence result for the weighted empirical beta copula process is stronger\nthan the one for the empirical copula and its use is more straightforward. The\nsimplicity of its application is illustrated for weighted Cram\\'er--von Mises\ntests for independence and for the estimation of the Pickands dependence\nfunction of an extreme-value copula.\n", "versions": [{"version": "v1", "created": "Fri, 19 May 2017 10:36:55 GMT"}, {"version": "v2", "created": "Thu, 11 Jan 2018 08:57:56 GMT"}], "update_date": "2018-01-12", "authors_parsed": [["Berghaus", "Betina", ""], ["Segers", "Johan", ""]]}, {"id": "1705.06995", "submitter": "Yang Cao", "authors": "Yang Cao, Liyan Xie, Yao Xie, and Huan Xu", "title": "Nearly second-order asymptotic optimality of sequential change-point\n  detection with one-sample updates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequential change-point detection when the distribution parameters are\nunknown is a fundamental problem in statistics and machine learning. When the\npost-change parameters are unknown, we consider a set of detection procedures\nbased on sequential likelihood ratios with non-anticipating estimators\nconstructed using online convex optimization algorithms such as online mirror\ndescent, which provides a more versatile approach to tackle complex situations\nwhere recursive maximum likelihood estimators cannot be found. When the\nunderlying distributions belong to a exponential family and the estimators\nsatisfy the logarithm regret property, we show that this approach is nearly\nsecond-order asymptotically optimal. This means that the upper bound for the\nfalse alarm rate of the algorithm (measured by the average-run-length) meets\nthe lower bound asymptotically up to a log-log factor when the threshold tends\nto infinity. Our proof is achieved by making a connection between sequential\nchange-point and online convex optimization and leveraging the logarithmic\nregret bound property of online mirror descent algorithm. Numerical and real\ndata examples validate our theory.\n", "versions": [{"version": "v1", "created": "Fri, 19 May 2017 13:53:14 GMT"}, {"version": "v2", "created": "Fri, 1 Sep 2017 00:43:32 GMT"}, {"version": "v3", "created": "Thu, 16 Nov 2017 15:48:02 GMT"}, {"version": "v4", "created": "Mon, 4 Dec 2017 23:31:58 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["Cao", "Yang", ""], ["Xie", "Liyan", ""], ["Xie", "Yao", ""], ["Xu", "Huan", ""]]}, {"id": "1705.07019", "submitter": "Dave Zachariah", "authors": "Dave Zachariah and Petre Stoica", "title": "Model-Robust Counterfactual Prediction Method", "comments": null, "journal-ref": "ICML Workshop, ML for Causal Inference, Counterfactual Prediction,\n  and Autonomous Action, 2018", "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a novel method for counterfactual analysis based on observational\ndata using prediction intervals for units under different exposures. Unlike\nmethods that target heterogeneous or conditional average treatment effects of\nan exposure, the proposed approach aims to take into account the irreducible\ndispersions of counterfactual outcomes so as to quantify the relative impact of\ndifferent exposures. The prediction intervals are constructed in a\ndistribution-free and model-robust manner based on the conformal prediction\napproach. The computational obstacles to this approach are circumvented by\nleveraging properties of a tuning-free method that learns sparse additive\npredictor models for counterfactual outcomes. The method is illustrated using\nboth real and synthetic data.\n", "versions": [{"version": "v1", "created": "Fri, 19 May 2017 14:29:13 GMT"}, {"version": "v2", "created": "Fri, 27 Oct 2017 13:22:57 GMT"}, {"version": "v3", "created": "Wed, 20 Dec 2017 13:10:43 GMT"}, {"version": "v4", "created": "Wed, 7 Feb 2018 10:08:40 GMT"}, {"version": "v5", "created": "Mon, 28 May 2018 19:48:06 GMT"}], "update_date": "2018-07-18", "authors_parsed": [["Zachariah", "Dave", ""], ["Stoica", "Petre", ""]]}, {"id": "1705.07048", "submitter": "Daniel Hsu", "authors": "Daniel Hsu, Kevin Shi, Xiaorui Sun", "title": "Linear regression without correspondence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article considers algorithmic and statistical aspects of linear\nregression when the correspondence between the covariates and the responses is\nunknown. First, a fully polynomial-time approximation scheme is given for the\nnatural least squares optimization problem in any constant dimension. Next, in\nan average-case and noise-free setting where the responses exactly correspond\nto a linear function of i.i.d. draws from a standard multivariate normal\ndistribution, an efficient algorithm based on lattice basis reduction is shown\nto exactly recover the unknown linear function in arbitrary dimension. Finally,\nlower bounds on the signal-to-noise ratio are established for approximate\nrecovery of the unknown linear function by any estimator.\n", "versions": [{"version": "v1", "created": "Fri, 19 May 2017 15:22:38 GMT"}, {"version": "v2", "created": "Tue, 7 Nov 2017 23:16:39 GMT"}], "update_date": "2017-11-09", "authors_parsed": [["Hsu", "Daniel", ""], ["Shi", "Kevin", ""], ["Sun", "Xiaorui", ""]]}, {"id": "1705.07196", "submitter": "Vincent Guigues", "authors": "Vincent Guigues, Anatoli Juditsky, Arkadi Nemirovski", "title": "Hypothesis Testing via Euclidean Separation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss an \"operational\" approach to testing convex composite hypotheses\nwhen the underlying distributions are heavy-tailed. It relies upon Euclidean\nseparation of convex sets and can be seen as an extension of the approach to\ntesting by convex optimization developed in [8, 12]. In particular, we show how\none can construct quasi-optimal testing procedures for families of\ndistributions which are majorated, in a certain precise sense, by a\nsub-spherical symmetric one and study the relationship between tests based on\nEuclidean separation and \"potential-based tests.\" We apply the promoted\nmethodology in the problem of sequential detection and illustrate its practical\nimplementation in an application to sequential detection of changes in the\ninput of a dynamic system.\n  [8] Goldenshluger, Alexander and Juditsky, Anatoli and Nemirovski, Arkadi,\nHypothesis testing by convex optimization, Electronic Journal of Statistics,9\n(2):1645-1712, 2015. [12] Juditsky, Anatoli and Nemirovski, Arkadi, Hypothesis\ntesting via affine detectors, Electronic Journal of Statistics, 10:2204--2242,\n2016.\n", "versions": [{"version": "v1", "created": "Fri, 19 May 2017 21:27:24 GMT"}, {"version": "v2", "created": "Sun, 28 May 2017 21:01:49 GMT"}, {"version": "v3", "created": "Thu, 8 Nov 2018 15:02:06 GMT"}, {"version": "v4", "created": "Mon, 12 Nov 2018 18:57:25 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Guigues", "Vincent", ""], ["Juditsky", "Anatoli", ""], ["Nemirovski", "Arkadi", ""]]}, {"id": "1705.07349", "submitter": "Ning Xu", "authors": "Ning Xu, Jian Hong, Timothy C.G. Fisher", "title": "$\\left( \\beta, \\varpi \\right)$-stability for cross-validation and the\n  choice of the number of folds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a new concept of stability for cross-validation,\ncalled the $\\left( \\beta, \\varpi \\right)$-stability, and use it as a new\nperspective to build the general theory for cross-validation. The $\\left(\n\\beta, \\varpi \\right)$-stability mathematically connects the generalization\nability and the stability of the cross-validated model via the Rademacher\ncomplexity. Our result reveals mathematically the effect of cross-validation\nfrom two sides: on one hand, cross-validation picks the model with the best\nempirical generalization ability by validating all the alternatives on test\nsets; on the other hand, cross-validation may compromise the stability of the\nmodel selection by causing subsampling error. Moreover, the difference between\ntraining and test errors in q\\textsuperscript{th} round, sometimes referred to\nas the generalization error, might be autocorrelated on q. Guided by the ideas\nabove, the $\\left( \\beta, \\varpi \\right)$-stability help us derivd a new class\nof Rademacher bounds, referred to as the one-round/convoluted Rademacher\nbounds, for the stability of cross-validation in both the i.i.d.\\ and\nnon-i.i.d.\\ cases. For both light-tail and heavy-tail losses, the new bounds\nquantify the stability of the one-round/average test error of the\ncross-validated model in terms of its one-round/average training error, the\nsample sizes $n$, number of folds $K$, the tail property of the loss (encoded\nas Orlicz-$\\Psi_\\nu$ norms) and the Rademacher complexity of the model class\n$\\Lambda$. The new class of bounds not only quantitatively reveals the\nstability of the generalization ability of the cross-validated model, it also\nshows empirically the optimal choice for number of folds $K$, at which the\nupper bound of the one-round/average test error is lowest, or, to put it in\nanother way, where the test error is most stable.\n", "versions": [{"version": "v1", "created": "Sat, 20 May 2017 19:46:01 GMT"}, {"version": "v2", "created": "Sat, 27 May 2017 22:53:42 GMT"}, {"version": "v3", "created": "Tue, 30 May 2017 01:44:13 GMT"}, {"version": "v4", "created": "Mon, 19 Jun 2017 10:54:21 GMT"}, {"version": "v5", "created": "Thu, 6 Jul 2017 00:21:03 GMT"}], "update_date": "2017-07-07", "authors_parsed": [["Xu", "Ning", ""], ["Hong", "Jian", ""], ["Fisher", "Timothy C. G.", ""]]}, {"id": "1705.07382", "submitter": "Nicolas Garcia Trillos", "authors": "Nicolas Garcia Trillos and Daniel Sanz-Alonso", "title": "The Bayesian update: variational formulations and gradient flows", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.AP stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Bayesian update can be viewed as a variational problem by characterizing\nthe posterior as the minimizer of a functional. The variational viewpoint is\nfar from new and is at the heart of popular methods for posterior\napproximation. However, some of its consequences seem largely unexplored. We\nfocus on the following one: defining the posterior as the minimizer of a\nfunctional gives a natural path towards the posterior by moving in the\ndirection of steepest descent of the functional. This idea is made precise\nthrough the theory of gradient flows, allowing to bring new tools to the study\nof Bayesian models and algorithms. Since the posterior may be characterized as\nthe minimizer of different functionals, several variational formulations may be\nconsidered. We study three of them and their three associated gradient flows.\nWe show that, in all cases, the rate of convergence of the flows to the\nposterior can be bounded by the geodesic convexity of the functional to be\nminimized. Each gradient flow naturally suggests a nonlinear diffusion with the\nposterior as invariant distribution. These diffusions may be discretized to\nbuild proposals for Markov chain Monte Carlo (MCMC) algorithms. By\nconstruction, the diffusions are guaranteed to satisfy a certain optimality\ncondition, and rates of convergence are given by the convexity of the\nfunctionals. We use this observation to propose a criterion for the choice of\nmetric in Riemannian MCMC methods.\n", "versions": [{"version": "v1", "created": "Sun, 21 May 2017 02:44:07 GMT"}, {"version": "v2", "created": "Fri, 2 Nov 2018 02:55:57 GMT"}], "update_date": "2018-11-05", "authors_parsed": [["Trillos", "Nicolas Garcia", ""], ["Sanz-Alonso", "Daniel", ""]]}, {"id": "1705.07408", "submitter": "Mikhail  Ermakov s", "authors": "Mikhail Ermakov", "title": "On asymptotically minimax nonparametric detection of signal in Gaussian\n  white noise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For the problem of nonparametric detection of signal in Gaussian white noise\nwe point out strong asymptotically minimax tests. The sets of alternatives are\na ball in Besov space $B^r_{2\\infty}$ with \"small\" balls in $L_2$ removed.\n", "versions": [{"version": "v1", "created": "Sun, 21 May 2017 07:43:53 GMT"}], "update_date": "2017-05-23", "authors_parsed": [["Ermakov", "Mikhail", ""]]}, {"id": "1705.07411", "submitter": "Thomas Kahle", "authors": "Thomas Kahle and Johannes Rauh and Seth Sullivant", "title": "Algebraic Aspects of Conditional Independence and Graphical Models", "comments": "20 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.AC stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This chapter of the forthcoming Handbook of Graphical Models contains an\noverview of basic theorems and techniques from algebraic geometry and how they\ncan be applied to the study of conditional independence and graphical models.\nIt also introduces binomial ideals and some ideas from real algebraic geometry.\nWhen random variables are discrete or Gaussian, tools from computational\nalgebraic geometry can be used to understand implications between conditional\nindependence statements. This is accomplished by computing primary\ndecompositions of conditional independence ideals. As examples the chapter\npresents in detail the graphical model of a four cycle and the intersection\naxiom, a certain implication of conditional independence statements. Another\nimportant problem in the area is to determine all constraints on a graphical\nmodel, for example, equations determined by trek separation. The full set of\nequality constraints can be determined by computing the model's vanishing\nideal. The chapter illustrates these techniques and ideas with examples from\nthe literature and provides references for further reading.\n", "versions": [{"version": "v1", "created": "Sun, 21 May 2017 08:11:44 GMT"}], "update_date": "2017-05-23", "authors_parsed": [["Kahle", "Thomas", ""], ["Rauh", "Johannes", ""], ["Sullivant", "Seth", ""]]}, {"id": "1705.07463", "submitter": "Dionysios Kalogerias", "authors": "Dionysios S. Kalogerias, Athina P. Petropulu", "title": "Spatially Controlled Relay Beamforming: $2$-Stage Optimal Policies", "comments": "68 pages, 10 figures, this work constitutes an extended\n  preprint/version of a two part paper (soon to be) submitted for publication\n  to the IEEE Transactions on Signal Processing in Spring/Summer 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.IT math.IT math.ST stat.AP stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of enhancing Quality-of-Service (QoS) in power constrained,\nmobile relay beamforming networks, by optimally and dynamically controlling the\nmotion of the relaying nodes, is considered, in a dynamic channel environment.\nWe assume a time slotted system, where the relays update their positions before\nthe beginning of each time slot. Modeling the wireless channel as a Gaussian\nspatiotemporal stochastic field, we propose a novel $2$-stage stochastic\nprogramming problem formulation for optimally specifying the positions of the\nrelays at each time slot, such that the expected QoS of the network is\nmaximized, based on causal Channel State Information (CSI) and under a total\nrelay transmit power budget. This results in a schema where, at each time slot,\nthe relays, apart from optimally beamforming to the destination, also\noptimally, predictively decide their positions at the next time slot, based on\ncausally accumulated experience. Exploiting either the Method of Statistical\nDifferentials, or the multidimensional Gauss-Hermite Quadrature Rule, the\nstochastic program considered is shown to be approximately equivalent to a set\nof simple subproblems, which are solved in a distributed fashion, one at each\nrelay. Optimality and performance of the proposed spatially controlled system\nare also effectively assessed, under a rigorous technical framework; strict\noptimality is rigorously demonstrated via the development of a version of the\nFundamental Lemma of Stochastic Control, and, performance-wise, it is shown\nthat, quite interestingly, the optimal average network QoS exhibits an\nincreasing trend across time slots, despite our myopic problem formulation.\nNumerical simulations are presented, experimentally corroborating the success\nof the proposed approach and the validity of our theoretical predictions.\n", "versions": [{"version": "v1", "created": "Sun, 21 May 2017 15:29:13 GMT"}], "update_date": "2017-05-23", "authors_parsed": [["Kalogerias", "Dionysios S.", ""], ["Petropulu", "Athina P.", ""]]}, {"id": "1705.07477", "submitter": "Tianyang Li", "authors": "Tianyang Li, Liu Liu, Anastasios Kyrillidis, Constantine Caramanis", "title": "Statistical inference using SGD", "comments": "To appear in AAAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel method for frequentist statistical inference in\n$M$-estimation problems, based on stochastic gradient descent (SGD) with a\nfixed step size: we demonstrate that the average of such SGD sequences can be\nused for statistical inference, after proper scaling. An intuitive analysis\nusing the Ornstein-Uhlenbeck process suggests that such averages are\nasymptotically normal. From a practical perspective, our SGD-based inference\nprocedure is a first order method, and is well-suited for large scale problems.\nTo show its merits, we apply it to both synthetic and real datasets, and\ndemonstrate that its accuracy is comparable to classical statistical methods,\nwhile requiring potentially far less computation.\n", "versions": [{"version": "v1", "created": "Sun, 21 May 2017 17:01:51 GMT"}, {"version": "v2", "created": "Sun, 19 Nov 2017 20:59:52 GMT"}], "update_date": "2017-11-21", "authors_parsed": [["Li", "Tianyang", ""], ["Liu", "Liu", ""], ["Kyrillidis", "Anastasios", ""], ["Caramanis", "Constantine", ""]]}, {"id": "1705.07527", "submitter": "Subhabrata Sen", "authors": "Rajarshi Mukherjee and Subhabrata Sen", "title": "Testing Degree Corrections in Stochastic Block Models", "comments": "Major re-write; Determines detection thresholds below log n graph\n  density; 61 pages, 1 Fig", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study sharp detection thresholds for degree corrections in Stochastic\nBlock Models in the context of a goodness of fit problem, and explore the\neffect of the unknown community assignment (a high dimensional nuisance\nparameter) and the graph density on testing for degree corrections. When degree\ncorrections are relatively dense, a simple test based on the total number of\nedges is asymptotically optimal. For sparse degree corrections, the results\nundergo several changes in behavior depending on density of the underlying\nStochastic Block Model. For graphs which are not extremely sparse, optimal\ntests are based on Higher Criticism or Maximum Degree type tests based on a\nlinear combination of within and across (estimated) community degrees. In the\nspecial case of balanced communities, a simple degree based Higher Criticism\nTest (Mukherjee, Mukherjee, Sen 2016) is optimal in case the graph is not\ncompletely dense, while the more complicated linear combination based procedure\nis required in the completely dense setting.\n  The ``necessity\" of the two step procedure is demonstrated for the case of\nbalanced communities by the failure of the ordinary Maximum Degree Test in\nachieving sharp constants. Finally for extremely sparse graphs the optimal\nrates change, and a version of the maximum degree test with a different\nrejection region is shown to be optimal.\n", "versions": [{"version": "v1", "created": "Mon, 22 May 2017 00:40:40 GMT"}, {"version": "v2", "created": "Mon, 15 Jul 2019 15:58:30 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Mukherjee", "Rajarshi", ""], ["Sen", "Subhabrata", ""]]}, {"id": "1705.07577", "submitter": "Rajarshi Mukherjee", "authors": "Rajarshi Mukherjee, Whitney K. Newey, and James M. Robins", "title": "Semiparametric Efficient Empirical Higher Order Influence Function\n  Estimators", "comments": "16 pages, 1 Typo Corrected", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robins et al. (2008, 2016) applied the theory of higher order influence\nfunctions (HOIFs) to derive an estimator of the mean of an outcome Y in a\nmissing data model with Y missing at random conditional on a vector X of\ncontinuous covariates; their estimator, in contrast to previous estimators, is\nsemiparametric efficient under minimal conditions. However, the Robins et al.\n(2008, 2016) estimator depends on a non-parametric estimate of the density of\nX. In this paper, we introduce a new HOIF estimator that has the same\nasymptotic properties as their estimator but does not require nonparametric\nestimation of a multivariate density, which is important because accurate\nestimation of a high dimensional density is not feasible at the moderate sample\nsizes often encountered in applications. We also show that our estimator can be\ngeneralized to the entire class of functionals considered by Robins et al.\n(2008) which include the average effect of a treatment on a response Y when a\nvector X suffices to control confounding and the expected conditional variance\nof a response Y given a vector X.\n", "versions": [{"version": "v1", "created": "Mon, 22 May 2017 06:52:50 GMT"}, {"version": "v2", "created": "Tue, 23 May 2017 22:20:31 GMT"}, {"version": "v3", "created": "Fri, 20 Oct 2017 02:56:04 GMT"}], "update_date": "2017-10-23", "authors_parsed": [["Mukherjee", "Rajarshi", ""], ["Newey", "Whitney K.", ""], ["Robins", "James M.", ""]]}, {"id": "1705.07605", "submitter": "Marek Omelka", "authors": "Natalie Neumeyer, Marek Omelka, Sarka Hudecova", "title": "A copula approach for dependence modeling in multivariate nonparametric\n  time series", "comments": null, "journal-ref": null, "doi": "10.1016/j.jmva.2018.11.016", "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is concerned with modeling the dependence structure of two (or\nmore) time-series in the presence of a (possible multivariate) covariate which\nmay include past values of the time series. We assume that the covariate\ninfluences only the conditional mean and the conditional variance of each of\nthe time series but the distribution of the standardized innovations is not\ninfluenced by the covariate and is stable in time. The joint distribution of\nthe time series is then determined by the conditional means, the conditional\nvariances and the marginal distributions of the innovations, which we estimate\nnonparametrically, and the copula of the innovations, which represents the\ndependency structure. We consider a nonparametric as well as a semiparametric\nestimator based on the estimated residuals. We show that under suitable\nassumptions these copula estimators are asymptotically equivalent to estimators\nthat would be based on the unobserved innovations. The theoretical results are\nillustrated by simulations and a real data example.\n", "versions": [{"version": "v1", "created": "Mon, 22 May 2017 08:27:37 GMT"}, {"version": "v2", "created": "Mon, 10 Dec 2018 15:19:49 GMT"}], "update_date": "2018-12-11", "authors_parsed": [["Neumeyer", "Natalie", ""], ["Omelka", "Marek", ""], ["Hudecova", "Sarka", ""]]}, {"id": "1705.07635", "submitter": "Nadhir Ben Rached", "authors": "Mohamed-Slim Alouini and Nadhir Ben Rached and Abla Kammoun and Raul\n  Tempone", "title": "On the Efficient Simulation of the Left-Tail of the Sum of Correlated\n  Log-normal Variates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The sum of Log-normal variates is encountered in many challenging\napplications such as in performance analysis of wireless communication systems\nand in financial engineering. Several approximation methods have been developed\nin the literature, the accuracy of which is not ensured in the tail regions.\nThese regions are of primordial interest wherein small probability values have\nto be evaluated with high precision. Variance reduction techniques are known to\nyield accurate, yet efficient, estimates of small probability values. Most of\nthe existing approaches, however, have considered the problem of estimating the\nright-tail of the sum of Log-normal random variables (RVS). In the present\nwork, we consider instead the estimation of the left-tail of the sum of\ncorrelated Log-normal variates with Gaussian copula under a mild assumption on\nthe covariance matrix. We propose an estimator combining an existing\nmean-shifting importance sampling approach with a control variate technique.\nThe main result is that the proposed estimator has an asymptotically vanishing\nrelative error which represents a major finding in the context of the left-tail\nsimulation of the sum of Log-normal RVs. Finally, we assess by various\nsimulation results the performances of the proposed estimator compared to\nexisting estimators.\n", "versions": [{"version": "v1", "created": "Mon, 22 May 2017 09:54:08 GMT"}, {"version": "v2", "created": "Fri, 26 May 2017 14:54:30 GMT"}], "update_date": "2017-05-29", "authors_parsed": [["Alouini", "Mohamed-Slim", ""], ["Rached", "Nadhir Ben", ""], ["Kammoun", "Abla", ""], ["Tempone", "Raul", ""]]}, {"id": "1705.07987", "submitter": "Johan Segers", "authors": "Holger Rootz\\'en and Johan Segers and Jennifer L. Wadsworth", "title": "Multivariate generalized Pareto distributions: parametrizations,\n  representations, and properties", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multivariate generalized Pareto distributions arise as the limit\ndistributions of exceedances over multivariate thresholds of random vectors in\nthe domain of attraction of a max-stable distribution. These distributions can\nbe parametrized and represented in a number of different ways. Moreover,\ngeneralized Pareto distributions enjoy a number of interesting stability\nproperties. An overview of the main features of such distributions are given,\nexpressed compactly in several parametrizations, giving the potential user of\nthese distributions a convenient catalogue of ways to handle and work with\ngeneralized Pareto distributions.\n", "versions": [{"version": "v1", "created": "Mon, 22 May 2017 20:35:05 GMT"}], "update_date": "2017-05-24", "authors_parsed": [["Rootz\u00e9n", "Holger", ""], ["Segers", "Johan", ""], ["Wadsworth", "Jennifer L.", ""]]}, {"id": "1705.07997", "submitter": "Justin Khim", "authors": "Justin Khim and Po-Ling Loh", "title": "Permutation Tests for Infection Graphs", "comments": "70 pages, 15 figures, 2 tables", "journal-ref": "Journal of the American Statistical Association, 2020", "doi": "10.1080/01621459.2019.1700128", "report-no": null, "categories": "math.ST cs.SI stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We formulate and analyze a novel hypothesis testing problem for inferring the\nedge structure of an infection graph. In our model, a disease spreads over a\nnetwork via contagion or random infection, where the random variables governing\nthe rates of contracting the disease from neighbors or random infection are\nindependent exponential random variables with unknown rate parameters. A subset\nof nodes is also censored uniformly at random. Given the statuses of nodes in\nthe network, the goal is to determine the underlying graph. We present a\nprocedure based on permutation testing, and we derive sufficient conditions for\nthe validity of our test in terms of automorphism groups of the graphs\ncorresponding to the null and alternative hypotheses. Further, the test is\nvalid more generally for infection processes satisfying a basic symmetry\ncondition. Our test is easy to compute and does not involve estimating unknown\nparameters governing the process. We also derive risk bounds for our\npermutation test in a variety of settings, and motivate our test statistic in\nterms of approximate equivalence to likelihood ratio testing and maximin tests.\nWe conclude with an application to real data from an HIV infection network.\n", "versions": [{"version": "v1", "created": "Mon, 22 May 2017 20:54:35 GMT"}, {"version": "v2", "created": "Mon, 6 Aug 2018 20:46:31 GMT"}, {"version": "v3", "created": "Mon, 16 Dec 2019 19:55:47 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Khim", "Justin", ""], ["Loh", "Po-Ling", ""]]}, {"id": "1705.08020", "submitter": "Qingyuan Zhao", "authors": "Qingyuan Zhao, Dylan S. Small and Ashkan Ertefaie", "title": "Selective inference for effect modification via the lasso", "comments": "32 pages, 4 figures, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effect modification occurs when the effect of the treatment on an outcome\nvaries according to the level of other covariates and often has important\nimplications in decision making. When there are tens or hundreds of covariates,\nit becomes necessary to use the observed data to select a simpler model for\neffect modification and then make valid statistical inference. We propose a two\nstage procedure to solve this problem. First, we use Robinson's transformation\nto decouple the nuisance parameters from the treatment effect of interest and\nuse machine learning algorithms to estimate the nuisance parameters. Next,\nafter plugging in the estimates of the nuisance parameters, we use the Lasso to\nchoose a low-complexity model for effect modification. Compared to a full model\nconsisting of all the covariates, the selected model is much more\ninterpretable. Compared to the univariate subgroup analyses, the selected model\ngreatly reduces the number of false discoveries. We show that the conditional\nselective inference for the selected model is asymptotically valid given the\nrate assumptions in classical semiparametric regression. Extensive simulation\nstudies are conducted to verify the asymptotic results and an epidemiological\napplication is used to demonstrate the method.\n", "versions": [{"version": "v1", "created": "Mon, 22 May 2017 21:57:28 GMT"}, {"version": "v2", "created": "Wed, 5 Jul 2017 16:53:31 GMT"}, {"version": "v3", "created": "Mon, 8 Oct 2018 19:49:43 GMT"}], "update_date": "2018-10-10", "authors_parsed": [["Zhao", "Qingyuan", ""], ["Small", "Dylan S.", ""], ["Ertefaie", "Ashkan", ""]]}, {"id": "1705.08184", "submitter": "Roi Weiss", "authors": "Aryeh Kontorovich, Sivan Sabato, Roi Weiss", "title": "Nearest-Neighbor Sample Compression: Efficiency, Consistency, Infinite\n  Dimensions", "comments": null, "journal-ref": "Advances in Neural Information Processing Systems 30 (NIPS),\n  1573--1583, 2017", "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine the Bayes-consistency of a recently proposed\n1-nearest-neighbor-based multiclass learning algorithm. This algorithm is\nderived from sample compression bounds and enjoys the statistical advantages of\ntight, fully empirical generalization bounds, as well as the algorithmic\nadvantages of a faster runtime and memory savings. We prove that this algorithm\nis strongly Bayes-consistent in metric spaces with finite doubling dimension\n--- the first consistency result for an efficient nearest-neighbor sample\ncompression scheme. Rather surprisingly, we discover that this algorithm\ncontinues to be Bayes-consistent even in a certain infinite-dimensional\nsetting, in which the basic measure-theoretic conditions on which classic\nconsistency proofs hinge are violated. This is all the more surprising, since\nit is known that $k$-NN is not Bayes-consistent in this setting. We pose\nseveral challenging open problems for future research.\n", "versions": [{"version": "v1", "created": "Tue, 23 May 2017 11:21:22 GMT"}, {"version": "v2", "created": "Wed, 25 Oct 2017 10:55:59 GMT"}, {"version": "v3", "created": "Wed, 26 Jun 2019 06:47:20 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Kontorovich", "Aryeh", ""], ["Sabato", "Sivan", ""], ["Weiss", "Roi", ""]]}, {"id": "1705.08301", "submitter": "Samuel Cohen", "authors": "Samuel N. Cohen", "title": "Data and uncertainty in extreme risks - a nonlinear expectations\n  approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR q-fin.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimation of tail quantities, such as expected shortfall or Value at Risk,\nis a difficult problem. We show how the theory of nonlinear expectations, in\nparticular the Data-robust expectation introduced in [5], can assist in the\nquantification of statistical uncertainty for these problems. However, when we\nare in a heavy-tailed context (in particular when our data are described by a\nPareto distribution, as is common in much of extreme value theory), the theory\nof [5] is insufficient, and requires an additional regularization step which we\nintroduce. By asking whether this regularization is possible, we obtain a\nqualitative requirement for reliable estimation of tail quantities and risk\nmeasures, in a Pareto setting.\n", "versions": [{"version": "v1", "created": "Tue, 23 May 2017 14:18:54 GMT"}, {"version": "v2", "created": "Wed, 14 Feb 2018 15:04:10 GMT"}], "update_date": "2018-02-15", "authors_parsed": [["Cohen", "Samuel N.", ""]]}, {"id": "1705.08391", "submitter": "Yingjie Fei", "authors": "Yingjie Fei and Yudong Chen", "title": "Exponential error rates of SDP for block models: Beyond Grothendieck's\n  inequality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.SI math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider the cluster estimation problem under the Stochastic\nBlock Model. We show that the semidefinite programming (SDP) formulation for\nthis problem achieves an error rate that decays exponentially in the\nsignal-to-noise ratio. The error bound implies weak recovery in the sparse\ngraph regime with bounded expected degrees, as well as exact recovery in the\ndense regime. An immediate corollary of our results yields error bounds under\nthe Censored Block Model. Moreover, these error bounds are robust, continuing\nto hold under heterogeneous edge probabilities and a form of the so-called\nmonotone attack.\n  Significantly, this error rate is achieved by the SDP solution itself without\nany further pre- or post-processing, and improves upon existing\npolynomially-decaying error bounds proved using the Grothendieck\\textquoteright\ns inequality. Our analysis has two key ingredients: (i) showing that the graph\nhas a well-behaved spectrum, even in the sparse regime, after discounting an\nexponentially small number of edges, and (ii) an order-statistics argument that\ngoverns the final error rate. Both arguments highlight the implicit\nregularization effect of the SDP formulation.\n", "versions": [{"version": "v1", "created": "Tue, 23 May 2017 16:14:41 GMT"}], "update_date": "2017-05-24", "authors_parsed": [["Fei", "Yingjie", ""], ["Chen", "Yudong", ""]]}, {"id": "1705.08393", "submitter": "David Gerard", "authors": "David Gerard and Matthew Stephens", "title": "Unifying and Generalizing Methods for Removing Unwanted Variation Based\n  on Negative Controls", "comments": "34 pages, 6 figures, methods implemented at\n  https://github.com/dcgerard/vicar , results reproducible at\n  https://github.com/dcgerard/ruvb_sims", "journal-ref": null, "doi": "10.5705/ss.202018.0345", "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unwanted variation, including hidden confounding, is a well-known problem in\nmany fields, particularly large-scale gene expression studies. Recent proposals\nto use control genes --- genes assumed to be unassociated with the covariates\nof interest --- have led to new methods to deal with this problem. Going by the\nmoniker Removing Unwanted Variation (RUV), there are many versions --- RUV1,\nRUV2, RUV4, RUVinv, RUVrinv, RUVfun. In this paper, we introduce a general\nframework, RUV*, that both unites and generalizes these approaches. This\nunifying framework helps clarify connections between existing methods. In\nparticular we provide conditions under which RUV2 and RUV4 are equivalent. The\nRUV* framework also preserves an advantage of RUV approaches --- their\nmodularity --- which facilitates the development of novel methods based on\nexisting matrix imputation algorithms. We illustrate this by implementing RUVB,\na version of RUV* based on Bayesian factor analysis. In realistic simulations\nbased on real data we found that RUVB is competitive with existing methods in\nterms of both power and calibration, although we also highlight the challenges\nof providing consistently reliable calibration among data sets.\n", "versions": [{"version": "v1", "created": "Tue, 23 May 2017 16:19:42 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Gerard", "David", ""], ["Stephens", "Matthew", ""]]}, {"id": "1705.08413", "submitter": "Kyungchul Song", "authors": "Ji Hyung Lee and Kyungchul Song", "title": "Stable Limit Theorems for Empirical Processes under Conditional\n  Neighborhood Dependence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a new concept of stochastic dependence among many\nrandom variables which we call conditional neighborhood dependence (CND).\nSuppose that there are a set of random variables and a set of sigma algebras\nwhere both sets are indexed by the same set endowed with a neighborhood system.\nWhen the set of random variables satisfies CND, any two non-adjacent sets of\nrandom variables are conditionally independent given sigma algebras having\nindices in one of the two sets' neighborhood. Random variables with CND include\nthose with conditional dependency graphs and a class of Markov random fields\nwith a global Markov property. The CND property is useful for modeling\ncross-sectional dependence governed by a complex, large network. This paper\nprovides two main results. The first result is a stable central limit theorem\nfor a sum of random variables with CND. The second result is a Donsker-type\nresult of stable convergence of empirical processes indexed by a class of\nfunctions satisfying a certain bracketing entropy condition when the random\nvariables satisfy CND.\n", "versions": [{"version": "v1", "created": "Tue, 23 May 2017 17:02:03 GMT"}, {"version": "v2", "created": "Thu, 1 Jun 2017 12:59:20 GMT"}, {"version": "v3", "created": "Mon, 17 Jul 2017 21:04:21 GMT"}, {"version": "v4", "created": "Tue, 5 Jun 2018 00:36:19 GMT"}], "update_date": "2018-06-06", "authors_parsed": [["Lee", "Ji Hyung", ""], ["Song", "Kyungchul", ""]]}, {"id": "1705.08524", "submitter": "Alexander Volfovsky", "authors": "Ravi Jagadeesan, Natesh Pillai, Alexander Volfovsky", "title": "Designs for estimating the treatment effect in networks with\n  interference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce new, easily implementable designs for drawing\ncausal inference from randomized experiments on networks with interference.\nInspired by the idea of matching in observational studies, we introduce the\nnotion of considering a treatment assignment as a quasi-coloring\" on a graph.\nOur idea of a perfect quasi-coloring strives to match every treated unit on a\ngiven network with a distinct control unit that has identical number of treated\nand control neighbors. For a wide range of interference functions encountered\nin applications, we show both by theory and simulations that the classical\nNeymanian estimator for the direct effect has desirable properties for our\ndesigns. This further extends to settings where homophily is present in\naddition to interference.\n", "versions": [{"version": "v1", "created": "Tue, 23 May 2017 20:24:25 GMT"}], "update_date": "2017-05-25", "authors_parsed": [["Jagadeesan", "Ravi", ""], ["Pillai", "Natesh", ""], ["Volfovsky", "Alexander", ""]]}, {"id": "1705.08527", "submitter": "Elizabeth Ogburn", "authors": "Elizabeth L. Ogburn, Oleg Sofrygin, Ivan Diaz, Mark J. van der Laan", "title": "Causal inference for social network data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe semiparametric estimation and inference for causal effects using\nobservational data from a single social network. Our asymptotic result is the\nfirst to allow for dependence of each observation on a growing number of other\nunits as sample size increases. While previous methods have generally\nimplicitly focused on one of two possible sources of dependence among social\nnetwork observations, we allow for both dependence due to transmission of\ninformation across network ties, and for dependence due to latent similarities\namong nodes sharing ties. We describe estimation and inference for new causal\neffects that are specifically of interest in social network settings, such as\ninterventions on network ties and network structure. Using our methods to\nreanalyze the Framingham Heart Study data used in one of the most influential\nand controversial causal analyses of social network data, we find that after\naccounting for network structure there is no evidence for the causal effects\nclaimed in the original paper.\n", "versions": [{"version": "v1", "created": "Tue, 23 May 2017 20:36:30 GMT"}, {"version": "v2", "created": "Thu, 25 May 2017 20:04:46 GMT"}, {"version": "v3", "created": "Mon, 24 Jul 2017 14:45:06 GMT"}, {"version": "v4", "created": "Thu, 5 Oct 2017 21:34:53 GMT"}, {"version": "v5", "created": "Mon, 17 Feb 2020 19:13:47 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Ogburn", "Elizabeth L.", ""], ["Sofrygin", "Oleg", ""], ["Diaz", "Ivan", ""], ["van der Laan", "Mark J.", ""]]}, {"id": "1705.08530", "submitter": "Bowei Yan", "authors": "Bowei Yan, Mingzhang Yin and Purnamrita Sarkar", "title": "Convergence Analysis of Gradient EM for Multi-component Gaussian Mixture", "comments": "36 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study convergence properties of the gradient\nExpectation-Maximization algorithm \\cite{lange1995gradient} for Gaussian\nMixture Models for general number of clusters and mixing coefficients. We\nderive the convergence rate depending on the mixing coefficients, minimum and\nmaximum pairwise distances between the true centers and dimensionality and\nnumber of components; and obtain a near-optimal local contraction radius. While\nthere have been some recent notable works that derive local convergence rates\nfor EM in the two equal mixture symmetric GMM, in the more general case, the\nderivations need structurally different and non-trivial arguments. We use\nrecent tools from learning theory and empirical processes to achieve our\ntheoretical results.\n", "versions": [{"version": "v1", "created": "Tue, 23 May 2017 20:47:17 GMT"}, {"version": "v2", "created": "Mon, 4 Dec 2017 18:16:50 GMT"}], "update_date": "2017-12-05", "authors_parsed": [["Yan", "Bowei", ""], ["Yin", "Mingzhang", ""], ["Sarkar", "Purnamrita", ""]]}, {"id": "1705.08617", "submitter": "Shuaiwen Wang", "authors": "Shuaiwen Wang, Haolei Weng, Arian Maleki", "title": "Which bridge estimator is optimal for variable selection?", "comments": "84 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT math.IT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of variable selection for linear models under the\nhigh-dimensional asymptotic setting, where the number of observations $n$ grows\nat the same rate as the number of predictors $p$. We consider two-stage\nvariable selection techniques (TVS) in which the first stage uses bridge\nestimators to obtain an estimate of the regression coefficients, and the second\nstage simply thresholds this estimate to select the \"important\" predictors. The\nasymptotic false discovery proportion (AFDP) and true positive proportion\n(ATPP) of these TVS are evaluated. We prove that for a fixed ATPP, in order to\nobtain a smaller AFDP, one should pick a bridge estimator with smaller\nasymptotic mean square error in the first stage of TVS. Based on such\nprincipled discovery, we present a sharp comparison of different TVS, via an\nin-depth investigation of the estimation properties of bridge estimators.\nRather than \"order-wise\" error bounds with loose constants, our analysis\nfocuses on precise error characterization. Various interesting signal-to-noise\nratio and sparsity settings are studied. Our results offer new and thorough\ninsights into high-dimensional variable selection. For instance, we prove that\na TVS with Ridge in its first stage outperforms TVS with other bridge\nestimators in large noise settings; two-stage LASSO becomes inferior when the\nsignal is rare and weak. As a by-product, we show that two-stage methods\noutperform some standard variable selection techniques, such as LASSO and Sure\nIndependence Screening, under certain conditions.\n", "versions": [{"version": "v1", "created": "Wed, 24 May 2017 05:47:46 GMT"}, {"version": "v2", "created": "Mon, 30 Jul 2018 03:52:13 GMT"}, {"version": "v3", "created": "Tue, 12 Mar 2019 21:17:56 GMT"}, {"version": "v4", "created": "Wed, 25 Mar 2020 20:57:14 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Wang", "Shuaiwen", ""], ["Weng", "Haolei", ""], ["Maleki", "Arian", ""]]}, {"id": "1705.08930", "submitter": "Fang Han", "authors": "Fang Han, Zhao Ren, and Yuxin Zhu", "title": "Pairwise Difference Estimation of High Dimensional Partially Linear\n  Model", "comments": "28 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a regularized pairwise difference approach for estimating\nthe linear component coefficient in a partially linear model, with consistency\nand exact rates of convergence obtained in high dimensions under mild scaling\nrequirements. Our analysis reveals interesting features such as (i) the\nbandwidth parameter automatically adapts to the model and is actually\ntuning-insensitive; and (ii) the procedure could even maintain fast rate of\nconvergence for $\\alpha$-H\\\"older class of $\\alpha\\leq1/2$. Simulation studies\nshow the advantage of the proposed method, and application of our approach to a\nbrain imaging data reveals some biological patterns which fail to be recovered\nusing competing methods.\n", "versions": [{"version": "v1", "created": "Wed, 24 May 2017 19:05:32 GMT"}, {"version": "v2", "created": "Wed, 13 Sep 2017 18:09:25 GMT"}, {"version": "v3", "created": "Fri, 12 Jan 2018 03:30:16 GMT"}], "update_date": "2018-01-15", "authors_parsed": [["Han", "Fang", ""], ["Ren", "Zhao", ""], ["Zhu", "Yuxin", ""]]}, {"id": "1705.09457", "submitter": "Christiane G\\\"orgen", "authors": "Christiane G\\\"orgen, Anna Bigatti, Eva Riccomagno, Jim Q. Smith", "title": "Discovery of statistical equivalence classes using computer algebra", "comments": "26 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discrete statistical models supported on labelled event trees can be\nspecified using so-called interpolating polynomials which are generalizations\nof generating functions. These admit a nested representation. A new algorithm\nexploits the primary decomposition of monomial ideals associated with an\ninterpolating polynomial to quickly compute all nested representations of that\npolynomial. It hereby determines an important subclass of all trees\nrepresenting the same statistical model. To illustrate this method we analyze\nthe full polynomial equivalence class of a staged tree representing the best\nfitting model inferred from a real-world dataset.\n", "versions": [{"version": "v1", "created": "Fri, 26 May 2017 07:17:24 GMT"}], "update_date": "2017-05-29", "authors_parsed": [["G\u00f6rgen", "Christiane", ""], ["Bigatti", "Anna", ""], ["Riccomagno", "Eva", ""], ["Smith", "Jim Q.", ""]]}, {"id": "1705.09485", "submitter": "Robert Griffiths Professor", "authors": "Robert C. Griffiths and Simon Tavar\\'e", "title": "Ancestral inference from haplotypes and mutations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST q-bio.PE stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider inference about the history of a sample of DNA sequences,\nconditional upon the haplotype counts and the number of segregating sites\nobserved at the present time. After deriving some theoretical results in the\ncoalescent setting, we implement rejection sampling and importance sampling\nschemes to perform the inference. The importance sampling scheme addresses an\nextension of the Ewens Sampling Formula for a configuration of haplotypes and\nthe number of segregating sites in the sample. The implementations include both\nconstant and variable population size models. The methods are illustrated by\ntwo human Y chromosome data sets.\n", "versions": [{"version": "v1", "created": "Fri, 26 May 2017 09:03:30 GMT"}, {"version": "v2", "created": "Wed, 28 Feb 2018 17:48:00 GMT"}], "update_date": "2018-03-01", "authors_parsed": [["Griffiths", "Robert C.", ""], ["Tavar\u00e9", "Simon", ""]]}, {"id": "1705.09494", "submitter": "Thomas Fung", "authors": "Thomas Fung and Eugene Seneta", "title": "Quantile function expansion using regularly varying functions", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a simple result that allows us to evaluate the asymptotic order of\nthe remainder of a partial asymptotic expansion of the quantile function $h(u)$\nas $u\\to 0^+$ or $1^-$. This is focussed on important univariate distributions\nwhen $h(\\cdot)$ has no simple closed form, with a view to assessing asymptotic\nrate of decay to zero of tail dependence in the context of bivariate copulas.\nThe Introduction motivates the study in terms of the standard Normal. The\nNormal, Skew-Normal and Gamma are used as initial examples. Finally, we discuss\napproximation to the lower quantile of the Variance-Gamma and Skew-Slash\ndistributions.\n", "versions": [{"version": "v1", "created": "Fri, 26 May 2017 09:22:57 GMT"}, {"version": "v2", "created": "Wed, 9 Aug 2017 11:16:51 GMT"}], "update_date": "2017-08-10", "authors_parsed": [["Fung", "Thomas", ""], ["Seneta", "Eugene", ""]]}, {"id": "1705.09542", "submitter": "Stefan Roth", "authors": "Wolfgang Karcher, Stefan Roth, Evgeny Spodarev, Corinna Walk", "title": "An Inverse Problem for Infinitely Divisible Moving Average Random Fields", "comments": "44 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a low frequency sample of an infinitely divisible moving average random\nfield $\\{\\int_{\\mathbb{R}^d} f(x-t)\\Lambda(dx); \\ t \\in \\mathbb{R}^d \\}$ with a\nknown simple function $f$, we study the problem of nonparametric estimation of\nthe L\\'{e}vy characteristics of the independently scattered random measure\n$\\Lambda$. We provide three methods, a simple plug-in approach, a method based\non Fourier transforms and an approach involving decompositions with respect to\n$L^2$-orthonormal bases, which allow to estimate the L\\'{e}vy density of\n$\\Lambda$. For these methods, the bounds for the $L^2$-error are given. Their\nnumerical performance is compared in a simulation study.\n", "versions": [{"version": "v1", "created": "Fri, 26 May 2017 11:49:27 GMT"}], "update_date": "2017-05-29", "authors_parsed": [["Karcher", "Wolfgang", ""], ["Roth", "Stefan", ""], ["Spodarev", "Evgeny", ""], ["Walk", "Corinna", ""]]}, {"id": "1705.09677", "submitter": "Zelda Mariet", "authors": "Zelda Mariet and Suvrit Sra", "title": "Elementary Symmetric Polynomials for Optimal Experimental Design", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We revisit the classical problem of optimal experimental design (OED) under a\nnew mathematical model grounded in a geometric motivation. Specifically, we\nintroduce models based on elementary symmetric polynomials; these polynomials\ncapture \"partial volumes\" and offer a graded interpolation between the widely\nused A-optimal design and D-optimal design models, obtaining each of them as\nspecial cases. We analyze properties of our models, and derive both greedy and\nconvex-relaxation algorithms for computing the associated designs. Our analysis\nestablishes approximation guarantees on these algorithms, while our empirical\nresults substantiate our claims and demonstrate a curious phenomenon concerning\nour greedy method. Finally, as a byproduct, we obtain new results on the theory\nof elementary symmetric polynomials that may be of independent interest.\n", "versions": [{"version": "v1", "created": "Wed, 24 May 2017 16:34:00 GMT"}], "update_date": "2017-05-30", "authors_parsed": [["Mariet", "Zelda", ""], ["Sra", "Suvrit", ""]]}, {"id": "1705.09793", "submitter": "Olivier Roustant", "authors": "O Roustant (Mines Saint-\\'Etienne MSE), Y Deville", "title": "On the validity of parametric block correlation matrices with constant\n  within and between group correlations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the set Bp of parametric block correlation matrices with p blocks\nof various (and possibly different) sizes, whose diagonal blocks are compound\nsymmetry (CS) correlation matrices and off-diagonal blocks are constant\nmatrices. Such matrices appear in probabilistic models on categorical data,\nwhen the levels are partitioned in p groups, assuming a constant correlation\nwithin a group and a constant correlation for each pair of groups. We obtain\ntwo necessary and sufficient conditions for positive definiteness of elements\nof Bp. Firstly we consider the block average map $\\phi$, consisting in\nreplacing a block by its mean value. We prove that for any A $\\in$ Bp , A is\npositive definite if and only if $\\phi$(A) is positive definite. Hence it is\nequivalent to check the validity of the covariance matrix of group means, which\nonly depends on the number of groups and not on their sizes. This theorem can\nbe extended to a wider set of block matrices. Secondly, we consider the subset\nof Bp for which the between group correlation is the same for all pairs of\ngroups. Positive definiteness then comes down to find the positive definite\ninterval of a matrix pencil on Sp. We obtain a simple characterization by\nlocalizing the roots of the determinant with within group correlation values.\n", "versions": [{"version": "v1", "created": "Sat, 27 May 2017 09:13:37 GMT"}], "update_date": "2017-05-30", "authors_parsed": [["Roustant", "O", "", "Mines Saint-\u00c9tienne MSE"], ["Deville", "Y", ""]]}, {"id": "1705.09887", "submitter": "Yanwei  Fu", "authors": "Yanwei Fu, HanZe Dong, Yu-feng Ma, Zhengjun Zhang, Xiangyang Xue", "title": "Vocabulary-informed Extreme Value Learning", "comments": "we significantly change the content of this paper which makes it\n  another paper. In order not to misleading, we decided to withdraw it", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The novel unseen classes can be formulated as the extreme values of known\nclasses. This inspired the recent works on open-set recognition\n\\cite{Scheirer_2013_TPAMI,Scheirer_2014_TPAMIb,EVM}, which however can have no\nway of naming the novel unseen classes. To solve this problem, we propose the\nExtreme Value Learning (EVL) formulation to learn the mapping from visual\nfeature to semantic space. To model the margin and coverage distributions of\neach class, the Vocabulary-informed Learning (ViL) is adopted by using vast\nopen vocabulary in the semantic space. Essentially, by incorporating the EVL\nand ViL, we for the first time propose a novel semantic embedding paradigm --\nVocabulary-informed Extreme Value Learning (ViEVL), which embeds the visual\nfeatures into semantic space in a probabilistic way. The learned embedding can\nbe directly used to solve supervised learning, zero-shot and open set\nrecognition simultaneously. Experiments on two benchmark datasets demonstrate\nthe effectiveness of proposed frameworks.\n", "versions": [{"version": "v1", "created": "Sun, 28 May 2017 02:13:06 GMT"}, {"version": "v2", "created": "Fri, 26 Jan 2018 23:27:27 GMT"}], "update_date": "2018-01-30", "authors_parsed": [["Fu", "Yanwei", ""], ["Dong", "HanZe", ""], ["Ma", "Yu-feng", ""], ["Zhang", "Zhengjun", ""], ["Xue", "Xiangyang", ""]]}, {"id": "1705.09898", "submitter": "Atin Gayen", "authors": "Atin Gayen and M. Ashok Kumar", "title": "Projection Theorems of Divergences and Likelihood Maximization Methods", "comments": "28 pages, added projection theorem for density power divergences,\n  minor corrections made, submitted to Bernoulli", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Projection theorems of divergences enable us to find reverse projection of a\ndivergence on a specific statistical model as a forward projection of the\ndivergence on a different but rather \"simpler\" statistical model, which, in\nturn, results in solving a system of linear equations. Reverse projection of\ndivergences are closely related to various estimation methods such as the\nmaximum likelihood estimation or its variants in robust statistics. We consider\nprojection theorems of three parametric families of divergences that are widely\nused in robust statistics, namely the R\\'enyi divergences (or the Cressie-Reed\npower divergences), density power divergences, and the relative\n$\\alpha$-entropy (or the logarithmic density power divergences). We explore\nthese projection theorems from the usual likelihood maximization approach and\nfrom the principle of sufficiency. In particular, we show the equivalence of\nsolving the estimation problems by the projection theorems of the respective\ndivergences and by directly solving the corresponding estimating equations. We\nalso derive the projection theorem for the density power divergences.\n", "versions": [{"version": "v1", "created": "Sun, 28 May 2017 06:27:15 GMT"}, {"version": "v2", "created": "Fri, 16 Jun 2017 12:36:43 GMT"}], "update_date": "2017-06-19", "authors_parsed": [["Gayen", "Atin", ""], ["Kumar", "M. Ashok", ""]]}, {"id": "1705.09977", "submitter": "Alexander Kolnogorov", "authors": "Alexander Kolnogorov, Alexander Nazin, Dmitry Shiyan", "title": "Two-Armed Bandit Problem, Data Processing, and Parallel Version of the\n  Mirror Descent Algorithm", "comments": "11 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the minimax setup for the two-armed bandit problem as applied to\ndata processing if there are two alternative processing methods available with\ndifferent a priori unknown efficiencies. One should determine the most\neffective method and provide its predominant application. To this end we use\nthe mirror descent algorithm (MDA). It is well-known that corresponding minimax\nrisk has the order $N^{1/2}$ with $N$ being the number of processed data. We\nimprove significantly the theoretical estimate of the factor using Monte-Carlo\nsimulations. Then we propose a parallel version of the MDA which allows\nprocessing of data by packets in a number of stages. The usage of parallel\nversion of the MDA ensures that total time of data processing depends mostly on\nthe number of packets but not on the total number of data. It is quite\nunexpectedly that the parallel version behaves unlike the ordinary one even if\nthe number of packets is large. Moreover, the parallel version considerably\nimproves control performance because it provides significantly smaller value of\nthe minimax risk. We explain this result by considering another parallel\nmodification of the MDA which behavior is close to behavior of the ordinary\nversion. Our estimates are based on invariant descriptions of the algorithms.\nAll estimates are obtained by Monte-Carlo simulations. It's worth noting that\nparallel version performs well only for methods with close efficiencies. If\nefficiencies differ significantly then one should use the combined algorithm\nwhich at initial sufficiently short control horizon uses ordinary version and\nthen switches to the parallel version of the MDA.\n", "versions": [{"version": "v1", "created": "Sun, 28 May 2017 18:51:12 GMT"}], "update_date": "2017-05-30", "authors_parsed": [["Kolnogorov", "Alexander", ""], ["Nazin", "Alexander", ""], ["Shiyan", "Dmitry", ""]]}, {"id": "1705.09988", "submitter": "Mehmet Niyazi Cankaya mehmetn", "authors": "Mehmet Niyazi \\c{C}ankaya, Abdullah Yal\\c{c}{\\i}nkaya, \\\"Omer\n  Alt{\\i}nda\\v{g}, Olcay Arslan", "title": "On The Robustness of Epsilon Skew Extension for Burr III Distribution on\n  Real Line", "comments": "22 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Burr III distribution is used in a wide variety of fields of lifetime\ndata analysis, reliability theory, and financial literature, etc. It is defined\non the positive axis and has two shape parameters, say $c$ and $k$. These shape\nparameters make the distribution quite flexible. They also control the tail\nbehavior of the distribution. In this study, we extent the Burr III\ndistribution to the real axis and also add a skewness parameter, say\n$\\varepsilon$, with epsilon-skew extension approach. When the parameters $c$\nand $k$ have a relation such that $ck \\approx 1 $ or $ck < 1 $, it is skewed\nunimodal. Otherwise, it is skewed bimodal with the same level of peaks on the\nnegative and positive sides of real line. Thus, ESBIII distribution can capture\nfitting the various data sets even when the number of parameters are three.\nLocation and scale form of this distribution are also given. Some\ndistributional properties of the new distribution are investigated. The maximum\nlikelihood (ML) estimation method for the parameters of ESBIII is considered.\nThe robustness properties of ML estimators are studied and also tail behaviour\nof ESBIII distribution is examined. The applications on real data are\nconsidered to illustrate the modeling capacity of this distribution in the\nclass of bimodal distributions.\n", "versions": [{"version": "v1", "created": "Sun, 28 May 2017 20:37:01 GMT"}], "update_date": "2017-05-30", "authors_parsed": [["\u00c7ankaya", "Mehmet Niyazi", ""], ["Yal\u00e7\u0131nkaya", "Abdullah", ""], ["Alt\u0131nda\u01e7", "\u00d6mer", ""], ["Arslan", "Olcay", ""]]}, {"id": "1705.10046", "submitter": "Stefan Richter", "authors": "Stefan Richter and Rainer Dahlhaus", "title": "Cross validation for locally stationary processes", "comments": "67 pages (28 main article, 39 appendix), 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an adaptive bandwidth selector via cross validation for local\nM-estimators in locally stationary processes. We prove asymptotic optimality of\nthe procedure under mild conditions on the underlying parameter curves. The\nresults are applicable to a wide range of locally stationary processes such\nlinear and nonlinear processes. A simulation study shows that the method works\nfairly well also in misspecified situations.\n", "versions": [{"version": "v1", "created": "Mon, 29 May 2017 06:35:05 GMT"}], "update_date": "2017-05-30", "authors_parsed": [["Richter", "Stefan", ""], ["Dahlhaus", "Rainer", ""]]}, {"id": "1705.10140", "submitter": "Jean-Marc Bardet", "authors": "Jean-Marc Bardet (SAMM), Paul Doukhan (AGM)", "title": "Non-parametric estimation of time varying AR(1)--processes with local\n  stationarity and periodicity", "comments": null, "journal-ref": "Electronic journal of statistics, Shaker Heights, OH : Institute\n  of Mathematical Statistics, 2018, 12 (2), pp.2323 - 2354", "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extending the ideas of [7], this paper aims at providing a kernel based\nnon-parametric estimation of a new class of time varying AR(1) processes (Xt),\nwith local stationarity and periodic features (with a known period T), inducing\nthe definition Xt = at(t/nT)X t--1 + $\\xi$t for t $\\in$ N and with a t+T\n$\\not\\equiv$ at. Central limit theorems are established for kernel estima-tors\nas(u) reaching classical minimax rates and only requiring low order moment\nconditions of the white noise ($\\xi$t)t up to the second order.\n", "versions": [{"version": "v1", "created": "Mon, 29 May 2017 12:03:37 GMT"}, {"version": "v2", "created": "Tue, 24 Jul 2018 09:07:30 GMT"}, {"version": "v3", "created": "Mon, 12 Nov 2018 14:07:28 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Bardet", "Jean-Marc", "", "SAMM"], ["Doukhan", "Paul", "", "AGM"]]}, {"id": "1705.10157", "submitter": "Alejandro  Cholaquidis", "authors": "Catherine Aaron, Alejandro Cholaquidis, Ricardo Fraiman, Badih Ghattas", "title": "Robust Fusion Methods for Big Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address one of the important problems in Big Data, namely how to combine\nestimators from different subsamples by robust fusion procedures, when we are\nunable to deal with the whole sample.\n", "versions": [{"version": "v1", "created": "Mon, 29 May 2017 13:03:52 GMT"}, {"version": "v2", "created": "Thu, 8 Jun 2017 21:25:14 GMT"}], "update_date": "2017-06-12", "authors_parsed": [["Aaron", "Catherine", ""], ["Cholaquidis", "Alejandro", ""], ["Fraiman", "Ricardo", ""], ["Ghattas", "Badih", ""]]}, {"id": "1705.10182", "submitter": "Taiji Suzuki", "authors": "Taiji Suzuki", "title": "Fast learning rate of deep learning via a kernel perspective", "comments": "36 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a new theoretical framework to analyze the generalization error of\ndeep learning, and derive a new fast learning rate for two representative\nalgorithms: empirical risk minimization and Bayesian deep learning. The series\nof theoretical analyses of deep learning has revealed its high expressive power\nand universal approximation capability. Although these analyses are highly\nnonparametric, existing generalization error analyses have been developed\nmainly in a fixed dimensional parametric model. To compensate this gap, we\ndevelop an infinite dimensional model that is based on an integral form as\nperformed in the analysis of the universal approximation capability. This\nallows us to define a reproducing kernel Hilbert space corresponding to each\nlayer. Our point of view is to deal with the ordinary finite dimensional deep\nneural network as a finite approximation of the infinite dimensional one. The\napproximation error is evaluated by the degree of freedom of the reproducing\nkernel Hilbert space in each layer. To estimate a good finite dimensional\nmodel, we consider both of empirical risk minimization and Bayesian deep\nlearning. We derive its generalization error bound and it is shown that there\nappears bias-variance trade-off in terms of the number of parameters of the\nfinite dimensional approximation. We show that the optimal width of the\ninternal layers can be determined through the degree of freedom and the\nconvergence rate can be faster than $O(1/\\sqrt{n})$ rate which has been shown\nin the existing studies.\n", "versions": [{"version": "v1", "created": "Mon, 29 May 2017 13:47:44 GMT"}], "update_date": "2017-05-31", "authors_parsed": [["Suzuki", "Taiji", ""]]}, {"id": "1705.10190", "submitter": "Shiyun Chen", "authors": "Shiyun Chen, Ery Arias-Castro", "title": "Sequential Multiple Testing", "comments": "arXiv admin note: text overlap with arXiv:1604.07520", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study an online multiple testing problem where the hypotheses arrive\nsequentially in a stream. The test statistics are independent and assumed to\nhave the same distribution under their respective null hypotheses. We\ninvestigate two procedures LORD and LOND, proposed by (Javanmard and Montanari,\n2015), which are proved to control the FDR in an online manner. In some\n(static) model, we show that LORD is optimal in some asymptotic sense, in\nparticular as powerful as the (static) Benjamini-Hochberg procedure to first\nasymptotic order. We also quantify the performance of LOND. Some numerical\nexperiments complement our theory.\n", "versions": [{"version": "v1", "created": "Thu, 25 May 2017 18:08:05 GMT"}], "update_date": "2017-05-30", "authors_parsed": [["Chen", "Shiyun", ""], ["Arias-Castro", "Ery", ""]]}, {"id": "1705.10238", "submitter": "Asok K. Nanda Prof.", "authors": "Suchismita Das and Asok K. Nanda", "title": "Some Ageing Properties of Dynamic Additive Mean Residual Life Model", "comments": "13 pages", "journal-ref": "Rashi (2017), Vol 2, Issue 1, pp. 26-33", "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although proportional hazard rate model is a very popular model to analyze\nfailure time data, sometimes it becomes important to study the additive hazard\nrate model. Again, sometimes the concept of the hazard rate function is\nabstract, in comparison to the concept of mean residual life function. A new\nmodel called `dynamic additive mean residual life model' where the covariates\nare time-dependent has been defined in the literature. Here we study the\nclosure properties of the model for different positive and negative ageing\nclasses under certain condition(s). Quite a few examples are presented to\nillustrate different properties of the model.\n", "versions": [{"version": "v1", "created": "Mon, 29 May 2017 15:13:38 GMT"}], "update_date": "2017-05-30", "authors_parsed": [["Das", "Suchismita", ""], ["Nanda", "Asok K.", ""]]}, {"id": "1705.10261", "submitter": "Pim van der Hoorn", "authors": "Pim van der Hoorn, Gabor Lippner, Dmitri Krioukov", "title": "Sparse Maximum-Entropy Random Graphs with a Given Power-Law Degree\n  Distribution", "comments": null, "journal-ref": null, "doi": "10.1007/s10955-017-1887-7", "report-no": null, "categories": "math.PR cond-mat.stat-mech cs.SI math.ST physics.soc-ph stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Even though power-law or close-to-power-law degree distributions are\nubiquitously observed in a great variety of large real networks, the\nmathematically satisfactory treatment of random power-law graphs satisfying\nbasic statistical requirements of realism is still lacking. These requirements\nare: sparsity, exchangeability, projectivity, and unbiasedness. The last\nrequirement states that entropy of the graph ensemble must be maximized under\nthe degree distribution constraints. Here we prove that the hypersoft\nconfiguration model (HSCM), belonging to the class of random graphs with latent\nhyperparameters, also known as inhomogeneous random graphs or $W$-random\ngraphs, is an ensemble of random power-law graphs that are sparse, unbiased,\nand either exchangeable or projective. The proof of their unbiasedness relies\non generalized graphons, and on mapping the problem of maximization of the\nnormalized Gibbs entropy of a random graph ensemble, to the graphon entropy\nmaximization problem, showing that the two entropies converge to each other in\nthe large-graph limit.\n", "versions": [{"version": "v1", "created": "Mon, 29 May 2017 15:35:38 GMT"}, {"version": "v2", "created": "Fri, 22 Sep 2017 11:24:18 GMT"}, {"version": "v3", "created": "Tue, 10 Oct 2017 20:39:51 GMT"}], "update_date": "2017-10-12", "authors_parsed": [["van der Hoorn", "Pim", ""], ["Lippner", "Gabor", ""], ["Krioukov", "Dmitri", ""]]}, {"id": "1705.10298", "submitter": "Jean-Gabriel  Young", "authors": "Jean-Gabriel Young, Giovanni Petri, Francesco Vaccarino, Alice Patania", "title": "Construction of and efficient sampling from the simplicial configuration\n  model", "comments": "6 pages, 4 figures", "journal-ref": "Phys. Rev. E 96, 032312 (2017)", "doi": "10.1103/PhysRevE.96.032312", "report-no": null, "categories": "physics.soc-ph math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simplicial complexes are now a popular alternative to networks when it comes\nto describing the structure of complex systems, primarily because they encode\nmulti-node interactions explicitly. With this new description comes the need\nfor principled null models that allow for easy comparison with empirical data.\nWe propose a natural candidate, the simplicial configuration model. The core of\nour contribution is an efficient and uniform Markov chain Monte Carlo sampler\nfor this model. We demonstrate its usefulness in a short case study by\ninvestigating the topology of three real systems and their randomized\ncounterparts (using their Betti numbers). For two out of three systems, the\nmodel allows us to reject the hypothesis that there is no organization beyond\nthe local scale.\n", "versions": [{"version": "v1", "created": "Mon, 29 May 2017 17:34:00 GMT"}, {"version": "v2", "created": "Mon, 25 Sep 2017 19:06:37 GMT"}], "update_date": "2017-09-27", "authors_parsed": [["Young", "Jean-Gabriel", ""], ["Petri", "Giovanni", ""], ["Vaccarino", "Francesco", ""], ["Patania", "Alice", ""]]}, {"id": "1705.10347", "submitter": "Suzanne Thornton", "authors": "Suzanne Thornton, Wentao Li, Min-ge Xie", "title": "An effective likelihood-free approximate computing method with\n  statistical inferential guarantees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Approximate Bayesian computing is a powerful likelihood-free method that has\ngrown increasingly popular since early applications in population genetics.\nHowever, complications arise in the theoretical justification for Bayesian\ninference conducted from this method with a non-sufficient summary statistic.\nIn this paper, we seek to re-frame approximate Bayesian computing within a\nfrequentist context and justify its performance by standards set on the\nfrequency coverage rate. In doing so, we develop a new computational technique\ncalled approximate confidence distribution computing, yielding theoretical\nsupport for the use of non-sufficient summary statistics in likelihood-free\nmethods. Furthermore, we demonstrate that approximate confidence distribution\ncomputing extends the scope of approximate Bayesian computing to include\ndata-dependent priors without damaging the inferential integrity. This\ndata-dependent prior can be viewed as an initial `distribution estimate' of the\ntarget parameter which is updated with the results of the approximate\nconfidence distribution computing method. A general strategy for constructing\nan appropriate data-dependent prior is also discussed and is shown to often\nincrease the computing speed while maintaining statistical inferential\nguarantees. We supplement the theory with simulation studies illustrating the\nbenefits of the proposed method, namely the potential for broader applications\nand the increased computing speed compared to the standard approximate Bayesian\ncomputing methods.\n", "versions": [{"version": "v1", "created": "Mon, 29 May 2017 18:28:14 GMT"}, {"version": "v2", "created": "Tue, 20 Nov 2018 16:57:02 GMT"}, {"version": "v3", "created": "Thu, 29 Nov 2018 16:52:27 GMT"}, {"version": "v4", "created": "Fri, 30 Nov 2018 17:04:55 GMT"}], "update_date": "2018-12-03", "authors_parsed": [["Thornton", "Suzanne", ""], ["Li", "Wentao", ""], ["Xie", "Min-ge", ""]]}, {"id": "1705.10445", "submitter": "Katsumi Shimotsu", "authors": "Hiroyuki Kasahara and Katsumi Shimotsu", "title": "Asymptotic Properties of the Maximum Likelihood Estimator in Regime\n  Switching Econometric Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Markov regime switching models have been widely used in numerous empirical\napplications in economics and finance. However, the asymptotic distribution of\nthe maximum likelihood estimator (MLE) has not been proven for some empirically\npopular Markov regime switching models. In particular, the asymptotic\ndistribution of the MLE has been unknown for models in which some elements of\nthe transition probability matrix have the value of zero, as is commonly\nassumed in empirical applications with models with more than two regimes. This\nalso includes models in which the regime-specific density depends on both the\ncurrent and the lagged regimes such as the seminal model of Hamilton (1989) and\nswitching ARCH model of Hamilton and Susmel (1994). This paper shows the\nasymptotic normality of the MLE and consistency of the asymptotic covariance\nmatrix estimate of these models.\n", "versions": [{"version": "v1", "created": "Tue, 30 May 2017 03:15:07 GMT"}, {"version": "v2", "created": "Thu, 28 Jun 2018 07:32:20 GMT"}], "update_date": "2018-06-29", "authors_parsed": [["Kasahara", "Hiroyuki", ""], ["Shimotsu", "Katsumi", ""]]}, {"id": "1705.10466", "submitter": "Kohei Chiba", "authors": "Kohei Chiba", "title": "Estimation of the lead-lag parameter between two stochastic processes\n  driven by fractional Brownian motions", "comments": "Completely rewritten; 32 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the problem of estimating the lead-lag parameter\nbetween two stochastic processes driven by fractional Brownian motions (fBMs)\nof the Hurst parameter greater than 1/2. First we propose a lead-lag model\nbetween two stochastic processes involving fBMs, and then construct a\nconsistent estimator of the lead-lag parameter with possible convergence rate.\nOur estimator has the following two features. Firstly, we can construct the\nlead-lag estimator without using the Hurst parameters of the underlying fBMs.\nSecondly, our estimator can deal with some non-synchronous and irregular\nobservations. We explicitly calculate possible convergence rate when the\nobservation times are (1) synchronous and equidistant, and (2) given by the\nPoisson sampling scheme. We also present numerical simulations of our results\nusing the R package YUIMA.\n", "versions": [{"version": "v1", "created": "Tue, 30 May 2017 06:11:55 GMT"}, {"version": "v2", "created": "Mon, 12 Mar 2018 05:13:56 GMT"}], "update_date": "2018-03-13", "authors_parsed": [["Chiba", "Kohei", ""]]}, {"id": "1705.10598", "submitter": "Xin Tong Thomson", "authors": "Xin T. Tong", "title": "Performance analysis of local ensemble Kalman filter", "comments": "40 pages, 3 figures", "journal-ref": null, "doi": "10.1007/s00332-018-9453-2", "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensemble Kalman filter (EnKF) is an important data assimilation method for\nhigh dimensional geophysical systems. Efficient implementation of EnKF in\npractice often involves the localization technique, which updates each\ncomponent using only information within a local radius. This paper rigorously\nanalyzes the local EnKF (LEnKF) for linear systems, and shows that the filter\nerror can be dominated by the ensemble covariance, as long as 1) the sample\nsize exceeds the logarithmic of state dimension and a constant that depends\nonly on the local radius; 2) the forecast covariance matrix admits a stable\nlocalized structure. In particular, this indicates that with small system and\nobservation noises, the filter error will be accurate in long time even if the\ninitialization is not. The analysis also reveals an intrinsic inconsistency\ncaused by the localization technique, and a stable localized structure is\nnecessary to control this inconsistency. While this structure is usually taken\nfor granted for the operation of LEnKF, it can also be rigorously proved for\nlinear systems with sparse local observations and weak local interactions.\nThese theoretical results are also validated by numerical implementation of\nLEnKF on a simple stochastic turbulence in two dynamical regimes.\n", "versions": [{"version": "v1", "created": "Thu, 25 May 2017 07:09:44 GMT"}, {"version": "v2", "created": "Wed, 21 Mar 2018 04:02:17 GMT"}], "update_date": "2018-04-04", "authors_parsed": [["Tong", "Xin T.", ""]]}, {"id": "1705.10696", "submitter": "Pierre C. Bellec", "authors": "Pierre C Bellec", "title": "Localized Gaussian width of $M$-convex hulls with applications to Lasso\n  and convex aggregation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Upper and lower bounds are derived for the Gaussian mean width of the\nintersection of a convex hull of $M$ points with an Euclidean ball of a given\nradius. The upper bound holds for any collection of extreme point bounded in\nEuclidean norm. The upper bound and the lower bound match up to a\nmultiplicative constant whenever the extreme points satisfy a one sided\nRestricted Isometry Property.\n  This bound is then applied to study the Lasso estimator in fixed-design\nregression, the Empirical Risk Minimizer in the anisotropic persistence\nproblem, and the convex aggregation problem in density estimation.\n", "versions": [{"version": "v1", "created": "Tue, 30 May 2017 15:14:42 GMT"}, {"version": "v2", "created": "Tue, 26 Sep 2017 21:41:38 GMT"}], "update_date": "2017-09-28", "authors_parsed": [["Bellec", "Pierre C", ""]]}, {"id": "1705.10735", "submitter": "Joshua Cape", "authors": "Joshua Cape, Minh Tang, and Carey E. Priebe", "title": "The two-to-infinity norm and singular subspace geometry with\n  applications to high-dimensional statistics", "comments": "36 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The singular value matrix decomposition plays a ubiquitous role throughout\nstatistics and related fields. Myriad applications including clustering,\nclassification, and dimensionality reduction involve studying and exploiting\nthe geometric structure of singular values and singular vectors.\n  This paper provides a novel collection of technical and theoretical tools for\nstudying the geometry of singular subspaces using the two-to-infinity norm.\nMotivated by preliminary deterministic Procrustes analysis, we consider a\ngeneral matrix perturbation setting in which we derive a new Procrustean matrix\ndecomposition. Together with flexible machinery developed for the\ntwo-to-infinity norm, this allows us to conduct a refined analysis of the\ninduced perturbation geometry with respect to the underlying singular vectors\neven in the presence of singular value multiplicity. Our analysis yields\nsingular vector entrywise perturbation bounds for a range of popular matrix\nnoise models, each of which has a meaningful associated statistical inference\ntask. In addition, we demonstrate how the two-to-infinity norm is the preferred\nnorm in certain statistical settings. Specific applications discussed in this\npaper include covariance estimation, singular subspace recovery, and multiple\ngraph inference.\n  Both our Procrustean matrix decomposition and the technical machinery\ndeveloped for the two-to-infinity norm may be of independent interest.\n", "versions": [{"version": "v1", "created": "Tue, 30 May 2017 16:39:39 GMT"}, {"version": "v2", "created": "Wed, 12 Sep 2018 20:29:29 GMT"}, {"version": "v3", "created": "Tue, 2 Oct 2018 01:54:25 GMT"}], "update_date": "2018-10-03", "authors_parsed": [["Cape", "Joshua", ""], ["Tang", "Minh", ""], ["Priebe", "Carey E.", ""]]}, {"id": "1705.10881", "submitter": "Harm Derksen", "authors": "Harm Derksen", "title": "A general theory of singular values with applications to signal\n  denoising", "comments": "59 pages, 27 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.IT cs.NA math.IT math.OC math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the Pareto frontier for two competing norms $\\|\\cdot\\|_X$ and\n$\\|\\cdot\\|_Y$ on a vector space. For a given vector $c$, the pareto frontier\ndescribes the possible values of $(\\|a\\|_X,\\|b\\|_Y)$ for a decomposition\n$c=a+b$. The singular value decomposition of a matrix is closely related to the\nPareto frontier for the spectral and nuclear norm. We will develop a general\ntheory that extends the notion of singular values of a matrix to arbitrary\nfinite dimensional euclidean vector spaces equipped with dual norms. This also\ngeneralizes the diagonal singular value decompositions for tensors introduced\nby the author in previous work. We can apply the results to denoising, where\n$c$ is a noisy signal, $a$ is a sparse signal and $b$ is noise. Applications\ninclude 1D total variation denoising, 2D total variation Rudin-Osher-Fatemi\nimage denoising, LASSO, basis pursuit denoising and tensor decompositions.\n", "versions": [{"version": "v1", "created": "Tue, 30 May 2017 22:25:03 GMT"}], "update_date": "2017-06-01", "authors_parsed": [["Derksen", "Harm", ""]]}, {"id": "1705.11014", "submitter": "Lorenz Schwachh\\\"ofer", "authors": "Lorenz Schwachh\\\"ofer, Nihat Ay, J\\\"urgen Jost, H\\^ong V\\^an L\\^e", "title": "Congruent families and invariant tensors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical results of Chentsov and Campbell state that -- up to constant\nmultiples -- the only $2$-tensor field of a statistical model which is\ninvariant under congruent Markov morphisms is the Fisher metric and the only\ninvariant $3$-tensor field is the Amari-Chentsov tensor. We generalize this\nresult for arbitrary degree $n$, showing that any family of $n$-tensors which\nis invariant under congruent Markov morphisms is algebraically generated by the\ncanonical tensor fields defined in an earlier paper.\n", "versions": [{"version": "v1", "created": "Wed, 31 May 2017 10:12:30 GMT"}], "update_date": "2017-06-01", "authors_parsed": [["Schwachh\u00f6fer", "Lorenz", ""], ["Ay", "Nihat", ""], ["Jost", "J\u00fcrgen", ""], ["L\u00ea", "H\u00f4ng V\u00e2n", ""]]}, {"id": "1705.11107", "submitter": "Ankur Moitra", "authors": "Linus Hamilton, Frederic Koehler, Ankur Moitra", "title": "Information Theoretic Properties of Markov Random Fields, and their\n  Algorithmic Applications", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Markov random fields area popular model for high-dimensional probability\ndistributions. Over the years, many mathematical, statistical and algorithmic\nproblems on them have been studied. Until recently, the only known algorithms\nfor provably learning them relied on exhaustive search, correlation decay or\nvarious incoherence assumptions. Bresler gave an algorithm for learning general\nIsing models on bounded degree graphs. His approach was based on a structural\nresult about mutual information in Ising models.\n  Here we take a more conceptual approach to proving lower bounds on the mutual\ninformation through setting up an appropriate zero-sum game. Our proof\ngeneralizes well beyond Ising models, to arbitrary Markov random fields with\nhigher order interactions. As an application, we obtain algorithms for learning\nMarkov random fields on bounded degree graphs on $n$ nodes with $r$-order\ninteractions in $n^r$ time and $\\log n$ sample complexity. The sample\ncomplexity is information theoretically optimal up to the dependence on the\nmaximum degree. The running time is nearly optimal under standard conjectures\nabout the hardness of learning parity with noise.\n", "versions": [{"version": "v1", "created": "Wed, 31 May 2017 14:18:20 GMT"}], "update_date": "2017-06-01", "authors_parsed": [["Hamilton", "Linus", ""], ["Koehler", "Frederic", ""], ["Moitra", "Ankur", ""]]}]