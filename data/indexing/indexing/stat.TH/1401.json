[{"id": "1401.0062", "submitter": "Creighton Heaukulani", "authors": "Creighton Heaukulani, Daniel M. Roy", "title": "The combinatorial structure of beta negative binomial processes", "comments": "Published at http://dx.doi.org/10.3150/15-BEJ729 in the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2016, Vol. 22, No. 4, 2301-2324", "doi": "10.3150/15-BEJ729", "report-no": "IMS-BEJ-BEJ729", "categories": "math.ST math.PR stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We characterize the combinatorial structure of conditionally-i.i.d. sequences\nof negative binomial processes with a common beta process base measure. In\nBayesian nonparametric applications, such processes have served as models for\nlatent multisets of features underlying data. Analogously, random subsets arise\nfrom conditionally-i.i.d. sequences of Bernoulli processes with a common beta\nprocess base measure, in which case the combinatorial structure is described by\nthe Indian buffet process. Our results give a count analogue of the Indian\nbuffet process, which we call a negative binomial Indian buffet process. As an\nintermediate step toward this goal, we provide a construction for the beta\nnegative binomial process that avoids a representation of the underlying beta\nprocess base measure. We describe the key Markov kernels needed to use a NB-IBP\nrepresentation in a Markov Chain Monte Carlo algorithm targeting a posterior\ndistribution.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2013 00:48:01 GMT"}, {"version": "v2", "created": "Thu, 12 Jun 2014 15:09:53 GMT"}, {"version": "v3", "created": "Sat, 7 Mar 2015 23:33:40 GMT"}, {"version": "v4", "created": "Thu, 23 Jun 2016 08:21:20 GMT"}], "update_date": "2016-06-24", "authors_parsed": [["Heaukulani", "Creighton", ""], ["Roy", "Daniel M.", ""]]}, {"id": "1401.0087", "submitter": "Iuliana Teodorescu", "authors": "Iuliana Teodorescu and Chris Tsokos", "title": "Contributors of carbon dioxide in the atmosphere in Europe: the surface\n  response analysis", "comments": "arXiv admin note: substantial text overlap with arXiv:1312.7827", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP math.ST stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is a continuation of the statistical modeling of the nonlinear\nrelationship between atmospheric CO2 and attributable variables that can\naccount for emissions, based on data from EU countries, in order to compare the\nrelevant findings to those obtained in the case of US data, in [1, 2]. The\ncurrent study was initiated in [3], leading to the optimal second-order model,\nbased on three linear terms and five second-order terms. We conclude this study\nin the present work, by finding the canonical decomposition of the nonlinear\nmodel, and by computing the specific two-dimensional confidence regions that it\nleads to. We then use the model in order to quantify the net effect of various\nrisk factors, and compare to the results obtained in the US case.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2013 04:10:40 GMT"}], "update_date": "2014-01-03", "authors_parsed": [["Teodorescu", "Iuliana", ""], ["Tsokos", "Chris", ""]]}, {"id": "1401.0211", "submitter": "Yang Feng", "authors": "Jianqing Fan, Yang Feng, Jiancheng Jiang and Xin Tong", "title": "Feature Augmentation via Nonparametrics and Selection (FANS) in High\n  Dimensional Classification", "comments": "30 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.AP stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a high dimensional classification method that involves\nnonparametric feature augmentation. Knowing that marginal density ratios are\nthe most powerful univariate classifiers, we use the ratio estimates to\ntransform the original feature measurements. Subsequently, penalized logistic\nregression is invoked, taking as input the newly transformed or augmented\nfeatures. This procedure trains models equipped with local complexity and\nglobal simplicity, thereby avoiding the curse of dimensionality while creating\na flexible nonlinear decision boundary. The resulting method is called Feature\nAugmentation via Nonparametrics and Selection (FANS). We motivate FANS by\ngeneralizing the Naive Bayes model, writing the log ratio of joint densities as\na linear combination of those of marginal densities. It is related to\ngeneralized additive models, but has better interpretability and computability.\nRisk bounds are developed for FANS. In numerical analysis, FANS is compared\nwith competing methods, so as to provide a guideline on its best application\ndomain. Real data analysis demonstrates that FANS performs very competitively\non benchmark email spam and gene expression data sets. Moreover, FANS is\nimplemented by an extremely fast algorithm through parallel computing.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2013 19:53:11 GMT"}, {"version": "v2", "created": "Fri, 2 Jan 2015 17:27:38 GMT"}], "update_date": "2015-01-05", "authors_parsed": [["Fan", "Jianqing", ""], ["Feng", "Yang", ""], ["Jiang", "Jiancheng", ""], ["Tong", "Xin", ""]]}, {"id": "1401.0398", "submitter": "Philip Dawid", "authors": "A. Philip Dawid and Monica Musio", "title": "Theory and Applications of Proper Scoring Rules", "comments": "13 pages", "journal-ref": "Metron 72 (2014), 169-183", "doi": "10.1007/s40300-014-0039-y", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give an overview of some uses of proper scoring rules in statistical\ninference, including frequentist estimation theory and Bayesian model selection\nwith improper priors.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2014 09:31:54 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Dawid", "A. Philip", ""], ["Musio", "Monica", ""]]}, {"id": "1401.0609", "submitter": "Estate Khmaladze", "authors": "Estate Khmaladze", "title": "Note on distribution free testing for discrete distributions", "comments": "Published in at http://dx.doi.org/10.1214/13-AOS1176 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2013, Vol. 41, No. 6, 2979-2993", "doi": "10.1214/13-AOS1176", "report-no": "IMS-AOS-AOS1176", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper proposes one-to-one transformation of the vector of components\n$\\{Y_{in}\\}_{i=1}^m$ of Pearson's chi-square statistic,\n\\[Y_{in}=\\frac{\\nu_{in}-np_i}{\\sqrt{np_i}},\\qquad i=1,\\ldots,m,\\] into another\nvector $\\{Z_{in}\\}_{i=1}^m$, which, therefore, contains the same \"statistical\ninformation,\" but is asymptotically distribution free. Hence any\nfunctional/test statistic based on $\\{Z_{in}\\}_{i=1}^m$ is also asymptotically\ndistribution free. Natural examples of such test statistics are traditional\ngoodness-of-fit statistics from partial sums $\\sum_{I\\leq k}Z_{in}$. The\nsupplement shows how the approach works in the problem of independent interest:\nthe goodness-of-fit testing of power-law distribution with the Zipf law and the\nKarlin-Rouault law as particular alternatives.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2014 08:52:17 GMT"}], "update_date": "2014-01-06", "authors_parsed": [["Khmaladze", "Estate", ""]]}, {"id": "1401.0683", "submitter": "Fredrik Lindsten", "authors": "Fredrik Lindsten and Randal Douc and Eric Moulines", "title": "Uniform ergodicity of the Particle Gibbs sampler", "comments": null, "journal-ref": null, "doi": "10.1111/sjos.12136", "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The particle Gibbs (PG) sampler is a systematic way of using a particle\nfilter within Markov chain Monte Carlo (MCMC). This results in an off-the-shelf\nMarkov kernel on the space of state trajectories, which can be used to simulate\nfrom the full joint smoothing distribution for a state space model in an MCMC\nscheme. We show that the PG Markov kernel is uniformly ergodic under rather\ngeneral assumptions, that we will carefully review and discuss. In particular,\nwe provide an explicit rate of convergence which reveals that: (i) for fixed\nnumber of data points, the convergence rate can be made arbitrarily good by\nincreasing the number of particles, and (ii) under general mixing assumptions,\nthe convergence rate can be kept constant by increasing the number of particles\nsuperlinearly with the number of observations. We illustrate the applicability\nof our result by studying in detail two common state space models with\nnon-compact state spaces.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2014 17:27:49 GMT"}, {"version": "v2", "created": "Wed, 5 Feb 2014 18:51:22 GMT"}], "update_date": "2015-03-24", "authors_parsed": [["Lindsten", "Fredrik", ""], ["Douc", "Randal", ""], ["Moulines", "Eric", ""]]}, {"id": "1401.0844", "submitter": "Fabio Rapallo", "authors": "Roberto Fontana, Fabio Rapallo and Maria Piera Rogantin", "title": "$D$-optimal saturated designs: a simulation study", "comments": "8 pages. Preliminary version submitted to the 7th IWS Proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.CO math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we focus on saturated $D$-optimal designs. Using recent results,\nwe identify $D$-optimal designs with the solutions of an optimization problem\nwith linear constraints. We introduce new objective functions based on the\ngeometric structure of the design and we compare them with the classical\n$D$-efficiency criterion. We perform a simulation study. In all the test cases\nwe observe that designs with high values of $D$-efficiency have also high\nvalues of the new objective functions.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jan 2014 21:19:02 GMT"}], "update_date": "2014-01-07", "authors_parsed": [["Fontana", "Roberto", ""], ["Rapallo", "Fabio", ""], ["Rogantin", "Maria Piera", ""]]}, {"id": "1401.0903", "submitter": "Emmanuel Bacry", "authors": "Emmanuel Bacry and Jean-Francois Muzy", "title": "Second order statistics characterization of Hawkes processes and\n  non-parametric estimation", "comments": "25 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST physics.geo-ph q-fin.ST q-fin.TR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the jumps correlation matrix of a multivariate Hawkes process is\nrelated to the Hawkes kernel matrix through a system of Wiener-Hopf integral\nequations. A Wiener-Hopf argument allows one to prove that this system (in\nwhich the kernel matrix is the unknown) possesses a unique causal solution and\nconsequently that the second-order properties fully characterize a Hawkes\nprocess. The numerical inversion of this system of integral equations allows us\nto propose a fast and efficient method, which main principles were initially\nsketched in [Bacry and Muzy, 2013], to perform a non-parametric estimation of\nthe Hawkes kernel matrix. In this paper, we perform a systematic study of this\nnon-parametric estimation procedure in the general framework of marked Hawkes\nprocesses. We describe precisely this procedure step by step. We discuss the\nestimation error and explain how the values for the main parameters should be\nchosen. Various numerical examples are given in order to illustrate the broad\npossibilities of this estimation procedure ranging from 1-dimensional\n(power-law or non positive kernels) up to 3-dimensional (circular dependence)\nprocesses. A comparison to other non-parametric estimation procedures is made.\nApplications to high frequency trading events in financial markets and to\nearthquakes occurrence dynamics are finally considered.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jan 2014 15:28:07 GMT"}, {"version": "v2", "created": "Fri, 13 Feb 2015 08:33:23 GMT"}], "update_date": "2015-02-16", "authors_parsed": [["Bacry", "Emmanuel", ""], ["Muzy", "Jean-Francois", ""]]}, {"id": "1401.0967", "submitter": "Mohammad Jafari Jozani", "authors": "Sahar Nazari, Mohammad Jafari Jozani and Mahmood Kharrati-Kopaei", "title": "Nonparametric Density Estimation Using Partially Rank-Ordered Set\n  Samples With Application in Estimating the Distribution of Wheat Yield", "comments": "23 pages, 3 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study nonparametric estimation of an unknown density function $f$ based on\nthe ranked-based observations obtained from a partially rank-ordered set (PROS)\nsampling design. PROS sampling design has many applications in environmental,\necological and medical studies where the exact measurement of the variable of\ninterest is costly but a small number of sampling units can be ordered with\nrespect to the variable of interest by any means other than actual measurements\nand this can be done at low cost. PROS observations involve independent order\nstatistics which are not identically distributed and most of the commonly used\nnonparametric techniques are not directly applicable to them. We first develop\nkernel density estimates of $f$ based on an imperfect PROS sampling procedure\nand study its theoretical properties. Then, we consider the problem when the\nunderlying distribution is assumed to be symmetric and introduce some plug-in\nkernel density estimators of $f$. We use an EM type algorithm to estimate\nmisplacement probabilities associated with an imperfect PROS design. Finally,\nwe expand on various numerical illustrations of our results via several\nsimulation studies and a case study to estimate the distribution of wheat yield\nusing the total acreage of land which is planted in wheat as an easily obtained\nauxiliary information.\n  Our results show that the PROS density estimate performs better than its SRS\nand RSS counterparts.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2014 02:25:20 GMT"}], "update_date": "2014-01-07", "authors_parsed": [["Nazari", "Sahar", ""], ["Jozani", "Mohammad Jafari", ""], ["Kharrati-Kopaei", "Mahmood", ""]]}, {"id": "1401.0993", "submitter": "Xiaohui Chen", "authors": "Xiaohui Chen, Mengyu Xu, Wei Biao Wu", "title": "Covariance and precision matrix estimation for high-dimensional time\n  series", "comments": "Published in at http://dx.doi.org/10.1214/13-AOS1182 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2013, Vol. 41, No. 6, 2994-3021", "doi": "10.1214/13-AOS1182", "report-no": "IMS-AOS-AOS1182", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider estimation of covariance matrices and their inverses (a.k.a.\nprecision matrices) for high-dimensional stationary and locally stationary time\nseries. In the latter case the covariance matrices evolve smoothly in time,\nthus forming a covariance matrix function. Using the functional dependence\nmeasure of Wu [Proc. Natl. Acad. Sci. USA 102 (2005) 14150-14154 (electronic)],\nwe obtain the rate of convergence for the thresholded estimate and illustrate\nhow the dependence affects the rate of convergence. Asymptotic properties are\nalso obtained for the precision matrix estimate which is based on the graphical\nLasso principle. Our theory substantially generalizes earlier ones by allowing\ndependence, by allowing nonstationarity and by relaxing the associated moment\nconditions.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2014 06:37:22 GMT"}], "update_date": "2014-01-07", "authors_parsed": [["Chen", "Xiaohui", ""], ["Xu", "Mengyu", ""], ["Wu", "Wei Biao", ""]]}, {"id": "1401.1026", "submitter": "Daniel J. Nordman", "authors": "Daniel J. Nordman, Helle Bunzel, Soumendra N. Lahiri", "title": "A nonstandard empirical likelihood for time series", "comments": "Published in at http://dx.doi.org/10.1214/13-AOS1174 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2013, Vol. 41, No. 6, 3050-3073", "doi": "10.1214/13-AOS1174", "report-no": "IMS-AOS-AOS1174", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard blockwise empirical likelihood (BEL) for stationary, weakly\ndependent time series requires specifying a fixed block length as a tuning\nparameter for setting confidence regions. This aspect can be difficult and\nimpacts coverage accuracy. As an alternative, this paper proposes a new version\nof BEL based on a simple, though nonstandard, data-blocking rule which uses a\ndata block of every possible length. Consequently, the method does not involve\nthe usual block selection issues and is also anticipated to exhibit better\ncoverage performance. Its nonstandard blocking scheme, however, induces\nnonstandard asymptotics and requires a significantly different development\ncompared to standard BEL. We establish the large-sample distribution of\nlog-ratio statistics from the new BEL method for calibrating confidence regions\nfor mean or smooth function parameters of time series. This limit law is not\nthe usual chi-square one, but is distribution-free and can be reproduced\nthrough straightforward simulations. Numerical studies indicate that the\nproposed method generally exhibits better coverage accuracy than standard BEL.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2014 10:03:14 GMT"}], "update_date": "2014-01-07", "authors_parsed": [["Nordman", "Daniel J.", ""], ["Bunzel", "Helle", ""], ["Lahiri", "Soumendra N.", ""]]}, {"id": "1401.1137", "submitter": "Fran\\c{c}ois Caron", "authors": "Fran\\c{c}ois Caron and Emily B. Fox", "title": "Sparse graphs using exchangeable random measures", "comments": "New title. Extended version", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.SI math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical network modeling has focused on representing the graph as a\ndiscrete structure, namely the adjacency matrix, and considering the\nexchangeability of this array. In such cases, the Aldous-Hoover representation\ntheorem (Aldous, 1981;Hoover, 1979} applies and informs us that the graph is\nnecessarily either dense or empty. In this paper, we instead consider\nrepresenting the graph as a measure on $\\mathbb{R}_+^2$. For the associated\ndefinition of exchangeability in this continuous space, we rely on the\nKallenberg representation theorem (Kallenberg, 2005). We show that for certain\nchoices of such exchangeable random measures underlying our graph construction,\nour network process is sparse with power-law degree distribution. In\nparticular, we build on the framework of completely random measures (CRMs) and\nuse the theory associated with such processes to derive important network\nproperties, such as an urn representation for our analysis and network\nsimulation. Our theoretical results are explored empirically and compared to\ncommon network models. We then present a Hamiltonian Monte Carlo algorithm for\nefficient exploration of the posterior distribution and demonstrate that we are\nable to recover graphs ranging from dense to sparse--and perform associated\ntests--based on our flexible CRM-based formulation. We explore network\nproperties in a range of real datasets, including Facebook social circles, a\npolitical blogosphere, protein networks, citation networks, and world wide web\nnetworks, including networks with hundreds of thousands of nodes and millions\nof edges.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2014 16:57:16 GMT"}, {"version": "v2", "created": "Wed, 9 Apr 2014 15:13:26 GMT"}, {"version": "v3", "created": "Fri, 27 Mar 2015 12:40:04 GMT"}], "update_date": "2016-02-22", "authors_parsed": [["Caron", "Fran\u00e7ois", ""], ["Fox", "Emily B.", ""]]}, {"id": "1401.1264", "submitter": "Peng Ding", "authors": "Peng Ding, and Zhi Geng", "title": "Identifiability of Subgroup Causal Effects in Randomized Experiments\n  with Nonignorable Missing Covariates", "comments": "Statistics in Medicine (2014)", "journal-ref": null, "doi": "10.1002/sim.6014", "report-no": null, "categories": "math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although randomized experiments are widely regarded as the gold standard for\nestimating causal effects, missing data of the pretreatment covariates makes it\nchallenging to estimate the subgroup causal effects. When the missing data\nmechanism of the covariates is nonignorable, the parameters of interest are\ngenerally not pointly identifiable, and we can only get bounds for the\nparameters of interest, which may be too wide for practical use. In some real\ncases, we have prior knowledge that some restrictions may be plausible. We show\nthe identifiability of the causal effects and joint distributions for four\ninterpretable missing data mechanisms, and evaluate the performance of the\nstatistical inference via simulation studies. One application of our methods to\na real data set from a randomized clinical trial shows that one of the\nnonignorable missing data mechanisms fits better than the ignorable missing\ndata mechanism, and the results conform to the study's original expert\nopinions. We also illustrate the potential applications of our methods to\nobservational studies using a data set from a job-training program.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2014 04:18:22 GMT"}], "update_date": "2014-01-08", "authors_parsed": [["Ding", "Peng", ""], ["Geng", "Zhi", ""]]}, {"id": "1401.1267", "submitter": "Peng Ding", "authors": "Peng Ding", "title": "Three Occurrences of the Hyperbolic-Secant Distribution", "comments": "The American Statistician (2014)", "journal-ref": null, "doi": "10.1080/00031305.2013.867902", "report-no": null, "categories": "math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although it is the generator distribution of the sixth natural exponential\nfamily with quadratic variance function, the Hyperbolic-Secant distribution is\nmuch less known than other distributions in the exponential families. Its lack\nof familiarity is due to its isolation from many widely-used statistical\nmodels. We fill in the gap by showing three examples naturally generating the\nHyperbolic-Secant distribution, including Fisher's analysis of similarity\nbetween twins, the Jeffreys' prior for contingency tables, and invalid\ninstrumental variables.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2014 04:24:29 GMT"}], "update_date": "2014-01-08", "authors_parsed": [["Ding", "Peng", ""]]}, {"id": "1401.1383", "submitter": "Helen Ogden", "authors": "Helen Ogden", "title": "Robustness properties of marginal composite likelihood estimators", "comments": "7 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Composite likelihoods are a class of alternatives to the full likelihood\nwhich are widely used in many situations in which the likelihood itself is\nintractable. A composite likelihood may be computed without the need to specify\nthe full distribution of the response, which means that in some situations the\nresulting estimator will be more robust to model misspecification than the\nmaximum likelihood estimator. The purpose of this note is to show that such\nincreased robustness is not guaranteed. An example is given in which various\nmarginal composite likelihood estimators are inconsistent under model\nmisspecification, even though the maximum likelihood estimator is consistent.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2014 13:53:59 GMT"}], "update_date": "2014-01-08", "authors_parsed": [["Ogden", "Helen", ""]]}, {"id": "1401.1397", "submitter": "Sonja Petrovic", "authors": "Aleksandra B. Slavkovi\\'c, Xiaotian Zhu and Sonja Petrovi\\'c", "title": "Fibers of multi-way contingency tables given conditionals: relation to\n  marginals, cell bounds and Markov bases", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A reference set, or a fiber, of a contingency table is the space of all\nrealizations of the table under a given set of constraints such as marginal\ntotals. Understanding the geometry of this space is a key problem in algebraic\nstatistics, important for conducting exact conditional inference, calculating\ncell bounds, imputing missing cell values, and assessing the risk of disclosure\nof sensitive information.\n  Motivated primarily by disclosure limitation problems where constraints can\ncome from summary statistics other than the margins, in this paper we study the\nspace $\\mathcal{F_T}$ of all possible multi-way contingency tables for a given\nsample size and set of observed conditional frequencies. We show that this\nspace can be decomposed according to different possible marginals, which, in\nturn, are encoded by the solution set of a linear Diophantine equation. We\ncharacterize the difference between two fibers: $\\mathcal{F_T}$ and the space\nof tables for a given set of corresponding marginal totals. In particular, we\nsolve a generalization of an open problem posed by Dobra et al. (2008). Our\ndecomposition of $\\mathcal{F_T}$ has two important consequences: (1) we derive\nnew cell bounds, some including connections to Directed Acyclic Graphs, and (2)\nwe describe a structure for the Markov bases for the space $\\mathcal{F_T}$ that\nleads to a simplified calculation of Markov bases in this particular setting.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2014 14:29:38 GMT"}], "update_date": "2014-01-08", "authors_parsed": [["Slavkovi\u0107", "Aleksandra B.", ""], ["Zhu", "Xiaotian", ""], ["Petrovi\u0107", "Sonja", ""]]}, {"id": "1401.1403", "submitter": "Atul Mallik", "authors": "Atul Mallik, Moulinath Banerjee and George Michailidis", "title": "M-estimation in multistage sampling procedures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-stage (designed) procedures, obtained by splitting the sampling budget\nsuitably across stages, and designing the sampling at a particular stage based\non information about the parameter obtained from previous stages, are often\nadvantageous from the perspective of precise inference. We develop a generic\nframework for M-estimation in a multistage setting and apply empirical process\ntechniques to develop limit theorems that describe the large sample behavior of\nthe resulting M-estimates. Applications to change-point estimation, inverse\nisotonic regression, classification and mode estimation are provided: it is\ntypically seen that the multistage procedure accentuates the efficiency of the\nM-estimates by accelerating the rate of convergence, relative to one-stage\nprocedures. The step-by-step process induces dependence across stages and\ncomplicates the analysis in such problems, which we address through careful\nconditioning arguments.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2014 14:48:23 GMT"}], "update_date": "2014-01-08", "authors_parsed": [["Mallik", "Atul", ""], ["Banerjee", "Moulinath", ""], ["Michailidis", "George", ""]]}, {"id": "1401.1674", "submitter": "Antonio Forcina", "authors": "Roberto Colombi and Antonio Forcina", "title": "Testing order restrictions in contingency tables", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several interesting models for contingency tables are defined by a system of\nequality and inequality constraints on a suitable set of marginal log-linear\nparameters. After reviewing the most common difficulties which are intrinsic to\norder restricted testing problems, we propose two new families of testing\nprocedures, based on similar attempts appeared in the econometric literature,\nin order to increase the probability of detecting several relevant violations\nof the supposed order relations. One set of procedures is based on the\ndecomposition of the log-likelihood ratio when testing the given set of\ninequalities and the nested model derived by forcing inequalities into strict\nequalities. The other set uses the asymptotic joint normal distribution of the\nestimates of the marginal log-linear parameters to be constrained.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2014 12:04:41 GMT"}], "update_date": "2014-01-09", "authors_parsed": [["Colombi", "Roberto", ""], ["Forcina", "Antonio", ""]]}, {"id": "1401.2188", "submitter": "Guillaume Lecu\\'e", "authors": "Guillaume Lecu\\'e and Shahar Mendelson", "title": "Sparse recovery under weak moment assumptions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that iid random vectors that satisfy a rather weak moment assumption\ncan be used as measurement vectors in Compressed Sensing, and the number of\nmeasurements required for exact reconstruction is the same as the best possible\nestimate -- exhibited by a random gaussian matrix. We also prove that this\nmoment condition is necessary, up to a $\\log \\log $ factor. Applications to the\nCompatibility Condition and the Restricted Eigenvalue Condition in the noisy\nsetup and to properties of neighbourly random polytopes are also discussed.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2014 22:07:49 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2014 15:15:29 GMT"}, {"version": "v3", "created": "Thu, 5 Jun 2014 14:05:57 GMT"}, {"version": "v4", "created": "Thu, 8 Jan 2015 17:57:27 GMT"}, {"version": "v5", "created": "Tue, 3 Mar 2015 13:07:46 GMT"}], "update_date": "2016-02-22", "authors_parsed": [["Lecu\u00e9", "Guillaume", ""], ["Mendelson", "Shahar", ""]]}, {"id": "1401.2205", "submitter": "Quentin Berthet", "authors": "Quentin Berthet", "title": "Optimal Testing for Planted Satisfiability Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.CC math.PR stat.TH", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  We study the problem of detecting planted solutions in a random\nsatisfiability formula. Adopting the formalism of hypothesis testing in\nstatistical analysis, we describe the minimax optimal rates of detection. Our\nanalysis relies on the study of the number of satisfying assignments, for which\nwe prove new results. We also address algorithmic issues, and give a\ncomputationally efficient test with optimal statistical performance. This\nresult is compared to an average-case hypothesis on the hardness of refuting\nsatisfiability of random formulas.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2014 23:34:17 GMT"}, {"version": "v2", "created": "Fri, 23 May 2014 20:21:36 GMT"}, {"version": "v3", "created": "Sun, 8 Feb 2015 04:11:42 GMT"}], "update_date": "2015-02-10", "authors_parsed": [["Berthet", "Quentin", ""]]}, {"id": "1401.2267", "submitter": "Hannes Leeb", "authors": "Hannes Leeb, Benedikt M. P\\\"otscher, Karl Ewald", "title": "On Various Confidence Intervals Post-Model-Selection", "comments": "Published at http://dx.doi.org/10.1214/14-STS507 in the Statistical\n  Science (http://www.imstat.org/sts/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Statistical Science 2015, Vol. 30, No. 2, 216-227", "doi": "10.1214/14-STS507", "report-no": "IMS-STS-STS507", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We compare several confidence intervals after model selection in the setting\nrecently studied by Berk et al. [Ann. Statist. 41 (2013) 802-837], where the\ngoal is to cover not the true parameter but a certain nonstandard quantity of\ninterest that depends on the selected model. In particular, we compare the\nPoSI-intervals that are proposed in that reference with the \"naive\" confidence\ninterval, which is constructed as if the selected model were correct and fixed\na priori (thus ignoring the presence of model selection). Overall, we find that\nthe actual coverage probabilities of all these intervals deviate only\nmoderately from the desired nominal coverage probability. This finding is in\nstark contrast to several papers in the existing literature, where the goal is\nto cover the true parameter.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2014 09:40:41 GMT"}, {"version": "v2", "created": "Thu, 4 Sep 2014 09:36:10 GMT"}, {"version": "v3", "created": "Wed, 29 Jul 2015 06:56:07 GMT"}], "update_date": "2015-07-30", "authors_parsed": [["Leeb", "Hannes", ""], ["P\u00f6tscher", "Benedikt M.", ""], ["Ewald", "Karl", ""]]}, {"id": "1401.2272", "submitter": "Markus Bibinger", "authors": "Randolf Altmeyer, Markus Bibinger", "title": "Functional stable limit theorems for quasi-efficient spectral\n  covolatility estimators", "comments": "to appear, Stochastic Processes and their Applications, 2015", "journal-ref": null, "doi": "10.1016/j.spa.2015.07.009", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider noisy non-synchronous discrete observations of a continuous\nsemimartingale with random volatility. Functional stable central limit theorems\nare established under high-frequency asymptotics in three setups:\none-dimensional for the spectral estimator of integrated volatility, from\ntwo-dimensional asynchronous observations for a bivariate spectral covolatility\nestimator and multivariate for a local method of moments. The results\ndemonstrate that local adaptivity and smoothing noise dilution in the Fourier\ndomain facilitate substantial efficiency gains compared to previous approaches.\nIn particular, the derived asymptotic variances coincide with the benchmarks of\nsemiparametric Cram\\'er-Rao lower bounds and the considered estimators are thus\nasymptotically efficient in idealized sub-experiments. Feasible central limit\ntheorems allowing for confidence are provided.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2014 09:58:27 GMT"}, {"version": "v2", "created": "Sat, 25 Jul 2015 09:56:43 GMT"}], "update_date": "2015-07-28", "authors_parsed": [["Altmeyer", "Randolf", ""], ["Bibinger", "Markus", ""]]}, {"id": "1401.2425", "submitter": "Seyed Jalil Kazemitabar", "authors": "Seyed Jalil Kazemitabar", "title": "Poisson Regression with Survey Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a way to remove the bias of a Poisson regression when the subjects\nare partially observed. In this paper we address this issue under certain\nassumptions about the missing-data generating process. We fix the total number\nof observed subjects and allow individual subjects to be observed randomly.\nThis theme is relevant when a researcher is provided with a survey data not\ncovering the whole population. A highlighting result is that if subjects are\nobserved according to a random sampling without replacement, a Poisson\ndistribution with sampling-ratio-adjusted mean is an asymptotically consistent\nmodel of the observed count variable. An innovative asymptotic regime is\nemployed to derive the results.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2014 18:54:08 GMT"}, {"version": "v2", "created": "Sun, 2 Mar 2014 18:49:35 GMT"}, {"version": "v3", "created": "Mon, 7 Jul 2014 01:38:32 GMT"}], "update_date": "2014-07-08", "authors_parsed": [["Kazemitabar", "Seyed Jalil", ""]]}, {"id": "1401.2597", "submitter": "Linxi Liu", "authors": "Linxi Liu and Wing Hung Wong", "title": "Multivariate Density Estimation via Adaptive Partitioning (I): Sieve MLE", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a non-parametric approach to multivariate density estimation. The\nestimators are piecewise constant density functions supported by binary\npartitions. The partition of the sample space is learned by maximizing the\nlikelihood of the corresponding histogram on that partition. We analyze the\nconvergence rate of the sieve maximum likelihood estimator, and reach a\nconclusion that for a relatively rich class of density functions the rate does\nnot directly depend on the dimension. This suggests that, under certain\nconditions, this method is immune to the curse of dimensionality, in the sense\nthat it is possible to get close to the parametric rate even in high\ndimensions. We also apply this method to several special cases, and calculate\nthe explicit convergence rates respectively.\n", "versions": [{"version": "v1", "created": "Sun, 12 Jan 2014 07:45:51 GMT"}, {"version": "v2", "created": "Wed, 19 Aug 2015 21:53:55 GMT"}], "update_date": "2015-08-21", "authors_parsed": [["Liu", "Linxi", ""], ["Wong", "Wing Hung", ""]]}, {"id": "1401.2709", "submitter": "Shiro Ishikawa", "authors": "Shiro Ishikawa", "title": "A quantum linguistic characterization of the reverse relation between\n  confidence interval and hypothesis testing", "comments": "arXiv admin note: substantial text overlap with arXiv:1312.6757", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although there are many ideas for the formulations of statistical hypothesis\ntesting, we consider that the likelihood ratio test is the most reasonable and\northodox. However, it is not handy, and thus, it is not usual in elementary\nbooks. That is, the statistical hypothesis testing written in elementary books\nis different from the likelihood ratio test. Thus, from the theoretical point\nof view, we have the following question: \"What is the statistical hypothesis\ntesting written in elementary books?\" For example, we consider that even the\ndifference between \"one sided test\" and \"two sided test\" is not clear yet. In\nthis paper, we give an answer to this question. That is, we propose a new\nformulation of statistical hypothesis testing, which is contrary to the\nconfidence interval methods. In other words, they are two sides of the same\ncoin. This will be done in quantum language (or, measurement theory), which is\ncharacterized as the linguistic turn of the Copenhagen interpretation of\nquantum mechanics, and also, a kind of system theory such that it is applicable\nto both classical and quantum systems. Since quantum language is suited for\ntheoretical arguments, we believe that our results are essentially final as a\ngeneral theory.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2014 04:42:50 GMT"}, {"version": "v2", "created": "Tue, 14 Jan 2014 08:09:55 GMT"}], "update_date": "2014-01-15", "authors_parsed": [["Ishikawa", "Shiro", ""]]}, {"id": "1401.2781", "submitter": "Kristoffer H. Hellton", "authors": "Kristoffer Hellton and Magne Thoresen", "title": "When and why are principal component scores a good tool for visualizing\n  high-dimensional data?", "comments": "Update to the final version of the paper published in the\n  Scandinavian Journal of Statistics (2017). The initial version of the paper\n  had the title \"Asymptotic distribution of principal component scores for\n  pervasive, high-dimensional eigenvectors\"", "journal-ref": "Scand. J. Stat., When and why are principal component scores a\n  good tool for visualizing high-dimensional data? (2017), 44(3) 581-597 (DOI:\n  10.1111/sjos.12264)", "doi": "10.1111/sjos.12264", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Principal component analysis (PCA) is a popular dimension reduction technique\noften used to visualize high-dimensional data structures. In genomics, this can\ninvolve millions of variables, but only tens to hundreds of observations.\nTheoretically, such extreme high-dimensionality will cause biased or\ninconsistent eigenvector estimates, but in practice the principal component\nscores are used for visualization with great success. In this paper, we explore\nwhen and why the classical principal component scores can be used to visualize\nstructures in high-dimensional data, even when there are few observations\ncompared to the number of variables. Our argument is two-fold: First, we argue\nthat eigenvectors related to pervasive signals will have eigenvalues scaling\nlinearly with the number of variables. Second, we prove that for linearly\nincreasing eigenvalues, the sample component scores will be scaled and rotated\nversions of the population scores, asymptotically. Thus the visual information\nof the sample scores will be unchanged, even though the sample eigenvectors are\nbiased. In the case of pervasive signals, the principal component scores can be\nused to visualize the population structures, even in extreme high-dimensional\nsituations.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2014 10:48:44 GMT"}, {"version": "v2", "created": "Mon, 1 Jun 2015 09:49:49 GMT"}, {"version": "v3", "created": "Thu, 12 Apr 2018 09:49:19 GMT"}, {"version": "v4", "created": "Wed, 10 Jun 2020 12:20:17 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Hellton", "Kristoffer", ""], ["Thoresen", "Magne", ""]]}, {"id": "1401.2823", "submitter": "Dionissios Hristopulos Prof.", "authors": "Dionissios T. Hristopulos", "title": "Radial Covariance Functions Motivated by Spatial Random Field Models\n  with Local Interactions", "comments": "14 pages, 10 figures, 5 Appendices; Version 2: minor typos corrected", "journal-ref": "Stochastic Environmental Research and Risk Assessment, 29(3),\n  739-754, 2015", "doi": "10.1007/s00477-014-0933-0", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive explicit expressions for a family of radially symmetric,\nnon-differentiable, Spartan covariance functions in $\\mathbb{R}^2$ that involve\nthe modified Bessel function of the second kind. In addition to the\ncharacteristic length and the amplitude coefficient, the Spartan covariance\nparameters include the rigidity coefficient $\\eta_{1}$ which determines the\nshape of the covariance function. If $ \\eta_{1} >> 1$ Spartan covariance\nfunctions exhibit multiscaling. We also derive a family of radially symmetric,\ninfinitely differentiable Bessel-Lommel covariance functions valid in\n$\\mathbb{R}^{d}, d\\ge 2$. We investigate the parametric dependence of the\nintegral range for Spartan and Bessel-Lommel covariance functions using\nexplicit relations and numerical simulations. Finally, we define a generalized\nspectrum of correlation scales $\\lambda^{(\\alpha)}_{c}$ in terms of the\nfractional Laplacian of the covariance function; for $0 \\le \\alpha \\le1$ the\n$\\lambda^{(\\alpha)}_{c}$ extend from the smoothness microscale $(\\alpha=1)$ to\nthe integral range $(\\alpha=0)$. The smoothness scale of mean-square continuous\nbut non-differentiable random fields vanishes; such fields, however, can be\ndiscriminated by means of $\\lambda^{(\\alpha)}_{c}$ scales obtained for $\\alpha\n<1$.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2014 13:03:41 GMT"}, {"version": "v2", "created": "Tue, 15 Jul 2014 13:23:39 GMT"}], "update_date": "2015-02-03", "authors_parsed": [["Hristopulos", "Dionissios T.", ""]]}, {"id": "1401.2897", "submitter": "Andrei Khrennikov Yu", "authors": "Masanari Asano, Takahisa Hashimoto, Andrei Khrennikov, Masanori Ohya,\n  Yoshiharu Tanaka", "title": "Violation of contextual generalization of the Leggett-Garg inequality\n  for recognition of ambiguous figures", "comments": "Presented at the conference Quantum Interactions 14, University of\n  Leicester, July 2014; submitted to Physica Scripta, IOP; new version contains\n  discussions on Bell and contextuality, marginal selectivity,\n  Kolmogorovization of contextual data", "journal-ref": "Phys. Scr. T 163 (2014) 014006", "doi": "10.1088/0031-8949/2014/T163/014006", "report-no": null, "categories": "q-bio.NC math.PR math.ST quant-ph stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We interpret the Leggett-Garg (LG) inequality as a kind of contextual\nprobabilistic inequality in which one combines data collected in experiments\nperformed for three different contexts. In the original version of the\ninequality these contexts have the temporal nature and they are given by three\npairs of instances of time, $(t_1, t_2), (t_2, t_3), (t_3, t_4),$ where $t_1 <\nt_2 < t_3.$ We generalize LG conditions of macroscopic realism and noninvasive\nmeasurability in the general contextual framework. Our formulation is done in\nthe purely probabilistic terms: existence of the context independent joint\nprobability distribution $P$ and the possibility to reconstruct the\nexperimentally found marginal (two dimensional) probability distributions from\nthe $P.$ We derive an analog of the LG inequality, \"contextual LG inequality\",\nand use it as a test of \"quantum-likeness\" of statistical data collected in a\nseries of experiments on recognition of ambiguous figures. In our experimental\nstudy the figure under recognition is the Schroeder stair which is shown with\nrotations for different angles. Contexts are encoded by dynamics of rotations:\nclockwise, anticlockwise, and random. Our data demonstrated violation of the\ncontextual LG inequality for some combinations of aforementioned contexts.\nSince in quantum theory and experiments with quantum physical systems this\ninequality is violated, e.g., in the form of the original LG-inequality, our\nresult can be interpreted as a sign that the quantum(-like) models can provide\na more adequate description of the data generated in the process of recognition\nof ambiguous figures.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2014 09:33:13 GMT"}, {"version": "v2", "created": "Wed, 15 Jan 2014 18:16:15 GMT"}, {"version": "v3", "created": "Fri, 2 May 2014 14:01:00 GMT"}], "update_date": "2015-06-18", "authors_parsed": [["Asano", "Masanari", ""], ["Hashimoto", "Takahisa", ""], ["Khrennikov", "Andrei", ""], ["Ohya", "Masanori", ""], ["Tanaka", "Yoshiharu", ""]]}, {"id": "1401.3020", "submitter": "Kei Kobayashi", "authors": "Kei Kobayashi and Henry P. Wynn", "title": "Empirical geodesic graphs and CAT(k) metrics for data analysis", "comments": "Statistics and Computing, 2019", "journal-ref": null, "doi": "10.1007/s11222-019-09855-3", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A methodology is developed for data analysis based on empirically constructed\ngeodesic metric spaces. For a probability distribution, the length along a path\nbetween two points can be defined as the amount of probability mass accumulated\nalong the path. The geodesic, then, is the shortest such path and defines a\ngeodesic metric. Such metrics are transformed in a number of ways to produce\nparametrised families of geodesic metric spaces, empirical versions of which\nallow computation of intrinsic means and associated measures of dispersion.\nThese reveal properties of the data, based on geometry, such as those that are\ndifficult to see from the raw Euclidean distances. Examples of application\ninclude clustering and classification. For certain parameter ranges, the spaces\nbecome CAT(0) spaces and the intrinsic means are unique. In one case, a minimal\nspanning tree of a graph based on the data becomes CAT(0). In another, a\nso-called \"metric cone\" construction allows extension to CAT($k$) spaces. It is\nshown how to empirically tune the parameters of the metrics, making it possible\nto apply them to a number of real cases.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2014 21:53:07 GMT"}, {"version": "v2", "created": "Mon, 3 Mar 2014 05:03:27 GMT"}, {"version": "v3", "created": "Tue, 8 Jul 2014 08:12:56 GMT"}, {"version": "v4", "created": "Thu, 15 Oct 2015 06:26:55 GMT"}, {"version": "v5", "created": "Sat, 8 Apr 2017 18:13:36 GMT"}, {"version": "v6", "created": "Thu, 14 Mar 2019 19:59:23 GMT"}], "update_date": "2019-03-18", "authors_parsed": [["Kobayashi", "Kei", ""], ["Wynn", "Henry P.", ""]]}, {"id": "1401.3034", "submitter": "Pramita Bagchi", "authors": "Pramita Bagchi, Moulinath Banerjee and Stilian Stoev", "title": "Inference for Monotone Trends Under Dependence", "comments": null, "journal-ref": null, "doi": "10.1080/01621459.2015.1100622", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We focus on the problem estimating a monotone trend function under additive\nand dependent noise. New point-wise confidence interval estimators under both\nshort- and long-range dependent errors are introduced and studied. These\nintervals are obtained via the method of inversion of certain discrepancy\nstatistics arising in hypothesis testing problems. The advantage of this\napproach is that it avoids the estimation of nuisance parameters such as the\nderivative of the unknown function, which existing methods are forced to deal\nwith. While the methodology is motivated by earlier work in the independent\ncontext, the dependence of the errors, especially longrange dependence leads to\nnew challenges, such as the study of convex minorants of drifted fractional\nBrownian motion that may be of independent interest. We also unravel a new\nfamily of universal limit distributions (and tabulate selected quantiles) that\ncan henceforth be used for inference in monotone function problems involving\ndependence.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2014 23:18:11 GMT"}, {"version": "v2", "created": "Mon, 11 Aug 2014 06:33:23 GMT"}, {"version": "v3", "created": "Thu, 23 Oct 2014 16:20:22 GMT"}, {"version": "v4", "created": "Fri, 30 Oct 2015 09:16:16 GMT"}, {"version": "v5", "created": "Mon, 22 Feb 2016 16:00:30 GMT"}], "update_date": "2016-02-23", "authors_parsed": [["Bagchi", "Pramita", ""], ["Banerjee", "Moulinath", ""], ["Stoev", "Stilian", ""]]}, {"id": "1401.3084", "submitter": "Paul Kabaila", "authors": "Paul Kabaila and Gayan Dharmarathne", "title": "A comparison of Bayesian and frequentist interval estimators in\n  regression that utilize uncertain prior information", "comments": null, "journal-ref": "A comparison of Bayesian and frequentist interval estimators in\n  regression that utilize uncertain prior information. Australian & New Zealand\n  Journal of Statistics, 57, 99-118 (2015)", "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a linear regression model with regression parameter beta and\nnormally distributed errors. Suppose that the parameter of interest is theta =\na^T beta where a is a specified vector. Define the parameter tau = c^T beta - t\nwhere c and t are specified and a and c are linearly independent. Also suppose\nthat we have uncertain prior information that tau = 0. Kabaila and Giri, 2009,\nJSPI, describe a new frequentist 1-alpha confidence interval for theta that\nutilizes this uncertain prior information. We compare this confidence interval\nwith Bayesian 1-alpha equi-tailed and shortest credible intervals for theta\nthat result from a prior density for tau that is a mixture of a rectangular\n\"slab\" and a Dirac delta function \"spike\", combined with noninformative prior\ndensities for the other parameters of the model. We show that these frequentist\nand Bayesian interval estimators depend on the data in very different ways. We\nalso consider some close variants of this prior distribution that lead to\nBayesian and frequentist interval estimators with greater similarity.\nNonetheless, as we show, substantial differences between these interval\nestimators remain.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2014 06:47:59 GMT"}], "update_date": "2017-10-18", "authors_parsed": [["Kabaila", "Paul", ""], ["Dharmarathne", "Gayan", ""]]}, {"id": "1401.3121", "submitter": "Cosimo Munari", "authors": "Pablo Koch-Medina, Cosimo Munari", "title": "Law-invariant risk measures: extension properties and qualitative\n  robustness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We characterize when a convex risk measure associated to a law-invariant\nacceptance set in $L^\\infty$ can be extended to $L^p$, $1\\leq p<\\infty$,\npreserving finiteness and continuity. This problem is strongly connected to the\nstatistical robustness of the corresponding risk measures. Special attention is\npaid to concrete examples including risk measures based on expected utility,\nmax-correlation risk measures, and distortion risk measures.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2014 10:05:28 GMT"}], "update_date": "2014-01-15", "authors_parsed": [["Koch-Medina", "Pablo", ""], ["Munari", "Cosimo", ""]]}, {"id": "1401.3146", "submitter": "Johannes Rauh", "authors": "Nils Bertschinger, Johannes Rauh", "title": "The Blackwell relation defines no lattice", "comments": "5 pages, 1 figure", "journal-ref": null, "doi": "10.1109/ISIT.2014.6875280", "report-no": null, "categories": "cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blackwell's theorem shows the equivalence of two preorders on the set of\ninformation channels. Here, we restate, and slightly generalize, his result in\nterms of random variables. Furthermore, we prove that the corresponding partial\norder is not a lattice; that is, least upper bounds and greatest lower bounds\ndo not exist.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2014 11:30:27 GMT"}], "update_date": "2015-03-05", "authors_parsed": [["Bertschinger", "Nils", ""], ["Rauh", "Johannes", ""]]}, {"id": "1401.3167", "submitter": "Alexander Schied", "authors": "Volker Kr\\\"atschmer, Alexander Schied, Henryk Z\\\"ahle", "title": "Quasi-Hadamard differentiability of general risk functionals and its\n  application", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST q-fin.RM stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We apply a suitable modification of the functional delta method to\nstatistical functionals that arise from law-invariant coherent risk measures.\nTo this end we establish differentiability of the statistical functional in a\nrelaxed Hadamard sense, namely with respect to a suitably chosen norm and in\nthe directions of a specifically chosen \"tangent space\". We show that this\nnotion of quasi-Hadamard differentiability yields both strong laws and limit\ntheorems for the asymptotic distribution of the plug-in estimators. Our results\ncan be regarded as a contribution to the statistics and numerics of risk\nmeasurement and as a case study for possible refinements of the functional\ndelta method through fine-tuning the underlying notion of differentiability\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2014 12:45:42 GMT"}, {"version": "v2", "created": "Mon, 16 Feb 2015 21:53:12 GMT"}], "update_date": "2015-02-18", "authors_parsed": [["Kr\u00e4tschmer", "Volker", ""], ["Schied", "Alexander", ""], ["Z\u00e4hle", "Henryk", ""]]}, {"id": "1401.3191", "submitter": "Gyula Pap", "authors": "J\\'ozsef G\\'all, Gyula Pap, Martien van Zuijlen", "title": "Joint ML estimation of all parameters in a discrete time random field\n  HJM type interest rate model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider discrete time Heath-Jarrow-Morton type interest rate models,\nwhere the interest rate curves are driven by a geometric spatial autoregression\nfield. Strong consistency and asymptotic normality of the maximum likelihood\nestimators of the parameters are proved for stable no-arbitrage models\ncontaining a general stochastic discounting factor, where explicit form of the\nML estimators is not available given a non-i.i.d. sample. The results form the\nbasis of further statistical problems in such models.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2014 14:21:46 GMT"}], "update_date": "2014-01-15", "authors_parsed": [["G\u00e1ll", "J\u00f3zsef", ""], ["Pap", "Gyula", ""], ["van Zuijlen", "Martien", ""]]}, {"id": "1401.3257", "submitter": "Virgile Caron Dr", "authors": "Virgile Caron", "title": "Importance Sampling for multi-constraints rare event probability", "comments": "Conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Improving Importance Sampling estimators for rare event probabilities\nrequires sharp approx- imations of the optimal density leading to a nearly\nzero-variance estimator. This paper presents a new way to handle the estimation\nof the probability of a rare event defined as a finite intersection of subset.\nWe provide a sharp approximation of the density of long runs of a random walk\ncondi- tioned by multiples constraints, each of them defined by an average of a\nfunction of its summands as their number tends to infinity.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2014 17:03:48 GMT"}], "update_date": "2014-01-15", "authors_parsed": [["Caron", "Virgile", ""]]}, {"id": "1401.3408", "submitter": "George Moustakides", "authors": "George V. Moustakides", "title": "Multiple optimality properties of the Shewhart test", "comments": "31 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For the problem of sequential detection of changes, we adopt the probability\nmaximizing approach in place of the classical minimization of the average\ndetection delay, and propose modified versions of the Shiryaev, Lorden and\nPollak performance measures. For these alternative formulations, we demonstrate\nthat the optimum sequential detection scheme is the simple Shewhart rule.\nInterestingly, we can also solve problems which under the classical setup have\nbeen open for many years, as optimum change detection with time varying\nobservations or with multiple post-change probability measures. For the last\ncase, we also offer the exact solution for Lorden's original setup when the\naverage false alarm period is within certain limits.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2014 02:12:01 GMT"}], "update_date": "2014-01-16", "authors_parsed": [["Moustakides", "George V.", ""]]}, {"id": "1401.3424", "submitter": "Teng Zhang", "authors": "Teng Zhang, Xiuyuan Cheng and Amit Singer", "title": "Marchenko-Pastur Law for Tyler's M-estimator", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the limiting behavior of Tyler's M-estimator for the\nscatter matrix, in the regime that the number of samples $n$ and their\ndimension $p$ both go to infinity, and $p/n$ converges to a constant $y$ with\n$0<y<1$. We prove that when the data samples $x_1, \\ldots, x_n$ are identically\nand independently generated from the Gaussian distribution $\\mathcal{N}(0, I)$,\nthe operator norm of the difference between a properly scaled Tyler's\nM-estimator and $\\sum_{i=1}^n x_i x_i^\\top/n$ tends to zero. As a result, the\nspectral distribution of Tyler's M-estimator converges weakly to the\nMar\\v{c}enko-Pastur distribution.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2014 04:35:49 GMT"}, {"version": "v2", "created": "Wed, 22 Jan 2014 04:25:42 GMT"}, {"version": "v3", "created": "Mon, 1 Dec 2014 04:56:40 GMT"}, {"version": "v4", "created": "Fri, 1 Apr 2016 06:33:00 GMT"}], "update_date": "2016-04-04", "authors_parsed": [["Zhang", "Teng", ""], ["Cheng", "Xiuyuan", ""], ["Singer", "Amit", ""]]}, {"id": "1401.3801", "submitter": "Masahito Hayashi", "authors": "Shun Watanabe, Masahito Hayashi", "title": "Finite-length Analysis on Tail probability for Markov Chain and\n  Application to Simple Hypothesis Testing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT math.IT math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using terminologies of information geometry, we derive upper and lower bounds\nof the tail probability of the sample mean. Employing these bounds, we obtain\nupper and lower bounds of the minimum error probability of the 2nd kind of\nerror under the exponential constraint for the error probability of the 1st\nkind of error in a simple hypothesis testing for a finite-length Markov chain,\nwhich yields the Hoeffding type bound. For these derivations, we derive upper\nand lower bounds of cumulant generating function for Markov chain. As a\nbyproduct, we obtain another simple proof of central limit theorem for Markov\nchain.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2014 00:16:10 GMT"}, {"version": "v2", "created": "Sun, 15 Mar 2015 01:29:58 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Watanabe", "Shun", ""], ["Hayashi", "Masahito", ""]]}, {"id": "1401.3814", "submitter": "Masahito Hayashi", "authors": "Masahito Hayashi, Shun Watanabe", "title": "Information Geometry Approach to Parameter Estimation in Markov Chains", "comments": "Appendix D is added", "journal-ref": "Annals of Statistics, Volume 44, Number 4, 1495-1535 (2016)", "doi": "10.1214/15-AOS1420", "report-no": null, "categories": "math.ST cs.IT math.IT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the parameter estimation of Markov chain when the unknown\ntransition matrix belongs to an exponential family of transition matrices.\nThen, we show that the sample mean of the generator of the exponential family\nis an asymptotically efficient estimator. Further, we also define a curved\nexponential family of transition matrices. Using a transition matrix version of\nthe Pythagorean theorem, we give an asymptotically efficient estimator for a\ncurved exponential family.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2014 02:35:13 GMT"}, {"version": "v2", "created": "Fri, 6 Jun 2014 12:45:52 GMT"}, {"version": "v3", "created": "Tue, 3 Feb 2015 00:47:52 GMT"}, {"version": "v4", "created": "Tue, 5 May 2015 23:17:37 GMT"}], "update_date": "2016-09-28", "authors_parsed": [["Hayashi", "Masahito", ""], ["Watanabe", "Shun", ""]]}, {"id": "1401.3987", "submitter": "Marco Chiani Dr.", "authors": "Marco Chiani", "title": "Distribution of the largest root of a matrix for Roy's test in\n  multivariate analysis of variance", "comments": null, "journal-ref": "Journal of Multivariate Analysis, 2016", "doi": "10.1016/j.jmva.2015.10.007", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let ${\\bf X, Y} $ denote two independent real Gaussian $\\mathsf{p} \\times\n\\mathsf{m}$ and $\\mathsf{p} \\times \\mathsf{n}$ matrices with $\\mathsf{m},\n\\mathsf{n} \\geq \\mathsf{p}$, each constituted by zero mean i.i.d. columns with\ncommon covariance. The Roy's largest root criterion, used in multivariate\nanalysis of variance (MANOVA), is based on the statistic of the largest\neigenvalue, $\\Theta_1$, of ${\\bf{(A+B)}}^{-1} \\bf{B}$, where ${\\bf A =X X}^T$\nand ${\\bf B =Y Y}^T$ are independent central Wishart matrices. We derive a new\nexpression and efficient recursive formulas for the exact distribution of\n$\\Theta_1$. The expression can be easily calculated even for large parameters,\neliminating the need of pre-calculated tables for the application of the Roy's\ntest.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2014 11:13:55 GMT"}, {"version": "v2", "created": "Sat, 18 Jan 2014 09:56:32 GMT"}, {"version": "v3", "created": "Wed, 5 Feb 2014 08:55:23 GMT"}, {"version": "v4", "created": "Sun, 2 Apr 2017 18:20:24 GMT"}], "update_date": "2017-04-04", "authors_parsed": [["Chiani", "Marco", ""]]}, {"id": "1401.4007", "submitter": "Zhou Zhou", "authors": "Zhou Zhou", "title": "Inference of weighted $V$-statistics for nonstationary time series and\n  its applications", "comments": "Published in at http://dx.doi.org/10.1214/13-AOS1184 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2014, Vol. 42, No. 1, 87-114", "doi": "10.1214/13-AOS1184", "report-no": "IMS-AOS-AOS1184", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the behavior of Fourier transforms for a wide class of\nnonstationary nonlinear processes. Asymptotic central and noncentral limit\ntheorems are established for a class of nondegenerate and degenerate weighted\n$V$-statistics through the angle of Fourier analysis. The established theory\nfor $V$-statistics provides a unified treatment for many important time and\nspectral domain problems in the analysis of nonstationary time series, ranging\nfrom nonparametric estimation to the inference of periodograms and spectral\ndensities.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2014 12:27:41 GMT"}], "update_date": "2014-01-17", "authors_parsed": [["Zhou", "Zhou", ""]]}, {"id": "1401.4827", "submitter": "Jianji Wang", "authors": "Jianji Wang, Nanning Zheng", "title": "Measures of Correlation for Multiple Variables", "comments": "multivariate correlation, multivariate correlation analysis,\n  multivariate correlation coefficient", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multivariate correlation analysis plays an important role in various fields\nsuch as statistics, economics, and big data analytics. In this paper, we\npropose a pair of measures, the unsigned correlation coefficient (UCC) and the\nunsigned incorrelation coefficient (UIC), to measure the strength of\ncorrelation and incorrelation (lack of correlation) among multiple variables.\nThe absolute value of Pearson's correlation coefficient is a special case of\nUCC for two variables. Some important properties of UCC and UIC show that the\nproposed UCC and UIC are a pair of effective measures for multivariate\ncorrelation. We also take the unsigned tri-variate correlation coefficient as\nan example to visually display the effectiveness of the proposed UCC, and the\ngeometrical explanation of UIC is also discussed. All the properties and the\nfigures of UCC and UIC show that the proposed UCC and UIC are the general\nmeasures of correlation for multiple variables.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2014 09:03:38 GMT"}, {"version": "v2", "created": "Mon, 14 Apr 2014 07:15:08 GMT"}, {"version": "v3", "created": "Tue, 22 Nov 2016 10:44:45 GMT"}, {"version": "v4", "created": "Sun, 4 Dec 2016 07:36:30 GMT"}, {"version": "v5", "created": "Fri, 23 Aug 2019 03:45:28 GMT"}, {"version": "v6", "created": "Mon, 27 Jan 2020 02:38:19 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Wang", "Jianji", ""], ["Zheng", "Nanning", ""]]}, {"id": "1401.4849", "submitter": "Sebastien Bubeck", "authors": "S\\'ebastien Bubeck, Elchanan Mossel, Mikl\\'os Z. R\\'acz", "title": "On the influence of the seed graph in the preferential attachment model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.DM cs.SI math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the influence of the seed graph in the preferential attachment\nmodel, focusing on the case of trees. We first show that the seed has no effect\nfrom a weak local limit point of view. On the other hand, we conjecture that\ndifferent seeds lead to different distributions of limiting trees from a total\nvariation point of view. We take a first step in proving this conjecture by\nshowing that seeds with different degree profiles lead to different limiting\ndistributions for the (appropriately normalized) maximum degree, implying that\nsuch seeds lead to different (in total variation) limiting trees.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2014 10:23:44 GMT"}, {"version": "v2", "created": "Fri, 7 Feb 2014 19:16:28 GMT"}, {"version": "v3", "created": "Fri, 28 Mar 2014 13:27:19 GMT"}], "update_date": "2014-03-31", "authors_parsed": [["Bubeck", "S\u00e9bastien", ""], ["Mossel", "Elchanan", ""], ["R\u00e1cz", "Mikl\u00f3s Z.", ""]]}, {"id": "1401.4883", "submitter": "Gabriela Ciuperca", "authors": "Gabriela Ciuperca", "title": "Estimation in a change-point nonlinear quantile model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers a nonlinear quantile model with change-points. The\nquantile estimation method, which as a particular case includes median model,\nis more robust with respect to other traditional methods when model errors\ncontain outliers. Under relatively weak assumptions, the convergence rate and\nasymptotic distribution of change-point and of regression parameter estimators\nare obtained. Numerical study by Monte Carlo simulations shows the performance\nof the proposed method for nonlinear model with change-points.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2014 13:04:04 GMT"}, {"version": "v2", "created": "Fri, 7 Feb 2014 12:31:55 GMT"}, {"version": "v3", "created": "Fri, 27 Feb 2015 08:05:06 GMT"}], "update_date": "2015-03-02", "authors_parsed": [["Ciuperca", "Gabriela", ""]]}, {"id": "1401.5187", "submitter": "Asaf Weinstein", "authors": "Asaf Weinstein and Ehud Weinstein", "title": "Inequalities for the Bayes Risk", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several inequalities are presented which, in part, generalize inequalities by\nWeinstein and Weiss, giving rise to new lower bounds for the Bayes risk under\nsquared error loss.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2014 06:11:57 GMT"}], "update_date": "2014-01-22", "authors_parsed": [["Weinstein", "Asaf", ""], ["Weinstein", "Ehud", ""]]}, {"id": "1401.5272", "submitter": "Ramji Venkataramanan", "authors": "Ramji Venkataramanan, Sekhar Tatikonda", "title": "The Rate-Distortion Function and Excess-Distortion Exponent of Sparse\n  Regression Codes with Optimal Encoding", "comments": "16 pages. IEEE Transactions on Information Theory", "journal-ref": "IEEE Transactions on Information Theory, Vol. 63, no. 8, pp.\n  5228-5243 (August 2017)", "doi": "10.1109/TIT.2017.2716360", "report-no": null, "categories": "cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the performance of sparse regression codes for lossy\ncompression with the squared-error distortion criterion. In a sparse regression\ncode, codewords are linear combinations of subsets of columns of a design\nmatrix. It is shown that with minimum-distance encoding, sparse regression\ncodes achieve the Shannon rate-distortion function for i.i.d. Gaussian sources\n$R^*(D)$ as well as the optimal excess-distortion exponent. This completes a\nprevious result which showed that $R^*(D)$ and the optimal exponent were\nachievable for distortions below a certain threshold. The proof of the\nrate-distortion result is based on the second moment method, a popular\ntechnique to show that a non-negative random variable $X$ is strictly positive\nwith high probability. In our context, $X$ is the number of codewords within\ntarget distortion $D$ of the source sequence. We first identify the reason\nbehind the failure of the standard second moment method for certain\ndistortions, and illustrate the different failure modes via a stylized example.\nWe then use a refinement of the second moment method to show that $R^*(D)$ is\nachievable for all distortion values. Finally, the refinement technique is\napplied to Suen's correlation inequality to prove the achievability of the\noptimal Gaussian excess-distortion exponent.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2014 11:22:48 GMT"}, {"version": "v2", "created": "Fri, 7 Feb 2014 11:57:57 GMT"}, {"version": "v3", "created": "Tue, 29 Apr 2014 13:43:46 GMT"}, {"version": "v4", "created": "Fri, 18 Dec 2015 19:47:25 GMT"}, {"version": "v5", "created": "Sun, 4 Jun 2017 08:28:03 GMT"}, {"version": "v6", "created": "Mon, 19 Jun 2017 16:15:11 GMT"}], "update_date": "2017-07-17", "authors_parsed": [["Venkataramanan", "Ramji", ""], ["Tatikonda", "Sekhar", ""]]}, {"id": "1401.5398", "submitter": "Anirban Bhattacharya", "authors": "Anirban Bhattacharya, Debdeep Pati, Natesh S. Pillai, David B. Dunson", "title": "Dirichlet-Laplace priors for optimal shrinkage", "comments": "arXiv admin note: substantial text overlap with arXiv:1212.6088", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Penalized regression methods, such as $L_1$ regularization, are routinely\nused in high-dimensional applications, and there is a rich literature on\noptimality properties under sparsity assumptions. In the Bayesian paradigm,\nsparsity is routinely induced through two-component mixture priors having a\nprobability mass at zero, but such priors encounter daunting computational\nproblems in high dimensions. This has motivated an amazing variety of\ncontinuous shrinkage priors, which can be expressed as global-local scale\nmixtures of Gaussians, facilitating computation. In sharp contrast to the\nfrequentist literature, little is known about the properties of such priors and\nthe convergence and concentration of the corresponding posterior distribution.\nIn this article, we propose a new class of Dirichlet--Laplace (DL) priors,\nwhich possess optimal posterior concentration and lead to efficient posterior\ncomputation exploiting results from normalized random measure theory. Finite\nsample performance of Dirichlet--Laplace priors relative to alternatives is\nassessed in simulated and real data examples.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2014 17:37:37 GMT"}], "update_date": "2014-01-22", "authors_parsed": [["Bhattacharya", "Anirban", ""], ["Pati", "Debdeep", ""], ["Pillai", "Natesh S.", ""], ["Dunson", "David B.", ""]]}, {"id": "1401.5408", "submitter": "Cristian Rojas", "authors": "Cristian R. Rojas and Bo Wahlberg", "title": "On change point detection using the fused lasso method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we analyze the asymptotic properties of l1 penalized maximum\nlikelihood estimation of signals with piece-wise constant mean values and/or\nvariances. The focus is on segmentation of a non-stationary time series with\nrespect to changes in these model parameters. This change point detection and\nestimation problem is also referred to as total variation denoising or l1 -mean\nfiltering and has many important applications in most fields of science and\nengineering. We establish the (approximate) sparse consistency properties,\nincluding rate of convergence, of the so-called fused lasso signal approximator\n(FLSA). We show that this only holds if the sign of the corresponding\nconsecutive changes are all different, and that this estimator is otherwise\nincapable of correctly detecting the underlying sparsity pattern. The key idea\nis to notice that the optimality conditions for this problem can be analyzed\nusing techniques related to brownian bridge theory.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2014 18:16:40 GMT"}], "update_date": "2014-01-22", "authors_parsed": [["Rojas", "Cristian R.", ""], ["Wahlberg", "Bo", ""]]}, {"id": "1401.5551", "submitter": "Hajir Roozbehani", "authors": "Hajir Roozbehani and Yury Polyanskiy", "title": "Algebraic Methods of Classifying Directed Graphical Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Directed acyclic graphical models (DAGs) are often used to describe common\nstructural properties in a family of probability distributions. This paper\naddresses the question of classifying DAGs up to an isomorphism. By considering\nGaussian densities, the question reduces to verifying equality of certain\nalgebraic varieties. A question of computing equations for these varieties has\nbeen previously raised in the literature. Here it is shown that the most\nnatural method adds spurious components with singular principal minors, proving\na conjecture of Sullivant. This characterization is used to establish an\nalgebraic criterion for isomorphism, and to provide a randomized algorithm for\nchecking that criterion. Results are applied to produce a list of the\nisomorphism classes of tree models on 4,5, and 6 nodes. Finally, some evidence\nis provided to show that projectivized DAG varieties contain useful information\nin the sense that their relative embedding is closely related to efficient\ninference.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2014 04:45:01 GMT"}, {"version": "v2", "created": "Tue, 23 Dec 2014 03:35:58 GMT"}], "update_date": "2014-12-24", "authors_parsed": [["Roozbehani", "Hajir", ""], ["Polyanskiy", "Yury", ""]]}, {"id": "1401.5555", "submitter": "Monowar Hasan", "authors": "Hina Tabassum, Zaher Dawy, Ekram Hossain, Mohamed-Slim Alouini", "title": "Interference Statistics and Capacity Analysis for Uplink Transmission in\n  Two-Tier Small Cell Networks: A Geometric Probability Approach", "comments": "We have withdrawn the paper due to some limitations", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Small cell networks are evolving as an economically viable solution to\nameliorate the capacity and coverage of state-of-the-art wireless cellular\nsystems. Nonetheless, the dense and unplanned deployment of the small cells\n(e.g., femtocells, picocells) with restricted user access significantly\nincreases the impact of interference on the overall network performance. To\nthis end, this paper presents a novel framework to derive the statistics of the\ninterference considering dedicated and shared spectrum access for uplink\ntransmissions in two-tier small cell networks such as the macrocell-femtocell\nnetworks. The derived expressions are validated by the Monte-Carlo simulations.\nNumerical results are generated to assess the feasibility of shared and\ndedicated spectrum access in femtocells under varying traffic load and spectral\nreuse scenarios.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2014 05:18:23 GMT"}, {"version": "v2", "created": "Thu, 30 Jan 2014 20:58:39 GMT"}], "update_date": "2014-01-31", "authors_parsed": [["Tabassum", "Hina", ""], ["Dawy", "Zaher", ""], ["Hossain", "Ekram", ""], ["Alouini", "Mohamed-Slim", ""]]}, {"id": "1401.5571", "submitter": "Marco Iglesias", "authors": "Marco A. Iglesias, Kui Lin, Andrew M. Stuart", "title": "Well-Posed Bayesian Geometric Inverse Problems Arising in Subsurface\n  Flow", "comments": null, "journal-ref": null, "doi": "10.1088/0266-5611/30/11/114001", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the inverse problem of determining the\npermeability of the subsurface from hydraulic head measurements, within the\nframework of a steady Darcy model of groundwater flow. We study geometrically\ndefined prior permeability fields, which admit layered, fault and channel\nstructures, in order to mimic realistic subsurface features; within each layer\nwe adopt either constant or continuous function representation of the\npermeability. This prior model leads to a parameter identification problem for\na finite number of unknown parameters determining the geometry, together with\neither a finite number of permeability values (in the constant case) or a\nfinite number of fields (in the continuous function case). We adopt a Bayesian\nframework showing existence and well-posedness of the posterior distribution.\nWe also introduce novel Markov Chain-Monte Carlo (MCMC) methods, which exploit\nthe different character of the geometric and permeability parameters, and build\non recent advances in function space MCMC. These algorithms provide rigorous\nestimates of the permeability, as well as the uncertainty associated with it,\nand only require forward model evaluations. No adjoint solvers are required and\nhence the methodology is applicable to black-box forward models. We then use\nthese methods to explore the posterior and to illustrate the methodology with\nnumerical experiments.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2014 07:01:08 GMT"}, {"version": "v2", "created": "Mon, 16 Jun 2014 07:24:34 GMT"}], "update_date": "2015-06-18", "authors_parsed": [["Iglesias", "Marco A.", ""], ["Lin", "Kui", ""], ["Stuart", "Andrew M.", ""]]}, {"id": "1401.5580", "submitter": "Pradip Sircar", "authors": "Jugalkishore K. Banoth, Pradip Sircar", "title": "Polynomial Transformation Method for Non-Gaussian Noise Environment", "comments": "4 pages", "journal-ref": "WORLDCOMP 2011, Proc. CSC, pp. 329, Jul 18-21, 2011, Las Vegas,\n  Nevada, USA", "doi": null, "report-no": null, "categories": "math.ST cs.CE stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Signal processing in non-Gaussian noise environment is addressed in this\npaper. For many real-life situations, the additive noise process present in the\nsystem is found to be dominantly non-Gaussian. The problem of detection and\nestimation of signals corrupted with non-Gaussian noise is difficult to track\nmathematically. In this paper, we present a novel approach for optimal\ndetection and estimation of signals in non-Gaussian noise. It is demonstrated\nthat preprocessing of data by the orthogonal polynomial approximation together\nwith the minimum error-variance criterion converts an additive non-Gaussian\nnoise process into an approximation-error process which is close to Gaussian.\nThe Monte Carlo simulations are presented to test the Gaussian hypothesis based\non the bicoherence of a sequence. The histogram test and the kurtosis test are\ncarried out to verify the Gaussian hypothesis.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2014 07:45:29 GMT"}], "update_date": "2014-01-23", "authors_parsed": [["Banoth", "Jugalkishore K.", ""], ["Sircar", "Pradip", ""]]}, {"id": "1401.5613", "submitter": "Krzysztof Szajowski", "authors": "A. Ochman-Gozdek, W. Sarnowski and K.J. Szajowski", "title": "A precision of the sequential change point detection", "comments": "8 pages. The research has been supported by grant S30103/I-18. This\n  paper was presented in part at 59th ISI World Statistics Congress 25-30\n  August 2013, Hong Kong Special Administrative Region, China in the session\n  CPS018", "journal-ref": "Applicationes Mathematicae. 2017, vol. 44, nr 2, s. 267-280", "doi": "10.4064/am2278-5-2017", "report-no": null, "categories": "math.ST math.PR stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A random sequence having two segments being the homogeneous Markov processes\nis registered. Each segment has his own transition probability law and the\nlength of the segment is unknown and random. The transition probabilities of\neach process are known and a priori distribution of the disorder moment is\ngiven. The decision maker aim is to detect the moment of the transition\nprobabilities change. The detection of the disorder rarely is precise. The\ndecision maker accepts some deviation in estimation of the disorder moment. In\nthe considered model the aim is to indicate the change point with fixed,\nbounded error with maximal probability. The case with various precision for\nover and under estimation of this point is analysed. The case when the disorder\ndoes not appears with positive probability is also included. The results\ninsignificantly extends range of application, explain the structure of optimal\ndetector in various circumstances and shows new details of the solution\nconstruction. The motivation for this investigation is the modelling of the\nattacks in the node of networks. The objectives is to detect one of the attack\nimmediately or in very short time before or after it appearance with highest\nprobability. The problem is reformulated to optimal stopping of the observed\nsequences. The detailed analysis of the problem is presented to show the form\nof optimal decision function.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2014 10:33:27 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Ochman-Gozdek", "A.", ""], ["Sarnowski", "W.", ""], ["Szajowski", "K. J.", ""]]}, {"id": "1401.5817", "submitter": "Joel Zinn", "authors": "James Kuelbs, Joel Zinn", "title": "Half-Region Depth for Stochastic Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the concept of half-region depth, introduced by Lopez-Pintado and\nRomo in 2011. We show that for a wide variety of standard stochastic processes,\nsuch as Brownian motion and other symmetric stable processes with stationary\nindependent increments tied down at 0, half-region depth assigns depth zero to\nall sample functions. To alleviate this difficulty we introduce a method of\nsmoothing, which often not only eliminates the problem of zero depth, but\nallows us to extend the theoretical results on consistency in that paper up to\nthe $\\sqrt n$ level for many smoothed processes.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2014 22:23:35 GMT"}], "update_date": "2014-01-24", "authors_parsed": [["Kuelbs", "James", ""], ["Zinn", "Joel", ""]]}, {"id": "1401.5833", "submitter": "Nathaniel Strawn", "authors": "Mauro Maggioni, Stanislav Minsker, and Nate Strawn", "title": "Multiscale Dictionary Learning: Non-Asymptotic Bounds and Robustness", "comments": "This new version reorganizes proofs, and more numerical experiments\n  are performed", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-dimensional datasets are well-approximated by low-dimensional\nstructures. Over the past decade, this empirical observation motivated the\ninvestigation of detection, measurement, and modeling techniques to exploit\nthese low-dimensional intrinsic structures, yielding numerous implications for\nhigh-dimensional statistics, machine learning, and signal processing. Manifold\nlearning (where the low-dimensional structure is a manifold) and dictionary\nlearning (where the low-dimensional structure is the set of sparse linear\ncombinations of vectors from a finite dictionary) are two prominent theoretical\nand computational frameworks in this area. Despite their ostensible\ndistinction, the recently-introduced Geometric Multi-Resolution Analysis (GMRA)\nprovides a robust, computationally efficient, multiscale procedure for\nsimultaneously learning manifolds and dictionaries.\n  In this work, we prove non-asymptotic probabilistic bounds on the\napproximation error of GMRA for a rich class of data-generating statistical\nmodels that includes \"noisy\" manifolds, thereby establishing the theoretical\nrobustness of the procedure and confirming empirical observations. In\nparticular, if a dataset aggregates near a low-dimensional manifold, our\nresults show that the approximation error of the GMRA is completely independent\nof the ambient dimension. Our work therefore establishes GMRA as a provably\nfast algorithm for dictionary learning with approximation and sparsity\nguarantees. We include several numerical experiments confirming these\ntheoretical results, and our theoretical framework provides new tools for\nassessing the behavior of manifold learning and dictionary learning procedures\non a large class of interesting models.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2014 00:11:49 GMT"}, {"version": "v2", "created": "Fri, 16 May 2014 18:40:50 GMT"}, {"version": "v3", "created": "Sun, 13 Dec 2015 23:51:47 GMT"}], "update_date": "2015-12-15", "authors_parsed": [["Maggioni", "Mauro", ""], ["Minsker", "Stanislav", ""], ["Strawn", "Nate", ""]]}, {"id": "1401.6044", "submitter": "Steven Blostein", "authors": "James Falt and Steven D. Blostein", "title": "Sequential Detection of an Abrupt Change in a Random Sequence with\n  Unknown Initial State", "comments": "3 figures, preliminary condensed versions appeared in IEEE ISIT 2014\n  and Proc. 50th Annual Conference on Information Sciences and Systems (CISS)\n  2016, and James Falt, Bayesian Detection of a Change in a Random Sequence\n  with Unknown Initial and Final Distributions, Queen's University, M.A.Sc.\n  Thesis, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of sequentially detecting an abrupt change in a sequence of\nindependent and identically distributed (IID) random variables is addressed.\nWhereas previous approaches assume a known probability density function (PDF)\nat the start of the sequence, the problem addressed is the detection of a\nsingle change in distribution among a finite number of known 'equal-energy'\nPDFs, but where the initial and final distributions are not known a priori. A\nBayesian multiple hypothesis approach is proposed where (i) unlike previous\nthreshold policies, the minimum cost hypothesis is tracked through time, (ii)\nunder an exponential delay-cost function that satisfies an upper bound\ndetermined by the distances between hypotheses, the probability of detecting a\nchange from an incorrect initial distribution asymptotically vanishes with\ntime, (iii) computation is recursive and constant per unit time, and (iv) the\nunknown initial state gives rise to unavoidable incorrect detections that be\nmade to vanish with a constant test threshold with negligibly small effect on\ncorrect detection delay for change times beyond a lower bound. Simulations\nillustrate the analysis and reveal that average delay approaches that of the\noptimal CUSUM test after an initial transient period determined by an incorrect\ndetection probability constraint.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2014 16:41:10 GMT"}, {"version": "v2", "created": "Tue, 17 Jun 2014 20:09:36 GMT"}, {"version": "v3", "created": "Fri, 20 Jun 2014 03:49:46 GMT"}, {"version": "v4", "created": "Fri, 8 Dec 2017 17:17:08 GMT"}], "update_date": "2017-12-11", "authors_parsed": [["Falt", "James", ""], ["Blostein", "Steven D.", ""]]}, {"id": "1401.6145", "submitter": "Monowar Hasan", "authors": "Hesham ElSawy and Ekram Hossain", "title": "On Stochastic Geometry Modeling of Cellular Uplink Transmission with\n  Truncated Channel Inversion Power Control", "comments": "Submitted to IEEE Transactions on Wireless Communications (TWC)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using stochastic geometry, we develop a tractable uplink modeling paradigm\nfor outage probability and spectral efficiency in both single and multi-tier\ncellular wireless networks. The analysis accounts for per user equipment (UE)\npower control as well as the maximum power limitations for UEs. More\nspecifically, for interference mitigation and robust uplink communication, each\nUE is required to control its transmit power such that the average received\nsignal power at its serving base station (BS) is equal to a certain threshold\n$\\rho_o$. Due to the limited transmit power, the UEs employ a truncated channel\ninversion power control policy with a cutoff threshold of $\\rho_o$. We show\nthat there exists a transfer point in the uplink system performance that\ndepends on the tuple: BS intensity ($\\lambda$), maximum transmit power of UEs\n($P_u$), and $\\rho_o$. That is, when $P_u$ is a tight operational constraint\nwith respect to [w.r.t.] $\\lambda$ and $\\rho_o$, the uplink outage probability\nand spectral efficiency highly depend on the values of $\\lambda$ and $\\rho_o$.\nIn this case, there exists an optimal cutoff threshold $\\rho^*_o$, which\ndepends on the system parameters, that minimizes the outage probability. On the\nother hand, when $P_u$ is not a binding operational constraint w.r.t. $\\lambda$\nand $\\rho_o$, the uplink outage probability and spectral efficiency become\nindependent of $\\lambda$ and $\\rho_o$. We obtain approximate yet accurate\nsimple expressions for outage probability and spectral efficiency which reduce\nto closed-forms in some special cases.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2014 19:59:44 GMT"}], "update_date": "2014-01-24", "authors_parsed": [["ElSawy", "Hesham", ""], ["Hossain", "Ekram", ""]]}, {"id": "1401.6294", "submitter": "Badong Chen", "authors": "Badong Chen, Guangmin Wang, Nanning Zheng, Jose C. Principe", "title": "An Extended Result on the Optimal Estimation under Minimum Error Entropy\n  Criterion", "comments": "15 pages, no figures, submitted to Entropy", "journal-ref": "Entropy 2014, 16(4), 2223-2233", "doi": "10.3390/e16042223", "report-no": null, "categories": "cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The minimum error entropy (MEE) criterion has been successfully used in\nfields such as parameter estimation, system identification and the supervised\nmachine learning. There is in general no explicit expression for the optimal\nMEE estimate unless some constraints on the conditional distribution are\nimposed. A recent paper has proved that if the conditional density is\nconditionally symmetric and unimodal (CSUM), then the optimal MEE estimate\n(with Shannon entropy) equals the conditional median. In this study, we extend\nthis result to the generalized MEE estimation where the optimality criterion is\nthe Renyi entropy or equivalently, the \\alpha-order information potential (IP).\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2014 09:27:32 GMT"}], "update_date": "2015-04-14", "authors_parsed": [["Chen", "Badong", ""], ["Wang", "Guangmin", ""], ["Zheng", "Nanning", ""], ["Principe", "Jose C.", ""]]}, {"id": "1401.6578", "submitter": "Christos Thrampoulidis", "authors": "Christos Thrampoulidis, Samet Oymak, Babak Hassibi", "title": "Simple Error Bounds for Regularized Noisy Linear Inverse Problems", "comments": "6pages, 2 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider estimating a structured signal $\\mathbf{x}_0$ from linear,\nunderdetermined and noisy measurements\n$\\mathbf{y}=\\mathbf{A}\\mathbf{x}_0+\\mathbf{z}$, via solving a variant of the\nlasso algorithm: $\\hat{\\mathbf{x}}=\\arg\\min_\\mathbf{x}\\{\n\\|\\mathbf{y}-\\mathbf{A}\\mathbf{x}\\|_2+\\lambda f(\\mathbf{x})\\}$. Here, $f$ is a\nconvex function aiming to promote the structure of $\\mathbf{x}_0$, say\n$\\ell_1$-norm to promote sparsity or nuclear norm to promote low-rankness. We\nassume that the entries of $\\mathbf{A}$ are independent and normally\ndistributed and make no assumptions on the noise vector $\\mathbf{z}$, other\nthan it being independent of $\\mathbf{A}$. Under this generic setup, we derive\na general, non-asymptotic and rather tight upper bound on the $\\ell_2$-norm of\nthe estimation error $\\|\\hat{\\mathbf{x}}-\\mathbf{x}_0\\|_2$. Our bound is\ngeometric in nature and obeys a simple formula; the roles of $\\lambda$, $f$ and\n$\\mathbf{x}_0$ are all captured by a single summary parameter\n$\\delta(\\lambda\\partial((f(\\mathbf{x}_0)))$, termed the Gaussian squared\ndistance to the scaled subdifferential. We connect our result to the literature\nand verify its validity through simulations.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jan 2014 20:34:39 GMT"}], "update_date": "2014-01-28", "authors_parsed": [["Thrampoulidis", "Christos", ""], ["Oymak", "Samet", ""], ["Hassibi", "Babak", ""]]}, {"id": "1401.6714", "submitter": "Sabyasachi Chatterjee", "authors": "Sabyasachi Chatterjee, Andrew Barron", "title": "Information Theory of Penalized Likelihoods and its Statistical\n  Implications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend the correspondence between two-stage coding procedures in data\ncompression and penalized likelihood procedures in statistical estimation.\nTraditionally, this had required restriction to countable parameter spaces. We\nshow how to extend this correspondence in the uncountable parameter case.\nLeveraging the description length interpretations of penalized likelihood\nprocedures we devise new techniques to derive adaptive risk bounds of such\nprocedures. We show that the existence of certain countable coverings of the\nparameter space implies adaptive risk bounds and thus our theory is quite\ngeneral. We apply our techniques to illustrate risk bounds for $\\ell_1$ type\npenalized procedures in canonical high dimensional statistical problems such as\nlinear regression and Gaussian graphical Models. In the linear regression\nproblem, we also demonstrate how the traditional $l_0$ penalty times\n$\\frac{\\log(n)}{2}$ plus lower order terms has a two stage description length\ninterpretation and present risk bounds for this penalized likelihood procedure.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2014 01:58:13 GMT"}, {"version": "v2", "created": "Sun, 27 Apr 2014 19:32:55 GMT"}, {"version": "v3", "created": "Thu, 7 May 2015 03:51:18 GMT"}], "update_date": "2015-05-08", "authors_parsed": [["Chatterjee", "Sabyasachi", ""], ["Barron", "Andrew", ""]]}, {"id": "1401.6801", "submitter": "Liubov Markovich", "authors": "A.V. Dobrovidov and L. A Markovich", "title": "Data-driven bandwidth choice for gamma kernel estimates of density\n  derivatives on the positive semi-axis", "comments": "5 pages, 4 figures, Proc. of IFAC International Workshop on\n  Adaptation and Learning in Control and Signal Processing,pp. 500-505, 2013,\n  Caen, France, July 3-5", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In some applications it is necessary to estimate derivatives of probability\ndensities defined on the positive semi-axis. The quality of nonparametric\nestimates of the probability densities and their derivatives are strongly\ninfluenced by smoothing parameters (bandwidths). In this paper an expression\nfor the optimal smoothing parameter of the gamma kernel estimate of the density\nderivative is obtained. For this parameter data-driven estimates based on\nmethods called \"rule of thumb\" and \"cross-validation\" are constructed. The\nquality of the estimates is verified and demonstrated on examples of density\nderivatives generated by Maxwell and Weibull distributions.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2014 10:56:58 GMT"}, {"version": "v2", "created": "Sun, 27 Jul 2014 15:13:12 GMT"}], "update_date": "2014-07-29", "authors_parsed": [["Dobrovidov", "A. V.", ""], ["Markovich", "L. A", ""]]}, {"id": "1401.6882", "submitter": "Micha\\\"{e}l Chichignoud", "authors": "Micha\\\"el Chichignoud, S\\'ebastien Loustau", "title": "Bandwidth selection in kernel empirical risk minimization via the\n  gradient", "comments": "Published at http://dx.doi.org/10.1214/15-AOS1318 in the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2015, Vol. 43, No. 4, 1617-1646", "doi": "10.1214/15-AOS1318", "report-no": "IMS-AOS-AOS1318", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we deal with the data-driven selection of multidimensional and\npossibly anisotropic bandwidths in the general framework of kernel empirical\nrisk minimization. We propose a universal selection rule, which leads to\noptimal adaptive results in a large variety of statistical models such as\nnonparametric robust regression and statistical learning with errors in\nvariables. These results are stated in the context of smooth loss functions,\nwhere the gradient of the risk appears as a good criterion to measure the\nperformance of our estimators. The selection rule consists of a comparison of\ngradient empirical risks. It can be viewed as a nontrivial improvement of the\nso-called Goldenshluger-Lepski method to nonlinear estimators. Furthermore, one\nmain advantage of our selection rule is the nondependency on the Hessian matrix\nof the risk, usually involved in standard adaptive procedures.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2014 15:07:40 GMT"}, {"version": "v2", "created": "Sat, 20 Sep 2014 14:58:44 GMT"}, {"version": "v3", "created": "Sat, 31 Jan 2015 20:32:41 GMT"}, {"version": "v4", "created": "Tue, 18 Aug 2015 05:20:22 GMT"}], "update_date": "2016-08-11", "authors_parsed": [["Chichignoud", "Micha\u00ebl", ""], ["Loustau", "S\u00e9bastien", ""]]}, {"id": "1401.6926", "submitter": "Ilya Soloveychik", "authors": "Ilya Soloveychik and Ami Wiesel", "title": "Performance Analysis of Tyler's Covariance Estimator", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2014.2376911", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper analyzes the performance of Tyler's M-estimator of the scatter\nmatrix in elliptical populations. We focus on the non-asymptotic setting and\nderive the estimation error bounds depending on the number of samples n and the\ndimension p. We show that under quite mild conditions the squared Frobenius\nnorm of the error of the inverse estimator decays like p^2/n with high\nprobability.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2014 16:55:33 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2014 21:11:10 GMT"}, {"version": "v3", "created": "Mon, 3 Mar 2014 12:01:29 GMT"}, {"version": "v4", "created": "Thu, 11 Sep 2014 07:22:26 GMT"}], "update_date": "2015-06-18", "authors_parsed": [["Soloveychik", "Ilya", ""], ["Wiesel", "Ami", ""]]}, {"id": "1401.6959", "submitter": "Alexei Kourbatov", "authors": "Alexei Kourbatov", "title": "The distribution of maximal prime gaps in Cramer's probabilistic model\n  of primes", "comments": "12 pages, 2 figures, errata fixed", "journal-ref": "International Journal of Statistics and Probability; Vol. 3, No.\n  2, 2014, pp.18-29", "doi": "10.5539/ijsp.v3n2p18", "report-no": null, "categories": "math.NT math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the framework of Cramer's probabilistic model of primes, we explore the\nexact and asymptotic distributions of maximal prime gaps. We show that the\nGumbel extreme value distribution exp(-exp(-x)) is the limit law for maximal\ngaps between Cramer's random primes. The result can be derived from a general\ntheorem about intervals between discrete random events occurring with slowly\nvarying probability monotonically decreasing to zero. A straightforward\ngeneralization extends the Gumbel limit law to maximal gaps between prime\nconstellations in Cramer's model.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2014 18:51:51 GMT"}, {"version": "v2", "created": "Sun, 4 May 2014 17:44:46 GMT"}, {"version": "v3", "created": "Sat, 27 Sep 2014 17:12:52 GMT"}], "update_date": "2014-09-30", "authors_parsed": [["Kourbatov", "Alexei", ""]]}, {"id": "1401.6978", "submitter": "Jing Lei", "authors": "Jing Lei, Vincent Q. Vu", "title": "Sparsistency and agnostic inference in sparse PCA", "comments": "Published in at http://dx.doi.org/10.1214/14-AOS1273 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2015, Vol. 43, No. 1, 299-322", "doi": "10.1214/14-AOS1273", "report-no": "IMS-AOS-AOS1273", "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The presence of a sparse \"truth\" has been a constant assumption in the\ntheoretical analysis of sparse PCA and is often implicit in its methodological\ndevelopment. This naturally raises questions about the properties of sparse PCA\nmethods and how they depend on the assumption of sparsity. Under what\nconditions can the relevant variables be selected consistently if the truth is\nassumed to be sparse? What can be said about the results of sparse PCA without\nassuming a sparse and unique truth? We answer these questions by investigating\nthe properties of the recently proposed Fantope projection and selection (FPS)\nmethod in the high-dimensional setting. Our results provide general sufficient\nconditions for sparsistency of the FPS estimator. These conditions are weak and\ncan hold in situations where other estimators are known to fail. On the other\nhand, without assuming sparsity or identifiability, we show that FPS provides a\nsparse, linear dimension-reducing transformation that is close to the best\npossible in terms of maximizing the predictive covariance.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2014 19:38:27 GMT"}, {"version": "v2", "created": "Thu, 11 Sep 2014 12:05:03 GMT"}, {"version": "v3", "created": "Thu, 5 Mar 2015 07:56:59 GMT"}], "update_date": "2015-03-06", "authors_parsed": [["Lei", "Jing", ""], ["Vu", "Vincent Q.", ""]]}, {"id": "1401.7001", "submitter": "Rene Michel", "authors": "Rene Michel, Igor Schnakenburg, Tobias von Martens", "title": "A modified $\\chi^2$-test for uplift models with applications in\n  marketing performance measurement", "comments": "18 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uplift, essentially being the difference between two probabilities, is a\ncentral number in marketing performance measurement. A frequent question in\napplications is whether the uplifts of two campaigns are significantly\ndifferent. In this article we present a new $\\chi^2$-statistic which allows to\nanswer this question by performing a statistical test. We show that this\nstatistic is asymptotically $\\chi^2$-distributed and demonstrate its\napplication in a real life example. By running simulations with this new and\nalternative approaches, we find our suggested test to exhibit a better decisive\npower.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2014 20:54:59 GMT"}], "update_date": "2014-01-28", "authors_parsed": [["Michel", "Rene", ""], ["Schnakenburg", "Igor", ""], ["von Martens", "Tobias", ""]]}, {"id": "1401.7195", "submitter": "Dave Zachariah", "authors": "Dave Zachariah, Nafiseh Shariati, Mats Bengtsson, Magnus Jansson and\n  Saikat Chatterjee", "title": "Estimation for the Linear Model with Uncertain Covariance Matrices", "comments": null, "journal-ref": "IEEE Transactions on Signal Processing, 2014, Vol. 62, No. 6,\n  pages 1525-1535", "doi": "10.1109/TSP.2014.2301973", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive a maximum a posteriori estimator for the linear observation model,\nwhere the signal and noise covariance matrices are both uncertain. The\nuncertainties are treated probabilistically by modeling the covariance matrices\nwith prior inverse-Wishart distributions. The nonconvex problem of jointly\nestimating the signal of interest and the covariance matrices is tackled by a\ncomputationally efficient fixed-point iteration as well as an approximate\nvariational Bayes solution. The statistical performance of estimators is\ncompared numerically to state-of-the-art estimators from the literature and\nshown to perform favorably.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2014 14:37:22 GMT"}], "update_date": "2014-03-12", "authors_parsed": [["Zachariah", "Dave", ""], ["Shariati", "Nafiseh", ""], ["Bengtsson", "Mats", ""], ["Jansson", "Magnus", ""], ["Chatterjee", "Saikat", ""]]}, {"id": "1401.7241", "submitter": "Li Ma", "authors": "Li Ma", "title": "Markov adaptive P\\'olya trees and multi-resolution adaptive shrinkage in\n  nonparametric modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a hierarchical nonparametric model for probability measures\nbased on a multi-resolution transformation of probability distributions. The\nmodel allows a varying amount of shrinkage to be applied to data features of\ndifferent scales and/or at different locations in the sample space, and the\nvarying shrinkage level is locally adaptive to the empirical behavior of the\ndata. Moreover, the model's hierarchical design---through a latent Markov tree\nstructure---allows borrowing of information across locations and scales in\nsetting the adaptive shrinkage level. Inference under the model proceeds\nefficiently using general recipes for conjugate hierarchical models. We\nillustrate the work of the model in density estimation and evaluate its\nperformance through simulation under several schematic scenarios carefully\ndesigned to be representative of a variety of applications. We compare its\nperformance to those of several state-of-the-art nonparametric models---the\nP\\'olya tree, the optional P\\'olya tree, and the Dirichlet process mixture of\nnormals. In addition, we establish several important theoretical properties for\nthe model including absolute continuity, full nonparametricity, and posterior\nconsistency.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2014 16:07:32 GMT"}, {"version": "v2", "created": "Sat, 28 Mar 2015 21:34:00 GMT"}], "update_date": "2015-03-31", "authors_parsed": [["Ma", "Li", ""]]}, {"id": "1401.7278", "submitter": "Yun Yang", "authors": "Yun Yang, Surya T. Tokdar", "title": "Minimax-optimal nonparametric regression in high dimensions", "comments": "Published at http://dx.doi.org/10.1214/14-AOS1289 in the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2015, Vol. 43, No. 2, 652-674", "doi": "10.1214/14-AOS1289", "report-no": "IMS-AOS-AOS1289", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Minimax $L_2$ risks for high-dimensional nonparametric regression are derived\nunder two sparsity assumptions: (1) the true regression surface is a sparse\nfunction that depends only on $d=O(\\log n)$ important predictors among a list\nof $p$ predictors, with $\\log p=o(n)$; (2) the true regression surface depends\non $O(n)$ predictors but is an additive function where each additive component\nis sparse but may contain two or more interacting predictors and may have a\nsmoothness level different from other components. For either modeling\nassumption, a practicable extension of the widely used Bayesian Gaussian\nprocess regression method is shown to adaptively attain the optimal minimax\nrate (up to $\\log n$ terms) asymptotically as both $n,p\\to\\infty$ with $\\log\np=o(n)$.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2014 17:52:54 GMT"}, {"version": "v2", "created": "Tue, 26 Aug 2014 06:41:56 GMT"}, {"version": "v3", "created": "Wed, 1 Apr 2015 12:06:13 GMT"}], "update_date": "2015-04-02", "authors_parsed": [["Yang", "Yun", ""], ["Tokdar", "Surya T.", ""]]}, {"id": "1401.7790", "submitter": "Anne Marie Svane", "authors": "Anne Marie Svane", "title": "Estimation of Minkowski tensors from digital grey-scale images", "comments": "15 pages", "journal-ref": "Image Anal. Stereol. 34 (2015), no. 1, 51-61", "doi": "10.5566/ias.1124", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been shown that local algorithms based on grey-scale images sometimes\nlead to asymptotically unbiased estimators for surface area and integrated mean\ncurvature. This paper extends the results to estimators for Minkowski tensors.\nIn particular, asymptotically unbiased local algorithms for estimation of all\nvolume and surface tensors and certain mean curvature tensors are given. This\nrequires an extension of the known asymptotic formulas to estimators with\nposition dependent weights.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2014 10:40:11 GMT"}], "update_date": "2016-02-24", "authors_parsed": [["Svane", "Anne Marie", ""]]}, {"id": "1401.7801", "submitter": "Dennis Dobler", "authors": "Dennis Dobler and Markus Pauly", "title": "How to Bootstrap Aalen-Johansen Processes for Competing Risks?\n  Handicaps, Solutions and Limitations", "comments": "Keywords: Aalen-Johansen Estimator; Bootstrap; Competing risk;\n  Counting processes; Cumulative incidence function; Left-truncation;\n  Right-censoring; Weighted Bootstrap", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical inference in competing risks models is often based on the famous\nAalen-Johansen estimator. Since the corresponding limit process lacks\nindependent increments, it is typically applied together with Lin's (1997)\nresampling technique involving standard normal multipliers. Recently, it has\nbeen seen that this approach can be interpreted as a wild bootstrap technique\nand that other multipliers, as e.g. centered Poissons, may lead to better\nfinite sample performances, see Beyersmann et al. (2013). Since the latter is\nclosely related to Efron's classical bootstrap, the question arises whether\nthis or more general weighted bootstrap versions of Aalen-Johansen processes\nlead to valid results. Here we analyze their asymptotic behaviour and it turns\nout that such weighted bootstrap versions in general possess the wrong\ncovariance structure in the limit. However, we explain that the weighted\nbootstrap can nevertheless be applied for specific null hypotheses of interest\nand also discuss its limitations for statistical inference. To this end, we\nintroduce different consistent weighted bootstrap tests for the null hypothesis\nof stochastically ordered cumulative incidence functions and compare their\nfinite sample performance in a simulation study.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2014 11:24:51 GMT"}], "update_date": "2014-01-31", "authors_parsed": [["Dobler", "Dennis", ""], ["Pauly", "Markus", ""]]}, {"id": "1401.7819", "submitter": "Enrico Bibbona", "authors": "Enrico Bibbona and Ilia Negri", "title": "Higher Moments and Prediction Based Estimation for the COGARCH(1,1)\n  model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  COGARCH models are continuous time version of the well known GARCH models of\nfinancial returns. They are solution of a stochastic differential equation\ndriven by a L\\'evy process. The first aim of this paper is to show how the\nmethod of Prediction-Based Estimating Functions (PBEFs) can be applied to draw\nstatistical inference from a discrete sample of observations of a COGARCH(1,1)\nmodel as far as the higher order structure of the process is clarified.\nMotivated by the search for an optimal PBEF, a second aim of the paper is to\nprovide recursive expressions for the joint moments of any fixed order of the\nprocess, whenever they exist. Asymptotic results are given and a simulation\nstudy shows that the method of PBEF outperforms the other available estimation\nmethods.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2014 12:21:08 GMT"}, {"version": "v2", "created": "Tue, 22 Jul 2014 17:30:02 GMT"}, {"version": "v3", "created": "Fri, 31 Oct 2014 16:56:06 GMT"}], "update_date": "2014-11-03", "authors_parsed": [["Bibbona", "Enrico", ""], ["Negri", "Ilia", ""]]}, {"id": "1401.7893", "submitter": "Daniel Commenges", "authors": "Daniel Commenges, J\\'er\\'emie Bureau and Hein Putter", "title": "Inference with penalized likelihood", "comments": "15 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work studies the statistical properties of the maximum penalized\nlikelihood approach in a semi-parametric framework. We recall the penalized\nlikelihood approach for estimating a function and review some asymptotic\nresults. We investigate the properties of two estimators of the variance of\nmaximum penalized likelihood estimators: sandwich estimator and a Bayesian\nestimator. The coverage rates of confidence intervals based on these estimators\nare studied through a simulation study of survival data. In a first simulation\nthe coverage rates for the survival function and the hazard function are\nevaluated. In a second simulation data are generated from a proportional hazard\nmodel with covariates. The estimators of the variances of the regression\ncoefficients are studied. As for the survival and hazard functions, both\nsandwich and Bayesian estimators exhibit relatively good properties, but the\nBayesian estimator seems to be more accurate. As for the regression\ncoefficients, we focussed on the Bayesian estimator and found that it yielded\ngood coverage rates.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2014 15:54:03 GMT"}], "update_date": "2014-01-31", "authors_parsed": [["Commenges", "Daniel", ""], ["Bureau", "J\u00e9r\u00e9mie", ""], ["Putter", "Hein", ""]]}, {"id": "1401.7898", "submitter": "Aryeh Kontorovich", "authors": "Aryeh Kontorovich and Roi Weiss", "title": "Maximum Margin Multiclass Nearest Neighbors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a general framework for margin-based multicategory classification\nin metric spaces. The basic work-horse is a margin-regularized version of the\nnearest-neighbor classifier. We prove generalization bounds that match the\nstate of the art in sample size $n$ and significantly improve the dependence on\nthe number of classes $k$. Our point of departure is a nearly Bayes-optimal\nfinite-sample risk bound independent of $k$. Although $k$-free, this bound is\nunregularized and non-adaptive, which motivates our main result: Rademacher and\nscale-sensitive margin bounds with a logarithmic dependence on $k$. As the best\nprevious risk estimates in this setting were of order $\\sqrt k$, our bound is\nexponentially sharper. From the algorithmic standpoint, in doubling metric\nspaces our classifier may be trained on $n$ examples in $O(n^2\\log n)$ time and\nevaluated on new points in $O(\\log n)$ time.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2014 16:00:43 GMT"}], "update_date": "2014-01-31", "authors_parsed": [["Kontorovich", "Aryeh", ""], ["Weiss", "Roi", ""]]}, {"id": "1401.7899", "submitter": "Alexander Sokol", "authors": "Alexander Sokol, Marloes H. Maathuis and Benjamin Falkeborg", "title": "Quantifying identifiability in independent component analysis", "comments": "22 pages, 2 figures", "journal-ref": "Electronic Journal of Statistics, Vol. 8 (2014), 1438-1459", "doi": "10.1214/14-EJS932", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are interested in consistent estimation of the mixing matrix in the ICA\nmodel, when the error distribution is close to (but different from) Gaussian.\nIn particular, we consider $n$ independent samples from the ICA model $X =\nA\\epsilon$, where we assume that the coordinates of $\\epsilon$ are independent\nand identically distributed according to a contaminated Gaussian distribution,\nand the amount of contamination is allowed to depend on $n$. We then\ninvestigate how the ability to consistently estimate the mixing matrix depends\non the amount of contamination. Our results suggest that in an asymptotic\nsense, if the amount of contamination decreases at rate $1/\\sqrt{n}$ or faster,\nthen the mixing matrix is only identifiable up to transpose products. These\nresults also have implications for causal inference from linear structural\nequation models with near-Gaussian additive noise.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2014 16:01:21 GMT"}, {"version": "v2", "created": "Sat, 23 Aug 2014 11:06:16 GMT"}], "update_date": "2014-08-26", "authors_parsed": [["Sokol", "Alexander", ""], ["Maathuis", "Marloes H.", ""], ["Falkeborg", "Benjamin", ""]]}, {"id": "1401.8080", "submitter": "Fumiyasu Komaki", "authors": "Fumiyasu Komaki", "title": "Simultaneous prediction for independent Poisson processes with different\n  durations", "comments": "19 pages", "journal-ref": "Journal of Multivariate Analysis, Volume 141, 2015, Pages 35-48", "doi": "10.1016/j.jmva.2015.06.008", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simultaneous predictive densities for independent Poisson observables are\ninvestigated. The observed data and the target variables to be predicted are\nindependently distributed according to different Poisson distributions\nparametrized by the same parameter. The performance of predictive densities is\nevaluated by the Kullback-Leibler divergence. A class of prior distributions\ndepending on the objective of prediction is introduced. A Bayesian predictive\ndensity based on a prior in this class dominates the Bayesian predictive\ndensity based on the Jeffreys prior.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2014 08:05:35 GMT"}, {"version": "v2", "created": "Mon, 3 Feb 2014 02:28:46 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Komaki", "Fumiyasu", ""]]}, {"id": "1401.8104", "submitter": "Tobias Kley", "authors": "Tobias Kley, Stanislav Volgushev, Holger Dette, Marc Hallin", "title": "Quantile spectral processes: Asymptotic analysis and inference", "comments": "Published at http://dx.doi.org/10.3150/15-BEJ711 in the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2016, Vol. 22, No. 3, 1770-1807", "doi": "10.3150/15-BEJ711", "report-no": "IMS-BEJ-BEJ711", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantile- and copula-related spectral concepts recently have been considered\nby various authors. Those spectra, in their most general form, provide a full\ncharacterization of the copulas associated with the pairs $(X_t,X_{t-k})$ in a\nprocess $(X_t)_{t\\in\\mathbb{Z}}$, and account for important dynamic features,\nsuch as changes in the conditional shape (skewness, kurtosis),\ntime-irreversibility, or dependence in the extremes that their traditional\ncounterparts cannot capture. Despite various proposals for estimation\nstrategies, only quite incomplete asymptotic distributional results are\navailable so far for the proposed estimators, which constitutes an important\nobstacle for their practical application. In this paper, we provide a detailed\nasymptotic analysis of a class of smoothed rank-based cross-periodograms\nassociated with the copula spectral density kernels introduced in Dette et al.\n[Bernoulli 21 (2015) 781-831]. We show that, for a very general class of\n(possibly nonlinear) processes, properly scaled and centered smoothed versions\nof those cross-periodograms, indexed by couples of quantile levels, converge\nweakly, as stochastic processes, to Gaussian processes. A first application of\nthose results is the construction of asymptotic confidence intervals for copula\nspectral density kernels. The same convergence results also provide asymptotic\ndistributions (under serially dependent observations) for a new class of\nrank-based spectral methods involving the Fourier transforms of rank-based\nserial statistics such as the Spearman, Blomqvist or Gini autocovariance\ncoefficients.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2014 09:51:25 GMT"}, {"version": "v2", "created": "Wed, 4 Feb 2015 20:20:27 GMT"}, {"version": "v3", "created": "Wed, 30 Mar 2016 11:22:41 GMT"}], "update_date": "2016-03-31", "authors_parsed": [["Kley", "Tobias", ""], ["Volgushev", "Stanislav", ""], ["Dette", "Holger", ""], ["Hallin", "Marc", ""]]}]