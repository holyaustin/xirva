[{"id": "1704.00315", "submitter": "Gregory Rice", "authors": "Gregory Rice and Marco Shum", "title": "Inference for the cross-covariance operator of stationary functional\n  time series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When considering two or more time series of functions or curves, for instance\nthose derived from densely observed intraday stock price data of several\ncompanies, the empirical cross-covariance operator is of fundamental importance\ndue to its role in functional lagged regression and exploratory data analysis.\nDespite its relevance, statistical procedures for measuring the significance of\nsuch estimators are undeveloped. We present methodology based on a functional\ncentral limit theorem for conducting statistical inference for the\ncross-covariance operator estimated between two stationary, weakly dependent,\nfunctional time series. Specifically, we consider testing the null hypothesis\nthat two series possess a specified cross-covariance structure at a given lag.\nSince this test assumes that the series are jointly stationary, we also develop\na change-point detection procedure to validate this assumption, which is of\nindependent interest. The most imposing technical hurdle in implementing the\nproposed tests involves estimating the spectrum of a high dimensional spectral\ndensity operator at frequency zero. We propose a simple dimension reduction\nprocedure based on functional PCA to achieve this, which is shown to perform\nwell in a small simulation study. We illustrate the proposed methodology with\nan application to densely observed intraday price data of stocks listed on the\nNYSE.\n", "versions": [{"version": "v1", "created": "Sun, 2 Apr 2017 15:29:15 GMT"}], "update_date": "2017-04-04", "authors_parsed": [["Rice", "Gregory", ""], ["Shum", "Marco", ""]]}, {"id": "1704.00530", "submitter": "Ming-Tien Tsai", "authors": "Ming-Tien Tsai", "title": "Admissibility of invariant tests for means with covariates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For a multinormal distribution with a $p$-dimensional mean vector\n${\\mbtheta}$ and an arbitrary unknown dispersion matrix ${\\mbSigma}$, Rao ([9],\n[10]) proposed two tests for the problem of testing $ H_{0}:{\\mbtheta}_{1} =\n{\\bf 0}, {\\mbtheta}_{2} = {\\bf 0}, {\\mbSigma}~\n\\hbox{unspecified},~\\hbox{versus}~H_{1}:{\\mbtheta}_{1} \\ne {\\bf 0},\n{\\mbtheta}_{2} ={\\bf 0}, {\\mbSigma}~\\hbox{unspecified}$, where\n${\\mbtheta}^{'}=({\\mbtheta}^{'}_{1},{\\mbtheta}^{'}_{2})$. These tests are\nreferred to as Rao's $W$-test (likelihood ratio test) and Rao's $U$-test\n(union-intersection test), respectively. This work is inspired by the\nwell-known work of Marden and Perlman [6] who claimed that Hotelling's\n$T^{2}$-test is admissible while Rao's $U$-test is inadmissible. Both Rao's\n$U$-test and Hotelling's $T^{2}$-test can be constructed by applying the\nunion-intersection principle that incorporates the information\n${\\mbtheta}_{2}={\\bf 0}$ for Rao's $U$-test statistic but does not incorporate\nit for Hotelling's $T^{2}$-test statistic. Rao's $U$-test is believed to\nexhibit some optimal properties. Rao's $U$-test is shown to be admissible by\nfully incorporating the information ${\\mbtheta}_{2}={\\bf 0}$, but Hotelling's\n$T^{2}$-test is inadmissible.\n", "versions": [{"version": "v1", "created": "Mon, 3 Apr 2017 11:21:12 GMT"}], "update_date": "2017-04-04", "authors_parsed": [["Tsai", "Ming-Tien", ""]]}, {"id": "1704.00566", "submitter": "Jinyuan Chang", "authors": "Jinyuan Chang, Cheng Yong Tang, Tong Tong Wu", "title": "A new scope of penalized empirical likelihood with high-dimensional\n  estimating equations", "comments": null, "journal-ref": "Annals of Statistics 2018, Vol. 46, No. 6B, 3185-3216", "doi": "10.1214/17-AOS1655", "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical methods with empirical likelihood (EL) are appealing and\neffective especially in conjunction with estimating equations through which\nuseful data information can be adaptively and flexibly incorporated. It is also\nknown in the literature that EL approaches encounter difficulties when dealing\nwith problems having high-dimensional model parameters and estimating\nequations. To overcome the challenges, we begin our study with a careful\ninvestigation on high-dimensional EL from a new scope targeting at estimating a\nhigh-dimensional sparse model parameters. We show that the new scope provides\nan opportunity for relaxing the stringent requirement on the dimensionality of\nthe model parameter. Motivated by the new scope, we then propose a new\npenalized EL by applying two penalty functions respectively regularizing the\nmodel parameters and the associated Lagrange multipliers in the optimizations\nof EL. By penalizing the Lagrange multiplier to encourage its sparsity, we show\nthat drastic dimension reduction in the number of estimating equations can be\neffectively achieved without compromising the validity and consistency of the\nresulting estimators. Most attractively, such a reduction in dimensionality of\nestimating equations is actually equivalent to a selection among those\nhigh-dimensional estimating equations, resulting in a highly parsimonious and\neffective device for high-dimensional sparse model parameters. Allowing both\nthe dimensionalities of model parameters and estimating equations growing\nexponentially with the sample size, our theory demonstrates that the estimator\nfrom our new penalized EL is sparse and consistent with asymptotically normally\ndistributed nonzero components. Numerical simulations and a real data analysis\nshow that the proposed penalized EL works promisingly.\n", "versions": [{"version": "v1", "created": "Mon, 3 Apr 2017 13:18:59 GMT"}, {"version": "v2", "created": "Sun, 28 May 2017 03:25:14 GMT"}], "update_date": "2018-12-21", "authors_parsed": [["Chang", "Jinyuan", ""], ["Tang", "Cheng Yong", ""], ["Wu", "Tong Tong", ""]]}, {"id": "1704.00624", "submitter": "Bertrand Iooss", "authors": "Bertrand Iooss (1,2,3), Lo\\\"ic Le Gratiet (1) ((1) EDF R&D, (2) IMT,\n  (3) GdR MASCOT-NUM)", "title": "Uncertainty and sensitivity analysis of functional risk curves based on\n  Gaussian processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A functional risk curve gives the probability of an undesirable event as a\nfunction of the value of a critical parameter of a considered physical system.\nIn several applicative situations, this curve is built using phenomenological\nnumerical models which simulate complex physical phenomena. To avoid cpu-time\nexpensive numerical models, we propose to use Gaussian process regression to\nbuild functional risk curves. An algorithm is given to provide confidence\nbounds due to this approximation. Two methods of global sensitivity analysis of\nthe models' random input parameters on the functional risk curve are also\nstudied. In particular, the PLI sensitivity indices allow to understand the\neffect of misjudgment on the input parameters' probability density functions.\n", "versions": [{"version": "v1", "created": "Mon, 3 Apr 2017 14:45:46 GMT"}, {"version": "v2", "created": "Tue, 25 Jul 2017 11:38:13 GMT"}], "update_date": "2017-07-26", "authors_parsed": [["Iooss", "Bertrand", ""], ["Gratiet", "Lo\u00efc Le", ""]]}, {"id": "1704.00642", "submitter": "Timothy Cannings", "authors": "Timothy I. Cannings, Thomas B. Berrett and Richard J. Samworth", "title": "Local nearest neighbour classification with applications to\n  semi-supervised learning", "comments": "60 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.CV cs.LG stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive a new asymptotic expansion for the global excess risk of a\nlocal-$k$-nearest neighbour classifier, where the choice of $k$ may depend upon\nthe test point. This expansion elucidates conditions under which the dominant\ncontribution to the excess risk comes from the decision boundary of the optimal\nBayes classifier, but we also show that if these conditions are not satisfied,\nthen the dominant contribution may arise from the tails of the marginal\ndistribution of the features. Moreover, we prove that, provided the\n$d$-dimensional marginal distribution of the features has a finite $\\rho$th\nmoment for some $\\rho > 4$ (as well as other regularity conditions), a local\nchoice of $k$ can yield a rate of convergence of the excess risk of\n$O(n^{-4/(d+4)})$, where $n$ is the sample size, whereas for the standard\n$k$-nearest neighbour classifier, our theory would require $d \\geq 5$ and $\\rho\n> 4d/(d-4)$ finite moments to achieve this rate. These results motivate a new\n$k$-nearest neighbour classifier for semi-supervised learning problems, where\nthe unlabelled data are used to obtain an estimate of the marginal feature\ndensity, and fewer neighbours are used for classification when this density\nestimate is small. Our worst-case rates are complemented by a minimax lower\nbound, which reveals that the local, semi-supervised $k$-nearest neighbour\nclassifier attains the minimax optimal rate over our classes for the excess\nrisk, up to a subpolynomial factor in $n$. These theoretical improvements over\nthe standard $k$-nearest neighbour classifier are also illustrated through a\nsimulation study.\n", "versions": [{"version": "v1", "created": "Mon, 3 Apr 2017 15:34:11 GMT"}, {"version": "v2", "created": "Fri, 24 Aug 2018 11:16:30 GMT"}, {"version": "v3", "created": "Sat, 18 May 2019 10:49:46 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Cannings", "Timothy I.", ""], ["Berrett", "Thomas B.", ""], ["Samworth", "Richard J.", ""]]}, {"id": "1704.00835", "submitter": "Arkadi Nemirovski", "authors": "Anatoli Juditsky, Arkadi Nemirovski", "title": "Near-Optimality of Linear Recovery from Indirect Observations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of recovering linear image $Bx$ of a signal $x$ known\nto belong to a given convex compact set ${\\cal X}$ from indirect observation\n$\\omega=Ax+\\xi$ of $x$ corrupted by random noise $\\xi$ with finite covariance\nmatrix. It is shown that under some assumptions on ${\\cal X}$ (satisfied, e.g.,\nwhen ${\\cal X}$ is the intersection of $K$ concentric ellipsoids/elliptic\ncylinders, or the unit ball of the spectral norm in the space of matrices) and\non the norm $\\|\\cdot\\|$ used to measure the recovery error (satisfied, e.g., by\n$\\|\\cdot\\|_p$-norms, $1\\leq p\\leq 2$, on ${\\mathbf{R}}^m$ and by the nuclear\nnorm on the space of matrices), one can build, in a computationally efficient\nmanner, a \"presumably good\" linear in observations estimate, and that in the\ncase of zero mean Gaussian observation noise, this estimate is near-optimal\namong all (linear and nonlinear) estimates in terms of its worst-case, over\n$x\\in {\\cal X}$, expected $\\|\\cdot\\|$-loss. These results form an essential\nextension of those in our paper arXiv:1602.01355, where the assumptions on\n${\\cal X}$ were more restrictive, and the norm $\\|\\cdot\\|$ was assumed to be\nthe Euclidean one. In addition, we develop near-optimal estimates for the case\nof \"uncertain-but-bounded\" noise, where all we know about $\\xi$ is that it is\nbounded in a given norm by a given $\\sigma$. Same as in arXiv:1602.01355, our\nresults impose no restrictions on $A$ and $B$.\n  This arXiv paper slightly strengthens the journal publication Juditsky, A.,\nNemirovski, A. \"Near-Optimality of Linear Recovery from Indirect Observations,\"\nMathematical Statistics and Learning 1:2 (2018), 171-225.\n", "versions": [{"version": "v1", "created": "Mon, 3 Apr 2017 23:55:18 GMT"}, {"version": "v2", "created": "Mon, 17 Apr 2017 14:42:45 GMT"}, {"version": "v3", "created": "Sun, 30 Apr 2017 02:29:24 GMT"}, {"version": "v4", "created": "Thu, 15 Jun 2017 14:25:52 GMT"}, {"version": "v5", "created": "Sun, 17 Mar 2019 12:33:25 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Juditsky", "Anatoli", ""], ["Nemirovski", "Arkadi", ""]]}, {"id": "1704.00850", "submitter": "Qian Qin", "authors": "Qian Qin, James P. Hobert, Kshitij Khare", "title": "Estimating the spectral gap of a trace-class Markov operator", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The utility of a Markov chain Monte Carlo algorithm is, in large part,\ndetermined by the size of the spectral gap of the corresponding Markov\noperator. However, calculating (and even approximating) the spectral gaps of\npractical Monte Carlo Markov chains in statistics has proven to be an extremely\ndifficult and often insurmountable task, especially when these chains move on\ncontinuous state spaces. In this paper, a method for accurate estimation of the\nspectral gap is developed for general state space Markov chains whose operators\nare non-negative and trace-class. The method is based on the fact that the\nsecond largest eigenvalue (and hence the spectral gap) of such operators can be\nbounded above and below by simple functions of the power sums of the\neigenvalues. These power sums often have nice integral representations. A\nclassical Monte Carlo method is proposed to estimate these integrals, and a\nsimple sufficient condition for finite variance is provided. This leads to\nasymptotically valid confidence intervals for the second largest eigenvalue\n(and the spectral gap) of the Markov operator. In contrast with previously\nexisting techniques, our method is not based on a near-stationary version of\nthe Markov chain, which, paradoxically, cannot be obtained in a principled\nmanner without bounds on the spectral gap. On the other hand, it can be quite\nexpensive from a computational standpoint. The efficiency of the method is\nstudied both theoretically and empirically.\n", "versions": [{"version": "v1", "created": "Tue, 4 Apr 2017 01:52:24 GMT"}, {"version": "v2", "created": "Thu, 22 Jun 2017 03:55:20 GMT"}, {"version": "v3", "created": "Thu, 4 Apr 2019 23:58:26 GMT"}], "update_date": "2019-04-08", "authors_parsed": [["Qin", "Qian", ""], ["Hobert", "James P.", ""], ["Khare", "Kshitij", ""]]}, {"id": "1704.01055", "submitter": "Yuping Song", "authors": "Yuping Song, Hanchao Wang", "title": "One-step Local M-estimator for Integrated Jump-Diffusion Models", "comments": "There are some lackness for simulation study and empirical analysis,\n  some error correction to be done for the detailed proof", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, robust nonparametric estimators, instead of local linear\nestimators, are adapted for infinitesimal coefficients associated with\nintegrated jump-diffusion models to avoid the impact of outliers on accuracy.\nFurthermore, consider the complexity of iteration of the solution for local\nM-estimator, we propose the one-step local M-estimators to release the\ncomputation burden. Under appropriate regularity conditions, we prove that\none-step local M-estimators and the fully iterative M-estimators have the same\nperformance in consistency and asymptotic normality. Through simulation, our\nmethod present advantages in bias reduction, robustness and reducing\ncomputation cost. In addition, the estimators are illustrated empirically\nthrough stock index under different sampling frequency.\n", "versions": [{"version": "v1", "created": "Tue, 4 Apr 2017 15:30:50 GMT"}, {"version": "v2", "created": "Sun, 24 Jun 2018 08:55:12 GMT"}], "update_date": "2018-06-26", "authors_parsed": [["Song", "Yuping", ""], ["Wang", "Hanchao", ""]]}, {"id": "1704.01171", "submitter": "Harry Crane", "authors": "Harry Crane and Ryan Martin", "title": "Rethinking probabilistic prediction in the wake of the 2016 U.S.\n  presidential election", "comments": "19 pages; 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.OT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To many statisticians and citizens, the outcome of the most recent U.S.\npresidential election represents a failure of data-driven methods on the\ngrandest scale. This impression has led to much debate and discussion about how\nthe election predictions went awry -- Were the polls inaccurate? Were the\nmodels wrong? Did we misinterpret the probabilities? -- and how they went right\n-- Perhaps the analyses were correct even though the predictions were wrong,\nthat's just the nature of probabilistic forecasting. With this in mind, we\nanalyze the election outcome with respect to a core set of effectiveness\nprinciples. Regardless of whether and how the election predictions were right\nor wrong, we argue that they were ineffective in conveying the extent to which\nthe data was informative of the outcome and the level of uncertainty in making\nthese assessments. Among other things, our analysis sheds light on the\nshortcomings of the classical interpretations of probability and its\ncommunication to consumers in the form of predictions. We present here an\nalternative approach, based on a notion of validity, which offers two immediate\ninsights for predictive inference. First, the predictions are more\nconservative, arguably more realistic, and come with certain guarantees on the\nprobability of an erroneous prediction. Second, our approach easily and\nnaturally reflects the (possibly substantial) uncertainty about the model by\noutputting plausibilities instead of probabilities. Had these simple steps been\ntaken by the popular prediction outlets, the election outcome may not have been\nso shocking.\n", "versions": [{"version": "v1", "created": "Tue, 4 Apr 2017 20:14:00 GMT"}], "update_date": "2017-04-06", "authors_parsed": [["Crane", "Harry", ""], ["Martin", "Ryan", ""]]}, {"id": "1704.01302", "submitter": "Natalia Markovich M", "authors": "Natalia Markovich", "title": "Extremes in Random Graphs Models of Complex Networks", "comments": "ASMDA2017 International Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regarding the analysis of Web communication, social and complex networks the\nfast finding of most influential nodes in a network graph constitutes an\nimportant research problem. We use two indices of the influence of those nodes,\nnamely, PageRank and a Max-linear model. We consider the PageRank %both as\n%Galton-Watson branching process and as an autoregressive process with a random\nnumber of random coefficients that depend on ranks of incoming nodes and their\nout-degrees and assume that the coefficients are independent and distributed\nwith regularly varying tail and with the same tail index. Then it is proved\nthat the tail index and the extremal index are the same for both PageRank and\nthe Max-linear model and the values of these indices are found. The\nachievements are based on the study of random sequences of a random length and\nthe comparison of the distribution of their maxima and linear combinations.\n", "versions": [{"version": "v1", "created": "Wed, 5 Apr 2017 08:15:54 GMT"}], "update_date": "2017-04-06", "authors_parsed": [["Markovich", "Natalia", ""]]}, {"id": "1704.01312", "submitter": "Pirmin Lemberger", "authors": "Pirmin Lemberger", "title": "On Generalization and Regularization in Deep Learning", "comments": "11 pages, 3 figures pedagogical paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Why do large neural network generalize so well on complex tasks such as image\nclassification or speech recognition? What exactly is the role regularization\nfor them? These are arguably among the most important open questions in machine\nlearning today. In a recent and thought provoking paper [C. Zhang et al.]\nseveral authors performed a number of numerical experiments that hint at the\nneed for novel theoretical concepts to account for this phenomenon. The paper\nstirred quit a lot of excitement among the machine learning community but at\nthe same time it created some confusion as discussions on OpenReview.net\ntestifies. The aim of this pedagogical paper is to make this debate accessible\nto a wider audience of data scientists without advanced theoretical knowledge\nin statistical learning. The focus here is on explicit mathematical definitions\nand on a discussion of relevant concepts, not on proofs for which we provide\nreferences.\n", "versions": [{"version": "v1", "created": "Wed, 5 Apr 2017 08:48:01 GMT"}, {"version": "v2", "created": "Thu, 6 Apr 2017 19:58:27 GMT"}], "update_date": "2017-04-10", "authors_parsed": [["Lemberger", "Pirmin", ""]]}, {"id": "1704.01418", "submitter": "Jeremy Sumner", "authors": "Jeremy G Sumner", "title": "Multiplicatively closed Markov models must form Lie algebras", "comments": "v2: 6 pages. Minimality condition included in Property 0 to close gap\n  in the proof of main result. To appear in the ANZIAM Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.GR math.ST q-bio.PE q-bio.QM stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that the probability substitution matrices obtained from a\ncontinuous-time Markov chain form a multiplicatively closed set if and only if\nthe rate matrices associated to the chain form a linear space spanning a Lie\nalgebra. The key original contribution we make is to overcome an obstruction,\ndue to the presence of inequalities that are unavoidable in the probabilistic\napplication, that prevents free manipulation of terms in the\nBaker-Campbell-Haursdorff formula.\n", "versions": [{"version": "v1", "created": "Tue, 4 Apr 2017 02:24:09 GMT"}, {"version": "v2", "created": "Fri, 1 Sep 2017 03:07:40 GMT"}], "update_date": "2017-09-04", "authors_parsed": [["Sumner", "Jeremy G", ""]]}, {"id": "1704.01437", "submitter": "Francois Roueff", "authors": "Fran\\c{c}ois Roueff (LTCI), Rainer Von Sachs", "title": "Time-frequency analysis of locally stationary Hawkes processes", "comments": "Bernoulli journal, A Para{\\^i}tre", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Locally stationary Hawkes processes have been introduced in order to\ngeneralise classical Hawkes processes away from stationarity by allowing for a\ntime-varying second-order structure. This class of self-exciting point\nprocesses has recently attracted a lot of interest in applications in the life\nsciences (seismology, genomics, neuro-science,...), but also in the modelling\nof high-frequency financial data. In this contribution we provide a fully\ndeveloped nonparametric estimation theory of both local mean density and local\nBartlett spectra of a locally stationary Hawkes process. In particular we apply\nour kernel estimation of the spectrum localised both in time and frequency to\ntwo data sets of transaction times revealing pertinent features in the data\nthat had not been made visible by classical non-localised approaches based on\nmodels with constant fertility functions over time.\n", "versions": [{"version": "v1", "created": "Wed, 5 Apr 2017 14:11:05 GMT"}, {"version": "v2", "created": "Tue, 14 Nov 2017 09:29:41 GMT"}, {"version": "v3", "created": "Tue, 30 Jan 2018 08:52:32 GMT"}], "update_date": "2018-01-31", "authors_parsed": [["Roueff", "Fran\u00e7ois", "", "LTCI"], ["Von Sachs", "Rainer", ""]]}, {"id": "1704.01458", "submitter": "Fabio Gobbi", "authors": "Fabio Gobbi, Sabrina Mulinacci", "title": "$\\beta$-mixing and moments properties of a non-stationary copula-based\n  Markov process", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides conditions under which a non-stationary copula-based\nMarkov process is $\\beta$-mixing. We introduce, as a particular case, a\nconvolution-based gaussian Markov process which generalizes the standard random\nwalk allowing the increments to be dependent.\n", "versions": [{"version": "v1", "created": "Wed, 5 Apr 2017 14:53:29 GMT"}], "update_date": "2017-04-06", "authors_parsed": [["Gobbi", "Fabio", ""], ["Mulinacci", "Sabrina", ""]]}, {"id": "1704.01620", "submitter": "Victor-Emmanuel Brunel", "authors": "Victor-Emmanuel Brunel", "title": "Uniform deviation and moment inequalities for random polytopes with\n  general densities in arbitrary convex bodies", "comments": "This work is an updated and extended version of a previous preprint\n  (arXiv:1311.2902)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove an exponential deviation inequality for the convex hull of a finite\nsample of i.i.d. random points with a density supported on an arbitrary convex\nbody in $\\R^d$, $d\\geq 2$. When the density is uniform, our result yields rate\noptimal upper bounds for all the moments of the missing volume of the convex\nhull, uniformly over all convex bodies of $\\R^d$: We make no restrictions on\ntheir volume, location in the space or smoothness of their boundary. After\nextending an identity due to Efron, we also prove upper bounds for the moments\nof the number of vertices of the random polytope. Surprisingly, these bounds do\nnot depend on the underlying density and we prove that the growth rates that we\nobtain are tight in a certain sense.\n", "versions": [{"version": "v1", "created": "Wed, 5 Apr 2017 19:23:53 GMT"}], "update_date": "2017-04-07", "authors_parsed": [["Brunel", "Victor-Emmanuel", ""]]}, {"id": "1704.01670", "submitter": "Dimas Dutra", "authors": "Dimas Abreu Archanjo Dutra, Bruno Ot\\'avio Soares Teixeira, Luis\n  Antonio Aguirre", "title": "Joint Maximum a Posteriori State Path and Parameter Estimation in\n  Stochastic Differential Equations", "comments": null, "journal-ref": null, "doi": "10.1016/j.automatica.2017.03.035", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we introduce the joint maximum a posteriori state path and\nparameter estimator (JME) for continuous-time systems described by stochastic\ndifferential equations (SDEs). This estimator can be applied to nonlinear\nsystems with discrete-time (sampled) measurements with a wide range of\nmeasurement distributions. We also show that the minimum-energy state path and\nparameter estimator (MEE) obtains the joint maximum a posteriori noise path,\ninitial conditions, and parameters. These estimators are demonstrated in\nsimulated experiments, in which they are compared to the prediction error\nmethod (PEM) using the unscented Kalman filter and smoother. The experiments\nshow that the MEE is biased for the damping parameters of the drift function.\nFurthermore, for robust estimation in the presence of outliers, the JME attains\nlower state estimation errors than the PEM.\n", "versions": [{"version": "v1", "created": "Thu, 6 Apr 2017 00:10:38 GMT"}], "update_date": "2017-04-07", "authors_parsed": [["Dutra", "Dimas Abreu Archanjo", ""], ["Teixeira", "Bruno Ot\u00e1vio Soares", ""], ["Aguirre", "Luis Antonio", ""]]}, {"id": "1704.01673", "submitter": "Yongcheng Qi", "authors": "Shuhua Chang, Yongcheng Qi", "title": "On Tests for Complete Independence of Normal Random Vectors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a random sample of $n$ independently and identically distributed\n$p$-dimensional normal random vectors. A test statistic for complete\nindependence of high-dimensional normal distributions, proposed by Schott\n(2005), is defined as the sum of squared Pearson's correlation coefficients. A\nmodified test statistic has been proposed by Mao (2014). Under the assumption\nof complete independence, both test statistics are asymptotically normal if the\nlimit $\\lim_{n\\to\\infty}p/n$ exists and is finite. In this paper, we\ninvestigate the limiting distributions for both Schott's and Mao's test\nstatistics. We show that both test statistics, after suitably normalized,\nconverge in distribution to the standard normal as long as both $n$ and $p$\ntend to infinity. Furthermore, we show that the distribution functions of the\ntest statistics can be approximated very well by a chi-square distribution\nfunction with $p(p-1)/2$ degrees of freedom as $n$ tends to infinity regardless\nof how $p$ changes with $n$.\n", "versions": [{"version": "v1", "created": "Thu, 6 Apr 2017 00:39:51 GMT"}], "update_date": "2017-04-07", "authors_parsed": [["Chang", "Shuhua", ""], ["Qi", "Yongcheng", ""]]}, {"id": "1704.01847", "submitter": "Dimas Dutra", "authors": "Dimas Abreu Dutra", "title": "Maximum a Posteriori Joint State Path and Parameter Estimation in\n  Stochastic Differential Equations", "comments": "Doctoral thesis in the \"Programa de P\\'os-Gradua\\c{c}\\~ao em\n  Engenharia El\\'etrica da Universidade Federal de Minas Gerais\" (PPGEE-UFMG).\n  http://hdl.handle.net/1843/BUOS-9S3H9D", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  A wide variety of phenomena of engineering and scientific interest are of a\ncontinuous-time nature and can be modeled by stochastic differential equations\n(SDEs), which represent the evolution of the uncertainty in the states of a\nsystem. For systems of this class, some parameters of the SDE might be unknown\nand the measured data often includes noise, so state and parameter estimators\nare needed to perform inference and further analysis using the system state\npath. The distributions of SDEs which are nonlinear or subject to non-Gaussian\nmeasurement noise do not admit tractable analytic expressions, so state and\nparameter estimators for these systems are often approximations based on\nheuristics, such as the extended and unscented Kalman smoothers, or the\nprediction error method using nonlinear Kalman filters. However, the Onsager\nMachlup functional can be used to obtain fictitious densities for the\nparameters and state-paths of SDEs with analytic expressions. In this thesis,\nwe provide a unified theoretical framework for maximum a posteriori (MAP)\nestimation of general random variables, possibly infinite-dimensional, and show\nhow the Onsager--Machlup functional can be used to construct the joint MAP\nstate-path and parameter estimator for SDEs. We also prove that the minimum\nenergy estimator, which is often thought to be the MAP state-path estimator,\nactually gives the state paths associated to the MAP noise paths. Furthermore,\nwe prove that the discretized MAP state-path and parameter estimators, which\nhave emerged recently as powerful alternatives to nonlinear Kalman smoothers,\nconverge hypographically as the discretization step vanishes. Their\nhypographical limit, however, is the MAP estimator for SDEs when the\ntrapezoidal discretization is used and the minimum energy estimator when the\nEuler discretization is used, associating different interpretations to each\ndiscretized estimate.\n", "versions": [{"version": "v1", "created": "Thu, 6 Apr 2017 13:59:42 GMT"}], "update_date": "2017-04-07", "authors_parsed": [["Dutra", "Dimas Abreu", ""]]}, {"id": "1704.02146", "submitter": "Maria Schuld", "authors": "Maria Schuld and Francesco Petruccione", "title": "Quantum ensembles of quantum classifiers", "comments": "19 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum machine learning witnesses an increasing amount of quantum algorithms\nfor data-driven decision making, a problem with potential applications ranging\nfrom automated image recognition to medical diagnosis. Many of those algorithms\nare implementations of quantum classifiers, or models for the classification of\ndata inputs with a quantum computer. Following the success of collective\ndecision making with ensembles in classical machine learning, this paper\nintroduces the concept of quantum ensembles of quantum classifiers. Creating\nthe ensemble corresponds to a state preparation routine, after which the\nquantum classifiers are evaluated in parallel and their combined decision is\naccessed by a single-qubit measurement. This framework naturally allows for\nexponentially large ensembles in which -- similar to Bayesian learning -- the\nindividual classifiers do not have to be trained. As an example, we analyse an\nexponentially large quantum ensemble in which each classifier is weighed\naccording to its performance in classifying the training data, leading to new\nresults for quantum as well as classical machine learning.\n", "versions": [{"version": "v1", "created": "Fri, 7 Apr 2017 09:12:39 GMT"}], "update_date": "2017-04-10", "authors_parsed": [["Schuld", "Maria", ""], ["Petruccione", "Francesco", ""]]}, {"id": "1704.02213", "submitter": "Sebastian Bayer", "authors": "Timo Dimitriadis and Sebastian Bayer", "title": "A Joint Quantile and Expected Shortfall Regression Framework", "comments": "31 pages, 3 figures", "journal-ref": "Electron. J. Statist. 13 (2019), no. 1, 1823--1871", "doi": "10.1214/19-EJS1560", "report-no": null, "categories": "math.ST q-fin.RM q-fin.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel regression framework which simultaneously models the\nquantile and the Expected Shortfall (ES) of a response variable given a set of\ncovariates. This regression is based on a strictly consistent loss function for\nthe pair quantile and ES, which allows for M- and Z-estimation of the joint\nregression parameters. We show consistency and asymptotic normality for both\nestimators under weak regularity conditions. The underlying loss function\ndepends on two specification functions, whose choice affects the properties of\nthe resulting estimators. We find that the Z-estimator is numerically unstable\nand thus, we rely on M-estimation of the model parameters. Extensive\nsimulations verify the asymptotic properties and analyze the small sample\nbehavior of the M-estimator for different specification functions. This joint\nregression framework allows for various applications including estimating,\nforecasting, and backtesting ES, which is particularly relevant in light of the\nrecent introduction of ES into the Basel Accords.\n", "versions": [{"version": "v1", "created": "Fri, 7 Apr 2017 13:04:19 GMT"}, {"version": "v2", "created": "Mon, 22 May 2017 07:34:05 GMT"}, {"version": "v3", "created": "Tue, 8 Aug 2017 07:51:08 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Dimitriadis", "Timo", ""], ["Bayer", "Sebastian", ""]]}, {"id": "1704.02408", "submitter": "Zhigang Bao", "authors": "Zhigang Bao, Jiang Hu, Guangming Pan, Wang Zhou", "title": "Canonical correlation coefficients of high-dimensional Gaussian vectors:\n  finite rank case", "comments": "This is an extended version of the previous work arXiv:1407.7194v2.\n  In the current work, we have included the result on the fluctuations, and the\n  limit part has also been reorganized", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a Gaussian vector $\\mathbf{z}=(\\mathbf{x}',\\mathbf{y}')'$,\nconsisting of two sub-vectors $\\mathbf{x}$ and $\\mathbf{y}$ with dimensions $p$\nand $q$ respectively, where both $p$ and $q$ are proportional to the sample\nsize $n$. Denote by $\\Sigma_{\\mathbf{u}\\mathbf{v}}$ the population\ncross-covariance matrix of random vectors $\\mathbf{u}$ and $\\mathbf{v}$, and\ndenote by $S_{\\mathbf{u}\\mathbf{v}}$ the sample counterpart. The canonical\ncorrelation coefficients between $\\mathbf{x}$ and $\\mathbf{y}$ are known as the\nsquare roots of the nonzero eigenvalues of the canonical correlation matrix\n$\\Sigma_{\\mathbf{x}\\mathbf{x}}^{-1}\\Sigma_{\\mathbf{x}\\mathbf{y}}\\Sigma_{\\mathbf{y}\\mathbf{y}}^{-1}\\Sigma_{\\mathbf{y}\\mathbf{x}}$.\nIn this paper, we focus on the case that $\\Sigma_{\\mathbf{x}\\mathbf{y}}$ is of\nfinite rank $k$, i.e. there are $k$ nonzero canonical correlation coefficients,\nwhose squares are denoted by $r_1\\geq\\cdots\\geq r_k>0$. We study the sample\ncounterparts of $r_i,i=1,\\ldots,k$, i.e. the largest $k$ eigenvalues of the\nsample canonical correlation matrix\n$\\S_{\\mathbf{x}\\mathbf{x}}^{-1}\\S_{\\mathbf{x}\\mathbf{y}}\\S_{\\mathbf{y}\\mathbf{y}}^{-1}\\S_{\\mathbf{y}\\mathbf{x}}$,\ndenoted by $\\lambda_1\\geq\\cdots\\geq \\lambda_k$. We show that there exists a\nthreshold $r_c\\in(0,1)$, such that for each $i\\in\\{1,\\ldots,k\\}$, when $r_i\\leq\nr_c$, $\\lambda_i$ converges almost surely to the right edge of the limiting\nspectral distribution of the sample canonical correlation matrix, denoted by\n$d_{+}$. When $r_i>r_c$, $\\lambda_i$ possesses an almost sure limit in\n$(d_{+},1]$. We also obtain the limiting distribution of $\\lambda_i$'s under\nappropriate normalization. Specifically, $\\lambda_i$ possesses Gaussian type\nfluctuation if $r_i>r_c$, and follows Tracy-Widom distribution if $r_i<r_c$.\nSome applications of our results are also discussed.\n", "versions": [{"version": "v1", "created": "Sat, 8 Apr 2017 00:30:09 GMT"}, {"version": "v2", "created": "Thu, 1 Jun 2017 13:44:01 GMT"}, {"version": "v3", "created": "Tue, 6 Jun 2017 05:40:14 GMT"}], "update_date": "2017-06-07", "authors_parsed": [["Bao", "Zhigang", ""], ["Hu", "Jiang", ""], ["Pan", "Guangming", ""], ["Zhou", "Wang", ""]]}, {"id": "1704.02531", "submitter": "Paul McNicholas", "authors": "Michael P.B. Gallaugher and Paul D. McNicholas", "title": "Three Skewed Matrix Variate Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Three-way data can be conveniently modelled by using matrix variate\ndistributions. Although there has been a lot of work for the matrix variate\nnormal distribution, there is little work in the area of matrix skew\ndistributions. Three matrix variate distributions that incorporate skewness, as\nwell as other flexible properties such as concentration, are discussed.\nEquivalences to multivariate analogues are presented, and moment generating\nfunctions are derived. Maximum likelihood parameter estimation is discussed,\nand simulated data is used for illustration.\n", "versions": [{"version": "v1", "created": "Sat, 8 Apr 2017 20:03:01 GMT"}, {"version": "v2", "created": "Sun, 23 Apr 2017 22:05:55 GMT"}, {"version": "v3", "created": "Sat, 8 Jul 2017 20:00:10 GMT"}, {"version": "v4", "created": "Sat, 4 Nov 2017 22:20:45 GMT"}, {"version": "v5", "created": "Mon, 13 Aug 2018 21:19:08 GMT"}], "update_date": "2018-08-15", "authors_parsed": [["Gallaugher", "Michael P. B.", ""], ["McNicholas", "Paul D.", ""]]}, {"id": "1704.02545", "submitter": "Ming-Tien Tsai", "authors": "Ming-Tien Tsai", "title": "A note on MLE of covariance matrix", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For a multivariate normal set up, it is well known that the maximum\nlikelihood estimator of covariance matrix is neither admissible nor minimax\nunder the Stein loss function. For the past six decades, a bunch of researches\nhave followed along this line for Stein's phenomenon in the literature. In this\nnote, the results are two folds: Firstly, with respect to Stein type loss\nfunction we use the full Iwasawa decomposition to enhance the unpleasant\nphenomenon that the minimum risks of maximum likelihood estimators for the\ndifferent coordinate systems (Cholesky decomposition and full Iwasawa\ndecomposition) are different. Secondly, we introduce a new class of loss\nfunctions to show that the minimum risks of maximum likelihood estimators for\nthe different coordinate systems, the Cholesky decomposition and the full\nIwasawa decomposition, are of the same, and hence the Stein's paradox\ndisappears.\n", "versions": [{"version": "v1", "created": "Sun, 9 Apr 2017 00:36:42 GMT"}, {"version": "v2", "created": "Fri, 28 Apr 2017 04:32:27 GMT"}, {"version": "v3", "created": "Sun, 16 Jul 2017 05:37:53 GMT"}, {"version": "v4", "created": "Sun, 23 Jul 2017 07:13:16 GMT"}], "update_date": "2017-07-25", "authors_parsed": [["Tsai", "Ming-Tien", ""]]}, {"id": "1704.02598", "submitter": "Vasilis Syrgkanis", "authors": "Vasilis Syrgkanis", "title": "A Sample Complexity Measure with Applications to Learning Optimal\n  Auctions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new sample complexity measure, which we refer to as\nsplit-sample growth rate. For any hypothesis $H$ and for any sample $S$ of size\n$m$, the split-sample growth rate $\\hat{\\tau}_H(m)$ counts how many different\nhypotheses can empirical risk minimization output on any sub-sample of $S$ of\nsize $m/2$. We show that the expected generalization error is upper bounded by\n$O\\left(\\sqrt{\\frac{\\log(\\hat{\\tau}_H(2m))}{m}}\\right)$. Our result is enabled\nby a strengthening of the Rademacher complexity analysis of the expected\ngeneralization error. We show that this sample complexity measure, greatly\nsimplifies the analysis of the sample complexity of optimal auction design, for\nmany auction classes studied in the literature. Their sample complexity can be\nderived solely by noticing that in these auction classes, ERM on any sample or\nsub-sample will pick parameters that are equal to one of the points in the\nsample.\n", "versions": [{"version": "v1", "created": "Sun, 9 Apr 2017 13:17:52 GMT"}, {"version": "v2", "created": "Tue, 11 Apr 2017 12:52:22 GMT"}], "update_date": "2017-04-18", "authors_parsed": [["Syrgkanis", "Vasilis", ""]]}, {"id": "1704.02646", "submitter": "Dana Yang", "authors": "Dana Yang", "title": "Posterior Asymptotic Normality for an Individual Coordinate in\n  High-dimensional Linear Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the sparse high-dimensional linear regression model\n$Y=Xb+\\epsilon$ where $b$ is a sparse vector. For the Bayesian approach to this\nproblem, many authors have considered the behavior of the posterior\ndistribution when, in truth, $Y=X\\beta+\\epsilon$ for some given $\\beta$. There\nhave been numerous results about the rate at which the posterior distribution\nconcentrates around $\\beta$, but few results about the shape of that posterior\ndistribution. We propose a prior distribution for $b$ such that the marginal\nposterior distribution of an individual coordinate $b_i$ is asymptotically\nnormal centered around an asymptotically efficient estimator, under the truth.\nSuch a result gives Bayesian credible intervals that match with the confidence\nintervals obtained from an asymptotically efficient estimator for $b_i$. We\nalso discuss ways of obtaining such asymptotically efficient estimators on\nindividual coordinates. We compare the two-step procedure proposed by Zhang and\nZhang (2014) and a one-step modified penalization method.\n", "versions": [{"version": "v1", "created": "Sun, 9 Apr 2017 19:19:16 GMT"}], "update_date": "2017-04-11", "authors_parsed": [["Yang", "Dana", ""]]}, {"id": "1704.02658", "submitter": "Stanislav Minsker", "authors": "Stanislav Minsker and Nate Strawn", "title": "Distributed Statistical Estimation and Rates of Convergence in Normal\n  Approximation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.DC stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a class of new algorithms for distributed statistical\nestimation that exploit divide-and-conquer approach. We show that one of the\nkey benefits of the divide-and-conquer strategy is robustness, an important\ncharacteristic for large distributed systems. We establish connections between\nperformance of these distributed algorithms and the rates of convergence in\nnormal approximation, and prove non-asymptotic deviations guarantees, as well\nas limit theorems, for the resulting estimators. Our techniques are illustrated\nthrough several examples: in particular, we obtain new results for the\nmedian-of-means estimator, as well as provide performance guarantees for\ndistributed maximum likelihood estimation.\n", "versions": [{"version": "v1", "created": "Sun, 9 Apr 2017 20:43:55 GMT"}, {"version": "v2", "created": "Thu, 20 Apr 2017 21:50:04 GMT"}, {"version": "v3", "created": "Mon, 27 Aug 2018 22:25:54 GMT"}], "update_date": "2018-08-29", "authors_parsed": [["Minsker", "Stanislav", ""], ["Strawn", "Nate", ""]]}, {"id": "1704.02760", "submitter": "Olga Klopp", "authors": "Alexandra Carpentier, Olga Klopp (CREST, MODAL'X), Matthias L\\\"offler\n  (CAM)", "title": "Constructing confidence sets for the matrix completion problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the present note we consider the problem of constructing honest and\nadaptive confidence sets for the matrix completion problem. For the Bernoulli\nmodel with known variance of the noise we provide a realizable method for\nconstructing confidence sets that adapt to the unknown rank of the true matrix.\n", "versions": [{"version": "v1", "created": "Mon, 10 Apr 2017 08:43:43 GMT"}], "update_date": "2017-04-11", "authors_parsed": [["Carpentier", "Alexandra", "", "CREST, MODAL'X"], ["Klopp", "Olga", "", "CREST, MODAL'X"], ["L\u00f6ffler", "Matthias", "", "CAM"]]}, {"id": "1704.02840", "submitter": "Kosaku Takanashi", "authors": "Kosaku Takanashi", "title": "Local Asymptotic Normality of Infinite-Dimensional Concave Extended\n  Linear Models", "comments": "26 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study local asymptotic normality of M-estimates of convex minimization in\nan infinite dimensional parameter space. The objective function of M-estimates\nis not necessary differentiable and is possibly subject to convex constraints.\nIn the above circumstance, narrow convergence with respect to uniform\nconvergence fails to hold, because of the strength of it's topology. A new\napproach we propose to the lack-of-uniform-convergence is based on\nMosco-convergence that is weaker topology than uniform convergence. By applying\nnarrow convergence with respect to Mosco topology, we develop an\ninfinite-dimensional version of the convexity argument and provide a proof of a\nlocal asymptotic normality. Our new technique also provides a proof of an\nasymptotic distribution of the likelihood ratio test statistic defined on real\nseparable Hilbert spaces.\n", "versions": [{"version": "v1", "created": "Mon, 10 Apr 2017 13:05:06 GMT"}], "update_date": "2017-04-11", "authors_parsed": [["Takanashi", "Kosaku", ""]]}, {"id": "1704.02860", "submitter": "Stefan Richter", "authors": "Rainer Dahlhaus, Stefan Richter and Wei Biao Wu", "title": "Towards a general theory for non-linear locally stationary processes", "comments": "50 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper some general theory is presented for locally stationary\nprocesses based on the stationary approximation and the stationary derivative.\nLaws of large numbers, central limit theorems as well as deterministic and\nstochastic bias expansions are proved for processes obeying an expansion in\nterms of the stationary approximation and derivative. In addition it is shown\nthat this applies to some general nonlinear non-stationary Markov-models. In\naddition the results are applied to derive the asymptotic properties of maximum\nlikelihood estimates of parameter curves in such models.\n", "versions": [{"version": "v1", "created": "Mon, 10 Apr 2017 14:00:00 GMT"}, {"version": "v2", "created": "Wed, 6 Sep 2017 16:30:11 GMT"}, {"version": "v3", "created": "Sun, 19 Nov 2017 18:47:17 GMT"}], "update_date": "2017-11-21", "authors_parsed": [["Dahlhaus", "Rainer", ""], ["Richter", "Stefan", ""], ["Wu", "Wei Biao", ""]]}, {"id": "1704.03212", "submitter": "Sunanda Bagchi", "authors": "Sunanda Bagchi", "title": "Nearly resolution V plans on blocks of small size", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Bagchi (2010) main effect plans \"orthogonal through the block factor\"\n(POTB) have been constructed. The main advantages of a POTB are that (a) it may\nexist in a set up where an \"usual\" orthogonal main effect plan (OMEP) cannot\nexist and (b) the data analysis is nearly as simple as an OMEP. In the present\npaper we extend this idea and define the concept of orthogonality between a\npair of factorial effects ( main effects or interactions) \"through the block\nfactor\" in the context of a symmetrical experiment. We consider plans generated\nfrom an initial plan by adding runs. For such a plan we have derived necessary\nand sufficient conditions for a pair of effects to be orthogonal through the\nblock factor in terms of the generators. We have also derived a sufficient\ncondition on the generators so as to turn a pair of effects aliased in the\ninitial plan separated in the final plan. The theory developed is illustrated\nwith plans for experiments with three-level factors in situations where\ninteractions between three or more factors are absent. We have constructed\nplans with blocks of size four and fewer runs than a resolution $V$ plan\nestimating all main effects and all but at most one two-factor interactions.\n", "versions": [{"version": "v1", "created": "Tue, 11 Apr 2017 09:34:28 GMT"}], "update_date": "2017-04-12", "authors_parsed": [["Bagchi", "Sunanda", ""]]}, {"id": "1704.03262", "submitter": "Sabrina Mulinacci", "authors": "Fabio Gobbi and Sabrina Mulinacci", "title": "Gaussian autoregressive process with dependent innovations. Some\n  asymptotic results", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce a modified version of a gaussian standard\nfirst-order autoregressive process where we allow for a dependence structure\nbetween the state variable $Y_{t-1}$ and the next innovation $\\xi_t$. We call\nthis model dependent innovations gaussian AR(1) process (DIG-AR(1)). We analyze\nthe moment and temporal dependence properties of the new model. After proving\nthat the OLS estimator does not consistently estimate the autoregressive\nparameter, we introduce an infeasible estimator and we provide its\n$\\sqrt{T}$-asymptotic normality.\n", "versions": [{"version": "v1", "created": "Tue, 11 Apr 2017 12:26:01 GMT"}], "update_date": "2017-04-12", "authors_parsed": [["Gobbi", "Fabio", ""], ["Mulinacci", "Sabrina", ""]]}, {"id": "1704.03304", "submitter": "Dennis Dobler", "authors": "Dennis Dobler and Andrew C. Titman", "title": "Time-dynamic inference for non-Markov transition probabilities under\n  independent right-censoring", "comments": "33 pages, 3 tables, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, weak convergence of the general non-Markov state transition\nprobability estimator by Titman (2015) is established which, up to now, has not\nbeen verified yet for other general non-Markov estimators. A similar theorem is\nshown for the bootstrap, yielding resampling-based inference methods for\nstatistical functionals. Formulas of the involved covariance functions are\npresented in detail. Particular applications include the conditional expected\nlength of stay in a specific state, given occupation of another state in the\npast, as well as the construction of time-simultaneous confidence bands for the\ntransition probabilities. The expected lengths of stay in the two-sample liver\ncirrhosis data-set by Andersen et al. (1993) are compared and confidence\nintervals for their difference are constructed. With borderline significance\nand in comparison to the placebo group, the treatment group has an elevated\nexpected length of stay in the healthy state given an earlier disease state\noccupation. In contrast, the Aalen-Johansen estimator-based confidence\ninterval, which relies on a Markov assumption, leads to a drastically different\nconclusion. Also, graphical illustrations of confidence bands for the\ntransition probabilities demonstrate the biasedness of the Aalen-Johansen\nestimator in this data example. The reliability of these results is assessed in\na simulation study.\n", "versions": [{"version": "v1", "created": "Tue, 11 Apr 2017 14:25:01 GMT"}, {"version": "v2", "created": "Fri, 4 Jan 2019 19:48:53 GMT"}], "update_date": "2019-01-08", "authors_parsed": [["Dobler", "Dennis", ""], ["Titman", "Andrew C.", ""]]}, {"id": "1704.03377", "submitter": "L\\'eo Belzile", "authors": "L\\'eo R. Belzile, Johanna G. Ne\\v{s}lehov\\'a", "title": "Extremal attractors of Liouville copulas", "comments": "30 pages including supplementary material, 6 figures", "journal-ref": "Journal of Multivariate Analysis, 160C, pp. 68-92 (2017)", "doi": "10.1016/j.jmva.2017.05.008", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Liouville copulas, which were introduced in McNeil and Neslehova (2010), are\nasymmetric generalizations of the ubiquitous Archimedean copula class. They are\nthe dependence structures of scale mixtures of Dirichlet distributions, also\ncalled Liouville distributions. In this paper, the limiting extreme-value\ncopulas of Liouville copulas and of their survival counterparts are derived.\nThe limiting max-stable models, termed here the scaled extremal Dirichlet, are\nnew and encompass several existing classes of multivariate max-stable\ndistributions, including the logistic, negative logistic and extremal\nDirichlet. As shown herein, the stable tail dependence function and angular\ndensity of the scaled extremal Dirichlet model have a tractable form, which in\nturn leads to a simple de Haan representation. The latter is used to design\nefficient algorithms for unconditional simulation based on the work of Dombry,\nEngelke and Oesting (2015) and to derive tractable formulas for\nmaximum-likelihood inference. The scaled extremal Dirichlet model is\nillustrated on river flow data of the river Isar in southern Germany.\n", "versions": [{"version": "v1", "created": "Tue, 11 Apr 2017 15:51:44 GMT"}, {"version": "v2", "created": "Thu, 6 Jul 2017 20:21:01 GMT"}], "update_date": "2017-07-10", "authors_parsed": [["Belzile", "L\u00e9o R.", ""], ["Ne\u0161lehov\u00e1", "Johanna G.", ""]]}, {"id": "1704.03606", "submitter": "Shahab Asoodeh", "authors": "Shahab Asoodeh, Mario Diaz, Fady Alajaji, and Tam\\'as Linder", "title": "Privacy-Aware Guessing Efficiency", "comments": "ISIT 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the problem of guessing a discrete random variable $Y$ under a\nprivacy constraint dictated by another correlated discrete random variable $X$,\nwhere both guessing efficiency and privacy are assessed in terms of the\nprobability of correct guessing. We define $h(P_{XY}, \\epsilon)$ as the maximum\nprobability of correctly guessing $Y$ given an auxiliary random variable $Z$,\nwhere the maximization is taken over all $P_{Z|Y}$ ensuring that the\nprobability of correctly guessing $X$ given $Z$ does not exceed $\\epsilon$. We\nshow that the map $\\epsilon\\mapsto h(P_{XY}, \\epsilon)$ is strictly increasing,\nconcave, and piecewise linear, which allows us to derive a closed form\nexpression for $h(P_{XY}, \\epsilon)$ when $X$ and $Y$ are connected via a\nbinary-input binary-output channel. For $(X^n, Y^n)$ being pairs of independent\nand identically distributed binary random vectors, we similarly define\n$\\underline{h}_n(P_{X^nY^n}, \\epsilon)$ under the assumption that $Z^n$ is also\na binary vector. Then we obtain a closed form expression for\n$\\underline{h}_n(P_{X^nY^n}, \\epsilon)$ for sufficiently large, but nontrivial\nvalues of $\\epsilon$.\n", "versions": [{"version": "v1", "created": "Wed, 12 Apr 2017 03:28:37 GMT"}], "update_date": "2017-04-13", "authors_parsed": [["Asoodeh", "Shahab", ""], ["Diaz", "Mario", ""], ["Alajaji", "Fady", ""], ["Linder", "Tam\u00e1s", ""]]}, {"id": "1704.03631", "submitter": "Alexander Kolnogorov", "authors": "Alexander V. Kolnogorov", "title": "Batch Data Processing and Gaussian Two-Armed Bandit", "comments": "6 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the two-armed bandit problem as applied to data processing if\nthere are two alternative processing methods available with different a priori\nunknown efficiencies. One should determine the most effective method and\nprovide its predominant application. Gaussian two-armed bandit describes the\nbatch, and possibly parallel, processing when the same methods are applied to\nsufficiently large packets of data and accumulated incomes are used for the\ncontrol. If the number of packets is large enough then such control does not\ndeteriorate the control performance, i.e. does not increase the minimax risk.\nFor example, in case of 50 packets the minimax risk is about 2% larger than\nthat one corresponding to one-by-one optimal processing. However, this is\ncompletely true only for methods with close efficiencies because otherwise\nthere may be significant expected losses at the initial stage of control when\nboth actions are applied turn-by-turn. To avoid significant losses at the\ninitial stage of control one should take initial packets of data having smaller\nsizes.\n", "versions": [{"version": "v1", "created": "Wed, 12 Apr 2017 06:18:09 GMT"}], "update_date": "2017-04-13", "authors_parsed": [["Kolnogorov", "Alexander V.", ""]]}, {"id": "1704.03656", "submitter": "Hamzeh Torabi", "authors": "Esmaeil Bashkar and Hamzeh Torabi and Ali Dolati and Felix Belzunce", "title": "A new notion of majorization with applications to the comparison of\n  extreme order statistics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we use a new partial order, called the f-majorization order.\nThe new order includes as special cases the majorization , the reciprocal\nmajorization and the p-larger orders. We provide a comprehensive account of the\nmathematical properties of the f-majorization order and give applications of\nthis order in the context of stochastic comparison for extreme order statistics\nof independent samples following the Frechet distribution and scale model. We\ndiscuss stochastic comparisons of series systems with independent heterogeneous\nexponentiated scale components in terms of the usual stochastic order and the\nhazard rate order. We also derive new result on the usual stochastic order for\nthe largest order statistics of samples having exponentiated scale marginals\nand Archimedean copula structure.\n", "versions": [{"version": "v1", "created": "Wed, 12 Apr 2017 08:16:39 GMT"}], "update_date": "2017-04-13", "authors_parsed": [["Bashkar", "Esmaeil", ""], ["Torabi", "Hamzeh", ""], ["Dolati", "Ali", ""], ["Belzunce", "Felix", ""]]}, {"id": "1704.03754", "submitter": "Vasilis Syrgkanis", "authors": "Vasilis Syrgkanis", "title": "A Proof of Orthogonal Double Machine Learning with $Z$-Estimators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider two stage estimation with a non-parametric first stage and a\ngeneralized method of moments second stage, in a simpler setting than\n(Chernozhukov et al. 2016). We give an alternative proof of the theorem given\nin (Chernozhukov et al. 2016) that orthogonal second stage moments, sample\nsplitting and $n^{1/4}$-consistency of the first stage, imply\n$\\sqrt{n}$-consistency and asymptotic normality of second stage estimates. Our\nproof is for a variant of their estimator, which is based on the empirical\nversion of the moment condition (Z-estimator), rather than a minimization of a\nnorm of the empirical vector of moments (M-estimator). This note is meant\nprimarily for expository purposes, rather than as a new technical contribution.\n", "versions": [{"version": "v1", "created": "Wed, 12 Apr 2017 13:34:56 GMT"}, {"version": "v2", "created": "Fri, 14 Apr 2017 18:37:29 GMT"}], "update_date": "2017-04-18", "authors_parsed": [["Syrgkanis", "Vasilis", ""]]}, {"id": "1704.03866", "submitter": "Gautam Kamath", "authors": "Ilias Diakonikolas, Gautam Kamath, Daniel M. Kane, Jerry Li, Ankur\n  Moitra, Alistair Stewart", "title": "Robustly Learning a Gaussian: Getting Optimal Error, Efficiently", "comments": "To appear in SODA 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.IT cs.LG math.IT math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the fundamental problem of learning the parameters of a\nhigh-dimensional Gaussian in the presence of noise -- where an\n$\\varepsilon$-fraction of our samples were chosen by an adversary. We give\nrobust estimators that achieve estimation error $O(\\varepsilon)$ in the total\nvariation distance, which is optimal up to a universal constant that is\nindependent of the dimension.\n  In the case where just the mean is unknown, our robustness guarantee is\noptimal up to a factor of $\\sqrt{2}$ and the running time is polynomial in $d$\nand $1/\\epsilon$. When both the mean and covariance are unknown, the running\ntime is polynomial in $d$ and quasipolynomial in $1/\\varepsilon$. Moreover all\nof our algorithms require only a polynomial number of samples. Our work shows\nthat the same sorts of error guarantees that were established over fifty years\nago in the one-dimensional setting can also be achieved by efficient algorithms\nin high-dimensional settings.\n", "versions": [{"version": "v1", "created": "Wed, 12 Apr 2017 17:55:05 GMT"}, {"version": "v2", "created": "Sun, 5 Nov 2017 21:52:55 GMT"}], "update_date": "2017-11-07", "authors_parsed": [["Diakonikolas", "Ilias", ""], ["Kamath", "Gautam", ""], ["Kane", "Daniel M.", ""], ["Li", "Jerry", ""], ["Moitra", "Ankur", ""], ["Stewart", "Alistair", ""]]}, {"id": "1704.03995", "submitter": "Satoshi Kuriki", "authors": "Satoshi Kuriki, Henry P. Wynn", "title": "Optimal experimental design that minimizes the width of simultaneous\n  confidence bands", "comments": "34 pages, 2 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an optimal experimental design for a curvilinear regression model\nthat minimizes the band-width of simultaneous confidence bands. Simultaneous\nconfidence bands for curvilinear regression are constructed by evaluating the\nvolume of a tube about a curve that is defined as a trajectory of a regression\nbasis vector (Naiman, 1986). The proposed criterion is constructed based on the\nvolume of a tube, and the corresponding optimal design that minimizes the\nvolume of tube is referred to as the tube-volume optimal (TV-optimal) design.\nFor Fourier and weighted polynomial regressions, the problem is formalized as\none of minimization over the cone of Hankel positive definite matrices, and the\ncriterion to minimize is expressed as an elliptic integral. We show that the\nM\\\"obius group keeps our problem invariant, and hence, minimization can be\nconducted over cross-sections of orbits. We demonstrate that for the weighted\npolynomial regression and the Fourier regression with three bases, the\ntube-volume optimal design forms an orbit of the M\\\"obius group containing\nD-optimal designs as representative elements.\n", "versions": [{"version": "v1", "created": "Thu, 13 Apr 2017 05:16:33 GMT"}, {"version": "v2", "created": "Mon, 26 Mar 2018 14:16:47 GMT"}, {"version": "v3", "created": "Fri, 1 Mar 2019 04:13:12 GMT"}, {"version": "v4", "created": "Sat, 30 Mar 2019 07:17:28 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Kuriki", "Satoshi", ""], ["Wynn", "Henry P.", ""]]}, {"id": "1704.04040", "submitter": "Michael Hoffmann", "authors": "Michael Hoffmann, Mathias Vetter, Holger Dette", "title": "Nonparametric inference of gradual changes in the jump behaviour of\n  time-continuous processes", "comments": "53 pages, 8 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In applications the properties of a stochastic feature often change gradually\nrather than abruptly, that is: after a constant phase for some time they slowly\nstart to vary. In this paper we discuss statistical inference for the detection\nand the localisation of gradual changes in the jump characteristic of a\ndiscretely observed Ito semimartingale. We propose a new measure of time\nvariation for the jump behaviour of the process. The statistical uncertainty of\na corresponding estimate is analyzed by deriving new results on the weak\nconvergence of a sequential empirical tail integral process and a corresponding\nmultiplier bootstrap procedure.\n", "versions": [{"version": "v1", "created": "Thu, 13 Apr 2017 09:13:13 GMT"}], "update_date": "2017-04-14", "authors_parsed": [["Hoffmann", "Michael", ""], ["Vetter", "Mathias", ""], ["Dette", "Holger", ""]]}, {"id": "1704.04278", "submitter": "Joona Karjalainen", "authors": "Joona Karjalainen and Lasse Leskel\\\"a", "title": "Moment-based parameter estimation in binomial random intersection graph\n  models", "comments": "15 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Binomial random intersection graphs can be used as parsimonious statistical\nmodels of large and sparse networks, with one parameter for the average degree\nand another for transitivity, the tendency of neighbours of a node to be\nconnected. This paper discusses the estimation of these parameters from a\nsingle observed instance of the graph, using moment estimators based on\nobserved degrees and frequencies of 2-stars and triangles. The observed data\nset is assumed to be a subgraph induced by a set of $n_0$ nodes sampled from\nthe full set of $n$ nodes. We prove the consistency of the proposed estimators\nby showing that the relative estimation error is small with high probability\nfor $n_0 \\gg n^{2/3} \\gg 1$. As a byproduct, our analysis confirms that the\nempirical transitivity coefficient of the graph is with high probability close\nto the theoretical clustering coefficient of the model.\n", "versions": [{"version": "v1", "created": "Thu, 13 Apr 2017 20:42:52 GMT"}, {"version": "v2", "created": "Sun, 24 Jun 2018 19:37:37 GMT"}], "update_date": "2018-06-26", "authors_parsed": [["Karjalainen", "Joona", ""], ["Leskel\u00e4", "Lasse", ""]]}, {"id": "1704.04418", "submitter": "Oleg Lepski", "authors": "Oleg Lepski and Thomas Willer", "title": "Estimation in the convolution structure density model. Part I: oracle\n  inequalities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of nonparametric estimation under $\\bL_p$-loss, $p\\in\n[1,\\infty)$, in the framework of the convolution structure density model on\n$\\bR^d$. This observation scheme is a generalization of two classical\nstatistical models, namely density estimation under direct and indirect\nobservations. In Part I the original pointwise selection rule from a family of\n\"kernel-type\" estimators is proposed. For the selected estimator, we prove an\n$\\bL_p$-norm oracle inequality and several of its consequences. In Part II the\nproblem of adaptive minimax estimation under $\\bL_p$--loss over the scale of\nanisotropic Nikol'skii classes is addressed. We fully characterize the behavior\nof the minimax risk for different relationships between regularity parameters\nand norm indexes in the definitions of the functional class and of the risk. We\nprove that the selection rule proposed in Part I leads to the construction of\nan optimally or nearly optimally (up to logarithmic factor) adaptive estimator.\n", "versions": [{"version": "v1", "created": "Fri, 14 Apr 2017 13:32:01 GMT"}], "update_date": "2017-04-17", "authors_parsed": [["Lepski", "Oleg", ""], ["Willer", "Thomas", ""]]}, {"id": "1704.04420", "submitter": "Oleg Lepski", "authors": "Oleg Lepski and Thomas Willer", "title": "Estimation in the convolution structure density model. Part II:\n  adaptation over the scale of anisotropic classes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper continues the research started in \\cite{LW16}. In the framework of\nthe convolution structure density model on $\\bR^d$, we address the problem of\nadaptive minimax estimation with $\\bL_p$--loss over the scale of anisotropic\nNikol'skii classes. We fully characterize the behavior of the minimax risk for\ndifferent relationships between regularity parameters and norm indexes in the\ndefinitions of the functional class and of the risk. In particular, we show\nthat the boundedness of the function to be estimated leads to an essential\nimprovement of the asymptotic of the minimax risk. We prove that the selection\nrule proposed in Part I leads to the construction of an optimally or nearly\noptimally (up to logarithmic factor) adaptive estimator.\n", "versions": [{"version": "v1", "created": "Fri, 14 Apr 2017 13:37:33 GMT"}], "update_date": "2017-04-17", "authors_parsed": [["Lepski", "Oleg", ""], ["Willer", "Thomas", ""]]}, {"id": "1704.04614", "submitter": "Holger Dette", "authors": "Holger Dette, Josua G\\\"osmann", "title": "Relevant change points in high dimensional time series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the problem of detecting relevant change points in\nthe mean vector, say $\\mu_t =(\\mu_{1,t},\\ldots ,\\mu_{d,t})^T$ of a high\ndimensional time series $(Z_t)_{t\\in \\mathbb{Z}}$.\n  While the recent literature on testing for change points in this context\nconsiders hypotheses for the equality of the means $\\mu_h^{(1)}$ and\n$\\mu_h^{(2)}$ before and after the change points in the different components,\nwe are interested in a null hypothesis of the form $$ H_0: |\\mu^{(1)}_{h} -\n\\mu^{(2)}_{h} | \\leq \\Delta_h ~~~\\mbox{ for all } ~~h=1,\\ldots ,d $$ where\n$\\Delta_1, \\ldots , \\Delta_d$ are given thresholds for which a smaller\ndifference of the means in the $h$-th component is considered to be\nnon-relevant.\n  We propose a new test for this problem based on the maximum of squared and\nintegrated CUSUM statistics and investigate its properties as the sample size\n$n$ and the dimension $d$ both converge to infinity. In particular, using\nGaussian approximations for the maximum of a large number of dependent random\nvariables, we show that on certain points of the boundary of the null\nhypothesis a standardised version of the maximum converges weakly to a Gumbel\ndistribution.\n", "versions": [{"version": "v1", "created": "Sat, 15 Apr 2017 09:51:45 GMT"}, {"version": "v2", "created": "Fri, 3 Nov 2017 19:57:24 GMT"}, {"version": "v3", "created": "Mon, 1 Feb 2021 12:45:52 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Dette", "Holger", ""], ["G\u00f6smann", "Josua", ""]]}, {"id": "1704.04707", "submitter": "James P. Crutchfield", "authors": "S. E. Marzen and J. P. Crutchfield", "title": "Structure and Randomness of Continuous-Time Discrete-Event Processes", "comments": "10 pages, 2 figures;\n  http://csc.ucdavis.edu/~cmg/compmech/pubs/ctdep.htm", "journal-ref": null, "doi": "10.1007/s10955-017-1859-y", "report-no": null, "categories": "cond-mat.stat-mech cs.IT math.IT math.ST nlin.CD stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Loosely speaking, the Shannon entropy rate is used to gauge a stochastic\nprocess' intrinsic randomness; the statistical complexity gives the cost of\npredicting the process. We calculate, for the first time, the entropy rate and\nstatistical complexity of stochastic processes generated by finite unifilar\nhidden semi-Markov models---memoryful, state-dependent versions of renewal\nprocesses. Calculating these quantities requires introducing novel mathematical\nobjects ({\\epsilon}-machines of hidden semi-Markov processes) and new\ninformation-theoretic methods to stochastic processes.\n", "versions": [{"version": "v1", "created": "Sun, 16 Apr 2017 01:35:17 GMT"}], "update_date": "2017-09-13", "authors_parsed": [["Marzen", "S. E.", ""], ["Crutchfield", "J. P.", ""]]}, {"id": "1704.04752", "submitter": "Arnak Dalalyan S.", "authors": "Arnak S. Dalalyan", "title": "Further and stronger analogy between sampling and optimization: Langevin\n  Monte Carlo and gradient descent", "comments": "Updated version of the COLT 2017 paper, some typos are corrected and\n  Theorem 3 slightly improved", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we revisit the recently established theoretical guarantees for\nthe convergence of the Langevin Monte Carlo algorithm of sampling from a smooth\nand (strongly) log-concave density. We improve the existing results when the\nconvergence is measured in the Wasserstein distance and provide further\ninsights on the very tight relations between, on the one hand, the Langevin\nMonte Carlo for sampling and, on the other hand, the gradient descent for\noptimization. Finally, we also establish guarantees for the convergence of a\nversion of the Langevin Monte Carlo algorithm that is based on noisy\nevaluations of the gradient.\n", "versions": [{"version": "v1", "created": "Sun, 16 Apr 2017 11:23:28 GMT"}, {"version": "v2", "created": "Fri, 28 Jul 2017 15:08:57 GMT"}], "update_date": "2017-07-31", "authors_parsed": [["Dalalyan", "Arnak S.", ""]]}, {"id": "1704.04806", "submitter": "Zhipeng Lou", "authors": "Zhipeng Lou and Wei Biao Wu", "title": "Simultaneous Inference for High Dimensional Mean Vectors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $X_1, \\ldots, X_n\\in\\mathbb{R}^p$ be i.i.d. random vectors. We aim to\nperform simultaneous inference for the mean vector $\\mathbb{E} (X_i)$ with\nfinite polynomial moments and an ultra high dimension. Our approach is based on\nthe truncated sample mean vector. A Gaussian approximation result is derived\nfor the latter under the very mild finite polynomial ($(2+\\theta)$-th) moment\ncondition and the dimension $p$ can be allowed to grow exponentially with the\nsample size $n$. Based on this result, we propose an innovative resampling\nmethod to construct simultaneous confidence intervals for mean vectors.\n", "versions": [{"version": "v1", "created": "Sun, 16 Apr 2017 18:21:18 GMT"}], "update_date": "2017-04-18", "authors_parsed": [["Lou", "Zhipeng", ""], ["Wu", "Wei Biao", ""]]}, {"id": "1704.04926", "submitter": "Fabio Rapallo", "authors": "Cristiano Bocci and Fabio Rapallo", "title": "Exact tests to compare contingency tables under quasi-independence and\n  quasi-symmetry", "comments": "14 pages, 4 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.CO stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we define log-linear models to compare several square\ncontingency tables under the quasi-independence or the quasi-symmetry model,\nand the relevant Markov bases are theoretically characterized. Through Markov\nbases, an exact test to evaluate if two or more tables fit a common model is\nintroduced. Two real-data examples illustrate the use of these models in\ndifferent fields of applications.\n", "versions": [{"version": "v1", "created": "Mon, 17 Apr 2017 10:49:12 GMT"}], "update_date": "2017-04-18", "authors_parsed": [["Bocci", "Cristiano", ""], ["Rapallo", "Fabio", ""]]}, {"id": "1704.05050", "submitter": "Huiming Zhang", "authors": "Huiming Zhang, Kai Tan, Bo Li", "title": "The COM-negative binomial distribution: modeling overdispersion and\n  ultrahigh zero-inflated count data", "comments": "22 pages,3 figures, Accepted for publication in Frontiers of\n  Mathematics in China", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we focus on the COM-type negative binomial distribution with\nthree parameters, which belongs to COM-type $(a,b,0)$ class distributions and\nfamily of equilibrium distributions of arbitrary birth-death process. Besides,\nwe show abundant distributional properties such as overdispersion and\nunderdispersion, log-concavity, log-convexity (infinite divisibility), pseudo\ncompound Poisson, stochastic ordering and asymptotic approximation. Some\ncharacterizations including sum of equicorrelated geometrically distributed\nrandom variables, conditional distribution, limit distribution of COM-negative\nhypergeometric distribution, and Stein's identity are given for theoretical\nproperties. COM-negative binomial distribution was applied to overdispersion\nand ultrahigh zero-inflated data sets. With the aid of ratio regression, we\nemploy maximum likelihood method to estimate the parameters and the\ngoodness-of-fit are evaluated by the discrete Kolmogorov-Smirnov test.\n", "versions": [{"version": "v1", "created": "Sat, 15 Apr 2017 16:45:47 GMT"}, {"version": "v2", "created": "Tue, 10 Jul 2018 14:19:51 GMT"}], "update_date": "2018-07-11", "authors_parsed": [["Zhang", "Huiming", ""], ["Tan", "Kai", ""], ["Li", "Bo", ""]]}, {"id": "1704.05098", "submitter": "Yun Yang", "authors": "Yun Yang", "title": "Statistical inference for high dimensional regression via Constrained\n  Lasso", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.CO stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a new method for estimation and constructing\nconfidence intervals for low-dimensional components in a high-dimensional\nmodel. The proposed estimator, called Constrained Lasso (CLasso) estimator, is\nobtained by simultaneously solving two estimating equations---one imposing a\nzero-bias constraint for the low-dimensional parameter and the other forming an\n$\\ell_1$-penalized procedure for the high-dimensional nuisance parameter. By\ncarefully choosing the zero-bias constraint, the resulting estimator of the low\ndimensional parameter is shown to admit an asymptotically normal limit\nattaining the Cram\\'{e}r-Rao lower bound in a semiparametric sense. We propose\na tuning-free iterative algorithm for implementing the CLasso. We show that\nwhen the algorithm is initialized at the Lasso estimator, the de-sparsified\nestimator proposed in van de Geer et al. [\\emph{Ann. Statist.} {\\bf 42} (2014)\n1166--1202] is asymptotically equivalent to the first iterate of the algorithm.\nWe analyse the asymptotic properties of the CLasso estimator and show the\nglobally linear convergence of the algorithm. We also demonstrate encouraging\nempirical performance of the CLasso through numerical studies.\n", "versions": [{"version": "v1", "created": "Mon, 17 Apr 2017 19:21:33 GMT"}], "update_date": "2017-04-19", "authors_parsed": [["Yang", "Yun", ""]]}, {"id": "1704.05120", "submitter": "Jacob Steinhardt", "authors": "Jacob Steinhardt", "title": "Does robustness imply tractability? A lower bound for planted clique in\n  the semi-random model", "comments": "Improved lower bound to give recovery probability tending to zero.\n  Factored out and highlighted perturbed Bernoulli argument", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.IT cs.LG math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a robust analog of the planted clique problem. In this analog, a\nset $S$ of vertices is chosen and all edges in $S$ are included; then, edges\nbetween $S$ and the rest of the graph are included with probability\n$\\frac{1}{2}$, while edges not touching $S$ are allowed to vary arbitrarily.\nFor this semi-random model, we show that the information-theoretic threshold\nfor recovery is $\\tilde{\\Theta}(\\sqrt{n})$, in sharp contrast to the classical\ninformation-theoretic threshold of $\\Theta(\\log(n))$. This matches the\nconjectured computational threshold for the classical planted clique problem,\nand thus raises the intriguing possibility that, once we require robustness,\nthere is no computational-statistical gap for planted clique. Our lower bound\ninvolves establishing a result regarding the KL divergence of a family of\nperturbed Bernoulli distributions, which may be of independent interest.\n", "versions": [{"version": "v1", "created": "Mon, 17 Apr 2017 20:53:18 GMT"}, {"version": "v2", "created": "Tue, 4 Sep 2018 21:21:55 GMT"}], "update_date": "2018-09-06", "authors_parsed": [["Steinhardt", "Jacob", ""]]}, {"id": "1704.05335", "submitter": "Charles-Alban Deledalle", "authors": "Charles-Alban Deledalle (IMB), Lo\\\"ic Denis (LHC), Sonia Tabti (GREYC,\n  LTCI), Florence Tupin (LTCI)", "title": "MuLoG, or How to apply Gaussian denoisers to multi-channel SAR speckle\n  reduction?", "comments": null, "journal-ref": null, "doi": "10.1109/TIP.2017.2713946", "report-no": null, "categories": "math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speckle reduction is a longstanding topic in synthetic aperture radar (SAR)\nimaging. Since most current and planned SAR imaging satellites operate in\npolarimetric, interferometric or tomographic modes, SAR images are\nmulti-channel and speckle reduction techniques must jointly process all\nchannels to recover polarimetric and interferometric information. The\ndistinctive nature of SAR signal (complex-valued, corrupted by multiplicative\nfluctuations) calls for the development of specialized methods for speckle\nreduction. Image denoising is a very active topic in image processing with a\nwide variety of approaches and many denoising algorithms available, almost\nalways designed for additive Gaussian noise suppression. This paper proposes a\ngeneral scheme, called MuLoG (MUlti-channel LOgarithm with Gaussian denoising),\nto include such Gaussian denoisers within a multi-channel SAR speckle reduction\ntechnique. A new family of speckle reduction algorithms can thus be obtained,\nbenefiting from the ongoing progress in Gaussian denoising, and offering\nseveral speckle reduction results often displaying method-specific artifacts\nthat can be dismissed by comparison between results.\n", "versions": [{"version": "v1", "created": "Tue, 18 Apr 2017 13:32:37 GMT"}], "update_date": "2017-08-02", "authors_parsed": [["Deledalle", "Charles-Alban", "", "IMB"], ["Denis", "Lo\u00efc", "", "LHC"], ["Tabti", "Sonia", "", "GREYC,\n  LTCI"], ["Tupin", "Florence", "", "LTCI"]]}, {"id": "1704.05466", "submitter": "Pauli Pihajoki Dr", "authors": "Pauli Pihajoki", "title": "A geometric approach to non-linear correlations with intrinsic scatter", "comments": "19 pages, 5 figures. Revision accepted to MNRAS", "journal-ref": null, "doi": "10.1093/mnras/stx2179", "report-no": null, "categories": "astro-ph.IM astro-ph.HE math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new mathematical model for $n-k$-dimensional non-linear\ncorrelations with intrinsic scatter in $n$-dimensional data. The model is based\non Riemannian geometry, and is naturally symmetric with respect to the measured\nvariables and invariant under coordinate transformations. We combine the model\nwith a Bayesian approach for estimating the parameters of the correlation\nrelation and the intrinsic scatter. A side benefit of the approach is that\ncensored and truncated datasets and independent, arbitrary measurement errors\ncan be incorporated. We also derive analytic likelihoods for the typical\nastrophysical use case of linear relations in $n$-dimensional Euclidean space.\nWe pay particular attention to the case of linear regression in two dimensions,\nand compare our results to existing methods. Finally, we apply our methodology\nto the well-known $M_\\text{BH}$-$\\sigma$ correlation between the mass of a\nsupermassive black hole in the centre of a galactic bulge and the corresponding\nbulge velocity dispersion. The main result of our analysis is that the most\nlikely slope of this correlation is $\\sim 6$ for the datasets used, rather than\nthe values in the range $\\sim 4$-$5$ typically quoted in the literature for\nthese data.\n", "versions": [{"version": "v1", "created": "Tue, 18 Apr 2017 18:00:03 GMT"}, {"version": "v2", "created": "Wed, 23 Aug 2017 11:11:52 GMT"}], "update_date": "2017-11-08", "authors_parsed": [["Pihajoki", "Pauli", ""]]}, {"id": "1704.05630", "submitter": "Javier \\'Alvarez-Li\\'ebana", "authors": "M. Dolores Ruiz-Medina and J. \\'Alvarez-Li\\'ebana", "title": "Classical and bayesian componentwise predictors for non-compact\n  correlated ARH(1) processes", "comments": "33 pages: 6 figures are included. In press, accepted manuscript", "journal-ref": "REVSTAT 2017", "doi": null, "report-no": null, "categories": "stat.AP math.ST stat.OT stat.TH", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  A special class of standard Gaussian Autoregressive Hilbertian processes of\norder one (Gaussian ARH(1) processes), with bounded linear autocorrelation\noperator, which does not satisfy the usual Hilbert-Schmidt assumption, is\nconsidered. To compensate the slow decay of the diagonal coefficients of the\nautocorrelation operator, a faster decay velocity of the eigenvalues of the\ntrace autocovariance operator of the innovation process is assumed. As usual,\nthe eigenvectors of the autocovariance operator of the ARH(1) process are\nconsidered for projection, since, here, they are assumed to be known. Diagonal\ncomponentwise classical and bayesian estimation of the autocorrelation operator\nis studied for prediction. The asymptotic efficiency and equivalence of both\nestimators is proved, as well as of their associated componentwise ARH(1)\nplugin predictors. A simulation study is undertaken to illustrate the\ntheoretical results derived.\n", "versions": [{"version": "v1", "created": "Wed, 19 Apr 2017 06:56:54 GMT"}, {"version": "v2", "created": "Tue, 4 Sep 2018 10:59:40 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Ruiz-Medina", "M. Dolores", ""], ["\u00c1lvarez-Li\u00e9bana", "J.", ""]]}, {"id": "1704.05656", "submitter": "Claudia Kluppelberg", "authors": "Sven Buhl and Claudia Kl\\\"uppelberg", "title": "Generalised least squares estimation of regularly varying space-time\n  processes based on flexible observation schemes", "comments": "37 pages, 18 Figures and 3 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regularly varying stochastic processes model extreme dependence between\nprocess values at different locations and/or time points. For such processes we\npropose a two-step parameter estimation of the extremogram, when some part of\nthe domain of interest is fixed and another increasing. We provide conditions\nfor consistency and asymptotic normality of the empirical extremogram centred\nby a pre-asymptotic version for such observation schemes. For max-stable\nprocesses with Fr{\\'e}chet margins we provide conditions, such that the\nempirical extremogram (or a bias-corrected version) centred by its true version\nis asymptotically normal. In a second step, for a parametric extremogram model,\nwe fit the parameters by generalised least squares estimation and prove\nconsistency and asymptotic normality of the estimates. We propose subsampling\nprocedures to obtain asymptotically correct confidence intervals. Finally, we\napply our results to a variety of Brown-Resnick processes. A simulation study\nshows that the procedure works well also for moderate sample sizes.\n", "versions": [{"version": "v1", "created": "Wed, 19 Apr 2017 08:54:53 GMT"}, {"version": "v2", "created": "Mon, 27 Aug 2018 08:14:42 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Buhl", "Sven", ""], ["Kl\u00fcppelberg", "Claudia", ""]]}, {"id": "1704.05719", "submitter": "S\\'andor Baran", "authors": "S\\'andor Baran, Csilla Sz\\'ak-Kocsis and Milan Stehl\\'ik", "title": "D-optimal designs for complex Ornstein-Uhlenbeck processes", "comments": "20 pages, 7 figures", "journal-ref": "Journal of Statistical Planning and Inference 197 (2018), 93-106", "doi": "10.1016/j.jspi.2017.12.006", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complex Ornstein-Uhlenbeck (OU) processes have various applications in\nstatistical modelling. They play role e.g. in the description of the motion of\na charged test particle in a constant magnetic field or in the study of\nrotating waves in time-dependent reaction diffusion systems, whereas Kolmogorov\nused such a process to model the so-called Chandler wobble, small deviation in\nthe Earth's axis of rotation. In these applications parameter estimation and\nmodel fitting is based on discrete observations of the underlying stochastic\nprocess, however, the accuracy of the results strongly depend on the\nobservation points.\n  This paper studies the properties of D-optimal designs for estimating the\nparameters of a complex OU process with a trend. We show that in contrast with\nthe case of the classical real OU process, a D-optimal design exists not only\nfor the trend parameter, but also for joint estimation of the covariance\nparameters, moreover, these optimal designs are equidistant.\n", "versions": [{"version": "v1", "created": "Wed, 19 Apr 2017 13:11:13 GMT"}], "update_date": "2018-08-13", "authors_parsed": [["Baran", "S\u00e1ndor", ""], ["Sz\u00e1k-Kocsis", "Csilla", ""], ["Stehl\u00edk", "Milan", ""]]}, {"id": "1704.05927", "submitter": "Vincenzo Carotenuto", "authors": "V. Carotenuto, and A. De Maio, and D. Orlando, and P. Stoica", "title": "Model Order Selection Rules For Covariance Structure Classification", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2017.2728523", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The adaptive classification of the interference covariance matrix structure\nfor radar signal processing applications is addressed in this paper. This\nrepresents a key issue because many detection architectures are synthesized\nassuming a specific covariance structure which may not necessarily coincide\nwith the actual one due to the joint action of the system and environment\nuncertainties. The considered classification problem is cast in terms of a\nmultiple hypotheses test with some nested alternatives and the theory of Model\nOrder Selection (MOS) is exploited to devise suitable decision rules. Several\nMOS techniques, such as the Akaike, Takeuchi, and Bayesian information criteria\nare adopted and the corresponding merits and drawbacks are discussed. At the\nanalysis stage, illustrating examples for the probability of correct model\nselection are presented showing the effectiveness of the proposed rules.\n", "versions": [{"version": "v1", "created": "Wed, 19 Apr 2017 20:35:32 GMT"}], "update_date": "2017-10-11", "authors_parsed": [["Carotenuto", "V.", ""], ["De Maio", "A.", ""], ["Orlando", "D.", ""], ["Stoica", "P.", ""]]}, {"id": "1704.05991", "submitter": "Shirshendu Chatterjee", "authors": "Shirshendu Chatterjee and Ofer Zeitouni", "title": "Thresholds For Detecting An Anomalous Path From Noisy Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the \"searching for a trail in a maze\" composite hypothesis\ntesting problem, in which one attempts to detect an anomalous directed path in\na lattice 2D box of side n based on observations on the nodes of the box. Under\nthe signal hypothesis, one observes independent Gaussian variables of unit\nvariance at all nodes, with zero, mean off the anomalous path and mean \\mu_n on\nit. Under the null hypothesis, one observes i.i.d. standard Gaussians on all\nnodes. Arias-Castro et al. (2008) showed that if the unknown directed path\nunder the signal hypothesis has known the initial location, then detection is\npossible (in the minimax sense) if \\mu_n >> 1/\\sqrt log n, while it is not\npossible if \\mu_n << 1/ log n\\sqrt log log n. In this paper, we show that this\nresult continues to hold even when the initial location of the unknown path is\nnot known. As is the case with Arias-Castro et al. (2008), the upper bound here\nalso applies when the path is undirected. The improvement is achieved by\nreplacing the linear detection statistic used in Arias-Castro et al. (2008)\nwith a polynomial statistic, which is obtained by employing a multi-scale\nanalysis on a quadratic statistic to bootstrap its performance. Our analysis is\nmotivated by ideas developed in the context of the analysis of random polymers\nin Lacoin (2010).\n", "versions": [{"version": "v1", "created": "Thu, 20 Apr 2017 03:13:54 GMT"}], "update_date": "2017-04-21", "authors_parsed": [["Chatterjee", "Shirshendu", ""], ["Zeitouni", "Ofer", ""]]}, {"id": "1704.06150", "submitter": "Antoine Godichon-Baggioni", "authors": "Antoine Godichon-Baggioni, Cathy Maugis-Rabusseau and Andrea Rau", "title": "Clustering transformed compositional data using K-means, with\n  applications in gene expression and bicycle sharing system data", "comments": null, "journal-ref": null, "doi": "10.1080/02664763.2018.1454894", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although there is no shortage of clustering algorithms proposed in the\nliterature, the question of the most relevant strategy for clustering\ncompositional data (i.e., data made up of profiles, whose rows belong to the\nsimplex) remains largely unexplored in cases where the observed value of an\nobservation is equal or close to zero for one or more samples. This work is\nmotivated by the analysis of two sets of compositional data, both focused on\nthe categorization of profiles but arising from considerably different\napplications: (1) identifying groups of co-expressed genes from high-throughput\nRNA sequencing data, in which a given gene may be completely silent in one or\nmore experimental conditions; and (2) finding patterns in the usage of stations\nover the course of one week in the Velib' bicycle sharing system in Paris,\nFrance. For both of these applications, we focus on the use of appropriately\nchosen data transformations, including the Centered Log Ratio and a novel\nextension we propose called the Log Centered Log Ratio, in conjunction with the\nK-means algorithm. We use a nonasymptotic penalized criterion, whose penalty is\ncalibrated with the slope heuristics, to select the number of clusters present\nin the data. Finally, we illustrate the performance of this clustering\nstrategy, which is implemented in the Bioconductor package coseq, on both the\ngene expression and bicycle sharing system data.\n", "versions": [{"version": "v1", "created": "Thu, 20 Apr 2017 14:03:52 GMT"}], "update_date": "2018-05-17", "authors_parsed": [["Godichon-Baggioni", "Antoine", ""], ["Maugis-Rabusseau", "Cathy", ""], ["Rau", "Andrea", ""]]}, {"id": "1704.06160", "submitter": "Davy Paindaveine", "authors": "Davy Paindaveine, Germain Van Bever", "title": "Halfspace depths for scatter, concentration and shape matrices", "comments": "63 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose halfspace depth concepts for scatter, concentration and shape\nmatrices. For scatter matrices, our concept is similar to those from Chen, Gao\nand Ren (2017) and Zhang (2002). Rather than focusing, as in these earlier\nworks, on deepest scatter matrices, we thoroughly investigate the properties of\nthe proposed depth and of the corresponding depth regions. We do so under\nminimal assumptions and, in particular, we do not restrict to elliptical\ndistributions nor to absolutely continuous distributions. Interestingly, fully\nunderstanding scatter halfspace depth requires considering different\ngeometries/topologies on the space of scatter matrices. We also discuss, in the\nspirit of Zuo and Serfling (2000), the structural properties a scatter depth\nshould satisfy, and investigate whether or not these are met by scatter\nhalfspace depth. Companion concepts of depth for concentration matrices and\nshape matrices are also proposed and studied. We show the practical relevance\nof the depth concepts considered in a real-data example from finance.\n", "versions": [{"version": "v1", "created": "Thu, 20 Apr 2017 14:17:25 GMT"}, {"version": "v2", "created": "Fri, 25 Aug 2017 21:03:50 GMT"}, {"version": "v3", "created": "Sun, 22 Oct 2017 20:49:47 GMT"}, {"version": "v4", "created": "Thu, 26 Oct 2017 07:07:31 GMT"}], "update_date": "2017-10-27", "authors_parsed": [["Paindaveine", "Davy", ""], ["Van Bever", "Germain", ""]]}, {"id": "1704.06230", "submitter": "Ansgar Steland", "authors": "Ansgar Steland and Rainer von Sachs", "title": "Large-sample approximations for variance-covariance matrices of\n  high-dimensional time series", "comments": null, "journal-ref": "Bernoulli, 23, Number 4A (2017), 2299-2329", "doi": "10.3150/16-BEJ811", "report-no": null, "categories": "math.PR math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributional approximations of (bi--) linear functions of sample\nvariance-covariance matrices play a critical role to analyze vector time\nseries, as they are needed for various purposes, especially to draw inference\non the dependence structure in terms of second moments and to analyze\nprojections onto lower dimensional spaces as those generated by principal\ncomponents. This particularly applies to the high-dimensional case, where the\ndimension $d$ is allowed to grow with the sample size $n$ and may even be\nlarger than $n$. We establish large-sample approximations for such bilinear\nforms related to the sample variance-covariance matrix of a high-dimensional\nvector time series in terms of strong approximations by Brownian motions. The\nresults cover weakly dependent as well as many long-range dependent linear\nprocesses and are valid for uniformly $ \\ell_1 $-bounded projection vectors,\nwhich arise, either naturally or by construction, in many statistical problems\nextensively studied for high-dimensional series. Among those problems are\nsparse financial portfolio selection, sparse principal components, the LASSO,\nshrinkage estimation and change-point analysis for high--dimensional time\nseries, which matter for the analysis of big data and are discussed in greater\ndetail.\n", "versions": [{"version": "v1", "created": "Thu, 20 Apr 2017 16:52:23 GMT"}], "update_date": "2018-03-20", "authors_parsed": [["Steland", "Ansgar", ""], ["von Sachs", "Rainer", ""]]}, {"id": "1704.06329", "submitter": "Hamzeh Torabi", "authors": "Esmaeil Bashkar and Hamzeh Torabi and Majid Asadi", "title": "Stochastic comparisons of series and parallel systems with heterogeneous\n  components", "comments": "arXiv admin note: text overlap with arXiv:1704.03656", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we discuss stochastic comparisons of parallel systems with\nindependent heterogeneous exponentiated Nadarajah-Haghighi (ENH) components in\nterms of the usual stochastic order, dispersive order, convex transform order\nand the likelihood ratio order. In the presence of the Archimedean copula, we\nstudy stochastic comparison of series dependent systems in terms of the usual\nstochastic order.\n", "versions": [{"version": "v1", "created": "Thu, 20 Apr 2017 20:42:25 GMT"}], "update_date": "2017-04-24", "authors_parsed": [["Bashkar", "Esmaeil", ""], ["Torabi", "Hamzeh", ""], ["Asadi", "Majid", ""]]}, {"id": "1704.06398", "submitter": "Iain Johnstone", "authors": "Iain M. Johnstone", "title": "Tail sums of Wishart and GUE eigenvalues beyond the bulk edge", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider the classical Gaussian unitary ensemble of size $N$ and the real\nWishart ensemble $W_N(n,I)$. In the limits as $N \\to \\infty$ and $N/n \\to\n\\gamma > 0$, the expected number of eigenvalues that exit the upper bulk edge\nis less than one, 0.031 and 0.170 respectively, the latter number being\nindependent of $\\gamma$. These statements are consequences of quantitative\nbounds on tail sums of eigenvalues outside the bulk which are established here\nfor applications in high dimensional covariance matrix estimation.\n", "versions": [{"version": "v1", "created": "Fri, 21 Apr 2017 04:52:57 GMT"}, {"version": "v2", "created": "Mon, 24 Jul 2017 21:21:14 GMT"}], "update_date": "2017-07-26", "authors_parsed": [["Johnstone", "Iain M.", ""]]}, {"id": "1704.06428", "submitter": "Guy Martial", "authors": "Guy Martial Nkiet (URMI)", "title": "Asymptotic theory of multiple-set linear canonical analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with asymptotics for multiple-set linear canonical analysis\n(MSLCA). A definition of this analysis, that adapts the classical one to the\ncontext of Euclidean random variables, is given and properties of the related\ncanonical coefficients are derived. Then, estimators of the MSLCA's elements,\nbased on empirical covariance operators, are proposed and asymptotics for these\nestimators are obtained. More precisely, we prove their consistency and we\nobtain asymptotic normality for the estimator of the operator that gives MSLCA,\nand also for the estimator of the vector of canonical coefficients. These\nresults are then used to obtain a test for mutual non-correlation between the\ninvolved Euclidean random variables.\n", "versions": [{"version": "v1", "created": "Fri, 21 Apr 2017 07:46:27 GMT"}], "update_date": "2017-04-24", "authors_parsed": [["Nkiet", "Guy Martial", "", "URMI"]]}, {"id": "1704.06431", "submitter": "Antoine Chambaz", "authors": "Alexander Luedtke (FHCRC), Antoine Chambaz (MODAL'X)", "title": "Faster Rates for Policy Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article improves the existing proven rates of regret decay in optimal\npolicy estimation. We give a margin-free result showing that the regret decay\nfor estimating a within-class optimal policy is second-order for empirical risk\nminimizers over Donsker classes, with regret decaying at a faster rate than the\nstandard error of an efficient estimator of the value of an optimal policy. We\nalso give a result from the classification literature that shows that faster\nregret decay is possible via plug-in estimation provided a margin condition\nholds. Four examples are considered. In these examples, the regret is expressed\nin terms of either the mean value or the median value; the number of possible\nactions is either two or finitely many; and the sampling scheme is either\nindependent and identically distributed or sequential, where the latter\nrepresents a contextual bandit sampling scheme.\n", "versions": [{"version": "v1", "created": "Fri, 21 Apr 2017 07:59:24 GMT"}], "update_date": "2017-04-24", "authors_parsed": [["Luedtke", "Alexander", "", "FHCRC"], ["Chambaz", "Antoine", "", "MODAL'X"]]}, {"id": "1704.06521", "submitter": "Dimbihery Rabenoro", "authors": "Dimbihery Rabenoro", "title": "Functional limit laws for the increments of L\\'evy processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a functional form of the Erd\\\"os-Renyi law of large numbers for\nLevy processes.\n", "versions": [{"version": "v1", "created": "Fri, 21 Apr 2017 13:07:36 GMT"}, {"version": "v2", "created": "Tue, 17 Oct 2017 14:32:26 GMT"}, {"version": "v3", "created": "Tue, 14 Aug 2018 17:35:43 GMT"}, {"version": "v4", "created": "Fri, 30 Nov 2018 18:50:23 GMT"}, {"version": "v5", "created": "Mon, 2 Nov 2020 23:51:10 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Rabenoro", "Dimbihery", ""]]}, {"id": "1704.06537", "submitter": "Markus Bibinger", "authors": "Markus Bibinger, Christopher Neely and Lars Winkelmann", "title": "Estimation of the discontinuous leverage effect: Evidence from the\n  NASDAQ order book", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An extensive empirical literature documents a generally negative correlation,\nnamed the \"leverage effect,\" between asset returns and changes of volatility.\nIt is more challenging to establish such a return-volatility relationship for\njumps in high-frequency data. We propose new nonparametric methods to assess\nand test for a discontinuous leverage effect --- i.e. a relation between\ncontemporaneous jumps in prices and volatility. The methods are robust to\nmarket microstructure noise and build on a newly developed price-jump\nlocalization and estimation procedure. Our empirical investigation of six years\nof transaction data from 320 NASDAQ firms displays no unconditional negative\ncorrelation between price and volatility cojumps. We show, however, that there\nis a strong relation between price-volatility cojumps if one conditions on the\nsign of price jumps and whether the price jumps are market-wide or\nidiosyncratic. Firms' volatility levels strongly explain the cross-section of\ndiscontinuous leverage while debt-to-equity ratios have no significant\nexplanatory power.\n", "versions": [{"version": "v1", "created": "Fri, 21 Apr 2017 13:42:57 GMT"}, {"version": "v2", "created": "Fri, 8 Dec 2017 18:23:16 GMT"}], "update_date": "2017-12-11", "authors_parsed": [["Bibinger", "Markus", ""], ["Neely", "Christopher", ""], ["Winkelmann", "Lars", ""]]}, {"id": "1704.06629", "submitter": "Vincent Brault", "authors": "Vincent Brault, Christine Keribin and Mahendra Mariadassou", "title": "Consistency and Asymptotic Normality of Latent Block Model Estimators", "comments": "36 pages, 2 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Latent Block Model (LBM) is a model-based method to cluster\nsimultaneously the $d$ columns and $n$ rows of a data matrix. Parameter\nestimation in LBM is a difficult and multifaceted problem. Although various\nestimation strategies have been proposed and are now well understood\nempirically, theoretical guarantees about their asymptotic behavior is rather\nsparse and most results are limited to the binary setting. We prove here\ntheoretical guarantees in the valued settings. We show that under some mild\nconditions on the parameter space, and in an asymptotic regime where\n$\\log(d)/n$ and $\\log(n)/d$ tend to $0$ when $n$ and $d$ tend to infinity, (1)\nthe maximum-likelihood estimate of the complete model (with known labels) is\nconsistent and (2) the log-likelihood ratios are equivalent under the complete\nand observed (with unknown labels) models. This equivalence allows us to\ntransfer the asymptotic consistency, and under mild conditions, asymptotic\nnormality, to the maximum likelihood estimate under the observed model.\nMoreover, the variational estimator is also consistent and, under the same\nconditions, asymptotically normal.\n", "versions": [{"version": "v1", "created": "Fri, 21 Apr 2017 16:45:23 GMT"}, {"version": "v2", "created": "Fri, 5 Jul 2019 09:51:57 GMT"}, {"version": "v3", "created": "Tue, 5 Nov 2019 17:17:24 GMT"}, {"version": "v4", "created": "Tue, 25 Feb 2020 10:50:14 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Brault", "Vincent", ""], ["Keribin", "Christine", ""], ["Mariadassou", "Mahendra", ""]]}, {"id": "1704.06666", "submitter": "Hamzeh Torabi", "authors": "H. Nadeb and H. Torabi and G.G. Hamedani", "title": "Goodness of fit test under progressive Type-I interval censoring", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose several statistics for testing uniformity under\nprogressive Type-I interval censoring. We obtain the critical points of these\nstatistics and study the power of the proposed tests against a representative\nset of alternatives via simulation. Finally, we generalize our methods for\ncontinuous and completely specified distributions.\n", "versions": [{"version": "v1", "created": "Fri, 21 Apr 2017 18:02:11 GMT"}], "update_date": "2017-04-25", "authors_parsed": [["Nadeb", "H.", ""], ["Torabi", "H.", ""], ["Hamedani", "G. G.", ""]]}, {"id": "1704.06742", "submitter": "Chao Gao", "authors": "Chao Gao and John Lafferty", "title": "Testing Network Structure Using Relations Between Small Subgraph\n  Probabilities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.SI math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of testing for structure in networks using relations\nbetween the observed frequencies of small subgraphs. We consider the statistics\n\\begin{align*} T_3 & =(\\text{edge frequency})^3 - \\text{triangle frequency}\\\\\nT_2 & =3(\\text{edge frequency})^2(1-\\text{edge frequency}) - \\text{V-shape\nfrequency} \\end{align*} and prove a central limit theorem for $(T_2, T_3)$\nunder an Erd\\H{o}s-R\\'{e}nyi null model. We then analyze the power of the\nassociated $\\chi^2$ test statistic under a general class of alternative models.\nIn particular, when the alternative is a $k$-community stochastic block model,\nwith $k$ unknown, the power of the test approaches one. Moreover, the\nsignal-to-noise ratio required is strictly weaker than that required for\ncommunity detection. We also study the relation with other statistics over\nthree-node subgraphs, and analyze the error under two natural algorithms for\nsampling small subgraphs. Together, our results show how global structural\ncharacteristics of networks can be inferred from local subgraph frequencies,\nwithout requiring the global community structure to be explicitly estimated.\n", "versions": [{"version": "v1", "created": "Sat, 22 Apr 2017 03:34:30 GMT"}], "update_date": "2017-04-25", "authors_parsed": [["Gao", "Chao", ""], ["Lafferty", "John", ""]]}, {"id": "1704.06762", "submitter": "Antonio Forcina", "authors": "Antonio Forcina", "title": "Multiplicative models for frequency data, estimation and testing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is about models for a vector of probabilities whose elements must\nhave a multiplicative structure and sum to 1 at the same time; in certain\napplications, as basket analysis, these models may be seen as a constrained\nversion of quasi-independence. After reviewing the basic properties of these\nmodels, their geometric features as a curved exponential family are\ninvestigated. A new algorithm for computing maximum likelihood estimates is\npresented and new insights are provided on the underlying geometry. The\nasymptotic distribution of three statistics for hypothesis testing are derived\nand a small simulation study is presented to investigate the accuracy of\nasymptotic approximations.\n", "versions": [{"version": "v1", "created": "Sat, 22 Apr 2017 08:01:17 GMT"}, {"version": "v2", "created": "Sun, 18 Mar 2018 09:37:57 GMT"}, {"version": "v3", "created": "Fri, 23 Mar 2018 21:01:59 GMT"}, {"version": "v4", "created": "Sun, 15 Apr 2018 16:52:42 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Forcina", "Antonio", ""]]}, {"id": "1704.06787", "submitter": "Hamzeh Torabi", "authors": "Hamzeh Torabi and Sayyed Mahmoud Mirjalili and Hossein Nadeb", "title": "A new simple and powerful normality test for progressively Type-II\n  censored data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a new goodness-of-fit test for a location-scale family based\non progressively Type-II censored order statistics is proposed. Using Monte\nCarlo simulation studies, the present researchers have observed that the\nproposed test for normality is consistent and quite powerful in comparison with\nexisting goodness-of-fit tests based on progressively Type-II censored data.\nAlso, the new test statistic for a real data set is used and the results show\nthat our new test statistic performs well.\n", "versions": [{"version": "v1", "created": "Sat, 22 Apr 2017 12:09:03 GMT"}], "update_date": "2017-04-25", "authors_parsed": [["Torabi", "Hamzeh", ""], ["Mirjalili", "Sayyed Mahmoud", ""], ["Nadeb", "Hossein", ""]]}, {"id": "1704.06831", "submitter": "Shubhanshu Shekhar", "authors": "Shubhanshu Shekhar, Sebastien Roch and Siavash Mirarab", "title": "Species tree estimation using ASTRAL: how many genes are enough?", "comments": "22 pages, 2 figures, Accepted for oral presentation at RECOMB 2017;\n  Under review at IEEE TCBB", "journal-ref": null, "doi": "10.1109/TCBB.2017.2757930", "report-no": null, "categories": "q-bio.PE cs.CE math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Species tree reconstruction from genomic data is increasingly performed using\nmethods that account for sources of gene tree discordance such as incomplete\nlineage sorting. One popular method for reconstructing species trees from\nunrooted gene tree topologies is ASTRAL. In this paper, we derive theoretical\nsample complexity results for the number of genes required by ASTRAL to\nguarantee reconstruction of the correct species tree with high probability. We\nalso validate those theoretical bounds in a simulation study. Our results\nindicate that ASTRAL requires $\\mathcal{O}(f^{-2} \\log n)$ gene trees to\nreconstruct the species tree correctly with high probability where n is the\nnumber of species and f is the length of the shortest branch in the species\ntree. Our simulations, which are the first to test ASTRAL explicitly under the\nanomaly zone, show trends consistent with the theoretical bounds and also\nprovide some practical insights on the conditions where ASTRAL works well.\n", "versions": [{"version": "v1", "created": "Sat, 22 Apr 2017 18:25:44 GMT"}, {"version": "v2", "created": "Sat, 16 Sep 2017 03:04:45 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["Shekhar", "Shubhanshu", ""], ["Roch", "Sebastien", ""], ["Mirarab", "Siavash", ""]]}, {"id": "1704.06977", "submitter": "Xin Bing", "authors": "Xin Bing, Florentina Bunea, Yang Ning, Marten Wegkamp", "title": "Adaptive Estimation in Structured Factor Models with Applications to\n  Overlapping Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work introduces a novel estimation method, called LOVE, of the entries\nand structure of a loading matrix A in a sparse latent factor model X = AZ + E,\nfor an observable random vector X in Rp, with correlated unobservable factors Z\n\\in RK, with K unknown, and independent noise E. Each row of A is scaled and\nsparse. In order to identify the loading matrix A, we require the existence of\npure variables, which are components of X that are associated, via A, with one\nand only one latent factor. Despite the fact that the number of factors K, the\nnumber of the pure variables, and their location are all unknown, we only\nrequire a mild condition on the covariance matrix of Z, and a minimum of only\ntwo pure variables per latent factor to show that A is uniquely defined, up to\nsigned permutations. Our proofs for model identifiability are constructive, and\nlead to our novel estimation method of the number of factors and of the set of\npure variables, from a sample of size n of observations on X. This is the first\nstep of our LOVE algorithm, which is optimization-free, and has low\ncomputational complexity of order p2. The second step of LOVE is an easily\nimplementable linear program that estimates A. We prove that the resulting\nestimator is minimax rate optimal up to logarithmic factors in p. The model\nstructure is motivated by the problem of overlapping variable clustering,\nubiquitous in data science. We define the population level clusters as groups\nof those components of X that are associated, via the sparse matrix A, with the\nsame unobservable latent factor, and multi-factor association is allowed.\nClusters are respectively anchored by the pure variables, and form overlapping\nsub-groups of the p-dimensional random vector X. The Latent model approach to\nOVErlapping clustering is reflected in the name of our algorithm, LOVE.\n", "versions": [{"version": "v1", "created": "Sun, 23 Apr 2017 20:43:44 GMT"}, {"version": "v2", "created": "Thu, 28 Sep 2017 04:06:07 GMT"}, {"version": "v3", "created": "Thu, 22 Mar 2018 03:01:20 GMT"}, {"version": "v4", "created": "Thu, 20 Jun 2019 23:02:35 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Bing", "Xin", ""], ["Bunea", "Florentina", ""], ["Ning", "Yang", ""], ["Wegkamp", "Marten", ""]]}, {"id": "1704.06998", "submitter": "Mikhail  Ermakov s", "authors": "Mikhail Ermakov", "title": "On One Property of Tikhonov Regularization Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For linear inverse problem with Gaussian random noise we show that Tikhonov\nregularization algorithm is minimax in the class of linear estimators and is\nasymptotically minimax in the sense of sharp asymptotic in the class of all\nestimators. The results are valid if some a priori information on a Fourier\ncoefficients of solution is provided. For trigonometric basis this a priori\ninformation implies that the solution belongs to a ball in Besov space\n$B^r_{2\\infty}$.\n", "versions": [{"version": "v1", "created": "Sun, 23 Apr 2017 23:11:55 GMT"}, {"version": "v2", "created": "Thu, 27 Apr 2017 11:12:05 GMT"}, {"version": "v3", "created": "Wed, 7 Jun 2017 17:26:15 GMT"}], "update_date": "2017-06-08", "authors_parsed": [["Ermakov", "Mikhail", ""]]}, {"id": "1704.07012", "submitter": "Hiroyuki Masuyama Dr.", "authors": "Hiroyuki Masuyama", "title": "Binary sampling from discrete distributions", "comments": "This paper has been submitted to European Journal of Operational\n  Research", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers direct sampling methods from discrete target\ndistributions. The inverse transform sampling (ITS) method is one of the most\npopular direct sampling methods. The main purpose of this paper is to propose a\ndirect sampling algorithm that supersedes the binary-search ITS method (which\nis an improvement of the ITS method with binary search). The proposed algorithm\nis based on binarizing the support set of the target distribution. Thus, the\nproposed algorithm is referred to as binary sampling (BS). The BS algorithm\nconsists of two procedures: backward binary sampling (BBS) and forward binary\nsampling (FBS). The BBS procedure draws a single sample (the first sample) from\nthe target distribution while constructing a one-way random walk on a binary\ntree for the FBS procedure. By running the random walk, the FBS procedure\ngenerates the second and subsequent samples. The BBS and FBS procedures have\n$O(N)$ and $O(\\ln N)$ time complexities, respectively, and they also have\n$O(N)$ space complexity, where $N+1$ is the cardinality of the support set of\nthe target distribution. Therefore, the time and space complexities of the BS\nalgorithm are equivalent to those of the standard (possibly best) binary-search\nITS algorithm. However, the BS algorithm has two advantages over the standard\nbinary-search ITS algorithm. First, the BBS procedure is parallelizable and\nthus the total running time of the BS algorithm can be reduced. Second, the BS\nalgorithm is more accurate in terms of relative rounding error that influences\ngenerated samples.\n", "versions": [{"version": "v1", "created": "Mon, 24 Apr 2017 01:17:24 GMT"}, {"version": "v2", "created": "Fri, 12 May 2017 07:27:07 GMT"}, {"version": "v3", "created": "Sun, 28 May 2017 03:32:38 GMT"}, {"version": "v4", "created": "Sat, 3 Jun 2017 00:30:52 GMT"}], "update_date": "2017-06-06", "authors_parsed": [["Masuyama", "Hiroyuki", ""]]}, {"id": "1704.07040", "submitter": "Daniel Eck", "authors": "Daniel J. Eck", "title": "Bootstrapping for multivariate linear regression models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The multivariate linear regression model is an important tool for\ninvestigating relationships between several response variables and several\npredictor variables. The primary interest is in inference about the unknown\nregression coefficient matrix. We propose multivariate bootstrap techniques as\na means for making inferences about the unknown regression coefficient matrix.\nThese bootstrapping techniques are extensions of those developed in Freedman\n(1981), which are only appropriate for univariate responses. Extensions to the\nmultivariate linear regression model are made without proof. We formalize this\nextension and prove its validity. A real data example and two simulated data\nexamples which offer some finite sample verification of our theoretical results\nare provided.\n", "versions": [{"version": "v1", "created": "Mon, 24 Apr 2017 04:55:16 GMT"}, {"version": "v2", "created": "Tue, 12 Sep 2017 16:11:19 GMT"}], "update_date": "2017-09-13", "authors_parsed": [["Eck", "Daniel J.", ""]]}, {"id": "1704.07090", "submitter": "Bertrand Iooss", "authors": "Bertrand Iooss (GdR MASCOT-NUM, IMT), Amandine Marrel", "title": "An efficient methodology for the analysis and modeling of computer\n  experiments with large number of inputs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complex computer codes are often too time expensive to be directly used to\nperform uncertainty, sensitivity, optimization and robustness analyses. A\nwidely accepted method to circumvent this problem consists in replacing\ncpu-time expensive computer models by cpu inexpensive mathematical functions,\ncalled metamodels. For example, the Gaussian process (Gp) model has shown\nstrong capabilities to solve practical problems , often involving several\ninterlinked issues. However, in case of high dimensional experiments (with\ntypically several tens of inputs), the Gp metamodel building process remains\ndifficult, even unfeasible, and application of variable selection techniques\ncannot be avoided. In this paper, we present a general methodology allowing to\nbuild a Gp metamodel with large number of inputs in a very efficient manner.\nWhile our work focused on the Gp metamodel, its principles are fully generic\nand can be applied to any types of metamodel. The objective is twofold:\nestimating from a minimal number of computer experiments a highly predictive\nmetamodel. This methodology is successfully applied on an industrial computer\ncode.\n", "versions": [{"version": "v1", "created": "Mon, 24 Apr 2017 08:48:11 GMT"}], "update_date": "2017-04-25", "authors_parsed": [["Iooss", "Bertrand", "", "GdR MASCOT-NUM, IMT"], ["Marrel", "Amandine", ""]]}, {"id": "1704.07229", "submitter": "Zhiqiang Tan", "authors": "Zhiqiang Tan, Cun-Hui Zhang", "title": "Penalized Estimation in Additive Regression with High-Dimensional Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Additive regression provides an extension of linear regression by modeling\nthe signal of a response as a sum of functions of covariates of relatively low\ncomplexity. We study penalized estimation in high-dimensional nonparametric\nadditive regression where functional semi-norms are used to induce smoothness\nof component functions and the empirical $L_2$ norm is used to induce sparsity.\nThe functional semi-norms can be of Sobolev or bounded variation types and are\nallowed to be different amongst individual component functions. We establish\nnew oracle inequalities for the predictive performance of such methods under\nthree simple technical conditions: a sub-gaussian condition on the noise, a\ncompatibility condition on the design and the functional classes under\nconsideration, and an entropy condition on the functional classes. For random\ndesigns, the sample compatibility condition can be replaced by its population\nversion under an additional condition to ensure suitable convergence of\nempirical norms. In homogeneous settings where the complexities of the\ncomponent functions are of the same order, our results provide a spectrum of\nexplicit convergence rates, from the so-called slow rate without requiring the\ncompatibility condition to the fast rate under the hard sparsity or certain\n$L_q$ sparsity to allow many small components in the true regression function.\nThese results significantly broadens and sharpens existing ones in the\nliterature.\n", "versions": [{"version": "v1", "created": "Mon, 24 Apr 2017 13:50:11 GMT"}], "update_date": "2017-04-25", "authors_parsed": [["Tan", "Zhiqiang", ""], ["Zhang", "Cun-Hui", ""]]}, {"id": "1704.07461", "submitter": "Ashwin Pananjady", "authors": "Ashwin Pananjady, Martin J. Wainwright, Thomas A. Courtade", "title": "Denoising Linear Models with Permuted Data", "comments": "To appear in part at ISIT 2017, Aachen", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The multivariate linear regression model with shuffled data and additive\nGaussian noise arises in various correspondence estimation and matching\nproblems. Focusing on the denoising aspect of this problem, we provide a\ncharacterization the minimax error rate that is sharp up to logarithmic\nfactors. We also analyze the performance of two versions of a computationally\nefficient estimator, and establish their consistency for a large range of input\nparameters. Finally, we provide an exact algorithm for the noiseless problem\nand demonstrate its performance on an image point-cloud matching task. Our\nanalysis also extends to datasets with outliers.\n", "versions": [{"version": "v1", "created": "Mon, 24 Apr 2017 20:46:48 GMT"}], "update_date": "2017-04-26", "authors_parsed": [["Pananjady", "Ashwin", ""], ["Wainwright", "Martin J.", ""], ["Courtade", "Thomas A.", ""]]}, {"id": "1704.07513", "submitter": "Qiyang Han", "authors": "Qiyang Han", "title": "Oracle posterior contraction rates under hierarchical priors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We offer a general Bayes theoretic framework to derive posterior contraction\nrates under a hierarchical prior design: the first-step prior serves to assess\nthe model selection uncertainty, and the second-step prior quantifies the prior\nbelief on the strength of the signals within the model chosen from the first\nstep. In particular, we establish non-asymptotic oracle posterior contraction\nrates under (i) a local Gaussianity condition on the log likelihood ratio of\nthe statistical experiment, (ii) a local entropy condition on the\ndimensionality of the models, and (iii) a sufficient mass condition on the\nsecond-step prior near the best approximating signal for each model. The\nfirst-step prior can be designed generically. The posterior distribution enjoys\nGaussian tail behavior and therefore the resulting posterior mean also\nsatisfies an oracle inequality, automatically serving as an adaptive point\nestimator in a frequentist sense. Model mis-specification is allowed in these\noracle rates.\n  The local Gaussianity condition serves as a unified attempt of non-asymptotic\nGaussian quantification of the experiments, and can be easily verified in\nvarious experiments considered in [GvdV07a] and beyond. The general results are\napplied in various problems including: (i) trace regression, (ii)\nshape-restricted isotonic/convex regression, (iii) high-dimensional partially\nlinear regression, (iv) covariance matrix estimation in the sparse factor\nmodel, (v) detection of non-smooth polytopal image boundary, and (vi) intensity\nestimation in a Poisson point process model. These new results serve either as\ntheoretical justification of practical prior proposals in the literature, or as\nan illustration of the generic construction scheme of a (nearly) minimax\nadaptive estimator for a complicated experiment.\n", "versions": [{"version": "v1", "created": "Tue, 25 Apr 2017 01:56:38 GMT"}, {"version": "v2", "created": "Wed, 17 May 2017 03:22:03 GMT"}, {"version": "v3", "created": "Wed, 10 Feb 2021 22:02:43 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Han", "Qiyang", ""]]}, {"id": "1704.07531", "submitter": "Longshaokan Wang", "authors": "Longshaokan Wang, Eric B. Laber, Katie Witkiewitz", "title": "Sufficient Markov Decision Processes with Alternating Deep Neural\n  Networks", "comments": "31 pages, 3 figures, extended abstract in the proceedings of\n  RLDM2017. (v2 revisions: Fixed a minor bug in the code w.r.t. setting seed,\n  as a result numbers in the simulation experiments had some slight changes,\n  but conclusions stayed the same. Corrected typos. Improved notations.)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in mobile computing technologies have made it possible to monitor\nand apply data-driven interventions across complex systems in real time. Markov\ndecision processes (MDPs) are the primary model for sequential decision\nproblems with a large or indefinite time horizon. Choosing a representation of\nthe underlying decision process that is both Markov and low-dimensional is\nnon-trivial. We propose a method for constructing a low-dimensional\nrepresentation of the original decision process for which: 1. the MDP model\nholds; 2. a decision strategy that maximizes mean utility when applied to the\nlow-dimensional representation also maximizes mean utility when applied to the\noriginal process. We use a deep neural network to define a class of potential\nprocess representations and estimate the process of lowest dimension within\nthis class. The method is illustrated using data from a mobile study on heavy\ndrinking and smoking among college students.\n", "versions": [{"version": "v1", "created": "Tue, 25 Apr 2017 04:10:37 GMT"}, {"version": "v2", "created": "Sat, 17 Mar 2018 05:59:04 GMT"}], "update_date": "2018-03-20", "authors_parsed": [["Wang", "Longshaokan", ""], ["Laber", "Eric B.", ""], ["Witkiewitz", "Katie", ""]]}, {"id": "1704.07873", "submitter": "Marten Wegkamp", "authors": "Dragan Radulovic and Marten Wegkamp", "title": "Weak Convergence of Stationary Empirical Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We offer an umbrella type result which extends weak convergence of the\nclassical empirical process on the line to that of more general processes\nindexed by functions of bounded variation. This extension is not contingent on\nthe type of dependence of the underlying sequence of random variables. As a\nconsequence we establish weak convergence for stationary empirical processes\nindexed by general classes of functions under alpha mixing conditions.\n", "versions": [{"version": "v1", "created": "Tue, 25 Apr 2017 19:22:43 GMT"}, {"version": "v2", "created": "Wed, 13 Sep 2017 15:20:51 GMT"}], "update_date": "2017-09-14", "authors_parsed": [["Radulovic", "Dragan", ""], ["Wegkamp", "Marten", ""]]}, {"id": "1704.07897", "submitter": "Klas Modin", "authors": "Martin Bauer, Sarang Joshi, Klas Modin", "title": "Diffeomorphic random sampling using optimal information transport", "comments": "8 pages, 3 figures", "journal-ref": null, "doi": "10.1007/978-3-319-68445-1_16", "report-no": null, "categories": "math.NA math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we explore an algorithm for diffeomorphic random sampling of\nnonuniform probability distributions on Riemannian manifolds. The algorithm is\nbased on optimal information transport (OIT)---an analogue of optimal mass\ntransport (OMT). Our framework uses the deep geometric connections between the\nFisher-Rao metric on the space of probability densities and the right-invariant\ninformation metric on the group of diffeomorphisms. The resulting sampling\nalgorithm is a promising alternative to OMT, in particular as our formulation\nis semi-explicit, free of the nonlinear Monge--Ampere equation. Compared to\nMarkov Chain Monte Carlo methods, we expect our algorithm to stand up well when\na large number of samples from a low dimensional nonuniform distribution is\nneeded.\n", "versions": [{"version": "v1", "created": "Tue, 25 Apr 2017 20:16:29 GMT"}], "update_date": "2018-07-20", "authors_parsed": [["Bauer", "Martin", ""], ["Joshi", "Sarang", ""], ["Modin", "Klas", ""]]}, {"id": "1704.07971", "submitter": "Adel Javanmard", "authors": "Adel Javanmard and Jason D. Lee", "title": "A Flexible Framework for Hypothesis Testing in High-dimensions", "comments": "45 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.AP stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hypothesis testing in the linear regression model is a fundamental\nstatistical problem. We consider linear regression in the high-dimensional\nregime where the number of parameters exceeds the number of samples ($p> n$).\nIn order to make informative inference, we assume that the model is\napproximately sparse, that is the effect of covariates on the response can be\nwell approximated by conditioning on a relatively small number of covariates\nwhose identities are unknown. We develop a framework for testing very general\nhypotheses regarding the model parameters. Our framework encompasses testing\nwhether the parameter lies in a convex cone, testing the signal strength, and\ntesting arbitrary functionals of the parameter. We show that the proposed\nprocedure controls the type I error, and also analyze the power of the\nprocedure. Our numerical experiments confirm our theoretical findings and\ndemonstrate that we control false positive rate (type I error) near the nominal\nlevel, and have high power. By duality between hypotheses testing and\nconfidence intervals, the proposed framework can be used to obtain valid\nconfidence intervals for various functionals of the model parameters. For\nlinear functionals, the length of confidence intervals is shown to be minimax\nrate optimal.\n", "versions": [{"version": "v1", "created": "Wed, 26 Apr 2017 05:01:16 GMT"}, {"version": "v2", "created": "Tue, 19 Feb 2019 07:35:33 GMT"}, {"version": "v3", "created": "Sun, 14 Jul 2019 08:10:47 GMT"}, {"version": "v4", "created": "Sat, 21 Sep 2019 06:11:57 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Javanmard", "Adel", ""], ["Lee", "Jason D.", ""]]}, {"id": "1704.07977", "submitter": "Taku Moriyama", "authors": "Taku Moriyama and Yoshihiko Maesono", "title": "Smoothed nonparametric two-sample tests", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose new smoothed median and the Wilcoxon's rank sum test. As is\npointed out by Maesono et al.(2016), some nonparametric discrete tests have a\nproblem with their significance probability. Because of this problem, the\nselection of the median and the Wilcoxon's test can be biased too, however, we\nshow new smoothed tests are free from the problem. Significance probabilities\nand local asymptotic powers of the new tests are studied, and we show that they\ninherit good properties of the discrete tests.\n", "versions": [{"version": "v1", "created": "Wed, 26 Apr 2017 05:36:18 GMT"}], "update_date": "2017-04-27", "authors_parsed": [["Moriyama", "Taku", ""], ["Maesono", "Yoshihiko", ""]]}, {"id": "1704.08015", "submitter": "Taku Moriyama", "authors": "Taku Moriyama", "title": "A new method of joint nonparametric estimation of probability density\n  and its support", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a new method of joint nonparametric estimation of\nprobability density and its support. As is well known, nonparametric kernel\ndensity estimator has \"boundary bias problem\" when the support of the\npopulation density is not the whole real line. To avoid the unknown boundary\neffects, our estimator detects the boundary, and eliminates the boundary-bias\nof the estimator simultaneously. Moreover, we refer an extension to a simple\nmultivariate case, and propose an improved estimator free from the unknown\nboundary bias.\n", "versions": [{"version": "v1", "created": "Wed, 26 Apr 2017 08:49:01 GMT"}, {"version": "v2", "created": "Thu, 27 Apr 2017 03:05:41 GMT"}, {"version": "v3", "created": "Thu, 31 Aug 2017 05:39:26 GMT"}], "update_date": "2017-09-01", "authors_parsed": [["Moriyama", "Taku", ""]]}, {"id": "1704.08066", "submitter": "Matias Cattaneo", "authors": "Matias D. Cattaneo and Michael Jansson and Kenichi Nagasawa", "title": "Bootstrap-Based Inference for Cube Root Asymptotics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST econ.EM stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a valid bootstrap-based distributional approximation for\nM-estimators exhibiting a Chernoff (1964)-type limiting distribution. For\nestimators of this kind, the standard nonparametric bootstrap is inconsistent.\nThe method proposed herein is based on the nonparametric bootstrap, but\nrestores consistency by altering the shape of the criterion function defining\nthe estimator whose distribution we seek to approximate. This modification\nleads to a generic and easy-to-implement resampling method for inference that\nis conceptually distinct from other available distributional approximations. We\nillustrate the applicability of our results with four examples in econometrics\nand machine learning.\n", "versions": [{"version": "v1", "created": "Wed, 26 Apr 2017 11:41:13 GMT"}, {"version": "v2", "created": "Wed, 26 Jun 2019 14:14:59 GMT"}, {"version": "v3", "created": "Fri, 29 May 2020 13:59:24 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Cattaneo", "Matias D.", ""], ["Jansson", "Michael", ""], ["Nagasawa", "Kenichi", ""]]}, {"id": "1704.08227", "submitter": "Rahul Kidambi", "authors": "Prateek Jain, Sham M. Kakade, Rahul Kidambi, Praneeth Netrapalli and\n  Aaron Sidford", "title": "Accelerating Stochastic Gradient Descent For Least Squares Regression", "comments": "54 pages, 3 figures, 1 table; updated acknowledgements, minor title\n  change. Paper appeared in the proceedings of the Conference on Learning\n  Theory (COLT), 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is widespread sentiment that it is not possible to effectively utilize\nfast gradient methods (e.g. Nesterov's acceleration, conjugate gradient, heavy\nball) for the purposes of stochastic optimization due to their instability and\nerror accumulation, a notion made precise in d'Aspremont 2008 and Devolder,\nGlineur, and Nesterov 2014. This work considers these issues for the special\ncase of stochastic approximation for the least squares regression problem, and\nour main result refutes the conventional wisdom by showing that acceleration\ncan be made robust to statistical errors. In particular, this work introduces\nan accelerated stochastic gradient method that provably achieves the minimax\noptimal statistical risk faster than stochastic gradient descent. Critical to\nthe analysis is a sharp characterization of accelerated stochastic gradient\ndescent as a stochastic process. We hope this characterization gives insights\ntowards the broader question of designing simple and effective accelerated\nstochastic methods for more general convex and non-convex optimization\nproblems.\n", "versions": [{"version": "v1", "created": "Wed, 26 Apr 2017 17:30:27 GMT"}, {"version": "v2", "created": "Tue, 31 Jul 2018 18:11:32 GMT"}], "update_date": "2018-08-02", "authors_parsed": [["Jain", "Prateek", ""], ["Kakade", "Sham M.", ""], ["Kidambi", "Rahul", ""], ["Netrapalli", "Praneeth", ""], ["Sidford", "Aaron", ""]]}, {"id": "1704.08562", "submitter": "Robert Adler", "authors": "Robert J. Adler, Kevin Bartz, Sam C. Kou, Anthea Monod", "title": "Estimating thresholding levels for random fields via Euler\n  characteristics", "comments": "35 pages, 13 figures. 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Lipschitz-Killing curvature (LKC) regression, a new method to\nproduce $(1-\\alpha)$ thresholds for signal detection in random fields that does\nnot require knowledge of the spatial correlation structure. The idea is to fit\nobserved empirical Euler characteristics to the Gaussian kinematic formula via\ngeneralized least squares, which quickly and easily provides statistical\nestimates of the LKCs --- complex topological quantities that can be extremely\nchallenging to compute, both theoretically and numerically. With these\nestimates, we can then make use of a powerful parametric approximation via\nEuler characteristics for Gaussian random fields to generate accurate\n$(1-\\alpha)$ thresholds and $p$-values. The main features of our proposed LKC\nregression method are easy implementation, conceptual simplicity, and\nfacilitated diagnostics, which we demonstrate in a variety of simulations and\napplications.\n", "versions": [{"version": "v1", "created": "Thu, 27 Apr 2017 13:33:00 GMT"}], "update_date": "2017-04-28", "authors_parsed": [["Adler", "Robert J.", ""], ["Bartz", "Kevin", ""], ["Kou", "Sam C.", ""], ["Monod", "Anthea", ""]]}, {"id": "1704.08672", "submitter": "Kevin Yang", "authors": "Kevin Yang", "title": "Local Marchenko-Pastur Law for Random Bipartite Graphs", "comments": "24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.CO math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is the first chapter of three of the author's undergraduate\nthesis. We study the random matrix ensemble of covariance matrices arising from\nrandom $(d_b, d_w)$-regular bipartite graphs on a set of $M$ black vertices and\n$N$ white vertices, for $d_b \\gg \\log^4 N$. We simultaneously prove that the\nGreen's functions of these covariance matrices and the adjacency matrices of\nthe underlying graphs agree with the corresponding limiting law (e.g.\nMarchenko-Pastur law for covariance matrices) down to the optimal scale. This\nis an improvement from the previously known mesoscopic results. We obtain\neigenvector delocalization for the covariance matrix ensemble as consequence,\nas well as a weak rigidity estimate.\n", "versions": [{"version": "v1", "created": "Thu, 27 Apr 2017 17:35:43 GMT"}], "update_date": "2017-04-28", "authors_parsed": [["Yang", "Kevin", ""]]}, {"id": "1704.08825", "submitter": "Oliver Lang", "authors": "Oliver Lang and Mario Huemer", "title": "Classical Widely Linear Estimation of Real Valued Parameter Vectors in\n  Complex Valued Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work investigates the task of estimating a real valued parameter vector\nbased on complex valued measurements in a classical set-up. The application of\nstandard estimators in general results in complex valued estimates of the real\nvalued parameter vector. To avoid this systematic error, widely linear\nclassical estimators that produce real valued estimates are investigated. One\nof these estimators is the widely linear least squares (WLLS) estimator\nproposed in this work, which does not utilize any noise statistics. Further, we\nintroduce the best widely linear unbiased estimator (BWLUE) for real valued\nparameter vectors. The proposed estimators in general outperform their standard\ncounterparts LS estimator and BWLUE, respectively, and they only require half\nas many complex valued measurements. We compare the novel approaches to\nstandard classical estimators in two application scenarios. One of these\napplications considers the estimation of a real valued impulse response based\non noisy measurements of the system's magnitude and phase response. For this\nproblem, we propose a novel two-step approach based on the introduced widely\nlinear concepts that outperforms standard estimators.\n", "versions": [{"version": "v1", "created": "Fri, 28 Apr 2017 07:17:28 GMT"}], "update_date": "2017-05-01", "authors_parsed": [["Lang", "Oliver", ""], ["Huemer", "Mario", ""]]}, {"id": "1704.08964", "submitter": "Roger Laeven", "authors": "Z. Merrick Li, Roger J. A. Laeven, Michel H. Vellekoop", "title": "Dependent Microstructure Noise and Integrated Volatility Estimation from\n  High-Frequency Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we develop econometric tools to analyze the integrated\nvolatility of the efficient price and the dynamic properties of microstructure\nnoise in high-frequency data under general dependent noise. We first develop\nconsistent estimators of the variance and autocovariances of noise using a\nvariant of realized volatility. Next, we employ these estimators to adapt the\npre-averaging method and derive a consistent estimator of the integrated\nvolatility, which converges stably to a mixed Gaussian distribution at the\noptimal rate $n^{1/4}$. To refine the finite sample performance, we propose a\ntwo-step approach that corrects the finite sample bias, which turns out to be\ncrucial in applications. Our extensive simulation studies demonstrate the\nexcellent performance of our two-step estimators. In an empirical study, we\ncharacterize the dependence structures of microstructure noise in several\npopular sampling schemes and provide intuitive economic interpretations; we\nalso illustrate the importance of accounting for both the serial dependence in\nnoise and the finite sample bias when estimating integrated volatility.\n", "versions": [{"version": "v1", "created": "Fri, 28 Apr 2017 14:55:26 GMT"}, {"version": "v2", "created": "Tue, 12 Jun 2018 19:40:09 GMT"}], "update_date": "2018-06-14", "authors_parsed": [["Li", "Z. Merrick", ""], ["Laeven", "Roger J. A.", ""], ["Vellekoop", "Michel H.", ""]]}, {"id": "1704.08979", "submitter": "Tilmann Gneiting", "authors": "Tilmann Gneiting", "title": "When is the mode functional the Bayes classifier?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In classification problems, the mode of the conditional probability\ndistribution, i.e., the most probable category, is the Bayes classifier under\nzero-one or misclassification loss. Under any other cost structure, the mode\nfails to persist.\n", "versions": [{"version": "v1", "created": "Fri, 28 Apr 2017 15:31:12 GMT"}], "update_date": "2017-05-01", "authors_parsed": [["Gneiting", "Tilmann", ""]]}]